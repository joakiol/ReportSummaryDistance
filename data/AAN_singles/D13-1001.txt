Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1?11,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsEvent-based Time Label Propagation for Automatic Dating of News ArticlesTao Ge Baobao Chang?
Sujian Li Zhifang SuiKey Laboratory of Computational Linguistics, Ministry of EducationSchool of Electronics Engineering and Computer Science, Peking UniversityNo.5 Yiheyuan Road, Haidian District, Beijing, P.R.China, 100871{getao,chbb,lisujian,szf}@pku.edu.cnAbstractSince many applications such as timeline sum-maries and temporal IR involving temporalanalysis rely on document timestamps, thetask of automatic dating of documents hasbeen increasingly important.
Instead of usingfeature-based methods as conventional mod-els, our method attempts to date documentsin a year level by exploiting relative tempo-ral relations between documents and events,which are very effective for dating documents.Based on this intuition, we proposed an event-based time label propagation model calledconfidence boosting in which time label in-formation can be propagated between docu-ments and events on a bipartite graph.
The ex-periments show that our event-based propaga-tion model can predict document timestampsin high accuracy and the model combined witha MaxEnt classifier outperforms the state-of-the-art method for this task especially whenthe size of the training set is small.1 IntroductionTime is an important dimension of any informa-tion space and can be useful in information re-trieval, question-answering systems and timelinesummaries.
In the applications involving tempo-ral analysis, document timestamps are very useful.For instance, temporal information retrieval mod-els take into consideration the document?s creationtime for document retrieval and ranking (Kalczyn-ski and Chou, 2005; Berberich et al 2007) for bet-ter dealing with time-sensitive queries; some infor-?Corresponding authormation retrieval applications such as Google Scholarcan list articles published during the time a userspecifies for better satisfying users?
needs.
In addi-tion, timeline summarization techniques (Hu et al2011; Binh Tran et al 2013) and some event-eventordering models (Chambers and Jurafsky, 2008;Yoshikawa et al 2009) also rely on the timestamps.Unfortunately, many documents on the web do nothave a credible timestamp, as Chambers (2012) re-ported.
Therefore, it is significant to date docu-ments, that is to predict document creation time.One typical method for dating document is basedon temporal language models, which were first usedfor dating by de Jong et al(2005).
They learnedlanguage models (unigram) for specific time periodsand scored articles with normalized log-likelihoodratio scores.
The other typical approach for the taskwas proposed by Nathanael Chambers (2012).
InChambers?s work, discriminative classifiers ?
max-imum entropy (MaxEnt) classifiers were used byincorporating linguistic features and temporal con-straints for training, which outperforms the previoustemporal language models on a subset of GigawordCorpus (Graff et al 2003).However, the conventional methods have somelimitations because they predict creation time ofdocuments mainly based on feature-based modelswithout understanding content of documents, whichmay lead to wrong predictions in some cases.
Forinstance, assume that D1 and D2 are documentswhose content is given as follows:(D1) Sudan last year accused Eritrea ofbacking an offensive by rebels in the east-ern border region.1(D2) Two years ago, Sudan accused Er-itrea of backing an offensive by rebels inthe eastern border region.SinceD1 andD2 share many important features, theprevious dating methods are very likely to predictthe same timestamp for the two documents.
How-ever, it will be easy to infer that the creation time ofD1 should be one year earlier than that of D2 if weanalyze the content of the two documents.Unlike the previous methods, this paper exploitsrelative temporal relations between events and doc-uments for dating documents on the basis of an un-derstanding of document content.It is known that each event in a news article hasa relative temporal relation with the document.
Byanalyzing the relative temporal relation, time of theevent can be known if we know the document times-tamp; on the other hand, if the time of an event isknown, it can also be used to predict the creationtime of documents mentioning the event, which canbe best demonstrated with the above-mentioned ex-ample of D1 and D2.
In the example, ?last year?is an important cue to infer that the event mentionedby the documents occurred in 2002 if we know thetimestamp of D1 is 2003.
With the information thatthe event occurred in 2002, it can also be inferredfrom the temporal expression ?Two years ago?
thatD2 was written in 2004.
In this way, the timestampof the labeled document (D1) is propagated to theunlabeled document (D2) through the event both ofthem mention, which is the main intuition of this pa-per.In fact, this intuition seems practical to date doc-uments on the web because web data is very re-dundant.
Many documents on the web can be con-nected via events because an event is usually men-tioned by different documents.
According to ouranalysis of a collection of news articles spanning 5years, it is found that an event is mentioned by 3.44news articles on average; on the other hand, a doc-ument usually refers to multiple events.
Therefore,if one knows a document timestamp, time of eventsthe document mentions can be obtained by analyz-ing the relative temporal relations between the doc-ument and the events.
Likewise, if the time of anevent is known, then it can be used to predict cre-ation time of the documents which mention it.Based on the intuition, we proposed an event-based time label propagation model called confi-dence boosting in which timestamps are propagatedaccording to relative temporal relations betweendocuments and events.
In this way, documents canbe dated with an understanding of content so thatthis model can date document more credibly.
To ourknowledge, it is the first time that the relative tempo-ral relations between documents and events are ex-ploited for dating documents, which is proved to beeffective by the experimental results.2 Event-based Time Label PropogationAs mentioned above, the relative temporal relationsbetween documents and events are useful for dat-ing documents.
By analyzing the temporal relations,even if there are only a small number of documentslabeled with timestamps, this information can bepropagated to documents connected with them on abipartite graph using breadth first traversal (BFS).Figure 1: An example of BFS-based propagationAs shown in figure 1, there are two kinds of nodesin the bipartite graph.
A document node is a singledocument while an event node represents an event.The edge between a document node and an eventnode means that the document mentions the event.Also, the edge carries the information of the rela-tive temporal relation between the document and theevent.
The label propagation from node i to node jwill occur if BFS condition which is defined as fol-lows is satisfied:{eij ?
Ei ?
L and j /?
L(BFS condition)When the timestamp of i is propagated to j:Y (j) = Y (i) + ?
(i, j)L = L ?
{j}where E is the set of edges of the bipartite graph,eij denotes the edge between node i and j, L is theset of nodes which have been already labeled withtimestamps, Y (i) is the year of node i and ?
(i, j) isthe relative temporal relation between node i and j.2In figure 1, the timestamp of document D1 is 2003,which is known.
This information can be propagatedto its adjacent nodes i.e.
the event nodes it men-tions according to the relative temporal relations.Then, these event nodes propagate their timestampsto other documents which mention them.
By re-peating this process, the timestamp of the documentcan be propagated to documents which are reachablefrom the initially labeled document on the bipartitegraph.Although the BFS-based propagation process canpropagate timestamps from few labeled documentsto a large number of unlabeled ones, it has two short-comings for this task.
First, once one timestamp ispropagated incorrectly, this error will lead to moremistakes in the following propagations.
If such anerror occurred at the beginning of the propagationprocess, it would lead to propagation of errors.
Sec-ond, BFS-based method cannot address conflict ofpredictions during propagation, which is shown infigure 2.Figure 2: Conflict of predictions during propagationTo address the problems of the BFS-basedmethod, we proposed a novel propagation modelcalled confidence boosting model which improvesthe BFS-based model by optimizing the global con-fidence of the bipartite graph.
In the confidenceboosting model, every node in the bipartite graphhas a confidence which measures the credibility ofthe predicted timestamp of the node.
When thetimestamp of a node is propagated to other nodes,its confidence will be also propagated to the tar-get nodes with some loss.
The loss of confi-dence is called confidence decay.
Formally, theconfidence decay process is described as follows:c(j) = c(i)?
?
(i, j)where c(i) denotes confidence of node i and?
(i, j) is the decay factor from node i tonode j.
For guaranteeing that timestampscan be propagated on the bipartite graph cred-ibly, we define the following condition whichis called CB (Confidence Boosting) condition:{eij ?
Ec(i)?
?
(i, j) > c(j)(CB condition)In the confidence boosting model, propagation fromnode i to node j will occur only if CB condition issatisfied.
When timestamps are propagated on thebipartite graph, timestamps and confidence of nodeswill be updated dynamically.
A node with high con-fidence is more active than nodes with low confi-dence to propagate its timestamp because a nodewith high confidence is more likely to satisfy the CBcondition for propagating its timestamp.
Moreover,a prediction with low confidence can be corrected bythe prediction with high confidence.
Therefore, theconfidence boosting model can address both prop-agation of errors and conflict of predictions whichcannot be tackled by the BFS-based model.However, there are challenges for running suchpropagation models in practice.
First, the relativetemporal relations between documents and eventsare usually unavailable.
Second, events extractedfrom different documents do not have any connec-tion even if they refer to the same event.
There-fore, each event is connected with only one docu-ment in the bipartite graph and thus cannot prop-agate its timestamp to other documents unless weperform event coreference resolution.
Third, propa-gations from generic events are very likely to lead topropagation errors because generic events can hap-pen in any year.
Also, how to set the confidence anddecay factors reasonably in practice for a confidenceboosting model is worthy of investigation.
All thesechallenges for the propagation models and their cor-responding solutions will be discussed in Section 3.3 Details of Event-based PropagationModelsIn this section, details of the event-based time la-bel propagation models including challenges andtheir corresponding solutions are presented.
We firstdiscuss the event extraction and processing involv-ing relative temporal relation mining, event coref-erence resolution and distinguishing specific extrac-tions from generic ones in Section 3.1.
Then, weshow the confidence boosting algorithm in detail inSection 3.2.33.1 Event extraction and processingAs mentioned in previous sections, events play a keyrole in the propagation models.
We define an eventas a Subject-Predicate-Object (SPO) triple.
To ex-tract events from raw text, an open information ex-traction software - ReVerb (Fader et al 2011) isused.
ReVerb is a program that automatically iden-tifies and extracts relationships from English sen-tences.
It takes raw text as input and outputs SPOtriples which are called extractions.However, extractions extracted by ReVerb cannotbe used directly for our propagation models for threemain reasons.
First, the relative temporal relationsbetween documents and the extractions are unavail-able.
Second, the extractions extracted from differ-ent documents do not have any connection even ifthey refer to the same event.
Third, propagationsfrom generic events are very likely to lead to propa-gation errors.For addressing the three challenges for the prop-agation models, we first presented a rule-basedmethod for mining the relative temporal relations be-tween extractions and documents in Section 3.1.1.Then, an efficient event coreference resolutionmethod is introduced in Section 3.1.2.
Finally, themethod for distinguishing specific extractions fromgeneric ones is shown in Section 3.1.3.3.1.1 Relative temporal relation miningWe used a rule-based method to extract temporalexpressions and used Stanford parser (De Marneffeet al 2006) to analyze association between the tem-poral expressions and the extractions.
Specifically,we define that an extraction is associated with a tem-poral expression if there is an arc from the predicateof the extraction to the temporal expression in thedependency tree.
For a certain extraction, there arethe following four cases whose instances are shownin table 1 for handling.Case 1: The extraction is associated with an abso-lute temporal expressions with year mentions in thesentence.In this case, the time of the extraction is equal tothe year mention:Y (ex) = Y earMentionFor the example in table 1, Y (ex) = 1999.Case 2: The extraction is associated with a relativetemporal expression (not involving year) in the sen-Case Instance1 In 1999, South Korea exported 89,000tons of pork to Japan.2In April, however, the BOI investmentsshowed marked improvement.Last month, Kazini vowed to resign histop army job.3 Julius Erving moved with his family toFlorida three years ago.4 The meeting focused on ways to revivethe stalled Mideast peace process.Table 1: Instances of various temporal expressionstence.In this case, the time of the extraction is equal tothe creation time of the document:Y (ex) = Y (d)Case 3: The extraction is associated with a relativetemporal expression (involving specific year gap) inthe sentence.In this case, the time of the extraction is computedas follows:Y (ex) = Y (d)?
Y earGapFor the example in table 1, Y (ex) = Y (d)?
3.Case 4: The extraction is not associated with anytemporal expression in the sentence or the othercases.In this case, it is difficult to recognize the rela-tive temporal relations.
However, timeliness can beleveraged to determine the relations as a heuristicmethod.
It is known that timeliness is an importantfeature of news so that events reported by a news ar-ticle usually took place a couple of days or weeksbefore the article was written.
Therefore, we heuris-tically consider the year of the extraction is the samewith that of its source document in this case:Y (ex) = Y (d)In the cases except case 1, the relative tempo-ral relation between an extraction and the docu-ment it comes from can be determined.
To evalu-ate the performance of the rule-based method, wesampled 3,000 extractions from documents writtenin the year of 1995-1999 of Gigaword corpus andmanually labeled these extractions with a timestampbased on their context and their corresponding docu-ment timestamps as golden standard.
Table 2 shows4the accuracy of each case which will be used as apart of the decay factor in the confidence boostingmodel.Case Accuracy1 0.774(168/217)2 0.994(844/849)3 0.836(281/336)4 0.861(1376/1598)Total 0.890(2669/3000)Table 2: Accuracy of the four casesWe define the set of these determined relative tem-poral relations R as follows:R = {rd,ex|d = doc(ex), ex ?
C2 ?
C3 ?
C4}rd,ex =< d, ex, ?
(d, ex) >?
(d, ex) = ??
(ex, d) = {0,?1,?2,?3, ...}where Ck is the set of extractions in case k anddoc(ex) is the document which extraction ex comesfrom.
rd,ex is a triple describing the relative tempo-ral relation between d and ex.
For example, triplerd,ex =< d, ex,?1 > means that the time of ex-traction ex is one year before the time of documentd.3.1.2 Event coreference resolutionExtractions from different documents have noconnections.
However, there are a great number ofextractions referring to the same event.
For find-ing such coreferential event extractions efficiently,hierarchical agglomerative clustering (HAC) is usedto cluster highly similar extractions into one cluster.We use cosine to measure the similarity between ex-tractions and select bag of words as features.
Notethat it is less meaningful to cluster the extractionsfrom the same document because coreferential ex-tractions from the same document are not helpful fortimestamp propagations.
For this reason, similaritybetween extractions from the same documents is setto 0.For HAC, selection of threshold is important.
Ifthe threshold is set too high, only a few extractionscan be clustered despite high purity; on the contrary,if the threshold is set too low, purity of clusters willdescend.
In fact, selection of threshold is a trade-offbetween the precision and recall of event corefer-ence resolution.
For selecting a suitable threshold,extractions from documents written in 1995-1999are used as a development set.In practice, it is difficult for us to directly evalu-ate the performance of the coreference resolution ofevent extractions without golden standard which re-quires much labors for manual annotations.
Alterna-tively, entropy which measures the purity of clustersis used for evaluation because it can indirectly re-flect the precision of coreference resolution to someextent:Entropy = ?
?jnjn?iP (i, j)?
log2 P (i, j)where P (i, j) is the probability of finding an extrac-tion whose timestamp is i in the cluster j, nj is thenumber of items in cluster j and n is the total num-ber of extractions.
Note that timestamp of an extrac-tion is assigned based on its document timestampusing the method proposed in Section 3.1.1.Figure 3 shows the effect of selection of thethreshold on cluster performance.
It can be foundthat when the threshold reaches 0.8, the entropystarts descending gently and is low enough.
Sincewe want to find as many coreferential extractions aspossible on the premise that the precision is good,the threshold is set to 0.8.
Note that extractionswhich are single in one cluster will be filtered outbecause they do not have any connections with anyother documents.0.6 0.65 0.7 0.75 0.8 0.85 0.90.20.250.30.350.40.450.50.550.60.65ThresholdEntropyFigure 3: Entropy of clusters under different thresholds3.1.3 Distinguishing specific events fromgeneric onesNot all extractions extracted by ReVerb refer toa specific event.
For instance, the extraction ?Ger-many?s DAX index was down 0.2 percent?
is un-desirable for our task because it refers to a generic5event and this event may occur in any year.
In otherwords, it is not able to indicate a certain timestampand thus propagations from a generic event node arevery likely to result in propagation errors.
In con-trast, the extraction ?some of the provinces in Chinawere hit by SARS?
refers to a specific event whichtook place in 2003.
For our task, such specific eventextractions which are associated with one certaintimestamp are desirable.
For the sake of distinguish-ing such extractions from the generic ones, a Max-Ent classifier is used to classify extractions as eitherspecific ones or generic ones.Training Set Generation A training set is indis-pensable for training a MaxEnt classifier.
In orderto generate training examples, we performed HACdiscussed in Section 3.1.2 for event coreference res-olution on extractions from all documents writtenin May and June of 1995-1999 and then analyzedeach cluster.
If extractions in a cluster have differenttimestamps, then the extractions in this cluster willbe labeled as generic extractions (negative); other-wise, extractions in the cluster are labeled as spe-cific ones (positive).
In this way, the training set canbe generated without manually labeling.
To avoidbias of positive and negative examples, we sampled3,500 positive examples and 3,500 negative exam-ples to train the model.Feature Selection The following features were se-lected for training:Named Entities: People and places are often dis-cussed during specific time periods, particularly innews genre.
Intuitively, if an extraction containsspecific named entities then this extraction is lesslikely to be a generic event.
If an extraction con-tains named entities, types and uninterrupted tokensof the named entities will be included as features.Numeral: According to our analysis of the train-ing set generated by the above-mentioned method,generic extractions usually contain numerals.
Forexample, the extraction ?15 people died in this ac-cident?
and the extraction ?225 people died in thisaccident?
have the same tokens except numerals andthey are labeled as a generic event because they areclustered into one group due to high similarity butthey in fact refer to different events happening indifferent years.
Therefore, if an extraction containsnumerals, the feature ?NUM?
will be included.Bag of words: Bag of words can also be an indicatorof specific extractions and generic ones.
For exam-ple, an extraction containing ?stock?, ?index?, ?fell?and ?exchange?
is probably a generic one.The model obtained after training can be used topredict whether an extraction is a specific one.
Wedefine P (S = 1|ex) as the probability that an ex-traction is a specific one, which can be provided bythe classifier.
Extractions whose probability to be aspecific one is less than 0.05 are filtered out.
For theother extractions, this probability is used as a part ofthe decay factor in the confidence boosting model,which will be discussed in detail in Section 3.2.3.2 Confidence boostingAfter extracting and processing the event extrac-tions, relative temporal relations between documentsand events can be constructed.
This can be for-mally represented by a bipartite graph G=?V,E?.There are two kinds of nodes on the bipartite graph:document nodes and event nodes.
Slightly dif-ferent with the event node mentioned in Section2, an event node in practice is a cluster of coref-erential extractions and it can be connected withmultiple document nodes.
Note that the bipar-tite graph does not contain any isolate node.
Forbriefness, we define DNode as the set of docu-ment nodes and ENode as the set of event nodes.The set of edges E is formally defined as follows:E = {eij , eji|i ?
DNode, j ?
ENode, ri,j ?
R}where R is the set of relative temporal relations de-fined as Section 3.1.1.3.2.1 Confidence and decay factorAs mentioned in Section 2, the confidence of anode measures the credibility of the predicted times-tamp.
According to the definition, we set the confi-dence of initially labeled nodes to 1 and set confi-dence of nodes without any timestamp to 0 in prac-tice.
When the timestamp of a node is propagatedto another node, its confidence will be propagated tothe target node with some loss, as discussed in Sec-tion 2.
The confidence loss is caused by two factorsin practice.
The first one is the credibility of the rel-ative temporal relation between two nodes and theother one depends on whether an extraction refers toa specific event.Relative temporal relations between documents6and extractions we mined using the rule-basedmethod in Section 3.1.1 are not absolutely correct.The credibility of the relations has an effect on theconfidence decay.
Formally, we used pi(i, j) to de-note the credibility of the relative temporal relationbetween node i and node j.
The credibility of a rel-ative temporal relation in each case can be estimatedthrough table 2.
If the credibility of the relative tem-poral relation between i and j is low, propagationfrom node i to j probably leads to error.
Therefore,the confidence loss should be much in this case.
Oncontrary, if the relation is highly credible, it will beless likely that propagation errors occur.
Therefore,the confidence loss should be little.In addition, whether an extraction refers to ageneric event or a specific one exerts an impact onthe confidence loss.
If an extraction refers to ageneric event, then the extractions in the same clus-ter with it probably have different timestamps.
Sinceour propagation model assumes that extractions in acluster are coreferent and thus they should have thesame timestamp, propagations from a generic eventnode are very likely to result in propagation errors.Therefore, the timestamp of a generic event nodein fact is less credible for propagations and confi-dence of such event nodes should be low for limitingpropagations from the nodes.
For this reason, prop-agation from a document node to a generic eventnode leads to much loss of confidence.
We definethe probability that an event node refers to a specificevent as follows:P (S = 1|enode) =1|C|?ex?CP (S = 1|ex)where C is the set of extractions in the event nodeand P (S = 1|ex) is the probability that an extrac-tion refers to a specific event, which can be providedby the MaxEnt classifier discussed in Section 3.1.3.Considering the two factors for confidence loss,we formally define the decay factor by (1).?
(s, t) = (1){pi(s, t) if t ?
DNodepi(s, t)?
P (S = 1|t) otherwise3.2.2 Confidence boosting algorithmIn confidence boosting model, the propagationfrom i to j will occur only if the CB condition isFigure 4: Algorithm of confidence boostingsatisfied.
The confidence boosting propagation pro-cess can be described as figure 4.Whenever timestamps are propagated to othernodes, the global confidence of the bipartite graphwill increase.
For this reason, this propagation pro-cess is called confidence boosting.
In this model,a node with high confidence is more active thannodes with low confidence to propagate its times-tamp.
Moreover, a prediction with low confidencecan be corrected by the prediction with high con-fidence.
Therefore, the confidence boosting modelcan alleviate the problem of propagation of errorsto some extent and handle conflict of predictions.Thus, it can propagate timestamps more crediblythan the BFS-based model.
It can also be provedthat each node on the bipartite graph must reach thehighest confidence it can reach so that the globalconfidence of the bipartite graph must be optimalwhen the confidence boosting propagation processends regardless of propagation orders, which will bediscussed in Section 3.2.3.3.2.3 Proof of the optimality of confidenceboostingProof by contradiction can be used to prove thatpropagation orders do not affect the optimality of theconfidence boosting model.Proof Assume by contradiction that there is somenode that does not reach its highest confidence it canreach when a confidence boosting process in propa-gation order A ends:?vt s.t.
cA(vt) < c?
(vt)where cA(vt) is the confidence of vt when thepropagation process in order A ends and c?
(vt) isthe highest confidence that vt can reach.
Assumethat (v1, v2, ?
?
?
, vt?1, vt) is the optimal propagation7path from the propagation source node v1 to thenode vt that leads to the highest confidence of vt,which means that c?
(vt) = c?
(vt?1) ?
?
(vt?1, vt),c?
(vt?1) = c?
(vt?2) ?
?
(vt?2, vt?1), ..., c?
(v2) =c?
(v1) ?
?
(v1, v2).
Then according to CB condi-tion, since cA(vt?1) ?
?
(vt?1, vt) ?
cA(vt) <c?
(vt) = c?
(vt?1) ?
?
(vt?1, vt), the inequalitycA(vt?1) < c?
(vt?1) must hold.
Similarly, it can beeasily inferred that cA(vt?2) < c?
(vt?2) and finallycA(v1) < c?(v1).
Since v1 is the source node whosetimestamp is initially labeled and its confidence is 1,the inequality cA(v1) < c?
(v1) cannot hold.
Thus,the assumption that cA(vt) < c?
(vt) cannot be sat-isfied.
Therefore, it can be proved that each nodeon the bipartite graph must reach the highest con-fidence it can reach so that the global confidence ofthe bipartite graph must be optimal when confidenceboosting propagation process ends no matter whatorder time labels are propagated in.4 ExperimentsIn this section, we evaluate the performance of ourtime label propagation models and different auto-matic document dating models on the Gigaworddataset.
We first present the experimental setting.Then we show experimental results and perform ananalysis.4.1 Experimental SettingDataset To simulate the environment of the webwhere data is very redundant, we use all documentswritten in April, June, July and September of 2000-2004 of Gigaword Corpus as dataset instead of sam-pling a subset of documents from each period.
Thedataset contains 900,199 news articles.Pre-processing Many extractions extracted by Re-Verb are short and uninformative and do not carryany valuable information for propagating temporalinformation.
Also, some extractions do not referto events which already happened.
These extrac-tions may affect the performance of event corefer-ence resolution and the rule-based method proposedin Section 3.1.1 for mining relative temporal rela-tions.
Therefore, we filter out these undesirable ex-tractions in advance with a rule-based method.
Therules are shown in table 3.
This preprocessing re-moves large numbers of ?bad?
extractions which areundesirable for our task.
As a result, not only com-putation efficiency but also precision of event coref-erence resolution will be improved.Rule1 If the number of tokens of the extrac-tion is less than 5 then this extractionwill be filtered out.Rule2 If the maximum idf of terms of the ex-traction is less than 3.0 then this ex-traction will be filtered out.Rule3 If the tense of the extraction is not pasttense then this extraction will be fil-tered out.Rule4 If the extraction is the content of di-rect quotation then this extraction willbe filtered out.Table 3: Pre-processing Rules|DNode| 550,124|ENode| 968,064|E| 3,104,666Table 4: Basic information of the bi-partite graphBasic information of the document-event bipartitegraph constructed is shown in table 4.Evaluation To evaluate the performance of thepropagation models for the task of dating on differ-ent sizes of the training set, we used different sizesof the labeled documents for training and consid-ered the remaining documents as the test set.
Notethat the training set is randomly sampled from thedataset.
To be more persuasive, we repeated aboveexperiments for five times.However, in the time label propagation process,not all documents can be labeled.
For those doc-uments which cannot be labeled in the process ofpropagation, a MaxEnt classifier serves as a comple-mentary approach to predict their timestamps.
Forthe MaxEnt classifier, unigrams and named entitiesare simply selected as features and the initially la-beled documents as well as documents labeled dur-ing propagation process are used for training.Baseline methods are temporal language modelsproposed by de Jong et al(2005) and the state-of-the-art discriminative classifier with linguistic fea-tures and temporal constraints which was proposed8Initially Labeled 1k 5k 10k 50k 100k 200k 500kReached Min 443980 448653 453022 484562 518603 599724 732701Reached Max 444266 448998 454028 484996 519333 579878 732799Reached Avg 444107 448742 453786 484622 519110 579835 732758Prop Ratio 444.1 89.7 45.4 9.7 5.2 2.9 1.5Prop acc(BFS) 0.438 0.515 0.551 0.646 0.691 0.725 0.775Prop acc(CB) 0.494 0.569 0.603 0.701 0.746 0.776 0.807Table 5: Performance of PropagationInitially Labeled 1k 5k 10k 50k 100k 200k 500kTemporal LMs 0.277 0.323 0.353 0.412 0.422 0.425 0.420Maxent(Unigrams) 0.326 0.378 0.407 0.486 0.517 0.553 0.590Maxent(Unigrams+NER) 0.331 0.383 0.418 0.506 0.549 0.590 0.665Chambers?s 0.331 0.386 0.423 0.524 0.571 0.615 0.690BFS+Maxent 0.459 0.508 0.533 0.595 0.626 0.658 0.707CB+Maxent 0.486 0.535 0.559 0.624 0.655 0.685 0.726Table 6: Overall accuracy of dating modelsby Nathanael Chambers (2012).
In Chambers?s jointmodel, the interpolation parameter ?
is set to 0.35which is considered optimal in his work.4.2 Experimental ResultsTable 5 shows the performance of propagation mod-els where Reached denotes the number of docu-ments labeled when the propagation process ends,prop ratio and prop accuracy are defined as follows:Prop Ratio =#ReachedDocNodes#LabeledDocNodesProp Accuracy =#CorrectDocNodes?#LabeledDocNodes#ReachedDocNodes?#LabeledDocNodeswhere #LabeledDocNodes is the number of ini-tially labeled document nodes which are documentsin the training set and #ReachedDocNodes is thenumber of document nodes labeled when the propa-gation process ends.Note that prop ratio and accuracy in table 5 arethe mean of the prop ratio and accuracy of the fivegroups of experiments.
It is clear that confidenceboosting model improves the prop accuracy overBFS-based model.
When only 1,000 documentsare initially labeled with timestamps, the confidenceboosting model can propagate their timestamps tomore than 400,000 documents with an accuracy of0.494, approximately 12.8% relative improvementover the BFS counterpart, which proves effective-ness of the confidence boosting model.However, as shown in table 5, hardly can the prop-agation process propagate timestamps to all doc-uments.
One reason is that the number of docu-ment nodes on the bipartite graph is only 550,124,approximately 61.1% of all documents.
The otherdocuments may not mention events which are alsomentioned by other documents, which means theyare isolate and thus are excluded from the bipartitegraph.
Also, the event coreference resolution phasedoes not guarantee finding all coreferential extrac-tions; in other words, recall of event coreference res-olution is not 100%.
The other reason is that somedocuments are unreachable from the initially labelednodes even if they are in the bipartite graph.The overall accuracy of different dating modelsis shown in table 6.
As with table 5, overall accu-racy in table 6 is the average performance of mod-els in the five groups of experiments.
As reportedby Nathanael Chambers (2012), the discriminativeclassifier performs much better than the temporallanguage models on the Gigaword dataset.
In thecase of 500,000 training examples, the Maxent clas-sifier using unigram features outperforms the tem-poral language models by 40.5% relative accuracy.If the size of the training set is large enough, named9entities and linguistic features as well as temporalconstraints will improve the overall accuracy sig-nificantly.
However, if the size of the training setis small, these features will not result in much im-provement.Compared with the previous models, the propaga-tion models predict the document timestamps muchmore accurately especially in the case where the sizeof the training set is small.
When the size of thetraining set is 1,000, our BFS-based model and con-fidence boosting model combined with the MaxEntclassifier outperform Chambers?s joint model whichis considered the state-of-the-art model for the taskof automatic dating of documents by 38.7% and46.8% relative accuracy respectively.
This is be-cause the feature-based methods are not very reli-able especially when the size of the training set issmall.
In contrast, our propagation models can pre-dict timestamps of documents with an understand-ing of document content, which allows our methodto date documents more credibly than the baselinemethods.
Also, by comparing table 5 with table 6,it can be found that prop accuracy is almost alwayshigher than overall accuracy, which also verifies thatthe propagation models are more credible for dat-ing document than the feature-based models.
More-over, data is so redundant that a great number ofdocuments can be connected with events they share.Therefore, even if a small number of documents arelabeled, the labeled information can be propagatedto large numbers of articles through the connectionsbetween documents and events according to relativetime relations.
Even if the size of the training setis large, e.g.
500,000, our propagation models stilloutperform the state-of-the-art dating method.
Ad-ditionally, some event nodes on the bipartite graphmay be labeled with a timestamp during the processof propagation as a byproduct.
The temporal infor-mation of the events would be useful for other tem-poral analysis tasks.5 Related WorkIn addition to work of de Jong et al(2005) andChambers (2012) introduced in previous sections,there is also other research focusing on the task ofdocument dating.
Kanhabua and Norvag (2009) im-proved temporal language models by incorporatingtemporal entropy and search statistics and apply-ing two filtering techniques to the unigrams in themodel.
Kumar et al(2011) is also based on thetemporal language models, but more historically-oriented, which models the timeline from the presentday back to the 18th century.
In addition, they usedKL-divergence instead of normalized log likelihoodratio to measure differences between a documentand a time period?s language model.However, these methods are based on tempo-ral language models so they also suffer from theproblem of the method of de Jong et al(2005).Therefore, they inevitably make wrong predictionsin some cases, just as mentioned in Section 1.
Com-pared with these methods, our event-based propaga-tion models exploit relative temporal relations be-tween documents and events for dating documenton a basis of an understanding of document content,which is more reasonable and also proved to be moreeffective by the experimental results.6 ConclusionThe main contribution of this paper is exploitingrelative temporal relations between events and doc-uments for the document dating task.
Differentwith the conventional work which dates documentswith feature-based methods, we proposed an event-based time label propagation model called confi-dence boosting in which timestamps are propagatedon a document-event bipartite graph according torelative temporal relations between documents andevents for dating documents on a basis of an under-standing of document content.
We discussed chal-lenges for the propagation models and gave the cor-responding solutions in detail.
The experimental re-sults show that our event-based propagation modelcan predict document timestamps in high accuracyand the model combined with a MaxEnt classifieroutperforms the state-of-the-art method on a data-redundant dataset.AcknowledgementsWe thank the anonymous reviewers for their valu-able suggestions.
This paper is supported byNSFC Project 61075067, NSFC Project 61273318and National Key Technology R&D Program (No:2011BAH10B04-03).10ReferencesKlaus Berberich, Srikanta Bedathur, Thomas Neumann,and Gerhard Weikum.
2007.
A time machine fortext search.
In Proceedings of the 30th annual in-ternational ACM SIGIR conference on Research anddevelopment in information retrieval, pages 519?526.ACM.Giang Binh Tran, Mohammad Alrifai, and DatQuoc Nguyen.
2013.
Predicting relevant news eventsfor timeline summaries.
In Proceedings of the 22ndinternational conference on World Wide Web compan-ion, pages 91?92.
International World Wide Web Con-ferences Steering Committee.Nathanael Chambers and Dan Jurafsky.
2008.
Jointlycombining implicit constraints improves temporal or-dering.
In Proceedings of the Conference on Empir-ical Methods in Natural Language Processing, pages698?706.
Association for Computational Linguistics.Nathanael Chambers.
2012.
Labeling documents withtimestamps: Learning from their time expressions.
InProceedings of the 50th Annual Meeting of the Asso-ciation for Computational Linguistics: Long Papers-Volume 1, pages 98?106.
Association for Computa-tional Linguistics.FMG de Jong, Henning Rode, and Djoerd Hiemstra.2005.
Temporal language models for the disclosureof historical text.
Royal Netherlands Academy of Artsand Sciences.Marie-Catherine De Marneffe, Bill MacCartney, Christo-pher D Manning, et al2006.
Generating typed de-pendency parses from phrase structure parses.
In Pro-ceedings of LREC, volume 6, pages 449?454.Anthony Fader, Stephen Soderland, and Oren Etzioni.2011.
Identifying relations for open information ex-traction.
In Proceedings of the Conference on Empiri-cal Methods in Natural Language Processing, pages1535?1545.
Association for Computational Linguis-tics.David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda.2003.
English gigaword.
Linguistic Data Consortium,Philadelphia.Po Hu, Minlie Huang, Peng Xu, Weichang Li, Adam KUsadi, and Xiaoyan Zhu.
2011.
Generatingbreakpoint-based timeline overview for news topic ret-rospection.
In Data Mining (ICDM), 2011 IEEE 11thInternational Conference on, pages 260?269.
IEEE.Pawel Jan Kalczynski and Amy Chou.
2005.
Temporaldocument retrieval model for business news archives.Information processing management, 41(3):635?650.Nattiya Kanhabua and Kjetil N?rva?g.
2009.
Us-ing temporal language models for document dating.In Machine Learning and Knowledge Discovery inDatabases, pages 738?741.
Springer.Abhimanu Kumar, Matthew Lease, and Jason Baldridge.2011.
Supervised language modeling for temporal res-olution of texts.
In Proceedings of the 20th ACM in-ternational conference on Information and knowledgemanagement, pages 2069?2072.
ACM.Katsumasa Yoshikawa, Sebastian Riedel, Masayuki Asa-hara, and Yuji Matsumoto.
2009.
Jointly identifyingtemporal relations with markov logic.
In Proceedingsof the Joint Conference of the 47th Annual Meeting ofthe ACL and the 4th International Joint Conference onNatural Language: Volume 1-Volume 1, pages 405?413.
Association for Computational Linguistics.11
