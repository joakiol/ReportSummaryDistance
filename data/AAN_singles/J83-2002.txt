Treating Coordination in Logic GrammarsVeronica Dahl 1Computing Sciences DepartmentSimon Fraser UniversityBurnaby, B.C.
V5A 1S6Michael  C. McCord 2Computer Science DepartmentUniversity of KentuckyLexington, KY 40506Logic grammars are grammars expressible in predicate logic.
Implemented in theprogramming language Prolog, logic grammar systems have proved to be a good basis fornatural language processing.
One of the most difficult constructions for natural languagegrammars to treat is coordination (construction with conjunctions like 'and').
This paperdescribes a logic grammar formalism, modifier structure grammars (MSGs), together with aninterpreter written in Prolog, which can handle coordination (and other natural languageconstructions) in a reasonable and general way.
The system produces both syntacticanalyses and logical forms, and problems of scoping for coordination and quantifiers aredealt with.
The MSG formalism seems of interest in its own right (perhaps even outsidenatural language processing) because the notions of syntactic structure and semanticinterpretation are more constrained than in many previous systems (made more implicit inthe formalism itself), so that less burden is put on the grammar writer.1.
IntroductionSince the development of the Prolog programminglanguage (Colmerauer 1973; Roussel 1975), logicprogramming (Kowalski 1974, 1979; Van Emden1975) has been applied in many different fields.
Innatural anguage processing, useful grammar formal-isms have been developed and incorporated in Prolog:metamorphosis grammars, due to Colmerauer (1978),and extraposition grammars, defined by F. Pereira(1981); definite clause grammars (Pereira and Warren1980) are a special case of metamorphosis grammars.The first sizable application of logic grammars was aSpanish/French-consultable data base system by Dahl(1977, 1981), which was later adapted to Portuguesel Visiting in the Computer Science Department,  University ofKentucky, during part of this research.
Work partially supported byCanadian NSERC Grant A2436 and Simon Fraser P.R.
Grant42406,2 Current address: IBM Thomas J. Watson Research Center,P.O.
Box 218, Yorktown Heights, NY 10598.by L. Pereira and H. Coelho and to English by F.Pereira and D. Warren.
Coelho (1979) developed aconsulting system in Portuguese for library service,and F. Pereira and D. Warren (1980) developed asizable English data base query system with facilitiesfor query optimization.
McCord (1982, 1981) pres-ented ideas for syntactic analysis and semantic inter-pretation in logic grammars, with application to Eng-lish grammar; some of these ideas are used in ourwork described here.Coordination (grammatical construction with theconjunctions 'and', 'or', 'but') has long been one ofthe most difficult natural anguage phenomena to han-dle, because it can involve such a wide range of gram-matical constituents (or non-constituent fragments),and ellipsis (or reduction) can occur in the items con-joined.
In most grammatical frameworks, the grammarwriter desiring to handle coordination can get by rea-sonably well by writing enough specific rules involvingparticular grammatical categories; but it appears that aproper and general treatment must recognize coordina-Copyright 1983 by the Association for Computational Linguistics.
Permission to copy without fee all or part of this material is grantedprovided that the copies are not made for direct commercial advantage and the Journal reference and this copyright notice are included onthe first page.
To copy otherwise, or to republish, requires a fee and/or  specific permission.0362-613X/83/020069-23 $0 .00American Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983 69Veronica Dahl and Michael C. McCord Treating Coordination in Logic Grammarstion as a "metagrammatical"  construction, in the sensethat metarules, general system operations, or "second-pass" operations such as transformations, are neededfor its formulation.Perhaps the most general and powerful metagram-matical device for handling coordination in computa-tional linguistics has been the SYSCONJ facility foraugmented transition networks (ATNs) (Woods 1973;Bates 1978).
The ATN interpreter with this facilitybuilt into it can take an ATN that does not itself men-tion conjunctions at all, and will parse reduced coordi-nate constructions, which are of the formA X and Y B,for example,John drove his car through andA Xcompletely demolished a plate glass window.Y Bwhere the unreduced eep structure corresponds toA X B and A Y B.The result of the parse is this unreduced structure.SYSCONJ accomplishes this by treating the conjunc-tion as an interruption which causes the parser to backup in its history of the parse.
Before backing up, thecurrent configuration ( immediately before the inter-ruption) is suspended for later merging.
The backingup is done to a point when the string X was beingparsed (this defines X), and with this configuration thestring Y is parsed.
The parsing of Y stops when aconfiguration is reached that can be merged with thesuspended configuration, whereupon B is parsed.
Thechoices made in this process can be deterministic ornon-deterministic, and can be guided by syntactic orsemantic heuristics.There are some problems with SYSCONJ, however.It suffers from inefficiency, due to the combinatorialexplosion from all the choices it makes.
Because ofthis inefficiency, it in fact has not been used to a greatextent in ATN parsing.
Another problem is that itdoes not handle embedded complex structures.
Fur-thermore, it is not clear to us that SYSCONJ offers agood basis for handling the scoping problems that arisefor semantic interpretation when conjunctions interactwith quantifiers (and other modifiers) in the sentence.This latter problem is discussed in detail below.In this paper we present a system for handling co-ordination in logic grammars.
The system consists ofthree things:(1) a new formalism for logic grammars, which wecall modifier structure grammars (MSGs),(2) an interpreter (or parser) for MSGs that takes allthe responsibility for the syntactic aspects of co-ordination (as with SYSCONJ), and(3) a semantic interpretation component hat prod-uces logical forms from the output of the parserand deals with scoping problems for coordination.The whole system is implemented in Prolog-10(Pereira, Pereira, and Warren 1978).Coordination has of course received some treat-ment in standard logic grammars by the writing ofspecific grammar ules.
The most extensive treatmentof this sort that we know of is in Pereira et al (1982),which also deals with ellipsis.
However,  we are awareof no general, metagrammatical treatment of coordina-tion in logic grammars previous to ours.Modifier structure grammars, described in detail inSection 2, are true logic grammars, in that they can betranslated (compiled) directly into Horn clause sys-tems, the program format for Prolog.
In fact, thetreatment of extraposit ion in MSGs is based on F.Pereira's (1981) extraposit ion grammars (XGs), andMSGs can be compiled into XGs (which in turn can becompiled into Horn clause systems).
A new elementin MSGs is that the formation of analysis structures ofsentences has been made largely implicit in the gram-mar formalism.
For previous logic grammar formal-isms, the formation of analyses is entirely the responsi-bility of the grammar writer.
Compiling MSGs intoXGs consists in making this formation of analysesexplicit.Although MSGs can be compiled into XGs, it seemsdifficult to do this in a way that treats coordinationautomatically (it appears to require more metalogicalfacilities than are currently available in Prolog sys-tems).
Therefore, we are using an interpreter for MSGs(written in Prolog).For MSGs, the analysis structure associated (by thesYstem) with a sentence is called the modifier structure(MS) of the sentence.
This structure can be consid-ered an annotated phrase structure tree, and in factthe name "modif ier structure grammar" is intended tobe parallel to "phrase structure grammar".
If extrapo-sition and coordination are neglected, there is acontext-free phrase structure grammar underlying anMSG; and the MS trees are indeed derivation trees forthis underlying grammar, but with extra informationattached to the nodes.In an MS tree, each node contains not only syntac-tic information but also a term called a semantic item(supplied in the grammar),  which determines thenode's contribution to the logical form of the sentence.This contribution is for the node alone, and does notrefer to the daughters of the node, as in the approachof Gazdar (1981).
Through their semantic items, thedaughters of a node act as modifiers of the node, in afairly traditional sense made precise below - hence theterm "modif ier structure".The notion of modifier structure used here and thesemantic interpretation component,  which depends onit, are much the same as in previous work by McCord70 American Journal of Computational Linguistics, Volume 9, Number 2, April- June 1983Veronica Dahl and Michael C. McCord Treating Coordination in Logic Grammars(1982, 1981), especially the latter paper.
But newelements are the notion of MSG (making modifierstructure implicit in the grammar), the MSG interpret-er, with its treatment of coordination, and the specificrules for semantic interpretation of coordination.The MSG interpreter is described in Section 3.
Asindicated above, the interpreter completely handles thesyntax of coordination.
The MSG grammar itselfshould not mention conjunctions at all.
The interpret-er has a general facility for treating certain words asdemons (cf.
Winograd 1972), and conjunctions arehandled in this way.
When a conjunction demon ap-pears in a sentenceA X conj Y B,a process is set off which in outline is like SYSCONJ,in that backing up is done in the parse history in orderto parse Y parallel to X, and B is parsed by mergerwith the state interrupted by the conjunction.
Howev-er, our system has the following interesting features:(1) The MSG interpreter manipulates tacks insuch a way that embedded coordination (and coordi-nation of more than two elements) and interactionswith extraposition are handled.
(Examples are givenin the Appendix.
)(2) The interpreter produces a modifier structurefor the sentenceA X conj Y Bwhich remains close to the surface form, as opposed tothe unreduced structureA X B conj A Y B(but it does show all the pertinent semantic relationsthrough unification of variables).
Not expanding tothe unreduced form is important for keeping the modi-fier relationships traight, in particular, getting theright quantifier scoping.
Our system analyzes the sen-tenceEach man drove a car through andcompletely demolished a glass window,producing the logical formeach(X,man(X),exists(Y,car(Y),exists(Z,glass(Z)&window(Z),drove_through(X,Y,Z)&completely(demolished(X,Z)) )))This logical form would be difficult to recover fromthe unreduced structure, because the quantified nounphrases are repeated in the unreduced structure, andthe logical form that corresponds most naturally to theunreduced structure is not logically equivalent o theabove logical form.
(3) In general, the use of modifier structures andthe associated semantic interpretation component per-mits a good treatment of scoping problems involvingcoordination.
Examples are given below.
(4) The system seems reasonably efficient.
Forexample, the analysis of the example sentence under(2) above (including syntactic analysis and semanticinterpretation) was done in 177 milliseconds.
Thereader can examine analysis times for other examplesin the Appendix.
One reason for the efficiency is justthat the system is formulated as a logic programmingsystem, and especially that it uses Prolog-10, with itscompiler.
Another reason presumably lies in the de-tails of the MSG interpreter.
For example, the inter-preter does not save the complete history of the parse,so that the backing up necessary for coordination doesnot examine as much.
(5) The code for the system seems short, andmost of it is listed in this paper.The semantic interpretation component is describedin Section 4, but not in complete detail since it is tak-en in the main from McCord (1982, 1981).
Emphasisis on the new aspects involving semantic interpretationof coordinate modifiers.Semantic interpretation of a modifier structure treeis done in two stages.
The first stage, called reshaping,deals heuristically with the well-known scoping prob-lem, which arises because of the discrepancies that canexist between (surface) syntactic relations and intend-ed semantic relations.
Reshaping is a transformationof the syntactic MS tree into another MS tree with the(hopefully) correct modifier relations.
The secondstage takes the reshaped tree and translates it intological form.
The modifiers actually do their work ofmodification in this second stage, through their seman-tic items.As an example of the effects of reshaping on coor-dinate structures involving quantifiers, the sentenceEach man and each woman ate an appleis given the logical formeach(X,man(X),exists(Y,apple(Y),ate(X,Y)))& each(X,woman(X),exists(Y,apple(Y),ate(X,Y))),whereas the sentenceA man and a woman sat at each tableis given the formeach(Y,table(Y), exists(X,man(X),sat_at(X,Y))& exists(X,woman(X),sat_at (X,Y))).Section 5 of the paper presents a short discussionof possible improvements for the system, and Section6 consists of concluding remarks.
The Appendix tothe paper contains a listing of most of the system, asample MSG, and sample parses.
The reader may wishto examine the sample parses at this point.American Journal of Computational Linguistics, Volume 9, Number 2, Apri l- June 1983 71Veronica Dahl and Mlichael C. IVlcCord Treating Coordination in Logic Grammars2.
Modif ier  Structure GrammarsThe most fundamental  type of logic grammar isColmerauer 's  (1978) metamorphosis grammar (MG).Grammars of this type can be viewed as generalizedtype-0 phrase structure grammars in which the gram-mar symbols (terminals and non-terminals) are termsfrom predicate logic.
In derivations, the rewriting ofsymbol strings involves unification (Robinson 1965),instead of simple replacement.F.
Pereira's (1981) extraposition grammars (XGs)are essentially generalizations of MGs designed tohandle (left) extraposition.
In the left-hand side of anXG rule, grammar symbols can be connected by theinfix operator '...', indicating a gap.
When such a ruleis used in rewriting, the gaps appearing in the left-hand side may match arbitrary strings of grammarsymbols, and then the left-hand side is replaced by theright-hand side followed by the symbol stringsmatched by the gaps (in the same order).
For exam-ple, the XG rulea,b...c...d - -> e,fis really a rule schemaa ,b ,X ,c ,Y ,d - -> e,f,X,Ywhere X and Y stand for arbitrary grammar symbolstrings.
There is a constraint on the use of gaps inrewriting called the bracketing constraint, for which werefer to F. Pereira (1981).
However, our MSG inter-preter includes XG interpretation, so the use of gaps isin fact completely specified below.In XG rules, symbols on the left-hand side follow-ing gaps represent left-extraposed elements.
For ex-ample, the extraposition of noun phrases to the frontof relative clauses (with replacement by relative pro-nouns) can be handled by the XG rules:relative clause - -> rel marker, sentence.rel_marker...trace -- > rel_pronoun.nounphrase  - -> trace.where 'trace' marks the position out of which the nounphrase is being moved, and is used by the second ruleabove in conjunction with a relative marker to produce(or analyze) a relative pronoun.Pereira's implementation of XGs is a Prolog pro-gram that compiles XGs to Horn clause systems, whichin turn can be run by Prolog for parsing sentences.
Inthe compiled systems, extraposition is handled by themanipulation of a stack called the extraposition list,which is similar to the HOLD list for ATN's (Woods1973).
Elements (like 'trace' above) on the left-handsides of XG rules following the initial symbol are ineffect put on the extraposition list during parsing, andcan be taken off when they are required later by theright-hand side of another rule.
Our MSG interpreteruses a reformulation of this same method.Since the grammar symbols in XGs (and MGs) canbe arbitrary terms from predicate logic, they can con-tain arguments.
These arguments can be used to holduseful information such as selectional restrictions andanalysis structures.
For example, in the rulesentence (s(Subj,Pred)) -- >noun_phrase(Subj) ,verb_phrase(Pred)each non-terminal is augmented with an argumentrepresenting a syntactic structure.
(Here, followingProlog-10 syntax, the capitalized items are variables.
)Manipulating such arguments is the only way of get-ting analysis structures in XGs.
As indicated in theIntroduction, a new ingredient in MSGs over XGs is toautomate this process, or to make it implicit in thegrammar.MSG rules are of two forms.
The basic form isA :Sem- -> B.where A - ->B is an XG rule and Sem is a term called asemantic item, which plays a role in the semantic inter-pretation of a phrase analyzed by application of therule.
The semantic item is (as in McCord 1981) ofthe formOperator -Logica lFormwhere, roughly, LogicalForm is the part of the logicalform of the sentence contributed by the rule, and Op-erator determines the way this partial structure com-bines with others.
Details on semantic items are post-poned to Section 4 (on semantic interpretation).
Ac-tually, the current section and Section 3 deal mainlywith syntactic constructions which are independent ofthe form of semantic items.The second type of MSG rule looks exactly like anXG rule (no Sem is exhibited), but the system takescare of inserting a special "tr ivial" Sem, g-true.
(Herethe '8' is the operator for left-conjoining, described inSection 4.)
Most MSG rules for higher (non-lexical)types of phrases are of this type, but not all of themare.A simple example of an MSG is shown in Figure 1.Following the notational conventions of XGs (as wellas the simpler definite clause grammars built intoProlog-10), we indicate terminal symbols by enclosingthem in brackets \[ \].
Rules can contain tests on theirright-hand sides, enclosed in braces {}, which are Pro-log goals.
In this example, the tests are calls to thelexicon, shown after the grammar ules, which consistsof assertions (non-conditional Horn clauses).This grammar, together with the semantic interpre-tation component, will handle sentences like the fol-lowing, producing the indicated logical forms:72 American Journal of Computational Linguistics, Volume 9, Number 2, Apri l - June 1983Veronica Dahl and Mlichael C. IVlcCord Treating Coordination in Logic Grammarssent - -> nounph(X),verbph(X).nounph(X) --> det(X),noun(X).nounph(X) --> proper_noun(X).verbph(X) --> verb(X,Y),nounph(Y).det (X) :Sem- -> \[D\],{d(D,X,Sem)}.noun(X) :g -Pred- -> \[N\],{n(N,X,Pred)}.proper_noun(N) -->verb (X,Y): g-Pred -- >/*  Lexical entries */\[N\],{npr(N)}.\[V\],{v(V,X,Y,Pred) }.n(man,X,man(X)), n(woman,X,woman(X)).npr(john), npr(mary).v(saw,X,Y,saw(X,Y)), v(heard,X,Y,heard(X,Y)).d(each,X,P/Q-each(X,Q,P)) .d(a,X,P/Q-exists(X,Q,P)).Figure 1.
A simple MSG with lexicon.John saw Mary.saw(john,mary).John heard each woman.each(Y,woman(Y),heard(john,Y)).Each man saw a woman.each(X,man(X),exists(Y,woman(Y),saw(X,Y))).A larger example MSG is listed in the Appendix.This grammar includes rules dealing with extraposition,and the lexicon contains rules used by the MSG inter-preter in handling coordination.Now let us look at the formation of syntactic struc-tures by the MSG system.
As stated in the Introduc-tion, syntactic structures are trees called modifierstructure (MS) trees.Suppose that a phrase is analyzed by application ofan MSG ruleA:Sem --> B.and further rule applications in an MSG.
(The Semmay be explicit or supplied by the system for the sec-ond type of rule.)
Then the modifier structure of thephrase is a term of the formsyn(NT,Sem,Mods)where NT is the leading symbol (a non-terminal) in Aand where Mods is the list of modifier structures ofthe subphrascs analyzed with the right-hand side B ofthe rule.
The 'syn' structure is considered a tree node,labeled with the two items NT and Sem, and havingdaughter list Mods.As an example, the MS tree for the sentence "Eachman saw a woman" produced by the grammar in Fig-ure 1 is shown in Figure 2.
This tree is printed bydisplaying the first two fields of a 'syn' on one lineand then recursively displaying the daughters, indenteda fixed amount.sent g-truenounph(X) g-truedet(X) P/Q-each(X,Q,P)noun(X) g-man(X)verbph(X) g-trueverb(X,Y) g-saw(X,Y)nounph(Y) g-truedet(Y) R/S-exists(Y,S,R)noun(Y) g-woman(Y)Figure 2.
MS tree for "Each  man saw a woman."
.Let us now indicate briefly how MSGs can be com-piled into XGs so that these MS trees are produced asanalyses.
This method of compiling does not handlecoordination metagrammatically (as does the interpret-er), but it does seem to be of general interest forMSGs.In the compiled XG version of an MSG, each non-terminal is given two additional arguments, added, say,at the end.
Each argument holds a list of modifiers.If the original non-terminal is nt(X1 .... ,Xn), the newnon-terminal will look likent(X1 .... ,Xn,Modsl,Mods2).When this non-terminal is expanded by a non-trivialrule, then Modsl  will differ from Mods2 by havingone additional modifier on the front, namely the modi-fier contributed by the rule application.
A rule istrivial if its right-hand side is empty.
When a trivialrule is used to expand 'nt' above, Modsl  will equalMods2.As an example of rule translation, the first rule inFigure l is translated tosent(\[syn(sent,g-true,Modsl) I Mods\],Mods) -->nounph(X,Mods 1,Mods2),verbph(X,Mods2,\[ \]).
(Here \[X \] Y\] denotes the list with first member X andremainder Y.
)Any non-terminal on the left-hand side of an MSGbesides the leading non-terminal is given a pair ofidentical Mods arguments (because it contributes nomodifier by itself).
For example, the MSG rulerel mk(X).. .trace(X) --> rel_pron.would translate torel_mk(X,\[syn(rel mk(X),g-true,Mods 1 ) I Mods\],Mods)...trace(X,Mods2,Mods2) --> rel_pron(Modsl, \[  ]).American Journal of Computational Linguistics, Volume 9, Number 2, April- June 1983 73Veronica Dahl and Michael C. McCord Treating Coordination in Logic GrammarsFor parsing a sentence with respect o the grammarin Figure 1, one would usesent(\[MST\],\[ \])as start symbol (with MST unknown) and the parsewould bind MST to the modifier structure tree of thesentence.Pairs of list arguments manipulated in the way justoutlined are called "di f ference lists", and the tech-nique is common in logic programming.
One part ofcompiling MGs to Horn clauses is the addition to eachnon-terminal of an argument pair for the terminalstrings being analyzed.
Pereira's compilation of XGsto Horn clauses involves one more argument pair forextraposit ion lists.
So the compilation of MSGs toHorn clauses involves three argument pairs totally.
Inthe MSG interpreter, described in the next section,only a single argument (not a pair) is needed for eachof these three lists.3.
The MSG Interpreter  and the Syntax ofCoord inat ionOur MSG processor actually has a bit of compiler in it,because there is a preprocessor that translates MSGrules into a form more convenient for the interpreterto use.An MSG ruleA:Sem - -> Bis preprocessed into a termrule (NT,Ext,Sem,B 1)where NT is the leading non-terminal in A, Ext is theconversion of the remainder of A into an extrapositionlist, and B1 is the conversion of B to list form.The notion and representation of extraposition listsused here are just the same as F. Pereira's (1981).
Anode in such a list is of the formx(Context,Type,Symbol,Ext)where Context is either 'gap' or 'nogap',  Type is either'terminal'  or 'nonterminal' ,  Symbol is a grammar sym-bol, and Ext is the remainder of the list.
We denotethe empty extraposition list by 'nil' (Pereira used \[ \]).The " left-hand side remainder" in a grammar ule(the part after the leading symbol) is converted to anextraposit ion list in a straightforward way, with onenode for each symbol in the remainder.
The Contextsays whether the symbol has a gap preceding it, andthe remaining fields of an 'x' node have the obviousmeaning.
For the rulea , \ [b \ ] .
.
.c - -> dthe extraposition list would bex(nogap,terminal,b,x(gap,nonterminal,c,nil)).The right-hand side of an MSG rule is preprocessedto a (simple) list form in the obvious way.
Thus, aright-hand side (d,e,f) is converted to the list \[d,e,f\],and a right-hand side with a single element d is con-verted to the list \[d\].As a complete example, the MSG rulea .
.
.b :e -p - -> \[c\],{d},eis converted torule (a,x(gap,nonterminal,b,nil),e-p,\[\[c\],{d} ,el).If the MSG rule exhibits no semantic item, then thepreprocessor supplies the trivial item e-true.The 'rule' forms of the rules in an MSG are storedas assertions in the Prolog data base, to be used by theinterpreter.
One can understandrule (NT,Ext,Sem,B 1)as the assertion: "There is a rule for the non-terminalNT with extraposition list Ext, etc.
"The rule preprocessor is listed at the beginning ofthe Appendix.Now let us look at the interpreter itself, which islisted after the preprocessor in the Appendix.The top-level procedure isparse (String,NonTerminal,Syn)which takes a String of terminals and attempts to parseit as a phrase of type NonTerminal,  with the syntacticstructure Syn.
We should comment that 'parse'  de-fines a top-down parser.This procedure calls the main working procedureprs (BodyList,String,Mods,Par,Mer,Ext)which parses String against a list BodyList of goals ofthe type that can appear in the right-hand side (thebody) of a rule.
The list of resulting syntactic struc-tures is Mods (one modifier for each non-trivial ex-pansion of a non-terminal in BodyList).
The remain-ing three arguments of 'prs'  are for stacks called theparent stack, the merge stack, and the extraposit ionlist.
These are initialized to 'nil' in the call of 'parse'to 'prs'.The parent stack serves two purposes.
One is tocontrol the recursion in the normal working of theparser.
(The parser is much like an interpreter for aprogramming language - in fact, for a specialized ver-sion of Prolog itself.)
The other purpose is to provideinformation for the coordination demon, when it backsup in (part of) the parse history.A non-empty parent stack is a term of the formparent (BodyList,Mods,Par)where BodyList is a body list, Mods is a modifier list,and Par is again a parent stack.
A new level getspushed onto the parent stack by the sixth rule for 'prs'and the ancillary procedure 'prspush'.
This happens74 American Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983Veronica Dahl and Michael C. McCord Treating Coordination in Logic Grammarswhen 'prs' is looking at a body list of the form\ [NT IBL \ ] ,  where the initial element NT is a non-terminal that can be expanded by a 'rule' entry.
Ifthat rule is trivial (if its own body is empty), then noactual push is done, and 'prs' continues with the re-maining current body list BL.
Otherwise, 'prspush'goes to a lower level, to parse against the body of theexpanding rule.
The items \ [NT IBL \ ]  and Mods fromthe higher level are saved on the parent stack (Mods isa variable for the remaining modifiers to be found onthe higher level).Note that the body list \ [NT IBL\ ]  saved in the firstfield of the 'parent' term is more than is needed formanaging the recursive return to the higher level.Only the remainder, BL, is needed for this, becauseNT has already been used in the parse.
In fact, therule that pops to the higher level (the eighth rule for'prs') does ignore NT in doing the pop.
The extrainformation, NT, is saved for the second purpose ofthe parent stack, the backing up by the coordinationdemon.Before going into the details of coordination,though, let us continue with the description of the"normal" working of the parser.In normal parsing, there is exactly one place wherea new 'syn' node is added to the MS trees being built.This is in the second rule for 'prspush', which handlesnon-trivial rule expansions.
The addition of this nodeis in accordance with the definition of modifier struc-ture given in the preceding section.The pushing rule of 'prs' (the sixth rule) also ma-nipulates the extraposition stack.
The extrapositioncomponent of the expanding rule is concatenated ontothe front of the main extraposition list (being carriedin the last argument of 'prs').
This is analogous to aHOLD operation in ATNs.
Of course, if no extraposi-tion is shown in the rule, the extraposition list willremain the same.The third and fourth rules for 'prs' handle terminalsin the body list.
The first of these tries to remove theterminal from the string argument, and the secondtries to remove it from the extraposition list (as in aVIR arc for ATNs).The seventh 'prs' rule tries to remove a non-terminal from the extraposition list (again, like a VIRarc).The last 'prs' rule is the termination condition forthe parse.
It just requires that all arguments be null.Now we can discuss coordination demons.
All therest of the interpreter rules deal with these.The first 'prs' rule is the one that notices demonwords D. It calls a procedure 'demon', passing D asthe first argument and all the rest of the information ithas in other arguments.
'demon' takes control of therest of the parse.
In the listed interpreter there is onlyone 'demon' rule, one that tests whether D is a con-junction.
It does this with the goalconjunction(D,Cat,Sem),which gives the syntactic category Cat for the con-junction D, and the semantic item Sem for a new mod-ifier node to be constructed for the right conjunct.The lexicon contains 'conjunction' entries as asser-tions.For understanding what the conjunction demondoes, it is best to look at an example, as it would beparsed for the grammar in the Appendix.
We will usethe specific notation (for variables, etc.)
given in thedemon rule, and the reader should refer to that rule inthe Appendix.
It should be borne in mind that Prologis non-deterministic; we will only state what happenson the successful path through the choices made.The example isJohn saw and Mary heard the train.When the demon for 'and' is called, the current bodylist isBL= \[comps(\[obj-Y\])\[.The non-terminal comps(Comps) looks for a listComps of complements, and in this case there is to beone complement, an object noun phrase.
The MS treeconstructed so far issent e-truenounph(X,def) @P-def(X,X=john,P)verbph(X) C-trueverb(X,\[obj-Y\]) g-saw(X,Y)I ModsI Mods2Here the entry \[ Mods in the last daughter position forthe verb phrase indicates further modifiers on thatlevel to be put in the unbound variable Mods.
(This isexplicitly the same variable 'Mods' used in the demonrule.)
Similarly, I Mods2 represents the remainingmodifiers for 'sent' node.
The variable Mods2 doesnot appear in the 'demon' rule, but will be referred tobelow.The parent stack Par available to the demon hastwo levels, and the two body lists are\[verbph(X)\],\[sent\].
(Recall that we are describing the state of affairs inthe successful path through the search space.)
Therecursive procedure 'backup' is called, which can lookany number of levels through the parent stack.
It goesto the second level, where the body list is \[sent\].
(Choosing the first level with \[verbph(X)\] would beappropriate for the sentence " John saw and barelyheard the train".)
In passing up a level, 'backup' re-quires that the body list skipped over must be'satisfied', which means that any pending goals in thebody list (members of its tail) are satisfiable by trivialAmerican Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983 75Veronica Dahl and Michael C. McCord Treating Coordination in Logic Grammarsrules.
When 'backup' does pass up a level, the modifi-er list for that level is closed off.
Thus Mods in thetree displayed above will be bound to the empty list.
(There are no more modifiers for that 'verbph' node.
)As a single remaining daughter for the level backedup to, a new 'syn' node for the right conjunct is at-tached by the demon.
This means binding the variableMods2 in the above tree to the list consisting of thisnode.
Now our tree looks likesent g-truenounph(X,def) @P-def(X,X=john,P)verbph(X) g-trueverb(X,\[obj-Y\]) g-saw(X,Y)conj(and) Q*R-(Q&R)I Mods0The variable Mods0 is to contain the list of modifiersfor the conjunction node.
This list will turn out tohave a single element, a new 'sent' node for the re-mainder of the sentence, "Mary heard the train".Backing up to the \[sent\] level makes the non-terminal NT=sent  available to the demon, and theparent stack Parl  at the \[sent\] level.
The demon thencontinues the parse by calling 'prs' with body list\[NT\]=\[sent\] ,  but with information pushed onto themerge stack.
The main item stored on the merge stackis the body list BL=\[comps(\[obj-Y\]) \ ] ,  which waspending at the time of interruption by the conjunction.The items Par l ,  Ext, and of course the old mergestack Mer are also pushed on.So now we continue parsing "Mary heard thetrain", but with another kind of demon lurking, theinterrupted goal BL.
The second rule for 'prs' noticesthis demon.
When we are parsing and come to a goalthat can be unified with BL, then we can try merging.This happens when we are looking for the comple-ments of "heard".
This unification includes the unifi-cation of the object variable Y of "saw" with the ob-ject variable of "heard",  so that "the train" will logi-cally be the object of "saw" as well as "heard".The procedure 'cutoff'  called by the second 'prs'rule requires that no new unsatisfied goals have devel-oped in parsing the right conjunct (aside from the goalBL to be merged) and also closes off modifier lists inthe local parent stack Par for the right conjunct.Then the merged parse is continued by a call to'prs', with BL as goal and with the parent stack, mergestack, and extraposition list popped from the mergestack.
When this is completed, our MS tree is asshown in Figure 3.The meanings of the semantic items used in this MStree, and their use in producing the logical form, willbe explained in the next section; but it is worth statingnow what the resulting logical form is:def (Y,train(Y),saw(john,Y) &heard(mary,Y)).The reader may examine the analyses produced forother examples listed in the Appendix.sent g-truenounph(X,def) @P-def(X,X=john,P)verbph(X) g-trueverb(X,\[obj-Y\]) g-saw(X,Y)conj(and) Q*R-(Q&R)sent g-truenounph(Z,def) @S-def(Z,Z=mary,S)verbph(Z) g-truecomps(\[obj-Y\]) g-truecomp(obj-Y) g-truenounph(Y,def) g-truedet(Y,def) T /U-def(Y ,U,T)noun(Y,\[ \]) g-train(Y)Figure 3.
MS tree for"John saw and Mary heard the train."4.
Semant ic  In terpretat ion  and Coord inat ionThe overall idea of the semantic interpretationcomponent was given in the Introduction.
The rulesystem is listed completely in the Appendix.
Thissystem is taken essentially from McCord (1981), withsome rules deleted (rules dealing with focus), andsome rules added for coordination.For a discussion of MS tree reshaping as a means ofhandling scoping of modifiers, we refer to McCord(1982, 1981).
Also, the reader may examine the ex-amples of reshaped trees given in the Appendix.We will, however, review the second stage of se-mantic interpretation, because the new rules for coor-dination are added here and because it is more centralfor understanding modifier structure.
In this stage, thereshaped MS tree is translated to logical form, and thetop-level procedure for this is 'translate'.
This proce-dure actually works only with the semantic-item com-ponents of MS tree nodes.
(Reshaping uses the first,syntactic omponents.
)One semantic item can combine with (or modify) asecond semantic item to produce a third semantic item.
'translate' uses these combining operations in astraightforward recursive fashion to produce the logi-cal form of an MS tree.
The ancillary procedure('transmod') that actually does the recursion producescomplete semantic items as translations, not just logi-cal forms.
For the top-level result, the operator com-ponent is thrown away.
'transmod' works simply asfollows: The daughters (modifiers) of a tree node Nare translated recursively (to semantic items) andthese items cumulatively modify the semantic item ofN, the leftmost acting as the outermost modifier, etc.So the heart of the translation process is in therules that say how semantic items can combine with76 American Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983Veronica Dahl and Michael C. McCord Treating Coordination in Logic Grammarsother semantic items.
These are rules for the proce-duretrans(Sem0,Seml,Sem2)which says that Sere0 combines with (modifies) Semlto produce Sem2.
In the typical case, this combinationdepends only on the Operator component of Sem0;but there are exceptional cases where it depends aswell on the operator in Seml.
Furthermore, 'trans' isfree to create a new operator for the result, Sem2,which can affect later operations.
This happens withcoordinate modifiers.
We often speak of Sem0"operating on" Seml, but "combining with" is themore accurate term generally.The only operators appearing in the small samplegrammar in the Appendix are of the form g, @P, P/Q,and P*Q.
Here P and Q are variables standing forlogical forms.
The listing for 'trans' in the Appendixincludes only rules for these operators and their auxili-aries, although larger grammars involve other opera-tors.
We will elucidate the effects of these four opera-tors with examples.
The last one, P'Q, is used forcoordination.The operator 'g' is for left-conjoining.
Wheng-man(X) operates on g-see(X,Y), the result isg-man(X)&see(X,Y).The operator @P is used for substitutions in itsassociated logical form.
When @P-not(P) operates ong-laugh(X), the result is g-not(laugh(X)).The operator P/Q is used for forms that requiretwo substitutions.
WhenP/Q-each(X,Q,P)operates on g-man(X), the result is@P-each(X,man(X),P),which in turn can operate by substituting for P.Notice that @p and P /Q are similar to lambda(P)and lambda(Q)lambda(P) respectively.
But they alsointeract with other operators in the system in specificways.To show these first three operators working togeth-er, let us look at the MS tree that would be producedfor the sentence "Each man laughed".
(Reshapingleaves this tree unaltered.)
We throw away the syn-tactic fields in the tree nodes (working only with thesemantic items), and show the successive stages inproducing the logical form in Figure 4.
In followingthe steps in Figure 4, the reader should refer to the'trans' rules in the Appendix, which are numbered forreference here.
In each step of the translation, a nodecombines with its parent, and the 'trans' rule used todo this is indicated.The operator P*Q appears in coordinate modifiers.The first four 'trans' rules deal with it, and they createauxiliary operators.
The following example will makeclear how these are manipulated.
The sentence is(1) g-trueg-trueP/Q-each(X,Q,P)g-man(X)g-trueg-laughed(X) (Rule 7 applies)(2) g-trueg-trueP/Q-each(X,Q,P)g-man(X)g-laughed(X) (Rule 7)(3) g-laughed(X)g-trueP/Q-each(X,Q,P)g-man(X) (Rule 7)(4) g-laughed(X)g-man(X)P/Q-each(X,Q,P) Rule 5)(5) g-laughed(X)@P-each(X,man(X),P) (Rule 6)(6) g-each(X,man(X),laughed(X)).Figure 4.
The working of 'translate'.
"Each man ate an apple and a pear.
"This example is shown in the Appendix, with the ini-tial syntactic analysis and the reshaped tree.
In thereshaped tree, the 'sent' node has three daughters, thefirst being for the simple noun phrase "each man", thesecond for the conjoined noun phrase "an apple and apear", and the third for the verb phrase with the ob-ject removed.If we perform all the modifications that are possiblein this tree without involving the coordination opera-tor, and if we remove the syntactic fields, then the treelooks like the following:g-ate(X,Y)@P-each(X,man(X),P)g-trueQ/R-exists(Y,R,Q)g-apple(Y)S*T-(S&T)@U-exists(Y,pear(Y),U)Now the first 'trans' rule can apply to the lowest pairof nodes, and the tree becomes:g-ate(X,Y)@P-eaeh(X,man(X),P)g-trueQ/R-exists(Y,R,Q)g-apple(Y)cbase 1 (@U-exists(Y,pear(Y),U),S,T)-(S&T)American Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983 77Veronica Dahl and Michael C. McCord Treating Coordination in Logic GrammarsWe have saved the modifier for "a pear" in the firstargument of the 'cbasel '  operator.
Next, this itemoperates on the g-true node, by application of thesecond 'trans' rule, and we get the treeg-ate(X,Y)@P-each(X,man(X),P)cbase2(g,@U-exists(Y,pear(Y),U),S,T,S&T)-trueQ/R-exists(Y,R,Q)g-apple(Y)Now, the third 'trans' rule is applied twice, to the twodaughters of the 'cbase2' node, and we getg-ate(X,Y)@P-each(X,man(X),P)cbase2(@Q,@U-exists(Y,pear(Y),U),S,T,S&T)-exists(Y,apple(Y),Q)Then, as the last step with coordination operators, thefourth 'trans' rule is applied to let the 'cbase2' nodeoperate on the top node of the tree.
This involves tworecursive calls to 'trans', in which the two conjunctnoun phrases operate on the material in the scope ofthe coordinate node.
(In this case, the material in thescope is ate(X,Y).)
This material gets duplicated, be-cause of the double application to it.
The resultingtree now isg-exists(Y,apple(Y),ate(X,Y))&exists(Y,pear(Y),ate(X,Y))@P-each(X,man(X),P)Finally, the @P node modifies the top node, and afterdiscarding the operator (an 'g') in the resulting item,we get the logical formeach(X,man(X),exists(Y,apple(Y),ate(X,Y))&exists(Y),pear(Y),ate(X,Y)) )Near the end of the Introduction, examples weregiven of two syntactically similar sentences with coor-dination, for which the produced logical forms arequite different.
For the sentence"Each man and each woman ate an apple",the reshaping stage produces a tree that in outlinelooks like the following:sentnounph "each man"conj(and)nounph "each woman"nounph "an apple"verbph "ate"Then, the material for "ate an apple" will be in thescope of the conjoined noun phrase and this materialgets duplicated, with the resulting logical form beingeach(X,man(X),exists(Y,apple(Y),ate(X,Y)))&each(X,woman(X),exists(Y,apple(Y),ate(X,Y))).On the other hand, for the sentence"A man and a woman sat at each table",reshaping moves the universally quantified nounphrase to the left of the existentially quantified con-joined noun phrase, and the tree is as follows:sentnounph "each table"nounph "a man"conj(and)nounph "a woman"verbph "sat at"Then the only material in the scope of the conjoinednoun phrase is for "sat at", and only this gets dupli-cated.
(In fact, the scoping is like that for our earlierexample, "Each man ate an apple and a pear".)
Thecomplete logical form iseach(Y,table(Y), exists(X,man(X),sat at(X,Y))& exists(X,woman(X),sat_at(X,Y)) ).Notice that the logical forms for conjoined phrasesin the above analyses share variables.
For instance,the same variable X is used in both man(X) andwoman(X) in the last analysis.
This sharing of varia-bles arises naturally because of the unification of bodylists that is performed during parsing by the 'merge'demon.
It keeps things straight very nicely, becausethe shared variables may appear in another predica-tion, like sat_at(X,Y) above, which occurs only once,outside the conjoined phrase, but is related logically toboth conjuncts.This sharing of variables presents no problems aslong as the variables are quantified over (as they areby the existential in the preceding example).
But itmakes proper nouns less convenient to treat.
If coor-dination were not being considered, it would be con-venient to parse proper nouns by the sort of rule listedin Figure 1 in Section 2, where the proper noun getsimmediately unified with the variable X appearing innounph(X).
But if such a rule is used with the MSGparser, then a sentence as simple as " John and Marylaughed" will not parse, because the parser attempts tounify the logical subject variable with both ' john' and'mary'.Therefore, as the semantic item for a proper nounN, we use a quantified form, specifically@P-def(X,X=N,P) ,and this is carried through in most of the processing.However, the procedure 'translate', after it has carriedout all the modification, calls a procedure 'simplify'which simplifies the logical form.
This gets rid ofsome unnecessary 'true's and it carries out the substi-tutions implicit in the proper noun forms, by doingsome copying of structures and renaming of variables.78 American Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983Veronica Dahl and Michael C. McCord Treating Coordination in Logic GrammarsFor example, the logical form for " John and Marylaughed" prior to simplification is essentiallydef (X,X= john,laughed(X))&def(X,X=mary, laughed(X)) .But after simplification, it islaughed(john)&laughed(mary).In the sample analyses in the Appendix, we give insome cases only the logical form and in other cases theintermediate structures also (the syntactic analysis treeand the reshaped tree).
Analysis times are in milli-seconds.
These do not include times for I /O and con-version of character strings to word lists.
Variablesare printed by Prolog-10 in the form n ,  where n is aninteger.5.
Possible Extens ionsThe main advantages of the formalism presentedhere are:?
automating the treatment of coordination,?
freeing the user of concern with structure-building,and?
providing a modular treatment of semantics, basedupon information given locally in each rule.While making a reasonable compromise betweenpower and elegance on the one hand, and efficiencyon the other, our present implementation could beimproved in several ways.
For instance, because theparsing history is kept in a stack that is regularly pop-ped - the Parent stack - some parsing states are nolonger available for backing up to, so the possibilityexists for some acceptable sentences not to be recog-nized.We have experimented with modifications of theMSG interpreter in which more of the parse history issaved, and have also considered compiling MSGs intoProlog and using a general 'state' predicate which re-turns the proof history, but we have not as yet ob-tained satisfactory results along these lines.Another possible improvement is to use some se-mantic guidance for the (at present blind) backing upthrough parsing states.
The parser already carriesalong semantic information (in semantic items) to beused later on.
Some of this information could perhapsalso be used during parsing, in order to improve thebackup.
Research along these lines may well providesome more insight into the dilemma of whether syntaxand semantics hould be kept separate or intermingled.It would also be interesting to include collectiveand respective readings of coordinated noun phrases,perhaps along the lines proposed in Dahl (1981).We do not presume that our general treatment ofcoordination will work for all possible MSG grammars.Care is necessary in writing an MSG, as with any otherformalism.
What we do provide are enough elementsto arrive at a grammar definition that can treat moststructure-building and coordination problems in amodular and largely automated manner.We have also investigated an alternative approachto coordination, which is not metagrammatical but isnevertheless more flexible than previous approaches,and involves still another grammar formalism we be-lieve worth studying in itself.
We have named it thegapping grammar (GG) formalism, as its main featureis that it allows a grammar ule to rearrange gaps in afairly arbitrary fashion.
This will be the subject of aforthcoming article.6.
Conc luding RemarksWe have described a new logic grammar system forhandling coordination metagrammatical ly,  which alsoautomatical ly builds up the modifier structure of asentence during parsing.
This structure, as we haveseen, can be considered an annotated phrase structuretree, but the underlying grammar - unlike other recentapproaches to NL processing - is not necessarilycontext-free.
The rules accepted are generalizedtype-0 rules that may include gaps (in view, for in-stance, of left extraposition), and semantic interpreta-tion, as we have seen, is guided through the semanticitems, local to each rule, which help resolve scopingproblems.
The system's emantic interpretation com-ponent can in particular deal with scoping problemsinvolving coordination.While the treatment of coordination is the mainmotivation for developing still another logic grammarformalism, we believe our notion of modifier structuregrammar to be particularly attractive for allowing theuser to write grammars in a more straightforward man-ner and more clearly.
Also, because the semanticinformation about the structure being built up is de-scribed modularly in the grammar rules, it becomeseasier to adapt the parser to alternative domains ofapplication: modifying the logical representation ob-tained need only involve the semantic items in eachrule.
A related but less flexible idea was independent-ly developed for Restriction Grammars by Hirshmanand Puder (1982).
RGs are also logic grammars in thesense that they are based on Prolog, but they deal onlywith context-free definitions augmented by restrictions(which are procedures attached to the rules).
In RGs,a tree record of the context-free rules applied is auto-matically generated uring the parse.
More evolvedrepresentations for the sentence, however, are againthe user's responsibil ity and require processing thisautomatically generated parse tree.Another important point, in our view, is the factthat our system does not preclude context-sensitiverules, transformations, or gaps.
This is contrary towhat seems to be the general tendency today, both intheoretical linguistics (for example, Gazdar 1981) andin computational  linguistics (for example, Hirshmanand Puder 1982, Joshi and Levy 1982, RobinsonAmerican Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983 79Veronica Dahl and Michael C. McCord Treating Coordination in Logic Grammars1982, Schubert and Pelletier 1982),  towards usingcontext-free grammars (which, however,  are oftenaugmented in some way - through restrictions, localconstraints, rule schemata, metarules, etc.
- compen-sating for the lack of expressiveness in simple context-free grammars).
This approach was largely motivatedby the need to provide alternatives to transformationalgrammar, which on the one hand was felt by AI re-searchers to deal insufficiently with semantics and withsentence analysis, and on the other hand, as observedby Gazdar (1981),  could not offer linguistically ade-quate explanations for important constructs, such ascoordinat ion and unbounded dependencies.
Furtherarguments supporting this approach include claims ofmore efficient parsability, simplicity, and modularity.From the particular point of view of logic gram-mars, more evolved grammar formalisms make a greatdeal of sense for various reasons.
In the first place,they provide various advantages that have been illus-trated in Dahl (1981),  namely modularity and concise-ness, clarity and efficiency.
A detailed discussion ofthese advantages with respect to augmented transitionnetworks can be found in Pereira and Warren (1980).Furthermore, they include lower-level grammars asa special case.
In particular, context-free rules aug-mented with procedures may be written, since even thesimplest logic grammar defined to date (DCGs) allowsProlog calls to be interspersed with the rules.
Thegreater expressive power al lowed by more evolvedformalisms, then, can only represent a gain, since itdoes not preclude more elementary approaches.
Logicgrammars, in short, seem to be developing - like othercomputer formalisms - into higher-level tools thatallow the user to avoid mechanizable effort in order toconcentrate on as yet unmechanizable, creative tasks.MSGs are intended as a contribution in this direction.7.
ReferencesBates, M. 1978 The Theory and Practice of Augmented TransitionNetwork Grammars.
in Bolc, L., Ed., Natural Language Com-munication with Computers.
Springer-Verlag, New York: 191-259.Coelho, H.M.F.
1979 A Program Conversing in Portuguese Provid-ing a Library Service.
Ph.D. thesis, University of Edinburgh.Colmerauer, A.
1973 Un systeme de communication homme-machinein francais.
Groupe d' Intelligence Artificielle, Universit6 d'Aix-Marseille.Colmerauer, A.
1978 Metamorphosis Grammars.
In Bolc, L., Ed.,Natural Language Communication with Computers.
Springer-Verlag, New York: 133-189.Dahl, V. 1977 Un Systeme Deductif d'Interrogation de Banques deDonnees en Espagnol.
Th6se de Doctorat de Sp6cialit6,Universit6 d'Aix-Marsielle.Dahl, V. 1981 Translating Spanish into Logic through Logic.American Journal of Computational Linguistics 13 : 149-164.Gazdar, G. 1981 Unbounded Dependencies and Coordinate Struc-ture.
Linguistic Inquiry 12(2): 155-184.Hirshman, L. and Puder, K. 1982 Restriction Grammar in Prolog.Proc.
First International Logic Programming Conference.
Mars-eille, France: 85-90.Joshi, A. and Levy, L.S.
1982 Phrase Structure Trees Bear MoreFruit than You Would Have Thought.
American Journal ofComputational Linguistics 8:1-11.Kowalski, R.A. 1974 Predicate Logic as a Programming Language.Proc.
IFIP 74.
North-Holland, Amsterdam, The Netherlands:569-574.Kowalski, R.A. 1979 Logic for Problem Solving.
North-Holland,New York, New York.McCord, M.C.
1982 Using Slots and Modifiers in Logic Grammarsfor Natural Language.
Artificial Intelligence 18: 327-367.McCord, M.C.
1981 Focalizers, the Scoping Problem, and Seman-tic Interpretation Rules in Logic Grammars.
Technical Report,University of Kentucky.
To appear in Warren, D. and vanCaneghem, M., Eds., Logic Programming and its Applications.Pereira, F. 1981 Extraposition Grammars.
American Journal ofComputational Linguistics 7: 243-256.Pereira, F. and Warren, D. 1980 Definite Clause Grammars forLanguage Analysis - a Survey of the Formalism and a Compari-son with Transition Networks.
Artificial Intelligence 13: 231-278.Pereira, F. and Warren, D. 1982 An Efficient Easily AdaptableSystem for Interpreting Natural Language Queries.
AmericanJournal of Computational Linguistics 8:110-122.Pereira, L.M.
et al 1982 ORBI - An Expert System for Environ-mental Resource Evaluation through Natural Language.
Univer-sidade Nova de Lisboa.Pereira, L.; Pereira, F.; and Warren, D. 1978 User's Guide to DECSystem-lO Prolog.
Department of Artificial Intelligence, Univer-sity of Edinburgh.Robinson, J.
1982 Diagram: a Grammar for Dialogues.
Comm.ACM 25: 27-47.Robinson, J.A.
1965 A Machine-Oriented Logic Based on theResolution Principle.
J. ACM 12: 23-41.Roussel, P.L.
1975 Prolog Manuel de Reference et d'Utilisation.Universit6 d'Aix-Marseille.Schubert, L. and Pelletier, F. 1982 From English to Logic:Context-Free Computation of 'Conventional' Logical Transla-tion.
American Journal of Computational Linguistics 8 (1) : 27-44.Van Emden, M.H.
1975 Programming with Resolution Logic.Machine Intelligence, 8.
John Wiley, New York, New York.Winograd, T. 1972.
Understanding Natural Language.
AcademicPress, New York.
New York.Woods, W.A.
1973 An Experimental Parsing System for TransitionNetwork Grammars.
In Rustin, R., Ed., Natural LanguageProcessing.
Algorithmics Press, New York, New York: 145-149.80 American Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983Veronica Dahl and Michael C. McCord Treating Coordinat ion in Logic GrammarsAPPENDIX/* Grammar rule preprocessor.
*/?
- public readRules/0,parse/3,go/0.
:- op(1000,xfy,(...)).
:- op(1100,xfy,:).readRules :-tell(metgrr),repeat,read(Rule),process(Rule).process(endRules) :-!,told.process(Rule) :-!,parts (Rule,Head,Sem,Body),makex(Head,NT,Ext),makelist (Body,Body 1 ),write(rule(NT,Ext,Sem,Body 1)),write ('.
'),nl,nl,fail.process(Clause) :-assertz(Clause),fail.parts((Head:Sem--> Body),Head,Sem,Body) :-!.parts((Head --> Body),Head,e-true,Body).makelist((X,L),\[X I L 1 \]) :-!,makelist(L,L1).makelist(\[ ],\[ \]):-!.makelist(X,\[X\]).makex((NT,L),NT,Ext) :- !,makexl(nogap,L,Ext).makex((NT...L),NT,Ext) :- !,makexl(gap,L,Ext).makex(NT,NT,nil).makexl (CT,(S,L),x(CT,Type,S1,X)) :-!,type (S,S 1,Type),makex 1(nogap,L ,X ).makexl (CT,(S...L),x(CT,Type,S1,X)) :-!,type(S,S 1,Type),makexl (gap,L,X).makexl (CT,S,x(CT,Type,S 1 ,nil)) :-type(S,S1,Type).type(\[S\],S,terminal) :-!.type (S,S,nonterminal)./* Parser */parse(String,NonTerminal,Syn) :-prs(\[NonTerminal\],String,\[Syn\],nil,nil,nil),!.prs(BL,\[D I X\],Mods,Par,Mer,Ext) :-demon(D,BL,X,Mods,Par,Mer,Ext).prs(BL,X,Mods,Par,merge (BL,Par 1,Mer,Ext),nil) :-cutoff(Par),prs(BL,X,Mods,Parl,Mer,Ext).prs(\[\[W\] I BL\],\[W I X\],Mods,Par,Mer,Ext) :-gap (Ext),prs(BL,X,Mods,Par,Mer,Ext).prs(\[\[W\] I BL\],X,Mods,Par,Mer,x(_,terrninal,W,Ext)) :-prs (BL,X,Mods,Par,Mer,Ext).American Journal of Computat ional  Linguistics, Volume 9, Number 2, Apri l - June 1983 81Veronica Dahl and Michael C. McCord Treating Coordinat ion in Logic Grammarsprs(\[{B} I BL\],X,Mods,Par,Mer,Ext) :-!,B,prs(BL,X,Mods,Par,Mer,Ext).prs(\[NT I BL\],X,Mods,Par,Mer,Ext) :-rule(NT,Ext0,Sem,Body),stack(Ext0,Ext,Extl),prspush(Body,NT,BL,Sem,X,Mods,Par,Mer,Ext 1).prs(\[NT I BL\],X,Mods,Par,Mer,x(_,nonterminal,NT,Ext)) :-prs (BL,X,Mods,Par,Mer,Ext).prs(\[ \],X,\[ \],parent(\[_ I BL\],Mods,Par),Mer,Ext) :-prs(BL,X,Mods,Par,Mer,Ext).prs(\[ \],\[ \],\[ \],nil,nil,nil).prspush(\[ \],_,BL,_,X,Mods,Par,Mer,Ext) :-!,prs(BL,X,Mods,Par,Mer,Ext).prspush(Body,NT,BL,Sem,X,\[syn(NT,Sem,Mods 1) \] Mods\],Par,Mer,Ext) :-prs(Body,X,Modsl ,parent(\[NT I BL\],Mods,Par),Mer,Ext).gap(x(gap, , )).gap(nil).stack(nil,X,X).stack(x(C,T,S,X1),X2,x(C,T,S,X3)) :- stack(X1,X2,X3).cutoff(parent(\[_ I BL\],\[ \],Par)) :- satisfied(BL), cutoff(Par).cutoff(nil).demon(D,BL,X,Mods,Par,Mer,Ext) :-conjunction(D,Cat,Sem),backup(Par,Mods,\[syn(Cat,Sem,Mods0)\],\[NT I _\],Parl ),prs ( \[NT\] ,X ,Mods0 ,nil ,merge ( BL ,Par 1 ,Mer,Ext) ,nil ).backup(parent (BL,Mods,Par) ,Mods0,Mods0,BL,parent (BL,Mods,Par)).backup(parent(\[ I BL\],Mods,Par),\[ \],Mods0,BL1,Parl) :-satisfied(BL),backup (Par,Mods,Mods0,BL 1 ,Par 1 ).satisfied(\[ \]) :-!.satisfied(\[NT t BL\]) :- rule(NT, , ,\[ \]),I,satisfied(BL)./ *  Semantic Interpretation Rules * /:- op(400,xfy,&).
:- op(300,fx,@)./* Reshaping Rules */reshape(Tree,Sisters,Tree 1) :-daughters (Tree,Daus),reshapelist(Daus,Daus 1),reorder(Dausl,Daus2),raise (Daus2,Tree,Sisters,Daus3),newdaus(Tree,Daus3,Treel).reshapelist(\[Tree I Trees\],Trees2) :-!,reshapelist (Trees,Trees 1 ),reshape(Tree,Sisters,Tree 1),concat(Sisters,\[Tree 1 I Trees 1 \],Trees2).reshapelist(\[ \],\[ \]).reorder(\[A I L\],M) :-reorder(L,L1),insert(A,L1,M).reorder(\[ \],\[ \]).82 American Journal of Computat ional  Linguistics, Volume 9, Number 2, Apri l - June 1983Veronica Dahl and Michael C. McCord Treating Coordination in Logic Grammarsinsert(A,\[B I L\],M) :-prec(A,PA),prec(B,PB),(PB>PA,!,M=\[B I L1\],insert(A,L,L1) IM=\[A,B I L\]).insert(A,\[ \],\[A\]).raise(\[Dau I Daus\],Tree,\[Dau I Sisters\],Dausl) :-above(Dau,Tree),!,raise (Daus,Tree,Sisters,Daus 1 ).raise(\[Dau I Daus\],Tree,Sisters,\[Dau I sl\]) :-raise(Daus,Tree,Sisters,Daus 1).raise(\[ \],Tree,\[ ],\[ \]).daughters ( yn(_,_,Daus),Daus).newdaus (syn(NT,Sem,_),Daus,syn(NT,Sem,Daus)).cat(syn(NT, , ),NT).prec(Syn,P) :- stype(Syn,S),precl (S,P),!.prec(_,0).stype(syn(nounph(_,Stype), , Stype).precl (def,6).precl (all,6).precl (indef,4).above(Synl,Syn2) :-cat(Synl,nounph( , )),cat(Syn2,Cat),-,+ (Cat=relative(_) I Cat=conj(_))./* Translation Rules */translate(Syn,LogForml) :-transmod(Syn,8-true,8-LogForm),simplify(LogForm,\[ \],LogForml).transmods(\[Mod I Mods\],Sem 1,Sem3) :-transmods(Mods,Seml,Sem2),transmod(Mod,Sem2,Sem3).transmods(\[ \],Sem,Sem).transmod(syn(_,Sem,Mods),Sem 1,Sem2):-transmods(Mods,Sem,Sem0),trans(Sem0,Seml,Sem2)./* Rules for 'trans' are numbered for convenient reference in the text./ *1" /  trans(Sem,C*D-P,cbasel(Sem,C,D)-P) :-!./*2*/  trans(cbasel (Sem,C,D)-P,Op-Q,cbase2 (Op,Sem,C,D,R)-true) :-!,conj(P,Q,R)./*3*/  trans(Op-P,cbase2(Op 1,Sem,C,D,B)-P 1,cbase2 (Op2,Sem,C,D,B)-P2) :-!,trans(Op-P,Op 1-P1,Op2-P2)./*4*/  trans(cbase2(Op,Seml,C,D,B)-P,Sem2,Opl-B) :-!,trans(Op-P,Sem2,Opl-C),trans(Seml,Sem2,Opl-D)./*5*/  trans(P/Q-R,Op-Q,@P-R)./*6*/  trans(@P-Q,Op-P,Op-Q)./*7*/  trans(?-P,Op-Q,Op-R) :- conj(P,Q,R)./*8*/  trans(r-P,Op-Q,Op-R) :- conj(Q,P,R)./*9*/ trans(subst(X)-X,Sem,Sem)./* 10"/ trans(id-P,Sem,Sem).
*/American Journal of Computational Linguistics, Volume 9, Number 2, April- June 1983 83Veronica Dahl and Michael C. McCord Treating Coordination in Logic Grammarsconj(true,Q,Q) :-!.conj(P,true,P) :-!.conj(P,Q,P&Q)./* Simplification Rules */simplify(X,D,Y) :- var(X),!,find(X,D,Y).simplify(E,_,E) :- atomic(E),!.simplify(def(X,X=Y,E),D,E 1 ) :-!, simplify(E,\[X=Y I D\],E 1 ).simplify(true&E,D,E 1) :-!, simplify(E,D,E 1).simplify(E&true,D,E 1) :-!, simplify(E,D,E 1).simplify(E,D,E1) :-E=..\[P I Args\],simplist(Args,D,Args 1 ),EI=..\[P I Argsl\].find(X,\[X1 =Y I _\],Y) :- X= =XI,!.find(X,\[_ I D\],Y) :- find(X,D,Y),!.find(X,\[ \],X).simplist(\[E \] L\],D,\[E1 I L1\]) :-simplify(E,D,E 1),simplist (L,D,L 1 ).simplist(\[ \],_,\[ \])./* Syntax */:- readRules.sent--> nounph(X,_),verbph(X).nounph(X,def):@P-def(X,X=N,P) --> \[N\],{prop(N)}.nounph(X,Stype) -->det(X,Stype),adj (X),noun(X,Comps),comps(Comps),relative(X).nounph(X,_) --> trace(X).det(X,Stype):Sem --> \[D\],{deter(D,X,Stype,Sem)}.adj(_) --> \[ \].adj (X):Sem -- > \[Adj\], { adjec(Adj,X,Sem) }.noun(X,Comps):e-Pred --> \[N\],{n(N,X,Comps,Pred) }.relative(X) --> \[ \].relative(X) --> open,rel_mk(X),sent,close.open...close--> \[ \].rel mk(X)...trace(X) --> \[N\],{rel_pro(N)}.rel_mk(X)...\[P\],trace(X)--> \[P\],{prep(P)},\[N\],{rel_pro(N)}.verbph(X) --> advl,verb(X,Comps),comps(Comps).advl--> \[ \].advl:Sem--> \[Adv\],{adverb(Adv,Sem)}.verb(X,Comps) :~-Pred -- > \[V\],{v(V,Pred,X,Comps) }.comps(\[ \ ] ) - ->\ [  \].eomps(\[X I L\]) --> comp(X),comps(L).comp(obj-X) --> nounph(X,_).comp(pobj(Prep)-X) --> \[Prep\],nounph(X,_).endRules.84 American Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983Veronica Dahl and Michael C. McCord Treating Coordination in Logic Grammars/* Lexicon */conjunction(and,conj(and),P*Q-(P&Q)).conjunction(or,conj(or),P*Q-(P;Q)).conjunction(but,conj (but),P*Q-but(P,Q)).prop(john).prop(bill).prop(mary).deter(a,X,indef,Q/P-exists(X,P,Q)).deter (an,X,indef,Q/P-exists(X,P,Q)).deter(the,X,def,Q/P-def(X,P,Q)).deter (each,X,all,Q/P-each(X,P,Q)).deter (every,X,all,Q/P-every(X,P,Q)).adjec(red,X,g-red(X)).adjec(blue,X,8-blue(X)).adjec(glass,X,g-glass (X)).n(man,X,\[ \],man(X)).n(woman,X,\[ ],woman(X)).n(car,X,\[ \],car(X)).n(train,X,\[ \],train(X)).n(book,X,\[ \],book(X)).n(pencil,X,\[ \],pencil(X)).n(table,X,\[ ],table(X)).n(window,X,\[ \],window(X)).n(father,X,\[pobj(of)-Y\],father(X,Y)).n(friend,X,\[pobj(of)-Y\],friend(X,Y)).n(apple,X,\[ ],apple(X)).n(pear,X,\[ ],pear(X)).v(saw,saw(X,Y),X,\[obj-Y\]).v(heard,heard(X,Y),X,\[obj-Y\]).v(demolished,demolished(X,Y),X,\[obj-Y\]).v(laughed,laughed(X),X,\[ \]).v(drove,drove_through(X,Y,Z) ,X,\[obj-Y,pobj (through)-Z\]).v(gave,gave(X,Y,Z),X,\[obj-Y,pobj(to)-Z\]).v(ate,ate(X,Y),X,\[obj-Y\]).v(sat,sat_at(X,Y),X,\[pobj(at)-Y\]).adverb(completely,@P-completely(P)).adverb (finally, @ P-finally (P)).rel_pro(who).rel_pro(whom).rel_pro(that).rel_pro(which).prep(to).prep(from).prep(with).prep(of).prep(through).American Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983 85Veronica Dahl and Michae l  C. McCord Treating Coordination in Logic GrammarsEXAMPLES1:Prolog-10 version 3Input sentence:\]: each man ate an apple and a pear.Syntactic analysis, time = 143 msec.sent g-truenounph(_l,all) e-truedet(_l,all) 2/ 3-each( 1, 3, 2)noun(_l,\[ \]) g-man(_l)verbph(_l) g-trueverb(_l,\[obj-_4\]) g-ate( 1, 4)comps(\[obj-_4\]) g-truecomp(obj-_4) g-truenounph(_4,indef) e-truedet(_4,indef) 5/ 6-exists( 4, 6, 5)noun(_4,\[ \]) g-apple(_4)conj(and) 7* 8- 7& 8nounph(_4,indef) g-truedet(_4,indef) 9/ 10-exists( 4, 10, 9)noun(_4,\[ \]) g-pear(_4)Reshaping tree, time = 16 msec.sent e-truenounph(_l,all) g-truedet(_l,all) 2/ 3-each( 1, 3, 2)noun(_l,\[ \]) e-man(_l)nounph(_4,indef) e-truedet(_4,indef) 5/ 6-exists( 4, 6, 5)noun(_4,\[ \]) g-apple(_4)conj(and) 7* 8- 7& 8nounph(_4,indef) e-truedet(_4,indef) 9/ 10-exists( 4, 10,_9)noun(_4,\[ \]) g-pear(_4)verbph(_l) g-trueverb(_l,\[obj-_4\]) g-ate( 1, 4)comps(\[obj-_4\]) e-truecomp(obj-_4) g-trueSemantic analysis, time = 22 msec.each(_l,man(_l),exists(_2,apple(_2),ate( 1, 2))&exists(_2,pear(_2),ate( 1, 2)))Input sentence:1: john ate an apple and a pear.Syntactic analysis, time = 144 msec.Reshaping tree, time = 35 msec.Semantic analysis, time = 11 msec.exists(_l,apple(_l),ate(john,_l))&exists(_l,pear(_l),ate(john,_l))Input sentence:\] : a man and a woman saw each train.Syntactic analysis, time = 94 msec.sent g-truenounph(_l,indef) e-true86 American Journal of Computational Linguistics, Volume 9, Number 2, April- June 1983Veronica Dahl and Michael C. McCord Treating Coordination in Logic Grammarsdet(_l,indef) 2/ 3-exists( 1, 3, 2)noun(_l,\[ \]) g-man(_l)conj(and) 4* 5- 4& 5nounph(_l,indef) g-truedet(_l,indef) 6/ 7-exists( 1, 7, 6)noun(_l,\[ \]) g-woman(_l)verbph(_l) g-trueverb(_l,\[obj-_8\]) g-saw( 1, 8)comps(\[obj-_8\]) g-truecomp(obj-_8) g-truenounph(_8,all) g-truedet(_8,all) 9/ 10-each( 8, 10, 9)noun(_8,\[ \]) g-train(_8)Reshaping tree, time = 24 msec.sent g-truenounph(_l,all) g-truedet(_l,all) 2/ 3-each( 1, 3, 2)noun(_l,\[ \]) g-train(_l)nounph(_4,indef) g-truedet(_4,indef) 5/ 6-exists( 4, 6, 5)noun(_4,\[ \]) g-man(_4)conj(and) 7* 8- 7& 8nounph(_4,indef) g-truedet(_4,indef) 9/ 10-exists( 4, 10, 9)noun(_4,\[ \]) g-woman(_4)verbph(_4) g-trueverb(_4,\[obj-_l\]) g-saw( 4, 1)comps(\[obj-_l\]) g-truecomp(obj-_l) g-trueSemantic analysis, time = 16 msec.each(_l,train(_l),exists(_2,man(_2),saw( 2, 1))&exists(_2,woman(_2),saw( 2, 1)))Input sentence:I: each man and each woman ate an apple.Syntactic analysis, time = 78 msec.sent g-truenounph(_l,all) g-truedet(_l,all) 2/ 3-each( 1, 3, 2)noun(_l,\[ \]) g-man(_l)conj(and) 4* 5- 4& 5nounph(_l,all) g-truedet(_l,all) 6/ 7-each( 1, 7, 6)noun(_l,\[ \]) g-woman(_l)verbph(_l) g-trueverb(_l,\[obj-_8\]) g-ate( 1, 8)comps(\[obj-_8\]) g-truecomp(obj-_8) g-truenounph(_8,indef) g-truedet(_8,indef) 9/ 10-exists( 8, 10, 9)noun(_8,\[ \]) g-apple(_8)Reshaping tree, time = 14 msec.American Journal of Computational Linguistics, Volume 9, Number 2, April-June 1983 87Veronica Dahl and Michael C. McCord Treating Coordinat ion in Logic Grammarssent g-truenounph(_l,all) g-truedet(_l,all) 2/ 3-each( 1, 3, 2)noun(_1,\[ \]) g-man(_l)conj(and) 4* 5- 4& 5nounph(_l,all) g-truedet(_l,all) 6/ 7-each( 1, 7, 6)noun(_l,\[ \]) g-woman(_l)nounph(8,indef) g-truedet(_8,indef) 9/ 10-exists( 8, 10,_9)noun(_8,\[ \]) g-apple(_8)verbph(_l) g-trueverb(_l,\[obj-_8\]) g-ate( 1, 8)comps(\[obj-_8\]) g-truecomp(obj-_8) g-trueSemantic analysis, time = 20 msec.each(_l,man(_l),exists( 2,apple(_2),ate( 1, 2)))&each(_l,woman(_l),exists(_2,apple(_2),ate( 1  2)))Input sentence:I : john saw and the woman heard a man that laughed.Syntactic analysis, time - 182 msec.sent g-truenounph(_l,def) @_2-def( 1, l=john,_2)verbph(_l) g-trueverb(_l,\[obj-_3\]) g-saw( 1, 3)conj(and) 4* 5- 4& 5sent g-truenounph(_6,def) g-truedet(_6,def) 7/ 8-def( 6, 8, 7)noun(_6,\[ \]) g-woman(_6)verbph(_6) g-trueverb(_6,\[obj-_3\]) g-heard( 6, 3)comps(lob j- 3\]) g-truecomp(obj-_3) g-truenounph(_3,indef) g-truedet(_3,indef) 9/ 10-exists( 3, 10, 9)noun(_3,\[ \]) g-man(_3)relative(_3) g-truerel_mk(_3) g-truesent g-truenounph( 3, 11) g-trueverbph(_3) g-trueverb(_3,\[ \]) g-laughed(_3)Reshaping tree, time = 24 msec.sent g-truenounph(_l,def) @_2-def( 1, l=john,_2)verbph(_l) g-trueverb(_l,\[obj-_3\]) g-saw( 1, 3)conj(and) 4* 5- 4& 5nounph(_6,def) g-truedet(_6,def) 7/ 8-def( 6, 8, 7)noun(_6,\[ \]) g-woman(_6)nounph(_3,indef) g-true88 American Journal of Computat ional  Linguistics, Volume 9, Number 2, Apri l - June 1983Veronica Dahl and Michael C. McCord Treating Coordination in Logic Grammarsdet(_3,indef) 9/ 10-exists( 3, 10, 9)noun(_3,\[ \]) g-man(_3)relative(_3) g-truenounph(3,wh) g-truerel_mk(_3) g-truesent g-trueverbph(_3) g-trueverb(_3,\[ \]) g-laughed(_3)sent g-trueverbph(_6) g-trueverb(_6,\[obj-_3\]) g-heard( 6, 3)comps(\[obj-_3\]) g-truecomp(obj-_3) g-trueSemantic analysis, time = 18 msec.def (_ 1, woman (_ 1 ), exists (_2 ,man ( _2 ) &laughed ( _2 ),saw(john,_2)&heard( 1, 2)))Input sentence:I: john drove the car through and completely demolished a window.Syntactic analysis, time = 80 msec.sent g-truenounph(_l,def) @_2-def( 1, l=john, 2)verbph(_l) g-trueverb(_l,\[obj-_3,pobj(through)-_4\]) g-drove_through( 1, 3, 4)comps(\[obj-_3,pobj (through)-_4\]) g-truecomp(obj-_3) g-truenounph(_3,def) g-truedet(3,def) 5/ 6-def( 3, 6, 5)noun(_3,\[ \]) g-car(_3)comps (\[pobj (through)-_4\]) g-truecomp(pobj (through)-_4) g-trueconj(and) 7* 8- 7& 8verbph(_l) g-trueadvl @_9-completely(_9)verb(_l,\[obj-_4\]) g-demolished( 1, 4)comps(\[obj-_4\]) g-truecomp(obj-_4) g-truenounph(_4,indef) g-truedet(_4,indef)_10/_ll-exists( 4, 11, 10)noun(_4,\[ \]) g-window(_4)Reshaping tree, time - 22 msec.sent g-truenounph(_l,def) @ 2-def( 1, l=john,_2)nounph(3,def) g-truedet(_3,def) 4/ 5-def( 3, 5, 4)noun(_3,\[ \]) g-car(_3)verbph(_l) g-trueverb(_l,\[obj-_3,pobj(through)-_6\]) g-drove_through( 1, 3, 6)comps(\[obj-_3,pobj(through)-_6\]) g-truecomp(obj-_3) g-truecomps(\[pobj (through)-_6\]) g-truecomp(pobj (through)-_6) g-trueconj(and) 7* 8- 7& 8nounph(_6,indef) g-trueAmerican Journal of Computational Linguistics, Volume 9, Number 2, April- June 1983 89Veronica Dahl and Michael C. McCord Treating Coordination in Logic Grammarsdet(_6,indef) 9 /  10-exists( 6, 10, 9)noun(_6,\[ \]) 8-window(_6)verbph(_ l )  8-trueadvl @_11-completely(_ l  1)verb(_l , \ [obj-_6\])  C-demolished( 1, 6)comps(\[obj-_6\]) e-truecomp(obj-_6) e-trueSemantic analysis, time = 9 msec.def(_ l ,car(_ l ) ,exists(_2,window(_2),drove_through(john, 1 2)&completely(demolished(john,_2))))Input sentence:I: the woman who gave a book to john anddrove a car through a window laughed.Syntactic analysis, time = 250 msec.Reshaping tree, time = 108 msec.Semantic analysis, time = 28 msec.def(_ l  ,woman(_l  ) &exists(_2,book(_2),exists(_3,car(_3),exists(_4,window(_4),gave( 1, 2,john)&drove_through( 1, 3, 4))) ) , laughed(_ l ) )Input sentence:I: john saw the man that mary saw and bill heard.Syntactic analysis, time = 87 msec.Reshaping tree, time = 27 msec.Semantic analysis, time = 25 msec.def(_ l ,man(_ l )&saw(mary,_ l )&heard(bi l l ,_ l ) ,saw( john,_ l ) )Input sentence:I: john saw the man that heard the woman that laughed and saw bill.Syntactic analysis, time = 174 msec.Reshaping tree, time = 101 msec.Semantic analysis, time = 23 msec.def(_ l  ,man(_ 1)&def(_2,woman(_2)&laughed(_2)&saw(_2,bill),heard( 1, 2)) ,saw(john,_ l ) )Input sentence:I: the man that mary saw and john heard and bill gave a book to laughed.Syntactic analysis, time = 1199 msec.Reshaping tree, time = 106 msec.Semantic analysis, time = 40 msec.def(_ l  ,man(_ 1 )&saw(mary,_l ) &exists (_2,book(_2),heard(john,_l)&gave(bil l ,  2  1)) , laughed(_l))Input sentence:I: the man that mary saw and heard gave an apple to each woman.Syntactic analysis, time = 144 msec.sent e-truenounph(_ l ,def)  e-truedet(_ l ,def)  2 /  3-def( 1, 3, 2)noun(_ l , \ [  \]) e -man(_ l )relat ive(_l)  e-truere l_mk(_ l )  e-true90 American Journal of Computat ional  Linguistics, Volume 9, Number 2, Apri l - June 1983Veronica Dahl and Michael C. McCord Treating Coordination in Logic Grammarssent 8-truenounph(_4,def) @_5-def( 4, 4=mary,_5)verbph(4) C-trueverb(_4,\[obj-_l\]) E-saw( 4, 1)conj(and) 6* 7- 6& 7verb(_4,\[obj-_l\]) C-heard( 4, 1)comps(\[obj- 1\]) 8-truecomp(obj-_l) E-truenounph( 1, 8) C-trueverbph(1) f-trueverb(_l,\[obj-_9,pobj(to)-_10\]) E-gave( 1, 9, 10)comps(\[obj-_9,pobj(to)-_l 0\]) C-truecomp(obj-_9) E-truenounph(_9,indef) C-truedet(_9,indef) ll/_12-exists( 9, 12,_11)noun( 9,\[ \]) 7-apple(_9)comps (\[pobj-(to)-_ 10\]) E-truecomp (pobj (to)-_ 10) g-truenounph(_10,all) 8-truedet(_10,all) 13/_14-each( 10, 14, 13)noun(_10,\[ ]-) E-woman(_10)Reshaping tree, time = 26 msec.sent C-truenounph(1,def) g-truedet(_l,def) 2/ 3-def( 1, 3, 2)noun(_l,\[ \]) g-man(_l)relative(_l) g-truenounph(_l,wh) g-truenounph(_4,def) @_5-def( 4, 4=mary,_5)rel_mk(_l) g-truesent g-trueverbph(_4) e-trueverb(_4,\[obj-_l\]) g-saw( 4, 1)conj(and) 6* 7- 6& 7verb(_4,\[obj-_l\]) t-heard( 4, 1)comps(\[obj-_l \])t-truecomp(obj-_l) g-truenounph(8,all) e-truedet(_8,all) 9/ 10-each( 8, 10, 9)noun(_8,\[ \]) g-woman(_8)nounph(11,indef) g-truedet(_ll,indef) 12/ 13-exists( 11, 13,_12)noun(_l 1,\[ \]) ~-app\]-e(_l 1)verbph(_l) t-trueverb(1,\[obj-_ll,pobj(to)-_8\]) g-gave( 1, 11,_8)comps(\[obj-_l 1,pobj(to)-_8\]) e-truecomp(obj-_l 1) g-truecomps(\[pobj(to)-_8\]) t-truecomp(pobj(to)-_8) t-trueSemantic analysis, time = 22 msec.def(_l,man(_l)&heard(mary,_l)&saw(mary,_l),each(_2,woman(_2),exists(_3,apple(_3),gave( 1, 3, 2))))American Journal of Computational Linguistics, Volume 9, Number 2, April- June 1983 91
