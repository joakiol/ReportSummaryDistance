The SENSEVAL?3 Multilingual English?Hindi Lexical Sample TaskTimothy ChklovskiInformation Sciences InstituteUniversity of Southern CaliforniaMarina del Rey, CA 90292timc@isi.eduRada MihalceaDepartment of Computer ScienceUniversity of North TexasDallas, TX 76203rada@cs.unt.eduTed PedersenDepartment of Computer ScienceUniversity of MinnesotaDuluth, MN 55812tpederse@d.umn.eduAmruta PurandareDepartment of Computer ScienceUniversity of MinnesotaDuluth, MN 55812pura0010@d.umn.eduAbstractThis paper describes the English?Hindi Multilinguallexical sample task in SENSEVAL?3.
Rather thantagging an English word with a sense from an En-glish dictionary, this task seeks to assign the mostappropriate Hindi translation to an ambiguous tar-get word.
Training data was solicited via the OpenMind Word Expert (OMWE) from Web users whoare fluent in English and Hindi.1 IntroductionThe goal of the MultiLingual lexical sample taskis to create a framework for the evaluation of sys-tems that perform Machine Translation, with a fo-cus on the translation of ambiguous words.
Thetask is very similar to the lexical sample task, ex-cept that rather than using the sense inventory froma dictionary we follow the suggestion of (Resnik andYarowsky, 1999) and use the translations of the tar-get words into a second language.
In this task forSENSEVAL-3, the contexts are in English, and the?sense tags?
for the English target words are theirtranslations in Hindi.This paper outlines some of the major issues thatarose in the creation of this task, and then describesthe participating systems and summarizes their re-sults.2 Open Mind Word ExpertThe annotated corpus required for this task wasbuilt using the Open Mind Word Expert system(Chklovski and Mihalcea, 2002), adapted for mul-tilingual annotations 1.To overcome the current lack of tagged data andthe limitations imposed by the creation of such datausing trained lexicographers, the Open Mind Word1Multilingual Open Mind Word Expert can be accessed athttp://teach-computers.org/word-expert/english-hindiExpert system enables the collection of semanticallyannotated corpora over the Web.
Tagged examplesare collected using a Web-based application that al-lows contributors to annotate words with their mean-ings.The tagging exercise proceeds as follows.
Foreach target word the system extracts a set of sen-tences from a large textual corpus.
These examplesare presented to the contributors, together with allpossible translations for the given target word.
Usersare asked to select the most appropriate translationfor the target word in each sentence.
The selectionis made using check-boxes, which list all possibletranslations, plus two additional choices, ?unclear?and ?none of the above.?
Although users are encour-aged to select only one translation per word, the se-lection of two or more translations is also possible.The results of the classification submitted by otherusers are not presented to avoid artificial biases.3 Sense Inventory RepresentationThe sense inventory used in this task is the set ofHindi translations associated with the English wordsin our lexical sample.
Selecting an appropriateEnglish-Hindi dictionary was a major decision earlyin the task, and it raised a number of interesting is-sues.We were unable to locate any machine readableor electronic versions of English-Hindi dictionaries,so it became apparent that we would need to manu-ally enter the Hindi translations from printed mate-rials.
We briefly considered the use of Optical Char-acter Recognition (OCR), but found that our avail-able tools did not support Hindi.
Even after decidingto enter the Hindi translations manually, it wasn?tclear how those words should be encoded.
Hindi isusually represented in Devanagari script, which hasa large number of possible encodings and no clearstandard has emerged as yet.Association for Computational Linguisticsfor the Semantic Analysis of Text, Barcelona, Spain, July 2004SENSEVAL-3: Third International Workshop on the Evaluation of SystemsWe decided that Romanized or transliteratedHindi text would be the the most portable encoding,since it can be represented in standard ASCII text.However, it turned out that the number of English?Hindi bilingual dictionaries is much less than thenumber of Hindi?English, and the number that usetransliterated text is smaller still.Still, we located one promising candidate, theEnglish?Hindi Hippocrene Dictionary (Raker andShukla, 1996), which represents Hindi in a translit-erated form.
However, we found that many Englishwords only had two or three translations, making ittoo coarse grained for our purposes2 .In the end we selected the Chambers English?Hindi dictionary (Awasthi, 1997), which is a highquality bilingual dictionary that uses Devanagariscript.
We identified 41 English words from theChambers dictionary to make up our lexical sam-ple.
Then one of the task organizers, who isfluent in English and Hindi, manually transliter-ated the approximately 500 Hindi translations ofthe 41 English words in our lexical sample fromthe Chambers dictionary into the ITRANS format(http://www.aczone.com/itrans/).
ITRANS softwarewas used to generate Unicode for display in theOMWE interfaces, although the sense tags used inthe task data are the Hindi translations in transliter-ated form.4 Training and Test DataThe MultiLingual lexical sample is made up of 41words: 18 nouns, 15 verbs, and 8 adjectives.
Thissample includes English words that have varying de-grees of polysemy as reflected in the number of pos-sible Hindi translations, which range from a low of3 to a high of 39.Text samples made up of several hundred in-stances for each of 31 of the 41 words were drawnfrom the British National Corpus, while samples forthe other 10 words came from the SENSEVAL-2 En-glish lexical sample data.
The BNC data is in a?raw?
text form, where the part of speech tags havebeen removed.
However, the SENSEVAL-2 data in-cludes the English sense?tags as determined by hu-man taggers.After gathering the instances for each word inthe lexical sample, we tokenized each instance andremoved those that contain collocations of the tar-get word.
For example, the training/test instancesfor arm.n do not include examples for contact arm,2We have made available transcriptions of the entries forapproximately 70 Hippocrene nouns, verbs, and adjectivesat http://www.d.umn.edu/?pura0010/hindi.html, although thesewere not used in this task.pickup arm, etc., but only examples that refer to armas a single lexical unit (not part of a collocation).
Inour experience, disambiguation accuracy on collo-cations of this sort is close to perfect, and we aimedto concentrate the annotation effort on the more dif-ficult cases.The data was then annotated with Hindi transla-tions by web volunteers using the Open Mind WordExpert (bilingual edition).
At various points in timewe offered gift certificates as a prize for the mostproductive tagger in a given day, in order to spurparticipation.
A total of 40 volunteers contributed tothis task.To create the test data we collected two indepen-dent tags per instance, and then discarded any in-stances where the taggers disagreed.
Thus, eachinstance that remains in the test data has completeagreement between two taggers.
For the trainingdata, we only collected one tag per instance, andtherefore this data may be noisy.
Participating sys-tems could choose to apply their own filtering meth-ods to identify and remove the less reliably anno-tated examples.After tagging by the Web volunteers, there weretwo data sets provided to task participants: onewhere the English sense of the target word is un-known, and another where it is known in both thetraining and test data.
These are referred to as thetranslation only (t) data and the translation and sense(ts) data, respectively.
The t data is made up of in-stances drawn from the BNC as described above,while the ts data is made up of the instances fromSENSEVAL-2.
Evaluations were run separately foreach of these two data sets, which we refer to as thet and ts subtasks.The t data contains 31 ambiguous words: 15nouns, 10 verbs, and 6 adjectives.
The ts data con-tains 10 ambiguous words: 3 nouns, 5 verbs, and 2adjectives, all of which have been used in the En-glish lexical sample task of SENSEVAL-2.
Thesewords, the number of possible translations, and thenumber of training and test instances are shown inTable 1.
The total number of training instances inthe two sub-tasks is 10,449, and the total number oftest instances is 1,535.5 Participating SystemsFive teams participated in the t subtask, submittinga total of eight systems.
Three teams (a subset ofthose five) participated in the ts subtask, submittinga total of five systems.
All submitted systems em-ployed supervised learning, using the training ex-amples provided.
Some teams used additional re-sources as noted in the more detailed descriptionsTable 1: Target words in the SENSEVAL-3 English-Hindi taskLexical Unit Translations Train Test Lexical Unit Translations Train Test Lexical Unit Translations Train TestTRANSLATION ONLY (T?DATA)band.n 8 224 91 bank.n 21 332 52 case.n 13 348 42different.a 4 320 25 eat.v 3 271 48 field.n 14 300 100glass.n 8 379 13 hot.a 18 348 32 line.n 39 360 11note.v 11 220 12 operate.v 9 280 50 paper.n 8 264 73plan.n 8 210 35 produce.v 7 265 67 rest.v 14 172 10rule.v 8 160 18 shape.n 8 320 32 sharp.a 16 248 48smell.v 5 210 17 solid.a 16 327 37 substantial.a 15 250 100suspend.v 4 370 28 table.n 21 378 16 talk.v 6 341 35taste.n 6 350 40 terrible.a 4 200 99 tour.n 5 240 9vision.n 14 318 20 volume.n 9 309 54 watch.v 10 300 100way.n 16 331 22 TOTAL 348 8945 1336TRANSLATION AND SENSE ONLY (TS?DATA)bar.n 19 278 39 begin.v 6 360 15 channel.n 6 92 16green.a 9 175 26 nature.n 15 71 14 play.v 14 152 10simple.a 9 166 19 treat.v 7 100 32 wash.v 16 10 11work.v 24 100 17 TOTAL 125 1504 199below.5.1 NUSThe NUS team from the National University of Sin-gapore participated in both the t and ts subtasks.
Thet system (nusmlst) uses a combination of knowledgesources as features, and the Support Vector Machine(SVM) learning algorithm.
The knowledge sourcesused include part of speech of neighboring words,single words in the surrounding context, local col-locations, and syntactic relations.
The ts system(nusmlsts) does the same, but adds the English senseof the target word as a knowledge source.5.2 LIA-LIDILEMThe LIA-LIDILEM team from the Universite?
d?Avignon and the Universite?
Stendahl Grenoble hadtwo systems which participated in both the t and tssubtasks.
In the ts subtask, only the English sensetags were used, not the Hindi translations.The FL-MIX system uses a combination of threeprobabilistic models, which compute the most prob-able sense given a six word window of context.
Thethree models are a Poisson model, a Semantic Clas-sification Tree model, and a K nearest neighborssearch model.
This system also used a part of speechtagger and a lemmatizer.The FC-MIX system is the same as the FL-MIXsystem, but replaces context words by more gen-eral synonym?like classes computed from a wordaligned English?French corpus which number ap-proximately 850,000 words in each language.5.3 HKUSTThe HKUST team from the Hong Kong Universityof Science and Technology had three systems thatparticipated in both the t and ts subtasksThe HKUST me t and HKUST me ts sys-tems are maximum entropy classifiers.
TheHKUST comb t and HKUST comb ts systemsare voted classifiers that combine a new KernelPCA model with a maximum entropy model anda boosting?based model.
The HKUST comb2 tand HKUST comb2 ts are voted classifiers thatcombine a new Kernel PCA model with a maximumentropy model, a boosting?based model, and aNaive Bayesian model.5.4 UMDThe UMD team from the University of Maryland en-tered (UMD?SST) in the t task.
UMD?SST is a su-pervised sense tagger based on the Support VectorMachine learning algorithm, and is described morefully in (Cabezas et al, 2001).5.5 DuluthThe Duluth team from the University of Minnesota,Duluth had one system (Duluth-ELSS) that partici-pated in the t task.
This system is an ensemble ofthree bagged decision trees, each based on a differ-ent type of lexical feature.
This system was knownas Duluth3 in SENSEVAL-2, and it is described morefully in (Pedersen, 2001).6 ResultsAll systems attempted all of the test instances, soprecision and recall are identical, hence we reportTable 2: t Subtask ResultsSystem Accuracynusmlst 63.4HKUST comb t 62.0HKUST comb2 t 61.4HKUST me t 60.6FL-MIX 60.3FC-MIX 60.3UMD-SST 59.4Duluth-ELSS 58.2Baseline (majority) 51.9Table 3: ts Subtask ResultsSystem Accuracynusmlsts 67.3FL-MIX 64.1FC-MIX 64.1HKUST comb ts 63.8HKUST comb2 ts 63.8HKUST me ts 60.8Baseline (majority) 55.8the single Accuracy figure.
Tables 2 and 3 show re-sults for the t and ts subtasks, respectively.We note that the participating systems all ex-ceeded the baseline (majority) classifier by somemargin, suggesting that the sense distinctions madeby the translations are clear and provide sufficientinformation for supervised methods to learn effec-tive classifiers.Interestingly, the average results on the ts data arehigher than the average results on the t data, whichsuggests that sense information is likely to be helpfulfor the task of targeted word translation.
Additionalinvestigations are however required to draw some fi-nal conclusions.7 ConclusionThe Multilingual Lexical Sample task inSENSEVAL-3 featured English ambiguous wordsthat were to be tagged with their most appropriateHindi translation.
The objective of this task is todetermine feasibility of translating words of variousdegrees of polysemy, focusing on translation ofspecific lexical items.
The results of five teamsthat participated in this event tentatively suggestthat machine learning techniques can significantlyimprove over the most frequent sense baseline.Additionally, this task has highlighted creationof testing and training data by leveraging theknowledge of bilingual Web volunteers.
Thetraining and test data sets used in this exercise areavailable online from http://www.senseval.org andhttp://teach-computers.org.AcknowledgmentsMany thanks to all those who contributed to the Mul-tilingual Open Mind Word Expert project, makingthis task possible.
We are also grateful to all the par-ticipants in this task, for their hard work and involve-ment in this evaluation exercise.
Without them, allthese comparative analyses would not be possible.We are particularly grateful to a research grantfrom the University of North Texas that provided thefunding for contributor prizes, and to the NationalScience Foundation for their support of Amruta Pu-randare under a Faculty Early CAREER Develop-ment Award (#0092784).ReferencesS.
Awasthi, editor.
1997.
Chambers English?HindiDictionary.
South Asia Books, Columbia, MO.C.
Cabezas, P. Resnik, and J. Stevens.
2001.
Su-pervised sense tagging using Support Vector Ma-chines.
In Proceedings of the Senseval-2 Work-shop, Toulouse, July.T.
Chklovski and R. Mihalcea.
2002.
Building asense tagged corpus with the Open Mind WordExpert.
In Proceedings of the ACL Workshop onWord Sense Disambiguation: Recent Successesand Future Directions, Philadelphia.T.
Pedersen.
2001.
Machine learning with lexicalfeatures: The Duluth approach to Senseval-2.
InProceedings of the Senseval-2 Workshop, pages139?142, Toulouse, July.J.
Raker and R. Shukla, editors.
1996.
Hip-pocrene Standard Dictionary English-HindiHindi-English (With Romanized Pronunciation).Hippocrene Books, New York, NY.P.
Resnik and D. Yarowsky.
1999.
Distinguish-ing systems and distinguishing senses: New eval-uation methods for word sense disambiguation.Natural Language Engineering, 5(2):113?133.
