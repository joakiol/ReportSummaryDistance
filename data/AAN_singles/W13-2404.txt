Proceedings of the 4th Biennial International Workshop on Balto-Slavic Natural Language Processing, pages 18?23,Sofia, Bulgaria, 8-9 August 2013. c?2010 Association for Computational LinguisticsAspect-Oriented Opinion Mining from User Reviews in CroatianGoran Glava??
Damir Korenc?ic??
Jan ?najder?
?University of Zagreb, Faculty of Electrical Engineering and ComputingUnska 3, 10000 Zagreb, Croatia?Rud?er Bo?kovic?
Institute, Department of ElectronicsBijenic?ka cesta 54, 10000 Zagreb, Croatia{goran.glavas,jan.snajder}@fer.hr damir.korencic@irb.hrAbstractAspect-oriented opinion mining aims toidentify product aspects (features of prod-ucts) about which opinion has been ex-pressed in the text.
We present an approachfor aspect-oriented opinion mining fromuser reviews in Croatian.
We propose meth-ods for acquiring a domain-specific opinionlexicon, linking opinion clues to productaspects, and predicting polarity and ratingof reviews.
We show that a supervised ap-proach to linking opinion clues to aspectsis feasible, and that the extracted clues andaspects improve polarity and rating predic-tions.1 IntroductionFor companies, knowing what customers think oftheir products and services is essential.
Opinionmining is being increasingly used to automaticallyrecognize opinions about products in natural lan-guage texts.
Numerous approaches to opinion min-ing have been proposed, ranging from domain-specific (Fahrni and Klenner, 2008; Qiu et al 2009;Choi et al 2009) to cross-domain approaches (Wil-son et al 2009; Taboada et al 2011), and fromlexicon-based methods (Popescu and Etzioni, 2007;Jijkoun et al 2010; Taboada et al 2011) to ma-chine learning approaches (Boiy and Moens, 2009;Go et al 2009).While early attempts focused on classifyingoverall document opinion (Turney, 2002; Pang etal., 2002), more recent approaches identify opin-ions expressed about individual product aspects(Popescu and Etzioni, 2007; Fahrni and Klenner,2008; Mukherjee and Liu, 2012).
Identifying opin-ionated aspects allows for aspect-based comparisonacross reviews and enables opinion summarizationfor individual aspects.
Furthermore, opinionatedaspects may be useful for predicting overall reviewpolarity and rating.While many opinion mining systems and re-sources have been developed for major languages,there has been considerably less development forless prevalent languages, such as Croatian.
In thispaper we present a method for domain-specific,aspect-oriented opinion mining from user reviewsin Croatian.
We address two tasks: (1) identifica-tion of opinion expressed about individual productaspects and (2) predicting the overall opinion ex-pressed by a review.
We assume that solving thefirst task successfully will help improve the perfor-mance on the second task.
We propose a simplesemi-automated approach for acquiring domain-specific lexicon of opinion clues and prominentproduct aspects.
We use supervised machine learn-ing to detect the links between opinion clues (e.g.,excellent, horrible) and product aspects (e.g., pizza,delivery).
We conduct preliminary experiments onrestaurant reviews and show that our method cansuccessfully pair opinion clues with the targetedaspects.
Furthermore, we show that the extractedclues and opinionated aspects help classify reviewpolarity and predict user-assigned ratings.2 Related WorkAspect-based opinion mining typically consistsof three subtasks: sentiment lexicon acquisition,aspect-clue pair identification, and overall reviewopinion prediction.
Most approaches to domain-specific sentiment lexicon acquisition start from amanually compiled set of aspects and opinion cluesand then expand it with words satisfying certainco-occurrence or syntactic criteria in a domain-specific corpus (Kanayama and Nasukawa, 2006;Popescu and Etzioni, 2007; Fahrni and Klenner,2008; Mukherjee and Liu, 2012).
Kobayashi et18al.
(2007) extract aspect-clue pairs from weblogposts using a supervised model with parts of de-pendency trees as features.
Kelly et al(2012)use a semi-supervised SVM model with syntacticfeatures to classify the relations between entity-property pairs.
Opinion classification of reviewshas been approached using supervised text cate-gorization techniques (Pang et al 2002; Funk etal., 2008) and semi-supervised methods based onthe similarity between unlabeled documents and asmall set of manually labeled documents or clues(Turney, 2002; Goldberg and Zhu, 2006).Sentiment analysis and opinion mining ap-proaches have been proposed for several Slaviclanguages (Chetviorkin et al 2012; Buczynski andWawer, 2008; Smr?, 2006; Smailovic?
et al 2012).Methods that rely on translation, using resourcesdeveloped for major languages, have also been pro-posed (Smr?, 2006; Steinberger et al 2012).
Thusfar, there has been little work on opinion miningfor Croatian.
Glava?
et al(2012) use graph-basedalgorithms to acquire a sentiment lexicon from anewspaper corpus.
Agic?
et al(2010) describe arule-based method for detecting polarity phrasesin financial domain.
To the best of our knowledge,our work is the first that deals with aspect-orientedopinion mining for Croatian.3 Aspect-Oriented Opinion MiningOur approach consists of three steps: (1) acquisi-tion of an opinion lexicon of domain-specific opin-ion clues and product aspects, (2) recognition ofaspects targeted by opinion clues, and (3) predic-tion of overall review polarity and opinion rating.The linguistic preprocessing includes sentencesegmentation, tokenization, lemmatization, POS-tagging, and dependency parsing.
We use the in-flectional lexicon from ?najder et al(2008) forlemmatization, POS tagger from Agic?
et al(2008),and dependency parser from Agic?
(2012).
As weare dealing with noisy user-generated text, prior toany of these steps, we use GNU Aspell tool1 forspelling correction.Step 1: Acquisition of the opinion lexicon.
Weuse a simple semi-automatic method to acquireopinion clues and aspects.
We identify candidatesfor positive clues as lemmas that appear much morefrequently in positive than in negative reviews (wedetermine review polarity based on user-assigned1http://aspell.net/rating).
Analogously, we consider as negativeclue candidates lemmas that occur much more fre-quently in negative than in positive reviews.
As-suming that opinion clues target product aspects,we extract as aspect candidates all lemmas thatfrequently co-occur with opinion clues.
We thenmanually filter out the false positives from the listsof candidate clues and aspects.Unlike some approaches (Popescu and Etzioni,2007; Kobayashi et al 2007), we do not requirethat clues or aspects belong to certain word cate-gories or to a predefined taxonomy.
Our approachis pragmatic ?
clues are words that express opin-ions about aspects, while aspects are words thatopinion clues target.
For example, we treat wordslike stic?i (to arrive) and sve (everything) as aspects,because they can be targets of opinion clues, as in?pizza je stigla kasno" (?pizza arrived late") and?sve super!"
(?everything?s great!
").Step 2: Identifying opinionated aspects.
Weaim to pair in each sentence the aspects with theopinion clues that target them.
For example, in?dobra pizza, ali lazanje su u?asne" (?good pizza,but lasagna was terrible"), the clue dobra (good)should be paired with the aspect pizza, and u?asne(terrible) should be paired with lazanje (lasagne).In principle, the polarity of an opinion is deter-mined by both the opinion clue and the aspect.
Atan extreme, an aspect can invert the prior polarityof an opinion clue (e.g., ?cold pizza" has a negative,whereas ?cold ice-cream" has a positive polarity).However, given that no such cases occurred in ourdataset, we chose not to consider this particulartype of inversion.
On the other hand, the polarityof an opinion may be inverted explicitly by the useof negations.
To account for this, we use a verysimple rule to recognize negations: we consider anaspect-clue pair to be negated if there is a negationword within a?3 token window of the opinion clue(e.g., ?pizza im nikad nije hladna" ?
?their pizza isnever cold").To identify the aspect-clue pairs, we train a super-vised model that classifies all possible pairs withina sentence as either paired or not paired.
We usefour sets of features:(1) Basic features: the distance between the as-pect and the clue (in number of tokens); the numberof aspects and clues in the sentence; the sentencelength (in number of tokens); punctuation, otheraspects, and other clues in between the aspect andthe clue; the order of the aspect and the clue (i.e.,19which one comes before);(2) Lexical features: the aspect and clue lemmas;bag-of-words in between the aspect and the clue; afeature indicating whether the aspect is conjoinedwith another aspect (e.g., ?pizza i sendvic?
su biliizvrsni" ?
?pizza and sandwich were amazing");a feature indicating whether the clue is conjoinedwith another clue (e.g., ?velika i slasna pizza" ?
?large and delicious pizza");(3) Part-of-speech features: POS tags of the as-pect and the clue word; set of POS tags in betweenthe aspect and the clue; set of POS tags preced-ing the aspect/clue; set of POS tags following theaspect/clue; an agreement of gender and numberbetween the aspect and the clue;(4) Syntactic dependency features: dependencyrelation labels along the path from the aspect to theclue in the dependency tree (two features: a con-catenation of these labels and a set of these labels);a feature indicating whether the given aspect is syn-tactically the closest to the given clue; a featureindicating whether the given clue is syntacticallythe closest to given aspect.Step 3: Predicting overall review opinion.
Weuse extracted aspects, clues, and aspect-clue pairsto predict the overall review opinion.
We considertwo separate tasks: (1) prediction of review po-larity (positive or negative) and (2) prediction ofuser-assigned rating that accompanies a review.
Weframe the first task as a binary classification prob-lem, and the second task as a regression problem.We use the following features for both tasks:(1) Bag-of-word (BoW): the standard tf-idfweighted BoW representation of the review;(2) Review length: the number of tokens in thereview (longer reviews are more likely to containmore opinion clues and aspects);(3) Emoticons: the number of positive (e.g.,?:)?)
and negative emoticons (e.g., ?:(?
);(4) Opinion clue features: the number and thelemmas of positive and negative opinion clues;(5) Opinionated aspect features: the number andthe lemmas of positively and negatively opinion-ated aspects.4 EvaluationFor experimental evaluation, we acquired adomain-specific dataset of restaurant reviews2 from2Available under CC BY-NC-SA license fromhttp://takelab.fer.hr/cropinion(HR) Zaista za svaku pohvalu!
Jelo su nam dostavili15 minuta ranije.
Naruc?ili smo pizzu koja je bilaprepuna dodataka, dobro pec?ena, i vrlo ukusna.
(EN) Really laudable!
Food was delivered 15 minutesearly.
We ordered pizza which was filled with ex-tras, well-baked, and very tasteful.Rating: 6/6Table 1: Example of a review (text and rating)Pauza.hr,3 Croatia?s largest food ordering website.The dataset contains 3310 reviews, totaling about100K tokens.
Each review is accompanied by anopinion rating on a scale from 0.5 (worst) to 6(best).
The average user rating is 4.5, with 74%of comments rated above 4.
We use these user-assigned ratings as gold-standard labels for super-vised learning.
Table 1 shows an example of areview (clues are bolded and aspects are under-lined).
We split the dataset into a development anda test set (7:3 ratio) and use the former for lexiconacquisition and model training.Experiment 1: Opinionated aspects.
To builda set on which we can train the aspect-clue pair-ing model, we sampled 200 reviews from the de-velopment set and extracted from each sentenceall possible aspect-clue pairs.
We obtained 1406aspect-clue instances, which we then manually la-beled as either paired or not paired.
Similarly forthe test set, we annotated 308 aspect-clue instancesextracted from a sample of 70 reviews.
Amongthe extracted clues, 77% are paired with at leastone aspect and 23% are unpaired (the aspect isimplicit).We trained a support vector machine (SVM) withradial basis kernel and features described in Section3.
We optimized the model using 10-fold cross-validation on the training set.
The baseline assignsto each aspect the closest opinion clue within thesame sentence.
We use stratified shuffling test (Yeh,2000) to determine statistical significance of per-formance differences.Results are shown in Table 2.
All of oursupervised models significantly outperform theclosest clue baseline (p < 0.01).
The Ba-sic+Lex+POS+Synt model outperforms Basicmodel (F-score difference is statistically significantat p < 0.01), while the F-score differences betweenBasic and both Basic+Lex and Basic+Lex+POSare pairwise significant at p < 0.05.
The F-score3http://pauza.hr/20Model Precision Recall F1Baseline 31.8 71.0 43.9Basic 77.2 76.1 76.6Basic+Lex 78.1 82.6 80.3Basic+Lex+POS 80.9 79.7 80.3Basic+Lex+POS+Synt 84.1 80.4 82.2Table 2: Aspect-clue pairing performanceReview polarity Review ratingModel Pos Neg Avg r MAEBoW 94.1 79.1 86.6 0.74 0.94BoW+E 94.4 80.3 87.4 0.75 0.91BoW+E+A 95.7 85.2 90.5 0.80 0.82BoW+E+C 95.7 85.6 90.7 0.81 0.79BoW+E+A+C 96.0 86.2 91.1 0.83 0.76E ?
emoticons; A ?
opinionated aspects; C ?
opinion cluesTable 3: Review polarity and rating performancedifferences between Basic+Lex, Basic+Lex+POS,and Basic+Lex+POS+Synt are pairwise not statis-tically significant (p < 0.05).
This implies thatlinguistic features increase the classification per-formance, but there are no significant differencesbetween models employing different linguistic fea-ture sets.
We also note that improvements over theBasic model are not as large as we expected; weattribute this to the noisy user-generated text andthe limited size of the training set.Experiment 2: Overall review opinion.
Weconsidered two models: a classification model forpredicting review polarity and a regression modelfor predicting user-assigned rating.
We trained themodels on the full development set (2276 reviews)and evaluated on the full test set (1034 reviews).For the classification task, we consider reviewsrated lower than 2.5 as negative and those ratedhigher than 4 as positive.
Ratings between 2.5 and4 are mostly inconsistent (assigned to both positiveand negative reviews), thus we did not considerreviews with these ratings.
For classification, weused SVM with radial basis kernel, while for re-gression we used support vector regression (SVR)model.
We optimized both models using 10-foldcross-validation on the training set.Table 3 shows performance of models with dif-ferent feature sets.
The model with bag-of-wordsfeatures (BoW) is the baseline.
For polarity classi-fication, we report F1-scores for positive and nega-tive class.
For rating prediction, we report Pearsoncorrelation (r) and mean average error (MAE).The models that use opinion clue features(BoW+E+C) or opinionated aspect features(BoW+E+A and BoW+E+A+C) outperform thebaseline model (difference in classification and re-gression performance is significant at p < 0.05and p < 0.01, respectively; tested using stratifiedshuffling test).
This confirms our assumption thatopinion clues and opinionated aspects improve theprediction of overall review opinion.
Performanceon negative reviews is consistently lower than forpositive reviews; this can be ascribed to the factthat the dataset is biased toward positive reviews.Models BoW+E+A and BoW+E+C perform simi-larly (the difference is not statistically significant atp < 0.05), suggesting that opinion clues improvethe performance just as much as opinionated as-pects.
We believe this is due to (1) the existence ofa considerable number (23%) of unpaired opinionclues (e.g., u?asno (terrible) in ?Bilo je u?asno!
"(?It was terrible!"))
and (2) the fact that most opin-ionated aspects inherit the prior polarity of the cluethat targets them (also supported by the fact theBoW+E+A+C model does not significantly outper-form the BoW+E+C nor the BoW+E+A models).Moreover, note that, in general, user-assigned rat-ings may deviate from the opinions expressed intext (e.g., because some users chose to commentonly on some aspects).
However, the issue of an-notation quality is out of scope and we leave it forfuture work.5 ConclusionWe presented a method for aspect-oriented opinionmining from user reviews in Croatian.
We proposeda simple, semi-automated approach for acquiringproduct aspects and domain-specific opinion clues.We showed that a supervised model with linguisticfeatures can effectively assign opinions to the in-dividual product aspects.
Furthermore, we demon-strated that opinion clues and opinionated aspectsimprove prediction of overall review polarity anduser-assigned opinion rating.For future work we intend to evaluate ourmethod on other datasets and domains, varyingin level of language complexity and correctness.Of particular interest are the domains with aspect-focused ratings and reviews (e.g., electronic prod-uct reviews).
Aspect-based opinion summarizationis another direction for future work.21AcknowledgmentsThis work has been supported by the Ministry ofScience, Education and Sports, Republic of Croatiaunder the Grant 036-1300646-1986 and Grant 098-0982560-2566.References?eljko Agic?, Marko Tadic?, and Zdravko Dovedan.2008.
Improving part-of-speech tagging accuracyfor Croatian by morphological analysis.
Informat-ica, 32(4):445?451.
?eljko Agic?, Nikola Ljube?ic?, and Marko Tadic?.
2010.Towards sentiment analysis of financial texts inCroatian.
In Nicoletta Calzolari, editor, Proceed-ings of the Seventh conference on International Lan-guage Resources and Evaluation (LREC?10), Val-letta, Malta.
European Language Resources Associ-ation (ELRA).
?eljko Agic?.
2012.
K-best spanning tree dependencyparsing with verb valency lexicon reranking.
In Pro-ceedings of 24th international Conference on Com-putational Linguistics (COLING 2012): Posters,pages 1?12.Erik Boiy and Marie-Francine Moens.
2009.
Amachine learning approach to sentiment analysisin multilingual web texts.
Information retrieval,12(5):526?558.Aleksander Buczynski and Aleksander Wawer.
2008.Shallow parsing in sentiment analysis of product re-views.
In Proceedings of the Partial Parsing work-shop at LREC, pages 14?18.Ilia Chetviorkin, Pavel Braslavskiy, and NataliaLoukachevich.
2012.
Sentiment analysis track atromip 2011.
Dialog.Yoonjung Choi, Youngho Kim, and Sung-HyonMyaeng.
2009.
Domain-specific sentiment analysisusing contextual feature generation.
In Proceedingsof the 1st international CIKM workshop on Topic-sentiment analysis for mass opinion, pages 37?44.ACM.Angela Fahrni and Manfred Klenner.
2008.
Old wineor warm beer: Target-specific sentiment analysis ofadjectives.
In Proc.
of the Symposium on AffectiveLanguage in Human and Machine, AISB, pages 60?63.Adam Funk, Yaoyong Li, Horacio Saggion, KalinaBontcheva, and Christian Leibold.
2008.
Opin-ion analysis for business intelligence applications.In Proceedings of the first international workshopon Ontology-supported business intelligence, page 3.ACM.Goran Glava?, Jan ?najder, and Bojana Dalbelo Ba?ic?.2012.
Semi-supervised acquisition of Croatian sen-timent lexicon.
In Text, Speech and Dialogue, pages166?173.
Springer.Alec Go, Richa Bhayani, and Lei Huang.
2009.
Twit-ter sentiment classification using distant supervision.CS224N Project Report, Stanford, pages 1?12.Andrew B Goldberg and Xiaojin Zhu.
2006.
See-ing stars when there aren?t many stars: Graph-basedsemi-supervised learning for sentiment categoriza-tion.
In Proceedings of the First Workshop on GraphBased Methods for Natural Language Processing,pages 45?52.
Association for Computational Lin-guistics.Valentin Jijkoun, Maarten de Rijke, and WouterWeerkamp.
2010.
Generating focused topic-specific sentiment lexicons.
In Proceedings of the48th Annual Meeting of the Association for Compu-tational Linguistics, pages 585?594.
Association forComputational Linguistics.Hiroshi Kanayama and Tetsuya Nasukawa.
2006.Fully automatic lexicon expansion for domain-oriented sentiment analysis.
In Proceedings of the2006 Conference on Empirical Methods in NaturalLanguage Processing, EMNLP ?06, pages 355?363,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Colin Kelly, Barry Devereux, and Anna Korhonen.2012.
Semi-supervised learning for automatic con-ceptual property extraction.
In Proceedings of the3rd Workshop on Cognitive Modeling and Com-putational Linguistics, CMCL ?12, pages 11?20,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Nozomi Kobayashi, Kentaro Inui, and Yuji Matsumoto.2007.
Extracting aspect-evaluation and aspect-of re-lations in opinion mining.
In Proceedings of the2007 Joint Conference on Empirical Methods in Nat-ural Language Processing and Computational Nat-ural Language Learning (EMNLP-CoNLL), pages1065?1074.Arjun Mukherjee and Bing Liu.
2012.
Aspect ex-traction through semi-supervised modeling.
In Pro-ceedings of the 50th Annual Meeting of the Associ-ation for Computational Linguistics: Long Papers-Volume 1, pages 339?348.
Association for Computa-tional Linguistics.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
Sentiment classification usingmachine learning techniques.
In Proceedings of theACL-02 conference on Empirical methods in naturallanguage processing-Volume 10, pages 79?86.
Asso-ciation for Computational Linguistics.Ana-Maria Popescu and Oren Etzioni.
2007.
Extract-ing product features and opinions from reviews.
InNatural language processing and text mining, pages9?28.
Springer.22Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.
2009.Expanding domain sentiment lexicon through dou-ble propagation.
In Proceedings of the 21st in-ternational jont conference on Artifical intelligence,pages 1199?1204.Jasmina Smailovic?, Miha Grc?ar, and Martin ?nidar?ic?.2012.
Sentiment analysis on tweets in a financial do-main.
In Proceedings of the 4th Jozef Stefan Inter-national Postgraduate School Students Conference,pages 169?175.Pavel Smr?.
2006.
Using WordNet for opinion mining.In Proceedings of the Third International WordNetConference, pages 333?335.
Masaryk University.Jan ?najder, Bojana Dalbelo Ba?ic?, and Marko Tadic?.2008.
Automatic acquisition of inflectional lexicafor morphological normalisation.
Information Pro-cessing & Management, 44(5):1720?1731.Josef Steinberger, Mohamed Ebrahim, Maud Ehrmann,Ali Hurriyetoglu, Mijail Kabadjov, Polina Lenkova,Ralf Steinberger, Hristo Tanev, Silvia V?zquez, andVanni Zavarella.
2012.
Creating sentiment dictio-naries via triangulation.
Decision Support Systems.Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-berly Voll, and Manfred Stede.
2011.
Lexicon-based methods for sentiment analysis.
Computa-tional linguistics, 37(2):267?307.Peter D Turney.
2002.
Thumbs up or thumbs down?Semantic orientation applied to unsupervised classi-fication of reviews.
In Proceedings of the 40th an-nual meeting on association for computational lin-guistics, pages 417?424.
Association for Computa-tional Linguistics.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2009.
Recognizing contextual polarity: An explo-ration of features for phrase-level sentiment analysis.Computational linguistics, 35(3):399?433.Alexander Yeh.
2000.
More accurate tests for thestatistical significance of result differences.
In Pro-ceedings of the 18th conference on Computationallinguistics-Volume 2, pages 947?953.
Associationfor Computational Linguistics.23
