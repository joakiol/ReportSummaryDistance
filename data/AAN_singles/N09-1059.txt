Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 521?529,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsThe Effect of Corpus Size on Case Frame Acquisitionfor Discourse AnalysisRyohei SasanoGraduate School of Informatics,Kyoto Universitysasano@i.kyoto-u.ac.jpDaisuke KawaharaNational Institute of Informationand Communications Technologydk@nict.go.jpSadao KurohashiGraduate School of Informatics,Kyoto Universitykuro@i.kyoto-u.ac.jpAbstractThis paper reports the effect of corpus size oncase frame acquisition for discourse analysisin Japanese.
For this study, we collected aJapanese corpus consisting of up to 100 bil-lion words, and constructed case frames fromcorpora of six different sizes.
Then, we ap-plied these case frames to syntactic and casestructure analysis, and zero anaphora resolu-tion.
We obtained better results by using caseframes constructed from larger corpora; theperformance was not saturated even with acorpus size of 100 billion words.1 IntroductionVery large corpora obtained from the Web havebeen successfully utilized for many natural lan-guage processing (NLP) applications, such as prepo-sitional phrase (PP) attachment, other-anaphora res-olution, spelling correction, confusable word set dis-ambiguation and machine translation (Volk, 2001;Modjeska et al, 2003; Lapata and Keller, 2005; At-terer and Schu?tze, 2006; Brants et al, 2007).Most of the previous work utilized only the sur-face information of the corpora, such as n-grams,co-occurrence counts, and simple surface syntax.This may be because these studies did not requirestructured knowledge, and for such studies, the sizeof currently available corpora is considered to havebeen almost enough.
For instance, while Brants etal.
(2007) reported that translation quality continuedto improve with increasing corpus size for traininglanguage models at even size of 2 trillion tokens, theincrease became small at the corpus size of largerthan 30 billion tokens.However, for more complex NLP tasks, such ascase structure analysis and zero anaphora resolution,it is necessary to obtain more structured knowledge,such as semantic case frames, which describe thecases each predicate has and the types of nouns thatcan fill a case slot.
Note that case frames offer notonly the knowledge of the relationships between apredicate and its particular case slot, but also theknowledge of the relationships among a predicateand its multiple case slots.
To obtain such knowl-edge, very large corpora seem to be necessary; how-ever it is still unknown how much corpora would berequired to obtain good coverage.For examples, Kawahara and Kurohashi pro-posed a method for constructing wide-coverage caseframes from large corpora (Kawahara and Kuro-hashi, 2006b), and a model for syntactic and casestructure analysis of Japanese that based upon caseframes (Kawahara and Kurohashi, 2006a).
How-ever, they did not demonstrate whether the coverageof case frames was wide enough for these tasks andhow dependent the performance of the model was onthe corpus size for case frame construction.This paper aims to address these questions.
Wecollect a very large Japanese corpus consisting ofabout 100 billion words, or 1.6 billion unique sen-tences from the Web.
Subsets of the corpus are ran-domly selected to obtain corpora of different sizesranging from 1.6 million to 1.6 billion sentences.We construct case frames from each corpus and ap-ply them to syntactic and case structure analysis, andzero anaphora resolution, in order to investigate the521relationships between the corpus size and the perfor-mance of these analyses.2 Related WorkMany NLP tasks have successfully utilized verylarge corpora, most of which were acquired fromthe Web (Kilgarriff and Grefenstette, 2003).
Volk(2001) proposed a method for resolving PP attach-ment ambiguities based upon Web data.
Modjeskaet al (2003) used the Web for resolving nominalanaphora.
Lapata and Keller (2005) investigated theperformance of web-based models for a wide rangeof NLP tasks, such as MT candidate selection, ar-ticle generation, and countability detection.
Nakovand Hearst (2008) solved relational similarity prob-lems using the Web as a corpus.With respect to the effect of corpus size on NLPtasks, Banko and Brill (2001a) showed that forcontent sensitive spelling correction, increasing thetraining data size improved the accuracy.
Attererand Schu?tze (2006) investigated the effect of cor-pus size in combining supervised and unsupervisedlearning for two types of attachment decision; theyfound that the combined system only improved theperformance of the parser for small training sets.Brants et al (2007) varied the amount of languagemodel training data from 13 million to 2 trillion to-kens and applied these models to machine transla-tion systems.
They reported that translation qual-ity continued to improve with increasing corpus sizefor training language models at even size of 2 tril-lion tokens.
Suzuki and Isozaki (2008) provided ev-idence that the use of more unlabeled data in semi-supervised learning could improve the performanceof NLP tasks, such as POS tagging, syntactic chunk-ing, and named entities recognition.There are several methods to extract useful infor-mation from very large corpora.
Search engines,such as Google and Altavista, are often used to ob-tain Web counts (e.g.
(Nakov and Hearst, 2005;Gledson and Keane, 2008)).
However, search en-gines are not designed for NLP research and the re-ported hit counts are subject to uncontrolled vari-ations and approximations.
Therefore, several re-searchers have collected corpora from the Web bythemselves.
For English, Banko and Brill (2001b)collected a corpus with 1 billion words from vari-ety of English texts.
Liu and Curran (2006) createda Web corpus for English that contained 10 billionwords and showed that for content-sensitive spellingcorrection the Web corpus results were better thanusing a search engine.
Halacsy et al (2004) createda corpus with 1 billion words for Hungarian fromthe Web by downloading 18 million pages.
Othersutilize publicly available corpus such as the NorthAmerican News Corpus (NANC) and the GigawordCorpus (Graff, 2003).
For instance, McClosky et al(2006) proposed a simple method of self-training atwo phase parser-reranker system using NANC.As for Japanese, Kawahara and Kurohashi(2006b) collected 23 million pages and created acorpus with approximately 20 billion words.
Googlereleased Japanese n-gram constructed from 20 bil-lion Japanese sentences (Kudo and Kazawa, 2007).Several news wires are publicly available consistingof tens of million sentences.
Kotonoha project isnow constructing a balanced corpus of the present-day written Japanese consisting of 50 million words(Maekawa, 2006).3 Construction of Case FramesCase frames describe the cases each predicate hasand what nouns can fill the case slots.
In this study,case frames we construct case frames from raw cor-pora by using the method described in (Kawaharaand Kurohashi, 2006b).
This section illustrates themethodology for constructing case frames.3.1 Basic MethodAfter parsing a large corpus by a Japanese parserKNP1, we construct case frames from modifier-headexamples in the resulting parses.
The problems forcase frame construction are syntactic and semanticambiguities.
In other words, the resulting parses in-evitably contain errors and predicate senses are in-trinsically ambiguous.
To cope with these problems,we construct case frames from reliable modifier-head examples.First, we extract modifier-head examples that hadno syntactic ambiguity, and assemble them by cou-pling a predicate and its closest case component.That is, we assemble the examples not by predi-cates, such as tsumu (load/accumulate), but by cou-1http://nlp.kuee.kyoto-u.ac.jp/nl-resource/knp-e.html522Table 1: Examples of Constructed Case Frames.Case slot Examples Generalized examples with ratega (nominative) he, driver, friend, ?
?
?
[CT:PERSON]:0.45, [NE:PERSON]:0.08, ?
?
?tsumu (1) wo (accusative) baggage, luggage, hay, ?
?
?
[CT:ARTIFACT]:0.31, ?
?
?
(load) ni (dative) car, truck, vessel, seat, ?
?
?
[CT:VEHICLE]:0.32, ?
?
?tsumu (2) ga (nominative) player, children, party, ?
?
?
[CT:PERSON]:0.40, [NE:PERSON]:0.12, ?
?
?
(accumulate) wo (accusative) experience, knowledge, ?
?
?
[CT:ABSTRACT]:0.47, ?
?
?...
... ...ga (nominative) company, Microsoft, firm, ?
?
?
[NE:ORGANIZATION]:0.16, [CT:ORGANIZATION]:0.13, ?
?
?hanbai (1) wo (accusative) goods, product, ticket, ?
?
?
[CT:ARTIFACT]:0.40, [CT:FOOD]:0.07, ?
?
?
(sell) ni (dative) customer, company, user, ?
?
?
[CT:PERSON]:0.28, ?
?
?de (locative) shop, bookstore, site ?
?
?
[CT:FACILITY]:0.40, [CT:LOCATION]:0.39, ?
?
?...
... ...ples, such as nimotsu-wo tsumu (load baggage) andkeiken-wo tsumu (accumulate experience).
Suchcouples are considered to play an important rolefor constituting sentence meanings.
We call the as-sembled examples as basic case frames.
In orderto remove inappropriate examples, we introduce athreshold ?
and use only examples that appeared noless than ?
times in the corpora.Then, we cluster the basic case frames to mergesimilar case frames.
For example, since nimotsu-wo tsumu (load baggage) and busshi-wo tsumu (loadsupplies) are similar, they are merged.
The similar-ity is measured by using a Japanese thesaurus (TheNational Language Institute for Japanese Language,2004).
Table 1 shows examples of constructed caseframes.3.2 Generalization of ExamplesWhen we use hand-crafted case frames, the datasparseness problem is serious; by using case framesautomatically constructed from a large corpus, it wasalleviated to some extent but not eliminated.
For in-stance, there are thousands of named entities (NEs)that cannot be covered intrinsically.
To deal withthis problem, we generalize the examples of the caseslots.
Kawahara and Kurohashi also generalized ex-amples but only for a few types.
In this study, wegeneralize case slot examples based upon commonnoun categories and NE classes.First, we generalize the examples based upon thecategories that tagged by the Japanese morpholog-ical analyzer JUMAN2.
In JUMAN, about 20 cat-egories are defined and tagged to common nouns.For example, ringo (apple), inu (dog) and byoin2http://nlp.kuee.kyoto-u.ac.jp/nl-resource/juman-e.htmlTable 2: Definition of NE in IREX.NE class ExamplesORGANIZATION NHK Symphony OrchestraPERSON Kawasaki KenjiroLOCATION Rome, SinuijuARTIFACT Nobel PrizeDATE July 17, April this yearTIME twelve o?clock noonMONEY sixty thousand dollarsPERCENT 20%, thirty percents(hospital) are tagged as FOOD, ANIMAL and FA-CILITY, respectively.
For each category, we calcu-late the ratio of the categorized example among allcase slot examples, and add it to the case slot (e.g.
[CT:FOOD]:0.07).We also generalize the examples based upon NEclasses.
We use a common standard NE defini-tion for Japanese provided by the IREX (1999).We first recognize NEs in the source corpus byusing an NE recognizer (Sasano and Kurohashi,2008); and then construct case frames from the NE-recognized corpus.
Similar to the categories, foreach NE class, we calculate the NE ratio among allthe case slot examples, and add it to the case slot(e.g.
[NE:PERSON]:0.12).
The generalized exam-ples are also included in Table 1.4 Discourse Analysis with Case FramesIn order to investigate the effect of corpus sizeon complex NLP tasks, we apply the constructedcases frames to an integrated probabilistic modelfor Japanese syntactic and case structure analysis(Kawahara and Kurohashi, 2006a) and a probabilis-tic model for Japanese zero anaphora resolution(Sasano et al, 2008).
In this section, we briefly de-scribe these models.5234.1 Model for Syntactic and Case StructureAnalysisKawahara and Kurohashi (2006a) proposed an in-tegrated probabilistic model for Japanese syntacticand case structure analysis based upon case frames.Case structure analysis recognizes predicate argu-ment structures.
Their model gives a probability toeach possible syntactic structure T and case struc-ture L of the input sentence S, and outputs the syn-tactic and case structure that have the highest proba-bility.
That is to say, the system selects the syntacticstructure Tbest and the case structure Lbest that max-imize the probability P (T,L|S):(Tbest, Lbest) = argmax(T,L)P (T,L|S)= argmax(T,L)P (T,L, S) (1)The last equation is derived because P (S) is con-stant.
P (T,L, S) is defined as the product of a prob-ability for generating a clause Ci as follows:P (T,L, S) = ?i=1..nP (Ci|bhi) (2)where n is the number of clauses in S, and bhi isCi?s modifying bunsetsu3.
P (Ci|bhi) is approxi-mately decomposed into the product of several gen-erative probabilities such as P (A(sj) = 1|CFl, sj)and P (nj |CFl, sj , A(sj) = 1), where the functionA(sj) returns 1 if a case slot sj is filled with an inputcase component; otherwise 0.
P (A(sj)=1|CFl, sj)denotes the probability that the case slot sj is filledwith an input case component, and is estimated fromresultant case structure analysis of a large raw cor-pus.
P (nj |CFl, sj , A(sj) = 1) denotes the proba-bility of generating a content part nj from a filledcase slot sj in a case frame CFl, and is calculatedby using case frames.
For details see (Kawahara andKurohashi, 2006a).4.2 Model for Zero Anaphora ResolutionAnaphora resolution is one of the most importanttechniques for discourse analysis.
In English, overtpronouns such as she and definite noun phrases suchas the company are anaphors that refer to preced-ing entities (antecedents).
On the other hand, in3In Japanese, bunsetsu is a basic unit of dependency, con-sisting of one or more content words and the following zero ormore function words.
It corresponds to a base phrase in English.Japanese, anaphors are often omitted; these omis-sions are called zero pronouns.
Zero anaphora res-olution is the integrated task of zero pronoun detec-tion and zero pronoun resolution.We proposed a probabilistic model for Japanesezero anaphora resolution based upon case frames(Sasano et al, 2008).
This model first resolvescoreference and identifies discourse entities; thengives a probability to each possible case frame CFand case assignment CA when target predicate v,input case components ICC and existing discourseentities ENT are given, and outputs the case frameand case assignment that have the highest probabil-ity.
That is to say, this model selects the case frameCFbest and the case assignment CAbest that maxi-mize the probability P (CF,CA|v, ICC,ENT ):(CF best, CAbest)= argmax(CF,CA)P (CF,CA|v, ICC,ENT ) (3)P (CF,CA|v, ICC,ENT ) is approximately de-composed into the product of several probabilities.Case frames are used for calculating P (nj |CFl,sj , A(sj) = 1), the probability of generating a con-tent part nj from a case slot sj in a case frameCFl, and P (nj |CFl, sj , A?
(sj)=1), the probabilityof generating a content part nj of a zero pronoun,where the function A?
(sj) returns 1 if a case slot sjis filled with an antecedent of a zero pronoun; other-wise 0.P (nj |CFl, sj , A?
(sj)=1) is similar to P (nj |CFl,sj , A(sj)=1) and estimated from the frequencies ofcase slot examples in case frames.
However, whileA?
(sj)=1 means sj is not filled with an overt argu-ment but filled with an antecedent of zero pronoun,case frames are constructed from overt predicate ar-gument pairs.
Therefore, the content part nj is oftennot included in the case slot examples.
To cope withthis problem, this model also utilizes generalized ex-amples to estimate P (nj |CFl, sj , A(sj) = 1).
Fordetails see (Sasano et al, 2008).5 Experiments5.1 Construction of Case FramesIn order to investigate the effect of corpus size,we constructed case frames from corpora of dif-ferent sizes.
We first collected Japanese sentences524Table 4: Statistics of the Constructed Case Frames.Corpus size (sentences) 1.6M 6.3M 25M 100M 400M 1.6G# of predicate 2460 6134 13532 27226 42739 65679(type) verb 2039 4895 10183 19191 28523 41732adjective 154 326 617 1120 1641 2318noun with copula 267 913 2732 6915 12575 21629average # of case frames for a predicate 15.9 12.2 13.3 16.1 20.5 25.3average # of case slots for a case frame 2.95 3.44 3.88 4.21 4.69 5.08average # of examples for a case slot 4.89 10.2 19.5 34.0 67.2 137.6average # of unique examples for a case slot 1.19 1.85 3.06 4.42 6.81 9.64average # of generalized examples for a case slot 0.14 0.24 0.37 0.49 0.67 0.84File size(byte) 8.9M 20M 56M 147M 369M 928MTable 3: Corpus Sizes and Thresholds.Corpus size for caseframe construction 1.6M 6.3M 25M 100M 400M 1.6G(sentences)Threshold ?introduced in Sec.
3.1 2 3 4 5 7 10Corpus size toestimate generative 1.6M 3.2M 6.3M 13M 25M 50Mprobability (sentences)from the Web using the method proposed by Kawa-hara and Kurohashi (2006b).
We acquired approx-imately 6 billion Japanese sentences consisting ofapproximately 100 billion words from 100 millionJapanese web pages.
After discarding duplicate sen-tences, which may have been extracted from mirrorsites, we acquired a corpus comprising of 1.6 bil-lion (1.6G) unique Japanese sentences consisting ofapproximately 25 billion words.
The average num-ber of characters and words in each sentence was28.3, 15.6, respectively.
Then we randomly selectedsubsets of the corpus for five different sizes; 1.6M,6.3M, 25M, 100M, and 400M sentences to obtaincorpora of different sizes.We constructed case frames from each corpus.
Weemployed JUMAN and KNP to parse each corpus.We changed the threshold ?
introduced in Section3.1 depending upon the size of the corpus as shownin Table 3.
Completing the case frame construc-tion took about two weeks using 600 CPUs.
Ta-ble 4 shows the statistics for the constructed caseframes.
The number of predicates, the average num-ber of examples and unique examples for a case slot,and whole file size were confirmed to be heavily de-pendent upon the corpus size.
However, the averagenumber of case frames for a predicate and case slotsfor a case frame did not.5.2 Coverage of Constructed Case Frames5.2.1 SettingIn order to investigate the coverage of the resul-tant case frames, we used a syntactic relation, casestructure, and anaphoric relation annotated corpusconsisting of 186 web documents (979 sentences).This corpus was manually annotated using the samecriteria as Kawahara et al (2004).
There were 2,390annotated relationships between predicates and theirdirect (not omitted) case components and 837 zeroanaphoric relations in the corpus.We used two evaluation metrics depending uponwhether the target case component was omitted ornot.
For the overt case component of a predicate, wejudged the target component was covered by caseframes if the target component itself was included inthe examples for one of the corresponding case slotsof the case frame.
For the omitted case component,we checked not only the target component itself butalso all mentions that refer to the same entity as thetarget component.5.2.2 Coverage of Case FramesFigure 1 shows the coverage of case frames forthe overt argument, which would have tight relationswith case structure analysis.
The lower line showsthe coverage without considering generalized exam-ples, the middle line shows the coverage consideringgeneralized NE examples, and the upper line showsthe coverage considering all generalized examples.Figure 2 shows the coverage of case frames forthe omitted argument, which would have tight rela-tions with zero anaphora resolution.
The upper lineshows the coverage considering all generalized ex-amples, which is considered to be the upper boundof performance for the zero anaphora resolution sys-5250.00.20.40.60.81.01M 10M 100M 1000MCoverageCorpus Size (Number of Sentences)0.8970.6830.649+NE,CT match+ NE matchexact matchFigure 1: Coverage of CF (overt argument).0.00.20.40.60.81.01M 10M 100M 1000MCoverageCorpus Size (Number of Sentences)0.8920.6080.472+NE,CT match+ NE matchexact matchFigure 2: Coverage of CF (omitted argument).tem described in Section 4.2.
Comparing with Fig-ure 1, we found two characteristics.
First, the lowerand middle lines of Figure 2 were located lower thanthe corresponding lines in Figure 1.
This would re-flect that some frequently omitted case componentsare not described in the case frames because the caseframes were constructed from only overt predicateargument pairs.
Secondly, the effect of generalizedNE examples was more evident for the omitted ar-gument reflecting the important role of NEs in zeroanaphora resolution.Both figures show that the coverage was improvedby using larger corpora and there was no saturationeven when the largest corpus of 1.6 billion sentenceswas used.
When the largest corpus and all general-ized examples were used, the case frames achieved acoverage of almost 90% for both the overt and omit-ted argument.Figure 3 shows the coverage of case frames foreach predicate type, which was calculated for bothovert and omitted argument considering all general-ized examples.
The case frames for verbs achieveda coverage of 93.0%.
There were 189 predicate-argument pairs that were not included case frames;0.00.20.40.60.81.01M 10M 100M 1000MCoverageCorpus Size (Number of Sentences)verbadjectivenoun with copula0.9300.7880.545Figure 3: Coverage of CF for Each Predicate Type.11 pairs of them were due to lack of the case frameof target predicate itself, and the others were dueto lack of the corresponding example.
For adjec-tive, the coverage was 78.8%.
The main cause ofthe lower coverage would be that the predicate argu-ment relations concerning adjectives that were usedin restrictive manner, such as ?oishii sushi?
(deli-cious sushi), were not used for case frame construc-tion, although such relations were also the target ofthe coverage evaluation.
For noun with copula, thecoverage was only 54.5%.
However, most predicateargument relations concerning nouns with copulawere easily recognized from syntactic preference,and thus the low coverage would not quite affect theperformance of discourse analysis.5.3 Syntactic and Case Structure Analysis5.3.1 Accuracy of Syntactic AnalysisWe investigated the effect of corpus size for syn-tactic analysis described in Section 4.1.
We usedhand-annotated 759 web sentences, which was usedby Kawahara and Kurohashi (2007).
We evaluatedthe resultant syntactic structures with regard to de-pendency accuracy, the proportion of correct depen-dencies out of all dependencies4.Figure 4 shows the accuracy of syntactic struc-tures.
We conducted these experiments with caseframes constructed from corpora of different sizes.We also changed the corpus size to estimate gen-erative probability of a case slot in Section 4.1 de-pending upon the size of the corpus for case frameconstruction as shown in Table 3.
Figure 4 also in-4Note that Kawahara and Kurohashi (2007) exclude the de-pendency between the last two bunsetsu, since Japanese is head-final and thus the second last bunsetsu unambiguously dependson the last bunsetsu.5260.8860.8880.8900.8920.8940.8961M 10M 100M 1000MAccuracyCorpus Size (Number of Sentences)0.8941.6Gp < 0.1100M25Mp < 0.016.3M1.6M400Mp < 0.125Mp < 0.016.3M1.6M100Mp < 0.16.3M1.6M25Mp < 0.16.3M1.6M6.3M1.6Mwith case framesw/o case framesFigure 4: Accuracy of Syntactic Analysis.
(McNemar?stest results are also shown under each data point.
)cludes McNemar?s test results.
For instance, the dif-ference between the corpus size of 1.6G and 100Msentences is significant at the 90% level (p = 0.1),but not significant at the 99% level (p = 0.01).In Figure 4, ?w/o case frames?
shows the accu-racy of the rule-based syntactic parser KNP that doesnot use case frames.
Since the model describedin Section 4.1 assumes the existence of reasonablecase frames, when we used case frames constructedfrom very small corpus, such as 1.6M and 6.3M sen-tences, the accuracy was lower than that of the rule-based syntactic parser.
Moreover, when we testedthe model described in Section 4.1 without any caseframes, the accuracy was 0.885.We confirmed that better performance was ob-tained by using case frames constructed from largercorpora, and the accuracy of 0.8945 was achievedby using the case frames constructed from 1.6G sen-tences.
However the effect of the corpus size waslimited.
This is because there are various causesof dependency error and the case frame sparsenessproblem is not serious for syntactic analysis.We considered that generalized examples canbenefit for the accuracy of syntactic analysis, andtried several models that utilize these examples.However, we cannot confirm any improvement.5.3.2 Accuracy of Case Structure AnalysisWe conducted case structure analysis on 215 websentences in order to investigate the effect of cor-pus size for case structure analysis.
The case mark-ers of topic marking phrases and clausal modifiers5It corresponds to 0.877 in Kawahara and Kurohashi?s(2007) evaluation metrics.0.4000.5000.6000.7000.8000.9001M 10M 100M 1000MAccuracyCorpus Size (Number of Sentences)0.784Figure 5: Accuracy of Case Structure Analysis.Table 5: Corpus Sizes for Case Frame Construction andTime for Syntactic and Case Structure Analysis.Corpus size 1.6M 6.3M 25M 100M 400M 1.6GTime (sec.)
850 1244 1833 2696 3783 5553were evaluated by comparing them with the goldstandard in the corpus.
Figure 5 shows the experi-mental results.
We confirmed that the accuracy ofcase structure analysis strongly depends on corpussize for case frame construction.5.3.3 Analysis SpeedTable 5 shows the time for analyzing syntacticand case structure of 759 web sentences.
Althoughthe time for analysis became longer by using caseframes constructed from a larger corpus, the growthrate was smaller than the growth rate of the size forcase frames described in Table 4.Since there is enough increase in accuracy of casestructure analysis, we can say that case frames con-structed larger corpora are desirable for case struc-ture analysis.5.4 Zero Anaphora Resolution5.4.1 Accuracy of Zero Anaphora ResolutionWe used an anaphoric relation annotated corpusconsisting of 186 web documents (979 sentences)to evaluate zero anaphora resolution.
We used first51 documents for test and used the other 135 doc-uments for calculating several probabilities.
In the51 test documents, 233 zero anaphora relations wereannotated between one of the mentions of the an-tecedent and corresponding predicate that had zeropronoun.In order to concentrate on evaluation for zeroanaphora resolution, we used the correct mor-5270.000.100.200.300.400.501M 10M 100M 1000MF-measureCorpus Size (Number of Sentences)0.4170.3300.313+NE,CT match+ NE matchexact matchFigure 6: F-measure of Zero Anaphora Resolution.phemes, named entities, syntactic structures andcoreference relations that were manually annotated.Since correct coreference relations were given, thenumber of created entities was the same between thegold standard and the system output because zeroanaphora resolution did not create new entities.The experimental results are shown in Figure 6, inwhich F-measure was calculated by:R = # of correctly recognized zero anaphora# of zero anaphora annotated in corpus ,P = # of correctly recognized zero anaphora# of system outputted zero anaphora ,F = 21/R + 1/P .The upper line shows the performance using allgeneralized examples, the middle line shows theperformance using only generalized NEs, and thelower line shows the performance without usingany generalized examples.
While generalized cat-egories much improved the F-measure, generalizedNEs contributed little.
This tendency is similar tothat of coverage of case frames for omitted argumentshown in Figure 2.
Unlike syntactic and case struc-ture analysis, the performance for the zero anaphoraresolution is quite low when using case frames con-structed from small corpora, and we can say caseframes constructed from larger corpora are essentialfor zero anaphora resolution.5.4.2 Analysis SpeedTable 6 shows the time for resolving zeroanaphora in 51 web documents consisting of 278sentences.
The time for analysis became longer byusing case frames constructed from larger corpora,Table 6: Corpus Sizes for Case Frame Construction andTime for Zero Anaphora Resolution.Corpus size 1.6M 6.3M 25M 100M 400M 1.6GTime (sec.)
538 545 835 1040 1646 2219which tendency is similar to the growth of the timefor analyzing syntactic and case structure.5.5 DiscussionExperimental results of both case structure analy-sis and zero anaphora resolution show the effective-ness of a larger corpus in case frame acquisition forJapanese discourse analysis.
Up to the corpus sizeof 1.6 billion sentences, or 100 billion words, theseexperimental results still show a steady increase inperformance.
That is, we can say that the corpussize of 1.6 billion sentences is not enough to obtaincase frames of sufficient coverage.These results suggest that increasing corpus sizeis more essential for acquiring structured knowledgethan for acquiring unstructured statistics of a corpus,such as n-grams, and co-occurrence counts; and forcomplex NLP tasks such as case structure analysisand zero anaphora resolution, the currently availablecorpus size is not sufficient.Therefore, to construct more wide-coverage caseframes by using a larger corpus and reveal howmuchcorpora would be required to obtain sufficient cov-erage is considered as future work.6 ConclusionThis paper has reported the effect of corpus sizeon case frame acquisition for syntactic and casestructure analysis, and zero anaphora resolution inJapanese.
We constructed case frames from cor-pora of six different sizes ranging from 1.6 millionto 1.6 billion sentences; and then applied these caseframes to Japanese syntactic and case structure anal-ysis, and zero anaphora resolution.
Experimental re-sults showed better results were obtained using caseframes constructed from larger corpora, and the per-formance showed no saturation even when the cor-pus size was 1.6 billion sentences.The findings suggest that increasing corpus sizeis more essential for acquiring structured knowledgethan for acquiring surface statistics of a corpus; andfor complex NLP tasks the currently available cor-pus size is not sufficient.528ReferencesMichaela Atterer and Hinrich Schu?tze.
2006.
The ef-fect of corpus size in combining supervised and un-supervised training for disambiguation.
In Proc.
ofCOLING-ACL?06, pages 25?32.Michele Banko and Eric Brill.
2001a.
Mitigating thepaucity-of-data problem: Exploring the effect of train-ing corpus size on classifier performance for naturallanguage processing.
In Proc.
of HLT?01.Michele Banko and Eric Brill.
2001b.
Scaling to veryvery large corpora for natural language disambigua-tion.
In Proc.
of ACL?01, pages 26?33.Thorsten Brants, Ashok C. Popat, Peng Xu, Franz J. Och,and Jeffrey Dean.
2007.
Large language models inmachine translation.
In Proc.
of EMNLP-CoNLL?07,pages 858?867.Ann Gledson and John Keane.
2008.
Using web-searchresults to measure word-group similarity.
In Proc.
ofCOLING?08, pages 281?288.David Graff.
2003.
English Gigaword.
Technical ReportLDC2003T05, Linguistic Data Consortium, Philadel-phia, PA USA.Peter Halacsy, Andras Kornai, Laszlo Nemeth, AndrasRung, Istvan Szakadat, and Vikto Tron.
2004.
Creat-ing open language resources for Hungarian.
In Proc.of LREC?04, pages 203?210.IREX Committee, editor.
1999.
Proc.
of the IREX Work-shop.Daisuke Kawahara and Sadao Kurohashi.
2006a.
Afully-lexicalized probabilistic model for Japanese syn-tactic and case structure analysis.
In Proc.
of HLT-NAACL?06, pages 176?183.Daisuke Kawahara and Sadao Kurohashi.
2006b.Case frame compilation from the web using high-performance computing.
In Proc.
of LREC?06, pages1344?1347.Daisuke Kawahara and Sadao Kurohashi.
2007.Probabilistic coordination disambiguation in a fully-lexicalized Japanese parser.
In Proc.
of EMNLP-CoNLL?07, pages 306?314.Daisuke Kawahara, Ryohei Sasano, and Sadao Kuro-hashi.
2004.
Toward text understanding: Integrat-ing relevance-tagged corpora and automatically con-structed case frames.
In Proc.
of LREC?04, pages1833?1836.Adam Kilgarriff and Gregory Grefenstette.
2003.
In-troduction to the special issue on the web as corpus.Computational Linguistic, 29(3):333?347.Taku Kudo and Hideto Kazawa.
2007.
Web Japanese N-gram version 1, published by Gengo Shigen Kyokai.Mirella Lapata and Frank Keller.
2005.
Web-based mod-els for natural language processing.
ACM Transac-tions on Speech and Language Processing, 2:1:1?31.Vinci Liu and James R. Curran.
2006.
Web text corpusfor natural language processing.
In Proc.
of EACL?06,pages 233?240.Kikuo Maekawa.
2006.
Kotonoha, the corpus develop-ment project of the National Institute for Japanese lan-guage.
In Proc.
of the 13th NIJL International Sympo-sium, pages 55?62.David McClosky, Eugene Charniak, and Mark Johnson.2006.
Effective self-training for parsing.
In Proc.
ofHLT-NAACL?06, pages 152?159.Natalia N. Modjeska, Katja Markert, and Malvina Nis-sim.
2003.
Using the web in machine learning forother-anaphora resolution.
In Proc.
of EMNLP-2003,pages 176?183.Preslav Nakov and Marti Hearst.
2005.
A study of usingsearch engine page hits as a proxy for n-gram frequen-cies.
In Proc.
of RANLP?05.Preslav Nakov and Marti A. Hearst.
2008.
Solving rela-tional similarity problems using the web as a corpus.In Proc.
of ACL-HLT?08, pages 452?460.Ryohei Sasano and Sadao Kurohashi.
2008.
Japanesenamed entity recognition using structural natural lan-guage processing.
In Proc.
of IJCNLP?08, pages 607?612.Ryohei Sasano, Daisuke Kawahara, and Sadao Kuro-hashi.
2008.
A fully-lexicalized probabilistic modelfor japanese zero anaphora resolution.
In Proc.
ofCOLING?08, pages 769?776.Jun Suzuki and Hideki Isozaki.
2008.
Semi-supervisedsequential labeling and segmentation using giga-wordscale unlabeled data.
In Proceedings of ACL-HLT?08,pages 665?673.The National Language Institute for Japanese Language.2004.
Bunruigoihyo.
Dainippon Tosho, (In Japanese).Martin Volk.
2001.
Exploiting the WWW as a corpusto resolve PP attachment ambiguities.
In Proc.
of theCorpus Linguistics, pages 601?606.529
