2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 477?487,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsCross-lingual Word Clusters for Direct Transfer of Linguistic StructureOscar Ta?ckstro?m?SICS / Uppsala UniversityKista / Uppsala, Swedenoscar@sics.seRyan McDonaldGoogleNew York, NYryanmcd@google.comJakob UszkoreitGoogleMountain View, CAuszkoreit@google.comAbstractIt has been established that incorporating wordcluster features derived from large unlabeledcorpora can significantly improve prediction oflinguistic structure.
While previous work hasfocused primarily on English, we extend theseresults to other languages along two dimen-sions.
First, we show that these results holdtrue for a number of languages across families.Second, and more interestingly, we provide analgorithm for inducing cross-lingual clustersand we show that features derived from theseclusters significantly improve the accuracy ofcross-lingual structure prediction.
Specifically,we show that by augmenting direct-transfer sys-tems with cross-lingual cluster features, the rel-ative error of delexicalized dependency parsers,trained on English treebanks and transferredto foreign languages, can be reduced by up to13%.
When applying the same method to di-rect transfer of named-entity recognizers, weobserve relative improvements of up to 26%.1 IntroductionThe ability to predict the linguistic structure of sen-tences or documents is central to the field of nat-ural language processing (NLP).
Structures such asnamed-entity tag sequences (Bikel et al, 1999) or sen-timent relations (Pang and Lee, 2008) are inherentlyuseful in data mining, information retrieval and otheruser-facing technologies.
More fundamental struc-tures such as part-of-speech tag sequences (Ratna-parkhi, 1996) or syntactic parse trees (Collins, 1997;Ku?bler et al, 2009), on the other hand, comprise thecore linguistic analysis for many important down-stream tasks such as machine translation (Chiang,?The majority of this work was performed while the authorwas an intern at Google, New York, NY.2005; Collins et al, 2005).
Currently, superviseddata-driven methods dominate the literature on lin-guistic structure prediction (Smith, 2011).
Regret-tably, the majority of studies on these methods havefocused on evaluations specific to English, since it isthe language with the most annotated resources.
No-table exceptions include the CoNLL shared tasks(Tjong Kim Sang, 2002; Tjong Kim Sang andDe Meulder, 2003; Buchholz and Marsi, 2006; Nivreet al, 2007) and subsequent studies on this data, aswell as a number of focused studies on one or twospecific languages, as discussed by Bender (2011).While annotated resources for parsing and severalother tasks are available in a number of languages, wecannot expect to have access to labeled resources forall tasks in all languages.
This fact has given rise toa large body of research on unsupervised (Klein andManning, 2004), semi-supervised (Koo et al, 2008)and transfer (Hwa et al, 2005) systems for predictionof linguistic structure.
These methods all attempt tobenefit from the plethora of unlabeled monolingualand/or cross-lingual data that has become availablein the digital age.
Unsupervised methods are ap-pealing in that they are often inherently languageindependent.
This is borne out by the many recentstudies on unsupervised parsing that include evalu-ations covering a number of languages (Cohen andSmith, 2009; Gillenwater et al, 2010; Naseem et al,2010; Spitkovsky et al, 2011).
However, the perfor-mance for most languages is still well below that ofsupervised systems and recent work has establishedthat the performance is also below simple methodsof linguistic transfer (McDonald et al, 2011).In this study we focus on semi-supervised andlinguistic-transfer methods for multilingual structureprediction.
In particular, we pursue two lines of re-search around the use of word cluster features indiscriminative models for structure prediction:4771.
Monolingual word cluster features induced fromlarge corpora of text for semi-supervised learn-ing (SSL) of linguistic structure.
Previous stud-ies on this approach have typically focused onlyon a small set of languages and tasks (Freitag,2004; Miller et al, 2004; Koo et al, 2008;Turian et al, 2010; Faruqui and Pado?, 2010; Haf-fari et al, 2011; Tratz and Hovy, 2011).
Herewe show that this method is robust across 13 lan-guages for dependency parsing and 4 languagesfor named-entity recognition (NER).
This is thefirst study with such a broad view on this subject,in terms of language diversity.2.
Cross-lingual word cluster features for transfer-ring linguistic structure from English to otherlanguages.
We develop an algorithm that gener-ates cross-lingual word clusters; that is clustersof words that are consistent across languages.This is achieved by means of a probabilisticmodel over large amounts of monolingual datain two languages, coupled with parallel datathrough which cross-lingual word-cluster con-straints are enforced.
We show that by augment-ing the delexicalized direct transfer system ofMcDonald et al (2011) with cross-lingual clus-ter features, we are able to reduce its error byup to 13% relative.
Further, we show that by ap-plying the same method to direct-transfer NER,we achieve a relative error reduction of 26%.By incorporating cross-lingual cluster features in alinguistic transfer system, we are for the first timecombining SSL and cross-lingual transfer.2 Monolingual Word Cluster FeaturesWord cluster features have been shown to be use-ful in various tasks in natural language processing,including syntactic dependency parsing (Koo et al,2008; Haffari et al, 2011; Tratz and Hovy, 2011),syntactic chunking (Turian et al, 2010), and NER(Freitag, 2004; Miller et al, 2004; Turian et al, 2010;Faruqui and Pado?, 2010).
Intuitively, the reason forthe effectiveness of cluster features lie in their abil-ity to aggregate local distributional information fromlarge unlabeled corpora, which aid in conquering datasparsity in supervised training regimes as well as inmitigating cross-domain generalization issues.In line with much previous work on word clustersfor tasks such as dependency parsing and NER, forwhich local syntactic and semantic constraints areof importance, we induce word clusters by means ofa probabilistic class-based language model (Brownet al, 1992; Clark, 2003).
However, rather than themore commonly used model of Brown et al (1992),we use the predictive class bigram model introducedby Uszkoreit and Brants (2008).
The two modelsare very similar, but whereas the former takes class-to-class transitions into account, the latter directlymodels word-to-class transitions.
By ignoring class-to-class transitions, an approximate maximum likeli-hood clustering can be found efficiently with the dis-tributed exchange algorithm (Uszkoreit and Brants,2008).
This is a useful property, as we later developan algorithm for inducing cross-lingual word clustersthat calls this monolingual algorithm as a subroutine.More formally, let C : V 7?
1, .
.
.
,K be a (hard)clustering function that maps each word type from thevocabulary, V , to one ofK cluster identities.
With themodel of Uszkoreit and Brants (2008), the likelihoodof a sequence of word tokens, w = ?wi?mi=1, withwi ?
V ?
{S}, where S is a designated start-of-segment symbol, factors asL(w; C) =m?i=1p(wi|C(wi))p(C(wi)|wi?1) .
(1)Compare this to the model of Brown et al (1992):L?
(w; C) =m?i=1p(wi|C(wi))p(C(wi)|C(wi?1)) .While the use of class-to-class transitions can leadto more compact models, which is often useful forconquering data sparsity, when clustering large datasets we can get reliable statistics directly on the word-to-class transitions (Uszkoreit and Brants, 2008).In addition to the clustering model that we makeuse of in this study, a number of additional wordclustering and embedding variants have been pro-posed.
For example, Turian et al (2010) assessedthe effectiveness of the word embedding techniquesof Collobert and Weston (2008) and Mnih and Hin-ton (2007) along with the word clustering techniqueof Brown et al (1992) for syntactic chunking andNER.
Recently, Dhillon et al (2011) proposed a word478Single words S0c{p}, N0c{p}, N1c{p}, N2c{p}Word pairs S0c{p}N0c{p}, S0pcN0p, S0pN0pc,S0wN0c, S0cN0w, N0cN1c, N1cN2cWord triples N0cN1cN2c, S0cN0cN1c, S0hcS0cN0c,S0cS0lcN0c, S0cS0rcN0c, S0cN0cN0lcDistance S0cd, N0cd, S0cN0cdValency S0cvl, S0cvr , N0cS0vlUnigrams S0hc, S0lc, S0rc, N0lcThird-order S0h2c, S0l2c, S0r2c, N0l2cLabel set S0cS0ll, S0cS0rl, N0cN0ll, N0cN0rlTable 1: Additional cluster-based parser features.
Si andNi: the ith tokens in the stack and buffer.
p: the part-of-speech tag, c: the cluster.
v: the valence of the left (l) orright (r) set of children.
l: the label of the token underconsideration.
d: distance between the words on the top ofthe stack and buffer.
Sih, Sir and Sil: the head, right-mostmodifier and left-most modifier of the token at the top ofthe stack.
Gx{y} expands to Gxy and Gx.embedding method based on canonical correlationanalysis that provides state-of-the art results for word-based SSL for English NER.
As an alternative to clus-tering words, Lin and Wu (2009) proposed a phraseclustering approach that obtained the state-of-the-artresult for English NER.3 Monolingual Cluster ExperimentsBefore moving on to the multilingual setting, weconduct a set of monolingual experiments where weevaluate the use of the monolingual word clustersjust described as features for dependency parsing andNER.
In the parsing experiments, we study the fol-lowing thirteen languages:1 Danish (DA), German(DE), Greek (EL), English (EN), Spanish (ES), French(FR), Italian (IT), Korean (KO), Dutch (NL), Portugese(PT), Russian (RU), Swedish (SV) and Chinese (ZH)?
representing the Chinese, Germanic, Hellenic, Ro-mance, Slavic, Altaic and Korean genera.
In the NERexperiments, we study three Germanic languages:German (DE), English (EN) and Dutch (NL); and oneRomance language: Spanish (ES).Details of the labeled and unlabeled data sets usedare given in Appendix A.
For all experiments wefixed the number of clusters to 256 as this performedwell on held-out data.
Furthermore, we only clus-tered the 1 million most frequent word types in eachlanguage for both efficiency and sparsity reasons.
For1The particular choice of languages was made purely basedon data availability and institution licensing.Word & bias w?1,0,1, w?1:0, w0:1, w?1:1, bPre-/suffix w:1,:2,:3,:4,:5?1,0,1 , w?5:,?4:,?3:,?2:,?1:?1,0,1Orthography Hyp?1,0,1, Cap?1,0,1, Cap?1:0,Cap0:1, Cap?1:1PoS p?1,0,1, p?1:0, p0:1, p?1:1, p?2:1, p?1:2Cluster c?1,0,1, c?1:0, c0:1, c?1:1, c?2:1, c?1:2Transition ?/p?1,0,1,?/c?1,0,1,?/Cap?1,0,1,?/bTable 2: NER features.
Hyp: Word contains hyphen.
Cap:First letter is capitalized.
?/f - Transition from previousto current label conjoined with feature f .
w:j : j-characterprefix of w. w?j:: j-character suffix of w. fi: Feature fat relative position i. fi,j : Union of features at positions iand j. fi:j : Conjoined feature sequence between relativepositions i and j (inclusive).
b: Bias.languages in which our unlabeled data did not haveat least 1 million types, we considered all types.3.1 Cluster Augmented Feature ModelsAll of the parsing experiments reported in this studyare based on the transition-based dependency parsingparadigm (Nivre, 2008).
For all languages and set-tings, we use an arc-eager decoding strategy, with abeam of eight hypotheses, and perform ten epochs ofthe averaged structured perceptron algorithm (Zhangand Clark, 2008).
We extend the state-of-the-art fea-ture model recently introduced by Zhang and Nivre(2011) by adding an additional word cluster basedfeature template for each word based template.
Ad-ditionally, we add templates where one or more part-of-speech feature is replaced with the correspondingcluster feature.
The resulting set of additional fea-ture templates are shown in Table 1.
The expandedfeature model includes all of the feature templates de-fined by Zhang and Nivre (2011), which we also useas the baseline model, whereas Table 1 only showsour new templates due to space limitations.For all NER experiments, we use a sequential first-order conditional random field (CRF) with a unitvariance Normal prior, trained with L-BFGS until-convergence ( = 0.0001, typically obtained afterless than 400 iterations).
The feature model usedfor the NER tagger is shown in Table 2.
These aresimilar to the features used by Turian et al (2010),with the main difference that we do not use any longrange features and that we add templates that conjoinadjacent clusters and adjacent tags as well as tem-plates that conjoin label transitions with tags, clustersand capitalization features.479DA DE EL EN ES FR IT KO NL PT RU SV ZH AVGNO CLUSTERS 84.3 88.9 76.1 90.3 82.8 85.7 81.4 82.0 77.2 86.9 83.5 84.7 74.9 83.0CLUSTERS 85.8 89.5 77.3 90.7 83.6 85.7 82.2 83.6 77.8 87.6 86.0 86.5 75.5 84.0Table 3: Supervised parsing results measured with labeled attachment score (LAS) on the test set.
All results arestatistically significant at p < 0.05, except FR and NL.DE EN ES NL AVGNO CLUSTERS 65.4 89.2 75.0 75.7 76.3CLUSTERS 74.8 91.8 81.1 84.2 83.0?
DEVELOPMENT SET ?
TEST SETNO CLUSTERS 69.1 83.5 78.9 79.6 77.8CLUSTERS 74.4 87.8 82.0 85.7 82.5Table 4: Supervised NER results measured with F1-scoreon the CoNLL 2002/2003 development and test sets.3.2 ResultsThe results of the parsing experiments, measuredwith labeled accuracy score (LAS) on all sentencelengths, excluding punctuation, are shown in Table 3.The baselines are all comparable to the state-of-the-art.
On average, the addition of word cluster featuresyields a 6% relative reduction in error and upwardsof 15% (for RU).
All languages improve except FR,which sees neither an increase nor a decrease in LAS.We observe an average absolute increase in LASof approximately 1%, which is inline with previousobservations (Koo et al, 2008).
It is perhaps notsurprising that RU sees a large gain as it is a highlyinflected language, making observations of lexicalfeatures far more sparse.
Some languages, e.g., FR,NL, and ZH see much smaller gains.
One likely cul-prit is a divergence between the tokenization schemesused in the treebank and in our unlabeled data, whichfor Indo-European languages is closely related to thePenn Treebank tokenization.
For example, the NLtreebank contains many multi-word tokens that aretypically broken apart by our automatic tokenizer.The NER results, in terms of F1 measure, are listedin Table 4.
Introducing word cluster features forNER reduces relative errors on the test set by 21%(39% on the development set) on average.
Brokendown per language, reductions on the test set varyfrom substantial for NL (30%) and EN (26%), downto more modest for DE (17%) and ES (12%).
Theaddition of cluster features most markedly improverecognition of the PER category, with an average errorreduction on the test set of 44%, while the reductionsfor ORG (19%), LOC (17%) and MISC (10%) are moremodest, but still significant.
Although our resultsare below the best reported results for EN and DE(Lin and Wu, 2009; Faruqui and Pado?, 2010), therelative improvements of adding word clusters areinline with previous results on NER for EN (Milleret al, 2004; Turian et al, 2010), who report errorreductions of approximately 25% from adding wordcluster features.
Slightly higher reductions whereachieved for DE by Faruqui and Pado?
(2010), whoreport a reduction of 22%.
Note that we did not tunehyper-parameters of the supervised learning methodsand of the clustering method, such as the numberof clusters (Turian et al, 2010; Faruqui and Pado?,2010), and that we did not apply any heuristic for datacleaning such as that used by Turian et al (2010).4 Cross-lingual Word Cluster FeaturesAll results of the previous section rely on the avail-ability of large quantities of language specific anno-tations for each task.
Cross-lingual transfer methodsand unsupervised methods have recently been shownto hold promise as a way to at least partially sidestepthe demand for labeled data.
Unsupervised methodsattempt to infer linguistic structure without using anyannotated data (Klein and Manning, 2004) or possi-bly by using a set of linguistically motivated rules(Naseem et al, 2010) or a linguistically informedmodel structure (Berg-Kirkpatrick and Klein, 2010).The aim of transfer methods is instead to use knowl-edge induced from labeled resources in one or moresource languages to construct systems for target lan-guages in which no or few such resources are avail-able (Hwa et al, 2005).
Currently, the performanceof even the most simple direct transfer systems farexceeds that of unsupervised systems (Cohen et al,2011; McDonald et al, 2011; S?gaard, 2011).480Figure 1: Cross-lingual word cluster features for parsing.
Top-left: Cross-lingual (EN-ES) word clustering model.Top-right: Samples of some of the induced cross-lingual word clusters.
Bottom-left: Delexicalized cluster-augmentedsource (EN) treebank for training transfer parser.
Bottom-right: Parsing of target (ES) sentence using the transfer parser.4.1 Direct Transfer of Discriminative ModelsOur starting point is the delexicalized direct transfermethod proposed by McDonald et al (2011) based onwork by Zeman and Resnik (2008).
This method wasshown to outperform a number of state-of-the-art un-supervised and transfer-based baselines.
The methodis simple; for a given training set, the learner ignoresall lexical identities and only observes features overother characteristics, e.g., part-of-speech tags, ortho-graphic features, direction of syntactic attachment,etc.
The learner builds a model from an annotatedsource language data set, after which the model isused to directly make target language predictions.There are three basic assumptions that drive this ap-proach.
First, that high-level tasks, such as syntacticparsing, can be learned reliably using coarse-grainedstatistics, such as part-of-speech tags, in place offine-grained statistics such as lexical word identities.Second, that the parameters of features over coarse-grained statistics are in some sense language inde-pendent, e.g., a feature that indicates that adjectivesmodify their closest noun is useful in all languages.Third, that these coarse-grained statistics are robustlyavailable across languages.
The approach proposedby McDonald et al (2011) relies on these three as-sumptions.
Specifically, by replacing fine-grainedlanguage specific part-of-speech tags with universalpart-of-speech tags, generated with the method de-scribed by Das and Petrov (2011), a universal parseris achieved that can be applied to any language forwhich universal part-of-speech tags are available.Below, we extend this approach to universal pars-ing by adding cross-lingual word cluster features.
Across-lingual word clustering is a clustering of wordsin two languages, in which the clusters correspond tosome meaningful cross-lingual property.
For exam-ple, prepositions from both languages should be inthe same cluster, proper names from both languagesin another cluster and so on.
By adding features de-fined over these clusters, we can, to some degree,481re-lexicalize the delexicalized models, while main-taining the ?universality?
of the features.
This ap-proach is outlined in Figure 1.
Assuming that wehave an algorithm for generating cross-lingual wordclusters (see Section 4.2), we can augment the delex-icalized parsing algorithm to use these word clusterfeatures at training and testing time.In order to further motivate the proposed approach,consider the accuracy of the supervised Englishparser.
A parser with lexical, part-of-speech andcluster features achieves 90.7% LAS (see Table 3).
Ifwe remove all lexical and cluster features, the sameparser achieves 83.1%.
However, if we add back justthe cluster features, the accuracy jumps back up to89.5%, which is only 1.2% below the full system.Thus, if we can accurately learn cross-lingual clus-ters, there is hope of regaining some of the accuracylost due to the delexicalization process.4.2 Inducing Cross-lingual Word ClustersOur first method for inducing cross-lingual clustershas two stages.
First, it clusters a source language(S) as in the monolingual case, and then projectsthese clusters to a target language (T), using wordalignments.
Given two aligned word sequenceswS =?wSi?mSi=1 and wT =?wTi?mTj=1, let AT |S be aset of scored alignments from the source language tothe target language, where (wTj , wSaj , sj,aj ) ?
AT |Sis an alignment from the aj th source word to the jthtarget word, with score sj,aj ?
?.2 We use the short-hand j ?
AT |S to denote those target words wTj thatare aligned to some source word wSaj .
Provided aclustering CS , we assign the target word t ?
VT tothe cluster with which it is most often aligned:CT (t) = argmaxk?j?AT |Ss.t.
wTj =tsj,aj[CS(wSaj ) = k], (2)where [?]
is the indicator function.
We refer to thecross-lingual clusters induced in this way as PRO-JECTED CLUSTERS.This simple projection approach has two potentialdrawbacks.
First, it only provides a clustering ofthose target language words that occur in the word2In our case, the alignment score corresponds to the condi-tional alignment probability p(wTj |wSaj ).
All -alignments areignored and we use ?
= 0.95 throughout.aligned data, which is typically smaller than ourmonolingual data sets.
Second, the mapped cluster-ing may not necessarily correspond to an acceptabletarget language clustering in terms of monolinguallikelihood.
In order to tackle these issues, we pro-pose the following more complex model.
First, tofind clusterings that are good according to both thesource and target language, and to make use of moreunlabeled data, we model word sequences in each lan-guage by the monolingual language model with like-lihood function defined by equation (1).
Denote theselikelihood functions respectively by LS(wS ; CS) andLT (wT ; CT ), where we have overloaded notation sothat the word sequences denoted by wS and wT in-clude much more plentiful non-aligned data whentaken as an argument of the monolingual likelihoodfunctions.
Second, we couple the clusterings definedby these individual models, by introducing additionalfactors based on word alignments, as proposed byOch (1999):LT |S(wT ;AT |S , CT , CS) =?j?AT |Sp(wTj |CT (wTj ))p(CT (wTj )|CS(wSaj )) .and the symmetric LS|T (wS ;AS|T , CS , CT ).
Notethat the simple projection defined by equation (2)correspond to a hard assignment variant of this prob-abilistic formulation when the source clustering isfixed.
Combining all four factors results in the jointmonolingual and cross-lingual objective functionLS,T (wS ,wT ;AT |S ,AS|T , CS , CT ) =LS(.
.
.)
?
LT (.
.
.)
?
LT |S(.
.
.)
?
LS|T (.
.
.)
.
(3)The intuition of this approach is that the clusteringsCS and CT are forced to jointly explain the sourceand target data, treating the word alignments as aform of soft constraints.
We approximately optimize(3) with the alternating procedure in Algorithm 1, inwhich we iteratively maximize LS and LT , keepingthe other factors fixed.
In this way we can generatecross-lingual clusterings using all the monolingualdata while forcing the clusterings to obey the wordalignment constraints.
We refer to the clusters in-duced with this method as X-LINGUAL CLUSTERS.In practice we found that each unconstrainedmonolingual run of the exchange algorithm (lines482Algorithm 1 Cross-lingual clustering.Randomly initialize source/target clusterings CS and CT .for i = 1 .
.
.
N do1.
Find C?S ?
argmaxCS LS(wS ; CS).
(?)2.
Project C?S to CT using equation (2).- keep cluster of non-projected words in CT fixed.3.
Find C?T ?
argmaxCT LT (wT ; CT ).
(?)4.
Project C?T to CS using equation (2).- keep cluster of non-projected words in CS fixed.end for?
Optimized via the exchange algorithm keeping the clusterof projected words fixed and only clustering additional wordsnot in the projection.1 and 3) moves the clustering too far from those thatobey the word alignment constraints, which causesthe procedure to fail to converge.
However, we foundthat fixing the clustering of the words that are as-signed clusters in the projection stages (lines 2 and4) and only clustering the remaining words workswell in practice.
Furthermore, we found that iteratingthe procedure has little effect on performance and setN = 1 for all subsequent experiments.5 Cross-lingual ExperimentsIn our first set of experiments on using cross-lingualcluster features, we evaluate direct transfer of ourEN parser, trained on Stanford style dependencies(De Marneffe et al, 2006), to the the ten non-ENIndo-European languages listed in Section 3.
We ex-clude KO and ZH as initial experiments proved directtransfer a poor technique when transferring parsersbetween such diverse languages.
We study the impactof using cross-lingual cluster features by comparingthe strong delexicalized baseline model of McDon-ald et al (2011), which only has features derivedfrom universal part-of-speech tags, projected fromEnglish with the method of Das and Petrov (2011), tothe same model when adding features derived fromcross-lingual clusters.
In both cases the feature mod-els are the same as those used in Section 3.1, exceptthat they are delexicalized by removing all lexicalword-identity features.
We evaluate both the PRO-JECTED CLUSTERS and the X-LINGUAL CLUSTERS.For these experiments we train the perceptronfor only five epochs in order to prevent over-fitting,which is an acute problem due to the divergence be-tween the training and testing data sets in this setting.Furthermore, in accordance to standard practices weonly evaluate unlabeled attachment score (UAS) dueto the fact that each treebank uses a different ?
possi-bly non-overlapping ?
label set.In our second set of experiments, we evaluate di-rect transfer of a NER system trained on EN to DE,ES and NL.
We use the same feature models as inthe monolingual case, with the exception that we useuniversal part-of-speech tags for all languages andwe remove the capitalization feature when transfer-ring from EN to DE.
Capitalization is both a prevalentand highly predictive feature of named-entities in EN,while in DE, capitalization is even more prevalent, buthas very low predictive power.
Interestingly, whiledelexicalization has shown to be important for di-rect transfer of dependency-parsers (McDonald et al,2011), we noticed in preliminary experiments thatit substantially degrades performance for NER.
Wehypothesize that this is because word features are pre-dictive of common proper names and that these areoften translated directly across languages, at least inthe case of newswire text.
As for the transfer parser,when training the source NER model, we regularizethe model more heavily by setting ?
= 0.1.Appendix A contains the details of the training,testing, unlabeled and parallel/aligned data sets.5.1 ResultsTable 5 lists the results of the transfer experimentsfor dependency parsing.
The baseline results arecomparable to those in McDonald et al (2011) andthus also significantly outperform the results of re-cent unsupervised approaches (Berg-Kirkpatrick andKlein, 2010; Naseem et al, 2010).
Importantly, cross-lingual cluster features are helpful across the boardand give a relative error reduction ranging from 3%for DA to 13% for PT, with an average reduction of6%, in terms of unlabeled attachment score (UAS).This shows the utility of cross-lingual cluster fea-tures for syntactic transfer.
However, X-LINGUALCLUSTERS provides roughly the same performanceas PROJECTED CLUSTERS suggesting that even sim-ple methods of cross-lingual clustering are sufficientfor direct transfer dependency parsing.We would like to stress that these results are likelyto be under-estimating the parsers?
actual ability topredict Stanford-style dependencies in the target lan-guages.
This is because the target language anno-tations that we use for evaluation differ from the483DA DE EL ES FR IT NL PT RU SV AVGNO CLUSTERS 36.7 48.9 59.5 60.2 70.0 64.6 52.8 66.8 29.7 55.4 54.5PROJECTED CLUSTERS 38.9 50.3 61.1 62.6 71.6 68.6 54.5 70.7 32.9 57.0 56.8X-LINGUAL CLUSTERS 38.7 50.7 63.0 62.9 72.1 68.8 54.3 71.0 34.4 56.9 57.3?
ALL DEPENDENCY RELATIONS ?
ONLY SUBJECT/OBJECT RELATIONSNO CLUSTERS 44.6 56.7 67.2 60.7 77.4 64.6 59.5 53.3 29.3 57.3 57.1PROJECTED CLUSTERS 49.8 57.1 72.2 65.9 80.4 70.5 67.0 62.6 34.6 65.0 62.5X-LINGUAL CLUSTERS 49.2 59.0 72.5 65.9 80.9 72.7 65.7 62.5 37.2 64.4 63.0Table 5: Direct transfer dependency parsing from English.
Results measured by unlabeled attachment score (UAS).ONLY SUBJECT/OBJECT RELATIONS ?
UAS measured only over words marked as subject/object in the evaluation data.Stanford dependency annotation.
Some of these dif-ferences are warranted in that certain target languagephenomena are better captured by the native annota-tion.
However, differences such as choice of lexicalversus functional head are more arbitrary.To highlight this point we run two additional ex-periments.
First, we had linguists, who were alsofluent speakers of German, re-annotate the DE test setso that unlabeled arcs are consistent with Stanford-style dependencies.
Using this data, NO CLUSTERSobtains 60.0% UAS, PROJECTED CLUSTERS 63.6%and X-LINGUAL CLUSTERS 64.4%.
When comparedto the scores on the original data set (48.9%, 50.3%and 50.7%, respectively) we can see that not only isthe baseline system doing much better, but that theimprovements from cross-lingual clustering are muchmore pronounced.
Next, we investigated the accuracyof subject and object dependencies, as these are oftenannotated in similar ways across treebanks, typicallymodifying the main verb of the sentence.
The bottomhalf of Table 5 gives the scores when restricted tosuch dependencies in the gold data.
We measure thepercentage of modifiers in subject and object depen-dencies that modify the correct word.
Indeed, herewe see the difference in performance become clearer,with the cross-lingual cluster model reducing errorsby 14% relative to the non-cross-lingual model andupwards of 22% relative for IT.We now turn to the results of the transfer experi-ments for NER, listed in Table 6.
While the perfor-mance of the transfer systems is very poor when noword clusters are used, adding cross-lingual wordclusters give substantial improvements across all lan-guages.
The simple PROJECTED CLUSTERS workwell, but the X-LINGUAL CLUSTERS provide evenlarger improvements.
On average the latter reduceDE ES NL AVGNO CLUSTERS 25.4 49.5 49.9 41.6PROJECTED CLUSTERS 39.1 62.1 61.8 54.4X-LINGUAL CLUSTERS 43.1 62.8 64.7 56.9?
DEVELOPMENT SET ?
TEST SETNO CLUSTERS 23.5 45.6 48.4 39.1PROJECTED CLUSTERS 35.2 59.1 56.4 50.2X-LINGUAL CLUSTERS 40.4 59.3 58.4 52.7Table 6: Direct transfer NER results (from English) mea-sured with average F1-score on the CoNLL 2002/2003development and test sets.errors on the test set by 22% in terms of F1 and upto 26% for ES.
We also measure how well the di-rect transfer NER systems are able to detect entityboundaries (ignoring the entity categories).
Here, onaverage, the best clusters provide a 24% relative errorreduction on the test set (75.8 vs. 68.1 F1).To our knowledge there are no comparable resultson transfer learning of NER systems.
Based on theresults of this first attempt at this scenario, we believethat transfer learning by multilingual word clusterscould be developed into a practical way to constructNER systems for resource poor languages.6 ConclusionIn the first part of this study, we showed that wordclusters induced from a simple class-based languagemodel can be used to significantly improve on state-of-the-art supervised dependency parsing and NERfor a wide range of languages and even across lan-guage families.
Although the improvements varybetween languages, the addition of word cluster fea-tures never has a negative impact on performance.484This result has important practical consequences asit allows practitioners to simply plug in word clus-ter features into their current feature models.
Givenprevious work on word clusters for various linguisticstructure prediction tasks, these results are not toosurprising.
However, to our knowledge this is the firststudy to apply the same type of word cluster featuresacross languages and tasks.In the second part, we provided two simple meth-ods for inducing cross-lingual word clusters.
The firstmethod works by projecting word clusters, inducedfrom monolingual data, from a source language toa target language directly via word alignments.
Thesecond method, on the other hand, makes use ofmonolingual data in both the source and the targetlanguage, together with word alignments that act asconstraints on the joint clustering.
We then showedthat by using these cross-lingual word clusters, wecan significantly improve on direct transfer of dis-criminative models for both parsing and NER.
Asin the monolingual case, both types of cross-lingualword cluster features yield improvements across theboard, with the more complex method providing asignificantly larger improvement for NER.
Althoughthe performance of transfer systems is still substan-tially below that of supervised systems, this researchprovides one step towards bridging this gap.
Further,we believe that it opens up an avenue for future workon multilingual clustering methods, cross-lingual fea-ture projection and domain adaptation for direct trans-fer of linguistic structure.AcknowledgmentsWe thank John DeNero for help with creating theword alignments; Reut Tsarfaty and Joakim Nivre forrewarding discussions on evaluation; Slav Petrov andKuzman Ganchev for discussions on cross-lingualclustering; and the anonymous reviewers, along withJoakim Nivre, for valuable comments that helpedimprove the paper.
The first author is grateful for thefinancial support of the Swedish National GraduateSchool of Language Technology (GSLT).A Data SetsIn the parsing experiments, we use the following datasets.
For DA, DE, EL, ES, IT, NL, PT and SV, weuse the predefined training and evaluation data setsfrom the CoNLL 2006/2007 data sets (Buchholz andMarsi, 2006; Nivre et al, 2007).
For EN we usesections 02-21, 22, and 23 of the Penn WSJ Tree-bank (Marcus et al, 1993) for training, developmentand evaluation.
For FR we used the French Treebank(Abeille?
and Barrier, 2004) with splits defined in Can-dito et al (2010).
For KO we use the Sejong KoreanTreebank (Han et al, 2002) randomly splitting thedata into 80% training, 10% development and 10%evaluation.
For RU we use the SynTagRus Treebank(Boguslavsky et al, 2000; Apresjan et al, 2006) ran-domly splitting the data into 80% training, 10% devel-opment and 10% evaluation.
For ZH we use the PennChinese Treebank v6 (Xue et al, 2005) using theproposed data splits from the documentation.
BothEN and ZH were converted to dependencies usingv1.6.8 of the Stanford Converter (De Marneffe et al,2006).
FR was converted using the procedure definedin Candito et al (2010).
RU and KO are native depen-dency treebanks.
For the CoNLL data sets we usethe part-of-speech tags provided with the data.
Forall other data sets, we train a part-of-speech taggeron the training data in order to tag the developmentand evaluation data.For the NER experiments we use the training, de-velopment and evaluation data sets from the CoNLL2002/2003 shared tasks (Tjong Kim Sang, 2002;Tjong Kim Sang and De Meulder, 2003) for allfour languages (DE, EN, ES and NL).
The data setfor each language consists of newswire text anno-tated with four entity categories: Location (LOC),Miscellaneous (MISC), Organization (ORG) and Per-son (PER).
We use the part-of-speech tags suppliedwith the data, except for ES where we instead useuniversal part-of-speech tags (Petrov et al, 2011).Unlabeled data for training the monolingual clustermodels was extracted from one year of newswire ar-ticles from multiple sources from a news aggregationwebsite.
This consists of 0.8 billion (DA) to 121.6 bil-lion (EN) tokens per language.
All word alignmentsfor the cross-lingual clusterings were produced withthe dual decomposition aligner described by DeNeroand Macherey (2011) using 10.5 million (DA) to 12.1million (FR) sentences of aligned web data.485ReferencesAnne Abeille?
and Nicolas Barrier.
2004.
Enriching afrench treebank.
In Proceedings of LREC.Juri Apresjan, Igor Boguslavsky, Boris Iomdin, LeonidIomdin, Andrei Sannikov, and Victor Sizov.
2006.
Asyntactically and semantically tagged corpus of russian:State of the art and prospects.
In Proceedings of LREC.Emily M. Bender.
2011.
On achieving and evaluatinglanguage-independence in NLP.
Linguistic Issues inLanguage Technology, 6(3):1?26.Taylor Berg-Kirkpatrick and Dan Klein.
2010.
Phyloge-netic grammar induction.
In Proceedings of ACL.Daniel M. Bikel, Richard Schwartz, and Ralph M.Weischedel.
1999.
An algorithm that learns what?sin a name.
Machine Learning, 34(1):211?231.Igor Boguslavsky, Svetlana Grigorieva, Nikolai Grigoriev,Leonid Kreidlin, and Nadezhda Frid.
2000.
Depen-dency treebank for Russian: Concept, tools, types ofinformation.
In Proceedings of COLING.Peter F. Brown, Peter V. deSouza, Robert L. Mercer, Vin-cent J. Della Pietra, and Jenifer C. Lai.
1992.
Class-based n-gram models of natural language.
Computa-tional Linguistics, 18:467?479.Sabine Buchholz and Erwin Marsi.
2006.
CoNLL-Xshared task on multilingual dependency parsing.
InProceedings of CoNLL.Marie Candito, Beno?
?t Crabbe?, and Pascal Denis.
2010.Statistical french dependency parsing: treebank conver-sion and first results.
In Proceedings of LREC.David Chiang.
2005.
A hierarchical phrase-based modelfor statistical machine translation.
In Proceedings ofACL.Alexander Clark.
2003.
Combining distributional andmorphological information for part of speech induction.In Proceedings of EACL.Shay B. Cohen and Noah A. Smith.
2009.
Shared lo-gistic normal distributions for soft parameter tying inunsupervised grammar induction.
In Proceedings ofNAACL.Shay B. Cohen, Dipanjan Das, and Noah A. Smith.
2011.Unsupervised structure prediction with non-parallelmultilingual guidance.
In Proceedings of EMNLP.Michael Collins, Philipp Koehn, and Ivona Kuc?erova?.2005.
Clause restructuring for statistical machine trans-lation.
In Proceedings of ACL.Michael Collins.
1997.
Three generative, lexicalisedmodels for statistical parsing.
In Proceedings of ACL.Ronan Collobert and Jason Weston.
2008.
A unified ar-chitecture for natural language processing: deep neuralnetworks with multitask learning.
In Proceedings ofICML.Dipanjan Das and Slav Petrov.
2011.
Unsupervised part-of-speech tagging with bilingual graph-based projec-tions.
In Proceedings of ACL-HLT.Marie-Catherine De Marneffe, Bill MacCartney, andChris D. Manning.
2006.
Generating typed depen-dency parses from phrase structure parses.
In Proceed-ings of LREC.John DeNero and Klaus Macherey.
2011.
Model-basedaligner combination using dual decomposition.
In Pro-ceedings of ACL-HLT.Paramveer Dhillon, Dean Foster, and Lyle Dean.
2011.Multi-view learning of word embeddings via cca.
InProceedings of NIPS.Manaal Faruqui and Sebastian Pado?.
2010.
Trainingand evaluating a german named entity recognizer withsemantic generalization.
In Proceedings of KONVENS.Dayne Freitag.
2004.
Trained named entity recogni-tion using distributional clusters.
In Proceedings ofEMNLP.Jennifer Gillenwater, Kuzman Ganchev, Joa?o Grac?a, Fer-nando Pereira, and Ben Taskar.
2010.
Sparsity independency grammar induction.
In Proceedings ofACL.Gholamreza Haffari, Marzieh Razavi, and Anoop Sarkar.2011.
An ensemble model that combines syntacticand semantic clustering for discriminative dependencyparsing.
In Proceedings of ACL.Chung-hye Han, Na-Rare Han, Eon-Suk Ko, and MarthaPalmer.
2002.
Development and evaluation of a koreantreebank and its application to nlp.
In Proceedings ofLREC.Rebecca Hwa, Philip Resnik, Amy Weinberg, ClaraCabezas, and Okan Kolak.
2005.
Bootstrappingparsers via syntactic projection across parallel texts.Natural Language Engineering, 11(03):311?325.Dan Klein and Chris D. Manning.
2004.
Corpus-basedinduction of syntactic structure: models of dependencyand constituency.
In Proceedings of ACL.Terry Koo, Xavier Carreras, and Michael Collins.
2008.Simple semi-supervised dependency parsing.
In Pro-ceedings of ACL-HLT.Sandra Ku?bler, Ryan McDonald, and Joakim Nivre.
2009.Dependency parsing.
Morgan & Claypool Publishers.Dekang Lin and Xiaoyun Wu.
2009.
Phrase clusteringfor discriminative learning.
In Proceedings of ACL-IJCNLP, pages 1030?1038.Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beat-rice Santorini.
1993.
Building a large annotated corpusof English: the Penn treebank.
Computational Linguis-tics, 19(2):313?330.Ryan McDonald, Slav Petrov, and Keith Hall.
2011.Multi-source transfer of delexicalized dependencyparsers.
In Proceedings of EMNLP.486Scott Miller, Jethran Guinness, and Alex Zamanian.
2004.Name tagging with word clusters and discriminativetraining.
In Proceedings of HLT-NAACL.Andriy Mnih and Geoffrey Hinton.
2007.
Three newgraphical models for statistical language modelling.
InProceedings of ICML.Tahira Naseem, Harr Chen, Regina Barzilay, and MarkJohnson.
2010.
Using universal linguistic knowl-edge to guide grammar induction.
In Proceedings ofEMNLP.Joakim Nivre, Johan Hall, Sandra Ku?bler, Ryan McDon-ald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret.2007.
The CoNLL 2007 shared task on dependencyparsing.
In Proceedings of EMNLP-CoNLL.Joakim Nivre.
2008.
Algorithms for deterministic incre-mental dependency parsing.
Computational Linguis-tics, 34(4):513?553.Franz Josef Och.
1999.
An efficient method for determin-ing bilingual word classes.
In Proceedings of EACL.Bo Pang and Lillian Lee.
2008.
Opinion mining andsentiment analysis.
Now Publishers Inc.Slav Petrov, Dipanjan Das, and Ryan McDonald.
2011.
Auniversal part-of-speech tagset.
In ArXiv:1104.2086.Adwait Ratnaparkhi.
1996.
A maximum entropy modelfor part-of-speech tagging.
In Proceedings of EMNLP.Noah A. Smith.
2011.
Linguistic Structure Prediction.Morgan & Claypool Publishers.Anders S?gaard.
2011.
Data point selection for cross-language adaptation of dependency parsers.
In Pro-ceedings of ACL.Valentin I. Spitkovsky, Hiyan Alshawi, and Daniel Juraf-sky.
2011.
Lateen EM: Unsupervised training withmultiple objectives, applied to dependency grammarinduction.
In Proceedings of EMNLP.Erik F. Tjong Kim Sang and Fien De Meulder.
2003.Introduction to the conll-2003 shared task: Language-independent named entity recognition.
In Proceedingsof CoNLL.Erik F. Tjong Kim Sang.
2002.
Introduction to the conll-2002 shared task: Language-independent named entityrecognition.
In Proceedings of CoNLL.Stephen Tratz and Eduard Hovy.
2011.
A fast, effec-tive, non-projective, semantically-enriched parser.
InProceedings of EMNLP.Joseph Turian, Lev-Arie Ratinov, and Yoshua Bengio.2010.
Word representations: A simple and generalmethod for semi-supervised learning.
In Proceedingsof ACL.Jakob Uszkoreit and Thorsten Brants.
2008.
Distributedword clustering for large scale class-based languagemodeling in machine translation.
In Proceedings ofACL-HLT.Naiwen Xue, Fei Xia, Fu-dong Chiou, and Marta Palmer.2005.
The penn chinese treebank: Phrase structureannotation of a large corpus.
Natural Language Engi-neering, 11(02):207?238.Daniel Zeman and Philip Resnik.
2008.
Cross-languageparser adaptation between related languages.
In IJC-NLP Workshop: NLP for Less Privileged Languages.Yue Zhang and Stephen Clark.
2008.
A tale of twoparsers: Investigating and combining graph-based andtransition-based dependency parsing.
In Proceedingsof EMNLP.Yue Zhang and Joakim Nivre.
2011.
Transition-baseddependency parsing with rich non-local features.
InProceedings of ACL-HLT.487
