Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 495?503,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsEfficient Disfluency Detection with Transition-based ParsingShuangzhi Wu?, Dongdong Zhang?, Ming Zhou?, Tiejun Zhao?
?Harbin Institute of Technology?Microsoft Research{v-shuawu, dozhang, mingzhou}@microsoft.comtjzhao@hit.edu.cnAbstractAutomatic speech recognition (ASR) out-puts often contain various disfluencies.
Itis necessary to remove these disfluenciesbefore processing downstream tasks.
Inthis paper, an efficient disfluency detectionapproach based on right-to-left transition-based parsing is proposed, which can effi-ciently identify disfluencies and keep ASRoutputs grammatical.
Our method exploitsa global view to capture long-range de-pendencies for disfluency detection by in-tegrating a rich set of syntactic and dis-fluency features with linear complexity.The experimental results show that ourmethod outperforms state-of-the-art workand achieves a 85.1% f-score on the com-monly used English Switchboard test set.We also apply our method to in-house an-notated Chinese data and achieve a sig-nificantly higher f-score compared to thebaseline of CRF-based approach.1 IntroductionWith the development of the mobile internet,speech inputs have become more and more popu-lar in applications where automatic speech recog-nition (ASR) is the key component to convertspeech into text.
ASR outputs often contain var-ious disfluencies which create barriers to sub-sequent text processing tasks like parsing, ma-chine translation and summarization.
Usually,disfluencies can be classified into uncompletedwords, filled pauses (e.g.
?uh?, ?um?
), discoursemarkers (e.g.
?I mean?
), editing terms (e.g.
?youknow?)
and repairs.
To identify and remove dis-fluencies, straightforward rules can be designedto tackle the former four classes of disfluenciessince they often belong to a closed set.
However,the repair type disfluency poses particularly moredifficult problems as their form is more arbitrary.Typically, as shown in Figure 1, a repair disflu-ency type consists of a reparandum (?to Boston?
)and a filled pause (?um?
), followed by its repair(?to Denver?).
This special structure of disfluencyconstraint, which exists in many languages suchas English and Chinese, reflects the scenarios ofspontaneous speech and conversation, where peo-ple often correct preceding words with followingwords when they find that the preceding wordsare wrong or improper.
This procedure might beinterrupted and inserted with filled pauses whenpeople are thinking or hesitating.
The challengesof detecting repair disfluencies are that reparan-dums vary in length, may occur everywhere, andare sometimes nested.I want a flight to Boston um to Denver FPRM RPcorrectFigure 1: A typical example of repair type disflu-ency consists of FP (Filled Pause), RM (Reparan-dum), and RP (Repair).
The preceding RM is cor-rected by the following RP.There are many related works on disfluencydetection, that mainly focus on detecting repairtype of disfluencies.
Straightforwardly, disflu-ency detection can be treated as a sequence la-beling problem and solved by well-known ma-chine learning algorithms such as conditional ran-dom fields (CRF) or max-margin markov network(M3N) (Liu et al, 2006; Georgila, 2009; Qianand Liu, 2013), and prosodic features are alsoconcerned in (Kahn et al, 2005; Zhang et al,2006).
These methods achieve good performance,but are not powerful enough to capture compli-cated disfluencies with longer spans or distances.Recently, syntax-based models such as transition-based parser have been used for detecting disflu-495encies (Honnibal and Johnson, 2014; Rasooli andTetreault, 2013).
These methods can jointly per-form dependency parsing and disfluency detec-tion.
But in these methods, great efforts are madeto distinguish normal words from disfluent wordsas decisions cannot be made imminently from leftto right, leading to inefficient implementation aswell as performance loss.In this paper, we propose detecting disfluenciesusing a right-to-left transition-based dependencyparsing (R2L parsing), where the words are con-sumed from right to left to build the parsing treebased on which the current word is predicted to beeither disfluent or normal.
The proposed modelscater to the disfluency constraint and integrate arich set of features extracted from contexts of lexi-cons and partial syntactic tree structure, where theparsing model and disfluency predicting model arejointly calculated in a cascaded way.
As shown inFigure 2(b), while the parsing tree is being built,disfluency tags are predicted and attached to thedisfluency nodes.
Our models are quite efficientwith linear complexity of 2?N (N is the length ofinput).wasgreatwasgreatdidhedidroot rootNNN N NN XX(a) (b)heFigure 2: An instance of the detection procedurewhere ?N?
stands for a normal word and ?X?
a dis-fluency word.
Words with italic font are Reparan-dums.
(a) is the L2R detecting procedure and (b)is the R2L procedure.Intuitively, compared with previous syntax-based work such as (Honnibal and Johnson,2014) that uses left-to-right transition-based pars-ing (L2R parsing) model, our proposed approachsimplifies disfluency detection by sequentiallyprocessing each word, without going back to mod-ify the pre-built tree structure of disfluency words.As shown in Figure 2(a), the L2R parsing basedjoint approach needs to cut the pre-built depen-dency link between ?did?
and ?he?
when ?was?is identified as the repair of ?did?, which is neverneeded in our method as Figure 2(b).
Furthermore,our method overcomes the deficiency issue in de-coding of L2R parsing based joint method, mean-ing the number of parsing transitions for each hy-pothesis path is not identical to 2 ?N , which leadsto the failure of performing optimal search duringdecoding.
For example, the involvement of the ex-tra cut operation in Figure 2(a) destroys the com-petition scoring that accumulates over 2 ?N tran-sition actions among hypotheses in the standardtransition-based parsing.
Although the heuristicscore, such as the normalization of transition count(Honnibal and Johnson, 2014), can be introduced,the total scores of all hypotheses are still not sta-tistically comparable from a global view.We conduct the experiments on English Switch-board corpus.
The results show that our methodcan achieve a 85.1% f-score with a gain of 0.7point over state-of-the-art M3N labeling model in(Qian and Liu, 2013) and a gain of 1 point overstate-of-the-art joint model proposed in (Honnibaland Johnson, 2014).
We also apply our method onChinese annotated data.
As there is no availablepublic data in Chinese, we annotate 25k Chinesesentences manually for training and testing.
Weachieve 71.2% f-score with 15 points gained com-pared to the CRF-based baseline, showing that ourmodels are robust and language independent.2 Transition-based dependency parsingIn a typical transition-based parsing, the Shift-Reduce decoding algorithm is applied and a queueand stack are maintained (Zhang and Clark,2008).
The queue stores the stream of the inputand the front of the queue is indexed as the currentword.
The stack stores the unfinished words whichmay be linked to the current word or a future wordin the queue.
When words in the queue are con-sumed in sequential order, a set of transition ac-tions is applied to build a parsing tree.
There arefour kinds of transition actions in the parsing pro-cess (Zhang and Clark, 2008), as described below.?
Shift : Removes the front of the queue andpushes it to the stack.?
Reduce : Pops the top of the stack.?
LeftArc : Pops the top of the stack, and linksthe popped word to the front of the queue.?
RightArc : Links the front of the queue to thetop of the stack and, removes the front of thequeue and pushes it to the stack.The choice of each transition action during pars-ing is scored by a generalized perceptron (Collins,4962002) which can be trained over a rich set of non-local features.
In decoding, beam search is per-formed to search the optimal sequence of transi-tion actions.
As each word must be pushed to thestack once and popped off once, the number of ac-tions needed to parse a sentence is always 2 ?
N ,where N is the length of the sentence.Transition-based dependency parsing (Zhangand Clark, 2008) can be performed in either a left-to-right or a right-to-left way, both of which havea performance that is comparable as illustrated inSection 4.
However, when they are applied todisfluency detection, their behaviors are very dif-ferent due to the disfluency structure constraint.We prove that right-to-left transition-based parsingis more efficient than left-to-right transition-basedparsing for disfluency detection.3 Our method3.1 ModelUnlike previous joint methods (Honnibal andJohnson, 2014; Rasooli and Tetreault, 2013), weintroduce dependency parsing into disfluency de-tection from theory.
In the task of disfluencydetection, we are given a stream of unstructuredwords from automatic speech recognition (ASR).We denote the word sequence with Wn1:= w1,w2,w3,...,wn, which is actually the inverse order ofASR words that should be wn, wn?1,wn?2,...,w1.The output of the task is a sequence of binary tagsdenoted as Dn1= d1, d2,d3,...,dn, where each dicorresponds to wi, indicating whether wiis a dis-fluency word (X) or not (N).1Our task can be modeled as formula (1), whichis to search the best sequence D?given the streamof words Wn1.D?= argmaxDP (Dn1|Wn1) (1)The dependency parsing tree is introduced intomodel (1) to guide detection.
The rewritten for-mula is shown below:D?= argmaxD?TP (Dn1, T |Wn1) (2)We jointly optimize disfluency detection andparsing with form (3), rather than considering allpossible parsing trees:(D?, T?)
= argmax(D,T )P (Dn1, T |Wn1) (3)1We just use tag ?N?
to represent a normal word, in prac-tice normal words will not be tagged anything by default.As both the dependency tree and the disfluencytags are generated word by word, we decomposeformula (3) into:(D?, T?)
= argmax(D,T )n?i=1P (di, Ti1|Wi1, Ti?11)(4)where Ti1is the partial tree after word wiis con-sumed, diis the disfluency tag of wi.We simplify the joint optimization in a cascadedway with two different forms (5) and (6).
(D?, T?)
= argmax(D,T )n?i=1P (Ti1|Wi1, Ti?11)?
P (di|Wi1, Ti1) (5)(D?, T?)
= argmax(D,T )n?i=1P (di|Wi1, Ti?11)?
P (Ti1|Wi1, Ti?11, di) (6)Here, P (Ti1|.)
is the parsing model, and P (di|.)
isthe disfluency model used to predict the disluencytags on condition of the contexts of partial treesthat have been built.In (5), the parsing model is calculated first, fol-lowed by the calculation of the disfluency model.Inspired by (Zhang et al, 2013), we associate thedisfluency tags to the transition actions so that thecalculation of P (di|Wi1, Ti1) can be omitted as dican be inferred from the partial tree Ti1.
We thenget(D?, T?)
= argmax(D,T )n?i=1P (di, Ti1|Wi1, Ti?11)(7)Where the parsing and disfluency detection areunified into one model.
We refer to this model asthe Unified Transition(UT) model.While in (6), the disfluency model is calculatedfirst, followed by the calculation of the parsingmodel.
We model P (di|.)
as a binary classifier toclassify whether a word is disfluent or not.
We re-fer to this model as the binary classifier transition(BCT) model.3.2 Unified transition-based model (UT)In model (7), in addition to the standard 4 transi-tion actions mentioned in Section 2, the UT model497adds 2 new transition actions which extend theoriginal Shift and RightArc transitions as shownbelow:?
Dis Shift: Performs what Shift does thenmarks the pushed word as disfluent.?
Dis RightArc: Adds a virtual link from thefront of the queue to the top of the stackwhich is similar to Right Arc, marking thefront of the queue as disfluenct and pushingit to the stack.Figure 3 shows an example of how the UTmodel works.
Given an input ?he did great wasgreat?, the optimal parsing tree is predicted by theUT model.
According to the parsing tree, we canget the disfluency tags ?N X X N N?
which havebeen attached to each word.
To ensure the normalwords are built grammatical in the parse tree, weapply a constraint to the UT model.UT model constraint: When a word is markeddisfluent, all the words in its left and right sub-trees will be marked disfluent and all the links ofits descendent offsprings will be converted to vir-tual links, no matter what actions are applied tothese words.For example, the italic word ?great?
will bemarked disfluent, no matter what actions are per-formed on it.wasgreat did herootN NXNgreatXFigure 3: An example of UT model, where ?N?means the word is a fluent word and ?X?
means it isdisfluent.
Words with italic font are Reparandums.3.3 A binary classifier transition-basedmodel (BCT)In model (6), we perform the binary classifierand the parsing model together by augmentingthe Shift-Reduce algorithm with a binary classifiertransition(BCT) action:?
BCT : Classifies whether the current word isdisfluent or not.
If it is, remove it from thequeue, push it into the stack which is simi-lar to Shift and then mark it as disfluent, oth-erwise the original transition actions will beused.It is noted that when BCT is performed, the nextaction must be Reduce.
This constraint guaranteesthat any disfluent word will not have any descen-dent offspring.
Figure 2(b) shows an example ofthe BCT model.
When the partial tree ?great was?is built, the next word ?did?
is obviously disfluent.Unlike UT model, the BCT will not link the word?did?
to any word.
Instead only a virtual link willadd it to the virtual root.3.4 Training and decodingIn practice, we use the same linear model for bothmodels (6) and (7) to score a parsing tree as:Score(T ) =?action?
(action) ?~?Where ?
(action) is the feature vector extractedfrom partial hypothesis T for a certain action and~?
is the weight vector.
?
(action) ?~?
calculates thescore of a certain transition action.
The score of aparsing tree T is the sum of action scores.In addition to the basic features introduced in(Zhang and Nivre, 2011) that are defined over bagof words and POS-tags as well as tree-based con-text, our models also integrate three classes ofnew features combined with Brown cluster fea-tures (Brown et al, 1992) that relate to the right-to-left transition-based parsing procedure as de-tailed below.Simple repetition function?
?I(a, b): A logic function which indicateswhether a and b are identical.Syntax-based repetition function?
?L(a, b): A logic function which indicateswhether a is a left child of b.?
?R(a, b): A logic function which indicateswhether a is a right child of b.Longest subtree similarity function?
NI(a, b): The count of identical children onthe left side of the root node between subtreesrooted at a and b.?
N#(a0..n, b): The count of words among a0.. anthat are on the right of the subtree rootedat b.498Table 1 summarizes the features we use in themodel computation, where wsdenotes the topword of the stack, w0denotes the front word ofthe queue and w0..2denotes the top three words ofthe queue.
Every picorresponds to the POS-tagof wiand p0..2represents the POS-tags of w0..2.In addition, wic means the Brown cluster of wi.With these symbols, several new feature templatesare defined in Table 1.
Both our models have thesame feature templates.BasicfeaturesAll templates in (Zhang andNivre, 2011)New disfluency featuresFunctionunigrams?I(ws, w0);?I(ps, p0);?L(w0, ws);?L(p0, ps);?R(w0, ws);?R(p0, ps);NI(w0, ws);NI(p0, ps);N#(w0..2, ws);N#(p0..2, ps);Functionbigrams?I(ws, w0)?I(ps, p0);?L(w0, ws)?L(p0, ps);?R(w0, ws)?R(p0, ps);NI(w0, ws)NI(p0, ps);N#(w0..2, ws)N#(p0..2, ps);?I(ws, w0)wsc;?I(ws, w0)w0c;Functiontrigramswsw0?I(ws, w0);wsw0?I(ps, p0);Table 1: Feature templates designed for disfluencydetection and dependency parsing.Similar to the work in (Zhang and Clark, 2008;Zhang and Nivre, 2011), we train our models byaveraged perceptron (Collins, 2002).
In decod-ing, beam search is performed to get the optimalparsing tree as well as the tag sequence.4 Experiments4.1 Experimental setupOur training data is the Switchboard portion ofthe English Penn Treebank (Marcus et al, 1993)corpus, which consists of telephone conversationsabout assigned topics.
As not all the Switchboarddata has syntactic bracketing, we only use the sub-corpus of PAESED/MRG/SWBD.
Following theexperiment settings in (Charniak and Johnson,2001), the training subcorpus contains directories2 and 3 in PAESED/MRG/SWBD and directory4 is split into test and development sets.
We usethe Stanford dependency converter (De Marneffeet al, 2006) to get the dependency structure fromthe Switchboard corpus, as Honnibal and John-son (2014) prove that Stanford converter is robustto the Switchboard data.For our Chinese experiments, no public Chinesecorpus is available.
We annotate about 25k spo-ken sentences with only disfluency annotations ac-cording to the guideline proposed by Meteer et al(1995).
In order to generate similar data formatas English Switchboard corpus, we use Chinesedependency parsing trained on the Chinese Tree-bank corpus to parse the annotated data and usethese parsed data for training and testing .
For ourChinese experiment setting, we respectively selectabout 2k sentences for development and testing.The rest are used for training.To train the UT model, we create data for-mat adaptation by replacing the original Shift andRightArc of disfluent words with Dis Shift andDis RightArc, since they are just extensions ofShift and RightArc.
For the BCT model, disflu-ent words are directly depended to the root nodeand all their links and labels are removed.
Wethen link all the fluent children of disfluent wordsto parents of disfluent words.
We also removepartial words and punctuation from data to simu-late speech recognizer results where such informa-tion is not available (Johnson and Charniak, 2004).Additionally, following Honnibal and Johnson(2014), we remove all one token sentences as thesesentences are trivial for disfluency detection, thenlowercase the text and discard filled pauses like?um?
and ?uh?.The evaluation metrics of disfluency detectionare precision (Prec.
), recall (Rec.)
and f-score(F1).
For parsing accuracy metrics, we use unla-beled attachment score (UAS) and labeled attach-ment score (LAS).
For our primary comparison,we evaluate the widely used CRF labeling model,the state-of-the-art M3N model presented by Qianand Liu (2013) which has been commonly used asbaseline in previous works and the state-of-the-artL2R parsing based joint model proposed by Hon-nibal and Johnson (2014).4.2 Experimental results4.2.1 Performance of disfluency detection onEnglish Swtichboard corpusThe evaluation results of both disfluency detec-tion and parsing accuracy are presented in Table2.
The accuracy of M3N directly refers to the re-499Disfluency detection accuracy Parsing accuracyMethod Prec.
Rec.
F1 UAS LASCRF(BOW) 81.2% 44.9% 57.8% 88.7% 84.7%CRF(BOW+POS) 88.3% 62.2% 73.1% 89.2% 85.6%M3N N/A N/A 84.1% N/A N/AM3N?90.5% 79.1% 84.4% 91% 88.2%H&J N/A N/A 84.1% 90.5% N/AUT(basic features) 86% 72.5% 78.7% 91.9% 89.0%UT(+new features) 88.8% 75.1% 81.3% 92.1% 89.4%BCT(basic features) 88.2% 77.9% 82.7% 92.1% 89.3%BCT(+new features) 90.3% 80.5% 85.1% 92.2% 89.6%Table 2: Disfluency detection and parsing accuracies on English Switchboard data.
The accuracy ofM3N refers to the result reported in (Qian and Liu, 2013).
H&J is the L2R parsing based joint model in(Honnibal and Johnson, 2014).
The results of M3N?come from the experiments with toolkit released byQian and Liu (2013) on our pre-processed corpus.sults reported in (Qian and Liu, 2013).
The re-sults of M3N?come from our experiments with thetoolkit2released by Qian and Liu (2013) whichuses our data set with the same pre-processing.
Itis comparable between our models and the L2Rparsing based joint model presented by Honni-bal and Johnson (2014), as we all conduct experi-ments on the same pre-processed data set.
In orderto compare parsing accuracy, we use the CRF andM3N?model to pre-process the test set by remov-ing all the detected disfluencies, then evaluate theparsing performance on the processed set.
Fromthe table, our BCT model with new disfluency fea-tures achieves the best performance on disfluencydetection as well as dependency parsing.The performance of the CRF model is low, be-cause the local features are not powerful enoughto capture long span disfluencies.
Our main com-parison is with the M3N?labeling model and theL2R parsing based model by Honnibal and John-son (2014).
As illustrated in Table 2, the BCTmodel outperforms the M3N?model (we got anaccuracy of 84.4%, though 84.1% was reportedin their paper) and the L2R parsing based modelrespectively by 0.7 point and 1 point on disflu-ency detection, which shows our method can ef-ficiently tackle disfluencies.
This is because ourmethod can cater extremely well to the disfluencyconstraint and perform optimal search with iden-tical transition counts over all hypotheses in beamsearch.
Furthermore, our global syntactic and dis-2The toolkit is available athttps://code.google.com/p/disfluency-detection/downloads.fluency features can help capture long-range de-pendencies for disfluency detection.
However, theUT model does not perform as well as BCT.
Thisis because the UT model suffers from the riskthat normal words may be linked to disfluencieswhich may bring error propagation in decoding.In addition our models with only basic featuresrespectively score about 3 points below the mod-els adding new features, which shows that thesefeatures are important for disfluency detection.
Incomparing parsing accuracy, our BCT model out-performs all the other models, showing that thismodel is more robust on disfluent parsing.4.2.2 Performance of disfluency detection ondifferent part-of-speechesIn this section, we further analyze the frequencyof different part-of-speeches in disfluencies andtest the performance on different part-of-speeches.Five classes of words take up more than 73% ofall disfluencies as shown in Table 3, which arepronouns (contain PRP and PRP$), verbs (con-tain VB,VBD,VBP,VBZ,VBN), determiners (con-tain DT), prepositions (contain IN) and conjunc-tions (contain CC).
Obviously, these classes ofwords appear frequently in our communication.Pron.
VerbDete.Prep.
Conj.
OthersDist.
30.2% 14.7% 13% 8.7% 6.7% 26.7%Table 3: Distribution of different part-of-speeches in disfluencies.
Conj.=conjunction;Dete.=determiner; Pron.=pronoun; Prep.= prepo-sition.500Table 4 illustrates the performance (f-score) onthese classes of words.
The results of L2R pars-ing based joint model in (Honnibal and Johnson,2014) are not listed because we cannot get suchdetailed data.CRF(BOW)CRF(BOW+POS)M3N?UT(+feat.)BCT(+feat.)Pron.
73.9% 85% 92% 91.5% 93.8%Verb 38.2% 64.8% 84.2% 82.3% 84.7%Dete.
66.8% 80% 88% 83.7% 87%Prep.
60% 71.5% 79.1% 76.1% 79.3%Conj.
75.2% 82.2% 81.6% 79.5% 83.2%Others 43.2% 61% 78.4% 72.3% 79.1%Table 4: Performance on different classesof words.
Dete.=determiner; Pron.=pronoun;Conj.=conjunction; Prep.= preposition.
feat.=newdisfluency featuresAs shown in Table 4, our BCT model outper-forms all other models except that the performanceon determiner is lower than M3N?, which showsthat our algorithm can significantly tackle com-mon disfluencies.4.2.3 Performance of disfluency detection onChinese annotated corpusIn addition to English experiments, we also applyour method on Chinese annotated data.
As thereis no standard Chinese corpus, no Chinese experi-mental results are reported in (Honnibal and John-son, 2014; Qian and Liu, 2013).
We only use theCRF-based labeling model with lexical and POS-tag features as baselines.
Table 5 shows the resultsof Chinese disfluency detection.Model Prec.
Rec.
F1CRF(BOW) 89.5% 35.6% 50.9%CRF(BOW+POS) 83.4% 41.6% 55.5%UT(+new features) 86.7% 59.5% 70.6%BCT(+new features) 85.5% 61% 71.2%Table 5: Disfluency detection performance onChinese annotated data.Our models outperform the CRF model withbag of words and POS-tag features by more than15 points on f-score which shows that our methodis more effective.
As shown latter in 4.2.4, thestandard transition-based parsing is not robust inparsing disfluent text.
There are a lot of parsing er-rors in Chinese training data.
Even though we arestill able to get promising results with less data andun-golden parsing annotations.
We believe that ifwe were to have the golden Chinese syntactic an-notations and more data, we would get much betterresults.4.2.4 Performance of transition-basedparsingIn order to show whether the advantage of the BCTmodel is caused by the disfluency constraint or thedifference between R2L and L2R parsing models,in this section, we make a comparison between theoriginal left-to-right transition-based parsing andright-to-left parsing.
These experiments are per-formed with the Penn Treebank (PTB) Wall StreetJournal (WSJ) corpus.
We follow the standard ap-proach to split the corpus as 2-21 for training, 22for development and section 23 for testing (Mc-Donald et al, 2005).
The features for the twoparsers are basic features in Table 1.
The POS-tagger model that we implement for a pre-processbefore parsing also uses structured perceptron fortraining and can achieve a competitive accuracy of96.7%.
The beam size for both POS-tagger andparsing is set to 5.
Table 6 presents the results onWSJ test set and Switchboard (SWBD) test set.Data sets Model UAS LASWSJ L2R Parsing 92.1% 89.8%R2L Parsing 92.0% 89.6%SWBD L2R Parsing 88.4% 84.4%R2L Parsing 88.7% 84.8%Table 6: Performance of our parsers on differenttest sets.The parsing accuracy on SWBD is lower thanWSJ which means that the parsers are more robuston written text data.
The performances of R2L andL2R parsing are comparable on both SWBD andWSJ test sets.
This demonstrates that the effec-tiveness of our disfluency detection model mainlyrelies on catering to the disfluency constraint byusing R2L parsing based approach, instead of thedifference in parsing models between L2R andR2L parsings.5 Related workIn practice, disfluency detection has been exten-sively studied in both speech processing field andnatural language processing field.
Noisy channelmodels have been widely used in the past to detect501disfluencies.
Johnson and Charniak (2004) pro-posed a TAG-based noisy channel model wherethe TAG model was used to find rough copies.Thereafter, a language model and MaxEnt re-ranker were added to the noisy channel modelby Johnson et al (2004).
Following their frame-work, Zwarts and Johnson (2011) extended thismodel using minimal expected f-loss oriented n-best reranking with additional corpus for languagemodel training.Recently, the max-margin markov networks(M3N) based model has achieved great improve-ment in this task.
Qian and Liu (2013) presenteda multi-step learning method using weighted M3Nmodel for disfluency detection.
They showed thatM3N model outperformed many other labelingmodels such as CRF model.
Following this work,Wang et al (2014) used a beam-search decoder tocombine multiple models such as M3N and lan-guage model, they achieved the highest f-score.However, direct comparison with their work is dif-ficult as they utilized the whole SWBD data whilewe only use the subcorpus with syntactic annota-tion which is only half the SWBD corpus and theyalso used extra corpus for language model train-ing.Additionally, syntax-based approaches havebeen proposed which concern parsing and dis-fluency detection together.
Lease and Johnson(2006) involved disfluency detection in a PCFGparser to parse the input along with detecting dis-fluencies.
Miller and Schuler (2008) used a rightcorner transform of syntax trees to produce a syn-tactic tree with speech repairs.
But their perfor-mance was not as good as labeling models.
Thereexist two methods published recently which aresimilar to ours.
Rasooli and Tetreault (2013) de-signed a joint model for both disfluency detectionand dependency parsing.
They regarded the twotasks as a two step classifications.
Honnibal andJohnson (2014) presented a new joint model by ex-tending the original transition actions with a new?Edit?
transition.
They achieved the state-of-the-art performance on both disfluency detection andparsing.
But this model suffers from the problemthat the number of transition actions is not identi-cal for different hypotheses in decoding, leading tothe failure of performing optimal search.
In con-trast, our novel right-to-left transition-based jointmethod caters to the disfluency constraint whichcan not only overcome the decoding deficiency inprevious work but also achieve significantly higherperformance on disfluency detection as well as de-pendency parsing.6 Conclusion and Future WorkIn this paper, we propose a novel approach fordisfluency detection.
Our models jointly performparsing and disfluency detection from right to leftby integrating a rich set of disfluency featureswhich can yield parsing structure and difluencytags at the same time with linear complexity.
Thealgorithm is easy to implement without compli-cated backtrack operations.
Experiential resultsshow that our approach outperforms the baselineson the English Switchboard corpus and experi-ments on the Chinese annotated corpus also showthe language independent nature of our method.The state-of-the-art performance on disfluency de-tection and dependency parsing can benefit thedownstream tasks of text processing.In future work, we will try to add new classes offeatures to further improve performance by cap-turing the property of disfluencies.
We wouldalso like to make an end-to-end MT test overtranscribed speech texts with disfluencies removedbased on the method proposed in this paper.AcknowledgmentsWe are grateful to the anonymous reviewers fortheir insightful comments.
We also thank Mu Li,Shujie Liu, Lei Cui and Nan Yang for the helpfuldiscussions.ReferencesPeter F Brown, Peter V Desouza, Robert L Mercer,Vincent J Della Pietra, and Jenifer C Lai.
1992.Class-based n-gram models of natural language.Computational linguistics, 18(4):467?479.Eugene Charniak and Mark Johnson.
2001.
Edit detec-tion and parsing for transcribed speech.
In Proceed-ings of the second meeting of the North AmericanChapter of the Association for Computational Lin-guistics on Language technologies, pages 1?9.
As-sociation for Computational Linguistics.Michael Collins.
2002.
Discriminative training meth-ods for hidden markov models: Theory and exper-iments with perceptron algorithms.
In Proceedingsof the ACL-02 conference on Empirical methods innatural language processing-Volume 10, pages 1?8.Association for Computational Linguistics.502Marie-Catherine De Marneffe, Bill MacCartney,Christopher D Manning, et al 2006.
Generat-ing typed dependency parses from phrase structureparses.
In Proceedings of LREC, volume 6, pages449?454.Kallirroi Georgila.
2009.
Using integer linear pro-gramming for detecting speech disfluencies.
In Pro-ceedings of Human Language Technologies: The2009 Annual Conference of the North AmericanChapter of the Association for Computational Lin-guistics, Companion Volume: Short Papers, pages109?112.
Association for Computational Linguis-tics.Matthew Honnibal and Mark Johnson.
2014.
Jointincremental disfluency detection and dependencyparsing.
Transactions of the Association for Com-putational Linguistics, 2:131?142.Mark Johnson and Eugene Charniak.
2004.
A tag-based noisy channel model of speech repairs.
InProceedings of the 42nd Annual Meeting on Asso-ciation for Computational Linguistics, page 33.
As-sociation for Computational Linguistics.Mark Johnson, Eugene Charniak, and Matthew Lease.2004.
An improved model for recognizing disflu-encies in conversational speech.
In Proceedings ofRich Transcription Workshop.Jeremy G Kahn, Matthew Lease, Eugene Charniak,Mark Johnson, and Mari Ostendorf.
2005.
Effectiveuse of prosody in parsing conversational speech.
InProceedings of the conference on human languagetechnology and empirical methods in natural lan-guage processing, pages 233?240.
Association forComputational Linguistics.Matthew Lease and Mark Johnson.
2006.
Early dele-tion of fillers in processing conversational speech.In Proceedings of the Human Language Technol-ogy Conference of the NAACL, Companion Volume:Short Papers, pages 73?76.
Association for Compu-tational Linguistics.Yang Liu, Elizabeth Shriberg, Andreas Stolcke, DustinHillard, Mari Ostendorf, and Mary Harper.
2006.Enriching speech recognition with automatic detec-tion of sentence boundaries and disfluencies.
Audio,Speech, and Language Processing, IEEE Transac-tions on, 14(5):1526?1540.Mitchell P Marcus, Mary Ann Marcinkiewicz, andBeatrice Santorini.
1993.
Building a large anno-tated corpus of english: The penn treebank.
Compu-tational linguistics, 19(2):313?330.Ryan McDonald, Koby Crammer, and FernandoPereira.
2005.
Online large-margin training of de-pendency parsers.
In Proceedings of the 43rd an-nual meeting on association for computational lin-guistics, pages 91?98.
Association for Computa-tional Linguistics.Marie W Meteer, Ann A Taylor, Robert MacIntyre,and Rukmini Iyer.
1995.
Dysfluency annotationstylebook for the switchboard corpus.
University ofPennsylvania.Tim Miller and William Schuler.
2008.
A unified syn-tactic model for parsing fluent and disfluent speech.In Proceedings of the 46th Annual Meeting of the As-sociation for Computational Linguistics on HumanLanguage Technologies: Short Papers, pages 105?108.
Association for Computational Linguistics.Xian Qian and Yang Liu.
2013.
Disfluency detectionusing multi-step stacked learning.
In HLT-NAACL,pages 820?825.Mohammad Sadegh Rasooli and Joel R Tetreault.2013.
Joint parsing and disfluency detection in lin-ear time.
In EMNLP, pages 124?129.Xuancong Wang, Hwee Tou Ng, and Khe Chai Sim.2014.
A beam-search decoder for disfluency detec-tion.
In Proc.
of COLING.Yue Zhang and Stephen Clark.
2008.
A tale oftwo parsers: investigating and combining graph-based and transition-based dependency parsing us-ing beam-search.
In Proceedings of the Conferenceon Empirical Methods in Natural Language Pro-cessing, pages 562?571.
Association for Computa-tional Linguistics.Yue Zhang and Joakim Nivre.
2011.
Transition-baseddependency parsing with rich non-local features.
InProceedings of the 49th Annual Meeting of the Asso-ciation for Computational Linguistics: Human Lan-guage Technologies: short papers-Volume 2, pages188?193.
Association for Computational Linguis-tics.Qi Zhang, Fuliang Weng, and Zhe Feng.
2006.
A pro-gressive feature selection algorithm for ultra largefeature spaces.
In Proceedings of the 21st Interna-tional Conference on Computational Linguistics andthe 44th annual meeting of the Association for Com-putational Linguistics, pages 561?568.
Associationfor Computational Linguistics.Dongdong Zhang, Shuangzhi Wu, Nan Yang, andMu Li.
2013.
Punctuation prediction withtransition-based parsing.
In ACL (1), pages 752?760.Simon Zwarts and Mark Johnson.
2011.
The impact oflanguage models and loss functions on repair disflu-ency detection.
In Proceedings of the 49th AnnualMeeting of the Association for Computational Lin-guistics: Human Language Technologies-Volume 1,pages 703?711.
Association for Computational Lin-guistics.503
