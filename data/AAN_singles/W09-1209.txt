Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL): Shared Task, pages 61?66,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsMultilingual Dependency Learning:Exploiting Rich Features for Tagging Syntactic and Semantic DependenciesHai Zhao(??
)?, Wenliang Chen(???
)?,Jun?ichi Kazama?, Kiyotaka Uchimoto?, and Kentaro Torisawa?
?Department of Chinese, Translation and LinguisticsCity University of Hong Kong83 Tat Chee Avenue, Kowloon, Hong Kong, China?Language Infrastructure Group, MASTAR ProjectNational Institute of Information and Communications Technology3-5 Hikari-dai, Seika-cho, Soraku-gun, Kyoto, Japan, 619-0289haizhao@cityu.edu.hk, chenwl@nict.go.jpAbstractThis paper describes our system about mul-tilingual syntactic and semantic dependencyparsing for our participation in the joint taskof CoNLL-2009 shared tasks.
Our systemuses rich features and incorporates various in-tegration technologies.
The system is evalu-ated on in-domain and out-of-domain evalu-ation data of closed challenge of joint task.For in-domain evaluation, our system ranksthe second for the average macro labeled F1 ofall seven languages, 82.52% (only about 0.1%worse than the best system), and the first forEnglish with macro labeled F1 87.69%.
Andfor out-of-domain evaluation, our system alsoachieves the second for average score of allthree languages.1 IntroductionThis paper describes the system of National In-stitute of Information and Communications Tech-nology (NICT) and City University of Hong Kong(CityU) for the joint learning task of CoNLL-2009shared task (Hajic?
et al, 2009)1.
The system is ba-sically a pipeline of syntactic parser and semanticparser.
We use a syntactic parser that uses very richfeatures and integrates graph- and transition-basedmethods.
As for the semantic parser, a group of wellselected feature templates are used with n-best syn-tactic features.1Our thanks give to the following corpus providers, (Taule?et al, 2008; Palmer and Xue, 2009; Hajic?
et al, 2006; Surdeanuet al, 2008; Burchardt et al, 2006) and (Kawahara et al, 2002).The rest of the paper is organized as follows.
Thenext section presents the technical details of our syn-tactic dependency parsing.
Section 3 describes thedetails of the semantic dependency parsing.
Section4 shows the evaluation results.
Section 5 looks into afew issues concerning our forthcoming work for thisshared task, and Section 6 concludes the paper.2 Syntactic Dependency ParsingBasically, we build our syntactic dependency parsersbased on the MSTParser, a freely available imple-mentation2, whose details are presented in the paperof McDonald and Pereira (2006).
Moreover, we ex-ploit rich features for the parsers.
We represent fea-tures by following the work of Chen et al (2008) andKoo et al (2008) and use features based on depen-dency relations predicted by transition-based parsers(Nivre and McDonald, 2008).
Chen et al (2008) andKoo et al (2008) proposed the methods to obtainnew features from large-scale unlabeled data.
In oursystem, we perform their methods on training databecause the closed challenge does not allow to useunlabeled data.
In this paper, we call these new ad-ditional features rich features.2.1 Basic FeaturesFirstly, we use all the features presented by McDon-ald et al (2006), if they are available in data.
Thenwe add new features for the languages having FEATinformation (Hajic?
et al, 2009).
FEAT is a set ofmorphological-features, e.g.
more detailed part ofspeech, number, gender, etc.
We try to align differ-ent types of morphological-features.
For example,2http://mstparser.sourceforge.net61we can obtain a sequence of gender tags of all wordsfrom a head h to its dependent d. Then we representthe features based on the obtained sequences.Based on the results of development data, we per-form non-projective parsing for Czech and Germanand perform projective parsing for Catalan, Chinese,English, Japanese, and Spanish.2.2 Features Based on Dependency PairsI    see    a    beautiful    bird    .Figure 1: Example dependency graph.Chen et al (2008) presented a method of extract-ing short dependency pairs from large-scale auto-parsed data.
Here, we extract all dependency pairsrather than short dependency pairs from trainingdata because we believe that training data are reli-able.
In a parsed sentence, if two words have de-pendency relation, we add this word pair into a listnamed L and count its frequency.
We consider thedirection.
For example, in figure 1, a and bird havedependency relation in the sentence ?I see a beauti-ful bird.?.
Then we add word pair ?a-bird:HEAD?3into list L and accumulate its frequency.We remove the pairs which occur only once intraining data.
According to frequency, we thengroup word pairs into different buckets, with bucketLOW for frequencies 2-7, bucket MID for frequen-cies 8-14, and bucket HIGH for frequencies 15+.We set these threshold values by following the set-ting of Chen et al (2008).
For example, the fre-quency of pair ?a-bird:HEAD?
is 5.
Then it isgrouped into bucket ?LOW?.
We also add a vir-tual bucket ?ZERO?
to represent the pairs that arenot included in the list.
So we have four buckets.
?ZERO?, ?LOW?, ?MID?, and ?HIGH?
are used asbucket IDs.Based on the buckets, we represent new featuresfor a head h and its dependent d. We check wordpairs surrounding h and d. Table 1 shows the wordpairs, where h-word refers to the head word, d-wordrefers to the dependent word, h-word-1 refers to3HEAD means that bird is the head of the pair.the word to the left of the head in the sentence, h-word+1 refers to the word to the right of the head,d-word-1 refers to the word to the left of the depen-dent, and d-word+1 refers the word to the right ofthe dependent.
Then we obtain the bucket IDs ofthese word pairs from L.We generate new features consisting of indicatorfunctions for bucket IDs of word pairs.
We call thesefeatures word-pair-based features.
We also generatecombined features involving bucket IDs and part-of-speech tags of heads.h-word, d-wordh-word-1, d-wordh-word+1, d-wordh-word, d-word-1h-word, d-word+1Table 1: Word pairs for feature representation2.3 Features Based on Word ClustersKoo et al (2008) presented new features based onword clusters obtained from large-scale unlabeleddata and achieved large improvement for Englishand Czech.
Here, word clusters are generated onlyfrom the training data for all the languages.
We per-form word clustering by using the clustering tool4,which also was used by Koo et al (2008).
Thecluster-based features are the same as the ones usedby Koo et al (2008).2.4 Features Based on Predicted RelationsNivre and McDonald (2008) presented an integrat-ing method to provide additional information forgraph-based and transition-based parsers.
Here, werepresent features based on dependency relationspredicted by transition-based parsers for graph-based parser.
Based on the results on developmentdata, we choose the MaltParser for Catalan, Czech,German, and Spanish, and choose another MaxEnt-based parser for Chinese, English, and Japanese.2.4.1 A Transition-based Parser: MaltParserFor Catalan, Czech, German, and Spanish, weuse the MaltParser, a freely available implementa-4http://www.cs.berkeley.edu/?pliang/software/brown-cluster-1.2.zip62tion5, whose details are presented in the paper ofNivre (2003).
More information about the parser canbe available in the paper (Nivre, 2003).Due to computational cost, we do not select newfeature templates for the MaltParser.
Following thefeatures settings of Hall et al (2007), we use theirCzech feature file and Catalan feature file.
To sim-ply, we apply Czech feature file for German too, andapply Catalan feature file for Spanish.2.4.2 Another Transition-based Parser:MaxEnt-based ParserIn three highly projective language, Chinese,English and Japanese, we use the maximum en-tropy syntactic dependency parser as in Zhao andKit (2008).
We still use the similar feature notationsof that work.
We use the same greedy feature selec-tion of Zhao et al (2009) to determine an optimalfeature template set for each language.
Full featuresets for the three languages can be found at website,http://bcmi.sjtu.edu.cn/?zhaohai.2.4.3 Feature RepresentationFor training data, we use 2-way jackknifing togenerate predicted dependency parsing trees by twotransition-based parsers.
Following the features ofNivre and McDonald (2008), we define features fora head h and its dependent d with label l as shown intable 2, where GTran refers to dependency parsingtrees generated by the MaltParser or MaxEnt-baseParser and ?
refers to any label.
All features areconjoined with the part-of-speech tags of the wordsinvolved in the dependency.Is (h, d, ?)
in GTran?Is (h, d, l) in GTran?Is (h, d, ?)
not in GTran?Is (h, d, l) not in GTran?Table 2: Features set based on predicted labels3 n-best Syntactic Features for SemanticDependency ParsingDue to the limited computational resource that wehave, we used the the similar learning framework asour participant in semantic-only task (Zhao et al,5http://w3.msi.vxu.se/?nivre/research/MaltParser.htmlNormal n-best MatchedCa 53 54 50Ch 75 65 55En 73 70 63Table 3: Feature template sets:n-best vs. non-n-best2009).
Namely, three languages, a single maximumentropy model is used for all identification and clas-sification tasks of predicate senses or argument la-bels in four languages, Catalan, Czech, Japanese, orSpanish.
For the rest three languages, an individualsense classifier still using maximum entropy is ad-ditionally used to output the predicate sense previ-ously.
More details about argument candidate prun-ing strategies and feature template set selection aredescribed in Zhao et al (2009).The same feature template sets as the semantic-only task are used for three languages, Czech, Ger-man and Japanese.
For the rest four languages, wefurther use n-best syntactic features to strengthensemantic dependency parsing upon those automati-cally discovered feature template sets.
However, wecannot obtain an obvious performance improvementin Spanish by using n-best syntactic features.
There-fore, only Catalan, Chinese and English semanticparsing adopted these types of features at last.Our work about n-best syntactic features stillstarts from the feature template set that is originallyselected for the semantic-only task.
The original fea-ture template set is hereafter referred to ?the normal?or ?non-n-best?.
In practice, only 2nd-best syntacticoutputs are actually adopted by our system for thejoint task.To generate helpful feature templates from the2nd-best syntactic tree, we simply let al feature tem-plates in the normal feature set that are based onthe 1st-best syntactic tree now turn to the 2nd-bestone.
Using the same notations for feature templaterepresentation as in Zhao et al (2009), we take anexample to show how the original n-best featuresare produced.
Assuming a.children.dprel.bag isone of syntactic feature templates in the normalset, this feature means that all syntactic children ofthe argument candidate (a) are chosen, and theirdependant labels are collected, the duplicated la-bels are removed and then sorted, finally all thesestrings are concatenated as a feature.
The cor-63Language FeaturesCatalan p:2.lm.dprela.lemma + a:2.h.forma.lemma + a:2.pphead.form(a:2:p:2|dpPath.dprel.seq) + p.FEAT1Chinese a:2.h.posa:2.children.pos.seq + p:2.children.pos.seqa:2:p:2|dpPath.dprel.baga:2:p:2|dpPathPred.form.seqa:2:p:2|dpPath.pos.bag(a:2:p:2|dpTreeRelation) + p.pos(a:2:p:2|dpPath.dprel.seq) + a.posEnglish a:2:p:2|dpPathPred.lemma.baga:2:p:2|dpPathPred.pos.baga:2:p:2|dpTreeRelationa:2:p:2|dpPath.dprel.seqa:2:p:2|dpPathPred.dprel.seqa.lemma + a:2.dprel + a:2.h.lemma(a:2:p:2|dpTreeRelation) + p.posTable 4: Features for n-best syntactic treeresponding 2nd-best syntactic feature will be a :2.children.dprel.bag.
As all operations to gener-ate the feature for a.children.dprel.bag is withinthe 1st-best syntactic tree, while those for a :2.children.dprel.bag is within the 2nd-best one.
Asall these 2nd-best syntactic features are generated,we use the same greedy feature selection procedureas in Zhao et al (2009) to determine the best fit fea-ture template set according to the evaluation resultsin the development set.For Catalan, Chinese and English, three opti-mal n-best feature sets are obtained, respectively.Though dozens of n-best features are initially gen-erated for selection, only few of them survive af-ter the greedy selection.
A feature number statis-tics is in Table 3, and those additionally selectedn-best features for three languages are in Table4.
Full feature lists and their explanation forall languages will be available at the website,http://bcmi.sjtu.edu.cn/?zhaohai.4 Evaluation ResultsTwo tracks (closed and open challenges) are pro-vided for joint task of CoNLL2009 shared task.We participated in the closed challenge and evalu-ated our system on the in-domain and out-of-domainevaluation data.avg.
Cz En GrSyntactic (LAS) 77.96 75.58 82.38 75.93Semantic (Labeled F1) 75.01 82.66 74.58 67.78Joint (Macro F1) 76.51 79.12 78.51 71.89Table 6: The official results of our submission for out-of-domain task(%)Test DevBasic ALL Basic ALLCatalan 82.91 85.88 83.15 85.98Chinese 74.28 75.67 73.36 75.64Czech 77.21 79.70 77.91 80.22English 88.63 89.19 86.35 87.40German 84.61 86.24 83.99 85.44Japanese 92.31 92.32 92.01 92.85Spanish 83.59 86.29 83.73 86.22Average 83.32 85.04 82.92 84.82(+1.72) (+1.90)Table 7: The effect of rich features for syntactic depen-dency parsing4.1 Official ResultsThe official results for the joint task are in Table 5,and the out-of-domain task in Table 6, where num-bers in bold stand for the best performances for thespecific language.
For out-of-domain (OOD) eval-uation, we did not perform any domain adaptation.For both in-domain and out-of-domain evaluation,our system achieved the second best performancefor the average Macro F1 scores of all the languages.And our system provided the first best performancefor the average Semantic Labeled F1 score and theforth for the average Labeled Syntactic Accuracyscore for in-domain evaluation.4.2 Further resultsAt first, we check the effect of rich features for syn-tactic dependency parsing.
Table 7 shows the com-parative results of basic features and all features ontest and development data, where ?Basic?
refers tothe system with basic features and ?ALL?
refers tothe system with basic features plus rich features.
Wefound that the additional features provided improve-ment of 1.72% for test data and 1.90% for develop-ment data.Then we investigate the effect of different train-ing data size for semantic parsing.
The learning64average Catalan Chinese Czech English German Japanese SpanishSyntactic (LAS) 85.04 85.88 75.67 79.70 89.19 86.24 92.32 86.29Semantic (Labeled F1) 79.96 80.10 76.77 82.04 86.15 76.19 78.17 80.29Joint (Macro F1) 82.52 83.01 76.23 80.87 87.69 81.22 85.28 83.31Table 5: The official results of our joint submission (%)Data Czech Chinese Englishnormal n-best normal n-best25% 80.71 75.12 75.24 82.02 82.0650% 81.52 76.50 76.59 83.52 83.4275% 81.90 76.92 77.01 84.21 84.30100% 82.24 77.35 77.34 84.73 84.80Table 8: The performance in development set (semanticlabeled F1) vs. training corpus sizecurves are drawn for Czech, Chinese and English.We use 25%, 50% and 75% training corpus, respec-tively.
The results in development sets are given inTable 8.
Note that in this table the differences be-tween normal and n-best feature template sets arealso given for Chinese and English.
The resultsin the table show that n-best features help improveChinese semantic parsing as the training corpus issmaller, while it works for English as the trainingcorpus is larger.5 DiscussionThis work shows our further endeavor in syntacticand semantic dependency parsing, based on our pre-vious work (Chen et al, 2008; Zhao and Kit, 2008).Chen et al (Chen et al, 2008) and Koo et al (Kooet al, 2008) used large-scale unlabeled data to im-prove syntactic dependency parsing performance.Here, we just performed their method on trainingdata.
From the results, we found that the new fea-tures provided better performance.
In future work,we can try these methods on large-scale unlabeleddata for other languages besides Chinese and En-glish.In Zhao and Kit (2008), we addressed that seman-tic parsing should benefit from cross-validated train-ing corpus and n-best syntactic output.
These twoissues have been implemented during this sharedtask.
Though existing work show that re-ranking forsemantic-only or syntactic-semantic joint tasks maybring higher performance, the limited computationalresources does not permit us to do this for multiplelanguages.To analyze the advantage and the weakness of oursystem, the ranks for every languages of our sys-tem?s outputs are given in Table 9, and the perfor-mance differences between our system and the bestone in Table 106.
The comparisons in these two ta-bles indicate that our system is slightly weaker in thesyntactic parsing part, this may be due to the reasonthat syntactic parsing in our system does not ben-efit from semantic parsing as the other joint learn-ing systems.
However, considering that the seman-tic parsing in our system simply follows the outputof the syntactic parsing and the semantic part of oursystem still ranks the first for the average score, thesemantic part of our system does output robust andstable results.
It is worth noting that semantic la-beled F1 in Czech given by our system is 4.47%worse than the best one.
This forby gap in this lan-guage further indicates the advantage of our systemin the other six languages and some latent bugs orlearning framework misuse in Czech semantic pars-ing.6 ConclusionWe describe the system that uses rich features andincorporates integrating technology for joint learn-ing task of syntactic and semantic dependency pars-ing in multiple languages.
The evaluation resultsshow that our system is good at both syntactic andsemantic parsing, which suggests that a feature-oriented method is effective in multiple languageprocessing.ReferencesAljoscha Burchardt, Katrin Erk, Anette Frank, AndreaKowalski, Sebastian Pado?, and Manfred Pinkal.
2006.6The difference for Chinese in the latter table is actuallycomputed between ours and the second best system.65average Catalan Chinese Czech English German Japanese SpanishSyntactic (LAS) 4 4 4 4 2 3 3 4Semantic (Labeled F1) 1 1 3 4 1 2 2 1Joint (Macro F1) 2 1 3 4 1 3 2 1Table 9: Our system?s rank within the joint task according to three main measuresaverage Catalan Chinese Czech English German Japanese SpanishSyntactic (LAS) 0.73 1.98 0.84 0.68 0.69 1.24 0.25 1.35Semantic (Labeled F1) - - 0.38 4.47 - 2.42 0.09 -Joint (Macro F1) 0.12 - 0.15 2.40 - 1.22 0.37 -Table 10: The performance differences between our system and the best one within the joint task according to threemain measuresThe SALSA corpus: a German corpus resource forlexical semantics.
In Proceedings of LREC-2006,Genoa, Italy.Wenliang Chen, Daisuke Kawahara, Kiyotaka Uchimoto,Yujie Zhang, and Hitoshi Isahara.
2008.
Dependencyparsing with short dependency relations in unlabeleddata.
In Proceedings of IJCNLP-2008, Hyderabad, In-dia, January 8-10.Jan Hajic?, Jarmila Panevova?, Eva Hajic?ova?, PetrSgall, Petr Pajas, Jan S?te?pa?nek, Jir???
Havelka, MarieMikulova?, and Zdene?k Z?abokrtsky?.
2006.
Prague De-pendency Treebank 2.0.Jan Hajic?, Massimiliano Ciaramita, Richard Johans-son, Daisuke Kawahara, Maria Anto`nia Mart?
?, Llu?
?sMa`rquez, Adam Meyers, Joakim Nivre, SebastianPado?, Jan S?te?pa?nek, Pavel Stran?a?k, Mihai Surdeanu,Nianwen Xue, and Yi Zhang.
2009.
The CoNLL-2009 shared task: Syntactic and semantic dependen-cies in multiple languages.
In Proceedings of CoNLL-2009, Boulder, Colorado, USA.Johan Hall, Jens Nilsson, Joakim Nivre, Gu?lsen Eryig?it,Bea?ta Megyesi, Mattias Nilsson, and Markus Saers.2007.
Single malt or blended?
a study in multilingualparser optimization.
In Proceedings of the CoNLLShared Task Session of EMNLP-CoNLL 2007, pages933?939, Prague, Czech, June.Daisuke Kawahara, Sadao Kurohashi, and Ko?iti Hasida.2002.
Construction of a Japanese relevance-taggedcorpus.
In Proceedings of LREC-2002, pages 2008?2013, Las Palmas, Canary Islands.Terry Koo, Xavier Carreras, and Michael Collins.
2008.Simple semi-supervised dependency parsing.
In Pro-ceedings of ACL-08: HLT, pages 595?603, Columbus,Ohio, USA, June.Ryan McDonald and Fernando Pereira.
2006.
On-line learning of approximate dependency parsing algo-rithms.
In Proceedings of EACL-2006, pages 81?88,Trento, Italy, April.Ryan McDonald, Kevin Lerman, and Fernando Pereira.2006.
Multilingual dependency analysis with a two-stage discriminative parser.
In Proceedings of CoNLL-X, New York City, June.Joakim Nivre and Ryan McDonald.
2008.
Integratinggraph-based and transition-based dependency parsers.In Proceedings of ACL-08: HLT, pages 950?958,Columbus, Ohio, June.Joakim Nivre.
2003.
An efficient algorithm for projec-tive dependency parsing.
In Proceedings of the 8th In-ternational Workshop on Parsing Technologies (IWPT03), pages 149?160, Nancy, France, April 23-25.Martha Palmer and Nianwen Xue.
2009.
Adding seman-tic roles to the Chinese Treebank.
Natural LanguageEngineering, 15(1):143?172.Mihai Surdeanu, Richard Johansson, Adam Meyers,Llu?
?s Ma`rquez, and Joakim Nivre.
2008.
The CoNLL-2008 shared task on joint parsing of syntactic and se-mantic dependencies.
In Proceedings of the CoNLL-2008.Mariona Taule?, Maria Anto`nia Mart?
?, and Marta Re-casens.
2008.
AnCora: Multilevel Annotated Corporafor Catalan and Spanish.
In Proceedings of the LREC-2008, Marrakesh, Morroco.Hai Zhao and Chunyu Kit.
2008.
Parsing syntactic andsemantic dependencies with two single-stage maxi-mum entropy models.
In Proceedings of CoNLL-2008,pages 203?207, Manchester, UK, August 16-17.Hai Zhao, Wenliang Chen, Chunyu Kit, and GuodongZhou.
2009.
Multilingual dependency learning: Ahuge feature engineering method to semantic depen-dency parsing.
In Proceedings of CoNLL-2009, Boul-der, Colorado, USA.66
