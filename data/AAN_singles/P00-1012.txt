The order of prenominal adjectivesin natural language generationRobert MaloufAlfa InformaticaRijksuniversiteit GroningenPostbus 7169700 AS GroningenThe Netherlandsmalouf@let.rug.nlAbstractThe order of prenominal adjectivalmodifiers in English is governed bycomplex and difficult to describe con-straints which straddle the boundarybetween competence and performance.This paper describes and comparesa number of statistical and machinelearning techniques for ordering se-quences of adjectives in the context ofa natural language generation system.1 The problemThe question of robustness is a perennial prob-lem for parsing systems.
In order to be useful,a parser must be able to accept a wide range ofinput types, and must be able to gracefully dealwith dysfluencies, false starts, and other ungram-matical input.
In natural language generation, onthe other hand, robustness is not an issue in thesame way.
While a tactical generator must be ableto deal with a wide range of semantic inputs, itonly needs to produce grammatical strings, andthe grammar writer can select in advance whichconstruction types will be considered grammati-cal.
However, it is important that a generator notproduce strings which are strictly speaking gram-matical but for some reason unusual.
This is aparticular problem for dialog systems which usethe same grammar for both parsing and genera-tion.
The looseness required for robust parsingis in direct opposition to the tightness needed forhigh quality generation.One area where this tension shows itself clearlyis in the order of prenominal modifiers in English.In principle, prenominal adjectives can, depend-ing on context, occur in almost any order:the large red American car?
?the American red large car*car American red the largeSome orders are more marked than others, butnone are strictly speaking ungrammatical.
So, thegrammar should not put any strong constraints onadjective order.
For a generation system, how-ever, it is important that sequences of adjectivesbe produced in the ?correct?
order.
Any other or-der will at best sound odd and at worst convey anunintended meaning.Unfortunately, while there are rules of thumbfor ordering adjectives, none lend themselves to acomputational implementation.
For example, ad-jectives denoting size do tend to precede adjec-tives denoting color.
However, these rules under-specify the relative order for many pairs of adjec-tives and are often difficult to apply in practice.In this paper, we will discuss a number of statisti-cal and machine learning approaches to automati-cally extracting from large corpora the constraintson the order of prenominal adjectives in English.2 Word bigram modelThe problem of generating ordered sequences ofadjectives is an instance of the more general prob-lem of selecting among a number of possibleoutputs from a natural language generation sys-tem.
One approach to this more general problem,taken by the ?Nitrogen?
generator (Langkilde andKnight, 1998a; Langkilde and Knight, 1998b),takes advantage of standard statistical techniquesby generating a lattice of all possible strings givena semantic representation as input and selectingthe most likely output using a bigram languagemodel.Langkilde and Knight report that this strategyyields good results for problems like generatingverb/object collocations and for selecting the cor-rect morphological form of a word.
It also shouldbe straightforwardly applicable to the more spe-cific problem we are addressing here.
To deter-mine the correct order for a sequence of prenom-inal adjectives, we can simply generate all possi-ble orderings and choose the one with the high-est probability.
This has the advantage of reduc-ing the problem of adjective ordering to the prob-lem of estimating n-gram probabilities, some-thing which is relatively well understood.To test the effectiveness of this strategy, wetook as a dataset the first one million sentencesof the written portion of the British National Cor-pus (Burnard, 1995).1 We held out a randomly se-lected 10% of this dataset and constructed a back-off bigram model from the remaining 90% usingthe CMU-Cambridge statistical language model-ing toolkit (Clarkson and Rosenfeld, 1997).
Wethen evaluated the model by extracting all se-quences of two or more adjectives followed bya noun from the held-out test data and countedthe number of such sequences for which the mostlikely order was the actually observed order.
Notethat while the model was constructed using theentire training set, it was evaluated based on onlysequences of adjectives.The results of this experiment were some-what disappointing.
Of 5,113 adjective sequencesfound in the test data, the order was correctly pre-dicted for only 3,864 for an overall prediction ac-curacy of 75.57%.
The apparent reason that thismethod performs as poorly as it does for this par-ticular problem is that sequences of adjectives arerelatively rare in written English.
This is evi-denced by the fact that in the test data only one se-quence of adjectives was found for every twentysentences.
With adjective sequences so rare, thechances of finding information about any particu-lar sequence of adjectives is extremely small.
Thedata is simply too sparse for this to be a reliablemethod.1The relevant files were identified by the absence of the<settDesc> (spoken text ?setting description?)
SGML tagin the file header.
Thanks to John Carroll for help in prepar-ing the corpus.3 The experimentsSince Langkilde and Knight?s general approachdoes not seem to be very effective in this particu-lar case, we instead chose to pursue more focusedsolutions to the problem of generating correctlyordered sequences of prenominal adjectives.
Inaddition, at least one generation algorithm (Car-roll et al, 1999) inserts adjectival modifiers in apost-processing step.
This makes it easy to in-tegrate a distinct adjective-ordering module withthe rest of the generation system.3.1 The dataTo evaluate various methods for orderingprenominal adjectives, we first constructed adataset by taking all sequences of two or moreadjectives followed by a common noun in the 100million tokens of written English in the BritishNational Corpus.
From 247,032 sequences, weproduced 262,838 individual pairs of adjectives.Among these pairs, there were 127,016 differentpair types, and 23,941 different adjective types.For test purposes, we then randomly held out10% of the pairs, and used the remaining 90% asthe training sample.Before we look at the different methods forpredicting the order of adjective pairs, there aretwo properties of this dataset which bear noting.First, it is quite sparse.
More than 76% of theadjective pair types occur only once, and 49%of the adjective types only occur once.
Second,we get no useful information about the syntag-matic context in which a pair appears.
The left-hand context is almost always a determiner, andincluding information about the modified headnoun would only make the data even sparser.
Thislack of context makes this problem different fromother problems, such as part-of-speech taggingand grapheme-to-phoneme conversion, for whichstatistical and machine learning solutions havebeen proposed.3.2 Direct evidenceThe simplest strategy for ordering adjectives iswhat Shaw and Hatzivassiloglou (1999) call thedirect evidence method.
To order the pair {a,b},count how many times the ordered sequences?a,b?
and ?b,a?
appear in the training data andoutput the pair in the order which occurred moreoften.This method has the advantage of being con-ceptually very simple, easy to implement, andhighly accurate for pairs of adjectives which ac-tually appear in the training data.
Applying thismethod to the adjectives sequences taken fromthe BNC yields better than 98% accuracy forpairs that occurred in the training data.
However,since as we have seen, the majority of pairs occuronly once, the overall accuracy of this method is59.72%, only slightly better than random guess-ing.
Fortunately, another strength of this methodis that it is easy to identify those pairs for whichit is likely to give the right result.
This meansthat one can fall back on another less accurate butmore general method for pairs which did not oc-cur in the training data.
In particular, if we ran-domly assign an order to unseen pairs, we can cutthe error rate in half and raise the overall accuracyto 78.28%.It should be noted that the direct evidencemethod as employed here is slightly differentfrom Shaw and Hatzivassiloglou?s: we simplycompare raw token counts and take the largervalue, while they applied a significance test to es-timate the probability that a difference betweencounts arose strictly by chance.
Like one finds ina trade-off between precision and recall, the useof a significance test slightly improved the accu-racy of the method for those pairs which it hadan opinion about, but also increased the numberof pairs which had to be randomly assigned anorder.
As a result, the net impact of using a sig-nificance test for the BNC data was a very slightdecrease in the overall prediction accuracy.The direct evidence method is straightforwardto implement and gives impressive results for ap-plications that involve a small number of frequentadjectives which occur in all relevant combina-tions in the training data.
However, as a generalapproach to ordering adjectives, it leaves quitea bit to be desired.
In order to overcome thesparseness inherent to this kind of data, we needa method which can generalize from the pairswhich occur in the training data to unseen pairs.3.3 TransitivityOne way to think of the direct evidence method isto see that it defines a relation ?
on the set of En-glish adjectives.
Given two adjectives, if the or-dered pair ?a,b?
appears in the training data moreoften then the pair ?b,a?, then a ?
b.
If the re-verse is true, and ?b,a?
is found more often than?a,b?, then b ?
a.
If neither order appears in thetraining data, then neither a?
b nor b?
a and anorder must be randomly assigned.Shaw and Hatzivassiloglou (1999) propose togeneralize the direct evidence method so that itcan apply to unseen pairs of adjectives by com-puting the transitive closure of the ordering re-lation ?.
That is, if a ?
c and c ?
b, we canconclude that a ?
b.
To take an example fromthe BNC, the adjectives large and green never oc-cur together in the training data, and so wouldbe assigned a random order by the direct evi-dence method.
However, the pairs ?large,new?and ?new,green?
occur fairly frequently.
There-fore, in the face of this evidence we can assignthis pair the order ?large,green?, which not coin-cidently is the correct English word order.The difficulty with applying the transitive clo-sure method to any large dataset is that there of-ten will be evidence for both orders of any givenpair.
For instance, alongside the evidence sup-porting the order ?large,green?, we also find thepairs ?green,byzantine?, ?byzantine,decorative?,and ?decorative,new?, which suggest the order?green, large?.Intuitively, the evidence for the first order isquite a bit stronger than the evidence for the sec-ond.
The first ordered pairs are more frequent, asare the individual adjectives involved.
To quan-tify the relative strengths of these transitive in-ferences, Shaw and Hatzivassiloglou (1999) pro-pose to assign a weight to each link.
Say the order?a,b?
occurs m times and the pair {a,b} occurs ntimes in total.
Then the weight of the pair a?
bis:?
log(1?n?k=m(nk)?12n)This weight decreases as the probability that theobserved order did not occur strictly by chanceincreases.
This way, the problem of finding theorder best supported by the evidence can be statedas a general shortest path problem: to find the pre-ferred order for {a,b}, find the sum of the weightsof the pairs in the lowest-weighted path from a tob and from b to a and choose whichever is lower.Using this method, Shaw and Hatzivassilogloureport predictions ranging from 81% to 95% ac-curacy on small, domain specific samples.
How-ever, they note that the results are very domain-specific.
Applying a graph trained on one domainto a text from another another generally givesvery poor results, ranging from 54% to 58% accu-racy.
Applying this method to the BNC data gives83.91% accuracy, in line with Shaw and Hatzivas-siloglou?s results and considerably better than thedirect evidence method.
However, applying themethod is computationally a bit expensive.
Likethe direct evidence method, it requires storing ev-ery pair of adjectives found in the training dataalong with its frequency.
In addition, it also re-quires solving the all-pairs shortest path problem,for which common algorithms run in O(n3) time.3.4 Adjective bigramsAnother way to look at the direct evidencemethod is as a comparison between two proba-bilities.
Given an adjective pair {a,b}, we com-pare the number of times we observed the order?a,b?
to the number of times we observed the or-der ?b,a?.
Dividing each of these counts by thetotal number of times {a,b} occurred gives us themaximum likelihood estimate of the probabilitiesP(?a,b?|{a,b}) and P(?b,a?|{a,b}).Looking at it this way, it should be clear whythe direct evidence method does not work well, asmaximum likelihood estimation of bigram proba-bilities is well known to fail in the face of sparsedata.
It should also be clear how we might im-prove the direct evidence method.
Using the samestrategy as described in section 2, we constructeda back-off bigram model of adjective pairs, againusing the CMU-Cambridge toolkit.
Since thismodel was constructed using only data specifi-cally about adjective sequences, the relative in-frequency of such sequences does not degrade itsperformance.
Therefore, while the word bigrammodel gave an accuracy of only 75.57%, the ad-jective bigram model yields an overall predictionaccuracy of 88.02% for the BNC data.3.5 Memory-based learningAn important property of the direct evidencemethod for ordering adjectives is that it requiresstoring all of the adjective pairs observed in thetraining data.
In this respect, the direct evidencemethod can be thought of as a kind of memory-based learning.Memory-based (also known as lazy, near-est neighbor, instance-based, or case-based) ap-proaches to classification work by storing all ofthe instances in the training data, along with theirclasses.
To classify a new instance, the store ofpreviously seen instances is searched to find thoseinstances which most resemble the new instancewith respect to some similarity metric.
The newinstance is then assigned a class based on the ma-jority class of its nearest neighbors in the space ofpreviously seen instances.To make the comparison between the directevidence method and memory-based learningclearer, we can frame the problem of adjective or-dering as a classification problem.
Given an un-ordered pair {a,b}, we can assign it some canon-ical order to get an instance ab.
Then, if a pre-cedes b more often than b precedes a in the train-ing data, we assign the instance ab to the classa?
b.
Otherwise, we assign it to the class b?
a.Seen as a solution to a classification problem,the direct evidence method then is an applicationof memory-based learning where the chosen sim-ilarity metric is strict identity.
As with the inter-pretation of the direct evidence method exploredin the previous section, this view both reveals areason why the method is not very effective andalso indicates a direction which can be taken toimprove it.
By requiring the new instance to beidentical to a previously seen instance in order toclassify it, the direct evidence method is unable togeneralize from seen pairs to unseen pairs.
There-fore, to improve the method, we need a more ap-propriate similarity metric that allows the classi-fier to get information from previously seen pairswhich are relevant to but not identical to new un-seen pairs.Following the conventional linguistic wisdom(Quirk et al, 1985, e.g.
), this similarity metricshould pick out adjectives which belong to thesame semantic class.
Unfortunately, for manyadjectives this information is difficult or impos-sible to come by.
Machine readable dictionar-ies and lexical databases such as WordNet (Fell-baum, 1998) do provide some information aboutsemantic classes.
However, the semantic classifi-cation in a lexical database may not make exactlythe distinctions required for predicting adjectiveorder.
More seriously, available lexical databasesare by necessity limited to a relatively small num-ber of words, of which a relatively small fractionare adjectives.
In practice, the available sourcesof semantic information only provide semanticclassifications for fairly common adjectives, andthese are precisely the adjectives which are foundfrequently in the training data and so for whichsemantic information is least necessary.While we do not reliably have access to themeaning of an adjective, we do always have ac-cess to its form.
And, fortunately, for many ofthe cases in which the direct evidence methodfails, finding a previously seen pair of adjec-tives with a similar form has the effect of find-ing a pair with a similar meaning.
For ex-ample, suppose we want to order the adjectivepair {21-year-old,Armenian}.
If this pair ap-pears in the training data, then the previous oc-currences of this pair will be used to predictthe order and the method reduces to direct ev-idence.
If, on the other hand, that particu-lar pair did not appear in the training data, wecan base the classification on previously seenpairs with a similar form.
In this way, wemay find pairs like {73-year-old,Colombian} and{44-year-old,Norwegian}, which have more orless the same distribution as the target pair.To test the effectiveness of a form-based sim-ilarity metric, we encoded each adjective pair abas a vector of 16 features (the last 8 charactersof a and the last 8 characters of b) and a classa ?
b or b ?
a. Constructing the instance baseand testing the classification was performed usingthe TiMBL 3.0 (Daelemans et al, 2000) memory-based learning system.
Instances to be classifiedwere compared to previously seen instances bycounting the number of feature values that the twoinstances had in common.In computing the similarity score, featureswere weighted by their information gain, an in-formation theoretic measure of the relevance of afeature for determining the correct classification(Quinlan, 1986; Daelemans and van den Bosch,1992).
This weighting reduces the sensitivity ofmemory based learning to the presence of irrele-vant features.Given the probability pi of finding each classi in the instance base D, we can compute the en-tropy H(D), a measure of the amount of uncer-tainty in D:H(D) =?
?pipi log2 piIn the case of the adjective ordering data, thereare two classes a ?
b and b ?
a, each of whichoccurs with a probability of roughly 0.5, so theentropy of the instance base is close to 1 bit.
Wecan also compute the entropy of a feature f whichtakes values V as the weighted sum of the entropyof each of the values V :H(D f ) = ?vi?VH(D f =vi)|D f =vi ||D|Here H(D f =vi) is the entropy of subset of the in-stance base which has value vi for feature f .
Theinformation gain of a feature then is simply thedifference between the total entropy of the in-stance base and the entropy of a single feature:G(D, f ) = H(D)?H(D f )The information gain G(D, f ) is the reduction inuncertainty in D we expect to achieve by learningthe value of the feature f .
In other words, know-ing the value of a feature with a higher G gets uscloser on average to knowing the class of an in-stance than knowing the value of a feature with alower G does.The similarity ?
between two instances then isthe number of feature values they have in com-mon, weighted by the information gain:?
(X ,Y ) =n?i=1G(D, i)?(xi,yi)where:?
(xi,yi) ={1 if xi = yi0 otherwiseClassification was based on the five training in-stances most similar to the instance to be classi-fied, and produced an overall prediction accuracyof 89.34% for the BNC data.3.6 Positional probabilitiesOne difficulty faced by each of the methods de-scribed so far is that they all to one degree or an-other depend on finding particular pairs of adjec-tives.
For example, in order for the direct evi-dence method to assign an order to a pair of ad-jectives like {blue, large}, this specific pair musthave appeared in the training data.
If not, an or-der will have to be assigned randomly, even ifthe individual adjectives blue and large appearquite frequently in combination with a wide vari-ety of other adjectives.
Both the adjective bigrammethod and the memory-based learning methodreduce this dependency on pairs to a certain ex-tent, but these methods still suffer from the factthat even for common adjectives one is much lesslikely to find a specific pair in the training datathan to find some pair of which a specific adjec-tive is a member.Recall that the adjective bigram methoddepended on estimating the probabilitiesP(?a,b?|{a,b}) and P(?b,a?|{a,b}).
Suppose wenow assume that the probability of a particularadjective appearing first in a sequence dependsonly on that adjective, and not the the other ad-jectives in the sequence.
We can easily estimatethe probability that if an adjective pair includessome given adjective a, then that adjective occursfirst (let us call that P(?a,x?|{a,x})) by lookingat each pair in the training data that includesthat adjective a.
Then, given the assumption ofindependence, the probability P(?a,b?|{a,b})is simply the product of P(?a,x?|{a,x}) andP(?x,b?|{b,x}).
Taking the most likely orderfor a pair of adjectives using this alternativemethod for estimating P(?a,b?|{a,b}) andP(?a,b?|{a,b}) gives quite good results: aprediction accuracy of 89.73% for the BNC data.At first glance, the effectiveness of this methodmay be surprising since it is based on an indepen-dence assumption which common sense indicatesmust not be true.
However, to order a pair of ad-jectives, this method brings to bear informationfrom all the previously seen pairs which includeeither of adjectives in the pair in question.
Sinceit makes much more effective use of the train-ing data, it can nevertheless achieve high accu-racy.
This method also has the advantage of be-ing computationally quite simple.
Applying thismethod requires only one easy-to-calculate valuebe stored for each possible adjective.
Comparedto the other methods, which require at a mini-mum that all of the training data be available dur-ing classification, this represents a considerableresource savings.3.7 Combined methodThe two highest scoring methods, using memory-based learning and positional probability, performsimilarly, and from the point of view of accuracythere is little to recommend one method over theother.
However, it is interesting to note that the er-rors made by the two methods do not completelyoverlap: while either of the methods gives theright answer for about 89% of the test data, oneof the two is right 95.00% of the time.
This in-dicates that a method which combined the infor-mation used by the memory-based learning andpositional probability methods ought to be ableto perform better than either one individually.To test this possibility, we added two new fea-tures to the representation described in section3.5.
Besides information about the morphologicalform of the adjectives in the pair, we also includedthe positional probabilities P(?a,x?|{a,x}) andP(?b,x?|{b,x}) as real-valued features.
For nu-meric features, the similarity metric ?
is com-puted using the scaled difference between the val-ues:?
(xi,yi) =xi?
yimaxi?miniRepeating the MBL experiment with these twoadditional features yields 91.85% accuracy forthe BNC data, a 24% reduction in error rate overpurely morphological MBL with only a modestincrease in resource requirements.4 Future directionsTo get an idea of what the upper bound on ac-curacy is for this task, we tried applying the di-rect evidence method trained on both the train-ing data and the held-out test data.
This gavean accuracy of approximately 99%, which meansthat 1% of the pairs in the corpus are in the?wrong?
order.
For an even larger percentage ofpairs either order is acceptable, so an evaluationprocedure which assumes that the observed or-der is the only correct order will underestimatethe classification accuracy.
Native speaker intu-itions about infrequently-occurring adjectives arenot very strong, so it is difficult to estimate whatfraction of adjective pairs in the corpus are ac-tually unordered.
However, it should be clearthat even a perfect method for ordering adjectiveswould score well below 100% given the experi-mental set-up described here.While the combined MBL method achievesreasonably good results even given the limitationsof the evaluation method, there is still clearlyroom for improvement.
Future work will pur-sue at least two directions for improving the re-sults.
First, while semantic information is notavailable for all adjectives, it is clearly availablefor some.
Furthermore, any realistic dialog sys-tem would make use of some limited vocabularyDirect evidence 78.28%Adjective bigrams 88.02%MBL (morphological) 89.34% (*)Positional probabilities 89.73% (*)MBL (combined) 91.85%Table 1: Summary of results.
With the exceptionof the starred values, all differences are statisti-cally significant (p< 0.005)for which semantic information would be avail-able.
More generally, distributional clusteringtechniques (Schu?tze, 1992; Pereira et al, 1993)could be applied to extract semantic classes fromthe corpus itself.
Since the constraints on adjec-tive ordering in English depend largely on seman-tic classes, the addition of semantic informationto the model ought to improve the results.The second area where the methods describedhere could be improved is in the way that multi-ple information sources are integrated.
The tech-nique method described in section 3.7 is a fairlycrude method for combining frequency informa-tion with symbolic data.
It would be worthwhileto investigate applying some of the more sophis-ticated ensemble learning techniques which havebeen proposed in the literature (Dietterich, 1997).In particular, boosting (Schapire, 1999; Abney etal., 1999) offers the possibility of achieving highaccuracy from a collection of classifiers which in-dividually perform quite poorly.5 ConclusionIn this paper, we have presented the results of ap-plying a number of statistical and machine learn-ing techniques to the problem of predicting theorder of prenominal adjectives in English.
Thescores for each of the methods are summarized intable 1.
The best methods yield around 90% ac-curacy, better than the best previously publishedmethods when applied to the broad domain dataof the British National Corpus.
Note that Mc-Nemar?s test (Dietterich, 1998) confirms the sig-nificance of all of the differences reflected here(with p< 0.005) with the exception of the differ-ence between purely morphological MBL and themethod based on positional probabilities.From this investigation, we can draw some ad-ditional conclusions.
First, a solution specificto adjective ordering works better than a gen-eral probabilistic filter.
Second, machine learn-ing techniques can be applied to a different kindof linguistic problem with some success, even inthe absence of syntagmatic context, and can beused to augment a hand-built competence gram-mar.
Third, in some cases statistical and memorybased learning techniques can be combined in away that performs better than either individually.6 AcknowledgmentsI am indebted to Carol Bleyle, John Carroll, AnnCopestake, Guido Minnen, Miles Osborne, au-diences at the University of Groningen and theUniversity of Sussex, and three anonymous re-viewers for their comments and suggestions.
Thework described here was supported by the Schoolof Behavioral and Cognitive Neurosciences at theUniversity of Groningen.ReferencesSteven Abney, Robert E. Schapire, and Yoram Singer.1999.
Boosting applied to tagging and PP attach-ment.
In Proceedings of the Joint SIGDAT Confer-ence on Empirical Methods in Natural LanguageProcessing and Very Large Corpora.Lou Burnard.
1995.
Users reference guide for theBritish National Corpus, version 1.0.
Technical re-port, Oxford University Computing Services.John Carroll, Ann Copestake, Dan Flickinger, andVictor Poznanski.
1999.
An efficient chart gen-erator for (semi-)lexicalist grammars.
In Proceed-ings of the 7th European Workshop on NaturalLanguage Generation (EWNLG?99), pages 86?95,Toulouse.Philip R. Clarkson and Ronald Rosenfeld.
1997.Statistical language modeling using the CMU-Cambridge Toolkit.
In G. Kokkinakis, N. Fako-takis, and E. Dermatas, editors, Eurospeech ?97Proceedings, pages 2707?2710.Walter Daelemans and Antal van den Bosch.
1992.Generalization performance of backpropagationlearning on a syllabification task.
In M.F.J.Drossaers and A. Nijholt, editors, Proceedings ofTWLT3: Connectionism and Natural LanguageProcessing, Enschede.
University of Twente.Walter Daelemans, Jakub Zavrel, Ko van der Sloot,and Antal van den Bosch.
2000.
TiMBL:Tilburg memory based learner, version 3.0, refer-ence guide.
ILK Technical Report 00-01, TilburgUniversity.
Available from http://ilk.kub.nl/~ilk/papers/ilk0001.ps.gz.Thomas G. Dietterich.
1997.
Machine learningresearch: four current directions.
AI Magazine,18:97?136.Thomas G. Dietterich.
1998.
Approximate statisticaltests for comparing supervised classification learn-ing algorithms.
Neural Computation, 10(7):1895?1924.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
MIT Press, Cambridge,MA.Irene Langkilde and Kevin Knight.
1998a.
Gener-ation that exploits corpus-based statistical knowl-edge.
In Proceedings of 36th Annual Meeting ofthe Association for Computational Linguistics and17th International Conference on ComputationalLinguistics, pages 704?710, Montreal.Irene Langkilde and Kevin Knight.
1998b.
The practi-cal value of n-grams in generation.
In Proceedingsof the International Natural Language GenerationWorkshop, Niagara-on-the-Lake, Ontario.Fernando Pereira, Naftali Tishby, and Lilian Lee.1993.
Distributional clustering of English words.In Proceedings of the 30th annual meeting of theAssociation for Computational Linguistics, pages183?190.J.
Ross Quinlan.
1986.
Induction of decision trees.Machine Learning, 1:81?106.Randolf Quirk, Sidney Greenbaum, Geoffrey Leech,and Jan Svartvik.
1985.
A Comprehensive Gram-mar of the English Language.
Longman, London.Robert E. Schapire.
1999.
A brief introduction toboosting.
In Proceedings of the Sixteenth Interna-tional Joint Conference on Artificial Intelligence.Hinrich Schu?tze.
1992.
Dimensions of meaning.In Proceedings of Supercomputing, pages 787?796,Minneapolis.James Shaw and Vasileios Hatzivassiloglou.
1999.Ordering among premodifiers.
In Proceedings ofthe 37th Annual Meeting of the Association forComputational Linguistics, pages 135?143, Col-lege Park, Maryland.
