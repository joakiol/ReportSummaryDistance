N-gram-based Machine TranslationJose?
B. Marin?o?Rafael E. Banchs?Josep M. Crego?Adria` de Gispert?Patrik Lambert?Jose?
A. R. Fonollosa?Marta R. Costa-jussa`?Universitat Polite`cnica de CatalunyaThis article describes in detail an n-gram approach to statistical machine translation.
This ap-proach consists of a log-linear combination of a translation model based on n-grams of bilingualunits, which are referred to as tuples, along with four specific feature functions.
Translationperformance, which happens to be in the state of the art, is demonstrated with Spanish-to-Englishand English-to-Spanish translations of the European Parliament Plenary Sessions (EPPS).1.
IntroductionThe beginnings of statistical machine translation (SMT) can be traced back to the earlyfifties, closely related to the ideas from which information theory arose (Shannon andWeaver 1949) and inspired by works on cryptography (Shannon 1949, 1951) duringWorld War II.
According to this view, machine translation was conceived as the problemof finding a sentence by decoding a given ?encrypted?
version of it (Weaver 1955).Although the idea seemed very feasible, enthusiasm faded shortly afterward because ofthe computational limitations of the time (Hutchins 1986).
Finally, during the nineties,two factors made it possible for SMT to become an actual and practical technology:first, significant increment in both the computational power and storage capacity ofcomputers, and second, the availability of large volumes of bilingual data.The first SMT systems were developed in the early nineties (Brown et al 1990, 1993).These systems were based on the so-called noisy channel approach, which models theprobability of a target language sentence T given a source language sentence S as theproduct of a translation-model probability p(S|T), which accounts for adequacy of trans-lation contents, times a target language probability p(T), which accounts for fluencyof target constructions.
For these first SMT systems, translation-model probabilities atthe sentence level were approximated from word-based translation models that weretrained by using bilingual corpora (Brown et al 1993).
In the case of target languageprobabilities, these were generally trained from monolingual data by using n-grams.Present SMT systems have evolved from the original ones in such a way thatmainly differ from them in two respects: first, word-based translation models have been?
Department of Signal Theory and Communications, Campus Nord, Barcelona 08034, Spain.Submission received: 9 August 2005; revised submission received: 26 April 2006; accepted forpublication: 5 July 2006?
2006 Association for Computational LinguisticsComputational Linguistics Volume 32, Number 4replaced by phrase-based translation models (Zens, Och, and Ney 2002; Koehn, Och,and Marcu 2003) which are directly estimated from aligned bilingual corpora by consid-ering relative frequencies, and second, the noisy channel approach has been expandedto a more general maximum entropy approach in which a log-linear combination ofmultiple feature functions is implemented (Och and Ney 2002).As an extension of the machine translation problem, technological advances in thefields of automatic speech recognition (ASR) and text to speech synthesis (TTS) made itpossible to envision the challenge of spoken language translation (SLT) (Kay, Gawron,and Norvig 1992).
According to this, SMT has also been approached from a finite-statepoint of view as the most natural way of integrating ASR and SMT (Riccardi, Pieraccini,and Bocchieri 1996; Vidal 1997; Knight and Al-Onaizan 1998; Bangalore and Riccardi2000).
In this SMT approach, translation models are implemented by means of finite-state transducers for which transition probabilities are learned from bilingual data.As opposed to phrase-based translation models, which consider probabilities betweentarget and source units referred to as phrases, finite-state translation models rely onprobabilities among sequences of bilingual units, which are defined by the transitionsof the transducer.The translation system described in this article implements a translation model thathas been derived from the finite-state perspective?more specifically, from the work ofCasacuberta (2001) and Casacuberta and Vidal (2004).
However, whereas in this earlierwork the translation model is implemented by using a finite-state transducer, in the sys-tem presented here the translation model is implemented by using n-grams.
In this way,the proposed translation system can take full advantage of the smoothing and consist-ency provided by standard back-off n-gram models.
The translation model presentedhere actually constitutes a language model of a sort of ?bilanguage?
composed of bilin-gual units, which will be referred to as tuples (de Gispert and Marin?o 2002).
An alterna-tive approach, which relies on bilingual-unit unigram probabilities, was developed byTillmann and Xia (2003); in contrast, the approach presented here considers bilingual-unit n-gram probabilities.
In addition to the tuple n-gram translation model, thetranslation system presented here implements four specific feature functions that arelog-linearly combined along with the translation model for performing the decoding(Marin?o et al 2005).This article is intended to provide a detailed description of the n-gram-basedtranslation system, as well as to demonstrate the system performance in a wide-domain, large-vocabulary translation task.
The article is structured as follows.
First,Section 2 presents a complete description of the n-gram-based translation model.
Then,Section 3 describes in detail the additional feature functions that, along with the trans-lation model, compose the n-gram-based SMT system implemented.
Section 4 describesthe European Parliament Plenary Session (EPPS) data, as well as the most relevantdetails about the translation tasks considered.
Section 5 presents and discusses thetranslation experiments and their results.
Finally, Section 6 presents some conclusionsand intended further work.2.
The Tuple N-gram ModelThis section describes in detail the tuple n-gram translation model, which constitutesthe core model implemented by the n-gram-based SMT system.
First, the bilingual unitdefinition and model computation are presented in Section 2.1.
Then, some importantrefinements to the basic translation model are provided and discussed in Section 2.2.Finally, Section 2.3 discusses issues related to n-gram-based decoding.528Marin?o et al N-gram-based Machine Translation2.1 Tuple Extraction and Model ComputationAs already mentioned, the translation model implemented by the described SMT sys-tem is based on bilingual n-grams.
This model actually constitutes a language model ofa particular bilanguage composed of bilingual units that are referred to as tuples.
In thisway, the translation model probabilities at the sentence level are approximated by usingn-grams of tuples, such as described by the following equation:p(T, S) ?K?k=1p((t, s)k|(t, s)k?1, (t, s)k?2, .
.
.
, (t, s)k?n+1) (1)where t refers to target, s to source, and (t, s)k to the kth tuple of a given bilingualsentence pair.
It is important to note that since both languages are linked up in tuples,the context information provided by this translation model is bilingual.Tuples are extracted from a word-to-word aligned corpus in such a way that aunique segmentation of the bilingual corpus is achieved.
Although in principle anyViterbi alignment should allow for tuple extraction, the resulting tuple vocabularydepends highly on the particular alignment set considered, and this impacts the trans-lation results.
According to our experience, the best performance is achieved whenthe union of the source-to-target and target-to-source alignment sets (IBM models;Brown et al [1993]) is used for tuple extraction (some experimental results regardingthis issue are presented in Section 4.2.2).
Additionally, the use of the union can alsobe justified from a theoretical point of view by considering that the union set typicallyexhibits higher recall values than do other alignment sets such as the intersection andsource-to-target.In this way, as opposed to other implementations, where one-to-one (Bangaloreand Riccardi 2000) or one-to-many (Casacuberta and Vidal 2004) alignments are used,tuples are extracted from many-to-many alignments.
This implementation producesa monotonic segmentation of bilingual sentence pairs, which allows for simulta-neously capturing contextual and reordering information into the bilingual translationunit structures.
This segmentation also allows for estimating the n-gram probabil-ities appearing in (1).
In order to guarantee a unique segmentation of the corpus,tuple extraction is performed according to the following constraints (Crego, Marin?o,and de Gispert 2004): a monotonic segmentation of each bilingual sentence pair is produced, no word inside the tuple is aligned to words outside the tuple, and no smaller tuples can be extracted without violating the previousconstraints.Notice that, according to this, tuples can be formally defined as the set of shortestphrases that provides a monotonic segmentation of the bilingual corpus.
Figure 1presents a simple example illustrating the unique tuple segmentation for a given pair ofsentences, as well as the complete phrase set.The first important observation from Figure 1 is related to the possible occurrenceof tuples containing unaligned elements on the target side.
This is the case for tuple 1.Tuples of this kind should be handled in an alternative way for the system to be ableto provide appropriate translations for such unaligned elements.
The problem of how529Computational Linguistics Volume 32, Number 4Figure 1Example of tuple extraction.
Tuples are extracted from Viterbi alignments in such a way that theset of shortest bilingual units that provide a monotonous segmentation of the bilingual sentencepair is achieved.to handle this kind of situation, which we refer to as involving source-nulled tuples, isdiscussed in detail in Section 2.2.2.Also, as observed from Figure 1, the total number of tuples is significantly lowerthan the total number of phrases, and, in most of the cases, longer phrases can beconstructed by considering tuple n-grams, which is the case for phrases 2, 6, 7, 9, 10,and 11.
However, phrases 4 and 5 cannot be generated from tuples.
In general, the tuplerepresentation is not able to provide translations for individual words that appear tiedto other words unless they occur alone in some other tuple.
This problem, which werefer to as embedded words, is discussed in detail in Section 2.2.1.Another important observation from Figure 1 is that each tuple length is implicitlydefined by the word links in the alignment.
As opposed to phrase-extraction proce-dures, for which a maximum phrase length should be defined to avoid a vocabularyexplosion, tuple extraction procedures do not have any control over tuple lengths.According to this, the tuple approach will strongly benefit from the structural similaritybetween the languages under consideration.
Then, for close language pairs, tuples areexpected to successfully handle those short reordering patterns that are included inthe tuple structure, as in the case of ?traducciones perfectas : perfect translations?presented in Figure 1.
On the other hand, in the case of distant pairs of languages, forwhich a large number of long tuples are expected to occur, the approach will more easilyfail to provide a good translation model due to tuple sparseness.2.2 Translation Model RefinementsThe basic n-gram translation model, as defined in the previous section, exhibits someimportant limitations that can be easily overcome by incorporating specific changes in530Marin?o et al N-gram-based Machine Translationeither the tuple vocabulary or the n-gram model.
This section describes such limitationsand provides a detailed description of the implemented refinements.2.2.1 Embedded Words.
The first issue regarding the n-gram translation model is relatedto the already mentioned problem of embedded words, which refers to the fact thatthe tuple representation is not able to provide translations for individual words all thetime.
Embedded words can become a serious drawback when they occur in relativelysignificant numbers in the tuple vocabulary.Consider for example the word translations in Figure 1.
As seen from the figure, thisword appears embedded into tuple ?traducciones perfectas : perfect translations.?
If asimilar situation is encountered for all other occurrences of that word in the trainingcorpus, then no translation probability for an independent occurrence of that wordwill exist.
A more relevant example would be the case of the embedded word perfectsince this adjective always moves relative to the noun it is modifying.
In this case,providing the translation system with a word-to-word translation probability for ?per-fectas : perfect?
only guarantees that the decoder will have a translation option for anisolated occurrence of such words but does not guarantee anything about word order.So, certainly, any adjective?noun combination including the word perfect, which has notbeen seen during the training stage, will be translated in the wrong order.
Accordingly,the problem resulting from embedded words can be partially solved by incorporating abilingual dictionary able to provide word-to-word translation when required by thetranslation system.
A more complete treatment for this problem must consider theimplementation of a word-reordering strategy for the proposed SMT approach (as willbe discussed in Section 6, this constitutes one of the main concerns for our furtherresearch).In our n-gram-based SMT implementation, the following strategy for handling em-bedded words is considered.
First, one-word tuples for each detected embedded wordare extracted from the training data and their corresponding word-to-word translationprobabilities are computed by using relative frequencies.
Then, the tuple n-gram modelis enhanced by including all embedded-word tuples as unigrams into the model.
Sincea high-precision alignment set is desirable for extracting such one-word tuples andestimating their probabilities, the intersection of both alignments, source to target andtarget-to-source, is used instead of the union.In the particular case of the EPPS tasks considered in this work, embedded wordsdo not constitute a real problem because of the great amount of training material andthe reduced size of the test data set (see Section 4.1 for a detailed description of theEPPS data set).
On the contrary, in other translation tasks with less available trainingmaterial, the embedded-word handling strategy described above has been very useful(de Gispert, Marin?o, and Crego 2004).2.2.2 Tuples with Empty Source Sides.
The second important issue regarding then-gram translation model is related to tuples with empty source sides, hereinafterreferred to as source-nulled tuples.
In the tuple n-gram model implementation, it fre-quently happens that some target words linked to NULL end up producing tuples withNULL source sides.
Consider, for example, the first tuple of the example presented inFigure 1.
In this example, ?NULL : we?
is a source-nulled tuple if Spanish is consideredto be the source language.
Notice that tuples of this kind cannot be allowed since noNULL is expected to occur in a translation input.The classical solution to this problem in the finite-state transducer framework isthe inclusion of epsilon arcs (Knight and Al-Onaizan 1998; Bangalore and Riccardi531Computational Linguistics Volume 32, Number 42000).
However, epsilon arcs significantly increase decoding complexity.
In our n-gramsystem implementation, this problem is easily solved by preprocessing the union set ofalignments before extracting tuples, in such a way that any target word that is linkedto NULL is attached to either its preceding word or its following word.
In this way, notarget word remains linked to NULL, and source-nulled tuples will not occur duringtuple extraction.Some different strategies for handling target words aligned to NULL have beenconsidered.
In the simplest strategy, which will be referred to as the attach-to-right strat-egy, target words aligned to NULL are always attached to their following word.
Thissimple strategy happens to provide better results, for English-to-Spanish and Spanish-to-English translations, than the opposite one (attachment to the previous word), andalso better than a more sophisticated strategy that considers bigram probabilities fordeciding whether a given word should be attached to the following or to the pre-vious one.Notice that in the particular cases of Spanish and English, the attach-to-right strat-egy can be justified heuristically.
Indeed, when translating from Spanish to English,most of the source-nulled tuples result from omitted verbal subjects, which is a verycommon situation in Spanish.
This is the case for the first tuple in Figure 1.
Suppose,for instance, that the attach-to-right strategy is used in Figure 1; in such a case, thetuple ?quisie?ramos : would like?
will be replaced by the new tuple ?quisie?ramos : wewould like,?
which actually makes a better translation unit, at least from a grammaticalpoint of view.
Similarly, some common situations can be identified for translations inthe English-to-Spanish direction, such as omitted determiners (e.g., ?I want informationabout European countries : quiero informacio?n sobre los pa?
?ses Europeos?).
Again,the attach-to-right strategy for the unaligned Spanish determiner los seems to be thebest one.Experimental results comparing the attach-to-right strategy to an additional strat-egy based on a statistical translation lexicon are provided in Section 5.1.3.2.2.3 Tuple Vocabulary Pruning.
The third and last issue regarding the n-gram transla-tion model is related to the computational costs resulting from the tuple vocabulary sizeduring decoding.
The idea behind this refinement is to reduce both computation timeand storage requirements without degrading translation performance.
In our n-gram-based SMT system implementation, the tuple vocabulary is pruned by using histogramcounts.
This pruning is performed by keeping the N most frequent tuples with commonsource sides.Notice that such a pruning, because it is performed before computing tuple n-gramprobabilities, has a direct impact on the translation model probabilities and then onthe overall system performance.
For this reason, the pruning parameter N is criticalfor efficient usage of the translation system.
While a low value of N will significantlydecrease translation quality, on the other hand, a large value of N will provide thesame translation quality than a more adequate N, but with a significant increment incomputational costs.
The optimal value for this parameter depends on data and shouldbe adjusted empirically for each considered translation task.2.3 N-gram-based DecodingDecoding for the n-gram-based translation model is slightly different from phrase-based decoding.
For this reason, a specific decoding tool had to be implemented.
This532Marin?o et al N-gram-based Machine Translationsection briefly describes MARIE, the n-gram based search engine developed for ourSMT system (Crego, Marin?o, and de Gispert 2005a).MARIE implements a beam-search strategy based on dynamic programming.
Thedecoding is performed monotonically and is guided by the source.
During decoding,partial-translation hypotheses are arranged into different stacks according to the totalnumber of source words they cover.
In this way, a given hypothesis only competes withthose hypotheses that provide the same source-word coverage.
At every translationstep, stacks are pruned to keep decoding tractable.
MARIE allows for two differentpruning methods: Threshold pruning: for which all partial-translation hypotheses scoringbelow a predetermined threshold value are eliminated. Histogram pruning: for which the maximum number of partial-translationhypotheses to be considered is limited to the K-best ranked ones.Additionally, MARIE allows for hypothesis recombination, which provides a moreefficient search.
In the implemented algorithm, partial-translation hypotheses are re-combined if they coincide exactly in both the present tuple and the tuple trigram history.MARIE also allows for considering additional feature functions during decoding.All these models are taken into account simultaneously, along with the n-gram trans-lation model.
In our SMT system implementation, four additional feature functions areconsidered.
These functions are described in detail in Section 3.2.3.
Feature Functions for the N-gram-based SMT SystemThis section describes in detail some feature functions that are implemented along withthe n-gram translation model for the complete translation system.
First, in subsection3.1, the log-linear combination framework and the implemented optimization proce-dure are discussed.
Then, four specific feature functions that constitute our SMT systemare detailed in Section 3.2.3.1 Log-linear Combination FrameworkAs mentioned in the Introduction, in recent translation systems the noisy channel ap-proach has been replaced by a more general approach, which is founded on the princi-ples of maximum entropy (Berger, Della Pietra, and Della Pietra 1996).
In this approach,the corresponding translation for a given source language sentence S is defined by thetarget language sentence that maximizes a log-linear combination of multiple featurefunctions hi(S, T) (Och and Ney 2002), such as described by the following equation:argmaxT?m?mhm(S, T) (2)where ?m represents the coefficient of the mth feature function hm(S, T), which ac-tually corresponds to a log-scaled version of the mth-model probabilities.
Optimalvalues for the ?m coefficients are estimated via an optimization procedure by using adevelopment data set.533Computational Linguistics Volume 32, Number 43.2 Translation System FeaturesIn addition to the tuple n-gram translation model, our n-gram-based SMT systemimplements four feature functions: a target-language model, a word-bonus model, andtwo lexicon models.
These system features are described next.3.2.1 Target-language Model.
This feature provides information about the target lan-guage structure and fluency.
It favors those partial-translation hypotheses that are morelikely to constitute correctly structured target sentences over those that are not.
Themodel is implemented by using a word n-gram model of the target language, which iscomputed according to the following expression:hTL(T, S) = hTL(T) = logK?k=1p(wk|wk?1, wk?2, .
.
.
, wk?n+1) (3)where wk refers to the kth word in the considered partial-translation hypothesis.
Noticethat this model only depends on the target side of the data, and can in fact be trained byincluding additional information from other available monolingual corpora.3.2.2 Word-bonus Model.
This feature introduces a bonus that depends on the partial-translation hypothesis length.
This is done to compensate for the system preference forshort translations over large ones.
The model is implemented through a bonus factorthat directly depends on the total number of words contained in the partial-translationhypothesis, and it is computed as follows:hWP(T, S) = hWP(T) = M (4)where M is the number of words contained in the partial-translation hypothesis.3.2.3 Source-to-Target Lexicon Model.
This feature actually constitutes a complemen-tary translation model.
This model provides, for a given tuple, a translation probabilityestimate between its source and target sides.
This feature is implemented by using theIBM-1 lexical parameters (Brown et al 1993; Och et al 2004).
Accordingly, the source-to-target lexicon probability is computed for each tuple according to the followingequation:hLF(T, S) = log 1(I + 1)JJ?j=1I?i=0q(tnj |sni ) (5)where sni and tnj are the ith and jth words in the source and target sides of tuple (t, s)n,with I and J the corresponding total number of words in each side.
In the equation,q(.)
refers to IBM-1 lexical parameters, which are estimated from alignments computedin the source-to-target direction.3.2.4 Target-to-Source Lexicon Model.
Similar to the previous feature, this featurefunction constitutes a complementary translation model too.
It is computed in ex-534Marin?o et al N-gram-based Machine Translationactly the same way the previous model is, with the only difference that IBM-1 lexicalparameters are estimated from alignments computed in the target-to-source directioninstead.4.
EPPS Translation TaskThis section describes in detail the most relevant issues about the translation tasks con-sidered.
Section 4.1 describes the EPPS data set that is used, and Section 4.2 presents theoverall implementation details in regard to preprocessing, training, and optimization.4.1 Corpus DescriptionThe EPPS data set is composed of the official plenary session transcriptions of the Eu-ropean Parliament, which are currently available in eleven different languages (Koehn2002).
However, in the case of the results presented here, we have used the Spanish andEnglish versions of the EPPS data that have been prepared by RWTH Aachen Universityin the context of the European Project TC-STAR.
The training, development, and testdata used include session transcriptions from April 1996 until September 2004, fromOctober 21 until October 28, 2004, and from November 15 until November 18, 2004,respectively.Table 1 presents the basic statistics for the training, development, and test data setsfor each considered language.
More specifically, the statistics shown in Table 1 are thenumber of sentences, the number of words, the vocabulary size (or number of distinctwords), the average sentence length in number of words, and the number of availabletranslation references.As seen from Table 1, although the total number of words in the training set isvery similar for both languages, vocabulary sizes are substantially different.
Indeed,the Spanish vocabulary is approximately 60% larger than the English vocabulary.
Thiscan be explained by the more inflected nature of Spanish, which is particularly evidentin the case of nouns, adjectives, and verbs, which may have many different forms de-pending on gender, number, tense, and mode.
As will be seen from results presented inSection 5, this difference in vocabulary size has important consequences in translationquality for the English-to-Spanish direction.Regarding the development data set, only 1, 008 sentences were considered.
Noticefrom Table 1 that in this case, the Spanish vocabulary is 20% larger than the EnglishTable 1Basic statistics for the training, development, and test data sets (M and k stand for millions andthousands, respectively; Lmean refers to the average sentence length in number of words, andRef.
to the number of available translation references).Set Language Sentences Words Vocabulary Lmean Ref.Train English 1.22 M 33.4 M 105 k 23.7 1Spanish 1.22 M 34.8 M 169 k 28.4 1Dev.
English 1008 26.0 k 3.2 k 25.8 3Spanish 1008 25.7 k 3.9 k 25.5 3Test English 1094 26.8 k 3.9 k 24.5 2Spanish 840 22.7 k 4.0 k 27.0 2535Computational Linguistics Volume 32, Number 4vocabulary.
Another important issue regarding the development data set is the numberof unseen words, that is, those words present in the development data that are notpresent in the training data.
In this case, 35 words (0.13%) out of the total number ofwords in the English development set did not occur in the training data.
From these 35words, only 30 corresponded to different words.
Similarly, 61 words (0.24%) out of thetotal number of words in the Spanish development set were not in the training data.
Inthis case, 57 different words occurred.Notice also in Table 1 that a different test set was used for each translation direction,and although a different number of sentences is considered in each case, vocabularysizes are almost equivalent.
Regarding unseen words, in this case, 112 words (0.42%) outof the total number of words in the English test set did not occur in the training data.From these 112 words, only 81 corresponded to different words.
Similarly, 46 words(0.20%) out of the total number of words in the Spanish test were not in the trainingdata.
In this case, 40 different words occurred.4.2 Preprocessing, Training, and System OptimizationThis section presents the overall implementation details in regard to preprocessing,training, and optimization of the translation system.
Two languages, English and Span-ish, and both translation directions between them are considered for several differentsystem configurations.4.2.1 Preprocessing and Alignment.
The training data are preprocessed by using stan-dard tools for tokenizing and filtering.
In the filtering stage, some sentence pairs areremoved from the training data to allow for a better performance of the alignment tool.Sentence pairs are removed according to the following two criteria: Fertility filtering: removes sentence pairs with a word ratio larger than apredefined threshold value. Length filtering: removes sentence pairs with at least one sentence of morethan 100 words in length.
This helps to maintain bounded alignmentcomputational times.After preprocessing, word-to-word alignments are performed in both directions,source-to-target and target-to-source.
In our system implementation, GIZA++ (Och andNey 2000) is used for computing the alignments.
A total of five iterations for modelsIBM-1 and HMM, and three iterations for models IBM-3 and IBM-4, are performed.Then, the obtained alignment sets are used for computing the intersection and theunion of alignments from which tuples and embedded-word tuples are extracted,respectively.4.2.2 Tuple Extraction and Pruning.
A tuple set for each translation direction is ex-tracted from the union set of alignments while avoiding source-nulled tuples by usingthe procedure described in Section 2.2.2.
Then, the resulting tuple vocabularies arepruned according to the procedure described in Section 2.2.3.
In the case of the EPPSdata under consideration, pruning parameter values of N = 20 and N = 30 are used forSpanish-to-English and English-to-Spanish, respectively.In order to better justify such alignment set and pruning parameter selections,Tables 2 and 3 present model sizes and translation accuracies for the tuple n-gram model536Marin?o et al N-gram-based Machine TranslationTable 2Tuple vocabulary sizes and their corresponding number of n-grams (in millions), andtranslation accuracy when tuples are extracted from different alignment sets.
Notice thatBLEU measurements in this table correspond to translations computed by using the tuplen-gram model alone.Direction Alignment set Tuple voc.
Bigrams Trigrams BLEUES ?
EN Source-to-target 1.920 6.426 2.353 0.4424union 2.040 6.009 1.798 0.4745refined 2.111 6.851 2.398 0.4594EN ?
ES Source-to-target 1.813 6.263 2.268 0.4152union 2.023 6.092 1.747 0.4276refined 2.081 6.920 2.323 0.4193when tuples are extracted from different alignment sets and when different pruningparameters are used, respectively.
Translation accuracy is measured in terms of theBLEU score (Papineni et al 2002), which is computed here for translations generatedby using the tuple n-gram model alone, in the case of Table 2, and by using the tuplen-gram model along with the additional four feature functions described in Section 3.2,in the case of Table 3.
Both translation directions, Spanish to English (ES ?
EN) andEnglish to Spanish (EN ?
ES), are considered in each table.In the case of Table 2, model size and translation accuracy are evaluated againstthe type of alignment set used for extracting tuples.
Three different alignment sets areconsidered: source-to-target, the union of source-to-target and target-to-source, and the?refined?
alignment method described by Och and Ney (2003).
For the results presentedin Table 2, a pruning parameter value of N = 20 was used for the Spanish-to-Englishdirection, while a value of N = 30 was used for the English-to-Spanish direction.As can be clearly seen in Table 2, the union alignment set happens to be the mostfavorable one for extracting tuples in both translation directions since it provides asignificantly better translation accuracy, in terms of BLEU score, than the other twoalignment sets considered.
Notice also in Table 2 that the union set is the one providingthe smallest model sizes according to the number of bigrams and trigrams.
This mightexplain the improvement observed in translation accuracy, with respect to the other twocases, in terms of model sparseness.Table 3Tuple vocabulary sizes and their corresponding number of n-grams (in millions), andtranslation accuracy for different pruning values and both translation directions.
Notice thatBLEU measurements in this table correspond to translations computed by using the tuplen-gram model along with the additional four feature functions described in Section 3.2.Direction Pruning Tuple voc.
Bigrams Trigrams BLEUES ?
EN N = 30 2.109 6.233 1.805 0.5440N = 20 2.040 6.009 1.798 0.5434N = 10 1.921 5.567 1.759 0.5399EN ?
ES N = 30 2.023 6.092 1.747 0.4688N = 20 1.956 5.840 1.733 0.4671N = 10 1.843 5.342 1.677 0.4595537Computational Linguistics Volume 32, Number 4In the case of Table 3, model size and translation accuracy are compared for threedifferent pruning conditions: N = 30, N = 20, and N = 10.
For all the cases presented inthe table, tuples were extracted from the union set of alignments.Notice in Table 3 how translation accuracy is clearly affected by pruning.
In thecase of Spanish to English, values of N = 20 and N = 10, while providing tuple vo-cabulary reductions of 3.27% and 8.91% with respect to N = 30, respectively, producea translation BLEU score reductions of 0.11% and 0.75%.
On the other hand, in thecase of English to Spanish, values of N = 20 and N = 10 provide tuple vocabularyreductions of 3.31% and 8.89% and a translation BLEU score reductions of 0.36% and1.98% with respect to N = 30, respectively.
According to these results, a similar tuplevocabulary reduction seems to affect English-to-Spanish translations more than it af-fects Spanish-to-English translations.
For this reason, we finally adopted N = 20 andN = 30 as the pruning parameter values for Spanish to English and English to Spanish,respectively.Another important observation derived from Table 3 is the higher BLEU scorevalues with respect to the ones presented in Table 2.
This is because, as mentionedabove, the results presented in Table 3 were obtained by considering a full translationsystem that implements the tuple n-gram model along with the additional four featurefunctions described in Section 3.2.
The relative impact of the described feature functionson translation accuracy is studied in detail in Section 5.1.1.4.2.3 Translation Model and Feature Function Training.
After pruning, a tuple n-grammodel is trained for each translation direction by using the SRI Language Modelingtoolkit (Stolcke 2002).
The options for Kneser?Ney smoothing (Kneser and Ney 1995)and interpolation of higher and lower n-grams are used in these trainings.
Then, eachtuple n-gram translation model is finally enhanced by including the unigram probabil-ities for the embedded-word tuples such as described in Section 2.2.2.Similarly, a word n-gram target language model is trained for each translationdirection by using the SRI Language Modeling toolkit.
Again, as in the case of thetuple n-gram model, Kneser?Ney smoothing and interpolation of higher and lowern-grams are used.
Extended target language models might also be obtained by addingadditional information from other available monolingual corpora.
However, in thetranslation tasks described here, target language models are estimated by using onlythe information contained in the target side of the training data set.In our SMT system implementation, trigram models are considered for both thetuple translation model and the target language model.
This selection is based onperplexity measurements (over the development data set) obtained for n-gram modelscomputed from the EPPS training data by using different n-gram sizes.
Table 4 presentsTable 4Perplexity measurements for translation and target language models of different n-gram sizes.Type of model Language Bigram Trigram 4-gram 5-gramTranslation ES ?
EN 201.75 161.26 156.88 157.24Translation EN ?
ES 223.94 179.12 174.10 174.49Language Spanish 81.98 52.49 48.03 47.54Language English 78.91 50.59 46.22 45.59538Marin?o et al N-gram-based Machine Translationperplexity values obtained for translation and target language models with differentn-gram sizes.Although our system implements trigram models, the performance of translationsystems using different n-gram sized models is also evaluated.
These results are pre-sented and discussed in Section 5.1.2.Finally, the source-to-target and target-to-source lexicon models are computed foreach translation direction according to the procedure described in Section 3.2.3.
For eachconsidered lexicon model, either the alignment set in the source-to-target direction orthe alignment set in the target-to-source direction is used, accordingly.4.2.4 System Optimization.
Once the models are computed, a set of optimal log-linearcoefficients is estimated for each translation direction and system configuration viaan optimization procedure, which is described as follows.
First, a development dataset that does not overlap either the training set or the test set is required.
Then, trans-lation quality over the development set is maximized by iteratively varying the set ofcoefficients.
In our SMT system implementation, this optimization procedure is per-formed by using a tool developed in-house, which is based on a simplex method (Presset al 2002), and the BLEU score (Papineni et al 2002) is used as a translation qualitymeasurement.As will be described in the next section, several different system configurationsare considered in the experiments.
For all these optimizations, the development datadescribed in Table 1 are used.
As presented in the table, the development data includedthree translation references for both English and Spanish, which are used to computethe BLEU score at each iteration of the optimization procedures.The same decoder settings are used for all system optimizations.
These settings arethe following: decoding is performed monotonically, that is, no reordering capabilitiesare used, decoding is guided by the source sentence to be translated, although available in the decoder, threshold pruning is not used, and a value of K = 50 for during-decoding histogram pruning is used.5.
Translation Experiments and Error AnalysisThis section presents all translation experiments performed and a brief error analysisof the obtained results.
In order to evaluate the relative contributions of differentsystem elements to the overall performance of the n-gram-based translation system,three different experimental settings are considered.
The experiments and their re-sults are described in Section 5.1, and a brief error analysis of results is presented inSection 5.2.
Finally, a comparison between n-gram-based SMT and state-of-the-artphrase-based translation systems is presented in Section 5.3.5.1 Translation Experiments and ResultsAs already mentioned, three experimental settings are considered.
For each setting,the impact on translation quality of a different system parameter is evaluated, namely,539Computational Linguistics Volume 32, Number 4feature function, n-gram size, and the source-nulled tuple strategy.
Evaluations in allthree experimental settings are performed with respect to the same standard systemconfiguration, which is defined in terms of the following parameters: Alignment set used for tuple extraction: UNION Tuple vocabulary pruning parameter: N = 20 for Spanish to English, andN = 30 for English to Spanish N-gram size used in translation model: 3 N-gram size used in target language model: 3 Expanded translation model with embedded-word tuples: YES Source-nulled tuple handling strategy: attach-to-right Feature functions considered: target language, word-bonus,source-to-target lexicon, and target-to-source lexiconIn the three experimental settings considered, which are presented in the followingsubsections, a total of seven different system configurations are evaluated in bothtranslation directions, English to Spanish and Spanish to English.
Thus, a total of 14different translation experiments are performed.
For each of these cases, the corre-sponding test set is translated by using the corresponding estimated models and setof optimal coefficients.
The same decoder settings (which were previously described inSection 4.2.4) that were used during the optimizations are used for all translationexperiments.
Translation results are evaluated in terms of mWER and BLEU by usingthe two references available for each language test set.5.1.1 Feature Function Contributions.
This experiment is designed to evaluate therelative contribution of feature functions to the overall system performance.
In thissection, four different systems are evaluated.
These systems are: System A.
This constitutes the basic n-gram translation system, whichimplements the tuple trigram translation model alone, that is, noadditional feature function is used. System B.
This is a target-reinforced system.
In this system, the translationmodel is used along with the target-language and word-bonus models. System C. This is a lexicon-reinforced system.
In this system, thetranslation model is used along with the source-to-target andtarget-to-source lexicon models. System D. This constitutes the full system, that is, the translation model isused along with all four additional feature functions.
This systemcorresponds to the standard system configuration that was defined at thebeginning of Section 5.1.Table 5 summarizes the results of this evaluation, in terms of BLEU and mWER, forthe four systems considered.
As can be seen from the table, both translation directions,540Marin?o et al N-gram-based Machine TranslationTable 5Evaluation results for experiments on feature function contribution.Direction System ?lm ?wb ?s2t ?t2s mWER BLEUES ?
EN A ?
?
?
?
39.71 0.4745B 0.29 0.31 ?
?
39.51 0.4856C ?
?
0.77 0.08 35.77 0.5356D 0.49 0.30 0.94 0.25 34.94 0.5434EN ?
ES A ?
?
?
?
44.46 0.4276B 0.33 0.27 ?
?
44.67 0.4367C ?
?
0.29 0.15 41.69 0.4482D 0.66 0.73 0.32 0.47 40.34 0.4688Spanish to English and English to Spanish, are considered.
Table 5 also presents theoptimized log-linear coefficients associated with the features considered in each systemconfiguration (the log-linear weight of the translation model has been omitted from thetable because its value is fixed to 1 in all cases).As can be observed in Table 5, the inclusion of the four feature functions intothe translation system definitively produces a significant improvement in translationquality in both translation directions.
In particular, it becomes evident that the featureswith the most impact on translation quality are the lexicon models.
The target languagemodel and the word bonus also contribute to improving translation quality, but to alesser degree.Also, although it is more evident in the English-to-Spanish direction than in theopposite one, it can be noticed from the presented results that the contribution oftarget-language and word-bonus models is more relevant when the lexicon mod-els are used (full system).
In fact, as seen from the ?lm values in Table 5, whenthe lexicon models are not included, the target-language model contribution to theoverall translation system becomes much less significant.
A comparative analysis ofthe resulting translations suggests that including the lexicon models tends to favorshort tuples over long ones, so the target-language model becomes more importantfor providing target context information when the lexicon models are used.
How-ever, more experimentation and research are required for fully understanding thisinteresting result.Another important observation, which follows from comparing results betweenboth translation directions, is that in all cases the Spanish-to-English translations areconsistently and significantly better than the English-to-Spanish translations.
This isclearly due to the more inflected nature of Spanish vocabulary.
For example, the singleEnglish word the can generate any of the four Spanish words el, la, los, and las.
Similarsituations occur with nouns, adjectives, and verbs that may have many different formsin Spanish.
This would suggest that the English-to-Spanish translation task is moredifficult than the Spanish-to-English task.5.1.2 Translation and Language N-gram Size.
This experiment is designed to evaluatethe impact of translation- and language-model n-gram sizes on overall system perform-ance.
In this section, the full system (System D in the previous experiment) is com-pared with two similar systems for which 4-grams are used for training the translation541Computational Linguistics Volume 32, Number 4model and/or the target language model.
More specifically, the three systems comparedin this experiment are: System D, which implements a tuple trigram translation model and a wordtrigram target language model.
This system corresponds to the standardsystem configuration that was defined at the beginning of Section 5.1. System E, which implements a tuple trigram translation model and a word4-gram target language model. System F, which implements a tuple 4-gram translation model and a word4-gram target language model.Table 6 summarizes the results of this evaluation for Systems E, F, and D. Again, bothtranslation directions are considered and the optimized coefficients associated with thefour feature functions are also presented for each system configuration.As can be seen in Table 6, the use of 4-grams for model computation does notprovide a clear improvement in translation quality.
This is more evident in the English-to-Spanish direction for which System F happens to be the worst ranked one, whileSystem D is the one obtaining the best mWER score and system E is the one obtainingthe best BLEU score.
On the other hand, in the Spanish-to-English direction, it seemsthat a little improvement with respect to System D is achieved by using 4-grams.However, it is not clear which system performs the best since System E obtains thebest BLEU score while System F obtains the best mWER score.According to these results, more experimentation and research are required to fullyunderstand the interaction between the n-gram sizes of translation and target languagemodels.
Notice that in the particular case of the n-gram SMT system described here,such an interaction is not evident at all since the n-gram-based translation model itselfcontains some of the target language model information.5.1.3 Source-nulled Tuple Strategy Comparison.
This experiment is designed to eval-uate a different strategy for handling source-nulled tuples.
In this section, the standardsystem configuration (System D) presented at the beginning of Section 5.1, which imple-ments the attach-to-right strategy described in Section 2.2.2, is compared with a similarsystem (referred to as System G) implementing a more complex strategy for handlingthose tuples with NULL source sides.
More specifically, the latter system uses theIBM-1 lexical parameters (Brown et al 1993) for computing the translation probabilitiesof two possible new tuples: the one resulting when the null-aligned-word is attached toTable 6Evaluation results for experiments on n-gram size incidence.Direction System ?lm ?wb ?s2t ?t2s mWER BLEUES ?
EN D 0.49 0.30 0.94 0.25 34.94 0.5434E 0.50 0.54 0.66 0.45 34.66 0.5483F 0.66 0.50 1.01 0.57 34.59 0.5464EN ?
ES D 0.66 0.73 0.32 0.47 40.34 0.4688E 0.57 0.45 0.51 0.26 40.55 0.4714F 1.24 1.07 0.99 0.57 40.91 0.4688542Marin?o et al N-gram-based Machine Translationthe previous word and the one resulting when it is attached to the following one.
Then,the attachment direction is selected according to the tuple with the highest translationprobability.Table 7 summarizes the results of evaluation Systems D and G. Again, both trans-lation directions are considered and the optimized coefficients associated with the fourfeature functions are also presented for each system configuration.As can be seen in Table 7, consistently better results are obtained in both translationtasks when using IBM-1 lexicon probabilities to handle tuples with a NULL sourceside.
Even though slight improvements are achieved in both cases, especially withthe English-to-Spanish translation task, the results show how the initial attach-to-rightstrategy is easily improved by making use of some bilingual knowledge.5.2 Error AnalysisIn this last section, we present a brief description of an error analysis performedon some of the outputs provided by the standard system configuration that was de-scribed in Section 5.1 (system D).
More specifically, a detailed review of 100 trans-lated sentences and their corresponding source sentences, in each direction, wasconducted.
This analysis was very useful since it allowed us to identify the most com-mon errors and problems related to our n-gram based SMT system in each translationdirection.A detailed analysis of all the reviewed translations reveals that most translationproblems encountered are typically related to four basic different types of errors: Verbal forms: A significant number of wrong verbal tenses and auxiliaryforms were detected.
This problem turned out to be the most commonone, reflecting the difficulty of the current statistical approach to capturethe linguistic phenomena that shape head verbs, auxiliary verbs, andpronouns into full verbal forms in each language, especially given theinflected nature of the Spanish language. Omitted translations: A large number of translations involving tuples withNULL target sides were detected.
Although in some cases these situationscorresponded to correct translations, most of the time they resulted inomitted-word errors. Reordering problems: The two specific situations that most commonlyoccurred were problems related to adjective?noun and subject?verbstructures.Table 7Evaluation results for experiments on strategies for handling source-nulled tuples.Direction System ?lm ?wb ?s2t ?t2s mWER BLEUES ?
EN D 0.49 0.30 0.94 0.25 34.94 0.5434G 0.49 0.45 0.78 0.39 34.15 0.5451EN ?
ES D 0.66 0.73 0.32 0.47 40.34 0.4688G 0.96 0.93 0.53 0.44 40.12 0.4694543Computational Linguistics Volume 32, Number 4 Concordance problems: Inconsistencies related to gender and numberwere the most commonly found.Table 8 presents the relative number of occurrences for each of the four types of errorsidentified in both translation directions.Notice in Table 8 that the most common errors in both translation directions arethose related to verbal forms.
However, it is important to mention that 29.5% of verbal-form errors in the English-to-Spanish direction actually correspond to verbal omissions.Similarly, 12.8% of verbal-form errors in the Spanish-to-English direction are verbalomissions.
According to this, if errors due to omitted translations and to omitted verbalforms are considered together, it is evident that errors involving omissions constitutethe most important group, especially in the case of English-to-Spanish translations.
Itis also interesting to note that the Spanish-to-English direction exhibits more omitted-translation errors that are not related to verbal forms than the English-to-Spanishdirection.Also in Table 8, it can be seen that concordance errors affect more than twice as manyEnglish-to-Spanish translations as Spanish-to-English ones.
This result can be explainedby the more inflected nature of Spanish.Finally, as an illustrative example, three Spanish-to-English translation outputs arepresented below.
For each presented example, errors have been boldfaced and correcttranslations are provided in brackets:Example 1The policy of the European Union on Cuba NULL must [must not] change.Example 2To achieve these purposes, it is necessary NULL for the governments to be allocated[to allocate], at least, 60,000 million NULL dollars a year .
.
.Example 3In the UK we have NULL [already] laws enough [enough laws], but we want to encourageNULL other States .
.
.5.3 N-gram-based SMT Compared with Phrase-Based SMTThe n-gram-based translation system here described has been also evaluated and com-pared to other phrase-based translation systems in the context of the European ProjectTable 8Percentage of occurrence for each type of error in English-to-Spanish and Spanish-to-Englishtranslations that were studied.Type of error English-to-Spanish Spanish-to-EnglishVerbal forms 31.3% 29.9%Omitted translations 22.0% 26.1%Reordering problems 15.9% 19.7%Concordance problems 10.8% 4.6%Other errors 20.0% 19.7%544Marin?o et al N-gram-based Machine TranslationTC-STAR.
A detailed description of the first evaluation campaign (including the maincharacteristics of every system) is available through the consortium?s Web site as aprogress report (Ney et al 2005).Table 9 presents the four best BLEU results for the EPPS translation task in thefirst TC-STAR?s evaluation campaign, where the results corresponding to our n-gram-based translation system are provided in brackets.
A total of six systems were evaluatedin this evaluation campaign.
The task consisted of two translation directions: Englishto Spanish and Spanish to English, and three different evaluation conditions: finaltext edition, verbatim, and ASR output.
The final text edition condition correspondsto the official transcripts of the EPPS, so it is actually a written-language translationcondition.
On the other hand, the other two conditions are spoken-language transla-tion conditions.
More specifically, the verbatim condition corresponds to literal tran-scriptions of parliamentary speeches, which include hesitations, repeated words, andother spontaneous speech effects; and the ASR output condition corresponds to theoutput of an automatic speech recognition system, so it additionally includes speech-recognition errors.As can be seen in Table 9, performance of the n-gram-based translation system isamong the three best systems for the translation directions and conditions consideredin the first TC-STAR evaluation campaign.Another independent comparison of the translation system proposed here withother phrase-based translation systems is available through the results of the secondshared task of the ACL 2005 workshop on ?Building and using parallel texts: Data-driven machine translation and beyond.?
In this shared task, which was entitled ?Ex-ploiting Parallel Texts for Statistical Machine Translation,?
our n-gram-based translationsystem was evaluated in four different translation directions: Spanish to English, Frenchto English, German to English, and Finish to English (Banchs et al 2005).
The domainof this task was also the European Parliament; however, the data set considered in thisevaluation was different from the one used in TC-STAR?s evaluation campaign.
Thefinal text edition condition (official transcripts) was the only one considered here.
A totalof twelve different systems participated in this shared task.
Table 10 presents the fourbest BLEU results for each of the four translation directions considered in the sharedtask.
Again, results corresponding to our n-gram-based translation system are providedin brackets.As can be seen in Table 10, the performance of the n-gram-based translation systemis among the three best systems for the four translation directions considered in theACL 2005 workshop shared task.
The third system in Table 10 for ES to EN translationTable 9The four best BLEU results for the EPPS translation task in TC-STAR?s first evaluation campaign.N-gram based system results are provided in brackets.
All BLEU values presented here havebeen taken from TC-STAR?s SLT Progress Report, available at: http://www.tc-star.org/.Direction Condition First Second Third FourthES ?
EN Final text edition [53.3] 53.1 47.5 46.1Verbatim 45.9 44.1 [42.1] 38.1ASR output 41.5 39.7 [37.7] 34.7EN ?
ES Final text edition [46.2] 45.2 38.9 37.6Verbatim 42.5 [38.1] 36.8 33.4ASR output 38.7 34.3 [33.8] 33.0545Computational Linguistics Volume 32, Number 4Table 10The four best BLEU results for the four translation directions considered in the shared task?Exploiting Parallel Texts for Statistical Machine Translation?
(ACL 2005 workshop on?Building and using parallel texts: Data-driven machine translation and beyond?).
N-gram-based system results are provided in brackets.
All BLEU values presented here have beentaken from the shared task?s Web site: http://www.statmt.org/wpt05/mt-shared-task/.Direction Condition First Second Third FourthFR ?
EN Final text edition 30.27 [30.20] 29.53 28.89ES ?
EN Final text edition 30.95 [30.07] 29.84 29.08DE ?
EN Final text edition 24.77 [24.26] 23.21 22.91FI ?
EN Final text edition 22.01 20.95 [20.31] 18.87deserves some comment.
This system is a conventional phrase-based system sharingthe same decoder MARIE, IBM features, word bonus, and target-language model as then-gram-based system.
The specific characteristics of the phrase-based system are directand inverse phrase conditional probabilities and phrase penalty.
Additional compar-isons between an n-gram system and a phrase-based system sharing a common decoderand training and test framework can be found in Crego et al (2005c).6.
Conclusions and Further WorkAs can be concluded from the results presented, the tuple n-gram translation model,when used along with additional feature functions, provides state-of-the-art transla-tions for the considered translation directions.Another important result is that the quality of Spanish-to-English translations issignificantly and consistently better than those obtained in English-to-Spanish transla-tions.
Consequently, significant efforts should be dedicated towards properly exploitingmorphological analysis and synthesis methods for improving English-to-Spanish trans-lation quality.Additionally, four commonly occurring types of translation errors were identifiedby reviewing a significant number of translated sentence pairs.
This analysis has pro-vided us with useful hints for future research and improvement of our SMT system.However, more evaluation and discussion are required in this area in order to fullyunderstand these common translation failures and then implementing appropriatesolutions.All the experiments presented in this work were performed using monotone de-coding, and no reordering strategies were implemented.
Although this system con-figuration proved to provide state-of-the-art translations for the tasks presented, thismay not hold for tasks involving more distant language pairs for which reorderingcapabilities must be implemented.
Accordingly, along with other results obtained inthe present work, we consider that further research on n-gram SMT should focus on thefollowing issues: Reordering strategies, as well as non-monotonous decoding schemes, forthe proposed SMT system must be developed and tested.
As mentionedbefore, reordering problems specifically related to adjective?noun andsubject?verb structures occur very often in Spanish-to-English and546Marin?o et al N-gram-based Machine TranslationEnglish-to-Spanish translations.
Preliminary results concerning the use ofword class deterministic reordering and POS-tag-based reorderingpatterns can be found in Costa-jussa`, Fonollosa, and Monte (2006) andCrego and Marin?o (2006), respectively. An effective long-tuple unfolding strategy must be developed to avoidthe occurrence of long tuples resulting from long alignment links, whichhappens to be a common situation when dealing with translationsbetween distant pairs of languages.
This problem is closely related toreordering, and some preliminary results have been presented by Crego,Marin?o, and de Gispert (2005b). The definition of the tuple as a bilingual pair will be revised in order tobetter handle unaligned words in both the source and the target sides.
Asmentioned above, a better strategy for dealing with target words alignedto NULL is required.
Similarly, a better handling of NULLs in the targetside will result in fewer omitted-translation errors. The extension of the embedded-word concept to the more general idea ofembedded n-grams should be evaluated and implemented.
Accordingly, atranslation probability should be estimated for those groups of wordsthat always occur embedded in tuples.
This would guarantee that thedecoder will always have a translation option for any given word or wordcombination previously seen in the training data.
Further work is requiredto determine the relative impact of these embedded n-grams on thetranslation model, and the most appropriate strategy for handling them. Linguistic information must be used to cope with the observedmorphological problems in the English-to-Spanish translation direction,as well as the more general problem of incorrect verbal form translations.In this regard, ongoing research on linguistic tuples classification isbeing done in order to improve translation results.
Preliminary resultson detecting and classifying verb forms have been presented byde Gispert (2005). A more detailed error analysis than the one presented in Section 5.2 isrequired to fully understand the n-gram SMT system behavior and thespecific causes of each resulting type of error.
It would be very useful forimproving our translation system performance to clearly identify whetherthese errors are due to unseen information while training, to modelingproblems, or to decoding errors.AcknowledgmentsThis work has been partly funded by theEuropean Union under the integrated projectTC-STAR (Technology and Corpora forSpeech to Speech Translation) (IST-2002-FP6-506738, http://www.tc-star.org), theSpanish Department of Education andScience (MEC), the Department ofUniversities, Research and InformationSociety (Generalitat de Catalunya), andthe Universitat Polite`cnica de Catalunya.ReferencesBanchs, Rachel E., Josep Maria Crego,Adria` de Gispert, Patrik Lambert, andJose?
Bernardo Marin?o.
2005.
Statisticalmachine translation of Euparl data byusing bilingual n-grams.
In ACL Workshopon Data-Driven Machine Translation andBeyond, pages 133?136, Ann Arbor, MI.Bangalore, Srinivas and Giuseppe Riccardi.2000.
Stochastic finite-state models forspoken language machine translation.547Computational Linguistics Volume 32, Number 4In Proceedings of the Workshop on EmbeddedMachine Translation Systems, pages 52?59,Seattle, WA.Berger, Adam, Stephen Della Pietra, andVincent Della Pietra.
1996.
A maximumentropy approach to natural languageprocessing.
Computational Linguistics,22(1):39?71.Brown, Peter, John Cocke, Stephen DellaPietra, Vincent Della Pietra, FrederickJelinek, John Lafferty, Robert Mercer, andPaul S. Roossin.
1990.
A statisticalapproach to machine translation.Computational Linguistics, 16(2):79?85.Brown, Peter, Stephen Della Pietra, VincentDella Pietra, and Robert Mercer.
1993.The mathematics of statistical machinetranslation: Parameter estimation.Computational Linguistics, 19(2):263?311.Casacuberta, Francisco.
2001.
Finite-statetransducers for speech input translation.
InProceedings IEEE ASRU, pages 375?380,Madonna di Campiglio, Italy.Casacuberta, Francisco and Enrique Vidal.2004.
Machine translation with inferredstochastic finite-state transducers.Computational Linguistics, 30(2):205?225.Costa-jussa`, Marta Ruiz, Jose?
Adria?nRodriguez Fonollosa, and Enric Monte.2006.
Using reordering in statisticalmachine translation based on alignmentblock classification.
Internal Report.http://gps-tsc.upc.es/veu/personal/mruiz/docs/br06.pdf.Crego, Josep Maria, Jose?
BernardoMarin?o, and Adria` de Gispert.
2004.Finite-state-based and phrase-basedstatistical machine translation.
InProceedings of the 8th InternationalConference on Spoken LanguageProcessing, pages 37?40, Jeju, Korea.Crego, Josep Maria, Jose?
Bernardo Marin?o,and Adria` de Gispert.
2005a.
AnNgram-based statistical machinetranslation decoder.
In INTERSPEECH2005, pages 3185?3188, Lisbon, Portugal.Crego, Josep Maria, Jose?
Bernardo Marin?o,and Adria` de Gispert.
2005b.
Reorderedsearch and tuple unfolding for Ngram-based SMT.
Proceedings of the TenthMachine Translation Summit, pages 283?289,Phuket, Thailand.Crego, Josep Maria, Marta Ruiz Costa-jussa`,Jose?
Bernardo Marin?o, and Jose?
Adria?nRodriguez Fonollosa.
2005c.
Ngram-based versus phrase-based statisticalmachine translation.
In Proceedings of theInternational Workshop on Spoken LanguageTranslation, pages 177?184, Pittsburgh, PA.Crego, Josep Maria and Jose?
BernardoMarin?o.
2006.
Integration of POStag-basedsource reordering into SMT decoding byan extended search graph.
In Proceedings ofthe 7th Biennial Conference of the Associationfor Machine Translation in the Americas,Boston, MA.de Gispert, Adria` and Jose?
Bernardo Marin?o.2002.
Using X-grams for speech-to-speech translation.
In Proceedings of the7th International Conference on SpokenLanguage Processing, pages 1885?1888,Denver, CO.de Gispert, Adria`, Jose?
Bernardo Marin?o, andJosep Maria Crego.
2004.
TALP:Xgram-based spoken language translationsystem.
In Proceedings of the InternationalWorkshop on Spoken Language Translation,pages 85?90, Kyoto, Japan.de Gispert, Adria`.
2005.
Phrase linguisticclassification and generalization forimproving statistical machine translation.In ACL?05 Student Workshop, pages 67?72,Ann Arbor, MI.Hutchins, John.
1986.
Machine Translation:Past, Present and Future.
Ellis Horwood,Chichester, England.Kay, Martin, Jean Mark Gawron, and PeterNorvig.
1992.
Verbmobil: A TranslationSystem for Face-to-Face Dialog.
CSLI.Kneser, Reinhard and Hermann Ney.
1995.Improved backing-off for m-gramlanguage modeling.
In IEEE InternationalConference on Acoustics, Speech and SignalProcessing, pages 49?52, Detroit, MI.Knight, Kevin and Yaser Al-Onaizan.1998.
Translation with finite-statedevices.
In AI Lecture Notes in ArtificialIntelligence, volume 1529, Springer-Verlag,pages 421?437.Koehn, Philippe, Franz Joseph Och,and Daniel Marcu.
2003.
Statisticalphrase-based translation.
In Proceedingsof the 2003 Meeting of the North Americanchapter of the ACL, pages 48?54, Edmonton,Alberta, Canada.Koehn, Philippe.
2002.
Europarl: Amultilingual corpus for evaluationof machine translation.
Availableonline at: http://people.csail.mit.edu/people/koehn/publications/europarl/.Marin?o, Jose?
Bernardo, Rafael E. Banchs,Josep Maria Crego, Adria` de Gispert,Patrik Lambert, Jose?
Adria?n RodriguezFonollosa, and Marta Ruiz.
2005.
BilingualN-gram statistical machine translation.In Proceedings of the Tenth MachineTranslation Summit, pages 275?282,Phuket, Thailand.548Marin?o et al N-gram-based Machine TranslationNey, Hermann, Volker Steinbiss, RichardZens, Evgeny Matusov, Jorge Gonza?lez,Young-suk Lee, Salim Roukos, MarcelloFederico, Muntsin Kolss, and RafaelBanchs.
2005.
SLT progress report.TC-STAR Deliverable D5, EuropeanCommunity project no.
FP6-506738.Available online at: http://www.tc-star.org/pages/f documents.htm.Och, Franz Joseph and Hermann Ney.2000.
Improved statistical alignmentmodels.
In Proceedings of the 38th AnnualMeeting of the ACL, pages 440?447,Hong Kong, China.Och, Franz Joseph and Hermann Ney.
2002.Discriminative training and maximumentropy models for statistical machinetranslation.
In Proceedings of the 40thAnnual Meeting of the ACL, pages 295?302,Philadelphia, PA.Och, Franz Joseph and Hermann Ney.
2003.A systematic comparison of variousstatistical alignment models.
ComputationalLinguistics, 29(1):19?51.Och, Franz Joseph, Daniel Gildea, SanjeevKhudanpur, Anoop Sarkar, Kenji Yamada,Alexander Fraser, Shankar Kumar, LibinShen, David Smith, Katharine Eng, VirenJain, Zhen Jin, and Dragomir Radev.
2004.A smorgasbord of features for statisticalmachine translation.
In Proceedings of theHuman Language Technology ConferenceNAACL, pages 161?168, Boston, MA, May.Papineni, Kishore, Salim Roukos, ToddWard, and Wei-Jing Zhu.
2002.
Bleu:A method for automatic evaluation ofmachine translation.
In Proceedings of the40th Annual Conference of the ACL,pages 311?318, Philadelphia, PA.Press, William H., Saul Teukolsky, WilliamVetterling, and Brian P. Flannery.2002.
Numerical Recipes in C++: TheArt of Scientific Computing, CambridgeUniversity Press.Riccardi, Giuseppe, Roberto Pieraccini, andEnrico Bocchieri.
1996.
Stochastic automatafor language modeling.
Computer Speechand Language, 10(4):265?293.Shannon, Claude E. 1949.
Communicationtheory of secrecy systems.
Bell SystemTechnical Journal, 28:656?715.Shannon, Claude E. 1951.
Prediction andentropy of printed English.
Bell SystemTechnical Journal, 30:50?64.Shannon, Claude E. and Warren Weaver.1949.
The Mathematical Theory ofCommunication, University of IllinoisPress, Urbana, IL.Stolcke, Andreas 2002.
SRLIM: An extensiblelanguage modeling toolkit.
In Proceedingsof the International Conference on SpokenLanguage Processing, pages 901?904,Denver, CO.Tillmann, Christoph and Fei Xia.
2003.
Aphrase-based unigram model for statisticalmachine translation.
In Proceedings ofHLT-NAACL - Short Papers, pages 106?108,Edmonton, Alberta, Canada.Vidal, Enrique.
1997.
Finite-state speech-to-speech translation.
In Proceedings of 1997IEEE International Conference on Acoustics,Speech and Signal Processing, pages 111?114,Munich, Germany.Weaver, Warren.
1955.
Translation.
InWilliam Locke and A. Donald Booth,editors, Machine Translation of Languages:Fourteen Essays.
John Wiley & Sons, NewYork, pages 15?23.Zens, Richard, Franz Joseph Och, andHermann Ney.
2002.
Phrase-basedstatistical machine translation.
In25th German Conference on ArtificialIntelligence, pages 18?32, September.Aachen, Springer Verlag.549
