Plan-Based Dialogue Management in a Physics TutorReva FreedmanLearning Research and Development CenterUniversity of PittsburghPittsburgh, PA 15260freedrk+@pitt, eduhttp://www.pitt, edu/~freedrkAbstractThis paper describes an application of APE (theAtlas Planning Engine), an integrated planning andexecution system at the heart of the Atlas dialoguemanagement system.
APE controls a mixed-initiative dialogue between a human user and ahost system, where turns in the 'conversation' mayinclude graphical actions and/or written text.
APEhas full unification and can handle arbitrarilynested discourse constructs, making it morepowerful than dialogue managers based on finite-state machines.
We illustrate this work bydescribing Atlas-Andes, an intelligent tutoringsystem built using APE with the Andes physicstutor as the host.1 IntroductionThe purpose of the Atlas project is to enlarge thescope of student interaction in an intelligenttutoring system (ITS) to include coherentconversational sequences, including both writtentext and GUI actions.
A key component of Atlasis APE, the Atlas Planning Engine, a "just-in-time" planner specialized for easy constructionand quick generation of hierarchically organizeddialogues.
APE is a domain- and task-independentsystem.
Although to date we have used APE as adialogue manager for intelligent tutoring systems,APE could also be used to manage other types ofhuman-computer conversation, such as an advice-giving system or an interactive help system.Planning is an essential component of adialogue-based ITS.
Although there are manyreasons for using natural anguage in an ITS, assoon as the student gives an unexpected responseto a tutor question, the tutor needs to be able toThis research was supported by NSF grant number9720359 to CIRCLE, the Center for InterdisciplinaryResearch on Constructive Learning Environments attheUniversity of Pittsburgh and Carnegie-MellonUniversity.plan in order to achieve its goals as well asrespond appropriately to the student's tatement.Yet classical planning is inappropriate fordialogue generation precisely because it assumesan unchanging world.
A more appropriateapproach is the "practical reason" approachpioneered by Bratman (1987, 1990).
According toBratman, human beings maintain plans and preferto follow them, but they are also capable ofchanging the plans on the fly when needed.Bratman's approach has been introduced intocomputer science under the name of reactiveplanning (Georgeff and Ingrand 1989, Wilkins etal.
1995).In this paper we discuss the rationale for the useof reactive planning as well as the use of thehierarchical task network (HTN) style of planoperators.
Then we describe APE (the AtlasPlanning Engine), a dialogue planner we haveimplemented to embody the above concepts.
Wedemonstrate he use of APE by showing how wehave used it to add a dialogue capability to anexisting ITS, the Andes physics tutor.
By showingdialogues that Atlas-Andes can generate, wedemonstrate the advantages of this architectureover the finite-state machine approach to dialoguemanagement.2 Integrated planning and execution fordialogue generation2.1 'Practical reason' and the BDI modelFor an ITS, planning is required in order to ensurea coherent conversation as well as to accomplishtutorial goals.
But it is impossible to plan a wholeconversation in advance when the student canrespond freely at every turn, just as human beingscannot plan their daily lives in advance because ofpossible changes in conditions.
Classical planningalgorithms are inappropriate because the tutormust be able to change plans based on the52student's responses.For this reason we have adopted the ideas of thephilosopher Michael Bratman (1987, 1990).Bratman uses the term "practical reason" todescribe his analysis since he is concerned withhow to reason about practical matters.
For humanbeings, planning is required in order toaccomplish one's goals.
Bratman's key insight isthat human beings tend to follow a plan once theyhave one, although they are capable of droppingan intention or changing a partial plan whennecessary.
In other words, human beings do notdecide what to do from scratch at each turn.Bratman and others who have adopted hisapproach use a tripartite mental model thatincludes beliefs, desires and intentions (Bratman,Israel and Pollack 1988, Pollack 1992, Georgeffet al 1998), hence the name "BDI model.
"Beliefs, which are uninstantiated plans in thespeaker's head, are reified by the plan library.Desires are expressed as the agent's goals.Intentions, or plan steps that the agent hascommitted to but not yet acted on, are stored in anagenda.
Thus the agent's partial plan forachieving a goal is a network of intentions.
A plancan be left in a partially expanded state until it isnecessary to refine it further.2.2 Implementation via reactive planningBratman's approach has been elaborated in acomputer science context by subsequentresearchers (Bratman, Israel and Pollack 1988,Pollack 1992, Georgeff et al 1998).
Reactiveplanning (Georgeff and Ingrand 1989, Wilkins etal.
1995), originally known as "integratedplanning and execution," is one way ofimplementing Bratman's model.
Originallydeveloped for real-time control of the spaceshuttle, reactive planning has since been used in avariety of other domains.
For the Atlas project wehave developed a reactive planner called APE(Atlas Planning Engine) which uses these ideas toconduct a conversation.
After each studentresponse, the planner can choose to continue withits previous intention or change something in theplan to respond better to the student's utterance.Like most reactive planners, APE is ahierarchical task network (HTN) style planner(Yang 1990, Erol, Hendler and Nau 1994).Hierarchical decomposition asserts that each goalcan be achieved via a series of subgoals instead ofrelying on means-end reasoning.
Hierarchicaldecomposition is more appropriate to dialoguegeneration for a number of reasons.
First,decomposition is better suited to the type of large-scale dialogue planning required in a real-worldtutoring system, as it is easier to establish what ahuman speaker will say in a given situation thanto be able to understand why in sufficient detailand generality to do means-end planning.
Second,Hierarchical decomposition minimizes searchtime.
Third, our dialogues are task-oriented andhave a hierarchical structure (Grosz and Sidner1986).
In such a case, matching the structure ofthe domain simplifies operator developmentbecause they can often be derived from transcriptsof human tutoring sessions.
The hierarchyinformation is also useful in determiningappropriate referring expressions.
Fourth, inter-leaved planning and execution is important fordialogue generation because we cannot predict hehuman user's future utterances.
In an HTN-basedsystem, it is straightforward to implementinterleaved planning and execution because oneonly needs to expand the portion of the plan thatis about to be executed.
Finally, the conversationis in a certain sense the trace of the plan.
In otherwords, we care much more about the actionsgenerated by the planner than the states involved,whether implicitly or explicitly specified.Hierarchical decomposition provides this tracenaturally.3 Background: the Andes physics tutorAndes (Gertner, Conati and VanLehn 1998) is anintelligent tutoring system in the domain of first-year college physics.
Andes teaches via coachedproblem solving (VanLehn 1996).
In coachedproblem solving, the tutoring system tracks thestudent as the latter attempts to solve a problem.If the student gets stuck or deviates too far from acorrect solution path, the tutoring system provideshints and other assistance.A sample Andes problem is shown in mid-solution in Figure 1.
A physics problem is givenin the upper-left corner with a picture below it.Next to the picture the student has begun tosketch the vectors involved using the GUI buttonsalong the left-hand edge of the screen.
As the53student draws vectors, Andes and the studentcooperatively fill in the variable definitions in theupper-right corner.
Later the student will use thespace below to write equations connecting thevariables.In this example, the elevator is decelerating, sothe acceleration vector should face the oppositedirection from the velocity vector.
(If theacceleration vector went the same direction as thevelocity vector, the speed of the elevator wouldincrease and it would crash into the ground.)
Thisis an important issue in beginning physics; itoccurs in five Andes problems.When such errors occur, Andes turns theincorrect item red and provides hints to studentsin the lower-left corner of the screen.
A sample ofthese hints, shown in the order a student wouldencounter them, is shown in Fig.
2.
But hints arean output-only form of natural language; thestudent can't take the initiative or ask a question.In addition, there is no way for the system to askthe student a question or lead the student througha multi-step directed line of reasoning.
Thus thereis no way to use some of the effective rhetoricalmethods used by skilled human tutors, such asanalogy and reductio ad absurdum.
Currentpsychological research suggests that activemethods, where students have to answerquestions, will improve the performance oftutoring systems.4 Structure of the Atlas Planning EngineFigure3 shows a sample plan operator.
Forlegibility, the key elements have been rendered inEnglish instead of in Lisp.
The hiercx slotprovides a way for the planner to be aware of thecontext in which a decomposition is proposed.Items in the hiercx slot are instantiated and addedto the transient database only so long as theoperator which spawned them is in the agenda.To initiate a planning session, the user invokesthe planner with an initial goal.
The systemsearches the operator library to find all operatorswhose goal field matches the next goal on theagenda and whose filter conditions and precon-An elevator slows to a stop from an initial downward velocityof 10.0 m\]s in 2.00 seconds.
A passenger in the elevator isholding a 3.00 kilogram package by a vertical string.What is the tension in the string during the process?i ........ ii ....... i i i. I ?Y~TO e',ev~o, at 10 m/selev~or at a stopmass of p~:w'.,I,,~magnitude of the inst~?~taneous Velocity of pack, age ~ {rkne TO v._wmagnitude of the avelage Acceleratiorl of package ,dudng TO... a._xv_va~- - IpkgFigure I: Screen shot of the Andes physics tutor54S: (draws acceleration vector in same direction as velocity)T: Wrong.S: What's wrongwith that?T: Think about he direction of the acceleration vector.S: Please explain further.T: Remember that the direction of acceleration is the direction of the change in velocity.S: Please explain further.T: The'direction of the acceleration vector is straight up.S: (draws acceleration vector correctly)Figure 2: Andes hint sequence formatted as dialogueditions are satisfied.
Goals are represented infirst-order logic without quantifiers and matchedvia unification.
Since APE is intended especiallyfor generation of hierarchically organized task-oriented iscourse, each operator has a multi-steprecipe in the style of Wilkins (1988).
When amatch is found, the matching goal is removedfrom the agenda and is replaced by the steps inthe recipe.
APE has two kinds of primitiveactions; one ends a turn and the other doesn't.From the point of view of discourse generation,the most important APE recipe items are thoseallowing the planner to change the agenda whennecessary.
These three types of recipe items makeAPE more powerful than a classical planner.?
Fact: Evaluate a condition.
If false, skip therest of the recipe.
Fact is used to allow run-timedecision making by bypassing the rest of anoperator when circumstances change during itsexecution.
Fact can be used with retry-at toimplement a loop just as in Prolog.?
Retry-at.
The purpose of retry-at is to allowthe planner to back up to a choice point and makea new decision.
It removes goals sequentiallyfrom the top of the agenda, a full operator at atime, until the supplied argument is false.
Then itrestores the parent goal of the last operatorremoved, so that further planning can choose anew way to achieve it.
Retry-at implements aProlog-like choice of alternatives, but it differsfrom backtracking in that the new operator ischosen based on conditions that apply when theretry operation is executed, rather than on a list ofpossible operators formed when the originaloperator was chosen.
For retry-at o be useful, theauthor must provide multiple operators for thesame goal.
Each operator must have a set ofpreconditions enabling it to be chosen at theappropriate ime.?
Prune-replace: The intent of prune-replace is(de f -operator  hand le -same-d i rec t ion:goal  (...): f i l te r  ():p recond (...); We have  asked  a quest ion  about  acce le ra t ion; ... and the s tudent  has g iven  an answer; ... f rom wh ich  we can deduce  that  s /he  th inks  accel ,  and ve loc i ty  go in; the same d i rec t ion; and  we have  not  g iven  the exp lanat ion  be low yet: rec ipe  (...); Te l l  the s tudent :  "But i f  the acce le ra t ion  went  the samed i rec t ion  as the ve loc i ty ,  then the e levator  wou ld  be speed ing  up.
"; Mark  that  we are g iv ing  th is  exp lanat ion; Te l l  the s tudent  that  tu tor  is request ing  another  answer  ("Try aga in . "
); Ed i t  the agenda (us ing prune-replace) so that  respond ing  to anotheranswer  is at the top  of the agenda:h ie rcx  ())Figure 3: Sample plan operator55to allow the planner to remove goals from theagenda based on a change in circumstances.
Itremoves goals sequentially from the top of theagenda, one at a time, until the supplied argumentbecomes false.
Then it replaces the removed goalswith an optional ist of new goals.
Prune-replaceallows a type of decision-making frequently usedin dialogue generation.
When a conversationpartner does not give the expected response, onewould often like to remove the next goal from theagenda and replace it with one or morereplacement goals.
Prune-replace implements ageneralized version of this concept.APE is domain-independent a d communicateswith a host system via an API.
As a partner in adialogue, it needs to obtain information from theworld as well as produce output turns.Preconditions on plan operators can be used toaccess information from external knowledgesources.
APE contains a recipe item type that canbe used to execute an external program such as acall to a GUI interface.
APE also has recipe itemsallowing the user to assert and retract facts in aknowledge base.
Further details about the APEplanner can be found in (Freedman, 2000).5 Implementation of At las-Andes5.1 Architecture of Atlas-AndesThe first system we have implemented with APEis a prototype Atlas-Andes system that replacesthe hints usually given for an incorrectacceleration vector by a choice of generatedsubdialogues.
Figure 4 shows the architecture ofAtlas-Andes; any other system built with APEwould look similar.
Robust natural languageunderstanding in Atlas-Andes is provided byRos6's CARMEL system (Ros6 2000); it uses thespelling correction algorithm devised by Elmi andEvens (1998).5.2 Structure of human tutorial dialoguesIn an earlier analysis (Kim, Freedman and Evens1998) we showed that a significant portion ofhuman-human tutorial dialogues can be modeledwith the hierarchical structure of task-orienteddialogues (Grosz and Sidner 1986).
Furthermore,a main building block of the discourse hierarchy,corresponding to the transaction level inConversation Analysis (Sinclair and Coulthard1975), matches the tutoring episode defined byVanLehn et al (1998).
A tutoring episodeconsists of the turns necessary to help the studentmake one correct entry on the interface.NLU(CARMEL) Plan LibraryUser APE< Interface II IGUI TransientInterpreter Knowledge(Andes) BaseHost(Andes)Figure 4: Interface between Atlas and host system56To obtain empirical data for the Atlas-Andesplan operators, we analyzed portions of a corpusof human tutors helping students olve similarphysics problems.
Two experienced tutors wereused.
Tutor A was a graduate student in computerscience who had majored in physics; tutor B wasa professional physics tutor.The complete corpus contained solutions to fivephysics problems by 41 students each.
Weanalyzed every tutoring episode dealing with theacceleration vector during deceleration, totaling29 examples divided among 20 students and bothtutors.
The tutors had very different styles.Tutor A tended to provide encouragement ratherthan content, making those transcripts less usefulfor deriving an information-based approach.Tutor B used an information-based approach, butafter one wrong answer tended to complete thesolution as a monologue.
Largely followingtutor B's approach to sequence and content, weisolated six ways of teaching the student aboutdirection of acceleration.5.3 Sample output and evaluationFigure 5 shows an example of text that can begenerated by the Atlas-Andes ystem, showing ananalogy-based approach to teaching this content.The operator library used to generate this textcould generate a combinatorially arge number ofversions of this dialogue as well as selectedexamples of other ways of teaching aboutdirection of acceleration.This operator library used to generate this textcontained 1l 1 plan operators, divided as follows:Tutoring schemataSwitching between schemataAPI and GUI handlingAnswer handlingDomain-dep.
lex.
insertionDomain-indep.
lex.
insertionTOTAL4 4%5 4%33 30%35 31%24 22%10 9%111 100%We are currently working on components hat willallow us to increase the number of physicsconcepts covered without a correspondingincrease in the number of operators.
The schemaswitching operators prevent the tutor fromrepeating itself during a physics problem.
Theycould be reduced or eliminated by a generaldiscourse history component that tutoring schemaoperators could refer to.
Domain-dependentlexical insertion refers to the choice of lexicalitems such as car and east in the sample dialogue,while domain-independent iexical insertion refersto items such as OK and exactly.
Both categoriescould be eliminated, or at least severely reduced,through the use of a text realization package.Together that would provide a one-third reductionin the number of operators needed.
As the set ofAPI and GUI handling operators is fixed, thatwould reduce by half the number of applicationoperators needed.The largest remaining category of operators isthe answer handlers.
These operators handle avariety of answers for each of the five questionsthat the system can ask.
The answers werecognize include categories such as "don'tknow" as well as specific answers (e.g.
a directionperpendicular to the correct answer) which werecognize because the tutor has specific repliesfor them.
In order to reduce the number ofS: (draws acceleration vector in same direction as velocity)T: What is the definition of acceleration?S: Don't know.T: OK, let's try this.
If a car was driving along east, which way would you have to push on itto make it stop?S: West.T: Exactly.
The opposite direction.
So the net force goes the opposite direction, and so doesthe acceleration.
Try to draw the acceleration vector again now.S: (draws acceleration vector correctly)Figure 5: Example of generated ialogue57operators further, we must investigate moregeneral methods of handling student errors.
Inparticular, we plan to investigate error-classifyingpredicates that apply to more than one question aswell as the use of intention-based predicates.Since the system only covers one rule of physics,albeit in a variety of ways, we plan to make someof these efficiency improvements before addingnew rules of physics and testing it with users.Preconditions for the operators in the planlibrary utilize discourse or interaction history, thecurrent goal hierarchy, recent information such asthe tutor's current goal and the student's latestresponse, shared information such as a model ofobjects on the screen, and domain knowledge.
Asan example of the latter, if the student draws anacceleration vector which is incorrect but notopposite to the velocity vector, a differentresponse will be generated.5.4 DiscussionMany previous dialogue-based ITSs have beenimplemented with finite-state machines, eithersimple or augmented.
In the most common finitestate mode\[, each time the human user issues anutterance, the processor educes it to one of asmall number of categories.
These categoriesrepresent the possible transitions between states.Thus history can be stored, and contextconsidered, only by expanding the number ofstates.
This approach puts an arbitrary restrictionon the amount of context or depth ofconversational nesting that can be considered.More importantly, it misses the significantgeneralization that these types of dialogues arehierarchical: larger units contain repeatedinstances of the same smaller units in differentsequences and instantiated with different values.Furthermore, the finite-state machine approachdoes not allow the author to drop one line ofattack and replace it by another without hard-coding every possible transition.It is also clear that the dialogue-based approachhas many benefits over the hint-sequenceapproach.
In addition to providing a multi-stepteaching methods with new content, it canrespond flexibly to a variety of student answers ateach step and take context into account whengenerating a reply.6 Related workWenger (1987), still the chief textbook on ITSs,states that using a global planner to control an ITSis too inefficient to try.
This is no longer true, ifindeed it ever was.
Vassileva (1995) proposes asystem based on AND-OR graphs with a separateset of rules for reacting to unexpected events.Lehuen, Nicolle and Luzzati (1996) present amethod of dialogue analysis that producesschemata very similar to ours.
Earlier dialogue-based ITSs that use augmented finite-statemachines or equivalent include CIRCSIM-Tutor(Woo et al 1991, Zhouet al 1999) and thesystem described by Woolf (1984).
Cook (1998)uses levels of finite-state machines.
None of thesesystems provides for predicates with variables orunification.7 ConclusionsIn this paper we described APE, an integratedplanner and execution system that we haveimplemented as part of the Atlas dialoguemanager.
APE uses HTN-style operators and isbased on reactive planning concepts.
AlthoughAPE is intended largely for use in domains withhierarchical, multi-turn plans, it can be used toimplement any conversation-based system, whereturns in the 'conversation' may include graphicalactions and/or text.
We illustrated the use of APEwith an example from the Atlas-Andes physicstutor.
We showed that previous models based onfinite-state machines are insufficient to handle thenested subdialogues and abandoned partialsubdialogues that occur in practical applications.We showed how APE generated a sampledialogue that earlier systems could not handle.AcknowledgmentsWe thank Abigail Gertner for her generousassistance with the Andes system, and MichaelRingenberg for indispensible programmingsupport.
Carolyn Ros6 built the CARMELnatural language understanding component.Mohammed EImi and Michael Glass of IllinoisInstitute of Technology provided the spellingcorrection code.
We thank Pamela Jordan and thereferees for their comments.B8ReferencesBratman, M. E. 1987.
Intentions, Plans, and PracticalReason.
Cambridge, MA: Harvard.Bratman, M. E. 1990.
What is Intention?
In P.R.Cohen, J. Morgan and M. E. Pollack, Intentions inCommunication.
Cambridge, MA: MIT Press.Bratman, M. E., Israel, D. J. and Pollack, M.E.
1988.Plans and Resource-Bounded Practical Reasoning.Computational Intelligence 4(4): 349-355.Cook, J.
1998.
Knowledge Mentoring as a Frameworkfor Designing Computer-Based Agents for Sup-porting Musical Composition Learning.
PhD.
diss.,Computing Department, The Open University.EImi, M.A.
and Evens, M.W.
1998.
SpellingCorrection using Context.
In Proceedings of the 17thCOLING/36th ACL (COLING-ACL '98), Montreal.Erol, K., Hendler, J. and Nau, D.S.
1994.
HTNPlanning: Complexity and Expressivity.
InProceedings of the Twelfth National Conference onArtificial Intelligence (AAAI '94), Seattle.Freedman, R. 2000 (to appear).
Using a ReactivePlanner as the Basis for a Dialogue Agent.
InProceedings of the Thirteenth Florida ArtificialIntelligence Research Symposium (FLAIRS'00),Orlando.Gertner, A.S., Conati, C. and VanLehn, K. 1998.Procedural Help in Andes: Generating Hints Using aBayesian Network Student Model.
In Proceedings ofthe Fifteenth National Conference on ArtificialIntelligence (AAAI '98), Madison.Georgeff, M. P. and Ingrand, F. F. 1989.
Decision-Making in an Embedded Reasoning System.
InProceedings of the Eleventh International JointConference on Artificial Intelligence (IJCAI '89),Detroit.Georgeff, M.P., Pell, B., Pollack, M. E., Tambe, M.and Wooldridge, M. 1998.
The Belief-Desire-Intention Model of Agency.
In N. Jenning, J. Muller,and M. Wooldridge (Eds.
), Intelligent Agents V.Springer.Grosz, B.J.
and Sidner, C.L.
1986.
Attention,Intentions, and the Structure of Discourse.Computational Linguistics 12(3): 175-204.Kim, J., Freedman, R. and Evens, M. 1998.Responding to Unexpected Student Utterances inCIRCSIM-Tutor v. 3: Analysis of Transcripts.
InProceedings of the Eleventh Florida ArtificialIntelligence Research Symposium (FLAIRS '98),Sanibel Island.Lehuen, J., Nicolle, A. and Luzzati, D. 1996.
Unmod61e hypoth6tico-exp6rimental dynamique pour lagestion des dialogues homme-machine.
In Actes dudixi6me congr6s de reconnaissance d s formes etintelligence artificielle (RFIA '96), Rennes.Pollack, M.E.
1992.
The Uses of Plans.
ArtificialIntelligence 57(1): 43-69.Ros6, C. P. 2000.
A Framework for Robust SemanticInterpretation.
In Proceedings of the First AnnualConference of the North American Chapter of theAssociation for Computational Linguistics(NAACL '00).Sinclair, J. M. and Coulthard, R. M. 1975.
Towards anAnalysis of Discourse: The English Used byTeachers and Pupils.
London: Oxford UniversityPress.VanLehn, K. 1996.
Conceptual and Meta Learningduring Coached Problem Solving.
In IntelligentTutoring Systems."
Third International Conference(ITS '96), Montreal.
Berlin: Springer.
LNCS 1086.VanLehn, K., Siler, S., Murray, C. and Baggett, W.1998.
What Makes a Tutorial Event Effective?
InProceedings of the Twenty-first Annual Conferenceof the Cognitive Science Society, Madison.
Hillsdale,N J: Erlbaum.Vassileva, J.
1995.
Reactive Instructional Planning toSupport Interacting Teaching Strategies.
InProceedings of the Seventh World Conference on AIand Education (AI-ED '95), Washington, D.C.Charlottesville, VA: AACE.Wenger, E. 1987.
Artificial Intelligence and TutoringSystems."
Computational nd Cognitive Approachesto the Communication of Knowledge.
San Mateo,CA: Morgan Kaufmann.Wilkins, D. 1988.
Practical Planning: Extending theClassical AI Planning Paradigm.
San Mateo, CA:Morgan Kaufmann.Wilkins, D., Myers, K., Lowrance, J. and Wesley, L.1995.
Planning and Reacting in Uncertain andDynamic Environments.
Journal of Experimentaland Theoretical Artificial Intelligence 7:121-152.Woo, C., Evens, M.W., Michael, J.A.
and Rovick,A.A.
1991.
Dynamic Instructional Planning for anIntelligent Physiology Tutoring System.
InProceedings of the Fourth Annual 1EEE Computer-Based Medical Systems Symposium, Baltimore.Woolf, B.
1984.
Context-Dependent Planning in aMachine Tutor.
Ph.D.
diss., Dept.
of Computer andInformation Science, University of Massachusetts atAmherst.
COINS Technical Report 84-21.Yang, Q.
1990.
Formalizing planning knowledge forhierarchical planning.
Computational Intelligence6(I): 12-24.Zhou, Y., Freedman, R., Glass, M., Michael, J.A.,Rovick, A.A. and Evens, M.W.
1999.
DeliveringHints in a Dialogue-Based Intelligent TutoringSystem.
In Proceedings of the Sixteenth NationalConference on Artificial Intelligence (AAAI '99),Orlando, FL.59
