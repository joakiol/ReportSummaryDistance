Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 85?88,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsDictionary Definitions based Homograph Identification using aGenerative Hierarchical ModelAnagha Kulkarni Jamie CallanLanguage Technologies InstituteSchool of Computer Science, Carnegie Mellon University5000 Forbes Ave, Pittsburgh, PA 15213, USA{anaghak, callan}@cs.cmu.eduAbstractA solution to the problem of homograph(words with multiple distinct meanings) iden-tification is proposed and evaluated in this pa-per.
It is demonstrated that a mixture modelbased framework is better suited for this taskthan the standard classification algorithms ?relative improvement of 7% in F1 measureand 14% in Cohen?s kappa score is observed.1 IntroductionLexical ambiguity resolution is an important re-search problem for the fields of information re-trieval and machine translation (Sanderson, 2000;Chan et al, 2007).
However, making fine-grainedsense distinctions for words with multiple closely-related meanings is a subjective task (Jorgenson,1990; Palmer et al, 2005), which makes it difficultand error-prone.
Fine-grained sense distinctionsaren?t necessary for many tasks, thus a possibly-simpler alternative is lexical disambiguation at thelevel of homographs (Ide and Wilks, 2006).Homographs are a special case of semanticallyambiguous words:  Words that can convey multi-ple distinct meanings.
For example, the word barkcan imply two very different concepts ?
?outerlayer of a tree trunk?, or, ?the sound made by adog?
and thus is a homograph.
Ironically, the defi-nition of the word ?homograph?
is itself ambiguousand much debated; however, in this paper we con-sistently use the above definition.If the goal is to do word-sense disambiguationof homographs in a very large corpus, a manually-generated homograph inventory may be impracti-cal.
In this case, the first step is to determine whichwords in a lexicon are homographs.
This problemis the subject of this paper.2 Finding the Homographs in a LexiconOur goal is to identify the homographs in a largelexicon.
We assume that manual labor is a scarceresource, but that online dictionaries are plentiful(as is the case on the web).
Given a word from thelexicon, definitions are obtained from eight dic-tionaries: Cambridge Advanced Learners Diction-ary (CALD), Compact Oxford English Dictionary,MSN Encarta, Longman Dictionary of Contempo-rary English (LDOCE), The Online Plain TextEnglish Dictionary, Wiktionary, WordNet andWordsmyth.
Using multiple dictionaries providesmore evidence for the inferences to be made andalso minimizes the risk of missing meanings be-cause a particular dictionary did not include one ormore meanings of a word (a surprisingly commonsituation).
We can now rephrase the problem defi-nition as that of determining which words in thelexicon are homographs given a set of dictionarydefinitions for each of the words.2.1 FeaturesWe use nine meta-features in our algorithm.
In-stead of directly using common lexical featuressuch as n-grams we use meta-features which arefunctions defined on the lexical features.
This ab-85straction is essential in this setup for the generalityof the approach.
For each word w to be classifiedeach of the following meta-features are computed.1.
Cohesiveness Score: Mean of the cosine simi-larities between each pair of definitions of w.2.
Average Number of Definitions: The averagenumber of definitions per dictionary.3.
Average Definition Length: The averagelength (in words) of definitions of w.4.
Average Number of Null Similarities: Thenumber of definition pairs that have zero co-sine similarity score (no word overlap).5.
Number of Tokens: The sum of the lengths(in words) of the definitions of w.6.
Number of Types: The size of the vocabularyused by the set of definitions of w.7.
Number of Definition Pairs with n WordOverlaps: The number of definition pairs thathave more than n=2 words in common.8.
Number of Definition Pairs with m WordOverlaps: The number of definition pairs thathave more than m=4 words in common.9.
Post Pruning Maximum Similarity: (below)The last feature sorts the pair-wise cosine similar-ity scores in ascending order, prunes the top n% ofthe scores, and uses the maximum remaining scoreas the feature value.
This feature is less ad-hocthan it may seem.
The set of definitions is formedfrom eight dictionaries, so almost identical defini-tions are a frequent phenomenon, which makes themaximum cosine similarity a useless feature.
Apruned maximum turns out to be useful informa-tion.
In this work n=15 was found to be most in-formative using a tuning dataset.Each of the above features provides someamount of discriminative power to the algorithm.For example, we hypothesized that on average thecohesiveness score will be lower for homographsthan for non-homographs.
Figure 1 provides anillustration.
If empirical support was observed forsuch a hypothesis about a candidate feature thenthe feature was selected.
This empirical evidencewas derived from only the training portion of thedata (Section 3.1).The above features are computed on definitionsstemmed with the Porter Stemmer.
Closed classwords, such as articles and prepositions, and dic-tionary-specific stopwords, such as ?transitive?,?intransitive?, and ?countable?, were also removed.Figure 1.
Histogram of Cohesiveness scores for Homo-graphs and Non-homographs.2.2 ModelsWe formulate the homograph detection process asa generative hierarchical model.
Figure 2 providesthe plate notation of the graphical model.
The la-tent (unobserved) variable Z models the class in-formation: homograph or non-homograph.
Node Xis the conditioned random vector (Z is the condi-tioning variable) that models the feature vector.Figure 2.
Plate notation for the proposed model.This setup results in a mixture model with twocomponents, one for each class.
The Z is assumedto be Bernoulli distributed and thus parameterizedby a single parameter p. We experiment with twocontinuous multivariate distributions, Dirichlet andMultivariate Normal (MVN), for the conditionaldistribution of X|Z.Z ~ Bernoulli (p)X|Z ~ Dirichlet (az)ORX|Z ~ MVN (muz, covz)We will refer to the parameters of the condi-tional distribution as ?z.
For the Dirichlet distribu-tion, ?z is a ten-dimensional vector az = (az1, ..,az10).
For the MVN, ?z represents a nine-dimensional mean vector muz = (muz1, .., muz9)Np ZX ?86and a nine-by-nine-dimensional covariance matrixcovz.
We use maximum likelihood estimators(MLE) for estimating the parameters (p, ?z).
TheMLEs for Bernoulli and MVN parameters haveanalytical solutions.
Dirichlet parameters were es-timated using an estimation method proposed andimplemented by Tom Minka1.We experiment with three model setups: Super-vised, semi-supervised, and unsupervised.
In thesupervised setup we use the training data describedin Section 3.1 for parameter estimation and thenuse thus fitted models to classify the tuning andtest dataset.
We refer to this as the Model I. InModel II, the semi-supervised setup, the trainingdata is used to initialize the Expectation-Maximization (EM) algorithm (Dempster et al,1977) and the unlabeled data, described in Section3.1, updates the initial estimates.
The Viterbi(hard) EM algorithm was used in these experi-ments.
The E-step was modified to include onlythose unlabeled data-points for which the posteriorprobability was above certain threshold.
As a re-sult, the M-step operates only on these high poste-rior data-points.
The optimal threshold value wasselected using a tuning set (Section 3.1).
The unsu-pervised setup, Model III, is similar to the semi-supervised setup except that the EM algorithm isinitialized using an informed guess by the authors.3 DataIn this study, we concentrate on recognizinghomographic nouns, because homographic ambi-guity is much more common in nouns than inverbs, adverbs or adjectives.3.1 Gold Standard DataA set of potentially-homographic nouns was identi-fied by selecting all words with at least two noundefinitions in both CALD and LDOCE.
This setcontained 3,348 words.225 words were selected for manual annotationas homograph or non-homograph by random sam-pling of words that were on the above list and usedin prior psycholinguistic studies of homographs(Twilley et al, 1994; Azuma, 1996) or on the Aca-demic Word List (Coxhead, 2000).Four annotators at, the Qualitative Data AnalysisProgram at the University of Pittsburgh, were1http://research.microsoft.com/~minka/software/fastfit/trained to identify homographs using sets of dic-tionary definitions.
After training, each of the 225words was annotated by each annotator.
On aver-age, annotators categorized each word in just 19seconds.
The inter-annotator agreement was 0.68,measured by Fleiss?
Kappa.23 words on which annotators disagreed (2/2vote) were discarded, leaving a set of 202 words(the ?gold standard?)
on which at least 3 of the 4annotators agreed.
The best agreement between thegold standard and a human annotator was 0.87kappa, and the worst was 0.78.
The class distribu-tion (homographs and non-homographs) was 0.63,0.37.
The set of 3,123 words that were not anno-tated was the unlabeled data for the EM algorithm.4 Experiments and ResultsA stratified division of the gold standard data inthe proportion of 0.75 and 0.25 was done in thefirst step.
The smaller portion of this division washeld out as the testing dataset.
The bigger portionwas further divided into two portions of 0.75 and0.25 for the training set and the tuning set, respec-tively.
The best and the worst kappa between ahuman annotator and the test set are 0.92 and 0.78.Each of the three models described in Section2.2 were experimented with both Dirichlet andMVN as the conditional.
An additional experimentusing two standard classification algorithms ?
Ker-nel Based Na?ve Bayes (NB) and Support VectorMachines (SVM) was performed.
We refer to thisas the baseline experiment.
The Na?ve Bayes clas-sifier outperformed SVM on the tuning as well asthe test set and thus we report NB results only.
Afour-fold cross-validation was employed for the allthe experiments on the tuning set.
The results aresummarized in Table 1.
The reported precision,recall and F1 values are for the homograph class.The na?ve assumption of class conditional fea-ture independence is common to simple Na?veBayes classifier, a kernel based NB classifier;however, unlike simple NB it is capable of model-ing non-Gaussian distributions.
Note that in spiteof this advantage the kernel based NB is outper-formed by the MVN based hierarchical model.
Ournine features are by definition correlated and thusit was our hypothesis that a multivariate distribu-tion such as MVN which can capture the covari-ance amongst the features will be a better fit.
Theabove finding confirms this hypothesis.87Table 1.
Results for the six models and the baseline on the tuning and test set.One of the known situations when mixture mod-els out-perform standard classification algorithmsis when the data comes from highly overlappingdistributions.
In such cases the classification algo-rithms that try to place the decision boundary in asparse area are prone to higher error-rates thanmixture model based approach.
We believe thatthis is explanations of the observed results.
On thetest set a relative improvement of 7% in F1 and14% in kappa statistic is obtained using the MVNmixture model.The results for the semi-supervised models arenon-conclusive.
Our post-experimental analysisreveals that the parameter updation process usingthe unlabeled data has an effect of overly separat-ing the two overlapping distributions.
This is trig-gered by our threshold based EM methodologywhich includes only those data-points for whichthe model is highly confident; however such data-points are invariable from the non-overlapping re-gions of the distribution, which gives a false viewto the learner that the distributions are less over-lapping.
We believe that the unsupervised modelsalso suffer from the above problem in addition tothe possibility of poor initializations.5 ConclusionsWe have demonstrated in this paper that the prob-lem of homograph identification can be ap-proached using dictionary definitions as the sourceof information about the word.
Further more, usingmultiple dictionaries provides more evidence forthe inferences to be made and also minimizes therisk of missing few meanings of the word.We can conclude that by modeling the underly-ing data generation process as a mixture model, theproblem of homograph identification can be per-formed with reasonable accuracy.The capability of identifying homographs fromnon-homographs enables us to take on the nextsteps of sense-inventory generation and lexicalambiguity resolution.AcknowledgmentsWe thank Shay Cohen and Dr. Matthew Harrison for thehelpful discussions.
This work was supported in part bythe Pittsburgh Science of Learning Center which isfunded by the National Science Foundation, awardnumber SBE-0354420.ReferencesA.
Dempster, N. Laird, and D. Rubin.
1977.
Maximumlikelihood from incomplete data via the EM algo-rithm.
Journal of the Royal Statistical Society, SeriesB, 39(1):1?38.A.
Coxhead.
2000.
A New Academic Word List.TESOL, Quarterly, 34(2): 213-238.J.
Jorgenson.
1990.
The psychological reality of wordsenses.
Journal of Psycholinguistic Research 19:167-190.L.
Twilley, P. Dixon, D. Taylor, and K. Clark.
1994.University of Alberta norms of relative meaning fre-quency for 566 homographs.
Memory and Cognition.22(1): 111-126.M.
Sanderson.
2000.
Retrieving with good sense.
In-formation Retrieval, 2(1): 49-69.M.
Palmer, H. Dang, C. Fellbaum, 2005.
Making fine-grained and coarse-grained sense distinctions.
Jour-nal of Natural Language Engineering.
13: 137-163.N.
Ide and Y. Wilks.
2006.
Word Sense Disambigua-tion, Algorithms and Applications.
Springer,Dordrecht, The Netherlands.T.
Azuma.
1996.
Familiarity and Relatedness of WordMeanings: Ratings for 110 Homographs.
BehaviorResearch Methods, Instruments and Computers.28(1): 109-124.Y.
Chan, H. Ng, and D. Chiang.
2007.
Proceeding ofAssociation for Computational Linguistics, Prague,Czech Republic.Tuning Set Test SetPreci-sion Recall F1 KappaPreci-sion Recall F1 KappaModel I ?
Dirichlet 0.84 0.74 0.78 0.47 0.81 0.62 0.70 0.34Model II ?
Dirichlet 0.85 0.71 0.77 0.45 0.81 0.60 0.68 0.33Model III ?
Dirichlet 0.78 0.74 0.76 0.37 0.82 0.56 0.67 0.32Model I ?
MVN 0.70 0.75 0.78 0.32 0.80 0.73 0.76 0.41Model II ?
MVN 0.74 0.82 0.78 0.34 0.71 0.79 0.74 0.25Model III ?
MVN 0.69 0.89 0.77 0.22 0.64 0.84 0.72 0.22Baseline ?
NB 0.82 0.73 0.77 0.43 0.82 0.63 0.71 0.3688
