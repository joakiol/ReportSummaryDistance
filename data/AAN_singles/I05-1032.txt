R. Dale et al (Eds.
): IJCNLP 2005, LNAI 3651, pp.
357 ?
365, 2005.?
Springer-Verlag Berlin Heidelberg 2005Finding Taxonomical Relation from an MRD forThesaurus ExtensionSeonHwa Choi and HyukRo ParkDept.
of Computer Science,Chonnam National University,300 Youngbong-Dong, Puk-Ku Gwangju, 500-757, Koreacsh123@dreamwiz.com, hyukro@chonnam.ac.krAbstract.
Building a thesaurus is very costly and time-consuming task.
Toalleviate this problem, this paper proposes a new method for extending athesaurus by adding taxonomic information automatically extracted from anMRD.
The proposed method adopts a machine learning algorithm in acquiringrules for identifying a taxonomic relationship to minimize human-intervention.The accuracy of our method in identifying hypernyms of a noun is 89.7%, andit shows that the proposed method can be successfully applied to the problem ofextending a thesaurus.1   IntroductionAs the natural language processing (NLP) systems became large and applied to widevariety of application domains, the need for a broad-coverage lexical knowledge-basehas increased more than ever before.
A thesaurus, as one of these lexical knowledge-bases, mainly represents a taxonomic relationship between nouns.
However, becausebuilding broad-coverage thesauri is a very costly and time-consuming job, they arenot readily available and often too general to be applied to a specific domain.The work presented here is an attempt to alleviate this problem by devising a newmethod for extending a thesaurus automatically using taxonomic informationextracted from a machine readable dictionary (MRD).Most of the previous approaches for extracting hypernyms of a noun from thedefinition in an MRD rely on the lexico-syntactic patterns compiled by human experts.Not only these methods require high cost for compiling lexico-syntactic patterns butalso it is very difficult for human experts to compile a set of lexical-syntactic patternswith a broad-coverage because, in natural languages, there are various differentexpressions which represent the same concept.
Accordingly the applicable scope of a setof lexico-syntactic patterns compiled by human is very limited.To overcome the drawbacks of human-compiled lexico-syntactic patterns, we usepart-of-speech (POS) patterns only and try to induce these patterns automaticallyusing a small bootstrapping thesaurus and machine learning methods.The rest of the paper is organized as follows.
We introduce the related works insection 2.
Section 3 deals with the problem of features selection.
In section 4, ourproblem is formally defined as a machine learning method and discussimplementation details.
Section 5 is devoted to experimenal result.
Finally, we cometo the conclusion of this paper in section 6.358 S.H.
Choi and H.R.
Park2   Related work[3] introduced a method for the automatic acquisition of the hyponymy lexicalrelation from unrestricted text, and gave several examples of lexico-syntactic patternsfor hyponymy that can be used to detect these relationships including those used here,along with an algorithm for identifying new patterns.
Hearst?s approach iscomplementary to statistically based approaches that find semantic relations betweenterms, in that hers requires a single specially expressed instance of a relation while theothers require a statistically significant number of generally expressed relations.
Thehyponym-hypernym pairs found by Hearst?s algorithm include some that shedescribes as ?context and point-of-view dependent?, such as ?Washington/nationalist?and ?aircraft/target?.
[4] was somewhat less sensitive to this kind of problem sinceonly the most common hypernym of an entire cluster of nouns is reported, so much ofthe noise is filtered.
[3] tried to discover new patterns for hyponymy by hand,nevertheless it is a costly and time-consuming job.
In the case of [3] and [4], since thehierarchy was learned from text, it got to be domain-specific different from a general-purpose resource such as WordNet.
[2] proposed a method that combines a set of unsupervised algorithms in order toaccurately build large taxonomies from any MRD, and a system that 1)performs fullyautomatic extraction of a taxonomic link from MRD entries and 2) ranks the extractedrelations in a way that selective manual refinement is allowed.
In this project, theyintroduced the idea of the hyponym-hypernym relationship appears between the entryword and the genus term.
Thus, usually a dictionary definition is written to employ agenus term combined with differentia which distinguishes the word being definedfrom other words with the same genus term.
They found the genus term by simpleheuristic defined using several examples of lexico-syntactic patterns for hyponymy.
[1] presented the method to extract semantic information from standard dictionarydefinitions.
Their automated mechanism for finding the genus terms is based on theobservation that the genus term from verb and noun definitions is typically the headof the defining phrase.
The syntax of the verb phrase used in verb definitions makes itpossible to locate its head with a simple heuristic: the head is the single verbfollowing the word to.
He asserted that heads are bounded on the left and right byspecific lexical defined by human intuition, and the substring after eliminatingboundary words from definitions is regarded as a head.By the similar idea to [2], [10] introduced six kinds of rule extracting a hypernymfrom Korean MRD according to a structure of a dictionary definition.
In this work,Moon proposed that only a subset of the possible instances of the hypernym relationwill appear in a particular form, and she divides a definition sentence into a head termcombined with differentia and a functional term.
For extracting a hypernym, Moonanalyzed a definition of a noun by word list and the position of words, and thensearched a pattern coinciding with the lexico-syntactic patterns made by humanintuition in the definition of any noun, and then extracted a hypernym using anappropriate rule among 6 rules.
For example, rule 2 states that if a word X occurs infront of a lexical pattern ?leul bu-leu-deon i-leum ( the name to call )?,then X isextracted as a hypernym of the entry word.Several approaches[11][12][13] have been researched for building a semantichierarchy of Korean nouns adopting the method of [2].Finding Taxonomical Relation from an MRD for Thesaurus Extension 3593   Features for Hypernym IdentificationMachine learning approaches require an example to be represented as a feature vector.How an example is represented or what features are used to represent the example hasprofound impact on the performance of the machine learning algorithms.
This sectiondeals with the problems of feature selection with respect to characteristics of Koreanfor successful identification of hypernyms.Location of a word.
In Korean, a head word usually appears after its modifyingwords.
Therefore a head word has tendency to be located at the end of a sentence.
Inthe definition sentences in a Korean MRD, this tendency becomes much stronger.
Inthe training examples, we found that 11% of the hypernyms appeared at the start, 81%of them appeared at the end and 7% appeared at the middle of a definition sentence.Thus, the location of a noun in a definition sentences is an important feature fordetermining whether the word is a hypernym or not.POS of a function word attached to a noun.
Korean is an agglutinative language inwhich a word-phrase is generally a composition of a content word and somenumber of function words.
A function word denotes the grammatical relationshipbetween word-phrases, while a content word contains the central meaning of theword-phrase.In the definition sentences, the function words which attached to hypernyms areconfined to a small number of POSs.
For example, nominalization endings, objectivecase postpositions come frequently after hypernyms but dative postpositions orlocative postpositions never appear after hypernyms.
A functional word is appropriatefeature for identifying hypernyms.Context of a noun.
The context in which a word appears is valuable information anda wide variety of applications such as word clustering or word sense disambiguationmake use of it.
Like in many other applications, context of a noun is important indeciding hyperhyms too because hypernyms mainly appear in some limited context.Although lexico-syntactic patterns can represent more specific contexts, buildingset of lexco-syntactic patterns requires enormous training data.
So we confinedourselves only to syntactic patterns in which hypernyms appear.We limited the context of a noun to be 4 word-phrases appearing around the noun.Because the relations between word-phrases are represented by the function words ofthese word-phrases, the context of a noun includes only POSs of the function wordsof the neighboring word-phrases.
When a word-phrase has more than a functionalmorpheme, a representative functional morpheme is selected by an algorithmproposed by [8].When a noun appears at the start or at the end of a sentence, it does not have rightor left context respectively.
In this case, two treatments are possible.
The simplestapproach is to treat the missing context as don?t care terms.
On the other hand, wecould extend the range of available context to compensate the missing context.
Forexample, the context of a noun at the start of a sentence includes 4 POSs of functionwords in its right-side neighboring word-phrases.360 S.H.
Choi and H.R.
Park4   Learning Classification RulesDecision tree learning is one of the most widely used and a practical methods forinductive inference such as ID3, ASSISTANT, and C4.5[14].
Because decision treelearning is a method for approximating discrete-valued functions that is robust tonoisy data, it has therefore been applied to various classification problemssuccessfully.Our problem is to determine for each noun in definition sentences of a wordwhether it is a hypernym of the word or not.
Thus our problem can be modeled astwo-category classification problem.
This observation leads us to use a decision treelearning algorithm C4.5.Our learning problem can be formally defined as followings:?
Task T : determining  whether a noun is a hypernym of an entry word  or not .?
Performance measure P : percentage of nouns correctly classified.?
Training examples E : a set of nouns appearing in the definition sentences ofthe MRD with their feature vectors and target values.To collect training examples, we used a Korean MRD provided by KoreanTermBank Project[15] and a Korean thesaurus compiled by ElectronicCommunication Research Institute.
The dictionary contains approximately 220,000nouns with their definition sentences while the thesaurus has approximately 120,000nouns and taxonomy relations between them.
The fact that 46% of nouns in thedictionary are missing from the thesaurus shows that it is necessary to extend athesaurus using an MRD.Using the thesaurus and the MRD, we found that 107,000 nouns in the thesaurushave their hypernyms in the definition sentences in the MRD.
We used 70% of thesenouns as training data and the remaining 30% of them as evaluation data.For each training pair of hypernym/hyponym nouns, we build a triple in the formof (hyponym definition-sentences hypernym) as follows.ga-gyeong [ a-leum-da-un gyeong-chi (a beautiful scene)] gyeong-chihyponym                        definition sentence                                        hypernymMorphological analysis and Part-Of-Speech tagging are applied to the definitionsentences.
After that, each noun appearing in the definition sentences is convertedinto a feature vector using features mentioned in section 3 along with a target value(i.e.
whether this noun is a hypernym of the entry word or not).Table 1 shows some of the training examples.
In this table, the attributeIsHypernym which can have a value either Y or N is a target value for given noun.Hence the purpose of learning is to build a classifier which will predict this value fora noun unseen from the training examples.In Table 1, Location denotes the location of a noun in a definition sentence.
0indicates that the noun appears at the start of the sentence, 1 denotes at the middle ofthe sentence, and 2 denotes at the end of a sentence respectively.
FW of a hypernym isthe POS of a function word attachted to the noun and context1,...,context4 denote thePOSs of  function words appearing to the right/left of the noun.
?*?
denotes a don?tcare condition.
The meanings of POS tags are list in Appendix A.Finding Taxonomical Relation from an MRD for Thesaurus Extension 361Table 1.
Some of training examplesNoun Location FW of ahypernymcontext1 context2 context3 context4 IsHypernymN1 1 jc ecx exm nq * YN2 2 * exm ecx jc nq YN3 2 * exm jc nca exm YN4 1 exm jc jc ecx m NN5 1 jc jc ecx m jca NN6 1 jc ecx m jca exm YN7 2 * exm exm jca exm YN8 1 * nc jca exm jc NN9 1 jca nc nc nc jc YN10 2 exn a nca jc nca Y.. .. .. .. .. .. ..
..Fig.
1 shows a part of decision tree learned by C4.5 algorithm.
From this tree, wecan easily find that the most discriminating attribute is Location while the least oneis Context.Fig.
1.
A learned decision tree for task T5   ExperimentTo evaluate the proposed method, we measure classification accuracy as well asprecision, recall, and F-measure which are defined as followings respectively.recallprecisionrecallprecisionMeasureFcaarecallbaaprecisiondcbadaaccuracytionclassifica+=?+=+=++++=**2362 S.H.
Choi and H.R.
ParkTable 2.
Contingency table for evaluating a binary classifierYes is correct No is correctYes was assigned a bNo was assigned c dTable 3.
Evaluation resultClassificationaccuracy Precesion Recall F-MeasureA 91.91% 95.62% 92.55% 94.06%B 92.37% 93.67% 95.23% 94.44%C 89.75% 83.83% 89.92% 86.20%Table 4.
Evaluation resultProposed Y.J.Moon 96[10]A BM.S.Kim95[11] C DY.M.Choi98[13]ClassificationAccuracy 91.91% 92.37% 88.40% 88.40% 68.81% 89.40%Table 3 shows the performance of the proposed approach.
We have conducted twosuite of experiments.
The purpose of the first suite of experiment is to measure theperformance differences according to the different definitions for the context of aword.
In the experiment denoted A in table 3, the context of a word is defined as 4POSs of the function words, 2 of them immediately proceeding and 2 of themimmediately following the word.
In the experiment denoted B, when the word appearsat the beginning of a sentence or at the end of a sentence, we used only right or leftcontext of the word respectively.
Our experiement shows that the performance of B isslightly better than that of A.In the second suite of experiment, we measure the performance of our system fornouns which do not appear in the thesaurus.
This performance can give us a figure abouthow well our system can be applied to the problem of extending a thesaurus.
The resultis shown in Table 3 in the row labeled with C.  As we expected, the performance isdroped slightly, but the difference is very small.
This fact convince us that the proposedmethod can be successfully applied to the problem of extending a thesuarus.Table 4 compares the classification accuracy of the proposed method with those ofthe previous works.
Our method outperforms the performance of the previous worksreported in the literature[10] by 3.51%.Because the performance of the previous works are measured with small data in arestricted domain, we reimplemented one of the those previous works[10] to comparethe performances using same data.
The result is shown in Table 4 under the columnmarked D. Column C is the performance of the [10] reported in the literature.
ThisFinding Taxonomical Relation from an MRD for Thesaurus Extension 363result shows that as the heuristic rules in [10] are dependent on lexical information, ifthe document collection is changed or the application domain is changed, theperformance of the method degrades seriously.6   ConclusionTo extend a thesaurus, it is necessary to identify hypernyms of a noun.
There havebeen several works to build taxonomy of nouns from an MRD.
However, most ofthem relied on the lexico-syntactic patterns compiled by human experts.This paper has proposed a new method for extending a thesaurus by adding ataxonomic relationship extracted from an MRD.
The taxonomic relationship isidentified using nouns appearing in the definition sentences of a noun in the MRD andsyntactic pattern rules compiled by a machine learning algorithm.Our experiment shows that the classification accuracy of the proposed method is89.7% for nouns not appearing in the thesaurus.Throughout our research, we have found that machine learning approaches to theproblems of identifying hypernyms from an MRD could be a competitive alternative tothe methods using human-compiled lexico-syntactic patterns, and such taxonomyautomatically extracted from an MRD can effectively supplement an existing thesaurus.References1.
Martin S. Chodorow, Roy J. Byrd, George E. Heidorn.
: Extracting Semantic HierarchiesFrom A Large On-Line Dictionary.
In Proceedings of the 23rd Conference of theAssociation for Computational Linguistics (1985)2.
Rigau G., Rodriguez H., Agirre E. : Building Accurate Semantic Taxonomies fromMololingual MRDs.
In Proceedings of the 36th Conference of the Association forComputational Linguistics (1998)3.
Marti A. Hearst.
: Automatic acquisition of hyonyms from large text corpora.
InProceedings of the Fourteenth International Conference on Computational Linguistics(1992)4.
Sharon A. Caraballo.
: Automatic construction of a hypernym-labled noun hierarchy fromtext.
In Proceedings of the 37th Conference of the Association for ComputationalLinguistics (1999).5.
Fernando Pereira, Naftali Thishby, Lillian Lee.
: Distributional clustering of Englishwords.
In Proceedings of the 31th Conference of the Association for ComputationalLinguistics (1993)6.
Brian Roark, Eugen Charniak.
: Noun-phrase co-occurrence statistics for semi-automaticsemantic lexicon construction.
In Proceedings of the 36th Conference of the Associationfor Computational Linguistics and 17th International Conference on ComputationalLinguistics (1998)7.
Tom M.
Mitchell.
: Machine Learning.
Carnegie Mellon University.
McGraw-Hill (1997).8.
SeonHwa Choi, HyukRo Park.
: A New Method for Inducing Korean DependencyGrammars reflecting the Characteristics of Korean Dependency Relations.
In Proceedingsof the 3rd Conterence on East-Asian Language Processing and Internet InformationTechnology (2003)9.
YooJin Moon, YeongTak Kim.
:The Automatic Extraction of Hypernym in Korean.
InPreceedings of Korea Information Science Society Vol.
21, NO.
2 (1994) 613-616364 S.H.
Choi and H.R.
Park10.
YooJin Moon.
: The Design and Implementation of WordNet for Korean Nouns.
InProceedings of Korea Information Science Society (1996)11.
MinSoo Kim, TaeYeon Kim, BongNam Noh.
: The Automatic Extraction of Hypernymsand the Development of WordNet Prototype for Korean Nouns using Koran MRD.
InProceedings of Korea Information Processing Society (1995)12.
PyongOk Jo, MiJeong An, CheolYung Ock, SooDong Lee.
: A Semantic Hierarchy ofKorean Nouns using the Definitions of Words in a Dictionary.
In Proceedings of KoreaCognition Society (1999)13.
YuMi Choi and SaKong Chul.
: Development of the Algorithm for the AutomaticExtraction of Broad Term.
In Proceedings of Korea Information Management Society(1998) 227-23014.
Quinlan J. R.: C4.5: Programs for Machine Learning.
San Mateo, CA: Morgan Kaufman(1993)  http://www.rulequest.com/Personal/15.
KORTERM.
: KAIST language resources http://www.korterm.or.kr/Appendix A. POS Tag SetTable 5.
POS tag setCATEGORY  TAG DESCRIPTIONnoun common nn common nounnca active common nounncs statove common nounnct time common nounproper nq proper nounbound nb bound nounnbu unit bound nounnumeral nn numeralpronoun npp personal pronounnpd demonstrative pronounpredicate verb pv verbadjective pa adjectivepad demonstrative adjectiveauxiliary px auxiliary verbmodification adnoun m adnounmd demonstrative adnounmn numeral adnounadverb a general adverbajs sentence conjunctive adverbajw word conjunctive adverbad demonstrative adverbindependence interjection ii interjectionparticle case jc casejca adverbial case particlejcm adnominal case particlejj conjunctive case particlejcv vocative case particleFinding Taxonomical Relation from an MRD for Thesaurus Extension 365CATEGORY  TAG DESCRIPTIONauxiliary jx auxiliarypredicative jcp predicative particleending prefinal efp prefinal endingconjunctive ecq coordinate conjunctive endingecs subordinate conjunctive endingecx auxiliary conjunctive endingtransform exn nominalizing endingexm adnominalizing endingexa adverbalizing endingfinal ef final endingaffix prefix xf prefixsuffix xn suffixxpv verb-derivational suffixxpa adjective-derivational suffix
