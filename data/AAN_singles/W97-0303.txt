An Efficient D is t r ibut ion  of Labor in a Two Stage RobustInterpretat ion ProcessCarolyn Penstein Ros6Carnegie Mellon UniversityBaker Hall 135FPittsburgh, PA 15213cprose@cs.cmu.eduAlon LavieCarnegie Mellon UniversityCenter for Machine TranslationPittsburgh, PA 15213alavie~cs.cmu.eduAbstractAlthough Minimum Distance Parsing(MDP) offers a theoretically attractive so-lution to the problem of extragrammat-icality, it is often computationally infea-sible in large scale practical applications.In this paper we present an alternative ap-proach where the labor is distributed be-tween a more restrictive partial parser anda repair module.
Though two stage ap-proaches have grown in popularity in re-cent years because of their efficiency, theyhave done so at the cost of requiring handcoded repair heuristics (Ehrlich and Han-rieder, 1996; Danieli and Gerbino, 1995).In contrast, our two stage approach doesnot require any hand coded knowledgesources dedicated to repair, thus makingit possible to achieve a similar run timeadvantage over MDP without losing thequality of domain independence.1 IntroductionThe correct interpretation of spontaneous pokenlanguage poses challenges that continue to fall out-side of the reach of state-of-the-art technology.
Thefirst essential task of a natural anguage interface isto map the user's utterance onto some meaning rep-resentation which can then be used for further pro-cessing.
The three biggest challenges that continueto stand in the way of accomplishing even this mostbasic task are extragrammaticality, ambiguity, andspeech recognition errors.
In this paper we addressthe issue of how to handle the problem of extra-grammaticality efficiently, where extragrammatical-ity is defined as any deviation of an input string fromthe coverage of a given system's parsing grammar.We demonstrate the superiority of our approach bycomparing performance between it and a set of alter-native approaches in terms of parse time and parsequality over the same previously unseen test corpus.The approach presented in this paper is the com-26pletely automatic portion of the ROSE 1 approach.ROSE, RObustness with Structural Evolution, re-pairs extragrammatical input in two phases.
Thefirst phase, Repair Hypothesis Formation, is re-sponsible for assembling a set of hypotheses aboutthe meaning of the ungrammatical utterance.
Thisphase is itself divided into two stages, Partial Pars-ing and Combination.
A restricted version of Lavie'sGLR* parser (Lavie, 1995; Lavie and Tomita, 1993)is used to obtain an analysis of islands of thespeaker's entence in cases where it is not possibleto obtain an analysis for the entire sentence.
In theCombination stage, the fragments from the partialparse are assembled into a set of alternative meaningrepresentation hypotheses.
A genetic programmingapproach is used to search for different ways to com-bine the fragments in order to avoid requiring anyhand-crafted repair rules.
In ROSE's second phase,Interaction with the User, the system generates aset of queries, negotiating with the speaker in orderto narrow down to a single best meaning representa-tion hypothesis.
In this paper, only the HypothesisFormation phase is described and evaluated.
Sincerepairs beyond those made possible by the partialparser are performed uring the Combination stage,we refer to the implementation of the Combinationstage as the repair module.
Though a set of hypothe-ses are produced by during the Combination stage,in the evaluation presented in this paper, only the re-pair hypothesis cored by the repair module as bestis returned.The ROSE approach was developed in the con-text of the JANUS large-scale multi-lingual machinetranslation system (Lavie et al, 1996; Woszcyna etal., 1993; Woszcyna et al, 1994).
Currently, theJANUS system deals with the scheduling domainwhere two speakers attempt o schedule a meetingtogether over the phone.
The system is composedof four language independent and domain indepen-dent modules including speech-recognition, parsing,discourse processing, and generation.
The repairmodule described in this paper is similarly languageROSE is pronounced ros~, like the wine.independent and domain independent, requiring nohand-coded knowledge dedicated to repair.
Theevaluations described in this paper were conductedusing a grammar with approximately 1000 rules anda lexicon with approximately 1000 lexical items.2 A l te rnat ive  Avenues  TowardsRobustnessThere are a wide range of different approaches tohandling the problem of extragrammaticality, butwhich way is best?
Three basic avenues existwhereby the coverage of a natural anguage under-standing system can be expanded: further develop-ment of the parsing grammar, addition of flexibil-ity to the parsing algorithm, or addition of a post-processing repair stage after the parsing stage.It is always possible to add additional rules to aparsing grammar in order to expand the coverage,but this approach is both time intensive in terms ofdevelopment and ultimately computationally expen-sive at run time since large, cumbersome grammarsgenerate xcessive amounts of ambiguity.
Addingflexibility to the parsing algorithm is preferable insome respects, particularly in that it reduces thegrammar development burden.
However, it lends it-self to the same weakness in terms of computationalexpense.
In the extreme case, in a Minimum Dis-tance Parser (MDP) (Lehman, 1989; Hipp, 1992),any ungrammatical sentence can be mapped ontoa sentence inside of the coverage of the grammarthrough a series of insertions, deletions, and in somecases substitutions or transpositions.The more flexibility, the better the coverage intheory, but in realistic large scale systems this ap-proach becomes computationally intractable.
Cur-rent efforts towards robust interpretation have fo-cused on less powerful partial parsers (Abney, 1996;Nord, 1996; Srinivas et al, 1996; Federici, Mon-temagni, and Pirrelli, 1996) and repair approacheswhere the labor is distributed between two or morestages (Ehrlich and Hanrieder, 1996; Danieli andGerbino, 1995).
The purpose of the second stageis to assemble the pieces of the partial parse pro-duced in the first stage.
In this paper we presenta two stage approach composed of a partial parserfollowed by a completely automatic repair module.Though two stage approaches have grown inpopularity in recent years because of their effi-ciency, they have done so at the cost of requiringhand coded repair heuristics (Ehrlich and Hanrieder,1996; Danieli and Gerbino, 1995).
In contrast, theROSE approach does not require any hand codedknowledge sources dedicated to repair, thus makingit possible to achieve the benefits of repair withoutlosing the quality of domain independence.In this paper, we compare the performance of thetwo stage ROSE approach with MDP.
A parameter-ized version of Lavie's GLR* parser (Lavie, 1995)is used which has been extended to perform a lim-ited version of MDP in which insertions and dele-tions are possible, but not transpositions or substi-tutions.
We refer to this parameterized MDP parseras LR MDP.
We run LR MDP over the same testcorpus in different settings, demonstrating the flex-ibil ity/quality/parse time trade off.
With this wedemonstrate that the two stage ROSE approach,coupling the restricted version of the GLR* parserwith a post-processing repair stage, achieves bettertranslation quality far more efficiently than any flex-ibility setting of LR MDP over the same corpus.3 MDP versus  Two StageI n terpretat ionEfforts towards solving the problem of extragram-maticality have primarily been in the direction ofbuilding flexible parsers.
In principle, Minimum Dis-tance Parsers (Lehman, 1989; Hipp, 1992) have thegreatest flexibility.
They fit an extragrammaticalsentence to the parsing grammar through a series ofinsertions, deletions, and transpositions.
Since anystring can be mapped onto any other string througha series of insertions, deletions, and transpositions,this approach makes it possible to repair any sen-tence.
The underlying assumption behind the MDPapproach is that the analysis of the string that de-viates the least from the input string is most likelyto be the best analysis.
Thus, Minimum DistanceParsing appears to be a reasonable approach.In practice, however, Minimum Distance Parsinghas only been used successfully in very small andlimited domains.
Lehman's core grammar, describedin (Lehman, 1989), has on the order of 300 rules,and all of the inputs to her system can be assumedto be commands to a calendar program.
Hipp's Cir-cuit Fix-It Shop system, described in (Hipp, 1992),has a vocabulary of only 125 words and a grammarsize of only 500 rules.
Flexible parsing algorithmsintroduce a great deal of extra ambiguity.
This inturn may deem certain approaches impractical forsystems of realistic scale.
Therefore, an importantquestion one must ask is whether the MDP approachcan scale up to a larger system and/or domain.An example of a more restrictive parsing algo-rithm is Lavie's GLR* skipping parser described in(Lavie, 1995).
GLR* is a parsing system based onTomita's Generalized LR parsing algorithm whichwas designed to be robust to two particular types ofextra-grammaticality: noise in the input, and lim-ited grammar coverage.
GLR* attempts to overcomethese forms of extra-grammaticality by ignoring theunparsable words and fragments and conducting asearch for the maximal subset of the original inputthat is covered by the grammar.The GLR* parser is capable of skipping over anyportion of an input utterance that cannot be incor-porated into a grammatical nalysis and recover the27analysis of the largest grammatical subset of the ut-terance.
Partial analyses for skipped portions of theutterance can also be returned by the parser.
Thus,whereas MDP considers insertions and transposi-tions in addition to deletions, GLR* only considersdeletions.
GLR* can be viewed as a restricted formof MDP applied to an efficient non-robust generalparsing method.
GLR* can, in most cases, achievemost of the robustness of the more general MDPapproach while maintaining feasibility, due to effi-ciency properties of the GLR approach and an effec-tive well:guided search.
In the evaluation presentedin this paper, GLR* has been restricted to skip onlyinitial segments so that the partial analyses returnedare always for contiguous portions of the sentence.Because GLR* was designed as an enhancementto the widely used standard GLR context-free pars-ing algorithm, grammars, lexicons and other toolsdeveloped for the standard GLR parser can be usedwithout modification.
GLR* uses the standardSLR(0) parsing tables which are compiled in advancefrom the grammar.
It inherits the benefits of GLRin terms of ease of grammar development, and, toa large extent, efficiency properties of the parser it-self.
In the case that an input sentence is completelygrammatical, GLR* will normally return the exactsame parse as the GLR parser.The weakness of this and other partial parsing ap-proaches (Abney, 1996; Nord, 1996; Srinivas et al,1996; Federici, Montemagni, and Pirrelli, 1996) isthat part of the original meaning of the utterancemay be thrown away with the portion(s) of the ut-terance that are skipped if only the analysis for thelargest subset is returned, or part of the analysiswill be missing if the parser only attempts to builda partial parse.
These less powerful algorithms tradecoverage for speed.
The idea is to introduce noughflexibility to gain an acceptable level of coverage atan acceptable computational expense.The goal behind the two stage approach (Ehrlichand Hanrieder, 1996; Danieli and Gerbino, 1995)is to increase the coverage possible at a reasonablecomputational cost by introducing a post-processingrepair stage, which constructs a complete mean-ing representation ut of the fragments of a partialparse.
Since the input to the second stage is a collec-tion of partial parses, the additional flexibility thatis introduced at this second stage can be channeledjust to the part of the analysis that the parser doesnot have enough knowledge to handle straightfor-wardly.
This is unlike the MDP approach, where thefull amount of flexibility is unnecessarily applied toevery part of the analysis, even in completely gram-matical sentences.
Therefore, this two stage processis a more efficient distribution of labor since the firststage is highly constrained by the grammar and theresults of this first stage are then used to constrainthe search in the second stage.
Additionally, in caseswhere the limited flexibility parser is sufficient, thesecond stage can be entirely bypassed, yielding aneven greater savings in time.4 The  Two Stage  In terpretat ionProcessThe main goal of the two stage ROSE approach is toachieve the ability to robustly interpret spontaneousnatural language fficiently in a system at least aslarge and complex as the JANUS multi-lingual ma-chine translation system, which provides the contextfor this work.
In this section we describe the divi-sion of labor between the Partial Parsing stage andthe Combination stage in the ROSE approach.4.1 The  Par t ia l  Parsing StageSentence: That wipes out my mornings.Partial Analyses:Chunkl :  that((ROOT THAT)(TYPE PRONOUN)(FRAME *THAT))Chunk2: out((TYPE NEGATIVE)(DEGREE NORMAL)(FRAME *RESPOND))Chunk3: my((ROOT I)(TYPE PERSON-POSS)(FRAME *I))Chunk4: mornings((TIME-OF-DAY MORNING)(NUMBER PLURAL)(FRAME *SIMPLE-TIME)(SIMPLE-UNIT-NAME TOD))Figure 1: Parse ExampleThe first stage in our approach is the Partial Pars-ing stage where the goal is to obtain an analysis forislands of the speaker's utterance if it is not possibleto obtain an analysis for the whole utterance.
Thisis accomplished with a restricted version of Lavie'sGLR* parser (Lavie, 1995; Lavie and Tomita, 1993)that produces an analysis for contiguous portions ofthe input sentence.
See Figure 1 for an exampleparse.
Here the GLR* parser attempts to handlethe sentence "That wipes out my mornings."
Theexpression "wipes out" does not match anything inthe parsing grammar.
The grammar also does not28allow time expressions to be modified by possessivepronouns.
So "my mornings" also does not parse.Although the grammar ecognizes "out" as a way ofexpressing a rejection, as in "Tuesdays are out," itdoes not allow the time being rejected to follow the"out".
However, although the parser was not ableto obtain a complete parse for this sentence, it wasable to extract four chunks.The chunks are feature structures in which theparser encodes the meaning of portions of the user'ssentence.
This frame based meaning representationis called an interlingua because it is language inde-pendent.
It is defined by an interlingua specification,which serves as the primary symbolic knowledgesource used during the Combination stage.
Eachframe encodes a concept in the domain.
The set offrames in the meaning representation are arrangedinto subsets that are assigned a particular type.Each frame is associated with a set of slots.
Theslots represent relationships between feature struc-tures.
Each slot is associated with a type whichdetermines the set of possible frames which can befillers of that slot.
Though this meaning representa-tion specification is knowledge that must be encodedby hand, it is knowledge that can be used by all as-pects of the system, not only the repair module asis the case with repair rules.
Arguably, any welldesigned system would have such a specification todescribe its meaning representation.The four chunks extracted by the parser each en-code a different part of the meaning of the sentence"That wipes out my mornings."
The first chunk rep-resents the meaning of "that".
The second one rep-resents the meaning of "out".
Since "out" is gener-ally a way of rejecting a meeting time in this domain,the associated feature structure represents the con-cept of a response that is a rejection.
Since "wipes"does not match anything in the grammar, this tokenis left without any representation among the frag-ments returned by the parser.
The last two chunksrepresent the meaning of "my" and "mornings" re-spectively.The disadvantage of this skipping parser over theMDP approach is that it does not have the abil-ity to perform some necessary repairs that the morecomplicated approach can make.
In this case, forexample, it is unable to determine how these piecesfit together into one coherent parse.
The goal of theCombination stage is to overcome this limitation ef-ficiently.
Thus, the second stage of the interpreta-tion process is responsible for making the remainingtypes of repairs.
More flexibility can be introducedin the second stage efficiently since the search spacehas already been reduced with the addition of theknowledge obtained from the partial parse.4.2 The  Combinat ion  StageThe purpose of the Combination stage is to makethe remainder of the types of repairs that could inprinciple be done with a minimum distance parserusing insertions, deletions, and transpositions, butthat cannot be performed with the skipping parser.The Combination stage takes as input the partialanalyses returned by the skipping parser.
Thesechunks are combined into a set of best repair hy-potheses.
The hypotheses built during this combina-tion process pecify how to build meaning represen-tations out of the partial analyses produced by theparser that are meant to represent the meaning ofthe speaker's whole sentence, rather than just parts.Since the meaning representation is compositional,a single, more complete meaning representation canbe built by assembling the meaning representationsfor the parts of the sentence.Ideal Repair Hypothesis:(MY-COMB((FRAME *RESPOND)(DEGREE NORMAL)(TYPE NEGATIVE)) ; argl((TIME-OF-DAY MORNING)(NUMBER PLURAL)(FRAME *SIMPLE-TIME)(SIMPLE-UNIT-NAME TOD)) ; arg2WHEN) ; slot;insert arg2 into argl in slotIdeal Structure:((FRAME *RESPOND)(DEGREE NORMAL)(TYPE NEGATIVE)(WHEN ((FRAME *SIMPLE-TIME)(TIME-OF-DAY MORNING)(NUMBER PLURAL)(SIMPLE-UNIT-NAME TOD))))Gloss: Mornings are out.Figure 2: Combination ExampleIn this Combination stage, a genetic programming(Koza, 1992; Koza, 1994) approach is used to evolvea population of programs that specify how to buildcomplete meaning representations from the chunksreturned from the parser.
The repair module mustdetermine not only which subset of chunks returnedby the parser to include in the final result, but alsohow to put them together.
For example, the idealrepair hypothesis for the example in Figure 2 is onethat specifies that the temporal expression should beinserted into the NI-IEN slot in the *RESPOND frame.The repair process is analogous in some ways to fit-ting pieces of a puzzle into a mold that containsreceptacles for particular shapes.
In this analogy,the meaning representation specification acts as themold with receptacles of different shapes, making itpossible to compute all of the ways partial analyses29can fit together in order to create a structure that islegal in this frame based meaning representation.Both the skipping parsing algorithm and the ge-netic programming combination algorithm are com-pletely domain independent.
Therefore, the ROSEapproach maintains the positive quality of domainindependence that the minimum distance parsingapproach as while avoiding some of the computa-tional expense.5 The Genetic ProgrammingCombinat ion Process In-DepthRecovery from parser failure is a natural applica-tion for genetic programming (Koza, 1992; Koza,1994).
One can easily conceptualize the process ofconstructing a meaning representation hypothesis asthe execution of a computer program that assemblesthe set of chunks returned from the parser.
Thisprogram would specify the operations required forbuilding larger chunks out of smaller chunks andthen even larger ones from those.
Because the pro-grams generated by the genetic search are hierar-chical, they naturally represent he compositionalnature of the repair process.5.1 Constructing Alternative HypothesesSee Figure 2 for an example repair hypotheses.I4Y-COMB is a simple function that attempts to insertthe second feature structure into some slot in thefirst feature structure.
It selects a slot, if a suitableone can be found, and then instantiates the thirdparameter to this slot.
In this case, the WHEN slotis selected.
So the feature structure correspondingto "mornings" is inserted into the WHEN slot in thefeature structure corresponding to "out".
The re-sult is a feature structure indicating that "Morningsare out."
Though this is not an exact representa-tion of the speaker's meaning, it is the best that canbe done with the available feature structures ~.
No-tice that since the expression "wipes out" is foreignto the parsing grammar, and no similar expression isassociated with the same meaning in it, the MDP ap-proach would also not be able to do better than thissince it can only insert and delete in order to fit thecurrent sentence to the rules in its parsing grammar.Additionally, since the time expression follows "out"rather than preceding it as the grammar expects,only MDP with transpositions in addition to inser-tions and deletions would be able to arrive at the2Note that part of the expression "wipes out" matchesa rule in the grammar that happens to have a similarmeaning since "out" can be used as a rejection as in"Tuesday is out."
If the expression had been "out ofsight", which is positive, both the ROSE approach andMDP would construct he opposite meaning from theintended meaning.
Problems like this can only be dealtwith through interaction with the user to confirm thatrepaired meanings reflect he speaker's true intention.30same result.
Note that the feature structures corre-sponding to "my" and "that" are not included in thishypothesis.
The job of the Combination Mechanismis both to determine which fragments to include aswell as how to combine the selected ones.In the genetic programming approach, a popula-tion of programs are evolved that specify how tobuild complete meaning representations from thechunks returned from the parser.
A complete mean-ing representation is one that is meant to representthe meaning of the speaker's whole utterance, ratherthan just part.
Partial solutions are evolved throughthe genetic search specifying how to build parts ofthe full meaning representation.
Because in the samepopulation there can be programs that specify howto build different parts of the meaning representa-tion, different parts of the full solution are evolvedin parallel, making it possible to evolve a completesolution quickly.Hypothesisl:(MY-COMB(MY-COMB((FRAME *RESPOND))((FRAME *SIMPLE-TIME)(TIME-OF-DAY MORNING)(NUMBER PLURAL)(SIMPLE-UNIT-NAME TOD))WHEN)((FRAME *THAT)(ROOT THAT) (TYPE PRONOUN))WHEN)Result l :  Mornings and that are out.
((FRAME *RESPOND)(DEGREE NORMAL)(TYPE NEGATIVE)(WHEN (*MULTIPLE*((FRAME *SIMPLE-TIME)(TIME-OF-DAY MORNING)(NUMBER PLURAL)(SIMPLE-UNIT-NAME TOD))((FRAME *THAT)(ROOT THAT)(TYPE PRONOUN)))))Figure 3: Alternative Repair Hypothesis 1Since a set of alternative meaning representationhypotheses are constructed uring the Combinationstage, the result is similar to an ambiguous parse.See Figure 3 and Figure 4 for two alternative repairhypotheses produced uring the Combination stagefor the example in Figure 1.
The result of each of thehypotheses i an alternative representation for thesentence.
The first hypothesis, displayed in FigureHypothesis2:(MY-COMB((TIME-OF-DAY MORNING)(NUMBER PLURAL)(FRAME *SIMPLE-TIME)(SIMPLE-UNIT-NAME TOD))((FRAME *RESPOND)(DEGREE NORMAL)(TYPE NEGATIVE))??
)Result2: Mornings.
((FRAME *SIMPLE-TIME)(TIME-OF-DAY MORNING)(NUMBER PLURAL)(SIMPLE-UNIT-NAME TOD))Figure 4: A l te rnat ive  Repa i r  Hypothes is  23, corresponds to the interpretation, "Mornings andthat are out."
The problem with this hypothesis isthat it includes the chunk "that", which in this caseshould be left out.In the second hypothesis, displayed in Figure 4,the repair module attempts to insert the rejectionchunk into the time expression chunk, the oppositeof the ideal order.
No slot could be found in thetime expression chunk in which to insert the rejec-tion expression chunk.
In this case, the slot remainsuninstantiated and the largest chunk, in this casethe time expression chunk, is returned.
This hy-potheses produces a feature structure that is indeeda portion of the correct structure, though not thecomplete structure.5.2 App ly ing  the  Genet ic  P rogrammingParad igm to Repa i rThere are five steps involved in applying the geneticprogramming paradigm to a particular problem: de-termining a set of terminals, determining a set offunctions, determining a fitness measure, determin-ing the parameters and variables to control the run,and determining the method for deciding when tostop the evolution process.
The first two constrainthe range of repairs that the Repair process is capa-ble of making.
The fitness measure determines howalternative repair hypotheses are ranked, and thuswhether it is possible that the search will converge onthe correct hypothesis rather than on a sub-optimalcompeting hypothesis.
The last two factors deter-mine how quickly it will converge and how long it isgiven to converge.The set of terminals for this problem is most nat-urally a chunk from the parser.
Each operation in-volved in the repair process takes chunks as inputand returns an augmented chunk as output.
Thesingle operator, called my-comb, takes two chunks asinput.
It inserts the second chunk into a slot in thefirst chunk.
If it is not possible to insert the sec-ond chunk into the first one, it attempts to mergethem.
If this too is not possible, the largest chunkis returned.The fitness measure is trained from repair exam-ples from a separate corpus and is discussed in moredetail below.
The parameters for the run, such asthe size of the population of programs on each gener-ation, are determined experimentally from the train-ing corpus.5.3 Tra in ing  a F i tness  Funct ionThe purpose of the trained fitness function is to rankthe repair hypotheses that are produced in each gen-eration.
Since survival of the fittest is the key to theevolutionary process, the determination of which hy-potheses are more fit is absolutely crucial.
Since thepurpose of the repair module is to evolve a hypoth-esis that generates the ideal meaning representationstructure, hypotheses that produce meaning repre-sentation structures closer to the ideal representa-tion should be ranked as better than others that pro-duce structures that are more different.
Of course,the repair module does not have access to that idealstructure while it is searching for the best combina-tion of chunks.
So a fitness function is trained thatmust estimate how close the result of a particularrepair hypothesis is to the ideal structure by consid-ering secondary evidence.The first step in training a fitness function is todecide which pieces of information to make availableto the fitness function for it to use in making its de-cision.
The fitness function, once it is trained, com-bines these pieces of information into a single scorethat can be used for ranking the hypotheses.
In thecurrent version of the ranking function, three piecesof information are given: the number of operationsin the repair hypothesis, the number of frames andatomic slot fillers in the resulting meaning represen-tation structure, and the average of the statisticalscores for the set of repairs that were made.
Thestatistical score of a repair corresponds to the mu-tual information between a slot and the type of fillerthat was inserted into it.
This statistical informationis trained on a training corpus of meaning represen-tation structures.Each piece of information provided to the fitnessfunction is represented as a numerical score.
Thenumber of operations in the repair hypothesis is ameasure of how complex the hypothesis is.
The pur-pose of this score is to allow the fitness function toprefer simpler solutions.
The number of frames andatomic slot fillers is a measure of how complete arepair hypothesis is.
It allows the fitness functionto prefer more complete solutions over less completeones.
The statistical scores are a rough measure of31the quality of the decisions that were made in formu-lating the hypothesis, such as the decision of whichslot in one structure to insert another structure into.The fitness function that combines these threepieces of information is trained over a training cor-pus of sentences than need repair coupled with idealmeaning representation structures.
The purpose ofthe training process is to learn a function that canmake wise decisions about the trade offs betweenthese three different factors.
Sometimes these threefactors make conflicting predictions about which hy-potheses are better.
For example, a structure witha large number of frames that was constructed bymaking a lot of statistically unlikely decisions maybe less good than a smaller structure made with de-cisions that were more likely to be correct.
Thefactor that only considers the completeness of thesolution would predict that the hypothesis produc-ing the larger structure is better.
On the other hand,the factor considering only the statistical predictionswould choose the other hypothesis.
Neither factorwill be correct in all circumstances.
Simple repairhypotheses tend to be better in general, but thisgoal can conflict with the goal of having a large re-sulting structure.
The goal of the training processis to learn a function that can make these trade-offssuccessfully.The trained fitness function combines the threegiven numerical scores using addition, subtraction,multiplication, and division.
It is trained using agenetic programming technique.
A successful fit-ness function ranks hypotheses the same way as anideal fitness function that can compare the result-ing structures with the ideal one.
Before a fitnessfunction can be trained, there must first be trainingdata.
Appropriate training data for the fitness func-tion is a set of ranked lists of scores, e.g., the threescores mentioned above.
Each set of three scores cor-responds to the repair hypothesis it was extractedfrom.
These sets of scores in the training examplesare ranked the way the ideal fitness function wouldrank the associated hypotheses.
The purpose of thetraining process is to find a function that combinesthe three scores into a single score such that whenthe set of single scores are sorted, the ordering is thesame as in the training example.
Correctly sortingthe sets of scores is equivalent o ranking the hy-potheses themselves.
Therefore, a function that cansuccessfully sort the scores in the training exampleswill be correspondingly good at ranking repair hy-potheses.6 A Comparat ive  Ana lys i s  in  aLarge  Sca le  P ract i ca l  Set t ingIn order to compare the two stage repair approachwith the single stage MDP approach in a practi-cal, large-scale scenario, we conducted a compara-tive evaluation.
As mentioned above, we make use32of a version of Lavie's GLR* parser (Lavie, 1995)extended to be able to perform both skipping andinserting which we refer to as LR MDP.
This makesit possible to compare the two stage ROSE approachto MDP keeping all other factors constant.The parser uses a semantic grammar with approx-imately 1000 rules which maps the input sentenceonto an interlingua representation (ILT) which rep-resents the meaning of the sentence in a language-independent manner.
This ILT is then passed toa generation component which generates a sentencein the target language which is then graded by ahuman judge as Bad, Partial, Okay, or Perfect interms of translation quality.
Partial indicates thatthe result communicated part of the content of theoriginal sentence while not containing any incorrectinformation.
Okay indicates that the generated sen-tence communicated all of the relevant informationin the original sentence but not in the ideal way.
Per-fect indicates both that the result communicated therelevant information and that it did so in a smooth,high quality manner.
The corpus used in this evalu-ation contains 500 sentences from a corpus of spon-taneous cheduling dialogues collected in English.In a previous experiment we determined that thetwo stage approach performs about two orders ofmagnitude faster than LR MDP.
For the purposeof the evaluation presented in this paper we testedthe effect of imposing a maximum deviation penaltyon the minimum distance parser in order to deter-mine how much flexibility could be allowed beforethe computational cost would become unreasonable.A full, unconstrained implementation f MDP canfind an analysis for any sentence using a combinationof insertions, deletions, and transpositions.
How-ever, in order to make it viable to test the MDPapproach in a system as large as the one which pro-vides the context for this work, we make use of amore restricted version of MDP.
While the full MDPalgorithm allows insertions, deletions, and transpo-sitions, our more constrained version of MDP allowsonly insertions and deletions.
Although this still al-lows the MDP parser to repair any sentence, in somecases the result will not be as complete as it wouldhave been with the unconstrained version of MDPor with the two stage repair process.
Additionally,with a lexicon on the order of 1000 lexical items,it is not practical to do insertions on the level ofthe lexical items themselves.
Instead, we allow onlynon-terminals to be inserted.
An insertion penaltyequivalent to the minimum number of words it wouldtake to generate a given non-terminal is assigned toa parse for each inserted non-terminal.In order to test the effect of imposing a maximumdeviation penalty, we used a parameterized versionof LR MDP, where the deviation penalty of a parseis the total number of words skipped plus the parse'sassociated insertion penalty as described above.The avenues of exploration made available hereCD.EF-.c82Q.2500200015001000500i/lII /I ///ll \]: 1 !
: //~ //i iMDP1MDP3 -~--MDP5 -m--GLR* w/Restarts ..x .....GLR* w/Restarts + Repair -~-.-f i 25 10 15 20Sentence LengthFigure 5: Parse  T imes  for  A l te rnat ive  S t ra teg iesNIL Bad Partial Okay PerfectMDP 1 21.4% 3.4% 3.4% 18.4% 53.4%MDP 3 16.2% 4.2% 5.0% 19.6% 55.0%MDP 5 8.4% 8.2% 6.0% 21.0% 56.4%GLR* with Restarts 9.2% 6.4% 12.8% 19.4% 52.2%GLR* with Restarts + Repair 0.4% 9.6% 11.8% 23.4% 54.8%Figure 6: Translation Quality of Alternative Strategiesare far from exhaustive.
Substitutions and transpo-sitions are not allowed in this version of the parser,nor is it possible to set a separate maximum penaltyfor skipping and for inserting.
Additionally, inser-tions and deletions are weighted equally, where someresearchers have weighted them differently (Hipp,1992).
These and other possibilities are left for fu-ture inquiry.7 Eva luat ionThe LR MDP parser was run over the corpus atthree different flexibility settings.
The first setting,MDP 1, is Minimum Distance Parsing with max-imum deviation penalty of 1.
Similarly, MDP 3and MDP 5 are MDP with maximum devaitionpenalty of 3 and 5 respectively.
We also ran theversion of GLR* where only initial segments can beskipped which we refer to as GLR*  w i th  Restar ts .Thus, while the parser can restart from each word inthe sentence, analyses produced are always for con-tiguous segments of the sentence.
We ran GLR*w i th  Restar ts  both with and without repair.
Tim-ings for all five of these iterations over the corpusare displayed in Figure 5.
Notice that GLR*  w i thRestar ts  is significantly faster than even MDP 1.And since the repair stage is run only for sentencesthat the repair module determines need repair, andsince the repair process takes only seconds on aver-age to run, no significant difference in time can beseen in this graph between the case with repair andthe case without repair.The translation quality ratings for the five differ-ent iterations over the corpus are found in Figure6.
Predictably, MDP 5 is an improvement overMDP 1 and MDP 3, with an associated significantcost in run time.
Also, not surprisingly, the very re-stricted GLR*  w i th  Restar ts ,  while faster than ei-ther of the other two, has a correspondingly lower as-sociated translation quality.
However, GLR*  w i thRestar ts  --{- Repa i r  outperforms the other methodsin terms of total number of acceptable translations,while not being significantly slower than GLR*33with Restarts without repair.
Though these re-sults display certain trends in the performance ofthese alternative approaches, the differences in gen-eral are very small.
For example, the difference innumber of acceptable translations between MDP 5and GLR* with restarts + repair is only about1%.
The largest difference between the two is thatGLR* with restarts + repair has about 7% moresentences with translation quality of Partial or bet-ter, indicating that GLR* with restarts + repairproduces analyses that are useful for furthering theconversation between the two speakers using the sys-tem 7% more often than MDP 5.While we have no doubt that increasingly moreflexible versions of MDP would perform better thanMDP 5, we have already demonstrated that evenMDP 5 is impractical in terms of its run-time per-formance.
Thus we conclude that the two stageROSE approach, even with a very limited flexibil-ity parser, is a superior choice.
We believe that byincreasing the flexibility of the parser to include verylimited skipping in addition to restarts would in-crease the performance of this two stage approachwithout incurring a significant increase in run timeperformance.
Determining exactly how much skip-ping is ideal is a direction for future research.8 Conc lus ionsIn this paper we addressed the issue of how to ef-ficiently handle the problem of extragrammaticalityin a large-scale spontaneous spoken language sys-tem.
We argue that even though Minimum Dis-tance Parsing offers a theoretically attractive so-lution to the problem of extragrammaticality, it iscomputationally infeasible in large scale practicalapplications.
Our analysis demonstrates that theROSE approach, consisting of a skipping parser withlimited flexibility coupled with a completely auto=matic post-processing repair module, performs ig-nificantly faster than even a version of MDP limitedonly to skipping and inserting and constrained to amaximum deviation penalty of 5, while producinganalyses of superior quality.ReferencesAbney, S. 1996.
Partial parsing via finite-state cas-cades.
In Proceedings of the Eight European Sum-mer School In Logic, Language and Information,Prague, Czech Republic.Danieli, M. and E. Gerbino.
1995.
Metrics for eval-uating dialogue strategies in a spoken languagesystem.
In Working Notes of the AAAI SpringSymposium on Empirical Methods in DiscourseInterpretation and Generation.Ehrlich, U. and G. Hanrieder.
1996.
Robust speechparsing.
In Proceedings of the Eight EuropeanSummer School In Logic, Language and Informa-tion, Prague, Czech Republic.Federici, S., S. Montemagni, and V. Pirrelli.
1996.Shallow parsing and text chunking: a view on un-derspecification i  syntax.
In Proceedings of theEight European Summer School In Logic, Lan-guage and Information, Prague, Czech Republic.Hipp, D. R. 1992.
Design and Development of Spo-ken Natural-Language Dialog Parsing Systems.Ph.D.
thesis, Dept.
of Computer Science, DukeUniversity.Koza, J.
1992.
Genetic Programming: On the Pro-gramming of Computers by Means of Natural Se-lection.
MIT Press.Koza, J.
1994.
Genetic Programming II.
MIT Press.Lavie, A.
1995.
A Grammar Based Robust ParserFor Spontaneous Speech.
Ph.D. thesis, School ofComputer Science, Carnegie Mellon University.Lavie, A., D. Gates, M. Gavalda, L. Mayfield, andA.
Waibel L. Levin.
1996.
Multi-lingual transla-tion of spontaneously poken language in a limiteddomain.
In Proceedings of COLING 96, Kopen-hagen.Lavie, A. and M. Tomita.
1993.
GLR* - an efficientnoise-skipping parsing algorithm for context freegrammars.
In Proceedings of the Third Interna-tional Workshop on Parsing Technologies.Lehman, J. F. 1989.
Adaptive Parsing: Self-Extending Natural Language Interfaces.
Ph.D.thesis, School of Computer Science, Carnegie Mel-lon University.
CMU-CS-89-191.Nord, G. Van.
1996.
Robist parsing with the head-corner parser.
In Proceedings of the Eight Euro-penn Summer School In Logic, Language and In-formation, Prague, Czech Republic.Srinivas, B., C. Doran, B. Hockey, and A. Joshi.1996.
An approach to robust partial parsing andevaluation metrics.
In Proceedings of the EightEuropean Summer School In Logic, Language andInformation, Prague, Czech Republic.Woszcyna, M., N. Aoki-Waibel, F. D. Buo, N. Coc-caro, K. Horiguchi, T. Kemp, A. Lavie, A. Mc-Nair, T. Polzin, I. Rogina, C. P. Ros@, T. Schultz,B.
Suhm, M. Tomita, and A. Waibel.
1994.JANUS 93: Towards pontaneous speech transla-tion.
In Proceedings of the International Confer-ence on Acoustics, Speech, and Signal Processing.Woszcyna, M., N. Coccar9, A. Eisele, A. Lavie,A.
McNair, T. Polzin, I. Rogina, C. P. Ros~,T.
Sloboda, M. Tomita, J. Tsutsumi, N. Waibel,A.
Waibel, and W. Ward.
1993.
Recent advancesin JANUS: a speech translation system.
In Pro-ceedings of the ARPA Human Languages Technol-ogy Workshop.34
