Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 480?487,Prague, Czech Republic, June 2007. c?2007 Association for Computational LinguisticsFinding document topics for improving topic segmentationOlivier FerretCEA LIST, LIC2M18 route du Panorama, BP6Fontenay aux Roses, F-92265 Franceferreto@zoe.cea.frAbstractTopic segmentation and identification are of-ten tackled as separate problems whereasthey are both part of topic analysis.
In thisarticle, we study how topic identification canhelp to improve a topic segmenter based onword reiteration.
We first present an unsu-pervised method for discovering the topicsof a text.
Then, we detail how these topicsare used by segmentation for finding topicalsimilarities between text segments.
Finally,we show through the results of an evaluationdone both for French and English the inter-est of the method we propose.1 IntroductionIn this article, we address the problem of linear topicsegmentation, which consists in segmenting doc-uments into topically homogeneous segments thatdoes not overlap each other.
This part of the Dis-course Analysis field has received a constant interestsince the initial work in this domain such as (Hearst,1994).
One criterion for classifying topic segmen-tation systems is the kind of knowledge they de-pend on.
Most of them only rely on surface featuresof documents: word reiteration in (Hearst, 1994;Choi, 2000; Utiyama and Isahara, 2001; Galley etal., 2003) or discourse cues in (Passonneau and Lit-man, 1997; Galley et al, 2003).
As such systems donot require external knowledge, they are not sensi-tive to domains but they are limited by the type ofdocuments they can be applied to: lexical reiterationis reliable only if concepts are not too frequently ex-pressed by several means (synonyms, etc.)
and dis-course cues are often rare and corpus-specific.To overcome these difficulties, some systemsmake use of domain-independent knowledge aboutlexical cohesion: a lexical network built from a dic-tionary in (Kozima, 1993); a thesaurus in (Mor-ris and Hirst, 1991); a large set of lexical co-occurrences collected from a corpus in (Choi et al,2001).
To a certain extent, these lexical networksenable topic segmenters to exploit a sort of conceptreiteration.
However, their lack of any explicit topi-cal structure makes this kind of knowledge difficultto use when lexical ambiguity is high.The most simple solution to this problem is to ex-ploit knowledge about the topics that may occur indocuments.
Such topic models are generally builtfrom a large set of example documents as in (Yam-ron et al, 1998), (Blei and Moreno, 2001) or in onecomponent of (Beeferman et al, 1999).
These sta-tistical topic models enable segmenters to improvetheir precision but they also restrict their scope.Hybrid systems that combine the approacheswe have presented were also developed and illus-trated the interest of such a combination: (Job-bins and Evett, 1998) combined word recurrence,co-occurrences and a thesaurus; (Beeferman et al,1999) relied on both lexical modeling and discoursecues; (Galley et al, 2003) made use of word reitera-tion through lexical chains and discourse cues.The work we report in this article takes place inthe first category we have presented.
It does notrely on any a priori knowledge and exploits wordusage rather than discourse cues.
More precisely,we present a new method for enhancing the results480of segmentation systems based on word reiterationwithout relying on any external knowledge.2 PrinciplesIn most of the algorithms in the text segmentationfield, documents are represented as sequences of ba-sic discourse units.
When they are written texts,these units are generally sentences, which is also thecase in our work.
Each unit is turned into a vector ofwords, following the principles of the Vector Spacemodel.
Then, the similarity between the basic unitsof a text is evaluated by computing a similarity mea-sure between the vectors that represent them.
Such asimilarity is considered as representative of the top-ical closeness of the corresponding units.
This prin-ciple is also applied to groups of basic units, such astext segments, because of the properties of the Vec-tor Space model.
Segments are finally delimited bylocating the areas where the similarity between unitsor groups of units is weak.This quick overview highlights the important roleof the evaluation of the similarity between discourseunits in the segmentation process.
When no exter-nal knowledge is used, this similarity is only basedon the strict reiteration of words.
But it can be en-hanced by taking into account semantic relations be-tween words.
This was done for instance in (Jobbinsand Evett, 1998) by taking semantic relations fromRoget?s Thesaurus.
This resource was also used in(Morris and Hirst, 1991) where the similarity be-tween discourse units was more indirectly evaluatedthrough the lexical chains they share.
The same ap-proach was adopted in (Stokes et al, 2002) but withWordNet as the reference semantic resource.In this article, we propose to improve the detec-tion of topical similarity between text segments butwithout relying on any external knowledge.
For eachtext to segment, we first identify its topics by per-forming an unsupervised clustering of its words ac-cording to their co-occurrents in the text.
Thus, eachof its topics is represented by a subset of its vocab-ulary.
When the similarity between two segments isevaluated during segmentation, the words they shareare first considered but the presence of words of thesame topic is also taken into account.
This makesit possible to find similar two segments that refer tothe same topic although they do not share a lot ofwords.
It is also a way to exploit long-range rela-tions between words at a local level.
More globally,it helps to reduce the false detection of topic shifts.3 Unsupervised Topic IdentificationThe approach we propose first requires to discoverthe topics of texts.
For performing such a task with-out using a priori knowledge, we assume that themost representative words of each of the topics ofa text occur in similar contexts.
Hence, for eachword of the text with a minimal frequency, we col-lect its co-occurrents, we evaluate the pairwise simi-larity of these selected text words by relying on theirco-occurrents and finally, we build topics by apply-ing an unsupervised clustering method to them.3.1 Building the similarity matrix of text wordsThe first step for discovering the topics of a text isa linguistic pre-processing of it.
This pre-processingsplits the text into sentences and represents each ofthem as the sequence of its lemmatized plain words,that is, nouns (proper and common nouns), verbsand adjectives.
After filtering the low frequencywords of the text (frequency < 3), the co-occurrentsof the remaining words are classically collected byrecording the co-occurrences in a fixed-size win-dow (15 plain words) moved over the pre-processedtext.
As a result, each text word is represented bya vector that contains its co-occurrents and their co-occurrence frequency.
The pairwise similarity be-tween all the selected text words is then evaluatedfor building their similarity matrix.
We classicallyapply the Cosine measure between the vectors thatrepresent them for this evaluation.3.2 From a similarity matrix to text topicsThe final step for discovering the topics of a text isthe unsupervised clustering of its words from theirsimilarity matrix.
We rely for this task on an adap-tation of the Shared Nearest Neighbor (SNN) algo-rithm described in (Ert?z et al, 2001).
This algo-rithm particularly fits our needs as it automaticallydetermines the number of clusters ?
in our case thenumber of topics of a text ?
and does not take intoaccount the elements that are not representative ofthe clusters it builds.
This last point is important forour application as all the plain words of a text arenot representative of its topics.
The SNN algorithm481yearyearlybovinecase becomeBEShumanmarketpairskiswissanimalcarcassdeclarefederalinfectdiseasedirectorindicateshakingcowmakerproductionstreulelastmadcompanystockliFigure 1: Similarity graph after its sparsification(see Algorithm 1) performs clustering by detectinghigh-density areas in a similarity graph.
In our case,the similarity graph is directly built from the simi-larity matrix: each vertex represents a text word andan edge links two words whose similarity is not null.The SNN algorithm splits up into two main stages:the first one finds the elements that are the most rep-resentative of their neighborhood.
These elementsare the seeds of the final clusters that are built in thesecond stage by aggregating the remaining elementsto those selected by the first stage.
This first stageAlgorithm 1 SNN algorithm1.
sparsification of the similarity graph2.
building of the SNN graph3.
computation of the distribution of strong links4.
search for topic seeds and filtering of noise5.
building of text topics6.
removal of insignificant topics7.
extension of text topicsstarts by sparsifying the similarity graph, which isdone by keeping only the links towards the k (k=10)most similar neighbors of each text word (step 1).Figure 1 shows the resulting graph for a two-topicdocument of our evaluation framework (see Sec-tion 5.1).
Then, the similarity graph is transposedinto a shared nearest neighbor (SNN) graph (step 2).In this graph, the similarity between two words isgiven by the number of direct neighbors they sharein the similarity graph.
This transposition makes thesimilarity values more reliable, especially for high-dimensional data like textual data.
Strong links inthe SNN graph are finally detected by applying afixed threshold to the distribution of shared neigh-bor numbers (step 3).
A word with a high numberof strong links is taken as the seed of a topic as it isrepresentative of the set of words that are linked toit.
On the contrary, a word with few strong links issupposed to be outlier (step 4).The second stage of the SNN algorithm firstbuilds text topics by associating to topic seeds theremaining words that are the most similar to themprovided that their number of shared neighbors ishigh enough (step 5).
Moreover, the seeds that arejudged as too close to each other are also groupedduring this step in accordance with the same crite-ria.
The last two steps bring small improvements tothe results of this clustering.
First, when the num-ber of words of a topic is too small (size < 3), thistopic is judged as insignificant and it is discarded(step 6).
Its words are added to the set of words with-out topic after step 5.
We added this step to the SNNalgorithm to balance the fact that without any ex-ternal knowledge, all the semantic relations betweentext words cannot be found by relying only on co-occurrence.
Finally, the remaining text topics areextended by associating to them the words that areneither noise nor already part of a topic (step 7).
Astopics are defined at this point more precisely than atstep 4, the integration of words that are not stronglylinked to a topic seed can be safely performed byrelying on the average strength of their links in theSNN graph with the words of the topic.
After theSNN algorithm is applied, a set of topics is associ-ated to the text to segment, each of them being de-fined as a subset of its vocabulary.4 Using Text Topics for Segmentation4.1 Topic segmentation using word reiterationAs TextTiling, the topic segmentation method ofHearst (Hearst, 1994), the topic segmenter we pro-pose, called F06, first evaluates the lexical cohesionof texts and then finds their topic shifts by iden-tifying breaks in this cohesion.
The first step ofthis process is the linguistic pre-processing of texts,which is identical for topic segmentation to the pre-482processing described in Section 3.1 for the discover-ing of text topics.
The evaluation of the lexical cohe-sion of a text relies as for TextTiling on a fixed-sizefocus window that is moved over the text to segmentand stops at each sentence break.
The cohesion inthe part of text delimited by this window is evalu-ated by measuring the word reiteration between itstwo sides.
This is done in our case by applying theDice coefficient between the two sides of the focuswindow, following (Jobbins and Evett, 1998).
Thiscohesion value is associated to the sentence break atthe transition between the two sides of the window.More precisely, if Wl refers to the vocabulary of theleft side of the focus window and Wr refers to thevocabulary of its right side, the cohesion in the win-dow at position x is given by:LCrec(x) =2 ?
card(Wl ?
Wr)card(Wl) + card(Wr)(1)This measure was adopted instead of the Cosinemeasure used in TextTiling because its definition interms of sets makes it easier to extend for taking intoaccount other types of relations, as in (Jobbins andEvett, 1998).
A cohesion value is computed for eachsentence break of the text to segment and the finalresult is a cohesion graph of the text.The last part of our algorithm is mainly takenfrom the LCseg system (Galley et al, 2003) and isdivided into three steps:?
computation of a score evaluating the probabil-ity of each minimum of the cohesion graph tobe a topic shift;?
removal of segments with a too small size;?
selection of topic shifts.The computation of the score of a minimum m be-gins by finding the pair of maxima l and r around it.This score is then given by:score(m) = LC(l) + LC(r) ?
2 ?
LC(m)2 (2)This score, whose values are between 0 and 1, is ameasure of how high is the difference between theminimum and the maxima around it.
Hence, it fa-vors as possible topic shifts minima that correspondto sharp falls of lexical cohesion.The next step is done by removing as a possibletopic shift each minimum that is not farther than 2sentences from its preceding neighbor.
Finally, theselection of topic shifts is performed by applying athreshold computed from the distribution of mini-mum scores.
Thus, a minimum m is kept as a topicshift if score(m) > ???
?
?, where ?
is the averageof minimum scores, ?
their standard deviation and ?is a modulator (?
= 0.6 in our experiments).4.2 Using text topics to enhance segmentationThe heart of the algorithm we have presented aboveis the evaluation of lexical cohesion in the focus win-dow, as given by Equation 1.
This evaluation isalso a weak point as card(Wl ?
Wr) only relies onword reiteration.
As a consequence, two differentwords that respectively belongs to Wl and Wr butalso belong to the same text topic cannot contributeto the identification of a possible topical similaritybetween the two sides of the focus window.The algorithm F06T is based on the same princi-ples as F06 but it extends the evaluation of lexicalcohesion by taking into account the topical proxim-ity of words.
The reference topics for judging thisproximity are of course the text topics discovered bythe method of Section 3.
In this extended version,the evaluation of the cohesion in the focus windowis made of three steps:?
computation of the word reiteration cohesion;?
determination of the topic(s) of the window;?
computation of the cohesion based on text top-ics and fusion of the two kinds of cohesion.The first step is identical to the computation of thecohesion in F06.
The second one aims at restrict-ing the set of topics that are used in the last stepto the topics that are actually representative of thecontent of the focus window, i.e.
representative ofthe current context of discourse.
This point is espe-cially important in the areas where the current topicis changing because amplifying the influence of thesurrounding topics can lead to the topic shift beingmissed.
Hence, a topic is considered as represen-tative of the content of the focus window only if itmatches each side of this window.
In practice, thismatching is evaluated by applying the Cosine mea-sure between the vector that represents one side of483the window and the vector that represents the topic1and by testing if the resulting value is higher than afixed threshold (equal to 0.1 in the experiments ofSection 5).
It must be noted that several topics maybe associated to the focus window.
As the discov-ering of text topics is done in an unsupervised wayand without any external knowledge, a theme of atext may be scattered over several identified topicsand then, its presence can be characterized by sev-eral of them.The last step of the cohesion evaluation first con-sists in determining for each side of the focus win-dow the number of its words that belong to one ofthe topics associated to the window.
The cohesionof the window is then given by Equation 3, that es-timates the significance of the presence of the texttopics in the window:LCtop(x) =card(TWl) + card(TWr)card(Wl) + card(Wr)(3)where TWi?
{l,r} = (Wi ?Tw)?
(Wl ?Wr) and Twis the union of all the representations of the topicsassociated to the window.
TWi corresponds to thewords of the i side of the window that belong to thetopics of the window (Wi?Tw) but are not part of thevocabulary from which the lexical cohesion basedon word reiteration is computed (Wl ?
Wr).Finally, the global cohesion in the focus windowis computed as the sum of the two kinds of cohesion,the one computed from word reiteration (see Equa-tion 1) and the one computed from text topics (seeEquation 3).5 Evaluation5.1 Evaluation frameworkThe main objective of our evaluation was to verifythat taking into account text topics discovered with-out relying on external knowledge can actually im-prove a topic segmentation algorithm that is initiallybased on word reiteration.
Since the work of Choi(Choi, 2000), the evaluation framework he proposedhas become a kind of standard for the evaluation oftopic segmentation algorithms.
This framework is1Each word of the topic vector has a weight equal to 1.
Inthe window vector, this weight is equal to the frequency of theword in the corresponding side of the window.based on the building of artificial texts made of seg-ments extracted from different documents.
It has atleast two advantages: the reference corpus is easyto build as it does not require human annotations;parameters such as the size of the documents or thesegments can be precisely controlled.
But it has alsoan obvious drawback: its texts are artificial.
This is aproblem in our case as our algorithm for discoveringtext topics exploits the fact that the words of a topictend to co-occur at the document scale.
This hypoth-esis is no longer valid for documents built accord-ing to the procedure of Choi.
It is why we adaptedhis framework for having more realistic documentswithout losing its advantages.
This adaptation con-French English# source doc.
128 87# source topics 11 3segments/doc.
10 (84%) 10 (97%)8 (16%) 8 (3%)sentences/doc.
65 68plain words/doc.
797 604Table 1: Data about our evaluation corporacerns the way the document segments are selected.Instead of taking each segment from a different doc-ument, we only use two source documents.
Each ofthem is split into a set of segments whose size is be-tween 3 and 11 sentences, as for Choi, and an eval-uation document is built by concatenating these seg-ments in an alternate way from the beginning of thesource documents, i.e.
one segment from a sourcedocument and the following from the other one, un-til 10 segments are extracted.
Moreover, in orderto be sure that the boundary between two adjacentsegments of an evaluation document actually corre-sponds to a topic shift, the source documents are se-lected in such a way that they refer to different top-ics.
This point was controlled in our case by takingdocuments from the corpus of the CLEF 2003 eval-uation for crosslingual information retrieval: eachevaluation document was built from two source doc-uments that had been judged as relevant for two dif-ferent CLEF 2003 topics.
Two evaluation corporamade of 100 documents each, one in French and onein English, were built following this procedure.
Ta-ble 1 shows their main characteristics.4845.2 Topic identificationAs F06T exploits document topics, we also evalu-ated our method for topic identification.
This evalu-ation is based on the corpus of the previous section.For each of its documents, a reference topic is builtfrom each group of segments that come from thesame source document by gathering the words thatonly appear in these segments.
A reference topic isassociated to the discovered topic that shares with itthe largest number of words.
Three complementarymeasures were computed to evaluate the quality ofdiscovered topics.
The main one is purity, which isclassically used for unsupervised clustering:Purity =k?i=1viV P (Tdi) (4)where P (Tdi), the purity of the discovered topicTdi, is equal to the fraction of the vocabulary of Tdithat is part of the vocabulary of the reference topicTdi is assigned to, V is the vocabulary of all the dis-covered topics and vi is the vocabulary of Tdi.
Thesecond measure evaluates to what extent the refer-ence topics are represented among the discoveredtopics and is equal to the ratio between the num-ber of discovered topics that are assigned to a refer-ence topic (assigned discovered topics) and the num-ber of reference topics.
The last measure estimateshow strongly the vocabulary of reference topics ispresent among the discovered topics and is equal tothe ratio between the size of the vocabulary of theassigned discovered topics and the size of the vo-cabulary of reference topics.
Table 2 gives the meanpurity referencetopics (%)ref.
topicvocab.
(%)French 0.771 (0.117) 89.5 (23.9) 29.9 (7.8)English 0.766 (0.082) 99.0 (10.0) 31.6 (5.3)Table 2: Evaluation of topic identificationof each measure, followed by its standard deviation.Results are globally similar for French and English.They show that our method for topic identificationbuilds topics that are rather pure, i.e.
each of them isstrongly tied to a reference topic, but their content israther sparse in comparison with the content of theirassociated reference topics.5.3 Topic segmentationFor validating the hypothesis that underlies ourwork, we applied F06 and F06T to find the topicbounds in the documents of our two evaluation cor-pora.
Moreover, we also tested four well known seg-menters on our corpora to compare the results of F06and F06T with state-of-the-art algorithms.
We clas-sically used the error metric Pk proposed in (Beefer-man et al, 1999) to measure segmentation accuracy.Pk evaluates the probability that a randomly cho-sen pair of sentences, separated by k sentences, iswrongly classified, i.e.
they are found in the samesegment while they are actually in different ones(miss) or they are found in different segments whilethey are actually in the same one (false alarm).
Wealso give the value of WindowDiff (WD), a variant ofPk proposed in (Pevzner and Hearst, 2002) that cor-rects some of its insufficiencies.
Tables 3 and 4 showsystems Pk pval(F06) pval(F06T) WDU00 25.91 0.003 1.3e-07 27.42C99 27.57 4.2e-05 3.6e-10 35.42TextTiling* 21.08 0.699 0.037 27.43LCseg 20.55 0.439 0.111 28.31F06 21.58  0.013 27.83F06T 18.46 0.013  24.05Table 3: Evaluation of topic segmentation for theFrench corpus (Pk and WD as percentages)the results of our evaluations for topic segmentation(smallest values are best results).
U00 is the sys-tem described in (Utiyama and Isahara, 2001), C99the one proposed in (Choi, 2000) and LCseg is pre-sented in (Galley et al, 2003).
TextTiling* is a vari-ant of TextTiling in which the final identification oftopic shifts is taken from (Galley et al, 2003).
Allthese systems were used as F06 and F06T withoutfixing the number of topic shifts to find.
Moreover,their parameters were tuned for our evaluation cor-pus to obtain their best results.
For each result, wealso give the significance level pval of its differencefor Pk with F06 and F06T, evaluated by a one-sidet-test with a null hypothesis of equal means.
Lev-els lower than 0.05 are considered as statisticallysignificant (bold-faced values).
The first importantpoint to notice about these tables is the fact that485systems Pk pval(F06) pval(F06T) WDU00 19.42 0.048 4.3e-05 21.22C99 21.63 1.2e-04 1.8e-09 30.64TextTiling* 15.81 0.308 0.111 19.80LCseg 14.78 0.043 0.496 19.73F06 16.90  0.010 20.93F06T 14.06 0.010  18.31Table 4: Evaluation of topic segmentation for theEnglish corpus (Pk and WD as percentages)F06T has significantly better results than F06, bothfor French and English.
Hence, it confirms our hy-pothesis about the interest of taking into account thetopics of a text for its segmentation, even if thesetopics were discovered in an unsupervised way andwithout using external knowledge.
Moreover, F06Thave the best results among all the tested algorithms,with a significant difference in most of the cases.Another notable point about these results is theirstability across our two corpora, even if these cor-pora are quite similar.
Whereas F06 and F06T wereinitially developed on a corpus in French, their re-sults on the English corpus are comparable to theirresults on the French test corpus, both for the dif-ference between them and the difference with thefour other algorithms.
The comparison with thesealgorithms also illustrates the relationships betweenthem: TextTiling*, LCseg, F06 and F06T share alarge number of principles and their overall resultsare significantly higher than the results of U00 andC99.
This trend is different from the one observedfrom the Choi corpus for which algorithms such C99or U00 have good results (Pk for C99, U00, F06 andF06T is respectively equal to 12%, 10%, 14% and14%).
This means probably that algorithms withgood results on a corpus built as the Choi corpus willnot necessarily have good results on ?true?
texts,which agrees with (Georgescul et al, 2006).
Finally,we can observe that all these algorithms have betterresults on the English corpus than on the French one.As the two corpora are quite similar, this differenceseems to come from their difference of language,perhaps because repetitions are more discouraged inFrench than in English from a stylistic viewpoint.This tends to be confirmed by the ratio between thesize of the lemmatized vocabulary of each corpusand their number of tokens, equal to 8% for theFrench corpus and to 5.6% for the English corpus.6 Related WorkOne of the main problems addressed by our workis the detection of the topical similarity of two textunits.
We have tackled this problem following anendogenous approach, which is new in the topic seg-mentation field to our knowledge.
The main advan-tage of this option is that it does not require externalknowledge.
Moreover, it can integrate relations be-tween words, such as proper nouns for instance, thatare unlikely to be found in an external resource.Other solutions have been already proposed tosolve the problem we consider.
Most of them consistof two steps: first, they automatically build a seman-tic representation of words from the co-occurrencescollected from a large corpus; then, they use thisrepresentation for enhancing the representation ofeach text unit to compare.
This overall principle isimplemented with different forms by several topicsegmenters.
In CWM (Choi et al, 2001), a variantof C99, each word of a sentence is replaced by itsrepresentation in a Latent Semantic Analysis (LSA)space.
In the work of Ponte and Croft (Ponte andCroft, 1997), the representations of sentences are ex-panded by adding to them words selected from anexternal corpus by the means of the Local ContextAnalysis (LCA) method.
Finally in (Caillet et al,2004), a set of concepts are learnt from a corpusin an unsupervised way by using the X-means clus-tering algorithm and the paragraphs of documentsare represented in the space defined by these con-cepts.
In fact, the way we use relations betweenwords is closer to (Jobbins and Evett, 1998), evenif the relations in this work come from a network ofco-occurrences or a thesaurus rather than from texttopics.
In both cases the similarity of two text unitsis determined by the proportion of their words thatare part of a relation across the two units.More globally, our work exploits the topics of atext for its segmentation.
This kind of approachwas also explored in (Blei and Moreno, 2001) whereprobabilistic topic models were built in an unsuper-vised way.
More recently, (Purver et al, 2006) hasalso proposed a method for unsupervised topic mod-eling to address both topic segmentation and identi-486fication.
(Purver et al, 2006) is closer to our workthan (Blei and Moreno, 2001) because it does not re-quire to build topic models from a corpus but as inour case, its results do not outperform LCseg (Galleyet al, 2003) while its model is far more complex.7 Conclusion and Future WorkIn this article, we have first proposed an unsuper-vised method for discovering the topics of a textwithout relying on external knowledge.
Then, wehave shown how these topics can be used for im-proving a topic segmentation method based on wordreiteration.
Moreover, we have proposed an adapta-tion of the evaluation framework of Choi that aimsat building more realistic evaluation documents.
Fi-nally, we have demonstrated the interest of themethod we present through its evaluation both on aFrench and an English corpus.However, the solution we have proposed for im-proving the identification of topical similarities be-tween text excerpts cannot completely make up fornot using any external knowledge.
Hence, we planto use a network of lexical co-occurrences, which isa source of knowledge that is easy to build automati-cally from a large corpus.
More precisely, we intendto extend our method for discovering text topics bycombining the co-occurrence graph of a documentwith such a network.
This network could also beused more directly for topic segmentation as in (Job-bins and Evett, 1998).ReferencesDoug Beeferman, Adam Berger, and John Lafferty.1999.
Statistical models for text segmentation.
Ma-chine Learning, 34(1):177?210.David M. Blei and Pedro J. Moreno.
2001.
Topic seg-mentation with an aspect hidden markov model.
In24th ACM SIGIR, pages 343?348.Marc Caillet, Jean-Fran?ois Pessiot, Massih Amini, andPatrick Gallinari.
2004.
Unsupervised learning withterm clustering for thematic segmentation of texts.
InRIAO?04, pages 1?11.Freddy Y. Y. Choi, Peter Wiemer-Hastings, and JohannaMoore.
2001.
Latent semantic analysis for text seg-mentation.
In EMNLP?01, pages 109?117.Freddy Y. Y. Choi.
2000.
Advances in domain inde-pendent linear text segmentation.
In NAACL?00, pages26?33.Levent Ert?z, Michael Steinbach, and Vipin Kuma.
2001.Finding topics in collections of documents: A sharednearest neighbor approach.
In Text Mine?01, Work-shop of the 1st SIAM International Conference onData Mining.Michel Galley, Kathleen McKeown, Eric Fosler-Lussier,and Hongyan Jing.
2003.
Discourse segmentation ofmulti-party conversation.
In ACL?03, pages 562?569.Maria Georgescul, Alexander Clark, and Susan Arm-strong.
2006.
An analysis of quantitative aspects inthe evaluation of thematic segmentation algorithms.In 7th SIGdial Workshop on Discourse and Dialogue,pages 144?151.Marti A. Hearst.
1994.
Multi-paragraph segmentation ofexpository text.
In ACL?94, pages 9?16.Amanda C. Jobbins and Lindsay J. Evett.
1998.
Text seg-mentation using reiteration and collocation.
In ACL-COLING?98, pages 614?618.Hideki Kozima.
1993.
Text segmentation based on sim-ilarity between words.
In ACL?93 (Student Session),pages 286?288.Jane Morris and Graeme Hirst.
1991.
Lexical cohe-sion computed by thesaural relations as an indicatorof the structure of text.
Computational Linguistics,17(1):21?48.Rebecca J. Passonneau and Diane J. Litman.
1997.
Dis-course segmentation by human and automated means.Computational Linguistics, 23(1):103?139.Lev Pevzner and Marti A. Hearst.
2002.
A critique andimprovement of an evaluation metric for text segmen-tation.
Computational Linguistics, 28(1):19?36.Jay M. Ponte and Bruce W. Croft.
1997.
Text segmen-tation by topic.
In First European Conference on re-search and advanced technology for digital libraries.Matthew Purver, Konrad P. K?rding, Thomas L. Grif-fiths, and Joshua B. Tenenbaum.
2006.
Unsupervisedtopic modelling for multi-party spoken discourse.
InCOLING-ACL 2006, pages 17?24.N.
Stokes, J. Carthy, and A.F.
Smeaton.
2002.
Segment-ing broadcast news streams using lexical chains.
InSTAIRS?02, pages 145?154.Masao Utiyama and Hitoshi Isahara.
2001.
A statisticalmodel for domain-independent text segmentation.
InACL?01, pages 491?498.J.P.
Yamron, I. Carp, L. Gillick, S. Lowe, and P. van Mul-bregt.
1998.
A hidden markov model approach to textsegmentation and event tracking.
In ICASSP, pages333?336.487
