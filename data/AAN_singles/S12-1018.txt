First Joint Conference on Lexical and Computational Semantics (*SEM), pages 105?113,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsAnnotating Preferences in Negotiation DialoguesAna?
?s Cadilhac, Nicholas Asher and Farah BenamaraIRIT, CNRS and University of Toulouse118, route de Narbonne31062 Toulouse, France{cadilhac, asher, benamara}@irit.frAbstractModeling user preferences is crucial in manyreal-life problems, ranging from individualand collective decision-making to strategic in-teractions between agents and game theory.Since agents do not come with their prefer-ences transparently given in advance, we haveonly two means to determine what they are ifwe wish to exploit them in reasoning: we caninfer them from what an agent says or fromhis nonlinguistic actions.
In this paper, we an-alyze how to infer preferences from dialoguemoves in actual conversations that involve bar-gaining or negotiation.
To this end, we pro-pose a new annotation scheme to study howpreferences are linguistically expressed in twodifferent corpus genres.
This paper describesthe annotation methodology and details theinter-annotator agreement study on each cor-pus genre.
Our results show that preferencescan be easily annotated by humans.1 IntroductionModeling user preferences is crucial in many real-life problems, ranging from individual and collec-tive decision-making (Arora and Allenby, 1999)to strategic interactions between agents (Brainov,2000) and game theory (Hausman, 2000).
A web-based recommender system can, for example, helpa user to identify (among an optimal ranking) theproduct item that best fits his preferences (Burke,2000).
Modeling preferences can also help to findsome compromise or consensus between two ormore agents having different goals during a nego-tiation (Meyer and Foo, 2004).Working with preferences involves three subtasks(Brafman and Domshlak, 2009): preference acquisi-tion, which extracts preferences from users, prefer-ence modeling where a model of users?
preferencesis built using a preference representation languageand preference reasoning which aims at computingthe set of optimal outcomes.
We focus in this paperon the first task.Handling preferences is not easy.
First, specifyingan ordering over acceptable outcomes is not trivialespecially when multiple aspects of an outcome mat-ter.
For instance, choosing a new camera to buy maydepend on several criteria (e.g.
battery life, weight,etc.
), hence, ordering even two outcomes (cameras)can be cognitively difficult because of the need toconsider trade-offs and dependencies between thecriteria.
Second, users often lack complete infor-mation about preferences initially.
They build apartial description of agents?
preferences that typi-cally changes over time.
Indeed, users often learnabout the domain, each others?
preferences and eventheir own preferences during a decision-making pro-cess.
Since agents don?t come with their preferencestransparently given in advance, we have only twomeans to determine what they are if we wish to ex-ploit them in reasoning: we can infer them fromwhat an agent says or from his nonlinguistic actions.In this paper, we analyze how to infer preferencesfrom dialogue moves in actual conversations that in-volve bargaining or negotiation.Within the Artificial Intelligence community,preference acquisition from nonlinguistic actionshas been performed using a variety of specifictasks, including preference learning (Fu?rnkranz and105Hu?llermeier, 2011) and preference elicitation meth-ods (Chen and Pu, 2004) (such as query learning(Blum et al, 2004), collaborative filtering (Su andKhoshgoftaar, 2009) and qualitative graphical rep-resentation of preferences (Boutilier et al, 1997)).However, these tasks don?t occur in actual conver-sations about negotiation.
We are interested in howagents learn about preferences from actual conver-sational turns in real dialogue (Edwards and Barron,1994), using NLP techniques.To this end, we propose a new annotation schemeto study how preferences are linguistically expressedin dialogues.
The annotation study is performedon two different corpus genres: the Verbmobil cor-pus (Wahlster, 2000) and a booking corpus, builtby ourselves.
This paper describes the annotationmethodology and details the inter-annotator agree-ment study on each corpus genre.
Our results showthat preferences can be easily annotated by humans.2 Background2.1 What are preferences?A preference is commonly understood as an order-ing by an agent over outcomes, which are under-stood as actions that the agent can perform or goalstates that are the direct result of an action of theagent.
For instance, an agent?s preferences may bedefined over actions like buy a new car or by its endresult like have a new car.
The outcomes over whicha preference is defined will depend on the domain ortask.Among these outcomes, some are acceptable forthe agent, i.e.
the agent is ready to act in such away as to realize them, and some outcomes are not.Among the acceptable outcomes, the agent will typ-ically prefer some to others.
Our aim is not to de-termine the most preferred outcome of an agent butfollows rather the evolution of their commitments tocertain preferences as the dialogue proceeds.
To givean example, if an agent proposes to meet on a certainday X and at a certain time Y, we learn that amongthe agent?s acceptable outcomes is a meeting on Xat Y, even if this is not his most preferred outcome.We are interested in an ordinal definition of prefer-ences, which consists in imposing a ranking over all(relevant) possible outcomes and not a cardinal defi-nition which is based on numerical values that allowcomparisons.More formally, let ?
be a set of possibleoutcomes.
A preference relation, written , is areflexive and transitive binary relation over elementsof ?.
The preference orderings are not necessarilycomplete, since some candidates may not be com-parable by a given agent.
Given the two outcomeso1 and o2, o1  o2 means that outcome o1 is equallyor more preferred to the decision maker than o2.Strict preference o1  o2 holds iff o1  o2 and noto2  o1.
The associated indifference relation iso1 ?
o2 if o1  o2 and o2  o1.2.2 Preferences vs. opinionsIt is important to distinguish preferences from opin-ions.
While opinions are defined as a point of view, abelief, a sentiment or a judgment that an agent mayhave about an object or a person, preferences, aswe have defined them, involve an ordering on be-half of an agent and thus are relational and com-parative.
Hence, opinions concern absolute judg-ments towards objects or persons (positive, negativeor neutral), while preferences concern relative judg-ments towards actions (preferring them or not overothers).
The following examples illustrate this:(a) The movie is not bad.
(b) The scenario of the first season is better than thesecond one.
(c) I would like to go to the cinema.
Let?s go and seeMadagascar 2.
(a) expresses a direct positive opinion towards themovie but we do not know if this movie is the mostpreferred.
(b) expresses a comparative opinion be-tween two movies with respect to their shared fea-tures (scenarios) (Ganapathibhotla and Liu, 2008).If actions involving these movies (e.g.
seeing them)are clear in the context, such a comparative opin-ion will imply a preference, ordering the first seasonscenario over the second.
Finally, (c) expresses twopreferences, one depending on the other.
The firstis that the speaker prefers to go to the cinema overother alternative actions; the second is, given thatpreference, that he wants to see Madagascar 2 overother possible movies.Reasoning about preferences is also distinct fromreasoning about opinions.
An agent?s preferences106determine an order over outcomes that predicts howthe agent, if he is rational, will act.
This is not truefor opinions.
Opinions have at best an indirect linkto action: I may hate what I?m doing, but do it any-way because I prefer that outcome to any of the al-ternatives.3 DataOur data come from two corpora: one already-existing, Verbmobil (CV ), and one that we cre-ated, Booking (CB).The first corpus is composed of 35 dialogues ran-domly chosen from the existing corpus Verbmobil(Wahlster, 2000), where two agents discuss on whenand where to set up a meeting.
Here is a typical frag-ment:pi1 A: Shall we meet sometime in the next week?pi2 A: What days are good for you?pi3 B: I have some free time on almost every dayexcept Fridays.pi4 B: Fridays are bad.pi5 B: In fact, I?m busy on Thursday too.pi6 A: Next week I am out of town Tuesday, Wednes-day and Thursday.pi7 A: So perhaps Monday?The second corpus was built from various En-glish language learning resources, available on theWeb (e.g., www.bbc.co.uk/worldservice/learningenglish).
It contains 21 randomly se-lected dialogues, in which one agent (the customer)calls a service to book a room, a flight, a taxi, etc.Here is a typical fragment:pi1 A: Northwind Airways, good morning.
May Ihelp you?pi2 B: Yes, do you have any flights to Sydney nextTuesday?pi3 A: Yes, there?s a flight at 16:45 and one at 18:00.pi4 A: Economy, business class or first class ticket?pi5 B: Economy, please.Our approach to preference acquisition exploitsdiscourse structure and aims to study the impactof discourse for extracting and reasoning on prefer-ences.
Cadilhac et al (2011) show how to computeautomatically preference representations for a wholestretch of dialogue from the preference representa-tions for elementary discourse units.
Our annota-tion here concentrates on the commitments to pref-erences expressed in elementary discourse units orEDUs.
We analyze how the outcomes and the depen-dencies between them are linguistically expressedby performing, on each corpus, a two-level anno-tation.
First, we perform a segmentation of the di-alogue into EDUs.
Second, we annotate preferencesexpressed by the EDUs.The examples above show the effects of segmen-tation.
Each EDU is associated with a label pii.For Verbmobil, we rely on the already avail-able discourse annotation of Baldridge and Las-carides (2005).
For Booking, the segmentationwas made by consensus.We detail, in the next section, our preference an-notation scheme.4 Preference annotation schemeTo analyze how preferences are linguistically ex-pressed in each EDU, we must: (1) identify the set?
of outcomes, on which the agent?s preferencesare expressed, and (2) identify the dependencies be-tween the elements of ?
by using a set of specificoperators, i.e.
identifying the agent?s preferences onthe stated outcomes.
Consider the segment ?Let?smeet Thursday or Friday?.
We have ?
= {meetThursday, meet Friday} where outcomes are linkedby a disjunction that means the agent is ready to actfor one of these outcomes, preferring them equally.Within an EDU, preferences can be expressed indifferent ways.
They can be atomic preference state-ments or complex preference statements.4.1 Atomic preferencesAtomic preference statements are of the form ?I pre-fer X?, ?Let?s X?, or ?We need X?, where X de-scribes an outcome.
X may be a definite noun phrase(?Monday?, ?next week?, ?almost every day?
), aprepositional phrase (?at my office?)
or a verbphrase (?to meet?).
They can be expressed withincomparatives and/or superlatives (?a cheaper room?or ?the cheapest flight?
).Preferences can also be expressed in an indirectway using questions.
Although not all questionsentail that their author commits to a preference, inmany cases they do.
That is, if A asks ?can we meetnext week??
he implicates a preference for meeting.For negative and wh-interrogatives, the implication107is even stronger.
Expressions of sentiment or polite-ness can also be used to indirectly introduce prefer-ences.
In Booking, the segment ?economy please?indicates the agent?s preference to be in an economyclass.EDUs can also express preferences via free-choicemodalities; ?I am free on Thursday?
or ?I can meeton Thursday?
tells us that Thursday is a possible dayto meet, it is an acceptable outcome.A negative preference expresses an unacceptableoutcome, i.e.
what the agent does not prefer.
Neg-ative preference can be expressed explicitly withnegation words (?I don?t want to meet on Friday?
)or inferred from the context (?I am busy on Mon-day?
).While the logical form of an atomic preferencestatement is something of the form Pref(X), weabbreviate this in the annotation language, using justthe outcome expression X to denote that the agentprefers X to the alternatives, i.e.
X  X .
If X isan unacceptable outcome, we use the non-booleanoperator not to denote that the agent prefers not X toother alternatives, i.e.
X  X .
In our Verbmobilannotation, X is typically an NP denoting a time orplace; X as an outcome is thus shorthand for meeton X or meet at X .
For Booking, X is short forreserve or book X .4.2 Complex preferencesPreference statements can also be complex, express-ing dependencies between outcomes.
Borrowingfrom the language of conditional preference net-works or CP-nets (Boutilier et al, 2004), we rec-ognize that some preferences may depend on an-other action.
For instance, given that I have cho-sen to eat fish, I will prefer to have white wineover red wine?something which we express aseat fish : drink white wine  drink red wine.Among the possible combinations, we find con-junctions, disjunctions and conditionals.
We exam-ine these conjunctive, disjunctive and conditionaloperations over outcomes and suppose a languagewith non-boolean operators &,5 and 7?
taking out-come expressions as arguments.With conjunctions of preferences, as in ?CouldI have a breakfast and a vegetarian meal??
or in?Mondays and Fridays are not good?
?, the agent ex-presses two preferences (respectively over the ac-ceptable outcomes breakfast and vegetarian mealand the non acceptable outcomes not Mondays andnot Fridays) that he wants to satisfy and he prefersto have one of them if he can not have both.
Henceo1 & o2 means o1  o1 and o2  o2.The semantics of a disjunctive preference is a freechoice one.
For example in ?either Monday or Tues-day is fine for me?
or in ?I am free Monday andTuesday?, the agent states that either Monday orTuesday is an acceptable outcome and he is indif-ferent between the choice of the outcomes.
Henceo1 5 o2 means o2 : o1 ?
o1, o2 : o1  o1 ando1 : o2 ?
o2, o1 : o2  o2.Finally, some EDUs express conditional amongpreferences.
For example, in the sentence ?Whatabout Monday, in the afternoon?
?, there are twopreferences: one for the day Monday, and, given theMonday preference, one for the time afternoon (ofMonday), at least for one syntactic reading of theutterance.
Hence o1 7?
o2 means o1  o1 ando1 : o2  o2.For each EDU, annotators identify how outcomesare expressed and then indicate if the outcomes areacceptable, or not, using the operator not and howthe preferences on these outcomes are linked usingthe operators &,5 and 7?.4.3 ExampleWe give below an example of how some EDUs areannotated.
<o> i indicates that o is the outcomenumber i in the EDU, the symbol // is used to sepa-rate the two annotation levels and brackets indicatehow outcomes are attached.pi1 : <Tuesday the sixteenth> 1 I got class<from nineto twelve> 2?
// 1 7?
not 2pi2 : What about <Friday afternoon> 1, <at twothirty> 2 or <three> 3, // 1 7?
(25 3)pi3 : <The room with balcony> 1 should be equipped<with a queen size bed> 2, <the other one> 3<with twin beds> 4, please.
// (1 7?
2) & (3 7?4)In pi1, the annotation tells us that we have two out-comes and that the agent prefers outcome 1 over anyother alternatives and given that, he does not pre-fer outcome 2.
In pi2, the annotation tells us thatthe agent prefers to have one of outcome 2 and out-come 3 satisfied given that he prefers outcome 1.
Inthis example, the free choice between outcome 2 and108outcome 3 is lexicalized by the coordinating con-junction ?or?.
On the contrary, pi3 is a more complexexample where there is no discursive marker to findthat the preference operator between the couples ofoutcomes 1 and 2 on one hand, and 3 and 4 on theother hand, is the conjunctive operator &.5 Inter-annotator agreementsOur two corpora (Verbmobil and Booking)were annotated by two annotators using the pre-viously described annotation scheme.
We per-formed an intermediate analysis of agreement anddisagreement between the two annotators on twoVerbmobil dialogues.
Annotators were thustrained only for Verbmobil.
The aim is to study towhat extent our annotation scheme is genre depen-dent.
The training allowed each annotator to under-stand the reason of some annotation choices.
Afterthis step, the dialogues of our corpora have been an-notated separately, discarding those two dialogues.Table 1 presents some statistics about the annotateddata in the gold standard.CV CBNo.
of dialogues 35 21No.
of outcomes 1081 275No.
of EDUs with outcomes 776 182% with 1 outcome 71% 70%% with 2 outcomes 22% 19%% with 3 or more outcomes 8% 11%No.
of unacceptable outcomes (not) 266 9No.
of conjunctions (&) 56 31No.
of disjunctions (5) 75 29No.
of conditionals (7?)
184 37Table 1: Statistics for the two corpora.We compute four inter-annotator agreements: onoutcome identification, on outcome acceptance, onoutcome attachment and finally on operator identifi-cation.
Table 2 summarizes our results.5.1 Agreements on outcome identificationTwo inter-annotator agreements were computed us-ing Cohen?s Kappa.
One based on an exact matchingbetween two outcome annotations (i.e.
their corre-sponding text spans), and the other based on a le-CV CBOutcome identification (Kappa) exact : 0.66lenient : 0.85Outcome acceptance (Kappa) 0.90 0.95Outcome attachment (F-measure) 93% 82%Operator identification (Kappa) 0.93 0.75Table 2: Inter-annotator agreements for the two corpora.nient match between annotations (i.e.
there is anoverlap between their text spans as in ?2p.m?
and?around 2p.m?).
This approach is similar to the oneused by Wiebe, Wilson and Cardie (2005) to com-pute agreement when annotating opinions in newscorpora.
We obtained an exact agreement of 0.66and a lenient agreement of 0.85 for both corpus gen-res.We made the gold standard after discussing casesof disagreement.
We observed four cases.
The firstone concerns redundant preferences which we de-cided not to keep in the gold standard.
In such cases,the second EDU pi2 does not introduce a new prefer-ence, neither does it correct the preferences stated inpi1; rather, the agent just wants to insist by repeat-ing already stated preferences, as in the followingexample:pi1 A: Thursday, Friday, and Saturday I am out.pi2 A: So those days are all out for me,The second case of disagreement comes fromanaphora which are often used to introduce new, tomake more precise or to accept preferences.
Hence,we decided to annotate them in the gold standard.Here is an example:pi1 A: One p.m. on the seventeenth?pi2 B: That sounds fantastic.The third case of disagreement concerns prefer-ence explanation.
We chose not to annotate theseexpressions in the gold standard because they areused to explain already stated preferences.
In thefollowing example, one judge annotated ?from nineto twelve?
to be expressions of preferences while theother did not :pi1 A: Monday is really not good,pi2 A: I have got class from nine to twelve.109Finally, the last case of disagreement comes frompreferences that are not directly related to the actionof fixing a date to meet but to other actions, such ashaving lunch, choosing a place to meet, etc.
Eventhough those preferences were often missed by an-notators, we decided to keep them, when relevant.5.2 Agreements on outcome acceptanceThe aim here is to compute the agreement on the notoperator, that is if an outcome is acceptable, as in?<Mondays> 1 are good // 1?, or unacceptable, asin ?<Mondays> 1 are not good // not 1?.
We get aCohen?s Kappa of 0.9 for Verbmobil and 0.95 forBooking.
The main case of disagreement concernsanaphoric negations that are inferred from the con-text, as in pi2 below where annotators sometimes failto consider ?in the morning?
as unacceptable out-comes:pi1 A: Tuesday is kind of out,pi2 A: Same reason in the morningSame case of disagreement in this example where?Monday?
is an unacceptable outcome:pi1 well, I am, busy <in the afternoon of the twentysixth> 1, // not 1pi2 that is <Monday> 1 // not 15.3 Agreements on outcome attachmentSince this task involves structure building, we com-pute the agreement using the F-score measure.
Theagreement was computed on the previously builtgold standard once annotators discussed cases ofoutcome identification disagreements.
We comparehow each outcome is attached to the others withinthe same EDU.
This agreement concerns EDUsthat contain at least three outcomes, that is 8% ofEDUs from Verbmobil and 11% of EDUs fromBooking.
When comparing annotations for the ex-ample pi1 below, there is three errors, one for out-come 2, one for 3 and one for 4.pi1 <for the next week> 1 the only days I haveopen are <Monday> 2 or <Tuesday> 3 <in themorning> 4.?
Annotation 1 : 1 7?
(25 (3 7?
4))?
Annotation 2 : 1 7?
((25 3) 7?
4)We obtain an agreement of 93% for Verbmobiland 82% for Booking.5.4 Agreements on outcome dependenciesFinally, we compute the agreements for each coupleof outcomes on which annotators agreed about howthey are attached.In Verbmobil, the most frequently used binaryoperator is 7?.
Because the main purpose of theagents in this corpus is to schedule an appointment,the preferences expressed by the agents are mainlyfocused on concepts of time and there are many con-ditional preferences since it is common that prefer-ences on specific concepts depend on more broadtemporal concepts.
For example, preferences onhours are generally conditional on preferences ondays.
In Booking, there are almost as many & as7?
because independent and dependent preferencesare more balanced in this corpus.
The agents dis-cuss preferences about various criteria that are in-dependent.
For example, to book a hotel, the agentexpress his preferences towards the size of the bed(single or double), the quality of the room (smokeror nonsmoker), the presence of certain conveniences(TV, bathtub), the possibility to have breakfast inhis room, etc.
Within an EDU, such preferences areoften expressed in different sentences (compared toVerbmobil where segments?
lengths are smaller)which lead annotators to link those preferences withthe operator &.
Conditionals between preferenceshold when decision criteria are dependent.
For ex-ample, the preference for having a vegetarian mealis conditional on the preference for having lunch.There also are conditionals between temporal con-cepts, for example, to choose the time of a flight.Table 3 shows the Kappa for each operator oneach corpus genre.
The Cohen?s Kappa, averagedover all the operators, is 0.93 for Verbmobil and0.75 for Booking.
We observe two main cases ofdisagreement: between 5 and &, and between &and 7?.
These cases are more frequent for Bookingmainly because annotators were not trained on thiscorpus.
This is why the Kappa was lower than forVerbmobil.
We discuss below the main two casesof disagreement.Confusion between 5 and &.
The same lin-guistic realizations do not always lead to the sameoperator.
For instance, in ?<Monday> 1 and<Wednesday> 2 are good?
we have 15 2 whereasin ?<Monday> 1 and <Wednesday> 2 are not110CV CB& 0.90 0.665 0.97 0.897?
0.92 0.71Table 3: Agreements on binary operators.good?
or in ?I would like a <single room> 1 anda <taxi> 2?
we have respectively not 1 & not 2and 1 & 2.The coordinating conjunction ?or?
is a strong pre-dictor for recognizing a disjunction of preferences,at least when the ?or?
is clearly outside of the scopeof a negation1, as in the examples below (in pi1, thenegation is part of the wh-question, and not booleanover the preference):pi1 Why don?t we <meet, either Thursday the first> 1,or <Thursday the eighth> 2 // 15 2pi2 Would you like <a single> 1 or <a double> 2?
//15 2The coordinating conjunction ?and?
is also astrong indication, especially when it is used to linktwo acceptable outcomes that are both of a singletype (e.g., day of the week, time of day, place,type of room, etc.)
between which an agent wantsto choose a single realization.
For example, inVerbmobil, agents want to fix a single appoint-ment so if there is a conjunction ?and?
between twotemporal concepts of the same level, it is a disjunc-tion of preference (see pi3 below).
It is also the casein Booking when an agent wants to book a singleplane flight (see pi4).pi3 <Monday> 1 and <Tuesday> 2 are good for me// 15 2pi4 You could <travel at 10am.> 1, <noon> 2 and<2pm> 3 // 15 (25 3)The acceptability modality distributes acrossthe conjoined NPs to deliver something like3(meet Monday) ?
3(meet Tuesday) in modallogic (clearly acceptability is an existentialrather than universal modality), and as isknown from studies of free choice modality1When there is a propositional negation over the disjunctionas in ?I don?t want sheep or wheat?, which occurs frequentlyin a corpus in preparation, we no longer have a disjunction ofpreferences.
(Schulz, 2007), such a conjunction translates to3(meet Monday ?
meet Tuesday), which ex-presses our free choice disjunction of preferences,o1 5 o2.On the other hand, when the conjunction ?and?links two outcomes referring to a single conceptthat are not acceptable, it gives a conjunction ofpreferences, as in pi5.
Once again thinking interms of modality is helpful.
The ?not accept-able?
modality distributes across the conjunction,this gives something like 2?o1 ?
2?o2 (where ?is truth conditional negation) which is equivalent to2(?o1 ?
?o2), i.e.
not o1 & not o2 and not equiv-alent to 2(?o1 ?
?o2), i.e.
not o1 5 not o2.The connector ?and?
also involves a conjunctionof preferences when it links two independent out-comes that the agent wants to satisfy simultaneously.For example, in pi6, the agent wants to book two ho-tel rooms, and so the outcomes are independent.
Inpi7, the agent expresses his preferences on two differ-ent features he wants for the hotel room he is book-ing.pi5 <Thursday the thirtieth> 1, and <Wednesday thetwenty ninth> 2 are, booked up // not 1 & not 2pi6 Can I have one room< with balcony> 1 and <onewithout balcony> 2?
// 1 & 2pi7 <Queen> 1 and <nonsmoking> 2 // 1 & 2Confusion between & and 7?.
In this case, dis-agreements are mainly due to the difficulty for an-notators to decide if preferences are dependent, ornot.
For example, in ?I have a meeting <startingat three> 1, but I could meet <at one o?clock> 2?,one annotator put not 1 7?
2 meaning that theagent is ready to meet at one o?clock because hecan not meet at three, while the other annotatednot 1 & 2 meaning that the agent is ready to meetat one o?clock independently of what it will do atthree.Some connectors introduce contrast between thepreferences expressed in a segment as ?but?,?although?
and ?unless?.
In the annotation, we canmodel it thanks to the operator 7?.
When it is usedbetween two conflicting values, it represents a cor-rection.
Thus, the annotation o1 7?
not o1 means weneed to replace in our model of preferences o1  o1by o1  o1.
And vice versa for not o1 7?
o1.pi8 I have class <on Monday> 1, but, <any time, afterone or two> 2 I am free.
// not 1 7?
(1 7?
2)111pi9 <Friday> 1 is a little full, although there is somepossibility, <before lunch> 2 // not 1 7?
(1 7?
2)pi10 we?re full <on the 22nd> 1, unless you want <asmoking room> 2 // not 1 7?
(1 7?
2)However, it is important to note that the coordi-nating conjunction ?but?
does not always introducecontrast, as in the example below, where it intro-duces a conjunction of preferences.pi11 I am busy <on Monday> 1, but <Tuesdayafternoon> 2, sounds good // not 1 & 2The subordinating conjunctions ?if?, ?because?and ?so?
are indications for detecting conditionalpreferences.
The preferences in the main clause de-pend on the preferences in the subordinate clause(if-clause, because-clause, so-clause), as in the ex-amples below.pi12 so if we are going to be able to meet <that, lastweek in January> 1, it is going have to be <the,twenty fifth> 2 // 1 7?
2pi13 <the twenty eighth> 1 I am free, <all day> 2, ifyou want to go for <a Sunday meeting> 3 // 3 7?
(2 7?
1)pi14 it is going to have to be <Wednesday the third> 1because, I am busy <Tuesday> 2 // not 2 7?
1pi15 I have a meeting <from eleven to one> 1, sowe could, meet <in the morning from nine toeleven> 2, or,<in the afternoon after one> 3 // not1 7?
(25 3)Whether or not there are some discursive markersbetween two outcomes, to find the appropriate oper-ator, we need to answer some questions : does theagent want to satisfy the two outcomes at the sametime ?
Are the preferences on the outcomes depen-dent or independent ?We have shown in this section that it is difficult toanswer the second question and there is quite someambiguity between the operators & et 7?.
This am-biguity can be explained by the fact that both opera-tors model the same optimal preference.
Indeed, wesaw in section 4.2 that for two outcomes o1 and o2linked by a conjunction of preferences (o1 & o2), wehave o1  o1 and o2  o2.
For two outcomes o1 ando2 where o2 is linked to o1 by a conditional prefer-ence (o1 7?
o2), we have o1  o1 and o1 : o2  o2.In both cases, the best possible world for the agentis the one where o1 and o2 are both satisfied at thesame time.6 Conclusion and Future WorkIn this paper, we proposed a linguistic approachto preference aquisition that aims to infer prefer-ences from dialogue moves in actual conversationsthat involve bargaining or negotiation.
We stud-ied how preferences are linguistically expressed inelementary discourse units on two different cor-pus genres: one already available, the Verbmobilcorpus and the Booking corpus purposely builtfor this project.
Annotators were trained only forVerbmobil.
The aim is to study to what extentour annotation scheme is genre dependent.Our preference annotation scheme requires twosteps: identify the set of acceptable and non accept-able outcomes on which the agents preferences areexpressed, and then identify the dependencies be-tween these outcomes by using a set of specific non-boolean operators expressing conjunctions, disjunc-tions and conditionals.
The inter-annotator agree-ment study shows good results on each corpus genrefor outcome identification, outcome acceptance andoutcome attachment.
The results for outcome de-pendencies are also good but they are better forVerbmobil.
The difficulties concern the confu-sion between disjunctions and conjunctions mainlybecause the same linguistic realizations do not al-ways lead to the same operator.
In addition, anno-tators often fail to decide if the preferences on theoutcomes are dependent or independent.This work shows that preference acquisition fromlinguistic actions is feasible for humans.
The nextstep is to automate the process of preference extrac-tion using NLP methods.
We plan to do it using anhybrid approach combining both machine learningtechniques (for outcome extraction and outcome ac-ceptance) and rule-based approaches (for outcomeattachment and outcome dependencies).ReferencesNeeraj Arora and Greg M. Allenby.
1999.
Measur-ing the influence of individual preference structuresin group decision making.
Journal of Marketing Re-search, 36:476?487.Jason Baldridge and Alex Lascarides.
2005.
Annotatingdiscourse structures for robust semantic interpretation.In Proceedings of the 6th IWCS.Avrim Blum, Jeffrey Jackson, Tuomas Sandholm, and112Martin Zinkevich.
2004.
Preference elicitation andquery learning.
Journal of Machine Learning Re-search, 5:649?667.Craig Boutilier, Ronen Brafman, Chris Geib, and DavidPoole.
1997.
A constraint-based approach to prefer-ence elicitation and decision making.
In AAAI SpringSymposium on Qualitative Decision Theory, pages 19?28.Craig Boutilier, Craig Brafman, Carmel Domshlak, Hol-ger H. Hoos, and David Poole.
2004.
Cp-nets: A toolfor representing and reasoning with conditional ceterisparibus preference statements.
Journal of Artificial In-telligence Research, 21:135?191.Ronen I. Brafman and Carmel Domshlak.
2009.
Prefer-ence handling - an introductory tutorial.
AI Magazine,30(1):58?86.Sviatoslav Brainov.
2000.
The role and the impact ofpreferences on multiagent interaction.
In Proceedingsof ATAL, pages 349?363.
Springer-Verlag.Robin Burke.
2000.
Knowledge-based recommendersystems.
In Encyclopedia of Library and InformationScience, volume 69, pages 180?200.
Marcel Dekker.Ana?
?s Cadilhac, Nicholas Asher, Farah Benamara, andAlex Lascarides.
2011.
Commitments to preferencesin dialogue.
In Proceedings of SIGDIAL, pages 204?215.
ACL.Li Chen and Pearl Pu.
2004.
Survey of preference elici-tation methods.
Technical report.Ward Edwards and F. Hutton Barron.
1994.
Smartsand smarter: Improved simple methods for multiat-tribute utility measurement.
Organizational Behaviorand Human Decision Processes, 60(3):306?325.Johannes Fu?rnkranz and Eyke Hu?llermeier, editors.2011.
Preference Learning.
Springer.Murthy Ganapathibhotla and Bing Liu.
2008.
Miningopinions in comparative sentences.
In Proceedings ofthe 22nd International Conference on ComputationalLinguistics - Volume 1, COLING ?08, pages 241?248,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.Daniel M. Hausman.
2000.
Revealed preference, be-lief, and game theory.
Economics and Philosophy,16(01):99?115.Thomas Meyer and Norman Foo.
2004.
Logical founda-tions of negotiation: Strategies and preferences.
In InProceedings of the Ninth International Conference onPrinciples of Knowledge Representation and Reason-ing (KR04, pages 311?318.Katrin Schulz.
2007.
Minimal Models in Semantics andPragmatics: Free Choice, Exhaustivity, and Condi-tionals.
PhD thesis, ILLC.Xiaoyuan Su and Taghi M. Khoshgoftaar.
2009.
A sur-vey of collaborative filtering techniques.
Advances inArtificial Intelligence, 2009:1?20.Wolfgang Wahlster, editor.
2000.
Verbmobil: Founda-tions of Speech-to-Speech Translation.
Springer.Janyce Wiebe, Theresa Wilson, and Claire Cardie.
2005.Annotating expressions of opinions and emotions inlanguage.
Language Resources and Evaluation, 39(2-3):165?210.113
