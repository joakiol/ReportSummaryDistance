Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 10?19,Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational LinguisticsAn End-to-End Evaluation of Two Situated Dialog SystemsLina M. Rojas-BarahonaInria, LORIA, UMR 7503Villers-le`s-NancyF-54600, Francelina.rojas@loria.frAlejandra LorenzoUniversite?
de LorraineLORIA, UMR 7503Vandoeuvre-le`s-NancyF-54500, Francealejandra.lorenzo@loria.frClaire GardentCNRS, LORIA, UMR 7503Vandoeuvre-le`s-NancyF-54500, Franceclaire.gardent@loria.frAbstractWe present and evaluate two state-of-the artdialogue systems developed to support dialogwith French speaking virtual characters in thecontext of a serious game: one hybrid statis-tical/symbolic and one purely statistical.
Weconducted a quantitative evaluation where wecompare the accuracy of the interpreter andof the dialog manager used by each system; auser based evaluation based on 22 subjects us-ing both the statistical and the hybrid system;and a corpus based evaluation where we exam-ine such criteria as dialog coherence, dialogsuccess, interpretation and generation errors inthe corpus of Human-System interactions col-lected during the user-based evaluation.
Weshow that although the statistical approach isslightly more robust, the hybrid strategy seemsto be better at guiding the player through thegame.1 IntroductionIn recent years, there has been much research on cre-ating situated conversational characters i.e., virtualcharacters (VCs) that look and act like humans butinhabit a virtual environment (Gratch et al, 2002;Hofs et al, 2010; Traum et al, 2007; Johnson et al,2005; Traum et al, 2008; DeVault et al, 2011).In this paper, we focus on French speaking, situ-ated conversational agents who interact with virtualcharacters in the context of a serious game designedto promote careers in the plastic industry (The Mis-sion Plastechnologie game or MP).
We present andcompare two state-of-the art dialogue systems.
Thefirst system (H) is a hybrid approach that com-bines an information-state dialogue manager (Lars-son and Traum, 2000) with a classifier for interpret-ing the players?
phrases.
The second system (QA)is a question/answering character model which pre-dicts the system dialog move given a player?s ut-terance (Leuski and Traum, 2008).
Both systemsuse a generation-by-selection strategy (Leuski et al,2006; Gandhe and Traum, 2007) where the system?sutterances are selected from a corpus of possibleoutputs based on the dialog manager output.
Whileprevious work focuses on relatively short dialogs ina static setting, in our systems we consider long in-teractions in which dialogs occur in a setting thatdynamically evolves as the game unfolds.We evaluate the two dialog systems in the con-text of the 3D game they were developed for andseek to determine the degree to which a dialog sys-tem is operational.
To answer this question, we anal-yse both systems with respect not only to quantita-tive metrics such as accuracy but also to user- andcorpus-based metrics.
User-based metrics are com-puted based on a questionnaire the users filled in;while corpus-based metrics are manually extractedfrom the corpus of Player-VC interactions collectedduring the user-based evaluation.
As suggested byevaluation frameworks such as PARADISE (Walkeret al, 1997) and SASSI (Hone and Graham, 2000),we show that a multiview evaluation permits a betterassessment of how well the dialog system functions?in the real world?.
The metrics proposed assess di-alog success and coherence, as well the costs of dia-log components.The paper is organized as follows.
In Section 2,10we present the MP game, the dialogue strategiesused in the different dialogs and the dialog data usedfor training.
Section 3 presents the two dialog sys-tems we compare.
Section 4 presents the evaluationschemes used to compare these two systems and dis-cusses the results obtained.
Section 5 concludes withdirections for further research.2 Dialogues in the MP GameWe begin by describing the MP game, the dialogs inthe MP game, the strategies used to guide the hybriddialog manager and the data used for training.2.1 The MP Game and DialogsThe MP game is a multi-player quest where 3teenagers seek to build a joystick in order to freetheir uncle trapped in a video game 1.
To buildthis joystick, the player (who alternatively repre-sents anyone of these three teenagers) must explorethe plastic factory and achieve 17 mandatory goals(find the plans, get the appropriate mould, retrievesome plastic from the storing shed, etc), as wellas 11 optional goals which, when reached, providethem with extra information about the plastic indus-try (and therefore increases their knowledge of it).In total, the player can achieve up to 28 gamegoals by conducting 12 separate dialogs in variousparts of the virtual world.
Each of the 12 dialogsin the MP game helps players to achieve the gamegoals.
The player interacts with the virtual charac-ters to obtain information that helps her to achievethese goals and, as a consequence, to increase herscore in the game.
Table 1 summarises the gamegoals and the contextual parameters (player?s role,location in the virtual world, VCs present) associ-ated with each dialog.2.2 Dialog Data and AnnotationTo train both classifiers, the one used by the hybridand the one used by the QA system, we collectedHuman-Machine dialog data using a Wizard-of-Ozsetting and manually annotated each turn with a di-alog move.
The resulting corpus (called EmospeechCorpus) and the annotation scheme (as well as theinter-annotator agreement) used are described in de-1The MP game was created by Artefacto, http://www.artefacto.fr/index_ok.htmtail (Rojas-Barahona et al, 2012).
Briefly, the Emo-speech Corpus comprises 1249 dialogs, 10454 utter-ances and 168509 words.
It contains 3609 player ut-terances consisting of 31613 word tokens and 2969word types, with approximately 100 conversationsfor each dialog in the game.
Turns were annotatedwith dialog moves (Traum and Larsson, 2003) cap-turing both domain knowledge (e.g., about the goalsset by the game) and the set of core communicativeacts.2.3 Dialog StrategiesWe identified four main dialog strategies underlyingthe 12 MP dialogs and used these to define the plansguiding the rule-based discourse management in thehybrid system.
These strategies can be seen as trans-actions made up of conversational games (Carletta etal., 1997).Strategy 1.
This strategy is used in the first di-alog only and consists of a single Address Requestmove by the VC followed by the player?s answer:Lucas requests Ben to find the address of the Plas-tic Enterprise that must be hidden somewhere in thelab.
Ben can accept, reject or ask for help.
Lucasanswers accordingly and ends the conversation.Strategy 2.
Nine dialogues follow this strategy.They include several (up to 5) requests for infor-mation and the corresponding system/player?s ex-change.
Appendix A shows an example dialog fol-lowing this strategy.Strategy 3: This is a confirmation strategy wherethe VC first checks that the player has alreadyachieved a given task, before informing her aboutthe next step (e.g.
dialogs with Melissa in Table 1).Strategy 4.
This strategy, exemplified in Ap-pendix B, is similar to strategy 2 but additionallyincludes a negotiation step where the VC asks theplayer for help.3 Dialogue SystemsThe game and the two dialog systems built were in-tegrated as agents within the Open Agent Architec-ture as shown in Figure 1.
Both systems access adatabase for starting the appropriate dialogs at theappropriate place in the virtual world while simulta-neously storing all interactions in the database.11Id VC Player Goals Location1 Lucas Ben Find the address of the enterprise.
Uncle?s place.2 M.Jasper Lucas The manufacturing first step Enterprise reception3 Samir Julie Find the plans of the joystick Designing OfficeOptional: job, staff, studies, security policies4 Samir Julie Find out what to do next Designing OfficeOptional: jobs in the enterprise, staff in the enterprise5 Melissa Lucas Find the mould, optional where are the moulds Plant6 Melissa Lucas Find the right machine Plant7 Melissa Lucas Confirm you have found the right mould and machine and Plantfind out what to do next8 Operator Julie Knowing about the material space and about the job Material SpaceOptional: find out what to do in the case of failurehelping to feed a machine with the right material9 Serge Ben Perform quality tests.
Laboratory TestsOptional: VC?s job10 Serge Ben Find out what to do next.
Laboratory TestsOptional: know what happens with broken items11 Sophia Julie Find the electronic components, knowing about VC?s job Finishing12 Sophia Lucas Finishing process FinishingOptional: know about conditioning the productTable 1: Description of the 12 dialogs in the MP Game.Figure 1: General Architecture for the dialog system:modules are implemented as agents within the OpenAgent Architecture.3.1 The Hybrid Dialogue SystemThe hybrid system combines an interpreter; a rulebased, Information State Approach dialog manager;a generator; and the game/dialog communicationcomponents i.e., the OAA interface.The Interpreter Module In the hybrid system,the interpreter is a classifier trained on the anno-tated data (cf.
section 2.2), which maps the player?sutterance to a dialog move.
To build the classi-fier we experimented with both SVM (Support Vec-tor Machine) and LR (Logistic Regression) 2 us-ing different sets of features: utterances were pre-processed by removing stop words and convertingcontent words to unaccented lowercase.
Afterwards,we experiment with and without TF*IDF (term fre-quency*Inverse Document Frequency) filtering andcontext moves (from 0 to 4 previous dialog moves).Since the game consist of a number of differentdialogs, two options naturally arise: we could eithertrain a single classifier on the whole dataset or trainone classifier per dialog.
Hence the data sets (and thenumber of categories to be learned) differ dependingon whether we trained one classifier on the wholegame data or a classifier for each dialog.In addition, hand-written rules are used to correctmisclassification errors as follows.
The best predic-tion given by the classifier is matched against theexpected move determined by the last move storedin the information-state (see below the descriptionof the dialog manager).
In case of a mismatch, theinterpreter selects a move that is valid in the currentcontext and updates the information state with thismove.
For instance, if the last move is a yes/no ques-tion, confirm and disconfirm dialog acts are validmoves; for propositional questions, Goali is a valid2We used LIBSVM (Chang and Lin, 2001) and MALLET(McCallum, 2002) for the LR classifier with L1 Regularisation.12dialog move 3; etc.
Since the process is non deter-ministic, this re-interpretation process may improvethe system response but it may also be incorrect.
Forinstance, in the following example re-interpretationcorrectly overrides the dialog move output by theclassifier to a move asking the VC (Samir) for thenext goal to be achieved.Samir: Vous avez d?autres questions pour moi?Do you have other questions ?Julie: comment cela fonctionne ?How does it work?Samir: Eh bien , il va falloir la fabriquer maintenant cettemanette .
Allez voir Me?lissa.Well, you have to build the joystick now.
Go to see Melissa.In contrast, the dialog below shows a case wherere-interpretation fails.
Instead of re-interpreting theplayer?s (Julie) input as a request for the next goal,it outputs a request for information about the staffthereby yielding an incoherent exchange.Samir: D?
autres questions ?Other questions?Julie: oui qu?est-ce que je peux faire avec ces bouts de papier ?yes, what can I do with these pieces of paper ?Samir: Et bien sachez qu?il y a de plus en plus des femmes danscette industrie ...you should know there are more and more women in this indus-try ...The DialogManager We designed a plan for eachdialog strategy and extended Midiki (Burke et al,2003) to support the OAA architecture and accessthe relational database specifying the configurationsof the different dialogs in the game.
Each time a newdialog is launched, the information state is loadedwith the corresponding dialog-context (e.g., speak-ers, list of goals to be discussed) and the plan mod-eling the corresponding dialog strategy.
To supportdialog management, we implemented a set of updateand selection rules for integrating players?
moves,handling the information-state and for preparing theagenda according to the plan.
More specifically, thefollowing rules are executed at runtime: Integration:integrates dialog moves (e.g., questions, answers,acknowledgments) in the information state (ques-tions are listed in the Question Under Discussion,3The system asks the player for the goal to be discussed:ask(task(X)) and the player answers one goal in the situateddialog: Goali.answers change the Commond Ground, player an-swers are integrated in response to VCs questions).Manage Plan: searches the next action in the plan.Refill Agenda: updates the agenda with the next ac-tion and Selection: selects the next dialog move ac-cording to the plan.
Once the system move has beenselected, the Generator searches an appropriate ver-balisation.The Generator As mentioned above, the gener-ator implements a generation-by-selection strategy.Given the dialog move output by the dialog man-ager, the generator selects any utterance in this cor-pus that is labeled with this dialog move and withthe identifier of the current dialog.In addition, two types of dialog moves aregiven special treatment.
The first two moves ofeach dialog are systematically constrained to bea welcome greeting followed by either a requestto pursue a goal (ask(Goali) or a proposalto help (ask(task(X))).
Furthermore, proposi-tional questions (i.e., proposals by the system todiscuss additional topics) were annotated separatelywith their respective dialog goals.
For example,Samir?s sentence: Are you interested in hearingabout my job, the people that work here or the se-curity policies?, was annotated with the goals: job,staff and security policies.
For these dialog acts, thegenerator checks the list of current missing goals soas to retrieve an appropriate propositional question.In this way, the system can coherently direct theplayer by suggesting possible topics without usingvague and repetitive sentences such as Would youlike to know more?.3.2 The QA SystemThe QA system combines a classifier that matchesplayers?
turns to system dialog moves with the samegeneration-by-selection algorithm used in the hybridsystem.
Like the hybrid system, the QA dialog sys-tem maintains a constant interaction with the gameto allow for the game coherence and continuity.
Inparticular, at the end of each dialog, the game goalsthat have been reached through the dialog are re-turned to the game server so that the game can pro-ceed and be updated with the appropriate score.For the QA system, we trained a Logistic Re-gression (LR) classifier for each dialog in the game.13We applied the same preprocessing and extracted thesame features used for training the interpreter in thehybrid system.3.3 Discussion and Interaction ExamplesAs shown above, while the QA system simplymatches the player?s input to a system response, thehybrid system has a much more elaborate dialogmanagement policy including re-interpretation andthe use of game and dialog history information,to guide the dialog.
As a result, the QA dialogsare generally more spontaneous, giving the playermore initiative whereas the hybrid system enforcesa more System-Driven dialog strategy thereby guid-ing the player through the game.
The following twoexamples illustrate this point.
Sophia is the systemand Lucas the player.
The game context providestwo goals which can be discussed: one mandatory(To find out that finishing the manufacturing processinvolves conditioning the product), and one optional(To be told what conditioning the product means).The examples show how the hybrid system proposesboth goals to the user while the QA engine providesthe same information fluently.Hybrid systemSophia: Vous avez fait du bon travail les enfants!You did a great job kids!Sophia: Bien.
Que puis-je faire pour vous ?What can I do for you?Lucas: J?ai fini la manetteI?ve finished the joystickSophia: Normalement j?ai encore quelques e?tapes a` re?aliseravant l?envoi au client.
Vous voulez en savoir plus ?Normally I still have to condition the product.
Do you want toknow more about conditioning a product?Lucas: OuiYes, okSophia: Conditionner le produit veut dire l?emballer soigneuse-ment pour pouvoir l?expe?dier au client.
Aldo, le logisticien as-sure qu?on ne manque pas de stock et de ge?rer les livraisons etles expe?ditions.Conditioning the product means packing it carefully in order toship it to the customer.
Aldo,the logistics coordinator ensuresthere is no shortage of stock and he is also in charge of the de-liveries and shipments.Sophia: Je vous laisse tester votre manette .
Au revoirI leave you test out your joystick.
GoodbyeQuestion AnswerSophia: he?
bien c?est du bon travail tout c?a.Good!
That?s a great job kids!Sophia: Alors , ou` en sommes nous?So where are we?Lucas:voila` nous avons utilise?
les composants.
Quelle estl?e?tape suivante?We used the components, what is the next step?Sophia: On finis la fabrication par conditionner le produit.We finish the fabrication by conditioning the product.Lucas:OkSophia: Conditioner le produit veut dire l?emballer soigneuse-ment pour pouvoir l?expe?dier au client .
Le logisticien assurequ?on ne manque pas de stock et de ge?rer les livraisons et lesexpe?ditions.Conditioning the product means packing it carefully in order toship it to the customer.
Aldo,the logistics coordinator ensuresthere is no shortage of stock and he is also in charge of the de-liveries and shipments.Sophia: Et voila, je vous dis au revoirOk, I say good bye!4 EvaluationIn evaluating the two systems, we seek to comparetheir usability: Which system is best suited for useby real users in the context of the MP serious game?We also seek to better understand which modulecauses which errors and why.
To address these ques-tions we conducted a quantitative evaluation wherewe compare the accuracy of the interpreter and thedialog manager integrated in each system; a userbased evaluation involving 22 subjects using boththe QA and the hybrid system; and a corpus basedevaluation where we examine such criteria as dialogcoherence, dialog success, interpretation and gener-ation errors in the corpus of Human-System interac-tions collected during the user-based evaluation.4.1 Quantitative EvaluationWe begin by evaluating the accuracy of the inter-preter and the dialog manager used by the hybrid andthe QA system respectively.
These two classifierswere trained on the Emospeech corpus mentionedabove and evaluated with 30-fold cross-validation.Hybrid System As we mentioned in section 3.1,since the game includes different dialogs, a natu-ral question arise: whether to implement the inter-14preter with a single classifier for the whole dataset,or using a different classifier for each dialog in thegame.
To answer this question, we compared theaccuracy reached in each case.
The details of theseexperiments are described in (Rojas-Barahona et al,2012).
The highest accuracy is reported when usinga single classifier for the whole game, reaching anaccuracy of 90.26%, as opposed to 88.22% in aver-age for each dialog.
In both cases, the classifier usedis LR, with L1 regularisation and applying the tf*idffiltering.
However, although the classifier trained onthe whole dialog data has better accuracy (learninga model per dialog often run into the sparse data is-sue), we observed that, in practice, it often predictedinterpretations that were unrelated to the current di-alog thereby introducing incoherent responses in di-alogs.
For instance, in the dialog below, the playerwants to know how waste is managed in the fac-tory.
The best prediction given by the interpreter is agoal related to another dialog thereby creating a mis-match with the DM expectations.
Re-interpretationthen fails producing a system response that informsthe player of the next goal to be pursued in the gameinstead of answering the player?s request.Ben: Comment on ge`re les dechets ici?How is the waste managed here ?Serge: Allez voir Sophia pour qu?elle vous fournisse les com-posants e?lectroniques ne?cessaires a` votre manette.Go and see Sophia, she?ll give you the electronic componentsyou need for your joystick.For the user based experiment, we therefore usethe LR models with one classifier per dialog.QA System For evaluating the QA classifier, wealso compared results with or without tf*idf filter-ing.
The best results were obtained by the LR clas-sifier for each dialog with tf*idf filtering yielding anaccuracy of 88.27% as shown in Table 2.4.2 Preliminary User-Based EvaluationThe accuracy of the interpreter and the dialog man-ager used by the hybrid and the QA system onlygives partial information on the usability of the di-alog engine in a situated setting.
We therefore con-ducted a user-based evaluation which aims to assessthe following points: interpretation quality, overallsystem quality, dialog clarity, game clarity and tim-ing.
We invited 22 subjects to play the game twice,Id w/o Tf*Idf w Tf*Idf1 83.33 82.932 93.55 91.83 72 80.954 80 82.475 95.24 93.986 97.56 97.57 97.5 97.448 70.59 769 92.77 91.1410 85.53 86.4911 83.51 87.512 94.12 91.04Avg.
87.14 88.27Table 2: Results of the LR classifier for mapping play-ers?
utterances to system moves, with content-words anda context of four previous system moves, with and with-out tf*idf filtering.once with one system and once with the other.
Theexperiment is biased however in that the players al-ways used the hybrid system first.
This is because inpractice, the QA system often fail to provide noviceplayers with enough guidance to play the game.
Thiscan be fixed by having the player first use the hybridsystem.
Interestingly, the game guidance made pos-sible by the Information State approach is effectivein guiding players through the game e.g., by propos-ing new goals to be discussed at an appropriate pointin the dialog; and by taking dialog history into ac-count.After playing, each user completed the question-naire shown in Table 3.
For those criteria such asdialog and game clarity, we do not report the scoressince these are clearly impacted by how many timesthe player has played the game.
Table 4 shows themean of the quantitative scores given by the 22 sub-jects for interpretation, overall system quality andtiming.
We computed a significance test betweenthe scores given by the subjects, using the Wilcoxonsigned-rank test4.
As shown in the Table, for allcriteria, except Q.4, the QA performs significantly(p < 0.01) better than the Hybrid system.4The Wilcoxon signed-rank test is the non-parametric alter-native to the paired t-test for correlated samples, applicable, e.g.when dealing with measures which cannot be assumed to haveequal-interval scales, as is usual with user questionnaires.15InterpretationQ.1 Did you have the feeling the virtual characters understood you?
(very bad 1 ... 100 very good)Overall System QualityQ.2 Did you find the conversations coherent?
(very bad 1 .
.
.
100 very good)Q.3 Did you enjoy talking with the virtual characters?
(very annoying 1 ... 100 very enjoyable)Q.4 Would you prefer playing the game without conversations with virtual characters?
(yes/no)Q.5 What is your overall evaluation of the quality of the conversations?
(very bad 1 .
.
.
100 very good)Dialogue clarityQ.6 How easy was it to understand what you were supposed to ask?
(very difficult 1 ... 100 very easy)Q.7 How clear was the information given by the virtual characters?
(totally unclear 1 ... 100 very clear)Q.8 How effective were the instructions at helping you complete the game?
(not effective 1 ... 100 very effective)Game clarityQ.9 How easy was it to understand the game?
(totally unclear 1 ... 100 very clear)TimingQ.10 Were the system responses too slow (1) / just at the right time (2) / too fast (3)Table 3: Questionnaire filled by the subjects that played with both dialog systems.Interpretation.
Question Q.1 aims to captures theuser?s assessment of the dialog system ability to cor-rectly interpret the player?s utterances.
The QA sys-tem scores 0.7 points higher than the Hybrid systemsuggesting better question/answer coherence for thissystem.
One possible reason is that while the hybridsystem detects any incoherence and either tries tofix it using re-interpretation (which as we saw some-times yields an incoherent dialog) or make it explicit(using a misunderstanding dialog act i.e., a requestfor rephrasing), the QA system systematically pro-vides a direct answer to the player?s input.The relatively low scores assigned by the userto the interpretation capabilities of the two systems(57.36 and 64.55 respectively) show that the highaccuracy of the interpreter and the dialog manageris not a sufficient criteria for assessing the usabilityof a dialog system.Timing.
One important factor for the usability ofa system is of course real time runtimes.
The eval-uation shows that overall the speed of the QA sys-tem was judged more adequate.
Interestingly thoughthe difference between the two systems stems no somuch from cases where the hybrid approach is tooslow than from cases where it is too fast.
These casesare due to the fact that while the QA system alwaysissues one-turn answer, the rule based dialog basedapproach used in the hybrid system often producetwo consecutive turns, one answering the player andthe other attempting to guide her towards the follow-ing game goal.In sum, although the QA system seems more ro-bust and better at supporting coherent dialogs, thehybrid system seems to be more effective at guidingQuestion Hybrid QAInterpr.
Q.1 57.36 64.55 (*)Sys Qual.Q.2 57.78 60.68 (*)Q.3 60.77 66.45 (*)Q.4/no 86.37 81.82Q.5 59.54 65.68 (*)Avg.
66.12 68.66 (*)Timing Q.10 2.25 2.05 (*)Table 4: Mean of the quantitative scores given by 22 in-dividuals.
(*) denotes statistical significance at p < 0.01(two-tailed significance level).the player through the game.4.3 Corpus-Based EvaluationThe User-Based evaluation resulted in the collectionof 298 dialogs (690 player and 1813 system turns)with the Hybrid system and 261 dialogs (773 playerand 1411 system turns) with the QA system.
To bet-ter understand the causes of the scores derived fromthe user-filled questionnaire, we performed manualerror analysis on this data focusing on dialog inco-herences, dialog success, dialog management andgeneration errors (reported in Table 5).DM Errors The count of dialog management(DM) errors is the ratio WRP of wrong system re-sponses on counts of player?s input.
In essence thismetrics permits comparing the accuracy of the QAdialog manager with that of the hybrid system.
Onaverage there is no clear distinction between the twosystems.16Generation Errors The system response selectedby the generation component might be contextuallyinappropriate for at least two reasons.
First, it maycontain information which is unrelated to the currentcontext.
Second, it might have been imprecisely orincorrectly annotated.
For instance, in the dialogbelow, the annotation of the turn Yes, thanks.
Whatdo you want me to do?
did not indicate that the turnincluded a Confirm dialog move.
Selecting this turnin the absence of a yes/no question resulted in acontextually inappropriate system response.SYSTEM: Bonjour les petits jeunes je suis le pre?parateurmatie?re.Hello kids, I am the raw material responsibleSYSTEM: Oui merci.
Vous me voulez quoi en fait ?Yes, thanks.
What do you want me to do?PLAYER: je veux en savoir plus sur cet endroit.I would like to know more about this placeAs shown in Table 5, for both systems, there werefew generation errors.Id %DM H. %DM.
QA %Gen H. & QA1 0.0 4.55 0.572 10.81 12.00 1.023 10.38 12.04 1.494 16.22 14.86 0.325 10.34 2.13 1.466 0.0 0.0 0.947 9.52 4.0 0.08 11.68 7.08 2.069 2.13 26.47 0.7610 15.63 16.13 6.0811 11.94 8.33 3.1912 14.29 8.16 3.17Avg.
9.41 9.65 1.76Table 5: DM and generation errors detected in the hybridand the QA systems.Unsuccessful Dialogs We counted as unsuccess-ful those dialogs that were closed before discussingthe mandatory goals.
The results are shown in Ta-ble 6.
Overall the QA system is more robust leadingto the mandatory goals being discussed in almost alldialogs.
One exception was dialog 8, where the sys-tem went into a loop due to the player repeating thesame sequence of dialog moves.
We fixed this byId %Uns.
H. %Inco.
H. %Uns.
QA.
%Inc.
QA.1 0 0.0 0.0 0.02 0 0.0 0.0 0.03 6.67 3.33 7.41 0.04 7.14 0.0 0.0 4.05 3.85 0.0 0.0 0.06 0.0 0.0 0.0 0.07 21.21 0.0 0.0 0.08 3.70 0.0 15.63 3.139 0.0 0.0 0.0 4.3510 0.0 6.67 0.0 16.6711 3.45 6.90 0.0 3.7012 4.17 4.17 4.55 4.55Avg.
4.89 1.76 4.47 3.03Table 6: Overall dialog errors, the percentage of unsuc-cessful dialogsintegrating a loop detection step in the QA dialogmanager.
For the hybrid system, dialog 7, a dialoginvolving the confirmation strategy (cf.
section 2)is the most problematic.
In this case, the DM rulesused to handle this strategy are inappropriate in thatwhenever the system fails to identify a contextuallyappropriate response, it simply says so and quits thedialog.
The example illustrates the difficulty of de-veloping a complete and coherent DM rule system.Incoherent Dialogs We counted as incoherent, di-alogs where most system answers were unrelated tothe player?s input.
As shown in Table 6, despiteinterpretation and generation imprecisions, most di-alogs were globally coherent.
They made sense ac-cording to the game context: they were related to thetask to be solved by the player in the game, and thegenerated instructions were correctly understood.The hybrid system produces slightly less incoher-ent dialogs probably because of its re-interpretationmechanism which permits correcting contextuallyinvalid dialog moves.5 ConclusionWe have presented a multi-view evaluation of twosystem architectures for conversational agents situ-ated in a serious game.
Although the QA systemseems more robust and is easier to deploy, the hy-brid dialog engine seems to fare better in terms ofgame logic in that it guides the player more effec-17tively through the game.
The evaluation shows theimportance of assessing not only the dialog engineaccuracy but also its usability in the setting it wasdesigned for.
In future work, we plan to computea regression model of user satisfaction for applyingreinforcement learning and find the optimal strategy.In addition, we plan to extend the comparison toother domains such as language learning and com-plex negociation dialogs.6 AcknowledgmentsThe research presented in this paper was partiallysupported by the Eurostar EmoSpeech project andby the European Fund for Regional Developmentwithin the framework of the INTERREG IV A Alle-gro Project.ReferencesC.
Burke, C. Doran, A. Gertner, A. Gregorowicz,L.
Harper, J. Korb, and D. Loehr.
2003.
Dialoguecomplexity with portability?
: research directions forthe information state approach.
In Proceedings of theHLT-NAACL 2003 workshop on Research directions indialogue processing - Volume 7.Jean Carletta, Stephen Isard, Gwyneth Doherty-Sneddon,Amy Isard, Jacqueline C. Kowtko, and Anne H. An-derson.
1997.
The reliability of a dialogue struc-ture coding scheme.
Comput.
Linguist., 23(1):13?31,March.Chih C. Chang and Chih J. Lin, 2001.
LIBSVM: a libraryfor support vector machines.David DeVault, Anton Leuski, and Kenji Sagae.
2011.An evaluation of alternative strategies for implement-ing dialogue policies using statistical classificationand hand-authored rules.
In 5th International JointConference on Natural Language Processing (IJCNLP2011).Sudeep Gandhe and David Traum.
2007.
Creating spo-ken dialogue characters from corpora without annota-tions.
In Proceedings of 8th Conference in the AnnualSeries of Interspeech Events, pages 2201?2204.Jonathan Gratch, Jeff Rickel, Elisabeth Andre?, JustineCassell, Eric Petajan, and Norman Badler.
2002.
Cre-ating interactive virtual humans: Some assembly re-quired.
IEEE Intelligent Systems, 17:54?63, July.Dennis Hofs, Marie?t Theune, and Rieks Akker op den.2010.
Natural interaction with a virtual guide in avirtual environment: A multimodal dialogue system.Journal on Multimodal User Interfaces, 3(1-2):141?153, March.
Open Access.Kate S. Hone and Robert Graham.
2000.
Towards atool for the subjective assessment of speech systeminterfaces (sassi).
Nat.
Lang.
Eng., 6(3-4):287?303,September.W.
L. Johnson, H. H. Vilhja?lmsson, and S. Marsella.2005.
Serious games for language learning: Howmuch game, how much AI?
In Artificial Intelligencein Education.S.
Larsson and D. Traum.
2000.
Information state and di-alogue management in the TRINDI dialogue move en-gine toolkit.
Natural Language Engineering, 6:323?340.Anton Leuski and David Traum.
2008.
A statistical ap-proach for text processing in virtual humans.
In Pro-ceedings of the 26th Army Science Conference.Anton Leuski, Ronakkumar Patel, David Traum, andBrandon Kennedy.
2006.
Building effective questionanswering characters.
In Proceedings of the 7th SIG-DIAL Workshop on Discourse and Dialogue, pages18?27.Andrew Kachites McCallum.
2002.
Mal-let: A machine learning for language toolkit.http://mallet.cs.umass.edu.Lina M. Rojas-Barahona, Alejandra Lorenzo, and ClaireGardent.
2012.
Building and exploiting a corpus of di-alog interactions between french speaking virtual andhuman agents.
In Proceedings of the 8th InternationalConference on Language Resources and Evaluation(to be published).David R. Traum and Staffan Larsson.
2003.
The in-formation state approach to dialogue management.
InJan Kuppevelt, Ronnie W. Smith, and Nancy Ide, ed-itors, Current and New Directions in Discourse andDialogue, volume 22 of Text, Speech and LanguageTechnology, pages 325?353.
Springer Netherlands.10.1007/978-94-010-0019-2 15.David R. Traum, Antonio Roque, Anton Leuski, Panayi-otis Georgiou, Jillian Gerten, Bilyana Martinovski,Shrikanth Narayanan, Susan Robinson, and AshishVaswani.
2007.
Hassan: A virtual human for tac-tical questioning.
In Proceedings of the 8th SIGdialWorkshop on Discourse and Dialogue, page 71?74,September.David Traum, Stacy C. Marsella, Jonathan Gratch, JinaLee, and Arno Hartholt.
2008.
Multi-party, multi-issue, multi-strategy negotiation for multi-modal vir-tual agents.
In Proceedings of the 8th internationalconference on Intelligent Virtual Agents, IVA ?08,pages 117?130, Berlin, Heidelberg.
Springer-Verlag.Marilyn A. Walker, Donald Hindle, Jeanne Fromer,Giuseppe Di Fabbrizio, and Craig Mestel.
1997.
Eval-uating competing agent strategies for a voice emailagent.
CoRR, cmp-lg/9706019.18A.
Example of a dialog with the hybrid system.Translation into English of a dialog between Samir(the system) and Julie (the player) (Strategy 2), itcorresponds to the third dialog in Table 1Samir: Hello my name is Samir, the product designerSamir: What are you doing here young people?Julie: we come to build the joystick of Professor GeekmanSamir: You are in the right place.
The plans are in the closetSamir: Before would you like to hear about my job, the studiesI did or my colleaguesJulie: Tell me about your job.Samir: Well, for instance, is me who devise and design theitems we construct in this enterpriseSamir: Do you want to know more about my colleagues orabout the security measures applied here?Julie: What do your colleagues do?Samir: My job is universal!
In fact it can please both girls thatboys...Samir: In your opinion, what studies should be done to getthereJulie: Designing studies?Samir: This is a creative job.
Several training can lead to thejob arts, industrial design, computer-aided designSamir: And does the safety standards interest you?Julie: That is important the safety yes, tell me moreSamir: You know, here you are in a strategic place.The novelties, the products of tomorrow, is here that they areborn.
They must be protected.
For that reason we control theentrance here.Samir: Well, Good Luck.
Bye!B.
Translation to English of a dialog with theQA system.
Dialog between the raw material opera-tor (the system) and Julie (the player), it correspondsto the 8th dialog in Table 1(Strategy 4).Preparateur1: Hello I am the raw material responsible.
I canprovide you a lot of information about this place.Preparateur1: What can I do for you ?Julie: What do you do here?Preparateur1: My role is to ensure machines are suppliedwith the right materials,in good colors.
I turn on the dryingovens and the whole supply system.Julie: How does it work the supply system?Preparateur1: Well when we get the pellet material, they arewet ...Julie: What does it happen when there is a problem?Preparateur1: In that case, I call the technician, he is the bestfor fixing everythingJulie:Thanks for the information, what should I do now?Preparateur1: It is not complicated and you will learn things.I have a new machine to supply but I can not find the rightmaterial.
Would you give me a hand?Julie: yesPreparateur1: You must supply this machine with a newgeneration of plastic.
This machine allows the manufacture ofplastic bagsJulie: okPreparateur1: Let?s go!Julie: Ok, Let?s start!Preparateur1: Great, Thanks!Preparateur1: You are very kind, thank you.19
