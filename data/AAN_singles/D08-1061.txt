Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 582?590,Honolulu, October 2008. c?2008 Association for Computational LinguisticsWeakly-Supervised Acquisition of Labeled Class Instances using GraphRandom WalksPartha Pratim Talukdar?University of PennsylvaniaPhiladelphia, PA 19104partha@cis.upenn.eduJoseph Reisinger?University of Texas at AustinAustin, TX 78712joeraii@cs.utexas.eduMarius Pas?caGoogle Inc.Mountain View, CA 94043mars@google.comDeepak RavichandranGoogle Inc.Mountain View, CA 94043deepakr@google.comRahul Bhagat?USC Information Sciences InstituteMarina Del Rey, CA 90292rahul@isi.eduFernando PereiraGoogle Inc.Mountain View, CA 94043pereira@google.comAbstractWe present a graph-based semi-supervised la-bel propagation algorithm for acquiring open-domain labeled classes and their instancesfrom a combination of unstructured and struc-tured text sources.
This acquisition methodsignificantly improves coverage compared toa previous set of labeled classes and instancesderived from free text, while achieving com-parable precision.1 Introduction1.1 MotivationUsers of large document collections can readily ac-quire information about the instances, classes, andrelationships described in the documents.
Such rela-tions play an important role in both natural languageunderstanding andWeb search, as illustrated by theirprominence in both Web documents and among thesearch queries submitted most frequently by Webusers (Jansen et al, 2000).
These observations moti-vate our work on algorithms to extract instance-classinformation from Web documents.While work on named-entity recognition tradi-tionally focuses on the acquisition and identifica-tion of instances within a small set of coarse-grainedclasses, the distribution of instances within querylogs indicates that Web search users are interestedin a wider range of more fine-grained classes.
De-pending on prior knowledge, personal interests andimmediate needs, users submit for example medi-cal queries about the symptoms of leptospirosis or?Contributions made during internships at Google.the treatment of monkeypox, both of which are in-stances of zoonotic diseases, or the risks and benefitsof surgical procedures such as PRK and angioplasty.Other users may be more interested in African coun-tries such as Uganda and Angola, or active volca-noes like Etna and Kilauea.
Note that zoonotic dis-eases, surgical procedures, African countries andactive volcanoes serve as useful class labels that cap-ture the semantics of the associated sets of class in-stances.
Such interest in a wide variety of specificdomains highlights the utility of constructing largecollections of fine-grained classes.Comprehensive and accurate class-instance in-formation is useful not only in search but alsoin a variety of other text processing tasks includ-ing co-reference resolution (McCarthy and Lehn-ert, 1995), named entity recognition (Stevenson andGaizauskas, 2000) and seed-based information ex-traction (Riloff and Jones, 1999).1.2 ContributionsWe study the acquisition of open-domain, labeledclasses and their instances from both structuredand unstructured textual data sources by combin-ing and ranking individual extractions in a princi-pled way with the Adsorption label-propagation al-gorithm (Baluja et al, 2008), reviewed in Section 3below.A collection of labeled classes acquired fromtext (Van Durme and Pas?ca, 2008) is extended in twoways:1.
Class label coverage is increased by identify-ing additional class labels (such as public agen-cies and governmental agencies) for existing582instances such as Office of War Information),2.
The overall instance coverage is increased byextracting additional instances (such as Addi-son Wesley and Zebra Books) for existing classlabels (book publishers).The WebTables database constructed by Cafarellaet al (2008) is used as the source of additionalinstances.
Evaluations on gold-standard labeledclasses and instances from existing linguistic re-sources (Fellbaum, 1998) indicate coverage im-provements relative to that of Van Durme and Pas?ca(2008), while retaining similar precision levels.2 First Phase ExtractorsTo show Adsorption?s ability to uniformly combineextractions from multiple sources and methods, weapply it to: 1) high-precision open-domain extrac-tions from free Web text (Van Durme and Pas?ca,2008), and 2) high-recall extractions from WebTa-bles, a large database of HTML tables mined fromthe Web (Cafarella et al, 2008).
These two meth-ods were chosen to be representative of two broadclasses of extraction sources: free text and structuredWeb documents.2.1 Extraction from Free TextVan Durme and Pas?ca (2008) produce an open-domain set of instance clusters C ?
C that parti-tions a given set of instances I using distributionalsimilarity (Lin and Pantel, 2002), and labels usingis-a patterns (Hearst, 1992).
By filtering the classlabels using distributional similarity, a large numberof high-precision labeled clusters are extracted.
Thealgorithm proceeds iteratively: at each step, all clus-ters are tested for label coherence and all coherentlabels are tested for high cluster specificity.
LabelL is coherent if it is shared by at least J% of theinstances in cluster C, and it is specific if the totalnumber of other clusters C ?
?
C, C ?
6= C containinginstances with label L is less thanK.
When a clusteris found to match these criteria, it is removed fromC and added to an output set.
The procedure termi-nates when no new clusters can be removed from C.Table 1 shows a few randomly chosen classes andrepresentative instances obtained by this procedure.2.2 Extraction from Structured TextTo expand the instance sets extracted from freetext, we use a table-based extraction method thatmines structured Web data in the form of HTMLtables.
A significant fraction of the HTML ta-bles in Web pages is assumed to contain coherentlists of instances suitable for extraction.
Identifyingsuch tables from scratch is hard, but seed instancelists can be used to identify potentially coherent ta-ble columns.
In this paper we use the WebTablesdatabase of around 154 million tables as our struc-tured data source (Cafarella et al, 2008).We employ a simple ranking scheme for candi-date instances in the WebTables corpus T .
Each ta-ble T ?
T consists of one or more columns.
Eachcolumn g ?
T consists of a set of candidate in-stances i ?
g corresponding to row elements.
Wedefine the set of unique seed matches in g relative tosemantic class C ?
C asMC(g)def= {i ?
I(C) : i ?
g}where I(C) denotes the set of instances in seed classC.
For each column g, we define its ?-unique classcoverage, that is, the set of classes that have at least?
unique seeds in g,Q(g;?
)def= {C ?
C : |MC(g)| ?
?
}.Using M and Q we define a method for scoringcolumns relative to each class.
Intuitively, such ascore should take into account not only the numberof matches from class C, but also the total num-ber of classes that contribute to Q and their relativeoverlap.
Towards this end, we introduce the scoringfunctionscore(C, g;?
)def= |MC(g)|?
??
?seed matches?class coherence?
??
?|MC(g)||?C??Q(g;?)
I(C?
)|which is the simplest scoring function combiningthe number of seed matches with the coherence ofthe table column.
Coherence is a critical notionin WebTables extraction, as some tables contain in-stances across many diverse seed classes, contribut-ing to extraction noise.
The class coherence intro-duced here also takes into account class overlap; that583Class Size Examples of InstancesBook Publishers 70 crown publishing, kluwer academic, prentice hall, puffinFederal Agencies 161 catsa, dhs, dod, ex-im bank, fsis, iema, mema, nipc, nmfs, tdh, usdotMammals 956 armadillo, elephant shrews, long-tailed weasel, river otter, weddell seals, wild goatNFL Players 180 aikman, deion sanders, fred taylor, jamal lewis, raghib ismail, troy vincentScientific Journals 265 biometrika, european economic review, nature genetics, neuroscienceSocial Issues 210 gender inequality, lack of education, substandard housing, welfare dependencyWriters 5089 bronte sisters, hemingway, kipling, proust, torquato tasso, ungaretti, yeatsTable 1: A sample of the open-domain classes and associated instances from (Van Durme and Pas?ca, 2008).is, a column containing many semantically similarclasses is penalized less than one containing diverseclasses.1 Finally, an extracted instance i is assigneda score relative to class C equal to the sum of all itscolumn scores,score(i, C;?
)def=1ZC?g?T,T?Tscore(C, g;?
)where ZC is a normalizing constant set to the max-imum score of any instance in class C. This scor-ing function assigns high rank to instances that oc-cur frequently in columns with many seed matchesand high class specificity.The ranked list of extracted instances is post-filtered by removing all instances that occur in lessthan d unique Internet domains.3 Graph-Based ExtractionTo combine the extractions from both free and struc-tured text, we need a representation capable of en-coding efficiently all the available information.
Wechose a graph representation for the following rea-sons:?
Graphs can represent complicated relationshipsbetween classes and instances.
For example,an ambiguous instance such as Michael Jor-dan could belong to the class of both Profes-sors and NBA players.
Similarly, an instancemay belong to multiple nodes in the hierarchyof classes.
For example, Blue Whales could be-long to both classes Vertebrates and Mammals,because Mammals are a subset of Vertebrates.1Note that this scoring function does not take into accountclass containment: if all seeds are both wind Instruments andinstruments, then the column should assign higher score to themore specific class.?
Extractions frommultiple sources, such asWebqueries, Web tables, and text patterns can berepresented in a single graph.?
Graphs make explicit the potential paths of in-formation propagation that are implicit in themore common local heuristics used for weakly-supervised information extraction.
For exam-ple, if we know that the instance Bill Clintonbelongs to both classes President and Politicianthen this should be treated as evidence that theclass of President and Politician are related.Each instance-class pair (i, C) extracted in thefirst phase (Section 2) is represented as a weightededge in a graph G = (V,E,W ), where V is the setof nodes, E is the set of edges and W : E ?
R+is the weight function which assigns positive weightto each edge.
In particular, for each (i, C,w) triplefrom the set of base extractions, i and C are addedto V and (i, C) is added to E, 2 with W (i, C) = w.The weight w represents the total score of all extrac-tions with that instance and class.
Figure 1 illustratesa portion of a sample graph.
This simple graph rep-resentation could be refined with additional types ofnodes and edges, as we discuss in Section 7.In what follows, all nodes are treated in the sameway, regardless of whether they represent instancesor classes.
In particular, all nodes can be assignedclass labels.
For an instance node, that means thatthe instance is hypothesized to belong to the class;for a class node, that means that the node?s class ishypothesized to be semantically similar to the label?sclass (Section 5).We now formulate the task of assigning labels tonodes as graph label propagation.
We are given a2In practice, we use two directed edges, from i to C andfrom C to i, both with weight w.584bob dylanmusician0.95johnny cash0.87singer0.73billy joel0.820.75Figure 1: Section of a graph used as input into Adsorp-tion.
Though the nodes do not have any type associatedwith them, for readability, instance nodes are marked inpink while class nodes are shown in green.set of instances I and a set of classes C representedas nodes in the graph, with connecting edges as de-scribed above.
We annotate a few instance nodeswith labels drawn from C. That is, classes are usedboth as nodes in the graph and as labels for nodes.There is no necessary alignment between a classnode and any of the (class) labels, as the final labelswill be assigned by the Adsorption algorithm.The Adsorption label propagation algo-rithm (Baluja et al, 2008) is now applied tothe given graph.
Adsorption is a general frameworkfor label propagation, consisting of a few nodesannotated with labels and a rich graph structurecontaining the universe of all labeled and unlabelednodes.
Adsorption proceeds to label all nodesbased on the graph structure, ultimately producing aprobability distribution over labels for each node.More specifically, Adsorption works on a graphG = (V,E,W ) and computes for each node v a la-bel distribution Lv that represents which labels aremore or less appropriate for that node.
Several in-terpretations of Adsorption-type algorithms have ap-peared in various fields (Azran, 2007; Zhu et al,2003; Szummer and Jaakkola, 2002; Indyk and Ma-tousek, 2004).
For details, the reader is referred to(Baluja et al, 2008).
We use two interpretationshere:Adsorption through Random Walks: Let Gr =(V,Er,Wr) be the edge-reversed version of theoriginal graph G = (V,E,W ) where (a, b) ?Er iff (b, a) ?
E; and Wr(a, b) = W (b, a).Now, choose a node of interest q ?
V .
To es-timate Lq for q, we perform a random walk onGr starting from q to generate values for a ran-dom label variable L. After reaching a node vduring the walk, we have three choices:1.
With probability pcontv , continue the ran-dom walk to a neighbor of v.2.
With probability pabndv , abandon the ran-dom walk.
This abandonment proba-bility makes the random walk stay rela-tively close to its source when the graphhas high-degree nodes.
When the ran-dom walk passes through such a node,it is likely that further transitions will beinto regions of the graph unrelated to thesource.
The abandonment probability mit-igates that effect.3.
With probability pinjv , stop the randomwalk and emit a label L from Iv.Lq is set to the expectation of all labels L emit-ted from random walks initiated from node q.Adsorption through Averaging: For this interpre-tation we make some changes to the originalgraph structure and label set.
We extend the la-bel distributions Lv to assign a probability notonly to each label in C but also to the dummylabel ?, which represents lack of informationabout the actual label(s).
We represent the ini-tial knowledge we have about some node labelsin an augmented graph G?
= (V ?, E?,W ?)
asfollows.
For each v ?
V , we define an ini-tial distribution Iv = L?, where L?
is thedummy distribution with L?(?)
= 1, repre-senting lack of label information for v. In addi-tion, let Vs ?
V be the set of nodes for whichwe have some actual label knowledge, and letV ?
= V ?
{v?
: v ?
Vs}, E?
= E ?
{(v?, v) :v ?
Vs}, and W ?
(v?, v) = 1 for v ?
Vs,W ?
(u, v) = W (u, v) for u, v ?
V .
Finally,let Iv?
(seed labels) specify the knowledge aboutpossible labels for v ?
Vs. Less formally, thev?
nodes in G?
serve to inject into the graph theprior label distributions for each v ?
Vs.The algorithm proceeds as follows: For eachnode use a fixed-point computation to find label585distributions that are weighted averages of thelabel distributions for all their neighbors.
Thiscauses the non-dummy initial distribution of Vsnodes to be propagated across the graph.Baluja et al (2008) show that those two views areequivalent.
Algorithm 1 combines the two views:instead of a random walk, for each node v, it itera-tively computes the weighted average of label distri-butions from neighboring nodes, and then uses therandom walk probabilities to estimate a new labeldistribution for v.For the experiments reported in Section 4, weused the following heuristics from Baluja et al(2008) to set the random walk probabilities:?
Let cv =log ?log(?
+ expH(v)) where H(v) =?
?u puv ?
log(puv) with puv =W (u,v)Pu?
W (u?
,v).H(v) can be interpreted as the entropy of v?sneighborhood.
Thus, cv is lower if v has manyneighbors.
We set ?
= 2.?
jv = (1 ?
cv) ?
?H(v) if Iv 6= L> and 0otherwise.?
Then letzv = max(cv + jv, 1)pcontv = cv/zvpinjv = jv/zvpabndv = 1?
pcontv ?
pabndvThus, abandonment occurs only when the con-tinuation and injection probabilities are lowenough.The algorithm is run until convergence which isachieved when the label distribution on each nodeceases to change within some tolerance value.
Alter-natively, the algorithm can be run for a fixed numberof iterations which is what we used in practice3.Finally, since Adsorption is memoryless, it eas-ily scales to tens of millions of nodes with denseedges and can be easily parallelized, as describedby Baluja et al (2008).3The number of iterations was set to 10 in the experimentsreported in this paper.Algorithm 1 Adsorption Algorithm.Input: G?
= (V?, E?,W ?
), Iv (?v ?
V ?
).Output: Distributions {Lv : v ?
V }.1: Lv = Iv ?v ?
V?2:3: repeat4: Nv =?u W (u, v)5: Dv = 1Nv?u W (u, v)Lu ?v ?
V?6: for all v ?
V?do7: Lv = pcontv ?Dv +pinjv ?
Iv +pabndv ?L>8: end for9: until convergence4 Experiments4.1 DataAs mentioned in Section 3, one of the benefits ofusing Adsorption is that we can combine extrac-tions by different methods from diverse sources intoa single framework.
To demonstrate this capabil-ity, we combine extractions from free-text patternsand from Web tables.
To the best of our knowl-edge, this is one of the first attempts in the area ofminimally-supervised extraction algorithms whereunstructured and structured text are used in a prin-cipled way within a single system.Open-domain (instance, class) pairs were ex-tracted by applying the method described by VanDurme and Pas?ca (2008) on a corpus of over 100MEnglish web documents.
A total of 924K (instance,class) pairs were extracted, containing 263K uniqueinstances in 9081 classes.
We refer to this dataset asA8.Using A8, an additional 74M unique (in-stance,class) pairs are extracted from a random 10%of the WebTables data, using the method outlined inSection 2.2.
For maximum coverage we set ?
= 2and d = 2, resulting in a large, but somewhat noisycollection.
We refer to this data set as WT.4.2 Graph CreationWe applied the graph construction scheme describedin Section 3 on the A8 and WT data combined, re-sulting in a graph with 1.4M nodes and 75M edges.Since extractions in A8 are not scored, weight of all586Seed Class Seed InstancesBook Publishers millbrook press, academic press, springer verlag, chronicle books, shambhala publicationsFederal Agencies dod, nsf, office of war information, tsa, femaMammals african wild dog, hyaena, hippopotamus, sperm whale, tigerNFL Players ike hilliard, isaac bruce, torry holt, jon kitna, jamal lewisScientific Journals american journal of roentgenology, pnas, journal of bacteriology, american economic review,ibm systems journalTable 2: Classes and seeds used to initialize Adsorption.edges originating from A8 were set at 14.
This graphis used in all subsequent experiments.5 EvaluationWe evaluated the Adsorption algorithm under twoexperimental settings.
First, we evaluate Adsorp-tion?s extraction precision on (instance, class) pairsobtained by Adsorption but not present in A8 (Sec-tion 5.1).
This measures whether Adsorption canadd to the A8 extractions at fairly high precision.Second, we measured Adsorption?s ability to assignlabels to a fixed set of gold instances drawn fromvarious classes (Section 5.2).Book Publishers Federal Agencies NFL Players Scientific Journals Mammals20406080100Adsorption A8BookPublishersFederalAgenciesNFLPlayersScientificJournalsMammalsA8 AdsorptionFigure 2: Precision at 100 comparisons for A8 and Ad-sorption.5.1 Instance PrecisionFirst we manually evaluated precision across fiverandomly selected classes from A8: Book Publish-ers, Federal Agencies, NFL Players, Scientific Jour-nals and Mammals.
For each class, 5 seed in-stances were chosen manually to initialize Adsorp-tion.
These classes and seeds are shown in Table 2.Adsorption was run for each class separately and the4A8 extractions are assumed to be high-precision and hencewe assign them the highest possible weight.resulting ranked extractions were manually evalu-ated.Since the A8 system does not produce ranked listsof instances, we chose 100 random instances fromthe A8 results to compare to the top 100 instancesproduced by Adsorption.
Each of the resulting 500instance-class pairs (i, C) was presented to two hu-man evaluators, who were asked to evaluate whetherthe relation ?i is a C?
was correct or incorrect.
Theuser was also presented with Web search link to ver-ify the results against actual documents.
Resultsfrom these experiments are presented in Figure 2and Table 4.
The results in Figure 2 show that theA8 system has higher precision than the Adsorptionsystem.
This is not surprising since the A8 system istuned for high precision.
When considering individ-ual evaluation classes, changes in precision scoresbetween the A8 system and the Adsorption systemvary from a small increase from 87% to 89% for theclass Book Publishers, to a significant decrease from52% to 34% for the class Federal Agencies, with adecrease of 10% as an average over the 5 evaluationclasses.Class Precision at 100(non-A8 extractions)Book Publishers 87.36Federal Agencies 29.89NFL Players 94.95Scientific Journals 90.82Mammal Species 84.27Table 4: Precision of top 100 Adsorption extractions (forfive classes) which were not present in A8.Table 4 shows the precision of the Adsorption sys-tem for instances not extracted by the A8 system.587Seed Class Non-Seed Class Labels Discovered by AdsorptionBook Publishers small presses, journal publishers, educational publishers, academic publishers,commercial publishersFederal Agencies public agencies, governmental agencies, modulation schemes, private sources,technical societiesNFL Players sports figures, football greats, football players, backs, quarterbacksScientific Journals prestigious journals, peer-reviewed journals, refereed journals, scholarly journals,academic journalsMammal Species marine mammal species, whale species, larger mammals, common animals, sea mammalsTable 3: Top class labels ranked by their similarity to a given seed class in Adsorption.Seed Class Sample of Top Ranked Instances Discovered by AdsorptionBook Publishers small night shade books, house of anansi press, highwater books,distributed art publishers, copper canyon pressNFL Players tony gonzales, thabiti davis, taylor stubblefield, ron dixon, rodney hannahScientific Journals journal of physics, nature structural and molecular biology,sciences sociales et sante?, kidney and blood pressure research,american journal of physiology?cell physiologyTable 5: Random examples of top ranked extractions (for three classes) found by Adsorption which were not presentin A8.Such an evaluation is important as one of the mainmotivations of the current work is to increase cov-erage (recall) of existing high-precision extractorswithout significantly affecting precision.
Results inTable 4 show that Adsorption is indeed able to ex-traction with high precision (in 4 out of 5 cases)new instance-class pairs which were not extractedby the original high-precision extraction set (in thiscase A8).
Examples of a few such pairs are shownin Table 5.
This is promising as almost all state-of-the-art extraction methods are high-precision andlow-recall.
The proposed method shows a way toovercome that limitation.As noted in Section 3, Adsorption ignores nodetype and hence the final ranked extraction may alsocontain classes along with instances.
Thus, in ad-dition to finding new instances for classes, it alsofinds additional class labels similar to the seed classlabels with which Adsorption was run, at no extracost.
Some of the top ranked class labels extractedby Adsorption for the corresponding seed class la-bels are shown in Table 3.
To the best of our knowl-edge, there are no other systems which perform bothtasks simultaneously.5.2 Class Label RecallNext we evaluated each extraction method on its rel-ative ability to assign labels to class instances.
Foreach test instance, the five most probably class la-bels are collected using each method and the MeanReciprocal Rank (MRR) is computed relative to agold standard target set.
This target set, WN-gold,consists of the 38 classes in Wordnet containing 100or more instances.In order to extract meaningful output from Ad-sorption, it is provided with a number of labeled seedinstances (1, 5, 10 or 25) from each of the 38 testclasses.
Regardless of the actual number of seedsused as input, all 25 seed instances from each classare removed from the output set from all methods,in order to ensure fair comparison.The results from this evaluation are summarizedin Table 6; AD x refers to the adsorption run with xseed instances.
Overall, Adsorption exhibits higherMRR than either of the baseline methods, with MRRincreasing as the amount of supervision is increased.Due to its high coverage, WT assigns labels toa larger number of the instance in WN-gold thanany other method.
However, the average rank ofthe correct class assignment is lower, resulting is588MRR MRR # foundMethod (full) (found only)A8 0.16 0.47 2718WT 0.15 0.21 5747AD 1 0.26 0.45 4687AD 5 0.29 0.48 4687AD 10 0.30 0.51 4687AD 25 0.32 0.55 4687Table 6: Mean-Reciprocal Rank scores of instance classlabels over 38 Wordnet classes (WN-gold).
MRR (full)refers to evaluation across the entire gold instance set.MRR (found only) computes MRR only on recalled in-stances.lower MRR scores compared to Adsorption.
Thisresult highlights Adsorption?s ability to effectivelycombine high-precision, low-recall (A8) extractionswith low-precision, high-recall extractions (WT) ina manner that improves both precision and coverage.6 Related WorkGraph based algorithms for minimally supervisedinformation extraction methods have recently beenproposed.
For example, Wang and Cohen (2007)use a random walk on a graph built from entities andrelations extracted from semi-structured text.
Ourwork differs both conceptually, in terms of its focuson open-domain extraction, as well as methodologi-cally, as we incorporate both unstructured and struc-tured text.
The re-ranking algorithm of Bellare et al(2007) also constructs a graph whose nodes are in-stances and attributes, as opposed to instances andclasses here.
Adsorption can be seen as a general-ization of the method proposed in that paper.7 ConclusionThe field of open-domain information extraction hasbeen driven by the growth of Web-accessible data.We have staggering amounts of data from variousstructured and unstructured sources such as generalWeb text, online encyclopedias, query logs, web ta-bles, or link anchor texts.
Any proposed algorithmto extract information needs to harness several datasources and do it in a robust and scalable manner.Our work in this paper represents a first step towardsthat goal.
In doing so, we achieved the following:1.
Improved coverage relative to a high accuracyinstance-class extraction system while main-taining adequate precision.2.
Combined information from two differentsources: free text and web tables.3.
Demonstrated a graph-based label propagationalgorithm that given as little as five seeds perclass achieved good results on a graph withmore than a million nodes and 70 millionedges.In this paper, we started off with a simple graph.For future work, we plan to proceed along the fol-lowing lines:1.
Encode richer relationships between nodes,for example instance-instance associations andother types of nodes.2.
Combine information from more data sourcesto answer the question of whether more data ordiverse sources are more effective in increasingprecision and coverage.3.
Apply similar ideas to other information extrac-tion tasks such as relation extraction.AcknowledgmentsWe would like to thank D. Sivakumar for useful dis-cussions and the anonymous reviewers for helpfulcomments.ReferencesA.
Azran.
2007.
The rendezvous algorithm: multiclasssemi-supervised learning with markov random walks.Proceedings of the 24th international conference onMachine learning, pages 49?56.S.
Baluja, R. Seth, D. Sivakumar, Y. Jing, J. Yagnik,S.
Kumar, D. Ravichandran, and M. Aly.
2008.
Videosuggestion and discovery for youtube: taking randomwalks through the view graph.K.
Bellare, P. Talukdar, G. Kumaran, F. Pereira, M. Liber-man, A. McCallum, and M. Dredze.
2007.
Lightly-Supervised Attribute Extraction.
NIPS 2007Workshopon Machine Learning for Web Search.M.
Cafarella, A. Halevy, D. Wang, E. Wu, and Y. Zhang.2008.
Webtables: Exploring the power of tables on theweb.
VLDB.589C.
Fellbaum, editor.
1998.
WordNet: An Electronic Lexi-cal Database and Some of its Applications.
MIT Press.M.
Hearst.
1992.
Automatic acquisition of hyponymsfrom large text corpora.
In Proceedings of the 14th In-ternational Conference on Computational Linguistics(COLING-92), pages 539?545, Nantes, France.P.
Indyk and J. Matousek.
2004.
Low-distortion embed-dings of finite metric spaces.
Handbook of Discreteand Computational Geometry.B.
Jansen, A. Spink, and T. Saracevic.
2000.
Real life,real users, and real needs: a study and analysis of userqueries on the Web.
Information Processing and Man-agement, 36(2):207?227.D.
Lin and P. Pantel.
2002.
Concept discovery from text.In Proceedings of the 19th International Conferenceon Computational linguistics (COLING-02), pages 1?7.K.
McCarthy and W. Lehnert.
1995.
Using decisiontrees for coreference resolution.
In Proceedings of the14th International Joint Conference on Artificial Intel-ligence (IJCAI-95), pages 1050?1055, Montreal, Que-bec.E.
Riloff and R. Jones.
1999.
Learning dictionaries forinformation extraction by multi-level bootstrapping.In Proceedings of the 16th National Conference onArtificial Intelligence (AAAI-99), pages 474?479, Or-lando, Florida.M.
Stevenson and R. Gaizauskas.
2000.
Using corpus-derived name lists for named entity recognition.
InProceedings of the 6th Conference on Applied Natu-ral Language Processing (ANLP-00), Seattle, Wash-ington.M.
Szummer and T. Jaakkola.
2002.
Partially labeledclassification with markov random walks.
Advances inNeural Information Processing Systems 14: Proceed-ings of the 2002 NIPS Conference.B.
Van Durme and M. Pas?ca.
2008.
Finding cars, god-desses and enzymes: Parametrizable acquisition of la-beled instances for open-domain information extrac-tion.
Twenty-Third AAAI Conference on Artificial In-telligence.R.
Wang and W. Cohen.
2007.
Language-IndependentSet Expansion of Named Entities Using theWeb.
DataMining, 2007.
ICDM 2007.
Seventh IEEE Interna-tional Conference on, pages 342?350.X.
Zhu, Z. Ghahramani, and J. Lafferty.
2003.
Semi-supervised learning using gaussian fields and har-monic functions.
ICML-03, 20th International Con-ference on Machine Learning.590
