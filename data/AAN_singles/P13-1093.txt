Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 944?953,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsAutomatic detection of deception in child-produced speech using syntacticcomplexity featuresMaria YanchevaDivision of Engineering Science,University of TorontoToronto Ontario Canadamaria.yancheva@utoronto.caFrank RudziczToronto Rehabilitation Institute; andDepartment of Computer Science,University of TorontoToronto Ontario Canadafrank@cs.toronto.eduAbstractIt is important that the testimony of chil-dren be admissible in court, especiallygiven allegations of abuse.
Unfortunately,children can be misled by interrogators ormight offer false information, with direconsequences.
In this work, we evalu-ate various parameterizations of five clas-sifiers (including support vector machines,neural networks, and random forests) indeciphering truth from lies given tran-scripts of interviews with 198 victims ofabuse between the ages of 4 and 7.
Theseevaluations are performed using a novelset of syntactic features, including mea-sures of complexity.
Our results showthat sentence length, the mean numberof clauses per utterance, and the Stajner-Mitkov measure of complexity are highlyinformative syntactic features, that classi-fication accuracy varies greatly by the ageof the speaker, and that accuracy up to91.7% can be achieved by support vec-tor machines given a sufficient amount ofdata.1 IntroductionThe challenge of disambiguating between truthand deception is critical in determining the ad-missibility of court testimony.
Unfortunately, thetestimony of maltreated children is often not ad-mitted in court due to concerns about truthfulnesssince children can be instructed to deny transgres-sions or misled to elicit false accusations (Lyonand Dorado, 2008).
However, the child is oftenthe only witness of the transgression (Undeutsch,2008); automatically determining truthfulness insuch situations is therefore a paramount goal sothat justice may be served effectively.2 Related WorkResearch in the detection of deception in adultspeech has included analyses of verbal and non-verbal cues such as behavioral changes, facial ex-pression, speech dysfluencies, and cognitive com-plexity (DePaulo et al, 2003).
Despite statisticallysignificant predictors of deception such as shortertalking time, fewer semantic details, and less co-herent statements, DePaulo et al (2003) found thatthe median effect size is very small.
Deceptionwithout special motivation (e.g., everyday ?whitelies?)
exhibited almost no discernible cues of de-ception.
However, analysis of moderating factorsshowed that cues were significantly more numer-ous and salient when lies were about transgres-sions.Literature on deception in children is relativelylimited.
In one study, Lewis et al (1989) studied3-year-olds and measured behavioral cues, such asfacial expression and nervous body movement, be-fore and after the elicitation of a lie.
Verbal re-sponses consisted of yes/no answers.
Results sug-gested that 3-year-old children are capable of de-ception, and that non-verbal behaviors during de-ception include increases in ?positive?
behaviors(e.g., smiling).
However, verbal cues of deceptionwere not analyzed.
Crucially, Lewis et al (1989)showed that humans are no more accurate in deci-phering truth from deception in child speech thanin adult speech, being only about 50% accurate.More recently, researchers have used linguis-tic features to identify deception.
Newman et al(2003) inferred deception in transcribed, typed,and handwritten text by identifying features of lin-guistic style such as the use of personal pronouns944and exclusive words (e.g., but, except, without).These features were obtained with the LinguisticInquiry and Word Count (LIWC) tool and usedin a logistic regression classifier which achieved,on average, 61% accuracy on test data.
Featureanalysis showed that deceptive stories were char-acterized by fewer self-references, more negativeemotion words, and lower cognitive complexity,compared to non-deceptive language.Another recent stylometric experiment in auto-matic identification of deception was performedby Mihalcea and Strapparava (2009).
The authorsused a dataset of truthful and deceptive typed re-sponses produced by adult subjects on three dif-ferent topics, collected through the Amazon Me-chanical Turk service.
Two classifiers, Na?
?veBayes (NB) and a support vector machine (SVM),were applied on the tokenized and stemmed state-ments to obtain best classification accuracies of70% (abortion topic, NB), 67.4% (death penaltytopic, NB), and 77% (friend description, SVM),where the baseline was taken to be 50%.
Thelarge variability of classifier performance based onthe topic of deception suggests that performanceis context-dependent.
The authors note this aswell by demonstrating significantly lower resultsof 59.8% for NB and 57.8% for SVM when cross-topic classification is performed by training eachclassifier on two topics and testing on the third.The Mihalcea-Strapparava mturk dataset wasfurther used in a study by Feng et al (2012) whichemploys lexicalized and unlexicalized productionrules to obtain deep syntactic features.
The cross-validation accuracy obtained on the three topicswas improved to 77% (abortion topic), 71.5%(death penalty topic), and 85% (friend descrip-tion).
The results nevertheless varied with topic.Another experiment using syntactic features foridentifying sentences containing uncertain or un-reliable information was conducted by Zheng et al(2010) on an adult-produced dataset of abstractsand full articles from BioScope, and on paragraphsfrom Wikipedia.
The results demonstrated that us-ing syntactic dependency features extracted withthe Stanford parser improved performance on thebiological dataset, while an ensemble classifiercombining a conditional random field (CRF) anda MaxEnt classifier performed better than individ-ual classifiers on the Wikipedia dataset.A meta-analysis of features used in deceptiondetection was performed by Hauch et al (2012)and revealed that verbal cues based on lexical cat-egories extracted using the LIWC tool show sta-tistically significant, though small, differences be-tween truth- and lie-tellers.
Vartapetiance andGillam (2012) surveyed existing cues to verbal de-ception and demonstrated that features in LIWCare not indicative of deception in online content,recommending that the features used to identifydeception and the thresholds between deceptionand truth be based on the specific data set.In the speech community, analysis of deceptivespeech has combined various acoustic, prosodic,and lexical features (Hirschberg et al, 2005).
Gra-ciarena et al (2006) combined two independentsystems ?
an acoustic Gaussian mixture modelbased on Mel cepstral features, and a prosodicsupport vector machine based on features such aspitch, energy, and duration ?
and achieved an ac-curacy of 64.4% on a test subset of the Columbia-SRI-Colorado (CSC) corpus of deceptive and non-deceptive speech (Hirschberg et al, 2005).While previous studies have achieved somepromising results in detecting deception with lex-ical, acoustic, and prosodic features, syntax re-mains relatively unexplored compared to LIWC-based features.
Syntactic complexity as a cueto deception is consistent with literature in socialpsychology which suggests that emotion suppres-sion (e.g., inhibition of guilt and fear) consumescognitive resources, which can influence the un-derlying complexity of utterances (Richards andGross, 1999; Richards and Gross, 2000).
Ad-ditionally, the use of syntactic features is moti-vated by their successful use on adult-produceddatasets for detecting deceptive or uncertain utter-ances (Feng et al, 2012; Zheng et al, 2010), aswell as in other applications, such as the evaluationof changes in text complexity (Stajner and Mitkov,2012), the identification of personality in conver-sation and text (Mairesse et al, 2007), and the de-tection of dementia through syntactic changes inwriting (Le et al, 2011).Past work has focused on identifying deceptivespeech produced by adults.
The problem of deter-mining validity of child testimony in high-stakeschild abuse court cases motivates the analysis ofchild-produced deceptive language.
Further, theuse of binary classification schemes in previouswork does not account for partial truths often en-countered in real-life scenarios.
Due to the rarityof real deceptive data, studies typically use arti-945ficially produced deceptive language which fallsunambiguously in one of two classes: completetruth or complete deception (Newman et al, 2003;Mihalcea and Strapparava, 2009).
Studies whichmake use of real high-stakes courtroom data con-taining partial truths, such as the Italian DECOURcorpus analyzed by Fornaciari and Poesio (2012),preprocess the dataset to eliminate any partiallytruthful utterances.
Since utterances of this kindare common in real language, their eliminationfrom the dataset is not ideal.The present study evaluates the viability of anovel set of 17 syntactic features as markers of de-ception in five classifiers.
Moreover, to our knowl-edge, it is the first application of automatic de-ception detection to a real-life dataset of deceptivespeech produced by maltreated children.
The datais scored using a gradient of truthfulness, whichis used to represent completely true, partially true,and completely false statements.
Descriptions ofthe data (section 3) and feature sets (section 4) pre-cede experimental results (section 5) and the con-cluding discussion (section 6).3 DataThe data used in this study were obtained fromLyon et al (2008), who conducted and transcribeda truth-induction experiment involving maltreatedchildren awaiting court appearances in the LosAngeles County Dependency Court.
Subjectswere children between the ages of 4 and 7 (99 boysand 99 girls) who were interviewed regarding anunambiguous minor transgression involving play-ing with a toy.
To ensure an understanding of lyingand its negative consequences, all children passeda preliminary oath-taking competency task, requir-ing each child to correctly identify a truth-tellerand a lie-teller in an object labeling task, as wellas to identify which of the two would be the targetof negative consequences.During data collection, a confederate first en-gaged each child individually in one of four condi-tions: a) play, b) play and coach, c) no play, and d)no play and coach.
In the two play conditions, theconfederate engaged the child in play with a toyhouse (in the no play conditions, they did not); inthe two coach conditions, the confederate coachedthe child to lie (i.e., to deny playing if they playedwith the toy house, or to admit playing if theydid not).
The confederate then left and the childwas interviewed by a second researcher who per-formed a truth-induction manipulation consistingof one of: a) control ?
no manipulation, b) oath?
the interviewer reminded the child of the im-portance of telling the truth and elicited a promiseof truth-telling, and c) reassurance ?
the inter-viewer reassured the child that telling the truth willnot lead to any negative consequences.Each pre- and post-induction transcription maycontain explicit statements of up to seven features:looking at toy-house, touching toy-house, playingwith toy-house, opening toy-house doors or win-dows to uncover hidden toys, playing with thesehidden toys, spinning the toy-house, and puttingback or hiding a toy.
All children in the play condi-tion engaged in all seven actions, while children inthe no play condition engaged in none.
An eighthfeature is the lack of explicit denial of touching orplaying with the toy house, which is consideredto be truthful in the play condition, and deceptivein the no play condition (see the examples in theappendix).
A transcription is labeled as truth ifat least half of these features are truthful (53.2%of all transcriptions) and lie otherwise (46.8% oftranscriptions).
Other thresholds for this binarydiscrimination are explored in section 5.4.Each child?s verbal response was recordedtwice: at time T1 (prior to truth-induction), andat time T2 (after truth-induction).
Each child wassubject to one of the four confederate conditionsand one of the three induction conditions.
The rawdata were pre-processed to remove subjects withblank transcriptions, resulting in a total of 173 sub-jects (87 boys and 86 girls) and 346 transcriptions.4 MethodsSince the data consist of speech produced by 4- to7-year-old children, the predictive features mustdepend on the level of syntactic competence ofthis age group.
The ?continuity assumption?
statesthat children have a complete system of abstractsyntactic representation and have the same set ofabstract functional categories accessible to adults(Pinker, 1984).
An experimental study with 3-to 8-year-old children showed that their syntac-tic competence is comparable to that of adults;specifically, children have a productive rule forpassive forms which allows them to generalizeto previously unheard predicates while followingadult-like constraints to avoid over-generalization(Pinker et al, 1987).
Recent experiments withsyntactic priming showed that children?s represen-tations of abstract passive constructions are well-developed as early as age 3 or 4, and young946children are generally able to form passive con-structions with both action and non-action verbs(Thatcher et al, 2007).
These results suggest thatmeasures of syntactic complexity that are typicallyused to evaluate adult language could be adaptedto child speech, provided that the children are atleast 3 or 4 years old.Here, the complexity of speech is character-ized by the length of utterances and by the fre-quency of dependent and coordinate clauses, withmore complex speech consisting of longer utter-ances and a higher number of subordinate clauses.We segmented the transcriptions into sentences,clauses and T-units, which are ?minimally ter-minable units?
consisting of a main clause andits dependent clauses (Hunt, 1965; O?Donnell etal., 1967)1.
Deceptive communication generallyhas shorter duration and is less detailed than non-deceptive speech (DePaulo et al, 2003), so thelength of each type of segment was counted alongwith frequency features over segments.
Here, thefrequency of dependent and coordinate clauses perconstituent approximate clause-based measures ofcomplexity.Our approach combines a set of features ob-tained from a functional dependency grammar(FDG) parser with another (non-overlapping) setof features obtained from a phrase-based grammarparser.
We obtained FDG parses of the transcrip-tions using Connexor?s Machinese Syntax parser(Tapanainen and Ja?rvinen, 1997) and extracted thefollowing 5 features:ARI Automated readability index.
Measuresword and sentence difficulty, 4.71 cw +0.5ws ?21.43, where c is the number of characters, wis the number of words, and s is the numberof sentences (Smith and Senter, 1967).ASL Average sentence length.
The number ofwords over the number of sentences.COM Sentence complexity.
The ratio of sen-tences with ?
2 finite predicators to thosewith ?
1 finite predicator (Stajner andMitkov, 2012).PAS Passivity.
The ratio of non-finite mainpredicators in a passive construction (@?1T-units include single clauses, two or more phrases in ap-position, or clause fragments.
Generally, coordinate clausesare split into separate T-units, as are clauses interrupted bydiscourse boundary markers.FMAINV %VP) to the total number of fi-nite (@+FMAINV %VA) and non-finite (@?FMAINV %VA and @?FMAINV %VP)main predicators, including active construc-tions.MCU Mean number of clauses per utterance.Additionally, we searched for specific syntacticpatterns in phrase-based parses of the data.
Weused the Stanford probabilistic natural languageparser (Klein and Manning, 2003) for construct-ing these parse trees, the Stanford Tregex utility(Levy and Andrew, 2006) for searching the con-structed parse trees, and a tool provided by Lu(2011) which extracts a set of 14 clause-based fea-tures in relation to sentence, clause and T-unit con-stituents.4.1 Feature analysisAnalysis of variance (ANOVA) was performed onthe set of 17 features, shown in Table 1.
A one-factor ANOVA across the truth and lie groupsshowed three significant feature variations: aver-age sentence length (ASL), sentence complexity(COM), and mean clauses per utterance (MCU).Dependencies between some feature pairs that arepositively correlated are shown in Figure 1.As expected, the number of clauses (MCU) isdependent on sentence length (ASL) (r(344) =.92, p < .001).
Also, the number of T-units is de-pendent on the number of clauses: CN/C is corre-lated with CN/T (r(344) = .89, p < .001), CP/Cis correlated with CP/T (r(344) = .85, p < .001),and DC/C is correlated with DC/T (r(344) = .92,p < .001).
Other features are completely un-correlated.
For example, the number of passiveconstructions is independent of sentence length(r(344) = ?.0020, p > .05), the number of com-plex nominals per clause is independent of clauselength (r(344) = .076, p > .05), and the densityof dependent clauses is independent of the densityof coordinate phrases (r(344) = ?.027, p > .05).5 ResultsWe evaluate five classifiers: logistic regres-sion (LR), a multilayer perceptron (MLP), na?
?veBayes (NB), a random forest (RF), and a supportvector machine (SVM).
Here, na?
?ve Bayes, whichassumes conditional independence of the features,and logistic regression, which has a linear deci-sion boundary, are baselines.
The MLP includes avariable number of layers of hidden units, which947Figure 1: Independent and dependent feature pairs; data points are labeled as truth (blue) and lie (green).Feature F1,344 dAutomated Readability Index (ARI) 0.187 0.047Average Sentence Length (ASL) 3.870 0.213Sentence Complexity (COM) 10.93 0.357Passive Sentences (PAS) 1.468 0.131Mean Clauses per Utterance (MCU) 6.703 0.280Mean Length of T-Unit (MLT) 2.286 0.163Mean Length of Clause (MLC) 0.044 -0.023Verb Phrases per T-Unit (VP/T) 3.391 0.199Clauses per T-Unit (C/T) 2.345 0.166Dependent Clauses per Clause (DC/C) 1.207 0.119Dependent Clauses per T-Unit (DC/T) 1.221 0.119T-Units per Sentence (T/S) 3.692 0.208Complex T-Unit Ratio (CT/T) 2.103 0.157Coordinate Phrases per T-Unit (CP/T) 0.463 -0.074Coordinate Phrases per Clause (CP/C) 0.618 -0.085Complex Nominals per T-Unit (CN/T) 0.722 0.092Complex Nominals per Clause (CN/C) 0.087 0.032Table 1: One-factor ANOVA (F statistics and Co-hen?s d-values, ?
= 0.05) on all features acrosstruth and lie groups.
Statistically significant re-sults are in bold.apply non-linear activation functions on a linearcombination of inputs.
The SVM is a paramet-ric binary classifier that provides highly non-lineardecision boundaries given particular kernels.
Therandom forest is an ensemble classifier that returnsthe mode of the class predictions of several deci-sion trees.5.1 Binary classification across all dataThe five classifiers were evaluated on the entirepooled data set with 10-fold cross validation.
Ta-ble 2 lists the parameters varied for each classi-fier, and Table 3 shows the cross-validation accu-racy for the classifiers with the best parameter set-tings.
The na?
?ve Bayes classifier performs poorly,as could be expected given the assumption of con-ditional feature independence.
The SVM classifierperforms best, with 59.5% cross-validation accu-racy, which is a statistically significant improve-ment over the baselines of LR (t(4) = 22.25, p <.0001), and NB (t(4) = 16.19, p < .0001).Parameter ValuesLR R Ridge value 10?10 to 10?2MLPL Learning rate 0.0003 to 0.3M Momentum 0 to 0.5H Number of hiddenlayers1 to 5NB K Use kernelestimatortrue, falseRFI Number of trees 1 to 20K Maximum depth unlimited, 1 to 10SVMK Kernel Linear, RBF,PolynomialE PolynomialExponent2 to 5G RBF Gamma 0.001 to 0.1C Complexityconstant0.1 to 10Table 2: Empirical parameter settings for eachclassifier5.2 Binary classification by age groupSignificant variation in syntactic complexity is ex-pected across ages.
To account for such variation,we segmented the dataset in four groups: 44 tran-948Accuracy ParametersLR 0.5347 R = 10?10MLP 0.5838 L = 0.003, M = 0.4NB 0.5173 K = falseRF 0.5809 I = 10, K = 6SVM 0.5954 Polynomial, E = 3, C = 1Table 3: Cross-validation accuracy of binary clas-sification performed on entire dataset of 346 tran-scriptions.scriptions of 4-year-olds, 120 of 5-year-olds, 94 of6-year-olds, and 88 of 7-year-olds.
By compari-son, Vrij et al (2004) used data from only 35 chil-dren in their study of 5- and 6-year-olds.
Classi-fication of truthfulness was performed separatelyfor each age, as shown in Table 4.
In compar-ison with classification accuracy on pooled data,a paired t-test shows statistically significant im-provement across all age groups using RF, t(3) =10.37, p < .005.Age (years)4 5 6 7LR 0.6136 0.5333 0.5957* 0.4886MLP 0.6136?
0.5583 0.6170?
0.5909*NB 0.6136* 0.5250 0.5426 0.5682RF 0.6364?
0.6333* 0.6383?
0.6591?SVM 0.6591 0.5583 0.6064 0.6250*Table 4: Cross-validation accuracy of binary clas-sification partitioned by age.
The best classifier ateach age is shown in bold.
The classifiers showingstatistically significant incremental improvementare marked: *p < .05, ?p < .001 (paired t-test,d.f.
4)5.3 Binary classification by age group, onverbose transcriptionsThe length of speech, in number of words, varieswidely (min = 1, max = 167, ?
= 36.83,?
= 28.34) as a result of the unregulated natureof the interview interaction.
To test the effect ofverbosity, we segment the data by child age andselect only the transcriptions with above-averageword counts (i.e., ?
37 words), resulting in fourgroups: 12 transcriptions of 4-year-olds, 48 of 5-year-olds, 39 of 6-year-olds, and 37 of 7-year-olds.This mimics the scenario in which some mini-mum threshold is placed on the length of a child?sspeech.
In this verbose case, 63.3% of transcriptsare labeled truth across age groups (using the samedefinition of truth as in section 3), with no sub-stantial variation between ages; in the non-verbosecase, 53.2% are marked truth.
Fisher?s exact teston this contingency table reveals no significant dif-ference between these distributions (p = 0.50).Classification results are shown in Table 5.
Thesize of the training set for the youngest age cat-egory is low compared to the other age groups,which may reduce the reliability of the higher ac-curacy achieved in that group.
The other three agegroups show a growing trend, which is consistentwith expectations ?
older children exhibit greatersyntactic complexity in speech, allowing greatervariability of feature values across truth and de-ception.
Here, both SVM and RF achieve 83.8%cross-validation accuracy in identifying deceptionin the speech of 7-year-old subjects.4 5 6 7LR 0.7500?
0.5417 0.6667?
0.7297?MLP 0.8333?
0.6250?
0.6154 0.7838?NB 0.6667?
0.4583 0.4103 0.7297*RF 0.8333?
0.5625 0.7179?
0.8378?SVM 0.9167* 0.6250?
0.6154* 0.8378?Table 5: Cross-validation accuracy of binary clas-sification performed on transcriptions with aboveaverage word count (136 transcriptions), by agegroup.
Rows represent classifiers, columns repre-sent ages.
The best classifier for each age is inbold.
The classifiers showing statistically signifi-cant incremental improvement are marked: *p <.05, ?p < .001 (paired t-test, d.f.
4)5.4 Threshold variationTo study the effect of the threshold between thetruth and lie classes, we vary the value of thethreshold, ?
, from 1 to 8, requiring the admissionof at least ?
truthful details (out of 8 possible de-tails) in order to label a transcription as truth.
Theeffect of ?
on classification accuracy over the en-tire pooled dataset for each of the 5 classifiers isshown in Figure 2.
A one-factor ANOVA with?
as the independent variable with 8 levels, andcross-validation accuracy as the dependent vari-able, confirms that the effect of the threshold is sta-tistically significant (F7,40 = 220.69, p < .0001)with ?
= 4 being the most conservative setting.949Figure 2: Effect of threshold and classifier choiceon cross-validation accuracy.
Threshold ?
= 0 isnot present, since all data would be labeled truth.5.5 Linguistic Inquiry and Word CountThe Linguistic Inquiry and Word Count (LIWC)tool for generating features based on word cate-gory frequencies has been used in deception de-tection with adults, specifically: first-person sin-gular pronouns (FP), exclusive words (EW), nega-tive emotion words (NW), and motion verbs (MV)(Newman et al, 2003).
We compare the perfor-mance of classifiers trained with our 17 syntacticfeatures to those of classifiers trained with thoseLIWC-based features on the same data.
To evalu-ate the four LIWC categories, we use the 86 wordsof the Pennebaker model (Little and Skillicorn,2008; Vartapetiance and Gillam, 2012).
The per-formance of the classifiers trained with LIWC fea-tures is shown in Table 6.The set of 17 syntactic features proposed hereresult in significantly higher accuracies acrossclassifiers and experiments (?
= 0.63, ?
= 0.10)than with the LIWC features used in previouswork (?
= 0.58, ?
= 0.09), as shown in Figure 3(t(53) = ?0.0691, p < .0001).6 Discussion and future workThis paper evaluates automatic estimation of truth-fulness in the utterances of children using a novelset of lexical-syntactic features across five typesof classifiers.
While previous studies have favoredword category frequencies extracted with LIWC(Newman et al, 2003; Little and Skillicorn, 2008;Hauch et al, 2012; Vartapetiance and Gillam,Figure 3: Effect of feature set choice on cross-validation accuracy.2012; Almela et al, 2012; Fornaciari and Poesio,2012), our results suggest that the set of syntac-tic features presented here perform significantlybetter than the LIWC feature set on our data, andacross seven out of the eight experiments based onage groups and verbosity of transcriptions.Statistical analyses showed that the average sen-tence length (ASL), the Stajner-Mitkov measureof sentence complexity (COM), and the meannumber of clauses per utterance (MCU) are thefeatures most predictive of truth and deception(see section 4.1).
Further preliminary experi-ments are exploring two methods of feature se-lection, namely forward selection and minimum-Redundancy-Maximum-Relevance (mRMR).
Inforward selection, features are greedily added one-at-a-time (given an initially empty feature set) un-til the cross-validation error stops decreasing withthe addition of new features (Deng, 1998).
Thisresults in a set of only two features: sentencecomplexity (COM) and T-units per sentence (T/S).Features are selected in mRMR by minimizingredundancy (i.e., the average mutual informationbetween features) and maximizing the relevance(i.e., the mutual information between the givenfeatures and the class) (Peng et al, 2005).
Thisapproach selects five features: verb phrases per T-unit (VP/T), passive sentences (PAS), coordinatephrases per clause (CP/C), sentence complexity(COM), and complex nominals per clause (CN/C).These results confirm the predictive strength ofsentence complexity.
Further, preliminary classi-950Group Accuracy Best Classifier ParametersEntire dataset 0.5578 RF I = 20, K = unlimited4-yr-olds 0.5682 MLP L = 0.005, M = 0.3, H = 15-yr-olds 0.5583 RF I = 5, K = unlimited6-yr-olds 0.5319 MLP L = 0.005, M = 0.3, H = 17-yr-olds 0.6591 RF I = 5, K = unlimited4-yr-olds, verbose 0.8333 SVM PolyKernel, E = 4, C = 105-yr-olds, verbose 0.7083 SVM NormalizedPolyKernel, E = 1, C = 106-yr-olds, verbose 0.6154 MLP L = 0.09, M = 0.2, H = 17-yr-olds, verbose 0.7027 MLP L = 0.01, M = 0.5, H = 3Table 6: Best 10-fold cross-validation accuracies achieved on various subsets of the data, using theLIWC-based feature set.fication results across all classifiers suggest thataccuracies are significantly higher given forwardselection (?
= 0.58, ?
= 0.02) relative to theoriginal feature set (?
= 0.56, ?
= 0.03); t(5) =?2.28, p < .05 while the results given the mRMRfeatures are not significantly different.Generalized cross-validation accuracy increasessignificantly given partitioned age groups, whichsuggests that the importance of features may bemoderated by age.
A further incremental in-crease is achieved by considering only transcrip-tions above a minimum length.
O?Donnell etal.
(1967) examined syntactic complexity in thespeech and writing of children aged 8 to 12, andfound that speech complexity increases with age.This phenomenon appears to be manifested in thecurrent study by the extent to which classificationincreases generally across the 5-, 6-, and 7-year-old groups, as shown in Table 5.
Future examina-tion of the effect of age on feature saliency mayyield more appropriate age-dependent features.While past research has used logistic regressionas a binary classifier (Newman et al, 2003), ourexperiments show that the best-performing classi-fiers allow for highly non-linear class boundaries;SVM and RF models achieve between 62.5% and91.7% accuracy across age groups ?
a significantimprovement over the baselines of LR and NB,as well as over previous results.
Moreover, sincethe performance of human judges in identifyingdeception is not significantly better than chance(Lewis et al, 1989; Newman et al, 2003), theseresults show promise in the use of automatic de-tection methods.Partially truthful transcriptions were scored us-ing a gradient of 0 to 8 truthful details, and athreshold ?
was used to perform binary classifica-tion.
Extreme values of ?
lead to poor F-scores de-spite high accuracy, since the class distribution oftranscriptions is very skewed towards either class.Future work can explore the effect of thresholdvariation given sufficient data with even class dis-tributions for each threshold setting.
When suchdata is unavailable, experiments can make use ofthe most conservative setting (?
= 4, or an equiv-alent mid-way setting) for analysis of real-life ut-terances containing partial truths.Future work should consider measures of con-fidence for each classification, where possible, sothat more ambiguous classifications are not treatedon-par with more certain ones.
For instance, con-fidence can be approximated in MLPs by the en-tropy across continuous-valued output nodes, andin RFs by the number of component decision treesthat agree on a classification.
Although acousticdata were not provided with this data set (Lyonand Dorado, 2008) (and, in practice, cannot be as-sured), future work should also examine the dif-ferences in the acoustics of children across truthconditions.AcknowledgmentsThe authors thank Kang Lee (Ontario Institute forStudies in Education, University of Toronto) andAngela Evans (Brock University) for sharing boththis data set and their insight.951AppendixThe following is an example of evasive deceptivespeech from a 6-year-old after no truth induction(i.e., the control condition in which the interviewermerely states that he needs to ask more questions):... Yeah yeah ok, I?m a tell you.
Weplayed that same game and I won andhe won.
I?m going to be in trouble if Itell you.
It a secret.
It?s a secret ?cuzwe?re friends.
...Transcription excerpt labeled as truth by athreshold of ?
= 1: 7-year-old child?s response(play, no coach condition), in which the child doesnot explicitly deny playing with the toy house, andadmits to looking at it but does not confess to anyof the other six actions:...I was playing, I was hiding the coinand I was trying to find the house... try-ing to see who was in there...Transcription excerpt labeled as truth by athreshold of ?
= 4: 7-year-old child?s response(play, no coach condition), in which the child doesnot explicitly deny playing, and admits to three ac-tions:...me and him was playing with it... wewere just spinning it around and got thetoys out...ReferencesAngela Almela, Rafael Valencia-Garcia, and PascualCantos.
2012.
Seeing through deception: A compu-tational approach to deceit detection in written com-munication.
Proceedings of the EACL 2012 Work-shop on Computational Approaches to DeceptionDetection, April 23-27, 2012, Avignon, France, 15-22.Ethem Alpaydin.
2010.
Introduction to MachineLearning.
Cambridge, MA: MIT Press.Kan Deng.
1998.
OMEGA: On-line memory-basedgeneral purpose system classifier.
Doctoral thesis,School of Computer Science, Carnegie Mellon Uni-versityBella M. DePaulo, James J. Lindsay, Brian E. Mal-one, Laura Muhlenbruck, Kelly Charlton, and Har-ris Cooper.
2003.
Cues to deception.
PsychologicalBulletin, 129(1):74-118.Song Feng, Ritwik Banerjee and Yejin Choi.
2012.Syntactic stylometry for deception detection.
Pro-ceedings of the 50th Annual Meeting of the Associa-tion for Computational Linguistics, July 8-14, 2012,Jeju, Republic of Korea, 171-175.Tommaso Fornaciari and Massimo Poesio.
2012.
Onthe use of homogeneous sets of subjects in deceptivelanguage analysis.
Proceedings of the EACL 2012Workshop on Computational Approaches to Decep-tion Detection, April 23-27, 2012, Avignon, France,39-47.Martin Graciarena, Elizabeth Shriberg, Andreas Stol-cke, Frank Enos, Julia Hirschberg, Sachin Kajarekar.2006.
Combining prosodic lexical and cepstral sys-tems for deceptive speech detection.
Proceedingsof the IEEE International Conference on Acoustics,Speech, and Signal Processing (ICASSP), pages I-1033-I-1036.Valerie Hauch, Jaume Masip, Iris Blandon-Gitlin, andSiegfried L. Sporer.
2012.
Linguistic cues to de-ception assessed by computer programs: A meta-analysis.
Proceedings of the EACL Workshop onComputational Approaches to Deception Detection,pages 1-4.Julia Hirschberg, Stefan Benus, Jason M. Brenier,Frank Enos, Sarah Friedman, Sarah Gilman, CynthiaGirand, Martin Graciarena, Andreas Kathol, LauraMichaelis, Bryan Pellom, Elizabeth Shriberg, andAndreas Stolcke.
2005.
Distinguishing deceptivefrom non-deceptive speech.
Proceedings of Eu-rospeech 2005, pages 1833-1836.Kellogg W. Hunt.
1965.
Grammatical structures writ-ten at three grade levels.
NCTE Research Report No.3.Dan Klein and Christopher Manning.
2003.
Accurateunlexicalized parsing.
Proceedings of the 41st An-nual Meeting of the Association for ComputationalLinguistics, pages 423-430.Xuan Le, Ian Lancashire, Graeme Hirst, and ReginaJokel.
2011.
Longitudinal detection of dementiathrough lexical and syntactic changes in writing: acase study of three British novelists.
Literary andLinguistic Computing, 26(4):435-461.Roger Levy and Galen Andrew.
2006.
Tregex andTsurgeon: tools for querying and manipulating treedata structures.
5th International Conference onLanguage Resources and Evaluation.Michael Lewis, Catherine Stanger, and Margaret W.Sullivan.
1989.
Deception in 3-year-olds.
Devel-opmental Psychology, 25(3):439-443.A.
Little and D. B. Skillicorn.
2008.
Detecting de-ception in testimony.
Proceedings of IEEE Interna-tional Conference of Intelligence and Security Infor-matics (ISI 2008), June 17-20, 2008, Taipei, Taiwan,13-18.952Xiaofei Lu.
2011.
Automatic analysis of syntacticcomplexity in second language writing.
Interna-tional Journal of Corpus Linguistics, 15(4):474-496.Thomas D. Lyon and J. S. Dorado.
2008.
Truth in-duction in young maltreated children: the effects ofoath-taking and reassurance on true and false disclo-sures.
Child Abuse & Neglect, 32(7):738-748.Thomas D. Lyon, Lindsay C. Malloy, Jodi A. Quas,and Victoria A. Talwar.
2008.
Coaching, truth in-duction, and young maltreated children?s false al-legations and false denials.
Child Development,79(4):914-929.Franc?ois Mairesse, Marilyn A. Walker, Matthias R.Mehl, and Roger K. Moore.
2007.
Using linguis-tic cues for the automatic recognition of personalityin conversation and text.
Journal of Artificial Intel-ligence Research, 30:457-500.Rada Mihalcea and Carlo Strapparava.
2009.
The liedetector: explorations in the automatic recognitionof deceptive language.
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, August 4,2009, Suntec, Singapore, 309-312.Matthew L. Newman, James W. Pennebaker, Diane S.Berry, and Jane M. Richards.
2003.
Lying words:predicting deception from linguistic styles.
PSPB,29(5):665-675.Roy C. O?Donnell, William J. Griffin, and RaymondC.
Norris.
1967.
A transformational analysis of oraland written grammatical structures in the languageof children in grades three, five, and seven.
PSPB,29(5):665-675.Steven Pinker.
1984.
Language learnability and lan-guage development, Cambridge, MA: Harvard Uni-versity Press.Steven Pinker, David S. Lebeaux, and Loren Ann Frost.1987.
Productivity and constraints in the acquisitionof the passive.
Cognition, 26:195-267.Hanchuan Peng, Fuhui Long, and Chris Ding.
2005.Feature selection based on mutual information: cri-teria of max-dependency, max-relevance, and min-redundancy.
IEEE Transactions on Pattern Analysisand Machine Intelligence, 27(8):1226-1238.J.
M. Richards and J. J.
Gross.
1999.
Composure atany cost?
The cognitive consequences of emotionsuppression.
PSPB, 25(8):1033-1044.J.
M. Richards and J. J.
Gross.
2000.
Emotion regu-lation and memory: the cognitive costs of keepingone?s cool.
Journal of Personality and Social Psy-chology, 79:410-424.E.
A. Smith and R. J. Senter.
1967.
Automated read-ability index.
Technical report, Defense TechnicalInformation Center.
United States.Sanja Stajner and Ruslan Mitkov.
2012.
Diachronicchanges in text complexity in 20th century Englishlanguage: an NLP Approach.
Proceedings of the In-ternational Conference on Language Resources andEvaluation (LREC), pages 1577-1584.Pasi Tapanainen and Timo Ja?rvinen.
1997.
A non-projective dependency parser.
Proceedings of the5th Conference on Applied Natural Language Pro-cessing, pages 64-71.Katherine Thatcher, Holly Branigan, Janet McLean,and Antonella Sorace.
2007.
Children?s early acqui-sition of the passive: evidence from syntactic prim-ing.
Child Language Seminar, University of Read-ing.Udo Undeutsch.
2008.
Courtroom evaluation of eye-witness testimony.
Applied Psychology, 33(1):51-66.Anna Vartapetiance and Lee Gillam.
2012.
?I don?tknow where he is not?
: does deception research yetoffer a basis for deception detectives?
Proceedingsof the EACL 2012 Workshop on Computational Ap-proaches to Deception Detection, April 23-27, 2012,Avignon, France, 5-14.Aldert Vrij, Lucy Akehurst, Stavroula Soukara, andRay Bull.
2004.
Detecting deceit via analysesof verbal and nonverbal behavior in children andadults.
Human Communication Research, 30(1):8?41Yi Zheng, Qifeng Dai, Qiming Luo, and Enhong Chen.2010.
Hedge classification with syntactic depen-dency features based on an ensemble classifier.
Pro-ceedings of the Fourteenth Conference on Compu-tational Natural Language Learning, July 15-16,2010, Uppsala, Sweden, 151-156.953
