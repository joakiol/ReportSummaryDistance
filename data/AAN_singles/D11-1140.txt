Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1512?1523,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsLexical Generalization in CCG Grammar Induction for Semantic ParsingTom Kwiatkowski?t.m.kwiatkowksi@sms.ed.ac.ukLuke Zettlemoyer?lsz@cs.washington.eduSharon Goldwater?sgwater@inf.ed.ac.ukMark Steedman?steedman@inf.ed.ac.uk?School of InformaticsUniversity of EdinburghEdinburgh, EH8 9AB, UK?Computer Science & EngineeringUniversity of WashingtonSeattle, WA 98195AbstractWe consider the problem of learning fac-tored probabilistic CCG grammars for seman-tic parsing from data containing sentencespaired with logical-form meaning representa-tions.
Traditional CCG lexicons list lexicalitems that pair words and phrases with syntac-tic and semantic content.
Such lexicons canbe inefficient when words appear repeatedlywith closely related lexical content.
In thispaper, we introduce factored lexicons, whichinclude both lexemes to model word meaningand templates to model systematic variation inword usage.
We also present an algorithm forlearning factored CCG lexicons, along with aprobabilistic parse-selection model.
Evalua-tions on benchmark datasets demonstrate thatthe approach learns highly accurate parsers,whose generalization performance benefitsgreatly from the lexical factoring.1 IntroductionSemantic parsers automatically recover representa-tions of meaning from natural language sentences.Recent work has focused on learning such parsersdirectly from corpora made up of sentences pairedwith logical meaning representations (Kate et al,2005; Kate and Mooney, 2006; Wong and Mooney,2006, 2007; Zettlemoyer and Collins, 2005, 2007;Lu et al, 2008; Kwiatkowski et al, 2010).For example, in a flight booking domain wemight have access to training examples such as:Sentence: I want flights from BostonMeaning: ?x.
f light(x)?
f rom(x,bos)and the goal is to learn a grammar that can map new,unseen, sentences onto their corresponding mean-ings, or logical forms.One approach to this problem has developed al-gorithms for leaning probabilistic CCG grammars(Zettlemoyer and Collins, 2005, 2007; Kwiatkowskiet al, 2010).
These grammars are well-suited to thetask of semantic parsing, as they closely link syn-tax and semantics.
They can be used to model awide range of complex linguistic phenomena and arestrongly lexicalized, storing all language-specificgrammatical information directly with the words inthe lexicon.
For example, a typical learned lexiconmight include entries such as:(1) f light `N :?x.
f light(x)(2) f light `N/(S|NP) :?
f?x.
f light(x)?
f (x)(3) f light `N\N :?
f?x.
f light(x)?
f (x)(4) f are`N :?x.cost(x)(5) f are`N/(S|NP) :?
f?x.cost(x)?
f (x)(6) f are`N\N :?
f?x.cost(x)?
f (x)(7) Boston`NP :bos(8) Boston`N\N :?
f?x.
f rom(x,bos)?
f (x)(9) New York `NP :nyc(10) New York `N\N :?
f?x.
f rom(x,nyc)?
f (x)Although lexicalization of this kind is usefulfor learning, as we will see, these grammars canalso suffer from sparsity in the training data, sinceclosely related entries must be repeatedly learned forall members of a certain class of words.
For exam-ple, the list above shows a selection of lexical itemsthat would have to be learned separately.In this list, the word ?flight?
is paired with thepredicate flight in three separate lexical items whichare required for different syntactic contexts.
Item1512(1) has the standard N category for entries of thistype, item (2) allows the use of the word ?flight?with that-less relative clauses such as ?flight depart-ing Boston?, and item (3) is useful for phrases withunconventional word order such as ?from Bostonflight to New York?.
Representing these three lexi-cal items separately is inefficient, since each word ofthis class (such as ?fare?)
will require three similarlystructured lexical entries differing only in predicatename.
There may also be systemtatic semantic vari-ation between entries for a certain class of words.For example, in (6) ?Boston?
is paired with the con-stant bos that represents its meaning.
However, item(7) also adds the predicate from to the logical form.This might be used to analyse somewhat elliptical,unedited sentences such as ?Show me flights Bostonto New York,?
which can be challenging for seman-tic parsers (Zettlemoyer and Collins, 2007).This paper builds upon the insight that a large pro-portion of the variation between lexical items fora given class of words is systematic.
Therefore itshould be represented once and applied to a small setof basic lexical units.
1 We develop a factored lex-icon that captures this insight by distinguishing lex-emes, which pair words with logical constants, fromlexical templates, which map lexemes to full lexicalitems.
As we will see, this can lead to a significantlymore compact lexicon that can be learned from lessdata.
Each word or phrase will be associated with afew lexemes that can be combined with a shared setof general templates.We develop an approach to learning factored,probabilistic CCG grammars for semantic pars-ing.
Following previous work (Kwiatkowski et al,2010), we make use of a higher-order unificationlearning scheme that defines a space of CCG gram-mars consistent with the (sentence, logical form)training pairs.
However, instead of constructingfully specified lexical items for the learned grammar,we automatically generate sets of lexemes and lexi-cal templates to model each example.
This is a dif-ficult learning problem, since the CCG analyses that1A related tactic is commonly used in wide-coverage CCGparsers derived from treebanks, such as work by Hockenmaierand Steedman (2002) and Clark and Curran (2007).
Theseparsers make extensive use of category-changing unary rules,to avoid data sparsity for systematically related categories (suchas those related by type-raising).
We will automatically learn torepresent these types of generalizations in the factored lexicon.are required to construct the final meaning represen-tations are not explicitly labeled in the training data.Instead, we model them with hidden variables anddevelop an online learning approach that simultane-ously estimates the parameters of a log-linear pars-ing model, while inducing the factored lexicon.We evaluate the approach on the benchmark Atisand GeoQuery domains.
This is a challenging setup,since the GeoQuery data has complex meaning rep-resentations and sentences in multiple languages,while the Atis data contains spontaneous, uneditedtext that can be difficult to analyze with a formalgrammar representation.
Our approach achieves ator near state-of-the-art recall across all conditions,despite having no English or domain-specific infor-mation built in.
We believe that ours is the only sys-tem of sufficient generality to run with this degree ofsuccess on all of these datasets.2 Related workThere has been significant previous work on learn-ing semantic parsers from training sentences la-belled with logical form meaning representations.We extend a line of research that has addressedthis problem by developing CCG grammar induc-tion techniques.
Zettlemoyer and Collins (2005,2007) presented approaches that use hand gener-ated, English-language specific rules to generate lex-ical items from logical forms as well as Englishspecific type-shifting rules and relaxations of theCCG combinators to model spontaneous, uneditedsentences.
Zettlemoyer and Collins (2009) extendsthis work to the case of learning in context depen-dent environments.
Kwiatkowski et al (2010) de-scribed an approach for language-independent learn-ing that replaces the hand-specified templates witha higher-order-unification-based lexical inductionmethod, but their approach does not scale well tochallenging, unedited sentences.
The learning ap-proach we develop for inducing factored lexicons isalso language independent, but scales well to thesechallenging sentences.There have been a number of other approachesfor learning semantic parsers, including ones basedon machine translation techniques (Papineni et al,1997; Ramaswamy and Kleindienst, 2000; Wongand Mooney, 2006), parsing models (Miller et al,1996; Ge and Mooney, 2006; Lu et al, 2008), in-1513ductive logic programming algorithms (Zelle andMooney, 1996; Thompson and Mooney, 2002; Tangand Mooney, 2000), probabilistic automata (He andYoung, 2005, 2006), and ideas from string kernelsand support vector machines (Kate and Mooney,2006; Nguyen et al, 2006).More recent work has focused on training se-mantic parsers without supervision in the form oflogical-form annotations.
Clarke et al (2010) andLiang et al (2011) replace semantic annotations inthe training set with target answers which are moreeasily available.
Goldwasser et al (2011) presentwork on unsupervised learning of logical form struc-ture.
However, all of these systems require signifi-cantly more domain and language specific initializa-tion than the approach presented here.Other work has learnt semantic analyses from textin the context of interactions in computational envi-ronments (Branavan et al (2010), Vogel and Juraf-sky (2010)); text grounded in partial observations ofa world state (Liang et al, 2009); and from raw textalone (Poon and Domingos, 2009, 2010).There is also related work that uses the CCGgrammar formalism.
Clark and Curran (2003)present a method for learning the parameters of alog-linear CCG parsing model from fully annotatednormal?form parse trees.
Watkinson and Manand-har (1999) describe an unsupervised approach forlearning syntactic CCG lexicons.
Bos et al (2004)present an algorithm for building semantic represen-tations from CCG parses but requires fully?specifiedCCG derivations in the training data.3 Overview of the ApproachHere we give a formal definition of the problem andan overview of the learning approach.Problem We will learn a semantic parser thattakes a sentences x and returns a logical form z repre-senting its underlying meaning.
We assume we haveinput data {(xi,zi)|i = 1 .
.
.n} containing sentencesxi and logical forms zi, for example xi =?Show meflights to Boston?
and zi = ?x.
f light(x)?
to(x,bos).Model We will represent the parser as a factored,probabilistic CCG (PCCG) grammar.
A traditionalCCG lexical item would fully specify the syntax andsemantics for a word (reviewed in Section 4).
Forexample, Boston`NP : bos represents the entry forthe word ?Boston?
with syntactic category NP andmeaning represented by the constant bos.
Where alexicon would usually list lexical items such as this,we instead use a factored lexicon (L,T ) containing:?
A list of lexemes L. Each lexeme pairs a wordor phrase with a list of logical constants that canbe used to construct its meaning.
For example,one lexeme might be (Boston, [bos]).?
A list of lexical templates T .
Each templatetakes a lexeme and maps it on to a full lexicalitem.
For example, there is a single templatethat can map the lexeme above to the final lex-ical entry Boston `NP : bos.We will make central use of this factored repre-sentation to provide a more compact representationof the lexicon that can be learned efficiently.The factored PCCG will also contain a parametervector, ?
, that defines a log-linear distribution overthe possible parses y, conditioned on the sentence x.Learning Our approach for learning factored PC-CGs extends the work of Kwiatkowski et al (2010),as reviewed in Section 7.
Specifically, we modifythe lexical learning, to produce lexemes and tem-plates, as well as the feature space of the model, butreuse the existing parameter estimation techniquesand overall learning cycle, as described in Section 7.We present the complete approach in three partsby describing the factored representation of the lex-icon (Section 5), techniques for proposing potentialnew lexemes and templates (Section 6), and finallya complete learning algorithm (Section 7).
How-ever, the next section first reviews the required back-ground on semantic parsing with CCG.4 Background4.1 Lambda CalculusWe represent the meanings of sentences, wordsand phrases with logical expressions that can con-tain constants, quantifiers, logical connectors andlambda abstractions.
We construct the meanings ofsentences from the meanings of words and phrasesusing lambda-calculus operations.
We use a versionof the typed lambda calculus (Carpenter, 1997), inwhich the basic types include e, for entities; t, fortruth values; and i for numbers.
We also have func-tion types that are assigned to lambda expressions.1514The expression ?x.
f light(x) takes an entity and re-turns a truth value, and has the function type ?e, t?.4.2 Combinatory Categorial GrammarCCG (Steedman, 1996, 2000) is a linguistic formal-ism that tightly couples syntax and semantics, andcan be used to model a wide range of language phe-nomena.
A traditional CCG grammar includes a lex-icon ?
with entries like the following:f lights`N :?x.
f light(x)to` (N\N)/NP :?y.?
f .?x.
f (x)?
to(x,y)Boston`NP :boswhere each lexical item w`X : h has words w, a syn-tactic category X , and a logical form h. For the firstexample, these are ?flights,?
N, and ?x.
f light(x).In this paper, we introduce a new way of represent-ing lexical items as (lexeme, template) pairs, as de-scribed in section 5.CCG syntactic categories may be atomic (suchas S or NP) or complex (such as (N\N)/NP)where the slash combinators encode word orderinformation.
CCG uses a small set of combinatoryrules to build syntactic parses and semantic repre-sentations concurrently.
Two example combinatoryrules are forward (>) and backward (<) application:X/Y : f Y : g ?
X : f (g) (>)Y : g X\Y : f ?
X : f (g) (<)These rules apply to build syntactic and semanticderivations under the control of the word order infor-mation encoded in the slash directions of the lexicalentries.
For example, given the lexicon above, thephrase ?flights to Boston?
can be parsed to produce:flights to BostonN (N\N)/NP NP?x.
f light(x) ?y?
f?x.
f (x)?
to(x,y) bos>(N\N)?
f?x.
f (x)?
to(x,bos)<N?x.
f light(x)?
to(x,bos)where each step in the parse is labeled with the com-binatory rule (?> or ?<) that was used.CCG also includes combinatory rules of forward(> B) and backward (< B) composition:X/Y : f Y/Z : g?
X/Z : ?x.
f (g(x)) (> B)Y\Z : g X\Y : f ?
X\Z : ?x.
f (g(x)) (< B)These rules allow a relaxed notion of constituencywhich helps limit the number of distinct CCG lexicalitems required.To the standard forward and backward slashes ofCCG we also add a vertical slash for which the di-rection of application is underspecified.
We shall seeexamples of this in Section 10.4.3 Probabilistic CCGsDue to ambiguity in both the CCG lexicon and theorder in which combinators are applied, there willbe many parses for each sentence.
We discriminatebetween competing parses using a log-linear modelwhich has a feature vector ?
and a parameter vector?
.
The probability of a parse y that returns logicalform z, given a sentence x is defined as:P(y,z|x;?
,?)
= e?
??(x,y,z)?(y?,z?)
e?
??(x,y?,z?)
(1)Section 8 fully defines the set of features used in thesystem presented.
The most important of these con-trol the generation of lexical items from (lexeme,template) pairs.
Each (lexeme, template) pair usedin a parse fires three features as we will see in moredetail later.The parsing, or inference, problem done at testtime requires us to find the most likely logical formz given a sentence x, assuming the parameters ?
andlexicon ?
are known:f (x) = argmaxz p(z|x;?
,?)
(2)where the probability of the logical form is found bysumming over all parses that produce it:p(z|x;?
,?)
=?yp(y,z|x;?
,?)
(3)In this approach the distribution over parse trees yis modeled as a hidden variable.
The sum overparses in Eq.
3 can be calculated efficiently usingthe inside-outside algorithm with a CKY-style pars-ing algorithm.To estimate the parameters themselves, weuse stochastic gradient updates (LeCun et al,1998).
Given a set of n sentence-meaning pairs{(xi,zi) : i = 1...n}, we update the parameters ?
it-eratively, for each example i, by following the localgradient of the conditional log-likelihood objective1515Oi = logP(zi|xi;?
,?).
The local gradient of the in-dividual parameter ?
j associated with feature ?
j andtraining instance (xi,zi) is given by:?Oi??
j = Ep(y|xi,zi;?
,?)[?
j(xi,y,zi)]?Ep(y,z|xi;?
,?)[?
j(xi,y,z)](4)As with Eq.
3, all of the expectations in Eq.
4 arecalculated through the use of the inside-outside al-gorithm on a pruned parse chart.
For a sentenceof length m, each parse chart span is pruned usinga beam width proportional to m 23 , to allow largerbeams for shorter sentences.5 Factored LexiconsA factored lexicon includes a set L of lexemes anda set T of lexical templates.
In this section, we for-mally define these sets, and describe how they areused to build CCG parses.
We will use a set of lex-ical items from our running example to discuss thedetails of how the following lexical items:(1) f light `N :?x.
f light(x)(2) f light `N/(S|NP) :?
f?x.
f light(x)?
f (x).
.
.
(6) Boston`NP :bos(7) Boston`N\N :?
f?x.
f rom(x,bos)?
f (x)are constructed from specific lexemes and templates.5.1 LexemesA lexeme (w,~c) pairs a word sequence w with anordered list of logical constants ~c = [c1 .
.
.cm].
Forexample, item (1) and (2) above would come froma single lexeme (flight, [ f light]).
Similar lexemeswould be represented for other predicates, for exam-ple (fare, [cost]).
Lexemes also can contain multipleconstants, for example (cheapest, [argmin,cost]),which we will see more examples of later.5.2 Lexical TemplatesA lexical template takes a lexeme and produces alexical item.
Templates have the general form?
(?,~v).[?
`X : h~v]where h~v is a logical expression that contains vari-ables from the list ~v.
Applying this template to theinput lexeme (w,~c) gives the full lexical item w `X :h where the variable ?
has been replaced with thewordspan w and the logical form h has been createdby replacing each of the variables in~v with the coun-terpart constant from ~c.
For example, the lexicalitem (6) above would be constructed from the lex-eme (Boston, [bos]) using the template ?
(?,~v).[?
`NP :v1].
Items (1) and (2) would both be constructedfrom the single lexeme (flight, [ f light]) with the twodifferent templates ?
(?,~v).[?
` N : ?x.v1(x)] and?
(?,~v).[?
`N/(S|NP) :?
f?x.v1(x)?
f (x)]5.3 Parsing with a Factored LexiconIn general, there can by many different (lexeme,template) pairs that produce the same lexical item.For example, lexical item (7) in our running ex-ample above can be constructed from the lexemes(Boston, [bos]) and (Boston, [ f rom,bos]), given ap-propriate templates.To model this ambiguity, we include the selectionof a (lexeme, template) pair as a decision to be madewhile constructing a CCG parse tree.
Given the lex-ical item produced by the chosen lexeme and tem-plate, parsing continues with the traditional combi-nators, as reviewed in Section 4.2.
This direct inte-gration allows for features that signal which lexemesand templates have been used while also allowingfor well defined marginal probabilities, by summingover all ways of deriving a specific lexical item.6 Learning Factored LexiconsTo induce factored lexicons, we will make use of twoprocedures, presented in this section, that factor lexi-cal items into lexemes and templates.
Section 7 willdescribe how this factoring operation is integratedinto the complete learning algorithm.6.1 Maximal FactoringsGiven a lexical item l of the form w `X : h withwords w, a syntactic category X , and a logical formh, we define the maximal factoring to be the unique(lexeme, template) pair that can be used to recon-struct l and includes all of the constants of h inthe lexeme (listed in a fixed order based on anordered traversal of h).
For example, the maxi-mal factoring for the lexical item Boston ` NP :bos is the pair we saw before: (Boston, [bos]) and?
(?,~v).[?
` NP : v1].
Similarly, the lexical itemBoston ` N\N : ?
f .?x.
f (x)?
f rom(x,bos) wouldbe factored to produce (Boston, [ f rom,bos]) and?
(?,~v).[?
` N\N :?
f .?x.
f (x)?
v1(x,v2)].As we will see in Section 7, this notion of factor-1516ing can be directly incorporated into existing algo-rithms that learn CCG lexicons.
When the originalalgorithm would have added an entry l to the lexi-con, we can instead compute the factoring of l andadd the corresponding lexeme and template to thefactored lexicon.6.2 Introducing Templates with ContentMaximal factorings, as just described, provide forsignificant lexical generalization but do not handleall of the cases needed to learn effectively.
Forinstance, the maximal split for the item Boston `N\N : ?
f .?x.
f (x) ?
f rom(x,bos) would introducethe lexeme (Boston, [ f rom,bos]), which is subopti-mal since each possible city would need a lexemeof this type, with the additional from constant in-cluded.
Instead, we would ideally like to learn thelexeme (Boston, [bos]) and have a template that in-troduces the from constant.
This would model thedesired generalization with a single lexeme per city.In order to permit the introduction of extra con-stants into lexical items, we allow the creation oftemplates that contain logical constants through par-tial factorings.
For instance, the template below canintroduce the predicate from?
(?,~v).[?
`N\N :?
f .?x.
f (x)?
f rom(x,v1)]The use of templates to introduce extra semanticconstants into a lexical item is similar to, but moregeneral than, the English-specific type-shifting rulesused in Zettlemoyer and Collins (2007), which wereintroduced to model spontaneous, unedited text.They are useful, as we will see, in learning to re-cover semantic content that is implied, but not ex-plicitly stated, such as our original motivating phrase?flights Boston to New York.
?To propose templates which introduce semanticcontent, during learning, we build on the intuitionthat we need to recover from missing words, suchas in the example above.
In this scenario, thereshould also be other sentences that actually includethe word, in our example this would be somethinglike ?flights from Boston.?
We will also assumethat we have learned a good factored lexicon for thecomplete example that could produce the parse:flights from BostonN (N\N)/NP NP?x.
f light(x) ?y?
f?x.
f (x)?
f rom(x,y) bos>(N\N)?
f?x.
f (x)?
f rom(x,bos)<N?x.
f light(x)?
f rom(x,bos)Given analyses of this form, we introduce newtemplates that will allow us to recover from miss-ing words, for example if ?from?
was dropped.
Weidentify commonly occurring nodes in the best parsetrees found during training, in this case the non-terminal spanning ?from Boston,?
and introducetemplates that can produce the nonterminal, even ifone of the words is missing.
Here, this approachwould introduce the desired template ?
(?,~v).[?
`N\N : ?
f .?x.
f (x) ?
f rom(x,v1)] for mapping thelexeme (Boston, [bos]) directly to the intermediatestructure.Not all templates introduced this way will modelvalid generalizations.
However, we will incorporatethem into a learning algorithm with indicator fea-tures that can be weighted to control their use.
Thenext section presents the complete approach.7 Learning Factored PCCGsOur Factored Unification Based Learning (FUBL)method extends the UBL algorithm (Kwiatkowskiet al, 2010) to induce factored lexicons, while alsosimultanously estimating the parameters of a log-linear CCG parsing model.
In this section, we firstreview the NEW-LEX lexical induction procedurefrom UBL, and then present the FUBL algorithm.7.1 Background: NEW-LEXNEW-LEX generates lexical items by splitting andmerging nodes in the best parse tree of each trainingexample.
Each parse node has a CCG category X : hand a sequence of words w that it spans.
We willpresent an overview of the approach using the run-ning example with the phrase w =?in Boston?
andthe category X : h = S\NP :?x.loc(x,bos), which isof the type commonly seen during learning.
Thesplitting procedure is a two step process that firstsplits the logical form h, then splits the CCG syn-tactic category X and finally splits the string w.The first step enumerates all possible splits ofthe logical form h into a pair of new expressions1517( f ,g) that can be used to reconstruct h by ei-ther function application (h = f (g)) or composition(h = ?x.
f (g(x))).
For example, one possible split is:( f = ?y.
?x.loc(x,y) , g = bos)which corresponds to the function application case.The next two steps enumerate all ways of splittingthe syntactic category X and words w to introducetwo new lexical items which can be recombined withCCG combinators (application or composition) torecreate the original parse node X : h spanning w. Inour example, one possibility would be:(in` (S\NP)/NP :?y.
?x.loc(x,y) , Boston`NP :bos)which could be recombined with the forward appli-cation combinator from Section 4.2.To assign categories while splitting, the grammarused by NEW-LEX only uses two atomic syntac-tic categories S and NP.
This allows NEW-LEX tomake use of a direct mapping from semantic typeto syntactic category when proposing syntactic cate-gories.
In this schema, the standard syntactic cat-egory N is replaced by the category S|NP whichmatches the type ?e, t?
and uses the vertical slash in-troduced in Section 4.2.
We will see categories suchas this in the evaluation.7.2 The FUBL AlgorithmFigure 1 shows the FUBL learning algorithm.
Weassume training data {(xi,zi) : i= 1 .
.
.n}where eachexample is a sentence xi paired with a logical formzi.
The algorithm induces a factored PCCG, includ-ing the lexemes L, templates T , and parameters ?
.The algorithm is online, repeatedly performingboth lexical expansion (Step 1) and a parameter up-date (Step 2) for each training example.
The over-all approach is closely related to the UBL algo-rithm (Kwiatkowski et al, 2010), but includes exten-sions for updating the factored lexicon, as motivatedin Section 6.Initialization The model is initialized with a fac-tored lexicon as follows.
MAX-FAC is a functionthat takes a lexical item l and returns the maximalfactoring of it, that is the unique, maximal (lexeme,template) pair that can be combined to construct l,as described in Section 6.1.
We apply MAX-FAC toeach of the training examples (xi,zi), creating a sin-gle way of producing the desired meaning zi from aInputs: Training set {(xi,zi) : i = 1 .
.
.n} where eachexample is a sentence xi paired with a logical formzi.
Set of entity name lexemes Le.
Number of itera-tions J.
Learning rate parameter ?0 and cooling rateparameter c. Empty lexeme set L. Empty templateset T .Definitions: NEW-LEX(y) returns a set of new lex-ical items from a parse y as described in Sec-tion 7.1.
MAX-FAC(l) generates a (lexeme, tem-plate) pair from a lexical item l. PART-FAC(y)generates a set of templates from parse y.
Both ofthese are described in Section 7.2.
The distributionsp(y|x,z;?
,(L,T )) and p(y,z|x;?
,(L,T )) are definedby the log-linear model described in Section 4.3.Initialization:?
For i = 1 .
.
.n?
(?,pi) = MAX-FAC(xi ` S : zi)?
L = L??
, T = T ?pi?
Set L = L?Le.?
Initialize ?
using coocurrence statistics, as de-scribed in Section 8.Algorithm:For t = 1 .
.
.J, i = 1 .
.
.n :Step 1: (Add Lexemes and Templates)?
Let y?
= argmaxy p(y|xi,zi;?
,(L,T ))?
For l ?
NEW-LEX(y?)?
(?,pi) = MAX-FAC(l)?
L = L??
, T = T ?pi?
?= PART-FAC(y?)
, T = T ?
?Step 2: (Update Parameters)?
Let ?
= ?01+c?k where k = i+ t?n.?
Let ?= Ep(y|xi,zi;?
,(L,T ))[?(xi,y,zi)]?Ep(y,z|xi;?
,(L,T ))[?(xi,y,z)]?
Set ?
= ?
+ ?
?Output: Lexemes L, templates T , and parameters ?
.Figure 1: The FUBL learning algorithm.lexeme containing all of the words in xi.
The lex-emes and templates created in this way provide theinitial factored lexicon.Step 1 The first step of the learning algorithm inFigure 1 adds lexemes and templates to the fac-tored model given by performing manipulations onthe highest scoring correct parse y?
of the currenttraining example (xi,zi).
First the NEW-LEX pro-cedure is run on y?
as described in Section 6.1 to1518generate new lexical items.
We then use the func-tion MAX-FAC to create the maximal factorings ofeach of these new lexical items as described in Sec-tion 6 and these are added to the factored represen-tation of the lexicon.
New templates can also be in-troduced through partial factorings of internal parsenodes as described in Section 6.2.
These templatesare generated by using the function PART-FAC toabstract over the wordspan and a subset of the con-stants contained in the internal parse nodes of y?.This step allows for templates that introduce newsemantic content to model elliptical language, as de-scribed in Section 6.2.Step 2 The second step does a stochastic gradientdescent update on the parameters ?
used in the pars-ing model.
This update is described in Section 4.3Discussion The FUBL algorithm makes use of adirect online approach, where lexemes and tem-plates are introduced in place while analyzing spe-cific sentences.
In general, this will overgeneralize;not all ways of combining lexemes and templateswill produce high quality lexical items.
However,the overall approach includes features, presented inSection 8, that can be used to learn which ones arebest in practice.
The complete algorithm iterates be-tween adding new lexical content and updating theparameters of the parsing model with each proce-dure guiding the other.8 Experimental setupData Sets We evaluate on two benchmark seman-tic parsing datasets: GeoQuery, which is made up ofnatural language queries to a database of geograph-ical information; and Atis, which contains naturallanguage queries to a flight booking system.
TheGeo880 dataset has 880 (English-sentence, logical-form) pairs split into a training set of 600 pairs anda test set of 280.
The Geo250 data is a subset ofthe Geo880 sentences that have been translated intoJapanese, Spanish and Turkish as well as the originalEnglish.
We follow the standard evaluation proce-dure for Geo250, using 10-fold cross validation ex-periments with the same splits of the data as Wongand Mooney (2007).
The Atis dataset contains 5410(sentence, logical-form) pairs split into a 4480 ex-ample training set, a 480 example development setand a 450 example test set.Evaluation Metrics We report exact match Re-call (percentage of sentences for which the correctlogical-form was returned), Precision (percentage ofreturned logical-forms that are correct) and F1 (har-monic mean of Precision and Recall).
For Atis wealso report partial match Recall (percentage of cor-rect literals returned), Precision (percentage of re-turned literals that are correct) and F1, computed asdescribed by Zettlemoyer and Collins (2007).Features We introduce two types of features todiscriminate between parses: lexical features andlogical-form features.Lexical features fire on the lexemes and templatesused to build the lexical items used in a parse.
Foreach (lexeme,template) pair used to create a lexi-cal item we have indicator features ?l for the lex-eme used, ?t for the template used, and ?
(l,t) for thepair that was used.
We assign the features on lexi-cal templates a weight of 0.1 to prevent them fromswamping the far less frequent but equally informa-tive lexeme features.Logical-form features are computed on thelambda-calculus expression z returned at the root ofthe parse.
Each time a predicate p in z takes anargument a with type Ty(a) in position i, it trig-gers two binary indicator features: ?
(p,a,i) for thepredicate-argument relation; and ?
(p,Ty(a),i) for thepredicate argument-type relation.
Boolean opera-tor features look at predicates that occurr togetherin conjunctions and disjunctions.
For each variablevi that fills argument slot i in two conjoined pred-icates p1 and p2 we introduce a binary indicatorfeature ?con j(i,p1,p2).
We introduce similar features?dis j(i,p1,p2) for variables vi that are shared by predi-cates in a disjunction.Initialization The weights for lexeme features areinitialized according to coocurrance statistics be-tween words and logical constants.
These are esti-mated with the Giza++ (Och and Ney, 2003) imple-mentation of IBM Model 1.
The initial weights fortemplates are set by adding ?0.1 for each slash inthe syntactic category and ?2 if the template con-tains logical constants.
Features on lexeme-templatepairs and all parse features are initialized to zero.Systems We compare performance to all recently-published, directly-comparable results.
For Geo-Query, this includes the ZC05, ZC07 (Zettlemoyer1519System Exact MatchRec.
Pre.
F1ZC07 74.4 87.3 80.4UBL 65.6 67.1 66.3FUBL 81.9 82.1 82.0Table 1: Performance on the Atis development set.System Exact Match Partial MatchRec.
Pre.
F1.
Rec.
Pre.
F1ZC07 84.6 85.8 85.2 96.7 95.1 95.9HY06 - - - - - 90.3UBL 71.4 72.1 71.7 78.2 98.2 87.1FUBL 82.8 82.8 82.8 95.2 93.6 94.6Table 2: Performance on the Atis test set.and Collins, 2005, 2007), ?
-WASP (Wong andMooney, 2007), UBL (Kwiatkowski et al, 2010)systems and DCS (Liang et al, 2011).
For Atis,we report results from HY06 (He and Young, 2006),ZC07, and UBL.9 ResultsTables 1-4 present the results on the Atis and Geo-query domains.
In all cases, FUBL achieves at ornear state-of-the-art recall (overall number of correctparses) when compared to directly comparable sys-tems and it significantly outperforms UBL on Atis.On Geo880 the only higher recall is achievedby DCS with prototypes - which uses signifi-cant English-specific resources, including manuallyspecified lexical content, but does not require train-ing sentences annotated with logical-forms.
OnGeo250, FUBL achieves the highest recall acrosslanguages.
Each individual result should be inter-preted with care, as a single percentage point cor-responds to 2-3 sentences, but the overall trend isencouraging.On the Atis development set, FUBL outperformsZC07 by 7.5% of recall but on the Atis test setFUBL lags ZC07 by 2%.
The reasons for this dis-crepancy are not clear, however, it is possible thatthe syntactic constructions found in the Atis test setdo not exhibit the same degree of variation as thoseseen in the development set.
This would negate theneed for the very general lexicon learnt by FUBL.Across the evaluations, despite achieving high re-call, FUBL achieves significantly lower precisionthan ZC07 and ?
-WASP.
This illustrates the trade-off from having a very general model of proposinglexical structure.
With the ability to skip unseenSystem Rec.
Pre.
F1Labelled Logical FormsZC05 79.3 96.3 87.0ZC07 86.1 91.6 88.8UBL 87.9 88.5 88.2FUBL 88.6 88.6 88.6Labelled Question AnswersDCS 91.1 - -Table 3: Exact match accuracy on the Geo880 test set.System English SpanishRec.
Pre.
F1 Rec.
Pre.
F1?
-WASP 75.6 91.8 82.9 80.0 92.5 85.8UBL 81.8 83.5 82.6 81.4 83.4 82.4FUBL 83.7 83.7 83.7 85.6 85.8 85.7System Japanese TurkishRec.
Pre.
F1 Rec.
Pre.
F1?
-WASP 81.2 90.1 85.8 68.8 90.4 78.1UBL 83.0 83.2 83.1 71.8 77.8 74.6FUBL 83.2 83.8 83.5 72.5 73.7 73.1Table 4: Exact-match accuracy on the Geo250 data set.words, FUBL returns a parse for all of the Atis testsentences, since the factored lexicons we are learn-ing can produce a very large number of lexical items.These parses are, however, not always correct.10 AnalysisThe Atis results in Tables 1 and 2 highlight the ad-vantages of factored lexicons.
FUBL outperformsthe UBL baseline by 16 and 11 points respectivelyin exact-match recall.
Without making any modi-fication to the CCG grammars or parsing combina-tors, we are able to induce a lexicon that is generalenough model the natural occurring variations in thedata, for example due to sloppy, unedited sentences.Figure 2 shows a parse returned by FUBL fora sentence on which UBL failed.
Whilethe word ?cheapest?
is seen 208 times in thetraining data, in only a handful of these in-stances is it seen in the middle of an utter-ance.
For this reason, UBL never proposesthe lexical item, cheapest ` NP\(S|NP)/(S|NP) :?
f?g.argmin(?x.
f (x)?
g(x),?y.cost(y)), which isused to parse the sentence in Figure 2.
In contrast,FUBL uses a lexeme learned from the same word indifferent contexts, along with a template learnt fromsimilar words in a similar context, to learn to per-1520pittsburgh to atlanta the cheapest on july twentiethNP (S|NP)\NP/NP NP NP\(S|NP)/(S|NP) (S|NP)/NP/NP NP NPpit ?x?y?
z.to(z,x) atl ?
f?g.argmin(?x.
f (x)?g(x),?y.cost(y)) ?x?y?
z.month(z,x) jul 20?
f rom(z,y) ?day(z,y)> >(S|NP)\NP (S|NP)/NP?x?y.to(y,atl)?
f rom(y,x) ?x?y.month(y, jul)?day(y,x)< >(S|NP) (S|NP)?x.to(x,atl)?
f rom(x, pit) ?x.month(x, jul)?day(x,20)>NP\(S|NP)?
f .argmin(?x.
f (x)?month(x, jul)?day(x,20),?y.cost(y))<NPargmin(?x.
f rom(x, pit)?
to(x,atl)?month(x, jul)?day(x,20),?y.cost(y))Figure 2: An example learned parse.
FUBL can learn this type of analysis with novel combinations of lexemes andtemplates at test time, even if the individual words, like ?cheapest,?
were never seen in similar syntactic constructionsduring training, as described in Section 10.form the desired analysis.As well as providing a new way to search the lex-icon during training, the factored lexicon provides away of proposing new, unseen, lexical items at testtime.
We find that new, non-NP, lexical items areused in 6% of the development set parses.Interestingly, the addition of templates that intro-duce semantic content (as described in Section 6.2)account for only 1.2% of recall on the Atis develop-ment set.
This is suprising as elliptical constructionsare found in a much larger proportion of the sen-tences than this.
In practice, FUBL learns to modelmany elliptical constructions with lexemes and tem-plates introduced through maximal factorings.
Forexample, the lexeme (to, [ f rom, to]) can be usedwith the correct lexical template to deal with ourmotivating example ?flights Boston to New York?.Templates that introduce content are therefore onlyused in truly novel elliptical constructions for whichan alternative analysis could not be learned.Table 5 shows a selection of lexemes and tem-plates learned for Atis.
Examples 2 and 3 show thatmorphological variants of the same word must stillbe stored in separate lexemes.
However, as theselexemes now share templates, the total number oflexical variants that must be learned is reduced.11 DiscussionWe argued that factored CCG lexicons, which in-clude both lexemes and lexical templates, providea compact representation of lexical knowledge thatcan have advantages for learning.
We also describeda complete approach for inducing factored, prob-abilistic CCGs for semantic parsing, and demon-Most common lexemes by type of constants in~c.1 e (Boston, [bos]) (Denver, [den])2 ?e, t?
(flight, [ f light]) (flights, [ f light])3 ?e, i?
(fare, [cost]) (fares, [cost])4 ?e,?e, t??
(from, [ f rom]) (to, [to])5 ?e, i?, (cheapest, [argmin,cost])?e, t?
(earliest, [argmin,dep time])6 ?i,?i, t?
?, (after, [>,dep time])?e, i?
(before, [<,dep time])Most common templates matching lexemes above.1 ?
(?,~v).?
`NP :v12 ?
(?,~v).?
`S|NP :?x.v1(x)3 ?
(?,~v).?
`NP|NP :?x.v1(x)4 ?
(?,~v).?
`S|NP/NP\(S|NP) :?x?y.v1(x,y)5 ?
(?,~v).?
`NP/(S|NP) :?
f .v1(?x.
f (x),?y,v2(y))6 ?
(?,~v).?
`S|NP\(S|NP)/NP :?x?y?
z.v1(v2(z),x)?
y(x)Table 5: Example lexemes and templates learned fromthe Atis development set.strated strong performance across a wider range ofbenchmark datasets that any previous approach.In the future, it will also be important to ex-plore morphological models, to better model vari-ation within the existing lexemes.
The factored lex-ical representation also has significant potential forlexical transfer learning, where we would need tolearn new lexemes for each target application, butmuch of the information in the templates could, po-tentially, be ported across domains.AcknowledgementsThe work was supported in part by EU ERC Ad-vanced Fellowship 249520 GRAMPLUS, and anESPRC PhD studentship.
We would like to thankYoav Artzi for helpful discussions.1521ReferencesBos, Johan, Stephen Clark, Mark Steedman, James R.Curran, and Julia Hockenmaier.
2004.
Wide-coveragesemantic representations from a CCG parser.
In Pro-ceedings of the International Conference on Computa-tional Linguistics.Branavan, S.R.K., Luke Zettlemoyer, and Regina Barzi-lay.
2010.
Reading between the lines: Learning to maphigh-level instructions to commands.
In Associationfor Computational Linguistics (ACL).Carpenter, Bob.
1997.
Type-Logical Semantics.
The MITPress.Clark, Stephen and James R. Curran.
2003.
Log-linearmodels for wide-coverage CCG parsing.
In Proceed-ings of the Conference on Empirical Methods in Natu-ral Language Processing.Clark, Stephen and James R. Curran.
2007.
Wide-coverage efficient statistical parsing with CCGand log-linear models.
Computational Linguistics33(4):493?552.Clarke, James, Dan Goldwasser, Ming-Wei Chang, andDan Roth.
2010.
Driving semantic parsing fromthe world?s response.
In Proceedings of the Four-teenth Conference on Computational Natural Lan-guage Learning (CoNLL-2010).
Uppsala, Sweden,pages 18?27.Ge, Ruifang and Raymond J. Mooney.
2006.
Discrimina-tive reranking for semantic parsing.
In Proceedings ofthe COLING/ACL 2006 Main Conference Poster Ses-sions.Goldwasser, Dan, Roi Reichart, James Clarke, and DanRoth.
2011.
Confidence driven unsupervised semanticparsing.
In Association for Computational Linguistics(ACL).He, Yulan and Steve Young.
2005.
Semantic processingusing the hidden vector state model.
Computer Speechand Language .He, Yulan and Steve Young.
2006.
Spoken languageunderstanding using the hidden vector state model.Speech Communication 48(3-4).Hockenmaier, Julia and Mark Steedman.
2002.
Gener-ative models for statistical parsing with CombinatoryCategorial Grammar.
In Proceedings of the 40th Meet-ing of the ACL.
Philadelphia, PA, pages 335?342.Kate, Rohit J. and Raymond J. Mooney.
2006.
Usingstring-kernels for learning semantic parsers.
In Pro-ceedings of the 44th Annual Meeting of the Associationfor Computational Linguistics.Kate, Rohit J., Yuk Wah Wong, and Raymond J. Mooney.2005.
Learning to transform natural to formal lan-guages.
In Proceedings of the National Conferenceon Artificial Intelligence.Kwiatkowski, Tom, Luke Zettlemoyer, Sharon Goldwa-ter, and Mark Steedman.
2010.
Inducing probabilisticCCG grammars from logical form with higher-orderunification.
In Proceedings of the Conference on Em-perical Methods in Natural Language Processing.LeCun, Y., L. Bottou, Y. Bengio, and P. Haffner.
1998.Gradient-based learning applied to document recogni-tion.
Proceedings of the IEEE 86(11):2278?2324.Liang, P., M. I. Jordan, and D. Klein.
2009.
Learningsemantic correspondences with less supervision.
InAssociation for Computational Linguistics and Inter-national Joint Conference on Natural Language Pro-cessing (ACL-IJCNLP).Liang, P., M. I. Jordan, and D. Klein.
2011.
Learningdependency-based compositional semantics.
In Asso-ciation for Computational Linguistics (ACL).Lu, Wei, Hwee Tou Ng, Wee Sun Lee, and Luke S. Zettle-moyer.
2008.
A generative model for parsing naturallanguage to meaning representations.
In Proceedingsof The Conference on Empirical Methods in NaturalLanguage Processing.Miller, Scott, David Stallard, Robert J. Bobrow, andRichard L. Schwartz.
1996.
A fully statistical approachto natural language interfaces.
In Proc.
of the Associ-ation for Computational Linguistics.Nguyen, Le-Minh, Akira Shimazu, and Xuan-Hieu Phan.2006.
Semantic parsing with structured SVM ensem-ble classification models.
In Proceedings of the COL-ING/ACL 2006 Main Conference Poster Sessions.Och, Franz Josef and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics 29(1):19?51.Papineni, K. A., S. Roukos, and T. R. Ward.
1997.Feature-based language understanding.
In Proceed-ings of European Conference on Speech Communica-tion and Technology.Poon, Hoifung and Pedro Domingos.
2009.
Unsuper-vised semantic parsing.
In Conference on EmpiricalMethods in Natural Language Processing (EMNLP).Poon, Hoifung and Pedro Domingos.
2010.
Unsuper-vised ontology induction from text.
In Association forComputational Linguistics (ACL).Ramaswamy, Ganesh N. and Jan Kleindienst.
2000.
Hier-archical feature-based translation for scalable naturallanguage understanding.
In Proceedings of Interna-tional Conference on Spoken Language Processing.Steedman, Mark.
1996.
Surface Structure and Interpre-tation.
The MIT Press.1522Steedman, Mark.
2000.
The Syntactic Process.
The MITPress.Tang, Lappoon R. and Raymond J. Mooney.
2000.
Au-tomated construction of database interfaces: Integrat-ing statistical and relational learning for semantic pars-ing.
In Proceedings of the Joint Conference on Empiri-cal Methods in Natural Language Processing and VeryLarge Corpora.Thompson, Cynthia A. and Raymond J. Mooney.
2002.Acquiring word-meaning mappings for natural lan-guage interfaces.
Journal of Artificial Intelligence Re-search 18.Vogel, Adam and Dan Jurafsky.
2010.
Learning to follownavigational directions.
In Association for Computa-tional Linguistics (ACL).Watkinson, Stephen and Suresh Manandhar.
1999.
Un-supervised lexical learning with categorial grammarsusing the LLL corpus.
In Proceedings of the 1st Work-shop on Learning Language in Logic.Wong, Yuk Wah and Raymond Mooney.
2006.
Learningfor semantic parsing with statistical machine transla-tion.
In Proceedings of the Human Language Technol-ogy Conference of the NAACL.Wong, Yuk Wah and Raymond Mooney.
2007.
Learn-ing synchronous grammars for semantic parsing withlambda calculus.
In Proceedings of the Association forComputational Linguistics.Zelle, John M. and Raymond J. Mooney.
1996.
Learn-ing to parse database queries using inductive logic pro-gramming.
In Proceedings of the National Conferenceon Artificial Intelligence.Zettlemoyer, Luke S. and Michael Collins.
2005.
Learn-ing to map sentences to logical form: Structured clas-sification with probabilistic categorial grammars.
InProceedings of the Conference on Uncertainty in Arti-ficial Intelligence.Zettlemoyer, Luke S. and Michael Collins.
2007.
On-line learning of relaxed CCG grammars for parsing tological form.
In Proc.
of the Joint Conference on Em-pirical Methods in Natural Language Processing andComputational Natural Language Learning.Zettlemoyer, Luke S. and Michael Collins.
2009.
Learn-ing context-dependent mappings from sentences tological form.
In Proceedings of The Joint Conferenceof the Association for Computational Linguistics andInternational Joint Conference on Natural LanguageProcessing.1523
