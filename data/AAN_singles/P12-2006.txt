Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 28?32,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsFast and Scalable Decoding with Language Model Look-Aheadfor Phrase-based Statistical Machine TranslationJoern Wuebker, Hermann NeyHuman Language Technologyand Pattern Recognition GroupComputer Science DepartmentRWTH Aachen University, Germanysurname@cs.rwth-aachen.deRichard Zens*Google, Inc.1600 Amphitheatre ParkwayMountain View, CA 94043zens@google.comAbstractIn this work we present two extensions tothe well-known dynamic programming beamsearch in phrase-based statistical machinetranslation (SMT), aiming at increased effi-ciency of decoding by minimizing the numberof language model computations and hypothe-sis expansions.
Our results show that languagemodel based pre-sorting yields a small im-provement in translation quality and a speedupby a factor of 2.
Two look-ahead methods areshown to further increase translation speed bya factor of 2 without changing the search spaceand a factor of 4 with the side-effect of someadditional search errors.
We compare our ap-proach with Moses and observe the same per-formance, but a substantially better trade-offbetween translation quality and speed.
At aspeed of roughly 70 words per second, Mosesreaches 17.2% BLEU, whereas our approachyields 20.0% with identical models.1 IntroductionResearch efforts to increase search efficiency forphrase-based MT (Koehn et al, 2003) have ex-plored several directions, ranging from generalizingthe stack decoding algorithm (Ortiz et al, 2006) toadditional early pruning techniques (Delaney et al,2006), (Moore and Quirk, 2007) and more efficientlanguage model (LM) querying (Heafield, 2011).This work extends the approach by (Zens andNey, 2008) with two techniques to increase trans-lation speed and scalability.
We show that takinga heuristic LM score estimate for pre-sorting thephrase translation candidates has a positive effect onboth translation quality and speed.
Further, we intro-duce two novel LM look-ahead methods.
The ideaof LM look-ahead is to incorporate the LM proba-bilities into the pruning process of the beam searchas early as possible.
In speech recognition it hasbeen used for many years (Steinbiss et al, 1994;Ortmanns et al, 1998).
First-word LM look-aheadexploits the search structure to use the LM costs ofthe first word of a new phrase as a lower bound forthe full LM costs of the phrase.
Phrase-only LMlook-ahead makes use of a pre-computed estimateof the full LM costs for each phrase.
We detail theimplementation of these methods and analyze theireffect with respect to the number of LM computa-tions and hypothesis expansions as well as on trans-lation speed and quality.
We also run comparisonswith the Moses decoder (Koehn et al, 2007), whichyields the same performance in BLEU, but is outper-formed significantly in terms of scalability for fastertranslation.
Our implementation is available undera non-commercial open source licence?.2 Search Algorithm ExtensionsWe apply the decoding algorithm described in (Zensand Ney, 2008).
Hypotheses are scored by aweighted log-linear combination of models.
A beamsearch strategy is used to find the best hypothesis.During search we perform pruning controlled by theparameters coverage histogram size?
Nc and lexical?Richard Zens?s contribution was during his time at RWTH.
?www-i6.informatik.rwth-aachen.de/jane?number of hypothesized coverage vectors per cardinality28histogram size?
Nl .2.1 Phrase candidate pre-sortingIn addition to the source sentence f J1 , the beamsearch algorithm takes a matrix E(?, ?)
as input,where for each contiguous phrase f?
= f j .
.
.
f j?within the source sentence, E( j, j?)
contains a list ofall candidate translations for f?
.
The candidate listsare sorted according to their model score, which wasobserved to speed up translation by Delaney et al(2006).
In addition to sorting according to the purelyphrase-internal scores, which is common practice,we compute an estimate qLME(e?)
for the LM scoreof each target phrase e?.
qLME(e?)
is the weightedLM score we receive by assuming e?
to be a com-plete sentence without using sentence start and endmarkers.
We limit the number of translation optionsper source phrase to the No top scoring candidates(observation histogram pruning).The pre-sorting during phrase matching has twoeffects on the search algorithm.
Firstly, it definesthe order in which the hypothesis expansions takeplace.
As higher scoring phrases are considered first,it is less likely that already created partial hypothe-ses will have to be replaced, thus effectively reduc-ing the expected number of hypothesis expansions.Secondly, due to the observation pruning the sortingaffects the considered phrase candidates and conse-quently the search space.
A better pre-selection canbe expected to improve translation quality.2.2 Language Model Look-AheadLM score computations are among the most expen-sive in decoding.
Delaney et al (2006) report signif-icant improvements in runtime by removing unnec-essary LM lookups via early pruning.
Here we de-scribe an LM look-ahead technique, which is aimedat further reducing the number of LM computations.The innermost loop of the search algorithm iter-ates over all translation options for a single sourcephrase to consider them for expanding the currenthypothesis.
We introduce an LM look-ahead scoreqLMLA(e?|e??
), which is computed for each of thetranslation options.
This score is added to the over-all hypothesis score, and if the pruning threshold is?number of lexical hypotheses per coverage vectorexceeded, we discard the expansion without com-puting the full LM score.First-word LM look-ahead pruning defines theLM look-ahead score qLMLA(e?|e??)
= qLM(e?1|e??)
tobe the LM score of the first word of target phrase e?given history e??.
As qLM(e?1|e??)
is an upper bound forthe full LM score, the technique does not introduceadditional seach errors.
The score can be reused, ifthe LM score of the full phrase e?
needs to be com-puted afterwards.We can exploit the structure of the search to speedup the LM lookups for the first word.
The LM prob-abilities are stored in a trie, where each node cor-responds to a specific LM history.
Usually, eachLM lookup consists of first traversing the trie to findthe node corresponding to the current LM historyand then retrieving the probability for the next word.If the n-gram is not present, we have to repeat thisprocedure with the next lower-order history, until aprobability is found.
However, the LM history forthe first words of all phrases within the innermostloop of the search algorithm is identical.
Just be-fore the loop we can therefore traverse the trie oncefor the current history and each of its lower order n-grams and store the pointers to the resulting nodes.To retrieve the LM look-ahead scores, we can thendirectly access the nodes without the need to traversethe trie again.
This implementational detail was con-firmed to increase translation speed by roughly 20%in a short experiment.Phrase-only LM look-ahead pruning defines thelook-ahead score qLMLA(e?|e??)
= qLME(e?)
to be theLM score of phrase e?, assuming e?
to be the full sen-tence.
It was already used for sorting the phrases,is therefore pre-computed and does not require ad-ditional LM lookups.
As it is not a lower bound forthe real LM score, this pruning technique can intro-duce additional search errors.
Our results show thatit radically reduces the number of LM lookups.3 Experimental Evaluation3.1 SetupThe experiments are carried out on theGerman?English task provided for WMT 2011?.
?http://www.statmt.org/wmt1129system BLEU[%] #HYP #LM w/sNo = ?baseline 20.1 3.0K 322K 2.2+pre-sort 20.1 2.5K 183K 3.6No = 100baseline 19.9 2.3K 119K 7.1+pre-sort 20.1 1.9K 52K 15.8+first-word 20.1 1.9K 40K 31.4+phrase-only 19.8 1.6K 6K 69.2Table 1: Comparison of the number of hypothesis expan-sions per source word (#HYP) and LM computations persource word (#LM) with respect to LM pre-sorting, first-word LM look-ahead and phrase-only LM look-ahead onnewstest2009.
Speed is given in words per second.Results are given with (No = 100) and without (No = ?
)observation pruning.The English language model is a 4-gram LMcreated with the SRILM toolkit (Stolcke, 2002) onall bilingual and parts of the provided monolingualdata.
newstest2008 is used for parameteroptimization, newstest2009 as a blind testset.
To confirm our results, we run the final set ofexperiments also on the English?French task ofIWSLT 2011?.
We evaluate with BLEU (Papineni etal., 2002) and TER (Snover et al, 2006).We use identical phrase tables and scaling fac-tors for Moses and our decoder.
The phrase tableis pruned to a maximum of 400 target candidates persource phrase before decoding.
The phrase table andLM are loaded into memory before translating andloading time is eliminated for speed measurements.3.2 Methodological analysisTo observe the effect of the proposed search al-gorithm extensions, we ran experiments with fixedpruning parameters, keeping track of the number ofhypothesis expansions and LM computations.
TheLM score pre-sorting affects both the set of phrasecandidates due to observation histogram pruning andthe order in which they are considered.
To sepa-rate these effects, experiments were run both withhistogram pruning (No = 100) and without.
FromTable 1 we can see that in terms of efficiency bothcases show similar improvements over the baseline,?http://iwslt2011.org16171819201  4  16  64  256  1024  4096BLEU[%]words/secMosesbaseline+pre-sort+first-word+phrase-onlyFigure 1: Translation performance in BLEU [%] on thenewstest2009 set vs. speed on a logarithmic scale.We compare Moses with our approach without LM look-ahead and LM score pre-sorting (baseline), with addedLM pre-sorting and with either first-word or phrase-onlyLM look-ahead on top of +pre-sort.
Observation his-togram size is fixed to No = 100 for both decoders.which performs pre-sorting with respect to the trans-lation model scores only.
The number of hypothesisexpansions is reduced by ?20% and the number ofLM lookups by ?50%.
When observation pruningis applied, we additionally observe a small increaseby 0.2% in BLEU.Application of first-word LM look-ahead furtherreduces the number of LM lookups by 23%, result-ing in doubled translation speed, part of which de-rives from fewer trie node searches.
The heuristicphrase-only LM look-ahead method introduces ad-ditional search errors, resulting in a BLEU drop by0.3%, but yields another 85% reduction in LM com-putations and increases throughput by a factor of 2.2.3.3 Performance evaluationIn this section we evaluate the proposed extensionsto the original beam search algorithm in terms ofscalability and their usefulness for different appli-cation constraints.
We compare Moses and four dif-ferent setups of our decoder: LM score pre-sortingswitched on or off without LM look-ahead and bothLM look-ahead methods with LM score pre-sorting.We translated the test set with the beam sizes set toNc = Nl = {1,2,4,8,16,24,32,48,64}.
For Moseswe used the beam sizes 2i, i ?
{1, .
.
.
,9}.
Transla-30setup system WMT 2011 German?English IWSLT 2011 English?Frenchbeam size speed BLEU TER beam size speed BLEU TER(Nc,Nl) w/s [%] [%] (Nc,Nl) w/s [%] [%]best Moses 256 0.7 20.2 63.2 16 10 29.5 52.8this work: first-word (48,48) 1.1 20.2 63.3 (8,8) 23 29.5 52.9phrase-only (64,64) 1.4 20.1 63.2 (16,16) 18 29.5 52.8BLEU: Moses 16 12 19.6 63.7 4 40 29.1 53.2?
-1% this work: first-word (4,4) 67 20.0 63.2 (2,2) 165 29.1 53.1phrase-only (8,8) 69 19.8 63.0 (4,4) 258 29.3 52.9BLEU: Moses 8 25 19.1 64.2 2 66 28.1 54.3?
-2% this work: first-word (2,2) 233 19.5 63.4 (1,1) 525 28.4 53.9phrase-only (4,4) 280 19.3 63.0 (2,2) 771 28.5 53.2fastest Moses 1 126 15.6 68.3 1 116 26.7 55.9this work: first-word (1,1) 444 18.4 64.6 (1,1) 525 28.4 53.9phrase-only (1,1) 2.8K 16.8 64.4 (1,1) 2.2K 26.4 54.7Table 2: Comparison of Moses with this work.
Either first-word or phrase-only LM look-ahead is applied.
We considerboth the best and the fastest possible translation, as well as the fastest settings resulting in no more than 1% and 2%BLEU loss on the development set.
Results are given on the test set (newstest2009).tion performance in BLEU is plotted against speedin Figure 1.
Without the proposed extensions, Mosesslightly outperforms our decoder in terms of BLEU.However, the latter already scales better for higherspeed.
With LM score pre-sorting, the best BLEUvalue is similar to Moses while further accelerat-ing translation, yielding identical performance at 16words/sec as Moses at 1.8 words/sec.
Applicationof first-word LM look-ahead shifts the graph to theright, now reaching the same performance at 31words/sec.
At a fixed translation speed of roughly70 words/sec, our approach yields 20.0% BLEU,whereas Moses reaches 17.2%.
For phrase-only LMlook-ahead the graph is somewhat flatter.
It yieldsnearly the same top performance with an even bettertrade-off between translation quality and speed.The final set of experiments is performed on boththe WMT and the IWSLT task.
We directly com-pare our decoder with the two LM look-ahead meth-ods with Moses in four scenarios: the best possi-ble translation, the fastest possible translation with-out performance constraint and the fastest possibletranslation with no more than 1% and 2% loss inBLEU on the dev set compared to the best value.Table 2 shows that on the WMT data, the top per-formance is similar for both decoders.
However, ifwe allow for a small degradation in translation per-formance, our approaches clearly outperform Mosesin terms of translation speed.
With phrase-only LMlook-ahead, our decoder is faster by a factor of 6for no more than 1% BLEU loss, a factor of 11 for2% BLEU loss and a factor of 22 in the fastest set-ting.
The results on the IWSLT data are very similar.Here, the speed difference reaches a factor of 19 inthe fastest setting.4 ConclusionsThis work introduces two extensions to the well-known beam search algorithm for phrase-based ma-chine translation.
Both pre-sorting the phrase trans-lation candidates with an LM score estimate and LMlook-ahead during search are shown to have a pos-itive effect on translation speed.
We compare ourdecoder to Moses, reaching a similar highest BLEUscore, but clearly outperforming it in terms of scal-ability with respect to the trade-off ratio betweentranslation quality and speed.
In our experiments,the fastest settings of our decoder and Moses differin translation speed by a factor of 22 on the WMTdata and a factor of 19 on the IWSLT data.
Our soft-ware is part of the open source toolkit Jane.AcknowledgmentsThis work was partially realized as part of the Quaero Pro-gramme, funded by OSEO, French State agency for innovation.31References[Delaney et al2006] Brian Delaney, Wade Shen, andTimothy Anderson.
2006.
An efficient graph searchdecoder for phrase-based statistical machine transla-tion.
In International Workshop on Spoken LanguageTranslation, Kyoto, Japan, November.
[Heafield2011] Kenneth Heafield.
2011.
KenLM: Fasterand Smaller Language Model Queries.
In Proceedingsof the 6th Workshop on Statistical Machine Transla-tion, pages 187?197, Edinburgh, Scotland, UK, July.
[Koehn et al2003] P. Koehn, F. J. Och, and D. Marcu.2003.
Statistical Phrase-Based Translation.
In Pro-ceedings of the 2003 Meeting of the North Americanchapter of the Association for Computational Linguis-tics (NAACL-03), pages 127?133, Edmonton, Alberta.
[Koehn et al2007] Philipp Koehn, Hieu Hoang, Alexan-dra Birch, Chris Callison-Burch, Marcello Federico,Nicola Bertoldi, Brooke Cowan, Wade Shen, Chris-tine Moran, Richard Zens, Chris Dyer, Ondr?ej Bo-jar, Alexandra Constantine, and Evan Herbst.
2007.Moses: Open Source Toolkit for Statistical MachineTranslation.
In Annual Meeting of the Association forComputational Linguistics (ACL), demonstration ses-sion, pages 177?180, Prague, Czech Republic, June.
[Moore and Quirk2007] Robert C. Moore and ChrisQuirk.
2007.
Faster beam-search decoding for phrasalstatistical machine translation.
In Proceedings of MTSummit XI.
[Ortiz et al2006] Daniel Ortiz, Ismael Garcia-Varea, andFrancisco Casacuberta.
2006.
Generalized stack de-coding algorithms for statistical machine translation.In Proceedings of the Workshop on Statistical MachineTranslation, pages 64?71, New York City, June.
[Ortmanns et al1998] S. Ortmanns, H. Ney, and A. Ei-den.
1998.
Language-model look-ahead for large vo-cabulary speech recognition.
In International Confer-ence on Spoken Language Processing, pages 2095?2098, Sydney, Australia, October.
[Papineni et al2002] Kishore Papineni, Salim Roukos,Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a Methodfor Automatic Evaluation of Machine Translation.
InProceedings of the 41st Annual Meeting of the Asso-ciation for Computational Linguistics, pages 311?318,Philadelphia, Pennsylvania, USA, July.
[Snover et al2006] Matthew Snover, Bonnie Dorr,Richard Schwartz, Linnea Micciulla, and JohnMakhoul.
2006.
A Study of Translation Edit Ratewith Targeted Human Annotation.
In Proceedingsof the 7th Conference of the Association for Ma-chine Translation in the Americas, pages 223?231,Cambridge, Massachusetts, USA, August.
[Steinbiss et al1994] V. Steinbiss, B. Tran, and HermannNey.
1994.
Improvements in Beam Search.
In Proc.of the Int.
Conf.
on Spoken Language Processing (IC-SLP?94), pages 2143?2146, September.
[Stolcke2002] Andreas Stolcke.
2002.
SRILM ?
AnExtensible Language Modeling Toolkit.
In Proceed-ings of the Seventh International Conference on SpokenLanguage Processing, pages 901?904.
ISCA, Septem-ber.
[Zens and Ney2008] Richard Zens and Hermann Ney.2008.
Improvements in Dynamic Programming BeamSearch for Phrase-based Statistical Machine Transla-tion.
In International Workshop on Spoken LanguageTranslation, pages 195?205, Honolulu, Hawaii, Octo-ber.32
