Proceedings of the ACL-SIGLEX Workshop on Deep Lexical Acquisition, pages 67?76,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsBootstrapping Deep Lexical Resources: Resources for CoursesTimothy BaldwinDepartment of Computer Science and Software EngineeringUniversity of Melbourne, Victoria 3010 Australiatim@csse.unimelb.edu.auAbstractWe propose a range of deep lexical acqui-sition methods which make use of mor-phological, syntactic and ontological lan-guage resources to model word similarityand bootstrap from a seed lexicon.
Thedifferent methods are deployed in learn-ing lexical items for a precision gram-mar, and shown to each have strengths andweaknesses over different word classes.
Aparticular focus of this paper is the rela-tive accessibility of different language re-source types, and predicted ?bang for thebuck?
associated with each in deep lexicalacquisition applications.1 IntroductionOver recent years, computational linguistics hasbenefitted considerably from advances in statisti-cal modelling and machine learning, culminatingin methods capable of deeper, more accurate au-tomatic analysis, over a wider range of languages.Implicit in much of this work, however, has beenthe existence of deep language resources (DLRhereafter) of ever-increasing linguistic complexity,including lexical semantic resources (e.g.
Word-Net and FrameNet), precision grammars (e.g.
theEnglish Resource Grammar and the various Par-Gram grammars) and richly-annotated treebanks(e.g.
PropBank and CCGbank).Due to their linguistic complexity, DLRs are in-variably constructed by hand and thus restricted insize and coverage.
Our aim in this paper is to de-velop general-purpose automatic methods which canbe used to automatically expand the coverage of anexisting DLR, through the process of deep lexicalacquisition (DLA hereafter).The development of DLRs can be broken downinto two basic tasks: (1) design of a data represen-tation to systematically capture the generalisationsand idiosyncracies of the dataset of interest (systemdesign); and (2) classification of data items accord-ing to the predefined data representation (data clas-sification).
In the case of a deep grammar, for exam-ple, system design encompasses the construction ofthe system of lexical types, templates, and/or phrasestructure rules, and data classification correspondsto the determination of the lexical type(s) each in-dividual lexeme conforms to.
DLA pertains to thesecond of these tasks, in automatically mapping agiven lexeme onto a pre-existing system of lexicaltypes associated with a DLR.We propose to carry out DLA through a boot-strap process, that is by employing some notion ofword similarity, and learning the lexical types for anovel lexeme through analogy with maximally sim-ilar word(s) for which we know the lexical types.
Inthis, we are interested in exploring the impact of dif-ferent secondary language resources (LRs) on DLA,and estimating how successfully we can expect tolearn new lexical items from a range of LR types.That is, we estimate the expected DLA ?bang for thebuck?
from a range of secondary LR types of vary-ing size and complexity.
As part of this, we lookat the relative impact of different LRs on DLA fordifferent open word classes, namely nouns, verbs,adjectives and adverbs.We demonstrate the proposed DLA methods rel-ative to the English Resource Grammar (see Sec-tion 2.1), and in doing so assume the lexical typesof the target DLR to be syntactico-semantic in na-ture.
For example, we may predict that the worddog has a usage as an intransitive countable noun(n intr le,1 cf.
The dog barked), and also as atransitive verb (v np trans le, cf.
It dogged myevery step).A secondary interest of this paper is the consid-eration of how well we could expect to performDLA for languages of differing density, from ?low-1All example lexical types given in this paper are taken di-rectly from the English Resource Grammar ?
see Section 2.1.67density?
languages (such as Walpiri or Uighur) forwhich we have limited LRs, to ?high-density?
lan-guages (such as English or Japanese) for which wehave a wide variety of LRs.
To this end, while we ex-clusively target English in this paper, we experimentwith a range of LRs of varying complexity and type,including morphological, syntactic and ontologicalLRs.
Note that we attempt to maintain consistencyacross the feature sets associated with each, to makeevaluation as equitable as possible.The remainder of this paper is structured as fol-lows.
Section 2 outlines the process of DLA and re-views relevant resources and literature.
Sections 3,4 and 5 propose a range of DLA methods based onmorphology, syntax and ontological semantics, re-spectively.
Section 6 evaluates the proposed meth-ods relative to the English Resource Grammar.2 Task OutlineThis research aims to develop methods for DLAwhich can be run automatically given: (a) a pre-existing DLR which we wish to expand the cover-age of, and (b) a set of secondary LRs/preprocessorsfor that language.
The basic requirements to achievethis are the discrete inventory of lexical types in theDLR, and a pre-classification of each secondary LR(e.g.
as a corpus or wordnet, to determine what set offeatures to employ).
Beyond this, we avoid makingany assumptions about the language family or DLRtype.The DLA strategy we propose in this research isto use secondary LR(s) to arrive at a feature sig-nature for each lexeme, and map this onto the sys-tem of choice indirectly via supervised learning, i.e.observation of the correlation between the featuresignature and classification of bootstrap data.
Thismethodology can be applied to unannotated corpusdata, for example, making it possible to tune a lex-icon to a particular domain or register as exempli-fied in a particular repository of text.
As it does notmake any assumptions about the nature of the sys-tem of lexical types, we can apply it fully automat-ically to any DLR and feed the output directly intothe lexicon without manual intervention or worry ofmisalignment.
This is a distinct advantage when theinventory of lexical types is continually undergoingrefinement, as is the case with the English ResourceGrammar (see below).A key point of interest in this paper is the investi-gation of the relative ?bang for the buck?
when dif-ferent types of LR are used for DLA.
Crucially, weinvestigate only LRs which we believe to be plausi-bly available for languages of varying density, andaim to minimise assumptions as to the pre-existenceof particular preprocessing tools.
The basic types ofresources and tools we experiment with in this paperare detailed in Table 1.Past research on DLA falls into two basic cat-egories: expert system-style DLA customised tolearning particular linguistic properties, and DLAvia resource translation.
In the first instance, a spe-cialised methodology is proposed to (automatically)learn a particular linguistic property such as verbsubcategorisation (e.g.
Korhonen (2002)) or nouncountability (e.g.
Baldwin and Bond (2003a)), andlittle consideration is given to the applicability ofthat method to more general linguistic properties.
Inthe second instance, we take one DLR and map itonto another to arrive at the lexical information inthe desired format.
This can take the form of a one-step process, in mining lexical items directly froma DLR (e.g.
a machine-readable dictionary (Sanfil-ippo and Poznan?ski, 1992)), or two-step process inreusing an existing system to learn lexical propertiesin one format and then mapping this onto the DLRof choice (e.g.
Carroll and Fang (2004) for verb sub-categorisation learning).There have also been instances of more gen-eral methods for DLA, aligned more closely withthis research.
Fouvry (2003) proposed a methodof token-based DLA for unification-based precisiongrammars, whereby partially-specified lexical fea-tures generated via the constraints of syntactically-interacting words in a given sentence context, arecombined to form a consolidated lexical entry forthat word.
That is, rather than relying on indi-rect feature signatures to perform lexical acquisition,the DLR itself drives the incremental learning pro-cess.
Also somewhat related to this research is thegeneral-purpose verb feature set proposed by Joanisand Stevenson (2003), which is shown to be appli-cable in a range of DLA tasks relating to Englishverbs.2.1 English Resource GrammarAll experiments in this paper are targeted at theEnglish Resource Grammar (ERG; Flickinger(2002), Copestake and Flickinger (2000)).
The ERGis an implemented open-source broad-coverageprecision Head-driven Phrase Structure Grammar68Secondary LR type Description Preprocessor(s)Word list???
List of words with basic POS ?Morphological lexicon?
Derivational and inflectional word relations ?Compiled corpus???
Unannotated text corpus POS tagger?
?Chunk parser?Dependency parser?WordNet-style ontology?
Lexical semantic word linkages ?Table 1: Secondary LR and tool types targeted in this research (???
= high expectation of availability for agiven language; ??
= medium expectation of availability; ?
= low expectation of availability)(HPSG) developed for both parsing and generation.It contains roughly 10,500 lexical items, which,when combined with 59 lexical rules, compile outto around 20,500 distinct word forms.2 Each lex-ical item consists of a unique identifier, a lexicaltype (one of roughly 600 leaf types organized intoa type hierarchy with a total of around 4,000 types),an orthography, and a semantic relation.
The gram-mar also contains 77 phrase structure rules whichserve to combine words and phrases into larger con-stituents.
Of the 10,500 lexical items, roughly 3,000are multiword expressions.To get a basic sense of the syntactico-semanticgranularity of the ERG, the noun hierarchy, for ex-ample, is essentially a cross-classification of count-ability/determiner co-occurrence, noun valence andpreposition selection properties.
For example, lex-ical entries of n mass count ppof le type canbe either countable or uncountable, and optionallyselect for a PP headed by of (example lexical itemsare choice and administration).As our target lexical type inventory for DLA, weidentified all open-class lexical types with at least10 lexical entries, under the assumption that: (a)the ERG has near-complete coverage of closed-classlexical entries, and (b) the bulk of new lexical entrieswill correspond to higher-frequency lexical types.This resulted in the following breakdown:32All statistics and analysis relating to the ERG in this paperare based on the version of 11 June, 2004.3Note that all results are over simplex lexemes only, and thatwe choose to ignore multiword expressions in this research.Word class Lexical types Lexical itemsNoun 28 3,032Verb 39 1,334Adjective 17 1,448Adverb 26 721Total 110 5,675Note that it is relatively common for a lexeme tooccur with more than one lexical type in the ERG:22.6% of lexemes have more than one lexical type,and the average number of lexical types per lexemeis 1.12.In evaluation, we assume we have prior knowl-edge of the basic word classes each lexeme belongsto (i.e.
noun, verb, adjective and/or adverb), infor-mation which could be derived trivially from pre-existing shallow lexicons and/or the output of a tag-ger.Recent development of the ERG has been tightlycoupled with treebank annotation, and all major ver-sions of the grammar are deployed over a commonset of treebank data to help empirically trace theevolution of the grammar and retrain parse selectionmodels (Oepen et al, 2002).
We treat this as a held-out dataset for use in analysis of the token frequencyof each lexical item, to complement analysis of type-level learning performance (see Section 6).2.2 Classifier designThe proposed procedure for DLA is to generate afeature signature for each word contained in a givensecondary LR, take the subset of lexemes containedin the original DLR as training data, and learn lex-ical items for the remainder of the lexemes throughsupervised learning.
In order to maximise compara-bility between the results for the different DLRs, weemploy a common classifier design wherever possi-ble (in all cases other than ontology-based DLA),69using TiMBL 5.0 (Daelemans et al, 2003); weused the IB1 k-NN learner implementation withinTiMBL, with k = 9 throughout.4 We additionallyemploy the feature selection method of Baldwin andBond (2003b), which generates a combined rankingof all features in descending order of ?informative-ness?
and skims off the top-N features for use inclassification; N was set to 100 in all experiments.As observed above, a significant number of lex-emes in the ERG occur in multiple lexical items.
Ifwe were to take all lexical type combinations ob-served for a single lexeme, the total number of lex-ical ?super?-types would be 451, of which 284 aresingleton classes.
Based on the sparseness of thisdata and also the findings of Baldwin and Bond(2003b) over a countability learning task, we chooseto carry out DLA via a suite of 110 binary classifiers,one for each lexical type.We deliberately avoid carrying out extensive fea-ture engineering over a given secondary LR, choos-ing instead to take a varied but simplistic set of fea-tures which is parallelled as much as possible be-tween LRs (see Sections 3?5 for details).
We addi-tionally tightly constrain the feature space to a max-imum of 3,900 features, and a maximum of 50 fea-ture instances for each feature type; in each case,the 50 feature instances are selected by taking thefeatures with highest saturation (i.e.
the highest ra-tio of non-zero values) across the full lexicon.
Thisis in an attempt to make evaluation across the differ-ent secondary LRs as equitable as possible, and geta sense of the intrinsic potential of each secondaryLR in DLA.
Each feature instance is further trans-lated into two feature values: the raw count of thefeature instance for the target word in question, andthe relative occurrence of the feature instance overall target word token instances.One potential shortcoming of our classifier archi-tecture is that a given word can be negatively clas-sified by all unit binary classifiers and thus not as-signed any lexical items.
In this case, we fall backon the majority-class lexical type for each word classthe word has been pre-identified as belonging to.4We also experimented with bsvm and SVMLight, and amaxent toolkit, but found TiMBL to be superior overall, we hy-pothesise due to the tight integration of continuous features inTiMBL.3 Morphology-based Deep LexicalAcquisitionWe first perform DLA based on the following mor-phological LRs: (1) word lists, and (2) morphologi-cal lexicons with a description of derivational wordcorrespondences.
Note that in evaluation, we pre-suppose that we have access to word lemmas al-though in the first instance, it would be equally pos-sible to run the method over non-lemmatised data.53.1 Character n-gramsIn line with our desire to produce DLA methodswhich can be deployed over both low- and high-density languages, our first feature representationtakes a simple word list and converts each lexemeinto a character n-gram representation.6 In the caseof English, we generated all 1- to 6-grams for eachlexeme, and applied a series of filters to: (1) filter outall n-grams which occurred less than 3 times in thelexicon data; and (2) filter out all n-grams which oc-cur with the same frequency as larger n-grams theyare proper substrings of.
We then select the 3,900character n-grams with highest saturation across thelexicon data (see Section 2.2).The character n-gram-based classifier is the sim-plest of all classifiers employed in this research, andcan be deployed on any language for which we havea word list (ideally lemmatised).3.2 Derviational morphologyThe second morphology-based DLA method makesuse of derivational morphology and analysis of theprocess of word formation.
As an example of howderivational information could assist DLA, know-ing that the noun achievement is deverbal and in-corporates the -ment suffix is a strong predictor ofit being optionally uncountable and optionally se-lecting for a PP argument (i.e.
being of lexical typen mass count ppof le).We generate derivational morphological featuresfor a given lexeme by determining its word clus-ter in CATVAR7 (Habash and Dorr, 2003) and thenfor each sister lexeme (i.e.
lexeme occurring in the5Although this would inevitably lose lexical generalisationsamong the different word forms of a given lemma.6We also experimented with syllabification, but found thecharacter n-grams to produce superior results.7In the case that the a given lemma is not in CATVAR, weattempt to dehyphenate and then deprefix the word to find amatch, failing which we look for the lexeme of smallest editdistance.70same cluster as the original lexeme with the sameword stem), determine if there is a series of editoperations over suffixes and prefixes which mapsthe lexemes onto one another.
For each sister lex-eme where such a correspondence is found to ex-ist, we output the nature of the character transforma-tion and the word classes of the lexemes involved.E.g., the sister lexemes for achievementN in CAT-VAR are achieveV, achieverN, achievableAdj andachievabilityN; the mapping between achievementNand achieverN, e.g., would be analysed as:N ?ment$ ?
N +r$Each such transformation is treated as a single fea-ture.We exhaustively generate all such transformationsfor each lexeme, and filter the feature space as forcharacter n-grams above.Clearly, LRs which document derivational mor-phology are typically only available for high-densitylanguages.
Also, it is worth bearing in mind thatderivational morphology exists in only a limitedform for certain language families, e.g.
agglutinativelanguages.4 Syntax-based Deep Lexical AcquisitionSyntax-based DLA takes a raw text corpus and pre-processes it with either a tagger, chunker or depen-dency parser.
It then extracts a set of 39 feature typesbased on analysis of the token occurrences of a givenlexeme, and filters over each feature type to producea maximum of 50 feature instances of highest satura-tion (e.g.
if the feature type is the word immediatelyproceeding the target word, the feature instances arethe 50 words which proceed the most words in ourlexicon).
The feature signature associated with aword for a given preprocessor type will thus havea maximum of 3,900 items (39?
50?
2).84.1 TaggingThe first and most basic form of syntactic pre-processing is part-of-speech (POS) tagging.
Forour purposes, we use a Penn treebank-style taggercustom-built using fnTBL 1.0 (Ngai and Florian,2001), and further lemmatise the output of the taggerusing morph (Minnen et al, 2000).8Note that we will have less than 50 feature instances forsome feature types, e.g.
the POS tag of the target word, giventhat the combined size of the Penn POS tagset is 36 elements(not including punctuation).The feature types used with the tagger are detailedin Table 2, where the position indices are relative tothe target word (e.g.
the word at position ?2 is twowords to the left of the target word, and the POStag at position 0 is the POS of the target word).
Allfeatures are relative to the POS tags and words in theimmediate context of each token occurrence of thetarget word.
?Bi-words?
are word bigrams (e.g.
bi-word (1, 3) is the bigram made up of the words oneand three positions to the right of the target word);?bi-tags?
are, similarly, POS tag bigrams.4.2 ChunkingThe second form of syntactic preprocessing, whichbuilds directly on the output of the POS tagger, isCoNLL 2000-style full text chunking (Tjong KimSang and Buchholz, 2000).
The particular chun-ker we use was custom-built using fnTBL 1.0 onceagain, and operates over the lemmatised output ofthe POS tagger.The feature set for the chunker output includes asubset of the POS tagger features, but also makesuse of the local syntactic structure in the chunker in-put in incorporating both intra-chunk features (suchas modifiers of the target word if it is the head of achunk, or the head if it is a modifier) and inter-chunkfeatures (such as surrounding chunk types when thetarget word is chunk head).
See Table 2 for full de-tails.Note that while chunk parsers are theoreticallyeasier to develop than full phrase-structure or tree-bank parsers, only high-density languages such asEnglish and Japanese have publicly available chunkparsers.4.3 Dependency parsingThe third and final form of syntactic preprocessingis dependency parsing, which represents the pinna-cle of both robust syntactic sophistication and inac-cessibility for any other than the highest-density lan-guages.The particular dependency parser we use isRASP9 (Briscoe and Carroll, 2002), which outputshead?modifier dependency tuples and further classi-fies each tuple according to a total of 14 relations;RASP also outputs the POS tag of each word to-ken.
As our features, we use both local word andPOS features, for comparability with the POS tagger9RASP is, strictly speaking, a full syntactic parser, but weuse it in dependency parser mode71Feature type Positions/description TotalTAGGER 39POS tag (?4,?3,?2,?1, 0, 1, 2, 3, 4) 9Word (?4,?3,?2,?1, 1, 2, 3, 4) 8POS bi-tag ( (?4,?1), (?4, 0), (?3,?2), (?3,?1), (?3, 0), (?2,?1), (?2, 0),(?1, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 2), (1, 3), (1, 4), (2, 3) ) 16Bi-word ((?3,?2), (?3,?1), (?2,?1), (1, 2), (1, 3), (2, 3)) 6CHUNKER 39Modifierhead Chunk heads when target word is modifier 1Modifierchunk Chunk types when target word is modifier 1Modifieeword Modifiers when target word is chunk head 1ModifieePOS POS tag of modifiers when target word is chunk head 1Modifieeword+POS Word + POS tag of modifiers when target word is chunk head 1POS tag (?3,?2,?1, 0, 1, 2, 3) 7Word (?3,?2,?1, 1, 2, 3) 6Chunk (?4,?3,?2,?1, 0, 1, 2, 3, 4) 9Chunk head (?3,?2,?1, 1, 2, 3) 6Bi-chunk ((?2,?1), (?2, 0), (?1, 0), (0, 1), (0, 2), (1, 2)) 6DEPENDENCY PARSER 39POS tag (?2,?1, 0, 1, 2) 5Word (?2,?1, 1, 2) 4Conjword Words the target word coordinates with 1ConjPOS POS of words the target word coordinates with 1Head Head word when target word modifier in dependency relation (?
14) 14Modifier Modifier when target word head of dependency relation (?
14) 14Table 2: Feature types used in syntax-based DLA for the different preprocessorsand chunker, and also dependency-derived features,namely the modifier of all dependency tuples the tar-get word occurs as head of, and conversely, the headof all dependency tuples the target word occurs asmodifier in, along with the dependency relation ineach case.
See Table 2 for full details.4.4 CorporaWe ran the three syntactic preprocessors over a to-tal of three corpora, of varying size: the Brown cor-pus (?460K tokens) and Wall Street Journal corpus(?1.2M tokens), both derived from the Penn Tree-bank (Marcus et al, 1993), and the written compo-nent of the British National Corpus (?98M tokens:Burnard (2000)).
This selection is intended to modelthe effects of variation in corpus size, to investigatehow well we could expect syntax-based DLA meth-ods to perform over both smaller and larger corpora.Note that the only corpus annotation we make useof is sentence tokenisation, and that all preproces-sors are run automatically over the raw corpus data.This is in an attempt to make the methods maximallyapplicable to lower-density languages where anno-tated corpora tend not to exist but there is at least thepossibility of accessing raw text collections.5 Ontology-based Deep LexicalAcquisitionThe final DLA method we explore is based on thehypothesis that there is a strong correlation betweenthe semantic and syntactic similarity of words, aclaim which is best exemplified in the work of Levin(1993) on diathesis alternations.
In our case, wetake word similarity as given and learn the syntacticbehaviour of novel words relative to semantically-similar words for which we know the lexical types.We use WordNet 2.0 (Fellbaum, 1998) to determineword similarity, and for each sense of the targetword in WordNet: (1) construct the set of ?seman-tic neighbours?
of that word sense, comprised of allsynonyms, direct hyponyms and direct hypernyms;and (2) take a majority vote across the lexical typesof the semantic neighbours which occur in the train-ing data.
Note that this diverges from the learningparadigm adopted for the morphology- and syntax-based DLA methods in that we use a simple votingstrategy rather than relying on an external learner tocarry out the classification.
The full set of lexicalentries for the target word is generated by taking theunion of the majority votes across all senses of theword, such that a polysemous lexeme can potentiallygive rise to multiple lexical entries.
This learning72procedure is based on the method used by van derBeek and Baldwin (2004) to learn Dutch countabil-ity.As for the suite of binary classifiers, we fall backon the majority class lexical type as the default inthe instance that a given lexeme is not contained inWordNet 2.0 or no classification emerges from theset of semantic neighbours.
It is important to re-alise that WordNet-style ontologies exist only for thehighest-density languages, and that this method willthus have very limited language applicability.6 EvaluationWe evaluate the component methods over the 5,675open-class lexical items of the ERG described inSection 2.1 using 10-fold stratified cross-validation.In each case, we calculate the type precision (theproportion of correct hypothesised lexical entries)and type recall (the proportion of gold-standard lex-ical entries for which we get a correct hit), whichwe roll together into the type F-score (the harmonicmean of the two) relative to the gold-standard ERGlexicon.
We also measure the token accuracy forthe lexicon derived from each method, relative tothe Redwoods treebank of Verbmobil data associ-ated with the ERG (see Section 2.1).10 The token ac-curacy represents a weighted version of type preci-sion, relative to the distribution of each lexical itemin a representative text sample, and provides a crudeapproximation of the impact of each DLA methodon parser coverage.
That is, it gives more credit for amethod having correctly hypothesised a commonly-occurring lexical item than a low-frequency lexicalitem, and no credit for having correctly identified alexical item not occurring in the corpus.The overall results are presented in Figure 1,which are then broken down into the four openword classes in Figures 2?5.
The baseline method(Base) in each case is a simple majority-class classi-fier, which generates a unique lexical item for eachlexeme pre-identified as belonging to a given wordclass of the following type:Word class Majority-class lexical typeNoun n intr leVerb v np trans leAdjective adj intrans leAdverb adv int vp le10Note that the token accuracy is calculated only over theopen-class lexical items, not the full ERG lexicon.In each graph, we present the type F-score and to-ken accuracy for each method, and mark the best-performing method in terms of each of these evalua-tion measures with a star (?).
The results for syntax-based DLA (SPOS, SCHUNK and SPARSE) are basedon the BNC in each case.
We return to investigatethe impact of corpus size on the performance of thesyntax-based methods below.Looking first at the combined results over all lex-ical types (Figure 1), the most successful methodin terms of type F-score is syntax-based DLA,with chunker-based preprocessing marginally out-performing tagger- and parser-based preprocessing(type F-score = 0.641).
The most successful methodin terms of token accuracy is ontology-based DLA(token accuracy = 0.544).The figures for token accuracy require some qual-ification: ontology-based DLA tends to be liberalin its generation of lexical items, giving rise toover 20% more lexical items than the other meth-ods (7,307 vs. 5-6000 for the other methods) andproportionately low type precision.
This correlateswith an inherent advantage in terms of token ac-curacy, which we have no way of balancing up inour token-based evaluation, as the treebank data of-fers no insight into the true worth of false nega-tive lexical items (i.e.
have no way of distinguishingbetween unobserved lexical items which are plainwrong from those which are intuitively correct andcould be expected to occur in alternate sets of tree-bank data).
We leave investigation of the impact ofthese extra lexical items on the overall parser perfor-mance (in terms of chart complexity and parse se-lection) as an item for future research.The morphology-based DLA methods werearound baseline performance overall, with charac-ter n-grams marginally more successful than deriva-tional morphology in terms of both type F-score andtoken accuracy.Turning next to the results for the proposed meth-ods over nouns, verbs, adjectives and adverbs (Fig-ures 2?5, respectively), we observe some interest-ing effects.
First, morphology-based DLA hoversaround baseline performance for all word classesexcept adjectives, where character n-grams producethe highest F-score of all methods, and nouns, wherederivational morphology seems to aid DLA slightly(providing weak support for our original hypothesisin Section 3.2 relating to deverbal nouns and affixa-tion).7300.20.40.60.81OntBase  00.20.40.60.81Type F-scoreToken accuracyMethod S    PARSES    CHUNKS    POSM    DERIVM    CHAR* *Figure 1: Results for the proposed deep lexical ac-quisition methods over ALL lexical types00.20.40.60.81OntBase  00.20.40.60.81Token accuracyMethodM    DERIVM    CHAR S    PARSES    CHUNKS    POS* *Type F-scoreFigure 2: Results for the proposed deep lexical ac-quisition methods over NOUN lexical types00.20.40.60.81OntBase  00.20.40.60.81Token accuracyMethodM    DERIVM    CHAR S    PARSES    CHUNKS    POS**Type F-scoreFigure 3: Results for the proposed deep lexical ac-quisition methods over VERB lexical types00.20.40.60.81OntBase  00.20.40.60.81Token accuracyMethodM    DERIVM    CHAR S    PARSES    CHUNKS    POS**Type F-scoreFigure 4: Results for the proposed deep lexical ac-quisition methods over ADJECTIVE lexical types00.20.40.60.81OntBase  00.20.40.60.81Token accuracyMethodM    DERIVM    CHAR S    PARSES    CHUNKS    POS**TypeF-scoreFigure 5: Results for the proposed deep lexical ac-quisition methods over ADVERB lexical types00.20.40.60.81BNCWSJBrown  00.20.40.60.81Type F-score ()Token accuracy ()CorpusNounVerbAdjAdvoerbAdjF-scoreToken accFigure 6: Results for the syntax-based deep lexicalacquisition methods over corpora of differing sizeNote: Base = baseline, MCHAR = morphology-based DLA with character n-grams, MDERIV = derivationalmorphology-based DLA, SPOS = syntax-based DLA with POS tagging, SCHUNK = syntax-based DLA withchunking, SPARSE = syntax-based DLA with dependency parsing, and Ont = ontology-based DLA74Syntax-based DLA leads to the highest type F-score for nouns, verbs and adverbs, and the highesttoken accuracy for adjectives and adverbs.
The dif-ferential in results between syntax-based DLA andthe other methods is particularly striking for ad-verbs, with a maximum type F-score of 0.544 (forchunker-based preprocessing) and token accuracy of0.340 (for tagger-based preprocessing), as comparedto baseline figures of 0.471 and 0.017 respectively.There is relatively little separating the three stylesof preprocessing in syntax-based DLA, althoughchunker-based preprocessing tends to have a slightedge in terms of type F-score, and tagger-based pre-processing generally produces the highest token ac-curacy.11 This suggests that access to a POS taggerfor a given language is sufficient to make syntax-based DLA work, and that syntax-based DLA thushas moderately high applicability across languagesof different densities.Ontology-based DLA is below baseline in termsof type F-score for all word classes, but results inthe highest token accuracy of all methods for nounsand verbs (although this finding must be taken witha grain of salt, as noted above).Another noteworthy feature of Figures 2?5 is thehuge variation in absolute performance across theword classes: adjectives are very predictable, with amajority class-based baseline type F-score of 0.832and token accuracy of 0.847; adverbs, on the otherhand, are similar to verbs and nouns in terms of theirbaseline type F-score (at 0.471), but the adverbs thatoccur commonly in corpus data appear to belong toless-populated lexical types (as seen in the baselinetoken accuracy of a miniscule 0.017).
Nouns appearthe hardest to learn in terms of the relative incre-ment in token accuracy over the baseline.
Verbs areextremely difficult to get right at the type level, but itappears that ontology-based DLA is highly adept atgetting the commonly-occurring lexical items right.To summarise these findings, adverbs seem tobenefit the most from syntax-based DLA.
Adjec-tives, on the other hand, can be learned most effec-tively from simple character n-grams, i.e.
similarly-spelled adjectives tend to have similar syntax, asomewhat surprising finding.
Nouns are surpris-ingly hard to learn, but seem to benefit to some de-gree from corpus data and also ontological similar-ity.
Lastly, verbs pose a challenge to all methods11This trend was observed across all three corpora, althoughwe do no present the full results here.at the type level, but ontology-based DLA seems tobe able to correctly predict the commonly-occurringlexical entries.Finally, we examine the impact of corpus size onthe performance of syntax-based DLA with tagger-based preprocessing.12 In Figure 6, we examinethe relative change in type F-score and token ac-curacy across the four word classes as we increasethe corpus size (from 0.5m words to 1m and fi-nally 100m words, in the form of the Brown cor-pus, WSJ corpus and BNC, respectively).
For verbsand adjectives, there is almost no change in eithertype F-score or token accuracy when we increasethe corpus size, whereas for nouns, the token ac-curacy actually drops slightly.
For adverbs, on theother hand, the token accuracy jumps up from 0.020to 0.381 when we increase the corpus size from1m words to 100m words, while the type F-scorerises only slightly.
It thus seems to be the case thatlarge corpora have a considerable impact on DLAfor commonly-occurring adverbs, but that for theremaining word classes, it makes little differencewhether we have 0.5m or 100m words.
This canbe interpreted either as evidence that modestly-sizedcorpora are good enough to perform syntax-basedDLA over (which would be excellent news for low-density languages!
), or alternatively that for the sim-plistic syntax-based DLA methods proposed here,more corpus data is not the solution to achievinghigher performance.Returning to our original question of the ?bangfor the buck?
associated with individual LRs, thereseems to be no simple answer: simple word lists areuseful in learning the syntax of adjectives in particu-lar, but offer little in terms of learning the other threeword classes.
Morphological lexicons with deriva-tional information are moderately advantageous inlearning the syntax of nouns but little else.
A POStagger seems sufficient to carry out syntax-basedDLA, and the word class which benefits the mostfrom larger amounts of corpus data is adverbs, other-wise the proposed syntax-based DLA methods don?tseem to benefit from larger-sized corpora.
Ontolo-gies have the greatest impact on verbs and, to a lesserdegree, nouns.
Ultimately, this seems to lend weightto a ?horses for courses?, or perhaps ?resources forcourses?
approach to DLA.12The results for chunker- and parser-based preprocessing arealmost identical, and this omitted from the paper.757 ConclusionWe have proposed three basic paradigms for deeplexical acquisition, based on morphological, syntac-tic and ontological language resources, and demon-strated the effectiveness of each strategy at learn-ing lexical items for the lexicon of a precision En-glish grammar.
We discovered surprising variationin the results for the different DLA methods, witheach learning method performing particularly wellfor at least one basic word class, but the best overallmethods being syntax- and ontology-based DLA.The results presented in this paper are based onone particular language (English) and a very spe-cific style of DLR (a precision grammar, namely theEnglish Resource Grammar), so some caution mustbe exercised in extrapolating the results too liberallyover new languages/DLA tasks.
In future research,we are interested in carrying out experiments overother languages and alternate DLRs to determinehow well these results generalise and formulate al-ternate strategies for DLA.AcknowledgementsThis material is based upon work supported in part by NTTCommunication Science Laboratories, Nippon Telegraph andTelephone Corporation.
We would like to thank the membersof the University of Melbourne LT group and the three anony-mous reviewers for their valuable input on this research.ReferencesTimothy Baldwin and Francis Bond.
2003a.
Learning thecountability of English nouns from corpus data.
In Proc.
ofthe 41st Annual Meeting of the ACL, pages 463?70, Sapporo,Japan.Timothy Baldwin and Francis Bond.
2003b.
A plethora ofmethods for learning English countability.
In Proc.
of the2003 Conference on Empirical Methods in Natural Lan-guage Processing (EMNLP 2003), pages 73?80, Sapporo,Japan.Ted Briscoe and John Carroll.
2002.
Robust accurate statisticalannotation of general text.
In Proc.
of the 3rd InternationalConference on Language Resources and Evaluation (LREC2002), pages 1499?1504, Las Palmas, Canary Islands.Lou Burnard.
2000.
User Reference Guide for the British Na-tional Corpus.
Technical report, Oxford University Comput-ing Services.John Carroll and Alex Fang.
2004.
The automatic acquisi-tion of verb subcategorisations and their impact on the per-formance of an HPSG parser.
In Proc.
of the First Inter-national Joint Conference on Natural Language Processing(IJCNLP-04), pages 107?14, Sanya City, China.Ann Copestake and Dan Flickinger.
2000.
An open-sourcegrammar development environment and broad-coverage En-glish grammar using HPSG.
In Proc.
of the 2nd Interna-tional Conference on Language Resources and Evaluation(LREC 2000), Athens, Greece.Walter Daelemans, Jakub Zavrel, Ko van der Sloot, and An-tal van den Bosch.
2003.
TiMBL: Tilburg Memory BasedLearner, version 5.0, Reference Guide.
ILK Technical Re-port 03-10.Christiane Fellbaum, editor.
1998.
WordNet: An ElectronicLexical Database.
MIT Press, Cambridge, USA.Dan Flickinger.
2002.
On building a more efficient grammar byexploiting types.
In Stephan Oepen, Dan Flickinger, Jun?ichiTsujii, and Hans Uszkoreit, editors, Collaborative LanguageEngineering.
CSLI Publications, Stanford, USA.Frederik Fouvry.
2003.
Robust Processing for Constraint-based Grammar Formalisms.
Ph.D. thesis, University of Es-sex.Nizar Habash and Bonnie Dorr.
2003.
CATVAR: A databaseof categorial variations for English.
In Proc.
of the NinthMachine Translation Summit (MT Summit IX), pages 471?4,New Orleans, USA.Eric Joanis and Suzanne Stevenson.
2003.
A general featurespace for automatic verb classification.
In Proc.
of the 10thConference of the EACL (EACL 2003), pages 163?70, Bu-dapest, Hungary.Anna Korhonen.
2002.
Subcategorization Acquisition.
Ph.D.thesis, University of Cambridge.Beth Levin.
1993.
English Verb Classes and Alterations.
Uni-versity of Chicago Press, Chicago, USA.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotated corpusof English: the Penn treebank.
Computational Linguistics,19(2):313?30.Guido Minnen, John Carroll, and Darren Pearce.
2000.
Ro-bust, applied morphological generation.
In Proceedings ofthe first International Natural Language Genration Confer-ence, Mitzpe Ramon, Israel.Grace Ngai and Radu Florian.
2001.
Transformation-basedlearning in the fast lane.
In Proc.
of the 2nd Annual Meetingof the North American Chapter of Association for Compu-tational Linguistics (NAACL2001), pages 40?7, Pittsburgh,USA.Stephan Oepen, Dan Flickinger, Kristina Toutanova, andChristoper D. Manning.
2002.
LinGO Redwoods: A richand dynamic treebank for HPSG.
In Proc.
of The First Work-shop on Treebanks and Linguistic Theories (TLT2002), So-zopol, Bulgaria.Antonio Sanfilippo and Victor Poznan?ski.
1992.
The acquisi-tion of lexical knowledge from combined machine-readabledictionary sources.
In Proc.
of the 3rd Conference on Ap-plied Natural Language Processing (ANLP), pages 80?7,Trento, Italy.Erik F. Tjong Kim Sang and Sabine Buchholz.
2000.
Introduc-tion to the CoNLL-2000 shared task: Chunking.
In Proc.of the 4th Conference on Computational Natural LanguageLearning (CoNLL-2000), Lisbon, Portugal.Leonoor van der Beek and Timothy Baldwin.
2004.
Crosslin-gual countability classification with EuroWordNet.
In Pa-pers from the 14th Meeting of Computational Linguistics inthe Netherlands, pages 141?55, Antwerp, Belgium.
AntwerpPapers in Linguistics.76
