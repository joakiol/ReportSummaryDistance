Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 854?862, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsRe-training Monolingual Parser Bilingually for Syntactic SMT?Shujie Liu*, ?Chi-Ho Li, ?Mu Li and ?Ming Zhou?School of Computer Science and TechnologyHarbin Institute of Technology, Harbin, Chinashujieliu@mtlab.hit.edu.cn?Microsoft Research Asia, Beijing, China{chl, muli, mingzhou}@microsoft.comAbstractThe training of most syntactic SMT approachesinvolves two essential components, wordalignment and monolingual parser.
In thecurrent state of the art these two componentsare mutually independent, thus causingproblems like lack of rule generalization, andviolation of syntactic correspondence intranslation rules.
In this paper, we propose twoways of re-training monolingual parser with thetarget of maximizing the consistency betweenparse trees and alignment matrices.
One istargeted self-training with a simple evaluationfunction; the other is based on training dataselection from forced alignment of bilingualdata.
We also propose an auxiliary method forboosting alignment quality, by symmetrizingalignment matrices with respect to parse trees.The best combination of these novel methodsachieves 3 Bleu point gain in an IWSLT taskand more than 1 Bleu point gain in NIST tasks.1 IntroductionThere are many varieties in syntactic statisticalmachine translation (SSMT).
Apart from a fewattempts to use synchronous parsing to produce thetree structure of both source language (SL) andtarget language (TL) simultaneously, most SSMTapproaches make use of monolingual parser toproduce the parse tree(s) of the SL and/or TLsentences, and then link up the information of thetwo languages through word alignment.
In thecurrent state of the art, word aligner andmonolingual parser are trained and appliedseparately.
On the one hand, an average wordaligner does not consider the syntax information ofboth languages, and the output links may violatesyntactic correspondence.
That is, some SL wordsyielded by a SL parse tree node may not be tracedto, via alignment links, some TL words withlegitimate syntactic structure.
On the other hand,parser design is a monolingual activity and itsimpact on MT is not well studied (Ambati, 2008).Many good translation rules may thus be filteredby a good monolingual parser.In this paper we will focus on the translationtask from Chinese to English, and the string-to-treeSSMT model as elaborated in (Galley et al2006).There are two kinds of translation rules in thismodel, minimal rules, and composed rules, whichare composition of minimal rules.
The minimalrules are extracted from a special kind of nodes,known as frontier nodes, on TL parse tree.
Theconcept of frontier node can be illustrated byFigure 1, which shows two partial bilingualsentences with the corresponding TL sub-trees andword alignment links.
The TL words yielded by aTL parse node can be traced to the correspondingSL words through alignment links.
In the diagram,each parse node is represented by a rectangle,showing the phrase label, span, and complementspan respectively.
The span of a TL node   isdefined as the minimal contiguous SL string thatcovers all the SL words reachable from  .
Thecomplement span of   is the union of spans of allthe nodes that are neither descendants norancestors of   (c.f.
Galley et al2006) .
A frontiernode is a node of which the span and thecomplement span do not overlap with each other.In the diagram, frontier nodes are grey in color.Frontier node is the key in the SSMT model, as itidentifies the bilingual information which isconsistent with both the parse tree and alignmentmatrix.There are two major problems in the SSMTmodel.
The first one is the violation of syntactic854structure by incorrect alignment links, as shown bythe two dashed links in Figure 1(a).
These twoincorrect links hinder the extraction of a goodminimal rule ???
?
and that of agood composed rule ???
, ?
NP(DT(the),NN(herdsmen), POS('s)) ?.
By and large, incorrectalignment links lead to translation rules that arelarge in size, few in number, and poor ingeneralization ability (Fossum et al008).
Thesecond problem is parsing error, as shown inFigure 1(b).
The incorrect POS tagging of the word?lectures" causes a series of parsing errors,including the absence of the noun phrase?NP(NN(propaganda), NN(lectures))?.
Theseparsing errors hinder the extraction of good rules,such as ?
?
?
NP(NN(propaganda),NN(lectures)) ?.Note that in Figure 1(a), the parse tree is correct,and the incorrect alignment links might be fixed ifthe aligner takes the parse tree into consideration.Similarly, in Figure 1(b) some parsing errors mightbe fixed if the parser takes into consideration thecorrect alignment links about ?propaganda?
and?lecture?.
That is, alignment errors and parsingmight be fixed if word aligner and parser are notmutually independent.In this paper, we emphasize more on thecorrection of parsing errors by exploitingalignment information.
The general approach is tore-train a parser with parse trees which are themost consistent with alignment matrices.
Our firststrategy is to apply the idea of targeted self-training (Katz-Brown et al2011) with the simpleevaluation function of frontier set size.
That is tore-train the parser with the parse trees which giverise to the largest number of frontier nodes.
Thesecond strategy is to apply forced alignment(Wuebker et al2010) to bilingual data and selectthe parse trees generated by our SSMT system forre-training the parser.
Besides, although we do notinvent a new word aligner exploiting syntacticinformation, we propose a new method tosymmetrize the alignment matrices of twodirections by taking parse tree into consideration.61-6NNS61-6POS41-3,5-6NNIN31-2,4-6lived1in2the3herdsmen4?s5yurts6at7night8??1??2?3??4?5?
?62 3 null1 4 6 6 6 1VDB21,3-6DTnull11-661-6IN12-6NN12-6NP4-61-3,6NP4-61-3,6NP3-61-6PP1-62-6PP1-6----VPa1large2number3of4people5coming6to7listen8to9their10propaganda11lectures12?1?2??3??4?5?6?
?77 7 5 6 1 4 4null null null null 3null1-7DT71-7JJ71-7NN51-4,6-7IN61-5,7NNS13-7VBGnull1-7TOnull1-7VBnull1-7TO31,4-7PRP41-7NN41-7VP71-6NP3-41,4-7NP3-41,4-7PP3-41,4-7VP3-41,4-7VP1-44-7VP61-5,7NP1-64,5,7NP1-64,7PP1-74NP1-7----S(a)  (b)Figure 1.
Two example partial bilingual sentences with word alignment and syntactic tree for thetarget sentence.
All the nodes in gray are frontier nodes.
Example (a) contains two error links (in dashline), and the syntactic tree for the target sentence of example (b) is wrong.8552 Parser Re-training StrategiesMost monolingual parsers used in SSMT aretrained upon certain tree bank.
That is, a parser istrained with the target of maximizing theagreement between its decision on syntacticstructure and that decision in the human-annotatedparse trees.
As mentioned in Section 1,monolingual syntactic structure is not necessarilysuitable for translation, and sometimes thebilingual information in word alignment may helpthe parser find out the correct structure.
Therefore,it is desirable if there is a way to re-train a parserwith bilingual information.What is needed includes a framework of parserre-training, and a data selection strategy thatmaximizes the consistency between parse tree andalignment matrix.
Our two solutions will beintroduced in the next two subsections respectively.2.1 Targeted Self-Training with Frontier SetBased Evaluation (TST-FS)The first solution is based on targeted self-training(TST) (Katz-Brown et al2011).
In standard self-training, the top one parse trees produced by thecurrent parser are taken as training data for thenext round, and the training objective is still thecorrectness of monolingual syntactic structure.
Intargeted self-training, the training objective shiftsto certain external evaluation function.
For eachsentence, the n-best parse trees from the currentparser are re-ranked in accordance with thisexternal evaluation function, and the top one of there-ranked candidates is then selected as trainingdata for the next round.
The key of targeted self-training is the definition of this external evaluationfunction.As shown by the example in Figure 1(b), anincorrect parse tree is likely to hinder theextraction of good translation rules, because thenumber of frontier nodes in the incorrect tree is ingeneral smaller than that in the correct tree.Consider the example in Figure 2, which is aboutthe same partial bilingual sentence as in Figure1(b).
Although both parse trees do not have thecorrect syntactic structure, the tree in Figure 2 hasmore frontier nodes, leads to more valid translationrules, and is therefore more preferable.This example suggests a very simple externalevaluation function, viz.
the size of frontier set.Given a bilingual sentence, its alignment matrix,and the N-best parse trees of the TL sentence, wewill calculate the number of frontier nodes for eachparse tree, and re-rank the parse trees in itsdescending order.
The new top one parse tree isselected as the training data for the next round oftargeted self-training of the TL parser.
In thefollowing we will call this approach as targetedself-training with frontier set based evaluation(TST-FS).Note that the size of the N-best list should bekept small.
It is because sometimes a parse treewith an extremely mistaken structure happens tohave perfect match with the alignment matrix,thereby giving rise to nearest the largest frontier setsize.
It is empirically found that a 5-best list ofparse trees is already sufficient to significantlyimprove translation performance.2.2 Forced Alignment-based Parser Re-Training (FA-PR)If we doubt that the parse tree from a monolingualparser is not appropriate enough for translationpurpose, then it seems reasonable to consider usingthe parse tree produced by an SSMT system to re-train the parser.
A na?ve idea is simply to run anSSMT system over some SL sentences and retrievethe by-product TL parse trees for re-training themonolingual parser.
The biggest problem of thisna?ve approach is that the translation by an MTsystem is often a 'weird' TL sentence, and thus theassociated parse tree is of little use in improvingthe parser.Forced alignment (Wuebker et al2010) ofbilingual data is a much more promising approach.71-6NP3-41,5-7NP3-41,5-7PP3-41,5-7VP61-5,7NP1-63-5,7NPVP13-71-63-4,7PP3-41,5-7VP1-73-4NPa1large2 number3 of4 people5 coming6 to7 listen8 to9 their10 propaganda11 lectures12?1               ?2            ?
?3           ?
?4                ?5                 ?6               ?
?77 7 5 6 1 4 4null null null null 3null1-7DT71-7JJ71-7NN51-4,6-7IN61-5,7NNS13-7VBGnull1-7TOnull1-7VBnull1-7TO31,4-7PRP41-7NN41-7VPFigure 2.
The parse tree selected by TST-FS forthe example in Figure 1(b)856When applied to SSMT, given a bilingual sentence,it performs phrase segmentation of the SL side,parsing of the TL side, and word alignment of thebilingual sentence, using the full translation systemas in decoding.
It finds the best decoding path thatgenerates the TL side of the bilingual sentence, andthe parse tree of the TL sentence is also obtained asa by-product.
The parse trees from forcedalignment are suitable for re-training themonolingual parser.Here is the simple iterative re-training algorithm.First we have a baseline monolingual parser andplug it into an SSMT system.
Then perform forcedalignment, using the SSMT system, of somebilingual data and obtain the parse trees as newtraining data for the parser.
The new parser canthen be applied again to do the second round offorced alignment.
This iteration of forcedalignment followed by parser re-training is keptgoing until some stopping criterion is met.
In thefollowing we will call this approach as forcedalignment based parser re-training (FA-PR).Algorithm 1  Forced Alignment Based Parser Re-Training (FA-PR)?
step1:      ;                .?
step2: Use parser      to parse targetsentences of training data, and build aSSMT system      .?
step3: Perform forced alignment on trainingdata with      to get parse treesfor target sentence of trainingdata.?
step4: Train a new parser          with.?
step5:                       .?
Step6: Go to step 2, until performance ofon development data drops, or a presetlimit is reached.There are a few important implementationdetails of FA-PR.
Forced alignment is guaranteedto obtain a parse tree if all translation rules are keptand no pruning is performed during decoding.
Yetin reality an average MT system applies pruningduring translation model training and decoding,and a lot of translation rules will then be discarded.In order to have more parse trees be considered byforced alignment, we keep all translation rules andrelax pruning constraints in the decoder, viz.enlarge the stack size of each cell in the chart from50 to 150.Another measure to guarantee the existence of adecoding path in forced alignment is to allow partof a SL or TL sentence translate to null.
Considerthe example in Figure 1(b).
We also add a nullalignment for any span of the source and targetsentences to handle the null translation scenario.
Itis easy to add a null translation candidate for aspan of the source sentence during decoding, butnot easy for target spans.
For example, suppose thebest translation candidate for the source span " ?
1NP ?
5 ?
6 ??
7" is "a large number of peoplecoming NP", and the best translation candidate for"?
2 ??
3 ??
4" is "their propaganda lectures",there is no combination of candidates from two n-best translation lists which can match a sequence inthe given target part, so we add a translationcandidate ("to listen to ") generated from null,whose syntactic label can be any label (decidedaccording to the translated context, which is?ADJP?
here).
The feature weights for the addednull alignment are set to be very small, so as toavoid the competition with the normal candidates.In order to generate normal trees with not so manynull alignment sub-trees for the target sentence(such trees are not suitable for parser re-training),only target spans with less than 4 words can alignto null, and such null-aligned sub-tree can only beadded  no more than 3 times.With all the mentioned modification of theforced alignment, the partial target tree generatedusing forced alignment for the example in Figure1(b) is shown in Figure 3.
We can see that evena1large2 number3 of4 people5 coming6 to7 listen8 to9 their10 propaganda11 lectures1271-6NP41-3,5-7NP61-5,7NP5-61-4,7PP5-71-4NPnull1-7ADJP3-41,5-7NP?1               ?2            ?
?3           ?
?4                ?5                 ?6               ?
?77 7 5 6 1 4 4null null null null 3null1-7DT71-7JJ71-7NN51-4,6-7IN61-5,7NNS13-7VBGnull1-7TOnull1-7VBnull1-7TO31,4-7PRP41-7NN41-7VP3-41,5-7NP1-45-7NPFigure 3.
The parse tree selected by FA-PR for theexample in Figure 1(b)857with an incorrect sub-tree, more useful rules can beextracted, compared with the baseline sub-tree andthe sub-tree generated from TST-FS.3  Word Alignment SymmetrizationThe most widely used word aligners in MT, likeHMM and IBM Models (Och and Ney, 2003), aredirectional aligners.
Such aligner produces one setof alignment matrices for the SL-to-TL directionand another set for the TL-to-SL direction.Symmetrization refers to the combination of thesetwo sets of alignment matrices.The most popular method of symmetrization isintersect-diag-grow (IDG).
Given a bilingualsentence and its two alignment matrices     andIDG starts with all the links in        .Then IDG considers each link inin turn.
A link is added if its additiondoes not make some phrase pairs overlap.Although IDG is simple and efficient, and has beenshown to be effective in phrase-based SMT, it isproblematic in SSMT, as illustrated by the examplein section 1.3.1 Intersect-Diag-Syntactic-Grow (IDSG)We propose a new symmetrization method,Intersect-Diag-Syntactic-Grow (IDSG), which isan adaptation of IDG but also taking syntacticinformation in consideration.
It is sketched inAlgorithm 2.Algorithm 2 Intersect-Diag-Syntactic-Grow?
step1: Generate all the candidate linksusing IDG.?
step2: Select the one which can generate thebiggest frontier set:?
step3: Add   to  , and repeat step 1, until nonew link can be added.Like IDG, IDSG starts with all the links inand its main task is to add links selectedfrom                         .
IDSG isalso subject to the constraints of IDG.
The newcriterion in link selection in IDSG is specified inStep 2.
Given a parse tree of the TL side of thebilingual sentence, in each iteration IDSGconsiders the change of frontier set size caused bythe addition of each link in       .
The linkleading to the maximum number of frontier nodesis added (and removed from       ).
This processcontinues until no more links can be added.In sum, IDSG add links in an order which takesyntactic structure into consideration, and the linkwith the least violation of the syntactic structure isadded first.For the example in Figure 1(a), IDSG succeedsin discarding the two incorrect links, and producesthe final alignment and frontier set as shown inFigure 4.
Note that IDSG still fails to produce thecorrect link (the3, ??
4), since this link does notappear in        at all.3.2 Combining TST-FS/FA-PR and IDSGParser re-training aims to improve a parser withalignment matrix while IDSG aims to improvealignment matrix with parse tree.
It is reasonable tocombine them, and there are two alternatives of thecombination, depending on the order of application.That is, we could either improve alignment matrixby IDSG and then re-train parser with the betteralignment, or re-train parser and then improvealignment matrix with better syntactic information.Either alternative can be arranged into an iterativetraining routine, but empirically it is found thatonly one round of parser re-training before or afteronly one round of IDSG is already enough.61-5NNS51-4,6POS41-3,5-6NNIN31-2,4-6lived1in2the3herdsmen4?s5yurts6at7night8??1??2?3??4?5?
?62 3 null1 4 5 6 1 1VDB21,3-6DTnull11-611-6IN11-6NN11-6NP4-51-3,6NP4-61-3NP3-61-2PP12-6PP1-6----VPFigure 4, the alignment generated by IDSG for theexample in Figure 1(a)8584 ExperimentIn this section, we conduct experiments on Chineseto English translation task to test our proposedmethods of parser re-training and word alignmentsymmetrization.
The evaluation method is the caseinsensitive IBM BLEU-4 (Papineni et al2002).Significant testing is carried out using bootstrap re-sampling method proposed by Koehn (2004) witha 95% confidence level.4.1 Parser and SMT DecoderThe syntactic parser we used in this paper isBerkley parser, with the grammar trained on WSJcorpus, and the training method follows Petrov andKlein (2007).
Our SMT decoder is an in-houseimplementation of string-to-tree decoder.
Thefeatures we used are standard used features, suchas translation probabilities, lexical weights,language model probabilities and distortionprobability.
The feature weights are tuned usingthe minimum error rate training (MERT) (Och,2003).4.2 Experiment Data Setting and BaselinesWe test our method with two data settings: one isIWSLT data set, the other is NIST data set.dev8+dialog dev9Baseline 50.58 49.85Table 1.
Baselines for IWSLT data setNIST'03 NIST'05 NIST'08Baseline 37.57 36.44 24.87Table 2.
Baselines for NIST data setOur IWSLT data is the IWSLT 2009 dialog taskdata set.
The training data include the BTEC andSLDB training data.
The training data contains 81ksentence pairs, 655k Chinese words and 806kEnglish words.
The language model is 5-gramlanguage model trained with the English sentencesin the training data.
We use the combination ofdev8 and dialog as development set, and dev9 astest set.
The TL sentences of the training data withthe selected/generated trees are used as the trainingdata to re-train the parser.
To get the baseline ofthis setting, we run IDG to combine the bi-direction alignment generated by Giza++ (OchNey, 2003), and run Berkeley parser (Petrov andKlein, 2007) to parse the target sentences.
With thebaseline alignments and syntactic trees, we extractrules and calculate features.
The baseline resultsare shown in Table 1.For the NIST data set, the bilingual training datawe used is NIST 2008 training set excluding theHong Kong Law and Hong Kong Hansard.
Thetraining data contains 354k sentence pairs, 8MChinese words and 10M English words, and is alsothe training data for our parser re-training.
Thelanguage model is 5-gram language model trainedwith the Giga-Word corpus plus the Englishsentences in the training data.
The developmentdata to tune the feature weights of our decoder isNIST 2003 evaluation set, and test sets are NIST2005 and 2008 evaluation sets.
The baseline forNIST data is got in a similar way with for IWSLT,which are shown in Table 2 .4.3 Results of TST-FS/ FA-PRThe parser re-training strategies TST-FS and FA-PR are tested with two baselines, one is the defaultparser without any re-training and another isstandard self-training (SST).
All three re-trainingapproaches are based on the same bilingualdatasets as used in translation model training.
TheMT performances on IWSLT and NIST by the fourapproaches are shown in Table 3 and 4respectively.It can be seen that just standard self-trainingdoes improve translation performance, as re-training on the TL side of bilingual data is a kindof domain adaptation (from WSJ to IWSLT/NIST).But targeted self-training achieves more noticeableimprovement, almost twice as much as standardself-training.
This confirms the value of wordalignment information in parser re-training.
Finally,the even larger improvement of FA-PR than TST-FS shows that merely increasing the number offrontier nodes is not enough.
Some frontier nodesare of poor quality, and the frontier nodes found inforced alignment are more suitable.It can also be seen that the improvement inIWSLT is larger than that in NIST.
The first reasonis that both WSJ and NIST are of the news domainand of formal writing style, whereas IWSLT is ofthe tourist domain and of colloquial style.Therefore any improvement from the default parser,which is trained on WSJ, is expected to be smallerin the NIST case.
Another reason is that, since the859IWSLT dataset is much smaller, the impact ofmore and better rules is more obvious.Note that the figures in Table 3 and 4 are aboutparser re-training for only one iteration.
It is foundthat, more iteration do not lead to furthersignificant improvement.
The forced alignment ofbilingual training data does not obtain a fulldecoding path for every bilingual sentence.
It isbecause, although all translation rules are kept,there is still pruning during decoding.
Only 64% ofthe IWSLT dataset and 53% of the NIST datasetcan be successfully forced-aligned.
In general, thelonger the bilingual sentence, the less likely forcedalignment is successful, and that is why a lowerproportion of NIST can be forced-aligned.4.4  SymmetrizationThe new symmetrization method IDSG iscompared with the baseline method IDG.dev8+dialog dev9 # RulesIDG 50.58 49.85 515KIDSG52.71(+2.31)51.80(+2.05)626KTable 5.
MT performance of symmetrizationmethods on IWSLT data set.
The results in boldtype are significantly better than the performanceof IDG.NIST'03 NIST'05 NIST'08 #RulesIDG 37.57 36.44 24.87 3,376KIDSG38.15(+0.58)37.07(+0.63)25.67(+0.80)4,109KTable 6.
MT performance of symmetrizationmethods on NIST data.
The results in bold type aresignificantly better than the performance of IDG.As shown by the results in Table 5 and 6, IDSGenlarges the set of translation rules by more than20%, thereby improving translation performancesignificantly.
As in parser re-training, theimprovement in the IWSLT task is larger than thatin the NIST task.
Again, it is because the IWSLTdataset is very small and so the effect of rule tablesize is more obvious.4.5 Methods combinedAs mentioned in section 3.2, parser re-training andthe new symmetrization method can be combinedin two different ways, depending on the order ofapplication.
Table 7 and 8 show the experimentresults of combining FA-PR with IDSG.It can be seen that either way of the combinationis better than using FA-PR or IDSG alone.
Yetthere is no significant difference between the twokinds of combination.The best result is a gain of more than 3 Bleupoints on IWSLT and that of more than 1 Bleupoint on NIST.5 Related WorksThere are a lot of attempts in improving wordalignment with syntactic information (Cherry andLin, 2006; DeNero and Klein, 2007; Hermjackob,2009) and in improving parser with alignmentinformation (Burkett and Klein, 2008).
Yet strictlyspeaking all these attempts aim to improve thedev8+dialog dev9 # RulesBaseline 50.58 49.85 515KSST52.04(+1.46)51.26(+1.41)574KTST-FS52.75(+2.17)52.51(+2.66)572KFA-PR53.31(+2.73)52.8(+2.95)591KTable 3.
MT performance of parser re-trainingstrategies on IWSLT data set.
The results inbold type are significantly better than thebaseline.NIST'03 NIST'05 NIST'08 #RulesBaseline 37.57 36.44 24.87 3,376KSST37.98(+0.41)36.79(+0.35)25.30(+0.43)3,462KTST-FS38.42(+0.85)37.39(+0.95)25.79(+0.92)3,642KFA-PR38.74(+1.17)37.69(+1.25)25.89(+1.02)3,976KTable 4.
MT performance of parser re-trainingstrategies on NIST data set.
The results in boldtype are significantly better than the baseline.860dev8+dialog dev9#RulesBaseline 50.58 49.85 515KIDSG52.71(+2.31)51.80(+2.05)626KFA-PR53.31(+2.73)52.8(+2.95)591KIDSG  thenFA-PR53.64(3.06)53.32(+3.47)602KFA-PR thenIDSG53.81(+3.23)53.26(+3.41)597KTable 7.
MT performance of the new methodson IWSLT data set.
The results in bold typeare significantly better than the baseline.NIST'03 NIST'05 NIST'08 #RulesBaseline 37.57 36.44 24.87 3,376KIDSG38.15(+0.58)37.07(+0.63)25.67(+0.80)4,109KFA-PR38.74(+1.17)37.69(+1.25)25.89(+1.02)3,976KIDSGthenFA-PR38.97(+1.40)37.95(+1.51)26.74(+1.87)4,557KFA-PRthenIDSG38.90(+1.33)37.94(+1.50)26.52(+1.65)4,478KTable 8.
MT performance of the new methodson NIST data set.
The results in bold type aresignificantly better than the baseline.parser/aligner itself rather than the translationmodel.To improve the performance of syntacticmachine translation, Huang and Knight (2006)proposed a method incorporating a handful ofrelabeling strategies to modify the syntactic treesstructures.
Ambati and Lavie (2008) restructuredtarget parse trees to generate highly isomorphictarget trees that preserve the syntactic boundariesof constituents aligned in the original parse trees.Wang et al(2010) proposed to use re-structuringand re-labeling to modify the parser tree.
The re-structuring method uses a binarization method toenable the reuse of sub-constituent structures, andthe linguistic and statistical re-labeling methods tohandle the coarse nonterminal problem, so as toenhance generalization ability.
Different from theprevious work of modifying tree structures withpost-processing methods, our methods try to learna suitable grammar for string-to-tree SMT models,and directly produce trees which are consistentwith word alignment matrices.Instead of modifying the parse tree to improvemachine translation performance, many methodswere proposed to modify word alignment by takingsyntactic tree into consideration, including deletingincorrect word alignment links by a discriminativemodel (Fossum et al2008), re-aligning sentencepairs using EM method with the rules extractedwith initial alignment (Wang et al2010), andremoving ambiguous alignment of functionalwords with constraint from chunk-levelinformation during rule extraction (Wu et al2011).
Unlike all these pursuits, to generate aconsistent word alignment, our method modifiesthe popularly used IDG symmetrization method tomake it suitable for string-to-tree rule extraction,and our method is much simpler and faster than theprevious works.6 ConclusionIn this paper we have attempted to improve SSMTby reducing the errors introduced by the mutualindependence between monolingual parser andword aligner.
Our major contribution is thestrategies of re-training parser with the bilingualinformation in alignment matrices.
Either of ourproposals of targeted self-training with frontier setsize as evaluation function and forced alignmentbased re-training is more effective than baselineparser or standard self-training of parser.
As anauxiliary method, we also attempted to improvealignment matrices by a new symmetrizationmethod.In future, we will explore more alternatives inintegrating parsing information and alignmentinformation, such as discriminative wordalignment using a lot of features from parser.ReferencesVamshi Ambati and Alon Lavie.
2008.
Improvingsyntax driven translation models by re-structuringdivergent and non-isomorphic parse tree structures.In Student Research Workshop of the EighthConference of the Association for MachineTranslation in the Americas, pages 235-244.861David Burkett and Dan Klein.
2008.
Two languages arebetter than one (for syntactic parsing).
InProceedings of the Conference on EmpiricalMethods on Natural Language Processing, pages877-886.Colin Cherry and Dekang Lin.
2006.
Soft syntacticconstraints for word alignment throughdiscriminative training.
In Proceedings of the 21stInternational Conference on ComputationalLinguistics and 44th Annual Meeting of theAssociation for Computational Linguistics.John DeNero and Dan Klein.
2007.
Tailing wordalignment to syntactic machine translation.
InProceedings of the Association for ComputationalLinguistics, pages 17-24.Victoria Fossum, Kevin Knight, Steven Abney.
2008.Using syntax to improve word alignment precisionfor syntax-based machine translation.
In Proceedingsof the Third Workshop on Statistical MachineTranslation, pages 44-52.Michel Galley, Jonathan Graehl, Kevin Knight, DanielMarcu, Steve Deneefe, Wei Wang and IgnacioThayer.
2006.
Scalable inference and training ofcontext-rich syntactic translation models.
InProceedings of the 21st International Conference onComputational Linguistics and 44th Annual Meetingof the Association for Computational Linguistics,pages 961-968.Ulf Hermjackob.
Improved word alignment withstatistics and linguistic heuristics.
In Proceedings ofthe Conference on Empirical Methods on NaturalLanguage Processing, pages 229-237.Bryant Huang, Kevin Knight.
2006.
Relabeling syntaxtrees to improve syntax-based machine translationquality.
In Proceedings of the Human TechnologyConference of the North American Chapter of theACL, pages 240-247.Jason Katz-Brown, Slav Petrov, Ryan McDonald, FranzOch, David Talbot, Hiroshi Ichikawa, MasakazuSeno, Hideto Kazawa.
2011.
Training a parser formachine translation reordering.
In Proceedings of theConference on Empirical Methods on NaturalLanguage Processing, pages 183-192.Philipp Koehn.
2004.
Statistical significance tests formachine translation evaluation.
In Proceedings of theConference on Empirical Methods on NaturalLanguage Processing, pages 388-395.Wei Wang, Jonathan May, Kevin Knight, Daniel Marcu.2010.
Re-structuring, re-labeling, and re-alignmentfor syntax-Based machine translation.
ComputationalLinguistics, 36(2).Xianchao Wu, Takuya Matsuzaki and Jun'ichi Tsujii.2011.
Effective use of function words for rulegeneralization in forest-based translation.
InProceedings of the Association for ComputationalLinguistics, pages 22-31.Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In Proceedings of theAssociation for Computational Linguistics, pages160-167.Franz Josef Och and Hermann Ney.
2003.
A systematiccomparison of various statistical alignment models.Computational Linguistics, 29(1).Joern Wuebker, Arne Mauser and Hermann Ney.
2010.Training phrase translation models with leaving-one-out.
In Proceedings of the Association forComputational Linguistics, pages 475-484.Kishore Papineni, Salim Roukos, Todd Ward and Wei-jing Zhu.
2002.
BLEU: a method for automaticevaluation of machine translation.
In Proceedings ofthe Association for Computational Linguistics, pages311-318.Slav Petrov and Dan Klein.
2007.
Improved inferencefor unlexicalized parsing.
In Proceedings of HumanLanguage Technologies: The Annual Conference ofthe North American Chapter of the Association forComputational Linguistics, pages 404?411.862
