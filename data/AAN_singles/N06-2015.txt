Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 57?60,New York, June 2006. c?2006 Association for Computational LinguisticsOntoNotes: The 90% SolutionEduard Hovy Mitchell Marcus Martha Palmer Lance Ramshaw Ralph WeischedelUSC/ICI Comp & Info Science ICS and Linguistics BBN Technologies BBN Technologies4676 Admiralty U. of Pennsylvania U. of Colorado 10 Moulton St. 10 Moulton St.Marina d. R., CA Philadelphia, PA Boulder, CO Cambridge, MA Cambridge, MAhovy@isi.edumitch@cis.upenn.edumartha.palmer@colorado.edulance.ramshaw@bbn.comweischedel@bbn.comAbstract*We describe the OntoNotes methodology and itsresult, a large multilingual richly-annotated corpusconstructed at 90% interannotator agreement.
Aninitial portion (300K words of English newswireand 250K words of Chinese newswire) will bemade available to the community during 2007.1 IntroductionMany natural language processing applicationscould benefit from a richer model of text meaningthan the bag-of-words and n-gram models that cur-rently predominate.
Until now, however, no suchmodel has been identified that can be annotateddependably and rapidly.
We have developed amethodology for producing such a corpus at 90%inter-annotator agreement, and will release com-pleted segments beginning in early 2007.The OntoNotes project focuses on a domain in-dependent representation of literal meaning thatincludes predicate structure, word sense, ontologylinking, and coreference.
Pilot studies have shownthat these can all be annotated rapidly and withbetter than 90% consistency.
Once a substantialand accurate training corpus is available, trainedalgorithms can be developed to predict these struc-tures in new documents.
*This work was supported under the GALE program of theDefense Advanced Research Projects Agency, Contract No.HR0011-06-C-0022.This process begins with parse (TreeBank) andpropositional (PropBank) structures, which providenormalization over predicates and their arguments.Word sense ambiguities are then resolved, witheach word sense also linked to the appropriatenode in the Omega ontology.
Coreference is alsoannotated, allowing the entity mentions that arepropositional arguments to be resolved in context.Annotation will cover multiple languages (Eng-lish, Chinese, and Arabic) and multiple genres(newswire, broadcast news, news groups, weblogs,etc.
), to create a resource that is broadly applicable.2 TreebankingThe Penn Treebank (Marcus et al, 1993) is anno-tated with information to make predicate-argumentstructure easy to decode, including function tagsand markers of ?empty?
categories that representdisplaced constituents.
To expedite later stages ofannotation, we have developed a parsing system(Gabbard et al, 2006) that recovers both of theselatter annotations, the first we know of.
A first-stage parser matches the Collins (2003) parser onwhich it is based on the Parseval metric, while si-multaneously achieving near state-of-the-art per-formance on recovering function tags (F-measure89.0).
A second stage, a seven stage pipeline ofmaximum entropy learners and voted perceptrons,achieves state-of-the-art performance (F-measure74.7) on the recovery of empty categories by com-bining a linguistically-informed architecture and arich feature set with the power of modern machinelearning methods.573 PropBankingThe Penn Proposition Bank, funded by ACE(DOD), focuses on the argument structure of verbs,and provides a corpus annotated with semanticroles, including participants traditionally viewed asarguments and adjuncts.
The 1M word Penn Tree-bank II Wall Street Journal corpus has been suc-cessfully annotated with semantic argumentstructures for verbs and is now available via thePenn Linguistic Data Consortium as PropBank I(Palmer et al, 2005).
Links from the argumentlabels in the Frames Files to FrameNet frame ele-ments and VerbNet thematic roles are being added.This style of annotation has also been successfullyapplied to other genres and languages.4 Word SenseWord sense ambiguity is a continuing major ob-stacle to accurate information extraction, summari-zation and machine translation.
The subtle fine-grained sense distinctions in WordNet have notlent themselves to high agreement between humanannotators or high automatic tagging performance.Building on results in grouping fine-grainedWordNet senses into more coarse-grained sensesthat led to improved inter-annotator agreement(ITA) and system performance (Palmer et al,2004; Palmer et al, 2006), we have  developed aprocess for rapid sense inventory creation and an-notation that includes critical links between thegrouped word senses and the Omega ontology(Philpot et al, 2005; see Section 5 below).This process is based on recognizing that sensedistinctions can be represented by linguists in anhierarchical structure, similar to a decision tree,that is rooted in very coarse-grained distinctionswhich become increasingly fine-grained untilreaching WordNet senses at the leaves.
Sets ofsenses under specific nodes of the tree are groupedtogether into single entries, along with the syntac-tic and semantic criteria for their groupings, to bepresented to the annotators.As shown in Figure 1, a 50-sentence sample ofinstances is annotated and immediately checked forinter-annotator agreement.
ITA scores below 90%lead to a revision and clarification of the groupingsby the linguist.
It is only after the groupings havepassed the ITA hurdle that each individual group islinked to a conceptual node in the ontology.
In ad-dition to higher accuracy, we find at least a three-fold increase in annotator productivity.Figure 1.
Annotation ProcedureAs part of OntoNotes we are annotating themost frequent noun and verb senses in a 300Ksubset of the PropBank, and will have this dataavailable for release in early 2007.4.1 VerbsOur initial goal is to annotate the 700 most fre-quently occurring verbs in our data, which aretypically also the most polysemous; so far 300verbs have been grouped and 150 double anno-tated.
Subcategorization frames and semanticclasses of arguments play major roles in determin-ing the groupings, as illustrated by the grouping forthe 22 WN 2.1 senses for drive in Figure 2.
In ad-wordCheck against ontology (1 person)not OKAnnotate test (2 people)Results: agreementand confusion matrixSense partitioning, creating definitions,commentary, etc.
(2 or 3 people)Adjudication (1 person)OKnot OKSaveforfullannotationGI: operating or traveling via a vehi-cleNP (Agent) drive NP, NP drive PPWN1: ?Can you drive a truck?
?, WN2: ?drive to school,?, WN3: ?drive her toschool,?, WN12: ?this truck drives well,?
WN13: ?he drives a taxi,?,WN14: ?The cardrove around the corner,?, WN:16: ?drive the turnpike to work,?G2: force to a position or stanceNP drive NP/PP/infinitivalWN4: ?He drives me mad.,?
WN6: ?drive back the invaders,?
WN7: ?She finallydrove him to change jobs,?
WN8: ?drive a nail,?
WN15: ?drive the herd,?
WN22:?drive the game.
?G3:  to exert energy on behalf ofsomething NP drive NP/infinitivalWN5: ?Her passion drives her,?
WN10: ?He is driving away at his thesis.
?G4: cause object to move rapidly bystriking it NP drive NPWN9: ?drive the ball into the outfield ,?
WN17 ?drive a golf ball,?
WN18 ?drive aball?Figure 2.
A Portion of the Grouping of WordNet Senses for "drive?58dition to improved annotator productivity and ac-curacy, we predict a corresponding improvementin word sense disambiguation performance.
Train-ing on this new data, Chen and Palmer (2005) re-port 86.3% accuracy for verbs using a smoothedmaximum entropy model and rich linguistic fea-tures, which is 10% higher than their earlier, state-of-the art performance on ungrouped, fine-grainedsenses.4.2 NounsWe follow a similar procedure for the annotationof nouns.
The same individual who groups Word-Net verb senses also creates noun senses, startingwith WordNet and other dictionaries.
We aim todouble-annotate the 1100 most frequent polyse-mous nouns in the initial corpus by the end of2006, while maximizing overlap with the sentencescontaining annotated verbs.Certain nouns carry predicate structure; theseinclude nominalizations (whose structure obvi-ously is derived from their verbal form) and vari-ous types of relational nouns (like father,President, and believer, that express relations be-tween entities, often stated using of).
We haveidentified a limited set of these whose structuralrelations can be semi-automatically annotated withhigh accuracy.5 OntologyIn standard dictionaries, the senses for each wordare simply listed.
In order to allow access to addi-tional useful information, such as subsumption,property inheritance, predicate frames from othersources, links to instances, and so on, our goal is tolink the senses to an ontology.
This requires de-composing the hierarchical structure into subtreeswhich can then be inserted at the appropriate con-ceptual node in the ontology.The OntoNotes terms are represented in the110,000-node Omega ontology (Philpot et al,2005), under continued construction and extensionat ISI.
Omega, which has been used for MT,summarization, and database alignment, has beenassembled semi-automatically by merging a vari-ety of sources, including Princeton?s WordNet,New Mexico State University?s Mikrokosmos, anda variety of Upper Models, including DOLCE(Gangemi et al, 2002), SUMO (Niles and Pease,2001), and ISI?s Upper Model, which are in theprocess of being reconciled.
The verb frames fromPropBank, FrameNet, WordNet, and Lexical Con-ceptual Structures (Dorr and Habash, 2001) haveall been included and cross-linked.In work planned for later this year, verb andnoun sense groupings will be manually insertedinto Omega, replacing the current (primarilyWordNet-derived) contents.
For example, of theverb groups for drive in the table above, G1 andG4 will be placed into the area of ?controlled mo-tion?, while G2 will then sort with ?attitudes?.6 CoreferenceThe coreference annotation in OntoNotes connectscoreferring instances of specific referring expres-sions, meaning primarily NPs that introduce oraccess a discourse entity.
For example, ?Elco In-dustries, Inc.?, ?the Rockford, Ill. Maker of fasten-ers?, and ?it?
could all corefer.
(Non-specificreferences like ?officials?
in ?Later, officials re-ported??
are not included, since coreference forthem is frequently unclear.)
In addition, properpremodifiers and verb phrases can be marked whencoreferent with an NP, such as linking, ?when thecompany withdrew from the bidding?
to ?the with-drawal of New England Electric?.Unlike the coreference task as defined in theACE program, attributives are not generallymarked.
For example, the ?veterinarian?
NP wouldnot be marked in ?Baxter Black is a large animalveterinarian?.
Adjectival modifiers like ?Ameri-can?
in ?the American embassy?
are also not sub-ject to coreference.Appositives are annotated as a special kind ofcoreference, so that later processing will be able tosupply and interpret the implicit copula link.All of the coreference annotation is being dou-bly annotated and adjudicated.
In our initial Eng-lish batch, the average agreement scores betweeneach annotator and the adjudicated results were91.8% for normal coreference and 94.2% for ap-positives.7 Related and Future WorkPropBank I (Palmer et al, 2005), developed atUPenn, captures predicate argument structure forverbs; NomBank provides predicate argumentstructure for nominalizations and other noun predi-cates (Meyers et al, 2004).
PropBank II annota-59tion (eventuality ID?s, coarse-grained sense tags,nominal coreference and selected discourse con-nectives) is being applied to a small (100K) paral-lel Chinese/English corpus (Babko-Malaya et al,2004).
The OntoNotes representation extendsthese annotations, and allows eventual inclusion ofadditional shallow semantic representations forother phenomena, including temporal and spatialrelations, numerical expressions, deixis, etc.
Oneof the principal aims of OntoNotes is to enableautomated semantic analysis.
The best current al-gorithm for semantic role labeling for PropBankstyle annotation (Pradhan et al, 2005) achieves anF-measure of 81.0 using an SVM.
OntoNotes willprovide a large amount of new training data forsimilar efforts.Existing work in the same realm falls into twoclasses: the development of resources for specificphenomena or the annotation of corpora.
An ex-ample of the former is Berkeley?s FrameNet pro-ject (Baker et al, 1998), which produces richsemantic frames, annotating a set of examples foreach predicator (including verbs, nouns and adjec-tives), and describing the network of relationsamong the semantic frames.
An example of thelatter type is the Salsa project (Burchardt et al,2004), which produced a German lexicon based onthe FrameNet semantic frames and annotated alarge German newswire corpus.
A second exam-ple, the Prague Dependency Treebank (Hajic et al,2001), has annotated a large Czech corpus withseveral levels of (tectogrammatical) representation,including parts of speech, syntax, and topic/focusinformation structure.
Finally, the IL-Annotationproject (Reeder et al, 2004) focused on the repre-sentations required to support a series of increas-ingly semantic phenomena across seven languages(Arabic, Hindi, English, Spanish, Korean, Japaneseand French).
In intent and in many details,OntoNotes is compatible with all these efforts,which may one day all participate in a larger multi-lingual corpus integration effort.ReferencesO.
Babko-Malaya, M. Palmer, N. Xue, A. Joshi, and S. Ku-lick.
2004.
Proposition Bank II: Delving Deeper, Frontiersin Corpus Annotation, Workshop, HLT/NAACLC.
F. Baker, C. J. Fillmore, and J.
B. Lowe.
1998.
The Berke-ley FrameNet Project.
In Proceedings of COLING/ACL,pages 86-90.J.
Chen and M. Palmer.
2005.
Towards Robust High Per-formance Word Sense Disambiguation of English VerbsUsing Rich Linguistic Features.
In Proceedings ofIJCNLP2005, pp.
933-944.B.
Dorr and N. Habash.
2001.
Lexical Conceptual StructureLexicons.
In Calzolari et al ISLE-IST-1999-10647-WP2-WP3, Survey of Major Approaches Towards Bilin-gual/Multilingual Lexicons.A.
Burchardt, K. Erk, A. Frank, A. Kowalski, S. Pado, and M.Pinkal.
2006.
Consistency and Coverage: Challenges forexhaustive semantic annotation.
In Proceedings of DGfS-06.C.
Fellbaum (ed.).
1998.
WordNet: An On-line Lexical Data-base and Some of its Applications.
MIT Press.R.
Gabbard, M. Marcus, and S. Kulick.
Fully Parsing the PennTreebank.
In Proceedings of HLT/NAACL 2006.A.
Gangemi, N. Guarino, C. Masolo, A. Oltramari, and L.Schneider.
2002.
Sweetening Ontologies with DOLCE.
InProceedings of EKAW  pp.
166-181.J.
Hajic, B.
Vidov?-Hladk?, and P. Pajas.
2001: The PragueDependency Treebank: Annotation Structure and Support.Proceeding of the IRCS Workshop on Linguistic Data-bases, pp.
105?114.M.
Marcus, B. Santorini, and M. A. Marcinkiewicz.
1993.Building a Large Annotated Corpus of English: The PennTreebank.
Computational Linguistics 19: 313-330.A.
Meyers, R. Reeves, C Macleod, R. Szekely, V. Zielinska,B.
Young, and R. Grishman.
2004.
The NomBank Project:An Interim Report.
Frontiers in Corpus Annotation, Work-shop in conjunction with HLT/NAACL.I.
Niles and A. Pease.
2001.
Towards a Standard Upper On-tology.
Proceedings of the International Conference onFormal Ontology in Information Systems (FOIS-2001).M.
Palmer, O. Babko-Malaya, and H. T. Dang.
2004.
Differ-ent Sense Granularities for Different Applications, 2ndWorkshop on Scalable Natural Language UnderstandingSystems, at HLT/NAACL-04,M.
Palmer, H. Dang and C. Fellbaum.
2006.
Making Fine-grained and Coarse-grained Sense Distinctions, BothManually and Automatically, Journal of Natural LanguageEngineering, to appear.M.
Palmer, D. Gildea, and P. Kingsbury.
2005.
The Proposi-tion Bank: A Corpus Annotated with Semantic Roles,Computational Linguistics, 31(1).A.
Philpot, E.. Hovy, and P. Pantel.
2005.
The Omega Ontol-ogy.
Proceedings of the ONTOLEX Workshop at IJCNLPS.
Pradhan, W. Ward, K. Hacioglu, J. Martin, D. Jurafsky.2005.
Semantic Role Labeling Using Different SyntacticViews.
Proceedings of the ACL.F.
Reeder, B. Dorr, D. Farwell, N. Habash, S. Helmreich, E.H.Hovy, L. Levin, T. Mitamura, K. Miller, O. Rambow, A.Siddharthan.
2004.
Interlingual Annotation for MT Devel-opment.
Proceedings of AMTA.60
