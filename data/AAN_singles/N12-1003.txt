2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 20?28,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsIdentifying High-Level Organizational Elementsin Argumentative DiscourseNitin Madnani Michael Heilman Joel TetreaultEducational Testing ServicePrinceton, NJ, USA{nmadnani,mheilman,jtetreault}@ets.orgMartin ChodorowHunter College of CUNYNew York, NY, USAmartin.chodorow@hunter.cuny.eduAbstractArgumentative discourse contains not onlylanguage expressing claims and evidence, butalso language used to organize these claimsand pieces of evidence.
Differentiating be-tween the two may be useful for many appli-cations, such as those that focus on the content(e.g., relation extraction) of arguments andthose that focus on the structure of arguments(e.g., automated essay scoring).
We proposean automated approach to detecting high-levelorganizational elements in argumentative dis-course that combines a rule-based system anda probabilistic sequence model in a principledmanner.
We present quantitative results on adataset of human-annotated persuasive essays,and qualitative analyses of performance on es-says and on political debates.1 IntroductionWhen presenting an argument, a writer or speakerusually cannot simply state a list of claims andpieces of evidence.
Instead, the arguer must explic-itly structure those claims and pieces of evidence, aswell as explain how they relate to an opponent?s ar-gument.
Consider example 1 below, adapted froman essay rebutting an opponent?s argument that griz-zly bears lived in a specific region of Canada.The argument states that based on theresult of the recent research, there proba-bly were grizzly bears in Labrador.
It mayseem reasonable at first glance, but ac-tually, there are some logical mistakesin it.
.
.
.
There is a possibility that theywere a third kind of bear apart from blackand grizzly bears.
Also, the explorer ac-counts were recorded in the nineteenthcentury, which was more than 100 yearsago.
.
.
.
In sum, the conclusion of thisargument is not reasonable since the ac-count and the research are not convinc-ing enough.
.
.
.The argument begins by explicitly restating theopponent?s claim, prefacing the claim with thephrase ?The argument states that.?
Then, the sec-ond sentence explicitly marks the opponent?s argu-ment as flawed.
Later on, the phrase ?There is apossibility that?
indicates the subsequent clause in-troduces evidence contrary to the opponent?s claim.Finally, the sentence ?In sum, .
.
.?
sums up the ar-guer?s stance in relation to the opponent?s claim.1As illustrated in the above example, argumenta-tive discourse can be viewed as consisting of lan-guage used to express claims and evidence, andlanguage used to organize them.
We believe thatdifferentiating organizational elements from contentwould be useful for analyzing persuasive discourse.1The word Also signals that additional evidence is about tobe presented and should also be marked as shell.
However, itwas not marked in this specific case by our human annotator(?3.2).20We refer to such organizational elements as shell, in-dicating that they differ from the specific claims andevidence, or ?meat,?
of an argument.
In this work,we develop techniques for detecting shell in texts.We envision potential applications in political sci-ence (e.g., to better understand political debates), in-formation extraction or retrieval (e.g., to help a sys-tem focus on content rather than organization), andautomated essay scoring (e.g., to analyze the qualityof a test-taker?s argument), though additional workis needed to determine exactly how to integrate ourapproach into such applications.Detecting organizational elements could also be afirst step in parsing an argument to infer its structure.We focus on this initial step, leaving the other stepsof categorization of spans (as to whether they evalu-ate the opponent?s claims, connect one?s own claims,etc.
), and the inference of argumentation structure tofuture work.Before describing our approach to identifyingshell, we begin by defining it.
Shell refers to se-quences of words used to refer to claims and evi-dence in persuasive writing or speaking, providingan organizational framework for an argument.
Itmay be used by the writer or the speaker in the fol-lowing ways:?
to declare one?s own claims (e.g., ?There is thepossibility that?)?
to restate an opponent?s claims (e.g., ?The argu-ment states that?)?
to evaluate an opponent?s claims (e.g., ?It mayseem reasonable at first glance, but actually, thereare some logical mistakes in it?)?
to present evidence and relate it to specific claims(e.g., ?To illustrate my point, I will now give theexample of?
)There are many ways of analyzing discourse.
Themost relevant is perhaps rhetorical structure theory(RST) (Mann and Thompson, 1988).
To our knowl-edge, the RST parser from Marcu (2000) is the onlyRST parser readily available for experimentation.The parser is trained to model the RST corpus (Carl-son et al, 2001), which treats complete clauses (i.e.,clauses with their obligatory complements) as the el-ementary units of analysis.
Thus, the parser treatsthe first sentence in example 1 as a single unit anddoes not differentiate between the main and subordi-nate clauses.
In contrast, our approach distinguishesthe sequence ?The argument states that .
.
.
?
as shell(which is used here to restate the external claim).Furthermore, we identify the entire second sentenceas shell (here, used to evaluate the external claim),whereas the RST parser splits the sentence into twoclauses, ?It may seem .
.
.?
and ?but actually .
.
.
?,linked by a ?contrast?
relationship.2 Finally, ourapproach focuses on explicit markers of organiza-tional structure in arguments, whereas RST covers abroader range of discourse connections (e.g., elabo-ration, background information, etc.
), including im-plicit ones.
(Note that additional related work is de-scribed in ?6.
)This work makes the following contributions:?
We describe a principled approach to the taskof detecting high-level organizational elements inargumentative discourse, combining rules and aprobabilistic sequence model (?2).?
We conduct experiments to validate the approachon an annotated sample of essays (?3, ?4).?
We qualitatively explore how the approach per-forms in a new domain: political debate (?5).2 Detection MethodsIn this section, we describe three approaches to theproblem of shell detection: a rule-based system(?2.1), a supervised probabilistic sequence model(?2.2), and a simple lexical baseline (?2.3).2.1 Rule-based systemWe begin by describing a knowledge-based ap-proach to detecting organizational elements in argu-mentative discourse.
This approach uses a set of 25hand-written regular expression patterns.3In order to develop these patterns, we created asample of 170 annotated essays across 57 distinctprompts.4 The essays were written by test-takers ofa standardized test for graduate admissions.
Thissample of essays was similar in nature to but didnot overlap with those discussed in other sections2We used the RST parser of Marcu (2000) to analyze theoriginal essay from which the example was adapted.3We use the PyParsing toolkit to parse sentences with thegrammar for the rule system.4Prompts are short texts that present an argument or issueand ask test takers to respond to it, either by analyzing the givenargument or taking a stance on the given issue.21MODAL?
do | don?t | can | cannot | will | would | .
.
.ADVERB?
strongly | totally | fundamentally | vehemently | .
.
.AGREEVERB?
disagree | agree | concur | .
.
.AUTHORNOUN?
writer | author | speaker | .
.
.SHELL?
I [MODAL] [ADVERB] AGREEVERB with the AUTHORNOUNFigure 1: An example pattern that recognizes shell language describing the author?s position with respect to an oppo-nent?s, e.g., I totally agree with the author or I will strongly disagree with the speaker.of the paper (?2.2, ?3.2).
The annotations were car-ried out by individuals experienced in scoring per-suasive writing.
No formal annotation guidelineswere provided.
Besides shell language, there wereother annotations relevant to essay scoring.
How-ever, we ignored them for this study because theyare not directly relevant to the task of shell languagedetection.From this sample, we computed lists of n-grams(n = 1, 2, .
.
.
, 9) that occurred more than once inessays from at least half of the 57 distinct essayprompts.
We then wrote rules to recognize the shelllanguage present in the n-gram lists.
Additionalrules were added to cover instances of shell that weobserved in the annotated essays but that were notfrequent enough to appear in the n-gram analysis.We use ?Rules?
to refer to this method.2.2 Supervised Sequence ModelThe next approach we describe is a supervised, prob-abilistic sequence model based on conditional ran-dom fields (CRFs) (Lafferty et al, 2001), using asmall number of general features based on lexicalfrequencies.
We assume access to a labeled datasetof N examples (w,y) indexed by i, containing se-quences of words w(i) and sequences of labels y(i),with individual words and labels indexed by j (?3describes our development and testing sets).
y(i) is asequence of binary values, indicating whether eachword w(i)j in the sequence is shell (y(i)j = 1) or not(y(i)j = 0).
Following Lafferty et al (2001), we finda parameter vector ?
that maximizes the followinglog-likelihood objective function:L(?|w,y) =N?i=1log p(y(i) | w(i), ?
)(1)=N?i=1(?>f(w(i), y(i))?
logZ(i))The normalization constant Zi is a sum over allpossible label sequences for the ith example, and fis a feature function that takes pairs of word and la-bel sequences and returns a vector of feature values,equal in dimensions to the number of parameters in?.5The feature values for the jth word and label pairare as follows (these are summed over all elementsto compute the values of f for the entire sequence):?
The relative frequency of w(i)j in the British Na-tional Corpus.?
The relative frequency of w(i)j in a set of 100,000essays (see below).?
Eight binary features for whether the above fre-quencies meet or exceed the following thresholds:10{?6,?5,?4,?3}.?
The proportion of prompts for which w(i)j ap-peared in at least one essay about that prompt inthe set of 100,000.?
Three binary features for whether the above pro-portion of prompts meets or exceeds the followingthresholds: {0.25, 0.50, 0.75}.?
A binary feature with value 1 if w(i)j consists onlyof letters a-z, and 0 otherwise.
This feature dis-tinguishes punctuation and numbers from other to-kens.5We used CRFsuite 0.12 (Okazaki, 2007) to implement theCRF model.22?
A binary feature with value 1 if the rule-based sys-tem predicts that w(i)j is shell, and 0 otherwise.?
A binary feature with value 1 if the rule-based sys-tem predicts that w(i)j?1 is shell, and 0 otherwise.?
Two binary features for whether or not the currenttoken was the first or last in the sentence, respec-tively.?
Four binary features for the possible transitionsbetween previous and current labels (y(i)j and y(i)j?1,respectively).To define the features related to essay promptsand lexical frequencies in essays, we created a setof 100,000 essays from a larger set of essays writtenby test-takers of a standardized test for graduate ad-missions (the same domain as in ?2.1).
The essayswere written in response to 228 different promptsthat asked students to analyze various issues or ar-guments.
We use additional essays sampled fromthis source later to acquire annotated training andtest data (?3.2).We developed the above feature set using cross-validation on our development set (?3).
The intu-ition behind developing the word frequency featuresis that shell language generally consists of chunks ofwords that occur frequently in persuasive language(e.g., ?claims,?
?conclude?)
but not necessarily asfrequently in general text (e.g., the BNC).
The se-quence model can also learn to disprefer changes ofstate, such that multi-word subsequences are labeledas shell even though some of the individual words inthe subsequence are stop words, punctuation, etc.Note there are a relatively small number of pa-rameters in the model,6 which allows us to estimateparameters on a relatively small set of labeled data.We briefly experimented with adding an `2 penaltyon the magnitude of ?
in Equation 2, but this did notseem to improve performance.When making predictions y?
(i) about the label se-quence for a new sentence, the most common ap-proach is to find the most likely sequence of labels ygiven the words w(i), found with Viterbi decoding:6There were 42 parameters in our implementation of the fullCRF model.
Excluding the four transition features, each of the19 features had two parameters, one for the positive class andone for the negative class.
Having two parameters for each isunnecessary, but we are not aware of how to have the crfsuitetoolkit avoid these extra features.y?
(i) = argmaxyp?
(y | w(i)) (2)We use ?CRFv?
to refer to this approach.
We usethe suffix ?+R?
to denote models that include thetwo rule-based system prediction features, and weuse ?-R?
to denote models that exclude these twofeatures.In development, we observed that this decodingapproach seemed to very strongly prefer labeling anentire sentence as shell or not, which is often notdesirable since shell often appears at just the begin-nings of sentences (e.g., ?The argument states that?
).We therefore test an alternative prediction rulethat works at the word-level, rather than sequence-level.
This approach labels each word as shell ifthe sum of the probabilities of all paths in whichthe word was labeled as shell?that is, the marginalprobability?exceeds some threshold ?.
Words arelabeled as non-shell otherwise.
Specifically, an indi-vidual word w(i)j is labeled as shell (i.e., y?
(i)j = 1)according to the following equation, where 1(q) isan indicator function that returns 1 if its argument qis true, and 0 otherwise.y?
(i)j = 1((?yp?
(y | w(i)) yj)?
?
)(3)We tune ?
using the development set, as discussedin ?3.We use ?CRFm?
to refer to this approach.2.3 Lexical BaselineAs a simple baseline, we also evaluated a methodthat labels words as shell if they appear frequentlyin persuasive writing?specifically, in the set of100,000 unannotated essays described in ?2.2.
Inthis approach, word tokens are marked as shellif they belonged to the set of k most frequentwords from the essays.
Using the developmentset discussed in ?3.2, we tested values of k in{100, 200, .
.
.
, 1000}.
Setting k = 700 led to thehighest F1.We use ?TopWords?
to refer to this method.233 ExperimentsIn this section, we discuss the design of our exper-imental evaluation and present results on our devel-opment set, which we used to select the final meth-ods to evaluate on the held-out test set.3.1 MetricsIn our experiments, we evaluated the performanceof the shell detection methods by comparing token-level system predictions to human labels.
Shell lan-guage typically occurs as fairly long sequences ofwords, but identifying the exact span of a sequenceof shell seems less important than in related tag-ging tasks, such as named entity recognition.
There-fore, rather than evaluating based on spans (eitherwith exact or a partial credit system), we measuredperformance at the word token-level using standardmetrics: precision, recall, and the F1 measure.
Forexample, for precision, we computed the propor-tion of tokens predicted as shell by a system thatwere also labeled as shell in our human-annotateddatasets.3.2 Annotated DataTo evaluate the methods described in ?2, we gath-ered annotations for 200 essays that were not in thelarger, unannotated set discussed in ?2.2.
We splitthis set of essays into a development set of 150 es-says (68,601 word tokens) and a held-out test set of50 essays (21,277 word tokens).
An individual withextensive experience at scoring persuasive writingand familiarity with shell language annotated all to-kens in the essays with judgments of whether theywere shell or not (in contrast to ?2.1, this annotationonly involved labeling shell language).From the first annotator?s judgments on the devel-opment set, we created a set of annotation guidelinesand trained a second annotator.
The second anno-tator marked the held-out test set so that we couldmeasure human agreement.
Comparing the two an-notators?
test set annotations, we observed agree-ment of F1 = 0.736 and Cohen?s ?
= 0.699 (wedo not use ?
in our experiments but report it heresince it is a common measure of human agreement).Except for measuring agreement, we did not use thesecond annotator?s judgments in our experiments.77In the version of this paper submitted for review, we mea-recallprecision0.00.20.40.60.81.0l0.0 0.2 0.4 0.6 0.8 1.0linesCRFm?RCRFm+Rpointsl CRFm?RCRFm+RCRFv?RCRFv+RRulesTopWordsFigure 2: Precision and recall of the detection methods atvarious thresholds, computed through cross-validation onthe development set.
Points indicate performance for therule-based and baseline system as well as points whereF1 is highest.3.3 Cross-validation ResultsTo develop the CRF?s feature set, to tune hyperpa-rameters, and to select the most promising systemsto evaluate on the test set, we randomly split the sen-tences from the development set into two halves andconducted tests with two-fold cross-validation.We tested thresholds for the CRF at ?
={0.01, 0.02, .
.
.
, 1.00}.Figure 2 shows the results on the development set.For the rule-based system, which did not require la-beled data, performance is computed on the entiredevelopment set.
For the CRF approaches, the pre-cision and recall were computed after concatenatingpredictions on each of the cross-validation folds.The TopWords baseline performed quite poorly,with F1 = 0.205.
The rule-based system performedmuch better, with F1 = 0.382, but still not as wellas the CRF systems.
The CRF systems that pre-dict maximum sequences had F1 = 0.382 withoutthe rule-based system features (CRFv?R), and F1 =0.467 with the rule-based features (CRFv+R).
TheCRF systems that made predictions from marginalscores performed best, with F1 = 0.516 withoutthe rule-based features, and F1 = 0.551 with therule-based features.
Thus, both the rule-based sys-sured test set agreement with judgments from a third individ-ual, who was informally trained by the first, without the formalguidelines.
Agreement was somewhat lower: F1 = 0.668 and?
= 0.613.24Method P R F1 LenTopWords 0.125 0.759 0.214 ?
2.80Rules 0.561 0.360 0.439 ?
4.99CRFv?R 0.729 0.268 0.392 ?
15.67CRFv+R 0.763 0.369 0.498 ?
13.30CRFm?R 0.586 0.574 0.580 9.00CRFm+R 0.556 0.670 0.607 9.96Human 0.685 0.796 0.736 ?
7.91Table 1: Performance on the held-out test set, in terms ofprecision (P), recall (R), F1 measure, and average lengthin tokens of sequences of one or more words labeled asshell (Len).
?
indicates F1 scores that are statisticallyreliably different from CRFm+R at the p < 0.01 level.tem features and the marginal prediction approachled to gains in performance.From an examination of the predictions from theCRFm+R and CRFm?R systems, it appears that amajor contribution of the features derived from therule-based system is to help the hybrid CRFm+Rsystem avoid tagging entire sentences as shell whenonly parts of them are actually shell.
For exam-ple, consider the sentence ?According to this state-ment, the speaker asserts that technology can notonly influence but also determine social customs andethics?
(typographical errors included).
CRFm?Rtags everything up to ?determine?
as shell, whereasthe rule-based system and CRFm+R correctly stopafter ?asserts that.
?4 Test Set ResultsNext, we present results on the held-out test set.For the CRFm systems, we used the thresholds thatled to the highest F1 scores on the developmentset (?
= 0.26 for CRFm+R and ?
= 0.32 forCRFm?R).
Table 1 presents the results for all sys-tems, along with results comparing the second anno-tator?s labels (?Human?)
to the gold standard labelsfrom the first annotator.The same pattern emerged as on the developmentset, with CRFm+R performing the best.
The F1score of 0.607 for the CRFm+R system was rel-atively close to the F1 score of 0.736 for agree-ment between human annotators.
To test whetherCRFm+R?s relatively high performance was due tochance, we computed 99% confidence intervals forthe differences in F1 score between CRFm+R andeach of the other methods.
We used the bias-corrected and accelerated (BCa) Bootstrap (Efronand Tibshirani, 1993) with 10,000 rounds of resam-pling at the sentence level for each comparison.
Adifference is statistically reliable at the ?
level (i.e.,p < ?)
if the (1 ?
?
)% confidence interval for thedifference does not contain zero, which correspondsto the null hypothesis.
Statistically reliable differ-ences are indicated in Table 1.
The only system thatdid not have a reliably lower F1 score than CRFm+Rwas CRFm?R, though due to the relatively smallsize of our test set, we do not take this as strong ev-idence against using the rule-based system featuresin the CRF.We note that while the CRFm+R system had lowerprecision (0.556) than the CRFv+R system (0.763),its threshold ?
could be tuned to prefer high preci-sion rather than the best development set F1.
Suchtuning could be very important depending on the rel-ative costs of false positives and false negatives fora particular application.We also computed the mean length of sequencesof one or more contiguous words labeled as shell.Here also, we observed that the CRFm+R approachprovided a close match to human performance.
Themean lengths of shell for the first and second anno-tators were 8.49 and 7.91 tokens, respectively.
Forthe CRFm+R approach, the mean length was slightlyhigher at 9.96 tokens, but this was much closer to themeans of the human annotators than the mean forthe CRFv+R system, which was 13.30 tokens.
Forthe rule-based system, the mean length was 4.99 to-kens, indicating that it captures short sequences suchas ?In addition,?
more often than the other systems.5 Observations about a New DomainIn this section, we apply our system to a corpus oftranscripts of political debates8 in order to under-stand whether the system can generalize to a newdomain with a somewhat different style of argu-mentation.
Our analyses are primarily qualitativein nature due to the lack of gold-standard annota-tions.
We chose two historically well-known debates8The Lincoln?Douglas debates were downloaded fromhttp://www.bartleby.com/251/.
The other debateswere downloaded from http://debates.org/.25(Lincoln?Douglas from 1858 and Kennedy?Nixonfrom 1960) and two debates that occurred more re-cently (Gore?Bush from 2000 and Obama?McCainfrom 2008).
These debates range in length from38,000 word tokens to 65,000 word tokens.Political debates are similar to the persuasive es-says we used above in that debate participants statetheir own claims and evidence as well as evaluatetheir opponents?
claims.
They are different from es-says in that they are spoken rather than written?meaning that they contain more disfluencies, collo-quial language, etc.
?and that they cover differentsocial and economic issues.
Also, the debates are insome sense a dialogue between two people.We tagged all the debates using the CRFm+R sys-tem, using the same parameters as for the test setexperiments (?4).First, we observed that a smaller percentage oftokens were tagged as shell in the debates than inthe essays.
For the annotated essay test set (?3.2),the percentage of tokens tagged as shell was 14.0%(11.6% were labeled as shell by the first annota-tor).
In contrast, the percentage of tokens taggedas shell was 4.2% for Lincoln?Douglas, 5.4% forKennedy?Nixon, 4.6% for Gore?Bush, and 4.8% forObama?McCain.
It is not completely clear whetherthe smaller percentages tagged as shell are due to alack of coverage by the shell detector or more sub-stantial differences in the domain.However, it seems that these debates genuinely in-clude less shell.
One potential reason is that many ofthe essay prompts asked test-takers to respond to aparticular argument, leading to responses containingmany phrases such as ?The speaker claims that?
and?However, the argument lacks specificity .
.
.
?.We analyzed the system?s predictions and ex-tracted a set of examples, some of which appear inTable 2, showing true positives, where most of thetokens appear to be labeled correctly as shell; falsepositives, where tokens were incorrectly labeled asshell; and false negatives, where the system missedtokens that should have been marked.Table 2 also provides some examples from our de-velopment set, for comparison.We observed many instances of correctly markedshell, including many that appeared very differentin style than the language used in essays.
For ex-ample, Lincoln demonstrates an aggressive style inthe following: ?Now, I say that there is no charitableway to look at that statement, except to conclude thathe is actually crazy.?
Also, Bush employs a some-what atypical sentence structure here: ?It?s not whatI think and its not my intentions and not my plan.
?However, the system also incorrectly tagged se-quences as shell, particularly in short sentences (e.g.,?Are we as strong as we should be??).
It also missedshell, partially or entirely, such as in the followingexample: ?But let?s get back to the core issue here.
?These results suggest that although there is poten-tial for improvement in adapting to new domains,our approach to shell detection at least partially gen-eralizes beyond our initial domain of persuasive es-say writing.6 Related WorkThere has been much previous work on analyzingdiscourse.
In this section, we describe similaritiesand differences between that work and ours.Rhetorical structure theory (Mann and Thomp-son, 1988) is perhaps the most relevant area of work.See ?1 for a discussion.In research on intentional structure, Grosz andSidner (1986) propose that any discourse is com-posed of three interacting components: the linguisticstructure defined by the actual utterances, the inten-tional structure defined by the purposes underlyingthe discourse, and an attentional structure defined bythe discourse participants?
focus of attention.
De-tecting shell may also be seen as trying to identifyexplicit cues of intentional structure in a discourse.Additionally, the categorization of shell spans as towhether they evaluate the opponents claims, connectones own claims, etc., may be seen as determiningwhat Grosz and Sidener call ?discourse segment pur-poses?
(i.e., the intentions underlying the segmentscontaining the shell spans).We can also view shell detection as the task ofidentifying phrases that indicate certain types ofspeech acts (Searle, 1975).
In particular, we aim toidentify markers of assertive speech acts, which de-clare that the speaker believes a certain proposition,and expressive speech acts, which express attitudestoward propositions.Shell also overlaps with the concept of discoursemarkers (Hutchinson, 2004), such as ?however?
or26LINCOLN (L) ?
DOUGLAS (D) DEBATESTP L: Now, I say that there is no charitable way to look at that statement, except to conclude that he isactually crazy.L: The first thing I see fit to notice is the fact that .
.
.FP D: He became noted as the author of the scheme to .
.
.D: .
.
.
such amendments were to be made to it as would render it useless and inefficient .
.
.FN D: I wish to impress it upon you, that every man who voted for those resolutions .
.
.L: That statement he makes, too, in the teeth of the knowledge that I had made the stipulation tocome down here .
.
.KENNEDY (K) ?
NIXON (N) DEBATESTP N: I favor that because I believe that?s the best way to aid our schools .
.
.N: And in our case, I do believe that our programs will stimulate the creative energies of .
.
.FP N: We are for programs, in addition, which will see that our medical care for the aged .
.
.K: Are we as strong as we should be?FN K: I should make it clear that I do not think we?re doing enough .
.
.N: Why did Senator Kennedy take that position then?
Why do I take it now?BUSH (B) ?
GORE (G) DEBATESTP B: It?s not what I think and its not my intentions and not my plan.G: And FEMA has been a major flagship project of our reinventing government efforts.
And I agree, itworks extremely well now.FP B: First of all, most of this is at the state level.G: And it focuses not only on increasing the supply, which I agree we have to do, but also on .
.
.FN B: My opponent thinks the government?the surplus is the government?s money.
That?s not what IthinkG: I strongly support local control, so does Governor Bush.OBAMA (O) ?
MCCAIN (M) DEBATESTP M: But the point is?the point is, we have finally seen Republicans and Democrats sitting down andnegotiating together .
.
.O: And one of the things I think we have to do is make sure that college is affordable .
.
.FP O: .
.
.
but in the short term there?s an outlay and we may not see that money for a while.O: We have to do that now, because it will actually make our businesses and our families better off.FN O: So I think the lesson to be drawn is that we should never hesitate to use military force .
.
.
to keep theAmerican people safe.O: But let?s get back to the core issue here.PERSUASIVE ESSAYS (DEVELOPMENT SET, SPELLING ERRORS INCLUDED)TP However, the argument lacks specificity and relies on too many questionable assumptions to make astrong case for adopting an expensive and logistically complicated program.I believe that both of these claims have been made in hase and other factors need to be considered.FP Since they are all far from now, the prove is not strong enough to support the conclusion.As we know that one mind can not think as the other does.FN History has proven that .
.
.The given issue which states that in any field of inquiry .
.
.
is a controversional one.Table 2: Examples of CRFm+R performance.
Underlining marks tokens predicted to be shell, and bold font indicatesshell according to human judgments (our judgments for the debate transcripts, and the annotator?s judgments for thedevelopment set).
Examples include true positives (TP), false positives (FP), and false negatives (FN).
Note that someFP and FN examples include partially accurate predictions.27?therefore.?
Discourse markers, however, are typ-ically only single words or short phrases that ex-press a limited number of relationships.
On the otherhand, shell can capture longer sequences that ex-press more complex relationships between the com-ponents of an argumentative discourse (e.g., ?Butlet?s get back to the core issue here?
signals that thefollowing point is more important than the previousone).There are also various other approaches to ana-lyzing arguments.
Notably, much recent theoreti-cal research on argumentation has focused on ar-gumentation schemes (Walton et al, 2008), whichare high-level strategies for constructing arguments(e.g., argument from consequences).
Recently, Fengand Hirst (2011) developed automated methods forclassifying texts by argumentation scheme.
In sim-ilar work, Anand et al (2011) use argumentationschemes to identify tactics in blog posts (e.g., moralappeal, social generalization, appeals to external au-thorities etc.).
Although shell language can certainlybe found in persuasive writing, it is used to orga-nize the persuader?s tactics and claims rather thanto express them.
For example, consider the follow-ing sentence: ?It must be the case that this dietworks since it was recommended by someone wholost 20 pounds on it.?
In shell detection, we focuson the lexico-syntactic level, aiming to identify thebold words as shell.
In contrast, work on argumenta-tion schemes focuses at a higher level of abstraction,aiming to classify the sentence as an attempt to per-suade by appealing to an external authority.7 ConclusionsIn this paper, we described our approach to detect-ing language used to explicitly structure an arguer?sclaims and pieces of evidence as well as explainhow they relate to an opponent?s argument.
We im-plemented a rule-based system, a supervised proba-bilistic sequence model, and a principled hybrid ver-sion of the two.
We presented evaluations of thesesystems using human-annotated essays, and we ob-served that the hybrid sequence model system per-formed the best.
We also applied our system to po-litical debates and found evidence of the potential togeneralize to new domains.AcknowledgmentsWe would like to thank the annotators for helpingus create the essay data sets.
We would also liketo thank James Carlson, Paul Deane, Yoko Futagi,Beata Beigman Klebanov, Melissa Lopez, and theanonymous reviewers for their useful comments onthe paper and annotation scheme.ReferencesP.
Anand, J.
King, J. Boyd-Graber, E. Wagner, C. Martell,D.
Oard, and P. Resnik.
2011.
Believe me?we cando this!
annotating persuasive acts in blog text.
InProc.
of AAAI Workshop on Computational Models ofNatural Argument.L.
Carlson, D. Marcu, and M. E. Okurowski.
2001.Building a discourse-tagged corpus in the frameworkof rhetorical structure theory.
In Proc.
of the SecondSIGdial Workshop on Discourse and Dialogue.B.
Efron and R. Tibshirani.
1993.
An Introduction to theBootstrap.
Chapman and Hall/CRC.V.
W. Feng and G. Hirst.
2011.
Classifying argumentsby scheme.
In Proc.
of ACL.Barbara J. Grosz and Candace L. Sidner.
1986.
Atten-tion, Intentions, and the Structure of Discourse.
Com-put.
Linguist., 12(3):175?204.B.
Hutchinson.
2004.
Acquiring the meaning of dis-course markers.
In Proc.
of ACL.J.
Lafferty, A. McCallum, and F. Pereira.
2001.
Con-ditional random fields: Probabilistic models for seg-menting and labeling sequence data.
In Proc.
of ICML.W.
C. Mann and S. A. Thompson.
1988.
Rhetoricalstructure theory: Toward a functional theory of textorganization.
Text, 8(3).D.
Marcu.
2000.
The Theory and Practice of DiscourseParsing and Summarization.
MIT Press.N.
Okazaki.
2007.
CRFsuite: a fast implementation ofconditional random fields (CRFs).J.
R. Searle.
1975.
A classification of illocutionary acts.Language in Society, 5(1).D.
Walton, C. Reed, and F. Macagno.
2008.
Argumenta-tion Schemes.
Cambridge University Press.28
