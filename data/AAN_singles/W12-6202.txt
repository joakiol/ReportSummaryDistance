Proceedings of the 10th International Workshop on Finite State Methods and Natural Language Processing, pages 10?19,Donostia?San Sebastia?n, July 23?25, 2012. c?2012 Association for Computational LinguisticsPractical Finite State Optimality TheoryDale GerdemannUniversity of Tu?bingendg@sfs.nphil.uni-tuebingen.deMans HuldenUniversity of the Basque CountryIXA GroupIKERBASQUE, Basque Foundation for Sciencemhulden@email.arizona.eduAbstractPrevious work for encoding Optimality The-ory grammars as finite-state transducers hasincluded two prominent approaches: the so-called ?counting?
method where constraint vi-olations are counted and filtered out to someset limit of approximability in a finite-statesystem, and the ?matching?
method, whereconstraint violations in alternative strings arematched through violation alignment in orderto remove suboptimal candidates.
In this pa-per we extend the matching approach to showhow not only markedness constraints, but alsofaithfulness constraints and the interaction ofthe two types of constraints can be capturedby the matching method.
This often producesexact and small FST representations for OTgrammars which we illustrate with two practi-cal example grammars.
We also provide a newproof of nonregularity of simple OT gram-mars.1 IntroductionThe possibility of representing Optimality Theory(OT) grammars (Prince and Smolensky, 1993) ascomputational models and finite-state transducers,in particular, has been widely studied since the in-ception of the theory itself.
In particular, construct-ing an OT grammar step-by-step as the compositionof a set of transducers, akin to rewrite rule com-position in (Kaplan and Kay, 1994), has offeredthe attractive possibility of simultaneously model-ing OT parsing and generation as a natural conse-quence of the bidirectionality of finite-state trans-ducers.
Two main approaches have received atten-tion as practical options for implementing OT withfinite-state transducers: that of Karttunen (1998)and Gerdemann and van Noord (2000).1 Both ap-1Earlier finite-state approaches do exist, see e.g.
Ellison(1994) and Hammond (1997).proaches model constraint interaction by construct-ing a GEN-transducer, which is subsequently com-posed with filtering transducers that mark violationsof constraints, and remove suboptimal candidates?candidates that have received more violation marksthan the optimal candidate, with the general tem-plate:Grammar = Gen .o.
MarkC1 .o.
FilterC1 ...MarkCN .o.
FilterCNIn Karttunen?s system, auxiliary ?counting?
trans-ducers are created that first remove candidates withmaximally k violation marks for some fixed k, thenk?1, and so on, until nothing can be removed with-out emptying the candidate set, using a finite-stateoperation called priority union.
Gerdemann and vanNoord (2000) present a similar system that they calla ?matching?
approach, but which does not rely onfixing a maximal number of distinguishable viola-tions k. The matching method is a procedure bywhich we can in many cases (though not always)distinguish between infinitely many violations in afinite-state system?something that is not possiblewhen encoding OT by the alternative approach ofcounting violations.In this paper our primary purpose is to both ex-tend and simplify this ?matching?
method.
Wewill include interaction of both markedness andfaithfulness constraints (MAX, DEP, and IDENTviolations)?going beyond both Karttunen (1998)and Gerdemann and van Noord (2000), where onlymarkedness constraints were modeled.
We shall alsoclarify the notation and markup used in the matchingapproach as well as present a set of generic trans-ducer templates for EVAL by which modeling vary-ing OT grammars becomes a simple matter of mod-ifying the necessary constraint transducers and or-dering them correctly in a series of compositions.10We will first give a detailed explanation of the?matching?
approach in section 2?our encoding,notation, and tools differ somewhat from that ofGerdemann and van Noord (2000), although the coretechniques are essentially alike.
This is followed byan illustration of our encoding and method througha standard OT grammar example in section 3.
Inthat section we also give examples of debugging OTgrammars using standard finite state calculus meth-ods.
In section 4 we also present an alternate en-coding of an OT account of prosody in Karttunen(2006) illustrating devices where GEN is assumed toadd metrical and stress markup in addition to chang-ing, inserting, or deleting segments.
We also com-pare this grammar to both a non-OT grammar and anOT grammar of the same phenomenon described inKarttunen (2006).
In section 5, we conclude with abrief discussion about the limitations of FST-basedOT grammars in light of the method developed inthis paper, as well as show a new proof of nonregu-larity of some very simple OT constraint systems.1.1 NotationAll the examples discussed are implemented withthe finite-state toolkit foma (Hulden, 2009b).
Theregular expressions are also compilable with the Xe-rox tools (Beesley and Karttunen, 2003), althoughsome of the tests of properties of finite-state trans-ducers, crucial for debugging, are unavailable.
Theregular expression formalism used is summarized intable 1.2 OT evaluation with matchingIn order to clarify the main method used in this pa-per to model OT systems, we will briefly recapitu-late the ?matching?
approach to filter out suboptimalcandidates, or candidates with more violation marksin a string representation, developed in Gerdemannand van Noord (2000).22.1 WorseningThe fundamental technique behind the finite-statematching approach to OT is a device which we call?worsening?, used to filter out strings from a trans-ducer containing more occurrences of some desig-nated special symbol s (e.g.
a violation marker),2Also discussed in Ja?ger (2002).AB ConcatenationA|B Union?A Complement?
Any symbol in alphabet% Escape symbol[ and ] Grouping bracketsA:B Cross productT.l Output projection of TA -> B Rewrite A as BA (->) B Optionally rewrite A as B|| C D Context specifier[..] -> A Insert one instance of AA -> B ... C Insert B and C around A.#.
End or beginning of stringTable 1: Regular expression notation in foma.than some other candidate string in the same poolof strings.
This method of transducer manipulationis perhaps best illustrated through a self-containedexample.Consider a simple morphological analyzer en-coded as an FST, say of English, that onlyadds morpheme-boundaries?+-symbols?to inputwords, perhaps consulting a dictionary of affixes andstems.
Some of the mappings of such a transducercould be ambiguous: for example, the words decon-struction or incorporate could be broken down intwo ways by such a morpheme analyzer:Suppose our task was now to remove alternatemorpheme breakdowns from the transducer so that,if an analysis with a smaller number of morphemeswas available for any word, a longer analysis wouldnot be produced.
In effect, deconstruction shouldonly map to deconstruct+ion, since the other al-ternative has one more morpheme boundary.
Theworsening trick is based on the idea that we canuse the existing set of words from the output sideof the morphology, add at least one morphemeboundary to all of them, and use the resulting setof words to filter out longer ?candidates?
from theoriginal morphology.
For example, one way ofadding a +-symbol to de+construction produces11de+construct+ion, which coincides with the orig-inal output in the morphology, and can now be usedto knock out this suboptimal division.
This processcan be captured through:AddBoundary = [?
* 0:%+ ?
*]+;Worsen = Morphology .o.
AddBoundary;Shortest = Morphology .o.
?Worsen.l;the effect of which is illustrated for the word de-construction in figure 1.
Here, AddBoundary isa transducer that adds at least one +-symbol to theinput.
The Worsen transducer is simply the origi-nal transducer composed with the AddBoundarytransducer.
The Shortest morphology is thenconstructed by extracting the output projection ofWorsen, and composing its negation with the orig-inal morphology.Figure 1: Illustration of a worsening filter for morphemeboundaries.2.2 Worsening in OTThe above ?worsening?
maneuver is what the?matching?
approach to model OT syllabification isbased upon.
Evaluation of competing candidateswith regard to a single OT constraint can be per-formed in the same manner.
This, of course, pre-supposes that we are using transducers to mark con-straint violations in input strings, say by the sym-bol *.
Gerdemann and van Noord (2000) illustratethis by constructing a GEN-transducer that syllabi-fies words,3 and another set of transducers that mark3Although using a much more complex set of markup sym-bols than here.violations of some constraint.
Then, having a con-straint, NOCODA, implemented as a transducer thatadds violation marks when syllables end in conso-nants, we can achieve the following sequence ofmarkup by composition of GEN and NOCODA, fora particular example input bebop:The above transducers could be implemented verysimply, by epenthesis replacement rules:# Insert periods arbitrarily inside wordsGen = [..] (->) %.
|| \.#.
_ \.#.
;# Insert *-marks after C .
or C .#.NoCoda = [..] -> %* || C+ [%.
| .#.]
_ ;Naturally, at this point in the compositionchain we would like to filter out the suboptimalcandidates?that is, the ones with fewer violationmarks, then remove the marks, and continue withthe next constraint, until all constraints have beenevaluated.
The problem of filtering out the subopti-mal candidates is now analogous to the ?worsening?scenario above: we can create a ?worsening?-filterautomaton by adding violation marks to the entireset of candidates.
In this example, the candidatebe.bop?
would produce a worse candidate be?.bop?,which (disregarding for the moment syllable bound-ary marks and the exact position of the violation) canbe used to filter out the suboptimal beb?.op?.3 An OT grammar with faithfulness andmarkedness constraintsAs previous work has been limited to working withonly markedness constraints as well as a some-what impoverished GEN?one that only syllabifieswords?our first task when approaching a morecomplete finite-state methodology of OT needs toaddress this point.
In keeping with the ?richnessof the base?-concept of OT, we require a suitable12GEN to be able to perform arbitrary deletions (eli-sions), insertions (epentheses), and changes to theinput.
A GEN-FST that only performs this task(maps ??
?
??)
on input strings is obviously fairlyeasy to construct.
However, we need to do more thanthis: we also need to keep track of which parts ofthe input have been modified by GEN in any wayto later be able to pinpoint and mark faithfulnessviolations?places where GEN has manipulated theinput?through an FST.3.1 Encoding of GENPerhaps the simplest possible encoding that meetsthe above criteria is to have GEN not only changethe input, but also mark each segment in its outputwith a marker whereby we can later distinguish howthe input was changed.
To do so, we perform thefollowing markup:?
Every surface segment (output) is surroundedby brackets [ .
.
.
].?
Every input segment that was manipulated byGEN is surrounded by parentheses ( .
.
.
).For example, given the input a, GEN would pro-duce an infinite number of outputs, and among them:[a] GEN did nothing(a)[] GEN deleted the a(a)[e] GEN changed the a to e()[d](a)[i] GEN inserted a d and changed a to i...This type of generic GEN can be defined through:Gen = S -> %( ... %) %[ (S) %] ,,S -> %[ ... %] ,,[..] (->) [%( %) %[ S %]]* ;assuming here that S represents the set of segmentsavailable.3.2 Evaluation of faithfulness and markednessconstraintsAs an illustrative grammar, let us consider a standardOT example of word-final obstruent devoicing?asin Dutch or German?achieved through the interac-tion of faithfulness and markedness constraints.
Theconstraints model the fact that underlyingly voicedobstruents surface as devoiced in word-final posi-tion, as in pad ?
pat.
A set of core constraints toillustrate this include:?
?VF: a markedness constraint that disallows fi-nal voiced obstruents.?
IDENTV: a faithfulness constraint that militatesagainst change in voicing.?
VOP: a markedness constraint against voicedobstruents in general.The interaction of these constraints to achieve de-voicing can be illustrated by the following tableau.4bed ?VF IDENTV VOP+ bet * *pet **!bed *!
**ped *!
* *The tableau above represents a kind of shorthandoften given in the linguistic literature where, for thesake of conciseness, higher-ranked faithfulness con-straints are omitted.
For example, there is nothingpreventing the candidate bede to rank equally withbet, were it not for an implicit high-ranked DEP-constraint disallowing epenthesis.
As we are build-ing a complete computational model with an unre-stricted GEN, and no implicit assumptions, we needto add a few constraints not normally given whenarguing about OT models.
These include:?
DEP: a faithfulness constraint against epenthe-sis.?
MAX: a faithfulness constraint against dele-tion.?
IDENTPL: a faithfulness constraint againstchanges in place of articulation of segments.This is crucial to avoid e.g.
bat or bap beingequally ranked with bet in the above example.54The illustration roughly follows (Kager, 1999), p. 42.5Note that a generic higher-ranked IDENT will not do, be-cause then we would never get the desired devoicing in the firstplace.13Including these constraints explicitly allows us torule out unwanted candidates that may otherwiserank equal with the candidate where word-final ob-struents are devoiced, as illustrated in the following:bed DEPMAXIDENTPL?
VFIDENTVVOP+ bet * *pet **!bed *!
**ped *!
* *bat *!
* *bep *!
* *be *!
*bede *!
**Once we have settled for the representationof GEN, the basic faithfulness constraint markuptransducers?whose job is to insert asterisks wher-ever violations occur?can be defined as follows:Dep = [..] -> {*} || %( %) _ ;Max = [..] -> {*} || %[ %] _ ;Ident = [..] -> {*} || %( S %) %[ S %] _ ;That is, DEP inserts a *-symbol after ( )-sequences, which is how GEN marks epenthesis.Likewise, MAX-violations are identified by the se-quence [ ], and IDENT-violations by a parenthesizedsegment followed by a bracketed segment.
To definethe remaining markup transducers, we shall take ad-vantage of some auxiliary template definitions, de-fined as functions:def Surf(X) [X .o.
[0:%[ ?
0:%]]*].l/[ %( (S) %) | %[ %] ];def Change(X,Y) [%( X %) %[ Y %]];Here, Surf(X) in effect changes the language Xso that it can match every possible surface encod-ing produced by GEN; for example, a surface se-quence ab may look like [a][b], or [a](a)[b], etc.,since it may spring from various different underly-ing forms.
This is a useful auxiliary definition thatwill serve to identify markedness violations.
Like-wise Change(X,Y) reflects the GEN representa-tion of changing a segment X to Y needed to con-cisely identify changed segments.
Using the abovewe may now define the remaining violation markupsneeded.CVOI = [b|d|g];Voiced = [b|d|g|V];Unvoiced = [p|t|k];define VC Change(Voiced,Unvoiced) |Change(Unvoiced,Voiced);define Place Change(p,?-b)|Change(t,?-d)|Change(k,?-g)|Change(b,?-p)|Change(d,?-t)|Change(g,?-k)|Change(a,?)|Change(e,?)|Change(i,?)|Change(o,?)|Change(u,?
);VF = [..] -> {*} || Surf(CVOI) _ .#.
;IdentV = [..] -> {*} || VC _ ;VOP = [..] -> {*} || Surf(CVOI) _ ;IdentPl = [..] -> {*} || Place _ ;The final remaining element for a complete imple-mentation concerns the question of ?worsening?
andits introduction into a chain of transducer composi-tion.
To this end, we include a few more definitions:AddViol = [?
* 0:%* ?
*]+;Worsen = [Gen.i .o.
Gen]/%* .o.
AddViol;def Eval(X) X .o.
?
[X .o.
Worsen].l .o.
%*->0;Cleanup = %[|%] -> 0 .o.
%( \%)* %) -> 0;Here, AddViol is the basic worsening methoddiscussed above whereby at least one violation markis added.
However, because GEN adds markup tothe underlying forms, we need to be a bit more flex-ible in our worsening procedure when matching upviolations.
It may be the case that two different com-peting surface forms have the same underlying form,but the violation marks will not align correctly be-cause of interfering brackets.
Given two competingcandidates with a different number of violations, forexample (a)[b]* and [a], we would like the latter tomatch the former after adding a violation mark sincethey both originate in the same underlying form a.The way to achieve this is to undo the effect of GEN,and then redo GEN in every possible configurationbefore adding the violation marks.
The transducerWorsen, above, does this by a composition of theinverse GEN, followed by GEN, ignoring already ex-isting violations.
For the above example, this leadsto representations such as:[a] Gen.i?
a Gen?
(a)[b] AddViol?
(a)[b]*.140p t k a e i o u1b d g2g:04d:0 5b:0p t k a e i o ub d g g:0d:0b:030:k0:t0:pFigure 2: OT grammar for devoicing compiled into anFST.We also define a Cleanup transducer that re-moves brackets and parts of the underlying form.Now we are ready to compile the entire systeminto an FST.
To apply only GEN and the first con-straint, for example, we can calculate:Eval(Gen .o.
Dep) .o.
Cleanup;and likewise the entire grammar can be calculatedby:Eval(Eval(Eval(Eval(Eval(Eval(Gen .o.
Dep) .o.
Max) .o.
IdentPl) .o.VF) .o.
IdentV) .o.
VOP) .o.
Cleanup;This yields an FST of 6 states and 31 transitions(see figure 2)?it can be ascertained that the FSTindeed does represent a relation where word-finalvoiced obstruents are always devoiced.3.3 Permutation of violationsAs mentioned in Gerdemann and van Noord(2000), there is an additional complication with the?worsening?-approach.
It is not always the case thatin the pool of competing candidates, the violationmarkers line up, which is a prerequisite for filteringout suboptimal ones by adding violations?althoughin the above grammar the violations do line up cor-rectly.
However, for the vast majority of OT gram-mars, this can be remedied by inserting a violation-permuting transducer that moves violations markersaround before worsening, to attempt to produce acorrect alignment.
Such a permuting transducer canbe defined as in figure 3.If the need for permutation arises, repeated per-mutations can be included as many times as war-ranted in the definition of Worsen:Figure 3: Violation permutation transducer.Permute = [%*:0 ?
* 0:%*|0:%* ?
* %*:0]*/?
;Worsen = [Gen.i .o.
Gen]/%* .o.Permute .o.
... .o.
Permute .o.AddViol;Knowing how many permutations are necessaryfor the transducer to be able to distinguish betweenany number of violations in a candidate pool is pos-sible as follows: we can can calculate for some con-straint ConsN in a sequence of constraints,Eval(Eval(Gen .o.
Cons1) ... .o.
ConsN) .o.ConsN .o.
\%* -> 0;Now, this yields a transducer that maps every un-derlying form to n asterisks, n being the numberof violations with respect to ConsN in the candi-dates that have successfully survived ConsN.
If thistransducer represents a function (is single-valued),then we know that two candidates with a differentnumber of violations have not survived ConsN, andthat the worsening yielded the correct answer.
Sincethe question of transducer functionality is knownto be decidable (Blattner and Head, 1977), andan efficient algorithm is given in Hulden (2009a),which is included in foma (with the command testfunctional) we can address this question by cal-culating the above for each constraint, if necessary,and then permute the violation markers until theabove transducer is functional.3.4 Equivalence testingIn many cases, the purpose of an OT grammar isto capture accurately some linguistic phenomenonthrough the interaction of constraints rather than byother formalisms.
However, as has been noted by15Karttunen (2006), among others, OT constraint de-bugging is an arduous task due to the sheer num-ber of unforeseen candidates.
One of the advantagesin encoding an OT grammar through the worseningapproach is that we can produce an exact represen-tation of the grammar, which is not an approxima-tion bounded by the number of constraint violationsit can distinguish (as in Karttunen (1998)), or by thelength of strings it can handle.
This allows us toformally calculate, among other things, the equiva-lence of an OT grammar represented as an FST andsome other transducer.
For example, in the abovegrammar, the intention was to model end-of-wordobstruent devoicing through optimality constraints.Another way to model the same thing would be tocompile the replacement rule:Rule = b -> p, d -> t, g -> k || _ .#.
;The transducer resulting from this is shown in fig-ure 4.0@ k p t1b d g2b:p d:t g:k@ k p tb d gb:p d:t g:kFigure 4: Devoicing transducer compiled through a rule.As is seen, the OT transducer (figure 2) andthe rule transducer (figure 4) are not structurallyidentical.
However, both transducers represent afunction?i.e.
for any given input, there is alwaysa unique winning candidate.
Although transducerequivalence is not testable by algorithm in the gen-eral case, it is decidable in the case where one oftwo transducers is functional.
If this is the case it issufficient to test that domain(?1) = domain(?2) andthat ?
?12 ?
?1 represents identity relations only.
Asan algorithm to decide if a transducer is an identitytransducer is also included in foma, it can be used toascertain that the two above transducers are in factidentical, and that the linguistic generalization cap-tured by the OT constraints is correct:regex Rule.i .o.
Grammar;test identitywhich indeed returns TRUE.
For a small grammar,such as the devoicing grammar, determining the cor-rectness of the result by other means is certainly fea-sible.
However, for more complex systems the abil-ity to test for equivalence becomes a valuable tool inanalyzing constraint systems.4 Variations on GEN: an OT grammar ofstress assignmentMost OT grammars that deal with phonological phe-nomena with faithfulness and markedness gram-mars are implementable through the approach givenabove, with minor variations according to what spe-cific constraints are used.
In other domains, how-ever, in may be the case that GEN, as describedabove, needs modification.
A case in point are gram-mars that mark prosody or perform syllabificationthat often take advantage of only markedness con-straints.
In such cases, there is often no need forGEN to insert, change, and delete material if allfaithfulness constraints are assumed to outrank allmarkedness constraints.
Or alternatively, if the OTgrammar is assumed to operate on a different stra-tum where no faithfulness constraints are present.However, GEN still needs to insert material intostrings, such as stress marks or syllable boundaries.To test the approach with a larger ?real-world?
grammar we have reimplemented a Finnishstress assignment grammar, originally implementedthrough the counting approach of Karttunen (1998)in Karttunen (2006), following a description inKiparsky (2003).
The grammar itself contains nineconstraints, and is intended to give a complete ac-count of stress placement in Finnish words.
Withoutgoing into a line-by-line analysis of the grammar,the crucial main differences in this implementationto that of the previous sections are:?
GEN only inserts symbols ( ) ?
and ?to mark feet and stress?
Violations need to be permuted in Worsen toyield an exact representation?
GEN syllabifies words correctly through a re-placement rule (no constraints are given in thegrammar to model syllabification; this is as-sumed to be already performed)16kainostelijat -> (ka?i.nos).
(te?.li).jatkalastelemme -> (ka?.las).te.
(le?m.me)kalasteleminen -> *(ka?.las).te.
(le?.mi).nenkalastelet -> (ka?.las).
(te?.let)kuningas -> (ku?.nin).gasstrukturalismi -> (stru?k.tu).ra.
(li?s.mi)ergonomia -> (e?r.go).
(no?.mi).amatematiikka -> (ma?.te).ma.
(ti?ik.ka)Figure 5: Example outputs of matching implementationof Finnish OT.Compiling the entire grammar through the sameprocedure as above outputs a transducer with 134states, and produces the same predictions as Kart-tunen?s counting OT grammar.6 As opposed to theprevious devoicing grammar, compiling the Finnishprosody grammar requires permutation of the viola-tion markers, although only one constraint requiresit (STRESS-TO-WEIGHT, and in that case, compos-ing Worsen with one round of permutation is suffi-cient for convergence).Unlike the counting approach, the current ap-proach confers two significant advantages.
The firstis that we can compile the entire grammar into anFST that does not restrict the inputs in any way.
Thatis, the final product is a stand-alone transducer thataccepts as input any sequence of any length of sym-bols in the Finnish alphabet, and produces an outputwhere the sequence is syllabified, marked with feet,and primary and secondary stress placement (see fig-ure 5).
The counting method, in order to compile atall, requires that the set of inputs be fixed to somevery limited set of words, and that the maximumnumber of distinguishable violations (and indirectlyword length) be fixed to some k.7 The second ad-vantage is that, as mentioned before, we are able toformally compare the OT grammar (because it is notan approximation), to a rule-based grammar (FST)that purports to capture the same phenomena.
Forexample, Karttunen (2006), apart from the count-ing OT implementation, also provides a rule-basedaccount of Finnish stress, which he discovers to bedistinct from an OT account by finding two words6Including replicating errors in Kiparsky?s OT analysis dis-covered by Karttunen, as seen in figure 5.7Also, compiling the grammar is reasonably quick: 7.04s ona 2.8MHz Intel Core 2, vs. 2.1s for a rewrite-rule-based accountof the same phenomena.where their respective predictions differ.
However,by virtue of having an exact transducer, we can for-mally analyze the OT account together with the rule-based account to see if they differ in their predictionsfor any input, without having to first intuit a differ-ing example:regex RuleGrammar.i .o.
OTGrammar;test identityFurther, we can subject the two grammars to theusual finite-state calculus operations to gain possibleinsight into what kinds of words yield different pre-dictions with the two?something useful for linguis-tic debugging.
Likewise, we can use similar tech-niques to analyze for redundancy in grammars.
Forexample, we have assumed that the VOP-constraintplays no role in the above devoicing tableaux.
Usingfinite-state calculus, we can prove it to be so for anyinput if the grammar is constructed with the methodpresented here.5 Limits on FST implementationWe shall conclude the presentation here with a briefdiscussion of the limits of FST representability, evenof simple OT grammars.
Previous analyses haveshown that OT systems are beyond the generativecapacity of finite-state systems, under some assump-tions of what GEN looks like.
For example, Frankand Satta (1998) present such a constraint systemwhere GEN is taken to be defined through a trans-duction equivalent to:8Gen = [a:b|b:a]* | [a|b]*;That is, a relation which either maps all a?s to b?sand vice versa, or leaves the input unchanged.
Now,let us assume the presence of a single markednessconstraint ?a, militating against the letter a.
In thatcase, given an input of the format a?b?
the effectivemapping of the entire system is one that is an identityrelation if there are fewer a?s than b?s; otherwise thea?s and b?s are swapped.
As is easily seen, this is nota regular relation.One possible objection to this analysis of non-regularity is that linguistically GEN is usually as-sumed to perform any transformation to the input8The idea is attributed to Markus Hiller in the article.17whatsoever?not just limiting itself to a proper sub-set of ??
?
??.
However, it is indeed the casethat even with a canonical GEN-function, some verysimple OT systems fall outside the purview of finite-state expressibility, as we shall illustrate by a differ-ent example here.5.1 A simple proof of OT nonregularityAssume a grammar that has four very basic con-straints: IDENT, forbidding changes, DEP, for-bidding epenthesis, ?ab, a markedness constraintagainst the sequence ab, and MAX, forbidding dele-tion, ranked IDENT,DEP  ?ab  MAX.
We as-sume GEN to be as general as possible?performingarbitrary deletions, insertions, and changes.It is clear, as is illustrated in table 2, that for all in-puts of the format anbm the grammar in question de-scribes a relation that deletes all the a?s or all the b?sdepending on which there are fewer instances of, i.e.anbm ?
an if m < n, and anbm ?
bm if n < m.This can be shown by a simple pumping argumentto not be realizable through an FST.aaabb IDENT DEP ?ab MAXaaaaa *!
*aaacbb *!aaabb *!aaab *!
*bb ***!+ aaa **Table 2: Illustrative tableau for a simple constraint sys-tem not capturable as a regular relation.Implementing this constraint system with themethods presented here is an interesting exerciseand serves to examine the behavior of the method.We define GEN, DEP, MAX, and IDENT as be-fore, define a universal alphabet (excluding markupsymbols), and the constraint ?ab naturally as:S = ?
- %( - %) - %[ - %] - %* ;NotAB = [..] -> {*} || Surf(a b) _ ;Now, with one round of permutation of the viola-tion markers in Worsen as follows:Worsen = [Gen.i .o.
Gen]/{*} .o.AddViol .o.
Permute;we calculatedefine Grammar Eval(Eval(Eval(Eval(Gen .o.
Ident) .o.
Dep) .o.
NotAB) .o.Max) .o.
Cleanup;which produces an FST that cannot distinguish be-tween more than two a?s or b?s in a string.
Whileit correctly maps aab to aa and abb to bb, thetableau example of aaabb is mapped to both aaaand bb.
However, with one more round of permu-tation in Worsen, we produce an FST that can in-deed cover the example, mapping aaabb uniquelyto bb, while failing with aaaabbb (see figure 6).This illustrates the approximation characteristic ofthe matching method: for some grammars (proba-bly most natural language grammars) the worseningapproach will at some point of permutation of the vi-olation markers terminate and produce an exact FSTrepresentation of the grammar, while for some gram-mars such convergence will never happen.
How-ever, if the permutation of markers terminates andproduces a functional transducer when testing eachviolation as described above, the FST is guaranteedto be an exact representation.0b @1a5a:0@ 2b:03a@a@b:04a@a b:0b6a:0 b 7a:0ba:0Figure 6: An non-regular OT approximation.It is an open question if it is decidable by exam-ining a grammar whether it will yield an exact FSTrepresentation.
We do not expect this question to beeasy, since it cannot be determined by the nature ofthe constraints alone.
For example, the above four-constraint system does have an exact FST represen-tation in some orderings of the constraints, but notin the particular one given above.186 ConclusionWe have presented a practical method of implement-ing OT grammars as finite-state transducers.
The ex-amples, definitions, and templates given should besufficient and flexible enough to encode a wide vari-ety of OT grammars as FSTs.
Although no methodcan encode all OT grammars as FSTs, the funda-mental advantage with the system outlined is thatfor a large majority of practical cases, an FST canbe produced which is not an approximation that canonly tell apart a limited number of violations.
Ashas been noted elsewhere (e.g.
Eisner (2000b,a)),some OT constraints, such as Generalized Align-ment constraints, are on the face of it not suitablefor FST implementation.
We may add to this thatsome very simple constraint systems, assuming acanonical GEN, and only using the most basic faith-fulness and markedness constraints, are likewise notencodable as regular relations, and seem to have thegenerative power to encode phenomena not foundin natural language.
However, for most practicalpurposes?and this includes modeling actual phe-nomena in phonology and morphology?the presentapproach offers a fruitful way to implement, ana-lyze, and debug OT grammars.ReferencesBeesley, K. R. and Karttunen, L. (2003).
Finite StateMorphology.
CSLI Publications, Stanford, CA.Blattner, M. and Head, T. (1977).
Single-valued a-transducers.
Journal of Computer and System Sci-ences, 15(3):328?353.Eisner, J.
(2000a).
Directional constraint evaluationin optimality theory.
In Proceedings of the 18thconference on Computational linguistics, pages257?263.
Association for Computational Linguis-tics.Eisner, J.
(2000b).
Easy and hard constraint rankingin optimality theory.
In Finite-state phonology:Proceedings of the 5th SIGPHON, pages 22?33.Ellison, T. M. (1994).
Phonological derivation in op-timality theory.
In Proceedings of COLING?94?Volume 2, pages 1007?1013.Frank, R. and Satta, G. (1998).
Optimality theoryand the generative complexity of constraint viola-bility.
Computational Linguistics, 24(2):307?315.Gerdemann, D. and van Noord, G. (2000).
Approx-imation and exactness in finite state optimalitytheory.
In Proceedings of the Fifth Workshop ofthe ACL Special Interest Group in ComputationalPhonology.Hammond, M. (1997).
Parsing syllables: ModelingOT computationally.
Rutgers Optimality Archive(ROA), 222-1097.Hulden, M. (2009a).
Finite-state Machine Construc-tion Methods and Algorithms for Phonology andMorphology.
PhD thesis, The University of Ari-zona.Hulden, M. (2009b).
Foma: a finite-state compilerand library.
In EACL 2009 Proceedings, pages29?32.Ja?ger, G. (2002).
Gradient constraints in finite stateOT: the unidirectional and the bidirectional case.More than Words.
A Festschrift for Dieter Wun-derlich, pages 299?325.Kager, R. (1999).
Optimality Theory.
CambridgeUniversity Press.Kaplan, R. M. and Kay, M. (1994).
Regular mod-els of phonological rule systems.
ComputationalLinguistics, 20(3):331?378.Karttunen, L. (1998).
The proper treatment of op-timality theory in computational phonology.
InFinite-state Methods in Natural Language Pro-cessing.Karttunen, L. (2006).
The insufficiency of paper-and-pencil linguistics: the case of Finnishprosody.
Rutgers Optimality Archive.Kiparsky, P. (2003).
Finnish noun inflection.
Gener-ative approaches to Finnic linguistics.
Stanford:CSLI.Prince, A. and Smolensky, P. (1993).
Optimalitytheory: Constraint interaction in generative gram-mar.
ms. Rutgers University Cognitive ScienceCenter.Riggle, J.
(2004).
Generation, recognition, andlearning in finite state Optimality Theory.
PhDthesis, University of California, Los Angeles.19
