Proceedings of NAACL HLT 2009: Short Papers, pages 257?260,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsRecognising the Predicate?argument Structure of TagalogMeladel MisticaAustralian National University ?
LinguisticsThe University of Melbourne ?
CSSEThe University of Sydney ?
Linguisticsmmistica@csse.unimelb.edu.auTimothy BaldwinCSSEThe University of Melbournetim@csse.unimelb.edu.auAbstractThis paper describes research on parsingTagalog text for predicate?argument structure(PAS).
We first outline the linguistic phe-nomenon and corpus annotation process, thendetail a series of PAS parsing experiments.1 IntroductionPredicate?argument structure (PAS) has beenshown to be highly valuable in tasks such as infor-mation extraction (Surdeanu et al, 2003; Miyao etal., 2009).
In this research, we develop a resource foranalysing the predicate?argument structure of Taga-log, a free word order language native to the Philip-pines, and carry out preliminary empirical investiga-tion of PAS parsing methods over Tagalog.The motivation for this research is the investiga-tion of the interaction between information structureand word order in Tagalog.
That is, we wish to de-termine the utility of discourse-based contextual in-formation in predicting word order in Tagalog, in anatural language generation context.
We see PAS asthe natural representation for this exploration.
Thisresearch clearly has implications beyond our imme-diate interests, however, in terms of resource cre-ation for an NLP resource-poor language, and thefacilitation of research on parsing and parsing-basedapplications in Tagalog.
It is also one of the first in-stances of research on PAS parsing over a genuinelyfree word order language.2 BackgroundTagalog is an Austronesian language of the Malayo-Polynesian branch, which forms the basis of the na-tional language of the Philippines, Filipino (a.k.a.Pilipino) (Gordon, 2005).
It is a verb-initial lan-guage, with relatively free word order of verbalarguments (Kroeger, 1993), as exemplified in theword-order variants provided with (1).
There areno discernible meaning differences between the pro-vided variants, but there are various soft constraintson free word order, as discussed by Kroeger (1993)and Sells (2000).
(1) NagbigaygavengGENlibrobooksaDATbabaewomanangNOMlalakiman?The man gave the woman a book?Nagbigay ng libro ang lalaki sa babaeNagbigay sa babae ng libro ang lalakiNagbigay sa babae ang lalaki ng libroNagbigay ang lalaki sa babae ng libroNagbigay ang lalaki ng librosa babaeIn addition to these free word order possibilities,Tagalog exhibits voice marking, a morpho-syntacticphenomenon which is common in Austronesian lan-guages and gives prominence to an element in a sen-tence (Schachter and Otanes, 1972; Kroeger, 1993).This poses considerable challenges to generation,because of the combinatorial explosion in the pos-sible ways of expressing what is seemingly the sameproposition.
Below, we provide a brief introductionto Tagalog syntax, with particular attention to voicemarking.2.1 ConstituencyThere are three case markers in Tagalog: ang, ngand sa, which are by convention written as separatepreposing words, as in (1).
These markers normallyprepose phrasal arguments of a given verb.The sa marker is predominantly used for goals,recipients, locations and definite objects, while ngmarks possessors, actors, instruments and indefiniteobjects (Kroeger, 1993).
Ang is best explained interms of Tagalog?s voice-marking system.2572.2 Tagalog Voice MarkingTagalog has rich verbal morphology which givesprominence to a particular dependent via voicemarking (Schachter and Otanes, 1972); this specialdependent in the sentence is the ang-marked argu-ment.There are 5 major voice types in Tagalog: Ac-tor Voice (AV); Patient/Object Voice (OV); Da-tive/Locative Voice (DV); Instrumental Voice (IV);and Benefactive Voice (BV) (Kroeger, 1993).
Thisvoice marking, manifested on the verb, reflects thesemantic role of the ang-marked constituent, as seenin the sentences below from Kroeger (1993), illus-trating the 3 voice types of AV, OV, and BV.
(2) Actor Voice (AV)BumilibuyangNOMlalakemanngGENisdafishsaDATtindahanstore?The man bought fish at the store?
(3) Object Voice (OV)BinilibuyngGENlalakemanangNOMisdafishsaDATtindahan.store?The man bought fish at the store?
(4) Benefactive Voice (BV)IbinilibuyngGENlalakemanngGENisdafishangNOMbata.child?The man bought fish for the child?In each case, the morphological marking on the verb(which indicates the voice type) is presented in bold,along with the focused ang argument.In addition to displaying free word order, there-fore, Tagalog presents the further choice of whichvoice to encode the proposition with.3 Data and ResourcesFor this research, we annotated our own corpus ofTagalog text for PAS.
This is the first such resourceto be created for the Tagalog language.
To date,we have marked up two chapters (about 2500 to-kens) from a narrative obtained from the Guten-berg Project1 called Hiwaga ng Pagibig (?The Mys-tery of Love?
); we intend to expand the amount of1http://www.gutenberg.org/etext/18955annotated data in the future.
The annotated datais available from www.csse.unimelb.edu.au/research/lt/resources/tagalog-pas.3.1 Part-of-speech Mark-upFirst, we developed a set of 5 high-level part-of-speech (POS) tags for the task, with an additionaltag for sundries such as punctuation.
The tags are asfollows:Description Example(s)proper name names of people/citiespronoun personal pronounsopen-class word nouns, verbs, adjectivesclosed-class word conjunctionsfunction word case markersother punctuationThese tags are aimed at assisting the identificationof constituent boundaries, focusing primarily on dif-ferentiating words that have semantic content fromthose that perform a grammatical function, with theidea that function words, such as case markers, gen-erally mark the start of an argument, while open-class words generally occur within a predicate or ar-gument.
Closed-class words, on the other hand (e.g.sentence conjuncts) tend not to be found inside pred-icates and arguments.The advantage of having a coarse-grained set oftags is that there is less margin for error and dis-agreement on how a word can be tagged.
For futurework, we would like to compare a finer-grained setof tags, such as that employed by dela Vega et al(2002), with our tags to see if a more detailed dis-tinction results in significant benefits.In Section 4, we investigate the impact of the in-clusion of this extra annotation on PAS recogni-tion, to gauge whether the annotation effort was war-ranted.3.2 Predicate and Argument Mark-upNext, we marked up predicates and their (core) argu-ments, employing the standard IOB tag scheme.
Wemark up two types of predicates: PRD and PRD-SUB.The former refers to predicates that belong to mainclauses, whilst the latter refers to predicates that oc-cur in subordinate or dependent clauses.We mark up 4 types of arguments: ANG, NG,SA and NG-COMP.
The first three mark nominal258phrases, while the last marks sentential comple-ments (e.g.
the object of quotative verbs).We follow the multi-column format used inthe CoNLL 2004 semantic role labelling (SRL)task (Carreras and Ma`rquez, 2004), with as manycolumns as there are predicates in a sentence, andone predicate and its associated arguments per col-umn.3.3 AnnotationOur corpus consists of 259 predicates (47 of whichare subordinate, i.e.
PRD-SUB), and 435 arguments.The following is a breakdown of the arguments:Argument type: SA ANG NG NG-CMPCount: 83 193 147 123.4 Morphological ProcessingIn tandem with the corpus annotation, we developeda finite-state morphological analyser using XFST andLEXC (Beesley and Karttunen, 2003), that extractsmorphological features for individual words in theform of a binary feature vector.2 While LEXC is or-dinarily used to define a lexicon of word stems, weopted instead to list permissible syllables, based onthe work of French (1988).
This decision was basedpurely on resource availability: we did not have anextensive list of stems in Tagalog, or the means togenerate such a list.4 ExperimentsIn this section, we report on preliminary results forPAS recognition over our annotated data.
The ap-proach we adopt is similar to the conventional ap-proach adopted in CoNLL-style semantic role la-belling: a two-phase approach of first identifying thepredicates, then identifying arguments and attachingthem to predicates, in a pipeline architecture.
Pri-mary areas of investigation in our experiments are:(1) the impact of POS tags on predicate prediction;and (2) the impact of morphological processing onoverall performance.In addition to experimenting with the finite statemorphological processing (see Section 3.4), we ex-periment with a character n-gram method, where wesimply take the first and last n characters of a word2Thanks to Steven Bird for help with infixation and definingpermissible syllables for the morphological analyseras features.
In our experiments, we set n to 3 and 2characters for prefix and suffixes, respectively.We treat each step in the pipeline as a structuredlearning task, which we model with conditional ran-dom fields (Lafferty et al, 2001) using CRF++.3All of the results were arrived at via leave-one-outcross-validation, defined at the sentence level, andthe evaluation was carried out in terms of precision(P), recall (R) and F-score (F) using the evaluationsoftware from the CoNLL 2004 SRL task.4.1 Predicate identificationFirst, we attempt to identify the predicate(s) in agiven sentence.
Here, we experiment with wordcontext windows of varying width (1?6 words),and also POS features in the given context win-dow.
Three different strategies are used to derivethe POS tags: (1) from CRF++, with a word bi-gram context window of width 3 (AUTO1); (2) againfrom CRF++, with a word bigram context windowof width 1 (AUTO2); and (3) from gold-standardPOS tags, sourced from the corpus (GOLD).
AUTO1and AUTO2 were the two best-performing POS tag-ging methods amongst a selection of configurationstested, both achieving a word accuracy of 0.914.We compare these three POS tagging options witha method which uses no POS tag information (NOPOS).
The results for the different POS taggers witheach word context width size are presented in Ta-ble 1.Our results indicate that the optimal window sizefor the predicate identification is 5 words.
We alsosee that POS contributes to the task, and that the rel-ative difference between the gold-standard POS tagsand the best of the automatic POS taggers (AUTO2)is small.
Of the two POS taggers, the best per-formance for AUTO2 is clearly superior to that forAUTO1.4.2 Argument Identification and AttachmentWe next turn to argument identification and attach-ment, i.e.
determining the word extent of argumentswhich attach to each predicate identified in the firststep of the pipeline.
Here, we build three predicaterecognisers from Section 4.1: NO POS, AUTO2 and3http://sourceforge.net/projects/crfpp/259Window NO POS AUTO1 AUTO2 GOLDsize P R F P R F P R F P R F1 .255 .086 .129 .406 .140 .208 .421 .143 .214 .426 .144 .2152 .436 .158 .232 .487 .272 .349 .487 .262 .340 .529 .325 .4033 .500 .190 .275 .477 .255 .332 .500 .262 .344 .571 .335 .4224 .478 .190 .272 .509 .290 .370 .542 .280 .369 .523 .325 .4015 .491 .204 .278 .494 .274 .351 .558 .349 .429 .571 .360 .4426 .478 .190 .272 .484 .269 .346 .490 .262 .341 .547 .338 .418Table 1: Results for predicate identification (best score in each column in bold)Morphological NO POS AUTO2 GOLDanalysis P R F P R F P R FFINITE STATE .362 .137 .199 .407 .201 .269 .420 .207 .278CHAR n-GRAMS .624 .298 .404 .643 .357 .459 .623 .377 .470COMBINED .620 .307 .410 .599 .362 .451 .623 .386 .477Table 2: Results for argument identification and attachment (best score in each column in bold)GOLD, all based on a window size of 5.
We com-bine these with morphological features from: (1) thefinite-state morphological analyser, (2) character n-grams, and (3) the combination of the two.
The re-sults of the different combinations are shown in Ta-ble 2, all based on a word context window of 3, asthis was found to be superior for the task in all cases.The results with character n-grams were in allcases superior to those for the morphological anal-yser, although slight gains were seen when the twowere combined in most cases (most notably in re-call).
There was surprisingly little difference be-tween the GOLD results (using gold-standard POStags) and the AUTO2 results.5 ConclusionIn this paper, we have presented a system that recog-nises PAS in Tagalog text.
As part of this, we cre-ated the first corpus of PAS for Tagalog, and pro-duced preliminary results for predicate identificationand argument identification and attachment.In future work, we would like to experiment withlarger datasets, include semantic features, and trialother learners amenable to structured learning tasks.ReferencesKenneth R. Beesley and Lauri Karttunen.
2003.
FiniteState Morphology.
CSLI Publications, Stanford, USA.Xavier Carreras and Llu?
?s Ma`rquez.
2004.
Introductionto the CoNLL-2004 shared task: Semantic role label-ing.
In Proc.
of CoNLL-2004, pages 89?97, Boston,USA.Ester D. dela Vega, Melvin Co, and Rowena CristinaGuevara.
2002.
Language model for predicting partsof speech of Filipino sentences.
In Proceedings of the3rd National ECE Conference.Koleen Matsuda French.
1988.
Insights into Tagalog.Summer Institute of Linguistics, Dallas, USA.Raymond Gordon, Jr. 2005.
Ethnologue: Languagesof the World.
SIL International, Dallas, USA, 15thedition.Paul Kroeger.
1993.
Phrase Structure and Grammati-cal Relations in Tagalog.
CSLI Publications, Stanford,USA.John Lafferty, Andrew McCallum, and Fernando Pereira.2001.
Conditional random fields: Probabilistic modelsfor segmenting and labeling sequence data.
In Proc.
ofICML 2001, pages 282?289, Williamstown, USA.Yusuke Miyao, Kenji Sagae, Rune Saetre, Takuya Mat-suzaki, and Jun?ichi Tsujii.
2009.
Evaluating contri-butions of natural language parsers to protein?proteininteraction extraction.
Bioinformatics, 25(3):394?400.Paul Schachter and Fe T. Otanes.
1972.
Tagalog Refer-ence Grammar.
University of California Press, Berke-ley.Peter Sells.
2000.
Raising and the order of clausalconstituents in the Philippine languages.
In IleanaPaul, Vivianne Phillips, and Lisa Travis, editors, For-mal Issues in Austronesian Linguistics, pages 117?143.
Kluwer Academic Publishers, Dordrecht, Ger-many.Mihai Surdeanu, Sanda Harabagiu, John Williams, andPaul Aarseth.
2003.
Using predicate-argument struc-tures for information extraction.
In Proc.
of ACL 2003,pages 8?15, Sapporo, Japan.260
