Proceedings of SSST-6, Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 102?110,Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational LinguisticsApplication of Clause Alignment for Statistical Machine TranslationSvetla Koeva, Borislav Rizov, Ivelina Stoyanova, Svetlozara Leseva, Rositsa Dekova, Angel Genov,Ekaterina Tarpomanova, Tsvetana Dimitrova and Hristina KukovaDepartment of Computational LinguisticsInstitute for Bulgarian Language, Bulgarian Academy of SciencesSofia 1113, Bulgaria{svetla,boby,iva,zarka,rosdek,angel,katja,cvetana,hristina}@dcl.bas.bgAbstractThe paper presents a new resource light flexi-ble method for clause alignment which com-bines the Gale-Church algorithm with in-ternally collected textual information.
Themethod does not resort to any pre-developedlinguistic resources which makes it very ap-propriate for resource light clause alignment.We experiment with a combination of themethod with the original Gale-Church algo-rithm (1993) applied for clause alignment.The performance of this flexible method, as itwill be referred to hereafter, is measured overa specially designed test corpus.The clause alignment is explored as meansto provide improved training data for thepurposes of Statistical Machine Translation(SMT).
A series of experiments with Mosesdemonstrate ways to modify the parallel re-source and effects on translation quality: (1)baseline training with a Bulgarian-Englishparallel corpus aligned at sentence level; (2)training based on parallel clause pairs; (3)training with clause reordering, where clausesin each source language (SL) sentence are re-ordered according to order of the clauses inthe target language (TL) sentence.
Evaluationis based on BLEU score and shows small im-provement when using the clause aligned cor-pus.1 MotivationEvaluation on the performance of MT systems hasshown that a pervasive shortcoming shared by boththe phrase-based and the syntax-based SMT systemsis translating long and (syntactically) complex sen-tences (Koehn et al, 2003; Li et al, 2007; Sudoh etal., 2010).The power of phrase-based SMT lies in local lex-ical choice and short-distance reordering (Li et al,2007).
Syntax-based SMT is better suited to copewith long-distance dependencies, however there alsoare problems, some of them originated from the lin-guistic motivation itself ?
incorrect parse-trees, orreordering that might involve blocks that are notconstituents (Li et al, 2007).An efficient way to overcome the problem of sen-tence length and complexity is to process the clausesin a similar way as sentences.
This has incited grow-ing interest towards the alignment and processing ofclauses ?
a group of syntactically and semanticallyrelated words expressing predicative relation andpositioned between sentence borders or clause con-nectors.
(It is known that some predicative relationscan be considered complex being saturated with an-other predicative relation ?
but with the above givendefinition this case is simplified).The differences in word order and phrase structureacross languages can be better captured at a clauserather than at a sentence level, therefore, monolin-gual and parallel text processing in the scope of theclauses may significantly improve syntactic parsing,automatic translation, etc.
The sentences can be verylong and complex in structure, may consist of a con-siderable number of clauses which in turn may varywith respect to their relative position to each otherin parallel texts both due to linguistic reasons per seand translators?
choices.The flexible order, length and number of clauses102in sentences, along with the different word order andways of lexicalisation across languages contribute tothe complexity of clause alignment as compared tosentence alignment and call for more sophisticatedapproaches.
These findings have inspired growingresearch into clause-to-clause machine translationinvolving clause splitting, alignment and word orderrestructuring within the clauses (Cowan et al, 2006;Ramanathan et al, 2011; Sudoh et al, 2010; Goh etal., 2011).A fixed clause order in a language (i.e.
rela-tive clauses in Bulgarian, English, French and manyother languages follow the head noun, while in Chi-nese, Japanese, Turkish, etc.
they precede it) maycorrespond to a free order in another (i.e.
Bulgar-ian and English adverbial clauses).
The hypothesisis that a SMT model can be improved by inducinga straightforward clause alignment through reorder-ing the clauses of the source language text so as tocorrespond to the order of the clauses in the targetlanguage text.2 State-of-the-artThe task of clause alignment is closely related tothat of sentence alignment (Brown et al, 1990; Galeand Church, 1993; Kay and Roscheisen, 1993) andphrase alignment (DeNero and Klein, 2008; Koehnet al, 2003).
There are two main approaches ?
sta-tistical and lexical, often employed together to pro-duce hybrid methods.
Machine learning techniquesare applied to extract models from the data and re-duce the need of predefined linguistic resources.Boutsis, Piperidis and others (Boutsis andPiperidis, 1998; Boutsis and Piperidis, 1998;Piperidis et al, 2000) employ a method combin-ing statistical techniques and shallow linguistic pro-cessing applied on a bilingual parallel corpus ofsoftware documentation which is sentence-aligned,POS-tagged and shallow parsed.
The combined taskof clause borders identification uses linguistic in-formation (POS tagging and shallow parsing) andclause alignment based on pure statistical analysis.The reported precision is 85.7%.
Kit et al (2004)propose a method for aligning clauses in Hong Konglegal texts to English which relies on linguistic in-formation derived from a glossary of bilingual legalterms and a large-scale bilingual dictionary.
The al-gorithm selects a minimal optimal set of scores inthe similarity matrix that covers all clauses in bothlanguages.
The authors report 94.60% alignment ac-curacy of the clauses, corresponding to 88.64% ofthe words.The quality of the parallel resources is of cru-cial importance to the performance of SMT sys-tems and substantial research is focused on devel-oping good parallel corpora of high standard.
Mostclause alignment methods are applied on domainspecific corpora, in particular administrative cor-pora and are not extensively tested and evaluated ongeneral corpora or on texts of other domains.
Al-though clause segmentation is often performed to-gether with clause alignment (Papageorgiou, 1997)the former tends to be more language-specific andtherefore clause alignment is performed and eval-uated independently.
The majority of the avail-able comparative analyses discuss modifications ofone method rather than the performance of differentmethods.
Moreover, the performance of resource-free against resource-rich methods has been poorlyexplored.
To the best of our knowledge, there isno purely resource-free method for clause alignmentoffered so far.In recent years, handling machine translation atthe clause level has been found to overcome some ofthe limitations of phrase-based SMT.
Clause alignedcorpora have been successfully employed in thetraining of models for clause-to-clause translation,reordering and subsequent sentence reconstructionin SMT ?
Cowan et al (2006) for syntax-basedGerman-to-English SMT, Sudoh et al (2010) forEnglish-to-Japanese phrase-based SMT, among oth-ers.Cowan et al (2006) discuss an approach fortree-to-tree SMT using Tree Adjoining Grammars.Clause alignment is performed on a corpus (Eu-roparl) which is then used in the training of a modelfor mapping parse trees in the source language toparse trees in the target language.
The performanceof this syntax-based method is similar to the phrase-based model of Koehn et al (2003).Sudoh et al (2010) propose a method for clause-to-clause translation by means of a standard SMTmethod.
The clauses may contain non-terminals asplaceholders for embedded clauses.
After transla-tion is performed, the non-terminals are replaced103by their clause translations.
The model for clausetranslation is trained using a clause-aligned bilin-gual corpus of research paper abstract.
The proposedimprovement by using Moses is 1.4% in BLEU(33.19% to 34.60%), and 1.3% in TER (57.83% to56.50%) and 2.2% in BLEU (32.39% to 34.55%)and 3.5% in TER (58.36% to 54.87%) using a hi-erarchical phrase-based SMT system.The potential of clause alignment along withother sub-sentence levels of alignment in extract-ing matching translation equivalents from transla-tion archives has been recognised within the EBMTframework, as well (Piperidis et al, 2000).3 Bootstrapping clause alignmentThe clause alignment is modelled as a bipartitegraph.
Each node in the graph corresponds to aclause in either the source or the target language.A pair of clauses that are fully or partially trans-lational equivalents is connected by an edge in thegraph.
The connected components of the graph arebeads (the smallest group of aligned clauses).
Inthese terms, the task of clause alignment is the taskof the identification of the edges in a bipartite graph,where the nodes are the clauses (Brown et al, 1990).A bootstrapping method for clause alignment thatdoes not exploit any pre-developed linguistic re-sources is elaborated.
The method uses length-balance based alignment algorithm ?
i.e.
Gale-Church (Gale and Church, 1993), for the data col-lecting.
The bootstrapping algorithm attains highprecision and relatively good recall.
In order toimprove the recall while preserving the precisionthe method is combined with the Gale-Church al-gorithm applied to clause alignment.The proposed method consists of the followingstages:1.
Initial clause alignment that serves as trainingdata.2.
Identifying similarities between clauses in dif-ferent languages.3.
Building the clause alignment.3.1 The Gale and Church algorithmGale and Church (1993) describe a method for align-ing sentences based on a simple statistical model ofsentence lengths measured in number of characters.It relies on the fact that longer sentences in one lan-guage tend to be translated into longer sentences inthe other language, and vice versa.
A probabilis-tic score is assigned to each proposed correspon-dence of sentences, based on the scaled differenceand the variance of the lengths of the two sentences.The method is reported to give less than 4% error interms of alignment and is probably the most widelyused sentence alignment method.The extended version of the Gale-Church alignerfrom the Natural Language Toolkit1 is applied forclause alignment.
The original Gale-Church methodapplies the 1:1, 0:1, 1:0, 1:2, 2:1 and 2:2 bead mod-els; in the extended version ?
the 1:3, 3:1, 2:3, 3:2,3:3 models are added.3.2 Clause alignment training dataThe clause beads are identified by applying theGale-Church algorithm.
The aim is to select a setof aligned beads which are to serve as a training setfor the subsequent stages.
Only beads showing highprobability of correctness are used.
For any proba-bility p we could find ?
so that for the Gale-Churchmeasure within [?
?, ?]
the corresponding bead iscorrect with probability p.3.3 Clause similarityClause similarity is measured by means of: a) par-tial word alignment, b) length similarity, and c)weighted punctuation similarity.3.3.1 Word alignmentTo align words in the scope of parallel clauses,word-to-word connections (weighted links betweentwo words based on word similarity) are calculatedusing several methods given below:?
Vector space modelA given word is assigned a vector< x1, x2, ?
?
?
, xn >in an n-dimensional vector space, where eachdimension represents a bead in the preliminaryclause alignment and x i is the number of theoccurrences of the word in the bead.
The set ofthese vectors is a matrix.1http://nltk.googlecode.com104The vector space word similarity is the cosineof the angle between the vectors of the words(Ruge, 1992; Schu?tze, 1992).
Two words aresimilar if the cosine is above a specified thresh-old.
The observations over the training andtest data show that the translation equivalentsare identified best when the cosine is higherthan 0.7.
However, the word-to-word align-ment reduces some of the errors which increasein number when lowering the threshold.
There-fore, the threshold is set at 0.4 acquiring a goodbalance between the number of the connectionsobtained and the error rate.A second vector space matrix is built using thefirst two words in each clause on the assump-tion that clause-introducing words may expressstronger word-to-word connections.Some experiments with word similarity asso-ciation measures e.g.
the chi-square measure(Evert, 2005) failed to show any improvements.Word forms are treated as instances of one andthe same word if either their actual or nor-malised forms are equal (Kay and Roscheisen,1993).
The normalised forms cover correspon-dences between grammatically and semanti-cally related words in languages with rich in-flectional and derivational morphology.
Themorphology algorithm proposed by Kay andRoscheisen (1993) is applied for splitting po-tential suffixes and prefixes and for obtainingthe normalised word forms.
The vector spaceword-to-word connections are calculated forboth actual and normalised forms and the ob-tained similarity measures are summed up.?
Levenshtein measure (Levenshtein, 1966)Church (1993) employs a method that in-duces sentence alignment by employing cog-nates (words that are spelled similarly acrosslanguages).
Instead the standard Levenshteindistance (the number of edits required to trans-form a string A into another string B) is ap-plied.
The non-Latin characters are transliter-ated into Latin ones.
The distance is calculatedwithin a tolerance different for a different wordlength.
The distance is then transformed intosimilarity by means of the tolerance.
?1?levenshteintolerance + 1.?
PunctuationSimilarity is calculated also if two words con-tain identical prefixes or suffixes which arepunctuation marks or special characters.
Punc-tuation and special characters are not all equal.Some of them are more robust, e.g.
marksfor currency and measurement, or mathemati-cal symbols ($, , , %, +,<,>, =) or the differenttypes of brackets.
Others (e.g.
comma, hyphen,colon, semi-colon) may be governed by lan-guage specific rules and may lead to improve-ment only for those pairs of languages that em-ploy similar rules.The word-to-word similarity measure is theweighted sum of the above measures where theLevenshtein similarity is multiplied by 3, thepunctuation similarity by 0.4 and the vectorspace similarity measure by 1, which is definedas a base.The similarity connections are sorted descend-ingly and sequentially processed.
At each itera-tion only connections between dangling wordsare stored.
Thus there is only one connec-tion left for each word resulting in partial wordalignment.
The weights of all obtained word-to-word connections are summed up to pro-duce the weight of the clause association that ispropagated to the clause similarity calculationstage.3.3.2 Length similarityZero-weighted similarity connections betweenclauses are collected using Gale-Church?s distancemeasure.
Thus connections are added without in-creasing the weight of the existing ones.3.3.3 Weighted punctuation similarityThis similarity is calculated by the following for-mula?Z?PUmin(count(Z ?
cl1), count(Z ?
cl2)),105where PU is the set of the punctuation marks andspecial symbols being prefixes and suffixes of wordsin the clauses processed.3.4 Clause alignment with the bootstrappingmethodThe bipartite graph is built by filtering the set of thecalculated clause similarity connections.
The con-nected components of this graph form the clausebeads.
A conservative fallback strategy is appliedto add the dangling clauses to the most appropri-ate bead.
The filtering process starts by defining athreshold for grouping (1,2) and every clause simi-larity connection with weight above it is consideredstrong.
In a way similar to word alignment, the re-maining (weak) connections are sorted descendinglyand processed one by one.
If the processed connec-tion relates clauses that are not attached to any bead,it passes the filter.
In other words these two clausesform a 1:1 bead.The bootstrapping method evaluated on the testcorpus has precision above 94% and recall of 77%.To overcome this low recall we combine the Gale-Church algorithm with the core method.3.5 Combined clause alignmentThe combined method also distinguishes strong andweak clause connections by means of a thresholdconstant.
At the beginning the Gale-Church resultsin clause alignment are compared with the strongconnections.
If they comply with the Gale-Church?sbeads, the weak connections are processed.
Theweak connections are added to the final graph ifthey do not contradict Gale-Church?s output, i.e.when they do not connect clauses from two differ-ent beads.In case of a strong connection the Gale-Church?salignment is discarded, assuming that the seman-tic and the syntactic similarities between clauses aremore significant than the length.4 Clause alignment evaluation4.1 Test corpusA test corpus was constructed for the purposesof method evaluation.
It consists of 363,402 to-kens altogether (174,790 for Bulgarian and 188,612for English) distributed over five thematic domains:Fiction (21.4%), News (37.1%), Administrative(20.5%), Science (11.2%) and Subtitles (9.8%).
Thepurpose of using a general testing corpus with textsfrom a variety of domains is to investigate methodperformance in a wider range of contexts.Both Bulgarian and English parts of the corpusare first automatically segmented and then alignedat sentence level.
The task of sentence detectionin Bulgarian is carried out using a Bulgarian sen-tence splitter (Koeva and Genov, 2011).
For sen-tence splitting of the English texts a pre-trainedOpenNLP2 model is used.
Sentence alignment isproduced using HunAlign3 (Varga et al, 2005), withthe alignment manually verified by human experts.Clause splitting is considered a highly languagedependent task and separate linguistic models needto be developed for each language.
For the pur-poses of the present study, Bulgarian sentences aremanually or semiautomatically split into clauses andfor the English texts a pre-trained OpenNLP parseris used to determine clause boundaries followed bymanual expert verification and post-editing (the taskof automatic clause splitting falls outside the scopeof the present study).Subsequently, manual clause alignment is per-formed.
Tables 1 and 2 present the number of sen-tences and clauses, respectively, in Bulgarian andEnglish with their average length in tokens (LS(t))and in characters (LS(ch)).LanguageSentencesnumber LS(t) LS(ch)Bulgarian 13,213 13.23 73.04English 13,896 13.57 69.21Total 27,109 ?
?Table 1: Number of sentences and their length.Different models of clause alignment reflect in-terlingual symmetry or assymetry, such as: 1:1 forequivalent clauses in both languages; 0:1 or 1:0 ifa clause in one of the languages is missing in theother; 1 : N and N : 1 (N > 1) in the cases of dif-ferent clause segmentation, when clauses contain thesame information; N : M (N,M > 1) in relativelyrare cases when the information is crossed among2http://opennlp.apache.org/index.html3http://mokk.bme.hu/resources/hunalign/106LanguageClausesnumber LS(t) LS(ch)Bulgarian 24,409 7.20 39.54English 28,949 6.57 33.22Total 53,358 ?
?Table 2: Number of clauses and their length.clauses.
The distribution of the models is given inTable 3.Model Frequency % of all0:1 553 2.531:0 412 1.881:1 17,708 80.881:2 2,055 9.391:3 309 1.411:4 98 0.452:1 588 2.692:2 81 0.372:3 15 0.073:1 31 0.143:2 7 0.03Table 3: Distribution of bead models in the manuallyaligned corpus.4.2 EvaluationThe precision is calculated as the number of trueconnections (between clauses in the two languages)divided by the number of the proposed connections,while the recall is the proportion of true connectionsto all connections in the corpus.
The connections ina bead are the Cartesian product of the clauses in thefirst and the second language.
The K : 0 and 0 : Kbead models are considered as K : 1 and 1 : K byadding a fake clause.The evaluation is performed both over the corpusas a whole and on each of the domain specific sub-corpora included in it.The evaluation of the clause alignment implemen-tation of the Gale-Church algorithm on the same cor-pus shows overall precision of 0.902, recall ?
0.891and F1 measure ?
0.897.
Although the originalGale-Church method performs very well in terms ofboth precision and recall, sentence alignment posesa greater challenge.
The explanation for this fact liesDomain Precision Recall F1Total 0.910 0.911 0.911Administrative 0.865 0.857 0.861Fiction 0.899 0.902 0.901News 0.933 0.946 0.940Science 0.874 0.852 0.862Subtitles 0.934 0.934 0.934Table 4: Performance of the flexible method.in the broader scope of variations of clause corre-spondences as compared to sentences.The bootstrapping method performs better in thetranslations with clause reordering.
An exampleis the administrative subcorpus where Gale-Churchgives precision/recall ?
81.5%/79.7% compared to86.6%/85.8% shown by the bootstrapping method.In the texts with less clause order asymmetries theresults are close.5 Application of clause alignment in SMTTypical Moses4 (Koehn et al, 2007) models are builton a large amount of parallel data aligned at the sen-tence level.
For the purposes of the present study aspecially designed parallel corpus is used.
The aimis to demonstrate the effect of using syntactically en-hanced parallel data (clause segmentation and align-ment, reordering of clauses, etc.
).A series of experiments with Moses is designedto demonstrate the effect of training data modifica-tion on the performance of the SMT system.
Thedifferent training datasets comprise the same sen-tences but differ in their syntactic representation.The baseline model is constructed on the basis ofaligned sentence pairs.
The first experiment is basedon aligned clauses rather than sentences.
The secondexperiment demonstrates the effect of reordering ofthe clauses within the source language sentences.The main purpose of the experiments is to demon-strate possible applications of the clause alignmentmethod for training an SMT system, enhanced withlinguistic information.5.1 Training corpusFor the demonstration purposes of the present studywe apply a small corpus of 27,408 aligned sen-4http://www.statmt.org/moses/107tence pairs (comprising 382,950 tokens in Bulgar-ian and 409,757 tokens in English) which is semi-automatically split into clauses and automaticallyaligned at clause level.
The current purposes of theresearch do not include the development of a fullSMT model but focus on the demonstration of theeffect of syntactical information on the performanceof the SMT system.
Thus, the size of the train-ing corpus is considered sufficient for demonstrationpurposes.
The parallel texts are extracted from sev-eral domains ?
Administrative, Fiction, News, Sci-ence, Subtitles.5.2 Test corpusThe test corpus compiled for the purposes of evalu-ation of the SMT performance is independently de-rived from the Bulgarian-English parallel corpus anddoes not overlap with the training corpus.
It how-ever, resembles its structure and contains texts fromthe same domains as the training data.
Table 5 givesthe number of tokens in the Bulgarian and in the En-glish part of the test corpus, with percent of tokensin the Bulgarian texts.Domain BG ENl % (BG)Administrative 36,042 35,185 21.10Fiction 34,518 38,723 20.21News 64,169 62,848 37.57Science 18,912 19,856 11.07Subtitles 17,147 18,951 10.04Total 170,788 175,563Table 5: Number of tokens in the test corpus.5.3 Baseline modelThe baseline model corresponds to the traditionalMoses trained models and is constructed fromaligned sentences in Bulgarian and English.
TheBLEU score for translation from Bulgarian into En-glish is 16.99 while for the reverse it is substantiallylower ?
15.23.
In the subsequent tests we observethe results for the Bulgarian-to-English translationonly.5.4 Clause level trained modelThe first experiment aims to demonstrate that train-ing of the model based on aligned clauses rather thansentences yields improvement.
The assumption isthat alignment at a sub-sentential level would im-prove word and phrase alignment precision by limit-ing the scope of occurrence of translational equiva-lents.
On the other hand, however, lower level align-ment reduces the number of aligned phrases.
Forthis purpose clauses are the optimal scope for align-ment as phrases rarely cross clause boundaries.The results of the clause level training show smallimprovement of 0.11 in the BLEU score from 16.99(baseline) to 17.10 for the Bulgarian-to-Englishtranslation.5.5 Reordering of clausesThe second experiment relies on reordering ofclauses within aligned sentences.
The experimentaims at showing that reordering improves perfor-mance of SMT system.A simple clause reordering task was carried outwithin the sentences on the parallel training cor-pus.
Clause reordering involves linear reordering ofclauses in the source language sentences to matchthe linear order of corresponding clauses in the tar-get language sentences.Reordering applies to cases where asymmetriesare present in the alignment i.e.
crossed connectionsbetween clauses, which is expected to vary acrosslanguages and domains.
This suggests that the pro-portion of the corpus affected by reordering also de-pends on the language and on the domain.
Based onan experiment with a smaller corpus, approximately7% of the Bulgarian sentences are affected by re-ordering when adjusted to the English sentences.The result is BLEU score of 17.12 compared to16.99 (baseline) which yields an improvement of0.13.5.6 AnalysisThe results obtained from the above two experi-ments show a small yet consistent improvement inthe BLEU score.
It shows a possibility to im-prove the results by applying parallel data enhancedby syntactic information, namely, aligned pairs atclause level, or sentences with reordered clauses.The data, however, are not sufficient to draw adefinite conclusion both on whether the improve-ment is stable and on which of the two methods ?108using clause aligned pairs or reordered sentences ?performs better.6 ConclusionsThe research done in the scope of this paper hasshown that, on the one hand, the Gale-Church al-gorithm is applicable for clause alignment.
The re-sults achieved by the bootstrapping method, on theother hand, show that clause alignment may be ap-propriately improved by means of similarity mea-surement especially for the domain dependent tasks?
particularly for the domains for which non-linearorder of the translated clauses is typical.
Exper-iments showed that especially for texts exhibitingalignment asymmetries our method for clause align-ment outperforms Gale-Church considerably.We applied automatic clause alignment for build-ing a Moses training dataset enhanced with syntac-tic information.
Two experiments were performed?
first, involving aligned clause pairs, and the sec-ond using clause reordering in the source languageassuming that the order of clauses in the target lan-guage defines relations specific for the particularlanguage.
The experiments suggest that the clausereordering might improve translation models.The series of experiments conducted with Mosesshowed possible applications of the clause align-ment method for training an SMT system, enhancedwith linguistic information.ReferencesSotiris Boutsis and Stelios Piperidis.
1998.
OK withalignment of sentences.
What about clauses?
Pro-ceedings of the Panhellenic Conference on New Infor-mation Technology (NIT98).
pp.
288?297.Sotiris Boutsis and Stelios Piperidis.
1998.
Aligningclauses in parallel texts.
Proceedings of the 3rd Con-ference on Empirical Methods in Natural LanguageProcessing (EMNLP 1998).
pp.
17?26.Peter F. Brown, John Cocke, Stephen A. Della Pietra,Vincent J. Della Pietra, Frederick Jelinek, Robert L.Mercer and Paul S. Roossin.
1990.
A statistical ap-proach to language translation.
Computational Lin-guistics, 16(2): 79?85.Kenneth Church.
1993.
Charalign: A program for align-ing parallel texts at the character level.
Proceedings ofthe 31st Annual Meeting of the Association for Com-putational Linguistics (ACL 1993).
pp.
1?8.Brooke Cowan, Ivona Kucerova?
and Michael Collins.2006.
A Discriminative Model for Tree-to-Tree Trans-lation.
Proceedings of the Conference on EmpiricalMethods in Natural Language Processing (EMNLP2006).
pp.
232?241.John DeNero and Dan Klein.
2008.
The Complexity ofPhrase Alignment Models.
Proceedings of the 46thAnnual Meeting of the Association for ComputationalLinguistics (ACL 2008), Short Paper Track.Stefan Evert.
2005.
The Statistics of Word Cooccur-rences: Word Pairs and Collocations.
Ph.D. thesis.
In-stitut fur maschinelle Sprachverarbeitung, Universityof Stuttgart.William A. Gale and Kenneth.
W. Church.
1993.A Program for Aligning Sentences in BilingualCorpora.
Computational Linguistics, 19(1): 75?102.
URL: http://acl.ldc.upenn.edu/J/J93/J93-1004.pdf.Chooi-Ling Goh, Takashi Onishi and Eiichiro Sumita.2011.
Rule-based Reordering Constraints for Phrase-based SMT.
Mikel L. Forcada, Heidi Depraetere,Vincent Vandeghinste (eds.)
Proceedings of the 15thConference of the European Association for MachineTranslation (EAMT 2011).
pp.
113?120.Mridul Gupta, Sanjika Hewavitharana and Stephan Vo-gel.
2011.
Extending a probabilistic phrase alignmentapproach for SMT.
Proceedings of the InternationalWorkshop on Spoken Language Translation (IWSLT2011).
pp.
175-182.Martin Kay and Martin Roscheisen.
1993.
Text trans-lation alignment.
Computational Linguistics, 19(1):121?142.Chunyu Kit, Jonathan J. Webster, King Kui Sin, HaihuaPan, Heng Li.
2004.
Clause Alignment for HongKong Legal Texts: A Lexical-based Approach.
Inter-national Journal of Corpus Linguistics, 9(1): 29?51.Philipp Koehn, Franz J. Och and Daniel Marcu.
2003.Statistical phrase-based translation.
Proceedings ofthe North American Chapter of the Association forComputational Linguistics (NAACL 2003).
pp.
48?54.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, Evan Herbst.
2007.
Moses: Open SourceToolkit for Statistical Machine Translation.
AnnualMeeting of the Association for Computational Linguis-tics (ACL), demonstration session.
Prague, Czech Re-public, June 2007.Svetla Koeva, Diana Blagoeva and Siya Kolkovska.2010.
Bulgarian National Corpus Project.
NicolettaCalzolari, Khalid Choukri, Bente Maegaard, JosephMariani, Jan Odijk, Stelios Piperidis, Mike Rosner,109Daniel Tapias (eds.)
Proceedings of the 7th conferenceon International Language Resources and Evaluation(LREC 2010).
pp.
3678?3684.Svetla Koeva and Angel Genov.
2011.
Bulgarian lan-guage processing chain.
Proceedings of Integration ofmultilingual resources and tools in Web applications.Workshop in conjunction with GSCL 2011, 26 Septem-ber 2011, University of Hamburg.
(to appear)Vladimir Levenshtein 1966.
Binary codes capable ofcorrecting deletions, insertions, and reversals.
SovietPhysics Doklady, 10. pp.
707?710.Chi-Ho Li, Minghui Li, Dongdong Zhang, Mu Li, MingZhou and Yi Guan.
2007.
A probabilistic approach tosyntax-based reordering for statistical machine trans-lation.
Proceedings of the 45rd Annual Meeting ofthe Association for Computational Linguistics (ACL2007).
pp.
720?727.Harris Papageorgiou 1997.
Clause recognition in theframework of alignment.
Ruslan Mitkov and NicolasNicolov, N.
(eds.)
Current Issues in Linguistic Theory,136: 417?425.
John Benjamins B.V.Stelios Piperidis, Harris Papageorgiou and Sotiris Bout-sis.
2000.
From sentences to words and clauses.Chapter 6.
Jean Veronis and Nancy Ide (eds.)
Paral-lel Text Processing: Alignment and Use of TranslationCorpora.
Text, Speech and Language Technology se-ries, 13: 117?137.Ananthakrishnan Ramanathan, Pushpak Bhattacharyya,Karthik Visweswariah, Kushal Ladha and AnkurGandhe.
2011.
Clause-Based Reordering Constraintsto Improve Statistical Machine Translation.
Proceed-ings of the 5th International Joint Conference on Nat-ural Language Processing (IJCNLP 2011).
pp.
1351?1355.Gerda Ruge.
1992.
Experiments on linguistically basedterm associations.
Information Processing & Manage-ment.
28(3):317-332.Hinrich Schu?tze.
1992.
Context Space.
Working Notesof the AAAI Fall Symposium on Probabilistic Ap-proaches to Natural Language.
pp.
113-120Katsuhito Sudoh, Kevin Duh, Hajime Tsukada, TsutomuHirao, Masaaki Nagata.
2010.
Divide and Trans-late: Improving Long Distance Reordering in Statis-tical Machine Translation.
Proceedings of the Joint5th Workshop on Statistical Machine Translation andMetricsMATR.
pp.
418?427.Daniel Varga, Laszlo Nemeth, Peter Halacsy, Andras Ko-rnai, Viktor Tron, Viktor Nagy.
2005.
Parallel cor-pora for medium density languages.
Proceedings ofthe RANLP 2005. pp.
590?596.110
