Segment Predictability as a Cue in Word Segmentation: Application toModern GreekC.
Anton RyttingDepartment of LinguisticsThe Ohio State UniversityColumbus, Ohio, U.S.A. 43201rytting@ling.ohio-state.eduAbstractSeveral computational simulations of howchildren solve the word segmentation problemhave been proposed, but most have beenapplied only to a limited number of languages.One model with some experimental supportuses distributional statistics of sound sequencepredictability (Saffran et al 1996).
However,the experimental design does not fully specifyhow predictability is best measured ormodeled in a simulation.
Saffran et al (1996)assume transitional probability, but Brent(1999a) claims mutual information (MI) ismore appropriate.
Both assume predictabilityis measured locally, relative to neighboringsegment-pairs.This paper replicates Brent?s (1999a) mutual-information model on a corpus of child-directed speech in Modern Greek, andintroduces a variant model using a globalthreshold.
Brent?s finding regarding thesuperiority of MI is confirmed; the relativeperformance of local comparisons and globalthresholds depends on the evaluation metric.1 IntroductionA substantial portion of research in childlanguage acquisition focuses on the wordsegmentation problem?how children learn toextract words (or word candidates) from acontinuous speech signal prior to having acquired asubstantial vocabulary.
While a number of robuststrategies have been proposed and tested forinfants learning English and a few other languages(discussed in Section 1.1), it is not clear whether orhow these apply to all or most languages.
Inaddition, experiments on infants often leaveundetermined many details of how particular cuesare actually used.
Computational simulations ofword segmentation have also focused mainly ondata from English corpora, and should also beextended to cover a broader range of the corporaavailable.The line of research proposed here is twofold: onthe one hand we wish to understand the nature ofthe cues present in Modern Greek, on the other wewish to establish a framework for orderlycomparison of word segmentation algorithmsacross the desired broad range of languages.Finite-state techniques, used by e.g., Belz (1998) inmodeling phonotactic constraints and syllablewithin various languages, provide onestraightforward way to formulate some of thesecomparisons, and may be useful in future testing ofmultiple cues.Previous research (Rytting, 2004) examined therole of utterance-boundary information in ModernGreek, implementing a variant of Aslin andcolleagues?
(1996) model within a finite-stateframework.
The present paper examines moreclosely the proposed cue of segment predictability.These two studies lay the groundwork forexamining the relative worth of various cues,separately and as an ensemble.1.1 Infant StudiesStudies of English-learning infants find theearliest evidence for word segmentation andacquisition between 6 and 7.5 months (Jusczyk andAslin, 1995) although many of the relevant cuesand strategies seem not to be learned until muchlater.Several types of information in the speech signalhave been identified as likely cues for infants,including lexical stress, co-articulation, andphonotactic constraints (see e.g., Johnson &Jusczyk, 2001 for a review).
In addition, certainheuristics using statistical patterns over (strings of)segments have also been shown to be helpful in theabsence of other cues.One of these (mentioned above) is extrapolationfrom the segmental context near utteranceboundaries to predict word boundaries (Aslin et al,1996).
Another proposed heuristic utilizes therelative predictability of the following segment orsyllable.
For example, Saffran et al (1996) haveconfirmed the usefulness of distributional cues for8-month-olds on artificially designed micro-Barcelona, July 2004Association for Computations LinguisticsACL Special Interest Group on Computational Phonology (SIGPHON)Proceedings of the Workshop of thelanguages?albeit with English-learning infantsonly.The exact details of how infants use these cuesare unknown, since the patterns in their stimuli fitseveral distinct models (see Section 1.2).
Onlyfurther research will tell how and to what degreethese strategies are actually useful in the context ofnatural language-learning settings?particularly fora broad range of languages.
However, what is notin doubt is that infants are sensitive to the cues inquestion, and that this sensitivity begins wellbefore the infant has acquired a large vocabulary.1.2 Implementations and AmbiguitiesWhile the infant studies discussed above focusprimarily on the properties of particular cues,computational studies of word-segmentation mustalso choose between various implementations,which further complicates comparisons.
Severalmodels (e.g., Batchelder, 2002; Brent?s (1999a)MBDP-1 model; Davis, 2000; de Marcken, 1996;Olivier, 1968) simultaneously address the questionof vocabulary acquisition, using previously learnedword-candidates to bootstrap later segmentations.
(It is beyond the scope of this paper to discussthese in detail; see Brent 1999a,b for a review.
)Other models do not accumulate a storedvocabulary, but instead rely on the degree ofpredictability of the next syllable (e.g., Saffran etal., 1996) or segment (e.g., Christiansen et al,1998).
The intuition here, first articulated byHarris (1954), is that word boundaries are markedby a spike in unpredictability of the followingphoneme.
The results from Saffran et al (1996)show that English-learning infants do respond toareas of unpredictability; however, it is not clearfrom the experiment how this unpredictability isbest measured.
Two specific ambiguities inmeasuring (un)predictability are examined here.Brent (1999a) points out one type of ambiguity,namely that Saffran and colleagues?
(1996) resultscan be modeled as favoring word-breaks at pointsof either low transitional probability or low mutualinformation.
Brent reports results for modelsrelying on each of these measures.
It should benoted that these models are not the main focus ofhis paper, but provided for illustrative purposes;nevertheless, these models provide the bestcomparison to Saffran and colleagues?
experiment,and may be regarded as an implementation of thesame.Brent (1999a) compares these two models interms of word tokens correctly segmented (seeSection 3 for exact criteria), reportingapproximately 40% precision and 45% recall fortransitional probability (TP) and 50% precision and53% recall for mutual information (MI) on the first1000 utterances of his corpus (with improvementsgiven larger corpora).
Indeed, their performanceon word tokens is surpassed only by Brent?s mainmodel (MBDP-1), which seems to have about 73%precision and 67% recall for the same range.1Another question which Saffran et al (1996)leave unanswered is whether the segmentationdepends on local or global comparisons ofpredictability.
Saffran et al assume implicitly, andBrent (1999a) explicitly, that the propercomparison is local?in Brent, dependent solely onthe adjacent pairs of segments.
However,predictability measures for segmental bigrams(whether TP or MI) may be compared in anynumber of ways.
One straightforward alternativeto the local comparison is to compare thepredictability measures compare to some globalthreshold.
Indeed, Aslin et al (1996) andChristiansen et al (1998) simply assumed themean activation level as a global activationthreshold within their neural network framework.21.3 Global and Local ComparisonsThe global comparison, taken on its own, seemsa rather simplistic and inflexible heuristic: for anypair of phonemes xy, either a word boundary isalways hypothesized between x and y, or it neveris.
Clearly, there are many cases where x and ysometimes straddle a word boundary andsometimes do not.
The heuristic also takes noaccount of lengths of possible words.
However,the local comparison may take length into accounttoo much, disallowing words of certain lengths.
Inorder to see that, we must examine Brent?s (1999a)suggested implementation of Saffran et al (1996)more closely.In the local comparison, given some string?wxyz?, in order for a word boundary to beinserted between x and y, the predictabilitymeasure for xy must be lower than both that of wxand of yz.
It follows that neither wx nor yz canhave word boundaries between them, since theycannot simultaneously have a lower predictabilitymeasure than xy.
This means that, within anutterance, word boundaries must have at least twosegments between them, so this heuristic will notcorrectly segment utterance-internal one-phoneme1 The specific percentages are not reported in the text,but have been read off his graph.
Brent does not reportprecision or recall for utterance boundaries; thosepercentages would undoubtedly be higher.2 These methodologies did not ignore localinformation, but encoded it within the feature vector.However, Rytting (2004) showed that this extra context,while certainly helpful, is not strictly necessary in theGreek corpus under question.
A context of just onephoneme yielded better-than-chance results.words.3  Granted, only a few one-phoneme wordtypes exist in either English or Greek (or otherlanguages).
However, these words are oftenfunction words and so are less likely to appear atedges of utterances (e.g., ends of utterances forarticles and prepositions; beginnings for postposedelements).
Neither Brent?s (1999a)implementation of Saffran?s et al (1996) heuristicnor Aslin?s et al (1996) utterance-boundaryheuristic can explain how these might be learned.Brent (1999a) himself points out another length-related limitation?namely, the relative difficultythat the ?local comparison?
heuristic has insegmenting learning longer words.
The bigram MIfrequencies may be most strongly influenced by?and thus as an aggregate largely encode?the mostfrequent, shorter words.
Longer words cannot bememorized in this representation (althoughcommon ends of words such as prefixes andsuffixes might be).In order to test for this, Brent proposes thatprecision for word types (which he calls ?lexiconprecision?)
be measured as well as for wordtokens.
While the word-token metric emphasizesthe correct segmentation of frequent words, theword-type metric does not share this bias.
Brentdefines this metric as follows:  ?After each block[of 500 utterances], each word type that thealgorithm produced was labeled a true positive ifthat word type had occurred anywhere in theportion of the corpus processed so far; otherwise itis labeled a false positive.?
Measured this way, MIyields a word type precision of only about 27%;transitional probability yields a precision ofapproximately 24% for the first 1000 utterances,compared to 42% for MBDP-1.
He does notmeasure word type recall.This same limitation in finding longer, lessfrequent types may apply to comparisons against aglobal threshold as well.
This is also in need oftesting.
It seems that both global and localcomparisons, used on their own as sole or decisiveheuristics, may have serious limitations.
It is notclear a priori which limitation is most serious;hence both comparisons are tested here.2 Constructing a Finite-State Model2.1 Outline of current researchWhile in its general approach the study reportedhere replicates the mutual-information andtransitional-probability models in Brent (1999a), it3 At the edges of utterances, this restriction will notapply, since word boundaries are automatically insertedat utterance boundaries, while still allowing thepossibility of a boundary insertion at the next position.differs slightly in the details of their use.
First,whereas Brent dynamically updated his measuresover a single corpus, and thus blurred the linebetween training and testing data, our model pre-compiles statistics for each distinct bigram-typeoffline, over a separate training corpus.4  Secondly,we compare the use of a global threshold(described in more detail in Section 2.3, below) toBrent?s (1999a) use of the local context (asdescribed in Section 1.3 above).Like (Brent, 1999a), but unlike Saffran et al(1996), our model focuses on pairs of segments,not on pairs of syllables.
While Modern Greeksyllabic structure is not as complicated asEnglish?s, it is still more complicated than the CVstructure assumed in Saffran et al (1996); hence,access to syllabification cannot be assumed.52.2 Corpus DataIn addition to the technical differences discussedabove, this replication breaks new ground in termsof the language from which the training and testcorpora are drawn.
Modern Greek differs fromEnglish in having only five vowels, generallysimpler syllable structures, and a substantialamount of inflectional morphology, particularly atthe ends of words.
It also contains not onlypreposed function words (e.g., determiners) butpostposed ones as well, such as the possessivepronoun, which cannot appear utterance-initially.For an in-depth discussion of Modern Greek, see(Holton et al, 1997).
While it is not anticipatedthat Modern Greek will be substantially morechallenging to segment than English, the choicedoes serve as an additional check on currentassumptions.The Stephany corpus (Stephany, 1995) is adatabase of conversations between children andcaretakers, broadly transcribed, currently with nonotations for lexical stress, included as part of theCHILDES database (MacWhinney, 2000).
Inorder to preserve adequate unseen data for futuresimulations and experiments, and also to use datamost closely approximating children of a very4 While this difference is not intended as a strongtheoretical claim, it can be seen as reflecting the factthat even before infants seem to begin the wordsegmentation process, they have already been exposedto a substantial amount of linguistic material.
However,it is not anticipated to affect the general pattern ofresults.5 Furthermore, if Brent?s ?local comparison?implementation were based on syllables to more closelycoincide with Saffran?s et al (1996) experiment (notsomething Brent ever suggests), it would fail to detectany one-syllable words, clearly problematic for bothGreek and English, and many languages besides.young age, files from the youngest child only wereused in this study.
However, since the heuristicsand cues used are very simple compared tovocabulary-learning models such as Brent?sMDLP-1, it is anticipated that they will requirerelatively little context, and so the small size of thetraining and testing corpora will not adverselyeffect the results to a great degree.As in other studies, only adult input was used fortraining and testing.
In addition, non-segmentalinformation such as punctuation, dysfluencies,parenthetical references to real-world objects, etc.were removed.
Spaces were taken to representword boundaries without comment or correction;however, it is worth noting that the transcriberssometimes departed from standard orthographicpractice when transcribing certain types of word-clitic combinations.
The text also contains asignificant number of unrealized vowels, such as[ap] for /apo/ ?from?, or [in] or even [n] for /ine/?is?.
Such variation was not regularized, buttreated as part of the learning task.The training corpus contains 367 utterancetokens with a total of 1066 word tokens (319types).
Whereas the average number of words perutterance (2.9) is almost identical to that in theKorman (1984) corpus used by Christiansen et al(1998), utterances and words were slightly longerin terms of phonemes (12.8 and 4.4 phonemesrespectively, compared to 9.0 and 3.0 in Korman).The test corpus consists of 373 utterance tokenswith a total of 980 words (306 types).
Allutterances were uttered by adults to the same childas in the training corpus.
As with the trainingcorpus, dysfluencies, missing words, or otherirregularities were removed; the word boundarieswere kept as given by the annotators, even whenthis disagreed with standard orthographic wordbreaks.2.3 Model DesignUsed as a solitary cue (as it is in the tests runhere), comparison against a global threshold maybe implemented within the same framework asBrent?s (1999) TP and MI heuristics.
However, itmay be implemented within a finite-stateframework as well, with equivalent behavior.
Thissection will describe how the ?global comparison?heuristic is modeled within a finite-stateframework.While such an implementation is not technicallynecessary here, one advantage of the finite-stateframework is the compositionality of finite statemachines, which allows for later composition ofthis approach with other heuristics depending onother cues, analogous to Christiansen et al (1998).Since the finite-state framework selects the bestpath over the whole utterance, it also allows foroptimization over a sequence of decisions, ratherthan optimizing each local decision separately.6Unlike Belz (1998), where the actual FSMstructure (including classes of phonemes that couldbe group onto one arc) was learned, here thestructure of each FSM is determined in advance.Only the weight on each arc is derived from data.No attempt is made to combine phonemes toproduce more minimal FSMs; each phoneme (andphoneme-pair) is modeled separately.Like Brent (1999a) and indeed most models inthe literature, this model assumes (for sake ofconvenience and simplicity) that the child hearseach segment produced within an utterance withouterror.
This assumption translates into the finite-state domain as a simple acceptor (or equivalently,an identity transducer) over the segment sequencefor a given utterance.7Word boundaries are inserted by means of atransducer that computes the cost of wordboundary insertion from the predictability scores.In the MI model, the cost of inserting a wordboundary is proportional to the mutualinformation.
For ease in modeling, this wasrepresented with a finite state transducer with twopaths between every pair of phonemes (x,y), withzero-counts modeled with a maximum weight of99.
The direct path, representing a path with noword boundary inserted, costs ?MI(x,y), which ispositive for bigrams of low predictability (negativeMI), where word boundaries are more likely.
Theother path, representing a word boundary insertion,carries the cost of the global threshold, in this casearbitrarily set to zero (although it could beoptimized with held-out data).
A small subset ofthe resulting FST, representing the connectionsover the alphabet {ab} is illustrated in Figure 1,below:6 See Rabiner (1989) for a discussion of choosingoptimization criteria.
It is worth noting that thisdistinction does not come into play in the one-cuemodel reported here, as all decisions are modeled asindependent of one another.
However, it is expected totake on some importance in models combining multiplecues, such as those proposed in Section 4 of this paper.7 While modeling the mishearing of segments wouldbe more realistic and highly interesting, it is beyond thescope of this study.
However, a weighted transducerrepresenting a segmental confusion matrix could inprinciple replace the current identity transducer, withoutdisrupting the general framework of the model.Figure 1: The MI model over the alphabet {ab}The best (least-cost) path over this subset modelinserts boundaries between two adjacent a?s andtwo adjacent b?s, but not between ab or ba; thusthe (non-Greek) string ?ababaabbaaa?
would besegmented ?ababa#ab#ba#a#a?
by the FSM.The FSM for transitional probability has thesame structure as that of MI, but with differentweights on each path.
For each pair of phonemesxy, the cost for the direct path from x to y is?log(P(y|x)).
The global threshold cost ofinserting a word boundary was set (again,arbitrarily) as the negative log of the mean of allTP values.
In the two-phoneme subset (shown inFigure 2), the only change is that the directpathway from a to b is now more expensive thanthe threshold path, so the best path over the FSMwill insert word boundaries between a and b aswell.
Hence our example string ?ababaabbaaa?would be segmented ?a#ba#ba#a#b#ba#a#a?
bythe FSM.
(The stranded ?word?
#b# would ofcourse be an error, but this problem does not arisein actual Greek input, since two adjacent b?s, likeall geminate consonants, are ruled out by Greekphonotactics.
)Figure 2: The TP model over the alphabet {ab}During testing each FST model was composed(separately) with the segment identity transducerfor the utterance under consideration.
A shortsample section of such a composition, with the bestpath in bold, is shown in Figure 3.Figure 3: A section of the composition of the MImodel and an utterance acceptorThe output projection of the best path from theresulting FST was converted back into text andcompared to the text of the original utterance.These compositions, best-path projections, andconversions were performed using the AT&T finitestate toolkit (Mohri et al, 1998).82.4 A Concrete ExampleTake, for example, an utterance from the testcorpus /tora#Telis#na#aniksume#afto/ ?now youwant us to open this.?
The mutual information andtransitional probability figures for this utteranceare given in Table 1.Context PredictabilityLeft Right MI TP# t 0.000 3.219t o ?1.661 0.781o r ?1.018 2.350r a ?0.800 1.113a T 1.824 6.375T e ?0.744 1.540e l ?0.225 3.059l i ?0.903 1.197i s ?0.491 2.382s n 1.555 4.317n a ?0.300 1.613a a 2.516 4.429a n ?0.339 2.424n i ?0.071 2.029i k ?0.337 2.633k s ?0.444 2.428s u ?0.172 3.219u m ?1.387 2.413m e ?1.230 1.055e a 1.095 3.008a f ?1.473 2.525f t ?2.068 0.484t o ?1.661 0.781o # 0.000 3.219Table 1: MI and TP values for bigrams in the testutterance /tora#Telis#na#aniksume#afto/.
Valuesabove threshold are bold; local maxima italicized.In this example, the correct boundaries fallbetween the pairs (a,T), (s,n), (a,a), and (e,a).
Boththe mutual information and the transitionalprobability for the first three of these pairs areabove the global mean, so word boundaries areposited under both global models.9  (Since each ofthese is also a local maximum, the local modelsalso posit boundaries between these three pairs.
)The pair (e,a) is above threshold for MI but not for8 FSM Library Version 3.7, freely available fromhttp://www.research.att.com/sw/tools/fsm/9 Since all values are given in terms of negative MIand negative log probability, high values for bothmeasures indicate relatively improbable pairings.TP, so the global TP model fails to posit aboundary here.
Finally, the two local models posita number of spurious boundaries at the other localmaxima, shown by the italic numbers in the table.The resulting predictions for each model are:Global MI: #tora#Telis#na#aniksume#afto#Global TP: #tora#Telis#na#aniksumeafto#Local MI: #tora#Te#lis#na#an#iks#ume#afto#Local TP: #to#ra#Te#lis#na#ani#ks#ume#afto#3 ResultsThe four model variants (global MI, global TP,local MI, and local TP) were each evaluated onthree metrics: word boundaries, word tokens, andword types.
Note that the first metric reported,simple boundary placement, considers onlyutterance-internal word-boundaries, rather thanincluding those word boundaries which aredetected ?for free?
by virtue of being utterance-boundaries also.
This boundary measure may bemore conservative than that reported by otherauthors, but is easily convertible into other metrics.The second metric, the percentage of wordtokens detected, is the same as Brent (1999a).
Inorder for a word to be counted as correctly found,three conditions must be met: (a) the word?sbeginning (left boundary) is correctly detected, (b)the word?s ending (right boundary) is correctlydetected, and (c) these two are consecutive (i.e., nofalse boundaries are posited within the word).The last metric (word type) is slightly moreconservative than Brent?s (1999a) in that the wordtype must have been actually spoken in the sameutterance (not the same block of 500 utterances) inwhich it was detected to count as a match.
Thislessens the possibility that a mismatch that happensto be segmentally identical to an actual word (butwhose semantic context may not be conducive tolearning its correct meaning) is counted as a match.However, this situation is presumably rather rare.Tables 2 and 3 present the results over the testset for both the global and the local comparisons ofthe predictability statistics proposed by Saffran etal.
(1996) and Brent (1999a).Table 2: Global Comparison: FST best pathswith bigrams compared to a global threshold onlyLocalComparisonBound-ariesWordTokensWordTypesPrecision 42.0% 31.5% 20.1%Recall 62.6% 41.1% 27.8%MIF-Score 50.3% 35.7% 23.4%Precision 41.5% 28.0% 20.2%Recall 74.1% 41.6% 22.9%TPF-Score 53.2% 33.5% 21.4%Table 3: Local Comparison: Replication of Brent(1999a); each bigram compared to both neighbors4 Conclusion4.1 Comparing the Four VariantsThe findings here confirm Brent?s (1999a)contention that mutual information is a bettermeasure of predictability than is transitionalprobability?at least for the task of identifyingwords, not just boundaries.
This is particularlytrue in the global comparison.
Transitionalprobability finds more word boundaries in the?local comparison?
model, but this does not carryover to the task of pulling out the word themselves,which is arguably the infant?s main concern.
Thisresult should be kept in mind when interpreting orreplicating (Saffran et al, 1996) or similar studies.While Brent?s ?local comparison?
heuristic wasunable to pull out one-phoneme-long words, aspredicted above, this did not adversely affect it asmuch as anticipated.
On the contrary, both thelocal and global comparison heuristics tended topostulate too many word boundaries, as Brent hadobserved.
This is not necessarily a bad thing forinfants, for several reasons.First, infants may have a preference for findingshort words, since these will presumably be easierto remember and learn, particularly if the child?sphonetic memory is limited.
Second, it is probablyeasier to reject a hypothesized word (for example,on failing to find a consistent semantic cue for it)than to obtain a word not correctly segmented;hence false positives are less of a problem thanfalse negatives for the child.
Third and mostimportantly, this cue is not likely to operate on itsown, but rather as one among many contributingcues.
Other cues may act as filters on theboundaries suggested by this cue.
One example ofthis is the distribution of segments before utteranceedges, as used by e.g., Aslin et al (1996) andChristiansen et al (1998) which indicate the set ofpossible word-final segments in the language.GlobalComparisonBound-ariesWordTokensWordTypesPrecision 43.9% 30.8% 22.3%Recall 54.4% 35.3% 29.7%MIF-Score 48.6% 32.9% 25.5%Precision 40.4% 28.4% 20.0%Recall 41.7% 29.0% 28.4%TPF-Score 41.0% 28.7% 23.5%However, as far as these results go, the wordtype metric shows that the finite-state model usinga global threshold suffered slightly less from thisproblem than the local comparison model.
For theMI variants, both recall and precision for wordtype were about 2% higher on the global thresholdvariant.
For transitional probability, the precisionof the local and global models was roughly equal,but recall for the global comparison model was5.5% higher.
Not only were the global modelsbetter at pulling out a variety of words, but theyalso managed to learn longer ones (especially theglobal TP variant), including a few four-syllablewords.
The local model learned no four-syllablewords, and relatively few three-syllable words.The mixed nature of these results suggests thatevaluation depends fairly crucially on whatperformance metric needs to be optimized.
Thisdemands stronger prior hypotheses regarding theprocess and needed input of a vocabulary-acquiring child.
However, it cannot be blindlyassumed that children are selecting low points overas short a window as Brent?s (1999a) MI and TPmodels suggest.
Quite possibly the best modelwould involve either a hybrid of local and globalcomparisons, or a longer window, or even a?gradient?
window where far neighbors count lessthan near ones in a computed average.However, further speculation on point this ofless importance than considering how this cueinteracts with others known experimentally to besalient to infants.
Christiansen et al (1998) andJohnson and Jusczyk (2001) have already begansimulating and testing these interactions inEnglish.
However, more work needs to be done tounderstand better the nature of these interactionscross-linguistically.4.2 Further ResearchAs mentioned above, one obvious area for futureresearch is the interaction between predictabilitycues like MI and utterance-final information; thisis one of the cue combinations explored inChristiansen et al (1998) in English.
Previousresearch (Rytting, 2004) examined the role ofutterance-final information in Greek, and foundthat this cue performs better than chance on itsown.
However, it seems that utterance-finalinformation would be more useful as a filter on theheuristics explored here to restrain them fromoversegmenting the utterance.
Since nearly allGreek words end in /a/, /e/, /i/, /o/, /u/, /n/, or /s/,just restricting word boundaries to positions afterthese seven phonemes boosts boundary precisionconsiderably with little effect on recall.1010 Naturally, in unrestricted speech the characteristicsPreliminary testing suggests that this filter boostsboth precision and recall at the word level.However, a model that incorporates the likelihoodsof word boundaries after each of these finalsegments, properly weighted, may be even morehelpful than this simple, unweighted filter.Another fruitful direction is the exploration ofprosodic information such as lexical stress.
Withthe exception of a certain class of clitic groups,Greek words have at most one stress.
Hence, atleast one word boundary must occur between twostressed vowels.
Relations between stress and thebeginnings and endings of words, while notpredicted to be as robust a cue as in English (seee.g., Cutler, 1996), should also provide usefulinformation, both alone and in combination withsegmental cues.Finally, the relationship between these more?static?
cues and the cues that emerge asvocabulary begins to be acquired (as in Brent?smain MBDP-1 model and others discussed above)seems not to have received much attention in theliterature.
As vocabulary is learned, it can helpbootstrap these cues by augmenting heuristic cueswith actual probabilities derived from its parses.Hence, the combination of e.g., MLDP-1 and theseheuristics may prove more powerful than eitherapproach alone.5 AcknowledgementsThis material is based upon work supportedunder a National Science Foundation GraduateResearch Fellowship.
Sincere thanks go to theNSF for their financial support, and to Chris Brew,Eric Fosler-Lussier, Brian Joseph, members of thecomputational linguistics and phonologydiscussion groups at the Ohio State University, andto anonymous reviewers of previous versions ofthis paper for their helpful comments andencouragement.ReferencesRichard N. Aslin, Julide Z. Woodward, Nicholas P.LaMendola, and Thomas G. Bever.
1996.Models of word segmentation in fluent maternalspeech to infants.
In Signal to syntax, James L.Morgan and Katherine Demuth, ed., pages 117-of word boundaries diverge from those of utteranceboundaries.
For example, final vowels may delete fromutterance-medial words; instances such as [in] for /ine/?is?
and [ap] for /apo/ ?from?
were already mentioned.However, if we assume that the canonical forms of thesewords occur frequently enough to be acquired normally,then knowledge of these canonical forms may assist theacquisition of variant forms (as well as the phrasalphonological processes that give rise to them) later on.134, Lawrence Erlbaum Associates, Mahwah,New Jersey.Elanor Olds Batchelder.
2002.
Bootstrapping thelexicon: A computational model of infant speechsegmentation.
Cognition, 83:167-206.Anja Belz.
1998.
An Approach to the AutomaticAcquisition of Phonotactic Constraints.
InProceedings of SIGPHON ?98: The Computationof Phonological Constraints, T. Mark Ellison,ed., pages 35-44Michael R. Brent.
1999a.
An efficient,probabilistically sound algorithm forsegmentation and word discovery.
MachineLearning, 34:71-105.Michael R. Brent.
1999b.
Speech segmentation andword discovery: A computational perspective.Trends in Cognitive Sciences, 3(8):294-301.Morton H. Christiansen, Joseph Allen, and Mark S.Seidenberg.
1998.
Learning to segment speechusing multiple cues: A connectionist model.Language and Cognitive Processes, 13(2/3):221-268.Anne Cutler.
1996.
Prosody and the wordboundary problem.
In Signal to syntax, James L.Morgan and Katherine Demuth, ed., pages 87-100, Lawrence Erlbaum Associates, Mahwah,New Jersey.Matt H. Davis.
2000.
Lexical segmentation inspoken word recognition.
Unpublished PhDthesis, Birkbeck College, University of London.Available: http://www.mrc-cbu.cam.ac.uk/personal/matt.davis/thesis/index.htmlCarl G. de Marcken.
1996.
Unsupervised languageacquisition.
PhD dissertation, MIT, Cambridge,MA.
Available: http://xxx.lanl.gov/abs/cmp-lg/9611002Zelig S. Harris.
1954.
Distributional structure.Word, 10:146-162.David Holton, Peter Mackridge and IrenePhilippaki-Warburton.
1997.
Greek:  AComprehensive Grammar of the ModernLanguage, Routledge, London and New York.Elizabeth K. Johnson and Peter W. Jusczyk.
2001.Word segmentation by 8-month-olds: whenspeech cues count more than statistics.
Journalof Memory and Language, 44 (4), 548 567.Myron Korman.
1984.
Adaptive aspects ofmaternal vocalizations in differing contexts atten weeks.
First Language, 5:44-45.Brian MacWhinney.
2000.
The CHILDES project:Tools for analyzing talk.
Third Edition.Lawrence Erlbaum Associates, Mahwah, NewJersey.Mehryar Mohri, Fernando C. N. Pereira, andMichael Riley.
1998.
A Rational Design for aWeighted Finite-State Transducer Library.Lecture Notes in Computer Science, 1436.D.
C. Olivier.
1968.
Stochastic grammars andlanguage acquisition mechanisms.
PhDdissertation, Harvard University, Cambridge,Massachusetts.Lawrence R. Rabiner.
1989.
A tutorial on hiddenMarkov models and selected applications inspeech recognition.
Proceedings of the IEEE,77:2, pages 257-285.C.
Anton Rytting.
2004.
Greek word segmentationusing minimal information.
In Proceedings ofthe Student Research Workshop at HLT/NAACL2004, pages 207-212, Association forComputational Linguistics, Boston, Massa-chusetts.
Available: http://acl.ldc.upenn.edu/hlt-naacl2004/studws/pdf/sw-8.pdfJenny R. Saffran, Richard N. Aslin and Elissa L.Newport.
1996.
Statistical learning by 8-month-old infants.
Science, 274, 1926-1928.Ursula Stephany.
1995.
The acquisition of Greek.In The crosslinguistic study of languageacquisition.
D. I. Slobin, ed., Vol.
4.
