Research on Architectures for Integrated Speech/LanguageSystems in VerbmobilGfinther GSrz~ Marcus Kesseler, JSrg Spilker, Hans WeberUniversity of Erbmgen-NfirnbergIMMD (Computer Science) VIII --- Artificial Inl0elligenceAm Weichselgarten 9D-91058 ERLAN(\]ENEmaih {goerz, kesseler, spilker, weber}Oinformat ik.
uni-erl angen, deAbstractThe German joint research project Verb-mobil (VM) aims at the deveh)pmentof a speech to speech translation sys-tem.
This paper reports on researchdone in our group which belongs to Verb-mobil's subprojeet on system architec-tures (TP15).
Our specific research areasare the construction of parsers for spon-taneous peech, investigations in the par-allelization of parsing and to contributeto the development of a flexible com-munication architecture with distributedcontrol.1 IntroductionThe German joint research project Verbmobil(VM) 1 aims at the development of a speech tospeech translation system.
This paper reportson research done in our group which belongs toVcrbmobil's subproject on system architectures(TP15).
The task of this subproject is to providebasic research results on incremental and inter-active system architectures for the VM researchprototype and to demonstrate their feasibility inthe prototypical INTARC system.
Our specificresearch areas are the construction of parsers forspontaneous speech, investigations in the paral-lelization of parsing and to contribute to the de-velopment of a flexible communication architec-ture with distributed control.
The paper is or-ganized as follows: Section 2 reports on the de-sign and implementation of an incremental in-teractive speech parser which integrates tatisticsi1This work was flmded by the German FederalMirfistry for Researdl and Tedmology (BMFT) inthe framework of the Verbmobil Project under GrantBMFT 01 IV 101 H / 9.
The responsibility for thecontents of this study lies with the authors.with a chart-parser einploying a unification gram-mar (UG) formalism.
Furthermore, results of ex-periments on the interaction between the parserand a speech recognizer using expectations, are re-ported.
In section 3 we present experiences witha parallel version of the parser.
Section 4 dealswith distributed control in modular Natural Lan-guage/Speech (NLSP) systems.2 Design and Implementation ofIncremental Interactive SpeechParsersIn a Left Right Incremental architecture (LRI),higher level modules can work in parallel withlower level modules.
The obvious benefits of suchan arrangement are twofold: The system does nothave to wait for a speaker to stop talking and top-down constraints from higher level to lower levelmodules can be used easily. '
lb achieve LR!
behav-ior the singular modules must fulfil\] the followingrequirements:Processing proceeds incrementally along thetime axis ("left to right").Pieces of output have to be transferred to thenext module as soon as possible.So far in INTARC-1.3 we have achieved an LRIstyle coupling of ibur different modules: Wordrecognition module, syntactic parser, semanticmodule and prosodic boundary module.
Our wordrecognition module is a modified Viterbi decoder,where two changes in the algorithm design weremade: We use only the forward search pass, andwhenever a final ttMM state is reached for an ac-tive word model, a corresponding word hypothesisis sent to the parser.
Itence backward search be-comes a part of the parsing algorithm.
The LRIparsing algorithm is a modified active chart parserwith an agenda driven control mechanism.
Thechart vertices correspond to the .frames of the sig-nal representation.
Edges correspond to Word orphrase hypotheses, being partial in the case of ac-484tive edges.
A parsing cycle corresponds to a newtime point related to the utterance, in every cyclea new vertex is created and new word hypothesesending at that time point are read and insertedinto the chart.
In one cycle, a ba(:kwar(| searchis performed to the beginning of the utterance orto some designated time point in the past con~stitnting a starting point for grammatical analy-sis.
Search is guided by a weighted linear com-bination of acoustic score, bigram score, prosodyscore, grammar derivation seore and grammaticalparsability.
The search prodecure is a beam searchimplemented asan agenda ccess mechanism.
Thegrammar is a probabilistic typed UG with sepa-rate rules for pauses and other spontanous speechphelnonmua.2.1 Basic Ob jec tsIn the h)llowing we use record notation to referto subcoml)oncnts of an object.
A chart ver-tex Vt corresponds to frame number t. Verticeshave four lists with pointers to edges ending inand starting in thai; vertex: inactive-out, inactive~in, active-out and active-out.
A word hypothe-sis W is a quadruple (from, to, key, score) withJ}vm and to being the start and end frames of W.W.Key is the name of the lexical entry of W andW.score is the acoustic score of W for the framesspanned, given by a corresponding HMM acousticword model.
An edge i',' consists of flora, the startvertex and to, a list of end vertices.
Note that af-ter a Viterbi forward pass identical word hypothe-ses do always come in sequence, differing only inending time.
E.actual is the last vertex addedto t?to in an operation.
Those "families" of hy-potheses are represented as one edge with a set ofend vertices.
E.words keeps the covered string ofword hypotheses while SCORE is a record keepingscore components.
Besides that an edge consistsof a grammar ule E.rule and F,.next, a pointerto some element of the right hand side of l?ruleor NIL.
As in standard active chart parsing anedge is passive, if E.ncxt = nil, otherwise it isactive.
E.eat points to the left hand side of thegrammar rule.
SCORE is a record with entries forinside and outside probabilities given to an edgeby acoustic, bigram, prosody and grammar model:Ins ide-X Model scores for the spanned portionof an edge.Outs ide -X  Optimistic estimates for the portionfi'om vertex 0 to the beginning of an edge.For every vertex we keep a best first store of scorededge pairs.
We (:all that store Agenda/ in cycle i.2.2 Bas ic  Operat ions'I'here are tive basic operations to detine the op-erations of the parsing algorithm.
The two op-erations Combine and Seek Down are similar tothe well known Earley algorithm operations Com-pleter arm Predictor.
Furthermore, there are twooperations to insert new word hypotheses, Insertand Inherit.
All these operations can create newedges, so operations to calculate new scores fromold ones are attached to them.
hi order to im-plement our t)eam search method appropriatelybut sinq)ly, we define an operation Agenda-Pu~q~ ,which selects pairs of active and passive edges tobe prmn;d or to be processed in the future.
TheCt (, notation for l)asic operations are given in -' ,' 'simplicity.2.2.1 CombineFor a t)air of active and passive edges (A, l),if A.next  = I.cat and L f ivm ~ A.to,  insert edgeti with l','.rule - A.rule, E.cat :-- A.eat, E.nexl --:shif l (A.uext),  l?fl~)m.-= A.fl'o,n, l?to = A.to.For X = Bigram, Grammar and Prosody:t?Outs ide-X = A.Outs ide-X + I .
lns ide-X +7'tans(X, A, 1)l?
lnsidc-X = A .
lns ide-X  4- 1.1nside-X 4-7'rans(X,A,1)I"or X = Acoustic:E. Outside-X = A. Oulside-X\[ l .
from\] @ L lnsi&'- X"Frans(X,A, I)l?1nsidc-X = A. lns idc-X\[1. f lvm\]  (t) L Ins ide-XTrans(X,A, l )'l)he operator ct) performs an addition o \ [a  nun>her to every element of a set.
Trans(X,A , l )  is thespecilic transition penalty a model will give to twoedges.
In the ctLse of acoustic scores, the penMty isalways zero and can be neglected.
In the.
bigramc~use it will be the transition from the last wordcovered by A to the tirst word covered by B.2.2.2 Seek  DownWhenever an active edge A is inserted, insert anedge E for every rule 1~ such that A.next  - E.cat,I','.
rule = If, F,.f lvm - A. actual, t3.
to = {A. actual}?
For X --- Acoustic, Prosody and l)igraln:E. lnside-X = 0I?
Outside-X = A. Outside-XFor X == Grammar:1?
lnside-X = grammar score of  IIl?Outs ide-X = A.Outs ide-X + 7~rans(X,A,l';) +I~.inside-X.
This reeursive operation of introduc-ing new active edges is precompiled in our parserand extremely etlicient.4852.2.3 Inser tFor a new word hypothesis W = (a,i, key, score)such that no W' = (a,i-i,key, score') exists, in-sert an edge E with E.rule = lex(key), E.cat =lex(key), E.from = Va, E.to = {~} and for X =Acoustic:E.Inside-X = E. Outside-X = { (i, score)},for X = Prosody and Bigram:E.Inside-X = E.Outside-X = O,for X = Grammar E.Inside-X = E.Outside-X =grammar score of lex(keg).2.2.4 InheritFor a new word hypothesis W = (a,i, key, score)such that a W' = (a,i-l,key, score') exists:For all E in Vi_l.inactive-in or Vi_l.active-in: If last(E.words) = key then add {~} toE.to, add (i,E.Inside-Acoustic\[i-l\]- score' +score) to E.Inside-Acoustic and add (i,E.Outside-Acoustic\[i-I\]- score' + score) to E.Outside-Acoustic.If E is active, perform a Seek-Down on E in ~.2.2.5 Agenda PushWhenever an edge E is inserted into the chart,if E is active then for all passive A, such thatA.from 6 E.to and combined-seore(E,A) > Beam-Value, insert (E,A, combined-score(E,A )) into theactual agenda.
If E is passive then for all active A,such that E.f~vm 6 A.to and combined-score(A,E)> Beam- Value, insert (A,E, combined-score(A, E))into the actual agenda.
Combined-Score is a lin-ear combination of the outside components of anedge C which would be created by A and E in aCombine operation.
Beam-Value is calculated asa fixed offset from the maximum Combined-Scoreon an agenda.
Since we process best-first insidethe beam, the maximum is known when the firsttriple is inserted into an agenda.
Agenda-Pop willremove the best triple from an actual agenda andreturn it.2.3 A s imple  LR I  la t t i ce  parserThe follwing control oop implements a simple LRIlattice parser.1.
T = 0.
Create VT2.
Insert initial active edge E into VT, withE.next = S3.
Increment T. Create VT4.
For every W with W.end = 7': Insert(W) orInherit(W)5.
Until Agenda\[T\] is empty:(a) Combine(Agenda-Pop)(b) When combination with initial edge issuccessful, send result to SEMANTICS6.
Communicate with PROSODY and go to 32.4 The  Grammar  ModelThe UG used in our experiments consists of 700lexical entries and 60 rules.
We used a variantof inside-outside training to estimate a model ofUG derivations.
It is a rule bigram model simi-lar to PCFG with special extensions for UG typeoperations.
The probability of future unificationsis made dependent from the result type of ear-lier unifications.
The model is described in moredetail in (Weber 1994a; Weber 1995); it is verysimilar to (Brew 1995).2.5 LRI Coupling with ProsodyIn INTARC we use three classes of boundaries,B0 (no boundary), B2 (phrase boundary), B3(sentence boundary) and B9 (real break).
Theprosody module, developed at the University ofBonn, classifies time intervals according to theseclasses.
A prosody hypothesis consists of a be-ginning and ending time and model probabilitiesfor the boundary types which sum up to one.
Aprosodic transition penalty used in the Combineoperation was taken to be the score of the bestcombination of bottom-up boundary hypothesisBx and a trigram score (lword, Bx, rword).
Herelword is the last word of the edge to the left andrword is the first word spanned by the edge to theright.
Prosody hypotheses are consumed by theparser in every cycle and represented as attributesof vertices which fall inside a prosodic time inter-val.
In a couple of tests we already achieved a re-duction of edges of about 10% without change inrecognition rate using a very simple trigram withonly five word categories.2.6 Exper imenta l  ResultsIn a system like INTARC-1.3, the analysis treeis of much higher importance than the recoveredstring; for the goal of speech translation an ad-equate semantic representation for a string withword errors is more important han a good stringwith a wrong reading.
The grammar scores haveonly indirect influence on the string; their mainfunction is picking the right tree.
We cannot mea-sure something like a "tree recognition rate" or"rule accuracy", because there is no treebank forour grammar.
The word accuracy results cannotbe compared to word accuracy as usually appliedto an acoustic decoder in isolation.
We countedonly those words as recognized which could be486built into a valid parse from the beginning of theutterance.
Words to the right which could notbe integrated into a parse, were counted as dele-tions --- although they might have been correct instandard word accuracy terms.
This evaluationmethod is much harder than standard word accu-racy, but it appears to be a good approximationto "rule accuracy".
Using this strict method weachieved a word accuracy of 47%, which is quitepromising.Results using top down prediction of possibleword hypotheses by the parser work inspired by(Kita et.
al.
1989) have already been publishedin (Hauenstein and Weber 1994a; ltmlenstein andWeber 1994b), (Weber 1994a), and (Weber 1995).Recognition rates had been improved there forread speech.
In spontaneous speech we could notachieve the same effects.2.7 Cur rent  WorkOur current work, which led to INTARC-2.0, usesa new approach for the interaction of syntax andsemantics and a revision of the interaction of theparser with a new decoder.
For the last case weimplemented a precompiler for word-based pre-diction which to our current experience is clearlysuperior to the previous word-class based predic-tion.
For the implementation of the interactionof syntax and semantics we proceed as follows: Anew turn-based UG has been written, for which acontext-sensitive stochastic traiuing is being per-formed.
The resulting grammar is then strippeddown to a pure type skeleton which is actuallybeing used for syntactic parsing.
Using full struc-ture sharing in the syntactic chart, which con-tains only packed edges, we achieve a complex-ity of O(n3).
In contrast to that, for semanticanalysis a second, unpacked chart is used, whoseedges are provided by an unpacker module whichis the interface between the two analysis levels.The unpacker, which has exponential complexity,selects only the n best scored packed edges, wheren is a parameter.
Only if semantic analysis fails itrequests further edges from the unpacker.
In thisway, the computational effort on the whole is keptas low as possible.3 Parallel ParsingOne of our main research interests has been theexploration of performance gains in NLP throughparallelization.
To this end, we developed a par-allel version of the INTARC parser.
Althoughthe results so far are yet not as encouragingas we expected, our efforts make for interest-ing lessons in software engineering.
The parallelparser had to obey the tbllowing restrictions: Run-ning on our local shared memory lnnltiprocessor(SparcServerl000) with 6 processors, paralleliza-tion should be controlled by inserting Solaris-2.4thread and process control primitives directly intothe code.
The only realistic choice we had wasto translate our parser with Chestnut Inc.'s Lisp-to-C-Translator automatically into C. Since theLisp functions library is available in C source, wecould insert the necessary Solaris parallelisationand synchronization primitives into key positionsof the involved fnnctions.3.1 Para l le l i zat ion  S t ra tegy  andPre l iminary  Resu l tsFor effective parallelization it is crucial to keepcommunication between processors to a minimum.Early experiments with a fully distributed chartshowed that the effort required to keep the partialcharts consistent was much larger that the poten-tial gains of increased parallelism.
The chart mustbe kept as a single data structure in a shared mem-ory processor, where concurrent reads are possi-ble and only concurrent writes have to be serial-ized with synchronisation primitives.
An analysisof profiling data shows that even the heavily op-timized UG formalism causes between 50% -and70% of the compntational load in the serial c~e.Therefore we provide an arbitrary number of uni-fication workers running in parallel which are fedunification tasks from the top of an agenda sortedby scores.
Due to the high optimization levelof the sequential parser, load-balancing is faMypoor.
Namely, the very fast type check used tocircumvent most unifications, causes large dispar-ities in the granularity of agenda tasks.
Further-more, pathological examples have been found inwhich a single unification takes much longer thanall other tasks combined.I ~::~ :: "~- ~'~14~- IM  ?
, , ?
, , , , ,3 t tx l  ~ 2  ~tz3  ~t4  ~ 5  Sta6  $*1z7 Sstz$ ~ lz9  r ,~t lOFigure 1: PercentuM gains and losses over at-tained over 10 ditferent sentences (Spilker 1995)4874 Dist r ibuted Control inVerbmobi lThe question of control in VM is tightly knitwith the architecture of the VM system.
As yet,the concept of architecture in VM has been usedmostly to describe the overall modularization andthe interfaces implied by the data flow betweenmodules.
This socalled dornair~ architecture is in-complete in the sense that it does not specifyany interactio~ strategics.
Within our researchon interactive system architectures we developed amodular communication framework, ICE ~, in co-operation with the University of Hamburg.
Now,ICE is the architectural framework of the VM re-search prototype.4.1 The  INTARC Arch i tec tureThe INTARC architecture as first presented by(Pyka 1992) is a distributed software system thatallows for tile intcrconncction of NLSP modulesunder the principles of incrementality and inter-activity.
Figure 2 shows the modularization ofINTARC-1.3: There is a main broad channel con-necting all modules in bottom-up direction, i.e.,from signal to interpretation.
Furthermore, thereare smaller channels connecting several modules,which are used for the top-down interactive dis-ambiguation data flow.
Inerementality is requiredfor all modules.
ICE assumes that each modulehas a local memory that is not directly accessi-ble to other modules.
Modules communicate ex-plicitly with one another via messages ent overbidirectional channels.
This kind of communica-tion architecture is hardly new and eonl?onts usdirectly with a large number of unresolved issuesin distributed problem solving, ef.
(Durfee et al1989).
In the last 20 years there have been numer-ous architecture proposals for distributed prob-lem solving among computing entities that ex-change information explicitly via message passing.None of these models include explicit strategiesor paradigms to tackle the problem of distributedcontrol.4.2 Structural  Constra ints  of  Verblnobi lModularity, being a fundamental assumption inVM (Wahlster 1992), does still leave us with twoproblems: First, modules have to communicatewith one another, and second, their local behav-iors have to be somehow coordinated into a coher-ent global, possibly optimal, behavior.
Unfortu-nately, the task of system integration has to obeysome structural constraints which are mostly prag-matic in natnre:2based on PVM (parallel virtual madfine)semRnb~represenl~(mtI.
.
.
.
.
.
.
.
.
.
.
.
.
.
/-.. ~-?a,fi~f~.~ ,,)~ho.
.~'~z,- Ol~mb~g~ogonDet*lFIow(TopDo~n)MoJtl Da~ Flo* (l-lottom Ui))Figure 2: 'l)he interactive, incremental INTARC-1.3 architectureSome of the modules are very complex soft-ware systems in thelnselves.
Highly parame-terizable and with control subtly spread overmany interacting submodules, understandingand then integrating such systems into a com-mon control strategy can be a very dauntingtask.Control issues are often very tightly knit withthe domain the module is aimed at, i.e., itis very difficult to understand the controlstrategies used without sound knowledge ofthe underlying domain.
The problem evengets worse if what is to be fine-tuned is the in-teraction between several complex modules.These two arguments are similar in nature, butdiflhr in the architecturM levels that they apply to.
'File former is implementation related, the latteralgorithm arid theory related.4.3 Layers  of  Cont ro lModules have to colnmunicate with one anotherand their local behaviors have to be coordinatedinto a coherent global, possibly optimal, behavior.In highly distributed systems we generally tind thefollowing levels of control:Sys tem Contro l :  The minimal set of operat-ing system related actions that each participat-ing module must be able to per\[brm which will488typically include means to start up, reset, monitot, trace and terminate individual modules or thesystem as a whole.Is() lated Loca l  Cont roh  The control strate-gies used within the module, disregarding any in-teractions beyond initial input of data and finaloutput of solutions.
'Fhere is only one thread ofcontrol active at any time.ln teraet iv ( ;  Loca l  Cont roh  ll.oughly, this canbe seen as isolated local control extended with in-teraction cal)al/ilities, lncr~"mentalitp is given bythe l)ossibility of control flowing back to a certaininternal stake aftex an outl)ut operation, llighermtcraclivily is made possible by entering a statemore often fl:om w~rious points within the rood-tile and by adding a new waiting lool/to cheek forany tot)-down requests.
The requirement for any.time behavior is a special case of that (G6rz andKesseler \ ]994).in ore: experience ~he change to interactive COl>trol will tremendously increase the complexity ofthe resulting (:ode.
But we are swill making thesimplifying assumptions that tile algorithm canbe used increnlentally - but there are algorithmsm~suitable for incremental processing (e.g.
A*).h~crementality can lead to the (\[elrlalld for a eoln-i)\]ete redesign of a lnodule.
Furthexmore we as-sume that simply by exchanging data and doingsimple extensions in the control \[tow everythingwill balan(:e out nicely on the system scale whichis enorlnously naiv(:.
Even for the sequential archi-tecture implied by the case of isolated local con-trol, we have to solve a whole plethora of uewproblems that corne along with interaetivity:* Mutual deadlock- Mutual live-lock- Race conditions (missing synchronization),, Over-synchronizationD ia logue  Cont roh  In systems like VM there isa module that comes close to possessing the "inte--grated view" ot'a centralized blackboard control:the dialogue module.
So it seems the right place tohandle some of the global strategic control issues,like:- l )omain error trundling.
Observe timeont constraints.
ll,esolve, external ambiguitie.s/unl(nownsThe fact that tile dialogue module exercises a kindof global control does not invalidate what has bee, nsaid about the unfeasability of central control, be..cause the control exercised by it is very coar.',egrained.
To handle liner grained control issues inany rood ule would take us back to memory and/oreomm,mication system contention.Re ferencesChris Brew.
Stochastic t\]I'SG, l)roccx,dings of l.he\]'hn'ol)ean ACI, Conference 1995, b;din/)urgh, 1995l';dnmnd 11.
I)urfec, Victor I{.
I,cssev, and I)anM I).Corkill.
Coop~rative l)istribut{d Probh:m Soh.,ing,pages 83 147.
Volume 4 ot: Aw'on I{arr et al (b;d.).The ll.ndbook of Arlifi'ciul lntclli.qence l{eading,Mass.
: Addison-Wesley, 1989.
(',iitdher G6rz and Marcus I<esschw.
Anytime ALgorithms for Speech Parsing?
Proceedings of(\]OIAN(L94, Kyoto, 19{)4Andrcas llauensl,eiu and \[laus Weber.
An invesligaotion of tightly coupled time synchronous speech lan-guage inlcEfaccs usin 9 a unification grammar.
In:l'.
McKevitt (Ed.
): Proceedings of tile Workshop onIntegration of Natural Language and Speech Pro-(:esslng, AAAI-94, Seatde, \[994, 42 49Andrcas lIauenstein and Hans Weber.
An lnveatiga-lion of Tightly Coupled Time Synchronous SpeechLanguage hderfaces.
Proceedings of K()NVI'\]NS 94,Vietma: Springer, September 19!
)4, 141 150Marcus Kcsseh!r.
l)istribvted Control in Vcrbmo-bil+ Uniwwsil.y of Erlangen-N iit'nberg, IMM D V\[ l 1,Verbmot)il {el)Ort 24, 1994.Kit.a, K., I<awabata, T. and Saito, \[I. HMM conliu-ous speech recognition usin9 predictive L 1~ parsiwI.IEEE IC,4,S'SI ~ Proceedings , 1989, 703 706.
(\]laudius \[)yka.
Management of hypotheses in an iutc~.qralcd spccch-la~*guage architecture.
Proceedings ofEUAl-92, 1992, 558 56036vg Spilker.
Parallclisicrun 9 eines inkrcmc.nlellcn,aklivcn (\]hartparscrs.
Diploma thesis, Uniw~rsil;yof F, rlangen-N6rnberg, l" rlangen, December 1995.Wolfgmlg Wahlstcr and Judith l';ngelkamp, editors.Wissenschafllichc Ziele und Nctzpldnc filr dasVERBM 0 BlL-Projekt.
I)FK 1, SaarbriM~en, \] 992.Ilans Weber.
Time Synchronous Uhart Parsingof ,5'pccch lntcgratin 9 UniJication Grammars wilhStatistics.
Speech arid l,anguage l~\]ngineering, Pro-ceedings of {;he l';ighth Twente Workshop on Lan-guage Technology, (1,.
Bores, A. Nijholt, Ed.
),Twentc, 1\[)94, 107-119tlans Weber.
I,R-inkrcmcntclles probabili-stisches Chartparsing yon Worthypothcsenmengcnmit Unifikations.qrammatiken: Eine engc Kopplungyon Suche und Analyse.
Ph.l).
Thesis, Universityof Hamburg, 1995, Verbmobil Report 52.489
