Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 681?686,Beijing, China, July 26-31, 2015. c?2015 Association for Computational LinguisticsRhetoric Map of an Answer to Compound QueriesBoris GalitskyKnowledge Trail Inc.San-Francisco, USAbgalitsky@hotmail.comDmitry IlvovskyNational Research Universi-ty Higher School of Eco-nomics, Moscow, Russiadilvovsky@hse.ruSergey O. KuznetsovNational Research Universi-ty Higher School of Eco-nomics, Moscow, Russiaskuznetsov@hse.ruAbstractGiven a discourse tree for a text as a can-didate answer to a compound query, wepropose a rule system for valid and inva-lid occurrence of the query keywords inthis tree.
To be a valid answer to a query,its keywords need to occur in a chain ofelementary discourse unit of this answerso that these units are fully ordered andconnected by nucleus ?
satellite relations.An answer might be invalid if the que-ries?
keywords occur in the answer's sat-ellite discourse units only.
We build therhetoric map of an answer to prevent itfrom firing by queries whose keywordsoccur in non-adjacent areas of the An-swer Map.
We evaluate the improvementof search relevance by filtering outsearch results not satisfying the proposedrule system, demonstrating a 4% increaseof accuracy with respect to the nearestneighbor learning approach which doesnot use the discourse tree structure.1 IntroductionAnswering compound queries, where its key-words are distributed through text of a candidateanswer, is a sophisticated problem requiring deeplinguistic analysis.
If the query keywords occurin an answer text in a linguistically connectedmanner, this answer is most likely relevant.
Thisis usually true when all these keywords occur inthe same sentence: they should be connectedsyntactically.
For the inter-sentence connections,these keywords need to be connected via anapho-ra, refer to the same entity or sub-entity, or belinked via rhetoric discourse.If the query keywords occur in different sen-tences, there should be linguistic cues for somesort of connections between these occurrences.
Ifthere is no connection, then different constraintsfor an object expressed by a query might be ap-plied to different objects in the answer text,therefore, this answer is perhaps irrelevant.There are following possibilities of such connec-tions.Anaphora.
If two areas of keyword occurrenc-es are connected with anaphoric relation, the an-swer is most likely relevant.Communicative actions.
If the text contains adialogue, and some question keywords are in arequest and other are in the reply to this request,then these keywords are connected and the an-swer is relevant.
To identify such situation, oneneeds to find a pair of communicative actionsand to confirm that this pair is of request-replykind.Rhetoric relations.
They indicate the coher-ence structure of a text (Mann and Thompson,1988).
Rhetoric relations for text can be repre-sented by a Discourse tree (DT) which is a la-beled tree.
The leaves of this tree correspond tocontiguous units for clauses (elementary dis-course units, EDU).
Adjacent EDUs as well ashigher-level (larger) discourse units are orga-nized in a hierarchy by rhetoric relation (e.g.,background, attribution).
Anti-symmetric rela-tion takes a pair of EDUs: nuclei, which are coreparts of the relation, and satellites, the supportiveparts of the rhetoric relation.The most important class of connections wefocus in this study is rhetoric.
Once an answertext is split into EDUs, and rhetoric relations areestablished between them, it is possible to estab-lish rules for whether query keywords occurringin text are connected by rhetoric relations (andtherefore, this answer is likely relevant) or notconnected (and this answer is most likely irrele-vant).
Hence we use the DT as a base for an An-swer Map of a text: certain sets of nodes in DTcorrespond to queries so that this text is a validanswer, and certain sets of nodes correspond toan invalid answer.
Our definition of the AnswerMap follows the methodology of inverse indexfor search: instead of taking queries and consid-ering all valid answers for it from a set of text,681we take a text (answer) and consider the totalityof valid and invalid queries consisting of thekeywords from this text.Usually, the main clause of a compound queryincludes the main entity and some of its con-straints, and the supplementary clause includesthe other constraint.
In the most straightforwardway, the main clause of a query is mapped into anucleus and the supplementary clause is mappedinto a satellite of RST relation such as elabora-tion.
Connection by other RST relation, where asatellite introduces additional constraints for anucleus, has the same meaning for answer validi-ty.
This validity still holds when two EDUs areconnected with a symmetric relation such asjoint.
However, when the images of the main andsupplementary clause of the query are satellitesof different nucleus, it most likely means thatthey express constraints for different entities, andtherefore constitute an irrelevant answer for thisquery.There is a number of recent studies employingRST features for passage re-ranking under ques-tion answering (Joty and Moschitti, 2014;Surdeanu et al., 2014).
In the former study, thefeature space of subtrees of parse trees includesthe RST relations to improve question answeraccuracy.
In the latter project, RST features con-tributed to the totality of features learned to re-rank the answers.
In (Galitsky et al., 2014) rheto-ric structure, in particular, was used to broadenthe set of parse trees to enrich the feature spaceby taking into account overall discourse structureof candidate answers.
Statistical learning in thesestudies demonstrated that rhetoric relation can beleveraged for better search relevance.
In the cur-rent study, we formulate the explicit rules forhow a query can be mapped into the answer DTand the relevance of this map can be verified.2 Example of an Answer MapEx.
1.
DT including 6 nodes {e1...e6} is shownin Fig 1 (Joty and Moschitti, 2014).
Text is splitinto six EDUs:[what?s more,]e1 [he be-lieves]e2 [seasonal swings inthe auto industry this yeararen?t occurring at the sametime in the past,]e3 [becauseof production and pricing dif-ferences]e4 [that are curbingthe accuracy of seasonal ad-justments]e5 ] [built into theemployment data.]e6Fig.1.
Discourse tree for the Example 1Horizontal lines indicate text segments; satel-lites are connected to their nuclei by curved ar-rows.
One can see that this text is a relevant an-swer to the queryAre seasonal swings in the autoindustry due to pricing differ-ences?but is an irrelevant answer to the queryAre pricing differences builtinto employment data?Fig.
2.
An Answer Map and its areas for validand invalid answersA valid set of nodes of an Answer Map is de-fined as the one closed under common ancestorrelations in a DT.
For example, the i-nodes onthe bottom-left of DT in Fig.
2 constitute the in-valid set, and the v-nodes on the right of DT con-stitute the valid set.Ex.
2.I went to watch a movie becauseI had nothing else to do.
I en-joyed the movie which was aboutanimals finding food in a de-sert.
To feed in a desert envi-ronment, zebras run hundreds ofmiles in search of sources ofwater.This answer is valid for the following queries(phrases) since their keywords form v-set:- enjoy movie watched whennothing else to do- I went to watch a movieabout feeding in desert en-vironment- I went to watch a movieabout zebras run hundreds ofmiles682- I went to watch a movieabout searching sources ofwaterAnd this text is not a correct answer for thefollowing queries (phrases), since their keywordsform i-sets:- animals find food in desertwhen have nothing else to do- I had nothing else exceptfinding food in a desert- I had nothing else to do butrun hundreds of miles insearch of water- finding food in a desert - agood thing to do3 Definition and Construction Algo-rithmDiscourse tree includes directed arcs for anti-symmetric rhetoric relation and undirected arcsfor symmetric rhetoric relations such as joint,time sequence, and others.
For two nodes of DTwe define its directed common ancestor as acommon ancestor node which is connected withthese nodes via directed arcs.The valid set of EDUs which is a result ofmapping of a query is closed under common di-rected ancestor relation: it should contain the setof all directed common ancestor for all EDUs.Hence this constraint is applied for antisymmet-ric RST relations; query terms can occur insymmetric EDU nodes in an arbitrary way.To construct an Answer Map from DT, firstly,we need to map keywords and phrases of a queryinto EDUs of an answer.
For each noun phrasefor a query, we find one or more EDUs whichinclude noun phrases with the same head noun.Not each keyword has to be mapped, but thereshould be not more than a single EDU each key-word is mapped under a given mapping.
For ex-ample, noun phrase from the query family do-ing its taxes is mapped into the EDU in-cluding how individuals and familiesfile their taxes since they have the samehead noun tax.
If a multiple mapping exists fora query, we need to find at least one valid occur-rence to conclude that this query is a valid onefor the given map.For a query Q, if its keywords occur in candi-date answer A and the set of EDUs ???
?, thencommonAncestorsDT(A)(????)
?
???
?.For a real-word search system, the enforce-ment of RST rules occurs at indexing time, sinceRST parsing is rather slow.For answer text A, we produce a sequence oftexts ??
< {A directed common ancestor I} forall pairs of EDU nodes connected with their par-ents by directed arcs.
Then the match of the setof keyword occurs with the extended index in theregular manner: there is no element ??
for inva-lid mapping ?
to ????
.4 Approach ScalabilityIn terms of search engineering, enforcing of thecondition of the Rhetoric Map of an answer re-quires additional part of the index besides theinverse one.
Building this additional index re-quires enumeration of all maximal sequences ofkeywords from Rhetoric Map for every docu-ment (potential answer A).
Once A is determinedto be fired by query Q using the regular searchindex, there should be an entry in Rhetoric Mapwhich is fired by a query formed as a conjunc-tion of terms in Q.Since application of Rhetoric Map rules oc-curs via an inverse index, the search time is con-stant with respect to the size of the overall RMindex and size of a given document.
The index-ing time is significantly higher due to rhetoricparsing, and the size of index is increased ap-proximately by the number of average maximalpaths in a DT graph, which is 3-5.
Hence alt-hough the performance of search will not signifi-cantly change, the amount of infrastructure ef-forts associated with RM technology is substan-tial.5 EvaluationWe used the TREC evaluation dataset as a list oftopics: http://trec.nist.gov/data/qa/.
Given a shortfactoid question for entity, person, organization,event, etc.
such as #EVENT Pakistan earth-quakes of October 2005# we ran a websearch and automatically (using shallow parsingprovided by Stanford NLP) extracted compoundsentences from search expressions, such as Amassive earthquake struck Pakistanand parts of India and Afghanistanon Saturday morning October 8, 2005.This was the strongest earthquake inthe area during the last hundredyears.Ten to twenty such queries were derived for atopic.
Those portions of text were selected withobvious rhetoric relation between the clauses.We then fed Bing Search Engine API such que-ries and built the Answer Map for each candidateanswer.
We then ran the Answer Map - based683filter.
Finally, we manually verify that these fil-tered answers are relevant to the initial questionsand to the queries.We evaluated improvement of search rele-vance for compound queries by applying the DTrules.
These rules provide Boolean decisions forcandidate answers, but we compare them withscore-based answer re-ranking based on ML ofbaseline SVM tree kernel (Moschitti, 2006), dis-course-based SVM (Ilvovsky, 2014) and nearest-neighbor Parse Thicket-based approach (Galitskyet al., 2013).The approach based on SVM tree kernel takesquestion-answer pairs (also from TREC dataset)and forms the positive set from the correct pairsand negative set from the incorrect pairs.
Thetree kernel learning (Duffy and Collins, 2002) forthe pairs of extended parse trees produces multi-ple parse trees for each sentence, linking them bydiscourse relations of anaphora, communicativeactions, ?same entity?
relation and rhetoric rela-tions (Galitsky et al., 2014).In the Nearest Neighbor approach to question?
answer classification one takes the same dataof parse trees connected by discourse relationsand instead of applying SVM learning to pairs,compare these data for question and answer di-rectly, finding the highest similarity.To compare the score-based answer re-rankingapproaches with the rule-based answer filteringone, we took first 20 Bing answers and classifiedthem as valid (top 10) and invalid (bottom 10)under the former set of approaches and selectedup to 10 acceptable (using the original ranking)under the latter approach.
Hence the order ofthese selected set of 10 answers is irrelevant forour evaluation and we measured the percentageof valid answers among them (the focus of eval-uation is search precision, not recall).Answer validity was assessed by Amazon Me-chanical Turk.
The assessors were asked tochoose relevant answers from the randomly sort-ed list of candidate answers.
Table 1 shows theevaluation results.Table 1.
Evaluation resultsFiltering method BaselineBing search,%SVM TKlearning of QApairs (baselineimprovement),%SVM TKlearning forthe pairs forextended parsetrees, %Nearestneighbor forquestion ?answer, %AnswerMap, %Sources /QuerytypesSource ofdiscourseinformation- - Anaphora, same entity, selecteddiscourse relationsDiscourseTreeClauses connected withelaboration68.3 69.4 73.9 74.6 79.2Clauses connected withattribution67.5 70.1 72.7 75.1 78.8Clauses connected withsummary64.9 66.3 70.2 74.0 78.0Clauses injoint/sequence relation64.1 65.2 68.1 72.3 76.3Average 66.2 67.8 71.2 74.0 78.0The top two rows show the answer filteringmethods and sources of discourse information.Bottom rows show evaluation results for querieswith various rhetoric relations between clauses.One can observe just a 1.5% improvement byusing SVM tree kernel without discourse, further3.5% improvement by using discourse-enabledSVM tree kernel, and further improvement of2.8% by using nearest neighbor learning.
Thelatter is still 4% lower than the Answer Map ap-proach, which is the focus of this study.
We ob-serve that the baseline search improvement,SVM tree kernel approach has a limited capabil-ity of filtering out irrelevant search results in ourevaluation settings.
Also, the role of discourseinformation in improving search results for que-ries with symmetric rhetoric relation betweenclauses is lower than that of the anti-symmetricrelations.684Code and examples are available atcode.google.com/p/relevance-based-on-parse-trees/ (packageopennlp.tools.parse_thicket.external_rst).6 Discussion and ConclusionOverall, our evaluation settings are focused oncompound queries where most answers correctlybelong to the topic of interest in a query andthere is usually sufficient number of keywords toassure this.
However, in the selected search do-main irrelevant answers are those based on for-eign entities or mismatched attributes of theseentities.
Hence augmenting keyword statisticswith the structured information of parse trees isnot critical to search accuracy improvement.
Atthe same time, discourse information for candi-date answers is essential to properly form andinterpret the constraints expressed in queries.Although there has been a substantial ad-vancement in document-level RST parsing, in-cluding the rich linguistic features-based of(Feng and Hirst, 2012) and powerful parsingmodels (Joty et al., 2013), document level dis-course analysis has not found a broad range ofapplications such as search.
The most valuableinformation from DT includes global discoursefeatures and long range structural dependenciesbetween DT constituents.Despite other studies (Surdeanu et al., 2014)showed that discourse information is beneficialfor search via learning, we believe this is the firststudy demonstrating how Answer Map affectssearch directly.
To be a valid answer for a ques-tion, its keywords need to occur in adjacent EDUchain of this answer so that these EDUs are fullyordered and connected by nucleus ?
satellite rela-tions.
Note the difference between the proximityin text as a sequence of words and proximity inDT (Croft et al., 2009).
An answer is expected tobe invalid if the questions' keywords occur in theanswer's satellite EDUs and not in their nucleusEDUs.
The purpose of the rhetoric map of ananswer is to prevent it from being fired by ques-tions whose keywords occur in non-adjacent are-as of this map.ReferencesS.
Joty and A. Moschitti.
2014.
Discriminative Re-ranking of Discourse Parses Using Tree Kernels.Proceedings of the 2014 Conference on EmpiricalMethods in Natural Language Processing(EMNLP), pages 2049?2060, October 25-29, 2014,Doha, Qatar.V.
Wei Feng and G. Hirst.
2012.
Text-level discourseparsing with rich linguistic features.
In Proceedingsof the 50th Annual Meeting of the Association forComputational Linguistics (ACL-2012), pages 60-68, Jeju, Korea.P.
Jansen, M. Surdeanu, and P. Clark.
2014.
Dis-course Complements Lexical Semantics for Non-factoid Answer Reranking.
In Proceedings of the52nd Annual Meeting of the Association for Com-putational Linguistics (ACL).S.
Joty, G. Carenini, and R. T. Ng.
2012.
A NovelDiscriminative Framework for Sentence-LevelDiscourse Analysis.
In Proceedings of the 2012Joint Conference on Empirical Methods in NaturalLanguage Processing and Computational NaturalLanguage Learning, EMNLP-CoNLL?12, pages904?915, Jeju Island, Korea.
Association for Com-putational Linguistics.W.
Mann, S. Thompson.
1988.
Rhetorical StructureTheory: Toward a Functional Theory of Text Or-ganization.
Text, 8(3):243?281.S.
Joty, G. Carenini, R. Ng, Y. Mehdad.
2013.
Com-bining Intra- and Multi-sentential Rhetorical Pars-ing for Document-level Discourse Analysis.
InProceedings of the 51st Annual Meeting of the As-sociation for Computational Linguistics, Sofia,Bulgaria.B.
Galitsky, D. Ilvovsky, S.O.
Kuznetsov, F. Strok.2013.
Matching sets of parse trees for answeringmulti-sentence questions.
In Proceedings of theRecent Advances in Natural Language Processing(RANLP), Shoumen, Bulgaria, pages 285?294.D.
Ilvovsky.
2014.
Going beyond sentences whenapplying tree kernels.
Proceedings of the StudentResearch Workshop ACL 2014, pp.
56-63.B.
Galitsky, D. Usikov, S.O.
Kuznetsov.
2013.
ParseThicket Representations for Answering Multi-sentence questions.
20th International Conferenceon Conceptual Structures, ICCS 2013.B.
Galitsky, S.O.
Kuznetsov.
2008.
Learning commu-nicative actions of conflicting human agents.
J.Exp.
Theor.
Artif.
Intell.
20(4): 277-317.B.
Galitsky.
2012.
Machine Learning of SyntacticParse Trees for Search and Classification of Text.Engineering Application of AI.A.
Moschitti.
2006.
Efficient Convolution Kernels forDependency and Constituent Syntactic Trees.
InProceedings of the 17th European Conference onMachine Learning, Berlin, Germany.A.
Severyn, A. Moschitti.
2012.
Structural relation-ships for large-scale learning of answer re-ranking.SIGIR 2012: 741-750.685A.
Severyn, A. Moschitti.
2012.
Fast Support VectorMachines for Convolution Tree Kernels.
Data Min-ing Knowledge Discovery 25: 325-357.M.
Collins and N. Duffy.
2002.
Convolution kernelsfor natural language.
In Proceedings of NIPS, 625?632.H.
Lee, A. Chang, Y. Peirsman, N. Chambers, MihaiSurdeanu and Dan Jurafsky.
2013.
Deterministiccoreference resolution based on entity-centric,precision-ranked rules.
Computational Linguistics39(4).B.
Croft, D. Metzler, T. Strohman.
2009.
Search En-gines - Information Retrieval in Practice.
PearsonEducation.
North America.V.
Vapnik.
1995.
The Nature of Statistical LearningTheory.
?
Springer-Verlag.686
