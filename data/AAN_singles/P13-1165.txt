Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1680?1690,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsPublic Dialogue: Analysis of Tolerance in Online DiscussionsArjun Mukherjee?
Vivek Venkataraman?
Bing Liu?
Sharon Meraz?
?Department of Computer Science  ?Department of CommunicationUniversity of Illinois at Chicagoarjun4787@gmail.com {vvenka6, liub, smeraz}@uic.eduAbstractSocial media platforms have enabled people tofreely express their views and discuss issues ofinterest with others.
While it is important to dis-cover the topics in discussions, it is equally use-ful to mine the nature of such discussions or de-bates and the behavior of the participants.
Thereare many questions that can be asked.
One keyquestion is whether the participants give rea-soned arguments with justifiable claims viaconstructive debates or exhibit dogmatism andegotistic clashes of ideologies.
The central ideaof this question is tolerance, which is a keyconcept in the field of communications.
In thiswork, we perform a computational study of tol-erance in the context of online discussions.
Weaim to identify tolerant vs. intolerant partici-pants and investigate how disagreement affectstolerance in discussions in a quantitativeframework.
To the best of our knowledge, thisis the first such study.
Our experiments usingreal-life discussions demonstrate the effective-ness of the proposed technique and also providesome key insights into the psycholinguisticphenomenon of tolerance in online discussions.1 IntroductionSocial media platforms have enabled peoplefrom anywhere in the world to express theirviews and discuss any issue of interest in onlinediscussions/debates.
Existing works in this con-text include recognition of support and opposecamps (Agrawal et al, 2003), mining of authori-ties and subgroups (Mayfield and Ros?, 2011;Abu-Jbara et al (2012), dialogue act segmenta-tion and classification (Morbini and Sagae, 2011;Boyer et al, 2011), etc.This paper probes further to study a differentand important angle, i.e., the psycholinguisticphenomenon of tolerance in online discussions.Tolerance is an important concept in the field ofcommunications.
It is a subfacet of deliberationwhich refers to critical thinking and exchange ofrational arguments on an issue among partici-pants that seek to achieve consensus/solution(Habermas, 1984).Perhaps the most widely accepted definitionof tolerance is that of Gastil (2005; 2007), whodefines tolerance as a means to engage (in writ-ten or spoken communication) in critical think-ing, judicious argument, sound reasoning, andjustifiable claims through constructive discus-sion as opposed to mere coercion/egotistic clash-es of ideologies.In this work, we adopt this definition, and alsoemploy the following characteristics of tolerance(also known as ?code of conduct?)
(Crocker,2005; Gutmann and Thompson, 1996) to guideour work.Reciprocity: Each member (or participant) offersproposals and justifications in terms that otherscould understand and accept.Publicity: Each member engages in a processthat is transparent to all and each memberknows with whom he is agreeing or disagree-ing.Accountability: Each member gives acceptableand sound reasons to others on the variousclaims or proposals suggested by him.Mutual respect and civic integrity: Each mem-ber?s speech should be morally acceptable, i.e.,using proper language irrespective of agree-ment or disagreement of views.The issue of tolerance has been actively re-searched in the field of communications for thepast two decades, and has been investigated inmultiple dimensions.
However, existing studiesare typically qualitative and focus on theorizingthe socio-linguistic aspects of tolerance (moredetails in ?2).With the rapid growth of social media, thelarge volumes of online discussions/debates offera golden opportunity to investigate people?s im-plicit psyche in discussions quantitatively basedon the real-life data, i.e., their tolerance levelsand their arguing nature, which are of fundamen-tal interest to several fields, e.g., communica-tions, marketing, politics, and sociology(Dahlgren, 2005; Gastil, 2005; Moxey and1680Sanford, 2000).
Communication and politicalscholars are hopeful that technologies capable ofidentifying tolerance levels of people on socialissues (often discussed in online discussions) canrender vital statistics which can be used in pre-dicting political outcomes in elections and help-ful in tailoring voting campaigns and agendas tomaximize winning chances (Dahlgren, 2002).Objective: The objective of this work is two-fold:1.
Identifying tolerant and intolerant participantsin discussions.2.
Analyzing how disagreement affects toler-ance and estimating the tipping point of sucheffects.To the best of our knowledge, these tasks havenot been attempted quantitatively before.
Thefirst task is a classification/prediction problem.Due to the complex and interactive nature of dis-cussions, the traditional n-gram features are nolonger sufficient for accurate classification.
Wethus propose a generative model, called DTM, todiscover some key pieces of information whichcharacterize the nature of discussions and theirparticipants, e.g., the arguing nature (agreeingvs.
disagreeing), topic and expression distribu-tions.
These allow us to generate a set of novelfeatures from the estimated latent variables ofDTM capable of capturing authors?
tolerancepsyche during discussions.
The features are thenused in learning to identify tolerant and intoler-ant authors.
Our experimental results show thatthe proposed approach is effective and outper-forms several strong baselines significantly.The second task studies the interplay of toler-ance and disagreement.
It is well-known thattolerance facilitates constructive disagreements,but sustained disagreements often result in atransition to destructive disagreement leading topolarization and intolerance (Dahlgren, 2005).An interesting question is: What is the tippingpoint of disagreement to exhibit intolerance?
Wetake a Bayesian approach to seek an answer anddiscover issue-specific tipping points.
Our em-pirical results discover some interesting relation-ships which are supported by theoretical studiesin psychology and linguistic communications.Finally, this work also produces an annotatedcorpus of tolerant and intolerant users in onlinediscussions across two domains: politics and re-ligion.
We believe this is the first such datasetand will be a valuable resource to the communi-ty.2 Related WorkAlthough limited work has been done on analy-sis of tolerance in online discussions, there areseveral general research areas that are related toour work.Communications: Tolerance has been an activeresearch area in the field of communications forthe past two decades.
Ryfe (2005) provided acomprehensive survey of the literature.
The topichas been studied in multiple dimensions, e.g.,opinion and attitude (Luskin et al, 2004; Price etal., 2002), public engagement (Escobar, 2012),psychoanalysis (Slavin and Kriegman, 1992),argument repertoire (Cappella et al, 2002), etc.Tolerance has also been investigated in thedomain of political communications with an em-phasis on political sophistication (Gastil andDillard, 1999), civic culture (Dahlgren, 2002),and democracy (Fishkin, 1991).
These existingworks study tolerance from the qualitative per-spective.
Our focus is quantitative analysis.Sentiment analysis: Sentiment analysis deter-mines positive or negative opinions expressed ontopics (Liu, 2012; Pang and Lee, 2008).
Maintasks include aspect extraction (Hu and Liu,2004; Popescu and Etzioni, 2005; Mukherjee andLiu, 2012c; Chen et al, 2013), opinion polarityidentification (Hassan and Radev, 2010; Choiand Cardie, 2010) and subjectivity analysis(Wiebe, 2000).
Although related, tolerance isdifferent from sentiment.
Sentiments are mainlyindicated by sentiment terms (e.g., great, good,bad, and poor).
Tolerance in discussions refersto the reception of certain views and often indi-cated by agreement and disagreement expres-sions and other features (?5).Online discussions or debates: Several worksput authors in debate into support and opposecamps.
Agrawal et al (2003) used a graph basedmethod, and Murakami and Raymond (2010)used a rule-based method.
In (Mukherjee andLiu, 2012a), contention points were identified, in(Mukherjee and Liu, 2012b), various expressionsin review comment discussions were mined, andin (Galley et al, 2004; Hillard et al, 2003),speaker utterances were classified into agree-ment, disagreement, and backchannel classes.Also related are studies on linguistic style ac-commodation (Mukherjee and Liu, 2012d) anduser pair interactions (Mukherjee and Liu, 2013)in online debates.
However, these works do notconsider tolerance analysis in debate discussions,which is the focus of this work.1681In a similar vein, several classification meth-ods have been proposed to recognize opinionstances and speaker sides in online debates (So-masundaran and Wiebe, 2009; Thomas et al,2006; Bansal et al, 2008; Burfoot et al, 2011;Yessenalina et al, 2010).
Lin and Hauptmann(2006) also proposed a method to identify oppos-ing perspectives.
Abu-Jbara et al (2012) identi-fied subgroups.
Kim and Hovy (2007) studiedelection prediction by analyzing online discus-sions.
Other related works studying dialogue anddiscourse in discussions include authority recog-nition (Mayfield and Ros?, 2011), dialogue actsegmentation and classification (Morbini andSagae, 2011; Boyer et al, 2011), discourse struc-ture prediction (Wang et al, 2011).All these prior works are valuable.
But theyare not designed to identify tolerance or to ana-lyze tipping points of disagreements for intoler-ance in discussions which are the focus of thiswork.3 Discussion/Debate DataFor this research, we used discussion posts fromVolconvo.com.
This forum is divided into vari-ous domains: Politics, Religion, Science, etc.Each domain consists of multiple discussionthreads.
Each thread consists of a list of posts.Our experimental data is from two domains, Pol-itics and Religion.
The data is summarized inTable 1(a).
In this work, the terms users, authorsand participants are used interchangeably.
Thefull data is used for modeling, but 436 and 501authors from Politics and Religion domains weremanually labeled as being tolerant or intolerant(Table 1(c)) respectively for classification exper-iments.Two judges (graduate students) were used tolabel the data.
The judges are fluent in Englishand were briefed on the definition of tolerance(see ?1).
From each domain (Politics, Religion),we randomly sampled authors having not morethan 60 posts in order to reduce the labeling bur-den as the judges need to read all posts and seeall interactions of each author before providing alabel.
Given all posts by an author, ?
and his/herassociated interactions (posts by other authorsreplying or quoting ?
), the judges were asked toprovide a label for author ?
as being tolerant orintolerant.
In our labeling, we found that usersstrongly exhibit one dominant trait: tolerant orintolerant, as our data consists of topics like elec-tions, immigration, theism, terrorism, and vege-tarianism across politics and religion domains,which are often heated and thus attract peoplewith pre-determined, strong, and polarizedstances1.The judges worked in isolation (to prevent bi-as) during annotation/labeling and were alsoasked to provide a short reason for their judg-ment.
The agreement statistics using Cohen?skappa are given in Table 1(b), which shows sub-stantial agreements according to the scale 2  in(Landis and Koch, 1977).
This shows that toler-ance as defined in ?1 is quite decisive and onecan decide whether a debater is exhibiting toler-ant vs. intolerant quite well.
To account for disa-greements in labels, the judges discussed theirreasons to reach a consensus.
The final labeleddata is reported in Table 1(c).4 ModelWe now present our generative model to capturethe key aspects of discussions/debates and theirintricate relationships, which enable us to (1)design sophisticated features for classificationand (2) perform an in-depth analysis of the inter-play of disagreement and tolerance.
The model iscalled Debate Topic Model (DTM).DTM is a semi-supervised generative modelmotivated by the joint occurrence of various top-ics; and agreement and disagreement expressions(abbreviated AD-expressions hereon) in debateposts.
A typical debate post mentions a few top-ics (using similar topical terms) and expressessome viewpoints with one or more AD-expression types (Agreement and Disagreement)using semantically related expressions.
This ob-servation forms the basis of the generative pro-cess of our model where documents (posts) arerepresented as admixtures of latent topics andAD-expression types (Agreement and Disagree-ment).
This key observation and the motivationof modeling debates are from our previous workin (Mukherjee and Liu, 2012a).
In the new set-1  These hardened perspectives are theoretically supportedby the polarization effect (Sunstein, 2002), and the hostilemedia effect, a scenario where partisans rigidly hold on totheir stances (Hansen and Hyunjung, 2011).2  Agreement levels are as follows.
?
?
[0, 0.2]: Poor,?
?
(0.2, 0.4]:Fair, ?
?
(0.4, 0.6]: Moderate, ?
?
(0.6, 0.8]:Substantial, and ?
?
(0.8, 1.0]: Almost perfect agreement.Domain Posts Authors  Cohen?s ?
Tol.
Intol.
TotalPolitics 48605 1027  0.74    213  223  436Religion 66835 1370  0.77    207  294  501(a) Full Data     (b) Agreement   (c) Labeled dataTable 1: Data statistics (Tol: Tolerant users; Intol:Intolerant users.
Total = Tol.
+ Intol).1682ting, we model topics and debate expression dis-tributions specific to authors as this work is con-cerned with modeling authors?
(in)tolerance na-ture.
Making latent variable ??
and ??
authorspecific facilitates modeling user behaviors(?5.3).Assume we have ?1??
topics and ?1??
expres-sion types in our corpus.
In our case of debateposts, based upon reading various posts, we hy-pothesize that ?
= 2 as in debates as we mostlyfind 2 dominant expression types: Agreementand Disagreement.
Meanings of variables used inthe following discussion are detailed in Table 2.In this work, a document/post is viewed as a bagof n-grams and we use terms to denote bothwords (unigrams) and phrases (n-grams)3.
DTMis a switching graphical model performing aswitch between topics and AD-expressions simi-lar to that in (Zhao et al, 2010).
The switch isdone using a learned maximum entropy (Max-Ent) model.
The rationale here is that topical andAD-expression terms usually play different syn-tactic roles in a sentence.
Topical terms (e.g.,?U.S.
elections,?
?government,?
?income tax?
)tend to be noun and noun phrases while expres-sion terms (?I refute,?
?how can you say,?
?I?dagree?)
usually contain pronouns, verbs, wh-determiners, and modals.
In order to utilize thepart-of-speech (POS) tag information, we placethe topic/AD-expression distribution, ??,?,?
(theprior over the indicator variable ??,?,?)
in the termplate (Figure 1)  and set it using a Max-Ent mod-el conditioned on the observed context ??,?,?
as-sociated with ??,?,?
and the learned Max-Entparameters ?
(details in ?4.1).
In this work, weuse both lexical and POS features of the previ-ous, current and next POS tags/lexemes of theterm ??,?,?
as the contextual information,i.e., ??,?,?
= [?????,?,?
?1 , ?????,?,?
, ????
?,?,?+1 ,??,?,??1,??,?,?
, ?
?,?,?+1], which is used to producefeature functions for Max-Ent.
For phrasal terms(n-grams), all POS tags and lexemes of ??,?
areconsidered as contextual information for compu-ting feature functions in Max-Ent.
DTM has thefollowing generative process:A.
For each AD-expression type ?, draw ???~???(??)B.
For each topic t, draw ???~???(??)C.
For each author ?
?
{1 ??}:i.
Draw ???~???(??)ii.
Draw ???~???(??)iii.
For each document/post ?
?
{1 ???}:I.
For each term ?
?,?,?, ?
?
{1 ???,?}:a.
Set ??,?,?
?
??????(??,?,?
; ?)b.
Draw ??,?,?~?????????(??,?,?)c.
if (??,?,?
=  ???)
// ?
?,?is an AD-expression termDraw ?
?,?,?~ ????(???
)else // ??,?,?
=  ??
?, ?
?,?,?is a topical termDraw ?
?,?,?~ ????(???)d.
Emit ??,?,?~????(???,?,???,?,?
)4.1 InferenceWe employ posterior inference using Monte Car-3 Topics in most topic models (e.g., LDA (Blei et al, 2003))are unigram distributions and a document is treated as anexchangeable bag-of-words.
This offers a computationaladvantage over models considering word orders (Wallach,2006).
As our goal is to enhance the expressiveness ofDTM (rather than ?modeling?
word order), we use 1-4grams preserving the advantages of exchangeable modeling.Figure 1: Plate notation of DTMVariable/Function Description?
; ?
; ?An author ?
; set of all authors; docu-ment, ?(?,?
); ?
?Post ?
by author ?
; Set of all posts by??;?
;?# of topics; expression types; vocabu-lary??,?,?
; ??,????
term in (?,?
); Total # of terms in(?,?)??,?,?
Distribution over topics and AD-expressions?
?,?,?Associated feature context of observed??,?,??
Learned Max-Ent parameters??,?,?
?
{??
?, ???
}Binary indicator/switch variable ( topic(???)
or AD-expression (???)
) for ??,?,????;???(??,???
,??,??????
)?
?s distribution over topics ; expressiontypes (Agreement: ??,???
, Disagree-ment: ??,??????
)??,??
;??,?,?
?Topic distribution of post ?
by author?
; Probability mass of topic ?
in ??,??
.??,?,??{??,?????}???,??
;Expression type distribution of post ?by author ?
; Corresponding probabilitymasses of Agreement: ??,?,?=???
andDisagreement in ??,?,?=??????
.??,?,?
Topic/Expression type of ??,?,????
;  ??
?Topic ?
?s ; Expression type ?
?s distri-bution over vocabulary terms??
; ??
; ??
; ??
Dirichlet priors of ???
;  ???
;???
;  ?????,???
; ??,??
?# of times topic ?
; expression type ?assigned to ???,???
; ??,??
?# of times term ?
appears in topic ?
;expression type ?Table 2: List of notationsx?zrw Na, d?Da?E ?EA?T ?T?T  T?E  E?E ?T1683lo Gibbs sampling.
Denoting the random varia-bles {?, ?, ?}
by singularscripts{?
?, ?
?, ??}
,?1??
, where ?
= ?
?
??,???
, asingle iteration consists of performing the fol-lowing sampling:?(??
= ?, ??
= ???|???,???,???,??
= ?)
?exp (?
????(??,?,?,???)?
?=1 )?
exp (?
????(??,?,?,?)?
?=1 )??{??,??}???,?????+????,(?)????+??????,?????+????,(?)????+???(1)?(??
= ?, ??
= ???|???,???,???
,??
= ?)
?exp (?
????(??,?,?,???)?
?=1 )?
exp (?
????(??,?,?,?)?
?=1 )??{??,??}???,?????+????,(?)????+??????,?????+????,(?)????+???
(2)where ?
= (?,?, ?)
denotes the ???
term of docu-ment ?
by author ?
and the subscript ??
denotesassignments excluding the term at (?,?, ?).
Omis-sion of the latter index denoted by (?)
representsthe marginalized sum over the latter index.Count variables are detailed in Table 1 (last tworows).
?1??
are the parameters of the learnedMax-Ent model corresponding to the ?
binaryfeature functions ?1??
for Max-Ent.
The learnedMax-Ent ?
parameters in conjunction with theobserved context, ??,?,?
feed the supervision sig-nal for updating the topic/expression switch pa-rameter, ?
in equations (1) and (2).The hyper-parameters for the model were setto the values ?
?= ?
?= 0.1 and ??
= 50/?, ??
=50/ ?
, suggested in (Griffiths and Steyvers,2004).
Model parameters were estimated after5000 Gibbs iterations with a burn-in of 1000 it-erations.
The Max-Ent parameters ?
werelearned using 500 labeled terms in each domain(politics:- topical: 376 and AD-expression: 124;religion:- topical: 349 and AD-expression: 151)appearing at least 10 times in debate threads oth-er than the data in Table 1 (we do so since thedata in Table 1(c) is later used in the classifica-tion experiments in ?6.1).Table 3 lists some top AD-expressions discov-ered by DTM.
We see that DTM can clustermany correct AD-expressions, e.g., ?I disagree?,?I refute?, ?don?t accept?, etc.
in disagreement;and ?I agree?, ?you?re correct?, ?agree withyou?, etc.
in agreement.
Further, it also discovershighly specific and more distinctive expressionsbeyond those used in Max-Ent training (markedblue in italics), e.g., ?I don?t buy your?, ?can youprove,?
?you fail to?, and ?you have no clue?
indisagreement; and phrases like ?valid point?,?rightly said?, ?I do support?, and ?very wellput?
in agreement.
In ?6.1, we will see that theseAD-expressions serve as high quality featuresfor predicting tolerance.Lastly, we note that DTM also estimates sev-eral pieces of useful information (e.g., AD-expressions, posterior estimates of author?s argu-ing nature, ???
; latent topics and expressions,???
;  ???
, etc.).
These will be used to produce arich set of user behavioral features for character-izing tolerance in ?5.3.5 Feature EngineeringWe now propose features which will be used formodel building to classify tolerant and intolerantauthors in Table 1(c).
We use three sets of fea-tures.5.1 Language based Features of ToleranceWord and POS n-grams: As tolerance in com-munication is directly reflected in language us-age, word n-grams are obvious features.
We alsouse POS tags (obtained using Stanford Tagger4)as features.
The rationale of using POS tag basedfeatures is that intolerant communications areoften characterized by hate/egotistic speechwhich have pronounced use of specific part ofspeech (e.g., pronouns) (Zingo, 1998).Heuristic Factor Analysis: In psycholinguistics,factor analysis refers to the process of findinggroups of semantically similar linguistic con-structs (words/phrases).
It is also called meaningextraction in (Chung and Pennebaker, 2007).
Astolerance in discussions is characterized by rea-soned expressions which often accompanysourcing (e.g., providing a hyperlink, making anattempt to clarify with some evidence, etc.
), wecompiled a list of reasoned and sourced expres-sions (shown in Table 4) from prior works4 http://nlp.stanford.edu/software/tagger.shtmlDisagreement expressions (??=?????????????
)I, disagree, I don?t, I disagree, argument, reject, claim, I reject,I refute, and, your, I refuse, won?t, the claim, nonsense, I con-test, dispute, I think, completely disagree, don?t accept, don?tagree, incorrect, doesn?t, hogwash, I don?t buy your, I reallydoubt, your nonsense, true, can you prove, argument fails, youfail to, your assertions, bullshit, sheer nonsense, doesn?t makesense, you have no clue, how can you say, do you even, contra-dict yourself, ?Agreement expressions (??=??????????
)agree, I, correct, yes, true, accept, I agree, don?t, indeed correct,your, point, that, I concede, is valid, your claim, not really,would agree, might, agree completely, yes indeed, absolutely,you?re correct, valid point, argument, the argument, proves, doaccept, support, agree with you, rightly said, personally, wellput, I do support, personally agree, doesn?t necessarily, exactly,very well put, absolutely correct, kudos, point taken,...Table 3: Top terms (comma delimited) of two expres-sion types.
Red (bold) terms denote possible errors.Blue (italics) terms are newly discovered; rest (black)terms have been used in Max-Ent training.1684(Chung and Pennebaker, 2007; Flor and Hadar,2005; Moxey and Sanford, 2000; Pennebaker, etal.,  2007).5.2 Debate Expression FeaturesAD-expressions: As we have seen in ?4, DTMcan discover specific agreement and disagree-ment expressions in debates.
We use these ex-pressions as another feature set.
Estimated AD-expressions (Table 3) serve as a principled wayof performing factor analysis in debates insteadof heuristic factor analysis as in Table 4 used inprior works.As the AD-expression types are modeled asDirichlet distributions (??~???(??
)), due to thesmoothing effect, each term in the vocabularyhas some non-zero probability mass associatedwith the expression types.
To ensure that the dis-covered expressions are representative AD-expressions, we only consider the terms in ?
?with ?(?|?)
= ??,??
> 0.001  as probabilitymasses lower than 0.001 are more due to thesmoothing effect of Dirichlet distribution thantrue correlation.5.3 User Behavioral FeaturesHere we propose several features of user interac-tion which reflect the socio-psychological stateof tolerance while participating in discussions.We note that these features rely on the posteriorestimates of latent variables ?
?, ?, and ?
in DTM(?4) and are thus difficult to obtain withoutmodeling.Overall Arguing Nature: The posterior on ???
(Table 2) for each author, ?
gives an estimate of?
?s overall arguing nature (agreeing or disagree-ing).
We use the probability mass assigned toeach arguing nature type as a user behavioralfeature.
This gives us two features ?1, ?2 as fol-lows:?1(?)
=  ??,???
;   ?2(?)
=  ??,??????
(3)Behavioral Response: As intolerant users arelikely to attract more disagreement, it is naturallyuseful to estimate the response (agreeing vs. dis-agreeing) a user receives from other users.
Forcomputing behavioral response, we first use theposterior on ?
to compute the distribution of AD-expressions (i.e., the relative probability massesof agreeing and disagreeing expressions) in adocument ?
by an author ?
as follows:??,?,???
=??????,?,?=??,1?????,?????????,?,?=???,1?????,???;??,?,??????
=??????,?,?=?????,1?????,?????????,?,?=???,1?????,???
(4)Now to get the overall behavioral response of anauthor, ?
we take the expected value of theagreeing and disagreeing responses that ?
re-ceived from other authors ??
who replied to orquoted ?
?s posts.
The expectations below aretaken over all posts ??
by ??
which reply/quoteposts of ?.?3(?)
=  ?[???
??,???
]; ?4(?)
=  ?????
??,??????
?
(5)Equality of Speech: In communication literature(Dahlgren, 2005; Habermas, 1984), equality istheorized as an essential element of tolerance.Each participant must be able to participate on anequal footing with others without anybody domi-nating the discussion.
In online debates, we canmeasure this phenomenon using the followingfeature:?5(?)
= ?
?
?# ??
?????
??
?
??
??????
?# ??
?????
??
??????
??
?[??,?,??????
]?
(6)where the inner expectation is taken over allposts of ?
in thread ?
and the outer expectation istaken over all threads ?
in which ?
participated.The above definition computes the aggressiveposting behavior of author ?
whereby he tires todominate the thread by posting more than others.The aggressive posting behavior is weighted byauthor?s disagreeing nature because a personusually exhibits a dominating nature when hepushes hard to establish his ideology (which isoften in disagreement with others) (Moxey andSanford, 2000).Topic Shifts: An interesting phenomenon of hu-man (social) psyche is that when people are una-ble to logically argue their stances and feel theyare losing the debate, they often try to belit-tle/deride others by pulling unrelated topics intodiscussion (Slavin and Kriegman, 1992).
This isFactor: Reasoning words/phrasesbecause, because of, since, reason, reason being, reason is,reason why, due to, owing to, as in, therefore, thus, hence-forth, hence, implies, implies that, implying, hints, hinting,hints towards, it follows that, it turns out, conclude, conse-quence, consequently, the cause, rationale, the rationale, justi-fication, the justification, provided, premise, assumption, onthe proviso, in spite, ?Factor: Sourcing words/phrasespresence of hyperlinks/urls, source, reference, for example,for instance, namely, to explain, to detail, to clarify, to eluci-date, to illustrate, to be precise, furthermore, moreover, apartfrom, besides, we find, ?Table 4: Heuristic Factor Analysis (HFA).Words/Phrases in each factor compiled from priorworks in psycholinguistics.1685referred to as topic shifts.
Topic shifts thus have arelation with tolerance in deliberation.
Stromer-Galley (2005) reported that if the discussion isoff topic, then tolerance or deliberation cannotmeet its objective of deep consideration of anissue.
Hence, the average topic shifts of an au-thor, ?
across various posts in a thread can serveas a good feature for measuring tolerance.
Weuse the posterior on per-document topic distribu-tion, ??,?,??
=??????,?,?=?,1?????,?????????,?,?=???,1?????,??
?to measure topicshifts using KL-Divergence as follows:?6 = ?
?avg?,???
??????
?
???????,??
||??,???
???
(7)We first compute author, ?
?s average topic shiftsin a thread, ?
which measures his topic shifts in ?.But this only gives us his behavior in one thread.To capture his overall behavior, we take the ex-pected value of this behavior over all threads inwhich ?
participated.
We take average KL-divergence (KL-Div.)
over all pairs of posts by ?in a given thread to account for the asymmetry ofKL-Div.Finally, we note that by no means do we claimthat the mere presence and a large value of any ofthe above features imply that a user is intolerantor tolerant.
They are indicators of the phenome-non of tolerance in discussions/debates.
The ac-tual prediction is done using the learned modelsin ?6.1.6 Experimental EvaluationWe now detail the experiments that investigatethe strengths of features in ?5.
In particular, wefirst consider the task of classifying whether anauthor is tolerant or intolerant in discussions.Then, we analyze how disagreement affects tol-erance.6.1 Tolerant and Intolerant ClassificationHere, we show that the features in ?5 can helpbuild accurate models for predicting tolerance.We employ a linear kernel 5  SVM (using theSVMLight system (Joachims, 1999)) and report 5-fold cross validation (CV) results on the task ofpredicting the socio-psychological nature of us-ers?
communication: tolerant vs. intolerant inpolitics and religion domains (Table 1(c)).
Notethat for each fold of 5-fold CV, DTM was run onthe full data of each domain (Table 1(a)) exclud-ing the users (and their associated posts) in thetest set of that fold for generating the features ofthe training instances (users).
The learned DTM5 Other kernels (rbf, poly, sigmoid) did not perform as well.was then fitted (using the approach in (Hofmann,1999)) to the test set users and their posts forgenerating the features of the test instances.To investigate the effectiveness of the pro-posed framework, we incrementally add featuresets starting with the baseline features.
Wordunigrams and bigrams (inclusive of unigrams)6serve as our first baseline (B1a, B1b).
Word +POS bigrams is our second baseline (B2).?Word?
in B2 uses bigrams as B1b gives betterresults.
B2 + Heuristic Factor Analysis (HFA)(Table 4) serve as our third baseline (B3).
Table5 shows the experiment results.
We note the fol-lowing:1.
Across both domains, adding POS bigramsslightly improves classification accuracy andF1-score beyond standard word unigrams andbigrams.
Feature selection using informationgain (IG) does not help much.2.
Using heuristic factor analyses (HFA) of rea-soned and sourced expressions (Table 4)brings about 1% and 2% improvement in ac-curacy in politics and religion domains re-spectively.3.
Debate expression features (DE) in ?5.2 anduser behavioral features (UB) in ?5.3 pro-duced from DTM progressively improve clas-sification accuracies by 4% and 8% in politicsdomains and 5% and 6% in religion domains.The improvements are also statistically signif-icant.In summary, we can see that modeling made amajor impact.
It improved the accuracy by about10% than traditional unigram and bigram base-lines.
This shows that the debate expressions anduser behaviors computed using the DTM modelcan capture various dimensions of (in)tolerancenot captured by n-grams.6.2 How Disagreement affects Tolerance?We now quantitatively study the effect of disa-greement on tolerance.
We recall from ?1 thattolerance indicates constructive discussion andallows disagreement.
Some level of disagree-ment is often times an integral component ofdeliberation and tolerance (Cappella et al,2002).Disagreements, however, can be either con-structive or destructive.
The distinction is thatthe former is aimed at arriving at a consensus orsolution, while the latter leads to polarizationand intolerance (Sunstein, 2002).
It was alsoshown in (Dahlgren, 2005) that sustained disa-6 Higher order n-grams did not result in better results.1686greement often takes a transition towards de-structive disagreement and is likely to lead tointolerance.
Similar phenomena was also identi-fied in psychology literature (Critchley, 1964).In such cases, the participants often stubbornlystick to an extreme attitude, which eventuallyresults in intolerance and defeats the very pur-pose of deliberative discussion.An intriguing research question is: What is therelationship between disagreement and intoler-ance?
The question is interesting from both thecommunication and psycholinguistic perspec-tives.
The best of our knowledge, this is the firstattempt towards seeking an answer.
We work inthe context of five issues/threads in real-lifeonline debates.
To derive quantitative and defi-nite conclusions, it is required to perform thefollowing tasks:?
For each issue, empirically investigate in ex-pectation the tipping point of disagreementbeyond which a user tends to be intolerant.?
Further, investigate the confidence on the es-timated tipping point (i.e., what is the likeli-hood that the estimated tipping point is statis-tically significant instead of chance alone).We formalize the above tasks in the Bayesiansetting.
Recall from Table 2 of ?4, that ??,???
(re-spectively, ??,?????? )
are the estimates of agreeingand disagreeing nature of an author and ??,???
+??,??????
= 1.
Let ??(?)
denote the event that inexpectation a threshold value of 0 < ?
< 1serves as a tipping point of disagreement beyondwhich intolerance is exhibited.
Note that we em-phasize the term ?in expectation?
(taken over allauthors).
We do not mean that every authorwhose disagreement, ??,??????
>  ?
, is intolerant.The empirical likelihood of ??(?)
can be ex-pressed by the following probability expression:????(?)?
=??????,??????
> ?|?
= ??
?
????,??????
> ?|?
= ???
(8)The events ?
= ?
and ?
= ?
denote that author?
is intolerant and tolerant respectively.
The ex-pectation is taken over authors.
Showing that ?indeed serves as the tipping point of disagree-ment to exhibit intolerance corresponds is to re-jecting the null hypothesis that the probabilitiesin (8) are equal.
We employ a Fisher?s exact testto test significance and report confidencemeasures (using p-values) for the tipping pointthresholds.
The results are shown in Table 6.The threshold ?
is computed using the entropymethod in (Fayyad and Irani, 1993) as follows:We first fit our previously learned model (usingthe data in Table 1 (a)) to the new threads in Ta-ble 6 and its users and posts to obtain the esti-mates of ??,??????
and other latent variables forfeature generation.
The learned classifier in ?6.1is used to predict the nature of users (tolerant vs.Feature SettingPolitics ReligionPrecision Recall F1 Accuracy Precision Recall F1 AccuracyB1a: Word unigrams 64.1 86.3 73.7 70.1 61.9 86.8 72.6 71.9Word unigram + IG 64.5 86.2 73.9 70.2 62.7 86.9 72.9 71.9B1b: Word bigrams 66.8 87.8 75.9 72.4 64.9 89.1 75.9 75.1B2: W+POS bigrams 68.5 86.8 76.4 73.7 66.6 88.4 76.8 76.7B3: B2 + HFA(Table 4) 69.2 90.5 78.1 75.2 66.4 90.6 76.8 77.5B3 + DE (?5.2) 74.7 91.3 82.4?
79.5?
70.2 92.8 80.8?
82.1?B3 + DE + UB (?5.3) 76.1 92.2 83.1?
83.2?
71.7 93.4 82.1?
83.3?Table 5: Precision, Recall, F1 score on the tolerant class, and Accuracy for different feature settings across 2domains.
DE: Debate expression features (AD-expressions, Table3, ?5.2).
UB: User behavioral features(?5.3).
Improvements in F1 and Accuracy using DTM features (beyond baselines, B1-B3) are statisticallysignificant (?
: p<0.02; ?
: p<0.01) using paired t-test with 5-fold CV.Thread/Issue # Posts # Users % InTol.
????,?,??????
?
?
p-valueRepeal Healthcare 1823 33 39.9 0.57 0.65 0.02Europe?s Collapse 1824 33 42.5 0.61 0.61 0.01Obama Euphoria 1244 26 30.7 0.66 0.71 0.01Socialism 831 49 44.8 0.69 0.48 0.03Abortion 1232 58 48.4 0.78 0.37 0.01Table 6: Tipping points of disagreements for intolerance (?)
of different issues.
????,?,??????
?
: the expecteddisagreement over all posts in each issue/thread, # Posts: the total number of posts, # Users: the total numberof users/authors, % Intol: % of intolerant users in each thread, ?
: the estimated tipping point, and p-value:computed from two-tailed Fisher?s exact test.1687intolerant) in the new threads7.
Then, for eachuser we have his predicted deliberative (social)psyche (Tolerant vs. Intolerant) and also hisoverall disagreeing nature exhibited in thatthread (the posterior on ??,??????
?
[0, 1]).
For athread, tolerant and intolerant users (data points)span the range [0, 1] attaining different valuesfor ??,??????
.
Each candidate tipping point of disa-greement, 0 ?
??
?
1 results in a binary partitionof the range with each partition containing someproportion of tolerant and intolerant users.
Wecompute the entropy of the partition for everycandidate tipping point in the range [0, 1].
Thefinal tipping point threshold, ?
is chosen suchthat it minimizes the partition entropy based onthe binary cut-point method in (Fayyad andIrani, 1993).Since we perform a thread level analysis, theresults in Table 6 are thread/issue specific.
Wenote the following from Table 6:1.
Across all threads/issues, we find that the ex-pected disagreement over all posts, ?,????,?,??????
?
> 0.5 showing that in discussionsof the reported issues, disagreement predomi-nates.2.
????,?,??????
?
also gives an estimate of overallheat in the issue being discussed.
We findsensitive issues like abortion and socialismbeing more heated than healthcare, Obama,etc.3.
The percentage of intolerant users increaseswith the expected overall disagreement in theissue except for the issue Obama euphoria.4.
The estimated tipping point of disagreementto exhibit intolerance, ?
happens to vary in-versely with the expected disagreement,????,?,??????
?
except the issue Obama euphoria.This reflects that as overall disagreement inthe issue increases, the tipping point of intol-erance decreases, i.e., due to high discussionheat, people are likely to turn intolerant evenwith relatively small amount of disagreement.This finding dovetails with prior studies inpsychology (Rokeach and Fruchter, 1956) thatheated discussions are likely to reduce thresh-7 Although this prediction may not be perfect, it can beregarded as considerably reliable to study the trend of toler-ance across different issues as our classifier (in ?6.1) attainsa high (83%) classification accuracy using the full featureset.
As judging all users across all threads would requirereading about 7000 posts, for confirmation, we randomlysampled 30 authors across various threads for labeling byour judges.
28 out of 30 predictions produced by the classi-fier correlated with the judges' labels, which should be suf-ficiently accurate for our analysis.olds of reception leading to dogmatism, ego-tism, and intolerance.
Table 6 shows that formoderately heated issues (healthcare, Eu-rope?s collapse), in expectation, author?s dis-agreement ??,??????
should exceed 61-65% toexhibit intolerance.
However, for sensitive is-sues, we find that the tipping point is muchlower, abortion: 37%; socialism: 48%.5.
The issue Obama Euphoria is an exception toother issues?
trends.
Even though in expecta-tion, it has ????,?,??????
?
= 66% overall disa-greement, the percentage of intolerant usersremains the lowest (30%) and the tippingpoint attains a highest value (?
= 0.71), show-ing more tolerance on the issue.
A plausiblereason could be that Obama is somewhat moreliked and hence attracts less intolerance fromusers8.6.
The p-values of the estimated tipping points, ?across all issues are statistically significant at98-99% confidence levels.7 ConclusionThis work performed a deep analysis of the soci-opsychological and psycholinguistic phenome-non of tolerance in online discussions, which isan important concept in the field of communica-tions.
A novel framework is proposed, which iscapable of characterizing and classifying toler-ance in online discussions.
Further, a novel tech-nique was also proposed to quantitatively evalu-ate the interplay of tolerance and disagreement.Our empirical results using real-life online dis-cussions render key insights into the psycholin-guistic process of tolerance and dovetail withexisting theories in psychology and communica-tions.
To the best of our knowledge, this is thefirst such quantitative study.
In our future work,we want to further this research and study therole of diversity of opinions in the context oftolerance and its relation to polarization.AcknowledgmentsThis work was supported in part by a grant fromNational Science Foundation (NSF) under grantno.
IIS-1111092.8 This observation may be linked to the political phenome-non of ?democratic citizenship through exposure to diverseperspectives?
(Mutz, 2006) where it was shown that expo-sure to heterogeneous opinions (i.e., greater disagreement),often enhances tolerance.1688ReferencesAbu-Jbara, A., Dasigi, P., Diab, M. and DragomirRadev.
2012.
Subgroup detection in ideologicaldiscussions.
ACL.Agrawal, R. Rajagopalan, S. Srikant, R. Xu.
Y.
2003.Mining newsgroups using networks arising fromsocial behavior.
WWW.Bansal, M., Cardie, C., and Lee, L. 2008.
The powerof negative thinking: Exploiting label disagreementin the min-cut classification framework.
In COL-ING.Blei, D., A. Ng,  and M. Jordan.
2003.
Latent Di-richlet Allocation.
In JMLR.Boyer, K.; Grafsgaard, J.; Ha, E. Y.; Phillips, R.; andLester, J.
2011.
An affect-enriched dialogue actclassification model for task-oriented dialogue.
InACL.Burfoot, C.,  S. Bird,  and T. Baldwin.
2011.
Collec-tive Classification of Congressional Floor-DebateTranscripts.
In ACL.Cappella, J. N., Price, V., and Nir, L. 2002.
Argumentrepertoire as a reliable and valid measure ofopinion quality: electronic dialogue duringcampaign 2000.
Political Communication.
PoliticalCommunication.Chen, Z., Mukherjee, A., Liu, B., Hsu, M.,Castellanos, M., Ghosh, R. 2013.
LeveragingMulti-Domain Prior Knowledge in Topic Models.In IJCAI.Chung, C. K., and Pennebaker, J. W. 2007.
Revealingpeople?s thinking in natural language: Using anautomated meaning extraction method in open?ended self?descriptions,.
J. of Research inPersonality.Choi, Y. and Cardie, C. 2010.
Hierarchical sequentiallearning for extracting opinions and their attributes.In ACL.Critchley, M. 1964.
The neurology of psychoticspeech.
The British Journal of Psychiatry.Crocker, D. A.
2005.
Tolerance and DeliberativeDemocracy.
UMD Technical Report.Dahlgren, P. 2002.
In search of the talkative public:Media, deliberative democracy and civic culture.Javnost/The Public.Dahlgren, Peter.
2005.
The Internet, Public Spheres,and Political Communication: Dispersion andDeliberation.
Political Communication.Escobar, O.
2012.
Public Dialogue and Deliberation:A communication perspective forpublicengagement practitioners.
Handbook andTechnical Report.Fayyad, U., and Irani, K. 1993.
Multi-intervaldiscretization of continuous-valued attributes forclassification learning.
In UAI.Fishkin, J.
1991.
Democracy and deliberation.
NewHaven, CT: Yale University Press.Flor, M., and Hadar, U.
2005.
The production ofmetaphoric expressions in spontaneous speech: Acontrolled-setting experiment.
Metaphor andSymbol.Galley, M.,  K.  McKeown, J. Hirschberg,  E.Shriberg.
2004.
Identifying agreement anddisagreement in conversational speech: Use ofBayesian networks to model pragmaticdependencies.
In ACL.Gastil, J.
2005.
Communication as Deliberation: ANon-Deliberative Polemic on CommunicationTheory.
Univ.
of  Washington, Technical Report.Gastil, J., and Dillard, J. P. 1999.
Increasing politicalsophistication through public deliberation.
PoliticalCommunication.Gastil, John.
2007.
Political communication anddeliberation.
Sage Publications.Griffiths, T. and Steyvers, M. 2004.
Finding scientifictopics.
In PNAS.Gutmann, A., and Thompson, D. F. 1996.
Democracyand disagreement.
Harvard University Press.Habermas.
1984.
The theory of communicativeaction: Reason and rationalization of society.
(T.McCarthy, Trans.
Vol.
1).
Boston, MA: BeaconPress.Hillard, D., Ostendorf, M., and Shriberg, E. 2003.Detection of Agreement vs.
Disagreement inMeetings: Training with Unlabeled Data.
HLT-NAACL.Hansen, G. J., and Hyunjung, K. 2011.
Is the mediabiased against me?
A meta-analysis of the hostilemedia effect research.
Communication ResearchReports, 28, 169-179.Hassan, A. and Radev, D. 2010.
Identifying textpolarity using random walks.In ACL.Hofmann, T. 1999.
Probabilistic latent semanticanalysis.
In UAI.Hu, M. and Liu, B.
2004.
Mining and summarizingcustomer reviews.
In SIGKDD.Joachims, T. Making large-Scale SVM LearningPractical.
Advances in Kernel Methods - SupportVector Learning, B. Sch?lkopf and C. Burges andA.
Smola (ed.
), MIT-Press, 1999.Kim, S. and Hovy, E. 2007.
Crystal: Analyzingpredictive opinions on the web.
In EMNLP-CoNLL.Landis, J. R. and Koch, G. G. 1977.
Themeasurement of observer agreement for categoricaldata.
Biometrics, 159?174.Lin, W. H., and Hauptmann, A.
2006.
Are thesedocuments written from different perspectives?
: atest of different perspectives based on statisticaldistribution divergence.
In ACL.Liu, B.
2012.
Sentiment Analysis and Opinion Min-ing.
Morgan & Claypool Publisher, USA.Luskin, R. C., Fishkin, J. S., and Iyengar, S. 2004.Considered Opinions on U.S. Foreign Policy: Face-to-Face versus Online Deliberative Polling.International Communication Association, NewOrleans, LA.Mayfield, E. and Rose, C. P. 2011.
RecognizingAuthority in Dialogue with an Integer LinearProgramming Constrained Model.
In ACL.Moxey, L. M., and Sanford, A. J.
2000.Communicating quantities: A review ofpsycholinguistic evidence of how expressionsdetermine perspectives.
Applied CognitivePsychology.Morbini, F. and Sagae, K. 2011.
Joint Identificationand Segmentation of Domain-Specific DialogueActs for Conversational Dialogue Systems.
In ACL.1689Murakami,  A.,  and Raymond, R. 2010.
Support orOppose?
Classifying Positions in Online Debatesfrom Reply Activities and Opinion Expressions.
InCOLING.Mukherjee, A. and Liu, B.
2013.
Discovering UserInteractions in Ideological Discussions.
In ACL.Mukherjee, A. and Liu, B.
2012a.
MiningContentions from Discussions and Debates.
InKDD.Mukherjee, A. and Liu, B.
2012b.
Modeling reviewComments.
In ACL.Mukherjee, A. and Liu, B.
2012c.
Aspect Extractionthrough Semi-Supervised Modeling.
In ACL.Mukherjee, A. and Liu, B.
2012d.
Analysis ofLinguistic Style Accommodation in OnlineDebates.
In COLING.Mutz, D. 2006.
Hearing the Other Side: DeliberativeVersus Participatory Democracy.
Cambridge:Cambridge University Press, 2006.Pang, B. and Lee, L. 2008.
Opinion mining andsentiment analysis.
Foundations and Trends inInformation Retrieval.Pennebaker, J. W., Chung, C. K., Ireland, M.,Gonzales, A., and Booth, R. J.
2007.
Thedevelopment and psychometric properties ofLIWC2007.
LIWC.Net.Popescu, A. and Etzioni, O.
2005.
Extracting productfeatures and opinions from reviews.
In EMNLP.Price, V., Cappella, J. N., and Nir, L. 2002.
Doesdisagreement contribute to more deliberativeopinion?
Political Communication.Rokeach, M., and Fruchter, B.
1956.
A factorial studyof dogmatism and related concepts.
The Journal ofAbnormal and Social Psychology.Ryfe, D. M. (2005).
Does deliberative democracywork?
Annual review of political science.Slavin, M. O., and Kriegman, D. 1992.
The adaptivedesign of the human psyche: Psychoanalysis,evolutionary biology, and the therapeutic process.Guilford Press.Somasundaran, S., J. Wiebe.
2009.
Recognizingstances in online debates.
In ACL-IJCNLP.Stromer-Galley, J.
2005.
Conceptualizing andMeasuring Coherence in Online Chat.
AnnualMeeting of the International CommunicationAssociation.Sunstein, C. R. 2002.
The law of group polarization.Journal of political philosophy.Thomas, M.,  B.  Pang and  L.  Lee.
2006.
Get out thevote: Determining support or opposition fromCongressional floor-debate transcripts.
In EMNLP.Wang, L., Lui, M., Kim, S. N., Nivre, J., andBaldwin, T. 2011.
Predicting thread discoursestructure over technical web forums.
In EMNLP.Wiebe, J.
2000.
Learning subjective adjectives fromcorpora.
In Proc.
of National Conference on AI.Yessenalina, A., Yue, A., Cardie, C. 2010.
Multi-level structured models for document-levelsentiment classification.
In EMNLP.Zhao, X.,  J.  Jiang, H. Yan,  and X.  Li.
2010.
Jointlymodeling aspects and opinions with a MaxEnt-LDA hybrid.
In EMNLP.Zingo, M. T. (1998).
Sex/gender Outsiders, HateSpeech, and Freedom of Expression: Can They Saythat about Me?
Praeger Publishers.1690
