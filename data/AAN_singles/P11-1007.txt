Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 62?71,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsDomain Adaptation by Constraining Inter-Domain Variabilityof Latent Feature RepresentationIvan TitovSaarland UniversitySaarbruecken, Germanytitov@mmci.uni-saarland.deAbstractWe consider a semi-supervised setting for do-main adaptation where only unlabeled data isavailable for the target domain.
One way totackle this problem is to train a generativemodel with latent variables on the mixture ofdata from the source and target domains.
Sucha model would cluster features in both do-mains and ensure that at least some of the la-tent variables are predictive of the label on thesource domain.
The danger is that these pre-dictive clusters will consist of features specificto the source domain only and, consequently,a classifier relying on such clusters would per-form badly on the target domain.
We in-troduce a constraint enforcing that marginaldistributions of each cluster (i.e., each latentvariable) do not vary significantly across do-mains.
We show that this constraint is effec-tive on the sentiment classification task (Panget al, 2002), resulting in scores similar tothe ones obtained by the structural correspon-dence methods (Blitzer et al, 2007) withoutthe need to engineer auxiliary tasks.1 IntroductionSupervised learning methods have become a stan-dard tool in natural language processing, and largetraining sets have been annotated for a wide vari-ety of tasks.
However, most learning algorithms op-erate under assumption that the learning data orig-inates from the same distribution as the test data,though in practice this assumption is often violated.This difference in the data distributions normally re-sults in a significant drop in accuracy.
To addressthis problem a number of domain-adaptation meth-ods has recently been proposed (see e.g., (Daume?and Marcu, 2006; Blitzer et al, 2006; Bickel et al,2007)).
In addition to the labeled data from thesource domain, they also exploit small amounts oflabeled data and/or unlabeled data from the targetdomain to estimate a more predictive model for thetarget domain.In this paper we focus on a more challengingand arguably more realistic version of the domain-adaptation problem where only unlabeled data isavailable for the target domain.
One of the mostpromising research directions on domain adaptationfor this setting is based on the idea of inducing ashared feature representation (Blitzer et al, 2006),that is mapping from the initial feature representa-tion to a new representation such that (1) examplesfrom both domains ?look similar?
and (2) an accu-rate classifier can be trained in this new representa-tion.
Blitzer et al (2006) use auxiliary tasks basedon unlabeled data for both domains (called pivot fea-tures) and a dimensionality reduction technique toinduce such shared representation.
The success oftheir domain-adaptation method (Structural Corre-spondence Learning, SCL) crucially depends on thechoice of the auxiliary tasks, and defining them canbe a non-trivial engineering problem for many NLPtasks (Plank, 2009).
In this paper, we investigatemethods which do not use auxiliary tasks to inducea shared feature representation.We use generative latent variable models (LVMs)learned on all the available data: unlabeled data forboth domains and on the labeled data for the sourcedomain.
Our LVMs use vectors of latent features62to represent examples.
The latent variables encoderegularities observed on unlabeled data from bothdomains, and they are learned to be predictive ofthe labels on the source domain.
Such LVMs canbe regarded as composed of two parts: a mappingfrom initial (normally, word-based) representationto a new shared distributed representation, and alsoa classifier in this representation.
The danger of thissemi-supervised approach in the domain-adaptationsetting is that some of the latent variables will cor-respond to clusters of features specific only to thesource domain, and consequently, the classifier re-lying on this latent variable will be badly affectedwhen tested on the target domain.
Intuitively, onewould want the model to induce only those featureswhich generalize between domains.
We encode thisintuition by introducing a term in the learning ob-jective which regularizes inter-domain difference inmarginal distributions of each latent variable.Another, though conceptually similar, argumentfor our method is coming from theoretical re-sults which postulate that the drop in accuracy ofan adapted classifier is dependent on the discrep-ancy distance between the source and target do-mains (Blitzer et al, 2008; Mansour et al, 2009;Ben-David et al, 2010).
Roughly, the discrepancydistance is small when linear classifiers cannot dis-tinguish between examples from different domains.A necessary condition for this is that the feature ex-pectations do not vary significantly across domains.Therefore, our approach can be regarded as mini-mizing a coarse approximation of the discrepancydistance.The introduced term regularizes model expecta-tions and it can be viewed as a form of a general-ized expectation (GE) criterion (Mann and McCal-lum, 2010).
Unlike the standard GE criterion, wherea model designer defines the prior for a model ex-pectation, our criterion postulates that the model ex-pectations should be similar across domains.In our experiments, we use a form of HarmoniumModel (Smolensky, 1986) with a single layer of bi-nary latent variables.
Though exact inference withthis class of models is infeasible we use an effi-cient approximation (Bengio and Delalleau, 2007),which can be regarded either as a mean-field approx-imation to the reconstruction error or a determinis-tic version of the Contrastive Divergence samplingmethod (Hinton, 2002).
Though such an estimatoris biased, in practice, it yields accurate models.
Weexplain how the introduced regularizer can be inte-grated into the stochastic gradient descent learningalgorithm for our model.We evaluate our approach on adapting sentimentclassifiers on 4 domains: books, DVDs, electronicsand kitchen appliances (Blitzer et al, 2007).
Theloss due to transfer to a new domain is very sig-nificant for this task: in our experiments it wasapproaching 9%, in average, for the non-adaptedmodel.
Our regularized model achieves 35% aver-age relative error reduction with respect to the non-adapted classifier, whereas the non-regularized ver-sion demonstrates a considerably smaller reductionof 26%.
Both the achieved error reduction and theabsolute score match the results reported in (Blitzeret al, 2007) for the best version1 of the SCL method(SCL-MI, 36%), suggesting that our approach is aviable alternative to SCL.The rest of the paper is structured as follows.
InSection 2 we introduce a model which uses vec-tors of latent variables to model statistical dependen-cies between the elementary features.
In Section 3we discuss its applicability in the domain-adaptationsetting, and introduce constraints on inter-domainvariability as a way to address the discovered lim-itations.
Section 4 describes approximate learningand inference algorithms used in our experiments.In Section 5 we provide an empirical evaluation ofthe proposed method.
We conclude in Section 6 withfurther examination of the related work.2 The Latent Variable ModelThe adaptation method advocated in this paper is ap-plicable to any joint probabilistic model which usesdistributed representations, i.e.
vectors of latentvariables, to abstract away from hand-crafted fea-tures.
These models, for example, include RestrictedBoltzmann Machines (Smolensky, 1986; Hinton,2002) and Sigmoid Belief Networks (SBNs) (Saulet al, 1996) for classification and regression tasks,Factorial HMMs (Ghahramani and Jordan, 1997)for sequence labeling problems, Incremental SBNsfor parsing problems (Titov and Henderson, 2007a),1Among the versions which do not exploit labeled data fromthe target domain.63as well as different types of Deep Belief Net-works (Hinton and Salakhutdinov, 2006).
Thepower of these methods is in their ability to automat-ically construct new features from elementary onesprovided by the model designer.
This feature induc-tion capability is especially desirable for problemswhere engineering features is a labor-intensive pro-cess (e.g., multilingual syntactic parsing (Titov andHenderson, 2007b)), or for multitask learning prob-lems where the nature of interactions between thetasks is not fully understood (Collobert and Weston,2008; Gesmundo et al, 2009).In this paper we consider classification tasks,namely prediction of sentiment polarity of a user re-view (Pang et al, 2002), and model the joint distri-bution of the binary sentiment label y ?
{0, 1} andthe multiset of text features x, xi ?
X .
The hiddenvariable vector z (zi ?
{0, 1}, i = 1, .
.
.
,m) en-codes statistical dependencies between componentsof x and also dependencies between the label y andthe featuresx.
Intuitively, the model can be regardedas a logistic regression classifier with latent features.The model assumes that the features and the latentvariable vector are generated jointly from a globally-normalized model and then the label y is gener-ated from a conditional distribution dependent onz.
Both of these distributions, P (x, z) and P (y|z),are parameterized as log-linear models and, conse-quently, our model can be seen as a combination ofan undirected Harmonium model (Smolensky, 1986)and a directed SBN model (Saul et al, 1996).
Theformal definition is as follows:(1) Draw (x, z) ?
P (x, z|v),(2) Draw label y ?
?
(w0 +?mi=1 wizi),where v and w are parameters, ?
is the logistic sig-moid function, ?
(t) = 1/(1 + e?t), and the jointdistribution of (x, z) is given by the Gibbs distribu-tion:P (x, z|v) ?
exp(|x|?j=1vxj0+n?i=1v0izi+|x|,n?j,i=1vxjizi).Figure 1 presents the corresponding graphicalmodel.
Note that the arcs between x and z are undi-rected, whereas arcs between y and z are directed.The parameters of this model ?
= (v,w) can beestimated by maximizing joint likelihood L(?)
oflabeled data for the source domain {x(l), y(l)}l?SL......xzyvwFigure 1: The latent variable model: x, z, y are randomvariables, dependencies between x and z are parameter-ized by matrix v, and dependencies between z and y - byvector w.and unlabeled data for the source and target domain{x(l)}l?SU?TU , where SU and TU stand for the un-labeled datasets for the source and target domains,respectively.
However, given that, first, amount ofunlabeled data |SU ?
TU | normally vastly exceedsthe amount of labeled data |SL| and, second, thenumber of features for each example |x(l)| is usuallylarge, the label y will have only a minor effect onthe mapping from the initial features x to the latentrepresentation z (i.e.
on the parameters v).
Conse-quently, the latent representation induced in this wayis likely to be inappropriate for the classification taskin question.
Therefore, we follow (McCallum et al,2006) and use a multi-conditional objective, a spe-cific form of hybrid learning, to emphasize the im-portance of labels y:L(?, ?)=?
?l?SLlogP (y(l)|x(l), ?
)+?l?SU?TU?SLlogP (x(l)|?
),where ?
is a weight, ?
> 1.Direct maximization of the objective is prob-lematic, as it would require summation over allthe 2m latent vectors z.
Instead we use a mean-field approximation.
Similarly, an efficient ap-proximate inference algorithm is used to computeargmaxy P (y|x, ?)
at testing time.
The approxima-tions are described in Section 4.3 Constraints on Inter-Domain VariabilityAs we discussed in the introduction, our goal isto provide a method for domain adaptation basedon semi-supervised learning of models with dis-tributed representations.
In this section, we first dis-cuss the shortcomings of domain adaptation withthe above-described semi-supervised approach andmotivate constraints on inter-domain variability of64the induced shared representation.
Then we pro-pose a specific form of this constraint based on theKullback-Leibler (KL) divergence.3.1 Motivation for the ConstraintsEach latent variable zi encodes a cluster or a com-bination of elementary features xj .
At least someof these clusters, when induced by maximizing thelikelihood L(?, ?)
with sufficiently large ?, will beuseful for the classification task on the source do-main.
However, when the domains are substan-tially different, these predictive clusters are likelyto be specific only to the source domain.
For ex-ample, consider moving from reviews of electronicsto book reviews: the cluster of features related toequipment reliability and warranty service will notgeneralize to books.
The corresponding latent vari-able will always be inactive on the books domain(or always active, if negative correlation is inducedduring learning).
Equivalently, the marginal distri-bution of this variable will be very different for bothdomains.
Note that the classifier, defined by the vec-torw, is only trained on the labeled source examples{x(l), y(l)}l?SL and therefore it will rely on such la-tent variables, even though they do not generalizeto the target domain.
Clearly, the accuracy of suchclassifier will drop when it is applied to target do-main examples.
To tackle this issue, we introduce aregularizing term which penalizes differences in themarginal distributions between the domains.In fact, we do not need to consider the behaviorof the classifier to understand the rationale behindthe introduction of the regularizer.
Intuitively, whenadapting between domains, we are interested in rep-resentations z which explain domain-independentregularities rather than in modeling inter-domaindifferences.
The regularizer favors models which fo-cus on the former type of phenomena rather than thelatter.Another motivation for the form of regularizationwe propose originates from theoretical analysis ofthe domain adaptation problems (Ben-David et al,2010; Mansour et al, 2009; Blitzer et al, 2007).Under the assumption that there exists a domain-independent scoring function, these analyses showthat the drop in accuracy is upper-bounded by thequantity called discrepancy distance.
The discrep-ancy distance is dependent on the feature represen-tation z, and the input distributions for both domainsPS(z) and PT (z), and is defined asdz(S,T )=maxf,f ?|EPS [f(z)6=f?
(z)]?EPT [f(z)6=f?
(z)]|,where f and f ?
are arbitrary linear classifiersin the feature representation z.
The quantityEP [f(z)6=f ?
(z)] measures the probability mass as-signed to examples where f and f ?
disagree.
Thenthe discrepancy distance is the maximal change inthe size of this disagreement set due to transfer be-tween the domains.
For a more restricted class ofclassifiers which rely only on any single feature2zi, the distance is equal to the maximum over thechange in the distributions P (zi).
Consequently, forarbitrary linear classifiers we have:dz(S,T ) ?
maxi=1,...,m|EPS [zi = 1]?
EPT [zi = 1]|.It follows that low inter-domain variability of themarginal distributions of latent variables is a neces-sary condition for low discrepancy distance.
Min-imizing the difference in the marginal distributionscan be regarded as a coarse approximation to theminimization of the distance.
However, we haveto concede that the above argument is fairly infor-mal, as the generalization bounds do not directlyapply to our case: (1) our feature representationis learned from the same data as the classifier, (2)we cannot guarantee that the existence of a domain-independent scoring function is preserved under thelearned transformation x?z and (3) in our settingwe have access not only to samples from P (z|x, ?
)but also to the distribution itself.3.2 The Expectation CriterionThough the above argument suggests a specific formof the regularizing term, we believe that the penal-izer should not be very sensitive to small differ-ences in the marginal distributions, as useful vari-ables (clusters) are likely to have somewhat differ-ent marginal distributions in different domains, butit should severely penalize extreme differences.To achieve this goal we instead propose to use thesymmetrized Kullback-Leibler (KL) divergence be-tween the marginal distributions as the penalty.
The2We consider only binary features here.65derivative of the symmetrized KL divergence is largewhen one of the marginal distributions is concen-trated at 0 or 1 with another distribution still havinghigh entropy, and therefore such configurations areseverely penalized.3 Formally, the regularizer G(?
)is defined asG(?)
=m?i=1D(PS(zi|?
)||PT (zi|?
))+D(PT (zi|?)||PS(zi|?
)), (1)where PS(zi) and PT (zi) stand for the training sam-ple estimates of the marginal distributions of latentfeatures, for instance:PT (zi = 1|?)
=1|TU |?l?TUP (zi = 1|x(l), ?
).We augment the multi-conditional log-likelihoodL(?, ?)
with the weighted regularization term G(?
)to get the composite objective function:LR(?, ?, ?)
= L(?, ?)?
?G(?
), ?
> 0.Note that this regularization term can be regardedas a form of the generalized expectation (GE) crite-ria (Mann and McCallum, 2010), where GE criteriaare normally defined as KL divergences between aprior expectation of some feature and the expecta-tion of this feature given by the model, where theprior expectation is provided by the model designeras a form of weak supervision.
In our case, both ex-pectations are provided by the model but on differentdomains.Note that the proposed regularizer can be triviallyextended to support the multi-domain case (Mansouret al, 2008) by considering symmetrized KL diver-gences for every pair of domains or regularizing thedistributions for every domain towards their average.More powerful regularization terms can also bemotivated by minimization of the discrepancy dis-tance but their optimization is likely to be expensive,whereas LR(?, ?, ?)
can be optimized efficiently.3An alternative is to use the Jensen-Shannon (JS) diver-gence, however, our preliminary experiments seem to suggestthat the symmetrized KL divergence is preferable.
Though thetwo divergences are virtually equivalent when the distributionsare very similar (their ratio tends to a constant as the distribu-tions go closer), the symmetrized KL divergence stronger penal-izes extreme differences and this is important for our purposes.4 Learning and InferenceIn this section we describe an approximate learningalgorithm based on the mean-field approximation.Though we believe that our approach is independentof the specific learning algorithm, we provide the de-scription for completeness.
We also describe a sim-ple approximate algorithm for computing P (y|x, ?
)at test time.The stochastic gradient descent algorithm iter-ates over examples and updates the weight vectorbased on the contribution of every considered exam-ple to the objective function LR(?, ?, ?).
To com-pute these updates we need to approximate gradientsof ??
logP (y(l)|x(l), ?)
(l ?
SL), ??
logP (x(l)|?
)(l ?
SL ?
SU ?
TU ) as well as to estimate the con-tribution of a given example to the gradient of theregularizer??G(?).
In the next sections we will de-scribe how each of these terms can be estimated.4.1 Conditional Likelihood TermWe start by explaining the mean-field approximationof logP (y|x, ?).
First, we compute the means ?
=(?1, .
.
.
, ?m):?i = P (zi = 1|x,v) = ?
(v0i +?|x|j=1 vxji).Now we can substitute them instead of z to approx-imate the conditional probability of the label:P (y = 1|x, ?)
=?z P (y|z,w)P (z|x,v)?
?
(w0 +?mi=1wi?i).We use this estimate both at testing time and alsoto compute gradients ??
logP (y(l)|x(l), ?)
duringlearning.
The gradients can be computed efficientlyusing a form of back-propagation.
Note that withthis approximation, we do not need to normalizeover the feature space, which makes the model veryefficient at classification time.This approximation is equivalent to the computa-tion of the two-layer perceptron with the soft-maxactivation function (Bishop, 1995).
However, theabove derivation provides a probabilistic interpreta-tion of the hidden layer.4.2 Unlabeled Likelihood TermIn this section, we describe how the unlabeled like-lihood term is optimized in our stochastic learning66algorithm.
First, we note that, given the directednature of the arcs between z and y, the weightsw do not affect the probability of input x, that isP (x|?)
= P (x|v).Instead of directly approximating the gradient?v logP (x(l)|v), we use a deterministic version ofthe Contrastive Divergence (CD) algorithm, equiv-alent to the mean-field approximation of the recon-struction error used in training autoassociaters (Ben-gio and Delalleau, 2007).
The CD-based estimatorsare biased estimators but are guaranteed to converge.Intuitively, maximizing the likelihood of unlabeleddata is closely related to minimizing the reconstruc-tion error, that is training a model to discover suchmapping parameters u that z encodes all the neces-sary information to accurately reproduce x(l) from zfor every training example x(l).
Formally, the mean-field approximation to the negated reconstruction er-ror is defined asL?
(x(l),v) = logP (x(l)|?,v),where the means, ?i = P (zi = 1|x(l),v), are com-puted as in the preceding section.
Note that whencomputing the gradient of?vL?, we need to take intoaccount both the forward and backward mappings:the computation of the means ?
from x(l) and thecomputation of the log-probability of x(l) given themeans ?:dL?dvki=?L??vki+?L??
?id?idvki.4.3 Regularization TermThe criterion G(?)
is also independent of the classi-fier parametersw, i.e.
G(?)
= G(v), and our goal isto compute the contribution of a considered examplel to the gradient?vG(v).The regularizer G(v) is defined as in equation (1)and it is a function of the sample-based domain-specific marginal distributions of latent variables PSand PT :PT (zi = 1|?)
=1|TU |?l?TU?
(l)i ,where the means ?
(l)i = P (zi = 1|x(l),v); PS canbe re-written analogously.
G(v) is dependent on theparameters v only via the mean activations of thelatent variables ?
(l), and contribution of each exam-ple l can be computed by straightforward differenti-ation:dG(l)(v)dvki=(logpp??log1?
p1?
p??p?p+1?
p?1?
p)d?
(l)idvki,where p = PS(zi = 1|?)
and p?
= PT (zi = 1|?
)if l is from the source domain, and, inversely, p =PT (zi = 1|?)
and p?
= PS(zi = 1|?
), otherwise.One problem with the above expression is thatthe exact computation of PS and PT requires re-computation of the means ?
(l) for all the exam-ples after each update of the parameters, resultingin O(|SL ?
SU ?
TU |2) complexity of each iterationof stochastic gradient descent.
Instead, we shuffleexamples and use amortization; we approximate PSat update t by:P?
(t)S (zi = 1)={(1??)P?
(t?1)S (zi=1)+??
(l)i , l?SL?SUP?
(t?1)S (zi = 1), otherwise,where l is an example considered at update t. Theapproximation P?T is computed analogously.5 Empirical EvaluationIn this section we empirically evaluate our approachon the sentiment classification task.
We start withthe description of the experimental set-up and thebaselines, then we present the results and discuss theutility of the constraint on inter-domain variability.5.1 Experimental settingTo evaluate our approach, we consider the samedataset as the one used to evaluate the SCLmethod (Blitzer et al, 2007).
The dataset is com-posed of labeled and unlabeled reviews of four dif-ferent product types: books, DVDs, electronics andkitchen appliances.
For each domain, the datasetcontains 1,000 labeled positive reviews and 1,000 la-beled negative reviews, as well as several thousandsof unlabeled examples (4,919 reviews per domain inaverage: ranging from 3,685 for DVDs to 5,945 forkitchen appliances).
As in Blitzer et al (2007), werandomly split each labelled portion into 1,600 ex-amples for training and 400 examples for testing.6770758085Books70.872.774.776.575.683.3DVD Electronics Kitchen AverageBaseNoRegRegReg+In-domain73.374.674.876.275.482.877.675.673.976.677.978.884.6NoReg+74.676.078.980.285.879.077.783.282.180.086.5Figure 2: Averages accuracies when transferring to books, DVD, electronics and kitchen appliances domains, andaverage accuracy over all 12 domain pairs.We evaluate the performance of our domain-adaptation approach on every ordered pair of do-mains.
For every pair, the semi-supervised meth-ods use labeled data from the source domain andunlabeled data from both domains.
We comparethem with two supervised methods: a supervisedmodel (Base) which is trained on the source do-main data only, and another supervised model (In-domain) which is learned on the labeled data fromthe target domain.
The Base model can be regardedas a natural baseline model, whereas the In-domainmodel is essentially an upper-bound for any domain-adaptation method.
All the methods, supervised andsemi-supervised, are based on the model describedin Section 2.Instead of using the full set of bigram and unigramcounts as features (Blitzer et al, 2007), we use a fre-quency cut-off of 30 to remove infrequent ngrams.This does not seem to have an adverse effect on theaccuracy but makes learning very efficient: the av-erage training time for the semi-supervised methodswas about 20 minutes on a standard PC.We coarsely tuned the parameters of the learningmethods using a form of cross-validation.
Both theparameter of the multi-conditional objective ?
(seeSection 2) and the weighting for the constraint ?
(seeSection 3.2) were set to 5.
We used 25 iterations ofstochastic gradient descent.
The initial learning rateand the weight decay (the inverse squared varianceof the Gaussian prior) were set to 0.01, and both pa-rameters were reduced by the factor of 2 every it-eration the objective function estimate went down.The size of the latent representation was equal to 10.The stochastic weight updates were amortized withthe momentum (?)
of 0.99.We trained the model both without regularizationof the domain variability (NoReg, ?
= 0), and withthe regularizing term (Reg).
For the SCL methodto produce an accurate classifier for the target do-main it is necessary to train a classifier using both theinduced shared representation and the initial non-transformed representation.
In our case, due to jointlearning and non-convexity of the learning problem,this approach would be problematic.4 Instead, wecombine predictions of the semi-supervised mod-els Reg and NoReg with the baseline out-of-domainmodel (Base) using the product-of-experts combina-tion (Hinton, 2002), the corresponding methods arecalled Reg+ and NoReg+, respectively.In all our models, we augmented the vector z withan additional component set to 0 for examples in thesource domain and to 1 for the target domain exam-ples.
In this way, we essentially subtracted a un-igram domain-specific model from our latent vari-able model in the hope that this will further reducethe domain dependence of the rest of the model pa-rameters.
In preliminary experiments, this modifica-tion was beneficial for all the models including thenon-constrained one (NoReg).5.2 Results and DiscussionThe results of all the methods are presented in Fig-ure 2.
The 4 leftmost groups of results correspondto a single target domain, and therefore each of4The latent variables are not likely to learn any useful map-ping in the presence of observable features.
Special trainingregimes may be used to attempt to circumvent this problem.68them is an average over experiments on 3 domain-pairs, for instance, the group Books represents anaverage over adaptation experiments DVDs?books,electronics?books, kitchen?books.
The rightmostgroup of the results corresponds to the average overall 12 experiments.
First, observe that the total dropin the accuracy when moving to the target domain is8.9%: from 84.6% demonstrated by the In-domainclassifier to 75.6% shown by the non-adapted Baseclassifier.
For convenience, we also present the er-rors due to transfer in a separate Table 1: our bestmethod (Reg+) achieves 35% relative reduction ofthis loss, decreasing the gap to 5.7%.Now, let us turn to the question of the utility of theconstraints.
First, observe that the non-regularizedversion of the model (NoReg) often fails to outper-form the baseline and achieves the scores consider-ably worse than the results of the regularized ver-sion (2.6% absolute difference).
We believe thatthis happens because the clusters induced when opti-mizing the non-regularized learning objective are of-ten domain-specific.
The regularized model demon-strates substantially better results slightly beatingthe baseline in most cases.
Still, to achieve alarger decrease of the domain-adaptation error, itwas necessary to use the combined models, Reg+and NoReg+.
Here, again, the regularized modelsubstantially outperforms the non-regularized one(35% against 26% relative error reduction for Reg+and NoReg+, respectively).In Table 1, we also compare the results ofour method with the results of the best ver-sion of the SCL method (SCL-MI) reportedin Blitzer et al (2007).
The average error reduc-tions for our method Reg+ and for the SCL methodare virtually equal.
However, formally, these twonumbers are not directly comparable.
First, the ran-dom splits are different, though this is unlikely toresult in any significant difference, as the split pro-portions are the same and the test sets are suffi-ciently large.
Second, the absolute scores achievedin Blitzer et al (2007) are slightly worse than thosedemonstrated in our experiments both for supervisedand semi-supervised methods.
In absolute terms,our Reg+ method outperforms the SCL method bymore than 1%: 75.6% against 74.5%, in average.This is probably due to the difference in the usedlearning methods: optimization of the Huber loss vs.D Base NoReg Reg NoReg+ Reg+ SCL-MIB 10.6 12.4 7.7 8.6 6.7 5.8D 9.5 8.2 8.0 6.6 7.3 6.1E 8.2 13.0 9.7 6.8 5.5 5.5K 7.5 8.8 6.5 4.4 3.3 5.6Av 8.9 10.6 8.0 6.6 5.7 5.8Table 1: Drop in the accuracy score due to the transferfor the 4 domains: (B)ooks, (D)VD, (E)electronics and(K)itchen appliances, and in average over the domains.our latent variable model.5 This comparison sug-gests that our domain-adaptation method is a viablealternative to SCL.Also, it is important to point out that the SCLmethod uses auxiliary tasks to induce the sharedfeature representation, these tasks are constructedon the basis of unlabeled data.
The auxiliary tasksand the original problem should be closely related,namely they should have the same (or similar) setof predictive features.
Defining such tasks can bea challenging engineering problem.
On the senti-ment classification task in order to construct themtwo steps need to be performed: (1) a set of wordscorrelated with the sentiment label is selected, and,then (2) prediction of each such word is regarded adistinct auxiliary problem.
For many other domains(e.g., parsing (Plank, 2009)) the construction of aneffective set of auxiliary tasks is still an open prob-lem.6 Related WorkThere is a growing body of work on domain adapta-tion.
In this paper, we focus on the class of meth-ods which induce a shared feature representation.Another popular class of domain-adaptation tech-niques assume that the input distributions P (x) forthe source and the target domain share support, thatis every example x which has a non-zero probabil-ity on the target domain must have also a non-zeroprobability on the source domain, and vice-versa.Such methods tackle domain adaptation by instancere-weighting (Bickel et al, 2007; Jiang and Zhai,2007), or, similarly, by feature re-weighting (Sat-pal and Sarawagi, 2007).
In NLP, most features5The drop in accuracy for the SCL method in Table 1 is iscomputed with respect to the less accurate supervised in-domainclassifier considered in Blitzer et al (2007), otherwise, the com-puted drop would be larger.69are word-based and lexicons are very different fordifferent domains, therefore such assumptions arelikely to be overly restrictive.Various semi-supervised techniques for domain-adaptation have also been considered, one examplebeing self-training (McClosky et al, 2006).
How-ever, their behavior in the domain-adaptation set-ting is not well-understood.
Semi-supervised learn-ing with distributed representations and its applica-tion to domain adaptation has previously been con-sidered in (Huang and Yates, 2009), but no attempthas been made to address problems specific to thedomain-adaptation setting.
Similar approaches hasalso been considered in the context of topic mod-els (Xue et al, 2008), however the preference to-wards induction of domain-independent topics wasnot explicitly encoded in the learning objective ormodel priors.A closely related method to ours is thatof (Druck and McCallum, 2010) which performssemi-supervised learning with posterior regulariza-tion (Ganchev et al, 2010).
Our approach differsfrom theirs in many respects.
First, they do not fo-cus on the domain-adaptation setting and do not at-tempt to define constraints to prevent the model fromlearning domain-specific information.
Second, theirexpectation constraints are estimated from labeleddata, whereas we are trying to match expectationscomputed on unlabeled data for two domains.This approach bears some similarity to the adap-tation methods standard for the setting where la-belled data is available for both domains (Chelbaand Acero, 2004; Daume?
and Marcu, 2006).
How-ever, instead of ensuring that the classifier param-eters are similar across domains, we favor modelsresulting in similar marginal distributions of latentvariables.7 Discussion and ConclusionsIn this paper we presented a domain-adaptationmethod based on semi-supervised learning with dis-tributed representations coupled with constraints fa-voring domain-independence of modeled phenom-ena.
Our approach results in competitive domain-adaptation performance on the sentiment classifica-tion task, rivalling that of the state-of-the-art SCLmethod (Blitzer et al, 2007).
Both of these meth-ods induce a shared feature representation but un-like SCL our method does not require constructionof any auxiliary tasks in order to induce this repre-sentation.
The primary area of the future work is toapply our method to structured prediction problemsin NLP, such as syntactic parsing or semantic role la-beling, where construction of auxiliary tasks provedproblematic.
Another direction is to favor domain-invariability not only of the expectations of individ-ual variables but rather those of constraint functionsinvolving latent variables, features and labels.AcknowledgementsThe author acknowledges the support of the Clusterof Excellence on Multimodal Computing and Inter-action at Saarland University and thanks the anony-mous reviewers for their helpful comments and sug-gestions.ReferencesShai Ben-David, John Blitzer, Koby Crammer, AlexKulesza, Fernando Pereira, and Jennifer WortmanVaughan.
2010.
A theory of learning from differentdomains.
Machine Learning, 79:151?175.Yoshua Bengio and Olivier Delalleau.
2007.
Justify-ing and generalizing contrastive divergence.
Techni-cal Report TR 1311, Department IRO, University ofMontreal, November.S.
Bickel, M. Bru?eckner, and T. Scheffer.
2007.
Dis-criminative learning for differing training and test dis-tributions.
In Proc.
of the International Conference onMachine Learning (ICML), pages 81?88.Christopher M. Bishop.
1995.
Neural Networks for Pat-tern Recognition.
Oxford University Press, Oxford,UK.John Blitzer, Ryan McDonald, and Fernando Pereira.2006.
Domain adaptation with structural correspon-dence learning.
In Proc.
of EMNLP.John Blitzer, Mark Dredze, and Fernando Pereira.
2007.Biographies, bollywood, boom-boxes and blenders:Domain adaptation for sentiment classification.
InProc.
45th Meeting of Association for ComputationalLinguistics (ACL), Prague, Czech Republic.John Blitzer, Koby Crammer, Alex Kulesza, FernandoPereira, and Jennifer Wortman.
2008.
Learningbounds for domain adaptation.
In Proc.
Advances InNeural Information Processing Systems (NIPS ?07).Ciprian Chelba and Alex Acero.
2004.
Adaptation ofmaximum entropy capitalizer: Little data can help alot.
In Proc.
of the Conference on Empirical Meth-ods for Natural Language Processing (EMNLP), pages285?292.70R.
Collobert and J. Weston.
2008.
A unified architecturefor natural language processing: Deep neural networkswith multitask learning.
In International Conferenceon Machine Learning, ICML.Hal Daume?
and Daniel Marcu.
2006.
Domain adaptationfor statistical classifiers.
Journal of Artificial Intelli-gence, 26:101?126.Gregory Druck and Andrew McCallum.
2010.
High-performance semi-supervised learning using discrim-inatively constrained generative models.
In Proc.
ofthe International Conference on Machine Learning(ICML), Haifa, Israel.Kuzman Ganchev, Joao Graca, Jennifer Gillenwater, andBen Taskar.
2010.
Posterior regularization for struc-tured latent variable models.
Journal of MachineLearning Research (JMLR), pages 2001?2049.Andrea Gesmundo, James Henderson, Paola Merlo, andIvan Titov.
2009.
Latent variable model of syn-chronous syntactic-semantic parsing for multiple lan-guages.
In CoNLL 2009 Shared Task.Zoubin Ghahramani and Michael I. Jordan.
1997.
Fac-torial hidden Markov models.
Machine Learning,29:245?273.G.
E. Hinton and R. R. Salakhutdinov.
2006.
Reducingthe dimensionality of data with neural networks.
Sci-ence, 313:504?507.Geoffrey E. Hinton.
2002.
Training Products of Expertsby Minimizing Contrastive Divergence.
Neural Com-putation, 14:1771?1800.Fei Huang and Alexander Yates.
2009.
Distributionalrepresentations for handling sparsity in supervised se-quence labeling.
In Proceedings of the Annual Meet-ing of the Association for Computational Linguistics(ACL).Jing Jiang and ChengXiang Zhai.
2007.
Instance weight-ing for domain adaptation in nlp.
In Proc.
of theAnnual Meeting of the ACL, pages 264?271, Prague,Czech Republic, June.
Association for ComputationalLinguistics.Gideon S. Mann and Andrew McCallum.
2010.
General-ized expectation criteria for semi-supervised learningwith weakly labeled data.
Journal of Machine Learn-ing Research, 11:955?984.Yishay Mansour, Mehryar Mohri, and Afshin Ros-tamizadeh.
2008.
Domain adaptation with multiplesources.
In Advances in Neural Information Process-ing Systems.Yishay Mansour, Mehryar Mohri, and Afshin Ros-tamizadeh.
2009.
Domain adaptation: Learningbounds and algorithms.
In Proceedings of The 22ndAnnual Conference on Learning Theory (COLT 2009),Montreal, Canada.Andrew McCallum, Chris Pal, Greg Druck, and XueruiWang.
2006.
Multi-conditional learning: Genera-tive/discriminative training for clustering and classifi-cation.
In AAAI.David McClosky, Eugene Charniak, and Mark Johnson.2006.
Reranking and self-training for parser adapta-tion.
In Proc.
of the Annual Meeting of the ACL andthe International Conference on Computational Lin-guistics, Sydney, Australia.B.
Pang, L. Lee, and S. Vaithyanathan.
2002.
Thumbsup?
Sentiment classification using machine learningtechniques.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing.Barbara Plank.
2009.
Structural correspondence learningfor parse disambiguation.
In Proceedings of the Stu-dent Research Workshop at EACL 2009, pages 37?45,Athens, Greece, April.
Association for ComputationalLinguistics.Sandeepkumar Satpal and Sunita Sarawagi.
2007.
Do-main adaptation of conditional probability models viafeature subsetting.
In Proceedings of 11th EuropeanConference on Principles and Practice of KnowledgeDiscovery in Databases (PKDD), Warzaw, Poland.Lawrence K. Saul, Tommi Jaakkola, and Michael I. Jor-dan.
1996.
Mean field theory for sigmoid beliefnetworks.
Journal of Artificial Intelligence Research,4:61?76.Paul Smolensky.
1986.
Information processing in dy-namical systems: foundations of harmony theory.
InD.
Rumehart and J McCelland, editors, Parallel dis-tributed processing: explorations in the microstruc-tures of cognition, volume 1 : Foundations, pages 194?281.
MIT Press.Ivan Titov and James Henderson.
2007a.
Constituentparsing with Incremental Sigmoid Belief Networks.
InProc.
45th Meeting of Association for ComputationalLinguistics (ACL), pages 632?639, Prague, Czech Re-public.Ivan Titov and James Henderson.
2007b.
Fast and robustmultilingual dependency parsing with a generative la-tent variable model.
In Proc.
of the CoNLL sharedtask, Prague, Czech Republic.G.-R. Xue, W. Dai, Q. Yang, and Y. Yu.
2008.
Topic-bridged PLSA for cross-domain text classification.
InProceedings of the SIGIR Conference.71
