Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 216?225,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsMetaphor Detection with Topic Transition, Emotion and Cognition inContextHyeju Jang, Yohan Jo, Qinlan Shen, Michael Miller,Seungwhan Moon, Carolyn P. Ros?eLanguage Technologies InstituteCarnegie Mellon University5000 Forbes Ave, Pittsburgh, PA 15213, USA{hyejuj,yohanj,qinlans,millerm,seungwhm,cprose}@cs.cmu.eduAbstractMetaphor is a common linguistic tool incommunication, making its detection indiscourse a crucial task for natural lan-guage understanding.
One popular ap-proach to this challenge is to capture se-mantic incohesion between a metaphorand the dominant topic of the surroundingtext.
While these methods are effective,they tend to overclassify target words asmetaphorical when they deviate in mean-ing from its context.
We present a newapproach that (1) distinguishes literal andnon-literal use of target words by exam-ining sentence-level topic transitions and(2) captures the motivation of speakersto express emotions and abstract conceptsmetaphorically.
Experiments on an on-line breast cancer discussion forum datasetdemonstrate a significant improvement inmetaphor detection over the state-of-the-art.
These experimental results also re-veal a tendency toward metaphor usage inpersonal topics and certain emotional con-texts.1 IntroductionFigurative language is commonly used in humancommunication ranging from literature to every-day speech.
One of the most common forms ofnon-literal language is metaphor, in which twodissimilar concepts are compared.
In the ut-terance, ?Time is money?
(Lakoff and Johnson,1980), for example, the concept of ?time?
is com-pared to ?money?
to emphasize that time is valu-able.
Bringing in information from another do-main allows more effective ways of expressingthoughts, feelings, and ideas than only using lit-eral language.Previous approaches to modeling metaphorhave used either the semantic and syntactic in-formation in just the sentence that contains ametaphor (Turney et al, 2011; Tsvetkov et al,2014), or the context beyond a single sentence(Broadwell et al, 2013; Strzalkowski et al, 2013;Schulder and Hovy, 2014; Klebanov et al, 2015;Jang et al, 2015) to detect topical discrepancybetween a candidate metaphor and the dominanttheme (See Section 2 for more detailed literaturereview).Although previous approaches were effective atcapturing some aspects of the governing contextof a metaphor, the space of how to best use thecontextual information is still wide open.
Previouscontext-based models tend to overclassify literalwords as metaphorical if they find semantic con-trast with the governing context.
These cases man-ifested in the work by Schulder and Hovy (2014)and Jang et al (2015) as high recall but low preci-sion for metaphorical instances.We present a new approach that uses lexical andtopical context to resolve the problem of low pre-cision on metaphor detection.
To better capturethe relevant context surrounding a metaphor, weapproach the problem in two directions.
First,we hypothesize that topic transition patterns be-tween sentences containing metaphors and theircontexts are different from that of literal sen-tences.
To this end, we incorporate several indi-cators of sentence-level topic transitions as fea-tures, such as topic similarity between a sentenceand its neighboring sentences, measured by Sen-tence LDA.
Second, we observe that metaphor isoften used to express speakers?
emotional experi-ences; we therefore model a speaker?s motivationin using metaphor by detecting emotion and cog-nition words in metaphorical and literal sentencesand their contexts.To demonstrate the efficacy of our approach, we216evaluate our system on the metaphor detection taskpresented by Jang et al (2015) using a breast can-cer discussion forum dataset.
This dataset is dis-tinct in that it features metaphors occurring in con-versational text, unlike news corpora or other for-mal texts typical in computational linguistics.Our contributions are three-fold: (1) We ex-tend the previous approaches for contextually de-tecting metaphor by exploring topic transitions be-tween a metaphor and its context rather than onlydetecting lexical discrepancies.
In addition, (2) wepropose to capture emotional and cognitive con-tent to better uncover speakers?
motivation for us-ing metaphors.
Lastly, (3) through our empiricalevaluation, we find that metaphor occurs more fre-quently around personal topics.2 Relation to Prior WorkResearch in automatic metaphor detection hasspanned from detecting metaphor in limited setsof syntactic constructions to studying the use ofmetaphor in discourse, with approaches rangingfrom rule-based methods using lexical resourcesto statistical machine learning models.
Here, wefocus in particular on approaches that use contextwider than a sentence for metaphor detection.
Fora more thorough review of metaphor processingsystems, refer to Shutova (2015).The main idea behind using context in metaphordetection is that metaphorically used words tendto violate lexical cohesion in text.
Different meth-ods, however, approach the problem of detectingsemantic outliers in different ways.Li and Sporleder (2009; 2010) identifymetaphorical idioms using the idea that non-literalexpressions break lexical cohesion of a text.
Liand Sporleder (2009) approached the problem byconstructing a lexical cohesion graph.
In thegraph, content words in a text are representedas vertices, which are connected by edges repre-senting semantic relatedness.
The intuition be-hind their approach was that non-literal expres-sions would lower the average semantic related-ness of the graph.
To classify a word as literal ormetaphorical, Li and Sporleder (2010) use Gaus-sian Mixture Models with semantic similarity fea-tures, such as the relatedness between this targetword and words in its context.Broadwell et al (2013) and Strzalkowski etal.
(2013) base their approach on the idea thatmetaphors are likely to be concrete words that arenot semantically associated with the surroundingcontext.
Broadwell et al (2013) implemented thisidea using topic chains, which consist of nounphrases that are connected by pronominal men-tion, repetition, synonym, or hyponym relations.Strzalkowski et al (2013) build on this idea bytaking nouns and adjectives around the target con-cept as candidate source relations.
They filteredout candidate sources that were in the same topi-cal chain as the target concept or were not linkedto the word being classified by a direct dependencypath.Schulder and Hovy (2014) also hypothesize thatnovel metaphors are marked by their unusualnessin a given context.
They use a domain-specificterm relevance metric, which measures how typ-ical a term is for the domain associated with theliteral usage of a word, and common relevance,which measures how common a word is across do-mains.
If a term is neither typical for a text?s do-main nor common, it is taken as a metaphor can-didate.
A particular strength of this approach isits accommodation of common words without dis-criminative power, which often confuse context-based models.Jang et al (2015) model context by using bothglobal context, the context of an entire post, andlocal context, the context within a sentence, in re-lationship to a word being classified as metaphor-ical or literal.
They used word categories fromFrameNet, topic distribution, and lexical chain in-formation (similar in concept to the topic chain in-formation in (Broadwell et al, 2013)) to model thecontrast between a word and its global context.
Tomodel the contrast between a word and its localcontext, they used lexical concreteness, word cat-egories and semantic relatedness features.Mohler et al (2013) built a domain-aware se-mantic signature for a text to capture the con-text surrounding a metaphorical candidate.
Un-like other approaches that try to discriminatemetaphors from their context, their approach usesbinary classifiers to compare the semantic signa-ture for a text with that of known metaphors.The above approaches attempted to capturegoverning context in various ways and were ef-fective when applied to the problem of metaphordetection.
However, these methods tend to over-classify literal instances as metaphorical when se-mantic cohesion is violated within their govern-ing contexts.
Additionally, these methods could217fail to detect extended metaphors, which span overwider contexts.
In this paper, we specifically fo-cus on the problem of discriminating literal in-stances from metaphorical instances by expand-ing the scope of what is captured within a context.Like (Mohler et al, 2013), we share the intuitionthat there could be associations between specificmetaphors and their contexts, but we relax the as-sumption that metaphors must be similar to knownmetaphors.3 Our ApproachTo better capture the distinctions betweenmetaphorical and literal usages of the sameword (target word), we approach the task in twodirections.
First, we model how topics in contextchange for both metaphorical and literal instancesof a target word (Section 3.1).
Second, we con-sider the situational context for why individualschoose to use metaphor (Section 3.2).
We usemulti-level modeling to combine these two typesof features with the specific target word to modelinteractions between the features and a particularmetaphor (Section 3.3).3.1 Topic TransitionIn writing, cohesion refers to the presence or ab-sence of explicit cues in the text that allow thereader to make connections between ideas (Cross-ley and McNamara, 2010).
For example, over-lapping words and concepts between sentencesindicate that the same ideas are being referredto across these sentences.
Metaphorically usedwords tend to be semantically incohesive with thegoverning context.
Therefore, determining seman-tic or topical cohesion is important for metaphordetection.However, even if a text is literal and cohesive,not all words within the text are semantically re-lated.
In example (1), a human could easily de-termine that ?pillows?, ?music?, ?flickering can-dles?, and ?a foot massage?
share the theme ofrelaxation.
But it is difficult to define their re-latedness computationally ?
these terms are notsynonyms, hypernyms, antonyms, or in any otherwell-defined lexical relation.
Additionally, evenif the whole sentence is correctly interpreted asways of indulging oneself, it is still semanticallycontrasted with the surrounding sentences aboutmedicine.
In this example, the target word ?can-dle?
is used literally, but the contrast between thesentence containing the target word and its con-text makes it computationally difficult to deter-mine that it is not metaphorical:(1) ... yet encouraged to hear you havea diagnosis and it?s being treated.Since you have to give up yourscented stuff you?ll just have to fig-ure out some very creative waysto indulge yourself.
Soft pillows,relaxing music, flickering candles,maybe a foot massage.
Let?s hopeyour new pain relief strategy worksand the Neulasta shot is not so bad .I never had Taxotere, but have readit can be much easier than AC formany people.
...Example (2) also shows semantic inconsistencybetween the candidate metaphor ?boat?
and thesurrounding sentences about medicine.
However,in this example, ?boat?
is metaphorically used.Thus, it is difficult to determine whether a wordis metaphorical or literal when there is semanticcontrast because both example (1) and example (2)show semantic contrast.
(2) When my brain mets were discov-ered last year, I had to see a neu-rosurgeon.
He asked if I under-stood that my treatment was palla-tive care.
Boy, did it rock myboat to hear that phrase!
I agreewith Fitz, pallative treatment is tohelp with pain and alleviate symp-toms.....but definitely different thanhospice care.The primary difference between these two ex-amples is in the nature of the semantic contrast.
Inexample (1), the topic of the sentence containing?candle?
is relaxation, while the topic of the pre-vious and following sentences is medicine.
Thetransition between medicine and relaxation tendsto be more literal, whereas the transition betweenthe topic in the sentence containing ?boat?
and thesurrounding medical topic sentences tends to bemore metaphorical.We use these differences in the topic transitionfor metaphor detection.
We consider topic transi-tions at the sentence level, rather than the wordlevel, because people often represent an idea ator above the sentence level.
Thus, topic is better-represented at the sentence level.218To model context at the sentence level, wefirst assign topics to each sentence using SentenceLatent Dirichlet Allocation (LDA) (Jo and Oh,2011).
Sentence LDA has two main advantagesover standard LDA for our work.
First, while stan-dard LDA assumes that each word is assigned atopic derived from the topic distribution of a doc-ument, Sentence LDA makes the constraint thatall words in the same sentence must be assignedthe same topic.
Due to this property, the generatedtopics are better aligned with the role or purposeof a sentence, compared to topics generated fromLDA.
Additionally, having each sentence assignedto one topic helps us avoid using heuristics for rep-resenting the topic of each sentence.1Using Sentence LDA, we modeled four featuresto capture how the topic changes around the sen-tence where a target word resides.
We refer to thissentence as the target sentence.Target Sentence Topic (TargetTopic): We hy-pothesize that sentences containing a metaphormay prefer topics that are different from thoseof sentences where the same word is used liter-ally.
Hence, TargetTopic is a T -dimensional bi-nary feature, where T is the number of topics, thatindicates the topic assigned to the sentence con-taining the target word.Topic Difference (TopicDiff): We hypothesizethat a metaphorical sentence is more likely to bedifferent from its neighboring sentences, in termsof topic, than a literal sentence.
Therefore, Top-icDiff is a two-dimensional binary feature that in-dicates whether the topic assigned to the targetsentence is different from that of the previous andnext sentences.Topic Similarity (TopicSim): Under the samehypothesis as TopicDiff, TopicSim is a two-dimensional feature that represents the similaritybetween the topic of the target sentence and itsprevious and next sentences.
Unlike TopicDiff,which is binary, TopicSim has continuous valuesbetween 0 and 1, as we use the cosine similaritybetween each topic?s word distributions as topicsimilarity.
Note that in Sentence LDA, all top-ics share the same vocabulary, but assign differ-ent probabilities to different words as in LDA al-though all tokens in a sentence are assigned to the1We also tried standard LDA for assigning topics to sen-tences, by representing each sentence as a topic distributionover its words.
However, this representation was not as infor-mative as Sentence LDA in our task, so we leave out the LDAtopics in further discussion.same topic in Sentence LDA.Topic Transition (TopicTrans): The topic ofa metaphorical sentence may extend over mul-tiple sentences, so a topic transition may occura few sentences ahead or behind the target sen-tence.
TopicTrans looks for the nearest sentenceswith a different topic before and after the cur-rent target sentence and encodes the topics of thedifferent-topic sentences.
Hence, TopicTrans is a2T -dimensional feature, where T is the number oftopics, that indicates the topics of the nearest sen-tences that have a different topic from the targetsentence.Topic Transition Similarity (Topic-TransSim): The topics before and after atransition, even in the extended case for Topic-Trans, are still expected to be more different inmetaphorical cases than in literal cases, as we as-sume for TopicSim.
Therefore, TopicTransSimis a two-dimensional continuous feature thatencodes the cosine similarity between the topic ofthe target sentence and the topics of the nearestsentences that have a different topic before andafter the target sentence.3.2 Emotion and CognitionMetaphors are often used to explain or describeabstract ideas, such as difficult concepts or emo-tions (Meier and Robinson, 2005).
(Fainsilber andOrtony, 1987) showed that descriptions of feelingscontain more metaphorical language than descrip-tions of behavior.In our domain, writers are searching for sup-port through the emotionally tumultuous experi-ence of breast cancer and often turn to metaphorto express this emotion.
For example, the word?road?
can be used as a metaphor to express theemotional experiences of waiting for or passingthrough steps in treatment.
A similar phenomenonis that markers of cognition, such as ?I think?,can occur to introduce the abstract source of themetaphor.
In example (3), one breast cancer pa-tient in our data describes her speculation abouther condition metaphorically, writing,(3) i have such a long road i just won-der what to do with myself.To encode these emotional and cognitive ele-ments as features, we use Linguistic Inquiry WordCount (LIWC) (Tausczik and Pennebaker, 2010).LIWC is a tool that counts word use in certain219psychologically relevant categories.
Focusing onemotional and cognitive processes, we use theLIWC term lists for categories seen in Table 1.LIWC category Example Termsaffect ache, like, sweetpositive emotion passion, agree, givingnegative emotion agony, annoy, missanxiety embarrass, avoidanger assault, offendsadness despair, grimcognitive mechanisms if, couldinsight believe, awarecause make, pickdiscrep would, hopetentativeness anyone, supposecertainty never, trueTable 1: Selected LIWC categories.We count the number of words that fall into eachcategory within either an immediate or global con-text.
For these LIWC features, we take the targetsentence and its neighboring sentences as the im-mediate context and the entire post as the globalcontext for a candidate metaphor instance.
Thecounts for each category in either the immediateor global context are used as features encoded bywhat degree the immediate or global context ex-presses the emotional or cognitive category.We expect words indicative of emotion and cog-nition to appear more frequently in metaphori-cal cases.
Our preliminary statistical analysis onthe development set revealed that this holds truewithin the target sentence and shows a tendency inthe surrounding sentences.3.3 Multi-Level ModelingOur topical and emotion and cognition contextfeatures are general across target words.
How-ever, the specific features that are informative formetaphor identification may depend on the tar-get word.
To account for the specificity of targetwords, we use multi-level modeling (Daume III,2007).
The idea of multi-level modeling is to paireach of our features with every target word whilekeeping one set of features independent of the tar-get words.
There are then multiple copies of eachtopic transition and emotion/cognition feature, allpaired with a different target word.
Thus, if thereare N target words, our feature space becomesN + 1 times larger.4 ExperimentsOur main experimental task is metaphor detec-tion or disambiguation ?
given a post containinga candidate metaphor word, we aim to determinewhether the word is used literally or metaphori-cally in context.4.1 DataWe conducted experiments on a dataset of postsfrom a public breast cancer support group discus-sion forum, annotated by Jang et al (2015).
Wechose to work on this dataset because it featuresmetaphors occurring in naturalistic language.In this dataset, posts are restricted to those con-taining one of seven candidate metaphors that ap-pear either metaphorically or literally: ?boat?,?candle?, ?light?, ?ride?, ?road?, ?spice?, and?train?.
We split the data randomly into a devel-opment set of 800 posts for preliminary analysisand a cross-validation set of 1,870 posts for clas-sification as in (Jang et al, 2015).4.2 MetricsWe report five evaluation metrics for every model:kappa, F1 score, precision, recall, and accuracy.Kappa, which corrects for agreement by chance,was calculated between predicted results and ac-tual results.
Because the dataset is skewed towardsmetaphorical instances, we rely on the first fourmeasures over accuracy for our evaluation.4.3 BaselinesWe use the following two baselines: the feature setof (Jang et al, 2015) and a context unigram model.Jang et al (2015): We use the best configura-tion of features from Jang et al (2015), the state-of-the-art model on our dataset, as a baseline.
Thisfeature set consists of all of their local context fea-tures (word category, semantic relatedness, con-creteness), all of their global context features ex-cept lexical chaining (word category, global topicdistribution), and context unigrams.Context Unigram Model: All the words in apost, including the target word, are used as contextfeatures.4.4 SettingsWe ran Sentence LDA, setting the number of top-ics to 10, 20, 30, 50, and 100. ?
and ?
deter-mine the sparsity of the topic distribution of eachdocument and the word distribution of each topic,220Model ?
F1 P-L R-L P-M R-M AUnigram .435 .714 .701 .434 .845 .943 .824Unigram + AllTopic + AllLIWC*** .533 .765 .728 .550 .872 .937 .847Unigram + MM AllTopic + MM AllLIWC*** .543 .770 .754 .546 .872 .946 .852J .575 .786 .758 .587 .882 .943 .859J + AllTopic + AllLIWC* .609 .804 .772 .626 .892 .943 .869J + MM AllTopic** .619 .809 .784 .630 .893 .947 .873J + MM AllLIWC .575 .787 .757 .589 .882 .942 .859J + MM AllTopic + MM AllLIWC*** .631 .815 .792 .642 .896 .948 .876Table 2: Performance on metaphor identification task.
(Models) J: Jang et al (2015), MM - MultilevelModeling (Metrics) ?
: Cohen?s kappa, F1: average F1 score on M/L, P-L: precision on literals, R-L:recall on literals, P-M: precision on metaphors, R-M: recall on metaphors, A: accuracy, *: marginally sta-tistically significant (p < 0.1), **: statistically significant (p < 0.05), ***: highly statistically significant(p < 0.01) improvement over corresponding baseline by Student?s t-test.respectively; the lower the sparser.
Following con-vention, we set these parameters to 0.1 and 0.001,respectively, to enforce sparsity.
We also removedthe 37 most frequent words in the corpus, draw-ing the threshold at the point where content wordsand pronouns started to appear in the ranked list.The models with 10 topics performed the best onthe development set, with performance degradingas the number of topics increased.
We suspect thatpoorer performance on the models with more top-ics is due to feature sparsity.We used the support vector machine (SVM)classifier provided in the LightSIDE toolkit(Mayfield and Ros?e, 2010) with sequential mini-mal optimization (SMO) and a polynomial kernelof exponent 2.
For each experiment, we performed10-fold cross-validation.
We also trained the base-lines with the same SVM settings.4.5 ResultsThe results of our classification experiment areshown in Table 2.
We tested our topical and emo-tion and cognition features in combination withlexical features from our baselines: unigram andJang et al (2015).Adding our topical and emotion/cognition fea-tures to the baselines improved performance inpredicting metaphor detection.
We see that ourfeatures combined with the unigram features im-proved over the Unigram baseline although theydo not beat the Jang et al (2015) baseline.
How-ever, when our features are combined with the fea-tures from Jang et al (2015), we see large gains inperformance.
Additionally, our multi-level mod-eling significantly improved performance by tak-T0 T1 T2 T3 T4 T5 T6 T7 T8 T9Topic Distribution of Target Sentences01 MetaphoricalLiteralFigure 1: Proportions of topics assigned to targetsentences, when target words were used metaphor-ically vs. literally.
The proportions of metaphor-ical and literal cases are different with statisticalsignificance of p < 0.01 by Pearson?s chi-squaretest.ing into account the effects of specific metaphors.The topical features added to the baseline led to asignificant improvement in accuracy, while emo-tion and cognition features only slightly improvedthe accuracy without statistical significance.
How-ever, the combination of these emotion and cogni-tion features with topical features (in the last rowof Table 2) leads to improvement.
We performeda Student?s t-test for calculating statistical signifi-cance.5 DiscussionMetaphorical instances tend to have personaltopics.
An author was more likely to use targetwords metaphorically when the target sentence re-lates more closely to their own experience of dis-ease and treatment.
Specifically, metaphors wererelatively frequent when people shared their owndisease experience (Topic 0, Topic 9) or sympa-221Topic Top Words Example Sentences0 Disease/Treatmentget, chemo, if, they, as, out, can, like, now, she,feel, did, up, know, think, been, good, time, or,whenI?m scared of chemo and ct scans because it makescancer come back and you become more resistance totreatment with drugs like these later.1 Food good, they, gt, can, like, eat, fat, or, if, some,one, as, them, get, up, fiber, think, more, what*Martha?s Way* Stuff a miniature marshmallow in thebottom of a sugar cone to prevent ice cream drips.2 Emotions love, great, laura, good, hope, like, debbie, amy,up, happy, too, everyone, day, glad, look, fun,mary, what, kelly, howToo funny.
/ You?re so cute!
/ ene23...the photo in thelocket idea sounds great!3 Time chemo, week, go, last, then, next, weeks, taxol,good, done, treatment, first, start, one, more,rads, after, today, ?ll, nowI am now 45, and just had my ONE year anniversaryfrom finishing chemo last week!
!4 Greetings/Thanksthanks, hugs, hi, here, carrie, thank, welcome,love, us, glad, know, greg, good, everyone,thread, ladies, there, how, sorry, magsThank you so much for the story!!
/ Big Hugs!5 People she, he, they, out, get, up, her, when, like, one,as, from, there, our, time, did, if, can, go, whatShe has three children and her twin sister has taken herand her 3 children in.6 Support good, hope, well, happy, everyone, doing, glad,luck, hear, better, take, jen, care, great, liz,birthday, hugs, lol, watson, feelingYAY!
/ lol.
/ I wish you all good luck and peace.7 Relation what, know, she, as, can, her, cancer, if, there,has, think, been, how, like, our, who, when,they, would, usShe knows that she has BC but does not know that ithas spread.
/ I just read your message and I wonderedabout you.8 Religion god, love, lord, us, prayers, our, bless, dear, her,lu, may, day, patti, thank, know, comfort, amen,xoxo, he, prayDear Lord, I come to you with a friend that is not doingwell, Please bless her that her hands will reach for youthrew the last part of her breast cancer fight.9 Diagnosis diagnosed, when, chemo, she, breast, years,stage, cancer, dx, now, found, nodes, no, after,lump, they, age, then, year, mastectomyI was 64 when diagnosed wtth pure DCIS.....I had myninght radiation treatment today.
/ I was diagnosed Nov2007 at age 45.Table 3: Topics learned by Sentence LDA.T0 T1 T2 T3 T4 T5 T6 T7 T8 T9Vs.
Previous Sentence01 MetaphoricalLiteralT0 T1 T2 T3 T4 T5 T6 T7 T8 T9Vs.
Next Sentence01Topic Distribution of the Sentences Nearest to the Target Sentence and with a Different TopicFigure 2: Proportions of the topics of the sentencesthat are nearest to the target sentence and have adifferent topic from the target sentence.
The pro-portions of metaphorical and literal cases are dif-ferent with statistical significance of p < 0.01 byPearson?s chi-square test.thized with other people?s experiences (Topic 7),but were more infrequent when they simply talkedabout other people in Topic 5 (Figure 1).
Accord-ing to our closer examination of sample sentences,Topic 0 had many personal stories about diseaseand treatment, and Topic 7 was about learning andrelating to other people?s experiences.
Examplemetaphorical expressions include ?There is lightduring chemo.?
(Topic 0) and ?Hi Dianne - I amglad I found your post as I am sort of in the sameMetaphorical Literal01 Vs.
Previous SentenceMetaphorical Literal01 Vs. Next SentenceProportions of Target SentencesWith A Different Topic from ContextFigure 3: Proportions of target sentences whosetopic is different from that of the previous/nextsentence, when target words were used metaphor-ically vs. literally.
The proportions of metaphor-ical and literal cases are different with statisticalsignificance of p < 0.01 by Pearson?s chi-squaretest.boat.?
(Topic 7).
Analysis of our LIWC featuresalso supports the reflective nature of metaphors:?insight?
and ?discrepancy?
words such as ?wish?,?seem?, and ?feel?
occur more frequently aroundmetaphorical uses of target terms.The topics of the surrounding context(TopicTrans) were also informative for metaphordetection (Figure 2).
However, the topics ofthe surrounding sentences followed an oppositepattern to the topics of the target sentence; talking222l lllMetaphorical Literal01 Vs.
Previous SentencellllllllMetaphorical Literal01 Vs. Next SentenceTopic SimilarityBetween Target Sentence and ContextFigure 4: Cosine similarity between the topic ofa target sentence and the topic of its previous/nextsentence, when target words were used metaphor-ically vs. literally.
The means of the metaphoricaland literal cases are different with statistical sig-nificance of p < 0.01 by Welch?s t-test.Vs.
Previous SentenceMetaphorical Literal01 Vs. Next SentenceMetaphorical Literal01Topic Similarity Between Target Sentence and Nearest Transitioning ContextFigure 5: Cosine similarity of the topic of a tar-get sentence and the topic of the sentences thatare nearest to the target sentence and have a dif-ferent topic from the target sentence.
The meansof metaphorical and literal cases are different withstatistical significance only for the next sentence,with p < 0.01 by Welch?s t-test.about other people (Topic 5) in the context of atarget sentence led to more metaphorical usage oftarget words.
Similarly, writers used target wordsmore literally before or after they shared theirpersonal stories (Topic 0).
This pattern could bebecause the topic of the target sentence differsfrom the topics of the surrounding sentencesin these instances, which would mean that thetarget sentence is a topic that is more likely tobe literal.
Topic 9, however, does not follow thesame pattern.
One possible reason is that Topic9 and Topic 0 tend to frequently co-occur and bemetaphorical.
Thus, if a target word comes afteror before Topic 9 and it is Topic 0, then this wordmay more likely be metaphorical.Topic transitions are effective indicators ofmetaphor.
Metaphorical instances accompaniedmore drastic topic transitions than literal instances.This tendency, which matched our hypothesis, wasshown in all our topic features.
The immediatelyneighboring sentences of metaphorical instanceswere more likely to have a different topic from thetarget sentence than those of literal instances (Fig-ure 3).
Additionally, differences in topic betweenthe target sentence and the neighboring sentenceswere greater for metaphorical instances (Figure 4).The nearest sentences with topics different fromthe target sentence (TopicTransSim) also showedthis pattern (Figure 5).
An interesting finding wasthat a topic transition after the target sentence wasmore indicative of metaphor than a transition be-fore.Emotion and cognitive words are discrimina-tive depending on the metaphor.
Emotion andcognition in the surrounding contexts, which werecaptured by the LIWC features, helped identifymetaphors when combined with topical features.This result supports the claim in (Fainsilber andOrtony, 1987) that descriptions of feelings containmore metaphorical language than descriptions ofbehavior.This effect, however, was limited to specific tar-get words and emotions.
For example, we saw ahigher number of anxiety words in the immedi-ate and global contexts of metaphors, but the trendwas the opposite for anger words.
This may be be-cause our target words, ?boat?, ?candle?, ?light?,?ride?, ?road?, ?spice?
and ?train?, relate more toanxiety in metaphors such as ?bumpy road?
and?rollercoaster ride?, than to anger.
On the otherhand, cognitive words had more consistency, aswords marking insight and discrepancy were seensignificantly higher around metaphorical uses ofthe target words.
These patterns, nevertheless,could be limited to our domain.
It would be in-teresting to explore other patterns in different do-mains.A multi-level model captures word-specificeffects.
Our features in context helped recog-nize metaphors in different ways for different tar-get words, captured by the multi-level model.The paucity of general trends across metaphori-cal terms does not mean a limited applicability ofour method, though, as our features do not sup-pose any specific trends.
Rather, our method onlyassumes the existence of a correlation betweenmetaphors and the theme of their context, and ourmulti-level model effectively identifies the inter-action between metaphorical terms and their con-223texts as useful information.For all the figures in this section, most targetwords have a similar pattern.
See our supplemen-tal material for graphs by target word.6 ConclusionWe propose a new, effective method for metaphordetection using (1) sentence level topic transitionsbetween target sentences and surrounding contextsand (2) emotion and cognition words.
Both typesof features showed significant improvement overthe state-of-the-art.
In particular, our system madesignificant gains in solving the problem of over-classification in metaphor detection.We also find that personal topics are markers ofmetaphor, as well as certain patterns in topic tran-sition.
Additionally, language expressing emotionand cognition relates to metaphor, but in ways spe-cific to particular candidate words.
For our breastcancer forum dataset, we find more words relatedto anxiety around metaphors.Our proposed features can be expanded to otherdomains.
Though in other domains, the specifictopic transition and emotion/cognition patternswould likely be different, these features would stillbe relevant to metaphor detection.AcknowledgmentsThis research was supported in part by NSF GrantIIS-1302522.ReferencesGeorge Aaron Broadwell, Umit Boz, Ignacio Cases,Tomek Strzalkowski, Laurie Feldman, Sarah Taylor,Samira Shaikh, Ting Liu, Kit Cho, and Nick Webb.2013.
Using imageability and topic chaining to lo-cate metaphors in linguistic corpora.
In Social Com-puting, Behavioral-Cultural Modeling and Predic-tion, pages 102?110.
Springer.Scott A Crossley and Danielle S McNamara.
2010.Cohesion, coherence, and expert evaluations of writ-ing proficiency.
In Proceedings of the 32nd annualconference of the Cognitive Science Society, pages984?989.Hal Daume III.
2007.
Frustratingly easy domain adap-tation.
In Proceedings of the 45th Annual Meeting ofthe Association of Computational Linguistics, pages256?263, Prague, Czech Republic, June.
Associa-tion for Computational Linguistics.Lynn Fainsilber and Andrew Ortony.
1987.
Metaphor-ical uses of language in the expression of emotions.Metaphor and Symbolic Activity, 2(4):239?250.Hyeju Jang, Seunghwan Moon, Yohan Jo, and Car-olyn Penstein Ros?e.
2015.
Metaphor detection indiscourse.
In 16th Annual Meeting of the Special In-terest Group on Discourse and Dialogue, page 384.Yohan Jo and Alice Oh.
2011.
Aspect and SentimentUnification Model for Online Review Analysis.
InProceedings of the fourth ACM international con-ference on Web search and data mining, pages 815?824.Beata Beigman Klebanov, Chee Wee Leong, andMichael Flor.
2015.
Supervised word-levelmetaphor detection: Experiments with concretenessand reweighting of examples.
NAACL HLT 2015 3rdMetaphor Workshop, page 11.George Lakoff and M. Johnson.
1980.
Metaphors welive by.
Chicago/London.Linlin Li and Caroline Sporleder.
2010.
Using gaus-sian mixture models to detect figurative language incontext.
In Human Language Technologies: The2010 Annual Conference of the North AmericanChapter of the Association for Computational Lin-guistics, HLT ?10, pages 297?300, Stroudsburg, PA,USA.
Association for Computational Linguistics.Elijah Mayfield and Carolyn Ros?e.
2010.
An in-teractive tool for supporting error analysis for textmining.
In Proceedings of the NAACL HLT 2010Demonstration Session, pages 25?28.
Associationfor Computational Linguistics.Brian P Meier and Michael D Robinson.
2005.
Themetaphorical representation of affect.
Metaphor andsymbol, 20(4):239?257.Michael Mohler, David Bracewell, David Hinote, andMarc Tomlinson.
2013.
Semantic signatures forexample-based linguistic metaphor detection.
InProceedings of the First Workshop on Metaphor inNLP, pages 27?35.Marc Schulder and Eduard Hovy.
2014.
Metaphor de-tection through term relevance.
ACL 2014, page 18.Ekaterina Shutova.
2015.
Design and evaluation ofmetaphor processing systems.
Computational Lin-guistics.Caroline Sporleder and Linlin Li.
2009.
Unsupervisedrecognition of literal and non-literal use of idiomaticexpressions.
In Proceedings of the 12th Conferenceof the European Chapter of the Association for Com-putational Linguistics, pages 754?762.
Associationfor Computational Linguistics.Tomek Strzalkowski, George Aaron Broadwell, SarahTaylor, Laurie Feldman, Boris Yamrom, SamiraShaikh, Ting Liu, Kit Cho, Umit Boz, Ignacio Cases,et al 2013.
Robust extraction of metaphors fromnovel data.
Meta4NLP 2013, page 67.224Yla R Tausczik and James W Pennebaker.
2010.
Thepsychological meaning of words: Liwc and comput-erized text analysis methods.
Journal of languageand social psychology, 29(1):24?54.Yulia Tsvetkov, Leonid Boytsov, Anatole Gershman,Eric Nyberg, and Chris Dyer.
2014.
Metaphor de-tection with cross-lingual model transfer.Peter D Turney, Yair Neuman, Dan Assaf, and YohaiCohen.
2011.
Literal and metaphorical sense iden-tification through concrete and abstract context.
InProceedings of the 2011 Conference on the Empiri-cal Methods in Natural Language Processing, pages680?690.225
