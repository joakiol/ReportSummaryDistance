INLG 2012 Proceedings of the 7th International Natural Language Generation Conference, pages 59?66,Utica, May 2012. c?2012 Association for Computational LinguisticsLinguist?s Assistant: A Multi-Lingual Natural Language Generatorbased on Linguistic Universals, Typologies, and PrimitivesTod Allman Stephen Beale Richard DentonGraduate Institute of AppliedLinguisticsUniversity of Maryland, Bal-timore CountyDartmouth College6127 Wilder Lab7500 W. Camp Wisdom Rd.
1000 Hilltop Circle Hanover, NH 03755Dallas, TX 75236 Baltimore, MD 21250 richard.e.denton@tod_allman@gial.edu sbeale@csee.umbc.edu dartmouth.eduAbstractLinguist?s Assistant (LA) is a large scale se-mantic analyzer and multi-lingual natural lan-guage generator designed and developedentirely from a linguist?s perspective.
Thesystem incorporates extensive typological,semantic, syntactic, and discourse research in-to its semantic representational system and itstransfer and synthesizing grammars.
LA hasbeen tested with English, Korean, Kewa (Pa-pua New Guinea), Jula (Cote d?Ivoure), andNorth Tanna (Vanuatu), and proof-of-conceptlexicons and grammars have been developedfor Spanish, Urdu, Tagalog, Chinantec (Mexi-co), and Angas (Nigeria).
This paper willsummarize the major components of the NLGsystem, and then present the results of exper-iments that were performed to determine thequality of the generated texts.
The experi-ments indicate that when experienced mother-tongue translators use the drafts generated byLA, their productivity is typically quadrupledwithout any loss of quality.1 IntroductionThe fundamental goal underlying LA was to de-velop a system capable of generating high qualitytexts in a wide variety of languages, particularlyminority and endangered languages.
Drafts pro-duced by LA are always easily understandable,grammatically correct, semantically equivalent tothe source documents, and at approximately a sixthgrade reading level.
Because the system is basedon linguistic research, LA is expected to work wellfor typologically diverse languages; it works equal-ly well for languages that are coranking or clausechaining, highly isolating or highly polysynthetic,fusional or agglutinative, etc.
A natural languagegenerator of this type is practical only when trans-lating large quantities of texts into many differentlanguages.
Therefore semantic representations fora large variety of texts are being developed for LA.This system is a tool which enables linguists todocument a language and simultaneously generatenumerous texts for the speakers of that language.A model of LA is shown in Figure 1.Figure 1.
Model of Linguist?s AssistantAs seen in the figure, there are five primary com-ponents: 1) the ontology, 2) the semantic represen-tations, 3) the lexicon, 4) the transfer grammar, and5) the synthesizing grammar.
The two components59in ovals are static knowledge which is suppliedwith LA, and the three items in rectangles are user-supplied target language knowledge.
The finalproduct of LA is target text.2 The OntologyOne of the foundational principles of Natural Se-mantic Metalanguage theory (Goddard &Wierzbicka, 1994; Wierzbicka, 1996) proposesthat there is a small set of innate concepts whichare present in every language.
These innate con-cepts can be used to explicate every word in everylanguage.
If semantic representations were devel-oped using only these innate primitives, the prob-lem of lexical mismatch between languages wouldbe eliminated.
However, building semantic repre-sentations using only the innate concepts is un-wieldy, so semantically simple molecules wereidentified in a principled manner.
For our seman-tic molecules, we elected to use the defining vo-cabulary in Longman?s Contemporary EnglishDictionary (2003).
By using these semanticallysimple concepts, the problem of lexical mismatchbetween source and target languages is significant-ly reduced.
There are certainly still instances oflexical mismatch, and we have an approach fordealing with them which will be described below.LA also permits the automatic insertion of seman-tically complex concepts into the semantic repre-sentations, but only if the linguist indicates that thetarget language has a lexical equivalent.3 LA?s Semantic Representational SystemThe development of an adequate method of mean-ing representation for LA?s source texts proved tobe a challenge.
Formal semantics (Cann, 1993;Rosner, 1992), conceptual semantics (Jackendoff,1990) and generative semantics (Lakoff, 1987)were each considered but found unsuitable becausethey didn?t include sufficient information for mi-nority languages.
Therefore a new format was de-veloped specifically for LA?s semanticrepresentational system.
LA?s semantic represen-tations are comprised of a controlled, English in-fluenced metalanguage augmented by a featuresystem which was designed to accommodate awide variety of languages.
Fundamentally thesesemantic representations consist of concepts, struc-tures, and features.
The concepts that are permit-ted in the semantic representations are all semanti-cally simple as was described earlier.
The struc-tures permitted in the semantic representations area small restricted set of English-like sentencestructures.
The feature system developed for LAincludes semantic, syntactic, and discourse infor-mation.
The feature values have been gleanedfrom a wide variety of diverse languages.
Table 1shows a few examples of these features and theirvalues.Object Num-berSingular, Dual, Trial, Quadrial, Plu-ral, PaucalObject Partici-pant TrackingFirst Mention, Routine, Interroga-tive, Frame Inferable, Exiting, Re-staging, GenericObject Prox-imityNear Speaker and Listener, NearSpeaker, Near Listener, Remotewithin Sight, Remote out of Sight,Temporally Near, Temporally Re-mote, Contextually Near with FocusEvent Time Discourse, Present, Immediate Past,Earlier Today, Yesterday, 2 to 3days ago, 4 to 6 days ago, 1 to 4weeks ago, 1 to 5 months ago, 6 to12 months ago, ?, Immediate Fu-ture, Later Today, Tomorrow, 2 to 3days from now, ?PropositionIllocutionaryForceDeclarative, Imperative, ContentInterrogative, Yes-No InterrogativePropositionSalience Band(Longacre,1996)Pivotal Storyline, Script PredictableActions, Backgrounded Actions,Flashback, Setting, Irrealis, Evalua-tion, Cohesive MaterialObject PhraseSemantic RoleAgent, Patient, State, Source, Desti-nation, Instrument, Beneficiary,AddresseeTable 1.
Several Features and their ValuesThe semantic representation for ?Paulus startedwalking from the market to a village namedTerpen?
is shown in Figure 2.Figure 2.
LA?s Semantic Representational SystemAs seen in Figure 2, every concept, phrase, andproposition has numerous features associated withit; the letters and numbers below the concepts andbeside the phrase and proposition boundaries rep-resent specific feature values.
For example, the60phrase containing Paulus has its Semantic Role setto Agent, the phrase containing market has its Se-mantic Role set to Source, the phrase containingvillage has its Semantic Role set to Destination, theevent walk has its Time set to Discourse and itsAspect set to Inceptive, the proposition?s Illocu-tionary Force is set to Declarative and its SalienceBand is set to Pivotal Storyline, etc.4 LA?s LexiconThe target lexicon serves as a repository for all ofthe target language?s words and their associatedfeatures and forms.
Within the lexicon a linguistdefines the features that are pertinent to each syn-tactic category for his particular target language.For example, each noun can be assigned a gendervalue, an honorific value, a class value, etc.
Simi-larly the required forms are defined in the targetlexicon (e.g., English verbs have a stem plus a pasttense form, a perfect participle form, a gerundform, and a third singular present form).
Then lex-ical spellout rules are used to generate the variousforms of each target word.
All instances of supple-tion are entered into the target lexicon manually.5 LA?s Transfer GrammarThe purpose of LA?s transfer grammar1 is to re-structure the English influenced semantic represen-tations in order to produce a new underlyingrepresentation that is appropriate for the target lan-guage.
This new underlying representation con-sists of the target language?s words, structures, andfeatures.
For example, many languages have rulesthat are based on grammatical relations, but theobject phrases in the semantic representations aremarked with semantic roles rather than grammati-cal relations.
Therefore a rule in the transfergrammar must generate grammatical relations fromthe semantic roles.
For another example, manylanguages in the world are clause chaining ratherthan coranking, so a rule in the transfer grammarmust build appropriate clause chains from thecoranking propositions in the semantic representa-1 The translation process is often divided into three fundamen-tal steps: 1) analysis: analyze the source document to deter-mine its meaning, 2) transfer: reconstruct that meaning usingthe target language?s lexemes, structures, and world view, and3) synthesis: synthesize the final surface forms.
The term?Transfer Grammar?
here refers to the grammar in LA thatperforms the second step of the translation process.tions.
A model of LA?s transfer grammar is shownin Figure 3.
The transfer grammar consists of ninedifferent types of rules, several of which will bebriefly described below.Figure 3.
Model of LA?s Transfer GrammarComplex Concept Insertion Rules: These rulesare prebuilt for specific complex concepts and maybe activated by the user if his target language has alexical equivalent for a particular complex concept.For example, the concept blind is semanticallycomplex and is not permitted in the semantic rep-resentations.
Whenever the adjective ?blind?
isused attributively in a source document, it is re-placed in the semantic representations with the rel-ative clause who is not able to see.
But if thetarget language has a lexical equivalent for blind,the user can activate the complex concept insertionrule which will replace all occurrences of who isnot able to see in the semantic representations withblind.Styles of Direct Speech: Many languages employtechniques for indicating relative status when twopeople talk to one another.
Therefore in the se-mantic representations all propositions that are di-61rect speech are marked with five features indicat-ing: 1) the general category of the speaker (e.g.,father, mother, child, political leader, religiousleader, employer, employee, etc.
), 2) the generalcategory of the listener, 3) the speaker?s attitude, 4)the speaker?s approximate age, and 5) the age ofthe speaker relative to the listener.
Linguists areable to define the styles of direct speech that arepertinent to the target language, and then use thesefeatures and rules to set the style appropriately.Subsequent rules then insert the appropriate pro-nouns or honorific morphology to indicate the rela-tive status of the speaker to the listener.Relative Clause Strategies: Extensive typologicalresearch has been done regarding relative clauses(Comrie 1989:138, Giv?n 1990:645), and linguistshave found that languages apply a limited numberof strategies to a limited number of grammaticalrelations in what is commonly called the NP Ac-cessibility Hierarchy (Keenan & Comrie 1977,Comrie 1989:156).
Cross-linguistically relativeclauses may be classified as either embedded oradjoined.
If a language uses embedded relativeclauses, they may be pre-nominal, post-nominal, orcircum-nominal.
If a language uses adjoined rela-tive clauses, they are either sentence initial or sen-tence final.
There are generally three strategies forencoding the coreferential noun in a relativeclause: the gap strategy, the pronoun retentionstrategy, and the relative pronoun strategy.
Therelative clause rules in LA enable a linguist to de-scribe what types of relative clauses are employedin his target language, and which strategies areused at the various positions in the AccessibilityHierarchy.Collocation Correction Rules:  Collocation dealswith how certain words go together, and howwords and phrases co-occur with certain grammat-ical choices.
Every word in every language has itsown collocational range and restrictions.
There-fore collocation correction rules are used to changeone target word to another target word in a particu-lar environment.
For example, in English a kingwears his crown, but in Korean, a king ??
[sseuda] uses his crown.
So a collocation correctionrule will change the Korean verb ??
[ip da] ?towear?
to ??
[sseu da] ?to use?
whenever the agentis a king or queen and the patient is a crown.Theta Grid Adjustment Rules:  Every verb inevery language has an associated theta grid whichdescribes its argument structure.
The theta gridsfor the events in the semantic representations arevery similar to the theta grids for the equivalentEnglish verbs.
However, the verbs in other lan-guages have different argument structures, so thetheta grid adjustment rules enable a linguist to easi-ly restructure an event?s arguments according tothe theta grid of the target language?s equivalentverb.
The Korean theta grid adjustment rule forthe concept walk is shown in Figure 4.
That ruleinserts the appropriate Korean postpositions intothe source and destination phrases.Figure 4.
Korean Theta Grid Adjustment RuleStructural Adjustment Rules: The structural ad-justment rules are used to restructure the semanticrepresentations in any way that?s necessary in or-der to construct an appropriate underlying repre-sentation for the target language.
These rules maybe used to handle lexical mismatch, convert predi-cate adjective constructions to verbal construc-tions, build clause chains from corankingpropositions, make adjustments for various viewsof time, etc.
The structural adjustment rules lookidentical to the theta grid adjustment rule shown inFigure 4, but they are grouped separately becausethey perform a variety of tasks.The final product of the transfer grammar is anew underlying representation that is appropriatefor the target language.
This underlying represen-tation consists of the target language?s words,structures, and features.
This underlying represen-tation serves as the input to the synthesizinggrammar.6 LA?s Synthesizing GrammarLA?s synthesizing grammar is responsible for syn-thesizing the final surface forms of the target text.62LA?s synthesizing grammar was designed to re-semble as closely as possible the descriptivegrammars that field linguists routinely write.
Be-fore developing this grammar, dozens of descrip-tive grammars written by field linguists wereexamined in order to observe the capabilities thatare required to synthesize surface text.
A model ofthe final result is shown in Figure 5, and several ofthese rule types will be briefly described below.Figure 5.
Model of LA?s Synthesizing GrammarFeature Copying Rules: The feature copyingrules copy features from one constituent to anotherconstituent so that the spellout rules can add thenecessary morphology to indicate appropriateagreement.
For example, certain Jula nouns agreein person and number with their object nouns, so afeature copying rule copies the person and numberof the object noun to the verb.
Then a spellout ruleadds the appropriate morphology to the verb.Spellout Rules: The spellout rules add contextualmorphology in order to synthesize the final form ofeach target word.
There are four basic types ofspellout rules: (i) simple spellout rules which add aprefix, suffix, infix, circumfix, or a new word to anexisting word, or they provide a new translation ofa particular target word in a given context; (ii)form selection rules which select a form of a targetword from the target lexicon; (iii) morphophone-mic rules which perform morphophonemic opera-tions on the affixes that were added to the stem;and (iv) table spellout rules which group a com-mon set of affixes together into a single rule.
Afterthese spellout rules have been executed, each targetword is in its final surface form.
A table spelloutrule that adds tense suffixes to Kewa verbs isshown in Figure 6.Figure 6.
Spellout Rule that adds Kewa Tense AffixesClitic Rules: Linguists have found that languagesemploy three different types of clitics (Payne,1997): (i) pre-clitics which attach to the beginningof the first word in a phrase, (ii) second positionclitics which attach to the end of the first word in aphrase, and (iii) post-clitics which attach to the endof the last word in a phrase.
A clitic rule that addsthe post-clitic ?me to Kewa subjects is shown inFigure 7.Figure 7.
A Clitic Rule for KewaPronoun Rules: There are no pronouns in thesemantic representations because each language63has its own rules for determining when and wherepronouns are appropriate.
Therefore, after thephrase structure rules have moved each constituentinto its final position, the pronoun rules identifythe nominals that should be realized with pro-nouns, and then supply the appropriate surfaceforms.Word Morphophonemic Rules: The word mor-phophonemic rules are similar to the morphopho-nemic rules described in the spellout rule sectionabove, but these morphophonemic rules operateacross word boundaries rather than morphemeboundaries.
For example, the English indefinitearticle a changes to an whenever the next wordbegins with a vowel.7 LA?s Target TextAfter the synthesizing grammar has been executedand produced the final form of the target text,mother-tongue speakers edit the text to improvethe naturalness and information flow.
Samples ofEnglish and Korean texts generated by LA areshown in Figure 8.
The texts in that figure havenot been edited; they are the actual texts that weregenerated by LA.
These texts occur at the begin-ning of a story that describes how to prevent thespread of Avian Influenza.One day a doctor namedPaulus returned from themarket to his village namedTerpen.
While Paulus hadbeen at the market, somepeople had told him about acertain disease.
So whenPaulus returned to his vil-lage, he said to Isak, whowas the village chief, andthe other people who livedin Terpen, "A new diseasenamed Avian Influenza haskilled most of the birds thatare at the market.
This dis-ease has killed many chick-ens and many ducks.??
?
?????
???????
?????
?????
????.
???????
??
??
?????????
??
?????
????.
???????
??
???????
?
??
???????
???
??
???????
????."??
???????
???
???
??
??????
?????.
???
???
????
??????
?.Figure 8.
Examples of LA?s English and Korean Texts8 LA?s ResultsExtensive grammars and lexicons were developedfor English, Korean, Kewa, and Jula.
We beganeach project by working through a set of sentencescalled the Grammar Introduction.
The GrammarIntroduction consists of approximately 500 basicsentences, each illustrating a particular feature orconstruction of the semantic representational sys-tem.
For example, the Grammar Introduction in-cludes a series of propositions dealing with thevarious tenses, aspects, and moods, there?s a set ofpropositions dealing with relative clauses, objectcomplement clauses, and adverbial clauses, anoth-er set of propositions dealing with pronouns, etc.After completing the Grammar Introduction 2 , avery thorough foundation has been developed forthe lexicon and grammar, but the Grammar Intro-duction is intentionally restricted to a very smallset of concepts.
Therefore rules that deal withconcept-specific issues must be dealt with whileworking through actual texts.
While workingthrough the semantic representations of these texts,a very clear trend developed for each of the testlanguages: the number of new grammatical rulesrequired per chapter of text decreased very quicklyas seen in Figures 9 through 12.Figure 9.
Graph of New Rules for JulaFigure 10.
Graph of New Rules for Kewa2 For each test language, working through the Grammar Intro-duction took approximately 40 to 50 hours.64Figure 11.
Graph of New Rules for KoreanFigure 12.
Graph of New Rules for EnglishThe graphs shown above conclusively demonstratethat the grammars developed in LA are accuratelycapturing the significant generalizations of thesefour languages.9 Quality of Generated TextsAfter generating texts in Korean, Kewa, and Jula,experiments were performed to determine whetheror not the drafts generated by LA are of sufficientquality that they improve the productivity of expe-rienced mother-tongue translators.
Two sets ofexperiments were performed: the first set tested forincreased productivity, and the second set testedfor quality.
The first set compared the quantity oftext an experienced translator could translate in agiven period of time with the quantity of text gen-erated by LA that the same person could edit in thegiven time.
Eight professional mother-tonguetranslators participated in the Jula experiment, onetranslator participated in the Kewa experiment, andeighteen translators participated in the Korean ex-periment.
In these experiments, quantity was de-termined by word count.
Table 2 summarizes theresults of these productivity experiments.Language Ratio of Edited Words toManually Translated WordsJula 4.3Kewa 6.7Korean 4.6Table 2.
Summary of Productivity ExperimentsThe table shown above indicates that in each testlanguage, the drafts generated by LA were of suchhigh quality that they more than quadrupled theproductivity of experienced mother-tongue transla-tors.
The results of these experiments were cer-tainly encouraging, but at this point we didn?tknow whether or not the editors had done a thor-ough job of editing the generated texts.
Thereforewe performed another set of experiments to deter-mine whether or not the edited texts were compa-rable in quality with professionally translated texts.10 Quality of Edited TextsThe second set of experiments was performed withJula and Korean speakers in order to determine thequality of the edited LA drafts.
Speakers of theselanguages were asked to compare the edited LAtexts with the manually translated texts.
Theseevaluations were performed by people who did notknow how either of the texts had been produced.Forty evaluations were performed by Jula speak-ers, and 192 evaluations were performed by Kore-an speakers.
Although no evaluations wereperformed by Kewa speakers, the edited Kewadraft was ultimately published.
Table 3 summariz-es the Jula and Korean evaluations.Language LA Texts Manual Texts EqualJula 12 11 17Korean 88 71 33Table 3.
Summary of the Evaluation ExperimentsIn Table 3, the column labeled ?LA Texts?
indi-cates the number of evaluators who said that theedited LA text was better3 than the manually trans-lated text, the column labeled ?Manual Texts?
in-dicates the number of evaluators who said themanually translated text was better than the editedLA text, and the column labeled ?Equal?
indicatesthe number of evaluators who said that the editedLA text was equal in quality to the manually trans-3 The term ?better?
is intentionally very generic.
We didn?twant to ask the evaluators which text was more natural, or waseasier to read, etc.
Instead we let the evaluators choosewhichever text they thought was better for any reason.65lated text.
In both languages the evaluation exper-iments indicate that the edited LA texts are consid-ered as good as the manually translated texts.11 ConclusionsLA is a tool which drastically reduces the amountof time and effort required to produce an initialdraft of a translation of a text.
This tool enableslinguists to build large scale lexicons and gram-mars for a very wide variety of languages, particu-larly minority and endangered languages.
After alexicon and grammar have been completed, LAgenerates drafts of texts which are at approximate-ly a sixth grade reading level.
We hope to eventu-ally have a large library of communitydevelopment texts which will describe how to pre-vent the spread of various diseases such as AIDS,Avian Influenza, etc.
This tool works equally wellfor languages that are thoroughly studied, lan-guages that have only slightly been studied, andlanguages that are endangered.
Similarly, this toolworks equally well for languages that are typologi-cally diverse with respect to their morphologicaland syntactic features.
It is hoped that this toolwill empower speakers of minority languagesaround the world by providing them with transla-tions of vital information, which will not only ena-ble them to live longer, healthier, and moreproductive lives, but will also enable them to par-ticipate in the larger world.ReferencesAllman, Tod.
2010.
The Translator?s Assistant: AMultilingual Natural Language Generator basedon Linguistic Universals, Typologies, and Prim-itives.
Arlington, TX: University of Texas dis-sertation.Allman, Tod, and Stephen Beale.
2006.
A NaturalLanguage Generator for Minority Languages.
InProceedings of Speech and Language Technol-ogy for Minority Languages (SALTMIL).
Gen-oa, Italy.Beale, Stephen.
In print.
Documenting EndangeredLanguages using Linguist?s Assistant.
Lan-guage Documentation and Conservation.
Draftavailable at http:/onyxcons.com/LA/Beale, Stephen, and Tod Allman.
2011.
Linguist?sAssistant: a Resource for Linguists.
In Proceed-ings of 5th International Joint Conference onNatural Language Processing (IJCNLP-11), The9th Workshop on Asian Language Resources,Chiang Mai, Thailand.Cann, Ronnie.
1993.
Formal Semantics.
Cam-bridge: Cambridge University Press.Giv?n, Talmy.
1990.
Syntax: A Functional-Typological Introduction, 2 vols.
Amsterdam:John Benjamins.Goddard, Cliff, and Anna Wierzbicka.
1994.
Se-mantic and Lexical Universals: Theory andEmpirical Findings.
Amsterdam: JohnBenjamins.Jackendoff, Ray.
1990.
Semantic Structures.
Cam-bridge, Massachusetts: The MIT Press.Lakoff, George.
1987.
Women, Fire, and Danger-ous Things.
Chicago: University of ChicagoPress.Longacre, Robert.
1996.
The Grammar of Dis-course.
2nd ed.
New York: Plenum Press.Payne, Thomas.
1997, Describing Morphosyntax.Cambridge: Cambridge University Press.Wierzbicka, Anna.
1996.
Semantics: Primes andUniversals.
Oxford: Oxford University Press.66
