Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 248?252,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsA Corpus of Textual Revisions in Second Language WritingJohn Lee and Jonathan WebsterThe Halliday Centre for Intelligent Applications of Language StudiesDepartment of Chinese, Translation and LinguisticsCity University of Hong Kong{jsylee,ctjjw}@cityu.edu.hkAbstractThis paper describes the creation of the firstlarge-scale corpus containing drafts and fi-nal versions of essays written by non-nativespeakers, with the sentences aligned acrossdifferent versions.
Furthermore, the sentencesin the drafts are annotated with commentsfrom teachers.
The corpus is intended to sup-port research on textual revision by languagelearners, and how it is influenced by feedback.This corpus has been converted into an XMLformat conforming to the standards of the TextEncoding Initiative (TEI).1 IntroductionLearner corpora have been playing an increasinglyimportant role in both Second Language Acquisitionand Foreign Language Teaching research (Granger,2004; Nesi et al, 2004).
These corpora containtexts written by non-native speakers of the lan-guage (Granger et al, 2009); many also annotatetext segments where there are errors, and the cor-responding error categories (Nagata et al, 2011).
Inaddition, some learner corpora contain pairs of sen-tences: a sentence written by a learner of Englishas a second language (ESL), paired with its correctversion produced by a native speaker (Dahlmeierand Ng, 2011).
These datasets are intended to sup-port the training of automatic text correction sys-tems (Dale and Kilgarriff, 2011).Less attention has been paid to how a languagelearner produces a text.
Writing is often an iterativeand interactive process, with cycles of textual revi-sion, guided by comments from language teachers.Discipline # draftsApplied Physics 988Asian and International Studies 410Biology 2310Building Science and Technology 705Business 1754Computer Science 466Creative Media 118Electronic Engineering 1532General Education 651Law 31Linguistics 2165Management Sciences 1278Social Studies 912Total 13320Table 1: Draft essays are collected from courses in vari-ous disciplines at City University of Hong Kong.
Thesedrafts include lab reports, data analysis, argumentativeessays, and article summaries.
There are 3760 distinctessays, most of which consist of two to four successivedrafts.
Each draft has on average 44.2 sentences, and theaverage length of a sentence is 13.3 words.
In total, thecorpus contains 7.9 million words.Understanding the dynamics of this process wouldbenefit not only language teachers, but also the de-sign of writing assistance tools that provide auto-matic feedback (Burstein and Chodorow, 2004).This paper presents the first large-scale corpusthat will enable research in this direction.
After a re-view of previous work (?2), we describe the designand a preliminary analysis of our corpus (?3).248Figure 1: On top is a typical draft essay, interleaved with comments from a tutor (?3.2): two-digit codes from theComment Bank are enclosed in angled brackets, while open-ended comments are enclosed in angled brackets.
On thebottom is the same essay in TEI format, the output of the process described in ?3.3.2 Previous ResearchIn this section, we summarize previous research onfeedback in language teaching, and on the nature ofthe revision process by language learners.2.1 Feedback in Language LearningReceiving feedback is a crucial element in languagelearning.
While most agree that both the form andcontent of feedback plays an important role, thereis no consensus on their effects.
Regarding form,some argue that direct feedback (providing correc-tions) are more effective in improving the quality ofwriting than indirect feedback (pointing out an er-ror but not providing corrections) (Sugita, 2006), butothers reached opposite conclusions (Ferris, 2006;Lee, 2008).Regarding content, it has been observed thatteachers spend a disproportionate amount of timeon identifying word-level errors, at the expense ofthose at higher levels, such as coherence (Furneauxet al, 2007; Zamel, 1985).
There has been no large-scale empirical study, however, on the effectivenessof feedback at the paragraph or discourse levels.2.2 Revision ProcessWhile text editing in general has been ana-lyzed (Mahlow and Piotrowski, 2008), the natureof revisions by language learners ?
for example,whether learners mostly focus on correcting me-chanical, word-level errors, or also substantially re-organize paragraph or essay structures ?
has hardlybeen investigated.
One reason for this gap in theliterature is the lack of corpus data: none of the ex-isting learner corpora (Izumi et al, 2004; Grangeret al, 2009; Nagata et al, 2011; Dahlmeier and Ng,2011) contains drafts written by non-native speakersthat led to the ?final version?.
Recently, two cor-pora with text revision information have been com-piled (Xue and Hwa, 2010; Mizumoto et al, 2011),but neither contain feedback from language teach-ers.
Our corpus will allow researchers to not onlyexamine the revision process, but also investigateany correlation with the amount and type of feed-back.3 Corpus DescriptionWe first introduce the context in which our data wascollected (?3.1), then describe the kinds of com-ments in the drafts (?3.2).
We then outline theconversion process of the corpus into XML format(?3.3), followed by an evaluation (?3.4) and an anal-ysis (?3.5).3.1 BackgroundBetween 2007 and 2010, City University of HongKong hosted a language learning project whereEnglish-language tutors reviewed and providedfeedback on academic essays written by students,249Paragraph level Sentence level Word levelCoherence: more 680 Conjunction missing 1554 Article missing 10586elaboration is neededParagraph: new paragraph 522 Sentence: new sentence 1389 Delete this 9224Coherence: sign posting 322 Conjunction: wrong use 923 Noun: countable 7316Coherence: missing 222 Sentence: fragment 775 Subject-verb 4008topic sentence agreementTable 2: The most frequent error categories from the Comment Bank, aimed at errors at different levels.most of whom were native speakers of Chi-nese (Webster et al, 2011).
More than 300 TESOLstudents served as language tutors, and over 4,200students from a wide range of disciplines (see Ta-ble 1) took part in the project.For each essay, a student posted a first draft1 asa blog on an e-learning environment called Black-board Academic Suite; a language tutor then directlyadded comments on the blog.
Figure 1 shows an ex-ample of such a draft.
The student then revised his orher draft and may re-post it to receive further com-ments.
Most essays underwent two revision cyclesbefore the student submitted the final version.3.2 CommentsComments in the draft can take one of three forms:Code The tutor may insert a two-digit code, repre-senting one of the 60 common error categoriesin our ?Comment Bank?, adopted from theXWiLL project (Wible et al, 2001).
These cat-egories address issues ranging from the wordlevel to paragraph level (see Table 2), witha mix of direct (e.g., ?new paragraph?)
andindirect feedback (e.g., ?more elaboration isneeded?
).Open-ended comment The tutor may also providepersonally tailored comments.Hybrid Both a code and an open-ended comment.For every comment2, the tutor highlights the prob-lematic words or sentences at which it is aimed.Sometimes, general comments about the draft as awhole are also inserted at the beginning or the end.1In the rest of the paper, these drafts will be referred to ?ver-sion 1?, ?version 2?, and so on.2Except those comments indicating that a word is missing.3.3 Conversion to XML FormatThe data format for the essays and comments wasnot originally conceived for computational analysis.The drafts, downloaded from the blog entries, are inHTML format, with comments interspersed in them;the final versions are Microsoft Word documents.Our first task, therefore, is to convert them into amachine-actionable, XML format conforming to thestandards of the Text Encoding Initiative (TEI).
Thisconversion consists of the following steps:Comment extraction After repairing irregularitiesin the HTML tags, we eliminated attributes thatare irrelevant to comment extraction, such asfont and style.
We then identified the CommentBank codes and open-ended comments.Comment-to-text alignment Each comment isaimed at a particular text segment.
The textsegment is usually indicated by highlightingthe relevant words or changing their back-ground color.
After consolidating the tags forhighlighting and colors, our algorithm looksfor the nearest, preceding text segment with acolor different from that of the comment.Title and metadata extraction From the top of theessay, our algorithm scans for short lines withmetadata such as the student and tutor IDs,semester and course codes, and assignment andversion numbers.
The first sentence in the es-say proper is taken to be the title.Sentence segmentation Off-the-shelf sentencesegmentators tend to be trained on newswiretexts (Reynar and Ratnaparkhi, 1997), whichsignificantly differ from the noisy text in ourcorpus.
We found it adequate to use a stop-list,supplemented with a few regular expressions250Evaluation Precision RecallComment extraction- code 94.7% 100%- open-ended 61.8% 78.3%Comment-to-text alignment 86.0% 85.2%Sentence segmentation 94.8% 91.3%Table 3: Evaluation results of the conversion process de-scribed in ?3.3.
Precision and recall are calculated oncorrect detection of the start and end points of commentsand boundaries.that detect exceptions, such as abbreviationsand digits.Sentence alignment Sentences in consecutive ver-sions of an essay are aligned using cosine simi-larity score.
To allow dynamic programming,alignments are limited to one-to-one, one-to-two, two-to-one, or two-to-two3.
Below a cer-tain threshold4, a sentence is no longer aligned,but is rather considered inserted or deleted.
Thealignment results are stored in the XCES for-mat (Ide et al, 2002).3.4 Conversion EvaluationTo evaluate the performance of the conversion algo-rithm described in ?3.3, we asked a human to manu-ally construct the TEI XML files for 14 pairs of draftversions.
These gold files are then compared to theoutput of our algorithm.
The results are shown inTable 3.In comment extraction, codes can be reliablyidentified.
Among the open-ended comments, how-ever, those at the beginning and end of the draftsseverely affected the precision, since they are of-ten not quoted in brackets and are therefore indistin-guishable from the text proper.
In comment-to-textalignment, most errors were caused by inconsistentor missing highlighting and background colors.The accuracy of sentence alignment is 89.8%,measured from the perspective of sentences in Ver-sion 1.
It is sometimes difficult to decide whether asentence has simply been edited (and should there-fore be aligned), or has been deleted with a new sen-tence inserted in the next draft.3That is, the order of two sentences is flipped.4Tuned to 0.5 based on a random subset of sentence pairs.3.5 Preliminary AnalysisAs shown in Table 4, the tutors were much morelikely to use codes than to provide open-ended com-ments.
Among the codes, they overwhelmingly em-phasized word-level issues, echoing previous find-ings (?2.1).
Table 2 lists the most frequent codes.Missing articles, noun number and subject-verbagreement round out the top errors at the word level,similar to the trend for Japanese speakers (Lee andSeneff, 2008).
At the sentence level, conjunctionsturn out to be challenging; at the paragraph level,paragraph organization, sign posting, and topic sen-tence receive the most comments.In a first attempt to gauge the utility of the com-ments, we measured their density across versions.Among Version 1 drafts, a code appears on aver-age every 40.8 words, while an open-ended com-ment appears every 84.7 words.
The respective fig-ures for Version 2 drafts are 65.9 words and 105.0words.
The lowered densities suggest that studentswere able to improve the quality of their writing af-ter receiving feedback.Comment Form FrequencyOpen-ended 47072Hybrid 1993Code 88370- Paragraph level 3.2%- Sentence level 6.0%- Word level 90.8%Table 4: Distribution of the three kinds of comments(?3.2), with the Comment Bank codes further subdividedinto different levels (See Table 2).4 Conclusion and Future WorkWe have presented the first large-scale learner cor-pus which contains not only texts written by non-native speakers, but also the successive drafts lead-ing to the final essay, as well as teachers?
commentson the drafts.
The corpus has been converted into anXML format conforming to TEI standards.We plan to port the corpus to a platform for textvisualization and search, and release it to the re-search community.
It is expected to support stud-ies on textual revision of language learners, and theeffects of different types of feedback.251AcknowledgmentsWe thank Shun-shing Tsang for his assistance withimplementing the conversion and performing theevaluation.
This project was partially funded by aStrategic Research Grant (#7008065) from City Uni-versity of Hong Kong.ReferencesJill Burstein and Martin Chodorow.
2004.
AutomatedEssay Evaluation: The Criterion online writing ser-vice.
AI Magazine.Daniel Dahlmeier and Hwee Tou Ng.
2011.
Grammat-ical Error Correction with Alternating Structure Opti-mization.
Proc.
ACL.Robert Dale and Adam Kilgarriff.
2011.
Helping OurOwn: The HOO 2011 Pilot Shared Task.
Proc.
Eu-ropean Workshop on Natural Language Generation(ENLG), Nancy, France.Dana Ferris.
2006.
Does Error Feedback Help StudentWriters?
New Evidence on the Short- and Long-TermEffects of Written Error Correction.
In Feedback inSecond Language Writing: Contexts and Issues, KenHyland and Fiona Hyland (eds).
Cambridge Univer-sity Press.Clare Furneaux, Amos Paran, and Beverly Fairfax.
2007.Teacher Stance as Reflected in Feedback on StudentWriting: An Empirical Study of Secondary SchoolTeachers in Five Countries.
International Review ofApplied Linguistics in Language Teaching 45(1): 69-94.Sylviane Granger.
2004.
Computer Learner Corpus Re-search: Current Status and Future Prospect.
Languageand Computers 23:123?145.Sylviane Granger, Estelle Dagneaux, Fanny Meunier, andMagali Paquot.
2009. International Corpus of LearnerEnglish v2.
Presses universitaires de Louvain, Bel-gium.Nancy Ide, Patrice Bonhomme, and Laurent Romary.2000.
XCES: An XML-based Encoding Standard forLinguistic Corpora.
Proc.
LREC.Emi Izumi, Kiyotaka Uchimoto, and Hitoshi Isahara.2004.
The NICT JLE Corpus: Exploiting the Lan-guage Learners?
Speech Database for Research andEducation.
International Journal of the Computer, theInternet and Management 12(2):119?125.Icy Lee.
2008.
Student Reactions to Teacher Feedbackin Two Hong Kong Secondary Classrooms.
Journal ofSecond Language Writing 17(3):144-164.John Lee and Stephanie Seneff.
2008.
An Analysis ofGrammatical Errors in Nonnative Speech in English.Proc.
IEEE Workshop on Spoken Language Technol-ogy.Cerstin Mahlow and Michael Piotrowski.
2008.
Linguis-tic Support for Revising and Editing.
Proc.
Interna-tional Conference on Computational Linguistics andIntelligent Text Processing.Tomoya Mizumoto, Mamoru Komachi, Masaaki Nagata,and Yuji Matsumoto.
2011.
Mining Revision Log ofLanguage Learning SNS for Automated Japanese Er-ror Correction of Second Language Learners.
Proc.IJCNLP.Ryo Nagata, Edward Whittaker, and Vera Sheinman.2011.
Creating a Manually Error-tagged and Shallow-parsed Learner Corpus.
Proc.
ACL.Jeffrey C. Reynar and Adwait Ratnaparkhi.
1997.
AMaximum Entropy Approach to Identifying SentenceBoundaries.
Proc.
5th Conference on Applied NaturalLanguage Processing, Washington DC.Yoshihito Sugita.
2006.
The Impact of Teachers?
Com-ment Types on Students?
Revision.
ELT Journal60(1):34?41.Hilary Nesi, Gerard Sharpling, and Lisa Ganobcsik-Williams.
2004.
Student Papers Across the Cur-riculum: Designing and Developing a Corpus ofBritish Student Writing.
Computers and Composition21(4):439?450.Frank Tuzi.
2004.
The Impact of E-Feedback on the Re-visions of L2 Writers in an Academic Writing Course.Computers and Composition 21(2):217-235.Jonathan Webster, Angela Chan, and John Lee.
2011.Online Language Learning for Addressing Hong KongTertiary Students?
Needs in Academic Writing.
AsiaPacific World 2(2):44?65.David Wible, Chin-Hwa Kuo, Feng-Li Chien, Anne Liu,and Nai-Lung Tsao.
2001.
A Web-Based EFL Writ-ing Environment: Integrating Information for Learn-ers, Teachers, and Researchers.
Computers and Edu-cation 37(34):297-315.Huichao Xue and Rebecca Hwa.
2010.
Syntax-DrivenMachine Translation as a Model of ESL Revision.Proc.
COLING.Vivian Zamel.
1985.
Responding to Student Writing.TESOL Quarterly 19(1):79-101.252
