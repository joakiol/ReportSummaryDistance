Coling 2008: Proceedings of the workshop on Multi-source Multilingual Information Extraction and Summarization, pages 57?64Manchester, August 2008Automatic Annotation of Bibliographical References with TargetLanguageHarald Hammarstr?omDept.
of Comp.
Sci.Chalmers UniversityS-412 96 GothenburgSWEDENharald2@chalmers.seAbstractIn a large-scale project to list bibliograph-ical references to all of the ca 7 000 lan-guages of the world, the need arises toautomatically annotated the bibliographi-cal entries with ISO-639-3 language iden-tifiers.
The task can be seen as a specialcase of a more general Information Extrac-tion problem: to classify short text snip-pets in various languages into a large num-ber of classes.
We will explore supervisedand unsupervised approaches motivated bydistributional characterists of the specificdomain and availability of data sets.
Inall cases, we make use of a database withlanguage names and identifiers.
The sug-gested methods are rigorously evaluated ona fresh representative data set.1 IntroductionThere are about 7 000 languages in the world(Hammarstr?om, 2008) and there is a quite accu-rate database of which they are (Gordon, 2005).Language description, i.e., producing a phonologi-cal description, grammatical description, wordlist,dictionary, text collection or the like, of these 7000 languages has been on-going on a larger scalesince about 200 years.
This process is fully de-centralized, and at present there is no database overwhich languages of the world have been described,which have not, and which have partial descrip-tions already produced (Hammarstr?om, 2007b).We are conducting a large-scale project of listingall published descriptive work on the languagesc?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.of the world, especially lesser-known languages.In this project, the following problem naturallyarises:Given: A database of the world?s languages (con-sisting minimally of <unique-id, language-name>-pairs)Input: A bibliographical reference to a work withdescriptive language data of (at least one of)the language in the databaseDesired output: The identification of which lan-guage(s) is described in the bibliographicalreferenceWe would like to achieve this with as little humanlabour as possible.
In particular, this means thatthresholds that are to be set by humans are to beavoided.
However, we will allow (and do makeuse of ?
see below) supervision in the form of data-bases of language references annotated with targetlanguage as long as they are freely available.As an example, say that we are given a bibli-ographical reference to a descriptive work as fol-lows:Dammann, Ernst 1957 Studien zumKwangali: Grammatik, Texte, Glossar,Hamburg: Cram, de Gruyter & Co. [Ab-handlungen aus dem Gebiet der Aus-landskunde / Reihe B, V?olkerkunde,Kulturgeschichte und Sprachen 35]This reference happens to describe a Namibian-Angolan language called Kwangali [kwn].
Thetask is to automatically infer this, for an arbitrarybibliographical entry in an arbitrary language, us-ing the database of the world?s languages and/ordatabases of annotated entries, but without hu-manly tuned thresholds.
(We will assume that57the bibliographical comes segmented into fields,at least as to the title, though this does not mattermuch.
)Unfortunately, the problem is not simply thatof a clean database lookup.
As shall be seen,the distributional characteristics of the world lan-guage database and input data give rise to a specialcase of a more general Information Extraction (IE)problem.
To be more precise, an abstract IE prob-lem may be defined as follows:?
There is a set of natural language objects O?
There is a fixed set of categories C?
Each object in O belong to zero or more cat-egories, i.e., there is a function C : O ?Powerset(C)?
The task is to find classification function fthat mimics C.The special case we are considering here is suchthat:?
Each object in O contains a small amount oftext, on the order of 100 words?
The language of objects in O varies acrossobjects, i.e., not all objects are written in thesame language?
|C| is large, i.e., there are many classes (about7 000 in our case)?
|C(o)| is small for most objects o ?
O, i.e.,most objects belong to very few categories(typically exactly one category)?
Most objects o ?
O contain a few tokensthat near-uniquely identifies C(o), i.e., thereare some words that are very informative asto category, while the majority of tokens arevery little informative.
(This characteristicexcludes the logical possibility that each to-ken is fairly informative, and that the tokenstogether, on an equal footing, serve to pin-point category.
)We will explore and compare ways to exploit theseskewed distributional properties for more informeddatabase lookups, applied and evaluated on theoutlined reference-annotation problem.2 Data and SpecificsThe exact nature of the data at hand is felt to bequite important for design choices in our proposedalgorithm, and is assumed to be unfamiliar to mostreaders, wherefore we go through it in some detailhere.2.1 World Language DatabaseThe Ethnologue (Gordon, 2005) is a database thataims to catalogue all the known living languagesof the world.1As far as language inventory goes,the database is near perfect and language/dialectdivisions are generally accurate, though this issueis thornier (Hammarstr?om, 2005).Each language is given a unique three-letteridentifier, a canonical name and a set of variantand/or dialect names.2The three-letter codes aredraft ISO-639-3 standard.
This database is freelydownloadable3.
For example, the entry for Kwan-gali [kwn] contains the following information:Canonical name: KwangaliISO 639-3: kwnAlternative names4: {Kwangali,Shisambyu, Cuangar, Sambio, Kwan-gari, Kwangare, Sambyu, Sikwangali,Sambiu, Kwangali, Rukwangali}.The database contains 7 299 languages (thus 7299 unique id:s) and a total of 42 768 name tokens.Below are some important characteristics of thesecollections:?
Neither the canonical names nor the alterna-tive names are guaranteed to be unique (toone language).
There are 39 419 unique namestrings (but 42 768 name tokens in the data-base!).
Thus the average number of differentlanguages (= unique id:s) a name denotes is1.08, the median is 1 and the maximum is 14(for Miao).1It also contains some sign languages and some extinctattested languages, but it does not aim or claim to be completefor extinct and signed languages.2Further information is also given, such as number ofspeakers and existence of a bible translation is also given, butis of no concern for the present purposes.3From http://www.sil.org/iso639-3/download.asp accessed 20 Oct 2007.4The database actually makes a difference between dialectnames and other variant names.
In this case Sikwangali, Ruk-wangali, Kwangari, Kwangare are altername names denotingKwangali, while Sambyu is the name of a specific dialect andShisambyu, Sambiu, Sambio are variants of Sambyu.
We willnot make use of the distinction between a dialect name andsome other alternative name.58?
The average number of names (including thecanonical name) of a language is 5.86, themedian is 4, and the maximum is 77 (for Ar-menian [hye]).?
It is not yet well-understood how completedatabase of alternative names is.
In the prepa-ration of the test set (see Section 2.4) an at-tempt to estimate this was made, yielding thefollowing results.
100 randomly chosen bib-liographical entries contained 104 languagenames in the title.
43 of these names (41.3%)existed in the database as written.
66 (63.5%)existed in the database allowing for variationin spelling (cf.
Section 1).
A more interestingtest, which could not be carried out for prac-tical reasons, would be to look at a languageand gather all publications relating to that lan-guage, and collect the names occurring in ti-tles of these.
(To collect the full range ofnames denoting languages used in the bodiesof such publications is probably not a well-defined task.)
The Ethnologue itself does notsystematically contain bibliographical refer-ences, so it is not possible to deduce fromwhere/how the database of alternative nameswas constructed.?
A rough indication of the ratio betweenspelling variants versus alternative rootsamong alternative names is as follows.
Foreach of the 7299 sets of alternative names,we conflate the names which have an edit dis-tance5of?
i for i = 0, .
.
.
, 4.
The mean, me-dian and max number of names after conflat-ing is shown below.
What this means is thatlanguages in the database have about 3 nameson average and another 3 spelling variants onaverage.i Mean Median Max0 5.86 4 77 ?hye?1 4.80 3 65 ?hye?2 4.07 3 56 ?eng?3 3.41 2 54 ?eng?4 2.70 2 47 ?eng?2.2 Bibliographical DataDescriptive data on the languages of the worldare found in books, PhD/MA theses, journal arti-cles, conference articles, articles in collections and5Penalty weights set to 1 for deletion, insertion and sub-stitution alike.manuscripts.
If only a small number of languagesis covered in one publication, the title usually car-ries sufficient information for an experienced hu-man to deduce which language(s) is covered.
Onthe other hand, if a larger number of languages istargeted, the title usually only contains approxi-mate information as to the covered languages, e.g.,Talen en dialecten van Nederlands Nieuw-GuineaorWest African Language Data Sheets.
The (meta-)language [as opposed to target language] of de-scriptive works varies (cf.
Section 2.4).2.3 Free Annotated DatabasesTraining of a classifier (?language annotator?)
in asupervised framework, requires a set of annotatedentries with a distribution similar to the set of en-tries to be annotated.
We know of only two suchdatabases which can be freely accessed6; WALSand the library catalogue of MPI/EVA in Leipzig.WALS: The bibliography for the World At-las of Language Structures book can nowbe accessed online (http://www.wals.info/).
This database contains 5633 entriesannotated to 2053 different languages.MPI/EVA: The library catalogue for the libraryof the Max Planck Institute for Evolution An-thropology (http://biblio.eva.mpg.de/) is queryable online.
InMay 2006 it con-tained 7266 entries annotated to 2246 differ-ent languages.Neither database is free from errors, impreci-sions and inconsistencies (impressionistically 5%of the entries contain such errors).
Nevertheless,for training and development, we used both data-bases put together.
The two databases put together,duplicates removed, contains 8584 entries anno-tated to 2799 different languages.2.4 Test DataIn a large-scale on-going project, we are tryingto collect all references to descriptive work forlesser-known languages.
This is done by tediously6For example, the very wide coverage database world-cat (http://www.worldcat.org/) does not index in-dividual articles and has insufficient language annotation;sometimes no annotation or useless categories such as?other?
or ?Papuan?.
The SIL Bibliography (http://www.ethnologue.com/bibliography.asp) is well-annotated but contains only work produced by the SIL.
(SILhas, however, worked on very many languages, but not allpublications of the de-centralized SIL organization are listedin the so-called SIL Bibliography.
)59going through handbooks, overviews and biblio-graphical for all parts of the world alike.
In thisbibliography, the (meta-)language of descriptivedata is be English, German, French, Spanish, Por-tuguese, Russian, Dutch, Italian, Chinese, Indone-sian, Thai, Turkish, Persian, Arabic, Urdu, Nepali,Hindi, Georgian, Japanese, Swedish, Norwegian,Danish, Finnish and Bulgarian (in decreasing or-der of incidence)7.
Currently it contains 11788 en-tries.
It is this database that needs to be annotatedas to target language.
The overlap with the jointWALS-MPI/EVA database is 3984 entries.8Thus11788 ?
3984 = 7804 entries remain to be an-notated.
From these 7 804 entries, 100 were ran-domly selected and humanly annotated to form atest set.
This test set was not used in the develop-ment at all, and was kept totally fresh for the finaltests.3 ExperimentsWe conducted experiments with three differentmethods, plus the enhancement of spelling varia-tion on top of each one.Naive Lookup: Each word in the title is lookedup as a possible language name in the worldlanguage database and the output is the unionof all answers to the look-ups.Term Weight Lookup: Each word is given aweight according to the number of unique-id:s it is associated with in the training data.Based on these weights, the words of thetitle are split into two groups; informativeand non-informative words.
The output isthe union of the look-up:s of the informativewords in the world language database.Term Weight Lookup with Group Disambiguation:As above, except that names of genealogical(sub-)groups and country names that occurin the title are used for narrowing down theresult.7Those entries which are natively written with a differentalphabet alays also have a transliteration or translation (orboth) into ascii characters.8This overlap at first appears surprisingly low.
Part ofthe discrepancy is due to the fact that many references in theWALS database are in fact to secondary sources, which arenot intended to be covered at all in the on-going project oflisting.
Another reason for the discrepancy is due to a de-prioritization of better-known languages as well as dictionar-ies (as opposed to grammars) in the on-going project.
Even-tually, all unique references will of course be merged.Following a subsection on terminology and defin-itions, these will be presented in increasing orderof sophistication.3.1 Terminology and Definitions?
C: The set of 7 299 unique three-letter lan-guage id:s?
N : The set of 39 419 language name stringsin the Ethnologue (as above)?
C(c): The set of names ?
N associated withthe code c ?
C in the Ethnologue database(as above)?
LN(w) = {id|w ?
C(id), id ?
C}: The setof id:s ?
C that have w as one of its names?
CS(c) = ?winC(c)Spellings(w): The setof variant spellings of the set of names ?N associated with the code c ?
C in theEthnologye database.
For reference, theSpelling(w)-function is defined in detail inTable 1.?
LNS(w) = {id|w ?
CS(id), id ?
C}: Theset of id:s ?
C that have w as a possiblespelling of one of its names?
WE: The set of entries in the joint WALS-MPI/EVA database (as above).
Each entry ehas a title etand a set ecof language id:s?
C?
Words(et): The set of words, everythinglowercased and interpunctation removed, inthe title et?
LWEN(w) = {id|e ?
WE,w ?
et, id ?ec}: The set of codes associated with the en-tries whose titles contain the word w?
TD(w) = LN(w) ?
LWEN(w): The setof codes tied to the word w either as a lan-guage name or as a word that occurs in a ti-tle of an code-tagged entry (in fact, an Eth-nologue entry can be seen as a special kind ofbibliographical entry, with a title consisting ofalternative names annotated with exactly onecategory)?
TDS= LNS(w) ?
LWEN(w): The set ofcodes tied to the word w either as a (variantspelling of a) language name or as a word thatoccurs in a title of an code-tagged entry60?
WC(w) = |TD(w)|: The number of differ-ent codes associated with the word w?
WI(w) = |{et|w ?
Words(et), et?WE}|: The number of different bibliographi-cal entries for which the word w occurs in thetitle?
A: The set of entries in the test set (as above).Each entry e has a title etand a set ecof lan-guage id:s ?
C?
PAA(X) =|{e|X(e)==ec,e?A}||A|: The perfectaccuracy of a classifier function X on testset A is the number of entries in A whichare classified correctly (the sets of categorieshave to be fully equal)?
SAA(X) =?e?A|{X(e)?ec}||ec?X(e)|: The sum ac-curacy of a classifier function X on a test setA is the sum of the (possibly imperfect) ac-curacy of the entries of A (individual entriesmatch with score between 0 and 1)3.2 Naive Union LookupAs a baseline to beat, we define a naive lookupclassifier.
Given an entry e, we define naive unionlookup (NUL) as:NUL(e) = ?w?Words(et)LN(w)For example, consider the following entry e:Anne Gwena??
?elle Fabre 2002?Etude duSamba Leko, parler d?Allani (Cameroundu Nord, Famille Adamawa), PhD The-sis, Universit?e de Paris III ?
SorbonneNouvelleThe steps in itsNUL-classification is as followsare given in Table 2.Finally, NUL(e) = {ndi, lse, smx, dux, lec,ccg}, but, simply enough, ec= {ndi}.The resulting accuracies are PANUL(A) ?0.15 and SANUL(A) ?
0.21.
NUL performseven worse with spelling variants enabled.
Notsurprisingly, NUL overclassifies a lot, i.e., it con-sistently guesses more languages than is the case.This is because guessing that a title word indicatesa target language just because there is one lan-guage with such a name, is not a sound practice.In fact, common words like du [dux], in [irr], the[thx], to [toz], and la [wbm, lic, tdd] happen to benames of languages (!
).3.3 Term Weight LookupWe learn from the Naive Union Lookup experi-ment that we cannot guess blindly which word(s)in the title indicate the target language.
Some-thing has to be done to individate the informa-tiveness of each word.
Domain knowledge tellsus two relevant things.
Firstly, a title of a pub-lication in language description typically containsone or few words with very precise information onthe target language(s), namely the name of the lan-guage(s), and in addition a number of words whichrecur throughout many titles, such as ?a?, ?gram-mar?, etc.
Secondly, most of the language of theworld are poorly described, there are only a few,if any, publications with original descriptive data.Inspired by the tf -idf measure in Information Re-trieval (Baeza-Yates and Ribeiro-Neto, 1997), weclaim that informativeness of a word w, given an-notated training data, can be assessed as WC(w),i.e., the number of distinct codes associated withw in the training data or Ethnologue database.
Theidea is that a uniquitous word like ?the?
will be as-sociated with many codes, while a fairly uniquelanguage name will be associated with only one ora few codes.
For example, consider the followingentry:W. M. Rule 1977 A Comparative Studyof the Foe, Huli and Pole Languagesof Papua New Guinea, University ofSydney, Australia [Oceania LinguisticMonographs 20]Table 3 shows the title words and their associ-ated number of codes associated (sorted in ascend-ing order).So far so good, we now have an informative-ness value for each word, but at which point (abovewhich value?)
do the scores mean that word is anear-unique language name rather than a relativelyubiquitous non-informative word?
Luckily, we areassuming that there are only those two kinds ofwords, and that at least one near-unique languagewill appear.
This means that if we cluster the val-ues into two clusters, the two categories are likelyto emerge nicely.
The simplest kind of clusteringof scalar values into two clusters is to sort the val-ues and put the border where the relative increaseis the highest.
Typically, in titles where there isexactly one near-unique language name, the bor-der will almost always isolate that name.
In theexample above, where we actually have three near-61# Substition Reg.
Exp.
Replacement Comment1.
\?\?\?\?\" ??
diacritics truncated2.
[qk](?=[ei]) qu k-sound before soft vowel to qu3.
k(?=[aou]|$)|q(?=[ao]) c k-sound before hard vowel to c4.
oo|ou|oe u oo, ou, oe to u5.
[hgo]?u(?=[aouei]|$) w hu-sound before hard vowel to w6.
((?:[?aouei]*[aouei][?aouei]*)+?)(?
:an$|ana$|ano$|o$) \1a an?
to a7.
eca$ ec eca to ec8.
tsch|tx|tj ch tsch, tx to ch9.
dsch|dj j dsch, dj to j10.
x(?=i) sh x before i to sh11.
i(?=[aouei]) y i before a vowel to y12.
ern$|i?sche?$ ??
final sche, ern removed13.
([a-z])\1 \1 remove doublets14.
[bdgv] b/p,d/t,g/k,v/f devoice b, d, g, v15.
[oe] o/u,e/i lower vowelsTable 1: Given a language name w, its normalized spelling variants are enumerate according to the fol-lowing (ordered) list of substitution rules.
The set of spelling variants Spelling(w) should be understoodas the strings {w/action1?i|i ?
15}, where w/action1?iis the string with substitutions 1 thru i carriedout.
This normalization scheme is based on extensive experience with language name searching by thepresent author.Words(et) LN(Words(et)) Words(et) LN(Words(et))etude {} cameroun {}du {dux} du {dux}samba {ndi, ccg, smx} nord {}leko {ndi, lse, lec} famille {}parler {} adamawa {}d?allani {}Table 2: The calculation of NUL for an example entryunique identifiers, this procedure correctly puts theborder so that Foe, Pole and Huli are near-uniqueand the rest are non-informative.Now, that we have a method to isolate the groupof most informative words in a title et(denotedSIGWC(et)), we can restrict lookup only to them.TWL is thus defined as follows:TWL(e) = ?w?SIGWC(et)LN(w)In the example above, TWL(et) is{fli, kjy, foi, hui} which is almost correct,containing only a spurious [fli] because Huli isalso an alternative name for Fali in Cameroon,nowhere near Papua New Guinea.
This is acomplication that we will return to in the nextsection.The resulting accuracies jump up toPATWL(A) ?
0.57 and SATWL(A) ?
0.73.Given that we ?know?
which words in the ti-tle are the supposed near-unique language names,we can afford, i.e., not risk too much overgenera-tion, to allow for spelling variants.
Define TWLS(?with spelling variants?)
as:TWLS(e) = ?w?SIGWC(et)LNS(w)We get slight improvements in accuracyPATWLS(A) ?
0.61 and SATWLS(A) ?
0.74.The WC(w)-counts make use of the annotatedentries in the training data.
An intriguing modi-fication is to estimate WC(w) without this anno-tation.
It turns out that WC(w) can be sharplyestimated with WI(w), i.e., the raw number of en-tries in the training set in which w occurs in the62foe pole huli papua guinea comparative new study languages and a the of1 2 3 57 106 110 145 176 418 1001 1101 1169 14821.0 2.0 1.5 19.0 1.86 1.04 1.32 1.21 2.38 2.39 1.10 1.06 1.27Table 3: The values of WC(w) for w taken from an example entry (mid row).
The bottom row showsthe relative increase of the sequence of values in the mid-row, i.e., each value divided by the previousvalue (with the first set to 1.0).title.
This identity breaks down to the extent that aword w occurs in many entries, all of them point-ing to one and the same language id.
From domainknowledge, we know that this is unlikely if w isa near-unique language name, because most lan-guages do not have many descriptive works aboutthem.
The TWL-classifier is now unsupervised inthe sense that it does not have to have annotatedtraining entries, but it still needs raw entries whichhave a realistic distribution.
(The test set, or theset of entries to be annotated, can of course itselfserve as such a set.
)Modeling Term Weight Lookup with WI inplace of WC, call it TWI , yields slight accu-racy drops PATWI(A) ?
0.55 and SATWI(A) ?0.70, and with spelling variants PATWIS(A) ?0.59 and SATWIS(A) ?
0.71.
Since, we do infact have access to annotated data, we will use thesupervised classifier in the future, but it is impor-tant to know that the unsupervised variant is nearlyas strong.4 Term Weight Lookup with GroupDisambiguationAgain, from our domain knowledge, we know thata large number of entries contain a ?group name?,i.e., the name of a country, region of genealogical(sub-)group in addition to a near-unique languagename.
Since group names will naturally tend to beassociated with many codes, they will sorted intothe non-informative camp with the TWL-method,and thus ignored.
This is unfortunate, becausesuch group names can serve to disambiguate in-herent small ambivalences among near-unique lan-guage names, as in the case of Huli above.
Groupnames are not like language names.
They are muchfewer, they are typically longer (often multi-word),and they exhibit less spelling variation.Fortunately, the Ethnologue database also con-tains information on language classification andthe country (or countries) where each languageis spoken.
Therefore, it was a simple task tobuild a database of group names with genealog-ical groups and sub-groups as well as countries.PA SANUL 0.15 0.21TWL 0.57 0.73TWLS0.61 0.74TWI 0.55 0.70TWIS0.59 0.71TWG 0.59 0.74TWGS0.64 0.77Table 4: Summary of methods and correspondingaccuracy scores.All group names are unique9as group names (butsome group names of small genetic groups arethe same as that of a prominent language in thatgroup).
In total, this database contained 3 202groups.
This database is relatively complete forEnglish names of (sub-)families and countries, butshould be enlarged with the corresponding namesin other languages.We can add group-based disambiguation toTWL as follows.
The non-significant words of atitle is searched for matching group names.
The setof languages denoted by a group name is denotedL(g)withL(g) = C if g is not a group name foundin the database.TWG(e) = (?w?SIGWC(et)LN(w))?g?
(Words(et)\SIGWC(et))L(g)We get slight improvements in accuracyPATWG(A) ?
0.59 and SATWG(A) ?
0.74.The corresponding accuracies with spelling vari-ation enabled are PATWG(A) ?
0.64 andSATWG(A) ?
0.77.5 DiscussionA summary of accuracy scores are given in Table4.All scores conform to expected intuitions andmotivations.
The key step beyond naive lookup9In a few cases they were forced unique, e.g., when twofamilies X, Y were listed as having subgroups called Eastern(or the like), the corresponding group names were forced toEastern-X and Eastern-Y respectively.63is the usage of term weighting (and the fact thewe were able to do this without a threshold or thelike).In the future, it appears fruitful to look moreclosely at automatic extraction of groups from an-notated data.
Initial experiments along this linewere unsucessful, because data with evidence forgroups is sparse.
It also seems worthwhile totake multiword language names seriously (whichis more implementational than conceptual work).Given that near-unique language names and groupnames can be reliably identified, it is easy togenerate frames for typical titles of publicationswith language description data, in many languages.Such frames can be combed over large amounts ofraw data to speed up the collection of further rel-evant references, in the typical manner of contem-porary Information Extraction.6 Related WorkAs far as we are aware, the same problem or anisomorphic problem has not previously been dis-cussed in the literature.
It seems likely that isomor-phic problems exist, perhaps in Information Ex-traction in the bioinformatics and/or medical do-mains, but so far we have not found such work.The problem of language identification, i.e.,identify the language of a (written) documentgiven a set of candidate languages and train-ing data for them, is a very different problem?
requiring very different techniques (see Ham-marstr?om (2007a) for a survey and references).We have made important use of ideas from In-formation Retrieval and Data Clustering.7 ConclusionWe have presented (what is believed to be) the firstalgorithms for the specific problem of annotatinglanguage references with their target language(s).The methods used are tailored closely to the do-main and our knowledge of it, but it is likely thatthere are isomorphic domains with the same prob-lem(s).
We have made a proper evaluation and theaccuracy achieved is definetely useful.8 AcknowledgementsWe wish to thank the responsible entities for post-ing the Ethnologue, WALS, and the MPI/EVA li-brary catalogue online.
Without these resources,this study would have been impossible.ReferencesBaeza-Yates, Ricardo and Berthier Ribeiro-Neto.
1997.Modern Information Retrieval.
Addison-Wesley.Gordon, Jr., Raymond G., editor.
2005.
Ethnologue:Languages of the World.
SIL International, Dallas,15 edition.Hammarstr?om, Harald.
2005. Review of the Eth-nologue, 15th ed., Raymond G. Gordon, Jr.
(ed.
),SIL international, Dallas, 2005.
LINGUIST LIST,16(2637), September.Hammarstr?om, Harald.
2007a.
A fine-grained modelfor language identification.
In Proceedings ofiNEWS-07 Workshop at SIGIR 2007, 23-27 July2007, Amsterdam, pages 14?20.
ACM.Hammarstr?om, Harald.
2007b.
Handbook of Descrip-tive Language Knowledge: A Full-Scale ReferenceGuide for Typologists, volume 22 of LINCOM Hand-books in Linguistics.
Lincom GmbH.Hammarstr?om, Harald.
2008.
On the ethnologue andthe number of languages in the world.
SubmittedManuscript.64
