Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 512?516,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsHumans Require Context to Infer Ironic Intent(so Computers Probably do, too)Byron C. Wallace, Do Kook Choe, Laura Kertz and Eugene CharniakBrown University{byron wallace, do kook choe, laura kertz, eugene charniak}@brown.eduAbstractAutomatically detecting verbal irony(roughly, sarcasm) is a challenging taskbecause ironists say something otherthan ?
and often opposite to ?
what theyactually mean.
Discerning ironic intentexclusively from the words and syntaxcomprising texts (e.g., tweets, forumposts) is therefore not always possible:additional contextual information aboutthe speaker and/or the topic at hand isoften necessary.
We introduce a newcorpus that provides empirical evidencefor this claim.
We show that annota-tors frequently require context to makejudgements concerning ironic intent, andthat machine learning approaches tendto misclassify those same comments forwhich annotators required additionalcontext.1 Introduction & MotivationThis work concerns the task of detecting verbalirony online.
Our principal argument is that sim-ple bag-of-words based text classification models?
which, when coupled with sufficient data, haveproven to be extremely successful for many natu-ral language processing tasks (Halevy et al, 2009)?
are inadequate for irony detection.
In this paperwe provide empirical evidence that context is oftennecessary to recognize ironic intent.This is consistent with the large body of prag-matics/linguistics literature on irony and its us-age, which has emphasized the role that contextplays in recognizing and decoding ironic utter-ances (Grice, 1975; Clark and Gerrig, 1984; Sper-ber and Wilson, 1981).
But existing work on au-tomatic irony detection ?
reviewed in Section 2?
has not explicitly attempted to operationalizesuch theories, and has instead relied on features(mostly word counts) intrinsic to the texts that areto be classified as ironic.
These approaches haveachieved some success, but necessarily face anupper-bound: the exact same sentence can be bothintended ironically and unironically, depending onthe context (including the speaker and the topic athand).
Only obvious verbal ironies will be recog-nizable from intrinsic features alone.Here we provide empirical evidence for theabove claims.
We also introduce a new annotatedcorpus that will allow researchers to build modelsthat augment existing approaches to irony detec-tion with contextual information regarding the text(utterance) to be classified and its author.
Briefly,our contributions are summarized as follows.?
We introduce the first version of the redditirony corpus, composed of annotated com-ments from the social news website reddit.Each sentence in every comment in this cor-pus has been labeled by three independent an-notators as having been intended by the au-thor ironically or not.
This dataset is publiclyavailable.1?
We provide empirical evidence that humanannotators consistently rely on contextual in-formation to make ironic/unironic sentencejudgements.?
We show that the standard ?bag-of-words?
ap-proach to text classification fails to accuratelyjudge ironic intent on those cases for whichhumans required additional context.
Thissuggests that, as humans require context tomake their judgements for this task, so too docomputers.Our hope is that these observations and thisdataset will spur innovative new research on meth-ods for verbal irony detection.1https://github.com/bwallace/ACL-2014-irony5122 Previous WorkThere has recently been a flurry of interestingwork on automatic irony detection (Teppermanet al, 2006; Davidov et al, 2010; Carvalho etal., 2009; Burfoot and Baldwin, 2009; Tsur etal., 2010; Gonz?alez-Ib?a?nez et al, 2011; Filatova,2012; Reyes et al, 2012; Lukin and Walker, 2013;Riloff et al, 2013).
In these works, verbal ironydetection has mostly been treated as a standardtext classification task, though with some innova-tive approaches specific to detecting irony.The most common data source used to experi-ment with irony detection systems has been Twit-ter (Reyes et al, 2012; Gonz?alez-Ib?a?nez et al,2011; Davidov et al, 2010), though Amazon prod-uct reviews have been used experimentally as well(Tsur et al, 2010; Davidov et al, 2010; Reyes etal., 2012; Filatova, 2012).
Walker et al (2012)also recently introduced the Internet ArgumentCorpus (IAC), which includes a sarcasm label(among others).Some of the findings from these previous ef-forts have squared with intuition: e.g., overzealouspunctuation (as in ?great idea!!!!?)
is indicative ofironic intent (Carvalho et al, 2009).
Other workshave proposed novel approaches specifically forirony detection: Davidov et al (2010), for ex-ample, proposed a semi-supervised approach inwhich they look for sentence templates indicativeof irony.
Elsewhere, Riloff et al (2013) proposeda method that exploits contrasting sentiment in thesame utterance to detect irony.To our knowledge, however, no previous workon irony detection has attempted to leveragecontextual information regarding the author orspeaker (external to the utterance).
But this is nec-essary in some cases, however.
For example, inthe case of Amazon product reviews, knowing thekinds of books that an individual typically likesmight inform our judgement: someone who tendsto read and review Dostoevsky is probably be-ing ironic if she writes a glowing review of Twi-light.
Of course, many people genuinely do enjoyTwilight and so if the review is written subtly itwill likely be difficult to discern the author?s in-tent without this background.
In the case of Twit-ter, it is likely to be difficult to classify utteranceswithout considering the contextualizing exchangeof tweets (i.e., the conversation) to which they be-long.1234Figure 1: The web-based tool used by our annotators to la-bel reddit comments.
Enumerated interface elements are de-scribed as follows: 1 the text of the comment to be anno-tated ?
sentences marked as ironic are highlighted; 2 buttonsto label sentences as ironic or unironic; 3 buttons to requestadditional context (the embedding discussion thread or asso-ciated webpage ?
see Section 3.2); 4 radio button to provideconfidence in comment labels (low, medium or high).3 Introducing the reddit Irony DatasetHere we introduce the first version (?
1.0) ofour irony corpus.
Reddit (http://reddit.com) is a social-news website to which newsstories (and other links) are posted, voted onand commented upon.
The forum compo-nent of reddit is extremely active: popularposts often have well into 1000?s of user com-ments.
Reddit comprises ?sub-reddits?, which fo-cus on specific topics.
For example, http://reddit.com/r/politics features articles(and hence comments) centered around politicalnews.
The current version of the corpus is avail-able at: https://github.com/bwallace/ACL-2014-irony.
Data collection and annota-tion is ongoing, so we will continue to release new(larger) versions of the corpus in the future.
Thepresent version comprises 3,020 annotated com-ments scraped from the six subreddits enumeratedin Table 1.
These comments in turn comprise atotal of 10,401 labeled sentences.23.1 Annotation ProcessThree university undergraduates independentlyannotated each sentence in the corpus.
Morespecifically, annotators have provided binary ?la-bels?
for each sentence indicating whether or notthey (the annotator) believe it was intended by theauthor ironically (or not).
This annotation wasprovided via a custom-built browser-based anno-tation tool, shown in Figure 1.We intentionally did not provide much guid-ance to annotators regarding the criteria for what2We performed na?
?ve ?segmentation?
of comments basedon punctuation.513sub-reddit (URL) description number of labeled commentspolitics (r/politics) Political news and editorials; focus on the US.
873conservative (r/conservative) A community for political conservatives.
573progressive (r/progressive) A community for political progressives (liberals).
543atheism (r/atheism) A community for non-believers.
442Christianity (r/Christianity) News and viewpoints on the Christian faith.
312technology (r/technology) Technology news and commentary.
277Table 1: The six sub-reddits that we have downloaded comments from and the corresponding number of comments for whichwe have acquired annotations in this ?
version of the corpus.
Note that we acquired labels at the sentence level, whereas thecounts above reflect comments, all of which contain at least one sentence.constitutes an ?ironic?
statement, for two reasons.First, verbal irony is a notoriously slippery concept(Gibbs and Colston, 2007) and coming up with anoperational definition to be consistently applied isnon-trivial.
Second, we were interested in assess-ing the extent of natural agreement between an-notators for this task.
The raw average agreementbetween all annotators on all sentences is 0.844.Average pairwise Cohen?s Kappa (Cohen, 1960)is 0.341, suggesting fair to moderate agreement(Viera and Garrett, 2005), as we might expect fora subjective task like this one.3.2 ContextReddit is a good corpus for the irony detectiontask in part because it provides a natural prac-tical realization of the otherwise ill-defined con-text for comments.
In particular, each comment isassociated with a specific user (the author), andwe can view their previous comments.
More-over, comments are embedded within discussionthreads that pertain to the (usually external) con-tent linked to in the corresponding submission (seeFigure 2).
These pieces of information (previouscomments by the same user, the external link ofthe embedding reddit thread, and the other com-ments in this thread) constitute our context.
Allof this is readily accessible.
Labelers can opt torequest these pieces of context via the annotationtool, and we record when they do so.Consider the following example comment takenfrom our dataset: ?Great idea on the talkathonCruz.
Really made the republicans look like thesane ones.?
Did the author intend this statementironically, or was this a subtle dig on SenatorTed Cruz?
Without additional context it is diffi-cult to know.
And indeed, all three annotators re-quested additional context for this comment.
Thiscontext at first suggests that the comment mayhave been intended literally: it was posted in ther/conservative subreddit (Ted Cruz is a conserva-tive senator).
But if we peruse the author?s com-Figure 2: An illustrative reddit comment (highlighted).
Thetitle (?Virginia Republican ...?)
links to an article, providingone example of contextualizing content.
The conversationalthread in which this comment is embedded provides addi-tional context.
The comment in question was presumably in-tended ironically, though without the aforementioned contextthis would be difficult to conclude with any certainty.ment history, we see that he or she repeatedly de-rides Senator Cruz (e.g., writing ?Ted Cruz is noRonald Reagan.
They aren?t even close.?).
Fromthis contextual information, then, we can reason-ably assume that the comment was intended iron-ically (and all three annotators did so after assess-ing the available contextual information).4 Humans Need Context to Infer IronyWe explore the extent to which human annotatorsrely on contextual information to decide whetheror not sentences were intended ironically.
Recallthat our annotation tool allows labelers to requestadditional context if they cannot make a decisionbased on the comment text alone (Figure 1).
Onaverage, annotators requested additional contextfor 30% of comments (range across annotators of12% to 56%).
As shown in Figure 3, annotatorsare consistently more confident once they haveconsulted this information.We tested for a correlation between these re-quests for context and the final decisions regard-ing whether comments contain at least one ironicsentence.
We denote the probability of at least oneannotator requesting additional context for com-ment i by P (Ci).
We then model the probabilityof this event as a linear function of whether or not5146486174forced decision30 final decision15290529forced decision51 final decision176207364forced decision25 final decisionironic ?ironicironic ?unironicunironic ?unironicunironic ?ironicannotator 1annotator 2 annotator 3Figure 3: This plot illustrates the effect of viewing contextual information for three annotators (one table for each annotator).For all comments for which these annotators requested context, we show forced (before viewing the requested contextualcontent) and final (after) decisions regarding perceived ironic intent on behalf of the author.
Each row shows one of fourpossible decision sequences (e.g., a judgement of ironic prior to seeing context and unironic after).
Numbers correspond tocounts of these sequences for each annotator (e.g., the first annotator changed their mind from ironic to unironic 86 times).Cases that involve the annotator changing his or her mind are shown in red; those in which the annotator stuck with their initialjudgement are shown in blue.
Color intensity is proportional to the average confidence judgements the annotator provided:these are uniformly stronger after they have consulted contextualizing information.
Note also that the context frequently resultsin annotators changing their judgement.any annotator labeled any sentence in comment ias ironic.
We code this via the indicator variableIiwhich is 1 when comment i has been deemedto contain an ironic sentence (by any of the threeannotators) and 0 otherwise.logit{P (Ci)} = ?0+ ?1Ii(1)We used the regression model shown in Equa-tion 1, where ?0is an intercept and ?1capturesthe correlation between requests for context for agiven comment and its ultimately being deemedto contain at least one ironic sentence.
We fit thismodel to the annotated corpus, and found a signif-icant correlation:?
?1= 1.508 with a 95% confi-dence interval of (1.326, 1.690); p < 0.001.In other words, annotators request context sig-nificantly more frequently for those commentsthat (are ultimately deemed to) contain an ironicsentence.
This would suggest that the wordsand punctuation comprising online commentsalone are not sufficient to distinguish ironic fromunironic comments.
Despite this, most machinelearning based approaches to irony detection haverelied nearly exclusively on such intrinsic features.5 Machines Probably do, tooWe show that the misclassifications (with respectto whether comments contain irony or not) madeby a standard text classification model signifi-cantly correlate with those comments for whichhuman annotators requested additional context.This provides evidence that bag-of-words ap-proaches are insufficient for the general task ofirony detection: more context is necessary.We implemented a baseline classification ap-proach using vanilla token count features (binarybag-of-words).
We removed stop-words and lim-ited the vocabulary to the 50,000 most frequentlyoccurring unigrams and bigrams.
We added ad-ditional binary features coding for the presenceof punctuational features, such as exclamationpoints, emoticons (for example, ?;)?)
and questionmarks: previous work (Davidov et al, 2010; Car-valho et al, 2009) has found that these are goodindicators of ironic intent.For our predictive model, we used a linear-kernel SVM (tuning the C parameter via grid-search over the training dataset to maximize F1score).
We performed five-fold cross-validation,recording the predictions y?ifor each (held-out)comment i.
Average F1 score over the five-foldswas 0.383 with range (0.330, 0.412); mean recallwas 0.496 (0.446, 0.548) and average precisionwas 0.315 (0.261, 0.380).
The five most predictivetokens were: !, yeah, guys, oh and shocked.
Thisrepresents reasonable performance (with intuitivepredictive tokens); but obviously there is quite abit of room for improvement.3We now explore empirically whether these mis-classifications are made on the same comments forwhich annotators requested context.
To this end,we introduce a variable Mifor each comment isuch that Mi= 1 if y?i6= yi, i.e., Miis an in-3Some of the recently proposed strategies mentioned inSection 2 may improve performance here, but none of theseaddress the fundamental issue of context.515dicator variable that encodes whether or not theclassifier misclassified comment i.
We then rana second regression in which the output variablewas the logit-transformed probability of the modelmisclassifying comment i, i.e., P (Mi).
Here weare interested in the correlation of the event thatone or more annotators requested additional con-text for comment i (denoted by Ci) and model mis-classifications (adjusting for the comment?s truelabel).
Formally:logit{P (Mi)} = ?0+ ?1Ii+ ?2Ci(2)Fitting this to the data, we estimated?
?2= 0.971with a 95% CI of (0.810, 1.133); p < 0.001.
Putanother way, the model makes mistakes on thosecomments for which annotators requested addi-tional context (even after accounting for the an-notator designation of comments).6 Conclusions and Future DirectionsWe have described a new (publicly available) cor-pus for the task of verbal irony detection.
Thedata comprises comments scraped from the so-cial news website reddit.
We recorded confidencejudgements and requests for contextualizing infor-mation for each comment during annotation.
Weanalyzed this corpus to provide empirical evidencethat annotators quite often require context beyondthe comment under consideration to discern irony;especially for those comments ultimately deemedas being intended ironically.
We demonstratedthat a standard token-based machine learning ap-proach misclassified many of the same commentsfor which annotators tend to request context.We have shown that annotators rely on contex-tual cues (in addition to word and grammatical fea-tures) to discern irony and argued that this impliescomputers should, too.
The obvious next step is todevelop new machine learning models that exploitthe contextual information available in the corpuswe have curated (e.g., previous comments by thesame user, the thread topic).7 AcknowledgementThis work was made possible by the Army Re-search Office (ARO), grant #64481-MA.ReferencesC Burfoot and T Baldwin.
2009.
Automatic satire de-tection: are you having a laugh?
In ACL-IJCNLP,pages 161?164.
ACL.P Carvalho, L Sarmento, MJ Silva, and E de Oliveira.2009.
Clues for detecting irony in user-generatedcontents: oh...!!
it?s so easy;-).
In CIKM workshopon Topic-sentiment analysis for mass opinion, pages53?56.
ACM.HH Clark and RJ Gerrig.
1984.
On the pretense the-ory of irony.
Journal of Experimental Psychology,113:121?126.J Cohen.
1960.
A coefficient of agreement for nom-inal scales.
Educational and Psychological Mea-surement, 20:37?46.D Davidov, O Tsur, and A Rappoport.
2010.
Semi-supervised recognition of sarcastic sentences in twit-ter and amazon.
pages 107?116.E Filatova.
2012.
Irony and sarcasm: Corpus gener-ation and analysis using crowdsourcing.
In LREC,volume 12, pages 392?398.RW Gibbs and HL Colston.
2007.
Irony in languageand thought: a cognitive science reader.
LawrenceErlbaum.R Gonz?alez-Ib?a?nez, S Muresan, and N Wacholder.2011.
Identifying sarcasm in twitter: a closer look.In ACL, volume 2, pages 581?586.
Citeseer.HP Grice.
1975.
Logic and conversation.
1975, pages41?58.A Halevy, P Norvig, and F Pereira.
2009.
The unrea-sonable effectiveness of data.
Intelligent Systems,IEEE, 24(2):8?12.S Lukin and M Walker.
2013.
Really?
well.
ap-parently bootstrapping improves the performance ofsarcasm and nastiness classifiers for online dialogue.NAACL, pages 30?40.A Reyes, P Rosso, and T Veale.
2012.
A multidimen-sional approach for detecting irony in twitter.
LREC,pages 1?30.E Riloff, A Qadir, P Surve, LD Silva, N Gilbert, andR Huang.
2013.
Sarcasm as contrast between a pos-itive sentiment and negative situation.
In EMNLP,pages 704?714.D Sperber and D Wilson.
1981.
Irony and the use-mention distinction.
1981.J Tepperman, D Traum, and S Narayanan.
2006.?Yeah Right?
: Sarcasm Recognition for Spoken Di-alogue Systems.O Tsur, D Davidov, and A Rappoport.
2010.
ICWSM-a great catchy name: Semi-supervised recognitionof sarcastic sentences in online product reviews.
InAAAI Conference on Weblogs and Social Media.AJ Viera and JM Garrett.
2005.
Understanding in-terobserver agreement: the kappa statistic.
FamilyMedicine, 37(5):360?363.MA Walker, JEF Tree, P Anand, R Abbott, and J King.2012.
A corpus for research on deliberation and de-bate.
In LREC, pages 812?817.516
