Proceedings of the 10th Conference on Parsing Technologies, pages 80?82,Prague, Czech Republic, June 2007. c?2007 Association for Computational LinguisticsNbest Dependency Parsing with linguistically rich modelsXiaodong ShiInstitute of Artificial IntelligenceDepartment of Computer ScienceXiamen University, Xiamen 361005mandel@xmu.edu.cnYidong ChenInstitute of Artificial IntelligenceDepartment of Computer ScienceXiamen University, Xiamen 361005ydchen@xmu.edu.cnAbstractWe try to improve the classifier-based de-terministic dependency parsing in twoways: by introducing a better searchmethod based on a non-deterministic nbestalgorithm and by devising a series of lin-guistically richer models.
It is experimen-tally shown on a ConLL 2007 shared taskthat this results in a system with higher per-formance while still keeping it simpleenough for an efficient implementation.1 IntroductionThis work tries to improve the deterministic de-pendency parsing paradigm introduced in (Coving-ton 2001, Nivre 2003, Nivre and Hall, 2005) whereparsing is performed incrementally in a strict left-to-right order and a machine learned classifier isused to predict deterministically the next parseraction.
Although this approach is very simple, itachieved the state-of-art parsing accuracy.
How-ever, there are still some problems that leave fur-ther room for improvement:(1) A greedy algorithm without backtrackingcannot ensure to find the optimal solution.
In thecourse of left-to-right parsing, when further con-text is seen, the previous decisions may be wrongbut a deterministic parser cannot correct it.
Theusual way of preventing early error ?commitment?is to enable a k-best or beam-search strategy(Huang and Chiang 2005, Sagae and Lavie 2006).
(2) A classifier based approach (e.g.
using SVMor memory based learning) is usually linguisticallyna?ve, to make it applicable to multiple languages.However, a few studies (Collins 1999, Charniak etal 2003, Galley et al2006) have shown that lin-guistically sophisticated models can have a betteraccuracy at parsing, language modeling, and ma-chine translation, among others.In this paper we explore ways to improve on theabove-mentioned deterministic parsing model toovercome the two problems.
The rest of the paperis organized as follows.
Section 2 argues for asearch strategy better at finding the optimal solu-tion.
In section 3 we built a series of linguisticallyricher models and show experimental results dem-onstrating their practical consequences.
Finally wedraw our conclusions and point out areas to be ex-plored further.2 Dependency Parsing EnhancementsIn the classifier-based approach as in Nivre (2003)a parse tree is produced by a series of actionssimilar to a left-to-right shift-reduce parser.
Themain source of errors in this method is theirrevocability of the parsing action and a wrongdecision can therefore lead to further inaccuraciesin later stages.
So it cannot usually handle garden-path sentences.
Moreover, each action is usuallypredicted using only the local features of the wordsin a limited window, although dynamic features ofthe local context can be exploited (Carreras 2006).To remedy this situation, we just add a scoringfunction and a priority queue which records nbestpartial parses.
The scoring function is defined onthe parsing actions and the features of a partialparse.
It can be decomposed into two subfunctions:score(a,y)=parsing_cost(a,y) + lm(y)where a is parsing actions and y is partial parses,and parsing cost (parsing_cost) is used to imple-ment certain parsing preferences while the lingus-tic model score (lm) is usually modeled in the lin-guistic (in our case, dependency model) framework.80In the usual nbest or beam-search implementation(e.g.
Huang and Chiang 2005, Sagae and Lavie2006), only lm is present.We give justification of the first term as follows:Many probability functions need to know the de-pendency label and relative distance between thedependent and the head.
However, during parsingsometimes this head-binding can be very late.
Thismeans a right-headed word may need to wait verylong for its right head, and so a big partial-parsequeue is needed, while psychological evidencesuggests that there is some overhead involved inprocessing every word and a word tends to attachlocally.
By modeling parsing cost we can first usea coarse probability model to guide the nbest par-tial results in order not to defer the probability cal-culation.
As parsing progresses, more informationbecomes available; we can have a better estimationof our linguistic probability model to rectify theinaccuracy.This use of a coarse scoring mechanism to guidethe early parsing for possible later rectification ofthe decision is a novel feature of our parsingframework and enables better searching of the so-lution space.
To implement it, we just rememberthe exact score of the every major decision (wait,add a dependent or attach a head) in parsing, andre-score when more context is available.
Comparedwith (Charniak 2005), our parsing process requiresonly one pass.Thus, we can strike a balance between accuracy,memory and speed.
With a moderately-sized n(best partial results), we can reduce memory useand get higher speed to get a same accuracy.
Anadded advantage is that this idea is also useful inother bottom-up parsing paradigms (not only in adependency framework).In a word, our main innovation is the use of aparsing cost to influence the search paths, and theuse of an evolving lm function to enable progres-sively better modeling.
The nbest framework isgeneral enough to make this a very simple modifi-cation to the basic algorithm of Nivre (2003).3 Better Linguistic ModelingIn our modeling we combine different linguisticmodels by using many probability functions:lm(y)=?logP(wi,wj,x,y) =?W*log Pwhere w are the trained weight vector and P is avector of probability functions.
In our system weconsidered the following functions:P1: function measuring the probability of a headand a dependent.
This is the base function in mostdependency parsing framework.P2: function calculating the subcategorizationframe probability;P3:  function calculating the semantic frame us-ing a Chinese FrameNet (Liu 2006).P4: function measuring the semantic affinity be-tween a head and a dependent using resources suchas Hownet (Dong 2003).P5: Other Chinese specific probability functionsdefined on the features of the head, the dependents,the partial parse and the input.Model P2 is a probability function on pseudosubcategorization frames (as a concatenation of allthe dependents?
labels) as we don?t know the dis-tinction of arguments and adjuncts in the depend-ency Treebank.
We used a Markovian subcategori-zation scheme with left and right STOP delimitersto ease the data sparseness.
And as a first approxi-mation, we also experimented with a model whereeach label can only be used a certain times in adirection.
This model is called P2?
in Table 4.Other functions (P3-P5) are also very usefulwith its different linguistic content.
Model P5 actu-ally contains a lot of Chinese-specific functions,e.g.
between a sentence-final particle and a verb.We designed a series of experiments to show toeffectiveness of each model.
We use the Chinesetraining data of the ConLL 2007 shared task.
Wedivided the training data by a 9:1 split.
Table 1shows the statistics.Training testingsentences 51777 5180Words 302943 34232Table 1.
Experimental dataIn the baseline model, we train a simple probabilityfunction between a head and a dependent usingdeleted interpolation.
For nbest=1, we have adeterministic model.LAS UAS timeDeterministic 41.64 % 44.11 % 8snbest = 50 71.30 % 76.34 % 72snbest  = 500 71.90 % 76.99 % 827sTable 2. baseline systemsIt can be seen (Table 3) that combing differentlinguistic information can lead to significant in-81crease of the accuracy.
However, different modelshave different contributions.
Our experiments con-firm with Collins?s result in that subcategorizationcarries very important linguistic content.LAS UAS timeP1 71.90 % 76.99 % 827sP1 + P2?
73.45 % 78.44 % 832sP1 + P2?
+ P2 77.92 % 82.42 % 855sP1 + P2 + P3 79.13% 83.57% 1003sP1-4 81.21% 85.78% 1597sP1-5 83.12% 87.03% 2100sVerb valency  85.32 % 89.12 % -DE refinement 85.98% 90.20% -Table 3. systems with different linguistic models3.1 Relabeling of the parse treebankSometimes the information needed in the modelingis not in the data explicitly.
Implicit informationcan be made explicit and accessible to the parser.In the Chinese Treebank the relation label isoften determined by the head word?s semantic type.We tried the relabeling of coarse POS info of theverb in a effort to detect its valency; and refine-ment of the auxiliary word  ?
DE (as error analy-sis shows it is the where the most errors occur).Results are in Table 3.We also tried refinement of the relation label byusing the two connected words.
However, this doesnot improve the result.
Automatic linguistic model-ing using latent label (Matsuzaki 2005) can also beattempted but is not yet done.4 ConclusionsIn this paper we showed that simple classifier-based deterministic dependency parsing can beimproved using a more flexible search strategyover an nbest parsing framework and a variety oflinguistically richer models.
By incorporating dif-ferent linguistic knowledge, the parsing model canbe made more accurate and thus achieves betterresults.Further work to be done includes ways to com-bine machine learning based on the automatic fea-ture selection with manual linguistic modeling: aninteractive approach for better synergistic model-ing (where the machine proposes and the humanguides).
Various a priori models can be tried by themachine and patterns inherent in the data can berevealed to the human who can then explore morecomplex models.ReferencesXavier Carreras, Mihai Surdeanu, and Llu?s M?rquez.2006.
Projective Dependency Parsing with Percep-tron.
In Proceedings of CoNLL-X.
181-185.Liang Huang and David Chiang.
2005.
Better k-bestparsing.
In Proceedings of IWPT.Eugene Charniak; K. Knight, and K.Yamada.
2003.Syntax-based language models for statistical ma-chine translation.
In MT Summit IX.
Intl.
Assoc.
forMachine Translation.Eugene Charniak and Mark Johnson.
2005.
Coarse-tofine n-best parsing and maxent discriminativereranking.
In Proceedings of ACL.Michael Collins.
1999.
Head-Driven Statistical Models-for Natural Language Parsing.
PhD Dissertation,University of Pennsylvania.Michael Collins.
2004.
Parameter Estimation for Statis-tical Parsing Models: Theory and Practice of Distri-bution-Free Methods.
In Harry Bunt el al, New De-velopments in Parsing Technology, Kluwer.Michael A. Covington.
2001.
A fundamental algorithmfor dependency parsing.
Proceedings of the 39th An-nual ACM Southeast Conference, pp.
95-102.Zhendong Dong  and Qiang Dong.
2003.
HowNet - ahybrid language and knowledge resource.
In Pro-ceeding of Natural Language Processing and Knowl-edge Engineering.M.
Galley, J. Graehl, K. Knight, D. Marcu, S. DeNeefe,W.
Wang, and I. Thayer.
2006.
Scalable Inferenceand Training of Context-Rich Syntactic Models.
InProc.
ACL-COLING.Kaiying Liu.
2006.
Building a Chinese FrameNet.
InProceeding of 25th anniversary of Chinese Informa-tion Processing Society of China.Takuya Matsuzaki, Yusuke Miyao, Jun'ichi Tsujii.
2005.Probabilistic CFG with latent annotations.
In Pro-ceedings of ACL-2005.Joakim Nivre.
2003.
An efficient algorithm for projec-tive dependency parsing.
In Proceedings of IWPT.149-160.Joakim Nivre and Johan Hall.
2005.
MaltParser: A Lan-guage-Independent System for Data-Driven Depend-ency Parsing.
In Proceedings of the Fourth Work-shop on Treebanks and Linguistic.
Theories, Barce-lona, 9-10 December 2005.
137-148.Sagae, K. and Lavie, A.
2006 A best-first probabilisticshift-reduce parser.
In Proceedings of ACL.82
