Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X),pages 166?170, New York City, June 2006. c?2006 Association for Computational LinguisticsExperiments with a Multilanguage Non-ProjectiveDependency ParserGiuseppe AttardiDipartimento di Informaticalargo B. Pontecorvo, 3I-56127 Pisa, Italyattardi@di.unipi.it1 IntroductionParsing natural language is an essential step inseveral applications that involve documentanalysis, e.g.
knowledge extraction, questionanswering, summarization, filtering.
The bestperforming systems at the TREC QuestionAnswering track employ parsing for analyzingsentences in order to identify the query focus, toextract relations and to disambiguate meanings ofwords.These are often demanding applications, whichneed to handle large collections and to provideresults in a fraction of a second.
Dependencyparsers are promising for these applications since adependency tree provides predicate-argumentrelations which are convenient for use in the laterstages.
Recently statistical dependency parsingtechniques have been proposed which aredeterministic and/or linear (Yamada andMatsumoto, 2003; Nivre and Scholz, 2004).
Theseparsers are based on learning the correct sequenceof Shift/Reduce actions used to construct thedependency tree.
Learning is based on techniqueslike SVM (Vapnik 1998) or Memory BasedLearning (Daelemans 2003), which provide highaccuracy but are often computationally expensive.Kudo and Matsumoto (2002) report a two weeklearning time on a Japanese corpus of about 8000sentences with SVM.
Using Maximum Entropy(Berger, et al 1996) classifiers I built a parser thatachieves a throughput of over 200 sentences persecond, with a small loss in accuracy of about 2-3 %.The efficiency of Maximum Entropy classifiersseems to leave a large margin that can be exploitedto regain accuracy by other means.
I performed aseries of experiments to determine whetherincreasing the number of features or combiningseveral classifiers could allow regaining the bestaccuracy.
An experiment cycle in our settingrequires less than 15 minutes for a treebank ofmoderate size like the Portuguese treebank(Afonso et al, 2002) and this allows evaluating theeffectiveness of adding/removing features thathopefully might apply also when using otherlearning techniques.I extended the Yamada-Matsumoto parser tohandle labeled dependencies: I tried twoapproaches: using a single classifier to predictpairs of actions and labels and using two separateclassifiers, one for actions and one for labels.Finally, I extended the repertoire of actions usedby the parser, in order to handle non-projectiverelations.
Tests on the PDT (B?hmov?
et al, 2003)show that the added actions are sufficient to handleall cases of non-projectivity.
However, since thecases of non-projectivity are quite rare in thecorpus, the general learner is not supplied enoughof them to learn how to classify them accurately,hence it may be worthwhile to exploit a secondclassifier trained specifically in handling non-projective situations.1.
Summary of the approachThe overall parsing algorithm is an inductivestatistical parser, which extends the approach byYamada and Matsumoto (2003), by adding six newreduce actions for handling non-projectiverelations and also performs dependency labeling.Parsing is deterministic and proceeds bottom-up.Labeling is integrated within a single processingstep.166The parser is modular: it can use severallearning algorithms: Maximum Entropy, SVM,Winnow, Voted Perceptron, Memory BasedLearning, as well as combinations thereof.
Thesubmitted runs used Maximum Entropy and Ipresent accuracy and performance comparisonswith other learning algorithms.No additional resources are used.No pre-processing or post-processing is used,except stemming for Danish, German and Swedish.2 FeaturesColumns from input data were used as follows.LEMMA was used in features wheneveravailable, otherwise the FORM was used.
ForDanish, German and Swedish the Snowballstemmer (Porter 2001) was used to generate avalue for LEMMA.
This use of stemming slightlyimproved both accuracy and performance.Only CPOSTAG were used.
PHEAD/PDEPRELwere not used.FEATS were used to extract a single tokencombining gender, number, person and case,through a language specific algorithm.The selection of features to be used in the parseris controlled by a number of parameters.
For ex-ample, the parameter PosFeatures determinesfor which tokens the POS tag will be included inthe context, PosLeftChildren determines howmany left outermost children of a token to con-sider, PastActions tells how many previous ac-tions to include as features.The settings used in the submitted runs are listedbelow and configure the parser for not using anyword forms.
Positive numbers refer to input to-kens, negative ones to token on the stack.LemmaFeatures         -2 -1 0 1 2 3PosFeatures           -2 -1 0 1 2 3MorphoFeatures        -1 0 1 2DepFeatures           -1 0PosLeftChildren       2PosLeftChild          -1 0DepLeftChild          -1 0PosRightChildren      2PosRightChild         -1 0DepRightChild         -1PastActions           1The context for POS tags consisted of 1 token leftand 3 tokens to the right of the focus words, exceptfor Czech and Chinese were 2 tokens to the leftand 4 tokens to the right were used.
These valueswere chosen by performing experiments on thetraining data, using 10% of the sentences as held-out data for development.3 Inductive Deterministic ParsingThe parser constructs dependency trees employinga deterministic bottom-up algorithm which per-forms Shift/Reduce actions while analyzing inputsentences in left-to-right order.Using a notation similar to (Nivre and Scholz,2003), the state of the parser is represented by aquadruple ?S, I, T, A?, where S is the stack, I is thelist of (remaining) input tokens, T is a stack oftemporary tokens and A is the arc relation for thedependency graph.Given an input string W, the parser is initializedto ?
(), W, (), ()?, and terminates when it reaches aconfiguration ?S, (), (), A?.The parser by Yamada and Matsumoto (2003)used the following actions:Shift in a configuration ?S, n|I, T, A?, pushesn to the stack, producing the configura-tion ?n|S, I, T, A?.Right1 in a configuration ?s1|S, n|I, T, A?, addsan arc from s1 to n and pops s1 from thestack, producing the configuration ?S,n|I, T, A?
{(s1, r, n)}?.Left in a configuration ?s1|S, n|I, T, A?, addsan arc from n to s1, pops n from input,pops s1 from the stack and moves itback to I, producing the configuration?S, s1|I, T, A?
{(n, r, s1)}?.At each step the parser uses classifiers trained ontreebank data in order to predict which action toperform and which dependency label to assigngiven the current configuration.4 Non-Projective RelationsFor handling non-projective relations, Nivre andNilsson (2005) suggested applying a pre-processing step to a dependency parser, which con-sists in lifting non-projective arcs to their head re-peatedly, until the tree becomes pseudo-projective.A post-processing step is then required to restorethe arcs to the proper heads.1Nivre and Scholz reverse the direction, while I follow herethe terminology in Yamada and Matsumoto (2003).167I adopted a novel approach, which consists inadding six new parsing actions:Right2 in a configuration ?s1|s2|S, n|I, T, A?,adds an arc from s2 to n and removes s2from the stack, producing the configu-ration ?s1|S, n|I, T, A?
{(s2, r, n)}?.Left2 in a configuration ?s1|s2|S, n|I, T, A?,adds an arc from n to s2, pops n frominput, pops s1 from the stack and movesit back to I, producing the configuration?s2|S, s1|I, T, A?
{(n, r, s2)}?.Right3 in a configuration ?s1|s2|s3|S, n|I, T, A?,adds an arc from s3 to n and removes s3from the stack, producing the configu-ration ?s1|s2|S, n|I, T, A?
{(s3, r, n)}?.Left3 in a configuration ?s1|s2|s3|S, n|I, T, A?,adds an arc from n to s3, pops n frominput, pops s1 from the stack and movesit back to I, producing the configuration?s2|s3|S, s1|I, T, A?
{(n, r, s3)}?.Extract in a configuration ?s1|s2|S, n|I, T, A?,move s2 from the stack to the temporarystack, then Shift, producing the con-figuration ?n|s1|S, I, s2|T, A?.Insert in a configuration ?S, I, s1|T, A?, pops s1from T and pushes it to the stack, pro-ducing the configuration ?s1|S, I, T, A?.The actions Right2 and Left2 are sufficient tohandle almost all cases of non-projectivity: for in-stance the training data for Czech contain 28081non-projective relations, of which 26346 can behandled by Left2/Right2, 1683 byLeft3/Right3 and just 52 require Ex-tract/Insert.Here is an example of non-projectivity that canbe handled with Right2 (nejen ?
ale) and Left3(fax ?
V?t?inu):V?t?inu t?chto p??stroj?
lze take pou?
?vat nejen jako fax,ale sou?asn?
?The remaining cases are handled with the last twoactions: Extract is used to postpone the creationof a link, by saving the token in a temporary stack;Insert restores the token from the temporarystack and resumes normal processing.This fragment in Dutch is dealt by performing anExtract in configuration ?moeten|gemaakt|zou,worden|in, A?
followed immediately by an In-sert, leading to the following configuration,which can be handled by normal Shift/Reduceactions:Another linguistic phenomenon is the anticipationof pronouns, like in this Portuguese fragment:Tudo ?
possivel encontrar em o IXSal?o de Antiguidades, desde objectosde ouro e prata, moedas, ?The problem here is due to the pronoun Tudo(Anything), which is the object of encontrar(find), but which is also the head of desde (from)and its preceding comma.
In order to be able toproperly link desde to Tudo, it is necessary topostpone its processing; hence it is saved with Ex-tract to the temporary stack and put back later infront of the comma with Insert.
In fact the pairExtract/Insert behaves like a generalizedRightn/Leftn, when n is not known.
As in theexample, except for the case where n=2, it is diffi-cult to predict the value of n, since there can be anarbitrary long sequence of tokens before reachingthe position where the link can be inserted.5 PerformanceI used my own C++ implementation of MaximumEntropy, which is very fast both in learning andclassification.
On a 2.8 MHz Pentium Xeon PC,the learning time is about 15 minutes for Portu-guese and 4 hours for Czech.
Parsing is also veryfast, with an average throughput of 200 sentencesper second: Table 1 reports parse time for parsingeach whole test set.
Using Memory Based Learn-ing increases considerably the parsing time, whileas expected learning time is quite shorter.
On theother hand MBL achieves an improvement up to5% in accuracy, as shown in detail in Table 1.zou moeten worden gemaakt inzou gemaakt moeten worden inV?t?inu t?chto p??stroj?
lze take pou?
?vat nejen jako fax  ,  ale168Language Maximum Entropy MBLLAS%Cor-rectedLASUAS%LA%TraintimesecParsetimesecLAS%UAS%LA%TraintimesecParsetimesecArabic 53.81 54.15 69.50 72.97 181 2.6 59.70 74.69 75.49 24 950Bulgarian 72.89 72.90 85.24 77.68 452 1.5 79.17 85.92 83.22 88 353Chinese 54.89 70.00 81.33 58.75 1156 1.8 72.17 83.08 75.55 540 478Czech 59.76 62.10 73.44 69.84 13800 12.8 69.20 80.22 77.72 496 13500Danish 66.35 71.72 78.84 74.65 386 3.2 76.13 83.65 82.06 52 627Dutch 58.24 63.71 68.93 66.47 679 3.3 68.97 74.73 75.93 132 923German 69.77 75.88 80.25 78.39 9315 4.3 79.79 84.31 86.88 1399 3756Japanese 65.38 78.01 82.05 73.68 129 0.8 83.39 86.73 89.95 44 97Portuguese 75.36 79.40 85.03 80.79 1044 4.9 80.97 86.78 85.27 160 670Slovene 57.19 60.63 72.14 69.36 98 3.0 62.67 76.60 72.72 16 547Spanish 67.44 70.33 74.25 82.19 204 2.4 74.37 79.70 85.23 54 769Swedish 68.77 75.20 83.03 72.42 1424 2.9 74.85 83.73 77.81 96 1177Turkish 37.80 48.83 65.25 49.81 177 2.3 47.58 65.25 59.65 43 727Table 1.
Results for the CoNLL-X Shared task (official values in italics).For details on the CoNLL-X shared task and themeasurements see (Buchholz, et al 2006).6 ExperimentsI performed several experiments to tune the parser.I also tried alternative machine learning algo-rithms, including SVM, Winnow, Voted Percep-tron.The use of SVM turned out quite impracticalsince the technique does not scale to the size oftraining data involved: training an SVM with sucha large number of features was impossible for anyof the larger corpora.
For smaller ones, e.g.
Portu-guese, training required over 4 days but produced abad model which could not be used (I tried boththe TinySVM (Kudo 2002) and the LIBSVM(Chang and Lin 2001) implementations).Given the speed of the Maximum Entropy clas-sifier, I explored whether increasing the number offeatures could improve accuracy.
I experimentedadding various features controlled by the parame-ters above: none appeared to be effective, exceptthe addition of the previous action.The classifier returns both the action and the la-bel to be assigned.
Some experiments were carriedout splitting the task among several specializedclassifiers.
I experimented with:1. three classifiers: one to decide betweenShift/Reduce, one to decide which Reduceaction and a third one to choose the depend-ency in case of Left/Right action2.
two classifiers: one to decide which action toperform and a second one to choose the de-pendency in case of Left/Right actionNone of these variants produced improvements inprecision.
Only a small improvement in labeledattachment score was noticed using the full, non-specialized classifier to decide the action but dis-carding its suggestion for label and using a special-ized classifier for labeling.
However this wascombined with a slight decrease in unlabeled at-tachment score, hence it was not considered worththe effort.7 Error AnalysisThe parser does not attempt to assign a dependencyrelation to the root.
A simple correction of assign-ing a default value for each language gave an im-provement in the LAS as shown in Table 1.7.1 PortugueseOut of the 45 dependency relations that the parserhad to assign to a sentence, the largest number of169errors occurred assigning N<PRED (62), ACC (46),PIV (43), CJT (40), N< (34), P< (30).The highest number of head error occurred atthe CPOS tags PRP with 193 and V with 176.
Inparticular just four prepositions (em, de, a, para)accounted for 120 head errors.Most of the errors occur near punctuations.
Of-ten this is due to the fact that commas introducerelative phrases or parenthetical phrases (e.g.
?osuspeito, de 38 anos, que trabalha?
),that produce diversions in the flow.
Since theparser makes decisions analyzing only a windowof tokens of a limited size, it gets confused in cre-ating attachments.
I tried to add some global con-text features, to be able to distinguish these cases,in particular, a count of the number of punctuationmarks seen so far, whether punctuation is presentbetween the focus words.
None of them helpedimproving precision and were not used in the sub-mitted runs.7.2 CzechMost current parsers for Czech do not perform wellon Apos (apposition), Coord (coordination) andExD (ellipses), but they are not very frequent.
Thelargest number of errors occur on Obj (166), Adv(155), Sb (113), Atr (98).
There is also often con-fusion among these: 33 times Obj instead of Adv,32 Sb instead of Obj, 28 Atr instead of Adv.The high error rate of J (adjective) is expected,mainly due to coordination problems.
The error ofR (preposition) is also relatively high.
Prepositionsare problematic, but their error rate is higher thanexpected since they are, in terms of surface order,rather regular and close to the noun.
It could bethat the decision by the PDT to hang them as headsinstead of children, causes a problem in attachingthem.
It seems that a post-processing may correct asignificant portion of these errors.The labels ending with _Co, _Ap or _Pa arenodes who are members of the Coordination, Ap-position or the Parenthetical relation, so it may beworth while omitting these suffixes in learning andrestore them by post-processing.An experiment using as training corpus a subsetconsisting of just sentences which include non-projective relations achieved a LAS of 65.28 %and UAS of 76.20 %, using MBL.Acknowledgments.
Kiril Ribarov provided in-sightful comments on the results for Czech.The following treebanks were used for training theparser: (Afonso et al, 2002; Atalay et al, 2003;B?hmov?
et al, 2003; Brants et al, 2002; Chen etal., 2003; Civit Torruella and Mart?
Anton?n, 2002;D?eroski et al, 2006; Haji?
et al, 2004; Kawataand Bartels, 2000; Kromann, 2003; Nilsson et al,2005; Oflazer et al, 2003; Simov et al, 2005; vander Beek et al, 2002).ReferencesA.
Berger, S. Della Pietra, and M. Della Pietra.
1996.
AMaximum Entropy Approach to Natural LanguageProcessing.
Computational Linguistics, 22(1).S.
Buchholz, et al 2006.
CoNLL-X Shared Task onMultilingual Dependency Parsing.
In Proc.
of theTenth CoNLL.C.-C. Chang, C.-J.
Lin.
2001.
LIBSVM: a library forsupport vector machines.http://www.csie.ntu.edu.tw/~cjlin/libsvm/W.
Daelemans, J. Zavrel, K. van der Sloot, and A. vanden Bosch.
2003.
Timbl: Tilburg memory basedlearner, version 5.0, reference guide.
Technical Re-port ILK 03-10, Tilburg University, ILK.T.
Kudo.
2002. tinySVM.http://www.chasen.org/~taku/software/TinySVM/T.
Kudo, Y. Matsumoto.
2002.
Japanese DependencyAnalysis using Cascaded Chunking.
In Proc.
of theSixth CoNLL.R.
McDonald, et al 2005.
Non-projective DependencyParsing using Spanning Tree Algorithms.
In Proc.
ofHLT-EMNLP.J.
Nivre, et al 2004.
Memory-based Dependency Pars-ing.
In Proc.s of the Eighth CoNLL, ed.
H. T. Ng andE.
Riloff, Boston, Massachusetts, pp.
49?56.J.
Nivre and M. Scholz.
2004.
Deterministic Depend-ency Parsing of English Text.
In Proc.
of COLING2004, Geneva, Switzerland, pp.
64?70.J.
Nivre and J. Nilsson, 2005.
Pseudo-Projective De-pendency Parsing.
In Proc.
of the 43rd Annual Meet-ing of the ACL, pp.
99-106.M.F.
Porter.
2001.
Snowball Stemmer.http://www.snowball.tartarus.org/V.
N. Vapnik.
1998.
The Statistical Learning Theory.Springer.H.
Yamada and Y. Matsumoto.
2003.
Statistical De-pendency Analysis with Support Vector Machines.
InProc.
of the 8th International Workshop on ParsingTechnologies (IWPT), pp.
195?206.170
