Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 446?451,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsParticle Filter Rejuvenation and Latent Dirichlet AllocationChandler May,?Alex Clemmer?and Benjamin Van Durme?
?Human Language Technology Center of ExcellenceJohns Hopkins University?Microsoftcjmay@jhu.edu, clemmer.alexander@gmail.com, vandurme@cs.jhu.eduAbstractPrevious research has established sev-eral methods of online learning for la-tent Dirichlet alocation (LDA).
How-ever, streaming learning for LDA?allowing only one pass over the data andconstant storage complexity?is not aswell explored.
We use reservoir sam-pling to reduce the storage complexityof a previously-studied online algorithm,namely the particle filter, to constant.
Wethen show that a simpler particle filter im-plementation performs just as well, andthat the quality of the initialization dom-inates other factors of performance.1 IntroductionWe extend a popular model, latent Dirichlet allocation (LDA), to unbounded streams of docu-ments.
In order for inference to be practical inthis setting it must use constant space asymptoti-cally and run in pseudo-linear time, perhaps O(n)or O(n log n).Canini et al (2009) presented a method for LDAinference based on particle filters, where a sam-ple set of models is updated online with each newtoken observed from a stream.
In general, thesemodels should be regularly resampled and rejuve-nated using Markov Chain Monte Carlo (MCMC)steps over the history in order to improve the ef-ficiency of the particle filter (Gilks and Berzuini,2001).
The particle filter of Canini et al (2009) re-juvenates over independent draws from the historyby storing all past observations and states.
This al-gorithm thus has linear storage complexity and isnot an online learning algorithm in a strict sense(B?orschinger and Johnson, 2012).In the current work we propose using reservoirsampling in the rejuvenation step to reduce thestorage complexity of the particle filter to O(1).This improvement is practically useful in thelarge-data setting and is also scientifically interest-ing in that it recovers some of the cognitive plau-sibility which originally motivated B?orschingerand Johnson (2012).
However, in experiments onthe dataset studied by Canini et al (2009), weshow that rejuvenation does not benefit the par-ticle filter?s performance.
Rather, performanceis dominated by the effects of random initializa-tion (a problem for which we provide a correctionwhile abiding by the same constraints as Canini etal.
(2009)).
This result re-opens the question ofwhether rejuvenation is of practical importance inonline learning for static Bayesian models.2 Latent Dirichlet AllocationFor a sequence of N words collected into doc-uments of varying length, we denote the j-thword as wj, and the document it occurs in as di.LDA (Blei et al, 2003) ?explains?
the occurrenceof each word by postulating that a document wasgenerated by repeatedly: (1) sampling a topic zfrom ?
(d), the document-specific mixture of T top-ics, and (2) sampling a word w from ?
(z), theprobability distribution the z-th topic defines overthe vocabulary.The goal is to infer ?
and ?, under the model:wi| zi, ?(zi)?
Categorical(?(zi))?(z)?
Dirichlet(?
)zi| ?(di)?
Categorical(?(di))?(d)?
Dirichlet(?
)446initialize weights ?
(p)0= 1/P for p = 1, .
.
.
, Pfor i = 1, .
.
.
, N dofor p = 1, .
.
.
, P doset ?
(p)i= ?
(p)i?1P(wi| z(p)i?1,wi?1)sample z(p)iw.p.
P(z(p)i| z(p)i?1,wi).if ????22?
ESS thenfor j ?
R(i) dofor p = 1, .
.
.
, P dosample z(p)jw.p.P(z(p)j| z(p)i\j,wi)set ?
(p)i= 1/P for each particleAlgorithm 1: Particle filtering for LDA.Computing ?
and ?
exactly is generally in-tractable, motivating methods for approximate in-ference such as variational Bayesian inference(Blei et al, 2003), expectation propagation (Minkaand Lafferty, 2002), and collapsed Gibbs sampling(Griffiths and Steyvers, 2004).A limitation of these techniques is they requiremultiple passes over the data to obtain good sam-ples of ?
and ?.
This requirement makes them im-practical when the corpus is too large to fit directlyinto memory and in particular when the corpusgrows without bound.
This motivates online learn-ing techniques, including sampling-based meth-ods (Banerjee and Basu, 2007; Canini et al, 2009)and stochastic variational inference (Hoffman etal., 2010; Mimno et al, 2012; Hoffman et al,2013).
However, where these approaches gener-ally assume the ability to draw independent sam-ples from the full dataset, we consider the casewhen it is infeasible to access arbitrary elementsfrom the history.
The one existing algorithm thatcan be directly applied under this constraint, toour knowledge, is the streaming variational Bayesframework (Broderick et al, 2013) in which theposterior is recursively updated as new data arrivesusing a variational approximation.3 Online LDA Using Particle FiltersParticle filters are a family of sequential MonteCarlo (SMC) sampling algorithms designed to es-timate the posterior distribution of a system withdynamic state (Doucet et al, 2001).
A particle fil-ter approximates the posterior by a weighted sam-ple of points, or particles, from the state space.The particle cloud is updated recursively for eachnew observation using importance sampling (anapproach called sequential importance sampling).Canini et al (2009) apply this approach to LDAafter analytically integrating out ?
and ?, obtain-ing a Rao-Blackwellized particle filter (Doucet etal., 2000) that estimates the collapsed posteriorP(z | w).
In this setting, the P particles are sam-ples of the topic assignment vector z(p), and theyare propagated forward in state space one token ata time.
In general, the larger P is, the more ac-curately we approximate the posterior; for smallP , the approximation of the tails of the poste-rior will be particularly poor (Pitt and Shephard,1999).
However, a larger value of P increases theruntime and storage requirements of the algorithm.We now describe the Rao-Blackwellized parti-cle filter for LDA in detail (pseudocode is given inAlgorithm 1).
At the moment token i is observed,the particles form a discrete approximation of theposterior up to the (i?
1)-th word:P(zi?1| wi?1) ??p?
(p)i?1Izi?1(z(p)i?1)where Iz(z?)
is the indicator function, evaluatingto 1 if z = z?and 0 otherwise.
Now each par-ticle p is propagated forward by drawing a topicz(p)ifrom the conditional posterior distributionP(z(p)i| z(p)i?1,wi) and scaling the particle weightby P(wi| z(p)i?1,wi?1).
The particle cloud nowapproximates the posterior up to the i-th word:P(zi| wi) ??p?
(p)iIzi(z(p)i).Dropping the superscript (p) for notational conve-nience, the conditional posterior used in the prop-agation step is given byP(zi|zi?1,wi) ?
P(zi, wi| zi?1,wi?1)=n(wi)zi,i\i+ ?n(?
)zi,i\i+W?n(di)zi,i\i+ ?n(di)?,i\i+ T?where n(wi)zi,i\iis the number of times word wihasbeen assigned topic ziso far, n(?
)zi,i\iis the num-ber of times any word has been assigned topic zi,n(di)zi,i\iis the number of times topic zihas been as-signed to any word in document di, and n(di)?,i\iis thenumber of words observed in document di.
Theparticle weights are scaled as?(p)i?
(p)i?1?P(wi| z(p)i,wi)P(z(p)i| z(p)i?1)Q(z(p)i| z(p)i?1,wi)= P(wi| z(p)i?1,wi?1)447where Q is the proposal distribution for the parti-cle state transition; in our case,Q(z(p)i| z(p)i?1,wi) = P(z(p)i| z(p)i?1,wi),minimizing the variance of the importance weightsconditioned on wiand zi?1(Doucet et al, 2000).Over time the particle weights tend to diverge.To combat this inefficiency, after every state tran-sition we estimate the effective sample size (ESS)of the particle weights as ??i?
?22(Liu and Chen,1998) and resample the particles when that esti-mate drops below a prespecified threshold.
Sev-eral resampling strategies have been proposed(Doucet et al, 2000); we perform multinomialresampling as in Pitt and Shephard (1999) andAhmed et al (2011), treating the weights as un-normalized probability masses on the particles.After resampling we are likely to have severalcopies of the same particle, yielding a degenerateapproximation to the posterior.
To reintroduce di-versity to the particle cloud we take MCMC stepsover a sequence of states from the history (Doucetet al, 2000; Gilks and Berzuini, 2001).
We call theindices of these states the rejuvenation sequence,denoted R(i) (Canini et al, 2009).
The transitionprobability for a state j ?
R(i) is given byP(zj| zN\j,wN) ?n(wj)zj,N\j+ ?n(?
)zj,N\j+W?n(dj)zj,N\j+ ?n(dj)?,N\j+ T?where subscript N\j denotes counts up to tokenN , excluding those for token j.The rejuvenation sequence can be chosen bythe practitioner.
Choosing a long sequence (large|R(i)|) may result in a more accurate posterior ap-proximation but also increases runtime and stor-age requirements.
The tokens inR(i) may be cho-sen uniformly at random from the history or undera biased scheme that favors recent observations.The particle filter studied empirically by Canini etal.
(2009) stored the entire history, incurring lin-ear storage complexity in the size of the stream.Ahmed et al (2011) instead sampled ten docu-ments from the most recent 1000, achieving con-stant storage complexity at the cost of a recencybias.
If we want to fit a model to a long non-i.i.d.
stream, we require an unbiased rejuvenationsequence as well as sub-linear storage complexity.4 Reservoir SamplingReservoir sampling is a widely-used family of al-gorithms for choosing an array (?reservoir?)
of kitems.
The most common example, presented inVitter (1985) as Algorithm R, chooses k elementsof a stream such that each possible subset of k el-ements is equiprobable.
This effects sampling kitems uniformly without replacement, using run-timeO(n) (constant per update) and storageO(k).Initialize k-element array R ;Stream S ;for i = 1, .
.
.
, k doR[i]?
S[i] ;for i = k + 1, .
.
.
, length(S) doj ?
random(1, i);if j ?
k thenR[j]?
S[i] ;Algorithm 2: Algorithm R for reservoir samplingTo ensure constant space over an unboundedstream, we draw the rejuvenation sequence R(i)uniformly from a reservoir.
As each token of thetraining data is ingested by the particle filter, wedecide to insert that token into the reservoir, or not,independent of the other tokens in the current doc-ument.
Thus, at the end of step i of the particle fil-ter, each of the i tokens seen so far in the trainingsequence has an equal probability of being in thereservoir, hence being selected for rejuvenation.5 ExperimentsWe evaluate our particle filter on three datasetsstudied in Canini et al (2009): diff3, rel3,and sim3.
Each of these datasets is a collectionof posts under three categories from the 20 News-groups dataset.1We use a 60% training/40% test-ing split of this data that is available online.2We preprocess the data by splitting each lineon non-alphabet characters, converting the result-ing tokens to lower-case, and filtering out any to-kens that appear in a list of common English stopwords.
In addition, we remove the header of ev-ery file and filter every line that does not containa non-trailing space (which removes embeddedASCII-encoded attachments).
Finally, we shufflethe order of the documents.
After these steps, wecompute the vocabulary for each dataset as the setof all non-singleton types in the training data aug-mented with a special out-of-vocabulary symbol.1diff3: {rec.sport.baseball, sci.space,alt.atheism}; rel3: talk.politics.
{misc,guns, mideast}; and sim3: comp.
{graphics,os.ms-windows.misc, windows.x}.2http://qwone.com/?jason/20Newsgroups/20news-bydate.tar.gz448Figure 1: Fixed initialization with different reservoir sizes.During training we report the out-of-sampleNMI, calculated by holding the word proportions?
fixed, running five sweeps of collapsed Gibbssampling on the test set, and computing the topicfor each document as the topic assigned to themost tokens in that document.
Two Gibbs sweepshave been shown to yield good performance inpractice (Yao et al, 2009); we increase the num-ber of sweeps to five after inspecting the stabilityon our dataset.
The variance of the particle filter isoften large, so for each experiment we perform 30runs and plot the mean NMI inside bands spanningone sample standard deviation in either direction.Fixed Initialization.
Our first set of experi-ments has a similar parameterization3to the exper-iments of Canini et al (2009) except we draw therejuvenation sequence from a reservoir.
We initial-ize the particle filter with 200 Gibbs sweeps on thefirst 10% of each dataset.
Then, for each dataset,for rejuvenation disabled, rejuvenation based ona reservoir of size 1000, and rejuvenation basedon the entire history (in turn), we perform 30 runsof the particle filter from that fixed initial model.Our results (Figure 1) resemble those of Canini etal.
(2009); we believe the discrepancies are mostlyattributable to differences in preprocessing.In these experiments, the initial model was notchosen arbitrarily.
Rather, an initial model thatyielded out-of-sample NMI close to the initial out-of-sample NMI scores reported in the previous3T = 3, ?
= ?
= 0.1, P = 100, ess = 20, |R(i)| = 30Figure 2: Variable initialization with different initializationsample sizes.study was chosen from a set of 100 candidates.Variable Initialization.
We now investigate thesignificance of the initial model selection step usedin the previous experiments.
We run a new setof experiments in which the reservoir size is heldfixed at 1000 and the size of the initialization sam-ple is varied.
Specifically, we vary the size ofthe initialization sample, in documents, betweenzero (corresponding to no Gibbs initialization), 30,100, and 300, and also perform a run of batchGibbs sampling (with no particle filter).
In eachcase, 2000 Gibbs sweeps are performed.
In theseexperiments, the initial models are not held fixed;for each of the 30 runs for each dataset, the initialmodel was generated by a different Gibbs chain.The results for these experiments, depicted in Fig-ure 2, indicate that the size of the initializationsample improves mean NMI and reduces variance,and that the variance of the particle filter itself isdominated by the variance of the initial model.Tuned Initialization.
We observed previouslythat variance in the Gibbs initialization of themodel contributes significantly to variance of theoverall algorithm, as measured by NMI.
Withthis in mind, we consider whether we can reducevariance in the initialization by tuning the initialmodel.
Thus we perform a set of experiments inwhich we perform Gibbs initialization 20 timeson the initialization set, setting the particle filter?sinitial model to the model out of these 20 with449Figure 3: Variable initialization with tuning.the highest in-sample NMI.
This procedure is per-formed independently for each run of the particlefilter.
We may not always have labeled data forinitialization, so we also consider a variation inwhich Gibbs initialization is performed 20 timeson the first 80% of the initialization sample, held-out perplexity (per word) is estimated on the re-maining 20%, using a first-moment particle learn-ing approximation (Scott and Baldridge, 2013),and the particle filter is started from the modelout of these 20 with the lowest held-out perplex-ity.
The results, shown in Figure 3, show that wecan ameliorate the variance due to initialization bytuning the initial model to NMI or perplexity.6 DiscussionMotivated by a desire for cognitive plausibility,B?orschinger and Johnson (2011) used a particlefilter to learn Bayesian word segmentation mod-els, following the work of Canini et al (2009).They later showed that rejuvenation improved per-formance (B?orschinger and Johnson, 2012), butthis impaired cognitive plausibility by necessitat-ing storage of all previous states and observations.We attempted to correct this by drawing the re-juvenation sequence from a reservoir, but our re-sults indicate that the particle filter for LDA on ourdataset is highly sensitive to initialization and notinfluenced by rejuvenation.In the experiments of B?orschinger and Johnson(2012), the particle cloud appears to be resampledonce per utterance with a large rejuvenation se-quence;4each particle takes many more rejuvena-tion MCMC steps than new state transitions andthus resembles a batch MCMC sampler.
In our ex-periments resampling is done on the order of onceper document, leading to less than one rejuvena-tion step per transition.
Future work should care-fully note this ratio: sampling history much moreoften than new states improves performance butcontradicts the intuition behind particle filters.We have also shown that tuning the initial modelusing in-sample NMI or held-out perplexity canimprove mean NMI and reduce variance.
Perplex-ity (or likelihood) is often used to estimate modelperformance in LDA (Blei et al, 2003; Griffithsand Steyvers, 2004; Wallach et al, 2009; Hoff-man et al, 2010), and does not compare the in-ferred model against gold-standard labels, yet itappears to be a good proxy for NMI in our experi-ment.
Thus, if initialization continues to be crucialto performance, at least we may have the flexibil-ity of initializing without gold-standard labels.We have focused on NMI as our evaluation met-ric for comparison with Canini et al (2009).
How-ever, evaluation of topic models is a subject of con-siderable debate (Wallach et al, 2009; Yao et al,2009; Newman et al, 2010; Mimno et al, 2011)and it may be informative to investigate the effectsof initialization and rejuvenation using other met-rics such as perplexity or semantic coherence.7 ConclusionWe have proposed reservoir sampling for reduc-ing the storage complexity of a particle filter fromlinear to constant.
This work was motivated asan expected improvement on the model of Caniniet al (2009).
However, in the process of estab-lishing an empirical baseline we discovered thatrejuvenation does not play a significant role inthe experiments of Canini et al (2009).
More-over, we found that performance of the particlefilter was strongly affected by the random initial-ization of the model, and suggested a simple ap-proach to reduce the variability therein withoutusing additional data.
In conclusion, it is nowan open question whether?and if so, under whatassumptions?rejuvenation benefits particle filtersfor LDA and similar static Bayesian models.Acknowledgments We thank Frank Ferraro,Keith Levin, and Mark Dredze for discussions.4The ESS threshold isP ; the rejuvenation sequence is 100or 1600 utterances, almost one sixth of the training data.450ReferencesAmr Ahmed, Qirong Ho, Jacob Eisenstein, Eric P.Xing, Alexander J. Smola, and Choon Hui Teo.2011.
Unified analysis of streaming news.
In Pro-ceedings of the 20th International World Wide WebConference (WWW), pages 267?276.Arindam Banerjee and Sugato Basu.
2007.
Topicmodels over text streams: A study of batch and on-line unsupervised learning.
In Proceedings of the7th SIAM International Conference on Data Mining(SDM), pages 431?436.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent Dirichlet alocation.
Journal of Ma-chine Learning Research, 3:993?1022, Jan.Benjamin B?orschinger and Mark Johnson.
2011.
Aparticle filter algorithm for Bayesian wordsegmen-tation.
In Proceedings of the Australasian Lan-guage Technology Association Workshop (ALTA),pages 10?18.Benjamin B?orschinger and Mark Johnson.
2012.
Us-ing rejuvenation to improve particle filtering forBayesian word segmentation.
In Proceedings of the50th Annual Meeting of the Association for Compu-tational Linguistics (ACL), pages 85?89.Tamara Broderick, Nicholas Boyd, Andre Wibisono,Ashia C. Wilson, and Michael I. Jordan.
2013.Streaming variational Bayes.
In Advances in Neu-ral Information Processing Systems 26 (NIPS).Kevin R. Canini, Lei Shi, and Thomas L. Griffiths.2009.
Online inference of topics with latent Dirich-let alocation.
In Proceedings of the 12th Inter-national Conference on Artificial Intelligence andStatistics (AISTATS).Arnaud Doucet, Nando de Freitas, Kevin Murphy, andStuart Russell.
2000.
Rao-Blackwellised particlefiltering for dynamic Bayesian networks.
In Pro-ceedings of the 16th Conference on Uncertainty inArtificial Intelligence (UAI), pages 176?183.Arnaud Doucet, Nando de Freitas, and Neil Gordon,editors.
2001.
Sequential Monte Carlo Methods inPractice.
Springer, New York.Walter R. Gilks and Carlo Berzuini.
2001.
Following amoving target?Monte Carlo inference for dynamicBayesian models.
Journal of the Royal StatisticalSociety, 63(1):127?146.Thomas L. Griffiths and Mark Steyvers.
2004.
Find-ing scientific topics.
Proceedings of the NationalAcademy of Sciences, 101(suppl 1):5228?5235, Apr.Matthew D. Hoffman, David M. Blei, and FrancisBach.
2010.
Online learning for latent Dirichletallocation.
In Advances in Neural Information Pro-cessing Systems 23 (NIPS).Matthew D. Hoffman, David M. Blei, Chong Wang,and John Paisley.
2013.
Stochastic variational in-ference.
Journal of Machine Learning Research,14:1303?1347, May.Jun S. Liu and Rong Chen.
1998.
Sequential MonteCarlo methods for dynamic systems.
Journal ofthe American Statistical Association, 93(443):1032?1044, Sep.David Mimno, Hanna M. Wallach, Edmund Talley,Miriam Leenders, and Andrew McCallum.
2011.Optimizing semantic coherence in topic models.
InProceedings of the Conference on Empirical Meth-ods on Natural Language Processing (EMNLP),pages 262?272.David Mimno, Matthew D. Hoffman, and David M.Blei.
2012.
Sparse stochastic inference for la-tent Dirichlet alocation.
In Proceedings of the29th International Conference on Machine Learning(ICML).Thomas Minka and John Lafferty.
2002.
Expectation-propagation for the generative aspect model.
In Pro-ceedings of the 18th Conference on Uncertainty inArtificial Intelligence (UAI), pages 352?359.David Newman, Jey Han Lau, Karl Grieser, and Tim-othy Baldwin.
2010.
Automatic evaluation of topiccoherence.
In Human Language Technologies: 11thAnnual Conference of the North American Chap-ter of the Association for Computational Linguistics(NAACL HLT), pages 100?108.Michael K. Pitt and Neil Shephard.
1999.
Filtering viasimulation: Auxiliary particle filters.
Journal of theAmerican Statistical Association, 94(446):590?599,Jun.James G. Scott and Jason Baldridge.
2013.
A recur-sive estimate for the predictive likelihood in a topicmodel.
In Proceedings of the 16th InternationalConference on Artificial Intelligence and Statistics(AISTATS).Jeffrey S. Vitter.
1985.
Random sampling with a reser-voir.
ACM Transactions on Mathematical Software,11(1):37?57, Mar.Hanna M. Wallach, Iain Murray, Ruslan Salakhutdinov,and David Mimno.
2009.
Evaluation methods fortopic models.
In Proceedings of the 26th Interna-tional Conference on Machine Learning (ICML).Limin Yao, David Mimno, and Andrew McCallum.2009.
Efficient methods for topic model inferenceon streaming document collections.
In 15th ACMSIGKDD International Conference on KnowledgeDiscovery and Data Mining, pages 937?946.451
