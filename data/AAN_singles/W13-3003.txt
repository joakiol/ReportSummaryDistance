Proceedings of the 13th Meeting on the Mathematics of Language (MoL 13), pages 21?29,Sofia, Bulgaria, August 9, 2013. c?2013 Association for Computational LinguisticsOn the Parameterized Complexity ofLinear Context-Free Rewriting SystemsMartin BerglundUmea?
University, Swedenmbe@cs.umu.seHenrik Bjo?rklundUmea?
University, Swedenhenrikb@cs.umu.seFrank DrewesUmea?
University, Swedendrewes@cs.umu.seAbstractWe study the complexity of uniform mem-bership for Linear Context-Free RewritingSystems, i.e., the problem where we aregiven a string w and a grammar G and areasked whether w ?
L(G).
In particular,we use parameterized complexity theoryto investigate how the complexity dependson various parameters.
While we focusprimarily on rank and fan-out, derivationlength is also considered.1 IntroductionLinear Context-Free Rewriting Systems (LCFRS)were introduced by Vijay-Shanker et al(1987)with the purpose of capturing the syntax of nat-ural language.1 It is one of several suggested waysof capturing Joshi?s concept of mildly context-sensitive languages (Joshi, 1985).
As such, itstrengthens the expressive power of context-freegrammars, while avoiding the full computationalcomplexity of context-sensitive grammars.One of the defining features of mildly context-sensitive languages is that they should be decid-able in polynomial time.
This is indeed true for ev-ery language that can be generated by an LCFRS.Unlike the case for context-free grammars, how-ever, the universal or uniform membership prob-lem for LCFRSs, where both the grammar andthe string in question are considered as input, isknown to be PSPACE-complete (Kaji et al 1992),making a polynomial time solution very improba-ble.The best known algorithms for the problemhave a running time of O(|G| ?
|w|f ?
(r+1)), whereG is the grammar, w is the string, f is the fan-outand r is the rank of the grammar (Seki et al 1991;Burden and Ljunglo?f, 2005; Boullier, 2004).
(For1Seki et al(1991) independently suggested the nearlyidentical Multiple Context-Free Grammars.a definition of fan-out and rank, see Section 2.
)Unlike the rank of a context-free grammar, the fan-out and rank of an LCFRS cannot in general be re-duced to some fixed constant.
Increasing the fan-out always gives more generative power, as doesincreasing the rank while keeping the fan-out fixed(Satta, 1998).
The rank can be reduced to two, butat the price of an exponential increase in the fan-out.Research into algorithms for LCFRS parsingthat are efficient enough for practical use is quiteactive.
For example, algorithms for restrictedcases are being studied, e.g., by Go?mez-Rodr?
?guezet al(2010), as well as rank reduction, primarilyin special cases, where the fan-out is not affected;see, e.g., Sagot and Satta (2010).This article is a first step towards a finer com-putational complexity analysis of the membershipproblem for LCFRSs.
Specifically it asks thequestion ?could there exist an algorithm for theuniform LCFRS membership problem whose run-ning time is a fixed polynomial in |w| times an ar-bitrary function in f and r??
By employing pa-rameterized complexity theory, we show that suchan algorithm is very unlikely to be found.
Fix-ing the rank of the grammar to one, the mem-bership problem, parameterized by the fan-out, isW[SAT]-hard.
Fixing the fan-out to two and tak-ing the rank as the parameter, the problem is W[1]-hard.
Finally, if the fan-out, rank, and derivationlength are included in the parameter, the problemis W[1]-complete.
These results help guide futurework, suggesting other types of parameters andgrammar restrictions that may yield more favor-able complexity results.2 PreliminariesFor n ?
N, we write [n] for {1, .
.
.
, n} and [n]0for {0} ?
[n].
Given an alphabet ?
we write ?
?for all strings over ?
and ?+ for all non-emptystrings.
The empty string is denoted by ?.212.1 Linear context-free rewriting systemsLet ?
be an alphabet, x1, .
.
.
, xn variables, andw1, .
.
.
, wk strings over ?
such thatw1 ?
?
?wk = ?0 ?
xpi(1) ?
?1 ?
?
?xpi(n) ?
?nfor some permutation pi and some strings?0, .
.
.
, ?n ?
??.
Then define f as a functionover tuples of strings such thatf((x1, .
.
.
), .
.
.
, (.
.
.
, xn)) = (w1, .
.
.
, wk).A function is linear regular if and only if itcan be described in this way.
For examplef((x1), (x2)) = (a, bx2x1c) is linear regular, andf((aaa), (bc)) = (a, bbcaaac).Definition 2.1.
A Linear Context-Free RewritingSystem is a tupleG = (N,?, F,R, S), whereN isan alphabet of nonterminals, where each A ?
Nhas an associated fan-out #(A); S ?
N is theinitial nonterminal with #(S) = 1; ?
is an al-phabet of terminals; F is a set of linear regu-lar functions; and R is a set of rules of the formA ?
g(B1, .
.
.
, Bn), where A,B1, .
.
.
, Bn ?
Nand g is a function in F of type(??
)#(B1) ?
?
?
?
?
(??
)#(Bn) ?
(??
)#(A).For rules A ?
g(), where g has arity 0 andg() = (?1, .
.
.
, ?#(A)), we often simply writeA?
(?1, .
.
.
, ?#(A)).The rank of a rule is the number of nontermi-nals on the right-hand side.
The rank of G is themaximal rank of any rule in R. The fan-out of Gis the maximal fan-out of any nonterminal in N .The language generated by a nonterminal A is aset of n-tuples, where n = #(A).Definition 2.2.
Let G = (N,?, F,R, S) bea linear context-free rewriting system.
LetLA ?
(??
)#(A) denote the tuples that a nontermi-nal A ?
N can generate.
This is the smallest setsuch that if A ?
f(B1, .
.
.
, Bn) is in R then, forall bi ?
LBi where i ?
[n], f(b1, .
.
.
, bn) ?
LA.The language of G is L(G) = LS .For i ?
N, we write i-LCFRS for the class ofall LCFRSs of rank at most i and LCFRS(i) forthe class of all LCFRSs of fan-out at most i. Wealso write i-LCFRS(j) for i-LCFRS?LCFRS(j).2.2 Parameterized complexity theoryWe only reproduce the most central definitions ofparameterized complexity theory.
For a more thor-ough treatment, we refer the reader to (Downeyand Fellows, 1999; Flum and Grohe, 2006).A parameterized problem is a languageL ?
??
?
N, where ?
is a finite alphabet.
Thesecond component is called the parameter.
An al-gorithm for L is fixed-parameter tractable if thereis a computable function f and a polynomial psuch that for every (x, k) ?
??
?N, the algorithmdecides in time f(k) ?
p(|x|) whether (x, k) ?
L.The problem of deciding L is fixed-parametertractable if there is such an algorithm.
If so, Lbelongs to the class FPT.A parameterized problem L ?
??
?
Nis fpt-reducible to another parameterized prob-lem K ?
??
?
N if there is a mappingR : ??
?
N?
??
?
N such that1.
for all (x, k) ?
??
?
N, we have (x, k) ?
Lif and only if R(x, k) ?
K,2.
there is a computable function f and a poly-nomial p such that R(x, k) can be computedin time f(k) ?
p(|x|), and3.
there is a computable function g such that forevery (x, k) ?
??
?
N, if R(x, k) = (y, k?
),then k?
?
g(k).Note that several parameters may be combinedinto one by taking their maximum (or sum).The most commonly used hierarchy of parame-terized complexity classes is the following.FPT ?W[1] ?W[2] ?
?
?
?
?
?W[SAT] ?W[P] ?
XPThe classes W[1],.
.
.
,W[P] are defined using cir-cuits or, alternatively, logic.
None of the inclu-sions is known to be strict, except that FPT is astrict subclass of XP.
It is widely believed, how-ever, that each of them is strict.
The class XP isthe class of all parameterized problems for whichthere is a computable function f such that everyinstance (x, k) can be decided in time |x|f(k).2.3 Problems of interestWe know from Kaji et al(1992) that the universalmembership problem for 1-LCFRSs is PSPACE-complete.
Satta (1992) has further shown thatLCFRS(2)-MEMBERSHIP is NP-hard.We study the following decision problems,where the symbol P is used to indicate what theparameter is:?
P-LCFRS(j)-MEMBERSHIP, where j ?
Nis the membership problem for LCFRS(j),parameterized by the rank.22?
i-LCFRS(P)-MEMBERSHIP, where i ?
Nis the membership problem for i-LCFRS, pa-rameterized by the fan-out.?
P-LCFRS(P)-MEMBERSHIP is the mem-bership problem for LCFRS parameterizedby the rank and the fan-out.?
SHORT P-LCFRS(P)-DERIVATION is themembership problem for LCFRS parameter-ized by the rank, the fan-out, and the deriva-tion length.Since there are algorithms that solve the member-ship problem for LCFRSs with rank r and fan-outt and string w in time |w|(r+1)t (see, e.g., (Sekiet al 1991; Burden and Ljunglo?f, 2005; Boul-lier, 2004)), we can immediately conclude thatP-LCFRS(P)-MEMBERSHIP, as well as everyother parameterized membership problem men-tioned above, belongs to XP.3 Fixed rank grammarsThe following theorem establishes a lower boundfor 1-LCFRSs parameterized by the fan-out.Theorem 3.1.
1-LCFRS(P)-MEMBERSHIP isW[SAT]-hard.The proof of Theorem 3.1 is by reduction fromWEIGHTED MONOTONE SATISFIABILITY.
Be-fore we get into the actual proof, we discuss someproperties of this problem.Definition 3.1.
A monotone Boolean formula is aBoolean formula that contains only conjunctions,disjunctions, and variables.
In particular, there areno negations.
An instance of WEIGHTED MONO-TONE SATISFIABILITY is a pair (?, k), where ?is a monotone Boolean formula and k ?
N. Thequestion is whether ?
has a satisfying assignmentof weight k, i.e., an assignment that sets exactlyk of the variables that occur in ?
to true.
The pa-rameter is k. WEIGHTED MONOTONE SATISFIA-BILITY is W[SAT]-complete (Abrahamson et al1993; Abrahamson et al 1995; Downey and Fel-lows, 1999).We can view a monotone Boolean formula ?as an unranked tree, where the root node corre-sponds to the top level clause and the leaves corre-spond to bottom level clauses, i.e., variable occur-rences.
The set pos(?)
of positions of ?
is definedas usual, consisting of strings of natural numbersthat indicate how to navigate to the clauses in atree representation of ?.
We denote each subclauseof ?
by Cs, where s ?
pos(?)
is its position.
Thus?
= (((x1 ?
(x2 ?
x3)) ?
x3 ?
(x3 ?
x4))?
?x2 ?
((x1 ?
(x2 ?
x4)) ?
(x1 ?
x3)))C?C1C11C111C112C1121C1122C12C13C131C132C2C3C31C311C312C3121C3122C32C321C322Figure 1: A formula ?
and its tree representa-tion.
Conjunctive clauses are round and disjunc-tive rectangular.
For example, C111 is the leftmostoccurrence of x1 and C13 the clause (x3 ?
x4).C?
denotes the whole of ?, while, e.g., Cijl is thelth clause of the jth clause of the ith clause of ?.See Figure 1 for an example.
We use C for the setof all clauses of ?
and C?, C?, and CVar for thesets of conjunctive, disjunctive, and bottom levelclauses, respectively.
For all c ?
CVar let Var(c)denote the variable in c, and let Var(?)
denote theset of all variables in ?.Given a monotone Boolean formula ?
and avariable assignment ?
: Var(?)
?
B, we de-fine a verification tour for ?
and ?.
Such a tourmoves through the tree representation of ?, start-ing at the root node, and verifies that ?
satis-fies ?.
To this end, we first define the functionNext : pos(?)
?
pos(?)
?
{True} as follows.For the root clause let Next(?)
= True .
For allsi ?
pos(?
), where s ?
N?
and i ?
N, if Cs ?
C?and s(i + 1) ?
pos(?)
let Next(si) = s(i + 1),otherwise let Next(si) = Next(s).A verification tour over ?, given a variable as-signment ?
is constructed by the following proce-dure.
Set the initial position p = ?, then?
If Cp ?
C?
set p ?
p1 (i.e., go to the firstsubclause).?
If Cp ?
C?
set p ?
pi for any i (i.e.
non-deterministically pick a subclause).?
IfCp ?
CVar verify that ?
(Var(Cp)) = true .If so, set p ?
Next(p) and repeat.
Other-wise, the verification tour fails.A verification tour succeeds if it reaches True .23The following lemma can be proved by straight-forward induction on the structure of ?.Lemma 3.2.
If a verification tour for ?
and vari-able assignment ?
succeeds, then ?
satisfies ?.We are now ready to prove Theorem 3.1.Proof of Theorem 3.1.
Let (?, k) be an instance ofWEIGHTED MONOTONE SATISFIABILITY.
Let{x1, .
.
.
, xn} be the variables that appear in ?.
Inparticular, n is the number of distinct variables.Let m be the number of bottom level clauses.Intuitively, the LCFRS we will construct willguess a weight k variable assignment ?
and thensimulate a verification tour for ?
and ?.Basically, we will use one nonterminal perclause and use the structure of the grammar to sim-ulate a verification tour.
In order to verify that thenecessary bottom level clauses can all be satisfiedthrough the same k true variables, we will use theinput string to be parsed.
The string w will con-sist of bracketed sequences of m copies of each ofthe n variables, i.e., w = [xm1 ] ?
?
?
[xmn ].
To un-derstand the construction of the grammar, pleasekeep in mind that the only derivations that matterare those generating this particular input string.The grammar will guess which k variablesshould be set to true and disregard the other vari-ables.
Technically, this is done by first letting anonterminal F generate a tuple of k + 1 stringss0, .
.
.
, sk such that each si consists of zero ormore of the bracketed sequences of variables tobe disregarded.
The rest of the grammar generatesexactly k bracketed sequences that will be inter-leaved with s0, .
.
.
, sk.
During the generation ofthese k bracketed sequences it is nondeterministi-cally verified that the corresponding truth assign-ment satisfies ?.We use the following set of nonterminals:{S, F} ?
{Cs | s ?
pos(?)
?
{True}}For S, there is only one rule: S ?
fS(F ).
Thefunction fS places brackets around the k vari-ables that are guessed to be true, represented bythe strings t1, .
.
.
, tk, and interleaves them withthe remaining variables, represented by the stringss0, .
.
.
, sk:fS(s0, .
.
.
, sk, t1, .
.
.
, tk) = (s0[t1]s1 ?
?
?
[tk]sk)The nonterminal F has rules F ?
fF,i,j(F ) forall i ?
[n] and j ?
[k]0.
These rules produce thebracketed sequences of copies of the variables xito be disregarded, as can be seen from the corre-sponding function:fF,i,j(s0, .
.
.
, sk, t1, .
.
.
, tk) =(s0, .
.
.
, sj [xmi ], .
.
.
, sk, t1, .
.
.
, tk)Moreover, there is a single ruleF ?
fF (C?
)withfF (t1, .
.
.
, tk) = (?, .
.
.
, ?, t1, .
.
.
, tk)The rules for the nonterminals that representclauses differ according to the type of the clause,i.e., if the nonterminal represents a conjunctiveclause, a disjunctive clause, or a variable.
For eachconjunctive clause Cs there is exactly one rule,representing a move to its first subclause.
Here,fid is the identity function.Cs ?
fid (Cs1)For every disjunctive clause Cs and every i suchthat Csi is a subclause of Cs there is one rule.Cs ?
fid (Csi)For every bottom level clause, i.e., Cs ?
CVar ,every i ?
[k] and every j ?
[m] there is one rule.Cs ?
fs,i,j(CNext(s))Intuitively, such a rule corresponds to producing jcopies of the variable of clause Cs in component iof the tuple and moving on to the next clause thatshould be visited in a verification tour.
This can beseen from the corresponding function.fs,i,j(t1, .
.
.
, tk) = (t1, .
.
.
,Var(Cs)jti, .
.
.
, tk)The reason that the function produces j copies ofthe variable, rather than just one, is that it is un-known beforehand how many times a bottom levelclause that represents that particular variable willbe visited.
Thus the number of copies to be pro-duced has to be guessed nondeterministically inorder to make sure that a total of m copies of eachvariable set to true are eventually produced.If there is a weight k satisfying assignment,there will also be a verification tour that even-tually reaches True when Next is called (byLemma 3.2).
The single rule forCTrue simply pro-duces a k-tuple of empty strings.24The reduction is polynomial and the fan-out ofthe resulting grammar is 2k+1.
Thus it is an FPT-reduction.
It remains to argue that the grammarcan produce w if and only if ?
has a satisfyingassignment of weight k.We first note that whatever tuple is derived fromF , the first k + 1 entries in the tuple consist ofbracketed sequences of the form [xml ].
If thegrammar can produce w, it follows that the tuple(t1, .
.
.
, tk) produced from C?
must be such thateach ti equalsm copies of the same variable name.Any successful derivation of a string by thegrammar corresponds to a verification tour of ?and the variable assignment that sets the variablesthat appear in (t1, .
.
.
, tk) to true and all other vari-ables to false.
Thus ?
has a satisfying assignmentof weight k.For the other direction, assume that ?
has a sat-isfying assignment of weight k. Then the grammarcan guess this assignment and a correspondingsuccessful verification tour, thus producingw.Note that Theorem 3.1 can easily be strength-ened to grammars with a binary terminal alphabet.It is enough to represent each variable name bya bitstring of length dlog2(m)e in the above re-duction.
We also note that Theorem 3.1 immedi-ately implies that P-LCFRS(P)-MEMBERSHIPis W[SAT]-hard.4 Fixed fan-out grammarsWe next turn to the case where the fan-out is fixedto two, while the rank is treated as a parameter.Theorem 4.1.
P-LCFRS(2)-MEMBERSHIP isW[1]-hard.Proof.
We reduce from k-CLIQUE, the problem ofdeciding whether a given graph has a clique of sizek, with k as the parameter.
This problem is knownto be W[1]-complete (Flum and Grohe, 2006).
LetG = (V,E) be an undirected graph.
We assume,without loss of generality, that V = {1, .
.
.
, n}and that an edge connecting nodes i, j ?
V is rep-resented as the ordered pair (i, j) such that i < j,i.e., E ?
{(i, j) ?
V ?
V | i < j}.
To find outwhether G has a clique of size k we construct aninstance of the membership problem for LCFRSs.The input alphabet is ?
= {0, 1}.
Construct theinput string asw = 0n10n10n1 ?
?
?
10n?
??
?
(3k + 2)(k ?
1)/2 ones.The nonterminals are N = {A,E,C, S}, with Sbeing the initial nonterminal.
The rules are the fol-lowing.{A?
0i | i ?
{1, .
.
.
, n}}.
{E ?
0n?i10n?j | (i, j) ?
E}.
{C ?
(0i, 0n?i10i) | i ?
{1, .
.
.
, n}}.Handling S is a bit more complex.
Let?
= k(k?1)/2, the number of edges in a k-clique.Then the unique rule for S is:S ?
f(E, .
.
.
, E?
??
?
?, C, .
.
.
, C?
??
?2?, A, .
.
.
, A?
??
?2k).Now we need to define f .
Consider the followingapplication of f .f(e1, .
.
.
, e?, (c1, c?1), .
.
.
, (c?, c??
),(d1, d?1), .
.
.
, (d?, d??
), a1, .
.
.
, a2k).The application above evaluates to the stringc1e1d11c2e2d21 ?
?
??
?
?
1c?e?d?1a1?1a21a3?2a41s1a2k?1?ka2k.The substrings ?1 through ?k are left to be de-fined, and will contain all the c?
and d?
argumentsin a careful configuration derived from the struc-ture of a clique.
Let (pi1, pi?1), .
.
.
, (pi?, pi??)
be thelexicographically sorted sequence of edges in ak-clique with nodes numbered 1 through k. Forexample, (pi1, pi?1) = (1, 2), (pi2, pi?2) = (1, 3),(pik, pi?k) = (2, 3), and (pi?, pi??)
= (k ?
1, k).Then, for each l, find the longest subsequencesi1, .
.
.
, ip and j1, .
.
.
, jq of 1, .
.
.
, ?
for whichpii1 = ?
?
?
= piip = l and pi?j1 = ?
?
?
= pijq = l, andlet ?l = c?i1 ?
?
?
c?ip d?j1 ?
?
?
d?jq .This construction is simpler than it may at firstappear.
Basically, the clique is found by generat-ing k(k?
1)/2 copies of E, each of which will beplaced so that it has no choice but to generate anedge in a k-clique.
Looking at the first part of thestring, each 1cleldl1 must generate a string of theform 10n10n1: el will generate some 0n?i10n?j ,were (i, j) is an edge in G, which forces cl to gen-erate 0i and dl to generate 0j .
The trick is that cland dl yield the first string in a pair generated byan instance of C. The other string in the pair de-scribes the same number as the first, but in sucha way that it can be carefully placed in the lat-ter part of the derivation string, thus forcing otherinstances of the C nonterminal to pick the same25node (number of zeros) to generate.
These arethen placed in such a way that the edges picked bythe instances of E all belong to the same clique.For example, for k = 3 the result of f willbe c1e1d11c2e2d21c3e3d31a1c1c2a21c3d11d2d3,where the latter part ensures that c1 and c2 haveto pick the same node (lowest-numbered node inthe clique), as do c3 and d1, and d2 and d3.5 Short derivationsIn this section, we consider the length of deriva-tions as an additional parameter.
As usual, thelength of a derivation is the number of derivationsteps it consists of.
(In a derivation of an LCFRS(N,?, F,R, S), this is the same as the number ofapplications of functions in F .
)Let G = (N,?, F,R, S) be an LCFRS in thefollowing.
Consider the following problem:Definition 5.1.
An instance of the SHORT P-LCFRS(P) DERIVATION problem consists of aLCFRS G, some w ?
??
and a constant d ?
N.The question asked is: can w be derived by G inat most d steps?
The parameter is k = d + r + fwhere r is the maximum rank and f the maximumfanout.Lemma 5.1.
SHORT P-LCFRS(P) DERIVA-TION is W[1]-hard.Proof.
The W[1]-hardness of the problem followsimmediately from the reduction in the proof ofTheorem 4.1, since k-Clique is reduced to an in-stance of LCFRS membership with O(k2) deriva-tion steps, rank O(k2), and fixed fan-out.We next demonstrate that SHORT P-LCFRS(P) DERIVATION is in W[1] (and istherefore W[1]-complete) by reducing to SHORTCONTEXT-SENSITIVE DERIVATION, shown tobe W[1]-complete by Downey et al(1994).Let H = (NH ,?H , RH , SH) be an arbitrarycontext-sensitive grammar in the following.
Acontext-sensitive grammar has nonterminals,terminals and a starting nonterminal just like aLCFRS, but the rules are of the form ?
?
?
forstrings ?, ?
?
(?H ?NH)?
where 0 < |?| ?
|?|.A derivation starts with the string SH .
A stringw ?
?
?
w?
can be turned into w ?
?
?
w?
in onederivation step if (?, ?)
?
RH .Definition 5.2.
An instance of the SHORTCONTEXT-SENSITIVE DERIVATION problemconsists of a context-sensitive grammar H , astring w ?
?
?H , and a constant dH ?
N. Thequestion is: can w be derived by H in at most dHsteps?
The parameter is dH .We are now ready to prove membership in W[1]by a FPT-reduction from (G,w, d) to (H,w, dH).Lemma 5.2.
The SHORT P-LCFRS(P)DERIVATION problem is in W[1].Proof.
We can restrict ourselves to the case whereno nonterminal appears twice in a right-hand sideof any rule in G. This is because, e.g., a ruleof the form A ?
f(B,B) can be turned intoA ?
f(B,B?
), using a fresh copy B?
of B thathas the same rules asB (except for having the left-hand side B?
rather than B).
Note that this modifi-cation does not affect the parameter, and increasesthe size of the grammar only polynomially.The complete reduction is somewhat lengthy,but the core intuition is very simple.
The stringis kept the same, and a context-sensitive gram-mar H is constructed such that L(H) = L(G).H simulates G by maintaining a string serializa-tion of the current ?configuration?
of G, walkingthrough the whole string rewriting the appropriatenon-terminal for every rule application in G. Aconfiguration of G can be viewed in this way,aa ?
b ?
?
?
b ?
baA B Awhere the derivation has, so far, generated someterminal symbols (the lower-case letters), two in-stances of the non-terminal A and one instance ofB.
The configuration keeps track of where thesymbols generated by the non-terminals shouldgo in the string, so #(A) = 2, #(B) = 1,and if (c, d) ?
LA and e ?
LB this derivationcan generate the final string aacbeddbcba.
Theseintermediary configurations are in H serializedinto strings of nonterminals, with a ?nonterminalmarker?
symbol in each position where a non-terminal is referred to (i.e., H generates a symbolstating ?the ith string generated by instance j ofthe nonterminal A goes here?).
H then operateslike a Turing machine.
A special nonterminal, therewriting head, picks a rule from G to apply, andwalks through the string replacing the nonterminalmarkers that are affected by that rule.
This proce-dure is then repeated d times.We start by illustrating the principles of the re-duction by an example.
Consider the grammar26Pr1,1?2XS,1,1 =?
XA,1,2XA,2,2Pr1,1?2 =?
XA,1,2XA,2,2R =?
XA,1,2RXA,2,2 =?RXA,1,2XA,2,2 =?
Pr2,2?3XA,1,2XA,2,2?=?
XA,1,3XB,1,3XA,2,3B2,3R?=?Pr2,3?4XA,1,3XB,1,3XA,2,3XB,2,3?=?
XA,1,4XB,1,4XB,1,3XA,2,3XB,2,4XB,2,3R?=?Pr6,3?1XA,1,4XB,1,4XB,1,3XA,2,3XB,2,4XB,2,3?=?
Pr3,4?1XA,1,4XB,1,4bXA,2,3XB,2,4b?=?Pr5,4?1aXB,1,4baXB,2,4b?=?
aabaabR?=?
aabaabFigure 2: A derivation in the context-sensitive grammar constructed to simulate an LCFRS.
All steps inthe application of the first rule, r1 = S ?
f(A), are given, the rest is abbreviated.G = ({S,A,B}, {a, b}, F,R, S) where F is{f(x, y) = xy, ha() = (a, a), hb() = (b, b),g((x, y), (x?, y?))
= (xx?, yy?
)},and R contains the followingr1 = S ?
f(A) r2 = A?
g(A,B)r3 = A?
ha() r4 = A?
hb()r5 = B ?
ha() r6 = B ?
hb()Notice that L(G) = {ww | w ?
{a, b}+}.
Wenow describe how H is constructed by the reduc-tion, after which the more general description fol-lows.
A derivation in G starts with the nontermi-nal S and must then apply r1.
H is constructedto start with the string Pr1,1?2XS,1,1 (all thesesymbols are nonterminals, H has the same termi-nal alphabet as G).
The symbols  and  markthe beginning and end of the string.
The nonter-minal XS,1,1 is a ?nonterminal marker?
and de-notes the location where the first string generatedby instance 1 of the nonterminal S is to be placed.Since #(S) = 1 the first string is the only stringgenerated from S. The last subscript, the instancenumber, is there to differentiate markers belong-ing to different instances of the same nonterminal.The rewriting head non-deterministically picks aninstance number for a round of rewriting (singlerule application) from a pool sufficiently large todifferentiate between the maximal number of non-terminals (since the rank of G is at most k, nomore than k2 nonterminals can be generated in krule applications).
Pr1,1?2 is the ?rewriting head?,the anchor for rule applications.
The subscripts onP determines that it will apply the rule r1, rewrit-ing nonterminal markers corresponding to the lefthand side nonterminal of r1 which have instancenumber 1.
Applying the rule may create new non-terminal markers, all of which get the instancenumber 2, also determined by the subscript.That is, the rules for Pr1,i?j in H willbe Pr1,i?jXS,1,i ?
XA,1,jXA,2,jPr1,i?j , fori, j ?
[2k2], and Pr1,i?jx ?
xPr1,i?j for allother x 6= .
Pr5,i?jXB,1,i ?
aPr5,i?j is an-other example of a rule corresponding to rule r5of G. When a rewriting head hits  it is replacedby a nonterminal R which reverses through thestring (with rules of the form xR ?
Rx for allx 6= ), after which a new rewriting head is non-deterministically picked using one of the rules in{R ?
Pr,i?j | r ?
R, i, j ?
[2k2]}, afterwhich the string is rewritten once more.
Finally,there are rules  ?
?,  ?
?
and R ?
?, toremove all nonterminals once rewriting has termi-nated.
A derivation is demonstrated in Figure 2.By induction on the length of derivations, onecan show that L(H) = L(G).
Now we need tomodify the construction slightly to ensure that Hcan simulate d steps of G in dH steps.Limiting steps in G. Construct a SHORTP-LCFRS(P) DERIVATION instance (G?, w, d)from (G,w, d) whereG?
is such that it cannot per-form more than d derivation steps.
LetN ?
= {Ai | A ?
N, i ?
[d]},and letAi ?
f(Bj1 , Cj2 , .
.
.)
?
R?for all A ?
f(B,C, .
.
.)
?
R, i ?
[d] andj1 + j2 + ?
?
?
= i?
1.
Then G?
= (N ?,?, R?, S1).This reduction is somewhat heavy-handed, but isin FPT since it leaves k unchanged and each ruleis replaced by less than kk rules (since d and therank of the grammar are part of the parameter k).Deferring terminals.
A problem in completingthe reduction from (G,w, d) to (H,w, dH) is thatthe number of terminal symbolsG generates is notin its parameter k. For example, G may containa rule like A ?
a ?
?
?
a, for an arbitrary num-ber of as.
Applying this rule may make the in-termediary string H is operating on too long forit to complete rewriting in dH steps.
This can27easily be fixed by a polynomial-time rewriting ofH .
For any rule w ?
w?
in H such that w?
con-tains at least one terminal, replace every maximalsubstring ?
?
??
by a new nonterminal T?, a?terminal place-holder?.The rewriting head P andreversal nonterminal R just walk over the place-holders without changing them.
Now add the ruleT?
?
?
for each T?.
For example, where arewriting head inH might have replacedXA,1,1 byabcXB,1,1baXB,2,1cc it will now instead replace itby TabcXB,1,1TbaXB,2,1Tcc, and can defer replac-ing the place-holder nonterminals until the end.Completing the reduction.
Now we are readyto put all the pieces together.
Given the SHORTP-LCFRS(P) DERIVATION instance (G,w, d),apply the limiting steps reduction to construct(G?, w, d?).
Apply the rewriting construction toG to get the context-sensitive grammar H .
NowL(H) equals the language G can generate in dsteps.
Apply the deferring terminals constructionto H to get H ?.
All that remains is to calcu-late dH , the number of steps that H ?
may take.For an FPT-reduction this number may only de-pend on the parameter k of (G?, w, d?).
PickingdH = k5+103 is sufficient.
Each rule inG?
gener-ates less than k nonterminals (since the maximumrank is at most k), each of which will generateat most k markers in the derivation in H ?
(sincethe fanout is at most k).
The rule may in addi-tion generate (k + 1)k terminal place-holders (thek2 nonterminal markers and string ends separatingmaximal terminal substrings).
After k rule appli-cations, without replacing terminal placeholders,the intermediary string in a derivation in H is lessthan k(k2+(k+1)k)+3 symbols long.
Simulatinga rule application in H ?
entails walking the stringtwice (forward and then reversing), and k rules areapplied, giving 2k(k(k2+(k+1)k)+3) steps.
An-other k(k+ 1) + 3 steps at the end replace the ter-minal place-holders and remove markers and therewriting head.
Adding things up we arrive at apolynomial of degree 4 that can be rounded up tok5 + 103.Theorem 5.3.
SHORT P-LCFRS(P) DERIVA-TION is W[1]-hard.Proof.
This combines Lemmas 5.1 and 5.2.The result of Theorem 5.3 also trivially appliesto another natural choice of parameters, the depthof acyclic LCFRS, since they can naturally onlytake a limited number of derivation steps.Definition 5.3.
A LCFRS is acyclic of depth d if dis the smallest integer such that there is a function?
: N ?
[d] such that for all A?
f(B1, .
.
.
, Bn)in R and i ?
[n] it holds that ?
(A) < ?(Bi).Corollary.
The membership problem for acyclicLCFRS where the rank, fan-out, and depth aretaken as the parameter is W[1]-complete.6 DiscussionWe have shown that the 1-LCFRS(P)-MEMBERSHIP problem is W[SAT]-hard, butwe have no upper bound, except for the trivialXP membership.
A conjecture of Pietrzak (2003)may help explain the difficulty of finding suchan upper bound.
It states that any parameterizedproblem that has a property that Pietrzak callsadditive is either in FPT or not in W[P].
Basically,additivity says that any number of instances,sharing a parameter value, can in polynomial timebe combined into one big instance, with the sameparameter.
While 1-LCFRS(P)-MEMBERSHIPis not additive, it has subproblems that are.
Thismeans that if Pietrzak?s conjecture is true (andFPT 6= W[P]), then 1-LCFRS(P)-MEMBERSHIPcannot belong to W[P].While our results are mostly intractability re-sults, we see them as a first step towards a morefinely grained understanding of the complexity ofLCFRS parsing.
Ruling out simple parameteri-zation by fan-out or rank as a road towards effi-cient algorithms lets us focus on other possibili-ties.
Many possible parameterizations remain un-explored.
In particular, we conjecture that param-eterizing by string length yields FPT membership.In the search for features that can be used in algo-rithm development, it may also be useful to inves-tigate other formalisms, such as e.g., hypergraphreplacement and tree-walking transducers.AcknowledgmentsWe acknowledge the support of the Swedish Re-search Council grant 621-2011-6080.ReferencesK.
A. Abrahamson, R. G. Downey, and M. R. Fellows.1993.
Fixed-parameter intractability II (Extendedabstract).
In Proceedings of the 10th Annual Sym-posium on Theoretical Aspects of Computer Science(STACS?93), pages 374?385.28K.
A. Abrahamson, R. G. Downey, and M. R. Fellows.1995.
Fixed-parameter tractability and complete-ness IV: On completeness for W[P] and PSPACE-analogues.
Annals of Pure and Applied Logic,73:235?276.P.
Boullier.
2004.
Range concatenation grammars.In New Developments in Parsing Technology, pages269?289.
Kluwer Academic Publishers.H.
Burden and P. Ljunglo?f.
2005.
Parsing linearcontext-free rewriting systems.
In Proceedings of9th International Workshop on Parsing Technolo-gies.R.
G. Downey and M. R. Fellows.
1999.
Parameter-ized Complexity.
Springer-Verlag.R.
G. Downey, M. R. Fellows, B. M. Kapron, M. T.Hallett, and H. T. Wareham.
1994.
The parameter-ized complexity of some problems in logic and lin-guistics.
In Logical Foundations of Computer Sci-ence, pages 89?100.
Springer.J.
Flum and M. Grohe.
2006.
Parameterized Complex-ity Theory.
Springer-Verlag.C.
Go?mez-Rodr?
?guez, M. Kuhlmann, and G. Satta.2010.
Efficient parsing of well-nested linearcontext-free rewriting systems.
In Human LanguageTechnologies: The 2010 Annual Conference of theNorth American Chapter of the ACL, pages 276?284.A.
Joshi.
1985.
Tree adjoining grammars: How muchcontext-sensitivity is required to provide reasonablestructural descriptions.
In Natural Language Pars-ing, pages 206?250.
Cambridge University Press.Y.
Kaji, R. Nakanisi, H. Seki, and T. Kasami.
1992.The universal recognition problem for multiplecontext-free grammars and for linear context-freerewriting systems.
IEICE Transactions on Informa-tion and Systems, E75-D(1):78?88.K.
Pietrzak.
2003.
A conjecture on the parameterizedhierarchy.
Notes on a talk given at Dagstuhl Seminar03311.
Unpublished manuscript.B.
Sagot and G. Satta.
2010.
Optimal rank reductionfor linear context-free rewriting systems with fan-out two.
In Proceedings of the 48th Annual Meet-ing of the Association for Computational Linguistics(ACL?10), pages 525?533.G.
Satta.
1992.
Recognition of linear context-freerewriting systems.
In Proceedings of the 30th An-nual Meeting of the Association for ComputationalLinguistics (ACL?92), pages 89?95.G.
Satta.
1998.
Trading independent for synchronizedparallelism in finite copying parallel rewriting sys-tems.
J.
Computer and System Sciences, 56(1):27?45.H.
Seki, T. Matsumura, M. Fujii, and T. Kasami.
1991.On multiple context-free grammars.
TheoreticalComputer Science, 88(2):191?229.K.
Vijay-Shanker, D. J. Weir, and A. K. Joshi.
1987.Characterizing structural descriptions produced byvarious grammatical formalisms.
In Proceedings ofthe 25th Meeting of the Association for Computa-tional Linguists (ACL?87), pages 104?111.29
