Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 249?254,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsRandom Walk Factoid Annotation for Collective DiscourseBen King Rahul JhaDepartment of EECSUniversity of MichiganAnn Arbor, MIbenking@umich.edurahuljha@umich.eduDragomir R. RadevDepartment of EECSSchool of InformationUniversity of MichiganAnn Arbor, MIradev@umich.eduRobert Mankoff ?The New Yorker MagazineNew York, NYbob mankoff@newyorker.comAbstractIn this paper, we study the problem of au-tomatically annotating the factoids presentin collective discourse.
Factoids are in-formation units that are shared betweeninstances of collective discourse and mayhave many different ways of being realizedin words.
Our approach divides this prob-lem into two steps, using a graph-basedapproach for each step: (1) factoid dis-covery, finding groups of words that corre-spond to the same factoid, and (2) factoidassignment, using these groups of wordsto mark collective discourse units that con-tain the respective factoids.
We study thison two novel data sets: the New Yorkercaption contest data set, and the crosswordclues data set.1 IntroductionCollective discourse tends to contain relativelyfew factoids, or information units about which theauthor speaks, but many nuggets, different waysto speak about or refer to a factoid (Qazvinian andRadev, 2011).
Many natural language applicationscould be improved with good factoid annotation.Our approach in this paper divides this probleminto two subtasks: discovery of factoids, and as-signment of factoids.
We take a graph-based ap-proach to the problem, clustering a word graph todiscover factoids and using random walks to as-sign factoids to discourse units.We also introduce two new datasets in this pa-per, covered in more detail in section 3.
TheNew Yorker cartoon caption dataset, providedby Robert Mankoff, the cartoon editor at TheNew Yorker magazine, is composed of reader-submitted captions for a cartoon published in themagazine.
The crossword clue dataset consists?Cartoon Editor, The New Yorker magazineFigure 1: The cartoon used for the New Yorkercaption contest #331.of word-clue pairs used in major American cross-word puzzles, with most words having severalhundred different clues published for it.The term ?factoid?
is used as in (Van Halterenand Teufel, 2003), but in a slightly more abstractsense in this paper, denoting a set of related wordsthat should ideally refer to a real-world entity, butmay not for some of the less coherent factoids.The factoids discovered using this method don?tnecessarily correspond to the factoids that mightbe chosen by annotators.For example, given two user-submitted cartooncaptions?
?When they said, ?Take us to your leader,?
Idon?t think they meant your mother?s house,??
and ?You?d better call your mother and tellher to set a few extra place settings,?a human may say that they share the factoid called?mother.?
The automatic methods however, mightsay that these captions share factoid3, which isidentified by the words ?mother,?
?in-laws,?
?fam-ily,?
?house,?
etc.The layout of this paper is as follows: we reviewrelated work in section 2, we introduce the datasets249in detail in section 3, we describe our methods insection 4, and report results in section 5.2 Related WorkThe distribution of factoids present in text collec-tions is important for several NLP tasks such assummarization.
The Pyramid Evaluation method(Nenkova and Passonneau, 2004) for automaticsummary evaluation depends on finding and an-notating factoids in input sentences.
Qazvinianand Radev (2011) also studied the properties offactoids present in collective human datasets andused it to create a summarization system.
Henniget al (2010) describe an approach for automati-cally learning factoids for pyramid evaluation us-ing a topic modeling approach.Our random-walk annotation technique is sim-ilar to the one used in (Hassan and Radev, 2010)to identify the semantic polarity of words.
Dasand Petrov (2011) also introduced a graph-basedmethod for part-of-speech tagging in which edgeweights are based on feature vectors similarity,which is like the corpus-based lexical similaritygraph that we construct.3 Data SetsWe introduce two new data sets in this paper, theNew Yorker caption contest data set, and the cross-word clues data set.
Though these two data sets arequite different, they share a few important char-acteristics.
First, the discourse units tend to beshort, approximately ten words for cartoon cap-tions and approximately three words for crosswordclues.
Second, though the authors act indepen-dently, they tend to produce surprisingly similartext, making the same sorts of jokes, or referringto words in the same sorts of ways.
Thirdly, theauthors often try to be non-obvious: obvious jokesare often not funny, and obvious crossword cluesmake a puzzle less challenging.3.1 New Yorker Caption Contest Data SetThe New Yorker magazine holds a weekly con-test1 in which they publish a cartoon withouta caption and solicit caption suggestions fromtheir readers.
The three funniest captions are se-lected by the editor and published in the follow-ing weeks.
Figure 1 shows an example of sucha cartoon, while Table 1 shows examples of cap-tions, including its winning captions.
As part of1http://www.newyorker.com/humor/captionI don?t care what planet they are from, they can pass on theleft like everyone else.I don?t care what planet they?re from, they should have thecommon courtesy to dim their lights.I don?t care where he?s from, you pass on the left.If he wants to pass, he can use the right lane like everyoneelse.When they said, ?Take us to your leader,?
I don?t think theymeant your mother?s house.They may be disappointed when they learn that ?our leader?is your mother.You?d better call your mother and tell her to set a few extraplace settings.If they ask for our leader, is it Obama or your mother?Which finger do I use for aliens?I guess the middle finger means the same thing to them.I sense somehow that flipping the bird was lost on them.What?s the Klingon gesture for ?Go around us, jerk?
?Table 1: Captions for contest #331.
Finalists arelisted in italics.this research project, we have acquired five car-toons along with all of the captions submitted inthe corresponding contest.While the task of automatically identifying thefunny captions would be quite useful, it is well be-yond the current state of the art in NLP.
A muchmore manageable task, and one that is quite impor-tant for the contest?s editor is to annotate captionsaccording to their factoids.
This allows the orga-nizers of the contest to find the most frequentlymentioned factoids and select representative cap-tions for each factoid.On average, each cartoon has 5,400 submittedcaptions, but for each of five cartoons, we sam-pled 500 captions for annotation.
The annotatorswere instructed to mark factoids by identifyingand grouping events, objects, and themes presentin the captions, creating a unique name for eachfactoid, and marking the captions that contain eachfactoid.
One caption could be given many differ-ent labels.
For example, in cartoon #331, such fac-toids may be ?bad directions?, ?police?, ?take meto your leader?, ?racism?, or ?headlights?.
Afterannotating, each set of captions contained about60 factoids on average.
On average a caption wasannotated with 0.90 factoids, with approximately80% of the discourse units having at least one fac-toid, 20% having at least two, and only 2% hav-ing more than two.
Inter-annotator agreement wasmoderate, with an F1-score (described more insection 5) of 0.6 between annotators.As van Halteren and Teufel (2003) also found2500 20 40 600204060(a)0 5 10 15 20 25050100150(b)Figure 2: Average factoid frequency distributionsfor cartoon captions (a) and crossword clues (b).0 100 200 300 400 5000204060(a)0 100 200 300 400 5000510(b)Figure 3: Growth of the number of unique factoidsas the size of the corpus grows for cartoon captions(a) and crossword clues (b).when examining factoid distributions in human-produced summaries, we found that the distribu-tion of factoids in the caption set for each car-toon seems to follow a power law.
Figure 2 showsthe average frequencies of factoids, when orderedfrom most- to least-frequent.
We also found aHeap?s law-type effect in the number of uniquefactoids compared to the size of the corpus, as inFigure 3.3.2 Crossword Clues Data SetClues in crossword puzzles are typically obscure,requiring the reader to recognize double mean-ings or puns, which leads to a great deal of diver-sity.
These clues can also refer to one or moreof many different senses of the word.
Table 2shows examples of many different clues for theword ?tea?.
This table clearly illustrates the differ-ence between factoids (the senses being referredto) and nuggets (the realization of the factoids).The website crosswordtracker.com col-lects a large number of clues that appear in dif-ferent published crossword puzzles and aggregatesthem according to their answer.
From this site, wecollected 200 sets of clues for common crosswordanswers.We manually annotated 20 sets of crosswordclues according to their factoids in the same fash-ion as described in section 3.1.
On average eachset of clues contains 283 clues and 15 differentfactoids.
Inter-annotator agreement on this datasetwas quite high with an F1-score of 0.96.Clue SenseMajor Indian export drinkLeaves for a break?
drinkDarjeeling, e.g.
drinkAfternoon social event4:00 gathering eventSympathy partner filmMythical Irish queen personParty movement political movementWord with rose or garden plant and placeTable 2: Examples of crossword clues and theirdifferent senses for the word ?tea?.4 Methods4.1 Random Walk MethodWe take a graph-based approach to the discoveryof factoids, clustering a word similarity graph andtaking the resulting clusters to be the factoids.
Twodifferent graphs, a word co-occurrence graph anda lexical similarity graph learned from the corpus,are compared.
We also compare the graph-basedmethods against baselines of clustering and topicmodeling.4.1.1 Word Co-occurrence GraphTo create the word co-occurrence graph, we createa link between every pair of words with an edgeweight proportional to the number of times theyboth occur in the same discourse unit.4.1.2 Corpus-based Lexical Similarity GraphTo build the lexical similarity graph, a lexical sim-ilarity function is learned from the corpus, thatis, from one set of captions or clues.
We do thisby computing feature vectors for each lemma andusing the cosine similarity between these featurevectors as a lexical similarity function.
We con-struct a word graph with edge weights propor-tional to the learned similarity of the respectiveword pairs.We use three types of features in these featurevectors: context word features, context part-of-speech features, and spelling features.
Contextfeatures are the presence of each word in a win-dow of five words (two words on each side plus theword in question).
Context part-of-speech featuresare the part-of-speech labels given by the Stan-ford POS tagger (Toutanova et al, 2003) withinthe same window.
Spelling features are the countsof all character trigrams present in the word.Table 3 shows examples of similar word pairsfrom the set of crossword clues for ?tea?.
From251Figure 4: Example of natural clusters in a subsection of the word co-occurrence graph for the crosswordclue ?astro?.Word pair Sim.
(white-gloves, white-glove) 0.74(may, can) 0.57(midafternoon, mid-afternoon) 0.55(company, co.) 0.46(supermarket, market) 0.53(pick-me-up, perk-me-up) 0.44(green, black) 0.44(lady, earl) 0.39(kenyan, indian) 0.38Table 3: Examples of similar pairs of words as cal-culated on the set of crossword clues for ?tea?.this table, we can see that this method is ableto successfully identify several similar word pairsthat would be missed by most lexical databases:minor lexical variations, such as ?pick-me-up?
vs.?perk-me-up?
; abbreviations, such as ?company?and ?co.?
; and words that are similar only in thiscontext, such as ?lady?
and ?earl?
(referring toLady Grey and Earl Grey tea).4.1.3 Graph ClusteringTo cluster the word similarity graph, we use theLouvain graph clustering method (Blondel et al,2008), a hierarchical method that optimizes graphmodularity.
This method produces several hierar-chical cluster levels.
We use the highest level, cor-responding to the fewest number of clusters.Figure 4 shows an example of clusters foundin the word graph for the crossword clue ?as-tro?.
There are three obvious clusters, one for theHouston Astros baseball team, one for the dog inthe Jetsons cartoon, and one for the lexical prefix?astro-?.
In this example, two of the clusters areconnected by a clue that mentions multiple senses,?Houston ballplayer or Jetson dog?.4.1.4 Random Walk Factoid AssignmentAfter discovering factoids, the remaining task isto annotate captions according to the factoids theycontain.
We approach this problem by taking ran-dom walks on the word graph constructed in theprevious sections, starting the random walks fromwords in the caption and measuring the hittingtimes to different clusters.For each discourse unit, we repeatedly sam-ple words from it and take Markov random walksstarting from the nodes corresponding to the se-lected and lasting 10 steps (which is enough to en-sure that every node in the graph can be reached).After 1000 random walks, we measure the aver-age hitting time to each cluster, where a cluster isconsidered to be reached by the random walk thefirst time a node in that cluster is reached.
Heuris-tically, 1000 random walks was more than enoughto ensure that the factoid distribution had stabi-lized in development data.The labels that are applied to a caption are thelabels of the clusters that have a sufficiently lowhitting time.
We perform five-fold cross valida-tion on each caption or set of clues and tune thethreshold on the hitting time such that the aver-age number of labels per unit produced matchesthe average number of labels per unit in the goldannotation of the held-out portion.For example, a certain caption may have the fol-lowing hitting times to the different factoid clus-ters:factoid1 0.11factoid2 0.75factoid3 1.14factoid4 2.41If the held-out portion has 1.2 factoids per cap-tion, it may be determined that the optimal thresh-252old on the hitting times is 0.8, that is, a thresholdof 0.8 produces 1.2 factoids per caption in the test-set on average.
In this case factoid1 and factoid2would be marked for this caption, since the hittingtimes fall below the threshold.4.2 ClusteringA simple baseline that can act as a surrogate forfactoid annotation is clustering of discourse units,which is equivalent to assigning exactly one fac-toid (the name of its cluster) to each discourseunit.
As our clustering method, we use C-Lexrank(Qazvinian and Radev, 2008), a method that hasbeen well-tested on collective discourse.4.3 Topic ModelTopic modeling is a natural way to approach theproblem of factoid annotation, if we consider thetopics to be factoids.
We use the Mallet (McCal-lum, 2002) implementation of Latent Dirichlet Al-location (LDA) (Blei et al, 2003).
As with the ran-dom walk method, we perform five-fold cross val-idation, tuning the threshold for the average num-ber of labels per discourse unit to match the aver-age number of labels in the held-out portion.
Be-cause LDA needs to know the number of topicsa priori, we set the number of topics to be equalto the true number of factoids.
We also use theaverage number of unique factoids in the held-outportion as the number of LDA topics.5 Evaluation and ResultsWe evaluate this task in a way similar to pairwiseclustering evaluation methods, where every pair ofdiscourse units that should share at least one fac-toid and does is a true positive instance, every pairthat should share a factoid and does not is a falsenegative, etc.
From this we are able to calculateprecision, recall, and F1-score.
This is a reason-able evaluation method, since the average numberof factoids per discourse unit is close to one.
Be-cause the factoids discovered by this method don?tnecessarily match the factoids chosen by the an-notators, it doesn?t make sense to try to measurewhether two discourse units share the ?correct?factoid.Tables 4 and 5 show the results of the variousmethods on the cartoon captions and crosswordclues datasets, respectively.
On the crosswordclues datasets, the random-walk-based methodsare clearly superior to the other methods tested,whereas simple clustering is more effective on theMethod Prec.
Rec.
F1LDA 0.318 0.070 0.115C-Lexrank 0.131 0.347 0.183Word co-occurrence graph 0.115 0.348 0.166Word similarity graph 0.093 0.669 0.162Table 4: Performance of various methods annotat-ing factoids for cartoon captions.Method Prec.
Rec.
F1LDA 0.315 0.067 0.106C-Lexrank 0.702 0.251 0.336Word co-occurrence graph 0.649 0.257 0.347Word similarity graph 0.575 0.397 0.447Table 5: Performance of various methods annotat-ing factoids for crossword clues.cartoon captions dataset.In some sense, the two datasets in this paperboth represent difficult domains, ones in whichauthors are intentionally obscure.
The good re-sults acheived on the crossword clues dataset in-dicate that this obscurity can be overcome whendiscourse units are short.
Future work in thisvein includes applying these methods to domains,such as newswire, that are more typical for sum-marization, and if necessary, investigating howthese methods can best be applied to domains withlonger sentences.ReferencesDavid M Blei, Andrew Y Ng, and Michael I Jordan.2003.
Latent dirichlet alocation.
the Journal of ma-chine Learning research, 3:993?1022.Vincent D Blondel, Jean-Loup Guillaume, RenaudLambiotte, and Etienne Lefebvre.
2008.
Fast un-folding of communities in large networks.
Journalof Statistical Mechanics: Theory and Experiment,2008(10):P10008.Dipanjan Das and Slav Petrov.
2011.
Unsuper-vised part-of-speech tagging with bilingual graph-based projections.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies, pages600?609.Ahmed Hassan and Dragomir Radev.
2010.
Identify-ing text polarity using random walks.
In Proceed-ings of the 48th Annual Meeting of the Associationfor Computational Linguistics, pages 395?403.
As-sociation for Computational Linguistics.Leonhard Hennig, Ernesto William De Luca, and SahinAlbayrak.
2010.
Learning summary content unitswith topic modeling.
In Proceedings of the 23rd253International Conference on Computational Lin-guistics: Posters, COLING ?10, pages 391?399,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Andrew Kachites McCallum.
2002.
Mallet: A ma-chine learning for language toolkit.Ani Nenkova and Rebecca Passonneau.
2004.
Evalu-ating content selection in summarization: The pyra-mid method.Vahed Qazvinian and Dragomir R Radev.
2008.
Sci-entific paper summarization using citation summarynetworks.
In Proceedings of the 22nd InternationalConference on Computational Linguistics-Volume 1,pages 689?696.
Association for Computational Lin-guistics.Vahed Qazvinian and Dragomir R Radev.
2011.Learning from collective human behavior to intro-duce diversity in lexical choice.
In Proceedings ofthe 49th annual meeting of the association for com-putational linguistics: Human language techolo-gies, pages 1098?1108.Kristina Toutanova, Dan Klein, Christopher D Man-ning, and Yoram Singer.
2003.
Feature-rich part-of-speech tagging with a cyclic dependency network.In Proceedings of the 2003 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics on Human Language Technology-Volume 1, pages 173?180.
Association for Compu-tational Linguistics.Hans Van Halteren and Simone Teufel.
2003.
Exam-ining the consensus between human summaries: ini-tial experiments with factoid analysis.
In Proceed-ings of the HLT-NAACL 03 on Text summarizationworkshop-Volume 5, pages 57?64.
Association forComputational Linguistics.254
