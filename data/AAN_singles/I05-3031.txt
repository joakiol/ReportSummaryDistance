Two-Phase LMR-RC Tagging for Chinese Word SegmentationTak Pang Lau and Irwin KingDepartment of Computer Science and EngineeringThe Chinese University of Hong KongShatin, N.T., Hong Kong{tplau, king}@cse.cuhk.edu.hkAbstractIn this paper we present a Two-PhaseLMR-RC Tagging scheme to performChinese word segmentation.
In theRegular Tagging phase, Chinese sen-tences are processed similar to the orig-inal LMR Tagging.
Tagged sentencesare then passed to the Correctional Tag-ging phase, in which the sentences arere-tagged using extra information fromthe first round tagging results.
Twotraining methods, Separated Mode andIntegrated Mode, are proposed to con-struct the models.
Experimental re-sults show that our scheme in Inte-grated Mode performs the best in termsof accuracy, where Separated Mode ismore suitable under limited computa-tional resources.1 IntroductionThe Chinese word segmentation is a non-trivialtask because no explicit delimiters (like spacesin English) are used for word separation.
As thetask is an important precursor to many natural lan-guage processing systems, it receives a lot of at-tentions in the literature for the past decade (Wuand Tseng, 1993; Sproat et al, 1996).
In this pa-per, we propose a statistical approach based onthe works of (Xue and Shen, 2003), in which theChinese word segmentation problem is first trans-formed into a tagging problem, then the Max-imum Entropy classifier is applied to solve theproblem.
We further improve the scheme by in-troducing correctional treatments after first roundtagging.
Two different training methods are pro-posed to suit our scheme.The paper is organized as follows.
In Sec-tion 2, we briefly discuss the scheme proposed by(Xue and Shen, 2003), followed by our additionalworks to improve the performance.
Experimen-tal and bakeoff results are presented in Section 3.Finally, We conclude the paper in Section 4.2 Our Proposed Approach2.1 Chinese Word Segmentation as TaggingOne of the difficulties in Chinese word segmen-tation is that, Chinese characters can appear indifferent positions within a word (Xue and Shen,2003), and LMR Tagging was proposed to solvethe problem.
The basic idea of LMR Tagging isto assign to each character, based on its contextualinformation, a tag which represents its relative po-sition within the word.
Note that the original tagset used by (Xue and Shen, 2003) is simplifiedand improved by (Ng and Low, 2004) .
We shallthen adopt and illustrate the simplified case here.The tags and their meanings are summarizedin Table 1.
Tag L, M, and R correspond to thecharacter at the beginning, in the middle, and atthe end of the word respectively.
Tag S meansthe character is a ?single-character?
word.
Fig-ure 1 illustrates a Chinese sentence segmented byspaces, and the corresponding tagging results.After transforming the Chinese segmentationproblem to the tagging problem, various so-lutions can be applied.
Maximum Entropymodel (MaxEnt) (Berger, S. A. Della Pietra, and183Original sentence: ?????????
?After segmentation: ??
??
?
????
?Tagging: ??
??
?
????
?Figure 1: Example of LMR Tagging.V.
J. Della Pietra, 1996; Ratnaparkhi, 1996) wasproposed in the original work to solve the LMRTagging problem.
In order to make MaxEnt suc-cess in LMR Tagging, feature templates used incapturing useful contextual information must becarefully designed.
Furthermore, it is unavoid-able that invalid tag sequences will occur if wejust assign the tag with the highest probability.
Inthe next subsection, we describe the feature tem-plates and measures used to correct the tagging.Table 1: Tags used in LMR Tagging scheme.Tag DescriptionL Character is at the beginning of the word (or thecharacter is the leftmost character in the word)M Character is in the middle of the wordR Character is at the end of the word (or the charac-ter is the rightmost character in the word)S Character is a ?single-character?
word2.2 Two-Phase LMR-RC TaggingIn this section, we introduce our Two-Phase LMR-RC Tagging used to perform Chinese Text Seg-mentation.
The first phase, R-phase, is called Reg-ular Tagging, in which similar procedures as inthe original LMR Tagging are performed.
Thedifference in this phase as compared to the origi-nal one is that, we use extra feature templates tocapture characteristics of Chinese word segmen-tation.
The second phase, C-phase, is called Cor-rectional Tagging, in which the sentences are re-tagged by incorporating the regular tagging re-sults.
We hope that tagging errors can be cor-rected under this way.
The models used in bothphases are trained using MaxEnt model.Regular Tagging PhaseIn this phase, each character is tagged similarto the original approach.
In our scheme, giventhe contextual information (x) of current charac-ter, the tag (y?)
with highest probability will beassigned:y?
= argmaxy?
{L,M,R,S}p(y|x).The features describing the characteristics ofChinese segmentation problem are instantiationsof the feature templates listed in Table 2.
Notethat feature templates only describe the forms offeatures, but not the actual features.
So the num-ber of features used is much larger than the num-ber of templates.Table 2: Feature templates used in R-phase.
Ex-ample used is ?32???
?.Feature Type Example ?
Featuresextracted ofcharacter ??
?1 Characters withinwindow of ?2C?2=?3?,C?1=?2?,C0=???,C1=???,C2=??
?2 Two consecutivecharacters withinwindow of ?2C?2C?1=?32?,C?1C0=?2??,C0C1=????,C1C2=???
?3 Previous and nextcharactersC?1C1=?
2?
?4 Current character ispunctuation?5 ASCII characterswithin window of ?2A?2, A?1(as ?3?
and ?2?
areASCII)6 Current and characterin window ?1 belongto different typesD?1(as ?2?
is digit, but ???
is letter)Additional feature templates as compared to(Xue and Shen, 2003) and (Ng and Low, 2004)are template 5 and 6.
Template 5 is used to han-dle documents with ASCII characters.
For tem-plate 6, as it is quite common that word boundaryoccurs in between two characters with differenttypes, this template is used to capture such char-acteristics.Correctional Tagging PhaseIn this phase, the sequence of characters is re-tagged by using the additional information of tag-ging results after R-phase.
The tagging procedureis similar to the previous phase, except extra fea-tures (listed in Table 3) are used to assist the tag-ging.184Table 3: Additional feature templates used in C-phase.
Example used is ?32????
with taggingresults after R-phase as ?SSLMR?.Feature Type Example ?
Featuresextracted of character ??
?7 Tags of characterswithin window of?2T?2=?S?,T?1=?S?,T0=?L?,T1=?M?,T2=?R?8 Two consecutivetags within windowof ?2T?2T?1=?SS?,T?1T0=?SL?,T0T1=?LM?,T1T2=?MR?9 Previous and nexttagsT?1T1=?SM?Training MethodTwo training methods are proposed to constructmodels used in R- and C-phase: (1) SeparatedMode, and (2) Integrated Mode.
Separated Modemeans the models used in two phases are sepa-rated.
Model for R-phase is called R-model, andmodel for C-phase is called C-model.
IntegratedMode means only one model, I-model is used inboth phases.The training methods are illustrated now.
Firstof all, training data are divided into three parts,(1) Regular Training, (2) Correctional Training,and (3) Evaluation.
Our method first trains usingobservations extracted from Part 1 (observation issimply the pair (context, tag) of each character).The created model is used to process Part 2.
Afterthat, observations extracted from Part 2 (which in-clude previous tagging results) are used to createthe final model.
The performance is then evalu-ated by processing Part 3.Let O be the set of observations, with sub-scripts R or C indicating the sources of them.
LetTrainModel : O ?
P , where P is the set ofmodels, be the ?model generating?
function.
Thetwo proposed training methods can be illustratedas follow:1.
Separated ModeR?model = TrainModel(OR),C ?model = TrainModel(OC).2.
Integrated ModeI ?model = TrainModel(OR ?OC).The advantage of Separated Mode is that, it iseasy to aggregate different sets of training data.It also provides a mean to handle large trainingdata under limited resources, as we can divide thetraining data into several parts, and then use thesimilar idea to train each part.
The drawback ofthis mode is that, it may lose the features?
charac-teristics captured from Part 1 of training data, andIntegrated Mode is proposed to address the prob-lem, in which all the features?
characteristics inboth Part 1 and Part 2 are used to train the model.3 Experimental Results and DiscussionWe conducted closed track experiments on theHong Kong City University (CityU) corpus inThe Second International Chinese Word Segmen-tation Bakeoff to evaluate the proposed trainingand tagging methods.
The training data were splitinto three portions.
Part 1: 60% of the data istrained for R-phase; Part 2: 30% for C-phasetraining; and Part 3: the remaining 10% for eval-uation.
The evaluation part was further dividedinto six parts to simulate actual size of test doc-ument.
The MaxEnt classifier was implementedusing Java opennlp maximum entropy packagefrom (Baldridge, Morton, and Bierner, 2004), andtraining was done with feature cutoff of 2 and 160iterations.
The experiments were run on an IntelPentium4 3.0GHz machine with 3.0GB memory.To evaluate our proposed scheme, we carriedout four experiments for each evaluation data.
ForExperiment 1, data were processed with R-phaseonly.
For Experiment 2, data were processed withboth R- and C-phase, using Separated Mode astraining method.
For Experiment 3, data wereprocessed similar to Experiment 2, except Inte-grated Mode was used.
Finally for Experiment4, data were processed similar to Experiment 1,with both Part 1 and Part 2 data were used for R-model training.
The purpose of Experiment 4 is todetermine whether the proposed scheme can per-form better than just the single Regular Taggingunder the same amount of training data.
Table 4summarizes the experimental results measured inF-measure (the harmonic mean of precision andrecall).From the results, we obtain the following ob-servations.1.
Both Integrated and Separated Training modes185Table 4: Experimental results of CityU corpusmeasured in F-measure.Data Set Exp1 Exp2 Exp3 Exp41 0.918 0.943 0.949 0.9472 0.913 0.939 0.943 0.9433 0.912 0.935 0.939 0.9374 0.914 0.940 0.943 0.9425 0.921 0.942 0.945 0.9456 0.914 0.941 0.945 0.942in Two-Phase Tagging (Exp 2 and Exp 3) out-perform single Regular Tagging (Exp 1).
It isreasonable as more data are used in training.2.
Integrated Mode (Exp 3) still performs betterthan Exp 4, in which same amount of trainingdata are used.
This reflects that extra tagginginformation after R-phase helps in the scheme.3.
Separated Mode (Exp 2) performs worse thanboth Exp 3 and Exp 4.
The reason is that the C-model cannot capture enough features?
charac-teristics used for basic tagging.
We believe thatby adjusting the proportion of Part 1 and Part 2of training data, performance can be increased.4.
Under limited computational resources, inwhich constructing single-model using allavailable data (as in Exp 3 and Exp 4) is notpossible, Separated Mode shows its advantagein constructing and aggregating multi-modelsby dividing the training data into different por-tions.The official BakeOff2005 results are summa-rized in Table 5.
We have submitted multiple re-sults for CityU, MSR and PKU corpora by ap-plying different tagging methods described in thepaper.Table 5: Official BakeOff2005 results.Keys:F - Regular Tagging only, all training data are usedP1 - Regular Tagging only, 90% of training data are usedP2 - Regular Tagging only, 70% of training data are usedS - Regular and Correctional Tagging, Separated ModeI - Regular and Correctional Tagging, Integrated ModeCorpus R P F ROOV RIV MethodCityU 0.938 0.915 0.927 0.658 0.961 F0.936 0.913 0.925 0.656 0.959 P10.925 0.896 0.910 0.639 0.948 P20.937 0.922 0.929 0.698 0.956 IMSR 0.946 0.933 0.939 0.587 0.956 F0.941 0.932 0.937 0.624 0.950 SPKU 0.926 0.908 0.917 0.535 0.950 F0.917 0.903 0.910 0.600 0.937 P20.918 0.915 0.917 0.621 0.936 I4 ConclusionWe present a Two-Phase LMR-RC Taggingscheme to perform Chinese word segmentation.Correctional Tagging phase is introduced in ad-dition to the original LMR Tagging technique, inwhich the Chinese sentences are re-tagged usingextra information of first round tagging results.Two training methods, Separated Mode and In-tegrated Mode, are introduced to suit our scheme.Experimental results show that Integrated Modeachieve the highest accuracy in terms of F-measure, where Separated Mode shows its ad-vantages in constructing and aggregating multi-models under limited resources.AcknowledgementsThe work described in this paper was fully sup-ported by a grant from the Research Grants Coun-cil of the Hong Kong Special Administrative Re-gion, China (Project No.
CUHK4235/04E).ReferencesA.
L. Berger, S. A. Della Pietra, and V. J. Della Pietra.
1996.A maximum entropy approach to natural language pro-cessing.
Computational Linguistics, 22(1):39-71.A.
Ratnaparkhi.
1996.
A maximum entropy model for part-of-speech tagging.
In Proceedings of the First Confer-ence on Empirical Methods in Natural Language Pro-cessing, pages 133-142.H.
T. Ng and J. K. Low.
2004.
Chinese Part-of-SpeechTagging.
One-at-a-Time or All-at-once?
Word-Based orCharacter-Based?
In Proc.
of EMNLP.J.
Baldridge, T. Morton, and G. Bierner.2004.
The opennlp maxent package in Java.URL: http://maxent.sourceforge.net .N.
Xue and L. Shen.
2003.
Chinese word segmentation asLMR Tagging.
In Proc.
of SIGHAN Workshop.R.
Sproat, C. Shih, W. Gale, and N. Chang.
1996.
Astochastic finite-state word-segmentation algorithm forChinese.
Computational Linguistics, 22(3):377-404.R.
Sproat and T. Emerson.
2003.
The first internationalChinese word segmentation bakeoff.
In Proc.
of SIGHANWorkshop.Z.
Wu and G. Tseng.
1993.
Chinese text segmentation fortext retrieval: achievements and problems.
Journal ofthe American Society for Information Science, 44(9):532-542.186
