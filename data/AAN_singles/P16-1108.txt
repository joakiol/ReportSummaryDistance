Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 1138?1147,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsLeveraging Inflection Tables for Stemming and LemmatizationGarrett Nicolai and Grzegorz KondrakDepartment of Computing ScienceUniversity of Alberta{nicolai,gkondrak}@ualberta.caAbstractWe present several methods for stemmingand lemmatization based on discrimina-tive string transduction.
We exploit theparadigmatic regularity of semi-structuredinflection tables to identify stems in an un-supervised manner with over 85% accu-racy.
Experiments on English, Dutch andGerman show that our stemmers substan-tially outperform Snowball and Morfes-sor, and approach the accuracy of a super-vised model.
Furthermore, the generatedstems are more consistent than those an-notated by experts.
Our direct lemmatiza-tion model is more accurate than Morfetteand Lemming on most datasets.
Finally,we test our methods on the data from theshared task on morphological reinflection.1 IntroductionMany languages contain multiple inflected formsthat correspond to the same dictionary word.
In-flection is a grammatical procedure that has littleimpact on the meaning of the word.
For example,the German words in Table 1 all refer to the actionof giving.
When working with these languages,it is often beneficial to establish a consistent rep-resentation across a set of inflections.
This is thetask that we address here.There are two principal approaches to inflec-tional simplification: stemming and lemmatiza-tion.
Stemming aims at removing inflectional af-fixes from a word form.
It can be viewed as a kindof word segmentation, in which the boundaries ofthe stem are identified within the word; no attemptis made to restore stem changes that may occur aspart of the inflection process.
The goal of lemma-tization is to map any inflected form to its uniquelemma, which is typically the word form that rep-Word form Meaning Tag Stemgeben ?to give?
INF gebgibt ?gives?
3SIE gibgab ?gave?
1SIA gabgegeben ?given?
PP gebTable 1: Examples of German word-forms corre-sponding to the lemma geben.resents a set of related inflections in a dictionary.Unlike stemming, lemmatization must always pro-duce an actual word form.In this paper, we present a discriminativestring transduction approach to both stemming andlemmatization.
Supervised stemmers require mor-phologically annotated corpora, which are expen-sive to build.
We remove this constraint by ex-tracting stems from semi-structured inflection ta-bles, such as the one shown in Table 2, in an un-supervised manner.
We design two transductionmodels that are trained on such stems, and eval-uate them on unseen forms against a supervisedmodel.
We then extend our stemming models toperform the lemmatization task, and to incorporatean unannotated corpus.
We evaluate them on sev-eral datasets.Our best system improves the state ofthe art for Dutch, German, and Spanish.
Finally,we test our methods on the data from the sharedtask on morphological reinflection.This paper is organized as follows.
In Section 2,we present an overview of prior work on inflec-tional simplification.
In Section 3, we describe ourstemming methodology, followed by three typesof evaluation experiments in Section 4.
In Section5, we describe our approach to lemmatization, fol-lowed by both intrinsic and extrinsic experimentsin Section 6.
Section 7 concludes the paper.11382 Related WorkIn this section, we review prior work on stemmingand lemmatization.2.1 Stemming and SegmentationStemming is a sub-task of the larger problemof morphological segmentation.
Because of thescarcity of morphologically-annotated data, manysegmentation algorithms are unsupervised or rule-based.The Porter stemmer (Porter, 1980) and itsderivatives, such as Snowball, apply hand-craftedcontext rules to strip affixes from a word.
Cre-ation of such rule-based programs requires signif-icant effort and expert knowledge.
We use struc-tured inflection tables to create training data for adiscriminative transducer.Morfessor (Creutz and Lagus, 2002) and Lin-guistica (Goldsmith, 2001) are unsupervised wordsegmenters, which divide words into regularly oc-curring sub-sequences by applying the minimumdescription length (MDL) principle.
While thesemethods are good at identifying common mor-phemes, they make no distinction between stemsand affixes, and thus cannot be used for stemming.Morfessor Categories-MAP (Creutz and Lagus,2004; Creutz and Lagus, 2005) distinguishes be-tween stems and affixes, but not between deriva-tional and inflectional affixes.
We adapt a morerecent version (Gr?onroos et al, 2014) to be usedas an approximate stemmer.Poon et al (2009) abandons the generativemodel of Morfessor for a log-linear model thatpredicts segmentations in sequence.
The discrim-inative approach allows for the incorporation ofseveral priors that minimize over-segmentation.Their unsupervised model outperforms Morfessor,and they are also able to report semi- and fully-supervised results.
We also approach the prob-lem using a discriminative method, but by aligningstructured inflection tables, we can take advantageof linguistic knowledge, without requiring costlyannotation.Ruokolainen et al (2014) obtain further im-provements by combining a structured perceptronCRF with letter successor variety (LSV), and theunsupervised features of Creutz and Lagus (2004).Their system is inherently supervised, while ourstem annotations are derived in an unsupervisedmanner.Cotterell et al (2015) introduce Chipmunk, aSingular Plural1st2nd3rd1stPresent doy das da damosImperfect daba dabas daba d?abamosPreterite di diste dio dimosFuture dar?e dar?as dar?a daramosTable 2: A partial inflection table for the Spanishverb dar ?to give?.fully-supervised system for labeled morphologicalsegmentation.
Extending the sequence-predictionmodels, Chipmunk makes use of data that is anno-tated not only for stem or affix, but also for inflec-tional role, effectively combining morphologicalsegmentation and morphological analysis.
Whilehighly accurate, Chipmunk is limited in that it re-quires data that is fully-annotated for both seg-mentation and inflection.
Our system has accessto the morphological tags in inflection tables, butsegmentation and tag alignment are performed inan unsupervised way.2.2 LemmatizationUnlike stemmers, which can be unsupervised,lemmatizers typically require annotated trainingdata.
In addition, some lemmatizers assume ac-cess to the morphological tag of the word, and/orthe surrounding words in the text.
Our focus is oncontext-free lemmatization, which could later becombined with a contextual disambiguation mod-ule.Lemmatization is often part of the morpholog-ical analysis task, which aims at annotating eachword-form with its lemma and morphological tag.Toutanova and Cherry (2009) learn a joint modelfor contextual lemmatization and part-of-speechprediction from a morphologically annotated lexi-con.
Their transduction model is tightly integratedwith the POS information, which makes compar-ison difficult.
However, in Section 6, we evaluateour approach against two other fully-supervisedmorphological analyzers: Morfette (Chrupa?a etal., 2008) and Lemming (M?uller et al, 2015).Both of these systems perform lemmatization andmorphological analysis in context, but can betrained to learn non-contextual models.
Morfetterequires morphological tags during training, whileLemming requires a morphological model con-structed by its sister program, Marmot (M?uller etal., 2013).11393 Stemming MethodsWe approach stemming as a string transductiontask.
Stemming can be performed by insertingmorpheme boundary markers between the stemand the affixes.
For example, the German verbform gegeben is transduced into ge+geb+en,which induces the stem geb.3.1 Character AlignmentThe training of a transduction model requires a setof aligned pairs of source and target strings.
Thealignment involves every input and output charac-ter; the insertion and deletion operations are disal-lowed.
Atomic character transformations are thenextracted from the alignments.We infer the alignment with a modified ver-sion of the M2M aligner of Jiampojamarn et al(2007).
The program applies the Expectation-Maximization algorithm with the objective tomaximize the joint likelihood of its aligned sourceand target pairs.
For our task, the source and targetstrings are nearly identical, except that the targetincludes stem-affix boundary markers.
In order toaccount for every character in the target, which isusually longer than the source, we allow one-to-many alignment.
This has the effect of tying themarkers to the edge of a stem or affix.
In orderto encourage alignments between identical charac-ters, we modify the aligner to generalize all iden-tity transformations into a single match operation.3.2 Supervised TransductionOnce we have aligned the source and target pairs,we proceed to train a word-to-stem transductionmodel for stemming unseen test instances.
Theword-to-stem model learns where to insert bound-ary markers.
We refer to a model that is trainedon annotated morphological segmentations as oursupervised method.We perform string transduction by adapting DI-RECTL+, a tool originally designed for grapheme-to-phoneme conversion (Jiampojamarn et al,2010).
DIRECTL+ is a feature-rich, discrimina-tive character transducer that searches for a model-optimal sequence of character transformation rulesfor its input.
The core of the engine is a dy-namic programming algorithm capable of trans-ducing many consecutive characters in a single op-eration.
Using a structured version of the MIRAalgorithm (McDonald et al, 2005), training at-tempts to assign weights to each feature so that itsSTEM|INF geb|en setz|en tu|nSTEM|1SIA gab|- setz|te tat|-STEM|2SIE gib|st setz|t tu|stPP|STEM|PP ge|geb|en ge|setz|t ge|ta|nTable 3: Stemming of the training data basedon the patterns of regularity in inflectional tables.Stemmas are shown in bold.linear model separates the gold-standard deriva-tion from all others in its search space.DIRECTL+ uses a number of feature templatesto assess the quality of a rule: source context, tar-get n-gram, and joint n-gram features.
Contextfeatures conjoin the rule with indicators for allsource character n-grams within a fixed windowof where the rule is being applied.
Target n-gramsprovide indicators on target character sequences,describing the shape of the target as it is being pro-duced, and may also be conjoined with our sourcecontext features.
Joint n-grams build indicatorson rule sequences, combining source and targetcontext, and memorizing frequently-used rule pat-terns.Following Toutanova and Cherry (2009), wemodify the out-of-the-box version of DIRECTL+by implementing an abstract copy feature that in-dicates when a rule simply copies its source char-acters into the target, e.g.
b ?
b.
The copy featurehas the effect of biasing the transducer towardspreserving the source characters during transduc-tion.3.3 Unsupervised SegmentationIn order to train a fully-supervised model for stem-ming, large lists of morphologically-segmentedwords are generally required.
While such an-notated corpora are rare, semi-structured, crowd-sourced inflection tables are available for manylanguages on websites such as Wiktionary (Ta-ble 2).
In this section, we introduce an unsu-pervised method of inducing stems by leveragingparadigmatic regularity in inflection tables.Sets of inflection tables often exhibit the sameinflectional patterns, called paradigms, which arebased on phonological, semantic, or morphologi-cal criteria (cf.
Table 3).
Each table consists of listsof word forms, including the lemma.
The num-ber of distinct stems, such as ?geb?
and ?gib?
forthe verb geben, is typically very small, averagingslightly over two per German verb inflection table.1140Source g i b tTarget g i b +tTags STEM 3SIEJoint g e b +3SIETable 4: Alignment of the various representationsof the word gibt.The number of distinct affix forms correspondingto the same inflectional form across different lem-mas is also small, averaging below three for Ger-man verbs.
For example, the second person sin-gular indicative present suffix is always either -st,-est, or -t.We take advantage of this relative consistencyto determine the boundaries between the stems andaffixes of each word form in an unsupervised man-ner.
We first associate each word form in the train-ing data with an abstract tag sequence, which istypically composed of the STEM tag and a suffixtag representing a given inflection slot (Table 3).We then apply the unsupervised aligner to deter-mine the most likely alignment between the char-acter sequences and the tags, which are treatedas indivisible units.
The aligner simultaneouslylearns common representations for stems within asingle inflection table, as well as common repre-sentations for each affix across multiple tables.Some inflections, such as the German past par-ticiple (PP in Table 3) involve a circumfix, whichcan be analyzed as a prefix-suffix combination.Prior to the alignment, we associate all forms thatbelong to the inflection slots involving circumfix-ation with tag sequences composed of three tags.Occasionally, a word form will only have a suf-fix where one would normally expect a circumfix(e.g.
existiert).
In order to facilitate tag alignmentin such cases, we prepend a dummy null characterto each surface word form.After the stem-affix boundaries have been iden-tified, we proceed to train a word-to-stem trans-duction model as described in Section 3.2.
Werefer to this unsupervised approach as our basicmethod (cf.
Figure 1).3.4 Joint Stemming and TaggingThe method described in the previous section failsto make use of a key piece of information in the in-flection table: the lemma.
The stem of an inflectedform is typically either identical or very similar tothe stem of its lemma, or stemma (Table 3).
OurWords Noun Verb AdjEnglish 50,155 2 5 3Dutch 101,667 2 9 3German 96,038 8 27 48Table 5: The number of words and distinct inflec-tions for each language in the CELEX datasets.joint method takes advantage of this similarity bytransducing word-forms into stemmas with tags.The format of the training data for the word-to-stemma model is different from the word-to-stemmodel.
After the initial segmentation of the sourceword-forms into morphemes by the unsupervisedaligner, as described in Section 3.3, the stems arereplaced with the corresponding stemmas, and theaffixes are replaced with the inflection tags.
Forexample, the form gibt is paired with the sequencegeb+3SIE, with the stem and stemma re-alignedat the character level as shown in Table 4.Unlike the basic method, which simply in-serts morpheme breaks into word-forms, the jointmethod uses the tags to identify the boundaries be-tween stems and affixes.
At test time, the inputword-form is transduced into a stemma and tagsequence.
The character string that has generatedthe tag is then stripped from the input word-formto obtain the stem.
By making use of both thetags and the stemma, the word-to-stemma modeljointly optimizes the stem and affix combination.We refer to this unsupervised approach as our jointmethod.4 Stemming ExperimentsPrecise evaluation of stemming methods requiresmorphologically annotated lexicons, which arerare.
Unlike lemmas, stems are abstract represen-tations, rather than actual word forms.
Unsurpris-ingly, annotators do not always agree on the seg-mentation of a word.
In this section, we describethree experiments for evaluating stem extraction,intrinsic accuracy, and consistency.We evaluate our methods against three systemsthat are based on very different principles.
Snow-ball1is a rule-based program based on the method-ology of the Porter Stemmer.
Morfessor Flat-Cat (Gr?onroos et al, 2014) performs unsuper-vised morphological segmentation, and approxi-mates stemming by distinguishing stems and af-1http://snowball.tartarus.org1141EN NL DEOur method 85.9 88.0 85.7Snowball 48.2 58.8 49.5Morfessor 61.4 71.4 61.4Table 6: Unsupervised stemming accuracy of theCELEX training set.fixes.2Chipmunk (Cotterell et al, 2015), is afully-supervised system that represents the currentstate of the art.4.1 DataWe perform an evaluation of stemming on En-glish (EN), Dutch (NL), and German (DE) lex-icons from CELEX (Baayen et al, 1995).
Thethree languages vary in terms of morphologicalcomplexity (Table 5).
We use the morphologicalboundary annotations for testing all stemming sys-tems, as well as for training our supervised system.For both unsupervised systems, we could buildtraining sets from any inflection tables that con-tain unsegmented word-forms.
However, in orderto perform a precise comparison between the su-pervised and unsupervised systems, we extract theinflection tables from CELEX, disregarding thesegmentation information.
Each system is repre-sented by a single stemming model that works onnouns, verbs, and adjectives.
Due to differencesin representation, the number of training instancesvary slightly between models, but the number ofwords is constant (Table 5).In order to demonstrate that our unsupervisedmethods require no segmentation information, wecreate additional German training sets using theinflection tables extracted from Wiktionary byDurrett and DeNero (2013).
The sets contain18,912 noun forms and 43,929 verb forms.
Wederive separate models for verbs and nouns in or-der to compare the difficulty of stemming differentparts of speech.The test sets for both CELEX and Wiktionarydata come from CELEX, and consist of 5252,6155, and 9817 unique forms for English, Dutch,and German, respectively.
The German test setcontains 2620 nouns, 3837 verbs, and 3360 adjec-tives.Chipmunk3requires training data in which ev-2Morfessor is applied to the union of the training and testdata.3http://cistern.cis.lmu.de/chipmunkEN NL DESupervised 98.5 96.0 91.2Basic 82.3 89.1 80.9Joint 94.6 93.2 86.0Snowball 50.0 58.4 48.2Morfessor 65.2 60.9 51.8Table 7: Stemming accuracy of systems trainedand tested on CELEX datasets.ery morpheme of a word is annotated for morpho-logical function.
Since this information is not in-cluded in CELEX, we train and test Chipmunk,as well as a version of our supervised model, onthe data created by Cotterell et al (2015), whichis much smaller.
The English and German seg-mentation datasets contain 1161 and 1266 traininginstances, and 816 and 952 test instances, respec-tively.4.2 Stem Extraction EvaluationFirst, we evaluate our unsupervised segmentationapproach, which serves as the basis for our ba-sic and joint models, on the union of the trainingand development parts of the CELEX dataset.
Weare interested how often the stems induced by themethod described in Section 3.3 match the stemannotations in the CELEX database.The results are presented in Table 6.
Ourmethod is substantially more accurate than ei-ther Snowball or Morfessor.
Snowball, despitebeing called a stemming algorithm, often elimi-nates derivational affixes; e.g.
able in unbear-able.
Morfessor makes similar mistakes, althoughless often.
Our method tends to prefer longerstems and shorter affixes.
For example, it stemsverwandtestem, as verwandte, while CELEXhas verwandt.4.3 Intrinsic EvaluationThe results of the intrinsic evaluation of the stem-ming accuracy on unseen forms in Tables 7-9demonstrate the quality of our three models.
Thejoint model performs better than the basic model,and approaches the accuracy of the supervisedmodel.
On the CELEX data, our unsupervisedjoint model substantially outperforms Snowballand Morfessor on all three languages (Table 7).44The decrease in Morfessor accuracy between Tables 6and 7 can be attributed to a different POS distribution be-tween training and testing.1142Noun VerbBasic 76.8 90.3Joint 85.2 91.1Snowball 55.5 39.8Morfessor 61.9 34.9Table 8: German stemming accuracy of systemstrained on Wiktionary data, and tested on theCELEX data.EN DESupervised 94.7 85.1Chipmunk 94.9 87.4Table 9: Stemming accuracy of systems trainedand tested on the Chipmunk data.These results are further confirmed on the Ger-man Wiktionary data (Table 8).
Our supervisedmodel performs almost as well as Chipmunk onits dataset (Table 9).A major advantage of the joint model over thebasic model is its tag awareness (cf.
Table 4).Although the tags are not always correctly recov-ered on the test data, they often allow the modelto select the right analysis.
For example, the ba-sic model erroneously segments the German formerkl?arte as erkl?art+e because +e is a commonverbal, adjectival and nominal suffix.
The jointmodel, recognizing er as a verbal derivationalprefix, predicts a verbal inflection tag (+1SIA),and the correct segmentation erkl?ar+te.
Ver-bal stems are unlikely to end in ?art, and +te,unlike +e, can only be a verbal suffix.4.4 Consistency EvaluationWhen stemming is used for inflectional simplifi-cation, it should ideally produce the same stemfor all word-forms that correspond to a givenlemma.
In many cases, this is not an attainablegoal because of internal stem changes (cf.
Ta-ble 1).
However, most inflected words follow reg-ular paradigms, which involve no stem changes.For example, all forms of the Spanish verb can-tar contain the substring cant, which is consid-ered the common stem.
We quantify the extent towhich the various systems approximate this goalby calculating the average number of unique gen-erated stems per inflection table in the CELEX testEN NL DEGold 1.10 1.17 1.30Supervised 1.13 1.64 1.50Basic 1.06 1.21 1.25Joint 1.09 1.08 1.20Snowball 1.03 1.45 2.02Morfessor 1.11 1.68 3.27Table 10: Average number of stems per lemma.sets.5The results are presented in Table 10.
Thestems-per-table average tends to reflect the mor-phological complexity of a language.
All systemsachieve excellent consistency on English, but theDutch and German results paint a different pic-ture.
The supervised system falls somewhat shortof emulating the gold segmentations, which maybe due to the confusion between different parts ofspeech.
In terms of consistency, the stems gener-ated by our unsupervised methods are superior tothose of Snowball and Morfessor, and even to thegold stems.
We attribute this surprising result tothe fact that the EM-based alignment of the train-ing data favors consistency in both stems and af-fixes, although this may not always result in thecorrect segmentation.5 Lemmatization MethodsIn this section, we present three supervisedlemmatization methods, two of which incorporatethe unsupervised stemming models described inSection 3.
The different approaches are presentedschematically in Figure 1, using the example ofthe German past participle gedacht.5.1 Stem-based LemmatizationOur stem-based lemmatization method is an ex-tension of our basic stemming method.
We com-pose the word-to-stem transduction model fromSection 3 with a stem-to-lemma model that con-verts stems into lemmas.
The latter is trainedon character-aligned pairs of stems and lemmas,where stems are extracted from the inflection ta-bles via the unsupervised method described inSection 3.3.5Chipmunk is excluded from the consistency evaluationbecause its dataset is not composed of complete inflectiontables.1143Figure 1: Three lemmatization methods.5.2 Stemma-based LemmatizationOur stemma-based lemmatization method is anextension of our joint stemming method.
We com-pose the word-to-stemma transduction model de-scribed in Section 3.4 with a stemma-to-lemmamodel that converts stems into lemmas.
The lat-ter is trained on character-aligned pairs of stem-mas and lemmas, where stemmas are extracted viathe method described in Section 3.4.
Typically,the model simply appends a lemmatic affix to thestemma, as all stem changes are handled by theword-to-stemma model.5.3 Direct LemmatizationOur final lemmatization method is a word-to-lemma transduction model that directly transformsword-forms into lemmas and tags.
The model istrained on word-forms paired with their lemmasand inflectional tags, which are easily obtainedfrom the inflection tables.
A potential advantageof this method lies in removing the possibility oferror propagation that is inherent in pipeline ap-proaches.
However, it involves a more complextransduction model that must simultaneously ap-ply both stem changes, and transform inflectionalaffixes into lemmatic ones.5.4 Re-rankingIntuitively, lemmatization accuracy could be im-proved by leveraging large, unannotated corpora.After generating n-best lists of possible lemmas,we re-rank them using the method of Joachims(2002) implemented with the Liblinear SVM tool(Fan et al, 2008).
We employ four features of theprediction:1. normalized score from DIRECTL+,2.
rank in the n-best list3.
presence in the corpus,4.
normalized likelihood from a 4-gram charac-ter language model derived from the corpus.6 Lemmatization ExperimentsUnlike stemming, lemmatization is a completelyconsistent process: all word-forms within an in-flection table correspond to the same lemma.
Inthis section, we describe intrinsic and extrinsic ex-periments to evaluate the quality of the lemmasgenerated by our systems, and compare the resultsagainst the current state of the art.6.1 DataAs in our stemming experiments, we extract com-plete English, Dutch, and German inflection ta-bles from CELEX.
We use the same data splitsas in Section 4.1.
We also evaluate our methodson Spanish verb inflection tables extracted fromWiktionary by Durrett and DeNero (2013), usingthe original data splits.
Spanish is a Romance lan-guage, with a rich verbal morphology comprising57 inflections for each lemma.A different type of dataset comes from theCoNLL-2009 Shared Task (Haji?c et al, 2009).Unlike the CELEX and Wiktionary datasets, theyare extracted from an annotated text, and thus con-tain few complete inflection tables, with manylemmas represented by a small number of word-forms.
We extract all appropriate parts-of-speechfrom the test section of the corpus for English,German, and Spanish.
This results in a test set of5165 unique forms for English, 6572 for German,and 2668 for Spanish.For re-ranking, we make use of a word list con-structed from the first one million lines of the ap-propriate Wikipedia dump.6A character languagemodel is constructed using the CMU StatisticalLanguage Modeling Toolkit.720% of the devel-opment set is reserved for the purpose of traininga re-ranking model.
For Lemming and Morfette,we provide a lexicon generated from the corpus.Spanish marks unpredictable stress by markinga stressed vowel with an acute accent (e.g.
cant?o6All dumps are from November 2, 2015.7http://www.speech.cs.cmu.edu1144Wiki CELEX CoNLLES EN NL DE EN DE ESStem-based 97.1 89.1 82.3 76.3 90.2 71.1 83.2Stemma-based 94.5 96.4 85.2 85.8 92.5 75.9 91.2Direct 98.8 96.4 89.5 88.7 92.5 80.1 91.5Morfette 98.0 96.0 80.2 81.3 92.5 73.5 91.5Lemming 98.6 96.7 86.6 88.2 92.5 77.9 90.4Table 11: Lemmatization results without the use of a corpus.vs.
canto).
In order to facilitate generalization,we perform a lossless pre-processing step that re-places all accented vowels with their unaccentedequivalent followed by a special stress symbol(e.g.
canto?).
For consistency, this modificationis applied to the data for each system.6.2 Intrinsic EvaluationWe evaluate lemmatization using word accuracy.In cases where a surface word-form without amorphological tag may correspond to multiplelemmas, we judge the prediction as correct if itmatches any of the lemmas.
For example, boththe noun Schrei and the verb schreien are consid-ered to be correct lemmas for the German wordschreien.8The results without the use of a corpus areshown in Table 11.
Thanks to its tag awareness,the stemma-based method is more accurate thanthe stem-based method, except on the verb-onlySpanish Wiktionary dataset.
However, our bestmethod is the direct word-to-lemma model, whichoutperforms both Morfette and Lemming on mostdatasets.We interpret the results as the evidence for theeffectiveness of our discriminative string transduc-tion approach.
The direct model is superior to thestemma-based model because it avoids any infor-mation loss that may occur during an intermediatestemming step.
However, it is still able to take ad-vantage of the tag that it generates together withthe target lemma.
For example, Lemming incor-rectly lemmatizes the German noun form Verdi-enste ?earnings?
as verdien because +ste isa superlative adjective suffix.
Our direct model,however, considers dien to be an unlikely endingfor an adjective, and instead produces the correctlemma Verdienst.The results with the use of a corpus are shown8The capitalization of German nouns is ignored.CELEX CoNLLNL DE DE ESStem-based 82.3 76.9 71.9 90.6Stemma-based 87.3 88.4 79.0 93.3Direct 92.4 90.0 81.3 91.9Lemming 86.9 88.5 77.9 90.6Table 12: Lemmatization results boosted with araw corpus.in Table 12.
We omit the results on Spanish Wik-tionary and on both English datasets, which arealmost identical to those in Table 11.
We observethat both the stemma-based and direct methodsachieve a substantial error rate reduction on theDutch and German datasets, while Lemming im-provements are minimal.9The Spanish CoNLLresults are different: only the stem-based andstemma-based methods benefit noticeably from re-ranking.Error analysis indicates that the re-ranker is ableto filter non-existent lemmas, such as wint forWinter, and endstadie for Endstadien, insteadof Endstadium.
In general, the degree of improve-ment seems to depend on the set of randomly se-lected instances in the held-out set used for train-ing the re-ranker.
If a base model achieves a veryhigh accuracy on the held-out set, the re-rankertends to avoid correcting the predictions on the testset.6.3 Extrinsic EvaluationWe perform our final evaluation experiment onthe German dataset10from the SIGMORPHONshared task on morphological reinflection (Cot-9We were unable to obtain any corpus improvement withMorfette.10http://sigmorphon.org/sharedtask1145Task 1 Task 3Baseline 89.4 81.5Chipmunk 82.0 88.3Stem-based 86.9 89.3Stemma-based 84.0 89.5Lemma-based n/a 90.7Source-Target 94.8 88.2Table 13: Accuracy on the German dataset fromthe shared task on morphological reinflection.terell et al, 2016).11The task of inflection gen-eration (Task 1) is to produce a word-form givena lemma and an abstract inflectional tag.
The taskof unlabeled reinflection (Task 3) takes as input anunannotated inflected form instead of a lemma.We evaluate four different methods that com-bine the models introduced in this paper.
For Task1, the stem-based method composes a lemma-to-stem and a stem-to-word models; the stemma-based method is similar, but pivots on stemmas in-stead; and the source-target method is a lemma-to-word model.
For Task 3, a word-to-lemmamodel is added in front of both the stem-based andstemma-based methods; the lemma-based methodcomposes a word-to-lemma and a lemma-to-wordmodels; and the source-target method is a word-to-word model.
In addition, we compare with amethod that is similar to our stem-based method,but pivots on Chipmunk-generated stems instead.As a baseline, we run the transduction method pro-vided by the task organizers.The results are shown in Table 13.
On Task 1,none of the stemming approaches is competitivewith a direct lemma-to-word model.
This is notsurprising.
First, the lemmatic suffixes provide in-formation regarding part-of-speech.
Second, thestemmers fail to take into account the fact that thesource word-forms are lemmas.
For example, theGerman word ?uberhitzend ?overheated?
can eitherbe an adjective, or the present participle of the verb?uberhitzen; if the word is a lemma, it is obviouslythe former.The lemma-based method is the best perform-ing one on Task 3.
One advantage that it hasover the word-to-word model lies in the ability toreduce the potentially quadratic number of trans-duction operations between various related word-11We use the development sets for this evaluation becausethe target sides of the test sets have not been publicly released.forms to a linear number of transduction opera-tions between the word-forms and their lemmas,and vice-versa.7 ConclusionWe have presented novel methods that leveragereadily available inflection tables to produce high-quality stems and lemmas.
In the future, we planto expand our method to predict morphologicalanalyses, as well as to incorporate other informa-tion such as parts-of-speech.AcknowledgmentsThis research was supported by the NaturalSciences and Engineering Research Council ofCanada, and the Alberta Innovates TechnologyFutures.ReferencesHarald R. Baayen, Richard Piepenbrock, and Leon Gu-likers.
1995.
The CELEX Lexical Database.
Re-lease 2 (CD-ROM).
Linguistic Data Consortium,University of Pennsylvania, Philadelphia, Pennsyl-vania.Grzegorz Chrupa?a, Georgiana Dinu, and JosefVan Genabith.
2008.
Learning morphology withMorfette.
In LREC.Ryan Cotterell, Thomas M?uller, Alexander Fraser, andHinrich Sch?utze.
2015.
Labeled morphological seg-mentation with semi-markov models.
CoNLL 2015,page 164.Ryan Cotterell, Christo Kirov, John Sylak-Glassman,David Yarowsky, Jason Eisner, and Mans Hulden.2016.
The SIGMORPHON 2016 shared task?morphological reinflection.
In SIGMORPHON.Mathias Creutz and Krista Lagus.
2002.
Unsuper-vised discovery of morphemes.
In Proceedings ofthe ACL-02 workshop on Morphological and phono-logical learning-Volume 6, pages 21?30.Mathias Creutz and Krista Lagus.
2004.
Induction of asimple morphology for highly-inflecting languages.In Proceedings of the 7th Meeting of the ACL SpecialInterest Group in Computational Phonology: Cur-rent Themes in Computational Phonology and Mor-phology, pages 43?51.Mathias Creutz and Krista Lagus.
2005.
Induc-ing the morphological lexicon of a natural lan-guage from unannotated text.
In Proceedings of theInternational and Interdisciplinary Conference onAdaptive Knowledge Representation and Reasoning(AKRR05), volume 1(106-113), pages 51?59.1146Greg Durrett and John DeNero.
2013.
Supervisedlearning of complete morphological paradigms.
InHLT-NAACL, pages 1185?1195.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin.
2008.
Liblinear: Alibrary for large linear classification.
The Journal ofMachine Learning Research, 9:1871?1874.John Goldsmith.
2001.
Unsupervised learning of themorphology of a natural language.
Computationallinguistics, 27(2):153?198.Stig-Arne Gr?onroos, Sami Virpioja, Peter Smit, andMikko Kurimo.
2014.
Morfessor FlatCat: AnHMM-based method for unsupervised and semi-supervised learning of morphology.
In COLING,pages 1177?1185.Jan Haji?c, Massimiliano Ciaramita, Richard Johans-son, Daisuke Kawahara, Maria Ant`onia Mart?
?, Llu?
?sM`arquez, Adam Meyers, Joakim Nivre, SebastianPad?o, Jan?St?ep?anek, et al 2009.
The CoNLL-2009shared task: Syntactic and semantic dependencies inmultiple languages.
In CoNLL, pages 1?18.Sittichai Jiampojamarn, Grzegorz Kondrak, and TarekSherif.
2007.
Applying many-to-many alignmentsand hidden markov models to letter-to-phonemeconversion.
In NAACL-HLT, pages 372?379.Sittichai Jiampojamarn, Colin Cherry, and GrzegorzKondrak.
2010.
Integrating joint n-gram featuresinto a discriminative training network.
In NAACL-HLT.Thorsten Joachims.
2002.
Optimizing search en-gines using clickthrough data.
In Proceedings of theeighth ACM SIGKDD international conference onKnowledge discovery and data mining, pages 133?142.
ACM.Ryan McDonald, Koby Crammer, and FernandoPereira.
2005.
Online large-margin training of de-pendency parsers.
In ACL.Thomas M?uller, Helmut Schmid, and Hinrich Sch?utze.2013.
Efficient higher-order CRFs for morphologi-cal tagging.
In EMNLP, pages 322?332.Thomas M?uller, Ryan Cotterell, and Alexander Fraser.2015.
Joint lemmatization and morphological tag-ging with LEMMING.
In EMNLP.Hoifung Poon, Colin Cherry, and Kristina Toutanova.2009.
Unsupervised morphological segmentationwith log-linear models.
In NAACL-HLT, pages 209?217.Martin F Porter.
1980.
An algorithm for suffix strip-ping.
Program, 14(3):130?137.Teemu Ruokolainen, Oskar Kohonen, Sami Virpioja,and Mikko Kurimo.
2014.
Painless semi-supervisedmorphological segmentation using conditional ran-dom fields.
EACL, page 84.Kristina Toutanova and Colin Cherry.
2009.
A globalmodel for joint lemmatization and part-of-speechprediction.
In ACL, pages 486?494.1147
