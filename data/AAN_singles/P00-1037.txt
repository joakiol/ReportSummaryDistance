An Improved Error Model for Noisy Channel Spelling CorrectionAbstractThe noisy channel model has been appliedto a wide range of problems, includingspelling correction.
These models consistof two components: a source model and achannel model.
Very little research hasgone into improving the channel modelfor spelling correction.
This paperdescribes a new channel model forspelling correction, based on genericstring to string edits.
Using this modelgives significant performanceimprovements compared to previouslyproposed models.IntroductionThe noisy channel model (Shannon 1948)has been successfully applied to a widerange of problems, including spellingcorrection.
These models consist of twocomponents: a source model and a channelmodel.
For many applications, people havedevoted considerable energy to improvingboth components, with resultingimprovements in overall system accuracy.However, relatively little research has goneinto improving the channel model forspelling correction.
This paper describes animprovement to noisy channel spellingcorrection via a more powerful model ofspelling errors, be they typing mistakes orcognitive errors, than has previously beenemployed.
Our model works by learninggeneric string to string edits, along with theprobabilities of each of these edits.
Thismore powerful model gives significantimprovements in accuracy over previousapproaches to noisy channel spellingcorrection.1 Noisy Channel Spelling CorrectionThis paper will address the problem ofautomatically training a system to correctgeneric single word spelling errors.1  We donot address the problem of correctingspecific word set confusions such as{to,too,two} (see (Golding and Roth 1999)).We will define the spelling correctionproblem abstractly as follows: Given analphabet ?
, a dictionary D consisting ofstrings in ?
* and a string s, whereDs ?
and *?
?s , find the word Dw ?
thatis most likely to have been erroneously inputas s.  The requirement that Ds ?
can bedropped, but it only makes sense to do so inthe context of a sufficiently powerfullanguage model.In a probabilistic system, we want tofind )|(argmax   w swP .
Applying Bayes?Rule and dropping the constantdenominator, we get the unnormalizedposterior: )(*)|(argmax   w wPwsP .
We nowhave a noisy channel model for spellingcorrection, with two components, the sourcemodel P(w) and the channel model P(s | w).The model assumes that natural languagetext is generated as follows: First a personchooses a word to output, according to theprobability distribution P(w).
Then theperson attempts to output the word w, butthe noisy channel induces the person tooutput string s instead, according to the1Two very nice overviews of spelling correction canbe found in (Kukich 1992) and (Jurafsky and Martin2000).Eric Brill and Robert C. MooreMicrosoft ResearchOne Microsoft WayRedmond, Wa.
98052{brill,bobmoore}@microsoft.comdistribution P(s | w).
For instance, undertypical circumstances we would expectP(the | the) to be very high, P(teh | the) to berelatively high and P(hippopotamus | the) tobe extremely low.
In this paper, we willrefer to the channel model as the errormodel.Two seminal papers first posed anoisy channel model solution to the spellingcorrection problem.
In (Mayes, Damerau etal.
1991), word bigrams are used for thesource model.
For the error model, they firstdefine the confusion set of a string s toinclude s, along with all words w in thedictionary D such that s can be derived fromw by a single application of one of the fouredit operations:(1) Add a single letter.
(2) Delete a single letter.
(3) Replace one letter with another.
(4) Transpose two adjacent letters.Let C be the number of words in theconfusion set of d.  Then they define theerror model, for all s in the confusion set ofd, as:?????
?==otherwise )1()-(1d  s if)|(CdsP ?
?7KLVLVDYHU\VLPSOHHUURUPRGHOZKHUH LVthe prior on a typed word being correct, andthe remaining probability mass is distributedevenly among all other words in theconfusion set.Church and Gale (1991) propose amore sophisticated error model.
LikeMayes, Damerau, et al (1991), theyconsider as candidate source words onlythose words that are a single basic edit awayfrom s, using the same edit set as above.However, two improvements are made.First, instead of weighing all edits equally,each unique edit has a probability associatedwith it.
Second, insertion and deletionprobabilities are conditioned on context.The probability of inserting or deleting acharacter is conditioned on the letterappearing immediately to the left of thatcharacter.The error probabilities are derived byfirst assuming all edits are equiprobable.They use as a training corpus a set of space-delimited strings that were found in a largecollection of text, and that (a) do not appearin their dictionary and (b) are no more thanone edit away from a word that does appearin the dictionary.
They iteratively run thespell checker over the training corpus to findcorrections, then use these corrections toupdate the edit probabilities.
Ristad andYianilos (1997) present another algorithmfor deriving these edit probabilities from atraining corpus, and show that for theproblem of word pronunciation, using thelearned string edit distance gives one fourththe error rate compared to using unweightededits.2 An Improved Error ModelPrevious error models have all been basedon Damerau-Levenshtein distance measures(Damerau 1964; Levenshtein 1966), wherethe distance between two strings is theminimum number of single characterinsertions, substitutions and deletions (andin some cases, character pair transpositions)necessary to derive one string from another.Improvements have been made byassociating probabilities with individual editoperations.We propose a much more genericHUURU PRGHO  /HW  EH DQ DOSKDEHW  2XUmodel allows all edit operations of the form?  ZKHUH *?
?, .
3 ?  LV WKHprobability that when users intends to typeWKH VWULQJ  WKH\ W\SH  LQVWHDG 1RWH WKDWthe edit operations allowed in Church andGale (1991), Mayes, Damerau et al (1991)and Ristad and Yianilos (1997), are properlysubsumed by our generic string to stringsubstitutions.In addition, we condition on theposition in the string that the edit occurs in,3 ?  _ 361 ZKHUH 361   ^VWDUW RIword, middle of word, end of word}.2  Theposition is determined by the location ofVXEVWULQJ  LQ WKH VRXUFH GLFWLRQDU\ZRUGPositional information is a powerfulconditioning feature for rich edit operations.For instance, P(e | a) does not vary greatlybetween the three positions mentionedabove.
However, P(ent | ant) is highlydependent upon position.
People rarelymistype antler as entler, but often mistypereluctant as reluctent.Within the noisy channel framework,we can informally think of our error modelas follows.
First, a person picks a word togenerate.
Then she picks a partition of thecharacters of that word.
Then she typeseach partition, possibly erroneously.
Forexample, a person might choose to generatethe word physical.
She would then pick apartition from the set of all possiblepartitions, say: ph y s i c al.
Then shewould generate each partition, possibly witherrors.
After choosing this particular wordand partition, the probability of generatingthe string fisikle with the partition f i s i k lewould be P(f | ph) *P(i | y) * P(s | s) *P(i | i)* P(k | c) *P(le | al).3The above example points toadvantages of our model compared toprevious models based on weightedDamerau-Levenshtein distance.
Note thatneither P(f | ph) nor P(le | al) are modeleddirectly in the previous approaches to errormodeling.
A number of studies havepointed out that a high percentage ofmisspelled words are wrong due to a singleletter insertion, substitution, or deletion, orfrom a letter pair transposition (Damerau1964; Peterson 1986).
However, even if thisis the case, it does not imply that nothing is2Another good PSN feature would be morphemeboundary.3We will leave off the positional conditioninginformation for simplicity.to be gained by modeling more powerfuledit operations.
If somebody types thestring confidant, we do not really want tomodel this error as P(a | e), but rather P(ant |ent).
And anticedent can more accurately bemodeled by P(anti | ante), rather than P(i | e).By taking a more generic approach to errormodeling, we can more accurately model theerrors people make.A formal presentation of our modelfollows.
Let Part(w) be the set of allpossible ways of partitioning string w intoadjacent (possibly null) substrings.
For aparticular partition R?Part(w), where |R|=j(R consists of j contiguous segments), let Ribe the ith segment.
Under our model,P(s | w) =?
???
==?
)(||1|||| )()|()|(wPartRRiiiRTsPartTRTPwRPOne particular pair of alignments fors and w induces a set of edits that derive sfrom w.  By only considering the bestpartitioning of s and w, we can simplify thisto:P(s | w) =max R ?Part(w),T?Part(s) P(R|w)?=||1RiP(Ti|Ri)We do not yet have a good way toderive P(R | w), and in running experimentswe determined that poorly modeling thisdistribution gave slightly worse performancethan not modeling it at all, so in practice wedrop this term.3 Training the ModelTo train the model, we need a training setconsisting of {si, wi} string pairs,representing spelling errors si paired withthe correct spelling of the word wi.
Webegin by aligning the letters in si with thosein wi based on minimizing the edit distancebetween si and wi, based on single characterinsertions, deletions and substitutions.
Forinstance, given the training pair <akgsual,actual>, this could be aligned as:a     c       t     u     a      la      k     g     s     u     a     lThis corresponds to the sequence of editoperations:a?a    c?N ?g   t?s   u?u   a?a   l?lTo allow for richer contextualinformation, we expand each nonmatchsubstitution to incorporate up to N additionaladjacent edits.
For example, for the firstnonmatch edit in the example above, withN=2, we would generate the followingsubstitutions:c ?
kac ?
akc ?
kgac ?
akgct ?
kgsWe would do similarly for the othernonmatch edits, and give each of thesesubstitutions a fractional count.We can then calculate the probabilityRI HDFK VXEVWLWXWLRQ ?  DV FRXQW ?FRXQW FRXQW ? LVVLPSO\WKHVXPof the counts derived from our training dataas explained above.
Estimating FRXQW LVDbit tricky.
If we took a text corpus, thenextracted all the spelling errors found in thecorpus and then used those errors fortraining, FRXQW  ZRXOG VLPSO\ EH WKHnumber of times VXEVWULQJ  RFFXUV LQ WKHtext corpus.
But if we are training from a setof {si, wi} tuples and not given an associatedcorpus, we can do the following:(a) From a large collection of representativeWH[WFRXQWWKHQXPEHURIRFFXUUHQFHVRI (b) Adjust the count based on an estimate ofthe rate with which people make typingerrors.Since the rate of errors varies widelyand is difficult to measure, we can onlycrudely approximate it.
Fortunately, wehave found empirically that the results arenot very sensitive to the value chosen.Essentially, we are doing oneiteration of the Expectation-Maximizationalgorithm (Dempster, Laird et al 1977).The idea is that contexts that are useful willaccumulate fractional counts across multipleinstances, whereas contexts that are noisewill not accumulate significant counts.4 Applying the ModelGiven a string s, where Ds ?
, we want toreturn )|()|(argmax   w contextwPswP .
Ourapproach will be to return an n-best list ofcandidates according to the error model, andthen rescore these candidates by taking intoaccount the source probabilities.We are given a dictionary D and aset of parameters P, where each parameter is3 ?  IRU VRPH *?
?, , meaning theSUREDELOLW\WKDWLIDVWULQJ  LV LQWHQGHG WKHQRLV\FKDQQHOZLOOSURGXFH  LQVWHDG )LUVWnote that for a particular pair of strings {s,w} we can use the standard dynamicprogramming algorithm for finding editdistance by filling a |s|*|w| weight matrix(Wagner and Fisher 1974; Hall and Dowling1980), with only minor changes.
Forcomputing the Damerau-Levenshteindistance between two strings, this can bedone in O(|s|*|w|) time.
When we allowgeneric edit operations, the complexityincreases to O(|s|2*|w|2).
In filling in a cell(i,j) in the matrix for computing Damerau-Levenshtein distance we need only examinecells (i,j-1), (i-1,j) and (i-1,j-1).
Withgeneric edits, we have to examine all cells(a,b) where a ?
i and b ?
j.We first precompile the dictionaryinto a trie, with each node in the triecorresponding to a vector of weights.
If wethink of the x-axis of the standard weightmatrix for computing edit distance ascorresponding to w (a word in thedictionary), then the vector at each node inthe trie corresponds to a column in theweight matrix associated with computing thedistance between s and the string prefixending at that trie node.
:HVWRUHWKH ? SDUDPHWHUVDVDtrieof tries.
We have one trie corresponding toDOOVWULQJV WKDWDSSHDURQWKHOHIWKDQGVLGHof some substitution in our parameter set.At every node in this trie, corresponding to aVWULQJ ZHSRLQW WR D trie consisting of allVWULQJV  WKDW DSSHDURQ WKH ULJKW KDQG VLGHRIDVXEVWLWXWLRQLQRXUSDUDPHWHUVHWZLWKon the left hand side.
We store thesubstitution probabilities at the terminalQRGHVRIWKH WULHV%\ VWRULQJ ERWK  DQG  VWULQJV LQreverse order, we can efficiently computeedit distance over the entire dictionary.
Weprocess the dictionary trie from the rootdownwards, filling in the weight vector ateach node.
To find the substitutionparameters that are applicable, given aparticular node in the trie and a particularposition in the input string s (thiscorresponds to filling in one cell in onevector of a dictionary trie node) we trace upfrom the node to the root, while tracingGRZQ WKH  trie from the root.
As we traceGRZQ WKH  trie, if we encounter a terminalnode, we follow the pointer to theFRUUHVSRQGLQJ  trie, and then tracebackwards from the position in s whileWUDFLQJGRZQWKH trie.Note that searching through a staticdictionary D is not a requirement of ourerror model.
It is possible that with adifferent search technique, we could applyour model to languages such as Turkish forwhich a static dictionary is inappropriate(Oflazer 1994).Given a 200,000-word dictionary, andusing our best error model, we are able tospell check strings not in the dictionary inapproximately 50 milliseconds on average,running on a Dell 610 500mhz Pentium IIIworkstation.5 Results5.1  Error Model in IsolationWe ran experiments using a 10,000-word corpus of common English spellingerrors, paired with their correct spelling.We used 80% of this corpus for training and20% for evaluation.
Our dictionarycontained approximately 200,000 entries,including all words in the test set.
Theresults in this section are obtained with alanguage model that assigns uniformprobability to all words in the dictionary.
InTable 1 we show K-best results for differentmaximum context window sizes, withoutusing positional information.
For instance,the 2-best accuracy is the percentage of timethe correct answer is one of the top twoanswers returned by the system.
Note that amaximum window of zero corresponds tothe set of single character insertion, deletionand substitution edits, weighted with theirprobabilities.
We see that, up to a point,additional context provides us with moreaccurate spelling correction and beyond that,additional context neither helps nor hurts.MaxWindow 1-Best 2-Best 3-Best0 87.0 93.9 95.9CG 89.5 94.9 96.51 90.9 95.6 96.82 92.9 97.1 98.13 93.6 97.4 98.54 93.6 97.4 98.5Table 1 Results without positionalinformationIn Table 1, the row labelled CGshows the results when we allow theequivalent set of edit operations to thoseused in (Church and Gale 1991).
This is aproper superset of the set of edits where themaximum window is zero and a propersubset of the edits where the maximumwindow is one.
The CG model is essentiallyequivalent to the Church and Gale errormodel, except (a) the models above canposit an arbitrary number of edits and (b) wedid not do parameter reestimation (seebelow).Next, we measured how much wegain by conditioning on the position of theedit relative to the source word.
Theseresults are shown in Table 2.
As weexpected, positional information helps morewhen using a richer edit set than when usingonly single character edits.
For a maximumwindow size of 0, using positionalinformation gives a 13% relativeimprovement in 1-best accuracy, whereasfor a maximum window size of 4, the gain is22%.
Our full strength model gives a 52%relative error reduction on 1-best accuracycompared to the CG model (95.0%compared to 89.5%).Max Window 1-Best 2-Best 3-Best0 88.7 95.1 96.61 92.8 96.5 97.42 94.6 98.0 98.73 95.0 98.0 98.84 95.0 98.0 98.85 95.1 98.0 98.8Table 2 Results with positionalinformation.We experimented with iterativelyreestimating parameters, as was done in theoriginal formulation in (Church and Gale1991).
Doing so resulted in a slightdegradation in performance.
The data weare using is much cleaner than that used in(Church and Gale 1991) which probablyexplains why reestimation benefited them intheir experiments and did not give anybenefit to the error models in ourexperiments.5.2  Adding a Language ModelNext, we explore what happens toour results as we add a language model.
Inorder to get errors in context, we took theBrown Corpus and found all occurrences ofall words in our test set.
Then we mappedthese words to the incorrect spellings theywere paired with in the test set, and ran ourspell checker to correct the misspellings.We used two language models.
The firstassumed all words are equally likely, i.e.
thenull language model used above.
Thesecond used a trigram language modelderived from a large collection of on-linetext (not including the Brown Corpus).Because a spell checker is typically appliedright after a word is typed, the languagemodel only used left context.We show the results in Figure 1,where we used the error model withpositional information and with a maximumcontext window of four, and used thelanguage model to rescore the 5 best wordcandidates returned by the error model.Note that for the case of no language model,the results are lower than the results quotedabove (e.g.
a 1-best score above of 95.0%,compared to 93.9% in the graph).
This isbecause the results on the Brown Corpus arecomputed per token, whereas above we werecomputing results per type.One question we wanted to ask is whetherusing a good language model would obviatethe need for a good error model.
In Figure2, we applied the trigram model to resort the5-best results of the CG model.
We see thatwhile a language model improves results,using the better error model (Figure 1) stillgives significantly better results.
Using alanguage model with our best error modelgives a 73.6% error reduction compared tousing a language model with the CG errormodel.
Rescoring the 20-best output of theCG model instead of the 5-best onlyimproves the 1-best accuracy from 90.9% to91.0%.939495969798991001 2 3 4 5N-BestAccuracyNoLanguageModelTrigramLanguageModelFigure 1 Spelling CorrectionImprovement When Using a LanguageModel848688909294961 2 3 4 5N-BestAccuracyNoLanguageModelTrigramLanguageModelFigure 2 Using the CG Error Model witha Trigram Language ModelConclusionWe have presented a new error model fornoisy channel spelling correction based ongeneric string to string edits, and havedemonstrated that it results in a significantimprovement in performance compared toprevious approaches.
Without a languagemodel, our error model gives a 52%reduction in spelling correction error ratecompared to the weighted Damerau-Levenshtein distance technique of Churchand Gale.
With a language model, ourmodel gives a 74% reduction in error.One exciting future line of researchis to explore error models that adapt to anindividual or subpopulation.
With a rich setof edits, we hope highly accurateindividualized spell checking can soonbecome a reality.ReferencesChurch, K. and W. Gale (1991).
?Probability Scoringfor Spelling Correction.?
Statistics and Computing1: 93-103.Damerau, F. (1964).
?A technique for computerdetection and correction of spelling errors.
?Communications of the ACM 7(3): 659-664.Dempster, A., N. Laird, et al (1977).
?Maximumlikelihood from incomplete data via the EMalgorithm.?
Journal of the Royal Statistical Society39(1): 1-21.Golding, A. and D. Roth (1999).
?A Winnow-BasedApproach to Spelling Correction.?
MachineLearning 34: 107-130.Hall, P. and G. Dowling (1980).
?Approximate stringmatching.?
ACM Computing Surveys 12(4): 17-38.Jurafsky, D. and J. Martin (2000).
Speech andLanguage Processing, Prentice Hall.Kukich, K. (1992).
?Techniques for AutomaticallyCorrecting Words in Text.?
ACM ComputingSurveys 24(4): 377-439.Levenshtein, V. (1966).
?Binary codes capable ofcorrecting deletions, insertions and reversals.
?Soviet Physice -- Doklady 10: 707-710.Mayes, E., F. Damerau, et al (1991).
?Context BasedSpelling Correction.?
Information Processing andManagement 27(5): 517-522.Oflazer, K. (1994).
Spelling Correction inAgglutinative Languages.
Applied NaturalLanguage Processing, Stuttgart, Germany.Peterson, J.
(1986).
?A note on undetected typingerrors.?
Communications of the ACM 29(7): 633-637.Ristad, E. and P. Yianilos (1997).
Learning StringEdit Distance.
International Conference onMachine Learning, Morgan Kaufmann.Shannon, C. (1948).
?A mathematical theory ofcommunication.?
Bell System Technical Journal27(3): 379-423.Wagner, R. and M. Fisher (1974).
?The string tostring correction problem.?
JACM 21: 168-173.
