Responding Intelligently to UnparsableRalph M.  Weischede lJ ohn  E. B lack 2Inputs 1Depar tment  of Computer  and Information SciencesUniversity of De lawareNewark ,  De laware  19711All natural language systems are likely to receive inputs for which they are unprepared.The system must be able to respond to such inputs by explicitly indicating the reasons theinput could not be understood, so that the user will have precise information for trying torephrase the input.
If natural language communication to data bases, to expert consultantsystems, or to any other practical system is to be accepted by other than computer person-nel, this is an absolute necessity.This paper presents several ideas for dealing with parts of this broad problem.
One isthe use of presupposition to detect user assumptions.
The second is relaxation of testswhile parsing.
The third is a general technique for responding intelligently when no parsecan be found.
All of these ideas have been implemented and tested in one of two naturallanguage systems.
Some of the ideas are heuristics that might be employed by humans;others are engineering solutions for the problem of practical natural language systems.1.
IntroductionA truly natural language processing system doesnot have to have a perfect model of human languageuse, but it should have knowledge of whatever limita-tions its model has.
Then, for a user who has exceed-ed these limitations, the system can interactively aidthe user to rephrase the input in an acceptable way.This is a prerequisite to any practical application,whether it be natural language communicat ion to adata base, a medical consultation system, or an officeautomation system.
Users will not find such a systempractical unless it gives helpful feedback when thesystem fails to understand an input.As an example of how a user's input can exceed thesystem's model, we repeat an anecdote of Woods(1973b) about his system for answering natural lan-guage queries about lunar rock samples.
One questionasked was, "What is the average weight of all yoursamples?"
This overstepped the system's model in atleast three ways.1 This work was supported in part by the University of Dela-ware Research Foundation, Inc.2 Current address: W.L.
Gore & Associates, Inc., Newark,Delaware 19711.It surpassed the syntactic model, which did notprovide for a predeterminer such as "all" precedinganother determiner, such as "your" or "the".
There-fore, the sentence could not be parsed, even though"What is the average weight of all samples" or "Whatis the average weight of your samples" could havebeen.The semantic capabilities were also surpassed, be-cause semantic rules for translating "weight of" to afunctional representat ion had not been incorporated.Indeed, no data had been included for the weights ofthe samples.The third problem was that no semantic translationrules for possession were present.
The input violatedthe system's model of pragmatics, for the designershad not attr ibuted possession of the samples to themachine.This paper presents three ideas for giving usefulfeedback when a user exceeds the system's model.The ideas help to identify and explain the system'sproblem in processing an input in many cases, but donot perform the next step, which is suggesting how theuser might rephrase the input.These ideas have been tested in one of two sys-tems: (1) an intelligent utor for instruction in a for-eign language and (2) a system which computes theCopyright 1980 by the Association for Computational Linguistics.
Permission to copy without fee all or part of this material is grantedprovided that the copies are not made for direct commercial dvantage and the Journal reference and this copyright notice are included onthe first page.
To copy otherwise, or to republish, requires a fee and/or specific permission.0362-613X/80/020097-13501.00American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 97Ralph M. Weischedel and John E. Black Responding Intelligently to Unparsable Inputspresuppositions and entailments of a sentence.
Foreach idea presented in the paper, we will indicatewhether it pertains to systems in general or pertainsspecifically to the foreign language tutor system withits unique position of knowing more of the languagethan the user.In Section 2 of this paper we offer a way to recog-nize that an input exceeds the semantic model.
Ingeneral, the presuppositions or given information(defined later), of a user's input must be true in thesystem's model of context, for they represent factsthat must be shared among the participants of a dia-logue.
For each presupposition ot true in themachine's model, the system should print the falsepresupposition to identify an assumption that the usercannot make.Section 3 presents a technique for relaxing const-raints to accept sentences that would not parse other-wise.
Frequently one wonders whether the syntacticcomponent is responsible for much of the inability ofprevious systems to understand input partially, to iso-late parts not understood, and to interpret ill-formedinput.
A top-down, left-right parser essentially cannotproceed to material to the right of a constructionwhich the grammar is not prepared for.
Yet, such aparser should have much predictive ability about whatwas expected when the block occurred.
Section 4describes a collection of heuristics that capitalize onthe predictive abilities of a top-down, left-right parserto produce helpful messages when input is not under-stood.Finally, Section 5 discusses related work, and Sec-tion 6 presents our conclusions.2.
Using PresuppositionsSemantic information in a sentence is commonlydivided into two classes: given and new information.Given information, or presupposition, is that part of themeaning of a sentence which is presumed true in thecontext of a discourse.
New information is the assert-ed part.
For instance, "The defendant stopped beat-ing his wife", has as given information that there issome defendant presumed in the context and that thatperson had been beating his wife.
The new informa-tion is that the individual ceased that activity.Some presuppositions are associated with the use ofsyntactic constructs.
For instance, all noun phrasesmaking definite reference presume that there is a re-ferent in context.
All "wh" questions request newinformation corresponding to the value of a variableand presuppose the set of constraints on the value ofthe variable.
For instance, "Who is playing the tuba",presumes that someone is playing the tuba.The meaning of particular words is the source ofother examples.
The use of certain verbs, such as"describe", conveys presuppositions, or given informa-tion.
The question, "What books describe how Presi-dent Truman died", has a presupposition that Presi-dent Truman died.
Certain quantifying phrases carrygiven information, as in "Only project J1 receivesparts from New York companies", which presupposesthat project J1 receives parts from New York compa-nies.An analogy can be drawn between given informa-tion and preconditions or "input assertions" on a pro-cedure.
Given information for definite noun phrasescorresponds to predicates on the value of a variable.Given information from the meaning of predicatessuch as "describe" corresponds to assertions about thestate on entry of a procedure.
Therefore, given infor-mation includes preconditions on the execution of auser request.
Furthermore, such preconditions aredirectly traceable to particular phrases in that request.The psychological validity of given and new infor-mation has been demonstrated by Clark and Haviland(1977) and Haviland and Clark (1974).
The psycho-logical process they suggest is that (1) given and newinformation are first sorted in processing a sentence,(2) memory is then searched to establish that thegiven information holds in context, and (3) the newinformation is then asserted in memory.We have modelled this process in natural anguagesystems.
Research reported in Joshi and Weischedel(1977) and Weischedel (1979) demonstrated how toorganize an augmented transition etwork and lexiconto compute the given and new information of a sen-tence.In another system, we implemented the second ofthe three parts of the psychological process suggestedby Clark and Haviland.
That system was an intelligenttutor which pinpointed errors a student makes whileanswering questions in German during a reading com-prehension exercise (Weischedel, et.al., 1978).
A textpresented to English-speaking students in Germanprovides a relatively closed world for the tutor system,since questions refer to entities presented in the textand facts about them.
Therefore, these can be includ-ed as a detachable module of world knowledge specificto the particular text, along with any other worldknowledge that is applicable to the set of questions.
Itis still possible for the student o refer to knowledgenot contained in the model, but it is unlikely.
Thoughthe students have vast amounts of knowledge not inthe system model, they have insufficient vocabularyand syntactic forms to be able to express this knowl-edge initially.Thus, in the environment of foreign language in-struction, the system is in the unique position of hav-ing more vocabulary and syntactic forms than the userand, therefore, has more domain knowledge than the98 Amer ican Journal  of Computational Linguistics, Volume 6, Number  2, Apr i l - June 1980Ralph M. Weischedel and John E. Black Responding Intelligently to Unparsable Inputsuser can express.
Obviously most systems do not havethis property.Presuppositions were very effective in the Germantutor system, though they are a crucial semantic heckfor natural language systems in general.
Checkingpresuppositions against the world model of the Ger-man tutor provides recognition for several types oferrors.
First, given information of questions presentedby the system must be inferable from a student's an-swer; otherwise the answer is inappropriate for thequestion.
Consequently, the tutor diagnoses misunder-standing of a question by checking that the given in-formation of a question (which it knows independent-ly) is among the inferences of a student's answer.Only a very simple inference mechanism is used.Second, given information in the student's answeris checked against he world model.
If the given infor-mation does not exist in the system's knowledge base,the tutor finds one of two errors.
If the presupposi-tion is from a definite noun phrase, the tutor prints thenoun phrase and informs the student that it knows ofnothing that it could refer to.
If the presupposition isassociated with the semantics of a particular word, itassumes that this student, who is just learning German,has used the word incorrectly.
For instance, essenpresupposes that the one eating is human; fressen pres-upposes that the one eating is an animal.Given information is important for any question-answering system with natural language input.
Thesystem must check the presuppositions of the input inorder to guarantee that the user's assumptions are truein its world.
If any are not, the system can list pre-cisely the assumptions which are not true.These ideas were discussed first in Weischedel(1977) and in Weischedel, et.al.
(1978).
Kaplan(1977,1979) develops the ideas much further, specifi-cally for data base systems.
He postulates a hierarchyfor the presuppositions of an English query and hasimplemented strategies for guiding the user to newqueries when the data base would list the empty set inresponse to a query.Presupposition has received much attention in lin-guistics and philosophy; see for example Oh and Di-neen (1979), Karttunen (1973), and Karttunen andPeters (1975).3.
Two Mechanisms for Diagnosing Syntact ic FailuresWe assume that the purpose of a syntactic compo-nent is to translate from natural language input to aninternal semantic representation of the input.
Thisneed not be a completely syntactic process, but mayuse semantic omputations and contextual expectationsto guide the parsing/translating process.
Severalsources could prevent this process from finding atranslation of the input.
(We will refer to the inputcomponent as a "parser", though we do not presumethat a parse tree is ever explicitly computed.
)An important way that an input may fail to parse iswhen the user employs incorrect forms of the lan-guage.
If particular forms are anticipated, they maybe explicitly included in the syntactic model along withthe appropriate translation mechanism.
In the Germantutor mentioned in the previous section, there are se-veral examples of this.
For instance, English-speakingstudents frequently forget to put past participles at theend of a clause; e.g.
using "Ich habe gegessen dasFleisch" rather than the correct "Ich habe das Fleischgegessen," (I have eaten the meat).
The path in theaugmented transition net (ATN) corresponding to theincorrect form computes a message to tell students ofthe mistake, as well as computing the semantic repre-sentation of the answer for semantic analysis.
This isparticularly effective in the tutor system to catch in-stances of a student using English syntax patternsrather than German ones.In a similar way, any natural language processingsystem may include all anticipated forms and transla-tion rules for them whether or not they are strictlyproper for the language.Another way for a system to accept incorrect formsof language is suggested by observing a common styleof writing grammars.
Syntactic input components areoften designed using a context-free grammar whereeach grammar rule may be augmented by predicatesoperating on the semantic representations or on theconstituents linked by the grammar ule.
The predi-cates must be satisfied for the constituents to begrouped as a larger constituent.
(Of course, the gram-mar is no longer context-free then.)
Augmentedphrase structure grammars (Heidorn, 1975) encodeparsers and translators pecifically in this way.
Theaugmented transition network formalism also directlylends itself to writing parsers and translators in thisway by the predicates on arcs.
The version of system-ic grammar implemented by Winograd (1972) has thisflavor as well.
Still another example of this style ofwriting parsers is the linguistic string parser of Sager(1973) and Grishman (1973).A straightforward example of the use of such predi-cates is for subject-verb agreement.
It is easy for auser to make mistakes in long English sentences, re-suiting in parser failure.
A solution would be simplyto remove the predicate from the rule.
However,Grishman (1973) reports from their experience inprocessing scientific texts that the predicates effective-ly eliminate a large number of spurious parses.We suggest hat, instead of forcing all predicates tobe satisfied or ignoring the information inherent inthem, that the designer should designate that certainpredicates can be relaxed, with a record being kept ofeach predicate not satisfied during parsing.
Only pars-American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 99Ralph M. Weischedel and John E. Black Responding Intelligently to Unparsable Inputses yielding the fewest unsatisfied predicates are com-pleted.
Since the number of predicates that evaluateto false in a partial parse is a non-decreasing number,only those partial parses with the fewest unsatisfiedpredicates have to be continued.
Thus, the number ofspurious parses added should be small.
(Instead ofassuming that all failed predicates have equal weight,one could assign a partial order to them; but we havenot yet investigated this.
)This strategy was very effective in the Germantutor system.
Not only were several predicates al-lowed to fail, but also a procedural specialist was atta-ched to the appropriate arc of the ATN to compute aspecific error message and probable cause for thestudent's error.
Subject-verb agreement is one exam-ple.
Another is noun phrase declension, which is cru-cial to distinguishing "Das M~idchen gab dem Manneinen Hut" (the girl gave the man a hat) from "DemM~tdchen gab der Mann einen Hut" (the man gave thegirl a hat).The notion of allowing certain predicates to gounsatisfied is much more general than the highly spe-cial environment of the German tutor.
In the systemdescribed in the next section, several predicates weremade optional or "failable".
By "failable" we meanthat the predicates ought to be true for the pattern tomatch, but could be false without preventing the pat-tern from matching if there would be no parse with allsuch predicates true.
In addition to subject-verbagreement, pronominal case was also made failable.The two together allow a sentence such as "Me thinkhim win often" to be parsed, even though the parserhas a model of correct language.4.
Responses to Unparsab le  SentencesSome sentences will not be parsable even using themechanisms described in the previous section.
If oneuses an augmented transition network as a top-down,left-right parser, the arcs leaving a state where a parseis blocked offer a set of predictions or expectationsregarding what should occur next in the input string.These predictions include more than just the symbolsor constituents that were expected to follow; theyinclude the partial interpretation that was being fol-lowed.
In fact, this partial interpretation is potentiallyfar more informative than the symbols or constituentsthat were expected next.
(In the realm of program-ming languages, an Algol compiler that gives a syntaxerror message of "SEMI -COLON EXPECTED"  canbe quite frustrating since the cause of the problem canbe quite difficult to find.)
Thus, one of our majorgoals was to develop and test heuristics that wouldenable a natural language system to describe whatinterpretation it was following as an explanation ofwhy it expected specific items which were not present.Our approach is that the parser writer can assignmeaning to the states of a parser as it is being written,somewhat analogous to assigning meaning to programs(Floyd, 1967).
Floyd suggested postulating computa-tional states between the actions of a program andassociating predicates with these states to capture theintent of the computational state.
States are explicitlygiven in an ATN.
The designer's insight into themeaning of a particular state offers potentially awealth of information that can be presented to theuser about the interpretation being followed and whyit failed.
This may be of significant help in selectingan alternative way to express the input.The meaning of an ATN state may be specified byan ordered list of condition-action pairs, encoded asarbitrary LISP functions.
These  conditions and ac-tions may be functions of the current word in the in-put, the previous word in the input, any ATN registerhaving a value as of that state, any ATN register fromhigher levels in the graph, or the sequence of statestraversed.These condition-action pairs furnish a natural wayto distinguish among several interpretations or pathsthat are collapsed at a particular state.
The conditionsare used to unravel the collapsed paths by referring tothe ATN registers and input string.
The action for anygiven condition provides a flexible way of computingand printing messages the parser writer has chosen todescribe the interpretation being followed.In general, the effectiveness of this idea for gener-ating responses to unparsable sentences will depend onheuristics for determining the state at which the prob-lem in the input was encountered.
These ideas shouldbe very effective for natural language front ends toapplications uch as data base systems, expert consult-ant systems, and computer-assisted instruction sys-tems.The ideas do not  presume that the parser operatessequentially or prior to semantic or pragmatic ompo-nents.
The ideas would fit in equally well in a multi-processing environment where syntactic, semantic, andpragmatic components communicate asynchronously,such as GUS (Bobrow, et.al.
1977).
In a multipro-cessing system, one would have to write the condition-action pairs to use information and decisions from theother components.
The only assumption we havemade is that the parser is top-down, left-right, and iswritten in the formalism of the ATN.4.1 Se lect ing a State  f rom the Set  of Possible StatesIn essence, when a parse is blocked, one wants thepartial parse nearest o being complete.
We have cho-sen to select partial parses that have moved furthest inthe input string, or, in other words, those that matchthe longest initial string.
However, there may be se-veral paths and blocked states matching the longestinitial string.
Furthermore, the parse may have gone100 American Journal of Computational Linguistics, Volume 6.
Number 2, April-June 1980Ralph M. Weischedel  and John E. Black Responding Intel l igently to Unparsable Inputsseveral words beyond the point where the real problemoccurred.As a heuristic, states where a block has occurred areselected only i f  they are on a "longest path" matchingthe most input words.
The "length of a path" is de-fined to be the number of arcs traversed other thanPUSH or JUMP arcs with the universally (vacuously)true test, since those arcs make no test on the inputstring nor consume any part of it, (The pseudo-arcsPOP are counted.)
If there are still several states, onecan be selected nondeterministically.Given the state S selected by the heuristic above,there is a tree of states which are reachable from Susing only a string of PUSH or JUMP arcs with theuniversally true test.
S is the root of such a tree.
Themeaning of each of the states of the tree may often-times be summarized by the parser designer into onebrief description characterizing all of them as one con-ceptual unit (rather than a disjunction of descriptionsof each).
For states where this seems inappropriate, aspecial function (LOOKAHEAD)  can be added as anaction in the meaning of S to call the message generat-ing routine recursively for each state at distance onefrom S in the tree described above.
Using these twoideas we found that selecting the root S for its mean-ing, while ignoring its descendants, proved satisfactoryin our tests.The heuristic for selecting one partial parse andone state along a path for it was implemented in aparticular parser, to be described in section 4.2.
Wetested these ideas by constructing for each state anunparsable input such that the heuristic would selectthat s tate .
Some states either could not be a blockingpoint or could be one only by a non-English input,such as, " John forced Mary not."
After eliminatingsuch states, we tested the heuristic on one sentence foreach remaining state.For an input that does not parse, there is somemaximal initial input string consumed by any of thepartial parse paths.
Consider the set of states on thepartial parse paths such that at each such state themaximal input string has been parsed in reaching thatstate.
(The set can be more than a singleton even ifthere is only one path, since PUSH, JUMP, and POParcs do not consume input symbols.)
For the 39 ex-ample sentences, the average number of states in thatset was four.To measure the effectiveness of employing theheuristic of using only states at the end of a "longest"path (where JUMP and PUSH arcs with a universallytrue test are not counted in the length of the path), wecounted the number of " longest" paths for each exam-ple.
In 34 of the 39 test cases, this heuristic yieldedonly one state.
In each of the five remaining cases,two states were left as the last state of a longest path.As mentioned earlier, when more than one state isleft after selecting only states at the end of a longestpath, one can be selected nondeterministically.
Inthree of the five test cases where nondeterminism wasused, the two states would have produced essentiallythe same message, and therefore using both stateswould have added no insight.Thus, in our test the heuristic seemed very effec-tive.
Of course, the effectiveness of the heuristic de-pends in large part on the style in which the parser iswritten.
We describe the parser next.4.2 The  Parser  on wh ich  the  Ideas  were  TestedWe tested these ideas on a parser written in 1975as part of a Ph.D. thesis (Weischedel, 1975).
Thepurpose of the parser was to demonstrate how to com-pute two special classes of inferences, presuppositionsand entai lments of English sentences, by using anATN and a lexicon.
Because of its special purpose,the system included many constructions and lexicalitems of interest for their presuppositional or entail-ment content.
For the same reason, many frequentlyoccurring constructions of English were not imple-mented, e.g.
conjunction reduction, reduced relativeclauses, several consecutive prepositional phrases, andadverbials.A subset of constructions were selected f rom thelinguistic analysis of Anderson (1970), which was abasis of defining the lexical classes of the LinguisticString Parser, described in Sager (1973) and Grishman(1973).
Anderson's analysis defined lexical classes bythe left contexts (subject) in which a predicate (verbor noun) could occur, the right contexts (object) inwhich a predicate could occur, and the transformationswhich could act upon these strings of subject, predi-cate and object.
(Note, in this section the word"predicate" refers to part of an English clause, not aboolean test as in Section 3.)
Such strings define theparsable sentential forms; the transformations actingupon the strings give further forms.
Of course, ourATN parser encoded all surface forms in the graphs.explicitly.
The actions on the ATN arcs had the effectof inverting the transformations given by Andersonwhile moving along an ATN path matching the surfaceform.Conditions on the arcs were very significant in thestyle of our parser.
For instance, a condition beforePOPping from the sentential level checks whether theleft and right contexts matched for the word or predi-cate X form a string in the linguistic model of Ander-son (1970).In the lexical entries each semantic representationfor a word was associated with corresponding lexicalclasses.
Finding the semantic representation of a sen-tence, therefore, required determining lexical classesfor each of the words.American Journal of Computational Linguistics, Volume 6, Number 2, Apri l - June 1980 101Ralph M. Weischedel and John E. Black Responding Intelligently to Unparsable InputsThe arc condition which checks whether a predicateX occurred in appropriate right and left contexts wasnot one of the ones we declared to be "fai lable", be-cause this condition was necessary and sufficient fordetermining associated semantic representations.When the condition was not satisfied, the parser didnot have in its lexicon a semantic representation forthe word X. Consequently, the condition offered avery tight constraint for ascertaining when the parserhad no semantic representat ion corresponding to aninterpretation.
Maintaining such tight control overwhat the system could and could not translate is some-what akin in philosophy to using strongly typed pro-gramming languages with much error checking.
Peopledo not seem to have such a style in using natural lan-guages; however, it might be a useful engineering prin-ciple for natural language systems where accuracy ofunderstanding is crucial.Another consciously applied strategy in designingthe parser was to separate into distinct paths manystrings which conceivably could have been merged.The criterion for making a distinct path was whether astring which was syntactically differentiable also had adistinct semantic representation.
For instance, cleftsentences ,  such as " I t  was Mary who won",  couldhave been incorporated by simply listing left and rightcontexts for "be" in the lexicon.
However,  the syn-tactic form has distinct meaning, namely in the exam-pie, the presupposition that "Someone won."
There-fore, the parser has a special path for cleft sentences.This aspect of style yielded several relatively longpaths with little branching.
For such paths, the mes-sages for a blocked parse can pinpoint the interpreta-tion that was being followed and what was expectednext.
Examples of this are provided in section 4.3.One of the major advantages of testing our ideason this parser was the fact that there were many waysin which a sentence could fail to parse.
The parserwas already available, but more important for the as-signing of meaning to its states, its designer was readi-ly available.
A further reason for selecting this parserwas that it did cover a wide range of constructions andwas not a toy grammar.In general, we specifically avoided enhancing thegrammar to remove limitations.
We wanted a fullrange of tests and example problems to exercise ourideas as thoroughly as possible.
However,  simple bugssuch as erroneous omissions in lexical entries or typo-graphical errors were corrected as they were detected.Also, we did add one action to most arcs to save sur-face phrases as they were found, for more helpfulresponses to the user.The major drawback in selecting this parser forexperimentation is its original purpose.
Although itspurpose is very precise, it did not have a natural taskdomain.
Without a task, it seems impossible to makesome significant tests, such as giving naive users aspecific goal in the domain, then measuring how manytrials they require to achieve the goal in the restrictednatural language.4.3 Examples and AnalysesIn this section, we have organized example states,messages, and analyses around several themes; each ofthe following subsections comprises one theme.
Allgraphs here are much simplified recursive transitionnet approximations of the actual graphs in Weischedel(1979).
A double circle indicates a pop arc.
Lowercase indicates terminals; upper case indicates nonter-minals.4.3.1 Appropr iate Phrasing for Naive UsersThough the parser writer may know precisely whatinterpretation was being followed and what caused itto block at a given state, it is very challenging tophrase that knowledge in a way helpful to the user.This is a problem common to all natural language sys-tems, but the degree of the problem varies with theapplication of the system and with the style of thegrammar.
For instance, in the environment of an in-telligent tutor for computer-assisted language instruc-tion, the user is learning or has learned many informalgrammatical  concepts of the language (though thesemay not directly correspond to the formal ones imple-mented in the parser).
Consequently, the parser writ-er in creating response messages as part of thecondition-action pairs can use these concepts to pin-point for the user the reason the parser blocked.
Inother applications, the user might have few, if any,concepts of grammar.Since our tests were conducted on the English par-ser for generating presuppositions and entailments, theresponse messages were aimed at general users havingonly a few informal concepts of language, such assentence, subject, verb, and object.
In addition, theresponses often include examples with a similar struc-ture, rather than using technical terms.
For instance,suppose that the phrase "It  was the'class ..." was be-ing interpreted as a cleft sentence when it wasblocked.
The system prints that the input was beinginterpreted in the same way as a sentence such as "Itis John who left," rather than calling it a cleft sen-tence.The style of the particular parser also has a signifi-cant effect on the ability to phrase the reason for aparsing failure.
For instance, if one uses a "semanticgrammar"  (Burton, 1976 and Brown and Burton,1975) the parser writer can use the concepts of thedomain encoded in the grammar as a powerful descrip-tion of the interpretation being followed and of thecause of a blocked parse.
In INLAND (Hendrix,et.al., 1978), one can see how effective the domainconcepts encoded in the .semantic grammar can be in102 American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980Ralph M. Weischedel and John E. Black Responding Intelligently to Unpsrsable Inputs!I t // t /1,%or SFigure 1.
Paths involving state 02.responding to the user.
One class of response mes-sages in INLAND is a list of the elements that couldhave occurred next when the parse blocked.
Eventhough this list does not indicate the interpretationbeing followed, the semantic concepts of the domainwhich could occur next (e.g.
ship) are more meaning-ful to the user than such a list for a general-purposegrammar would be (e.g.
noun phrase).In effect, then, we tested the idea of using themeanings of states to generate responses on the hard-est case, where the parser is general and the users arecompletely naive about even informal grammaticalconcepts.
The remainder of this subsection describesthe problems we encountered, by examples.State 02 of Figure 1 exemplifies a very frustratingaspect of devising appropriate descriptions.
02 is partof the subgraph that recognizes right contexts(objects) of predicates.
The meaning of the nontermi-nals is as follows."
NP, a noun phrase; NPS, a posses-sive form of a noun phrase; S, a declarative sentence;WH-S, a wh-question; P, a preposition; V+ing, averb's present participle; and V+en,  a verb's pastparticiple.
Though there are four different possiblereasons for a parse to block at 02, each of which israther reliably recognized by a simple condition, themessages describing the problem are not precise.Four condition-action pairs represent he meaningassigned to 02.
The first checks for the input stringbeing empty.
If it is, the lexical entry for the predi-cate does not include the appropriate right contextbeing matched, and therefore has no translation for it.Though the problem is pinpointed, describing it to theuser is not easy; examples of uses that the system canunderstand seem to be the most helpful for this.
Ex-ample 1 demonstrates the message.
Each lexical itemcorresponding to a predicate has a list of sentences,one for each implemented left-right context pair; theexamples are stored on disk files and read only if re-quested.Examp~ 1:THE PROFESSOR PREVENTED A DULL  LECTURE /.NO PARSESTHE PROFESSOR PREVENTED A DULL  LECTURESTUCK AT THE END OF THE SENTENCESUBJECT UNDERSTOOD TO BE: 'THE PROFESSOR'VERB UNDERSTOOD TO BE: 'PREVENTED'THE WORD 'PREVENTED'  IS BE ING USED IN AWAY UNKNOWN TO THIS  SYSTEM.WOULD YOU L IKE EXAMPLES ?
*YESEXAMPLES FOR THE USAGE OF 'PREVENTED''THAT THE STUDENTS DID NOT ATTEND THELECTURE PREVENTED THE PROFESSORFROM ASS IGNING THE TEXT /.''
JOHN PREVENTED MARY FROM ATTENDING THELECTURE /.''
JOHN WAS PREVENTED FROM LEAVING BYMARY/ . ''
JOHN WAS PREVENTED FROM TRANSLAT ING THEASS IGNMENT BY ME /.
'A second condition-action pair associated with 02is apparently never used, because the parse can alwayscontinue beyond state 02.
This pair checks two condi-tions: whether the current input symbol is "that" andwhether two noun phrases form an appropriate rightAmerican Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 .
103Ralph M. Weischedel and John E. Black Responding Intelligently to Unparsable Inputscontext for the predicate found.
In this case the par-ser should have interpreted "that" as being used refer-entially.
However,  we had not included its referentialsense in the lexicon.
The message associated with thepair would pinpoint the problem were this the finalstate of a longest parse.
In one instance, the parsercan go one arc farther by pushing for a noun phraseand verifying that the predicate allows such a rightcontext.
Example 2 is such an instance.Examp& 2:I WILL  G IVE  DR SMITH THAT /.NO PARSESI WILL  G IVE  DR SMITHSTUCK AT THE WORD 'THAT'LOOKING FOR A NOUN PHRASE,  BUT THE WORD'THAT' CANNOT BE USED AS A PRONOUNIN THIS SYSTEM TO REFER TO SOMETHINGFar more likely circumstances are that the parsercan continue by interpreting "that"  as the beginningof a relative clause modifying the noun phrasematched in reaching state 02.
The meaning of the laststate in that case does not pinpoint the problem, but atleast it does explain the interpretation being followed,as demonstrated in Example 3.Examp~ 3:I ASS IGNED THE STUDENT THAT /.NO PARSESI ASS IGNED THE STUDENT THATSTUCK AT THE END OF THE SENTENCEINTERPRET ING 'THAT' AS THE BEGINNING OF ARELAT IVE  CLAUSE,  SUCH AS THE FOLLOWINGRELAT IVE  CLAUSES MODIFY ING 'THESTUDENT' :  'THE STUDENT THAT WON,'  'THESTUDENT WHICH WON,'  OR 'THE STUDENT WHOWON / .AT PRESENT,  THE SYSTEM DOES NOT UNDERSTAND'THAT' USED ALONE AS IN 'I KNOW THAT'THIS  ERROR OCCURRED WHILE  THE SYSTEM WASWORKING ON WHAT IT INTERPRETED TO BE ASENTENCE EMBEDDED WITHIN  THE MAINSENTENCE.
THE SYSTEM'S  INTERPRETAT IONOF THE WAY IT EXPECTED THAT EMBEDDEDSENTENCE TO F IT  INTO THE COMPLETESENTENCE WAS:SUBJECT UNDERSTOOD TO BE: 'I'VERB UNDERSTOOD TO BE: 'ASSIGNED'LOOKING FOR AN APPROPRIATE  OBJECT FOR'ASSIGNED'In Example 3, the parser has gone one word be-yond the real difficulty in the input.
The problem ofgoing beyond where the real block occurred is moreapparent han real for state 02, however.
If we hadnot decided a priori that for the purposes of testingour ideas we would not add to the parser or lexicon,we would have simply added the referential sense of"that" to the lexicon.A third condit ion-action pair associated with 02deals with an error in a design decision made whenfirst building the parser.
In Anderson (1970), thelexical analysis cites many predicates whose right con-texts include prepositions pecific to a particular predi-cate.
For instance, "tell" has right contexts specifical-ly allowing "of"  or "about" .
Paths leaving 02 uponfinding a preposit ion require that it specifically belisted in the lexical entry of the predicate.
However,in 1975 we made the erroneous assumption that onlyone preposition would be listed per predicate.
Thecondition-action pair checks whether this could be theproblem; unfortunately,  describing the problem to anaive user is itself a problem.
As Example 4 indicates,the best descr ipt ion'we could think of is the same asfor the first condition-action pair of 02 (Example 1).Examp~ 4:A PROFESSOR PRESSURED THE STUDENT ABOUTLEAVING /.NO PARSESA PROFESSOR PRESSURED THE STUDENTSTUCK AT THE WORD 'ABOUT'SUBJECT UNDERSTOOD TO BE: 'A PROFESSOR'VERB UNDERSTOOD TO BE: 'PRESSURED'THE WORD 'PRESSURED'  IS BE ING USED IN AWAY UNKNOWN TO THIS  SYSTEM.WOULD YOU L IKE  EXAMPLES ?
*YES' JOHN WAS PRESSURED INTO LEAVING /.
''THE PROFESSOR PRESSURED THE STUDENTSINTO STUDYING THE TEXT /.
'02 has one more condit ion-act ion pair which isused if no other pair applies.
There are two possiblecauses in this case: the predicate's lexical entry mightnot include the right context present in the sentence orthe NP that was just matched could have prepositionalphrases modifying it.
The message is essentially thesame as that in Example 1.
The cause, like the mes-sage, is not precise in this case.State 02 illustrates that even though the designermay assign condit ion-action pairs that pinpoint thecause for a sentence not being parsed, descriptions ofthe cause may not be as precise or helpful to a naiveuser.
Thus, the messages can be less helpful than onewould have hoped.104 American Journal of Computational Linguistics, Volume 6, Number 2, Apri l- June 1980not~% %, ?
"% ? "
' ~ WRalph M. Weischedel and John E. Black Responding Intelligently to Unparsable InputsFigure 2.
The path containing $9.4.3.2 The Precision PossibleIn spite of the problem illustrated in the last sec-tion, much precision is possible in messages to theuser.
For example, state S17, which appears in thefull diagrams of Weischedel (1979), is on the path forrecognizing a subset of the cleft sentences.
The paththat it is on is an example of many paths that are verylong, with little branching, and that correspond to aparticular interpretation.
(This is a characteristic ofthe style of the parser.)
At S17, the word "it", astring of tense and modal elements ending in a form of"be",  and a noun phrase have been matched.
Theonly arc leaving S17 matches a relative clause..
If ablock occurs here, either the input was not a completecleft sentence, or the relative clause began in an un-parsable way.
The message printed appears as Exam-ple 5.
The portion of the message describing relativeclause restrictions was generated from the condition-action pairs of a different state; that state's pairs wereinvolved because S17's pair explicitly called the LOO-KAHEAD function after printing the first part of themessage.Examp& 5:WAS IT JOHN ?NO PARSESWAS IT JOHNSTUCK AT THE END OF THE SENTENCEINTERPRET ING 'WAS IT JOHN' AS INSENTENCES OF THE FORM: 'WAS ITJOHN THAT WAS DULL.
'EXPECTED A RELAT IVE  CLAUSE.
EXAMPLESOF RELAT IVE  CLAUSES ARE: 'WHICHTHE STUDENT SELECTED'  OR 'THAT THEPROFESSOR TOOK' .
THIS SYSTEMEXPECTS RELAT IVE  CLAUSES TO BEGINWITH 'WHO', 'WHOM', 'WHICH',  OR'THAT'Another example of the kind of precision possiblecomes from one of the messages of $9, shown in Fig-ure 2.
LSUBJ matches left contexts of a predicate; inthis case the left context is the surface subject of theverb.
TENSE(be)  will match any tensed elementsending in a form of "be".
V+en represents a pastparticiple of a verb.
POBJ looks for the right contextof the verb, thus matching right contexts from whichthe surface subject was syntactically moved.
By thetime $9 has been reached, the system is interpretingthe input as a passive sentence.The first condition-action pair associated with $9checks whether the past participle found is in a partic-ular lexical subcategory, because passives of that sub-category are treated in a special manner.
The arcs forthe special case were not implemented.
The printedmessage appears in Example 6 and corresponds exactlyto the omission in the grammar.Examp~ 6:I WAS D ISAPPOINTED THAT THE LECTURE ISCROWDED /.NO PARSESI WAS D ISAPPOINTEDSTUCK AT THE WORD 'THAT'CURRENT SYSTEM CANNOT HANDLE PASS IVESENTENCES INVOLVING 'D ISAPPOINTED' .A second condition-action pair for $9 always printsa message if the first one did not apply.
This clausecorresponds to a general reason for blocking at $9:none of the expected right contexts for the verb couldbe found.
This could arise if the lexical entry did notlist the necessary right context and therefore had notranslation for this case.
It could also arise in a sen-tence such as "That I won was told immediately toMary."
(Recall that we simply did not include adverbi-al adjuncts in the parser.)
Just as the cause is not veryprecise for this instance, the message given in Example7 cannot be either.
The example sentences given asoutput do parse.
The input does not parse because thelexical entry simply did not include a noun phrase asone of its right contexts.American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 105Ralph M. Weischedel and John E. Black Responding Intelligently to Unparsable InputsExamp~ 7:ABE WAS BEL IEVED BY MARY /.NO PARSESABE WAS BEL IEVEDSTUCK AT THE WORD 'BY'SUBJECT UNDERSTOOD TO BE: 'ABE'VERB UNDERSTOOD TO BE: 'WAS BEL IEVED'IN GENERAL,  PHRASES INDICAT ING TIME,PLACE,  OR MANNER ARE NOT ALLOWED.ALTERNATELY ,  YOU MAY HAVE USED THEVERB 'BELIEVED'  IN AN UNKNOWN WAY.WOULD YOU L IKE  EXAMPLES ?
*YESEXAMPLES FOR THE USAGE OF 'BELIEVED'' JOHN BEL IEVED THAT I LEFT  /.
''I BEL IEVED JOHN ATTENDED THELECTURE /.''
JOHN BEL IEVED IN THE PROFESSOR'STEACHING THE COURSE /.
''I BEL IEVED IN JOHN'S  HAVING TAKENTHE TEXT /.
''MARY BEL IEVED IN JOHN'S  TRANSLAT INGOF THE ASS IGNMENT /.
''THAT MARY LEFT  WAS BEL IEVED BY THESTUDENTS /.
'Using states S17 and $9 along with the correspond-ing Examples 5 and 6, we have demonstrated that themessages can sometimes pinpoint the cause of a pars-ing failure.
There are many other states whosecondition-action pairs yield a precise diagnosis for thecause of a parsing failure.4.3.3 Embedded SentencesFor sentences with embeddings, merely to giveinformation based on the last state of the longest pathseems intuitively insufficient, for explanation of thehigher levels of the sentence may be ignored if themessage is based solely on the last state at an embed-ded level.
Consequently, the system prints messagesfor each incomplete sentential level represented in thepartial parse.
First, the message from the last state isprinted.
Then, starting at the highest level, an expla-natory message is printed for each incomplete senten-tial level.These messages are printed using the same ideas asdescribed for the last state on the longest path.
Thecriterion for selecting states is simple.
The parser'sstack contains all the states with an exiting PUSH arcthat has been started but remains unfinished.
Of thestates in that stack, only the ones corresponding to asentential level are relevant; these begin with an "S"or an "I" in our graph.
The set of condition-actionpairs for these states was written assuming this wasthe last state on the longest path.
Consequently, wewrote a second, smaller set of condition-action pairsespecially assuming that partially parsed embeddedsentences follow this state.Example 8 illustrates messages for embedded sen-tences.
The output beginning with "This error occur-red while ..." is the start of messages from higher lev-el, partially parsed sentences.
The useful hint at thetrue problem in parsing Example 8 comes from one ofthe states in the system's stack; the right context nec-essary to parse Example 8 has not been defined.Examp~ 8:DID MARY ASK DR SMITH IF I ATTENDEDTHE LECTURE ?NO PARSESDID MARY ASK DR SMITH IF I ATTENDEDTHE LECTURESTUCK AT THE END OF THE SENTENCEEXPECTED '/,' TO SEPARATE 'IF IATTENDED THE LECTURE'  FROMA QUEST ION WHICH IS EXPECTEDTO FOLLOW THE '/,' YOURINPUT BEGAN WITH AN 'IF' CLAUSE.IF THAT CLAUSE WAS NOT FULLYPROCESSED,  THERE ARE SEVERALPOSSIBLE  REASONS:I) ADVERBIAL  MATERIAL  TELL ING HOW,WHEN, OR WHERE CANNOT BEPROCESSED2) NO PREPOSIT IONAL PHRASES CANMODIFY  A NOUN (IN THIS  SYSTEM).THIS  ERROR OCCURRED WHILE  THE SYSTEM WASWORKING ON WHAT IT INTERPRETED TOBE A SENTENCE EMBEDDED WITHIN  THEMAIN SENTENCE.
THE SYSTEM'SINTERPRETAT ION OF THE WAY ITEXPECTED THAT EMBEDDED SENTENCE TOF IT  INTO THE COMPLETE SENTENCE WAS:SUBJECT UNDERSTOOD TO BE: 'MARY'VERB UNDERSTOOD TO BE: 'DID ASK'LOOKING FOR AN APPROPRIATE  OBJECT FOR'ASK'.4.3.4 Test ing the Longest Path Heurist icA serious difficulty in using the longest path as aheuristic for generating responses is that the parsermay be able to continue further in the input thanwhere the real parsing problem occurred.
To examinehow well the longest path heuristic performs in locat-ing the true cause of the problem, we analyzed the 39sentences described in section 4.1.
In only three ofthe 39 cases did the parser continue beyond the pointwhere the true problem occurred.
Contrasted withthis success rate, Woods (personal communication,1977) reported that in LUNAR,  the parser very oftenwas able to continue beyond the point of the problemin the input before becoming blocked.106 American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980Ralph M. Weischedel and John E. Black Responding Intelligently to Unparsable InputsThere are several factors that affect the success ofthe longest path heuristic.
One is the extent of thegrammar; the fact that adverbial adjuncts, reducedrelative clauses, and multiple, consecutive prepositionalphrases are not present in the grammar we tested un-doubtedly contributed to the high success rate.
There-fore, the heuristic should be very effective in appliednatural anguage interfaces that are constrained.Second, the style of grammar can affect the successof the heuristic.
For instance, our grammar immedi-ately upon finding the main predicate (e.g.
verb) of aclause requires that its syntactic expectations for rightcontexts of that particular main predicate be satisfiedat each step through the remainder of the string con-taining a right context.
Also, as near as possible, se-mantically different senses were usually separated intodistinct paths, even though they might have been col-lapsed into one.Third, applying semantic constraints and expecta-tions while parsing should also contribute to the effec-tiveness of the longest path heuristics, just as the syn-tactic constraints and expectations do.
The additionalconstraints will inhibit the parser from continuing be-yond a problem in the input by preventing it fromprocessing a phrase with the expected syntactic formbut which is unacceptable semantically.
For instance,suppose the actual right context of a predicate (e.g.verb) starts with a noun phrase, but the lexicon listsno right contexts for the predicate that begin with anoun phrase.
A parser might be able to continue byinterpreting the noun phrase as an adverbial adjunctspecifying a time, such as "last night."
If the parserinteracts with a semantic omponent requiring that thenoun phrase be interpretable as a time specification,the parser could not go on by interpreting the nounphrase erroneously.
Since our grammar does not inter-act with a semantic component, we are interested intesting the longest path heuristic in RUS (Bobrow,1978), a grammar which does interact closely withsemantics.4.3.5 Further Observat ionsA natural criterion for evaluating this strategy forunparsable sentences is the cost, both in processingand programming development.
In processing, verylittle is added.
Clearly, a small fraction of the parsingtime and memory usage is added to record the longestpath and to generate messages for the last state on it(and possibly one state per incomplete sentential lev-el).
However, it is easy to see that this is a minutefraction compared to the time and memory in search-ing for a parse.On the other hand, significant additional effort isrequired of the programmer to devise condition-actionpairs for each state.
However, spending that time hasbenefits in addition to the response ability added tothe system.
Analyzing the parser to develop themeaning of each state clarifies the programmer's un-derstanding of the system.
Furthermore, it serves assignificant documentation, since it describes the intentof the programmer at each point.For our graph having approximately 110 states, theaverage number of condition-action pairs per state was1.4.
The code for these pairs amounted to approxi-mately one page of a listing for the conditions andapproximately nine pages for the constant characterstrings used in generating the (rather long) printedmessages.
Therefore, it is clear that the condition-action pairs do not require a lot of programming, butdo require a better understanding and description ofthe parser.5.
Related WorkSeveral other projects have concentrated on givingmeaningful responses to partially understood input andof correcting erroneous assumptions.Kaplan (1977,1978,1979) reports on researchwhich extends the notion of presupposition.
Further-more, he has developed algorithms for computing theextended notion called presumption, particularly takingadvantage of the simplifying aspects of natural lan-guage queries of a data base.
The algorithms givehelpful responses to data base users when the query asstated would have the empty set as a response.
Mays(1980) deals with presumptions related to users' per-ceptions of the logical structure of a data base.Codd, et.al.
(1978) describes the first version of asystem called RENDEZVOUS, specifically addressingthe same problems as our paper, but proposing verydifferent approaches.
Unlike the ideas presented here,RENDEZVOUS is aimed only at interfaces to relation-al data bases.
It provides many interesting humanengineering features for clarification dialogue, even toa menu-driven specification of a formal query whennatural anguage queries prove unsatisfactory.Some very promising work which is complementaryto ours is reported in Hendrix, et.al.
(1978) and Hen-drix (1977).
They report on a new software tool LI-FER, which enables rapid development of semanticgrammars (Burton, 1976 and Brown and Burton,1975).
L IFER provides some error messages for un-parsable forms by printing the possible items thatcould appear at the point where the parser could notproceed.
Their heuristic for selecting one place wherethe block occurred is similar to ours.
Combining thefollowing additional features of L IFER with our workcould offer a powerful natural language interface.
LI-FER allows naive users the ability to add synonymsfor previously known words and to define new syntac-tic forms for sentences by the user presenting a sen-tence in the new form and an equivalent sentencewhich is already parsable.
It also provides an auto-matic facility for handling ellipsis.Kwasny and Sondheimer (1979) have extended ournotion of selectively relaxing predicates to deal withAmerican Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 107Ralph M. Weischedel and John E. Black Responding Intelligently to Unparsabla Inputsco-occurrence violations and relaxation of expectedword categories.
Their paper also reports a uniformway of treating ellipsis and conjunction, includinggapping.Allen (1979) argues that good clarification dialoguerequires that the system have a model of the plan theuser is following and of how the sequence of speechacts by the user fits into that plan.
We agree, and oneof our long-term goals is use of a model of user goals,plans, and speech acts for this purpose.
Other compu-tational models of speech acts appear in Cohen andPerrault (1979), Levin and Moore (1978), and Mann(1979).Pattern-matching as an alternative to a top-down,left-to-right parser, has often been suggested as ameans of processing ill-formed input, as discussed inKwasny and Sondheimer (1979), for example.
Hayesand Reddy (1979) also advocate pattern-matching as apart of an approach that they are implementing tocover the broad spectrum of problems in graceful in-teraction, including anaphora resolution, explanationfacilities, flexible parsing, generating descriptions ofentities in context, monitoring focus, and robust com-munication.6.
Conc lus ionsWe have drawn eight conclusions from our experi-ence with the two systems on which our heuristicswere tested.
First, computing the presuppositions, orgiven information, of user input provides a means fordetecting some of the user's assumptions inherent inthe input.
These may be checked against worldknowledge in the system to recognize discrepanciesbetween the user's model and the system's world mod-el and to point out an incorrect assumption to theuser.Second, an effective strategy for increasing therobustness of a parser is to allow relaxation of predi-cates (on ATN arcs) that the parser designer desig-nates as relaxable, or "failable."
The system will pref-er parses where no such predicates are false.
If noparse can be found with all predicates true, the systemwill relax the predicates designated as failable, and willsearch for a parse with the fewest failable predicatesfalse.The remaining conclusions regard our technique ofassigning meanings to states as a means of generatingresponses when no parse can be found.
The thirdconclusion is that the meanings of states, used with thelongest path heuristic, can often pinpoint the cause ofan input not parsing.Fourth, though the cause of the input not parsingcan often be pinpointed with the technique, describingthe cause to the user may be quite difficult because ofthe technical nature of the problem in the input.Fifth, the effectiveness of the longest path heuristicin correctly selecting the state corresponding to theactual problem in processing the input depends on thestyle of the grammar and the extent of the subset oflanguage covered.
The more constrained the languageused in the application domain, the less possibility forthe parser continuing beyond the point of the problem.Alternatively, the more syntactic and semantic const-raints used as expectations by the parser, the greaterthe likelihood that the problem in the input will cor-rectly correspond to a violated expectation, since vio-lated expectations will help prevent the parser fromgoing beyond the point of the problem.
This does notconflict with the notion of relaxing predicates, sincethe longest path heuristic is used only after no parsecan be found even after relaxing predicates.
In ourgrammar, the longest path heuristic selected the cor-rect state in over 90% of the test cases.Sixth, based on the two previous conclusions, theheuristic of responding using the meaning of states willbe most effective in semantic grammars or in parsersthat interact closely with semantic processes.Seventh, the longest path heuristic adds only a smallfraction to the computing time and memory usageduring parsing.
Furthermore, adding the condition-action pairs to represent he meaning of states doesnot require a lot of programming, but does require abetter understanding of the parser.Eighth and last, the technique of assigning meaningto states is applicable to explaining compile-time rrorsin programming languages as well.We also suggest four areas for further work.
First,the heuristics should be tested in a parser that inter-acts closely with semantics while parsing.
The purposefor that is twofold: (1) to more effectively respondto the user by paraphrasing the partial interpretationand semantic expectations when the input is unparsa-ble and (2) to test further the effectiveness of thelongest path heuristic.
Second, the user's goals andintent are critical constraints which we have not incor-porated in any of our heuristics.
The aforementionedwork on computational models of speech acts anddialogue games provide a starting point for this.
Athird area is to combine the ideas presented here withthe heuristics in L IFER (Hendrix, et.al., 1978); thecombination could provide a very user-oriented, flexi-ble interface.
Fourth, the effectiveness of our techni-que for responding to unparsable sentences hould beexamined in the domain of programming languagecompilers, because the user of a compiler knows manytechnical terms which the parser writer can employ inmessages to convey effectively the cause of a blockedparse.AcknowledgementsThe authors gratefully acknowledge the many valu-able contributions of the referees and George Heidornto improving the exposition.
Norm Sondheimer alsocontributed much in many discussions of our ideas.108 American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980Ralph M. Weischedel and John E. Black Responding Intelligently to Unparsable InputsReferencesAllen, James F., "A Plan-Based Approach to Speech Act Recogni-tion," Ph.D. Thesis, Dept.
of Computer Science, University ofToronto, Toronto, Canada, 1979.Anderson, Barbara B., "TransformationaUy Based English Stringsand their Word Subclasses," String Program Reports No.
7,Linguistic String Program, New York University, New York,NY 1970.Bobrow, D. G., R. M. Kaplan, M. Kay, D. A. Norman, H. Thomp-son, and T. Winograd, "GUS, A Frame Driven Dialog System,"Artificial Intelligence 8, 2, 1977.Bobrow, Robert J., "The RUS System," in B. L. Webber and R.Bobrow, Research in Natural Language Understanding, BBNReport 3878, Bolt Beranek and Newman Inc., Cambridge, MA,1978.Brown, J. S. and R. R. Burton, "Multiple Representations ofKnowledge for Tutorial Reasoning."
In D. G. Bobrow and A.Collins, Eds., Representation and Understanding, New York:Academic Press, 1975.Burton, R. R., "Semantic Grammar: An Engineering Technique forConstruction of Natural Language Understanding Systems.
"BBN Report 3453, Bolt, Beranek, and Newman, Cambridge,Mass.
Also, Ph.D. Dissertation, University of California,Irvine, CA, 1976.Clark, Herbert H. and Susan E. Haviland, "Comprehension a d theGiven-New Contract.
~ In R. Freedle, Ed., Discourse Processes:Advances in Research and Theory, Vol.
1.
Discourse Productionand Comprehension.
Norwood, N J: Ablex Publishing Corpora-tion, 1977.Codd, E. F., R. S. Arnold, J. M. Cadiou, C. L. Chang, N. Rousso-poulos, "RENDEZVOUS Version 1: An Experimental English-Language Query Formulation System for Casual Users of Rela-tional Data Bases," Research Report RJ2144 (29407), IBMResearch Laboratory, San Jose, CA, 1978.Cohen, Philip R. and C. Raymond Perrault, "Elements of a Plan-Based Theory of Speech Acts," Cognitive Science 3, 3, 1979.Floyd, R. W., "Assigning Meanings to Programs," Proc.
of a Sympo-sium in Applied Mathematics, Vol.
19.
American MathematicalSociety, 1967.Grishman, Ralph, "Implementation f the String Parser of English.
"In R. Rustin, Ed., Natural Language Processing.
New York:Algorithmies Press, 1973.Haviland, Susan E. and Herbert H. Clark, "What's New?
Acquir-ing new information as a process in comprehension."
Journal ofVerbal Learning and Verbal Behavior, 13, 1974.Hayes, P. and R. Reddy, "An Anatomy of Graceful Interaction inSpoken and Written Man-Machine Communication," TeehniealReport, Dept.
of Computer Science, Carnegie-Mellon Universi-ty, Pittsburgh, PA, 1979.Heidorn, George E., "Augmented Phrase Structure Grammars,"Theoretical Issues in Natural Language Processing, 1975.Hendrix, Gary G., Earl D. Sacerdoti, Daniel Sagalowiez, and Jona-than Slocum, "Developing a Natural Language Interface toComplex Data," ACM Transactions on Data Base Systems 3, 2,1978.Hendrix, G. G., "Human Engineering for Applied Natural LanguageProcessing," Proc.
5th International Joint Conference on ArtificialIntelligence, Cambridge, MA, August, 1977.Joshi, Aravind K. and Ralph M. Weischedel, "Computation of aSubclass of Inferences: Presupposition and Entailment."
Ameri-can Journal of Computational Linguistics, 1977, 1, Microfiche 63,1977.Kaplan, S. Jerrold, "Cooperative Responses from a Natural Lan-guage Data Base Query System: Preliminary Report," Techni-cal Report, Department of Computer and Information Science,Moore School, University of Pennsylvania, Philadelphia, PA,1977.Kaplan, S. Jerrold, "Indirect Responses to Loaded Questions,"Theoretical Issues in Natural Language Processing-2, University ofIllinois at Urbana-Champaign, July, 1978.Kaplan, S. Jerrold, "Cooperative Responses from a Natural Lan-guage Data Base Query System, ') Ph.D. Dissertation, Dept.
ofComputer & Information Science, University of Pennsylvania,Philadelphia, PA, 1979.Karttunen, L., "Presuppositions of Compound Sentences," Linguis-tic Inquiry, 4, 1973.Karttunen, L. and S. Peters, "Conventional Implieature in Mo-ntague Grammar," Proc.
of the First Annual Meeting of theBerkeley Linguistics Society, Berkeley, CA, 1975Kwasny, Stan and Norman K. Sondheimer, "Ungrammatieality andExtra-Grammaticality in Natural Language UnderstandingSystems," Proceedings of the 17th Annual Meeting of the Associa-tion for Computational Linguistics, 1979.Levin, J.
A. and J.
A. Moore, "'Dialogue Games: Meta-communication Structures for Natural Language Interaction,"Cognitive Science 1, 4, 1978.Mann, W. C., "Dialogue Games," in K. Hintikka, et.al., Eds.,Models of Dialogue, Amsterdam: North-Holland PublishingCompany, 1979.Mays, Eric, "Correcting Misconceptions About Data Base Struc-ture," Proceedings of the Conference of the Canadian Society forComputational Studies of Intelligence, 1980.Oh, Choon-Kyu and David A. Dineen, (Eds.
), Presupposition, Vol.11, Syntax and Semantics, New York: Academic Press, 1979.Sager, Naomi, "The String Parser for Scientific Literature."
In R.Rustin, Ed., Natural Language Processing.
New York: Algor-ithmies Press, 1973.Weischedel, Ralph M., "Computation of a Unique Subclass ofInferences: Presupposition and Entailment," Ph.D. Thesis,Department of Computer and Information Science, Universityof Pennsylvania, Philadelphia, PA, 1975.Weischedel, Ralph M., "A New Semantic Computation While Pars-ing: Presupposition and Entailment."
In C. Oh and D.
Dineen,Eds., Presupposition, Vol.
11, Syntax and Semantics, New York:Academic Press, 1979.Weischedel, Ralph M., "Please Re-phrase," Technical Report#77/1, Department of Computer and Information Sciences,University of Delaware, Newark, DE 1977.Weischedel, Ralph M., Wilfried Voge, and Mark James, "An Artifi-cial Intelligence Approach to Language Instruction," ArtificialIntelligence 10, 3, 1978.Winograd, T., Understanding Natural Language, New York: Aca-demic Press, Inc., 1972.Woods, W. A., "Transition Network Grammars for Natural Lan-guage Analysis," Comm.
ACM, 13, 10, 1970.Woods, W. A., "An Experimental Parsing System for TransitionNetwork Grammars."
In R. Rustin, Ed., Natural LanguageProcessing.
New York: Algorithmics Press, 1973a.Woods, W. A., "Progress in natural anguage understanding -- Anapplication to lunar geology,," AFIPS Conference Proceedings,NCC.
Montvale, NJ: AFIPS Press, 1973b.Woods, W. A., Personal Communication, 1977.Ralph M. Weischedel is an assistant professor in theDepartment o f  Computer and In format ion Sciences atthe University o f  Delaware.
He received the Ph.D. de-gree in computer and information science f rom the Uni-versity o f  Pennsylvania in 1975.John E. B lack  is Director o f  Computer Systems atW.
L. Gore & Associates, Inc., in Newark,  Delaware.He received the M.S .
degree in computer and informa-tion sciences f rom the University o f  Delaware in 1979.American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 109
