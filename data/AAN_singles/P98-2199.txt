Segregatory Coordination and Ellipsis in Text GenerationJ ames  ShawDept.
of Computer  ScienceColumbia UniversityNew York, NY 10027, USAshaw@cs.columbia.eduAbst rac tIn this paper, we provide an account of howto generate sentences with coordination con-structions from clause-sized semantic represen-tations.
An algorithm is developed and variousexamples from linguistic literature will be usedto demonstrate hat the algorithm does its jobwell.1 In t roduct ionThe linguistic literature has described numer-ous coordination phenomena (Gleitman, 1965;Ross, 1967; Neijt, 1979; Quirk et al, 1985; vanOirsouw, 1987; Steedman, 1990; Pollard andSag, 1994; Carpenter, 1998).
We will not ad-dress common problems associated with pars-ing, such as disambiguation a d construction ofsyntactic structures from a string.
Instead, weshow how to generate sentences with complexcoordinate constructions starting from seman-tic representations.
We have divided the pro-cess of generating coordination expressions intotwo major tasks, identifying recurring elementsin the conjoined semantic structure and delet-ing redundant elements using syntactic informa-tion.
Using this model, we are able to handlecoordination phenomenon uniformly, includingdifficult cases such as non-constituent coordina-tion.In this paper, we are specifically interested inthe generation of segregatory coordination con-structions.
In segregatory coordination, the co-ordination of smaller units is logically equivalentto coordination of clauses; for example, "Johnlikes Mary and Nancy" is logically equivalentto "John likes Mary" and "John likes Nancy".Other similar conjunction coordination phe-nomena, such as combinatory and rhetorical co-ordination, are treated ifferently in text gener-ation systems.
Since these constructions cannotbe analyzed as separate clauses, we will definethem here, but will not describe them furtherin the paper.
In combinatory coordination, thesentence "Mary and Nancy are sisters."
is notequivalent to "Mary is a sister."
and "Nancyis a sister."
The coordinator "and" sometimescan function as a rhetorical marker as in "Thetrain sounded the whistle and \[then\] departedthe station."
1To illustrate the common usage of coordina-tion constructions, we will use a system whichgenerates reports describing how much workeach employee has performed in an imaginarysupermarket human resource department.
Gen-erating a separate sentence for each tuple in therelational database would result in: "John re-arranged cereals in Aisle 2 on Monday.
Johnrearranged candies in Aisle 2 on Tuesday."
Asystem capable of generating segregatory coor-'dination construction can produce a shorter sen-tence: "John rearranged cereals in Aisle 2 onMonday and candies on Tuesday.
"In the next section, we briefly describe thearchitecture of our generation system and themodules that handle coordination construction.A comparison with related work in text gener-ation is presented in Section 3.
In Section 4,we describe the semantic representation usedfor coordination.
An algorithm for carryingout segregatory coordination is provided in Sec-tion 5 with an example.
In Section 6, we willanalyze various examples taken from linguisticliterature and describe how they are handled bythe current algorithm.2 Generat ion  Arch i tec tureTraditional text generation systems contain astrategic and a tactical component.
The strate-gic component determines what to say and theorder in which to say it while the tactical com-ponent determines how to say it.
Even though1The string enclosed in symbols \[ and \] are deletedfrom the surface xpression, but these concepts exist inthe semantic representation.1220the strategic omponent must first decide whichclauses potentially might be combined, it doesnot have access to lexical and syntactic knowl-edge to perform clause combining as the tac-tical component does.
We have implemented asentence planner, CASPER (Clause Aggregationin Sentence P lannER) ,  as the first module inthe tactical component to handle clause combin-ing.
The main tasks of the sentence planner areclause aggregation, sentence boundary determi-nation and paraphrasing decisions based on con-text (Wanner and Hovy, 1996; Shaw, 1995).The output of the sentence planner is an or-dered list of semantic structures each of whichcan be realized as a sentence.
A lexical chooser,based on a lexicon and the preferences speci-fied from the sentence planner, determines thelexical items to represent the semantic onceptsin the representation.
The lexicalized result isthen transformed into a syntactic structure andlinearized into a string using FUF/SURGE (E1-hadad, 1993; Robin, 1995), a realization compo-nent based on Functional Unification Grammar(Halliday, 1994; Kay, 1984).Though every component in the architecturecontributes to the generation of coordinate con-structions, most of the coordination actions takeplace in the sentence planner and the lexicalchooser.
These two modules reflect the twomain tasks of generating coordination conjunc-tion: the sentence planner identifies recurringelements among the coordinated propositions,and the lexical chooser determines which recur-ring elements to delete.
The reason for such adivision is that ellipsis depends on the sequen-tial order of the recurring elements at surfacelevel.
This information is only available aftersyntactic and lexical decisions have been made.For example, in "On Monday, John rearrangedcereals in Aisle 2 and cookies in Aisle 4.
", thesecond time PP is deleted, but in "John rear-ranged cereals in Aisle 2 and cookies in Aisle4 on Monday.
", the first time PP is deleted.
2CASPER only marks the elements as recurringand let the lexical chooser make deletion deci-sions later.
A more detailed description is pro-vided in Section 5.2The expanded first example is "On Monday, Johnrearranged cereals in Aisle 2 and \[on Monday\], \[John\]\[rearranged\] cookies in Aisle 4."
The expanded secondexample is "John rearranged cereals in Aisle 2 \[on Mon-day I and \[John\] [rearranged\] cookies in Aisle 4 on Mon-day.
"3 Re la ted  WorkBecause sentences with coordination can ex-press a lot of information with fewer words,many text generation systems have imple-mented the generation of coordination with var-ious levels of complexities.
In earlier systemssuch as EPICURE (Dale, 1992), sentences withconjunction are formed in the strategic ompo-nent as discourse-level optimizations.
Currentsystems handle aggregations decisions includingcoordination and lexical aggregation, such astransforming propositions into modifiers (adjec-tives, prepositional phrases, or relative clauses),in a sentence planner (Scott and de Souza, 1990;Dalianis and Hovy, 1993; Huang and Fiedler,1996; Callaway and Lester, 1997; Shaw, 1998).Though other systems have implemented co-ordination, their aggregation rules only handlesimple conjunction inside a syntactic structure,such as subject, object, or predicate.
In con-trast to these localized rules, the staged algo-rithm used in CASPER is global in the sense thatit tries to find the most concise coordinationstructures across all the propositions.
In addi-tion, a simple heuristic was proposed to avoidgenerating overly complex and potentially am-biguous sentences as a result of coordination.CASPER also systematically handles ellipsis andcoordination i prepositional c auses which werenot addressed before.
When multiple proposi-tions are combined, the sequential order of thepropositions is an interesting issue.
(Dalianisand Hovy, 1993) proposed a domain specific or-dering, such as preferring a proposition with ananimate subject o appear before a propositionwith an inanimate subject.
CASPER sequential-izes the propositions according to an order thatallows the most concise coordination of propo-sitions.4 The  Semant ic  Representat ionCASPER uses a representation i fluenced byLexical-Functional Grammar (Kaplan and Bres-nan, 1982) and Semantic Structures (Jackend-off, 1990).
While it would have been naturalto use thematic roles proposed in FunctionalGrammar, because our realization component,FUF/SURGE, uses them, these roles wouldadd more complexity into the coordination pro-cess.
One major task of generating coordina-tion expression is identifying identical elementsin the propositions being combined.
In Func-1221((pred ((pred c-lose) (type EVENT)(tense past)))(argl ((pred c-name) (type THING)(first-name ' ' John'S)))(arg2 ((pred c-laptop) (type THING)(specific no)(mod ((pred c-expensive)(type ATTRIBUTE)))))(mod ((pred c-yesterday)(type TIME))))Figure 1: Semantic representation for "Johnlost an expensive laptop yesterday.
"A1 re-stocked milk in Aisle 5 on Monday.A1 re-stocked coffee in Aisle 2 on Monday.A1 re-stocked tea in Aisle 2 on Monday.A1 re-stocked bread in Aisle 3 on Friday.Figure 2: A sample of input semantic represen-tations in surface form.tional Grammar, different processes have differ-ent names for their thematic roles (e.g., MEN-TAL process has role SENSER for agent whileINTENSIVE process has role IDENTIFIED).As a result, identifying identical elements un-der various thematic roles requires looking atthe process first in order to figure out whichthematic roles should be checked for redun-dancy.
Compared to Lexical-Functional Gram-mar which uses the same feature names, the the-matic roles for Functional Grammar makes theidentifying task more complicated.In our representation, the roles for each eventor state are PRED, ARG1, ARG2, ARG3, andMOD.
The slot PRED stores the verb concept.Depending on the concept in PRED, ARG1,ARG2, and ARG3 can take on different the-matic roles, such as Actor, Beneficiary, andGoal in "John gave Mary a red book yester-day."
respectively.
The optional slot MODstores modifiers of the PRED.
It can have oneor multiple circumstantial elements, includingMANNER, PLACE, or TIME.
Inside each argu-ment slot, it too has a MOD slot to store infor-mation such as POSSESSOR or ATTRIBUTE.An example of the semantic representation isprovided in Figure 1.5 Coord inat ion Algor i thmWe have divided the algorithm into four stages,where the first three stages take place in thesentence planner and the last stage takes placeA1 re-stocked coffee in Aisle 2 on Monday.A1 re-stocked tea in Aisle 2 on Monday.A1 re-stocked milk in Aisle 5 on Monday.A1 re-stocked bread in Aisle 3 on Friday.Figure 3: Propositions in surface ~rm after Stage 1.in the lexical chooser:Stage 1: group propositions and order themaccording to their similarities while satisfy-ing pragmatic and contextual constraints.Stage 2" determine recurring elements in theordered propositions that will be combined.Stage 3: create a sentence boundary when thecombined clause reaches pre-determinedthresholds.Stage 4" determine which recurring elementsare redundant and should be deleted.In the following sections, we provide detail oneach stage.
To illustrate, we use the imaginaryemployee report generation system for a humanresource department in a supermarket.5.1 Group and Order Proposit ionsIt is desirable to group together propositionswith similar elements because these elementsare likely to be inferable and thus redundantat surface level and deleted.
There are manyways to group and order propositions based onsimilarities.
For the propositions in Figure 2,the semantic representations have the follow-ing slots: PRED, ARG1, ARG2, MOD-PLACE,and MOD-TIME.
To identify which slot has themost similarity among its elements, we calcu-late the number of distinct elements in eachslot across the propositions, which we call NDE(number of distinct elements).
For the purposeof generating concise text, the system prefers togroup propositions which result in as many slotswith NDE -- 1 as possible.
For the propositionsin Figure 2, both NDEs of PRED and ARG1are 1 because all the actions are "re-stock" andall the agents are "AI"; the NDE for ARG2 is 4because it contains 4 distinct elements: "milk","coffee", "tea", and "bread"; similarly, the NDEof MOD-PLACE is 3; the NDE of MOD-TIMEis 2 ("on Monday" and "on Friday").The algorithm re-orders the propositions bysorting the elements in each slots using compar-ison operators which can determine that Mon-day is smaller than Tuesday, or Aisle 2 is smallerthan Aisle 4.
Starting from the slots withlargest NDE to the lowest, the algorithm re-1222((pred c-and) (type LIST)(elts"(((pred ((prsd "re-stocked") (type EVENT)(status RECI/RRING) ) )(arE1 ((pred "AI") (TYPE THING)(status RECURRING) ) )(arE2 ((pred "tea") (type THING)))(rood ((pred "on") (type TIME)(arEl ((pred "Monday")(type TIME-THING) ) ) ) ) )((pred ((pred "re-stocked") (type EVENT)(status RECURRING) ) )(argl ((pred "AI") (TYPE THING)(status RECURRING) ) )(arE2 ((pred "milk") (type THING)))(rood ((pred "on") (type TIME)(arE1 ((pred "Friday")(type TIME-THING) ) ) ) ) ) ) ) )Figure 4: The simplified semantic representationfor "A1 re-stocked tea on Monday and milk on Fri-day."
Note: "0  - a list.orders the propositions based on the elements ofeach particular slot.
In this case, propositionswill ordered according to their ARG2 first, fol-lowed by MOD-PLACE, MOD-TIME, ARG1,and PRED.
The sorting process will put similarpropositions adjacent o each other as shown inFigure 3.5.2 Ident i fy  Recur r ing  E lementsThe current algorithm makes its decisions ina sequential order and it combines only twopropositions at any one time.
The result propo-sition is a semantic representation which repre-sents the result of combining the propositions.One task of the sentence planner is to find a wayto combine the next proposition in the orderedpropositions into the resulting proposition.
InStage 2, it is concerned with how many slotshave distinct values and which slots they are.When multiple adjacent propositions have onlyone slot with distinct elements, these proposi-tions are 1-distinct.
A special optimization canbe carried out between the 1-distinct proposi-tions by conjoining their distinct elements intoa coordinate structure, such as conjoined verbs,nouns, or adjectives.
McCawley (McCawley,1981) described this phenomenon as Conjunc-tion Reduction - '~whereby conjoined clausesthat differ only in one item can be replaced bya simple clause that involves conjoining thatitem."
In our example, the first and secondpropositions are 1-distinct at ARG2, and theyare combined into a semantic structure repre-senting "A1 re-stocked coffee and tea in Aisle2 on Monday."
If the third proposition is 1-distinct at ARG2 in respect o the result propo-sition also, the element "milk" in ARG2 of thethird proposition would be similarly combined.In the example, it is not.
As a result, we can-not combine the third proposition using onlyconjunction within a syntactic structure.When the next proposition and the resultproposition have more than one distinct slot ortheir 1-distinct slot is different from the previ-ous 1-distinct slot, the two propositions are saidto be multiple-distinct.
Our approach in com-bining multiple-distinct propositions i differentfrom previous linguistic analysis.
Instead of re-moving recurring entities right away based ontransformation r substitution, the current sys-tem generates every conjoined multiple-distinctproposition.
During the generation processof each conjoined clause, the recurring ele-ments might be prevented from appearing atthe surface level because the lexical chooser pre-vented the realization component from generat-ing any string for such redundant elements.
Ourmultiple-distinct coordination produces whatlinguistics describes as ellipsis and gapping.Figure 4 shows the result combining two propo-sitions that will result in "A1 re-stocked tea onMonday and milk on Friday."
Some readersmight notice that PRED and ARG1 in bothpropositions are marked as RECURRING butonly subsequent recurring elements are deletedat surface level.
The reason will be explained inSection 5.4.5.3 Determine  Sentence  BoundaryUnless combining the next proposition intothe result proposition will exceed the pre-determined parameters for the complexity of asentence, the algorithm wilt keep on combin-ing more propositions into the result proposi-tion using 1-distinct or multiple-distinct oor-dination.
In normal cases, the predefined pa-rameter limits the number of propositions con-joined by multiple-distinct oordination to two.In special cases where the same slots across mul-tiple propositions are multiple-distinct, the pre-determined limit is ignored.
By taking advan-tage of parallel structures, these propositionscan be combined using multiple-distinct proce-dures without making the coordinate structuremore difficult to understand.
For example, thesentence "John took aspirin on Monday, peni-1223cillin on Tuesday, and Tylenol on Wednesday.
"is long but quite understandable.
Similarly,conjoining a long list of 3-distinct propositionsproduces understandable s ntences too: "Johnplayed tennis on Monday, drove to school onTuesday, and won the lottery on Wednesday.
"These constraints allow CASPER to produce sen-tences that are complex and contain a lot of in-formation, but they are also reasonably easy tounderstand.5.4 De lete  Redundant  E lementsStage 4 handles ellipsis, one of the most dif-ficult phenomena to handle in syntax.
In theprevious tages, elements that occur more thanonce among the propositions are marked as RE-CURRING, but the actual deletion decisionshave not been made because CASPER lacks thenecessary information.
The importance of thesurface sequential order can be demonstratedby the following example.
In the sentence "OnMonday, A1 re-stocked coffee and \[on Monday,\]\[A1\] removed rotten milk.
", the elements inMOD-TIME delete forward (i.e.
the subsequentoccurrence of the identical constituent disap-pears).
When MOD-TIME elements are real-ized at the end of the clause, the same elementsin MOD-TIME delete backward (i.e.
the an-tecedent occurrence of the identical constituentdisappears): "Al re-stocked coffee \[on Monday,\]and \[A1\] removed rotten milk on Monday."
Ourdeletion algorithm is an extension to the Di-rectionality Constraint in (Tai, 1969), whichis based on syntactic structure.
Instead, ouralgorithm uses the sequential order of the re-curring element for making deletion decisions.In general, if a slot is realized at the front ormedial of a clause, the recurring elements inthat slot delete forward.
In the first example,MOD-TIME is realized as the front adverbialwhile ARC1, "Ar', appears in the middle of theclause, so elements in both slots delete forward.On the other hand, if a slot is realized at the endposition of a clause, the recurring elements insuch slot delete backward, as the MOD-TIMEin second example.
The extended irectionalityconstraint also applies to conjoined premodifiersand postmodifiers as well, as demonstrated by"in Aisle 3 and \[in Aisle\] 4", and "at 3 \[PM\] and\[at\] 9 PM".Using the algorithm just described, the resultof the supermarket xample is concise and eas-ily understandable: "A1 re-stocked coffee and1.
The Base Plan called for one new fiber activa-tion at CSA 1061 in 1995 Q2.2.
New 150mb_mux multiplexor placements wereprojected at CSA 1160 and 1335 in 1995 Q2.3.
New 150mb.mux multiplexors were placed atCSA 1178 in 1995 Q4 and at CSA 1835 in 1997Q1.4.
New 150mb_mux multiplexor placements wereprojected at CSA 1160, 1335 and 1338 and onenew 200mb_mux multiplexor placement a CSA1913b in 1995 Q2.5.
At CSA 2113, the Base Plan called for 32working-pair transfers in 1997 Q1 and fourworking-pair t ansfers in 1997 Q2 and Q3.Figure 5: Text generated by CASPER.tea in Aisle 2 and milk in Aisle 5 on Monday.A1 re-stocked bread in Aisle 3 on Friday."
Fur-ther discourse processing will replace the second"Al" with a pronoun "he", and the adverbial"also" may be inserted too.CASPER has been used in an upgraded versionof PLANDoc(McKeown et al, 1994), a robust,deployed system which generates reports for jus-tifying the cost to the management in telecom-munications domain.
Some of the current out-put is shown in Figure 5.
In the figure, "CSA"is a location; "QI" stands for first quarter;"multiplexor" and '~orking-pair transfer" aretelecommunications equipment.
The first ex-ample is a typical simple proposition in the do-main, which consists of PRED, ARC1, ARC2,MOD-PLACE, and MOD-TIME.
The secondexample shows 1-distinct coordination at MOD-PLACE, where the second CSA been deleted.The third example demonstrates coordinationof two propositions with multiple-distinct inMOD-PLACE and MOD-TIME.
The fourth ex-ample shows multiple things: the ARC1 becameplural in the first proposition because multi-ple placements occurred as indicated by sim-ple conjunction in MOD-PLACE; the gappingof the PRED '~ras projected" in the secondclause was based on multiple-distinct oordina-tion.
The last example demonstrates the dele-tion of MOD-PLACE in the second propositionbecause it is located at the front of the clause atsurface level, so MOD-PLACE deletes forward.6 L ingu is t i c  PhenomenonIn this section, we take examples from variouslinguistic literature (Quirk et al, 1985; van Oir-1224souw, 1987) and show how the algorithm devel-oped in Section 5 generates them.
We also showhow the algorithm can generate sentences withnon-constituent coordination, which pose diffi-culties for most syntactic theories.Coordination involves elements of equal syn-tactic status.
Linguists have categorized coor-dination into simple and complex.
Simple coor-dination conjoins single clauses or clause con-stituents while complex coordination involvesmultiple constituents.
For example, the coor-dinate construction in "John .finished his workand \[John\] went home."
could be viewed asa single proposition containing two coordinateVPs.
Based on our algorithm, the phenomenonwould be classified as a multiple-distinct oordi-nation between two clauses with deleted ARG1,"John", in the second clause.
In our algorithm,the 1-distinct procedure can generate many sim-ple coordinations, including coordinate verbs,nouns, adjectives, PPs, etc.
With simple ex-tensions to the algorithm, clauses with relativeclauses could be combined and coordinated too.Complex coordinations involving ellipsis andgapping are much more challenging.
Inmultiple-distinct oordination, each conjoinedclause is generated, but recurring elementsamong the propositions are deleted dependingon the extended irectionalityconstraints men-tioned in Subsection 5.4.
It works because ittakes advantage of the parallel structure at thesurface level.Van Oirsouw (van Oirsouw, 1987), based onthe literature on coordinate deletion, identifieda number of rules which result in deletion underidentity: Gapping, which deletes medial mate-rial; Right-Node-Raising (RNR), which deletesidentical right most constituents in a syntactictree; VP-deletion (VPD), which deletes iden-tical verbs and handles post-auxiliary deletion(Sag, 1976).
Conjunction Reduction (CR),which deletes identical right-most or leftmostmaterial.
He pointed out that these four rulesreduce the length of a coordination by delet-ing identical material, and they serve no otherpurpose.
We will describe how our algorithmhandles the examples van Oirsouw used in Fig-ure 6.The algorithm described in Section 5 can usethe multiple-distinct procedure to handle all thecases except VPD.
In the gapping example, thePRED deletes forward.
In RNR, ARG2 deletesGapping: John ate fish and Bill ?
rice.P,_NR: John caught ?, and Mary killed the ra-bid dog.VPD:  John sleeps, and Peter does ?, too.CR I :  John gave ?
?, and Peter sold a recordto Sue.CR2: John gave a book to Mary and ?
?
arecord to Sue.Figure 6: Four coordination rules for identitydeletion described by van Oirsouw.backward because it is positioned at the end ofthe clause.
In CR1, even though the medial slotARG2 should delete forward, it deletes back-ward because it is considered at the end positionof a clause.
In this case, once ARG3 (the BEN-EFICIARY "to Sue") deletes backward, ARG2is at the end position of a clause.
This pro-cess does require more intelligent processing inthe lexical chooser, but it is not difficult.
InCR2, it is straight forward to delete forward be-cause both ARG1 and PRED are medial.
Thecurrent algorithm does not address VPD.
Forsuch a sentence, the system would have gener-ated "John and Peter slept" using 1-distinct.Non-constituent coordination phenomena,the coordination of elements that are not ofequal syntactic status, are challenging for syn-tactic theories.
The following non-constituentcoordination can be explained nicely with themultiple-distinct procedure.
In the sentence,"The spy was in his forties, of average build, andspoke with a slightly foreign accent.
", the coordi-nated constituents are VP, PP, and VP.
Basedon our analysis, the sentence could be gener-ated by combining the first two clauses usingthe 1-distinct procedure, and the third clause iscombined using the multiple-distinct procedure,with ARG1 ("the spy") deleted forward.The spy was in his forties, \[the spy\]\[was\] of average build, and \[the spy\]spoke with a slightly foreign accent.7 Conc lus ionBy separating the generation of coordinationconstructions into two tasks - identifying re-curring elements and deleting redundant ele-ments based on the extended irectionality con-straints, we are able to handle many coordi-nation constructions correctly, including non-constituent coordinations.
Through numerous1225examples, we have shown how our algorithm cangenerate complex coordinate constructions fromclause-sized semantic representations.
Both therepresentation a d the algorithm have been im-plemented and used in two different text gener-ation systems (McKeown et al, 1994; McKeownet al, 1997).8 AcknowledgmentsThis work is supported by DARPA ContractDAAL01-94-K-0119, the Columbia UniversityCenter for Advanced Technology in High Per-formance Computing and Communications inHealthcare (funded by the New York StateScience and Technology Foundation) and NSFGrants GER-90-2406.ReferencesCharles B. Callaway and James C. Lester.
1997.Dynamically improving explanations: A revision-based approach to explanation generation.
InProc.
of the 15th IJCAI, pages 952-958, Nagoya,Japan.Bob Carpenter.
1998.
Distribution, collection andquantification: A type-logical account.
To appearin Linguistics and Philosophy.Robert Dale.
1992.
Generating Referring Expres-sions: Constructing Descriptions in a Domain ofObjects and Processes.
MIT Press, Cambridge,MA.Hercules Dalianis and Eduard Hovy.
1993.
Aggre-gation in natural language generation.
In Proc.
ofthe ~th European Workshop on Natural LanguageGeneration, Pisa, Italy.Michael Elhadad.
1993.
Using argumentation tocontrol lexical choice: A functional unification-based approach.
Ph.D. thesis, Columbia Univer-sity.Lila R. Gleitman.
1965.
Coordinating conjunctionsin English.
Language, 41:260-293.Michael A. K. Halliday.
1994.
An Introduction toFunctional Grammar.
Edward Arnold, London,2nd edition.Xiaoron Huang and Armin Fiedler.
1996.
Para-phrasing and aggregating argumentative text us-ing text structure.
In Proc.
of the 8th Interna-tional Natural Language Generation Workshop,pages 21-3, Sussex, UK.Ray Jackendoff.
1990.
Semantic Structures.
MITPress, Cambridge, MA.Ronald M. Kaplan and Joan Bresnan.
1982.Lexical-functional grammar: A formal system forgrammatical representation.
I  Joan Bresnan, ed-itor, The Mental Representation of GrammaticalRelations, chapter 4.
MIT Press.Martin Kay.
1984.
Functional Unification Gram-mar: A formalism for machine translation.
InProc.
of the IOth COLING and PPnd ACL, pages75-78.James D. McCawley.
1981.
Everything that linguistshave always wanted to know about logic (but wereashamed to ask).
University of Chicago Press.Kathleen McKeown, Karen Kukich, and JamesShaw.
1994.
Practical issues in automatic doc-umentation generation.
In Proe.
of the 4th ACLConference on Applied Natural Language Process-ing, pages 7-14, Stuttgart.Kathleen McKeown, Shimei Pan, James Shaw,Desmond Jordan, and Barry Allen.
1997.
Lan-guage generation for multimedia healthcare brief-ings.
In Proc.
of the Fifth ACL Conf.
on ANLP,pages 277-282.Anneke H. Neijt.
1979.
Gapping: a eonstributionto Sentence Grammar.
Dordrecht: Poris Publica-tions.Carl Pollard and Ivan Sag.
1994.
Head-Driven Phrase Structure Grammar.
University ofChicago Press, Chicago.Randolph Quirk, Sidney Greebaum, Geoffrey Leech,and Jan Svartvik.
1985.
A Comprehensive Gram-mar of the English Language.
Longman Publish-ers, London.Jacques Robin.
1995.
Revision-Based Generation ofNatural Language Summaries Providing Histori-cal Background.
Ph.D. thesis, Columbia Univer-sity.John Robert Ross.
1967.
Constraints on variablesin syntax.
Ph.D. thesis, MIT.Ivan A.
Sag.
1976.
Deletion and Logical Form.Ph.D.
thesis, MIT.Donia R. Scott and Clarisse S. de Souza.
1990.
Get-ting the message across in RST-based text gener-ation.
In Robert Dale, Chris Mellish, and MichaelZock, editors, Current Research in Natural Lan-guage Generation, pages 47-73.
Academic Press,New York.James Shaw.
1995.
Conciseness through aggrega-tion in text generation.
In Proc.
of the 33rd A CL(Student Session), pages 329-331.James Shaw.
1998.
Clause aggregation using lin-guistic knowledge.
In Proc.
of the 9th Interna-tional Workshop on Natural Language Genera-tion.Mark Steedman.
1990.
Gapping as constituent coor-dination.
Linguistics and Philosophy, 13:207-264.J.
H.-Y.
Tai.
1969.
Coordination Reduction.
Ph.D.thesis, Indiana University.Robert van Oirsouw.
1987.
The Syntax of Coordi-nation.
Croom Helm, Beckenham.Leo Wanner and Eduard Hovy.
1996.
The Health-Doe sentence planner.
In Proc.
of the 8th Inter-national Natural Language Generation Workshop,pages 1-10, Sussex, UK.1226
