Bootstrapping Parallel CorporaChris Callison-BurchSchool of InformaticsUniversity of Edinburghcallison-burch@ed.ac.ukMiles OsborneSchool of InformaticsUniversity of Edinburghmiles@inf.ed.ac.ukAbstractWe present two methods for the automatic cre-ation of parallel corpora.
Whereas previouswork into the automatic construction of parallelcorpora has focused on harvesting them fromthe web, we examine the use of existing paral-lel corpora to bootstrap data for new languagepairs.
First, we extend existing parallel cor-pora using co-training, wherein machine trans-lations are selectively added to training corporawith multiple source texts.
Retraining transla-tion models yields modest improvements.
Sec-ond, we simulate the creation of training datafor a language pair for which a parallel corpusis not available.
Starting with no human trans-lations from German to English we produce aGerman to English translation model with 45%accuracy using parallel corpora in other lan-guages.
This suggests the method may be use-ful in the creation of parallel corpora for lan-guages with scarce resources.1 IntroductionStatistical translation models (such as those formulated inBrown et al (1993)) are trained from bilingual sentence-aligned texts.
The bilingual data used for constructingtranslation models is often gathered from governmentdocuments produced in multiple languages.
For exam-ple, the Candide system (Berger et al, 1994) was trainedon ten years?
worth of Canadian Parliament proceed-ings, which consists of 2.87 million parallel sentencesin French and English.
While the Candide system waswidely regarded as successful, its success is not indica-tive of the potential for statistical translation between ar-bitrary language pairs.
The reason for this is that collec-tions of parallel texts as large as the Canadian Hansardsare rare.Al-Onaizan et al (2000) explains in simple terms thereasons that using large amounts of training data en-sures translation quality: if a program sees a partic-ular word or phrase one thousand times during train-ing, it is more likely to learn a correct translation thanif sees it ten times, or once, or never.
Increasing theamount of training material therefore leads to improvedquality.
This is illustrated in Figure 1, which plotstranslation accuracy (measured as 100 minus word er-ror rate) for French?English, German?English, andSpanish?English translation models trained on incre-mentally larger parallel corpora.
The quality of thetranslations produced by each system increases over the100,000 training items, and the graph suggests the thetrend would continue if more data were added.
Noticethat the rate of improvement is slow: after 90,000 manu-ally provided training sentences pairs, we only see a 4-6%change in performance.
Sufficient performance for sta-tistical models may therefore only come when we haveaccess to many millions of aligned sentences.One approach that has been proposed to address theproblem of limited training data is to harvest the web forbilingual texts (Resnik, 1998).
The STRAND method au-tomatically gathers web pages that are potential transla-tions of each other by looking for documents in one lan-guage which have links whose text contains the name ofanother language.
For example, if an English web pagehad a link with the text ?Espan?ol?
or ?en Espan?ol?
thenthe page linked to is treated as a candidate translation ofthe English page.
Further checks verify the plausibilityof its being a translation (Smith, 2002).Instead of attempting to gather new translations fromthe web, we describe an alternate method for automat-ically creating parallel corpora.
Specifically, we exam-ine the use of existing translations as a resource to boot-strap more training data, and to create data for new lan-guage pairs.
We generate translation models from exist-ing data and use them to produce translations of new sen-4446485052545658606264 100002000030000400005000060000700008000090000100000Accuracy (100 - Word Error Rate)Training Corpus Size (number of sentence pairs)GermanFrenchSpanishFigure 1: Translation accuracy plotted against trainingcorpus sizetences.
Incorporating this machine-created parallel datato the original set, and retraining the translation modelsimproves the translation accuracy.
To perform the retrain-ing we use co-training (Blum and Mitchell, 1998; Abney,2002) which is a weakly supervised learning techniquethat relies on having distinct views of the items beingclassified.
The views that we employ for co-training aremultiple source documents.Section 2 motivates the use of weakly supervised learn-ing, and introduces co-training for machine translation.Section 3 reports our experimental results.
One experi-ment shows that co-training can modestly benefit trans-lation systems trained from similarly sized corpora.
Asecond experiment shows that co-training can have a dra-matic benefit when the size of initial training corpora aremismatched.
This suggests that co-training for statisti-cal machine translation is especially useful for languageswith impoverished training corpora.
Section 4 discussesthe implications of our experiments, and discusses wayswhich our methods might be used more practically.2 Co-training for Statistical MachineTranslationMost statistical natural language processing tasks use su-pervised machine learning, meaning that they requiretraining data that contains examples that have been an-notated with some sort of labels.
Two conflicting factorsmake this reliance on annotated training data a problem:?
The accuracy of machine learning improves as moredata is available (as we have shown for statisticalmachine translation in Figure 1).?
Annotated training data usually has some cost asso-ciated with its creation.
This cost can often be sub-stantial, as with the Penn Treebank (Marcus et al,1993).There has recently been considerable interest in weaklysupervised learning within the statistical NLP commu-nity.
The goal of weakly supervised learning is to reducethe cost of creating new annotated corpora by (semi-) au-tomating the process.Co-training is a weakly supervised learning techniqueswhich uses an initially small amount of human labeleddata to automatically bootstrap larger sets of machine la-beled training data.
In co-training implementations mul-tiple learners are used to label new examples and re-trained on some of each other?s labeled examples.
Theuse of multiple learners increases the chance that use-ful information will be added; an example which is eas-ily labeled by one learner may be difficult for the otherand therefore adding the confidently labeled example willprovide information in the next round of training.Self-training is a weakly supervised method in whicha single learner retrains on the labels that it applies tounlabeled data itself.
We describe its application tomachine translation in order to clarify how co-trainingwould work.
In self-training a translation model would betrained for a language pair, say German?English, froma German-English parallel corpus.
It would then produceEnglish translations for a set of German sentences.
Themachine translated German-English sentences would beadded to the initial bilingual corpus, and the translationmodel would be retrained.Co-training for machine translation is slightly morecomplicated.
Rather than using a single translationmodel to translate a monolingual corpus, it uses mul-tiple translation models to translate a bi- or multi-lingual corpus.
For example, translation models couldbe trained for German?English, French?English andSpanish?English from appropriate bilingual corpora,and then used to translate a German-French-Spanish par-allel corpus into English.
Since there are three candidateEnglish translations for each sentence alignment, the besttranslation out of the three can be selected and used toretrain the models.
The process is illustrated in Figure 2.Co-training thus automatically increases the size ofparallel corpora.
There are a number of reasons whymachine translated items added during co-training can beuseful in the next round of training:?
vocabulary acquisition ?
One problem that arisesfrom having a small training corpus is incompleteword coverage.
Without a word occurring in itstraining corpus it is unlikely that a translation modelwill produce a reasonable translation of it.
Becausethe initial training corpora can come from differentsources, a collection of translation models will bemore likely to have encountered a word before.
ThisMaison bleu Casa azulblaues Haus??
?BluemaisonblauesHouseBlue house2Maison bleu Casa azulblaues HausBlue houseBluemaisonblauesHausBlue house3French GermanSpanishEnglish target4Frenchsome english sentencesome french sentencsome english sentencesome french sentencesome english sentencesome french sentencesome english sentencesome french sentencesome english sentencesome french sentencesome english sentencesome french sentencesome english sentencesome french sentenceGerman Englishsome english sentencesome french sentencesome english sentencesome french sentencesome english sentencesome french sentencesome english sentencesome french sentencesome english sentencesome french sentencesome english sentencesome french sentencesome english sentencesome french sentenceSpanish Englishsome english sentencesome french sentencesome english sentencesome french sentencesome english sentencesome french sentencesome english sentencesome french sentencesome english sentencesome french sentencesome english sentencesome french sentencesome english sentencesome french sentence1EnglishFrenchsome english sentencesome french sentencsome english sentencesome frenchsentencesome english sentencesome frenchsentencesome english sentencesome frenchsentencesome english sentencesome frenchsentencesome english sentencesome frenchsentencesome english sentencesome frenchsentenceEnglishMaisonbleuBluehouse+Spanishsome english sentencesome french sentencsome english sentencesome frenchsentencesome english sentencesome frenchsentencesome english sentencesome frenchsentencesome english sentencesome frenchsentencesome english sentencesome frenchsentencesome english sentencesome frenchsentenceEnglishCasa azulBluehouse+blauesHausBluehouse+Germansome english sentencesome french sentencsome english sentencesome frenchsentencesome english sentencesome frenchsentencesome english sentencesome frenchsentencesome english sentencesome frenchsentencesome english sentencesome frenchsentencesome english sentencesome frenchsentenceEnglishFigure 2: Co-training using German, French, and Spanish sources to produce English machine translationsleads to vocabulary acquisition during co-training.?
coping with morphology ?
The problem mentionedabove is further exacerbated by the fact that mostcurrent statistical translation formulations have anincomplete treatment of morphology.
This would bea problem if the training data for a Spanish transla-tion model contained the masculine form of a adjec-tive, but not the feminine.
Because languages varyin how they use morphology (some languages havegrammatical gender whereas others don?t) one lan-guage?s translation model might have the translationof a particular word form whereas another?s wouldnot.
Thus co-training can increase the inventory ofword forms and reduce the problem that morphol-ogy poses to simple statistical translation models.?
improved word order ?
A significant source of er-rors in statistical machine translation is the word re-ordering problem (Och et al, 1999).
The word or-der between related languages is often similar whileword order between distant language may differ sig-nificantly.
By including more examples through co-training with related languages, the translation mod-els for distant languages will better learn word ordermappings to the target language.In all these cases the diversity afforded by multiple trans-lation models increases the chances that the machinetranslated sentences added to the initial bilingual corporawill be accurate.
Our co-training algorithm allows manysource languages to be used.3 Experimental ResultsIn order to conduct co-training experiments we firstneeded to assemble appropriate corpora.
The corpus usedin our experiments was assembled from the data used inthe (Och and Ney, 2001) multiple source translation pa-per.
The data was gathered from the Bulletin of the Eu-ropean Union which is published on the Internet in theeleven official languages of the European Union.
Weused a subset of the data to create a multi-lingual cor-pus, aligning sentences between French, Spanish, Ger-man, Italian and Portuguese (Simard, 1999).
Addition-ally we created bilingual corpora between English andeach of the five languages using sentences that were notincluded in the multi-lingual corpus.Och and Ney (2001) used the data to find a transla-tion that was most probable given multiple source strings.Och and Ney found that multi-source translations usingtwo source languages reduced word error rate when com-pared to using source strings from a single language.For multi-source translations using source strings in sixlanguages a greater reduction in word error rate wasachieved.
Our work is similar in spirit, although insteadof using multi-source translation at the time of transla-tion, we integrate it into the training stage.
WhereasOch and Ney use multiple source strings to improve thequality of one translation only, our co-training method at-tempts to improve the accuracy of all translation modelsby bootstrapping more training data from multiple sourcedocuments.3.1 SoftwareThe software that we used to train the statistical mod-els and to produce the translations was GIZA++ (Ochand Ney, 2000), the CMU-Cambridge Language Model-ing Toolkit (Clarkson and Rosenfeld, 1997), and the ISIReWrite Decoder.
The sizes of the language models usedin each experiment were fixed throughout, in order to en-sure that any gains that were made were not due to thetrivial reason of the language model improving (whichcould be done by building a larger monolingual corpus ofthe target language).The experiments that we conducted used GIZA++ toproduce IBM Model 4 translation models.
It should beobserved, however, that our co-training algorithm is en-tirely general and may be applied to any formulation ofstatistical machine translation which relies on parallelRound NumberTranslation Pair 0 1 2 3French?English 55.2 56.3 57.0 55.5Spanish?English 57.2 57.8 57.6 56.9German?English 45.1 46.3 47.4 47.6Italian?English 53.8 54.0 53.6 53.5Portuguese?Eng 55.2 55.2 55.7 54.3Table 1: Co-training results over three roundscorpora for its training data.3.2 EvaluationThe performance of translation models was evaluated us-ing a held-out set of 1,000 sentences in each language,with reference translations into English.
Each translationmodel was used to produce translation of these sentencesand the machine translations were compared to the ref-erence human translations using word error rate (WER).The results are reported in terms of increasing accuracy,rather than decreasing error.
We define accuracy as 100minus WER.Other evaluation metrics such as position independentWER or the Bleu method (Papineni et al, 2001) couldhave been used.
While WER may not be the best measureof translation quality, it is sufficient to track performanceimprovements in the following experiments.3.3 Co-trainingTable 1 gives the result of co-training using the mostaccurate translation from the candidate translations pro-duced by five translation models.
Each translation modelwas initially trained on bilingual corpora consisting ofaround 20,000 human translated sentences.
These trans-lation models were used to translate 63,000 sentences, ofwhich the top 10,000 were selected for the first round.At the next round 53,000 sentences were translated andthe top 10,000 sentences were selected for the secondround.
The final candidate pool contained 43,000 trans-lations and again the top 10,000 were selected.
The tableindicates that gains may be had from co-training.
Eachof the translation models improves over its initial trainingsize at some point in the co-training.
The German to En-glish translation model improves the most ?
exhibiting a2.5% improvement in accuracy.The table further indicates that co-training for ma-chine translation suffers the same problem reported inPierce and Cardie (2001): gains above the accuracy ofthe initial corpus are achieved, but decline as after a cer-tain number of machine translations are added to thetraining set.
This could be due in part to the mannerin items are selected for each round.
Because the besttranslations are transferred from the candidate pool to the2727.52828.52929.530 10000150002000025000300003500040000Accuracy (100 - Word Error Rate)Training Corpus Size (number of sentence pairs)Coaching of GermanFigure 3: ?Coaching?
of German to English by a Frenchto English translation model43.84444.244.444.644.84545.2 100000150000200000250000300000350000400000Accuracy (100 - Word Error Rate)Training Corpus Size (number of sentence pairs)Coaching of GermanFigure 4: ?Coaching?
of German to English by multipletranslation modelstraining pool at each round the number of ?easy?
trans-lations diminishes over time.
Because of this, the av-erage accuracy of the training corpora decreased witheach round, and the amount of noise being introducedincreased.
The accuracy gains from co-training mightextend for additional rounds if the size of the candidatepool were increased, or if some method were employedto reduce the amount of noise being introduced.3.4 CoachingIn order to simulate using co-training for language pairswithout extensive parallel corpora, we experimented witha variation on co-training for machine translation thatwe call ?coaching?.
It employs two translation modelsof vastly different size.
In this case we used a Frenchto English translation model built from 60,000 humantranslated sentences and a German to English translationmodel that contained no human translated sentences.
TheGerman-English translation model was meant to repre-sent a language pair with extremely impoverished paral-lel corpus.
Coaching is therefore a special case of co-training in that one view (the superior one) never retrainsupon material provided by the other (inferior) view.A German-English parallel corpus was created by tak-ing a French-German parallel corpus, translating theFrench sentences into English and then aligning the trans-lations with the German sentences.
In this experiment themachine translations produced by the French?Englishtranslation model were always selected.
Figure 3 showsthe performance of the resulting German to English trans-lation model for various sized machine produced parallelcorpora.We explored this method further by translating 100,000sentences with each of the non-German translation mod-els from the co-training experiment in Section 3.3.
Theresult was a German-English corpus containing 400,000sentence pairs.
The performance of the resulting modelmatches the initial accuracy of the model.
Thus machine-translated corpora achieved equivalent quality to human-translated corpora after two orders of magnitude moredata was added.The graphs illustrate that increasing the performanceof translation models may be achievable using machinetranslations alone.
Rather than the 2.5% improvementgained in co-training experiments wherein models of sim-ilar sizes were used, coaching achieves an 18%(+) im-provement by pairing translation models of radically dif-ferent sizes.4 Discussion and Future WorkIn this paper we presented two methods for the automaticcreation of additional parallel corpora.
Co-training uses anumber of different human translated parallel corpora tocreate additional data for each of them, leading to modestincreases in translation quality.
Coaching uses existingresources to create a fully machine translated corpora ?essentially reverse engineering the knowledge present inthe human translated corpora and transferring that to an-other language.
This has significant implications for thefeasibility of using statistical translation methods for lan-guage pairs for which extensive parallel corpora do notexist.A setting in which this would become extremely use-ful is if the European Union extends membership to anew country like Turkey, and wants develop translationresources for its language.
One can imagine that sizableparallel corpora might be available between Turkish and afew EU languages like Greek and Italian.
However, theremay be no parallel corpora between Turkish and Finnish.Our methods could exploit existing parallel corpora be-tween the current EU language and use machine transla-tions from Greek and Italian in order to create a machinetranslation system between Turkish and Finnish.We plan to extend our work by moving from co-training and its variants to another weakly supervisedlearning method, active learning.
Active learning incor-porates human translations along with machine transla-tions, which should ensure better resulting quality thanusing machine translations alone.
It will reduce the costof creating a parallel corpus entirely by hand, by selec-tively and judiciously querying a human translator.
Inorder to make the most effective use of the human trans-lator?s time we will be required to design an effective se-lection algorithm, which is something that was neglectedin our current research.
An effective selection algorithmfor active learning will be one which chooses those exam-ples which will add the most information to the machinetranslation system, and therefore minimizes the amountof time a human needs to spend translating sentences.ReferencesSteve Abney.
2002.
Bootstrapping.
In Proceedings ofthe 40th Annual Meeting of the Association for Com-putational Linguistics.Yaser Al-Onaizan, Ulrich Germann, Ulf Hermjakob,Kevin Knight, Philipp Koehn, Daniel Marcu, and Ya-mada Kenji.
2000.
Translating with scarce resources.In Proceedings of the National Conference on ArtificialIntelligence (AAAI).Adam Berger, Peter Brown, Stephen Della Pietra, Vin-cent Della Pietra, John Gillett, John Lafferty, RobertMercer, Harry Printz, and Lubos Ures.
1994.
TheCandide system for machine translation.Avrim Blum and Tom Mitchell.
1998.
Combining la-beled and unlabeled data with co-training.
In Proceed-ings of the Workshop on Computational Learning The-ory.Peter Brown, Stephen Della Pietra, Vincent Della Pietra,and Robert Mercer.
1993.
The mathematics of ma-chine translation: Parameter estimation.
Compuata-tional Linguistics, 19(2):263?311, June.Philip Clarkson and Ronald Rosenfeld.
1997.
Statisticallanguage modeling using the CMU-Cambridge toolkit.In ESCA Eurospeech Proceedings.Mitchell P. Marcus, Beatrice Santori, and Mary AnnMarcinkiewicz.
1993.
Building a large annotated cor-pus of English: the Penn Treebank.
ComputationalLinguistics, 19.Franz Joseph Och and Herman Ney.
2000.
Improved sta-tistical alignment models.
In Proceedings of the 38thAnnual Meeting of the Association for ComputationalLinguistics, pages 440?447, Hong Kong, October.Franz Joseph Och and Herman Ney.
2001.
Statisticalmulti-source translation.
In MT Summit 2001, pages253?258, Santiago de Compostela, Spain, September.Franz Joseph Och, Christop Tillmann, and Hermann Ney.1999.
Improved alignment models for statistical ma-chine translation.
In Proceedings of the Joint Confer-ence of Empirical Methods in Natural Language Pro-cessing and Very Large Corpora, College Park, Mary-land, June.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2001.
Bleu: a method for automatic eval-uation of machine translation.
IBM Research Report,September.David Pierce and Claire Cardie.
2001.
Limitations ofco-training for natural language learning from largedatasets.
In Proceedings of the 2001 Conference onEmpirical Methods in Natural Language Processing.Philip Resnik.
1998.
Parallel strands: A preliminaryinvestigation into mining the web for bilingual text.In Third Conference of the Association for MachineTranslation in the Americas.Michel Simard.
1999.
Text-translation alignment:Aligning three or more versions of a text.
In JeanVeronis, editor, Parallel Text Processing.
Kluwer Aca-demic.Noah Smith.
2002.
From words to corpora: Recognizingtranslation.
In Proceedings of the 2002 Conference onEmpirical Methods in Natural Language Processing,Philadelphia, Pennsylvania.
