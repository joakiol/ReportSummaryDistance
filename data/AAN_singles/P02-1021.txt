Semi-Supervised Maximum Entropy Based Approach to Acronym andAbbreviation Normalization in Medical TextsSerguei Pakhomov, Ph.D.Mayo Foundation, Rochester, MNpakhomov.sergey@mayo.eduAbstractText normalization is an importantaspect of successful informationretrieval from medical documentssuch as clinical notes, radiologyreports and discharge summaries.
Inthe medical domain, a significant partof the general problem of textnormalization is abbreviation andacronym disambiguation.
Numerousabbreviations are used routinelythroughout such texts and knowingtheir meaning is critical to dataretrieval from the document.
In thispaper I will demonstrate a method ofautomatically generating training datafor Maximum Entropy (ME) modelingof abbreviations and acronyms andwill show that using ME modeling is apromising technique for abbreviationand acronym normalization.
I reporton the results of an experimentinvolving training a number of MEmodels used to normalizeabbreviations and acronyms on asample of 10,000 rheumatology noteswith ~89% accuracy.1 Introduction and BackgroundText normalization is an important aspect ofsuccessful information retrieval frommedical documents such as clinical notes,radiology reports and discharge summaries,to name a few.
In the medical domain, asignificant part of the general problem oftext normalization is abbreviation andacronym1 disambiguation.
Numerousabbreviations are used routinely throughoutsuch texts and identifying their meaning iscritical to understanding of the document.The problem is that abbreviations are highlyambiguous with respect to their meaning.For example,  according to UMLS?2 (2001),RA may stand for ?rheumatoid arthritis?,?renal artery?, ?right atrium?, ?right atrial?,?refractory anemia?, ?radioactive?, ?rightarm?, ?rheumatic arthritis,?
etc.
Liu et al(2001) show that 33% of abbreviationslisted in UMLS are ambiguous.
In additionto problems with text interpretation,Friedman, et al (2001) also point out thatabbreviations constitute a major source oferrors in a system that automaticallygenerates lexicons for medical NLPapplications.Ideally, when looking for documentscontaining ?rheumatoid arthritis?, we wantto retrieve everything that has a mention ofRA in the sense of ?rheumatoid arthritis?but not those documents where RA means?right atrial.?
In a way, abbreviationnormalization problem is a special case ofthe word sense disambiguation (WSD)problem.
Modern approaches to WSDinclude supervised machine learningtechniques, where some amount of training1 To save space and for ease of presentation, I willuse the word ?abbreviation?
to mean both?abbreviation?
and ?acronym?
since the two could beused interchangeably for the purposes described inthis paper.2 Unified Medical Language System?, a databasecontaining biomedical information and a toolsrepository developed at the National Library ofMedicine to help helath professionals as well asmedical informatics researchers.Computational Linguistics (ACL), Philadelphia, July 2002, pp.
160-167.Proceedings of the 40th Annual Meeting of the Association fordata is marked up by hand and is used totrain a classifier.
One such techniqueinvolves using a decision tree classifier(Black 1988).
On the other side of thespectrum, the fully unsupervised learningmethods such as clustering have also beensuccessfully used (Shutze 1998).
A hybridclass of machine learning techniques forWSD relies on a small set of hand labeleddata used to bootstrap a larger corpus oftraining data (Hearst 1991, Yarowski 1995).Regardless of the technique that is used forWSD, the most important part of the processis the context in which the word appears(Ide and Veronis 1998).
This is also true forabbreviation normalization.For the problem at hand, one way totake context into account is to encode thetype of discourse in which the abbreviationoccurs, where discourse is defined narrowlyas the type of the medical document and themedical specialty, into a set of explicit rules.If we see RA in a cardiology report, then itcan be normalized to ?right atrial?
;otherwise, if it occurs in the context of arheumatology note, it is likely to mean?rheumatoid arthritis?
or ?rheumaticarthritis.?
This method of explicitely usingglobal context to resolve the abbreviationambiguity in suffers from at least threemajor drawbacks from the standpoint ofautomation.
First of all, it requires adatabase of abbreviations and theirexpansions linked with possible contexts inwhich particular expansions can be used,which is an error-prone labor intensive task.Second, it requires a rule-based system forassigning correct expansions to theirabbreviations, which is likely to becomefairly large and difficult to maintain.
Third,the distinctions made between variousmeanings are bound to be very coarse.
Wemay be able to distinguish correctly between?rheumatoid arthritis?
and ?right atrial?since the two are likely to occur in clearlyseparable contexts; however, distinguishingbetween ?rheumatoid arthritis?
and ?rightarm?
becomes more of a challenge and mayrequire introducing additional rules tofurther complicate the system.The approach I am investigating fallsinto the hybrid category of bootstrapping orsemi-supervised approaches to trainingclassifiers; however, it uses a differentnotion of bootstrapping from that of Hearst(1991) and Yarowski (1995).
Thebootstrapping portion of this approachconsists of using a hand crafted table ofabbreviations and their expansions pertinentto the medical domain.
This should not beconfused with dictionary or semanticnetwork approaches.
The table ofabbreviations and their expansions is just asimple list representing a one-to-manyrelationship between abbreviations and theirpossible ?meanings?
that is used toautomatically label the training data.To disambiguate the ?meaning?
ofabbreviations I am using a MaximumEntropy (ME) classifier.
Maximum Entropymodeling has been used successfully in therecent years for various NLP tasks such assentence boundary detection, part-of-speechtagging, punctuation normalization, etc.
(Berger 1996, Ratnaparkhi 1996, 1998,Mikheev 1998, 2000).
In this paper I willdemonstrate using Maximum Entropy for amostly data driven process of abbreviationnormalization in the medical domain.In the following sections, I will brieflydescribe Maximum Entropy as a statisticaltechnique.
I will also describe the process ofautomatically generating training data forME modeling and present examples oftraining and testing data obtained from amedical sub-domain of rheumatology.Finally, I will discuss the training andtesting process and present the results oftesting the ME models trained on twodifferent data sets.
One set contains oneabbreviation per training/testing corpus andthe other -- multiple abbreviations percorpus.
Both sets show around 89%accuracy results when tested on the held-outdata.2 Clinical DataThe data that was used for this studyconsists of a corpus of ~10,000 clinicalnotes (medical dictations) extracted atrandom from a larger corpus of 171,000notes (~400,000 words) and encompassesone of many medical specialties at the MayoClinic ?
rheumatology.
In the Mayo Clinic?ssetting, each clinical note is a documentrecording  information pertinent to treatmentof a patient that consists of a number ofsubsections such as Chief Complaint (CC),History of Present Illness (HPI),Impresssion/Report/Plan (IP), FinalDiagnoses (DX)3, to name a few.
In clinicalsettings other than the Mayo Clinic, thenotes may have different segmentation andsection headings; however, most clinicalnotes in most clinical settings do have somesort of segmentation and contain some sortof discourse markers, such as CC, HPI, etc.,that can be useful clues to tasks such as theone discussed in this paper.
Theoretically, itis possible that an abbreviation such as PAmay stand for ?paternal aunt?
in the contextof Family History (FH), and ?polyarthritis?in the Final Diagnoses context.
MEtechnique lends itself to modelinginformation that comes from a number ofheterogeneous sources such as variouslevels of local and discourse context.3 MethodsOne of the challenging tasks in textnormalization discussed in the literature isthe detection of abbreviations in unrestrictedtext.
Various techniques, including ME,have proven useful for detectingabbreviations with varying degrees ofsuccess.
(Mikheev 1998, 2000, Park and3 This format is specific to the Mayo Clinic.
Probablythe most commonly used format outside of Mayo isthe so-called SOAP format that stands for Subjective,Objective, Assessment, Plan.
The idea is the same,but the granularity is lower.Byrd 2001) It is important to mention thatthe methods described in this paper aredifferent from abbreviation detection;however, they are meant to operate intandem with abbreviation detectionmethods.Two types of methods will bediscussed in this section.
First, I will brieflyintroduce the Maximum Entropy modelingtechnique and then the method I used forgenerating the training data for MEmodeling.3.1 Maximum EntropyThis section presents a brief description ofME.
A more detailed and informativedescription can be found in Berger (1996)4,Ratnaparkhi (1998), Manning and Shutze(2000) to name just a few.Maximum Entropy is a relativelynew statistical technique to NaturalLanguage Processing, although the notion ofmaximum entropy has been around for along time.
One of the useful aspects of thistechnique is that it allows to predefine thecharacteristics of the objects being modeled.The modeling involves a set of predefinedfeatures or constraints on the training dataand uniformly distributes the probabilityspace between the candidates that do notconform to the constraints.
Since theentropy of a uniform distribution is at itsmaximum, hence the name of the modelingtechnique.Features are represented by indicatorfunctions of the following kind5:(1)??
?=== otherwiseycandxoifcoF ,0,1),(Where ?o?
stands for outcome and ?c?stands for context.
This function mapscontexts and outcomes to a binary set.
For4 This paper presents an Improved Iterative Scalingbut covers the Generalized Iterative Scaling as well.5 Borrowed from Ratnaparkhi implementation ofPOS tagger.example, to take a simplified part-of-speechtagging example, if y = ?the?
and x=?noun?,then F(o,c) = 1, where y is the wordimmediately preceding x.
This means that inthe context of ?the?
the next word isclassified as a noun.To find the maximum entropydistribution the Generalized IterativeScaling (GIS) algorithm is used, which is aprocedure for finding the maximum entropydistribution that conforms to the constraintsimposed by the empirical distribution of themodeled properties in the training data6.For the study presented in this paper, I usedan implementation of ME that is similar tothat of Ratnaparkhi?s and has beendeveloped as part of the open source Maxent1.2.4 package7.
(Jason Baldridge, TomMorton, and Gann Bierner,http://maxent.sourceforge.net).
In theMaxent implementation, features arereduced to contextual predicates,represented by the variable y in (1).
Just asan example, one of such contextualpredicates could be the type of discoursethat the outcome ?o?
occurs in:  PA paternal aunt | y = FH; PA  polyarthritis |y = DX.
Of course, using discourse markersas the only contextual predicate may not besufficient.
Other features such as the wordssurrounding the abbreviation in questionmay have to be considered as well.For this study two kinds of modelswere trained for each data set: local contextmodels (LCM) and combo (CM) models.The former were built by training on thesentence-level context only defined as twopreceding (wi-2,wi-1)  and  two following(wi+1,wi+2) words surrounding anabbreviation expansion.
The latter kind is amodel trained on a combination of sentenceand section level contexts defined simply as6 A consice step-by-step description and anexplanation of the algorithm itself can be found inManning and Shutze (2000).7 The ContextGenerator class of the maxent packagewas modified to allow for the features discussed inthis paper.the heading of the section in which anabbreviation expansion was found.3.2 Generating simulated training dataIn order to generate the training data,first, I identify potential candidates for  anabbreviation by taking the list of expansionsfrom a UMLS database and applying it tothe raw corpus of text data in the followingmanner.
The expansions for eachabbreviation found in the UMLS?s LRABRtable are loaded into a hash indexed by theabbreviation.ABBR EXPANSIONS FOUND INDATANR normal range; no radiation; norecurrence; no refill; nurse; nerveroot; no response; no report;nonreactive; nonresponderPA Polyarteritis; pseudomonasaeruginosa; polyarthritis;pathology; pulmonary artery;procainamide; paternal aunt; panicattack; pyruvic acid; paranoia;pernicious anemia; physicianassistant; pantothenic acid; plasmaaldosterone; periarteritisPN Penicillin; pneumonia; polyarteritisnodosa; peripheral neuropathy;peripheral nerve; polyneuropathypyelonephritis; polyneuritis;parenteral nutrition; positionalnystagmus; periarteritis nodosaBD band; twice a day; bundleINF Infection; infected; infusion;interferon; inferior; infant; infectiveRA Rheumatoid arthritis; renal artery;radioactive; right arm; right atrium;refractory anemia; rheumaticarthritis; right atrialTable 1.
Expansions found in the trainingdata and their abbreviations found inUMLS.The raw text of clinical notes is inputand filtered through a dynamic sliding-window buffer whose maximum windowsize is set to the maximum length of anyabbreviation expansion in the UMLS.
Whena match to an expansion is found, theexpansion and it?s context are recorded in atraining file as if the expansion were anactual abbreviation.
The file is fed to theME modeling software.
In this particularimplementation, the context of 7 words tothe left and 7 words to the right of the foundexpansion as well as the section label inwhich the expansion occurs are recorded;however, not all of this context ended upbeing used in this study.This methodology makes a reasonableassumption that given an abbreviation andone of it?s expansions, the two are likely tohave similar distribution.
For example, if weencounter a phrase like ?rheumatoidarthritis?, it is likely that the contextsurrounding the use of an expanded phrase?rheumatoid arthritis?
is similar to thecontext surrounding the use of theabbreviation ?RA?
when it is used to refer torheumatoid arthritis.
The followingsubsection provides additional motivationfor using expansions to simulateabbreviations.3.2.1 Distribution of abbreviations comparedto the distribution of their expansionsJust to get an idea of how similar are thecontexts in which abbreviations and theirexpansions occur, I conducted the followinglimited experiment.
I processed a corpus ofall available rheumatology notes (171,000)and recorded immediate contexts composedof words in positions {wi-1, wi-2 ,wi+1, wi+2}for one unambiguous abbreviation ?
DJD(degenerative joint disease).
Here wi iseither the abbreviation DJD or its multiwordexpansion ?degenerative joint disease.
?Since this abbreviation has only onepossible expansion, we can rely entirely onfinding the strings ?DJD?
and ?degenerativejoint disease?
in the corpus without havingto disambiguate the abbreviation by hand ineach instance.
For each instance of thestrings ?DJD?
and ?degenerative jointdisease?, I recorded the frequency withwhich words (tokens) in positions wi-1, wi-2,wi+1 and wi+2 occur with that string as well asthe number of unique strings (types) in thesepositions.It turns out that ?DJD?
occurs 2906times , ?degenerative joint disease?
occurs2517 times.
Of the 2906 occurrences ofDJD, there were 204 types that occurredimmediately prior to mention of DJD (wi-1position) and 115 types that occurredimmediately after (wi+1 position).
Of the2517 occurrences of ?degenerative jointdisease?, there were 207 types that occurredimmediately prior to mention of theexpansion (wi-1 position) and 141 words thatoccurred immediately after (wi+1 position).The overlap between DJD and its expansionis 115 types in wi-1 position and 66 types inwi+1 position.
Table 2 summarizes the resultsfor all four {wi-1, wi-2 ,wi+1, wi+2} positions.Context ContextoverlapN ofuniquecontextsContextsimilarity(%)Wi-1DJD 115 204 56degen.
joint dis 115 207 55Mean 55.5Wi+1DJD 66 115 50degen.
joint dis 66 141 46Mean 48Wi-2DJD 189 371 50degen.
joint dis 189 410 46Mean 48Wi+2DJD 126 245 51degen.
joint dis 126 301 41Mean 46Total 49.37Table 2.
DJD vs. ?degenerative jointdisease?
distribution comparison.On average, the overlap between thecontexts in which DJD and ?degenerativejoint disease?
occur is around 50%, which isa considerable number because this overlapcovers on average 91% of all occurrences inwi-1 and wi+1 as well as wi-2 and wi+2positions.3.2.2 Data setsOne of the questions that arose duringimplementation is whether it would be betterto build a large set of small ME modelstrained on sub-corpora containing contextfor each abbreviation of interest separatelyor if it would be more beneficial to train onemodel on a single corpus with contexts formultiple abbreviations.This was motivated by the idea thatME models trained on corpora focused on asingle abbreviation may perform moreaccurately; even though such approach maybe computationally expensive.ABBR N OF UMLSEXPANSIONSN OFOBSERVEDEXPANSIONSNR 23 10PA 72 15PN 28 11BD 30 3INF 13 7RA 28 8Mean 32.33 9Table 3.
A comparison between UMLSexpansions for 6 abbreviations and theexpansions actually found in the trainingdata.For this study, I generated two sets ofdata.
The first set (Set A) is composed oftraining and testing data for 6 abbreviations(NR, PA, PN, BD, INF, RA), where eachtraining/testing subset contains only oneabbreviation per corpus.
resulting in sixsubsets.
Table 1 shows the potentialexpansions for these abbreviations that wereactually found in the training corpora.Not all of the possible expansionsfound in the UMLS for a givenabbreviations will be found in the text of theclinical notes.
Table 3 shows the number ofexpansions actually found in therheumatology training data for each of the 6abbreviations listed in Table 1 as well as theexpansions found for a given abbreviation inthe UMLS database.The UMLS database has on average3 times more variability in possibleexpansions that were actually found in thegiven set of training data.
This is notsurprising because the training data wasderived from a relatively small subset of10,000 notes.The other set (Set B) is similar to thefirst corpus of training events; however, it isnot limited to just one abbreviation sampleper corpus.
Instead, it is compiled oftraining samples containing expansions from69 abbreviations.
The abbreviations toinclude in the training/testing were selectedbased on the following criteria:a. has at least two expansionsb.
has 100-1000 training data samplesThe data compiled for each set andsubset was split at random in the 80/20fashion into training and testing data.
Thetwo types of ME models (LCM and CM)were trained for each subset on 100iterations through the data with no cutoff(all training samples used in training).4 TestingTo summarize the goals of this study, one ofthe main questions in this study is whetherlocal sentence-level context can be usedsuccessfully to disambiguate abbreviationexpansion.
Another question that naturallyarose from the structure of the data used forthis study is whether more global section-level context indicated by section headingssuch as ?chief complaint?, ?history ofpresent illness?
,  etc., would have an effecton the accuracy of predicting theabbreviation expansion.
Finally, the thirdquestion is whether it is more beneficial toconstruct multiple ME models limited to asingle abbreviation.
To answer thesequestions, 4 sets of tests were conducted:1.
Local Context Model and Set A2.
Combo Model and Set A3.
Local Context Model and Set B4.
Combo Model and Set B4.1 ResultsTable 3 summarizes the results of trainingLocal Context models with the data fromSet A (one abbreviation per corpus).ABBR Acc.(%)TestEventTrainEventsOut.
Predic.NR 87.87 139.6 495.7 10.8 580.4PN 77.05 166.2 612.7 11 722.5BD 98.49 174.4 724.6 3 704.8PA 86.45 182.8 653.3 13.9 707.1INF 87.33 196.2 819.3 6.9 950.3RA 97.67 924.6 2535 7.6 1549.4Mean 89.14 297.3 973.43 8.87 869.08Table 3.
Local Context Model and Set AresultsThe results in Table 3 show that, on average,after a ten-fold cross-validation test, theexpansions for the given 6 abbreviationshave been predicted correctly 89.14%.ABBR Acc.(%)TestEventTrainEventsOut.
Predic.NR 89.515 139.6 504.6 10.8 589.4PN 78.739 166.2 618.7 11 746.1BD 98.39 174.4 736.6 3 713.8PA 86.193 182.8 692.2 13.9 717INF 87.409 196.2 842.3 7 959.8RA 97.693 924.6 2704 7.6 1559.4Mean 89.66 297.3 1016.4 8.88 880.92Table 4.
Combo Model and Set A resultsTable 3 as well as table 4 display theaccuracy, the number of training and testingevents/samples, the number of outcomes(possible expansions for a givenabbreviation) and the number of contextualpredicates averaged across 10 iterations ofthe cross-validation test.Table 4 presents the results of theCombo approach with the data also from SetA.
The results of the combined discourse +local context approach are only slightlybetter that those of the sentence-level onlyapproach.Table 5 displays the results for the setof tests performed on data containingmultiple abbreviations ?
Set B but contraststhe Local Context Model with the ComboModel.Acc.(%)TestEventTrainEventOut.
Pred.LCM 89.169 ~4791 ~21999 ~250 ~9400CM 89.015 ~4792 ~22000 ~251 ~9401Table 5.
Local Context Modelperformance contrasted to Combo modelperformance on Set BThe first row shows that the LCM modelperforms with 89.17% accuracy.
CM?sresult is very close: 89.01%.
Just as withTables 3 and 4, the statistics reported inTable 5 are averaged across 10 iterations ofcross-validation.5 DiscussionThe results of this study suggest that usingMaximum Entropy modeling forabbreviation disambiguation is a promisingavenue of research as well as technicalimplementation for text normalization tasksinvolving abbreviations.
Severalobservations can be made about the resultsof this study.
First of all, the accuracyresults on the small pilot sample of 6abbreviations as well as the larger samplewith 69 abbreviations are quite encouragingin light of the fact that the training of theME models is largely unsupervised8.8 With the exception of having to have a database ofacronym/abbreviations and their expansions whichhas to be compiled by hand.
However, once such listis compiled, any amount of data can be used fortraining with no manual annotation.Another observation is that itappears that using section-level context isnot really beneficial to abbreviationexpansion disambiguation in this case.
Theresults, however, are not by any meansconclusive.
It is entirely possible that usingsection headings as indicators of discoursecontext will prove to be beneficial on alarger corpus of data with more than 69abbreviations.The abbreviation/acronym database inthe UMLS tends to be more comprehensivethan most practical applications wouldrequire.
For example, the Mayo Clinicregards the proliferation of abbreviationsand acronyms with multiple meanings as aserious patient safety concern and makesefforts to ensure that only the ?approved?abbreviations (these tend to have lowerambiguity) are used in clinical practice,which would also make the task of theirnormalization easier and more accurate.
Itmay still be necessary to use a combinationof the UMLS?s and a particular clinic?sabbreviation lists  in order to avoid missingoccasional abbreviations that occur in thetext but have not made it to the approvedclinic?s list.
This issue also remains to beinvestigated.6 Future WorkIn the future, I am planning to testthe assumption that abbreviations and theirexpansions occur in similar contexts bytesting on hand-labeled data.
I also plan tovary the size of the window used fordetermining the local context from twowords on each side of the expression inquestion as well as the cutoff used duringME training.
It will also be necessary toextend this approach to other medical andpossibly non-medical domains with largerdata sets.
Finally, I will experiment withcombining the UMLS abbreviations tablewith the Mayo Clinic specific abbreviations.ReferencesBaldridge, J., Morton, T., and Bierner, G URL:http://maxent.sourceforge.netBerger,  A., Della Pietra, S., and Della Pietra, V.(1996).
A maximum entropy approach tonatural language processing.
ComputationalLinguistics, 22(1):39-71.Black, E. (1988).
An experiment in computationaldiscrinmination of English word senses.IBM Journal of Research and Development,32(2), 185-194.Friedman, C., Liu, H., Shagina, L., Johnson, S. andHripcsack, G. (2001) Evaluating the UMLSas a Source of Lexical Knowledge forMedical Language Processing.
In ProcAMIA 2001.Hearst, M. (1991).
Noun homograph disambiguationusing local context in large text corpora.
InProc.
7th Annual Conference of theUniversity of Waterloo Center for the newOED and Text Research, Oxford.Ide, N and Veronis, J.
(1998).
Word sensedisambiguation: the state of the art.Computational Linguistics, 24(1).Liu, H., Lussier, Y., and Friedman, C. (2001) AStudy of Abbreviations in UMLS.
In Proc.AMIA 2001.Mikheev, A.
(2000).
Document Centered Approachto Text Normalization.
In Proc.
SIGIR2000.Mikheev, A.
(1998).
Feature Lattices for MaximumEntropy Modeling.
In Proc.
ACL 1998.Manning, C. and Shutze H. (1999).
Foundations ofStatistical Natural Language Processing.MIT Press, Cambridge, MA.Park, Y and Byrd, R. (2001).
Hybrid text Mining forFinding Abbreviations and their Definitions.In Proc.
EMNLP 2001.Ratnaparkhi A.
(1996).
A maximum entropy part ofspeech tagger.
In Proceedings of theconference on empirical methods in naturallanguage processing, May 1996, Universityof PennsylvaniaRatnaparkhi A.
(1998).
Maximum Entropy Modelsfor Natural Language AmbiguityResolution.
Ph.
D. Thesis, U of Penn.Jurafski D. and Martin J.
(2000).
Speech andLanguage Processing.
Prentice Hall, NJ.Yarowski, D. (1995).
Unsupervised word sensedisambiguation rivaling supervisedmethods.
In Proc.
ACL-95, 189-196.UMLS.
(2001).
UMLS Knowledge Sources (12thed.).
Bethesda (MD) : National Library ofMedicine.
