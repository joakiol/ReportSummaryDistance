Proceedings of the SIGDIAL 2014 Conference, pages 208?217,Philadelphia, U.S.A., 18-20 June 2014.c?2014 Association for Computational LinguisticsInteraction Quality Estimation in Spoken Dialogue Systems UsingHybrid-HMMsStefan UltesUlm UniversityAlbert-Einstein-Allee 4389081 Ulm, Germanystefan.ultes@uni-ulm.deWolfgang MinkerUlm UniversityAlbert-Einstein-Allee 4389081 Ulm, Germanywolfgang.minker@uni-ulm.deAbstractResearch trends on SDS evaluation arerecently focusing on objective assess-ment methods.
Most existing methods,which derive quality for each system-user-exchange, do not consider tempo-ral dependencies on the quality of pre-vious exchanges.
In this work, we in-vestigate an approach for determining In-teraction Quality for human-machine dia-logue based on methods modeling the se-quential characteristics using HMM mod-eling.
Our approach significantly outper-forms conventional approaches by up to4.5% relative improvement based on Un-weighted Average Recall metrics.1 IntroductionSpoken Dialogue Systems (SDSs) play a key rolein achieving natural human-machine interaction.One reason is that speech is one major chan-nel of natural human communication.
Assess-ing the quality of such SDSs has been discussedfrequently in recent years.
The basic principleswhich all approaches underlie have been analyzedby M?oller et al.
(2009) creating a taxonomy forquality of human-machine interaction, i.e., Qual-ity of Service (QoS) and Quality of Experience(QoE).
Quality of Service describes objective cri-teria like total number of turns.
The recent shift ofinterest in dialogue assessment methods towardssubjective criteria is described as Quality of Expe-rience, putting the user in the spotlight of dialogueassessment.
For QoE, M?oller et al.
(2009) iden-tified several aspects contributing to a good userexperience, e.g., usability or acceptability.
Theseaspects can be combined under the term user sat-isfaction, describing the degree by which the useris satisfied with the system?s performance.
By as-sessing QoE, the hope of the research communityis to better measure the human-like quality of anSDS.
While this information may be used duringthe design process, enabling automatically deriveduser satisfaction within the dialogue managementallows for adaption of the ongoing dialogue (Ulteset al., 2012b).First work on deriving subjective metrics au-tomatically has been performed by Walker etal.
(1997) resulting in the PARADISE framework,which is the current quasi-standard in this field.Briefly explained, a linear dependency is assumedbetween dialogue parameters and user satisfactionto estimate qualitative performance on the dia-logue level.Measuring the performance of complete dia-logues does not allow for adapting to the user dur-ing the dialogue (Ultes et al., 2012b).
Hence,performance measures which provide a measure-ment for each system-user-exchange1are of inter-est.
Approaches based on Hidden Markov Models(HMMs) are widely used for sequence modeling.Therefore, Engelbrecht et al.
(2009) used thesemodels for predicting the dialogue quality on theexchange level.
Similar to this, we presented workon estimating Interaction Quality using HMMsand Conditioned HMMs (Ultes et al., 2012a).
Inthis contribution, we investigate an approach forrecognizing the dialogue quality using a hybridMarkovian model.
Here, hybrid means combin-ing statistical approaches such as Support VectorMachines with Hidden Markov Models by model-ing the observation probability of the HMMs us-ing classification.
While this is the first time hy-brid approaches are used for estimating InteractionQuality, they are well-known and have been usedbefore for other classification tasks (e.g.
(Valstarand Pantic, 2007; Onaran et al., 2011)).This paper is outlined as follows: Related workon subjective quality measurement on the ex-1A system-user-exchange consists of a system dialogueturn followed by a user dialogue turn208change level is presented in Section 2.
All experi-ments in this work are based on the InteractionQuality metric of the LEGO corpus described inSection 3.
We motivate for introducing time de-pendency and present our own approach on rec-ognizing Interaction Quality using a Markovianmodel presented in Section 4 and briefly presentthe classification algorithms used for the experi-ments in Section 5.
Experiments are presented inSection 6 and their results discussion in Section 7.2 Significant Related WorkMuch research on predicting subjective qualitymeasures on an exchange level has been per-formed hitherto.
However, most of this body ofwork lacks of either taking account of the sequen-tial structure of the dialogue or resulting in insuf-ficient performance.Engelbrecht et al.
(2009) presented an approachusing Hidden Markov Models (HMMs) to modelthe SDS as a process evolving over time.
Perfor-mance ratings on a 5 point scale (?bad?, ?poor?,?fair?, ?good?, ?excellent?)
have been applied bythe users of the SDS during the dialogue.
The in-teraction was halted while the user rated.
A HMMwas created consisting of 5 states (one for eachrating) and a 6-dimensional input vector.
WhileEngelbrecht et al.
(2009) relied on only 6 inputvariables, we will pursue an approach with 29 in-put variables.
Moreover, we will investigate dia-logues of a real world dialogue system annotatedwith quality labels by expert annotators.Higashinaka et al.
(2010) proposed a model forpredicting turn-wise ratings for human-human di-alogues.
Ratings ranging from 1 to 7 were appliedby two expert annotators labeling for smooth-ness, closeness, and willingness.
They achievedan UAR2of only 0.2-0.24 which is only slightlyabove the random baseline of 0.14.Hara et al.
(2010) derived turn level ratings fromoverall ratings of the dialogue which were appliedby the users after the interaction on a five pointscale within an online questionnaire.
Using n-grams to model the dialogue by calculating n-gramoccurrence frequencies for each satisfaction valueshowed that results for distinguishing between sixclasses at any point in the dialogue to be hardlyabove chance.A more robust measure for user satisfaction hasbeen presented by Schmitt et al.
(2011) within2Unweighted Average Recall, see Section 6susususu?s 1u 1s 2u 2s 3u 3s nu n?e 1e 2e 3e nFigure 1: A dialogue may be separated into a se-quence of system-user-exchanges where each ex-change eiconsists of a system turn sifollowed bya user turn ui.their work about Interaction Quality (IQ) for Spo-ken Dialogue Systems.
In contrast to user satis-faction, the labels were applied by expert annota-tors after the dialogue at the exchange level.
Auto-matically derived parameters were used as featuresfor creating a statistical model using static fea-ture vectors.
Schmitt et al.
(2011) performed IQrecognition on the LEGO corpus (see Section 3)using linear SVMs.
They achieved an UAR2of0.58 based on 10-fold cross-validation which isclearly above the random baseline of 0.2.
Ulteset al.
(2012a) put an emphasis on the sequentialcharacter of the IQ measure by applying a Hid-den Markov Models (HMMs) and a ConditionedHidden Markov Models (CHMMs).
Both havebeen applied using 6-fold cross validation and areduced feature set of the LEGO corpus achievingan UAR2of 0.44 for HMMs and 0.39 for CHMMs.While Ultes et al.
(2012a) used generic GaussianMixture Models to model the observation proba-bilities, we use confidence distributions of staticclassification algorithms.3 The LEGO CorpusFor Interaction Quality (IQ) estimation, we use theLEGO corpus published by Schmitt et al.
(2012).Interaction Quality is defined similarly to user sat-isfaction: While the latter represents the true dis-position of the user, IQ is the disposition of theuser assumed by an expert annotator.
Here, ex-pert annotators are people who listen to recordeddialogues after the interactions and rate them byassuming the point of view of the actual personperforming the dialogue.
These experts are sup-posed to have some experience with dialogue sys-tems.
In this work, expert annotators were ?ad-vanced students of computer science and engineer-ing?
(Schmitt et al., 2011), i.e., grad students.The LEGO corpus is based on 200 calls to209s 1u 1s 2u 2s 3u 3s nu n?e 1e 2e 3e ne n?e n-1e n-2e 1e 2e 3e n+1?exchange levelparameterswindow level parameters: {#},{Mean}, etc.dialoguelevel parameters: #, Mean, etc.Figure 2: The three different modeling levels representing the interaction at exchange en: The mostdetailed exchange level, comprising parameters of the current exchange; the window level, capturingimportant parameters from the previous n dialog steps (here n = 3); the dialog level, measuring overallperformance values from the entire previous interaction.the ?Let?s Go Bus Information System?
of theCarnegie Mellon University in Pittsburgh (Raux etal., 2006) recorded in 2006.
Labels for IQ havebeen assigned by three expert annotators to 200calls consisting of 4,885 system-user-exchanges(see Figure 1) in total with an inter-annotatoragreement of ?
= 0.54.
This may be consideredas a moderate agreement (cf.
Landis and Koch?sKappa Benchmark Scale (1977)) which is quitegood considering the difficulty of the task that re-quired to rate each exchange.
For instance, if oneannotator reduces the IQ value only one exchangeearlier than another annotator, both already dis-agree on two exchanges.
The final label was as-signed to each exchange by using the median ofall three individual ratings.IQ was labeled on a scale from 1 (extremely un-satisfied) to 5 (satisfied) considering the completedialogue up to the current exchange.
Thus, eachexchange has been rated without regarding any up-coming user utterance.
As the users are expectedto be satisfied at the beginning, each dialogue?sinitial rating is 5.
In order to ensure consistent la-beling, the expert annotators had to follow labelingguidelines (Schmitt et al., 2012).An example of an annotated dialogue is shownin Table 5.
It starts off with a good IQ until thesystem provides some results and then falls drasti-cally as the user input does not correspond to whatthe system expects.
Thus, the system remains in aloop until the user reacts appropriately.Parameters used as input variables for the IQmodel have been derived from the dialogue systemmodules automatically for each exchange.
Fur-thermore, parameters on three levels have beencreated: the exchange level, the dialogue level,and the window level (see Figure 2).
As parame-ters like ASRCONFIDENCE (confidence of speechrecognition) or UTTERANCE (word sequence rec-ognized by speech recognition) can directly beacquired from the dialogue modules they consti-tute the exchange level.
Counts, sums, means,and frequencies of exchange level parameters frommultiple exchanges are computed to constitute thedialogue level (all exchanges up to the currentone) and the window level (the three previous ex-changes).4 Hybrid-HMMAs Schmitt et al.
(2011) model the sequentialcharacter of the data only indirectly by design-ing special features, our approach applies Marko-vian modeling to directly model temporal de-pendencies.
Temporal dependencies on previoussystem-user-exchanges are not taken into accountby Schmitt et al.
; only parameters derived fromthe current exchange are used.
However, we foundout that Interaction Quality is highly dependent onthe IQ value of the previous exchange.
Addingthe parameter IQprevdescribing the previous IQvalue to the input vector to the IQ model consist-ing of several parameters results in an extended in-put vector.
Calculating the Information Gain Ra-tio (IGR) of each parameter of the extended inputvector shows that IQprevachieves the highest IGRvalue of 1.0.
In other words, IQprevrepresents theparameter which contains the most information forthe classification task.While performing IQ recognition on the ex-tended features set using the annotated IQ valuesresults in an UAR of 0.82, rather using the esti-mated IQ value results in an UAR of only 0.43.Consequently, other configurations have to be in-vestigated.
Here, Markovian approaches offer aself-contained concept of using these temporal de-pendencies.
However, Ultes et al.
(2012a) showedthat applying neither a classical HMM nor a con-ditioned HMM yields results outperforming staticapproaches.Therefore, in this Section we present a Hybrid-210HMM approach, which is based on the classicalHMM and takes advantage of good performingexisting static classification approaches.
The clas-sical HMM, specifically used for time-sequentialdata, consists of a set of states S with transitionprobability matrix A and initial probability vec-tor pi over a set of observations B (also called vo-cabulary) and an observation function bqtdepen-dent on the state qt.
For calculating the proba-bility p(qt|Ot, ?)
of seeing observation sequenceOt= (o1, o2, .
.
.
, ot) while being in state qtattime t given the HMM ?, the Forward Algorithmis used:p(qt= sj|Ot, ?)
= ?t(j)=|S|?i=1?t?1(i)aijbj(ot) .
(1)Here, aijdescribes the transition probability oftransitioning from state sito state sj.
To finda suitable model ?, the HMM must be trained,for example, by using the Baum-Welch algorithm.Usually, the observation function bqtis modeledwith Gaussian mixture models (GMMs).
For moreinformation on general HMMs, please refer to Ra-biner et al.
(1989).For determining the most likely class ?
?tat timet, where each state j ?
S is associated with oneclass ?, the following equation is used:?
?t= arg maxj?t(j) .
(2)For applying an HMM while exploiting exist-ing statistical classification approaches, the obser-vation function bj(ot) is modeled by using con-fidence score distributions of statistical classifiers,e.g., a Support Vector Machine in accordance withSchmitt et al.
(2011) (see Section 5).
Furthermore,the transition function aijis computed by takingthe frequencies of the state transitions containedin the given corpus.
Therefore, an ergodic HMMis used comprising five states with each represent-ing one of the five IQ scores.Moreover, in SDSs, a system action act is per-formed at the end of each system turn.
This canbe utilized by adding an additional dependency onthis action to the state transition function aij.
Byaugmenting Equation 1, this results in?t(j) =|S|?i=1?t?1(i)aij,actbj(ot) .
(3)This refinement models differences in state tran-sitions evoked by different system actions, e.g.,a different transition probability is expected if aWAIT action is performed compared to a CONFIR-MATION.
Equation 3 is equal to the belief up-date equation known from the Partially Observ-able Markov Decision Process formalism (Kael-bling et al., 1998).Therefore, two versions of the Hybrid-HMMare evaluated: an action-independent version as inEquation 1 and an action-dependent version as inEquation 3.5 Classifier TypesFor modeling the observation probability bj(ot)ofthe hybrid HMM, multiple classification schemeshave been applied to investigate the influence ofobservation distributions with different character-istics on the overall performance.In general, classification means estimating aclass ??
to the given observation o by comparingthe class-wise probabilities p(?|o).
In this work,this probability may be used to model the observa-tion probability bj(o) of the HMM by the posteriorprobabilityp(?|o) = bj(o) (4)for j = ?.As not all classification algorithms provide aposterior probability, it may be replaced by theconfidence distribution.
A general description ofthe classification algorithms used in this work aredescribed in the following Section along with amotivation for the feature subset of the LEGO cor-pus used for estimating the Interaction Quality inthis work.5.1 Support Vector MachineFor a two class problem, a Support Vector Ma-chine (SVM) (Vapnik, 1995) is based on the con-cept of linear discrimination with maximum mar-gin by defining a hyperplane separating the twoclasses.
The estimated class ??
for observation vec-tor ~o is based on the sign of the decision functionk(~o) =N?i=1?iziK(~mi, ~o) + b , (5)where ~mirepresent support vectors defining thehyper plane (together with b), zithe known class~mibelongs to, ?ithe weight of ~mi, and K(?, ?)
a211kernel function.
The kernel function is defined asK(~m, ~m?)
= ??
(~m), ?(~m?)?
, (6)where ?
(~m) represents a transformation functionmapping ~m into a space ?
of different dimension-ality and ?
?, ??
defines a scalar product in ?.
Byusing the kernel function, the linear discrimina-tion may happen in a space of high dimensional-ity without explicitly transforming the observationvectors into said space.The SVM implementation which is used in thiscontribution is libSVM (Chang and Lin, 2011).
Asthis algorithm does not provide class probabilitiesdirectly, the respective confidence scores are used.5.2 Naive BayesFor deriving the posterior probability, the NaiveBayes classifier may be used.
It calculates the pos-terior probability P (?|o) of having class ?
whenseeing the n-dimensional observation vector ~o byapplying Bayes rule (Duda et al., 2001):P (?|~o) =p(~o|?)
?
P (?)p(~o).
(7)In general, observations, i.e., elements of theobservation vector, may be correlated with eachother and introducing independence assumptionsbetween these elements does usually not reflectthe true state of the world.
However, correlationsare often not very high thus simplifying the Bayesproblem has proved to result in reasonable perfor-mance.
This is utilized by the Naive Bayes classi-fier by assuming said independence thus calculat-ingp(~o|?)
=n?i=1p(oi|?)
.
(8)5.3 Rule InductionThe classification algorithm Rule Induction orRule Learner is based on the idea of defining rulesto assign classes ??
to observation vectors ~o.
In thiswork, the algorithm RIPPER (Repeated Incremen-tal Pruning to Produce Error Reduction) (Cohen,1995) is used where each rule consists of conjunc-tions of An= v, where Anis a nominal attribute,or Ac?
?,Ac?
?, where Acis a continuous at-tribute.
Each part of the observation vector ~o is re-flected by one of the attributes.
The basic processof the algorithm for generating rules is divided intothree steps: First, rules are grown by adding at-tributes to the rule.
Second, the rules are pruned.If the resulting rule set is not of sufficient perfor-mance, all training examples which are covered bythe generated rules are removed from the exampleset and a new rule is created.5.4 Feature selectionAs stated previously, all experiments are based onthe LEGO corpus presented in Section 3.
In orderto keep the presented results comparable to pre-vious work based on HMM and CHMM (Ultes etal., 2012a), a reduced parameter set is used.
Pa-rameters with constant values for most exchangeshave been excluded.
These would result in rowsof zeros during computation of the covariance ma-trices of the feature vectors, which are needed forHMM and CHMM classification.
A row of ze-ros in the covariance matrix will make it non-invertible, which will cause errors during the com-putation of the emission probabilities.Therefore, a feature set consisting of 29 inter-action parameters is used for both defining a base-line and for evaluating the Hybrid-HMM.
The setconsists of the following parameters (for an expla-nation of the features, please refer to (Schmitt etal., 2012)):Exchange Level ASRRECOGNITIONSTATUS, ACTIVITY-TYPE, ASRCONFIDENCE, ROLEINDEX, ROLENAME,UTD, REPROMPT?, BARGED-IN?, DD, WPST,WPUTDialogue Level MEANASRCONFIDENCE, #ASRREJEC-TIONS, #TIMEOUTS ASRREJ, #BARGEINS, %ASR-REJECTIONS, %TIMEOUTS ASRREJ, %BARGEINS,#REPROMPTS,%REPROMPTS, #SYSTEMQUESTIONSWindow Level #TIMEOUTS ASRREJ, #ASRREJEC-TIONS, #BARGEINS, %BARGEINS, #SYSTEMQUES-TIONS, MEANASRCONFIDENCE, #ASRSUCCESS,#RE-PROMPTFor act in Equation 3, the exchange level pa-rameter ACTIVITYTYPE is used which may takeone out of the four values ?Announcement?, ?Con-firmation?, ?Question?, or ?wait?.
Their distribu-tion within the LEGO corpus is depicted in Fig-ure 3.6 Experiments and ResultsAll experiments are conducted using 6-fold cross-validation3.
This includes the baseline approach3Six folds have been selected as a reasonable trade-off be-tween validity and computation time.21230662477326627401000200030004000AnnouncementConfirmationQuestionwaitFigure 3: Distribution of the four values for actin Equation 3 in the LEGO corpus.
While ?wait?occurs rarely, the other three main actions occur atroughly the same frequency.
(also producing the observation probabilities ofthe Hybrid-HMM approach) and the evaluation ofthe Hybrid-HMM.
For the latter, two phases ofcross-validation were applied.Interaction Quality estimation is done byusing three commonly used evaluation met-rics: Unweighted Average Recall (UAR), Co-hen?s Kappa (Cohen, 1960) and Spearman?sRho (Spearman, 1904).
These are also selectedas the same metrics have been used in Schmitt etal.
(2011) as well.Recall in general is defined as the rate of cor-rectly classified samples belonging to one class.The recall in UAR for multi-class classificationproblems with N classes recalliis computed foreach class i and then averaged over all class-wiserecalls:UAR =1NN?i=1recalli.
(9)Cohen?s Kappa measures the relative agree-ment between two corresponding sets of ratings.In our case, we compute the number of labelagreements corrected by the chance level of agree-ment divided by the maximum proportion of timesthe labelers could agree.
However, Cohen?sweighted Kappa is applied as ordinal scores arecompared (Cohen, 1968).
A weighting factor w isintroduced reducing the discount of disagreementsthe smaller the difference is between two ratings:w =|r1?
r2||rmax?
rmin|.
(10)Here, r1and r2denote the rating pair and rmaxand rminthe maximum and minimum ratings pos-sible.Table 1: Results for IQ recognition of the statis-tical classifiers: UAR, ?
and ?
for linear SVM,Bayes classification and Rule Induction.
?2repre-sents the variances of the confidence scores.UAR ?
?
?2SVM (linear) .495 .611 .774 .020Bayes .467 .541 .716 .127Rule Induction .596 .678 .790 .131Correlation between two variables describes thedegree by which one variable can be expressed bythe other.
Spearman?s Rho is a non-parametricmethod assuming a monotonic function betweenthe two variables (Spearman, 1904).6.1 BaselineAs baseline, we adapted the approach of Schmittet al.
(2011).
While they focused only on an SVMwith linear kernel, we investigate three differentstatic classification approaches.
Different clas-sifiers will produce different confidence distribu-tions.
These distributions will have different char-acteristics which is of special interest for evaluat-ing the Hybrid-HMM as will be discussed in Sec-tion 7.
The confidence characteristics are repre-sented by the variance of the confidence scores?2.
This variance is used as indicator for how cer-tain the classifier is about its results.
If one IQvalue has a high confidence while all others havelow confidence, the classifier is considered to bevery certain.
This also results in a high variance.Vice versa, if all IQ values have almost equal con-fidence indicates high uncertainty.
This will resultin a low variance.The classification algorithms, which have beenselected arbitrarily, are SVM with linear kernel,Naive Bayes, and Rule Induction (see Section 5).The results in Table 1 show that an SVM with lin-ear kernel (as used by Schmitt et al.
(2011)) per-forms second best with an UAR of 0.495 afterRule Induction with an UAR of 0.596.
The re-sults of the SVM differ from the results obtainedby Schmitt et al.
(UAR of 0.58) as we used a re-duced feature set while they used all available fea-tures.6.2 Hybrid-HMMFor evaluating the Hybrid-HMM on InteractionQuality recognition, three aspects are of inter-est.
Most prominent is whether the presented ap-proaches outperform the baseline, i.e., the clas-213?3.7%+4.0%?*+2.0%?*?2.3%+4.5%?*+2.1%?*+2.2%?*+4.1%?*+2.0%?
*?7?%?5?%?3?%?1?%+1?%+3?%+5?%SVM (linear)BayesRuleInductionAIADHCFigure 4: Relative difference of UAR in percent between the baseline performance and the Hybrid-HMM for the action-independent (AI), action-dependent (AD) and handcrafted (HC) transition matrix.Differences marked with an * are significant (Wilcoxon test (Wilcoxon, 1945), ?
< 0.05).Table 2: Results for the Hybrid-HMM approach:UAR, ?
and ?
for the action-independent (AI) andaction-dependent (AD) versions.UAR ?
?AI AD AI AD AI ADSVM (linear) .477 .484 .599 .598 .770 .771Bayes .486 .489 .563 .564 .737 .741Rule Induction .608 .609 .712 .714 .826 .824sifier which produces the observation probabili-ties.
Moreover, performance values of action-dependent approaches and action-independent ap-proaches are compared.
In addition, the results areanalyzed with respect to the characteristic of theconfidence distribution.For producing the confidence scores represent-ing the observation probabilities, the statisticalclassification algorithms presented in Section 6.1are used.
The initial distribution pi for each HMMwas chosen in accordance with the annotationguidelines of the LEGO corpus starting each di-alogue with an IQ score of 5 resulting inpi5= P (IQ = 5) = 1.0pi4= pi3= pi2= pi1= P (IQ 6= 5) = 0.0 .Results of the experiments with action-dependent(AD) and action-independent (AI) transition func-tion may be seen in Table 2.
Again, Rule Inductionperformed best with Naive Bayes on the secondand SVM on the third place.7 DiscussionWhile previous work on applying the HMM andCHMM for IQ recognition could not outperformthe baseline (Ultes et al., 2012a), Hybrid-HMMexperiments show a significant improvement inUAR, Cohen?s ?
and Spearman?s ?
for NaiveBayes and Rule Induction.
While performancedeclines for the linear SVM, this difference hasshown to be not significant.The relative difference of the Hybrid-HMMcompared to the respective baseline approachesusing an action-dependent and an action-independent transition matrix is depicted inFigure 4.
Improvement for the Bayes method wasthe highest significantly increasing UAR by up to4.5% relative to the baseline.
However, addingaction-dependency to the Hybrid-HMM does notshow any effect.
This may be a result of usingACTIVITYTYPE instead of the actual action.However, using the actual action would result inthe need for more data as it contains 45 differentvalues.
Significance for all results has beencalculated using the Wilcoxon test (Wilcoxon,1945) by pair-wise comparison of the estimatedIQ values of all exchanges.
All results except forthe decline in SVM performance are significantwith ?
< 0.05.Correlating the confidence variances shown inTable 1 with the improvements of the Hybrid-HMM reveals that for methods with a highvariance?and therefore with a greater certaintyabout the classification result?, an improvementcould be accomplished.
However, the perfor-214Table 3: Results of Hybrid-HMM with hand-crafted transition matrix of the action-independentversion.UAR ?
?SVM (linear) .506 .642 .797Bayes .487 .563 .734Rule Induction .608 .712 .825Table 4: Handcrafted transition matrix based onempirical data.PPPPPPfromto1 2 3 4 51 0.7 0.3 0 0 02 0.25 0.5 0.25 0 03 0 0.25 0.5 0.25 04 0 0 0.25 0.5 0.255 0 0 0 0.3 0.7mance declined for classification approaches witha low confidence variance, which can be seen as asign for uncertain classification results.While the results for Hybrid-HMM are encour-aging, creating a simple handcrafted transitionmatrix for the action-independent version shownin Table 4 achieved even more promising resultsas performance for all classifier types could be im-proved significantly compared to the baseline (seeTable 3).
The handcrafted matrix was created in away to smooth the resulting estimates as only tran-sitions from one IQ rating to its neighbors have aprobability greater than zero.
Drastic changes inthe estimated IQ value compared to the previousexchange are thus less likely.
The exact valueshave been derived empirically.
By applying thishandcrafted transition matrix, even SVM perfor-mance with linear kernel could be improved sig-nificantly by 2.2% in UAR (see Figure 4) com-pared to the baseline.For creating the Interaction Quality scores, an-notation guidelines were used resulting in certaincharacteristics of IQ.
Therefore, it may be as-sumed that the effect of exploiting the dependencyon previous states is just a reflection of the guide-lines.
While this might be true, applying a Hy-brid HMM for IQ recognition is reasonable as, de-spite the guidelines, the IQ metric itself is stronglyrelated to user satisfaction, i.e., ratings appliedby users (without guidelines), achieving a Spear-man?s ?
of 0.66 (?
< 0.01) (Ultes et al., 2013).8 ConclusionsAs previously published, approaches for recogniz-ing the Interaction Quality of Spoken DialogueSystems are based on static classification withouttemporal dependency on previous values, a Hy-brid Hidden Markov Model approach has been in-vestigated based on three static classifiers.
TheHybrid-HMM achieved a relative improvement upto 4.5% and a maximum of 0.61 UAR.
Analyz-ing the experiments revealed that, while an im-provement could be achieved with the Hybrid-HMM approach, handcrafting a transition modelachieved even better results as performance for allanalyzed classifier types could be improved signif-icantly.
Furthermore, applying the Hybrid-HMMapproach only yields improved performance if thebasic classifier itself has a high confidence aboutits results.Further research should be conducted investi-gating the question how the presented approach aswell as the Interaction Quality paradigm in generalwill generalize for different dialogue domains.
AsIQ is designed to be domain independent, it maybe expected that the Hybrid-HMM will be appli-cable for different dialogue domains as well.Finally, it is notable that rule induction outper-formed SVM approaches in the baseline by 10 per-centage points.
While this contribution does notfocus on this, analyzing the model may help in un-derstanding the problem of estimating InteractionQuality better, especially since rule-based recog-nition methods allow easy interpretation.AcknowledgmentsThis work was supported by the TransregionalCollaborative Research Centre SFB/TRR 62?Companion-Technology for Cognitive TechnicalSystems?
which is funded by the German Re-search Foundation (DFG).ReferencesChih-Chung Chang and Chih-Jen Lin.
2011.
LIB-SVM: A library for support vector machines.
ACMTransactions on Intelligent Systems and Technology,2:27:1?27:27.Jacob Cohen.
1960.
A coefficient of agreement fornominal scales.
In Educational and PsychologicalMeasurement, volume 20, pages 37?46, April.Jacob Cohen.
1968.
Weighted kappa: Nominal scaleagreement provision for scaled disagreement or par-tial credit.
Psychological bulletin, 70(4):213.William W. Cohen.
1995.
Fast effective rule induc-tion.
In Proceedings of the 12th International Con-215ference on Machine Learning, pages 115?123.
Mor-gan Kaufmann, July.Richard O. Duda, Peter E. Hart, and David G. Stork.2001.
Pattern Classification (2nd Edition).
Wiley-Interscience, 2 edition, November.Klaus-Peter Engelbrecht, Florian G?odde, Felix Har-tard, Hamed Ketabdar, and Sebastian M?oller.
2009.Modeling user satisfaction with hidden markovmodel.
In SIGDIAL ?09: Proceedings of the SIG-DIAL 2009 Conference, pages 170?177, Morris-town, NJ, USA.
ACL.Sunao Hara, Norihide Kitaoka, and Kazuya Takeda.2010.
Estimation method of user satisfaction us-ing n-gram-based dialog history model for spo-ken dialog system.
In Proceedings of the Seventhconference on International Language Resourcesand Evaluation (LREC?10), Valletta, Malta, May.ELRA.Ryuichiro Higashinaka, Yasuhiro Minami, KohjiDohsaka, and Toyomi Meguro.
2010.
Issues in pre-dicting user satisfaction transitions in dialogues: In-dividual differences, evaluation criteria, and predic-tion models.
In Spoken Dialogue Systems for Am-bient Environments, volume 6392 of Lecture Notesin Computer Science, pages 48?60.
Springer Berlin/ Heidelberg.L.
P. Kaelbling, M. L. Littman, and A. R. Cassandra.1998.
Planning and acting in partially observablestochastic domains.
Artificial Intelligence, 101(1-2):99?134.J.
R. Landis and G. G. Koch.
1977.
The measurementof observer agreement for categorical data.
Biomet-rics, 33(1):159?174, March.Sebastian M?oller, Klaus-Peter Engelbrecht, C. K?uhnel,I.
Wechsung, and B. Weiss.
2009.
A taxonomy ofquality of service and quality of experience of mul-timodal human-machine interaction.
In Quality ofMultimedia Experience, 2009.
QoMEx 2009.
Inter-national Workshop on, pages 7?12, July.Ibrahim Onaran, N Firat Ince, A Enis Cetin, and AvivaAbosch.
2011.
A hybrid svm/hmm based system forthe state detection of individual finger movementsfrom multichannel ecog signals.
In Neural Engi-neering (NER), 2011 5th International IEEE/EMBSConference on, pages 457?460.
IEEE.Lawrence R. Rabiner.
1989.
A tutorial on hiddenMarkov models and selected applications in speechrecognition.
Morgan Kaufmann Publishers Inc., SanFrancisco, CA, USA.Antoine Raux, Dan Bohus, Brian Langner, Alan W.Black, and Maxine Eskenazi.
2006.
Doing researchon a deployed spoken dialogue system: One yearof let?as go!
experience.
In Proc.
of the Interna-tional Conference on Speech and Language Process-ing (ICSLP), September.Alexander Schmitt, Benjamin Schatz, and WolfgangMinker.
2011.
Modeling and predicting quality inspoken human-computer interaction.
In Proceed-ings of the SIGDIAL 2011 Conference, Portland,Oregon, USA, June.
Association for ComputationalLinguistics.Alexander Schmitt, Stefan Ultes, and WolfgangMinker.
2012.
A parameterized and annotated cor-pus of the cmu let?s go bus information system.
InInternational Conference on Language Resourcesand Evaluation (LREC).Charles Edward Spearman.
1904.
The proof and mea-surement of association between two things.
Ameri-can Journal of Psychology, 15:88?103.Stefan Ultes, Robert ElChabb, and Wolfgang Minker.2012a.
Application and evaluation of a condi-tioned hidden markov model for estimating inter-action quality of spoken dialogue systems.
In Pro-ceedings of the 4th International Workshop on Spo-ken Language Dialog System (IWSDS), pages 141?150.
Springer, November.Stefan Ultes, Alexander Schmitt, and WolfgangMinker.
2012b.
Towards quality-adaptive spokendialogue management.
In NAACL-HLT Workshopon Future directions and needs in the Spoken DialogCommunity: Tools and Data (SDCTD 2012), pages49?52, Montr?eal, Canada, June.
ACL.Stefan Ultes, Alexander Schmitt, and WolfgangMinker.
2013.
On quality ratings for spoken dia-logue systems ?
experts vs. users.
In Proceedings ofthe 2013 Conference of the North American Chap-ter of the Association for Computational Linguis-tics: Human Language Technologies, pages 569?578.
ACL, June.Michel F. Valstar and Maja Pantic.
2007.
Combinedsupport vector machines and hidden markov mod-els for modeling facial action temporal dynamics.In Human-Computer Interaction, volume 4796 ofLecture Notes in Computer Science, pages 118?127.Springer Berlin Heidelberg.Vladimir N. Vapnik.
1995.
The nature of statisticallearning theory.
Springer-Verlag New York, Inc.,New York, NY, USA.Marilyn Walker, Diane Litman, Candace A. Kamm,and Alicia Abella.
1997.
Paradise: a frameworkfor evaluating spoken dialogue agents.
In Proceed-ings of the eighth conference on European chap-ter of the Association for Computational Linguistics,pages 271?280, Morristown, NJ, USA.
ACL.Frank Wilcoxon.
1945.
Individual comparisons byranking methods.
Biometrics bulletin, 1(6):80?83.216AppendixTable 5: Example of a dialogue annotated with Interaction Quality for each system-user-exchange.
Asthe system fails to interact properly with the user in the end, the IQ value drops down to one.
Utterancerepresents either the system utterance or the recognized user utterance.
(CallID 2061123000 of theLEGO corpus.
)Utterance IQS: Welcome to the CMU Let?s Go bus information system.U: 5S: To get help at any time, just say Help or press zero.U: 5S: What can I do for you?U: PENN AT BUTLER TIME IS IT IS THE CENTRE AT HIGHLAND FROM RUNS THE 61A EIGHT THIRTY 61B CAN?T OAKLAND 5S: Leaving from OAKLAND .
Is this correct?U: OAKLAND 4S: Leaving from OAKLAND .
Is this correct?U: YES 4S: RightU: - 4S: Where do you want to go?U: SQUIRREL HILL OF FIFTH AVENUE 4S: Going to FIFTH AVENUE .
Is this correct?U: YES 5S: AlrightU: - 5S: When do you wanna travel?U: SUNDAY 4S: At what time do you wanna travel?U: AT FIVE FOUR VERY ABOUT ELEVEN O?CLOCK 4S: Leaving at 11 a.m. .
Is this correct?U: YES 5S: RightU: - 5S: Hold on.
Let me check that for you.U: - 5S: OAKLAND and FIFTH AVENUE are both the same stop.
Please provide a different start or end point.U: - 3S: To ask about a different trip, you can say, start a new query.
If you are finished, you can say goodbye.U: 61A 2S: You can say start a new query, or goodbye.U: FIVE DUQUESNE 1S: To ask about a different trip, you can say, start a new query.
If you are finished, you can say goodbye.U: LAST THE NEXT 1S: You can say start a new query, or goodbye.U: START WH 1S: To ask about a different trip, you can say, start a new query.
If you are finished, you can say goodbye.U: THE 1S: You can say start a new query, or goodbye.U: THANK YOU QUERY ELEVEN BACK 1S: To ask about a different trip, you can say, start a new query.
If you are finished, you can say goodbye.U: GOODBYE 1S: Thank you for using the cmu Let?s Go Bus Information System.
Goodbye.U: - 1217
