Recognition AssistanceTreating Errors in Texts Acquired from Various Recognition ProcessesG?bor PR?SZ?KYMorphoLogicK?sm?rki u.
81118 Budapest, Hungaryproszeky@morphologic.huM?ty?s NASZ?DIMorphoLogicK?sm?rki u.
81118 Budapest, Hungarynaszodim@morphologic.huBal?zs KISMorphoLogicK?sm?rki u.
81118 Budapest, Hungarykis@morphologic.huAbstractTexts acquired from recognition sources?conti-nuous speech/handwriting recognition andOCR?generally have three types of errors re-gardless of the characteristics of the source inparticular.
The output of the recognition processmay be (1) poorly segmented or not segmented atall; (2) containing underspecified symbols (wherethe recognition process can only indicate that thesymbol belongs to a specific group), e.g.
shapecodes; (3) containing incorrectly identified sym-bols.
The project presented in this paper addressesthese errors by developing of a unified linguisticframework called the MorphoLogic RecognitionAssistant that provides feedback and correctionsfor various recognition processes.
The frameworkuses customized morpho-syntactic and syntacticanalysis where the lexicons and their alphabetscorrespond to the symbol set acquired from therecognition process.
The successful frameworkmust provide three services: (1) proper disambi-guated segmentation, (2) disambiguation for un-derspecified symbols, (3) correction for incorr-ectly recognized symbols.
The paper outlines themethods of morpho-syntactic and syntacticpost-processing currently in use.IntroductionRecognition processes produce a sequence of dis-crete symbols that usually do not entirely corre-spond to characters of printed text.
Further on, werefer to this sequence as an input sequence.1 A1 This framework is actually a second tier of the dataflow.
The user receives a black box providing linguis-tically sound and correctly recognized text.
Inside theblack box, the first tier performs the actual recognition,and the second tier carries out linguistic corrections anddisambiguation.unified linguistic framework must perform a trans-formation where (1) the symbols from the recogni-tion process are converted into characters of writtentext, and (2) the correlation between the originalanalog source and the result is the closest possible.A post-processing framework must not simplyperform a symbol-to-symbol conversion.
A directconversion is either impossible (phonetic symbolsof any kind do not directly correspond to printedcharacters) or insufficient (source symbols are un-derspecified or incorrectly recognized).
Mor-pho-lexical and syntactic models can help this pro-cess as they recognize elements of the language,extracting meaningful passages from the input se-quence.Lexical databases with fully inflected forms arefairly standard for speech recognition, mainlywhere a small closed vocabulary is used, and new,unknown or ad hoc word formations are not re-quired (Gibbon et al, 1997).
This procedure isconvenient in languages with very small inflection-al paradigms.
An example of a language with fewinflections is English, where, in general, threeforms exist for nouns and four for verbs.
English istherefore not a good example for illustrating in-flectional morphology.Agglutinative languages such as Turkish, Fin-nish or Hungarian, however, have complex inflec-tional and derivational morphology, with signifi-cantly more endings on all verbs, nouns, adjectivesand pronouns.
The number of endings increase thesize of a basic vocabulary by a factor of thousands.Algorithmic morphological techniques have beendeveloped for efficient composition of inflectedforms and to avoid a finite but unmanageable explo-sion of lexicon size.
Still, according to Althoff et al(1996), these techniques have not been applied toany significant extent in speech technology.In this paper, we describe the application of anew method based on morphology and partialparsing.
This method uses a unified error modelwith flexible symbol mapping, facilitating the useof any linguistic module with traditional ortho-graphic lexicons?for any recognition process(OCR, handwriting, speech recognition), even forhighly inflectional languages.
The integrated sys-tem uses our existing morpho-syntactic modulesand lexicons.1 The error modelThe linguistic correction framework must be a-ware of three classes of error sources occurring inthe input sequence: (1) poor or nonexistent seg-mentation, (2) underspecified symbols, (3) in-correctly recognised symbols.The input sequence does not appear in the formof written text.
It comprises of complex symbolcodes in a normalized format, where the codesclosely correspond to the signals recognized by theparticular recognition process.
In the case of OCRor handwriting recognition, this can be a shapecode such as <lower> indicating a group of char-acters.
With speech recognition, this is rather aphoneme code such as <e:>.
(Here we use thenotation of the proposed framework.)
Standardorthographic characters may also appear in the in-put sequence.With all types of recognition processes, thereexists no one-to-one mapping between the sym-bols of the input sequence (the input alphabet) andthe orthographic alphabet of the written text.
Thenumber of identified phonemes/phoneme comp-lexes or characters/character complexes does notprovide information about the number of charac-ters to be used in the output text.
2  Unlike intwo-level-morphology, the framework must pro-vide n-to-m character (symbol) mapping, where n?
m. Mapping between speech and text chunks ofdifferent length makes the system able to offer, forexample, consonant sequences instead of affricatesusually represented by single characters:me{ts,ts?}
 metsz, metssz(?engraves,slits,cuts?
in affirmative andimperative)2 An example: in OCR outputs, the letter ?m?
often oc-curs in place of the ?rn?
sequence.
The correction mo-dule must be able to transform single ?m?-s into ?rn?.With continuous speech recognition (and, thoughless frequently, continuous handwriting recogni-tion) it is even possible that a written segmentboundary?such as the end of a word or asentence?occurs within a symbol.
The frameworkmust be aware of these schemes as well.The following sections present each error classwith Hungarian examples to show the complexityof the linguistic model required by some languages.2 The basics: symbol mappingAtomic segments of input sequences are assumed toconsist of (underspecified) symbols (phone-mes/phoneme complexes, characters/charactercomplexes).
The correction framework must have adatabase of complex symbols?either phonemecodes or shape codes representing the classes ofunderspecified characters.
An obvious approach toacquire a database of phonetic description of stemsand suffixes (for morphological processing) isconverting the existing (orthographical) lexicon.However, this conversion is very complicated andmay result in an extremely large database.
Withspeech recognition, for example, all orthographicrepresentations must be converted into as manyphonetic allomorphs as possible, on the basis of agrapheme-sequence-to-phoneme-sequence conver-sion.
This set contains every allomorph where thefirst or the last phoneme of which is subject tocontextual change.
E.g.
k?t (?two?)
is converted to{ke?t, ke?ty}, because of palatalization before cer-tain words, like nyu?l (?rabbit?
).ke?tynyu?l  k?t ny?l (?two rabbits?
)As the above method has some obvious disadvan-tages, we decided to separate the symbol mappingfrom the linguistic processes.
We have created adatabase mapping the recognized symbols to allpossible orthographical characters/character se-quences.
In this scheme, the framework creates se-veral possible orthographical sequences from theinput sequence (implemented internally as a direc-ted acyclic graph for performance reasons).
Thecorrection framework then segments and validateseach sequence using ?traditional?
linguistic modu-les with the original orthographical lexicons.
Theconversion database uses a unified entry formatsuitable for all types of recognition processes.
Ex-ample:<ccs> ((<t>|((c|)c<s>)|)(c(<s>|)c<s>|ts))This is a phoneme conversion entry.
On the leftside, a phonetic code is listed in the unified inter-nal representation of the framework.
(Note thatthis input symbol is the result of a mapping fromthe output of the recognition module.)
On the rightside, there is a directed acyclic graph (more or lessa regular expression) describing all possible or-thographic representations of the single phoneticentity.This is the core idea of the framework: the se-parate conversion process provides for an openarchitecture where the framework can be attachedto any recognition process, and even the linguisticmodules are replaceable.3 Morpho-lexical segmentationFor the simplest example, let us assume that theinput sequence consists of phonetic symbols withno segmentation: however, pauses are indicated bythe recognition process.
The input sequence isprocessed symbol by symbol, and when the seg-menter encounters a potential segment boundary,registers it and checks if the phonetic processorsaw any pause, stress or other sign of segmentationat that particular position in the original speechsignal.
This might require some interaction withspeech recognizer, but for the sake of simplicity,now we describe the operation of the linguisticsubsystem only.The original architecture design devises theframework as a feedback service, one requestingfurther information from the recognition source.
Inthe current implementation, however, the correctionframework can be separated from the recognitionprocess, and provide corrected and disambiguatedtext without feedback to the recognition module.In the analysis process of the unsegmented sig-nal (see Figure 1), for example, the input slicevonate?r has three morpho-lexically equally likelysegmentations: von a t?r, vonat ?r, vonat?r.
Eitherthe acoustic signal contains information confirmingor rejecting any of them; or all of them will betemporarily kept, and the segmentation processitself will filter them out later on.
In Figure 1, afterreading some further symbols from the input, itbecomes clear that the only orthographically correctword boundary is between vonat and ?rkezik .4 Underspecified formsIt is quite common that the recognition processcannot perfectly identify segments in the originalsignal source.
These are the cases of underspeci-fication.
Let us assume that a speech recognitionNon-segmented phonetic input Proposed orthographic segmentationvvovon ...............................................................................vonvona..............................................................................von avonat.............................................................................vonatvonate?
..........................................................................vonat?vonate?r .........................................................................von a t?r, vonat ?r, vonat?rvonate?rkvonate?rkevonate?rkezvonate?rkezi ..................................................................vonat ?rkezivonate?rkezik ................................................................vonat ?rkezikvonate?rkezika...............................................................vonat ?rkezik avonate?rkezikamvonate?rkezikama?vonate?rkezikama?s ?
?
.................................................................vonat ?rkezik a m?svonate?rkezikama?s ?
?ovonate?rkezikama?s ?
?od ................................................................ vonat ?rkezik a m?sodvonate?rkezikama?s ?
?odi ............................................................... vonat ?rkezik a m?sodivonate?rkezikama?s ?
?odik ............................................................ vonat ?rkezik a m?sodikvonate?rkezikama?s ?
?odikvvonate?rkezikama?s ?
?odikva?vonate?rkezikama?s ?
?odikva?g .................................................... vonat ?rkezik a m?sodik v?gvonate?rkezikama?s ?
?odikva?ga?vonate?rkezikama?s ?
?odikva?ga?ny ............................................ vonat ?rkezik a m?sodik v?g?nyvonate?rkezikama?s ?
?odikva?ga?nyrvonate?rkezikama?s ?
?odikva?ga?nyra......................................... vonat ?rkezik a m?sodik v?g?nyraFigure 1.
Morpho-lexical segmentation of a Hungarian phonetic stringprocess is unable to identify the value of the binaryfeature VOICED.
In these cases, the linguisticsubsystem attempts to find orthographicallywell-formed morpho-lexical constructions for bothvoiced and voiceless variants of the phoneme inquestion.
In fact, underspecified forms of the inputsignal are represented either by lists of possiblecharacters?like set representations in two-levelmorphology (Koskenniemi, 1983):vona{t,d}e?rkezikama?s?
?odi{g,k}{v,f}a?ga?nyra(?train is arriving to the second platform?
)or by underspecified feature complexes:vonaDe?rkezikama?s?
?odiGVa?ga?nyrawhere D, G and V are d, g and v, respectively, butnot specified as voiced or voiceless.5 Using higher-level linguistic processesThe linguistic correction framework operates ra-ther inefficiently if it uses morpho-lexical proces-sing only.
This results in extreme ambiguity: nu-merous overgenerated orthographic patterns ap-pear with grammatically incorrect segmentation.Thus the process must be improved by addinghigher level linguistic analysis.
Currently, theframework uses partial syntax similar to the me-chanism applied in the Hungarian grammar che-cker module.
This partial syntax describes parti-cular syntactic phenomena in order to identify in-correct grammar beyond the word boundaries.A more efficient post-processing filter is beingdeveloped by applying the HumorESK parser mo-dule (Pr?sz?ky, 1996).
Figure 2 shows the possiblesegmentations of the morphology-only system.
Inthis figure, an asterisk marks syntactically non-mo-tivated word sequences filtered out by the partialsyntax or the full parser?operating as a higher-le-vel segmenter.In the first 10 segmentations, the personal pro-noun ti (2nd person, pl.)
does not agree with eitherthe verb ?r (3rd person, sing.)
or the verb ?rok (1stperson, sing.).
Syntactically the last twosegmentations can be accepted (but semanticallyand according to topic-focus articulation, Nr.
11 isbizarre).
In most cases it is true that thesegmentation containing the longest matches in theinput sequence is the best orthographical candidate.6 Further developmentMorpho-lexical and syntactic segmentation andcorrection can be very useful in improving thequality of ?traditional?
recognition sources.
How-ever, it is important to emphasize that the proposedframework would only support existing recognitionmethods (e.g.
likelihood-based mechanisms inspeech recognition) rather than replacing them.
Thecurrent breakdown of the framework makes no as-sumptions on the operation of the underlying re-cognition process, and does not prefer any methodsto any other.
In terms of architecture, the correctionframework?s operation is separated from the rec-ognition module.One of the aims of this project is, however, abetter interaction between the linguistic and the re-cognition subsystem.
As the first step, it requires astandard feedback interface (yet to be developed).Because the current implementation of the Mor-phoLogic Recognition Assistant framework doesnot make assumptions of the recognition subsys-tem, it cannot influence its operation.
A standardfeedback interface consists of a formalism for de-scribing the interaction between a recognitionsource and the correction framework, regardless ofthe characteristics of the recognition subsystem.Stub modules must be developed to communicatewith existing recognition systems.An example for the dialogue between a phoneticand linguistic subsystem: first, a superficial acous-tic-phonetic analysis offers some sequence ofunderspecified feature complexes, then the lin-guistic subsystem attempts to transform them intopotential orthographically correct units with surfaceword boundaries.
Finally, the phonetic systemInput: nyelve?setitsik?eti?rok1.
*nyel v?sz e ti cikket ?r ok2.
*nyel v?sz e ti cikket ?rok3.
*nyel v?sze ti cikket ?r ok4.
*nyel v?sze ti cikket ?rok5.
*nyelv ?sz e ti cikket ?r ok6.
*nyelv ?sz e ti cikket ?rok7.
*nyelv?sz e ti cikket ?r ok8.
*nyelv?sz e ti cikket ?r ok9.
*nyelv?sze ti cikket ?r ok10.
*nyelv?sze ti cikket ?rok11.
nyelv?szeti cikket ?r ok12.
nyelv?szeti cikket ?rok(?I am writing a linguistic paper.?
)Figure 2.
Syntactic filteringcontrols whether which of the offered segmen-tation points can be confirmed acoustically.7 ImplementationThe first version of the MorphoLogic RecognitionAssistant framework has been implemented alongwith a demonstration interface.
This applicationtakes symbolic codes of different recognizedsymbols (phonemes, OCR-read characters etc.
),and provides orthographical output.
It has beenprogrammed in C++ using MS Visual Studio 6.0,and runs on 32-bit Windows systems.
As servicemodules, the framework incorporates the Humor(morphological analyser), the Helyesebb (gram-matical validator), and the HumorESK (full parser)technologies.
With a standard programming in-terface, it is ready to be integrated with existingrecognition systems.ConclusionThis paper has introduced a framework for treatingcommon error classes occurring in the output ofvarious recognition sources.
We have shown thatdifferent types of recognition sources share thesame error types: namely, (1) poor or nonexistentsegmentation, (2) underspecified and (3) incor-rectly recognized symbols.Our proposed solution is a post-processingphase performed on the output of the recognitionsource, where morpho-lexical and syntactic mod-els validate (either accept or reject) differentorthographical candidates derived from a singlerecognized symbol sequence.The system is language independent and com-pletely data-driven: by replacing the databases, theMorphoLogic Recognition Assistant is imme-diately ready to work with a different language.For the Humor system, descriptions exist for sev-eral languages (Hungarian, English, German,Spanish, Czech, Polish and Romanian).
Syntaxdescriptions are under development for Hungarianand English (prototypes exist).The proposed framework seems promising forcontinuous recognition systems.
Its main advan-tage is the ease of application of any linguisticmodule, thanks to the separate symbol mappingprocess and the open architecture.
However, wemust emphasize again that the MorphoLogic Re-cognition Assistant supports existing recognitionsystems rather than replacing them.AcknowledgementsThis research was carries out within the frameworkof the IKTA-063/2000 Project supported by theHungarian Ministry of Education.ReferencesAlthoff, F., G. Drexel, H. L?ngen, M. Pampel & C.Schillo (1996).
The treatment of compounds in amorphological component for speech recog-nition.
In: D. Gibbon (ed.)
Natural languageprocessing and speech technology, 71-76,Mouton de Gruyter, Berlin, New YorkGibbon, D., R. Moore, R. Winski, eds.
(1997).Handbook of Standards and Resources forSpoken Language Systems.
Walter de GruyterPublishers, Berlin & New YorkKoskenniemi, K. (1983) Two-level morphology: Ageneral computational model for word-formrecognition and production.
University of Hel-sinki, Department of General Linguistics, Hel-sinki, FinlandNakayama, T. (1994).
Modeling Content Identi-fication from Document Images.
Proceedings ofthe 4th Applied Natural Language ProcessingConference, 22-27, Stuttgart, GermanyPr?sz?ky, G. (1994).
Industrial Applications ofUnification Morphology Proceedings of the 4thConference on Applied Natural LanguageProcessing, 157?159, Stuttgart, GermanyPr?sz?ky, G. (1996).
Humor: a MorphologicalSystem for Corpus Analysis First TELRISeminar on Language Resources and LanguageTechnology, 149?158, Tihany, HungaryPr?sz?ky, G. (1996).
Syntax As Meta-morphologyProceedings of COLING-96, Vol.2, 1123?1126,Copenhagen, DenmarkPr?sz?ky, G. & B. Kis (1999).
Agglutinative andOther (Highly) Inflectional Languages.
Pro-ceedings of the 37th Annual Meeting of the As-sociation for Computational Linguistics,261?268.
College Park, Maryland, USASibun, P. & Spitz, A. L. (1994).
Language Deter-mination: Natural Language Processing fromScanned Document Images.
Proceedings of the4th Applied Natural Language ProcessingConference, 15-21,Stuttgart, Germany
