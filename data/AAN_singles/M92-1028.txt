LANGUAGE SYSTEMS, INC .DESCRIPTION OF THE DBG SYSTEM AS USED FOR MUC-4Christine A .
MontgomeryBonnie Glover StallsRobert E. StumbergerNaicong LiRobert S. BelvinAlfredo Arnai zSusan B .
HirshLanguage Systems, Inc .6269 Variel Avenue, Suite FWoodland Hills, CA 91367(818) 703-5034Internet: chris@lsi .comINTRODUCTIONLSI's Data Base Generation (DBG) system is a syntax-driven natural language processing system that integrate ssyntax and semantics to analyze message text.
The goal of the DBG system is to perform full-scale lexical, syn-tactic, semantic, and discourse analyses of message text and produce a system-internal knowledge representatio nof the text that can serve as input to a downstream system or external data structure, such as the MUC-4 tem-plates.DBG's development has been based on analysis of large volumes of message traffic (thousands of Air Force an dArmy messages) in five domains .
The DBG internal knowledge representation has been mapped to external datastructures for purposes of data base update, expert system update, and fusion of message content with the con -tent of other messages and other information sources.
Although our research on natural language understandingsystems goes back almost 20 years, the actual implementations for the individual components of the system ar eall quite recent, generally occurring within the last two to five years.
The texts in the various domains rangefrom formal written messages to transcribed radiotelephone conversations.
The DBG system has been formallytested on previously unseen messages in three of the domains, with competitive tests against humans performingthe same task in two domains.
Recently, the system has been adapted to the Machine Aided Voice Translatio n(MAVT) project.
In this application, the system takes a "live" voice input sentence, uses a speech recognizer t oconvert it to written text, processes the written text, and generates a written translation of the sentence in the tar -get language.
This written output is then input to a speech generator to produce a voice translation of the origi-nal utterance .
The languages processed thus far by this version of the system are English and Spanish, wit htranslation in both directions.THE DBG SYSTEM MODULE SThe DBG system consists of a series of modules that process message text in stages, and each major level ofanalysis is contained in a separate module .
Processing is performed sequentially : the output of each module is atemporary data structure that serves as input to the succeeding module and is then available to all later modules .Each individual module contains domain-independent processing mechanisms and knowledge bases (rule sets) .These knowledge bases allow the incorporation of domain-sensitive features.
The modularity of the DBG sys-tem has allowed the individual components to be improved and in several cases completely redesigned withou trequiring changes in the underlying system architecture .Figure 1 shows the functional flow of the DBG system .
The processing modules are shown in boxes and th eknowledge bases which apply at each processing stage are shown in ovals.
The output of each processing stage197E4aMinoXU 0 (,)cvWU)L198is indicated at the top of the particular box (e .g., words/phrases) .The basic components of the DBG system are the preprocessing module, the lexical analysis module, the syntac-tic parse module, the semantic parse module, and the knowledge representation module .
These five modulesform the core of the Expected Inputs Subsystem, which handles known, well-formed input text .
The knowledgebases include the lexicon and morphological rules, the set of grammatical principles used to construct the syn-tactic parse trees, the concept hierarchy, the discourse rules, and the rules for mapping into external data struc-tures (e .g ., into the MUC-4 templates) for downstream applications .
Items in the lexicon are linked to nodes i nthe concept hierarchy.The DBG system also has the capability of handling unknown (i .e ., new or erroneous) data.
This is accom-plished in the Unexpected Inputs Subsystem (UX) .
The UX subsystem consists of modules that are integrate dinto the Expected Inputs Subsystem.
At the lexical level, the UX modules that can apply are the lexical unex-pected inputs module (LUX) and the word acquisition module (WAM).
At the syntactic parse level, partia lparses are acceptable as input to the semantic parse module.
At the knowledge representation level, the self -evaluation module (SEM), which records calls to the UX subsystem, scores the system on its performance .
Thefunctions of these various modules are described in the following section .DBG SYSTEM PROCESSING STAGE SAt the preprocessing stage, the message is first extracted from the message stream and the message text is seg-mented into distinct words and sentences .
In the version of the system used for MUC-4, text to be processed i sthen identified by means of an event word list and a result word list .
The event words are associated with th eprimary events of interest for the MUC-4 task, and result words are used to describe the results of those events .Sentences to be processed were selected using these lists.
The selection of sentence with result words depend son the presence of certain event words in other sentences in the message.
After the sentences are selected, th esuccessive lexical, syntactic parse, and semantic parse modules then analyze the individual sentences .In the DBG system, for each sentence the lexical definitions of the words and multi-word phrases are matche dwith items in the lexicon (or derived from Unexpected Input processing, as described below), yielding a lexica lanalysis for the sentence .
In the course of MUC-4 development, the size of the DBG lexicon was expanded, tomore than 15,000 (root-form) entries, with more than 14,000 inflected entries added after compilation, yielding atotal system lexicon size of almost 30,000 entries .
Each entry in the lexicon contains morphological informationconcerning any irregularities in form, morphosyntactic features pertaining to reference and agreement, sub -categorization features, selectional restrictions, and links into the concept hierarchy .
The output of this stage ofprocessing is a set of words and phrases with their associated lexical features, which is then passed to the syn-tactic parser.The parser is a principle-based parser that uses grammatical principles from Government-Binding Theory to con -struct a parse tree for each sentence being processed.
The parser combines a bottom-up, data-driven approach t oattaching incoming words into the parse tree, with a top-down expectation that a complete tree will be buil taround a verbal projection (Cp-Ip-Vp) .
The parser mechanism works by projecting incoming words to maxima lX-bar projections (three-level node-graphs), and then attempting to attach the projections into currently availabl e"docking locations" on the existing tree, using syntactic and semantic checks to validate the attachment .
Theparse structure which is built up through these attachments is represented as an acyclic, directed graph .
Themechanism itself can be thought of as a "window" which moves through the emerging parse-graph of the sen-tence, examining/attaching a pair of nodes at a time.
The parser places theta-role information (similar to caseframes) in properly attached verb-argument nodes.The parse structure/graph for a sentence is then passed to the semantic parse module which traverses the grap hto extract semantic elements and their relations based on the local graph structure, theta-role assignment, an dsemantic labels derived from the underlying concept hierarchy .Due to the close integration of syntactic and semantic checking required by the parsers, a facility is also pro-vided which reads integrated lexical/conceptual representations (human writable/readable) that are created by th elexicon developer and converts them into entries for the system-internal lexicon and concept hierarchy databases .This mechanism ensures that lexical entries containing syntactic data are properly linked to concept hierarchyentries containing semantic data .199At the knowledge representation stage, the sentential semantic parses of a message are searched for event an dentity data elements having the appropriate category and relations to other elements to instantiate output frames .At this stage data elements from more than one sentence may be combined in the output knowledge representa-tion, depending on the narrative structure of the messages in the particular domain .
The knowledge representa-tion is in the form of frame structures specifying the properties of events and entities and their relations to on eanother.
In particular, the hierarchical organization of these frames enables the explicit representation of the rela-tions of various events and entities to one another and degrees of certainty associated with those events .
Infor-mation implicit to the message is provided by a mechanism of inheritance built into the concept hierarchy sub-system.
The system in this way has the capability of incorporating into the knowledge representation generi cand domain information not explicitly contained in the message, thus representing a deeper understanding of themessage text.Discourse rules also apply at this stage of processing .
These rules relate primary events and results events t oone another in the knowledge representation frames .
We are also investigating the use of global variables totrack entities in the text, in particular the notion of "deictic center" (Rapaport et al 1989), which incorporatesthe notion of focus space (Sidner 1983), to track the objects of interest in discourse .
Deictic center is the focusof attention in the reader/listener's mental model of the ongoing discourse, which consists of at least the WHO,WHERE, and WHEN information about the event being depicted in the discourse.
It is the record that th ereader/listener keeps, at any point of the discourse, concerning who or what is being talked about in the currentdiscourse, as well as where and when an event or action is taking place .There are linguistic devices/cues which serve to establish the deictic center (such as explicit mentioning of adiscourse entity in a certain syntactic position and with a certain semantic role), to maintain the deictic cente r(such as the use of deictic verbs and adverbs, as well as pronominal forms), and to indicate the shift of the deic-tic center or the possibility of such shift (such as long referential distance, referential competition (Givon 1983) ,as well as the linguistic devices for establishing a new deictic center) .
Keeping track of the deictic center of thediscourse will contribute to finding the correct referent for anaphoric expressions in the discourse, understandin gthe overall event-situation structures (Webber 1987) of the discourse, as well as, in the context of MUC, the taskof event separation.
In particular, the shift of WHERE, WHEN, and/or the perpetrator WHO, in combinationwith some other factors, are signs indicating that the discourse has taken up a new event.
The deictic centerapproach is currently being implemented in our system.Another important aspect of discourse modeling which is being incorporated into our system involves the notio nof subjectivity/perspective and belief spaces (Banfield 1981, Rapaport 1986, Wiebe & Rapaport 1988) whichhave been applied to narrative discourse.
In the context of MUC, such notions are important for referent track-ing as well as event separation.
The key notion here is that a discourse may present an event not only from theperspective of the speaker/reporter (which guides the construction of the discourse model of the listener/reader) ,but also from the the perspective of an entity mentioned in the discourse, such as another reporting source .Things that are considered to be already in the deictic center in one perspective may not yet be in the deicticcenter of another perspective.
Therefore, although within one perspective, an event (or an entity participating inan event) which has already been introduced in the previous discourse would normally be referred to by adefinite NP or a pronoun, it may be referred to by an indefinite NP if the perspective of discourse has shifted (t oanother reporting source, for example) .
Taking the issue of perspective into consideration would prevent thesystem from incorrectly inferring that this event (or entity) is a new one because of the use of the indefinite NP.Another parameter relevant to event separation, which has already been implemented in our system concern scertain verbal acts such as confirmation .
Some speech act verbs such as "confirm" or "repeat" usually indicat ethat the event/entity mentioned in the embedded clause has already been introduced in the previous discourse ,even though it is referred to by an indefinite NP .A key feature of the system that increases its flexibility and provides a built-in means of extending the system tonew material is the Unexpected Inputs (UX) subsystem.
The UX subsystem, which is a fully integrated part ofthe DBG system, automatically handles new or erroneous material at all levels, including lexical, syntactic, andsemantic/discourse unexpected input.
At the same time, it tallies the number of times it is invoked, the numberof error hypotheses utilized, and the type and degree of deviance of the data it processes in order to provide theuser with a measure of its performance and a check on the system output.200The UX subsystem accomplishes its task by intelligently relaxing the well-formedness constraints on textual dat athat the system normally requires and by providing tools for adding new words to the system .
At the lexicallevel, the Lexical Unexpected input module (LUX) corrects errors by allowing partial matches between words i nthe text and the lexical entries stored in the lexicon .
These partial matches are based on a set of erro rhypotheses relating to typographical and Baudot code transmission errors .
New or unidentified material ispassed to the on-line Word Acquisition Module (WAMl) for preliminary classification by the user by means ofmenu selection ; alternatively, the system can operate in an autonomous mode, wherein a word class is assigne dbased on the system's morphological analysis of the word .
The new words can also be stored for later incor-poration into the system by means of a second, more extensive mode of the Word Acquisition Module (WAM2) ,which operates off-line to allow periodic lexicon update by the System Administrator .The processing of unknown syntactic material is fully integrated into the syntactic parser .
This module con-structs parse fragments using the same grammatical principles as the normal syntactic parser but allowing outpu tof other than complete sentences .
The semantic rules can then operate on these parse fragments, as well as o ncomplete parses, to extract meaningful data .
The function of the Parse Unexpected Input (PUX) module is t orecord whether the syntactic and semantic parses obtained for an individual sentence are partial or complete ,which contributes to the evaluation of how successfully the system has processed the message .At the discourse level, partial as well as complete semantic parses can be searched to instantiate the frames, o rtemplates as they are termed in the DBG system, of the internal knowledge representation .
The Template Unex-pected Inputs Module (TUX) allows certain conditions to be relaxed in applying the rules used for searching thesemantic parses, in order to try to fill the internal knowledge representation templates more completely .
TUXalso records for evaluation purposes the rules relaxed and any semantic cooccurrence anomalies detected.
Forthe MUC-4 task, the PUX and TUX modules were not in operation .
The scoring against correctly filled-inMUC-4 templates constituted the evaluation.
For other applications, however, a system-generated evaluation o fhow well the various modules of the system performed is extremely useful .
For this purpose, the Self-Evaluation Module (SEM) rates the overall UX processing by the UX Subsystem by combining reports for th eother UX modules and numerically rating the accuracy of processing performed by them .DBG runs on all Sun workstations (including Sun3, Sun4 and Sun386i models) under the SunOS (UNIX) operat-ing system using Quintus Prolog .FORMAL TESTING OF THE DBG SYSTEM AND EXTENSION TO NEW DOMAIN SWe have conducted formal tests of the DBG system on previously unseen messages from two domains, Spac eEvent and Long Range Air.
In these tests, the system's performance was measured in comparison both to idea loutput and to humans performing essentially the same task as the system -- extracting information from messagetext and generating application- oriented output templates(*) containing that information .
We then collected an devaluated the test data, including the output frames, SEM scores, and the processing time, and analyzed andcategorized the system errors .
For both domains, the mean percentage scores for correctly filled output vecto r(an application oriented output structure similar to the MUC templates) slots were above 90% .SAMPLE DBG PROCESSING FOR MUC-4 MESSAGE TST2-MUC4-004 8In this section, output data structures for the lexical analysis, syntactic parse, semantic parse, knowledgerepresentation modules, and the MUC-4 templates are given to illustrate some of the problems and some of th esuccesses that the DBG system had in processing messages for MUC-4.
We will track one sentence throug hprocessing, Sentence 13, "a 15-year-old niece of Merino's was injured ."
In general, the DBG system was suc-cessful in extracting information from the message and instantiating the internal DBG knowledge representatio nfor the sentences that it processed .
For a variety of reasons, primarily having to do with event merging, the sys-tem did not properly pass on and synthesize the information for the MUC-4 templates .
It generated too manytemplates that diffused the appropriate information .
This result reflects the state of implementation of the sys-tem at the time of testing, rather than the capability of the system as it currently operates and in the long term .
(*) It is important to note that the term "template" in the DBG system is a label for the generic message level semantic and pragmati crepresentational units, not an application-oriented structure like the MUC templates .
It is the glass box output or internal representationa loutput, as opposed to the MUC templates, which are black box outputs mapped to the external representation required by a givenapplication .201In the preprocessing stage, the sentence was selected for processing and identified as possibly containing infor-mation pertaining to the results of a critical event on the basis of the word "injured," which is part of the resul tword list described above.
The output of the lexical analysis module is shown in Figure 2.
The results of thelexical matching and morphological processing can be seen here .
Displayed are the lexical category, (e.g ., det,adj, noun, aux, etc .)
of the matched item, or its morphological category if morphological processing applied(e.g., past, pastpart) ; the stem form (which in many instances is the same as the text item) ; the parse features, ifany (e .g ., persname, cont(inuous), passive) that are used during syntactic parsing; the subcategorization features(e .g., strict(argp) for 'of', which means that it must be followed by an argument of some kind) ; tense and agree-ment features for auxiliaries (e .g ., '+agr', '-past') ; and links into the concept hierarchy (e.g ., family-member, for'niece ') .
Other features in the lexicon, such as the selectional restrictions are not displayed in the data structure ,but can be checked.1lxi(det,a,a, 0, [],[],[],[strict(gp,ap,np)],[], [],[art])2lxi(adj,' 15-year-old', '15-year-old',[], ],[],0,[strict(np)],[],0,[' 15-year-old'] )3lxi(noun,niece,niece,0,[],0,0,[opt(genp)],[],0,[family_ member])4lxi(of,of,of, 0, [], [],0,[strict(argp)],[],[],[of] )5lxi(noun,merino,merino,[persname],0,0,0,0,0,0,[surname] )6lxi(noun,"'s',"'s',0,[],0,0,[],0,0,['*thing*'] )7lxi(aux,was,was,[cont],0,0,[],[xp('-agr','-past')],['+agr','+past'],[],[was] )lxi(aux,was,was,[passive],0,0,0, [xp('-agr','+past')], ['+agr','+Past'], 0,[was] )lxi(past,was,be,0,[],0,0,[strict(pred(adj,np),pp)],[ '+agr ' , ' +past ' ],0,[be])8lxi(adj,inj ured,injured,0,0,0,0,[opt(np,infp)],0,0,[injured] )lxi(past,in jured,in jure,0,0, 0, 0, [strict(np)],['+agr','+past'],0,[in jure] )lxi(pastpart,injured,injure,[],[],0,0,[strict(np)],['-agr', ' +past '],[],[injure] )Figure 2 .
Lexicalization for Sentence 13 of Message TST2-MUC4-004 8A representation of the syntactic parse for Sentence 13 is shown in Figure 3 .
In this parse, the verb is deter-mined to be passive, as is shown by the creation of a voice node (Vcemax) .
The subject of the sentence isidentified as the object of the verb, which is evidenced in the '+3' index on the Dmax node dominating the sub-ject of the sentence as well as the trace (i.e., *empty*) constituent under the Dmax node that serves as th eobject of the verb ' injured .
'Cmax(Cbar(C ,Imax(Dmax+3(Dbar(D([a] :det) ,Amax(Abar(A([' 15-year-old'] :adj),Nmax(Nbar(N([niece]:noun),Genmax(Genbar(Gen([of] :of),Nmax(Nbar(N([merino] :noun nme),Nrnax(Nbar(N(["'s'] :noun))))))))))))) ,Ibar(I(+agr,+past) ,Vicemax(Vicebar(Aux([was]:aux),Vmax(Vbar(V([injured] :pastpart),Dmax+3(Dbar(D(*empty*))))))))))) .Figure 3.
Syntactic Parse for Sentence 13 of Message TST2-MUC4-0048The semantic parse is shown in Figure 4 .
In this data structure, the data elements are labeled syntactically andsemantically, and indexing displays the constituent structure of the sentence .
Also, the tense and voice of thesentence are identified .202fp297:'MAINPRED'('9 .0') ='SUBJECT'('9.1') ='DETERMINER'('9 .2') ='ADJECTIVE MODIFIER'('9 .2') ='NOUN/FAMILY_MEMBER'('9 .2') ='GEN PHRASE'('9 .2') ='GEN OBJECT'('9.3') ='NOUN QUALIFIER/PERSON'('9.4') ='NOUN/*THING*'('9 .4') ='TENSE'('9 .1') ='VOICE'('9 .1') ='RESULT'('9 .1') =Figure 4 .
Functional (Semantic) Parse for Sentence 13 of Message TST2-MUC4-0048Portions of the internal knowledge representation (DBG templates) of the second bombing are shown in Figur e5 .
According to the discourse rules, the attack with explosives in Sentence 11 of the message caused a n"explode" template to be generated as the "event_parent" of an "attack" template in the knowledge representa-tion, and both of these have the same agent ("guerrillas"), patient ("Merino's home), and location (San Salva-dor).
This results in the generation of a bombing MUC-4 template the physical target of which is Merino's hom e(see Figure 5).
The result template "injure" is not properly tied in to the explode/attack event, and so does no tappear in the MUC-4 template .Event explode [1 .8 ]e_quant : 1agent: [1 .9 .1 ]patient : [1 .9 .2]location: [1 .9 .3 ]loc_qualifier.
incompletion: PASTdefiniteness: indefiniteevent_parent : [1 .8]event child: [1 .9]Event attack[1 .9 ]e_quant: 1agent : [1 .9 .1]patient: [1 .9 .2]location : [1 .9 .3 ]loc_qualifier: i ncompletion: PASTdefiniteness: indefiniteeventgarent : [1 .8]'INDEX'('9 .1' )'INDEX'('9 .2' )a'15-year-old 'niece'INDEX'('9 .3' )'INDEX'('9 .4' )merino,,, s,'PAST ''PASSIVE 'injure203Entityclass:type:position:position_text :quantifier:definiteness :Entitytype :subtype:description :description text:quantifierdefiniteness:Entitycity:country:type:description :description_textResul te_quantpatient:completion:definiteness:Entitytype:subtype:description:description_textqualifier:quantifier.definiteness:Agent [1 .9.1 ]humanHUMANguerrill aguerrillasPLURALindefinit ePatient [1 .9.2]RESIDENCE*THING*homemerino 's home1indefiniteLocation [1 .9.3]san salvadorel salvadorCITYsan salvadorsan salvadorinjure [1 .10]1[1 .10.1 ]PASTindefinitePatient [1 .10.1 ]FAMILY MEMBERPERSONniece15-year-old niece of merino' s15-year-old1indefiniteFigure 5.
DBG Templates (Internal Knowledge Representation) of a Portion of Message TST2-MUC4-004 8The MUC-4 output template for the second bombing in Message TST2-MUC4-0048 is shown in Figure 6 .Because the event merging processes for the MUC-4 domain were not yet implemented at the time of testing ,we generated seven templates for Message TST-MUC4-0048, whereas only two were required .
Because theevents were not merged properly, some of the information that we extracted correctly was output to othe rMUC-4 templates than the two bombing templates that were the closest match to the correct templates for th e204scoring program .
For Message TST-MUC4-0048, we did in fact generate templates for the two bombing sreported in the message.
Unfortunately, the name and description of the human target ended up in spuriou sattack templates .
Also, some information that came through in the internal knowledge representation did no tappear in the MUC-4 templates because it was not properly linked to other information in the knowledg erepresentation .
A case in point is the injury of Merino's 15-year-old niece, which is represented in template s[1 .10] and [1 .10 .1], but is not linked to other template information and did not appear in any MUC-4 template .The Template Unexpected Input (TUX) Module described above has the capability of using means other thanthe normal links to determine the role of unused data.
Unfortunately, the TUX Module was not yet integratedinto the version of the DBG system that processed the MUC-4 test messages .
On the other hand, the physica ltarget, "Merino's home", was filled in correctly .0.
MESSAGE : IDTST2-MUC4-004 81.
MESSAGE : TEMPLATE62.
INCIDENT: DATE- 19 APR 893.
INCIDENT: LOCATIONEL SALVADOR: SAN SALVADOR (CITY)4.
INCIDENT: TYPEBOMBING5.
INCIDENT: STAGE OF EXECUTIONACCOMPLISHED6.
INCIDENT: INSTRUMENT ID7.
INCIDENT: INSTRUMENT TYPEBOMB8.
PERP: INCIDENT CATEGORYSTATE-SPONSORED VIOLENCE9.
PERP: INDIVIDUAL ID"GUERRILLAS "10.
PERP: ORGANIZATION I D11.PERP: ORGANIZATION CONFIDENCE REPORTED AS FACT12.PHYS TGT: ID"MERINO 'S HOME "13.PHYS TGT: TYPEFACILITY: "MERINO 'S HOME "14.PHYS TGT: NUMBER1 : "MERINO 'S HOME "15.
PHYS TGT: FOREIGN NATION-16.
PHYS TGT: EFFECT OF INCIDENTSOME DAMAGE: "MERINO 'S HOME"17.
PHYS TGT: TOTAL NUMBER18.
HUM TGT : NAME19.HUM TGT: DESCRIPTION20.
HUM TGT: TYPE21.
HUM TGT: NUMBER22.
HUM TGT: FOREIGN NATION23.
HUM TGT: EFFECT OF INCIDENT24.
HUM TGT: TOTAL NUMBERFigure 6.
MUC-4 Output Templates for Message TST2-MUC4-004 8We believe that in the DBG system we have the capability to solve the problems that we encountered in theMUC-4 test and to perform efficiently a deeper level of text analysis than that required for MUC-4 .
LSI's goalremains the construction of a true text understanding system .
Our continuing long-range research goals in theareas of syntactic parser development, lexical/semantic development, and discourse processing have contributed ,and will continue to contribute, to the success of this effort .REFERENCES[1] Banfield, Ann.
Unspeakable Sentences : Narration and Representation in the Language of Fiction.
Boston:Routledge & Kegan Paul .
1982.
[2] Givon, Talmy (ed.)
Topic Continuity in Discourse .
Amsterdam: Benjamins.
1979 .
[3] Montgomery, C .A., Glover Stalls, B ., Belvin .
R.S ., and R E. Stumberger "Language Systems, Inc .
:Description of the DBG System as Used for MUC-3" in `Proceedings, Third Message Understandin gConference (MUC-3)' pp.
171-177, Defense Advanced Research Projects Agency (DARPA), Morga nKaufmann Publishers, Inc ., San Mateo, CA, 1991 .205[4] Rapaport, William J .
"Logical Foundations for Belief Representation," Cognitive Science 10 : 371-422.1986.
[5] Rapaport, William J ., Erwin M. Segal, Stuart C. Shapiro, David, A .
Zubin, Gail A .
Bruder, Judith F .Duchan, David M. Mark .
"Cognitive and Computer Systems For Understanding Narrative Text ."
Techn-ical Report 89-07, Department of Computer Science, SUNY Buffalo .
1989 .
[6] Sidner, Candace L. "Focusing in the Comprehension of Definite Anaphora," in M. Brady & R. Berwick(eds .)
Computational Models of Discourse .
Cambridge, MA : MIT Press, 267-330 .
1983 .
[7] Webber, Bonnie L .
"The Interpretation of Tense in Discourse, " Proc .
25th Annual Meeting of the Asso-ciation for Computational Linguistics (Stanford Univ .)
.
Morristown, NJ : Association for ComputationalLinguistics, 147-154.
1987.
[8] Wiebe, Janyce M. & William J .
Rapaport.
"A Computational Theory of Perspective an Reference inNarrative," Proc.
26th Annual Meeting of the Association for Computational Linguistics (SUNY Buffalo) .Morristown, NJ : Association for Computational Linguistics, 133-138 .
1988 .206
