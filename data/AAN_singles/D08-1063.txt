Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 600?609,Honolulu, October 2008. c?2008 Association for Computational LinguisticsMention Detection Crossing the Language BarrierImed Zitouni and Radu FlorianIBM T.J. Watson Research Center1101 Kitchawan Rd, Yorktown Heights, NY 10598{izitouni, raduf}@us.ibm.comAbstractWhile significant effort has been put into an-notating linguistic resources for several lan-guages, there are still many left that haveonly small amounts of such resources.
Thispaper investigates a method of propagat-ing information (specifically mention detec-tion information) into such low resourcelanguages from richer ones.
Experimentsrun on three language pairs (Arabic-English,Chinese-English, and Spanish-English) showthat one can achieve relatively decent perfor-mance by propagating information from a lan-guage with richer resources such as Englishinto a foreign language alone (no resourcesor models in the foreign language).
Fur-thermore, while examining the performanceusing various degrees of linguistic informa-tion in a statistical framework, results showthat propagated features from English helpimprove the source-language system perfor-mance even when used in conjunction with allfeature types built from the source language.The experiments also show that using propa-gated features in conjunction with lexically-derived features only (as can be obtained di-rectly from a mention annotated corpus) yieldssimilar performance to using feature types de-rived from many linguistic resources.1 IntroductionInformation extraction is a crucial step toward un-derstanding a text, as it identifies the important con-ceptual objects and relations between them in a dis-course.
It includes classification, filtering, and se-lection based on the language content of the sourcedata, i.e., based on the meaning conveyed by thedata.
It is a crucial step for several applications,such as summarization, information retrieval, datamining, question answering, language understand-ing, etc.
This paper addresses an important and basictask of information extraction: mention detection1 :the identification and classification of textual refer-ences to objects/abstractions mentions, which can beeither named (e.g.
John Smith), nominal (the presi-dent) or pronominal (e.g.
he, she).
For instance, inthe sentencePresident John Smith said he has nocomments.there are three mentions: President, John Smith andhe.
This is similar to the named entity recognition(NER) task with the additional twist of also identi-fying nominal and pronominal mentions.A few languages have received a lot of attentionin terms of natural language resources that were cre-ated ?
for instance, in English one has access to la-beled part-of-speech data, word sense information,parse tree structure, discourse, semantic role labeles,named entity data, to name just a few (our apologiesif we missed your favorite resource).
There are a fewother languages that also have annotated resources(such as Arabic, Chinese, German, French, Spanish,etc), but also a very large number of languages withfew resources.
It would be very useful if one couldmake use of the resources in the former languagesto help bootstrapping (or just the projection) of re-source in any resource-challenged language.Information transfer from a language to anothercan be very useful when the ?donor?
language hasmore resources than the receiving one.
As resourcesgrow in quantity and quality in the receiving lan-guage, it becomes less and less likely that there willbe a gain in performance by transfering information,as there are several sources of noise involved in the1We adopt here the ACE (NIST, 2007) nomenclature600process - such as the translation (machine generatedor not) and the inherent imperfection of the mentiondetection in the donor language.
To test this hypoth-esis, we conducted experiments on systems buildwith a varied amount of resources in the receiv-ing language, starting with the case where there arenone2 (all information is transferred through transla-tion alignment), and ending with the case where weused all the resources we could gather for that lan-guage.
The experiments will show that the gain inperformance decreases with the amount of resourcesused in the source language, but, still, even when allresources were used, a statistically significant gainwas still observed.Similarly to classical NLP tasks such as textchunking (Ramshaw and Marcus, 1995) and namedentity recognition (Tjong Kim Sang, 2002), we for-mulate mention detection as a sequence classifica-tion problem, by assigning a label to each token inthe text, indicating whether it starts a specific men-tion, is inside a specific mention, or is outside anymentions.
The classification is performed with a sta-tistical approach, built around the maximum entropy(MaxEnt) principle (Berger et al, 1996), that has theadvantage of combining arbitrary types of informa-tion in making a classification decision.2 Previous WorkThere are several investigations in literature thatexplore using parallel corpora to transfer informa-tion content from one language (most of the timeEnglish) to another.
The earliest investigations ofthe subject have been performed, on word sensedisambiguation (Dagan et al, 1991; P.F.Brown etal., 1991; Gale et al, 1992) (perhaps unsurpris-ingly given its close connection to machine trans-lation) ?
all propose and (lightly) evaluate methodsto use word sense information extracted from thetarget language to help the sense resolution in thesource language and machine translation.
(Daganand Itai, 1994) explicitly suggests performing wordsense disambiguation in the target language (Englishin the article) with the goal of resolving ambiguity inthe source language (Hebrew), and show moderate2While applying this method in the case where the sourcelanguage has absolutely no resources might be an interestingtest case, we don?t see it as being realistic.
Resources are buildnowadays in a large variety of languages, and not making useof them is rather foolish (a certain big bird and sand comes tomind).improvement on a small data set3.
More recently,(Diab and Resnik, 2001) presents a method for per-forming word sense tagging in both the source andtarget texts of parallel bilingual corpora with the En-glish WordNet sense inventory, by using translationcorrespondences.On more general cross-language informationtransfer, (Yarowsky et al, 2001) proposed and eval-uated a method of propagating POS tagging, namedmention, base noun phrase, and morphological in-formation from English into a foreign language,which is very similar to the one presented in thisarticle (experiments were run on French, Chinese,Czech, and Spanish ?
on human-generated transla-tions).
Their results show a significant improvementin performance while building an automatic classi-fier on the projected annotations over the same au-tomatic classifier trained on a small amount of an-notated data in the source language.
(Riloff et al,2002) extends the ideas in (Yarowsky et al, 2001),by showing how it can be used, in conjunction withan automatically trained information extraction sys-tem on the source language, to bootstrap the annota-tion of resources in the target language.
They showthat they can obtain 48 F-measure on a informationextraction task identifying locations, vehicles andvictims in plane crashes.
(Hwa et al, 2002) proposesa framework that enables the acquisition of syntacticdependency trees for low-resource languages by im-porting linguistic annotation from rich-resource lan-guages (English).
The authors run a large-scale ex-periment in which Chinese dependency parses wereinduced from English, and show that a parser trainedon the resulting trees outperformed simple baselines.
(Cabezas et al, 2001) investigates a similar methodof propagating syntactic treebank-like annotationsfrom English to Spanish.Finally, a large body of research has been doneon cross-language information retrieval, where thegoal is to find information in one language (e.g.
Chi-nese newswire) corresponding to a query in a differ-ent language (e.g.
English) ?
although the list of rel-evant papers is too long to be mentioned here (see,for instance, (Grefenstette, 1998)).The work presented here differs from the infor-mation extraction investigations presented above intwo aspects:?
it handles unrestricted text and a full set of3Very small by ?modern?
standards - 137 examples.
Prob-ably because at the time the article was written, there were nolarge publicly annotated databases, such as Semcor.601mention types (the ACE entity types) during theinformation transfer?
it investigates whether using a resource-richlanguage (English) can improve on the perfor-mance obtained by using various degrees of ex-istent resources in the source language (Arabic,Chinese, Spanish)?
the information transfer is performed over ma-chine generated translations and alignments.3 Mention DetectionAs mentioned in the introduction, the mention detec-tion problem is formulated as a classification prob-lem, by assigning to each token in the text a label,indicating whether it starts a specific mention, is in-side a specific mention, or is outside any mentions.Good performance in many natural language pro-cessing tasks has been shown to depend heavily onintegrating many sources of information (Florian etal., 2004).4 Given this observation, we are interestedin algorithms that can easily integrate and make ef-fective use of diverse input types.
We select a ex-ponential classifier, the Maximum Entropy (MaxEnthenceforth) classifier that integrates arbitrary typesof information and makes a classification decisionby aggregating all information available for a givenclassification.
But the reader can replace it with herfavorite feature-based classifier throughout the pa-per.To help with the presentation, we introduce somenotations: let Y = {y1, .
.
.
, yn} be the set of pre-dicted classes, X be the example space and F ={0, 1}m be a feature space.
Each example x ?
Xhas associated a vector of m binary features f (x) =(f1 (x) , .
.
.
, fm (x)).
The goal of the training pro-cess is to associate examples x ?
X with eithera probability distribution over the labels from Y ,P (?|x)(if we are interested in soft classification) orassociate one label y ?
Y (if we are interested inhard classification).The MaxEnt algorithm associates a set of weights{?ij}i=1...nj=1...m with the features (fj)i, and computesthe probability distribution asP (yi|x) =1Z(x)m?j=1?fj(x,yi)ij , (1)Z(x) =?i?j?fj(x,yi)ij4In fact, the feature set used for classification has a muchlarger impact on the performance of the resulting system thanthe classifier method itself.where Z(x) is a normalization factor.
The{?ij}j=1...m weights are estimated during the train-ing phase to maximize the likelihood of thedata (Berger et al, 1996).
In this paper, the Max-Ent model is trained using the sequential condi-tional generalized iterative scaling (SCGIS) tech-nique (Goodman, 2002), and it uses a Gaussianprior for regularization (Chen and Rosenfeld, 2000).Now take xN1 = (x1, x2, .
.
.
xN ), a sequence ofcontiguous tokens (i.e., a sentence or a document) inthe source language.
The goal of mention detectionsystem is to find the most likely sequence of labelsyN1 = (y1, y2 .
.
.
yN ) that best matches the input xN1 .In the mention detection case, each token xi in xN1is tagged with a label yi as follows:5?
if it?s not part of any entity, yi = O (O for ?out-side any mentions?)?
if it is part of an entity, it is composed of a sub-tag specifying whether it starts a mention (B-)or is inside a mention (I-), and a sub-type cor-responding to mention type (e.g.
B-PERSON).In ACE, there are seven possible types: person,organization, location, facility, geopolitical en-tity (GPE), weapon, and vehicle.To compute the best sequence yN1 , we useyN1 = arg maxy?N1P(y?N1 |xN1)= arg maxy?
?P(y?j |xN1 , y?j?11)= arg maxy?
?jP(y?j |xN1 , yj?1j?k)where P(y?j|xN1 , yj?1j?k)has an exponential form ofthe type (2).
We also used the standard Markov as-sumption that the probability P(y?j|xN1 , y?j?11)onlydepends on the previous k classifications.
Thismodel is similar to the MEMM model (McCallumet al, 2000), but it does not separate the probabilityinto generation probabilities and transition probabil-ities, and, crucially, has access to ?future?
observedfeatures (i.e.
it can examine the entire xN1 sequence,though in practice it will only examine some smallpart of it) ?
which is one way of eliminating label5The mention encoding is the IOB2 encoding presented in(Tjong Kim Sang and Veenstra, 1999) and introduced by(Ramshaw and Marcus, 1994) for base noun phrase chunking.602bias observed by (Lafferty et al, 2001).6The experiments are run on four languages, partof the ACE-2007 evaluation (NIST, 2007): Arabic,Chinese, English and Spanish.7 Systems across thelanguages use a large range of features, includinglexical (words and morphs in a 3-word window, pre-fixes and suffixes of length up to 4 characters, Word-Net (Miller, 1995) for English), syntactic (POS tags,text chunks), and the output of other information ex-traction models.
These features were described in(Florian et al, 2004), and are not discussed here.
Inthis paper we focus on the examining the benefit ofcross-language mention propagation information inimproving mention detection systems.Besides generic types of features, we also haveimplemented language-specific features:?
In Arabic, blank-delimited words are com-posed of zero or more prefixes, followed by astem and zero or more suffixes.
Each prefix,stem or suffix is a token; any contiguous se-quence of tokens can represent a mention.
Sim-ilar to the approaches described in (Florian etal., 2004) and (Zitouni et al, 2005), we decidedto ?condition?
the output of the system on thesegmented data: the text is segmented first intotokens and classification is then performed ontokens.
The segmentation model is similar tothe one presented by (Lee et al, 2003) and ob-tains an accuracy of 98%.?
In Chinese text, unlike in Indo-European lan-guages, words neither are white-space delim-ited nor do they have capitalization markers.Instead of a word-based model, we build acharacter-based one, since word segmentationerrors can lead to irrecoverable mention detec-tion errors; Jing et al (2003) also observes thatcharacter-based models are better performingthan word-based ones.
Word segmentation in-formation is still useful and is integrated as anadditional feature stream.?
In English and in Spanish mention detectionsystems are similar to those described in (Flo-rian et al, 2004) where words are the tokens toclassify.6In fact their example of label bias can be trivially solvedby allowing the classifier to examine features for subsequentwords.7The ACE data has the nice property of being consistent inannotations across these languages.4 Cross-Language Mention PropagationThe approach proposed in this article requires amention detection system build in a resource-richlanguage, and a translation from the source lan-guage to the resource-rich language, together withword alignment.
This assumption is realistic: whiletruly parallel data (humanly created) might be inshort supply or harder to acquire, adapting statis-tical machine translation (SMT) systems from onelanguage-pair to another is not as challenging as itused to be (Al-Onaizan and Papineni, 2006).
Wealso find that there is a large number of parallelcorpora available these days which cover many lan-guage pairs.
For example, for the European Union?s23 official languages we find 253 language pairs;each document in one language might have to betranslated in all other 22 languages.
This is in ad-dition to parallel corpora one could get from books,including religious texts such as the Bible, that aretranslated to a large number of languages.
On theother hand, even though mention detection systemis important for many natural language processingapplications, we still find lack of mention-annotatedcorpora in many languages.
In the approach we pro-pose below, the annotated corpus used to train themention detection classifier does not have to be partof a parallel corpus.To start the process, we first use a SMT systemto translate the source unit (document or sentence)xN1 into the resource-rich language, yielding the se-quence ?M1 = (?1, ?2, .
.
.
?M ).
Taking the sequenceof tokens ?M1 as input, the MaxEnt classifier assignsa mention label to each token, building the label se-quence ?M1 = (?1, ?2 .
.
.
?M ).
Using the SMT-produced word alignment between source text xN1and translated text ?M1 (Koehn, 2004),we propagatethe target labels ?M1 to the source language build-ing the label sequence y?N1 = (y?1, y?2 .
.
.
y?N ).8 Asan example, if a sequence of tokens in the resource-rich language ?i?i+1?i+2 is aligned to xjxj+1 in thesource language and if ?i?i+1?i+2 is tagged as a lo-cation mention, then the sequence xjxj+1 can be la-beled as a location mention: B-LOC, I-LOC.
Hence,each token xi in xN1 is tagged with a correspondingpropagated label y?i in y?N1 , y?i = ?
(i, A, ?M1), whereA is the alignment between the source and resource-rich languages.
In cases when the alignment is 1-to-1 the function becomes the identity, but one canimagine different scenarios which can be used in8Or by using Giza++ if your favorite engine does not giveyou word alignment.603El soldado nepal?s fue baleado              por ex soldados haitianos cuando patrullaba la zona central de Haiti , inform?
Minustah .The Nepalese soldier was gunned down by former Haitian soldiers when patrullaba  the central area of Haiti , reported minustah .GPELOCPERGPEGPEPER ORGGPELOCGPEPERPERGPEFigure 1: Word alignment for a Spanish sentence and its English machine-translation.
The mention labels shown arethe gold-standard ones for Spanish and the automatically detected ones for English.
If mentions were to be propagatedfrom English to Spanish, the last mention would be a miss, due to the fact that the English mention detection failed toidentify ?minustah?
as an organization.many-to-many alignment cases.
The alignement weuse in this paper is 1-to-many ({1...n}) from thesource language (eg., Arabic) to the resource-richlanguage (e.g., English).
Once we use SMT wordalignment to propagate label sequence ?M1 of ?M1 tothe corresponding text xN1 in the target language, weend up with a sequence of labels y?N1 where for eachtoken xi in xN1 we attach its label y?i in y?N1 .
Hence,we label te entire span and if the strategy results intwo mentions where one contains the other, we elim-inate the inner one.Figure 1 displays the alignment between a Span-ish sentence and its English automatic translation.
Italso shows a good match between the gold-standardtags in Spanish and the automatically extracted tagsin English.There are three ways in which we propose usingthese propagated labels:1.
Consider y?N1 as the result of propagating thedetected mentions in the original text xN1 , basi-cally selecting yN1 = y?N1 .
This situation corre-sponds to a case where no resources (annotateddata) are available/needed on the source side,where the propagated labels are the output ofthe system.2.
Use the label sequence y?N1 as an additional fea-ture in the MaxEnt framework when predictingP(yj|xN1 , yj?1j?k), together with other featuresbuilt from resources available on the sourcelanguage.
We will call this model CDP (Con-text Dependent Propagation).3.
Starting with a large corpus (possibly includingthe training data), translate it into the resource-rich language and run mention detection.
Thenselect the word sequences in the source lan-guage associated with the found mentions inthe translation and add them to a machine-generated gazetteer G9.
This gazetteer G is thenused to construct features for classification.
Wewill call this model CIP (Context IndependentPropagation).From a runtime point of view, the CIP method hasthe advantage that there is no need to perform ma-chine translation, and it can incorporate data from avery large amount of text.
The CDP method, on theother hand, has the advantage that features are com-puted in context, and will not fire unless the corre-sponding mentions were found in the translated ver-sion (hence the name).
Of course, the CDP methodcan incorporate features generated in the dictionaryG.
The experimental section analyzes the impact ofeach of these techniques on mention detection taskperformance.5 ResourcesExperiments are conducted on the ACE 2007 datasets10, in four languages: Arabic, Chinese, English,and Spanish.
This data is selected from a varietyof sources (broadcast news, broadcast conversations,newswire, web log, newswire, conversational tele-phony) and is labeled with 7 types: person, organi-zation, location, facility, GPE (geo-political entity),vehicle and weapon.
Besides mention level informa-tion, also labeled are coreference between the men-tions, relations, events, and time resolution.Since the evaluation tests set are not publiclyavailable, we have split the publicly available train-ing corpus into an 85%/15% data split.
To facilitatefuture comparisons with work presented here, andto simulate a realistic scenario, the splits are createdbased on article dates: the test data is selected as thelatest 15% of the data in chronological order, in eachof the covered genres.
This way, the documents in9This is in fact a way to automatically construct a source-side mention dictionary.10Same data as for ACE 2008.604Language Training TestArabic 323 56Chinese 538 95English 499 100Spanish 467 52Table 1: Datasets size (number of documents)the training and test data sets do not overlap in time,and the content of the test data is more recent thanthe training data.
Table 1 presents the number ofdocuments in the training/test datasets for each ofthe four languages.While performance on the ACE data is usuallyevaluated using a special-purpose measure - theACE value metric (NIST, 2007), given that we areinterested in the mention detection task only, wedecided to use the more intuitive and popular (un-weighted) F-measure, the harmonic mean of preci-sion and recall.6 Resource-Rich LanguagesFrom the set of four languages in ACE 2007, wewill unsurprisingly select English as the resource-rich language.
Table 2 shows the performance ofmention detection systems in all 4 languages onecan obtain by using all available resources in thatlanguage, including lexical (words and morphs in a3-word window, prefixes and suffixes of length upto 4, WordNet (Miller, 1995) for English), syntac-tic (POS tags, text chunks), and the output of otherinformation extraction models.N P R FArabic 3566 83.6 76.8 80.0Chinese 4791 81.1 71.3 75.8English 8170 84.6 80.8 82.7Spanish 2487 79.1 73.5 76.2Table 2: Performance of Arabic, Chinese, English andSpanish mention detection systems.
Performance is pre-sented in terms of Precision (P), Recall (R), and F-measure (F).
The column (N) displays the number ofmentions in the test set.Results show that the English mention detectionsystem has a better performance when compared tosystems dealing with other languages such as Ara-bic, Chinese and Spanish.
These results are not un-expected since the English model has access to alarger training data and uses richer set of informa-tion such as WordNet (Miller, 1995) and the outputLanguage Pair BLEU ScoreArabic-English 0.55Chinese-English 0.32Spanish-English 0.55Table 3: BLEU performance of the SMT systems on the3 language pairsof a larger set of information extraction models.7 ExperimentsTo show the effectiveness of cross-language mentionpropagation information in improving mention de-tection system performance in Arabic, Chinese andSpanish, we use three SMT systems with very com-petitive performance in terms of BLEU11 (Papineniet al, 2002).To give an idea of the SMT performance, Table 3shows the performance of the translation systems onthe three language pairs, computed on standard testsets.
The Arabic to English SMT system is similar tothe one described in (Huang and Papineni, 2007); ithas 0.55 BLEU score on NIST 2003 Arabic-Englishmachine translation evaluation test set.
The Chi-nese to English SMT system has similar architectureto the one described in (Al-Onaizan and Papineni,2006).
This system obtains a score of 0.32 casedBLUE on NIST 2003 Arabic-English machine trans-lation evaluation test set.
The Spanish to EnglishSMT system is similar to the one described in (Lee etal., 2006); it has a 0.55 BLEU score on the final textedition of the European Parliament Plenary Speechcorpus in TC-STAR 2006 evaluation.
As mentionedearlier, these three SMT systems have very compet-itive performance and are ranked among top 2 sys-tems participating to NIST or TC-STAR evaluations.Also, the English mention detection system used forexperiments has an F-measure of 82.7 and that hasvery competitive results among systems participat-ing in the ACE 2007 evaluation.Experiments are conducted under several con-ditions in order to investigate the effectiveness ofour approach in improving mention detection sys-tem performance on languages with different levelsof resource availability (from simple to more com-plex):1. the system does not have access to any train-ing data in the source language (no resources11BLEU is an automatic measure for the translation qualitywhich makes good use of multiple reference translations.605needed besides the MT system);2. the system has access to only lexical informa-tion (information that can be directly derivedexclusively from mention-labeled text);3. the system has access to lexical and syntactic(e.g., POS tags, text chunks) information (re-quires mention-labeled text, and models to pre-dict POS tags, etc);4. the system that has access to lexical, syntactic,and semantic information (requires even moremodels and labeled data).The rest of this section examines in detail these fourcases.To measure whether the improvement in per-formance of a particular system over anotherone is statistically significant or not, we usethe stratified bootstrap re-sampling significancetest (Noreen, 1989).
This approach was used in thenamed entity recognition shared task of CoNNL-2002 (http://www.cnts.ua.ac.be/conll2002/ner/,2002).
In the following tables, we add a dagger sign?
to results that are not statistically significant whencompared to the baseline results.7.1 No Source Language Training DataIn this first case, as described in Section 4, the men-tion labels in the source language are obtained di-rectly through the alignment from the mentions inthe translated text.
This is a very simple scenario,which can be implemented with ease, and, as we willsee, yields reasonable performance out-of-the-box.N P R FArabic 3566 52.7 49.6 51.1Chinese 4791 66.4 52.2 58.5Spanish 2487 63.4 63.6 63.5Table 4: Performance of the cross-language propagationfrom English mention detection system onto Arabic, Chi-nese and Spanish texts.
Performance is presented in termsof Precision (P), Recall (R), and F-measure (F).
The col-umn (N) shows the number of mentions in the test set.Experimental results presented in Table 4 showthe performance of applying this information trans-fer approach.
For each source language (Arabic,Chinese, or Arabic), we show the performance ofpropagating mentions from the English text.
Eventhough no training data to build a source languagemention classifier is available, we still can detectmentions with reasonably high accuracy.
We con-sider the obtained accuracy as reasonably good be-cause, as an example, the performance of a sys-tem that attaches to every word its most frequentlabel (unigram) is around 25% F-measure on Ara-bic.
Results in Table 4 also show that even thoughthe Chinese-to-English SMT system is lower in termof BLEU than the Arbic-to-English SMT system(0.32 vs. 0.55), performance of the cross-languagepropagation from English mention detection systemonto Chinese is better than the performance of thepropagation from English mention detection systemonto Arabic.
One reason for this is that we noticethat Chinese-to-English SMT system translates andaligns ACE categories better than Arabic-to-EnglishSMT system.7.2 Lexical ResourcesIn this section, we consider the case when we haveavailable training data in the source language to beable to train a statistical classifier.
We also considerthat the classifier has access to lexical informationonly.
Our goal here is to study the effectiveness ofadding cross-language mention propagation infor-mation to improve mention detection performanceon languages with limited resources.Table 5 shows the performance of the 3 languageswith and without cross-language mention propaga-tion information from English, with the 3 propa-gation methods described in Section 4.
One cansee that propagating mention propagation informa-tion results in system performance increase12.
Whensystems use the CIP method, no improvement canbe observed on Arabic and Chinese, while a smallimprovement of 0.5F point is obtained on Spanish(74.5 vs. 75.0).
In contrast, when systems use theCDP method an improvement is obtained in recall?
which is to be expected, given the method ?
lead-ing to systems with better performance in terms ofF-measure: 1.6F points improvement for Arabic,1.5F points improvement for Chinese and almost 3Fpoints improvement for Spanish.
The results for allthe CDP transfers and the CIP for Spanish are statis-tically significant.7.3 Lexical and Syntactic ResourcesWe represent in Table 6 mention detection systemperformance when syntactic resources are availablein the source language, in addition to lexical re-12Only systems?
performance marked with ?
is not statisti-cally significantly better.606Baseline CIP CDPN P R F P R F P R FArabic: 3566 81.8 71.7 76.4 82.2 71.3 76.4?
82.6 73.9 78.0Chinese: 4791 79.3 70.2 74.5 79.4 70.5 74.7?
79.8 72.5 76.0Spanish: 2478 79.1 70.4 74.5 79.7 70.8 75.0 80.4 74.6 77.4Table 5: Performance of Arabic, Chinese and Spanish mention detection using lexical features (?Baseline?
column).Columns ?CIP?
stands for systems that add cross-language context independent mention propagation information andcolumn ?CDP?
is for systems that add cross-language context dependent mention propagation information.Baseline CIP CDPN P R F P R F P R FArabic: 3566 82.2 72.6 77.1 82.7 72.9 77.5 83.2 74.5 78.6Chinese: 4791 80.0 71.3 75.5 79.9 71.5 75.5?
81.0 72.4 76.5Spanish: 2487 79.1 71.2 74.9 79.9 71.9 75.7 80.7 74.6 77.5Table 6: Performance of Arabic, Chinese and Spanish mention detection using lexical and syntactic features (POStags, chunk information, etc).sources available in the previous Subsection.
Thisexperiment is important because it tests the effec-tiveness of the propagation approach in improvingperformance on languages with a typical level of re-sources.Results show that even in this situation, the useof cross language mention propagation informa-tion still lead to considerable improvement: usingthe CDP transfer method yields improvements from1.1F in Chinese to 2.6F in Spanish.
Similar to theprevious section, the use of CIP information did notimprove performance significantly on Arabic (77.5vs.
77.1) and Chinese (75.5 vs. 75.5) systems, butwe notice an improvement in Spanish13.7.4 Lexical, Syntactic and Semantic ResourcesThis final section investigates whether the accessto cross-language mention propagation informationcan still improve the performance of existing com-petitive mention detection systems trained on lan-guages with large resources.
In this case, systemshave access to a full array of lexical, syntax, seman-tic information, including the output from other in-formation extraction models.
Table 7 presents theperformance of mention detection systems on thethree languages, in the familiar 3 propagation meth-ods: again, results show that better performanceis obtained when cross language mention informa-tion is used.
Under CIP, almost no change in termsof performance is obtained for Arabic and Span-13The dagger sign ?
marks the systems that are not statisti-cally significantly better.ish, though a slight improvement can be observedfor Chinese (76.9F vs. 75.8F).
When CDP is usedthe performance of mention detection systems is im-proved by 0.9F for Arabic (80.9 vs. 80.0), 2.3Ffor Chinese (78.1F vs. 75.8F) and 1.9F for Span-ish (78.1 vs. 76.2F).
Once again, the results provethat the use of cross language mention propagationinformation, especially through CDP, is effective inimproving the performance even in this case.By comparing results across tables, one can notethat systems having access to only lexical and crosslanguage mention propagation information are as ef-fective as systems having access to large set of in-formation.
For Chinese, we obtain a performance of75.8F when the system has access to lexical, syntac-tic and output of other information extraction mod-els.
On the other hand, the same system has aslightly better performance of 76.0 when it has ac-cess to lexical and cross language mention propa-gation information.
The same behavior is observedfor Spanish, we obtain a performance of 76.2F whenthe system has access to lexical, syntactic and outputof other information extraction models; compared to77.4F when lexical and cross language mention in-formation are used.
This is not true for Arabic wherehaving access to larger set of information led to bet-ter performance when compared to systems havingaccess to lexical information and CDP information(80.0F vs. 78.0).
We attribute this difference tothe fact that in Arabic we use the output of largernumber of information extraction models, and con-sequently a richer set of information.607Baseline CIP CDPN P R F P R F P R FArabic: 3566 83.6 76.8 80.0 83.9 77.0 80.2?
84.2 77.8 80.9Chinese: 4791 81.1 71.3 75.8 81.4 73.0 76.9 81.7 74.8 78.1Spanish: 2487 79.1 73.5 76.2 79.3 73.4 76.2?
80.1 76.2 78.1Table 7: Performance of Arabic, Chinese and Spanish mention detection using lexical, syntactic and output of otherinformation extraction models: full-blown systems.The other observation that is worth making is thatthe improvement in performance has a decreasingtendency as more resources are available.
The per-formance gain for CDP in Arabic goes from 1.6 to1.5 to 0.9, and the one on Spanish goes from 2.9 to2.6 to 1.9.
The one on Chinese follows part of thistrend, as it goes from 1.4 to 1.1 to 2.3.
While theevidence here is not definitive, one can indeed notethe reduced effectiveness of the method as more re-sources are available, which was indeed what we ex-pected.Results obtained by all these experiments helpanswer an important question: when trying to im-prove mention detection systems in a resource-poorlanguage, should we invest in building resources orshould we use propagation from a resource-rich lan-guage to (at least) bootstrap the process?
The answerseems to be the latter.8 ConclusionThis paper presents a new approach to mention de-tection in low, medium or high-resource languages,which benefits from projecting the output from aresource-rich language such as English.
We showthat even when no training data is available in onesource language, we can still build a decently per-forming baseline mention detection system by onlyusing resources from English.
This approach re-quires a mention detection system on a resource-rich language and an SMT system that translate textfrom the source to the resource-rich language, bothof which can be attained.In cases when large resources are available in thesource language, our cross language mention propa-gation technique is still able to further improve men-tion detection system performance.
Experimentsperformed on the four languages of ACE 2007, withEnglish chosen as the resource-rich language, showconsistent and significant improvements across con-ditions and levels of linguistic sophistication.
Theexperiments are conducted on clearly specified par-titions of the ACE 2007 data set, so future compar-isons against the presented work can be correctlyand accurately made.
We also note that systemsthat have access to lexical and cross language men-tion propagation information are as accurate as thosethat have access to lexical, syntactic and output ofother information extraction models in the sourcelanguage (but no cross-language resources).
As fu-ture work, we plan to extend this work to use semi-supervised and unsupervised approaches that canmake use of cross-language information propaga-tion.We believe that it is important for the researchcommunity to continue to invest in building betterresources in ?source?
languages, as it looks the mostpromising approach.
However, using a propagationapproach can definitely help bootstrap the process.AcknowledgmentsThis work was supported by DARPA/IPTO ContractNo.
HR0011-06-2-0001 under the GALE program.ReferencesYaser Al-Onaizan and Kishore Papineni.
2006.
Dis-tortion models for statistical machine translation.
InProceedings of the 21st International Conference onComputational Linguistics and 44th Annual Meet-ing of the Association for Computational Linguistics,pages 529?536, Sydney, Australia, July.
Associationfor Computational Linguistics.A.
Berger, S. Della Pietra, and V. Della Pietra.
1996.
Amaximum entropy approach to natural language pro-cessing.
Computational Linguistics, 22(1):39?71.C.
Cabezas, B. Dorr, and P. Resnik.
2001.
Spanish lan-guage processing at university of maryland: Buildinginfrastructure for multilingual applications.
In Pro-ceedings of the 2nd International Workshop on Span-ish Language Processing and Language Technologies.Stanley Chen and Ronald Rosenfeld.
2000.
A survey ofsmoothing techniques for me models.
IEEE Trans.
onSpeech and Audio Processing.I.
Dagan and A. Itai.
1994.
Word sense disambiguationusing a second language monolingual corpus.
Compu-tational Linguistics, 20(4):563?596.608Ido Dagan, Alon Itai, and Ulrike Schwall.
1991.
Twolanguages are more informative than one.
In Meet-ing of the Association for Computational Linguistics,pages 130?137.Mona Diab and Philip Resnik.
2001.
An unsupervisedmethod for word sense tagging using parallel corpora.In ACL ?02: Proceedings of the 40th Annual Meetingon Association for Computational Linguistics, pages255?262, Morristown, NJ, USA.
Association for Com-putational Linguistics.R.
Florian, H. Hassan, A. Ittycheriah, H. Jing, N. Kamb-hatla, X. Luo, N Nicolov, and S Roukos.
2004.
Astatistical model for multilingual entity detection andtracking.
In Proceedings of the Human LanguageTechnology Conference of the North American Chap-ter of the Association for Computational Linguistics:HLT-NAACL 2004, pages 1?8.W.
Gale, K. Church, and D. Yarowsky.
1992.
A methodfor disambiguating word senses in a large corpus.Computers and the Humanities, 26:415?439.Joshua Goodman.
2002.
Sequential conditional general-ized iterative scaling.
In Proceedings of ACL?02.Gregory Grefenstette.
1998.
Cross-Language Informa-tion Retrieval, volume 079238122X.
Kluwer Aca-demic Publishers.http://www.cnts.ua.ac.be/conll2002/ner/.
2002.Fei Huang and Kishore Papineni.
2007.
Hierarchi-cal system combination for machine translation.
InProceedings of the 2007 Joint Conference on Empir-ical Methods in Natural Language Processing andComputational Natural Language Learning (EMNLP-CoNLL), pages 277?286.Rebecca Hwa, Philip Resnik, and Amy Weinberg.
2002.Breaking the resource bottleneck for multilingual pars-ing.
In Proceedings of the Workshop on Linguis-tic Knowledge Acquisition and Representation: Boot-strapping Annotated Language Data.H.
Jing, R. Florian, X. Luo, T. Zhang, and A. Itty-cheriah.
2003.
HowtogetaChineseName(Entity): Seg-mentation and combination issues.
In Proceedings ofEMNLP?03, pages 200?207.Philipp Koehn.
2004.
Pharaoh: a Beam Search De-coder for Phrase-Based Statistical Machine Transla-tion Models.
In Proceedings of AMTA?04, WashingtonDC, September-October.John Lafferty, Andrew McCallum, and Fernando Pereira.2001.
Conditional random fields: Probabilistic modelsfor segmenting and labeling sequence data.
In ICML.Y.-S. Lee, K. Papineni, S. Roukos, O. Emam, and H. Has-san.
2003.
Language model based Arabic word seg-mentation.
In Proceedings of the ACL?03, pages 399?406.Young-Suk Lee, Yaser Al-Onaizan, Kishore Papineni,and Salim Roukos.
2006.
Ibm spoken language trans-lation system.
In TC-STAR Workshop on Speech-to-Speech Translation, pages 13?18, Barcelona, Spain,June.Andrew McCallum, Dayne Freitag, and FernandoPereira.
2000.
Maximum entropy markov models forinformation extraction and segmentation.
In ICML.G.
A. Miller.
1995.
WordNet: A lexical database.
Com-munications of the ACM, 38(11).NIST.
2007.
The ACE evaluation plan.www.nist.gov/speech/tests/ace/index.htm.Eric W. Noreen.
1989.
Computer-Intensive Methods forTesting Hypotheses.
John Wiley Sons.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a method for automatic evalua-tion of machine translation.
In Proceedings of the 40thAnnual Meeting of the Association for ComputationalLinguistics, pages 311?318.P.F.Brown, S.A.Della Pietra, V.J.
Della Pietra, andR.L.Mercer.
1991.
Word-sense disambiguation usingstatistical methods.
In Proceedings of ACL?91.L.
Ramshaw and M. Marcus.
1994.
Exploring the sta-tistical derivation of transformational rule sequencesfor part-of-speech tagging.
In Proceedings of the ACLWorkshop on Combining Symbolic and Statistical Ap-proaches to Language, pages 128?135.L.
Ramshaw and M. Marcus.
1995.
Text chunking us-ing transformation-based learning.
In David Yarowskyand Kenneth Church, editors, Proceedings of the ThirdWorkshop on Very Large Corpora, pages 82?94, Som-erset, New Jersey.
Association for Computational Lin-guistics.E.
Riloff, C. Schafer, and D. Yarowsky.
2002.
Inducinginformation extraction systems for new languages viacross-language projection.
In Proceedings of Coling2002, Taipei, Taiwan.E.
F. Tjong Kim Sang and J. Veenstra.
1999.
Represent-ing text chunks.
In Proceedings of EACL?99.E.
F. Tjong Kim Sang.
2002.
Introduction to the conll-2002 shared task: Language-independentnamed entityrecognition.
In Proceedings of CoNLL-2002, pages155?158.D.
Yarowsky, G. Ngai, and R. Wicentowski.
2001.
In-ducing multilingual text analysis tools via robust pro-jection across aligned corpora.
In Proceedings of HLT2001, San Diego, California, USA.Imed Zitouni, Jeff Sorensen, Xiaoqiang Luo, and RaduFlorian.
2005.
The impact of morphological stem-ming on Arabic mention detection and coreference res-olution.
In Proceedings of the ACL Workshop on Com-putational Approaches to Semitic Languages, pages63?70, Ann Arbor, June.609
