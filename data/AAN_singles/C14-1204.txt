Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 2161?2171, Dublin, Ireland, August 23-29 2014.Employing Event Inference to Improve Semi-Supervised ChineseEvent ExtractionPeifeng Li, Qiaoming Zhu, Guodong ZhouSchool of Computer Science & TechnologySoochow University, Suzhou, 215006, China{pfli, qmzhu, gdzhou}@suda.edu.cnAbstractAlthough semi-supervised model can extract the event mentions matching frequent event patterns, it suf-fers much from those event mentions, which match infrequent patterns or have no matching pattern.
Tosolve this issue, this paper introduces various kinds of linguistic knowledge-driven event inferencemechanisms to semi-supervised Chinese event extraction.
These event inference mechanisms can capturelinguistic knowledge from four aspects, i.e.
semantics of argument role, compositional semantics of trig-ger, consistency on coreference events and relevant events, to further recover missing event mentionsfrom unlabeled texts.
Evaluation on the ACE 2005 Chinese corpus shows that our event inference mech-anisms significantly outperform the refined state-of-the-art semi-supervised Chinese event extractionsystem in F1-score by 8.5%.1 IntroductionAn event is a specific occurrence involving arguments (participants and attributes) of the specific roles.In an event, trigger is the main word which most clearly expresses its occurrence, so recognizing anevent can be recast as identifying a corresponding trigger.
An event may have several arguments,which are entity mentions (e.g., person name, time, location, etc.)
and must fulfill the correspondingroles.
Take the following sentence as an example:S1: On the 25th Dec. (A1: Artifact), peacekeepers (A2: Artifact) returned (E1: Transport) to Am-man (A3: Place) by flight (A4: Vehicle).For this example, an event extraction system should identify one event mention E1, which is trig-gered by verb ?returned?
whose event type is Transport, with four arguments, ?peacekeepers?, ?25thDec.
?, ?flight?, and ?Amman?, fulfilling the roles of Artifact, Time, Vehicle, and Place, respectively.Automatically extracting events from free texts is a higher-level Information Extraction (IE) task,which is still a challenge due to the complexity of natural language and the domain-specific nature,especially in Chinese for its specific characteristics.
In particular, most of previous studies have fo-cused on English event extraction, while only a few concern Chinese.Currently, supervised learning models have dominated event extraction.
To reduce the labeled datarequired, a few semi-supervised models have been applied to English event extraction (e.g., Riloff1996; Yangarber et al., 2000; Stevenson and Greenwood, 2005; Huang and Riloff, 2012).
Since classi-fier-based model needs dozens of annotated documents to train model, most of previous semi-supervised models focused on pattern-based approach, which only needed a few seed (event) patterns.In those pattern-based approaches, frequent event patterns, which occur in many documents, werechosen as relevant patterns to match event mentions in unlabeled texts.
However, the order of words ina Chinese sentence is rather agile for its open and flexible structure, and different orders might expressthe same meaning due to the semantics-driven nature of the Chinese language.
This results in the di-versity of Chinese event patterns and numerous infrequent patterns, even some event mentions havingno matching patterns.
Hence, it is an issue to extract the event mentions with infrequent patterns.This work is licensed under a Creative Commons Attribution 4.0 International Licence.
Page numbers and proceedings footerare added by the organisers.
Licence details: http://creativecommons.org/licenses/by/4.0/.2161In this paper, we first implement a pattern-based semi-supervised model for Chinese event extrac-tion as a baseline, following the state-of-the-art system as described in (Liao and Grishman, 2010a)and then refine this model to suit Chinese event extraction.
Moreover, we propose various kinds ofnovel linguistic knowledge-driven event inference mechanisms to address the above issue and recovermissing event mentions.
These event inference mechanisms can capture the linguistic knowledge fromsemantics of argument role, compositional semantics of trigger, consistency on coreference events andrelevant events.
Evaluation on the ACE 2005 Chinese corpus shows that our event inference mecha-nisms dramatically outperform the baseline.The rest of this paper is organized as follows.
Section 2 overviews related work.
Section 3 presentsthe refined semi-supervised model for Chinese event extraction.
Section 4 proposes several linguisticknowledge-driven event inference mechanisms.
Section 5 reports and analyzes the experimental re-sults.
Finally, we conclude our work in Section 6.2 Related WorkAlmost all previous semi-supervised models focus on English event extraction, which can be subdi-vided into pattern-based models (e.g., Riloff, 1996; Yangrber et al., 2000; Liao and Grishman, 2010a;Chambers and Jurafsky, 2011; Balasubramanian et al., 2013) and classifier-based models (e.g., Chieuet al., 2003; Maslennikov and Chua, 2007; Patwardhan and Riloff, 2009; Liu and Strzalkowski, 2012;Wang et al., 2013).
Classifier-based models normally require a small set of annotated data (e.g., 100annotated documents), while pattern-based models need dozens of high quality seed patterns.Riloff (1996) first divided unlabeled documents into irrelevant and relevant documents, and the lat-ter was much likely to contain further relevant patterns.
Then event patterns from relevant documentswere generated by using an annotated data and a set of heuristic rules.
Yangarber et al.
(2000) pro-posed a document-centric view to boost a semi-supervised event extraction system, which assumesrelevant documents always contain some shared patterns.
Yangarber (2003) further introduced multi-ple learners into the bootstrapping procedure to make the final decision on the combination of multiplelearners on distinct event types.
Huang and Riloff (2012) employed role-identifying nouns, which pro-posed by Phillips and Riloff (2007), as seed terms to extract patterns from relevant documents andthen generated the labeled instances to train three classifiers in their event extraction system.As an alternative, Stevenson and Greenwood (2005) proposed a pattern similarity-centric view andselected relevant patterns on similarity scores.
Normally, bootstrapping on the document-centric viewtends to accept the irrelevant patterns with a high occurrence frequency in relevant documents.
To ad-dress this problem, Liao and Grishman (2010a) introduced a pattern similarity metric into the docu-ment-centric view as a filter to eliminate those irrelevant patterns.
Liao and Grishman (2011) furtherapplied an information retrieval mechanism to detect relevant documents and proposed a self-trainingstrategy for bootstrapping.In addition, several studies focused on the event pattern representation, such as pairwise (e.g., Sub-ject-Verb, Verb-Object) (Chambers and Jurafsky, 2008, 2009), SVO (Subject-Verb-Object)(Yangarber, 2000; Balasubramanian et al., 2013), chain (Sudo et al., 2001), subtree (Sudo et al., 2003)and complex pattern (Liu and Strzalkowski, 2012).In the literature, only one paper concerns semi-supervised Chinese event extraction.
Chen and Ji(2009a) applied various kinds of cross-lingual features in the bootstrapping procedure to extract Chi-nese event.
With the help of over 500 annotated seed event mentions in 100 documents, they onlyachieved 35% in F1-score.
This indicates the critical challenge in semi-supervised Chinese event ex-traction.Only a few studies concern event inference mechanisms.
Ji and Grishman (2008) employed a rule-based approach to propagate consistent triggers and arguments across topic-related documents.
Liaoand Grishman (2010b) employed cross-event consistent information to improve sentence-level eventextraction.
Hong et al.
(2011) regarded entity type consistency as a key feature to predict event men-tions and adopted an information retrieval mechanism to promote event extraction.
Li et al.
(2013)proposed a global argument inference model on Chinese argument extraction to explore specific rela-tionships among relevant event mentions to recover those inter-sentence arguments in the sentence,discourse and document layers.
Li et al.
(2014) also introduced Markov Logic Network (MLN) to cap-ture the discourse-level consistency between Chinese trigger mentions to further recover those poor-2162context event mentions.
In a word, all of above mechanisms focus on supervised event extraction andno literature involves in the event inference of semi-supervised event extraction.3 Semi-supervised Model for Chinese Event ExtractionIn this section, we refine a semi-supervised model for Chinese event extraction as a baseline, whichincludes two views, the document-centric view and pattern similarity-centric view.3.1 Semi-supervised ModelLiao and Grishman (2010a) proposed a state-of-the-art semi-supervised event extraction system,which was a pattern-based approach and adopted bootstrapping mechanism to extract relevant patterns.Besides, two distinct views, the document-centric view and the pattern similarity-centric view as de-scribed in Subsection 3.2 and 3.3, are incorporated in the bootstrapping procedure to rank event pat-terns on different metrics.
In each iteration, the candidate patterns, which extracted from unlabeledtexts as the candidates of relevant patterns, are ranked following the document-centric view, then thecandidate patterns with pattern similarity scores below a similarity threshold (0.9 in (Liao and Grish-man, 2010a)) will be removed; only top 3 candidate patterns in the ranking scores of the document-centric view will be accepted as relevant patterns.
In addition, if no pattern is found in the current iter-ation, the threshold will be reduced by 0.1 until new relevant patterns are extracted.As we mentioned earlier, the open and flexible structure of Chinese sentences results in the diversi-ty of Chinese event patterns.
Moreover, the syntax or semantic path is often used to represent eventpatterns, but the performance in Chinese syntactic parsers and Semantic Role Labeling (SRL) tools islower than that in English.
Therefore, we refine this semi-supervised model to suit Chinese event ex-traction in three aspects as follows, due to the above characteristics of Chinese language.Firstly, we construct a refined event pattern representation of Chinese events.
Liao and Grishman(2010a) used semantic roles to represent the relationship between the trigger and its arguments.
Due tothe wide spread of ellipsis (especially entities) and the relatively low performance of Chinese SRL,pairwise (trigger-entity) representation and dependency path are introduced to represent Chinese eventpattern in our refined model.
Hence, the event pattern in this paper is a triple-style template as follows.<trigger, entity type, their dependency path >A pattern is formed by a trigger, the entity type of its argument1 and the dependency path from thetrigger to the argument.
For example, trigger ?returned?
and its argument ?peacekeepers?
(entity type:PER) in sentence S1 can be described as a pattern <returned, PER, nsubj>.Secondly, we introduce a novel mechanism to extract candidate patterns.
Since verb and noun dom-inate in triggering an event in Chinese and they are chosen as candidate triggers to create candidatepatterns.
Besides, since different event types may have different roles and different roles are fulfilledby entities with different types, the entities whose types can fulfil the core roles of a specific event arechosen as candidate entities.
For example, Attacker and Target are the core roles of event Attack andentity types PER/ORG/GPE2 can fulfil above two roles, so we only accept those entities, whose typesbelong to PER/ORG/GPE, to form candidate patterns.
For each sentence in the unlabeled data, all can-didate trigger-entity pairs and their dependency path are enumerated as candidate patterns.Finally, we present a new mechanism to generate seed patterns based on seed triggers.
Consideringthe relatively large number of Chinese triggers and the flexibility of Chinese sentences, an instance-based approach is adopted by enumerating a few high-quality seed triggers with explicit meaning andhigh probability to trigger a specific event.
Instead of dozens of predefined patterns required in previ-ous studies, only one seed trigger is given to each event type or subtype without any predefined pat-terns.
Hence, all patterns consisting of a seed trigger in the candidate patterns are accepted as seed pat-terns for their high probability to trigger a specific event.3.2 Document-centric ViewThe document-centric view regards those documents containing the patterns always identified as rele-vant to a specific event as relevant documents and concludes that they are likely to contain additional1 All event arguments must be entity mentions following the ACE 2005 annotation guidelines of events.2 PER/ORG/GPE refers to person, organization and geo-political entity respectively, which are annotated in the ACE 2005corpus.
These helpful information can be seen as ontological classes.2163relevant patterns.
Hence, those candidate patterns occurring in the relevant documents frequently willbe extracted as relevant ones.
Following Yangarber et al.
(2000) and Liao and Grishman (2010a), wealso employ the disjunctive voting scheme to calculate the ranking scores Rscore(p) of pattern p as fol-lows.????
)p(Ld)p(LdScore )d(lRelog*)p(L)d(lRe)p(R =(1)where L(p) is the set of documents, which contain candidate pattern p, and Rel(d) is the relevancescore of document d as follows.???
?--Pp)p(Ld'))p(L)d(lRe1(1)d(lRe =                                                          (2)where Rel?
(d) is the relevance score of document d in the previous iteration.
Initially the relevancescore of document d is set to n if document d has n relevant patterns in the set of extracted patterns P.3.3 Pattern Similarity-centric ViewThe similarity-centric view tries to find the candidate patterns who are similar to those seed patterns.The similarity scores derive from two aspects, lexical similarity and syntactic similarity, while theformer is based on the trigger and entity type in a pattern and the latter is based on the relation be-tween the trigger and the entity.
Especially, we realize the pattern similarity view following the lexicaland syntactic similarity, and refine the similarity ranking score Iscore(p) of candidate pattern p as fol-lows:)d,d(DSim)e,e(ESim)t,t(WSim(Max)p(I spspspPsscore ?
?= ?
(3)where t, e and d represent the trigger, entity type and dependency path in candidate pattern p(tp, ep, dp)or seed pattern s(ts, es, ds) in the set of extracted patterns P, respectively; ESim identifies whether twoentities have the same type, and assigned 1 if two entities have the same entity type and otherwise asmall number 0.1; DSim calculates the similarity between two dependency paths in edit distance.
Fi-nally, WSim is to obtain the trigger similarity in lexical semantics, using Hownet (Dong and Dong,2006) following Liu and Li (2002):????
),(),( spsp ttDisttWSim(4)where Dis(tp,ts) is the distance between the sememes of triggers tp and ts, in HowNet?s sememe hierar-chical architecture, with parameter ?
assigned 0.75 following Liu and Li (2002).4 Event InferenceThe pattern-based semi-supervised model cannot extract those event mentions matching infrequentpatterns or without matching patterns.
The knowledge from linguistic aspect (e.g., definition of events,compositional semantics of Chinese words, coreference events and relevant events, etc.)
is helpful tofurther recover missing event mentions or filter pseudo event mentions.
In this section, various kindsof event inference mechanisms based on linguistic knowledge are proposed to improve the perfor-mance of semi-supervised Chinese event extraction.We unify the semi-supervised model and the event inference mechanisms into one model as follows:In each iteration, after the top 3 patterns have been chosen following the document-centric view andevent mentions in the unlabeled data have been extracted by pattern matching, all event inference2164mechanisms are applied to recover missing event mentions,.
Due to our inference mechanisms aretrigger-based and each inferred event mention may have more than one pattern while most of them arenoisy, we do not add those patterns in the set of relevant patterns for bootstrapping.4.1 Event Inference on Role SemanticsThe core of an event can be expressed as ?Who do What to Whom?
in which ?Who?
and ?Whom?
arethe core roles3 to participate in an event, while ?What?
often refers to event trigger.
The relationshipbetween the verbal trigger and its core roles are the key clues to express event semantics.
Since thesubject or object always play the core roles in an event mention, SVO (Sbject-Verb-Object) is a betterrepresentation of event pattern.
However, ellipsis is a widespread phenomenon in Chinese languageand many sentences do not have an overt subject or object, so lots of event mentions cannot be repre-sented as SVO pattern.
In this paper, we only use the trigger-entity pair to represent event pattern andone of the disadvantages of this representation is its loose constraint on events, which will extract lotsof pseudo event mentions.In most cases in Chinese, the object is often the most important core role to identify a specific eventand it is more helpful than the subject to distinguish true event mentions from pseudo ones.
Take fol-lowing two sentences as examples:S2: ??
(PER) ?(hit)?
????(PER)?
(The teacher hit this student.
)S3: ??
(PER) ?(call)?
??
?
????(PER)?
(The teacher made a phone call to this stu-dent.
)The relation between verb ?
(hit) and object????
(this student) is clear to indicate sentenceS2 is an Attack event mention since the object is a person, while object ??
(phone) in sentence S3 isnot a person and it indicates this sentence is not an Attack event mention following the sense of verb?
(call).
Therefore, the object is an effective evidence to indicate event mentions and it is incorpo-rated in our model to remove pseudo event mentions as follows.Role Semantics: If the object of a candidate verbal trigger mention is not an entity or its entity typecannot fulfil the object roles (e.g., Victim in events Injure and Die) in a specific event, this candidatetrigger mention4 will be inferred as pseudo one.For example, core role Target of event Attack often acts as the object of a verbal trigger and entitytypes PER, ORG and GPE can fulfill this role according to be definition of event Attack in the ACE2005 corpus.
Hence, a candidate trigger mention of event Attack will be regarded as pseudo one whenthis mention has an object which is not an entity or whose entity type is not PER, ORG or GPE.4.2 Event Inference on Compositional SemanticsIn Chinese language, a word is composed of one or more characters.
Almost all Chinese charactershave their own meanings and are morpheme (or single-morpheme word), the minimal meaningful unit.If a Chinese word contains more than one character, its meaning can often be derived from its compo-site morphemes.
This more fine-grained semantics is compositional semantics of Chinese words.
Ac-tually, it is also a normal way for a native Chinese speaker to understand a new Chinese word.Two-morpheme words are used widely in Chinese language and almost all Chinese triggers containone or two morphemes.
The compositional semantics of a two-morpheme word comes from both itsmorphemes and morphological structure.
Besides morphological structure Coordination, all othermorphological structures (e.g., Modifier-Head, Predicate-Object, Predicate-Complement (Li and zhou,2012)) always have one head morpheme, the morpheme as the governing semantic element, to expressthe meaning of a word.
Commonly, there are two head morphemes in a two-morpheme word of Coor-dination structure.
In particular, a two-morpheme word triggers an event if its two head morphemesare homogeneous (e.g., ?(attack)?
(attack), ?(die)?(die)).
Otherwise, it may refer to more than oneevent and this means that two triggers are within a word whose morphological structure is Coordina-tion.
Take the following sentence as an example:3 We select core roles following the ACE Chinese annotation guidelines of events.
Agent/Victim are the core roles of eventsDie/Injure while Attacker/Target are the core roles of event Attack.4 Recognizing a trigger mention can be recast as identifying a corresponding event mention, since trigger is the main wordwhich most clearly expresses the occurrence of an event.2165S4: ?????
(E2: Attack)?
(E3: Die)?????
(A younger stabbed (E2: Attack) a woman todeath (E3: Die).
)In S4, two-morpheme word ??
(stab a person to death) is a trigger with the Coordination struc-ture.
There are two event mentions in sentence S4, one Attack (E2) and one Die (E3), while morpheme?
(stab) triggers an Attack event and ?
(die) refers to a Die one.Almost all event extraction systems assigned only one event type to a trigger and this will lead tothat the other event type does not have any patterns to match and then cannot be identified.
To addressthis issue, we first identify those triggers who refers to two distinct events as follows: for each two-morpheme candidate trigger in the candidate patterns whose morphemes are m1 and m2, it will be iden-tified as candidate trigger with two event types and split into two single-morpheme word to generatetwo candidate trigger mentions when the following three conditions are satisfied:1) )m(POSverb)m(POSverb 21 ??
?2))s(Etype)s(Etype))s,m(Wsim())s,m(Wsim( MaxMax seedssseedss 212211 11 21 ???
??
?
?3) Morph(m1 m2)= Coordinationwhere POS(m) returns all possible parts of speech of morpheme m in Hownet and Etype(s) is to obtainthe event type of seed trigger s; WSim(m,s) is defined in Subsection 3.3 and returns 1 when one wordm is the synonym of the other word s; Morph(w) is to obtain the morphological structure of word wfollowing Li and Zhou (2012).Since there is a strong trigger consistency in those two-morpheme words of Coordination structurewhich refers to two distinct events, we propose an event inference mechanism as follows.Compositional semantics: For each two-morpheme word identified by the above three conditions,if one of its morphemes has been extracted as an trigger mention of a specific event type, the othermorpheme in the same word will refer to an a relevant event type.4.3 Event Inference on Coreference EventsTo mine more event mentions, we use the simple trigger-entity pair to represent event pattern in thispaper.
However, lots of event mentions still cannot be extracted due to the ellipsis of arguments.
Takefollowing sentences as examples:S5: ?????????????
(E4: Meeting)?
(The US and DPRK finished talking (E4:Meeting) in Kuala Lumpur.
)S6: ??
(E5: Meeting)??????
(The talks (E5: Meeting) are serious.
)Obviously, more than one pattern of event mention E4 can be generated from sentence S5, since itcontains more than one entity.
On the contrary, no pattern can be extracted from S6 and this leads toevent mention E5 cannot be extracted in our pattern-based semi-supervised model.Within a document, almost all event mentions are around a topic and there is a strong trigger con-sistency: if one mention of a word triggers a specific event, its other mentions in the same documentwill refer to the same event type.
Besides, similar words (e.g., ?
(bomb), ??
(bomb), ??
(bomb)),which contains the same head morpheme, always express the same or similar meaning following theprinciple of compositional semantics.
Similarly, there is a strong trigger consistency on those similarwords: If one mention of a word refers to a specific event, the mentions of its similar words in thesame document will trigger events of the same type.Since the mentions of the same word or similar words are often coreference ones and always referto the same event type, we propose an event inference mechanism on coreference events to recovermissing event mentions based on head morpheme as follows.
In particular, head morphemes are alsoidentified following Li and Zhou (2012).Coreference events: 1) if a mention of a candidate trigger refers to a specific event, all its othermentions in the same document will trigger the same type event; 2) if one mention of a candidate trig-ger refers to a specific event, all the mentions of its similar words in the same document will triggerthe same type event too.4.4 Event Inference on Relevant EventsThe bootstrapping procedure of the document-centric view selects frequent patterns in relevant docu-2166ments and ignores those infrequent patterns both in relevant or irrelevant documents.
However, thenumber of infrequent patterns in Chinese is larger than that in English, due to its open and flexiblesentence structure, as mentioned in Subsection 3.1.Besides the pattern-based semi-supervised model, we propose a trigger-based mechanism as a sup-plement to recover those missing event mentions concerning infrequent patterns following this as-sumption: if a trigger mention refers a specific event in a document, there is a high probability that itsrelevant events occur in the same document.
Take the following sentence as an example:S7: ???
(E6: Attack)???
1???????
(E7: Die)?
(An Arabian was dying (E7: Die) inthis conflict (E6: Attack).
)In sentence S7, there is an extracted Die event mention E7 triggered by ??
(die) and ??
(con-flict) is a candidate trigger mention.
If there is an evidence that ??
(conflict) triggers an Attack eventin the other documents, it is possible to identify ??
(conflict) as a trigger mention of Attack event inS7 for the high probability that events Die and Attack occur in the same document.
We propose an in-ference mechanism on relevant events as follows.Relevant Events: If a trigger mention is identified in a document, each candidate trigger mention inthe same document will be recognized as true ones when it satisfies the following condition: this can-didate trigger occurs in the other documents as an event trigger and refers to the relevant events of thisidentified trigger mentions.Since the seed triggers have a high probability to trigger a specific event, to further explore thosemissing event mentions, we expand this inference mechanism following compositional semantics inChinese and expand the condition as follows: This candidate trigger occurs in the other documents asan event trigger or contains one of the seed triggers, which refers to the relevant events of this identi-fied trigger mentions.5 ExperimentationIn this section, we systematically evaluate our event inference mechanisms on the ACE 2005 Chinesecorpus and provide the analysis.5.1 Experimental SettingThe ACE 2005 Chinese corpus is the only available corpus in Chinese event extraction and it is usedin all our experiments.
This corpus contains 633 documents annotated with 33 predefined types.
Dueto evaluation on all 33 types is a hard work for the time-consuming bootstrapping procedure and thediversity of distinct event types, most of previous works selected part of event types for evaluation.
Inthis paper, 3 event types (i.e.
Die, Injure and Attack) are selected for evaluation, because they reflectthe relevance of different event types and occur at different frequencies in the corpus.
While eventsDie and Injure are easy to define, event Attack is rather complicated and can be divided into severalsubtypes.
In the ACE 2005 Chinese corpus, almost one third of the annotated event mentions belong tothe above three event types.
Moreover, we report the experimental results on all 33 event types to fur-ther verify the effectiveness of our inference mechanisms in Subsection 5.2.Unlike MUC shared task, which only distinguishes whether a sentence contains a specific eventmention or not, we follow previous studies on the ACE 2005 corpus and report the performance oftrigger-based event extraction: a trigger is correctly identified if its position and event type match areference trigger.
As for evaluation, we use the ground truth entities, time and values annotated in theACE 2005 Chinese corpus, and report the micro-average Precision (P), Recall (R) and F1-score (F1).Table 1 shows the seed triggers for the three event types.
For example, only one seed trigger is pro-vided for either the Die or Injure event, while three seed triggers are given for event Attack.
Since theAttack event contains several distinct event subtypes, we assign one seed trigger to each of its majorsubtypes.
Thus, all patterns whose triggers belong to the set of seed triggers are accepted as seed pat-terns automatically.Type Die Injure AttackSeed triggers ?
(die) ?
(injure) ??
(attack), ??
(conflict), ?
(hit)Table 1.
Seed triggers of Die, Injure and Attack event types2167Besides, all the sentences in the corpus are divided into words using a Chinese word segmentationtool (ICTCLAS) with all entities annotated in the corpus kept.
We use Berkeley Parser and StanfordParser to create the constituent and dependency parse trees.5.2 Experimental ResultsTo verify the performance of our event inference mechanisms, it is compared with the refined baseline,a supervised model for Chinese event extraction.
Table 2 shows the results of our event inferencemechanisms with peak recall, precision and F1-score, following Liao and Grishman (2010a).
Com-pared with the baseline, Table 2 shows that our event inference mechanisms improve the F1-score ofChinese event extraction by 8.5%, largely due to the improvement of 11.8% in recall.
These resultsconfirm the effectiveness of our event inference mechanisms in recovering missing event mentions.The disadvantage of our event inference mechanisms is the fact that it will also introduce some pseudoevent mentions into our model and harm the precision.
Additionally, there is still a big performancegap between our model and the supervised model and this leaves much room for future research.Approach Attack Injure Die All (micro-average)P(%) R(%) F1 P(%) R(%) F1 P(%) R(%) F1 P(%) R(%) F1Baseline 71.4 36.6 48.4 93.2 41.7 57.6 90.1 44.0 59.3 79.7 39.4 52.7+Event inference 70.9 47.5 56.9 83.2 54.6 65.9 80.8 57.2 67.0 75.5 51.2 61.2Supervised model 70.4 72.5 71.4 85.3 78.4 81.7 83.9 92.9 88.1 77.2 78.4 77.8Table 2.
Performance of event inference mechanisms in Chinese event extraction (Attack/Injure/Die).Table 2 also indicates the performance difference of our inference mechanisms for distinct eventtypes.
Among all event types, event Attack achieves the highest improvement (8.5%) in F1-score, witha dramatic improvement of 10.9% in recall and a less loss of 0.5% in precision.
Event Die and Injurealso gain a significant improvement of 7.7% and 8.3% in F1-score respectively, largely due to the in-crease in recall, while their precisions reduce rapidly due to those pseudo event mentions inferred byour inference mechanisms.
However, the loss of precision of event Attack is much less than these ofevents Die and Injure.
The reason is that the inference on role semantics mainly impacts on Attackevents to remove pseudo event mentions.To well evaluate different approaches, it is better to compare them on different corpora.
Since theACE 2005 Chinese corpus is the only available corpus in Chinese event extraction, we divide it intothree sub-corpora according to data sources, i.e.
Broadcast News, Newswire and WebLog, which aremuch different in various aspects, such as quality, length and style.
Figure 1 compares the perfor-mance of different models on different sub-corpora.
It indicates that our event inference mechanismsperfect better than the baseline in all three sub-corpora and that results confirm the huge influence ofthe event inference mechanisms.
It also shows that the WebLog sub-corpus reports the worst F1-scoredue to the low document quality and the low percentage of relevant documents, and that the Newswiresub-corpus reports significantly better performance than the Broadcast News sub-corpus due to itsspoken nature.Figure 1.
Performance comparison (F1-score) on different data sources.To further verify the effectiveness of our event inference mechanisms, we evaluate them on all 33event types.
Due to event extraction is a domain-specific task, distinct event types have the differentseed triggers and different pro-process procedures.
In this paper, we just report the final results for the50.9 57.836.959.6 65.744.8050100Broadcast news Newwise WebLogBaseline Baseline+Event Inference2168sake of brevity.
Table 3 shows the experimental results on all 33 event types and it ensures that ourmechanisms are effective on extracting all event types.
Compared with the baseline, our approach im-proves the F1-score by 7.6%, which is less than that reported in Table 2.
Among all 33 event types, theperformances of almost all event types associated with justice are higher than other event types fortheir unambiguous definitions and high coverage of seed triggers while event Transport achieves thelowest performance for its complexity and low coverage of seed triggers.
Besides, the performance onall event types is lower than that on 3 event types and this result comes from the low performance ofthe Transport event which occupies almost 20% of all annotated event mentions in the ACE 2005Chinese corpus.Approach P(%) R(%) F1Baseline 70.7 34.2 46.1+Event inference 65.2 45.7 53.7Table 3.
Performance of event inference mechanisms in Chinese event extraction (All 33 event types).5.3 Analysis on Event Inference MechanismsTable 4 shows the contributions of the different event inference mechanisms.
It is worthy to mentionthat an event mentions may be identified by both the semi-supervised model and the event inferencemechanisms.
In this paper, we attribute those extracted event mentions to the former and the contribu-tion of our inference mechanisms is greater than those in Table 4.Inference P(%) R(%) F1Baseline 79.7 39.4 52.7+Inference on role semantics (RS) 87.5(+7.8) 39.1(-0.3) 54.1(+1.4)+Inference on compositional semantic (CS) 85.7(+6.0) 43.7(+4.3) 57.8(+3.7)+Inference on coreference events (CE) 83.0(+3.3) 45.8(+6.4) 59.0(+1.2)+Inference on relevant events (RE) 75.7(-4.0) 51.3(+11.9) 61.2(+2.2)Table 4.
The contribution of event inference on Chinese event extraction.Actually, inference mechanism RS is a filter to remove those pseudo event mentions and it can im-prove the precision (+7.8%), with a less lost (-0.3%) in recall.
Moreover, it can also help the seed pat-tern generation to generate high quality seed patterns.
Table 5 shows the contribution of RS on seedpattern generation and we report the result of Chinese event extraction which only uses the seed pat-terns5.
It improves the accuracy from 75.8% to 82.5%, largely due to the decline (-30) in the set ofpseudo event mentions.
These results indicate that the object is a key clue to identify event mentions.Method #True event mentions #Pseudo event mentionsw/o RS 273 87w/ RS 269 57Table 5.
The contribution of RS on seed pattern generation.Chen and Ji (2009b) have reported that almost 13% of Chinese triggers are in-word or cross-wordsand this figure ensures it is an important issue.
Inference mechanism CS gains the highest improve-ment (+3.7%) in F1-score and this result indicates that compositional semantics is an effective way tosolve such issue.
The accuracy of this inference mechanism is very high (~92%) and most of the ex-ceptions need the help of deep semantics since these instances are also hard to be distinguished byhumans without the context.Inference mechanisms CE and RE improve the F1-scores by 1.2% and 2.2% respectively.
CE as-sumes all mentions of a word in a document only have one sense and it will introduce lots of pseudoevent mentions to reduce precision.
The experimental results also show that RE is an effective sup-plement of the document-centric view to mine event mentions.
Although they derive from the similar5 Since sometimes a pattern can infer both true event mentions and pseudo event mentions, it is hard to identify whether apattern is relevant or irrelevant without the test data.
Hence, we compare their extracted event mentions in this paper.2169principle of occurrence of relevant events, they focus on different perspectives where RE is trigger-based and the document-centric view is pattern-based.
RE ignores the difference on patterns and iden-tifies event mentions on the occurrence of their relevant event mentions.
In addition, sense shifting ofChinese words in different contexts is the main factor to extract lots of pseudo event mentions andthen reduce the precision rapidly.It?s obvious that these inference mechanisms interact with others.
In particular, almost 20% eventmentions can be inferred by both CE and RE for the transitivity of event inference on coreference andrelevant events.
Besides, RS is not only beneficial to the semi-supervised model, but also helpful tothe other inference mechanisms to further remove pseudo event mentions.6 ConclusionThis paper proposes various kinds of novel linguistic knowledge-driven event inference mechanismsas a supplement of the semi-supervised Chinese event extraction to recover missing event mentions.The experimental results verify their effectiveness to extract the event mentions with infrequent pat-terns or without matching pattern.
Although this paper focuses on Chinese language, most of the eventinference mechanisms are language-independent and can be applied to other languages.
Our futurework will focus on how to apply our event inference mechanisms to other languages and introducemore effective inference mechanisms to further improve the performance of semi-supervised eventextraction.AcknowledgmentsThe authors would like to thank three anonymous reviewers for their comments on this paper.
Thisresearch was supported by the National Natural Science Foundation of China under Grant No.61331011 and No.
61272260, the National 863 Project of China under Grant No.
2012AA011102.ReferenceNiranjan Balasubramanian, Stephen Soderland, Mausam and Oren Etzioni.
2013.
Generating Coherent EventSchemas at Scale.
In Proc.
EMNLP 2013, pages 1721-1731, Seatle, WA.Nathanael Chambers and Dan Jurafsky.
2008.
Unsupervised Learning of Narrative Event Chains.
In Proc.
ACL-HLT 2008, pages 787-797, Hawaii.Nathanael Chambers and Dan Jurafsky.
2009.
Unsupervised Learning of Narrative Schemas and Their Partici-pants.
In Proc.
ACL 2009, pages 602-610, Columbus, OH.Nathanael Chambers and Dan Jurafsky.
2011.
Template-Based Information Extraction without the Templates.
InProc.
ACL 2011, pages 976-986, Portland, OR.Hai Leong Chieu, Hwee Tou Ng and Yoong Keok Lee.
2003.
Closing the Gap: Learning-based InformationExtraction Rivaling Knowledge-Engineering Methods.
In Proc.
ACL 2003, pages 216-230, Sapporo, Japan.Zheng Chen and Heng Ji.
2009a.
Can One Language Bootstrap the Other: A Case Study on Event Extraction.
InProc.
NAACL-HLT 2009 Workshop on Semi-supervised Learning for Natural Language Processing, pages66-74, Boulder, CO.Zheng Chen and Heng Ji.
2009b.
Language Specific Issue and Feature Exploration in Chinese Event Extraction.In Proc.
NAACL-HLT 2009, pages 209-212, Boulder, CO.Zhengdong Dong and Qiang Dong.
2006.
HowNet and the Computation of Meaning.
World Scientific Pub Co.Inc.Yu Hong, Jianfeng Zhang, Bin Ma, Jianmin Yao, Guodong Zhou and Qiaoming Zhu.
2011.
Using Cross-EntityInference to Improve Event Extraction.
In Proc.
ACL 2011, pages 1127-1136, Portland, OR.Ruihong Huang and Ellen Riloff.
2012.
Bootstrpped Training of Event Extraction Classifiers.
In Proc.
EACL2012, pages 286-295, Avignon, France.Heng Ji and Ralph Grishman.
2008.
Refining Event Extraction through Cross-Document Inference.
In Proc.ACL-HLT 2008, pages 254-262, Columbus, OH.2170Peifeng Li and Guodong Zhou.
2012.
Employing Morphological Structures and Sememes for Chinese Event Ex-traction.
In Proc.
COLING 2012, pages 1619-1634, Mumbai, India.Peifeng Li, Qiaoming Zhu, and Guodong Zhou.
2013.
Argument Inference from Relevant Event Mentions inChinese Argument Extraction.
In Proc.
ACL 2013, pages 1477-1487, Sofia, Bugaria.Peifeng Li, Qiaoming Zhu, Guodong Zhou.
2014.
Using Compositional Semantics and Discourse Consistency toImprove Chinese Trigger Identification.
Information Processing and Management, 50: 399?415.Shasha Liao and Ralph Grishman.
2010a.
Filtered Ranking for Bootstrapping in Event Extraction.
In Proc.
COL-ING 2010, pages 680-688, Beijing, China.Shasha Liao and Ralph Grishman.
2010b.
Using Document Level Cross-Event Inference to Improve Event Ex-traction.
In Proc.
ACL 2010, pages 789-797, Uppsala, Sweden.Shasha Liao and Ralph Grishman.
2011.
Can Document Selection Help Semi-supervised Learning?
A CaseStudy On Event Extraction.
In Proc.
ACL 2011, pages 260-265, Portland, OR.Qun Liu and Sujian Li.
2002.
Word Similarity Computing Based on How-net.
In Proc.
3th Chinese Lexical Se-mantic Workshop, Taibei, Taiwan.Ting Liu and Tomek Strzalkowski.
2012.
Bootstrapping Events and Relations from Text.
In Proc.
EACL 2012,pages 296-305, Avignon, France.Mstislav Maslennikov and Tat-Seng Chua.
2007.
A Multi-resolution Framework for Information Extraction fromFree Text.
In Proc.
ACL 2007, pages 592-599, Prague, Czech Republic.Siddharth Patwardhan and Ellen Riloff.
2009.
A Unified Model of Phrasal and Sentential Evidence for Infor-mation Extraction.
In Proc.
EMNLP 2009, pages 151-160, Singapore.William Phillips and Ellen Riloff.
2007.
Exploiting Role-Identifying Nouns and Expressions for Information Ex-traction.
In Proc.
RANLP 2007, pages 468-473, Borovets, Bulgaria.Ellen Riloff.
1996.
Automatically Generating Extraction Patterns from Untagged Text.
In Proc.
AAAI 1996,pages 1044-1049, Portland, OR.Mark Stevenson and Mark Greenwood.
2005.
A Semantic Approach to IE Pattern Induction.
In Proc.
ACL 2005,pages 379-386, Ann Arbor, MI.Kiyoshi Sudo, Satoshi Sekine, Ralph Grishman.
2001.
Automatic Pattern Acquisition for Japanese InformationExtraction.
In Proc.
HLT 2001, pages 1-7, San Diego, CA.Kiyoshi Sudo, Satoshi Sekine, Ralph Grishman.
2003.
An Improved Extraction Pattern Representation Modelfor Automatic IE Pattern Acquisition.
In Proc.
ACL 2003, pages 224-231, Tokyo, Japan.Roman Yangarber, Ralph Grishman, Pasi Tapanainen and Silja Huttunen.
2000.
Automatic Acquisition of Do-main Knowledge for Information Extraction.
In Proc.
COLING 2000, pages 940-946, Hong Kong.Roman Yangarber.
2003.
Counter-Training in Discovery of Semantic Patterns.
In Proc.
ACL 2003, pages 343-350, Sapporo, Japan.Jian Wang, Qian Xu, Hongfei Lin, Zhihao Yang, Yanpeng Li.
2013.
Semi-supervised Method for BiomedicalEvent Extraction.
Proteome Science, 11(Suppl 1): S17.2171
