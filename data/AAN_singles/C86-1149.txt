Anothe r St ride Towa rdsKnowledge-Based Machine Translat ionMasaru TomitaJaime G. CarbonellComputer Science DepartmentCarnegieMellon UniversityPittsburgh, PA 1521312 Apr i l1986AbstractBuilding on the well-established premise that reliable machinetranslation requires a significant degree of.
text comprehension,this paper presents a recent advance in multi-lingual knowledge-based machine translation (KBMT).
Unlike previous approaches,the current method provides for separate syntactic and semanticknowledge sources that are integrated dynamically for parsingand generation.
Such a separation enables the system to havesyntactic grammars, language specific but domain general, andsemantic knowledge bases, domain specific but language general.Subsequently, grammars and domain knowledge are precompiledautomatically in any desired combination to produce very efficientand very thorough real-time parsers.
A pilot implementation of ourKBMT architecture using functional grammars and entity-orientedsemantics demonstrates the feasibility of the new approach?1.
IntroductionThis paper introduces a new approach to knowledge-basedmachine translation for well-defined domains, integrating tworecent advances in computational inguistics: entity-orientedparsing \[16\] and functional grammars \[4, 19\].
The entity-orientedformalism has several strengths in representing semanticknowledge for circumscribed domains, but has limitations inrepresenting general syntactic knowledge.
Functional grammarformalisms, such as lexical functional grammar (LFG) andfunctional unification grammar (UG), on the other hand, canrepresent general syntactic knowledge, but are severely limited intheir ability to represent general semantic information.
In ourapproach, the semantic and syntactic knowledge bases aredeveloped separately in the entity-oriented and functionalgrammar formalisms, and a multi-stage grammar preoompflercompiles tfiem into a single knowledge base which contains bothsyntactic and semantic information in a form suitable for efficientreal-time parsing.
Our integrated approach copes with limitationsof both entity-oriented and functional grammar formalisms,retaining the advantages of each.
The approach is particularlywell suited for machine translation, where knowledge of multiplelanguages must be represented in a uniform manner.Knowledge-based machine translation (KBMT) \[8\] is the processof applying syntactic knowledge of the source language andsemantic knowledge pertinent to the source text in order toproduce a canonical language-free meaning representation,which may then be rendered in many different languages.
Theanalysis process of producing a meaning representation is farmore complex than that of using target-language knowledge toexpress the meaning, representation in the target language,because the former is a many-to-one mapping, whereas the lattermay be coerced into a one-to-one mapping.
2 Whereas KBMT is inprinciple far superior to conventional transfer grammartechniques requiring a human translator (the "posteditor") toclean Lip syntactic and semantic errors \[5, 8\], in practice semanticanalysis requires fairly thorough coverage of the domain.
Thisravenous hunger for domain knowledge makes KBMT more'practical for domains in which the development of the knowledgebase can be amortizecl over very large numbers of texts totranslate .. domains such as stocks and other securitynegoti~:Ltions, doctor-patient communication, weather forecasts,banking transactions, financial reports, economic analyses,invoices and purchase orders, etc.
Thus, KBM\] is particularlywell-suited for multi-lingual Iranslation in high.volume well-definedsemantic domains.Whereas the technical feasibility of KBMT was proposed anddemonstrated for limited domains by Carbonell, Cullingford andGershman \[5\], its practical utility remained eh.lsive.
The entity-oriented approach factors linguistic and domain knowledge intoseparate data structures, thus making KBMT systems far moreextensible and economically attractive than the earlierapproaches.
Moreover, recognizing that on occasion someesoteric domain knowledge necessary for semantic analysis willbe lacking, we retain the possibility of interacting with a humanuser knowledgeable of the domain (but not of different targetlanguages) to clarify any difficulties too complex for the domainsemantics to handle, as illustrated in figure 1-1.2.
BackgroundAutomating various forms of syntactic analysis has been acentral concern of Computational Linguistics, producing methodsranginq from context-free grarnmar interpreters \[11,25, 13\], toATNs\[28\], to unification grammars \[18\], and lexical-functionalgrammars \[4\].
The problem is that the production of accurate,uoarnbigaous parses of \[he source text, tolerant of minorgrammatical deviations; requires a fairly complete semantic modelof the domain, and a method for bringing the semantic knowledgeto bear in the parsing process.
Semantically-oriented parsershave succeeded at integrating semantics with syntax, but only atthe cost of intertwining both knowledge suurces into ttlo program1The riathors would like to acknowledge the other members of the the machinetlanslation laboratory at CMU who contributed in various ways to the researchdescribed in this paper: Peggy Anderson, Philip Franklin, Alex Ilcuphuaml, MarionKee, I liroaki Sails, Yuko Tomita and Teruka Watanabe.2The analyzer needs to comprehend all possible syntactic variants of anysemantic messafjo in the analysis phase because it cannot contrel the form of itsinput, but to produce acceptable output, the generator need only render the themeaning in a well-d~.~fined staridald surface form.
Of course, to I)reduco moreexpressive text, end to preserve syr,lactic as well as semantic Invari..u'~ce in thetranslation process, tile generalor must he expanded into a one-to-many mappirlgprocess compel able in complexity to !hat of the analyzer.633~ / /  +..e1,,+|o,, i.Humell Ueel!Figu re 1 -1 : Knowledge-Based Interactive Machine Translationitself in fairly non-extensible ways \[23, 17, 2, 6\].
Subsequentimprovements have succeeded in factoring out much of thedomain semantics, but leaving the syntactic interpret;.
{tion as partof the recognition program rather than as an explicit externalgrammar \[9, 14, 16\].In order to overcome these problems we have sought a methodfor static separation of the syntactic and semantic knowledgesources in the data structures, and dynanlic integration to bring allrelevant knowledge to bear in the process of parsing.
Staticseparation has the advantage that as linguistic coverageincreases, or new languages are added to the system, parsing(and translation) still function for all previous semantic domains.Conversely, if the semantic domains are extended, or new onesadded, parsing and translation of texts in these domains willfunction for all previously entered languages.
In contrast, earliermethods that mixed semantic and syntactic information requiredhand-crafted updates to all previous structures in order tointegrate new grammatical extensions or new languages.
With thepossible exception of Lytinen \[21J, who attempted a rudimentaryform of static separation and dynamic integration, this ratherappealing principle has not heretofore been a primary designcriterion of natural language parsers in general, much less fullmachine-translation systems.Many of the syntactic analysis methods do not integrate well withsemantic knowledge, especially knowledge that must be kept inseparate data structures and integrated only by the preeompiler atthe run:time language intepretation process.
Similarly, many ofthe semantic representation formalisms do not lend themselveswell to dynamic integration with syntactic constraints at parsetime.
The best fit we have been able to achieve comes fromprecompiling syntactic and semantic knowledge into a singleknowledge base which is used only at run.time, as described inthe subsequent sections.3.
System OverviewFigure 3-1 shows the architecture of our current system.
Asmentioned in the previous section, we modularize domain-specificsemantic knowledge and domain-independent (but language-specific) syntactic knowledge.
We precompile semantic entitiesand LFG-style grammars into a single large grammar which is lessperspicuous but more efficient.
This merged grammar is furtherprecompiled into a yet larger parsing table for added efficiency,enabling the run-time system to parse input text in a very efficientmanner using the parsing algorithm recently introduced byTomita \[26, 25\].
More on this issue shall be discussed in section 6.Doliiilli Iudepelltlli Knowlea ,'t H EIzal)'as eomaill ladepcudel!
Kuowll~I!
(or L~nlus~ | DefluHIoas 1 tar LaaIungl 2I I LFO.Ilke LFG-IIkI ?o',e0 ..... ,t' ," , : ; ' ."
; : ' ;  .... " .
.
.
.?
t 1 I .
.
.
.
.
.
.
.
.
.
l : ...............T __ I __.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
1 \[ ................ \] Structur e (\]rammay Structure GrammarI ................., Il _ _\[ ........... 1 Pursing TableI N P U T ~ E r n c a n t  on-line Parser Generator FUTPUr .....I Sp.c~, Reno~nieo.
~ ~ speec~ sy.
, , , , i  .
.
.
.
VeU:e \[NP T % ~ OUTPUTu ~, Inrerenc+rsFigu re 3-1; System Structure4 .
"IFh,,~ Ent i ty -Or iented  ApproachFile entity-oriented approach to restricted.domain parsing wasfirst proposed by Hayes \[16\] as a method of organizing semanticand symactic information about all domain conc(;pts around acollection of various entities (objects, events, commands, states,etc.)
that a particular system needs to recognize.
An entitydefinition contains information about tile internal structure of theentities, about relations to other entities, about the way tile entitieswill be manifested ia tile natural language input, and about thecorrespondence between the internal structure and multiplesurface forms for each entity.Let us consider the domain of elector-patient conversations; inparticular, the patient's initial complaint aboul some ailment.Entities in this domain include an event entity PA/IENI-COMPLAINT-ACT and object entities PAIN, HUMAN and so on.
Afragment of an entity.oriented grammar is shown in figure 4.1.The notation here is slightly simplified from that of Hayes,Sentences of different surface form that should be recognized asinstantiations of this entity include:I have a head acheI have a burning pain in the chest.I don't feel any pain.Did you have a dull ache in your head?\[EetityName: PAT I EHT-COMPLAINT-ACTType: STRUCTUREDAgent: IIUMAN ; Semantic restr ict ion on the agent.Pain; PAINSur faceRepreeentat ion :\[Syntaxr~/pe : SENTENTIALHead: (have  J fee l )Subj: ($Agent) ; SAgent and SPain refer to theDOb~'.
(SPain) \] \] ; semantic cases above.634\[EntityName: PAINType: STI~UCTUREOLocation: BODY-PART ; Semantic restr ict ion o11 tile locationPainKied : PAIN-FEELSur faceRepr esentat ion :\[Syntaxlype : NOUNPHRASEllead: (pain I ache)PP: ( \[Prep: iaComp: ($Location) \]) ,AdJ: ( \[AdjPhrase: (sharp I stabbing I acuLe \[ sudden)Component  ; Pa illKindValue: ACUTE \]\[AdjPhraso: (du)\] I throbbing I diffuse i lasting)Component: Pair~KindValue: DIFFUSE \])\]\]Figure 4-1 : Example Entity DefinitionThe final semantic representation of the sentence"1 have a (lull ache in my chest"produced by insLantiating entities is shown in figure 4-2.\ [C  fnan le  : MEI) I CAI_-COMPLA I N r--AC rt.yRe '.
SEN i I \ [NT \ [A tagea  L : \[of name: PERSONn,lmle: *spuake~ "~ \] ; t i l e  " I "  vthn has  the  c l les t  ache .pa i r l :  \[C FiIafilO; PAINlocal ion: \[cfname : IIODY-PAIIIname:  CIU!ST \]pain-kind: I)IFFUSE\]\]Figu re 4-2: Sample Semantic Representation:Instantiated EntitiesThe 'SurlaceRepresentation' parts of an entity guide the parsingby providing syn\[actic structures tied to the semantic portion oftile entity.
A', \[he result ol parsing a sentence (see figure 4-2), acomposiiion uf the semantic porlion e\[ the instantiated orltities isproduced.
This knowledge structure may be given to any backendprocess, whether it be a language generator (for the targetlanguage), a paraphraser, a data.base query system, or an expertsystem.The primary advantage of the entity-oriented grammar fortnalismhinges on its clarity of the sub-language definition (seeKittredge\[20\] for a discussion of sub-languages).
Since allinformation relating to an entity is grouped in one place, alanguage definer will be able to see more clearly whether adefinition is complete and what would be the consequences of anyaddition or change to the definition.
Similarly, since syntactic andsemantic information about an entity are grouped together, theformer can refer to the latter in a clear and coherent way, beth inthe grarnmar production and in the run time system.
Thisadvantage is even more valuable in the application to multi-lingualmachine translation.
Because the semantic portions of the entitiesare totally language independent, we can use one set of entitydefinitions for all languages .- merely requiring that each entityhave a multiple number of surface forms; one or more for eachlanguage.
In this way, on can ensure that semantic coverage isconsistent across all languages.In addition to clarity and its multi.lingual extensibility, anotheradvantage of the entity-oriented approach isrobustness in dealingwith extragrammatical input.
Robust recovery from ill-formedinput is a crucial feature for practical interactive languagesystems, but is beyond the immediate scope of this paper.
SeeCarbonell and Hayes \[7J for a full discussion on entity.basedrobust parsing.The major limitation of entity-oriented grammars arises from thevery same close coupling of syntax and semantics: all syntacticknowledge common across domains (or across entities within onedomain) must be replicated by hand for each and every entitydefinition.
Syntactic generalities are not captured.
This problemis not merely an aesthetic one; it takes prodigious efforts forgrammar developers to build and perfect each domain grammar,with little cross-domain transfer.
14ow then, can one overcomethis central limitation and yet retain all the advantages of semanticanalysis in general and the entity-oriented approach in particular?The answer lies in decoupfing the syntactic information atgrammar dew)lopment ime -- thus having a general grammar foreach language and integrating it via an automatedprecompilation process to produce highly coupled structures forthe run-time system.
Such an approach has been made possiblethrough the advent of unification and flmctional gramrnars.5.
The Functional Grammar FormalismFunctional grammars, as presented by Kay \[18\], provide the keyto automated compilation of syntactic and semantic knowledge.In essence, they define syntax in a functional manner based or\]syntactic rolus, ralher than by positions of constituents in thesurface string.
The functional framework has clear advantages forlanguages such as Japanese, wh~,re word order is of milch lesssignificance than in t?nglish, but case markings tape up the role ofprovidin.~l Ihe surface cues for assigning syntactic and semanticroles to each constituent.
Moreover, functional structuresintegrate far more coherently into case-frame based semanticstructures such as entity definitions.Two well-known functional grammar formalisms are FunctionalUnification Grammar rUG)\[19\] and Lexical Function Grammar(LFG\] \[4\].
In this paper, however, we do not distinguish betweenthem and refer to both by the term "functional grammar".Application of the functional grammar formalism to machinetranslation is discussed in \[tg\].
Attempts have being made toimplement parsers using these grammars, most notably in thePATR-II project at Stanford \[22, 24\].
However, these efforts havenot been integrated with external semantic knowledge bases, andhave not been applied in the context of KBMT systems.There are two main advantages of using the functional grammarformalism in practical machine translation systems:?
A system implemented strictly within the functionalgrammar formalism will be reversible, in the sense thatif the system maps from A to B then, to the sameextent, it maps from Eli to A. lhus, we do not need towrite separate grammars for parsing and generation.We merely compile the same grammar into an efficientuni.directional structure for parsing, and a differentuni-directional structure for generation into thatlanguage.?
Functional grammar formalisms such as UG and LFGare well-known among computational inguists, andtherefore need not be trained (with some justifiableresistance) to write grammars in arcane system-specific formalisms.The general problem in parsing with functional gramrnars isimplementation inefficiency for any practical application.Although much work has been done to enhance efficiency\[24, 22\], the functional grammar formalisms are considered farless efficient than formalisrns like ATNs\[28\] or (especially)context-free phrase structure grammars.
We resolve thisefficiency problem by precompiling a grammars written in a thefunctional grammar (together with a separate domain semanticsspecification) into an augmented context-free grammars, .asdescribed in the following section.6.
Grammar Precompilation and EfficientOn-Line ParsingThe previous two sections have described two kinds ofknowledge representation methods: the entity.oriented grammarformalism for domain specific but language general semanticknowledge ,and the functional grammar formalism for domain-independent but language specific syntactic knowledge In order635to parse a sentence in real time using these knowledge bases, weprecompile the semantic and syntactic knowledge, as well asmorphological rules and 'dictionary, into a single largemorph/syn/sem grammar.
This morph/syn/sem grammar isrepresented by a (potentially very large) set of context-free phrasestructure rules, each of which is augmented with a Lisp programfor test and action as in ATNs 3 A simplified fragment of amorph/syn/sem grammar is shown in figure 6-1.patient-complalot-act-1-S --> patient-NP complaint-act-1-VP((cond ((equal (not (getvalue '(x1: agr:)))(oetvalue '(x2: agr:)))(return nil)))(setvalue '(xO: semcase:) (getvalue '(x2: semcase:)))(setvalue '(xO: semcase: agent:) (getvalue '(x1: semcase:)))(setvalue '(xO: syncase:) (getvalue '(x2: syncase:)))(setvalue '(xO: syncase: subj:) (getvalue '{xt:)))(return (getvalue '(xO:))))complaint-act-l-VP --> complaint-act-l-V((setvalue"(xO: semcase:) (getvalue '(x1: semcase:)))(setvalue '(xO: syncase: prod:) (getvalue '(x1:)))(setvalue '(xO: agr:) (getvalue '(x1: agr:)))(setvalue '(xO: form:) (getvalue '(x1: form:)))(return (getvalue '(xO:))))complaint-act-1-V --> ACHE-V((setvalue '(xO: semcase: cfname:) 'PATIENT-COMPLAINT-ACT)(setvalue '(xO: agr:) (getvalue '{x1: agr:)))(setvalue '(xO: form:) (getvalue '(xl: form:)))(return (getvalue '(xO))))Figure 6-1 : A Compiled Grammar FragmentOnce we have a grammar in this form, we can apply efficientcontext-free parsing algorithms, and whenever the parser reducesconstituents into a higher-level nonterminal using a phrasestructure rule, the Lisp program associated with the rule isevaluated.
The Lisp program handles such aspects asconstruction of a semantic representation of the input sentence,passing attribute values among constituents at different levels andchecking semantic and syntactic constraints such as subject-verbagreement.
Recall that those Lisp programs are generatedautomatically by the grammar precompiler from LFG f-structuresand semantic entities.
Note also that the Lisp programs can befurther compiled into machine code by the Lisp compiler,We adopt the algorithm introduced by Tomita \[25, 26\] as ourcontext-free parsing algorithm to parse a sentence with thenlorph/syn/sem grammar.
The Tomita algorithm can be viewedas an extended LR parsing algorithm \[t\].
We compile further themorph/syn/sem grammar further into a table called theaugmented LR parsing table, with which the algorithm works veryefficiently.The Temita algorithm has three major advantages in theapplication of real-time machine translation systems;raThe algorithm is fast, due to the LR tableprecompilation; in several tests it has proven fasterthan any ether general context-free parsing algorithmpresently in practice.
For instance, timings indicate a5 to t0 fold speed advantage over Earley's algorithmin several experiments with English grammars andsarnple sets of sentences.?
The efficiency of the algorithm is not affected by thesize of its grammar, once the LR parsing table isobtained.
This characteristic is especially importantfor our system, because the size of themorph/syn/sem grammar will be very large Inpractical applications.,, The algorithm parses a sentence strictly from left toright, proving all the on-line parsing advantagesdescribe below.The on-line parser starts parsing as soon as the user types in thefirst word of a sentence, without waiting for the end of a line or asentence boundary.
There are two main benefits from on.lineparsing:raThe parser's response time can be reducedsignificantly.
When the user finishes.typing a wholesentence, most of the input sentence has beenalready processed by the parser,?
Any errors, such as mis-typing and ungrammaticalusages, can be detected almost as soon as theyoccur, and the parser can warn the user immediatelywithout waiting for the end of the line.Thus, on-line parsing provides major advantage for interactiveapplications (sucb as real-time parsing, immediate translation oftelex messages, and eventual integration sith speech recognitionand syntesis systems), but is transparent when operating in batch.processing mode for long texts.
More discussion of on-lineparsing can be found in Chapter 7 of Tomita \[25\].7.
Future Direct ionsThe twin advantages of the KBMT approach and the reversiblefunctional grammars, applied to f-structures and semantic entitydefinitions, are 1) to provide a measure of extensibility that cannotbe achieved via the conventional transfer grammar approach, and2) to enable efficient real-time parsing via multi-stageprecompilation.
A further advantage over traditional transfergrammars becomes evident when one considers the translationproblem from a more global perspective.
In order to translatebetween any pair of N languages, our approach requires .thedevelopment of only N bi-directienal grammars (one perlanguage).
On the other hand, the conventional transfer approachrequires that a new grammar be developed for each pair oflanguages and for each direction of the translation, Thus, toachieve the same number of bi-directional translations, requireson the order of N 2 transfer grammars.
This calculation yields over5,000 transfer grammars vs 72 functional/entity grammars totranslate among the 72 most commonly spoken languages today.Recall that in addition to the economy of developrnent argument,the KBMT paradigm produces meaning.invariant translations forthose domains whose semantics have been successfully codified.Although we have made significant inroads in the establishmentof knowledge-based machine translation as a viable and superioralternative to the transfer grammar methodology, much of thedifficult work remains before us.
The integration of entity-orientedsemantic representations and a generalized functional grammar,coupled with grammar precompilers, on-line parsers andgenerator provide a significant improvement over the firstsuccessful attempts to perform knowledge.based machinetranslation \[10, 5\].
The improvements are based on extensibilityand uniformity of the semantic and syntactic knowledge sources,providing static separation and dynamic "run-time" integration,Our initial implementations convince us that this approach mayhold the key to practical KBMT.Our pilot system operates in a subdomain ()f doctor.patientcommunications, selected for its relative syntactic richness, butfairly self-contained semantics.
We have selected English andJapanese as our initial source and target languages, although weare also starting to investigate Spanish, French, German andItalian.
Moreover, we are-striving to produce a system requir!ngmihimal if any clarification from the source-language user in his or3 re be exact, eaeh rule has two Lisp programs; one lot parsing and the other forgel~erntion, Thec~e programs ale syt~thesized automatically by the ptecenlpiler inoldel \[0 tesl ~t~ltlOOtJc aRd Sylltac\[iC ~:onstraiuts.
including as Iong-dislaocedependencies alibi to assign const\[iucllts their appropriate sornantic and syntactic636her own language, and no aid whatsoever from a human translatoror "posteditor" who knows both languages.
We intend to growthis pilot system in several dimensions, including achieving ameasure of completeness in subdomain coverage, adding one ortwo more languages, moving to a second and perhaps a thirddomain, and tailoring our implementation for relative efficiency ofoperation by completing the development of our multi-phaseprecompilers.In additio!\] to continued construction and extension of the pilotsystem -- the vehicle through which we are testing our theoreticaltenets -- we are pursing the following objectives:?
B i -d i rect ional i ty  -- As discussed above, functionalgrammars are theoretically bi-directional, but such aproperty has not yet been proven in practice for largescale systems.
Our approach is not to interpret thebi-directienal grammars directly, but rather to compilethem into much more efficient (and different) parsingand generation grarnmars, The latter endeavor stillrequires empirical wtlidation.o hlcrenler ltal  Compi lat ion ..
In order to expedite thegrammar development and testing cycle, we arecontemplating incremental compilation for newadditions or recent changes into large existinggn~mmars rapidly.
Although the compilation processhas proven successful in earlier parsers we have built\[3,27\], incremental compilation introduces newteuhnical problems.~, User ex'tensJbility -- A longer range research topicis to provide zt structured interface whereby a user ofth(~ KI\]MT system couM add donlain knowledge(entities) sad dictionary envies without r(.
'quiring anykno~Icdgc of the internal struciure of the system.Extendir~ 9 th,!~ lexicon i'.~, of course, milch simpler themextending the domain semantics.
All such extensionswould work in concert with existing domainknowledge, lexicon, and grammar.e Robustness -- The recognition of ill-structuredlanguage is very important, especially for the short-text domains we envision for our system (telexmessages, banking transactions, doctor.patientdialogs, etc.).
We have built selective-relaxationmethods that integrate semantic and syntacticconstrains before in the MULTIPAR system \[7, 12\], buthave not yet investigated their application orextension into the functional/entity paradigm selectedhere.?
Speech Compat ib i l i ty  -- A long-term objective is tointegrate speech recognition and generation with on-line real-time machine translation.
A parallel projectat CMU is integrating speaker-independentcontinuousospeech recognition with a case.framesemantic parser of English \[15\].
We expect results ofthat investigation, which is already moving towardsthe precornpilation parsers discussed here, to pavethe way towards eventual translation of spokenlanguage.We expect that these and other developments will require acontinued focused research effort over the coming years.
4 Weclaim only to have taken one more stride in the long marchtowards the theoretical and practical development of fully-automated knowledge-based machine translation.8.
References1.
Aho, A. V. and UIIman, J.
\[)., The Theory of Parsing, Translationand Compiling, Prentice-Hall, Englewood Cliffs, N. J., , Vol.
II,1972.2.
Birnbaum, L. and Selfridge, M., "Conceptual Analysis in NaturalLanguage," in Inside Computer Understanding, R. Schank andC.
Riesbeck, ads., New Jersey: Erlbaum Assoc., 1980, pp.318- 353.3.
Boggs, W. M. and Carbonell, J. G., Kee, M. and Monarch, I.,"The DYPAR-I Tutorial arid Reference Manual," Tech.
report,Carnegie-Mellon University, Computer Science Department,1985.4.
Bresnan, d. arid t(aplan, R., LexicaI.Functional Gramman hFormal System for GramnlatJcal Re.pres6,otation, MIT Press,Cambridge, Massachusetts, t 982, pp.
173.281.5.
Carbonell, J. G., Cutlingford, R. E. and Gershman A. G., "StepsTowards I<nowledge-Based Machine Translation," IEEE Trans.PAMI, Vol.
PAMI-3, No.
4, July 1981.6.
Carbonell, J. G. and Hayes, P. J., "Dynamic Strategy Selectionin Flexible Parsing," Proceedings el the 19th Meeting of theAssociation for Con'~putatienal Linguistics, 1981.7.
Carbonell, J. G. and Hayes, P. J., "Recovery Strategies forParsing Extragrammatical Language," American Journal ofComputational Linguistics, VoI.
9, No.
3-4, 1983, pp.
123-146.8.
Carbonell, J. G., and Tomita, M., "Knowledge.Based MachineTranslation, The CMU Approach," in Theoretical Issues inMachine Translation, Nirenberg, S., ed., Cambridge, U. Press,1986.9.
Carbonell, J. G., "Discourse Pragmatics in Task-OrientedNatural Language Interfaces," Proceedings of the 21st annualmeeting of the Association for Computational Linguistics, 1983.10.
Charniak, E. and Wilks, Y., Computational Semantics,Amsterdam: North Holland, 1976.11.Earley, J., "An Efficient Context-free Parsing Algorithm,"Communication of ACM, Vol.
6, NO.
8, February 1970, pp.94-102.12.
Fain, J., Carbonell, J. G., Hayes, P. J. and Minton, S. N.,"MULTIPAR: a Robust Entity-Oriented Parser," Proceedings ofSeventh the Cognitive Science Society Conference, Irvine, CA,1985, pp.
110-119.13.
Gazdar, G., Phrase Structure Grammar, D. Reidel, 1982, pp.131-186.14.
Hayes, P. J. and Carbonell, J. G., "A Natural LanguageProcessing Tutorial," Tech.
report, Carnegie-Mellon University,Computer Science Department, 1983.15.
Hayes, P. J., Hauptmann, A., Carbonell, J. G., and Tomita, M.,"Parsing Spoken Language: a Semantic Caseframe Approach,"Proceedings of COLING-86, 1986.4Since the deve\]oDieent of this new.generation technology for knowledge-based machine translation promises Io be a lYlajer i lew direction to the field, butrequires sLibslantial resources to grow frolri theoretical conceptiun to large-sea.toapplication, we are starting the International Center for Machine Translational CMU.
"file center is dedicat~,,d to research and devnlopmenl of new techl3iquesfor machine Iraaslatien and theil eegineerinc into substantial denlonstratierlsystems.
)Is first major project is the investigation at the lunctionatgrammar/entily-orierlted approach to 1(\[3M\], as fJlosenled irl this hOPer.
Persor, sieteresled in acquiring more inlellnStiorJ aboel tlln center elay rio slJ I.
)y COl~taclitlgone of the atl~l;OlS.63716.
Hayes, P. J., "Entity-Oriented Parsing," lOth InternationalConference on Computational Linguistics, Stanford, July 1984,pp.
212.217.17.
Hendrix, G. G., Sacerdoti, E. D. and Slocum, J., "Developing aNatural Language Interface to Complex Data," Tech.
reportArtificia!
Intelligence Center., SRI International, 1976.18.
Kay, M., "Functional Gramrnar," Fifth Annual Meeting of theBerkeley Linguisti~ Society, MI\] Press, Berkeley, California,February 1979, pp.
pp.
142-158.19.
Kay, M., "Functional Unification Grammar: A Formalism forMachine Translation," lOth International Conference onComputational Linguistics, Stanford, July 1984, pp.
75-78.20.
Kittredge, R. and Lehrberger, J., Sublanguages: Studies ofLanguage in Restricted Semantic Domains, deGruyter, Berlin,1981.21.
Lytinen, S., The Organization of Knowledge in a Multi-lingual,Integrated Parser, PhD dissertation, Yale University, November1984.22.
Pereira, F. C. N., "A Structure-Sharing Representation forUnification-Based Grammar Formalisms," 23rd Annual Meetingof the Association for Computational Linguistics, Chicago, July1985, pp.
137-144.23.
Riesbeck, C., "Conceptual Analysis," in Conceptual InformationProcessing, R. C. Schank, ed., Amsterdam: North-Holland, 1975,pp.
83-156, ch.
4.24.
Shieber, S. M., "Using Restriction to Extend Parsing Algorithmsfor Complex-Feature-Based Formalisms," 23rd Annual Meetingof the Association for Computational Linguistics, Chicago, July1985, pp.
145.152.25.
Tomita, M., Efficient Parsing for Natural Language: A Fastalgorithm for Practical Systems, Kluwer Academic Publishers,Boston, MA, 1985.26.
Tomita, M., "An Efficient Context-free Parsing Algorithm forNatural Lnaguages," 9th International Joint Conference onArtificial Intefligence (IJCAI85), August 1985.27.
Tomita, M., An Efficient Context-free Parsing Algorithm forNatural Languages and Its Applications, PhD dissertation,Computer Science Department, Carnegie-Mellon University,May 1985.28.
Woods, W. A., "Transition Network Grammars for NaturalLanguage Analysis," CACM, Vol.
13, 1970, pp.
pp.591-606.638
