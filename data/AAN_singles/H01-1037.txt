The Integrated Feasibility Experiment (IFE) ProcessJ.
Allen SearsCorporation for National ResearchInitiatives1895 Preston White DriveReston, Va. 20191asears@cnri.reston.va.usStephen E. CrossSoftware Engineering InstituteCarnegie Mellon UniversityPittsburgh, PA 15213-3890sc@sei.cmu.eduABSTRACTIn this paper, we describe a process used for guiding theevaluation and transformation process for language processingresearch and development.
The Integrated Feasibility Experimentprocess is explained by describing the key six steps, and thenproviding a specific example to help understand how to implementthe steps.1.
INTRODUCTIONThe objective of this paper is to describe a reliable and repeatableprocess used to guide the development of information systemswhere technology teams must come together to implement aconcept.
This paper describes an ?IFE process?
that has beenused successfully multiple times over the last eight years, and hasserved as both a framework for language experimentation, and as avehicle for integrating and applying language technologycomponents.2.
DESCRIBING THE IFE SIX KEY STEPSThe IFE process consists of six steps that guide development andexperimentation.
The emphasis placed on each step depends onthe maturity of the technology and the involvement of the users.The six steps are as follows (note that the six steps aresummarized in Figure 1)2.1 Step #1: ScenarioDescribe a scenario for employing the information technology thatwill allow everyone to visualize how the technology is to be usedduring a real situation.
This step places emphasis on making thetechnology look and behave like a system.
This is a critical stepfor two main reasons:a.
For the technology teams that are to integrate technology, thescenario provides a real and accessible description of how thetechnology should be used.
This assists the teams directly indescribing the architecture and components needed to build aninformation system for the given scenario.b.
The scenario is key in describing the intent of the informationsystem to the operational user.
Typically, operational usersbecome involved in this scenario building process to give early andhelpful feedback to the technology development teams.2.2 Step #2: ArchitectureMany people believe that describing the architecture is the keystep in building and information system.
However, if the ideasabout components and interconnections are vague or incomplete,then the architecture step is actually best developed using ahypothesis and test process.
In all cases the architecture mustallow plug-and-play concepts that support the inclusion and reuseof mature processing components, plus the inclusion of newcomponents that will be the focus of experimentation.2.3 Step #3: Reuse Components:The third step is to identify and make plans to reuse componentsthat one will depend on during the IFE.
This step is critical forthe technology teams because many of the components to be usedcome from years of development and experimentation.
Withmature components populating a large share of the architecture,the development teams are then free to experiment with newcomponents that are considered to be necessary for end-to-endprocessing.
Moreover, the developers can experiment with dataflow and interconnection strategies.
This experimentation step iscritical in order to transform into tomorrows?
network-centricprocessing models supported by communication interoperabilityprovide by TCP/IP processing.2.4 Step #4: User InvolvementObtaining operational user involvement early-on is an importantstep to support a technology transformation objective.
Theoperational user will have insights and needs that cannot bepredicted by the technology developers.
Moreover, userinvolvement improves the interest, understanding and potentialcommitment to the technology.
If user centered final exam metricsare stated clearly then they provide a useful objective to helpfocus technology development and implementation.
This all maysound like motherhood, but it is a critical step that is missing oftenfrom technology development projects large and small.2.5 Step #5: Rapid PrototypingThe use of a rapid prototype approach is not new.
In the mid1980s it became the key focus for specifying and buildinginformation systems.
However, the rapid prototype process mustbe used in conjunction with other steps of the IFE, or else thedevelopment effort will end up as a simple demonstration thatdoes not scale to real user needs.
The spiral development modelfor development that emphasizes the ?build a little, test a little?approach, should be used to keep development on track andheaded toward the target needs of the user.2.6 Step #6: Evaluation and FeedbackMetric-based evaluation is important for any developmentprocess.
For an IFE the specification of usable metrics is not easybecause the teams are coming together to build a ?new?
capability.The best approach comes by making an early commitment andfollowing through with the measurement process and then laterchanging the evaluation process to better represent the emerginginformation processing capability.
One should have measures fortechnology accomplishment and such measures should focus oncomponent performance.
In addition, one must have an overall?task performance?
metric or metrics that reflect the needs of theoperational user and the intent of the scenario.Integrated Feasibility Experiment Steps1.
Scenario  ..
Helps to visualize the use of new technology2.
Architecture  ..
Components, interconnects, data flow, andprocessing model3.
Reuse components ..  Must build on past accomplishments4.
User  ..
The user provides application pull, as opposed totechnology push5.
Rapid prototype  ..
Build a little, test a little strategy to keepeffort on track and on target6.
Evaluation and feedback:  Metrics-based evaluations are keyto understanding accomplishmentFigure 1: The six steps of an Integrated Feasibility Experiment2.7 Historical NoteAn Integrated Feasibility Development (IFD) process was firstused in 1990 by Steve Cross and his team to guide development ofthe DARPA and Rome Labs  replanning system called DART(Dynamic Adaptive Replanning Technology).
DART wasdeveloped to assist logistics and transportation planners inscheduling the movement and deliver of people and materials.
Anoperational prototype was actually used during the Persian Gulfconflict in 1990.
The IFD name has been changed to IFE byreplacing ?Development?
with ?Experimentation?
in order toemphasize the experimentation and scientific exploration aspect ofthe effort, but the steps of the process have remained the same.3.
WHY THE IFE PROCESS WORKSTheir three good reasons the process works and a forthexplanation that deals with the basics of building andimplementing information technology.3.1 Application PullThe scenario and user involvement (steps 1 and 4) work togetherto provide an ?application pull?
on the technology.
To manyefforts fail because they start with a new idea which is pushed anddeveloped and then is found to be in search of  (ISO) of ameaningful application.
This ?application push?
model fails inmost cases because no user is willing or able to invest in anacquisition follow-on process.
Instead, the application pullprocess will address new information system introductionmethods that take full advantage of commercially createdinformation technology, and blend in radically new ideas thatprovide for scale and success.
These steps insure transformationefforts will be based on innovation and speed.3.2 Scalable BaselineThe architecture and reuse-of-components focus (steps 2 and 3)provides a baseline capability that will enable the informationtechnology to scale up to deal with operational needs.
Moreover,this investment in the software architecture provides theinfrastructure needed to explore new ideas in an affordable andrepeatable fashion.3.3 Build A Little, Test A LittleRapid prototyping and evaluation steps (steps 5 and 6) offer asimple and understandable approach to allow for incrementalprogress that is informed by failure as much as by achievement.This is key.
Innovation must be allowed to fail just as long as theprocess moves forward and is informed in a positive way by thefailure.
Too many projects fail to provide for the process ofmanaging risk and failure.
Such projects are doomed to incrementaladvancement at best.3.4 A Managed Process That WorksSome observers of the IFE process have said the six steps arenecessary and sufficient to provide guidelines for informationsystems development and implementation.
Necessary andsufficient does not guarantee success.
It does however provide asmall and simple set of steps that can help the technologycommunity to shape information technology, and give it anoutstanding shot at success.
In most instances the IFEmethodology has addressed crisis action and crisis responsescenarios that address dynamic problems in the effective use ofpeople, resources, information, and network-centric computing.This methodology has been used to increase cooperation betweendefense and intelligence groups to develop command, control,computing, and intelligence infrastructure fundamental todeveloping new concepts of operation, and the foundation onwhich future capabilities are built.4.
AN EXAMPLE IFEThe following provides an example of the Strong Angel IFE usedfor the ?PacTIDES?
exercise in June 2000.
This exercise wassponsored by the US Joint Military Command known asCinCPAC and included seven other nations and the UnitedNations.
Both the accomplishments and the lessons learned willbe covered.
The Strong Angel IFE provided and outstandingframework for learning more about end-to-end languageprocessing.4.1 Strong Angel IFE OverviewStep 1.
Scenario:  The primary application focus for the IFEwas the spread of  disease, with special emphasis givento information processing techniques.
The operationaluser was Dr. Eric Rasmussen, MD who was the ThirdFleet Surgeon for the United States Navy.
Dr.Rasmussen was most concerned about providingeffective support and relief to people during?Humanitarian Assistance?
operations that arebecoming common through out the world.
Exampleslike Bosnia and Kosovo come to mind immediately.The story line was that refugees were caught in aborder location and world organizations were comingtogether to provide food, shelter, and security.
Thespread of disease soon became one of the top securityrisks.
The TIDES system was used by the securityteams to get timely information about relevant eventsso they could anticipate critical situations they mayface instead of simply reacting to issues.Step 2.
Technology teams outlined a plug-and-play architecturecalled the ?TIDES Portal?
that was used to guide thedevelopment and experimentation process.
Thearchitecture was built on a client ?
server model wherecomponents for language processing were looselyconfederated over the Internet.Step 3: Component specification: The three primaryinformation processing components were focused ondetection, extraction, and user interaction.
There alsowas a translingual component that provided two waytranslations to and from Korean.
The scenario wasexpanded to include the treat of a missile launce fromNorth Korea that could carry a biological war-head.The translingual component was an add-on rather thana main line processing component.
There were sevendifferent sources of news that was being processed toprovide information to relief and security personnel.These sources included both text and speechinformation.
The speech information was transformedinto text and then became input to detection andextraction processing.
The user interface componentwas the most difficult to construct because theunderlying end-to-end processing model was emergingand changing each month.
Moreover, the looselycoupled distributed processing model for the TIDESPortal was difficult to realize in a coherent userinterface.
This issue and other shortcomings arediscussed in the lessons learned section of this paper.Step 4: Operational User Involvement.
The scenario definitionprocess helped Dr Rasmussen and the other relief andsecurity operators understand how the technologywould come together to be used.
The TIDES Portal andthe ?PacTIDES?
experiments were use byrepresentatives of several of the RIMPAC nations andalso by United Nations personnel.
For the first timeever the RIMPAC exercises conducted by sevennations: US, Canada, Japan, Chile, Australia, Korea,and UK, included a focus on a humanitarian assistanceissues.
For the first time users were able to understandin context the kinds of capability an automatedinformation processing system such as TIDES mayprovide in the future.
The potential for TIDES supportreceived strong endorsement from these operators whoare literally overwhelmed by data, documents, andemail, but who are often starved for actionableinformation.Step 5.
The rapid prototype process was used to develop theIFE integrated system called the ?TIDES Portal?.Initial TIDES Portal implementation was tested inearly 2000, and the final exam for TIDES Portal wasconducted during Strong Angel was held In June 2000on the Parker Ranch in Hawaii.
The system was usedby military and by UN World Food Programpersonnel.
There was one situation where UN folksneeded timely information about a situation in Africa,and the TIDES Portal came through.
The UN team wasimpressed.
However, most of the lessons learned atStrong Angel pointed to weaknesses in the TIDESPortal concept of operations.
These weaknesses havebecome the main focus for development of IFE-Bio in2001.Step 6.
Metric-based evaluation was used in Strong Angel withlimited success.
The weaknesses in the end-to-endprocessing capability of the TIDES Portal dominatedthe IFE and limited the ability of research groups toconduct full metrics-based evaluations in a meaningfulway.
This issue will receive more attention in duringIFE-Bio final exams in June 2001.5.
LESSONS LEARNEDThe Strong Angel IFE was judged to be a success even thoughseveral parts of the effort resulted in failure.
The important pointis that the TIDES Program learned from both the failures and theaccomplishments and the lessons help guide the IFE process in2001.
The following provides an example of the Strong Angel IFEused for the ?PacTIDES?
exercise in June 2000.
This exercise wassponsored by the US Joint Military Command known asCinCPAC and included seven other nations and the UnitedNations.
Both the accomplishments and the lessons learned willbe covered.
The Strong Angel IFE provided and outstandingframework for learning more about end-to-end languageprocessing.5.1 Lessons Learned From Negative Examplesin Strong Angel IFEA.
Process model was too uncoupled.
Several groups cametogether integrated by only the Internet.
The processingcomponents were not synchronized and basically hadlittle inter-dependency.
Therefore, there was little in theway of information management within theinfrastructure to hold the information processing modeltogether.B.
Late-binding decisions about distributed processingburned up critical development cycles.
The situationhere is simple: initially the assumption was made thatfull Internet connectivity at T1 rates would be available,and then the assumption was changed to anticipate NOInternet connectivity outside of the camp.
The change inthe Internet connectivity and quality of serviceassumptions were made with two months to go.
Mostof the time was then spent on building local servers andprocesses that would simulate that externalcommunications was in place.
During the critical lasttwo months critical development and testing wasstopped and attention was turned to re-engineering theprocessing infrastructure.C.
Collection issues were not properly anticipated:  Thestrengths of TIDES processing comes from end-to-endprocessing of streams of information from sources suchas radio, TV, email, newswire, etc.
Unfortunately thelanguage detection and extraction communities areconditioned to processing from training and test setsprovided to them in efforts such as TREC and MUC.Strong Angel concepts of operation actually requiredcontinuous processing of streaming information frommultiple sources.
These capture and processingpriorities were not realized soon enough in the IFEprocess, and were therefore sorely lacking at the StrongAngel final exam.D.
TDT processing concepts were not included:  Thedetection, extraction, and summarization process forStrong Angel anticipated Topic Detection and Tracking(TDT) capabilities, but the algorithms were neverincorporated.
This means that critical front-end filteringand grouping functions were missing.5.2 Lessons Learned From Positive Examplesin Strong Angel IFEA.
The Strong Angel team never imagined how difficult theliving and information processing environment could bein a refugee camp.
In fact there was fine grain dusteverywhere and the power was intermittent.
Betterunderstanding of these environmental factors was apositive coming from the Strong Angel effort.B.
A key positive was developing the understanding forhow detection, extraction, and summarization mustwork together with collection and distribution toprovide an end-to-end processing infrastructure.C.
An important accomplishment occurred when UN folkswanted to know more about a growing crisis in Ugandaafter a humanitarian incident.
It turns out that TIDESprocessing was able to give the UN contingentinformation that they needed that was current and multi-source.
The UN folks were thrilled and amazed.
Mostamazing to the TIDES folks was the capability onlyused 10% of what was anticipated for TIDESprocessing.
In other words, a very small and easyproduct provided significant value.
There is greatconfidence that much more can be accomplished in IFEprocessing in 2001.6.
LOOKING AHEAD FOR THE IFEPROCESSFor TIDES two different but concurrent IFE processes are beingpursued during 2001.
First a team including MITRE, UMASS,NYU, and the Navy are developing IFE-Bio concerned withgathering real time information to aid in the analysis of spread ofdisease.
A team of BBN, UMASS, and CIA are looking atautomatically extracting information in real time from a wide rangeof Arabic open source material.
When ready and mature,technology and language processing techniques will beincorporated into Foreign Broadcast Information Service (FBIS)processing.
A short abstraction of IFE processing six steps isprovided in figure 2 for the 2001 effort called  IFE-Bio.
In additionthe DARPA Communicator is using the IFE process to help in thedevelopment and transformation process for dialogue interaction.The Communicator IFE process is being continued aggressively in2001 by a team including Lockheed, MIT, and the United StatesMarines Corps.
For DARPA Communicator the initial LCSMarine IFE process has matured and is now being applied to awider range of military exercises.
Valuable lessons learned emergefrom every exercise and aggressive concepts of operation are beinginvestigated.IFE - Bio:  Example for TIDES?
Scenario:  TIDES technology will be used to extract information aboutspread of specific diseases.
Crisis response teams will pose ad hocquestions to the system.?
Architecture:  End-to-end processing to include source capture from audioand text, TDT processing, extraction, summarization, and finally alerting &distribution.?
Reuse components:  IFE - Bio will use language processing componentsfrom NYU, UMASS, and MITRE?
User:  LCDR.
Eric Rassmussen, former Third Fleet Surgeon, will stresstest the IFE crew to see how well they respond to questions that wouldcome up during a crisis.?
Rapid prototype: Initial build for 27 Feb, then mid-term in April will testsecond build, finally the June 2001 will test the final build of the prototype.?
Evaluation and feedback: Technical evaluations will cover all keycomponents.
The user evaluation will focus on ease-of-use andperformance improvementFigure 2: Overview example of IFE-Bio
