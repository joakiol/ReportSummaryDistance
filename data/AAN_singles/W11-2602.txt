Proceedings of EMNLP 2011, Conference on Empirical Methods in Natural Language Processing, pages 10?21,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsDialectal to Standard Arabic Paraphrasingto Improve Arabic-English Statistical Machine TranslationWael Salloum and Nizar HabashCenter for Computational Learning SystemsColumbia University{wael,habash}@ccls.columbia.eduAbstractThis paper is about improving the qualityof Arabic-English statistical machine trans-lation (SMT) on dialectal Arabic text us-ing morphological knowledge.
We present alight-weight rule-based approach to producingModern Standard Arabic (MSA) paraphrasesof dialectal Arabic out-of-vocabulary (OOV)words and low frequency words.
Our ap-proach extends an existing MSA analyzer witha small number of morphological clitics, anduses transfer rules to generate paraphrase lat-tices that are input to a state-of-the-art phrase-based SMT system.
This approach improvesBLEU scores on a blind test set by 0.56 abso-lute BLEU (or 1.5% relative).
A manual erroranalysis of translated dialectal words showsthat our system produces correct translationsin 74% of the time for OOVs and 60% of thetime for low frequency words.1 IntroductionMuch work has been done on Modern Standard Ara-bic (MSA) natural language processing (NLP) andmachine translation (MT).
In comparison, researchon dialectal Arabic (DA), the unstandardized spokenvarieties of Arabic, is still lacking in NLP in generaland MT in particular.
In this paper we address the is-sue of MT out-of-vocabulary (OOV) terms and lowfrequency terms in highly dialectal Arabic text.We present a light-weight rule-based approach toproducing MSA morphological paraphrases of DAOOV words and low frequency words.
However, wedon?t do lexical translation.
Our approach extendsan existing MSA analyzer to two DA varieties (Lev-antine and Egyptian) with less than 40 morphologi-cal clitics.
We use 11 morphological transfer rulesto generate paraphrase lattices that are input to astate-of-the-art phrase-based statistical MT (SMT)system.
Our system improves BLEU scores on ablind test set by 0.56 absolute BLEU (or 1.5% rela-tive).
A manual error analysis of translated dialectalwords shows that our system produces correct trans-lations in 74% of the time for OOVs and 60% of thetime for low frequency words.The rest of this paper is structured as follows:Section 2 is related work, Section 3 presents linguis-tic challenges and motivation, Section 4 details ourapproach and Section 5 presents results evaluatingour approach under a variety of conditions.2 Related WorkDialectal Arabic NLP Much work has been donein the context of MSA NLP (Habash, 2010).
Specif-ically for Arabic-to-English SMT, the importance oftokenization using morphological analysis has beenshown by many researchers (Lee, 2004; Zollmannet al, 2006; Habash and Sadat, 2006).
In contrast,research on DA NLP is still in its early stages: (Ki-lany et al, 2002; Kirchhoff et al, 2003; Duh andKirchhoff, 2005; Habash and Rambow, 2006; Chi-ang et al, 2006).
Several researchers have exploredthe idea of exploiting existing MSA rich resourcesto build tools for DA NLP, e.g., Chiang et al (2006)built syntactic parsers for DA trained on MSA tree-banks.
Such approaches typically expect the pres-ence of tools/resources to relate DA words to theirMSA variants or translations.
Given that DA andMSA do not have much in terms of parallel cor-pora, rule-based methods to translate DA-to-MSA10or other methods to collect word-pair lists have beenexplored.
For example, Abo Bakr et al (2008) intro-duced a hybrid approach to transfer a sentence fromEgyptian Arabic into MSA.
This hybrid system con-sisted of a statistical system for tokenizing and tag-ging, and a rule-based system for constructing dia-critized MSA sentences.
Moreover, Al-Sabbagh andGirju (2010) described an approach of mining theweb to build a DA-to-MSA lexicon.
In the con-text of DA-to-English SMT, Riesa and Yarowsky(2006) presented a supervised algorithm for onlinemorpheme segmentation on DA that cut the OOVsby half.Machine Translation for Closely Related Lan-guages Using closely related languages has beenshown to improve MT quality when resources arelimited.
Hajic?
et al (2000) argued that for very closelanguages, e.g., Czech and Slovak, it is possibleto obtain a better translation quality by using sim-ple methods such as morphological disambiguation,transfer-based MT and word-for-word MT.
Zhang(1998) introduced a Cantonese-Mandarin MT thatuses transformational grammar rules.
In the contextof Arabic dialect translation, Sawaf (2010) built ahybrid MT system that uses both statistical and rule-based approaches for DA-to-English MT.
In his ap-proach, DA is normalized into MSA using a dialec-tal morphological analyzer.
This use of ?resource-rich?
related languages is a specific variant of themore general approach of using pivot/bridge lan-guages (Utiyama and Isahara, 2007; Kumar et al,2007).
In the case of MSA and DA variants, itis plausible to consider the MSA variants of a DAphrase as monolingual paraphrases (Callison-Burchet al, 2006; Habash, 2008; Du et al, 2010).This paper presents results on a rule-based sys-tem to generate alternative paraphrases for DA OOVwords and low frequency words to help improveSMT from highly dialectal Arabic to English.
Ourwork is most similar to Sawaf (2010)?s approach toDA normalization into MSA, although we shy awayfrom the term in our work since we do not produce asingle MSA version of the input to pass on to MSA-English MT.
Instead we pass multiple paraphrases(or alternative normalizations) as a lattice to an SMTsystem, in a manner similar to Du et al (2010).
Cer-tain aspects of our approach are similar to Riesaand Yarowsky (2006)?s, in that we use morpholog-ical analysis for DA to help DA-English MT; butunlike them and similar to Sawaf (2010), we use arule-based approach to model DA morphology.
Ourmorphological analysis implementation is quite sim-ilar to the approach taken by Abo Bakr et al (2008),which extend existing MSA analyzers through rules;however, unlike them, we are not interested in gen-erating MSA per se, but rather to use it as a bridgeto English MT.
Our interest in OOV words is simi-lar to Habash (2008), who compared multiple tech-niques for handling MSA OOVs; however, unlikehim, we target dialectal phenomena and we use lat-tices as input to the SMT system.
Also related is therecent work by Nakov and Ng (2011), who use mor-phological knowledge to generate paraphrases for amorphologically rich language, Malay, to extend thephrase table in a Malay-to-English SMT system.3 Challenge and MotivationWe are primarily interested in improving Arabic-English SMT on highly dialectal text.
This partic-ular type of text has many challenges.
We discussthese challenges and motivate our research approachwith an analysis of DA OOV terms in a state-of-the-art SMT system.3.1 Arabic Linguistic ChallengesThe Arabic language poses many challenges forNLP.
Arabic is a morphologically complex languagewhich includes rich inflectional morphology, ex-pressed both templatically and affixationally, andseveral classes of attachable clitics.
For exam-ple, the Arabic word A?
E?J.J?J??
w+s+y-ktb-wn+hA1?and they will write it?
has two proclitics (+?
w+?and?
and +?
s+ ?will?
), one prefix -?y- ?3rd per-son?, one suffix 	?
?- -wn ?masculine plural?
and onepronominal enclitic A?+ +hA ?it/her?.
Additionally,Arabic is written with optional diacritics that primar-ily specify short vowels and consonantal doubling.The absence of these diacritics together with the lan-guage?s complex morphology lead to a high degreeof ambiguity: the Buckwalter Arabic Morphological1Arabic transliteration is presented in the Habash-Soudi-Buckwalter scheme (Habash et al, 2007): (in alphabetical or-der) Abt?jHxd?rzs?SDTD??
?fqklmnhwy and the additional sym-bols: ?
Z, ?
@, A?
@, A?@, w??
', y?
Z?
', h??, ?
?.11Analyzer (BAMA), for instance, produces an averageof 12 analyses per word.
Moreover, some letters inArabic are often spelled inconsistently which leadsto an increase in both sparsity (multiple forms of thesame word) and ambiguity (same form correspond-ing to multiple words), e.g., variants of HamzatedAlif,@ ?
or @A?, are often written without theirHamza (Z ?
): @ A; and the Alif-Maqsura (or dotlessYa) ?
?
and the regular dotted Ya ?y are often usedinterchangeably in word final position (Kholy andHabash, 2010).
Arabic complex morphology andambiguity are handled using tools for disambigua-tion and tokenization (Habash and Rambow, 2005;Diab et al, 2007).
For our SMT system, we pre-process the Arabic text so that it is tokenized inthe Penn Arabic Treebank tokenization (Maamouriet al, 2004), Alif/Ya normalized and undiacritized.These measures have an important effect on reduc-ing overall OOV rate (Habash, 2008).3.2 Dialectal Arabic ChallengesContemporary Arabic is in fact a collection of vari-eties: MSA, which has a standard orthography andis used in formal settings, and DAs, which are com-monly used informally and with increasing presenceon the web, but which do not have standard or-thographies.
There are several varieties of DA whichprimarily vary geographically, e.g., Levantine Ara-bic, Egyptian Arabic, etc.
DAs differ from MSAphonologically, morphologically and to some lesserdegree syntactically.
The differences between MSAand DAs have often been compared to Latin and theRomance languages (Habash, 2006).
The morpho-logical differences are most noticeably expressed inthe use of clitics and affixes that do not exist inMSA.
For instance, the Levantine Arabic equivalentof the MSA example above is A??J.J?Jk?
w+H+y-ktb-w+hA ?and they will write it?.
The optionalityof vocalic diacritics helps hide some of the differ-ences resulting from vowel changes; compare thediacritized forms: Levantine wHayuktubuwhA andMSA wasayaktubuwnahA.All of the NLP challenges of MSA describedabove are shared by DA.
However, the lack of stan-dard orthographies for the dialects and their numer-ous varieties pose new challenges.
Additionally,DAs are rather impoverished in terms of availabletools and resources compared to MSA; e.g., there isvery little parallel DA-English corpora and almostno MSA-DA parallel corpora.
The number and so-phistication of morphological analysis and disam-biguation tools in DA is very limited in compari-son to MSA (Duh and Kirchhoff, 2005; Habash andRambow, 2006; Abo Bakr et al, 2008).
MSA toolscannot be effectively used to handle DA: Habash andRambow (2006) report that less than two-thirds ofLevantine verbs can be analyzed using an MSA mor-phological analyzer.3.3 Dialectal Arabic OOVsWe analyzed the types of OOVs in our dev setagainst our large system (see Section 5) with an eyefor dialectal morphology.
The token OOV rate is1.51% and the type OOV rate is 7.45%; although thetoken OOV rate may seem small, it corresponds toalmost one third of all sentences having one OOV atleast (31.48%).
In comparison with MSA test sets,such as NIST MTEval 2006?s token OOV rate of0.8% (and 3.42% type OOV rate), these numbersare very high specially given the size of trainingdata.
Out of these OOVs, 25.9% have MSA read-ings or are proper nouns.
The rest, 74.1%, are di-alectal words.
We classified the dialectal words intotwo types: words that have MSA-like stems and di-alectal affixational morphology (affixes/clitics) andthose that have dialectal stem and possibly dialectalmorphology.
The former set accounts for almost halfof all OOVS (49.7%) or almost two thirds of all di-alectal OOVS.
In this paper we only target dialectalaffixational morphology cases as they are the largestclass involving dialectal phenomena that do not re-quire extension to our stem lexica.
The morphologi-cal coverage of the analyzer we use, ALMOR, whichitself uses the BAMA databases is only 21% of allthe OOV words.
Our analyzer, ADAM, presented inSection 4.2, improves coverage substantially.It is important to note that a word can be in-vocabulary (INV) but not have a correct possibletranslation in the phrase table.
Some of these wordsmay be of such low frequency that their various pos-sible translations simply do not appear in the train-ing data.
Others may have a frequent MSA read-ing and an infrequent/unseen DA reading (or viceversa).124 ApproachOur basic approach to address the issue of transla-tional OOVs is to provide rule-based paraphrases ofthe source language words into words and phrasesthat are INV.
The paraphrases are provided as al-ternatives in an input lattice to the SMT system.This particular implementation allows this approachto be easily integrated with a variety of SMT sys-tems.
The alternatives include different analysesof the same original word and/or translations intoMSA.
We focus on the question of Arabic dialects,although the approach can be extended to handlelow frequency MSA words also that may have beenmis-tokenized by the MSA preprocessing tools.
Asmentioned above, we only report in this work on di-alect morphology translation to MSA and we leavelemma/word translation to future work.
We identifyfour distinct operations necessary for this approachand evaluate different subsets of them in Section 5.1.
Selection.
Identify the words to handle, e.g.,OOVs or low frequency words.2.
Analysis.
Produce a set of alternative analysesfor each word.3.
Transfer.
Map each analysis into one or moretarget analyses.4.
Generation.
Generate properly tokenizedforms of the target analyses.The core steps of analysis-transfer-generation aresimilar to generic transfer-based MT (Dorr et al,1999).
In essence our approach can be thought ofas a mini-rule-based system that is used to hybridizean SMT system (Simard et al, 2007; Sawaf, 2010).4.1 SelectionThe most obvious set of words to select for para-phrasing is the phrase-table OOV words.
We iden-tify them by comparing each word in the sourcetext against all phrase-table singletons.
Another setof words to consider includes low frequency words(DA or MSA), which are less likely to be associatedwith good phrase-table translations.
We compute thefrequency of such words against the original trainingdata.
We further extend the idea of frequency-basedselection to typed-frequency selection in which weconsider different frequency cut-offs for differenttypes of words (MSA or DA).
Evaluation and moredetails are presented in Section 5.3.4.2 AnalysisWhereas much work has been done on MSA mor-phological analysis (Al-Sughaiyer and Al-Kharashi,2004), a small handful of efforts have targeted thecreation of dialectal morphology systems (Kilany etal., 2002; Habash and Rambow, 2006; Abo Bakr etal., 2008).
In this section, we present a new dialec-tal morphological analyzer, ADAM, built as an ex-tension to an already existing MSA analyzer.
Weonly focus on extensions that address dialectal af-fixes and clitics, as opposed to stems, which we planto address in future work.
This approach to extend-ing an MSA analyzer is similar to work done byAbo Bakr et al (2008) and it contrasts as rather ashallow/quick-and-dirty solution compared to othermore demanding efforts on building dialectal an-alyzers from scratch, such as the MAGEAD sys-tem (Habash and Rambow, 2006; Altantawy et al,2011).4.2.1 ADAM: Analyzer for Dialectal ArabicMorphologyADAM is built on the top of BAMA database(Buckwalter, 2004) as used in the ALMOR morpho-logical analyzer/generator (Habash, 2007), which isthe rule-based component of the MADA system formorphological analysis and disambiguation of Ara-bic (Habash and Rambow, 2005; Roth et al, 2008).The ALMOR system presents analyses as lemma andfeature-value pairs including clitics.The BAMA databases contain three tables ofArabic stems, complex prefixes and complex suf-fixes2 and three additional tables with constraintson matching them.
MSA, according to the BAMAdatabases, has 1,208 complex prefixes and 940 com-plex suffixes, which correspond to 49 simple pre-fixes/proclitics and 177 simple suffixes/enclitics, re-spectively.
The number of combinations in prefixesis a lot bigger than in suffixes, which explains thedifferent proportions of complex affixes to simpleaffixes.We extended the BAMA database through a2We define a complex prefix as the full sequence of pre-fixes/proclitics that may appear at the beginning of a word.Complex suffixes are defined similarly.13Dialect Word ??J.J?JkA??
wmAHyktblw ?And he will not write for him?Analysis Proclitics [ Lemma & Features ] Encliticsw+ mA+ H+ yktb +l +wconj+ neg+ fut+ [katab IV subj:3MS voice:act] +prep +pron3MSand+ not+ will+ he writes +for +himTransfer Word 1 Word 2 Word 3Proclitics [ Lemma & Features ] [ Lemma & Features ] [ Lemma & Features ] Encliticconj+ [ lan ] [katab IV subj:3MS voice:act] [ li ] +pron3MSand+ will not he writes for +himGeneration w+ ln yktb l +hMSA Phrase ??
I.J?K???
wln yktb lh ?And he will not write for him?Figure 1: An example illustrating the analysis-transfer-generation steps to translate a word with dialectal morphologyinto its MSA equivalent phrase.set of rules that add new Levantine/Egyptiandialectal affixes and clitics by copying and ex-tending existing MSA affixes/clitics.
For instance,the dialectal future proclitic +h H+ ?will?
hasa similar behavior to the standard Arabic futureparticle +?
s+.
As such, an extension rule wouldcreate a copy of each occurrence of the MSAprefix and replace it with the dialectal prefix.The algorithm that uses this rule to extend theBAMA database adds the prefix Ha/FUT_PARTand many other combinations involving it,e.g., wa/PART+Ha/FUT_PART+ya/IV3MS, andfa/CONJ+Ha/FUT_PART+na/IV1P.
We reservediscussion of other more complex mappings withno exact MSA equivalence to a future publicationon ADAM.The rules (89 in total) introduce 11 new dialectalproclitics (plus spelling variants and combinations)and 27 dialectal enclitics (again, plus spelling vari-ants and combinations).
ADAM?s total of simple pre-fixes and suffixes increases to 60 (22% increase) and204 (15% increase) over BAMA, respectively.
Thenumbers for complex prefixes and suffixes increaseat a faster rate to 3,234 (168% increase) and (142%increase), respectively.As an example of ADAM output, consider the sec-ond set of rows in Figure 1, where a single analysisis shown.4.2.2 ADAM performanceWe conducted an analysis of ADAM?s behaviorover the OOV set analyzed in Section 3.3.
WhereasALMOR (before ADAM) only produces analyzes for21% of all the OOV words, ADAM covers almost63%.
Among words with dialectal morphology,ADAM?s coverage is 84.4%.
The vast majority of theunhandled dialectal morphology cases involve a par-ticular Levantine/Egyptian suffix ?+ +?
?not?.
Weplan to address these cases in the future.
In about10% of all the analyzed words, ADAM generatesalternative dialectal readings to supplement exist-ing ALMOR MSA analyses, e.g., I.J?K.
bktb has anMSA (and coincidentally dialectal) analysis of ?withbooks?
and ADAM also generates the dialectal onlyanalysis ?I write?.4.3 TransferIn the transfer step, we map ADAM?s dialectal anal-yses to MSA analyses.
This step is implementedusing a set of transfer rules (TR) that operate onthe lemma and feature representation produced byADAM.
The TRs can change clitics, features orlemma, and even split up the dialectal word intomultiple MSA word analyses.
Crucially the inputand output of this step are both in the lemma andfeature representation (Habash, 2007).
A particularanalysis may trigger more than one rule resulting inmultiple paraphrases.
This only adds to the fan-outwhich started with the original dialectal word havingmultiple analyses.Our current system uses 11 rules only, which weredetermined to handle all the dialectal clitics added inADAM.
As more clitics are added in ADAM, moreTRs will be needed.
As examples, two TRs whichlead to the transfer output shown in the third set ofrows in Figure 1 can be described as follows:33All of our rules are written in a declarative form, which14?
if the dialectal analysis shows future and nega-tion proclitics, remove them from the word andcreate a new word, the MSA negative-futureparticle 	??
ln, to precede the current word andwhich inherits all proclitics preceding the fu-ture and negation proclitics.?
if the dialectal analysis shows the dialectal in-direct object enclitic, remove it from the wordand create a new word to follow the currentword; the new word is the preposition +?
l+with an enclitic pronoun that matches the fea-tures of the indirect object.In the current version evaluated in this paper, we al-ways provide a lower-scored back-off analysis thatremoves all dialectal clitics as an option.4.4 GenerationIn this step, we generate Arabic words from all anal-yses produced by the previous steps.
The gener-ation is done using the general tokenizer TOKAN(Habash, 2007) to produce Arabic Treebank (ATB)scheme tokenizations.
TOKAN is used in the base-line system to generate tokenizations for MSA frommorphologically disambiguated input in the sameATB scheme (see Section 5.1).
The various gener-ated forms are added in the lattices, which are theninput to the SMT system.5 Evaluation on Machine Translation5.1 Experimental SetupWe use the open-source Moses toolkit (Koehn etal., 2007) to build two phrase-based SMT systemstrained on two different data conditions: a medium-scale MSA-only system trained using a newswire(MSA-English) parallel text with 12M words onthe Arabic side (LDC2007E103) and a large-scaleMSA/DA-mixed system (64M words on the Arabicside) trained using several LDC corpora includingsome limited DA data.
Both systems use a stan-dard phrase-based architecture.
The parallel cor-pus is word-aligned using GIZA++ (Och and Ney,2003).
Phrase translations of up to 10 words areextracted in the Moses phrase table.
The languagemodel for both systems is trained on the Englishmay be complicated to explain given the allotted space, as suchwe present only the functional description of the TRs.side of the large bitext augmented with English Gi-gaword data.
We use a 5-gram language model withmodified Kneser-Ney smoothing.
Feature weightsare tuned to maximize BLEU on the NIST MTEval2006 test set using Minimum Error Rate Training(Och, 2003).
This is only done on the baseline sys-tems.For all systems, the English data is tokenized us-ing simple punctuation-based rules.
The Arabic sideis segmented according to the Arabic Treebank tok-enization scheme (Maamouri et al, 2004) using theMADA+TOKAN morphological analyzer and tok-enizer (Habash and Rambow, 2005) ?
v3.1 (Roth etal., 2008).
The Arabic text is also Alif/Ya normal-ized (Habash, 2010).
MADA-produced Arabic lem-mas are used for word alignment.Results are presented in terms of BLEU (Papineniet al, 2002), NIST (Doddington, 2002) and ME-TEOR (Banerjee and Lavie, 2005) metrics.4 How-ever, all optimizations were done against the BLEUmetric.
All evaluation results are case insensitive.All of the systems we present use the lattice inputformat to Moses (Dyer et al, 2008), including thebaselines which do not need them.
We do not re-port on the non-lattice baselines, but in initial exper-iments we conducted, they did not perform as wellas the degenerate lattice version.The Devtest Set Our devtest set consists of sen-tences containing at least one non-MSA segment (asannotated by LDC)5 in the Dev10 audio develop-ment data under the DARPA GALE program.
Thedata contains broadcast conversational (BC) seg-ments (with three reference translations), and broad-cast news (BN) segments (with only one reference,replicated three times).
The data set contained amix of Arabic dialects, with Levantine Arabic be-ing the most common variety.
The particular na-ture of the devtest being transcripts of audio dataadds some challenges to MT systems trained on pri-marily written data in news genre.
For instance,each of the source and references in the devtest setcontained over 2,600 uh-like speech effect words(uh/ah/oh/eh), while the baseline translation systemwe used only generated 395.
This led to severe4We use METEOR version 1.2 with four match modules:exact, stem, wordnet, and paraphrases.5http://www.ldc.upenn.edu/15brevity penalty by the BLEU metric.
As such, we re-moved all of these speech effect words in the source,references and our MT system output.
Another sim-ilar issue was the overwhelming presence of com-mas in the English reference compared to the Ara-bic source: each reference had about 14,200 com-mas, while the source had only 64 commas.
OurMT system baseline predicted commas in less thanhalf of the reference cases.
Similarly we removecommas from the source, references, and MT out-put.
We do this to all the systems we compare in thispaper.
However, even with all of this preprocess-ing, the length penalty was around 0.95 on averagein the large system and around 0.85 on average inthe medium system.
As such, we report additionalBLEU sub-scores, namely the unigram and bigramprecisions (Prec-1 and Prec-2, respectively), to pro-vide additional understanding of the nature of ourimprovements.We split this devtest set into two sets: a develop-ment set (dev) and a blind test set (test).
We reportall our analyses and experiments on the dev set andreserve the test set for best parameter runs at the endof this section.
The splitting is done randomly atthe document level.
The dev set has 1,496 sentenceswith 32,047 untokenized Arabic words.
The test sethas 1,568 sentences with 32,492 untokenized Arabicwords.5.2 Handling Out-of-Vocabulary WordsIn this section, we present our results on handlingOOVs in our baseline MT system following the ap-proach we described in Section 4.
The results aresummarized in Table 1.
The table is broken intotwo parts corresponding to the large and mediumsystems.
Each part contains results in BLEU, Prec-1 (unigram precision), Prec-2 (bigram precision),NIST and METEOR metrics.
The performance ofthe large system is a lot better than the medium sys-tem in all experiments.
Some of the difference issimply due to training size; however, another factoris that the medium system is trained on MSA onlydata while the large system has DA in its trainingdata.We compare the baseline system (first row) to twomethods of OOV handling through dialectal para-phrase into MSA.
The first method uses the ADAMmorphological analyzer and generates directly skip-ping the transfer step to MSA.
Although this maycreate implausible output for many cases, it is suf-ficient for some, especially through the system?snatural addressing of orthographic variations.
Thismethod appears in Table 1 as ADAM Only.
The sec-ond method includes the full approach as discussedin Section 4, i.e., including the transfer step.The use of the morphological analyzer onlymethod (ADAM Only) yields positive improvementsacross all metrics and training data size conditions.In the medium system, the improvement is around0.42% absolute BLEU (or 2.1% relative).
The largesystem improves by about 0.34% absolute BLEU (oralmost 1% relative).
Although these improvementsare small, they are only accomplished by targeting apart of the OOV words (about 0.6% of all words).The addition of transfer rules leads to furthermodest improvements in both large and mediumsystems according to BLEU; however, the NISTand METEOR metrics yield negative results in themedium system.
A possible explanation for thedifference in behavior is that paraphrase-based ap-proaches to MT often suffer in smaller data con-ditions since the paraphrases they map into maythemselves be OOVs against a limited system.
Ourtransfer approach also has a tendency to generatelonger paraphrases as options, which may have leadto more fragmentation in the METEOR score algo-rithm.
In terms of BLEU scores, the full system(analysis and transfer) improves over the baselineon the order of 0.5% BLEU absolute.
The relativeBLEU score in the large and medium systems are1.24% and 2.54% respectively.All the systems in Table 1 do not drop unhan-dled OOVs, thus differing from the most commonmethod of ?handling?
OOV, which is known togame popular MT evaluation metrics such as BLEU(Habash, 2008).
In fact, if we drop OOVs in ourbaseline system, we get a higher BLEU score of36.36 in the large system whose reported base-line gets 36.16 BLEU.
That said, our best resultwith OOV handling produces a higher BLEU score(36.61) which is a nice result for doing the rightthing and not just deleting problem words.
All dif-ferences in BLEU scores in the large system are sta-tistically significant above the 95% level.
Statisticalsignificance is computed using paired bootstrap re-sampling (Koehn, 2004).16Large (64M words) Medium (12M words)System BLEU Prec-1 Prec-2 NIST METEOR BLEU Prec-1 Prec-2 NIST METEORBaseline 36.16 74.56 45.04 8.9958 52.59 20.09 63.69 30.89 6.0039 40.85ADAM Only 36.50 74.79 45.22 9.0655 52.95 20.51 64.37 31.22 6.1994 41.80ADAM+Transfer 36.61 74.85 45.37 9.0825 53.02 20.60 64.70 31.48 6.1740 41.77Table 1: Results for the dev set under large and medium training conditions.
The baseline is compared to usingdialectal morphological analysis only and analysis plus transfer to MSA.
BLEU and METEOR scores are presentedas percentages.Large (64M words)System BLEU Prec-1 Prec-2 NIST METEORBaseline 36.16 74.56 45.04 8.9958 52.59ADAM+Transfer 36.61 74.85 45.37 9.0825 53.02+ Freq x ?
10 36.71 74.89 45.50 9.0821 52.97+ Freq xMSA ?
10 36.62 74.86 45.38 9.0816 52.96+ Freq xDIAMSA ?
13 36.66 74.86 45.43 9.0836 53.01+ Freq xDIA ?
45 36.73 75.00 45.57 9.0961 53.03+ Freq xMSA ?
10 + xDIAMSA ?
13 + xDIA ?
45 36.78 74.96 45.61 9.0926 52.96Table 2: Results for the dev set under large training condition, varying the set of words selected for MSA paraphrasing.5.3 Extending Word SelectionFollowing the observation that some dialectalwords may not pose a challenge to SMT since theyappear frequently in training data, while some MSAwords may be challenging since they are infrequent,we conduct a few experiments that widen the set ofwords selected for DA-MSA paraphrasing.
We re-port our results on the large data condition only.
Re-sults are shown in Table 2.
The baseline and bestsystem from Table 1 are repeated for convenience.We consider two types of word-selection exten-sions beyond OOVs.
First, we consider frequency-based selection, where all words with less than orequal to a frequency of x are considered for para-phrasing in addition to being handled in the system?sphrase table.
Many low frequency words actuallyend up being OOVs as far as the phrase table is con-cerned since they are not aligned properly or at all byGIZA++.
Secondly we consider a typed-frequencyapproach, where different frequency values are con-sidered depending on wether a word is MSA only,dialect only or has both dialect and MSA readings.We determine MSA words to be those that have AL-MOR analyses but no new ADAM analyses.
Dialect-only words are those that have ADAM analyses butno ALMOR analyses.
Finally, dialect/MSA wordsare those that have ALMOR analyses and get moredialect analyses through ADAM.
The intuition be-hind the distinction is that problematic MSA onlywords may be much less frequent than problematicdialectal words.We conducted a large number of experiments toempirically determine the best value for x in thefrequency-based approach and xMSA, xDIA, andxDIAMSA for the typed frequency approach.
Forthe typed frequency approach, we took a greedy pathto determine optimal values for each case and thenused the best results collectively.
Our best valuesare presented in Table 2.
Both frequency-based ap-proaches improve over the best results of only tar-geting OOVs.
Further more, the fine-tuned typedfrequency approach even yields further improve-ments leading to 0.62% absolute BLEU improve-ment over the baseline (or 1.71% relative).
Thisscore is statistically significant against the baselineand the ADAM+Transfer system as measured usingpaired bootstrap resampling (Koehn, 2004).5.4 Blind Test ResultsWe apply our two basic system variants and best re-sult with typed frequency selection to the blind testset.
The results are shown in Table 3.
The test setoverall has slightly higher scores than the dev set,suggesting it may be easier to translate relatively.17Large (64M words)System BLEU Prec-1 Prec-2 NIST METEORBaseline 37.24 75.12 46.40 9.1599 52.93ADAM Only 37.63 75.40 46.59 9.2414 53.39ADAM+Transfer 37.71 75.46 46.70 9.2472 53.41+ Freq xMSA ?
10 + xDIAMSA ?
13 + xDIA ?
45 37.80 75.47 46.82 9.2578 53.44Table 3: Results for the blind test set under large training condition, comparing our best performing settings.All of our system variants improve over the baselineand show the same rank in performance as on the devset.
Our best performer improves over the baselineby 0.56 absolute BLEU (or 1.5% relative).
The rel-ative increase in Prec-2 is higher than in Prec-1 sug-gesting perhaps that some improvements are comingfrom better word order.5.5 Manual Error AnalysisWe conduct two manual error analyses comparingthe baseline to our best system.
First we comparethe baseline system to our best system applied onlyto OOVs.
Among all 656 OOV tokens (1.51%) inour dev set we attempt to handle 417 tokens (0.96%)(i.e., 63.57% of possible OOVs) which could pos-sibly affect 320 sentences (21.39%); however, weonly see a change in 247 sentences (16.51%).
Wetook a 50-sentence sample from these 247 sentences(our sample is 20%).
We classified every occur-rence of an OOV into not handled (the output hasthe OOV word), mistranslated (including deleted),or corrected (the output contains the correct transla-tion); we focused on adequacy rather than fluencyin this analysis.
Table 4 presents some examplesfrom the analysis set illustrating different behaviors.Among the OOVs in the sample (total 68 instances),22% are not handled.
Among the handled cases, wesuccessfully translate 74% of the cases.
Translationerrors are mostly due to spelling errors, lexical am-biguity or proper names.
There are no OOV dele-tions.
This analysis suggests that our results reflectthe correctness of the approach as opposed to ran-dom BLEU bias due to sentence length, etc.In the second manual error analysis, we comparetwo systems to help us understand the effect of han-dling low frequency (LF) words: (a) our best systemapplied only to OOVs [OOV], and (b) our best sys-tem applied to OOVs and LF words [OOV+LF].
ForLF words only (as compared to OOVs), we attemptto handle 669 tokens (1.54%) which could possi-bly affect 489 sentence (32.69%); however, we seea change in only 268 sentences (17.91%) (as com-pared to the OOV handling system).
We took a 50-sentence sample from these sentences in the dev setwhere the output of the two systems is different (to-tal 268 sentences; our sample is 19%).
We classifiedeach LF word into mistranslated or correct, and weannotated each case as dialectal, MSA, or tokeniza-tion error.
Among the LF words in the sample (total64 instances), the [OOV+LF] system successfullytranslated 55% of the cases while the [OOV] sys-tem successfully translated 50% of the cases.
Over-all, 11% of all LF words in our sample are due to atokenization error, 34% are MSA, and 55% are di-alectal.
Among dialectal cases, the [OOV+LF] sys-tem successfully translated 60% of the cases whilethe [OOV] system successfully translated 42% ofthe cases.
Among MSA cases, the [OOV+LF] sys-tem successfully translates 55% of the cases whilethe [OOV] system successfully translate 64% of thecases.
The conclusion here is that (a) the majority ofLF cases handled are dialectal and (b) the approachto handle them is helpful; however (c) the LF han-dling approach may hurt MSA words overall.
Ta-ble 5 presents some examples from the analysis setillustrating different behaviors.6 Conclusion and Future WorkWe presented a light-weight rule-based approachto producing MSA paraphrases of dialectal ArabicOOV words and low frequency words.
The gener-ated paraphrase lattices result in improved BLEUscores on a blind test set by 0.56 absolute BLEU(or 1.5% relative).
In the future, we plan to extendour system?s coverage of phenomena in the handleddialects and on new dialects.
We are interested inusing ADAM to extend the usability of existing mor-phological disambiguation systems for MSA to the18Arabic y?ny ?n AlAzdHAmAt btstxdmwn1 Albn?klAt2?Reference You mean for traffic jams you use1 the bicycles2?Baseline I mean, about the traffic btstxdmwn1 Albn?klAt2?OOV-Handle I mean, about the traffic use1 Albn?klAt2?Arabic nHnA bntAml3 Anh fy h?A Almwqf tbdA msyrh?
jdydh?
slmyh?
mTlwbh?
lAlmnTqh?
.Reference We hope3 in this situation to start a new peace process that the region needs.Baseline We bntAml3 that in this situation start a new march peaceful needed for the region.OOV-Handle We hope3 that this situation will start a new march peaceful needed for the region.Arabic dktwr Anwr mAjd ?
?qy4 ry?ys mrkz Al?rq AlAwsT lldrAsAt AlAstrAtyjyh?
mn AlryAD ...Reference Dr. Anwar Majid ?Ishqi4 President of the Middle East Center for Strategic Studies from Riyadh ...Baseline Dr. anwar majed ?
?qy4 head of middle east center for strategic studies from riyadh ...OOV-Handle Dr. anwar majed love4, president of the middle east center for strategic studies from riyadh ...Table 4: Examples of different results of handling OOV words.
Words of interest are bolded.
Superscript indexes areused to link the related words within each example.
Words with index 1 and 3 are correctly translated; the word withindex 2 is not handled; and the word with index 4 is an incorrectly translated proper name.Arabic ... wl?lk Ht?Aml m?
Aljmy?
?ly hAlAsAs.Reference ... and I shall therefore deal with everyone on this basis.OOV ... and therefore dealt with everyone to think.OOV+LF ... and therefore dealt with everyone on this basis.Arabic ... t?ydwn nfs Alkrh?
An lm ykn AswA ...Reference ... repeat the same thing if not worse ...OOV ... to re - the same if not worse ...OOV+LF ... bring back the same if not worse ...Table 5: Examples of different results of handling LF words.
Words of interest are bolded.
Both examples show a LFword mistranslated in the first system and successfully translated in the second system.
The first examples shows adialectal word while the second example shows an MSA word.dialects, e.g., MADA.
Furthermore, we want to au-tomatically learn additional morphological systemrules and transfer rules from limited available data(DA-MSA or DA-English) or at least use these re-sources to learn weights for the manually createdrules.AcknowledgmentsThis research was supported by the DARPA GALEprogram, contract HR0011-06-C-0022.
Any opin-ions, findings, conclusions or recommendations ex-pressed in this work are those of the authors anddo not necessarily reflect the view of DARPA.
Wewould like to thank Amit Abbi for help with theMT baseline.
We also would like to thank JohnMakhoul, Richard Schwartz, Spyros Matsoukas, Ra-bih Zbib and Mike Kayser for helpful discussionsand feedback and for providing us with the devtestdata.ReferencesHitham Abo Bakr, Khaled Shaalan, and Ibrahim Ziedan.2008.
A Hybrid Approach for Converting WrittenEgyptian Colloquial Dialect into Diacritized Arabic.In The 6th International Conference on Informaticsand Systems, INFOS2008.
Cairo University.Rania Al-Sabbagh and Roxana Girju.
2010.
Mining theWeb for the Induction of a Dialectical Arabic Lexicon.In Nicoletta Calzolari, Khalid Choukri, Bente Mae-gaard, Joseph Mariani, Jan Odijk, Stelios Piperidis,Mike Rosner, and Daniel Tapias, editors, LREC.
Eu-ropean Language Resources Association.Imad A. Al-Sughaiyer and Ibrahim A. Al-Kharashi.2004.
Arabic morphological analysis techniques:A comprehensive survey.
Journal of the Ameri-can Society for Information Science and Technology,55(3):189?213.Mohamed Altantawy, Nizar Habash, and Owen Ram-bow.
2011.
Fast Yet Rich Morphological Analysis.In proceedings of the 9th International Workshop onFinite-State Methods and Natural Language Process-ing (FSMNLP 2011), Blois, France.19Satanjeev Banerjee and Alon Lavie.
2005.
METEOR:An Automatic Metric for MT Evaluation with Im-proved Correlation with Human Judgments.
In Pro-ceedings of the ACL Workshop on Intrinsic and Ex-trinsic Evaluation Measures for Machine Transla-tion and/or Summarization, pages 65?72, Ann Arbor,Michigan.Tim Buckwalter.
2004.
Buckwalter Arabic Morpholog-ical Analyzer Version 2.0.
Linguistic Data Consor-tium, University of Pennsylvania.
LDC Catalog No.
:LDC2004L02, ISBN 1-58563-324-0.Chris Callison-Burch, Philipp Koehn, and Miles Os-borne.
2006.
Improved statistical machine transla-tion using paraphrases.
In Proceedings of the HumanLanguage Technology Conference of the NAACL, MainConference, pages 17?24.David Chiang, Mona Diab, Nizar Habash, Owen Ram-bow, and Safiullah Shareef.
2006.
Parsing ArabicDialects.
In Proceedings of the European Chapter ofACL (EACL).Mona Diab, Kadri Hacioglu, and Daniel Jurafsky, 2007.Arabic Computational Morphology: Knowledge-based and Empirical Methods, chapter AutomatedMethods for Processing Arabic Text: From Tokeniza-tion to Base Phrase Chunking.
Springer.George Doddington.
2002.
Automatic evaluation of ma-chine translation quality using n-gram co-occurrencestatistics.
In Human Language Technology, pages128?132, San Diego.Bonnie J. Dorr, Pamela W. Jordan, and John W. Benoit.1999.
A Survey of Current Research in MachineTranslation.
In M. Zelkowitz, editor, Advances inComputers, Vol.
49, pages 1?68.
Academic Press, Lon-don.Jinhua Du, Jie Jiang, and Andy Way.
2010.
Facil-itating translation using source language paraphraselattices.
In Proceedings of the 2010 Conferenceon Empirical Methods in Natural Language Process-ing, EMNLP?10, pages 420?429, Cambridge, Mas-sachusetts.Kevin Duh and Katrin Kirchhoff.
2005.
POS tagging ofdialectal Arabic: a minimally supervised approach.
InProceedings of the ACL Workshop on ComputationalApproaches to Semitic Languages, Semitic ?05, pages55?62, Ann Arbor, Michigan.Christopher Dyer, Smaranda Muresan, and Philip Resnik.2008.
Generalizing word lattice translation.
In Pro-ceedings of ACL-08: HLT, Columbus, Ohio.Nizar Habash and Owen Rambow.
2005.
Arabic Tok-enization, Part-of-Speech Tagging and MorphologicalDisambiguation in One Fell Swoop.
In Proceedings ofthe 43rd Annual Meeting of the Association for Com-putational Linguistics (ACL?05), pages 573?580, AnnArbor, Michigan.Nizar Habash and Owen Rambow.
2006.
MAGEAD:A Morphological Analyzer and Generator for the Ara-bic Dialects.
In Proceedings of the 21st InternationalConference on Computational Linguistics and 44thAnnual Meeting of the Association for ComputationalLinguistics, pages 681?688, Sydney, Australia.Nizar Habash and Fatiha Sadat.
2006.
Arabic Prepro-cessing Schemes for Statistical Machine Translation.In Proceedings of the Human Language TechnologyConference of the NAACL, Companion Volume: ShortPapers, pages 49?52, New York City, USA.Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter.2007.
On Arabic Transliteration.
In A. van den Boschand A. Soudi, editors, Arabic Computational Mor-phology: Knowledge-based and Empirical Methods.Springer.Nizar Habash.
2006.
On Arabic and its Dialects.
Multi-lingual Magazine, 17(81).Nizar Habash.
2007.
Arabic Morphological Representa-tions for Machine Translation.
In A. van den Boschand A. Soudi, editors, Arabic Computational Mor-phology: Knowledge-based and Empirical Methods.Springer.Nizar Habash.
2008.
Four Techniques for Online Han-dling of Out-of-Vocabulary Words in Arabic-EnglishStatistical Machine Translation.
In Proceedings ofACL-08: HLT, Short Papers, pages 57?60, Columbus,Ohio.Nizar Habash.
2010.
Introduction to Arabic NaturalLanguage Processing.
Morgan & Claypool Publish-ers.Jan Hajic?, Jan Hric, and Vladislav Kubon.
2000.
Ma-chine Translation of Very Close Languages.
In Pro-ceedings of the 6th Applied Natural Language Pro-cessing Conference (ANLP?2000), pages 7?12, Seat-tle.Ahmed El Kholy and Nizar Habash.
2010.
Tech-niques for Arabic Morphological Detokenization andOrthographic Denormalization.
In Workshop on Lan-guage Resources and Human Language Technologyfor Semitic Languages in the Language Resources andEvaluation Conference (LREC), Valletta, Malta.H.
Kilany, H. Gadalla, H. Arram, A. Yacoub, A. El-Habashi, and C. McLemore.
2002.
EgyptianColloquial Arabic Lexicon.
LDC catalog numberLDC99L22.Katrin Kirchhoff, Jeff Bilmes, Sourin Das, Nicolae Duta,Melissa Egan, Gang Ji, Feng He, John Henderson,Daben Liu, Mohamed Noamany, Pat Schone, RichardSchwartz, and Dimitra Vergyri.
2003.
Novel Ap-proaches to Arabic Speech Recognition: Report fromthe 2002 Johns Hopkins Summer Workshop.
In IEEEInternational Conference on Acoustics, Speech, andSignal Processing, Hong Kong, China.20P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: open source toolkitfor statistical machine translation.
In Proceedings ofthe 45th Annual Meeting of the Association for Com-putational Linguistics Companion Volume Proceed-ings of the Demo and Poster Sessions, pages 177?180,Prague, Czech Republic.Philipp Koehn.
2004.
Statistical significance tests for-machine translation evaluation.
In Proceedings of theEmpirical Methods in Natural Language ProcessingConference (EMNLP?04), Barcelona, Spain.Shankar Kumar, Franz J. Och, and Wolfgang Macherey.2007.
Improving word alignment with bridge lan-guages.
In Proceedings of the 2007 Joint Conferenceon Empirical Methods in Natural Language Process-ing and Computational Natural Language Learning(EMNLP-CoNLL), pages 42?50, Prague, Czech Re-public.Young-Suk Lee.
2004.
Morphological Analysis for Sta-tistical Machine Translation.
In Proceedings of the 5thMeeting of the North American Chapter of the Associ-ation for Computational Linguistics/Human LanguageTechnologies Conference (HLT-NAACL04), pages 57?60, Boston, MA.Mohamed Maamouri, Ann Bies, Tim Buckwalter, andWigdan Mekki.
2004.
The Penn Arabic Treebank:Building a Large-Scale Annotated Arabic Corpus.
InNEMLAR Conference on Arabic Language Resourcesand Tools, pages 102?109, Cairo, Egypt.Preslav Nakov and Hwee Tou Ng.
2011.
Translat-ing from Morphologically Complex Languages: AParaphrase-Based Approach.
In Proceedings of theMeeting of the Association for Computational Linguis-tics (ACL?2011), Portland, Oregon, USA.F.
J. Och and H. Ney.
2003.
A systematic comparison ofvarious statistical alignment models.
ComputationalLinguistics, 29(1):19?51.Franz Josef Och.
2003.
Minimum Error Rate Trainingfor Statistical Machine Translation.
In Proceedingsof the 41st Annual Conference of the Association forComputational Linguistics, pages 160?167, Sapporo,Japan.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a Method for Automatic Eval-uation of Machine Translation.
In Proceedings of the40th Annual Meeting of the Association for Computa-tional Linguistics, pages 311?318, Philadelphia, PA.Jason Riesa and David Yarowsky.
2006.
Minimally Su-pervised Morphological Segmentation with Applica-tions to Machine Translation.
In Proceedings of the7th Conference of the Association for Machine Trans-lation in the Americas (AMTA06), pages 185?192,Cambridge,MA.Ryan Roth, Owen Rambow, Nizar Habash, Mona Diab,and Cynthia Rudin.
2008.
Arabic Morphological Tag-ging, Diacritization, and Lemmatization Using Lex-eme Models and Feature Ranking.
In Proceedings ofACL-08: HLT, Short Papers, pages 117?120, Colum-bus, Ohio.Hassan Sawaf.
2010.
Arabic dialect handling in hybridmachine translation.
In Proceedings of the Confer-ence of the Association for Machine Translation in theAmericas (AMTA), Denver, Colorado.Michel Simard, Nicola Ueffing, Pierre Isabelle, andRoland Kuhn.
2007.
Rule-based translation with sta-tistical phrase-based post-editing.
In Proceedings ofthe Second Workshop on Statistical Machine Transla-tion, pages 203?206, Prague, Czech Republic.Masao Utiyama and Hitoshi Isahara.
2007.
A compar-ison of pivot methods for phrase-based statistical ma-chine translation.
In HLT-NAACL, pages 484?491.Xiaoheng Zhang.
1998.
Dialect MT: a case study be-tween Cantonese and Mandarin.
In Proceedings of the36th Annual Meeting of the Association for Computa-tional Linguistics and 17th International Conferenceon Computational Linguistics, ACL ?98, pages 1460?1464, Montreal, Canada.Andreas Zollmann, Ashish Venugopal, and Stephan Vo-gel.
2006.
Bridging the Inflection Morphology Gapfor Arabic Statistical Machine Translation.
In Pro-ceedings of the Human Language Technology Confer-ence of the NAACL, Companion Volume: Short Papers,pages 201?204, New York City, USA.21
