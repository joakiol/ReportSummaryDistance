Proceedings of the EACL 2014 Workshop on Type Theory and Natural Language Semantics (TTNLS), pages 55?62,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsFrom Natural Language to RDF Graphs with PregroupsAntonin Delpeuch?cole Normale Sup?rieure45 rue d?Ulm75005 Paris, Franceantonin.delpeuch@ens.frAnne PrellerLIRMM161 rue Ada34392 Montpellier Cedex 5, Francepreller@lirmm.frAbstractWe define an algorithm translating naturallanguage sentences to the formal syntax ofRDF, an existential conjunctive logic widelyused on the Semantic Web.
Our translationis based on pregroup grammars, an efficienttype-logical grammatical framework with atransparent syntax-semantics interface.
We in-troduce a restricted notion of side effects inthe semantic category of finitely generated freesemimodules over {0, 1} to that end.
Thetranslation gives an intensional counterpart toprevious extensional models.
We establisha one-to-one correspondence between exten-sional models and RDF models such that sat-isfaction is preserved.
Our translation encom-passes the expressivity of the target languageand supports complex linguistic constructionslike relative clauses and unbounded dependen-cies.1 IntroductionThere is a general agreement that Natural LanguageProcessing has two aspects.
One is syntax, rules howwords are put together to form a grammatical string.The other is semantics, rules how meanings of stringsare computed from the meanings of words.
To this weadd a third aspect, namely that semantics must includerules of logic how to compute the truth of the wholestring from the truth of its parts.The Resource Description Framework (RDF)(Hayes and McBride, 2004) is an artificial languagethat takes the intuitive form of knowledge graphs.
Itssemantics has the expressive power of the fragment ofmultisorted first order logic that uses conjunction andexistential quantification only.
This restricted expres-sive power limits the statements of natural languagethat can be interpreted as RDF graphs.
Typically,statements with negation words are excluded.We use pregroup grammars as the linguistic andmathematical tool to recognise and interpret natu-ral language strings in RDF.
Pregroup Calculus, alsoknown as Compact Bilinear Logic (Lambek, 1993)(Lambek, 1999), is a simplification of Lambek?s Syn-tactic Calculus, (Lambek, 1958).
Pregroup grammarsare based on a lexicon like all categorial grammars.Syntactical analysis consists in the construction of aproof (derivation) in the calculus.All semantics proposed so far use functors fromthe lexical category of (Preller and Lambek, 2007)into some symmetric compact closed category.
Theyinclude the compositional distributional vector spacemodels of (Clark et al., 2008), (Kartsaklis et al., 2013)based on context and the functional logical models of(Preller, 2012).We proceed as follows.
Recalling that words andgrammatical strings recognised by the grammar arerepresented by meaning-morphisms in the lexical cat-egory, we propose a "syntactic" functor from the latterinto a symmetric monoidal category CSof ?morphismswith side effects?
over the category C of finite dimen-sional semimodules over the lattice B = {0, 1}.
The el-ements of the semimodule S identify with RDF graphs.The value of the syntactic functor at a statement is theRDF graph of the statement.
The extensional modelsof logic are recast as "semantic" functors from the lexi-cal category to C. We associate to any semantic functoran RDF interpretation and show that a statement is truein the semantic functor if and only if the correspondingRDF graph is true in the RDF interpretation.2 Preliminaries2.1 RDF graphsRDF is a widely-adopted framework introduced in(Hayes and McBride, 2004) as a standard for linkedinformation representation on the Web.
Informally, anRDF graph is a set of labeled links between objects,which represent statements concerning the linked ob-jects.Throughout this article we will simply consider thatthey are represented by strings of characters withoutspaces, written in a mono-spaced font: the entity Johnis denoted by the string John.A link between two objects is a triple, made of oneentity (the subject of the predicate), a property (the typeof the link, also represented by a string) and a secondentity (the object of the predicate).
Graphically, we rep-resent a triple as a directed property from the subject tothe object, labeled by the predicate.RDF allows to use nodes without labels, called blanknodes.
Concretely, this means that we can always pick55a fresh node, named blank-n where n is some num-ber, such that this node is not involved in any triple yet.An example We can represent the sentence Johnowns a white boat using a fresh blank node for a whiteboat:John owns blank-1blank-1 rdf:type boatblank-1 is_white trueHere, rdf:type is a special RDF predicate indicatingthe type of its subject.
The graph representing this setof triples isJohn blank-1trueboatownsis-whiterdf:typeFigure 1: A graph with a blank nodeRecall that our goal is to translate natural languagesentences to graphs.
Graphs can indeed be seen as se-mantic representations of sentences, in the sense thatthey can be used to assign a truth value to a sentence,trough the notion of entailment (Hayes and McBride,2004).A graph H is an instance of G when H can be ob-tained from G by assigning labels to some blank nodes(possibly none of them).
A graph G0entails anothergraph G if an instance of G is a subgraph of G0.
Withthese definitions, we can define true RDF graphs as thegraphs entailed by some reference graph, storing all thetrue facts.2.2 Pregroup grammarsA pregroup grammar (Lambek, 1999), consists of thefree pregroup C(B) generated by a partially orderedset B and a lexicon DB.
By ?free pregroup?
we meanthe free compact closed category C(B) generated byB following the version given in (Preller and Lambek,2007)1.
The lexicon DBintroduces the monoidal cat-egory LB, freely generated by the inequalities and thelexical morphisms given by the lexicon.
Lexical entrieshave "formal meanings" in the lexical category, the freecompact closed category generated by B and the mor-phisms introduced by the words.
They are analogue tothe lambda-terms intervening in categorial grammars,(Steedman, 1996).The working of pregroup grammars can be describedwithout explicit use of category theory.
The main resultof this section however, the decomposition lemma, in-vokes properties of the graphs proved in (Preller andLambek, 2007).1Semantics requires more than one morphism betweenobjects, whereas the partial preorder of the free pregroup of(Lambek, 1999) confounds all morphisms with identical do-main and codomain.We start with the formal definition of a monoidal cat-egory followed by the condition it must satisfy to becompact closed.Definition 1.
A category C is1.
monoidal if there is a bifunctor ?
: C ?
C ?
C,a distinguished object I , the unit of ?, satisfying(A ?
B) ?
C = A ?
(B ?
C), (f ?
g) ?
h =f ?
(g ?
h)22. compact closed if it is monoidal and there are con-travariant endofunctors ( )rand ( )`, called rightadjoint and left adjoint, such that for every objectA and every morphism f : A?
B there are mor-phisms ?f: I ?
Ar?
A, the name of f , andf: A?
Br?
I , the coname of f , satisfying forany g : B ?
C(A?B)r= Br?Ar, (A?B)`= B`?A`(f?
1C) ?
(1A?
?g) = g ?
f(1Ar?
g) ?
(?f?
1Cr) = (f ?
g)r.3.
symmetric if it is monoidal and there is a naturalisomorphism ?AB: A ?
B ?
B ?
A such that?
?1AB= ?BA.Recall that ?
is a bifunctor if and only if the follow-ing equalities are satisfied for all objects A,B and allmorphisms fi: Ai?
Bi, gi: Bi?
Ci, i = 1, 21A?
1B= 1A?BInterchange Law(f2?
f1)?
(g2?
g1) = (f2?
g2) ?
(f1?
g1)(1)The morphisms of C(B) and LBidentify withgraphs, which we now describe without invoking cat-egory theory.The objects of C(B) are called types.
They includethe elements of B, called basic types.
For instance, theset B may include the basic types s for statements, dfor determiners, n for noun phrases, o for direct ob-jects with corresponding types in relatives clauses r,?n and?o.
There is only one strict inequality n < o.Assimilating B to a category, we write iab: a ?
binstead of a ?
b and 1afor iaa.
A simple typeis an iterated left adjoint or right adjoint of a basictype .
.
.
,a``= a(?2),a`= a(?1),a = a(0),ar=a(1),arr= a(2), .
.
.
.
The iterator of t = a(z)is theinteger z.
An arbitrary type is a string of simple typesseparated by the symbol ?.
In particular, the emptystring is a type, denoted I .The lexicon of a pregroup grammar consists of a setof pairs word : T where the type T ?
C(B) capturesthe different grammatical roles a word may play.
For2Strictly speaking, these equalities hold up to natural iso-morphisms, but the coherence theorem of (Mac Lane, 1971)makes it possible to replace the isomorphisms by equalitieswithout loss of generality.56instanceproper name : ntransitive verb : nr?
s?
o`transitive verb :?nr?
r ?
o`transitive verb : nr??or?
rdeterminer : dadjective : dr?
dcountnoun : dr?
nrelpronoun : nr?
n?
r`?
?nrelpronoun : nr?
n?
r`?
?oA pregroup grammars analyses a string of words byconstructing a graph: choose an entry wi: Tifor eachword wiand align the types in the order of the words.Place non-crossing oriented underlinks such that thetail of an underlink is a basic type with an even num-ber of iterations, say t = a(z), where z = ?2n.
Ifthe head is to the left of the tail then it is the left ad-joint b(z)`= b(z?1), for some basic type b ?
a.
If itis to the right then its a right adjoint b(z)r= b(z+1).Complete the graph by repeating the nodes that are nothead or tail of an underlink in a line below and addinga vertical link between corresponding nodes.The string is said to be grammatical if exactly onesimple type remains that is not the tail or head of anunderlink and if it is a basic type.
The resulting graphis called a reduction and denotes a unique morphismr : T1?
.
.
.?Tn?
b of C(B).
More generally, graphsstanding for morphisms align the domain above and thecodomain below.For instance, the graph below exhibits a reduction tothe sentence type s(n)?
(nr?
s?
o`)?
(d)?
(dr?
d)?
(dr?
n)john owns a white boat;;sgg ;; ;;The following two graphs are reductions to the nounphrase type n. The first graph corresponds to the casewhere the relative pronoun is the object of the verb inthe relative clause whereas it is the subject in the sec-ond graphd?
dr?
n?
nr?
n?
r`??o?
n?
nr??or?
ra cat that bob hates??
?
?nbb ::??d?
dr?
n?
nr?
n?
r`??n??nr?
r ?
o`?
na cat that bobhates??
?
?nee ??
ccThe meanings of words are also represented bygraphs that correspond to morphisms of the lexical cat-egory LB.
In fact, every entry w : T in the lexicongives rise to a meaning morphism wT: I ?
T and alexical morphism wTrepresented by the following ori-ented labelled graphswb=wb= wbT = ar?
bwT=ar?
b""wwT=awbT = ar?
b?
c`wT=ar?
b ?
c`wTwT=a ?
cbTTT jjjwTT = ar?
cr?
bwT=ar?
cr?
bwwT=c ?
abTTT jjjwTIf T has two factors that are basic types, there is besidesthe main lexical morphismwTan auxiliary lexical mor-phism jT.T = nr?
n?
r`?
d, d =?n,?othatT=nr?
n ?
r`?
djd""}}thatrnthatndjdWe omit the subscript T if this does not lead to confu-sion.The nodes of the meaning graphs are the simpletypes of T .
They form the lower line of the graph, theupper line is the empty string I .
The correspondingmorphism has domain I and codomain T .
An overlinkmay have several tails but only one head.
The tails ofoverlinks are right or left adjoints of basic types, thehead is a basic type3.The lexical category LBgenerated by the lexiconDBis the compact closed category freely generated byB, the symmetry morphisms ?aband the lexical mor-phisms introduced by DB.Strings of words also have meaning(s) in the lex-ical category.
The lexical meaning of a grammati-cal string word1.
.
.wordnrecognised by the reductionr : T1.
.
.
Tn?
b is, by definition, the composite ofthe tensor product of the word meanings and the cho-sen reduction.r ?
(word1T1?
.
.
.?
wordnTn) : I ?
b .The meaning of a composite morphism g ?
f can besimplified graphically.
Stack the graph of f above thegraph of g and walk the paths of the graph starting ata node that is not the head of a link until you arriveat a node that is not the tail of a link.
Compose thelabels in the order they are encountered along the path.Replace the whole path by a single link labelling it bythe composite label of the path.
The resulting graphrepresents the morphism g ?
f , (Selinger, 2011).For instance, the grammatical strings mentioned3"basic type" is replaced by simple type with an even iter-ator in the general case57above above simplify to(n)?
(nr?
s?
o`)?
(d)?
(dr?
d)?
(dr?
n)johnwhite boat;;sgg ;; ;;owna=n ?
ojohnboat?red?asTTT jjjown=Isown?(john?
(boat?red?a))T =?nr?
r ?
o`d?
dr?
n?
nr?
n?
r`??n??nr?
r ?
o`?
na catthatbobhateT??
?
?nee ??
ff  !
!  that ?
hateT?
((cat ?
a)?
bob)] : I ?
I ?
nT?= nr??or?
rd?
dr?
n?
nr?
n?
r`??o?
n?
nr??or?
ra catthatbob hateT???
?
?ndd ::?
?  !
! = that ?
hateT??
((cat ?
a)?
bob)] : I ?
I ?
nAll unlabelled links in the graph above correspondto inequalities of basic types.
Inserting the strict in-equalities at the appropriate place and applying the in-terchange law, we decompose the label into minimalbuilding blocks that correspond one-to-one to the re-sources occurring in the RDF graph associated to thestatement.
For example,own ?
(john?
(boat ?
white ?
a))= own ?
(1n?
in) ?
(1n?
boat) ?
(1n?
white))?(john?
a) .
(2)The expression after the equality symbol above is acomposite of tensor products the factors of which areeither inequalities between basic objects or lexical mor-phisms.
Only the rightmost tensor product containsmore than one lexical morphism.
In fact, all factorsare lexical morphisms with domain I .The translation of statements to RDF graphs rests onthe existence of this decomposition.
Borrowing the ter-minology of RDF graphs, call any lexical morphismwith domain I a node word and any other lexical mor-phism a property word.Lemma 1 (Decomposition).
Let word1.
.
.wordnbe a grammatical string with lexical morphismsword1, .
.
.
, wordnand a reduction r : T1.
.
.
Tn?b.
Then there is an enumeration of the node wordswordi1: I ?
b1, .
.
.
, wordim: I ?
bmsuch thatthe lexical meaning of the string satisfiesr ?
(word1?
.
.
.?
wordn)= p1?
?
?
?
?
pm??
(wordi1?
.
.
.?
wordim) ,where each pkis either a tensor product of inequalitiesof basic types or a tensor product of inequalities andone property word wordjk.
Moreover, k < k?impliesjk< jk?.In particular, the meaning of the string belongs tothe monoidal category generated by the lexiconThis is a straightforward consequence of the charac-terisation of morphisms as normal graphs in the freecategory, (Preller and Lambek, 2007) and the inter-change law.We map lexical morphisms to "unfinished" RDFtripleslexical morphism RDF triplenoun : d?
n ?
rdf : type nounadjective : d?
d ?
is-adjective trueverb : a?
b?
c ?
verb ?determiner : I ?
d blank ?
?,?
?
blankpropername : I ?
n propername ?
?,?
?
propername(3)The question marks designate unoccupied positions inthe triple.
Node words occupy either the subject or theobject position, unary property words leave only thesubject position open, binary property words occupythe centre position leaving subject and object positionunoccupied.
Finally, the noun phrases a cat that hatesBob and a cat that Bob hates are respectively translatedto the following graphs :blank-1Bobcathatesrdf:type(a) A cat that hates Bobblank-1Bobcathatesrdf:type(b) A cat that Bob hates3 The TranslationLet B = ?
{0, 1},+, ??
be the commutative semiring inwhich the addition, +, is the lattice operator ?
and themultiplication, ?, the lattice operator ?
on {0, 1}.The semantic category which hosts the RDF graphsand our models of grammatical strings is the category Cof finitely generated semimodules over B.
It is compactclosed satisfying A`= A = Arfor each object A.Every object A has a?canonical?
basis (ei)isuch thatevery element v ?
A can be written uniquely as v =?i?iei, where ?i?
B.
We refer to elements ofA asvectors.
Morphisms of C are maps that commute withaddition and scalar multiplication.We interpret RDF graphs as elements of a semimod-ule S determined by the RDF vocabulary, see below.58The translation of grammatical strings is given by afunctor from the monoidal category generated by thelexical morphisms into a category of morphisms withside effects mapping the decomposition of a grammati-cal string to a vector of S.Let L be a set of labels that includes the propertywords and a ?very large?, but finite number n0of la-bels blanki, for i = 1, .
.
.
n04.
The other elementsof L are node names and property names of an RDFvocabulary.Define N as the semimodule over the semi-ring Bfreely generated by L and denote elabelthe basis vec-tor of N corresponding to label ?
L. We presentRDF triples by basis vectors of S = N ?
N ?
N andRDF graphs by sums of basis vectors of S, for instanceebob?ehate?eblank+eblank?erdf?type?ecat.
Hence,the vector sum models the union of RDF graphs.We want to interpret the lexical morphisms such thatthey construct a triple when applied to an argument andadd it to the vector of S already constructed.
Composi-tion of the category C alone is not powerful enough toachieve this.
We define a new category CSin whichthe entity a white boat will be denoted by the pair(eblank-1, eblank-1?
erdf:type?
eboat+ eblank-1?
eis-white?etrue).Therefore we switch from C to the monoidal cate-gory CSbelow in which arrows have two components.The first component creates the triple and the secondcomponent adds the new triple to the graph as a ?sideeffect?.Definition 2 (Category with Side Effects).
Let{a1, .
.
.
, am} and {b1, .
.
.
, bn} be the basis5of A andB.
For any p ?
C(A,S), q ?
C(B,S), define p?+q ?C(A?B,S) as the unique linear map satisfying for anarbitrary basis vector ai?
bjof A?B(p?+q) : ai?
bj7?
p(ai) + q(bj) .The category CSof morphisms with side effects in Shas:?
objects as in C?
morphisms (f, p) : A ?
B where f ?
C(A,B),Ker(f) = {0} and p ?
C(A,S).?
arrows 1A= (1A, 0).?
an operation ?
defined by (f, p)?
(h, q) = (f ?h, p?h+ q).?
an operation ?
on objects defined as in C?
an operation ?
on arrows defined by (f, p) ?
(h, q) = (f ?
h, p?+q).Examples of morphisms in the first component arethe symmetry ?
: N?N ?
N?N , pi1, pi2: N?N ?N defined by ?(ai?
bj) = bj?
ai, pi1(ai?
bj) = aiand pi2(ai?
bj) = bj.The new operation ?+introduced above concernsthe second component only.
The morphism p ?+q4it suffices that n0exceeds the number of occurrences ofdeterminers in the set of digitalised documents5In C, every object has a unique basis: the canonical one.computes at ai?
bjthe union of the RDF graphs p(ai)and q(bj), computed separately by p and q.As an illustration, consider the following morphismsof CSmjohn= (ejohn, 0), mblanki= (eblanki, 0)The arrow of a proper noun consists of the node rep-resenting this entity, e.g.
ejohn, paired with the emptygraph represented by 0 ?
S. Choosing the empty graphmeans that nothing is said about this node.
A similarremark holds for determiners.mwhite= (1N, 1N?
eis-white?
etrue),mboat= (1N, 1N?
erdf-type?
eboat)An adjective or a noun is a morphism that maps a nodeword to itself and to the empty slot in the correspondingtriple.
As a side effect, it adds this triple to the secondcomponent.mown= (1N?
eown?
1N, 1N?
eown?
1N)A transitive verb is a morphism that maps an orderedpair of nodes to a triple making the first the subject andthe second the object of the triple.Compose the morphismsmwhite?mblanki= (eblanki, t1)t1= (eblanki?
eis-white?
etrue)mboat?mwhite?mblanki= (eblanki, t2+ t1)t2= (eblanki?
erdf-type?
eboat)mown?
(mjohn?
(mboat?mwhite?mblanki)) =mown?
(ejohn?
eblanki, 0 + t2+ t1) =(ejohn?
eown?
eblanki, t3+ t2+ t1)t3= ejohn?
eown?
eblanki(4)The effect of composition is to create a new triple onthe left of the comma and to store it on the right.Proposition 1.
The category with side effects CSis amonoidal category.The proof of this proposition is given in appendix A.Define a monoidal structure preserving functor Ffrom the monoidal category generated by the lexicalmorphisms to CSthus?
F(s) = S = N ?N ?N?
F(a) = N if a 6= s?
F(1a) = F(iab) = F(jab) = 1F(a), for all basictypes a, b ?
B?
F(that : r ?
n) = (1, 0)?
F(name : I ?
d) = (ename, 0)?
F(determiner : I ?
d) = (eblanki, 0)?
F(word : dr?
n) = (1, 1?
erdf-type?
eword)?
F(word : dr?
d) = (1, 1?
eis-word?
etrue)?
F(wordnr?s?ol) = (1?
eword?
1, 1?
eword?
1)F(word?nr?r?ol) = (pi1, 1?
eword?
1)F(wordnr?
?or?r) = (pi2, (1?
eword?
1) ?
?
).Note that the morphisms in the example above satisfymword= F(word).
Computation (4) shows that Fmaps the lexical meaning of john owns a white boat tothe three RDF triples t1, t2, t3.59Lemma 2.
Let word1.
.
.wordnbe a statement withcorresponding lexical entries word1: T1.
.
.wordn:Tnand r : T1.
.
.
Tn?
s a reduction to the sentencetype.
Then second component ofF(r ?
(word1?
.
.
.?
wordn)) =(f, t1+ ?
?
?+ tm) ?
CS(I, S)is a sum of RDF triples ti?
S, for k = 1, .
.
.
,m.Moreover, tkhas the form (3) determined by the prop-erty word wordjksuch that the unlabelled nodes arefilled by node words of the statement.The proof is given in Appendix B.Definition 3 (RDF Translation).
The RDF graph trans-lating the statement word1.
.
.wordnwith reductionr : T1.
.
.
Tn?
s is the second component of F(r ?(word1?
.
.
.?
wordn)).For instance, the translation of the statement Johnowns a white boat isejohn?
eown?
eblanki+ eblanki?
eis-white?
etrue+ eblanki?
erdf-type?
eboat,becauseF(own ?
(john?
(boat ?
white ?
a))= mown?
(mjohn?
(mboat?mwhite?mblanki)) .The translation algorithm from text to RDF graphsstarts with a parsing algorithm of pregroup grammarsthat chooses a type for each word of the statement andprovides a reduction to the sentence type.
Next it com-putes the decomposition of the formal meaning in thelexical category by ?yanking?.
Finally it computes theRDF graph by applying the translation functor F to thedecomposition.
The parsing algorithm is cubic poly-nomial in the number of words.
Decomposition is lin-ear, because the number of links is proportional to thenumber of words.
Finally, translation again is linear,because the sum of the number of property words andof the number of node words in the decomposition isproportional to the number of words.4 C-Models and RDF InterpretationsIn this section, we establish the connection between theextensional models of meaning of (Preller, 2012) withthe RDF interpretations of (Hayes, 2004) via the trans-lation F from natural language to RDF graphs.
Weshow that a statement is true in an extensional modelif and only if the RDF graph computed by F is truein the RDF interpretation associated to the extensionalmodel.Choose an object U of C, the ?universe of discourse?of the fragment of natural language.
The basis vectorsof U stand for individuals or concepts.
Properties arerepresented by maps that test (n-tuples of) entities andlet (part of) them pass if the test succeeds.Let 1 ?
i1< ?
?
?
< im?
n be a strictly increasingsequence.
A linear map q : U1?
.
.
.
?
Un?
Ui1?.
.
.
?Uimis said to be a selector if for any basis vectore1?
.
.
.?
en?
U1?
.
.
.?
Unq(e1?.
.
.
?en) = ei1?.
.
.
?eimor q(e1?.
.
.
?en) = 0 .We say that q selects the i-th factor ifm = 1 and i = i1and that it is a projector if m = n. If the latter isthe case then q is an idempotent and self-adjoint en-domorphism, hence a ?property?
in quantum logic, see(Abramsky and Coecke, 2004).If the domain V and the codomainUi1?.
.
.
?Uimarefixed then the selectors are in a one-to-one correspon-dence with the ?truth-value?
functions p : A?
{>,?
}on the set A of basis vectors of V related by the condi-tionp(a) = > if and only if q(a) 6= 0for all a ?
A .Let v =?kl=1ajlbe an arbitrary vector of V .
Aselector q : V ?W is said to be true at v if q(ajl) 6= 0,for l = 1, .
.
.
, k.Lemma 3.
Selectors are closed under composition andthe tensor product.
Every identity is a selector.Let p : V ?
W and q : W ?
X be selectors andv ?
V .
Then q ?
p is true at v if and only if p is true atv and q is true at w = p(v).Proof.
The first assertion is straight forward.
To showthe second, assume that a is a basis vector for which(q ?
p)(a) 6= 0.
Then p(a) 6= 0 because q(0) = 0.Hence p(a) is a basis vector of W selected by p. Theproperty now follows for an arbitrary vector from thedefinitions.Definition 4.
A compact closed structure preservingfunctorM : LB?
C is a C-model with universe U ifit satisfies?
M(s) = U ?
U?
M(a) = U for any basic type a 6= s?
M(1a) = M(iab) = M(jab) = 1M(a), for allbasic types a, b ?
B?
M(that) = 1U?
M(wordar?b) and M(wordnr?s?ol) are projec-tors?
M(word?n?r?ol) = pi1?M(wordnr?s?ol)M(wordnr?
?or?r) = pi2?M(wordnr?s?ol) ?
??
M maps determiners and proper names in the sin-gular to basis vectors.The last condition guarantees that the interpretationsof a transitive verb in a statement and in a relativeclause are equal if the relative pronoun is the subject ofthe verb in the relative clause and that they differ onlyby the symmetry isomorphism if the relative pronounis the object.Definition 5.
A statement word1.
.
.wordnwith re-duction r : T1?
.
.
.
?
Tn?
b is true in M ifM(r ?
(word1?
.
.
.?
wordn) 6= 0.Truth in a model can be reformulated in terms of se-lector truth with the help of Lemma 1.60Lemma 4.
Let p1??
?
??
pm??(wordi1?
.
.
.
?wordim)be the decomposition of the formal meaning of thestatement word1.
.
.wordn.
Then M(pl) is a selec-tor and M(wordik) a vector in U, for 1 ?
l ?
m?,1 ?
k ?
m.Moreover, the statement is true in M if and only ifthe selectorM(pl) is true atM(pl+1)??
?
??M(pm?)?(M(wordi1)?
.
.
.
?M(wordim)) for 1 ?
l ?
m?.Proof.
M maps the meaning of the string toM(p1) ??
?
?
?
M(pm?)
?
(M(wordi1) ?
.
.
.
?M(wordim)).Note that for k = 1, .
.
.
,m?any factor of M(pk) isthe identity of U unless it isM(wordjk) = qk.
ThusM(pk) is a tensor product of selectors.
Hence bothassertions follow from Lemma 3.Any C-modelM defines an RDF interpretation.
Thevocabulary consists of the basis vectors elabel?
N ,see previous section.
The set of property symbols isgiven byP = {eis-adjective: adjective ?
D} ?
{rdf:type}?
{everb: verb ?
C}Define an RDF interpretation IMas follows?
set of propertiesIP = {M(word) : eword?
P} ?
{rdf:type}?
set of resourcesIR = IP ?
U ?
{true}?
mapping IS and its extension to blank nodesIS(eword) =M(word),IS(eblanki) =M(determineri)?
mapping IEXT from IP into the power set of IR?
IRIEXT(rdf-type) ={?e,M(noun)?
: M(noun) is true at e}IEXT(IS(eis-adjective)) ={?e,true?
: M(adjective) is true at e}IEXT(IS(everb)) ={?e1, e2?
: M(verb) is true at e1?
e2} .Proposition 2.
A statement word1.
.
.wordnis true ina C-model M if and only if every triple of its RDFtranslation G is true in the RDF interpretation IMThe proof is given in Appendix B.5 ConclusionThe modelling of natural language by RDF graphs re-mains limited by the expressivity of RDF.
The lattergoes way beyond the few examples presented here.
Sofar, we have only considered the extensional branch ofa word.
Future work will take advantage of the dis-tinction between a property and its extension in RDF tointroduce the conceptual branch of a plural, which doesnot refer to an extension, e.g Tom likes books, or cap-ture the difference between Eve and John own a boatand Eve and John are athletes.AcknowledgmentsThis work was supported by the ?cole NormaleSup?rieure and the LIRMM.
The first author wishes tothank David Naccache, Alain Lecomte, Antoine Amar-illi, Hugo Vanneuville and both authors the membersof the TEXTE group at the LIRMM for their interest inthe project.ReferencesSamson Abramsky and Bob Coecke.
2004.
A categor-ical semantics of quantum protocols.
In Proceed-ings of the 19th Annual IEEE Symposium on Logicin Computer Science, pages 415?425.Stephen Clark, Bob Coecke, and MehrnooshSadrzadeh.
2008.
A compositional distribu-tional model of meaning.
In W. Lawless P. Bruzaand J. van Rijsbergen, editors, Proceedings ofConference on Quantum Interactions.
University ofOxford, College Publications.Patrick Hayes and Brian McBride.
2004.
Rdf seman-tics.
Technical report, Hewlett Packard Labs.Patrick Hayes.
2004.
Rdf semantics.
Technical report,W3C Recommendation, W3C.Dimitri Kartsaklis, Mehrnoosh Sadrzadeh, StephenPulman, and Bob Coecke, 2013.
Reasoning aboutMeaning in Natural Language with Compact ClosedCategories and Frobenius Algebras.
CambridgeUniversity Press.Joachim Lambek.
1958.
The mathematics of sen-tence structure.
American Mathematical Monthly,65:154?170.Joachim Lambek, 1993.
Substructural Logics, chap-ter From categorial grammar to bilinear logic, pages207?237.
Oxford University Press.Joachim Lambek.
1999.
Type grammar revisited.
InAlain Lecomte, editor, Logical Aspects of Computa-tional Linguistics, volume 1582 of LNAI, pages 1?27, Heidelberg.
Springer.Saunders Mac Lane.
1971.
Categories for the WorkingMathematician.
Springer.Anne Preller and Joachim Lambek.
2007.
Freecompact 2-categories.
Mathematical Structures forComputer Sciences, 17(1):1?32.Anne Preller, 2012.
From Sentence to Concept: Pred-icate Logic and Quantum Logic in Compact ClosedCategories, pages 00?29.
Oxford University Press.Peter Selinger.
2011.
A survey of graphical lan-guages for monoidal categories.
In New Structuresfor Physics, volume 813 of Lecture Notes in Physics,pages 289?233.
Springer.Mark Steedman.
1996.
Surface Structure and Inter-pretation, volume 30 of Linguistic Inquiry Mono-graph.
MIT Press, Cambridge, Massachusetts.61A Proof of proposition 1Note first that composition and the tensor are well de-fined.Assume (f, p) : A ?
B and (g, q) : B ?
C. Thenq ?
f : A?
S and p : A?
S, so q ?
f + p : A?
S.Therefore (g, q) ?
(f, p) = (g ?
f, q ?
f + p) : A?
Cis well defined.
Similarly, if (fi, pi) : Ai?
Bifori = 1, 2 then p1?+p2: A1?
A2?
S and therefore(f1?f2, p1?+p2) : A1?A2?
B1?B2as required.The operation ?+is associative on arrows.
Indeed,let (ai)i, (bj)jand (ck)kbe the basis of A, B and C,respectively.
Then for r : C ?
S((p?+q)?+r)(ai?
bj?
ck)=(p?+q)(ai?
bj) + r(ck)=p(ai) + q(bj) + r(ck)=(p?+(q ?+r))(ai?
bj?
ck) .Hence the tensor product on arrows of CSis associative.To show the interchange law (1), we need a lemma:Lemma 5.
Let p : C ?
S, q : D ?
S and f : A ?C, g : B ?
D with Ker(f) = Ker(g) = {0}.
Then(p?+q) ?
(f ?
g) = (p ?
f)?+(q ?
g)Indeed, let (ai)i, (bi)i, (ci)iand (di)ibe the basesof A, B, C and D respectively.
For all i and j, wedecompose f(ai) on the basis (ci)iand similarly forg(bj) on (di)i:f(ai) =?rcirand g(bj) =?sdisEach family of indices (ir)rand (is)sis non empty,because Ker(f) = Ker(g) = {0}.
Hence,((p?+q) ?
(f ?
g))(ai?
bj)=(p?+q)(f(ai)?
g(bj))=(p?+q)((?rcir)?
(?sdis))=(p?+q)(?r,scir?
dis)=?r,sp(cir) + q(dis)=?rp(cir) +?sq(dis)=p(f(ai)) + q(g(bj))=((p ?
f)?+(q ?
g))(ai?
bj)The fifth equality uses the fact that 1 + 1 = 1 and thesum is non empty.
This terminates the proof of thelemma.Now let (f1, p1) : A ?
C, (f2, p2) : C ?
E,(g1, q1) : B ?
D and (g2, q2) : D ?
F .
We showfirst the following equality(f1?+g1)+(f2?+g2) = (f1+f2)?+(g1+g2).
(5)Indeed, let (ei)iand (fj)jbe the bases of A and Brespectively.
Then, for all i and j,((f1?+g1) + (f2?+g2))(ei?
fj)=(f1?+g1)(ei?
fj) + (f2?+g2)(ei?
fj)=f1(ei) + g1(fj) + f2(ei) + g2(fj)=((f1+ f2)?+(g1+ g2))(ei?
fj) .Finally, the Interchange Law follows from (5) and thedefinitions thus((f2, p2)?
(g2, q2)) ?
((f1, p1)?
(g1, q1))=(f2?
g2, p2?+q2) ?
(f1?
g1, p1?+q1)=((f2?
g2) ?
(f1?
g1), (p2?+q2) ?
(f1?
g1) + (p1?+q1))=((f2?
f1)?
(g2?
g1), (p2?
f1)?+(q2?
g1) + (p1?+q1))=((f2?
f1)?
(g2?
g1), (p2?
f1+ p1)?+(q2?
g1+ q1))=(f2?
f1, p2?
f1+ p1)?
(g2?
g1, q2?
g1+ q1)=((f2, p2) ?
(f1, p1))?
((g2, q2) ?
(g1, q1)) .Therefore CSis a monoidal category.B Proof of Lemma 2 and Proposition 2Proof.
Note that both F and M map inequalities ofbasic types to identities, hence also any atom withouta lexical morphism to an identity.
Let wordjlbe theproperty word occurring in pl, say as the kl-th fac-tor, ql= M(wordjl) and ml= F(wordjl), forl = 1, .
.
.
,m. Then M(pl) = 1U?
.
.
.
ql.
.
.
?
1Uand F(pl) = 1N?
.
.
.ml.
.
.
?
1N.
Suppose that eiis a basis vector of U and enodeia basis vector of Nsatisfying ei= I(enodei).Use induction on n?m?l and assume that e1?.
.
.?erl=M(pl+1)??
?
??M(pn?m)?(M(nodei1)?.
.
.
?M(nodeim)) and (enode1, 0) ?
.
.
.
?
(enoderl, 0) =F(pl+1) ?
?
?
?
?
F(pn?m) ?
(F(enodei1) ?
.
.
.
?F(enodeim)).6Let tlbe the triple created when composing F(pl)with (enode1, 0)?
.
.
.?
(enoderl, 0).
We want the showthat tlis true in IMif and only ifM(pl) is true at e1?.
.
.?
erl.Consider the case where wordjl: d ?
d. Theother cases are shown similarly.
Recall that ml?
(enodekl, 0) = (enodekl, tl), with tl= enodekl?eis-wordjl?
etrue.
Hence, F(pl)((enode1, 0) ?
.
.
.
?
(enoder, 0)) = ((enode1, 0) ?
.
.
.
(enodekl, tl) .
.
.
?
(enoder, 0) = (enode1?
.
.
.
?
enoder, tl).
Then tlis true in IMif and only if (I(enodekl),true) ?IEXT(I(eis-word)) if and only if qlis true at ekl, bydefinition of I .
On the other hand, 1U?.
.
.
ql.
.
.
?1Uistrue at e1?
.
.
.
ekl.
.
.
?erif and only if qlis true at ekl.If that is the case thenM(pl)(e1?
.
.
.
ekl.
.
.?
er) =e1?
.
.
.
ekl.
.
.?
er.60 can be replaced by any vector of S without changingthe proof.62
