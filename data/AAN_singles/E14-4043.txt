Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 221?225,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsZero subject detection for PolishMateusz Kope?cInstitute of Computer Science, Polish Academy of Sciences,Jana Kazimierza 5, 01-248 Warsaw, Polandm.kopec@ipipan.waw.plAbstractThis article reports on the first machinelearning experiments on detection of nullsubjects in Polish.
It emphasizes the roleof zero subject detection as the part ofmention detection ?
the initial step of end-to-end coreference resolution.
Anaphoraresolution is not studied in this article.1 IntroductionZero subject detection is an important issue foranaphora and coreference resolution for the null-subject languages, including all Balto-Slavic lan-guages and most Romance languages.
Their dis-tinctive feature is the possibility for an indepen-dent clause to lack an explicit subject.
Person,number, and/or gender agreement with the refer-ent is indicated by the morphology of the verb:(1) Maria wr?ci?a ju?z z Francji.
?Spe?dzi?a tammiesia?c.
?Maria came back from France.
?Hadsingular:femininespenta month there.
?The recently created Polish Coreference Cor-pus1(PCC) (Ogrodniczuk et al., 2013) containszero subject annotation.
A markable representingthe null subject is the verbal form following theposition where the argument would have been ex-pected.
As tested on the development part of thecorpus (described in detail later), omitting a per-sonal pronoun is a frequent issue in the Polish lan-guage ?
about 30% of verbs do not have explicitsubjects.
Russo et al.
(2012) reports similar fig-ures for Italian (30.42%) and Spanish (41.17%).Moreover, these null subjects are often part oflarge coreference clusters ?
the average size of anon-singleton coreference cluster in the develop-ment subcorpus was 3.56 mentions.
At the same1Publicly available at http://zil.ipipan.waw.pl/PolishCoreferenceCorpus.time, the non-singleton coreference cluster con-taining at least one zero subject had on average5.89 mentions.A mention detection module heavily influencesthe final coreference resolution score of an end-to-end coreference resolution system.
In Ogrod-niczuk and Kope?c (2011a) the system working ongold mentions achieved 82.90% F1 BLANC (Re-casens and Hovy, 2011), whereas on system men-tions the result dropped to 38.13% (the zero sub-ject detection module was not implemented).The aim of this paper is to find a method of au-tomatic zero subject detection to improve the ac-curacy of mention detection as the initial step ofcoreference resolution.2 Related WorkWe present some of the most recent articles aboutmachine learning zero subject detection.Rello et al.
(2012b) describes a Brazilian Por-tuguese corpus with 5665 finite verbs total, outof which 77% have an explicit subject, 21% azero pronoun and 2% are impersonal construc-tions.
They extract various verb, clause and neigh-boring token features for each verb occurrence andclassify it into one of these 3 classes, achieving83.04% accuracy of a decision tree learning classi-fier, better than the baseline result of the Palavrasparser.
A very similar study is conducted alsofor Spanish (Rello et al., 2012a), with the bestresult of the lazy learning classifier K?
(Clearyand Trigg, 1995) of 87.6% accuracy, outperform-ing the baseline of Connexor parser.Chinese zero pronoun detection and resolutionis presented by Zhao and Ng (2007).
Features forzero pronoun identification consider mainly thegold standard parse tree structure.
Their trainingcorpus contained only 343 zero pronouns, as com-pared to 10098 verbs with explicit subjects ?
forChinese, the phenomenon is much less frequentthan for Polish or Spanish.
Therefore they weigh221positive and negative examples to get the balancebetween precision and recall ?
the best result of50.9% F1measure for positive to negative exam-ple weight ratio of 8:1 is reported.A study for the Romanian language (Mihaila etal., 2011) describes a corpus consisting of 2741sentences and 997 zero pronouns.
Class imbalanceis solved by training machine learning algorithmson all positive examples (zero pronouns) and thesame number of negative examples (sampled fromthe corpus).
Features used consider morphosyn-tactic information about the verb, precedence ofthe reflective pronoun ?se?
and the number ofverbs in the sentence.
Their best ensemble clas-sifier scored 74.5% accuracy.Only a few studies (for example (Broda et al.,2012; Ogrodniczuk and Kope?c, 2011b; Kope?c andOgrodniczuk, 2012)) consider the problem of rule-based or machine learning coreference resolutionfor the Polish language, however these attemptsleave zero subject detection as a non-trivial taskfor further study.3 Problem statementTable 1 presents part of speech definitions as-sumed in this article, based on the book about theNational Corpus of Polish (Przepi?rkowski et al.,2012).
Coarse-grained POS indicates whether aword with a given part of speech may be a subject(Noun) or a verb (Verb) in a sentence.
The last fourcolumns present which morphosyntactic informa-tion is available for each part of speech.
There arefew differences in this definition with respect tothe original approach in the book:?
We treat numerals, gerunds and pronouns asNouns ?
because they are frequently sub-jects of the sentence and have the samemorphosyntactic information as ?standard?nouns.?
We do not consider siebie (?self?, tradition-ally treated as pronoun) as a Noun, as it can-not be a subject.?
Tags: impt, imps, inf, pcon, pant, pact, ppas,pred, which are traditionally considered verbtags, are not treated by us as Verbs, becausethey cannot have a subject.With such a definition of parts of speech, ourtask may be stated as follows: given a clause witha Verb, decide whether the clause contains a NounCoarse--grainedPOSPOS TagNumberCaseGenderPersonNounNoun subst + + +Depreciative form depr + + +Main numeral num + + +Collective numeral numcol + + +Gerund ger + + +Personal pronoun ?
1st, 2nd person ppron12 + + + +Personal pronoun ?
3rd person ppron3 + + + +VerbNon-past form fin + +Future byc?
bedzie + +Agglutinate byc?
aglt + +L-participle praet + +winien-like verb winien + +Table 1: Parts of speechwhich is the Verb?s explicit subject.
From now onin this paper, the words ?noun?
and ?verb?
havethe meaning of Noun and Verb, respectively.
Inthis study, we do not try to handle the cases ofsubjects not being nouns, as judging from our ob-servations, it is very infrequent.
We do take intoaccount in our solution the cases of the subject notin the nominative case, as in the example:(2) Pienie?dzynoun:genitivenie starczy dla wszys-tkich.
?There wouldn?t be enough money for everyone.
?It is worth noting that Polish is a free-word-order language, therefore there are many possibleplaces for the subject to appear, with respect to theposition of the verb.As the corpus has only automatic morphosyn-tactic information available (provided by the PAN-TERA tagger (Aceda?nski, 2010)), not corrected bythe coreference annotators, the only verbs consid-ered in this study are the ones found by the tag-ger.
If such a verb was marked as a mention bythe coreference annotator (verb mention in table2), it is a positive example for our machine learn-ing study, otherwise a negative one.
Sentence andclause segmentation in the corpus was also auto-matic.
We are aware that the corpus used for thestudy was not perfectly suited for the task ?
verbswith a zero subject are not marked there explicitly,but can only be found based on automatic tagging.However the tagging error of detecting verbs is re-ported as not higher than 0.04% (for the fin tag,see (Aceda?nski, 2010) for details), so we considerthe resource sufficiently correct.4 Development and evaluation dataEach text of the Polish Coreference Corpus is a250-350 word sample, consisting of full, subse-quent paragraphs extracted from a larger text.
Textgenres balance correspond to the National Corpus222Corpus # texts # sentences # tokens # verbs # mentions # verb mentionsDevelopment 390 6481 110379 10801 37250 3104Evaluation 389 6737 110474 11000 37167 3106Total 779 13218 220853 21801 74417 6210Table 2: Zero subject study data statisticsof Polish (Przepi?rkowski et al., 2012).
At thetime this study started, 779 out of 1773 texts (ran-domly chosen) of the Polish Coreference Corpuswere already manually annotated.
Annotated textswere randomly split into two equal-sized subcor-pora for development and evaluation.
Their de-tailed statistics are presented in Table 2.4.1 Inter-annotator agreement210 texts of the Polish Coreference Corpus wereannotated independently by two annotators.
Thispart was analyzed for the inter-annotator agree-ment of deciding if a verb has a zero subject ornot.
In the data there were 5879 verbs total,for which observed agreement yielded 92.57%.Agreement expected by chance (assuming a perannotator chance annotation probability distribu-tion) equalled 57.52%, therefore chance-correctedCohen?s ?
for the task equalled 82.51%.4.2 Results of full dependency parsingThe first Polish dependency parser was recentlydeveloped and described by Wr?blewska (2012).The author reports 71% LAS2and 75.2% UAS3performance of this parser.
This parser was usedto detect null subjects ?
every verb lacking thedependency relation of the subject type (subj)was marked as missing the subject.
This base-line method achieved accuracy of 67.23%, preci-sion of 46.53%, recall of 90.47% and F1equal to61.45%.
These results are worse than a simple ma-jority baseline classifier, therefore current state-of-the-art Polish dependency parsing is not a satisfac-tory solution to the task stated in this article.5 FeaturesBased on a number of experiments on the develop-ment corpus, we chose a number of features pre-sented in table 3.Subject candidate existence features from thebottom of the table 3 use variables: c1, c2and w.Separate feature was generated for each combi-nation of these three variables.
The variable w2Labeled attachment score ?
the percentage of tokens thatare assigned a correct head and a correct dependency type.3Unlabeled attachment score ?
the percentage of tokensthat are assigned a correct head.represents the window around the verb, with fol-lowing values: the clause containing the verb, thesentence containing the verb, windows of 1 to 5tokens before the verb, windows of 1 to 5 tokensafter the verb, windows of 1 to 5 tokens both be-fore and after the verb.
Variable c1representscompatibility of noun and verb, with values be-ing any nonempty subset of the set of followingconditions: case of the noun equal to nominative(NOM), number agreement with the verb (NUM),person or gender agreement (POG), depending onwhich was available to check, see Table 1.
Vari-able c2is similar to c1, with the following values:{NOM}, {POG}, {NOM, POG}.Feature TypeVerb featuresnumber of the verb ?
to help with cases of plural verbs having twoor more singular nouns as subjectnominaltag of the verb ?
as it may happen, that some parts of speech behavedifferentlybooleanis the verb on the pseudo-verbs list extracted from (?Swidzi?nski,1994) ?
i.e.
may not require a subjectbooleanNeighboring token featurestag of the next token nominaltag of the previous token nominalis the previous tag equal to praet ?
a redundant feature to the pre-vious one, but it should help with the cases like:.
.
.
by?apraetmaglt:pri.
.
.
".
.
.
(I) was .
.
.
"when we split a word into a L-participle and agglutinate.
Annota-tion guidelines were to only mark the agglutinate as a mention,when the verb does not have an explicit subjectbooleandoes one of the previous two tokens have the pred tag ?
should al-low detecting examples similar to:Mo?znapredsie?
by?opraettego spodziewac?.".
.
.
It could have been expected.
.
.
.
"Trzebapredby?opraetmy?slec?
wcze?sniej.
"(One) should have thought before.
"when by?o ("have") cannot have subject, as it is part of an imper-sonal constructionbooleanis the next tag inf ?
similar role to the previous feature, as in:Wtedy nale?zyfinpoprosic?inf.
"(One) should then ask for it.
"when nale?zy ("one should") cannot have a subjectbooleanis the previous token a comma booleanLength featuresnumber of tokens in the sentence (following the hypothesis, that theshorter the sentence/clause, the less likely for the subject to appear)numericalnumber of tokens in the clause with the verb numericalSubject candidate existence featuresexistence of a noun not preceded by jak/jako ("as") in window wfulfilling conditions from set c1booleanexistence of at least two nouns not preceded by jak/jako ("as") inwindow w both fulfilling conditions from set c2booleanTable 3: Features6 EvaluationPresented features were used to train a machinelearning algorithm.
We chose the JRip imple-mentation of RIPPER (Cohen, 1995) from WEKA(Hall et al., 2009) for the possibility to interpret therules, which is outside of the scope of this paper.6.1 Accuracy on the development corpusA baseline model which always predicts that averb has an explicit subject achieves 71.13% ac-223True valuesnull subject explicit subjectPredictionsnull subject 2093 815explicit subject 1013 7079Table 4: Confusion matrixcuracy on the development data.
The upper boundof the ITA (as stated earlier) is around 92.57% ac-curacy.We used 10-fold cross-validation which was re-peated 10 times with different random seeds fortraining and train/test splits.
The average from thetotal of 100 trials (each cross-validation split sep-arately) was equal to 82.74%, with standard devi-ation of 1.27%.
As the Shapiro-Wilk (1965) testfor normality for this data gives p-value of 0.38, itmay be assumed that it follows the normal distri-bution.
In that case, the 95% confidence intervalfor the accuracy is equal to [82.49%, 82.99%].6.2 Accuracy on the evaluation corpusThe evaluation corpus was used only for two ex-periments presented below: to calculate accuracyand learning curve of the developed solution.We used the model learnt on the developmentcorpus and tested it on the evaluation corpus,achieving 83.38% accuracy.
A majority classifierwould achieve 71.76% accuracy on this corpus.The confusion matrix is depicted in Table 4.
Forfinding the null subjects, recall of 67.39% and pre-cision of 71.97% gives F1measure of 69.60%.6.3 Learning curveTo test how the number of training examples in-fluences the quality of the trained classifier, weused subsets of the development corpus of varioussizes as training sets.
The test set was the samein all cases (the evaluation corpus).
Proportionsof the examples used ranged from 5% to 100%of the development corpus, each proportion wastested 10 times to provide an estimation of vari-ance.
For example, to evaluate the efficiency ofthe classifier trained on 5% of the training exam-ples, we randomly sampled 5% of the examples,trained the classifier and tested it on the full evalu-ation corpus.
Then we repeated it another 9 times,randomly choosing a different 5% portion of theexamples for training.Again the Shapiro-Wilk test was taken to assessthe normality of results for each proportion, outof 19 proportions tested (the proportion of 1 wasof course not tested for normality), only 3 had p-0.2 0.4 0.6 0.8 1.00.790.82Proportion of training set usedAccuracy on evaluationcorpusFigure 1: Learning curvevalue less than 0.1, therefore we assumed that thedata is distributed approximately normally.
The95% confidence intervals of the classifiers trainedon a given proportion of the development corpusare shown in the Figure 1.
The algorithm clearlybenefits from having more training examples.
Weobserve that the curve is generally of the desiredshape, yet it flattens when approaching the fulltraining set used.
It may suggest that the devel-oped solution would not be able to significantlyexceed 84%, even given more training examples.7 Conclusions and future workThis article presented an efficient zero subject de-tection module for Polish.
We highlighted somedifficult examples to take into account and pro-posed a solution for the Polish language.The achieved accuracy of 83.38% significantlyexceeds the baseline of majority tagging, equal to71.76%, but there is still room for improvement,as the upper bound of 92.57% was computed.
Theachieved result for the task of null subject detec-tion looks promising for the application in mentiondetection for coreference resolution.The invented solution needs to be incorporatedin a complete coreference resolver for Polish andevaluated for the extent to which using such an ad-vanced separate classifier for zero subject detec-tion improves the mention detection and, further-more, end-to-end coreference resolution accuracy.AcknowledgementsThe work reported here was cofounded by theComputer-based methods for coreference resolu-tion in Polish texts project financed by the Pol-ish National Science Centre (contract number6505/B/T02/2011/40) and by the European Unionfrom resources of the European Social Fund.Project PO KL ?Information technologies: Re-search and their interdisciplinary applications?.224ReferencesSzymon Aceda?nski.
2010.
A Morphosyntactic BrillTagger for Inflectional Languages.
In Hrafn Lofts-son, Eir?kur R?gnvaldsson, and Sigr?n Helgad?ttir,editors, Advances in Natural Language Processing,volume 6233 of Lecture Notes in Computer Science,pages 3?14.
Springer.Bartosz Broda, ?ukasz Burdka, and Marek Maziarz.2012.
IKAR: An Improved Kit for Anaphora Res-olution for Polish.
In COLING (Demos), pages 25?32.John G. Cleary and Leonard E. Trigg.
1995.
K*:An instance-based learner using an entropic distancemeasure.
In In Proceedings of the 12th InternationalConference on Machine Learning, pages 108?114.Morgan Kaufmann.William W. Cohen.
1995.
Fast effective rule induc-tion.
In In Proceedings of the Twelfth InternationalConference on Machine Learning, pages 115?123.Morgan Kaufmann.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H. Witten.2009.
The WEKA data mining software: an update.SIGKDD Explor.
Newsl., 11(1):10?18, November.Mateusz Kope?c and Maciej Ogrodniczuk.
2012.
Cre-ating a Coreference Resolution System for Pol-ish.
In Proceedings of the Eighth InternationalConference on Language Resources and Evalua-tion, LREC 2012, pages 192?195, Istanbul, Turkey.ELRA.Claudiu Mihaila, Iustina Ilisei, and Diana Inkpen.2011.
Zero Pronominal Anaphora Resolution for theRomanian Language.
Research Journal on Com-puter Science and Computer Engineering with Ap-plications?
POLIBITS, 42.Maciej Ogrodniczuk and Mateusz Kope?c.
2011a.
End-to-end coreference resolution baseline system forPolish.
In Zygmunt Vetulani, editor, Proceedings ofthe 5th Language & Technology Conference: Hu-man Language Technologies as a Challenge forComputer Science and Linguistics, pages 167?171,Pozna?n, Poland.Maciej Ogrodniczuk and Mateusz Kope?c.
2011b.Rule-based coreference resolution module for Pol-ish.
In Proceedings of the 8th Discourse Anaphoraand Anaphor Resolution Colloquium (DAARC2011), pages 191?200, Faro, Portugal.Maciej Ogrodniczuk, Katarzyna G?owi?nska, MateuszKope?c, Agata Savary, and Magdalena Zawis?awska.2013.
Polish coreference corpus.
pages 494?498.Adam Przepi?rkowski, Miros?aw Ba?nko, Rafa?
L.G?rski, and Barbara Lewandowska-Tomaszczyk,editors.
2012.
Narodowy Korpus Je?zyka Polskiego[Eng.
: National Corpus of Polish].
WydawnictwoNaukowe PWN, Warsaw.Marta Recasens and E. Hovy.
2011.
BLANC: Imple-menting the Rand index for coreference evaluation.pages 485?510.Luz Rello, Ricardo Baeza-Yates, and Ruslan Mitkov.2012a.
Elliphant: Improved Automatic Detectionof Zero Subjects and Impersonal Constructions inSpanish.
In Proceedings of the 13th Conference ofthe European Chapter of the Association for Com-putational Linguistics, pages 706?715, Avignon,France, April.
Association for Computational Lin-guistics.Luz Rello, Gabriela Ferraro, and Iria Gayo.
2012b.A First Approach to the Automatic Detection ofZero Subjects and Impersonal Constructions in Por-tuguese.
Procesamiento del Lenguaje Natural,49:163?170.Lorenza Russo, Sharid Lo?iciga, and Asheesh Gulati.2012.
Improving machine translation of null sub-jects in Italian and Spanish.
In Proceedings ofthe Student Research Workshop at the 13th Confer-ence of the European Chapter of the Association forComputational Linguistics, pages 81?89, Avignon,France, April.
Association for Computational Lin-guistics.S.
S. Shapiro and M. B. Wilk.
1965.
An analysisof variance test for normality (complete samples).Biometrika, 52(3/4):591?611, Dec.Marek?Swidzi?nski.
1994.
Syntactic dictionary of pol-ish verbs.Alina Wr?blewska.
2012.
Polish dependency bank.Linguistic Issues in Language Technology, 7(1).Shanheng Zhao and Hwee Tou Ng.
2007.
Identifica-tion and Resolution of Chinese Zero Pronouns: AMachine Learning Approach.
In EMNLP-CoNLL,pages 541?550.
ACL.225
