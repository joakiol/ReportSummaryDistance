Mandarin-English Information (MEI):Investigating Translingual Speech RetrievalHelen Meng, 1 Sanjeev Khudanpur, ~ Gina Levow, 3 Douglas W. Oard, 3 Hsin-Min Wang'1The Chinese University of Hong Kong, 2Johns Hopkins University,3University of Maryland and 4Academia Sinica (Taiwan){hmmeng@se.cuhk.edu.hk, sanjeev@clsp.jhu.edu, gina@umiacs.umd.edu,oard@, glue.umd.edu, whm@ iis.sinica.edu.tw }AbstractWe describe a system which supportsEnglish text queries searching forMandarin Chinese spoken documents.This is one of the first attempts to tightlycouple speech recognition with machinetranslation technologies for cross-mediaand cross-language retrieval.
TheMandarin Chinese news audio are indexedwith word and subword units by speechrecognition.
Translation of these multi-scale units can effect cross-languageinformation retrieval.
The integratedtechnologies will be evaluated based onthe performance of translingnal speechretrieval.1.
IntroductionMassive quantities of audio and multimediaprograms are becoming available.
For example,in mid-February 2000, www.real.com listed1432 radio stations, 381 Internet-onlybroadcasters, and 86 television stations withInternet-accessible content, with 529broadcasting in languages other than English.Monolingual speech retrieval is now practical, asevidenced by services such as SpeechBot(speechbot.research.compaq.com), and it is clearthat there is a potential demand for translingualspeech retrieval if effective techniques can bedeveloped.
The Mandarin-English Information(MEI) project represents one of the first effortsin that direction.MEI is one of the four projects elected forthe Johns Hopkins University (JHU) SummerWorkshop 2000.1 Our research focus is on theintegration of speech recognition and embeddedtranslation technologies in the context oftranslingual speech retrieval.
Possibleapplications of this work include audio andvideo browsing, spoken document retrieval,automated routing of information, andautomatically alerting the user when specialevents occur.At the time of this writing, most of the MEIteam members have been identified.
This paperprovides an update beyond our first proposal\[Meng et al, 2000\].
We present some ongoingwork of our current eam members, as well asour ideas on an evolving plan for the upcomingJHU Summer Workshop 2000.
We believe theinput from the research community will benefitus greatly in formulating ourfinal plan.2.
Background2.1 Translingual Information RetrievalThe earliest work on large-vocabulary cross-language information retrieval from free-text(i,e., without manual topic indexing) wasreported in 1990 \[Landauer and Littman, 1990\],and the topic has received increasing attentionover the last five years \[Oard and Diekema,1998\].
Work on large-vocabulary retrieval fromrecorded speech is more recent, with some initialwork reported in 1995 using subword indexing\[Wechsler and Schauble, 1995\], followed by thefirst TREC 2 Spoken Document Retrieval (SDR)I http://www.clsp,jhu.edu/ws2000/2 Text REtrieval Conference, http://trec.nist.gov23evaluation \[Garofolo et al, 2000\].
The TopicDetection and Tracking (TDT) evaluations,which started in 1998, fall within our definitionof speech retrieval for this purpose, differingfrom other evaluations principally in the natureof the criteria that human assessors use whenassessing the relevance of a news stow to aninformation eed.
In TDT, stories are assessedfor relevance to an event, while in TREC storiesare assessed for relevance to an explicitly statedinformation eed that is often subject- ratherthan event-oriented.The TDT-33 evaluation marked the firstcase of translingual speech retrieval - the task offinding information in a collection of recordedspeech based on evidence of the informationneed that might be expressed (at least partially)in a different language.
Translingual speechretrieval thus merges two lines of research thathave developed separately until now.
In theTDT-3 topic tracking evaluation, recognizertranscripts which have recognition errors wereavailable, and it appears that every team madeuse of them.
This provides a valuable point ofreference for investigation of techniques thatmore tightly couple speech recognition withtranslingual retrieval.
We plan to explore oneway of doing this in the Mandarin-EnglishInformation (MEI) project.2.2 The Chinese LanguageIn order to retrieve Mandarin audio documents,we should consider a number of linguisticcharacteristics of the Chinese language:The Chinese language has many dialects.Different dialects are characterized by theirdifferences in the phonetics, vocabularies andsyntax.
Mandarin, also known as Putonglma("the common language"), is the most widelyused dialect.
Another major dialect is Cantonese,predominant in Hong Kong, Macau, SouthChina and many overseas Chinese communities.Chinese is a syllable-based language,where each syllable carries a lexical tone.Mandarin has about 400 base syllables and fourlexical tones, plus a "light" tone for reducedsyllables.
There are about 1,200 distinct, tonalsyllables for Mandarin.
Certain syllable-tone3 http://morph.ldc.upenn.edu/Projects/TDT3/combinations are non-existent in the language.The acoustic correlates of the lexical toneinclude the syllable's fundamental frequency(pitch contour) and duration.
However, theseacoustic features are also highly dependent onprosodic variations of spoken utterances.The structure of Mandarin (base) syllablesis (CG)V(X), where (CG) the syllable onset - Cthe initial consonant, G is the optional medialglide, V is the nuclear vowel, and X is the coda(which may be a glide, alveolar nasal or velarnasal).
Syllable onsets and codas are optional.Generally C is known as the syllable initial, andthe rest (GVX) syllable final.
4 Mandarin hasapproximately 21 initials and 39 finals.
5In its written form, Chinese is a sequenceof characters.
A word may contain one or morecharacters.
Each character is pronounced as atonal syllable.
The character-syllable mapping isdegenerate.
On one hand, a given character mayhave multiple syllable pronunciations - forexample, the character/d" may be pronounced as/hang2/, 6/hang4/, or/xing2/.
On the other hand,a given tonal syllable may correspond tomultiple characters.
Consider the two-syllablepronunciation/fu4 shu4/, which corresponds toatwo-character word.
Possible homophonesinclude ~, ,  (meaning "rich"), ~ ~tR, ("negativenumber"), ~1~1~, ("complex number" or"plural"), ~1~ ("repeat").
7Aside from homographs and homophones,another source of ambiguity in the Chineselanguage is the definition of a Chinese word.The word has no delimiters, and the distinctionbetween a word and a phrase is often vague.
Thelexical structure of the Chinese word is verydifferent compared to English.
Inflectionalforms are minimal, while morphology and wordderivations abide by a different set of rules.
Aword may inherit the syntax and semantics of(some of) its compositional characters, for4 http://m?rph'ldc'upenn'edu/Pr?jects/Chinese/intr?
'html5 The corresponding linguistic haracteristics of Cantoneseare very similar.6 These are Mandarin pinyin, the number encodes the toneof the syllable.7 Example drawn from \[Leung, 1999\].24example, 8 ~ means red (a noun or anadjective), ~., means color (a noun), and ~.
,together means "the color red"(a noun) orsimply "red" (an adjective).
Alternatively, aword may take on totally differentcharacteristics of its own, e.g.
~.
means east (anoun or an adjective), ~ means west (a noun oran adjective), and .~.~ together means thing (anoun).
Yet another case is where thecompositional characters of a word do not formindependent lexical entries in isolation, e.g.
D~means fancy (a verb), but its characters do notoccur individually.
Possible ways of derivingnew words from characters are legion.
Theproblem of identifying the words string in acharacter sequence is known as the segmentation/ tokenization problem.
Consider the syllablestring:/zhe4 yil wan3 hui4 ru2 chang2 ju3 xing2/The corresponding character string has threepossible segmentations - all are correct, but eachinvolves a distinct set of words:(Meaning: It will be take place tonight as usual.
)(Meaning: The evening banquet will take placeas usual.
)(Meaning: If this evening banquet akes placefrequently...)The above considerations lead to a numberof techniques we plan to use for our task.
Weconcentrate on three equally critical problemsrelated to our theme of translingual speechretrieval: (i) indexing Mandarin Chinese audiowith word and subword units, (ii) translatingvariable-size units for cross-languageinformation retrieval, and (iii) devising effectiveretrieval strategies for English text queries andMandarin Chinese news audio.3.
Multiscale Audio IndexingA popular approach to spoken documentretrieval is to apply Large-Vocabularys Examples drawn from \[Meng and Ip, 1999\].Continuous Speech Recognition (LVCSR) 9 foraudio indexing, followed by text retrievaltechniques.
Mandarin Chinese presents achallenge for word-level indexing by LVCSR,because of the ambiguity in tokenizing asentence into words (as mentioned earlier).Furthermore, LVCSR with a static vocabulary ishampered by the out-of-vocabulary (OOV)problem, especially when searching sources withtopical coverage as diverse as that found inbroadcast news.By virtue of the monosyllabic nature of theChinese language and its dialects, the syllableinventory can provide a complete phonologicalcoverage for spoken documents, and circumventthe OOV problem in news audio indexing,offering the potential for greater recall insubsequent retrieval.
The approach thus supportssearches for previously unknown query terms inthe indexed audio.The pros and cons of subword indexing foran English spoken document retrieval task wasstudied in \[Ng, 2000\].
Ng pointed out that theexclusion of lexical knowledge when subwordindexing is performed in isolation may adverselyimpact discrimination power for retrieval, butthat some of that impact can be mitigated bymodeling sequential constraints among subwordunits.
We plan to investigate the efficacy ofusing both word and subword units forMandarin audio indexing \[Meng et al, 2000\].Although Ng found that such an approachproduced little gain over words alone forEnglish, the structure of Mandarin Chinese mayproduce more useful subword features.3.1 Modeling Syllable Sequence ConstraintsWe have thus far used overlapping syllable N-grams for spoken document retrieval for twoChinese dialects - Mandarin and Cantonese.Results on a known-item retrieval task with over1,800 error-free news transcripts \[Meng et al,1999\] indicate that constraints from overlappingbigrams can yield significant improvements inretrieval performance over syllable unigrams,producing retrieval performance competitive9 The lexicon size of a typical large-vocabularycontinuous speech recognizer can range from 10,000to 100,000 word forms.25with that obtained using automatically tokenizedChinese words.The study in \[Chen, Wang and Lee, 2000\]also used syllable pairs with skipped syllables inbetween.
This is because many Chineseabbreviations are derived from skippingcharacters, e.g.
J .~:~.~t:~  ~ NationalScience Council" can be abbreviated as l~r~(including only the first, third and the lastcharacters).
Moreover, synonyms often differ byone or two characters, e.g.
both ~ ' /~4~ and~.~,,Ag mean "Chinese culture".
Inclusion o fthese "skipped syllable pairs" also contributed toretrieval performance.When modeling sequential syllableconstraints, lexical constraints on recognizedwords may be helpful.
We thus plan to exp\]Iorethe potential for integrated sequential model\]lingof both words and syllables \[Meng et al, 20013\].4.
Multiseale Embedded TranslationFigures 1 and 2 illustrate two translingualretrieval strategies.
In query translation, Englishtext queries are transformed into Mandarin andthen used to retrieve Mandarin documents.
Fordocument translation, Mandarin documents aretranslated into English before they are indexedand then matched with English queries.McCarley has reported improved effectivenessfrom techniques that couple the two techniques\[McCarley, 1999\], but time constraints maylimit us to explonng only the query translationstrategy dunng the six-week Workshop.4,1 Word  Translat ionWhile we make use of sub-wordtranscription tosmooth out-of-vocabulary(OOV)problems in speech recognition as describedabove, and to alleviate the OOV problem :fortranslation as we discuss in the next section,accurate translation generally relies on theadditional information available at the word andphrase levels.
Since the "bag of words"information retrieval techniques do notincorporate any meaningful degree of languageunderstanding to assess similarity betweenqueries and documents, a word-for-word (or,more generally, term-for-term) embeddedtranslation approach can achieve a useful levelof effectiveness for many translingual retrievalapplications \[Oard and Diekema, 1998\].We have developed such a technique for theTDT-3 topic tracking evaluation \[Levow andOard, 2000\].
For that work we extracted anenriched bilingual Mandarin-English term list bycombining two term lists: (i) A list assembledby the Linguistic Data Consortium from freelyavailable on-line resources; and (ii) entries fromthe CETA file (sometimes referred to as"Optilex").
This is a Chinese to Englishtranslation resource that was manually compiledby a team of linguists from more than 250 textsources, including special and general-purposeprint dictionaries, and other text sources uch asnewspapers.
The CETA file contains over250,000 entries, but for our lexical work weextracted a subset of those entries drawn fromcontemporary general-purpose sources.
We alsoexcluded efinitions uch as "particle indicatinga yes/no question."
Our resulting Chinese toEnglish merged bilingual term list containstranslations for almost 200,000 Chinese terms,with average of almost two translationalternatives per term.
We have also used thesame resources to construct an initial English toChinese bilingual term list that we plan to refinebefore the Workshop.Three significant challenges faced by term-to-term translation systems are term selection inthe source language, the source languagecoverage of the bilingual term list, andtranslation selection in the target language whenmore than one alternative translation is known.Word segmentation is a natural by-product oflarge vocabulary Mandarin speech recognition,and white space provides word boundaries forthe English queries.
We thus plan to choosewords as our basic term set, perhaps augmentingthis with the multiword expressions found in thebilingual term list.Achieving adequate source languagecoverage is challenging in news retrievalapplications of the type modelled by TDT,because proper names and technical terms thatmay not be present in general-purpose lexicalresources often provide important retrieval cues.Parallel (translation equivalent) corpora haveproven to be a useful source of translation26equivalent terms, but obtaining appropriatedomain-specific parallel corpora in electronicform may not be practical in some applications.We therefore plan to investigate the use ofcomparable corpora to learn translationequivalents, based on techniques in \[Fung,1998\].
Subword translation, described below,provides a complementary way of handlingterms for which translation equivalents cannotbe reliably extracted from the availablecomparable corpora.One way of dealing with multipletranslations is to weight the alternativetranslations using either a statistical translationmodel trained on parallel or comparable corporato estimate translation probability conditionedon the source language term.
When suchresources are not sufficiently informative, it isgenerally possible to back off to anunconditioned preference statistic based onusage frequency of each possible translation i  arepresentative monolingual corpus in the targetlanguage.
In retrospective r trieval applicationsthe collection being searched can be used forthis purpose.
We have applied simple versionsof this approach with good results \[Levow andOard, 2000\].We have recently observed that a simplertechnique introduced by \[Pirkola, 1998\] canproduce xcellent results.
The key idea is to usethe structure of the lexicon, in which severaltarget language terms can represent a singlesource language term, to induce structure in thetranslated query that the retrieval system canautomatically exploit.
In essence, the translatedquery becomes a bag of bags of terms, whereeach smaller bag corresponds to the set ofpossible translations for one source-languageterm.
We plan to implement his structuredquery translation approach using the Inquery\[Callan, 1992\] "synonym" operator in the samemanner as \[Pirkola, 1998\], and to the potential toextend the technique to accommodate alternativerecognition hypothesis and subword units aswell:4.2 Subword  Translat ionSince Mandarin spoken documents can beindexed with both words and subwords, thetranslation (or "phonetic transliteration") ofsubword units is of particular interest.
We planto make use of cross-language phoneticmappings derived from English and Mandarinpronunciation rules for this purpose.
This shouldbe especially useful for handling named entitiesin the queries, e.g.
names of people, places andorganizations, etc.
which are generally importantfor retrieval, but may not be easily translated.Chinese translations of English proper nounsmay involve semantic as well as phoneticmappings.
For example, "Northern Ireland" istranslated as :~b~ttlM - -  where the firstcharacter ~ means 'north', and the remainingcharacters ~tllllll are pronounced as /ai4-er3-lan2L Hence the translation is both semanticand phonetic.
When Chinese translations striveto attain phonetic similarity, the mapping maybe inconsistent.
For example, consider thetranslation of "Kosovo" - sampling Chinesenewspapers in China, Taiwan and Hong Kongproduces the following translations:~-~r~ /kel-suo3-wo4?, ~-~ /kel-suo3-fo2/,~'~&/kel-suo3-ful/f l4"~dt/kel-suo3-fu2/, or~/ke  1-suo3-fo2/.As can be seen, there is no systematicmapping to the Chinese character sequences, butthe translated Chinese pronunciations bear someresemblance to the English pronunciation (/k ows ax vow/).
In order to support retrieval underthese circumstances, the approach shouldinvolve approximate matches between theEnglish pronunciation and the Chinesepronunciation.
The matching algorithm shouldalso accommodate phonological variations.Pronunciation dictionaries, or pronunciationgeneration tools for both English words andChinese words / characters will be useful for thematching algorithm.
We can probably leverageoff of ideas in the development of universalspeech recognizers \[Cohen et al, 1997\].5.
Mulfiscale Retrieval5.1 Coupling Words and SubwordsWe intend to use both words and subwords forretrieval.
Loose coupling would involve separateretrieval runs using words and subwords,producing two ranked lists, followed by listmerging using techniques such as those exploredby \[Voorhees, 1995\].
Tight coupling, by27contrast, would require creation of a unifiedindex containing both word and subword units,resulting in a single ranked list.
We hope toexplore both techniques during the Workshop.5.2 Imperfect Indexing and Translat ionIt should be noted that speech recognitionexacerbates uncertainty when indexing audio,and that translation or transliteration exacerbatesuncertainty when translating queries and/ordocuments.
To achieve robustness for retrieval,we have tried three techniques that we havefound useful: (i) Syllable lattices were used in\[Wang, 1999\] and \[Chien et al, 2000\] formonolingual Chinese retrieval experiments.
Thelattices were pruned to constrain the searchspace, but were able to achieve robust retrievalbased on imperfect recognized transcripts.
(ii)Query expansion, in which syllable transcriptionwere expanded to include possibly confusablesyllable sequences based on a syllable confusionmatrix derived from recognition errors, was usedin \[Meng et al, 1999\].
(iii) We have expandedthe document representation using termsextracted from similar documents in acomparable collection \[Levow and Oard, 2000\],and similar techniques are known to work wellin the case of query translation (Ballesteros andCroft, 1997).
We hope to add to this set: oftechniques by exploring the potential for queryexpansion based on cross-language phoneticmapping.6.
Using the TDT-3 CollectionWe plan to use the TDT-2 collection fordevelopment testing and the TDT-3 collectionfor evaluation.
Both collections providedocuments from two English newswire sources,six English broadcast news audio sources, twoMandarin Chinese newswire sources, and oneMandarin broadcast news source (Voice ofAmerica).
Manually established storyboundaries are available for all audiocollections, and we plan to exploit thatinformation to simplify our experiment design.The TDT-2 collection includes completerelevance assessments for 20 topics, and theTDT-3 collection provides the same for 60additional topics, 56 of which have at least onerelevant audio story.
For each topic, at least fourEnglish stories and four Chinese stories areknown.We plan to automatically derive text queriesbased on one or more English stories that arepresented as exemplars, and to use those queriesto search the Mandarin audio collection.Manually constructed queries will provide acontrastive condition.
Unlike the TDT "topictracking" task in which stories must be declaredrelevant or not relevant in the order of theirarrival, we plan to perform retrospectiveretrieval experiments in which all documents areknown when the query is issued.
By relaxingthe temporal ordering of the TDT topic trackingtask, we can meaningfully search for MandarinChinese stories that may have arrived before theexemplar story or stories.
We thus plan to reportranked retrieval measures of effectiveness uchas average precision in addition to the detectionstatistics (miss and false alarm) typicallyreported in TDT.7.
SummaryThis paper presents our current ideas andevolving plan for the MEI project, to take placeat the Johns Hopkins University SummerWorkshop 2000.
Translingual speech retrieval isa long-term research direction, and our teamlooks forward to jointly taking an initial step totackle the problem.
The authors welcome allcomments and suggestions, aswe strive to betterdefine the problem in preparation for the six-week Workshop.AcknowledgmentsThe authors wish to thank Patrick Schone, ErikaGrams, Fred Jelinek, Charles Wayne, Kenney?
Ng, John Garofolo, and the participants in theDecember 1999 WS2000 planning meeting andthe TDT-3 workshop for their many helpfulsuggestions.
The Hopkins Summer Workshopseries is supported by grants from the NationalScience Foundation.
Our results reported in thispaper eference thesis work in progress of Wai-Kit Lo (Ph.D. candidate, The Chinese Unversityof Hong Kong) and Berlin Chen (Ph.D.candidate, National Taiwan University).28ReferencesBallesteros and W. B. Croft, "PhrasalTranslation and Query Expansion Techniquesfor Cross-Language Information Retrieval,"Proceedings ofACM SIGIR, 1997.Callan, J. P., W. B. Croft, and S. M. Harding,"The INQUERY Retrieval System,"Proceedings of the 3rd International Conferenceon Database and Expert Systems Applications,1992.Carbonnell, J., Y. Yang, R. Frederking and R.D.Brown, "Translingual Information Retrieval: AComparative Evaluation," Proceedings ofIJCAI,1997.Chen, B., H.M. Wang, and L.S.
Lee, "Retrievalof Broadcast News Speech in Mandarin ChineseCollected in Taiwan using Syllable-LevelStatistical Characteristics," Proceedings ofICASSP, 2000.Chien, L. F., H. M. Wang, B. R. Bai, and S. C.Lin, "A Spoken-Access Approach for ChineseText and Speech Information Retrieval," Journalof the American Society for InformationScience, 51 (4), pp.
313-323, 2000.Choy, C. Y., "Acoustic Units for MandarinChinese Speech Recognition," M.Phil.
Thesis,The Chinese University of Hong Kong, HongKong SAR, China, 1999.Cohen, P., S. Dharanipragada, J. Gros, M.Mondowski, C. Neti, S. Roukos and T. Ward,"Towards a Universal Speech Recognizer forMultiple Languages," Proceedings of ASRU,1997.Fung, P., "A Statistical View on BilingualLexicon Extraction: From parallel corpora tonon-parallel corpora," Proceedings of AMTA,1998.Garofolo, J.S., Auzanne, G.P., Voorhees, E.M.,"The TREC Spoken Document Retrieval Track:A Success Story," Proceedings of the Recherched'informations A sistre par Ordinateur: Content-Based Multimedia Information AccessConference, April 12-14, 2000,to be published.Knight, K. and J. Graehl, "MachineTransliteration," Proceedings ofACL, 1997.Landauer, T. K. and M.L.
Littman, "FullyAutomatic Cross-Language Document RetrievalUsing Latent Semantic Indexing," Proceedingsof the 6 th Annual Conference of the UW Centrefor the New Oxford English Dictionary, 1990.Leung, R., "Lexical Access for LargeVocabulary Chinese Speech Recognition," M.Phil.
Thesis, The Chinese University of HongKong, Hong Kong SAR, China 1999.Levow, G. and D.W. Oard, "Translingual TopicTracking with PRISE," Working notes of theDARPA TDT-3 Workshop, 2000.Lin, C. H., L. S. Lee, and P. Y. Ting, "A NewFramework for Recognition of MandarinSyllables with Tones using Sub-Syllabic Units,"Proceedings ofICASSP, 1993.Liu~ F. H., M. Picheny, P. Srinivasa, M.Monkowski and J. Chen, "Speech Recognitionon Mandarin Call Home: A Large-Vocabulary,Conversational, nd Telephone Speech Corpus,"Proceedings ofICASSP, 1996.McCarley, S., "Should we Translate theDocuments or the Queries in Cross-LanguageInformation Retrieval," Proceedings of ACL,1999.Meng, H. and C. W. Ip, "An Analytical Study o fTransformational Tagging of Chinese Text,"Proceedings of the Research On ComputationalLingustics (ROCLING) Conference, 1999.Meng, H., W. K. Lo, Y. C. Li and P. C. Ching,"A Study on the Use of Syllables for ChineseSpoken Document Retrieval," Technical ReportSEEM1999-11, The Chinese University of HongKong, 1999.Meng, H., Khudanpur, S., Oard, D. W. andWang, H. M., "Mandarin-English Information(MEI)," Working notes of the DARPA TDT-3Workshop, 2000.Ng, K., "Subword-based Approaches for SpokenDocument Retrieval," Ph.D. Thesis, MIT,February 2000.Oard, D. W. and A.R.
Diekema, "Cross-Language Information Retrieval," AnnualReview of Information Science and Technology,vol.33, 1998.Pirkola, A., "The effects of query structure anddictionary setups in dictionary-based cross-language information retrieval," Proceedings ofACM SIGIR, 1998.Sheridan P. and J. P. Ballerini, "Experiments inMultilingual Information Retrieval using the29SPIDER System," Proceedings of ACM SIGIR,1996.Voorhees, E., "Learning Collection FusionStrategies," Proceedings of SIGIR, 1995.Wang, H. M., "Retrieval of Mandarin SpokenDocuments Based on Syllable LatticeMatching," Proceedings of the FourthInternational Workshop on InformationRetrieval in Asian Languages, 1999.Wechsler, M. and P. Schaiible, "SpeechRetrieval Based on Automatic Indexing,"Proceedings of MIRO- 1995.English Text Queries(words)Words that are present entities and unknown wordstranslation dictionary\[ Trans'a~on I I TransliterationMand~Sn Queries (with words and syllables)Mandarin Spoken Documents \[(indexed with word and subword units)"7Information RetrievalEngineI Evaluate RetrievalPerformanceFigure 1.
Query translation strategy.Mandarin Spoken Documents(indexed with word and subword units)lTranslationDocuments inEnglishEnglish Text Queries(words)I Information RetrievalEngineEvaluateRetrievalPerformanceFigure 2.
Document translation strategy.3O
