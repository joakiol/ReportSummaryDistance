Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 59?65,Baltimore, Maryland USA, June 26?27, 2014.c?2014 Association for Computational LinguisticsParallel FDA5 for Fast Deployment of AccurateStatistical Machine Translation SystemsErgun Bic?iciCentre for Next Generation LocalisationSchool of ComputingDublin City Universityergun.bicici@computing.dcu.ieQun LiuCentre for Next Generation LocalisationSchool of ComputingDublin City Universityqliu@computing.dcu.ieAndy WayCentre for Next Generation LocalisationSchool of ComputingDublin City Universityaway@computing.dcu.ieAbstractWe use parallel FDA5, an efficiently pa-rameterized and optimized parallel im-plementation of feature decay algorithmsfor fast deployment of accurate statisticalmachine translation systems, taking onlyabout half a day for each translation di-rection.
We build Parallel FDA5 MosesSMT systems for all language pairs inthe WMT14 translation task and obtainSMT performance close to the top Mosessystems with an average of 3.49 BLEUpoints difference using significantly lessresources for training and development.1 IntroductionParallel FDA5 is developed for fast deploymentof accurate statistical machine translation systemsusing an efficiently parameterized and optimizedparallel implementation of feature decay algo-rithms (Bic?ici and Yuret, 2014).
Parallel FDA5takes about half a day for each translation direc-tion.
We achieve SMT performance that is on parwith the top constrained Moses SMT systems.Statistical machine translation (SMT) is a dataintensive problem.
If you have the translations forthe source sentences you are translating in yourtraining set or even portions of it, then the trans-lation task becomes easier.
If some tokens are notfound in the training data then you cannot trans-late them and if some translated word do not ap-pear in your language model (LM) corpus, then itbecomes harder for the SMT engine to find its cor-rect position in the translation.
The importance ofparallel FDA5 increases with the proliferation oftraining material available for building SMT sys-tems.
Table 2 presents the statistics of the avail-able training and LM corpora for the constrained(C) systems as well as the statistics of the ParallelFDA5 selected training and LM corpora.Parallel FDA5 runs separate FDA5 models onrandomized subsets of the training data and com-bines the selections afterwards.
We run parallelFDA5 SMT experiments using Moses (Koehn etal., 2007) in all language pairs in WMT14 (Bojaret al., 2014) and obtain SMT performance close tothe top constrained Moses systems training usingall of the training material.
Parallel FDA5 allowsrapid prototyping of SMT systems for a given tar-get domain or task and can be very useful for MTin target domains with limited resources or in dis-aster and crisis situations (Lewis et al., 2011).2 Parallel FDA5 for Instance Selection2.1 FDA5FDA is developed mainly for building high per-formance SMT systems using fewer yet relevantdata that is selected for increasing the coverage ofthe test set features while maximizing their diver-sity (Bic?ici and Yuret, 2011; Bic?ici, 2011).
Par-allel FDA parallelize instance selection and sig-nificantly reduces the time to deploy accurate MTsystems in the presence of large training data fromweeks to half a day and still achieve state-of-the-art SMT performance (Bic?ici, 2013).
FDA5is developed for efficient parameterization, opti-mization, and implementation of FDA (Bic?ici andYuret, 2014).
FDA5 can be used in both trans-ductive learning scenarios where test set is used toselect the training data or in active learning sce-narios where training set itself is used to obtain asorting of the training data and select.We run transductive learning experiments inthis work such that the instance selection is per-formed for the given test set.
According toSMT experiments performed on the 2 million sen-tence English-German section of the Europarl cor-pus (Bic?ici and Yuret, 2014), FDA5 can increasethe performance by 0.41 BLEU points comparedto using all of the available training data and by59Algorithm 1: Parallel FDA5Input: Parallel training sentences U , test setfeatures F , and desired number oftraining instances N .Output: Subset of the parallel sentences to beused as the training data L ?
U .1 U ?
shuffle(U)2 U ,M ?
split(U , N)3 L?
{}4 foreach Ui?
U do5 ?Li, si?
?
FDA5(Ui,F ,M)6 L?
L ?
?Li, si?7 L ?
merge(L)3.22 BLEU points compared to random selection.FDA5 is also used for selecting the training setin the WMT14 medical translation task (Calixtoet al., 2014) and the tuning set in the WMT14German-English translation task (Li et al., 2014).FDA5 has 5 parameters that effect the instancescores based on the three formulas used:?
Initialization:init(f) = log(|U|/CU(f))i|f |l(1)?
Decay:decay(f) = init(f)(1+CL(f))?cdCL(f)(2)?
Sentence score:sentScore(S) =1|S|s?f?F (S)fvalue(f)(3)CL(f) returns the count of feature f in L. dis the feature score polynomial decay factor, c isthe feature score exponential decay factor, s isthe sentence score length exponent, i is the initialfeature score idf exponent, and l is the initialfeature score n-gram length exponent.
FDA5 isavailable at http://github.com/bicici/FDAand the FDA5 optimizer is available athttp://github.com/bicici/FDAOptimization.2.2 Parallel FDA5Parallel FDA5 (ParFDA5) is presented in Algo-rithm 1, which first shuffles the training sentences,U and runs individual FDA5 models on the multi-ple splits from which equal number of sentences,M , are selected.
We use ParFDA5 for select-ing parallel training data and LM data for build-ing SMT systems.
merge combines k sorted ar-rays, Li, into one sorted array in O(Mk log k) us-ing their scores, si, where Mk is the total numberof elements in all of the input arrays.1ParFDA5makes FDA5 more scalable to domains with largetraining corpora and allows rapid deployment ofSMT systems.
By selecting from random splits ofthe original corpus, we work with different n-gramfeature distributions in each split and prevent fea-ture values from becoming negligible, which canenhance the diversity.2.3 Language Model Data SelectionWe select the LM training data with ParFDA5based on the following observation (Bic?ici, 2013):No word not appearing in the trainingset can appear in the translation.It is impossible for an SMT system to translate aword unseen in the training corpus nor can it trans-late it with a word not found in the target side ofthe training set2.
Thus we are only interestedin correctly ordering the words appearing in thetraining corpus and collecting the sentences thatcontain them for building the LM.
At the sametime, a compact and more relevant LM corpus isalso useful for modeling longer range dependen-cies with higher order n-gram models.
We use1-gram features for LM corpus selection since wedon?t know which phrases will be generated by thetranslation model.
After the LM corpus selection,the target side of the parallel training data is addedto the LM corpus.3 ResultsWe run ParFDA5 SMT experiments for all lan-guage pairs in both directions in the WMT14translation task (Bojar et al., 2014), which includeEnglish-Czech (en-cs), English-German (en-de),English-French (en-fr), English-Hindi (en-hi), andEnglish-Russian (en-ru).
We true-case all of thecorpora, use 150-best lists during tuning, set theLM order to a value between 7 and 10 for all lan-guage pairs, and train the LM using SRILM (Stol-cke, 2002).
We set the maximum sentence lengthfilter to 126 and for GIZA++ (Och and Ney, 2003),1(Cormen et al., 2009), question 6.5-9.
Merging k sortedlists into one sorted list using a min-heap for k-way merging.2Unless the translation is a verbatim copy of the source.60S ?
TTraining Data LM DataData #word S (M) #word T (M) #sent (K) SCOV TCOV #word (M) TCOVen-cs C 253.5 223.4 16068 0.8282 0.7046 717.0 0.8539en-cs ParFDA5 22.0 19.6 1205 0.8161 0.6062 325.8 0.8238cs-en C 223.4 253.5 16068 0.7046 0.8282 5541.9 0.9552cs-en ParFDA5 19.3 22.0 1205 0.7046 0.7581 351.0 0.9132en-de C 116.0 109.5 4511 0.812 0.7101 1573.8 0.8921en-de ParFDA5 16.7 16.8 845 0.8033 0.6316 206.9 0.8184de-en C 109.5 116.0 4511 0.7101 0.812 5446.8 0.9525de-en ParFDA5 17.8 19.6 845 0.7087 0.753 339.5 0.9082en-fr C 1096.1 1287.8 40344 0.8885 0.9163 2534.5 0.9611en-fr ParFDA5 22.6 26.6 1008 0.8735 0.8412 737.4 0.9491fr-en C 1287.8 1096.1 40344 0.9163 0.8885 6255.8 0.9675fr-en ParFDA5 20.9 19.3 1008 0.8963 0.7845 463.4 0.9282en-hi C 3.4 5.0 306 0.5467 0.5986 36.3 0.7972en-hi ParFDA5 3.3 4.9 254 0.5467 0.5976 41.2 0.8115hi-en C 5.0 3.4 306 0.5986 0.5467 5350.4 0.9473hi-en ParFDA5 5.0 3.3 284 0.5985 0.5466 966.8 0.9209en-ru C 49.6 46.1 2531 0.7992 0.6823 590.8 0.8679en-ru ParFDA5 19.6 18.6 1107 0.7991 0.6388 282.1 0.8447ru-en C 46.1 49.6 2531 0.6823 0.7992 5380.6 0.9567ru-en ParFDA5 16.6 19.4 1107 0.6821 0.7586 225.1 0.9009Table 2: The data statistics for the available training and LM corpora for the constrained (C) submissionscompared with the ParFDA5 selected training and LM corpora statistics.
#words is in millions (M) and#sents is in thousands (K).S ?
T d c s i lTraining,n=2en-de 1.0 0.5817 1.4176 5.0001 -3.154de-en 1.0 1.0924 1.3604 5.0001 -4.341en-cs 1.0 0.0676 0.8299 5.0001 -0.8788cs-en 1.0 1.5063 0.7777 3.223 -2.3824en-ru 1.0 0.6519 1.6877 5.0001 -1.1888ru-en 1.0 1.607 3.0001 0.0 -1.8247en-hi 1.0 3.0001 3.0001 1.5701 -1.5699hi-en 1.0 0.0 1.1001 5.0001 -0.8264en-fr 1.0 0.8143 0.801 3.5996 -1.3394fr-en 1.0 0.19 1.0106 5.0001 1.238LM,n=1en-de 1.0 0.1924 1.0487 5.0001 4.9404de-en 1.0 1.7877 3.0001 3.1213 -0.4147en-cs 1.0 0.4988 1.1586 5.0001 -5.0001cs-en 0.9255 0.2787 0.7439 3.7264 -2.0564en-ru 1.0 1.4419 2.239 1.5543 -0.5097ru-en 1.0 2.4844 3.0001 4.6669 3.7978en-hi 1.0 0.0 0.0 5.0001 -4.944hi-en 1.0 0.3053 3.0001 5.0001 4.1216en-fr 1.0 3.0001 2.0452 3.0229 3.4364fr-en 1.0 0.7467 0.7641 5.0001 5.0001Table 1: Optimized ParFDA5 parameters for se-lecting the training set using 2-grams or the LMcorpus using 1-grams.max-fertility is set to 10, with the number of itera-tions set to 7,3,5,5,7 for IBM models 1,2,3,4, andthe HMM model and 70 word classes are learnedover 3 iterations with the mkcls tool during train-ing.
The development set contains 5000 sentences,2000 of which are randomly sampled from pre-vious years?
development sets (2008-2012) and3000 come from the development set for WMT14.3.1 Optimized ParFDA5 ParametersTable 1 presents the optimized ParFDA5 parame-ters obtained using the development set.
Transla-tion direction specific differences are visible.
Anegative value for l shows that FDA5 prefersshorter features, which we observe mainly whenthe target language is English.
We also observehigher exponential decay rates when the target lan-guage is mainly English.
For optimizing the pa-rameters for selecting LM corpus instances, westill use a parallel corpus and instead of optimiz-ing for TCOV, we optimize for SCOV such thatwe select instances that are relevant for the targettraining corpus but still maximize the coverage ofsource features and be able to represent the sourcesentences within a translation task.
The selectedLM corpus is prepared for a translation task.3.2 Data SelectionWe select the same number of sentences with Par-allel FDA (Bic?ici, 2013), which is roughly 15%of the training corpus for en-de, 35% for ru-en,6% for cs-en, and 2% for en-fr.
After the trainingset selection, we select the LM data using the tar-get side of the training set as the target domain toselect LM instances for.
For en and fr, we haveaccess to the LDC Gigaword corpora (Parker etal., 2011; Graff et al., 2011), from which we ex-tract only the story type news.
We select 15 mil-lion sentences for each LM not including the se-61S ?
TTime (Min) Space (MB)ParFDA5 MosesOverallMosesTrain LM Total Train Tune Total PT LM ALLen-cs 5 28 34 375 702 1162 1196 1871 5865 19746cs-en 7 65 72 358 448 867 939 1808 4906 18650en-de 8 29 38 302 1059 1459 1497 1676 2923 18313de-en 8 85 93 358 474 924 1017 1854 5219 19247en-fr 23 60 84 488 781 1372 1456 2309 9577 24362fr-en 21 99 120 315 490 897 1017 1845 4888 17466en-hi 2 9 11 91 366 511 522 269 817 4292hi-en 1 36 37 91 330 467 504 285 9697 3845en-ru 11 25 35 358 369 837 872 2174 4770 21283ru-en 10 62 71 309 510 895 966 1939 2735 19537Table 3: The space and time required for building the ParFDA5 Moses SMT systems.
The sizes are inMB and time in minutes.
PT stands for the phrase table.
ALL does not contain the size of the LM.BLEUcS ?
en en?
Tcs-en de-en fr-en hi-en ru-en en-cs en-de en-fr en-hi en-ruWMT14C 0.288 0.28 0.35 0.139 0.318 0.21 0.201 0.358 0.111 0.287ParFDA5 0.256 0.239 0.319 0.105 0.282 0.172 0.168 0.325 0.07 0.257diff 0.032 0.041 0.031 0.034 0.036 0.038 0.033 0.033 0.041 0.03LM order 9 9 9 9 9 9 9 7 10 9Table 4: BLEUc for the top constrained result in WMT14 (WMT14C) and for ParFDA5 results, theirdifference to WMT14C, and the LM order used are presented.
Average difference is 3.49 BLEU points.lected training set, which is added later.
The statis-tics of the ParFDA5 selected training data and theavailable training data for the constrained transla-tion task is given in Table 2.
The size of the LMcorpora includes both the LDC and the monolin-gual LM corpora provided by WMT14.
Table 2shows the significant size differences between theconstrained dataset (C) and the ParFDA5 selecteddata.
Table 2 also present the source and targetcoverage (SCOV and TCOV) in terms of the 2-grams of the test set observed in the training dataor the LM data.
The quality of the training cor-pus can be measured by TCOV, which is found tocorrelate well with the BLEU performance achiev-able (Bic?ici and Yuret, 2011; Bic?ici, 2011).3.3 Computing StatisticsWe quantify the time and space requirements forrunning ParFDA5 SMT systems for each trans-lation direction.
The space and time requiredfor building the ParFDA5 Moses SMT systemsare given in Table 3 where the sizes are in MBand the time in minutes.
PT stands for thephrase table.
We used Moses version 2.1.1, fromwww.statmt.org/moses.
Building a ParFDA5Moses SMT system takes about half a day.3.4 Translation ResultsThe results of our two ParFDA5 SMT experimentsfor each language pair and their tokenized BLEUperformance, BLEUc, together with the LM orderused and the top constrained submissions to theWMT14 are given in Table 43, which use phrase-based Moses for comparison4.
We observed sig-nificant gains (+0.23 BLEU points) using higherorder LMs last year (Bic?ici, 2013) and thereforewe use LMs of order 7 to 10.
The test set con-tains 10,000 sentences and only 3000 of which areused for evaluation, which can make the transduc-tive learning application of ParFDA5 harder.
Inthe transductive learning setting, ParFDA5 is se-lecting target test task specific SMT resources andtherefore, having irrelevant instances in the test setmay decrease the performance by causing FDA5to select more domain specific data and less taskspecific.
ParFDA5 significantly reduces the timerequired for training, development, and deploy-ment of an SMT system for a given translation3We use the results from matrix.statmt.org.4Phrase-based Moses systems usually rank in the top 3.62pplOOV log OOV = ?19 log OOV = ?11Translation T order train FDA5 FDA5 LM % red.
train FDA5 FDA5 LM % red.
train FDA5 FDA5 LM % red.en-cs en3866 1205 525 0.391764 1731 938 0.47 1370 1218 805 0.414 1788 1746 877 0.51 1389 1229 753 0.465 1799 1752 868 0.52 1398 1233 745 0.476 1802 1753 867 0.52 1400 1234 744 0.47cs-en cs3557 706 276 0.5480 419 333 0.31 408 342 307 0.254 487 422 292 0.4 415 344 269 0.355 495 424 285 0.42 421 346 263 0.386 497 425 284 0.43 423 346 262 0.38en-de en31666 2116 744 0.551323 1605 747 0.44 831 890 607 0.274 1307 1596 689 0.47 821 885 560 0.325 1307 1596 680 0.48 822 885 553 0.336 1308 1596 679 0.48 822 885 552 0.33de-en de3691 849 417 0.4482 498 394 0.18 386 379 345 0.114 470 490 344 0.27 376 373 301 0.25 470 490 336 0.29 377 373 293 0.226 471 490 334 0.29 377 373 292 0.23en-fr en3270 411 153 0.43185 167 173 0.07 173 151 166 0.044 170 160 135 0.21 159 144 130 0.195 171 160 126 0.27 160 145 121 0.24fr-en fr3306 604 179 0.42349 325 275 0.21 320 275 261 0.194 338 321 235 0.3 310 271 224 0.285 342 322 228 0.33 314 272 217 0.31en-hi en32035 2123 950 0.53242 246 114 0.53 168 168 96 0.434 237 241 87 0.63 164 165 73 0.555 238 242 78 0.67 165 165 66 0.66 239 242 75 0.68 165 165 64 0.62hi-en hi31842 1860 623 0.661894 1898 482 0.75 915 911 377 0.594 1910 1914 398 0.79 923 919 312 0.665 1915 1919 378 0.8 925 921 296 0.686 1915 1919 378 0.8 926 921 296 0.68en-ru en3959 1176 585 0.391067 1171 668 0.37 814 840 566 0.34 1053 1159 603 0.43 803 831 511 0.365 1052 1159 591 0.44 802 831 501 0.386 1052 1159 588 0.44 802 831 498 0.38ru-en ru3558 689 340 0.39385 398 363 0.06 334 334 333 0.04 377 391 325 0.14 327 328 298 0.095 378 392 318 0.16 328 329 292 0.116 378 392 318 0.16 328 329 291 0.11Table 5: Perplexity comparison of the LM built from the training corpus (train), ParFDA5 selectedtraining corpus (FDA5), and the ParFDA5 selected LM corpus (FDA5 LM).
% red.
column lists thepercentage of reduction.task.
The average difference to the top constrainedsubmission in WMT14 is 3.49 BLEU points.
Foren-ru and en-cs, true-casing the LM using a true-caser trained on all of the available training datadecreased the performance by 0.5 and 0.9 BLEUpoints respectively and for cs-en and fr-en, in-creased the performance by 0.2 and 0.5 BLEUpoints.
We use the true-cased LM results usinga true-caser trained on all of the available train-ing data for all language pairs where for hi-en,the true-caser is trained on the ParFDA5 selectedtraining data.3.5 LM Data QualityA LM training data selected for a given transla-tion task allows us to train higher order languagemodels, model longer range dependencies better,and at the same time, achieve lower perplexityas given in Table 5.
We compare the perplexityof the ParFDA5 selected LM with a LM trainedon the ParFDA5 selected training data and a LMtrained using all of the available training corpora.To be able to compare the perplexities, we takethe OOV tokens into consideration during calcu-lations (Bic?ici, 2013).
We present results for thecases when we handle OOV words with a costof ?19 or ?11 each in Table 5.
We are able toachieve significant reductions in the number ofOOV tokens and the perplexity, reaching up to66% reduction in the number of OOV tokens andup to 80% reduction in the perplexity.63BLEUcS ?
en en?
Tcs-en de-en fr-en ru-en en-cs en-de en-fr en-ruParFDA5 0.256 0.239 0.319 0.282 0.172 0.168 0.325 0.257ParFDA 0.243 0.241 0.254 0.223 0.171 0.179 0.238 0.173diff 0.013 -0.002 0.065 0.059 0.001 -0.011 0.087 0.084Table 7: Parallel FDA5 WMT14 results compared with parallel FDA WMT13 results.
Training set sizesare given in millions (M) of words on the target side.
Average difference is 3.7 BLEU points.BLEUcS ?
en en?
Tcs-en fr-en en-cs en-frParFDA5 0.256 0.319 0.172 0.325ParFDA5 15% 0.248 0.321 0.178 0.333diff -0.008 0.002 0.006 0.008Table 6: ParFDA5 results, ParFDA5 results using15% of the training set, and their difference.3.6 Using 15% of the Available Training SetIn the FDA5 results (Bic?ici and Yuret, 2014),we found that selecting 15% of the best train-ing set size maximizes the performance for theEnglish-German out-of-domain translation taskand achieves 0.41 BLEU points improvement overa baseline system using all of the available train-ing data.
We run additional experiments select-ing 15% of the training data for fr-en and cs-enlanguage pairs to see the effect of increased train-ing sets selected with ParFDA5.
The results aregiven in Table 6 where most of the results improve.The slight performance decrease for cs-en may bedue to using a true-caser trained on only the se-lected training data.
We observe larger gains inthe en?
T translations.3.7 ParFDA5 versus Parallel FDAWe compare this year?s results with the resultswe obtained last year (Bic?ici, 2013) in Table 7.The task setting is different in WMT14 since thetest set contains 10,000 sentences but only 3000of these are used as the actual test set, whichcan make the transductive learning application ofParFDA5 harder.
We select the same number ofinstances for the training sets but 5 million moreinstances for the LM corpus this year.
The aver-age difference to the top constrained submissionin WMT13 was 2.88 BLEU points (Bic?ici, 2013)and this has increased to 3.49 BLEU points inWMT14.
On average, the performance improved3.7 BLEU points when compared with ParFDA re-sults last year.
For the fr-en, en-fr, and en-ru trans-lation directions, we observe increases in the per-formance.
This may be due to better modeling ofthe target domain by better parameterization andoptimization that FDA5 is providing.
We observesome decrease in the performance in en-de and de-en results.
Since the training material remainedthe same for WMT13 and WMT14 and the mod-eling power of FDA5 increased, building a domainspecific rather than a task specific ParFDA5 modelmay be the reason for the decrease.4 ConclusionWe use parallel FDA5 for solving computationalscalability problems caused by the abundance oftraining data for SMT models and LMs and stillachieve SMT performance that is on par withthe top performing SMT systems.
Parallel FDA5raises the bar of expectations from SMT withhighly accurate translations and lower the bar toentry for SMT into new domains and tasks by al-lowing fast deployment of SMT systems in abouthalf a day.
Parallel FDA5 enables a shift from gen-eral purpose SMT systems towards task adaptiveSMT solutions.AcknowledgmentsThis work is supported in part by SFI(07/CE/I1142) as part of the CNGL Centrefor Global Intelligent Content (www.cngl.org)at Dublin City University and in part by theEuropean Commission through the QTLaunchPadFP7 project (No: 296347).
We also thank theSFI/HEA Irish Centre for High-End Computing(ICHEC) for the provision of computationalfacilities and support.ReferencesErgun Bic?ici and Deniz Yuret.
2011.
Instance selec-tion for machine translation using feature decay al-gorithms.
In Proceedings of the Sixth Workshop onStatistical Machine Translation, pages 272?283, Ed-64inburgh, Scotland, July.
Association for Computa-tional Linguistics.Ergun Bic?ici and Deniz Yuret.
2014.
Optimizing in-stance selection for statistical machine translationwith feature decay algorithms.
IEEE/ACM Transac-tions On Audio, Speech, and Language Processing(TASLP).Ergun Bic?ici.
2011.
The Regression Model of MachineTranslation.
Ph.D. thesis, Koc?
University.
Supervi-sor: Deniz Yuret.Ergun Bic?ici.
2013.
Feature decay algorithms for fastdeployment of accurate statistical machine transla-tion systems.
In Proceedings of the Eighth Work-shop on Statistical Machine Translation, Sofia, Bul-garia, August.
Association for Computational Lin-guistics.Ond?rej Bojar, Christian Buck, Christian Federmann,Barry Haddow, Philipp Koehn, Matou?s Mach?a?cek,Christof Monz, Pavel Pecina, Matt Post, HerveSaint-Amand, Radu Soricut, and Lucia Specia.2014.
Findings of the 2014 workshop on statisti-cal machine translation.
In Proc.
of the Ninth Work-shop on Statistical Machine Translation, Balrimore,USA, June.
Association for Computational Linguis-tics.Iacer Calixto, Ali Hosseinzadeh Vahid, Xiaojun Zhang,Jian Zhang, Xiaofeng Wu, Andy Way, and Qun Liu.2014.
Experiments in medical translation sharedtask at wmt 2014.
In Proceedings of the Ninth Work-shop on Statistical Machine Translation, Baltimore,USA, June.
Association for Computational Linguis-tics.Thomas H. Cormen, Charles E. Leiserson, Ronald L.Rivest, and Clifford Stein.
2009.
Introduction toAlgorithms (3.
ed.).
MIT Press.David Graff,?Angelo Mendonc?a, and Denise DiPersio.2011.
French Gigaword third edition, LinguisticData Consortium.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: Opensource toolkit for statistical machine translation.
InACL, pages 177?180, Prague, Czech Republic, June.William Lewis, Robert Munro, and Stephan Vogel.2011.
Crisis mt: Developing a cookbook for mtin crisis situations.
In Proceedings of the SixthWorkshop on Statistical Machine Translation, pages501?511, Edinburgh, Scotland, July.
Association forComputational Linguistics.Liangyou Li, Xiaofeng Wu, Santiago Cortes Vaillo,Jun Xie, Jia Xu, Andy Way, and Qun Liu.
2014.The dcu-ictcas-tsinghua mt system at wmt 2014 ongerman-english translation task.
In Proceedings ofthe Ninth Workshop on Statistical Machine Transla-tion, Baltimore, USA, June.
Association for Compu-tational Linguistics.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.Robert Parker, David Graff, Junbo Kong, Ke Chen, andKazuaki Maeda.
2011.
English Gigaword fifth edi-tion, Linguistic Data Consortium.Andreas Stolcke.
2002.
Srilm - an extensible languagemodeling toolkit.
In Proc.
Intl.
Conf.
on SpokenLanguage Processing, pages 901?904.65
