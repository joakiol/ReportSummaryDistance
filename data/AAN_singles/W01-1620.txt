A hybrid approach to the development of dialogue systemsdirected by semanticsEmilio Sanchis, Isabel Galiano, Fernando Garca, Antonio CanoDepartamento de Sistemas Informaticos y ComputacionUniversidad Politecnica de ValenciaCamino de Vera s/n, 46020-Valencia, SPAINesanchis,mgaliano,fgarcia,acano@dsic.upv.esAbstractIn this work we present an approachto the development of the BA-SURDE1dialogue system, which an-swers telephone queries about rail-way timetables in Spanish.
We willfocus on the understanding and di-alogue components which are mod-eled under a stochastic framework.The preliminary results from seman-tic and dialogue interpretations ofuser dialogue turns are also includedin this work.1 IntroductionIn the development of dialogue systems manyknowledge sources must be taken into ac-count.
The specic characteristics of eachknowledge source imply that dierent kindsof models and dierent architectures can beused.
It is widely accepted that stochasticmodels are a good representation for someof these knowledge sources and some spe-cic works have been done to represent thesemantic of the sentences and the dialoguestructure (Pieraccini et al, 1997)(Baggia etal., 1999)(Lamel et al, 2000)(Martinez et al,2000)(Segarra et al, 2001).We present an approach in which the dia-logue structure is represented by a stochasticnetwork of dialogue acts.
One advantage ofthis kind of network is that it can be learntfrom annotated training samples.
Moreover,it gives us a prediction of the next dialogueacts which are expected from the user as well1Work partially funded by CICYT under projectTIC98-0423-C06as some information about the possible dia-logue acts that can be generated by the sys-tem.
The identication of the user dialogueacts is done through the semantic represen-tation of the sentence.
This semantic inter-pretation not only supplies the correspondingdialogue act but also supplies the informa-tion given about the query constraints, suchus Date, Departure city, etc.To be able to provide the information re-quested by the user, the system has to man-age the values supplied by the user during theconversation.
We do this by means of a recordof current values that is updated after eachuser turn and is used to generate the databasequeries and to participate in the generation ofthe dialogue turns of the system.2 The Dialogue moduleThe dialogue model proposed is a stochasticnetwork which is automatically learnt froma training set of dialogue samples obtainedby the Wizard of Oz technique (Figure 1).A dialogue sample is a concatenation of di-alogue acts which represents the translationof a given user utterance into a sentence of adialogue act language.One important decision is the denition ofthe set of dialogue acts associated to the ap-plication.
If we establish a low number ofdialogue acts that are independent from thetask, we can expect a good modelization ofthe dialogue structure and an easy identica-tion of the dialogue acts which are generatedby the user; we could also change the applica-tion without having to make many changes inthe dialogue model.
However, in order for thesystem to generate its dialogue turn, more in-U:Closing:NilM:Closing:NilU:Opening:NilDataBase QueryDataBase AnswerDataBaseGENERATIONANSWERArrival_city:Barcelona...Departure_city:ValenciaDate: 23/06/2001M:Opening:NilM:Answer:Departure_timeU:Question:Departure_time(Departure_time)M:New_question:NilRecord _of_Current_ValuesFigure 1: An example of a part of the Dialogue model.formation about the content of the sentencesis required.If we increase the number of dialogue actsso that each dialogue act has a more specicmeaning, then the variability of decisions (oractions) associated to each state in the net-work is reduced.
In other words, a dialogueact will have a very specic intention, butwe will need a huge number of labeled dia-logues to learn the model.
For example, ifthe act is Question there are many kinds ofquestions associated to it, but if the act isQuestion:Departure time it only represents aquestion about the departure time.Since a balance between the number of la-bels and the model structure is needed, withinthe BASURDE project we have dened a setof three-level dialogue acts.
This set repre-sents not only information about a general di-alogue behaviour but also information aboutthe task (Martinez et al, 2000).The rst level of each dialogue act labelsthe dialogue behaviour.
The labels we deneat this level are generic for any task.
The sec-ond level is related to the semantic represen-tation of a sentence and it is specic to thetask.
In the Dialogue model presented hereonly the rst two levels are considered.The following labels have been de-ned for the rst level: Opening, Clos-ing, Undened, Not understood, Waiting,A?rmation, Rejection, Question, Con-rmation, Answer.
The labels denedfor the second level are: Departure time,Return departure time, Arrival time, Re-turn arrival time, Price, Departure city,Arrival city, Lenght of trip, Stops, Depar-ture date, Arrival date, Train type, Services.For example, a dialogue turn can be labeledas follows:Me puede decir el horario de los trenes a Valenciael proximo lunes ?
(Can you tell me the timetable to Valencia fornext Monday ?
)(Question: Departure time)The stochastic network representing the Di-alogue model is obtained from a training setof dialogues which are labeled in terms of dia-logue act sequences.
This network is built byusing the bigram probabilities.The dialogue act network can be used intwo ways:- To predict the next dialogue act of theuser; helping the recognition and understand-ing processes.- To decide the next action of the system.As there are not enough samples to learn anaccurate model this decision making processshould be driven by the semantics.Now we will describe how the dialoguemanager works.
It has two main compo-nents: the dialogue network and the recordof current values.
The input of this mod-ule is supplied by the Understanding module.This input is a frame representation of thesemantic information obtained from the userturn.
We can extract the corresponding di-alogue act from each input frame as well asthe constraints about the query given by theuser.
The Dialogue Manager uses this infor-mation in two ways: it determines the next di-alogue transition to be made and updates therecord of current values using the constraintsobtained from the query.The Dialogue Manager output, which isalso a frame representation, is sent to the an-swer generator and then to the synthesizer.The dynamics of this process is given by thefollowing Dialogue Manager algorithm:/*Initialization*/Put State=OpeningInit(Record of Current Values) /*Init(RCV)*/RepeatSentence=obtain sentence from the user turnFrame=extract meaning(Sentence)State=Transition to(State,Frame)RCV=Update(Frame)/* actions of the manager */if complete query(RCV)thenSend Database queryState=Choose transitionelseselect transitions permitted by RCVState=Choose one of these selected transitionsGenerate output frameuntil State=ClosingThe dialogue manager accepts the framesobtained from the user turn as input.
Firstit modies the record of current values if nec-essary.
If there is enough information in thisrecord, a query to the database is made, anoutput frame with the answer is generated,and a transition in the dialogue network ismade.
Otherwise the record of current valuesis used to determine which transitions of thedialogue network should be pruned, i.e.
thosethat are not compatible with the updated in-formation.
This situation occurs because themodel is learnt from a limited set of samplesand it is a bigram model with just one labelhistory, and then the constraints given in pre-vious turns can not be taken into account.For example, one of the transitions of thenetwork might imply asking the user aboutthe departure city and this information hasalready been given in a previous turn.
Inthis case the corresponding transition wouldbe forbidden.
After the set of allowed tran-sitions is determined, one of them is selectedand the corresponding output frame is gener-ated.
The process nish when a Closing labelis found.3 The Understanding moduleWe use frames to represent the meaning ofsentences.
Each frame represents a conceptand can have some attributes associated toit.
We have dened 18 types of frames; someof them are related to the task (for exampleDeparture time, Price, etc.
), and others arerelated to the general characteristics of thedialogues (for example, Not understood, Af-rmation, etc.).
Note that each type of framehas a corresponding dialogue act associatedto it.We use a two phases approach for the un-derstanding process (Figure 2).
In the rstphase a sequence of semantic units and itscorresponding segmentation is obtained froman input sentence.
In the second phase one ormore frames are extracted from this semanticsentence.The rst phase is implemented from astochastic transduction point of view (Segarraet al, 2001); that is, the input sentence (inwords) is translated into an output sentenceof a semantic language.
The vocabulary ofthis semantic language is composed by a setof semantic units, that represents meanings ofsegments of words.The segmentation of these sentences allowsus to dene two kind of stochastic models:the Semantic model and the Semantic-Unitmodel.
The Semantic model represents theallowed sequences of semantic units and theirprobabilities.
The Semantic-Unit model rep-resents the allowed sequences of words andtheir probabilities which are associated toeach semantic unit.These models can be automatically learntfrom a set of annotated training samples.
Inthis work, we have used bigram models, butany other type of stochastic model, like n-grams or automata learnt by GrammaticalInference techniques (Segarra et al, 2001),could be used.
These models can be inte-grated into a unique understanding model;each semantic unit of the Semantic modelORTOGRAPHIC/DECODINGSEMANTICGENERATIONFRAMEINPUT SENTENCE SECUENCE OF PAIRSSEGMENT/SEMANTIC UNIT FRAMEthe timetable:<Departure_time>Can you tell me:Queryto:Destination_markerDestination_city: ValenciaDeparture_date: 14/05/2001(Departure_time)Can you tell me the timetableto Valencia for next Monday ?Valencia:Destination_cityfor next Monday:Departure_dateFigure 2: Transduction approach in two phases.is substituted by its corresponding Semantic-Unit model.As we already have the Dialogue model ofthe system, we can obtain a specic Semanticmodel for each user dialogue act.
However,the use of specic models can lead to a lackof training samples and therefore to the useof tied models.
In our case, we have denedonly specic models for the rst level of ourset of dialogue labels.A Viterbi decoding algorithm supplies themost likely sequence of semantic units for theinput sentence and its corresponding segmen-tation.
As the output of the Understandingmodule is a frame, a set of rules is applied toobtain the corresponding frame.
These rulespermit us to leave behind semantic units suchas courtesy, markers, etc., and select only thesemantic units that have a corresponding slotassociated to the frame.4 Experimental ResultsIn this section we report the preliminary re-sults from semantic and dialogue interpreta-tions of user dialogue turns.We dened a training set of 175 dialogueswith 1,141 user utterances and a test set of40 dialogues with 268 user utterances fromthe orthographic transcription of a set of 215dialogues, obtained through a Wizard of Oztechnique.
The number of words in these twosets was 11,987 and the medium length ofthe utterances was 10.5 words.
The percent-age of correctly understood sentences (correctframes) was 80%, and the percentage of cor-rect user dialogue act identication was 87%.5 ConclusionsWe have presented an approach for the devel-opment of dialogue systems based on stochas-tic models which are automatically learntfrom training samples.
We have proposed asystem architecture which includes an Under-standing module that extracts the semanticsof the user turns in terms of frames.
A prelim-inary implementation of the system has beendone, and preliminary results are reported.We hope that the behaviour of the systemimproves when we have more dialogue train-ing samples.
We will model other dialoguesituations which were not encountered in ourcurrent training corpus.ReferencesBaggia P., Kelner A., Perennou E., Popovici C.,Strum J., Wessel F. 1999.
Language Model-ing and Spoken Dialogue Systems the ARISEexperience.
Eurospeech99, pp.
1767{1770.Bonafonte A., Castell N., LLeida E., Mari~no J.B.,Sanchis E., Torres M.I., Aibar P. 2000.
Desar-rollo de un sistema de dialogo oral en domin-ios restringidos.
I Jornadas en Tecnologa delHabla, Sevilla.Lamel L., Rosset S., Gauvain J.L., Bennacef S.,Garnier-Rizet M., Prouts B.
2000.
The LIMSIArise system.
Speech Communication,31, pp.339{353.Martinez C., and Casacuberta F. 2000.
A patternrecognition approach to dialog labelling usingnite- state transducers.
V Iberoamerican Sym-posium on Pattern Recognition, pp.
669{677.Pieraccini R, Levin E., and Eckert W. 1997.AMICA: the AT&T Mixed Initiative Conver-sational Architecture.
Eurospeech97, pp.
1875{1878.Segarra E., Sanchis E., Galiano M., Garca F.,Hurtado L.F. 2001.
Extracting semantic infor-mation through automatic learning techniques.IX Spanish Symposium on Pattern Recognitionand Image Analysis (AERFAI), Castellon.
