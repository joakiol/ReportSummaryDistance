A Computat ional  Semantics for Natura l  LanguageLewis  G.  Creary  and  Car l  J .
Po l la rdHewlet t -Packard  Laborator ies1501 Page  Mi l l  RoadPalo Alto,  CA 94304, USAAbstractIn the new Head-driven Phrase Structure Grammar(HPSG) language processing system that is currently underdevelopment at Hewlett-Packard Laboratories, theMontagovian semantics of the earlier GPSG system (see\[Gawron et al 19821) is replaced by a radically differentapproach with a number of distinct advantages.
In placeof the lambda calculus and standard first-order logic, ourmedium of conceptual representation is a new logical for-realism called NFLT (Neo-Fregean Language of Thought);compositional semantics is effected, not by schematiclambda expressions, but by LISP procedures that operateon NFLT expressions to produce new expressions.
NFLThas a number of features that make it well-suited {'or nat-ural language translations, including predicates of variablearity in which explicitly marked situational roles supercedeorder-coded argument positions, sortally restricted quan-tification, a compositional (but nonextensional) semanticsthat handles causal contexts, and a princip\[ed conceptualraising mechanism that we expect o lead to a computation-ally tractable account of propositional attitudes.
The useof semantically compositional LiSP procedures in place oflambda-schemas llows us to produce fully reduced trans-lations on the fly, with no need for post-processing.
Thisapproach should simplify the task of using semantic infor-mation (such as sortal incompatibilities) to eliminate badparse paths.I.
IntroductionSomeone who knows a natural language is able to useutterances of certain types to give and receive informationabout the world, flow can we explain this?
We take asour point of departure the assumption that members of alanguage community share a certain mental system - -  agrammar - -  that mediates the correspondence b tween ut-terance types and other things in the world, such as individ-u~ds, relations, and states of ~ffairs, to a large degree, thissystem i~ the language.
According to the relation theoryof meaning (Barwise & Perry !1983!
), linguistic meaning isa relation between types of utterance events and other as-pects of objective reality.
We accept this view of linguisticmeaning, but unlike Barwise and Perry we focus on how themeaning relation is mediated by the intersubjective psycho-logical system of grammar.\[n our view, a computational semantics \['or a naturallanguage has three essential components:172a.
a system of conceptual representation for internal useas a computational medium in processes of informationretrieval, inference, planning, etc.b.
a system of linkages between expressions of the naturallanguage and those of the conceptual representation,andc.
a system of linkages between expressions in the concep-tual representation and objects, relations, and states ofaffairs in the external world.\[n this paper, we shall concentrate almost exclusively onthe first two components.
We shall sketch our ontologi-cal commitments, describe our internal representation lan-guage, explain how our grammar (and our computer im-plementation) makes the connection between English andthe internal representations, and finally indicate the presentstatus and future directions of our research.Our internal representation language.
NFLT.
is due toCreary 119831.
The grammatical theory in which the presentresearch is couched is the theory of head grammar (HG) setforth in \[Pollard 1984\] and \[Pollard forthcoming i and imple-mented as the front end of the HPSG (Head-driven PhraseStructure Grammar)  system, an English \[auguage databasequery system under development at Hewlett-Packard Lab-oratories.
The non-semantic aspects of the implementationare described in IFlickinger, Pollard, & Wasow t9851 and\[Proudian & Pollard 1.9851.2.
Ontological AssumptionsTo get started, we make the following assumptionsabout what categories of things are in the world.a.
There are individuals.
These include objects of theusual kind (such as Ron and Nancy) as well as situations.Situations comprise states (such as Ron's being tall) andevents (such as Ron giving his inaugural address on January21, 1985).b.
There are relations (subsuming properties).
Exam-ples are COOKIE (= the property of being a cookie) and BUY(= the relation which Nancy has to the cookies she buys).Associated with each relation is a characteristic set of rolesappropriate to that relation (such as AGENT, PATIENT, LO-CATION, etc.)
which can be filled by individuals.
Simplesituations consist of individuals playing roles in relations.Unlike properties and relations in situation semantics\[Barwise & Perry 1983\[, our relations do not have fixed ar-ity (number of arguments).
This is made possible by takingexplicit account of roles, and has important linguistic con-sequences.
Also there is no distinguished ontological cate-gory of locations~ instead, the location of an event is justthe individual that fills the LOCATION role.c.
Some relations are sortal relations, or sorts.
Associ-ated with each sort {but not with any non-sortal relation)is a criterion of identity for individuals of that sort \[Coc-chiarella 1977, Gupta 1980 I. Predicates denoting sorts oc-cur in the restrictor-clanses of quantifiers (see section 4.2below), and the associated criteria of identity are essentialto determining the truth values of quantified assertions.Two important sorts of situations are states and events.One can characterize a wide range of subsorts of these(which we shall call situation types) by specifying a par-ticular configuration of relation, individuals, and roles.
Forexample, one might consider the sort of event in which Ronkisses Nancy in the Oval Office, i.e.
in which the relation isKISS, Ron plays the AGENT role, Nancy plays the PATIENTrole, and the Oval Office plays the LOCATION role.
Onemight also consider the sort of state in which Ron is a per-son, i.e.
in which the relation is PERSON, and Ron playsthe INSTANCE role.
We assume that the INSTANCE role isappropriate only for sortal relations.d.
There are concepts, both subjective and objective.Some individuals are information-processing or anisms thatuse complex symbolic objects (subjective concepts) as com-putational media for information storage and retrieval, in-ference, planning, etc.
An example is Ron's internal rep-resentation of the property COOKIE.
This representationin turn is a token of a certain abstract type ~'COOKIE,an objective concept which is shared by the vast majorityof speakers of English.
t Note that the objective concept~COOKIE, the property COOKIE, and the extension of thatproperty (i.e.
the set ofall cookies) are three distinct hingsthat play three different roles in the semantics of the Eng-lish noun cookie.e.
There are computational processes in organisms formanipulating concepts e.g.
methods for constructing com-plex concepts from simpler ones, inferencing nmchanisms,etc.
Concepts of situations are called propositions; organ-isms use inferencing mechanisms to derive new propositionsfrom old.
To the extent that concepts are accurate repre-sentations of existing things and the relations in which theystand, organisms can contain information.
We call the sys-tem of objective concepts and concept-manipulating mech-anisms instantiated in an organism its conceptual ~ystem.Communities of organisms can share the same conceptualsystem.f.
Communities of organisms whose common concep-tual system contains a subsystem of a certain kind calleda grammar can cornnmnicate with each other.
Roughly,grammars are conceptual subsystems that mediate betweenevents of a specific type (calh:d utterances) and other as-pects of reality.
Grammars enable organisms to use utter-ances to give and receive information about the world.
Thisis the subject of sections 4-6.3.
The  In terna lRepresentation Language: NFLTThe translation of input sentences into a logical for-malism of some kind is a fairly standard feature of com-puter systems for natural-language understanding, and onewhich is shared by the HPSG system.
A distinctive featureof this system, however, is the particular logical formalisminvolved, which is called NFLT (Neo-Fregean Language ofThought).
2 This is a new logical language that is beingdeveloped to serve as the internal representation mediumin computer agents with natural anguage capabilities.
Thelanguage is the result of augmenting and partially reinter-preting the standard predicate calculus formalism in sev-eral ways, some of which will be described very briefly inthis section.
Historically, the predicate calculus was de-ve|oped by mathematical logicians as an explication of thelogic of mathematical proofs, in order to throw light onthe nature of purely mathematical concepts and knowledge.Since many basic concepts that are commonplace in natu-ral language (including concepts of belief, desire, intention,temporal change, causality, subjunctive conditionality, etc.
)play no role in pure mathematics, we should not be espe-cially surprised to find that the predicate calculus requiressupplementation in order to represent adequately and natu-rally information involving these concepts.
The belief thatsuch supplementation is needed has led to the design ofNFLT,While NFLT  is much closer semantically to natural lan-guage than is the standard predicate calculus, and is tosome extent inspired by psycho\[ogistic considerations, itis nevertheless a formal logic admitting of a mathemati-cally precise semantics.
The intended semantics incorpo-rates a Fregean distinction between sense and denotation,associated principles of compositionality, and a somewhatnon-Fregean theory of situations or situation-types as thedenotations of sentential formulas.3.1.
Predicates of Variable ArityAtomic formulas in NFLT have an explicit ro\[e-markerfor each argument; in this respect NFLT resembles seman-tic network formalisms and differs from standard predicatet We regard this notion of obiective concept as the appro-priate basis on which to reconstruct, ia terms of informa-tion processing, Saussure's notions of ~ignifiant (signifier)and #ignifig (signified) \[1916!, as well an Frege's notion ofSinn (sense, connotation) \[1892 I.~" The formalism is called ~neo-Fregean" because it in-corporates many of the semantic ideas of Gottlob Frege,though it also departs from Frege's ideas in several signif-icant ways.
It is called a "language of thought" becauseunlike English, which is first and foremost a medium ofcommunication, NFLT is designed to serve as a mediumof reasoning in computer problem-solving systems, whichwe regard for theoretical purposes as thinking organisms,(Frege referred to his own logical formalism, Begriffsschrift,an a "formula language for pure thought" \[Frege 1879, titleand p. 6 (translation)\]).17"3calculus, in which the roles are order-coded.
This explicitrepresentation of roles permits each predicate-symbol inNFLT  to take a variable number of arguments, which inturn makes it possible to represent occurrences of the sameverb with the same predicate-symbol, despite differencesin valence (i.e.
number and identity of attached comple-ments and adjuncts).
This clears up a host of problemsthat arise in theoretical frameworks (such an Montague se-mantics and situation semantics) that depend on fixed-arityrelations (see \[Carlson forthcoming\] and \[Dowry 1982\] fordiscussion).
In particular, new roles (corresponding to ad-juncts or optional complements in natural anguage) can beadded as required, and there is no need for explicit existen-tial quantification over ~missing arguments".Atomic formulas in NFLT are compounded of a base-predicate and a set of rolemark-argument pairs, as in thefollowing example:( la) English:Ron kissed Nancy  in the Oval Office on April1, 1985.
( lb) NFLT Internal Syntax:(k iss (agent  .
con)(pat ient  .
nancy)( locat ion  .
ova l -o f f i ce )(t ime .
4- i -85)  )(lc) NFLT Display Syntax:( K ISS  agt: RONp~:nt:  NANCYloc :  OVAL-OFFICEart: 4-i -8S)The base-predicate 'KISS' takes a variable number of argu-ments, depending on the needs of a particular context.
\[n,iLe display syntax, the arguments are explicitly introducedby abbreviated lowercase role markers.3.2.
Sor ta l  Quant i f i ca t ionQuantificational expressi .
.s  in NFLT differ from thosein predicate calculus by alway~ rontaining a restrictor-clauseconsisting of a sortal predication, in addition to the u, sualscope-clause, as in the following example:(2a) English:Ron ate  a cookie  in the Oval Office.
(2b) NFLT Display Syntax:{ SOME XS(COOKIE  inst: XS)(EAT agt :RON ptnt :X5Io?
: OVAL-OFF ICE)  }Note that we always quantify over instances of a sort, i.e.the quantified variable fills the instance role in the restrictor-clause.This style of quantifier is superior in several ways tothat of the predicate calcuhls for the purposes of represent-ing commonsense knowledge.
It is intuitively more natu-ral, since it follows the quantificational pattern of English.More importantly, it is more general, being sufficient tohandle a number of natural language determiners such asmany, most, few, etc., that cannot be represented using onlythe unrestricted quantification of standard predicate calcu-lus (see \[Wallace 1965\], {Barwise & Cooper 1981\]).
Finally,information carried by the sortal predicates in quantifiers(namely, criteria of identity for things of the various sortsin question) provides a sound semantic basis for countingthe members of extensions of such predicates (see section2, assumption c above).Any internal structure which a variable may have isirrelevant to its function as a uniquely identifiable place-holder in a formula, in particular, a quantified formula canitself serve as its own ~bound variable".
This is how quanti-tiers are actually implemented in the HPSG system; in theinternal (i.e.
implementation) syntax for quantified NFLT-formulas, bound variables of the usual sort are dispensedwith in favor of pointers to the relevant quantified formu-las.
Thus, of the three occurrences of X5 in the display-formula (2b), the first has no counterpart in the internalsyntax, while the last two correspond internally to LISPpointers back to the data structure that implements (2b).This method of implementing quantification has some im-portant advantages.
First, it eliminates the technical prob-lems of variable clash that arise in conventional treatments.There are no ~alphabetic variants", just structurally equiv-alent concept tokens.
Secondly, each occurrence of a quanti-fied ~bound variable" provides direct computational accessto the determiner, restrictor-clause, and scope-clause withwhich it is associated.A special class of quantificational expressions, calledquantifier expressions, have no scope-clause.
An exampleis:(3) NFLT Display Syntax:(SOME g l  (COOKIE ins t :  x l )  )Such expressions translate quantified noun phrases in En-glish, e.g.
a cookie.3.3 .
Causa l  Re la t ions  andNon-Extens iona l i tyAccording to the standard semantics for the predicatecalculus, predicate symbols denote the extensions of rela-tions (i.e.
sets of ordered n-tuples) and sentential formu-las denote truth values.
By contrast, we propose a non-eztensional semantics for NFLT: we take predicate symbolsto denote relations themselves (rather than their exten-sions), and sentential formulas to denote situations or situ-ation types (rather than the corresponding truth values).
3The motivation for this is to provide for the expression ofpropositions involving causal relations among situations, asin the following example:a The distinction between situations and situation typescorresponds roughly to the fnite/infinitive distinction innatural language.
For discussion of this within the frame-work of situation semantics, ee \[Cooper 1984\].174(4a) English:J ohn  has  brown eyes because  he is o f  genotypeXYZW.
(4b) NFLT Display Syntax:( C~USEconditn: (GENOTYPE-XYZW inst : JOHN)result: (BROWN-EYED bearer:JOHN} )Now, the predicate calculus is an extensional languagein the sense that the replacement of categorical subpartswithin an expression by new subparts having the sameextension must preserve the extension of the original ex-pression.
Such replacements within a sentential expressionmust preserve the truth-value of the expression, since theextension of a sentence is a truth-value.
NFLT  is not ex-tensional in this sense.
\[n particular, some of its predicate-symbols may denote causal relations among situations, andextension-preserving substitutions within causal contextsdo not generally preserve the causal relations.
Suppose,for example, that the formula (4b) is true.
While the ex-tension of the NFLT-predicate 'GENOTYPE-XYZW' is theset of animals of genotype XYZW, its denotation is not thisset, but rather what Putnam I1969\] would call a "physicalproperty", the property of having the genotype XYZW.
Asnoted above (section 2, assumption d) a property is to bedistinguished both from the set of objects of which it holdsand from any concept of it.
Now even if this property wereto happen by coincidence to have the same extension asthe property of being a citizen of Polo Alto born preciselyat noon on I April \].956, the substitution of a predicate-symbol denoting this latter property for 'GENOTYPE-XYZW'in the formula (4b) would produce a falsehood.However, NFLT's lack of extensionality does not involveany departure from compositional semantics.
The deno-tation of an NFLT-predicate-symbol is a property; thus,although the substitution discussed earlier preserves theextension of 'GENOTYPE-XYZW', it does not preserve thedenotation of that predicate-symbol.
Similarly, the deno-tation of an NFLT-sentence is a situation or ~ttuation-type,as distinguished both from a mere truth-val,e and from apropositionJ Then, although NFLT  is not at~ extensionallanguage in the standard sense, a Fregean a.alogue of theprinciple of extensionality does hold for it: The replace-ment of subparts within an expression by new subpartshaving the same denotation must preserve the denotationof the original expression (see \[Frege 18921).
Moreover, suchreplacements within an NFLT-sentence must preserve tiletruth-value of that sentence, since the truth-value is deter-mined by the denotation.3.4.
In tent iona l i ty  andConceptua l  Ra is ingThe NFLT  notation for representing information aboutpropositional attitudes is an improved version of the neo-Fregean scheme described in \[Creary 1979 I, section 2, whichis itself an extension and improvement of that found in\[McCarthy 1979\].
The basic idea underlying this schemeis that propositional attitudes are relations between peo-ple (or other intelligent organisms) and propositions; bothternm of such relations are taken as members of the do-main of discourse.
Objective propositions and their com-ponent objective concepts are regarded a.s abstract enti-ties, roughly on a par with numbers, sets, etc.
They areperson-independent components of situations involving be-lief, knowledge, desire, and the like.
More specifically, ob-jective concepts are abstract types which may have as to-ken~ the subjective concepts of individual organisms, whichin turn are configurations of information and associatedprocedures in various individual memories (cf.
section 2,assurnption d above).Unlike Montague semantics \[Montague 19731, the se-mantic theory underlying NFLT  does not imply that anorganism necessarily believes all the logical equivalents ofa proposition it believes.
This is because distinct propo-sitions have as tokens distinct subjective concepts, even ifthey necessarily have the same truth-value.Here is an example of the use of NFLT  to representinformation concerning propositional attitudes:(5a) English:Nancy  wants  to  t ick le  Ron .
(5b) NFLT Display Syntax:(WANT appr: NANCYprop: t(TICKLE agt: I  p tnt :RON))\[n a Fregean spirit, we assign to each categorematicexpression of NFLT  both a sense and a denotation.
For ex-ample, the denotation of the predicate-constant 'COOKIE'is the property COOKIE, while the sense of that constant isa certain objective concept - the ~standard public" conceptof a cookie.
We say that ~COOKIE' expresses its sense anddenotes its denotation.
The result of appending the "con-ceptual raising" symbol ' l" to the constant "COOKIE' isa new constant, ' TCOOKIE', that denotes the concept that'COOKTE' expresses (i.e. '
1"' applies to a constant and formsa standard name of the sense of that constant).
By ap-pending multiple occurrences of ' T' to constants, we obtainnew constants that denote concepts of concepts, conceptsof concepts of concepts, etc.
5\[n expression (5b), ' 1" is not explicitly appended toa constant, but instead is prefxed to a compound expres-sion.
When used in this way, " 1" functions as a syncat-egorematic operator that "conceptually raises" each cate-gorematic onstant within its scope and forms a term incor-porating the raised constants and denoting a proposition.4 Thus, something similar to what Barwise and Perry call"situation semantics" 119831 is to be provided for NFLT-expressions, insofar as those expressions involve no ascrip-tion of propositional attitudes (the Barwise-Perry semanticsfor ascriptions of propositional attitudes takes a quite dif-ferent approach from that to be described for NFLT in thenext section):s For further details concerning this Fregean conceptualhierarchy, see \[Creary 1979 I, sections 2.2 and 2.3.1.
Cap-italization, '$'-postfixing, and braces are used there to dothe work done here by the symbol ' t'.175Thus, the subformula ' T (T ICKLE  aqt : I  p tn t :RON)  ' isthe name of a proposition whose component concepts arethe relation-concept TTICKLE and the individual conceptsTI and I'RON.
This proposition is the sense of the unraisedsubformula ' (TICKLE agt: I p int :  RON) '.The individual concept TI, the minimal concept of self,is an especially interesting objective concept.
We assumethat for each sufficiently self-conscious and active organismX, X's minimal internal representation f itself is g token ofTI.
This concept is the sense of the indexical pronoun I, andis itself indexical in the sense that what it is a concept of isdetermined not by its content (which is the same for eachtoken), but rather by the context of its use.
The contentof this concept is partly descriptive but mostly procedural,consisting mainly of the unique and important role that itplays in the information-processing of the organisms thathave it.4.
Lex iconHPSG's head grammar takes as its point of departureSaussure's \[1916 t notion of a sign.
A sign is a conceptual ob-ject, shared by a group of organisms, which consist,~ of twoassociated concepts that we call (by a conventional buse oflanguage) a phonolooical representation a d a semantic rep-resentation.
For example, members of the English-speakingcommunity share a sign which consists of an internal rep-resentation of the utterance-type /kUki/ together with aninternal representation of the property of being a cookie.In a computer implementation, we model such a concep-tual object with a data object of this form:(6) (cookie ;COOKIE}Here the symbol 'cookie' is a surrogate for a phonologicalrepresentation (in fact we ignore phonology altogether anddeal only with typewritten English input).
The symbol'COOKIE' (a basic constant of NFLT denoting the prop-erty COOKIE) models the corresponding semantic represen-tation.
We call a data object such as (6) a lezical entry.Of course there must be more to a language than simplesigns like (6).
Words and phrases of certain kinds can char-acteristically combine with certain other kinds of phrases toform longer expressions that can convey :,nformation aboutthe world.
Correspondingly, we assume that a grammarcontains in addition to a lexicon a set of grammatical rules(see next section) for combining simple signs to producenew signs which pair longer English expressions with morecomplex NFLT translations.
For rules to work, each signmust contain information about how it figures in the rules.We call this information the (syntactic) category of thesign.
Following established practice, we encode categoriesas specifications of values for a finite set of features.
Aug-mented with such information, lexical signs assume formssuch as these:(7a) {cookie ; COOKIE; \[MAJOR: N; AGR: 3RDSGI}(7b) (kisses ; KISS; \[MAJOR: V; VFORM: FINI}Such features as MAJOR (major category), AGR (agree-ment), and VFORM (verb form) encode inherent syntacticproperties of signs.Still more information is required, however.
Certainexpressions (heads) characteristically combine with otherexpressions of specified categories (complements) to formlarger expressions.
(For the time being we ignore optionalelements, called adjuncts.)
This is the linguistic notion ofsubcategoeization.
For example, the English verb touchessubcategorizes for two NP's, of which one must be third-person-singular.
We encode subcategorization informationas the value of a feature called SUBCAT.
Thus the valueof the SUBCAT feature is a sequence of categories.
(Suchfeatures, called stack-valued features, play a central rolein the HG account of binding.
See \[Pollard forthcomingi.
)Augmented with its SUBCAT feature, the \[exical sign (2b)takes the form:(8) {kisses ; KZflS; \[MAJOR: V; VFORM: FIN 1SUBCAT: NP, NP-3RDSG}(Symbols like 'NP'  and 'NP-3RDSG' are shorthand for cer-tain sets of feature specifications).
For ease of reference,we use traditional grammatical relation names for comple-ments.
Modifying the usage of Dowry \[1982\], we designatethem (in reverse of the order that they appear in SUBCAT)as subject, direct object, indirect object, and oblique objects.
(Under this definition, determiners count as subjects of thenouns they combine with.)
Complements that themselvessubcategorize for a complement fall outside this hierarchyand are called controlled complements.
The complementnext in sequence after a controlled complement is called itscontroller.For the sign (8) to play a communicative role, one ad-ditional kind of information is needed.
Typically, headsgive information about relation.~, while complements giveinformation about the roles that individuals play in thoserelations.
Thus lexical signs must assign roles to their com-plements.
Augmented with role-assignment information,the lexical sign (8) takes the form:(9) (kisses ; KISS; IMAJOR: V: VFORM: FIN iSUBCAT: ~NP, patient),(NP-3RDSG, agent?
}Thu~ (9) assign,, the roles AGENT and PATIENT to the sub-ject and direct object respectively.
(Note: we assume thatnouns subcategorize for a determiner complement and as-sign it the instance role.
See section 6 below.)5.
Grammat ica l  Ru les\[n addition to the lexicon, the grammar must containmechanisms for constructing more complex signs that me-diate between longer English expressions and more complexNFLT translations.
Such mechanisms are called grammat-ical rules.
From a purely syntactic point of view, rules canbe regarded as ordering principles.
For example, Englishgrammar has a rule something like this:(lO) If X is a sign whose SUBCAT value contains justone category Y, and Z is a sign whose category isconsistent with Y, then X and Z can be combinedto form a new sign W whose expression is got by178concatenating the expressions of X and Z.That is, put the final complement (subject} to the left ofthe head.
We write this rule in the abbreviated form:(11) -> C H \[Condition: length of SUBCAT of H = 11The form of (11) is analogous to conventional phrase struc-ture rules such as NP  - > DET N or S - > NP  VP;in fact (11) subsumes both of these.
However, (11) hasno left-hand side.
This is because the category of theconstructed sign (mother) can be computed from the con-stituent signs (daughters) by general principles, as we shallpresently show.Two more rules of English are:(12) -> H C \[Condition: length of SUBCAT of H = 2 I(13) -> I-I C2 C1\[Condition: length of SUBCAT of H = 31(12) says: put a direct object or subject-controlled comple-ment after the head.
And (13) says: put an indirect objector object-controlled complement after the direct object.
Asin (11), the complement signs have to be consistent withthe subcategorization specifications on the head.
In (13),the indices on the complement symbols correspond to theorder of the complement categories in the SUBCAT of thehead.The category and translation of a mother need not bespecified by the rule used to construct it.
Instead, they arecomputed from information on the daughters by universalprinciples that govern rule application.
Two such princi-ples are the Head Feature Principle (HFP) (14) and theSubcategorization Principle (15):(14) Head Feature Principle:Unless otherwise specified, the head features on amother coincide with the head features on the headdaughter.
(For present purposes, assume the head features are all fea-tures except SUBCAT.
)(15) Subcategorization Principle:The SUBCAT value on the mother is got by deletingfrom the SUBCAT value on the head daughter thosecategories corresponding to complement daughters.
(Additional principles not discussed here govern control andbinding.}
The basic idea is that we start with the headdaughter and then process the complement daughters in theorder given by the indices on the complement symbols in therule.
So far, we have said nothing about the determinationof the mother's translation.
We turn to this question in thenext section.6.
The  Semant ic  In terpretat ion  Pr inc ip leNow we can explain how the NFLT-translation of aphrase is computed from the translations of its constituents.The basic idea is that every time we apply a grammar rule,we process the head first and then the complements inthe order indicated by the rule (see \[Proudian & Pollard1985i).
As each complement is processed, the correspond-ing category-role pair is popped off the SUBCAT stack ofthe head; the category information is merged (unified) withthe category of the complement, and the role information isused to combine the complement translation with the headtranslation.
We state this formally as:(16) Semantic Interpretation Principle (SIP):The translation of the mother is computed by thefollowing program:a. Initialize the mother's translation to be thehead daughter's translation.b.
Cycle through the complement daughters, set-ting the mother's translation to the result ofcombining the complement's translation withthe mother's translation.c.
Return the mother's translation.The program given in (16) calls a function whose ar-guments are a sign (the complement), a rolemark (gottenfrom the top of the bead's SUBCAT stack), and an NFLTexpression (the value of the mother translation computedthus far).
This function is given in (17).
There are twocases to consider, according as the translation of the com-plement is a determiner or not.
(17) Function for Combining Complements:a.
If the MAJOR feature value of the comple-ment is DET, form the quantifier-expressionwhose determiner is the complement transla-tion and whose restriction is the mother trans-lation.
Then add to the restriction a role linkwith the indicated rolemark (viz.
instance}whose argument is a pointer back to that quan-tifier-expression, and return the resulting quan-tifier-expression.b.
Otherwise, add to the mother translation a rolelink with the indicated rolemark whose argu-ment is a pointer to the complement transla-tion (a quantifier-expression or individual con-stant).
\[f the complement translation isa quan-tifier-expression, return the quantificational ex-pression formed from that quantifier-expressionby letting its scope-clause be the mother trans-lation; if not, return the mother translation.The first case arises when the head daughter is a nounand the complement is a determiner.
Then (17) simply re-turns a complement like (3).
In the second case, there aretwo subcases according as the complement transiation isa quantifier-expression or something else (individual con-stant, sentential expression, propositional term, etc.)
Forexample, suppose the head is this:(18) {jogs ; JOG; \[MAJOR: V; VFORM: FIN ISUBCAT: <NP-3RDSG, agent )  }If the (subject) complement translation is 'RON' (not a quan-tifier-expression), the mother translation is just:(19) {JOG aqt:RON);but if the complement translation is'{I~LL P3 (PERSON inst:P3)}'(a quantifier-expresslon), the mother translation is:177concatenating the expressions of X and Z.That is, put the final complement (subject) to the left ofthe head.
We write this rule in the abbreviated form:(11) -> C H \[Condition: length of SUBCAT of H = 11The form of (11) is analogous to conventional phrase struc-ture rules such as NP - > DET N or S - > NP VP;in fact (U) subsumes both of these.
However, (11) hasno left-hand side.
This is because the category of theconstructed sign (mother) can be computed from the con-stituent signs (daughter8) by general principles, as we shallpresently show.Two more rules of English are:(12) -> H C \[Condition: length of SUBCAT of H = 2\[(13) ->HC2C1\[Condition: length of SUBCAT of H = 3\](12) says: put a direct object or subject-controlled comple-ment after the head.
And (13) says: put an indirect objector object-controlled complement after the direct object.
Asin (11), the complement signs have to be consistent withthe subcategorization specifications on the head.
In (13),the indices on the complement symbols correspond so theorder of the complement categories in the SUBCAT of thehead.The category and translation of a mother need not bespecified by the rule used to construct it.
instead, they arecomputed from information on the daughters by universalprinciples that govern rule application.
Two such princi-ples are the Head Feature Principle (HFP) (14) and theSubcategorization Principle (15):(14) Head Feature Principle:Unless otherwise specified, the head features on amother coincide with the head features on the headdaughter.
(For present purposes, assume the head features are all fea-tures except SUBCAT.
)(15) Subcategorization Principle:The SUBCAT value on the mother is got by deletingfrom the SUBCAT value on the head daughter thosecategories corresponding to complement daughters.
(Additional principles not discussed here govern control andbinding.)
The basic idea is that we start with the headdaughter and then process the complement daughters in theorder given by the indices on the complement symbols in therule.
So far, we have said nothing about the determinationof the mother's translation.
We turn to this question in thenext section.6.
The  Semantic Interpretation PrincipleNow we can explain how the NFLT-translation of aphrase is computed from the translations of its constituents.The basic idea is that every time we apply a grammar rule,we process the head first and then the complements inthe order indicated by the rule (see !Proudiaa & Pollard19851).
As each complement is processed, the correspond-ing category-role pair is popped off the SUBCAT stack ofthe head; the category information is merged (unified) withthe category of the complement, and the role information isused to combine the complement translation with the headtranslation.
We state this formally as:(16) Semantic Interpretation Principle (SIP):The translation of the mother is computed by thefollowing program:a. Initialize the mother's translation to be thehead daughter's translation.b.
Cycle through the complement daughters, et-ting the mother's translation to the result ofcombining the complement's translation withthe mother's translation.c.
Return the mother's translation.The program given in (16) calls a function whose ar-guments are a sign (the complement), a rolemark (gottenfrom the top of the head's SUBCAT stack), and an NFLTexpression (the value of the mother translation computedthus far).
This function is given in (17).
There are twocases to consider, according as the translation of the com-plement is a determiner or not.
(17) Function for Combining Complements:a.
If the MAJOR feature value of the comple-ment is DET, form the quantifier-expressionwhose determiner is the complement transla-tion and whose restriction is the mother trans-lation.
Then add to the restriction a role linkwith the indicated rolemark (viz.
instance)whose argument is a pointer back to that quan-tifier-expression, and return the resulting quan-tifier-expression.b.
Otherwise, add to the mother translation a rolelink with the indicated rolemark whose argu-ment is a pointer to the complement transla-tion (a quantifier-expression or individual con-stant).
If the complement translation is a quan-tifier-expression, return tile quantificational ex-pression formed from that quantifier-expressionby letting its scope-clause be the mother trans-latio,; if not, return the mother translation.The first case arises when the head daughter is a nounand the complement is a determiner.
Then (17) simply re-turns a complement like (3).
In the second c,~e.
there aretwo subcases according as the complement translation isa quantifier-expression or something else (individual con-stant, sentential expression, propositional term, etc.)
Forexample, suppose the head is this:(18) {jogs ; JOG; \[MAJOR: V; VFORM: FIN ISUBCAT: <NP-3RDSG, agent.>}If the (subject) complement translation is 'RON' (not a quan-tifier-expression), the mother translation is just:(19) {JOG agt:RON);but if the complement translation is'{ALL P3 (PERSON ins t :P3) ) '(a quantifier-expression), the mother translation is:177son, Yale University Press, New Haven and London,1974.Pollard, Carl \[19841 .
Generalized Phrase Structure Gram-mars, Head Grammars, and Natural Language.
Doc-,torsi dissertation, Stanford University.Pollard, Carl \[forthcomingl.
~A Semantic Approach toBinding in a Monostratal Theory."
To appear inLinguistics and Philosophy.Proudian, Derek, and Carl Pollard \[1985\].
~Parsing Head-driven Phrase Structure Grammar."
Proceedingsof the ~Srd Annual Meeting of the Association forComputational Linouistics.Putnam, Hilary \[1969 I.
"On Properties."
In Essays inHonor o/Carl G. Hempel, N. Rescher, ed., D. Rei-del, Dordrecht.
Reprinted in Mind, Language, andReality: Philosophical Papers (Vol.
I, Ch.
19), Cam-bridge University Press, Cambridge, 1975.Saussure, Ferdinand e \[1916\].
Gouts de Linguistiquc Gen-erale.
Paris: Payot.
Translated into English byWade Baskin as Course in General Linguistics, ThePhilosophical Library, New York, 1959 (paperbackedition, McGraw-Hill, New York, 1966).Wallace, John \[1965 I.
"Sortal Predicates and Quantifica-tion."
The Journal o\[ Philosophy 62, 8-13.179
