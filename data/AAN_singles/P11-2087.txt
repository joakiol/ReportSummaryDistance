Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 496?501,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsPutting it Simply: a Context-Aware Approach to Lexical SimplificationOr BiranComputer ScienceColumbia UniversityNew York, NY 10027ob2008@columbia.eduSamuel BrodyCommunication & InformationRutgers UniversityNew Brunswick, NJ 08901sdbrody@gmail.comNoe?mie ElhadadBiomedical InformaticsColumbia UniversityNew York, NY 10032noemie@dbmi.columbia.eduAbstractWe present a method for lexical simplifica-tion.
Simplification rules are learned from acomparable corpus, and the rules are appliedin a context-aware fashion to input sentences.Our method is unsupervised.
Furthermore, itdoes not require any alignment or correspon-dence among the complex and simple corpora.We evaluate the simplification according tothree criteria: preservation of grammaticality,preservation of meaning, and degree of sim-plification.
Results show that our method out-performs an established simplification base-line for both meaning preservation and sim-plification, while maintaining a high level ofgrammaticality.1 IntroductionThe task of simplification consists of editing an in-put text into a version that is less complex linguisti-cally or more readable.
Automated sentence sim-plification has been investigated mostly as a pre-processing step with the goal of improving NLPtasks, such as parsing (Chandrasekar et al, 1996;Siddharthan, 2004; Jonnalagadda et al, 2009), se-mantic role labeling (Vickrey and Koller, 2008) andsummarization (Blake et al, 2007).
Automated sim-plification can also be considered as a way to helpend users access relevant information, which wouldbe too complex to understand if left unedited.
Assuch, it was proposed as a tool for adults withaphasia (Carroll et al, 1998; Devlin and Unthank,2006), hearing-impaired people (Daelemans et al,2004), readers with low-literacy skills (Williams andReiter, 2005), individuals with intellectual disabil-ities (Huenerfauth et al, 2009), as well as healthINPUT: In 1900, Omaha was the center of a nationaluproar over the kidnapping of Edward Cudahy, Jr., theson of a local meatpacking magnate.CANDIDATE RULES:{magnate?
king} {magnate?
businessman}OUTPUT: In 1900, Omaha was the center of a nationaluproar over the kidnapping of Edward Cudahy, Jr., theson of a local meatpacking businessman.Figure 1: Input sentence, candidate simplification rules,and output sentence.consumers looking for medical information (El-hadad and Sutaria, 2007; Dele?ger and Zweigen-baum, 2009).Simplification can take place at different levels ofa text ?
its overall document structure, the syntaxof its sentences, and the individual phrases or wordsin a sentence.
In this paper, we present a sentencesimplification approach, which focuses on lexicalsimplification.1 The key contributions of our workare (i) an unsupervised method for learning pairs ofcomplex and simpler synonyms; and (ii) a context-aware method for substituting one for the other.Figure 1 shows an example input sentence.
Theword magnate is determined as a candidate for sim-plification.
Two learned rules are available to thesimplification system (substitute magnate with kingor with businessman).
In the context of this sen-tence, the second rule is selected, resulting in thesimpler output sentence.Our method contributes to research on lexicalsimplification (both learning of rules and actual sen-tence simplification), a topic little investigated thusfar.
From a technical perspective, the task of lexi-cal simplification bears similarity with that of para-1Our resulting system is available for download athttp://www.cs.columbia.edu/ ob2008/496phrase identification (Androutsopoulos and Malaka-siotis, 2010) and the SemEval-2007 English Lexi-cal Substitution Task (McCarthy and Navigli, 2007).However, these do not consider issues of readabil-ity and linguistic complexity.
Our methods lever-age a large comparable collection of texts: En-glish Wikipedia2 and Simple English Wikipedia3.Napoles and Dredze (2010) examined WikipediaSimple articles looking for features that characterizea simple text, with the hope of informing researchin automatic simplification methods.
Yatskar et al(2010) learn lexical simplification rules from the edithistories of Wikipedia Simple articles.
Our methoddiffers from theirs, as we rely on the two corpora as awhole, and do not require any aligned or designatedsimple/complex sentences when learning simplifica-tion rules.42 DataWe rely on two collections ?
English Wikipedia(EW) and Simple English Wikipedia (SEW).
SEWis a Wikipedia project providing articles in Sim-ple English, a version of English which uses fewerwords and easier grammar, and which aims to beeasier to read for children, people who are learningEnglish and people with learning difficulties.
Due tothe labor involved in simplifying Wikipedia articles,only about 2% of the EW articles have been simpli-fied.Our method does not assume any specific align-ment or correspondance between individual EW andSEW articles.
Rather, we leverage SEW only asan example of an in-domain simple corpus, in or-der to extract word frequency estimates.
Further-more, we do not make use of any special propertiesof Wikipedia (e.g., edit histories).
In practice, thismeans that our method is suitable for other caseswhere there exists a simplified corpus in the samedomain.The corpora are a snapshot as of April 23, 2010.EW contains 3,266,245 articles, and SEW contains60,100 articles.
The articles were preprocessed asfollows: all comments, HTML tags, and Wiki linkswere removed.
Text contained in tables and figures2http://en.wikipedia.org3http://simple.wikipedia.org4Aligning sentences in monolingual comparable corpora hasbeen investigated (Barzilay and Elhadad, 2003; Nelken andShieber, 2006), but is not a focus for this work.was excluded, leaving only the main body text ofthe article.
Further preprocessing was carried outwith the Stanford NLP Package5 to tokenize the text,transform all words to lower case, and identify sen-tence boundaries.3 MethodOur sentence simplification system consists of twomain stages: rule extraction and simplification.
Inthe first stage, simplification rules are extracted fromthe corpora.
Each rule consists of an ordered wordpair {original?
simplified} along with a score indi-cating the similarity between the words.
In the sec-ond stage, the system decides whether to apply a rule(i.e., transform the original word into the simplifiedone), based on the contextual information.3.1 Stage 1: Learning Simplification Rules3.1.1 Obtaining Word PairsAll content words in the English Wikipedia Cor-pus (excluding stop words, numbers, and punctua-tion) were considered as candidates for simplifica-tion.
For each candidate word w, we constructed acontext vectorCVw, containing co-occurrence infor-mation within a 10-token window.
Each dimensioni in the vector corresponds to a single word wi inthe vocabulary, and a single dimension was added torepresent any number token.
The value in each di-mension CVw[i] of the vector was the number of oc-currences of the corresponding wordwi within a ten-token window surrounding an instance of the candi-date word w. Values below a cutoff (2 in our exper-iments) were discarded to reduce noise and increaseperformance.Next, we consider candidates for substitution.From all possible word pairs (the Cartesian productof all words in the corpus vocabulary), we first re-move pairs of morphological variants.
For this pur-pose, we use MorphAdorner6 for lemmatization, re-moving words which share a common lemma.
Wealso prune pairs where one word is a prefix of theother and the suffix is in {s, es, ed, ly, er, ing}.
Thishandles some cases which are not covered by Mor-phAdorner.
We use WordNet (Fellbaum, 1998) asa primary semantic filter.
From all remaining wordpairs, we select those in which the second word, in5http://nlp.stanford.edu/software/index.shtml6http://morphadorner.northwestern.edu497its first sense (as listed in WordNet)7 is a synonymor hypernym of the first.Finally, we compute the cosine similarity scoresfor the remaining pairs using their context vectors.3.1.2 Ensuring SimplificationFrom among our remaining candidate word pairs,we want to identify those that represent a complexword which can be replaced by a simpler one.
Ourdefinition of the complexity of a word is based ontwo measures: the corpus complexity and the lexicalcomplexity.
Specifically, we define the corpus com-plexity of a word asCw =fw,Englishfw,Simplewhere fw,c is the frequency of word w in corpus c,and the lexical complexity as Lw = |w|, the lengthof the word.
The final complexity ?w for the wordis given by the product of the two.
?w = Cw ?
LwAfter calculating the complexity of all words par-ticipating in the word pairs, we discard the pairs forwhich the first word?s complexity is lower than thatof the second.
The remaining pairs constitute thefinal list of substitution candidates.3.1.3 Ensuring GrammaticalityTo ensure that our simplification substitutionsmaintain the grammaticality of the original sentence,we generate grammatically consistent rules fromthe substitution candidate list.
For each candidatepair (original, simplified), we generate all consis-tent forms (fi(original), fi(substitute)) of the twowords using MorphAdorner.
For verbs, we createthe forms for all possible combinations of tenses andpersons, and for nouns we create forms for both sin-gular and plural.For example, the word pair (stride, walk) will gen-erate the form pairs (stride, walk), (striding, walk-ing), (strode, walked) and (strides, walks).
Signifi-cantly, the word pair (stride, walked) will generate7Senses in WordNet are listed in order of frequency.
Ratherthan attempting explicit disambiguation and adding complex-ity to the model, we rely on the first sense heuristic, which isknow to be very strong, along with contextual information, asdescribed in Section 3.2.exactly the same list of form pairs, eliminating theoriginal ungrammatical pair.Finally, each pair (fi(original), fi(substitute)) be-comes a rule {fi(original) ?
fi(substitute)},with weight Similarity(original, substitute).3.2 Stage 2: Sentence SimplificationGiven an input sentence and the set of rules learnedin the first stage, this stage determines which wordsin the sentence should be simplified, and appliesthe corresponding rules.
The rules are not appliedblindly, however; the context of the input sentenceinfluences the simplification in two ways:Word-Sentence Similarity First, we want to en-sure that the more complex word, which we are at-tempting to simplify, was not used precisely becauseof its complexity - to emphasize a nuance or for itsspecific shade of meaning.
For example, suppose wehave a rule {Han?
Chinese}.
We would want toapply it to a sentence such as ?In 1368 Han rebelsdrove out the Mongols?, but to avoid applying it toa sentence like ?The history of the Han ethnic groupis closely tied to that of China?.
The existence ofrelated words like ethnic and China are clues thatthe latter sentence is in a specific, rather than gen-eral, context and therefore a more general and sim-pler hypernym is unsuitable.
To identify such cases,we calculate the similarity between the target word(the candidate for replacement) and the input sen-tence as a whole.
If this similarity is too high, itmight be better not to simplify the original word.Context Similarity The second factor has to dowith ambiguity.
We wish to detect and avoid caseswhere a word appears in the sentence with a differ-ent sense than the one originally considered whencreating the simplification rule.
For this purpose, weexamine the similarity between the rule as a whole(including both the original and the substitute words,and their associated context vectors) and the contextof the input sentence.
If the similarity is high, it islikely the original word in the sentence and the ruleare about the same sense.3.2.1 Simplification ProcedureBoth factors described above require sufficientcontext in the input sentence.
Therefore, our sys-tem does not attempt to simplify sentences with lessthan seven content words.498Type Gram.
Mean.
Simp.Baseline 70.23(+13.10)% 55.95% 46.43%System 77.91(+8.14)% 62.79% 75.58%Table 1: Average scores in three categories: grammatical-ity (Gram.
), meaning preservation (Mean.)
and simplifi-cation (Simp.).
For grammaticality, we show percent ofexamples judged as good, with ok percent in parentheses.For all other sentences, each content word is ex-amined in order, ignoring words inside quotationmarks or parentheses.
For each word w, the set ofrelevant simplification rules {w ?
x} is retrieved.For each rule {w ?
x}, unless the replacementword x already appears in the sentence, our systemdoes the following:?
Build the vector of sentence context SCVs,w in asimilar manner to that described in Section 3.1,using the words in a 10-token window surround-ing w in the input sentence.?
Calculate the cosine similarity of CVw andSCVs,w.
If this value is larger than a manuallyspecified threshold (0.1 in our experiments), donot use this rule.?
Create a common context vector CCVw,x for therule {w ?
x}.
The vector contains all fea-tures common to both words, with the featurevalues that are the minimum between them.
Inother words, CCVw,x[i] = min(CVw[i], CVx[i]).We calculate the cosine similarity of the commoncontext vector and the sentence context vector:ContextSim = cosine(CCVw,x, SCVs,w)If the context similarity is larger than a threshold(0.01), we use this rule to simplify.If multiple rules apply for the same word, we usethe one with the highest context similarity.4 Experimental SetupBaseline We employ the method of Devlin andUnthank (2006) which replaces a word with its mostfrequent synonym (presumed to be the simplest) asour baseline.
To provide a fairer comparison to oursystem, we add the restriction that the synonymsshould not share a prefix of four or more letters(a baseline version of lemmatization) and use Mor-phAdorner to produce a form that agrees with thatof the original word.Type Freq.
Gram.
Mean.
Simp.Base High 63.33(+20)% 46.67% 50%Sys.
High 76.67(+6.66)% 63.33% 73.33%Base Med 75(+7.14)% 67.86% 42.86%Sys.
Med 72.41(+17.25)% 75.86% 82.76%Base Low 73.08(+11.54)% 53.85% 46.15%Sys.
Low 85.19(+0)% 48.15% 70.37%Table 2: Average scores by frequency bandEvaluation Dataset We sampled simplificationexamples for manual evaluation with the followingcriteria.
Among all sentences in English Wikipedia,we first extracted those where our system chose tosimplify exactly one word, to provide a straightfor-ward example for the human judges.
Of these, wechose the sentences where the baseline could alsobe used to simplify the target word (i.e., the wordhad a more frequent synonym), and the baseline re-placement was different from the system choice.
Weincluded only a single example (simplified sentence)for each rule.The evaluation dataset contained 65 sentences.Each was simplified by our system and the baseline,resulting in 130 simplification examples (consistingof an original and a simplified sentence).Frequency Bands Although we included only asingle example of each rule, some rules could beapplied much more frequently than others, as thewords and associated contexts were common in thedataset.
Since this factor strongly influences theutility of the system, we examined the performancealong different frequency bands.
We split the eval-uation dataset into three frequency bands of roughlyequal size, resulting in 46 high, 44 med and 40 low.Judgment Guidelines We divided the simplifica-tion examples among three annotators 8 and ensuredthat no annotator saw both the system and baselineexamples for the same sentence.
Each simplificationexample was rated on three scales: Grammaticality- bad, ok, or good; Meaning - did the transforma-tion preserve the original meaning of the sentence;and Simplification - did the transformation result in8The annotators were native English speakers and were notthe authors of this paper.
A small portion of the sentence pairswere duplicated among annotators to calculate pairwise inter-annotator agreement.
Agreement was moderate in all categories(Cohen?s Kappa = .350?
.455 for Simplicity, .475?
.530 forMeaning and .415?
.425 for Grammaticality).499a simpler sentence.5 Results and DiscussionTable 1 shows the overall results for the experiment.Our method is quantitatively better than the base-line at both grammaticality and meaning preserva-tion, although the difference is not statistically sig-nificant.
For our main goal of simplification, ourmethod significantly (p < 0.001) outperforms thebaseline, which represents the established simplifi-cation strategy of substituting a word with its mostfrequent WordNet synonym.
The results demon-strate the value of correctly representing and ad-dressing content when attempting automatic simpli-fication.Table 2 contains the results for each of the fre-quency bands.
Grammaticality is not strongly influ-enced by frequency, and remains between 80-85%for both the baseline and our system (consideringthe ok judgment as positive).
This is not surpris-ing, since the method for ensuring grammaticality islargely independent of context, and relies mostly ona morphological engine.
Simplification varies some-what with frequency, with the best results for themedium frequency band.
In all bands, our system issignificantly better than the baseline.
The most no-ticeable effect is for preservation of meaning.
Here,the performance of the system (and the baseline) isthe best for the medium frequency group.
However,the performance drops significantly for the low fre-quency band.
This is most likely due to sparsity ofdata.
Since there are few examples from which tolearn, the system is unable to effectively distinguishbetween different contexts and meanings of the wordbeing simplified, and applies the simplification ruleincorrectly.These results indicate our system can be effec-tively used for simplification of words that occurfrequently in the domain.
In many scenarios, theseare precisely the cases where simplification is mostdesirable.
For rare words, it may be advisable tomaintain the more complex form, to ensure that themeaning is preserved.Future Work Because the method does not placeany restrictions on the complex and simple corpora,we plan to validate it on different domains and ex-pect it to be easily portable.
We also plan to extendour method to larger spans of texts, beyond individ-ual words.ReferencesAndroutsopoulos, Ion and Prodromos Malakasiotis.2010.
A survey of paraphrasing and textual entail-ment methods.
Journal of Artificial IntelligenceResearch 38:135?187.Barzilay, Regina and Noemie Elhadad.
2003.
Sen-tence alignment for monolingual comparable cor-pora.
In Proc.
EMNLP.
pages 25?32.Blake, Catherine, Julia Kampov, Andreas Or-phanides, David West, and Cory Lown.
2007.Query expansion, lexical simplification, and sen-tence selection strategies for multi-documentsummarization.
In Proc.
DUC.Carroll, John, Guido Minnen, Yvonne Canning,Siobhan Devlin, and John Tait.
1998.
Practicalsimplication of english newspaper text to assistaphasic readers.
In Proc.
AAAI Workshop on Inte-grating Artificial Intelligence and Assistive Tech-nology.Chandrasekar, R., Christine Doran, and B. Srinivas.1996.
Motivations and methods for text simplifi-cation.
In Proc.
COLING.Daelemans, Walter, Anja Hthker, and ErikTjong Kim Sang.
2004.
Automatic sentencesimplification for subtitling in Dutch and English.In Proc.
LREC.
pages 1045?1048.Dele?ger, Louise and Pierre Zweigenbaum.
2009.Extracting lay paraphrases of specialized expres-sions from monolingual comparable medical cor-pora.
In Proc.
Workshop on Building and UsingComparable Corpora.
pages 2?10.Devlin, Siobhan and Gary Unthank.
2006.
Help-ing aphasic people process online information.
InProc.
ASSETS.
pages 225?226.Elhadad, Noemie and Komal Sutaria.
2007.
Mininga lexicon of technical terms and lay equivalents.In Proc.
ACL BioNLP Workshop.
pages 49?56.Fellbaum, Christiane, editor.
1998.
WordNet: AnElectronic Database.
MIT Press, Cambridge,MA.Huenerfauth, Matt, Lijun Feng, and Noe?mie El-hadad.
2009.
Comparing evaluation techniques500for text readability software for adults with intel-lectual disabilities.
In Proc.
ASSETS.
pages 3?10.Jonnalagadda, Siddhartha, Luis Tari, Jo?rg Haken-berg, Chitta Baral, and Graciela Gonzalez.
2009.Towards effective sentence simplification for au-tomatic processing of biomedical text.
In Proc.NAACL-HLT .
pages 177?180.McCarthy, Diana and Roberto Navigli.
2007.Semeval-2007 task 10: English lexical substitu-tion task.
In Proc.
SemEval.
pages 48?53.Napoles, Courtney and Mark Dredze.
2010.
Learn-ing simple wikipedia: a cogitation in ascertainingabecedarian language.
In Proc.
of the NAACL-HLT Workshop on Computational Linguistics andWriting.
pages 42?50.Nelken, Rani and Stuart Shieber.
2006.
Towardsrobust context-sensitive sentence alignment formonolingual corpora.
In Proc.
EACL.
pages 161?166.Siddharthan, Advaith.
2004.
Syntactic simplifica-tion and text cohesion.
Technical Report UCAM-CL-TR-597, University of Cambridge, ComputerLaboratory.Vickrey, David and Daphne Koller.
2008.
Apply-ing sentence simplification to the CoNLL-2008shared task.
In Proc.
CoNLL.
pages 268?272.Williams, Sandra and Ehud Reiter.
2005.
Generatingreadable texts for readers with low basic skills.
InProc.
ENLG.
pages 127?132.Yatskar, Mark, Bo Pang, Cristian Danescu-Niculescu-Mizil, and Lillian Lee.
2010.
For thesake of simplicity: Unsupervised extraction oflexical simplifications from wikipedia.
In Proc.NAACL-HLT .
pages 365?368.501
