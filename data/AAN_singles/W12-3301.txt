Proceedings of the 2012 Student Research Workshop, pages 1?6,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsA Broad Evaluation of Techniques for AutomaticAcquisition of Multiword ExpressionsCarlos Ramisch?, ?, Vitor De Araujo?, Aline Villavicencio?
?Federal University of Rio Grande do Sul (Brazil)?
GETALP ?
LIG, University of Grenoble (France){ceramisch, vbuaraujo, avillavicencio}@inf.ufrgs.brAbstractSeveral approaches have been proposed for the au-tomatic acquisition of multiword expressions fromcorpora.
However, there is no agreement aboutwhich of them presents the best cost-benefit ratio, asthey have been evaluated on distinct datasets and/orlanguages.
To address this issue, we investigatethese techniques analysing the following dimen-sions: expression type (compound nouns, phrasalverbs), language (English, French) and corpus size.Results show that these techniques tend to extractsimilar candidate lists with high recall (?
80%) fornominals and high precision (?
70%) for verbals.The use of association measures for candidate filter-ing is useful but some of them are more onerous andnot significantly better than raw counts.
We finishwith an evaluation of flexibility and an indication ofwhich technique is recommended for each language-type-size context.1 IntroductionTaking into account multiword expressions (MWEs) isimportant to confer naturalness to the output of NLP sys-tems.
An MT system, for instance, needs to be aware ofidiomatic expressions like raining cats and dogs to avoidliteral translations.1 Likewise, a parser needs to deal withverb-particle expressions like take off from Paris and withlight verb constructions like take a walk along the riverin order to avoid PP-attachment errors.Even though the last decade has seen considerable re-search in the automatic acquisition of MWEs, both intheoretical and in computational linguistics, to date thereare few NLP applications integrating explicit MWE treat-ment.
This may be partly explained by the complexity ofMWEs: as they are heterogeneous and flexible, there isno unique push-button approach to identify all types ofMWEs in all languages (Sag et al, 2002).
Existing ap-proaches are either generic but present relatively low pre-1The equivalent expressions in French would be raining ropes, inGerman raining young dogs, in Portuguese raining Swiss knives, etc.cision or they require a large amount of language-specificresources to yield good results.The goal of this paper is to evaluate approaches for theautomatic acquisition of MWEs from corpora (?2), exam-ining as parameters of the experimental context the lan-guage (English and French), type of target MWE (verbaland nominal) and size of corpus (small, medium, large).We focus on 4 approaches2 and the experimental setup ispresented in ?3.
In ?4 we evaluate the following acqui-sition dimensions: quality of extracted candidates and ofassociation measures, use of computational resources andflexibility.
Thus, this research presents a comparative in-vestigation of available approaches and indicates the bestcost-benefit ratio in a given context (language, type, cor-pus size), pointing out current limitations and suggestingfuture avenues of research for the field.2 MWE Acquisition ApproachesEfforts for the evaluation of MWE acquisition approachesusually focus on a single technique or compare the qual-ity of association measures (AMs) used to rank a fixedannotated list of MWEs.
For instance, Evert and Krenn(2005) and Seretan (2008) specifically evaluate and anal-yse the lexical AMs used in MWE extraction on smallsamples of bigram candidates.
Pearce (2002), systemat-ically evaluates a set of techniques for MWE extractionon a small test set of English collocations.
Analogously,Pecina (2005) and Ramisch et al (2008) present exten-sive comparisons of individual AMs and of their combi-nation for MWE extraction in Czech, German and En-glish.
There have also been efforts for the extrinsic eval-uation of MWEs for NLP applications such as informa-tion retrieval (Xu et al, 2010), word sense disambigua-tion (Finlayson and Kulkarni, 2011) and MT (Carpuatand Diab, 2010).One recent initiative aiming at more comparable eval-2We consider only freely available, downloadable and openly docu-mented tools.
Therefore, outside the scope of this work are proprietarytools, terminology and lexicography tools, translation aid tools and pub-lished techniques for which no available implementation is provided.1uations of MWE acquisition approaches was in the formof a shared task (Gr?goire et al, 2008).
However, thepresent work differs from the shared task in its aims.
Thelatter considered only the ranking of precompiled MWElists using AMs or linguistic filters at the end of extrac-tion.
However, for many languages and domains, no suchlists are available.
In addition, the evaluation results pro-duced for the shared task may be difficult to generalise,as some of the evaluations prioritized the precision of thetechniques without considering the recall or the noveltyof the extracted MWEs.
To date little has been said aboutthe practical concerns involving MWE acquisition, likecomputational resources, flexibility or availability.
Withthis work, we hope to help filling this gap by performinga broad evaluation of the acquisition process as a whole,considering many different parameters.We focus on 4 approaches for MWE acquisition fromcorpora, which follow the general trend in the area of us-ing shallow linguistic (lemmas, POS, stopwords) and/orstatistical (counts, AMs) information to distinguishingordinary sequences (e.g.
yellow dress, go to a concert)from MWEs (e.g.
black box, go by a name).
In additionto the brief description below, Section 4.4 underlines themain differences between the approaches.1.
LocalMaxs3 extracts MWEs by generating all pos-sible n-grams from a sentence and then filteringthem based on the local maxima of the AM?s dis-tribution (Silva and Lopes, 1999).
It is basedpurely on word counts and is completely languageindependent, but it is not possible to directly in-tegrate linguistic information in order to target aspecific type of construction.4 The evaluationincludes both LocalMaxs Strict which prioritizeshigh precision (henceforth LocMax-S) and Local-Maxs Relaxed which focuses on high recall (hence-forth LocMax-R).
A variation of the original algo-rithm, SENTA, has been proposed to deal with non-contiguous expressions (da Silva et al, 1999).
How-ever, it is computationally costly5 and there is nofreely available implementation.2.
MWE toolkit6 (mwetk) is an environment fortype and language-independent MWE acquisition,integrating linguistic and frequency information(Ramisch et al, 2010).
It generates a targeted listof MWE candidates extracted and filtered accordingto user-defined criteria like POS sequences and a set3http://hlt.di.fct.unl.pt/luis/multiwords/index.html4Although this can be simulated by concatenating words and POStags together in order to form a token.5It is based on the calculation of all possible n-grams in a sen-tence, which explode in number when going from contiguous to non-contiguous n-grams.6http://mwetoolkit.sourceforge.netSmall Medium Large# sentences 5,000 50,000 500,000# en words 133,859 1,355,482 13,164,654# fr words 145,888 1,483,428 14,584,617Table 1: Number of sentences and of words of each fragment ofthe Europarl corpus in fr and in en.of statistical AMs.
It is an integrated framework forMWE treatment, providing from corpus preprocess-ing facilities to the automatic evaluation of the re-sulting list with respect to a reference.
Its input isa corpus annotated with POS, lemmas and depen-dency syntax, or if these are not available, raw text.3.
Ngram Statistics Package7 (NSP) is a traditionalapproach for the statistical analysis of n-grams intexts (Pedersen et al, 2011).
It provides tools forcounting n-grams and calculating AMs, where an n-gram is a sequence of n words occurring either con-tiguously or within a window of w words in a sen-tence.
While most of the measures are only appli-cable to bigrams, some of them are also extended totrigrams and 4-grams.
The set of available AMs in-cludes robust and theoretically sound measures suchas log-likelihood and Fischer?s exact test.
Althoughthere is no direct support to linguistic informationsuch as POS, it is possible to simulate them to someextent using the same workaround as for LocMax.4.
UCS toolkit8 provides a large set of sophisticatedAMs.
It focuses on high accuracy calculations forbigram AMs, but unlike the other approaches, itstarts from a list of candidates and their respec-tive frequencies, relying on external tools for corpuspreprocessing and candidate extraction.
Therefore,questions concerning contiguous n-grams and sup-port of linguistic filters are not dealt with by UCS.
Inour experiments, we will use the list of candidatesgenerated by mwetk as input for UCS.As the focus of this work is on MWE acquisition (iden-tification and extraction), other tasks related to MWEtreatment, namely interpretation, classification and appli-cations (Anastasiou et al, 2009), are not considered inthis paper.
This is the case, for instance, of approachesfor dictionary-based in-context MWE token identificationrequiring an initial dictionary of valid MWEs, like jMWE(Kulkarni and Finlayson, 2011).3 Experimental SetupFor comparative purposes, we investigate the acquisitionof MWEs in two languages, English (en) and French7http://search.cpan.org/dist/Text-NSP8http://www.collocations.de/software.html2(fr), analysing nominal and verbal expressions in en andnominal in fr,9 obtained with the following rules:?
Nominal expressions en: a noun preceded by a se-quence of one or more nouns or adjectives, e.g.
Eu-ropean Union, clock radio, clown anemone fish.?
Nominal expressions fr: a noun followed by eitheran adjective or a prepositional complement (with theprepositions de, ?
and en) followed by an option-ally determined noun, e.g.
algue verte, ali?nation debien, allergie ?
la poussi?re.?
Verbal expressions en: verb-particle constructionsformed by a verb (except be and have) followed bya prepositional particle10 not further than 5 wordsafter it, e.g.
give up, switch the old computer off.To test the influence of corpus size on performance,three fragments of the en and fr parts of the Eu-roparl corpus v311 were used as test corpora: (S)mall,(M)edium and (L)arge, summarised in Table 1.The extracted MWEs were automatically evaluatedagainst the following gold standards: WordNet 3, theCambridge Dictionary of Phrasal Verbs, and the VPC(Baldwin, 2008) and CN (Kim and Baldwin, 2008)datasets 12 for en; the Lexique-Grammaire13 for fr.
Thetotal number of entries is listed below, along with thenumber of entries occurring at least twice in each cor-pus (in parentheses), which was the denominator used tocalculate recall in ?
4.1:?
Nominal expressions en: 59,683 entries (S: 122, M:764, L: 2,710);?
Nominal expressions fr: 69,118 entries (S: 220, M:1,406, L: 4,747);?
Verbal expressions en: 1,846 entries (S: 699, M:1,846, L: 1,846).4 Evaluation ResultsThe evaluation of MWE acquisition is an open problem.While classical measures like precision and recall assumethat a complete (or at least broad-coverage) gold standardexists, manual annotation of top-n candidates and meanaverage precision (MAP) are labour-intensive even whenapplied to a small sample, emphasizing precision regard-less of the number of acquired new expressions.
As ap-proaches differ in the way they allow the description ofextraction criteria, we evaluate candidate extraction sep-arately from AMs.9As fr does not present many verb-particle constructions and dueto the lack of availability of resource for other types of fr verbal ex-pressions (e.g.
light verb constructions), only nominal expressions areconsidered.10up, off, down, back, away, in, on.11http://www.statmt.org/europarl/12The latter are available from http://multiword.sf.net/13http://infolingu.univ-mlv.fr/LocMax-SLocMax-R mwetk NSP UCSLocMax-SLocMax-R mwetk NSP UCSLocMax-SLocMax-R mwetk NSP UCSen-noun                     fr-noun                     en-verb0%10%20%30%40%50%60%70%80%90%100%Precision Recall F-measureFigure 1: Quality of candidates extracted from medium corpus,comparison across languages/MWE types.4.1 Extracted CandidatesWe consider as MWE candidates the initial set of se-quences before any AM is applied.
Candidate extractionis performed through the application of patterns describ-ing the target MWEs in terms of POS sequences, as de-scribed in ?
3.
To minimise potential cases of noise, can-didates occurring only once in the corpus were discarded.We compare the quality of these candidates in terms of(P)recision, (R)ecall and (F)-measure using the gold stan-dard references described in ?
3.
These measures are un-derestimations as they assume that candidates not in thegold standard are false MWEs, whereas they may simplybe absent due to coverage limitations.The quality of candidates extracted from the medium-size corpus (M) varies across MWE types/languages, asshown in Figure 1.
The candidates for UCS are obtainedby keeping only the bigrams in the candidate list returnedby the mwetk.
For nominal MWEs, the approaches havesimilar patterns of performance in the two languages,with high recall and low precision yielding an F-measureof around 10 to 15%.
The variation between en and frcan be partly explained by the differences in size of thegold standards for each of these languages.
Further re-search would be needed to determine to what degree thecharacteristics of these languages and the set of extractionpatterns influence these results.
For verbal expressions,LocMax has high precision (around 70%) but low recallwhile the other approaches have more balanced P and Rvalues around 20%.
This is partly due to the need forsimulating POS filters for extraction of verbal MWE can-didates with LocMax.
The filter consists of keeping onlycontiguous n-grams in which the first and the last wordsmatched verb+particle pattern and removing interveningwords.The techniques differ in terms of extraction strategy:(i) mwetk and NSP allow the definition of linguistic fil-ters while LocMax only allows the application of grep-3S M LLocMax-SP 7.53% 6.18% 4.50%R 42.62% 38.48% 37.42%LocMax-RP 7.46% 6.02% ?R 42.62% 38.48% ?P-mwetkP 6.50% 4.40% 2.35%R 83.61% 86.78% 89.23%NSPP 6.61% 4.46% 2.48%R 83.61% 85.73% 89.41%UCSP 6.96% 4.91% 2.77%R 96.19% 95.65% 96.88%Table 2: (P)recision and (R)ecall of en nominal candidates,comparison across corpus sizes (S)mall, (M)edium and (L)arge.like filters after extraction; (ii) there is no preliminary fil-tering in mwetk and NSP, they simply return all candi-dates matching a pattern, while LocMax filters the candi-dates based on the local maxima criterion; (iii) LocMaxonly extracts contiguous candidates while the others al-low discontiguous candidates.
The way mwetk and NSPextract discontiguous candidates differs: the former ex-tracts all verbs with particles no further than 5 positions tothe right.
NSP extracts bigrams in a window of 5 words,and then filters the list keeping only those in which thefirst word is a verb and that contain a particle.
However,the results are similar, with slightly better values for NSP.The evaluation of en nominal candidates according tocorpus size is shown in Table 2.14 For all approaches,precision decreases when the corpus size increases asmore noise is returned, while recall increases for all ex-cept LocMax.
This may be due to the latter ignoringsmaller n-grams when larger candidates containing thembecome sufficiently frequent, as is the case when the cor-pus increases.
Table 3 shows that the candidates extractedby LocMax are almost completely covered by the candi-dates extracted by the other approaches.
The relaxed ver-sion extracts slighly more candidates, but still much lessthan mwetk, NSP and UCS, which all extract a similarset of candidates.
In order to distinguish the performanceof the approaches, we need to analyse the AMs they useto rank the candidates.4.2 Association MeasuresTraditionally, to evaluate an AM, the candidates areranked according to it and a threshold value is applied,below which the candidates are discarded.
However, ifwe average the precision considering all true MWEs as14It was not possible to evaluate LocMax-R on the large corpus asthe provided implementation did not support corpora of this magnitude.LocMax-SLocMax-RmwetkNSPUCSTotalverbsLocMax-S ?
124 124 122 124 124LocMax-R 4747 ?
156 153 156 156mwetk 4738 4862 ?
1565 1926 1926NSP 4756 4879 14611 ?
1565 1629UCS 4377 4364 13407 13045 ?
1926Total nouns 4760 4884 15064 14682 13418Table 3: Intersection of the candidate lists extracted frommedium corpus.
Nominal candidates en in bottom left, verbalcandidates en in top right.threshold points, we obtain the mean average precision(MAP) of the measure without setting a hard threshold.Table 4 presents the MAP values for the tested AMs15applied to the candidates extracted from the large cor-pus (L), where the larger the value, the better the perfor-mance.
We used as baseline the assignment of a randomscore and the use of the raw frequency for the candidates.Except for mwetk:t and mwetk:pmi, all MAP valuesare significantly different from the two baselines, with atwo-tailed t test for difference of means assuming unequalsample sizes and variances (p-value < 0.005).The LocMax:glue AM performs best for all typesof MWEs, suggesting local maxima as a good genericMWE indicator and glue as an efficient AM to generatehighly precise results (considering the difficulty of thistask).
On the other hand this approach returns a small setof candidates and this may be problematic depending onthe task (e.g.
for building a wide-coverage lexicon).
Formwetk, the best overall AM is the Dice coefficient; theother measures are not consistently better than the base-line, or perform better for one MWE type than for theother.
The Poisson-Stirling (ps) measure performed quitewell, while the other two measures tested for NSP per-formed below baseline for some cases.
Finally, as we ex-pected, the AMs applied by UCS perform all above base-line and, for nominal MWEs, are comparable to the bestAM (e.g.
Poisson.pv and local.MI).
The MAP for verbalexpressions varies much for UCS (from 30% to 53% ), butnone of the measures comes close to the MAP of the glue(87.06%).
None of the approaches provides a straightfor-ward method to choose or combine different AMs.4.3 Computational resourcesIn the decision of which AM to adopt, factors like the de-gree of MWE flexibility and computational performancemay be taken into account.
For instance, the Dice coef-ficient can be applied to any length of n-gram quite fast15Due to length limitations, we cannot detail the calculation of theevaluated AMs; please refer to the documentation of each approach,cited in ?
2, for more details.4en noun fr noun en verbBaselinerandom 2.749 6.1072 17.2079freq 4.7478 8.7946 22.7155LocMax-Sglue 6.9901 12.9383 87.0614mwetkdice 5.7783 9.5419 46.3609t-test 5.0907 8.6373 26.4185pmi 2.7589 2.9173 53.5591log-lik.
3.166 5.5176 45.8837NSPpmi 2.9902 7.6782 62.1689ps 5.3985 12.3791 57.6238tmi 2.108 4.8928 19.8009UCSz.score 6.1202 11.7657 46.8707Poisson.pv 6.5858 12.8226 32.7737MI 5.1465 9.3363 53.5591relative.risk 5.0999 9.2919 46.6702odds.ratio 5.0364 9.2104 50.2201gmean 6.0101 11.524 45.6089local.MI 6.4294 12.7779 29.9858Table 4: Mean average precision of AMs in large corpus.while more sophisticated measures like Poisson.pv can beapplied only to 2-grams and sometimes use much com-putational resources.
Even if one could argue that we canbe lenient towards a slow offline extraction process, theextra waiting may not be worth a slight quality improve-ment.
Moreover, memory limitations are an issue if nolarge computer clusters are available.In Figure 2, we plotted in log-scale the time in sec-onds used by each approach to extract nominal and ver-bal expressions in en, using a dedicated 2.4GHz quad-core Linux machine with 4Gb RAM.
For nominal expres-sions, time increases linearly with the size of the corpus,whereas for verbal expressions it seems to increase fasterthan the size of the corpus.
UCS is the slowest approachfor both MWE types while NSP and LocMax-S are thefastest.
However, it is important to emphasize that NSPconsumed more than 3Gb memory to extract 4- and 5-grams from the large corpus and LocMax-R could nothandle the large corpus at all.
In theory, all techniques canbe applied to arbitrarily large corpora if we used a map-reduce approach (e.g.
NSP provides tools to split and jointhe corpus).
However, the goal of this evaluation is to dis-cover the performance of the techniques with no manualoptimization.
In this sense, mwetk seems to provide anaverage trade-off between quality and resources used.4.4 FlexibilityTable 5 summarises the characteristics of the approaches.Among them, UCS does not extract candidates from cor-pora but takes as input a list of bigrams and their counts.S M LLocMax-xSRmweweeweeeweeeetSkm-NPoU-xmConuxmn-fmcr---------mn-noan voCb0%12voCb0%13k4m567289L2voCb0%12voCb0%13k4m567289L2Figure 2: Time (seconds, log scale) to extract en nouns (boldline) and verbs (dashed line) from corpora.LocMax mwetk NSP UCSCandidate extraction Yes Yes Yes NoN-grams with n > 2 Yes Yes Yes NoDiscontiguous MWE No Yes Yes ?Linguistic filter No Yes No NoRobust AMs No No Yes YesLarge corpora Partly Yes Yes NoAvailability Free Free Free FreeTable 5: Summary of tools for MWE acquisition.While it only supports n-grams of size 2, NSP imple-ments some of the AMs for 3 and 4-grams and mwetkand LocMax have no constraint on the number of words.LocMax extracts only contiguous MWEs while mwetkallows the extraction of unrestrictedly distant words andNSP allows the specification of a window of maximum wignored words between each two words of the candidate.Only mwetk integrates linguistic filters on the lemma,POS and syntactic annotation, but this was performed us-ing external tools (sed/grep) for the other approaches withsimilar results.
The AMs implemented by LocMax andmwetk are conceived for any size of n-gram and are thusless statistically sound than the clearly designed measuresused by UCS and, to some extent, by NSP (Fisher test).The large corpus used in our experiments was not sup-ported by LocMax-R version, but LocMax-S has a ver-sion that deals with large corpora, as well as mwetk andNSP.
Finally, all of these approaches are freely availablefor download and documented on the web.5 Conclusions and future workWe evaluated the automatic acquisition of MWEs fromcorpora.
The dimensions evaluated were type ofconstruction (for flexibility and contiguity), languageand corpus size.
We evaluated two steps separately:candidate extraction and filtering with AMs.
Can-didate lists are very similar, with approaches like5mwetk and NSP returning more candidates (they covermost of the nominal MWEs in the corpus) but hav-ing lower precision.
LocMax-S presented a remark-ably high precision for verbal expressions.
However,the choice of an AM may not only take into ac-count its MAP but also its flexibility and the compu-tational resources used.
Our results suggest that theapproaches could be combined using machine learn-ing (Pecina, 2005).
The data used in our experi-ments is available at http://www.inf.ufrgs.br/~ceramisch/?page=downloads/mwecompare.In the future, we would like to develop this evaluationfurther by taking into account other characteristics suchas the domain and genre of the source corpus.
Such eval-uation would be useful to guide future research on spe-cialised multiword terminology extraction, determiningdifferences with respect to generic MWE extraction.
Wewould also like to evaluate other MWE-related tasks (e.g.classification, interpretation) and also dictionary-basedidentification (Kulkarni and Finlayson, 2011) and bilin-gual MWE acquisition (Carpuat and Diab, 2010).
Fi-nally, we believe that an application-based extrinsic eval-uation involving manual validation of candidates wouldultimately demonstrate the usefulness of current MWEacquisition techniques.AcknowledgementsThis work was partly funded by the CAMELEON project(CAPES?COFECUB 707-11).ReferencesDimitra Anastasiou, Chikara Hashimoto, Preslav Nakov, andSu Nam Kim, editors.
2009.
Proc.
of the ACL Workshop onMWEs: Identification, Interpretation, Disambiguation, Ap-plications (MWE 2009), Suntec, Singapore, Aug. ACL.Timothy Baldwin.
2008.
A resource for evaluating the deeplexical acquisition of english verb-particle constructions.
InGr?goire et al (Gr?goire et al, 2008), pages 1?2.Marine Carpuat and Mona Diab.
2010.
Task-based evaluationof multiword expressions: a pilot study in statistical machinetranslation.
In Proc.
of HLT: The 2010 Annual Conf.
of theNAACL (NAACL 2003), pages 242?245, Los Angeles, Cali-fornia, Jun.
ACL.Joaquim Ferreira da Silva, Ga?l Dias, Sylvie Guillor?, and Jos?Gabriel Pereira Lopes.
1999.
Using localmaxs algorithm forthe extraction of contiguous and non-contiguous multiwordlexical units.
In Proceedings of the 9th Portuguese Confer-ence on Artificial Intelligence: Progress in Artificial Intelli-gence, EPIA ?99, pages 113?132, London, UK.
Springer.Stefan Evert and Brigitte Krenn.
2005.
Using small randomsamples for the manual evaluation of statistical associationmeasures.
Comp.
Speech & Lang.
Special issue on MWEs,19(4):450?466.Mark Finlayson and Nidhi Kulkarni.
2011.
Detecting multi-word expressions improves word sense disambiguation.
InKordoni et al (Kordoni et al, 2011), pages 20?24.Nicole Gr?goire, Stefan Evert, and Brigitte Krenn, editors.2008.
Proc.
of the LREC Workshop Towards a Shared Taskfor MWEs (MWE 2008), Marrakech, Morocco, Jun.Su Nam Kim and Timothy Baldwin.
2008.
Standardised evalu-ation of english noun compound interpretation.
In Gr?goireet al (Gr?goire et al, 2008), pages 39?42.Valia Kordoni, Carlos Ramisch, and Aline Villavicencio, edi-tors.
2011.
Proc.of the ACL Workshop on MWEs: from Pars-ing and Generation to the Real World (MWE 2011), Portland,OR, USA, Jun.
ACL.Nidhi Kulkarni and Mark Finlayson.
2011. jMWE: A javatoolkit for detecting multi-word expressions.
In Kordoniet al (Kordoni et al, 2011), pages 122?124.
?ric Laporte, Preslav Nakov, Carlos Ramisch, and Aline Villav-icencio, editors.
2010.
Proc.of the COLING Workshop onMWEs: from Theory to Applications (MWE 2010), Beijing,China, Aug. ACL.Darren Pearce.
2002.
A comparative evaluation of collocationextraction techniques.
In Proc.
of the Third LREC (LREC2002), Las Palmas, Canary Islands, Spain, May.
ELRA.Pavel Pecina.
2005.
An extensive empirical study of collo-cation extraction methods.
In Proc.
of the ACL 2005 SRW,pages 13?18, Ann Arbor, MI, USA, Jun.
ACL.Ted Pedersen, Satanjeev Banerjee, Bridget McInnes, SaiyamKohli, Mahesh Joshi, and Ying Liu.
2011.
The ngramstatistics package (text::NSP) : A flexible tool for identify-ing ngrams, collocations, and word associations.
In Kordoniet al (Kordoni et al, 2011), pages 131?133.Carlos Ramisch, Paulo Schreiner, Marco Idiart, and AlineVillavicencio.
2008.
An evaluation of methods for the ex-traction of multiword expressions.
In Gr?goire et al (Gr?-goire et al, 2008), pages 50?53.Carlos Ramisch, Aline Villavicencio, and Christian Boitet.2010.
Multiword expressions in the wild?
the mwetoolkitcomes in handy.
In Yang Liu and Ting Liu, editors, Proc.of the 23rd COLING (COLING 2010) ?
Demonstrations,pages 57?60, Beijing, China, Aug.
The Coling 2010 Orga-nizing Committee.Ivan Sag, Timothy Baldwin, Francis Bond, Ann Copestake, andDan Flickinger.
2002.
Multiword expressions: A pain in theneck for NLP.
In Proc.
of the 3rd CICLing (CICLing-2002),volume 2276/2010 of LNCS, pages 1?15, Mexico City, Mex-ico, Feb. Springer.Violeta Seretan.
2008.
Collocation extraction based on syn-tactic parsing.
Ph.D. thesis, University of Geneva, Geneva,Switzerland.Joaquim Silva and Gabriel Lopes.
1999.
A local maximamethod and a fair dispersion normalization for extractingmulti-word units from corpora.
In Proceedings of the SixthMeeting on Mathematics of Language (MOL6), pages 369?381, Orlando, FL, USA, Jul.Ying Xu, Randy Goebel, Christoph Ringlstetter, and GrzegorzKondrak.
2010.
Application of the tightness continuummeasure to chinese information retrieval.
In Laporte et al(Laporte et al, 2010), pages 54?62.6
