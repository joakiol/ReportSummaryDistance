Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1650?1659,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsNeural Sentiment Classification with User and Product AttentionHuimin Chen1, Maosong Sun1,2?, Cunchao Tu1, Yankai Lin1, Zhiyuan Liu11Department of Computer Science and Technology,State Key Lab on Intelligent Technology and Systems,National Lab for Information Science and Technology, Tsinghua University, Beijing, China2Beijing Advanced Innovation Center for Imaging Technology,Capital Normal University, Beijing, ChinaAbstractDocument-level sentiment classification aimsto predict user?s overall sentiment in a doc-ument about a product.
However, most ofexisting methods only focus on local text in-formation and ignore the global user pref-erence and product characteristics.
Eventhough some works take such informationinto account, they usually suffer from highmodel complexity and only consider word-level preference rather than semantic levels.To address this issue, we propose a hierarchi-cal neural network to incorporate global userand product information into sentiment clas-sification.
Our model first builds a hierar-chical LSTM model to generate sentence anddocument representations.
Afterwards, userand product information is considered via at-tentions over different semantic levels due toits ability of capturing crucial semantic com-ponents.
The experimental results show thatour model achieves significant and consistentimprovements compared to all state-of-the-art methods.
The source code of this papercan be obtained from https://github.com/thunlp/NSC.1 IntroductionSentiment analysis aims to analyze people?s sen-timents or opinions according to their generatedtexts and plays a critical role in the area of datamining and natural language processing.
Recently,sentiment analysis draws increasing attention of re-searchers with the rapid growth of online review?Corresponding author: M. Sun (sms@tsinghua.edu.cn)sites such as Amazon, Yelp and IMDB, due to itsimportance to personalized recommendation.In this work, we focus on the task of document-level sentiment classification, which is a fundamen-tal problem of sentiment analysis.
Document-levelsentiment classification assumes that each docu-ment expresses a sentiment on a single product andtargets to determine the overall sentiment about theproduct.Most existing methods take sentiment classifica-tion as a special case of text classification problem.Such methods treat annotated sentiment polaritiesor ratings as categories and apply machine learningalgorithms to train classifiers with text features, e.g.,bag-of-words vectors (Pang et al, 2002).
Since theperformance of text classifiers heavily depends onthe extracted features, such studies usually attend todesign effective features from text or additional sen-timent lexicons (Ding et al, 2008; Taboada et al,2011).Motivated by the successful utilization of deepneural networks in computer vision (Ciresan et al,2012), speech recognition (Dahl et al, 2012) andnatural language processing (Bengio et al, 2006),some neural network based sentiment analysis mod-els are proposed to learn low-dimensional text fea-tures without any feature engineering (Glorot et al,2011; Socher et al, 2011; Socher et al, 2012;Socher et al, 2013; Kim, 2014).
Most proposedneural network models take the text information ina sentence or a document as input and generate thesemantic representations using well-designed neu-ral networks.
However, these methods only focus1650on the text content and ignore the crucial character-istics of users and products.
It is a common sensethat the user?s preference and product?s characteris-tics make significant influence on the ratings.To incorporate user and product information intosentiment classification, (Tang et al, 2015b) bringin a text preference matrix and a representation vec-tor for each user and product into CNN sentimentclassifier.
It modifies the word meaning in the in-put layer with the preference matrix and concate-nates the user/product representation vectors withgenerated document representation before softmaxlayer.
The proposed model achieves some im-provements but suffers the following two problems:(1) The introduction of preference matrix for eachuser/product is insufficient and difficult to be welltrained with limited reviews.
For example, mostusers in IMDB and Yelp only have several tens ofreviews, which is not enough to obtain a well-tunedpreference matrix.
(2) The characteristics of userand product should be reflected on the semanticlevel besides the word level.
For example, a twostar review in Yelp said ?great place to grab a steakand I am a huge fan of the hawaiian pizza ?
?
?
butI don?t like to have to spend 100 bucks for a dinerand drinks for two?.
It?s obvious that the poor ratingresult mainly relies on the last sentence comparedwith others.To address these issues, we propose a novel hier-archical LSTM model to introduce user and prod-uct information into sentiment classification.
Asillustrated in Fig.
1, our model mainly consists oftwo parts.
Firstly, we build a hierarchical LSTMmodel to generate sentence-level representation anddocument-level representation jointly.
Afterwards,we introduce user and product information as atten-tions over different semantic levels of a document.With the consideration of user and product informa-tion, our model can significantly improve the per-formance of sentiment classification in several real-world datasets.To summarize, our effort provide the followingthree contributions:(1) We propose an effective Neural SentimentClassification model by taking global user and prod-uct information into consideration.
Comparingwith (Tang et al, 2015b), our model contains muchless parameters and is more efficient for training.
(2) We introduce user and product informationbased attentions over different semantic levels of adocument.
Traditional attention-based neural net-work models only take the local text informationinto consideration.
In contrast, our model puts for-ward the idea of user-product attention by utilizingthe global user preference and product characteris-tics.
(3) We conduct experiments on several real-world datasets to verify the effectiveness of ourmodel.
The experimental results demonstrate thatour model significantly and consistently outper-forms other state-of-the-art models.2 Related WorkWith the trends of deep learning in computer vi-sion, speech recognition and natural language pro-cessing, neural models are introduced into senti-ment classification field due to its ability of textrepresentation learning.
(Glorot et al, 2011) useStacked Denoising Autoencoder in sentiment clas-sification for the first time.
Socher conducts a se-ries of recursive neural network models to learnrepresentations based on the recursive tree struc-ture of sentences, including Recursive Autoen-coder (RAE) (Socher et al, 2011), Matrix-VectorRecursive Neural Network (MV-RNN) (Socher etal., 2012) and Recursive Neural Tensor Network(RNTN) (Socher et al, 2013).
Besides, (Kim, 2014)and (Johnson and Zhang, 2014) adopt convolutionneural network (CNN) to learn sentence representa-tions and achieve outstanding performance in senti-ment classification.Recurrent neural network also benefits sentimentclassification because it is capable of capturing thesequential information.
(Li et al, 2015), (Tai etal., 2015) investigate tree-structured long-short termmemory (LSTM) networks on text or sentimentclassification.
There are also some hierarchicalmodels proposed to deal with document-level senti-ment classification (Tang et al, 2015a; Bhatia et al,2015), which generate different levels (e.g., phrase,sentence or document) of semantic representationswithin a document.
Moreover, attention mecha-nism is also introduced into sentiment classification,which aims to select important words from a sen-1651WordRepresentationLSTMLayerLSTMLayerSentenceRepresentationDocumentRepresentationSentenceLevelWordLevelSentence AttentionWord Attention11w 21w 11lw11h 21h l11h1h 2h hn1sdu p1S 2S Sn12w 22w 2lw2212h l22h2h2s2nw2nh1nw nnlw1nh lnnhsnFigure 1: The architecture of User Product Attention based Neural Sentiment Classification model.tence or sentences from a document (Yang et al,2016).Most existing sentiment classification models ig-nore the global user preference and product charac-teristics, which have crucial effects on the sentimentpolarities.
To address this issue, (Tang et al, 2015b)propose to add user/product preference matrices andrepresentation vectors into CNN models.
Neverthe-less, it suffers from high model complexity and onlyconsiders word-level preference rather than seman-tic levels.
In contrast, we propose an efficient neuralsentiment classification model with users and prod-ucts to serve as attentions in both word and semanticlevels.3 MethodsIn this section, we will introduce our User Prod-uct Attention (UPA) based Neural Sentiment Clas-sification (NSC) model in detail.
First, we give theformalizations of document-level sentiment classi-fication.
Afterwards, we discuss how to obtain doc-ument semantic representation via the HierarchicalLong Short-term Memory (HLSTM) network .
Atlast, we present our attention mechanisms which in-corporates the global information of users and prod-ucts to enhance document representations.
The en-hanced document representation is used as featuresfor sentiment classification.
An overall illustrationof UPA based NSC model is shown in Fig.
1.3.1 FormalizationsSuppose a user u ?
U has a review about a prod-uct p ?
P .
We represent the review as a document dwith n sentences {S1,S2, ?
?
?
,Sn}.
Here, li is thelength of i-th sentence.
The i-th sentence Si con-sists of li words as {wi1, wi2, ?
?
?
, wili}.
Document-level sentiment classification aims to predict thesentiment distributions or ratings of these reviewsaccording to their text information.3.2 Neural Sentiment Classification ModelAccording to the principle of compositionality(Frege, 1892), we model the semantic of a docu-ment through a hierarchical structure composed ofword-level, sentence-level and document-level.
Tomodel the semantic representations of sentences, weadopt Long Short-Term Memory (LSTM) networkbecause of its excellent performance on sentimentclassification, especially for long documents.
Sim-ilarly, we also use LSTM to learn document repre-sentations.In word level, we embed each word in a sentenceinto a low dimensional semantic space.
That means,each word wij is mapped to its embedding wij ?
Rd.At each step, given an input word wij , the currentcell state cij and hidden state hij can be updated withthe previous cell state cij?1 and hidden state hij?1 as1652follows:?
?iijf ijoij??
=???????
(W ?
[hij?1,wij]+ b), (1)c?ij = tanh(W ?
[hij?1,wij]+ b), (2)cij = f ij  cij?1 + iij  c?ij , (3)hij = oij  tanh(cij), (4)where i, f ,o are gate activations,  stands forelement-wise multiplication, ?
is sigmoid function,W,b are the parameters we need to train.
We thenfeed hidden states [hi1,hi2, ?
?
?
,hili ] to an averagepooling layer to obtain the sentence representationsi.In sentence level, we also feed the sentence em-beddings [s1, s2, ?
?
?
, sn] into LSTM and then ob-tain the document representation d through an aver-age pooling layer in a similar way.3.3 User Product AttentionWe bring in User Product Attention to capture thecrucial components over different semantic levelsfor sentiment classification.
Specifically, we em-ploy word-level UPA to generate sentence represen-tations and sentence-level UPA to obtain documentrepresentation.
We give the detailed implementa-tions in the following parts.It is obvious that not all words contribute equallyto the sentence meaning for different users andproducts.
Hence, in word level, instead of feed-ing hidden states to an average pooling layer, weadopt a user product attention mechanism to extractuser/product specific words that are important tothe meaning of sentence.
Finally, we aggregate therepresentations of those informative words to formthe sentence representation.
Formally, the enhancedsentence representation is a weighted sum of hiddenstates as:si =li?j=1?ijhij , (5)where ?ij measures the importance of the j-th wordfor current user and product.
Here, we embed eachuser u and each product p as continuous and real-valued vectors u ?
Rdu and p ?
Rdp , where duand dp are the dimensions of user embeddings andproduct embeddings respectively.
Thus, the atten-tion weight ?ij for each hidden state can be definedas:?ij =exp(e(hij ,u,p))?lik=1 exp(e(hik,u,p)), (6)where e is a score function which scores the impor-tance of words for composing sentence representa-tion.
The score function e is defined as:e(hij ,u,p) =vT tanh(WHhij +WUu+WPp+ b),(7)where WH , WU and WP are weight matrices, v isweight vector and vT denotes its transpose.The sentences that are clues to the meaning ofthe document vary in different users and products.Therefore, in sentence level, we also use a attentionmechanism with user vector u and product vectorp in word level to select informative sentences tocompose the document representation.
The docu-ment representation d is obtained via:d =n?i=1?ihi, (8)where ?i is the weight of hidden state hi in sentencelevel which can be calculated similar to the wordattention.3.4 Sentiment ClassificationSince document representation d is hierarchicallyextracted from the words and sentences in the doc-uments, it is a high level representation of the docu-ment.
Hence, we regard it as features for documentsentiment classification.
We use a non-linear layerto project document representation d into the targetspace of C classes:d?
= tanh(Wcd+ bc).
(9)Afterwards, we use a softmax layer to obtain thedocument sentiment distribution:pc =exp(d?c)?Ck=1 exp(d?k), (10)where C is the number of sentiment classes, pc isthe predicted probability of sentiment class c. In1653Datasets #classes #docs #users #products #docs/user #docs/product #sens/doc #words/senIMDB 10 84,919 1,310 1,635 64.82 51.94 16.08 24.54Yelp 2014 5 231,163 4,818 4,194 47.97 55.11 11.41 17.26Yelp 2013 5 78,966 1,631 1,633 48.42 48.36 10.89 17.38Table 1: Statistics of IMDB, Yelp2013 and Yelp2014 datasetsour model, cross-entropy error between gold senti-ment distribution and our model?s sentiment distri-bution is defined as loss function for optimizationwhen training:L = ?
?d?DC?c=1pgc(d) ?
log(pc(d)), (11)where pgc is the gold probability of sentiment classc with ground truth being 1 and others being 0, Drepresents the training documents.4 ExperimentsIn this section, we introduce the experimental set-tings and empirical results on the task of document-level sentiment classification.4.1 Experimental SettingsWe evaluate the effectiveness of our NSC modelon three sentiment classification datasets with userand product information: IMDB, Yelp 2013 andYelp 2014, which are built by (Tang et al, 2015b).The statistics of the datasets are summarized inTable 1.
We split the datasets into training, de-velopment and testing sets in the proportion of8:1:1, with tokenization and sentence splitting byStanford CoreNLP (Manning et al, 2014).
Weuse two metrics including Accuracy which mea-sures the overall sentiment classification perfor-mance andRMSE which measures the divergencesbetween predicted sentiment classes and groundtruth classes.
The Accuracy and RMSE metricsare defined as:Accuracy = TN (12)RMSE =?
?Ni=1(gdi ?
pri)2N , (13)where T is the numbers of predicted sentiment rat-ings that are identical with gold sentiment ratings,N is the numbers of documents and gdi, pri repre-sent the gold sentiment rating and predicted senti-ment rating respectively.Word embeddings could be randomly initializedor pre-trained.
We pre-train the 200-dimensionalword embeddings on each dataset in (Tang et al,2015a) with SkipGram (Mikolov et al, 2013).
Weset the user embedding dimension and product em-bedding dimension to be 200, initialized to zero.The dimensions of hidden states and cell states inour LSTM cells are set to 200.
We tune the hy-per parameters on the development sets and useadadelta (Zeiler, 2012) to update parameters whentraining.
We select the best configuration based onperformance on the development set, and evaluatethe configuration on the test set.4.2 BaselinesWe compare our NSC model with several base-line methods for document sentiment classification:Majority regards the majority sentiment cate-gory in training set as the sentiment category of eachdocument in test set.Trigram trains a SVM classifier with unigrams,bigrams and trigrams as features.TextFeature extracts text features includingword and character n-grams, sentiment lexicon fea-tures, etc, and then train a SVM classifier.UPF extracts use-leniency features (Gao et al,2013) and corresponding product features fromtraining data, which is further concatenated with thefeatures in Trigram an TextFeature.AvgWordvec averages word embeddings in adocument to obtain document representation whichis fed into a SVM classifier as features.SSWE generates features with sentiment-specificword embeddings (SSWE) (Tang et al, 2014) andthen trains a SVM classifier.RNTN + RNN represents each sentence with theRecursive Neural Tensor Network (RNTN) (Socheret al, 2013) and feeds sentence representations into1654Models IMDB Yelp2013 Yelp2014Acc.
RMSE Acc.
RMSE Acc.
RMSEModels without user and product informationMajority 0.196 2.495 0.411 1.060 0.392 1.097Trigram 0.399 1.783 0.569 0.814 0.577 0.804TextFeature 0.402 1.793 0.556 0.845 0.572 0.800AvgWordvec + SVM 0.304 1.985 0.526 0.898 0.530 0.893SSWE + SVM 0.312 1.973 0.549 0.849 0.557 0.851Paragraph Vector 0.341 1.814 0.554 0.832 0.564 0.802RNTN + Recurrent 0.400 1.764 0.574 0.804 0.582 0.821UPNN (CNN and no UP) 0.405 1.629 0.577 0.812 0.585 0.808NSC 0.443 1.465 0.627 0.701 0.637 0.686NSC + LA 0.487 1.381 0.631 0.706 0.630 0.715Models with user and product informationTrigram + UPF 0.404 1.764 0.570 0.803 0.576 0.789TextFeature + UPF 0.402 1.774 0.561 1.822 0.579 0.791JMARS N/A 1.773 N/A 0.985 N/A 0.999UPNN (CNN) 0.435 1.602 0.596 0.784 0.608 0.764UPNN (NSC) 0.471 1.443 0.631 0.702 N/A N/ANSC+UPA 0.533 1.281 0.650 0.692 0.667 0.654Table 2: Document-level sentiment classification results.
Acc.
(Accuracy) and RMSE are the evaluation metrics.
The best perfor-mances are in bold in both groups.the Recurrent Neural Network (RNN).
Afterwards,the hidden vectors of RNN are averaged to obtaindocument representation for sentiment classifica-tion.Paragraph Vector implements the PVDM (Leand Mikolov, 2014) for document sentiment clas-sification.JMARS considers the information of users andaspects with collaborative filtering and topic model-ing for document sentiment classification.UPNN brings in a text preference matrix and arepresentation vector for each user and product intoCNN sentiment classifier (Kim, 2014).
It modifiesthe word meaning in the input layer with the prefer-ence matrix and concatenates the user/product rep-resentation vectors with generated document repre-sentation before softmax layer.For all baseline methods above, we report the re-sults in (Tang et al, 2015b) since we use the samedatasets.4.3 Model ComparisonsWe list the experimental results in Table 2.
Asshown in this table, we manually divide the resultsinto two parts, the first one of which only considersthe local text information and the other one incorpo-rates both local text information and the global userproduct information.From the first part in Table 2, we observe thatNSC, the basic implementation of our model, sig-nificantly outperforms all the other baseline meth-ods which only considers the local text informa-tion.
To be specific, NSC achieves more than 4%improvements over all datasets compared to typicalwell-designed neural network models.
It demon-strates that NSC is effective to capture the sequen-tial information, which can be a crucial factor tosentiment classification.
Moreover, we employ theidea of local semantic attention (LA) in (Yang etal., 2016) and implement it in NSC model (denotedas NSC+LA).
The results shows that the attentionbased NSC obtains a considerable improvementsthan the original one.
It proves the importance ofselecting more meaningful words and sentences insentiment classification, which is also a main reasonof introducing global user and product informationin an attention form.In the second part of Table 2, we show the per-formance of models with user product information.From this part, we have the following observations:(1) The global user and product information is1655Basic Model Level IMDB Yelp2013 Yelp2014Word Sentence Acc RMSE Acc RMSE Acc RMSENSCAVG AVG 0.443 1.465 0.627 0.701 0.637 0.686AVG ATT 0.498 1.336 0.632 0.701 0.653 0.672ATT AVG 0.513 1.330 0.640 0.686 0.662 0.657ATT ATT 0.533 1.281 0.650 0.692 0.667 0.654Table 3: Effect of attention mechanisms in word and sentence level.
AVG means an average pooling layer, and ATT representsthe attention mechanism in word or sentence level.Basic Model Attention Type IMDB Yelp2013 Yelp2014Acc RMSE Acc RMSE Acc RMSENSCATT 0.487 1.381 0.631 0.706 0.630 0.715PA 0.485 1.456 0.630 0.704 0.644 0.676UA 0.525 1.276 0.645 0.699 0.644 0.680UPA 0.533 1.281 0.650 0.692 0.667 0.654Table 4: Effect of user and product attention mechanisms.
UA represents the user attention mechanism, and PA indicates theproduct attention mechanism.helpful to neural network based models for senti-ment classification.
With the consideration of suchinformation in IMDB, UPNN achieves 3% improve-ment and our proposed NSC+UPA obtains 9% im-provement in accuracy.
The significant improve-ments state the necessity of considering these globalinformation in sentiment classification.
(2) Our proposed NSC model with user produc-tion attention (NSC+UPA) significantly and consis-tently outperforms all the other baseline methods.
Itindicates the flexibility of our model on various real-world datasets.
Note that, we also implement (Tanget al, 2015b)?s method to deal with user and prod-uct information on NSC (denoted as UPNN (NSC)).Though the employment of NSC improves the per-formance of UPNN, it is still not comparable to ourmodel.
More specifically, UPNN exceed the mem-ory of our GPU (12G) when dealing with Yelp2014dataset due to the high complexity of its parame-ters.
Compared to UPNN which utilizes the userproduct information with matrices and vectors si-multaneously, our model only embeds each user andproduct as a vector, which makes it suitable to large-scale datasets.
It demonstrates that our NSC modelis more effective and efficient to handle additionaluser and product information.Observations above demonstrate that NSC withuser product attention (NSC+UPA) is capable ofcapturing meanings of multiple semantic layerswithin a document.
Comparing with other userproduct based models, our model incorporatesglobal user product information in an effective andefficient way.
Furthermore, the model is also robustand achieves consistent improvements than state-of-the-art methods on various real-world datasets.4.4 Model Analysis: Effect of AttentionMechanisms in Word and Sentence LevelTable 3 shows the effect of attention mechanismsin word or sentence level respectively.
From thetable, we can observe that: (1) Both the atten-tion mechanisms applied in word level and sentencelevel improve the performance for document senti-ment classification compared with utilizing averagepooling in word and sentence level; (2) The atten-tion mechanism in word level improves more for ourmodel as compared to sentence level.
The reason isthat the word attention mechanism can capture theinformative words in all documents, while the sen-tence attention mechanism may only work in longdocuments with various topics.
(3) The model con-sidering both word level attention and sentence levelattention outperforms the ones considering only onesemantic level attention.
It proves that the charac-teristics of users and products are reflected on mul-tiple semantic levels, which is also a critical mo-tivation of introducing User Product Attention intosentiment classification.16560 100 200 300 400 500 600 700 800 900 10000.40.450.50.550.60.650.70.75Input document lengthAccuracyNSC+UPAUPNN(NSC)NSC+LANSC(a) Accuracy over document length0 5 10 15 20 25 30 350.350.40.450.50.550.6Input sentence numberAccuracyNSC+UPAUPNN(NSC)NSC+LANSC(b) Accuracy over sentence numberFigure 2: Accuracy over various input document lengths on IMDB test set4.5 Model Analysis: Effect of User ProductAttention MechanismsTable 4 shows the performance of attention mech-anisms with the information of users or products.From the table, we can observe that:(1) The information of both users and productscontributes to our model as compared to a semanticattention.
It demonstrates that our attention mech-anism can catch the specific characteristic of a useror a product.
(2) The information of users is more effectivethan the products to enhance document representa-tions.
Hence, the discrimination of user preferenceis more obvious than product characteristics.4.6 Model Analysis: Performance overSentence Numbers and LengthsTo investigate the performance of our modelover documents with various lengths, we comparethe performance of different implementations ofNSC under different document lengths and sentencenumber settings.
Fig.
2 shows the accuracy of sen-timent classification generated by NSC, NSC+ATT,UPNN(NSC) and NSC+UPA on the IMDB test setwith respect to input document lengths and inputsentence numbers in a document.
From Fig.
2, weobserve that our model NSC with attention mecha-nism of user and product information consistentlyoutperforms other baseline methods for all inputdocument lengths and sentence numbers.
It indi-cates the robustness and flexibility of NSC on dif-ferent datasets.4.7 Case StudyGreat   wine        ,        great  ambiance  ,      amazing  music      !User1     PreferenceLocalAttentionUser2    PreferenceFigure 3: Visualization of attentions over wordsTo demonstrate the effectiveness of our global at-tention, we provide a review instance in Yelp2013dataset for example.
The content of this review is?Great wine, great ambiance, amazing music!?.
Wevisualize the attention weights in word-level for twodistinct users and the local semantic attention (LA)in Fig 3.
Here, the local semantic attention rep-resents the implementation in (Yang et al, 2016),which calculates the attention without consideringthe global information of users and products.
Notethat, darker color means lower weight.According to our statistics, the first user oftenmentions ?wine?
in his/her review sentences.
Onthe contrary, the second user never talks about?wine?
in his/her review sentences.
Hence, we in-fer that the first user may has special preference towine while the second one has no concern aboutwine.
From the figure, we observe an interestingphenomenon which confirms to our inference.
Forthe word ?wine?, the first user has the highest atten-1657tion weight and the second user has the lowest atten-tion weight.
It indicates that our model can capturethe global user preference via our user attention.5 Conclusion and Future WorkIn this paper, we propose a hierarchical neuralnetwork which incorporates user and product in-formation via word and sentence level attentions.With the user and product attention, our model cantake account of the global user preference and prod-uct characteristics in both word level and semanticlevel.
In experiments, we evaluate our model onsentiment analysis task.
The experimental resultsshow that our model achieves significant and consis-tent improvements compared to other state-of-the-art models.We will explore more in future as follows:(1) In this paper, we only consider the global userpreference and product characteristics according totheir personal behaviors.
In fact, most users andproducts usually have some text information suchas user and product profiles.
We will take advan-tages of those information in sentiment analysis infuture.
(2) Aspect level sentiment classification is alsoa fundamental task in the field of sentiment analy-sis.
The user preference and product characteristicsmay also implicitly influence the sentiment polarityof the aspect.
We will explore the effectiveness ofour model on aspect level sentiment classification.6 AcknowledgementsThis work is supported by the National So-cial Science Foundation of China (13&ZD190) andthe National Natural Science Foundation of China(NSFC No.
61331013).
We sincerely thank ShiqiShen and Lei Xu for their insightful discussions,and thank Ayana, Yu Zhao, Ruobing Xie, JiachengZhang and Meng Zhang in Tsinghua UniversityNatural Language Processing group for their con-structive comments.
We also thank all anonymousreviewers for their insightful suggestions.ReferencesYoshua Bengio, Holger Schwenk, Jean-Se?bastienSene?cal, Fre?deric Morin, and Jean-Luc Gauvain.2006.
Neural probabilistic language models.
InInnovations in Machine Learning, pages 137?186.Springer.Parminder Bhatia, Yangfeng Ji, and Jacob Eisenstein.2015.
Better document-level sentiment analysis fromrst discourse parsing.
In Proceedings of EMNLP.Dan Ciresan, Ueli Meier, and Ju?rgen Schmidhuber.2012.
Multi-column deep neural networks for imageclassification.
In Proceedings of CVPR, pages 3642?3649.
IEEE.George E Dahl, Dong Yu, Li Deng, and Alex Acero.2012.
Context-dependent pre-trained deep neural net-works for large-vocabulary speech recognition.
IEEETrans.
Audio, Speech, and Language Processing,20(1):30?42.Xiaowen Ding, Bing Liu, and Philip S Yu.
2008.
Aholistic lexicon-based approach to opinion mining.
InProceedings of WSDM, pages 231?240.
ACM.Gottlob Frege.
1892.
On sense and reference.
In Lud-low.Wenliang Gao, Naoki Yoshinaga, Nobuhiro Kaji, andMasaru Kitsuregawa.
2013.
Modeling user leniencyand product popularity for sentiment classification.
InProceedings of IJCNLP, pages 1107?1111.Xavier Glorot, Antoine Bordes, and Yoshua Bengio.2011.
Domain adaptation for large-scale sentimentclassification: A deep learning approach.
In Proceed-ings of ICML, pages 513?520.Rie Johnson and Tong Zhang.
2014.
Effective use ofword order for text categorization with convolutionalneural networks.
arXiv preprint arXiv:1412.1058.Yoon Kim.
2014.
Convolutional neural networks forsentence classification.
In Proceedings of EMNLP.Quoc V Le and Tomas Mikolov.
2014.
Distributed rep-resentations of sentences and documents.
In Proceed-ings of ICML.Jiwei Li, Dan Jurafsky, and Eudard Hovy.
2015.
Whenare tree structures necessary for deep learning of rep-resentations?
arXiv preprint arXiv:1503.00185.Christopher D Manning, Mihai Surdeanu, John Bauer,Jenny Rose Finkel, Steven Bethard, and David Mc-Closky.
2014.
The stanford corenlp natural languageprocessing toolkit.
In Proceedings of ACL, pages 55?60.Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-frey Dean.
2013.
Efficient estimation of wordrepresentations in vector space.
arXiv preprintarXiv:1301.3781.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
: Sentiment classification us-ing machine learning techniques.
In Proceedings ofEMNLP, pages 79?86.1658Richard Socher, Jeffrey Pennington, Eric H Huang, An-drew Y Ng, and Christopher D Manning.
2011.
Semi-supervised recursive autoencoders for predicting sen-timent distributions.
In Proceedings of EMNLP, pages151?161.Richard Socher, Brody Huval, Christopher D Manning,and Andrew Y Ng.
2012.
Semantic compositionalitythrough recursive matrix-vector spaces.
In Proceed-ings of EMNLP, pages 1201?1211.Richard Socher, Alex Perelygin, Jean Y Wu, JasonChuang, Christopher D Manning, Andrew Y Ng, andChristopher Potts.
2013.
Recursive deep models forsemantic compositionality over a sentiment treebank.In Proceedings of EMNLP, page 1642.Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-berly Voll, and Manfred Stede.
2011.
Lexicon-basedmethods for sentiment analysis.
CL, 37(2):267?307.Kai Sheng Tai, Richard Socher, and Christopher D Man-ning.
2015.
Improved semantic representations fromtree-structured long short-term memory networks.
InProceedings of ACL.Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, Ting Liu,and Bing Qin.
2014.
Learning sentiment-specificword embedding for twitter sentiment classification.In Proceedings of ACL, pages 1555?1565.Duyu Tang, Bing Qin, and Ting Liu.
2015a.
Documentmodeling with gated recurrent neural network for sen-timent classification.
In Proceedings of EMNLP,pages 1422?1432.Duyu Tang, Bing Qin, and Ting Liu.
2015b.
Learn-ing semantic representations of users and products fordocument level sentiment classification.
In Proceed-ings of ACL.Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong He, AlexSmola, and Eduard Hovy.
2016.
Hierarchical atten-tion networks for document classification.
In Pro-ceedings NAACL.Matthew D Zeiler.
2012.
Adadelta: an adaptive learningrate method.
arXiv preprint arXiv:1212.5701.1659
