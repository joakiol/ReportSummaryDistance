Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 225?232Manchester, August 2008A Probabilistic Model for Measuring Grammaticality and Similarityof Automatically Generated Paraphrases of Predicate PhrasesAtsushi Fujita Satoshi SatoGraduate School of Engineering, Nagoya University{fujita,ssato}@nuee.nagoya-u.ac.jpAbstractThe most critical issue in generating andrecognizing paraphrases is developmentof wide-coverage paraphrase knowledge.Previous work on paraphrase acquisitionhas collected lexicalized pairs of expres-sions; however, the results do not ensurefull coverage of the various paraphrasephenomena.
This paper focuses on pro-ductive paraphrases realized by generaltransformation patterns, and addresses theissues in generating instances of phrasalparaphrases with those patterns.
Our prob-abilistic model computes how two phrasesare likely to be correct paraphrases.
Themodel consists of two components: (i) astructured N -gram language model thatensures grammaticality and (ii) a distribu-tional similarity measure for estimating se-mantic equivalence and substitutability.1 IntroductionIn many languages, a concept can be expressedwith several different linguistic expressions.
Han-dling such synonymous expressions in a given lan-guage, i.e., paraphrases, is one of the key issues ina broad range of natural language processing tasks.For example, the technology for identifying para-phrases would play an important role in aggregat-ing the wealth of uninhibited opinions about prod-ucts and services that are available on the Web,from both the consumers and producers viewpoint.On the other hand, whenever we draw up a docu-ment, we always seek the most appropriate expres-sion for conveying our ideas.
In such a situation, asystem that generates and proposes alternative ex-pressions would be extremely beneficial.c?
Atsushi Fujita and Satoshi Sato, 2008.
Licensedunder the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license.
Some rights reserved.http://creativecommons.org/licenses/by-nc-sa/3.0/Most of previous work on generating and recog-nizing paraphrases has been dedicated to develop-ing context-free paraphrase knowledge.
It is typi-cally represented with pairs of fragmentary expres-sions that satisfy the following conditions:Condition 1.
Semantically equivalentCondition 2.
Substitutable in some contextThe most critical issue in developing suchknowledge is ensuring the coverage of the para-phrase phenomena.
To attain this coverage, wehave proposed a strategy for dividing paraphrasephenomena into the following two classes (Fujitaet al, 2007):(1) Non-productive (idiosyncratic) paraphrasesa.
burst into tears ?
criedb.
comfort ?
console(Barzilay and McKeown, 2001)(2) Productive paraphrasesa.
be in our favor ?
be favorable to usb.
show a sharp decrease ?
decrease sharply(Fujita et al, 2007)Typical examples of non-productive paraphrasesare lexical paraphrases such as those shown in (1)and idiomatic paraphrases of literal phrases (e.g.,?kick the bucket?
?
?die?).
Knowledge of thisclass of paraphrases should be stored statically,because they cannot be represented with abstractpatterns.
On the other hand, a productive para-phrase is one having a degree of regularity, asexhibited by the examples in (2).
It is thereforereasonable to represent them with a set of generalpatterns such as those shown in (3).
This attainsa higher coverage, while keeping the knowledgemanageable.
(3) a. N1V N2?
N1?s V -ing of N2b.
N1V N2?
N2be V -en by N1(Harris, 1957)Various methods have been proposed to ac-quire paraphrase knowledge (these are reviewedin Section 2.1) where pairs of existing expres-225sions are collected from the given corpus, tak-ing the above two conditions into account.
On theother hand, another issue arises when paraphraseknowledge is generated from the patterns for pro-ductive paraphrases such as shown in (3) by instan-tiating variables with specific words, namely,Condition 3.
Both expressions are grammaticalThis paper proposes a probabilistic model forcomputing how likely a given pair of expressionssatisfy the aforementioned three conditions.
Inparticular, we focus on the post-generation assess-ment of automatically generated productive para-phrases of predicate phrases in Japanese.In the next section, we review previous ap-proaches and models.
The proposed probabilis-tic model is then presented in Section 3, where thegrammaticality factor and similarity factor are de-rived from a conditional probability.
In Section 4,the settings for and results of an empirical exper-iment are detailed.
Finally, Section 5 summarizesthis paper.2 Previous work2.1 Acquiring paraphrase knowledgeThe task of automatically acquiring paraphraseknowledge is drawing the attention of an increas-ing number of researchers.
They are tackling theproblem of how precisely paraphrase knowledgecan be acquired, although they have tended to no-tice that it is hard to acquire paraphrase knowl-edge that ensures full coverage of the variousparaphrase phenomena from existing text corporaalone.
To date, two streams of research haveevolved: one acquires paraphrase knowledge fromparallel/comparable corpora, while the other usesthe regular corpus.Several alignment techniques have been pro-posed to acquire paraphrase knowledge from par-allel/comparable corpora, imitating the techniquesdevised for machine translation.
Multiple trans-lations of the same text (Barzilay and McKeown,2001), corresponding articles from multiple newssources (Barzilay and Lee, 2003; Quirk et al,2004; Dolan et al, 2004), and bilingual corpus(Bannard and Callison-Burch, 2005) have beenutilized.
Unfortunately, this approach producesonly a low coverage because the size of the par-allel/comparable corpora is limited.In the second stream, i.e., paraphrase acquisitionfrom the regular corpus, the distributional hypothe-sis (Harris, 1968) has been adopted.
The similarityof two expressions, computed from this hypothe-sis, is called distributional similarity.
The essenceof this measure is summarized as follows:Feature representation: to compute the similar-ity, given expressions are first mapped tocertain feature representations.
Expressionsthat co-occur with the given expression, suchas adjacent words (Barzilay and McKeown,2001; Lin and Pantel, 2001), and modi-fiers/modifiees (Yamamoto, 2002; Weeds etal., 2005), have so far been examined.Feature weighting: to precisely compute the sim-ilarity, the weight for each feature is adjusted.Point-wise mutual information (Lin, 1998)and Relative Feature Focus (Geffet and Da-gan, 2004) are well-known examples.Feature comparison measures: to convert twofeature sets into a scalar value, several mea-sures have been proposed, such as cosine,Lin?s measure (Lin, 1998), Kullback-Leibler(KL) divergence and its variants.While most researchers extract fully-lexicalizedpairs of words or word sequences only, two algo-rithms collect template-like knowledge using de-pendency parsers.
DIRT (Lin and Pantel, 2001)collects pairs of paths in dependency parses thatconnect two nominal entities.
TEASE (Szpektor etal., 2004) discovers dependency sub-parses fromtheWeb, based on sets of representative entities fora given lexical item.
The output of these systemscontains the variable slots as shown in (4).
(4) a. X wrote Y ?
X is the author of Yb.
X solves Y ?
X deals with Y(Lin and Pantel, 2001)The knowledge in (4) falls between that in (1),which is fully lexicalized, and that in (3), whichis almost fully abstracted.
As a way of enrich-ing such a template-like knowledge, Pantel et al(2007) proposed the notion of inferential selec-tional preference and collected expressions thatwould fill those slots.As mentioned in Section 1, the aim of the stud-ies reviewed here is to collect paraphrase knowl-edge.
Thus, they need not to take the grammatical-ity of expressions into account.2.2 Generating paraphrase instancesRepresenting productive paraphrases with a set ofgeneral patterns makes them maintainable and at-tains a higher coverage of the paraphrase phe-nomena.
From the transformation grammar (Har-226ris, 1957), this approach has been adopted bymany researchers (Mel?c?uk and Polgue`re, 1987;Jacquemin, 1999; Fujita et al, 2007).
An impor-tant issue arises when such a pattern is used to gen-erate instances of paraphrases by replacing its vari-ables with specific words.
This involves assessingthe grammaticality of two expressions in additionto their semantic equivalence and substitutability.As a post-generation assessment of automati-cally generated productive paraphrases, we haveapplied distributional similarity measures (Fujitaand Sato, 2008).
Our findings from a series of em-pirical experiments are summarized as follows:?
Search engines are useful for retrieving thecontextual features of predicate phrases de-spite some limitations (Kilgarriff, 2007).?
Distributional similarity measures produce atolerable level of performance.The grammaticality of a phrase, however, is merelyassessed by issuing the phrase as a query to a com-mercial search engine.
Although a more frequentexpression is more grammatical, the length biasshould also be considered in the assessment.Quirk et al (2004) built a paraphrase genera-tion model from a monolingual comparable cor-pus based on a statistical machine translationframework, where the language model assessesthe grammaticality of the translations, i.e., gen-erated expressions.
The translation model, how-ever, is not suitable for generating productive para-phrases, because it learns word alignments at thesurface level.
To cover all of the productive para-phrases, we require an non-real comparable corpusin which all instances of productive paraphraseshave a chance of being aligned.
Furthermore, asthe translation model optimizes the word align-ment at the sentence level, the substitutability ofthe aligned word sequences cannot be explicitlyguaranteed.2.3 Existing measures for paraphrasesTo date, no model has been established that takesinto account all of the three aforementioned condi-tions.
With the ultimate aim of building an idealmodel, this section overviews the characteristicsand drawbacks of the four existing measures.Lin?s measureLin (1998) proposed a symmetrical measure:ParLin(s ?
t) =?f?Fs?Ft(w(s, f) + w(t, f))?f?Fsw(s, f) +?f?Ftw(t, f),where Fsand Ftdenote sets of features with posi-tive weights for words s and t, respectively.Although this measure has been widely citedand has so far exhibited good performance, itssymmetry seems unnatural.
Moreover, it maynot work well for dealing with general predicatephrases because it is hard to enumerate all phrasesto determine the weights of features w(?, f).
Wethus simply adopted the co-occurrence frequencyof the phrase and the feature as in (Fujita and Sato,2008).Skew divergenceThe skew divergence, a variant of KL diver-gence, was proposed in (Lee, 1999) based on aninsight: the substitutability of one word for anotherneed not be symmetrical.
The divergence is givenby the following formula:dskew(t, s) = D (Ps?
?Pt+ (1?
?
)Ps) ,where Psand Ptare the probability distributionsof features for the given original and substitutedwords s and t, respectively.
0 ?
?
?
1 is a pa-rameter for approximating KL divergence D. Thescore can be recast into a similarity score via, forexample, the following function (Fujita and Sato,2008):Parskew(s?t) = exp (?dskew(t, s)) .This measure offers an advantage: the weightfor each feature is determined theoretically.
How-ever, the optimization of ?
is difficult because itvaries according to the task and even the data size(confidence of probability distributions).Translation-based conditional probabilityBannard and Callison-Burch (2005) proposeda probabilistic model for acquiring phrasal para-phrases1.
The likelihood of t as a paraphrase ofthe given phrase s is defined as follows:P (t|s) =?f?tr(s)?tr(t)P (t|f)P (f |s),where tr (e) stands for a set of foreign languagephrases that are aligned with e in the given paral-lel corpus.
Parameters P (t|f) and P (f |s) are alsoestimated using the given parallel corpus.
A large-scale parallel corpus may enable us to precisely ac-quire a large amount of paraphrase knowledge.
It1In their definition, the term ?phrase?
is a sequence ofwords, while in this paper it designates the subtrees governedby predicates (Fujita et al, 2007).227is not feasible, however, to build (or obtain) a par-allel corpus in which all the instances of productiveparaphrases are translated to the same expressionin the other side of language.3 Proposed probabilistic model3.1 Formulation with conditional probabilityRecall that our aim is to establish a measure thatcomputes the likelihood of a given pair of automat-ically generated predicate phrases satisfying thefollowing three conditions:Condition 1.
Semantically equivalentCondition 2.
Substitutable in some contextCondition 3.
Both expressions are grammaticalBased on the characteristics of the existing mea-sures reviewed in Section 2.3, we propose a proba-bilistic model.
Let s and t be the source and targetpredicate phrase, respectively.
Assuming that s isgrammatical, the degree to which the above con-ditions are satisfied is formalized as a conditionalprobability P (t|s), as in (Bannard and Callison-Burch, 2005).
Then, assuming that s and t areparadigmatic (i.e., paraphrases) and thus do not co-occur, the proposed model is derived as follows:P (t|s) =?f?FP (t|f)P (f |s)=?f?FP (f |t)P (t)P (f)P (f |s)= P (t)?f?FP (f |t)P (f |s)P (f),where F denotes a set of features.
The firstfactor P (t) is called the grammaticality factorbecause it quantifies the degree to which condi-tion 3 is satisfied, except that we assume thatthe given s is grammatical.
The second factor?f?FP (f |t)P (f |s)P (f)(Sim(s, t), hereafter), on theother hand, is called the similarity factor becauseit approximates the degree to which conditions 1and 2 are satisfied by summing up the overlap ofthe features of two expressions s and t.The characteristics and advantages of the pro-posed model are summarized as follows:1) Asymmetric.2) Grammaticality is assessed by P (t).3) No heuristic is introduced.
As the skew diver-gence, the weight of the features can be simplyestimated as conditional probabilities P (f |t)and P (f |s) and marginal probability P (f).4) There is no need to enumerate all the phrases.s and t are merely the given conditions.The following subsections describe each factor.3.2 Grammaticality factorThe factor P (t) quantifies how the phrase t isgrammatical using statistical language model.Unlike English, in Japanese, predicates such asverbs and adjectives do not necessarily determinethe order of their arguments, although they havesome preference.
For example, both of the twosentences in (5) are grammatical.
(5) a. kare-wa pasuta-o hashi-de taberu.he-TOP pasta-ACC chopsticks-IMP to eatHe eats pasta with chopsticks.b.
kare-wa hashi-de pasuta-o taberu.he-TOP chopsticks-IMP pasta-ACC to eatHe eats pasta with chopsticks.This motivates us to use structured N -gram lan-guage models (Habash, 2004).
Given a phrase t,its grammaticality P (t) is formulated as follows,assuming a (N?
1)-th order Markov process forgenerating its dependency structure T (t):P (t) =[?i=1...|T (t)|Pd(ci|d1i, d2i, .
.
.
, dN?1i)]1/|T (t)|,where |T (t)| stands for the number of nodes inT (t).
To ignore the length bias of the target phrase,a normalization factor 1/|T (t)| is introduced.
djidenotes the direct ancestor node of the i-th nodeci, where j is the distance from ci; for example, d1iand d2iare the parent and grandparent nodes of ci,respectively.Then, a concrete definition of the nodes inthe dependency structure is given.
Widely-usedJapanese dependency parsers such as CaboCha2and KNP3 consider a sequence of words as a nodecalled a ?bunsetsu?
that consists of at least onecontent word followed by a sequence of functionwords if any.
The hyphenated word sequences in(6) exemplify those nodes.
(6) kitto kare-ha kyou-nosurely he-TOP today-GENkaigi-ni-ha ko-nai-daro-u.meeting-DAT-TOP to come-NEG-mustHe will surely not come to today?s meeting.As bunsetsu can be quite long, involving morethan ten words, regarding it as a node makesthe model complex.
Therefore, we compare the2http://chasen.org/?taku/software/cabocha/3http://nlp.kuee.kyoto-u.ac.jp/nl-resource/knp.html228<EOS>.
= punc.u = auxda = auxnai = auxiN: nounV: verbAdv: adverbAdvN: adverbial nounPro: pronouncp: case particletp: topic-marking particleap: adnominal particleaux: auxiliary verbpunc: punctuationkuru = Vwa = tptni = cpikaigi = Ni ino = apkyou = AdvNkitto = Advittkare = ProrJapanese base-chunk(bunsetsu)wa = tptFigure 1: MDS of sentence (6).following two versions of dependency structureswhose nodes are smaller than bunsetsu.MDS: Morpheme-based dependency structure(Takahashi et al, 2001) regards a morphemeas a node.
MDS of sentence (6) is shown inFigure 1.CFDS: The node of a content-function-based de-pendency structure is either a sequence ofcontent words or of function words.
CFDSof sentence (6) is shown Figure 2.Structured N -gram language models were cre-ated from 15 years of Mainichi newspaper articles4using a dependency parser Cabocha, with N beingvaried from 1 to 3.
Then, the 3-gram conditionalprobability Pd(ci|d1i, d2i) is given by the linear in-terpolation of those three models as follows:Pd(ci|d1i, d2i) = ?3PML(ci|d1i, d2i)+?2PML(ci|d1i)+?1PML(ci),s.t.
?j?j= 1,where mixture weights ?jare selected via an EMalgorithm using development data5 that has notbeen used for estimating PML.3.3 Similarity factorThe similarity factor Sim(s, t) quantifies how twophrases s and t are similar by comparing two setsof contextual features f ?
F for s and t.4Mainichi 1991-2005 (1.5GB, 21M sentences).5Yomiuri 2005 (350MB, 4.7M sentences) and Asahi 2005(180MB, 2.7M sentences).<EOS>nai-daro-u-.
= Fi .C: Content partF: Function partkuru = Cwa = F ni-wa = Fikaigi = Ci ino = Fkyou = Ckitto = Cittkare = CJapanese base-chunk(bunsetsu)Figure 2: CFDS of sentence (6).We employ the following two types of featuresets, which we have examined in our previouswork (Fujita and Sato, 2008), where a feature fconsists of an expression e and a relation r:BOW: A pair of phrases is likely to be seman-tically similar, if the distributions of thewords surrounding the phrases is similar.The relation set RBOWcontains only ?co-occur in the same sentence?.MOD: A pair of phrases is likely to be substi-tutable with each other, provided they sharea number of instances of modifiers and mod-ifiees: the set of the relation RMODconsistsof two relations ?modifier?
and ?modifiee?.Conditional probability distributions P (f |s)and P (f |t) are estimated using a Web search en-gine as in (Fujita and Sato, 2008).
Given a phrasep, snippets of Web pages are firstly obtained viaYahoo API6 by issuing p as a query.
The max-imum number of snippets is set to 1,000.
Then,the features of the phrase are retrieved from thosesnippets using a morphological analyzer ChaSen7and CaboCha.
Finally, the conditional probabilitydistribution P (f |p) is estimated as follows:P (f |p) = P (?r, e?|p)=freqsni(p, r, e)?r?
?R?e?freqsni(p, r?, e?
),where freqsni(p, r, e) stands for the frequency ofthe expression e appealing with the phrase p in re-lation r within the snippets for p.The weight for features P (f) is estimated usinga static corpus based on the following equation:P (f) = P (?r, e?
)=freqcp(r, e)?r?
?R?e?freqcp(r?, e?
),6http://developer.yahoo.co.jp/search/7http://chasen.naist.jp/hiki/ChaSen/229where freqcp(r, e) indicates the frequency of theexpression e appearing with something in relationr within the given corpus.
Two different sorts ofcorpora are separately used to build two variationsof P (f).
The one is Mainichi, which is used forbuilding structured N -gram language models inSection 3.2, while the other is a huge corpus con-sisting of 470M sentences collected from the Web(Kawahara and Kurohashi, 2006).4 Experiments4.1 DataWe conducted an empirical experiment to evalu-ate the proposed model using the test suite devel-oped in (Fujita and Sato, 2008).
The test suite con-sists of 176,541 pairs of paraphrase candidates thatare automatically generated using a pattern-basedparaphrase generation system (Fujita et al, 2007)for 4,002 relatively high-frequency phrases sam-pled from a newspaper corpus8.To evaluate the system from a generation view-point, i.e., how well a system can rank a correctcandidate first, we extracted paraphrase candidatesfor 200 randomly sampled source phrases fromthe test suite.
Table 1 shows the statistics of thetest data.
The ?All-Yield?
column shows that thenumber of candidates for a source phrase variesconsiderably, which implies that the data containscases that have various difficulties.
While the av-erage number of candidates for each source phrasewas 48.3 (the maximum was 186), it was dramati-cally reduced through extracting features for eachsource and candidate paraphrase from Web snip-pets: to 5.2 with BOW and to 4.8 with MOD.
Thissuggests that a large number of spurious phraseswere generated but discarded by going to the Web,and the task was significantly simplified.4.2 QuestionsThrough this experiment, we evaluated several ver-sions of the proposed model to answer the follow-ing questions:Q1.
Is the proposed model superior to existingmeasures in practice?
ParLinand Parskeware regarded as being the baseline.Q2.
Which language model performs better at es-timating P (t)?
MDS and CFDS are com-pared.Q3.
Which corpus performs better at estimatingP (f)?
The advantage of Kawahara?s huge8The grammaticality of the source phrases are guaranteed.Table 1: Statistics of test data (?Ph.?
: # of phrases).Source All BOW MODPhrase type Ph.
Ph.
Yield Ph.
Yield Ph.
YieldN :C:V 18 57 3.2 54 3.0 54 3.0N1:N2:C:V 57 4,596 80.6 594 10.4 551 9.7N :C:V1:V254 4,767 88.3 255 4.7 232 4.3N :C:Adv:V 16 51 3.2 39 2.4 38 2.4Adj:N :C:V 2 8 4.0 5 2.5 5 2.5N :C:Adj 53 173 3.3 86 1.6 83 1.6Total 200 9,652 48.3 1,033 5.2 963 4.8corpus (WebCP) over Mainichi is evaluated.Q4.
Which set of features performs better?
In ad-dition to BOW and MOD, the harmonic meanof the scores derived from BOW and MOD isexamined (referred to as HAR).Q5.
Can the quality of P (f |s) and P (f |t) be im-proved by using a larger number of snippets?As the maximum number of snippets (NS),we compared 500 and 1,000.4.3 ResultsTwo assessors were asked to judge paraphrase can-didates that are ranked first by either of the abovemodels if each candidate satisfies each of the threeconditions.
The results for all the above optionsare summarized in Table 2, where the strict preci-sion is calculated based on those cases that gaintwo positive judgements, while the lenient preci-sion is for at least one positive judgement.A1: Our greatest concern is the actual perfor-mance of our probabilistic model.
However, novariation of the proposed model could outperformthe existing models (ParLinand Parskew) thatonly assess similarity.
Furthermore, McNemer?stest with p < 0.05 revealed that the precisions ofall the models, except the combination of CFDSfor P (t) and Mainichi for P (f), were significantlyworse than those of the best models.To clarify the cause of these disappointing re-sults, we investigated the performance of each fac-tor.
Table 3 shows how well the grammaticalityfactors select a grammatical phrase, while Table 4illustrates how well the similarity factors rank acorrect paraphrase first.
As shown in these tables,neither factor performed the task well, althoughcombinations produced a slight improvement inperformance.
A detailed discussion is given belowin A2 for the grammaticality factors, and in A3-A5for the similarity factors.A2: Comparisons between MDS and CFDSrevealed that CFDS always produced better re-sults than MDS not only when used for measuringgrammaticality (Table 3), but also when used as a230Table 2: Precision for 200 test cases.NS= 500 Strict LenientModel BOW MOD HAR BOW MOD HARParLin78 (39%) 88 (44%) 87 (44%) 116 (58%) 128 (64%) 127 (64%)Parskew81 (41%) 88 (44%) 88 (44%) 120 (60%) 127 (64%) 128 (64%)MDS, Mainichi 72 (36%) 73 (37%) 76 (38%) 109 (55%) 112 (56%) 114 (57%)MDS, WebCP 71 (36%) 73 (37%) 72 (36%) 108 (54%) 110 (55%) 113 (57%)CFDS, Mainichi 79 (40%) 78 (39%) 83 (42%) 120 (60%) 119 (60%) 123 (62%)CFDS, WebCP 79 (40%) 77 (39%) 80 (40%) 118 (59%) 116 (58%) 118 (59%)NS= 1,000 Strict LenientModel BOW MOD HAR BOW MOD HARParLin79 (40%) 88 (44%) 88 (44%) 116 (58%) 128 (64%) 129 (65%)Parskew84 (42%) 89 (45%) 89 (45%) 121 (61%) 128 (64%) 128 (64%)MDS, Mainichi 72 (36%) 75 (38%) 76 (38%) 109 (55%) 114 (57%) 114 (57%)MDS, WebCP 71 (36%) 74 (37%) 72 (36%) 109 (55%) 111 (56%) 113 (57%)CFDS, Mainichi 79 (40%) 82 (41%) 83 (42%) 121 (61%) 121 (61%) 122 (61%)CFDS, WebCP 79 (40%) 78 (39%) 79 (40%) 119 (60%) 116 (58%) 119 (60%)Table 3: Precision of measuring grammaticality.Model Strict LenientMDS 104 (52%) 141 (71%)CFDS 108 (54%) 142 (71%)Table 4: Precision of similarity factors.Strict LenientNSCorpus BOW MOD HAR BOW MOD HAR500 Mainichi 60 (30%) 68 (34%) 74 (37%) 98 (49%) 109 (55%) 114 (57%)500 WebCP 57 (28%) 61 (31%) 74 (37%) 94 (47%) 99 (50%) 120 (60%)1,000 Mainichi 57 (28%) 70 (35%) 74 (37%) 92 (46%) 113 (57%) 116 (58%)1,000 WebCP 57 (28%) 60 (30%) 72 (36%) 93 (47%) 96 (48%) 116 (58%)component of the entire model (Table 2).
This re-sult is quite natural because MDS cannot verify thecollocation between content words in those caseswhere a number of function words appear betweenthem.
On the other hand, CFDS with N = 3 couldverify this as a result of treating the sequence offunction words as a single node.As mentioned in A1, however, a more sophisti-cated language model must enhance the proposedmodel.
One way of obtaining a suitable granularityof nodes is to introduce latent classes, such as theSemi-Markov class model (Okanohara and Tsujii,2007).
The existence of many orthographic vari-ants of both the content and function words mayprevent us from accurately estimating the gram-maticality.
We plan to normalize these variationsby using several existing resources such as theJapanese functional expression dictionary (Mat-suyoshi, 2008).A3: Contrary to our expectations, the huge Webcorpus did not offer any advantage over the news-paper corpus: Mainichi always produced better re-sults than WebCP when it was combined with thegrammaticality factor or when MOD was used.We can speculate that morphological and depen-dency parsers produce errors when features are ex-tracted, because they are tuned to newspaper arti-cles.
Likewise, P (f |s) and P (f |t) may involvenoise even though they are estimated using rela-tively clean parts of Web text that are retrieved byquerying phrase candidates.A4: For ParLinand Parskew, different sets offeatures led to consistent results with our previousexperiments in (Fujita and Sato, 2008), i.e., BOW< MOD ' HAR.
On the other hand, for the pro-posed models, MOD and HAR led to only smallor sometimes negative effects.
When the similar-ity factor was used alone, however, these featuresbeat BOW.
Furthermore, the impact of combiningBOW and MOD into HAR was significant.Given this tendency, it is expected that the gram-maticality factor might be excessively emphasized.Our probability model was derived straightfor-wardly from the conditional probability P (t|s);however, the combination of the two factors shouldbe tuned according to their implementation.A5: Finally, the influence of the number of Websnippets was analyzed; no significant differencewas observed.This is because we could retrieve more than 500snippets for only 172 pairs of expressions amongour test samples.
As it is time-consuming to ob-tain a large number of Web snippets, the trade-offbetween the number of Web snippets and the per-formance should be investigated further, althoughthe quality of the Web snippets and what appearsat the top of the search results will vary accordingto several factors other than linguistic ones.2315 ConclusionA pair of expressions qualifies as paraphrases iffthey are semantically equivalent, substitutable insome context, and grammatical.
In cases whereparaphrase knowledge is represented with abstractpatterns to attain a high coverage of the paraphrasephenomena, we should assess not only the first andsecond conditions, but also the third condition.In this paper, we proposed a probabilistic modelfor computing how two phrases are likely to beparaphrases.
The proposed model consists of twocomponents: (i) a structured N -gram languagemodel that ensures grammaticality and (ii) a distri-butional similarity measure for estimating seman-tic equivalence and substitutability between twophrases.
Through an experiment, we empiricallyevaluated the performance of the proposed modeland analyzed the characteristics.Future work includes building a more sophis-ticated structured language model to improve theperformance of the proposed model and conduct-ing an experiment on template-like paraphraseknowledge for other than productive paraphrases.ReferencesBannard, Colin and Chris Callison-Burch.
2005.
Paraphras-ing with bilingual parallel corpora.
In Proceedings of the43rd Annual Meeting of the Association for ComputationalLinguistics (ACL), pages 597?604.Barzilay, Regina and Kathleen R. McKeown.
2001.
Extract-ing paraphrases from a parallel corpus.
In Proceedings ofthe 39th Annual Meeting of the Association for Computa-tional Linguistics (ACL), pages 50?57.Barzilay, Regina and Lillian Lee.
2003.
Learning toparaphrase: an unsupervised approach using multiple-sequence alignment.
In Proceedings of the 2003 HumanLanguage Technology Conference and the North AmericanChapter of the Association for Computational Linguistics(HLT-NAACL), pages 16?23.Dolan, Bill, Chris Quirk, and Chris Brockett.
2004.
Unsu-pervised construction of large paraphrase corpora: exploit-ing massively parallel news sources.
In Proceedings of the20th International Conference on Computational Linguis-tics (COLING), pages 350?356.Fujita, Atsushi, Shuhei Kato, Naoki Kato, and Satoshi Sato.2007.
A compositional approach toward dynamic phrasalthesaurus.
In Proceedings of the ACL-PASCAL Workshopon Textual Entailment and Paraphrasing (WTEP), pages151?158.Fujita, Atsushi and Satoshi Sato.
2008.
Computing para-phrasability of syntactic variants using Web snippets.
InProceedings of the 3rd International Joint Conference onNatural Language Processing (IJCNLP), pages 537?544.Geffet, Maayan and Ido Dagan.
2004.
Feature vector qual-ity and distributional similarity.
In Proceedings of the20th International Conference on Computational Linguis-tics (COLING), pages 247?253.Habash, Nizar.
2004.
The use of a structural N-gram lan-guage model in generation-heavy hybrid machine transla-tion.
In Proceedings of the 3rd International Natural Lan-guage Generation Conference (INLG), pages 61?69.Harris, Zellig.
1957.
Co-occurrence and transformation inlinguistic structure.
Language, 33(3):283?340.Harris, Zellig.
1968.
Mathematical structures of language.John Wiley & Sons.Jacquemin, Christian.
1999.
Syntagmatic and paradigmaticrepresentations of term variation.
In Proceedings of the37th Annual Meeting of the Association for ComputationalLinguistics (ACL), pages 341?348.Kawahara, Daisuke and Sadao Kurohashi.
2006.
Case framecompilation from the Web using high-performance com-puting.
In Proceedings of the 5th International Conferenceon Language Resources and Evaluation (LREC).Kilgarriff, Adam.
2007.
Googleology is bad science.
Com-putational Linguistics, 33(1):147?151.Lee, Lillian.
1999.
Measures of distributional similarity.
InProceedings of the 37th Annual Meeting of the Associationfor Computational Linguistics (ACL), pages 25?32.Lin, Dekang.
1998.
Automatic retrieval and clustering ofsimilar words.
In Proceedings of the 36th Annual Meetingof the Association for Computational Linguistics and the17th International Conference on Computational Linguis-tics (COLING-ACL), pages 768?774.Lin, Dekang and Patrick Pantel.
2001.
Discovery of infer-ence rules for question answering.
Natural Language En-gineering, 7(4):343?360.Matsuyoshi, Suguru.
2008.
Hierarchically organized dictio-nary of Japanese functional expressions: design, compi-lation and application.
Ph.D. thesis, Graduate School ofInformatics, Kyoto University.Mel?c?uk, Igor and Alain Polgue`re.
1987.
A formal lexiconin meaning-text theory (or how to do lexica with words).Computational Linguistics, 13(3-4):261?275.Okanohara, Daisuke and Jun?ichi Tsujii.
2007.
A discrimi-native language model with pseudo-negative samples.
InProceedings of the 45th Annual Meeting of the Associationfor Computational Linguistics (ACL), pages 73?80.Pantel, Patrick, Rahul Bhagat, Bonaventura Coppola, Timo-thy Chklovski, and Eduard Hovy.
2007.
ISP: Learninginferential selectional preferences.
In Proceedings of Hu-man Language Technologies 2007: The Conference of theNorth American Chapter of the Association for Computa-tional Linguistics (NAACL-HLT), pages 564?571.Quirk, Chris, Chris Brockett, and William Dolan.
2004.Monolingual machine translation for paraphrase genera-tion.
In Proceedings of the 2004 Conference on Empiri-cal Methods in Natural Language Processing (EMNLP),pages 142?149.Szpektor, Idan, Hristo Tanev, Ido Dagan, and BonaventuraCoppola.
2004.
Scaling Web-based acquisition of entail-ment relations.
In Proceedings of the 2004 Conferenceon Empirical Methods in Natural Language Processing(EMNLP), pages 41?48.Takahashi, Tetsuro, Tomoya Iwakura, Ryu Iida, Atsushi Fu-jita, and Kentaro Inui.
2001.
KURA: a transfer-basedlexico-structural paraphrasing engine.
In Proceedings ofthe 6th Natural Language Processing Pacific Rim Sym-posium (NLPRS) Workshop on Automatic Paraphrasing:Theories and Applications, pages 37?46.Weeds, Julie, David Weir, and Bill Keller.
2005.
The dis-tributional similarity of sub-parses.
In Proceedings of theACL Workshop on Empirical Modeling of Semantic Equiv-alence and Entailment, pages 7?12.Yamamoto, Kazuhide.
2002.
Acquisition of lexical para-phrases from texts.
In Proceedings of the 2nd Interna-tional Workshop on Computational Terminology (Com-puTerm), pages 22?28.232
