Text  Segmentat ion  w i th  Mu l t ip le  Sur face  L ingu is t i c  CuesMOCHIZUKI Hajime and HONDA Takeo and OKUMURA ManabuSchool of Information ScienceJapan Advanced Institute of Science and TechnologyTatsunokuchi Ishikawa 923-1292 JapanTe1:(+81-761)51-1216, Fax: (+81-761)51-1149{mot izuki, honda, oku}@j aist.
ac.
jpAbstractIn general, a certain range of sentences in a text,is widely assumed to form a coherent unit which iscalled a discourse segment.
Identifying the segmentboundaries i a first step to recognize the structure ofa text.
In this paper, we describe a method for iden-tifying segment boundaries of a Japanese text withthe aid of multiple surface linguistic cues, though ourexperiments might be small-scale.
We also present amethod of training the weights for multiple linguisticcues automatically without the overfitting problem.1 IntroductionA text consists of multiple sentences that have se-mantic relations with each other.
They form se-mantic units which are usually called discourse seg-ments.
The global discourse structure of a textcan be constructed by relating the discourse seg-ments with each other.
Therefore, identifying seg-ment boundaries in a text is considered as a firststep to construct he discourse structure(Grosz andSidner, 1986).The use of surface linguistic cues in a text foridentification of segment boundaries has been exten-sively researched, since it is impractical to assumethe use of world knowledge for discourse analysis ofreal texts.
Among a variety of surface cues, lexi-cal cohesion(Halliday nd Hasan, 1976), the surfacerelationship among words that are semantically sim-ilar, has recently received much attention and hasbeen widely used for text segmentation(Morris andHirst, 1991; Kozima, 1993; Hearst, 1994; Okumuraand Honda, 1994).
Okumura and Honda (Okumuraand Honda, 1994) found that the information of lexi-cal cohesion is not enough and incorporation of othersurface information may improve the accuracy.In this paper, we describe a method for identi-fying segment boundaries of a Japanese text withthe aid of multiple surface linguistic cues, such asconjunctives, ellipsis, types of sentences, and lexicalcohesion.There are a variety of methods for combiningmultiple knowledge sources (linguistic ues)(McRoy,1992).
Among them, a weighted sum of the scores forall cues that reflects their contribution to identifyingthe correct segment boundaries is often used as theoverall measure to rank the possible segment bound-aries.
In the past researches (Kurohashi and Nagao,1994; Cohen, 1987), the weights for each cue tend tobe determined by intuition or trial and error.
Sincedetermining weights by hand is a labor-intensive taskand the weights do not always to achieve optimal oreven near-optimal performance(Rayner et al, 1994),we think it is better to determine the weights auto-matically in order to both avoid the need for ex-pert hand tuning and achieve performance that isat least locally optimal.
We begin by assuming theexistence of training texts with the correct segmentboundaries and use the method of multiple regres-sion analysis for automatically training the weights.However, there is a well-known problem in the meth-ods of automatically training the weights, that theweights tend to be overfitted to the training data.In such a case, the weights cause the degrade of theperformance for other texts.
It is considered that theoverfitting problem is caused by the relatively largenumber of the parameters (linguistic ues) comparedwith the size of the training data.
Furthermore, allof the linguistic cues are not always useful.
There-fore, we optimize the use of cues for training theweights.
We think if only the useful cues are se-lected from the entire set of cues, better weightscan be obtained.
Fortunately, since several meth-ods for parameters selection are already developedin the multiple regression analysis, we use one ofthese methods called the stepwise method.
There-fore we think we can obtain the weights only for theuseful by the using the multiple regression analysisand the stepwise method.To give the evidence for the above claims thatare summarized below, we carry out some prelim-inary experiments to show the effectiveness of ourapproach, even though our experiments might besmall-scale.?
Combining multiple surface cues is effective fortext segmentation.?
The multiple regression analysis with the step-wise method is good for selecting the useful cuesfor text segmentation and weighting these cuesautomatically.In section two we outline the surface linguistic uesthat we use for text segmentation.
In section three881we describe a method for automatically determiningthe weights for multiple cues.
In section four wedescribe a method for automatically selecting cues.In section five we describe the experiments with ourapproach.2 Surface Linguistic Cues forJapanese Text SegmentationThere are many linguistic cues that are available foridentifying segment boundaries (or non-boundaries)of a Japanese text.
However, it is not clear whichcues are useful to yield better results for text seg-mentation task.
Therefore, we first enumerate allthe linguistic cues.
Then, we select the useful cuesand combine the selected cues for text segmentation.We use the method that a weighted sum of the scoresfor all cues is used as the overall measure to rank thepossible segmentation with multiple linguistic cues.First we explain this method used for text seg-mentation with multiple linguistic cues.
Here, werepresent a point between sentences n and n + 1 asp(n,n + 1), where n ranges from 1 to the number ofsentences in the text minus 1.
Each point, p(n, n+l ) ,is a candidate for a segment boundary and has ascore scr(n, n + 1) which is calculated by a weightedsum of the scores for each cue i, scri(n,n + 1), asfollows:scr(n,n+ 1) = Zwi  X scri(n,n+ 1) (1)iA point p(n, n + 1) with a high score scr(n, n + 1)becomes a candidate with higher plausibility.
Thepoints in the text are selected in the order of thescore as the candidates of segment boundaries.We use the following surface linguistic cues forJapanese text segmentation:?
Occurrence of topical markers (i = 1..4).
If thetopical marker 'wa' or the subjective postpo-sition 'ga' appears either just before or after+ 1), add 1 to scri( , + 1).?
Occurrence of conjunctives (i = 5..10).
If oneof the six types of conjunctives 1 appears in thehead of the sentence n+l ,  add 1 to scri(n, n+l ) .?
Occurrence of anaphoric expressions (i =11..13).
If one of the three types of anaphoricexpressions 2 appears in the head of the sentencen + 1, add 1 to scri(n, n + 1).?
Omission of the subject (i=14).
If the sub-ject is omitted in the sentence n + 1, add 1 toscri(n, n + 1).s Succession of the sentence of the same type (i =15..18).
If both sentences n and n+l  are judgedas one of the four types of sentences s, add 1 toscri(n, n + 1).1The classification of conjunctives i based on the work inJapanese linguistics(Tokoro, 1987), which can be consideredto be equivalent to Schiffren's(Schiffren, 1987) in English.2The classification of anaphoric expressions in Japanesearises from the difference of the characteristics of their refer-ents from the viewpoint of the mutual knowledge between thespeaker/writer and hearer/reader(Seiho, 1992).SThe classification of types of sentences originates in thework in Japanese linguistics(Nagano, 1986).?
Occurrence of lexical chains (i = 19..22).
Herewe call a sequence of words which have lexi-cal cohesion relation with each other a lezicalchain like(Morris and Hirst, 1991).
Like Morrisand Hirst, we assume that lexical chains tendto indicate portions of a text that form a se-mantic unit.
We use the information of the lex-ical chains and the gaps of lexical chains thatare the parts of the chains with no words.
Thegap of a lexical chain can be considered to in-dicate a small digression of the topic.
In thecase that a lexical chain or a gap ends at sen-tence n, or begins at sentence n + 1, add 1 toscri(n,n + 1).
Here we assume that relatedwords are the words in the same class on the-saurus 4.?
Change of the modifier of words in lexical chains(i = 23).
If the modifier word of words in lexicalchains changes in the sentence n + 1, add 1 toscri(n,n + 1).
This cue originates in the ideathat it might indicate the different aspect of thetopic becomes the new topic.The above cues indicate both the plausibility andimplausibility of the point as the segment bound-ary.
Occurrence of the topical marker 'wa', for ex-ample, the indicates the segment boundary plausibil-ity, while occurrence of anaphora, succession of thesame type sentence indicate the implausibility.
Theweight for each cue reflects whether the cue is thepositive or negative factor for the segment bound-ary.
In the next section, we present our weightingmethod.3 Automat ica l ly  We ight ing  Mu l t ip leL ingu is t i c  CuesWe think it is better to determine the weights auto-matically, because it can avoid the need for experthand tuning and can achieve performance that isat least locally optimal.
We use the training textsthat are tagged with the correct segment bound-aries.
For automatically training the weights, weuse the method of the multiple regression analy-sis(Jobson, 1991).
We think the method can yielda set of weights that are better than those derivedby a labor-intensive hand-tuning effort.
Consider-ing the following equation S(n, n + 1), at each pointp(n, n + 1) in the training texts,p+ 1) = a + ?
+ 1) (2)i=1where a is a constant, p is the number of the cues,and wi is the estimated weight for the i-th cue, wecan obtain the above equations in the number of thepoints in the training texts.
Therefore, giving somevalue to S, we can calculate the weights wi for eachcue automatically by the method of least squares.The higher values should be given to S(n, n + 1)at the segment boundary points than non-boundary4We use the Kadokawa Ruigo Shin Jiten(Oono andHamanishi, 1981) as Japanese thesaurus.882points in the multiple regression analysis.
If we cangive the better value to S(n, n + 1) that reflects thereal phenomena in the texts more precisely, we thinkwe can expect the better performance.
However,since we have only the correct segment boundariesthat are tagged to the training texts, we decide togive 10 each S(n, n + 1) of the segment boundarypoint and -1  to the non-boundary point.
Thesevalues were decided by the results of the preliminaryexperiment with four types of S.Watanabe(Watanabe, 1996) can be considered asa related work.
He describes a system which auto-matically creates an abstract of a newspaper articleby selecting important sentences of a given text.
Heapplies the multiple regression analysis for weight-ing the surface features of a sentence in order todetermine the importance of sentences.
Each S of asentence in training texts is given a score that thenumber of human subjects who judge the sentenceas important, divided by the number of all subjects.We do not adopt the same method for giving a valueto S, because we think that such a task by humansubjects is labor-intensive.4 Automatically Selecting UsefulCuesIt is not clear which cues are useful in the linguisticcues listed in section 2.
Useless cues might cause abad effect on calculating weights in the multiple re-gression model.
Furthermore, the overfitting prob-lem is caused by the use of too many linguistic cuescompared with the size of training data.If we can select only the useful cues from the en-tire set of cues, we can obtain better weights andimprove the performance.
However, we need anobjective criteria for selecting useful cues.
Fortu-nately, many parameter selecting methods have al-ready been developed in the multiple regression anal-ysis.
We adopt one of these methods called the step-wise method which is very popular for parameterselection(Jobson, 1991).The most commonly used criterion for the addi-tion and deletion of variables in the stepwise methodis based on the partial F-statistic.
The partial F-statistic is given by(SSR - SSR~)/qf = SSE/ (N-p -  1) (3)where SSR denotes the regression sum of squares,SSE denotes the error sum of squares, p is the num-ber of linguistic cues, N is the number of trainingdata, and q is the number of cues in the model ateach selection step.
SSR and SSE refer to the largermodel with p cues plus an intercept, and SSRRrefers to the reduced model with (p - q) cues andan intercept(Jobson, 1991).The stepwise method begins with a model thatcontains no cues.
Next, the most significant cueis selected, and added to the model to form a newmodel(A) if and only if the partial F-statistic of thenew model(A) is greater than Fir,.
After adding thecue, some cues may be eliminated from the model(A)and a new model(B) is constructed if and only if thepartial F-statistic of the model(B) is less than Fo~,t.These two processes occur repetitively until a cer-tain termination condition is detected.
Fin and Fo~,tare some prescribed the partial F-statistic limits.Although there are other popular methods for cueselection (for example, the forward selection methodand the backward selection method), we use thestepwise method, because the stepwise method is ex-pected to be superior to the other methods.5 The ExperimentsTo give the evidence for the claims that are men-tioned in the previous ections and are summarizedbelow, we carry out some preliminary experimentsto show the effectiveness of our approach.?
Combining multiple surface cues is effective fortext segmentation.?
The multiple regression analysis with the step-wise method is good for selecting the useful cuesand weighting these cues automatically.We pick out 14 texts, which are from the examquestions of the Japanese language that ask us topartition the texts into a given number of segments.The question is like "Answer 3 points which partitionthe following text into semantic units."
The system'sperformance is evaluated by comparing the system'soutputs with the model answer attached to the aboveexam question.In our 14 texts, the average number of points(boundary candidates) is 20 (the range from 12 to47).
The average number of correct answers bound-aries from the model answer is 3.4 (the range from2 to 6).
Here we do not take into account he in-formation of paragraph boundaries (such as the in-dentation) at all due to the following two reasons:Many of the exam question texts have no marks ofparagraph boundaries; In case of Japanese texts, itis pointed out that paragraph boundaries and seg-ment boundaries do not always coincide with eachother(Tokoro, 1987).In our experiments, the system generates the out-puts in the order of the score scr(n,n + 1).
Weevaluate the performance in the cases where the sys-tem outputs 10%,20%,30%, and 40% of the num-ber of boundary candidates.
We use two measures,Recall and Precision for the evaluation: Recall isthe quotient of the number of correctly identifiedboundaries by the total number of correct bound-aries.
Precision is the quotient of the number ofcorrectly identified boundaries by the number of gen-erated boundaries.The experiments are made on the following cases:1.
Use the information of except for lexical cohe-sion (cues from 1 to 18 and 23).2.
Use the information of lexical cohesion(cuesfrom 19 to 22).8833.
Use all linguistic cues mentioned in section 2.The weights are manually determined by one ofthe authors.4.
Use all linguistic cues mentioned in section 2.The weights are automatically determined bythe multiple regression analysis.
We divide 14texts into 7 groups each consisting of 2 textsand use 6 groups for training and the remain-ing group for test.
Changing the group for thetest, we evaluate the performance by the crossvalidation(Weiss and Kulikowski, 1991).5.
Use only selected cues by applying the step-wise method.
As mentioned in section 4, we usethe stepwise method for selecting useful cues fortraining sets.
The condition is the same as forthe case 4 except for the cue selection.6.
Answer from five human subjects.
By this ex-periment, we try to clarify the upper bound ofthe performance of the text segmentation task,which can be considered to indicate the degreeof the difficulty of the task(Passonneau nd Lit-man, 1993; Gale et al, 1992).Figure 1,2 and table 1 show the results of the ex-periments.
Two figures show the system's mean per-formance of 14 texts.
Table 1 shows the 5 subjects'mean performance of 14 texts (experiment 6).
Wethink table 1 shows the upper bound of the perfor-mance of the text segmentation task.
We also cal-culate the lower bound of the performance of thetask("lowerbound" in figure 2).
It can be calcu-lated by considering the case where the system se-lects boundary candidates at random.
In the case,the precision equals to the mean probability thateach candidate will be a correct boundary.
The re-call is equal to the ratio of outputs.
In figure 1,comparing the performance among the case with-out lexical chains("ex.l"), the one only with lexicalchains("ex.2"), and the one with multiple linguis-tic cues("ex.3"), the results show that better perfor-mance can be yielded by using the whole set of thecues.
In figure 2, comparing the performance of thecase where the hand-tuned weights are used for mul-tiple linguistic cues("ex.3") and the one where theautomatic weights are determined with the trainingtexts("ex.4.test"), the results show that better per-formance can be yielded by automatically trainingthe weights in general.
Furthermore, since it canavoid the labor-intensive work and yield objectiveweights, automatic weighting is better than hand-tuning.Comparing the performance of the case where theautomatic weights are calculated with the entire setof cues("ex.4.test" in figure 2) and the one wherethe automatic weights are calculated with selectedcues("ex.5.test"), the results show that better per-formance can be yielded by the selected cues.
Theresult also shows that our cue selection method canavoid the overfitting problem in that the results fortraining and test data have less difference.
Thedifference between "ex.5.training" and "ex.5.test"is less than the one between "ex.4.training" and"ex.4.test".
In our cue selection, the average num-ber of selected cues is 7.4, though same cues are notalways selected.
The cues that are always selectedare the contrastive conjunctives(cue 9 in section 2)and the lexical chains(cues 19 and 20 in section 2).0.60.50.40.30.20.1a,..a"ex.1""ex.2" ~.?
ex.3" e02  0.3 0.4 05 06  07  0.8re in,0.60.50.40.30.20.10Figure 1: Hand tuning"ex.3"a, "ex.4.trsJning" ~-?
, "ex.4.test" -~--K%% "ex.5.treJn~ng" .M -"ex.5.1esr~.
6 .~ \ "loweYoound" ~' .
-........ ..... ~ "-.::--.::~.
"'Do:, o~ o:3 o:, o:5 o:~ o:, 0.8Figure 2: Automatic tuningTable 1: The result of the human subjects\[ recall \ [precis ion\[\[ 0.630714 \[ 0.57171s IWe also make an experiment with another answer,where we use points in a text that 3 or more humansubjects among five judged as segment boundaries.The average number of correct answers is 3.5 (therange from 2 to 6).
As a result, our system can yieldsimilar results as the one mentioned above.Litman and Passonneau(Litman d Passonneau,1995)'s work can be considered to be a related re-search, because they presented a method for textsegmentation that uses multiple knowledge sources.The model is trained with a corpus of spoken narra-tives using machine learning tools.
The exact com-parison is difficult.
However, since the slightly lower884upper bound for our task shows that our task is abit more difficult than theirs, our performance is notinferior to theirs.In fact, our experiments might be small-scale witha few texts to show the correctness of our claims andthe effectiveness of our approach.
However, we thinkthe initial results described here are encouraging.6 ConclusionIn this paper, we described a method for identify-ing segment boundaries of a Japanese text with theaid of multiple surface linguistic cues.
We made theclaim that automatically training the weights thatare used for combining multiple linguistic cues isan effective method for text segmentation.
Further-more, we presented the multiple regression analy-sis with the stepwise method as a method of auto-matically training the weights without causing theoverfltting problem.
Though our experiments mightbe small-scale, they showed that our claims and ourapproach are promising.
We think that we shouldexperiment with large datasets.As a future work, we now plan to calculate theweights for a subset of the texts by clustering thetraining texts.
Since there may be some differencesamong real texts which reflect the differences of theirauthor, their style, their genre, etc., we think thatclustering a set of the training texts and calculat-ing the weights for each cluster, rather than calcu-lating the weights for the entire set of texts, mightimprove the accuracy.
In the area of speech recogni-tion, to improve the accuracy of the language mod-els, clustering the training data is considered to bea promising method for automatic training(Carter,1994; Iyer et al, 1994).
Carter presents a methodfor clustering the sentences in a training corpus au-tomatically into some subcorpora on the criterion ofentropy reduction and calculating separate languagemodel parameters for each cluster.
He asserts thatthis kind of clustering offers a way to improve theperformance of a model significantly.AcknowledgmentsThe authors would like to express our gratitudeto Kadokawa publisher for allowing us to use theirthesaurus, and Dr.Shigenobu Aoki of Gunma Univ.and Dr.Teruo Matsuzawa of JA IST for their sugges-tions of statistical analysis, and Dr.Thanaruk Theer-amunkong of JAIST for his suggestions of improve-ments to this paper.ReferencesD.
Carter.
1994.
Improving Language Models by Clus-tering Training Sentences.
Proc.
of the 4th Conferenceon Applied Natural Language Processing, pages 59-64.R.
Cohen.
1987.
Analyzing the structure of argumenta-tive discourse.
Computational Linguistics, 13:11-24.W.A.
Gale, K.W.
Church, and D. Yarowsky.
1992.
Esti-mating Upper and Lower Bounds on the Performanceof Word-Sense Disambiguation Programs.
In Proc.
ofthe 30th Annual Meeting of the Association for Com-putational Linguistics, pages 249-256.B.J.
Grosz and C.L.
Sidner.
1986.
Attention, intention,and the structure of discourse.
Computational Lin-guistics, 12(3):175-204.H.A.K.
Halliday and R. Hasan.
1976.
Cohesion in En-glish.
Longman.M.A.
Hearst.
1994.
Multi-Paragraph Segmentation ofExpository Texts.
In Proe.
of the $~nd Annual Meet-ing of the Association for Computational Linguistics,pages 9-16.R.
Iyer, M. Ostendorf, and J.R. Rohlicek.
1994.
Lan-guage modeling with sentence-level mixtures.
In Proc.of the Human Language Technology Workshop 1994,pages 82-87.J.D.
Jobson.
1991.
Applied Multivariate Data Analy-sis Volume I: Regression and Ezperimental Design.Springer-Verlag.H.
Kozima.
1993.
Text segmentation based on similar-ity between words'.
In Proc.
of the 31st Annual Meet-ing of the Association for Computational Linguistics,pages 286-288.S.
Kurohashi and M. Naguo.
1994.
Automatic Detectionof Discourse Structure by Checking Surfce Informationin Sentence.
In Proc.
of the 15th International Confer-ence on Computational Linguistics, pages 1123-1127.D.J.
Litman and R.J. Passonneau.
1995.
CombiningMultiple Knowledge Sources for Discourse.
In Proc.
ofthe 33rd Annual Meeting of the Association for Com-putational Linguistics.S.W.
McRoy.
1992.
Using multiple knowledge sourcesfor word sense discrimination.
Computational Linguis-tics, 18(1):1-30.J.
Morris and G. Hirst.
1991.
Lexical Cohesion Com-puted by Thesanral Relations as an Indicator ofthe Structure of Text.
Computational Linguistics,17(1):21-48.K.
Nagaao.
1986.
Bunsho.ron Sousetsu.
Asakura.
inJapanese.M.
Okumura and T. Honda.
1994.
Word sense disam-biguation and text segmentation based on lexicai co-hesion.
In Proe.
of the 15th International Conferenceon Computational Linguistics, pages 755-761.Y.
Oono and M. Hamanishi.
1981.
Kadokawa RuigoShin Siren.
Kvxlokawa.
in Japanese.R.J.
Passonnean and D.J.
Litman.
1993.
Intention-based Segmentation: Human Reliability and Correla-tion with Linguistic Cues.
In 51st Annual Meeting ofthe Association for Computational Linguistics, pages148-155.M.
Rayner, D. Carter, V. Digalakis, and P. Price.
1994.Combining knowledge sources to reorder n-best speechhypothesis lists.
In Proc.
of the Human Language tech-nology Workshop 1994, pages 271-221.D.
Schiffren.
1987.
Discourse Markers.
Cambridge Uni-versity Press.I.
Seiho, 1992.
Kosoa no taikei, pages 51-122.
NationalLanguage Research Institute.K.
Tokoro.
1987.
Gendaibun Rhetoric Dokukaihou.Takumi.
in Japanese.H Watanabe.
1996.
A Method for Abstracting Newspa-per Articles by Using Surface Clues.
In Proc.
of the16th International Conference on Computational Lin-guistics, pages 974-979.S.M.
Weiss and C. Kulikowski.
1991.
Computer systemsthat learn: classification and prediction methods fromstatistics, neural nets, machine learning, and ezpertsystems.
Morgan Kaufmann.885
