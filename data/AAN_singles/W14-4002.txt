Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 11?21,October 25, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsBilingual Markov Reordering Labels for Hierarchical SMTGideon Maillette de Buy Wenniger and Khalil Sima?anInstitute for Logic, Language and ComputationUniversity of AmsterdamScience Park 107, 1098 XG Amsterdam, The Netherlandsgemdbw AT gmail.com, k.simaan AT uva.nlAbstractEarlier work on labeling Hiero grammarswith monolingual syntax reports improvedperformance, suggesting that such label-ing may impact phrase reordering as wellas lexical selection.
In this paper we ex-plore the idea of inducing bilingual labelsfor Hiero grammars without using anyadditional resources other than originalHiero itself does.
Our bilingual labelsaim at capturing salient patterns of phrasereordering in the training parallel corpus.These bilingual labels originate from hier-archical factorizations of the word align-ments in Hiero?s own training data.
In thispaper we take a Markovian view on syn-chronous top-down derivations over thesefactorizations which allows us to extract0th- and 1st-order bilingual reordering la-bels.
Using exactly the same trainingdata as Hiero we show that the Marko-vian interpretation of word alignment fac-torization offers major benefits over theunlabeled version.
We report extensiveexperiments with strict and soft bilinguallabeled Hiero showing improved perfor-mance up to 1 BLEU points for Chinese-English and about 0.1 BLEU points forGerman-English.Phrase reordering in Hiero (Chiang, 2007) is mod-elled with synchronous rules consisting of phrasepairs with at most two nonterminal gaps, therebyembedding ITG permutations (Wu, 1997) in lexi-cal context.
It is by now recognized that Hiero?sreordering can be strengthened either by labeling(e.g., (Zollmann and Venugopal, 2006)) or by sup-plementing the grammar with extra-grammaticalreordering models, e.g., (Xiao et al., 2011; Hucket al., 2013; Nguyen and Vogel, 2013).
In thispaper we concentrate on labeling approaches.Conceptually, labeling Hiero rules aims at in-troducing preference in the SCFG derivations forfrequently occurring lexicalized ordering constel-lations over rare ones which also affects lexical se-lection.
In this paper, we present an approach fordistilling phrase reordering labels directly fromalignments (hence bilingual labels).To extract bilingual labels from wordalignments we must first interpret the alignmentsas a hierarchy of phrases.
Luckily, everyword alignment factorizes into NormalizedDecomposition Trees (NDTs) (Zhang et al.,2008), showing explicitly how the word alignmentrecursively decomposes into phrase pairs.
Zhanget al.
(2008) employ NDTs for extracting Hierogrammars.
In this work, we extend NDTswith explicit phrase permutation operators alsoextracted from the original word alignment(Sima?an and Maillette de Buy Wenniger, 2013);Every node in the NDT is equipped with anode operator that specifies how the order ofthe target phrases (children of this node) isproduced from the corresponding source phrases.Subsequently, we cluster the node operatorsin these enriched NDTs according to theircomplexity, e.g., monotone (straight), inverted,non-binary but one-to-one, and the more complexcase of discontinuous (Maillette de Buy Wennigerand Sima?an, 2013).Inspired by work on parsing (Klein and Man-ning, 2003), we explore a vertical Markovianlabeling approach: intuitively, 0th-order labelssignify the reordering of the sub-phrases inside thephrase pair (Zhang et al., 2008), 1st-order labelssignify reordering aspects of the direct context(an embedding, parent phrase pair) of the phrasepair, and so on.
Like the phrase orientationmodels this labeling approach does not employexternal resources (e.g., taggers, parsers) beyondthe training data used by Hiero.We empirically explore this bucketing for 0th-11and 1st-order labels both as hard and soft labels.In experiments on German-English and Chinese-English we show that this extension of Hiero of-ten significantly outperforms the unlabeled modelwhile using no external data or monolingual la-beling mechanisms.
This suggests the viabilityof automatically inducing bilingual labels follow-ing the Markov labeling approach on operator-labelled NDTs as proposed in this paper.1 Hierarchical models and related workHiero SCFGs (Chiang, 2005; Chiang, 2007) allowonly up to two (pairs of) nonterminals on the right-hand-side (RHS) of synchronous rules.
The typesof permissible Hiero rules are:X ?
?
?, ??
(1)X ?
??
X1?, ?
X1??
(2)X ?
??
X1?
X2?
, ?
X1?
X2?
?
(3)X ?
??
X1?
X2?
, ?
X2?
X1?
?
(4)Here ?, ?, ?, ?, ?, ?
are terminal sequences, possi-bly empty.
Equation 1 corresponds to a normalphrase pair, 2 to a rule with one gap and 3 and 4to the monotone- and inverting rules respectively.Given an Hiero SCFG G, a source sentence s istranslated into a target sentence t by synchronousderivations d, each is a finite sequence of well-formed substitutions of synchronous productionsfrom G, see (Chiang, 2006).
Existing phrase-based models score a derivation der with linearinterpolation of a finite set of feature functions(?
(d)) of the derivation d, mostly working withlocal feature functions ?iof individual produc-tions, the target side yield string t of d (targetlanguage model features) and other features (seeexperimental section): arg maxd?GP(t,d | s) ?arg maxd?G?|?(d)|i=1?i?
?i.
The parameters {?i} areoptimized on a held-out parallel corpus by directerror-minimization (Och, 2003).A range of (distantly) related work exploitssyntax for Hiero models, e.g.
(Liu et al., 2006;Huang et al., 2006; Mi et al., 2008; Mi andHuang, 2008; Zollmann and Venugopal, 2006;Wu and Hkust, 1998).
In terms of labelingHiero rules, SAMT (Zollmann and Venugopal,2006; Mylonakis and Sima?an, 2011) exploits a?softer notion?
of syntax by fitting the CCG-likesyntactic labels to non-constituent phrases.
Thework of (Xiao et al., 2011) adds a lexicalizedorientation model to Hiero, akin to (Tillmann,2004) and achieves significant gains.
The workof (Huck et al., 2013; Nguyen and Vogel, 2013)overcomes technical limitations of (Xiao et al.,2011), making necessary changes to the decoder,which involves delayed (re-)scoring at hypernodesup in the derivation of nodes lower in the chartwhose orientations are affected by them.
Thisgoes to show that phrase-orientation models arenot mere labelings of Hiero.Soft syntactic constraints has been around forsome time now (Zhou et al., 2008; Venugopal etal., 2009; Chiang, 2010).
In (Zhou et al., 2008)Hiero is reinforced with a linguistically motivatedprior.
This prior is based on the level of syntactichomogeneity between pairs of non-terminalsand the associated syntactic forests rooted atthese nonterminals, whereby tree-kernels areapplied to efficiently measure the amount ofoverlap between all pairs of sub-trees inducedby the pairs of syntactic forests.
Crucially, thesyntactic prior encourages derivations that aremore syntactically coherent but does not blockderivations when they are not.
In (Venugopalet al., 2009) the authors associate distributionsover compatible syntactic labelings with grammarrules, and combine these preference distributionsduring decoding, thus achieving a summationrather than competition between compatible labelconfigurations.
The latter approach requiressignificant changes to the decoder and comes at aconsiderable computational cost.
An alternativeapproach (Chiang, 2010) uses labels similar to(Zollmann and Venugopal, 2006) together withboolean features for rule-label and substituted-label combinations; using discriminative training(MIRA) it is learned what combinations areassociated with better translations.The labeling approach presented next differsfrom existing approaches.
It is inspired by softlabeling but employs novel, non-linguistic bilin-gual labels.
And it shares the bilingual intuitionwith phrase orientation models but it is based ona Markov approach for SCFG labeling, therebyremaining within the confines of Hiero SCFG,avoiding the need to make changes inside thedecoder.11Soft constraint decoding can easily be implementedwithout adapting the decoder, through a smart application of?label bridging?
unary rules.
In practice however, adaptingthe decoder turns out to be computationally more efficient,therefore we used this solution in our experiments.1213762541we2should3tailor4our5policy6accordinglydarauf1m?usen2wir3unsere4politik5ausrichten6Figure 1: Example alignment from Europarl([1, 6], [1, 6], 1 )([1, 2], [2, 3], 2 )([1, 1], [3, 3], 4 ) ([2, 2], [2, 2], 5 )([4, 5], [4, 5], 3 )([4, 4], [4, 4], 6 ) ([5, 5], [5, 5], 7 )Figure 2: Normalized Decomposition Tree (Zhanget al., 2008) extended with pointers to originalalignment structure from Figure 12 Bilingual reordering labels for HieroFigure 1 shows an alignment from EuroparlGerman-English (Koehn, 2005) along with a treeshowing corresponding maximally decomposedphrase pairs.
Phrase pairs can be grouped into amaximally decomposed tree (called NormalizedDecomposition Tree ?
NDT) (Zhang et al., 2008).Figure 2 shows the NDT for Figure 1, extendedwith pointers to the original alignment structurein Figure 2.
The numbered boxes indicate howthe phrases in the two representations correspond.In an NDT every phrase pair is recursively splitup at every level into a minimum number (twoor greater) of contiguous parts.
In this examplethe root node splits into three phrase pairs, butthese phrase pairs together do not cover the entireparent phrase pair because of the discontinuity:?tailor ... accordingly/ darauf ... ausrichten?.Following (Zhang et al., 2008), we use theNDT factorizations of word alignments in thetraining data for extracting phrases.
Every NDTshows the hierarchical structuring into phrasesembedded in larger phrases, which together withthe context of the original alignment exposes thereordering complexity of every phrase (Sima?anand Maillette de Buy Wenniger, 2013).
We willexploit these elaborate distinctions based on thecomplexity of reordering for Hiero rule labels asexplained next.Phrase-centric (0th-order) labels are based onthe view of looking inside a phrase pair to seehow it decomposes into sub-phrase pairs.
The op-erator signifying how the sub-phrase pairs are re-ordered (target relative to source) is bucketted intoa number of ?permutation complexity?
categories.Straightforwardly, we can start out by using thetwo well known cases of Inversion TransductionGrammars (ITG) {Monotone, Inverted} and labeleverything2that falls outside these two categorywith a default label ?X?
(leaving some Hieronodes unlabeled).
This leads to the followingcoarse phrase-centric labeling scheme, which wename 0thITG+: (1) Monotonic(Mono): binarizable,fully monotone plus non-decomposable phrases(2) Inverted(Inv): binarizable, fully inverted (3) X:decomposable phrases that are not binarizable.A clear limitation of the above ITG-like label-ing approach is that all phrase pairs that decom-pose into complex non-binarizable reordering pat-terns are not further distinguished.
Furthermore,non-decomposable phrases are lumped togetherwith decomposable monotone phrases, althoughthey are in fact quite different.
To overcome theseproblems we extend ITG in a way that furtherdistinguishes the non-binarizable phrases and alsodistinguishes non-decomposable phrases from therest.
This gives a labeling scheme we will callsimply 0th-order labeling, abbreviated 0th, con-sisting of a more fine-grained set of five cases,ordered by increasing complexity (see examplesin Figure 4): (1) Atomic: non-decomposablephrases, (2) Monotonic(Mono): binarizable, fullymonotone, (3) Inverted(Inv): binarizable, fullyinverted (4) Permutation(Perm): factorizes into apermutation of four or more sub-phrases (5) Com-plex(Comp): does not factorize into a permutationand contains at least one embedded phrase.In Figure 3, we show a phrase-complexity la-beled derivation for the example of Figure 1.Observe how the phrase-centric labels reflect therelative reordering at the node.
For example, the2Non-decomposable phrases will still be groupedtogether with Monotone, since they are more similar to thiscategory than to the catchall ?X?
category.13S0accordinglypolicyourtailorshouldweCOMPLEX TOP1INVERTED E.F.D.2ATOMIC R.B.I.4MONO E.F.D.3ATOMIC L.B.M.7S0ausrichtenpolitikunserewirm?ussendaraufCOMPLEX TOP1INVERTED E.F.D.2ATOMIC R.B.I.4MONO E.F.D.3ATOMIC L.B.M.7Figure 3: Synchronous trees (implicit derivations end results) based on differently labelled Hierogrammars.
The figure shows alternative labeling for every node: Phrase-Centric (0th-order) (light gray)and Parent-Relative (1st-order) (dark gray).this is an important matterdas ist ein wichtige angelegenheit1122Monotonewe all agree on thisdas sehen wir alle1122Inversioni want to stress two pointsauf zweipunktem?ochte ich hinweisen11223344Permutationwe owe this to our citizensdas sind wir unsern burgern schuldig112233Complexit would be possiblekann mann11AtomicFigure 4: Different types of Phrase-Centric Alignment LabelsInverted label of node-pair 2 corresponds to theinversion in the alignment of ?we should, m?usenwir?
; in contrast, node-pair 1 is complex anddiscontinuous and the label is Complex.Parent-relative (1st-order) labels capture the re-ordering that a phrase undergoes relative to anembedding parent phrase.1.
For a binarizable mother phrase with orien-tation Xo?
{Mono, Inv}, the phrase itself caneither group to the left only Left-Binding-Xo, right only Right-Binding-Xo, or with bothsides (Fully-Xo).2.
Fully-Discontinuous: Any phrase withina non-binarizable permutation or complexalignment containing discontinuity.3.
Top: phrases that span the entire alignedsentence pair.In cases were multiple labels are applicable, thesimplest applicable label is chosen according tothe following preference order:{Fully-Monotone, Left/Right-Binding-Monotone,Fully-Inverted, Left/Right-Binding-Inverted,Fully-Discontinuous, TOP}.In Figure 3 the parent-relative labels in thederivation reflect the reordering taking place at thephrases with respect to their parent node.
Node 4has a parent node that inverts the order and thesibling node it binds is on the right, therefore it14is labeled ?right-binding inverted?
(R.B.I.
); E.F.D.and L.B.M.
are similar abbreviations for ?embed-ded fully discontinuous?
and ?left-binding mono-tone?
respectively.
As yet another example node7 in Figure 3 is labeled ?left-binding monotone?(L.B.M.)
since it is monotone, but the alignmentallows it only to bind to the left at the parent node,as opposed to only to the right or to both sideswhich cases would have yielded ?right-bindingmonotone?
R.B.M.
and ?
(embedded) fully mono-tone?
(E.F.M.)
parent-relative reordering labelsrespectively.Note that for parent-relative labels the bindingdirection of monotone and inverted may not beinformative.
We therefore also form a set ofcoarse parent-relative labels (?1stCoarse?)
by col-lapsing the label pairs Left/Right-Binding-Monoand Left/Right-Binding-Inverted into single labelsOne-Side-Binding-Mono and One-Side-Binding-Inv3.3 Features for soft bilingual labelingLabels used in hierarchical Statistical MachineTranslation (SMT) are typically adapted from ex-ternal resources such as taggers and parsers.
Likein our case, these labels are typically not fitted tothe training data ?
with very few exceptions e.g.,(Mylonakis and Sima?an, 2011; Mylonakis, 2012;Hanneman and Lavie, 2013).
Unfortunately thismeans that the labels will either overfit or underfit,and when they are used as strict constraints onSCFG derivations they are likely to underperform.Experience with mismatch between syntactic la-bels and the data is abundant (Venugopal et al.,2009; Marton et al., 2012; Chiang, 2010), andusing soft constraint decoding with suitable labelsubstitution features has been shown to be aneffective workaround solution.
The intuition be-hind soft constraint decoding is that even thoughheuristic labels are not perfectly tailored to thedata, they do provide useful information providedthe model is ?allowed to learn?
to use them onlyin as far as they can improve the final evaluationmetric (usually BLEU).3We could also further coarsen the 1stlabels byremoving entirely all sub-distinctions of binding-type forthe binarizable cases, but that would make the labelingessentially equal to the earlier mentioned 0thITG+except forlooking at the reordering occurring at the parent rather thaninside the phrase itself.
We did not explore this variant in thiswork, as the high similarity to the already explored 0thITG+variant made it not seem to add much extra information.??
?LHS10N111N212GAP111GAP212Substituting ruleDecoder chartLabel Substitution FeaturesFigure 5: Label substitution features, schematicview.
Labels/Gaps with same filling in the figurescorrespond to the situation of a nonterminal/gapwhose labels correspond (for N1/GAP1).
Fillingsof different shades (as for N2/GAP2 on the rightin the two figures) indicates the situation were thelabel of the nonterminal and the gap is different.Next we introduce the set of label substitutionfeatures used in our experiments.Label substitution features consist of a uniquefeature for every pair of labels ?L?, L??
in thegrammar, signifying a rule with left-hand-sidelabel L?substituting on a gap labeled L?.
Thesefeatures are combined with two more coarsefeatures, ?Match?
and ?Nomatch?, indicating ifthe substitution involves labels that match or not.Figure 5 illustrates the concept of label substi-tution features schematically.
In this figure thesubstituting rule is substituted onto two gaps inthe chart, which induces two label substitutionfeatures indicated by the two ellipses.
The sit-uation is analogous for rules with just one gap.To make things concrete, lets assume that boththe first nonterminal of the rule N1 as well asthe first gap it is substituted onto GAP1 havelabel MONO.
Furthermore lets assume the secondnonterminal N2 has label COMPLEX while thelabel of the gap GAP2 it substitutes onto is INV .This situation results in the following two specificlabel substitution features:?
subst(MONO,MONO)?
subst(INV ,COMPLEX)Canonical labeled rules.
Typically when la-beling Hiero rules there can be many differentlabeled variants of every original Hiero rule.
Withsoft constraint decoding this leads to prohibitivecomputational cost.
This also has the effect ofmaking tuning the features more difficult.
Inpractice, soft constraint decoding usually exploits15Systen Name Matching Type Label Order Label GranularityHiero-0thITG+Strict 0thorder CoarseHiero-0thStrict 0thorder FineHiero-1stCoarseStrict 1thorder CoarseHiero-1stStrict 1thorder FineHiero-0thITG+-Sft Soft 0thorder CoarseHiero-0th-Sft Soft 0thorder FineHiero-1stCoarse-Sft Soft 1thorder CoarseHiero-1st-Sft Soft 1thorder FineTable 1: Experiment names legendSystem NameDEV TESTBLEU ?
METEOR ?
TER ?
KRS ?
BLEU ?
METEOR ?
TER ?
KRS ?German-EnglishHiero 27.90 32.69 58.22 66.37 28.39 32.94 58.01 67.44SAMT 27.76 32.67 58.05 66.84N28.32 32.88 57.70NN67.63Hiero-0thITG+27.85 32.70 58.04NN66.27 28.36 32.90H57.83NN67.30Hiero-0th27.82 32.75 57.92NN66.66 28.39 33.03NN57.75NN67.55Hiero-1stCoarse27.86 32.66 58.23 66.37 28.22H32.90 57.93 67.47Hiero-1st27.74H32.60HH58.11 66.44 28.27 32.80HH57.95 67.39Chinese-EnglishHiero 31.70 30.72 61.21 58.28 31.63 30.56 59.28 58.03Hiero-0thITG+31.54 30.97NN62.79HH59.54NN31.94NN30.84NN60.76HH59.45NNHiero-0th31.66 30.95NN62.20HH60.00NN31.90NN30.79NN60.11HH59.68NNHiero-1stCoarse31.64 30.75 61.37 59.48NN31.57 30.57 59.58HH59.13NNHiero-1st31.74 30.79 61.94HH60.22NN31.77 30.62 60.13HH59.89NNTable 2: Mean results bilingual labels with strict matching.4a single labeled version per Hiero rule, whichwe call the ?canonical labeled rule?.
Following(Chiang, 2010), this canonical form is the mostfrequent labeled variant.4 ExperimentsWe evaluate our method on two language pairs:using German/Chinese as source and English astarget.
In all experiments we decode with a4-gram language model smoothed with modifiedKnesser-Ney discounting (Chen and Goodman,1998).
The data used for training the languagemodels differs per language pair, details are givenin the next paragraphs.
All data is lowercased asa last pre-processing step.
In all experiments weuse our own grammar extractor for the generationof all grammars, including the baseline Hierogrammars.
This enables us to use the samefeatures (as far as applicable given the grammarformalism) and assure true comparability of thegrammars under comparison.German-English4Statistical significance is dependent on variance ofresampled scores, and hence sometimes different for samemean scores across different systems.The data for our German-English experimentsis derived from parliament proceedings sourcedfrom the Europarl corpus (Koehn, 2005), withWMT-07 development and test data.
We used amaximum sentence length of 40 for filtering thetraining data.
We employ 1M sentence pairs fortraining, 1K for development and 2K for test-ing (single reference per source sentence).
Bothsource and target of all datasets are tokenizedusing the Moses(Hoang et al., 2007) tokenizationscript.
For these experiments both the baselineand our method use a language model trainedon the target side of the full original training set(approximately 1M sentences).Chinese-EnglishThe data for our Chinese-English experiments isderived from a combination of MultiUn(Eiseleand Chen, 2010; Tiedemann, 2012)5data andHong Kong Parallel Text data from the LinguisticData Consortium6.
The Hong Kong Parallel Textdata is in traditional Chinese and is thus firstconverted to simplified Chinese to be compatible5Freely available and downloaded fromhttp://opus.lingfil.uu.se/6The LDC catalog number of this dataset is LDC2004T0816System NameDEV TESTBLEU ?
METEOR ?
TER ?
KRS ?
BLEU ?
METEOR ?
TER ?
KRS ?German-EnglishHiero 27.90 32.69 58.22 66.37 28.39 32.94 58.01 67.44SAMT 27.76 32.67 58.05 66.84N28.32 32.88 57.70NN67.63Hiero-0thITG+-Sft 28.00N32.76NN57.90NN66.17 28.48 32.98 57.79NN67.32Hiero-0th-Sft 28.01N32.71 57.95NN66.24 28.45 32.98 57.73NN67.51Hiero-1stCoarse-Sft 27.94 32.69 57.91NN66.26 28.45N32.94 57.75NN67.36Hiero-1st-Sft 28.13NN32.80NN57.92NN66.32 28.45 33.00N57.79NN67.45Chinese-EnglishHiero 31.70 30.72 61.21 58.28 31.63 30.56 59.28 58.03Hiero-0thITG+-Sft 31.88N30.46HH60.64NN57.82H31.93NN30.37HH58.86NN57.60HHiero-0th-Sft 32.04NN30.90NN61.47HH59.36NN32.20NN30.74NN59.45H58.92NNHiero-1stCoarse-Sft 32.39NN31.02NN61.56HH59.51NN32.55NN30.86NN59.57HH59.03NNHiero-1st-Sft 32.63NN31.22NN62.00HH60.43NN32.61NN30.98NN60.19HH59.84NNTable 3: Mean results bilingual labels with soft matching.4with the rest of the data7.
We used a maximumsentence length of 40 for filtering the trainingdata.
The combined dataset has 7.34M sentencepairs.
The MulitUN dataset contains translateddocuments from the United Nations, similar ingenre to the parliament domain.
The Hong KongParallel Text in contrast contains a richer mixof domains, namely Hansards, Laws and News.For the dev and test set we use the Multiple-Translation Chinese datasets from LDC, part 1-48,which contain sentences from the News domain.We combined part 2 and 3 to form the dev set(1813 sentence pairs) and part 1 and 4 to form thetest set (1912 sentence pairs).
For both develop-ment and testing we use 4 references.
The Chinesesource side of all datasets is segmented using theStanford Segmenter(Chang et al., 2008)9.
TheEnglish target side of all datasets is tokenizedusing the Moses tokenization script.For these experiments both the baseline andour method use a language model trained on5.4M sentences of domain specific10news datataken from the ?Xinhua?
subcorpus of the EnglishGigaword corpus of LDC.117Using a simple conversion script downloaded fromhttp://www.mandarintools.com/zhcode.html8LDC catalog numbers: LDC2002T01, DC2003T17,LDC2004T07 and LDC2004T079Downloaded fromhttp://nlp.stanford.edu/software/segmenter.shtml10For Chinese-English translation the different domain ofthe train data (mainly parliament) and dev/test data (news)requires usage of a domain specific language model to getoptimal results.
For German-English, all data is from thethe parliament domain, so a language model trained on the(translation model) training data is already domain-specific.11The LDC catalog number of this dataset is LDC2003T054.1 Experimental StructureIn our experiments we explore the influence ofthree dimensions of bilingual reordering labels ontranslation accuracy.
These dimensions are:?
label granularity : granularity of the labeling{Coarse,Fine}?
label order : the type/order of the labeling{0th, 1st}?
matching type : the type of label matchingperformed during decoding {Strict,Soft}Combining these dimensions gives 8 differentreordering labeled systems per language pair.On top of that we use two baseline systems,namely Hiero and Syntax Augmented MachineTranslation (SAMT) to measure these systemsagainst.
An overview of the naming of ourreordering labeled systems is given in Table 1.Training and decoding details Our experimentsuse Joshua (Ganitkevitch et al., 2012) with Viterbibest derivation.
Baseline experiments use nor-mal decoding whereas soft labeling experimentsuse soft constraint decoding.
For training weuse standard Hiero grammar extraction constraints(Chiang, 2007) (phrase pairs with source spansup to 10 words; abstract rules are forbidden).During decoding maximum span 10 on the sourceside is maintained.
Following common practice,we use relative frequency estimates for phraseprobabilities, lexical probabilities and generativerule probability.We train our systems using (batch-kbest) Miraas borrowed by Joshua from the Moses codebase,allowing up to 30 tuning iterations.
Following17standard practice, we tune on BLEU, and aftertuning we use the configuration with the highestscores on the dev set with actual (corpus level)BLEU evaluation.
We report lowercase BLEU(Papineni et al., 2002), METEOR (Denkowskiand Lavie, 2011) and TER (Snover et al., 2006)scores for the tuned test set and also for the tuneddev set, the latter mainly to observe any possibleoverfitting.
We use Multeval version 0.5.1.12forcomputing these metrics.
We also use MultEval?simplementation of statistical significance testingbetween systems, which is based on multipleoptimizer runs and approximate randomization.Multeval (Clark et al., 2011) randomly swapsoutputs between systems and estimates the prob-ability that the observed score difference arose bychance.
Differences that are statistically signif-icant and correspond to improvement/worseningwith respect to the baseline are marked withN/Hatthe p ?
.05 level andNN/HHat the p ?
.01 level.
Wealso report the Kendall Reordering Score (KRS),which is the reordering-only variant of the LR-score (Birch and Osborne, 2010) (without theoptional interpolation with BLEU) and which isa sentence-level score.
For the computation ofstatistical significance of this metric we use ourown implementation of the sign test13(Dixon andMood, 1946), as also described in (Koehn, 2010).In our experiments we repeated each experi-ment three times to counter unreliable conclusionsdue to optimizer variance.
Scores are averagesover three runs of tuning plus testing.
Scoresmarked withNare significantly better than thebaseline, those marked withHare significantlyworse; according to the resampling test of Mul-teval (Clark et al., 2011).Preliminary experiment with strict matchingInitial experiments concerned 0th-order reorder-ing labels in a strict matching approach (no softconstraints).
The results are shown in Table 2 forboth language pairs.
The results for the Hiero andSAMT14baselines (Hiero and SAMT) are shownin the first rows.
Below it results for the 0th-order(phrase-centric) bilingual labeled systems witheither the Coarse (Hiero-0thITG+) or Fine label12https://github.com/jhclark/multeval13To make optimal usage of the 3 runs we computedequally weighted improvement/worsening counts for allpossible 3 ?
3 baseline output / system output pairs and usethose weighted counts in the sign test.14SAMT could only be ran for German-English and notfor Chinese-English, due to memory constraints.variant (Hiero-0th) are shown, followed by theresults for Coarse and Fine variant of the 1th-order(parent-relative) bilingual labeled systems (Hiero-1stCoarseand Hiero-1st).
All these systems use thedefault decoding with strict label matching.For German-English the effect of strict bilin-gual labels is mostly positive: although we haveno improvement for BLEU we do achieve sig-nificant improvements for METEOR and TERon the test set.
For Chinese-English, overallHiero-0thITG+shows the biggest improvements,namely significant improvements of +0.31 BLEU,+0.28 METEOR and +1.42 KRS.
TER is theonly metric that worsens, and considerably sowith +1.48 point.
Hiero-1stachieves the highestimprovement of KRS, namely 1.86 point higherthan the Hiero baseline.
Overall, this preliminaryexperiment shows that strict labeling sometimesgives improvements over Hiero, but sometimes itleads to worsening in terms of some of the metrics.Results with soft bilingual constraints Our ini-tial experiments with strict bilingual labels incombination with strict matching by the decodergave some hope such constraints could be useful.At the same time the results showed no stableimprovements across language pairs, and thusdoes not allow us to draw definite conclusionsabout the merit of bilingual labels.Results for experiments with soft bilingual la-beling are shown in Table 3.
Here Hiero corre-sponds to the Hiero baseline.
Below it are shownthe systems that use soft constraint decoding (SCD).
Hiero-0thITG+-Sft and Hiero-0th-Sft usingphrase-centric labels (0th-order) in Coarse or Fineform.
Similarly, Hiero-1stCoarse-Sft and Hiero-1st-Sft correspond to the analog systems with1st-order, parent-relative labels.
For German-English there are only minor improvements forBLEU and METEOR, with somewhat bigger im-provements for TER.
For Chinese-English how-ever the improvements are considerable, +0.98BLEU improvement over the Hiero baseline forHiero-1st-Sft as well as +0.42 METEOR and+1.81 KRS.
TER is worsening with +0.85 for thissystem.
For Chinese-English the Fine version ofthe labels gives overall superior results for both0th-order and 1st-order labels.Discussion Our best soft bilingual labeling systemfor German-English shows small but significantimprovements of METEOR and TER while im-18proving BLEU and KRS as well, but not signifi-cantly.
The results with soft-constraint matchingare better than those for strict-matching in general,while there is no clear winner between the Coarseand Fine variant of labels.For Chinese-English we see considerableimprovements and overall the best results forthe combination of soft-constraint matching,with the Fine 1st-order variant of the labeledsystems (Hiero-1st-Sft).
For Chinese-English theimprovement of the word-order is also particularlyclear as indicated by the +1.81 KRS improvementfor this best system.
Furthermore the negativeeffects in terms of worsening of TER are alsoreduced in the soft-matching setting, droppingfrom +1.48 TER to +0.85 TER.
The results forHiero-0th-Sft are also competitive, since thoughit gives somewhat lower improvements of BLEUand METEOR, it gives an improvement of +1.89KRS, while TER only worsens by +0.17 for thissystem.We conclude that bilingual Markov labels canmake a big difference in improvement of hier-archical SMT.
We observe that going beyondthe basic reordering labels of ITG, refining thecases not captured by ITG and even more ef-fective: taking a 1st-order rather than oth-orderperspective on reordering are major factors forthe success of including reordering information tohierarchical SMT through labeling.
Crucial to thesuccess of this undertaking is also the usage ofa soft-constraint approach to label matching, asopposed to strict-matching.
Finally, comparisonof the German-English results with results forSyntax-Augmented Machine Translation (SAMT)reveals that SAMT loses performance comparedto the Hiero baseline for BLEU, the metric uponwhich tuning is done, as well as METEOR, whileonly TER and KRS show improvement.
Sincethe best bilingual labeled system for German-English (Hiero-1st-Sft) improves METEOR andTER significantly, while also improving BLEUand KRS, though not significant, we believe ourlabeling is highly competitive with syntax-basedlabeling approaches, without the need for anyadditional resources in the form of parsers ortaggers, as syntax-based systems require.
Likelycomplementarity of reordering information, and(target) syntax, which improves fluency, makescombining both a promising possibility we wouldlike to explore in future work.5 ConclusionWe presented a novel method to enrich Hierarchi-cal Statistical Machine Translation with bilinguallabels that help to improve the translation quality.Considerable and significant improvements of theBLEU, METEOR and KRS are achieved simul-taneously for Chinese-English translation whiletuning on BLEU, where the Kendall ReorderingScore is specifically designed to measure im-provement of reordering in isolation.
For German-English more modest, statistically significant im-provements of METEOR and TER (simultane-ously) or BLEU (separately) are achieved.
Ourwork differs from related approaches that usesyntactic or part-of-speech information in the for-mation of reordering constraints in that it needs nosuch additional information.
It also differs fromrelated work on reordering constraints based onlexicalization in that it uses no such lexicaliza-tion but instead strives to achieve more globallycoherent translations, afforded by global, holisticconstraints that take the local reordering historyof the derivation directly into account.
Our exper-iments also once again reinforce the establishedwisdom that soft, rather than strict constraints,are a necessity when aiming to include new in-formation to an already strong system without therisk of effectively worsening performance throughconstraints that have not been directly tailoredto the data through a proper learning approach.While lexicalized constraints on reordering haveproven to have great potential, un-lexicalized softbilingual constraints, which are more general andtranscend the rule level have their own place inproviding another agenda of improving transla-tion which focusses more on the global coher-ence direction by directly putting soft alignment-informed constraints on the combination of rules.Finally, while more research is necessary in thisdirection, there are strong reasons to believe thatin the right setup these different approaches can bemade to further reinforce each other.AcknowledgementsThis work is supported by The Netherlands Or-ganization for Scientific Research (NWO) undergrant nr.
612.066.929.
The authors would like tothank Matt Post and Juri Ganitkevitch, for theirsupport with respect to the integration of FuzzyMatching Decoding into the Joshua codebase.19ReferencesAlexandra Birch and Miles Osborne.
2010.
Lrscorefor evaluating lexical and reordering quality in mt.In Proceedings of the Joint Fifth Workshop onStatistical Machine Translation and MetricsMATR,pages 327?332.Pi-Chuan Chang, Michel Galley, and Christopher D.Manning.
2008.
Optimizing chinese wordsegmentation for machine translation performance.In Proceedings of the Third Workshop on StatisticalMachine Translation, pages 224?232.Stanley F. Chen and Joshua T. Goodman.
1998.An empirical study of smoothing techniques forlanguage modeling.
Technical Report TR-10-98,Computer Science Group, Harvard University.David Chiang.
2005.
A hierarchical phrase-based model for statistical machine translation.
InProceedings of the 43rd Annual Meeting of the ACL,pages 263?270, June.David Chiang.
2006.
An introduction to synchronousgrammars.David Chiang.
2007.
Hierarchical phrase-basedtranslation.
Computational Linguistics, 33(2):201?228.David Chiang.
2010.
Learning to translate withsource and target syntax.
In Proceedings ofthe 48th Annual Meeting of the Association forComputational Linguistics, pages 1443?1452.Jonathan H. Clark, Chris Dyer, Alon Lavie, andNoah A. Smith.
2011.
Better hypothesis testingfor statistical machine translation: Controllingfor optimizer instability.
In Proceedings ofthe 49th Annual Meeting of the Associationfor Computational Linguistics: HLTTechnologies:Short Papers - Volume 2, pages 176?181.Michael Denkowski and Alon Lavie.
2011.
Meteor1.3: Automatic metric for reliable optimizationand evaluation of machine translation systems.
InProceedings of the Sixth Workshop on StatisticalMachine Translation, pages 85?91.W.
J. Dixon and A. M. Mood.
1946.
The statisticalsign test.
Journal of the American StatisticalAssociation, pages 557?566.Andreas Eisele and Yu Chen.
2010.
Multiun: Amultilingual corpus from united nation documents.In Proceedings of the 7th International Conferenceon Language Resources and Evaluation (LREC2010), pages 2868?2872.Juri Ganitkevitch, Yuan Cao, Jonathan Weese, MattPost, and Chris Callison-Burch.
2012.
Joshua4.0: Packing, pro, and paraphrases.
In Proceedingsof the Seventh Workshop on Statistical MachineTranslation, pages 283?291, Montr?eal, Canada,June.
Association for Computational Linguistics.Greg Hanneman and Alon Lavie.
2013.
Improvingsyntax-augmented machine translation by coarsen-ing the label set.
In HLT-NAACL, pages 288?297.Hieu Hoang, Alexandra Birch, Chris Callison-burch,Richard Zens, Rwth Aachen, Alexandra Constantin,Marcello Federico, Nicola Bertoldi, Chris Dyer,Brooke Cowan, Wade Shen, Christine Moran, andOndrej Bojar.
2007.
Moses: Open source toolkitfor statistical machine translation.
In Proceedingsof the 41st Annual Meeting on Association forComputational Linguistics - Volume 1, pages 177?180.Liang Huang, Kevin Knight, and Aravind Joshi.2006.
A syntax-directed translator with extendeddomain of locality.
In Proceedings of the Workshopon Computationally Hard Problems and JointInference in Speech and Language Processing,pages 1?8.Matthias Huck, Joern Wuebker, Felix Rietig, andHermann Ney.
2013.
A phrase orientationmodel for hierarchical machine translation.
InACL 2013 Eighth Workshop on Statistical MachineTranslation, pages 452?463.Dan Klein and Christopher D. Manning.
2003.Accurate unlexicalized parsing.
In Proceedingsof the 41st Annual Meeting on Association forComputational Linguistics - Volume 1, pages 423?430.P.
Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In Proc.
of MTSummit.Philipp Koehn.
2010.
Statistical Machine Translation.Cambridge University Press, New York, NY, USA.Yang Liu, Qun Liu, and Shouxun Lin.
2006.
Tree-to-string alignment template for statistical machinetranslation.
In Proceedings of the 21st InternationalConference on Computational Linguistics andthe 44th Annual Meeting of the Association forComputational Linguistics, pages 609?616.Gideon Maillette de Buy Wenniger and KhalilSima?an.
2013.
Hierarchical alignment decomposi-tion labels for hiero grammar rules.
In Proceedingsof the Seventh Workshop on Syntax, Semantics andStructure in Statistical Translation, pages 19?28.Yuval Marton, David Chiang, and Philip Resnik.2012.
Soft syntactic constraints for arabic?englishhierarchical phrase-based translation.
MachineTranslation, 26(1-2):137?157.Haitao Mi and Liang Huang.
2008.
Forest-basedtranslation rule extraction.
In Proceedings ofEMNLP.Haitao Mi, Liang Huang, and Qun Liu.
2008.
Forest-based translation.
In Proceedings of ACL: HLT,June.20Markos Mylonakis and Khalil Sima?an.
2011.Learning hierarchical translation structure withlinguistic annotations.
In Proceedings of the49th Annual Meeting of the Association forComputational Linguistics: Human LanguageTechnologies, pages 642?652.Markos Mylonakis.
2012.
Learning the LatentStructure of Translation.
Ph.D. thesis, Universityof Amsterdam.ThuyLinh Nguyen and Stephan Vogel.
2013.Integrating phrase-based reordering features into achart-based decoder for machine translation.
InProceedings of the 51st Annual Meeting of theAssociation for Computational Linguistics (Volume1: Long Papers), pages 1587?1596.Franz Josef Och.
2003.
Minimum error rate trainingin statistical machine translation.
In Proceedingsof the 41st Annual Meeting on Association forComputational Linguistics - Volume 1, pages 160?167.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: A method for automaticevaluation of machine translation.
In Proceedingsof the 40th Annual Meeting on Association forComputational Linguistics, pages 311?318.Khalil Sima?an and Gideon Maillette de Buy Wen-niger.
2013.
Hierarchical alignment trees:A recursive factorization of reordering in wordalignments with empirical results.
Internal Report.Matthew Snover, Bonnie Dorr, Richard Schwartz,Linnea Micciulla, and John Makhoul.
2006.
Astudy of translation edit rate with targeted humanannotation.
In In Proceedings of Association forMachine Translation in the Americas, pages 223?231.Jrg Tiedemann.
2012.
Parallel data, tools andinterfaces in opus.
In Proceedings of the 8thInternational Conference on Language Resourcesand Evaluation (LREC 2012), pages 2868?2872.Christoph Tillmann.
2004.
A unigram orientationmodel for statistical machine translation.
InProceedings of HLT-NAACL 2004: Short Papers,pages 101?104.Ashish Venugopal, Andreas Zollmann, Noah A. Smith,and Stephan Vogel.
2009.
Preference grammars:softening syntactic constraints to improve statisticalmachine translation.
In Proceedings of Human Lan-guage Technologies: The 2009 Annual Conferenceof the North American Chapter of the Associationfor Computational Linguistics, pages 236?244.Dekai Wu and Hongsing Wong Hkust.
1998.
Machinetranslation with a stochastic grammatical channel.In Proceedings of the 36th Annual Meeting ofthe Association for Computational Linguistics and17th International Conference on ComputationalLinguistics - Volume 2, pages 1408?1415.Dekai Wu.
1997.
Stochastic inversion transductiongrammars and bilingual parsing of parallel corpora.Computational Linguistics, 23:377?404.Xinyan Xiao, Jinsong Su, Yang Liu, Qun Liu, andShouxun Lin.
2011.
An orientation modelfor hierarchical phrase-based translation.
InProceedings of the 2011 International Conferenceon Asian Language Processing, pages 165?168.Hao Zhang, Daniel Gildea, and David Chiang.2008.
Extracting synchronous grammar rulesfrom word-level alignments in linear time.
InProceedings of the 22nd International Conferenceon Computational Linguistics - Volume 1, pages1081?1088.Bowen Zhou, Bing Xiang, Xiaodan Zhu, and YuqingGao.
2008.
Prior derivation models for formallysyntax-based translation using linguistically syntac-tic parsing and tree kernels.
In Proceedings ofthe ACL-08: HLT Second Workshop on Syntax andStructure in Statistical Translation (SSST-2), pages19?27.Andreas Zollmann and Ashish Venugopal.
2006.Syntax augmented machine translation via chartparsing.
In NAACL 2006 - Workshop on statisticalmachine translation, June.21
