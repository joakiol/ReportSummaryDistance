Proceedings of the BioNLP Shared Task 2013 Workshop, pages 104?108,Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational LinguisticsA fast rule-based approach for biomedical event extractionQuoc-Chinh BuiDepartment of Medical Informatics,Erasmus Medical CentreRotterdam, Netherlandsq.bui@erasmusmc.nlErik M. van MulligenDepartment of Medical Informatics,Erasmus Medical CentreRotterdam, Netherlandse.vanmulligen@erasmusmc.nlDavid CamposIEETA/DETI, University of Aveiro3810-193 AveiroPortugaldavid.campos@ua.ptJan A. KorsDepartment of Medical Informatics,Erasmus Medical CentreRotterdam, Netherlandsj.kors@erasmusmc.nlAbstractIn this paper we present a biomedical eventextraction system for the BioNLP 2013 eventextraction task.
Our system consists of twophases.
In the learning phase, a dictionary andpatterns are generated automatically fromannotated events.
In the extraction phase, thedictionary and obtained patterns are applied toextract events from input text.
When evaluatedon the GENIA event extraction task of theBioNLP 2013 shared task, the system obtainedthe best results on strict matching and the thirdbest on approximate span and recursivematching, with F-scores of 48.92 and 50.68,respectively.
Moreover, it has excellentperformance in terms of speed.1 IntroductionA growing amount of biomedical data iscontinuously being produced, resulting largelyfrom the widespread application of high-throughput techniques, such as gene and proteinanalysis.
This growth is accompanied by acorresponding increase of textual information, inthe form of articles, books and technical reports.In order to organize and manage these data,several manual curation efforts have been set upto identify entities (e.g., genes and proteins),their interactions (e.g., protein-protein) andevents (e.g., transcription and gene regulation).The extracted information is then stored instructured knowledge resources, such asMEDLINE and Swiss-Prot.
However, manualcuration of large quantities of data is a verydemanding and expensive task, and it is difficultto keep these databases up-to-date.
These factorshave naturally led to an increasing interest in theapplication of text mining (TM) systems tosupport those tasks.Automatic recognition of biomedical eventsfrom scientific documents was highly promotedby the BioNLP challenges (Kim et al 2009;2011), focusing on events that involve genes andproteins, such as gene expression, binding, andregulation.
Such events are typically representedas the relation between a trigger and one or morearguments, which can be biomedical concepts orother events.Several approaches have been proposed toextract biological events from text (Kim et al2009; 2011).
Based on their characteristics andapplied natural language processing (NLP) tools,these approaches can be categorized into twomain groups, namely rule- and machine learning(ML)-based approaches.
Rule-based approachesconsist of a set of rules that are manually definedor automatically learned from training data (Bui& Sloot, 2011; Cohen et al 2009; Kaljurand etal., 2009; Kilicoglu & Bergler, 2011).
To extractevents from text, first event triggers are detectedusing a dictionary, then the defined rules areapplied to the output of the NLP tools e.g.,dependency parse trees, to find their arguments.On the other hand, ML-based approaches exploitvarious feature sets and learning algorithms toextract events (Bj?rne & Salakoski, 2011; Miwaet al 2010; 2012; Riedel & McCallum, 2011).This article presents an enhanced version ofour biomedical event extraction system (Bui &Sloot, 2012).
Here we simplify the way patternsare generated from training data and improve themethod to extract events from text based on theobtained patterns.1042 System and methodsThe workflow of the system is illustrated inFigure 1.
A text preprocessing step, whichconverts unstructured text into a structuredrepresentation, is applied for both learning andextraction phases.
In the learning phase, adictionary and patterns are generatedautomatically from annotated events.
In theextraction phase, the dictionary and obtainedpatterns are applied to extract events from inputtext.2.1 Text preprocessingThe text preprocessing step intends to break theinput text into meaningful units, in order toreveal important linguistic features.
This stepconsists of splitting input text into singlesentences, tokenizing sentences, part-of-speech(POS) tagging, shallow parsing, and convertingobtained chunks into simple clauses.
An in-depthdescription of this step is provided in (Bui &Sloot, 2012).
An example of a structuredrepresentation is illustrated in Figure 2.2.2 Building a dictionaryThe dictionary construction is carried outautomatically using event triggers from trainingdata.
This process consists of four steps:grouping event triggers, calculating confidencescores, filtering out irrelevant triggers, anddetermining event types.
First, we collect allevent triggers annotated in the training dataset,convert them to lower-case and group thembased on their text and event types.
For eachevent trigger, we count the number of times itappears as an event trigger and the number oftimes it appears in the training dataset, in order tocalculate its confidence score.
Next, we filter outtriggers that have POS tags not starting with?NN?, ?VB?, or ?JJ?, as well as triggers thatconsist of more than two words, as suggested in aprevious study (Kilicoglu & Bergler, 2011).
Wefurther filter out more triggers by setting afrequency threshold and confidence score foreach event type.
Finally, we assign an event typefor each event trigger based on its type annotatedin the training data.
If an event trigger belongs tomore than one event group, we determine itsevent type based on the event group where itappears with highest frequency.
For instance, the?effect?
trigger appears in both ?Regulation?
and?Positive_regulation?
groups, but its frequencyin the ?Regulation?
group is higher, therefore itis assumed to be a ?Regulation?
event trigger.2.3 Predefined patternsWhen using a structured representation toexpress biomedical events, in most cases, anevent can be mapped into a ?container?, i.e., achunk, a phrase, or a clause as shown in Figure2.
Based on this representation, we define a listof the most common patterns that encoderelations between an event trigger and itsarguments.
The predefined list of patterns isshown in Table 1.
We skip all events that cannotbe expressed within a simple clause.TrainTestLearning phase Extracting phaseBuilddictionary - Sentence splitting- Tokenization- POS tagging- Shallow parsing- Chunk converterPre-processingGeneratepatternsExtractevents- Noun phrases- Simple clausesDictionaryPatternsEvents1 234Figure 1: workflow of the system.Figure 2: Structured representation of biomedicalevents.E2:Gene_expressionPRO2 expressionCauseE1: PhosphorylationE3: Neg.
Reg.PhosphorylationofPRO1inhibits ClausePhraseChunkSyntacticlayerThemeThemeTheme105Table 1: Common patterns for relations between anevent trigger and its arguments.
Trg denotes eventtrigger, prep: preposition, arg1: event theme, andarg2: theme2 or cause of an event.2.4 Generating patternsTo generate a pattern for each event, first we finda suitable container (e.g., chunk, phrase, orclause) that contains the event trigger and itsarguments.
If such a container is found, a patternis generated by extracting features from thatcontainer using a list of defined feature set asshown in Table 2.
Each generated pattern is thenassigned a key by combining its event trigger,POS tag, pattern type, and container type.
Thiskey is used to retrieve this pattern in theextraction step.
During the learning process, if akey of a newly generated pattern already exists,the system increases the frequency attribute ofthe existing pattern and updates the otherattributes accordingly.Features Description and examplesTrigger Event trigger.Prep1 Preposition between theme and trigger, e.g.
of,in.Pattern type Defined in Table 1.Prep2 Preposition between cause/theme2 and trigger.Container The container which contains this event.Distance1 Distance (number of chunks) between theme andevent trigger.Distance2 Distance (number of chunks) betweencause/theme2 and event trigger.POS POS tag of the trigger e.g.
NN, ADJ, and VBZ.Pro1 count Count number of events with a protein as theme.Even1 count Count number of events with an event as theme.Pro2 count Count number of events with a protein astheme2/cause.Even2 count Count number of events with an event astheme2/cause.Frequency Number of events sharing the same pattern key.This value is used to rank the patterns in theextraction step.Table 2: Feature set used to generate patterns.2.5 Extracting eventsIn this step, we apply the obtained patterns toextract events from text.
First, the input sentenceis converted into a structured representation byapplying the text preprocessing step.
Next,tokens of each sentence are matched against thedictionary to detect candidate event triggers.
Foreach candidate event trigger, a key is generatedto retrieve its corresponding patterns.
If patternsfor the event trigger exist, we then apply theretrieved patterns using the order of the syntacticlayers: chunk, phrase, and clause (see Figure 2).Furthermore, if there is more than one patternavailable for a syntactic layer (e.g.
chunk,phrase), the order to apply patterns is determinedby the frequency of these patterns, which iscalculated in the previous step.
Patterns withhigher frequency have higher priority.3 Results3.1 DatasetsWe used the training and development datasetsprovided by the BioNLP?11 and BioNLP?13shared tasks to train our system.
The statistics ofthe datasets are presented in Table 3.Items Training  TestAbstracts (+full papers) 950 (+20) 0 (+10)Proteins 19089 4359Events 16403 3301Availability of events Yes HiddenTable 3: Characteristics of the training and test da-tasets.All training data were used to build thedictionary and generate patterns.
In ourexperiment, we used the same dictionary for thelearning and extraction phases.
The confidencescore of all entries in the dictionary was set to0.1.
In the extraction phase, the distance features(?Distance1?
and ?Distance2?)
were set to amaximum of 10 chunks, and patterns that have afrequency lower than 3 were not used in order toreduce false-positive events.3.2 Event extractionTable 4 presents the results achieved by oursystem on the BioNLP 2013 GENIA test datasetusing both strict and approximate matching.
Oursystem achieves an F-score of 48.92 with strictmatching, and an F-score of 50.68 withapproximate matching.
For relaxed matching, theContainer Pattern typeChunkTrg ?
Arg1Arg2-Trg-Arg1Arg1-TrgPhraseTrg-Prep1- Arg1Trg-Prep1-Arg1-Prep2 ?Arg2Trg-Prep2-Arg2-Prep1 ?Arg1Arg2-Trg-Prep1-Arg1Arg1-Arg2-TrgClauseArg1 ?
TrgTrg ?
Arg1Arg2 ?
Trg ?
Arg1Arg1 ?
Trg ?
Arg2106data show that our system performs well onsimple events (?simple all?)
with an average F-score of 76.11, followed by protein modificationevents (?prot-mod all?)
with an average F-scoreof 74.37.
The performance declines on bindingevents with an F-score of 49.76 and regulatoryevents (?regulation all?)
with an average F-scoreof 35.80.
When comparing the performance ofour system between the two matching criteria,the data indicate that only Transcription eventsgain significant performance, with an F-scoreincrease of 30 points.Event type Strict matching Approximate spanR P F1 R P F1Gene expression 72.86 85.74 78.78 73.83 86.88 79.83Transcription 32.67 48.53 39.05 58.42 86.76 69.82Protein catabolism 42.86 75.00 54.55 42.86 75.00 54.55Localization 42.42 89.36 57.53 42.42 89.36 57.53Simple all 63.87 81.97 71.79 67.71 86.90 76.11Binding 47.45 52.32 49.76 47.45 52.32 49.76Phosphorylation 82.50 80.49 81.48 82.50 80.49 81.48Prot-mod all 69.11 80.49 74.37 69.11 80.49 74.37Regulation 12.50 30.25 17.69 13.19 31.09 18.53Positive regulation 30.62 49.93 37.96 31.68 51.66 39.28Negative regulation 28.33 49.17 35.95 28.90 50.17 36.67Regulation all 27.31 47.62 34.72 28.19 49.06 35.80Event total 40.99 60.67 48.92 42.47 62.83 50.68Table 4: Precision (P), recall (R) and F-score (F1)results achieved on the test set of BioNLP 2013, eval-uated on strict matching and approximate span andrecursive criteria.Table 5 presents a comparison of the overallperformance results with the top-five performingsystems in the BioNLP 2013 GENIA task.
Thedata show that our system (BioSem) achieves thebest results on strict matching, and ranks third onapproximate matching, with a slight difference inF-score of 0.29 point compared to the bestsystem.
Furthermore, our system yields the bestprecision on both matching criteria, with aconsiderable difference on strict matching.Team Strict matching Approximate spanR P F1 R P F1EVEX 42.99 54.89 48.22 45.44 58.03 50.97TEES-2.1 43.71 53.33 48.04 46.17 56.32 50.74NCBI 37.35 56.72 45.04 40.53 61.72 48.93DlutNLP 37.75 52.73 44.00 40.81 57.00 47.56BioSem 40.99 60.67 48.92 42.47 62.83 50.68Table 5: Performance comparison of overall Precision(P), recall (R) and F-score (F1) with the five best sys-tems.A closer look at the official results (data notshown) reveals that our system obtains the bestperformance on Binding event with an F-score of49.76, which is significantly higher than thesecond-best system (F-score 43.32).Interestingly, our system also yields the highestF-score (58.77) when evaluated on themes only.When aiming for a large-scale relationextraction, system performance in terms of speedhas to be taken into account.
By employing asimple text processing and an effective eventextraction algorithm, our system is very fast.
Ona standard PC with 4GB of RAM, it takes 49s toprocess the training dataset and 11s to processthe test dataset.4 Conclusion and future workThis article presents a system for biomedicalevent extraction that generates patternsautomatically from training data.
Whenevaluated on the test set, it presented the bestresults with strict matching and the third bestwith approximate span and recursive matching.Moreover, it obtains high precision on bothevaluation criteria, and has an excellentperformance in terms of speed.There are various ways to further improve theperformance of the system.
First, we believe thatan ML-based approach for trigger recognitionwill improve its results, by minimizingambiguity problems and improving recall,especially on regulatory events.
Second, the finalperformance depends on the output of the text-preprocessing step, especially the conversion ofchunks into structured representations.
If theperformance of this step is improved, forexample by using predicate argument structuresas proposed by (Miwa et al 2010) to obtainrelations between subject-verb-object, then moreprecise patterns could be obtained in the learningphase.
Consequently, the extraction phase wouldhave a cleaner input (with less false positives andfalse negatives), which will eventually enhancethe performance.
Furthermore, as proposed inour previous study (Bui et al 2011), the outputof the current system can be used as the input foran ML classifier to further reduce false-positiveevents.
The feature set used in the predefinedpatterns can also be used directly as feature setfor the ML classifier.AcknowledgmentsD.
Campos was funded by FEDER through theCOMPETE programme and by national fundsthrough FCT - ?Funda?
?o Para a Ci?ncia e aTecnologia?
under the project numberPTDC/EIA-CCO/100541/2008.107ReferencesBj?rne, J., & Salakoski, T. (2011).
Generalizing bio-medical event extraction (pp.
183?191).
Present-ed at the BioNLP Shared Task 2011 Workshop,Portland, Oregon, USA: Association for Compu-tational Linguistics.Bui, Q. C., & Sloot, P. (2011).
Extracting biologicalevents from text using simple syntactic patterns(pp.
143?146).
Presented at the BioNLP SharedTask 2011 Workshop, Portland, Oregon, USA.Bui, Q.-C., & Sloot, P. M. A.
(2012).
A robust ap-proach to extract biomedical events from litera-ture.
Bioinformatics (Oxford, England), 28(20),2654?2661.
doi:10.1093/bioinformatics/bts487Bui, Q.-C., Katrenko, S., & Sloot, P. M. A.
(2011).
Ahybrid approach to extract protein-protein inter-actions.
Bioinformatics (Oxford, England),27(2), 259?265.Cohen, K. B., Verspoor, K., Johnson, H. L., Roeder,C., Ogren, P. V, Jr, W. A.
B., White, E., et al(2009).
High-precision biological event extrac-tion with a concept recognizer.
Proceedings ofBioNLP?09 Shared Task Workshop (pp.
50?58).Kaljurand, K., Schneider, G., & Rinaldi, F. (2009).UZurich in the BioNLP 2009 shared task.
Pro-ceedings of BioNLP?09 Shared Task Workshop(pp.
28?36).Kilicoglu, H., & Bergler, S. (2011).
Adapting a gen-eral semantic interpretation approach to biologi-cal event extraction (pp.
173?182).
Presented atthe BioNLP Shared Task 2011 Workshop, Port-land, Oregon, USA: BioNLP Shared Task 2011Workshop.Kim, J.-D., Ohta, T., Pyysalo, S., Kano, Y., & Tsujii,J.
(2009).
Overview of BioNLP'09 shared task onevent extraction (pp.
1?9).
Presented at the Bi-oNLP Shared Task 2009 Workshop, Boulder,Colorado, USA: Association for ComputationalLinguistics.Kim, J.-D., Wang, Y., Takagi, T., & Yonezawa, A.(2011).
Overview of genia event task in bionlpshared task 2011 (pp.
7?15).
Presented at the Bi-oNLP Shared Task 2011 Workshop, Portland,Oregon, USA: Association for ComputationalLinguistics.Miwa, M., S?tre, R., Kim, J.-D., & Tsujii, J.
(2010).Event extraction with complex event classifica-tion using rich features.
Journal of bioinformat-ics and computational biology, 8(1), 131?146.Miwa, M., Thompson, P., & Ananiadou, S. (2012).Boosting automatic event extraction from the lit-erature using domain adaptation and coreferenceresolution.
Bioinformatics (Oxford, England),28(13), 1759?65.Riedel, S., & McCallum, A.
(2011).
Robust biomedi-cal event extraction with dual decomposition andminimal domain adaptation.
Presented at the Bi-oNLP Shared Task 2011 Workshop, Portland,Oregon, USA.108
