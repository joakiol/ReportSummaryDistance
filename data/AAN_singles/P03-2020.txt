Automatic Collection of Related Terms from the WebSatoshi Sato and Yasuhiro SasakiGraduate School of InformaticsKyoto UniversitySakyo, Kyoto, 606-8501Japansato@i.kyoto-u.ac.jp, sasaki@pine.kuee.kyoto-u.ac.jpAbstractThis paper proposes a method of collect-ing a dozen terms that are closely re-lated to a given seed term.
The proposedmethod consists of three steps.
The firststep, compiling corpus step, collects textsthat contain the given seed term by us-ing search engines.
The second step, au-tomatic term recognition, extracts impor-tant terms from the corpus by using Naka-gawa?s method.
These extracted terms be-come the candidates for the final step.
Thefinal step, filtering step, removes inappro-priate terms from the candidates based onsearch engine hits.
An evaluation resultshows that the precision of the method is85%.1 IntroductionThis study aims to realize an automatic method ofcollecting technical terms that are related to a givenseed term.
In case ?natural language processing?
isgiven as a seed term, the method is expected to col-lect technical terms that are related to natural lan-guage processing, such as morphological analysis,parsing, information retrieval, and machine transla-tion.
The target application of the method is auto-matic or semi-automatic compilation of a glossary ortechnical-term dictionary for a certain domain.
Re-cursive application of the method enables to collect alist of terms that are used in a certain domain: the listbecomes a glossary of the domain.
A technical-termdictionary can be compiled by adding an explanationfor every term in the glossary, which is performed byterm explainer (Sato, 2001).??
?a seed terms?Compilingcorpus??????corpusCs????
?the Web??ATR???
?related termsT?
Filtering ???
?candidatesXFigure 1: System configurationAutomatic acquisition of technical terms in a cer-tain domain has been studied as automatic termrecognition (Kageura and Umino, 1996; Kageuraand Koyama, 2000), and the methods require a largecorpus that are manually prepared for a target do-main.
In contrast, our system, which is proposed inthis paper, requires only a seed word; from this seedword, the system compiles a corpus from the Web byusing search engines and produces a dozen technicalterms that are closely related to the seed word.2 SystemFigure 1 shows the configuration of the system.
Thesystem consists of three steps: compiling corpus, au-tomatic term recognition (ATR), and filtering.
Thissystem is implemented for Japanese language.2.1 Compiling corpusThe first step, compiling corpus, produces a corpusCsfor a seed term s. In general, compiling corpus isto select the appropriate passages from a documentset.
We use the Web for the document set and se-lect the passages that describe s for the corpus.
Theactual procedure of compiling corpus is:1.
Web page collectionFor a given seed term s, the system first makesfour queries: ?s toha?, ?s toiu?, ?s ha?, and?s?, where toha, ha, and toiu are Japanesefunctional words that are often used for defin-ing or explaining a term.
Then, the system col-lects the top K (= 100) pages at maximum foreach query by using a search engine.
If a col-lected page has a link whose anchor string is s,the system collects the linked page too.2.
Sentence extractionThe system decomposes each page into sen-tences, and extracts the sentences that containthe seed term s.The reason why we use the additional three queriesis that they work efficiently for collecting web pagesthat contain a definition or an explanation of s. Weuse two search engines, Goo1 and Infoseek2.
Wesend all four queries to Goo but only the query ?s?
toInfoseek, because Infoseek usually returns the sameresult for the four queries.
A typical corpus size isabout 500 sentences.2.2 Automatic term recognitionThe second step, automatic term recognition (ATR),extracts important terms from the compiled cor-pus.
We use Nakagawa?s ATR method (Nakagawa,2000), which works well for Japanese text, withsome modifications.
The procedure is as follows.1.
Generation of term listTo make the term list L by extracting everyterm that is a noun or a compound noun fromthe compiled corpus.2.
Selection by scoringTo select the top N (= 30) terms from the list Lby using a scoring function.For the scoring function of a term x, we usethe following function, which is multiplying Nak-agawa?s Imp1by a frequency factor F (x, L)?.score(x, L) = Imp1(x, L)?
F (x, L)?F (x, L) ={1 if x is a single noun?frequency of x in L?
otherwise1www.goo.ne.jp2www.infoseek.co.jpWhile Nakagawa?s Imp1does not consider term fre-quency, this function does: ?
is a parameter that con-trols how strongly the frequency is considered.
Weuse ?
= 0.5 in experiments.The result of automatic term recognition for ???????
(natural language processing)?
is shown inthe column candidate in Table 1.2.3 FilteringThe filtering step is necessary because the obtainedcandidates are noisy due to the small corpus size.This step consists of two tests: technical-term testand relation test.2.3.1 Technical-term testThe technical-term test removes the terms that donot satisfy conditions of technical terms.
We employthe following four conditions that a technical termshould satisfy.1.
The term is sometimes or frequently used in acertain domain.2.
The term is not a general term.3.
There is a definition or explanation of the term.4.
There are several technical terms that are re-lated to the term.We have implemented the checking program of thefirst two conditions in the system: the third conditioncan be checked by integrating the system with termexplainer (Sato, 2001), which produces a definitionor explanation of a given term; the fourth conditioncan be checked by using the system recursively.There are several choices for implementing thechecking program.
Our choice is to use the Web viaa search engine.
A search engine returns a number,hit, which is an estimated number of pages that sat-isfy a given query.
In case the query is a term, its hitis the number of pages that contain the term on theWeb.
We use the following notation.H(x) = ?the number of pages that containthe term x?The number H(x) can be used as an estimatedfrequency of the term x on the Web, i.e., on thehugest set of documents.
Based on this number, wecan infer whether a term is a technical term or not:in case the number is very small, the term is not aTable 1: Result for ?natural language processing?candidate Tech.
Rel.??????
(natural langauge pro-cessing; NLP)- -????????
(NLP technology) ?
???????????
(NLP system) ?
?????????
(NLP research)???????
(NLP study) ?
???
(processing)??????
(text processing) ?????
(research and development)??????
(Information ProcessingSociety of Japan; IPSJ)?
?????
(semantic processing) ?
?????
(speech processing) ???????
(speech information pro-cessing)?
?????
(information processing)????????
(NLP domain)????
(research field) ?
?*????
(parsing) ?
?????
(information retrieval) ?
??????????
(SIGNLP) ?
?????
(speech recognition) ?
?????
(machine translation) ?
??????
(morphological analysis) ?
?????????
(information pro-cessing system)???
(research)????
(semantic analysis) ?
??????????
(chair of NLP) ?
?*????????????
(NLP sym-posium)??????
(application system) ???????
(knowledge informationprocessing)?
???
(language)??
(information)technical term because it does not satisfy the firstcondition; in case the number is large enough, theterm is probably a general term so that it is not atechnical term.
Two parameters, Min and Max, arenecessary here.
We have decided that we use searchengine Goo for H(x), and determined Min = 100and Max = 100, 000, based on preliminary experi-ments.In summary, our technical-term test is:If 100 ?
H(x) ?
100, 000then x is a technical term.2.3.2 Relation testThe relation test removes the terms that are notclosely related to the seed term from the candidates.Our conditions of ?x is closely related to s?
is: (1)x is a broader or narrower term of s; or (2) relationdegree between x and s is high enough, i.e., above agiven threshold.The candidate terms can be classified from theviewpoint of term composition.
Under a given seedterm, we introduce the following five types for clas-sification.Type 0 the given seed term s: e.g., ??
??
??
(natural language processing)Type 1 a term that contains s: e.g., ??????????
(natural language processing system)Type 2 a term that is a subsequence of s: e.g., ????
(natural language)Type 3 a term that contains at least a component ofs: e.g., ????
(language analysis)Type 4 others: e.g., ????
(parsing)The reason why we introduce these types is thatthe following rules are true with a few exception: (1)A type-1 term is a narrower term of the seed terms; (2) A type-2 term is a broader term of the seedterm s. We assume that these rules are always true:they are used to determine whether x is a broader ornarrower term of s.To measure the relation degree, we use con-ditional probabilities, which are calculated fromsearch engine hits.P (s|x) =H(s?
x)H(x)P (x|s) =H(s?
x)H(s)whereH(s?
x) = ?the number of pages that containboth s and x?One of two probabilities is equal to or greater thana given threshold Z, the system decides that x isclosely related to s. We use Z = 0.05 as the thresh-old.In summary, our relation test is:If x is type-1 or type-2; orP (s|x) ?
0.05 or P (x|s) ?
0.05then x is closely related to s.The result of the filtering step for ???????
(natural language processing)?
is in Table 1; aTable 2: Experimental ResultEvaluation I Evaluation IIdomain correct incorrect total S F A C R totalnatural language processing 101 (93%) 8 ( 7%) 109 6 3 14 11 8 43Japanese language 71 (81%) 17(19%) 88 7 0 19 5 1 32information technology 113 (88%) 15 (12%) 128 10 5 27 13 0 55current topics 106 (91%) 10 ( 9%) 116 2 0 13 19 5 39persons in Japanese history 128 (76%) 41 (24%) 169 18 0 23 1 0 42Total 519 (85%) 91(15%) 610 43 8 96 49 14 210check mark ???
indidates that the term passed thetest.
Twenty terms out of the thrity candidate termspassed the first techinical-term test (Tech.)
and six-teen terms out of the twenty terms passed the secondrelation test (Rel.).
The final result includes two in-appropriate terms, which are indicated by ?
*?.3 Experiments and DisucssionFirst, we examined the precision of the system.
Weprepared fifty seed terms in total: ten terms foreach of five genres; natural language processing,Japanese language, information technology, currenttopics, and persons in Japanese history.
From thesefifty terms, the system collected 610 terms in total;the average number of output terms per input is 12.2terms.
We checked whether each of the 610 termsis a correct related term of the original seed term byhand.
The result is shown in the left half (EvaluationI) of Table 2.
In this evaluation, 519 terms out of 610terms were correct: the precision is 85%.
From thishigh value, we conclude that the system can be usedas a tool that helps us compile a glossary.Second, we tried to examine the recall of thesystem.
It is impossible to calculate the actual re-call value, because the ideal output is not clear andcannot be defined.
To estimate the recall, we firstprepared three to five target terms that should becollected from each seed word, and then checkedwhether each of the target terms was included inthe system output.
We counted the number of tar-get terms in the following five cases.
The right half(Evaluation II) in Table 2 shows the result.S: the target term was collected by the system.F: the target term was removed in the filtering step.A: the target term existed in the compiled corpus,but was not extracted by automatic term extrac-tion.C: the target term existed in the collected webpages, but did not exist in the compiled corpus.R: the target term did not exist on the collected webpages.Only 43 terms (20%) out of 210 terms were col-lected by the system.
This low recall primarilycomes from the failure of automatic term recogni-tion (case A in the above classification).
Improve-ment of this step is necessary.We also examined whether each of the 210 targetterms passes the filtering step.
The result was that133 (63%) terms passed; 44 terms did not satisfythe condition H(x) ?
100; 15 terms did not satisfythe condition H(x) ?
100, 000; and 18 terms didnot pass the relation test.
These experimental resultssuggest that the ATR step may be replaced with asimple and exhaustive term collector from a corpus.We have a plan to examine this possibility next.ReferencesKyo Kageura and Teruo Koyama.
2000.
Special issue:Japanese term extraction.
Terminolgy, 6(2).Kyo Kageura and Bin Umino.
1996.
Methods of au-tomatic term recognition: A review.
Terminology,3(2):259?289.Hiroshi Nakagawa.
2000.
Automatic term recognitionbased on statistics of compound nouns.
Terminology,6(2):195?210.Satoshi Sato.
2001.
Automated editing of hypertextre?sume?
from the world wide web.
In Proceedingsof 2001 Symposium on Applications and the Internet(SAINT 2001), pages 15?22.
