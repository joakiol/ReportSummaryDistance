Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 311?314,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsJHU System Combination Scheme for WMT 2010Sushant NarsaleJohns Hopkins UniversityBaltimore, USA.sushant@jhu.eduAbstractThis paper describes the JHU systemcombination scheme that was used inthe WMT 2010 submission.
The in-cremental alignment scheme of (Karakoset.al, 2008) was used for confusion net-work generation.
The system orderin the alignment of each sentence waslearned using SVMs, following the workof (Karakos et.al, 2010).
Additionally,web-scale n-grams from the Google cor-pus were used to build language modelsthat improved the quality of the combi-nation output.
Experiments in Spanish-English, French-English, German-Englishand Czech-English language pairs wereconducted, and the results show approxi-mately 1 BLEU point and 2 TER pointsimprovement over the best individual sys-tem.1 IntroductionSystem Combination refers to the method of com-bining output of multiple MT systems, to pro-duce a output better than each individual system.Currently, there are several approaches to ma-chine translation which can be classified as phrase-based, hierarchical, syntax-based (Hildebrand andVogel, 2008) which are equally good in their trans-lation quality even though the underlying frame-works are completely different.
The motivationbehind System Combination arises from this di-versity in the state-of-art MT systems, which sug-gests that systems with different paradigms makedifferent errors, and can be made better by com-bining their strengths.One approach of combining translations isbased on representing translations by confusionnetwork and then aligning these confusion net-works using string alignment algorithms (Rostiet.al, 2009), (Karakos and Khudanpur, 2008).Another approach generates features for everytranslation to train algorithms for ranking systemsbased on their quality and the top ranking outputis considered to be a candidate translation, (Hilde-brand and Vogel, 2008) is an example of rankingbased combination.
We use ideas from rankingbased approaches to learn order in which systemsshould be aligned in a confusion network basedapproach.Our approach is based on incremental align-ment of confusion networks (Karakos et.al, 2008),wherein each system output is represented by aconfusion network.
The confusion networks arethen aligned in a pre-defined order to generate acombination output.
This paper contributes twoenhancements to (Karakos et.al, 2008).
First,use of Support Vector Machines to learn order inwhich the system outputs should be aligned.
Sec-ond, we explore use of Google n-grams for build-ing dynamic language model and interpolate theresulting language model with a large static lan-guage model for rescoring of system combinationoutputs.The rest of the paper is organized as follows:Section 2 illustrates the idea and pipeline of thebaseline combination system; Section 3 gives de-tails of SVM ranking for learning system orderfor combination; Section 4 explains use of Googlen-gram based language models; Results are dis-cussed in Section 5; Concluding remarks are givenin Section 6;2 Baseline System CombinationThis section summarizes the algorithm for base-line combination.
The baseline combinationpipeline includes three stages:1.
Representing translations by confusion net-works.3112.
Generating between system confusion net-works.3.
Rescoring the final confusion network.Confusion networks are compressed form oflattices with a constraint that all paths should passthrough all nodes.
Each system output is repre-sented by an equivalent confusion network.
Theper-system confusion networks are aligned one ata time.
The order in which systems are alignedis usually decided by evaluation of system?s per-formance.
Two alternatives for deciding the sys-tem order are discussed in Section 3.
Inversion-Transduction Grammar (Wu, 1997) is used foralignments and the cost function for aligning twoconfusion networks iscost(b1, b2) =1|b1||b2|?w?b1?v?b2c(v)c(w)1(w 6= v)where b1 and b2 are two different bins, |b1| and |b2|is the number of tokens in b1 and b2 respectively,c(v) and c(w) are the number of words of tokenv and token w. which are in b1 and b2 separately.The idea of this cost is to compute the probabilitythat a word from bin b1 is not equal to a word frombin b2.cost(b1, b2) = Prob(v 6= w, v ?
b1, w ?
b2)The final confusion network is rescored with a5-gram language model with Kneser-Ney smooth-ing.
To generate the final output, we need to findthe best (minimum-cost) path through the rescoredconfusion network.
In the best path every bin inthe network contributes only one word to the out-put.Ordering the systems for incremental combina-tion and use of different language models were thetwo components of the pipeline that were experi-mented with for WMT?2010 shared task.
The fol-lowing sections describe these variations in detail.3 Learning to Order Systems forCombinationDetermining the order in which systems arealigned is critical step in our system combinationprocess.
The first few aligned translations/systemsdetermine the word ordering in the final output andhave a significant influence on the final transla-tion quality.
For the baseline combination the sys-tems are aligned in the increasing order of (TER-BLEU) scores.
TER and BLEU (Papineni et.al,2002) scores are calculated over all the sentencesin the training set.
This approach to ordering ofsystems is static and results in a global order forall the source segments.
An alternative approachis to learn local order of systems for every sourcesentence using a SVM ranker.3.1 SVM Rank MethodThis section describes an approach to order sys-tems for alignment using SVMs (Karakos et.al,2010).
For each system output a number of fea-tures are generated, the features fall broadly underthe following three categories:N-gram AgreementsThese features capture the percentage of hypoth-esis for a source sentence that contain same n-grams as the candidate translation under consid-eration.
The n-gram matching is position indepen-dent because phrases often appear in different or-ders in sentences with same meaning and correctgrammar.
The scores for each n-gram are summedand normalized by sentence length.
N-grams oflength 1 ?
?
?
5 are used as five features.Length FeatureThe ratio of length of the translation to the sourcesentence is a good indication of quality of thetranslation, for a lengthy source sentence a shorttranslation is most likely to be bad.
Here, the ra-tio of source sentence length to length of the targetsentence is calculated.Language Model FeaturesLanguage models for target language are used tocalculate perplexity of a given translation.
Thelower the perplexity the better is the translationquality.
We use two different language models:(i) a large static 5-gram language model and (ii)adynamic language model generated from all thetranslations of the same source segment.
Theperplexity values are normalized by sentencelength.Translations in training set are ranked basedon (TER-BLEU) scores.
An SVM ranker is thentrained on this set.
The SVM ranker (Joachims,2002) returns a score for each translation, basedon its signed distance from the separating hyper-plane.
This value is used in the combination pro-cess to weight the contribution of systems to thefinal confusion network scores.312Table 1: Results for all Language pairs on development setes-en fr-en cz-en de-enCombination BLEU TER BLEU TER BLEU TER BLEU TERBEST SYSTEM 29.27 52.38 26.74 56.88 21.56 58.24 26.53 56.87BASELINE 28.57 51.61 27.65 55.20 21.01 58.79 26.80 54.54SVM 28.68 51.99 27.53 55.35 21.56 58.24 26.85 54.9SVM+NGRAM 29.92 50.92 27.86 55.06 21.80 57.78 27.24 54.864 Language ModelsIn the system combination process, the final con-fusion networks are rescored with language mod-els.
Language models are widely used to en-sure a fluent output translation.
I explored use oftwo language models.
The first language modelwas trained on the English side of French-Englishcorpus, UN corpus and English Gigaword cor-pus made available by WMT.
The second lan-guage model used counts generated from Googlen-grams.
It was trained by generating all 1-gramto 5-grams in the system outputs for a sourcesegment and then using the N-gram search en-gine (Lin et.al, 2010) built over Google n-gramsto get the corresponding n-gram counts.
The n-gram counts were used to train a 5-gram languagemodel with Kneser-Ney smoothing.
SRILMtoolkit (Stockle, 2002) was used for training thelanguage models.The baseline combinations were rescored onlywith the static language model.
I always did aweighted interpolation of the two language mod-els when using n-gram based language model.5 ResultsResults for four language pairs: Spanish-English,French-English, Czech-English and German-English are presented.
The training data forWMT?10 was divided into development and testset, consisting of 208 and 247 segments respec-tively.
Table 1 shows TER and BLEU scoreson the TEST set for all the four language pairsin the following settings: (i) Baseline corre-sponds to procedure described in section 2, (ii)SVM corresponds to using SVM ranker for learn-ing order of systems as described in section 3.1(iii)SVM+N-Grams corresponds to the use of aSVM ranker along with weighted interpolation ofn-gram language model and the large static lan-guage model.
The ranking SVM was trained us-ing SVM-light (Joachims, 2002) with a RBF ker-nel.
Two-fold cross-validation was done to pre-vent over-fitting on development data.
All thescores are with lower-cased outputs, a tri-gramlanguage model was used to true-case the outputbefore the final submission.
1-best output fromonly the primary systems were used for combina-tion.
The number of systems used for combinationin each language pair are: 6 for Czech-English,8 in Spanish-English, 14 in French-English and16 in German-English.
The best results for base-line combination were obtained with 3 systemsfor Czech-English, 6 systems for German-English,3 systems for Spanish-English and 9 systems forFrench-English.From the results, we conclude that for all lan-guage pairs the combinations with SVM and n-gram language models show gain over all the othersettings in both TER and BLEU evaluations.
How-ever, use of SVM with only one large languagemodel shows performance degradation on threeout of four language pairs.
Size of training data(208 segments) could be one reason for the degra-dation and this issue needs further investigation.For the final submission, the settings that per-formed the best on (TER?BLEU)2 scale were cho-sen.6 ConclusionThe system combination task gave us an opportu-nity to evaluate enhancements added to the JHUsystem combination pipeline.
Experimental re-sults show that web-scale language models can beused to improve translation quality, this further un-derlines the usefulness of web-scale resources likeGoogle n-grams.
Further investigation is neededto completely understand the reasons for incon-sistency in the magnitude of gain across differentlanguage pairs.
Specifically the impact of trainingdata on SVMs for ranking in system combinationscenario needs to be analysed.313AcknowledgmentsThis work was partially supported by the DARPAGALE program Grant No HR0022-06-2-0001.
Iwould like to thank all the participants of WMT2010 for their system outputs.
I would also liketo thank Prof. Damianos Karakos for his guidanceand support.
Many thanks go to the Center forLanguage and Speech Processing at Johns Hop-kins University for availability of their computerclusters.ReferencesAlmut Silja Hildebrand and Stephan Vogel.
2008.Combination of Machine Translation Systems viaHypothesis Selection from Combined N-Best Lists.In MT at work: Proceedings of the Eight Conferenceof Association of Machine Translation in the Amer-icas, pages 254-261, Waikiki, Hawaii, October.
As-sociation for Machine Translations in the Americas.Almut Silja Hildebrand and Stephan Vogel.
2009.CMU System Combination for WMT?09.
Proceed-ings of Fourth Workshop on Statistical MachineTranslation,Athen,Greece, March 2009.Andreas Stockle.
2002.
Srilm - an extensible languagemodeling toolkit.
In Proceedings International Con-ference for Spoken Language Processing, Denver,Colarado, September.Antti-Veikko I. Rosti and Necip Fazil Ayan and BingXiang and Spyros Matsoukas and Richard Schwartzand Bonnie J. Dorr 2007.
Combining Outputs fromMultiple Machine Translation Systems.
In Proceed-ings of the Third Workshop on Statistical MachineTransaltion, pages 183-186, Colombus, Ohio, June.Association for Computational Linguistics.Damianos Karakos and Sanjeev Khudanpur 2008.
Se-quential System Combination for Machine Transla-tion of Speech.
In Proceedings of IEEE SLT-08, De-cember 2008.Damianos Karakos and Jason Smith and Sanjeev Khu-danpur 2010.
Hypothesis Ranking and Two-passApproaches for Machine Translation System Com-bination.
In Proceedings of ICASSP-2010, Dallas,Texas, March 14-19 2010.Damianos Karakos and Jason Eisner and Sanjeev Khu-danpur and Markus Dreyer.
2008.
Machine Trans-lation system combination using ITG-based align-ments.
In Proceedings of ACL-08: HLT, Short Pa-pers, pages 81-84, Colombus, Ohio, June.
Associa-tion for Computational Linguistics.Dekang Lin and Kenneth Church and Heng Ji andSatoshi Sekine and David Yarowsky and ShaneBergsma and Kailash Patil and Emily Pitler RachelLathbury and Vikram Rao and Kapil Dalwani andSushant Narsale 2010.
New Tools for Web-ScaleN-grams.
In the Proceedings of LREC, 2010.D.
Wu 1997.
Stochastic inversion transduction gram-mars and bilingual parsing of parallel corpora.Computational Linguistics, vol.23,no.3,pp.377-403,September 1997.Kishore Papineni and Salim Roukos and Todd Wardand Wei-Jing Zhu.
2002.
BLEU: A method forautomatic evaluation of machine translation.
InProceedings of 40th Annual Meeting of Associa-tion for Computational Linguistics, pages 311-318.Philadelphia, PA, July.Thorsten Joachims 2002.
Optimizing Search Enginesusing Clickthrough Data.
In Proceedings of ACMConference on Knowledge Discovery and Data Min-ing(KDD), 2002.314
