Squibs and DiscussionsPipelines and Size ConstraintsEhud Reiter*University of AberdeenSome types of documents need to meet size constraints, uch as fitting into a limited number ofpages.
This can be a difficult constraint to enforce in a pipelined natural anguage generation(NLG) system, because size is mostly determined by content decisions, which usually are madeat the beginning of the pipeline, but size cannot be accurately measured until the document hasbeen completely processed by the NLG system.
I present experimental data on the performanceof single-solution pipeline, multiple-solution pipeline, and revision-based variants of the STOPsystem (which produces personalized smoking-cessation leaflets) in meeting a size constraint.This shows that a multiple-solution pipeline does much better than a single-solution pipeline,and that a revision-based system does best of all.1.
IntroductionSome types of documents need to fit on a limited number of pages.
For example, thisarticle, because it is a squib, must fit on eight pages in the style (font, layout, etc.
)specified by Computational Linguistics.
However, in certain cases it is useful to includeas much information as possible given the size limit; for example, I want to convey asmuch information as possible about my research in the allowed eight pages.Maximizing the amount of content subject o a size limit is also a problem for somenatural language generation (NLG) systems.
For example, the STOP system (Reiter,Robertson, and Osman 1999) produces personalized smoking-cessation leaflets thatmust fit on four A5 pages, in a certain style; but it is useful if the leaflets can conveyas much information as possible given this size constraint.One problem with performing this optimization in an NLG system is that thesize of a document is primarily determined by how much content it contains, thatis by decisions made during the content determination process.
However, an NLGsystem cannot accurately determine the size of a document until the document hasbeen completely processed by the NLG system and (in some cases) by an externaldocument presentation system, such as LaTeX or Microsoft Word.
This is becausethe size of the document is highly dependent on its exact surface form.
This is aphenomenon that may be familiar to readers who have tried to revise a paper to fit apage-limit constraint by making small changes to wording or even orthography.In consequence, it may be difficult to satisfy the size constraint while "filling up"the allowed pages in a pipelined NLG system that performs content determination ian early pipeline module, before the surface form of the document is known.
This isespecially true if each pipeline module is restricted to sending a single solution to thenext pipeline module, instead of multiple possible solutions.In this paper I give a brief summary of the pipeline debate and of STOP, presentmy experimental results, and then discuss the implications of this work.
* Department of Computing Science, Aberdeen AB24 3UE, UK.
E-maih ereiter@csd.abdn.ac.uk(~) 2000 Association for Computational LinguisticsComputational Linguistics Volume 26, Number 22.
Pipelines in NLGFor the past 20 years, the NLG community has generally agreed that modularizingNLG systems is sensible.
This has become ven more true in recent years, because ofa growing trend to incorporate xisting modules (especially realization systems uchas FUF/SURGE \[Elhadad and Robin 1997\]) into new systems.
While different systemsuse different numbers of modules, all recent systems that I am aware of are dividedinto modules.This leads to the question of how modules should interact.
In particular, is itacceptable to arrange modules in a simple pipeline, where a later module cannotaffect an earlier module?
Or is it necessary to allow revision or feedback, where a latermodule can request hat an earlier module modify its results?
If a pipeline is used,should modules pass a single solution down the line, or should they pass multiplesolutions and let subsequent modules choose between these?Many authors have argued that pipelines cannot optimally handle certain lin-guistic phenomena.
For example, Danlos and Namer (1988) point out that in French,whether a pronoun unambiguously refers to an entity depends on word ordering.This is because the pronouns le or la (which convey gender information) are abbre-viated to 1' (which does not contain gender information) when the word followingthe pronoun starts with a vowel.
But in a pipelined NLG system, pronominalizationdecisions are typically made earlier than word-ordering decisions; for example in thethree-stage pipelined architecture presented by Reiter and Dale (2000), pronominal-ization decisions are made in the second stage (microplanning), but word orderingis chosen during the third stage (realization).
This means that the microplanner willnot be able to make optimal pronominalization decisions in cases where le or la areunambiguous, but I' is not, since it does not know word order and hence whether thepronoun will be abbreviated.Many other such cases are described in Danlos's book (Danlos 1987).
The com-mon theme behind many of these examples i  that pipelines have difficulties atisfyinglinguistic constraints (such as unambiguous reference) or performing linguistic opti-mizations (such as using pronouns instead of longer referring expressions wheneverpossible) in cases where the constraints or optimizations depend on decisions madein multiple modules.
This is largely due to the fact that pipelined systems cannot per-form general search over a decision space that includes decisions made in more thanone module.Despite these arguments, most applied NLG systems use a pipelined architecture;indeed, a pipeline was used in every one of the systems urveyed by Reiter (1994) andPaiva (1998).
This may be because pipelines have many engineering advantages, andin practice the sort of problems pointed out by Danlos and other pipeline critics donot seem to be a major problem in current applied NLG systems (Mittal et al 1998).3.
STOPThe STOP system (Reiter, Robertson, and Osman 1999) generates personalized smoking-cessation leaflets, based on responses to a questionnaire about smoking likes and dis-likes, previous attempts to quit, and so forth.
The output of the system is a four-pageleaflet; each page is size A5.
An example of the two "inside" pages of a leaflet pro-duced by STOP is shown in Figure 1.
A STOP leaflet alo contains a front page thatis only partially generated (the rest is logos and fixed text) and a back page that isselected from a collection of 16 possible back pages, but is not otherwise personalized;these are not shown here due to space restrictions.252Reiter P ipel ines and Size Constraintsiiii ill ~i~ii;!;?
!iii !ii iiii!
!ii~~Tx:" ir:N,.NNWr s i l l '7 ~iiimsm'iiii!i!iiiiiiii~;i!~~iiiiiiiiiiiiiiiiiiiiiiii!iXDgo.%E d~m0 0E >,00.~a oC~.
c oo,O o .?
-ao= ~ 0 0 ~ ~1> > O.
0>->-6_ ~ ~ .~0o~- ,-~o o~om ?
.9o 0 -~ ~.~m o-o_  ~ ~ o~=~ : .
'=- _~ oo  O-  - "0 ~0 ~ 0 ~ ~- ~ 0 o o ~ =9,~-~ ~:=- .
- -c~xE o ' ~ U ~  (~~=~ o ~ ~,~, -~o~-~== ?~_.~_~ m E ~  =o.
.~o_~ (0 >, ~oo .
-E (~m~,~ .~ ?
o o .
_  ~:._= ~: -~c ~.
~o= ~: ~0>~=o~ ?
~ ~ :o~ ~,=o.~,0~ ,... o~o : :  o~'o  E0 0o  ~ o o a  ~_~_  i "~ = "~ ._~ -~~:~ 0 ,', E ~ (~ '~ '~>,O o-"O C~o~OJ~0 0 0 r~ ~er -"~o~C ~?d  < 'o~ ~ C 0 ?
- -~-~ ~)oo_~~gE~:I~ C tO?
~ E m.=_ ~ ~0 >,~r~ c nN~eg6_OOr ,<?
6.=_ o o ,,, .~= ~ ~ o= = ~~o~ 7 oo  .
..c:: =o -  = - ,~-~ - "~ E.~_ -o o o~ ~: ~ ~ ~ "-- m'O >-I~ m ~ m ~  '- m-  >"~ 0 ?li o .C~ ~ x~ m ?
c Z. .
,a  o m ~.
.~ ~"= ~: o f .~  .
.
.
.
.
.
.
.
.
.
- ~ ,  ~ "~o._: ~- o~ ~_~o_.
?- ~~ 0 0 "--~.~oC O.~mm =4"~ C 0 0 tU .~-- ~ c ~ oo .~o.~ >~ o?~>~-.=-~ -0 ~ - ~ m ~X: _~ ~ ~ oC~?
'o0 CgoO?
?
"O  O$= Ea a .
=o?
o N '~Q0.
.~ ~ 0 .0 >~ O~ >0 E ~E ~ o~ m0-~ ~ CO 0 l_l "~0--.
~ o  !
.~oo .~ .~ ~0= .-~ ~0 >" '~  o .0 C 0 0 .~=~-~ ~ o~.~- -~Q;0~0~?Q;C~Dr~~a ~a253Computational Linguistics Volume 26, Number 2A STOP leaflet must fit on four A5 pages; this is a hard constraint.
Furthermore,it is important to communicate as much information as possible subject o the sizeconstraint; his is a characteristic that the system tries to optimize.
However, it is evenmore important that leaflets be easy to read, and size optimization should not be atthe expense of readability.
For example, replacing an itemized list (such as the one atthe top of the second page in Figure 1) by a complex multiclause sentence can reducesize but often makes leaflets harder to read, especially for poor readers; hence we donot do this.The original version of STOP used a three-stage pipelined architecture (with eachpipeline module producing only one solution) similar to the one presented by Reiterand Dale (2000).
An initial document-planning stage produced a document plan datastructure, which specified the content of the document in terms of messages.
In STOP,messages were represented as strings (or lists of strings) that specified word formsand word order, but not punctuation, capitalization, and intertoken white space.
Thedocument plan also specified how messages were grouped into higher-level structures(such as paragraphs); discourse relations between messages orgroups of messages; andthe importance of each message and message group.Once an initial document plan had been produced, the document trimmer compo-nent of the document planner attempted toensure that the document produced by thedocument plan did not exceed four A5 pages.
It did this using a heuristic function thatestimated the size of the final document from the document plan.
If the heuristic sizeestimator indicated that the document was too large, the trimmer identified the leastimportant message in the document plan, deleted this message, and recalculated thedocument's estimated size.
1 This process continued until the document fitted on fourA5 pages according to the size estimator.
At this point the document plan was passedon to the other stages of the system, microplanning and realization.
These performedtasks such as deciding when discourse relations hould be expressed via cue phrases,and adding appropriate punctuation, capitalization, and white space to the text (bothof which tasks, incidentally, are affected by trimming and hence must take place afterit).
The realizer produced an RTF file, which was printed using Microsoft Word; in asense Word could be considered to be a fourth pipeline stage.The main difficulty in this approach was estimating the size of the final document.Since messages were represented as strings, we initially thought it would be easy tobuild an accurate size estimator.
But in fact this proved to be a difficult ask, becausethe size of a document is highly dependent on its exact surface form, including cuephrases, punctuation and capitalisation, and even typographic features uch as boldface.For example, consider the leaflet extract shown in Figure 1.
This fits on two A5pages, as desired.
However, if "bad for your health" in the paragraph just below thegraphic were changed from italic face to bold face, then this paragraph would requirefour lines instead of three lines.
Our layout style does not allow a section to start on apage unless both the section header and two lines of section text can fit on the page.Therefore, increasing the size of this paragraph to four lines causes Word to start thesection headed "You could do it .
.
."
on the next page; this makes the leaflet overflowonto an additional page, and thus violate the overall size constraint.Thus, a very small change in a document (such as changing a few words fromitalics to bold) can cause significant changes in a document's size.
The fact that a1 This is a simplification, as the trimmer also considers dependencies between messages and theimportance of message groups.
Trimming is in essence a type of bin-packing, and no doubt there isscope for improving the trimmer by incorporating into it sophisticated bin-packing algorithms.254Reiter Pipelines and Size Constraintsdocument's size is so sensitive to its exact surface form is what makes ize estimationdifficult.As a result of such problems, although the size estimator soon grew in complexityconsiderably beyond what we had originally intended, it still made mistakes.
In mostcases it was fairly accurate, but it was not 100% accurate on 100% of the documents.As the estimator grew in complexity, another problem appeared, which was thedifficulty of keeping it up-to-date.
A clinical trial of the STOP system started in Octo-ber 1998, and in the months immediately preceding the trial, numerous bug fixes andimprovements were made to STOP by the development team.
Some of these changesimpacted the size estimator, but developers did not always update the size estimatoraccordingly.
In part this was because updating the size estimator in some cases re-quired considerably more work than making the actual bug fix or improvement, andthe developers had many urgent changes that needed to be made to the core softwarein this period.In other words, another difficulty with building an estimator that predicted thebehavior of the microplanner, realizer, and Word was that it was difficult and time-consuming to maintain the accuracy of the estimator as changes were made to themicroplanner and realizer, and also to the exact RTF structures produced by our systemfor Word to process.4.
Experimental ResultsSTOP is currently being tested in a clinical trial, in order to determine its effectivenessin helping people stop smoking.
The version of STOP used in the clinical trial had asingle-solution pipeline architecture as described above.
Its trimmer used a size esti-mator that was tuned to be conservative (and hence often produced leaflets that weresmaller than they could have been), but still in a few cases underestimated true lengthand hence resulted in leaflets that were five A5 pages instead of four.
Such leafletswere manually fixed by the researchers unning the trial, usually by adjusting the for-matting of the leaflet (for example, margins or interparagraph separation).
We felt thiswas not acceptable for a production version of STOP, however; such a system shouldguarantee conformance tothe length constraint without needing manual intervention.Also, conformance should be achieved by adjusting content, not formatting.
The for-matting of STOP leaflets was designed by an expert graphic designer with the goal ofenhancing readability, and we believed it should be treated as fixed, not variable.
2In order to explore what should be done in a production version of STOP, weconducted some experiments (after the STOP clinical trial had started) on the impactof different architectures on satisfying the size constraint while utilizing as much aspossible of the available space.
For these experiments, we took the version of thesystem used in the clinical trial (including accumulated bug fixes and enhancements),and retuned the size estimator to take into account these accumulated changes.
Afterretuning, STOP produced leaflets that fit the size constraint for all members of a"tuning set" of 150 questionnaires.
Then we made the following changes:A delta parameter was added to the size estimator; essentially, a delta ofN makes the estimator think that a page can hold N more lines of textthan it can in reality contain.2 Similarly, I believe the editors of Computational Linguistics would not be pleased if I submitted a squibthat conformed tothe eight-page size limit by using nonstandard margins or line spacing.255Computational Linguistics Volume 26, Number 2A multiple-solution mode was added to the system.
In this mode, thetrimmer is run several times, at different delta values.
The resultantdocument plans are processed by the rest of the system and by Word,and a choice module picks the resulting document that has the highestword count while still satisfying the size constraint.A revision mode was added to the system.
In this mode, the systemgenerates an initial document using a fixed delta.
Then, a revisionmodule obtains the actual size of the document from Word, and eitherdeletes an additional message (if the document is too large) or restoresthe last deleted message (if the document meets the size constraint).
Thisprocess continues until the system finds the largest document that meetsthe size constraint.
3The modified system was run on a set of 1,000 questionnaires from the clinicaltrial, in the original single-solution pipeline mode, in the multiple-solution pipelinemode, and in revision mode.
For the pipeline modes, the system was run with thedeltas -2, -1, 0, 1, 2, 3, 4, 5, and 6.
Measurements were made of:?
The percentage of leaflets that exceeded the size constraint.?
For leaflets atisfying the size constraint, he average number of words inthe two inside pages, both as an absolute number and as a percentage ofthe number of words in the inside pages when processed under revisionmode.?
The average processing time (total elapsed time, not just computationtime) required per document, on a Pentium 266MHz with 128MB ofmemory.
4These results are shown in Tables 1 and 2.
For multiple-solution pipelines, we tried allpairs, triples, and quadruples of deltas between -2 and 6, and in Table 2 only showthe results for the pair, triple, and quadruple that led to the highest average wordcount while always satisfying the size constraint.
We also ran STOP on the full setof 2,582 clinical-trial questionnaires in single-delta mode with deltas of -1, 0, and 1,in order to get a more accurate stimate of the number of constraint violations underthese deltas.5.
D iscuss ion  of ResultsAs expected, the single-delta figures how that as the delta increases, both the averageword count and the number of leaflets that exceed the size constraint also increase.Note that although none of the leaflets produced from the 150-questionnaire "tuning3 Our revision module  did not give any guidance as to where messages should be added.
Thissometimes led to wasted space in situations where a message could be added to one part of the leafletbut  not others (for example, to the first inside page but  not the second), if the next message in theundelete list was in a portion of the leaflet that had no unused space.4 This measurement  was made on a subset of 100 documents,  because this is the size of collection thatSTOP was designed to be able to process in one run.
While the core NLG system could process anynumber  of documents,  the support  code (user-interface, logging, file management)  worked poorlywhen processing more than 100-200 documents  in one run.
For word count and constraint violationdata, we s imply restarted the system if it hung  when processing 1,000 questionnaires; but  this seemedless appropriate for execution time data.256Reiter Pipelines and Size ConstraintsTable 1Results of single-solution pipeline modedelta -2  - 1 0 1 2 3 4 5 6size constraint violations (%) 0 0 0.04 0.97 7.3 16 25 35 42Average word count (legal eaflets) 303 320 336 350 359 364 373 375 378Word count as % of revision mode 79 84 88 92 93 96 98 98 99Table 2Performance of different modes when meeting the size constraint in 100% of casesAverage size Averagearchitecture Average word count (% of revision) processing time1 solution (delta = -1) 320 84 2.2s2 solutions (deltas = -1, 4) 369 96 5.2s3 solutions (deltas = -1, 2, 6) 378 98 5.9s4 solutions (deltas = -1, 2, 4, 6) 380 99 6.2srevision 385 100 9.8sset" violated the size constraint with a delta of 0, one leaflet produced from the full2,582-questionnaire data set did break the size constraint at this delta.
This is perhapsnot surprising, it merely shows that as the size of the document set increases, so doesthe worst-case performance of the heuristic size estimator.
It is possible that in a verylarge data set (hundreds of thousands of questionnaires), some leaflets might breakthe size constraint even at a delta of -1.Shifting to a multiple-solution pipeline dramatically improves performance.
Av-erage leaflet size while guaranteeing conformance to the size constraint jumps from320 words in single-delta mode to 369 with two solutions; an increase of 15% in thenumber of words in the leaflet.
We get still better results with three and four solu-tions, although the increase is not as dramatic.
The best results of all are in revisionmode, although the increase in size over a four-solution pipeline (385 words versus380 words) is small.
However, revision mode also is robust in the face of increased ataset size (we can be confident hat the size constraint will be satisfied even on a set ofa million questionnaires) and "last-minute" changes to the code.
If developers tweakthe main STOP code and forget to update the size estimator, revision mode will stillalways produce documents that conform to the size constraint; it just may take longerto do the revision.
In contrast, changes to the code may result in the multiple-solutionpipeline producing documents that do not conform to the size constraint.As expected, processing time is lowest for the single-solution pipeline and highestfor revision mode.
However, in the context of STOP, even the 9.8 seconds requiredin revision mode is acceptable; under this mode a batch of 100 leaflets can still begenerated in under 20 minutes.6.
ImplicationsIn STOP, the single-solution pipeline does a poor job at meeting the size constraintwhile utilizing as much of the available space as possible.
No doubt the performanceof the single-solution pipeline could be enhanced by adding more complexity to the257Computational Linguistics Volume 26, Number 2size estimator; but such a system still would not give 100% accurate stimates on100% of the generated ocuments.
Furthermore additional complexity would makethe estimator harder to maintain as changes were made to the code being estimated.Both the multiple-solution pipeline and revision mode do a much better job ofutilizing the available space while observing the size constraint.
Revision mode doesbetter than the multiple-solution pipeline, but only slightly.
However, revision modeis robust in the face of increased ata set size and changes to the code.The effectiveness of multiple-solution pipelines hould perhaps not be surprising,given the popularity of such pipelines in other areas of speech and language pro-cessing.
For example, in a speech system a word-level analysis component may passseveral word hypotheses to a language model; and in a natural language analysissystem, a morphology system may pass several possible analyses of a surface formword to a parser.
However, multiple-solution pipelines have not received a great dealof attention in the NLG community.
I am not aware of any previous NLG papers thatpresented experimental data comparing single-solution to multiple-solution pipelines,and many NLG pipeline critics (including Danlos) assume that pipeline modules onlyproduce one solution.Do these results generalize to other constraints and optimizations?
In principle, itseems that similar findings should apply to other constraints and optimizations thatdepend on decisions or measurements made in more than one module.
However, abigcaveat is that many of the constraints and optimizations important o NLG systemsare difficult to measure, which may lessen the benefits of complex architectures.
Forexample, an important constraint in STOP is that texts should be easy to read for poorreaders.
However, the only computational mechanism we are aware of for measur-ing reading difficulty is reading-level formulas (such as Flesch Reading Ease), whoseaccuracy is doubtful (Kintsch and Vipond 1979).
Without reliable global measures ofreadability, perhaps the best we can do (and the approach adopted in STOP) is todesign messages that readability experts think are appropriate for poor readers; thisis something that can be done in a single-solution pipeline architecture.In other words, if we cannot properly measure the thing we are trying to optimizeor satisfy (which may be the case with the majority of constraints and optimizationsthat today's NLG systems builders are concerned with), then there may be little valuein shifting to a complex architecture that supports more sophisticated search (whichis perhaps the main benefit of revision and multiple-solution pipelines).
This mayexplain the continuing popularity of single-solution pipeline architectures in appliedNLG systems.AcknowledgmentsMany thanks to the STOP team andespecially Roma Robertson, who kept onproducing examples of STOP leaflets whichthe size estimator had difficulties with.
Mythanks also to Michael Elhadad, ChrisMellish, Vibhu Mittal, Daniel Paiva, and theanonymous reviewers for their very helpfulcomments; and a special thanks to StephanBusemann for suggesting we investigatemultiple-solution pipelines.
This researchwas supported by the Scottish OfficeDepartment ofHealth under grantK/OPR/2/2/D318, and the Engineeringand Physical Sciences Research Councilunder grant GR/L48812.ReferencesDanlos, Laurence.
1987.
The Linguistic Basisof Text Generation.
Cambridge UniversityPress, Cambridge, UK.Danlos, Laurence and Fiammetta Namer.1988.
Morphology and crossdependencies in the synthesis of personalpronouns in Romance languages.
InProceedings ofthe 12th InternationalConference on Computational Linguistics(COLING-88), volume 1, pages 139-141.Elhadad, Michael and Jacques Robin.
1997.SURGE: A comprehensive plug-insyntactic realisation component for textgeneration.
Technical Report, ComputerScience Dept, Ben-Gurion University, Beer258Reiter Pipelines and Size ConstraintsSheva, Israel.Kintsch, Walter and Douglas Vipond.
1979.Reading comprehension a d readabilityin educational practice and psychologicaltheory.
In Lars-GOran Nilsson, editor,Perspectives on Memory Research.
LawrenceErlbaum, pages 329-365.Mittal, Vibhu, Johanna Moore, GuiseppeCarenini, and Steven Roth.
1998.Describing complex charts in naturallanguage: A caption generation system.Computational Linguistics, 24:431-467.Paiva, Daniel.
1998.
A survey of appliednatural anguage generation systems.Technical Report ITRI-98-03, InformationTechnology Research Institute, Universityof Brighton, UK.Reiter, Ehud.
1994.
Has a consensus NLgeneration architecture appeared, and is itpsycholinguistically plausible?
InProceedings ofthe Seventh InternationalWorkshop on Natural Language Generation(INLGW-1994), pages 163-170.Reiter, Ehud and Robert Dale.
2000.
BuildingNatural Language Generation Systems.Cambridge University Press.
In press.Reiter, Ehud, Roma Robertson, and LieslOsman.
1999.
Types of knowledgerequired to personalise smoking cessationletters.
In Werner Horn et al, editors,Artificial Intelligence and Medicine:Proceedings ofAIMDM-1999,pages 389-399.
Springer-Verlag.259
