SESSION 4: SPEECH IRichard F. LyonApple Computer, Inc.,20450 Stevens Creek Boulevard, MS 76-2HCupertino, CA 95014INTRODUCTIONThis session focussed on robustness in speech recognition.The first two papers considered the effects of working with apopulation of real users in telephone-services environments,while the final two papers looked at front-end technologies,namely microphone arrays and representations of acousticinformation.SUMMARY OF PRESENTATIONS ANDDISCUSSIONThe first paper, "Field Test Evaluations and Optimizations ofSpeaker Independent Speech Recognition for TelephoneApplications," by Gagnoulet and Sorin of CNET, was presentedby Christel Sorin.
This paper discussed various ways ofimproving system usability and performance by optimizingboth the dialog ergonomy and the recognition technologywithin the constraints of low-cost real-time implementation.Techniques discussed included use of field data in training,increasing the number of parameters, automatic adjustments ofthe HMM structure, and better ejection procedures.
A briefdiscussion of the rejection rate versus error rate tradeoff ensued;nobody had any good data or ideas on how to make thistradeoff, so when one person suggested that the rejection rateshould be adjusted to keep the error rate under 5 percent, we saidOK and moved on.The second paper, "Collection and Analysis of Data FromReal Users: Impl icat ions for Speech Recognit ion/Understanding Systems," by Judith Spitz and the AI Speechgroup at NYNEX, concentrated on analyzing user responsecharacteristics as a function of the prompts used, and oncomparing user versus laboratory speech characteristics withrespect o their effects on recognition performance.
SinceNYNEX has gone to the trouble of collecting lots of good data,including TIM\[I" data run through the telephone network, therewas some discussion of the possibility of distributing some oftheir data, such as the Network-TIMrr data and telephoneservices data, through NIST.
Legal issues are the most seriousproblem at this point for the telephone services data, since it isnot possible to get explicit consent from the talkers.The third paper, "Autodirective Microphone Systems forNatural Communication with Speech Recognizers," byFlanagan, Mammone, and Elko of Rutgers University, waspresented by Jim Flanagan.
He surveyed recent advances andopportunities in steerable-beam icrophone arrays withautomatic source tracking.
An audio tape demonstratedexcellent-quality recording from a single speaker in a 300-seatauditorium using a 2D array on the ceiling.
A video tapeshowed the 1D array used in the HuManNet system.
The relativemerits of noise cancellation filters and steerable beams werediscussed, and it was suggested that noise cancellation mayactually be a much more useful technique when combined with asteerable microphone array.The final paper, "Signal Representation, AttributeExtraction, and the Use of Distinctive Features for PhoneticClassification," by Meng, Zue, and Leung of MIT's Laboratoryfor Computer Science, was presented by Helen Meng.
Thispresentation covered results of careful experimentalcomparisons of different front-end representations (e.g.auditory, Mel-cepstrum, DFT, etc.)
and various ways ofincorporating acoustic attributes and distinctive features, in thecontext of multilayer peroeptron based vowel classification.The dual auditory model (mean rate plus synchronyrepresentations) worked best as the front end (especially innoise, but by an insignificant margin in some other cases).Significant computational savings was possible by reducingthe front-end output o a few simple acoustic attributes, and theloss in accuracy was small and probably insignificant.
Usingdistinctive features was said to provide for the possibility ofbetter phonological-level generalization; the loss in accuracyof incorporating features (followed by a second MLP to do thephoneme classification) was not significant.
Discussionfollowed on possible explanations for why the auditory modelworks as well as it does; nobody had a sukable xplanation, butthe conjecture that it was primarily due to the synchronyinformation was shown to be not supported by the data, sincethe rate-only model worked almost as well.159
