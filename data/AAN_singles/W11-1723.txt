Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, ACL-HLT 2011, pages 175?181,24 June, 2011, Portland, Oregon, USA c?2011 Association for Computational LinguisticsCorporate News Classification and Valence Prediction: A SupervisedApproachSyed Aqueel Haider Rishabh MehrotraDept.
of Computer Science & Engineering Computer Science & Information SystemsGroupMIT, Manipal University BITS,PilaniKA-576104, India.
Rajasthan,India.Aqueel.h.rizvi@gmail.com erishabh@gmail.comAbstractNews articles have always been aprominent force in the formation of acompany?s financial image in the mindsof the general public, especially theinvestors.
Given the large amount ofnews being generated these days throughvarious websites, it is possible to mine thegeneral sentiment of a particular companybeing portrayed by media agencies over aperiod of time, which can be utilized togauge the long term impact on theinvestment potential of the company.However, given such a vast amount ofnews data, we need to first separatecorporate news from other kinds namely,sports, entertainment, science &technology, etc.
We propose a systemwhich takes news as, checks whether it isof corporate nature, and then identifiesthe polarity of the sentiment expressed inthe news.
The system is also capable ofdistinguishing the company/organizationwhich is the subject of the news fromother organizations which find mention,and this is used to pair the sentimentpolarity with the identified company.IntroductionWith the rapid advancements in the field ofinformation technology, the amount of informationavailable has increased tremendously.
Newsarticles constitute the largest available portion offactual information about events happening in theworld.
Corporate news constitutes a major chunkof these news articles.Sentiment Mining applied to the corporatedomain would help in various ways like AutomaticRecommendation Systems, to help organizationsevaluate their market strategies help them frametheir advertisement campaigns.
Our system tries toaddress these issues by automating the entireprocess of news collection, organization/productdetection and sentiment mining.This paper is divided into two main parts.
The firstpart describes a way of identifying corporate newsfrom a collection of news articles and then pairingthe news with the organization/company which isbeing talked about in the article.
The second partof our paper works on the output of the first part(corporate news) and detects the valence of theidentified corporate news articles.
It calculates anoverall score and identifies valence a s positive,negative or neutral based on this score.
The systemis immune to addition/mergers of companies, withregards to their identification, as it does not useany name lists.The model uses a machine learning approach to dothis task.
We extract a set of features from thenews and use them to train a set of classifiers.
Thebest model is then used to classify the test data.One advantage of our approach described below isthat it only requires a very small amount ofannotated training data.
We trained the model onthe NewsCorp dataset consisting of 860 annotatednews articles.
The system has shown promising175results on test data with classification accuracybeing  92.05% and a f-measure of 92.00.
The finalaverage valence detection accuracy measured was79.93%.Related WorkMuch work has been done on textclassification.
(Barak, 2009; Sebastiani,2002) Therehave been earlier attempts (Research  on SportsGame  News  Information  Extraction, YongguiYANG,et  al) However, they had focused mainlyon information extraction and not classification.Earlier attempts on web newsclassification(Krishnlal et al 2010) concentratedmainly on classification according to the domain ofthe news articles.
Not much work has been done inthe field of corporate news-company pairing.
Thispaper tries to address a more general problem ofdetecting the main organization being talked aboutin the articles.Sentiment analysis in computational linguisticshas focused on examining what textual featurescontribute to affective content of text andautomatically detecting these features to derive asentiment metric for a word, sentence or whole text.Niederhoffer (1971) after classifying New YorkTimes headlines into 19 categories evaluated howthe markets react to good and bad news.Davis et al(2006) investigate the effects ofoptimistic or pessimistic language used in financialpress releases on future firm performance.Sumbaly et al2009) used k gram models to detectsentiment in large news datasets.
Devitt(2007)improves upon and Melville(2009) have done workon sentiment analysis of web blogsPART I : News ClassificationSteps involved in news classification3.1 News Pre-processingThe preprocessor merges all the files into one butdefines start/end delimiters for each file in themerged file, to enable bulk processing.
The mergednews file is acted upon by a log-linear part ofspeech  tagger we obtained from the Stanford NLPwebpage(Manning,2000).3.2     Organization detectionWe follow a two step approach to organizationdetection:Step 1:   We extract the NNP/NNPS1 clusters inthe POS-tagged file using reguar expressions.
Forexample, the pos-tagged version of ?GeneralElectric Co?, is ?
General_NNP Electric_NNPCo_NNP?
which is detected as a likely candidatefor an organization.Step 2: We use a Named Entity Recognizer[2] toobtain organization names.
They are sorted inorder of their frequencies and top threeorganizations are stored for later use.
This ensuresthat even if some names have crept in asorganizations due to misclassification by NERtagger, they end up at the bottom of the list and arediscarded.Multiple Organization Focus: Let f1,f2 be thefrequencies of top 2 organizations.
Now if f2>f1/2then the news article is paired with organizationscorresponding to both f1 and f2.Baseline: Using just the frequency of top 3organizations as features, we get an accuracy of48.89% which is very low.
Therefore, we addadditional features which are described below.3.3   Keyword DetectionThe system matches each news article foroccurrence of a set of keywords like ?company?,?share?, ?asset?, etc.
which have been derivedfrom statistical observation of corporate news.
Wehave used POS tags to differentiate between thecontexts in which the keywords have been used.For example, ?share?
(verb) is not a keyword but?share?
(noun) is a keyword.
We calculate the netkeyword occurrence frequency asN(key)= )  where N(key) is the totalkeyword frequency and   is the frequencyof each keyword.3.4   Headline PreprocessingWe process the headline and detect likelycandidates for organization names and then crosscheck with the top 3 organization names detectedin the step 2.2.
We introduce a new feature h_valuedescribed as follows:1Please refer Appendix A for details of the POS Tags.1763.5  Detection of ProductsThe system detects likely candidates for productsusing three empirical rules:?
1.
_NNP followed by _POS followed by_NNP cluster.
Ex: Google?s Wave?
2.The followed by _NNP cluster.
Example:The new POWER7 processors from IBM?
3._PRP$ followed by _NNP cluster.Example:  Apple announced that its iPhone3G will not be launched in India.3.6  Executives DetectionWe follow a similar POS based approach to detectexecutives, and store their frequency.3.7    Feature GenerationWe use a total of 9 features to train the SVMclassifier.
They are described below:1-3:   frequency of top 3 organizations4:      frequency of Executives in the news article5-7:   frequencies of top 3 products discussed inthe news.8.
The N(key) value defined above in section 3.39.      h_value defined above in section 3.2.4    Classification and trainingWe tested our method with several classifiers.First we used Support Vector Machines usingLibSVM[**].
The results obtained weresatisfactory.
However, we experimented with othermodels to see model variation can lead to someimprovement.We tried Logistic Regression which is a classfor building and using a multinomial logisticregression model with a ridge estimator.
Wetrained our model with ridge parameter 1.0E-8.We compared our classification results withNaives Bayes classifier which uses estimatorclasses for making the model.
Numeric estimatorprecision values are chosen based on analysis ofthe training data.We also tested our dataset with AdaBoost(Adaptive Boosting) classifier.
AdaBoost callsa weak classifier repeatedly in a series of rounds tocorrectly identify the weights of the parameters.The detailed results of the classification algorithmsare discussed in the Experiments and Resultssection.PART II : Headline Sentiment taggingWe describe a lexical features based approach todetect the sentiment polarity in a news article.5.1 PreprocessingOne of the features of the news headlines extractedfrom the Internet was that many had all wordscapitalized.
The system detects the improperlycapitalized words and de-capitalizes their commonwords.
This task is accomplished by using thefollowing rule on the output given initially by thePOS Tagger in Part I of our framework.Rule: Only the words with POS tags as NNP orNNPS retain their capitalization, all others aredecapitalized.
Headline processing helps the POSTagger to tag the words correctly and hence thedependencies will now be correct.5.2 StemmingWords which might carry opinions may be presentin inflected forms which requires stemming of thewords before any rules can be applied on them.Words that are identified to have the same rootform are grouped in a finite number of clusterswith the identified root word as cluster center.
Wehave used the Porter Stemmer(Porter 1980)for thispurpose.5.3 Noise ReductionThe news article contains many parts of speechwhich are irrelevant to sentiment detection in ourcase, for example, prepositions, conjunctions, etc.We give a list of Penn Treebank tags which weeliminate:177CC , CD, DT, EX, IN,  PRP, PRP$, TO .
Please referto the Appendix A for the meaning of each POS-tag.5.4    Polarity EstimationWe used the SentiWordNet (Sebastiani,2006) inorder to calculate the sentiment polarity(valence)of all the words in the headline and the body.We use WordNet to find sentiment polarityvalue(SPV) of each word.
In WordNet, nouns,verbs, adjectives and adverbs are grouped intosynonym sets (synsets).
Synsets represent terms orconcepts.
For example, following is a synset fromWordNet:stadium, bowl, arena, sports stadium ?
(a largestructure for open-air sports or entertainments)The synsets are related to other synsets higher orlower in the hierarchy by different types ofrelationships e.g.?
Hyponym/Hypernym (Is-A relationships)?
Meronym/Holonym (Part-Of relationships)?
Nine noun and several verb Is-A hierarchiesUsing WordNet?s word hierarchy we boostedsentiment polarities of a word (synset in WordNet),depending on whether a noun/verb, having aparticular sentiment polarity  is a hyponym of thegiven synset.
The candidate synsets for polaritydetection were extracted using a bootstrappingapproach starting with some positive and negativeseed words.Parent synset Boosted Polaritypoor negativegood positiverise positivedown negativedecrease negativegrowth positiveloss negativeTable 1: Examples of hypernyms boostingsentiment polarity5.5    Overall Valence ClassificationAfter valences for each word have been detected,we proceed to find out the overall valence of thenews article.
We follow 2 rules for this task:1.
Since each word can have severalmeanings, to calculate the SPV of a word,we assumed that the these values were theaverage of all its possible meanings.2.
The SPV of words occurring in theheadline are given higher weightage, ascompared to those in the body.
Afterseveral experimental trials, we concludedthat a weight ratio of 4:1 was optimal.
( 4for words in headline).The second rule is a direct consequence of thefact that news writers always try to provide theoverall sentiment of the news in the headlineitself so as to ease the understanding of thereader.Now the overall valence score(OVS) is calculatedusing the simple expression OVS=where SP  is the Sentiment polarity value of eachword in the news article.Final decision:OVS > +k,               positive polarityOVS < -k,                negative polarity-k ?
OVS ?
k,         neutral polarityWe experimented with different values of k andfound out that a value of k=3 was most suitable forour task.
Also, we could have normalized kaccording to the length of the news article toaccount for larger number of polar words inlengthier articles.
However, we avoid doing so,because the probability of occurrence of positivepolar words is the same as that of negative polarwords, hence, neutralizing the effect of each other.Finally, the OVS  value provides a metric for thestrength of the valence of news article.
Highermagnitudes of OVS correspond to more stronglyexpressed sentiments.1786    Experiments and ResultsIn this section we discuss the dataset used in ourexperiments, the evaluation settings and theclassification results obtained with our model.6.1    The NewsCorp DatasetWe obtained 860 news samples from differentnews sites including:1.ABC news2.
Reuters3.
MSNBC4.
CBC News Online, etc.Our research team read these 860 news articles andcreated files for each of the news articles whichcontained details whether the article is corporate ornon-corporate and if it is corporate then otherdetails like main Organization being talked aboutin the article, different products and/or executivesrelated to the organization mentioned in the article.We used these metadata files to evaluate ourresults regarding Organization, product andexecutive detection.This dataset is then used to train the model forclassification and also for sentiment mining task.Sample metadata file:6.2    Evaluation MethodologyWe evaluate our method via 10-fold cross-validation, where we have sub-sampled thetraining folds in order to (a) keep thecomputational burden as low as possible and (b)show that we can learn sensible parameterizationsbased upon relatively low requirements in terms ofthe preferences seen on previous users.
Weevaluate the system in stages so that thecontribution of each stage in the overall resultbecomes clear.
We tested 860 news samples forcorporate news detection.
There were 261 truenegative, 39 false positive, 83 false negative and477 true positive articles.
Precision, Recall and F-score are computed as:Recall= TP / (TP+FN) Precision= TP / (TP+FP)F-Score=(2.Precision.Recall)/(Precision+Recall)We evaluated our results in three different stages.We first used basic Organization detection usingNER tagger output as our baseline.
Next weincorporated headline processing and keywordfrequency detection in the second stage.
Finally thethird stage included the Product and Executivedetection feature for result evaluation.6.3    Classification  ResultsIn order to classify the news article as corporateand non-corporate we used 4 differentclassification algorithms and compared theirresults.
The four algorithms are:1.
Support Vector Machines2.
Logistic Regression3.
Naives Bayes4.
AdaBoostTable 2 (Classification Results)Support Vector Machine gave us a third stage FValue of 88.66%  while Naives Bayes gave a FValue of 88.3%.Logistic Regression showed an improvementfactor of 1.7% over Naives Bayes by giving FValue of 90.0%.AdaBoost technique gave us the best classificationresult of  92& as the F value.The different Precision, Recall, ROC Area and FMeasure of the four algorithms are tabulated inTable 2 and Fig.2.Algorithm Precision Recall F-Val ROCAreaNaives Bayes 88.3 88.4 88.3 0.94SupportVectorMachine85.81 92.44 85.17 0.94LogisticRegression90.4 89.9 90.0 0.95AdaBoost 92.0 92.1 92.0 0.937179Fig.
1: Classification Results6.4    Valence detection experimental resultsThe proposed system was tested with 608 articlessince out of 860, 608 were identified to be ofcorporate type.
The classification was 3 way,namely POS, NEG and NEUT ( representing +ve, -ve and neutral respectively).
The results are shownin Figure 1 in the form of a confusion matrix.
Outof a total 608 financial news articles, 264 weretagged with positive sentiment,  162 with negativesentiment and 182 were found to be neutral.Fig 2.
Confusion Matrix for Valence DetectionHowever, our proposed approach yields anaccuracy of 84.84, 91.35 and 62.35 for positive ,negative and neutral news sentiments respectively .A possible reason for a low accuracy in case ofneutral news articles could be because of thepresence of some stray polar words in the body ofthe news, which might have added to a sum ofmore than ?k?
in magnitude(as defined in Section5.5), thereby leading to the development of anunwanted polarity.Also, we observe a higher accuracy in predictingnegative articles, the reason for which could not beidentified.
However, as proposed by a colleague, itcould possibly be attributed to the fact thatnegative sentiment is more strongly expressed byJournalists in news articles, as compared topositive sentiment, which might have aided inbetter detection of words with negative polarity.Finally, we calculated the overall predictionaccuracy by taking the average of accuracies for allthree sentiments, which comes out to be79.93%(Table 4).Precision Recall AccuracyPOS 80.58 84.85 84.84NEG 86.05 91.46 91.35NEUT 72.15 66.27 62.35Table 3:Scores for Valence Detection7    Conclusion and Future WorkA framework for valence identification and newsclassification has been proposed.
News articlesmined from the web by a crawler are fed to thesystem to filter the financial news from other kindsof news(sports, entertainment etc).
Next, theorganization which is the subject of this news isidentified.
Finally, we determine the sentimentpolarity of the news by utilizing several lexicalfeatures and semantic relationships from WordNet.We experiment with the system using our ownmanually tagged corpus of 860 news articles tofine tune various parameters like weights andthreshold values.
The resulting system performswell with identification of financial news as well asdetection of valence in those articles.
The systemgives good result for positive and negativesentiments but satisfactory results for neutralsentiments.
An overall accuracy of 79.93 % isobtained.In the near future, we intend to apply anaphoraresolution and use anaphoric distance to rank polarwords according to relevance.
This will help us toidentify and give more weight to words whichdescribe the sentiment of the author, from other?stray?
words which are external references, notdetermining the overall sentiment of the news.PredictedPOS NEG NEUTActualPOS 224 06 34NEG 04 148 10NEUT 50 18 114180ReferencesA New Text Mining Approach Based on HMM-SVMfor Web News ClassificationLewis, D. D.: Reuters-21578 Document Corpus V1.0Angela K. Davis, Jeremy M. Piger, and Lisa M. Sedor.2006.Beyond the numbers: An analysis of optimisticand pessimistic language in earnings press releases.Technical report, Federal Reserve Bank of St Louis.B.
E. Boser, I. Guyon, and V. Vapnik.
A trainingalgorithm for optimal margin classiers.
InProceedings of the Fifth Annual Workshop onComputational Learning Theory, pages 144{152.ACM Press, 1992.Barak and Dagan.2009.
Text Categorization fromCategory Name via Lexical Reference.
Proceedingsof NAACL HLT 2009.Chih-Chung Chang and Chih-Jen Lin, LIBSVM : alibrary for support vector machines, 2001.
Softwareavailable at http://www.csie.ntu.edu.tw/~cjlin/libsvmhttp://acl.ldc.upenn.edu/J/J93/J93-2004.pdfDevitt et al(2007) Sentiment Polarity Identification inFinancial News: A Cohesion-based ApproachGeorge A. Miller (1995).
WordNet: A Lexical Databasefor English.Communications of the ACM Vol.
38,No.
11: 39-41.Jenny Rose Finkel, Trond Grenager, and ChristopherManning.
2005.
Incorporating Non-local Informationinto Information Extraction Systems by GibbsSampling.
Proceedings of the 43nd Annual Meetingof the Association for Computational Linguistics(ACL 2005), pp.
363-370.Kristina Toutanova and Christopher D. Manning.
2000.Enriching the Knowledge Sources Used in aMaximum Entropy Part-of-Speech Tagger.
InProceedings of the Joint SIGDAT Conference onEmpirical Methods in Natural Language Processingand Very Large Corpora (EMNLP/VLC-2000), pp.63-70.Melville et al(2009) Sentiment Analysis of Blogs byCombining.
Lexical Knowledge with TextClassification.Ozgur, A.: Supervised and Unsupervised MachineLearning Techniques for Text DocumentCategorization.
Master?s Thesis (2004), BogaziciUniversity, Turkey.Porter, M.F.
(1980) An Algorithm for Suffix Stripping,Program, 14(3): 130?137Sebastiani, F.: Machine Learning in Automated TextCategorization.
ACM Computing Surveys 34 no.
5(2002)Sentiment Mining in Large News Datasets.
RoshanSumbaly, Shakti Sinha, May 10, 2009.UPAR7: A knowledge-based system for headlinesentiment tagging.
Fran?ois-R?gis ChaumartinLattice/Talana ?
Universit?
Paris 7U.
Hahn and M. Romacker Content Management in theSynDiKATe system ?
How tdocuments are automatically transformed to textknowledge bases.
Data & Knowledge Eing, 35, 2000, pages 137-159.Victor Niederhoffer.
1971.
The analysis of world eventsand stock prices.
Journal of Business, 44(2):193?219.Appendix A. POS TagsThe POS tags used in Part I of the paper are describedas follows:NN    =   NounNNS =   Plural NounNNP =   Proper NounPRP    = Personal PronounPRP$ =   Possessive PronounJJ        =   AdjectiveTO      = ?to?CD      = Cardinal NumberDT      = DeterminerCC      = Coordinating conjunctionEX      = Existential thereIN       = Preposition or subordinating conjunction181
