Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 625?632,Sydney, July 2006. c?2006 Association for Computational LinguisticsExploiting Syntactic Patterns as Clues in Zero-Anaphora ResolutionRyu Iida, Kentaro Inui and Yuji MatsumotoGraduate School of Information Science,Nara Institute of Science and Technology8916-5 Takayama, Ikoma, Nara, 630-0192, Japan{ryu-i,inui,matsu}@is.naist.jpAbstractWe approach the zero-anaphora resolu-tion problem by decomposing it intointra-sentential and inter-sentential zero-anaphora resolution.
For the former prob-lem, syntactic patterns of the appearanceof zero-pronouns and their antecedents areuseful clues.
Taking Japanese as a targetlanguage, we empirically demonstrate thatincorporating rich syntactic pattern fea-tures in a state-of-the-art learning-basedanaphora resolution model dramaticallyimproves the accuracy of intra-sententialzero-anaphora, which consequently im-proves the overall performance of zero-anaphora resolution.1 IntroductionZero-anaphora is a gap in a sentence that has ananaphoric function similar to a pro-form (e.g.
pro-noun) and is often described as ?referring back?to an expression that supplies the information nec-essary for interpreting the sentence.
For example,in the sentence ?There are two roads to eternity,a straight and narrow, and a broad and crooked,?the gaps in ?a straight and narrow (gap)?
and ?abroad and crooked (gap)?
have a zero-anaphoricrelationship to ?two roads to eternity.
?The task of identifying zero-anaphoric relationsin a given discourse, zero-anaphora resolution,is essential in a wide range of NLP applications.This is the case particularly in such a language asJapanese, where even obligatory arguments of apredicate are often omitted when they are inferablefrom the context.
In fact, in our Japanese newspa-per corpus, for example, 45.5% of the nominativearguments of verbs are omitted.
Since such gapscan not be interpreted only by shallow syntac-tic parsing, a model specialized for zero-anaphoraresolution needs to be devised on the top of shal-low syntactic and semantic processing.Recent work on zero-anaphora resolution canbe located in two different research contexts.
First,zero-anaphora resolution is studied in the con-text of anaphora resolution (AR), in which zero-anaphora is regarded as a subclass of anaphora.
InAR, the research trend has been shifting from rule-based approaches (Baldwin, 1995; Lappin and Le-ass, 1994; Mitkov, 1997, etc.)
to empirical, orcorpus-based, approaches (McCarthy and Lehnert,1995; Ng and Cardie, 2002a; Soon et al, 2001;Strube and Mu?ller, 2003; Yang et al, 2003) be-cause the latter are shown to be a cost-efficientsolution achieving a performance that is compa-rable to best performing rule-based systems (seethe Coreference task in MUC1 and the Entity De-tection and Tracking task in the ACE program2).The same trend is observed also in Japanese zero-anaphora resolution, where the findings made inrule-based or theory-oriented work (Kameyama,1986; Nakaiwa and Shirai, 1996; Okumura andTamura, 1996, etc.)
have been successfullyincorporated in machine learning-based frame-works (Seki et al, 2002; Iida et al, 2003).Second, the task of zero-anaphora resolutionhas some overlap with Propbank3-style semanticrole labeling (SRL), which has been intensivelystudied, for example, in the context of the CoNLLSRL task4.
In this task, given a sentence ?To at-tract younger listeners, Radio Free Europe inter-sperses the latest in Western rock groups?, an SRL1http://www-nlpir.nist.gov/related projects/muc/2http://projects.ldc.upenn.edu/ace/3http://www.cis.upenn.edu/?mpalmer/project pages/ACE.htm4http://www.lsi.upc.edu/?srlconll/625model is asked to identify the NP Radio Free Eu-rope as the A0 (Agent) argument of the verb at-tract.
This can be seen as the task of findingthe zero-anaphoric relationship between a nomi-nal gap (the A0 argument of attract) and its an-tecedent (Radio Free Europe) under the conditionthat the gap and its antecedent appear in the samesentence.In spite of this overlap between AR and SRL,there are some important findings that are yet tobe exchanged between them, partly because thetwo fields have been evolving somewhat indepen-dently.
The AR community has recently made twoimportant findings:?
A model that identifies the antecedent of ananaphor by a series of comparisons betweencandidate antecedents has a remarkable ad-vantage over a model that estimates the ab-solute likelihood of each candidate indepen-dently of other candidates (Iida et al, 2003;Yang et al, 2003).?
An AR model that carries out antecedentidentification before anaphoricity determina-tion, the decision whether a given NP isanaphoric or not (i.e.
discourse-new), sig-nificantly outperforms a model that executesthose subtasks in the reverse order or simulta-neously (Poesio et al, 2004; Iida et al, 2005).To our best knowledge, however, existing SRLmodels do not exploit these advantages.
In SRL,on the other hand, it is common to use syntacticfeatures derived from the parse tree of a given in-put sentence for argument identification.
A typ-ical syntactic feature is the path on a parse treefrom a target predicate to a noun phrase in ques-tion (Gildea and Jurafsky, 2002; Carreras and Mar-quez, 2005).
However, existing AR models dealwith intra- and inter-sentential anaphoric relationsin a uniform manner; that is, they do not use as richsyntactic features as state-of-the-art SRL modelsdo, even in finding intra-sentential anaphoric rela-tions.
We believe that the AR and SRL communi-ties can learn more from each other.Given this background, in this paper, we showthat combining the aforementioned techniques de-rived from each research trend makes signifi-cant impact on zero-anaphora resolution, takingJapanese as a target language.
More specifically,we demonstrate the following:?
Incorporating rich syntactic features in astate-of-the-art AR model dramatically im-proves the accuracy of intra-sentential zero-anaphora resolution, which consequently im-proves the overall performance of zero-anaphora resolution.
This is to be consideredas a contribution to AR research.?
Analogously to inter-sentential anaphora, de-composing the antecedent identification taskinto a series of comparisons between candi-date antecedents works remarkably well alsoin intra-sentential zero-anaphora resolution.We hope this finding to be adopted in SRL.The rest of the paper is organized as follows.Section 2 describes the task definition of zero-anaphora resolution in Japanese.
In Section 3,we review previous approaches to AR.
Section 4described how the proposed model incorporateseffectively syntactic features into the machinelearning-based approach.
We then report theresults of our experiments on Japanese zero-anaphora resolution in Section 5 and conclude inSection 6.2 Zero-anaphora resolutionIn this paper, we consider only zero-pronouns thatfunction as an obligatory argument of a predicatefor two reasons:?
Providing a clear definition of zero-pronounsappearing in adjunctive argument positionsinvolves awkward problems, which we be-lieve should be postponed until obligatoryzero-anaphora is well studied.?
Resolving obligatory zero-anaphora tends tobe more important than adjunctive zero-pronouns in actual applications.A zero-pronoun may have its antecedent in the dis-course; in this case, we say the zero-pronoun isanaphoric.
On the other hand, a zero-pronounwhose referent does not explicitly appear in thediscourse is called a non-anaphoric zero-pronoun.A zero-pronoun may be non-anaphoric typicallywhen it refers to an extralinguistic entity (e.g.
thefirst or second person) or its referent is unspecifiedin the context.The following are Japanese examples.
In sen-tence (1), zero-pronoun ?i is anaphoric as its an-tecedent, ?shusho (prime minister)?, appears in thesame sentence.
In sentence (2), on the other hand,?j is considered non-anaphoric if its referent (i.e.the first person) does not appear in the discourse.
(1) shushoi-wa houbeisi-te ,prime ministeri-TOP visit-U.S.-CONJ PUNC626ryoukoku-no gaikou-oboth countries-BETWEEN diplomacy-OBJ(?i-ga) suishinsuru(?i-NOM) promote-ADNOMhoushin-o akirakanisi-ta .plan-OBJ unveil-PAST PUNCThe prime minister visited the united statesand unveiled the plan to push diplomacybetween the two countries.
(2) (?j-ga) ie-ni kaeri-tai .
(?j -NOM) home-DAT want to go back PUNC(I) want to go home.Given this distinction, we consider the task ofzero-anaphora resolution as the combination oftwo sub-problems, antecedent identification andanaphoricity determination, which is analogous toNP-anaphora resolution:For each zero-pronoun in a given dis-course, find its antecedent if it isanaphoric; otherwise, conclude it to benon-anaphoric.3 Previous work3.1 Antecedent identificationPrevious machine learning-based approaches toantecedent identification can be classified as ei-ther the candidate-wise classification approach orthe preference-based approach.
In the former ap-proach (Soon et al, 2001; Ng and Cardie, 2002a,etc.
), given a target anaphor, TA, the model esti-mates the absolute likelihood of each of the candi-date antecedents (i.e.
the NPs preceding TA), andselects the best-scored candidate.
If all the can-didates are classified negative, TA is judged non-anaphoric.In contrast, the preference-based ap-proach (Yang et al, 2003; Iida et al, 2003)decomposes the task into comparisons of thepreference between candidates and selects themost preferred one as the antecedent.
For exam-ple, Iida et al (2003) proposes a method calledthe tournament model.
This model conducts atournament consisting of a series of matches inwhich candidate antecedents compete with eachother for a given anaphor.While the candidate-wise classification modelcomputes the score of each single candidate inde-pendently of others, the tournament model learnsthe relative preference between candidates, whichis empirically proved to be a significant advan-tage over candidate-wise classification (Iida et al,2003).3.2 Anaphoricity determinationThere are two alternative ways for anaphoric-ity determination: the single-step model and thetwo-step model.
The single-step model (Soon etal., 2001; Ng and Cardie, 2002a) determines theanaphoricity of a given anaphor indirectly as aby-product of the search for its antecedent.
Ifan appropriate candidate antecedent is found, theanaphor is classified as anaphoric; otherwise, it isclassified as non-anaphoric.
One disadvantage ofthis model is that it cannot employ the preference-based model because the preference-based modelis not capable of identifying non-anaphoric cases.The two-step model (Ng, 2004; Poesio et al,2004; Iida et al, 2005), on the other hand, car-ries out anaphoricity determination in a separatestep from antecedent identification.
Poesio etal.
(2004) and Iida et al (2005) claim that the lat-ter subtask should be done before the former.
Forexample, given a target anaphor (TA), Iida et al?sselection-then-classification model:1. selects the most likely candidate antecedent(CA) of TA using the tournament model,2.
classifies TA paired with CA as eitheranaphoric or non-anaphoric using ananaphoricity determination model.
If theCA-TA pair is classified as anaphoric, CA isidentified as the antecedent of TA; otherwise,TA is conclude to be non-anaphoric.The anaphoricity determination model learns thenon-anaphoric class directly from non-anaphorictraining instances whereas the single-step modelcannot not use non-anaphoric cases in training.4 Proposal4.1 Task decompositionWe approach the zero-anaphora resolution prob-lem by decomposing it into two subtasks: intra-sentential and inter-sentential zero-anaphora reso-lution.
For the former problem, syntactic patternsin which zero-pronouns and their antecedents ap-pear may well be useful clues, which, however,does not apply to the latter problem.
We there-fore build a separate component for each sub-task, adopting Iida et al (2005)?s selection-then-classification model for each component:1.
Intra-sentential antecedent identification:For a given zero-pronoun ZP in a givensentence S, select the most-likely candidateantecedent C?1 from the candidates appearingin S by the intra-sentential tournament model6272.
Intra-sentential anaphoricity determination:Estimate plausibility p1 that C?1 is the true an-tecedent, and return C?1 if p1 ?
?intra (?intrais a preselected threshold) or go to 3 other-wise3.
Inter-sentential antecedent identification:Select the most-likely candidate antecedentC?2 from the candidates appearing outside ofS by the inter-sentential tournament model.4.
Inter-sentential anaphoricity determination:Estimate plausibility p2 that C?2 is the trueantecedent, and return C?2 if p2 ?
?inter(?inter is a preselected threshold) or returnnon-anaphoric otherwise.4.2 Representation of syntactic patternsIn the first two of the above four steps, we use syn-tactic pattern features.
Analogously to SRL, weextract the parse path between a zero-pronoun toits antecedent to capture the syntactic pattern oftheir occurrence.
Among many alternative waysof representing a path, in the experiments reportedin the next section, we adopted a method as wedescribe below, leaving the exploration of other al-ternatives as future work.Given a sentence, we first use a standard depen-dency parser to obtain the dependency parse tree,in which words are structured according to the de-pendency relation between them.
Figure 1(a), forexample, shows the dependency tree of sentence(1) given in Section 2.
We then extract the pathbetween a zero-pronoun and its antecedent as inFigure 1(b).
Finally, to encode the order of sib-lings and reduce data sparseness, we further trans-form the extracted path as in Figure 1(c):?
A path is represented by a subtree consist-ing of backbone nodes: ?
(zero-pronoun),Ant (antecedent), Node (the lowest commonancestor), LeftNode (left-branch node) andRightNode.?
Each backbone node has daughter nodes,each corresponding to a function word asso-ciated with it.?
Content words are deleted.This way of encoding syntactic patterns is usedin intra-sentential anaphoricity determination.
Inantecedent identification, on the other hand, thetournament model allows us to incorporate threepaths, a path for each pair of a zero-pronoun andleft and right candidate antecedents, as shown in  	fffiflffi  ffiff !#" $" ffi  ffi % &	 '' '''' ''( ffi & ( %ffi  ffi ) * + ff,* - .ffi %	, -0/.1/12  ffi ( 3	, 4-56& 7 (  ( /85 + 92 %/ff :;ff< + 5* fl51=>@?  	fffiflffi  ffiff !#" $" ffi  ffi % &	 '' '''' ''( ffi & ( %ffi  ffi ) * + ff, .ffi %	, -/12 < + 5* fl51=ffAB?C DE F3GH89F3'' ''FI3GH89FI3/.12 ff< + 5* fl51=JK?
* -* --30-30-3ffFigure 1: Representation of the path between azero-pronoun to its antecedent    	           fiffflffi !
   " # fl$  % fffl  &'()  *+fi, %- &(.
)% % fifffl  fifffl	% *,% /0&1     %1   1    " 1  % fifffl1 0fifi,1  1  # $fl1   fiffflffi"1  &(.
)1  &(.
)1   fiffflffi"1   fifffl	1  /&2354762358562359!6  :;<  # =<0fi) flfi,%flfi,1  :;<1  # =<0fi)Figure 2: Paths used in the tournament modelFigure 25.4.3 Learning algorithmAs noted in Section 1, the use of zero-pronounsin Japanese is relatively less constrained by syn-tax compared, for example, with English.
Thisforces the above way of encoding path informationto produce an explosive number of different paths,which inevitably leads to serious data sparseness.This issue can be addressed in several ways.The SRL community has devised a range ofvariants of the standard path representation toreduce the complexity (Carreras and Marquez,2005).
Applying Kernel methods such as Treekernels (Collins and Duffy, 2001) and Hierarchi-cal DAG kernels (Suzuki et al, 2003) is anotherstrong option.
The Boosting-based algorithm pro-5To indicate which node belongs to which subtree, the la-bel of each node is prefixed either with L, R or I.628       Figure 4: Tree representation of features for thetournament model.posed by Kudo and Matsumoto (2004) is designedto learn subtrees useful for classification.Leaving the question of selecting learning al-gorithms open, in our experiments, we have sofar examined Kudo and Matsumoto (2004)?s al-gorithm, which is implemented as the BACT sys-tem6.
Given a set of training instances, each ofwhich is represented as a tree labeled either pos-itive or negative, the BACT system learns a listof weighted decision stumps with a Boosting al-gorithm.
Each decision stump is associated withtuple ?t, l, w?, where t is a subtree appearing inthe training set, l a label, and w a weight, indicat-ing that if a given input includes t, it gives w votesto l. The strength of this algorithm is that it dealswith structured feature and allows us to analyzethe utility of features.In antecedent identification, we train the tour-nament model by providing a set of labeled treesas a training set, where a label is either left orright.
Each labeled tree has (i) path trees TL,TR and TI (as given in Figure 2) and (ii) a setnodes corresponding to the binary features sum-marized in Table 3, each of which is linked tothe root node as illustrated in Figure 4.
This wayof organizing a labeled tree allows the model tolearn, for example, the combination of a subtreeof TL and some of the binary features.
Anal-ogously, for anaphoricity determination, we usetrees (TC , f1, .
.
.
, fn), where TC denotes a pathsubtree as in Figure 1(c).5 ExperimentsWe conducted an evaluation of our method usingJapanese newspaper articles.
The following fourmodels were compared:1.
BM: Ng and Cardie (2002a)?s model,which identify antecedents by the candidate-wise classification model, and determineanaphoricity using the one-step model.6http://chasen.org/?taku/software/bact/2.
BM STR: BM with the syntactic featuressuch as those in Figure 1(c).3.
SCM: The selection-then-classificationmodel explained in Section 3.4.
SCM STR: SCM with all types of syntacticfeatures shown in Figure 2.5.1 SettingWe created an anaphoric relation-tagged corpusconsisting of 197 newspaper articles (1,803 sen-tences), 137 articles annotated by two annotatorsand 60 by one.
The agreement ratio between twoannotators on the 197 articles was 84.6%, whichindicated that the annotation was sufficiently reli-able.In the experiments, we removed from theabove data set the zero-pronouns to which thetwo annotators did not agree.
Consequently, thedata set contained 995 intra-sentential anaphoriczero-pronouns, 754 inter-sentential anaphoriczero-pronouns, and 603 non-anaphoric zero-pronouns (2,352 zero-pronouns in total), with eachanaphoric zero-pronoun annotated to be linked toits antecedent.
For each of the following exper-iments, we conducted five-fold cross-validationover 2,352 zero-pronouns so that the set of thezero-pronouns from a single text was not dividedinto the training and test sets.In the experiments, all the features were auto-matically acquired with the help of the follow-ing NLP tools: the Japanese morphological ana-lyzer ChaSen7 and the Japanese dependency struc-ture analyzer CaboCha8, which also carried outnamed-entity chunking.5.2 Results on intra-sentential zero-anaphoraresolutionIn both intra-anaphoricity determination and an-tecedent identification, we investigated the effectof introducing the syntactic features for improv-ing the performance.
First, the results of an-tecedent identification are shown in Table 1.
Thecomparison between BM (SCM) with BM STR(SCM STR) indicates that introducing the struc-tural information effectively contributes to thistask.
In addition, the large improvement fromBM STR to SCM STR indicates that the use ofthe preference-based model has significant impacton intra-sentential antecedent identification.
This7http://chasen.naist.jp/hiki/ChaSen/8http://chasen.org/?taku/software/cabocha/629Figure 3: Feature set.Feature Type Feature DescriptionLexical HEAD BF characters of right-most morpheme in NP (PRED).Grammatical PRED IN MATRIX 1 if PRED exists in the matrix clause; otherwise 0.PRED IN EMBEDDED 1 if PRED exists in the relative clause; otherwise 0.PRED VOICE 1 if PRED contains auxiliaries such as ?(ra)reru?
; otherwise 0.PRED AUX 1 if PRED contains auxiliaries such as ?
(sa)seru?, ?hosii?, ?morau?, ?itadaku?,?kudasaru?, ?yaru?
and ?ageru?.PRED ALT 1 if PRED VOICE is 1 or PRED AUX is 1; otherwise 0.POS Part-of-speech of NP followed by IPADIC (Asahara and Matsumoto, 2003).DEFINITE 1 if NP contains the article corresponding to DEFINITE ?the?, such as ?sore?
or?sono?
; otherwise 0.DEMONSTRATIVE 1 if NP contains the article corresponding to DEMONSTRATIVE ?that?
or?this?, such as ?kono?, ?ano?
; otherwise 0.PARTICLE Particle followed by NP, such as ?wa (topic)?, ?ga (subject)?, ?o (object)?.Semantic NE Named entity of NP: PERSON, ORGANIZATION, LOCATION, ARTIFACT,DATE, TIME, MONEY, PERCENT or N/A.EDR HUMAN 1 if NP is included among the concept ?a human being?
or ?atribute of a humanbeing?
in EDR dictionary (Jap, 1995); otherwise 0.PRONOUN TYPE Pronoun type of NP.
(e.g.
?kare (he)?
?
PERSON, ?koko (here)?
?
LOCATION,?sore (this)?
?
OTHERS)SELECT REST 1 if NP satisfies selectional restrictions in Nihongo Goi Taikei (Japanese Lexi-con) (Ikehara et al, 1997); otherwise 0.COOC the score of well-formedness model estimated from a large number of triplets?Noun, Case, Predicate?
proposed by Fujita et al (2004)Positional SENTNUM Distance between NP and PRED.BEGINNING 1 if NP is located in the beggining of sentence; otherwise 0.END 1 if NP is located in the end of sentence; otherwise 0.PRED NP 1 if PRED precedes NP; otherwise 0.NP PRED 1 if NP precedes PRED; otherwise 0.DEP PRED 1 if NPi depends on PRED; otherwise 0.DEP NP 1 if PRED depends on NPi; otherwise 0.IN QUOTE 1 if NP exists in the quoted text; otherwise 0.Heuristic CL RANK a rank of NP in forward looking-center list based on Centering Theory (Groszet al, 1995)CL ORDER a order of NP in forward looking-center list based on Centering Theory (Groszet al, 1995)NP and PRED stand for a bunsetsu-chunk of a candidate antecedent and a bunsetsu-chunk of a predicate which has a targetzero-pronoun respectively.finding may well contribute to semantic role label-ing because these two tasks have a large overlap asdiscussed in Section 1.Second, to evaluate the performance of intra-sentential zero-anaphora resolution, we plottedrecall-precision curves altering threshold parame-ter and ?inter for intra-anaphoricity determinationas shown in Figure 5, where recall R and precisionP were calculated by:R = # of detected antecedents correctly# of anaphoric zero-pronouns ,P = # of detected antecedents correctly# of zero-pronouns classified as anaphoric .The curves indicate the upperbound of the perfor-mance of these models; in practical settings, theparameters have to be trained beforehand.Figure 5 shows that BM STR (SCM STR) out-performs BM (SCM), which indicates that in-corporating syntactic pattern features works re-markably well for intra-sentential zero-anaphoraTable 1: Accuracy of antecedent identification.BM BM STR SCM SCM STR48.0% 63.5% 65.1% 70.5%(478/995) (632/995) (648/995) (701/995)resolution.
Futhermore, SCM STR is signif-icantly better than BM STR.
This result sup-ports that the former has an advantage of learn-ing non-anaphoric zero-pronouns (181 instances)as negative training instances in intra-sententialanaphoricity determination, which enables it to re-ject non-anaphoric zero-pronouns more accuratelythan the others.5.3 DiscussionOur error analysis reveals that a majority of er-rors can be attributed to the current way of han-dling quoted phrases and sentences.
Figure 6shows the difference in resolution accuracy be-tween zero-pronouns appearing in a quotation63000.20.40.60.810  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8precisionrecallBM BM_STRSCMSCM_STRBMBM_STRSCMSCM_STRFigure 5: Recall-precision curves of intra-sentential zero-anaphora resolution.00.20.40.60.810  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8precisionrecallSCM_STRIN_QOUT_QSCM_STRIN_QOUT_QFigure 6: Recall-precision curves of resolving in-quote and out-quote zero-pronouns.
(262 zero-pronouns) and the rest (733 zero-pronouns), where ?IN Q?
denotes the former (in-quote zero-pronouns) and ?OUT Q?
the latter.The accuracy on the IN Q problems is consider-ably lower than that on the OUT Q cases, whichindicates that we should deal with in-quote caseswith a separate model so that it can take into ac-count the nested structure of discourse segmentsintroduced by quotations.5.4 Impact on overall zero-anaphoraresolutionWe next evaluated the effects of introducing theproposed model on overall zero-anaphora resolu-tion including inter-sentential cases.As a baseline model, we implemented the origi-nal SCM, designed to resolve intra-sentential zero-anaphora and inter-sentential zero-anaphora si-multaneously with no syntactic pattern features.Here, we adopted Support Vector Machines (Vap-nik, 1998) to train the classifier on the baseline00.20.40.60.810  0.05  0.1  0.15  0.2  0.25  0.3  0.35  0.4  0.45  0.5precisionrecallSCMSCM_STR?intra=0.0220.013 0.0090.005-0.006SCMSCM_STRFigure 7: Recall-precision curves of overall zero-anaphora resolution.00.050.10.150.20.250.3-0.05 -0.04 -0.03 -0.02 -0.01  0  0.01  0.02  0.03  0.04  0.05AUCthreshold ?intraSCMSCM_STRSCMSCM_STRFigure 8: AUC curves plotted by altering ?intra.model and the inter-sentential zero-anaphora res-olution in the SCM using structural information.For the proposed model, we plotted severalrecall-precision curves by selecting different valuefor threshold parameters ?intra and ?inter.
The re-sults are shown in Figure 7, which indicates thatthe proposed model significantly outperforms theoriginal SCM if ?intra is appropriately chosen.We then investigated the feasibility of parameterselection for ?intra by plotting the AUC values fordifferent ?intra values.
Here, each AUC value isthe area under a recall-precision curve.
The resultsare shown in Figure 8.
Since the original SCMdoes not use ?intra, the AUC value of it is constant,depicted by the SCM.
As shown in the Figure 8,the AUC-value curve of the proposed model is notpeaky, which indicates the selection of parameter?intra is not difficult.6316 ConclusionIn intra-sentential zero-anaphora resolution, syn-tactic patterns of the appearance of zero-pronounsand their antecedents are useful clues.
TakingJapanese as a target language, we have empiricallydemonstrated that incorporating rich syntactic pat-tern features in a state-of-the-art learning-basedanaphora resolution model dramatically improvesthe accuracy of intra-sentential zero-anaphora,which consequently improves the overall perfor-mance of zero-anaphora resolution.In our next step, we are going to address the is-sue of how to find zero-pronouns, which requiresus to design a broader framework that allows zero-anaphora resolution to interact with predicate-argument structure analysis.
Another importantissue is how to find a globally optimal solutionto the set of zero-anaphora resolution problemsin a given discourse, which leads us to exploremethods as discussed by McCallum and Well-ner (2003).ReferencesM.
Asahara and Y. Matsumoto, 2003.
IPADIC User Manual.Nara Institute of Science and Technology, Japan.B.
Baldwin.
1995.
CogNIAC: A Discourse Processing En-gine.
Ph.D. thesis, Department of Computer and Informa-tion Sciences, University of Pennsylvania.X.
Carreras and L. Marquez.
2005.
Introduction to the conll-2005 shared task: Semantic role labeling.
In Proceedingsof the Ninth CoNll, pages 152?164.M.
Collins and N.l Duffy.
2001.
Convolution kernels fornatural language.
In Proceedings of the NIPS, pages 625?632.A.
Fujita, K. Inui, and Y. Matsumoto.
2004.
Detection of in-correct case assignments in automatically generated para-phrases of japanese sentences.
In Proceeding of the firstIJCNLP, pages 14?21.D.
Gildea and D. Jurafsky.
2002.
Automatic labeling of se-mantic roles.
In Computational Linguistics, pages 245?288.B.
J. Grosz, A. K. Joshi, and S. Weinstein.
1995.
Center-ing: A framework for modeling the local coherence ofdiscourse.
Computational Linguistics, 21(2):203?226.R.
Iida, K. Inui, H. Takamura, and Y. Matsumoto.
2003.
In-corporating contextual cues in trainable models for coref-erence resolution.
In Proceedings of the 10th EACL Work-shop on The Computational Treatment of Anaphora, pages23?30.R.
Iida, K. Inui, and Y. Matsumoto.
2005.
Anaphora resolu-tion by antecedent identification followed by anaphoricitydetermination.
ACM Transactions on Asian Language In-formation Processing (TALIP), 4:417?434.S.
Ikehara, M. Miyazaki, S. Shirai A. Yokoo, H. Nakaiwa,K.
Ogura, Y. Ooyama, and Y. Hayashi.
1997.
NihongoGoi Taikei (in Japanese).
Iwanami Shoten.Japan Electronic Dictionary Research Institute, Ltd. Japan,1995.
EDR Electronic Dictionary Technical Guide.M.
Kameyama.
1986.
A property-sharing constraint in cen-tering.
In Proceedings of the 24th ACL, pages 200?206.T.
Kudo and Y. Matsumoto.
2004.
A boosting algorithm forclassification of semi-structured text.
In Proceedings ofthe 2004 EMNLP, pages 301?308.S.
Lappin and H. J. Leass.
1994.
An algorithm forpronominal anaphora resolution.
Computational Linguis-tics, 20(4):535?561.A.
McCallum and B. Wellner.
2003.
Object consolidationby graph partitioning with a conditionally trained distancemetric.
In Proceedings of the KDD-2003 Workshop onData Cleaning, Record Linkage, and Object Consolida-tion, pages 19?24.J.
F. McCarthy and W. G. Lehnert.
1995.
Using decisiontrees for coreference resolution.
In Proceedings of the14th IJCAI, pages 1050?1055.R.
Mitkov.
1997.
Factors in anaphora resolution: theyare not the only things that matter.
a case study basedon two different approaches.
In Proceedings of theACL?97/EACL?97 Workshop on Operational Factors inPractical, Robust Anaphora Resolution.H.
Nakaiwa and S. Shirai.
1996.
Anaphora resolution ofjapanese zero pronouns with deictic reference.
In Pro-ceedings of the 16th COLING, pages 812?817.V.
Ng.
2004.
Learning noun phrase anaphoricity to improvecoreference resolution: Issues in representation and opti-mization.
In Proceedings of the 42nd ACL, pages 152?159.V.
Ng and C. Cardie.
2002a.
Improving machine learningapproaches to coreference resolution.
In Proceedings ofthe 40th ACL, pages 104?111.M.
Okumura and K. Tamura.
1996.
Zero pronoun resolu-tion in japanese discourse based on centering theory.
InProceedings of the 16th COLING, pages 871?876.M.
Poesio, O. Uryupina, R. Vieira, M. Alexandrov-Kabadjov,and R. Goulart.
2004.
Discourse-new detectors for defi-nite description resolution: A survey and a preliminaryproposal.
In Proceedings of the 42nd ACL Workshop onReference Resolution and its Applications, pages 47?54.K.
Seki, A. Fujii, and T. Ishikawa.
2002.
A probabilisticmethod for analyzing japanese anaphora integrating zeropronoun detection and resolution.
In Proceedings of the19th COLING, pages 911?917.W.
M. Soon, H. T. Ng, and D. C. Y. Lim.
2001.
A ma-chine learning approach to coreference resolution of nounphrases.
Computational Linguistics, 27(4):521?544.M.
Strube and C. Mu?ller.
2003.
A machine learning ap-proach to pronoun resolution in spoken dialogue.
In Pro-ceedings of the 41st ACL, pages 168?175.J.
Suzuki, T. Hirao, Y. Sasaki, and E. Maeda.
2003.
Hierar-chical directed acyclic graph kernel: Methods for struc-tured natural language data.
In Proceeding of the 41stACL, pages 32?39.V.
N. Vapnik.
1998.
Statistical Learning Theory.
Adaptiveand Learning Systems for Signal Processing Communica-tions, and control.
John Wiley & Sons.X.
Yang, G. Zhou, J. Su, and C. L. Tan.
2003.
Coreferenceresolution using competition learning approach.
In Pro-ceedings of the 41st ACL, pages 176?183.632
