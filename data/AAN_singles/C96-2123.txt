On the Structural Complexity of Natural  Language SentencesDekang L in*Art i f ic ia l  I ntcl l igcn cc I,a, bovatoryMa.ss~cclmsetts Insdtttt( ;  of : l~cttnologyl{m 7(57, 545 Techno logy  Square(~atnbridgc, Massac.husetts,  USA,  02\] 239E -maih  l indck~*ai .mit .eduAbstractThe objective of this pal)er is to \[brmal-ize the intuition al)out l,he comph;xityof syntactic structures.
We propose adefinition of structm:al COml)h'xity suchthat sentences ranked by our definitionas more COml)h;x are gen(;rally more diI'-ficult lbr humans to process.
We justifythe definition by showing how it is ahle toaccount for several seemingly unrelatedphenomena in natural anguages.1 IntroductionIntuitive\]y, certain syntactic structures arc uLoredifficult for htnnans to process thau others.
Forexample, compare the following to sentences:(1) a.
'Fhe cat that the dog that the manbought chased died.b.
The man bought the dog that chasedthe cat that died.It is ohvious that sentence (la.)
is much mor(' dif-ficult to understarld than (1 b).
Since the two sen-tences are of the same length an(l involve the sameset of semantic relationships, the ditliculty in rm-derstan(ling (1 a) can only be attributed to its syn-tactic structure.
'\['he objecl;ive of this pal)er is to fortnalize theintuition a.bout the complexity of syutactic stru(>tures.
We propose a detinition of s t ruc tura lcolnI)h~xil;y (SC) such thai; sentences ranked byour definition as more complex are generally moredifficult for humans to process than otherwise sim-ilar sentences, hi other words, suppose a pair ofsentences A arid B consist of the same set of wordsand have essentially the same meaning, then sen-tence A is more difficult to process than sentence1~ if SC(A)>SC(B).
For example, the proposeddetinition of structural complexity correctly pre-*On lea,re Dora the University of Manitoba., Win-nipeg, M~mitoba, (\]~tnmla.
This rt,.se,Lrch as 1)een sup-ported by NSli',II.
(\] ltcsearch (',rant OG1)121338.
Theauthor is very gr~teful to the reviewers who pointedoat several mistakes in the draft.dicts that (la) ix much more difficult to processthan (lb).
'I'll(: notiou of structural complexity proposedin this l)apc'r oilers explanations \['or a set of seem-iugly unrelated phenomena:?
We will show dlat the definition of structuralcomph:xity explains why a I)utch sentence in-volving cross-serial dependencies i sliglrdyeasier to underst~md than a correspondingcenl, er-embedded German sentence.?
We will also show that extrapositions, uch asheavy-NP shift and PP extractions are moti-vated by reducing syntactic omplexity.
Theextraposition of an element is only warrantedwhen the.
structural COml)lexity of the sen-I.en(:e is reduced as a result.?
NP ntodifiers of a head tend to be closer tothe head than its PP modifiers, which in turntend to be closer than its CP (clausal) modi-tiers.
In Generalized Phrase Strcuture Gram-mar ((~VS(~) (Gazd~u" ctal.
,  1985), these lin-ear order constraints are stated explicitly inthe gralIllnar.
The notion of structured com-plexity provides an explanatory account.
'l'here are several reasons why the notion ofstrHCtltl:a\] COml)lexity ix tlseful.
Firstly, in nat-ural language generation, a generator should get>era.re the simphest sentence that conveys the in-tended meanings.
Structural complexity can beused to choose l;he syntactic strnctures with l;helowest structural complexity so that the resultingsentence is easier to understand than other alter-natives.Secondly, structural complexity is also neededin assessing the readability of dommtents.
\[t iswell known that the length of a sentence is not, arelit~ble indicator of its readability.
Yet, the read-ability of texts has up to now heen measured bytlJe lengths of sentences and familiarities of th(:words in the documents.
Using structural com-plexity instead of sentence length allows the read-~fl)ility of documents to be measured tnorc accu-rately.Finally, we propose, in Section 4, that extrapo-sitions ~re rnotiw~ted by reduction of structural729complexity.
In other words, extrapositions areonly allowed if the structural complexity of tilesentence is reduced as a result.
This constraintis nsefnl both in parsing sentences with extrapo-sitions and in deciding where to use extrapositionduring generation.The notion of structural complexity is defined inSection 2.
We then justify the definition of struc-tural complexity by demonstrating in Sections 3,4, and 5 that sentences with lower structural com-plexity are easier to understand than otherwisesimilar sentences with higher structural complex-ity.2 Structural ComplexityThe definition of structural complexity presumesthe notion of dependency relationships betweenwords in a sentence.
In dependency grammars(Hudson, 1984; Mel'Suk, 1987), a dependency re-lationship is a primitive relationship between twowords, called the head  and the modi f ier .
Inconstituency grammars that contain the X-bartheory as a component, dependency relationshipsbetween words are implicitly specified in X-barstructures.
The modifiers of a word w are the headwords of the specifier, complements, and adjunctsof w. For example, Figure 1 is the X-bar struc-ture of (2).
The word "will" has two modifiers:the head word ()fits NP specifier ("Kinf ' )  and thehead word of its VP complement ("bring").
Thedependency relationships in tim X-bar structurein l!
'igure 1 are shown in Figure 2.
Each directedlink in Fignre 2 represents a dependency relation-ship with the direction going from the head to themodifier.
(2) Kim will bring the wine in the evening./%" /%Kim willvbringDET l 'the NwinePPin P / /~DET I 'the NFigure 1: X-bar structures of (2)evening31 1 2Kim will bring the wine in the eveningFigure 2: t)ependency structure of (2)In order to recognize the structure of a sentence,a parser must establish the dependency links be-tween the words in the sentence.
Structural com-plexity measures how easy or di\[\[icnlt i is to es-tablish these dependency links.
The definition ofstructural complexity is based on the assumptionthat the shorter dependency links are easier to es--tablish than longer ones, where the length of adependency link is one plns the nmnber of wordsbetween the head and the moditier.
I:or e.xample,the lengths of tile links in Figure 2 are shown bythe numbers attached to the dependency links.Def in i t ion  2.1 (S t ruetura l  Complex i ty )The slructural complexity of a dependency struc-lure is the total length of the dependency links inthe structure.For example the structural complexity of the de-pendency structure in Figure 2 is 11.\[n the next three sections, we will show thatthe definition of structural comph'.xity does i,-deed retlect the difficulty in processing a sentence.We will present examples in which sentences withlower structural complexities are easier to processthan similar sentences with higher structural com-ph;xities.3 Center  embedd ingThe difficulty in processing center embedding sen-ten('es: such as (13), hgs been explained by itsrequirement on the size of tile stack in a parsb, r.This explanation presumes that the human parseruses a push-down stack to store the partially builtconstituents.
'l'he notion of structural complex-ity provides an explanation of the difficulty ofprocessing center embedding that makes muchweaker commitment to the parsing model.
Fig-ure 3 shows the lengths of the dependency linksin a center-embedding sentence (la) and a non-center-embedding sentence (lb) with similar se-mantics.
The structural complexity of the center-embedding sentence is 30, which is much higherthan the structurM complexity (=112) of the non-center-embedding sentence.The presumption that human sentence pro-cessor uses a push-down sl;ack is challenged bythe contrast between cross-serial dependencies inDutch (e.g., Figure 4a) and center-embedding sen-tences in German (e.g., Figm:e 4b.
)Since the cross serial dependencies are muchmore ditficnlt to handle with push-down stacks730n;I" F7 Lr ill1~1 r-?l?-I u \ ]The cat that the dog that the man bought chased diedThe man bought the dog that chased the cat that diedFigure 3: (\]ent,er-l,\]lnlmdding vs. Not-(,elt.e.l-(hire th;m their English couvd,erpm'l;s" (p.
249).
'I'his is also consistent with the sl.ru(;1;ural (:()lll-Iflexity account, since the structur3l comtJexity ofI:igurc 4c is 9, whic.h is signili('nntly lower t:hmi itsDutch a, ml (;c;rman connterl)iU'l,s (l"igure 43 an(l4l))i4 Ext rapos i t ionsl,\]xl,ra, l)osil:ion I'e\[~l'S l,O i,he lllOVetllell\[, Of ~Ill eleinenl; \['roill il,s ,ov'nml i)ositio\]l t,o a I)osii,iotl 3t, orl le3r Iihe end  of  l,tle senl,ellC(', l'\]xa\[I\]l)l(ts o\[  extr~t.1)osition in I",nglish in,:;lu(h<l!hnlw.
(hling Sentences.
.
.
.
.
.
.
Ihmvy-NP  shi f tDe manne hebben Hans de paarden leren voerenThe man have Hans the horses teach feeda.
1)utch: cross serial dependency, shuctuml complexity= 13Die Maenner haben Hans die Pferde fuettern gelehrtThe men have Hans the horses feed teachb.
Gennan: center embedding, structural complcxily=14The men taught Hans to feed the horsesc.
English: right branching, slmclural complexity=9I"igure 4: cross s(;ri31 dependency vs. ceni.er(3) a .
.
Ioc  sent \]12(; Izook he found in I)a.ris /ohis palb.
Joe sent :o his palI, he book lie found in I)3risF, xtral)oS(~.d re la t ive(4) a.
A m3n I;h31; no one knew slood 'uph.
A nr, m slood "up tihal\] I10 Olle klleWI~P-( , ,xtral)osit ion(5) a. I Feaid a. dcscril)tionof l lockncy's lal,csi, l>ic(.ur(~ !lcslcrdayb.
1 read a descril)t,ion ycslerdayof IIo(k I(y s hi test F, icl,urelgxl;ra('l;ion f rom AP(6) a.. \[low cerl,ain that the, Me~s will wi ,  arc:q o 'u '?h.
I Iow certa iu a'rc '!lO~ttlmt the Mets will wi.
?Me('hanislll for constraining exl iraposi i i iOl l  iS Ill'-gently ,ee(h'xl i, both parsing 3nd g~encr3l.ioll.
'1'0et),lm(l(ling .
.
.
.
.
.
.
.
.
.
.
vs. right.-i~ra.nchillg \[ihc I)CStl of the ;ulthor's I~nowhe(lge, noue of (.Irathan nested dependeucies, the hypothesis th3t hu-m3n parsex uses a, push-down sta,'k would pre-dict th3t the I)utch sentences ttch as Figure 43shotlld be much lilt)re ditli(:ult (IC) underst3nd thanthe correslmnding (.
lerl lt3II setlLeil('es with IleSl;ec\[(lepende~ncies (Figure 4b).
Itowever, da.ta frompsycho-linguistic experinlenl;s uggest (;h3t the, ya,re in fact slightly easier to proce.ss than the cor-responding (;erm3n senl;ent-cs with nested de, pen-dencics (B3ch et 31., 1986).
This obserw~,tion canbe 3('counted \[or l)y structur31 complexity, sincethe sl;ru('tur31 comt)lcxity of the I)ut,ch sentence(Figure 4&) is 13, which is slightly lower tha,n Lhcstructur31 complexity (=14) of the correspollding(~ernl3II senl.
(:tlce I:'igurc 411.
It was 31so el)servedin (Bach et el., 1!
)86) that "For someone with (weu3 limited competence in English 3nd either of theother langu3ges, the p3tterns in l)utch and Ger-m3n seem to be more difficult to process 3nd pro-I)road coverage parse.rs or ~ener3l,ors h3\[IdIes ex-~P \[~ \[~Pt) ( $1 ~ I ()\] ~ 1 ~ \] ~I I~rincil4e.d fash ioh .
The  reason('OF this iS that exlii'a,i)osil;iOllS 3I l l )ear  tO be depen-dent upon ccrt3in ast)ects of (:ontcxts thi{t 3re notcN)l;ured by usual synt~wtic fe3t;ures.
For exam-t>le, compare the following 1)3Jr of sentences(7) a, I (,alked wi(;h a, m3n yesh:rda,!lwith a must3cheb.
*l l,alked with a, ma, n one year  and fo'~ur'monihs ago wiiJi a tnjhsbw.hqThe syuta, ctic struct,,,'es of (7a)3,,,I (7B)are th,,s3me, which is shown in I:igure 5, except Iiha,\[i t)he3dwa:bial phrase Advl ) is "yesterday" in (7a) a, ml"one year a,.d four months 3go" in (71)).
Althoughthe two adw;rt)i31 phra,ses m'c two different stri .gs,ILihey a, re identical in their syntactic (~/.lltll'{~s I Yet.,extr31)osition is good in (73) but b3d in (7b).We propose~ th3t the lmrposc of extr31)osition isto m3ke 3 sentence easier to mlderst3nd.
There-|'ore, ext, r3posil&m is only allowed when the struc-tural comph~xity of l;he S(Hll;ellCe is reduced 3s a re-still;.
Note 1,}131, reduct ion of structuraJ c()mtJexityis not l, he only const, r3int on cxtr3position.
'\['here731jlp~NP ~ ~ _ _l PPV PP with mustachetalkedto a manFigure 5: Parse tree of (7a) and (7b)are also syntactic constrains uch as Right RoofCondition (Ross, 1967) or Complement Principle(Rochemont and Culicover, 1990).When a phrase is extraposed, the set of depen-dency relationships remains the same.
However,the lengths of some of the dependency links willchange.
The structural complexity of the sentencemay change as a result.
Figure 6 illustrates howextrapositions atlhct the lengths of dependencylinks is, (3), (4), (5), and (6).
Only the depen-dency links whose lengths are changed are shownthere.
In all cases, structural complexity is re-duced by the extraposition.Consider the difference between (7a) and (7b).In (7a), the extraposition of \ [pp with a mustache\]increases the length of the dependency link be-tween "man" and "with" by 1, but reduces thelength of the dependency between "talked" and"yesterday" by 3.
Therefore, the structural com-plexity is reduced by 2 as a result of the extrapo-sit,on.
In contrast, in (Tb), the extraposition of\[pp with a mustache\] increases tile length of thedependency link between "man" and "with" by 6and reduces the length of the dependency link be-tween "talk" and "ago" by 3.
Thus the structuralcomplexity is increased when \[Pe with a mustache\]is extraposed.The hypothesis that extraposition must reducethe structural complexity also explains why inheavy-NP shift, the extraposed NP must be heavy,i.e., consisting of many words.
When the comple-ment Nil ) of a verb is 'shifted' to the right across anadjunct modifier of the verb, the length of the de-pendency link from the verb to tile head of the NPis increased by length the adjunct modifier.
Onthe other hand, the length of the dependency linkfi'om the verb to the adjunct modifier is reducedby the length of the NP.
Theretbre, the structuralcomplexity of the sentence can only be reduced asa result of the extraposition when the NP is longerthan the adjunct modifier,Joe sent the book he found in Paris to his palJoe sent to his pal the book he found in Paris(a) Heavy-NP shift, SC reduction = (7+2)-(5+1) = 3A man that no one knew stood upA man stood up that no one knew(b) Exuaposcd relative clause, SC reduction=(5+l)-(3+l)=2I 7 ~ }I read a description of Hockney's latest picture yesterdayI read a description yesterday of Hockney's latest picture(c) PP-extraposition, SC reduction=(7+l)-(4+2)=2How certain that the Mats will win are youHow certain are you that the Mats will win(d) Extraction fl'om AP, SC reduction=(6+ 1 )-(3+ 1)=3Figure 6: Extraposition must reduce structuralcomplexity5 L inear  P recedenceIn most languages, the NP modifiers of a wordtend to be <;loser to the word than it, s PP rood,-tiers, which, in turn, tend to be closer to the wordthan its CP (clansal) modifiers.
In GPSG (Gaz-dar et al, 1985), these lineal: order constraints arestated explicitly as the linear precedence rules.
Inthis section, we show thai; the linear precedencerules in GPSG can be derived fl'om the assump-tion that the linear order among different typesof modifying phrases, such as NP, PP, and CP,should minimize the structural complexity so thatthe sentence is as easy to process as possible.Suppose a word w has n modifiers XP:I, XP~,..., XP,  ; the number of words in XPi is li; mM thehead word of XP i  is wi, which is the pi'th wordin XPi.
Without loss of generality, let us assumethat w precedes its modifiers.
\[f the order of themodifiers is XP1, XPu, ..., XP,;, then the lengthof the dependency link between w and the headof XPi is (Pi + 2j-:tl lj) and the total length ofdependency links within tile maximal projection732of w is:-,~ \-, i- t lj \] )~,~i=l (Pi -1- L , j=I  /=: (.
:-l)lt + ( , , .
-  U)l  + .
.
.+ l  .... , +Among a l l  \ ] )er t \ ] l l t t ;a l ; io f l s  Of XP  I , N i t2 ,  ..., Xl; '  ....t;hc al>ove sum is tit<'+ minitnal when 11 <_ 12 <_ ... <In.
In ol, her words, the total h',ngt;h of dCl)cnden<:ylinks is minilnal when tit<'+ modifiers with I'ewerwords are <:loser to the h(;ad.
(Icnerally spealdng,PPs contain more wor<ls than NPs and Cl)s con:rain more  words than  l.)Ps.
Therefor('., Nt  ) mod-i\[iers shouhl b<; closer 1,o t, he \]mad word t, han 1)1 >moditiers and t)l ) modifiers shoul<l be closer Lot;h(" head word t.han CI ) mo(li\[i(ws i f  l;hc sl;ru<:l, uralcomph'.xity of tim ma.xinml pl:ojec@tu of the.
\]madword w is to be minimized.6 D iscuss ionWe used the total length of the dci>endency linksin the definition of structural complexil,y.
The ex-amples ltresented in the previous sect, ions are alsoconsistent w:ith a definition l;hat uses the inaxi-mum length of structural  links.
The reasotL wechoose to use the stnrt is that the definition natu-rally incorporate the length into consi<lcration.
'I'hc arguments presented in previous s(;<:l;ionsarc preliminary.
Our riga,re work inchldc backingup th('~ hypothesis with (;mph'ical cvidc.n<:e and in-vest;igate the application of structtn'al complcxil,yin handling extraposit ion in parsing and genera-lion.7 Conc lus ionWe have proposed a notion of stru<'tural cotuph',x-ity+ A senten<'e with higher st, ructural cOral>It+x-ity is more dif\[icult I,o process than a similar set>tences with lower structural  complexity.
Struc-tural coruph'+xity is needed in both l>arsing a.ndgeneral;ion.
\[t can also be used to a.sscss tl,e read-ability of <locument;s. W<: supl>ort l,hc d('\[init;ion ofstru<:t, ural ('.omph~xity wil.h a sel, of se<>mingly un-relate<| phenomena: the contrast hcl, wcen center--embedding and right-branching sentences, ('.xt;ra-i>ositions, and the linear order among modifyingl>hrases.
\[in all of these cases, sentcnc(;s with lowerstructural  complexity arc easier to mtdcrstand.l{i<:lmr<l ludson.
1984.
Word Crammar.
Basill~lackw(;ll l)ublishers \[fruit;cal., Oxfor(1, Eng-land.Igor A. Mcl'Suk.
1987. l)cpc.ndency .synlax: the-ory and practice.
Sl;al;c Univ<;rsity o\[' New YorkPress, Albany.Michael S. ILochcmont and P('~t(',r W. (\]ulicovcr.1990.
l','nglish I"ocu,~ Constructions a'n.d theTheory of Grammar.
Camblfidge Studies in Lin-guistics.
Cambridge Univcrsit, y Press.J.
I(,()ss.
1967.
Constraints on.
variables in synla,.I 'h.I).
thesis, M.\[.
'I'., Canal>ridge, MA.ReferencesE.
Bach, C. l{rown, an<\[ W. Marslen-Wilson.1986.
(5 ossed and nested d(;pemlencies in (,e~-ma.n and I)utch: A psycholinguistic, stmdy.
Lan-guage and Cognilive l>rocesscs, 1(4):249 262."
( ( + Gerald Gtz la t ,  Ewan Klein, G',oflcly l'ulhm:hand Ivan Sag.
1985.
(~cneralizcd Ph.r'aisc ,%'lruc-ture Grammar.
Basil Blackwell Publisher Lt,(\[,Oxibrd, UK.733
