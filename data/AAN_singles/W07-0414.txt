Proceedings of SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation, pages 103?110,Rochester, New York, April 2007. c?2007 Association for Computational LinguisticsComparing Reordering Constraints for SMTUsing Efficient BLEU Oracle ComputationMarkus Dreyer, Keith Hall, and Sanjeev KhudanpurCenter for Language and Speech ProcessingJohns Hopkins University3400 North Charles Street, Baltimore, MD 21218 USA{dreyer,keith hall,khudanpur}@jhu.eduAbstractThis paper describes a new method tocompare reordering constraints for Statis-tical Machine Translation.
We investi-gate the best possible (oracle) BLEU scoreachievable under different reordering con-straints.
Using dynamic programming, weefficiently find a reordering that approxi-mates the highest attainable BLEU scoregiven a reference and a set of reorderingconstraints.
We present an empirical eval-uation of popular reordering constraints:local constraints, the IBM constraints,and the Inversion Transduction Grammar(ITG) constraints.
We present results for aGerman-English translation task and showthat reordering under the ITG constraintscan improve over the baseline by morethan 7.5 BLEU points.1 IntroductionReordering the words and phrases of a foreign sen-tence to obtain the target word order is a fundamen-tal, and potentially the hardest, problem in machinetranslation.
The search space for all possible per-mutations of a sentence is factorial in the numberof words/phrases; therefore a variety of models havebeen proposed that constrain the set of possible per-mutations by allowing certain reorderings while dis-allowing others.
Some models (Brown et al (1996),Kumar and Byrne (2005)) allow words to changeplace with their local neighbors, but disallow globalreorderings.
Other models (Wu (1997), Xiong et al(2006)) explicitly allow global reorderings, but donot allow all possible permutations, including somelocal permutations.We present a novel technique to compare achiev-able translation accuracies under different reorder-ing constraints.
While earlier work has trained andtested instantiations of different reordering modelsand then compared the translation results (Zens andNey, 2003) we provide a more general mechanismto evaluate the potential efficacy of reordering con-straints, independent of specific training paradigms.Our technique attempts to answer the question:What is the highest BLEU score that a given trans-lation system could reach when using reorderingconstraints X?
Using this oracle approach, we ab-stract away from issues that are not inherent in thereordering constraints, but may nevertheless influ-ence the comparison results, such as model and fea-ture design, feature selection, or parameter estima-tion.
In fact, we compare several sets of reorder-ing constraints empirically, but do not train them asmodels.
We merely decode by efficiently search-ing over possible translations allowed by each modeland choosing the reordering that achieves the high-est BLEU score.We start by introducing popular reordering con-straints (Section 2).
Then, we present dynamic-programming algorithms that find the highest-scoring permutations of sentences under given re-ordering constraints (Section 3).
We use this tech-nique to compare several reordering constraints em-pirically.
We combine a basic translation frameworkwith different reordering constraints (Section 4) and103present results on a German-English translation task(Section 5).
Finally, we offer an analysis of theresults and provide a review of related work (Sec-tions 6?8).2 Reordering ConstraintsReordering constraints restrict the movement ofwords or phrases in order to reach or approximatethe word order of the target language.
Some ofthe constraints considered in this paper were origi-nally proposed for reordering words, but we will de-scribe all constraints in terms of reordering phrases.Phrases are units of consecutive words read off aphrase translation table.2.1 Local ConstraintsLocal constraints allow phrases to swap with oneanother only if they are adjacent or very close toeach other.
Kumar and Byrne (2005) define twolocal reordering models for their Translation Tem-plate Model (TTM): In the first one, called MJ-1,only adjacent phrases are allowed to swap, and themovement has to be done within a window of 2.
Asequence consisting of three phrases abc can there-fore become acb or bac, but not cba.
One phrasecan jump at most one phrase ahead and cannot takepart in more than one swap.
In their second strategy,called MJ-2, phrases are allowed to swap with theirimmediate neighbor or with the phrase next to theimmediate neighbor; the maximum jump length is 2.This allows for all six possible permutations of abc.The movement here has to take place within a win-dow of 3 phrases.
Therefore, a four-phrase sequenceabcd cannot be reordered to cadb, for example.
MJ-1 and MJ-2 are shown in Figure 1.2.2 IBM ConstraintsFirst introduced by Brown et al (1996), the IBMconstraints are among the most well-known andmost widely used reordering paradigms.
Transla-tion is done from the beginning of the sentence tothe end, phrase by phrase; at each point in time, theconstraints allow one of the first k still untranslatedphrases to be selected for translation (see Figure 1d,for k=2).
The IBM constraints are much less restric-tive than local constraints.
The first word of the in-put, for example, can move all the way to the end,independent of the value of k. Typically, k is set to4 (Zens and Ney, 2003).
We write IBM with k=4 asIBM(4).
The IBM constraints are supersets of thelocal constraints.01if2you3to-me4that5explain6could(a) The sentence in foreign word order.03you1if4if you2to-me5to-me7that you8that6explainto-me9explain10could that11couldexplain(b) MJ-108you6to-me1if9if60to-me you7ifyou3that2to-me15to-me12that10explain4to-me5you youthat17that19could16explainyouto-me18explain21couldif youto-me13explainthat11to-meto-methat22could20explainthatthat couldthatexplain(c) MJ-206you1if7if11to-me you2to-me12to-me8that you3that16that13explain you4explain19explain17could you5could21could youif15thatto-me9explainto-me10couldto-meif18explainthat60couldthatif20couldexplainif(d) IBM(2)Figure 1: The German word order if you to-me that explaincould (?wenn Sie mir das erkla?ren ko?nnten?)
and all possiblereorderings under different constraints, represented as lattices.None of these lattices contains the correct English order if youcould explain that to-me.
See also Table 1.2.3 ITG ConstraintsThe Inversion Transduction Grammar (ITG) (Wu,1997), a derivative of the Syntax Directed Trans-duction Grammars (Aho and Ullman, 1972), con-strains the possible permutations of the input stringby defining rewrite rules that indicate permutationsof the string.
In particular, the ITG allows all per-mutations defined by all binary branching struc-tures where the children of any constituent may beswapped in order.
The ITG constraint is differentfrom the other reordering constraints presented inthat it is not based on finite-state operations.
An104Model # perm.
?Best?
sentence n-gram precisions BLEUMJ-1 13 if you that to-me could explain 100.0/66.7/20.0/0.0 0.0MJ-2 52 to-me if you could explain that 100.0/83.3/60.0/50.0 70.71IBM(2) 32 if to-me that you could explain 100.0/50.0/20.0/0.0 0.0IBM(4) 384 if you could explain that to-me 100.0/100.0/100.0/100.0 100.0IBM(4) (prune) 42 if you could explain that to-me 100.0/100.0/100.0/100.0 100.0ITG 394 if you could explain that to-me 100.0/100.0/100.0/100.0 100.0ITG (prune) 78 if you could explain that to-me 100.0/100.0/100.0/100.0 100.0Table 1: Illustrating example: The number of permutations (# perm.)
that different reordering paradigms consider for the inputsequence if you to-me that explain could, and the permutation with highest BLEU score.
The sentence length is 7, but there areonly 6!
possible permutations, since the phrase to-me counts as one word during reordering.
ITG (prune) is the ITG BLEU decoderwith the pruning settings we used in our experiments (beam threshold 10?4).
For comparison, IBM(4) (prune) is the latticeBLEU decoder with the same pruning settings, but we use pruning only for ITG permutations in our experiments.Figure 2: The example ifyou to-me that explain couldand its reordering to if youcould explain that to-me us-ing an ITG.
The alignmentsare added below the tree, andthe horizontal bars in the treeindicate a swap.ITG decoder runs in polynomial time and allows forlong-distance phrasal reordering.
A phrase can, forexample, move from the first position in the inputto the last position in the output and vice versa, byswapping the topmost node in the constructed bi-nary tree.
However, due to the binary bracketingconstraint, some permutations are not modeled.
Afour-phrase sequence abcd cannot be permuted intocadb or bdac.
Therefore, the ITG constraints are notsupersets of the IBM constraints.
IBM(4), for exam-ple, allows abcd to be permuted into cadb and bdac.3 Factored BLEU ComputationThe different reordering strategies described allowfor different permutations and restrict the searchspace in different ways.
We are concerned withthe maximal achievable accuracy under given con-straints, independent of feature design or parameterestimation.
This is what we call the oracle accuracyunder the reordering constraints and it is computedon a dataset with reference translations.We now describe algorithms that can be usedto find such oracle translations among unreorderedtranslation candidates.
There are two equivalentstrategies: The reordering constraints that are be-ing tested can be expressed as a special dynamic-programming decoder which, when applied to anunreordered hypothesis, searches the space of per-mutations defined by the reordering constraints andreturns the highest-scoring permutation.
We employthis strategy for the ITG reorderings (Section 3.2).For the other reordering constraints, we employ amore generic strategy: Given the set of reorder-ing constraints, all permutations of an unreorderedtranslation candidate are precomputed and explicitlyrepresented as a lattice.
This lattice is passed as in-put to a Dijkstra-style decoder (Section 3.1) whichtraverses it and finds the solution that reachest thehighest BLEU score.13.1 Dijkstra BLEU DecoderThe Dijkstra-style decoder takes as input a lattice inwhich each path represents one possible permutationof an unreordered hypothesis under a given reorder-ing paradigm, as in Figure 1.
It traverses the lat-tice and finds the solution that has the highest ap-proximate BLEU score, given the reference.
Thedynamic-programming algorithm divides the prob-lem into subproblems that are solved independently,the solutions of which contribute to the solutionsof other subproblems.
The general procedure issketched in Figure 3: for each subpath of the lat-tice containing the precomputed permutations, westore the three most recently attached words (Fig-1For both strategies, several unreordered translation candi-dates do not have to be regarded separately, but can be repre-sented as a weighted lattice and be used as input to the specialdynamic program or to the process that precomputes possiblepermutations.105?
([0, k, len + 1, w2, w3, wnew]) = maxw1( get bleu ( [0, j, len, w1, w2, w3], [j, k, wnew] ) ) (1)function get bleu ( [0, j, len, w1, w2, w3], [j, k, wnew] ) :=update ngrams (0, j, k, len, w1, w2, w3, wnew) ;return exp(144?n=1log(ngramsi([0, k, len + 1, w2, w3, wnew])len ?
n + 1));(2)Figure 3: Top: The BLEU score is used as inside score for a subpath from 0 to k with the rightmost words w2, w3, wnew in theDijkstra decoder.
Bottom: Pseudo code for a function get bleu which updates the n-gram matches ngrams1(.
.
.
), ngrams2(.
.
.
),ngrams3(.
.
.
), ngrams4(.
.
. )
for the resulting subpath in a hash table [0, k, len + 1, w2, w3, wnew] and returns its approximateBLEU score.
("","","")0/0/0/0("","to","me")2/1/0/0("to","me","if")3/1/0/0("me","if","you")4/2/0/0("if","you","could")5/3/1/0("you","could","explain")6/4/2/1("could","explain","that")7/5/3/206to-me if you7if you15you19could thatexplain20explainthat22thatFigure 4: Three right-most words and n-gram matches: This shows the best path for the MJ-2 reordering of if you to-me thatexplain could, along with the words stored at each state and the progressively updated n-gram matches.
The full path to-me if youcould explain that has 7 unigram matches, 5 bigram, 3 trigram, and 2 fourgram matches.
See the full MJ-2 lattice in Figure 1c.ure 4).
A context of three words is needed to com-pute fourgram precisions used in the BLEU score.Starting from the start state, we recursively extenda subpath word by word, following the paths inthe lattice.
Whenever we extend the path by aword to the right we incorporate that word and useupdate ngrams to update the four n-gram countsfor the subpath.
The function update ngrams hasaccess to the reference string2 and stores the updatedn-gram counts for the resulting path in a hash table.3The inside score of each subpath is the approximateBLEU score, calculated as the average of the fourn-gram log precisions.
An n-gram precision is al-ways the number of n-gram matches divided by thelength len of the path minus (n ?
1).
A path oflength 4 with 2 bigram matches, for example, hasa bigram precision of 2/3.
This method is similar toDijkstra?s algorithm (Dijkstra, 1959) composed witha fourgram finite-state language model, where thescoring is done using n-gram counts and precision2Multiple reference strings can be used if available.3An epsilon value of 1?10 is used for zero precisions.scores.
We call this the Dijkstra BLEU decoder.3.2 ITG BLEU DecoderFor the ITG reordering constraints, we use a dy-namic program that computes the permutations im-plicitly.
It takes only the unreordered hypothesisas input and creates the possible reorderings underthe ITG constraints during decoding, as it createsa parse chart.
The algorithm is similar to a CKYparsing algorithm in that it proceeds bottom-up andcombines smaller constituents into larger ones re-cursively.
Figure 5 contains details of the algo-rithm.
The ITG BLEU decoder stores the three left-most and the three rightmost words in each con-stituent.
A constituent from position i to posi-tion k, with wa, wb, and wc as leftmost words,and wx, wy, wz as rightmost words is written as[i, k, (wa, wb, wc), (wx, wy, wz)].
Such a constituentcan be built by straight or inverted rules.
Using aninverted rule means swapping the order of the chil-dren in the built constituent.
The successive bottom-up combinations of adjacent constituents result in hi-erarchical binary bracketing with swapped and non-106?
([i, k, (wa, wb, wc), (wx, wy, wz)]) = max(?
() ([i, k, (wa, wb, wc), (wx, wy, wz)]) ,?<> ([i, k, (wa, wb, wc), (wx, wy, wz)]))(3)?<>([i, k, (wa, wb, wc), (wx, wy, wz)]) =maxj,wa?
,wb?
,wc?
,wx?
,wy?
,wz?
(get bleu( [j, k, (wa, wb, wc), (wx?
, wy?
, wz?
)],[i, j, (wa?
, wb?
, wc?
), (wx, wy, wz)]) ) (4)Figure 5: Equations for the ITG oracle BLEU decoder.
[i, k, (wa, wb, wc), (wx, wy, wz)] is a constituent from i to k with leftmostwords wa,wb,wc and rightmost words wx,wy ,wz .
Top: A constituent can be built with a straight or a swapped rule.
Bottom: Aswapped rule.
The get bleu function can be adapted from Figure 3swapped constituents.
Our ITG BLEU decoder usesstandard beam search pruning.
As in Zens and Ney(2003), phrases are not broken up, but every phraseis, at the beginning of reordering, stored in the chartas one lexical token together with the precomputedn-gram matches and the n-gram precision score.In addition to standard ITG we run experimentswith a constrained ITG, in which we impose a bound?
on the maximum length of reordered constituents,measured in phrases.
If the combined length of twoconstituents exceeds this bound they can only becombined in the given monotone order.
Experimentswith this ITG variant give insight into the effect thatvarious long-distance reorderings have on the finalBLEU scores (see Table 3).
Such bounds are alsoeffective speedup techniques(Eisner and Tromble,2006).3.3 BLEU ApproximationsBLEU is defined to use the modified n-gram preci-sion, which means that a correct n-gram that oc-curs once in the reference, but several times in thesystem translation will be counted only once ascorrect.
The other occurrences are clipped.
Wedo not include this global feature since we wanta dynamic-programming solution with polynomialsize and runtime.
The decoder processes subprob-lems independently; words are attached locally andstored only as boundary words of covered paths/constituents.
Therefore we cannot discount a locallyattached word that has already been attached else-where to an alternative path/constituent.
However,clipping affects most heavily the unigram scoreswhich are constant, like the length of the sentence.44Since the sentence lengths are constant for all reorderingsof a given sentence we can in our experiments also ignore thebrevity penalty which cancels out.
If the input consists of sev-We also adopt the approximation that treats everysentence with its reference as a separate corpus (Till-mann and Zhang, 2006) so that ngram counts are notaccumulated, and parallel processing of sentencesbecomes possible.
Due to these two approximations,our method is not guaranteed to find the best reorder-ing defined by the reordering constraints.
However,we have found on our heldout data that an oraclethat does not accumulate n-gram counts is only min-imally worse than an oracle that does accumulatethem (up to 0.25 BLEU points).5 If, in addition,clipping is ignored, the resulting oracle stays virtu-ally the same, at most 0.02 BLEU points worse thanthe oracle found otherwise.
All results in this paperare computed with the original BLEU formula on thesentences found by the oracle algorithms.4 Creating a Monotone TranslationBaselineTo compare the reordering constraints under ora-cle conditions we first obtain unreordered candi-date translations from a simple baseline translationmodel.
For each reordering paradigm, we take thecandidate translations, get the best oracle reorder-ings under the given reordering constraints and pickthe best sentence according to the BLEU score.The baseline translation system is created usingprobabilistic word-to-word and phrase-to-phrase ta-eral sentences of different lengths (see fn.
1) then the brevitypenalty can be built in by keeping track of length ratios of at-tached phrases.5The accumulating oracle algorithm makes a greedy deci-sion for every sentence given the ngram counts so far accumu-lated (Zens and Ney, 2005).
The result of such a greedy or-acle method may depend on the order of the input sentences.We tried 100 shuffles of these and received 100 very simi-lar results, with a variance of under 0.006 BLEU points.
Thenon-accumulating oracles use an epsilon value (1?10) for zerocounts.107bles.
Using the translation probabilities, we createa lattice that contains word and phrase translationsfor every substring of the source sentence.
The re-sulting lattice is made of English words and phrasesof different lengths.
Every word or phrase transla-tion probability p is a mixture of p(f |e) and p(e|f).We discard short phrase translations exponentiallyby a parameter that is trained on heldout data.
Inser-tions and deletions are handled exclusively by theuse of a phrase table: an insertion takes place wher-ever the English side of a phrase translation is longerthan the foreign side (e.g.
English presidential can-didate for German Pra?sidentschaftskandidat), andvice versa for deletions (e.g.
we discussed for wirhaben diskutiert).
Gaps or discontinuous phrasesare not handled.
The baseline decoder outputs then-best paths through the lattice according to the lat-tice scores6, marking consecutive phrases so that theoracle reordering algorithms can recognize them andkeep them together.
Note that the baseline system istrained on real data, while the reordering constraintsthat we want to test are not trained.5 Empirical Comparison of ReorderingConstraintsWe use the monotone translation baseline model andthe oracle BLEU computation to evaluate differentpopular reordering strategies.
We now describe theexperimental settings.
The word and phrase transla-tion probabilities of the baseline model are trainedon the Europarl German-English training set, usingGIZA++ and the Pharaoh phrase extraction algo-rithm.
For testing we use the NAACL 2006 SMTShared Task test data.
For each sentence of the testset, a lattice is created in the way described in Sec-tion 4, with parameters optimized on a small heldoutset.7 For each sentence, the 1000-best candidates ac-cording to the lattice scores are extracted.
We takethe 10-best oracle candidates, according to the ref-erence, and use a BLEU decoder to create the bestpermutation of each of them and pick the best one.Using this procedure, we make sure that we get thehighest-scoring unreordered candidates and choosethe best one among their oracle reorderings.
Table 26We use a straightforward adaption of Algorithm 3 in Huangand Chiang (2005)7We fill the initial phrase and word lattice with the 20 bestcandidates, using phrases of 3 or less words.and Figure 6 show the resulting BLEU scores for dif-ferent sentence lengths.
Table 3 shows results of theITG runs with different length bounds ?.
The aver-age phrase length in the candidate translations of thetest set is 1.42 words.Oracle decodings under the ITG and underIBM(4) constraints were up to 1000 times slowerthan under the other tested oracle reordering meth-ods in our implementations.
Among the faster meth-ods, decoding under MJ-2 constraints was up to 40%faster than under IBM(2) constraints in our imple-mentation.202530354045  510152025303540BLEUSentence lengthITGIBM,k=4IBM,k=2 MJ-2 MJ-1 BaselineFigure 6: Reordering oracle scores for different sentencelengths.
See also Table 2.6 DiscussionThe empirical results show that reordering un-der sufficiently permissive constraints can improvea monotone baseline oracle by more than 7.5BLEU points.
This gap between choosing the bestunreordered sentences versus choosing the best op-timally reordered sentences is small for short sen-tences and widens dramatically (more than nineBLEU points) for longer sentences.The ITG constraints and the IBM(4) constraintsboth give very high oracle translation accuracies onthe German-English translation task.
Overall, theirBLEU scores are about 2 to more than 4 points bet-ter than the BLEU scores of the best other meth-ods.
This gap between the two highest-scoring con-straints and the other methods becomes bigger asthe sentence lengths grow and is greater than 4108Sentence length# oftestsentencesBLEU (NIST) scoresITG (prune) IBM, k=4 IBM, k=2 MJ-2 MJ-1 No reordering1?5 61 48.21 (5.35) 48.21 (5.35) 48.21 (5.35) 48.21 (5.35) 48.21 (5.35) 48.17 (5.68)6?10 230 43.83 (6.75) 43.71 (6.74) 41.94 (6.68) 42.50 (6.71) 40.85 (6.66) 39.21 (6.99)11?15 440 33.66 (6.71) 33.37 (6.71) 31.23 (6.62) 31.49 (6.64) 29.67 (6.56) 28.21 (6.76)16?20 447 30.47 (6.66) 29.99 (6.65) 27.00 (6.52) 27.06 (6.50) 25.15 (6.45) 23.34 (6.52)21?25 454 30.13 (6.80) 29.83 (6.79) 27.21 (6.67) 27.22 (6.65) 25.46 (6.58) 23.32 (6.63)26?30 399 26.85 (6.42) 26.36 (6.42) 22.79 (6.25) 22.47 (6.22) 20.38 (6.12) 18.31 (6.11)31?35 298 28.11 (6.45) 27.47 (6.43) 23.79 (6.25) 23.28 (6.21) 21.09 (6.12) 18.94 (6.06)36?40 242 27.65 (6.37) 26.97 (6.35) 23.31 (6.19) 22.73 (6.16) 20.70 (6.06) 18.22 (5.94)1?40 2571 29.63 (7.48) 29.17 (7.46) 26.07 (7.24) 25.89 (7.22) 23.95 (7.08) 21.89 (7.07)Table 2: BLEU and NIST results for different reordering methods on binned sentence lengths.
The ITG results are, unlike theother results, with pruning (beam 10?4).
The BLEU results are plotted in Figure 6.
All results are computed with the originalBLEU formula on the sentences found by the oracle algorithms.BLEU scores for sentences longer than 30 sentences.This advantage in translation accuracy comes withhigh computational cost, as mentioned above.Among the computationally more lightweight re-ordering methods tested, IBM(2) and MJ-2 are veryclose to each other in translation accuracy, withIBM(2) obtaining slightly better scores on longersentences, while MJ-2 is more efficient.
MJ-1 isless successful in reordering, improving the mono-tone baseline by only about 2.5 BLEU points at best,but is the best choice if speed is an issue.As described above, the reorderings defined bythe local constraints MJ-1 and MJ-2 are subsets ofIBM(2) and IBM(3).
We did not test IBM(3), butthe values can be interpolated between IBM(2) andIBM(4).
The ITG constraints do not belong in thisfamily of finite-state contraints; they allow reorder-ings that none of the other methods allow, and viceversa.
The fact that ITG constraints can reach suchhigh translation accuracies supports the findings inZens et al (2004) and is an empirical validation ofthe ITG hypothesis.The experiments with the constrained ITG showthe effect of reorderings spanning different lengths(see Table 3).
While most reorderings are short-distance (<5 phrases) a lot of improvements can stillbe obtained when ?
is increased from length 5 to 10and even from 10 to 20 phrases.7 Related WorkThere exist related algorithms that search the spaceof reorderings and compute BLEU oracle approxi-Len.
?=0 ?=5 ?=10 ?=20 ?=30 ?=4026?30 18.31 24.07 26.40 26.79 26.85 26.8531?35 18.94 25.10 27.21 28.00 28.09 28.1136?40 18.22 24.46 26.66 27.53 27.64 27.6526?40 18.49 24.74 26.74 27.41 27.50 27.51Table 3: BLEU results of ITGs that are constrained to reorder-ings not exceeding a certain span length ?.
Results shown fordifferent sentence lengths.mations.
Zens and Ney (2005) describe a dynamic-programming algorithm in which at every state thenumber of n-gram matches is stored, along with amultiset that contains all words from the referencethat have not yet been matched.
This makes it pos-sible to compute the modified ngram precision, butthe search space is exponential.
Tillmann and Zhang(2006) use a BLEU oracle decoder for discrimina-tive training of a local reordering model.
No de-tails about the algorithm are given.
Zens and Ney(2003) perform a comparison of different reorder-ing strategies.
Their study differs from ours in thatthey use reordering models trained on real data andmay therefore be influenced by feature selection,parameter estimation and other training-specific is-sues.
In our study, only the baseline translationmodel is trained on data.
Zens et al (2004) con-duct a study similar to Zens and Ney (2003) and notethat the results for the ITG reordering constraintswere quite dependent on the very simple probabilitymodel used.
Our study avoids this issue by using the109BLEU oracle approach.
In Wellington et al (2006),hand-aligned data are used to compare the standardITG constraints to ITGs that allow gaps.8 ConclusionsWe have presented a training-independent methodto compare different reordering constraints for ma-chine translation.
Given a sentence in foreign wordorder, its reference translation(s) and reorderingconstraints, our dynamic-programming algorithmsefficiently find the oracle reordering that has the ap-proximately highest BLEU score.
This allows eval-uating different reordering constraints experimen-tally, but abstracting away from specific features,the probability model or training methods of the re-ordering strategies.
The presented method evaluatesthe theoretical capabilities of reordering constraints,as opposed to more arbitrary accuracies of specifi-cally trained instances of reordering models.Using our oracle method, we presented an em-pirical evaluation of different reordering constraintsfor a German-English translation task.
The resultsshow that a good reordering of a given monotonetranslation can improve the translation quality dra-matically.
Both short- and long-distance reorderingscontribute to the BLEU score improvements, whichare generally greater for longer sentences.
Reorder-ing constraints that allow global reorderings tendto reach better oracles scores than ones that searchmore locally.
The ITG constraints and the IBM(4)constraints both give the highest oracle scores.The presented BLEU decoder algorithms can beuseful in many ways: They can generally help de-cide what reordering constraints to choose for agiven translation system.
They can be used fordiscriminative training of reordering models (Till-mann and Zhang, 2006).
Furthermore, they can helpdetecting insufficient parameterization or incapabletraining algorithms: If two trained reordering modelinstances show similar performances on a given task,but the oracle scores differ greatly then the trainingmethods might not be optimal.AcknowledgmentsThis work was partially supported by the NationalScience Foundation via an ITR grant (No 0121285),the Defense Advanced Research Projects Agencyvia a GALE contract (No HR0011-06-2-0001), andthe Office of Naval Research via a MURI grant (NoN00014-01-1-0685).
We thank Jason Eisner, DavidSmith, Roy Tromble and the anonymous reviewersfor helpful comments and suggestions.ReferencesA.
V. Aho and J. D. Ullman.
1972.
The Theory of Parsing,Translation, and Compiling.
Prentice Hall.A.L.
Berger P. F. Brown, S. A. Della Pietra, V. J. Della Pietra,J.
R. Gillett, J. D. Lafferty, R. L. Mercer, H. Printz, andL.
Ures.
1996.
Language translation apparatus and methodusing context-based translation models.
United States PatentNo.
5,510,981.E.W.
Dijkstra.
1959.
A note on two problems in connexionwith graphs.
Numerische Mathematik., 1:269?271.J.
Eisner and R. W. Tromble.
2006.
Local search with verylarge-scale neighborhoods for optimal permutations in Ma-chine Translation.
In Proc.
of the Workshop on Computa-tionally Hard Problems and Joint Inference, New York.L.
Huang and D. Chiang.
2005.
Better k-best parsing.
In Proc.of IWPT, Vancouver, B.C., Canada.S.
Kumar and W. Byrne.
2005.
Local phrase reorderingmodels for Statistical Machine Translation.
In Proc.
ofHLT/EMNLP, pages 161?168, Vancouver, B.C., Canada.C.
Tillmann and T. Zhang.
2006.
A discriminative global train-ing algorithm for Statistical MT.
In Proc.
of ACL, pages721?728, Sydney, Australia.B.
Wellington, S. Waxmonsky, and D. Melamed.
2006.
Empir-ical lower bounds on the complexity of translational equiv-alence.
In Proc.
of COLING-ACL, pages 977?984, Sydney,Australia.D.
Wu.
1997.
Stochastic inversion transduction grammars andbilingual parsing of parallel corpora.
Computational Lin-guistics, 23(3):377?404.D.
Xiong, Q. Liu, and S. Lin.
2006.
Maximum entropy basedphrase reordering model for Statistical Machine Translation.In Proc.
of COLING-ACL, pages 521?528, Sydney, Aus-tralia.R.
Zens and H. Ney.
2003.
A comparative study on reorderingconstraints in Statistical Machine Translation.
In Proc.
ofACL, pages 144?151, Sapporo, Japan.R.
Zens and H. Ney.
2005.
Word graphs for Statistical MachineTranslation.
In Proc.
of the ACL Workshop on Building andUsing Parallel Texts, pages 191?198, Ann Arbor, MI.R.
Zens, H. Ney, T. Watanabe, and E. Sumita.
2004.
Reorder-ing constraints for phrase-based Statistical Machine Transla-tion.
In Proc.
of CoLing, pages 205?211, Geneva.110
