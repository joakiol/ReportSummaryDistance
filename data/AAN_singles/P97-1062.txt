Learning Parse and Translation DecisionsFrom Examples With Rich ContextUl f  Hermjakob  and  Raymond J .
MooneyDept .
of Computer  SciencesUn ivers i ty  of Texas  at  Aust inAust in ,  TX  78712, USAu l f@cs .utexas .edu mooney@cs .utexas .eduAbst rac tWe present a knowledge and context-basedsystem for parsing and translating natu-ral language and evaluate it on sentencesfrom the Wall Street Journal.
Applyingmachine learning techniques, the systemuses parse action examples acquired un-der supervision to generate a determinis-tic shift-reduce parser in the form of a de-cision structure.
It relies heavily on con-text, as encoded in features which describethe morphological, syntactic, semantic andother aspects of a given parse state.1 In t roduct ionThe parsing of unrestricted text, with its enormouslexical and structural ambiguity, still poses a greatchallenge in natural anguage processing.
The tradi-tional approach of trying to master the complexity ofparse grammars with hand-coded rules turned out tobe much more difficult than expected, if not impos-sible.
Newer statistical approaches with often onlyvery limited context sensitivity seem to have hit aperformance ceiling even when trained on very largecorpora.To cope with the complexity of unrestricted text,parse rules in any kind of formalism will have toconsider a complex context with many different mor-phological, syntactic or semantic features.
This canpresent a significant problem, because ven linguisti-cally trained natural anguage developers have greatdifficulties writing and even more so extending ex-plicit parse grammars covering a wide range of nat-ural language.
On the other hand it is much easierfor humans to decide how specific sentences houldbe analyzed.We therefore propose an approach to parsingbased on learning from examples with a very strongemphasis on context, integrating morphological,syntactic, semantic and other aspects relevant tomaking good parse decisions, thereby also allowingthe parsing to be deterministic.
Applying machinelearning techniques, the system uses parse action ex-amples acquired under supervision to generate a de-terministic shift-reduce type parser in the form of adecision structure.
The generated parser transformsinput sentences into an integrated phrase-structureand case-frame tree, powerful enough to be fed intoa transfer and a generation module to complete thefull process of machine translation.Balanced by rich context and some backgroundknowledge, our corpus based approach relieves theNL-developer f om the hard if not impossible task ofwriting explicit grammar ules and keeps grammarcoverage increases very manageable.
Compared withstandard statistical methods, our system relies ondeeper analysis and more supervision, but radicallyfewer examples.2 Bas ic  Pars ing  Parad igmAs the basic mechanism for parsing text into ashallow semantic representation, we choose a shift-reduce type parser (Marcus, 1980).
It breaks parsinginto an ordered sequence of small and manageableparse actions such as shift and reduce.
This ordered'left-to-right' parsing is much closer to how humansparse a sentence than, for example, chart orientedparsers; it allows a very transparent control struc-ture and makes the parsing process relatively intu-itive for humans.
This is very important, becauseduring the training phase, the system is guided by ahuman supervisor for whom the flow of control needsto be as transparent and intuitive as possible.The parsing does not have separate phases forpart-of-speech selection and syntactic and semanticprocessing, but rather integrates all of them into asingle parsing phase.
Since the system has all mor-phological, syntactic and semantic ontext informa-tion available at all times, the system can make well-482based decisions very early, allowing a single path, i.e.deterministic parse, which eliminates wasting com-putation on 'dead end' alternatives.Before the parsing itself starts, the input stringis segmented into a list of words incl.
punctuationmarks, which then are sent through a morphologicalanalyzer that, using a lexicon 1, produces primitiveframes for the segmented words.
A word gets a prim-itive frame for each possible par t of speech.
(Mor-phological ambiguity is captured within a frame.
)parse stack"bought"synt: verbtop of top ofstack list?
"<input list >, "today"synt adv(R 2 TO S-VP AS PRED (OBJ PAT))"reduce the 2 top elements ofthe parse stackto a frame with syntax 'vp'and roles 'pred' and 'obj and pat'"1~ "bought abook .
.
.
.
today"synt: vp synt: advsub: (pred) (obj pat)/I "bought"synt: verbFigure 1: Example of a parse action (simplified);boxes represent framesThe central data structure for the parser consistsof a parse stack and an input list.
The parse stackand the input list contain trees of frames of wordsor phrases.
Core slots of frames are surface and lexi-cal form, syntactic and semantic ategory, subframeswith syntactic and semantic roles, and form restric-1The lexicon provides part-of-speech information andlinks words to concepts, as used in the KB (see nextsection).
Additional information i cludes irregular formsand grammatical gender etc.
(in the German lexicon).
"John bought a new computer science booktoday."
:synt/sem: S-SNT/I-EV-BUYforms: (3rd_person sing past_tense)lex : "buy"subs :(SUBJ AGENT) "John":synt/sem: S-NP/I-EN-JOHN(PRED) "John"synt/sem: S-NOUN/I-EN-JOHN(PRED) "bought":synt/sem: S-TR-VERB/I-EV-BUY(OBJ THEME) "a new computer science book":synt/sem: S-NP/I-EN-BOOK(DET) "a"(MOD) "new"(PRED) "computer science book"(MOD) "computer science"(MOD) "computer"(PRED) "science"(PRED) "book"(TIME) "today":synt/sem: S-ADV/C-AT-TIME(PRED) "today"synt/sem: S-ADV/I-EADV-TODAY(DUMMY) "."
:synt : D-PERIODFigure 2: Example of a parse tree (simplified).tions such as number, person, and tense.
Optionalslots include special information like the numericalvalue of number words.Initially, the parse stack is empty and the inputlist contains the primitive frames produced by themorphological nalyzer.
After initialization, the de-terministic parser applies a sequence of parse actionsto the parse structure.
The most frequent parse ac-tions are shift, which shifts a frame from the inputlist onto the parse stack or backwards, and reduce,which combines one or several frames on the parsestack into one new frame.
The frames to be com-bined are typically, but not necessarily, next to eachother at the top of the stack.
As shown in figure 1,the action(R 2 TO VP AS PRED (0BJ PAT))for example reduces the two top frames of the stackinto a new frame that is marked as a verb phraseand contains the next-to-the-top frame as its pred-icate (or head) and the top frame of the stack asits object and patient.
Other parse actions includeadd-into, which adds frames arbitrarily deep into anexisting frame tree, mark, which can mark any slotof any frame with any value, and operations to in-troduce empty categories (i.e.
traces and 'PRO', asin "Shei wanted PR.Oi to win.").
Parse actions can483have numerous arguments, making the parse actionlanguage very powerful.The parse action sequences needed for training thesystem are acquired interactively.
For each train-ing sentence, the system and the supervisor parsethe sentence step by step, with the supervisor enter-ing the next parse action, e.g.
(R 2 TO VP AS PRED(01aJ PAT) ), and the system executing it, repeatingthis sequence until the sentence is fully parsed.
Atleast for the very first sentence, the supervisor actu-ally has to type in the entire parse action sequence.With a growing number of parse action examplesavailable, the system, as described below in more de-tail, can be trained using those previous examples.In such a partially trained system, the parse actionsare then proposed by the system using a parse deci-sion structure which "classifies" the current context.The proper classification is the specific action or se-quence of actions that (the system believes) shouldbe performed next.
During further training, the su-pervisor then enters parse action commands by ei-ther confirming what the system proposes or overrul-ing it by providing the proper action.
As the corpusof parse examples grows and the system is trainedon more and more data, the system becomes morerefined, so that the supervisor has to overrule thesystem with decreasing frequency.
The sequence ofcorrect parse actions for a sentence is then recordedin a log file.3 FeaturesTo make good parse decisions, a wide range of fea-tures at various degrees of abstraction have to beconsidered.
To express such a wide range of fea-tures, we defined a feature language.
Parse featurescan be thought of as functions that map from par-tially parsed sentences to a value.
Applied to thetarget parse state of figure 1, the feature (SYNTOF OBJ OF -1 AT S-SYNT-ELEM), for example,designates the general syntactic lass of the objectof the first frame of the parse stack 2, in our examplenp 3.
So, features do not a priori operate on words orphrases, but only do so if their description referencessuch words or phrases, as in our example through thepath 'OBJ OF -1'.Given a particular parse state and a feature, thesystem can interpret the feature and compute its2S-SYNT-ELEM designates the top syntactic level;since -1 is negative, the feature refers to the 1st frameof the parse stack.
Note that the top of stack is at theright end for the parse stack.3If a feature is not defined in a specific parse state, thefeature interpreter assigns the special value unavailable.value for the given parse state, often using additionalbackground knowledge such as1.
A knowledge base (KB), which currently con-sists of a directed acyclic graph of 4356 mostlysemantic and syntactic oncepts connected by4518 is-a links, e.g.
"book,~o~,n-eoncept is-atangible - objectnoun-coneept".
Most conceptsrepresenting words are at a fairly shallow levelof the KB, e.g.
under 'tangible object', 'ab-stract', 'process verb', or 'adjective', with moredepth used only in concept areas more relevantfor making parse and translation decisions, suchas temporal, spatial and animate concepts.
42.
A subcategorization table that describes the syn-tactic and semantic role structures for verbs,with currently 242 entries.The following representative examples, for easierunderstanding rendered in English and not in fea-ture language syntax, further illustrate the expres-siveness of the feature language:?
the general syntactic class of frame_3 (thethird element of the parse stack): e.g.
verb, adj,np,?
whether or not the adverbial alternative offrame1 (the top element of the input list) isan adjectival degree adverb,?
the specific finite tense of frame_i,  e.g.
presenttense,?
whether or not frame_l contains an object,?
the semantic role of frame_l with respect toframe_2: e.g.
agent, time; this involves patternmatching with corresponding entries in the verbsubcategorization table,?
whether or not frarne_2 and frame_l satisfysubject-verb agreement.Features can in principal refer to any one or sev-eral elements on the parse stack or input list, andany of their subelements, at any depth.
Since thecurrently 205 features are supposed to bear somelinguistic relevance, none of them are unjustifiablyremote from the current focus of a parse state.The feature collection is basically independentfrom the supervised parse action acquisition.
Beforelearning a decision structure for the first time, thesupervisor has to provide an initial set of features4Supported by acquisition tools, word/concept airsare typically entered into the lexicon and the KB at thesame time, typically requiring less than a minute perword or group of closely related words.484done-operation-p treeSTART ~ .
- -7-ff~" -"  "2 7. .
- - -do -~ - - _ ~: J J  -art/ s j~  g ?
Ido er - - .
- re er o re ?
.
~" ."
shift n 'It s-verbred 'uCe 2 .
.
,~reduce 1... reduce 3...Figure 3: Example of a hybrid decision structurethat can be considered obviously relevant.
Partic-ularly during the early development of our system,this set was increased whenever parse examples hadidentical values for all current features but neverthe-less demanded ifferent parse actions.
Given a spe-cific conflict pair of partially parsed sentences, thesupervisor would add a new relevant feature that dis-criminates the two examples.
We expect our featureset to grow to eventually about 300 features whenscaling up further within the Wall Street Journal do-main, and quite possibly to a higher number whenexpanding into new domains.
However, such featureset additions require fairly little supervisor effort.Given (1) a log file with the correct parse actionsequence of training sentences as acquired under su-pervision and (2) a set of features, the system revis-its the training sentences and computes values forall features at each parse step.
Together with therecorded parse actions these feature vectors formparse examples that serve as input to the learningunit.
Whenever the feature set is modified, this stepmust be repeated, but this is unproblematic, becausethis process is both fully automatic and fast.4 Learning Decision StructuresTraditional statistical techniques also use features,but often have to sharply limit their number (forsome trigram approaches to three fairly simple fea-tures) to avoid the loss of statistical significance.In parsing, only a very small number of featuresare crucial over a wide range of examples, whilemost features are critical in only a few examples,being used to 'fine-tune' the decision structure forspecial cases.
So in order to overcome the antago-nism between the importance of having a large num-ber of features and the need to control the num-ber of examples required for learning, particularlywhen acquiring parse action sequence under super-vision, we choose a decision-tree based learning al-gorithm, which recursively selects the most discrim-inating feature of the corresponding subset of train-ing examples, eventually ignoring all locally irrele-vant features, thereby tailoring the size of the finaldecision structure to the complexity of the trainingdata.While parse actions might be complex for the ac-tion interpreter, they are atomic with respect o thedecision structure learner; e.g.
"(R 2 TO VP ASPFtED (OBJ PAT))" would be such an atomic clas-sification.
A set of parse examples, as already de-scribed in the previous ection, is then fed into anID3-based learning routine that generates a deci-sion structure, which can then 'classify' any givenparse state by proposing what parse action to per-form next.We extended the standard ID3 model (Quinlan,1986) to more general hybrid decision structures.In our tests, the best performing structure was adecision list (Rivest, 1987) of hierarchical decisiontrees, whose simplified basic structure is illustratedin figure 3.
Note that in the 'reduce operation tree',the system first decides whether or not to performa reduction before deciding on a specific reduction.Using our knowledge of similarity of parse actionsand the exceptionality vs. generality of parse actiongroups, we can provide an overhead structure thathelps prevent data fragmentation.4855 Transfer and Generat ionThe output tree generated by the parser can be usedfor translation.
A transfer module recursively mapsthe source language parse tree to an equivalent treein the target language, reusing the methods devel-oped for parsing with only minor adaptations.
Themain purpose of learning here is to resolve trans-lation ambiguities, which arise for example whentranslating the English "to knov\]' to German (wis-sen/kennen) or Spanish (saber/conocer).Besides word pair entries, the bilingual dictionaryalso contains pairs of phrases and expressions in aformat closely resembling traditional (paper) dictio-naries, e.g.
"to comment on SOMETHING_l"/"sichzu ETWAS_DAT_I ~iut3ern".
Even if a complextranslation pair does not bridge a structural mis-match, it can make a valuable contribution to dis-ambiguation.
Consider for example the term "inter-est rate".
Both element nouns are highly, ambigu-ous with respect to German, but the English com-pound conclusively maps to the German compound"Zinssatz".
We believe that an extensive collectionof complex translation pairs in the bilingual dictio-nary is critical for translation quality and we areconfident hat its acquisition can be at least partiallyautomated by using techniques like those describedin (Smadja et al, 1996).
Complex translation en-tries are preprocessed using the same parser as fornormal text.
During the transfer process, the result-ing parse tree pairs are then accessed using patternmatching.The generation module orders the components ofphrases, adds appropriate punctuation, and propa-gates morphologically relevant information in orderto compute the proper form of surface words in thetarget language.6 Wal l  S t reet  Journa l  Exper iments~Ve now present intermediate results on trainingand testing a prototype implementation of the sys-tem with sentences from the Wall Street Journal, aprominent corpus of 'real' text, as collected on theACL-CD.In order to limit the size of the required lexicon,we work on a reduced corpus of 105,356 sentences,a tenth of the full corpus, that includes all thosesentences that are fully covered by the 3000 mostfrequently occurring words (ignoring numbers etc.
)in the entire corpus.
The first 272 sentences used inthis experiment vary in length from 4 to 45 words,averaging at 17.1 words and 43.5 parse actions persentence.
One of these sentence is "Canadian man-ufacturers' new orders fell to $20.80 billion (Cana-Tr.
snt.
16 32 64 128 2561 97.5% 1 98.4  ICr/snt I 2.5 1 2.1j 11. .
I LI_I.L I0 1 I~ %  I 93.0% \[ 94.951791  9 s Is9  191.7 I  0.
6-57oStr~L I 55 ~10.3~18.8%126.8%Loops 13 6 0 1 1Table 1: Evaluation results with varying number oftraining sentences; with all 205 features and hybriddecision structure; Train.
= number of training sen-tences; pr/prec.
= precision; rec.
= recall; I.
= la-beled; Tagging = tagging accuracy; Cr/snt = cross-ings per sentence; Ops = correct operations; OpSeq= Operation Sequencelabeled precision95% -90% -85% -80% -75% I t I I I I I16 32  64  128  256  512  1024number of training sentencesFigure 4: Learning curve for labeled precision in ta-ble 1.dian) in January, down 4~o from December's $21.67billion billion on a seasonally adjusted basis, Statis-tics Canada, a federal agency, said.
".For our parsing test series, we use 17-fold cross-validation.
The corpus of 272 sentences that cur-rently have parse action logs associated with themis divided into 17 blocks of 16 sentences each.
The 17blocks are then consecutively used for testing.
Foreach of the 17 sub-tests, a varying number of sen-tences from the other blocks is used for training theparse decision structure, so that within a sub-test,none of the training sentences are ever used as a testsentence.
The results of the 17 sub-tests of each se-ries are then averaged.486Features 6 ' 25 50 100 205Prec.RecallL.
pr.L.
rec.TaggingCr/snt0 cr< lc r<2cr< 3cr< 4crOpsOpSeqStr&LLoopsVa zTw wrrI 87.3% ~ 88.7% 190.8%\] 91.7%179.8% ~ 86.7% \] 87.2%188.6%I 81.6% ~ 84.1% \[ 86.9% I 88.1%1 97.6% 1 9;.9  1 98.1% 1 98.2%157.4%1 59.6%170.6%172.1%\[ 72A% \[ 73.9% \[ 80.5% \[ 84.2%1 82.7% 1 84,9% \[ 88.6% 1 92.3%1 89.6% 1 89,7% 1 93.8% 1 94.5%I s.8 o 1 13.692--7W092.8%89.8%89.6%98.4%1.056.3%73.5%84.9%93.0%94.9%91.7%16.5%2618%Table 2: Evaluation results with varying number offeatures; with 256 training sentencesPrecision (pr.
):number of correct constituents in system parsenumber of constituents in system parseRecal l  (rec.
):number of correct constituents in system parsenumber of constituents in logged parseCross ing brackets  (cr): number of constituentswhich violate constituent boundaries with a con-stituent in the logged parse.Labe led  (l.) precision/recall measures not onlystructural correctness, but also the correctness ofthe syntactic label.
Correct  operat ions  (Ops)measures the number of correct operations duringa parse that is continuously corrected based on thelogged sequence.
The correct operations ratio is im-portant for example acquisition, because it describesthe percentage of parse actions that the supervisorcan confirm by just hitting the return key.
A sen-tence has a correct operat ing  sequence (OpSeq),if the system fully predicts the logged parse actionsequence, and a correct s t ruc ture  and label ing(Str~L), if the structure and syntactic labeling ofthe final system parse of a sentence is 100% correct,regardless of the operations leading to it.The current set of 205 features was sufficient toalways discriminate xamples with different parseactions, resulting in a 100% accuracy on sentencesalready seen during training.
While that percentageis certainly less important than the accuracy figuresfor unseen sentences, it nevertheless represents animportant upper ceiling.Many of the mistakes are due to encountering con-Type of deci- plain hier.
plainsion structure list list treePrecision 87.8% 91.0% 87.6%Recall 89.9% 88.2% 89.7%Lab.
precision 28.6% 87.4% 38.5%Lab.
recall 86.1% 84.7% 85.6%Tagging ace.
97.9% 96.0% 97.9%Crossings/snt 1.2 1.3 1.30crossings 55.2% 52.9% 51.5%_< 1 crossings 72.8% 71.0% 65.8%_~ 2 crossings 82.7% 82.7% 81.6%< 3 crossings 89.0% 89.0% 90.1%_< 4 crossings 93.4% 93.4% 93.4%Ops 86.5% 90.3% 90.2%OpSeq 12.9% 11.8% 13.6%Str~L 22.4% 22.8% 21.7%Endless loops 26 23 32hybridtree92.7%92.8%89.8%89.6%98.4%1.056.3%73.5%84.9%93 2%94.9%91.7%16.5%26.8%1Table 3: Evaluation results with varying types ofdecision structures; with 256 training sentences and205 featuresstructions that just have not been seen before at all,typically causing several erroneous parse decisions ina row.
This observation further supports our expec-tation, based on the results shown in table 1 and fig-ure 4, that with more training sentences, the testingaccuracy for unseen sentences will still rise signifi-cantly.Table 2 shows the impact of reducing the featureset to a set of N core features.
While the loss of a fewspecialized features will not cause a major degrada-tion, the relatively high number of features used inour system finds a clear justification when evaluatingcompound test characteristics, uch as the numberof structurally completely correct sentences.
When25 or fewer features are used, all of them are syn-tactic.
Therefore the 25 feature test is a relativelygood indicator for the contribution of the semanticknowledge base.In another test, we deleted all 10 features relatingto the subcategorization table and found that theonly metrics with degrading values were those mea-suring semantic role assignment; in particular, noneof the precision, recall and crossing bracket valueschanged significantly.
This suggests that, at least inthe presence of other semantic features, the subcat-egorization table does not play as critical a role inresolving structural ambiguity as might have beenexpected.Table 3 compares four different machine learningvariants: plain decision lists, hierarchical decision487lists, plain decision trees and a hybrid structure,namely a decision list of hierarchical decision trees,as sketched in figure 3.
The results show that ex-tensions to the basic decision tree model can signif-icantly improve learning results.SystemHuman translationCONTEX on correct parseCONTEX (full translation)LogosSYSTR.ANGlobalinkSyntax Semantics1.18 1.412.20 2.192.36 2.382.57 3.242.68 3.353.30 3.83Table 4: Translation evaluation results (best possi-ble = 1.00, worst possible = 6.00)Table 4 summarizes the evaluation results oftranslating 32 randomly selected sentences from ourWall Street Journal corpus from English to German.Besides our system, CONTEX, we tested three com-mercial systems, Logos, SYSTR.AN, and Globalink.In order to better assess the contribution of theparser, we also added a version that let our systemstart with the correct parse, effectively just testingthe transfer and generation module.
The resultingtranslations, in randomized order and without iden-tification, were evaluated by ten bilingual graduatestudents, both native German speakers living in theU.S.
and native English speakers teaching collegelevel German.
As a control, half of the evaluatorswere also given translations by a bilingual human.Note that the translation results using our parserare fairly close to those starting with a correct parse.This means that the errors made by the parserhave had a relatively moderate impact on transla-tion quality.
The transfer and generation moduleswere developed and trained based on only 48 sen-tences, so we expect a significant ranslation qualityimprovement by further development of those mod-ules.Our system performed better than the commercialsystems, but this has to be interpreted with caution,since our system was trained and tested on sentencesfrom the same lexically limited corpus (but of coursewithout overlap), whereas the other systems weredeveloped on and for texts from a larger variety ofdomains, making lexical choices more difficult in par-ticular.Table 5 shows the correlation between variousparse and translation metrics.
Labeled precision hasthe strongest correlation with both the syntactic andsemantic translation evaluation grades.
"Metric'PrecisionRecallLabeled precisionLabeled recallTagging accuracyNumber of crossing brackets JOperationsOperation sequenceSyntax Semantics-0.63 -0.63-0.64 -0.66-0.75 -0.78-0.65 -0.65-0.66 -0.560.58 0.54-0.45 -0.41-0.39 -0.36Table 5: Correlation between various parse andtranslation metrics.
Values near -1.0 or 1.0 indi-cate very strong correlation, whereas values near 0.0indicate a weak or no correlation.
Most correlationvalues, incl.
for labeled precision are negative, be-cause a higher (better) labeled precision correlateswith a numerically lower (better) translation scoreon the 1.0 (best) to 6.0 (worst) translation evalua-tion scale.7 Re la ted  WorkOur basic parsing and interactive training paradigmis based on (Simmons and Yu, 1992).
We haveextended their work by significantly increasing theexpressiveness of the parse action and feature lan-guages, in particular by moving far beyond the fewsimple features that were limited to syntax only, byadding more background knowledge and by intro-ducing a sophisticated machine learning component.
(Magerman, 1995) uses a decision tree model sim-ilar to ours, training his system SPATTER.
with parseaction sequences for 40,000 Wall Street Journal sen-tences derived from the Penn Treebank (Marcuset al, 1993).
Questioning the traditional n-grams,Magerman already advocates a heavier reliance oncontextual information.
Going beyond Magerman'sstill relatively rigid set of 36 features, we propose ayet richer, basically unlimited feature language set.Our parse action sequences are too complex to bederived from a treebank like Penn's.
Not only doour parse trees contain semantic annotations, rolesand more syntactic detail, we also rely on the moreinformative parse action sequence.
While this neces-sitates the involvement of a parsing supervisor fortraining, we are able to perform deterministic pars-ing and get aleady very good test results for only256 training sentences.
(Collins, 1996) focuses on bigram lexical depen-dencies (BLD).
Trained on the same 40,000 sen-tences as Spatter, it relies on a much more limitedtype of context than our system and needs littlebackground knowledge.488ModelLabeled precisionLabeled recallCrossings/sentenceSent.
with 0 cr.Sent.
with < 2 cr.I SPATTER, I BLD I CONTEX84.9% 86.3% 89.8%84.6% 85.8% 89.6%1.26 1.14 1.0256.6% 59.9% 56.3%81.4% 83.6% 84.9%Table 6: Comparing our system CONTEX withMagerman's SPATTER, and Collins' BLD; results forSPATTER, and BLD are for sentences of up to 40words.Table 6 compares our results with SPATTER, andBLD.
The results have to be interpreted cautiouslysince they are not based on the exact same sentencesand detail of bracketing.
Due to lexical restrictions,our average sentence length (17.1) is below the oneused in SPATTER and BLD (22.3), but some of ourtest sentences have more than 40 words; and whilethe Penn Treebank leaves many phrases uch as "theNew York Stock Exchange" without internal struc-ture, our system performs a complete bracketing,thereby increasing the risk of crossing brackets.8 Conc lus ionWe try to bridge the gap between the typically hard-to-scale hand-crafted approach and the typicallylarge-scale but context-poor statistical approach forunrestricted text parsing.Using?
a rich and unified context with 205 features,?
a complex parse action language that allows in-tegrated part of speech tagging and syntacticand semantic processing,?
a sophisticated decision structure that general-izes traditional decision trees and lists,?
a balanced use of machine learning and micro-modular background knowledge, i.e.
very smallpieces of highly' independent information?
a modest number of interactively acquired ex-amples from the Wall Street Journal,our system CONTEX?
computes parse trees and translations fast, be-cause it uses a deterministic single-pass parser,?
shows good robustness when encountering novelconstructions,?
produces good parsing results comparable tothose of the leading statistical methods, and?
delivers competitive results for machine trans-lations.While many limited-context s atistical approacheshave already reached a performance ceiling, we stillexpect to significantly improve our results when in-creasing our training base beyond the currently 256sentences, because the learning curve hasn't flat-tened out yet and adding substantially more exam-ples is still very feasible.
Even then the trainingsize will compare favorably with the huge numberof training sentences necessary for many statisticalsystems.Re ferencesE.
Black, J. Lafferty, and S. Roukos.
1992.
Devel-opment and evaluation of a broad-coverage prob-abilistic grammar of English-language computermanuals.
In 30th Proceedings of the A CL, pages185-192.M.
J. Collins.
1996.
A New Statistical Parser Basedon Bigram Lexical Dependencies.
In 3~th Proceed-ings of the ACL, pages 184-191.U.
Hermjakob.
1997.
Learning Parse and Trans-lation Decisions From Examples With Rich Con-text.
Ph.D. thesis, University of Texas atAustin, Dept.
of Computer Sciences TR 97-12.file://ftp.cs.utexas.edu/pub/mooney/papers/hermjakob-dissertation-97.ps.ZD.
M. Magerman.
1995.
Statistical Decision-TreeModels for Parsing In 33rd Proceedings of theACL, pages 276-283.M.
P. Marcus.
1980.
A Theory of Syntactic Recog-nition for Natural Language.
MIT Press.M.
P. Marcus, B. Santorini, and M. A. Marcinkie-wicz.
1993.
Building a Large Annotated Corpusof English: The Penn Treebank.
In Computa-tional Linguistics 19 (2), pages 184-191.S.
Nirenburg, J. Carbonell, M. Tomita, and K.Goodman.
1992.
Machine Translation: AKnowledge-Based Approach.
San Mateo, CA:Morgan Kaufmann.J.
R. Quinlan.
1986.
Induction of decision trees.
InMachine Learning I (I), pages 81-106.R.
L. Rivest.
1987.
Learning Decision Lists.
InMachine Learning 2, pages 229-246.R.
F. Simmons and Yeong-Ho Yu.
1992.
The Acqui-sition and Use of Context-Dependent Grammarsfor English.
In Computational Linguistics 18 (4),pages 391-418.F.
Smadja, K. R. KcKeown and V. Hatzivassiloglou.1996.
Translating Collocations for Bilingual Lex-icons: A Statistical Approach.
In ComputationalLinguistics 22 (I), pages 1-38.Globalink.
http://www.globalink.com/home.htmlOct.
1996.Logos.
http://www.logos-ca.com/ Oct. 1996.SYSTRAN.
http:/ /systranmt.com/ Oct. 1996.489
