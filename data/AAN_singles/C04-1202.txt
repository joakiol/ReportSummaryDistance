Using Gene Expression Programming to Construct Sentence RankingFunctions for Text SummarizationZhuli Xie, Xin Li, Barbara Di Eugenio,Peter C. NelsonDepartment of Computer ScienceUniversity of Illinois at ChicagoChicago, IL 60607, U.S.A.zxie@cs.uic.edu, xli1@cs.uic.edu,bdieugen@cs.uic.edu, nelson@cs.uic.eduWeimin Xiao, Thomas M. TirpakPhysical Realization Research Center ofMotorola LabsSchaumburg, IL 60196, U.S.A.awx003@motorola.com,T.Tirpak@motorola.comAbstractIn this paper, we consider the automatic textsummarization as a challenging task of ma-chine learning.
We proposed a novel summari-zation system architecture which employsGene Expression Programming technique as itslearning mechanism.
The preliminary experi-mental results have shown that our prototypesystem outperforms the baseline systems.1 IntroductionAutomatic text summarization has been studied fordecades (Edmundson 1969) and is still a very activearea (Salton et al 1994; Kupiec et al 1995; Bran-dow et al 1995; Lin 1999; Aone et al 1999; Sekineand Nobata 2001; Mani 2001; McKeown et al 2001;Radev et al 2003).
Only a few have tried using ma-chine learning to accomplish this difficult task (Lin1999; Aone et al 1999; Neto et al 2002).
Most re-search falls into combining statistical methods withlinguistic analysis.
We regard the summarization asa problem of empowering a machine to learn fromhuman-summarized text documents.
We employ anevolutionary algorithm, Gene Expression Program-ming (GEP) (Ferreira 2001), as the learning mecha-nism in our Adaptive Text Summarization (ATS)system to learn sentence ranking functions.
Eventhough our system generates extractive summaries,the sentence ranking function in use differentiatesours from that of (Edmundson 1969; Sekine andNobata.
1999; Goldstein et al 1999) who specified itto be a linear function of sentence features.
We usedGEP to generate a sentence ranking function fromthe training data and applied it to the test data, whichalso differs from (Lin 1999) who used decision tree,(Aone et al 1999; Kupiec et al 1995) who usedBayes?s rule, and (Neto et al 2002) who imple-mented both Na?ve Bayes and decision tree C4.5.This paper presents our approach, details the sys-tem architecture, and discusses preliminary experi-mental results.
Conclusions and future work areoutlined at the end.2 Background2.1 Gene Expression ProgrammingGene Expression Programming (GEP), first intro-duced by (Ferreira 2001), is an evolutionary algo-rithm that evolves computer programs and predictsmathematical models from experimental data.
Thealgorithm is similar to Genetic Programming (GP),but uses fixed-length character strings (called chro-mosomes) to represent computer programs which areafterwards expressed as expression trees (ETs).
GEPbegins with a random population of candidatesolutions in the form of chromosomes.
Thechromosomes are then mapped into ETs, evaluatedbased on a fitness function and selected by fitness toreproduce with modification via genetic operations.The new generation of solutions goes through thesame process until the stop condition is satisfied.The fittest individual serves as the final solution.GEP has been used to solve symbolic regression,sequence induction, and classification problems effi-ciently (Ferreira 2002; Zhou 2003).
We utilized GEPto find the explicit form of sentence ranking func-tions for the automatic text summarization.2.2 Sentence FeaturesIn our current system, every sentence s is repre-sented by five normalized features:?
Location of the Paragraph (P):MYP /=                               (1)where M is the total number of paragraphs in adocument; Y is the index of the paragraph s belongsto.?
Location of the Sentence (S):NXS /=                        (2)where N is the total number of sentences in theparagraph; X is the index of sentence s.?
Length of the Sentence (L):The length of the sentence is the number of words itcontained, i.e., l(s), normalized by Sigmoid function:))(())(()(,11slstdslsleeL????
?=+?= ??
(3)Where u(l(s)) is the average length of sentences, andstd(l(s)) is the standard deviation of the sentencelengths.?
Heading Sentence (H):H = 1, if s is a title, subtitle or heading, 0 otherwise.?
Content-word Frequencies (F):))(())(()(,11)(sCWstdsCWsCWeesF ????
?=+?= ??(4)?=?
?=kiii swwFreqsCW1.
)],(log[)(                         (5)where Freq(wi) is the frequency of wi in that docu-ment; ?
(CW(S)) is the mean of all the sentencescores, and std(CW(s)) is the standard deviation.2.3 Sentence ranking functionWe assume that for a certain type of documents, themechanism to perform summarization would be thesame.
Therefore, we only need to find one algorithmthat links a collection of documents and their corre-sponding summaries.
We process the text summari-zation learning task in two stages: training andtesting.
In the training stage, a set of training docu-ments with their summaries are provided, and thetext features are preprocessed using statistical meth-ods and natural language processing methods as de-fined in 2.2, then each sentence in a document isscored based on a sentence ranking function con-structed by GEP.
Fitness value of the summariza-tion task is the similarity between the summaryproduced by the machine and the summarization textof training document.
The top n ranked sentences11 The number of sentences extracted by the GEP module can bea variable, which is decided by the required number of words ina summary.
Or it can be a specified percentage of the total num-ber of sentences in the document.will be returned as the summary of that documentand presented in their nature order.
In the testingstage, a different document set is supplied to test thesimilarity between the machine summarized text andthe human or other system summarized text.3 System ArchitectureIn addition to the traditional way of extracting thehighest ranked sentences in a document to composea summary as in (Edmundson 1969; Lin 1999;Kupiec et al 1995; Brandow 1995; Zechner 1996),we embedded a machine learning mechanism in oursystem.
The system architecture is shown in Figure 1where the GEP module is highlighted.
In the trainingstage, each of the training documents is passed to theGEP module after being preprocessed into a set ofsentence feature vectors.
The GEP runs m genera-tions, and in each generation a population of p sen-tence scoring functions in the form of chromosomesin GEP is generated.
Every candidate scoring func-tion is then applied to sentence feature vectors fromevery training document and produces a score ac-cordingly.
Then all sentences in the same trainingdocument are ranked according to their scores, and nsentences with top scores are selected as an extract.The next step is to measure how similar the extractis to the objective summary.
As discussed by(McLellan et al 2001; Goldstein et al 1999; McKe-own et al 2001), evaluating the quality of a sum-mary often requires involvement of human subjects.This is almost impractical in a machine learningprocedure.
Thus we chose an alternative similaritymeasure as the approximation, i.e.
a cosine functionthat is often seen in Information Retrieval to calcu-late the relevance of two documents, to compute thesimilarity between an extract and the objectivesummary.
We compute the similarity values for eachof the obtained extracts and their objective summa-ries respectively, and feed the results into the FitnessCalculation module to get a fitness measure for thecurrent candidate sentence ranking function underconsideration:)),(( ii OESimilarityAvgFitness = ,                   (6)where Ei is the extract of the i-th document in thetraining set and Oi is its objective summary.After the fitness value for every chromosome inthe current generation is computed, the GEP popula-tion undergoes all genetic operators to produce thenext generation.
After the specified number of gen-erations has been reached, the final best chromo-some is returned as an optimal sentence rankingfunction for the training set and is ready to use in atest document to produce an extractive summary.4 ExperimentsWe randomly selected 60 documents from theCMPLG corpus2 for our experiments.
The only re-striction is that each document has an abstract pro-vided which will serve as the objective summary.Among these 60 documents, 50 are used for trainingand the remaining 10 are used for testing.
The func-tion set for the GEP to evolve sentence ranking func-tions includes (+, -, *, /, power, sqrt, exp, log, min,max, and constant 1, 2, 3, 5, 7).
The length of thechromosome is 128.
Other GEP control parametersare set as follows: population, 256; probability ofcrossover, 0.5; probability of mutation, 0.2; prob-ability of rotation, 0.2; generations, 10,000-50,000(in five runs).
Our system has produced a five-sentence extractive summary for each of the testingdocuments, and calculated the similarity between theproduced summary and the abstract coming alongwith the document.Ideally, we would like to compare our system withother summarizers.
However, due to theunavailability of other summarization systems toperform the same task, we designed three baselinemethods, namely lead-based, randomly-selected, andrandom-lead-based, to generate summaries for per-formance comparison, which were also adopted by(Brandow et al 1995; Zechner 1996; Radev et al2003).
The baseline methods are detailed as2 CMPLG corpus is composed of 183 documents from the Com-putation and Language (cmp-lg) collection, which has beenmarked up in XML.
The documents are scientific papers whichappeared in association for Computational Linguistics (ACL)sponsored conferences.follows:o The lead-based method selects the first sen-tences from the first five paragraphs as thesummary of each of the testing documents.o The randomly-selected method chooses five sen-tences from a document at random to compose asummary.o The random-lead-based method chooses fivesentences among the first sentences from allparagraphs in the document at random.We performed the random selection 1,000 times,and calculated the average similarity of the testingdocuments for each of the random-based methods.The experimental results are plotted in Figure 2,which have demonstrated that our system outper-forms all three baseline methods.Figure 2.
Similarity Comparison0.4420.2790.17 0.18100.10.20.30.40.5ATS Lead-based Rand-selectedRand-Lead-basedSyste mSimilarityOne sample sentence scoring function learned by theGEP is as follows:)3(7)( +?=PFSsscore ,                 (7).5 Conclusions and Future WorkIn this paper, we have presented a prototype summa-rization system which employs GEP as its learningmechanism for sentence ranking function.
In thepreliminary experiments for performance testing,our system outperforms the baseline methods by58%-160% when generating summaries for 10documents.
However, the value of the average simi-larity gained by our system is not as high as wewould like.
The reason most likely lies in the factthat the styles of the objective summaries written byhumans vary a lot or even conflict with each other.In other words, they do not possess many commonfeatures that are a must for high value of similaritybetween two texts.
Using content-words and the co-sine function to measure the similarity may not be anideal evaluation metric, neither is it an ideal fitnessmeasure in the GEP learning mechanism.
Our futurePreprocessObjectiveSummariesTrainingDocumentsGEPGenerate Scor-ing FunctionFitnessCalculationExtractsTestDocumentPost-processSummarizerSentence Scor-ing FunctionExtractiveSummaryFigure 1: System Architectureresearch will further study what kinds of similaritymeasure can be obtained from raw texts without in-volvement of human subjects.
Moreover, we plan tocluster collected documents to make every clustercontains articles summarized in a similar style.
Wewill also explore other sentence features, such assentence cohesion, semantic meaning, and rhetoricalrelations, for an ideal uniform sentence rankingfunction.6 AcknowledgementsOur thanks go to the Physical Realization ResearchCenter of Motorola Labs for their support of thisresearch project.ReferencesAone, C., Gorlinsky, J., Larsen, B., and Okurowski,M.
E. 1999.
A Trainable Summarizer with Knowl-edge Acquried from Robust NLP Techniques, Ad-vances in Automatic Text Summarization, pages71-80.
The MIT Press, Cambridge, Massachusetts.Brandow, R., Mitze, K., and Rau, L. F.  1995.Automatic condensation of electronic publicationsby sentence selection.
Information Processingand Management, 31(5):675-685.Edmundson, H. 1969.
New methods in automaticabstracting.
Journal of ACM, 16(2):264-285.Ferreira, C. 2001.
Gene Expression Programming: ANew Adaptive Algorithm for solving problems.Complex Systems, 13(2):87-129.Ferreira, C. 2002.
Gene Expression Programming:Mathematical Modeling by an Artificial Intelli-gence.
Angra do Heroismo, PortugalGoldstein, J., Kantrowitz, M., Mittal, V., and Car-bonell, J.
1999.
Summarizing Text Documents:Sentence Selection and Evaluation Metrics, inProc.
SIGIR ?99, pages 121-128.
Berkeley, Cali-fornia.Kupiec, J., Pedersen, J., and Chen, F.  1995.
A train-able document summarizer.
In Proc.
18th ACM-SIGIR Conference, pages 68-73.
Seattle, Wash-ington.Lin, C. 1999.
Training a Selection Function for Ex-traction.
In the 8th International Conference onInformation and Knowledge Management (CIKM99), Kansa City, Missouri.Mani, I.
2001.
Automatic Summarization, JohnBenjamins Publishing Company, Amster-dam/Philadelphia.McKeown, K. R., Barzilay, R., Evans, D., Hatzivas-siloglou, V., Kan, M. Y., Schiffman, B., Teufel, S.2001.
Columbia Multi-Document Summarization:Approach and Evaluation, in Proceedings of theDocument Understanding Conference (DUC01).Edmonton, Canada.McLellan, P., Tombros, A., Jose, J., Ounis, I., andWhitehead, M. 2001.
Evaluating summarisationtechnologies: A task-oriented approach.
In Proc.1st International Workshop on New Developmentsin Digital Libraries (NDDL-2001), InternationalConference on Enterprise Information Systems(ICEIS 2001), pages 99-112.
Setubal, Portugal.Neto, J. L., Freitas, A.
A., and Kaestner, C. A. A.2002.
Automatic Text Summarization using a Ma-chine Learning Approach.
In Proc.
16th BrazilianSymp.
on Artificial Intelligence (SBIA-2002).
Lec-ture Notes in Artificial Intelligence 2507, pp205-215.
Springer-Verlag.Radev, D. R., Teufel, S., Saggion, H., Lam, W.,Blitzer, J., Qi, H., Celebi, A., Liu, D., and Drabek,E.
2003.
Evaluation challenges in large-scaledocument summarization, in Proc.
41st AnnualMeeting of the Association for ComputationalLinguistics, pages 375-382.
Sapporo, Japan.Salton, G., Allan, J., Buckley, C., and Singhal, A.1994.
Automatic Analysis, Theme Generation, andSummarization of Machine-Readable Texts.
Sci-ence, 264(3):1421-1426.Sekine, S. and Nobata, C. 2001.
Sentence Extractionwith Information Extraction technique.
In Proc.
ofACM SIGIR'01 Workshop on Text Summarization.New Orleans.Zechner, K. 1996.
Fast generation of abstracts fromgeneral domain text corpora by extracting relevantsentences.
In Proc.
COLING-96, pages 986-989.Copenhagen, Denmark.Zhou, C., Xiao, W., Tirpak, T. M., and Nelson, P. C.2003.
Evolving Classification Rules with GeneExpression Programming.
IEEE Transactions onEvolutionary Computation, 7(6):519 ?
531.
