ParseTalk about Sentence- and Text-Level AnaphoraMichael Strube and Udo HahnC~Z~-  Computational Linguistics Research GroupFreiburg UniversityD-79085 Freiburg, Germany{strube, hahn}@coling.uni-freiburg.deAbstractWe provide a unified account of sentence-leveland text-level anaphora within the framework ofa dependency-based grammar model.
Criteria foranaphora resolution within sentence boundariesrephrase major concepts from GB's binding theory,while those for text-level anaphora incorporate anadapted version of a Grosz-Sidner-style focus model.1 IntroductionThis paper treats the resolution of anaphora with-in the framework of Parse Talk, a dependency-oriented grammar model that incorporates strictlexicalization, head-orientation (based on valencyspecifications), feature unification, and inheri-tance among lexicalized grammar specifications(Br6ker et al, 1994; Hahn et al, 1994).
The re-sults we present rest upon two major assumptions:1.
As many forms of anaphors (e.g., nomi-nal and pronominal anaphors) occur withinsentence boundaries (so-called intra-sententialor sentence anaphora) and beyond (inter-sentential or text anaphora), adequate theo-ries of anaphora should allow the formulationof grammatical regularities for both types us-ing a common set of grammatical primitives.2.
Anaphora are only one, yet very prominentphenomenon that yields textual cohesion indiscourse.
Adequate grammars hould there-fore also be easily extensible to cover non-anaphoric text phenomena (e.g., coherence re-lations, rhetorical predicates), which providefor additional levels of text (macro) structure,with descriptions tated at the same level oftheoretical sophistication as for anaphora.First, we will briefly compare our approach withwork done in the context of government-binding(GB) grammar and discourse representation the:ory (DRT).
As we conceive it, binding theory asdeveloped within the GB framework (Chomsky,1981; Kuno, 1987) offers one of the most sophis-ticated approaches for treating anaphora t thesentence level of description.
This has also beenrecognized by advocates of competing rammarformalisms, who have elaborated on GB's bind-ing principles (cf., e.g., Pollard and Sag (1992)within the context of HPSG, whose treatment isnevertheless restricted to reflexive pronouns).
In-terestingly enough, when faced with some cru-cial linguistic phenomena, such as topicalization,GB must assume rather complex movement oper-ations in order to cope with the data in a satisfac-tory manner.
Things get even more complicatedwhen languages with relatively free word order,such as German, are taken into account.
Finally,considering the case of text anaphora, binding the-ory has nothing to offer at all.Another strong alternative for considering ana-phora constitutes the framework of DRT (Kampand Reyle, 1993).
Its development can be con-sidered a landmark in the model-theoretic se-mantic analysis of various forms of quantifiedsentences, conditionals, and anaphorically linkedmulti-sentential discourse.
At this level of descrip-tion, DRT is clearly superior to GB.
On the otherhand, its lack of an equally thorough treatment ofcomplex syntactic onstructions makes it inferiorto GB.
These deficits are no wonder, since DRT isnot committed to any particular syntactic theory,and thus cannot place strict enough syntactic on-straints on the admissible constituent structures.Focusing on the text analysis potential of DRT, itscomplex machinery might work in a satisfactoryway for several well-studied forms of anaphora,but it necessarily fails if various non-anaphorictext phenomena need to be interpreted.
This isparticularly true of conceptually-rooted and prag-matically driven inferences necessary to build uptextual macro structures in terms of coherencerelations (Hobbs, 1982) or rhetorical structures(Mann and Thompson, 1988).
This shortcomingis simply due to the fact that DRT is basically ase-mantic theory, not a comprehensive model for textunderstanding; it lacks any systematic onnec-237tion to comprehensive r asoning systems coveringthe conceptual knowledge and specific problem-solving models underlying the chosen domain.Summing up, DRT is fairly restricted both withrespect o the incorporation of powerful syntacticconstraints at the sentence level and its extensionto the level of (non-anaphoric) text macro struc-tures.
GB, on the other hand, is strong with re-spect to the specification of binding conditions atthe sentence level, but offers no opportunity at allto extend its analytic scope beyond that sententiallevel.
We claim, however, that the dependency-based grammar model underlying ParseTalk1.
covers intra-sentential naphora at the samelevel of descriptive adequacy as current GB, al-though it provides less complex representationstructures than GB analyses; these structuresare nevertheless expressive nough to capturethe relevant distinctions,2.
does not exhibit an increasing level of struc-tural complexity when faced with crucial lin-guistic phenomena which cause considerableproblems for current GB theory,3.
goes beyond GB in that it allows the treat-ment of anaphora t the text level of descrip-tion within the same grammar formalism as isused for sentence level anaphora, and,4.
goes beyond the anaphora-centered treatmentof text structure characteristic of the DRT ap-proach in that it already accounts for the reso-lution of text-level ellipsis (sometimes also re-ferred to as functional anaphora, cf.
Hahn andStrube (1995)) and the interpretation of textmacro structures (a preliminary study is pre-sented in Hahn (1992)).2 DG Const ra in ts  on  AnaphoraIn this section, we present, quite informally, someconstraints on intra-sentential naphora in termsof dependency grammar (DG).
We will reconsiderthese constraints in Section 3, where our grammarmodel is dealt with in more depth.
We providehere a definition of d-binding and two constraintswhich describe the use of reflexive pronouns andanaphors (personal pronouns and definite nounphrases).
These constraints cover approximatelythe same phenomena as the binding theory of GB(Chomsky (1981); for a computational treatment,cf.
Correa (1988)).Dependency structures, by definition, refer tothe sentence level of linguistic description only.The relation of dependency holds between a lexi-cal head and one or several modifiers of that head,such that the occurrence of a head allows for theoccurrence of one or several modifiers (in somepre-specified linear ordering), but not vice versa.Speaking in terms of dependency structure rep-resentations, the head always precedes and, thus,(transitively) governs its associated modifiers inthe dependency tree.
This basic notion of govern-ment must be further refined for the descriptionof anaphoric relations in dependency trees (we donot claim a universal status for the following con-straints, but restrict their validity to the descrip-tion of the German language):D-b ind lng:  A modifier M is d-bound by somehead H, if no node N intervenes between M and Hfor which one of the following conditions holds:(i) node N represents a finite verb, or(ii) node N represents a noun with a possessivemodifier, i.e., possessive determiners, Saxon geni-tive, genitival and prepositional attributes.Based on the definition of d-binding, we are ableto specify several constraints on reflexive pronounsand anaphors in DG terms:Ref lex ive pronoun:The reflexive pronoun and the antecedent to whichthe reflexive pronoun refers are d-bound by thesame head.P ronomina l  and  nomina l  anaphors :(i) The antecedent c~ to which an anaphor ~rrefers must not be governed by the same headwhich d-binds 7r, unless (ii) applies.
(ii) The antecedent ~ to which an anaphor  refersmay only be governed by the same head H1 whichd-binds 7r, if (~ is a modifier of a head Hg, H2 isgoverned by H1, and a precedes 7r in the linearsequence of text items.
Hence, a is not d-boundby the head H1 which d-binds 7r.
IWe will now illustrate the working of these con-straints, starting with the consideration of reflex-ives.
Usually, the antecedent of a reflexive pro-noun is the subject of the clause to which the re-flexive belongs.
In (1), the subject Maria is d-bound by the same head as the reflexive sich.
(1) Mariai w~scht sichi.\[Maryi washes herselfi.\]Of course, the government relation between an-tecedent and reflexive need not be an immediateone.
For instance, a preposition may occur be-tween reflexive and verb, since the notion of d-binding does not discriminate between NPs andPPs (of.
(2)).
If the finite verb is a modal or aux-iliary verb, one or more non-finite verbs may occurbetween the reflexive and the finite verb (cf.
(3)).1 The definition of d-binding roughly corresponds tothe governing categoryin GB terminology, which reliesupon the notion of c-command, while the latter twogrammar constraints correspond to the three majorbinding principles of GB.238(2) Mariai lacht fiber sichi.\[Mary/ laughs about herself~.\](3) Maria/ m5chte sichi verbessern.\[Maryi wants to improve herselfi.\]If an intermediate node occurs between reflexiveand antecedent which denotes a noun with a pos-sessive modifier, the reflexive is d-bound by thisnoun (cf.
(4) vs. (5)); hence, that modifier is theantecedent of the reflexive.
Though Maria is thesubject of (4), only Peter can be considered theantecedent of the reflexive, since it is d-bound bythe head which d-binds Peter, viz.
Geschichte (cf.Fig.
1).
If the intermediate noun has no posses-sive modifiers, the subject of the entire clause isthe antecedent of the reflexive, since the reflexiveis d-bound by the finite verb irrespective of theoccurrence of the (object) NP (cf.
(6)).erz  ~a.
l .
tMaz?1 Gemo..h?c~tepObj~Figure 1: Dependency Tree for Examples 4 and 5(4) Maria erz~.hlt Peters/ Geschichte fiber sich/.\[Mary tells Peter's/ story about himself/.\](5) * Maria/ erz?hlt Peters Geschichte fiber sich/.\[* Mary/ tells Peter's story about herself/.\](6) Maria/ erz~hlt eine Geschichte fiber sichi.\[Maryi tells a story about hersel/i.\]We will now consider constraints on intra-sentential anaphora (personal pronouns and def-inite NPs).
As a general rule, the anaphor mustnot occupy the position of the reflexive pronoun.Hence, for all the examples given above, any ofthose sentences becomes ungrammatical if the re-flexives are replaced by non-reflexive anaphoricexpressions (of.
(7) vs.
(2)).
(7) * Maria/ lacht fiber siei.\[* Mary/ laughs about her/.\]It is also obvious that whenever the anaphor be-longs to a clause which is subordinate to one thatcontains the antecedent, both may be coreferent:this holds independently of the ordering of an-tecedent and pronoun (cf.
(8) vs. (11)).
On theother hand, if the anaphor belongs to the ma-trix clause and the antecedent to the subordinateclause, coreference is excluded (cf.
(9)).
But onecan easily think of cases where this rule is overrid-den.
Consider, e.g., a subordinate clause preced-ing its matrix, as is always true for topicalizations.The claim that a pronoun in the superordinateclause must not be coreferent to an antecedentin a subordinate clause is then obviously false (cf.
(10) and (11)).
In (10), the antecedent Peteris notd-bound by the head which d-binds the anaphorer, and Peter precedes er.
Therefore, coreferenceis possible.
2(8) Peter/ erwartet, daft eri einen Brief bekommt.\[Peter/ expects that he/ will get a letter.\](9) * Er/ erwartet, daft Peter/ e/hen Brief bekommt.\[ * He/ expects that Peter/ will get a letter.\](10) DaB Peteri e/hen Brief bekommt, erwartet er / .\[That Peter/ will get a letter, hei expects.\](11) DaB er/ e/hen Brief bekommt, erwartet Peter/.\[That hel will get a letter, Peter/ expects.\]Another special case arises if the antecedent is amodifier of the subject of a sentence.
In this casethe antecedent of a pronoun may be governed bythe head which d-binds the pronoun.
In (12) thepronoun belongs to the subordinate clause, but in(13) the antecedent of the pronoun belongs to thesubordinate clause, and the example seems to beacceptable.
In (14), where the subject Valet ismodified by the genitive attribute des Gewinners,the antecedent is governed by the head which alsod-binds the pronoun.
Both the relative clause andthe genitive attribute are modifiers of the subject,which usually occurs at the first position in theGerman main clause.
In this case, the antecedentprecedes the anaphor.
Hence, coreference betweenanaphor and antecedent must be granted.
3(12) Der Mann, der siei kennt, grfiflt die Fraui.\[The man who knows heri greets the womani.\](13..) Der Mann, der die Frau/ kennt, grfiflt siei.\[The man who knows the woman/ greets heri.\](14) Der Vater des Gewinnersi gratuliert ihm/.\[The winner's/father congratulates himi.\]The incorporation of an ordering constraint iseven more justified if one looks at sentences whichhave a similar structure, but are different with re-spect to word order (cf.
(15) vs. (16)).
In (15), thesubordinate clause immediately follows its headword, while in (16) the subordinate clause is ex-traposed.
In (16) the anaphor precedes its an-tecedent, which is governed by the head that d-binds the anaphor.
This violates the given con-straints, hence coreference is excluded.2GB explains topicalizatiou with a move of the top-icalized CP into the SpecComp hrase of the highestCP, so that the pronoun does not c-commandits an-tecedent (in these cases movements into an A-positionare assumed for which the binding principles of GB donot apply).3GB explains this phenomenon by linking the mod-ifiers to the subject as adjuncts.
In this position, thepronoun does not c-command the antecedent, and theadjunct of the subject is also in an A-position.239(15) Die Frage, ob Peteri nach Dublin fahren sollte,konnte eri noch nicht beantworten.\[The question, whether Peteri should go to Dublin,hei couldn't decide.\](16) * Die Frage konnte eri noch nicht beantworten,ob Peteri nach Dublin fahren sollte.\[* The question hei couldn't decide, whether Peterishould go to Dublin.\]Structural constraints are necessary conditions,but additional criteria have to be considered whendetermining the antecedent of an anaphor.
Mor-phosyntactic onditions require that a pronounmust agree with its antecedent in gender, num-ber and person, while a definite NP must agreewith its antecedent in number only.
Moreover,conceptual criteria have to be met as in the caseof nominal anaphors which must subsume theirantecedents at the conceptual level.
Similarly,for pronominal anaphors the selected antecedentmust be permitted in those conceptual roles con-necting the pronominal anaphors and its gram-matical head.The DG constraints for the use of reflexives andintra-sentential anaphora cover approximately thesame phenomena s GB, but the structures usedby DG analysis are less complex than those ofGB and do not require the formal machineryof empty categories, binding chains and complexmovements (cf.
Lappin and McCord (1990, p.205)for a similar argument).
Hence, our proposal pro-vides a more tractable basis for implementation.3 Major Grammatical  PredicatesThe ParseTalk model of DG (Hahn et al, 1994)exploits inheritance as a major abstraction mech-anism.
The entire lexical system is organized asa hierarchy of lexical classes (isac denoting thesubclass relation among lexical classes), with con-crete lexical items forming the leave nodes of thecorresponding lexicon grammar graph.
Valencyconstraints are attached to each lexical item, onwhich the local computation of concrete depen-dency relations between a head and its associatedmodifier is based.
These constraints incorporatecategorial knowledge about word classes and mor-phosyntactic knowledge involving complex featureterms as used in unification grammars.The definition of the grammatical predicates be-low is based on the following conventions: II de-notes the unification operation, 2_ the inconsis-tent element.
Let u be a complex feature termand !
a feature, then the extraction u\l yieldsthe value of l in u.
By definition, u\l gives _l_in all other cases.
In addition, we supply ac-cess to conceptual knowledge via a KL-ONE-styleclassification-based knowledge representation lan-guage.
The concept hierarchy consists of a set ofconcept names ~" = {COMPUTERSYSTEM, NOTE-BOOK, MOTHERBOARD, ...} and a subclass rela-tion isaF = {(NOTEBOOK, COMPUTERSYSTEM),(PCI-MOTHERBOARD, MOTHERBOARD), ...} Cx 9 r. roles C f" x 9 v is the set of relationswith role names "R = {has-part, has-cpu, ...} anddenotes the established relations in the knowledgebase, while R characterizes the labels of admittedconceptual relations.
The relation permit C 9 v x"R x 9 r characterizes the range of possible con-ceptual relations among concepts, e.g., (MOTn-ERBOARD, has-cpu, CPU) E permit.
Furthermore,object.attribute d notes the value of the propertyattribute at object and the symbol self refers tothe current lexical item.
The ParseTalk specifi-cation language, in addition, incorporates topo-logical primitives for relations within dependencytrees.
The relations left and head denote "~ oc-curs left of y" and "x is head of y' ,  resp.
Theseprimitive relations can be considered eclarativeequivalents to the procedural specifications usedin several tree-walking algorithms for anaphoraresolution, e.g., by Hobbs (1978) or Ingria andStallard (1989).
Note that in the description be-low tel + and rel* denote the transitive and transi-tive/reflexive closure of a relation rel, respectively.x d-binds y :<:~(x head + y)A -~q z: ((x head + z) A (z head + y)A (z isac* finiteVerbV 3u: (z head uA ((z spec u A u isac* DetPossessive)V (z saxGen u A u isac* Noun)V (z ppAtt u A u isac* Noun)V (z genAtt u A u isac* Noun)))))Box 1: D-bindingThe possible antecedents hat can be reachedvia anaphoric relations are described by the pred-icates isPotentialReflexi~eAntecedentOf (eft Box2) and isPotentialAnaphoricAntecedentOf(cf.
Box3).
These incorporate the predicate d-binds (of.Box 1) which formally defines the correspondingnotion from Section 2.
The evaluation of the ma-x isPotentialReflexiveAntecedentOf y :?
?.3 z: (z d-binds y A z d-binds x)Box 2: isPotentialRefleziveAntecedentOfjor predicate, isPotentiaIAnaphoricAntecedentOf(cf.
Box 3), determines the candidate set of possi-ble antecedents for (pro)nominal anaphors, and240x isPotentialAnaphoricAntecedentOf y :~:~--,3 z: (z d-binds x A z d-binds y)A (x left + yV --,=1 u: (u d-binds yA (u head + x)))Box 3: isPotentialAnaphoricAntecedentOfthus characterizes the notion of teachability informal terms.
The use of constraints as filtersbecomes evident through the further restrictionof this set by the predicates adapted to partic-ular grammatical relations, thus taking the no-tion of satisfiability into account.
For instance,the predicate PronAnaphorTest from Box 4 con-tains the grammatical constraint for pronominalanaphors according to which some pronoun andits antecedent must agree in gender, number, andperson, and the conceptual constraint describedin Section 2.
The predicate NomAnaphorTestfrom Box 5 captures the conceptual constraintfor nominal anaphors uch that the concept towhich the antecedent refers must be subsumed bythe concept o which the anaphoric noun phrase.refers.
Additionally it tests whether the defi-nite NP agrees with the antecedent in number.These two predicates cover the knowledge relatedto the resolution of intra-sentential as well asinter-sentential naphora.
Note the equivalenceof grammatical nd conceptual conditions withina single constraint.
All these predicates form partof the computation process aiming at the resolu-tion of anaphora s described in Section 4.PronAnaphorTest (pro, ante):?
:~ante isac* Noun A((pro.features\selt~agr\gen)LJ(ante.features\self~agr\gen) ?
_L) A((pro.features \ elf\agr\num)U(ante.features\self~agr\nurn) # _L) A((pro.features\self~agr\pers)Ll(ante.features\self~agr\pers) # .1_) ^Vx V role E R:(x head pro A(x.concept, pro.concept) E roles=~(x.concept, role, ante.concept) E permit)Box 4: PronAnaphorTestNomAnaphorTest (defNP, ante):~ante isac* Noun A((defNP.features \sel~agr\num)U(ante.features\sel~ag,\num) # _L) ^ante.concept isaF* defNP.conceptBox 5: NomAnaphorTest4 Resolut ion of AnaphoraThe ParseTaik environment builds on the actorcomputation model (Agha and Hewitt, 1987) asbackground for the procedural interpretation oflexicalized dependency specifications in terms ofso-called word actors (of.
Schacht et al 1994;Hahn et al 1994).
Word actors combine object-oriented features with concurrency ielding strictlexical distribution and distributed computationin a methodologically clean way.
The modelassumes word actors to communicate via asyn-chronous message passing.
An actor can send mes-sages only to other actors it knows about, its so-called acquaintances.
The arrival of a message atan actor is called an event; it triggers the execu-tion of a method that is composed of atomic ac-tions - among them the evaluation of grammaticalpredicates.
As we will show, the specification ofa particular message protocol corresponds to thetreatment of fairly general inguistic tasks, suchas establishing dependencies, properly arrangingcoordinations, and, of course, resolving anaphors.Consequently, any of these subprotocols consti-tutes part of the grammar specification proper.We shall illustrate the linguistic aspects ofword actor-based parsing by introducing the basicdata structures for text-level anaphora s acquain-tances of specific word actors, and then turn to thegeneral message-passing protocol that accountsfor intra- as well as inter-sentential naphora.Our exposition builds on the well-known focus-ing mechanism (Sidner, 1983; Grosz and Sidner,1986).
Accordingly, we distinguish each sentence'sunique focus, a complementary list of alternatepotential loci, and a history list composed of dis-course elements not in the list of potential loci,but occurring in previous entences of the currentdiscourse segment.
These data structures are re-alized as acquaintances of sentence delimiters torestrict the search space beyond the sentence tothe relevant word actors.The protocol evel of analysis encompasses theprocedural interpretation of the declarative con-straints given in Section 2.
At that level, in thecase of reflexive pronouns, the search for the an-tecedent is triggered by the occurrence of a reflex-ive pronoun in the text.
Upon instantiation of thecorresponding word actor, a SearchRefAntecedentmessage will be issued.
The distribution strategyof the message incorporates the syntactic restric-tions for the appearance ofa reflexive pronoun andits possible antecedent.
This can be described interms of two phases:1.
In phase 1 the message is forwarded from itsinitiator to the word actor which d-binds the241initiator.
Only if the message reaches a finiteverb or a noun which has a possessive modifieris a new message with phase 2 sent, and themessage in phase I terminates.
On any otheroccasion (e.g., the head of the initiator is apreposition or a non-finite verb) the messageis simply passed on to the receiver's head.2.
In phase 2 the message is forwarded to thesubject of the finite verb or, if a noun d-bindsthe reflexive, to the possessive modifier of thenoun.Only nouns or personal pronouns are capable ofresponding to SearchRefAntecedenl messages.
Ifthe search for an antecedent is successful, a Ref-AntecedentFound message is sent directly to theinitiator of the search message which changes itsconcept identifier accordingly.For pronominal anaphors, the search for the an-tecedent is triggered by the occurrence of a per-sonal pronoun.
Upon instantiation of the cor-responding word actor, a SearchPronAnlecedentmessage will be sent.
For nominal anaphors, thesearch for the antecedent is triggered by the at-tachment of a definite article as a modifier to itshead noun, so that a SearchNomAntecedent mes-sage will be issued.
Since the structural criteriafor the sentence position of both types of anaphorsare the same, the distribution mechanisms under-lying the corresponding messages can be describedby their common superclass, SearehAntecedent.
Itsdistribution strategy incorporates the syntacticrestrictions for the appearance of both elementsinvolved, anaphor and antecedent.
This can bedescribed in terms of three main phases:1.
In phase 1, the message is forwarded from itsinitiator to the head which d-binds the initia-tor.
Only if the message reaches this head aretwo further messages with phases la and 2 sentsimultaneously, and the message in phase I ter-minates.
On any other occasion (e.g., the headof the pronoun is a preposition) the message issimply passed on to the receiver's head.
(a) In phase la the modifiers of the initia-tor's direct head are tested, in order todetermine if any of these modifiers havemodifiers themselves.
When the test suc-ceeds, the message is forwarded to thesemodifiers, where the anaphor predicates( PronAnaphorTest or NomAnaphorTest)are evaluated in parallel.2.
In phase 2 the message is forwarded from thehead which d-binds the initiator (the originalsender) to the word actor which represents thesentence delimiter of the current sentence.
If onthat path the message ncounters a head whichd-binds the sender (mediating messages fromthe initiator), that head may possibly governan antecedent in its subtree.
New messageswith phase 2a are sent (their number dependson how many modifiers of the head exist).
(a) In phase 2a the message is forwarded fromthe head which d-binds the sender to eachof its modifiers (excluding the sender of themessage), where both anaphor predicatesare evaluated.3.
Phase 3 is triggered independently from phase1 and 2.
The path leads from the initiator tothe sentence delimiter of the previous entence,where its state is set to phase 3a.
(a) In phase 3a the sentence delimiter's ac-quaintances Focus and PotFoci are testedfor the anaphor predicates.Note that only nouns or personal pronouns arecapable of responding to SearchAn~ecedent mes-sages and test whether they fulfill the requiredcriteria for an anaphoric relation.
If  any of theanaphor predicates ucceeds, the determined an-te6edent sends an AntecedentFound message di-rectly to the initiator of SearchAntecedent; thismessage carries the concept identifier of the an-tecedent.
The initiator of the SearchAnteeedentmessage, viz.
the anaphor, upon receipt of the An-tecedentFound message changes its concept identi-fier accordingly.
This update of the concept iden-tifier is the final result of anaphora resolution, achange which accounts for the coreference betweenconcepts denoted by different lexical items at thetext level.We now discuss the protocol for establishinganaphoric relations based on intra- and inter-sentential anaphora considering the following text:(17) Die Firma Cornpaq, die den LTE-Lite entwik-kelt, bestiickt ihn mit einem PCI-Motherboard.Der Rechner hat eine Taktfrequenz yon 50 Mhz.\[The company Compaq, which develops the LTE-Lite, equips it with a PCI-motherboard.
The sys-tem comes with a clock frequency of 50Mhz.\]In the first sentence of (17), the SearchAnteeedentmessage is caused by the occurrence of the per-sonal ihn (cf.
Fig.
2 which depicts two instancesof anaphora resolution).
In phase 1, the messagereaches the finite verb bestiickt, where two newinstances of the message are created.
In phase2 it takes the path to the sentence delimiter ofthe current sentence (no effect).
In phase la, themessage reaches the subject Firma, which is theleftmost modifier of the verb, and determines thenoun LTE-Lite as the only possible antecedent ofihn.
The success of PronAnaphorTesl leads to thesending of an AntecedentFound message, the re-sult of which is the update of the concept identi-242- - -~*  searchA~tecedent message...... :~ antecedentFound message\[ .1~iiiii!iiiiii I "o ' '~ : ' , ' - - '~- .~ ..... "~0" '1  iiiiii::::::i:i ~.... :;!iiiii L ~ '~L"~'  " ?
J iiii::i:: .'!i::.........
~`~!~ii~i~ii~ii!iii~iiiiiiiiiii~i!iiiii~!iiiiiii~i~iiiiiii~iiiiiii~i~iiiii;i~:i~::~ ...........l a  .
.
.
.
.
.
.
~ i ~ ?
$ s tx I .
~ \[hat\]/ \- \[ihn\] \[mit\] t' \[Rechne:\]  .
.\[Die\] \[Compaq\] \ [entwieke l t  \] .-"" ?
\[PCI -Motherboard \ ]  IDeal'"- .
.
.
.
.
.
.
.
- -  ~ ?
.
?
\[die\] \[LTE Lite\]  ~ ' "  \[elaem\] ......"/ ........ ~-; .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
........\[den\] ....................................................... "'"Die  F i rma Cc~paq,The company Compaq,die den LTg-L i te  entwicke l t ,  bestfickt ihn mi t  einem PCI-Motherboard.
Der Rechner hat ...whiGh the LTE-Lite develops, equips it with a PCl-motherboard.
The system comes .
.
.Figure 2: Sample Communication Protocoltier of ihn with that of LTE-Lite.
Simultaneously,a SearchPronAntecedent message in phase 3 takesthe path to the sentence delimiter of the previ-ous sentence, where it evaluates PronAnaphorTestwith respect o its acquaintances Focus and Pot-Foci (no effect).The second sentence of (17) contains the def-inite noun phrase der Rechner.
The search ofan antecedent is triggered by the attachment ofthe definite article to the noun.
In phase 1 themessage reaches the finite verb hat, where newinstances of the message are created.
Phase layields no positive results and the message termi-nates.
In phase 2 the message takes the path fromthe finite verb to the sentence delimiter (no effect).Since there are no possible antecedents withinthe sentence, in phase 3 possible antecedents arechecked which are stored as the acquaintances Fo-cus and PotFoci of the sentence delimiter for theprevious entence.
Since Rechner subsumes LTE-Life at the conceptual level, NomAnaphorTestsucceeds.
An Antecedent\[bund message is cre-ated, which changes the concept identifier of Rech-her appropriately.5 Comparison to Related WorkFrom the linguistic viewpoint, sentence anaphora,so far, have only been sketchily dealt with by de-pendency grammarians, e.g., by Hudson (1984;1990).
The most detailed escription of grammat-ical regularities and an associated parsing proce-dure has been supplied by Lappin and McCord(1990).
It is based on the format of a slot grammar(SG), a slight theory variant of DG.
In particular,they treat pronominal coreference and anaphora(i.e., reflexives and reciprocals).
Our approachmethodologically differs in three major aspectsfrom that study: First, unlike the SG proposal,which is based on a second-pass algorithm operat-ing on fully parsed clauses to determine anaphoricrelationships, our proposal is basically an incre-mental single-pass parsing model.
Most impor-tan't, however, is that our model incorporates thetext-level of anaphora resolution, ashortcoming ofthe original SG approach that has recently beenremoved (Lappin and Leass, 1994), but still is asource of lots of problems.
Third, unlike our ap-proach, even the current SG model for anaphoraresolution does not incorporate conceptual knowl-edge and global discourse structures (for reasonsdiscussed by Lappin and Laess).
This decisionmight nevertheless cause trouble if more conceptu-ally rooted text cohesion and coherence structureshave to be accounted for (e.g., textual ellipses).A particular problem we have not yet solved,the plausible ranking of single antecedents froma candidate set, is dealt with in depth by Lappinand Laess (1994) and Hajicova et al (1992).
Bothdefine salience metrics capable of ordering alter-native antecedents according to structural crite-ria, several of which can directly be attributed tothe topological structure and topic/comment an-notations of the underlying dependency trees.2436 Conc lus ionsWe have outlined a model of anaphora resolutionwhich is founded on a dependency-based gram-mar model.
This model accounts for sentence-levelanaphora, with constraints adapted from GB, aswell as text-level anaphora, with concepts closeto Grosz-Sidner-style focus models.
The associ-ated text parser is based on the actor computationmodel.
Its message passing mechanisms constitutethe foundation for expressing specific linguisticprotocols, e.g., that for anaphora resolution.
Themain advantage of our approach lies in the unifiedframework for sentence- and text-level anaphora,using a coherent grammar format, and the pro-vision for access to grammatical and conceptualknowledge without prioritizing either one of them.It is also a striking fact that, given the same lin-guistic phenomena, structural dependency config-urations are considerably simpler than their GBcounterparts, though suitably expressive.The anaphora resolution module (for reflexives,intra- and inter-sentential naphora) has been re-alized as part of ParseTalk, a dependency parserwhich forms part of a larger text understandingsystem for the German language, currently underdevelopment at our laboratory.
The parser hasbeen implemented in Smalltalk; the Smalltalk sys-tem itself, which runs on a SUN SparcStation et-work, has been extended by asynchronous messagepassing facilities and physical distribution mecha-nisms (Xu, 1993).
The current lexicon contains ahierarchy of approximately 100 word class specifi-cations with nearly 3.000 lexical entries and corre-sponding concept descriptions from two domains(information technology and medicine) availablefrom the LOOM knowledge representation system(MacGregor and Bates, 1987).Acknowledgments.
We would like to thank our col-leagues in the CZ~Z) r group who read earlier versionsof this paper.
In particular, improvements are due todiscussions we had with S. Schacht, N. Br6ker, P. Neu-haus, and M. Klenner.
We also like to thank J. Alcan-tara (CorneU U) who kindly took the role of the nativespeaker via Internet.
This work has been funded byLGFG Baden- Wiirttemberg (1.1.4-7631.0; M. Strube)and a grant from DFG (Ha 2907/1-3; U. Hahn).ReferencesAgha, G. and Hewitt, C. (1987).
Concurrent program-ming using actors.
In A.Yonezawa nd M.Tokoro(Eds.
), Object-Oriented Concurrent Programming.Cambridge/MA: MIT Pr., pp.37-53.Brfker, N., Hahn, U., and Schacht, S. (1994).
Concur-rent lexicalized ependency parsing: the ParseTalkmodel.
Proc.
COLING '9~.
Kyoto, Japan.
Vol.1,pp.379-385.Chomsky, N. (1981).
Lectures on Government andBinding.
Dordrecht: Foris.Correa, N. (1988).
A binding rule for government-binding parsing.
Proc.
COLING '88.
Budapest,Hungary.
Vol.1, pp.123-129.Grosz, B. J. and Sidner, C. L. (1986).
Attention, in-tentions, and the structure of discourse.
Computa-tional Linguistics, 1~.
(3), 175-204.Hahn, U.
(1992).
On text coherence parsing.
Proc.COLING '9~.
Nantes, France, Vol.
1, pp.25-31.Hahn, U., Schacht, S., and BrSker, N. (1994).
Con-current, object-oriented dependency parsing: theParse Talk model.
International Journal of Human-Computer Studies, 41.
(1/2), 179-222.Hahn, U. and Strube, M. (1995).
ParseTalk aboutText-Level Ellipsis.
Freiburg University, CLIF Tech-nical Report.Hajicova, E., Kubon, V., and Kubon, P. (1992).
Stockof shared knowledge: a tool for solving pronominalanaphora.
Proc.
COLING "92.
Nantes, France, Vol.1, pp.127-133.Hobbs, J.
(1978).
Resolving pronoun references.
Lin-gua, 44.
311-338.Hobbs, J. R. (1982).
Towards an understanding of co-herence in discourse.
In Lehnert, W. and Ringle, M.(Eds.
), Strategies \]or Natural Language Processing.Hillsdale/NJ: Erlbaum, pp.
223-243.Hudson, R. (1984).
Word Grammar.
Oxford: Black-well.Hudson, R. (1990).
English Word Grammar.
Oxford:Blackwell.Ingria, R. and Stallard, D. (1989).
A computationalmechanism for pronominal reference.
Proc.
ACL"89.
Vancouver, Canada, pp.262-271.Kamp, H. and Reyle, U.
(1993).
From Discourse toLogic.
Dordrecht: Kluwer.Kuno, S. (1987).
Anaphora and discourse principles.In Nagao, M.
(Ed.
), Language and Artificial Intel-ligence.
Amsterdam: North-Holland, pp.87-111.Lappin, S. and Leass, H. J.
(1994).
An algorithmfor pronominal anaphora resolution.
ComputationalLinguistics, ~0.
(4), 535-561.Lappin, S. and McCord, M. (1990).
Anaphora reso-lution in slot grammar.
Computational Linguistics,16.
(4), 197-212.MacGregor, R. and Bates, R. (1987).
The LOOMKnowledge Representation Language.
iSI ReprintSeries, ISI/RS-87-188, Univ.
of Southern California.Mann, W. C. and Thompson, S. A.
(1988).
Rhetoricalstructure theory: toward a functional theory of textorganization.
Text, & (3), 243-281.Pollard, C. and Sag, I.
A.
(1992).
Anaphors in Englishand the scope of binding theory.
Linguistic Inquiry,~3.
(2) 261-303.Schacht, S., Hahn, U., and BrSker, N. (1994).
Concur-rent lexicalized ependency parsing: a behavioralview on ParseTalk events.
Proc.
COLING '94.
Ky-oto, Japan, Vol.l., pp.489-493.Sidner, C. L. (1983).
Focusing in the comprehensionof definite anaphora.
In Brady, M. and Berwick, R.(Eds.
), Computational Models o\] Discourse.
Cam-bridge/MA: MIT Pr., pp.267-330.Xu, W. (1993).
Distributed, Shared and Persistent Ob-jects.
A Model \]or Distributed Object- Oriented Pro-gramming.
London University, Dept.
of ComputerScience (Ph.D.Diss.
).244
