Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 146?149,Paris, October 2009. c?2009 Association for Computational LinguisticsGuessing the Grammatical Function of a Non-Root F-Structure in LFGAnton BrylCNGL,Dublin City University,Dublin 9, IrelandJosef van GenabithCNGL,Dublin City University,Dublin 9, Ireland{abryl,josef,ygraham}@computing.dcu.ieYvette GrahamNCLT,Dublin City University,Dublin 9, IrelandAbstractLexical-Functional Grammar (Kaplan andBresnan, 1982) f-structures are bilexicallabelled dependency representations.
Weshow that the Naive Bayes classifier is ableto guess missing grammatical function la-bels (i.e.
bilexical dependency labels) withreasonably high accuracy (82?91%).
Inthe experiments we use f-structure parseroutput for English and German Europarldata, automatically ?broken?
by replacinggrammatical function labels with a genericUNKNOWN label and asking the classifierto restore the label.1 IntroductionThe task of labeling unlabelled dependencies, asub-task of dependency parsing task, can occurin transfer-based machine translation (when onlyan inexact match can be found in the trainingdata for the given SL fragment) or in parsingwhere the system produces fragmented output.
Insuch cases it is often reasonably straightforwardto guess which fragments are dependent on whichother fragments (e.g.
in transfer-based MT).
Whatis harder to guess are the labels of the dependen-cies connecting the fragments.In this paper we systematically investigate thelabelling task by automatically deleting functionlabels from Lexical-Functional Grammar-basedparser output for German and English Europarldata, and then restoring them using a Naive Bayesclassifier trained on attribute names and attributevalues of the f-structure fragments.
We achieve82% (German) to 91% (English) accuracy for bothsingle and multiple missing function labels.The paper is organized as follows: in Section 2we define the problem and the proposed solutionmore formally.
Section 3 details the experimentalevaluations, and in Section 4 we present our con-clusions.????????
?PRED ?adopt?UNKNOWN f1????
?PERS 3NUM sgPRED ?resolution?SPEC f2[ DET f3 [PRED ?the?]]????
?SUBJ f4?
?PERS 3NUM sgPRED ?Parliament???????????
?Figure 1: Example of a ?broken?
f-structure (sim-plified).
The sentence is ?Parliament adopted theresolution.?
The missing function of f1 is OBJ.2 Guessing Unknown GrammaticalFunctionsLet us introduce some useful definitions.
By de-pendent f-structure of the parent f-structure fP wemean an f-structure fd which bears a grammati-cal function within fP , or belongs to a set whichbears a grammatical function within fP .
E.g., inFigure 1 f2 is a dependent f-structure of f1.
In thispaper we will not distinguish between these twosituations, but simply refer to multiple f-structuresbearing the same function within the same parentfor set-valued grammatical functions.
C(?, fP )denotes the number of dependent f-structures offP which bear the grammatical function ?
in fP(either directly or as members of a set).Let us formalize the simple case when the gram-matical function of only one dependent f-structureis missing.
Let FP be the set of f-structures whichhave a dependent f-structure with an UNKNOWN la-bel instead of the grammatical function.
Let ?
bethe set of all grammatical functions of the givengrammar.
We need a guessing function G : FP ?
?, such that G(fP ) is a meaningful replacementfor the UNKNOWN label in fP .
As the set ?
is fi-nite, the problem is evidently a classification task.F-structures are characterized by attributessome of which potentially carry information aboutthe f-structure?s grammatical function, even if146Language N-GF N-DEP AVG-DEP MIN-DEP MAX-DEPEnglish 24 9724 1.57 1 5German 39 10910 1.55 1 5Table 1: Data used in the evaluation.
N-GF is the number of different grammatical functions occurringin the dataset.
N-DEP is the number of dependent f-structures in the test set.
AVG-DEP, MIN-DEP,MAX-DEP is the average, min.
and max.
number of dependant structures per parent in the test set.we observe these attributes completely separatelyfrom each other.
For example, it seems likelythat an f-structure with an ATYPE attribute is anADJUNCT, while an f-structure which has CASEis probably a SUBJ or an OBJ.
Given this, NaiveBayes appears to be a promising solution here.
Be-low we describe a way to adapt this classifier to theproblem of grammatical function guessing.Let ?P ?
?
be the set of grammatical functionswhich are already present in fP .
Let ?
= {?1..?n}be the set of features, and let X = {x1..xn} bethe values of these features for the f-structure fdfor which the function should be guessed.
Thenthe answer ?d is chosen as follows:?d = arg max???(p(?
)MP (?
)n?i=1p(?i = xi|?
))(1)MP (?)
={p(C(?, fP ) > 1), if ?
?
?P1, otherwise (2)where the probabilities are estimated from thetraining data.
Equation (2) states that if ?
is al-ready present in the parent f-structure, the proba-bility of ?
being set-valued is considered.We propose two ways of building the featureset ?.
First, it is possible to consider the pres-ence/absence of each particular attribute in fd asa binary feature.
Second, it is possible to con-sider atomic attribute values as features as well.To give a motivating example, in many languagesthe value of CASE is extremely informative whendistinguishing objects from subjects.
We use onlythose atomic attribute values which do not rep-resent words.
E.g., NUM, PRED or NUM=sg arefeatures, while PRED=?resolution?
is not afeature.
This distinction prevents the feature setfrom growing too large and thus the probabilityestimates from being too inaccurate.If grammatical functions are missing for sev-eral dependent f-structures, it is possible to usethe same approach, guessing the missing func-tions one by one.
In general, however, these de-cisions will not be independent.
To illustrate this,let us consider a situation when the functions areto be guessed for two dependent f-structures ofthe same parent f-structure, OBJ being the correctanswer for the first and SUBJ for the second.
Ifthe guesser returns SUBJ for the first of the two,this answer will not only be incorrect, but also de-crease the probability of the correct answer for thesecond by decreasing MP (SUBJ) in Equation (1).This suggests that in such cases maximization ofthe joint probability of the values of all the miss-ing functions may be a better choice.3 Experimental EvaluationWe present two experiments which assess the ac-curacy of the proposed approach and compare dif-ferent variants of it in order to select the best, andan additional one which assesses the usefulness ofthe approach for practical machine translation.3.1 Data Used in the EvaluationFor our experiments we used sentences fromthe German-English part of the Europarl cor-pus (Koehn, 2005) parsed into f-structures withthe XLE parser (Kaplan et al, 2002) using En-glish (Riezler et al, 2002) and German (Butt etal., 2002) LFGs.
We parsed only sentences oflength 5?15 words.
For the first two experiments,we picked 2000 sentences for training and 1000for testing for both languages.
We ignored robust-ness features (FIRST, REST), functions related toc-structure constraints (MOTHER, LEFT SISTER,etc.
), and TOPIC.
Of the remaining functions, weconsidered only those occurring in the PREDs-only part of f-structure.
If a dependent f-structurehas multiple functions within the same parent f-structure, only the first function occurring in thedescription is considered.
This does not unduelyinfluence the results, as the grammatical functionof an f-structure, after exclusion of TOPIC, carriesmultiple labels in only about 2% of the cases in theEnglish data and about 1% in the German data.
InTable 1 we provide some useful statistics to helpthe reader interpret the results of the experiments.147Language MF NB-CASE NB-N NB-N&VEnglish 36.3% 56.7% 85.6% 91.6%German 23.4% 51.0% 74.8% 82.5%Table 2: Experiment 1: Guessing a Single Miss-ing Grammatical Function.
MF is the pick-most-frequent classifier.
NB-CASE is Naive Bayes(NB) with only CASE values used as features.
NB-N is NB with only attribute names used as fea-tures.
NB-N&V is NB with both attribute namesand atomic attribute values used as features.3.2 Experiment 1: Guessing a Single MissingGrammatical FunctionThe goal of this experiment is to evaluate the ac-curacy of the Bayesian guesser in the case whenthe grammatical function is unknown only for onedependent f-structure, and to assess whether theinclusion of attribute values into the feature setimproves the results, and whether attributes otherthan CASE are useful.Procedure.
As a baseline, we used a pick-most-frequent algorithm MF which considers only thefunction?s prior probability and the presence ofthis function in the parent (returning to Equations(1) and (2), MF is in fact Naive Bayes with anempty feature set ?).
The guesser was evaluatedin three variants: NB-CASE with the feature setformed only from the values of CASE attributes(if the f-structure has no CASE feature, the classi-fier degenerates to MF), NB-N with the feature setformed only from attribute names, and NB-N&Vwith the feature set formed from both attributenames and values.
All grammatical functions inthe test set were used as test cases.
At each step inthe evaluation, one function was removed and thenguessed by each algorithm.
For both languages thetest set was split into 10 non-intersecting subsetswith approximately equal numbers of grammati-cal functions in each, and the values obtained forthe 10 subsets were further used to assess the sta-tistical significance of the differences in the resultswith the paired Student?s t-test.Results.
Table 2 presents the results.
For bothEnglish and German all the three versions of theclassifier clearly outperform the baseline, and eventhe advantage of NB-CASE over the baseline isstatistically significant at the 0.5% level for bothlanguages.
However, NB-CASE performs muchworse than NB-N and NB-N&V (their advantageover NB-CASE is statistically significant at the0.5% level for both languages), confirming thatLanguage MF NB-S NB-JEnglish 22.0% 90.4% 91.2%German 17.1% 81.4% 82.1%Table 3: Experiment 2: Guessing Multiple Miss-ing Functions.
MF is the pick-most-frequent clas-sifier.
NB-S and NB-J are one-by-one and join-probability-based Naive Bayesian guessers.CASE is not the only feature which is useful inour task.
The increase in accuracy brought aboutby including the atomic attribute values into thefeature space is visible and significant at the samelevel.
The increase is somewhat more pronouncedfor German than for English.
For English the in-clusion of attribute values into the feature spaceaffects primarily the accuracy of SUBJ vs. OBJdecisions.
For German, the accuracy notably in-creases for telling SUBJ, OBJ and ADJ-GEN fromone another.3.3 Experiment 2: Guessing MultipleMissing Grammatical FunctionsThe goal of this experiment is to assess the accu-racy of the Bayesian guesser for multiple miss-ing grammatical functions within one parent f-structure, and to compare the accuracy of one-by-one vs. joint-probability-based guessing.
Ourevaluation procedure models the extreme casewhen the functions are unknown for all the depen-dent f-structures of a particular parent.Procedure.
As a baseline, we use the same al-gorithm MF as in Experiment 1, applied to themissing grammatical functions one by one.
TwoBayesian guessers are evaluated, NB-S guessingthe missing grammatical functions one by one, andNB-J guessing them all at once by maximizingthe joint probability of the values.
Both Bayesianguessers use attribute names and values as fea-tures.
All grammatical functions in the test setwere used as test cases.
At each step of the ex-periment, the grammatical functions of all the de-pendent f-structures of a particular parent wereremoved simultaneously, and then guessed witheach of the algorithms considered in this experi-ment.
Statistical significance was assessed in thesame way as in Experiment 1.Results.
Table 3 presents the accuracy scores.The one-by-one guesser and the joint-probability-based guesser perform nearly equally well, result-ing in accuracy levels very close to those obtainedin Experiment 1 for f-structures with a single148missing function.
Joint-probability-based guess-ing achieves an advantage which is statisticallysignificant at the 0.5% level for both languagesbut is not exceeding 1% absolute improvement.For both languages errors typically occur in distin-guishing OBJ vs. SUBJ and ADJUNCT vs. MOD,and additionally in XCOMP vs. OBJ for English.3.3.1 Experiment 3: Postprocessing theOutput of an MT DecoderThe goal of this experiment is to see how themethod influences the results of an SMT system.Procedure.
For this experiment we use the SulisSMT system (Graham et al, 2009), and a decoder,which selects the transfer rules by maximizing thesource-to-target probability of the complete trans-lation.
Such a decoder, though simple, allows usto create a realistic environment for evaluation.From the f-structures produced by the decoder,candidate sentences are generated with XLE, andthen the one best translation is selected for eachsentence using a language model.
The functionguesser is used to postprocess the output of thedecoder before sentence generation.
In the ex-periment, the function guesser uses both attributenames and values to make a guess.
Guessing ofmultiple missing functions is performed one-by-one, as joint guessing complicates the algorithmand leads to a very small improvement in accuracy.The function guesser is trained on 3000 sentences,which are a subset of the set used for inducing thetransfer rules.
The overall MT system is evaluatedboth with and without function guessing on 500held-out sentences, and the quality of the transla-tion is measured using the BLEU metric (Papineniet al, 2002).
We also calculate the number of sen-tences for which the generator output is unempty.Results.
The system without function guesserproduced results for 364 sentences out of 500,with BLEU score equal to 5.69%; with functionguesser the number of successfully generated sen-tences increases to 433, with BLEU improving to6.95%.
Thus, the absolute increase of BLEU scorebrought about by the guesser is 1.24%.
This sug-gests that the algorithm succeeds on real data andis useful in grammar-based machine translation.4 ConclusionIn this paper we addressed the problem of restor-ing unknown grammatical functions in automati-cally generated f-structures.
We proposed to viewthis problem as a classification task and to solveit with the Naive Bayes classifier, using the namesand the values of the attributes of the dependentf-structure to construct the feature set.The approach was evaluated on English andGerman data, and showed reasonable accuracy,restoring the missing functions correctly in about91% of the cases for English and about 82% forGerman.
It is tempting to interpret the differencesin accuracy for English and German as reflectingthe complexity of grammatical function assign-ment for the two languages.
It is not clear, how-ever, whether the differences are due to differencesin the grammars or in the underlying data.The experiments reported here use LFG-typerepresentations.
However, nothing much in themethod is specific to LFG, and therefore we areconfident that our method also applies to otherdependency-based representations.AcknowledgmentsThe research presented here was supported by Sci-ence Foundation Ireland grant 07/CE2/I1142 un-der the CNGL CSET programme.ReferencesM.
Butt, H. Dyvik, T. H. King, H. Masuichi, andC.
Rohrer.
2002.
The parallel grammar project.In COLING?02, Workshop on Grammar Engineer-ing and Evaluation.Y.
Graham, A. Bryl, and J. van Genabith.
2009.
F-structure transfer-based statistical machine transla-tion.
In LFG?09 (To Appear).R.
Kaplan and J. Bresnan.
1982.
Lexical functionalgrammar, a formal system for grammatical represe-nation.
The Mental Representation of GrammaticalRelations, pages 173?281.R.
M. Kaplan, T. H. King, and J. T. Maxwell III.
2002.Adapting existing grammars: the XLE experience.In COLING?02, Workshop on Grammar Engineer-ing and Evaluation.P.
Koehn.
2005.
Europarl: A parallel corpus for sta-tistical machine translation.
In MT Summit X, pages79?86.K.
Papineni, S. Roukos, T. Ward, and W. Zhu.
2002.BLEU: a method for automatic evaluation of ma-chine translation.
In ACL?02, pages 311?318.S.
Riezler, T. H. King, R. M. Kaplan, R. Crouch,J.
T. Maxwell III, and M. Johnson.
2002.
Pars-ing the wall street journal using a lexical-functionalgrammar and discriminative estimation techniques.In ACL?02, pages 271?278.149
