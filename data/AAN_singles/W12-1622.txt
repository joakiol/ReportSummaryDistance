Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 150?159,Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational LinguisticsGlobal Features for Shallow Discourse ParsingSucheta Ghosh Giuseppe Riccardi Richard JohanssonUniversity of Trento, Italy University of Gothenburg, Sweden{ghosh,riccardi}@disi.unitn.it richard.johansson@gu.seAbstractA coherently related group of sentencesmay be referred to as a discourse.
Inthis paper we address the problem of pars-ing coherence relations as defined in thePenn Discourse Tree Bank (PDTB).
Agood model for discourse structure anal-ysis needs to account both for local depen-dencies at the token-level and for globaldependencies and statistics.
We presenttechniques on using inter-sentential orsentence-level (global), data-driven, non-grammatical features in the task of parsingdiscourse.
The parser model follows upprevious approach based on using token-level (local) features with conditional ran-dom fields for shallow discourse parsing,which is lacking in structural knowledgeof discourse.
The parser adopts a two-stage approach where first the local con-straints are applied and then global con-straints are used on a reduced weightedsearch space (n-best).
In the latter stagewe experiment with different rerankerstrained on the first stage n-best parses,which are generated using lexico-syntacticlocal features.
The two-stage parser yieldssignificant improvements over the bestperforming model of discourse parser onthe PDTB corpus.1 IntroductionThere are relevant studies on the impact of globaland local features on the models for naturallanguage understanding.
In this work we ad-dress a similar problem in the context of dis-course parsing.
Although a good number ofthe papers in this area heavily rely on localclassifiers (Grosz et al, 1995; Soricut et al, 2003;Lapata, 2003; Barzilay et al, 2005), there are stillsome important works using global and localinformations together to form a model of dis-course (Grosz et al, 1992; Barzilay et al, 2004;Soricut et al, 2006).One of the main issues is the basis of the choicebetween a global or local or a joint model for dis-course parsing: it all depends on the criteria to beable to capture maximum amount of informationinside the discourse model.
The policy for dis-course segmentation plays a big role to formulatethe maximizing criteria (Grosz et al, 1992).
Westudy in the literature that defining a discourse seg-ment is mostly a data-driven process: some arguefor prosodic units, some for intentional structureand some for clause-like structures.
We work withPDTB 2.0 annotation framework, therefore use aclause-like structure.
Soricut et al (2003) empiri-cally showed that at the sentence level, there is astrong correlation between syntax and discourse,Ghosh et al (2011b) found the same.
Since thediscourse structure may span over multiple sen-tences, intersentential features are needed to im-prove the performance of a discourse parser.Linguistic theory suggests that a core argumentframe (i.e.
a pair of the Arg1 and the Arg2 con-nected with one and only one connective) is a jointstructure, with strong dependencies between ar-guments (Toutanova et al, 2008).
Following this,Ghosh et al (2011a) also injected some structure-level information through the token-level features,for eg.
the previous sentence feature.
Still thereis a room for improvement with more structure-level information to that discourse model; thoughit is cost-intensive to modify this discourse model.Therefore in this paper we re-use the model(Ghosh et al, 2011a) and optimize the current lossfunction adding the global features through re-ranking of the single-best model.Reranking has been a popular techniqueapplied in a variety of comparable NLPproblems including parsing (Collins, 2000;150Charniak and Johnson, 2005), semanticrole labeling (Toutanova et al, 2008), NPBracketing (Daume III et al, 2004), NER(Collins, 2002), opinion expression detection(Johansson and Moschitti, 2010), now we employthis technique in the area of discourse parsing.In the next sections, we detail on the back-grounds and motivations of this work, before thiswe also add a short discussion on PDTB (PennDiscourse TreeBank), i.e.
the data we used to trainthe system.
Then we proceed to the reranking ap-proaches and results sections after describing ourglobal feature set.
Finally we state and analyze theresults.2 The Penn Discourse Treebank 2.0The Penn Discourse Treebank (PDTB) is a re-source containing one million words from theWallStreet Journal corpus (Marcus et al, 1993) anno-tated with discourse relations.Connectives in the PTDB are treated as dis-course predicates taking two text spans as ar-guments (Arg), i.e.
parts of the text that de-scribe events, propositions, facts, situations.
Suchtwo arguments in the PDTB are called Arg1 andArg2, with the numbering not necessarily corre-sponding to their order in text.
Indeed, Arg2 isthe argument syntactically bound to the connec-tive, while Arg1 is the other one.In the PDTB, discourse relations can be eitherovertly or implicitly expressed.
However, we fo-cus here exclusively on explicit connectives andthe identification of their arguments, including theexact spans.
This kind of classification is verycomplex, since Arg1 and Arg2 can occur inmany different configurations (see Table 1).Explicit connectives (tokens) 18, 459Explicit connectives (types) 100Arg1 in same sentence as connective 60.9%Arg1 in previous, adjacent sentence 30.1%Arg1 in previous, non adjacent sentence 9.0%Table 1: Statistics about PDTB annotation from Prasad etal(2008).In PDTB the senses are assigned according to athree-layered hierarchy: the top-level classes arethe most generic ones and include TEMPORAL,CONTINGENCY, COMPARISON and EXPANSIONlabels.
We used these four surface senses only inour task.2.1 Backgrounds & MotivationCurrently we are using the single-best discourseparser by Ghosh et al (2011a).
This discourseparser can automatically extract of discourse ar-guments using a pipeline, illustrated in Fig 1.First, we input the explicit discourse connec-tives (with senses) to the system.
These canbe the gold labeled or automatically identified(Pitler and Nenkova, 2009); for simplicity here weuse Penn Discourse TreeBank (PDTB 2.0) gold-standard connectives (cf.
see 2).
Then a cascadedmodule is applied extracting the Arg2 arguments,then the Arg1s are extracted.Figure 1: Pipeline for argument detection given a connec-tive.The Arg2 and Arg1 extractors are imple-mented as conditional random field sequence la-belers, which use a set of syntactic and structuralfeatures (cf.
Ghosh et al (2011a)).
In order to re-duce the complexities, the sentence containing theconnective, and a context window of up to twosentences before and after are supplied to the se-quence labelers.We present a passage of 6 sentences from a nu-trition journal article parsed with that parser 1.:<Conn id=1,sense=Comparison>Although</Conn id=1> <ARG2 id=1>the mechanism of obesity developmentis not fully understood, it is confirmed<ARG1 id=2>that obesity occurs</ARG1 id=2><Conn id=2,sense=Temporal>when</Conn id=2><ARG2 id=2>energy intake exceeds energyexpenditure</ARG2 id=2> </ARG2 id=1>.There are multiple etiologiesfor this imbalance, hence,<Conn id=3, sense=Expansion>and </Conn id=3> <ARG2 id=3>the risingprevalence of obesity cannot be addressedby a single etiology</ARG2 id=3>.<ARG1 id=4>Genetic factors influencethe susceptibility of a given child to anobesity-conducive environment</ARG1 id=4>.<Conn id=4, sense=Comparison>However1we used best model of (Ghosh et al, 2011b;Ghosh et al, 2011a) and Stanford lexicalized parser(Klein and Manning, 2003) to parse the text also usedAddDiscourse tool to parse the connective and the senses(Pitler and Nenkova, 2009);parser took 17 second to parse151</Conn id=4>, <ARG2 id=4>environmentalfactors, lifestyle preferences, andcultural environment seem to play majorroles in the rising prevalence of obesityworldwide</ARG2 id=4>.
In a small numberof cases, childhood obesity is due togenes such as leptin deficiency ormedical causes such as hypothyroidismand growth hormone deficiency or sideeffects due to drugs (e.g.
- steroids).Most of the time, <Conn id=5, sense=Comparison> however </Conn id=5>,<ARG2 id=5>personal lifestyle choicesand cultural environment significantlyinfluence obesity</ARG2 id=5>.In the evaluations of Ghosh et al (2011a), itstates that recall was much lower than preci-sion for both the arguments, especially in case ofArg1.
The system often failed to predict Arg1.
Itis harder to identify since it is not always syntac-tically bound to the connective, like Arg2, more-over it is typically more distant than the Arg2s.We notice the same in the parser output.
Theparser found all five Arg2s for all five connec-tives, though there may be disagreement on the se-lected boundaries; the number of parsed Arg1s isonly two, whereas the second one with id of 4 is aprevious sentence argument.To improve the recall, (Ghosh et al, 2012)implemented a weighted constraint-basedhandcrafted postprocessor to force theGhosh et al (2011a) system to output argu-ments of each type abiding the requirementsdefined by the PDTB annotation guidelines.In order to find the best solution with a min-imum of constraint violations, the top k analy-ses output are generated by the CRF (ConditionalRandom Field) (Lafferty et al, 2001) for everysentence; these analyses can then be combined toform the k top analyses for the whole 5-sentencewindow around the connective.
This combina-tion is most efficiently carried out using a prior-ity queue similar to a chart cell in the k-best pars-ing algorithm by Huang and Chiang (2005).
(seeGhosh et al (2012) for details)2.2 Feature Set of Baseline SystemWe summarize the feature set of the base system(Ghosh et al, 2011a) to emphasize the distinctionbetween the local and global feature set for thiswork.The token-level (local) feature set in the Table 2can be divided into four categories:Features used for Arg1 and Arg2 segmentation and labeling.F1.
Token (T)F2.
Sense of Connective (CONN)F3.
IOB chain (IOB)F4.
PoS tagF5.
Lemma (L)F6.
Inflection (INFL)F7.
Main verb of main clause (MV)F8.
Boolean feature for MV (BMV)F9.
Previous sentence feature (PREV)Additional feature used only for Arg1F10.
Arg2 LabelsTable 2: Feature sets for Arg1 and Arg2 segmentation andlabeling in base system (Ghosh et al2011a).1.
Syntactic.
{F3, F4, F6} 22.
Semantic.
{F2}3.
Lexical {F5, F7, F8}4.
Structure related token-level features.
{F9, F10}The remaining one (F1) is the token itself.
Thesense of the connective feature (F2) extracted fromPDTB for the base system, though for the fully au-tomatic one (Ghosh et al, 2011b) it needs the PTB(Penn TreeBank)-style syntactic parse trees as in-put (Pitler and Nenkova, 2009).
The IOB(Inside-Outside-Begin) chain (F3) 3 (F3) is extracted froma full parse tree and corresponds to the syntacticcategories of all the constituents on the path be-tween the root note and the current leaf node ofthe tree.
Experiments with other syntactic fea-tures proved that IOB chain conveys all deep syn-tactic information needed in the task, and makesall other syntactic information redundant, for ex-ample clause boundaries, token distance from theconnective, constituent label, etc.In order to extract the morphologicalfeatures needed, we use the morpha tool(Minnen et al, 2001), which outputs lemma (F5)and inflection information (F6) of the candidatetoken.
The latter is the ending usually added tothe word root to convey inflectional information.It includes for example the -ing and -ed suffixesin verb endings as well as the -s to form the pluralof nouns.As for features (F7) and (F8), they rely on in-formation about the main verb of the current sen-tence.
More specifically, feature (F7) is the mainverb token , extracted following the head-finding2Infection can be defined as morpho-syntactic feature.3We extracted this feature using the Chun-klink.pl script made available by Sabine Buchholz atilk.uvt.nl/team/sabine/chunklink/README.html152strategy by Yamada and Matsumoto (2003), whilefeature (F8) is a boolean feature that indicates foreach token if it is the main verb in the sentence ornot.4The structure related token-level features donot use any parse tree.
The Arg2 label (F10)features are generated from the word sequenceindex in PDTB for the base system (for au-tomatic system it is generated by the pipeline(Ghosh et al, 2011b)); this feature is used to clas-sify Arg1 .
The previous sentence feature ?Prev?
(F9) is a connective-surface feature and is usedto capture if the following sentence begins witha connective.
This is meant for the classificationof the Arg1 that resides in the previous sentenceof the connective.
The feature value for each can-didate token of a sentence corresponds to the con-nective token that appears at the beginning of thefollowing sentence, if any.
Otherwise, it is equalto 0.Although both of the structure-related featuresare strong features according to the feature analy-sis in Ghosh et al (2011a), the base system is notable to capture all available global features insidethe 5-sentence discourse context, merely uses 2-sentence context.
This is due to the fact that CRFclassifier uses a narrow window, that can only cap-ture the information nearby the token under con-sideration.
Therefore it becomes impossible toinject more information about the 5-sentence dis-course window structure.3 Global Feature SetWe use a global feature-set.
The global featuresare defined as the data-driven, hand-crafted rulegenerated and non-grammatical (i.e.
no syntacticparse tree is used to generate this features) fea-tures.The model of Ghosh et al (2011a) is based onConditional Random Fields (CRF), and incorpo-rating a set of structural and lexical features.
Atthe core part of the model lies a local classi-fier, which labels each token sequentially with oneof the possible argument labels or OTHER in apipeline.
Now global information can be inte-grated into the model using global features at alonger-distance context, by defining a small set ofglobal constraints (if too many dependencies areencoded, the model will over-fit the training data4We used the head rules by Yamada & Matsumoto(http://www.jaist.ac.jp/?h-yamada/)and will not generalize well).The global features are computed using eachlist of k-best lists, in contrast to the lexico-syntactically generated local features for each to-ken item for each sentence of n-best lists.
Theusage of global feature is meant for exploring theyet undiscovered dimension of the each 5-sentencediscourse window.
Global feature set consists ofthe eight features that works on a full 5-sentencediscourse window (cf.
sec.
2.1).
The first six (i.e.GF0-GF5) of these are same with the constrainedsystem 2.1.None of the features are extracted from anyparse tree.
All the seven features (GF1-GF7) arederived from the generated Arg tags of the n-best lists, the first one is the logarithm of poste-rior probability computed from the CRF posteriorprobability output for each list of the n-best lists.The finer description of each feature is given be-low.GF0.
logarithm of Posterior Probability.
thisfeature is generated by the base CRF classifier.The CRF generates probability per sentence, foreach list of the n-best lists.
We calculate sum ofthe log of each probability during generation of k-best lists forming 5-sentence discourse window.GF1.
Overgeneration.
It is possible for an ar-gument to be split into more than one part in samesentence, we found these cases several times inPDTB.
This constraint is violated if an Arg1 orArg2 is split over multiple sentences.
This is apredominant problem for those lists of the n-bestlists those are generated with low posteriors.
Thisfeature exhibits the problem of overgeneration tothe reranker with the counts.GF2.
Undergeneration.
According to PDTBannotation scheme every connective must have ar-guments of each type, this constraint is violated ifan argument is missing.
This is the prevalent prob-lem in the single-best system, especially for theArg1 classification.
This feature works to spec-ify where a discourse structure missing the argu-ment(s) - one of the main problems that motivatedthis work.GF3.
Intersentential Arg2 (used only for Arg2reranker).
Count of Arg2, if any, occurs classifiedoutside connective sentence - this way the systemis constrained to have any inter-sentential Arg2.This is a hypothetically motivated feature to re-duce the complexity of the classification problem;although in fact in PDTB 2.0, there are a few cases153of Arg2 of explicit connective (i.e.
the 114 outof 18459), where it extends beyond the connec-tives sentence to include additional sentences inthe subsequent discourse (Prasad et al, 2008).GF4.
Arg1 after the connective sentence.
Countof Arg1, if any, occurs classified after connec-tive sentence.
Through this feature we attempt toconstrain the system to have Arg1s always occur-ring in the previous sentence or before the previ-ous sentence of the connective sentence.GF5.
Argument overlapping with the connec-tive.
Count of the cases if there is any token over-lap between Args and connective tokens.
This isalso not possible for the PDTB-style annotation,so we intend to constrain the overlapping, if any.GF6.
Argument begins with -I tag.
Count ofthe cases if the generated Arg chunks begins withthe -I (inside) tag, violating the principle of IOBtags for chunking.
This is only possible if the CRFchunker fails to tag the boundaries properly.GF7.
Argument begins with -E tag.
Count ofthe cases if the generated Arg chunks begins withthe -E (end) tag instead of a -B(begin) tag.
This isalso possible if only the CRF chunker fails to tagthe chunk boundaries properly.We attempt to categorize this feature set accord-ing to the properties they bear: {GF0} is the in-trinsic global feature - it is the evidence of confi-dence on decisions made by the single-best model;{GF1, GF2} check the prevalent problems seenthrough the evaluation of decisions by the sin-gle best model; {GF3, GF4, GF5} are the hy-pothetical global features those reduce classifica-tion complexities, they are inspired by the generaltrends or rules for annotation in PDTB.
{G6, G7}check the mistakes in IOB tagging by the CRFchunker.4 Reranking ApproachesWe formalize the reranking algorithm as follows:for a given sentence s, a reranker selects the bestparse y?
among the set of candidates candidate(s)according to some scoring function:y?
= argmaxy?candidate(s)score(y) (1)In n-best reranking, candidate(s) is simply a setof n-best parses from the baseline parser, that is,candidate(s) = {y1, y2, ..., yn}.In this paper we followed two approaches forthe reranking task:1.
Structured Learning Approach: in this casethe reranker learns directly from a scoring func-tion that is trained to maximize the performance ofthe reranking task (Collins and Duffy, 2002).
Wealso investigate two popular and efficient onlinestructured learning algorithms: the structuredvoted perceptron by Collins and Duffy (2002)and Passive-Aggressive(PA) algorithm byCrammer et al (2006).
The weight-vectorsobserved from the training phase are averagedfollowing Schapire and Freund (1999).
In case ofstructured perceptron for each of the candidate ina ranked list the scoring function of equation 1 iscomputed as follows:score(yi) = w ??
(xi,j) (2)where w is the parameter weight-vector and ?
isthe feature representing function of xi,j ; xi,j de-notes the j-th token of the i-th sentence.
Sincethe PA algorithm is based on the theory of large-margin, it attempts find a score that violates themargin maximally by adding an extra cost i.e.??
(xi,j) to the basic score function for structuredperceptron i.e.
equation 2.
Here ?
is computedas 1 ?
F (xi.j), F: F-measure.
The online PA alsotakes care of the learning rate of perceptron, whichis considered as 1 in structured perceptron.
Thelearning rate in online PA is min-value between aregularization constant and normalized score func-tion value.2.
Best vs. rest Approach: in the prefer-ence kernel approach (Shen and Joshi, 2003) thereranking problem is reduced to a binary classi-fication task on pairs.
This reduction enables evena standard support vector machine to optimize theproblem.
We use a component of this task.
Wedefine the best scored discourse window (section4.1) as a positive example and the rest are the neg-atives to the system.
We use a standard supportvector machine (Vapnik, 1995) with linear kernel.3.
Preference Kernel Approach: we also inves-tigated the classical approach of preference ker-nel, as it is introduced by (Shen and Joshi, 2003).In this method, the reranking problem learning toselect the correct candidate h1 from a candidateset {h1, ?
?
?
, hk} is reduced to a binary classifi-cation problem by creating pairs: positive traininginstances ?h1, h2?, ?
?
?
, ?h1, hk?
and negative in-stances ?h2, h1?, ?
?
?
, ?hk, h1?.
The advantage ofusing this approach is that there are abundant toolsfor binary machine learning.If we have a kernel K over the candidatespace T , we can construct a preference kernel154(Shen and Joshi, 2003) PK over the space of pairsT ?
T as follows:PK = K(h11, h12) + K(h21, h22)?
K(h11, h22) ?
K(h21, h12) (3)In our case, we make pair from the n-besthypotheses hi as ?h1i , h2i ?
generated by the basemodel.
We used linear kernel to train the reranker.Thus we create the feature vectors extractedfrom the candidate sequences using the featuresdescribed in Section 3.
We then trained linearSVMs (Support Vector Machine) using the LIB-LINEAR software (Fan et al, 2008), using L1 lossand L2 regularization.4.1 ExperimentsWe use PennDiscourse TreeBank(Prasad et al, 2008) and Penn TreeBank(Marcus et al, 1993) data through this entirework.
We keep the split of data as follows:02 ?
22 folders of PDTB (& PTB) are used fortraining, 23 ?
24 folders of the same are usedfor testing; remaining 00-01 folders are meantfor development split, it is used only to study theimpact of feature (cf.
5).We prepare the n-best outputs of sentences fromthe base system (cf.
2.1).
The training data is pre-pared from the input of n-best lists of the trainsplit, using a oracle module, which generates k-best oracle lists from the n-best single outputs.
Weprocure k-best lists from oracle using the evaluatormodule (see section 4.2), ordered by the highest tothe lowest probability score.
Each of the list of thek-best list is a 5-sentence discourse window.We prepare the test data given the n-best listsof the test split.
We obtain k-best list for test-ing, prepared with the module described in sec-tion 2.1.
We re-integrate the sentences con-nected with the same discourse connective idinto the 5-sentence discourse window keeping theconnective-bearing sentence in the middle.
Thisre-integration done using a priority queue in thestyle of Huang and Chiang (2005).
Each of the listfrom the k-best list are ordered by the highest tothe lowest score with sum of the log of posteriorprobabilities of each sentence in the n-best list.Therefore, in short, the n-best list is the list ofsentence-level analyses whereas the k-best list isthe list of 5-sentence discourse window-level anal-yses.Baseline: we consider the performance of thesingle-best output from the base implementation(cf.
2.1) as the baseline.4.2 EvaluationWe present our results using precision,recall and F1 measures.
FollowingJohansson and Moschitti (2010), we use threescoring schemes: exact, intersection (or partial),and overlap scoring.
In the exact scoring scheme,a span extracted by the system is counted ascorrect if its extent exactly coincides with onein the gold standard.
We also include two otherscoring schemes to have a rough approximationof the argument spans.
In the overlap scheme,an expression is counted as correctly detected ifit overlaps with a gold standard argument.
Theintersection scheme assigns a score between 0 and1 for every predicted span based on how much itoverlaps with a gold standard span, so unlike theother two schemes it will reward close matches.4.3 Classifier ResultsARG1 Results ARG2 ResultsExact P R F P R FBaseline 69.88 48.51 57.26 83.44 75.14 79.07Online PA 66.10 53.92 59.39(16) 82.59 76.39 79.37(4)Struct Per 67.18 52.64 59.03(4) 82.96 76.28 79.48(8)BestVsRest 66.19 52.83 58.94(8) 81.69 77.14 79.35(4)Pref-Linear 66.54 53.31 59.20(4) 82.82 76.28 79.42(4)Table 3: Exact Match Results for four classifiers.
Baselinescores in the first row.
Used n-best list numbers in parenthe-sis.
The best performances are boldfaced.We observe that reranking with global featuresimproved the F1 scores for Arg1 significantly, al-though for Arg2 the improvement is insignificant5.
Since in most of the cases the Arg2 is syntacti-cally bound with the connective, it is obvious thatlexico-syntactically motivated local features helpthe classification of Arg2.
On the other hand, theclassification of Arg1 is considerably dependenton non-grammatical, hand-crafted rule generatedfeatures.
If we compare to our reranking clas-sification results of Arg1 with that one withoutprevious sentence feature in Ghosh et al (2011a)then we observe that the global and globally moti-vated structural feature improved the classification5Throughout this work the permutation test is usedto compute the significance of difference, whereas tocompute the confidence interval bootstrap resampling isused(Hjorth, 1993).
We determined the significant digits forpresenting results using the methods illustrated by WeissteinE.
W. (Weisstein, 2012)155of Arg1 by more than 10 points.We also notice from the table for both the argu-ment classification cases that we achieve balancedscores in terms of the precision and the recall withthe structured global features.
In fact there is agood improvement of recall without much lossin terms of precision.There is not any significantimprovement in case of Arg2 reranking becausethe problem of the classification mostly resides onboundary detection of Arg2; also we know thatestimation of position of an Arg2 is pretty easytask given the connective is correctly identified.ARG1 Results ARG2 ResultsExact P R F P R FBaseline 82.90 61.65 70.72 93.40 84.20 88.56Online PA 80.11 69.43 74.39(16) 92.94 85.73 89.19(4)Struct Per 81.18 67.03 73.43(4) 93.20 85.50 89.17(8)BestVsRest 81.25 66.46 73.11(8) 93.03 85.16 89.1(4)Pref-linear 80.55 68.49 74.03(4) 93.12 85.56 89.18(4)Table 4: Partial Match Results for four classifiers.
Baselinescores in the first row.
Used n-best list numbers in parenthe-sis.
The best performances are boldfaced.We mark an improvement of the Arg1 in table4, with softer partial evaluation metrics; we alsoobserve the same trend in results for Arg2 classi-fication as in the table 3.4.3.1 Candidate Set SizeWe conduct experiments to study the influence ofcandidate set size on the quality of reranked out-put.
In addition we also attempt to notice theupper-bound of reranker performance, i.e.
the ora-cle performance.
We choose the reranker based ononline PA among the four classifier.
Since all thefour classifiers performed comparably the sameway, it is enough to study the performance of oneof them on candidate set size, that will reflect theperformance of the other classifiers.
We also de-scribe and discuss the results on the exact partialmeasures only, as we notice from the previous sec-tion that the effect of reranking is comparable withthe exact measure and softer measures.Reranked ARG1 Oraclek P R F P R F1 69.88 48.51 57.26 69.88 48.51 57.262 67.26 52.34 58.87 81.26 61.70 70.144 66.39 53.56 59.29 88.35 71.91 79.298 66.11 53.86 59.36 92.47 79.09 85.2616 66.10 53.92 59.39 93.80 83.77 88.50Table 5: Oracle and reranker performance as a function ofcandidate set size of Arg1.In both the tables (5, 6) we notice that the ora-Reranked ARG2 Oraclek P R F P R F1 83.44 75.14 79.07 83.44 75.14 79.072 82.90 75.69 79.13 90.13 82.43 86.114 82.59 76.39 79.37 92.27 86.53 89.318 82.41 76.44 79.32 92.81 88.13 90.4116 83.41 76.44 79.32 92.82 88.54 90.63Table 6: Oracle and reranker performance as a function ofcandidate set size of Arg2.cle performance is steadily increasing with 16-bestlists.
We observe that the performance of classi-fication of both Arg1 and Arg2 increases at thelevel of 2-best list then it stagnates after 4-best per-formance.
This nature of increment is may be re-lated to the simple but high-level feature set usedin this task of the discourse parsing; and it can alsobe some issues involved with local feature set, aswe observed a huge difference of posterior proba-bilities between the single-best and the each of the(n ?
1) lists of a n-best decision by CRF.4.3.2 Reranked Intersentential ARG1We also attempt to observe the effect with respectto inter-sentential classification in case of Arg1,with the results obtained with online PA percep-tron.
As expected, the change we notice the ef-fects in the table 7 is a fraction of potential im-provement.
We find comparing the inter-sententialvs.
overall classification results of Arg1 that theincrement in inter-sentential Arg1 classificationconsiderably contribute to the overall Arg1 clas-sification.P R F1Baseline Exact 52.87 27.80 36.44Partial 68.93 41.06 51.48Overlap 79.62 41.88 54.88Best Reranked ARG1 Exact 50.41 30.04 37.56Partial 66.51 44.95 53.78Overlap 76.13 44.54 56.23Table 7: Inter-sentential Reranked Arg1 Results.5 Impact of Feature on ARG1We study the impact of global features on the per-formance on Arg1 reranker with the developmentset (cf.
Section 4.1).
We are leaving behind thefeature performance of the Arg2, as the improve-ment by the reranker for this case is not significant.The Table 8 shows the results of investigationthrough an incremental greedy-search based fea-ture selection.
All the performance steps are eval-uated with a k of 16.156This impact table starts with the log posterioronly (GF0).
This results to the best result achievedby Ghosh et al (2011a) through the hill-climbingfeature analysis.
Beside this, we also checked thatif we run the reranker with this feature only, thenit results to the baseline performance with the testsplit.Then the undergeneration feature (GF2) is cho-sen through greedy search among the other fea-tures.
It gives us, jointly with the log posterior,a significant improvement over the baseline.
Theimpact is predictable as GF2 addresses the basicproblem that has driven us to the current task.The addition of the overgeneration (GF1) fea-ture also increased the performance, though non-significantly; this feature is important for thereranker because this is meant for fixing a predom-inant overgeneration problem in the n-best lists.We observe that the F1 measure increases sig-nificantly after adding the next important feature:Arg1 after the connective sentence (GF4); in thiscase the recall increases more in comparison to theincrement in the precision.In the next step, the feature: Argument over-lapping with connective (GF5) is added.
This de-creases the F1 score a bit, though it increases theprecision lowering the recall.We reach to the second-best performance of theArg1 reranker after adding the feature: Argumentbegins with -I tag (GF6).The addition of the feature: Argument beginswith -E tag (GF7) does not improve the perfor-mance much.
It is possible that there was no suchmistake by CRF inside the test data.The scores with partial and overlap matchesshow the same trend so we leave the discussionwith them in order to avoid the redundancy.Additionally, we also perform the individ-ual effect of each of features from the set(GF1,GF2,GF4,GF5,GF6,GF7), jointly with theintrinsic feature GF0, but none other than the un-dergeneration feature increased the performanceover the baseline.The intrinsic GF0 is contributing to achieve thebaseline performance; the undergeneration (GF2)feature is also contributing significantly.
In sum-mary, the combination of features optimizes theperformance of system in terms of F1-measure bydecreasing the value of precision and raising thevalue of recall.System P R F1GF0 (Posterior Only) 73.12 50.36 59.64GF0+GF2 69.62 55.34 61.67GF0+GF2+GF1 69.92 55.21 61.70GF0+GF2+GF1+GF4 70.12 56.05 62.30GF0+GF2+GF1+GF4+GF5 72.36 53.72 61.66GF0+GF2+GF1+GF4+GF5+GF6 71.10 55.28 62.20GF0+GF2+GF1+GF4+GF5+GF6+GF7 71.84 54.82 62.19Table 8: Exact Match Results for Arg1 through Incremen-tal Feature Selection.6 ConclusionWe note a significant improvement over the bestperforming model of discourse parser on thePDTB corpus.
This is mostly contributed by thebetter performance in Arg1 classification.We also find that global features have greaterimpact on Arg1 classification than that of Arg2.We investigate that that the performance of Arg1improved by more than 10 points in terms of F1measure using the global (see Section 3) and struc-ture related features (see Ghosh et al (2011a)).This happens perhaps due to the fact Arg2 is syn-tactically bound to the connective, whereas Arg1is not.
Arg2 depends more on local features (cf.Section 2.1) than global one.
Basically this natureof dependency of Arg1 on both local and globalfeatures are inherited through the PDTB annota-tion corpus, as well the local feature dependencyof Arg2 are completely data-driven.The motivation of the paper is to make a bal-anced classification for both the Arg1 and Arg2,achieved by implementing the constrained-systemwith global features.
This enables to increase ahuge recall without losing much in terms of preci-sion.It is also observed that while the performancesof oracle of Arg1 and Arg2 are increasingsteadily, the performances of both the rerankersstagnate at or before the point of 16-best lists; thisis perhaps due to our effective, simple and smallfeature set.In this task we emphasized on and studied thedata-driven, global and non-grammatical featureset.
This syntactic parse tree independent featureset may also be effective with the dialogue dataannotated with PDTB annotation style.7 AcknowledgementThis work was partially funded by IBM Collabo-rative Faculty Award 2011 grant.157References[Barzilay et al2004] Regina Barzilay, Lillian Lee, et al2004.
Catching the drift: Probabilistic content mod-els, with applications to generation and summariza-tion.
In Proc.
of NAACL-HLT, 2004.
[Barzilay et al2005] Regina Barzilay, Mirella Lapata,et al 2005.
Modeling local coherence: an entity-based approach.
In Proceedings of the 43rd AnnualMeeting of the Association for Computational Lin-guistics (ACL05).
[Charniak and Johnson2005] E. Charniak and M. John-son.
2005.
Coarse-to-fine n-best parsing and max-ent discriminative reranking.
In Proceedings of the43rd Annual Meeting of the ACL.
[Collins and Duffy2002] Michael Collins and NigelDuffy.
2002.
New ranking algorithms for parsingand tagging: Kernels over discrete structures, andthe voted perceptron.
In ACL02.
[Collins2000] Michael Collins.
2000.
Discriminativereranking for natural language parsing.
In Compu-tational Linguistics, pages 175?182.
Morgan Kauf-mann.
[Collins2002] Michael Collins.
2002.
Ranking algo-rithms for named-entity extraction: Boosting and thevoted perceptron.
In Proceedings of ACL 2002.
[Crammer et al2006] Koby Crammer, Ofer Dekel,Joseph Keshet, Shai Shalev-Schwartz, and YoramSinger.
2006.
Online passive-aggressive algo-rithms.
Journal of Machine Learning Research,7:551?585.
[Daume III et al2004] Hal Daume III, Daniel Marcu,et al 2004.
Np bracketing by maximum en-tropy tagging and svm reranking.
In Proceedingsof EMNLP?04.
[Fan et al2008] Rong-En Fan, Chih-Jen Lin, Kai-WeiChang, Xiang-Rui Wang, et al 2008.
Liblinear:A library for large linear classification.
Journal ofMachine Learning Research.
[Ghosh et al2011a] Sucheta Ghosh, Richard Johans-son, Giuseppe Riccardi, and Sara Tonelli.
2011a.Shallow discourse parsing with conditional randomfields.
In Proceedings of the 5th International JointConference on Natural Language Processing (IJC-NLP), Chiang Mai, Thailand.
[Ghosh et al2011b] Sucheta Ghosh, Sara Tonelli,Giuseppe Riccardi, and Richard Johansson.
2011b.End-to-end discourse parser evaluation.
In Pro-ceedings of 5th IEEE International Conference onSemantic Computing, Palo Alto, CA, USA.
[Ghosh et al2012] Sucheta Ghosh, Richard Johansson,Giuseppe Riccardi, and Sara Tonelli.
2012.
Improv-ing the recall of a discourse parser by constraint-based postprocessing.
In Proceedings of Inter-national Conference on Languages Resources andEvaluations (LREC 2012).
[Grosz et al1992] B.J.
Grosz, J. Hircshberg, et al1992.
Some intonational characteristics of discoursestructure.
In Ohala et al, editors, Proceedings of theInternational Conference on Spoken Language Pro-cessing, Vol.
1, volume 1, pages 429?432.
[Grosz et al1995] B.J.
Grosz, A. K. Joshi, S. Weinstein,et al 1995.
Centering: A framework for model-ing the local coherence of discourse.
ComputationalLinguistics, 21(2).
[Hjorth1993] J. S. Urban Hjorth.
1993.
ComputerIntensive Statistical Methods.
Chapman and Hall,London.
[Huang and Chiang2005] Liang Huang and David Chi-ang.
2005.
Better k-best parsing.
In Proceed-ings of the 9th International Workshop on ParsingTechnologies (IWPT 2005), pages 53?64, Vancou-ver, Canada.
[Johansson and Moschitti2010] Richard Johansson andAlessandro Moschitti.
2010.
Syntactic and seman-tic structure for opinion expression detection.
InProceedings of the Fourteenth Conference on Com-putational Natural Language Learning, pages 67?76.
[Klein and Manning2003] Dan Klein and Christo-pher D. Manning.
2003.
Fast exact inferencewith a factored model for natural language parsing.Advances in Neural Information Processing Systems15 (NIPS 2002), Cambridge, MA: MIT Press.
[Lafferty et al2001] John Lafferty, Andrew McCallum,and Fernando Pereira.
2001.
Conditional randomfields: Probabilistic models for segmenting and la-beling sequence data.
In 18th International Conf.on Machine Learning.
Morgan Kaufmann.
[Lapata2003] Mirella Lapata.
2003.
Probabilistic textstructuring: Experiments with sentence ordering.
InProceedings of the 41st Meeting of the Associationof Computational Linguistics, pages 545?552.
[Marcus et al1993] Mitchell P. Marcus, Beatrice San-torini, and Mary Ann Marcinkiewicz.
1993.
Build-ing a Large Annotated Corpus of English: the PennTreebank.
Computational Linguistics, 19(2):313?330.
[Minnen et al2001] Guido Minnen, John Carroll, andDarren Pearce.
2001.
Applied morphological pro-cessing of English.
Natural Language Engineering.
[Pitler and Nenkova2009] Emily Pitler and AniNenkova.
2009.
Using syntax to disambiguate ex-plicit discourse connectives in text.
In Proceedingsof the 47th Annual Meeting of the Association forComputational Linguistics and the 4th InternationalJoint Conference on Natural Language Processing.
[Prasad et al2008] Rashmi Prasad, Nikhil Dinesh, AlanLee, Eleni Miltsakaki, Livio Robaldo, AravindJoshi, and Bonnie Webber.
2008.
The Penn Dis-course Treebank 2.0.
In Proceedings of the 6th158International Conference on Languages Resourcesand Evaluations (LREC 2008), Marrakech, Mo-rocco.
[Schapire and Freund1999] Robert E. Schapire andYoav Freund.
1999.
Large margin classificationusing the perceptron algorithm.
Machine LearningJournal, 37(3):277?296.
[Shen and Joshi2003] Libin Shen and Aravind Joshi.2003.
An svm based voting algorithm with appli-cation to parse reranking.
In CoNLL 2003.
[Soricut et al2003] Radu Soricut, Daniel Marcu, et al2003.
Sentence level discourse parsing using syn-tactic and lexical information.
In Proceedings of theHuman Language Technology and North AmericanAssociation for Computational Linguistics Confer-ence (HLT/NAACL), May 27-June 1.
[Soricut et al2006] Radu Soricut, Daniel Marcu, et al2006.
Stochastic coherence modeling, parameterestimation and decoding for text planning applica-tions.
In Proceedings of ACL-2006 (Poster), pages803?810.
[Toutanova et al2008] Kristina Toutanova, AriaHaghighi, Christopher D. Manning, et al 2008.Kristina toutanova, aria haghighi, and christopherd.
manning, a global joint model for semantic rolelabeling.
Computational Linguistics.
[Vapnik1995] V. Vapnik.
1995.
The Nature of Statisti-cal Learning Theory.
Springer-Verlag.
[Weisstein2012] Eric W. Weisstein.
2012.
?significantdigits.?
from mathworld?a wolfram web resource.
[Yamada and Matsumoto2003] Hiroyasu Yamada andYuji Matsumoto.
2003.
Statistical dependency anal-ysis with support vector machines.
In Proceedingsof 8th International Workshop on Parsing Technolo-gies.159
