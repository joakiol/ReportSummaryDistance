Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 721?731, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsGeneralizing Sub-sentential Paraphrase Acquisitionacross Original Signal Type of Text PairsAure?lien Max Houda BouamorLIMSI-CNRS & Univ.
Paris SudOrsay, Francefirstname.lastname@limsi.frAnne VilnatAbstractThis paper describes a study on the impact ofthe original signal (text, speech, visual scene,event) of a text pair on the task of both man-ual and automatic sub-sentential paraphraseacquisition.
A corpus of 2,500 annotated sen-tences in English and French is described, andperformance on this corpus is reported foran efficient system combination exploiting alarge set of features for paraphrase recogni-tion.
A detailed quantified typology of sub-sentential paraphrases found in our corpustypes is given.1 IntroductionSub-sentential paraphrases can be acquired from textpairs expressing the same meaning (Madnani andDorr, 2010).
If the semantic similarity of a textpair has a direct impact on the quality of the ac-quired paraphrases, it has, to our knowledge, neverbeen shown what impact the type of original sig-nal has on paraphrase acquisition.
In this work,we consider four types of corpora, which we thinkare representative of the main types of originalsemantic signals: text pairs (roughly, sentences)originating a) from independent translations of atext (TEXT), b) from independent translations of aspeech (SPEECH), c) from independent descriptionsof a visual scene (SCENE), and d) from independentdescriptions of some event (EVENT).
We will reportthe results of experiments on sub-sentential para-phrase acquisition on all these corpus types in twolanguages, English and French, and provide someanswers to the following questions: What types ofparaphrases can be found by human annotators, withwhat confidence and in which quantities?
How wellcan representative paraphrase acquisition systemsperform on each corpus type, and how performancecan be improved through combination?
On whatcorpus types can performance be improved by usingtraining material from other corpus types?
Our ex-perimental results will provide several indications ofthe differences and complementarities of the corpustypes under study, and will notably show that perfor-mance on the most readily available corpus type canbe improved by using training data from the set ofall other corpus types.We will first describe the building proceduresand characteristics of our corpora (section 2), andthen describe our experimental settings for evalu-ating paraphrase acquisition (section 3.1).
Our ex-periments will first consist of the description (sec-tion 3.2) and evaluation (section 3.3) of a systemcombination on each corpus type and then of oursystem provided with additional training data fromthe other corpus types (section 3.4).
We will finallybriefly review related work (section 4) and discussour main findings and future work (section 5).2 Collection of sentence pair corporaIn this study, we will focus on paraphrase acquisitionfrom related sentence pairs characteristic of 4 corpustypes, which correspond to different original signaltypes of text pairs illustrated by the word alignmentmatrices on Figure 1.
A corpus for each type hasbeen collected for 2 languages, English and French,and comprises 625 sentence pairs per language.
Wenow briefly describe how each corpus was built.721Itisestimatedthatthetotalannualvolumeofimportandexportwillexceed9billionUSdollars.It is anticipatedthatthe annualtotalforeigntradevolumewillexceedUS$9billion.Soheusesthephotoboothstoremindpeoplewhathelookslike.He usesthosemachinesto remindthelivingof hisface.aboyisridingonabicyclefast.a boyridesa bikeon a dirtroad.PigeonshaveanunderstandingofnumbersonparwithprimatesPigeonshavenumericalabilitiesjustlikeprimatesFigure 1: Example reference alignment matrices for(from top to bottom) TEXT, SPEECH, SCENE andEVENT.
Sure alignments appear in green or gray (identi-ties) and possible alignments in yellow.TEXT For English, we used the MTC corpus1 (de-scribed in (Cohn et al2008)) consisting of setsof news article translations from Chinese, and forFrench the CESTA corpus2 consisting of sets ofnews article translations from English.
For eachsentence cluster, we selected sentence pairs withminimal edit distance above an empirically-selectedthreshold, covering all clusters first and then select-ing from already used clusters to reach the targetnumber of sentence pairs.e.g.
It is estimated that the total annual volume of importand export will exceed 9 billion US dollars.
?
It is an-ticipated that the annual total foreign trade volume willexceed US$9 billion.SPEECH For English, we used two freely avail-able subtitle files3 of the French movies Le FabuleuxDestin d?Ame?lie Poulain and Les Choristes, and forFrench we used two subtitle files from the DesperateHousewives TV series.
We first aligned each paral-lel corpus using the algorithm described in (Tiede-mann, 2007), based on time frames and developedfor bilingual subtitles, we then filtered out sentencepairs below a minimal edit distance threshold, andmanually removed obvious errors made by the algo-rithm.e.g.
So he uses the photo booths to remind people whathe looks like.
?
He uses those machines to remind theliving of his face.SCENE We used the Multiple Video DescriptionCorpus (Chen and Dolan, 2011) obtained from mul-tiple descriptions of short videos.
Similarly to whatwe did for TEXT, we selected sentence pairs fromclusters by minimal edit distance above a threshold.An important fact is that for English we were ableto use what is described as ?verified?
descriptions.There were, however, far fewer descriptions avail-able for French, and none had the ?verified?
status.We decided to use this corpus nonetheless, but withthe knowledge that this source for French is of a sub-stantially lower quality (this corpus type will there-fore appear as ?(SCENE)?
in all tables to reflect this).e.g.
a boy is riding on a bicycle fast.
?
a boy rides a bikeon a dirt road.1http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2002T012http://www.elda.org/article125.html3http://www.opensubtitles.org722Corpus statistics Annotator agreements Tokens in paraphrase statistics500 sentence pairs 50 sentence pairs not considering identity paraphrasessure para.
possible para.# tokens # tokens per sent.
sure para.
possible para.
% tokens # tokens % tokens # tokensENGLISHTEXT 21,473 21.0 66.1 20.4 18.6 4004 12.3 2651SPEECH 11,049 10.5 79.1 10.9 17.5 1942 31.6 3500SCENE 7,783 7.5 80.5 35.2 10.9 851 14.0 1094EVENT 8,609 8.0 65.3 20.5 17.5 1506 14.5 1251FRENCHTEXT 24,641 24.0 64.6 16.6 29.2 7218 6.2 1527SPEECH 11,850 11.5 82.7 20.8 22.5 2667 16.7 1981(SCENE) 7,012 6.5 42.8 9.3 3.9 275 9.4 664EVENT 9,121 9.1 67.8 3.8 19.6 1793 9.6 876Table 1: Description of all corpora and paraphrase reference sets for English (top) and French (bottom).
Note thatSCENE for French appears within parentheses as we do not consider it of the same quality as the other corpora.EVENT We used titles of news article clustersfrom the Google News4 news aggregation service.We further refined the clustering algorithm by filter-ing out article pairs whose publication dates differedfrom more than one day.
We repeated the same se-lection procedure as for TEXT and SCENE to havea maximal cluster coverage and select more similarpairs first.e.g.
Pigeons Have an Understanding of Numbers on ParWith Primates ?
Pigeons Have Numerical Abilities JustLike PrimatesTable 1 provides various statistics for these cor-pora.
The first observation is that TEXT contains sig-nificantly larger sentences than the other types, morethan twice as long as those of SPEECH.
Annotationwas performed following the guidelines proposed byCohn et al2008)5 using the YAWAT tool (Germann,2008), except that alignments where not initially ob-tained automatically so as not to bias our annota-tors?
work (there were two annotators per language).The main guidelines that they had to follow werethat sure and possible paraphrases must be distin-guished, smaller alignments were to be prefered butany-to-any alignments may be used, and sentencesshould be aligned as much as possible.
Henceforth,we will only consider for all reported statistics andexperiments those paraphrases that are not identitypairs (e.g.
(a nice day ?
a nice day)), as they are4http://news.google.com5See http://staffwww.dcs.shef.ac.uk/people/T.Cohn/paraphrase_guidelines.pdfconsidered trivial as far as acquisition is concerned.Table 1 also reports inter-annotator agreement6values computed on sets of 50 sentence pairs.
Wefind that acceptable values are obtained for sureparaphrases, but that low values are obtained forpossible paraphrases.
This was somehow expected,given the many possible interpretations of possibleparaphrases, but was not a problem for our experi-ments: as we will describe in section 3.1, the evalua-tion metrics we use will not count them as expectedsolutions, but will simply not count them as falsewhen proposed as candidates.Table 1 finally shows proportions and absolutenumbers of paraphrases of each type for all corpora.We find that there are approximately the same to-tal number of paraphrases for English (16,799) andFrench (17,001), but that English corpora collec-tively have an equivalent number of sure and pos-sible paraphrases (8,303 vs. 8,496) and French havemore sure paraphrases (11,953 vs. 5,048).
This maybe explained by the fact that our annotators workedindependently and that the corpora used have dif-ferences by nature, as our experiments will show.Other salient results include the fact that TEXT con-tains more sure paraphrases in number than the othercorpora, that SPEECH contains relatively more pos-sible paraphrases than the other corpora, and thatSCENE has significantly fewer paraphrases, both inproportion and number.
In Figure 2 various mea-6For each paraphrase type, we used the average of recallvalues obtained for each annotator set as the reference .723synonymy typography tense inclusion pragmatics syntax morphology numberENGLISHTEXT 51.2 7.6 5.1 12.1 0.6 4.4 12.1 6.4SPEECH 39.8 25.6 3.5 12.3 1.7 3.5 3.5 9.7SCENE 50.0 1.3 13.5 21.6 0.0 1.3 5.4 6.7EVENT 36.9 15.0 8.2 19.1 1.3 6.8 6.8 5.4FRENCHTEXT 46.9 9.0 8.7 2.1 3.6 6.6 3.0 19.8SPEECH 45.5 14.2 8.0 8.0 2.6 11.6 3.5 6.2(SCENE) 46.4 5.3 3.5 8.9 0.0 5.3 0.0 30.3EVENT 28.3 19.7 6.1 16.0 7.4 8.6 7.4 6.1Table 2: Percentages of paraphrase classes in 50 randomly selected sentence pairs for reference paraphrases for English(top) and French (bottom).
Classes are illustrated by the following examples: (mutual understanding ?
consensus)(synonymy), (California ?
CA) (typography), (letting ?
having let) (tense), (Asian Development Bank ?
AsianBank) (inclusion), (police dispatcher ?
woman) (pragmatics), (grief-stricken ?
struck with grief ) (syntactic), (Viet-name ?
Vietnam) (morphology), (mortgage ?
mortgages) (number).sures of sentence pair similarities are given.
TEXTcontains the most similar sentence pairs according toall metrics, with EVENT at a similar level on French.SCENE has sentence pairs that are more similar thanthose in SPEECH for English, but this is not the casefor French.
While the metrics used can only providea crude account of semantic equivalence at the sen-tence level, these results clearly indicate that trans-lating from text yields more similar sentences thantranslating from speech.Table 2 provides a typology of paraphrases foundin all our corpora and two languages, where eachclass has been quantified with respect to the refer-ence alignments.7 The main observation here is thatphrasal synonymy (e.g.
mutual understanding ?consensus) is the most present phenomenon.
It isalso interesting to note that the EVENT corpus type,which is easy to collect on a daily basis, contains ref-erence paraphrases spread over all classes.
Lastly, itis expected that paraphrases in the pragmatics class(e.g.
police dispatcher ?
woman) would be diffi-cult to acquire, as this would often rely on documentcontext and costly world knowledge.87Note that typologies of paraphrases have already been pro-posed in the literature (e.g.
(Culicover, 1968; Vila et al2011)),but that the choice of our classes has been primarily moti-vated by potential subsequent uses of the acquired paraphrases(paraphrases could be annotated as belonging to more than oneclass).
Note also that our experiments will also include resultsfocused on the synonymy class only (cf.
Table 5).8Reusing such types of paraphrases into applications wouldhowever often be too strongly context-dependent.COSINE*100 BLEU 1-TER METEOR010203040506070 TEXT SPEECH SCENE EVENTCOSINE*100 BLEU 1-TER METEOR010203040506070Figure 2: Sentence pair average similarities for all cor-pora for English (left) and French (right) using the co-sine of token vectors, BLEU (Papineni et al2002),TER (Snover et al2006) and METEOR (Lavie andAgarwal, 2007).3 Bilingual experiments across corpustypes3.1 Evaluation of paraphrase acquisitionWe followed the PARAMETRIC methodology de-scribed in (Callison-Burch et al2008) for assess-ing the performance of systems on the task of sub-sentential paraphrase acquisition.
In this methodol-ogy, a set of paraphrase candidates extracted froma sentence pair is compared with a set of referenceparaphrases, obtained through human annotation, bycomputing usual measures of precision (P ) and re-call (R).
The first value corresponds to the propor-tion of paraphrase candidates, denoted H, producedby a system and that are correct relative to the ref-erence set containing sure and possible paraphrases,denoted Rall.
Recall is obtained by measuring theproportion of the reference set of sure paraphrases,724TEXT      SPEECH     SCENE       EVENTGIZAFASTRTERpPIVOTbiphrasesbiphrasesbiphrasesbiphrasescombinationsystemparaphrasestraining and test instances of sentencepairsunion of biphraseswith featuresOriginal signal type of text pairsFigure 3: Architecture of our combination system forparaphrase identification.denoted Rsure, that are found by a system.
We alsocomputed an F-measure value (F1), which consid-ers recall and precision as equally important.
Thesevalues are thus given by the following formulae:P =|H ?
Rall||H|R =|H ?
Rsure||Rsure|F1 =2PRP +RNote that the way the sets Rall and Rsure of refer-ence paraphrase pairs are defined ensures that para-phrase pair candidates that include possible refer-ence paraphrases will not penalize precision whilenot increasing recall.All performance values reported in the follow-ing sections will be obtained using 10-fold cross-validation and averaging the results on each sub-test.All data sets of cross-validation contain 500 sen-tence pairs per corpus type, and 125 pairs are keptfor development.3.2 A framework for sub-sentential paraphraseidentificationWe now describe the systems that will be testedon the various corpora described in section 2 usingthe methodology described in section 3.1.
Follow-ing (Bouamor et al2012), a combination systemis used to automatically weight paraphrase pair can-didates produced by individual systems using a setof features aiming at recognizing paraphrases, as il-lustrated on Figure 3.
Four individual systems havebeen used and are described below: the reasons forconsidering those systems include their free avail-ability, the possibility of using comparable resourceswhen relevant for our two languages, and the spe-cific characteristics of the techniques used.Statistical learning of word alignments (GIZA)The GIZA++ tool (Och and Ney, 2004) com-putes statistical word alignment models of increas-ing complexity from parallel corpora.
It was runon each monolingual corpus of sentence pairs inboth directions, symmetrized alignments were keptand classical phrase extraction heuristics were ap-plied (Koehn et al2003), without growing phraseswith unaligned tokens.Linguistic knowledge on term variation (FASTR)The FASTR tool (Jacquemin, 1999) spots term vari-ants in large corpora, where variants are describedthrough metarules expressing how the morphosyn-tactic structure of a term variant can be derivedfrom a given term by means of regular expressionson morphosyntactic categories.
Paradigmatic varia-tion can also be expressed with constraints betweenwords, imposing that they be of the same morpho-logical or semantic family using existing resourcesavailable in our two languages.
Variants for allphrases from one sentence of a pair are extractedfrom the other sentence, and the intersection of thesets for both directions is kept.Edit rate on word sequences (TERp) The TERptool (Snover et al2010) can be used to compute anoptimal set of word and phrase edits that can trans-form one sentence into another one.9 Edit types areparameterized by one or more weights which wereoptimized towards F-measure by hill climbing with100 random restarts using the held-out data set con-sisting of 125 sentence pairs for each corpus type.Translational equivalence (PIVOT) We exploitedthe paraphrase probability defined by Bannard andCallison-Burch (2005) on bilingual parallel corpora.We used the Europarl corpus10 of parliamentary de-bates in English and French, consisting of approx-imately 1.7 million parallel sentences, using eachlanguage as source and pivot in turn.
GIZA++9Note that contrarily to what TERp allows, we did not usedthe possibility of using word or phrase equivalents as those areonly made available for English.
This type of knowledge ishowever captured in part by the FASTR and PIVOT systems.10http://statmt.org/europarl725Phrase pair features ?
edit distance between paraphrases, stem identity, bag-of-tokens similarity, phraselength ratioSentence pair features ?
sentence pair similarity (cosine, BLEU, TER, METEOR), relative position ofparaphrases, presence of common tokens at paraphrase boundaries, presence of another paraphrase pairfrom each system at paraphrase boundaries, presence of a paraphrase at a different position in the othersentenceDistributional features ?
similarity of token context vectors for each phrase of a paraphrase (derivedfrom counts in the large English-French parallel corpus from WMT?11 (http://www.statmt.org/wmt11/translation-task.html) (approx.
30 million parallel sentences)System features ?
combination of the individual systems that proposed the paraphrase pairTable 3: Features used by our classifiers.
Discretized intervals based on median values are used for real values, andbinarized values are used for combinations.was used for word alignment and phrase transla-tion probabilities were estimated from them by theMOSES system (Koehn et al2007).
For eachphrase of a sentence pair, we built its set of para-phrases, and extracted its paraphrase from the othersentence with highest probability.
We repeated thisprocess in both directions, and finally kept for eachphrase its paraphrase pair from any direction withhighest probability.Automatic validation of candidate paraphrasesTaking the union of all paraphrase pair candidatesfrom all the above systems for each sentence pair, weperform a Maximum Entropy two-class classifica-tion11, which allows us to include features that werenot necessarily exploited or straightforward to ex-ploit by individual systems to determine the proba-bility that each candidate is a good paraphrase.
Moregenerally, this allows us to attempt to learn a moregeneric characterization of paraphrases, which couldtrivially accept any number of systems as inputs.Positive examples for the classifier are those fromthe union of candidates that are also in the referenceset Rsure, while negative examples are the remainingones from the union.
The features that we used aresummarized in Table 3.3.3 Experimental resultsResults for individual systems, their union and ourvalidation system trained on each corpus type aregiven on Table 4.
First, we find that all individualsystems fare better on TEXT, for which more train-ing data were available and where semantic equiv-11Using the implementation at: http://homepages.inf.ed.ac.uk/lzhang10/maxent_toolkit.htmlalence of sentence pairs is most likely.
EVENT ap-pears to be the most difficult corpus type, whereasone could say that being the most readily data sourcethis is a disapointing result: we will return to this insection 3.4.
In terms of performance on F-measureper corpus type, GIZA performs best for TEXT andSPEECH, containing long sentences with possiblerepetitions, while TERp performs on par with GIZAfor SCENE and best for EVENT, where equivalencesthat are rare at the corpus level are more present.FASTR achieves a very low recall, showing that theencoded definitions of term variants do not cover alltypes of paraphrases, and also possibly that the lex-ical resource that it uses has incomplete coverage.It nonetheless obtains high precision values, mostnotably on TEXT.
One last comment regarding in-dividual systems is that PIVOT is by far the mostprecise of all the techniques used, but with a recallmuch lower than those of GIZA and TERp: as isthe case for FASTR, which makes use of manually-encoded lexical resources, PIVOT encodes in somesense some kind of semantic knowledge.12In all cases, our combination system managesto increase F-measure substantially over the bestindividual system for a corpus type and the sim-ple union.
Improvements are strong on TEXT(resp.
+12.5 and +11.6 on English and French)and on SPEECH (+11.7 and +11.1) and quite goodon SCENE (+3.2 and +6.4) and on EVENT (+5.412Note that the fact that English and French were used as thepivot for one another may have had some positive effect here,but, incidentally, the two corpora obtained by translating fromthe other language (TEXT and SPEECH) are not those wherePIVOT fares better.
The difference observed may however lie inthe higher complexity of the sentences in these corpus types.726Individual systems Combination systemsGIZA FASTR TERp?F PIVOT union validationP R F1 P R F1 P R F1 P R F1 P R F1 P R F1ENGLISHTEXT 48.2 58.9 53.0 63.1 5.9 10.7 41.2 66.4 50.9 73.4 25.8 38.2 20.8 80.8 33.1 68.4 62.8 65.5SPEECH 39.7 44.2 41.8 27.1 3.5 6.3 25.0 50.3 33.4 79.2 15.3 25.7 25.5 71.4 37.6 51.0 56.3 53.5SCENE 44.8 57.7 50.5 47.4 5.2 9.5 40.1 67.9 50.4 84.6 14.6 25.0 36.2 83.4 50.5 44.9 66.8 53.7EVENT 19.0 33.9 24.3 62.9 3.1 6.0 28.8 68.7 40.6 97.4 11.2 20.1 20.8 75.5 32.7 35.0 67.1 46.0FRENCHTEXT 52.5 58.9 55.5 56.9 4.9 9.1 46.4 61.4 52.8 64.5 30.3 41.2 41.5 77.9 54.1 74.7 61.0 67.1SPEECH 44.0 54.9 48.9 30.7 4.3 7.6 34.8 60.2 44.1 75.5 19.0 30.4 31.4 76.2 44.5 60.2 59.7 60.0(SCENE) 14.4 43.6 21.7 53.0 4.0 7.4 13.8 75.3 23.4 94.6 5.21 9.8 12.7 86.4 22.2 19.9 59.8 29.8EVENT 28.7 44.2 34.8 34.4 2.3 4.3 29.9 58.9 39.7 79.5 15.0 25.2 25.2 72.5 37.4 40.0 56.3 46.8Table 4: Evaluation results for individual systems (left) and combination systems (right) on all corpus types for English(top) and French (bottom).
Values in bold are for highest values for a given metric for each corpus type and language.and +6.1).
Recall from Table 1 that TEXT andSPEECH were the two corpus types with the highestnumber of sure paraphrase examples for both lan-guages: results show that our classifier was able toefficiently use them.Recall values for the union are quite strong forall corpus types, ranging from 71.4 (SPEECH in En-glish) to 83.4 (SCENE in English).
There is, how-ever, a substantial decrease between the unions andthe results of our combination systems, althoughrecall values for our systems are roughly between56 and 67, which may be considered an acceptablerange on such a task.
Further study of false neg-atives should help with engineering new features toimprove paraphrase recognition.
Lastly, we note thatprecision is in general highest for a specific system(PIVOT), and reaches high values for our validationsystem on TEXT, where we have the most examples(resp.
68.4 and 74.7 for English and French).As seen in Table 2, synonymy is the most presentphenomenon in all our corpora; it is also proba-bly one of the most useful type of knowledge formany applications.
We now therefore focus on thisclass, for which all the sure paraphrases in our cor-pora falling in this class have been annotated.
Ta-ble 5 shows F-measure values for the individualtechniques and our combination systems on all cor-pus types.
We first observe that our combination sys-tem also always improves here over the best individ-ual system, albeit not by a large margin on EVENT.GIZA FASTR TERp PIVOT validationENGLISHTEXT 52.2 6.1 47.3 47.1 68.1SPEECH 42.6 5.0 30.3 39.5 54.9SCENE 51.8 6.0 48.0 26.0 56.3EVENT 22.5 2.1 34.8 24.7 35.5FRENCHTEXT 55.3 3.9 50.7 50.5 70.3SPEECH 49.8 1.6 40.9 36.2 57.2(SCENE) 19.6 4.2 23.1 0.0 24.7EVENT 36.8 3.5 35.3 25.6 39.9Table 5: F-measure values for test instances in the syn-onymy class (see Table 2) for all individual systems andour validation system for English (top) and French (bot-tom).Also, we find that PIVOT performs relatively closerto GIZA and TERp on TEXT and SPEECH than forthe full set of classes, confirming the intuition thattranslational equivalence may be appropriate to rec-ognize synonymy.3.4 Experiments across corpus typesTo test how different the corpora under study are asregards paraphrase identification, we now considerusing as additional training data for our classifierscorpora of the other types, both individually and col-lectively.
Results are given on Table 6.1313Note that our results are still given by performing cross-validation averaging over 10 test sets for each tested corpustype.727+TEXT +SPEECH +SCENE +EVENT +AllENGLISH# ex+ 7,342 2,296 1,784 1,171 12,593TEXT 65.5 66.2 65.1 66.2 65.1SPEECH 56.0 53.5 52.8 54.8 56.6SCENE 49.7 54.3 53.7 53.8 42.7EVENT 51.1 45.3 42.5 46.0 56.2FRENCH# ex+ 12,961 3,340 966 2,160 19,427TEXT 67.1 67.2 66.7 67.0 66.6SPEECH 57.6 60.0 56.4 59.6 57.9(SCENE) 23.7 22.0 29.8 23.9 21.1EVENT 45.2 45.6 44.3 46.8 49.3Table 6: Evaluation results (F1 scores) for all corpustypes for English (top) and French (bottom) when addingtraining material from other corpus types (values withgray background on the diagonal are when no additionaltraining data are used).
?#ex+?
rows indicate numbers ofpositive paraphrase examples for each additional corpustype.The most notable observation is that EVENT issubstantially improved by using all available addi-tional training data for English (+10.2), and to alesser extent for French (+2.5) .
It should be notedthat no individual corpus type, save TEXT, individu-ally improves results on EVENT, and that results areyet substantially improved over the use of trainingdata from TEXT when using all available data, re-vealing a collective contribution of all corpus types.The second major observation is that all other cor-pus types seem to be quite specific in nature, as noaddition of training data from other types yields anyimprovement (with the exception of SPEECH on En-glish), but they often in fact decrease performance.For instance, SCENE in English is substantially neg-atively impacted by the use of the numerous exam-ples of TEXT (-4 in F-measure) and even more whenusing all other training data (-9).
This underlinesthe specific nature of this corpus type: independentdescriptions of the same scene in a video may beworded with much variation that mostly differ fromthat present in other corpus types.Our main conclusion here is therefore that all ourcorpora under study are quite specific in nature, butthat EVENT can benefit from all training data fromthe other corpus types.
We can further note that thefact that TEXT is almost not impacted by additionaldata may also be explained by the fact that this cor-pus type contains more than half of the total numberof examples for the two languages.
Finally, there aresubstantially more positive paraphrase examples forFrench (19,427) than for English (12,593).4 Related workOver the years, paraphrase acquisition and genera-tion have attracted a wealth of research works thatare too many to adequatly summarize here: (Mad-nani and Dorr, 2010) presents a complete and up-to-date review of the main approaches.
Sententialparaphrase collection has been tackled from specificresources increasing the probability of sentences be-ing paraphrases (Dolan et al2004; Bernhard andGurevych, 2008; Wubben et al2009), from com-parable monolingual corpora (Barzilay and Elhadad,2003; Fung and Cheung, 2004; Nelken and Shieber,2006), and even at web scale (Pasc?a and Dienes,2005; Bhagat and Ravichandran, 2008).Various techniques have been proposed for para-phrase acquisition from related sentence pairs(Barzilay and McKeown, 2001; Pang et al2003)and from bilingual parallel corpora (Bannard andCallison-Burch, 2005; Kok and Brockett, 2010).The issue of corpus construction for developing andevaluating paraphrase acquisition techniques are ad-dressed in (Cohn et al2008; Callison-Burch et al2008).
To the best of our knowledge, this is the firsttime that a study in paraphrase acquisition is con-ducted on several corpus types and for 2 languages.Faruqui and Pado?
(2011) study the acquisition of en-tailment pairs (premise and hypothesis), with ex-periments in 3 languages and various domains ofnewspaper corpora for one language.
Although theirwork is not directly comparable to ours, they reportthat robustness across domains is difficult to achieve.Laslty, the evaluation of automatically generatedparaphrases has recently received some attention(Liu et al2010; Chen and Dolan, 2011; Met-zler et al2011) although it remains a difficult is-sue.
Application-driven paraphrase generation pro-vides indirect means of evaluating paraphrase gen-eration (Zhao et al2009).
For instance, the field ofStatistical Machine Translation has produced worksshowing both the usefulness of human-produced728(Schroeder et al2009; Resnik et al2010) and au-tomatically produced paraphrases (Madnani et al2008; Marton et al2009; Max, 2010; He et al2011) for improving translation performance.5 Discussion and future workThis work has addressed the issue of sub-sententialparaphrase acquisition from text pairs.
Analogu-ously to bilingual parallel corpora, which are stillto date the most reliable resources for automatic ac-quisition of sub-sentential translations, monolingualparallel corpora are generally regarded as very ap-propriate for paraphrase acquisition.
However, theirlow availability makes searching for less parallelcorpora a necessity.
In this study, we have attemptedto identify corpora of various degrees of semantictextual similarity by considering text pairs originat-ing from various signal types.
These signal typesallow various degrees of freedom as to how to for-mulate a text: a text is read and translated into a dif-ferent language (TEXT); some speech is listened toin the context of a visual story and translated into adifferent language (SPEECH); some action is lookedat and described (SCENE); and some event that tookplace is concisely reported (EVENT).The results presented in this paper have shownhow these corpora differed in various aspects.
First,they contain varying quantities of paraphrases thatare differently distributed into paraphrase classes.Individual acquisition techniques, based on statis-tical learning of word alignments (GIZA), linguis-tic knowledge on term variation (FASTR), edit rateon word sequence (TERp), and translational equiv-alence (PIVOT), for which different performanceswere observed among them on the same corpustype, were shown to achieve different performancesacross corpus types.
An efficient combination ofcandidate paraphrases from these individual tech-niques exploiting additional features to character-ize paraphrases has yielded substantial increases inperformance on all corpus types; however, it is in-teresting to note that the highest amplitude in per-formance across corpus types was not so much onrecall (amplitude of 10.5 on English and 4.7 onFrench) than on precision (amplitude of 33.4 on En-glish and 34.714 on French).
This, some other fac-14Not considering (SCENE) for French.tors aside, emphasizes the fact that the correct idenfi-cation of paraphrases is facilitated when equivalenceof semantic content is more probable.
Many workshave accordingly attempted to identify text units thatare as parallel as possible from large corpora, andthe task of measuring semantic textual similarity,which can find many uses, has received some atten-tion lately (Agirre et al2012).
However, it itselfrelies on some knowledge on paraphrasing.Our avenues for future work lie in three main ar-eas.
The first one is to continue our current line ofwork and study the impact of additional individualacquisition techniques and better characterizationsof paraphrases in context, in tandem with workingon identifying parallel text pairs in large corpora.Another avenue is to start from the output of highrecall techniques and to attempt to characterize thecontexts of possible substitution for candidate para-phrases from large corpora as a means to acquireprecise paraphrases.
As the examples from Table 7show, some classes of paraphrases, and in particularin the continuum from our synonymy to pragmat-ics classes, require the joint acquisition of contextualinformation that license substitution.
Lastly, we planto apply such knowledge in text-to-text applications.synonymyTEXT take part in ?
participate ingreat assistance ?
enormous helpSPEECH make a deal ?
come to an agreementI don?t care ?
I don?t give a damnSCENE riding a bicycle ?
cyclinglady ?
womanEVENT jail escapee ?
prison fugitiveapologizes ?
expresses regretpragmaticsTEXT flew in ?
arrived inflood-control materials ?
needed suppliesSPEECH face ?
picturewant to sleep ?
dream about sleepingSCENE a man ?
someonebento ?
foodEVENT violence ?
bloodshedanger ?
emotionTable 7: Examples in English for the synonymy andpragmatics classes.729AcknowledgementsThe authors would like to thank the reviewers fortheir comments and suggestions.
This work waspartly funded by ANR project Edylex (ANR-09-CORD-008).ReferencesEneko Agirre, Daniel Cer, Mona Diab, and AitorGonzalez-Agirre.
2012.
SemEval-2012 Task 6: A Pi-lot on Semantic Textual Similarity.
In Proceedings ofSemEval, Montre?al, Canada.Colin Bannard and Chris Callison-Burch.
2005.
Para-phrasing with Bilingual Parallel Corpora.
In Proceed-ings of ACL, Ann Arbor, USA.Regina Barzilay and Noemie Elhadad.
2003.
Sentencealignment for monolingual comparable corpora.
InProceedings of EMNLP, Sapporo, Japan.Regina Barzilay and Kathleen R. McKeown.
2001.
Ex-tracting paraphrases from a parallel corpus.
In Pro-ceedings of ACL, Toulouse, France.Delphine Bernhard and Iryna Gurevych.
2008.
Answer-ing Learners?
Questions by Retrieving Question Para-phrases from Social Q&A Sites.
In Proceedings of theWorkshop on Innovative Use of NLP for Building Ed-ucational Applications, Columbus, USA.Rahul Bhagat and Deepak Ravichandran.
2008.
Largescale acquisition of paraphrases for learning surfacepatterns.
In Proceedings of ACL-HLT, Columbus,USA.Houda Bouamor, Aure?lien Max, and Anne Vilnat.
2012.Validation of sub-sentential paraphrases acquired fromparallel monolingual corpora.
In EACL, Avignon,France.Chris Callison-Burch, Trevor Cohn, and Mirella Lapata.2008.
Parametric: An automatic evaluation metric forparaphrasing.
In Proceedings of COLING, Manch-ester, UK.David Chen and William Dolan.
2011.
Collecting highlyparallel data for paraphrase evaluation.
In Proceedingsof ACL, Portland, USA.Trevor Cohn, Chris Callison-Burch, and Mirella Lapata.2008.
Constructing corpora for the development andevaluation of paraphrase systems.
Computational Lin-guistics, 34(4).P.
W. Culicover.
1968.
Paraphrase Generation and Infor-mation Retrieval from Stored Text.
Mechanical Trans-lation and Computational Linguistics, 11:78?88.Bill Dolan, Chris Quirk, and Chris Brockett.
2004.
Un-supervised construction of large paraphrase corpora:Exploiting massively parallel news sources.
In Pro-ceedings of COLING, Geneva, Switzerland.Manaal Faruqui and Sebastian Pado?.
2011.
Acquiringentailment pairs across languages and domains: A dataanalysis.
In Proceedings of the International Con-ference on Computational Semantics (IWCS), Oxford,UK.Pascale Fung and Percy Cheung.
2004.
Multi-levelbootstrapping for extracting parallel sentences from aquasi-comparable corpus.
In Proceedings of COLING,Geneva, Switzerland.Ulrich Germann.
2008.
Yawat : Yet Another WordAlignment Tool.
In Proceedings of the ACL-HLT,demo session, Columbus, USA.Wei He, Shiqi Zhao, Haifeng Wang, and Ting Liu.
2011.Enriching SMT Training Data via Paraphrasing.
InProceedings of IJCNLP, Chiang Mai, Thailand.Christian Jacquemin.
1999.
Syntagmatic and paradig-matic representations of term variation.
In Proceed-ings of ACL, College Park, USA.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical Phrase-Based Translation.
In Pro-ceedings of NAACL-HLT, Edmonton, Canada.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open SourceToolkit for Statistical Machine Translation.
In Pro-ceedings of ACL, demo session, Prague, Czech Repub-lic.Stanley Kok and Chris Brockett.
2010.
Hitting the RightParaphrases in Good Time.
In Proceedings of NAACL,Los Angeles, USA.Alon Lavie and Abhaya Agarwal.
2007.
METEOR: Anautomatic metric for MT evaluation with high levels ofcorrelation with human judgments.
In Proceedings ofthe ACL Workshop on Statistical Machine Translation,Prague, Czech Republic.Chang Liu, Daniel Dahlmeier, and Hwee Tou Ng.
2010.PEM: A paraphrase evaluation metric exploiting par-allel texts.
In Proceedings of EMNLP, Cambridge,USA.Nitin Madnani and Bonnie J. Dorr.
2010.
GeneratingPhrasal and Sentential Paraphrases: A Survey of Data-Driven Methods .
Computational Linguistics, 36(3).Nitin Madnani, Philip Resnik, Bonnie J. Dorr, andRichard Schwartz.
2008.
Are multiple referencetranslations necessary?
investigating the value ofparaphrased reference translations in parameter opti-mization.
In Proceedings of AMTA, Waikiki, USA.Yuval Marton, Chris Callison-Burch, and Philip Resnik.2009.
Improved Statistical Machine Translation UsingMonolingually-derived Paraphrases.
In Proceedingsof EMNLP, Singapore.730Aure?lien Max.
2010.
Example-Based Paraphrasing forImproved Phrase-Based Statistical Machine Transla-tion.
In Proceedings of EMNLP, Cambridge, USA.Donald Metzler, Eduard Hovy, and Chunliang Zhang.2011.
An empirical evaluation of data-driven para-phrase generation techniques.
In Proceedings of ACL-HLT, Portland, USA.Rani Nelken and Stuart M. Shieber.
2006.
Towards ro-bust context-sensitive sentence alignment for monolin-gual corpora.
In Proceedings of EACL, Trento, Italy.Franz Josef Och and Herman Ney.
2004.
The align-ment template approach to statistical machine trans-lation.
Computational Linguistics, 30(4).Bo Pang, Kevin Knight, and Daniel Marcu.
2003.Syntax-based alignement of multiple translations: Ex-tracting paraphrases and generating new sentences.
InProceedings of NAACL-HLT, Edmonton, Canada.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a method for automatic evalu-ation of machine translation.
In Proceedings of ACL,Philadelphia, USA.Marius Pasc?a and Peter Dienes.
2005.
Aligning Nee-dles in a Haystack: Paraphrase Acquisition Across theWeb.
In Proceedings of IJCNLP, Jeju Island, SouthKorea.Philip Resnik, Olivia Buzek, Chang Hu, Yakov Kronrod,Alex Quinn, and Benjamin B. Bederson.
2010.
Im-proving translation via targeted paraphrasing.
In Pro-ceedings of EMNLP, Cambridge, USA.Josh Schroeder, Trevor Cohn, and Philipp Koehn.
2009.Word Lattices for Multi-Source Translation.
In Pro-ceedings of EACL, Athens, Greece.Matthew Snover, Bonnie J. Dorr, Richard Schwartz, Lin-nea Micciulla, and John Makhoul.
2006.
A Study ofTranslation Edit Rate with Targeted Human Annota-tion.
In Proceedings of AMTA, Boston, USA.Matthew Snover, Nitin Madnani, Bonnie J. Dorr, andRichard Schwartz.
2010.
TER-Plus: paraphrase, se-mantic, and alignment enhancements to TranslationEdit Rate.
Machine Translation, 23(2-3).Jo?rg Tiedemann.
2007.
Building a Multilingual Paral-lel Subtitle Corpus.
In Proceedings of the Conferenceon Computational Linguistics in the Netherlands, Leu-ven, Belgium.Marta Vila, M. Anto`nia Mart?
?, and Horacio Rodr??guez.2011.
Paraphrase Concept and Typology.
A Linguisti-cally Based and Computationally Oriented Approach.Procesamiento del Lenguaje Natural, (462-3).Sander Wubben, Antal van den Bosch, Emiel Krahmer,and Erwin Marsi.
2009.
Clustering and machingheadlines for automatic paraphrase acquisition.
InProceedings of the European Workshop on NaturalLanguage Generation, Athens, Greece.Shiqi Zhao, Xiang Lan, Ting Liu, and Sheng Li.
2009.Application-driven Statistical Paraphrase Generation.In Proceedings of ACL-IJCNLP, Singapore.731
