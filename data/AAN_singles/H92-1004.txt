DARPA FEBRUARY 1992 AT IS  BENCHMARK TESTRESULTSDavid S. Pallett, Nancy L. DahIgren, Jonathan G. Fiscus,William M. Fisher, John S. Garofolo, Brett C. TjadenNational Institute of Standards and TechnologyBuilding 225, Room A216Gaithersburg, MD 208991 INTRODUCTIONThis paper documents the third in a series of Bench-mark Tests for the DARPA Air Travel Information Sys-tem (ATIS) common task domain.
The first results inthis series were reported at the June 1990 Speech andNatural Language Workshop \[1\], and the second at theFebruary 1991 Speech and Natural Language Workshop\[2\].
The February 1992 Benchmark Tests include: (1)ATIS domain spontaneous speech recognition systemtests, (2) ATIS natural anguage understanding tests,and (3) ATIS spoken language understanding tests.Since the February 1991 tests, a large ATIS spokenlanguage corpus has been collected, coordinated by aDARPA "Multi-Site ATIS Data COllection Working"(MADCOW) Group.
The activities of this group, andNIST's role in that effort, are documented in anotherpaper in this Proceedings \[3\].2 OCTOBER 1991 "DRY RUN"  TESTSThe procedures for test set selection, testing, scoring,adjudication, and reporting for the February 1992 ATISBenchmark Tests were developed and used for a "dryrun" test in October 1991, with unpublished results.
Asomewhat smaller test set was used at that time, whichdid not include test data from AT&T.
The implemen-tation of the tests was generally regarded as success-ful within the DARPA MADCOW Group and by theDARPA Spoken Language Program Coordinating Com-mittee.3 NEW CONDIT IONS FOR THESETESTSThe structure (and scoring) of these ATIS domain testsdiffer in several ways from the tests reported at the June1990 and February 1991 Workshops:?
Following the February 1991 Workshop, minor revi-sions (e.g., to accommodate connecting flights, clar-ify terminology, revise headings and restructure ta-bles, improve representation f fare structures, bugfixes, etc) were made to the relational air-travel-information database.
The MADCOW data collec-tion effort, and systems developed with this data,made use of this revised relational database (Ver-sion 3.3).?
The MADCOW data collection effort provided atafrom five sites (AT&T, BBN, CMU, MIT/LCS, andSRI), rather than the single ATIS data collectionsite (TI) used for the June 1990 and February 1991tests.?
Some (but not all) of the collecting sites providedsecondary (Crown PCC-160) microphone data inaddition to the primary (close- talking Sennheiser)microphone.
The use of the secondary microphonedata was encouraged, but not required, for theFebruary 1992 tests.?
The definition of "Class D" queries was broadenedto include "Class DI" queries.?
The files indicating the "classification" (i.e., ClassA, D or X) for each query were not provided alongwith the test queries (as they had been in previoustests), so'that each site had no extra informationregarding the context-dependency or answerabilityof each query.?
Similarly, "unanswerable" (Class X) queries werenot identified when the test material was released.If system developers provided answers for thesequeries, they were not scored.?
No utterances were to be treated ifferently on thegrounds of the presence of disfluencies such as falsestarts or restarts.
In the February 1991 tests, theseutterances were regarded as "Optional".?
Concern had been expressed at the February 1991meeting that some sites might have chosen to "over-generate" (by providing verbose) NL and SLS an-swers rather than provide more succinct answers.
Itwas argued that "correct" answers hould have at15least the information in the ".ref" files previouslyused in scoring answers, but no more than in somespecified maximal answer.
Bob Moore and EricJackson, at SRI, proposed and implemented an al-gorithmic procedure for deriving maximal referenceanswers (".rf2") from the NLParse-generated SQLfiles used to generate the .ref files.
Bill Fisher atNIST subsequently modified the NIST comparator(used in scoring the NL and SLS results) to imple-ment the new "minimum~maximum" scoring pro-cedure.
The Principles of Interpretation documentwas modified to accommodate these changes.
* Special reports were to be prepared by NIST topartition the tabulations of results according to theoriginating sites for the test data.?
Following completion of each phase of scoring theresults, NIST was to prepare and make available toall participants both detailed and summary reportsvia anonymous ftp.?
Because there had been a recommendation to re-port results for all answerable queries in completesubject-scenarios (i.e., the material collected uringone subject's working of one scenario), test mate-rial was to be provided to the testing sites in com-plete subject-scenarios.
Emphasis was to be placedon analysis of the subset of "answerable" queries(i.e., Class A+D), rather than on the individualclasses A and/or D. Further, the weighted errorpercentage (defined as twice the percentage of in-correct or "false" answers plus the percentage of"No_Answer" responses) was identified as preferableto the single-number "Score" reported at the Febru-ary 1991 meeting (Score (%) = 100 (%)- \[WeightedError (%)1)4 TEST  MATERIAL  SELECT IONAND DISTR IBUT IONWith the approval of the MADCOW Group, NIST hadreserved approximately 20% of the pooled MADCOWdata for test purposes.
NIST screened this data for theoccurrence of truncated utterances, rejected the subject-scenarios that included these phenomena, and deter-mined that there was a sufficient quantity of reservedpotential test material to permit release of a test set con-sisting of approximately 200 utterances from each of thefive MADCOW sites contributing data.
NIST did notmonitor the audio quality of the .wav files nor reviewthe accuracy of the transcriptions, ince no criteria foracceptability based on these have been defined, althoughin retrospect this might have simplified the adjudicationprocess.The test material, subsequent to deletion of some ma-terial during the adjudication process, consisted of 970non-null (and 1 null) utterances in all classes.
The num-ber of distinct scenarios used by all subjects was 42,with a total of 37 subjects ("speakers") completing 122subject-scenarios.
There were 17 male subjects, and 20were female.
Seven of the 122 subject-scenarios u edthe "Common-l" scenario; however, the test materialselected from BBN and CMU did not include any in-stances of this scenario.
The average number of queriesper subject-scenario was 8.
The MIT subject-scenarioshad an average number of 4.6 queries, and SRI and CMUeach had an average number of 12.1 queries per subject-scenario.
There were 508 lexemes represented in the testmaterial.
The average number of words per utterancewas about 11.After NIST selected the test material, it was producedon CD-ROM.
The test disc (NIST Speech Disc T3-1.1)was distributed to the testing sites on Jan. 6, 1992.Concurrent with preparation of the CD-ROMs, NISTstaff and the "Annotation Group" at SRI initiatedpreparation ofthe annotation files required to implementscoring.5 TEST  PROCEDUREFollowing completion of locally administered single-pass-per-system tests, participating sites submitted resultsfor (at least) three ATIS tests: the SPeech RECogni-tion (SPREC), Natural Language (NL) and Spoken Lan-guage System (SLS) tests.The format for data submission via e-mail was specifiedby NIST and all "official" results were received at NISTby 6:00 AM on Jan. 20, 1992.
As in previous ATIStests, answer hypotheses were to be in the form of lexicalSNOR (.lsn) files for the SPREC results and in CommonAnswer Specification (CAS) format files for the NL andSLS results.
Each submission was to be accompanied bya text file for each system providing asystem descriptionfollowing a suggested format.6 TEST  SCORING,  ADJUDICAT IONAND REPORTING PROCEDUREUpon receipt of the test results, NIST implemented pre-liminary scoring with a reference answer set including.cat, .ref and .rff2 files developed at NIST and SRI forthe NL and SLS tests, and the "lexical SNOR" (.lsn) filesderived from the detailed (.sro) transcriptions providedby the collecting sites for the SPREC tests.
On Jan. 24,1992, upon completion of the preliminary scoring and16preparation of the required reports, NIST released thepreliminary results by anonymous ftp.A detailed and formal procedure was established at NISTat the MADCOW group's request for handling requestsfor adjudication.The participating sites filed a total of 122 requests foradjudication, which were treated by NIST and the SRIAnnotation group in a manner similar to that followedfor the training data's bug reports.
Some of these re-quests involved more than one utterance, or reported onmore than one "bug" in an utterance, so that the numberof unique utterances potentially affected by the requestsfor adjudication was 193, or approximately 19% of thetest material.Of these utterances, the adjudicators determined that99 (51%) actually required one or more changes.
"NoAction" decisions were made for the remaining 49%.NIST was advised by Francis Kubala at BBN duringthe adjudication period that some of the reference tran-scriptions used for scoring the SPREC test appeared tobe inaccurate.
NIST subsequently reviewed all of thetranscriptions noted by Kubala and corrected them asdeemed appropriate.In addition to the 99 utterances noted as part of theformal requests for adjudication requiring changes to theannotations, 26 test utterances were identified by theadjudicators as requiring changes.The final total of 125 utterances (12.9% of the entire testset) for which annotation changes were made includesthe following breakdown (by category):?
42 with software problems related to annotationsor scoring (e.g., NLParse, batching, or Comparatorbugs),?
36 for which annotation errors had been made,?
27 involved problems with the transcriptions devel-oped at the originating sites, and?
20 involved differences of opinion in applying thePrinciples of Interpretation or the use of context ininterpreting the query.Following completion of the adjudication process, NISTreleased a set of "Official" ATIS Benchmark Test resultsto the community on Feb. 5, 1992.NIST was subsequently advised by Paramax that cor-rections to the reference answer set that were to havebeen made during the adjudication process did not ap-pear to have been made.
NIST and SRI determined thatthis had in fact been the case, and a total of 19 .rf2 fileswere corrected.
The entire set of NL and SLS resultswere then re-scored, and a "Revised Official" set of re-sults was made available to the community.
Analysis ofthe differences between these two sets of "official" resultsshows that only 5 of Paramax's NL and 4 of their SLSanswers were scored differently.Paramax also noted, following release of the "RevisedOfficial" results, that 20 of their NL as well as another20 of their SLS answers were scored as "False" becauseof known limitations in the NIST official scoring soft-ware.
NIST had determined that the degree to whichParamax's answers were affected by this known limita-tion was approximately ten times more severe than forany other site, and declined to alter the scoring softwareto accomodate Paramax's unusual responses.
NIST en-couraged Paramax to develop and document "unofficial"results \[4\] with slightly modified scoring software.A "handout" was prepared for, and distributed at, theFebruary 1992 Speech and Natural Language Workshopcontaining the System Descriptions provided by the par-ticipants and NIST's summaries of Benchmark Test re-sults.7 BENCHMARK TESTAND DISCUSSIONRESULTS7.1 AT IS  SPeech  RECogn i t ion(SPREC)  Test  Resu l ts :7.1.1 C lose-Ta lk ing  M ic rophoneTable 1 presents a tabulation of the February 1992 ATISspontaneous Speech RECognition (SPREC) test results.Results are presented for a number of defined subsets ofthe utterances, with the utterance classes defined in theannotation process.
The set Class ATDWX is the set ofall utterances in all classes, consisting of 971 utterances.The set Class A+D includes all answerable utterances,687 in all.
Individual scores for the component subsetsClass A, Class D, and Class X are also included.
Theutterances in Classes D and X tend to have a greaterdegree of disfluency than those in Class A.
This factormay be reflected in the corresponding error rates, sincethe lowest subset error rates are to be found for Class Autterances, and the highest for Class X.In the set of answerable queries, Class A+D, the worderror ranges from 6.2% to 13.8%, and the "Utterance17error rate" (corresponding approximately to "sentenceerror rate", but acknowledging the fact that some ut-terances consist of more than one sentence) range from34.6% to 60.1%.The lowest word error rate, in any of the subsets, 5.8%, isnoted for the BBN system described in \[5\] for the subsetof Class A utterances.Table 2 presents a matrix tabulation of ATIS SPREC re-sults for the set of answerable queries, Class A+D.
Thismatrix form of tabulation of results was developed atthe MADCOW group's request o shed light on poten-tial variabilities in the data for test set components fromdiffering originating sites.
The five columns of the ma-trix block correspond to the five originating sites for theMADCOW test data.
In this case, the six rows of thematrix block correspond to the six sets of SPREC testresults ent to NIST.
The "Overall Totals" column at theright of the central block presents results correspondingto those cited for the Class A+D subset in Table 1.
Note,for example, that the previously cited lowest Class A+Dsubset word error of 6.2% (for the BBN system) is shownin the second row entry of this column.The "Overall Totals" row presents results accumulatedover all systems for which results were reported to NIST.Note that the Overall (subset) Total Word Error ("W.Error") ranges from a low of 5.9%, for the data originat-ing at MIT/LCS, to 14.6% for the AT&T data subset.These data suggest that the MIT data subset is less chal-lenging for ATIS SPREC systems than the data fromother sites, but the reasons for this are not immediatelyevident.Analysis of the transcriptions suggests that the AT&Tdata subset has a higher incidence of disfluencies thanother subsets, partially explaining why it is more chal-lenging than the other data subsets.For the "Class A+D" data, the lowest subset word er-ror for any SPREC system is 3.2%, again for the BBNSPREC system and for the MIT data subset.
Analysisof a similar matrix for the Class A data (not shown) in-dicates that the lowest subset word error (again for theMIT data subset) is 2.6% for the BBN system, with acorresponding utterance rror of 20.7%.7.1.2 Secondary (Crown PCC-160) MicrophoneDataThree ATIS MADCOW sites provided ata for both theSennheiser close-talking microphone and the secondary(Crown PCC-160) microphone: CMU, MIT/LCS, andSRI.
Two sites agreed to use the Crown microphone datawith SPREC systems, using "robust" recognition algo-rithms: CMU and SRI.
In some cases, results for otheralgorithms for comparable subsets of the data are avail-able, and these have been excised from larger sets of dataprovided to NIST by CMU and SRI for the purposes ofcomparisons.Table 3 presents a matrix tabulation of the SPRECdata for the Class A+D data from CMU, MIT/LCSand SRI for 5 systems (i.e., 3 from CMU and 2 fromSRI).
The "cmu4" system is the CMU Sphinx II sys-tem \[6\] processing the close-talking microphone data,the "cmu6" system is the CMU codeword-dependent-cepstral-normalization (CDCN) system \[7\] processingthe close-talking data, and the "cmu3" system is theCMU CDCN system processing the Crown microphonedata.
The "sri3" system (processing the close-talking mi-crophone data) and "sri4" system (processing the Crownmicrophone data) are versions of the Sl:tI Decipher sys-tem incorporating the "I:tASTA" procedure for high-passfiltering of a log-spectral representation f speech \[8\].For the close-talking microphone data subset, the lowestword error rate (7.0%) is for the sri4 system, which maybe compared to the cmu4 system (10.4%) and the cmu6system (13.7%).
According to the system descriptionprovided by CMU, the two CMU systems differ in theamount of training material, among other factors.For the secondary microphone data subset, the word er-ror rate for the cmu3 system is 17.8%, and for the sri4system is 30.4%.There are indications of substantial variabilities due tooriginating site for the secondary microphone data, withboth the SRI and CMU data secondary microphone datasubsets giving rise to higher error rates than for the MITdata subsets.7.1.3 Statistical Significance: SPRECAs in previous benchmark tests, two statistical signifi-cance tests are routinely implemented at NIST in anal-ysis of speech recognition performance assessment tests.The utterance (sentence) error test is an application ofMcNemar's test, first suggested for use in this commu-nity by Gillick \[9\].
Another test consists of a MAtched-Pairs Sentence-Segment Word Error ("MAPSSWE") sig-nificance test, originally devised for use with the Re-source Management corpora.Analysis of the tabulation of the word error test results18for the answerable query subset (Class A+D) shown inTable 4a indicates that for the BBN system \[5\], the worderror rates are significantly different from (lower than)those for the other systems included in these tests.
Thesentence rror McNemar test (Table 4b) indicates a simi-lar result, but in this case, the sentence rror rate for theParamax SPREC system \[4\] does not differ significantlyfrom the BBN system.7.2 Natural Language (NL) TestsTable 5 presents a tabulation of the February 1992 ATISNatural Language (NL) understanding tests results.
Re-sults are presented for the set of all "answerable utter-ances", Class A+D, and for the individual Class A andClass D subsets.
As was the case for the SPREC results,in general the error rates are higher for Class D than forClass A utterances.For the set of answerable queries, Class A+D, theweighted error ranges from 30.1% to 75.4%.
Note thatfive of the systems have weighted error percentages be-tween 30.1% and 33.9%.Table 6 presents a matrix tabulation for the NL test re-sults for the set of answerable queries, Class A+D.
Therewere a total of 687 queries in this set.
The numberstabulated for this set in Table 5 appear in the "OverallTotals" column, along with corresponding percentages.The "Overall Totals" row indicates the variability dueto the test subsets' originating site.Of the 5 data subsets, the lower weighted error percent-ages in the "Overall Totals" row are to be found for theCMU and MIT data, with the SPd, AT&T, and BBNdata giving rise to higher weighted error percentages.Since the AT&T data was collected using a significantlydifferent collection paradigm- with the subject interfac-ing with the ATIS system simulation only over a phoneline, rather than viewing a screen display of travel infor-mation \[10\] - the fact that the AT&T data subset is moredifficult than three other sites is perhaps not surprising.However, the BBN ATIS data collection effort also dif-fered somewhat from that at other MADCOW sites inthat - although information was presented using a screendisplay - the BBN scenarios "included not only trip plan-ning scenarios, but also problem solving involving moregeneral kinds of database access...
This was done to tryto elicit a richer range of language usage.\[3\]" This factor("richer language usage") may provide a partial expla-nation for the high NL error rates noted for the BBNdata subset.For the CMU and MIT \[11\] systems, there appears to besome indication that the error percentages for "locally-collected" data are lower than for "foreign" data, per-haps because of greater familiarity with the local data-collection scenarios and environment, or use of a variantof the system under test when collecting the MADCOWdata from which the test set was selected.7 .3  Spoken Language Systems (SLS)TestsTable 7 presents a tabulation of the February 1992 Spo-ken Language System understanding test results.
As wasthe case for Table 5 (for the corresponding NL results),results are shown for several classes of the data, but em-phasis in this material is placed on the answerable ut-terances, comprising Class A+D.For the Class A+D set, the seven SLS systems haveweighted error ranging from 43.7% to 90.2%.
Note thatfour systems (from three sites: BBN, MIT and SRI\[12\]) have weighted error percentages between 43.7% and52.8%.Table 8 presents a matrix tabulation for the SLS testresults for Class A+D, comparable in structure to thatfor the NL results of Table 6.Of the 5 data subsets corresponding to different collec-tion sites, the range in weighted error is from 49.5% (forthe MIT data) to 73.1% (for the AT&T data).8 ACKNOWLEDGEMENTThe authors would like to acknowledge the help pro-vided by the entire MADCOW community throughoutthe ordeal of collecting, annotating, distributing and us-ing the MADCOW corpus for test purposes.
A com-panion paper in this Proceedings provides a detailed ac-knowledgement, but special credit was earned by LynetteI-Iirschman as Chair of the MADCOW Group.
It is toeveryone's credit that the essential data was collected,annotated, and distributed and that "deadlines" wereusually honored!Special thanks are also due to the group at MIT, par-ticularly Michael Phillips and Christie Clark Winterton,for quick turn- around in producing recordable CD-ROMdiscs for distribution of the MADCOW training corpusfrom master tapes produced by Brett Tjaden at NIST.The Annotation Group at SRI, consisting of KateHunicke-Smith, Harry Bratt and Beth Bryson, was in-valuable to the NIST effort to implement hese tests.19They participated actively and cheerfully in annotationof the test material and the adjudication process, in ad-dition to "training" one of the authors (ND) in the useof the NLParse software and annotation techniques.Francis Kubala, at BBN, called NIST's attention to someproblematic transcriptions for the SPREC tests.
NISTreviewed and revised these as appropriate, and in theprocess noted 3 truncated utterances (in one subject-scenario collected at BBN).
While the revised transcrip-tions were used in NIST's "revised official" scoring, NISTneglected to delete this subject-scenario fr m the NL andSLS tests, as specified by MADCOW protocols for han-dling data with truncated utterances.
Analysis of perfor-mance on this particular subject-scenario indicates thatmost sites did well, nonetheless.9 References1.
Pallett, et al, "DARPA ATIS Test Results June 1990",in Proc.
Speech and Natural Language Workshop, June1990, (R. Stern, ed.)
Morgan Kaufmann Publishers, Inc.ISBN 1-55860-157-0, pp.
114-121.2.
Pallett, D.S., "Session 2: DARPA Resource Manage-ment and ATIS Benchmark Test Poster Session", inProc.
Speech and Natural Language Workshop, Febru-ary 1991, (P. Price, ed.)
Morgan Kaufmann Publishers,Inc.
ISBN 1-55860-207-0, pp.
49-58.3.
MADCOW, "Multi-Site Data Collection for a SpokenLanguage Corpus", in Proc.
Speech and Natural Lan-guage Workshop, February 1992, (M. Marcus, ed.)
Mor-gan Kaufmann Publishers, Inc.4.
Norton, L.M., Dahl, D.A., and Linebarger, M.C., "Re-cent Improvements and Benchmark Results for the Para-max ATIS System", in Proc.
Speech and Natural Lan-guage Workshop, February 1992, (M. Marcus, ed.)
Mor-gan Kaufmann Publishers, Inc.5.
Kubala, F. et al, "BBN BYBLOS and HARC February1992 ATIS Benchmark Results", in Proc.
Speech andNatural Language Workshop, February 1992, (M. Mar-cus, ed.)
Morgan Kaufmann Publishers, Inc.6.
Ward, W. et al, "Speech Understanding in OpenTasks", in Proc.
Speech and Natural Language Work-shop, February 1992, (M. Marcus, ed.)
Morgan Kauf-mann Publishers, Inc.7.
Stern, R. M., et al, "Multiple Approaches to Robustspeech Recognition" in Proc.
Speech and Natural Lan-guage Workshop, February 1992, (M. Marcus, ed.)
Mor-gan Kaufmann Publishers, Inc.8.
Murveit, H., Butzberger, J. and Weintraub, M., "Re-duced Channel Dependence for Speech Recognition", inProc.
Speech and Natural Language Workshop, Febru-ary 1992, (M. Marcus, ed.)
Morgan Kaufmann Publish-ers, Inc.9.
Gfllick, L. and Cox, S.J., ~'Some Statistical Issues in theComparison of speech Recognition Algorithms", Pro-ceedings of ICASSP-89, Glasgow, May 1989, pp.532-535.10.
Pieraccini, R. et al, "Progress Report on the ChronusSystem: ATIS Benchmark Results", in Proc.
Speech andNatural Language Workshop, February 1992, (M. Mar-cus, ed.)
Morgan Kaufmann Publishers, Inc.11.
Zue, V., et al, "The MIT ATIS System: February 1992Progress Report", in Proc.
Speech and Natural Lan-guage Workshop, February 1992, (M. Marcus, ed.)
Mor-gan Kaufmann Publishers, Inc.12.
Appelt, D.E.
and Jackson, E., "SRI International Febru-ary 1992 ATIS Benchmark Test Results", in Proc.Speech and Natural Language Workshop, February1992, (M. Marcus, ed.)
Morgan Kaufmann Publishers,Inc.10 APPENDIX:  "OFF IC IAL""UNOFF IC IAL"  RESULTSVS.Several sites expressed interest in having results for ad-ditional systems included in NIST's "official" summary,although these results typically were not available at therequired time for "official" scoring.
At least one site tookexception to an idiosyncratic property of the "official"comparator's treatment of their system's responses toseveral queries, and requested permission to present "un-official" results at the meeting.
Another site noted thatthey had identified a "bug" in their CAS-answer- for-mat software, and after it was fixed, they also requestedpermission to report unofficial results.It was subsequently decided that the results ubmitted toNIST by the specified eadline, and uniformly scored atNIST with the "official" comparator and the adjudicatedfinal set of reference answers would comprise the only"official" results, and that locally scored results shouldbe represented as "unofficial", even if scored with thesame scoring software and answer set as the "official"results.It should be noted that since the results are for locallyimplemented tests, and since NIST's role in the tests isprincipally one of selecting and distributing the test ma-terial, and implementing the scoring software and uni-formly tabulating the results of the tests, the results arenot to be construed or represented as endorsements ofany systems or official findings on the part of NIST,DARPA or the U.S. Government.20Class A+D+X SubsetCorr  Sub Del  Insa t t3 -adx  85.6  10.5 3 .9  3.1bbn3-adx 92.5 5 ,7  1.8 1 .8cmu4-adx 88,2 9 .7  2.1 4 .4ml t4 -adx  84.1 11.5 4 .4  2 ,3paramax3-adx 91.5  6 .3  2.1 2.1sP13-adx 91.4  6 ,8  1,8 2 .4Er r  U. Er r  # Ut t ,17.5 64 .6  9709 .4  40 .3  97116.2 60.2 97118.1 59,6 97110,6 42.2 97111.0 48.7 971ATT Feb 92 Sprec Resu l tsBBN Feb 92 Sprec Resu l tsCMU Feb 92 ATIS Sph lnx - I I  Senn.MIT-LCS Feb 92 Sprec Resu l tsParamax/BBN Feb 92 Sprec Resu l tsSRI Feb 92 Sprec Resu l tsClass A+D SubsetCorr  Sub Del  Insa t t3 -a_d  88.9 7 .7  3 .4  2 .7bbn3-a d 95.2 3 ,6  1,1 1 .5cmu4-a d 91.9 6 .5  1 ,6  3 .7ml t4 -a_d  88.3  8 .7  3.1 1 .9paramax3-a_d 94.6  4 .0  1 .4  1.7s r i3 -a_d  93.8  4 .9  1.4 2.1Er r  U. Er r  # Ut t .13.8 60.1 6876 .2  34 .6  68711.8 54.4 68713.6 54.1 6877.1 36.4 6878 .4  44.5 687ATT Feb 92 Sprec Resu l ts  C lass  A+DBBN Feb 92 Sprec Resu l ts  C lass  A+DCMU Feb 92 ATIS Sph inx - I I  Senn.
C lass  A+DMIT-LCS Feb 92 Sprec Resu l ts  C lass  A+DParamax/BBN Feb 92 Sprec Resu l ts  C lass  A+DSRI Feb 92 Sprec Resu l ts  C lass  A+DClass A SubsetCorr  Sub De1 Ins  Er r  U, E r r  # Ut t .a t t3 -a  88 .9  7 .2  3 .9  2 ,0  13.1 60.9 402bbn3-a 95 .4  3 .3  1.3 1.2 5 .8  35 .6  402cmu4-a 92,8 5 .7  1.6 3 .2  10.4 54.2 402mi t4 -a  89.1 7 .8  3.1 1 .6  12.5 54.5 402paramax3-a 94 .9  3 .6  1 .5  1.4 6 .5  36.6 402s r l3 -a  94 .4  4 .0  1 .5  1.7 7 .3  44.0 402ATT Feb 92 Sprec Resu l ts  C lass  ABBN Feb 92 Sprec Resu l ts  C lass  ACMU Feb 92 ATIS Sph inx - I I  Senn.
C lass  AMIT-LCS Feb 92 Sprec Resu l ts  C lass  AParamax/BBN Feb 92 Sprec Resu l ts  C lass  ASRI Feb 92 Sprec Resu l ts  C lass  AClass D SubsetCorr  Sub Del  Ins Er r  U, E r r  # Ut t .a t t3 -d  89 .0  8 .7  2 .3  4.1 15,2 58.9 285bbn3-d 94.9  4 .2  0 ,8  1.9 7 ,0  33.3 285cmu4-d 90,3  8 .2  1 .5  4 .8  14.5 54.7 285ml t4 -d  86,7 10.3 3 .0  2 .3  15.7 53.7 285paramax3-d 94.1 4 .7  1.1 2 .2  8.1 36.1 285s r l3 -d  92 ,5  6 .4  1.1 2 .8  10.3 45.3 285ATT Feb 92 SpPec Resu l ts  C lass  DBBN Feb 92 Sprec Resu l ts  C lass  DCMU Feb 92 ATIS Sph lnx - I I  Senn.
C lass  DMIT-LCS Feb 92 Sprec Resu l ts  C lass  DParamax/BBN Feb 92 Sprec Resu l ts  C lass  DSRI Feb 92 Sprec Resu l ts  C lass  DClass X SubsetCorr  Sub Del  Insa t t3 -x  77 .4  17.3 5 .3  3 .9bbn3-x 85 .5  11.0 3 ,5  2 .7cmu4-x 78 .9  17.6 3 .4  6.1ml t4 -x  73 .8  18.5 7 ,7  3 .3paramax3-x 83 .7  12.2 4 .0  3.1s r l3 -x  85,5 11.5 3 .0  2 .9Er r  U. Er r  # Ut t ,26.5  75.6 28317.2 53.9 28427.2 74.3 28429.5 72,9 28419.4 56.3 28417.4 58.8 284ATT Feb 92 Spree Resu l ts  C lass  XBBN Feb 92 Spree ResuZts C lass  XCMU Feb 92 ATIS Sph inx - I I  Senn.
C lass  XMIT-LCS Feb 92 Spree Resu l ts  C lass  XParamax/BBN Feb 92 Sprec Resu l ts  C lass  XSRI Feb 92 Spree Resu l ts  C lass  XTable 1: ATIS SPREC Test Results21I Class A+D Subset II II OP ig inat ing  S i te  of  Test Data I I  Overa l l  I ForeignI ATT I BBN I CaU I MZT I SRX I I  Tota ls  I Co11.
S i teI (114  ut t . )
I (151  ut t . )
I (137 Ut t . )
\[ (152 ut t . )
I (133  ut t . )
I I  687 I Tota ls.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.at t3  I 13.0 3 .2  4.91 8 .9  2 .7  .51 7 .3  8 .8  2.ol 4.4  1.3 2.ol 8.7  2 .9  4.oll 7.7  3 .4  2.71 6 .7  3 ,4  2 .3I 21.0 69.3  I 11.1 55.0  I 16.0 75.9 I 7 .8  42.1 I 15.6 62.4  I I  13.8 60.1 I 12.4 58.3. .
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
* .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.bbn3 I 6 .3  1.1 3.ol 3.3  O.S .21 3.2  1,6 1.ol 1.8  0 .7  0 .8 \ [  4 .5  1.4 1.711 3.6  1.1 1.51 3.7  1.2 1.5I 10.4 50 .9  I 5 ,3  31.1 I 5 .8  38.7  I 3 .2  21.7  I 7 .7  35.3  I I  6 .2  34 ,6  I 6 .5  35.6s .
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
?
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
?
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Y cmu4 J 10.2 1.4 7.31 4 .8  1.5 .5J 7 .0 2.1 5.2J 3 .9  1.1 1,2J 7 .9  1.7 4.411 6 .5  1.6 3.71 6 .4  1.4 3 .3S I 18.9 68.4  I 7 .9 47.0  I 14.3 89.3  I 6 .3  44.1 I 14.0 47.4  I I  11.8 54.4  \[ 11.1 50 .7T .
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
* .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.E B i t4  I 7 ,9  2 .5  3.11 7 .6  3 .6  .51 9 .9  3 .9  1.71 5 .9  1.8 0.91 13.1 3 .7  2.611 8 .7  3.1 1.91 9 .5  3 .5  2 .2M I 13.4 51 .8  \[ 12.7 57.6  I 15 .5  61 .3  I 8 .6  46 .
I  I 19.4 64.1  I I  13 .6  54 .1  I 15 .1  56 .4s .
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.paPamax3 I 6 .8  1.5 2.81 3.1 0 .7  ,21 3 .4  2.3 1.21 2 .5  0 .7  1.11 5 .2  1.9 2.611 4 .0  1.4 1.71 4 .0  1.4 1.7I 11.0 48.2  I 5 .0  28.5  I 6.9  41.6  I 4.3  26.3  I 9.7  41,4  I I  7.1 36.4  I 7.1 36.4. .
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.sr i3  I 8.1 1.3 3.61 3 .2  1.2 ,51 5 .4  1.9 2.71 3 .2  1,3 1.01 5 .2  1.1 2.211 4 .9  1.4 2.11 4 .8  1.4 2.1I 13.1  57.0  I 6 .9  35 .8  I 10.0 56.2  I 5 .5  40 .8  I 8 .6  36 .1  I I  8 .4  44.5  I 8 .3  46.6======================= =:==================== =========:====== =============================================Overa l l  I 8 .7  1 .8  4.11 4 .8  1 .8  .41 6 .0  3.1 2.31 3 .6  1.1 1.21 7.4 2.1 2.911Tota ls  I 14 .6  57 .6  I 8 .0  42,5  I 11.4 57,2 I 5 .9  3o .s  I 12 .5  46 .1  I I. .
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
* .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
* .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Foreign \[ 7 .9 1.5 4.ol 5.1 1.9 .41 5.8  3 .3  1.71 3 .2  1.0 1.21 7 .9  2 .3  3.111 I ~Sub ~Dsl ~ Ins  ISystem I 13.4 55 .3  I 8 .5  44 .8  I 10.8 54.7  I 5 .4  35.0 I 13,3 48.1 I I  I ~W.EPP ~Utt .E r r  I. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Table 2: ATIS SPREC Results Class A+D by Collection SiteI Class A+D Subset \[I Or ig inat ing  S i te  of  Test Data Overa l l  \[ ForeignI CMU I MIT I SRI Tota ls  I Co11.
S i teI (101 ut t . )
I (152  ut t . )
I (79 Ut t . )
332 I Tota ls.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
?
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
, ,  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.cmu3 I 14.9 3 ,4  6 ,9  I 8 .3  2 .9  1.31 11.1 3 .9  4 .6  10.9 3 .3  3.71 9.1 3 .2  2 .2J 25.2 84.2 I 12.4 61 .8  J 19.6 54.4  17,8 66,9  I 14.5 59.3. .
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
, ,  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.S cmu4 I 7 .6  1,4 6,61 3.9  1.1 1.21 6 .4  0 .8  5 .5  5 .6  1.1 3.71 4.7  1.1 2 .4Y I 15.5 70.3 I 6 .3  44.1 I 12.7 43.0  10.4 51 .8  I 8.1 43 .7T cmu6 I 9,1 1.4 11.71 5 .0  1.3 2.71 S,O 1.1 5 .3  8 .4  1.3 6.01 5 .3  1.2 3 .4E I 22.1 80.2 I 8 .9  53.3 I 12,5 50.6  13.7 60 .8  I 9 .9  52.4M .
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.S ar ia  \[ 5 .2  1.5 2.71 3 .2  1.3 1.01 3 .8  1.1 2 .2  4 .0  1.3 1.81 4 .0  1.3 1.6I 9 .4  52.5  I 5 .5  40.8  I 7.1 34.2  7 ,0  42 .8  I 7 .0  45.5. .
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.8r i4  I 26.0 2 .7  17.41 14.1 3 .4  3.31 17.1 4,1 8.4 18.4 3 .3  8.71 18.7 3 .2  8 .7I 46.2  93.1 I 20.8  78.9 \[ 29.6 77,2 30.4  82,8 I 30,6  84.6============================================================================================OvePal l  I 12.6 2,1 9.11 6.9  2 .0  1.91 8.9  2 .2  5.211Tota ls  I 23.7  76.0 I 10 .8  55 .8  I 16 .3  51 .9  I I. .
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.FoPeign I 15.6 2,1 10.11 6 .9  2,0 1.91 7 .8  2 .0  5.111 I ~Sub ~Del ~ InsSyat~ I 27.8  72.8  I 10.8 55.8  I 14.9 49.4 I I  laW.Err bUtt.Err I. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Table 3: ATIS SPREC Crown and Crown Subset of SennheiserTest Results by Collection sites22COMPARISON MATRIX :  FOR THE WATCHED PA IRS  TESTFeb  91AT IS  SPREC C lass  A+D Resu l t sMin~J~um Number  o f  Cor rec t  Boundary  words  2a t t3 -a_d  bbn3-a_d  omu4-a_d  mi t4 -a_d  paramax3 er i3 -a_d.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.a t t3 -a_d  bbn3-ad  cmu4-a_d  same paramax3 8r i3 -ad.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.bbn3-a_d  bbn3-ad  bbn3-a_d  bbn3-ad  bbn3-a_d.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.cmu4-a_d  ?mu4-ad  paramax3 s r i3 -ad.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.m i t4 -a_d  paramax3 er i3 -ad.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
~+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.paramax3 paramax3.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.s r i3 -  a_d.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
ICOMPARISON MATRIX :  McNEMAR'S  TEST  ON CORRECT SENTENCES FOR THE TEST:Feb  91AT IS  SPREC C lass  A+D Resu l t sFor  a l l  sys temsI a t t3"a_d(274) l  bbn3"a_d(449) l  cmu4-a_d(313) l  mi t4 -a_d(315) l  paramax3(437)  l s r i3 -a_d(381).
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
?
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.at t3"a -d(274) l  I D=(175)  I 0=(39)  I o=(41)  I D=(163)  I 0=(107)I I bbn3-ad  I cmu4-e_d  I m i t4 -a_d  I paramax3 I s r i3 -a_d.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
?
.
.
.
.
.
.
.
.
.
.
.
.
.
.bbn3"a -d(449)  l I I D=(13e)  I D=(134)  t D=(12)  I D=(68)I I I bbn3-ad  I bbn3-a_d  I same I bbn3-a_d.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
?
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.cmu4"a-d(313)l  I I I O=( 2) I D=(124) t D=(68)I I I I same I paramax3 I e r i3 -a_d.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
?
.
.
.
.
.
.
.
.
.
.
.
.
.
.
?
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
?
.
.
.
.
.
.
.
.
.
.
.
.
.
.m i t4"a -d (31S)  l I I I I D=(122)  I D=(66)I I I I I paramax3 I s r i3 -ad.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.paramax3(437)  l ~ I I I I D=(Be)I I I 1 I I paramax3.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
?
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.s r i3"a -d (381) l  I } I I II I I I I I. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Table 4: ATIS SPREC Significance Test Comparisons: Class A+D23systemar t1bbnlcmulcmu8mlt2paramaxls r i lsystemat t l -abbn l -acmul -acmu8-aml t2 -aparamax l -as r l l -a#T378527582560551311533#T256322356346342223335#F209731021018712260#F96264646345025# NA100873264925494Class A+D# Ut t687687687687687687687W.
EPP75.433 .930.133.232 .572 .531.1# NA50540102612942Descr ip t ionATT Feb92 ATISBBN Feb92 ATISCMU-Phoenlx Feb92 ATI$CMU-MINDS-II Feb92 ATISMIT Feb92 ATISPARAMAX Feb92 ATISSRI Feb92 ATISClass A# Utt402402402402402402402W.
Er r60.226.422 .925 .423 .457.022 .9Descr ip t ionATT Feb92 ATIS C lass  A NLBBN Feb92 ATIS C lass  A NLCMU-Phoenlx Feb92 ATI8 C lass  A NLCMU-MINDS-II Feb92 ATI8 C lass  A NLMZT Feb92 ATI8 C lass  A NLPARAMAX Feb92 ATIS C lass  A NLSRI Feb92 ATIS C lass  A NLClass Dsystem # T # F # NA # Ut t  W. Er ra t t l -d  122 113 50 285 96.8bbn l -d  205 47 33 285 44.6cmul-d 226 56 3 285 40.4cmu8-d 214 55 16 285 44.2ml t2 -d  209 53 23 285 45.3paramax l -d  88 72 125 285 94.4s r11-d  198 35 52 285 42.8Descr ip t ionATT Feb92 ATIS C lass  D NLBBN Feb92 ATIS C lass  D NLCMU-Phoenlx Feb92 ATI8 C lass  D NLCMU-MINDS-II Feb92 ATIS C lass  D NLMIT Feb92 ATIS C lass  D NLPARAMAX Feb92 ATIS C lass  D NLSRI Feb92 ATIS C lass  D NLTable 5: Feb 92 ATIS NL Test Results - UsingMinimal/Maximal Scoring Criterion24I c lass  (A+D) Set I I  Ii OPig?net ing  S i te  of  Test  Data I I Overa l l  I FoeeignI ATT I BBN I cuu  I MIT I SRI I I  Tota ls  I Co l l .
S i teI 114 I 151 I 137 I 152 I 133 I I  687 \[ Tota l s. .
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.art1 I 60 39 15 I 69 36 48 I 80 46 11 I 98 43 11 I 71 45 17 I I  378 209 100 I 318 170 85I 53 34  131  48  24 30 I 58 34 8 I 54 28 71 53  34  13  I I  55  30  151  55  30  15I 81 .5  I 78.1 I 75 .2  I 63 .8  I 80 .5  I I 75 .4  I 74 .2. .
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.bbnl I 84 13 17 I 120 19 12 I 98 10 29 I 130 11 11 I 95 20 18 I I  527 73 87 I 407 54 75I 74 11 15 \] 79 13 8 I 72 7 21 I 86 7 7 I 71 15 14 II  77 11 13 I 75 10 14\[ 37 .7  I 33.1 I 35 .8  I 21.7  I 43.6  I1  33 .9  I 34.1. .
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
t l  .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.cmul I g9 14 1 I 110 41 0 I 125 10 2 I 134 18 0 I 114 19 0 I I  582 102 3 \] 457 92 1I 37 12 11 73 27 0 I 91 7 11 88 12 0 I 815 14 o I I  85  15  O l 83  17  0s I 25.4 I 54.3 \[ 16.1 I 23,7 I 28.6 I I  30.1 I 33 .8Y .
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.S cmu8 I 8g 13 12 I 107 41 3 I 122 10 5 I 131 lg  2 I 111 18 4 I I  560 101 26 I 438 91 21T I 78 11 11 I 71 27 2 i 89 7 4 i 86 12 1 i 83 14 3 I I  82 15 4 I 83 17 4E I 33.3  I 56 .3  I 18.2  I 25 .3  I 30.1 I I  33 .2  I 35.9M .
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.S m?t2 I 83 19 12 I 114 26 11 I 111 14 12 I 137 10 5 I 108 18 9 I I  581 87 49 I 414 77 44I 73 17 11 I 75 17 7 I 81 10 g I go 7 3 I so  14  7 I t  so  13 7 I 77 14 8I 43 .9  I 41 .7  I 2g .2  I 16 .4  I 33 .8  I I  32 .5  I 37 .0. .
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
i l  .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.panamaxl I 36 22 56 I 58 27 66 I 89 18 30 I 71 25 55 I 57 29 47 I I  311 122 254 I 311 122 254I 32 19 4g l  38  18  441  55  13  22  I 47 17 36 I 43 22 35 I I  45  18  371  48  18  37I 87.7  I 79.5 I 48.2 I 70.4 I 78.9 I I  72.5 I 72.5. .
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.sr?1 \[ 76 13 25 I 116 11 24 I 119 10 8 I 12g 18 7 I 93 10 30 t l  533 60 94 \] 440 50 54I 67 11 22 I 77 7 16 I 87 7 6 \[ 85 11 5 I 70 8 23 I I  78 g 14 I 79 9 12I 44 .7  I 30.5 \[ 20.4 I 25.7 I 37 .6  I I  31.1 I 29.6==~=~=================================~================~==============================================~==========OvePa l l  I 527 133 138 I 594 201 152 I 744 118 g7 I 830 143 91 I 647 15g 125 I ITota ls  I 66 17 17 I 55 19 15 I 78 12 10 I 78 13 g I 69 17 13I 50 .6  I 53 .4  I 34.7  I 35.4 I 47.6  Legend:.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.FoPeign I 457 94 123 \] 574 182 150 I 497 98 90 I 593 133 86 I 554 14g 95 I #T #F #NA ISystem I 88 14 18 I 53 20 17 I 73 14 13 I 75 15 9 I 6g 19 12 I I  I ~T ~F ~NA ITota l s  ~ 45.5  I 56 .7  I 41 .8  ~ 38,6 I 4g.2 i i i ~ We?ghted Er ror  I. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Table 6: ATIS NL Test Results - UsingMinimal/Maximal Scoring Criterion25systemar t2bbn2cmu2ml t lml t3paramax2sr12systemat t2 -abbn2-acmu2-aml t l -aml t3 -aparamax2-as r l2 -a#T300493458471419302444#T208301298305288215305#F2331062261329514869#F1184310458477032# NA15488384173237174# NA76580396711765# Utt687687687687687687687# Ut t402402402402402402402Class A+DW.
Er r90.243 .766.250 .752 .877 .645.4Descr ip t ionATT Feb 92 ATI8 8LSBBN Feb 92 ATI8 $L8CMU Feb 92 ATI8 $L$MIT/SRI Feb 92 ATIS SLSMIT Feb 92 ATI6 6LSPARAMAX/BBN Feb 92 ATIS 8LSSRI Feb 92 ATI6 SLSClass AW.
Er r77 .635 .851 .738 .640 .063 .932.1Descr ip t ionATT Feb 92 ATIS SL6 C lass  ABBN Feb 92 ATI8 8L8 C lass  ACMU Feb 92 ATI8 6L8 C lass  AMIT/SRI Feb 92 ATI6 SL6 C lass  AMIT Feb 92 ATI8 8L8 CZass APARAMAX/BBN Feb 92 ATI8 8LS C lass  ASRI Feb 92 ATIS SLS C lass  AClass Dsystem # T # F # NA # Ut t  W. Er ra t t2 -d  92 115 78 285 108.1bbn2-d 192 63 30 285 54.7cmu2-d 160 122 3 285 86.7ml t l -d  166 74 45 285 67.7mi t3 -d  131 48 106 285 70.9paramax2-d 87 78 120 285 96,8s r12-d  139 37 109 285 64.2Descr ip t ionATT Feb 92 ATIS 6L8 C lass  0BBN Feb 92 ATIS SL6 C lass  DCMU Feb 92 ATIS 8LS C lass  DMIT/SRI Feb 92 ATIS 6LS C lass  DMIT Feb 92 ATIS SLS C lass  DPARAMAX/BBN Feb 92 ATIS SLS C lass  DSRI Feb 92 ATIS SLS C lass  DTable 7: ATIS SLS Test Results - UsingMinimal/Maximal Scoring Criterion26I c lass  (A+D)  Set  I I  II Or?g?nat?ng S i te  of Test  Data I I  Overa l l  I ForeignI ATT I BBN I CMU I MZT I SRZ I I  To ta l s  I Co11.
S i teI 114 { 151 I 137 I 152 I 133 I I  687  I Tota ls.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.at t2  I 36  50 28 I 51 41 491  69 42 261  84 45 201  50 52 31 I I  50O 233 1541264 183 126I 32  44 251  40 27 321  50 31 19 I 55 32 13 I 38  39 23 I I  44  34 221  46 32 22I 112 .3  I 85 .6  I e0 .3  I 76 .3  I 101 .5  I I  90 .2  I 85 .9. .
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.bbn2 I 72 23 19 I 113 21 17 I 95 13 29 I 122 18 12 I 91 31 11 I I  493 106 88 I 380 85 71I 63 20 17 I 75 14 11 I 69 9 21 I 80 12 8 I 68 23 8 I I  72 15 13 I 71 16 13f 57 .0  I 39 .1  I 40.1 I 31 .5  I 54 .9  I I  43 .7  1 45 .0. .
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
?
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.cmu2 ~ 73 38 3 I 82 69 O I 98 39 0 I 113 39 0 I 92 41 O I I  458 226 3 I 360 187 3I 64 33 31  54 46 o l 72 28 o l 74 26 O l 69 31 0 I I  67 33 O l 65  34 Is I 69 .3  l 91 .4  ~ 56 .9  I 51 .3  I 61 .7  I I  66 .2  I 68 .5Y .
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.S m?tl I 72 28 14 ~ 103 30 18 I 94 19 24 I 121 22 9 I 81 33 19 I I  471 132 84 ~ 350 110 75r I 63 25 121 63  20 121  69 14 181  80 14 61  61 25 14 I I  69  19 121  65 21 14E I 61 .4  I 51 .7  I 45 ,3  I 34 .9  I 63 .9  I I  50 .7  I 55 .1M .
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.s mt t3  I 63  21 25 I 81 15 55 I 88 19 30 I 110 14 28 I 72 26 35 I I  419  95 173 I 309 81 1451 60 18 221  54 10 36 1 64 14 221  72 9 18{  54 20 26 I I  61 14 251  58 15 27I 58 ,8  I 56 .3  I 49 .6  I 38 .5  I 65 .4  I I  52.8  I 57 .4. .
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.paramax2 I 38 23 55 I 52 33 66 I 87 27 23 J 74 30 48 I 53 35 45 I I  302 148 237 I 302 148 237J 32 20 48 I 34 22 44 I 64 20 17 I 49 20 32 J 40 25 34 I I  44 22 34 J 44 22 34I 88 .6  I 87.4  I 56 .2  I 71.1 I 86 .5  I I  77.6  I 77.6. .
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.s r i2  ~ 55 12 47 J 101 13 37 J 93 13 31 J 112 20 20 J 83 11 39 I I  444 69 174 J 361 58 135l 48 11 411  67 9 25 J  68 9 231  74 13 131  62 5 29 I I  65 10 251  85 10 24I 62 .3  I 41.7  I 41.6  I 39.5  I 45 .9  I I  45.4  I 45.3=========== = ==:================= ======================== ===== ==== ===~===================== =============  ==Overa l l  I 412 195 191 I 593 222 242 I 624 172 163 I 736 191 137 I 522 229 180 I ITota ls  I 52 24 24 ~ 56 21 23 I 65 18 17 I 69 18 13 I 56 25 19 I II 72.8  I 64.9  1 52 .9  I 48 .8  I 68 .5  I I  Legend:.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
I I  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Foreign I 376 145 163 I 480 201 225 I 525 133 163 I 505 155 100 I 439 218 141 I I  I #T #F #NA ISystem I 55 21 24 I 53 22 25 I 54 16 20 I 65 20 13 I 55 27 18 I I  I ~T ~F ~NA ITota l s  I 66.2  I 69 .2  I 52 .2  ~ 53 .9  I 72 .3  I I  I ~ Weighted Er ror  I. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Table 8: ATIS SLS Test Results - UsingMinimal/Maximal Scoring Criterion27
