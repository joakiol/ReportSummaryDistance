Automatic Pattern Acquisitionfor Japanese Information ExtractionKiyoshi SudoComputer ScienceDepartmentNew York University715 Broadway, 7th floor,New York, NY 10003 USAsudo@cs.nyu.eduSatoshi SekineComputer ScienceDepartmentNew York University715 Broadway, 7th floor,New York, NY 10003 USAsekine@cs.nyu.eduRalph GrishmanComputer ScienceDepartmentNew York University715 Broadway, 7th floor,New York, NY 10003 USAgrishman@cs.nyu.eduABSTRACTOne of the central issues for information extraction is the cost ofcustomization from one scenario to another.
Research on the auto-mated acquisition of patterns is important for portability and scala-bility.
In this paper, we introduce Tree-Based Pattern representationwhere a pattern is denoted as a path in the dependency tree of a sen-tence.
We outline the procedure to acquire Tree-Based Patterns inJapanese from un-annotated text.
The system extracts the relevantsentences from the training data based on TF/IDF scoring and thecommon paths in the parse tree of relevant sentences are taken asextracted patterns.KeywordsInformation Extraction, Pattern Acquisition1.
INTRODUCTIONInformation Extraction (IE) systems today are commonly basedon pattern matching.
New patterns need to be written when wecustomize an IE system for a new scenario (extraction task); this iscostly if done by hand.
This has led to recent research on automatedacquisition of patterns from text with minimal pre-annotation.
Riloff[4] reported a successful result for her procedure that needs onlya pre-classified corpus.
Yangarber [6] developed a procedure forunannotated natural language texts.One of their common assumption is that the relevant documentsinclude good patterns.
Riloff implemented this idea by applying thepre-defined heuristic rules to pre-classified (relevant) documentsand Yangarber advanced further so that the system can classify thedocuments by itself given seed patterns specific to a scenario andthen find the best patterns from the relevant document set.Considering how they represent the patterns, we can see that,in general, Riloff and Yangarber relied on the sentence structureof English.
Riloff?s predefined heuristic rules are based on syn-tactic structures, such as ?<subj> active-verb?
and ?active-verb.<dobj>?.
Yangarber used triples of a predicate and some of itsarguments, such as ?<pred> <subj> <obj>?.The ChallengesOur careful examination of Japanese revealed some of the chal-lenges for automated acquisition of patterns and information ex-traction on Japanese(-like) language and other challenges whicharise regardless of the languages.Free Word-orderingFree word order is one of the most significant problems in analyz-ing Japanese.
To capture all the possible patterns given a predicateand its arguments, we need to permute the arguments and list all thepatterns separately.
For example, for ?<subj> <dobj> <iobj><predicate>?
with the constraint that the predicate comes last inthe sentence, there would be six possible patterns (permutations ofthree arguments).
The number of patterns to cover even simplefacts would rise unacceptably high.Flexible case marking systemThere is also a difficulty in a language with a flexible case markingsystem, like Japanese.
In particular, we found that, in Japanese,some of the arguments that are usually marked as object in En-glish were variously marked by different post-positions, and somecase markers (postpositions) are used for marking more than onegrammatical category in different situations.
For example, the topicmarker in Japanese, ?wa?, can mark almost any entity that wouldhave been variously marked in English.
It is difficult to deal withthis variety by simply fixing the number of arguments of a predicatefor creating patterns in Japanese.Relationships beyond direct predicate-argumentFurthermore, we may want to capture the relationship between apredicate and a modifier of one of its arguments.
In previous ap-proaches, one had to introduce an ad hoc frame for such a relation-ship, such as ?verb obj [PP <head-noun>]?, to extract the relation-ship between ?to assume?
and ?<organization>?
in the sentence?<person> will assume the <post> of <organization>?.Relationships beyond clausal boundariesAnother problem lies in relationships beyond clause boundaries, es-pecially if the event is described in a subordinate clause.
For exam-ple, for a sentence like ?<organization> announced that <person>retired from <post>,?
it is hard to find a relationship between<organization> and the event of retiring without the global viewfrom the predicate ?announce?.These problems lead IE systems to fail to capture some of the ar-guments needed for filling the template.
Overcoming the problemsabove makes the system capable of finding more patterns from thetraining data, and therefore, more slot-fillers in the template.In this paper, we introduce Tree-based pattern representation andconsider how it can be acquired automatically.2.
TREE-BASED PATTERN REPRESENTA-TION (TBP)DefinitionTree-based representation of patterns (TBP) is a representation ofpatterns based on the dependency tree of a sentence.
A pattern isdefined as a path in the dependency tree passing through zero ormore intermediate nodes within the tree.
The dependency tree is adirected tree whose nodes are bunsetsus or phrasal units, and whosedirected arcs denote the dependency between two bunsetsus: A!Bdenotes A?s dependency on B (e.g.
A is a subject and B is a pred-icate.)
Here dependency relationships are not limited to just thosebetween a case-marked element and a predicate, but also includethose between a modifier and its head element, which covers mostrelationships within sentences.
1TBP for Information ExtractionFigure 2 shows how TBP is used in comparison with the word-order based pattern, where A...F in the left part of the figure is asequence of the phrasal units in a sentence appearing in this or-der and the tree in the right part is its dependency tree.
To findthe relationship between B!F, a word-order based pattern needs adummy expression to hold C, D and E, while TBF can denote thedirect relationship as B!F.
TBP can also represent a complicatedpattern for a node which is far from the root node in the depen-dency tree, like C!D!E, which is hard to represent without thesentence structure.For matching with TBP, the target sentence should be parsed intoa dependency tree.
Then all the predicates are detected and thesubtrees which have a predicate node as a root are traversed to finda match with a pattern.Benefit of TBPTBP has some advantages for pattern matching over the surfaceword-order based patterns in addressing the problems mentionedin the previous section: Free word-order problemTBP can offer a direct representation of the dependency re-lationship even if the word-order is different. Free case-marking problemTBP can freely traverse the whole dependency tree and findany significant path as a pattern.
It does not depend on pre-defined case-patterns as Riloff [4] and Yangarber [6] did. Indirect relationshipsTBP can find indirect relationships, such as the relationshipbetween a predicate and the modifier of the argument of the1In this paper, we used the Japanese parser KNP [1] to obtain thedependency tree of a sentence.predicate.
For example, the pattern?<organization> of!<post> to!appoint?
can capture the rela-tionship between ?<organization>?
and ?to be appointed?in the sentence?<person> was appointed to <post> of <organization>.
? Relationships beyond clausal boundariesTBP can capture relationships beyond clausal boundaries.The pattern ?<post> to!appointCOMP!
announce?
can find therelationship between ?<post>?
and ?to announce?.
This re-lationship, later on, can be combined with the relationship?<organization>?
and ?to announce?
and merged into oneevent.3.
ALGORITHMIn this section, we outline our procedure for automatic acquisi-tion of patterns.
We employ a cascading procedure, as is shownin Figure 3.
First, the original documents are processed by a mor-phological analyzer and NE-tagger.
Then the system retrieves therelevant documents for the scenario as a relevant document set.
Thesystem, further, selects a set of relevant sentences as a relevant sen-tence set from those in the relevant document set.
Finally, all thesentences in the relevant sentence set are parsed and the paths inthe dependency tree are taken as patterns.3.1 Document PreprocessingMorphological analysis and Named Entity (NE) tagging is per-formed on the training data at this stage.
We used JUMAN [2] forthe former and a NE-system which is based on a decision tree algo-rithm [5] for the latter.
Also the part-of-speech information givenby JUMAN is used in the later stages.3.2 Document RetrievalThe system first retrieves the documents that describe the eventsof the scenario of interest, called the relevant document set.
A setof narrative sentences describing the scenario is selected to createa query for the retrieval.
For this experiment, we set the size ofthe relevant document set to 300 and retrieved the documents us-ing CRL?s stochastic-model-based IR system [3], which performedwell in the IR task in IREX, Information Retrieval and Extractionevaluation project in Japan 2.
All the sentences used to create thepatterns are retrieved from this relevant document set.3.3 Sentence RetrievalThe system then calculates the TF/IDF-based score of relevanceto the scenario for each sentence in the relevant document set andretrieves the n most relevant sentences as the source of the patterns,where n is set to 300 for this experiment.
The retrieved sentenceswill be the source for pattern extraction in the next subsection.First, the TF/IDF-based score for every word in the relevant doc-ument set is calculated.
TF/IDF score of word w is:score(w) =(TF (w) log(N+0:5)DF (w)log(N+1)if w is Noun, Verb or Named Entity0 otherwisewhere N is the number of documents in the collection, TF(w) isthe term frequency of w in the relevant document set and DF(w) isthe document frequency of w in the collection.Second, the system calculates the score of each sentence basedon the score of its words.
However, unusually short sentences and2IREX Homepage: http://cs.nyu.edu/cs/projects/proteus/irexDependency Tree Tree-Based Patternff ff f       @@@@@@@       @@@@@@@<organization>-wa<organization>-TOPIC<person>-ga<person>-SUBJ<post>-kara<post>-FROMtaininsuru(retire)happyosuru(announce)    1@@@@R3@@@@@     2fffffff-- --happyosuru(announce)taininsuru(retire)<organization>-wa(<organization>-TOPIC)<person>-ga(<person>-SUBJ)<post>-kara(<post>-FROM)123Figure 1: Tree-Based Pattern RepresentationWord-order PatternA B C D E F6Pattern [B * F]FEBADC3PPPPq3QQs-Pattern [B!F]PPPPPPPPPqPattern [C!E!F]TBPFigure 2: Extraction using Tree-Based Pattern Representationunusually long sentences will be penalized.
The TF/IDF score ofsentence s is:score(s) =Pw2sscore(w)length(s) + jlength(s) AVEjwhere length(s) is the number of words in s, and AVE is the av-erage number of words in a sentence.3.4 Pattern ExtractionBased on the dependency tree of the sentences, patterns are ex-tracted from the relevant sentences retrieved in the previous sub-section.
Figure 4 shows the procedure.
First, the retrieved sentenceis parsed into a dependency tree by KNP [1] (Stage 1).
This stagealso finds the predicates in the tree.
Second, the system takes allthe predicates in the tree as the roots of their own subtrees, as isshown in (Stage 2).
Then each path from the root to a node isextracted, and these paths are collected and counted across all therelevant sentences.
Finally, the system takes those paths with fre-quency higher than some threshold as extracted patterns.
Figure 5shows examples of the acquired patterns.4.
EXPERIMENTIt is not a simple task to evaluate how good the acquired pat-terns are without incorporating them into a complete extraction sys-tem with appropriate template generation, etc.
However, finding amatch of the patterns and a portion of the test sentences can be agood measure of the performance of patterns.The task for this experiment is to find a bunsetsu, a phrasal unit,that includes slot-fillers by matching the pattern to the test sentence.The performance is measured by recall and precision in terms of thenumber of slot-fillers that the matched patterns can find; these arecalculated as follows.Recall =# of Matched Relevant SlotF illers# of All Relevant SlotF illersOriginal Document SetDocumentPreprocessing-Preprocessed Document SetDocumentRetrieval-Relevant Document SetSentence Retrieval       Relevant Sentence Set(Tree representation)fffffPPPPPPPPPatternExtraction-f f ff f ff fExtracted PatternsFigure 3: Pattern Acquisition Procedure Overall ProcessPrecision =# of Matched Relevant SlotF illers# of All Matched SlotF illersThe procedure proposed in this paper is based on bunsetsus, andan individual bunsetsu may contain more than one slot filler.
Insuch cases the procedure is given credit for each slot filler.Strictly speaking, we don?t know how many entities in a matchedpattern might be slot-fillers when, actually, the pattern does notcontain any slot-fillers (in the case of over-generating).
We ap-proximate the potential number of slot-fillers by assigning 1 if the(falsely) matched pattern does not contain any Named-Entities, orassigning the number of Named-Entities in the (falsely) matchedpattern.
For example, if we have a pattern ?go to dinner?
for amanagement succession scenario and it matches falsely in somepart of the test sentences, this match will gain one at the numberof All Matched Slot-fillers (the denominator of the precision).
Onthe other hand, if the pattern is ?<post> <person> laugh?
and itfalsely matches ?President Clinton laughed?, this will gain two, thenumber of the Named Entities in the pattern.For the sake of comparison, we defined the baseline system withthe patterns acquired by the same procedure but only from the di-rect relationships between a predicate and its arguments (PA in Fig-ure 6 and 7).We chose the following two scenarios. Executive Management Succession: events in which corpo-rate managers left their positions or assumed new ones re-gardless of whether it was a present (time of the report) orpast event.Items to extract: Date, person, organization, title. Robbery Arrest: events in which robbery suspects were ar-rested.Items to extract: Date, suspect, suspicion.4.1 DataManagement SuccessionDocuments 15Sentences 79DATE 43PERSON 41ORGANIZATION 22OLD-ORGANIZATION 2NEW-POST 30OLD-POST 39Table 1: Test Set for Management Succession scenarioRobbery ArrestDocuments 28Sentences 182DATE 26SUSPICION 34SUSPECT 50Table 2: Test Set for Robbery Arrest scenarioFor all the experiments, we used the Mainichi-Newspaper-95corpus for training.
As described in the previous section, the systemretrieved 300 articles for each scenario as the relevant document setfrom the training data and it further retrieved 300 sentences as therelevant sentence set from which all the patterns were extracted.Test data was taken from Mainichi-Newspaper-94 by manuallyreviewing the data for one month.
The statistics of the test data areshown in Table 1 and 2.4.2 ResultsFigure 6 and Figure 7 illustrates the precision-recall curve of thisStage 1 (Dependency Tree)<org>-wa<psn>-ga<post>-nishuninsuru(p)-tohappyoshita(p)""bb""bbfffff-Stage 2 (Separated Trees)<org>-wa<psn>-ga<post>-nihappyoshita(p)QQk""bb""bbQQk++1234fffff<psn>-ga<post>-nishuninsuru(p)bb""QQk+56fff(p indicates the node is a predicate.
)Extracted Patterns1 <organization>-wa !
happyosuru2 <person>-ga !
shuninsuru-to !
happyosuru3 <post>-ni !
shuninsuru-to !
happyosuru4 shuninsuru-to !
happyosuru5 <person>-ga !
shuninsuru6 <post>-ni !
shuninsuruJapanese sentence :English Translation :<organization>-wa<organization>-TOPIC<person>-ga<person>-SBJ<post>-ni<post>-TOshuninsuru-tostart-COMPhappyoshita.announced.
(<organization> announced that <person> was appointed to <post>.
)Figure 4: Pattern Acquisition from ?<org>-wa <psn>-ga <pst>-ni shuninsuru-to happyoshita.
?experiment for the executive management succession scenario androbbery arrest scenario, respectively.
We ranked all the acquiredpatterns by calculating the sum of the TF/IDF-based score (sameas for sentence retrieval in Section 3.3) for each word in the patternand sorting them on this basis.
Then we obtained the precision-recall curve by changing the number of the top-ranked patterns inthe list.Figure 6 shows that TBP is superior to the baseline system bothin recall and precision.
The highest recall for TBP is 34% while thebaseline gets 29% at the same precision level.
On the other hand,at the same level of recall, TBP got higher precision (75%) than thebaseline (70%).We can also see from Figure 6 that the curve has a slightly anoma-lous shape where at lower recall (below 20%) the precision is alsolow for both TBP and the baseline.
This is due to the fact thatthe pattern lists for both TBP and the baseline contains some non-reliable patterns which get a high score because each word in thepatterns gets higher score than others.Figure 7 shows the result of this experiment on the Robbery Ar-rest scenario.
Although the overall recall is low, TBP achievedhigher precision and recall (as high as 30% recall at 40% of pre-cision) than the baseline except at the anomalous point where bothTBP and the baseline got a small number of perfect slot-fillers by ahighly ranked pattern, namely ?gotoyogi-de !
taihosuru (to arrest0 20 40 60 80 100Precision0204060Recall+ +++ ++ +++++++++* *** ********+ ... TBP* ... Baseline (PA)Figure 6: Result on Management Succession ScenarioScenario PatternsExecutive Succession : <post>-ni !
shokakusuru (to be promoted to <post>)<post>-ni !
shuninsuru (to assume <post>)<post>-ni !
shokakusuru !
(to announce an informal decision of promoting<jinji>-o !
happyosuru somebody to <post>)Robbery Arrest : satsujin-yogi-de !
taihosuru (to arrest in suspicion of murder)<date> !
taihosuru (to arrest on <date>)satsujin-yogi-de !
taihosuru (to arrest in suspicion of murder)<person>-yogisha !
#-o !
taihosuru (to arrest the suspect, <person>, age #)Figure 5: Acquired Patterns0 20 40 60 80 100Precision0204060Recall+++++++++++***************+ ... TBP* ... Baseline (PA)Figure 7: Result on Robbery Arrest Scenarioon suspicion of robbery)?
for the baseline and ?<person> yogisha!
<number>-o !
taihosuru (to arrest the suspect, <person>,age <number>)?.5.
DISCUSSIONLow RecallIt is mostly because we have not made a class of types of crimesthat the recall on the robbery arrest scenario is low.
Once we havea classifier as reliable as Named-Entity tagger, we can make a sig-nificant gain in the recall of the system.
And in turn, once we havea class name for crimes in the training data (automatically anno-tated by the classifier) instead of a separate name for each crime,it becomes a good indicator to see if a sentence should be used toacquire patterns.
And also, incorporating the classes in patterns canreduce the noisy patterns which do not carry any slot-fillers of thetemplate.For example on the management succession scenario, all theslot-fillers defined there were able to be tagged by the Named-Entity tagger [5] we used for this experiment, including the title.Since we knew all the slot-fillers were in one of the classes, wealso knew those patterns whose argument was not classified anyof the classes would not likely capture slot-fillers.
So we couldput more weight on those patterns which contained <person>,<organization>, <post> and <date> to collect the patterns withhigher performance, and therefore we could achieve high precision.Erroneous Case AnalysisWe also investigated other scenarios, namely train accident and air-plane accident scenario, which we will not report in this paper.However, some of the problems which arose may be worth men-tioning since they will arise in other, similar scenarios. Results or Effects of the Target EventEspecially for the airplane accident scenario, most errors wereidentified as matching the effect or result of the incident.
Atypical example is ?Because of the accident, the airport hadbeen closed for an hour.?
In the airplane accident scenario,the performance of the document retrieval and the sentenceretrieval is not as good as the other two scenarios, and there-fore, the frequency of relevant acquired patterns is rather lowbecause of the noise.
Further improvement in retrieval and amore robust approach is necessary. Related but Not-Desired SentencesIf the scenario is specific enough to make it difficult as an IRtask, the result of the document retrieval stage may includemany documents related to the scenario in a broader sensebut not specific enough for IE tasks.
In this experiment, thiswas the case for the airplane accident scenario.
The result ofdocument retrieval included documents about other accidentsin general, such as traffic accidents.
Therefore, the sentenceretrieval and pattern acquisition for these scenarios were af-fected by the results of the document retrievals.6.
FUTURE WORKInformation ExtractionTo apply the acquired patterns to an information extraction task,further steps are required besides those mentioned above.
Sincethe patterns are a set of the binary relationships of a predicate andanother element, it is necessary to merge the matched elements intoa whole event structure.Necessity for GeneralizationWe have not yet attempted any (lexical) generalization of patterncandidates.
The patterns can be expanded by using a thesaurusand/or introducing a new (lexical) class suitable for a particulardomain.
For example, the class of expressions of flight numberclearly helps the performance on the airplane accident scenario.Especially, the generalized patterns will help improve recall.Robust Pattern ExtractionAs is discussed in the previous section, the performance of our sys-tem relies on each component.
If the scenario is difficult for the IRtask, for example, the whole result is affected.
The investigation ofa more conservative approach would be necessary.TranslingualismThe presented results show that our procedure of automatic pat-tern acquisition is promising.
The procedure is quite general andaddresses problems which are not specific to Japanese.
With an ap-propriate morphological analyzer, a parser that produces a depen-dency tree and an NE-tagger, our procedure should be applicable toalmost any language.7.
ACKNOWLEDGMENTSThis research is supported by the Defense Advanced ResearchProjects Agency as part of the Translingual Information Detec-tion, Extraction and Summarization (TIDES) program, under GrantN66001-00-1-8917 from the Space and Naval Warfare Systems Cen-ter San Diego.
This paper does not necessarily reflect the positionor the policy of the U.S. Government.8.
REFERENCES[1] S. Kurohashi and M. Nagao.
Kn parser : Japanesedependency/case structure analyzer.
In the Proceedings of theWorkshop on Sharable Natural Language Resources, 1994.
[2] Y. Matsumoto, S. Kurohashi, O. Yamaji, Y. Taeki, andM.
Nagano.
Japanese morphological analyzing system:Juman.
Kyoto University and Nara Institute of Science andTechnology, 1997.
[3] M. Murata, K. Uchimoto, H. Ozaku, and Q. Ma.
Informationretrieval based on stochastic models in irex.
In theProceedings of the IREX Workshop, 1994.
[4] E. Riloff.
Automatically generating extraction patterns fromuntagged text.
In the Proceedings of Thirteenth NationalConference on Artificial Intelligence (AAAI-96), 1996.
[5] S. Sekine, R. Grishman, and H. Shinnou.
A decision treemethod for finding and classifying names in japanese texts.
Inthe Proceedings of the Sixth Workshop on Very LargeCorpora, 1998.
[6] R. Yangarber, R. Grishman, P. Tapanainen, and S. Huttunen.Unsupervised discovery of scnario-level patterns forinformation extraction.
In the Proceedings of the Sixth AppliedNatural Language Processing Conference, 2000.
