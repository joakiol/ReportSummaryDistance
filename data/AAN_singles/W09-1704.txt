Proceedings of the NAACL HLT Workshop on Unsupervised and Minimally Supervised Learning of Lexical Semantics, pages 27?35,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsCross-lingual Predicate Cluster Acquisition to ImproveBilingual Event Extraction by Inductive LearningHeng JiComputer Science DepartmentQueens College and The Graduate CenterThe City University of New Yorkhengji@cs.qc.cuny.eduAbstractIn this paper we present two approaches toautomatically extract cross-lingual predi-cate clusters, based on bilingual parallelcorpora and cross-lingual information ex-traction.
We demonstrate how these clus-ters can be used to improve the NISTAutomatic Content Extraction (ACE) eventextraction task1.
We propose a new induc-tive learning framework to automaticallyaugment background data for low-confidence events and then conduct globalinference.
Without using any additionaldata or accessing the baseline algorithmsthis approach obtained significant im-provement over a state-of-the-art bilingual(English and Chinese) event extraction sys-tem.1 IntroductionEvent extraction, the ?classical?
information extrac-tion (IE) task, has progressed from Message Un-derstanding Conference (MUC)-style singletemplate extraction to the more comprehensivemulti-lingual Automatic Content Extraction (ACE)extraction including more fine-grained types.
Thisextension has made event extraction more widelyapplicable in many NLP tasks including cross-lingual document retrieval (Hakkani-Tur et al,2007) and question answering (Schiffman et al,2007).
Various supervised learning approaches1 http://www.nist.gov/speech/tests/ace/have been explored for ACE multi-lingual eventextraction (e.g.
Grishman et al, 2005; Ahn, 2006;Hardy et al, 2006; Tan et al, 2008; Chen and Ji,2009).
All of these previous literatures showed thatone main bottleneck of event extraction lies in lowrecall.
It?s a challenging task to recognize the dif-ferent forms in which an event may be expressed,given the limited amount of training data.
The goalof this paper is to improve the performance of abilingual (English and Chinese) state-of-the-artevent extraction system without accessing its inter-nal algorithms or annotating additional data.As for a separate research theme, extensivetechniques have been used to produce word clus-ters or paraphrases from large unlabeled corpora(Brown et al, 1990; Pereira et al, 1993; Lee andPereira, 1999, Barzilay and McKeown, 2001; Linand Pantel, 2001; Ibrahim et al, 2003; Pang et al,2003).
For example, (Bannard and Callison-Burch,2005) and (Callison-Burch, 2008) described amethod to extract paraphrases from largely avail-able bilingual corpora.
The resulting clusters con-tain words with similar semantic information andtherefore can be useful to augment a small amountof annotated data.
We will automatically extractcross-lingual predicate clusters using two differentapproaches based on bilingual parallel corpora andcross-lingual IE respectively; and then use the de-rived clusters to improve event extraction.We propose a new learning method called in-ductive learning to exploit the derived predicateclusters.
For each test document, a backgrounddocument is constructed by gradually replacing thelow-confidence events with the predicates in thesame cluster.
Then we conduct cross-documentinference technique as described in (Ji and Grish-27man, 2008) to improve the performance of eventextraction.
This inductive learning approachmatches the procedure of human knowledge acqui-sition and foreign language education: analyze in-formation from specific examples and thendiscover a pattern or draw a conclusion; attemptsynonyms to convey/learn the meaning of an intri-cate word.The rest of this paper is structured as follows.Section 2 describes the terminology used in thispaper.
Section 3 presents the overall system archi-tecture and the baseline system.
Section 4 then de-scribes in detail the approaches of extracting cross-lingual predicate clusters.
Section 5 describes themotivations of using cross-lingual clusters to im-prove event extraction.
Section 6 presents an over-view of the inductive learning algorithm.
Section 7presents the experimental results.
Section 8 com-pares our approach with related work and Section 9then concludes the paper and sketches our futurework.2 TerminologyThe event extraction task we are addressing is thatof ACE evaluations.
ACE defines the followingterminology:entity: an object or a set of objects in one of thesemantic categories of interestmention: a reference to an entity (typically, anoun phrase)event trigger: the main word which most clearlyexpresses an event occurrenceevent arguments: the mentions that are in-volved in an event (participants)event mention: a phrase or sentence withinwhich an event is described, including triggerand argumentsThe 2005 ACE evaluation had 8 types of events,with 33 subtypes; for the purpose of this paper, wewill treat these simply as 33 distinct event types.For example, for a sentence ?Barry Diller onWednesday quit as chief of Vivendi Universal En-tertainment?, the event extractor should detect allthe following information: a ?Personnel_End-Position?
event mention, with ?quit?
as the triggerword, ?chief?
as an argument with a role of  ?posi-tion?, ?Barry Diller?
as the person who quit theposition, ?Vivendi Universal Entertainment?
as theorganization, and the time during which the eventhappened is ?Wednesday?.3 Approach Overview3.1 System PipelineFigure 1 depicts the general procedure of our ap-proach.
The set of test event mentions is improvedby exploiting cross-lingual predicate clusters.Figure 1.
System OverviewThe following section 3.2 will give more detailsabout the baseline bilingual event tagger.
Then wewill present the predicate cluster acquisition algo-rithm in section 4 and the method of exploitingclusters for event extraction in section 6.3.2 A Baseline Bilingual Event ExtractionSystemWe use a state-of-the-art bi-lingual event extrac-tion system (Grishman et al, 2005; Chen and Ji,2009) as our baseline.
The system combines pat-tern matching with a set of Maximum Entropyclassifiers: to distinguish events from non-events;Inductive LearningCross-lingual PredicateCluster AcquisitionTestDocumentBaselineEvent ExtractionPredicate ClustersUnlabeledCorporaCross-lingualIEBackgroundDocumentLow-confidenceEventReplacementCross-documentInferenceTest EventsParallelCorporaAlignmentBased ClusteringBaselineEvent ExtractionBackgroundEventsImprovedTest Events28to classify events by type and subtype; to distin-guish arguments from non-arguments; to classifyarguments by argument role; and given a trigger,an event type, and a set of arguments, to determinewhether there is a reportable event mention.
In ad-dition, the Chinese system incorporates some lan-guage-specific features to address the problem ofword segmentation (Chen and Ji, 2009).4 Cross-lingual Predicate Cluster Acqui-sitionWe start from two different approaches to extractcross-lingual predicate clusters, based on parallelcorpora and cross-lingual IE techniques respec-tively.4.1 Acquisition from Bilingual Parallel Cor-poraIn the first approach, we take use of the 852 Chi-nese event trigger words in ACE05 training cor-pora as our ?anchor set?.
For each Chinese trigger,we search its automatically aligned English wordsfrom a Chinese-English parallel corpus including50,000 sentence pairs (part of Global AutonomousLanguage Exploitation Y3 Machine Translationtraining corpora) to construct an English predicatecluster.
The word alignment was obtained by run-ning Giza++ (Och and Ney, 2003).
In each clusterwe record the frequency of each unique Englishword.
Then we conduct the same procedure in theother direction to construct Chinese predicate clus-ters anchored by English triggers.State-of-the-art Chinese-English word alignmenterror rate is about 40% (Deng and Byrne, 2005).Therefore the resulting cross-lingual clusters in-clude a lot of word alignment errors.
In order toaddress this problem, we filter the clusters by onlykeeping those predicates including the originalpredicate forms in ACE training data or Eng-lish/Chinese Propbank (Palmer et al, 2005; Xueand Palmer, 2009).4.2 Acquisition from Cross-lingual IEBased on the intuition that Machine Translation(MT) may translate a Chinese trigger word intodifferent English words in different contexts, weemploy the second approach using cross-lingual IEtechniques (Hakkani-Tur et al, 2007) on TDT5Chinese corpus to generate more clusters.
We ap-ply the following two cross-lingual IE pipelines:Chinese IE_MT: Apply Chinese IE on the Chinesetexts to get a set of Chinese triggers ch-trigger-set1,and then use word alignments to translate (project)ch-trigger-set1 into a set of English triggers en-trigger-set1;MT_English IE: Translate Chinese texts into Eng-lish, and then apply English IE on the translatedtexts to get a set of English triggers en-trigger-set2.For any Chinese trigger ch-trigger in ch-trigger-set1, if its corresponding translation en-trigger inen-trigger-set1 is the same as that in en-trigger-set2, then we add en-trigger into the cluster an-chored by ch-trigger.We apply the English and Chinese IE systemsas described in (Grishman et al, 2005; Chen and Ji,2009).
Both cross-lingual IE pipelines need ma-chine translation to translate Chinese documents(for English IE) or project the extraction resultsfrom Chinese IE into English.
We use the RWTHAachen Chinese-to-English statistical phrase-basedmachine translation system (Zens and Ney, 2004)for these purposes.4.3 Derived Cross-lingual Predicate ClustersApplying the above two approaches we obtained438 English predicate clusters and 543 Chinesepredicate clusters.For example, for a trigger ??
(injure)?, we canget the following two predicate clusters with theirfrequency in the parallel corpora:??
{injured:99 injuries:96 injury:76wounded:38 wounding:28 injuring:14 wounds:7killed:4 died:2 mutilated:1 casualties:1 chop:1 kill-ing:1 shot:1}.injured ?
{??
:1624 ??
:102 ?
:99 ??
:29 ??
:23 ?
:12 ??
:10 ??
:6 ??
:3 ??
:2 ??:1?
:1 ??
:1 ??
:1 ??
:1 ??
:1 ??
:1 ??
:1 }We can see that the predicates in the same clus-ter are not restrictedly synonyms, but they weregenerated as alternative translations for the sameword and therefore represent similar meanings.More importantly, these triggers vary from verycommon ones such as ?injured?
to rare words suchas ?mutilate?.
This indicates how these clusters canaid extracting low-confidence events: when decid-ing whether a word ?mutilate?
indicates a ?Life-29Injure?
event in a certain context, we can replace itwith other predicates in the same cluster and mayprovide us more reliable overall evidence.Figure 2 presents the distribution of clusterswhich include more than one predicate.Figure 2.
Cluster Size DistributionWe can see that most clusters include 2-9 predi-cates in both English and Chinese.
However onaverage English clusters include more predicates.In addition, there are many more singletons inChinese (232) than in English (101).
This indicatesthat Chinese event triggers are more ambiguous.5 Motivation of Using Cross-lingual Clus-ters for Event ExtractionAfter extracting cross-lingual predicate clusters,we can combine the evidence from all the predi-cates in each cluster to adjust the probabilities ofevent labeling.
In the following we present someexamples in both languages to demonstrate thismotivation.5.1 Improve Rare Trigger LabelingDue to the limited training data, many triggerwords only appear a few times as a particular typeof event.
This data sparse problem directly leads tothe low recall of trigger labeling.
But exploitingthe evidence from other predicates in the samecluster may boost the confidence score of the can-didate event.
We present two examples as follows.
(1) English Example 1For example, ?blown up?
doesn?t appear in thetraining data as a ?Conflict-Attack?
event, and so itcannot be identified in the following test sentence.However, if we replace it with other predicates inthe same cluster, the system can easily identify?Conflict-Attack?
events in the new sentences withhigh confidence values:(a) Test Sentence:Identified as  ?Conflict-Attack?
Event with Confi-dence=0:He told AFP that Israeli intelligence had been deal-ing with at least 40 tip-offs of impending attackswhen the Haifa bus was blown up.
(b) Cross-lingual Cluster??
?
{ blown up:4 bombing:3 blew:2 destroying:1destroyed:1 }(c) Replaced SentencesIdentified as ?Conflict-Attack?
Event with Confi-dence=0.799:He told AFP that Israeli intelligence had been deal-ing with at least 40 tip-offs of impending attackswhen the Haifa bus was destroyed.?
(2) Chinese Example 1Chinese predicate clusters anchored by Englishwords can also provide external evidence for eventidentification.
For example, the trigger word ???(release/parole)?
appears rarely in the Chinesetraining data but in most cases it can be replacedby a more frequent trigger ???(release)?
to rep-resent the same meaning.
Therefore by combiningthe evidence from ????
we can enhance the con-fidence value of identifying ????
as a  ?Justice-Release_Parole?
event.
For example,(a) Test Sentence:Identified as ?Justice-Release_Parole?
Event withConfidence=0:?????????????????????.
?
(This suspect was released because of the vio-lation case but committed a felony again.
)30(b) Cross-lingual Clusterreleasing ?
{??
:4 ??
:1 }(c) Replaced SentencesIdentified as ?Justice-Release_Parole?
Event withConfidence=0.964:?????????????????????.
?5.2 Improve Frequent Trigger LabelingOn the other hand, some common words are highlyambiguous in particular contexts.
But the otherless-ambiguous predicates in the clusters can helpclassify event types more accurately.
(1) English Example 2For example, in the following sentence the ?Per-sonnel-End_Position?
event is missing because?step?
doesn?t indicate any ACE events in thetraining data.
However, after replacing ?step?
withother prediates such as ?quit?, the system can iden-tify the event more easily:(a) Test Sentence:Identified as ?Personnel-End_Position?
Eventwith Confidence=0:Barry Diller on Wednesday step from chief of VivendiUniversal Entertainment, the entertainment unit ofFrench giant Vivendi Universal.
(b) Cross-lingual Cluster??
?
{ resign:6 step:5 quit:3}(c) Replaced SentencesClassified as ?Personnel-End_Position?
Eventwith Confidence=0.564:Barry Diller on Wednesday quit from chief of VivendiUniversal Entertainment, the entertainment unit ofFrench giant Vivendi Universal.?
(2) Chinese Example 2Some single-character Chinese predicates can rep-resent many different event types in different con-texts.
For example, the word ???
appears in 27different predicate clusters, representing the mean-ing of hit/call/strike/form/take/draw etc.
Thereforewe can take use of other less ambiguous predicatesin these clusters to adjust the likelihood of eventclassification.For example, in the following test sentence, theword ???
indicates two different event types.
Ifwe replace these words with other predicates, wecan classify them into different event types moreaccurately based on the evidence from replacedpredicates and contexts.
(a) Test Sentence:Event Classification for trigger word ???:??????????
(?call?, Phone-Write eventwith confidence 0) ????????????????
10 ????????
(?attacked/killed?,Conflict-Attack event with confidence 0.528)????????
(?attacked?, Conflict-Attack event withconfidence 0.946)???????????
(Severaldays ago the Captain called  urgent telegraphs to askfor help, expressing that the boat pilot Cai Mingzhiwas already killed by mainland fishermen and hehimself was assaulted and duressed to the mainland.
)(b) Cross-lingual Clustercall?
{???
:6 ??
:6 ?
:1 ??
:1 }attack?{??
:564 ??
:110 ??
:114 ??
:24 ??
:15 ??
:15 ??
:15 ?
:8 ?
:6 ??
:6 ??
:5 ??
:4 ??
:3 ??
:3 ??
:2 ??
:2 ?
:2 ??
:2 ??
:2 ??
:2 ??
:1 ??
:1 ??
:1 ??
:1 ??:1?
:1 ??
:1 ?
:1 }(c) Replaced SentencesEvent Classification for trigger word ???
withhigher confidence:???????????
(?call?, Phone-Writeevent with confidence 0.938) ??????????
?
?
?
?
?
?
10 ?
?
?
?
?
?
?
?
(?attacked/killed?, Conflict-Attack event with confi-dence 0.583)????????
(?attacked?, Con-flict-Attack event with confidence 0.987)???????????
?Based on the above motivations we propose toincorporate cross-lingual predicate clusters to re-fine event identification and classification.
In order31to exploit these clusters effectively, we shall gen-erate additional background data and conductglobal confidence.
The sections below will presentthe detailed algorithms.6 Inductive LearningWe design a framework of inductive learning toincorporate the derived predicate clusters.
Thegeneral idea of inductive learning is to analyze in-formation from all kinds of specific examples untilwe can draw a conclusion.
Since the main goal ofour approach is to improve the recall of event ex-traction, we shall focus on those events generatedby the baseline tagger with low confidence.
Forthose events we automatically generate back-ground documents using the predicate clusters (de-tails in section 6.1) and then conduct globalinference between each test document and itsbackground documents (section 6.2).6.1 Background Document GenerationFor each event mention in a test document, thebaseline event tagger produces the following localconfidence value:?
LConf(trigger, etype): The probability of astring trigger indicating an event mention withtype etype in a context sentence S;If LConf(trigger, etype) is lower than a threshold,and it belongs to a predicate cluster C,  we createan additional background document BD by:?
For each predicatei ?
C, we replace triggerwith predicatei in S to generate new sentenceS?, and add S?
into BD.6.2 Global InferenceFor each background document BD, we apply thebaseline event extraction and get a set of back-ground events.
We then apply the cross-documentinference techniques as described in (Ji andGrishman, 2008) to improve trigger and argumentlabeling performance by favoring interpretationconsistency across the test events and backgroundevents.This approach is based on the premise that manyevents will be reported multiple times from differ-ent sources in different forms.
This naturally oc-curs in the test document and the backgrounddocument because they include triggers from thesame predicate cluster.By aggregating events across each pair of testdocument TD and background document BD, weconduct the following statistical global inference:?
to remove triggers and arguments with lowconfidence in TD and BD;?
to adjust trigger and argument identificationand classification to achieve consistency acrossTD and BD.In this way we can propagate highly consistentand frequent triggers and arguments with highglobal confidence to override other, lower confi-dence, extraction results.7 Experimental Results7.1 Data and Scoring MetricWe used ACE2005 English and Chinese trainingcorpora to evaluate our approach.
Table 1 showsthe number of documents used for training, devel-opment and blind testing.Language TrainingSetDevelopmentSetTest SetEnglish 525 33 66Chinese 500 10 40Table 1.
Number of DocumentsWe define the following standards to determinethe correctness of an event mention:?
A trigger is correctly identified if its positionin the document matches a reference trigger.?
A trigger is correctly identified and classifiedif its event type and position in the documentmatch a reference trigger.?
An argument is correctly identified if its eventtype and position in the document match anyof the reference argument mentions.?
An argument is correctly identified and classi-fied if its event type, position in the document,and role match any of the reference argumentmentions.32TriggerIdentification+ClassificationArgumentIdentificationArgumentIdentification+ClassificationPerformanceLanguage/SystemP R F P R FArgumentClassificationAccuracyP R FBaseline 67.8 53.5 59.8 49.3 31.4 38.3 88.2 43.5 27.7 33.9English After UsingCross-lingualPredicate Clusters69.2 59.4 63.9 51.7 32.7 40.1 89.6 46.3 29.3 35.9Baseline 58.1 47.2 52.1 46.2 33.7 39.0 95.0 43.9 32.0 37.0Chinese After UsingCross-lingualPredicate Clusters60.2 52.6 56.1 46.8 36.7 41.1 95.6 44.7 35.1 39.3Table 2.
Overall Performance on Blind Test Set (%)7.2 Confidence Metric ThresholdingBefore blind testing we select the thresholds for thetrigger confidence LConf(trigger, etype) as definedin section 6.1 by optimizing the F-measure score ofon the development set.
Figure 3 shows the effecton precision and recall of varying the threshold forinductive learning using cross-lingual predicateclusters.Figure 3.
Trigger Labeling Performance withInductive Learning Confidence Thresholding onEnglish Development SetWe can see that the best performance on the de-velopment set can be obtained by selecting thresh-old 0.6, achieving 9.4% better recall with a littleloss in precision (0.26%) compared to the baseline(with threshold=0) .
Then we apply this thresholdvalue directly for blind test.
This optimizing pro-cedure is repeated for Chinese as well.7.3 Overall PerformanceTable 2 shows the overall Precision (P), Recall (R)and F-Measure (F) scores for the blind test set.For both English and Chinese, the inductivelearning approach using cross-lingual predicateclusters provided significant improvement over thebaseline event extraction system (about 4% abso-lute improvement on trigger labeling and 2%-2.3%on argument labeling).
The most significant gainwas provided for the recall of trigger labeling ?5.9% absolute improvement for English and 5.4%absolute improvement for Chinese.Surprisingly this approach didn?t cause any lossin precision.
In fact small gains were obtained onprecision for both languages.
This indicates thatcross-lingual predicate clusters are effective at ad-justing the confidence values so that the eventswere not over-generated.
The refined event triggerlabeling also directly yields better performance inargument labeling.We conducted the Wilcoxon Matched-PairsSigned-Ranks Test on a document basis.
The re-sults show that for both languages the improve-ment using cross-lingual predicate clusters issignificant at a 99.7% confidence level for triggerlabeling and a 96.4% confidence level for argu-ment labeling.7.4 DiscussionFor comparison we attempted a self-training ap-proach: adding high-confidence events in the testset back as additional training data and re-train theevent tagger.
This produced 1.7% worse F-measurescore for the English development set.
It further33proves that using the test set itself is not enough,we need to explore new predicates to serve asbackground evidence.In addition we also applied a bootstrapping ap-proach using relevant unlabeled data and obtainedlimited improvement ?
about 1.6% F-measure gainfor English.
As Ji and Grishman (2006) pointed out,both self-training and bootstrapping methods re-quire good data selection scheme.
But not for anytest set we can easily find relevant unlabeled data.Therefore the approach presented in this paper isless expensive ?
we can automatically generatebackground data while introducing new evidence.An alternative way of incorporating the cross-lingual predicate clusters would follow (Miller etal., 2004), namely encoding the cluster member-ship as an additional feature in the supervised-learning procedure of the baseline event tagger.However in the situation where we cannot directlychange the algorithms of the baseline system, ourapproach of inductive learning is more flexible.8 Related WorkOur approach of extracting predicate clusters isrelated to some prior work on paraphrase or wordcluster discovery, either from mono-lingual paral-lel corpora (e.g.
Barzilay and McKeown, 2001; Linand Pantel, 2001; Ibrahim et al, 2003; Pang et al,2003) or cross-lingual parallel corpora (e.g.
Ban-nard and Callison-Burch, 2005; Callison-Burch,2008).
Shinyama and Sekine (2003) presented anapproach of extracting paraphrases using names,dates and numbers as anchors.
Hasegawa et al(2004) described a paraphrase discovery approachbased on clustering concurrent name pairs.Several recent studies have stressed the benefitsof using paraphrases or word clusters to improveIE components.
For example, (Miller et al, 2004)proved that word clusters can significantly improveEnglish name tagging.
The idea of using predicatesin the same cluster for candidate trigger replace-ment is similar to Ge et al(1998) who used localcontext replacement for pronoun resolution.
To thebest of our knowledge, our work presented the firstexperiment of using cross-lingual predicate para-phrases for the ACE event extraction task.9 Conclusion and Future WorkIn this paper we described two approaches to ex-tract cross-lingual predicate clusters, and designeda new inductive learning framework to effectivelyincorporate these clusters for event extraction.Without using any additional data or changing thebaseline algorithms, we demonstrated that thismethod can significantly enhance the performanceof a state-of-the-art bilingual event tagger.We have noticed that the current filteringscheme based on Propbank may be too restricted tokeep enough informative predicates.
In the futurewe will attempt incorporating POS tagging resultsand frequency information.In addition we will extend this framework to ex-tract cross-lingual relation and name clusters toimprove other IE tasks such as name tagging, rela-tion extraction, event coreference and event trans-lation.
We are also interested in automaticallydiscovering new event types (non-ACE event types)or more fine-grained subtypes/attributes for exist-ing ACE event types from the derived predicateclusters.AcknowledgmentsThis material is based upon work supported by theDefense Advanced Research Projects Agency un-der Contract No.
HR0011-06-C-0023 via 27-001022, and the CUNY Research EnhancementProgram and GRTI Program.ReferencesDavid Ahn.
2006.
The stages of event extraction.
Proc.COLING/ACL 2006 Workshop on Annotating andReasoning about Time and Events.
Sydney, Australia.Colin Bannard and Chris Callison-Burch.
2005.
Para-phrasing with Bilingual Parallel Corpora.
Proc.
ACL2005.Regina Barzilay and Kathleen McKeown.
2001.
Ex-tracting Paraphrases from a Parallel Corpus.
Proc.ACL 2001.Peter F. Brown, Vinvent J. Della pietra, Peter V.deSouza, Jenifer C. Lai, Robert L. Mercer.
1990.Class-based N-gram Models of Natural Language.Computational Linguistics.Chris Callison-Burch.
2008.
Syntactic Constraints onParaphrases Extracted from Parallel Corpora.
Proc.EMNLP 2008.
Honolulu, USA.Zheng Chen and Heng Ji.
2009.
Language Specific Is-sue and Feature Exploration in Chinese Event Extrac-tion.
Proc.
HLT-NAACL 2009.
Boulder, Co.34Yonggang Deng and William Byrne.
2005.
HMM Wordand Phrase Alignment for Statistical Machine Trans-lation.
Proc.
HLT-EMNLP 2005.
Vancouver, Can-anda.Niyu Ge, John Hale and Eugene Charniak.
1998.
A Sta-tistical Approach to Anaphora Resolution.
Proc.Sixth Workshop on Very Large CorporaRalph Grishman, David Westbrook and Adam Meyers.2005.
NYU?s English ACE 2005 System Description.Proc.
ACE 2005 Evaluation Workshop.
Washington,US.Dilek Hakkani-Tur, Heng Ji and Ralph Grishman.
2007.Using Information Extraction to Improve Cross-lingual Document Retrieval.
Proc.
RANLP2007workshop on Multi-source, Multilingual InformationExtraction and Summarization.Hilda Hardy, Vika Kanchakouskaya and TomekStrzalkowski.
2006.
Automatic Event ClassificationUsing Surface Text Features.
Proc.
AAAI06 Work-shop on Event Extraction and Synthesis.
Boston,Massachusetts.
US.Takaaki Hasegawa, Satoshi Sekine and Ralph Grishman.2004.
Discovering Relations among Named Entitiesfrom Large Corpora.
Proc.
ACL 2004.
Barcelona,Spain.Ali Ibrahim, Boris Katz and Jimmy Lin.
2003.
Extract-ing Structural Paraphrases from Aligned Monolin-gual Corpora.
Proc.
ACL 2003.Heng Ji and Ralph Grishman.
2006.
Data Selection inSemi-supervised Learning for Name Tagging.
Proc.ACL 2006 Workshop on Information Extraction Be-yond the Document.
Sydney, Australia.Heng Ji and Ralph Grishman.
2008.
Refining EventExtraction Through Cross-document Inference.
Proc.ACL 2008.
Ohio, USALillian Lee and Fernando Pereira.
1999.
DistributionalSimilarity Models: Clustering vs.
Nearest Neighbors.Proc.
ACL1999.
pp.
33-40.Dekang Lin and Patrick Pantel.
2001.
DIRT-Discoveryof Inference Rules from Text.
Proc.
ACM SIGDDConference on Knowledge Discovery and Data Min-ing.Scott Miller, Jethran Guinness and Alex Zamanian.2004.Name Tagging with Word Clusters and Discrimina-tive Training.
Proc.
HLT-NAACL2004.
pp.
337-342.Boston, USA.Franz Josef Och and Hermann Ney.
2003.
"A System-atic Comparison of Various Statistical AlignmentModels", Computational Linguistics, volume 29,number 1, pp.
19-51.Martha Palmer, Daniel Gildea and Paul Kingsbury.2005.
The Proposition Bank: An Annotated Corpusof Semantic Roles.
Computational Linguistics.
Vol-ume 31, Issue 1. pp.
71-106.Bo Pang, Kevin Knight and Daniel Marcu.
2003.
Syn-tax-based Alignment of Multiple Translations: Ex-tracting Paraphrases and Generating New Sentences.Proc.
HLT/NAACL 2003.Fernando Pereira, Naftali Tishby and Lillian Lee.
1993.Distributional Clustering of English Words.
Proc.ACL1993.
pp.
183-190.Barry Schiffman, Kathleen R. McKeown, Ralph Grish-man and James Allan.
2007.
Question Answering us-ing Integrated Information Retrieval and InformationExtraction.
Proc.
HLT-NAACL 2007.
Rochester, US.Yusuke Shinyama and Satoshi Sekine.
2003.
ParaphraseAcquisition for Information Extraction.
Proc.
ACL2003 workshop on Paraphrasing (IWP 2003).Hongye Tan, Tiejun Zhao and Jiaheng Zheng.
2008.Identification of Chinese Event and Their ArgumentRoles.
Proc.
Computer and Information TechnologyWorkshops.Nianwen Xue and Martha Palmer.
2009.
Adding seman-tic roles to the Chinese Treebank.
Natural LanguageEngineering, 15(1):143-172.Richard Zens and Hermann Ney.
2004.
Improvementsin Phrase-Based Statistical Machine Translation.
InHLT/NAACL 2004.
New York City, NY, US35
