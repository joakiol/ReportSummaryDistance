Proceedings of ACL-08: HLT, pages 630?637,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsRobust Dialog Management with N-best Hypotheses Using Dialog Examplesand AgendaCheongjae Lee, Sangkeun Jung and Gary Geunbae LeePohang University of Science and TechnologyDepartment of Computer Science and EngineeringPohang, Republic of Korea{lcj80,hugman,gblee}@postech.ac.krAbstractThis work presents an agenda-based approachto improve the robustness of the dialog man-ager by using dialog examples and n-bestrecognition hypotheses.
This approach sup-ports n-best hypotheses in the dialog man-ager and keeps track of the dialog state us-ing a discourse interpretation algorithm withthe agenda graph and focus stack.
Giventhe agenda graph and n-best hypotheses, thesystem can predict the next system actionsto maximize multi-level score functions.
Toevaluate the proposed method, a spoken dia-log system for a building guidance robot wasdeveloped.
Preliminary evaluation shows thisapproach would be effective to improve the ro-bustness of example-based dialog modeling.1 IntroductionDevelopment of spoken dialog systems involves hu-man language technologies which must cooperateto answer user queries.
Since the performance inhuman language technologies such as AutomaticSpeech Recognition (ASR) and Natural LanguageUnderstanding (NLU)1 have been improved, this ad-vance has made it possible to develop spoken dialogsystems for many different application domains.Nevertheless, there are major problems for practi-cal spoken dialog systems.
One of them which mustbe considered by the Dialog Manager (DM) is theerror propagation from ASR and NLU modules.
In1Through this paper, we will use the term natural languageto include both spoken language and written languagegeneral, errors in spoken dialog systems are preva-lent due to errors in speech recognition or languageunderstanding.
These errors can cause the dialogsystem to misunderstand a user and in turn lead toan inappropriate response.
To avoid these errors, abasic solution is to improve the accuracy and robust-ness of the recognition and understanding processes.However, it has been impossible to develop perfectASR and NLU modules because of noisy environ-ments and unexpected input.
Therefore, the devel-opment of robust dialog management has also beenone of the most important goals in research on prac-tical spoken dialog systems.In the dialog manager, a popular method to dealwith these errors is to adopt dialog mechanisms fordetecting and repairing potential errors at the con-versational level (McTear et al, 2005; Torres et al,2005; Lee et al, 2007).
In human-computer com-munication, the goal of error recovery strategy isto maximize the user?s satisfaction of using the sys-tem by guiding for the repair of the wrong informa-tion by human-computer interaction.
On the otherhand, there are different approaches to improve therobustness of dialog management using n-best hy-potheses.
Rather than Markov Decision Processes(MDPs), partially observable MDPs (POMDPs) po-tentially provide a much more powerful frameworkfor robust dialog modeling since they consider n-best hypotheses to estimate the distribution of thebelief state (Williams and Young, 2007).In recent, we proposed another data-driven ap-proach for the dialog modeling called Example-based Dialog Modeling (EBDM) (Lee et al, 2006a).However, difficulties occur when attempting to de-630ploy EBDM in practical spoken dialog systems inwhich ASR and NLU errors are frequent.
Thus,this paper proposes a new method to improve the ro-bustness of the EBDM framework using an agenda-based approach and n-best recognition hypotheses.We consider a domain-specific agenda to estimatethe best dialog state and example because, in task-oriented systems, a current dialog state is highly cor-related to the previous dialog state.
We have alsoused the example-based error recovery approach tohandle exceptional cases due to noisy input or unex-pected focus shift.This paper is organized as follows.
Previous re-lated work is described in Section 2, followed by themethodology and problems of the example-based di-alog modeling in Section 3.
An agenda-based ap-proach for heuristics is presented in Section 4.
Fol-lowing that, we explain greedy selection with n-besthypotheses in Section 5.
Section 6 describes theerror recovery strategy to handle unexpected cases.Then, Section 7 provides the experimental results ofa real user evaluation to verify our approach.
Finally,we draw conclusions and make suggestions for fu-ture work in Section 8.2 Related WorkIn many spoken dialog systems that have been devel-oped recently, various knowledge sources are used.One of the knowledge sources, which are usuallyapplication-dependent, is an agenda or task model.These are powerful representations for segmentinglarge tasks into more reasonable subtasks (Rich andSidner, 1998; Bohus and Rudnicky, 2003; Young etal., 2007).
These are manually designed for variouspurposes including dialog modeling, search spacereduction, domain knowledge, and user simulation.In Collagen (Rich and Sidner, 1998), a plan tree,which is an approximate representation of a partialSharedPlan, is composed of alternating act and planrecipe nodes for internal discourse state representa-tion and discourse interpretation.In addition, Bohus and Rudnicky (2003) have pre-sented a RavenClaw dialog management which isan agenda-based architecture using hierarchical taskdecomposition and an expectation agenda.
For mod-eling dialog, the domain-specific dialog control isrepresented in the Dialog Task Specification layerusing a tree of dialog agents, with each agent han-dling a certain subtask of the dialog task.Recently, the problem of a large state space inPOMDP framework has been solved by groupingstates into partitions using user goal trees and on-tology rules as heuristics (Young et al, 2007).In this paper, we are interested in exploring algo-rithms that would integrate this knowledge sourcefor users to achieve domain-specific goals.
We usedan agenda graph whose hierarchy reflects the natu-ral order of dialog control.
This graph is used to bothkeep track of the dialog state and to select the bestexample using multiple recognition hypotheses foraugmenting previous EBDM framework.3 Example-based Dialog ModelingOur approach is implemented based on Example-Based Dialog Modeling (EBDM) which is one ofgeneric dialog modelings.
We begin with a briefoverview of the EBDM framework in this sec-tion.
EBDM was inspired by Example-Based Ma-chine Translation (EBMT) (Nagao, 1984), a trans-lation system in which the source sentence can betranslated using similar example fragments within alarge parallel corpus, without knowledge of the lan-guage?s structure.
The idea of EBMT can be ex-tended to determine the next system actions by find-ing similar dialog examples within the dialog cor-pus.
The system action can be predicted by findingsemantically similar user utterances with the dialogstate.
The dialog state is defined as the set of relevantinternal variables that affect the next system action.EBDM needs to automatically construct an exampledatabase from the dialog corpus.
Dialog ExampleDataBase (DEDB) is semantically indexed to gen-eralize the data in which the indexing keys can bedetermined according to state variables chosen bya system designer for domain-specific applications(Figure 1).
Each turn pair (user turn, system turn) inthe dialog corpus is mapped to semantic instances inthe DEDB.
The index constraints represent the statevariables which are domain-independent attributes.To determine the next system action, there are threeprocesses in the EBDM framework as follows:?
Query Generation: The dialog managermakes Structured Query Language (SQL)631Figure 1: Indexing scheme for dialog example database on building guidance domainstatement using discourse history and NLU re-sults.?
Example Search: The dialog managersearches for semantically similar dialog exam-ples in the DEDB given the current dialog state.If no example is retrieved, some state variablescan be ignored by relaxing particular variablesaccording to the level of importance given thedialog?s genre and domain.?
Example Selection: The dialog manager se-lects the best example to maximize the ut-terance similarity measure based on lexico-semantic similarity and discourse history simi-larity.Figure 2 illustrates the overall strategy of EBDMframework for spoken dialog systems.
The EBDMframework is a simple and powerful approachto rapidly develop natural language interfaces formulti-domain dialog processing (Lee et al, 2006b).However, in the context of spoken dialog system fordomain-specific tasks, this framework must solvetwo problems: (1) Keeping track of the dialog statewith a view to ensuring steady progress towards taskcompletion, (2) Supporting n-best recognition hy-potheses to improve the robustness of dialog man-ager.
Consequently, we sought to solve these prob-Figure 2: Strategy of the Example-Based DialogModeling (EBDM) framework.lems by integrating the agenda graph as a heuristicwhich reflects the natural hierarchy and order of sub-tasks needed to complete the task.4 Agenda GraphIn this paper, agenda graph G is simply a way ofencoding the domain-specific dialog control to com-plete the task.
An agenda is one of the subtask flows,which are possible paths from root node to terminalnode.
G is composed of nodes (v) which correspondto possible intermediate steps in the process of com-pleting the specified task, and edges (e) which con-632Figure 3: Example of an agenda graph for a buildingguidance.nect nodes.
In other words, v corresponds to usergoal state to achieve domain-specific subtask in itsexpected agenda.
Each node includes three differentcomponents: (1) A precondition that must be truebefore the subtask is executed; (2) A description ofthe node that includes its label and identifier; and(3) Links to nodes that will be executed at the subse-quent turn.
For every edge eij = (vi, vj), we defineda transition probability based on prior knowledge ofdialog flows.
This probability can be assigned basedon empirical analysis of human-computer conversa-tions, assuming that the users behave in consistent,goal-directed ways.
Alternatively, it can be assignedmanually at the discretion of the system developerto control the dialog flow.
This heuristic has ad-vantages for practical spoken dialog system becausea key condition for successful task-oriented dialogsystem is that the user and system know which taskor subtask is currently being executed.
To exem-plify, Figure 3 illustrates part of the agenda graph forPHOPE, a building guidance robot using the spokendialog system.
In Figure 3, G is represented by aDirected Acyclic Graph (DAG), where each link inthe graph reflects a transition between one user goalstate and the next.
The set of paths in G representan agenda designed by the system developer.
Weadapted DAG representation because it is more in-tuitive and flexible than hierarchical tree represen-tation.
The syntax for graph representation in oursystem is described by an XML schema (Figure 4).4.1 Mapping Examples to NodesIn the agenda graph G, each node v should holdrelevant dialog examples corresponding to user goalstates.
Therefore, the dialog examples in DEDB areFigure 4: XML description for the agenda graphmapped to a user goal state when a precondition ofthe node is true.
Initially, the root node of the DAG isthe starting state, where there is no dialog example.Then, the attributes of each dialog example are ex-amined via the preconditions of each user goal nodeby breadth-first traversal.
If the precondition is true,the node holds relevant that may appear in the user?sgoal state.
The method of selecting the best of theseexamples will be described in 5.4.2 Discourse InterpretationInspired by Collagen (Rich and Sidner, 1998; Leshet al, 2001), we investigated a discourse interpre-tation algorithm to consider how the current user?sgoal can contribute to the current agenda in a focusstack according to Lochbaum?s discourse interpreta-tion algorithm (Lochbaum, 1998).
The focus stacktakes into account the discourse structure by keepingtrack of discourse states.
In our system, the focusstack is a set of user goal nodes which lead to com-pletion of the subtask.
The top on the focus stack isthe previous node in this set.
The focus stack is up-dated after every utterance.
To interpret the type ofthe discourse state, this breaks down into five maincases of possible current node for an observed user?sgoal:?
NEW TASK: Starting a new task to complete anew agenda (Child of the root).?
NEW SUB TASK: Starting a new subtask topartially shift focus (A different child of theparent).633?
NEXT TASK: Working on the next subtask con-tributing to current agenda (Its child node).?
CURRENT TASK: Repeating or modifying theobserved goal on the current subtask (Currentnode).?
PARENT TASK: Modifying the observation onthe previous subtask (Parent node).Nodes in parentheses denote the topological positionof the current node relative to the top node on thefocus stack.
If NEXT TASK is selected, the currentnode is pushed to the focus stack.
NEXT TASK cov-ers totally focused behavior, i.e., when there are nounexpected focus shifts.
This occurs when the cur-rent user utterance is highly correlated to the pre-vious system utterance.
The remaining four casescover various types of discourse state.
For example,NEW SUB TASK involves starting a new subtask topartially shift focus, thereby popping the previousgoal off the focus stack and pushing a new user goalfor the new subtask.
NEW TASK, which is placedon the node linked to root node, involves starting anew task to complete a new agenda.
Therefore, a di-alog is re-started and the current node is pushed ontothe focus stack with the current user goal as its firstelement.If none of the above cases holds, the discourse in-terpretation concludes that the current input shouldbe rejected because we expect user utterances to becorrelated to the previous turn in a task-oriented do-main.
Therefore, this interpretation does not con-tribute to the current agenda on the focus stack dueto ASR and NLU errors that are due to noisy envi-ronments and unexpected input.
These cases can behandled by using an error recovery strategy in Sec-tion 6.Figure 5 shows some examples of pseudo-codesused in the discourse interpretation algorithm toselect the best node among possible next nodes.S,H ,and G denote the focus stack, hypothesis, andagenda graph, respectively.
The INTERPRET al-gorithm is initially called to interpret the current dis-course state.
Furthermore, the essence of a discourseinterpretation algorithm is to find candidate nodes ofpossible next subtask for an observed user goal, ex-pressed in the definition of GENERATE.
The SE-LECT algorithm selects the best node to maximizeFigure 5: Pseudo-codes for the discourse interpreta-tion algorithmthe score function based on current input and dis-course structure given the focus stack.
The detailsof how the score of candidate nodes are calculatedare explained in Section 5.5 Greedy Selection with n-best HypothesesMany speech recognizers can generate a list of plau-sible hypotheses (n-best list) but output only themost probable one.
Examination of the n-best listreveals that the best hypothesis, the one with thelowest word error rate, is not always in top-1 posi-tion but sometimes in the lower rank of the n-bestlist.
Therefore, we need to select the hypothesisthat maximizes the scoring function among a set ofn-best hypotheses of each utterance.
The role ofagenda graph is for a heuristic to score the discoursestate to successfully complete the task given the fo-cus stack.The current system depends on a greedy policywhich is based on immediate transitions rather thanfull transitions from the initial state.
The greedyselection with n-best hypotheses is implemented asfollows.
Firstly, every hypothesis hi is scanned andall possible nodes are generated using the discourseinterpretation.
Secondly, the multi-level score func-tions are computed for each candidate node ci givena hypothesis hi.
Using the greedy algorithm, thenode with the highest score is selected as the usergoal state.
Finally, the system actions are predictedby the dialog example to maximize the examplescore in the best node.The generation of candidate nodes is basedon multiple hypotheses from the previous EBDM634framework.
This previous EBDM framework chosea dialog example to maximize the utterance similar-ity measure.
However, our system generates a set ofmultiple dialog examples with each utterance sim-ilarity over a threshold given a specific hypothesis.Then, the candidate nodes are generated by match-ing to each dialog example bound to the node.
If thenumber of matching nodes is exactly one, that nodeis selected.
Otherwise, the best node which wouldbe pushed onto the focus stack must be selected us-ing multi-level score functions.5.1 Node SelectionThe node selection is determined by calculatingsome score functions.
We defined multi-level scorefunctions that combine the scores of ASR, SLU, andDM modules, which range from 0.00 to 1.00.
Thebest node is selected by greedy search with multiplehypotheses H and candidate nodes C as follows:c?
= argmaxhi?H,ci?C?SH(hi) + (1?
?
)SD(ci|S)where H is a list of n-best hypotheses and C is aset of nodes to be generated by the discourse in-terpretation.
For the node selection, we divided thescore function into two functions SH(hi), hypothe-sis score, and SD(ci|S), discourse score, where ci isthe focus node to be generated by single hypothesishi.We defined the hypothesis score at the utterancelevel asSH(hi) = ?Srec(hi) + ?Scont(hi)where Srec(hi) denotes the recognition score whichis a generalized confidence score over the confi-dence score of the top-rank hypothesis.
Scont(hi)is the content score in the view of content manage-ment to access domain-specific contents.
For exam-ple, in the building guidance domain, theses contentswould be a building knowledge database includingroom name, room number, and room type.
The scoreis defined as:Scont(hi) =??
?N(Chi )N(Cprev) if Chi ?
CprevN(Chi )N(Ctotal) if Chi * Cprevwhere Cprev is a set of contents at the previous turnand Ctotal is a set of total contents in the contentdatabase.
Chi denotes a set of focused contents byhypothesis hi at the current turn.
N(C) representsthe number of contents C. This score reflects thedegree of content coherence because the number ofcontents of interest has been gradually reduced with-out any unexpected focus shift.
In the hypothesisscore, ?
and ?
denote weights which depend on theaccuracy of speech recognition and language under-standing, respectively.In addition to the hypothesis score, we defined thediscourse score SD at the discourse level to considerthe discourse structure between the previous nodeand current node given the focus stack S. This scoreis the degree to which candidate node ci is in focuswith respect to the previous user goal and system ut-terance.
In the agenda graph G, each transition hasits own probability as prior knowledge.
Therefore,when ci is NEXT TASK, the discourse score is com-puted asSD(ci|S) = P (ci|c = top(S))where P (ci|c = top(S)) is a transition probabil-ity from the top node c on the focus stack S to thecandidate node ci.
However, there is a problem forcases other than NEXT TASK because the graph hasno backward probability.
To solve this problem, weassume that the transition probability may be lowerthan that of the NEXT TASK case because a userutterance is likely to be influenced by the previousturn.
Actually, when using the task-oriented dialogsystem, typical users stay focused most of the timeduring imperfect communication (Lesh et al, 2001).To assign the backward transition probability, weobtain the minimum transition probability Pmin(S)among from the top node on the focus stack S toits children.
Then, the discourse score SD can beformalized when the candidate node ci does not cor-respond to NEXT TASK as follows:SD(ci|S) = max{Pmin(S)?
?Dist(ci, c), 0}where ?
is a penalty of distance between candi-date node and previous node, Dist(ci, c), accordingto type of candidate node such as NEW TASK andNEW SUB TASK.
The simplest case is to uniformlyassign ?
to a specific value.To select the best node using the node score, weuse ?
(0 ?
?
?
1) as an interpolation weight635between the hypothesis score Sh and the discoursescore SD.
This weight is empirically assigned ac-cording to the characteristics of the dialog genre andtask.
For example, ?
can set lower to manage thetransactional dialog in which the user utterance ishighly correlated to the previous system utterance,i.e., a travel reservation task, because this task usu-ally has preference orders to fill slots.5.2 Example SelectionAfter selecting the best node, we use the examplescore to select the best dialog example mapped intothis node.e?
= argmaxej?E(c?
)?Sutter(h?, ej)+(1??
)Ssem(h?, ej)where h?
is the best hypothesis to maximize thenode score and ej is a dialog example in the bestnode c?.
Sutter(h, ej) denotes the value of the utter-ance similarity of the user?s utterances between thehypothesis h and dialog example ej in the best nodec?
(Lee et al, 2006a).To augment the utterance similarity used in theEBDM framework, we also defined the semanticscore for example selection, Ssem(h, ej):Ssem(h, ej) = # of matching index keys# of total index keysThe semantic score is the ratio of matching indexkeys to the number of total index keys between hy-pothesis h and example record ej .
This score re-flects that a dialog example is semantically closer tothe current utterance if the example is selected withmore index keys.
After processing of the node andexample selection, the best example is used to pre-dict the system actions.
Therefore, the dialog man-ager can predict the next actions with the agendagraph and n-best recognition hypotheses.6 Error Recovery StrategyAs noted in Section 4.2, the discourse interpretationsometimes fails to generate candidate nodes.
In ad-dition, the dialog manager should confirm the cur-rent information when the score falls below somethreshold.
For these cases, we adapt an example-based error recovery strategy (Lee et al, 2007).
Inthis approach, the system detects that something iswrong in the user?s utterance and takes immediatesteps to address the problem using some help mes-sages such as UtterHelp, InfoHelp, and UsageHelpin the example-based error recovery strategies.
Wealso added a new help message, AgendaHelp, thatuses the agenda graph and the label of each node totell the user which subtask to perform next such as?SYSTEM: Next, you can do the subtask 1)SearchLocation with Room Name or 2)Search Locationwith Room Type?.7 Experiment & ResultFirst we developed the spoken dialog system forPHOPE in which an intelligent robot can provide in-formation about buildings (i.e., room number, roomlocation, room name, room type) and people (i.e.,name, phone number, e-mail address, cellular phonenumber).
If the user selects a specific room to visit,then the robot takes the user to the desired room.For this system, ten people used the WOZ method tocollect a dialog corpus of about 500 utterances from100 dialogs which were based on a set of pre-defined10 subjects relating to domain-specific tasks.
Then,we designed an agenda graph and integrated it intothe EBDM framework.In an attempt to quantify the impact of our ap-proach, five Korean users participated in a prelimi-nary evaluation.
We provided them with pre-definedscenarios and asked them to collect test data from50 dialogs, including about 150 utterances.
Afterprocessing each dialog, the participants completeda questionnaire to assess their satisfaction with as-pects of the performance evaluation.
The speechrecognition hypotheses are obtained by using theHidden Markov model Toolkit (HTK) speech rec-ognizer adapted to our application domain in whichthe word error rate (WER) is 21.03%.
The results ofthe Task Completion Rate (TCR) are shown in Table1.
We explored the effects of our agenda-based ap-proach with n-best hypotheses compared to the pre-vious EBDM framework which has no agenda graphand supports only 1-best hypothesis.Note that using 10-best hypotheses and theagenda graph increases the TCR from 84.0% to90.0%, that is, 45 out of 50 dialogs were com-pleted successfully.
The average number of turns(#AvgTurn) to completion was also shorter, which636shows 4.35 turns per a dialog using the agenda graphand 10-best hypotheses.
From these results, we con-clude that the the use of the n-best hypotheses withthe agenda graph is helpful to improve the robust-ness of the EBDM framework against noisy inputs.System #AvgTurn TCR (%)1-best(-AG) 4.65 84.010-best(+AG) 4.35 90.0Table 1: Task completion rate according to using theAG (Agenda Graph) and n-best hypotheses for n=1and n=10.8 Conclusion & DiscussionThis paper has proposed a new agenda-based ap-proach with n-best recognition hypotheses to im-prove the robustness of the Example-based DialogModeling (EBDM) framework.
The agenda graphcan be thought of as a hidden cost of applying ourmethodology.
However, an explicit agenda is nec-essary to successfully achieve the purpose of usingspoken dialog system.
Our preliminary results indi-cate this fact that the use of agenda graph as heuris-tics can increase the TCR.
In addition, our approachis robust to recognition errors because it maintainsmultiple hypotheses for each user utterance.There are several possible subjects for further re-search on our approach.
First, the optimal interpo-lation weights should be determined.
This task willrequire larger dialog corpora by using user simula-tion.
Second, the cost of designing the agenda graphshould be reduced.
We have focused on developing asystem to construct this graph semi-automatically byapplying dialog state clustering and utterance clus-tering to achieve hierarchical clustering of dialog ex-amples.
Finally, future work will include expandingour system to other applications, such as navigationsystems for automobiles.AcknowledgementThis work was supported by grant No.
RTI04-02-06from the Regional Technology Innovation Programand by the Intelligent Robotics Development Pro-gram, one of the 21st Century Frontier R&D Pro-grams funded by the Ministry of Commerce, Indus-try and Energy (MOICE) of Korea.ReferencesBohus, B. and Rudnicky A.
2003.
RavenClaw: Dia-log Management Using Hierarchical Task Decompo-sition and an Expectation Agenda.
Proceedings of theEuropean Conference on Speech, Communication andTechnology, 597?600.Grosz, B.J.
and Kraus, S. 1996.
Collaborative Plansfor Complex Group Action.
Artificial Intelligence,86(2):269?357.Lee, C., Jung, S., Eun, J., Jeong, M., and Lee, G.G.2006.
A Situation-based Dialogue Management usingDialogue Examples.
Proceedings of the IEEE Inter-national Conference on Acoustics, Speech and SignalProcessing, 69?72.Lee, C., Jung, S., Jeong, M., and Lee, G.G.
2006.Chat and Goal-oriented Dialog Together: A UnifiedExample-based Architecture for Multi-domain DialogManagement.
Proceedings of the IEEE Spoken Lan-guage Technology Workshop, 194-197.Lee, C., Jung, S., and Lee, G.G.
2007.
Example-basedError Reocvery Strategy For Spoken Dialog System.Proceedings of the IEEE Automatic Speech Recogni-tion and Understanding Workshop, 538?543.Lesh, N., Rich, C., and Sidner, C. 2001.
Collaborat-ing with focused and unfocused users under imper-fect communication.
Proceedings of the InternationalConference on User Modeling, 63?74.Lochbaum, K.E.
1998.
A Collaborative Planning Modelof Intentional Structure.
Computational Linguistics,24(4):525?572.McTear, M., O?Neil, I., Hanna, P., and Liu, X.2005.
Handling errors and determining confirmationstrategies-An object-based approach.
Speech Commu-nication, 45(3):249?269.Nagao, M. 1984.
A Frame Work of a Mechnical Trans-latino between Japanese and English by Analogy Prin-ciple.
Proceedings of the international NATO sympo-sium on artificial and human intelligence, 173?180.Rich, C. and Sidner, C.. 1998.
Collagen: A Collab-oration Agent for Software Interface Agents.
Jour-nal of User Modeling and User-Adapted Interaction,8(3):315?350.Torres, F., Hurtado, L.F., Garcia, F., Sanchis, E., andSegarra, E. 2005.
Error Handling in a StochasticDialog System through Confidence Measure.
SpeechCommunication, 45(3):211?229.Williams, J.D.
and Young, S. 2007.
Partially ObservableMarkov Decision Processes for Spoken Dialog Sys-tems.
Computer Speech Language, 21(2):393-422.Young, S., Schatzmann, J., Weilhammer, K., and Ye, H..2007.
The Hidden Information State Approach to Di-alog Management.
Proceedings of the IEEE Inter-national Conference on Acoustics, Speech and SignalProcessing, 149?152.637
