Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 1024?1034,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsTowards Debugging Sentiment LexiconsAndrew SchneiderComputer and Information SciencesTemple Universityatschneider@temple.eduEduard DragutComputer and Information SciencesTemple Universityedragut@temple.eduAbstractCentral to many sentiment analysis tasksare sentiment lexicons (SLs).
SLs exhibitpolarity inconsistencies.
Previous workstudied the problem of checking the con-sistency of an SL for the case when the en-tries have categorical labels (positive, neg-ative or neutral) and showed that it is NP-hard.
In this paper, we address the moregeneral problem, in which polarity tagstake the form of a continuous distributionin the interval [0, 1].
We show that thisproblem is polynomial.
We develop a gen-eral framework for addressing the consis-tency problem using linear programming(LP) theory.
LP tools allow us to uncoverinconsistencies efficiently, paving the wayto building SL debugging tools.
We showthat previous work corresponds to 0-1 inte-ger programming, a particular case of LP.Our experimental studies show a strongcorrelation between polarity consistencyin SLs and the accuracy of sentiment tag-ging in practice.1 IntroductionMany sentiment analysis algorithms rely on sen-timent lexicons (SLs), where word forms or wordsenses1are tagged as conveying positive, negativeor neutral sentiments.
SLs are constructed by oneof three methods (Liu, 2012; Feldman, 2013): (1)Manual tagging by human annotators is gener-ally reliable, but because it is labor-intensive, slow,and costly, this method has produced small-sizedSLs comprising a few thousand words, e.g., Opin-ion Finder (OF) (Wilson et al, 2005), AppraisalLexicon (AL) (Taboada and Grieve, 2004), Gen-eral Inquirer (GI) (Stone et al, 1966), and Micro-WNOp (Cerini et al, 2007).
(2) Dictionary-1We refer to a string of letters or sounds as a word form &to a pairing of a word form with a meaning as a word sense.based acquisition relies on a set of seed wordsto expand its coverage to similar words.
Thereare over thirty dictionary-based techniques (An-dreevskaia and Bergler, 2006; Blum et al, 2004;Chen and Skiena, 2014; Choi and Wiebe, 2014;Esuli and Sebastiani, 2006; Feng et al, 2013; Has-san and Radev, 2010; Kamps et al, 2004; Moham-mad et al, 2009; Takamura et al, 2005; Turney,2002; Williams and Anand, 2009), most of thembased on WordNet (Fellbaum, 1998), such as Sen-tiWordNet (SWN)(Baccianella et al, 2010) andQ-WordNet (QWN) (Agerri and Garc??a-Serrano,2010).
(3) Corpus-based acquisition expands aset of seed words with the use of a large docu-ment corpus (Breck et al, 2007; Bross and Ehrig,2013; Choi and Cardie, 2009; Ding et al, 2008;Du et al, 2010; Hatzivassiloglou and McKeown,1997; Jijkoun et al, 2010; Kaji and Kitsuregawa,2007; Klebanov et al, 2013; Lu et al, 2011; Pengand Park, 2011; Tang et al, 2014; Wu and Wen,2010).
Method (1) generally produces the mostreliable annotations, however the considerable ef-fort required to yield substantial lexicons makesit less useful in practice.
The appeals of (2) and(3) lie in the formalism of their models and theircapability of producing large-sized SLs.
SLs areeither word or sense/synset oriented.
We refer tothe former as Sentiment Word Lexicons (SWLs),e.g., GI, OF, and AL, and to the latter as Senti-ment Sense Lexions (SSLs), e.g., SWN, QWN,and Micro-WNOp.
Besides the method of compi-lation, SLs may also vary with regard to sentimentannotation.Polarity disagreements are noted across SLsthat do (SWN, Q-WordNet) and do not (AL, GI)reference WordNet.
For instance, the adjectivespanicky and terrified, have negative andpositive polarities in OF, respectively.
They eachhave only one synset which they share in Word-Net: ?thrown into a state of intense fear or des-peration?.
Assuming that there is an intrinsic re-1024lationship between the sentiments of a word andits meanings, a single synset polarity assignmentto this synset cannot agree with both positive andnegative at the word level.
If the information givenin WordNet is accurate (the Oxford and Cam-bridge dictionaries give only this meaning for bothwords) then there must be an annotation inconsis-tency in OF, called a polarity inconsistency.
Whilesome inconsistencies are easy to detect, manualconsistency checking of an entire SL is an imprac-tical endeavor, primarily because of the sheer size(SWN has over 206,000 word-sense pairs).
Ad-ditionally, WordNet?s complex network structurerenders manual checking virtually impossible; aninstance of a polarity inconsistency may entail anentire sub-network of words and senses.
In thispaper we develop a rigorous formal method basedon linear programming (LP)(Schrijver, 1986) forpolarity consistency checking of SLs with accom-panying methods to unearth mislabeled words andsynsets when consistency is not satisfied.We translate the polarity consistency problem(PCP) into a form of the LP problem, suitableas the input to a standard LP solver, and utilizethe functionality available in modern LP software(e.g., identifying an irreducible infeasible subset)to pinpoint the sources of inconsistencies whenthey occur.
In our experimentation we are able toquickly uncover numerous intra- and inter-lexiconinconsistencies in all of the input SLs tested and tosuggest lexicon entries for a linguist to focus on in?debugging?
the lexicon.Background and Previous WorkSentiment resources have taken two basic ap-proaches to polarity annotation: discrete and frac-tional.
In the discrete approach, polarity is definedto be one of the discrete values positive, negative,or neutral.
A word or a synset takes exactly oneof the three values.
QWN, AL, GI, and OF followthe discrete polarity annotation.
In the fractionalapproach, polarity is defined as a 3-tuple of non-negative real numbers that sum to 1, correspond-ing to the positive, negative, and neutral values re-spectively.
SWN, Micro-WNOp, and Hassan andRadev (2010) employ a fractional polarity anno-tation.
For example, the single synset of the ad-jective admissible in WordNet has the senti-ment tags positive in QWN and ?.25, .625, .125?in SWN, so here SWN gives a primarily negativepolarity with some positive and less neutral polar-ity.
We denote by PCP-D and PCP-F the polaritylaughable :positiverisible : ?comic :negatives2: ?of or relatingto or characteristicof comedy?s3: ?arousingor provokinglaughter?s1: ?so unrea-sonable as toinvite derision?0.50.510.6 0.4Figure 1: Discrete vs. fractional polarity consis-tency.
Example taken from Dragut et al (2012).consistency problem for the discrete and fractionalpolarity annotations, respectively.Dragut et al (2012) introduces the PCP for do-main independent SLs and gives a solution to aparticular form of the PCP-D, but that methodcannot solve PCP-F. For example, they showthat the adjectives laughable, comic, andrisible (Figure 1) constitute an inconsistencyin the discrete case.
AL gives positive polarity forlaughable and OF gives negative for comic.If s2is not positive then laughable is not pos-itive and if s2is not negative then comic is notnegative, so there is no assignment of s2that satis-fies the whole system.
Hence there is an incon-sistency.
However, the following fractional po-larity tags do satisfy the system: s1: ?1, 0, 0?,s2: ?.66, .34, 0?, s3: ?0, 1, 0?, where the meaningof the second tag, for instance, is that s2is .66 pos-itive, .34 negative, and 0 neutral.
We thus see thatthe discrete polarity annotation is rigid and leadsto more inconsistencies, whereas the fractional an-notation captures more naturally the polarity spec-trum of a word or synset.
In this paper we givea solution to the PCP-F.
The differences betweenour solution and that of Dragut et al (2012) givesome insight into the general differences betweenthe fractional and discrete problems.
First, thediscrete case is intractable, i.e., computationallyNP-complete (Dragut et al, 2012); we show inthis paper (Section 3.2) that the fractional case istractable (solvable in polynomial time).
Second,the PCP-D is solved in Dragut et al (2012) bytranslation to the Boolean satisfiability problem(SAT) (Schaefer, 1978); here we recast the PCP-F in terms of LP theory.
Third, we show that theLP framework is a natural setting for the PCP asa whole, and that the PCP-D corresponds to the 0-1 integer LP problem (Section 3.2), a classic NP-complete problem (Karp, 2010).Our experiments (Section 5.4) show that cor-recting even a small number of inconsistencies cangreatly improve the accuracy of sentiment annota-tion tasks.
We implement our algorithm as a versa-tile tool for debugging SLs, which helps locate the1025sources of error in SLs.
We apply our algorithm toboth SWLs and SSLs and demonstrate the useful-ness of our approach to improving SLs.The main contributions of this paper are:?
solve the PCP-F;?
show that the PCP-F is tractable;?
show that the PCP is an instance of LP;?
develop a technique for identifying inconsis-tencies in SLs of various types;?
implement our algorithm as a prototype SLdebugger;?
show that there is a strong correlation be-tween polarity inconsistency in SLs and theperformance of sentiment tagging tools de-veloped on them.2 Problem DefinitionIn this section we give a formal characterizationof the polarity assignment of words and synsets inSLs using WordNet.
We use ?, +, 0 to denotenegative, positive, and neutral polarities, respec-tively, throughout the paper.2.1 Polarity RepresentationWe define the polarity of a synset or wordr in WordNet to be a discrete probabil-ity distribution, called a polarity distribution:P+(r), P?
(r), P0(r) ?
0 with P+(r) + P?
(r) +P0(r) = 1.
P+(r), P?
(r) and P0(r) representthe ?likelihoods?
that r is positive, negative orneutral, respectively.
For instance, the WordNetsynset ?worthy of reliance or trust?
of the adjec-tive reliable is given the polarity distributionP+= .375, P?= .0 and P0= .625 in Senti-WordNet.
We may drop r from the notation if themeaning is clear from context.
The use of a polar-ity distribution to describe the polarity of a wordor synset is shared with many previous works (An-dreevskaia and Bergler, 2006; Baccianella et al,2010; Kim and Hovy, 2006).2.2 WordNetA word-synset network N is a 4-tuple (W,S, E ,f) where W is a finite set of words, S is a finiteset of synsets, E ?
W ?
S and f is a functionassigning a positive integer to each element in E .For any word w and synset s, s is a synset of w if(w, s) ?
E .
For a pair (w, s) ?
E , f(w, s) is calledthe frequency of use of w in the sense given bys.
For a word w, we let freq(w) denote the sumof all f(w, s) such that (w, s) ?
E .
We definethe relative frequency of w with s by rf(w, s) =f(w,s)freq(w).
If f(w, s) = 0, the frequency of eachsynset of w is increased by a small constant .
Weuse  = .1 in our prototype.2.3 Word PolaritiesWe contend that there exists a relation between thesentiment orientation of a word and the polaritiesof its related senses (synsets), and we make the as-sumption that this relation takes the form of a lin-ear function.
Thus, for w ?
W and p ?
{+,?, 0},the polarity distribution of w is defined as:Pp(w) =?s?Swg(w, s) ?
Pp(s), (1)where Pp(s) is the polarity value of synset swith polarity p and g(w, s) is a rational num-ber.
For example, g can be the relative frequencyof s with respect to w in WordNet: g(w, s) =rf(w, s);?w ?
W, s ?
S. Alternatively, for eachword w we can draw g(w, ?)
from a Zipfian dis-tribution, following the observation that the distri-bution of word senses roughly follows a Zipfianpower-law (Kilgarriff, 2004; Sanderson, 1999).
Inthis paper, we will assume g(w, s) = rf(w, s).For example, the three synsets of the adjec-tive reliable with relative frequencies911,111,and111, respectively, are given the distributions?.375, 0, .625?, ?.5, 0, .5?, and ?.625, 0, .375?
inSentiWordNet.
So for reliable we have P+=9110.375 +1110.5 +1110.625 ?
0.41, P?= 0, andP0=9110.625 +1110.5 +1110.375 ?
0.59.2.4 Modeling Sentiment Orientation in SLsWords and synsets have unique polarities in someSLs, e.g., AL and OF.
For instance, reliablehas positive polarity in AL, GI, and OF.
Thequestion is: what does a discrete annotation ofreliable tell us about its polarity distribution?One might take it to mean that the polarity distri-bution is simply ?1, 0, 0?.
This contradicts the in-formation in SWN, which gives some neutral po-larity for all of the synsets of reliable.
So abetter polarity distribution would allow P0> 0.Furthermore, given that ?.41, 0, .59?, ?.40, 0, .60?,and ?.45, 0, .55?
give virtually identical informa-tion to a sentiment analyst, it seems unreasonableto expect exactly one to be the correct polaritytag for reliable and the other two incorrect.Therefore, instead of claiming to pinpoint an ex-act polarity distribution for a word, we propose toset a boundary on its variation.
This establishes a1026range of values, instead of a single point, in whichSLs can be said to agree.Thus, for a word w, we can definepolarity(w) ={+ if P+> P??
if P?> P+(2)which we refer to as MAX POL.
This model isadopted either explicitly or implicitly by numer-ous works (Hassan and Radev, 2010; Kim andHovy, 2004; Kim and Hovy, 2006; Qiu et al,2009).
Another model is the majority sense model,called MAJORITY, (Dragut et al, 2012), wherepolarity(w) ={+ if P+> P?+ P0?
if P?> P++ P0(3)Another polarity model, MAX, is defined aspolarity(w)={+ if P+>P?&P+>P0?
if P?>P+&P?>P0(4)For instance, reliable conveys positive po-larity according to MAX POL, since P+> P?,but neutral according to MAJORITY.
When thecondition of being neither positive nor negativecan be phrased as a conjunction of linear in-equalities, as is the case with MAJORITY andMAX POL, then we define neutral as not positiveand not negative.
These model definitions can beapplied to synsets as well.2.5 Polarity Consistency DefinitionInstead of defining consistency for SLs dependenton a choice of model, we develop a generic defi-nition applicable to a wide variety of models, in-cluding all of those discussed above.
We requirethat the polarity of a word or synset in the networkN be characterized by a set of linear inequalities(constraints) with rational coefficients.
Formally,for each word w ?
W , the knowledge that w hasa discrete polarity p ?
{+,?, 0} is characterizedby a set of linear inequalities:?
(w, p) = {ai,0P++ai,1P?+ai,2P0 bi}, (5)where ?
{?, <} and ai,0, ai,1, ai,2, bi?
Q,i = 0, 1, .
.
.
,m. For instance, if the MAX modelis used, for w = worship whose polarity is pos-itive in OF, we get the following set of inequali-ties: ?
(w,+) = {P+?P?> 0, P+?P0> 0} ={(?1)P++1P?+0P0<0, (?1)P++0P?+1P0<0}.Let L be an SL.
We denote the system of in-equalities introduced by all words and synsetsin L with known polarities in the network Nby ??
(N ,L).
The variables in ??
(N ,L) areperseverancew1: +persistencew2: 0pertinacityw3: ?tenacityw4: +s1: ?persistentdetermination?s3: ?the propertyof a continuousperiod of time?s2: ?the actof persisting orpersevering?0.50.291 10.50.70.01Figure 2: A network of 4 words and 3 synsetsP+(r), P?
(r) and P0(r), r ?
W ?
S. Denote by??
(N ,L) the set of constraints implied by the po-larity distributions for all r ?
L: P+(r)+P?
(r)+P0(r) = 1 and Pp?
{+,?,0}(r) ?
0, ?r ?
W ?
S.Let ??
(N ,L) = ??
(N ,L) ???
(N ,L).Example 1.
Let w1, w2, w3, and w4bethe nouns perseverance, persistence,pertinacity, and tenacity, respectively,which are in OF with polarities +, 0, ?,and +, respectively (Figure 2).
Assuming theMAJORITY model, ?
(w1,+) = {P+(w1) >P?
(w1) + P0(w1)} = {P+(w1) > 1 ?P+(w1)} = {?P+(w1) < ?12}, and ?
(w2, 0) ={P+(w2) ?
P?
(w2) + P0(w2), P?
(w2) ?P+(w2) + P0(w2)} = {P+(w2) ?12, P?
(w2) ?12}.
Similarly, ?(w3,?)
= {?P?
(w3) < ?12}and ?(w4,?)
= {?P+(w4) < ?12}.Definition 1.
A sentiment lexiconL is consistent ifthe system ??
(N,L) is feasible, i.e., has a solution.The PCP is then the problem of deciding if agiven SL L is consistent.
In general, PCP can bestated as follows: Given an assignment of polar-ities to the words, does there exist an assignmentof polarities to the synsets that agrees with that ofthe words?
If the polarity annotation is discrete,we have the PCP-D; if the polarity is fractional,we have PCP-F. Our focus is PCP-F in this paper.The benefits of a generic problem model are atleast two-fold.
First, different linguists may havedifferent views about the kinds of inequalities oneshould use to express the probability distributionof a word with a unique polarity in some SL.
Thenew model can accommodate divergent views aslong as they are expressed as linear constraints.Second, the results proven for the generic modelwill hold for any particular instance of the model.3 Polarity Consistency: an LP ApproachA careful analysis of the proposed formulationof the problem of SL consistency checking re-veals that this can be naturally translated into anLP problem.
The goal of LP is the optimiza-tion of a linear objective function, subject to lin-1027ear (in)equality constraints.
LP problems are ex-pressed in standard form as follows:minimize cTxsubject to Ax ?
b (6)and x ?
0x represents thevector of variables(to be determined),c and b are vec-tors of (known) co-efficients, A is a (known) matrix of coefficients,and (?
)Tis the matrix transpose.
An LP algorithmfinds a point in the feasible region where cTx hasthe smallest value, if such a point exists.
The feasi-ble region is the set of x that satisfy the constraintsAx ?
b and x ?
0.There are several non-trivial challenges thatneed to be addressed in transforming our prob-lem (i.e., the system ??
(N ,L)) into an LP prob-lem.
For instance, we have both strict and weakinequalities in our model, whereas standard LPdoes not include strict inequalities.
We describethe steps of this transformation next.3.1 Translation to LPIn our problem, x is the concatenation of all thetriplets ?P+(r), P?
(r), P0(r)?
for all r ?
W ?
S .Eliminate Word Related Variables.
For eachwordw ?
Lwe replaceP+(w), P?
(w) andP0(w)with their corresponding expressions according toEquation 1; then the linear system ??
(N ,L) hasonly the synset variables P+(s), P?
(s) and P0(s)for s ?
S.Example (continued).
Using the relative fre-quencies of Figure 2 in Equation 1 we get:?
(w1,+)= {?.5P+(s1)?
.5P+(s2) < ?12},?(w2,0)={.29P+(s1)+.01P+(s2)+.7P+(s3)?12,.29P?
(s1) + .01P?
(s2) + .7P?
(s3) ?12},?(w3,?
)= {?P?
(s1) < ?12}, and?
(w4,+)= {?P+(s1) < ?12}.Equality.
The system ??
(N ,L) contains con-straints of the form P+(s)+P?
(s)+P0(s)=1 foreach s ?
S, but observe that there are no equal-ity constraints in the standard LP form (Equation6).
The usual conversion procedure is to replace agiven equality constraint: aTx= b, with: aTx?
band ?aTx ?
?b.
However, this procedure in-creases the number of constraints in ??
(N ,L) lin-early.
This can have a significant computation im-pact since ??
(N ,L) may have thousands of con-straints (see discussion in Section 5.3).
Instead,we can show that the system F obtained by per-forming the following two-step transformation isequivalent to ??
(N ,L), in the sense that F is fea-sible iff ??
(N ,L) is feasible.
For every s ?
S ,(Step 1) we convert each P+(s)+P?
(s)+P0(s)=1to P+(s)+P?
(s)?1, and (Step 2) we replace ev-ery P0(s) in ??
(N ,L) with 1?P+(s)?P?
(s).Strict Inequalities.
Strict inequalities are notallowed in LP and their presence in inequality sys-tems in general poses difficulties to inequality sys-tem solvers (Goberna et al, 2003; Goberna andRodriguez, 2006; Ghaoui et al, 1994).
Fortu-nately results developed by the LP community al-low us to overcome this obstacle and maintain theflexibility of our proposed model.
We introducea new variable y ?
0, and for every strict con-straint of the form aTx < b, we rewrite the in-equality as aTx + y ?
b.
Let ???
(N ,L) be thisnew system of constraints.
We modify the objec-tive function (previously null) to maximize y (i.e.,minimize ?y).
Denote by F?the LP that maxi-mizes y subject to ???
(N ,L).
We can show that??
(N ,L) is feasible iff F?is feasible and y 6= 0.A sketch of the proof is as follows: if y > 0 thenaTx + y ?
b implies aTx < b. Conversely, ifaTx < b then ?y > 0 such that aTx + y ?
b,and maximizing for y will yield a y > 0 iff one isfeasible.
This step is omitted if we have no strictconstraints in ??
(N ,L).Example (continued).
The formulations of?
(w1,+), ?(w3,?
), and ?
(w4,+) involve strictinequalities, so they are rewritten in ???
(N ,L),e.g., ???
(w4,+) = {?P+(s1) + y ?
?12}.We denote by ?
(N ,L) the standard form of??
(N ,L) obtained by applying the above steps.This is the input to an LP solver.Theorem 1.
Sentiment lexicon L is polarity con-sistent iff ?
(N ,L) is feasible.3.2 Time ComplexityFor the network N and an SL L, the above trans-lation algorithm converts the PCP into an LPproblem on the order of O(|E|), a polynomialtime conversion.
The general class of linear pro-gramming problems includes subclasses that areNP-hard, such as the integer linear programming(ILP) problems, as well as polynomial solvablesubclasses.
We observe that our problem is rep-resented by a system of rational linear inequali-ties.
This class of LP problems is solvable in poly-nomial time (Khachiyan, 1980; G?acs and Lov?asz,1981).
This (informally) proves that the PCP-F issolvable in polynomial time.
PCP is NP-completein the discrete case (Dragut et al, 2012).
This isnot surprising since in our LP formulation of the1028PCP, the discrete case corresponds to the 0-1 in-teger programming (BIP) subclass.
(Recall that inthe discrete case each synset has a unique polar-ity.)
BIP is the special case of integer program-ming where variables are required to be 0 or 1.
BIPis a classic NP-hard problem (Garey and Johnson,1990).
We summarize these statements in the fol-lowing theorem.Theorem 2.
The PCP-F problem is P and thePCP-D is NP-complete.We proved a more general and more compre-hensive result than Dragut et al (2012).
The PCPsolved by Dragut et al (2012) is a particular caseof PCP-D: it can be obtained by instantiating ourframework with the MAJORITY model (Equation3) and requiring each synset to take a unique polar-ity.
We believe that the ability to encompass bothfractional and discrete cases within one frame-work, that of LP, is an important contribution, be-cause it helps to give structure to the general prob-lem of polarity consistency and to contextualizethe difference between the approaches.4 Towards Debugging SLsSimply stating that an SL is inconsistent is of lit-tle practical use unless accompanying assistancein diagnosing and repairing inconsistencies is pro-vided.
Automated assistance is necessary in theface of the scale and complexity of modern SLs:e.g., AL has close to 7,000 entries, SWN annotatesthe entirety of WordNet, over 206,000 word-sensepairs.
There are unique and interesting problemsassociated with inconsistent SLs, among them: (1)isolate a (small) subset of words/synsets that is po-larity inconsistent, but becomes consistent if oneof them is removed; we call this an IrreduciblePolarity Inconsistent Subset (IPIS); (2) return anIPIS with smallest cardinality (intuitively, such aset is easiest to repair); (3) find all IPISs, and (4)find the largest polarity consistent subset of an in-consistent SL.
In the framework of linear systemsof constraints, the problems (1) - (4) correspondto (i) the identification of an Irreducible Infeasi-ble Subset (IIS) of constraints within ?
(N ,L), (ii)finding IIS of minimum cardinality, (iii) finding allIISs and (iv) finding the largest set of constraintsin ?
(N ,L) that is feasible, respectively.
An IISis an infeasible subset of constraints that becomesfeasible if any single constraint is removed.
Prob-lems (ii) - (iv) are NP-hard and some may even bedifficult to approximate (Amaldi and Kann, 1998;Chinneck, 2008; Chakravarti, 1994; Tamiz et al,1996).
We focus on problem (1) in this paper,which we solve via IIS discovery.
We keep a bi-jective mapping from words and synsets to con-straints such that for any given constraint, we canuniquely identify the word or synset in ?
(N ,L)from which it was introduced.
Hence, once an IISis isolated, we know the corresponding words orsynsets.
Modern LP solvers typically can give anIIS when a system is found to be infeasible, butnone give all IISs or the IIS of minimum size.Example (continued).
The polarity assignmentsof w1, w2, w3, and w4, are consistent iff there existpolarity distributions ?P+(si), P?
(si), P0(si)?
fori = 1, 2, 3, such that: y > 0?
(w1,+): ?.5P+(s1) + .5P+(s2) + y ?
?12,?
(w2,0):.29P+(s1) + .01P+(s2) + .7P+(s3)?12AND .29P?
(s1) + .01P?
(s2) + .7P?(s3)?12,?(w3,?)
: ?P?
(s1) + y ?
?12,?
(w4,+) : ?P+(s1) + y ?
?12,?(s1):P+(s1)+P?(s1)?
1AND P+(s1), P?(s1)?0,?(s2):P+(s2)+P?(s2)?
1AND P+(s2), P?(s2)?0,?(s3):P+(s3)+P?(s3)?
1AND P+(s3), P?
(s3)?0.Upon examination, if y > 0, then ?(w3,?)
im-plies P?
(s1) >12and ?
(w4,+) implies P+(s1) >12.
Then P+(s1) + P?
(s1) > 1, contradicting?(s1).
Hence, this LP system is infeasible.
More-over {?(w3,?
), ?
(w4,+), ?
(s1)} is an IIS.
Trac-ing back we get that the set of words {w3, w4} isinconsistent.
Therefore it is an IPIS.Isolating IPISs helps focus SL diagnosis and re-pair efforts.
Fixing SLs via IIS isolation proceedsiteratively: (1) isolate an IIS, (2) determine a re-pair for this IIS, (3) if the model is still infeasi-ble, go to step (1).
This approach is well sum-marized by Greenberg?s aphorism: ?diagnosis =isolation + explanation?
(Greenberg, 1993).
Theproposed use requires human interaction to effectthe changes to the lexicon.
One might ask if thisinvolvement is strictly necessary; in response wedraw a parallel between our SL debugger and asoftware debugger.
A software debugger can iden-tify a known programming error, say the use ofan undefined variable.
It informs the program-mer, but it does not assign a value to the vari-able itself.
It requires the user to make the de-sired assignment.
Similarly, our debugger candeterministically identify an inconsistent compo-nent, but it cannot deterministically decide whichelements to adjust.
In most cases, this is simplynot an objective decision.
To illustrate this point,from our example, we know that minimally one1029SL adj.
adv.
noun verb totalUN 3,084 940 2,340 1,812 8,176AL 1,486 377 2 0 1,865GI 1,337 121 1,474 1,050 3,982SWLsOF 2,608 775 1,907 1,501 6,791SWN 18,156 3,621 82,115 13,767 117,659QWN 4,060 40 7,404 4,006 15,510SSLsMWN 255 30 487 283 1,055Table 1: Counts of words/synsets in each SLof pertinacity(?)
and tenacity(+) mustbe adjusted, but the determination as to which re-quires the subjective analysis of a domain expert.In this paper, we do not repair any of the dis-covered inconsistencies.
We focus on isolating asmany IPISs as possible.5 ExperimentsThe purpose of our experimental work is manifold,we show that: (1) inconsistencies exist in and be-tween SLs, (2) our algorithm is effective at uncov-ering them in the various types of SLs proposedin the literature, (3) fractional polarity representa-tion is more flexible than discrete, giving ordersof magnitude fewer inconsistencies, and (4) senti-ment analysis is significantly improved when theinconsistencies of a basis SL are corrected.Experiment Setup: We use four SWLs: GI,AL, OF and their union, denoted UN, and threeSSLs: QWN, SWN and MicroWN-Op.
The dis-tribution of their entries is given in Table 1.
TheMAJORITY model (Equation 3) is used in all tri-als.
This allows for direct comparison with Dragutet al (2012).
We implemented our algorithm inJava interfacing with the GUROBI LP solver2, andran the tests on a 4?
1.70GHz core computer with6GB of main memory.5.1 Inconsistencies in SWLsIn this set of experiments, we apply our algorithmto GI, AL, OF and UN.
We find no inconsisten-cies in AL, only 2 in GI, and 35 in both UN andOF (Table 2).
(Recall that an inconsistency is aset of words whose polarities cannot be concomi-tantly satisfied.)
These numbers do not representall possible inconsistencies (See discussion in Sec-tion 4).
In general, the number of IISs for an infea-sible system can be exponential in the size of thesystem ?
(N ,L) (Chakravarti, 1994), however ourresults suggest that in practice this does not occur.Compared with Dragut et al (2012), we see amarked decrease in the number of inconsistencies.2www.gurobi.comadj.
adv.
noun verb totalUN 8 14 5 8 35AL 0 0 0 - 0GI 2 0 0 0 2OF 7 15 4 9 35Table 2: SWL-Internal InconsistenciesInconsistency RatiosSWL adj.
adv.
noun verb totalUN 0.67 0.89 0.85 0.81 0.78AL 0.63 0.8 1 - 0.66GI 0.6 0.41 0.87 0.91 0.78OF 0.66 0.87 0.82 0.77 0.76Table 3: SentiWordNet paired with SWLsThey found 249, 2, 14, and 240 inconsistencies inUN, AL, GI, and OF, respectively.
These incon-sistencies are obtained in the first iteration of theirSAT-Solver.
This shows that about 86% of incon-sistent words in a discrete framework can be madeconsistent in a fractional system.5.2 Inconsistencies in SSLsIn this set of experiments we check the polarityinconsistencies between SWLs and SSLs.
We paireach SSL with each of the SWLs.SentiWordNet.
SWN is an automatically gen-erated SL with a fractional polarity annotation ofevery synset in WordNet.
Since SWN annotatesevery synset in WordNet, there are no free vari-ables in this trial.
Each variable Pp?
{+,?,0}(s)for s ?
S is fully determined by SWN, so thisamounts to a constant on the left hand side of eachinequality.
Our task is to simply check whether theinequality holds between the constant on the leftand that on the right.
Table 3 gives the proportionof words from each SWL that is inconsistent withSWN.
We see there is substantial disagreement be-tween SWN and all of the SWLs, in most casesmore than 70% disagreement.
For example, 5,260of the 6,921 words in OF do not agree with thepolarities assigned to their senses in SWN.
Thisoutcome is deeply surprising given that all theseSLs are domain independent ?
no step in theirconstruction processes hints to a specific domainknowledge.
This opens up the door to future anal-ysis of SL acquisition.
For instance, examiningthe impact that model choice (e.g., MAJORITYvs.
MAX) has on inter-lexicon agreement.Q-WordNet.
QWN gives a discrete polarity for15,510 WordNet synsets.
When a synset is an-notated in QWN, its variables, Pp?
{+,?,0}(s), areassigned the QWN values in ?
; a feasible assign-ment is sought for the remaining free variables.
Aninconsistency may occur among a set of words, or1030UN AL GI OFtotal 345 34 139 325Table 4: Q-WordNet paired with SWLs.a set of words and synsets.
Table 4 depicts theoutcome of this study.
We obtain 345 inconsis-tencies between QWN and UN.
The reduced num-ber of inconsistencies with AL (34) is explained bytheir limited ?overlay?
(QWN has only 40 adverbsynsets).
Dragut et al (2012) reports 455 incon-sistencies between QWN and UN, 110 more thanwe found here.
Again, this difference is due to therigidity of the discrete case, which leads to moreinconsistencies in general.Micro-WNOp.
This is a fractional SSL of1,105 synsets from WordNet manually annotatedby five annotators.
The synsets are divided intothree groups: 110 annotated by the consensusof the annotators, 496 annotated individually bythree annotators, and 499 annotated individuallyby two annotators.
We take the average polaritiesof groups 2 and 3 and include this data as two ad-ditional sets of values.
Table 5 gives the inconsis-tencies per user in each group.
For Groups 2 and3, we give the average number of inconsistenciesamong the users (Avg.
Incons.
in Table 5) as wellas the inconsistencies of the averaged annotations(Avg.
User in Table 5).Micro-WNOp gives us an opportunity to an-alyze the robustness of our method by compar-ing the number of inconsistencies of the individ-ual users to that of the averaged annotation.
Intu-itively, we expect that the average number of in-consistencies in a group of users to be close to thenumber of inconsistencies for the user averagedannotations.
This is clearly apparent from Table5, when comparing Lines 4 and 5 in Group 2 andLines 3 and 4 in Group 3.
For example, Group 2has an average of 68 inconsistencies for OF, whichis very close to the number of inconsistencies, 63,obtained for the group averaged annotations.
Thisstudy suggests a potential application of our al-gorithm: to estimate the confidence weight (trust)of a user?s polarity annotation.
A user with goodpolarity consistency receives a higher weight thanone with poor polarity consistency.
This can beapplied in a multi-annotator SL scenario.5.3 ComputationWe provide information about the runtime execu-tion of our method in this section.
Over all of ourexperiments, the resulting systems of constraintscan be as small as 2 constraints with 2 variablesUN AL GI OFCommon 45 3 13 43User 1 88 10 59 75User 2 50 8 24 48User 3 97 12 64 82Avg.
Incons.
78 10 49 68Group2Avg.
User 1,2,3 69 8 40 63User 4 72 9 46 60User 5 70 8 46 59Avg.
Incons.
71 9 46 60Group3Avg.
User 4,5 68 8 42 57Table 5: Micro-WNOp ?
SWD Inconsistenciesand as large as 3,330 constraints with 4,946 vari-ables.
We achieve very good overall executiontimes, 68 sec.
on average.
At its peak, our algo-rithm requires 770MB of memory.
Compared tothe SAT approach by Dragut et al (2012), whichtakes about 10 min.
and requires about 10GB ofmemory, our method is several orders of magni-tude more efficient and more practical, paving theway to building practical SL debugging tools.5.4 Inconsistency & Sentiment AnnotationThis experiment has two objectives: (1) show thattwo inconsistent SLs give very different resultswhen applied to sentiment analysis tasks and (2)given an inconsistent SL D, and D?an improvedversion ofD with fewer inconsistencies, show thatD?gives better results than D in sentiment anal-ysis tasks.
We use a third-party sentiment anno-tation tool that utilizes SLs, Opinion Parser (Liu,2012).
We give the instantiations of D below.In (1), we use the dataset aclImdb (Maas et al,2011), which consists of 50,000 reviews, and theSLs UN and SWN.
Let UN?and SWN?be the sub-sets of UN and SWN, respectively, with the prop-erty that they have the same set of (word, pos)pair entries and word appears in aclImdb.
UN?and SWN?have 6,003 entries.
We select fromaclImdb the reviews with the property that theycontain at least 50 words in SWN?and UN?.
Thisgives 516 negative and 567 positive reviews, a to-tal of 1,083 reviews containing a total of 31,701sentences.
Opinion Parser is run on these sen-tences using SWN?and UN?.
We obtain that16,741 (52.8%) sentences acquire different polar-ities between the two SLs.In (2), we use 110 randomly selected sentencesfrom aclImdb, which we manually tagged withtheir overall polarities.
We use OF and OF?, whereOF?is the version of OF after just six inconsisten-cies are manually fixed.
We run Opinion Parser onthese sentences using OF and OF?.
We obtain anaccuracy of 42% with OF and 47% with OF?, an1031improvement of 8.5% for just a small fraction ofcorrected inconsistencies.These two experiments show a strong correla-tion between polarity inconsistency in SLs and itseffect on sentiment tagging in practice.6 ConclusionResolving polarity inconsistencies helps to im-prove the accuracy of sentiment analysis tasks.
Weshow that LP theory provides a natural frameworkfor the polarity consistency problem.
We give apolynomial time algorithm for deciding whetheran SL is polarity consistent.
If an SL is found tobe inconsistent, we provide an efficient method touncover sets of words or word senses that are in-consistent and require linguists?
attention.
Effec-tive SL debugging tools such as this will help inthe development of improved SLs for use in senti-ment analysis tasks.7 AcknowledgmentsWe would like to thank Bing Liu for runningthe experiments of Section 5.4 on his commercialtool Opinion Parser, Christiane Fellbaum for thediscussions on polarity inconsistency, and PrasadSistla for the discussions on linear programming.We would also like to thank the reviewers for theirtime, effort, and insightful feedback.ReferencesRodrigo Agerri and Ana Garc??a-Serrano.
2010.
Q-wordnet: Extracting polarity from wordnet senses.In LREC.Edoardo Amaldi and Viggo Kann.
1998.
On the ap-proximability of minimizing nonzero variables orunsatisfied relations in linear systems.
TheoreticalComputer Science, 209.A.
Andreevskaia and S. Bergler.
2006.
Mining word-net for fuzzy sentiment: Sentiment tag extractionfrom wordnet glosses.
In EACL.Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-tiani.
2010.
SentiWordNet 3.0: An Enhanced Lex-ical Resource for Sentiment Analysis and OpinionMining.
In LREC.Avrim Blum, John Lafferty, Mugizi Robert Rweban-gira, and Rajashekar Reddy.
2004.
Semi-supervisedlearning using randomized mincuts.
In ICML.Eric Breck, Yejin Choi, and Claire Cardie.
2007.
Iden-tifying expressions of opinion in context.
In IJCAI.Juergen Bross and Heiko Ehrig.
2013.
Automatic con-struction of domain and aspect specific sentimentlexicons for customer review mining.
In CIKM.S.
Cerini, V. Compagnoni, A. Demontis, M. For-mentelli, and G. Gandini, 2007.
Language re-sources and linguistic theory: Typology, secondlanguage acquisition, English linguistics., chapterMicro-WNOp: A gold standard for the evaluation ofautomatically compiled lexical resources for opinionmining.
Franco Angeli Editore, Milano, IT.Nilotpal Chakravarti.
1994.
Some results concerningpost-infeasibility analysis.
European Journal of Op-erational Research, 73(1).Yanqing Chen and Steven Skiena.
2014.
Building sen-timent lexicons for all major languages.
In ACL.John W Chinneck.
2008.
Feasibility and infea-sibility in optimization: algorithms and computa-tional methods.
International Series in OperationsResearch and Management Science.
Springer, Dor-drecht.Yejin Choi and Claire Cardie.
2009.
Adapting apolarity lexicon using integer linear programmingfor domain-specific sentiment classification.
InEMNLP.Yoonjung Choi and Janyce Wiebe.
2014.
+/-effectwordnet: Sense-level lexicon acquisition foropinion inference.
In EMNLP.Xiaowen Ding, Bing Liu, and Philip S. Yu.
2008.
Aholistic lexicon-based approach to opinion mining.In WSDM.Eduard C. Dragut, Hong Wang, Clement Yu, PrasadSistla, and Weiyi Meng.
2012.
Polarity consistencychecking for sentiment dictionaries.
In ACL.Weifu Du, Songbo Tan, Xueqi Cheng, and Xi-aochun Yun.
2010.
Adapting information bottle-neck method for automatic construction of domain-oriented sentiment lexicon.
In WSDM.A.
Esuli and F. Sebastiani.
2006.
Determining termsubjectivity and term orientation for opinion mining.In EACL.Ronen Feldman.
2013.
Techniques and applicationsfor sentiment analysis.
Commun.
ACM, 56(4).C.
Fellbaum.
1998.
WordNet: An On-Line LexicalDatabase and Some of its Applications.
MIT Press,Cambridge, MA.Song Feng, Jun Sak Kang, Polina Kuznetsova, andYejin Choi.
2013.
Connotation lexicon: A dash ofsentiment beneath the surface meaning.
In ACL.Peter G?acs and Laszlo Lov?asz.
1981.
Khachiyans al-gorithm for linear programming.
In MathematicalProgramming at Oberwolfach, volume 14 of Mathe-matical Programming Studies.
Springer Berlin Hei-delberg.1032Michael R. Garey and David S. Johnson.
1990.
Com-puters and Intractability; A Guide to the Theory ofNP-Completeness.
W. H. Freeman & Co.Laurent E. Ghaoui, Eric Feron, and VendataramananBalakrishnan.
1994.
Linear Matrix Inequalities inSystem & Control Theory (Studies in Applied Math-ematics), volume 15.
SIAM.Miguel A. Goberna and Margarita M. L. Rodriguez.2006.
Analyzing linear systems containing strict in-equalities via evenly convex hulls.
European Jour-nal of Operational Research, 169(3).Miguel A. Goberna, Valentin Jornet, and Mar-garita M.L.
Rodriguez.
2003.
On linear systemscontaining strict inequalities.
Linear Algebra andits Applications, 360(0).Harvey J. Greenberg.
1993.
How to analyze the resultsof linear programspart 3: Infeasibility diagnosis.
In-terfaces, 23(6).Ahmed Hassan and Dragomir Radev.
2010.
Identify-ing text polarity using random walks.
In ACL.Vasileios Hatzivassiloglou and Kathleen R. McKeown.1997.
Predicting the semantic orientation of adjec-tives.
In ACL.Valentin Jijkoun, Maarten de Rijke, and WouterWeerkamp.
2010.
Generating focused topic-specific sentiment lexicons.
In ACL.Nobuhiro Kaji and Masaru Kitsuregawa.
2007.
Build-ing lexicon for sentiment analysis from massive col-lection of html documents.
In EMNLP-CoNLL.J.
Kamps, M. Marx, R. Mokken, and M. de Rijke.2004.
Using wordnet to measure semantic orienta-tion of adjectives.
In LREC.Richard M. Karp.
2010.
Reducibility among combina-torial problems.
In 50 Years of Integer Programming1958-2008 - From the Early Years to the State-of-the-Art.
Springer Berlin Heidelberg.L.
G. Khachiyan.
1980.
Polynomial algorithms in lin-ear programming.
Zh.
Vychisl.
Mat.
Mat.
Fiz., 20(1).Adam Kilgarriff.
2004.
How dominant is the common-est sense of a word?
In Text, Speech, and Dialogue,volume 3206 of Lecture Notes in Artificial Intelli-gence.M.
Kim and E. Hovy.
2004.
Determining the senti-ment of opinions.
In COLING.Soo-Min Kim and Eduard Hovy.
2006.
Identifying andanalyzing judgment opinions.
In HLT-NAACL.Beata Beigman Klebanov, Nitin Madnani, and JillBurstein.
2013.
Using pivot-based paraphrasingand sentiment profiles to improve a subjectivity lex-icon for essay data.
In ACL.Bing Liu.
2012.
Sentiment Analysis and Opinion Min-ing.
Synthesis Lectures on Human Language Tech-nologies.
Morgan & Claypool Publishers.Yue Lu, Malu Castellanos, Umeshwar Dayal, andChengXiang Zhai.
2011.
Automatic construction ofa context-aware sentiment lexicon: an optimizationapproach.
In WWW.Andrew L. Maas, Raymond E. Daly, Peter Pham, DanHuang, Andrew Ng, and Christopher Potts.
2011.Learning word vectors for sentiment analysis.
InACL.Saif Mohammad, Cody Dunne, and Bonnie Dorr.2009.
Generating high-coverage semantic orienta-tion lexicons from overtly marked words and a the-saurus.
In EMNLP.Wei Peng and Dae Hoon Park.
2011.
Generate adjec-tive sentiment dictionary for social media sentimentanalysis using constrained nonnegative matrix fac-torization.
In ICWSM.Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.2009.
Expanding domain sentiment lexicon throughdouble propagation.
In IJCAI.Mark Sanderson.
1999.
The impact on retrieval ef-fectiveness of skewed frequency distributions.
ACMTransactions on Information Systems, 17(4).Thomas J. Schaefer.
1978.
The complexity of satisfia-bility problems.
In STOC.Alexander Schrijver.
1986.
Theory of linear and in-teger programming.
John Wiley & Sons, Inc., NewYork, NY, USA.P.
Stone, D. Dunphy, M. Smith, and J. Ogilvie.
1966.The General Inquirer: A computer approach to con-tent analysis.
MIT Press.M.
Taboada and J. Grieve.
2004.
Analyzing appraisalautomatically.
In AAAI Spring Symposium.Hiroya Takamura, Takashi Inui, and Manabu Okumura.2005.
Extracting semantic orientations of words us-ing spin model.
In ACL.M.
Tamiz, S. J. Mardle, and D. F. Jones.
1996.
De-tecting IIS in infeasible linear programmes usingtechniques from goal programming.
Comput.
Oper.Res., 23(2).Duyu Tang, Furu Wei, Bing Qin, Ming Zhou, and TingLiu.
2014.
Building large-scale twitter-specific sen-timent lexicon : A representation learning approach.In COLING.P.
Turney.
2002.
Thumbs up or thumbs down?
seman-tic orientation applied to unsupervised classificationof reviews.
In ACL.Gbolahan K. Williams and Sarabjot Singh Anand.2009.
Predicting the polarity strength of adjectivesusing wordnet.
In ICWSM.1033T.
Wilson, J. Wiebe, and P. Hoffmann.
2005.
Recog-nizing contextual polarity in phrase-level sentimentanalysis.
In HLT/EMNLP.Yunfang Wu and Miaomiao Wen.
2010.
Disambiguat-ing dynamic sentiment ambiguous adjectives.
InCOLING.1034
