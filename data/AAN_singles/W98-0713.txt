III!I!III!IIIIIiIILexical Acquisition with WordNet and the Mikrokosmos OntologyTom O'Hara ,  Kav i  Mahesh  and  Serge i  N i renburgComput ing Research LaboratoryNew Mexico State UniversityLas Cruces, NM 88003-0001t omohara, mahesh,sergei~crl.nmsu.eduAbst rac tThis paper discusses an approach to augmentinga lexicon for knowledge-based machine translation(KBMT) with information derived from WordNet.The Mikrokosmos project at NMSU's ComputingResearch Laboratory has concentrated on the cre-ation of the Spanish and Japanese lexicons, sothe English lexicon is less developed.
We investi-gated using WordNet as a means to automate p0r-tions of the English lexicon development.
Severalheuristics axe used to find the WordNet synonymsets corresponding to the concepts in the Mikrokos-mos language-independent ontology.
Two of theseheuristics exploit the WordNet is-a hierarchy: oneperforms hierarchical matching of both taxonomies,and the other computes imilarity based on fre-quency of defining words and their ancestors ina cor-pus.
The result is a lexicon acquisition tool that pro-duces plausible lexical mappings from English wordsinto the Mikrokosmos ontology.
Initial performanceresults are included, which indicate good accuracyin the mappings.1 Introduction1.1 Problem AreaIt's an understatement that lexicon acquisition is acostly endeavor.
Traditional dictionaries have beendeveloped over the course of decades through theemployment of many lexicographers and numerousconsultants.
Furthermore, the development of se-mantic lexicons incurs additional cost for the ex-plicit encoding of meaning representations that pro-vide details often omitted in traditional dictionaries,which are written for humans not computers.
Atkins(1995) estimates that it would take 100 person-yearsto properly develop asemantic lexical database com-parable in scope to a standard college dictionary.Lexicons are a key component of machine trans-lation systems (Onyshkevych and Nirenburg, 1994).The Mikrokosmos (/~K) project at NMSU's Comput-ing Research Laboratory isdeveloping Spanish, Chi-nese and Japanese lexicons to support knowledge-based machine translation (KBMT).
The followingtable indicates the amount of effort that was re-quired for developing the initial Spanish lexicon en-tries from scratch (Viegas et al, 1996):6798 word-sense entries (as of 29 Mar 1996)Average of 1.2 meaning per word formAcquisition rate: 45 entries/day per personAcquisition effort: 4 person yearsLike many research centers, we  don't have the hu-man resources to construct the entire lexicons manu-ally, so we are investigating several different ways toautomate lexicon acquisition.
Viegas et al (1996)discuss one approach at this through the use of lexi-cal rules, such as for generating the morpho-semanticderivatives of Spanish verbs.A natural solution would be to take advantageof machine readable dictionaries (MILD's), suchas Longman's Dictionary of Contemporary En-glish (LDOCE).
This approach was popular in theeighties; however, it achieved mixed success.
See(Wilks et al, 1996) for a comprehensive surveyof MRD research.
One of the main problems isthat dictionaries aren't explicit about the particularsenses of the words used in definitions.
In addition,much knowledge of the world is assumed by the dic-tionary entries.
Consider the second LDOCE senseof the noun "whistle" (Procter, 1978):whistle, n .... 2. the high sound madeby passing air or steam through a smalltube-shaped area, either an instrument, amouth, or a beakObviously, ~air" does not mean musical melody,even though this is closer to the topic area of the def-inition than the gas-mixture sense.
Note also thatthe definition assumes the reader knows what theactual sound is like and just needs to know enoughto distinguish it from similar sounds, such as from aflute.As indicated in (Nirenburg, 1994), relying solelyon MRD's will not yield a lexicon sufficient for re-alistic applications.
These need to be fortified withmachine-readable versions of other reference sources,such as thesauri, collocation lists, and perhaps evenencyclopedias.
Furthermore, text corpora from the94III!IIIII!lIIIIiiIIspecific application domain should be used for train-ing and testing.
In the Mikrokosmos project, thistype of information has been consulted uring thedevelopment of the language-independent ontology,most of which was created manually (Mahesh andNirenburg, 1995).
Therefore, it is conceivable to au-tomate much of the lexical acquisition by mappingentries from MRD's  into concepts from the ontology.As long as a word being defined is a simple refine-ment of a concept present in the ontology, this map-ping forms the basis of the lexical representation,which can then be refined manually if necessary.
Thework reported here demonstrates the feasibility ofthis approach by mapping entries from Princeton'sWordNet (Miller, 1990) into our ontology.Like a thesaurus, WordNet is structured aroundgroups of synonymous words.
In WordNet thesegroups are called synsets and are taken as indistin-guishable in particular contexts.
Like a dictionary, itprovides definitions and usage examples.
However,imlike both, it provides explicit relationships amongthe synsets (e.g, /s-a and has-a).
Thus WordNetalso represents an explicit ontology of concepts, pro-vided that word senses are considered as concepts.
Itis this lexicalized ontology that facilitates mappingthe WordNet senses (i.e., synsets) for a English wordinto the corresponding concept in the Mikrokosmosontology.Note that there are several reasons why mappingdirectly from the WordNet synset to the equivalentin a particular foreign language is undesirable.
Themain reason is that mapping into a language-neutralontology facilitates richer text meaning representa-tions that are not tied to the specifics of particularlanguages.
For more details on this and other bene-fits of KBMT see (Nirenburg et al, 1992).1.2 Overview of the SolutionOverall, the algorithm is fairly straightforward andincorporates few domain-specific dependencies.
Tobegin with, the mapping algorithm does not performparsing or pattern matching of the definition entriesbut instead relies on the conventions used in theontology development.
For instance, the names ofconcepts use the corresponding English word when-ever possible; in cases where no English word pro-vide a suitable label, the name is based on the con-cept's parent label (e.g., VOLUNTARY-PERCEPTUAL-EVENT, a kind of PERCEPTUAL-EVENT).
Therefore,when a word from a synset and a pK concept nameare the same or just slight variations, there is a goodchance that the same concept is being referred to.The control mechanism thus is a generate-and-testcycle applied to each/~K concept: generate wordspotentially in WordNet synsets and test the sensesof these for the best matches with the Mikrokosmosconcept.The algorithm incorporates two main heuristics95that exploit the WordNet ontology hierarchy.
Onespecifically assigns the highest weight o the poten-tial synset/concept mapping which has the highestdegree of overlap between the respective is-a hier-archies.
For instance, when mapping to the con-cept DOG, the canine sense of "dog", which goesthrough MAMMAL and to ENTITY, is preferred overthe scoundrel sense, which goes through PERSON toENTITY.The other heuristic uses synset frequencies, esti-mated from a corpus of Wall Street Journal arti-cles.
This is based on a technique for disambiguat-ing noun groups using WordNet by Resnik (1995).For each pair of defining words that share a commonancestor, the support for the match is increased byan amount inversely proportional to the frequencyof the ancestor, because unrelated words only havecommon ancestors at the top level of the hierarchy.Two other heuristics exploit he ontology but in amore localized manner.
One assigns a weight basedon the degree of overlap among the children for eachconcepts.
The other does the same thing for thesiblings of each.
The final heuristic omputes thedegree of overlap among the words in the definitiontexts.
This was meant mainly as a weak supplementto the others to help discriminate close mappings,but it turned out to be more accurate than the otherlocalized heuristics.In cases where a fuUy-automated system mightnot be considered robust enough for a particularapplication domain, this approach can easily headapted to an interactive one.
In this case, themain benefit would be that the human lexicogra-pher can be relieved of much of the tedious aspectsof the English lexicon development.
Specifically, thematching of new words against concepts in the ontol-ogy can be done automatically, along with providingdefinition glosses and examples.
Therefore, the lex-icographer can concentrate on filling in the detailsnecessary to realize the lexical entry.2 Background and  ExamplesIn Mikrokosmos, most of the language-neutral in-formation is stored in the ontology.
Each conceptis represented by a rich flame structure, which al-lows for numerous links among the concepts.
For in-stance, it includes theme and instrument relations,as well as the more usual /s-a and set-membershiprelations; the ontology also contains electional re-strictions on case roles.
In contrast, he lexicon con-tains just the information needed to realize a conceptin a given language (Onyshkevych and Nirenburg,1994).
It will contain the usual information aboutmorphology and syntax; but, most of the semanticswill be defined in terms of a concept from the ontol-ogy.
Therefore, the semantics for the lexicon entrymight just be a direct mapping to the associatedIIiiIIiiiIII(book(book-N1(cat n) ;; category(morph) ;; morphology(anno ;; annotations(def "a copy of a written work or compositionthat has been published")(ex "I just read a good book on economics")(cro~-ref))(syn) ;; syntactic features(syn-struc ;; syntactic structure(1 ((root $var0)(cat n)) ))(sem-struc ;; semantic structure(lex-map ;; l ex ica l  mapping(1 (COOK)))) ;; to concept book(lex-rules) ;; lexical rules(pragm) ;; pragmatics(styl))) ;; stylisticsFigure I: Lexical representation for "book"concept.
This is illustrated in the lexical entry for"book" in figure 1.Nouns form the bulk of any lexicon and often havedirect mappings into the ontology.
Therefore, thistool facilitates acquisition significantly by producingmany entries that are nearly complete.
In contrast,the verbal entries it produces are only partially com-plete since Word_Net doesn't provide detailed infor-mation on subcategorizations a d selectional restric-tions.
Two examples will be given to illustrate theproblems that arise in the matching process.
Thefirst one is what one would think as a trivial caseto match, namely a concept for a simple concreteobject, a chair.
The other illustrates problems withdifferent ontological decompositions, specifically twodifferent views of singing.2.1 Direct mapping for "chair"The/~K hierarchy for the concept CHAIR is shownin figure 2.
WordNet has four synsets or senses for"chair", so each of these are potential candidates fora direct mapping:sl.
chair: a seat for one person, with a supportfor the backs2.
professorship, chair: the position of professors3.
president, chairman, chairwoman, chair,chairperson: the officer who presides at themeetings of an organizations4.
electric chair, chair, death chair, hot seat: aninstrument of death by electrocution that re-sembles a chairSince synsets 2 and 3 cover the human agent senseof chair, they won't match well with the pK  concept.But senses I and 4 will produce similar matches since96chair=#seating-furuiture=*furniture=*interior-building-part=*building-part=#building-artifact: =#artifact: =#inanlmate: =#separable-entity: =#physical-object: =#object: =#all=#place=#physical-object=#object=#allFigure 2:/zK concept hierarchy for CHAIRthey both are derived from ARTIFACT, as in/~K:sl: chair=*seat=#furuiture, ..., article of furniture=*furnishings=*instrumentality, instrumentation=*artifact, artefact=*object ..... physical object:*entitys4: electric hair, chair, death chair, hot seat=*instnunent of execution=#instrument=*device=*instrumentality, nstrumentation=*artifact, artefact=*object, ..., physical object=*.entityA problem that complicates selecting the appro-priate sense is that /zK classifies FURNITURE nil-der the generic INTERIOR-BUILDING-PARTS whereasWordNet uses the more specific FURNISHINGS.2.2 Problematic mapp ing  with "sing"The verb "sing ~ illustrates what could go wrongwhen trying to match from WordNet to/zK.
Thereare two main reasons for this problem: The WordNetverb hierarchy is much shallower than /~K's eventhierarchy; and, the concept of singing has been rep-resented differently.
Here is the pK  hierarchy forSING:sing: to produce musical sounds with the voice=*human-voice:the sound made through the mouth byhuman beings=*emit-sound:to create wave-like disturbances in the airIiiIiIIiI:=~wave-energy-event:events in which light, sound, etc.waves are transmitted or emitted=#physical-event:events involving physical force=*event:any activity, action, happening, orsituation=~alhrefers to any conceptThe salient aspect is singing as emitting waveformenergy.
In contrast, the WordNet hierarchy of theclosest synset for "sing" emphasizes the commttuica-tive aspects of singing:s2: sing:produce musical tones with the voice=~talk, speak, utter, mouth, verbalize:express in speech=~cornmunicate, ..., transmit feelings:n/a=~interact, ..., act towards others:act together with others=~act, move, take measures, ...:carry out an actionThe other senses cover miscellaneous meanings of"sing":sl.
sing, deliver by singing: n/as3.
whistle, sing: let off steam; as of tea kettlesst.
tattle, talk, blab .... : divulge information orsecrets; spill the beansConsequently, the hierarchy match will not pro-duce any alignment; and, the similarity match willnot be effective since the synset frequency counts areindirectly based on the WordNet hierarchy.
But thetext match will still be applicable.
Plus, since thechildren & sibling matches are localized, a plausiblematch can still be generated.3 ImplementationThe Onto-WordNet Mapper works by performing abreadth-first traversal of the pK  concept space, at-tempting to find matches for each concept node witha synset ~om WordNet.
The end result is a list of po-tential mappings sorted by a match score derived byweighting the scores ~om the individual heuristics.An  empty list indicates that no suitable matcheswere determined.
This mapping process is detailedin figure 3, which also shows the default weights usedprior to the optimization discussed later.
The fol-lowing sections describe each of the five matchingheuristics.
Note that a separate component, not de-scribed here, is used to produce the lexicon entryfrom the best match, provided the score is above acertain threshold.97For each Mikrokosmos concept:1.
Get candidate synset(a) Try to find a word in WordNet with the samespeUing (e.g.
REAL*ESTATE vs. "real estate").
(b) Try to find a word matching a prefix or suifixof the concept (e.g., PEPPER-VEGETABLE vs."pepper").2.
Perform structure match of the synset and concepthierarchies.
For each word and concept pair:(a) Check for exact match of the word and con-cept.
(b) Check for partial match of the word and con-cept (as above).
(c) Check predefined equivalences.
(d) Evaluate each match by computing the per-cent of matched nodes on the best-matchingbranches for each (scaled by length).3.
Perform concept-similarity match using corpus-derived probabilities(a) Get words occurring in the definition glossesfor synset & concept.
(b) Compute palrwise similarity by finding ances-tor with the highest information content (themost-informative-subsumer ).
(c) Evaluate the match by the degree of sup-port the synset gets from all of the most-informative-subsumers that are applicable.4.
Perform intersection matches for the following:(a) the sibling synsets ?, concepts.
(b) the children synsets & concepts.
(c) the definition gloss words ~om the synset &concept5.
Compute total match score by a weighted sum-?
25 * hier + .25 * sire + .2 * chi ld + .2 * sibl +.
1 * text.Figure 3: Onto-WordNet Mapping Algorithm3.1 Hierarch ica l  MatchThe hierarchy match (see figure 4) computes a scorefor the similarity of the two concept hierarchies.Since WordNet gives several words per synset, thematching at each step uses the max imum scores ofthe alternatives.
The matching proceeds node bynode up the hierarchies.
If a given node doesn'tmatch, it is skipped, but it still is included the totalnumber of nodes.As given here, this algorithm is quite inefficientsince similar subproblems are generated repeatedly.In the actual solution, the results from previousmatches are cached, making the solution compara-ble to one based on dynamic programming.
Notethat this problem is related to-the "Longest Corn-IliIiIiIIllmatch-hierarchies(wn, onto)1.
If both lists empty, the score and node-count is 02.
If either hierarchy is empty, the score is likewise 0.Determine node-count from the nodes in the otherhierarchy.3.
Compute the s'tmilarity of the WordNet synset andpK concept names.
If the result is above a presetthreshold (0.75), add it to the score, and tally inscore ofrecursive match of the parents:match-hierarchies(rest (wn), rest(onto))4.
Otherwise, take the maximum of the scores fromthe recursive matches in which the WordNet nodeand/or the pK node is skipped:max(match-hides(rest (wn), onto),match-hierarchies (wn, rest(onto)),match-hlerarchies(rest (wn), rest(onto)))This is done for each possible pairing of the hierar-chy paths, in case either concept has more than oneparent.Figure 4: Hierarchy Match Heuristicmort Subsequence" (LCS) problem, which is solvedvia dynamic programming in (Cormen et al, 1990).Their recursive formulation for the problem follows:Let l\[i, j\] be the length of an LCS of the sequences X~and r#:0 i f i=Oor j=Ol\[i, j \ ]  = l i i  - 1, j - 1\] + 1 if x ,  = y,,n==(l\[i,j-1\],z\[i-l,j\]) ~=,#y,3.2 Similarity MatchThe idea of the similarity heuristic is to use the infor-mation content of the common ancestor concepts (orsubsumers) for words in the definition texts.
This isbased on the technique Resnik (1995) uses for dis-ambiguating noun groups.
The frequency of a synsetis based on the frequency of the word plus the fre-quencies of all its descendant synsets.
Therefore,the top-level syusets have the highest frequenciesand thus the highest estimated probability of occur-rence.
For each pair of nouns from the text of bothdefinitions (one each from Word.Net and pK), themost-informatiue-subsumer is d termined by findingthe common ancestor with the highest informationcontent, which is inversely related to frequency.
Theinformation content of this ancestor determines thepairwise similarity score.
The candidate synset hatreceives the most support from the pairwiee similar-ity scores is then preferred.
These calculations aredetailed in figures 5 and 6.This technique requires an estimation for the fre-quencies of the WordNet synsets.
Unless the corpushas been annotated to indicate the WordNet synsetfor each word, there is no direct way to determine98the synset frequencies.
However, these can be es-timated by taking the frequency of the words in alldescendant synsets (i.e., all the words the synset sub-sulnes).Wordsc = {Word~\[Wor& has sense subsumed by c}Freqc = E Countww E Words=Pc = FreqcNsim(wi, wj) = max \[-log Jbc\]cEsubsumers(w~ ,wi)Figure 5: Calculation of similarity (Resnik, 1995)match-similarity(synset, concept)for each pair of nouns wi, wj from the definitionssims,# = calc-sim(w~, wj)misi,j = most-informative~subsumer(wi, wj)if misij E subsumers(synset) thenincrease synset-support by sim~,jincrease normalization by simijscore is synset-support scaled by normalizationFigure 6: Similarity-based heuristic3.3 Miscellaneous matching heuristicsThe remaining heuristics are similar in that theyeach are based on degree of overlap in word-basedmatching.
For instance, in the match-siblingsheuristic, the siblings sets for the candidate synsetand ~K concept are compared by determining thesize of the intersection relative to the size of thepK  set.
The match-children and match-definition-text heuristics are similar.
Figure 7 shows thegeneral form of these intersection-based matchingheuristics.
This uses an equivalence test modifiedto account for a few morphological variations; thetest also accounts for partial matches with the com-ponents of a concept name (similar to first step infigure 3).
!I|!I!IIIIII!Imatch-word-lists (wn-list, onto-list)wn-list = normalize(wn-list)onto-list .~ normalize(onto-list)overlap = intersection(wn-list, onto-list, similar-form)score -- length(overlap) / (1 + length(onto-list))similar-form(wordl, word2)return (word-sim~hrity(wordl, word2) >= 0.25)Figure 7: General form of intersection heuristics4 EvaluationTo evaluate the performance of the mapper, twosets of 100 random concepts were mapped by handinto the corresponding WordNet synset (or markedas not-applicable).
The first set was selected fromthe entire set of concepts mapped, whereas the sec-ond set was selected just from the cases with morethan one plausible mapping (e.g., the correspondingWordNet entry has more than one synset).
The re-sults of this test shows that it handles 77% of theambiguous cases and 94% of the cases overall, ex-cluding cases corresponding to lexical gaps in Word-Net (see table 1).
This shows an improvement ofmore than 15% over the lower bound, which wasestimated from the proportion of correct mappingsusing sense 1.
Note that these tests were performedafter development was completed on the system.Type Correct Lower Accuracyambiguous 70/91 60.2 76.9unrestricted 59/64 90.7 92.2Table 1: Evaluation of mapper performanceThe remainder of this section presents results onanalyzing how often the individual heuristics con-tribute to the correct result.
The most importantfinding is that the hierarchy and text match ac-count for most of the results.
Furthermore, when allheuristics are used together, the similarity heuristichas a minor contribution to the result, although itis second when heuristics apply individually.Table 2 contains the results for each heuristic eval-uated individually against he manual mapping ofthe ambiguous cases.
Note that the overall scoreshows the accuracy using the default weights forcomparison purposes.As a rough estimate for optimizing the weight-ing scheme, regression analysis was performed onthe score produced by each heuristic to the result ofthe manual mapping for the ambiguous cases.
Thisaccounts for the interactions among the heuristics.There are 343 data points, because the score for each99Heuristic Correct AccuracyHierarchySiblingsTextSimilarityChildrenOverall6645425812700.7250.4950.4620.6370.1320.769Table 2: Individual accuracy results (91 cases)sense is included, not just those for the current sense.See table 3.
Although the correlation coefficient isonly 0.41, the regression suggests that the hierarchymatch and the text match are the most significantheuristics.
When using these revised weights, theaccuracy increases to 81.3%.HeuristicHierarchy 0.815Siblings 0.237Text 0.976Similarity 0.332Children 0.605Coefficient StdError Weight0.134 0.2750.069 0.0800.176 0.3290.077 0.1120.178 0.204Table 3: Regression on results (n=343; R2=0.41)An alternative method for determining theseweights used an optimization search, which accountsfor nonlinear relationships.
This method producedthe weights hown in table 4.
This shows that onlythe hierarchy and text heuristics contribute signif-icantly to the result.
When these are applied tothe ambiguous sample, the accuracy becomes 83.5%.Note that the results given earlier uses the lower fig-ure, because this represents the evaluation beforetraining the weights on the sample.Heuristic DefaultWeightHierarchy 0.25 0.40Siblings 0.20 0.10Text 0.10 0.30Similarity 0.25 0.10Children 0.20 0.10OptimizedWeightTable 4: Optimization search for weightsThese results are preliminary: larger test setswould be required before conclusions can be drawn.However, it seems clear that a statistical approachis not likely to serve as a complete solution for thisproblem.
Instead, a combination of symbolic andI1I1iIIiIiIIIIIiIstatistical appro~':hes seems appropriate, with anemphasis on the fi)rmer.5 Relation to other workWork of this nature has been more common inmatching entries in multilingual dictionaries (e.g.,(Rigau and Agirre 1995)) than in lexical acquisition.This section will ~oncentrate on work augmentinglexical informatiozL by ontological mappings.Knight and Luk (1994) describe an approach to es-tablish correspondences between Longman's Dictio-nary of Contempol'ary English (LDOCE) and Word-Net entries.
A defiaition match compares overlapof the LDOCE de ~nition text to those of both theWordNet entry aJLd its hypernym along with thewords from closely-related synsets.
Their hierarchymatch uses the im I,licit hierarchy within LDOCE de-fined from the genas terms of the definitions, incor-porating work done at NMSU (Bruce and Guthrie,1991) that identifies and disaxabiguates the headnouns in the definJ tion texts.
The hierarchy is usedto guide the deterzaination f nontrivial matches byproviding local cozLtext in which senses can be con-sidered unambiguo as by filtering out the other sensesnot applicable to either subhierarchy.
It also allowsfor matching the ~ arents of words from an existingmatch.
Note that r, his mapping is facilitated by thetarget and source domains being the same: namely,English words.
Therefore, the problem of assessingcorrespondence is minimized.Chang and Chen (1996) describe an algorithm foraugmenting LDO?
'E with information from Long-man's Lexicon of Contemporary English (LLOCE).LLOCE is basically a thesaurus, with word lists ar-ranged under 14 subjects and 129 topics.
Thesetopic identifiers are used as a coarse form of sensedivision.
The mat~ zing algorithm works by comput-ing a similarity scol'e for the degree of overlap in thelist of words for each LDOCE sense compared to thelist of words from t\[ e LLOCE topics that contain theheadword (expanded to include cross-references).Other work is l,~s directly related.
Lehmann(1995) describes a methodology for semantic inte-gration that matches classes based on the overlapin the inclusions of typical class members.
For thisto be effective, these instances must have been con-sistently applied in both ontologies.
O'Sullivan etal.
(1995) describe work on doing the reverse pro-cess we do.
Specifi(ally, they augment WordNet bylinking in entries fr,)m an ontology describing wordprocessing.
However, their approach requires man-ual linking.6 ConclusionCombining traditioaal symbolic heuristics with astatistical approach yields an effective method foraugmenting lexical acquisition.
This report illus-i00trated how this facilitated the mapping of Word-Net synsets into a KBMT ontology.
The symbolicapproach included heuristics for structure matchingand intersection-based comparisons.
The statisticalapproach added a similarity test based on synset fre-quency estimated from a Wall Street Journal cor-pus.
The result is a lexicon acquisition system thatproduces accurate mappings.
This system has beenused within the Mikrokosmos project to produce abasic lexicon of over 2000 entries, which were man-ually validated to ensure correctness.
Additionalmappings will be possible when the ontology is ex-tended to other domain.% since it now emphasizesbusiness transactions.
To allow for broader cover-age, future work will address producing mappingsthat include refinements of the concepts from theontology.Although this work concentrated on nouns, thetechniques can be extended to include other typesof words.
Furthermore, it can be generalized tohandle ontology merging, in particular, the problemof merging classification systems.
Lehmann (1995)points out that there axe several practical ontologiessuitable for merging to be used with a variety of in-teliigent applications, such as the Electronic DataInterchange (EDI) standard for descriptions of busi-ness transactions (ANSI, 1994).
The idea is to takeadvantage ofthe time-consuming classification workalready done.AcknowledgementsThe WordNet support code uses the CommonLispinterface developed by Mark Nahabedian of MIT.At CRL, many people provided valuable input forthis work, including Jim Cowie, Mark Davis, NickOurusoff, Arnim Ruelas, Evelyne Viegas, and JanyceWiebe.ReferencesANSI, X12 Standard, Subrelease 003041, ANSI,Alexandria, VA, February 1994.Atkins, B.
(1995), "The Dynamic Database", in Ma-chine Tractable Dictionaries: Design and Con-struction, C. Guo, ed., Norwood, N J: Ablex Pub-lishing Corporation, pp.
131-143.Bruce, R., and L. Guthrie (1991), "Building a NounTaxonomy from a Machine Readable Dictionary",Technical Report MCCS-91-207, Computing Re-search Laboratory, NMSU.Chang, J., and J. Chen (1996), "Acquisition ofComputational-Semantic Lexicons from MachineReadable Lexical Resources", in Proc.
ACL'96Workshop on the Breadth and Depth of Seman-tic Lexicons, June 28, 1995, Santa Cruz, CA.IIIIII|iCormen, T., C. Leiserson, and R. Rivest (1990), In-troduction to Algorithms, Cambridge, MA: MITPress.Knight, K., and S. Luk (1994), "Building a Large-Scale Knowledge Base for Machine Translation",in Proc.
Twelfth National Conlerence on ArtificialIntelligence, August 1-4, 1994, Seattle, Washing-ton: American Association for Artificial Intelli-gence.Lehmann, F. (1995), "Combining Ontologies, The-sauri, and Standards", in Proc.
Workshop on Ba-sic Ontological Issues in Knowledge Sharing, In-ternational Joint Conference on Artificial Intel-ligence (IJCAI-95), Aug. 19-20, 1995.
Montreal,Canada.Mahesh, K., and S. Nirenburg (1995), "A SituatedOntology for Practical NLP', in Proc.
Workshopon Basic Ontological Issues in Knowledge 5baring,International Joint Conference on Artificial Intel-ligence (IJCAI-95), Aug. 19-20, 1995.
Montreal,Canada.Nirenburg S., J. Carbonell, M. Tomita and K. Good-man (1992), Machine Translation: A Knowledge-based Approach, San Mateo, CA: Morgan Kauf-mann.Nirenburg, S. (1994), "Lexicon Acquisitive for NLP:A Consumer Report", in Computational Ap-proaches to the Lexicon, B. Atkins & A.
Zampoli,eds., Oxford: Oxford University Press, pp.
313-347.Miller, G., (1990), "WordNet: An on-line lexicaldatabase", International Journal of Lexicography3(4).Onyshkevych, B., and S. Nirenburg (1994), "TheLexicon in the Scheme of KBMT Things", Tech-nical Report MCCS-94-277, Computing ResearchLaboratory, NMSU.O'Sullivan, D., A. McElligott, R. Sutclitfe (1995),"Augmenting the Princeton WordNet with a Do-main Specific Ontology", in Proc.
Workshop onBasic Ontological Issues in Knowledge Sharing,International Joint Conference on Artificial Intel-ligence (IJCAI-95), Aug. 19-20, 1995.
Montreal,Canada.Procter, P. (1978), ed., Longman Dictionary ofContemporary English, Harlow, Essex: LongmanGroup.Resnik, P. (1995), "Disambiguating Noun Groupingswith Respect o WordNet Senses", in Proc.
ThirdWorkshop on Very Large Corpora, June, 1995.Rigau, G. and E. Agirre (1995), "DisambiguatingBilingual Nominal Entries against WordNet', inProc.
Computational Lexicon Workshop at the Eu-ropean Summer School in Logic, Language and In-formation, Barcelona, pp.
71-82.Viegas, E., B. Onyshkevych, V. Raskin, and S.Nirenburg (1996), "From Submit o Submitted via101Submission: On Lexical Rules in Large-Scale Lex-icon Acquisition", in Proc.
31st Annual Meetingof the Association for Computational Linguistics,Santa Cruz, CA.Wilk% Y., B. Slator; and L. Guthrie (1996), ElectricWords, Cambridge, MA: MIT Press.
