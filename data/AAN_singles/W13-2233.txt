Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 262?270,Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational LinguisticsCombining Bilingual and Comparable Corporafor Low Resource Machine TranslationAnn IrvineCenter for Language and Speech ProcessingJohns Hopkins UniversityChris Callison-Burch?Computer and Information Science Dept.University of PennsylvaniaAbstractStatistical machine translation (SMT) per-formance suffers when models are trainedon only small amounts of parallel data.The learned models typically have bothlow accuracy (incorrect translations andfeature scores) and low coverage (highout-of-vocabulary rates).
In this work, weuse an additional data resource, compa-rable corpora, to improve both.
Begin-ning with a small bitext and correspond-ing phrase-based SMT model, we improvecoverage by using bilingual lexicon induc-tion techniques to learn new translationsfrom comparable corpora.
Then, we sup-plement the model?s feature space withtranslation scores estimated over compa-rable corpora in order to improve accu-racy.
We observe improvements between0.5 and 1.7 BLEU translating Tamil, Tel-ugu, Bengali, Malayalam, Hindi, and Urduinto English.1 IntroductionStandard statistical machine translation (SMT)models (Koehn et al 2003) are trained usinglarge, sentence-aligned parallel corpora.
Unfortu-nately, parallel corpora are not always available inlarge enough quantities to train robust models (Ko-lachina et al 2012).
In this work, we consider thesituation in which we have access to only a smallamount of bitext for a given low resource languagepair, and we wish to supplement an SMT modelwith additional translations and features estimatedusing comparable corpora in the source and tar-get languages.
Assuming access to a small amount?Performed while faculty at Johns Hopkins Universityof parallel text is realistic, especially consideringthe recent success of crowdsourcing translations(Zaidan and Callison-Burch, 2011; Ambati, 2011;Post et al 2012).We frame the shortcomings of SMT modelstrained on limited amounts of parallel text1 interms of accuracy and coverage.
In this con-text, coverage refers to the number of words andphrases that a model has any knowledge of at all,and it is low when the training text is small, whichresults in a high out-of-vocabulary (OOV) rate.Accuracy refers to the correctness of the transla-tion pairs and their corresponding probability fea-tures that make up the translation model.
Becausethe quality of unsupervised automatic word align-ments correlates with the amount of available par-allel text and alignment errors result in errors inextracted translation pairs, accuracy tends to below in low resource settings.
Additionally, esti-mating translation probabilities2 over sparse train-ing sets results in inaccurate feature scores.Given these deficiencies, we begin with a base-line SMT model learned from a small parallel cor-pus and supplement the model to improve its ac-curacy and coverage.
We apply techniques pre-sented in prior work that use comparable corporato estimate similarities between word and phrases.In particular, we build on prior work in bilinguallexicon induction in order to predict translationsfor OOV words, improving coverage.
We then usethe same corpora to estimate additional translationfeature scores, improving model accuracy.
We seeimprovements in translation quality between 0.51We consider low resource settings to be those with par-allel datasets of fewer than 1 million words.
Most standardMT datasets contain tens or hundreds of millions of words.2Estimating reordering probabilities over sparse data alsoleads to model inaccuracies; we do not tackle that here.262and 1.7 BLEU points translating the following lowresource languages into English: Tamil, Telugu,Bengali, Malayalam, Hindi, and Urdu.2 Previous WorkPrior work shows that a variety of signals, in-cluding distributional, temporal, topic, and stringsimilarity, may inform bilingual lexicon induc-tion (Rapp, 1995; Fung and Yee, 1998; Rapp,1999; Schafer and Yarowsky, 2002; Koehn andKnight, 2002; Monz and Dorr, 2005; Huanget al 2005; Schafer, 2006; Klementiev andRoth, 2006; Haghighi et al 2008; Mimno et al2009; Mausam et al 2010).
Other work hasused decipherment techniques to learn translationsfrom monolingual and comparable data (Ravi andKnight, 2011; Dou and Knight, 2012; Nuhn et al2012).
Daume?
and Jagarlamudi (2011) use con-textual and string similarity to mine translationsfor OOV words in a high resource language do-main adaptation for a machine translation setting.Unlike most other prior work on bilingual lexiconinduction, Daume?
and Jagarlamudi (2011) use thetranslations in end-to-end SMT.More recently, Irvine and Callison-Burch(2013) combine a variety of the techniques forestimating word pair similarity using source andtarget language comparable corpora.
That workshows that only a small amount of supervision isneeded to learn how to effectively combine simi-larity features into a single model for doing bilin-gual lexicon induction.
In this work, because weassume access to a small amount of bilingual data,it is natural to take such a supervised approach toinducing new translations, and we directly applythat of Irvine and Callison-Burch (2013).Klementiev et al(2012) use comparable cor-pora to score an existing Spanish-English phrasetable extracted from the Europarl corpus.
In thiswork, we directly apply their technique for scor-ing an existing phrase table.
However, unlike thatwork, our initial phrase tables are estimated fromsmall parallel corpora for genuine low resourcelanguages.
Additionally, we include new transla-tions discovered in comparable corpora.Other prior work has mined supplemental paral-lel data from comparable corpora (Munteanu andMarcu, 2006; AbduI-Rauf and Schwenk, 2009;Smith et al 2010; Uszkoreit et al 2010; Smith etal., 2013).
Such efforts are orthogonal and com-plementary to the approach that we take.Language Train Words (k) Dev Types Dev TokensSent Dict % OOV % OOVTamil 335 77 44 25Telugu 414 41 39 21Bengali 240 7 37 18Malayalam 263 151 6 3Hindi 659 n/a 34 11Urdu 616 116 23 6Table 1: Information about datasets released by Post et al(2012): thousands of words in the source language parallelsentences and dictionaries, and percent of development setword types (unique word tokens) and word tokens that areOOV (do not appear in either section of the training data).Language Web Crawls WikipediaTamil 0.1 4.4Telugu 0.4 8.6Bengali 2.7 3.3Malayalam 0.1 3.7Hindi 18.1 6.4Urdu 285 2.5Table 2: Millions of words of time-stamped web crawls andWikipedia text, by language.3 Using Comparable Corpora toImprove Accuracy and CoverageAfter describing our bilingual and comparable cor-pora, we briefly describe the techniques proposedby Irvine and Callison-Burch (2013) and Klemen-tiev et al(2012).
The contribution of this paperis the application and combination of these tech-niques in truly low resource translation conditions.3.1 DatasetsPost et al(2012) used Mechanical Turk to col-lect small parallel corpora for the following Indianlanguages and English: Tamil, Telugu, Bengali,Malayalam, Hindi, and Urdu.
They collected bothparallel sentence pairs and a dictionary of wordtranslations.3 We use all six datasets, which pro-vide real low resource data conditions for six trulylow resource language pairs.
Table 1 shows statis-tics about the datasets.Table 2 lists the amount of comparable datathat we use for each language.
Following bothKlementiev et al(2012) and Irvine and Callison-Burch (2013), we use time-stamped web crawlsas well as interlingually linked Wikipedia docu-ments.
We use the time-stamped data to estimatetemporal similarity and the interlingual Wikipedialinks, which indicate documents about the sametopic written in different languages, to estimate3No dictionary was provided for Hindi.263topic similarity.
We use both datasets in combina-tion with a dictionary derived from the small par-allel corpora to estimate contextual similarity.3.2 Improving CoverageIn order to improve the coverage of our low re-source translation models, we use bilingual lexi-con induction techniques to learn translations forwords which appear in our test sets but not in ourtraining data (OOVs).
Bilingual lexicon inductionis the task of inducing pairs of words that are trans-lations of one another from monolingual or com-parable corpora.
Irvine and Callison-Burch (2013)use a diverse set of features estimated over compa-rable corpora and a small set of known translationsas supervision for training a discriminative classi-fier, which makes predictions (translation or not atranslation) on test set words paired with all pos-sible translations.
Possible translations are takenfrom the set of all target words appearing in thecomparable corpora.
Candidates are ranked ac-cording to their classification scores.
They achievevery good performance on the induction task itselfcompared with an unsupervised baseline that ag-gregates the same similarity features uniformly.
Inour setting, we have access to a small parallel cor-pus, which makes such a supervised approach tobilingual lexicon induction a natural choice.We use the framework described in Irvine andCallison-Burch (2013) directly, and further detailsmay be found there.
In particular, we use the samefeature set, which includes the temporal, contex-tual, topic, orthographic, and frequency similaritybetween a candidate translation pair.
We derivetranslations to serve as positive supervision fromour automatically aligned parallel text4 and, likethe prior work, use random word pairs as nega-tive supervision.
Figure 1 shows some examplesof Bengali words, their correct translations, andthe top-3 translations that this framework induces.In our initial experiments, we add the high-est ranked English candidate translation for eachsource language OOV to our phrase tables.
Be-cause all of the OOVs appear at least once in ourcomparable corpora,5 we are able to mine transla-tions for all of them.
Adding these translations bydefinition improves the coverage of our MT mod-els.
Then, in additional sets of experiments, we4GIZA++ intersection alignments over all training data.5The Post et al(2012) datasets are crowdsourced Englishtranslations of source Wikipedia text.
Using Wikipedia ascomparable corpora, we observe all OOVs at least once.Source Induced Translations Correct Translation???????????mathematicalmathematicallyequalganitikovabe?????functionfunctionfunctionsvariables?????
?madeinaugurationgoalearnedFigure 1: Examples of OOV Bengali words, our top-3ranked induced translations, and their correct translations.also induce translations for source language wordswhich are low frequency in the training data andsupplement our SMT models with top-k transla-tions, not just the highest ranked.3.3 Improving AccuracyIn order to improve the accuracy of our mod-els, we use comparable corpora to estimate ad-ditional features over the translation pairs in ourphrase tables and include those features in tuningand decoding.
This approach follows that of Kle-mentiev et al(2012).
We compute both phrasalfeatures and lexically smoothed features (usingword alignments, like the Moses lexical transla-tion probabilities) for all of the following exceptorthographic similarity, for which we only use lex-ically smoothed features,6 resulting in nine addi-tional features: temporal similarity based on time-stamped web crawls, contextual similarity basedon web crawls and Wikipedia (separately), ortho-graphic similarity using normalized edit distance,and topic similarity based on inter-lingually linkedWikipedia pages.
Our hope is that by adding a di-verse set of similarity features to the phrase tables,our models will better distinguish between goodand bad translation pairs, improving accuracy.4 Experiments4.1 Experimental setupWe use the data splits given by Post et al(2012)and, following that work, include the dictionariesin the training data and report results on the devtestset using case-insensitive BLEU and four refer-ences.
We use the Moses phrase-based MT frame-work (Koehn et al 2007).
For each language, weextract a phrase table with a phrase limit of seven.In order to make our results comparable to thoseof Post et al(2012), we follow that work and use6Because the words within a phrase pair are often re-ordered, phrase-level orthographic similarity is unreliable.264Language Top-1 Acc.
Top-10 Acc.Tamil 4.5 10.2Telugu 32.8 47.9Bengali 17.9 29.8Malayalam 12.9 23.0Hindi 44.3 57.6Urdu 16.1 33.8Table 3: Percent of word types in a held out portion of thetraining data which are translated correctly by our bilinguallexicon induction technique.
Evaluation is over the top-1 andtop-10 outputs in the ranked lists for each source word.the English side of the training data to train a lan-guage model.
Using a language model trained ona larger corpus (e.g.
the English side of our com-parable corpora) may yield better results, but suchan improvement is orthogonal to the focus of thiswork.
Throughout our experiments, we use thebatch version of MIRA (Cherry and Foster, 2012)for tuning the feature set.7 We rerun tuning forall experimental conditions and report results av-eraged over three tuning runs (Clark et al 2011).Our baseline uses the bilingually extractedphrase pairs and standard translation probabilityfeatures.
We supplement it with the top rankedtranslation for each OOV to improve coverage (+OOV Trans) and with additional features to im-prove accuracy (+Features).
In Section 4.2, wemake each modification separately and then to-gether.
Then we present additional experimentswhere we induce translations for low frequencywords, in addition to OOVs (4.3), append top-ktranslations (4.4), vary the amount of training dataused to induce the baseline model (4.5), and varythe amount of comparable corpora used to esti-mate features and induce translations (4.6).4.2 ResultsBefore presenting end-to-end MT results, we ex-amine the performance of the supervised bilinguallexicon induction technique that we use for trans-lating OOVs.
In Table 3, top-1 accuracy is the per-cent of source language words in a held out portionof the training data8 for which the highest rankedEnglish candidate is a correct translation.9 Perfor-mance is lowest for Tamil and highest for Hindi.For all languages, top-10 accuracy is much higherthan the top-1 accuracy.
In Section 4.4, we explore7We experimented with MERT and PRO as well but sawconsistently better baseline performance using batch MIRA.8Described in Section 3.2.
We retrain with all trainingdata for MT experiments.9Post et al(2012) gathered up to six translations for eachsource word, so some have multiple correct translationsappending the top-k translations for OOV words toour model instead of just the top-1.Table 4 shows our results adding OOV transla-tions, adding features, and then both.
Additionaltranslation features alone, which improve ourmodels?
accuracy, increase BLEU scores between0.18 (Bengali) and 0.60 (Malayalam) points.Adding OOV translations makes a big differ-ence for some languages, such as Bengali andUrdu, and almost no difference for others, likeMalayalam and Tamil.
The OOV rate (Table 1) islow in the Malayalam dataset and high in the Tamildataset.
However, as Table 3 shows, the translationinduction accuracy is low for both.
Since few ofthe supplemental translations are correct, we don?tobserve BLEU gains.
In contrast, induction ac-curacies for the other languages are higher, OOVrates are substantial, and we do observe moderateBLEU improvements by supplementing phrase ta-bles with OOV translations.In order to compute the potential BLEU gainsthat we could realize by correctly translating allOOV words (achieving 100% accuracy in Table3), we perform an oracle experiment.
We use au-tomatic word alignments over the test sets to iden-tify correct translations and append those to thephrase tables.10 The results, in Table 4, show pos-sible gains between 4.3 (Telugu and Bengali) and0 (Malayalam) BLEU points above the baseline.Not surprisingly, the possible gain for Malayalam,which has a very low OOV rate, is very low.
Our+OOV Trans.
model gains between 0% (Tamil)and 38% (Urdu) of the potential improvement.Using comparable corpora to improve both ac-curacy (+Features) and coverage (+OOV Trans.
)results in translations that are better than apply-ing either technique alone for five of the six lan-guages.
BLEU gains range from 0.48 (Bengali)to 1.39 (Urdu).
We attribute the particularly goodUrdu performance to the relatively large compa-rable corpora (Table 2).
As a result, we have al-ready begun to expand our web crawls for all lan-guages.
In Section 4.6, we present results varyingthe amount of Urdu-English comparable corporaused to induce translations and estimate additionalfeatures.Table 4 also shows the Hiero (Chiang, 2005)and SAMT (Zollmann and Venugopal, 2006) re-sults that Post et al(2012) report for the same10Because the automatic word alignments are noisy, thisoracle is conservative.265Tamil Telugu Bengali Malayalam Hindi UrduExperiment BLEU Diff.
BLEU Diff.
BLEU Diff.
BLEU Diff.
BLEU Diff.
BLEU Diff.Baseline 9.45 11.72 12.07 13.55 15.01 20.39+Features 9.77 +0.32 11.96 +0.24 12.25 +0.18 14.15 +0.60 15.34 +0.33 20.97 +0.58+OOV Trans.
9.45 0.00 12.20 +0.48 12.74 +0.67 13.65 +0.10 15.59 +0.58 21.30 +0.91+Feats & OOV 9.98 +0.53 12.25 +0.53 12.55 +0.48 14.18 +0.63 16.08 +1.07 21.78 +1.39OOV Oracle 12.32 +2.87 16.04 +4.32 16.41 +4.34 13.55 0.00 17.72 +2.71 22.80 2.41Hiero 9.81 12.46 12.72 13.72 15.53 19.53SAMT 9.85 12.61 13.53 14.28 17.29 20.99Table 4: BLEU performance gains that target coverage (+OOV Trans.)
and accuracy (+Features), and both (+Feats & OOV).OOV oracle uses OOV translations from automatic word alignments.
Hiero and SAMT results are reported in Post et al(2012).datasets.
Both syntax-based models outperformthe phrase-based MT baseline for each languageexcept Urdu, where the phrase-based model out-performs Hiero.
Here, we extend a phrase-basedrather than a syntax-based system because it issimpler.
However, our improvements may also ap-ply to syntactic models (future work).
Because ourefforts have focused on the accuracy and cover-age of translation pairs and have not addressed re-ordering or syntax, we expect that combining themwith an SAMT grammar will result in state-of-theart performance.4.3 Translations of Low Frequency WordsGiven the positive results in Section 4.2, we hy-pothesize that mining translations for low fre-quency words, in addition to OOV words, may im-prove accuracy.
For source words which only ap-pear a few times in the parallel training text, thebilingually extracted translations in the standardphrase table are likely to be inaccurate.
There-fore, we perform additional experiments varyingthe minimum source word training data frequencyfor which we induce additional translations.
Thatis, if freq(wsrc) ?
M , we induce a new transla-tion for it and include that translation in our phrasetable.
Note that in the results presented in Table 4,M = 0.
In these experiments, we include our ad-ditional phrase table features estimated over com-parable corpora and hope that these scores will as-sist the model in choosing among multiple trans-lation options for low frequency words, one ormore of which is extracted bilingually and one ofwhich is induced using comparable corpora.
Table5 shows the results when we vary M .
As before,we average BLEU scores over three tuning runs.In general, modest BLEU score gains are madeas we supplement our phrase-based models withinduced translations of low frequency words.
Thehighest performance is achieved when M is be-tween 5 and 50, depending on language.
TheLanguage Base.
M : trans added for freq(wsrc) ?
M0 1 5 10 25 50Tamil 9.5 10.0 9.9 10.2 10.2 9.9 10.2Telugu 11.7 12.3 12.2 12.3 12.4 12.3 11.9Bengali 12.1 12.6 12.8 13.0 12.9 13.1 13.0Malayalam 13.6 14.2 14.1 14.2 14.2 13.9 13.9Hindi 15.0 16.1 16.1 16.2 16.2 16.0 15.8Urdu 20.4 21.8 21.8 21.8 21.9 22.1 21.8Table 5: Varying minimum parallel training data frequencyof source words for which new translations are induced andincluded in the phrase-based model.
In all cases, the top-1induced translation is added to the phrase table and featuresestimated over comparable corpora are included (i.e.
+Feats& Trans model).largest gains are 0.5 and 0.3 BLEU points for Ben-gali and Urdu, respectively, at M = 25.
Thisis not surprising; we also saw the largest rela-tive gains for those two languages when we addedOOV translations to our baseline model.
With theaddition of low frequency translations, our highestperforming Urdu model achieves a BLEU scorethat is 1.7 points higher than the baseline.In different data conditions, inducing transla-tions for low frequency words may result in betteror worse performance.
For example, the size of thetraining set impacts the quality of automatic wordalignments, which in turn impacts the reliabilityof translations of low frequency words.
However,the experiments detailed here suggest that includ-ing induced translations of low frequency wordswill not hurt performance and may improve it.4.4 Appending Top-K TranslationsSo far we have only added the top-1 induced trans-lation for OOV and low frequency source words toour phrase-based model.
However, the bilinguallexicon induction results in Table 3 show that ac-curacies in the top-10 ranked translations are, onaverage, nearly twice the top-1 accuracies.
Here,we explore adding the top-k induced translations.We hope that our additional phrase table featuresestimated over comparable corpora will enable the266Language Base.
k: top-k translations added1 3 5 10 25Tamil 9.5 10.0 10.0 9.8 10.0 10.0Telugu 11.7 12.3 11.7 11.9 11.7 11.6Bengali 12.1 12.6 12.6 12.6 12.7 12.8Malayalam 13.6 14.2 14.2 14.2 14.2 14.1Hindi 15.0 16.1 16.0 15.9 15.9 15.9Urdu 20.4 21.8 21.8 21.7 21.5 21.6Table 6: Adding top-k induced translations for source lan-guage OOV words, varying k. Features estimated over com-parable corpora are included (i.e.
+Feats & Trans model).The highest BLEU score for each language is highlighted.
Inmany cases differences are less than 0.1 BLEU.decoder to correctly choose between the k trans-lation options.
We induce translations for OOVwords only (M = 0) and include all comparablecorpora features.Table 6 shows performance as we append thetop-k ranked translations for each OOV word andvary k. With the exception of Bengali, using ak greater than 1 does not increase performance.In the case of Bengali, and additional 0.2 BLEUis observed when the top-25 translations are ap-pended.
In contrast, we see performance decreasesubstantially for other languages (0.7 BLEU forTelugu and 0.2 for Urdu) when the top-25 trans-lations are used.
Therefore, we conclude that, ingeneral, the models do not sufficiently distinguishgood from bad translations when we append morethan just the top-1.
Although using a k greater than1 means that more correct translations are in thephrase table, it also increases the number of possi-ble outputs over which the decoder must search.4.5 Learning Curves over Parallel DataIn the experiments above, we only evaluated ourmethods for improving the accuracy and coverageof models trained on small amounts of bitext us-ing the full parallel training corpora released byPost et al(2012).
Here, we apply the same tech-niques but vary the amount of parallel data in orderto generate learning curves.
Figure 2 shows learn-ing cures for all six languages.
In all cases, resultsare averaged over three tuning runs.
We sampleboth parallel sentences and dictionary entries.All six learning curves show similar trends.
Inall experimental conditions, BLEU performanceincreases approximately linearly with the log ofthe amount of training data.
Additionally, supple-menting the baseline with OOV translations im-proves performance more than supplementing thebaseline with additional phrase table scores based5 10 20 50 100 20020.020.521.021.522.0Comparable Corpora (Millions of Tokens)BLEU ?
?
?
?
???Baseline+Trans.+Feats.+Trans.
& Feats.Figure 3: English to Urdu translation results using vary-ing amounts of comparable corpora to estimate features andinduce translations.on comparable corpora.
However, in most cases,supplementing the baseline with both translationsand features improves performance more than ei-ther alone.
Performance gains are greatest whenvery little training data is used.
The Urdu learningcurve shows the most gains as well as the clean-est trends across training data amounts.
As before,we attribute this to the relatively large comparablecorpora available for Urdu.4.6 Learning Curves over ComparableCorporaIn our final experiment, we consider the effect ofthe amount of comparable corpora that we useto estimate features and induce translations.
Wepresent learning curves for Urdu-English becausewe have the largest amount of comparable corporafor that pair.
We use the full amount of paral-lel data to train a baseline model, and then werandomly sample varying amounts of our Urdu-English comparable corpora.
Sampling is doneseparately for the web crawl and Wikipedia com-parable corpora.
Figure 3 shows the results.
Asbefore, results are averaged over three tuning runs.The phrase table features estimated over com-parable corpora improve end-to-end MT perfor-mance more with increasing amounts of compa-rable corpora.
In contrast, the amount of com-parable corpora used to induce OOV translationsdoes not impact the performance of the resultingMT system as much.
The difference may be due267500 1000 2000 5000 10000 5000005101520TeluguTraining DataBLEUl l ll ll ll ll Baseline+Trans.+Feats.+Trans.
& Feats.
(a) Telugu500 1000 2000 5000 10000 2000005101520BengaliTraining DataBLEUl lll ll ll Baseline+Trans.+Feats.+Trans.
& Feats.
(b) Bengali500 1000 2000 5000 20000 50000 20000005101520MalayalamTraining DataBLEUl ll l l llll ll Baseline+Trans.+Feats.+Trans.
& Feats.
(c) Malayalam5 0 1000 2000 5000 10000 5000005101520TamilTraining DataBLEUl l ll lll l ll Baseline+Trans.+Feats.+Trans.
& Feats.
(d) Tamil500 1000 2000 5000 10000 2000005101520HindiTraining DataBLEUll ll ll lll Baseline+Trans.+Feats.+Trans.
& Feats.
(e) Hindi500 1000 2000 5000 20000 5000005101520UrduTraining DataBLEUll lllllllll Baseline+Trans.+Feats.+Trans.
& Feats.
(f) UrduFigure 2: Comparison of learning curves over lines of parallel training data for four SMT systems: ourbaseline phrase-based model (baseline), model that supplements the baseline with translations of OOVwords induced using our supervised bilingual lexicon induction framework (+Trans), model that supple-ments the baseline with additional phrase table features estimated over comparable corpora (+Feats), anda system that supplements the baseline with both OOV translations and additional features (+Trans &Feats).268to the fact that data sparsity is always more of anissue when estimating features over phrase pairsthan when estimating features over word pairs be-cause phrases appear less frequently than wordsin monolingual corpora.
Our comparable cor-pora features are estimated over phrase pairs whiletranslations are only induced for OOV words, notphrases.
So, it makes sense that the former wouldbenefit more from larger comparable corpora.5 ConclusionAs Post et al(2012) showed, it is reasonableto assume a small parallel corpus for training anSMT model even in a low resource setting.
Wehave used comparable corpora to improve the ac-curacy and coverage of phrase-based MT modelsbuilt using small bilingual corpora for six low re-source languages.
We have shown that our meth-ods improve BLEU score performance indepen-dently and that their combined impact is nearly ad-ditive.
Additionally, our results show that addinginduced translations of low frequency words im-proves performance beyond what is achieved byinducing translations for OOVs alone.
Finally, ourresults show that our techniques improve relativeperformance most when very little parallel train-ing data is available.6 AcknowledgementsThis material is based on research sponsored byDARPA under contract HR0011-09-1-0044 andby the Johns Hopkins University Human Lan-guage Technology Center of Excellence.
Theviews and conclusions contained in this publica-tion are those of the authors and should not beinterpreted as representing official policies or en-dorsements of DARPA or the U.S. Government.ReferencesSadaf AbduI-Rauf and Holger Schwenk.
2009.
Onthe use of comparable corpora to improve smt per-formance.
In Proceedings of the Conference of theEuropean Association for Computational Linguis-tics (EACL).Vamshi Ambati.
2011.
Active Learning for MachineTranslation in Scarce Data Scenarios.
Ph.D. thesis,Carnegie Mellon University.Colin Cherry and George Foster.
2012.
Batch tuningstrategies for statistical machine translation.
In Pro-ceedings of the Conference of the North AmericanChapter of the Association for Computational Lin-guistics (NAACL).David Chiang.
2005.
A hierarchical phrase-basedmodel for statistical machine translation.
In Pro-ceedings of the Conference of the Association forComputational Linguistics (ACL).Jonathan H. Clark, Chris Dyer, Alon Lavie, andNoah A. Smith.
2011.
Better hypothesis testingfor statistical machine translation: controlling foroptimizer instability.
In Proceedings of the Confer-ence of the Association for Computational Linguis-tics (ACL).Hal Daume?, III and Jagadeesh Jagarlamudi.
2011.Domain adaptation for machine translation by min-ing unseen words.
In Proceedings of the Confer-ence of the Association for Computational Linguis-tics (ACL).Qing Dou and Kevin Knight.
2012.
Large scale deci-pherment for out-of-domain machine translation.
InProceedings of the Joint Conference on EmpiricalMethods in Natural Language Processing and Com-putational Natural Language Learning.Pascale Fung and Lo Yuen Yee.
1998.
An IR approachfor translating new words from nonparallel, compa-rable texts.
In Proceedings of the Conference of theAssociation for Computational Linguistics (ACL).Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,and Dan Klein.
2008.
Learning bilingual lexi-cons from monolingual corpora.
In Proceedings ofthe Conference of the Association for ComputationalLinguistics (ACL).Fei Huang, Ying Zhang, and Stephan Vogel.
2005.Mining key phrase translations from web cor-pora.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing(EMNLP).Ann Irvine and Chris Callison-Burch.
2013.
Su-pervised bilingual lexicon induction with multiplemonolingual signals.
In Proceedings of the Confer-ence of the North American Chapter of the Associa-tion for Computational Linguistics (NAACL).Alexandre Klementiev and Dan Roth.
2006.
Weaklysupervised named entity transliteration and discov-ery from multilingual comparable corpora.
In Pro-ceedings of the Conference of the Association forComputational Linguistics (ACL).Alex Klementiev, Ann Irvine, Chris Callison-Burch,and David Yarowsky.
2012.
Toward statistical ma-chine translation without parallel corpora.
In Pro-ceedings of the Conference of the European Associ-ation for Computational Linguistics (EACL).Philipp Koehn and Kevin Knight.
2002.
Learning atranslation lexicon from monolingual corpora.
InACL Workshop on Unsupervised Lexical Acquisi-tion.269Philipp Koehn, Franz Joseph Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Pro-ceedings of the Conference of the North AmericanChapter of the Association for Computational Lin-guistics (NAACL).Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: Opensource toolkit for statistical machine translation.
InProceedings of the Conference of the Association forComputational Linguistics (ACL).Prasanth Kolachina, Nicola Cancedda, Marc Dymet-man, and Sriram Venkatapathy.
2012.
Prediction oflearning curves in machine translation.
In Proceed-ings of the Conference of the Association for Com-putational Linguistics (ACL).Mausam, Stephen Soderland, Oren Etzioni, Daniel S.Weld, Kobi Reiter, Michael Skinner, Marcus Sam-mer, and Jeff Bilmes.
2010.
Panlingual lexicaltranslation via probabilistic inference.
Artificial In-telligence, 174:619?637, June.David Mimno, Hanna Wallach, Jason Naradowsky,David Smith, and Andrew McCallum.
2009.Polylingual topic models.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing (EMNLP).Christof Monz and Bonnie J. Dorr.
2005.
Iterativetranslation disambiguation for cross-language infor-mation retrieval.
In Proceedings of the Conferenceon Research and Developments in Information Re-trieval (SIGIR).Dragos Munteanu and Daniel Marcu.
2006.
Extractingparallel sub-sentential fragments from non-parallelcorpora.
In Proceedings of the Conference of theAssociation for Computational Linguistics (ACL).Malte Nuhn, Arne Mauser, and Hermann Ney.
2012.Deciphering foreign language by combining lan-guage models and context vectors.
In Proceedingsof the Conference of the Association for Computa-tional Linguistics (ACL).Matt Post, Chris Callison-Burch, and Miles Osborne.2012.
Constructing parallel corpora for six indianlanguages via crowdsourcing.
In Proceedings ofthe Workshop on Statistical Machine Translation(WMT).Reinhard Rapp.
1995.
Identifying word translationsin non-parallel texts.
In Proceedings of the Confer-ence of the Association for Computational Linguis-tics (ACL).Reinhard Rapp.
1999.
Automatic identification ofword translations from unrelated English and Ger-man corpora.
In Proceedings of the Conferenceof the Association for Computational Linguistics(ACL).Sujith Ravi and Kevin Knight.
2011.
Decipheringforeign language.
In Proceedings of the Confer-ence of the Association for Computational Linguis-tics (ACL).Charles Schafer and David Yarowsky.
2002.
Inducingtranslation lexicons via diverse similarity measuresand bridge languages.
In Proceedings of the Confer-ence on Natural Language Learning (CoNLL).Charles Schafer.
2006.
Translation Discovery UsingDiverse Similarity Measures.
Ph.D. thesis, JohnsHopkins University.Jason R. Smith, Chris Quirk, and Kristina Toutanova.2010.
Extracting parallel sentences from compara-ble corpora using document level alignment.
In Pro-ceedings of the Conference of the North AmericanChapter of the Association for Computational Lin-guistics (NAACL).Jason Smith, Herve Saint-Amand, Magdalena Pla-mada, Philipp Koehn, Chris Callison-Burch, andAdam Lopez.
2013.
Dirt cheap web-scale paral-lel text from the common crawl.
In Proceedings ofthe Conference of the Association for ComputationalLinguistics (ACL).Jakob Uszkoreit, Jay M. Ponte, Ashok C. Popat, andMoshe Dubiner.
2010.
Large scale parallel docu-ment mining for machine translation.
In Proceed-ings of the International Conference on Computa-tional Linguistics (COLING).Omar F. Zaidan and Chris Callison-Burch.
2011.Crowdsourcing translation: Professional qualityfrom non-professionals.
In Proceedings of the Con-ference of the Association for Computational Lin-guistics (ACL).Andreas Zollmann and Ashish Venugopal.
2006.
Syn-tax augmented machine translation via chart pars-ing.
In Proceedings of the Workshop on StatisticalMachine Translation (WMT).270
