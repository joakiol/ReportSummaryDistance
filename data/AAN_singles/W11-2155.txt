Proceedings of the 6th Workshop on Statistical Machine Translation, pages 447?451,Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational LinguisticsFactored Translation with Unsupervised Word ClustersChristian Rish?jCenter for Language TechnologyUniversity of Copenhagencrjensen@hum.ku.dkAnders S?gaardCenter for Language TechnologyUniversity of Copenhagensoegaard@hum.ku.dkAbstractUnsupervised word clustering algorithms ?which form word clusters based on a measure ofdistributional similarity ?
have proven to beuseful in providing beneficial features for var-ious natural language processing tasks involv-ing supervised learning.
This work explores theutility of such word clusters as factors in sta-tistical machine translation.Although some of the language pairs in thiswork clearly benefit from the factor augmen-tation, there is no consistent improvement intranslation accuracy across the board.
For alllanguage pairs, the word clusters clearly im-prove translation for some proportion of thesentences in the test set, but has a weak oreven detrimental effect on the rest.It is shown that if one could determine whetheror not to use a factor when translating a givensentence, rather substantial improvements inprecision could be achieved for all of the lan-guage pairs evaluated.
While such an ?oracle?method is not identified, evaluations indicatethat unsupervised word cluster are most bene-ficial in sentences without unknown words.1 Factored translationOne can go far in terms of translation quality withplenty of bilingual text and a translation model thatmaps small chunks of tokens as they appear in thesurface form, that is, the usual phrase-based sta-tistical machine translation model.
Yet even witha large parallel corpus, data sparsity is still an is-sue.
Factored translation models are an extension ofphrase-based models which allow integration of addi-tional word-level annotation into the model.
Operat-ing on more general representations, such as lemmasor some kind of stems, translation model can drawon richer statistics and to some degree offset the datasparsity problem.4.1.1 The Brown algorithmIn this thesis, we use the bottom-up agglomerative word clustering algorithm of(Brown et al, 1992) to derive a hierarchical clustering of words.
The input to thealgorithm is a text, which is a sequence of words w1, .
.
.
, wn.
The output from theclustering algorithm is a binary tree, in which the leaves of the tree are the words.We interpret each internal node as a cluster containing the words in that subtree.Initially, the algorithm starts with each word in its own cluster.
As long as thereare at least two clusters left, the algorithm merges the two clusters that maximizesthe quality of the resulting clustering (quality will be defined later).1 Note that thealgorithm generates a hard clustering?each word belongs to exactly one cluster.To define the quality of a clustering, we view the clustering in the context of a class-based bigram la guage model.
Given a clustering C that maps each word to a cluster,the class-based language model assigns a probability to the input text w1, .
.
.
, wn,where the maximum-likelihood estimate of the model parameters (estimated withempirical counts) are used.
We define the quality of the clustering C to be thelogarithm of this probability (see Figure 4-1 and Equation 4.1) normalized by thelength of the text.......c1 c2 c3 ci cnw1 w2 w3 wi wnP (ci|ci?1)P (wi|ci) ci = C(wi)Figure 4-1: The class-based bigram language model, which defines the quality of aclustering, represented as a Bayesian network.1We use the term clustering to refer to a set of clusters.44Figure 1: Bayesian network illustrating the class-based language model that is used to define th qual-ity of a clustering in the Brown algorithm [Liang,2005]2 Unsupervised word clustersUnsupervised word clusters owe their appeal perhapsmostly to the relative ease of obtaining them.
Ob-taining regular morphological, syntactic or seman-tic analyses for tokens in a text relies on some sortof tagger, either based on manually crafted rules ortrainable on an annotated corpus.
Both rule-craftingand corpus annotation are time-consuming and ex-pensive processes, and might not be feasible for asmall or resource-scarce language.For unsupervised word clusters, on the other hand,one merely needs a large amount of raw (unanno-tated) text and some processing power.
Such cluster-ing is thus particularly interesting for resource-scarcelanguages, and especially so if the clusters enable thetraining of more generalized translation models with-out more bilingual text.The independence of annotated corpora or hand-crafted rules make unsupervised clusters interestingfor languages rich in NLP resources too.
They of-fer a way to exploit vast amounts of raw, unanno-tated, monolingual text, in a manner akin to the waylanguage models profitably may be trained on vastamounts of raw monolingual text.With the broad coverage achievable from vastamounts of monolingual text, word clusters mighthelp alleviate the problem of unknown words intranslation.
It is imaginable that a word form oth-erwise unknown to the translation model belongs to447a known cluster.
Appropriate use of word clusters,coupled with a broad-coverage language model, couldmake it be possible for the translation model to ar-rive at the intended translation.In this work we use two unsupervised clustering al-gorithms: Brown and Unsupos.
Other clustering al-gorithms were on the drawing board as well, namelyembeddings from the Neural Language Model of Col-lobert and Weston [2008] and word representationsfrom random indexing (RI)1.
These, however, wereabandoned due to time constraints.2.1 The Brown algorithmThe bottom-up agglomerative algorithm of Brownet al [1992] processes a sequence of tokens and pro-duces a binary tree with tokens as leaf nodes.
Eachinternal node in the tree can be interpreted as a clus-ter containing the tokens on the leaf nodes of thatsubtree.
The clustering produced is thus a hierarchi-cal clustering.Very briefly, the algorithm proceeds by first as-signing every token to its own cluster, and then iter-atively merges the two clusters that maximises thequality of the resulting clustering, where the qualityof a clustering is defined in terms of a class-basedlanguage model (figure 1).Note that this algorithm produces a hard clus-tering, in the sense that it assigns each token to asingle cluster.
From a semantic perspective, thereare homographic words whose underlying senses areconceptually and possibly syntactically distinct, andwhose cluster-tag intuitively should depend on theiruse in running text.
The clustering obtained from theBrown algorithm does not accommodate this wish.We use the implementation2 of Liang [2005].2.2 jUnsuposContrary to the hard clustering of the Brown algo-rithm, the jUnsupos algorithm of Biemann [2006]emits a Viterbi tagger which is sensitive to the con-text of a token in running text.
Thus, word forms canbelong to more than a single cluster, and such wordforms ?
which are considered ambiguous by the al-gorithm ?
will be assigned to a cluster dependingon their context.In a coarse outline, the algorithm works by firstinducing a distributional clustering for unambiguoushigh-frequency tokens, as well as a co-occurrence-based clustering for less common tokens.
The twopartly overlapping clusterings are then combined to1https://github.com/turian/random-indexing-wordrepresentations2Available at http://www.cs.berkeley.edu/~pliang/software/100001001 immediate urgent ongoing absolute ex-traordinary exceptional ideological un-precedented appalling overwhelming al-leged automatic [...]11111100111111110 worried concerned skepticalunhappy uneasy reticent unsure per-plexed excited apprehensive legion un-concerned [...]111111100010001 cover include involve excludeconfuse encompass designate precludetranscend duplicate defy precede [...]1111111000000 encourage promote protect defendsafeguard restore assist preserve coordi-nate convince destroy integrate [...]0111000 china russia iran israel turkey ukraine in-dia japan pakistan georgia serbia europol[...]1000110010 waste water drugs land fish materialmeat profit alcohol forest blood chemi-cals [...]Figure 2: Exemplars of word clusters obtained usingthe Brown algorithm (C=1000), showing the 12 mostfrequent tokens per clusterproduce a lexicon with derived syntactic categoriesand word forms.2.3 Cluster count and complexionA reasonable question when faced with the task ofinducing word clusters in an unsupervised manneris: How many clusters to produce?
This question ispresumably closely intertwined with the question ofwhat sort of beast a cluster obtained in this man-ner can be expected to be.
Would a clustering witharound 30-90 clusters correspond somewhat closelyto an ordinary part-of-speech tag-set for the givenlanguage?Looking at the handful of exemplar clusters shownin figure 2, which were obtained with the Brown algo-rithm (using a cluster count of 1000), we cautiouslynote some apparent patterns.?
The clusters appear to be subsets of the cluster-ing implied by conventional part-of-speech tags:The first two consist of adjectives (including therather ambiguous form legion), the next two(transitive) verbs and the final two nouns.?
Syntactically, members of the two apparent verb448clusters seem to consist of verbs in their infini-tive (or plurally inflected) form.?
From a quasi-semantic perspective, the last clus-ter appears to consist of nouns for corporealgoods (as apposed to immaterial things).?
While most exemplars from the second-last clus-ter are countries, all of the shown forms can besaid to be proper nouns.Note that only the 12 most frequent forms from eachcluster are displayed, the apparent patterns shouldbe taken with a pinch of salt.
Although the qualitiessuggested can be expected to relate to distributionalproperties that the clusters reflect, exceptional mem-bers are perhaps to be expected.In the present work, we went with the pre-trainedmodels for jUnsupos3, which have the followingcharacteristics4:Lang Corpus # Sents # Tagscs LCC 4 M 539de Wortschatz 40 M 396en Medline 2004 34 M 480es LCC 4.5 M 415fr LCC 3 M 359For the Brown algorithm, we are contrasting clus-ter count choices of 320 and 1000, based on reportsof other successful applications [Turian et al, 2010]5,with clustering models trained on monolingual datafrom the Europarl corpus and the News Commentarycorpus.3 Experimental setupThe baseline systems were set up in accordance withthe guidelines on the shared task website.
That is,they were trained with grow-diag-final-and wordalignment heuristics and msd-bidirectional-fe re-ordering.Translation models were trained on a concatena-tion of the Europarl and News Commentary corpora,which were first tokenized, then filtered to sentencelengths of up to 40 tokens, and finally lowercased.5-gram language models were built usingngram-count on a concatenation of the Eu-roparl corpora and the News Commentary corpora.3As available at http://wortschatz.uni-leipzig.de/~cbiemann/software/unsupos.html4LCC refers to the Leipzig Corpora, available athttp://corpora.uni-leipzig.de/.
Wortschatz refers tohttp://www.wortschatz.uni-leipzig.de/.
Medline is avail-able at http://www.nlm.nih.gov/mesh/filelist.html.5A planned evaluation of a cluster count of 3200 was aban-doned due to time constraintsFor the unsupervised word clusters, 5-gram languagemodels were used as well, built from tagged versionsof the same corpora.
All language models werebinarised and loaded using KenLM [Heafield, 2011].Minimum error rate training (MERT) was used tooptimise parameters on both baseline and factoredmodels against the 2008 news test set, as suggestedon the shared task website6.All phrase tables were filtered and binarised forthe development and testing corpora during tuningand testing, respectively.Seeing that the preparation of the raw corpora,word clustering models, factored corpora, languagemodels, as well as training, optimization and eval-uation of the various models was a rather involved,yet repetitive process, we took a stab at making aGNU Makefile-based approach for automated han-dling (and parallelisation) of the whole dependencygraph of subtasks.
The ongoing effort, which sharessome aspirations and abilities with the recently an-nounced Experiment Management System (EMS), ispublicly available7.4 ResultsTable 1a lists BLEU scores for adding jUnsupos tags(uPOS), Brown clusters with 320 clusters (C320) orBrown clusters with 1000 clusters (C1000) as eitheran alignment factor, a two-sided translation factor ora source-sided translation factor.Although using Brown clusters (C1000) as a two-sided translation factor improves BLEU scores forsome language pairs, most notably en-cs, en-de andcs-en, no clear across-the-board benefit is seen.4.1 Oracle scoresBased on the hypothesis that the factorisations arebeneficial when translation some sentences, and notwhen translating others, we completed an oracle-based evaluation, in which we assume to know a pri-ori whether to use the factored model for translatinga given sentence, or just go with the baseline, unfac-tored model.
In reality, we don?t have such an or-acle method for arbitrary sentences, but when deal-ing with the shared task test set (or other corporafor which we have reference translations), it was easyenough to check per-sentence BLEU scores for eachmodel and make the decision based on a comparison.Table 1b lists BLEU scores obtainable with eachfactor configuration given such an oracle method.
Inthis scenario, most factored models beat the baseline,indicating that the factorisations are beneficial forcertain sentences, and detrimental for others.6http://www.statmt.org/wmt11/translation-task.html7At https://gibhub.com/crishoj/factored449Pair Baseline Alignment factor Two-sided translation Source-sided transl.
BestC1000 C320 uPOS C1000 C320 uPOS C1000 C320 uPOS ?
%cs-en 18.18 17.77 17.19 13.54 18.59 18.36 17.50 18.19 18.19 17.59 0.41 2.3%de-en 18.45 17.94 17.57 16.36 18.56 18.42 17.93 18.12 18.12 17.86 0.11 0.6%en-cs 11.85 11.82 11.61 9.75 12.73 12.28 10.94 11.92 11.92 11.85 0.88 7.4%en-de 13.27 12.90 12.83 11.98 13.81 13.84 13.19 12.94 12.94 12.92 0.57 4.3%en-es 28.08 27.10 26.52 24.90 28.40 28.16 27.50 27.31 27.31 27.19 0.32 1.1%en-fr 25.90 24.60 23.98 21.85 25.89 20.59 24.16 24.89 24.89 24.74 ?
?es-en 26.70 24.87 24.71 23.92 25.76 25.96 25.40 24.92 24.92 24.92 ?
?fr-en 24.73 23.18 23.13 21.76 24.01 22.86 23.23 23.37 23.37 23.04 ?
?
(a) BLEU scores for factor configurations in comparison to the unfactored baselinePair Baseline Alignment factor Two-sided translation Source-sided transl.
BestC1000 C320 uPOS C1000 C320 uPOS C1000 C320 uPOS ?
%cs-en 18.18 19.93 19.81 19.19 20.01 20.00 19.83 19.58 19.58 19.63 1.83 10.1%de-en 18.45 20.06 20.00 19.75 20.28 20.26 20.15 19.84 19.84 19.90 1.83 9.9%en-cs 11.85 13.18 13.14 12.81 13.77 13.58 12.98 12.83 12.83 12.93 1.92 16.2%en-de 13.27 14.56 14.60 14.36 14.98 15.10 14.81 14.21 14.21 14.28 1.83 13.8%en-es 28.08 29.70 29.50 29.17 30.33 30.2 30.00 29.54 29.54 29.56 2.25 8.0%en-fr 25.90 27.34 27.22 26.90 27.84 26.98 27.32 27.15 27.15 27.16 1.94 7.5%es-en 26.70 27.83 27.81 27.74 28.16 28.20 28.06 27.64 27.64 27.73 1.50 5.6%fr-en 24.73 25.86 25.95 25.83 26.16 26.31 26.05 25.66 25.66 25.69 1.58 6.4%(b) BLEU scores with an oracle-directed, per-sentence selective usage of either the baseline or the factored modelTable 1: BLEU scores when using Brown Clusters with granularity 1000 (C1000), granularity 320 (C320)and unsupervised part-of-speech tags (uPOS) as either an added alignment factor, a two-sided translationfactor or a source-sided translation factorPair Baseline Oracle Abs.
?
Rel.
%cs-en 18.18 22.60 4.42 24.3%de-en 18.45 22.42 3.97 21.5%en-cs 11.85 15.89 4.04 34.1%en-de 13.27 17.16 3.89 29.3%en-es 28.08 32.52 4.44 15.8%en-fr 25.90 30.07 4.17 16.1%es-en 26.70 30.22 3.52 13.2%fr-en 24.73 28.67 3.94 15.9%Table 2: BLEU scores under the assumption of anoracle function indicating the optimal factor config-uration for each sentence4.2 Combined oracle scoresImagine another oracle function, which would notsimply determine whether to prefer a given factoredmodel over the baseline for a given sentence, butinstead indicate which of several possible factoredmodels to use when translating a given sentence.BLEU scores obtainable under the assumption ofsuch a combined oracle function are listed in table 2.As was the case for the individual factored models(table 1a), en-cs, en-de and cs-en see the largest ben-efits over the baselines.These oracle scores are obviously an idealised case.They indicate an upper bound that one could seek toapproximate by constructing an appropriate oraclefunction.4.3 Unknown wordsIn section 2 it was hypothesised that word clus-ters are potentially beneficial in translating sentenceswith unknown words ?
that is, word forms whichwere not seen in any aligned sentences (but whichmay belong to a word cluster known by the transla-tion model).With this hypothesis in mind, we would like to450Pair Sentences Baseline C1000 Rel.
%cs-en 1955 65% 17.63 17.70 0.4%de-en 1925 64% 17.84 17.56 -1.6%en-cs 1583 53% 11.85 12.63 6.6%en-de 1395 46% 13.65 13.47 -1.3%en-es 1327 44% 27.77 27.97 0.7%en-fr 1369 46% 25.43 25.11 -1.3%es-en 1316 44% 26.43 25.41 -3.9%fr-en 1423 47% 24.20 23.56 -2.6%Avg.
1537 51% 20.60 20.43 -0.4%(a) BLEU scores for sentences with unknown wordsPair Sentences Baseline C1000 Rel.
%cs-en 1048 35% 19.63 20.77 5.8%de-en 1078 36% 20.03 21.24 6.0%en-cs 1420 47% 11.85 12.90 8.9%en-de 1608 54% 12.97 14.22 9.6%en-es 1676 56% 28.41 28.88 1.7%en-fr 1634 54% 26.46 26.81 1.3%es-en 1687 56% 27.01 26.15 -3.2%fr-en 1580 53% 25.40 24.58 -3.2%Avg.
1466 49% 21.47 21.94 3.4%(b) BLEU scores for sentences with no unknown wordsTable 3: BLEU scores for the best overall factorisa-tion, Brown clusters (C=1000) as a two-sided trans-lation factor, on sentences with (table 3a) and with-out (table 3b) unknown wordssee how the factored models fare in comparison tothe unfactored baselines, specifically for those sen-tences containing unknown words, and for the rest(sentences without unknown words).
This targetedevaluation was done using the best overall factor con-figuration: Brown clusters (C=1000) as a two-sidedtranslation factor.The results are shown in tables 3a and 3b.
Onaverage (across language paris), 51% test set sen-tences contain at least 1 unknown word.
Contraryto what might be expected, the factorisation seemsto be most beneficial for sentences with all knownwords (3.4% improvement in BLEU score on aver-age).
For sentences with unknown words, the effectis weak or detrimental (except for en-cs), averaginga slight decrease (-0.4%) in BLEU score across thelanguage pairs.The lack of benefit for sentences with unknownwords is likely due to the fact that no additionalmonolingual data was used to make the Brown clus-ters for this experiment.
In other words, there isno chance of knowing the Brown cluster for an un-known word.
Furthermore, we assume that gains forsentences with unknown words are more likely witha factorisation that includes an alternative decodingpath for word clusters8.5 Conclusions and future workIn this work we have explored the utility of three un-supervised word clusterings as either an alignmentfactor, a two-sided translation factor or a source-sided translation factor.Although no across-the-board benefit was seen, itwas evident that the factorisations help in translatingsome proportion of the test set sentences.
Being ableto determine for which sentences to use a factoredmodel is clearly desirable.Overall, the single most beneficial of the factorconfigurations explored was Brown clusters with agranularity of 1000, as a two-sided translation factor.A more detailed evaluation of the effects of differentcluster sizes, as well as using clusters induced frommore text, would be interesting in a follow-up study.Using clusters in some more interesting factorconfigurations, particularly in alternative decodingpaths, is still pending.ReferencesC.
Biemann.
Unsupervised part-of-speech tagging em-ploying efficient graph clustering.
In Proceedings ofthe 21st International Conference on computationalLinguistics and 44th Annual Meeting of the Associa-tion for Computational Linguistics: Student ResearchWorkshop, pages 7?12, 2006.P.
F Brown, V. J.D Pietra, P. V deSouza, J.
C Lai, andR.
L Mercer.
Class-based n-gram models of naturallanguage.
Computational linguistics, 18(4):467?479,1992.R.
Collobert and J. Weston.
A unified architecture fornatural language processing: Deep neural networkswith multitask learning.
In Proceedings of the 25thinternational conference on Machine learning, page160?167, 2008.K.
Heafield.
KenLM: faster and smaller language modelqueries.
In Proceedings of the Sixth Workshop onStatistical Machine Translation, Edinburgh, UK, July2011.
Association for Computational Linguistics.P.
Liang.
Semi-supervised learning for natural language.PhD thesis, Massachusetts Institute of Technology,2005.J.
Turian, L. Ratinov, and Y. Bengio.
Word repre-sentations: A simple and general method for semi-supervised learning.
In Proceedings of the 48th AnnualMeeting of the Association for Computational Linguis-tics, page 384?394, 2010.8Evaluation of factor configurations with alternative de-coding paths were abandoned due to limited computationalresources and initially discouraging results451
