Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 955?964,Honolulu, October 2008. c?2008 Association for Computational LinguisticsAcquiring Domain-Specific Dialog Information from Task-OrientedHuman-Human Interaction through an Unsupervised LearningAnanlada Chotimongkol Alexander I. RudnickyLanguage Technologies Institute Language Technologies InstituteCarnegie Mellon University Carnegie Mellon UniversityPittsburgh, PA 15213, USA Pittsburgh, PA 15213, USAananlada@cs.cmu.edu air@cs.cmu.eduAbstractWe describe an approach for acquiring thedomain-specific dialog knowledge required toconfigure a task-oriented dialog system thatuses human-human interaction data.
The keyaspects of this problem are the design of a di-alog information representation and a learningapproach that supports capture of domain in-formation from in-domain dialogs.
Torepresent a dialog for a learning purpose, webased our representation, the form-based di-alog structure representation, on an observa-ble structure.
We show that this representationis sufficient for modeling phenomena that oc-cur regularly in several dissimilar task-oriented domains, including information-access and problem-solving.
With the goal ofultimately reducing human annotation effort,we examine the use of unsupervised learningtechniques in acquiring the components of theform-based representation (i.e.
task, subtask,and concept).
These techniques include statis-tical word clustering based on mutual infor-mation and Kullback-Liebler distance,TextTiling, HMM-based segmentation, andbisecting K-mean document clustering.
Withsome modifications to make these algorithmsmore suitable for inferring the structure of aspoken dialog, the unsupervised learning algo-rithms show promise.1 IntroductionIn recent dialog management frameworks, such asRavenClaw (Bohus and Rudnicky, 2003) and Col-lagen (Rich et al, 2001), domain-dependent com-ponents of a dialog manager are clearly separatedfrom domain-independent components.
This sepa-ration allows rapid development of a dialog man-agement module in a new task-oriented domain asdialog system developers can focus only on speci-fying domain-specific dialog information (e.g.
theDialog Task Specification in RavenClaw and TaskModels in Collagen) while general dialog beha-viors (e.g.
turn-taking, confirmation mechanism,and generic help) are provided by the framework.For task-oriented domains, the domain-specificdialog information is equivalent to task-specificinformation.
Examples of the task-specific infor-mation are steps in a task and domain keywords.Specifying task-specific knowledge by hand isstill a time consuming process (Feng et al, 2003).Furthermore, the hand-crafted knowledge may notreflect users?
perceptions of a task (Yankelovich,1997).
To reduce the subjectivity of system devel-opers, recorded conversations of humans perform-ing a similar task as a target dialog system havebeen used to help the developers design the taskspecification.
Nevertheless, analyzing a corpus ofdialogs by hand requires a great deal of human ef-fort (Bangalore et al, 2006).
This paper investi-gates the feasibility of automating this dialoganalysis process through a machine-learning ap-proach.
By inferring the task-specific dialog in-formation automatically from human-humaninteraction data, the knowledge engineering effortcould be reduced as the developers need to onlyrevise learned information rather than analyzing alarge amount of data.Acquiring the task-specific knowledge from acorpus of human-human dialogs is considered aknowledge acquisition process, where the targettask structure has not yet been specified but will beexplored from data before a dialog system is built.This is contrasted with a dialog structure recogni-tion process (Alexandersson and Reithinger, 1997;955Bangalore et al, 2006; Hardy et al, 2004), wherepre-specified dialog structure components are rec-ognized as a dialog progresses.We use an unsupervised learning approach inour knowledge acquisition process as it can freelyexplore the structure in the data without any influ-ence from human supervision.
Woszczyna andWaibel (1994) showed that when modeling a di-alog state transition diagram from data an unsuper-vised approach outperformed a supervised one as itbetter reflects the characteristic of the data.
It isalso interesting to see how well a machine-learningapproach can perform on the problem of task-specific knowledge acquisition when no assump-tion about the domain is made and no prior know-ledge is used.Examination of task-oriented human-human di-alogs show that task-specific information can beobserved in dialog transcription; therefore, itshould be feasible to be infer it through an unsu-pervised learning approach.
Figure 1 (a) shows adialog in an air travel domain.
This dialog is orga-nized into three parts according to the three steps(i.e.
reserve a flight, reserve a car, reserve a hotel)required to accomplish the task, creating a travelitinerary.
Domain keywords (highlighted in bold)required to accomplish each step are clearly com-municated.To infer task-specific knowledge from data us-ing an unsupervised learning approach, two prob-lems need to be addressed: 1) choosing anappropriate dialog representation that captures ob-servable task-specific knowledge in a dialog, and2) developing an unsupervised learning approachthat infers the task-specific knowledge modeled bythis representation from in-domain human-humandialogs.
The first problem is discussed in Section 3where a form-based dialog structure representa-tion is proposed.
After describing the definition ofeach component in the form-based dialog structurerepresentation, examples of how a domain expertmodels the task-specific information in a dialogwith the form-based representation are given Sec-tion 3.1.
Then the annotation experiment whichwas used to verify that the form-based representa-tion can be understood and applied by other humanannotators is discussed in Section 3.2.
For thesecond problem, we modify existing unsupervisedlearning approaches to make them suitable for in-ferring the structure of a spoken dialog.
Section 4describes these modifications and their perfor-mances when inferring the components of theform-based dialog structure representation frominteraction data.Figure 1: An example of a dialog in the air travel domain and its corresponding form-based representation(d)(b)(c)Form: flight reservationFlightInfo:FlightInfo:Fare:PassengerName:PaymentMethod:Form: hotel reservationHotelInfo:PassengerName:PaymentMethod:Form: car reservationCarInfo:PassengerName:PaymentMethod:Client   1:  I?d like to fly to Houston TexasAgent  2:  And departing Pittsburgh on what date?Client:  3: Departing on February twentiethAgent  4: What time would you like to depart Pittsburgh?Client   5: Seven a.m.Agent  6: The only non-stop flight I have would be on Continental Air-lines that?s at six thirty a.m. arrive Houston at eight fiftyClient   7: That?s okay I will take thatAgent  8: And what day would you be returning?Client   9: On Monday February twenty third...Agent  16:  Do you need a car?Client  17:  YeahAgent  18: The least expensive rate I have is Thrifty rental car for twen-ty three ninety a dayClient  19:  OkayAgent  20:  Would you like me to book that car for you?Client   21:  YesAgent  22:  Okay and would you need a hotel while you're in Houston?Client  23:  YesAgent  24:  And where at in Houston?Client  25:  Downtown...reserveaflightreserveacarreserveahotelAction: make_a_car _reservationAction: make_a_flight _reservationAction: make_a_hotel _reservation(a)9562 Related WorkAutomatic task-specific knowledge acquisition forconfiguring a dialog system is a relatively new re-search area.
Supervised learning approaches wereused to acquire a task model for a collaborativeagent (Garland et al, 2001) and task-specific in-formation for a customer care service (Feng et al,2003).
These supervised algorithms were trainedon rich knowledge sources (examples described ina specific annotation language and a well-organized website respectively) annotated by do-main experts.
In contrast, the unsupervised concep-tual clustering algorithm in DIA-MOLE (M?ller,1998) requires no additional human annotation toinfer a set of domain-specific dialog acts from in-domain dialogs.
The motivation behind the use ofan unsupervised approach is similar to ours, to re-duce human effort in creating a new dialog system.3 Form-based Dialog Structure Represen-tationMany models have been proposed to account forthe structure of a human-human conversation.Many such models focus on other aspects of a di-alog such as coordinated activities, i.e.
turn-takingand grounding, (Traum and Hinkelman, 1992) andregular patterns in the dialog (Carletta et al, 1997)rather than the domain-specific information com-municated by participants.
More complicated di-alog representations (Grosz and Sidner, 1986;Litman and Allen, 1987) model several aspects ofa dialog including domain-specific information.However, additional components in these models,such as beliefs and intentions, are difficult to ob-serve directly from a conversation and, as for thecurrent technology, may not be learnable throughan unsupervised learning approach.Since the task-specific information that wewould like to model will be used for configuring adialog system, we can view this information from adialog system perspective.
Our dialog representa-tion is based on form, a data representation used ina form-based (or frame-based) dialog system.
Aform is a simple representation that captures neces-sary task-specific information communicatedthrough dialog.
This information is observablefrom dialog transcription (see below) and thuscould be inferred through an unsupervised learningapproach.Typically, a form corresponds to a databasequery form while slots in the form represent searchcriteria.
Nevertheless, a form can represent relatedpieces of information required to perform any do-main action not just a database query action.
Withthis more general definition of a form, a form-based dialog structure representation can be ap-plied to various types of task-oriented domainswhere dialog participants have to gather pieces ofinformation, analogous to search criteria, throughdialog in order to perform domain actions that ful-fill a dialog goal.
Chotimongkol (2008) providedexamples of these domains, for instance, meeting(Banerjee and Rudnicky, 2006) and flight simula-tion control (Gorman et al, 2003).In the form-based dialog structure representa-tion, task-specific information in each dialog isorganized into a three-level structure of concept,subtask and task.
A concept is a word or a group ofwords which captures a piece of information re-quired to perform a domain action.
A subtask is asubset of a dialog which contains sufficient con-cepts to execute a domain action that advances adialog toward its goal.
A task is a subset of a di-alog (usually the entire dialog) which contains allthe subtasks that belong to the same goal.
A sub-task can also be considered as a step in a task.
Interms of representation, a task is represented by aset of forms, one for each of its subtasks.
A con-cept is a slot in a form.To model the structure of a dialog in a new do-main with the form-based dialog structure repre-sentation, a list of tasks, subtasks, and concepts inthat domain has to be specified.
This list is consi-dered a domain-specific tagset.
The form-baseddialog structure framework only provides the defi-nitions of these components (i.e.
task, subtask, andconcept), which can be regarded as meta-tags andare domain-independent.
A list of tasks, subtasks,and concepts can be identified manually as shownin Section 3.1 or automatically through a machine-learning approach as discussed in Section 4.
Sec-tion 3.1 illustrates how a domain expert models thetask-specific information in two task-oriented do-mains, air travel planning (information-accessing)and map reading (problem-solving), with the form-based representation.
These examples also showthat the form-based dialog structure representation957is sufficient for modeling task-specific informationin dissimilar domains.Nonetheless, by focusing on observable task-specific information and describing this informa-tion using a simple model, the form-based dialogstructure representation cannot model the informa-tion that is not clearly expressed in a dialog.
Ex-ample of such information in an air travel domainis the pickup date of a car rental which may not bediscussed in a dialog as it can be inferred from thearrival date of the corresponding flight.
Further-more, the form-based representation is not wellsuited for modeling a complex dialog that has adynamic structure such as a tutoring dialog.3.1 Dialog Structure Modeling ExamplesFigure 1 illustrates how a dialog in the air traveldomain (Eskenazi et al, 1999) can be representedwith the form-based dialog structure representa-tion.
A dialog in this domain usually has a singlegoal, to create an air-travel itinerary which mayinclude hotel and car reservations.
Thus, the entiredialog corresponds to one task.
The dialog in Fig-ure 1 (a) contains three subtasks, one for eachmake_?_reservation action.
The forms thatrepresent these subtasks are shown in Figure 1 (b)?
(d).
Each form contains a set of concepts neces-sary for making the corresponding reservation.
Fora display purpose, the values of these slots areomitted.A subtask can be further decomposed.
For ex-ample, to reserve a round trip ticket, two databaselookup actions, one for each leg, are required.
Areserve_flight subtask in Figure 1 is decomposedinto two query_flight_info subtasks.
The corres-ponding forms of these subtasks are illustrated inFigure 2.
Each FlighInfo concept in the flight res-ervation form is a result of a database lookup ac-tion that corresponds to each flight query form.Figure 2: An example of subtask decompositionFigure 3 show a dialog in the map reading do-main (Anderson et al, 1991) and its correspondingform-based dialog structure representation.
Thegoal of a dialog in this domain is to have a routefollower draw a route on his/her map according toa description given by a route giver.
Since drawingan entire route involves several drawing strokes, adraw_a_route task is divided into severaldraw_a_segment subtasks, one for each drawingaction.
This action required a set of concepts thatdescribe a segment as shown in a segment descrip-tion form.
Since the landmarks on the giver?s mapcan be different from those in the follower?s map,the participants have to explicitly define the Loca-tion of a mismatched Landmark before using it ina segment description.
In this case grounding be-comes another subtask and can be represented by aform.
This type of grounding is not necessary inthe air travel domain.Figure 3: An example of a dialog in the map reading domain and its corresponding form-based representation?Giver 3: right, below the start do you havea missionary camp?Follower 4: yeah.Giver 5: okay, well if you take it from thestart just run horizontally.Follower 6: uh-huh.Giver 7: to the left for about an inch.Follower 8: right.Giver 9: then go down along the side ofthe missionary camp.
?.Form: groundingLandmark: missionary campLocation: below the startForm: segment descriptionStartLocation: the startDirection: leftDistance: an inchEndLocation:draw_a_segmentgroundingAction:define_a_landmarkAction:drawingForm: flight queryDepartCity: HoustonArriveCity: PittsburghDepartDate: MondayFebruary twenty thirdDepartTime: five p.m.Form: flight queryDepartCity: PittsburghArriveCity: HoustonArriveState: TexasDepartDate: FebruarytwentiethDepartTime: seven a.m.Form: flight reservationFlightInfo:Airline: ContinentalDepartTime: six thirty a.m.ArriveCity: HoustonArriveTime: eight fiftyFlightInfo:Airline: ContinentalDepartCity: HoustonDepartTime: six forty p.m.ArriveCity: PittsburghArriveTime: ten twenty p.m.Fare: four hundred dollarsName:PaymentMethod:9583.2 Annotation ExperimentThe goal of this annotation experiment is to verifythat the form-based dialog structure framework canbe understood by human annotators other than itsdevelopers, and that they can consistently apply theframework to model task-specific information in adialog.
In this experiment, each annotator had todesign a form-based dialog structure representationfor a given task-oriented domain by specifying ahierarchical structure of tasks, sub-tasks and con-cepts in that domain.
Note that we are interested inthe process of designing a domain-specific tagsetfrom the definitions of task, subtask, and conceptprovided by the framework, not in the process ofusing an existing tagset to annotate data (see forexample (Carletta et al, 1997)).
The description ofthe framework is provided in annotation guidelinesalong with examples from the domains that werenot used in the experiment.The experimental procedure is as follows: thesubjects first developed their own tagset accordingto the guidelines by analyzing a set of in-domaindialogs, and then annotate those dialogs with thetagset they had designed.
To obtain enough anno-tated instances for each dialog structure componentand to make the annotation simple, the dialogstructure annotation part of the experiment wasdivided into two sub-parts: concept annotation andtask/sub-task annotation.
Two domains were usedin the experiment, air travel planning and mapreading.
Four subjects were assigned to each do-main.
None had used the scheme previously.
Theaverage number of tags that each subject annotatedis shown in the first row of Table 1.Since some variations in tagset designs are ac-ceptable as long as they conform to the guidelines,each subject?s annotation is judged against theguidelines rather than one specific reference anno-tation.
An annotation instance is marked as incor-rect only when it does not conform to theguidelines.
Each subject?s annotation was eva-luated by both a coding scheme expert and by oth-er subjects.
Accuracy is computed from theexpert?s judgment while acceptability is computedfrom peers?
judgments.
Acceptability scores shownin Table 1 were averaged from all other subjects inthe same group.
Please note that the result pre-sented in this table should not be compared to theresults from machine-learning approaches pre-sented in Table 2 and Table 3 as the evaluationprocedures and data sets are different.MeasureAir Travel Map ReadingC T C TNumber of tags 178.8 50.5 347.8 60.8Accuracy (%) 96.5 89.7 89.0 65.2Acceptability (%) 95.6 81.1 94.9 84.5Table 1: Accuracy and acceptability on concept annota-tion (C), and task/subtask annotation (T)Both accuracy and acceptability are high for allannotation tasks except for the accuracy oftask/subtask annotation in the map reading domain.Most of the errors come from the annotation of thegrounding subtasks.
Since its corresponding ac-tion is quite difficult to observe, subjects may nothave a concrete definition of grounding and weremore likely to produce errors.
In addition, theywere less critical when judging other subjects?
an-notations.
Consistency in applying the form-baseddialog structure representation shows that the re-presentation is unambiguous and could potentiallybe identified through a machine-learning approach.When comparing among components, conceptswere annotated more consistently than tasks andsubtasks in terms of both accuracy and acceptabili-ty.
One possible reason is that, a concept is easierto observe as its unit is smaller than a task or a sub-task.
Moreover, dialog participants have to clearlycommunicate the concepts in order to execute adomain action.
The subjects usually agreed ontasks and top-level subtasks, but did not quiteagree on low-level subtasks.
The low-level sub-tasks are correlated with the implementation of adialog system; hence, the designs of these subtasksare more subjective and likely to be different.4 Learning ApproachesThis section describes machine-learning approach-es for inferring the task-specific information mod-eled by the form-based dialog structurerepresentation from human-human conversations.Specifically, the learning approach has to infer alist of tasks, sub-tasks and concepts in a given do-main from in-domain dialogs similar to what ahuman does in Section 3.
To make the problemtractable, components in the form-based represen-tation are acquired separately.
For most task-oriented dialogs that we encountered, each dialogcorresponds to one task.
Hence, the learning effort959can be focused on identifying concept and subtask.Since we can only observe instances or values ofthese components in a dialog, we have to first iden-tify these instances and then make a generalizationfor its type.
For instant, to infer that there is a con-cept City in the air travel domain, a set of citynames has to be identified and grouped together.To identify a set of domain concepts from thetranscription of in-domain dialogs, we follow thealgorithm described in (Chotimongkol and Rud-nicky, 2002).
This algorithm utilizes an unsuper-vised clustering algorithm which clusters wordsbased on context similarity, e.g.
mutual informa-tion-based and Kullback-Liebler-based clustering,since the members of the same domain concept areusually used in similar contexts in a particular do-main.
Examples of the clusters obtained from theKL-based clustering algorithm are shown in Figure4.
These clusters represent Hour, RentalCompa-ny, and City respectively.
Underlined clustermembers belong to other concepts.
The clusteringalgorithm can identify all 12 members of Hour andabout half of RentalCompany.
In the third clus-ter, some airport names got merged with citynames because they occur in quite similar context.Figure 4: Learned concepts in the air travel domainThe rest of this section describes an approachfor identifying subtasks and their correspondingforms in a given domain.
We decided to simplifythe form-learning problem by first segmenting adialog into form-filling episodes (which are equiv-alent to sub-tasks), then grouping the ones that cor-respond to the same form together so that we candetermine a set of necessary slots in each formfrom the concepts present in its correspondingcluster.
We further simplify the problem by con-centrating on the domains that have only one top-level task (though in principle the approach can beextended to the domains that have multiple top-level tasks).
Since we utilize well-known unsuper-vised algorithms, only the modifications which areapplied to make these algorithms suitable for infer-ring the structure of a spoken dialog are discussed.Two unsupervised discourse segmentation algo-rithms are investigated: TextTiling (Hearst, 1997)and Hidden Markov Modeling (Barzilay and Lee,2004).
These algorithms only recover the sequenceof subtasks but not the hierarchical structure ofsubtasks similar to Bangalore et al?s (2006)chunk-based model.
Nevertheless, this simplifica-tion is sufficient when a subtask is embedded at thebeginning or the end of the higher-level subtaskwhich is the case for most embedded structures wehave found.
Both algorithms, while performingwell with expository text, require modificationswhen applying to a fine-grained segmentationproblem of spoken dialogs.
In WSJ text, the aver-age topic length is 428 words (Beeferman et al,1999) while in the air travel domain the averagesubtask length is 84 words (10 utterances).For TextTiling, the modifications include a dis-tance weight and a data-driven stop word list.
Forthe subtasks that are much shorter than the averagelength, distant words in the context window can beirrelevant.
A distance weight demotes the impor-tance of the context word that is far away from theconsidered boundary by giving it a lower weight.A manually prepared stop word list, containingcommon words, may not be suitable for every ap-plication domain.
We propose a novel approachthat determines a list of stop words directly fromword distribution in each data set.
TextTiling as-sumes that words that occur regularly throughout adialog are not informative.
However, the regularityof a particular word is determined from its distribu-tion over the dialog rather than from its frequency.A high frequency word is useful if its instancesoccur only in a specific location.
For example, theword ?delta?
which occurs many times in a re-serve_flight subtask but does not occur in othersubtasks is undoubtedly useful for determiningsubtask boundaries while the word ?you?
whichcan occur anywhere in a dialog is not useful.
Spe-cifically, a regularity count of word w is defined asthe number of sliding context windows in the simi-larity score calculation of TextTiling that containthe word w in each dialog.
A data-driven stopword list contains words that have a regularitycount greater than a pre-defined threshold.For HMM-based segmentation, we modifiedBarzilay and Lee?s (2004) content models by usinglarger text spans when inducing the HMM states.HMM states are created automatically by cluster-ing similar text spans together.
When using an ut-?
ONE, TWO, THREE, NINE, SIX, FOUR, SEVEN, FIVE,EIGHT, TEN, TWELVE, ELEVEN?
HERTZ, BUDGET, THRIFTY?
MIDWAY, LAGUARDIA, GATWICK, PHILADELPHIA,DALLAS, DENVER, MONTEREY, BOSTON, CHICAGO,AUSTIN, NEWARK, PITTSBURGH, SEATTLE, OTTAWA,SYRACUSE, BALTIMORE, HOUSTON, MADRID, L.A.,ATLANTA, DULLES, HONOLULU960terance as a text span, it may not contain enoughinformation to indicate its relevant subtask as someutterances in a task-oriented dialog are very shortand can occur in any subtask (e.g.
acknowledge-ments and yes/no responses).
Larger text spans,reference topics, were used in (Yamron et al,1998).
Nevertheless, this approach requires truesegment boundaries.
To eliminate the need of an-notated data in our algorithm, HMM states are in-duced from predicted segments generated byTextTiling instead.After segmenting all dialogs into sequences ofsubtasks, the bisecting K-means clustering algo-rithm (Steinbach et al, 2000) is used to group thesegments that belong to the same type of subtasktogether as they represent the same form type.
Theclustering is done based on cosine similarity be-tween segments.
This unsupervised clustering al-gorithm is also used to infer a set of HMM states inthe HMM-based segmentation described above.Words are used as features for both segmenta-tion and clustering algorithms.
If a set of domainconcepts has already been identified, we can usethis information to enhance the features.
Whenconcept annotation is available, we can incorporatea concept label into a representation of a conceptword.
A Label+Word representation joins a wordstring and its label and can help disambiguate be-tween similar words that belong to different con-cepts.
For instance, ?one?
in ?that one?
is not thesame token as ?[Hour]:one?.
A Label representa-tion, on the other hand, only represents a conceptword by its label.
This representation is based onthe assumption that a list of concepts occurring inone subtask is distinguishable from a list of con-cepts occurring in other subtasks regardless of thevalues of the concepts; hence, a concept label ismore informative than its value.
This representa-tion provides an abstraction over all different val-ues of the same concept type.
For example,[Airline]:northwest and [Airline]:delta arerepresented with the same token [Airline].
In allexperiments, concept labels are provided by a do-main expert as we assume that a set of domainconcepts has already been identified.4.1 Dialog Segmentation ResultsTo evaluate dialog segmentation performance, wecompare predicted boundaries against subtaskboundaries annotated by a domain expert.
Subtaskboundaries could occur only at utterance bounda-ries.
Two metrics are used: Pk (Beeferman et al,1999) and concept-based f-measure (C. F-1).
Pkmeasures the probability of misclassifying two ut-terances that are k utterances apart as belonging tothe same sub-task or different sub-tasks.
k is set tohalf the average sub-task length.
C. F-1 is a mod-ification of the standard f-measure (a harmonicmean of precision and recall) that gives credit tosome near misses.
Since the segmented dialogswill later be used to identify a set of forms andtheir associated slots, the segment that contains thesame set of concepts as the reference segment isacceptable even if its boundaries are slightly dif-ferent from the reference.
For this reason, a near-miss counts as a match if there is no concept be-tween the near-miss boundary and the referenceboundary.We evaluated the proposed dialog segmentationalgorithms with 24 dialogs from the air travel do-main and 20 dialogs from the map reading domain.The window size for TextTiling was set to 4 utter-ances.
The cut-off threshold for choosing subtaskboundaries was set to ?
- ?/2; where ?
is the meanof the depth scores (Hearst, 1997), the relativechange in word co-occurrence similarities on bothsides of a candidate boundary, in each dialog and ?is their standard deviation.
We found that a smallwindow size and a low cut-off threshold are moresuitable for identifying fine-grained segments as inthe case of subtasks.
However, we also found thatTextTiling is quite robust as varying these two pa-rameters doesn?t severely degrade its performance(Chotimongkol, 2008).
The threshold for selectingdata-driven stop words was set to ?
+ 2*?
; where ?is the mean of the regularity counts of all the wordsin a given dialog and ?
is their standard deviation.The performance of TextTiling and HMM-basedsegmentation algorithm is shown in Table 2.Augmented TextTiling, which uses a data-driven stop word list, distance weights, and theLabel+Word representation, performed significant-ly better than the baseline in both domains.
Each ofthese augmenting techniques can on their own im-prove segmentation performance but not signifi-cantly.
Unsurprisingly, the proposed regularitycounts discover stop words that are specific to spo-961ken dialogs, but are absent from the hand-craftedlist1, e.g.
?okay?
and ?yeah?.AlgorithmAir Travel Map ReadingPk C. F-1 Pk C. F-1TextTiling (baseline) 0.387 0.621 0.412 0.396TextTiling (augmented) 0.371 0.712 0.384 0.464HMM-based (utterance) 0.398 0.624 0.392 0.436HMM-based (segment) 0.385 0.698 0.355 0.507HMM-based (segment +Label representation)0.386 0.706 0.250 0.686Table 2: Dialog segmentation resultsFor HMM-based segmentation, the segmenta-tion result obtained when modeling the HMMstates from predicted subtasks generated by Text-Tiling (4th row) is better than the result obtainedwhen modeling the HMM states from utterances(3rd row).
Predicted segments provide more contextto the clustering algorithm that induces the HMMstates.
As a result a more robust state representa-tion is obtained.
A more efficient clustering algo-rithm can also improve the performance of theHMM-based segmentation algorithm since it pro-vides a state representation that better differentiatesamong dialog segments which belong to dissimilarsubtasks.
When the Label representation whichyielded a better subtask clustering result (see Sec-tion 4.2) was used, HMM-based segmentation pro-duced a better result (5th row) especially in the mapreading domain.
These numbers may appear mod-est compared to the numbers obtained when seg-menting expository text.
However, predicting theboundaries of fine-grained subtasks is more diffi-cult even with a supervised learning approach (Ar-guello and Ros?, 2006).
Our results are comparableto Arguello and Ros?
?s (2006) results.Between the two segmentation algorithms, theHMM-based algorithm performed slightly worsethan TextTiling in the air travel domain but per-formed significantly better in the map reading do-main.
The HMM-based algorithm can identifymore boundaries between fine-grained subtasks,which occur more often in the map reading do-main.
TextTiling, which relies on local lexical co-hesion, is unlikely to find two significant drops inlexical similarity that are only a couple of utter-ances apart, and thus fails to detect boundaries ofshort segments.
However, HMM-based segmenta-1 http://search.cpan.org/~creamyg/Lingua-StopWords-0.08/lib/Lingua/StopWords.pm.tion misses more boundaries between two subtaskoccurrences of the same type, which occurs moreoften in the air travel domain, as they are usuallyrepresented by the same state.4.2 Subtask Clustering ResultsWe evaluated the subtask clustering algorithm onthe same data set used in the dialog segmentationevaluation.
Table 3 presents the quality score (QS)for each clustering result.
These QSs were obtainedby comparing the output clusters against a set ofreference subtasks.
See (Chotimongkol and Rud-nicky, 2002) for the definition of QS.Feature Representation Air Travel Map ReadingLabel+Word (oracle) 0.738 0.791Label+Word 0.577 0.675Label 0.601 0.823Table 3: Subtask clustering resultsWhen predicted segments were clustered, thequality of the output (2nd row) is not as good aswhen the reference segments were used (1st row) asinaccurate segment boundaries affected the per-formance of the clustering algorithm.
However, thequalities of subtasks that occur frequently are notmuch different.
In terms of feature representation,the clustering algorithm that uses the Label repre-sentation achieved better performance in both do-mains.
When the sets of concepts in all of thesubtasks are disjoint, the clustering algorithm thatuses the Label representation can achieve a verygood result as in the map reading domain.
Thisresult is even better than the result obtained whenthe reference segments were clustered by the algo-rithm that uses the Label+Word representation.These results demonstrate that an appropriate fea-ture representation provides more useful informa-tion to the clustering algorithm than accuratesegment boundaries.
However, when the subtaskscontain overlapping sets of concepts as in the airtravel domain, the performance gain obtained fromthe Label representation is quite small.Figure 5 shows four types of forms in the airtravel domain that were acquired by the proposedform identification approach.
The slot names aretaken from concept labels.
The number in paren-theses is slot frequency in the corresponding clus-ter.
The underlined slots are the ones that belong toother forms.
Some slots in the car query form are962missing as some instances of its correspondingsubtask get merged into other clusters.Figure 5: Examples of forms obtained by the proposedunsupervised learning approach4.3 Discussions on Learning ApproachesThe results presented in the previous sections showthat existing unsupervised learning algorithms areable to identify components of the form-based di-alog structure representation..
However, somemodifications are required to make these algo-rithms more suitable for inferring the structure of aspoken dialog.
The advantages of different learn-ing algorithms can be combined to improve per-formance.
For example, TextTiling and HMM-based segmentation are good at detecting differenttypes of boundaries; therefore, combining the pre-dictions made by both algorithms could improvesegmentation performance.
Additional featuressuch as prosodic features could also be useful.Subsequent steps in the learning process are sub-jected to propagation errors.
However, the pro-posed learning algorithms, which are based ongeneralization of recurring patterns, are able tolearn from inaccurate information given that thenumber of errors is moderate, so that there areenough correct examples to learn from.
Given re-dundant information in dialog corpora, a domainknowledge acquisition process does not requirehigh learning accuracy and an unsupervised learn-ing approach is reasonable.
The overall quality ofthe learning result is acceptable.
The proposed un-supervised learning approach can infer much use-ful task-specific dialog information needed forautomatically configuring a task-oriented dialogsystem from data.5 Conclusion and Future DirectionsTo represent a dialog for a learning purpose, webased our representation, the form-based dialogstructure representation, on observable informa-tion.
Components of the form-based representationcan be acquired with acceptable accuracy fromobservable structures in dialogs without requiringhuman supervision.
We show that this dialog re-presentation can capture task-specific informationin dissimilar domains.
Additionally, it can be un-derstood and applied by annotators other than thedevelopers.Our investigation shows that it is feasible to au-tomatically acquire the domain-specific dialog in-formation necessary for configuring a task-orienteddialog system from a corpus of in-domain dialogs.This corpus-based approach could potentially re-duce human effort in dialog system development.A limitation of this approach is that it can discoveronly information present in the data.
For instance,the corpus-based approach cannot identify citynames absent in the corpus while a human devel-oper would know to include these.
Revision maybe required to make learned information more ac-curate and complete before deployment; we expectthat this effort would be less than the one requiredfor manual analysis.
A detailed evaluation of cor-rection effort would be desirable.In this paper, task-specific knowledge was ac-quired from in-domain dialogs without using anyprior knowledge about the domain.
In practice,existing knowledge sources about the world andthe domain, such as WordNet, could be used toimprove learning.
Some human supervision can bevaluable particularly in the form of semi-supervised learning and active learning.
In particu-lar a process that integrates human input at appro-priate times (for example seeding or correction) islikely to be part of a successful approach.AcknowledgmentsThis research was supported by DARPA grant NBCH-D-03-0010.
The content of the information inthis publication does not necessarily reflect theposition or the policy of the US Government, andno official endorsement should be inferred.Form: flight queryAirline  (79)ArriveTimeMin  (46)DepartTimeHour (40)DepartTimeMin  (39)ArriveTimeHour (36)ArriveCity (27)FlightNumber (15)ArriveAirport (13)DepartCity (13)Form: hotel queryFare  (75)City (36)HotelName (33)Area (28)ArriveDateMonth (14)Form: flight reservationFare (257)City (27)RentalCompany (17)HotelName (15)ArriveCity (14)AirlineCompany (11)Form: car queryCarType (13)City (3)State (1)963ReferencesJ.
Alexandersson and N. Reithinger.
1997.
LearningDialogue Structures From A Corpus.
In Proceedingsof EuroSpeech-97.
Rhodes, Greece.A.
H. Anderson, M. Bader, E. G. Bard, E. Boyle, G.Doherty, S. Garrod, S. Isard, J. Kowtko, J. McAllis-ter, J. Miller, C. Sotillo, H. Thompson, and R. Wei-nert.
1991.
The HCRC Map Task Corpus.
Languageand Speech, 34(4):351-366.J.
Arguello and C. P. Ros?.
2006.
Topic Segmentationof Dialogue.
In Proceedings of Workshop on Analyz-ing Conversations in Text and Speech.S.
Banerjee and A. I. Rudnicky.
2006.
You Are WhatYou Say: Using Meeting Participants?
Speech toDetect their Roles and Expertise.
In the NAACL-HLT2006 workshop on Analyzing Conversations in Textand Speech.
New York, NY.S.
Bangalore, G. D. Fabbrizio, and A. Stent.
2006.Learning the Structure of Task-Driven Human-Human Dialogs.
In Proceedings of COLING/ACL2006.
Sydney, Australia.R.
Barzilay and L. Lee.
2004.
Catching the Drift: Prob-abilistic Content Models, with Applications to Gen-eration and Summarization.
In Proceedings of HLT-NAACL 2004.
Boston, MA.D.
Beeferman, A. Berger, and J. Lafferty.
1999.
Statis-tical Models for Text Segmentation.
Machine Learn-ing, 34(1-3):177-210.D.
Bohus and A. I. Rudnicky.
2003.
RavenClaw: DialogManagement Using Hierarchical Task Decomposi-tion and an Expectation Agenda.
In Proceedings ofEurospeech2003.
Geneva, Switzerland.J.
Carletta, S. Isard, G. Doherty-Sneddon, A. Isard, J. C.Kowtko, and A. H. Anderson.
1997.
The reliability ofa dialogue structure coding scheme.
ComputationalLinguistics, 23(1):13-31.A.
Chotimongkol.
2008.
Learning the Structure of Task-Oriented Conversations from the Corpus of In-Domain Dialogs, Ph.D. Thesis CMU-LTI-08-001.Pittsburgh, Carnegie Mellon University.A.
Chotimongkol and A. Rudnicky.
2002.
AutomaticConcept Identification in Goal-Oriented Conversa-tions.
In Proceedings of ICSLP 2002.
Denver, CO.M.
Eskenazi, A. Rudnicky, K. Gregory, P. Constanti-nides, R. Brennan, C. Bennett, and J. Allen.
1999.Data Collection and Processing in the Carnegie Mel-lon Communicator.
In Proceedings of Eurospeech1999.
Budapest, Hungary.J.
Feng, S. Bangalore, and M. Rahim.
2003.
WebTalk:Mining Websites for Automatically Building DialogSystems.
In Proceedings of ASRU '03.
St. Thomas,U.S.
Virgin Islands.A.
Garland, N. Lesh, and C. Sidner.
2001.
LearningTask Models for Collaborative Discourse.
In Pro-ceedings of Workshop on Adaptation in DialogueSystems, NAACL '01.
Pittsburgh, PA.J.
C. Gorman, N. J. Cooke, P. W. Foltz, P. A. Kiekel,and M. J. Martin.
2003.
Evaluation of Latent Seman-tic Analysis-based measures of team communicationscontent.
In Proceedings of the Human Factors andErgonomic Society 47th Annual Meeting, (HFES2003).B.
J. Grosz and C. L. Sidner.
1986.
Attention, Inten-tions, and the Structure of Discourse.
ComputationalLinguistics, 12(3):175-204.H.
Hardy, A. Biermann, R. B. Inouye, A. Mckenzie, T.Strzalkowski, C. Ursu, N. Webb, and M. Wu.
2004.Data-Driven Strategies for an Automated DialogueSystem.
In Proceedings of ACL '04.
Barcelona,Spain.M.
A. Hearst.
1997.
TextTiling: Segmenting Text intoMulti-paragraph Subtopic Passages.
ComputationalLinguistics, 23(1):33-64.D.
Litman and J. Allen.
1987.
A Plan Recognition Mod-el for Subdialogues in Conversations.
CognitiveScience, 11(2):163-200.J.-U.
M?ller.
1998.
Using Unsupervised Learning forEngineering of Spoken Dialogues.
In Proceedings ofAAAI 1998 Spring Symposium on Applying MachineLearning to Discourse Processing.C.
Rich, C. L. Sidner, and N. Lesh.
2001.
Collagen:applying collaborative discourse theory to human-computer interaction.
AI Magazine, 22(4):15-25.M.
Steinbach, G. Karypis, and V. Kumar.
2000.
AComparison of Document Clustering Techniques.
InProceedings of KDD Workshop on Text Mining.D.
R. Traum and E. A. Hinkelman.
1992.
ConversationActs in Task-Oriented Spoken Dialogue.
Computa-tional Intelligence, 8(3):575--599.M.
Woszczyna and A. Waibel.
1994.
Inferring linguisticstructure in spoken language.
In Proceedings of theInternational Conference on Spoken LanguageProcessing (ICSLP).J.
P. Yamron, I. Carp, L. Gillick, S. Lowe, and P. v.Mulbregt.
1998.
A Hidden Markov Model Approachto Text Segmentation and Event Tracking.
In Pro-ceedings of ICASSP '98.
Seattle, WA.N.
Yankelovich.
1997.
Using Natural Dialogs as theBasis for Speech Interface Design.
In Susann Luper-foy (Ed.
), Automated Spoken Dialog Systems.
Cam-bridge, MA: MIT Press.964
