Proceedings of the EACL 2012 Workshop on Computational Approaches to Deception Detection, pages 91?96,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsDetecting Stylistic DeceptionPatrick JuolaEvaluating Variation in Language LaboratoryDuquesne UniversityPittsburgh, PA 15282 USAjuola@mathcs.duq.eduAbstractWhistleblowers and activists need the abil-ity to communicate without disclosing theiridentity, as of course do kidnappers and ter-rorists.
Recent advances in the technol-ogy of stylometry (the study of authorialstyle) or ?authorship attribution?
have madeit possible to identify the author with highreliability in a non-confrontational setting.In a confrontational setting, where the au-thor is deliberately masking their identity(i.e.
attempting to deceive), the results aremuch less promising.
In this paper, weshow that although the specific author maynot be identifiable, the intent to deceive andto hide his identity can be.
We show thisby a reanalysis of the Brennan and Green-stadt (2009) deception corpus and discusssome of the implications of this surprisingfinding.1 IntroductionDeception can occur in many different ways; it ispossible to deceive not only about the content of amessage, but about its background or origin.
Forexample, a friendly invitation can become sexualharassment when sent from the wrong person, andvery few ransom notes are signed by their authors.Recent research into stylometry has shown thatit is practical to identify authors based on theirwriting style, but it is equally practical (at presenttechnology) for authors to use a deliberately de-ceptive style, either obfuscating their own style ormimicking that of another writer, with a stronglikelihood of avoiding identification.In this paper, we investigate the possibility ofidentifying, not the specific author of a text, butwhether or not the author of a text wrote withthe (deceptive) intent to disguise their style.
Ourresults strongly suggest that this deceptive intentcan itself be identified with greater reliability thanthe actual author can be.2 BackgroundStylometric authorship attribution ?
assessingthe author of a document by statistical analysis ofits contents ?
has its origins in the 19th century(Mendenhall, 1887; de Morgan, 1851), but has ex-perienced tremendous resurgence since the workof (Mosteller and Wallace, 1964) and the begin-nings of the corpus revolution.
With the exponen-tial growth of digital-only texts and the increas-ing need to validate or test the legitimacy of ques-tioned digital documents, this is obviously an areawith many potential applications.The most commonly cited stylometric study isof course that of Mosteller and Wallace (1964),who examined the frequency of appearance of ap-proximately thirty function words within the col-lection of documents known as The Federalist Pa-pers.
Using a form of Bayesian analysis, theywere able to show significant differences amongthe various authors in their use of these wordsand hence infer the probabilities that each docu-ment had been written by each author ?
i.e.
in-fer authorship.
Another classic in this field is thestudy of the Oz books by Binongo (2003), wherehe applied principal component analysis (PCA) tothe frequencies of the fifty most frequent wordsin these books and was able to demonstrate (viathe first two principle components) a clear visualseparation between the books written by Baumand those written later by Thompson.
Recent sur-veys of this field (Argamon et al, 2009; Kop-pel et al, 2005; Rudman, 1998; Koppel et al,912009; Juola, 2006; Jockers and Witten, 2010; Sta-matatos, 2009) illustrate many techniques of in-creasing sophistication and accuracy.What, however, of the person who doesn?t wantto be identified?
Chaski (2005) cites several real-world instances where authorship attribution wasapplied to the task of detecting miscreants, and inone case a murderer.
We assume that these mis-creants would have preferred to hide their iden-tities if possible.
On a more positive note, ac-tivists who fear a tyrannical government would dowell to avoid being identified by the political po-lice.
Intuitively, it seems plausible that one wouldbe able to write ?in a different style,?
although italso seems intuitively plausible that at least partof one?s writing style is fixed and immutable (vanHalteren et al, 2005) ?
you can?t pretend, forexample, to a bigger vocabulary than you have,as you can?t use words that you don?t know.
Onthe other hand, the long tradition of pastiche andparody suggests that at least some aspects of stylecan be copied.It should be noted that this type of ?decep-tion?
is different than what most research projectstudy.
Traditionally, a ?deceptive?
statement oc-curs when a speaker or writer offers an untruth;we instead suggest that another form of ?decep-tion?
can occur when a speaker or writer offers astatement that he or she does not want to be iden-tified with.
This statement may be true (a whistle-blower identifying a problem, but not wanting torisk being fired) or false (a criminal writing a falseconfession to incriminate someone else) ?
thekey deception being the identity of the author.There is little research on the success of ?de-ceptive style?
and what little there is should lendhope to activists and whistleblowers.
A teamof Drexel researchers (Brennan and Greenstadt,2009; Afroz et al, 2012) developed a small cor-pus of deceptive writing (described in detail later),but were unable to find any methods to piercethe deception.
Larger scale analyses (Juola andVescovi, 2010; Juola and Vescovi, 2011) simi-larly failed.
?
[N]o method [out of more than 1000tested] was able to perform ?significantly?
abovechance at the standard 0.05 level.. .
.
We [.
.
. ]
ob-serve that, yes, there is a confirmed problem here.Although these analyses performed (on average)above chance, they did not do so by robust mar-gins, and there is enough variance in individualperformance that we cannot claim even to have?significant?
improvement.
?In light of these results, the Drexel team haveproposed and developed a tool [?Anonymouth?,(Afroz and Brennan, 2011; Perlroth, 2012)] thatprovides a more formal and systematic method ofdisguising their writing style.
Based in part on theJGAAP tool (Juola et al, 2009; Juola, 2006), thissystem allows would-be activists to see what as-pects of their linguistic fingerprints are more obvi-ous in a document, and guides these same activiststo make changes to neutralize their personal style,or even to assume a specific other?s style.
In somesense, Anonymouth is the ?evil twin?
counter-measure to JGAAP ?
while JGAAP detects style,Anonymouth in theory renders style indetectable.Does it work?
The tool is still too new for sub-stantial testing, but we assume based on the ear-lier work that it will still be difficult to detect theoriginal author under the deception.
However, itmay be possible to detect the act of deception it-self.
As will be seen in the following sections,standard stylometric tools themselves can do that.3 Materials and MethodsOne of the most powerful and flexible tools fortext analysis and classification is the JGAAP (JavaGraphical Authorship Attribution Program) soft-ware package.
Available for download fromwww.evllabs.com, it is a modular Java-based freeware program that implements a simplepipelined architecture for text classification.
Wehave applied it to the Brennan-Greenstadt (Bren-nan and Greenstadt, 2009) Adversarial corpusof imitative and obfuscative essays, to determinewhether these ?imitative and obfuscative?
essayshave themselves a stable style.JGAAP itself (Juola, 2006) follows a standardmodel for statistical authorship attribution.
Docu-ments are pre-processed (?canonicized?)
to elim-inate distracting or uninformative variation (forexample, the length of a printed line is set bythe editor, not the author, so ?normalizing whites-pace?
removes some editorial distraction).
Fol-lowing this, they are broken up into individualevents which are subject to some form of statis-tical analysis and classification.As an example, Binongo?s experiment couldbe captured within the JGAAP framework as fol-lows: preprocess the Oz books to remove extrane-ous materials (including punctuation), unify caseto neutralize syntax-based case distinctions (like92capital letters at the beginning of a sentence), andnormalize whitespace as described above.
Bi-nongo then broke the books up into individualwords and selected only the top fifty most com-mon words as his events of interest.
Finally, heapplied PCA to get a visual picture of how thedocuments separated in abstract event space.The B/G corpus (as published) collects thewritings of twelve people, with approximately tenessays (totaling about 5000 words) per person.
Inaddition, it has twelve passages from The Road bythe professional author Cormac McCarthy.
Thisestablishes a baseline of 126 essays of ?normal?writing, writing where there is no attempt to dis-guise style (and hence no deception).
Each sub-ject was then asked to write two additional essays:one deliberately written ?in such a way that theirpersonal writing style will not be recognized?
(aso-called ?obfuscation?
), and another in the styleof Cormac McCarthy as expressed in The Road(?imitation?).
This creates another twenty-fourinstances of ?deceptive?
writing where the writeris attempting to conceal their style.Of the twelve (thirteen including McCarthy)writers in the sample, we used nine (plus Mc-Carthy) as training data, labeling all instances ofthe writer using their own style as ?HONEST?and all instances of obfuscation/imitation as ?DE-CEPTIVE.?
The writings of three subjects (An-drew, Chris, and Sara) were used as test sub-jects, creating six unknown ?deceptive?
docu-ments and twenty-eight unknown ?honest?
doc-uments.
(This is obviously an unbalanced corpusas the number of honest documents is more thanfive times the number of deceptive ones; this willbe discussed later.
)These documents were analyzed by JGAAP us-ing the following settings, which previous test-ing (Noecker and Juola, 2009) has shown to workwell:?
Canonicizer : Unify Case & PunctuationSeparator?
Event Driver : Character 3-grams (CharacterN-grams with N set to 3)?
Event Culler : <none>?
Analysis Driver : Nearest Neighbor Driver?
Distance : (Normalized) Cosine Distance?Unify Case?
converts all (alphabetic) charac-ters to lower case, thus removing any apparent dif-ferences between sentence-initial words and theirsentence-internal equivalents.
?Punctuation Sep-arator?
breaks up groups of consecutive punctu-ation characters by inserting spaces (e.g.
?(!
)?would become ?
( !
)?).
The events analyzed werestrings of three consecutive characters (e.g.
theword ?there?
contains three such 3-grams (?the??her?
and ?ere?).
These 3-grams were not culled(unlike the Binongo experiment, where the eventswere culled to include only the top 50) and in-stead were all used in the analysis.
These 3-gramswere collected into a histogram for each docu-ment and inter-document distances were calcu-lated using the normalized cosine distance (akadot product distance).
Finally, each testing doc-ument attributed to (considered to be the samedeceptiveness type as) the closest training docu-ment.4 ResultsThe results are summarized in table 1.
Of thesix deceptive documents, five (or 83%) were cor-rectly identified, while of the twenty-eight non-deceptive documents, twenty-two (or 79%) werecorrectly identified.
(Of course, due to the imbal-ance in the test set, only 44% of the documentslabeled ?deceptive?
actually were; we considerthis statistic something of an artifact.)
This re-sult is of course far above chance: baseline per-formance would be only two correct on decep-tive documents and 19 correct on honest ones.Fisher?s exact test on the 2?2 contingency matrixshows a one-tailed probability of p < 0.00790 (ora two-tailed probability of double that, of course),confirming the high significance of this result.Preliminary error analysis is attached as table 2.Most notable is that none of the imitation CormacMcCarthy analyses were misclassified as ?nor-mal?
writing.5 Discussion and Future WorkPrevious work [(Brennan and Greenstadt, 2009;Juola and Vescovi, 2010; Juola and Vescovi,2011)] has shown that identifying the author of?deceptively?
written materials is extremely dif-ficult.
We thus have the highly surprising resultthat, while identifying the specific author may bedifficult, uncovering the mere fact that the author93Actual DeceptionY NDetected DeceptionY 5 6N 1 22Table 1: Results from deception-detection experimentFP FN (obfusc) FN (imit)Andrew 3 0 0Chris 1 1 0Sara 2 0 0Table 2: Number of incorrect classifications by typeis concerned about being identified is relativelyeasy.
This of course parallels the rather common-place situation in detective fiction where the factthat the criminal has wiped the fingerprints off themurder weapon is both easy to learn and highlysignificant, even if the criminal?s actual identitymust wait five more chapters for the big reveal.Similarly, it appears to be fairly easy to detect theattempt to wipe one?s authorial ?fingerprints?
offof the writing.This result is all the more surprising in light ofthe heterogeneity of the corpus; the writing styleof ten different people, collectively, created oursample of ?normal?
writing.
The writings of threeentirely different people fit that sample relativelywell.
Astonishingly, the attempts of all twelvepeople to write ?differently?
fit into a recogniz-able and distinctive stylistic pattern; these twelvepeople seem to have a relatively uniform sense of?the other.?
This sense of ?the other,?
in turn, per-sists even when these people model the writingsof a professional writer whose style itself is partof the ?normal?
sample!Put more strongly, when ?Chris?
(or any ofthe other test subjects) attempted to write in thestyle of Cormac McCarthy, the result was actuallycloser to a third party?s attempt to write decep-tively than it was to McCarthy?s writing himself.In the specific case of ?Andrew?s?
imitative writ-ing, all six of the six closest samples were of de-ceptive writing, suggesting that ?deceptive writ-ing?
is itself a recognizable style.Further investigation is clearly required into thecharacteristics of the style of deception.
For ex-ample, there may not be one single style; it mayinstead be the case that ?imitation McCarthy?
is arecognizable and distinct style from McCarthy?s,but also from ?obfuscated style.?
There may beone or several ?obfuscated styles.?
It is not clearfrom this study what the characteristics of thisstyle are, and in fact, the inability of JGAAP (andJGAAP?s distance-based measures in particular)to produce explanations for what are evidentlyclear-cut categorizations is one of the major weak-nesses of the JGAAP system as currently envi-sioned.
Even simple replication of this experi-ment would be of value, as while we consider itunlikely that our arbitrary choice of test subjectswould have created an unrepresentative result, wecan?t (yet) confirm that.
Indeed, we hope thatthis finding provides encouragement for the de-velopment of larger-scale corpora than the simpletwelve-subject Brennan-Greenstadt corpus.We also hope this finding spurs research intoexactly what the stylistic ?other?
is, and in partic-ular, research from a psychological or psycholin-guistic standpoint.
For example, Chaski (2005)[see also (Chaski, 2007)] argues that the linguisticconcept of ?markedness?
is a key aspect of authoridentification.
Chaski in particular suggests thatthe use or non-use of ?marked?
constructions is agood feature to capture.
Following her line of rea-soning, if I try to write as ?not-myself,?
does thismean I will deliberately use concepts that I con-sider to be ?marked?
and therefore unusual?
(Ifthis were true, this would have significant impli-cations for the theory of markedness, as this con-cept is usually held to be a property of a languageas a whole and not of individual idiolects.
In par-ticular, if I personally tend to use ?marked?
con-structions, and consider traditionally ?unmarked?construtions to be unusual, does this imply thattraditional notions of ?markedness?
are reversedin my idiolect, or that my cognitive processing of94this construction is atypical?)
Alternatively, if au-thorship is defined more computationally in termsof probability spaces, can we relate ?otherness?to a notion of prototypicality (Rosch and Mervis,1975) of language?Even without explanations, our basic resultshave significant implications for the stylometricarms race.
We acknowledge the legitimate needfor the good guys to analyze the writings of thebad guys to help find them, while also acknowl-edging the needs of the good guys (human rightsadvocates, corporate whistleblowers, etc.)
to befree to expose the abuses of the bad guys withoutfear of retribution.
We applaud the developmentof tools like Anonymouth for this reason.
On theother hand, if an attempt even to disguise one?sstyle is detectable, it may equally be suspicious?
especially in the mind of one who believesthat the innocent have no reason to disguise them-selves.
In this regard tools like Anonymouth maybe similar to encryption programs like PGP.
En-crypted email may be suspected due to its veryrarity.
Zimmermann (nd) has suggested that ?itwould be nice if everyone routinely used encryp-tion for all their E-mail, innocent or not, so thatno one drew suspicion by asserting their [right to]E-mail privacy with encryption.
?This result may also have significant implica-tions for (linguistic) forensic practices.
The ques-tion of reliability is key for any evidence.
Any de-fense lawyer will ask whether or not it?s possiblethat someone could have imitated the style of hisclient when writing the incriminating document.The results of repeated analysis of the Brennan-Greenstadt corpus suggest that it is, in fact, possi-ble to fool stylometric analysis.
The results pre-sented here, however, show that such deception isdetectable ?
the analyst can respond ?yes, it maybe possible, but such imitation would leave tracesthat were not found in the document.?
By show-ing a lack of deceptive intent, one can enhance thede facto reliability of a report.A key technical question that remains iswhether tools like Anonymouth will produce?strongly?
stylistic masking ?
and whether the useof such tools is as detectable as more freestyleapproaches to stylistic matching, where the au-thor is simply told ?write like so-and-so.?
In the-ory Anonymouth could guide a writer to specifictypes of stylistic difference (?you use words thatare too short; use longer words?)
?
in practice(Greenstadt, personal communication) this has sofar been shown to be very cumbersome.
(Ofcourse, Anonymouth itself is barely out of pro-totype stage and can probably be improved.)
Aworst-case scenario would be where the use ofAnonymouth itself left the equivalent of stylistic?toolmarks,?
allowing people to identify that themessage had been altered by this specific softwarepackage (and possibly even a specific version).This could, in turn, provide investigators with in-formation and evidence that actually makes it eas-ier to identify the origin of a given text (e.g.,how many people have Anonymouth on their sys-tems?
).6 ConclusionsThe results of this study, despite being prelimi-nary, show that attempts to disguise one?s writingstyle can be detected with relatively high accu-racy.
While these results technically only apply tofreestyle deception as opposed to tool-based de-ception, we expect that similar findings would ap-ply to the use of anti-stylometric tools.
Similarly,we have only shown one particular method is ca-pable of performing this detection, but we expectthat there are others as well and invite large-scaletesting to find the most accurate way to detect de-ceptive writing, which may or may not be the bestway to identify the author of non-deceptive writ-ing (or the author of deceptive writing, for thatmatter).From the standpoint of security tech-nologies, this creates another level in thecountermeasures/counter-countermeasures/etc.loop.
If the use of a tool provides security at onelevel, it is likely to create a weakness at another;disguising one?s writing style may at the sametime make it obvious to an appropriate observerthat you are trying to conceal something.
Withinterest in stylometry and stylometric securitygrowing, we acknowledge the need for stylisticmasking, but argue here that using such tools mayactually put the masked writer at risk.AcknowledgmentsThis material is based in part upon work sup-ported by the National Science Foundation underGrant Numbers OCI-0721667 and OCI-1032683.Any opinions, findings, and conclusions or rec-ommendations expressed in this material are those95of the author(s) and do not necessarily reflect theviews of the National Science Foundation.ReferencesSadia Afroz and Michael Brennan.
2011.
Deceivingauthorship detection.
In 28th Annual Meeting of theChaos Computer Club (28C3), Berlin.Sadia Afroz, Michael Brennan, and Rachel Green-stadt.
2012.
Detecting hoaxes, frauds, and decep-tion in writing style online.
In Proceedings of the33rd conference on IEEE Symposium on Securityand Privacy, pages=To appear.
IEEE.Shlomo Argamon, Moshe Koppel, James W. Pen-nebaker, and Jonathan Schler.
2009.
Automaticallyprofiling the author of an anonymous text.
CACM,52(2):119?123, February.Jose Nilo G. Binongo.
2003. Who wrote the 15thbook of Oz?
an application of multivariate analysisto authorship attribution.
Chance, 16(2):9?17.Michael Brennan and Rachel Greenstadt.
2009.
Prac-tical attacks against authorship recognition tech-niques.
In Proceedings of the Twenty-First Confer-ence on Innovative Applications of Artificial Intelli-gence (IAAI), Pasadena, CA.Carole E. Chaski.
2005. Who?s at the key-board: Authorship attribution in digital evidenceinvesigations.
International Journal of Digi-tal Evidence, 4(1):n/a.
Electronic-only journal:http://www.ijde.org, accessed 5.31.2007.Carole E. Chaski.
2007.
The keyboard dilemma andforensic authorship attribution.
Advances in DigitalForensics III.Augustus de Morgan.
1851.
Letter to Rev.
Heald18/08/1851.
In Sophia Elizabeth.
De Morgan (Ed.
)Memoirs of Augustus de Morgan by his wife SophiaElizabeth de Morgan with Selections from his Let-ters.M.
L. Jockers and D.M Witten.
2010.
A comparativestudy of machine learning methods for authorshipattribution.
LLC, 25(2):215?23.Patrick Juola and Darren Vescovi.
2010.
Empiricalevaluation of authorship obfuscation using JGAAP.In Proceedings of the Third Workshop on ArtificialIntelligence and Security, Chicago, IL USA, Octo-ber.Patrick Juola and Darren Vescovi.
2011.
Author-ship attribution for electronic documents.
In GilbertPetersen and Sujeet Shenoi, editors, Advances inDigital Forensics VII, International Federal for In-formation Processing, chapter 9, pages 115?129.Springer, Boston.Patrick Juola, John Noecker, Jr., Mike Ryan, andSandy Speer.
2009.
Jgaap 4.0 ?
a revised author-ship attribution tool.
In Proceedings of Digital Hu-manities 2009, College Park, MD.Patrick Juola.
2006.
Authorship attribution.
Founda-tions and Trends in Information Retrieval, 1(3).Moshe Koppel, Johnathan Schler, and K. Zigdon.2005.
Determining an author?s native language bymining a text for errors (short paper).
In Proceed-ings of KDD, Chicago,IL, August.Moshe Koppel, Jonathan Schler, and Shlomo Arga-mon.
2009.
Computational methods in authorshipattribution.
Journal of the American Society for In-formation Science and Technology, 60(1):9?26.T.
C. Mendenhall.
1887.
The characteristic curves ofcomposition.
Science, IX:237?49.F.
Mosteller and D. L. Wallace.
1964.
Inference andDisputed Authorship : The Federalist.
Addison-Wesley, Reading, MA.John Noecker, Jr. and Patrick Juola.
2009.
Cosine dis-tance nearest-neighbor classification for authorshipattribution.
In Proceedings of Digital Humanities2009, College Park, MD.Nicole Perlroth.
2012.
Software helps identify anony-mous writers or helps them stay that way, January.New York Times article of 3 January, 2012.Eleanor Rosch and Carolyn B. Mervis.
1975.
Familyresemblances: Studies in the internal structure ofcategories.
Cognitive Psychology, 7(4):573?605.J.
Rudman.
1998.
The state of authorship attributionstudies: Some problems and solutions.
Computersand the Humanities, 31:351?365.Efstathios Stamatatos.
2009.
A survey of modern au-thorship attribution methods.
Journal of the Amer-ican Society for Information Science and Technol-ogy, 60(3):538?56.Hans van Halteren, R. Harald Baayen, Fiona Tweedie,Marco Haverkort, and Anneke Neijt.
2005.
Newmachine learning methods demonstrate the exis-tence of a human stylome.
Journal of QuantitativeLinguistics, 12(1):65?77.Phil Zimmermann.
n.d. Why do you need PGP?http://www.pgpi.org/doc/whypgp/en.Retrieved 18 January, 2012.96
