Proceedings of the Workshop on Linguistic Distances, pages 43?50,Sydney, July 2006. c?2006 Association for Computational LinguisticsEvaluation of Several Phonetic Similarity Algorithmson the Task of Cognate IdentificationGrzegorz Kondrak and Tarek SherifDepartment of Computing ScienceUniversity of AlbertaEdmonton, Alberta, Canada T6G 2E8{kondrak,tarek}@cs.ualberta.caAbstractWe investigate the problem of measuringphonetic similarity, focusing on the iden-tification of cognates, words of the sameorigin in different languages.
We com-pare representatives of two principal ap-proaches to computing phonetic similar-ity: manually-designed metrics, and learn-ing algorithms.
In particular, we considera stochastic transducer, a Pair HMM, sev-eral DBN models, and two constructedschemes.
We test those approaches onthe task of identifying cognates amongIndoeuropean languages, both in the su-pervised and unsupervised context.
Ourresults suggest that the averaged contextDBN model and the Pair HMM achievethe highest accuracy given a large trainingset of positive examples.1 IntroductionThe problem of measuring phonetic similarity be-tween words arises in various contexts, includingspeech processing, spelling correction, commercialtrademarks, dialectometry, and cross-language in-formation retrieval (Kessler, 2005).
A number ofdifferent schemes for computing word similarityhave been proposed.
Most of those methods are de-rived from the notion of edit distance.
In its simplestform, edit distance is the minimum number of editoperations required to transform one word into theother.
The set of edit operations typically includessubstitutions, insertions, and deletions, and may in-corporate more complex transformations.By assigning variable weights to various edit op-erations depending on the characters involved inthe operations, one can design similarity schemesthat are more sensitive to a given task.
Such vari-able weight schemes can be divided into two maingroups.
One approach is to manually design edit op-eration weights on the basis of linguistic intuitionand/or physical measurements.
Another approachis to use machine learning techniques to derive theweights automatically from training data composedof a set of word pairs that are considered similar.The manually-designed schemes tend to be some-what arbitrary, but can be readily applied to diversetasks.
The learning approaches are also easily adapt-able to various tasks, but they crucially require train-ing data sets of reasonable size.
In general, the morecomplex the underlying model, the larger the datasets needed for parameter estimation.In this paper, we focus on a few representativesof both approaches, and compare their performanceon the specific task of cognate identification.
Cog-nate identification is a problem of finding, in distinctlanguages, words that can be traced back to a com-mon word in a proto-language.
Beyond historicallinguistics, cognate identification has applicationsin other areas of computational linguistics (Mackayand Kondrak, 2005).
Because the likelihood thattwo words across different languages are cognates ishighly correlated with their phonetic similarity, cog-nate identification provides an objective test of thequality of phonetic similarity schemes.The remainder of this paper is organized as fol-43lows.
Section 2 discusses the two manually designedschemes: the ALINE algorithm and a linguistically-motivated metric.
Section 3 discusses various learn-ing approaches.
In Section 4, we describe DynamicBayesian Nets.
Finally, in Section 5, we discuss theresults of our experiments.2 Two manually constructed schemesIn this section, we first describe two different con-structed schemes and then compare their properties.2.1 ALINEThe ALINE algorithm (Kondrak, 2000) assigns asimilarity score to pairs of phonetically-transcribedwords on the basis of the decomposition of phone-mes into elementary phonetic features.
The algo-rithm was originally designed to identify and aligncognates in vocabularies of related languages.
Nev-ertheless, thanks to its grounding in universal pho-netic principles, the algorithm can be used for esti-mating the similarity of any pair of words.The principal component of ALINE is a functionthat calculates the similarity of two phonemes thatare expressed in terms of about a dozen multi-valuedphonetic features (Place, Manner, Voice, etc.).
Thephonetic features are assigned salience weights thatexpress their relative importance.
Feature valuesare encoded as floating-point numbers in the range[0,1].
For example, the feature Manner can take anyof the following seven values: stop = 1.0, affricate= 0.9, fricative = 0.8, approximant = 0.6, high vowel= 0.4, mid vowel = 0.2, and low vowel = 0.0.
Thenumerical values reflect the distances between vocalorgans during speech production.The overall similarity score is the sum of individ-ual similarity scores between pairs of phonemes inan optimal alignment of two words, which is com-puted by a dynamic programming algorithm (Wag-ner and Fischer, 1974).
A constant insertion/deletionpenalty is applied for each unaligned phoneme.Another constant penalty is set to reduce relativeimportance of vowel?as opposed to consonant?phoneme matches.
The similarity value is normal-ized by the length of the longer word.ALINE?s behavior is controlled by a number ofparameters: the maximum phonemic score, the in-sertion/deletion penalty, the vowel penalty, and thefeature salience weights.
The parameters have de-fault settings for the cognate matching task, butthese settings can be optimized (tuned) on a devel-opment set that includes both positive and negativeexamples of similar words.2.2 A linguistically-motivated metricPhonetically natural classes such as /p b m/ are muchmore common among world?s languages than unnat-ural classes such as /o z g/.
In order to show that thebias towards phonetically natural patterns of phono-logical classes can be modeled without stipulatingphonological features, Mielke (2005) developed aphonetic distance metric based on acoustic and ar-ticulatory measures.
Mielke?s metric encompasses63 phonetic segments that are found in the invento-ries of multiple languages.
Each phonetic segmentis represented by a 7-dimensional vector that con-tains three acoustic dimensions and four articulatorydimensions (perceptual dimensions were left out be-cause of the difficulties involved in comparing al-most two thousand different sound pairs).
The pho-netic distance between any two phonetic segmentswere then computed as the Euclidean distance be-tween the corresponding vectors.For determining the acoustic vectors, the record-ings of 63 sounds were first transformed into wave-form matrices.
Next, distances between pairs ofmatrices were calculated using the Dynamic TimeWarping technique.
These acoustic distances weresubsequently mapped to three acoustic dimensionsusing multidimensional scaling.
The three dimen-sions can be interpreted roughly as (a) sonorous vs.sibilant, (b) grave vs. acute, and (c) low vs. highformant density.The articulatory dimensions were based on ultra-sound images of the tongue and palate, video im-ages of the face, and oral and nasal airflow measure-ments.
The four articulatory dimensions were: oralconstriction location, oral constriction size, lip con-striction size, and nasal/oral airflow ratio.2.3 ComparisonWhen ALINE was initially designed, there did notexist any concrete linguistically-motivated similarityscheme to which it could be compared.
Therefore, itis interesting to perform such a comparison with therecently proposed metric.44The principal difficulty in employing the metricfor computing word similarity is the limited sizeof the phonetic segment set, which was dictated bypractical considerations.
The underlying databaseof phonological inventories representing 610 lan-guages contains more than 900 distinct phonetic seg-ments, of which almost half occur in only one lan-guage.
However, because a number of complexmeasurements have to be performed for each sound,only 63 phonetic segments were analyzed, which isa set large enough to cover only about 20% of lan-guages in the database.
The set does not includesuch common phones as dental fricatives (which oc-cur in English and Spanish), and front rounded vow-els (which occur in French and German).
It is notat all clear how one to derive pairwise distances in-volving sounds that are not in the set.In contrast, ALINE produces a similarity score forany two phonetic segment so long as they can be ex-pressed using the program?s set of phonetic features.The feature set can in turn be easily extended to in-clude additional phonetic features required for ex-pressing unusual sounds.
In practice, any IPA sym-bol can be encoded as a vector of universal phoneticfeatures.Another criticism that could be raised againstMielke?s metric is that it has no obvious referencepoint.
The choice of the particular suite of acous-tic and articulatory measurements that underlie themetric is not explicitly justified.
It is not obvioushow one would decide between different metrics formodeling phonetic generalizations if more than onewere available.On the other hand, ALINE was designed with aspecific reference in mind, namely cognate identi-fication.
The ?goodness?
of alternative similarityschemes can be objectively measured on a test setcontaining both cognates and unrelated pairs fromvarious languages.A perusal of individual distances in Mielke?s met-ric reveals that some of them seem quite unintuitive.For example, [t] is closer to [j] than it is to [   ], [  ]is closer to [n] than to [i], [  ] is closer to [e] thanto [g].
etc.
This may be caused either by the omis-sion of perceptual features from the underlying setof features, or by the assignment of uniform weightsto different features (Mielke, personal communica-tion).It is difficult to objectively measure which pho-netic similarity scheme produces more ?intuitive?values.
In order to approximate a human evalua-tion, we performed a comparison with the perceptualjudgments of Laver (1994), who assigned numericalvalues to pairwise comparisons of 22 English conso-nantal phonemes on the basis of ?subjective auditoryimpressions?.
We counted the number of perceptualconflicts with respect to Laver?s judgments for bothMielke?s metric and ALINE?s similarity values.
Forexample, the triple ([ ], [j], [k]) is an example of aconflict because [ ] is considered closer to [j] than to[k] in Mielke?s matrix but the order is the oppositein Laver?s matrix.
The program identified 1246 con-flicts with Mielke?s metric, compared to 1058 con-flicts with ALINE?s scheme, out of 4620 triples.
Weconclude that in spite of the fact that ALINE is de-signed for identifying cognates, rather than directlyfor phonetic similarity, it is more in agreement withhuman perceptual judgments than Mielke?s metricwhich was explicitly designed for quantifying pho-netic similarity.3 Learning algorithmsIn this section, we briefly describe several ma-chine learning algorithms that automatically deriveweights or probabilities for different edit operations.3.1 Stochastic transducerRistad and Yianilos (1998) attempt to model editdistance more robustly by using Expectation Max-imization to learn probabilities for each of the pos-sible edit operations.
These probabilities are thenused to create a stochastic transducer, which scoresa pair of words based on either the most probablesequence of operations that could produce the twowords (Viterbi scoring), or the sum of the scores ofall possible paths that could have produced the twowords (stochastic scoring).
The score of an individ-ual path here is simply the product of the probabili-ties of the edit operations in the path.
The algorithmwas evaluated on the task of matching surface pro-nunciations in the Switchboard data to their canoni-cal pronunciations in a lexicon, yielding a significantimprovement in accuracy over Levenshtein distance.453.2 Levenshtein with learned weightsMann and Yarowsky (2001) applied the stochastictransducer of Ristad and Yianilos (1998) for induc-ing translation lexicons between two languages, butfound that in some cases it offered no improvementover Levenshtein distance.
In order to remedy thisproblem, they they proposed to filter the probabili-ties learned by EM into a few discrete cost classes,which are then used in the standard edit distancealgorithm.
The LLW approach yielded improve-ment over both regular Levenshtein and the stochas-tic transducer.3.3 CORDICORDI (Kondrak, 2002) is a program for detect-ing recurrent sound correspondences in bilingualwordlists.
The idea is to relate recurrent sound cor-respondences in wordlists to translational equiva-lences in bitexts.
A translation model is induced be-tween phonemes in two wordlists by combining themaximum similarity alignment with the competitivelinking algorithm of Melamed (2000).
Melamed?sapproach is based on the one-to-one assumption,which implies that every word in the bitext is alignedwith at most one word on the other side of the bitext.In the context of the bilingual wordlists, the cor-respondences determined under the one-to-one as-sumption are restricted to link single phonemes tosingle phonemes.
Nevertheless, the method is pow-erful enough to determine valid correspondences inwordlists in which the fraction of cognate pairs iswell below 50%.The discovered phoneme correspondences can beused to compute a correspondence-based similar-ity score between two words.
Each valid corre-spondence is counted as a link and contributes aconstant positive score (no crossing links are al-lowed).
Each unlinked segment, with the exceptionof the segments beyond the rightmost link, is as-signed a smaller negative score.
The alignment withthe highest score is found using dynamic program-ming (Wagner and Fischer, 1974).
If more than onebest alignment exists, links are assigned the weightaveraged over the entire set of best alignments.
Fi-nally, the score is normalized by dividing it by theaverage of the lengths of the two words.3.4 Pair HMMMackay and Kondrak (2005) propose to computingsimilarity between pairs of words with a techniqueadapted from the field of bioinformatics.
A Pair Hid-den Markov Model differs form a standard HMM byproducing two output streams in parallel, each corre-sponding to a word that is being aligned.
The modelhas three states that correspond to the basic edit op-erations: substitution, insertion, and deletion.
Theparameters of the model are automatically learnedfrom training data that consists of word pairs thatare known to be similar.
The model is trained usingthe Baum-Welch algorithm (Baum et al, 1970).4 Dynamic Bayesian NetsA Bayesian Net is a directed acyclic graph in whicheach of the nodes represents a random variable.The random variable can be either deterministic, inwhich case the node can only take on one value for agiven configuration of its parents, or stochastic, inwhich case the configuration of the parents deter-mines the probability distribution of the node.
Arcsin the net represent dependency relationships.Filali and Bilmes (2005) proposed to use Dy-namic Bayesian Nets (DBNs) for computing wordsimilarity.
A DBN is a Bayesian Net where a setof arcs and nodes are maintained for each point intime in a dynamic process.
This involves set of pro-logue frames denoting the beginning of the process,chunk frames which are repeated for the middle ofthe process, and epilogue frames to end the process.The conditional probability relationships are time-independent.
DBNs can encode quite complex in-terdependencies between states.We tested four different DBN models on the taskof cognate identification.
In the following descrip-tion of the models, Z denotes the current edit opera-tion, which can be either a substitution, an insertion,or a deletion.MCI The memoriless context-independent model(Figure 1) is the most basic model, which ismeant to be equivalent to the stochastic trans-ducer of Ristad and Yianilos (1998).
Its lackof memory signifies that the probability of Ztaking on a given value does not depend in anyway on what previous values of Z have been.The context-independence refers to the fact that46endscZtctbas(P) (C) (E)scZtctbasendscZtctbastendsendFigure 1: The MCI model.the probability of Z taking on a certain valuedoes not depend on the letters of the source ortarget word.
The a and b nodes in Figure 1 rep-resent the current position in the source and tar-get words, respectively.
The s and t nodes rep-resent the current letter in the source and targetwords.
The end node is a switching parent of Zand is triggered when the values of the a and bnodes move past the end of both the source andtarget words.
The sc and tc nodes are consis-tency nodes which ensure that the current editoperation is consistent with the current lettersin the source and target words.
Consistencyhere means that the source side of the edit oper-ation must either match the current source letteror be ?, and that the same be true for the targetside.
Finally, the send and tend nodes appearonly in the last frame of the model, and are onlygiven a positive probability if both words havealready been completely processed, or if thefinal edit operation will conclude both words.The following models all use the MCI modelas a basic framework, while adding new depen-dencies to Z.MEM In the memory model, the probability of thecurrent operation being performed depends onwhat the previous operation was.CON In the context-dependent model, the probabil-ity that Z takes on certain values is dependenton letters in the source word or target word.The model that we test in Section 5, takes intoaccount the context of two letters in the sourceword: the current one and the immediatelypreceding one.
We experimented with severalother variations of context sets, but they eitherperformed poorly on the development set, or re-quired inordinate amounts of memory.LEN The length model learns the probability dis-tribution of the number of edit operations tobe performed, which is the incorporated intothe similarity score.
This model represents anattempt to counterbalance the effect of longerwords being assigned lower probabilities.The models were implemented with the GMTKtoolkit (Bilmes and Zweig, 2002).
A more detaileddescription of the models can be found in (Filali andBilmes, 2005).5 Experiments5.1 SetupWe evaluated various methods for computing wordsimilarity on the task of the identification of cog-nates.
The input consists of pairs of words thathave the same meaning in distinct languages.
Foreach pair, the system produces a score represent-ing the likelihood that the words are cognate.
Ide-ally, the scores for true cognate pairs should alwaysbe higher than scores assigned to unrelated pairs.For binary classification, a specific score thresh-old could be applied, but we defer the decision onthe precision-recall trade-off to downstream applica-tions.
Instead, we order the candidate pairs by theirscores, and evaluate the ranking using 11-point in-terpolated average precision (Manning and Schutze,2001).
Scores are normalized by the length of thelonger word in the pair.Word similarity is not always a perfect indicatorof cognation because it can also result from lexicalborrowing and random chance.
It is also possiblethat two words are cognates and yet exhibit little sur-face similarity.
Therefore, the upper bound for aver-age precision is likely to be substantially lower than100%.47Languages Proportion Methodof cognates EDIT MIEL ALINE R&Y LLW PHMM DBNEnglish German 0.590 0.906 0.909 0.912 0.894 0.918 0.930 0.927French Latin 0.560 0.828 0.819 0.862 0.889 0.922 0.934 0.923English Latin 0.290 0.619 0.664 0.732 0.728 0.725 0.803 0.822German Latin 0.290 0.558 0.623 0.705 0.642 0.645 0.730 0.772English French 0.275 0.624 0.623 0.623 0.684 0.720 0.812 0.802French German 0.245 0.501 0.510 0.534 0.475 0.569 0.734 0.645Albanian Latin 0.195 0.597 0.617 0.630 0.568 0.602 0.680 0.676Albanian French 0.165 0.643 0.575 0.610 0.446 0.545 0.653 0.658Albanian German 0.125 0.298 0.340 0.369 0.376 0.345 0.379 0.420Albanian English 0.100 0.184 0.287 0.302 0.312 0.378 0.382 0.446AVERAGE 0.2835 0.576 0.597 0.628 0.601 0.637 0.704 0.709Table 1: 11-point average cognate identification precision for various methods.5.2 DataThe training data for our cognate identification ex-periments comes from the Comparative Indoeuro-pean Data Corpus (Dyen et al, 1992).
The data con-tains word lists of 200 basic meanings representing95 speech varieties from the Indoeuropean familyof languages.
Each word is represented in an or-thographic form without diacritics using the 26 let-ters of the Roman alphabet.
Approximately 180,000cognate pairs were extracted from the corpus.The development set was composed of three lan-guage pairs: Italian-Croatian, Spanish-Romanian,and Polish-Russian.
We chose these three languagepairs because they represent very different levels ofrelatedness: 25.3%, 58.5%, and 73.5% of the wordpairs are cognates, respectively.
The percentage ofcognates within the data is important, as it providesa simple baseline from which to compare the successof our algorithms.
If our cognate identification pro-cess were random, we would expect to get roughlythese percentages for our recognition precision (onaverage).The test set consisted of five 200-word lists repre-senting English, German, French, Latin, and Alba-nian, compiled by Kessler (2001).
The lists for theselanguages were removed from the training data (ex-cept Latin, which was not part of the training set), inorder to keep the testing and training data as sepa-rate as possible.
For the supervised experiments, weconverted the test data to have the same orthographicrepresentation as the training data.The training process for the DBN models con-sisted of three iterations of Expectation Maximiza-tion, which was determined to be optimal on the de-velopment data.
Each pair was used twice, once ineach source-target direction, to enforce the symme-try of the scoring, One of the models, the context-dependent model, remained asymmetrical despite totwo-way training.
In order to remove the undesir-able asymmetry, we averaged the scores in both di-rections for each word pair.5.3 ResultsTable 1 shows the average cognate identificationprecision on the test set for a number of meth-ods.
EDIT is a baseline edit distance with uniformcosts.
MIEL refers to edit distance with weightscomputed using the approach outlined in (Mielke,2005).
ALINE denotes the algorithm for aligningphonetic sequences (Kondrak, 2000) described inSection 2.1.
R&Y is the stochastic transducer ofRistad and Yianilos (1998).
LLW stands for Lev-enshtein with learned weights, which is a modifi-cation of R&Y proposed by Mann and Yarowsky(2001).
The PHMM column provides the resultsreported in (Mackay and Kondrak, 2005) for thebest Pair HMM model, which uses log odds scor-ing.
Finally, DBN stands for our best results ob-tained with a DBN model, in this case the averagedcontext model.Table 2 show the aggregate results for variousDBN models.
Two different results are given foreach model: the raw score, and the score normal-48Model Raw Score NormalizedMCI 0.515 0.601MEM 0.563 0.595LEN 0.516 0.587CON-FOR 0.582 0.599CON-REV 0.624 0.619CON-AVE 0.629 0.709Table 2: Average cognate identification precision forvarious DBN models.ized by the length of the longer word.
The mod-els are the memoriless context-independent model(MCI), memory model (MEM), length model (LEN)and context model (CON).
The context model re-sults are split as follows: results in the original di-rection (FOR), results with all word pairs reversed(REV), and the results of averaging the scores foreach word pair in the forward and reverse directions(AVE).Table 3 shows the aggregate results for the un-supervised approaches.
In the unsupervised tests,the training set was not used, as the models weretrained directly on the testing data without accessto the cognation information.
For the unsupervisedtests, the original, the test set was in its original pho-netic form.
The table compares the results obtainedwith various DBN models and with the CORDI al-gorithm described in Section 3.3.5.4 DiscussionThe results in Table 1 strongly suggest that thelearning approaches are more effective than themanually-designed schemes for cognate identifica-tion.
However, it has to be remembered that thelearning process was conducted on a relatively largeset of Indoeuropean cognates.
Even though therewas no overlap between the training and the testset, the latter also contained cognate pairs from thesame language family.
For each of the removed lan-guages, there are other closely related languages thatare retained in the training set, which may exhibitsimilar or even identical regular correspondences.The manually-designed schemes have the advan-tage of not requiring any training sets after theyhave been developed.
Nevertheless, Mielke?s met-ric appears to produce only small improvement overModel Raw Score NormalizedMCI 0.462 0.430MEM 0.351 0.308LEN 0.464 0.395CON-AVE 0.433 0.414CORDI ?
0.629Table 3: Phonetic test results.simple edit distance.
ALINE outperforms Mielke?smetric, which is not surprising considering thatALINE was developed specifically for identifyingcognates, and Mielke?s substitution matrix lacksseveral phonemes that occur in the test set.Among the DBN models, the average contextmodel performs the best.
The averaged contextmodel is clearly better than either of the unidirec-tional models on which it is based.
It is likely thatthe averaging allows the scoring to take contextualinformation from both words into account, insteadof just one or the other.
The averaged context DBNmodel performs about as well as on average as thePair HMM approach, but substantially better thanthe R&Y approach and its modification, LLW.In the unsupervised context, all DBN models failto perform meaningfully, regardless of whether thescores are normalized or not.
In view of this, it is re-markable that CORDI achieves a respectable perfor-mance just by utilizing discovered correspondences,having no knowledge of phonetics nor identity ofphonemes.
The precision of CORDI is at the samelevel as the phonetically-based ALINE.
In fact, amethod that combines ALINE and CORDI achievesthe average precision of 0.681 on the same test set(Kondrak, in preparation).In comparison with the results of Filali andBilmes (2005), certain differences are apparent.
Thememory and length models, which performed betterthan the memoriless context-independent model onthe pronunciation task, perform worse overall here.This is especially notable in the case of the lengthmodel which was the best overall performer on theirtask.
The context-dependent model, however, per-formed well on both tasks.As mentioned in (Mann and Yarowsky, 2001),it appears that there are significant differences be-tween the pronunciation task and the cognate iden-49tification task.
They offer some hypotheses as towhy this may be the case, such as noise in the dataand the size of the training sets, but these issues arenot apparent in the task presented here.
The train-ing set was quite large and consisted only of knowncognates.
The two tasks are inherently different, inthat scoring in the pronunciation task involves find-ing the best match of a surface pronunciation withpronunciations in a lexicon, while the cognate taskinvolves the ordering of scores relative to each other.Certain issues, such as length of words, may becomemore prominent in this setup.
We countered this bynormalizing all scores, which was not done in (Filaliand Bilmes, 2005).
As can be seen in Table 2, thenormalization by length appears to improve the re-sults on average.
It notable that normalization evenhelps the length model on this task, despite the factthat it was designed to take word length into account.6 ConclusionWe have compared the effectiveness of a number ofdifferent methods, including the DBN models, onthe task of cognate identification.
The results sug-gest that some of the learning methods, namely thePair HMMs and the averaged context DBN model,outperform the manually designed methods, pro-vided that large training sets are available.In the future, we would like to apply DBNsto other tasks involving computing word similarityand/or alignment.
An interesting next step would beto use them for tasks involving generation, for ex-ample the task of machine transliteration.AcknowledgmentsWe would like to thank Karim Filali for the DBNscripts, and for advice about how to use them.Thanks to Jeff Mielke for making his phoneme sim-ilarity matrix available for our experiments, and forcommenting on the results.
This research was sup-ported by the Natural Sciences and Engineering Re-search Council of Canada.ReferencesLeonard E. Baum, Ted Petrie, George Soules, and Nor-man Weiss.
1970.
A maximization technique occur-ring in the statistical analysis of probabilistic functionof Markov chains.
The Annals of Mathematical Statis-tics, 41(1):164?171.Jeff Bilmes and Geoffrey Zweig.
2002.
The graphicalmodels toolkit: An open source software system forspeech and time-series processing.
In Proc.
IEEE Intl.Conf.
on Acoustics, Speech, and Signal Processing.Isidore Dyen, Joseph B. Kruskal, and Paul Black.
1992.An Indoeuropean classification: A lexicostatistical ex-periment.
Transactions of the American PhilosophicalSociety, 82(5).Karim Filali and Jeff Bilmes.
2005.
A dynamic Bayesianframework to model context and memory in edit dis-tance learning: An application to pronunciation classi-fication.
In Proceedings of ACL 2005, pages 338?345.Brett Kessler.
2001.
The Significance of Word Lists.Stanford: CSLI Publications, Stanford, California.Brett Kessler.
2005.
Phonetic comparison algorithms.Transactions of the Philological Society, 103(2):243?260.Grzegorz Kondrak.
2000.
A new algorithm for thealignment of phonetic sequences.
In Proceedings ofNAACL 2000, pages 288?295.Grzegorz Kondrak.
2002.
Determining recurrent soundcorrespondences by inducing translation models.
InProceedings of COLING 2002, pages 488?494.John Laver.
1994.
Principles of Phonetics.
CambridgeUniversity Press.Wesley Mackay and Grzegorz Kondrak.
2005.
Com-puting word similarity and identifying cognates withPair Hidden Markov Models.
In Proceedings of the9th Conference on Computational Natural LanguageLearning (CoNLL), pages 40?47.Gideon S. Mann and David Yarowsky.
2001.
Multipathtranslation lexicon induction via bridge languages.
InProceedings of NAACL 2001, pages 151?158.Christopher D. Manning and Hinrich Schutze.
2001.Foundations of Statistical Natural Language Process-ing.
The MIT Press.I.
Dan Melamed.
2000.
Models of translational equiv-alence among words.
Computational Linguistics,26(2):221?249.Jeff Mielke.
2005.
Modeling distinctive feature emer-gence.
In Proceedings of the 24th West Cost Confer-ence on Formal Linguistics, pages 281?289.Eric Sven Ristad and Peter N. Yianilos.
1998.
Learn-ing string-edit distance.
IEEE Transactions on PatternAnalysis and Machine Intelligence, 20(5):522?532.Robert A. Wagner and Michael J. Fischer.
1974.
Thestring-to-string correction problem.
Journal of theACM, 21(1):168?173.50
