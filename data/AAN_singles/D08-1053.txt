Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 505?513,Honolulu, October 2008. c?2008 Association for Computational LinguisticsImproved Sentence A lignment on Parallel Web Pages Using aStochastic T ree A lignment ModelLei ShiMicrosoft Research Asia5F Sigma Center, 49 Zhichun Road, Beijing100190, P. R. Chinaleishi@microsoft.com?Ming ZhouMicrosoft Research Asia5F Sigma Center, 49 Zhichun Road, Beijing100190, P. R. Chinamingzhou@microsoft.com?AbstractParallel web pages are important sourceof training data for statistical machinetranslation.
In this paper, we present anew approach to sentence alignment onparallel web pages.
Parallel web pagestend to have parallel structures?and thestructural correspondence can be indica-tive information for identifying parallelsentences.
In our approach, the web pageis represented as a tree, and a stochastictree alignment model is used to exploitthe structural correspondence for sentencealignment.
Experiments show that thismethod significantly enhances alignmentaccuracy and robustness for parallel webpages which are much more diverse andnoisy than standard parallel corpora suchas ?Hansard?.
With improved sentencealignment performance, web mining sys-tems are able to acquire parallel sentencesof higher quality from the web.1 IntroductionSentence-aligned parallel bilingual corpora havebeen essential resources for statistical machinetranslation (Brown et al 1993), and many othermulti-lingual natural language processing applica-tions.
The task of aligning parallel sentences hasreceived considerable attention since the renais-sance of data driven machine translation in late1980s.During the past decades, a number of methodshave been proposed to address the sentence align-ment problem.
Although excellent performancewas reported on clean corpora, they are less robustwith presence of noise.
A recent study by (Singhand Husain 2005) completed a systematic evalua-tion on different sentence aligners under variousconditions.
Their experiments showed that the per-formance of sentence aligners are sensitive toproperties of the text, such as format complexity(presence of elements other than text), structuraldistance (a scale from literal to free translation),the amount of noise (text deletions or preprocess-ing errors) and typological distance between lan-guages.
Their performance varies on different typeof texts and they all demonstrate marked perfor-mance degradation over noisy data.
The resultssuggest that there is currently no universal solutionto sentence alignment under all conditions, anddifferent methods should be applied to differenttypes of texts.In this paper, we specifically address sentencealignment on parallel web pages.
It has come toattention with the increasing trend of acquiringlarge-scale parallel data from the web.
Currently,large-scale parallel data are not readily availablefor most language pairs and domains.
But due to asharply increasing number of bilingual web sites,web mining shows great promise as a solution tothis knowledge bottleneck problem.
Many systems(Ma 1999; Chen 2000; Yang 2002; Resnik 2003;Chen 2004) have been developed to discover paral-lel web pages, and sentence aligners are used toextract parallel sentences from the mined web cor-pora.
Sentence alignment performance on parallelweb pages, therefore, becomes an increasingly im-portant issue for large-scale high-quality paralleldata acquisition.Compared with clean parallel corpora such as"Hansard" (Brown et al 1993), which consists of505French-English translations of political debates inthe Canadian parliament, texts from the web are farmore diverse and noisy.
They are from many dif-ferent domains and of various genres.
Their trans-lation may be non-literal or written in disparatelanguage pairs.
Noise is abundant with frequentinsertions, deletions or non-translations.
And thereare many very short sentences of 1-3 words.
Dueto the characteristics of web corpora, direct appli-cation of conventional alignment methods withoutexploiting additional web document informationyields unsatisfactory alignment results.Our approach to this problem is to make use ofthe structural parallelism between parallel webpages.
Structural parallelism is the phenomenon,that when representing the same content in twodifferent languages, authors have a very strongtendency to use the same document structure.
As isshown in Figure 1, sentences located in similarposition on both pages are more likely to be trans-lations.
Hence, correspondence in the web pagestructure is an informative indication of parallelsentences.
In our approach, the web page isrepresented as a tree, and a stochastic tree align-ment model is used to find the most probablealignment of the tree pair based on their structureand the texts in tree nodes.
The tree alignment thenacts as useful information to constrain the scope ofsearch for parallel sentences.The paper is organized as follows: In section 2,we briefly survey previous approaches to sentencealignment.
In section 3, we present the stochastictree alignment model, including parameter estima-tion and decoding.
Then in section 4, we describehow to use the tree alignment model in sentencealignment.
Benchmarks are shown in section 5,and the paper is concluded in section 6.2 Sentence A lignment ModelsSentence alignment methods can be categorizedinto three major categories: the length-based, lex-icon-based and hybrid method which combines thelength-based model and lexicon-based model ascomplement to each other.The length model was based on the intuition thatthe length of a translated sentence is likely to besimilar to that of the source sentence.
(Brown et.
at.1991) used word count as the sentence length,whereas (Gale and Church 1993) used charactercount.
Dynamic programming is used to search theoptimal sentence alignment.
Both algorithms haveachieved remarkably good results for languagepairs like English-French and English-GermanFigure 1.
Example of parallel web pages506with an error rate of 4% on average.
But they arenot robust with respect to non-literal translations,deletions and disparate language pairs.Unlike the length-based model, which totallyignores word identity, lexicon-based methods uselexical information to align parallel sentences.Kay?s?
(Kay and Roscheisen 1993) approach isbased on the idea that words that are translations ofeach other will have similar distribution in sourceand target texts.
By adopting the IBM model 1,(Chen 1993) used word translation probabilities,which he showed gives better accuracy than thesentence length based method.
Melamed (Me-lamed 1996) rather used word correspondencefrom a different perspective as geometric corres-pondence for sentence alignment.The hybrid method combines the length modelwith the lexical method.
(Simard and Plamondon1996) used a two-pass approach, where the firstpass performs length-based alignment at the cha-racter level as in (Gale and Church 1993) and thesecond pass uses IBM Model 1, following (Chen1993).
Moore?s?
(Moore 2002) approach is similarto Simard?s.
The difference is that Moore used thedata obtained in the first pass to train the IBMmodel in the second pass, so that his approach doesnot require a priori knowledge about the languagepair.
Instead of using a two-pass approach, (Zhaoand Vogel 2002) combines the length model andthe IBM model 1 in a unified framework under amaximum likelihood criterion.
To make it morerobust on noisy text, they developed a backgroundmodel to handle text deletions.To further improve sentence alignment accuracyand robustness, methods that make use of addi-tional language or corpus specific informationwere developed.
In Brown and?
Church?s length-based aligner, they assume prior alignment onsome corpus specific anchor points to constrainand keep the Viterbi search on track.
(Wu 1994)implemented a length-based model for Chinese-English with language specific lexical clues to im-prove accuracy.
(Simard et al 1992) used cognates,which only exists in closely related language pairs.
(Chuang and Yeh 2005) exploited the statisticallyordered matching of punctuation marks in two lan-guages to achieve high accuracy sentence align-ment.
In their web parallel data mining system,(Chen and Nie 2000) used HTML tags in the sameway as cognates in (Simard et al 1992) for align-ing Chinese-English parallel sentences.
Tree basedalignment models have been successfully appliedin machine translation (Wu 1997, Yamada &Knight 2001, Gildea 2003).3 The Stochastic T ree A lignment ModelThe structure of the HTML document is recursive,with HTML markup tags embedded within othermarkup tags.
While converting an HTML docu-ment into the tree representation, such hierarchicalorder is maintained.
Each node of the tree is la-beled with their corresponding HTML tag (e.g.body, title, img etc.)
and in labeling tree nodes,only markup tags are used and attribute value pairsare dropped.
Among all markup tags in the HTMLfile, those of our most interest are tags containingcontent text, which is what we want to align.
Thesetags are those surrounding a text chunk or have theattribute of ?ALT?.
Comments, scripts and stylespecifications are not regarded as content text andhence are eliminated.
Figure 2 illustrates the treerepresentation of an example HTML document.htmlhead bodya#text2divtitle#text1Img#text3.
.
.<html><head><title>text1</title></head><body><a href=?.html?>text2</a><div> ?
?</div><img src=?.jpg?,alt=text3></body></html>Figure.
2 An example HTML document and itstree representation3.1 T ree A lignment ModelGiven two trees, the tree alignment is the non-directional alignments of their nodes.
A node inone tree can be aligned with at most one node inthe other tree.
It is valid for a node to be alignedwith nothing (NULL) and such case is regarded asnode deletion in tree alignment.
To comply withthe tree hierarchical structure, we constrain that thealignments keep the tree hierarchy invariant i.e.
ifnode A is aligned with node B, then the children ofA are either deleted or aligned with the children ofB.
Besides, to simplify the model training and de-coding, the tree alignment model also keeps the507sequential order invariant, i.e.
if node A is alignedwith node B, then the left sibling nodes of A cannotbe aligned with the right sibling nodes of B.The stochastic tree alignment model assignsprobabilities to tree alignments, based on the par-ticular configuration of the alignment and modelparameters.
Then, the decoder is able to find themost probable (optimal) alignment of two trees.
Tofacilitate the presentation of the tree alignmentmodel, the following symbols are introduced: giv-en a HTML document D, ?
?denotes the corres-ponding tree; ???
denotes the ith node of ???
,and????
?denotes the sub-tree rooted at????
.
Espe-cially, ?1?
?is the root of the tree???
.
?[?
,?
]?
?denotesthe forest consisting of the sub-trees rooted at sibl-ing nodes from ???
to????.
???
.
?
denotes the text inthe node ???
, and ???
.
?
denotes the label (i.e.HTML tag) of the node????
; ???
.??
denotes the jthchild of the node ????
; ???
.?[?
,?]
denotes the con-secutive sequence of ????
?s?
children?
nodes?
from????
.??
to????
.??
; the sub-tree rooted at ???
.??
isrepresented as ???
.???
and the forest of the sub-trees rooted at ????
?s?
children?
is?
represented?
as????
.??.
To accommodate node deletion, NULL isintroduced to denote the empty node.
Finally, thetree alignment is referred as A.Given two HTML documents F (in French) andE (in English) represented as trees ??and??
?, thetree alignment task is defined as finding the align-ment A that maximizes the conditionalprobability ?Pr(?|??
,??)
.
Based on the Bayes?Rule, Pr(?|??
,??)
?
?Pr(??
,??|?)Pr(?)
, wherePr(??
,??|?)
is the probability of synchronouslygenerating ??
and ??
given the alignment A, andPr(?)
is the prior knowledge of the tree alignment.To simplify computation, we assume a uniformprior probability Pr(?).
Hence, the tree alignmenttask is to find the A that maximizes the synchron-ous probability?Pr(??
,??|?
).Based on the hierarchical structure of the tree, inorder to facilitate the presentation and computationof the tree alignment probabilistic model, the fol-lowing alignment probabilities are defined in a hie-rarchically recursive manner:Pr(???
,???|?)
: The probability of synchronouslygenerating sub-tree pair {???
,???}
given the align-ment A;Pr(???
,???|?
): The probability of synchronouslygenerating node pair?{???
,???};Pr(?[?
,?]?
,?[?
,?
]?
|?)
: The probability of synchron-ously generating forest pairs {?[?
,?]?
,?[?
,?
]? }
giventhe alignment A.From the definition, the tree pair generativeprobability ?Pr(??
,??|?)
equals to the root sub-tree pair generative probability?Pr(?1?
,?1?|?).
Thealignment of the sub-tree pair ??
?and ???
may havethe following configurations, based on which thetree pair generative probability Pr(???
,???|?)
canbe calculated:(1) If????
?is aligned with ???
, and the children of???
?
are aligned with children of ???
(as isshown in Fig.
3a), then we have?Pr????
,??????
= Pr(???
,???)Pr(???
.??,???
.??|?
)(2) If ????
is deleted, and the children of ???
isaligned with ???
(as shown in Fig.
3b), then wehavePr????
,??????
= Pr(???
|????)Pr(???
.??,???|?
)(3) If ??
?is deleted, and????
is aligned with child-ren of ???
(as shown in Fig.
3c), then we havePr(???
,???|?)
= Pr(???
,???
.??|?)Pr(???|????
)(a)(b)NULL(c)NULLFmT FmTFmT EiT EiT EiTFigure.
3The above equations involve forest pair generativeprobabilities.
The alignment of the forest?[?
,?]?
?and ?[?
,?
]?
may have the following configura-tions, based on which their forest pair generativeprobability?Pr(?[?
,?]?
,?[?
,?
]?
|?
)?can be calculated:508(4) If ???
is aligned with ???
, and ?[?+1,?]?
isaligned with ?[?+1,?
]?
(as is shown in Fig.
4a),thenPr??[?
,?]?
,?[?,?
]?
??
?= Pr(???
,???|?)Pr(?[?+1,?]?
,?[?+1,?
]?
|?
)(5) If????
is deleted, and the forest rooted at????
?s?children ???
.??
?is combined with ?[?+1,?]?
foralignment with ?[?
,?
]?
, thenPr??[?
,?]?
,?[?,?
]?
??
?= Pr(???
|????)Pr(???
.????[?+1,?]?
,?[?,?
]?
|?
)(6) If????
is deleted, and the forest rooted at????
?s?children ????
.??
is combined with ?[?
,?
]?
foralignment with ?[?
,?]?
, thenPr??[?
,?]?
,?[?,?
]?
??
?= Pr(???|????)Pr(?[?
,?]?
,???
.????[?+1,?
]?
|?
)(a)E j]1,[iT ?Ei?F n]1,[mT ?Fm?
(b)Ej][i,TF n]1,[mT ?Fm?
.CFTFm(c)Ei?F n][m,T E j]1,[iT ?.CFTEiNULLNULLFigure.
4Finally, the node pair probability is modeledas ?Pr(???
,???)
= Pr(???
.
?,???
.
?)Pr(???
.
?,???
.
?)
,where Pr(???
.
?,???
.
?
)?is the generative probabilityof the translationally equivalent text chunksin????
?and????
, and Pr(???
.
?,???
.
?)?
is their HTMLtag pair probability.
The text chunk generativeprobability Pr(???
.
?,???
.
?)
can be modeled in avariety of ways.
The conventional length-based,lexicon-based or hybrid methods used for sentencealignment can be applied here.
In the next sub-section, we focus on how to estimate the tag pairprobability?Pr(???
.
?,???
.
?)?
from a set of parallelweb pages.
We expect pairs of the same or similarHTML tags to have high probabilities and theprobabilities for pairs of disparate tags to be low.3.2 Parameter Estimation Using Expectation-MaximizationOne way to estimate the tag pair generative proba-bility Pr(?, ??)?
is to manually align nodes betweenparallel trees, and use the manually aligned trees asthe training data for maximum likelihood estima-tion.
However, this is a time-consuming and error-prone procedure.
Instead, the Expectation Maximi-zation (EM) (Dempster, Laird and Rubin 1977)algorithm is used to estimate theparameters ?Pr(?, ??)?
on 5615 manually verifiedparallel web page pairs from 45 different bilingualweb sites.
The parameter estimation proceeds asfollows:1.
Start with initial parameter values.2.
Expectation: estimate count???????
(?, ??
)?which isthe expectation of aligning tag l with 'l .3.
Maximization: update the parameters basedto maximum likelihood estimation?
?
?
??
???
'''',,,Prlllcountllcountll   and?
?
?
??
?
?
??
???'],,[,,)Pr(''lNULLlcountlNULLcountNULLlcountlNULLcountNULLl4.
Repeat step 2 and 3 until the parametersstabilizeIn step 2, count???????
(?, ?? )
is the expected count of lbeing aligned with 'l  in the training corpus.
Bydefinition, count???????
(?, ?? )
is calculated ascount???????
(?, ?? )
= ?Pr(?|???,??
)count(?, ??
)where  count(?, ?? )
is the number of occurrence of lbeing aligned with l?
in the tree alignment A.To efficiently compute count???????
(?, ?? )
withoutenumerating?the?exponential?number?of?A?s?in?the?above equation, we extended the inside-outsidealgorithm presented in (Lari and Young, 1990).The inside probability ?(???
,???)
is defined as the509probability of generating sub-tree pair {???
,???
}when ???
is aligned with????
.
It is estimated as:?
?
?
?
?
?CFNCFNNNNN EiFmEiFmEiFm .,.,Pr, ??
?where ?(???
.??,???
.??)
is the inside probabilityfor the forest pair?(???
.??,???
.??)?
?
?
??
?AEiFmEiFm ACFNCFNCFNCFN .,.Pr.,.?
.The inside probability can be estimated recursivelyaccording to the various alignment configurationspresented in Figure 3 and Figure 4.
The outsideprobability??(???
,???)
is defined as the probabilityof generating the part of ?
?and ??
?excluding thesub-trees ???and????
, when ???
is aligned with????
.It is estimated as:?
?
?
??
?
?
??
??
?
?
??
??
???
????
?qk pkEkiFkmEiEpiFmFqmEiEpiFmFqmqpEpiFqmEiFmNULLaNULLaNRC FaNRC FaNLC FaNLC FaaaNN])|Pr()|Pr(.,..,.,[,,,,,,,,,,???
?where ??
,??
is the qth  ancestor of ???
, and ??
,??
isthe pth ancestor of ???
.
??
,??
(?
< ?)
is an ancestorof ???
?and a decedent of ???
,??
.
Similarly ??
,??
(?
<??
is an ancestor of ??
?, and a decedent of ??,?
?.a.LC F(N) is the forest rooted at a and to the left ofN, and a.RC F(N).
a.RC F(N) is the forest rooted asa and to the right of N. Once inside and outsideprobabilities are computed, the expected countscan be calculated as?
?
?
?
?
??
??
????EFFmEiTTllNllNEFEiFmEiFmTTNNNNllcount,..''
),Pr(,,,?
?where Pr(??
,??
)?is the generative probability ofthe tree pair {??
,??}
over all possible alignmentconfigurations.
Pr(??
,??
)?can be estimated usingdynamic programming techniques that will be pre-sented in the next sub-section.
Furthermore, theexpected count of tag deletion is estimated as:count???????(?,????)
= ?
count(?, ??
)??
?
count???????
(?, ??
)??????count???????(???
?, ?)
= ?
count(??
, ?)??
?
count???????(??
, ?)?????
?3.3 Dynamic Programming for DecodingAn intuitive way to find the optimal tree alignmentis to enumerate all alignments and pick the onewith the highest probability.
But it is intractablesince the total number of alignments is exponential.Based on the observation that if two trees are op-timally aligned, the alignment of their sub-treesmust also be optimal, dynamic programming canbe applied to find the optimal tree alignment usingthat of the sub-trees in a bottom-up manner.
That iswe first compute the optimal alignment probabili-ties of small trees and use them to compute that ofthe bigger tree by trying different alignment confi-gurations.
This procedure is recursive until the op-timal alignment probability of the whole tree isobtained.
The following is the pseudo-code of thebottom-up decoding algorithm:where |?
?| and |?
?| are the number of nodes in?
?and ??
.
The decoding algorithm finds the op-timal alignment and its probability for every sub-trees and forests.
By replacing the selection opera-tion with summing probabilities of all configura-tions, the sub-tree pair generative probabilityPr(??
,??)
can be calculated along the way.
Theworst-case time complexity of the algorithmis ??(|??||??|?????(??
)+ ????(??
)?2) , wherethe degree of a tree is defined as the largest degreeof its nodes.4 Sentence A lignment with T ree A lign-ment ModelSince the tree alignment model aligns parallel webpages at the tree node level instead of the sentencelevel, we integrate the tree alignment model withthe sentence alignment model in a cascaded mode,in which the whole sentence alignment process isdivided into two steps.
In the first step, the treealignment decoder finds the optimal alignment ofthe two trees.
Nodes having texts should be alignedwith nodes containing their translations.
Then inthe second step, the conventional sentence aligneris used to align sentences within text chunks in thefor i=|?
?| to 1 (bottom-up) {for j=|?
?|?to 1 (bottom-up) {Select and store optimal alignments of their children fo-rests ????
.
CF?and ????
.
CFby testing configurations 4-6;Select and store the optimal alignment of the sub-treepair ????
and????
?by testing configurations 1-3;Store the optimal configuration}}510aligned nodes.
In this step, various sentence align-ment models can be applied, including the length-based model, the lexicon-based model and the hy-brid model.
Language or corpus specific informa-tion may also be used to further improve sentencealignment accuracy.
The tree alignment acts asconstraints that confine the scope of the search ofsentence aligners.5 EvaluationTo evaluate the effectiveness of exploiting webpage document structure with the tree alignmentmodel for improving sentence alignment accuracy,we compared the performance of three types ofsentence alignment methods on parallel web pages.The first type is to simply discard web pagelayout information.
Web pages are converted toplain texts, and HTML tags are removed prior toperforming sentence alignment.
The second type isthe baseline method of using web page documentinformation.
Instead of exploiting full HTML doc-ument structure, it follows Chen?s?approach?
(Chenand Nie 2000) which uses HTML tags in the sameway as cognates used in (Simard et al 1992).
Thethird type is the combination of tree alignmentmodel and conventional sentence models.Each type of the web page sentence alignermakes use of three conventional sentence align-ment models, one is the length based model fol-lowing (Brown 1991), one is the lexicon basedmodel following (Chen 1993), and the other one isthe hybrid model presented in (Zhao 2002).
To befair in performance comparisons, the text genera-tive probability Pr(??
.
?,??
.
?)
in tree nodealignment is modeled in accordance with that inthe sentence alignment model.
All these sentencealigners are implemented to handle sentence beadtypes?of??1-0?,??0-1?,?1-1?,??1-2?,?1-3?,?2-1??and?
?3-1?.The test corpus is 150 parallel web page pairsrandomly drawn from 20 Chinese-English bilin-gual web sites on topics related to politics, sports,computer and literature.
By manual annotation,9,824 parallel sentence pairs are found.
All sen-tence aligners run through the test parallel webpages, and each extracts a set of sentence pairs thatit regards as parallel.
The output pairs are matchedwith the annotated parallel sentences from the testcorpus.
Only exact matches of the sentence pairsare counted as correct.Our evaluation metrics are precision (P), recall(R) and F-measure (F) defined as:pairsoutput   totalof #pairs sentence alignedcorrectly  of #P ?pairs parallel  trueof #pairs sentence alignedcorrectly  of #R ?RPR*P*2F ?
?Based on the results in table 1, we can see thatboth Type 2 and Type 3 aligners outperform con-ventional sentence alignment models.
LeveragingHTML document information can enhance sen-tence alignment quality.
Especially, by using thetree alignment model, Type 3 aligners achieve asignificant increase of around 7% on both preci-sion and recall.
Compared with the tree alignmentmodel, the improvement by the Type 2 aligners ismarginal.
A reason for this is that the tree align-ment model not only exploits HTML tag similari-ties as in the Type 2 method, but also takes intoaccount location of texts.
In the tree alignmentmodel, texts at similar locations in the tree hierar-chical structure are more probable to be transla-tions than those in disparate locations, even thoughthey all have the same tag.We also evaluate the performance of the treealigner.
Since sentence alignment is performedwithin the text chunks of aligned nodes, treealignment accuracy is very important for correctsentence alignment.
We measure the alignmentLength Lexicon HybridP R F P R F P R FType I 85.6% 72.8% 78.7% 83.1% 75.2% 78.9% 87.3% 76.4% 81.5%Type II 86.3% 74.8% 80.1% 85.7% 77.0% 81.1% 88.1% 78.6% 83.1%Type III 93.2% 79.3% 85.7% 92.9% 80.4% 86.2% 94.3% 83.1% 88.3%Table 1.
Performance comparison between different types of sentence alignment methods511accuracy on all nodes as well as that specificallyon text nodes on the test corpus.
The evaluationresult is shown in table 2.Benchmarks in Table 2 show that the treealignment model yields very reliable results withhigh accuracy in aligning both text nodes and non-text nodes.
After an analysis on text node align-ment errors, we find that 79.7% of them have textsof very short length (no more than 4 words), whichmay not contain sufficient information to be identi-fied as parallel.6 ConclusionsIn this paper, we present a new approach to sen-tence alignment on parallel web pages.
Due to thediversity and noisy nature of web corpora, a sto-chastic tree alignment model is employed to ex-ploit document structure in parallel web pages asuseful information for identifying parallel sen-tences.
The tree alignment model can be combinedwith various conventional sentence alignmentmodels to extract parallel sentences from parallelweb pages.
Experimental results show that exploit-ing structural parallelism inherent in parallel webpages provides superior alignment performanceover conventional sentence alignment methods andsignificant improvement (around 7% in both preci-sion and recall) is achieved by using the stochastictree alignment model.
With improved sentencealignment performance, web parallel data miningsystems are able to acquire parallel sentences ofhigher quality and quantity from the web.References:Brown, P. F., J. C. Lai and R. L. Mercer.
1991.
AligningSentences in Parallel Corpora .
Proceedings of ACL1991.Brown, P. E., S. A. D. Pietra, V. J. D. Pietra, and R. L.Mercer.
1993.
The Mathematics of Statistical Ma-chine Translation: Parameter Estimation, Computa-tional Linguistics V19(2), 1993Chen Jisong., Chau R. and C.-H. Yeh.
2004.
Discover-ing Parallel Text from the World Wide Web, Proceed-ings of the second workshop on Australasian Infor-mation Security, Data Mining and Web Intelligence,and Software Internationalization.Chen Jiang and Nie Jianyun.
2000.
Automatic construc-tion of parallel English-Chinese corpus for cross-language information retrieval.
Proceedings of thesixth conference on applied natural languageprocessingChen Stanley.
1993.
Aligning Sentences in BilingualCorpora Using Lexical Information.
Proceedings ofACL 1993Chuang T.C.
and Yeh.K.C.
2005.
Aligning Parallel Bi-lingual Corpora Statistically with Punctuation Crite-ria.
Computational Linguistics and Chinese Lan-guage Processing.
Vol.
10, 2005, pp.
95-122Dempster, A., Laird, N., and Rubin, D. 1977.
Maximumlikelihood from incomplete data via the EM algo-rithm.
Journal of the Royal Statistical Society, SeriesB, 39(1):1?38.Gale W. A. and K. Church.
1993.
A Program for Align-ing Sentences in Parallel Corpora, ComputationalLinguistics, 19(1):75?102Gildea.
D. 2003.
Loosely Tree-Based Alignment forMachine Translation.
In Proceedings of ACL 2003Kay Martin and Roscheisen Martin 1993.
Text Transla-tion Alignment.
Computational Linguistics19(1):121--142.Lari K. and S. J.
Young.
1990.
The estimation of sto-chastic context free grammars using the Inside-Outside algorithm, Computer Speech and Language,4:35?56Ma, Xiaoyi and M. Liberman.
1999.
Bits: A Method forBilingual Text Search over the Web.
Proceedings ofMachine Translation Summit VII.Melamed.
I. Dan.
1996.
A Geometric Approach toMapping Bitext Correspondence .
Proceedings ofEMNLP 96Moore Robert.
C. 2002.
Fast and Accurate SentenceAlignment of Bilingual Corpora .
Proceedings of 5thConference of the Association for Machine Transla-tion in the Americas, pp.
135-244Resnik, P. and N.A.
Smith.
2003.
The Web as a ParallelCorpus.Computational Linguistics, 29(3)Simard, M. and Plamondon, P. 1996 Bilingual SentenceAlignment: Balancing Robustness and Accuracy.Proceedings of AMTA-96, Canada.Simard, M., Foster, G. and Isabelle, P. 1992, UsingCognates to Align Sentences in Bilingual Corpora .Proceedings of the Fourth International Conferencetotal correct accuracyall node alignment 18492 17966 97.2%text node alignment 3646 3577 98.1%Table 2.
Tree Alignment Metrics512on Theoretical and Methodological Issues in Ma-chine translation (TMI92)Singh, A. K. and Husain, S. (2005).
Comparison, selec-tion and use of sentence alignment algorithms fornew language pairs.
Proceedings of the ACL Work-shop on Building and Using Parallel Texts.Wu.
Dekai.
1994.
Aligning a parallel English-Chinesecorpus statistically with lexical criterias.
Proceedingsof ACL 1994.Wu.?Dekai.?
?Stochastic Inversion Transduction Gram-mar and Bilingual Parsing of Parallel Corpora?
?Computational Linguistics, 23(3):374(1997)Yamada H. and Knight K. 2001 A Syntax based statis-tical translation model.
In Proceedings of ACL-01Yang C. C., and Li K. W., Mining English/Chinese Pa-rallel Documents from the World Wide Web, Pro-ceedings of the International World Wide Web Con-ference, Honolulu, Hawaii, 2002.Zhao Bin.
and Stephan.
Vogel.
2002.
Adaptive ParallelSentences Mining F rom Web Bilingual News Collec-tion.
2002 IEEE International Conference on DataMining.
745-748513
