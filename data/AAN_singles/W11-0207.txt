Proceedings of the 2011 Workshop on Biomedical Natural Language Processing, ACL-HLT 2011, pages 56?64,Portland, Oregon, USA, June 23-24, 2011. c?2011 Association for Computational LinguisticsMedical Entity Recognition:A Comparison of Semantic and Statistical MethodsAsma Ben AbachaLIMSI-CNRSBP 133, 91403 Orsay Cedex, Franceasma.benabacha@limsi.frPierre ZweigenbaumLIMSI-CNRSBP 133, 91403 Orsay Cedex, Francepz@limsi.frAbstractMedical Entity Recognition is a crucial steptowards efficient medical texts analysis.
Inthis paper we present and compare threemethods based on domain-knowledge andmachine-learning techniques.
We study tworesearch directions through these approaches:(i) a first direction where noun phrases areextracted in a first step with a chunker be-fore the final classification step and (ii) a sec-ond direction where machine learning tech-niques are used to identify simultaneously en-tities boundaries and categories.
Each of thepresented approaches is tested on a standardcorpus of clinical texts.
The obtained resultsshow that the hybrid approach based on bothmachine learning and domain knowledge ob-tains the best performance.1 IntroductionMedical Entity Recognition (MER) consists in twomain steps: (i) detection and delimitation of phrasalinformation referring to medical entities in textualcorpora (e.g.
pyogenic liver abscess, infection of bil-iary system) and (ii) identification of the semanticcategory of located entities (e.g.
Medical Problem,Test).
Example 1 shows the result of MER on a sen-tence where the located entity and its category aremarked with treatment and problem tags.
(1) <treatment> Adrenal-sparing surgery</treatment> is safe and effective , and maybecome the treatment of choice in patientswith <problem> hereditaryphaeochromocytoma </problem>.This task is very important for many applicationssuch as Question-Answering where MER is used inthe question analysis step (to determine the expectedanswers?
type, the question focus, etc.)
and in theoffline text tagging or annotation.One of the most important obstacles to identify-ing medical entities is the high terminological vari-ation in the medical domain (e.g.
Diabetes melli-tus type 1, Type 1 diabetes, IDDM, or juvenile di-abetes all express the same concept).
Other aspectsalso have incidence on MER processes such as theevolution of entity naming (e.g.
new abbreviations,names for new drugs or diseases).
These obstacleslimit the scalability of methods relying on dictionar-ies and/or gazetteers.
Thus, it is often the case thatother types of approaches are developed by exploit-ing not only domain knowledge but also domain-independent techniques such as machine learningand natural language processing tools.In this paper, we study MER with three dif-ferent methods: (i) a semantic method relying onMetaMap (Aronson, 2001) (a state-of-the-art toolfor MER) (ii) chunker-based noun phrase extractionand SVM classification and (iii) a last method us-ing supervised learning with Conditional RandomFields (CRF), which is then combined with the se-mantic method.
With these methods we particularlystudy two processing directions: (i) pre-extractionof noun phrases with specialized tools, followed bya medical classification step and (ii) exploitationof machine-learning techniques to detect simultane-ously entity boundaries and their categories.We also present a comparative study of the perfor-mance of different noun phrase chunkers on medical56texts: Treetagger-chunker, OpenNLP and MetaMap.The best chunker was then used to feed some ofthe proposed MER approaches.
All three methodswere experimented on the i2b2/VA 2010 challengecorpus of clinical texts (Uzuner, 2010).
Our studyshows that hybrid methods achieve the best perfor-mance w.r.t machine learning approaches or domainknowledge-based approaches if applied separately.After a review of related work (Section 2), we de-scribe the chunker comparison and the three MERmethods (Section 3).
We present experiments onclinical texts (Section 4), followed by a discussionand variant experiments on literature abstracts (Sec-tion 5), then conclude and draw some perspectivesfor further work (Section 6).2 Related WorkSeveral teams have tackled named entity recognitionin the medical domain.
(Rindflesch et al, 2000) pre-sented the EDGAR system which extracts informa-tion about drugs and genes related to a given can-cer from biomedical texts.
The system exploits theMEDLINE database and the UMLS.
Protein nameextraction has also been studied through several ap-proaches (e.g.
(Liang and Shih, 2005; Wang, 2007)).
(Embarek and Ferret, 2008) proposed an approachrelying on linguistic patterns and canonical entitiesfor the extraction of medical entities belonging tofive categories: Disease, Treatment, Drug, Test, andSymptom.
Another kind of approach uses domain-specific tools such as MetaMap (Aronson, 2001).MetaMap recognizes and categorizes medical termsby associating them to concepts and semantic typesof the UMLS Metathesaurus and Semantic Network.
(Shadow and MacDonald, 2003) presented an ap-proach based on MetaMap for the extraction of med-ical entities of 20 medical classes from pathologistreports.
(Meystre and Haug, 2005) obtained 89.9%recall and 75.5% precision for the extraction of med-ical problems with an approach based on MetaMapTransfer (MMTx) and the NegEx negation detectionalgorithm.In contrast with semantic approaches which re-quire rich domain-knowledge for rule or pattern con-struction, statistical approaches are more scalable.Several approaches used classifiers such as decisiontrees or SVMs (Isozaki and Kazawa, 2002).
Markovmodels-based methods are also frequently used (e.g.Hidden Markov Models, or CRFs (He and Kayaalp,2008)).
However, the performance achieved by suchsupervised algorithms depends on the availability ofa well-annotated training corpus and on the selectionof a relevant feature set.Hybrid approaches aim to combine the advan-tages of semantic and statistical approaches and tobypass some of their weaknesses (e.g.
scalabilityof rule-based approaches, performance of statisticalmethods with small training corpora).
(Proux et al,1998) proposed a hybrid approach for the extractionof gene symbols and names.
The presented systemprocessed unknown words with lexical rules in orderto obtain candidate categories which were then dis-ambiguated with Markov models.
(Liang and Shih,2005) developed a similar approach using empiri-cal rules and a statistical method for protein-namerecognition.3 Medical Entity Recognition ApproachesNamed entity recognition from medical texts in-volves two main tasks: (i) identification of entityboundaries in the sentences and (ii) entity catego-rization.
We address these tasks through three mainapproaches which are listed in Table 1.3.1 Noun Phrase ChunkingAlthough noun phrase segmentation is an importanttask for MER, few comparative studies on availabletools have been published.
A recent study (Kang etal., 2010), which claims to be the first to do suchcomparative experiments, tested six state-of-the-artchunkers on a biomedical corpus: GATE chunker,Genia Tagger, Lingpipe, MetaMap, OpenNLP, andYamcha.
This study encompassed sentence split-ting, tokenization and part-of-speech tagging andshowed that for both noun-phrase chunking andverb-phrase chunking, OpenNLP performed best (F-scores 89.7% and 95.7%, respectively), but differ-ences with Genia Tagger and Yamcha were small.With a similar objective, we compared the perfor-mance of three different noun-phrase chunkers in themedical domain: (i) Treetagger-chunker1, a state-of-the-art open-domain tool, (ii) OpenNLP2 and (iii)1http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger2http://incubator.apache.org/opennlp57Medical Entity Recognition1.
Boundaryidentification2.
Type categorization(with n medical entity categories)Method 1(MetaMap+)Noun phrasesegmentation- Rule-based method,- Noun phrase classification,- Number of classes = n + 1Method 2(TT-SVM)Noun phrasesegmentation- Statistical method with a SVM classifier,- Noun phrase classification,- Number of classes = n + 1Method 3(BIO-CRF)- Statistical method with a CRF classifier,- and the BIO format,- word-level classification,- Number of classes = 2n + 1Table 1: Proposed MER methodsCorpus of clinical texts (i2b2) Corpus of scientific abstracts (Berkeley)MetaMap TreeTagger OpenNLP MetaMap TreeTagger OpenNLPReference entities 58115 58115 58115 3371 3371 3371Correct entities 6532 35314 26862 151 2106 1874Found entities 212227 129912 122131 22334 19796 18850Recall 11.14% 60.06% 46.62% 4.48% 62.27% 55.59%Table 2: NP Segmentation ResultsMetaMap.
Regardless of the differences in corporawith (Kang et al, 2010) we chose these particu-lar tools to compare medical-domain specific toolswith open domain tools and to highlight the lowerperformance of MetaMap for noun-phrase chunk-ing compared to other tools.
This last point ledus to introduce the MetaMap+ approach for MER(Ben Abacha and Zweigenbaum, 2011) in order totake advantage of MetaMap?s domain-knowledgeapproach while increasing performance by relyingon external tools for noun-phrase chunking.We evaluate these tools on the subset of nounphrases referring to medical entities in our corpora(cf.
Section 4.1 for a description of the i2b2 cor-pus and Section 5 for the Berkeley corpus).
Weconsider that a noun phrase is correctly extracted ifit corresponds exactly to an annotated medical en-tity from the reference corpora.
Also, as our cor-pora are not fully annotated (only entities of the tar-geted types are annotated), we do not evaluate ?extranoun-phrases?
corresponding to non-annotated enti-ties.
The retrieved noun phrases are heterogeneous:many of them are not all relevant to the medical fieldand therefore not relevant to the MER task.
Ourgoal is to obtain the maximal number of correct nounphrases and leave it to the next step to filter out thosethat are irrelevant.
We therefore wish to maximizerecall at this stage.Table 2 shows that in this framework, Treetagger-chunker obtains the best recall.
We thus used itfor noun-phrase segmentation in the experimentedMER approaches (cf.
Sections 3.2 and 3.3).3.2 Semantic and Rule-Based Method: MM+MetaMap is a reference tool which uses the UMLSto map noun phrases in raw texts to the best match-ing UMLS concepts according to matching scores.MetaMap leads however to some residual problems,which we can arrange into three classes: (i) nounphrase chunking is not at the same level of per-formance as some specialized NLP tools, (ii) med-ical entity detection often retrieves general wordsand verbs which are not medical entities and (iii)some ambiguity is left in entity categorization sinceMetaMap can provide several concepts for the sameterm as well as several semantic types for the sameconcept.
Several ?term/concept/type?
combinations58are then possible.To improve MetaMap output, we thereforeuse an external noun phrase chunker (cf.
Sec-tion 3.1) and stop-list based filtering to recover fre-quent/noticeable errors.
MetaMap can propose dif-ferent UMLS semantic types for the same nounphrase, thus leading to different categories for thesame entity.
In such cases we apply a voting pro-cedure.
For instance, if the process retrieves threeUMLS semantic types for one noun phrase wheretwo are associated to the target category ?Problem?and one is associated to ?Treatment?, the ?Problem?category is chosen as the entity?s category.
In caseof a tie, we rely on the order output by MetaMap andtake the first returned type.More precisely, our rule-based method, which wecall MetaMap+ (MM+), can be decomposed into thefollowing steps:1.
Chunker-based noun phrase extraction.
Weuse Treetagger-chunker according to the above-mentioned test (cf.
Table 2).2.
Noun phrase filtering with a stop-word list.3.
Search for candidate terms in specialized listsof medical problems, treatments and testsgathered from the training corpus, Wikipedia,Health on the Net and Biomedical Entity Net-work.4.
Use MetaMap to annotate medical entities(which were not retrieved in the specializedlists) with UMLS concepts and semantic types.5.
Finally, filter MetaMap results with (i) a listof common/noticeable errors and (ii) the selec-tion of only a subset of semantic types to lookfor (e.g.
Quantitative Concept, Functional Con-cept, Qualitative Concept are too general se-mantic types and produce noise in the extrac-tion process).3.3 Statistical Method: TT-SVMThe second presented approach uses Treetagger-chunker to extract noun phrases followed by a ma-chine learning step to categorize medical entities(e.g.
Treatment, Problem, Test).
The problem isthen modeled as a supervised classification task withn + 1 categories (n is the number of entity cate-gories).
We chose an SVM classifier.As noted by (Ekbal and Bandyopadhyay, 2010),SVMs (Support Vector Machines) have advantagesover conventional statistical learning algorithms,such as Decision Trees or Hidden Markov Mod-els, in the following two aspects: (1) SVMs havehigh generalization performance independent of thedimension of feature vectors, and (2) SVMs allowlearning with all feature combinations without in-creasing computational complexity, by introducingkernel functions.In our experiments we use the libSVM (Changand Lin, 2001) implementation of the SVM classi-fier.
We chose the following feature set to describeeach noun phrase (NP):1.
Word features:?
words of the NP?
number of the NP words?
lemmas of the NP words?
3 words and their lemmas before the NP?
3 words and their lemmas after the NP2.
Orthographic features (some examples):?
first letter capitalized for the first word,one word or all words?
all letters uppercase for the first word, oneword or all words?
all letters lowercase for the first word, oneword or all words?
NP is or contains an abbreviation?
word of NP contains a single upper-case, digits, hyphen, plus sign, amper-sand, slash, etc.3.
Part-of-speech tags: POS tags of the NP words,of the 3 previous and 3 next words.3.4 Statistical Method: BIO-CRFWe conducted MER with a CRF in one single stepby determining medical categories and entity bound-aries at the same time.
We used the BIO format: B(beginning), I (inside), O (outside) which representsentity tagging by individual word-level tagging.
Forinstance, a problem-tagged entity is represented asa first word tagged B-P (begin problem) and other59(following) words tagged I-P (inside a problem).
Aproblem entity comprising one single word will betagged B-P.
Words outside entities are tagged withthe letter ?O?.If we have n categories (e.g.
Problem, Treatment,Test), we then have n classes of type B-, n classesof type I- (e.g.
P-B and P-I classes associated to theproblem category) and one class of type ?O?.
Fig-ure 1 shows an example sentence tagged with theBIO format.
As a result, the classification task con-sists in a word classification task (instead of a noun-phrase classification task) into 2n+1 target classes,where n is the number of categories.
As a conse-quence, relying on a chunker is no longer necessary.Figure 1: BIO Format (T = Test, P = Problem)Words in a sentence form a sequence, and the de-cision on a word?s category can be influenced bythe decision on the category of the preceding word.This dependency is taken into account in sequentialmodels such as Hidden Markov Models (HMMs) orConditional Random Fields (CRF).
In contrast withHMMs, CRF learning maximizes the conditionalprobability of classes w.r.t.
observations rather thantheir joint probability.
This makes it possible to useany number of features which may be related to allaspects of the input sequence of words.
These prop-erties are assets of CRFs for several natural languageprocessing tasks, such as POS tagging, noun phrasechunking, or named entity recognition (see (Tellierand Tommasi, 2010) for a survey).In our experiments we used the CRF++3 imple-mentation of CRFs.
CRF++ eases feature descrip-tion through feature templates.
We list hereaftersome of our main features.
We instructed CRF++ tomodel the dependency of successive categories (in-struction B in feature template).For each word we use the following features:3http://crfpp.sourceforge.net/1.
Word features: The word itself, two words be-fore and three words after, with their lemmas.2.
Morphosyntactic features: POS tag of the worditself, two words before and three words after.3.
Orthographic features (some examples):?
The word contains hyphen, plus sign, am-persand, slash, etc.?
The word is a number, a letter, a punctua-tion sign or a symbol.?
The word is in uppercase, capitalized, inlowercase (AA, Aa, aa)?
Prefixes of different lengths (from 1 to 4)?
Suffixes of different lengths (from 1 to 4)4.
Semantic features: semantic category of theword (provided by MetaMap+)5.
Other features: next verb, next noun, wordlength over a threshold, etc.Additionally, we tested semantic features con-structed from MM+ results.
More detail on theselast features is given in Section 5.3.4 Experiments on Clinical TextsWe performed MER experiments on English clinicaltexts.4.1 CorpusThe i2b2 corpus was built for the i2b2/VA 2010challenge4 in Natural Language Processing for Clin-ical Data (Uzuner, 2010).
The data for this challengeincludes discharge summaries from Partners Health-Care and from Beth Israel Deaconess Medical Cen-ter (MIMIC II Database), as well as discharge sum-maries and progress notes from University of Pitts-burgh Medical Center.
All records have been fullyde-identified and manually annotated for concept,assertion, and relation information.
The corpus con-tains entities of three different categories: Problem,Treatment and Test, 76,665 sentences and 663,476words with a mean of 8.7 words per sentence.
Ex-ample 2 shows an annotated sentence from the i2b2corpus.4http://www.i2b2.org/NLP/Relations/60(2) <problem>CAD</problem> s/p<treatment>3v-CABG </treatment> 2003and subsequent <treatment>stenting</treatment> of<treatment>SVG</treatment> and LIMA.Table 3 presents the number of training and test sen-tences.i2b2 Corpus Sentences WordsTraining Corpus 31 238 267 304Test Corpus 44 927 396 172Table 3: Number of training and test sentences4.2 Experimental SettingsWe tested the above-described five configurations(see Table 1):1.
MM: MetaMap is applied as a baseline method2.
MM+: MetaMap Plus (semantic and rule-basedmethod)3.
TT-SVM: Statistical method, chunking withTreetagger and Categorization with a SVMclassifier4.
BIO-CRF: Statistical method, BIO format witha CRF classifier5.
BIO-CRF-H: Hybrid method combining se-mantic and statistical methods (BIO-CRF withsemantic features constructed from MM+ re-sults)We evaluate the usual metrics of Recall (proportionof correctly detected entities among the referenceentities), Precision (proportion of correctly detectedentities among those output by the system), and F-measure (harmonic means of Recall and Precision).4.3 ResultsTable 4 presents the results obtained by each con-figuration.
BIO-CRF and BIO-CRF-H obtained thebest precision, recall and F-measures.
MM+ comesnext, followed by TT-SVM and MetaMap alone.Table 5 presents the obtained results per eachmedical category (i.e.
Treatment, Problem and Test)for three configurations.
Again, BIO-CRF-H obtainsthe best results for all metrics and all categories.Setting P R FMM 15.52 16.10 15.80MM+ 48.68 56.46 52.28TT-SVM 43.65 47.16 45.33BIO-CRF 70.15 83.31 76.17BIO-CRF-H 72.18 83.78 77.55Table 4: Results per setting on the i2b2 corpus.
R = recall,P = precision, F = F-measureSetting Category P R FMM+Problem 60.84 53.04 56.67Treatment 51.99 61.93 56.53Test 56.67 28.48 37.91TT-SVMProblem 48.25 43.16 45.56Treatment 42.45 50.86 46.28Test 57.37 35.76 44.06BIO-CRF-HProblem 82.05 73.14 77.45Treatment 83.18 73.33 78.12Test 87.50 68.69 77.07Table 5: Results per setting and per category on the i2b2corpus5 Discussion and Further ExperimentsWe presented three different methods for MER:MM+, TT-SVM, and BIO-CRF (with variant BIO-CRF-H).
In this section we quickly present supple-mentary results obtained on a second corpus withthe same methods, and discuss differences in resultswhen corpora and methods vary.5.1 CorporaDifferent kinds of corpora exist in the biomedicaldomain (Zweigenbaum et al, 2001).
Among themost recurring ones we may cite (i) clinical texts and(ii) scientific literature (Friedman et al, 2002).
Clin-ical texts have motivated a long stream of research(e.g.
(Sager et al, 1995), (Meystre et al, 2008)), andmore recently international challenges such as i2b22010 (Uzuner, 2010).
The scientific literature hasalso been the subject of much research (e.g.
(Rind-flesch et al, 2000)), especially in genomics for morethan a decade, e.g.
through the BioCreative chal-lenge (Yeh et al, 2005).61Section 4 presented experiments in MER on En-glish clinical texts.
To have a complementaryview on the performance of our methods, we per-formed additional experiments on the Berkeley cor-pus (Rosario and Hearst, 2004) of scientific litera-ture abstracts and titles extracted from MEDLINE.The original aim of this corpus was to study the ex-traction of semantic relationships between problemsand treatments (e.g.
cures, prevents, and side effect).In our context, we only use its annotation of med-ical entities.
The corpus contains two categories ofmedical entities: problems (1,660 entities) and treat-ments (1,179 entities) in 3,654 sentences (74,754words) with a mean of 20.05 words per sentence.
Wedivided the corpus into 1,462 sentences for trainingand 2,193 for testing.We tested the MetaMap (MM), MetaMap+(MM+) and BIO-CRF methods on the Berkeley cor-pus.
Table 6 presents the results.
BIO-CRF againobtain the best results, but it is not much better thanMM+ in this case.P R FMMProblem 5.32 7.63 6.27Treatment 6.37 18.84 9.52Total 5.35 12.34 7.46MM+Problem 34.47 44.97 39.02Treatment 18.11 39.36 24.81Total 23.43 42.47 30.20BIO-CRFProblem 41.88 38.88 40.32Treatment 29.85 23.86 26.52Total 36.94 32.13 34.37Table 6: Results on the Berkeley CorpusWe constructed three different models for theBIO-CRF method: a first model constructed fromthe Berkeley training corpus, a second model con-structed from the i2b2 corpus and a third modelconstructed from a combination of the formertwo.
We obtained the best results with the lastmodel: F=34.37% (F=22.97% for the first modeland F=30.08% for the second model).
These re-sults were obtained with a feature set with which weobtained 76.17% F-measure on the i2b2 corpus (i.e.words, lemmas, morphosyntactic categories, ortho-graphic features, suffixes and prefixes, cf.
set A4 inTable 7).The results obtained on the two corpora are noton the same scale of performance.
This is mainlydue to the characteristics of each corpus.
For in-stance, the i2b2 2010 corpus has an average words-per-sentence ratio of 8.7 while the Berkeley corpushas a ratio of 20.45 words per sentence.
Besides,the i2b2 corpus uses a quite specific vocabulary suchas conventional abbreviations of medical terms (e.g.k/p for kidney pancreas and d&c for dilation andcurettage) and abbreviations of domain-independentwords (e.g.
w/o for without and y/o for year old).However, according to our observations, the mostimportant characteristic which may explain these re-sults may be the quality of annotation.
The i2b2 cor-pus was annotated according to well-specified crite-ria to be relevant for the challenge, while the Berke-ley corpus was annotated with different rules andless control measures.
We evaluated a random sam-ple of 200 annotated medical entities in the Berkeleycorpus, using the i2b2 annotation criteria, and foundthat 20% did not adhere to these criteria.5.2 Semantic MethodsThe semantic methods have the advantage of beingreproducible on all types of corpora without a pre-processing or learning step.
However, their depen-dency to knowledge reduces their performance w.r.t.machine learning approaches.
Also the developmentof their knowledge bases is a relatively slow processif we compare it with the time which is necessary formachine learning approaches to build new extractionand categorization models.On the other hand, a clear advantage of semanticapproaches is that they facilitate semantic access tothe extracted information through conventional se-mantics (e.g.
the UMLS Semantic Network).In our experiments we did not obtain good resultswhen applying MetaMap alone.
This is mainly dueto the detection of entity boundaries (e.g.
?no peri-cardial effusion.?
instead of ?pericardial effusion?and ?
( Warfarin?
instead of ?Warfarin?
).We were able to enhance the overall performanceof MetaMap for this task by applying several inputand output filtering primitives, among which the useof an external chunker to obtain the noun phrases.Our observation is that the final results are limited bychunker performance.
Nevertheless, the approachprovided the correct categories for 52.28% correctly62extracted entities while the total ratio of the retrievedentities with correct boundaries is 60.76%.5.3 Machine Learning MethodsWe performed several tests with semantic featureswith the BIO-CRF method.
For instance, applyingMM+ on each word and using the obtained medicalcategory as an input feature for CRF decreased per-formance from 76.17% F-measure to 76.01%.
Thesame effect was observed by using the UMLS se-mantic type instead of the final category for eachword, with an F-measure decrease from 76.17% to73.55%.
This can be explained by a reduction infeature value space size (22 UMLS types instead of3 final categories) but also by the reduced perfor-mance of MetaMap if it is applied at the word level.The best solution was obtained by transformingthe output of the MM+ approach into BIO formattags and feeding them to the learning process asfeatures for each word.
Thus, each word in an en-tity tagged by MM+ has an input feature value cor-responding to one of the following: B-problem, I-problem, B-treatment, I-treatment, B-test and I-test.Words outside entities tagged by MM+ received an?O?
feature value.With these semantic features we were able to in-crease the F-measure from 76.19% to 77.55%.
Ta-ble 7 presents the contribution of each feature cate-gory to the BIO-CRF method on the i2b2 corpus.Features P R FA1: Words/Lemmas/POS 62.81 82.25 71.23A2: A1 + orthographic features 63.72 82.19 71.78A3: A2 + suffixes 67.91 82.89 74.65A4: A3 + prefixes 70.15 83.31 76.17A5: A4 + other features 70.22 83.28 76.19A6: A5 + semantic features 72.18 83.78 77.55Table 7: Contribution of each feature category (BIO-CRFmethod) on the i2b2 corpus6 ConclusionWe presented and compared three different ap-proaches to MER.
Our experiments show that per-forming the identification of entity boundaries witha chunker in a first step limits the overall perfor-mance, even though categorization can be performedefficiently in a second step.
Using machine learningmethods for joint boundary and category identifica-tion allowed us to bypass such limits.
We obtainedthe best results with a hybrid approach combiningmachine learning and domain knowledge.
More pre-cisely, the best performance was obtained with aCRF classifier using the BIO format with lexical andmorphosyntactic features combined with semanticfeatures obtained from a domain-knowledge basedmethod using MetaMap.Future work will tackle French corpora with botha semantic method and the BIO-CRF approach.
Wealso plan to exploit these techniques to build a cross-language question answering system.
Finally, itwould be interesting to try ensemble methods tocombine the set of MER methods tested in this pa-per.AcknowledgmentsThis work has been partially supported by OSEO un-der the Quaero program.ReferencesAlan R. Aronson.
2001.
Effective mapping of biomed-ical text to the UMLS metathesaurus: the MetaMapprogram.
In AMIA Annu Symp Proc, pages 17?21.Asma Ben Abacha and Pierre Zweigenbaum.
2011.
Au-tomatic extraction of semantic relations between medi-cal entities: a rule based approach.
Journal of Biomed-ical Semantics.
In Press.Chih-Chung Chang and Chih-Jen Lin, 2001.
LIB-SVM: a library for support vector machines.
Soft-ware available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.Asif Ekbal and Sivaji Bandyopadhyay.
2010.
Named en-tity recognition using support vector machine: A lan-guage independent approach.
International Journal ofElectrical and Electronics Engineering, 4(2):155?170.Mehdi Embarek and Olivier Ferret.
2008.
Learning pat-terns for building resources about semantic relations inthe medical domain.
In LREC?08, May.Carol Friedman, Pauline Kra, and Andrey Rzhetsky.2002.
Two biomedical sublanguages: a descriptionbased on the theories of Zellig Harris.
Journal ofBiomedical Informatics, 35:222?235.Ying He and Mehmet Kayaalp.
2008.
Biological en-tity recognition with Conditional Random Fields.
InAMIA Annu Symp Proc, pages 293?297.63Hideki Isozaki and Hideto Kazawa.
2002.
Efficient sup-port vector classifiers for named entity recognition.
InProceedings of COLING-2002, pages 390?396.N Kang, EM van Mulligen, and JA Kors.
2010.
Com-paring and combining chunkers of biomedical text.
JBiomed Inform, 44(2):354?360, nov.Tyne Liang and Ping-Ke Shih.
2005.
Empirical textualmining to protein entities recognition from PubMedcorpus.
In NLDB?05, pages 56?66.Ste?phane M. Meystre and Peter J. Haug.
2005.
Compar-ing natural language processing tools to extract medi-cal problems from narrative text.
In AMIA Annu SympProc, pages 525?529.S M Meystre, G K Savova, K C Kipper-Schuler, and J FHurdle.
2008.
Extracting information from textualdocuments in the electronic health record: a review ofrecent research.
Yearb Med Inform, 35:128?44.Denys Proux, Franc?ois Rechenmann, Laurent Julliard,Violaine Pillet, and Bernard Jacq.
1998.
Detectinggene symbols and names in biological texts : A firststep toward pertinent information extraction.
In Pro-ceedings of Genome Informatics, pages 72?80, Tokyo,Japan : Universal Academy Press.Thomas C. Rindflesch, Lorraine Tanabe, John N. Wein-stein, and Lawrence Hunter.
2000.
Edgar: Extractionof drugs, genes and relations from the biomedical lit-erature.
In Proceedings of Pacific Symposium on Bio-computing, pages 517?528.Barbara Rosario and Marti A. Hearst.
2004.
Classify-ing semantic relations in bioscience text.
In Proceed-ings of the 42nd Annual Meeting of the Associationfor Computational Linguistics (ACL 2004), Barcelona,July.N Sager, M Lyman, N T Nha`n, and L J Tick.
1995.
Med-ical language processing: applications to patient datarepresentation and automatic encoding.
Meth InformMed, 34(1?2):140?6.G Shadow and C MacDonald.
2003.
Extracting struc-tured information from free text pathology reports.
InAMIA Annu Symp Proc, Washington, DC.Isabelle Tellier and Marc Tommasi.
2010.
ChampsMarkoviens Conditionnels pour l?extractiond?information.
In E?ric Gaussier and Franc?oisYvon, editors, Mode`les probabilistes pour l?acce`s a`l?information textuelle.
Herme`s, Paris.O?zlem Uzuner, editor.
2010.
Working papers of i2b2Medication Extraction Challenge Workshop.
i2b2.Xinglong Wang.
2007.
Rule-based protein term identi-fication with help from automatic species tagging.
InProceedings of CICLING 2007, pages 288?298.Alexander Yeh, Alexander Morgan, Marc Colosimo, andLynette Hirschman.
2005.
BioCreAtIvE task 1A:gene mention finding evaluation.
BMC Bioinformat-ics, 6 Suppl 1.Pierre Zweigenbaum, Pierre Jacquemart, Natalia Grabar,and Beno?
?t Habert.
2001.
Building a text corpus forrepresenting the variety of medical language.
In V. L.Patel, R. Rogers, and R. Haux, editors, Proceedings ofMedinfo 2001, pages 290?294, Londres.64
