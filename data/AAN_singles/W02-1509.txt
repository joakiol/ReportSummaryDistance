Coping with problems in grammars automatically extracted from treebanksCarlos A. ProloComputer and Information Science DepartmentUniversity of PennsylvaniaSuite 400A, 3401 Walnut StreetPhiladelphia, PA, USA, 19104-6228prolo@linc.cis.upenn.eduAbstractWe report in this paper on an experiment on auto-matic extraction of a Tree Adjoining Grammar fromthe WSJ corpus of the Penn Treebank.
We use anautomatic tool developed by (Xia, 2001) properlyadapted to our particular need.
Rather than address-ing general aspects of the automatic extraction wefocus on the problems we have found to extract alinguistically (and computationally) sound grammarand approaches to handle them.1 IntroductionMuch linguistic research is oriented to findinggeneral principles for natural language, classify-ing linguistic phenomena, building regular mod-els (e.g., grammars) for the well-behaved (or well-understood) part of languages and studying remain-ing ?interesting?
problems in a compartmentalizedway.
With the availability of large natural languagecorpora annotated for syntactic structure, the tree-banks, e.g., (Marcus et al, 1993), automatic gram-mar extraction became possible (Chen and Vijay-Shanker, 2000; Xia, 1999).
Suddenly, grammarsstarted being extracted with an attempt to have?full?
coverage of the constructions in a certain lan-guage (of course, to the extent that the used corporarepresents the language) and that immediately posesa question: If we do not know how to model manyphenomena grammatically how can that be that weare extracting such a wide-coverage grammar?.To answer that question we have to start a newthread at the edge of linguistics and computationallinguistics.
More than numbers to express coverage,we have to start analyzing the quality of automat-ically generated grammars, identifying extractionproblems and uncovering whatever solutions are be-ing given for them, however interesting or ugly theymight be, challenging the current paradigms of lin-guistic research to provide answers for the problemson a ?by-need?
basis.In this paper we report on a particular experi-ence of automatic extraction of an English grammarfrom the WSJ corpus of the Penn Treebank (PTB)(Marcus et al, 1994)1 using Tree Adjoining Gram-mar (TAGs, (Joshi and Schabes, 1997)).
We use anautomatic tool developed by (Xia, 2001) properlyadapted to our particular needs and focus on someproblems we have found to extract a linguistically(and computationally) sound grammar and the so-lutions we gave to them.
The list of problems isa sample, far from being exhaustive2 Likewise, thesolutions will not always be satisfactory.In Section 2 we introduce the method of grammarextraction employed.
The problems are discussed inSection 3.
We conclude in Section 4.2 The extracted grammar2.1 TAGsA TAG is a set of lexicalized elementary trees thatcan be combined, through the operations of tree ad-junction and tree substitution, to derive syntac-tic structures for sentences.
We follow a commonapproach to grammar development for natural lan-guage using TAGs, under which, driven by local-ity principles, each elementary tree for a given lex-ical head is expected to contain its projection, andslots for its arguments (e.g., (Frank, 2002)).
Figure1 shows typical grammar template trees that can beselected by lexical items and combined to generatethe structure in Figure 2.
The derivation tree, to theright, contains the history of the tree grafting pro-cess that generated the derived tree, to the left.31We assume some familiarity with the basic notations in thePTB as in (Marcus et al, 1994).2(Prolo, 2002) includes a more comprehensive and detaileddiscussion of grammar extraction alternatives and problems.3For a more comprehensive introduction to TAGs and Lexi-calized TAGs we refer the reader to (Joshi and Schabes, 1997).NPNSNPV NPVPVPVPPPP NPDTNP* NP*np vt detpprightFigure 1: An example of Tree Adjoining GrammarDTNPNP*NPPP*VPV NPNNPNVPS[John][saw][Mary][from][the][window]Derived   tree Derivation  treevt[saw]np[John] np[Mary]  pp[from]np[window]det[the]Figure 2: Derivation of John saw Mary from the window2.2 LexTractGiven an annotated sentence from the PTB as in-put Xia?s LexTract tool (Xia, 1999; Xia, 2001) firstexecutes a rebracketing.
More precisely, additionalnodes are inserted to separate arguments and mod-ifiers and to structure the modifying process as bi-nary branching.
A typical rebracketed PTB tree isshown in Figure 3,4 in which we have distinguishedthe tree nodes inserted by LexTract.The second stage is the extraction of the grammartrees proper shown in Figure 4.
In particular, re-cursive modifier structures have to be detected andfactored out of the derived tree to compose the aux-iliary trees, the rest becoming an initial tree.
Theprocess is recursive also in the sense that factoredsubtree structures still undergo the spinning off pro-cess until we have all modifiers with their own trees,all the arguments of a head as substitution nodes ofthe tree containing their head, and the material un-der the argument nodes defining additional initialtrees for themselves.
Auxiliary trees are extractedfrom parent-child pairs with matching labels if thechild is elected the parent?s head and the child?s sib-ling is marked as modifier: the parent is mappedinto a root of an auxiliary tree, the head-child into its4Figures 3 and 4 are thanks to Fei Xia.
We are also gratefulto her for allowing us to use LexTract and make changes to itssource code to customize to our needs.foot, with the sibling subtree (after being recursivelyprocessed) being carried together into the auxiliarytree.
Notice that the auxiliary trees are therefore ei-ther strictly right or left branching, the foot alwaysimmediately under the root node.
Other kinds ofauxiliary trees are therefore not allowed.VBPdraftNPNNSpoliciesVBGusing?NPNNSpensVPSINatNPNNPFNXPRPtheyRBstillPP?LOCNP?SBJADVPS?MNRVPNP?SBJVPSVPFigure 3: LexTract rebracketing stageTo extract a grammar with Xia?s tool one has todefine tables for finding: the head child of a con-stituent expansion; which of the siblings of a headare acceptable arguments; and which constituent la-bels are plausible modifiers of another.
Special pro-visions are made for handling coordination.
For ad-ditional information see (Xia, 2001).
In this paperwe refer to (Xia, 1999)?s table settings and extractedgrammar, which we used as our starting point, asXia?s sample.
We used a customized version of Lex-Tract, plus additional pre-processing of the PTB in-put and post-processing of the extracted trees.3 Extraction ProblemsExtraction problems arise from several sources, in-cluding: (1) lack of proper linguistic account,5 (2)the (Penn Treebank) annotation style, (3) the (Lex-Tract) extraction tool, (4) possible unsuitability ofthe (TAG) model, and (5) annotation errors.
Werefrained from making a rigid classification of theproblems we present according to these sources.
Inparticular it is often difficult to decide whether toblame sources (1), (3), or (5) for a certain problem.We will not discuss in this paper problems due toannotation errors.
As for the PTB style problemswe only discuss one, the first listed below.5Here included the (occasional) inability on the part ofgrammar developers to find or make use of an existing account.#7#5#6PPINatSstillS2.tRBADVPdraftVBPNNSNP3.bVP3.tVP2.tVBGS3VPNP1.tFNXNNPNP1.b NP2.bPRPVP3.bNP5.tNP5.bVP1.bVP1.tS2.b1.bNP2.tNP3.tVP2.bNP4?5#5#2#3#4#1S1.t#5theypoliciesusing NNSpens#8#5:policiesNNS SVPVP*NP?
VBGusingVPNP#7:#1:SS*PPIN NPatNPNNPFNX#2:#6: #8:NPNNSpensNPSVPNPVBPdraftNPNPPRP#3:they#4:ADVP VP*RBstillVPa) Input tree decomposition b) Extracted elementary treesFigure 4: LexTract extraction stage(S-3 (NP-SBJ (PRP We))(VP (VBP make)(SBAR-NOM (WHNP-1 (WP what))(S we knowhow to make))))a) As a sentential clause in the PTB(S-3 (NP-SBJ (PRP We))(VP (VBP make)(NP (NP (WP what))(SBAR (WHNP-1 (-NONE- 0))(S we know ...)))))b) As a Noun phrase after pre-processedFigure 5: Free relatives in the Treebank3.1 Free RelativesFree relatives are annotated in the Penn Treebankas sentential complements as in Figure 5.a.
Theextracted tree corresponding to the occurrence of?make?
would be of a verb that takes a sententialcomplement (SBAR).
This does not seem to be cor-rect6, as the proper subcategorization of the verb oc-currence is transitive.In fact, free relatives may occur wherever an NPargument may occur.
So, the only reasonable ex-traction account consistent with maintaining themas SBARs would be one in which every NP sub-stitution node in an extracted tree would admit the6In both standard accounts for free relatives, the Head Ac-count (e.g., (Bresnan and Grimshaw, 1978)) and the Comp Ac-count (e.g., (Groos and von Riemsdijk, 1979)), commonly dis-cussed in the literature, the presence of the NP (or DP) is clear.existence of a counterpart tree, identical to the first,except that the NP argument label is replaced withan SBAR.
Instead we opted to reflect the NP char-acter of the free relatives by pre-processing the cor-pus (using the Head-analysis, for practical conve-nience).
The annotated example is then automat-ically replaced with the one in Figure 5.b.
Othercases of free-relatives (non-NP) are rare and notlikely to interfere with verb subcategorization.3.2 Wh percolation upIn the Penn Treebank the same constituent is anno-tated with different syntactic categories dependingon whether it possesses or not the wh feature.
Forinstance, a regular noun phrase has the syntacticcategory NP, whereas when the constituent is wh-marked, and is in the landing site of wh-movement,it carries the label WHNP.7 While that might lookappealing since the two constituents seem to havedistinct distributional properties, it poses a designproblem.
While regular constituents inherit theirsyntactic categorial feature (i.e.
their label) fromtheir heads, wh projections are often formed by in-heritance from their modifiers.
For instance: ?thefather?
is an NP, but modified by a wh expression(?the father of whom?, ?whose father?, ?which fa-ther?
), it becomes a WHNP.
The only solution wesee is to allow for nouns and NPs to freely project upto WHNPs during extraction.8 On the other hand, in7When the constituent is not wh-moved, it is correctly pre-served as an NP, as ?what?
in ?Who ate what?
?.8Of course another simple solution would be merging thewh constituents with their non-wh counterparts.
(NP (UCP (NN construction)(CC and)(JJ commercial))(NNS loans))a) NP modifiers(VP (VB be)(UCP-PRD (NP (CD 35))(CC or)(ADJP (JJR older))))b) non-verbal Predicates(VP (VB take)(NP (NN effect))(UCP-TMP (ADVP 96 days later)(, ,)(CC or)(PP in early February)))c) adverbial modifiersFigure 6: ?Unlike Coordinated Phrases?cases when the wh constituent is in a non-wh posi-tion, we need the opposite effect: a WHNP (or wh-noun POS tag) is allowed to project up to an NP.3.3 Unlike Coordinated Phrases (UCP)This is the expression used in the PTB to denotecoordinated phrases in which the coordinated con-stituents are not of the same syntactic category.
Therationale for the existence of such constructions isthat the coordinated constituents are alternative re-alizations of the same grammatical function withrespect to a lexical head.
In Figure 6.a, both anoun and an adjective are allowed to modify anothernoun, and therefore they can be conjoined while re-alizing that function.
Two other common cases are:coordination of predicates in copular constructions(Figure 6.b) and adverbial modification (Figure 6.c).We deal with the problem as follows.
First, we al-low for a UCP to be extracted as an argument whenthe head is a verb and the UCP is marked predica-tive (PRD function tag) in the training example; orwhenever the head is seen to have an obligatoryargument requirement (e.g., prepositions: ?Theycome from ((NP the house) and (PP behind thetree))?).
Second, a UCP is allowed to modify (ad-join to) most of the nodes, according to evidence inthe corpus and common sense (in the first and thirdexamples above we had NP and VP modification).With respect to the host tree, when attached as an ar-gument they are treated like any other non-terminal:a substitution node.
The left tree in Figure 7 shows    	Figure 7: Extracted trees for UCPthe case where the UCP is treated as a modifier.
Infact the trees are both for the example in Figure 6.a.Notice that the tree is non-lexicalized to avoid ef-fects of sparseness.
The UCP is then expanded as inthe right tree in Figure 7: an initial tree anchored bythe conjunction (the tree attaches either to a tree likethe one in the left or as a true argument ?
the latterwould be the case for the example in Figure 6.b).Now, the caveats.
First, we are giving the UCPthe status of an independent non-terminal, as if ithad some intrinsic categorial significance (as a syn-tactic projection).
The assumption of independenceof expansion, that for context-free grammars is in-herent to each non-terminal, in TAGs is further re-stricted to the substitution nodes.
For example,when an NP appears as substitution node, in a sub-ject or object position, or as an argument of a prepo-sition or a genitive marker, we are stating that anypossible expansion for the NP is licensed there.
Thesame happens for other labels in argument positionsas well.
While that is an overgenerating assumption(e.g.
the expletive ?there?
cannot be the realizationof an NP in object position), it is generally true.
Forthe UCP, however, we know that its expansion isin fact strongly dependent on where the substitu-tion node is, as we have argued before.
In fact itis lexically dependent (cf.
?I know ((the problem)and (that there is no solution to it))?, where the con-juncts are licensed by the subcategorizations of theverb ?know?).
On the other hand, it does not seemreasonable to expand the UCP node at the hostingtree ?
a cross product explosion.
A possible way ofalleviating this effect could be to expand only theauxiliary trees (a UCP modifying a VP is distinctfrom a UCP modifying an NP, and moreover theyare independent of lexical items).
But for true argu-ment positions there seems to be no clear solution.Second, the oddity of the UCP as a label becomesapparent once again when there are multiple con-juncts, as in Figure 8: it is enough for one of them tobe distinct to turn the entire constituent into a UCP.Recursive decomposition in the grammar in thesesituations clearly leads to some non-standard trees.Finally, and more crucially, we have omitted onecase in our discussion: the case in which the UCP(NP (UCP (JJ electronic)(, ,)(NN computer)(CC and)(NN building))(NNS products))Figure 8: UCP with multiple conjuncts(S (NP-SBJ-1 The Series 1989 B bonds)(VP (VBP are)(VP (VBN rated)(S *-1 double-A))))(S (NP-SBJ-1 The Series 1989 B bonds)(VP (VBP are)(UCP-PRD (ADJP-PRD (JJ uninsured))(CC and)(VP (VBN rated)(S *-1 double-A)))))Figure 9: UCP involving VP argument of the copulais the natural head-child of some node.
Under someaccounts of grammar development this never hap-pens: we have observed that UCP does not appearas head child in the account where the head is thesyntactic head of a node.
We have not always fol-lowed this rule.
With respect to the VP head, so farwe have followed one major tendency in the com-putational implementation of lexicalized grammars,according to which lexical verbs are prefered to aux-iliary verbs to head the VP.
Now, consider the pairof sentences in Figure 9.Under the lexical verb paradigm, in the first sen-tence the derivation would start with an initial treeanchored by the past participle verb (?rated?).
Butthen we have an interesting problem in the secondsentence, for which we do not currently have a neatsolution.
Following Xia?s sample settings of Lex-Tract parameters, in these cases the extraction isrescued by switching to the other paradigm: the ini-tial tree is extracted anchored by the auxiliary verbwith a UCP argument, and the VP is accepted as apossible conjunct.
A systematic move to the syn-tactic head paradigm, which we may indeed try,would have important consequences in the localityassumptions for the grammar development.3.4 VP topicalizationAnother problem with the lexical verb paradigm(see also discussion under UCP above) is the VPtopicalization as in the sentence in Figure 10.
Thesolution currently adopted (again, inherited from(SINV (ADVP (RB Also))(VP-TPC-2 (VBN excluded)(NP (-NONE- *-1)))(VP (MD will)(VP (VB be)(VP (-NONE- *T*-2))))(NP-SBJ-1 investments in ...))Figure 10: VP topicalization(S (NP-SBJ (NNP Congress))(VP (MD could)(VP (VB pass)(ADVP-MNR (RB quickly))(NP (NP (DT a)(??
??
)(JJ clean)(??
??
)(NN bill))(VP (VBG containing)(ADVP (JJ only))(NP ... )))))) 	    ffFigure 11: The extraposition problemXia?s sample settings) is as above: the paradigm isswitched and the auxiliary verb (?be?)
is chosen asthe anchor of the initial tree.3.5 Extraposition and Verb SubcategorizationOne of the key design principles that have beenguiding grammar development with TAGs is to keepverb arguments as substitution slots local to thetree anchored by the verb.
It is widely known thatthe Penn Treebank does not distinguish verb ob-jects from adjuncts.
So some sorts of heuristics areneeded to decide, among the candidates, which areto be taken as arguments (Kinyon and Prolo, 2002);the rest is extracted as separate VP modifier trees.However, this step is not enough for the trees tocorrectly reflect verb subcategorizations.
The oc-currence of discontinuous arguments, frequently ex-plained as argument extraposition (the argument israised past the adjunct) creates a problem.
In thesentence in Figure 11 the verb ?pass?
should anchora tree with one NP object.However in such a tree it would be impossible toadjoin the tree for the intervening ADVP ?quickly?as a VP modifier and still have it between the verband the NP.9 LexTract then would instead extract an9A striking use of sister adjunction in (Chiang, 2000) is ex-actly the elegant way it solves this problem: the non-argumenttree can be adjoined onto a node (say, VP), positioning itself inbetween the VP?s children, which is not possible with TAGs.
(NP (NP the 3 billion New Zealand dollars)(PRN (-LRB- -LRB-)(NP US$ 1.76 billion *U*)(-RRB- -RRB-)))a) A parenthetical NP attached to another NP(S (NP-SBJ The total relationship)(PRN (, ,)(SBAR-ADV as Mr. Lee sees it)(, ,))(VP (VBZ is) ...))b) A parenthetical S between subject and verbFigure 12: Parentheticalsintransitive tree for the VB ?pass?, onto which theADVP modifier tree would adjoin.
The second odd-ity is that the NP object would also be extracted as aVP modifier tree.
In a nutshell, objects in extractedtrees are restricted to those which are not extraposedand hence the trees may not truly reflect the properdomain of locality.
One view is that the set of treesfor a certain subcategorization frame would includethese degenerate cases.
LexTract has an option toallow limited discontinuity, i.e., a non-argument se-quence between the verb and the first object (but notbetween two objects).
The non-arguments wouldthen be adjoined to the V node.10 So far we haveused only the latter alternative.It is worth mentioning two other cases of extra-position.
Subject extraposition is handled by havingthe extraposed subject, usually a sentential form, ad-join at the VP of which it is the logical subject (theoriginal position is still occupied by an NP with theexpletive pronoun ?it?).
Relative clause extraposi-tion is modeled by a relative clause tree, only it ad-joins at a VP, instead of at an NP as is usual.3.6 ParentheticalsParenthetical expressions are ubiquitous in lan-guage: they may appear almost everywhere in a sen-tence and can be of almost any category (Fig.
12).We model them as adjoining, either to the left orright of the constituent they are dominated by, de-pending on whether they are to the left or right of thehead child of the parent?s node.
Occasionally suchtrees can also be initial.
The respective trees for theexamples of Figure 12 are drawn in Figure 13.
It10Of course, although the solution covers most of the occur-rences, and apart of any linguistic concern, there are still un-covered cases, e.g., when a parenthetical expression intervenesbetween the first and the second argument.  fiflffi  ffi ffiFigure 13: Extracted trees for parentheticalsis always the case that the label PRN dominates asingle substitution node.
Whenever this was not thecase in the training corpus, heuristics based on ob-servation were used to enforce that, by inserting anappropriate missing node.3.7 Projection labelsLexTract extracts trees with no concern for the ap-propriate projective structure of constituents whennot explicitly marked in the PTB.
Figure 14 showstwo examples of NP modification where the modi-fiers are single lexical items.
The extracted modifiertrees, shown on the right, do not have the projec-tion for the modifiers JJR ?stronger?
and the NNP?October?
(which should be, respectively, an ADJPand an NP).
That is so, because those nodes are notfound in the annotation.
(NP (DT a)(JJR stronger)(NN argument))(NP-SBJ-1 (NNP October)(NN weather)) !"ffi fi #  $ Figure 14: Simple modification annotation and ex-tracted treesHowever, if the modifiers are complex, that is, ifthe modifiers are themselves modified, the PTB in-serts their respective projections, and therefore theyappear in the extracted trees, as shown in Figure 15.There seems to be no reason for the two pairsof extracted trees to be different.
Much of this iscaused by the acknowledged flatness in the PennTreebank annotation.
That said, the trees like thosein the second pair should be preferred.
The projec-tion node (ADJP or NP) is understood to be domi-nating its head even when there is no further mod-ification, and it should be a concern of a good ex-traction process to insert the missing node into thegrammar.
Since LexTract do not allow us to spec-(NP (DT an)(ADJP (RB even)(JJR stronger))(NN argument))(NP-SBJ-1 (NP (JJ late)(NNP October))(NN weather))  %"&ffi      $ Figure 15: Complex modification annotation andextracted treesify for the insertion of ?obligatory?
projections wehad to accomplish this through a somewhat compli-cated post-processing step using a projection table.Some of our current projections are: nouns, per-sonal pronouns and the existential expletive to NP;adjectives to ADJP; adverbs to ADVP; sentences ei-ther to SBAR (S, SINV) or to SBARQ (SQ); Cardi-nals (CD) to Quantifier Phrases (QP) which them-selves project to NP.
Notice that not all categoriesare forcefully projected.
For instance, verbs arenot, allowing for simple auxiliary extraction.
INis also not projected due to its double role as PPhead (true preposition) and subordinate conjunc-tion, which should project onto SBARs.4 ConclusionWe discussed an experiment in grammar extractionfrom corpora with focus on problems arising whiletrying to give an adequate account for naturally oc-curing phenomena.
Without being exhaustive in ourlist, we expect to have brougt some attention to theneed to discuss solutions for them which are as rea-sonable as possible given the current state-of-the-artof the linguistic research, computational grammardevelopment and automatic extraction, and giventhe current corpus resources at our disposition.ACKNOWLEDGEMENTS: Thanks to ToniaBleam, Erwin Chan, Alexandra Kinyon, RashmiPrasad, Beatrice Santorini, Fei Xia and the XTAGGroup for valuable discussions along the realizationof this work and/or comments on this paper or re-lated material.ReferencesJoan Bresnan and Jane Grimshaw.
1978.
The syn-tax of free relatives in english.
Linguistic Inquiry,9(3):331?391.John Chen and K. Vijay-Shanker.
2000.
Automatedextraction of TAGs from the Penn Treebank.
InProceedings of the 6th International Workshop onParsing Technologies, Trento, Italy.David Chiang.
2000.
Statistical parsing with anautomatically-extracted Tree Adjoining Gram-mar.
In Proceedings of the 38th Annual Meetingof the Association for Computational Linguistics,Hong Kong, China.Robert Frank.
2002.
Phrase Structure Compositionand Syntactic Dependencies.
MIT Press, Cam-bridge, MA, USA.Anneke Groos and Henk von Riemsdijk.
1979.
Thematching effects in free relatives: a parameter ofcore grammar.
In Theory of Markedness in Gen-erative Grammar.
Scuola Normale Superiore diPisa, Italy.Aravind K. Joshi and Yves Schabes.
1997.
Tree-Adjoining Grammars.
In Handbook of FormalLanguages, volume 3, pages 69?123.
Springer-Verlag, Berlin.Alexandra Kinyon and Carlos A. Prolo.
2002.Identifying verb arguments and their syntacticfunction in the Penn Treebank.
In Proc.
of theThird LREC, pages 1982?87, Las Palmas, Spain.Mitchell Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotatedcorpus of English: The Penn Treebank.
Compu-tational Linguistics, 19(2):313?330.Mitchell Marcus, Grace Kim, Mary AnnMarcinkiewicz, Robert MacIntyre, Ann Bies,Mark Ferguson, Karen Katz, and Britta Schas-berger.
1994.
The Penn Treebank: Annotatingpredicate argument structure.
In Proceedingsof the 1994 Human Language TechnologyWorkshop.Carlos A. Prolo.
2002.
LR parsing for Tree Adjoin-ing Grammars and its application to corpus-basednatural language parsing.
Ph.D. Dissertation Pro-posal, University of Pennsylvania.Fei Xia.
1999.
Extracting tree adjoining gram-mars from bracketed corpora.
In Proceedings ofthe 5th Natural Language Processing Pacific RimSymposium(NLPRS-99), Beijing, China.Fei Xia.
2001.
Investigating the Relationship be-tween Grammars and Treebanks for Natural Lan-guages.
Ph.D. thesis, Department of Computerand Information Science, Un.
of Pennsylvania.
