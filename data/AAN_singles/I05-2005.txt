A Novel Method for Content Consistency and Efficient Full-textSearch for P2P Content Sharing SystemsHideki MimaUniversity of Tokyo7-3-1 Hongo, Bunkyo-ku, Tokyo, Japanmima@biz-model.t.u-tokyo.ac.jpHideto TomabechiCognitive Research Lab7-8-25 Roppongi, Minato-ku, Tokyo, JapanHideto_Tomabechi@crl.co.jpAbstractA problem associated with current P2P (peer-to-peer)systems is that the consistency between copied contentsis not guaranteed.
Additionally, the limitation of full-text search capability in most of the popular P2Psystems hinders the scalability of P2P-based contentsharing systems.
We proposed a new P2P contentsharing system in which the consistency of contents inthe network is maintained after updates or modificationshave been made to the contents.
Links to thedownloaded contents are maintained on a server.
As aresult, the updates and modifications to the contents canbe instantly detected and hence get reflected in futureP2P downloads.
Natural language processing includingmorphological analysis is performed distributedly by theP2P clients and the update of the inverted index on theserver is conducted concurrently to provide an efficientfull-text search.
The scheme and a preliminaryexperimental result have been mentioned1   IntroductionP2P content sharing systems can distribute largeamounts of contents with limited resources.
By utiliz-ing this exceptional feature, the P2P content sharingmodel is expected to be one of the major means forexchanging contents.However, the presently available P2P content shar-ing systems are mainly used to illegally copy moviesand music contents.
In some cases, the service provid-ers are accused of such illegal data exchange.We have recognized that the following technicalproblems may result in the above mentioned misuseof P2P.First, the presently available commercial P2P con-tent sharing systems do not provide sufficient func-tions to track the exchange of contents among users.Due to this, service providers cannot monitor theillegal exchange or tampering of shared contentsamong users.Second, the presently available commercial P2Pcontent sharing systems only provide simple searchfunctions, such as keyword search; therefore, they areunsuitable for contents that are either frequently up-dated or have text.
In practice, the current P2P contentsharing systems are mainly used to only share moviesand music contents because these are not frequentlyupdated.
The development of an appropriate searchmethod for the P2P content sharing system is requiredin order to apply them to search text contents and thelatest version of contents.In order to solve these technical problems, we aredeveloping a content consistency maintenance methodand an information search technique for P2P contentsharing systems.
Our content consistency maintenancemethod consists of a technique that prevents the tam-pering of contents and a method that maintains consis-tency between the following:1. how users exchange contents on a P2P contentssharing system and2.
how the service provider recognizes theexchange of contents.Finally, we aim to standardize the result of previ-ous research  [10].In order to handle the updates of contents, the P2Pcontent sharing system that we are developing main-tains digital signs for each version of the content.
Oursystem uses a download protocol based on asymmet-ric key encryption to maintain content consistency.
Inorder to obtain the latest version of contents, even forupdated contents, this method employs links to theoriginal and the downloaded contents.
These links aremanaged on a central server.In order to efficiently implement a full-text search,clients connected to our system perform morphologi-cal analysis and summarization of the text to generatetext information that is necessary for building a re-verse index on a central server.
The text informationis stored on a central server when the content is up-dated.
To reduce the load of full-text search, thesearch results are cached on clients.
By these tech-niques, we can distribute the load of natural languageprocessing among clients and rapidly search text con-tents with content updates.In this paper, we briefly describe the P2P contentsharing system that we are developing and the tech-niques used in it, namely, a content consistency main-tenance method and a full-text search method.
Wealso report the result of a preliminary experiment onload balancing of full-text search by our technique.This paper is structured as follows: Section 2 de-scribes related work.
Section 3 briefly describes the25P2P content sharing system that we are developing.Sections 4 and 5 describe techniques for content con-sistency maintenance and full-text search, respectively.Finally, Section 6 presents the conclusion and futurework.2   Related WorkThe two kinds of researches related to our work areresearches on content consistency maintenance andthose on information search in a P2P environment.In this paper, we refer to a hybrid P2P system, suchas Napster that uses a central server, as a P2P system,although it is not entirely decentralized.
This is be-cause, even a hybrid P2P system has an importantadvantage in terms of content sharing; it can distributelarge amounts of contents with less bandwidth con-sumption on the service providers side.2.1   Contents Consistency MaintenanceSince the contents are stored on clients in a P2Pcontent sharing system, malicious clients can tamperwith the contents if no protection method againsttampering is provided.The MD5 hash function in the protocol of Napster[4] enables a content publisher to send the hash valueof a content to a central server when it publishes thecontent.
Freenet  [2] prevents tampering with the con-tent by using the hash value of a content as its key.This technique is effective in preventing the tam-pering of static content such as a movie or musiccontent.
However, when this technique is applied tofrequently updated contents, each version is treated asa separate content because different versions havedifferent keys.
To handle such frequently updatedcontents, Freenet introduced indirect files in which thehash values of the contents are stored.
By retrievingan indirect file, a user can retrieve the last updatedcontent in two steps.
In order to share frequently up-dated contents, we need to provide a mechanism thatassociates the content ID with the hash value of aparticular version of the content, as in the case ofFreenet.Another problem of P2P content sharing systems isthat the provider of a content sharing service cannottrace the exchange of contents among users.Napster, which is a centralized P2P content sharingsystem similar to our system, uses a download proto-col by which the clients send a download request tothe central server before they download the contentfrom another client.
After this, the central server doesnot participate in the download process of the content.Using this protocol, the central server cannot identifywhether a download has been carried out successfullyor not.
A malicious client can send the same informa-tion to the central server and pretend that a downloadrequest has been made by another client.
It is alsopossible to send tampered content to another clientwithout being detected by the central server.2.2   Information Search in P2P EnvironmentThe two types of search techniques that are widelyused in P2P content sharing systems include using acentral search server  [4] and flooding of search re-quests  [6].The problems of using a central server, such aspoor scalability of a central search server and vulner-ability that arises from a single point of failure, arewidely known.
The flooding of search requests alsohas scalability problems.
As the number of nodes in anetwork increases, more search requests are floodedthat consume a major part of the bandwidth.
In orderto reduce search requests, many systems use floodingtechniques that often limit the search range with heu-ristic methods.
As a result, it cannot be assured that allexisting contents in a network can be found in thesesystems.In order to solve the problems associated with theabove mentioned techniques, several search methodsbased on distributed hash tables (DHT) have beenproposed  [5] [7].
These methods are scalable to a con-siderable extent.
A characteristic of these methods isthat exact match key search can be done with O (logn) or O (na) hops.Reynolds and Vahdat proposed a method for im-plementing full-text search by distributing the reverseindex on a DHT.
In this method, a key in a hash tablecorresponds to a particular keyword in a document,and a value in a hash table corresponds to a documentthat contains a keyword.
A client that publishes adocument notifies the nodes that correspond to thekeywords contained in the document and updates thereverse indexes on these nodes.
In this method, theload of the full-text search can be distributed amongthe nodes.
We can also expect that the reverse indexeson the nodes can be updated rapidly by pushing thelatest keywords in the contents from a client.On the other hand, this method has several limita-tions.
For example, when an AND search is per-formed by this method, the search results must betransferred between the nodes.
Li estimated theamount of resources that is necessary to implement afull-text search engine based on this method andpointed out that it is difficult to implement a large-scale search engine, such as Google, by this method[8].Furthermore, if this method were applied to a P2Pcontent sharing system, the problem of low availabil-ity of nodes would arise because the users?
PCs wouldbe used as nodes in such a system.
In order to storereverse indexes on the nodes, we have to replicatethem to ensure the availability of indexes.
This wouldrequire more resources than that estimated by Li.26Based on the above mentioned reasons, we believethat a full-text search technique using a central searchserver that manages reverse indexes is more feasiblethan a distributed reverse index technique for imple-menting a full-text search engine in a P2P environ-ment.3   System ArchitectureFigure 1 shows the architecture of our system.
Asdescribed earlier, we chose a central server architec-ture to provide a full-text search of the contents.The public keys of the clients are stored on a cen-tral server.
By sending a request to the server, a clientcan obtain a public key of another client that is con-nected with the central server.
The central server alsohas private and public keys.
Its public key is availableto all the clients.Each client has a unique ID.
When a client connectsto the central server, it sends its own IP address.
An-other client can obtain the IP address of a client byquerying to the server using its client ID.
The centralserver provides a content consistency maintenancemechanism and a full-text search engine.
Thesemechanisms are described in the following sections.4 Content Consistency Maintenance4.1   Data Structure for Content ManagementIn this system, a publisher of a document digitallysigns a document with its private key and registers itssign to the central search server with its unique ID.When a document is a text document, a client per-forms morphological analysis to generate search key-words from a document.The ID of contents and digital signs correspondingto different versions are managed on the centralsearch server.
Using the ID and version, a client canobtain a digital sign for a document by querying to thecentral server using its ID and version.
Using a digitalsign ensures that a malicious client does not tamperwith a document.A search result obtained from the central server isalso digitally signed to ensure that a client does nottamper with it.
As described in detail in section 5, asearch result is cached on a client and can be modified.To prevent this, a search result comprises the ID ofcontents and a digital sign.In this system, a client can obtain the latest versionof a document when a document is updated, by query-ing its ID to the central server.
However, a limitationassociated with this method is that only the latestversion of documents can be obtained.
For example,by using indirect files and hash values of contents asin Freenet, we can obtain previous versions of adocument by directly specifying a hash value of anearlier version.
However, neither does Freenet assurethat the latest version is always obtained nor does itassure that a particular earlier version is obtainedbecause a previous version may be deleted if there isno request for it in a certain period.
In our system, weconsider only the latest version of a document whichcan be obtained at any time.
Thus, we define ourdocument query protocol in order to obtain the latestversion.In order to prevent the concentration of downloadrequests on a certain client, our system manages a listof clients that have downloaded the latest version of adocument and distributes download sources to theseclients using this list.In this method, the ID of a client that downloadsthe latest version of a document is added to a list; thisID corresponds with the ID of the document.
When aclient sends a request to the central server todownload a document, the central server selects anappropriate client from a downloader?s list and returnsits ID to the client.
When the publisher updates adocument, the list corresponding to that document isemptied.We describe this procedure by the followingpseudo codes, where download is a function thatrequests the download of a document, nodeId is theID of a client that requests the download, update isa function that requests the update of a document, andgetNodeId is a function that gets the ID of a clientthat downloads a document whose ID is docId.nodeIdList: document ID x node ID listdownload(docId, nodeId) {nodeIdList[docId].add(nodeId); }update(docId, nodeId) {nodeIdList[docId] = {nodeId}; }getNodeId(docId) {index = rand() * nodeIdList[docId].length;return nodeIdList[docId][index]; }4.2 Tracing How Contents are ExchangedIn a P2P content sharing system that uses a simpledownload protocol, such as Napster, when a service- Client public keys- Contents certificate- Links to contents- Full-text search index- ContentsFigure 1.
System ArchitectureCentralserverClientClient Client27provider keeps records about how contents are trans-ferred among clients, there exist possibilities of aclient tampering with such records by sending falseinformation about downloading content to the centralserver.For example, by Napster protocol, a request to starta download that is sent when a client begins todownload from another client is the information thatthe central server receives from the client.
Therefore,the central server can obtain the same information inthe case when a download source does not transfer adocument as well as in the case when a downloadsource transfers a document successfully.To avoid this problem, our system uses a downloadprotocol that employs the public keys of clients man-aged on the central server.
The protocol is describedas follows wherein a download destination client isdenoted as client A and a download source client asclient B.1 Client A sends a download request to the centralserver.
The central server generates a commonencryption key and sends it to client B.2 Client B encrypts the requested content with acommon encryption key, signs it digitally, andsends the encrypted content to client A.3 Client A confirms that the downloaded contenthas been signed by client B.
Client A then sends arequest for the common encryption key to thecentral server.
The central server records that thecontent is downloaded.4 Client A decrypts the downloaded content withthe common encryption key.
Client A then veri-fies that the downloaded content is not altered us-ing digital sign on the central server.5 If the downloaded content is altered, client Asends the downloaded data with a sign of client Bto the central server.
The central server can thenconfirm that it is signed by client B and is altered.The central server can then cancel the downloadrecord created in step 3.By this protocol, the following properties are satis-fied:?
A content download is recorded on the centralserver as long as a download source client fol-lows the above protocol.?
The central server does not create a record whena document is not downloaded by a client.When a download source client encrypts a docu-ment with a common encryption key following theprotocol, a download destination client has to send arequest for a common key to the central server.
Thus,the central server can record a download.
As a result,the first property is satisfied.Further, when a client that downloaded a documentsends a request for a common key, it obtains a sign ofa download source client for the document.
When thedownloaded content is altered or different from therequested one, a download record can be cancelled bysending the downloaded data to the central server.Thus, the second property is satisfied.However, even with this protocol, in the case whenboth a download source client and a destination clientdo not follow this protocol, the central server cannotrecord downloads of contents, for example, in thecase where a download source client does not encryptthe content with a common key.
Currently, our systemdoes not handle such situations.
We would like toconsider this problem in our future work.
In order tohandle such situations, we evaluated the credibility ofclients from download histories and selected a credi-ble client as a download source.5   Full-text Search5.1 Load Balancing of Full-text SearchTo reduce the load of full-text search on the centralserver, our system uses a caching technique to cachethe search results of clients.
It has been reported thatapproximately 30% to 40% of search requests arerepeated on a full-text search engine [9].
Therefore, acaching technique is expected to considerably reducethe full-text search load.
We employed an appliedform of a hash-based caching method, as described in[3].
In this section, we describe the manner in which afull-text search is performed and search results arecached.The central server selects a fixed number of clientsas caches for the search results that connect for a longduration.
The central server assigns them to theequally divided range of a hash function.
A clientobtains a list of caches when it connects to the centralserver.
When a client performs a search, it calculatesthe hash value of a search keyword and sends a re-quest to the cache assigned to a section of the rangecontaining the hash value of the keyword.In an experiment described later, SHA1 is used as ahash function for clients IDs and search keywords.
Bycomparing several upper bits of hash values, we im-plement equally divided range of a hash function.If a cache does not have a search result for a searchkeyword, it forwards the search request to the centralserver.
The central server then returns the result to thecache with a search keyword, search time, and digitalsign.
The search time and digital sign that a clientreceives along with the search result from a cache canconfirm that the result is not stale and not tamperedwith by a cache.When a client sends a search request to a cache anddetects that a cache is not available because it is con-nected to the network or is overloaded, the requestsending client marks that it is not available on a list ofcaches.
It then sends the search request to a cacheassigned to the next section of the hash range.
Whenthe number of unavailable caches exceeds a certain28fixed number, it requests the central server for themost recent list of caches and updates it.5.2   A Load Balancing ExperimentIt is reported that the number of search requests foreach keyword follows Zipf distribution  [9].
Therefore,when we increase the number of caches by sub-dividing the range of a hash function, it is possiblethat search requests are concentrated to a certaincache.On the other hand, if we increase the number ofcaches by maintaining the number of sections of therange of a hash function and increasing the number ofclients assigned to each section, the cache hit ratiowould decrease.In this research, a preliminary experiment is per-formed in order to verify the advantages and disad-vantages of these alternatives.First, we generate a list of search keywords so thatthe number of requests for each keyword follows Zipfdistribution.
In this list, 40% of the queries are re-peated and requests of the most frequently repeatedword correspond to 0.2% of the entire range of re-quests.
These numbers follow the search trace ofExcite, as reported in  [9].If all search results corresponding to keywords inthis list can be cached, the cache hit ratio would be40%.Using this list, we measure the cache hit ratio, re-quired cache capacity, and the number of search re-quest counts for each cache client in the followingthree cases: (1) the range of a hash function is dividedinto 256 sections, a single client is assigned to eachsection, and 100,000 requests are sent; (2) the rangeof a hash function is divided into 1024 sections, asingle client is assigned to each section, and 400,000requests are sent; (3) the range of a hash function isdivided into 256 sections, 4 clients are assigned toeach section, and 400,000 requests are sent.
We as-sume that the same capacity is required to cache asearch result for any keyword.
Therefore, the numberof keywords that are requested more than twice arecounted as the required cache capacity.Figure 2 shows the experimental results.
Thisgraph shows the number of requests to each cache thatis sorted in a descending order.
In order to comparethese three cases, the scale of the x-axis of the resultof case (1) is expanded by four times.In case (1), although the range of the hash functionis divided equally, the number of requests to the mostfrequently requested cache is less than twice that ofthe least frequently requested one.
This shows thatboth the hash value of a frequently searched keywordand a not so frequently searched one are likely to becontained in one interval when the range is dividedinto relatively large intervals.
Thus, the search re-quests for each interval are balanced.
This result alsoshows that the cache hit ratio in case (1) is relativelyhigh.When the number of caches and search requests areincreased from that in case (1) and when the range isdivided into smaller intervals, as in case (2), searchrequests are concentrated to a certain cache, as shownin Table 1.
This shows that the search load becomesunbalanced among the caches.
However, in compari-son to case (1), the cache hit ratio is improved be-cause the number of search requests is increased inthis case.
As shown in Figure 1, the search loads arewell balanced between most of the caches except afew caches where the search requests are concentratedin case (2).
In order to balance the search load, weemployed certain techniques to forward the searchrequests from overloaded caches to others.
Currently,the above results only measure the number of searchrequests and do not consider the search load on caches.As a future work, we intend to perform a quantitativeexperiment of search load balancing under the condi-tion when our system would forward search requestsfrom overloaded caches to others.When the number of clients assigned to each sec-tion increases, as in case (3), the search load is wellbalanced as shown in Figure 2, which is similar to thatof case (1).
However, the cache hit ratio decreasesremarkably.
In order to increase the cache hit ratio inthis situation, other techniques such as hierarchicalcache would have to be used.In this experiment, we assume that the appearanceratio of repeated queries is the same.
However, due toFigure 2.
Distribution of Search Requests0200400600800100012001400(1) 256 clients 100,000 requests(2) 1024 clients 400,000 requests(3) 256x4 clients 400,000 requestsTable 1: Result of Experimentmax searchrequestscache hitratioav.
cachecapacity(1) 256 557 20.6% 75.7(2) 1024 1193 24.3% 61.4(3) 256?4 578 10.6% 42.129limited vocabulary of the users, the ratio of repeatedqueries in the entire range of queries is expected toincrease with the number of queries.
Owing to this,we can expect that the cache hit ratio does not de-crease when the number of queries increases.6   ConclusionIn this paper, some problems regarding currentlyavailable P2P content sharing systems such as contentconsistency maintenance and information search havebeen pointed out.
We proposed techniques in order tosolve these problems and described the outline of theP2P content sharing system that we are developing.This system uses a central server on which the digi-tal signs of contents publishers are maintained toprevent the tampering of contents.
Further, this sys-tem adopts a content transfer protocol that employsasymmetric encryption keys.
This protocol enables usto record content exchanges between clients on thecentral server.
On the contrary, since most other P2Pcontent sharing systems do not employ sufficienttechniques to maintain records of content exchanges,such records would be unreliable.
In particular, it isdifficult to maintain such records in decentralized P2Pcontent sharing systems.In order to solve the problem regarding informationsearch, we propose full-text search techniques for P2Pcontent sharing systems.
First, morphological analysisand summarizing of documents are performed foreach client and the results are sent to the central serverto generate reverse indexes.
We can implement arelatively efficient full-text search with this technique.More efficient and scalable full-text search techniquesbased on DHT are currently being researched.
It isdifficult to implement partial matching or AND searchby these techniques; however, they can be easily im-plemented with our method.
In order to reduce thesearch load on the central search server, we propose aload balance technique that caches search results onclients and uses a hash function to distribute searchrequests to clients.
In one of the experiments carriedout, it was seen that the search requests were satisfac-torily balanced, and the cache hit ratio was relativelyhigh for a considerably large set of search requeststhat follow Zipf distribution.We believe that content consistency maintenanceand efficient full-text search on P2P content sharingsystems can be implemented using our techniques.As a future work, we would like to consider noveltechniques to handle cases where multiple clients donot follow our content transfer protocol.
In addition,we believe it is necessary to quantitatively evaluateour implementation to confirm that our system func-tions well in a practically large-scale environment.With respect to the caching technique, we have toimprove our load balancing technique to avoid someclients from being overloaded.AcknowledgementsHideki Mima and Hideto Tomabechi express theirgratitude to the Ministry of Internal Affairs andCommunications for promoting the study in part un-der the SCOPE R&D grant scheme.References[1] P. Reynolds and A. Vahdat.
Efficient Peer-to-PeerKeyword Searching.
Middleware 2003.
[2] T. Hong.
Freenet: A distributed anonymous infor-mation storage and retrieval system.
In ICSI Work-shop on Design Issues in Anonymity and Unob-servability, 2000.
[3] David R. Karger, Eric Lehman, Frank ThomsonLeighton, Rina Panigrahy, Matthew S. Levine, andDaniel Lewin.
Consistent hashing and randomtrees: Distributed caching protocols for relievinghot spots on the World Wide Web.
In ACM Sympo-sium on Theory of Computing, pages 654-663, 1997.
[4] Napster.
http://www.napster.com/,http://opennap.sourceforge.net/.
[5] Ion Stoica, Robert Morris, David Karger, M. FransKaashoek, and Hari Balakrishnan.
Chord: A scal-able peer-to-peer lookup service for Internet appli-cations.
In Proceedings of ACM SIGCOMM?01,2001.
[6] Gnutella.
http://gnutella.wego.com/.
[7] Tylvia Ratnasamy, Paul Francis, Mark Handley,Richard Karp, and Scott Shenker.
A scalable con-tent-addressable network.
In Proceedings of ACMSIGCOMM?01, 2001.
[8] Jinyang Li, Boon Thau Loo, Joseph M. Hellerstein,M.
Frans Kaashoek, David R. Karger, Robert Mor-ris.
On the feasibility of peer-to-peer web indexingand search.
In 2nd International Workshop onPeer-to-Peer Systems, 2003.
[9] Yinglian Xie and David O'Hallaron.
Locality insearch engine queries and its implications for cach-ing.
IEEE Infocom 2002, 2002.
[10] Yasuaki Takebe, Hideki Mima, Hideto Tomabechi.A next-generation P2P contents sharing system?implementing content consistency maintenance andfull-text search.
In 11th DPS Workshop, 2003.30
