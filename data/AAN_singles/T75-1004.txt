~YNTACTIC PROCESSING AND~UNCTIONAL SENTENCE PERSPECTIVEMartin KayXEROX PARCThis paper contains some ideas thatnave occurred to me in the course of someprel iminary work on the notion of reversiblegrammar.
In order to make it possible togenerate and analyze sentences with the samegrammar, represented in the same way, I wasled to consider restr ict ions on theexpressive power of the formal ism that wouldbe acceptible only if the structures ofsentences contained more information thanAmerican l inguisits have usual ly beenprepared to admit.
I hope to convey to yousome of my surprise and delight in f indingthat certain l inguists of the Prague schoolargue for the representat ion of this sameinformation on altogether different grounds.I.
REVERSIBLE GRAMMARSFor me, a grammar is not so much a setof wel l - formedness condit ions on strings ofwords as a relation between strings of words(sentences) and structures.
Usual ly it isconstruct ive in the sense that there is adevice that interprets it to convert eitherstructures into sentences (a generator) orsentences into structures (a parser).
Agrammar for which both a generator and aparser can be found is what I callreversible and, of course, what I aminterested in is not so much part icularreversible grammars as a formal ism whichguarantees reversibi l i ty for any grammarthat adheres to it.
Context- free grammarsare clearly reversible in this sense andtransformat ional  grammars are clearly not.Augmented Transit ion Networks (ATNs) arereversible provided some quite reasonablerestr ict ions are placed on the operationsthat can be performed on registers.
This isnot to say that it is a tr ivial  matter toobtain a generator from an arbitrary ATNgrammar.It goes w i thout  saying that thecomposit ion of a generator and a parserinterpret ing the same reversible grammar onthe same sentence or structure does not, ingeneral, perform the identitytransformation.
Frequently, sentences areambiguous and structures often correspond tosets of more than oneparaphrase.
Parsing fol lowed by generat ionof each member of the result ing set ofstructures will therefore yield thegrammatical  paraphrases of the originalunder all grammatical  interpretat ions.The practical advantages of areversible grammar are obvious.
A computerprogram that engages in any kind ofconversat ion must both parse and generateand it would be economical  to base bothprocesses on the same grammar.
But, to me,the theoret ical  appeal is stronger.
It isplausible that we have something in ourheads that fills the function I am ascr ibingto grammar, though I am not insensit ive tothe claims of those who deny this.
But itis a l together implausible that we have twosuch things, one for parsing and one forgeneration, essent ial ly unrelated to oneanother.A left -to-r ight generator is one thatdeposits words into the output str ing oneafter another, in left -to-r ight sequence.
Aleft - to-r ight parser is one that examinesthe words of the input string one afteranother, from left to right.
Aleft - to-r ight reversible grammar is one forwhich there is a left -to-r ight generator anda left - to-r ight parser.
Once again, it isclear that context- free grammars, in theusual notation, meet the requirements.
ATNgrammars probably do not.
They certainly donot if we exclude the possib i l i ty  ofent ire ly reworking the grammar andpresent ing it in an ent irely new form to thegenerator.
The kind of grammar I have inmind would require no such  reworking.Intuit ively, the notion is a simple one.
Itis very like an ATN in that it analysessentences by moving through a network,examining the input string at eacht rans i t ion  and, if the current symbol meetsthe condit ions specif ied for the transit ion,ass igning it to a register.
The generatorwould also move through the network, makingexactly the same transit ions, but deposit ingthe contents of registers into the str ing ateach step.2.
THE PROCESSORGenerators and parsers for the kind ofrevers ible grammar I have in mind could beimplemented in a great variety of ways.
Oneof the simplest I know would be to use aversion of the General Syntact ic Processor(GSP).
GSP contains:(I) a grammar in the form of atransi t ion network, that is, aairected graph in which thewermissible transit ions betweenstates are represented by arcs, eachlabeled with a more or lesscompl icated set of act ions whicheetermine the appl icabi l i ty  of thearc and cause side effects, such asthe assignment of values tore~isters,(2) an agenda of tasks to be carr iedout,(3) a chart, that is, a directed graphconsist ing of ?ert iees and edgeswhich represents the sentence beinganalyzed or generated together with1~s component parts--phrases,In~ermediate derivations,  orwhatever--which,  together with theagenda, completely encapsulates thestate of the entire processor at anyglven point in its operation,(4) a set of schedul in~ rules whose jobis to determine the order in whichthe tasks on  the agenda wil l  becarr ied out, ana(5) the interpreter ?~self.Edges in the chart are either completeor incomplete.
Complete edges represent12.completely specif ied words or phrases and,if there is a path through the chart fromone edge to another, it is because the f i r s tprecedes the second in temporal, orleft-to-r ight,  sequence.
If there is nopath from one to another, then they belongto alternat ive hypotheses about thestructure of of the sentence.
So, thesentence "they are f lying planes" has, letus say, two analyses, each consist ing of anoun phrase fol lowed by a verb phrase.
Butthere is no path between the phrases in oneanalysis and those in the other.
The verbphrase in one analysis consists of the verb"are" fol lowed by the noun phrase "flyingplanes", which are therefore adjacent on thesame path, but there is no path from eitherof them to the verb phrase they make upbecause this is an alternative analysis ofthe same set of words.An incomplete edge represents part of aphrase together with an indicat ion of  whatwould have to be added to complete it.
Forexample, an incomplete noun phrase mightinclude the string "the big black" plus anindicat ion that a fo l lowing noun, possiblypreceded by some more adjectives, wouldcomplete it.
A special kind of incompleteedge is an empty edge.
Empty edges aresuccessors of themselves.
In other words,they are always incident from and to thesame vertex, ref lecting the fact that theyrepresent no part of the sentence, butmerely the potential for f inding somestructural  component.
The specif icat ion ofhow an incomplete edge can be completedtakes the form of one or more arcs in thegrammar, each paired with a direct ion-- leftor right.
If the direction is right, thencomplet ion can be achieved by fo l lowingsequences of arcs incident fro~ the givenstate; if it is left, then arcs incident tothe state must be followed.The interpreter uses the schedul ingrules to chose an item on the agenda whichit then carries out.
If all the tasks thatwere ever put on the agenda in the course ofgeneration or analysis were carr ied out inan arbitrary order, then all results thatthe grammar al lowed would be obtained sooneror later.
The scheduling rules formalizestrategie~ of one kind and another.
Theyare presumably designed so as to shorten thetime required to reach a result which is, insome sense, acceptable, at which time theremaining entries on the agenda can simplybe abandoned.The typical  task is an attempt to applyan arc from the grammar to an edge in thechart.
If the arc applies successfully,~ome new material  will be added to thechart.
In generation, the new materialtypical ly consists of one or two new edgesconst i tut ing a sequence with the same endpoints as those of the initial edge.usually, no more than one of the newlyintroduced edges will be incomplete.
Thus,there might be a task in which an arc wasappl ied to the noun-phrase edge representing"the big black dog" and which resulted inthe complete art icle "the" and theincomplete noun phrase "big black dog".
Inparsing, the task specif ies one or twoi3.euges, one of which is incomplete.
The ideais to  attempt to take the complete edge atleast one step nearer to complet ion byincorporat ing the other edge.
If only oneedge is specif ied, then the new edge willhave the same end points as the original,but wil l  presumably be di f ferent ly labeled.Within this version of GSP,top-to-bottom, left-to-r ight parsing, in themanner of an ATN parser, proceeds broadly asfollows:I.
Whenever, as the result of introducinga new edge into the chart, a newsequence consist ing of an incompleteeage fol lowed by a complete one comesinto existance, put a new task on theagenda for each of the "category" arcsnamed on the incomplete edge.
Whenone of these tasks is executed, thearc will be applied to the completee e giving rise, if successful,  to anew edge~ complete or incomplete.2.
Whenever a new incomplete edge isIntroduced that names a "Pop" or"Jump" arc, create tasks that willcause these to be carried out.3.
Place an empty sentence edge beforethe first word of the sentence.The process starts with step 3, whichimmediately causes a sequence of instancesu~ steps I and 2.An incomplete edge represents a stackframe in the ATN processor.
It is labeledwith a set of registers and it spans aportion of the chart represent ing the partof the str ing so far analyzed.
"Category"arcs are appl ied to an incomplete edge and acomplete edge immediately to its right.
Ifsuccessful,  the result is a new incompleteedge.
"Pop" arcs produce a complete edge,in exchange for an incomplete one.
"Jump"arcs produce an incomplete edge in exchangefor an incomplete edge, the dif ferencesbeing in the arcs that specify how toproceed towards completion, and possibly inthe labe l .It turns out that the mechanism ofFecursive calls that "Push" and "Pop" arcsprovide for is embraced by the devicesalready described.
Suppose that sentencesare to be analyzed as consist ing of a nounphrase fol lowed by a verb phrase and that anoun phrase, say "the big black dog" hassomehow been recognized at the beginning ofthe sentence.
This means that there will bea complete edge representing this nounphrase and an incomplete sentence edge whichhas the same end points with an arcspeci fy ing that a verb phrase with asingular, third-person verb, is to follow.Since the grammar contains a subnetworkgiving the structure of verb phrases, anempty edge labeled with the category "verbphrase" is introduced fol lowing thatincomplete sentence provided there is notone already there.
In due course, this willpresumably cause a complete verb phrase toappear.
The general principle is this:whenever an incomplete edge specif ies a"category" arc for wnlch ~nere is acorresponding subnetwork, an empty edge iscreated fol lowing that one for each of theinit ial arcs in the subnetwork in the hopethat this will lead to the creation of a newcomplete edge that the "category" arc can besuccessful ly applied to.3.
THE USE OF REGISTERSThe principal problem with this simpleplan, when applied to reversible grammars,is that the registers cannot be guaranteedto have the necessary contents at the timerequired.
One of the strengths of the ATNformalism is that it al lows the parser to"change its mind".
The canonical example isthe passive construction.
The first verbphrase in the sentence is assigned to thesubject register.
But when a passiveverb--part of the verb "be" and a transit ivepast part ic ip le--has been encountered, thecontents of the subject register are simplytransferred to the object register.
If a"by" phrase follows, its object wil l  latergo into the subject register.
In this way,a great deal of backing up is avoided.In generat ing a passive sentence, it isclear that the first step cannot be todeposit the contents of the subject registerin the first position.
An alternat ive mightbe to decide which register to use infi l l ing the first posit ion by examining a"voice" register, using the object insteadof the subject register if its value is"passive".
But this would require us toassign a value to the voice register inparsing before the relevant evidence is in.It would work only if the contents of thevoice register were changed at the same timeas the passive verb was recognized and thecontents of the subject register were movedto the object register.
It could indeed bemade to work, but the solution isunsat isfactory because it does not reflectany general principle that carries over toother cases.
More important, it violates aprincple that must be regarded asfundamental for the achievement ofrevers ib i l i ty  in general, namely that eachelementary operation that an arc in thegrammar can specify must have twosystematical ly  related interpretat ions,  foruse in generation and parsing respectively.Another solution would be to assign thefirst noun phrase to a neutral register whenit is encountered in parsing, and only tocopy it into the subject or object registerswhen it was finally establ ished which one itbelonged in.
This neutral  register wouldhave to be reflected direct ly in thestructure assigned to the sentence becauseit would be from there that the first nounphrase in the sentence would have to betaken by the generator.
One advantage ofthis scheme is that a passive marker ~ ,Idno longer be required in the structure of"passive sentences.
Instead, the voice of asentence would be determined by thegenerator on the asis o~ whichregister- -subject  or object- -had the samecontents as the special neutral  register.The general principle behind this strategyis that ~he contents of a regi ster are neverchanged in the course ~f either generation14.or parsing.
This is the solut ion Iadvocate.A name is needed for the neutralregister, and topic, or theme, suggestthemselves immediately.
But consider thecase of cleft sentences like "It was Brutusthat ki l led Caesar" and "It was Caesar thatBrutus ki l led" and assume, for the sake ofthe argument, that these are to be handledas main clauses and not by there lat ive-c lause mechanism.
Once again, theunder ly ing grammatical  function of the firstnoun phrase is not known when the parserfirst encounters it.
The problem can besolved by the same device, but of all thenames one might choose for the neutralregister, "topic" is least appropr iate inthis instance.
Something like focus orcomment would be more to the point.
What,then, of datives?
Consider "He gave Fido abone" and "He gave Fido to Mary".
Theproblem here is the noun phrase fol lowingthe verb.
In neither case can weconvinc ingly argue that it is either thetopic or the focus of the sentence.4.
FUNCTIONAL SENTENCE PERSPECTIVEThe most sat isfying solut ion to theseproblems is to be found in the work of thePrague school of l inguists, part icular lyMathesius, Firbas, Danes, and Sgall.
Thebasic notion is that of the Funct ionalSentence Perspect ive according to whichtopic and focus are two regions in the scaleof communicat ive dynamism along which eachof the major const i tuents of a sentence areordered.
In the unmarked case, eachsucceding const ituent in the surface stringhas a higher degree of communicat ivedynamism.
The point on the scale at whichone passes from topic to focus may or maynot be marked.
In speech, special  stresscan be used to mark any element as thefocus; in wr i t ing ,  several devices likec left ing fill the same role.Communicat ive dynamism correlates witha number of other notions that are morefamil iar in this part of the world.g lements that are low on this scale are theones that are more contextual ly  bound, whichis to say that they involve presupposi t ionsabout the preceding text.
In "It was Brutusthat ki l led Caesar", "that ki l led Caesar" isthe topic and it c learly involves thepresupposi t ion that someone ki l led Caesar.in an unmarked sentence, like "Brutus ki l ledCaesar", it is not clear whether thedividing line between topic and comment~alls before or after the verb; there arenevertheless three degrees of communicat ivedynamism involved.According to this .iew, the di f ferencebetween "He gave Fido to Mary" and "He gaveMary Fido" is not in what is topic and whatis focus but simply in the posit ions that"Mary" and "Fido" occupy on the scale ofcommunicat ive dynamism.
Consider thesentences:(I) John did all the work, but they gavethe reward to Bill.
(2) John did all the work, but they gaveBill the reward.
(3) They were so impressed with the workthat they gave Bill a reward.
(4) They were so impressed with the workthat they gave a reward to Bill.I c laim that (2) and (4) are less naturalthan (I) and (3) when read with evenintonation.
Sentence (5), with underl in ingfor stress, is, of course, quite natural,and (6) is questionable.
(5) John did all the work, but they gaveBill the reward.
(6) They were so impressed with the workthat they gave a reward to Bill.The claim is simply that the last itemcarries the greatest communicat ive load,represents the most novel component of thesentence.This is consistent with the observat ionthat dative movement is at best awkward whenthe direct object is a pronoun, as in(7) I gave him it.and it becomes more awkward when theindirect object is more ponderous, as in(8) I gave the man you said you had seenit.In fact, it is consistent with theobservat ion that ponderous const ituents tendto be deferred, using such devices asextraposit lon.
It is in the nature ofpronouns that they are contextual ly bound,and the complexity of large const ituentspresumably comes directly from the fact thatthey tend to convey new information.What this suggests is a formalism inwhich the structure of a phrase is a list ofattr ibutes named for grammatical  functions,whose values are words or other phrases.They are ordered so as to show thereposit ions on the scale of communicat ivedynamism and there is provision for a markerto be introduced into the list expl ic it lyseparat ing the topic from the focus.Consider ing only the sentence level, ands impl i fy ing greatly, this would giveexamples like the following, using " / "asthe marker:\ [Subject: John Verb:gave Dir-obj :(thecandy) Indir-obj:Mary\] => "John gavethe candy to Mary"\[ Indir-obJ:Mary Verb:gave Dir-obj : ( thecandy) Subject: John\] => "Mary wasgiven the candy by John"\[Verb:gave Dir-obJ:(the candy)Indir-obJ:Mary / Subject: John\] =>"It was John that gave Mary thecandy" or "John gave Mary the candy"\[Subject: John Verb:gave Dir-obj :(thecandy) / Indir-obj:Mary\] => "It wasMary that John gave the candy to"\[Subject: John Dir -obj : ( the candy) /Verb:gave Indir-obj :Mary\]  => "WhatJohn did with the candy was give itto Mary"The impl icat ions for reversiblesyntactic processing seem to be as follows:The famil iar set of registers, named for themost part for the names of grammaticalfunctions, are supplemented by three otherscal led topic, focus and, say, marker.Marker wil l  have a value only when thesentence is marked in the sense I have beenus ing .
Topic and focus will contain orderedlists of elements.
The structure of apassive sentence, for example, will berecognizable by the fact that it is unmarkedand has a patient (dative, or whatever) asthe first item on its topic list.
Theparser wil l  place the first noun phrase in a"standard" sentence on this list and onlycopy it into some other register later.
Thegenerator will ~ unload the first item intothe str ing and decide later what form ofverb to produce.The i l l - formedness of the ideas I havetried to present here is clear for all tosee.
I have so far acquired only the mosttenuous grasp of what the Czech l inguistsare doing and, while I should publ ic ly thankPetr Sgall for his patience in explaining itto me, it is only right that I should alsoappologise for the egregious errors I havedoubtless been guilty of.
But, whatevererrors of detail  there may be, one importantpoint will, I hope, remain.
The notions oftopic and focus are clearly well motivatedin theoret ical  l inguistics, and the richernot ion of functional sentence perspectiveprobably is also.
I have been led to thesesame notions for purely technical  reasonsar is ing out of my desire to build areversible syntactic processor.REFERENCESFirbas, J.
"On Defining the Theme inFunct ional  Sentence Analysis", TravauxL inguist iques d_ee Pragu_ee, Vol.
I, pp267-280, 1964.Kaplan, Ronald M. A General SyntacticProcessor in Randall Rustin(ed.)
"NaturalLanguage Processing", New York,Algor i thmics Press, 1973.Mathesius, V. "Zur Satzperspekt ive inmodernen English", Archiv fuer dasStudium der neueren Sprachen undLiteraturen, Vol.
155, pp.
202-210,1929.15.
