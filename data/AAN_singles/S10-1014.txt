Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 81?85,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsSemEval-2010 Task 18:Disambiguating Sentiment Ambiguous AdjectivesYunfang WuKey Laboratory of ComputationalLinguistics (Peking University)?Ministry of Education, Chinawuyf@pku.edu.cnPeng JinLaboratory of Intelligent InformationProcessing and Application, LeshanNormal University, Chinajinp@lstc.edu.cnAbstractSentiment ambiguous adjectives causemajor difficulties for existing algorithmsof sentiment analysis.
We present anevaluation task designed to provide aframework for comparing differentapproaches in this problem.
We define thetask, describe the data creation, list theparticipating systems and discuss theirresults.
There are 8 teams and 16 systems.1 IntroductionIn recent years, sentiment analysis has attractedconsiderable attention (Pang and Lee, 2008).
It isthe task of mining positive and negative opinionsfrom natural language, which can be applied tomany natural language processing tasks, such asdocument summarization and question answering.Previous work on this problem falls into threegroups: opinion mining of documents, sentimentclassification of sentences and polarity predictionof words.
Sentiment analysis both at documentand sentence level rely heavily on word level.The most frequently explored task at wordlevel is to determine the semantic orientation(SO) of words, in which most work centers onassigning a prior polarity to words or wordsenses in the lexicon out of context.
However,for some words, the polarity varies strongly withcontext, making it hard to attach each to aspecific sentiment category in the lexicon.
Forexample, consider ?low cost?
versus ?lowsalary?.
The word ?low?
has a positiveorientation in the first case but a negativeorientation in the second case.Turney and Littman (2003) claimed thatsentiment ambiguous words could not be avoidedeasily in a real-world application in the futureresearch.
But unfortunately, sentimentambiguous words are discarded by most researchconcerning sentiment analysis (Hatzivassiloglouand McKeown, 1997; Turney and Littman, 2003;Kim and Hovy, 2004).
The exception work isDing et al (2008).
They call these words ascontext dependant opinions and propose aholistic lexicon-based approach to solve thisproblem.
The language they deal with is English.The disambiguation of sentiment ambiguouswords can also be considered as a problem ofphrase-level sentiment analysis.
Wilson et al(2005) present a two-step process to recognizecontextual polarity that employs machinelearning and a variety of features.
Takamura et al(2006, 2007) propose latent variable model andlexical network to determine SO of phrases,focusing on ?noun+adjective?
pairs.
Theirexperimental results suggest that theclassification of pairs containing ambiguousadjectives is much harder than those withunambiguous adjectives.The task 18 at SemEval 2010 provides abenchmark data set to encourage studies on thisproblem.
This paper is organized as follows.Section 2 defines the task.
Section 3 describesthe data annotation.
Section 4 gives a briefsummary of 16 participating systems.
FinallySection 5 draws conclusions.2 Task Set up2.1 Task descriptionIn this task, we focus on 14 frequently usedsentiment ambiguous adjectives in Chinese,which all have the meaning of measurement, asshown below.81(1) Sentiment ambiguous adjectives(SAAs)={?
da ?large?, ?
duo ?many?, ?
gao?high?, ?
hou ?thick?,?
shen ?deep?, ?zhong ?heavy?, ??
ju-da ?huge?, ?
?zhong-da ?great?, ?
xiao ?small?, ?
shao?few?, ?
di ?low?, ?
bao ?thin?, ?
qian?shallow?,?
qing ?light?
}These adjectives are neutral out of context, butwhen they co-occur with some target nouns,positive or negative emotion will be evoked.Although the number of such ambiguousadjectives is not large, they are frequently usedin real text, especially in the texts expressingopinions and emotions.The task is designed to automaticallydetermine the SO of these sentiment ambiguousadjectives within context: positive or negative.For example, ?
gao ?high?should be assignedas positive in ???
gong-zi-gao ?salary ishigh?but negative in ???
jia-ge-gao ?price ishigh?.This task was carried out in an unsupervisedsetting.
No training data was provided, butexternal resources are encouraged to use.2.2 Data CreationWe collected data from two sources.
The mainpart was extracted from Xinhua News Agency ofChinese Gigaword (Second Edition) released byLDC.
The texts were automatically word-segmented and POS-tagged using the opensoftware ICTCLAS1.
In order to concentrate onthe disambiguation of sentiment ambiguousadjectives, and reduce the noise introduced bythe parser, we extracted sentences containingstrings in pattern of (2), where the target nounsare modified by the adjectives in most cases.
(2) noun+adverb+adjective (adjective?SAAs)e.g.?
?/n ?/d ?/a cheng-ben-jiao-di?the cost is low.
?Another small part of data was extracted fromthe Web.
Using the search engine Google2, wesearched the queries as in (3):(3) ?
hen ?very?+ adjective (adjective?SAAs )From the returned snippets, we manually pickedout some sentences that contain the strings of (2).Also, the sentences were automaticallysegmented and POS-tagged using ICTCLAS.Sentiment ambiguous adjectives in the datawere assigned as positive, negative or neutral,1 http://www.ictclas.org/.2 http://www.google.com/.independently by two annotators.
Since we focuson the distinction between positive and negativecategories, the neutral instances were removed.The inter-annotator agreement is in a high levelwith a kappa of 0.91.
After cases withdisagreement were negotiated between the twoannotators, a gold standard annotation wasagreed upon.
In total 2917 instances wereprovided as the test data in the task, and thenumber of sentences of per target adjective islisted in Table 2.Evaluation was performed in micro accuracyand macro accuracy:1 1/N Nmir i ii iP m n?
???
?
(1)1/Nmar iiP P N???
/i i iP m n?
(2)where N is the number of all target words, in isthe number of all test instances for a specificword, and im is the number of correctly labeledinstances.2.3 BaselineWe group 14 sentiment ambiguous adjectivesinto two categories: positive-like adjectives andnegative-like adjectives.
The former has theconnotation towards large measurement, whereasthe latter towards small measurement.
(4) Positive-like adjectives (Pa) ={?
da ?large?,?
duo ?many?, ?
gao ?high?, ?
hou?thick?, ?
shen ?deep?, ?
zhong ?heavy?,??
ju-da ?huge?,??
zhong-da ?great?
}(5) Negative-like adjectives (Na) ={?
xiao?small?, ?
shao ?few?, ?
di ?low?,?
bao?thin?, ?
qian ?shallow?,?
qing ?light?
}We conduct a baseline in the dataset.
Notconsidering the context, assign all positive-likeadjectives as positive and all negative-likeadjectives as negative.
The micro accuracy of thebaseline is 61.20%.The inter-annotator agreement of 0.91 can beconsidered as the upper bound of the dataset.3 Systems and ResultsWe published firstly trial data and then test data.In total 11 different teams downloaded both thetrial and test data.
Finally 8 teams submitted theirexperimental results, including 16 systems.823.1 ResultsTable 1 lists all systems?scores, ranked frombest to worst performance measured by microaccuracy.
To our surprise, the performance ofdifferent systems differs greatly.
The microaccuracy of the best system is 94.20% that is43.12% higher than the worst system.
Theaccuracy of the best three systems is even higherthan inter-annotator agreement.
The performanceof the worst system is only a little higher thanrandom baseline, which is 50% when werandomly assign the SO of sentiment ambiguousadjectives.Table 1: The scores of 16 systemsTable 2 shows that the performance ofdifferent systems differs greatly on each of 14target adjectives.
For example, the accuracy of?
da ?large?is 95.53% by one system but only46.51% by another system.Table 2: The scores of 14 ambiguous adjectives3.2 SystemsIn this section, we give a brief description of thesystems.YSC-DSAA This system creates a new wordlibrary named SAAOL (SAA-Oriented Library),which is built manually with the help of software.SAAOL consists of positive words, negativewords, NSSA, PSSA, and inverse words.
Thesystem divides the sentences into clauses usingheuristic rules, and disambiguates SAA byanalyzing the relationship between SAA and thekeywords.HITSZ_CITYU This group submitted threesystems, including one baseline system and twoimproved systems.HITSZ_CITYU_3: The baseline system isbased on collocation of opinion words and theirtargets.
For the given adjectives, theircollocations are extracted from People?s DailyCorpus.
With human annotation, the systemobtained 412 positive and 191 negativecollocations, which are regarded as seedcollocations.
Using the context words of seedcollocations as features, the system trains a one-class SVM classifier.HITSZ_CITYU_2 and HITSZ_CITYU_1:Using HowNet-based word similarity as clue, theauthors expand the seed collocations on bothambiguous adjectives side and collocated targetsside.
The authors then exploit sentence-levelopinion analysis to further improve performance.The strategy is that if the neighboring sentenceson both sides have the same polarity, theambiguous adjective is assigned as the samepolarity; if the neighboring sentences haveconflicted polarity, the SO of ambiguousadjective is determined by its context words andthe transitive probability of sentence polarity.The two systems use different parameters andcombination strategy.OpAL This system combines supervisedmethods with unsupervised ones.
The authorsemploy Google translator to translate the taskdataset from Chinese to English, since theirsystem is working in English.
The systemexplores three types of judgments.
The first onetrains a SVM classifier based on NTCIR data andEmotiBlog annotations.
The second one usessearch engine, issuing queries of ?noun + SAA +AND + non-ambiguous adjective?.
The non-ambiguous adjectives include positive set(?positive, beautiful, good?)
and negative set(?negative, ugly, bad?).
An example is ?pricehigh and good?.
The third one uses ?too, very-System MicroAcc.(%)MacroAcc.
(%)YSC-DSAA 94.20 92.93HITSZ_CITYU_1 93.62 95.32HITSZ_CITYU_2 93.32 95.79Dsaa 88.07 86.20OpAL 76.04 70.38CityUHK4 72.47 69.80CityUHK3 71.55 75.54HITSZ_CITYU_3 66.58 62.94QLK_DSAA_R 64.18 69.54CityUHK2 62.63 60.85CityUHK1 61.98 67.89QLK_DSAA_NR 59.72 65.68Twitter Sentiment 59.00 62.27Twitter Sentiment_ext 56.77 61.09Twitter Sentiment_zh 56.46 59.63Biparty 51.08 51.26Words Ins# Max% Min% Stdev?
|large 559 95.53 46.51 0.155?
|many 222 95.50 49.10 0.152?
||high 546 95.60 54.95 0.139?
|thick 20 95.00 35.00 0.160?
|deep 45 100.00 51.11 0.176?
|heavy 259 96.91 34.75 0.184??
|huge 49 100.00 10.20 0.273??
|great 28 100.00 7.14 0.243?
|small 290 93.10 49.66 0.167?
few 310 95.81 41.29 0.184?
|low 521 93.67 48.37 0.147?
|thin 33 100.00 18.18 0.248?
|shallow 8 100.00 37.50 0.155?
|light 26 100.00 34.62 0.19783rules?.
The final result is determined by themajority vote of the three components.CityUHK This group submitted four systems.Both machine learning method and lexicon-based method are employed in their systems.
Inthe machine learning method, maximum entropymodel is used to train a classifier based on theChinese data from NTCIR opinion task.
Clause-level and sentence-level classifiers are compared.In the lexicon-based method, the authors classifySAAs into two clusters: intensifiers (ourpositive-like adjectives in (4)) and suppressors(our negative-like adjectives in (5)), and then usethe polarity of context to determine the SO ofSAAs.CityUHK4: clause-level machine learning +lexicon.CityUHK3: sentence-level machine learning +lexicon.CityUHK2: clause-level machine learning.CityUHK2: sentence-level machine learning.QLK_DSAA This group submitted twosystems.
The authors adopt their SELC model(Qiu, et al, 2009), which is proposed to exploitthe complementarities between lexicon-basedand corpus-based methods to improve the wholeperformance.
They determine the sentencepolarity by SELC model, and simply regard thesentence polarity as the polarity of SAA in thesentence.QLK_DSAA_NR: Based on the result ofSELC model, they inverse the SO of SAA whenit is modified by negative terms.
Our taskincludes only positive and negative categories, sothey replace the neutral value obtained by SELCmodel by the predominant polarity of theadjective.QLK_DSAA_R: Based on the result ofQLK_DSAA_NR, they add a rule to cope withtwo modifiers ?
pian ?specially?
and ?
tai?too?, which always have the negative meaning.Twitter sentiment This group submitted threesystems.
The authors use a training data collectedfrom microblogging platform.
By exploitingTwitter, they collected automatically a datasetconsisting of negative and positive expressions.The sentiment classifier is trained using NaiveBayes with n-grams of words as features.Twitter Sentiment: Translating the task datasetfrom Chinese to English using Google translator,and then based on training data in English textsfrom Twitter.Twitter Sentiment_ext: With TwitterSentiment as basis, using extended data.Twitter Sentiment_zh: Based on training datain Chinese texts from Twitter.Biparty This system transforms the problemof disambiguating SAAs to predict the polarityof target nouns.
The system presents abootstrapping method to automatically build thesentiment lexicon, by building a nouns-verbsbiparty graph from a large corpus.
Firstly theyselect a few nouns as seed words, and then theyuse a cross inducing method to expand morenouns and verbs into the lexicon.
The strategy isbased on a random walk model.4 DiscussionThe experimental results of some systems arepromising.
The micro accuracy of the best threesystems is over 93%.
Therefore, the inter-annotator agreement (91%) is not an upperbound on the accuracy that can be achieved.
Onthe contrary, the experimental results of somesystems are disappointing, which are below ourpredefined simple baseline (61.20%), and areonly a little higher than random baseline (50%).The accuracy variance of different systemsmakes this task more interesting.The participating 8 teams exploit totallydifferent methods.Human annotation.
In YSC-DSAA system,the word library of SAAOL is verified by human.In HITSZ_CITYU systems, the seed collocationsare annotated by human.
The three systems ranktop 3.
Undoubtedly, human labor can helpimprove the performance in this task.Training data.
The OpAL system employsSVM machine learning based on NTCIR dataand EmotiBlog annotations.
The CityUHKsystems trains a maximum entropy classifierbased on the annotated Chinese data fromNTCIR.
The Twitter Sentiment systems use atraining data automatically collected fromTwitter.
The results show that some of thesesupervised methods based on training datacannot rival unsupervised ones, partly due to thepoor quality of the training data.English resources.
Our task is in Chinese.Some systems use English resources bytranslating Chinese into English, as OpAL andTwitter Sentiment.
The OpAL system achieves aquite good result, making this method apromising direction.
This also shows thatdisambiguating SAAs is a common problem innatural language.845 ConclusionThis paper describes task 18 at SemEval-2010,disambiguating sentiment ambiguous adjectives.The experimental results of the 16 participatingsystems are promising, and the used approachesare quite novel.We encourage further research into this issue,and integration of the disambiguation ofsentiment ambiguous adjectives into applicationsof sentiment analysis.AcknowledgmentsThis work was supported by National NaturalScience Foundation of China (No.
60703063),National Social Science Foundation of China(No.
08CYY016), and the Open ProjectsProgram of Key Laboratory of ComputationalLinguistics(Peking University) ?
Ministry ofEducation.
We thank Miaomiao Wen and TaoGuo for careful annotation of the data.ReferencesDing X., Liu B. and Yu, P. 2008.
A holistic lexicon-based approach to opinion mining.
Proceedings ofWSDM?08.Hatzivassiloglou, V. and McKeown, K. 1997Predicting the semantic orientation of adjectives.Proceedings of ACL?97.Kim, S and Hovy, E. 2004.
Determining the sentimentof opinions.
Proceedings of COLING?04.Pang, B. and Lee, L. 2008.
Opinion mining andsentiment analysis.
Foundations and Trends inInformation Retrieval.Qiu L., Zhang W., Hu, C. and Zhao, K. 2009.
SELC:A self-supervised model for sentiment analysis.
InProceedings of CIKM?09.Takamura, H., Inui,T.
and Okumura, M. 2006.
LatentVariable Models for Semantic Orientations ofphrases.
Proceedings of EACL?06.Takamura, H., Inui,T.
and Okumura, M. 2007.Extracting Semantic Orientations of Phrases fromDictionary.
Proceedings of NAACL HLT ?07.Turney, P. and Littman, M. 2003.
Measuring praiseand criticism: inference of semantic orientationfrom association.
ACM transaction on informationsystems.Wilson, T., Wiebe, J. and Hoffmann, P. 2005.Recognizing contextual polarity in phrase-levelsentiment analysis.
Proceedings ofHLT/EMNLP?05.85
