Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 531?536,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsModeling the Interpretation of Discourse Connectivesby Bayesian PragmaticsFrances YungNara Institute of Science and Technology8916-5 Takayama, Ikoma,Nara, 630-0101, Japanpikyufrances-y@is.naist.jpKevin DuhJohn Hopkins University810 Wyman Park Drive,Baltimore, MD 21211-2840, USAkevinduh@cs.jhu.eduTaku KomuraUniversity of Edinburgh10 Crichton Street,Edinburgh, EH8 9AB, United Kingdomtkomura@inf.ed.ac.ukYuji MatsumotoNara Institute of Science and Technology8916-5 Takayama, Ikoma,Nara, 630-0101, Japanmatsu@is.naist.jpAbstractWe propose a framework to model hu-man comprehension of discourse connec-tives.
Following the Bayesian pragmaticparadigm, we advocate that discourse con-nectives are interpreted based on a sim-ulation of the production process by thespeaker, who, in turn, considers the ease ofinterpretation for the listener when choos-ing connectives.
Evaluation against thesense annotation of the Penn DiscourseTreebank confirms the superiority of themodel over literal comprehension.
A fur-ther experiment demonstrates that the pro-posed model also improves automatic dis-course parsing.1 IntroductionA growing body of evidence shows that humaninterpretation and production of natural languageare inter-related (Clark, 1996; Pickering and Gar-rod, 2007; Zeevat, 2011; Zeevat, 2015).
In par-ticular, evidence shows that during interpretation,listeners simulate how the utterance is produced;and during language production, speakers simu-late how the utterance will be perceived.
Oneexplanation is that the human brain reasons byBayesian inference (Doya, 2007; Kilner et al,2007), which is, at the same time, a popular for-mulation used in language technology.In this work, we model how humans interpretthe sense of a discourse relation based on theBayesian pragmatic framework.
Discourse rela-tions are relations between units of texts that makea document coherent.
These relations are eithermarked by discourse connectives (DCs), such as?but?, ?as a result?, or implied implicitly, as in thefollowing examples:1.
He came late.
In fact, he came at noon.2.
It is late.
I will go to bed.The explicit DC ?in fact?
in Example (1) marks aSpecification relation.
On the other hand, a Resultrelation can be inferred between the two sentencesin Example (2) although there are not any explicitmarkers.
We say the two sentences (called argu-ments) are connected by an implicit DC.Discourse relations have a mixture of semanticand pragmatic properties (Van Dijk, 1980; Lewis,2006).
For example, the sense of a discourse rela-tion is encoded in the semantics of a DC (Exam-ple (1)), yet the interpretation of polysemic DCs(such as ?since?, ?as?)
and implicit DCs relies onthe pragmatic context (Example (2)).This work seeks to find out if Bayesian prag-matic approaches are applicable to human com-prehension of discourse relations.
Our contribu-tion includes: (i) an adaptation of the BayesianRational Speech Acts model to DC interpretationusing a discourse-annotated corpus, the Penn Dis-course Treebank; (ii) integration of the proposedmodel with a state-of-the-art automatic discourseparser to improve discourse sense classification.2 Related workThere is increasing literature arguing that the hu-man motor control and sensory systems make es-timations based on a Bayesian perspective (Doya,2007; Oaksford and Chater, 2009).
For example, itis proposed that the brain?s mirror neuron system531recognizes a perceptual input by Bayesian infer-ence (Kilner et al, 2007).
Similarly, behavioural,physiological and neurocognitive evidences sup-port that the human brain reasons about the uncer-tainty in natural languages comprehension by em-ulating the language production processes (Galan-tucci et al, 2006; Pickering and Garrod, 2013).Analogous to this principle of Bayesian lan-guage perception, a series of studies have devel-oped the Grice?s Maxims (Grice, 1975) based ongame-theoretic approaches (J?ager, 2012; Frankand Goodman, 2012; Goodman and Stuhlm?uller,2013; Goodman and Lassiter, 2014; Benz et al,2016).
These proposals argue that the speaker andthe listener cooperate in a conversation by recur-sively inferring the reasoning of each other in aBayesian manner.
The proposed framework suc-cessfully explains existing psycholinguistic theo-ries and predict experimental results at various lin-guistic levels, such as the perception of scalar im-plicatures (e.g.
?some?
meaning ?not all?
in prag-matic usage) and the production of referring ex-pressions (Lassiter and Goodman, 2013; Bergenet al, 2014; Kao et al, 2014; Potts et al, 2015;Lassiter and Goodman, 2015).
Recent efforts alsoacquire and evaluate the models using corpus data(Orita et al, 2015; Monroe and Potts, 2015).Production and interpretation of discourse re-lations is also a kind of cooperative communica-tion between speakers and listeners (or authors andreaders).
We hypothesize that the game-theoreticaccount of Bayesian pragmatics also applies tohuman comprehension of the meaning of a DC,which can be ambiguous or even dropped.3 MethodThis section explains how we model the interpre-tation of discourse relations by Bayesian pragmat-ics.
The model is based on the formal frameworkknown as Rational Speech Acts model (Frank andGoodman, 2012; Lassiter and Goodman, 2015).Section 3.1 explains the key elements of the RSAmodel, and Section 3.2 illustrates how it is adaptedfor discourse interpretation.3.1 The Rational Speech Acts modelThe Rational Speech Acts (RSA) model describesthe speaker and listener as rational agents whocooperate towards efficient communication.
It iscomposed of a speaker model and a listener model.In the speaker model, the utility function U de-fines the effectiveness for the speaker to use utter-ance d to express the meaning s in context C.U(d; s, C) = lnPL(s|d,C)?
cost(u) (1)PL(s|d,C) is the probability that the listenercan interpret speaker?s intended meaning s. Thespeaker selects an utterance which, s/he thinks,is informative to the listener.
The utility of d isthus defined by its informativeness towards the in-tended interpretation, which is quantified by nega-tive surprisal (lnPL(s|d,C)), according to Infor-mation Theory (Shannon, 1948).
The utility ismodified by production cost (cost(d)), which isrelated to articulation and retrieval difficulties, etc.PS(d|s, C) is the probability for the speaker touse utterance d for meaning s. It is proportional tothe soft-max of the utility of d.PS(d|s, C) ?
exp(?
?
U(d; s, C)) (2)where ?, the decision noise parameter, is set to 1.On the other hand, the probability for the lis-tener to infer meaning s from utterance d is de-fined by Bayes?
rule.PL(s|d,C) ?
PS(d|s, C)PL(s) (3)The listener infers the speaker?s intended mean-ing by considering how likely, s/he thinks, thespeaker uses that utterance (PS(d|s, C)).
The in-ference is also related to the salience of the mean-ing (PL(s)), a private preference of the listener.To summarize, the speaker and listener emulatethe language processing of each other.
However,instead of unlimitted iterations (i.e.
the speakerthinks the listener thinks the speaker thinks..), theinference is grounded on literal interpretation ofthe utterance.
Figure 1 illustrates the direction ofpragmatic inference between the speaker and lis-tener in their minds.Figure 1: Pragmatic listeners/speakers reason for 1or more levels, but not the literal listener/speaker.Our experiment compares the predictions of theliteral listener (L0), the pragmatic listener who532reasons for one level (L1), and the pragmatic lis-tener who reasons for two levels (L2).
Previ-ous works demonstrate that one level of reason-ing is robust in modeling human?s interpretation ofscalar implicatures (Lassiter and Goodman, 2013;Goodman and Stuhlm?uller, 2013).3.2 Applying the RSA model on discourserelation interpretationWe use the listener model of RSA to model howlisteners interpret the sense a DC.
Given the DCd and context C in a text, the listener?s inter-preted relation sense siis the sense that maximizesPL(s|d,C).
siis specifically defined assi= arg maxs?SPL(s|d,C) (4)where S is the set of defined relation senses.The literal listener, L0, interprets a DC directlyby its most likely sense in the context.
The proba-bility is estimated by counting the co-occurrencesin corpus data, the Penn Discourse Treebank, inwhich explicit and implicit DCs are labelled withdiscourse relation senses.PL0(s|d,C) =count(s, d, C)count(d,C)(5)More details about the annotation of PDTB will beexplained in Section 4.1.As shown in Figure 1, the pragmatic speaker S1estimates the utility of a DC by emulating the com-prehension of the literal listener L0(Eq.
1, 2).
Theprobability for the pragmatic speaker Snto use DCd to express meaning s is estimated as:PSn(d|s, C)=exp(lnPLn?1(s|d,C)?
cost(d))?d?
?Dexp(lnPLn?1(s|d?, C)?
cost(d?
))(6)where n ?
1.
D is the set of annotated DCs, in-cluding ?null?, which stands for an implicit DC.The cost function in Equation 6, cost(d), mea-sures the production effort of the DC.
As DCs aremostly short words, we simply define the cost ofproducing any explicit DC by a constant positivevalue, which is tuned manually in the experiments.On the other hand, the production cost for an im-plicit DC is 0, since no word is produced .In turn, the pragmatic listener L1emulates theDC production of the pragmatic speaker S1(Eq.3).
The probability for the pragmatic listener Lnto assign meaning s to DC d is estimated as:PLn(s|d,C) =PSn(d|s, C)PL(s)?s?
?SPSn(d|s?, C)PL(s?
)(7)where n ?
1 and S is the set of defined sense.
Thesalience of a relation sense in Equation 7, PL(s), isdefined by the frequency of the sense in the corpus.PL(s) =count(s)?s??Scount(s?
)(8)Lastly, we propose to define the context vari-able C by the the immediately previous discourserelation to resemble incremental processing.
Wehypothesize that certain patterns of relation tran-sitions are more expected and predictable.
Dis-course context in terms of relation sense, relationform (explicit DC or not), and the sense-form pairare compared in the experiments.4 ExperimentThis section describes experiments that evaluatethe model against discourse-annotated corpus.
Weseek to answer the following questions: (1) Canthe proposed model explain the sense interpreta-tion (annotation) of the DCs in the corpus?
(2)Is the DC interpretation refined by the context interms of previous discourse structure?
(3) Doesthe proposed model help automatic discourse pars-ing?
We first briefly introduce the corpus resourcewe use, the Penn Discourse Treebank.4.1 Penn Discourse TreebankThe Penn Discourse Treebank (PDTB) (Prasadet al, 2008) is the largest available discourse-annotated resource in English.
The raw text arecollected from news articles of the Wall StreetJournals.
On the PDTB, all explicit DCs are an-notated with discourse senses, while implicit dis-course senses are annotated between two adja-cent sentences.
Other forms of discourse relations,such as ?entity relations?, are also labeled.
In total,there are 5 form labels and 42 distinct sense labels,some of which only occur very sparsely.We thus use a simplified version of the annota-tion, which has 2 form labels (Explicit and Non-explicit DC) and 15 sense labels (first column ofTable 3), following the mapping convention ofthe CONLL shallow discourse parsing shared task(Xue et al, 2015).
Sections 2-22 are used as the533training set and the rest of the corpus, Sections 0,1, 23 and 24, are combined as the test set.
Sizes ofthe data sets are summarized in Table 1.Train Test TotalExplicit 15,402 3,057 18,459Non-Exp 18,569 3,318 21,887Total 33,971 6,375 40,346Table 1: Sample count per data set4.2 Does RSA explain DC interpretation?The RSA model argues that a rational listener doesnot just stick to the literal meaning of an utter-ance.
S/he should reason about how likely thespeaker will use that utterance, in the current con-text, based on the informativeness and productioneffort of the utterance.
If the RSA model explainsDC interpretation as well, discourse sense predic-tions made by the pragmatic listeners should out-perform predictions by the literal listener.In this experiment, we compare the DC inter-pretation by the literal listener L0, and pragmaticlisteners L1and L2.
Given a DC d and the dis-course context C for each test instance, the rela-tion sense is deduced by maximizing the proba-bility estimate PL(s|d,C).
PL0(s|d,C) is simplybased on co-occurrences in the training data (Eq.5).
PL1(s|d,C) and PL2(s|d,C) are calculated byEq.
6 and 7, in which the salience of each sense isalso extracted from the training data (Eq.
8).context C Explicit Non-ExplicitL0constant (BL) .8767 .2616prev.
form .8754 .2616prev.
sense .8727 .2507form-sense .8684 .2692L1constant .8853* .2616prev.
form .8830 .2616prev.
sense .8671 .2698*form-sense .8621 .2671L2constant .8853* .2616prev.
form .8830 .2616prev.
sense .8671 .2616form-sense .8621 .2616Table 2: Accuracy of prediction by L0, L1andL2.
Improvements above the baseline are bolded.
* means significant at p < 0.02 by McNemar Test.Table 2 shows the accuracy of discourse senseprediction by listeners L0, L1and L2, when pro-vided with various discourse contexts.
Predictionsby L1, when they are differ from the predictionsby L0under ?constant?
context, are more accuratethan expected by chance.
This provides supportthat the RSA framework models DC interpreta-tion.
Overall, predictions of non-implicit senseshardly differ among different models, since an im-plicit DC is much less informative than an explicitDC.
Moreover, previous relation senses or formsdo not improve the accuracy, suggesting that amore generalized formulation of contextual infor-mation is required to refine discourse understand-ing.
It is also observed that predictions by L2aremostly the same as L1.
This implies that the lis-tener is unlikely to emulate speaker?s productioniteratively at deeper levels.4.3 Insights on automatic discourse parsingNext, we investigate if the proposed method helpsautomatic discourse sense classification.
A fulldiscourse parser typically consists of a pipeline ofclassifiers: explicit and implicit DCs are first clas-sified and then processed separately by 2 classi-fiers (Xue et al, 2015).
On the contrary, the prag-matic listener of the RSA model considers if thespeaker would prefer a particular DC, explicit orimplicit, when expressing the intended sense.In this experiment, we integrate the output ofan automatic discourse parser with the probabil-ity prediction by the pragmatic listener L1.
Weemploy the winning parser of the CONLL sharedtask (Wang and Lan, 2015).
The parser is alsotrained on Sections 2-22 of PDTB, and thus doesnot overlap with our test set.
The sense classi-fication of the parser is based on a pool of lex-icosyntactic features drawn from gold standardarguments, DCs and automatic parsed trees pro-duced by CoreNLP (Manning et al, 2014).For each test sample, the parser outputs a prob-ability estimate for each sense.
We use these esti-mates to replace the salience measure (PL(s)) (inEq.
8) and deduce P?L1(s|d,C), where C is theprevious relation form.P?L1(s|d,C) =PS1(d|s, C)Pparser(s)?s?
?SPS1(d|s?, C)Pparser(s?
)(9)Table 3 compares the performance of the origi-nal parser output and the prediction based on P?L1.1This does not match with Table 1 as samples labeled with2 senses are double counted.
Multi-sense training samplesare splitted into multiple samples, each labelled with one ofthe senses.
In testing, a prediction is considered correct if itmatches with one of the multiple senses.534discourse parser P?L1testrelation sense tags output output countsConjunction .7022 .7079 1479Contrast .7382 .7152 1152Entity .5174 .5249 862Reason .4844 .5105 661Restatement .2773 .2871 567Result .4019 .4150 405Instantiation .4346 .4357 282Synchrony .6553 .7007 264Condition .9087 .9302 238Succession .7022 .7210 204Precedence .7523 .7762 200Concession .3048 .4382 146Chosen alternative .5000 .5200 36Alternative .8421 .8929 28Exception 1.00 1.00 1Accuracy / Total .5833 .5916 65251Table 3: F1 scores of original parser output vsparser output modified with P?L1.
Higher scoresare bolded.
The improvement in accuracy is sig-nificant at p < 0.05 by McNemar Test.Significant improvement in classification accuracyis achieved and the F1 scores for most senses areimproved.
This confirms the applicational poten-tial of our model on automatic discourse parsing.5 ConclusionWe propose a new framework to model the inter-pretation of discourse relations based on Bayesianpragmatics.
Experimental results support the ap-plicability of the model on human DC comprehen-sion and automatic discourse parsing.
As futurework, we plan to deduce a more general abstrac-tion of the context governing DC interpretation.
Alarger picture is to design a full, incremental dis-course parsing algorithm that is motivated by thepsycholinguistic reality of human discourse pro-cessing.ReferencesAnton Benz, Gerhard J?ager, Robert Van Rooij, andRobert Van Rooij.
2016.
Game theory and prag-matics.
Springer.Leon Bergen, Roger Levy, and Noah D. Goodman.2014.
Pragmatic reasoning through semantic infer-ence.Herbert H Clark.
1996.
Using language.
Cambridgeuniversity press.Kenji Doya.
2007.
Bayesian brain: Probabilistic ap-proaches to neural coding.
MIT press.Michael C. Frank and Noah D. Goodman.
2012.
Pre-dicting pragmatic reasoning in lanugage games.
Sci-ence, 336(6084):998.Bruno Galantucci, Carol A Fowler, and Michael TTurvey.
2006.
The motor theory of speech per-ception reviewed.
Psychonomic bulletin & review,13(3):361?377.Noah D Goodman and Daniel Lassiter.
2014.
Prob-abilistic semantics and pragmatics: Uncertainty inlanguage and thought.
Handbook of ContemporarySemantic Theory.
Wiley-Blackwell.Noah D Goodman and Andreas Stuhlm?uller.
2013.Knowledge and implicature: modeling language un-derstanding as social cognition.
Topics in cognitivescience, 5(1):173?184.HP Grice.
1975.
Logic and conversation in p. coleand j. morgan (eds.)
syntax and semantics volume 3:Speech acts.Gerhard J?ager.
2012.
Game theory in semanticsand pragmatics.
In Claudia Maienborn, Klaus vonHeusinger, and Paul Portner, editors, Semantics:An International Handbook of Natural LanguageMeaning, volume 3, pages 2487?2425.
Mouton deGruyter.Justine T Kao, Jean Y Wu, Leon Bergen, and Noah DGoodman.
2014.
Nonliteral understanding of num-ber words.
Proceedings of the National Academy ofSciences, 111(33):12002?12007.James M Kilner, Karl J Friston, and Chris D Frith.2007.
Predictive coding: an account of the mir-ror neuron system.
Cognitive processing, 8(3):159?166.Daniel Lassiter and Noah D Goodman.
2013.
Context,scale structure, and statistics in the interpretation ofpositive-form adjectives.
In Semantics and Linguis-tic Theory, volume 23, pages 587?610.Daniel Lassiter and Noah D Goodman.
2015.
Adjecti-val vagueness in a bayesian model of interpretation.Synthese, pages 1?36.Diana Lewis.
2006.
Discourse markers in english: adiscourse-pragmatic view.
Approaches to discourseparticles, pages 43?59.Christopher Manning, Mihai Surdeanu, John Bauer,Jenny Finkey, Steven J. Bethard, and David Mc-Closky.
2014.
The standord corenlp natural lan-guage processing toolkit.
Proceedings of the AnnualMeeting of the Association for Computational Lin-guistics: System Demonstrations, pages 55?60.535Will Monroe and Christopher Potts.
2015.
Learningin the rational speech acts model.
arXiv preprintarXiv:1510.06807.Mike Oaksford and Nick Chater.
2009.
Prcis ofbayesian rationality: The probabilistic approach tohuman reasoning.
Behavioral and Brain Sciences,32:69?84, 2.Naho Orita, Eliana Vornov, Naomi H. Feldman, andHal Daum?e III.
2015.
Why discourse affects speak-ers?
choice of refering expressions.
Proceedings ofthe Annual Meeting of the Association for Computa-tional Linguistics.Martin J Pickering and Simon Garrod.
2007.
Dopeople use language production to make predictionsduring comprehension?
Trends in cognitive sci-ences, 11(3):105?110.Martin J Pickering and Simon Garrod.
2013.An integrated theory of language production andcomprehension.
Behavioral and Brain Sciences,36(04):329?347.Christopher Potts, Daniel Lassiter, Roger Levy, andMichael C. Frank.
2015.
Embedded implicaturesas pragmatic inferences under compositional lexicaluncertainty.
Manuscript.Rashmi Prasad, Nikhit Dinesh, Alan Lee, Eleni Milt-sakaki, Livio Robaldo, Aravind Joshi, and BonnieWebber.
2008.
The penn discourse treebank 2.0.Proceedings of the Language Resource and Evalua-tion Conference.C.E.
Shannon.
1948.
A mathematical theory of com-munication.
The Bell System Technical Journal,27(379-423; 623-656).Teun A Van Dijk.
1980.
The semantics and pragmat-ics of functional coherence in discourse.
Speech acttheory: Ten years later, pages 49?66.Jianxiang Wang and Man Lan.
2015.
A refined end-to-end discourse parser.
CoNLL 2015, page 17.Nianwen Xue, Hwee Tou Ng, Sameer Pradhan, RashmiPrasadO Christopher Bryant, and Attapol T Ruther-ford.
2015.
The conll-2015 shared task on shallowdiscourse parsing.
CoNLL 2015, page 1.Henk Zeevat.
2011.
Bayesian interpretation and opti-mality theory.
Bidirectional Optimality Theory.
Pal-grave Macmillan, Amsterdam, pages 191?220.Henk Zeevat.
2015.
Perspectives on bayesian natu-ral language semantics and pragmatics.
In BayesianNatural Language Semantics and Pragmatics, pages1?24.
Springer.536
