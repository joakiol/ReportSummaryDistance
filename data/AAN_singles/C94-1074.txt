A "not-so-shallow" parser for collocational analysisBasili R.(*), M.T.
Pazienza (*), P. Velardi (?
)(*) Dipartimento Ingegneria Elettronica,Universit,~ di Roma,Tor Vergata\[rbas, pazienza}@tovvxl ,  ccd.utow:m, it:(?)
Istituto di Informatica, Universitk di Anconavela@anvax2, cinec..~.
J_tAbstract.
Collocational analysis is the basisof many studies on lexical acquisit ion.Collocations are extracted from corpora usingmore or less shallow processing techniques, thatspan from purely statistical methods to partialparsers.
Our point is that, despite one of tileobjectives of collocational analysis is to acquirehigh-coverage l xical data at low human cost,this is often not the case.
Human work is in factrequired for the initial training of moststatistically based methods.
A more seriousproblem is that shallow processing techniquesproduce a noise that is not acceptable for a fullyautomated system.We propose in this paper a not-so-shallowparsing strategy that reliably detects binary andternary relations among words.
We show thatadding more syntactic knowledge to the.
recipesignificantly improves the recall and precisionof tile detected collocations, regardless of anysubsequent statistical computation, while stillnleeting the cornputational requi,'ements ofcorpus parsers.1.
Week methods for the analysis of collocationsIn the past few years there has been aflourishing of interest in the study of wordcollocations.
A common method to extractcollocations is using windowing techniques forthe extraction of word associations.
In (Zernik1990; Calzolari and Bindi 1990; Smadja 1989;Church and Hanks 1990) associations aredetected in a ?5 window.
A wider window (?
tO0words) is used in (Gale et al 1992).
Windowingtechniques are also used in (Jelinek et al 1990),where it is proposed a trigram model toautomatical ly derive, and refine, context-freerules of the grammar (Fujisaki et al 1991).Windowing techniques weekly model tilelocality of language as well as other lexicalinformation.
The reliabil ity of the acquiredinformation depends upon tile window size.
Asmall window fails to detect many importantword relations, while enlarging tile windowaffects the tractability of tile statistical model(especially for markovian n-gram models).Finally, window-based collocations providelimited information when dealing with avariety of lexical phenomena.
For example, thesimple observation of word cooccurrences is not asuitable marker of lexical subcategorization.Another popular al;proach is usinl,r a partialparser, augmented with statistical parameters.Tile reciprocal contribution of syntax andstatistics has been outlined in (Zemik 119911) tohave an important role for automatic lexicaIacquisition.
The syntactic relations are usuallyderived by preq)rocessing the target corpus witha part-of-speech tagger or with a simplif iedparser.
Syntactic markers are appl ied toelementary links among words or to morestructurecl contexts.
The pa,'tial character of thedifferent parsers described in literature makes itpossible to process large corpora at a"reasonable" computational effort.Most syntax-based statistical approaches usedeterministic parsing, derived from Marcus'work on PARSIF'AI.
parser (Marcus, 1980).I'ARS1FAL is a deterministic parser with look-ahead cat)abil it ies, that enables part ia lanalyses.
One of the PARSIFAL emanations, theFidditch parser by I lindle, is used in (Flindle1990) to detect subject-w~rb-object (SVO) triples.SVO triples are allowed to be incomplete, i.e.the subject or the object can be missing.
Noisydata (i.e.
words that are neither syntacticallynor semantically ,elated) are reduced by the useof statistical measures, sucl-t as the Itllltllalinformation (Church et al 1991), as defined ininformation tlmory.The Fidditch parser requires a lexiconincluding informatkm about base word fornls atldsyntactic constraints (e.g,.
tile complementstructure of verbs).
Non-trivial prel iminarywork is tllus necessary in tuning the lexicon forthe different domains and sublanguages.
Asecond problem with the Fidditch parser is poorperformances: tilt_' recall and precis ion atdetecting word collocations are declared to be aslow as 50%, I-iowever it is unclear if this valueapplies only to SVO triples, and how it has beenderived.
The recall is low because tile Fidditchparser, as other partial parsers (Sekine et al1992; Resnik and Hearst, i993), only detect linksbetween adjacent or near-adjacent words.Thougll a 50"/,, precision and recall might be447reasonable for human assisted tasks, like inlexicography, supervised translation, etc., it isnot "fair enough" if collocational analysis mustserve a fully automated system.
In fact, corpuslinguistics became a popular research fieldbecause of the claim that shallow techniquescould overcome the lexical coverage bottleneck oftraditional NLP techniques.
Among theapplications of collocational analysis for lexicalacquisition are: the derivation of syntacticdisambiguation cues (Basili et al 1991, 1993a;Hindle and Rooths 1991,1993; Sekine 1992)(Bogges et al 1992), sense preference (Yarowski1992), acquisition of selectional restrictions(Basili et al 1992b, 1993b; Utsuro et al 1993),lexical preference in generation (Smadjia 1991),word clustering (Pereira 1993; Hindle 1990;Basili et al 1993c), etc.In the majority of these papers, even thoughthe (precedent or subsequent) statisticalprocessing reduces the number of accidentalassociations, very large corpora (10,000,000words) are necessary to obtain reliable data on a"large enough" number of words.
In addition,most papers produce a performance evaluation oftheir methods but do not provide a measure ofthe coverage, i.e.
the percentage of cases forwhich their method actually provides a (rightor wrong) solution.
It is quite common that resultsare discussed only for 10-20 cases.In our previous papers, we used semantictagging to further reduce the noise and gainevidence of recurrent phenomena even withsmall corpora.
However, no accurate or shallowmethod can resume valid information that hasbeen lost in previous steps (i.e.
in extractingcollocations).
We believe that a higherprecision and recall of the input collocationaldata is desirable to ensure a good coverage to thewhatever lexical learning algorithm.In this paper we describe a not-so-shallow,multi-step, parsing strategy that allows it todetect long distance syntactic relations whilekeeping the temporal complexity compatiblewith the computational requirements of large-scale parsers.
We demonstrate that a bit moresyntax can be added to the recipe, with asignificant improvement over existing partialparsers.
We do not discuss of any subsequentprocessing (statistically or /and knowledgebased) that may be applied to further improvethe quality of collocational data, since this isoutside the scope of this presentation.
Theinterested reader may refer to our previous workson the matter.2.
A "not-so-shallow" parsing techniqueOur syntactic analyzer (hereafter SSA)extracts partial syntactic structures from corpora.The analyzer, based on discontinuous grammar(Dahl,1989), is able to detect binary and ternarysyntactic relations among words, that we callelementary slmtactic lil~k,~ (esl), The frameworkof discontinuous grammars has severaladvantages: it allows a simple notation, andexhibits portability among different logicprogramming styles.
The presence of skip rulesmakes it possible to detect long distancedependencies between co-occurring words.
This isparticularly important in many texts, for thepresence of long coordinate constructions, nestedclauses, lists, parenthesised clauses.The partial parsing strategy describedhereafter equires in input few more than amorphologic lexicon (section 2.1).
Postmorphologic processing, as described in section2.2, is not strictly required, though obviously itincreases the reliability of the detected wordrelations.
The lexicon used is purelymorphologic, unlike for the Fidditch parser,neither it requires training, like in n-gram basedmodels.
This means that the shallow analyzer isportable by minimum changes over differentdomains.
This is not the case with thedeterministic partial parsing used in similarworks.
Furthermore the grammar ules are easyto tune to different linguistic subdomains.
Theanalyzer enables the detection of different ypesof syntactic links among words: noun-verb, verb-noun, noun-prepos i t ion-noun,  etc.
Thisinformation is richer than just SVO triples, inthat phrase structures are partitioned in moregranular units.The parsing method has been implementedfor different corpora, which exhibit verydifferent linguistic styles: a corpus of commercialactivities (CD), in telegraphic style, a legaldomain (LD) on taxation norms and lows, andremote sensing (RSD) abstracts.
The latter is inEnglish, while the former two are in Italian.The English application is rather less developed(a smaller morphologic lexicon, no post-morphology, etc.
), however it is useful here todemonstrate that the approach is languageindependent.
In this paper we use manyexamples from the RSD.2.1 MorphologyThe morphologic analyzer (Marziali, 1992)derives from the work on a generative approachto the Italian morphology (Russo, 1987), firstused in DANTE, a NLP system for analysis ofshort narrative texts in the financial domain(Antonacci et al 1989).
Tile analyzer includesover 7000 elementary lemmata (stems withoutaffixes, e.g.
flex is the elementary lemma for de-448flex, in-flex, re-fiex) anti has been experimentedsince now on economic, financial, commercial ndlegal domains.
Elementary lemmata cover muchmore than 70(}0 words, since many words have anaffix.An entry in the lexicon is as follows:lexicon(len~na, stem, ending_class,syntactic feature)where l emma iS the elementary lemma (e.g.ancora for ancor-aggio (anchor-age)), s tem is thelemma without ending (ancor), end ing_c lassiS one over about 60 types of inflections.
Forexample, ancora belongs to the class ec cosa,since it inflects like the word cosa (thinq,).The I ta l ian morphologic  lexicon andgrammars are fully general.
This means that theanalyzer has a tendency to overgenerate.
Forexample, the word agente (agent, in the sense ofdealer), is interpreted as a i~.oun and as thepresent participle of the verb agire (to act),though this type of inflected form is never foundin both Italian domains.
This problem is lessevident in English, that is less inflected.Overgeneration is a common problem withgrammar based approaches to morphology, asopposed to part of speech (pos) taggers.
On theother side, pos taggers need manual work forcorpus training every since a new domain is to beanalyzed.To quantitatively evaluate the phenomenonof overgeneration, we conskfered a test set of 25sentences in the LD, including about 800 words.Of these 800, there were 546 different nouns,adjectives anti verbs (i.e.
potentially ambiguouswords) .
The ana lyzer  p rov ided  631interpretations of the 546 words.
There were 76ambiguous words.
The overall  estimatedambigu i ty  is 76/546:0,139,  whi le  theovergeneration ratio is better evaluated by:O = \[631 - (546-76)\]/76=161/76:2,112.2.
Post morphological processingThe purpose of this module is to analysecompound expressions and numbers, such ascompound verbs, dates, numeric expressions, andsuper!atives.
Ad-hoc context free grammar havebeen defined.
Post morphological processingincludes also simple (but general ly valid)heuristic rules to reduce certain types ofambiguity.
"Ihere are two group of such rules:(i) Rules to disambiguate ambiguous noun-adjective (N /Agg)  interpretations (e.g.acid)(ii) Rules to disambiguate ambiguous verb-noun(V/N) interpretations (e.g.
study)One example of heuristics for N/Agg is:If N/Agg is neither preceded nor followedby a noun, or N/Agg, before a verb is reached,Then it is a noun.Ex: .
.
.
and sulphuric ~ was detectedThough examples are in English, postmorphology has not been developed for theEnglish language at the time we are w,'iting.After post-morphologic analysis, the 546nouns, verbs anti adjectives produced only 562interpretations.
The new overgeneration ratio isthenO':(562-(546-76))/76=92/76=1,2The est imated efficacy of the post-rnorphology, is 161/92=1,75, about 50% .
'eductionof the initial ambiguity.2.3.
The parserThe SSA syntactic analysis is a rewritingprocedure of a single sentence into a set of~!_1 ~meme~!-y_~y~ i?\]jg_jin!~ (esl).
The SSA isbased on a discontinuous grammar, describedmore formally in (Basili et al 1992a).
In tiffssection we provide a qualitative clescription ofthe rules by which esl's are generated.Examples of esl's generated by the parserare: N_V (the subject-verb relation), V N (thedirect object_verb relation), N P N (nounpreposition noun), V P N (verb preposit ionnoun), N_Adj (adjective noun), N N (conq)ound)etc.
Overall, we identify over 20 different esl's.There is a discontinuous grammar ule for eachesl.
A description of a rule used to derive N P Nlinks is in Figure 1.
This description applies bystraightforward modifications to any other esltype (though some esl rules include a concordancetest).As remfirked at the beginning of this section,skip rules are the key to extract long distancesyntactic relations and to approximate thebehaviour of a full parser.
The first predicateLOOK RIGItT of Figure 1 skips over the string Xuntil it finds a preposition (prep(w2)).
Thesecond LOOK_RIG\[ IT skips over Y until it findsa noun (noun(w3)).Given an initial string NL_segment ,BACKTRACK force the system to analyse allthe possible solut ions of the predicateLOOKRIGHT (i.e.
one-step rigth skips) toderive all the N P N groups, headed by thefirst norm (i.e.
wl).
For example, given the string:low concentrations of acetone and ethylalchool in acqueous olutionsthe following N_PN are generated:concentration of acetone, concentration ofalchool, concentration in solution, acetone in449solution, alchooI in solution,all of which are syntactically correct.SSA rule( NL segment, N_P_N)BEGINP, EPIZd~TIFNL_segment is EMPTY "IIIENF2KrI';ELSEBEGINNL segment=(wl Rest.
)IF (noun(wl) THFMBEGINLOOK_RIGIIT(X, w2, Rest ,  New_Rest); %Rest=(X w2 NewRest)IF (TEST_ON(X) AND prep(w2)  "IIIENBEG I NLOOK RIGIIT( Y, w2, New_Rest, _); %New_Rest--- (Y w3 _)IF ( TEST ON(Y) AND noun(w3)  'llIENASSERT(esl(N_P_N, wl,  w2, w3));BACKTRACK;END;BACKTRACK;ENDPOPwl FROM Nb_segment;ENDEND.Figure 1: A description of an N P N ruleAn uncontrolled application of skip ruleswould however produce unacceptable noise.
TheTEST_ON0 are ad hoc heuristic rules thatavoid uncontro l led skips.
For example,TEST2.ON(X) in Figure 1 verifies that the stringX does notinclude a verb.
Hence, in the sentence:... the atmospheric ode contparedfavourably with results ...the N P_N(code,with,results) i  ~ generated.In general, there is one-two different heuristicrule for each esl rule.
Heuristic rules aredesigned to take efficient decisions by exploitingpurely syntactic onstraints.
Such constraints aresimple and require a minimum computationaleffort (essentialy, unification among simplestructures).
In some case, a lower recall istolerated to avoid overgeneration.
For example,the second TEST ON(Y) rule of Figure 1 verifiesthat no more than two prepositions are skippedin the string Y.
This rule stems from theobservation that words located more than threepreposit ions apart,  are rarely semanticallyrelated, though a full syntactic parser wouldeventually detect a relation.
Hence, in the NLsegment:1% accuracy on the night side of the Earthwith stars down to visual magnitude treethe triple (accuracy, to, tree) is la_(gt generated,though syntactically correct.The derivation of esl's is enabled for nonadjacent word by virtue of skip rules.
However,interesting information can be lost in presence ofmore complex phenomena s nested relativeclauses or coordination of phrase structures.
Tocope with these phenomena, a post syntacticprocessor has been deve loped to extract linksstemming from coordination among previouslydetected links.
This processing significantlyincreases the set of collected esl, and the qualityof the der ived lexical information.
Thecontribution of this post syntactic processingdevice depends heavily on the structure ofincoming sentences.
In this phase, s impleunification .mechanisms are used, rather thanheuristics.3.
Performance evaluationRecall and PrecisionM,'my algorithms evaluate their recall andprecision against a human reference performer.This pose many problems, like finding a "fair"test material, using a large number of judges torender the evaluation less subjective, and finallyinterpreting the results.
One example of the450latter problem is the following: in (Smadja 1993)the nature of a syntactic link between twoassociated words is detected a posteriori.
Theperformance of the system, called XTRACT, weevaluated by letting human judges compare theirchoice against hat of the system.
The reportedperformances are about 80% precision, 90%recall.
One such evaluation experiment is, in ourview, questionable, since both the human judgesand XTRACT make a decision outside the contextof a sentence.
The interpretation of the resultsthen does not take into account how muchXTRACT succeeds in identifying syntacticrelations as they actually occurred in the testsuite.Another problem is that, a human judge ntayconsider not correct a syntactic association on theground of semantic knowledge 1.
Instead, theperformance of a syntactic parser should beevaluated only on a syntactic ground.We define the linguistic performance of SSAas its ability to approximate the generation ofthe full set of e lementary syntactic linksderivable by a complete grammar of the domain.Given the set I2 of all syntactically valid esland the set m of esl derived applying SSA, theprecision of the system can be defined as theratiocardinality(f2 m co) / cardinality(Q),while its recall can be expressed by:cardinality(co n ~2) / cardinality(~}),Global evaluations of the precision and recallare estimated by the mean values over thewhole corpora.We designed for testing purposes a fullattribute grammar of the Italian legal language,and we selected 150 sentences for which the fullgrammar was proved correct.
For each parsedsentence, a program automatically computes theesrs globally identified (without repetitions) bythe parse trees of each sentence, and comparesthem with those generated by SSA for the samesentence.
The following Table gives a measure of~erformance:Esl_typeN P NV P NRECALL69.1 ~Yo"N_V55 %67.5 %PRECISION81.8 %56 %V_N 86.6 %59 % 60.5 %To fully appreciate these results, we mustconsider, first, that the evaluation is on a purelysyntactic ground (many collocations detected by1 It is tmclear whether Smadja considered Otis problemin his evaluation experimentthe full grammar and not detected by the SSAare in fact semantically wrong), second, that thedomain is particularly complex.
There is anaverage of 23 trees per sentences in the test set.In particvlar, the low performances of N_Vgroups (i.e.
the subject relation) is influenced bythe very frequent (almost 80'}'0) presence of nestedrelatives (ex: The income that was perceivedduring 1988i..)is included..) and inversions (ex: siconsiderano esenti da tasse i  redditi..=*it isconsidered tax-free the income..).
No partialparser could cope with these entangledstructttres.One interesting aspect is that these resultsseem very stable for the domain.
In fact,incrementally adding new groups of sentences,the perfoemance values do not changesignificantly.l'or completeness, we also evaluated theEnglish grammar.
In this case, the evaluationwas carried entirely by hand, since no fullg rammar  of Engl ish was avai lab le  toautomatically derive the complete set of esl's.F'irst, a test set of 10 remote sensing abstracts(about 1400 words, 67 sentences) was selected atrandom.
The results are the following:Es l _ type  RECALLN _ N 78 %V_N.
81%N_p_N 94 %V pN 87 %N_ V 75 %PRECISION67 %58 %54 '~/o42 %57 %Here the recall is rather high, sincesentences have a much simple structure.However, there are many valid long distance ppattachments that for example most existingpartial parses would not detect.
The precision islower because the English parser does not havepost morphokGy as yet.
One major source of errorat detecting N V pairs are, as expected,comIxmnds.The most important factors that influencethe time complexity are: the number N ofsentences (words) of the corpus and the number kof different discontinuous rules (about 20, as wesaid).The global rewrit ing procedure of SSAdepends on the length n of the incoming textsegment according to the following expression:*ti=lwhere e(x) is the cost of the application of agrammar ule, as for in Figure 1, to a segment of4.51length x. e(x) is easily seen to depend on:1.
Predicates that test the syntactic ategory of aword (e.g.
noun(w1)), whose cost is equal tothat of a simple unification procedure i.e.
"t;2.
TEST ON predicates, whose cost is not greaterthan "~*n, where n is the substring length.We can thus say that the expression e(x) ofthe complexity of SSA syntactic rules verifiesthe following inequality:e(n) <- 3r+ 2'rn = O(n)Hence, the global cost is:N n~ ke(n - i) <- ~_~3"ck + 2"rk(n - i )  =i=1 i=1= 2"rkn(n + 1) +3"~kn = O(n 2)A significant information is that the processingtime needed on a Sun Sparc station by the fullgrammar to parse the test set of 150 sentences i 6hours, while SSA takes only 10 minutes.Portability and scalabilityThese two aspects are obviously related.
Thequestion is: How much, in terms of time andresources, is needed to switch to a differentdomain, or to update a given domain?
Since wedeveloped three entirely different applications,we can provide some reliable estimate of theseparameters.
The estimate of course is stronglydependent  upon the specific system weimplemented,  however we will frame ourevaluation in a way that broadly applies to anysystem that uses similar techniques.Morphology:Our experience when switching front thecommercial to the legal domain was that, whenrunning the analyzer over the new corpus, about30,000 words could not be analyzed.
This requiredthe insertion of about 1,500 new elementarylemmata.
Accounting for a new word requiresenter ing the stem without  affixes, theelementary lemma of the word and the endingclass (see section 2.1).
Entering a new word takesabout 5-10 minutes when the linguist is providedwith some onqine help, for example a list ofending classes, browsing and testing facilities,etc.
With these facilities, updating the lexiconis a relatively easy job, that does not require aspecialized linguist to be performed.Clear ly,  when implement ing  severalapplications, the global updating effort tends tozero.
This is not the case for statistically basedpart of speech taggers, that require always afixed effort to train on a new corpus.
On the longrun, it seems that grammar based approaches tomorphology have an advantage over pos taggers,in terms of portability.Our experience is that adding a new ruletakes about one-two man days.
First, one mustdetect he linguistic pattern that is not accountedfor in the grammar, and verify whether it can bereasonably accounted for, given the intrinsiclimitations of the parsing mechanism adopted.If the linguist decides that, indeed, adding anew rule is necessary and feasible, he /sheimplements the rule and test its effects.Grammar modifications are required to:* Select the esl types of interests;* Define the heuristic rules (TEST ON), asdiscussed in Section 2.3.One positive aspect of SSA is that itscomplexity is O(k) with respect o the number kof grammar ules.
Hence adding new rules doesnot affect the complexity class of the method.In summary,  portability is an essentialfeature of SSA.
While other parsers need a nontrivial effort to be tuned on clifferent linguisticdomains, we need only minimal adjustment toensure the required coverage of the morphologiclexicon.
However,  the act ivity of lexicalextension is needed with every approach.Portability is also guarantied by the modularityof the apl)roach.4.
Conclusions.Shallow methods for corpus analysis claimto have several desirable features, such aslimited manual work and high coverage.
Ourpoint is that this is not entirely true.
Fullystatistical methods require initial training overthe corpus to estimate parameters, and this is nottrivial.
Most of all, the effort is exactly thesame every since the domain changes.
Inaddition, a lot of noisy data are collected unlesssome shallow level of linguistic analysis isadded to increase performance.
But even then,reliable data are collected only for a fragment ofthe corpus.
And what about high coverage?
Ontl'te other side, we wouldn't  be here, hadtraditional NLP techniques had any chance tobecome truly scalable.This paper showed, if not else, that a bitmore syntax can be added to the recipe, whilestill meeting important requirements, uch ascomputational complexity and portabil ity.
Inmedia stat virtus: ql'ds could be the moral of thispaper, and in general of our research on lexicalacquisition.
Of course, we don't know whereexactly the perfect balance is, we just seek for abetter balance.452References.
(Antonacci 1989), F. Antonacci, M.T.
l'azienza, M.Russo, P. Velardi , (1989), A Logic based systemfor text analysis and lexical knowledge acquisitio,l, in Data and Knowledge Engineering, vol 4.
(Basili et al 1991), R. Basili, M. T. Pazienza, P. Velardi,(1991), Using word association for syntacticdisambiguation, in Trends in ArtificialIntelligence, E. Ardizzone et al, Eds., I.NAI n.549, Springer-Verlag.
(Basili et al 1992 a) R. Basili, M. T. Pazieuza, P. Velardi,(19921, A shallow Syntax to extract wordassociations from corpora", in Literary andLinguistic Computiug, vol.
2.
(Basili et al 1992 b) R. Basili, M. T. Pazienza, P. Velardi,(1992), Computational Lexicons: the neatexamples and the odd exemplars, Prec.
of 3rd.Conf.
on Applied NLP.
(Basili et al1993a), Basili, R., M.T.
Pazienza, P. Velardi,(19931.
Semi-automatic extraction of linguisticinformation for syntactic disambiguation, AppliedArtificial Intelligence, vol.
4, 1993.
(Basill et al1993b), Basili, R., M.T.
Pazienza, P. Velardi,(19931.
What can be learned from raw texts ?,Journal of Machine Translation, 8:147-173.
(Basili et a1.1993c), Basili, R., M.T.
Pazienza, P. Velardi,(1993).
llierarchical clustering of verbs, ACL-SIGLEX Workshop on Lexical Acquisition,Columbus Ohio, June.
(Bogges,1991), L. Bogges, R. Agarwal, R. Davis,I)isambiguation of prepositional phrases iuautomatically labelled technical text (1991).
Prec.of AAAI 1991(Church and llanks, 19901, K. Church and P. llauks, Wordassociation norm, mutnal information andlexicography, Computational Linguistics, vol.
16,n.1, 1990(Church et al 1991), Church, Gale, flanks and Ilindlc,Using statistics in lexicaI analysis, (19911.Lexical Acquisition, U. Zernik Ed., l.awrenceErlbaum Ass., Publ., 115-164.
(Calzolari and Bindi,1990) N.Calzolari and R. Bindi,Acquisition of lexical informatiou from Corpora,(19901, Prec.
of COLING 90.
(Dahl, 1989), Dahl,V., "Discontinous grammars", (1989).Computational Intelligence, n. 5, 161-179.
(Fujsaki et a1.,1991) Fujisaki T., F. Jelinek, J. Cooke, E.Black, T. Nishino, A probabilistic parsing methodfor sentence disambiguation, (19911.
Cu,'reuttrends in Parsing Technology, M. Tomita Ed.,Kluwer Ac.
Publ., 1991.
(Ilindle and Rooths,1991) D. llindle, M. l~,ooths,Structural Ambiguity and Lexical P, elatious (1991).Prec.
of ACL 1991(ltindle, 19901, D. llindle, Nouu Classification formpredicate-argument structure (199tl).
Prec.
of AC1.1990(Ilindle and Rooths,1991) D. Ilindle, M. Rooths,Structural Ambiguity and Lexical Relations (1991).Prec.
of ACL 1991(llindle and Rooths, 1993) 11. llindle and M. Rooths,Structural ambiguity and lexical relations (1993).
(2ompntational Linguistics, vol.
19, n. 1, 1993(Gale et al 1992), I!stimating the upper and lower boundson the performance of word-sense disambiguationprogrt, ms, (1992).
l:'roc, of ACL 1992(Jelinek et al, 1990) F. Jelinek, J.l).
l.al'ferty, F,.I.. Mecer,Basic methods of probabilistic context f,'eegrammars, (19901.
Research Report R( 216374 IBMYorkTown lleights NY 10598, 1990.
(Marcus, 1980), M. Max'cns, A Theory of Syntacticrecoguitiou for Natural I.anguage, MIT Press, 1980(Marziali,19921, Marziali, A., "Robust Methods fro.parsiug large-scale text archives, I)issertation,Facolth di lugegneria, Univerith "La Sapieuza"I>,oma, a.a. 1992 .
(Percira et at.
'1993) F.Pereira, N. Tishby, L. Lee, (19931.
"Distributional Clustering of English Words", inPrec.
of ACI, 93 Columbus, Ohio, June, 1993.
(Rnsso, 1987), M. Russo, "A generative grammar approachfor the morphologic and morphosyntactic analysisof the Italian langnage" (1987).
3rd.
Conf.
of theF.urol~ean Chapter of the ACI,, Copenhaghen, April1-3 1987.
(Sekiae et al 1992) Automatic learuiug for semanticcollocations, (19921.
Prec.
of 3rd.
ANLI', 1992(Smadja,1989), F. Smadja, "Lexical cooccurences: themissing link", (1989).
Literary and 1,iuguisticComputing, vol.4, n.3, 1989.
(Smadja,1991), F. Smadja, From N-Grams to collocations:au evaluation of XTRACT, (1991).
Prec.
of ACI,199l(Smadja,1990), F. Smadja, K. McKeou, Automaticallyextracting and rcsprescnting collocations forlangultge generation, (1990).
Prec.
of ACL 1990(Smadja, 1993), F. Smadja, Retrieving collocations fi'cmatext: XTRACT, (1993).
Computatioual Linguistics,w~l 19, u.l, 1993(l(esnik and llearst, 1993) P. Resnik, M. llearst, StructuralAmbiguity and Conceptual Relations, (1993).pt'oc, of the workshop on Very l,arge Corl?
)ra,Columbus, June 1993(Iltsuro et a1.,.1993), T. Utsnro, Y. Matsumoto, M. Nagao,verbal case frame acqnisition from bilingualcorlx)ra, (1993).
Prec.
of IJCAI 1993(Yarowski, 1992) Yarowsky 1)., "Word-SenseDisambiguation Using Statistical Models ofRoger's Categories Trained on Large Corpora",(1992).
Prec.
of COI,ING-92, Nantes, Aug.
23-28.
(Zernik,1990), tl.
Zernik, P. Jacobs, Tagging forl.earning: Collecting Thematic relations fromCorpus (1990).
Prec.
of COL1NG 1990(Zeruik,1991), U. Zernik, Ed.
"Lexical Acquisition:Fxploiting on-line resources to build a lexicon",(1991).
Lawrence Erlbatun Publ., 1991.453
