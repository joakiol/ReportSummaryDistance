Dialog Control in a Natural Language System 1Michael Gerlach Helmut HoracekUniversit~t Hamburg Fachbereich Informatik Projektgruppe WISBERJungiusstra6e 6 D-2000 Hamburg 36 F.R.G.ABSTRACTIn this paper a method for controllingthe dialog in a natural anguage (NL)system is presented.
It provides a deepmodeling of information processingbased on time dependent propositionalattitudes of the interacting agents.Knowledge about he state of the dialogis represented in a dedicated languageand changes of this state are describedby a compact set of rules.
An appropri-ate organization of rule application isintroduced including the initiation ofan adequate system reaction.
Finallythe application of the method in an NLconsultation system is outlined.INTRODUCTIONThe solution of complex problems fre-quently requires cooperation of multi-ple agents.
A great deal of interaction isneeded to identify suitable tasks whosecompletion contributes to attaining acommon goal and to organize thosetasks appropriately.
In particular, thisinvolves carrying out communicativesubtasks including the transfer ofknowledge, the adjustment of beliefs,expressing wants and pursuing theirsatisfaction, all of which is motivatedby the intentions of the interactingagents \[Werner 88\].
An ambitious dia-log system (be it an interface, a mani-pulation system, or a consultation sys-tem) which is intended to exhibit (someof) these capabilities hould thereforeconsider these intentions in processing1 The work described in this paper is partof the joint project WISBER, which is sup-ported by the German Federal Ministery forResearch and Technology under grant ITW-8502.
The partners in the project are: NixdorfComputer AG, SCS Orbit GmbH, SiemensAG, the University of Hamburg, and the Uni-versity of SaarbrOcken.the dialog, at least to the extent hat isrequired for the particular type of thedialog and the domain of application.A considerable amount of work in cur-rent AI research is concerned with in-ferring intentions from utterances (e.g.,\[Allen 83\], \[Carberry 83\], \[Grosz, Sidner86\]) or planning speech acts servingcertain goals (e.g., \[Appelt 85\]), but onlya few uniform approaches to both as-pects have been presented.Most approaches to dialog control de-scribed in the literature offer eitherrigid action schemata that enable thesimulation of the desired behavior onthe surface (but lack the necessary de-gree of flexibility, e. g., \[Metzing 79\]), ordescriptive methods which may also in-clude possible alternatives for the con-tinuation of the dialog, but without ex-pressing criteria to .~aide an adequatechoice among them (e. g., \[Me~ing et al87\], \[Bergmann, Gerlach 87\]).Modeling of beliefs and intentions (i.e.,of propositional ttitudes) of the agentsinvolved is found only in the ARGOTsystem \[Litman, Allen 84\].
This ap-proach behaves ufficiently well in se-veral isolated situations, but it fails todemonstrate a continuously adequatebehavior in the course of a complete dia-log.
An elaborated theoretical frame-work is provided in \[Cohen, Perrault79\] but they explicitly exclude the dele-tion of propositional attitudes.
Hence,they cannot explain what happenswhen a want has been satisfied.In our approach we have enhanced thepropositional attitudes by associatingthem with time intervals expressingtheir time of validity.
This enables us torepresent the knowledge about the ac-tual state of the dialog (and also aboutpast states) seen from the point of viewof a certain agent and to expresschanges in the propositional attitudes- 27  -occurring in the course of the dialogand to calculate their effect.
This deepmodeling is the essential resource forcontroling the progress of the conversa-tion in approaching its overall goal,and, in particular, for determining thenext subgoal in the conversation whichmanifests itself in a system utterance.We have applied our method in the NLconsultation system WISBER (\[Hora-cek et al 88\], \[Sprenger, Gerlach 88\])which is able to participate in a dialogin the domain of financial investment.REPRESENTINGPROPOSIT IONAL ATTITUDESKnowledge about the state of the dialogis represented as a set of propositionalattitudes.
The following three types ofproposit ional att i tudes of an agenttowards a proposition p form a basicrepertoire :KNOW : The agent is sure that p is true.This does not imply that p is really truesince the system has no means to findout the real state of the world.
As-suming that the user of a dialog systemobeys the sincerity condition (i.e., al-ways telling the truth, c.f.
\[Grice 75\])an assertion uttered by the user impliesthat the user knows the content of thatassertion.BELIEVE : The agent believes, but is notsure, that p is true, or he/she assumes pwithout sufficient evidence.WANT : The agent wants p to be true.Propositional attitudes are representedin our semantic representat ion lan-guage IRS, which is used by all systemcomponents involved in semantic-prag-matic processing.
IRS is based on predi-cate calculus, and contains a rich collec-tion of additional features required byNL processing (see \[Bergmann etal.
87\]for detailed information).
A propositio-nal attitude is written as(<type> <agent> <prop> <t ime>):?
<type> is an element of the set:KNOW, BELIEVE, and WANT.?
The two agents relevant in a dialogsystem are the USER and the SYSTEM.In addit ion,  we use the notion'mutua l  knowledge'.
In formal ly ,this means that both the user andthe system know that  <prop> istrue, and that each knows that theother knows, recursively.
We willuse the notat ion (KNOW MUTUAL< prop > ...) to express that the pro-position < prop > is mutual ly knownby the user and the system.?
< prop > is an IRS formula denotingthe proposition the attitude is about.It may again be a propositional atti-tude, as in (WANT USER (KNOW USER x...) ...) which means that the userwants to know x.
The propositionmay also contain the meta-predi-cates RELATED and AUGMENT: (RELATEDx) means 'something which is relatedto the individual x', i.e., it must bepossible to establish a chain of l inksconnecting the individual and theproposition.
In this general  formRELATED i S  only used to determineassumptions about the user's compe-tence.
For a more intensive applica-tion, however, fur ther  condit ionsmust be put on the connecting links.
(AUGMENT 0 means 'something morespecific than the formula f', i.e., atleast one of the variables must  bequant i f ied  or categor ized moreprecisely or additional propositionsmust be associated.
These meta-pre-dicates are used by the dialog con-trol rules as a very compact way ofexpressing eneral properties of pro-positions.?
Propositional attitudes as any otherstates hold during a period of time.In WISBER we use Al len's t imelogic \[Allen 84\] to represent suchtemporal information \[Poesio 88\].<time> must be an individual oftype TIME-INTERVAL.
In this paper,however, for the sake of brevity wewill use almost exclusively the spe-cial constants NOW, PAST and FUTURE,denoting time intervals which areasserted to be during, before or afterthe current ime.INFERENCE RULESAs new information is provided by theuser and inferences are made by thesystem, the set of propositional atti-tudes to be represented in the systemwill evolve.
While the semantic-prag-matic analysis of user utterances ex-ploits linguistic features to derive the- 28  -attitudes expressed by the utterances(c.f.
\[Gerlach, Sprenger 88\]), the dialogcontrol component interprets  ruleswhich embody knowledge about know-ing and wanting as well as about thedomain of discourse.
These rules de-scribe communicative as well as r/on-communicat ive actions, and specifyhow new propositional attitudes can bederived.
Rules about the domain of dis-course express tate changes includingthe involved action.
The related statesand the triggering action are associatedwith time-intervals so that the correcttemporal sequence can be derived.Both classes of rules are represented ina uniform formalism based on the sche-ma precond i t ion  - ac t ion  - effect:?
The precond i t ion  consists of patternsof propositional attitudes or statesin the domain of discourse.
The pat-terns may contain temporal restric-tions as well as the meta-predicatesmentioned above.
A preconditionmay also contain a rule description,e.g., to express that an agent knowsa rule.?
The act ion  may be either on the lev-el of communication (in the case ofspeech act triggering rules) or on thelevel of the domain (actions the dia-log is about).
However, there are al-so pure inference rules in the dialogcontrol module; their action part isvoid.?
The effect  of a rule is a set of descrip-tions of states of the world and pro-positional att itudes which are in-stantiated when applying the ruleyielding new entries in the system'sknowledge base.
We do not deletepropositional attitudes or other pro-OSitions, i.e., the system will notrget them, but we can mark thetime interval associated with an en-try as being 'finished'.
Thus we canexpress that the entry is no longervalid, and it will no longer match apattern with the time of val idityrestricted to NOW.CONTROL STRUCTURESo far, we have only discussed how theactual state of the dialog (from thepoint of view of  a cer ta in  agent )  can berepresented and how changes in thisstate can be described.
We still need amethod to determine and carry out therelevant changes, given a certain stateof the dialog, after interpreting a userutterance (i.e., to decide which dialogrules may be tried and in which order).For reasons of simplicity we have divid-ed the set of rules into three subsetseach of them being responsible for ac-complishing a specific subtask, namely:?
gaining additional information in-ferable from the interrelation bet-ween recent information comingfrom the last user utterance and theactual dialog context.
The combina-tion of new and old information may,e.
g., change the degree of certaintyof some proposition, i. e., terminatean (uncertain) BELIEVE state and cre-ate a (certain) KNOW state with iden-tical propositional content (the con-sistency maintenance rule package).?
pursuing a global (cognitive or ma-nipulative) goal; this may be doneeither by trying to satisfy this goaldirectly, or indirectly by substitut-ing a more adequate goal for it andpursuing this new goal.
In particu-lar, a goal substitution is urgentlyneeded in case the original goal isunsatisfiable (for the system), but apromising alternative is avai lable(the goal pursuit rule package).?
pursuing a communicative subgoal.I f  a goal can not (yet) be accom-plished due to lack of information,this leads to the creation of a WANTconcerning knowledge about themissing information.
When a goalhas been accomplished or a signi-ficant difference in the beliefs of theuser and the system has been disco-vered, the system WANTS the user tobe informed about that.
All this isdone in the phase concerned withcognitive goals.
Once such a WANT iscreated, it can be associated with anappropriate speech act, provided thecompetent dialog partner (be it theuser or an external expert) is deter-mined (the speech act t r igger in~rule package).There is a certain l inear dependencybetween these subtasks.
Therefore therespective rule packages are applied ina suitable (sequential) order, whereasthose rules belonging to the same pack-- 29  -age may be applied in any order (thereexist no interrelations within a singlerule package).
This simple forward in-ferencing works correctly and with anacceptable performance for the actualcoverage and degree of complexity ofthe system.A sequence consisting of these threesubtasks forms a (cognitive) processingcycle of the system from receiving auser message to init iating an adequatereply.
This procedure is repeated untilthere is evidence that the goal of theconversation has been accomplished (asindicated by knowledge and assump-tions about the user's WANTS) or thatthe user wants to finish the dialog.
Ineither case the system closes the dialog.APPL ICAT ION IN ACONSULTATION SYSTEMIn this section we present he applica-tion of our method in the NL consul-ration system WISBER involving rath-er complex interaction with subdialogs,requests for explanation, recommenda-tions, and adjustment  of proposals.However, it is possible to introducesome simplifications typical for consul-ration dialogs.
These are urgently need-ed in order to reduce the otherwise x-cessive amount of complexity.
In parti-cular, we assume that the user does notlie and take his/her assertions aboutreal world events as true (the sinceritycondition).
Moreover, we take it forgranted that the user is highly interest-ed in a consultation dialog and, there-fore, will pay attention to the conversa-tion on the screen so that it can be rea-sonably assumed that he/she is fullyaware of all utterances occurring in thecourse of the dialog.Based on these (implicit) expectations,the following (simplified) assumptions(1) and (2) represent the starting pointfor a consultation dialog:(1) (BELIEVE SYSTEM(WANT USER((EXIST X (STATE X))(HAS-EXPERIENCER X USER))NOW) NOW)(2) (BELIEVE SYSTEM(KNOW USER(RELATED ((EXIST Y (STATE Y))(HAS-EXPERIENCER Y USER)))NOW) NOW)They express that the user knows some-thing that 'has to do' (expressed by themeta-predicate RELATED) with states(STATE Y) concerning him/hersel f  andthat he/she wants to achieve a state(STATE X).
In assumption 1,(STATE X) is infact specialized for a consultation sys-tem as a real world state (instead of amental state which is the general as-sumption in any dialog system).
Thisstate can still be made more concretewhen the domain of application is takeninto account:In WISBER, we assume that the userwants his/her money 'to be invested.
'The second assumption expresses (apart of) the competence ofthe user.
Thisis not of particular importance for manyother types of dialog systems.
In a con-sultation system, however, this is thebasis for addressing the user in order toask him\]her to make his/her intentionsmore precise.
In the course of the dialogthese assumptions are supposed to beconfirmed and, moreover, their contentis expected to become more precise.In the subsequent paragraphs we out-line the processing behavior of the sys-tem by explaining the application andthe effect of some of the most importantdialog rules (at least one of each of thethree packages introduced in the previ-ous section), thus giving an impressionof the system's coverage.
In the rulespresented below, variables are suitablyquantified as they appear for the firsttime in the precondition.
In subsequentappearences they are referred to l ikeconstants.
The interpretation ofthe spe-cial constants denoting t ime-intervalsdepends on whether they occur on theleft or on the right side of a rule: in theprecondition the associated state/eventmust hold/occur during PAST, FUTURE oroverlaps NOW; in the effect the state/event is associated with a time-intervalthat starts at the reference time-inter-val.In a consultation dialog, the user'swants may not always express a directrequest for information, but rather re-fer to events and states in the realworld.
From such user wants the sys-tem must derive requests for knowledgeuseful when attempting to satisfythem.2 Consequently the task of infer-- 30  -(KNOW MUTUAL(WANT USER(EXIST A (ACTION A)) NOW) NOW)A(KNOW SYSTEM(UNIQUE R(AND (RULE R)(HAS-ACTION R A)(HAS-PRECONDITION R(EXIST 51 (STATE 51)))(HAS-EFFECT R(EXIST $2 (STATE 52))))) NOW)=~(KNOW MUTUAL(WANT USER51 NOW) NOW)A(KNOW MUTUALR NOW)A(KNOW MUTUAL(WANT USERs2 NOW) NOW)Rule 1: Inference drawn from a user want referring to an action with unambi-guous consequences (pursuing aglobal goal)ring communicative goals is of centralimportance for the functionality of thesystem.There is, however, a fundamental dis-tinction whether the content of a wantrefers to a state or to an event (to bemore precise, to an action, mostly).
Inthe latter case some important infer-ences can be drawn depending on thedomain knowledge about the envi-sioned action and the degree of preci-sion expressed in its specificatiqn.
If,according to the system's  domainmodel, the effect of the specified actionis unambiguous, the user can be expect-ed to be familiar with this relation, sohe/she can be assumed to envision theresulting state and, possibly, the pre-condition as well, if it is not yet ful-filled.
Thus, in principle, a plan consist-ing of a sequence of actions could be cre-ated by application of skil l ful rulechaining.This is exactly what Rule 1 asserts:Given the mutual knowledge that theuser wants a certain action to occur,and the system's knowledge (in form ofa unique rule) about the associated pre-condition and effect, the system con-cludes that  the user envis ions theresulting state and he/she is famil iarwith the connecting causal relation.
Ifthe uniqueness of the rule cannot be2 Unlike other systems, e.g., UC \[Wilensky etal.
84\], which can directly perform some kindsof actions required by the user, WISBER isunable to affect any part of the real world inthe domain of application.-31established, sufficient evidence derivedfrom the partner model might be analternative basis to obtain a sufficientcategorization of the desired event sothat a unique rule is found.
Otherwisethe user has to be asked to precisehis/her intention.Let us suppose, to give an example, thatthe user has expressed a want to investhis/her money.
According to WISBER'sdomain model, there is only one match-ing domain rule expressing that  theuser has to possess the money beforebut not after investing his/her money,and obtains, in exchange, an asset of anequivalent value.
Hence Rule 1 fires.The want expressed by the second partof the conclusion can be immediatelysatisfied as a consequence of the userutterance 'I have inherited 40 000 DM'by applying Rule 5 (which will be ex-plained later).
The remainder part  ofthe conclusion matches almost com-pletely the precondition of Rule 2.This rule states: If  the user wants toachieve a goal state (G) and is informedabout the way this can be done (he/sheknows the specific RULE R and is capableof performing the relevant action), thesystem is right to assume that the useris lacking some information which in-hibits him/her from actually doing it.Therefore, a want of the user indicatingthe intention to know more about thistransaction is created (expressed by themeta-predicate AUGMENT).
If the neces-sary capability cannot be attributed tothe user a consultation is impossible.If, to discuss another example, the userhas expressed a want aiming at a cer-(KNOW MUTUAL(WANT USER(EXIST S (STATE S)) NOW) NOW)A(KNOW MUTUAL(UNIQUE R(AND (RULE R)(HAS-EFFECT R S)(HAS-ACTION R(EXIST A (ACTION A))))) NOW)A(KNOW MUTUAL(CAPABILITY USER A) NOW)=~(BELIEVE SYSTEM(WANT USER(KNOW USER(AUGMENT S)FUTURE)NOW)NOW)Rule 2: Inference drawn from a user want referring to a state, given his/her ac-quaintance with the associated causal relation (pursuing a global goal)rain state (e.g., 'I want to have my mon-ey back'), the application of anotherrule almost identical to Rule 1 is at-tempted.
When its successful applica-tion yields the association of a uniqueevent, the required causal relation isestablished.
Moreover, the user's fami-l iarity with this relation must be deri-vable in order to follow the path indi-cated by Rule 2.
Otherwise, a want ofthe user would be created whose con-tent is to find out about suitable meansto achieve the desired state (as ex-pressed by Rule 3, leading to a systemreaction like, e.g., 'you must dissolveyour savings account').It is very frequently the case that thesatisfaction of a want cannot immedi-ately be achieved because the precisionof its specification is insufficient.
Whenthe domain-specific problem solvingcomponent indicates a clue about whatinformation would be helpful in this re-spect his triggers the creation of a sys-tem want to get acquainted with it.Whenever the user's uninformedness ina particular case is not yet proved, andthis information falls into his/her com-petence area, control is passed to the ge-neration component to address a suit-able question to the user (as expressedin Rule 4).Provided with new information hopeful-ly obtained by the user's reply the sys-tem tries again to satisfy the (more pre-cisely specified) user want.
This processis repeated until an adequate degree ofspecification is achieved at some stage.
(KNOW MUTUAL(WANT USER(EXIST G(STATE G)) NOW) NOW)A(KNOW SYSTEM(EXIST R(AND (RULE R)(HAS-EFFECT R G)(HAS-PRECONDITION R(EXIST S (STATE S)))(HAS-ACTION R(EXIST A (ACTION A))))) NOW)A(-= (KNOW USER R NOW))=~(BELIEVE SYSTEM(WANT USER(KNOW USERRFUTURE)NOW)NOW)Rule  3 :  Inference drawn from a user want referring to a state, missing his/her ac-quaintance with the associated causal relation (pursuing a global goal)- 32  -(WANT SYSTEM(KNOW SYSTEMX FUTURE) NOW)A(BELIEVE SYSTEM(KNOW USER(RELATED X)NOW) NOW)A(-I (KNOW SYSTEM(-1 (KNOW USERx NOW)) NOW))(ASKSYSTEMUSERx)(KNOW MUTUAL(WANT SYSTEM(KNOW SYSTEM XFUTURE)NOW) NOW)A(KNOW MUTUAL(BELIEVE SYSTEM(KNOW USER(RELA TED X)NOW)NOW) NOW)Rule 4: Inference drawn from the user's (assumed) competence and a systemwant in this area (triggering a speech act)In the course of the dialog each utter-ance effects parts of the system's cur-rent model of the user (concerning as-sumptions or temporarily establishedknowledge).
Therefore, these ffects arechecked in order to keep the data baseconsistent.
Consider, for instance, auser want aiming at investing somemoney which, after a phase of para-meter assembling, has led to the systemproposal 'I recommend you to buybonds' apparently accomplishing the(substitued) goal of obtaining enoughinformation to perform the envisionedaction.
Consequently, the state of theassociated user want is subject tochange which is expressed by Rule 5.Therefore, the mutual knowledge aboutthe user want is modified (by closingthe associated time-interval) and thethe user's want is marked as being 'fin-ished' and added to the (new) mutualknowledge.However, this simplified treatment ofthe satisfaction of a want includes therestrictive assumptions that the accept-ance of the proposal is (implicitly) anti-cipated, and that modifications of awant or of a proposal are not manage-able.
In a more elaborated version, thegoal accomplishment has to be markedas provisory.
If the user expresseshis/her acceptance either explicitly orchanges the topic (thus implicitlyagreeing to the proposal), the appli-cation of Rule 5 is fully justified.Apart from the problem of the increas-ing complexity and the amount of ne-cessary additional rules, the prelimi-nary status of our solution has much todo with problems of interpreting theAUGMENT-predicate which appears inthe representation f a communicativegoal according to the derivation by Rule2: The system is satisfied by finding anyadditional information augmenting theuser's knowledge, but it is not aware ofthe requirement that the informationmust be a suitable supplement (which isrecognizable by the user's confirmationonly).
(KNOW MUTUAL(WANT USER (MEETS TI NOW)X NOW) A(EXIST TI (KNOW MUTUAL(AND (TIME-INTERVAL TI) =:~ (WANT USER(DURING TI NOW)))) XA PAST)(KNOW MUTUAL NOW)x NOW)Rule 5: Inference drawn from a (mutually known) user want which the userknows to be accomplished (pursuing consistency maintenance)- 33  -FUTURE RESEARCHThe method described in this paper isfully implemented and integrated inthe complete NL system WISBER.
A re-latively small set of rules has provedsufficient to guide basic consultation di-alogs.
Currently we are extending theset of dialog control rules to performmore complex dialogs.
Our special in-terest lies on clarification dialogs tohandle misconceptions and inconsisten-cies.
The first steps towards handlinginconsistent user goals will be an expli-cit representation f the interrelation-ships holding between propositional t-titudes, e.g., goals being simultaneousor competing, or one goal being a re-finement of another goal.
A major ques-tion will be specifying the operationsnecessary to recognize those interrela-tionships working on the semantic re-presentation of the propositional con-tents.
As our set of rules grows, a moresophisticated control mechanism willbecome necessary, structuring the deri-vation process and employing both for-ward and backward reasoning.REFERENCESAllen 83Allen, J.F.
: Recognizing Intentions from Natur-al Language Utterances.
In: Brady, M., Ber-wick, R.C.
(eds.
): Computational Models of Dis-course, MIT Press, 1983, pp.
107-166.Allen 84Allen, J.F.
: Towards a General Theory of Actionand Time.
In: Artificial Intelligence 23 (2),1984, pp.
123-154.Appelt 85Appelt, D.E.
: Planning English Sentences.Cambridge University Press, 1985.Bergmann, Gerlaeh 88Bergmann, H., Gerlach, M.: Semantisch-pragmatische Verarbeitung von ~,uflerungenim nattlrlichsprachlichen BeratungssystemWISBER.
In: Brauer, W., Wahlster, W.
(eds.
):Wissensbasierte Systeme - GI-Kongress 1987.Springer Verlag, Berlin, 1987, pp.
318-327.Bergmann et.
al.
87Bergmann, H., Fliegner, M., Gerlach, M.,Marburger, H., Poesio, M.: \[RS - The InternalRepresentation Language.
WISBER Bericht Nr.14, Universi~t Hamburg, 1987.Carberry 83Carberry, S.: Tracking User Goals in an Infor-mation-Seeking Environment.
In: Proceedingsof the AAAI-83, Washington, D.C., 1983, pp.59-63.Cohen, Perrault 79Cohen, P.R., Perrault, C.R.
: Elements of a Plan-Based Theory of Speech Acts.
In: CognitiveScience 3, 1979, pp.
177-212.Gerlach, Sprenger 88Gerlach, M., Sprenger, M.: Semantic Interpreta-tion of Pragmatic Clues: Connectives, ModalVerbs, and Indirect Speech Acts.
In: Proc.
ofCOLING-88, Budapest, 1988, pp.
191-195.Grice 75 ~Grice, H.P.
: Logic and Conversation.
in: Cole,Morgan (ed.
): Syntax and Semantics, Vol.
3:Speech Acts, Academic Press, New York, 1975,pp.
41-58.Grosz, Sidner 86Grosz, B.J., Sidner, C.L.
: Attention, Intentions,and the Structure of Discourse.
In: Compu-tational Linguistics 12 (3), 1986, pp.
175-204.Horacek et al 88Horacek, H., Bergmann, H., Block, R., Fliegner,M., Gerlach, M., Poesio, M., Sprenger, M.: FromMeaning to Meaning - a Walk through WIS.BER.
In: Hoeppner, W.
(ed.
): Kiinstliche Intelli-genz - GWAI-88, Springer Verlag, Berlin, 1988,pp.
118-129.Litman, Allen 84Litman, D.J., Allen, J.F.
: A Plan RecognitionModel for Clarification Subdialogues.
In: Proc.COLING'84, Stanford, pp.
302-311.MeBing, et al 87Mefling, J., Liermann I., Schachter-Radig M.-J.
:HandIungsschemata in Beratungsdialogen -Am Gespr(zchsgegenstand orientierte Dialog-analyse.
Bericht Nr.
18, WISBER-Verbundpro-jekt, Dezember 1987, SCS Organisationsbera-tung und Informationstechnik GmbH, Ham-burg.Metzing 79Metzing, D.: Zur Entwicklung prozeduralerDialogmodeIle.
In: Metzing, D.
(Ed.
): Dialog-muster und Dialogprozesse.
Helmut BuskeVerlag, Hamburg, 1979.Poesio 88Poesio, M.: Toward a Hybrid Representation fTime.
In: Proc.
of the ECAI-88, Mtinchen, 1988,pp, 247-252.Sprenger, Gerlach 88Sprenger, M., Gerlach, M.: Expectations andPropositional Attitudes - Pragmatic Issues inWISBER.
In: Proc.
of the International Com-puter Science Conference '88, ttong Kong, 1988.Werner 88Werner, E.: Toward a Theory of Communica-tion and Cooperation for Multiagent Planning.In: Theoretical Aspects of Reasoning aboutKnowledge, Proceedings of the 1988 Confer-ence, Morgan Kaufman Publishers, Los Altos,1988, pp.
129-143.Wilensky et al 84Wilensky, R., Arens, Y., Chin, D.: Talking toUNIX in English: An Overview of UC.
In: Com-munications ofthe ACM, Vol.
27, No.
6, pp.
574-593.- 34  -
