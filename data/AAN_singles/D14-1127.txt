Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1203?1209,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsLearning Emotion Indicators from Tweets: Hashtags, Hashtag Patterns,and PhrasesAshequl QadirSchool of ComputingUniversity of UtahSalt Lake City, UT 84112, USAasheq@cs.utah.eduEllen RiloffSchool of ComputingUniversity of UtahSalt Lake City, UT 84112, USAriloff@cs.utah.eduAbstractWe present a weakly supervised approachfor learning hashtags, hashtag patterns, andphrases associated with five emotions: AFFEC-TION, ANGER/RAGE, FEAR/ANXIETY, JOY,and SADNESS/DISAPPOINTMENT.
Startingwith seed hashtags to label an initial set oftweets, we train emotion classifiers and usethem to learn new emotion hashtags and hash-tag patterns.
This process then repeats in abootstrapping framework.
Emotion phrasesare also extracted from the learned hashtagsand used to create phrase-based emotion clas-sifiers.
We show that the learned set of emo-tion indicators yields a substantial improve-ment in F-scores, ranging from +%5 to +%18over baseline classifiers.1 IntroductionIdentifying emotions in social media text can be benefi-cial for many applications, for example to help compa-nies understand how people feel about their products,to assist governments in recognizing growing anger orfear associated with an event, or to help media outletsunderstand people?s emotional response toward contro-versial issues or international affairs.
On the Twittermicro-blogging platform, people often use hashtags toexpress an emotional state (e.g., #happyasalways, #an-gryattheworld).
While some hashtags consist of a sin-gle word (e.g., #angry), many hashtags include multi-ple words and creative spellings (e.g., #cantwait4tmrw,#Youredabest), which can not be easily recognized us-ing sentiment or emotion lexicons.Our research learns three types of emotion in-dicators for tweets: hashtags, hashtag patterns,and phrases for one of five emotions: AFFEC-TION, ANGER/RAGE, FEAR/ANXIETY, JOY, or SAD-NESS/DISAPPOINTMENT.
We present a bootstrappingframework for learning emotion hashtags and extendthe framework to also learn more general hashtag pat-terns.
We then harvest emotion phrases from the hash-tags and hashtag patterns for contextual emotion clas-sification.First, we make the observation that emotion hashtagsoften share a common prefix.
For example, #angry-attheworld and #angryatlife both have the prefix ?an-gry at?, which suggests the emotion ANGER.
Conse-quently, we generalize beyond specific hashtags to cre-ate hashtag patterns that will match all hashtags withthe same prefix, such as the pattern #angryat* whichwill match both #angryattheworld and #angryatlife.A key challenge is that a seemingly strong emotionword or phrase can have a different meaning dependingupon the following words.
For example, #angry* mayseem like an obvious pattern to identify ANGER tweets.But #angrybirds is a popular hashtag that refers to agame, not the writer?s emotion.
Similarly, ?love you?usually expresses AFFECTION when it is followed bya person (e.g., #loveyoumom).
But it may express JOYin other contexts (e.g., #loveyoulife).
We use probabil-ity estimates to determine which hashtag patterns arereliable indicators for an emotion.Our second observation is that hashtags can also beused to harvest emotion phrases.
For example, if welearn that the hashtag #lovelife is associated with JOY,then we can extract the phrase ?love life?
from thehashtag and use it to recognize emotion in the bodyof tweets.
However, unlike hashtags, which are self-contained, the words surrounding a phrase in a tweetmust also be considered.
For example, negation cantoggle polarity (?don?t love life?
may suggest SAD-NESS, not JOY) and the aspectual context may indicatethat no emotion is being expressed (e.g., ?I would lovelife if ...?).
Consequently, we train classifiers to deter-mine if a tweet contains an emotion based on both anemotion phrase and its context.2 Related WorkIn addition to sentiment analysis, which has beenwidely studied (e.g., (Barbosa and Feng, 2010; Brodyand Diakopoulos, 2011; Kouloumpis et al., 2011;Mitchell et al., 2013)), recognizing emotions in socialmedia text has also become a popular research topic inrecent years.
Researchers have studied feature sets andlinguistic styles (Roberts et al., 2012), emotion influ-encing behaviors (Kim et al., 2012), sentence contexts(Yang et al., 2007b), hierarchical emotion classifica-tion (Ghazi et al., 2010; Esmin et al., 2012) and emo-tion lexicon creation (Yang et al., 2007a; Mohammad,2012a; Staiano and Guerini, 2014).
Researchers havealso started to utilize the hashtags of tweets, but pri-marily to collect labeled data (e.g., for sarcasm (Davi-1203Figure 1: Bootstrapped Learning.
(HT = hashtag; HP = hashtag pattern)dov et al., 2010; Riloff et al., 2013) and for senti-ment/emotion data (Wang et al., 2012; Mohammad etal., 2013; Choudhury et al., 2012; Purver and Bat-tersby, 2012; Mohammad, 2012a)).Wang et al.
(2011) investigated several graph basedalgorithms to collectively classify hashtag sentiments,but their work is focused on positive versus nega-tive polarity classification.
Our research extends thepreliminary work on bootstrapped learning of emo-tion hashtags (Qadir and Riloff, 2013) to additionallylearn patterns corresponding to hashtag prefix expres-sions and to extract emotion phrases from the hashtags,which are used to train phrase-based emotion classi-fiers.3 Learning Emotion Hashtags, HashtagPatterns and PhrasesFor our research, we collapsed Parrot?s emo-tion taxonomy (Parrott, 2001)1into 5 emotionclasses that frequently occur in tweets and min-imally overlap with each other: AFFECTION,ANGER/RAGE, FEAR/ANXIETY, JOY, and SAD-NESS/DISAPPOINTMENT.
We also used a NONE OFTHE ABOVE class for tweets that do not express anyemotion or express an emotion different from our fiveclasses.
For each of these categories, we identified 5common hashtags that are strongly associated with theemotion and used them as seeds.
Table 1 shows theseed hashtags.Compared to the Ekman emotion classes (Ekman,1992), one of the emotion taxonomies frequently usedin NLP research (Strapparava and Mihalcea, 2007; Mo-hammad, 2012b), JOY, ANGER, SADNESS and FEARare comparable to 4 of our 5 emotion classes.
We donot study Ekman?s SURPRISE and DISGUST classes,but include AFFECTION.3.1 Learning HashtagsFigure 1 presents the framework of the bootstrappingalgorithm for hashtag learning.
The process begins by1There were other emotions in Parrott?s taxonomy suchas SURPRISE, NEGLECT, etc.
that we did not use for thisresearch.Emotion Classes Seed HashtagsAFFECTION #loveyou, #sweetheart, #bff#romantic, #soulmateANGER & RAGE #angry, #mad, #hateyou#pissedoff, #furiousFEAR & ANXIETY #afraid, #petrified, #scared#anxious, #worriedJOY #happy, #excited, #yay#blessed, #thrilledSADNESS & #sad, #depressedDISAPPOINTMENT #disappointed, #unhappy#foreveraloneTable 1: Emotion Classes and Seed Hashtagscollecting tweets that contain the seed hashtags and la-beling them with the corresponding emotion.
For thispurpose, we collected 323,000 tweets in total that con-tain at least one of our seed hashtags.
We also exploit alarge pool of unlabeled tweets to use during bootstrap-ping, consisting of 2.3 million tweets with at least onehashtag per tweet (because we want to learn hashtags),collected using Twitter?s streaming API.
We did not in-clude retweets or tweets with URLs, to reduce duplica-tion and focus on tweets with original content.
The un-labeled tweets dataset had 1.29 average hashtags-per-tweet and 3.95 average tweets-per-hashtag.
We prepro-cessed the tweets with CMU?s tokenizer (Owoputi etal., 2013) and normalized with respect to case.The labeled tweets are then used to train a set ofemotion classifiers.
We trained one logistic regressionclassifier for each emotion class using the LIBLINEARpackage (Fan et al., 2008).
We chose logistic regressionbecause it produces probabilities with its predictions,which are used to assign scores to hashtags.
As fea-tures, we used unigrams and bigrams with frequency>1.
We removed the seed hashtags from the tweets sothe classifiers could not use them as features.For each emotion class e ?
E, the tweets contain-ing a seed hashtag for e were used as positive traininginstances.
The negative training instances consisted ofthe tweets containing seed hashtags for the competingemotions as well as 100,000 randomly selected tweets1204Affection Anger & Fear & Joy Sadness &Rage Anxiety Disappointment#yourthebest #godie #hatespiders #tripleblessed #leftout#myotherhalf #donttalktome #haunted #tgfad #foreverugly#bestfriendforever #pieceofshit #shittingmyself #greatmood #singleprobs#loveyoulots #irritated #worstfear #thankful #lonerlyfe#flyhigh #fuming #scaresme #atlast #teamlonely#comehomesoon #hateliars #nightmares #feelinggood #unloved#wuvyou #heated #paranoid #happygirl #friendless#alwaysandforever #getoutofmylife #hateneedles #godisgreat #heartbroken#missyousomuch #angrytweet #frightened #superhappy #needalife#loveyougirl #dontbothermewhen #freakedout #ecstatic #letdownTable 2: Examples of Learned Hashtagsfrom our unlabeled tweets.
Although some of the unla-beled tweets may correspond to emotion e, we expectthat most will have no emotion or an emotion differentfrom e, giving us a slightly noisy but large, diverse setof negative instances.We then apply each emotion classifier to the un-labeled tweets.
For each emotion e, we collect thetweets classified as e and extract the hashtags fromthose tweets to create a candidate pool Heof hashtagsfor emotion e. To limit the number of candidates, wediscard hashtags that occur < 10 times, have just onecharacter, or have> 20 characters.
Next, we score eachcandidate hashtag h by computing the average proba-bility assigned by the logistic regression classifier foremotion e over all of the tweets containing hashtag h.For each emotion class, we select the 10 hashtags withthe highest scores.
From the unlabeled tweets, we thenadd all tweets with one of the learned hashtags to thetraining instances, and the bootstrapping process con-tinues.
Table 2 shows examples of the learned hashtags.3.2 Learning Hashtag PatternsWe learn hashtag patterns in a similar but separate boot-strapping process.
We first expand each hashtag into asequence of words using an N-gram based word seg-mentation algorithm2supplied with corpus statisticsfrom our tweet collection.
For example, #angryatlifeexpands3to the phrase ?angry at life?.
We use a PrefixTree (Trie) data structure to represent all possible pre-fixes of the expanded hashtag phrases, but the prefixesconsist of words instead of characters.Next, we traverse the tries and consider all possi-ble prefix paths as candidate hashtag patterns.
Weonly consider prefixes that have occurred with at leastone following word.
For example, #angryashell, #an-gryasalways, #angrybird, #angryatlife, #angryatyouwould produce patterns: #angry*, #angryas*, #an-gryat* as shown in Figure 2.We score each pattern by applying the classifier for2http://norvig.com/ngrams/3On a random sample of 100 hashtags, we found expan-sion accuracy to be 76% (+8% partially correct expansions).Figure 2: Trie of example hashtags with prefix angry.Dotted lines lead to non-terminal nodes where patternsare extracted.emotion e (trained in the same way as hashtag learn-ing) to all tweets having hashtags that match the pat-tern.
We compute the average probability produced bythe classifier, and for each emotion class, we select the10 hashtag patterns with the highest scores.
From theunlabeled tweets, we then add all tweets with hashtagsthat match one of the learned hashtag patterns to thetraining instances, and the bootstrapping process con-tinues.
Table 3 shows examples of learned hashtag pat-terns and matched hashtags.3.3 Creating Phrase-based ClassifiersThe third type of emotion indicator that we acquire areemotion phrases.
At the end of the bootstrapping pro-cess, we apply the word segmentation algorithm to allof the learned hashtags and hashtag patterns to expandthem into phrases (e.g., #lovemylife ?
?love my life?
).Each phrase is assumed to express the same emotion asthe original hashtag.
However, as we will see in Sec-tion 4, just the presence of a phrase yields low preci-sion, and surrounding context must also be taken intoaccount.Consequently, we train a logistic regression classi-fier for each emotion e, which classifies a tweet withrespect to emotion e based on the presence of a learnedphrase for e as well as a context window of size 6around the phrase (set of 3 words on its left and set of 31205Emotion Hashtag Pattern Examples of Matching HashtagsAFFECTION #bestie* #bestiefolyfe, #bestienight, #bestielove#missedyou* #missedyoutoomuch, #missedyouguys, #missedyoubabiesANGER & RAGE #godie* #godieoldman, #godieyou, #godieinahole#pissedoff* #pissedofffather, #pissedoffnow, #pissedoffmoodFEAR & ANXIETY #tooscared* #tooscaredtogoalone, #tooscaredformama, #tooscaredtomove#nightmares* #nightmaresfordays, #nightmaresforlife, #nightmarestonightJOY #feelinggood* #feelinggoodnow, #feelinggoodforme, #feelinggoodabout#goodmood* #goodmooditsgameday, #goodmoodmode, #goodmoodnightSADNESS & #bummed* #bummedout, #bummedaf, #bummednowDISAPPOINTMENT #singlelife* #singlelifeblows, #singlelifeforme, #singlelifesucksTable 3: Examples of Learned Hashtag Patterns and Matching Hashtagswords on its right).
Tweets containing a learned phrasefor e and a seed hashtag for e are the positive traininginstances.
Tweets containing a learned phrase for e anda seed hashtag for a different emotion are used as thenegative training instances.
For example, when ?lovemy life?
is learned as an emotion phrase for JOY, thetweet, ?how can I love my life when everybody leavesme!
#sad?
will have one feature each for the left words?how?, ?can?, and ?I?, one feature each for the rightwords ?when?, ?everybody?
and ?leaves?, and onefeature for the phrase ?love my life?.
The tweet willthen be considered a negative instance for JOY because?#sad?
indicates a different emotion.4 Experimental ResultsTo evaluate our learned emotion indicators, we manu-ally selected 25 topic keywords/phrases4that we con-sidered to be strongly associated with emotions, butnot necessarily with any specific emotions of our study.We then searched in Twitter using Twitter Search APIfor any of these topic phrases and their correspond-ing hashtags.
These 25 topic phrases are: Prom,Exam, Graduation, Marriage, Divorce, Husband, Wife,Boyfriend, Girlfriend, Job, Hire, Laid Off, Retirement,Win, Lose, Accident, Failure, Success, Spider, LoudNoise, Chest Pain, Storm, Home Alone, No Sleep andInterview.
Since the purpose is to evaluate the qual-ity and coverage of the emotion hashtags that we learn,we filtered out any tweet that did not have at least onehashtag.Two annotators were given annotation guidelinesand were instructed to label each tweet with up totwo emotions.
The instructions specified that the emo-tion must be felt by the writer.
The annotators an-notated 500 tweets with an inter-annotator agreementlevel of 0.79 Kappa (?)
(Carletta, 1996).
The an-notation disagreements in these 500 tweets were thenadjudicated, and each annotator labeled an additional2,500 tweets.
Altogether this gave us an emotion an-notated dataset of 5,500 tweets.
We randomly sepa-rated out 1,000 tweets from this collection as a tuning4This data collection process is similar to the emotiontweet dataset creation by Roberts et al.
(2012)set, and used the remaining 4,500 tweets as evaluationdata.
The distribution of emotions in the evaluationdata was 6% for AFFECTION, 9% for ANGER/RAGE,13% for FEAR/ANXIETY, 22% for JOY, and 12% forSADNESS/DISAPPOINTMENT.
42% of the tweets hadnone of the 5 emotions and 4% of the tweets had morethan one emotions in the same tweet.We created two baseline systems to assess the diffi-culty of the emotion classification task.
First, we cre-ated SVM classifiers for each emotion using N-gramfeatures and performed 10-fold cross-validation on thetest data.
We used LIBSVM (Chang and Lin, 2011)and set the cost and gamma parameters based on thetuning data.
Second, we acquired the NRC EmotionalTweets Lexicon (Mohammad, 2012a), which containsemotion unigrams and bigrams for 8 emotions, 4 thatare comparable to ours: ANGER, FEAR, JOY and SAD-NESS.
We created a hashtag from each term in the lexi-con by appending a # symbol on the front and removingwhitespace.
For each term, we chose the emotion withthe highest score in the lexicon.Table 4 shows our experimental results.
The baselineclassifiers (SVM1uses unigrams, SVM1+2uses uni-grams and bigrams) have low recall but 63-78% pre-cision.
The hashtags created from the NRC Lexiconhave low precision.
This could be due to possible en-tries (e.g., ?candy?
or ?idea?
), which without contextare not much indicative of any specific emotion.The second section of Table 4 shows the results whenwe label a tweet based on the presence of a hash-tag or hashtag pattern.
First, we use just the 5 seedhashtags to assess their coverage (as expected, highprecision but low recall).
Next, we add the hashtagslearned during bootstrapping.
For most emotions, thehashtags achieve performance similar to the supervisedSVMs.
The following row shows results for our learnedhashtag patterns.
Recall improves by +14% for AF-FECTION, which illustrates the benefit of more generalhashtag patterns, and at least maintains similar level ofprecision for other emotions.
When the hashtags andhashtag patterns are combined (HTs+HPs), we see thebest of both worlds with improved recall as high as+17% in AFFECTION and +10% in FEAR/ANXIETY1206AFFECTION ANGER & FEAR & JOY SADNESS &Method RAGE ANXIETY DISAPPOINT.P R F P R F P R F P R F P R FBaselinesSVM178 40 53 66 17 27 68 33 44 66 47 55 63 26 37SVM1+278 35 48 67 10 17 68 29 41 65 43 52 63 21 32NRC Lexicon HTs n/a 26 16 20 39 12 18 36 13 19 28 18 22Learned Hashtags (HTs) and Hashtag Patterns (HPs)Seed HTs 94 06 11 75 01 03 100 06 11 93 04 08 81 02 05All HTs 82 34 48 63 23 34 60 37 46 81 13 22 72 28 40All HPs 76 48 59 60 22 32 57 42 48 84 09 16 73 16 26All HTs+HPs 74 51 60 56 27 36 55 47 51 80 15 25 70 29 41Learned Emotion PhrasesEmotion Phrases 32 28 30 17 46 25 28 45 35 50 23 32 26 30 28Phrase-based Classifier (PC) 54 07 12 48 05 09 63 17 27 69 12 20 50 06 11SVM1+PC 79 42 55 63 18 28 70 35 47 68 48 56 62 27 38Hybrid ApproachSVM1+PC ?
HTs+HPs 69 64 66 55 38 45 54 61 57 68 54 60 62 44 51Table 4: Emotion Classification Results (P = Precision, R = Recall, F = F-score)compared to All HTs, as well as improved F-scoresacross the board.The third section of Table 4 presents the results forthe emotion phrases.
The first row (Emotion Phrases)shows that labeling a tweet based solely on the pres-ence of a phrase is not very accurate.
Next, we appliedthe trained models of the phrase-based classifiers (de-scribed in Section 3.3) to each tweet of the evaluationdata.
This provided us with probability of an emotionfor each of the 5 emotions.
The phrase-based classifiers(PC) yield higher precision, albeit with low recall.
Fi-nally, we use these probabilities as 5 additional featuresto SVM1.
The corresponding SVM1+PC row showsa consistent 1-2 point F score gain over the originalSVM1baseline.The last section of Table 4 shows the best results witha hybrid system, which labels a tweet with emotion e ifEITHER the enhanced SVM labels it as e OR the tweetcontains a hashtag or hashtag pattern associated with e.This combined approach achieves substantially higherperformance than any individual method across all 5emotion classes, with improved F-scores ranging from+%5 to +%18 over the baseline classifiers, demonstrat-ing that the different types of emotion indicators arecomplementary.5 ConclusionsWe have shown that three types of emotion indicatorscan be learned from tweets with weakly supervisedbootstrapping: hashtags, hashtag patterns, and phrases.Our findings suggest that emotion hashtags are strongindicators for recognizing writer?s emotion in tweets,and can be further generalized into hashtag patterns bylearning prefix expressions corresponding to an emo-tion.
Phrases learned from the hashtags and patternsare not always reliable by themselves, but training ad-ditional classifiers with the emotion phrases and theirsurrounding context provides added benefits to emotionclassification in tweets.
Our results showed that com-bining the learned emotion indicators with an N-gramclassifier in a hybrid approach substantially improvesperformance across 5 emotion classes.AcknowledgmentsThis work was supported by the Intelligence AdvancedResearch Projects Activity (IARPA) via Department ofInterior National Business Center (DoI/NBC) contractnumber D12PC00285.
The U.S. Government is autho-rized to reproduce and distribute reprints for Govern-mental purposes notwithstanding any copyright anno-tation thereon.
The views and conclusions containedherein are those of the authors and should not be in-terpreted as necessarily representing the official poli-cies or endorsements, either expressed or implied, ofIARPA, DoI/NBC, or the U.S. Government.ReferencesLuciano Barbosa and Junlan Feng.
2010.
Robust senti-ment detection on twitter from biased and noisy data.In Proceedings of the 23rd International Conferenceon Computational Linguistics: Posters, COLING?10.Samuel Brody and Nicholas Diakopoulos.
2011.Cooooooooooooooollllllllllllll!!!!!!!!!!!!!!
: usingword lengthening to detect sentiment in microblogs.In Proceedings of the Conference on EmpiricalMethods in Natural Language Processing, EMNLP?11.Jean Carletta.
1996.
Assessing agreement on classifi-cation tasks: the kappa statistic.
Comput.
Linguist.,22:249?254, June.1207Chih-Chung Chang and Chih-Jen Lin.
2011.
Libsvm:A library for support vector machines.
ACM Trans.Intell.
Syst.
Technol., 2(3):27:1?27:27, May.Munmun De Choudhury, Michael Gamon, and ScottCounts.
2012.
Happy, nervous or surprised?
clas-sification of human affective states in social media.In Proceedings of the Sixth International Conferenceon Weblogs and Social Media.Dmitry Davidov, Oren Tsur, and Ari Rappoport.
2010.Semi-supervised recognition of sarcastic sentencesin twitter and amazon.
In Proceedings of the Four-teenth Conference on Computational Natural Lan-guage Learning, CoNLL ?10.Paul Ekman.
1992.
An argument for basic emotions.Cognition and Emotion, 6(3):169200.Ahmed Ali Abdalla Esmin, Roberto L. De Oliveira Jr.,and Stan Matwin.
2012.
Hierarchical classifica-tion approach to emotion recognition in twitter.
InProceedings of the 11th International Conference onMachine Learning and Applications, ICMLA, BocaRaton, FL, USA, December 12-15, 2012.
Volume 2,pages 381?385.
IEEE.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin.
2008.
Liblinear: Alibrary for large linear classification.
J. Mach.
Learn.Res., 9:1871?1874, June.Diman Ghazi, Diana Inkpen, and Stan Szpakowicz.2010.
Hierarchical versus flat classification ofemotions in text.
In Proceedings of the NAACLHLT 2010 Workshop on Computational Approachesto Analysis and Generation of Emotion in Text,CAAGET ?10.Suin Kim, JinYeong Bak, and Alice Oh.
2012.Discovering emotion influence patterns in onlinesocial network conversations.
SIGWEB Newsl.,(Autumn):3:1?3:6, September.Efthymios Kouloumpis, Theresa Wilson, and JohannaMoore.
2011.
Twitter sentiment analysis: The goodthe bad and the omg!
In Proceedings of the Fifth In-ternational Conference on Weblogs and Social Me-dia.Margaret Mitchell, Jacqui Aguilar, Theresa Wilson,and Benjamin Van Durme.
2013.
Open domain tar-geted sentiment.
In Proceedings of the 2013 Con-ference on Empirical Methods in Natural LanguageProcessing.Saif Mohammad, Svetlana Kiritchenko, and XiaodanZhu.
2013.
Nrc-canada: Building the state-of-the-art in sentiment analysis of tweets.
In Proceedingsof the seventh international workshop on SemanticEvaluation Exercises (SemEval-2013).Saif Mohammad.
2012a.
#emotional tweets.
In *SEM2012: The First Joint Conference on Lexical andComputational Semantics.Saif Mohammad.
2012b.
Portable features for clas-sifying emotional text.
In Proceedings of the 2012Conference of the North American Chapter of theAssociation for Computational Linguistics: HumanLanguage Technologies.Olutobi Owoputi, Brendan OConnor, Chris Dyer,Kevin Gimpel, Nathan Schneider, and Noah A.Smith.
2013.
Improved part-of-speech tagging foronline conversational text with word clusters.
InProceedings of the North American Chapter of theAssociation for Computational Linguistics (NAACL-2013).W.
Gerrod Parrott, editor.
2001.
Emotions in SocialPsychology.
Psychology Press.Matthew Purver and Stuart Battersby.
2012.
Experi-menting with distant supervision for emotion classi-fication.
In Proceedings of the 13th Conference ofthe European Chapter of the Association for Com-putational Linguistics, EACL ?12, pages 482?491.Ashequl Qadir and Ellen Riloff.
2013.
Bootstrappedlearning of emotion hashtags #hashtags4you.
InProceedings of the 4th Workshop on ComputationalApproaches to Subjectivity, Sentiment and SocialMedia Analysis.Ellen Riloff, Ashequl Qadir, Prafulla Surve, Lalin-dra De Silva, Nathan Gilbert, and Ruihong Huang.2013.
Sarcasm as contrast between a positive senti-ment and negative situation.
In Proceedings of the2013 Conference on Empirical Methods in NaturalLanguage Processing, EMNLP ?13.Kirk Roberts, Michael A. Roach, Joseph Johnson, JoshGuthrie, and Sanda M. Harabagiu.
2012.
Em-patweet: Annotating and detecting emotions on twit-ter.
In Proceedings of the Eighth InternationalConference on Language Resources and Evaluation(LREC-2012).
ACL Anthology Identifier: L12-1059.Jacopo Staiano and Marco Guerini.
2014.
De-pechemood: a lexicon for emotion analysis fromcrowd-annotated news.
In Proceedings of the 52ndAnnual Meeting of the Association for Computa-tional Linguistics (Volume 2: Short Papers).Carlo Strapparava and Rada Mihalcea.
2007.SemEval-2007 Task 14: Affective Text.
In Proceed-ings of the Fourth International Workshop on Se-mantic Evaluations (SemEval-2007).Xiaolong Wang, Furu Wei, Xiaohua Liu, Ming Zhou,and Ming Zhang.
2011.
Topic sentiment analysisin twitter: a graph-based hashtag sentiment classifi-cation approach.
In Proceedings of the 20th ACMinternational conference on Information and knowl-edge management, CIKM ?11.Wenbo Wang, Lu Chen, Krishnaprasad Thirunarayan,and Amit P. Sheth.
2012.
Harnessing twitter ?bigdata?
for automatic emotion identification.
In Pro-ceedings of the 2012 ASE/IEEE International Con-ference on Social Computing and 2012 ASE/IEEE1208International Conference on Privacy, Security, Riskand Trust, SOCIALCOM-PASSAT ?12.Changhua Yang, Kevin Hsin-Yih Lin, and Hsin-HsiChen.
2007a.
Building emotion lexicon fromweblog corpora.
In Proceedings of the 45th An-nual Meeting of the ACL on Interactive Poster andDemonstration Sessions, ACL ?07.Changhua Yang, Kevin Hsin-Yih Lin, and Hsin-HsiChen.
2007b.
Emotion classification using web blogcorpora.
In Proceedings of the IEEE/WIC/ACM In-ternational Conference on Web Intelligence, WI ?07,pages 275?278.1209
