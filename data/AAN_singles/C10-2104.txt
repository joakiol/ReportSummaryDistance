Coling 2010: Poster Volume, pages 901?909,Beijing, August 2010Kernel-based Reranking for Named-Entity ExtractionTruc-Vien T. Nguyen and Alessandro Moschitti and Giuseppe RiccardiDepartment of Information Engineering and Computer ScienceUniversity of Trentonguyenthi,moschitti,riccardi@disi.unitn.itAbstractWe present novel kernels based on struc-tured and unstructured features for rerank-ing the N-best hypotheses of conditionalrandom fields (CRFs) applied to entity ex-traction.
The former features are gener-ated by a polynomial kernel encoding en-tity features whereas tree kernels are usedto model dependencies amongst taggedcandidate examples.
The experiments ontwo standard corpora in two languages,i.e.
the Italian EVALITA 2009 and the En-glish CoNLL 2003 datasets, show a largeimprovement on CRFs in F-measure, i.e.from 80.34% to 84.33% and from 84.86%to 88.16%, respectively.
Our analysis re-veals that both kernels provide a compara-ble improvement over the CRFs baseline.Additionally, their combination improvesCRFs much more than the sum of the indi-vidual contributions, suggesting an inter-esting kernel synergy.1 IntroductionReranking is a promising computational frame-work, which has drawn special attention in theNatural Language Processing (NLP) community.Basically, this method first employs a probabilis-tic model to generate a list of top-n candidates andthen reranks this n-best list with additional fea-tures.
One appeal of this approach is its flexibilityof incorporating arbitrary features into a model.These features help in discriminating good frombad hypotheses and consequently their automaticlearning.
Various algorithms have been appliedfor reranking in NLP applications (Huang, 2008;Shen et al, 2004; Collins, 2002b; Collins andKoo, 2000), including parsing, name tagging andmachine translation.
This work has exploited thedisciminative property as one of the key criterionof the reranking algorithm.Reranking appears extremely interesting if cou-pled with kernel methods (Dinarelli et al, 2009;Moschitti, 2004; Collins and Duffy, 2001), as thelatter allow for extracting from the ranking hy-potheses a huge amount of features along withtheir dependencies.
Indeed, while feature-basedlearning algorithms involve only the dot-productbetween feature vectors, kernel methods allowfor a higher generalization by replacing the dot-product with a function between pairs of linguis-tic objects.
Such functions are a kind of similaritymeasure satisfying certain properties.
An exam-ple is the tree kernel (Collins and Duffy, 2001),where the objects are syntactic trees that encodegrammatical derivations and the kernel functioncomputes the number of common subtrees.
Simi-larly, sequence kernels (Lodhi et al, 2002) countthe number of common subsequences shared bytwo input strings.Named-entities (NEs) are essential for defin-ing the semantics of a document.
NEs are ob-jects that can be referred by names (Chinchor andRobinson, 1998), such as people, organizations,and locations.
The research on NER has beenpromoted by the Message Understanding Con-ferences (MUCs, 1987-1998), the shared task ofthe Conference on Natural Language Learning(CoNLL, 2002-2003), and the Automatic ContentExtraction program (ACE, 2002-2005).
In the lit-erature, there exist various learning approachesto extract named-entities from text.
A NER sys-901tem often builds some generative/discriminativemodel, then, either uses only one classifier (Car-reras et al, 2002) or combines many classifiers us-ing some heuristics (Florian et al, 2003).To the best of our knowledge, reranking hasnot been applied to NER except for the rerank-ing algorithms defined in (Collins, 2002b; Collins,2002a), which only targeted the entity detection(and not entity classification) task.
Besides, sincekernel methods offer a natural way to exploit lin-guistic properties, applying kernels for NE rerank-ing is worthwhile.In this paper, we describe how kernel methodscan be applied for reranking, i.e.
detection andclassification of named-entities, in standard cor-pora for Italian and English.
The key aspect ofour reranking approach is how structured and flatfeatures can be employed in discriminating candi-date tagged sequences.
For this purpose, we applytree kernels to a tree structure encoding NE tags ofa sentence and combined them with a polynomialkernel, which efficiently exploits global features.Our main contribution is to show that (a) treekernels can be used to define general features (notmerely syntactic) and (b) using appropriate al-gorithms and features, reranking can be very ef-fective for named-entity recognition.
Our studydemonstrates that the composite kernel is veryeffective for reranking named-entity sequences.Without the need of producing and heuristicallycombining learning models like previous work onNER, the composite kernel not only captures mostof the flat features but also efficiently exploitsstructured features.
More interestingly, this kernelyields significant improvement when applied totwo corpora of two different languages.
The eval-uation in the Italian corpus shows that our methodoutperforms the best reported methods whereas onthe English data it reaches the state-of-the-art.2 Background2.1 The dataDifferent languages exhibit different linguisticphenomena and challenges.
A robust NER sys-tem is expected to be well-adapted to multipledomains and languages.
Therefore, we experi-mented with two datasets: the EVALITA 2009Italian corpus and the well-known CoNLL 2003English shared task corpus.The EVALITA 2009 Italian dataset is basedon I-CAB, the Italian Content AnnotationBank (Magnini et al, 2006), annotated with fourentity types: Person (PER), Organization (ORG),Geo-Political Entity (GPE) and Location (LOC).The training data, taken from the local newspa-per ?L?Adige?, consists of 525 news stories whichbelong to five categories: News Stories, CulturalNews, Economic News, Sports News and LocalNews.
Test data, on the other hand, consist ofcompletely new data, taken from the same news-paper and consists of 180 news stories.The CoNLL 2003 English dataset is createdwithin the shared task of CoNLL-2003 (Sangand Meulder, 2003).
It is a collection of newswire articles from the Reuters Corpus, annotatedwith four entity types: Person (PER), Location(LOC), Organization (ORG) and Miscellaneousname (MISC).
The training and the developmentdatasets are news feeds from August 1996, whilethe test set contains news feeds from December1996.
Accordingly, the named entities in the testdataset are considerably different from those thatappear in the training or the development set.Italian GPE LOC ORG PERTrain 2813 362 3658 457724.65% 3.17% 32.06% 40.11%Test 1143 156 1289 237823.02% 3.14% 25.96% 47.89%English LOC MISC ORG PERTrain 7140 3438 6321 660030.38% 14.63% 26.90% 28.09%Dev 1837 922 1341 184230.92% 15.52% 22.57% 31.00%Test 1668 702 1661 161729.53% 12.43% 29.41% 28.63%Table 1: Statistics on the Italian EVALITA 2009and English CoNLL 2003 corpora.2.2 The baseline algorithmWe selected Conditional Random Fields (Laffertyet al, 2001) as the baseline model.
Conditional902random fields (CRFs) are a probabilistic frame-work for labeling and segmenting sequence data.They present several advantages over other purelygenerative models such as Hidden Markov models(HMMs) by relaxing the independence assump-tions required by HMMs.
Besides, HMMs andother discriminative Markov models are prone tothe label bias problem, which is effectively solvedby CRFs.The named-entity recognition (NER) task isframed as assigning label sequences to a set ofobservation sequences.
We follow the IOB nota-tion where the NE tags have the format B-TYPE,I-TYPE or O, which mean that the word is a be-ginning, a continuation of an entity, or not part ofan entity at all.
For example, consider the sentencewith their corresponding NE tags, each word is la-beled with a tag indicating its appropriate named-entity, resulting in annotated text, such as:Il/O presidente/O della/O Fifa/B-ORG Sepp/B-PERBlatter/I-PER affermando/O che/O il/O torneo/O era/Ostato/O ottimo/O (FIFA president Sepp Blatter says that thetournament was excellent)For our experiments, we used CRF++ 1 to buildour recognizer, which is a model trained discrim-inatively with the unigram and bigram features.These are extracted from a window at k wordscentered in the target word w (i.e.
the one we wantto classify with the B, O, I tags).
More in detailsuch features are:?
The word itself, its prefixes, suffixes, andpart-of-speech?
Orthographic/Word features.
These arebinary and mutually exclusive features thattest whether a word contains all upper-cased,initial letter upper-cased, all lower-cased,roman-number, dots, hyphens, acronym,lonely initial, punctuation mark, single-char,and functional-word.?
Gazetteer features.
Class (geographical,first name, surname, organization prefix, lo-cation prefix) of words in the window.?
Left Predictions.
The predicted tags on theleft of the word in the current classification.1http://crfpp.sourceforge.netThe gazetteer lists are built with names im-ported from different sources.
For English, thegeographic features are imported from NIMA?sGEOnet Names Server (GNS)2, The AlexandriaDigital Library (ADL) gazetteer3.
The companydata is included with all the publicly traded com-panies listed in Google directory4, the Europeanbusiness directory5.
For Italian, the generic propernouns are extracted from Wikipedia and variousItalian sites.2.3 Support Vector Machines (SVMs)Support Vector Machines refer to a supervisedmachine learning technique based on the latest re-sults of the statistical learning theory.
Given avector space and a set of training points, i.e.
posi-tive and negative examples, SVMs find a separat-ing hyperplane H(~x) = ~?
?
~x + b = 0 where?
?
Rn and b ?
R are learned by applying theStructural Risk Minimization principle (Vapnik,1998).
SVMs are a binary classifier, but they canbe easily extended to multi-class classifier, e.g.
bymeans of the one-vs-all method (Rifkin and Pog-gio, 2002).One strong point of SVMs is the possibility toapply kernel methods to implicitly map data ina new space where the examples are more easilyseparable as described in the next section.2.4 Kernel methodsKernel methods (Scho?lkopf and Smola, 2001) arean attractive alternative to feature-based methodssince the applied learning algorithm only needsto compute a product between a pair of objects(by means of kernel functions), avoiding the ex-plicit feature representation.
A kernel functionis a scalar product in a possibly unknown featurespace.
More precisely, The object o is mapped in~x with a feature function ?
: O ?
<n, where Ois the set of the objects.The kernel trick allows us to rewrite the deci-sion hyperplane as:H(~x) =( ?i=1..lyi?i~xi)?
~x+ b =2http://www.nima.mil/gns/html3http://www.alexandria.ucsb.edu4http://directory.google.com/Top/Business5http://www.europages.net903?i=1..lyi?i~xi ?
~x+ b =?i=1..lyi?i?
(oi) ?
?
(o) + b,where yi is equal to 1 for positive and -1 fornegative examples, ?i ?
< with ?i ?
0, oi?i ?
{1, .., l} are the training instances and theproduct K(oi, o) = ??
(oi) ?
?(o)?
is the kernelfunction associated with the mapping ?.Kernel engineering can be carried out by com-bining basic kernels with additive or multiplica-tive operators or by designing specific data objects(vectors, sequences and tree structures) for the tar-get tasks.Regarding NLP applications, kernel methodshave attracted much interest due to the ability ofimplicitly exploring huge amounts of structuralfeatures.
The parse tree kernel (Collins and Duffy,2001) and string kernel (Lodhi et al, 2002) areexamples of the well-known convolution kernelsused in various NLP tasks.2.5 Tree KernelsTree kernels represent trees in terms of their sub-structures (called tree fragments).
Such fragmentsform a feature space which, in turn, is mapped intoa vector space.
Tree kernels measure the similar-ity between pair of trees by counting the numberof fragments in common.
There are three impor-tant characterizations of fragment type: the Sub-Trees (ST), the SubSet Trees (SST) and the PartialTrees (PT).
For sake of space, we do not report themathematical description of them, which is avail-able in (Vishwanathan and Smola, 2002), (Collinsand Duffy, 2001) and (Moschitti, 2006), respec-tively.
In contrast, we report some descriptions interms of feature space that may be useful to un-derstand the new engineered kernels.In principle, a SubTree (ST) is defined by tak-ing any node along with its descendants.
A SubSetTree (SST) is a more general structure which doesnot necessarily include all the descendants.
Thedistinction is that an SST must be generated by ap-plying the same grammatical rule set which gen-erated the original tree, as pointed out in (Collinsand Duffy, 2001).
A Partial Tree (PT) is a moregeneral form of sub-structures obtained by relax-ing constraints over the SSTs.
Figure 1 shows theoverall fragment set of the ST, SST and PT kernelsfor the syntactic parse tree of the sentence frag-Figure 1: Three kinds of tree kernels.ment: gives a talk .In the next section, we will define new struc-tures for tagged sequences of NEs which alongwith the application of the PT kernel produce in-novative tagging kernels for reranking.3 Reranking Method3.1 Reranking StrategyAs a baseline we trained the CRFs model to gen-erate 10-best candidates per sentence, along withtheir probabilities.
Each candidate was then rep-resented by a semantic tree together with a featurevector.
We consider our reranking task as a binaryclassification problem where examples are pairsof hypotheses < Hi, Hj >.Given a sentence ?South African Breweries Ltdbought stakes in the Lech and Tychy brewers?
and threeof its candidate tagged sequences:H1 B-ORG I-ORG I-ORG I-ORG O O O O B-ORG OB-ORG O (the correct sequence)H2 B-MISC I-MISC B-ORG I-ORG O O O O B-ORGI-ORG I-ORG OH3 B-ORG I-ORG I-ORG I-ORG O O O O B-ORG OB-LOC Owhere B-ORG, I-ORG, B-LOC, O are the gen-erated NE tags according to IOB notation as de-scribed in Section 3.2.With the above data (an original sentence to-gether with a list of candidate tagged sequences),the following pairs of hypotheses will be gener-904ated < H1, H2 >, < H1, H3 >,< H2, H1 > and< H3, H1 >, where the first two pairs are positiveand the latter pairs are negative instances.
Then abinary classifier based on SVMs and kernel meth-ods can be trained to discriminate between thebest hypothesis, i.e.
< H1 > and the others.
Attesting time the hypothesis receiving the highestscore is selected (Collins and Duffy, 2001).3.2 Representation of Tagged Sequences inSemantic TreesWe now consider the representation that exploitsthe most discriminative aspects of candidate struc-tures.
As in the case of NER, an input can-didate is a sequence of word/tag pairs x ={w1/t1...wn/tn} where wi is the i?th word andti is the i?th NE tag for that word.
The first repre-sentation we consider is the tree structure.
See fig-ure 2 as an example of candidate tagged sequenceand its semantic tree.With the sentence ?South African Breweries Ltdbought stakes in the Lech and Tychy brewers?
and threeof its candidate tagged sequences in the previoussection, the training algorithm considers to con-struct a tree for each sequence, with the named-entity tags as pre-terminals and the words asleaves.
See figure 2 for an example of the seman-tic tree for the first tagged sequence.With this tree representation, for a word wi, thetarget NE tag would be set at parent and the fea-tures for this word are at child nodes.
This allowsus to best exploit the inner product between com-peting candidates.
Indeed, in the kernel space,the inner product counts the number of commonsubtrees thus sequences with similar NE tags arelikely to have higher score.
For example, the sim-ilarity between H1 and H3 will be higher than thesimilarity of the previous hypotheses withH2; thisis reasonable since these two also have higher F1.It is worth noting that another useful modifica-tion is the flexibility of incorporate diverse, ar-bitrary features into this tree structure by addingchildren to the parent node that contains entity tag.These characteristics can be exploited efficientlywith the PT kernel, which relaxes constraints ofproduction rules.
The inner product can implicitlyinclude these features and deal better with sparsedata.3.3 Global featuresMixed n-grams featuresIn previous works, some global features havebeen used (Collins, 2002b; Collins, 2002a) but theemployed algorithm just exploited arbitrary infor-mation regarding word types and linguistic pat-terns.
In contrast, we define and study diversefeatures by also considering n-grams patterns pre-ceding, and following the target entity.Complementary contextIn supervised learning, NER systems often suf-fer from low recall, which is caused by lack ofboth resource and context.
For example, a wordlike ?Arkansas?
may not appear in the training setand in the test set, there may not be enough con-text to infer its NE tag.
In such cases, neitherglobal features (Chieu and Ng, 2002) nor aggre-gated contexts (Chieu and Ng, 2003) can help.To overcome this deficiency, we employed thefollowing unsupervised procedure: first, the base-line NER is applied to the target un-annotated cor-pus.
Second, we associate each word of the corpuswith the most frequent NE category assigned inthe previous step.
Finally, the above tags are usedas features during the training of the improvedNER and also for building the feature represen-tation for a new classification instance.This way, for any unknown word w of the testset, we can rely on the most probable NE categoryas feature.
The advantage is that we derived it byusing the average over many possible contexts ofw, which are in the different instances of the un-nanotated corpus.The unlabeled corpus for Italian was collectedfrom La Repubblica 6 and it contains over 20 mil-lions words.
Whereas the unlabeled corpus forEnglish was collected mainly from The New YorkTimes 7 and BBC news stories 8 with more than35 millions words.Head wordAs the head word of an entity plays an impor-tant role in information extraction (Bunescu andMooney, 2005a; Surdeanu et al, 2003), it is in-6http://www.repubblica.it/7http://www.nytimes.com/8http://news.bbc.co.uk/905Figure 2: Semantic structure of the first sequencecluded in the global set together with its ortho-graphic feature.
We now describe some primitivesfor our global feature framework.1.
wi for i = 1 .
.
.
n is the i?th word2.
ti is the NE tag of wi3.
gi is the gazetteer feature of the word wi4.
fi is the most frequent NE tag seen in a largecorpus of wi5.
hi is the head word of the entity.
We nor-mally set the head word of an entity as its lastword.
However, when a preposition exists inthe entity string, its head word is set as thelast word before the preposition.
For exam-ple, the head word of the entity ?Universityof Pennsylvania?
is ?University?.6.
Mixed n-grams features of the words andtheir gazetteers/frequent-tag before/after thestart/end of an entity.
In addition to thenormal n-grams solely based on words, wemixed words with gazetteers/frequent-tagseen from a large corpus and create mixedn-grams features.Table 2 shows the full set of global features inour reranking framework.
Features are anchoredto each entity instance and adapted to entity types.This helps to discriminate different entities withthe same surface forms.
Moreover, they can becombined with n-grams patterns to learn and ex-plicitly push the score of the correct sequenceabove the score of competing sequences.3.4 Reranking with Composite KernelIn this section we describe our novel tagging ker-nels based on diverse global features as well assemantic trees for reranking candidate tagged se-quences.
As mentioned in the previous section,we can engineer kernels by combining tree andentity kernels.
Thus we focus on the problem todefine structure embedding the desired relationalinformation among tagged sequences.The Partial Tree KernelLet F = f1, f2, .
.
.
, f|F | be a tree fragmentspace of type PTs and let the indicator functionIi(n) be equal to 1 if the target f1 is rooted at noden and 0 otherwise, we define the PT kernel as:K(T1, T2) =?n1?NT1?n2?NT2?
(n1, n2)where NT1 and NT2 are the set of nodesin T1 and T2 respectively and ?
(n1, n2) =?|F |i=1 Ii(n1)Ii(n2), i.e.
the number of commonfragments rooted at the n1 and n2 nodes of thetype shown in Figure 1.c.The Polynomial KernelThe polynomial kernel between two candidatetagged sequences is defined as:K(x, y) = (1 + ~x1 ?
~x2)2,where ~x1 and ~x2 are two feature vectors extractedfrom the two sequences with the global featuretemplate.The Tagging KernelsIn our reranking framework, we incorporate theprobability from the original model with the treestructure as well as the feature vectors.
Let us con-sider the following notations:906Feature Descriptionws ws+1 .
.
.
we Entity stringgs gs+1 .
.
.
ge The gazetteer feature within the entityfs fs+1 .
.
.
fe The most frequent NE tag feature (seen from alarge corpus) within the entityhw The head word of the entitylhw Indicates whether the head word is lower-casedws?1 ws; ws?1 gs; gs?1 ws; gs?1 gs Mixed bigrams of the words/gazetteer featuresbefore/after the start of the entitywe we+1; we ge+1; ge we+1; ge ge+1 Mixed bigrams of the words/gazetteer featuresbefore/after the end of the entityws?1 ws; ws?1 fs; fs?1 ws; fs?1 fs Mixed bigrams of the words/frequent-tag fea-tures before/after the start of the entitywe we+1; we fe+1; fe we+1; fe fe+1 Mixed bigrams of the words/frequent-tag fea-tures before/after the end of the entityws?2 ws?1 ws; ws?1 ws ws+1; we?1 we we+1; we?2 we?1 we Trigram features of the words before/after thestart/end of the entityws?2 ws?1 gs; ws?2 gs?1 ws; ws?2 gs?1 gs;gs?2 ws?1 ws; gs?2 ws?1 gs; gs?2 gs?1 ws; gs?2 gs?1 gs;ws?1 ws gs+1; ws?1 gs ws+1; ws?1 gs gs+1;gs?1 ws ws+1; gs?1 ws gs+1; gs?1 gs ws+1; gs?1 gs gs+1Mixed trigrams of the words/gazetteer featuresbefore/after the start of the entitywe?1 we ge+1; we?1 ge we+1; we?1 ge ge+1;ge?1 we we+1; ge?1 we ge+1; ge?1 ge we+1; ge?1 ge ge+1;we?2 we?1 ge; we?2 ge?1 we; we?2 ge?1 ge;ge?2 we?1 we; ge?2 we?1 ge; ge?2 ge?1 we; ge?2 ge?1 geMixed trigrams of the words/gazetteer featuresbefore/after the end of the entityws?2 ws?1 fs; ws?2 fs?1 ws; ws?2 fs?1 fs;fs?2 ws?1 ws; fs?2 ws?1 fs; fs?2 fs?1 ws; fs?2 fs?1 fs;ws?1 ws fs+1; ws?1 fs ws+1; ws?1 fs fs+1;fs?1 ws ws+1; fs?1 ws fs+1; fs?1 fs ws+1; fs?1 fs fs+1Mixed trigrams of the words/frequent-tag fea-tures before/after the start of the entitywe?1 we fe+1; we?1 fe we+1; we?1 fe fe+1;fe?1 we we+1; fe?1 we fe+1; fe?1 fe we+1; fe?1 fe fe+1;we?2 we?1 fe; we?2 fe?1 we; we?2 fe?1 fe;fe?2 we?1 we; fe?2 we?1 fe; fe?2 fe?1 we; fe?2 fe?1 feMixed trigrams of the words/frequent-tag fea-tures before/after the end of the entityTable 2: Global features in the entity kernel for reranking.
These features are anchored for each entityinstance and adapted to entity categories.
For example, the entity string (first feature) of the entity?United Nations?
with entity type ?ORG?
is ?ORG United Nations?.?
K(x, y) = L(x) ?
L(y) is the basic kernelwhere L(x) is the log probability of a can-didate tagged sequence x under the originalprobability model.?
TK(x, y) = t(x) ?
t(y) is the partial tree ker-nel under the structure representation?
FK(x, y) = f(x) ?
f(y) is the polynomialkernel under the global featuresThe tagging kernels between two tagged se-quences are defined in the following combina-tions:1.
CTK = ?
?K + (1?
?)
?
TK2.
CFK = ?
?K + (1?
?)
?
FK3.
CTFK = ?
?K + (1?
?)
?
(TK + FK)where ?, ?, ?
are parameters weighting the twoparticipating terms.
Experiments on the validationset showed that these combinations yield the bestperformance with ?
= 0.2 for both languages,?
= 0.4 for English and ?
= 0.3 for and Italian,?
= 0.24 for English and ?
= 0.2 for Italian.4 Experimens and Results4.1 Experimental SetupAs a baseline we trained the CRFs classifier onthe full training portion (11,227 sentences in theItalian and 14,987 sentences in the English cor-pus).
In developing a reranking strategy for bothEnglish and Italian, the training data was split into5 sections, and in each case the baseline classifierwas trained on 4/5 of the data, then used to decodethe remaining 1/5.907The top 10 hypotheses together with their logprobabilities were recovered for each training sen-tence.
Similarly, a model trained on the wholetraining data was used to produce 10 hypothesesfor each sentence in the development set.
For thereranking experiments, we applied different ker-nel setups to the two corpora described in Section2.1.
The three kernels were trained on the trainingportion.Italian Test P R FCRFs 83.43 77.48 80.34CTK 84.97 78.03 81.35CFK 84.93 79.13 81.93CTFK 85.99 82.73 84.33(Zanoli et al, 2009) 84.07 80.02 82.00English Test P R FCRFs 85.37 84.35 84.86CTK 87.19 84.79 85.97CFK 86.53 86.75 86.64CTFK 88.07 88.25 88.16(Ratinov and Roth, ) N/A N/A 90.57Table 3: Reranking results of the three taggingkernels on the Italian and English testset.4.2 DiscussionTable 3 presents the reranking results on the testdata of both corpora.
The results show a 20.29%relative improvement in F-measure for Italian and21.79% for English.CFK based on unstructured features achieveshigher accuracy than CTK based on structuredfeatures.
However, the huge amount of subtreesgenerated by the PT kernel may limit the expres-sivity of some structural features, e.g.
many frag-ments may only generate noise.
This problem isless important with the polynomial kernel whereglobal features are tailored for individual entities.In any case, the experiments demonstrate thatboth tagging kernels CTK and CFK give im-provement over the CRFs baseline in both lan-guages.
This suggests that structured and unstruc-tured features are effective in discriminating be-tween competing NE annotations.Furthermore, the combination of the two tag-ging kernels on both standard corpora shows alarge improvement in F-measure from 80.34% to84.33% for Italian and from 84.86% to 88.16%for English data.
This suggests that these two ker-nels, corresponding to two kinds of feature, com-plement each other.To better collocate our results with previouswork, we report the best NER outcome on theItalian (Zanoli et al, 2009) and the English (Rati-nov and Roth, ) datasets, in the last row (in italic)of each table.
This shows that our model outper-forms the best Italian NER system and it is closeto the state-of-art model for English, which ex-ploits many complex features9.
Also note that weare very close to the F1 achieved by the best sys-tem of CoNLL 2003, i.e.
88.8.5 ConclusionWe analyzed the impact of kernel-based ap-proaches for modeling dependencies betweentagged sequences for NER.
Our study illustratesthat each individual kernel, either with structuredor with flat features clearly gives improvement tothe base model.
Most interestingly, as we showed,these contributions are independent and, the ap-proaches can be used together to yield better re-sults.
The composite kernel, which combines bothkinds of features, can outperform the state-of-the-art.In the future, it will be very interesting touse syntactic/semantic kernels, as for example in(Basili et al, 2005; Bloehdorn and Moschitti,2007a; Bloehdorn and Moschitti, 2007b).
An-other promising direction is the use of syntactictrees, feature sequences and pairs of instances,e.g.
(Nguyen et al, 2009; Moschitti, 2008).AcknowledgmentsWe would like to thank Roberto Zanoli andMarco Dinarelli for helpful explanationabout their work.
This work has been par-tially funded by the LiveMemories project(http://www.livememories.org/) and ExpertSystem (http://www.expertsystem.net/) researchgrant.9In the future we will be able to integrate them with theauthors collaboration.908ReferencesBasili, Roberto, Marco Cammisa, and AlessandroMoschitti.
2005.
Effective use of WordNet seman-tics via kernel-based learning.
In CoNLL.Bloehdorn, Stephan and Alessandro Moschitti.
2007a.Combined syntactic and semantic kernels for textclassification.
In ECIR.Bloehdorn, Stephan and Alessandro Moschitti.
2007b.Structure and semantics for expressive text kernels.In CIKM.Bunescu, Razvan C. and Raymond J. Mooney.
2005a.A shortest path dependency kernel for relation ex-traction.
In EMNLP.Carreras, Xavier, Llu?
?s Ma`rques, and Llus Padro?.2002.
Named entity extraction using Adaboost.
InCoNLL.Chieu, Hai Leong and Hwee Tou Ng.
2002.
Namedentity recognition: A maximum entropy approachusing global information.
In COLING.Chieu, Hai Leong and Hwee Tou Ng.
2003.
Namedentity recognition with a maximum entropy ap-proach.
In CoNLL.Chinchor, Nancy and Patricia Robinson.
1998.
Muc-7named entity task definition.
In the MUC.Collins, Michael and Nigel Duffy.
2001.
Convolutionkernels for natural language.
In NIPS.Collins, Michael and Terry Koo.
2000.
Discriminativereranking for natural language parsing.
In ICML.Collins, Michael.
2002a.
New ranking algorithms forparsing and tagging: Kernels over discrete struc-tures, and the voted perceptron.
In ACL.Collins, Michael.
2002b.
Ranking algorithms fornamed-entity extraction boosting and the voted per-ceptron.
In ACL.Dinarelli, Marco, Alessandro Moschitti, and GiuseppeRiccardi.
2009.
Re-ranking models based on smalltraining data for spoken language understanding.
InEMNLP.Florian, Radu, Abe Ittycheriah, Hongyan Jing, andTong Zhang.
2003.
Named entity recognitionthrough classifier combination.
In CoNLL.Huang, Liang.
2008.
Forest reranking: Discriminativeparsing with non-local features.
In ACL-HLT.Lafferty, John, Andrew McCallum, and FernandoPereira.
2001.
Conditional random fields: Prob-abilistic models for segmenting and labeling se-quence data.
In ICML.Lodhi, Huma, Craig Saunders, John Shawe Taylor,Nello Cristianini, , and Chris Watkins.
2002.
Textclassification using string kernels.
Journal of Ma-chine Learning Research, pages 419?444.Magnini, Bernardo, Emmanuele Pianta, Christian Gi-rardi, Matteo Negri, Lorenza Romano, ManuelaSperanza, Valentina Bartalesi Lenzi, and RacheleSprugnoli.
2006.
I-CAB: the italian content anno-tation bank.
In LREC.Moschitti, Alessandro.
2004.
A study on convolutionkernels for shallow semantic parsing.
In ACL.Moschitti, Alessandro.
2006.
Efficient convolutionkernels for dependency and constituent syntactictrees.
In ICML.Moschitti, Alessandro.
2008.
Kernel methods, syntaxand semantics for relational text categorization.
InCIKM.Nguyen, Truc-Vien T., Alessandro Moschitti, andGiuseppe Riccardi.
2009.
Convolution kernels onconstituent, dependency and sequential structuresfor relation extraction.
In EMNLP.Ratinov, Lev and Dan Roth.
Design challenges andmisconceptions in named entity recognition.
InCoNLL.Rifkin, Ryan Michael and Tomaso Poggio.
2002.
Ev-erything old is new again: a fresh look at historicalapproaches in machine learning.
PhD thesis, MIT.Sang, Erik F. Tjong Kim and Fien De Meulder.2003.
Introduction to the conll-2003 shared task:Language-independent named entity recognition.In CoNLL.Scho?lkopf, Bernhard and Alexander J. Smola.
2001.Learning with Kernels: Support Vector Machines,Regularization, Optimization, and Beyond.
MITPress, Cambridge, MA, USA.Shen, Libin, Anoop Sarkar, and Franz Josef Och.2004.
Discriminative reranking for machine transla-tion.
In HLT-NAACL, Boston, Massachusetts, USA.Surdeanu, Mihai, Sanda Harabagiu, John Williams,and Paul Aarseth.
2003.
Using predicate-argumentstructures for information extraction.
In ACL.Vapnik, Vladimir N. 1998.
Statistical Learning The-ory.
John Wiley and Sons, New York.Vishwanathan, S.V.N.
and Alexander J. Smola.
2002.Fast kernels on strings and trees.
In NIPS.Zanoli, Roberto, Emanuele Pianta, and Claudio Giu-liano.
2009.
Named entity recognition through re-dundancy driven classifiers.
In EVALITA.909
