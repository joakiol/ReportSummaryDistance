Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 259?263,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsWord Epoch Disambiguation:Finding How Words Change Over TimeRada MihalceaComputer Science and EngineeringUniversity of North Texasrada@cs.unt.eduVivi NastaseInstitute for Computational LinguisticsUniversity of Heidelbergnastase@cl.uni-heidelberg.deAbstractIn this paper we introduce the novel task of?word epoch disambiguation,?
defined as theproblem of identifying changes in word us-age over time.
Through experiments run us-ing word usage examples collected from threemajor periods of time (1800, 1900, 2000), weshow that the task is feasible, and significantdifferences can be observed between occur-rences of words in different periods of time.1 IntroductionMost current natural language processing workswith language as if it were a constant.
This how-ever, is not the case.
Language is continually chang-ing: we discard or coin new senses for old words;metaphoric and metonymic usages become so en-grained that at some point they are considered lit-eral; and we constantly add new words to our vocab-ulary.
The purpose of the current work is to look atlanguage as an evolutionary phenomenon, which wecan investigate and analyze and use when workingwith text collections that span a wide time frame.Until recently, such task would not have beenpossible because of the lack of large amounts ofnon-contemporary data.1 This has changed thanksto the Google books and Google Ngrams historicalprojects.
They make available in electronic formata large amount of textual data starting from the 17thcentury, as well as statistics on word usage.
We willexploit this data to find differences in word usageacross wide periods of time.1While the Brown corpus does include documents from dif-ferent years, it is far from the scale and time range of Googlebooks.The phenomena involved in language change arenumerous, and for now we focus on word usage indifferent time epochs.
As an example, the word gay,currently most frequently used to refer to a sexualorientation, was in the previous century used to ex-press an emotion.
The word run, in the past used in-transitively, has acquired a transitive sense, commonin computational circles where we run processes,programs and such.The purpose of the current research is to quan-tify changes in word usage, which can be the ef-fect of various factors: changes in meaning (ad-dition/removal of senses), changes in distribution,change in topics that co-occur more frequently witha given word, changes in word spelling, etc.
For nowwe test whether we can identify the epoch to which aword occurrence belongs.
We use two sets of words?
one with monosemous words, the other with poly-semous ones ?
to try and separate the effect of topicchange over time from the effect of sense change.We use examples from Google books, split intothree epochs: 1800+/-25 years, 1900+/-25, 2000+/-25.
We select open-class words that occur frequentlyin all these epochs, and words that occur frequentlyonly in one of them.
We then treat each epoch asa ?class,?
and verify whether we can correctly pre-dict this class for test instances from each epoch forthe words in our lists.
To test whether word usagefrequency or sense variation have an impact on thisdisambiguation task, we use lists of words that havedifferent frequencies in different epochs as well asdifferent polysemies.
As mentioned before, we alsocompare the performance of monosemous ?
and thus(sensewise) unchanged through time ?
and polyse-mous words, to verify whether we can in fact predictsense change as opposed to contextual variation.2592 Related WorkThe purpose of this paper is to look at words andhow they change in time.
Previous work that looksat diachronic language change works at a higher lan-guage level, and is not specifically concerned withhow words themselves change.The historical data provided by Google hasquickly attracted researchers in various fields, andstarted the new field of culturomics (Michel et al,2011).
The purpose of such research is to analysechanges in human culture, as evidenced by the riseand fall in usage of various terms.Reali and Griffiths (2010) analyse the similaritiesbetween language and genetic evolution, with thetransmission of frequency distributions over linguis-tic forms functioning as the mechanism behind thephenomenon of language change.Blei and Lafferty (2006) and Blei and Lafferty(2007) track changes in scientific topics through adiscrete dynamic topic model (dDTM) ?
both astypes of scientific topics at different time points, andas changing word probability distributions withinthese topics.
The ?Photography?
topic for examplehas changed dramatically since the beginning of the20th century, with words related to digital photog-raphy appearing recently, and dominating the mostcurrent version of the topic.Wang and McCallum (2006), Wang et al (2008)develop time-specific topic models, where topics,as patterns of word use, are tracked across a timechanging text collection, and address the task of(fine-grained) time stamp prediction.Wijaya and Yeniterzi (2011) investigate throughtopic models the change in context of a specific en-tity over time, based on the Google Ngram corpus.They determine that changes in this context reflectevents occurring in the same period of time.3 Word Epoch DisambiguationWe formulate the task as a disambiguation prob-lem, where we automatically classify the period oftime when a word was used, based on its surround-ing context.
We use a data-driven formulation, anddraw examples from word occurrences over threedifferent epochs.
For the purpose of this work, weconsider an epoch to be a period of 50 years sur-rounding the beginning of a new century (1800+/-25 years, 1900+/-25, 2000+/-25).
The word usageexamples are gathered from books, where the publi-cation year of a book is judged to be representativefor the time when that word was used.
We selectwords with different characteristics to allow us to in-vestigate whether there is an effect caused by sensechange, or the disambiguation performance comesfrom the change of topics and vocabulary over time.4 Experimental SettingTarget Words.
The choice of target words for ourexperiments is driven by the phenomena we aim toanalyze.
Because we want to investigate the behav-ior of words in different epochs, and verify whetherthe difference in word behavior comes from changesin sense or changes in wording in the context, wechoose a mixture of polysemous words and monose-mous words (according to WordNet and manuallychecked against Webster?s dictionary editions from1828, 1913 and the current Merriam-Webster edi-tion), and also words that are frequent in all epochs,as well as words that are frequent in only one epoch.According to these criteria, for each open class(nouns, verbs, adjectives, adverbs) we select 50words, 25 of which have multiple senses, 25 withone sense only.
Each of these two sets has a 10-5-5-5 distribution: 10 words that are frequent in allthree epochs, and 5 per each epoch such that thesewords are only frequent in one epoch.
To avoid part-of-speech ambiguity we also choose words that areunambiguous from this point of view.
This selectionprocess was done based on Google 1gram historicaldata, used for computing the probability distributionof open-class words for each epoch.
2The set of target words consists thus of 200open class words, uniformly distributed over the 4parts of speech, uniformly distributed over multiple-sense/unique sense words, and with the frequencybased sample as described above.
From this initialset of words, we could not identify enough examplesin the three epochs considered for 35,3 which left uswith a final set of 165 words.Data.
For each target word in our dataset, we collectthe top 100 snippets returned by a search on GoogleBooks for each of the three epochs we consider.2For each open class word we create ranked lists of words,where the ranking score is an adjusted tfidf score ?
the epochscorrespond to documents.
To choose words frequent only in oneepoch, we choose the top words in the list, for words frequentin all epochs we choose the bottom words in this list.3A minimum of 30 total examples was required for a wordto be considered in the dataset.260All the extracted snippets are then processed: thetext is tokenized and part-of-speech tagged using theStanford tagger (Toutanova et al, 2003), and con-texts that do not include the target word with thespecified part-of-speech are removed.
The positionof the target word is also identified and recorded asan offset alng with the example.For illustration, we show below an example drawnfrom each epoch for two different words,dinner:1800: On reaching Mr. Crane?s house, dinnerwas set before us ; but as is usual here in manyplaces on the Sabbath, it was both dinner andtea combined into a single meal.1900: The average dinner of today consistsof relishes; of soup, either a consomme (clearsoup) or a thick soup.2000: Preparing dinner in a slow cooker iseasy and convenient because the meal you?remaking requires little to no attention while itcooks.and surgeon:1800: The apothecaries must instantly dis-pense what medicines the surgeons requirefor the use of the regiments.1900: The surgeon operates, collects a fee,and sends to the physician one-third or one-half of the fee, this last transaction being un-known to the patient.2000: From a New York plastic surgeoncomes all anyone ever wanted to know?andnever imagined?about what goes on behindthe scenes at the office of one of the world?smost prestigious plastic surgeons.Disambiguation Algorithm.
The classification al-gorithm we use is inspired by previous work on data-driven word sense disambiguation.
Specifically, weuse a system that integrates both local and topicalfeatures.
The local features include: the currentword and its part-of-speech; a local context of threewords to the left and right of the ambiguous word;the parts-of-speech of the surrounding words; thefirst noun before and after the target word; the firstverb before and after the target word.
The topicalfeatures are determined from the global context andare implemented through class-specific keywords,which are determined as a list of at most five wordsoccurring at least three times in the contexts defin-ing a certain word class (or epoch).
This feature setis similar to the one used by (Ng and Lee, 1996).No.
Avg.
no.POS words examples Baseline WEDNoun 46 190 42.54% 66.17%Verb 49 198 42.25% 59.71%Adjective 26 136 48.60% 60.13%Adverb 44 213 40.86% 59.61%AVERAGE 165 190 42.96% 61.55%Table 1: Overall results for different parts-of-speech.The features are then integrated in a Naive Bayesclassifier (Lee and Ng, 2002).Evaluation.
To evaluate word epoch disambigua-tion, we calculate the average accuracy obtainedthrough ten-fold cross-validations applied on thedata collected for each word.
To place results in per-spective, we also calculate a simple baseline, whichassigns the most frequent class by default.5 Results and DiscussionTable 1 summarizes the results obtained for the 165words.
Overall, the task appears to be feasible,as absolute improvements of 18.5% are observed.While improvements are obtained for all parts-of-speech, the nouns lead to the highest disambiguationresults, with the largest improvement over the base-line, which interestingly aligns with previous obser-vations from work on word sense disambiguation(Mihalcea and Edmonds, 2004; Agirre et al, 2007).Among the words considered, there are words thatexperience very large improvements over the base-line, such as ?computer?
(with an absolute increaseover the baseline of 42%) or ?install?
(41%), whichare words that are predominantly used in one of theepochs considered (2000), and are also known tohave changed meaning over time.
There are alsowords that experience very small improvements,such as ?again?
(3%) or ?captivate?
(7%), which arewords that are frequently used in all three epochs.There are even a few words (seven) for which thedisambiguation accuracy is below the baseline, suchas ?oblige?
(-1%) or ?cruel?
(-15%).To understand to what extent the change in fre-quency over time has an impact on word epoch dis-ambiguation, in Table 2 we report results for wordsthat have high frequency in all three epochs consid-ered, or in only one epoch at a time.
As expected,the words that are used more often in an epochare also easier to disambiguate.4 For instance, the4The difference in results does not come from difference in261verb ?reassert?
has higher frequency in 2000, and ithas a disambiguation accuracy of 67.25% comparedto a baseline of 34.15%.
Instead, the verb ?con-ceal,?
which appears with high frequency in all threeepochs, has a disambiguation accuracy of 44.70%,which is a relatively small improvement over thebaseline of 38.04%.No.
Avg.
no.POS words examples Baseline WEDHigh frequency in all epochsNoun 18 180 42.31% 65.77%Verb 19 203 43.45% 56.43%Adjective 7 108 46.27% 57.75%Adverb 17 214 40.32% 56.41%AVERAGE 61 188 42.56% 59.33%High frequency in one epochNoun 28 196 42.68% 66.42%Verb 30 194 41.50% 61.80%Adjective 19 146 49.47% 61.02%Adverb 27 213 41.20% 61.63%AVERAGE 104 191 43.20% 62.86%Table 2: Results for words that have high frequency in allepochs, or in one epoch at a timeThe second analysis that we perform is concernedwith the accuracy observed for polysemous words ascompared to monosemous words.
Comparative re-sults are reported in Table 3.
Monosemous words donot have sense changes over time, so being able toclassify them in different epochs relies exclusivelyon variations in their context over time.
Polysemouswords?s context change because of both changes intopics/vocabulary over time, and changes in wordsenses.
The fact that we see a difference in ac-curacy between disambiguation results for monose-mous and polysemous words is an indication thatword sense change is reflected and can be capturedin the context.To better visualize the improvements obtainedwith word epoch disambiguation with respect to thebaseline, Figure 1 plots the results.6 ConclusionsIn this paper, we introduced the novel task of wordepoch disambiguation, which aims to quantify thechanges in word usage over time.
Using examplescollected from three major periods of time, for 165words, we showed that the word epoch disambigua-tion algorithm can lead to an overall absolute im-size in the data, as the number of examples extracted for wordsof high or low frequency is approximately the same.allEpochs1Epochpolysemousmonosemous1012141618202224Noun Verb Adj Adv Avg.WED?BaselinePOSBy epoch frequency101214161820222426Noun Verb Adj Adv Avg.WED?BaselinePOSBy number of sensesFigure 1: Word epoch disambiguation compared to thebaseline, for words that are frequent/not frequent (in agiven epoch), and monosemous/polysemous.No.
Avg.
no.POS words examples Baseline WEDPolysemous wordsNoun 24 191 41.89% 66.55%Verb 25 214 42.71% 58.84%Adjective 12 136 45.40% 57.42%Adverb 23 214 39.38% 60.03%AVERAGE 84 196 41.94% 61.16%Monosemous wordsNoun 22 188 43.25% 65.77%Verb 24 181 41.78% 60.63%Adjective 14 136 51.36% 62.47%Adverb 21 213 42.49% 59.15%AVERAGE 81 183 44.02% 61.96%Table 3: Results for words that are polysemous ormonosemous.provement of 18.5%, as compared to a baseline thatpicks the most frequent class by default.
These re-sults indicate that there are significant differencesbetween occurrences of words in different periodsof time.
Moreover, additional analyses suggest thatchanges in usage frequency and word senses con-tribute to these differences.
In future work, we planto do an in-depth analysis of the features that bestcharacterize the changes in word usage over time,and develop representations that allow us to tracksense changes.AcknowledgmentsThis material is based in part upon work sup-ported by the National Science Foundation CA-REER award #0747340.
Any opinions, findings,and conclusions or recommendations expressed inthis material are those of the authors and do notnecessarily reflect the views of the National ScienceFoundation.262ReferencesE.
Agirre, L. Marquez, and R. Wicentowski, editors.2007.
Proceedings of the 4th International Workshopon Semantic Evaluations, Prague, Czech Republic.D.
Blei and J. Lafferty.
2006.
Dynamic topic models.
InProceedings of the 23rd International Conference onMachine Learning.D.
Blei and J. Lafferty.
2007.
A correlated topic model ofScience.
The Annals of Applied Science, 1(1):17?35.Y.K.
Lee and H.T.
Ng.
2002.
An empirical evaluation ofknowledge sources and learning algorithms for wordsense disambiguation.
In Proceedings of the 2002Conference on Empirical Methods in Natural Lan-guage Processing (EMNLP 2002), Philadelphia, June.J.-B.
Michel, Y.K.
Shen, A. P. Aiden, A. Veres, M. K.Gray, J. P. Pickett, D. Hoiberg, D. Clancy, P. Norvig,J.
Orwant, S. Pinker, M. A. Nowak, and E. L. Aiden.2011.
Quantitative analysis of culture using millionsof digitized books.
Science, 331(6014):176?182, Jan-uary.R.
Mihalcea and P. Edmonds, editors.
2004.
Proceed-ings of SENSEVAL-3, Association for ComputationalLinguistics Workshop, Barcelona, Spain.H.T.
Ng and H.B.
Lee.
1996.
Integrating multipleknowledge sources to disambiguate word sense: Anexamplar-based approach.
In Proceedings of the 34thAnnual Meeting of the Association for ComputationalLinguistics (ACL 1996), Santa Cruz.F.
Reali and T. Griffiths.
2010.
Words as alleles: con-necting language evolution with bayesian learners tomodels of genetic drift.
Proceedings of the Royal So-ciety, 277(1680):429?436.K.
Toutanova, D. Klein, C. Manning, and Y. Singer.2003.
Feature-rich part-of-speech tagging with acyclic dependency network.
In Proceedings of Hu-man Language Technology Conference (HLT-NAACL2003), Edmonton, Canada, May.X.
Wang and A. McCallum.
2006.
Topics over time: Anon-Markov continuous-time model of topical trends.In Conference on Knowledge Discovery and DataMining (KDD).C.
Wang, D. Blei, and D. Heckerman.
2008.
Continuoustime dynamic topic models.
In International Confer-ence on Machine Learning (ICML).D.
Wijaya and R. Yeniterzi.
2011.
Understanding se-mantic change of words over centuries.
In Proc.
of theWorkshop on Detecting and Exploiting Cultural Diver-sity on the Social Web (DETECT) 2011.263
