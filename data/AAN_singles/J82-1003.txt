From English to Logic:Context-Free Computation of"Conventional" Logical Translation 1Lenhart K. SchubertDepartment of Computing ScienceUniversity of AlbertaFrancis Je f f ry  Pel let ierDepartment of PhilosophyUniversity of AlbertaEdmonton, Canada T6G 2H1We describe an approach to parsing and logical translation that was inspired byGazdar's work on context-free grammar for English.
Each grammar rule consists of asyntactic part that specifies an acceptable fragment of a parse tree, and a semantic partthat specifies how the logical formulas corresponding to the constituents of the fragmentare to be combined to yield the formula for the fragment.
However, we have sought toreformulate Gazdar's semantic rules so as to obtain more or less 'conventional' logicaltranslations of English sentences, avoiding the interpretation of NPs as property sets andthe use of intensional functors other than certain propositional operators.
The reformulat-ed semantic rules often turn out to be slightly simpler than Gazdar's.
Moreover, by using asemantically ambiguous logical syntax for the preliminary translations, we can account forquantifier and coordinator scope ambiguities in syntactically unambiguous sentenceswithout recourse to multiple semantic rules, and are able to separate the disambiguationprocess from the operation of the parser-translator.
We have implemented simple recur-sive descent and left-corner parsers to demonstrate the practicality of our approach.1.
IntroductionOur ultimate objective is the design of a naturallanguage understanding system whose syntactic, se-mantic and pragmatic apabilities are encoded in aneasily comprehensible and extensible form.
In addi-tion, these encodings hould be capable of supportingefficient algorithms for parsing and comprehension.In our view, the achievement of the former objec-tive calls for a careful structural separation of the sub-systems that specify possible constituent structure(syntax), possible mappings from constituent structureto underlying logical form (part of semantics), andpossible mappings from logical form to deeper, unam-biguous representations a a function of discoursecontext and world knowledge (part of pragmatics andl Submitted August 1981; revised July 1982.inference).
This sort of view is now widely held, asevidenced by a recent panel discussion on parsingissues (Robinson 1981).
In the words of one of thepanelists,"I take it to be uncontroversial that, otherthings being equal, a homogenized system is lesspreferable on both practical and scientificgrounds than one that naturally decomposes.Practically, such a system is easier to build andmaintain, since the parts can be designed, devel-oped, and understood to a certain extent inisolation... Scientifically, a decomposable sys-tem is much more likely to provide insight intothe process of natural language comprehension,whether by machines or people."
(Kaplan 1981)The panelists also emphasized that structural decom-position by no means precludes interleaving or paral-Copyright 1982 by the Association for Computat ional  Linguistics.
Permission to copy without fee all or part of this material is grantedprovided that the copies are not made for direct commercial advantage and the Journal reference and this copyright notice are included onthe first page.
To copy otherwise, or to republish, requires a fee and/or  specific permission.0362-613X/82/010026-19501.0026 American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982Lenhart K. Schubert and Francis Jeffry Pelletier From English to Logiclelism of the processes that draw on the various kindsof linguistic and non-linguistic knowledge.Note that we are making a distinction between thelogical form that corresponds directly to surface struc-ture on the one hand, and an unambiguous deeperrepresentation on the other.
Indeed, at the level oflogical form our theory of logical translation admitsambiguities in all of the formal building blocks (terms,functions, predicates, connectives, and quantifiers), aswell as in the scopes of quantifiers and coordinators.For example, logical-form translations may containterms such as Mary2 and <the l  (little2 gir l3)>, ambi-guous between various referents (e.g., MARY5 andMARY17),  and quasi-predicates such as has3, good2,cold5, and recovers l, ambiguous between variousproper predicates (e.g., has3: OWNS1, AFFL ICTED-WITH .. .
.
; good2: V IRTUOUS,  GOOD-TAST ING .
.
.
.
;cold5: COLD1,  EMOTIONLESS .
.
.
.
; and recovers l :RE-COVERS1,  REGAINS .
.
.
.
).
In other words, wedo not regard the logical form of a sentence as fullydetermining its meaning - not even its 'l iteral' mean-ing; rather, its meaning is determined by its logicalform along with the context of its utterance.
Thus"She is becoming cold" might convey on one occasionthat Lady Godiva is beginning to feel cold, on anotherthat Queen Victoria is becoming emotionless, and on athird that Mount St. Helens is cooling off; but thelogical form does no more than specify the femininegender of the referent and its property of "becomingcold (in some sense) at the time of utterance".
Ourprimary concern in this paper will be with the semanticrules that define immediate logical form, although weattempt to define this form in a way that minimizesthe remaining ap to the deeper representation.All the experience gained within AI and linguisticssuggests that bridging this final gap will be very diffi-cult.
Some would take as their lesson that researchefforts should concentrate on the last, pragmatic phaseof comprehension, where 'the real problems' lie.
Webelieve on the contrary that the only way to make thepragmatic problems tractable is to have a precise con-ception of the constituent structure and logical form ofthe natural language input, in terms of which the prag-matic operations can in turn be precisely formulated.In AI research, the objectives of clarity and exten-sibility have often been sacrificed to immediate per-formance goals.
One reason for this may have beenthe need to establish the credibility of a relativelyyoung and controversial discipline.
In any case, thestate of linguistic theory until fairly recently left noreal alternatives.
The transformational grammarswhose study dominated theoretical linguistics seemed apoor prospect even for the limited goal of describingnatural language syntax, because of the subtlety oftransformational rules and supplementary devices suchas co-indexing procedures, filters and constraints onmovement,  and the complexity of their interactions.Moreover, the prospects for writing efficient transfor-mational parsers seemed poor, given that transforma-tional grammars can in principle generate all recursive-ly enumerable languages.
But most importantly, gen-erative grammarians developed syntactic theories moreor less independently of any semantic considerations,offering no guidance to AI researchers whose primaryobjective was to compute 'meaning representat ions'for natural language utterances.
Katz and Fodor 'smarkerese (Katz & Fodor 1963) was patently inade-quate as a meaning representation language from anAI point of view, and Generative Semantics (Lakoff1971) never did develop into a formal theory of therelation between surface form and meaning.Theoretical inguistics took an important new turnwith the work of Montague on the logic of English andlater expansions and variants of his theory (e.g., seeThomason 1974a, Partee 1976a, and Cresswell 1973).According to Montague grammar the correspondencebetween syntactic structure and logical form is muchsimpler than had generally been supposed: to eachlexeme there corresponds a logical term or functor andto each rule of syntactic composit ion there corre-sponds a structurally analogous emantic rule of logicalcomposition; this is the so-called rule-to-rule hypothe-sis \[Bach 1976\].
2 Furthermore, the translations of allconsituents of a particular syntactic category are as-signed formal meanings of the same set-theoretic type;for example, all NPs, be they names or definite orindefinite descriptions, are taken to denote propertysets.
Crucially, the formal semantics of the logicaltranslations produced by the semantic rules of Mo-ntague grammar accords by and large with intuitionsabout entailment, synonymy, ambiguity and other se-mantic phenomena.2 Interestingly enough, this linguistic hypothesis was anticipat-ed by Knuth 's  work on the semantics of attribute grammars (Knuth1968).
Schwind (1978) has applied Knuth's  insights to the devel-opment of a formal basis for question answering systems, anticipat-ing some of the work by Gazdar  and others on which our ownefforts are founded.There is also some similarity between the rule-to-rule hypothe-sis and the rule-based approach to the interpretation of syntacticstructures that emerged within AI during the 1960's and early 70's.The idea of pairing semantic rules with phrase structure rules was atthe heart of DEACON (Craig et al 1966), a system based on F.B.
Thompson's  proposal to formalize English by limiting its subjectmatter  to well-defined computer  memory structures (Thompson1966).
However,  DEACON's  semantic rules performed directsemantic evaluation of sorts (via computations over a data base)rather than constructing logical translations.
The systems of Wino-grad (1972) and Woods (1977) constructed input translations priorto evaluation, using semantic rules associated with particular syn-tactic structures.
However, these rules neither corresponded one-to-one to syntactic rules nor l imited interpretive operat ions tocomposit ion of logical expressions; for example, they incorporatedtests for selectional restrictions and other forms of inference, withunrestricted use of the computational power of LISP.American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 27Lenhart K. Schubert and Francis Jeffry Pelletier From English to LogicThe chief limitation of Montague's grammar wasthat it treated only very small, syntactically (thoughnot semantically) simple fragments of English, andefforts were soon under way to extend the fragments,in some cases by addition of a transformational com-ponent (Partee 1976b, Cooper & Parsons 1976).
Atthe same time, however, linguists dissatisfied withtransformational theory were beginning to developnon-transformational alternatives to traditional genera-tive grammars (e.g., Peters & Ritchie 1969, Bresnan1978, Lapointe 1977, Brame 1978, Langendoen1979).
A particularly promising theory that emergedfrom this development, and explicitly incorporatesMontague's approach to semantics, is the phrase struc-ture theory advanced by Gazdar and others (Gazdar1980, 1981, Gazdar, Pullum & Sag 1980, Gazdar &Sag 1980, Sag 1980, Gazdar, Klein, Pullum & Sag, toappear).
The theory covers a wide range of the syn-tactic phenomena that have exercised transformation-alists from Chomsky onward, including subcategoriza-tion, coordination, passivization, and unbounded e-pendencies uch as those occurring in topicalization,relative clause constructions and comparatives.
Yetthe grammar itself makes no use of transformations; itconsists entirely of phrase structure rules, with a node-admissibility rather than generative interpretation.
Forexample, the rule \[(S) (NP) (VP)\] states that a frag-ment with root S, left branch NP and right branch VPis an admissible fragment of a syntactic tree.
3 Suchphrase structure rules are easy to understand and per-mit the use of efficient context-free parsing methods.Moreover, the grammar ealizes the rule-to-rule hy-pothesis, pairing each syntactic rule with a Montague-like semantic rule that supplies the intensional logictranslation of the constituent admitted by the syntacticrule.It has long been assumed by transformationaliststhat linguistic generalizations cannot be adequatelycaptured in a grammar devoid of transformations.Gazdar refutes the assumption by using metagrammat-ical devices to achieve descriptive legance.
Thesedevices include rule-schemata (e.g., coordination sche-mata that yield the rules of coordinate structure for allcoordinators and all syntactic categories), andmetarules (e.g., a passive metarule that takes anytransitive-VP rule as 'input' and generates a corre-sponding passive-VP rule as 'output' by deleting the3 We use traditional category symbols in our exposition, occa-sionally followed by supplementary features, e.g., (V TRAN)  fortransitive verb.
Gazdar actually assumes a two-bar X system (e.g.,see Bresnan 1976, Jackendoff  1977) that distinguishes between X,,~ and X categories (e.g., ~, V, and V, equivalent o the traditionalS, VP and V respectively) and employs complex symbols whosefirst component specifies the 'number of bars' and whose secondcomponent supplies a feature bundle encoding syntactic category,subcategorization, and morphosyntact ic and morphological informa-tion.object NP from the input rule and appending an op-tional by-PP).
Although metarules resemble trans-formational rules, they map rules into rules rather thantrees into trees, leaving the grammar itself context-free.
Another key innovation is the use of categorieswith 'gaps', such as NP/PP, denoting a NP from whicha PP has been deleted (not necessarily at the top lev-el).
A simple metarule and a few rule schemata reused to introduce rules involving such derived categor-ies, elegantly capturing unbounded ependencies.The character of the syntactic theory will becomeclearer in Section 4, where we supply a sampling ofgrammatical rules (with our variants of the semanticrules), along with the basic metarule for passives andthe coordination schemata.
First, however, we wouldlike to motivate our attempt o reformulate Gazdar'ssemantic rules so as to yield 'conventional' ogicaltranslations (Section 2), and to explain the syntacticand semantic idiosyncrasies of our target logic(Section 3).By 'conventional' logics we mean first-order (andperhaps second-order) predicate logics, augmentedwith a lambda operator, necessity operator, proposi-tional attitude operators and perhaps other non-extensional propositional operators, and with a Kripke-style possible-worlds semantics (Hughes & Cresswell1968).
4 The logic employed by Montague in his firstformal fragment of English comes rather close to whatwe have in mind (Montague 1970a), while the inten-sional logics of the later fragments introduce the un-conventional features we hope to avoid (1970b,c).
Itis the treatment in these later fragments that is usuallyreferred to by the term "Montague grammar".
(For adetailed discussion of the distinction between conven-tional logics in the above sense and intensional logics,see Guenthner 1978).We should stress that it is semantics, not syntax,which is the crux of the distinction.
We shall takecertain liberties with conventional logical syntax, align-ing it more nearly with the surface structure; but thiswill not lead to major departures from conventionalsemantics.
For example, our syntax of terms allowssyntactically unfamiliar formulas uch as\[<alll man2> mortal3\].4 We admit predicate modifiers and some second-order predi-cate constants into our logical vocabulary, and may ult imately wantto employ a full-fledged second-order logic, in view of such sen-tences as "Every  good general has at least some of Napo leon 'squalit ies".
On the other hand,  we may pare down rather thanexpand the logical apparatus, opting for a logic that treats proper-ties, propositions and other intensional entities as f irst-order indi-viduals.
This type of treatment,  which avoids the unwanted identityof logically equivalent propositions, appears to be gaining currency(e.g., Fodor 1978, McCar thy  1979, Thomason 1980, Chierchia1981).
Some minor adjustments would be required in our rules oflogical translation.28 Amer ican Journal  of Computational Linguistics, Volume 8, Number  1, January-March 1982Lenhart K. Schubert and Francis Jeffry Pelletier From English to LogicBut the formula derives its interpretation from its sti-pulated logical equivalence to(alll x:\[x man2\])\[x mortal3\],which may in turn becomeVx\[\[x HUMAN\] => \[x MORTAL\]\] ,after disambiguation.
52.
Intensional and 'Conventional' TranslationsWe should emphasize at the outset that our objec-tive is not to impugn Montague grammar, but merelyto make the point that the choice between intensionaland conventional translations is as yet unclear.
Giventhat the conventional approach appears to have cer-tain advantages, it is worth finding out where it leads;but we are not irrevocably committed to this approach.Fortunately, the translation component of a parser fora Gazdar-style grammar is easily replaced.Montague grammarians assume that natural lan-guages closely resemble formal logical systems; morespecifically, they postulate a strict homomorphismfrom the syntactic categories and rules of a naturallanguage to the semantic ategories and rules requiredfor its formal interpretation.
This postulate has ledthem to an analysis of the logical content of naturallanguage sentences which differs in important respectsfrom the sorts of analyses traditionally employed byphilosophers of language (as well as linguists and AIresearchers, when they have explicitly concernedthemselves with logical content).The most obvious difference is that intensionallogic translations of natural language sentences con-form closely with the surface structure of those sen-tences, except for some re-ordering of phrases, theintroduction of brackets, variables and certain logicaloperators, and (perhaps) the reduction of idioms.
Forexample, since the constituent structure of " John lovesMary" is\[John \[loves Mary\]\],the intensional logic translation likewise isolates acomponent translating the VP "loves Mary",  compos-ing this VP-translation with the translation of " John"to give the sentence formula.
By contrast, a conven-tional translation will have the structure\[John loves Mary\],in which " John"  and "Mary"  combine with the verb atthe same level of constituent structure.In itself, this difference is not important.
It onlybecomes important when syntactic composition is as-sumed to correspond to function application in thesemantic domain.
This is done in Montague grammar5 We consistently use infix form (with the predicate followingits first argument) and square brackets for complete sententialformulas.by resort to the Schoenfinkel-Church treatment ofmany-place functions as one-place functions(Schoenfinkel 1924, Church 1941).
For example, thepredicate " loves" in the above sentence is interpretedas a one-place function that yields a one-place functionwhen applied to its argument (in this instance, whenapplied to the semantic value of "Mary",  it yields thefunction that is the semantic value of "loves Mary").The resultant function in turn yields a sentence valuewhen applied to its argument (in this instance, whenapplied to the semantic value of " John",  it yields theproposition expressed by " John loves Mary").
Thus, adyadic predicator like " loves" is no longer interpretedas a set of pairs of individuals (at each possible worldor index), but rather as a function into functions.Similarly a triadic predicator like "gives" is interpretedas a function into functions into functions.Moreover, the arguments of these functions are notindividuals, because NPs in general and names in par-ticular are assumed to denote property sets (or truthfunctions over properties) rather than individuals.
It iseasy to see how the postulate of syntactic-semantichomomorphism leads to this further retreat from tradi-tional semantics.
Consider Gazdar's top-level rule ofdeclarative sentence structure and meaning:<10, \[(S) (NP) (VP)\], (VP' NP" )>.The first element of this triple supplies the rule num-ber (which we have set to 10 for consistency with thesample grammar of Section 4), the second the syntac-tic rule and the third the semantic rule.
The semanticrule states that the intensional logic translation of theS-constituent is compounded of the VP-translation (asfunctor) and the NP-translation (as operand), wherethe latter is first to be prefixed with the intension op-erator A.
In general, a primed syntactic symbol de-notes the logical translation of the corresponding con-stituent, and a double-primed symbol the logical trans-lation prefixed with the intension operator (thus, NP"stands for ANP').For example, if the NP dominates " John"  and theVP dominates "loves Mary", then S' (the translationof S) is((loves' AMary') A John') .Similarly the translation of "Every boy loves Mary"comes out as((loves' AMary') A(every' boy' ) ) ,given suitable rules of NP and VP formation.
6 Notethe uniform treatment of NPs in the logical formulas,i.e., (every' boy ' )  is treated as being of the same se-mantic category as John' ,  namely the (unique) seman-6 The exact function of the intension operator need not con-cern us here.
Roughly speaking, it is used to bring meanings withinthe domain of discourse; e.g,, while an NP t denotes a property setat each index, the corresponding ANp~ denotes the entire NPintension (mapping from indices to property sets) at each index.American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 29Lenhart K. Schubert and Francis Jeffry Pelletier From English to Logictic category corresponding to the syntactic categoryNP.
What is the set-theoretic type of that category?Since (every v boy t) cannot be interpreted as denotingan individual (at least not without making the rules ofsemantic valuation for formulas depend on the struc-ture of the terms they contain), neither can John w.The solution is to regard NPs as denoting sets of prop-erties, where a property determines a set of individualsat each index, and VPs as sets of such property sets(or in functional terms, as truth functions over truthfunctions over properties).
Thus John v does not de-note an individual, but rather a set of properties,namely those which John has; (every w boy t) denotesthe set of properties hared by all boys, (a v boy w) theset of all properties possessed by at least one boy, andso on.
It is not hard to see that the interpretation ofVPs as sets of property sets then leads to the appro-priate truth conditions for sentences.
7With respect o our objective of building a compre-hensible, expandable natural language understandingsystem, the simplicity of Gazdar 's  semantic rules andtheir one-to-one correspondence to phrase structurerules is extremely attractive; however, the semantics ofthe intensional ogic translations, as sketched above,seems to us quite unnatural.Admittedly naturalness is partly a matter of famili-arity, and we are not about to fault Montague gram-mar for having novel features (as some writers do,e.g., Harman 1975).
But Montague's emantics is atvariance with pretheoretical intuitions as well as philo-sophical tradition, as Montague himself acknowledged(1970c:268).
Intuitively, names denote individuals(when they denote anything real), not sets of proper-ties of individuals; extensional transitive verbs expressrelations between pairs of individuals, not betweenpairs of property sets, and so on; and intuitively,quantif ied terms such as "everyone"  and "no-one"simply don't bear the same sort of relationship to ob-jects in the world as names, even though the evidencefor placing them in the same syntactic category isoverwhelming.
Such objections would carry no weightif the sole purpose of formal semantics were to pro-vide an explication of intuitions about truth and logicalconsequence, for in that area intensional ogic is re-markably successful.
But formal semantics hould alsodo justice to our intuitions about the relationship be-tween word and object, where those intuitions areclear - and intensional ogic seems at odds with someof the clearest of those intuitions.
8There is also a computational objection to inten-sional logic translations.
As indicated in our introduc-tory remarks, a natural language understanding systemmust be able to make inferences that relate the naturallanguage input to the system's tored knowledge anddiscourse model.
A great deal of work in AI  has fo-cused on inference during language understanding andon the organization of the base of stored knowledgeon which the comprehension process draws.
Almostall of this work has employed more or less convention-al logics for expressing the stored knowledge.
(Evensuch idiosyncratic formalisms as Schank's conceptualdepen~lency theory (Schank 1973) are much more akinto, say, first order modal logic than to any form ofintensional ogic - see Schubert 1976).
How are in-tensional logic formulas to be connected up withstored knowledge of this conventional type?One possible answer is that the stored knowledgeshould not be of the conventional type at all, butshould itself be expressed in intensional logic.
Howev-er, the history of automatic deduction suggests thathigher-order logics are significantly harder to mecha-nize than lower-order logics.
Developing efficientinference rules and strategies for intensional ogics,with their arbitrari ly complex types and their inten-sion, extension and lambda abstract ion operators inaddition to the usual modal operators, promises to bevery difficult indeed.Another possible answer is that the intensionallogic translations of input sentences hould be post-processed to yield translations expressed in the lower-order, more conventional logic of the system's knowl-edge base.
A difficulty with this answer is that dis-course inferences need to be computed 'on the fly' toguide syntactic hoices.
For example, in the sentences" John saw the bird without binoculars" and " John sawthe bird without tail feathers" the syntactic roles ofthe preposit ional phrases (i.e., whether they modify"saw" or "the bird") can only be determined by infer-ence.
One could uncouple inference from parsing bycomputing all possible parses and choosing among theresultant translations, but this would be cumbersomeand psychologically implausible at best.As a final remark on the disadvantages of inten-sional translations, we note that Montague grammarrelies heavily on meaning postulates to deliver simpleconsequences, uch asA boy smiles - There is a boy;7 This was the approach in Montague (1970b) and is adoptedin Gazdar (1981a).
In another, less commonly adopted approachNPs are still interpreted as sets of properties but VPs are interpret-ed simply as properties, the truth condition for a sentence beingthat the property denoted by the VP be in the set of propertiesdenoted by the NP (Montague 1970c, Cresswell  1973).
In otherwords, the NP is thought of as predicating something about the VP,rather than the other way around.8 Thomason reminds us that ".
.
.we should not forget thef irmest and most irrefragable kind of data with which a semantictheory must  cope.
The theory must  harmonize with the actualdenotations taken by the expressions of natural languages,.
.
.
",  butconf ines his further remarks to sentence denotat ions,  i.e., truthvalues (Thomason,  1974b:54).30 Amer ican Journal  of Computat iona l  Linguist ics,  Vo lume 8, Number  1, January-March 1982Lenhart K. Schubert and Francis Jeffry Pelletier From English to Logic(in this instance an extensionalizing postulate is re-quired for "smiles" - see Montague 1970c:263).
Aconventional approach dispensing with postulates ofthis type would be preferable.Having stated our misgivings about Montaguegrammar, we need to confront the evidence in its fav-our.
Are there compelling reasons for regarding sen-tential constituents as more or less directly and uni-formly interpretable?
In support of the affirmative,one can point out the simplicity and elegance of thisstrategy from a logical point of view.
More tellingly,one can cite its success record: it has made possiblefor the first time the formal characterization of non-trivial fragments of natural languages, with preciselydefined syntactic-semantic mappings; and as onewould hope, the formal semantics accounts for manycases of entailment, ambiguity, contradictoriness, andother semantic phenomena, including some of the sub-tlest arising from intensional locutions.Concerning the simplicity of the strategy, we notethat the connection between language and the worldcould be just as simple as Montague grammar wouldhave it, without being quite so direct.
Suppose, for amoment,  that people communicated in first-order logic.Then, to express that A1, Bill and Clyde were born andraised in New York, we would have to say, in effect,"Al was born in New York.
A1 was raised in NewYork.
Bill was born in New York .
.
.
.
Clyde wasraised in New York."
The pressure to condense suchredundant verbalizations would be great, and mightwell lead to 'overlay'  verbalizations in which listsenumerating the non-repeated constituents were fit-ted into a common sentential matrix.
In other words,it might lead to something like constituent coordina-tion.
But unlike simple constituents, coordinated con-stituents would not be meaningful in isolation; theywould realize their meaning only upon expansion ofthe embedding overlay verbalization into a set of first-order formulas.
Yet the connection between languageand the world would remain simple, assuming that thesyntactic relation between overlay verbalizations andtheir first-order translations were simple.
It would bequite pointless to reeonstrue the semantics of the en-hanced language so as to align the denotations ofnames with the denotations of coordinated names, forexample, as is done in Montague grammar.
Whileformally simplifying the semantic mapping function,such a move would lead to complex and counterintui-tive semantic types.The success of Montague grammar in characterizingfragments of natural languages, with a proper accountof logical relations such as entailment, is indeed strongevidence in its favour.
The only way of challengingthis success is to offer an equally simple, equally via-ble alternative.
In part, this paper is intended as amove in that direction.
While we do not explicitlydiscuss logical relations between the translations ofsentences, the kinds of translations produced by thesample grammar in Section 4 should at least providesome basis for discussion.
To the extent that thetranslations are of a conventional type (or easily con-verted to conventional form), the entailment relationsshould be more or less self-evident.There is one linguistic phenomenon,  however,which deserves preliminary comment since it might bethought to provide conclusive evidence in favour ofMontague grammar, or at least in favour of the inten-sional treatment of NPs.
This concerns intensionalverbs such as those in sentences (1) and (2), and per-haps (3):(1) John looks for a unicorn,(2) John imagines a unicorn,(3) John worships a unicorn.These sentences admit non-referential  readings withrespect to the NP "a unicorn", i.e., readings that donot entail the existence of a unicorn which is the refer-ent of the NP.
In intensional ogic the nonreferentialreading of the first sentence would simply be(( looks-for t ^(a v unicornt))  ^ Johnt) .The formal semantic analysis of this formula turns outjust as required; that is, its value can be " t rue"  or" fa lse"  (in a given possible world) irrespective ofwhether or not there are unicorns (in that world).
Thereferential reading is a little more complicated, butpresents no difficulties.It is the non-referential reading which is trouble-some for conventional logics.
For the first sentence,there seems to be only one conventional translation,viz.
,3x\[\[John looks-for x\] & \[x unicorn\]\],and of course, this is the referential reading.
There isno direct way of representing the non-referential read-ing, since the scope of a quantif ier in conventionallogics is always a sentence, never a term.The only possible escape from the difficulty lies intranslating intensional verbs as complex(non-atomic)logical expressions involving opaque sententialoperators.
9 The extant literature on this subject sup-ports the view that a satisfactory decomposition can-not be supplied in all cases (Montague 1970c, Bennett1974, Partee 1974, Dowty 1978, 1979, Dowty, Wall &Peters 1981).
A review of this literature would be outof place here; but we would like to indicate that thecase against decomposition (and hence against conven-tional translations) is not closed, by offering the fol-9 With regard to our system-building objectives, such resort tolexical decomposition is no liability: the need for some use of lexi-cal decomposition to obtain "canonical" representations that facili-tate inference is widely acknowledged by AI researchers, and car-ried to extremes by some (e.g., Wilks 1974, Schank 1975).American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 31Lenhart K. Schubert and Francis Jeffry Pelletier From English to Logiclowing paraphrases of the three sample sentences.
(Paraphrase (1)w is well-known, except perhaps for theparticular form of adverbial (Quine 1960, Bennett1974, Partee 1974), while (2) I - (3)  '' are original).These could be formalized within a conventional logi-cal framework allowing for non-truth-functional sen-tential operators:(1)'  John tries to find a unicorn (by looking around),(2) I John forms a mental description which couldapply to a unicorn,(3) 1 John acts, thinks and feels as if  he worshipped aunicorn.
(3)" John worships an entity which he believes to bea unicorn.In each case the operator that is the key to the trans-lation is italicized.
Note that the original ambiguity of(1) and (2) has been preserved, but can now be con-strued as a quantifier scope ambiguity in the conven-tional fashion.
In (3) 1 and (3)" the embedded"worships" is to be taken in a veridical sense thatentails the existence of the worshippee.
It is importantto understand that the translations corresponding to(3) 1 and (3)" would not be obtained directly by apply-ing the rules of the grammar to the original sentence;rather, they would be obtained by amending the directtranslation, which is patently false for a hearer whointerprets "worships" veridically and does not believein unicorns.
Thus we are presupposing a mechanismsimilar to that required to interpret metaphor on aGricean account (Grice 1975).
The notion of "acting,thinking and feeling as if..." may seem rather ad hoc,but appears to be applicable in a wide variety of caseswhere (arguably) non-intensional verbs of human ac-tion and attitude are used non-referentially, as perhapsin " John is communing with a spirit", " John is afraidof the boogie-man in the attic", or " John is trackingdown a sasquatch".
Formulation (3)" represents amore radical alternative, since it supplies an ac-ceptable interpretation of (3) only if the entity actuallyworshipped by John may be an 'imaginary unicorn'.But we may need to add imaginary entities to our'ontological stable' in any event, since entities may beexplicitly described as imaginary (fictitious, hypotheti-cal, supposed) and yet be freely referred to in ordinarydiscourse.
Also, sentences uch as " John frequentlydreams about a certain unicorn" (based on an examplein Dowty, Wall and Peters 1981) seem to be untrans-latable into any logic without recourse to imaginaryentities.
Our paraphrases of (3) have the importantadvantage of entailing that John has a specific unicornin mind, as intuitively required (in contrast with (1)and (2)).
This is not the case for the intensional logictranslation of (3) analogous to that of (1), a fact thatled Bennett to regard "worships" - correctly, we think- as extensional (Bennett 1974).In the light of these considerations, the convention-al approach to logical translation seems well worthpursuing.
The simplicity of the semantic rules towhich we are led encourages us in this pursuit.3.
Syntactic and Semantic PreliminariesThe logical-form syntax provides for the formationof simple terms such asJohn1, x,quantified terms such as<somel  man2>, <the l  (little2 boy3)>,simple predicate formulas such asman2, loves3, P4,compound predicate formulas such as(loves2 Mary3), ((loves2 Mary3) Johnl) ,\[ Johnl loves2 Mary3\],modified predicate formulas such as(bright3 red4), (passionately2 (loves3 Mary4)),and lambda abstracts uch as~x\[x shaves2 x\], Xy\[y expects2 \[y wins4\]\].Note the use of sharp angle brackets for quantif iedterms, square brackets or blunt angle brackets forcompound predicate formulas, and round brackets formodified predicate formulas.
(We explain the use ofsquare brackets and blunt angle brackets below.)
Wealso permit sentences (i.e., compound predicate formu-las with all arguments in place) as operands of senten-tial operators, as in\[\[John5 loves6 Mary7\] possible3\],\[Suel believes2 \[John5 loves5 Mary6\]\],\[\[ Johnl feverish3\] because4\[Johnl has5 malaria6\]\].For coordination of expressions of all types(quantifiers, terms, predicate formulas, modifiers, andsentential operators) we use sharp angle brackets andprefix form, as in<or2 manyl  few3>, <and2 Johnl  Bill3>,<and4 (hugs2 Mary3) (kisses5 Sue6)>.The resemblance of coordinated expressions to quanti-fied terms is intentional: in both cases the sharp anglebrackets signal the presence of an unscoped operator(viz., the first element in brackets) to be scoped lateron.Finally, we may want to admit second-order predi-cates with first-order predicate arguments, as in\[Fidol little-for3 dog5\], \[bluel colour4\],\[Xx\[x kissesl Mary2\] is-fun3\],though it remains to be seen whether such second-order predications adequately capture the meaning ofEnglish sentences involving implicit comparatives andnominalization.32 American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982Lenhart K. Schubert and Francis Jeffry Pelletier From English to LogicFuller explanations of several of the above featuresfollow.
In outline, we first delve a little further intothe syntax and semantics of predicate formulas; thenwe discuss the sources and significance of ambiguitiesin the formulas.Atomic sentences are of the form\[t n P t 1 ... tn_l\], (equivalently, (P t 1 ... tn)),where t I .
.
.
.
, t n are terms and P is a predicate con-stant, and the square brackets and blunt angle brack-ets distinguish infix and prefix syntax respectively.We regard this sentential form as equivalent o\[t n (...((e t 1) t 2) ... tn_ 1 )1,i.e., as obtained by applying an n-ary predicatesuccessively to n terms.
For example,\[John loves Mary\] = Cloves Mary John)=\[ John Cloves Mary)\] = ((loves Mary) John).
10As in Montague grammar, this predicate applicationsyntax helps to keep the rules of translation simple: inmost cases the translation of a phrase is just the com-position of the translations of its top-level constitu-ents.
However, we saw earlier that a functional inter-pretation of predicate application leads to the interpre-tation of predicates as telescoped function-valuedfunctions, whereas we wish to interpret predicates asn-ary relations (in each possible world) in the conven-tional way.We can satisfy this requirement by interpretingpredicate application not as function application, butrather as leftmost section of the associated relation atthe value of the given argument.
For example, let Vdenote the semantic valuation function (with a particu-lar interpretation and possible world understood) andletV(P) = {<a,b,c>, <a,b ,d>,  <e,f ,g>},V(x) = a, V(y) = b, and V(z) = d,where P is a triadic predicate symbol, x, y, and z areindividual constants or variables, and a, b .
.
.
.
.
g areelements of the individual domain D. ThenV((P x)) = {<b,c>,  <b,d>},V((P x y)) = V(((P x) y) = {<c>,  <d>},  andV(\[z V x y\]) = V((((P x) y) z)) = {<>}.We use the convention {<>} = true, {} = false.Lambda abstraction can be defined compatibly byVl(~,x~b) = {{d} X Vi (x :d)  (~b) I d ?
D},where I is an interpretation, I(x:d) is an interpretationidentical to I except that x denotes d, and X denotesCartesian product (and a particular possible world is10 We provide the double syntax for purely cosmetic reasons.In our use of the notation, expressions delimited by square bracketswill generally be complete open or closed sentences, while expres-sions delimited by blunt angle brackets will be ' incompletesentences' ,  i.e., predicates with one or more arguments missing (anddenoting a relation with adicity = number of missing arguments).understood).
It can be verified that the usual lambda-conversion identities hold, i.e.,()~x(P...x...)
t) = (P...t...), andP = )tx(P x) = ~,xhy(P x y) .
.
.
.
.where P is a predicate of any adicity (including null, ifwe use{<>}XA= A for any set A).As far as modified predicate formulas such as(bright3 red4) are concerned, we can interpret themodifiers as functions from n-ary relations to n-aryrelations (perhaps with n restricted to 1).We now turn to a consideration of the potentialsources of ambiguity in the formulas.
One source ofambiguity noted in the Introduction lies in the primi-tive logical symbols themselves, which may correspondambiguously to various proper logical symbols.
Theambiguous ymbols are obtained by the translator viathe first stage of a two-stage lexicon (and with the aidof morphological analysis, not discussed here).
Thisfirst stage merely distinguishes the formal logical rolesof a lexeme, supplying a distinct (but in general stillambiguous) symbol or compound expression for eachrole, along with syntactic information.
For example,the entry for " recover"  might distinguish (i) a predi-cate role with preliminary translation "recovers- f rom"and the syntactic information that this is a V admissi-ble in the rule that expands a VP as a V optionallyfollowed by a (PP from); (this information is suppliedvia the appropriate rule number); and (ii) a predicaterole with preliminary translation " recovers"  and thesyntactic information that  this is a V admissible in therule that expands a VP as a V followed by an NP.Having obtained a preliminary translation of a lex-eme in keeping with its apparent syntactic role, thetranslator affixes an index to it which has not yet beenused in the current sentence (or if the translation is acompound expression, it affixes the same index to allof its primitive symbols).
In this way indexed pre-liminary translations such as Mary l ,  good2, andrecovers3 are obtained.
For example, the verb trans-lation selected for "recovers"  in the sentence context" John recovers the sofa" would be recovers2,recovers-from2 being ruled out by the presence of theNP complement.
The second stage of the lexicon sup-plies alternative final translations of the first-stagesymbols, which in the case of " recovers"  might beRE-COVERS,  REGAINS,  and so on.
Naturally, theprocessors that choose among these final symbolswould have to draw on knowledge stored in the propo-sitional data base and in the representat ion of thediscourse context.A second source of ambiguity lies in quantif iedterms.
The sentenceSomeone loves every manAmerican Journal of Computational Linguistics, Volume 8, Number i ,  January-March 1982 33Lenhart K. Schubert and Francis Jeffry Pelletier From English to Logicillustrates a quantifier scope ambiguity arising from asyntactically unambiguous construction.
Its logical-form translation is\[<somel one2> loves3 <every4 man5>\],wherein the relative scopes of the quantifiers omeland every4 are ambiguous.
Quantified terms are in-tended to be 'extracted' in the postprocessing phase topositions left-adjacent to sentential formulas (whichmay already be prefixed with other quantifiers).
Anew variable is introduced into each extracted quanti-fier expression, the angle brackets are changed toround brackets, and the new variable is substituted forall occurrences of the extracted term.
(Thus the levelof extraction must be 'high' enough to encompass allof these occurrences.)
In the above formula, quantifierextraction reveals the implicit ambiguity, yielding ei-ther(somel x:\[x one2\])(every4 y:\[y man5\])\[x loves3 y\]or(every4 y:\[y man5\])(somel x:\[x one2\])\[x loves3 y\],depending on the order of extraction.Assuming that somel and every4 correspond tothe standard existential and universal quantifiers, thesetranslations could be further processed to yield~x\[\[x one2\] & Vy\[\[y man5\] => \[x loves3 y\]\]\] andVy\[\[y man5\] => 3x\[\[x one2\] & \[x loves3 y\]\]\].However, we may not implement his last conversionstep, since it cannot be carried out for all quantifiers.For example, as Cresswell remarks, "most A's are B's"cannot be rendered as "for most x, either x is not anA or x is a B" (Cresswell 1973: 137).
(Consider, forinstance, A = dog and B = beagle; then the last state-ment is true merely because most things are not dogs -irrespective of whether or not most dogs are in factbeagles.)
It appears from recent work by Goebel (toappear) that standard mechanical inference methodscan readily be extended to deal with formulas withrestricted quantifiers.A third source of ambiguity lies in coordinatedexpressions.
For example, the logical form of thesentence "Every man loves Peggy or Sue" is\[<everyl man2> loves3 <or5 Peggy4 Sue6>\],which is open to the readings(everyl x:\[x man2\])\[ \[x loves3 Peggy4\] or5\[x loves3 Sue6\]\]and\[(everyl x:\[x man2\])\[x loves3 Peggy4\]or5 (everyl x:\[x man2\])\[x loves3 Sue6\]\].The postprocessing steps required to scope coordina-tors are similar to those for quantifiers and are illus-trated in Section 4.1 lAn important constraint on the disambiguation ofthe basic symbols as well as quantified terms and coor-dinated expressions i that identical expressions (i.e.,expressions with identical constituent structure, includ-ing indices) must be identically disambiguated.
Forexample, "John shaves himself" and "John shavesJohn" translate respectively into\[Johnl hx\[x shaves2 x\]\] = \[Johnl shaves2 Johnl\],and\[Johnl shaves2 John3\].The stated constraint ensures that both occurrences ofJohnl in the first formula will ultimately be replacedby the same unambiguous constant.
Similarly"Someone shaves himself" and "Someone shavessomeone" translate initially into\[<somel one2> shaves3 <somel one2>\] and\[<somel one2> shaves3 <some4 one5>\]respectively, and these translations become(somel x:\[x one2\])\[x shaves3 x\] and(somel x:\[x one2\])(some4 y:\[y one5\])\[x shaves3 y\]respectively after quantifier extraction.
Note that thetwo occurrences of <somel one2> in the first formulaare extracted in unison and replaced by a commonvariable.
Indexing will be seen to play a similar role inthe distribution of coordinators that coordinate non-sentential constituents.By allowing the above types of ambiguities in thelogical form translations, we are able to separate theproblem of disambiguation from the problems of pars-ing and translation.
This is an important advantage,since disambiguation depends upon pragmatic factors.For example, "John admires John" may refer to twodistinct individuals or just to one (perhaps whimsical-ly), depending on such factors as whether more thanone individual named John has been mentioned in thecurrent context.
Examples involving ambiguities innouns, verbs, determiners, etc., are easily supplied.Similarly, the determination of relative quantifierscopes involves pragmatic onsiderations in addition tolevel of syntactic embedding and surface order.
Thisis true both for explicit quantifier scope ambiguitiessuch as in the sentence "Someone loves every man",and for scope ambiguities introduced by decomposi-tion, such as the decomposition of "seeks" intohyhx\[x tries \[x finds y\]\],as a result of which a sentence likeJohn seeks a unicornadmits the alternative translations3x\[\[x unicorn\] & \[John tries \[John finds x\]\]\], and\[John tries 3x\[\[x unicorn\] & \[John finds x\]\]\],neglecting indices.
It is simpler to produce a singleoutput which can then be subjected to pragmatic post-11 If f irst-order predicates are to be allowed as arguments ofsecond-order predicates, then quantifier and coordinator scoping ofthe following types must also be allowed: \[P.. .<Q R>... \]  -~ ~kx(Qy:\[y Rl)\[x P...y...\], <C P R> ~ ~kx\[\[x PI C \[x R\]\].34 American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982Lenhart K. Schubert and Francis Jeffry Pelletier From English to Logicprocessing to determine likely quantifier scopes, thanto generate all possible orderings and then to make apragmatic hoice among them.
Much the same can besaid about scoping of coordinators.We also note that a grammar designed to generateall possible unambiguous translations of English phras-es and sentences would have to supply multiple seman-tic rules for certain syntactic rules.
For example, noone semantic rule can translate a quantif ier-noun com-bination (rule 3 in Section 4) so as to deliver bothreadings of "Someone loves every man" upon combi-nation of the verb translation with the translations ofthe NPs.
Our use of an ambiguous logical form pre-serves the rule-to-rule hypothesis.4.
Sample GrammarOur syntactic rules do not depart significantly fromGazdar's.
The semantic rules formally resembleGazdar's  as well, but of course produce conventionallyinterpretable translations of the type described in thepreceding section.
As in Gazdar 's  semantic rules,constituent translations are denoted by primed catego-ry symbols such as NP '  and V ' .
The semantic rulesshow how to assemble such translations (along withthe occasional variable and lambda operator) to formthe translations of larger constituents.
The transla-tions of individual lexemes are obtained as describedabove.In operation, the translator generates the minimumnumber of brackets consistent with the notationalequivalences tated earlier.
For example, in assem-bling \ [NP'  VP ' \ ] ,  with NP '  = John l  and VP t =\[loves2 Mary3\], the result is\[ Johnl loves2 Mary3\],rather than\[ Johnl (loves2 Mary3)\].Also, in binding a variable with lambda, the translatorreplaces all occurrences of the variable with a previ-ously unused variable, thus minimizing the need forlater renaming.
Finally, it performs lambda conver-sions on the fly.
For example, the result of assembling\ [NP'  VP ' \ ]  with NP '  = Johnl  andVPV= ?~x\[x shaves2 x\],is\[ Johnl shaves2 Johnl \ ] .The rules that follow have been adapted from Gaz-dar (1981a).
Note that each rule that involves a lexi-cal category such as PN, N or V is accompanied by aspecification of the subset of lexical items of that cate-gory admissible in the rule.
This feature is particularlyimportant for verb subcategorization.
In addition,each rule is followed by (a) a sample phrase acceptedby the rule, (b) an indication of how the logical trans-lation of the phrase is obtained, and possibly (c) somewords of further explanation.<I, \[(NP) (PN)\], PN'>, PN(1) = \[John, Mary, New York .
.
.
.
\](a) Mary(b) wi th  PN' : Mary6, NP' becomes  Mary6.<2, \[(AN) (ADJP) (N)\], (ADJP' N')>, N(2) = \[boy, game, noise,(a) l i t t le boy(b) wi th ADJP' : l i t t le2,  N' = boy3,AN' becomes ( l i tt le2 boy3);(c) " l i t t le"  is taken as a pred icate  modi f ier .
\]2<3, \[(NP) (Q) (AN)\], <Q' AN'>>, Q(3) : \[a, the, all, many,(a) the l i t t le  boy(b) wi th  Q' = thel, AN' = ( l i tt le2 boy3),NP' -> <thel ( l i tt le2 boy3)>.<4, \[(PP to) (to) (NP)\], NP'>(a) to Mary(b) wi th NP' = Mary6, PP' -> Mary6;(c) PP verb complements  have the same mean ing  as their  NP,<5, \[(VP) (V)\], V'>, V(5) = {run, smile, d i sappear  .
.
.
.
\](a) smi les(b) wi th V' = smi les4,  VP' -> smi les4.?
.
.
\ ]...\]as per  Gazdar  (1981a).12 Siegel (1979) argues rather persuasively that measure adjec-tives, unlike genuine predicate modif iers such as "consummate" ,actually combine with terms.
For such adjectives we might employthe semantic rule ~.x\[\[x ADJP ' \ ]  & \[x N'\] \] ;  in the case of "little",we would use ADJP '  = (little-for P), where P is an indeterminatepredicate to be replaced pragmatically by a comparison-class predi-cate.
Thus the translation of "little boy" (neglecting indices)would be ~kx\[\[x little-for PI & \[x boyl\].American Journal of Computat iona l  Linguistics, Volume 8, Number 1, January-March 1982 35Lenhart K. Schubert and Francis Jeffry Pelletier From English to Logic<6, \[(VP) (V) (NP) (PP to)\], (V' PP' NP')>V(6) = {give, hand, tell .
.
.
.
\](a) gives Fido to Mary(b) with V' = gives4, NP' : Fido5, PP' : Mary6, VP' -> (gives4 Mary6 Fido5>.<7, \[(VP INF) (to) (VP BASE)\], VP'>(a) to give Fido to Mary(b) with VP' : (gives4 Mary6 Fido5>, the resultant  inf in i t ive has thesame meaning.<8, \[(VP) (V) (VP INF)\], Ax\[x V' \[x VP'\]\]>,V(8) : {want, expect, try .
.
.
.
\](a) wants to give Fido to Mary(b) with V' : wants2, VP' = {gives4 Mary6 Fido5\],VP' -> Ax3\[x3 wants2 \[x3 gives4 Mary6 Fido5\]\];(c) The formal lambda var iable x given in the semantic rule has been replaced bythe new var iable x3.
Two pairs of square brackets have been deleted, inaccordance with the s impl i f i cat ion rules stated earl ier.<9, \[(VP) (V) (NP) (VP INF)\], (V' \[NP' VP'\])>,V(9) = {want, expect, imagine .
.
.
.
\](a) wants Bi l l  to give Fido to Mary(b) with V' : wants2, NP' : Bill3, VP' = (gives~ Mary6 Fido5),VP' -> (wants2 {Bill3 gives4 Mary6 Fido5\]).<10, \[(S DECL) (NP) (VP)\], \[NP' VP' \ ]>(a) the l itt le boy smiles(b) with NP' = <the\] (l ittle2 boy3)> and VP' = smiles4, the result  isS' -> \[<thel (little2 boy3)> smiles4\].
After  pragmat ic  postprocess ingto extract  quant i f iers,  the result  might beS' = (thel x5:\[x5 (little2 boy3)\]) \[x5 smiles4\].Further postprocess ing  to determine referents and d isambiguate  operatorsand predicates might then yie ldS' = \[INDIVI7 SMILESl\],where INDIV17 is a (possibly new) logical  constant unambiguous ly  denot ingthe referent of (the\] x5:\[x5 (little2 boy3)\]) and SMILESl is an unambiguouslogical predicate.
13 If constant INDIV17 is new, i.e., if the context prov idedno referent for the def in i te  descr ipt ion,  a supplementary  assert ion like\[INDIV17 (LITTLE2 BOYI)\]would be added to the context representat ion.
(a)' John wants to give Fido to Mary(b)' with NP' = Johnl,VP' : lx3\[x3 wants2 \[x3 gives4 Mary6 FidoS\]\],S' -> \[Johnl wants2 \[Johnl gives4 Mary6 FidoS\]\];(c) ' Note that Johnl becomes the subject of both the main clause and theembedded (subordinate) clause.The reader will observe that we have more or lessfully traced the derivation and translation of the sen-tences "The little boy smiles" and "John wants to giveFido to Mary" in the course of the above examples.The resultant phrase structure trees, with rule numbersand translations indicated at each node, are shown inFigs.
1 and 2.13 Definite singular terms often serve as descriptions to be usedfor referent determination, and in such cases it is the name of thereferent, rather than the description itself, which is ult imatelywanted in the formula.36 American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982Lenhart K. Schubert and Francis Jef f ry Pel letier From English to Logicru le  1: NP'=PN'=dohnlPN'=dohnlIdohn?ru le  10: S' = \[NP' VP'\]= \[dohnl wants2 \[dohnl g ives4  Mary6 F ido5\ ] \ ]ru le  8: VP' = Xx\[x V' \[x VP ' \ ] I= ~x3\[x3 wants2 \[x3 g ives4 Mary6 F ido5\ ] \ ]  \(vp IN?
UV' =wants2Iwantsru le  7" (VP INF) '= (VP BASE)'= <gives4 Mary6 Fido5>/to (_VP BASE)ru le  6" VP' = ( V' PP' NP' )/~(g ives4  Mary6 Fido5>(V  BASE)V' -g ives4Ig iveru le  1" NP' =PN'= Fido5PN' =Fido5FidoCpp to)ru le  4 PP' =NP'= Mar't6 /ru le  1: NP'=PN'= Mary6IMaryFigure 1.
Phrase structure and translation of the sentence"John wants to give Fido to Mary".American Journal of Computat ional  Linguistics, Volume 8, Number 1, January-March 1982 37Lenhart K. Schubert and Francis Jeffry Pelletier From English to Logicru le= <the1Q '=the lItheQru le  10: S' = \[NP' VP' \]= \ [<the1  ( l i t t le2  boy3)> smi les4 \ ]3: NP'= <O' AN' > ru le  5: VP' =( l i t t le2  boy3)> = smi les4s rn i lesru le  2: AN'= (ADJP' N' )= ( l i t t le2  boy3)ru le  n: ADdP' = ADd' N' =boy3= l i t t le2  IboyADd'= i t t le2V,l i t t leFigure 2.
Phrase structure and translation of the sentence"The little boy smiles.
"38 American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982Lenhart K. Schubert and Francis Jeffry Pelletier From English to LogicAll of the above rules, as well as our versions ofthe remaining rules in Gazdar (1981a), are as simpleas the intensional logic versions or simpler.
For exam-ple, our semantic rule 8, i.e., Ax\[x V' \[x VP'\]\],  may becontrasted with the corresponding rule suggested byGazdar:XP{P Xx\[(V' A(Vp' XP(P x))) XP(P x)\]}.Here the lambda variable x, as in our formula, is usedto feed a common logical subject to V' (the transla-tion of the main verb) and to VP' (the translation ofthe embedded infinitive); the variables P and P, on theother hand, serve to ensure that the arguments of theV' and VP'  functions will be of the correct type.
Our'conventional' rule is simpler because it makes no suchuse of lambda abstraction for type-raising and dispens-es with the intension operator.Gazdar's approach to unbounded dependenciescarries over virtually unchanged and can be illustratedwith the sentenceTo Mary John wants to give Fido.Here the PP "to Mary" has been topicalized by ex-traction from " John wants to give Fido to Mary",leaving a PP 'gap' at the extraction site.
This 'gap' issyntactically embedded within the infinitive VP "togive Fido", within the main VP "wants to give Fido",and at the highest level, within the sentence " Johnwants to give Fido".
In general, the analysis of un-bounded dependencies requires derived rules for propa-gating 'gaps' from level to level and linking rules forcreating and filling them.
The linking rules are ob-tained from the correspondingly numbered basic rulesby means of the metarule\ [AXCY\ ]  ==> \ [A /BXC/BY\ ] ,where A, B and C may be any basic (i.e., non-slash)syntactic categories uch that C can dominate B, andX, Y may be any sequences (possibly empty) of bas-ic categories.
The linking rules for topicalization areobtained from the rule schemata<I I, \[B/B t\] , h>, and<12, \[(S) B (S)/B\], <AhS' B')>,where B ranges over all basic phrasal categories, and tis a dummy element (trace).
The first of these sche-mata introduces the free variable h as the translationof the gap, while the second lambda-abstracts on hand then supplies B' as the value of the lambda varia-ble, thus 'filling the gap' at the sentence level.
Atsyntactic nodes intermediate between those admittedby schemata 11 and 12, the B-gap is transmitted byderived rules and h is still free.Of the following rules, 6, 8, and 10 are the particu-lar derived rules required to propagate the PP-gap inour example and 11 and 12 the particular linking rulesthat create and fill it:<11, \[(PP to)/(PP to)(a) t(b) PP' -> ht\], h><6, \[(VP)/(PP to) (V) (NP) (PP to)/(PP to)\], (V' PP' NP')>(a) give Fido(b) with V' : gives5, NP' : Fido6, PP' = h,VP' -> (gives5 h Fido6)(c) Note that the semantic rule is unchanged.<8, \[(VP)/(PP to) (V) (VP INF)/(PP to)\], Ax\[x V'(a) wants to give Fido(b) with V' = wants3, VP' = (gives5 h Fido6),VP' -> Ax4\[x4 wants3 \[x4 gives5 h Fido6\]\]\[x VP' \ ] \ ]><10, \[(S)/(PP to) (NP) (VP)/(PP to)\], \[NP' VP'\]>(a) John wants to give Fido(b) with NP' : John2,VP' = Ax4\[x4 wants3 Ix4 gives5 h Fido6\]\],S' -> \[John2 wants3 \[John2 gives5 h Fido6\]\]<12,(a)(b)(c)\[(S) (PP to) (S)/(PP to)\], (AhS' PP')>To Mary John wants to give FidoWith S' as in 10 (b) above and PP' : Maryl,S' -> \[John2 wants3 \[John2 gives5 Maryl Fido6\] \] .This translat ion is logical ly indist inguishable from thetranslat ion of the untopica l ized sentence.
However, thefront ing of "to Mary" has left a pragmat ic  trace: theAmerican Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 39Lenhart K. Schubert and Francis Jeffry Pelletier From English to Logiccorresponding argument Maryl has the lowest index, lowerthan that of the subject translat ion John2 (assuming thatsymbols are indexed in the order of occurrence of thelexical items they translate).
In subsequent pragmat icprocessing, this feature could be used to detect the specialsal ience of Maryl, without re-examinat ion of the superf ic ia lsentence form.Another example of a sentence that can be ana-lyzed by such methods, using relative clause rules simi-lar to those for topicalization, isEvery dog Mary wants to buy is small.The rules analyze "Mary wants to buy" as an S/NPwith translation\[Mary wants \[Mary buys h\]\],neglecting indices.
A further ule reduces the S/NP toan R (relative clause), and its semantic part abstractson h to yield the predicateR' = Xh\[Mary wants \[Mary buys h\]\]as the translation of the relative clause.
The rules forNPs can be formulated in such a way that "every dog"will be translated as<every kx\[\[x dog\] & \[x R\]\]>where R is a free predicate variable that is replaced bythe translation of the relative clause when the NP-Rrule<13, \[(NP) (NP) (R)\], <XRNP' R '>>is applied (cf., Gazdar 1981b; we have ignored multi-ple relative clauses).
The resulting NP translation is<every hx\[\[x dog\] & \[Mary wants\[Mary buys x\]\]\]>.The translation of the complete sentence, after extrac-tion of the quantifier and conversion of the constrainton the universally quantified variable to an implicativeantecedent, would be?y\[\[\[y dog\] & \[Mary wants \[Mary buys y\]\]\]=> \[y (small P)\]\],where P is an undetermined predicate (= dog, in theabsence of contrary contextual information).As a further illustration of Gazdar's approach andhow easily it is adapted to our purposes, we considerhis metarule for passives:<\[(VP)(V TRAN) (NP) X\], (St NP")> ==><\[(VP PASS) (V) X {(PP by)}\],~,p((~r p) pp")>;i.e., "for every active VP rule that expands VP as atransitive verb followed by NP, there is to be a passiveVP rule that expands VP as V followed by what, ifanything, followed the NP in the active VP rule, fol-lowed optionally by a by-PP" (Gazdar 1981a).
In theoriginal and resultant semantic rules, (~" ...) representsthe original rule matrix in which NP" is embedded;thus (~r p) is the result of substituting the lambdavariable P (which varies over NP intensions) for NP"in the original rule.
Intuitively, the lambda variable'reserves' the NP" argument position for later bindingby the subject of the passive sentence.
It can be seenthat the metarule will generate a passive VP rule cor-responding to our rule 6 which will account for sen-tences such as "Fido was given to Mary by John".Moreover, if we introduce a ditransitive rule<14, \[ (VP) (V TRAN) (NP) (NP) \] ,(V' NP' NP')>I4to allow for sentences such as "John gave Mary Fido",the metarule will generate a passive VP rule that ac-counts for "Mary was given Fido by John", in whichthe indirect rather than direct object has been turnedinto the sentence subject.The only change needed for our purposes is thereplacement of the property variable P introduced bythe metarule by an individual variable x:...(~r NP' ) .
.
.
.
.
> ...hx((~ r x) PP' )...Once the subject NP of the sentence is supplied viarule 10, x is replaced by the translation of that NPupon lambda conversion.Finally in this section, we shall briefly considercoordination.
Gazdar has supplied general coordina-tion rule schemata long with a cross-categorical se-mantics that assigns appropriate formal meanings tocoordinate structures of any category (Gazdar 1980b).Like Gazdar's rules, our rules generate logical-formtranslations of coordinated constituents such as<and John Bill>, <or many few>,<and (hugs Mary) (kisses Sue)>,echoing the surface forms.
However, it should beclear from our discussion in Section 2 that direct inter-pretation of expressions translating, say, coordinatedNPs or VPs is not compatible with our conventionalconception of formal semantics.
For example, no for-mal semantic value is assigned directly to the coordi-nated term in the formula\[<and John Bill> loves Mary\].Rather, interpretation is deferred until the pragmaticprocessor has extracted the coordinator from the em-bedding sentence (much as in the case of quantified14 In the computational version of the semantic rules, primedsymbols are actually represented as numbers giving the positions ofthe corresponding constituents, e.g., (1 2 3) in rule 14.
Thus noambiguity can arise.40 American Journal of Computat iona l  Linguistics, Volume 8, Number 1, January-March 1982Lenhart K. Schubert and Francis Jeffry Pelletier From English to Logicterms) and distributed the coordinated terms overduplicate copies of that sentence, yielding\[\[John loves Mary\] and \[Bill loves Mary\]\].We adopt the following coordination schematawithout change.
The superscript denotes sequences oflength > 1 of the superscripted element.
The schema-ta are accompanied by examples of phrases they admit,along with (unindexed) translations.
The bracketingin (a) and (a)' indicates syntactic structure.<15, \[(A ~) (~) (A)\], A'>,where A is any syntact ic category and ~ E {and, or\](a) and admires(b) admires(a)' or Mary(b)' Mary<16, \[(A) (A)+ (A ~) \ ] ,  <~' A 'A ' .
.
.A '>>(a) loves \[and admires\](b) <and loves admires>(a)' \[Fido Kim\] \[or Mary\](b)' <or Fido Kim Mary><17, \[(A) (A) (A ~)+\ ] ,  <~' A 'A ' .
.
.A '>>(a) Fido \[\[or Kim\] \[or Mary\]\](b) <or Fido Kim Mary>The order in which coordinators are extracted anddistributed is a matter of pragmatic choice.
However,a crucial constraint is that multiple occurrences of aparticular coordinated expression (with particular ind-ices) must be extracted and distributed in a singleoperation, at the level of a sentential formula whosescope encompasses all of those occurrences (much asin the case of quantifier extraction).
The followingexamples illustrate this process.
(a) John loves and admires Fido or Kim(b) \[Johnl <and3 loves2 admires4> <or6 Fido5 Kim7>\] ->\[\[Johnl loves2 <or6 Fido5 Kim7>\] and3\[Johnl admires4 <or6 Fido5 Kim7>\]\] ->\[\[\[Johnl loves2 Fido5\] and3\[Johnl admires4 Fido5\]\] or6\[\[Johnl loves2 Kim7\] and3\[Johnl admires4 Kim7\]\]\].
(c) Note that once the and3-conjunct ion has been chosen for init ialextract ion and distr ibut ion,  the s imultaneous extract ion andd istr ibut ion of both occurrences of the or6-d is junct ion at thehighest sentential  level is compulsory.
The resultant  formulaexpresses the sense of "John loves and admires Fido or lovesand admires Kim".
Init ial  extract ion of the or6-d is junct ionwould have led to the (implausible) reading "John loves Fido orKim and admires Fido or Kim" (which is true even if John lovesonly Fido and admires only Kim).
(a) ' All men want to marry Peggy or Sue(b)' \[<alll man2> wants3 \[<alll man2> marr ies4 <or6 Peggy5 Sue7>\] \ ] ->(alll x: \[x man2\]) Ix wants3 \[x marr ies4 <or6 Peggy5 Sue7>\]\] ->(alll x: \[x man2\]) \[x wants3\[\[x marr ies4 Peggy5\] or6 \[x marr ies4 Sue7\]\]\].
(c) ' In the second step above, the coordinator  or6 might insteadhave been raised to the second highest sentent ia l  level, y ie ld ing(alll x: \[x man2\]) \[Ix wants3 Ix marr ies4 Peggy5\]\] or6\[x wants3 \[x marr ies4 Sue7\]\]\],or to the highest  sentent ia l  level, y ie ld ingAmerican Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 41Lenhart K. Schubert and Francis Jef f ry Pel letier From English to Logic\[(allq x:\[x man2\]) \[x wants3 \[x marr ies4 Peggy5\]\] or6(alll x: \[x man2\]) \[x wants3 \[x marr ies4 Sue7\]\]\].The three readings are logical ly d ist inct  and all are quitep lausib le (in the absence of addit ional  context).
The readercan ver i fy that the first and second readings, but not thethird, could have been obtained by extract ing the coordinatorfirst and the quant i f ier  second.Finally, we should remark that the distributive rulesare not appropriate for the group reading of coordi-nate structures in sentences uch asJohn and Mary carried the sofa (together).We envisage a mereological interpretation in whichJohn and Mary together comprise a two-componententity.
However,  we refrain from introducing a logicalsyntax for such entities here (but see the treatment ofplurals in Schubert, 1982).5.
ParsingPhrase structure grammars are relatively easy toparse.
The most advanced parser for Gazdar-stylegrammars that we are aware of is Thompson's  chart-parser (Thompson 1981), which provides for slashcategories and coordination, but does not (as of thiswriting) generate logical translations.
We have imple-mented two small parser-translators for preliminaryexperimentation, one written in SNOBOL and theother in MACLISP.
The former uses a recursive de-scent algorithm and generates intensional logic transla-tions.
The latter is a ' left corner'  parser that uses ourreformulated semantic rules to generate conventionaltranslations.
It begins by finding a sequence of left-most phrase-structure-rule branches that lead from thefirst word upward to the sentence node.
(e.g., Mary-~ PN -~ NP -~ S).
The remaining branches of thephrase structure rules thus selected form a "front ier"of expectations.
Next a similar initial-unit sequence isfound to connect the second word of the sentence tothe lowest-level (most immediate) expectation, and soon.
There is provision for the definition and use ofsystems of features, although we find that the parserneeds to do very little feature checking to stay on theright syntactic track.
Neither parser at present han-dles slash categories and coordination (although theycould be handled inefficiently by resort to closure ofthe grammar under metarules and rule schemata).
Ex-traction of quantif iers from the logical-form transla-tions is at present based on the level of syntactic em-bedding and left-to-r ight order alone, and no otherform of postprocessing is attempted.l  515 Since submission of this paper for publication, we havebecome aware of several additional papers on parser-translatorssimilar to ours.
One is by Rosenschein & Shieber (1982), anotherby Gawron et al (1982); in conception these are based quitedirectly on the generalized phrase structure grammar of Gazdar andhis collaborators, and use reeursive descent parsers.
A relatedProlog-based approach is described by McCord (1981, 1982).It has been gratifyingly easy to write these parser-translators, confirming us in the conviction thatGazdar-sty le grammars hold great promise for thedesign of natural language understanding systems.
Itis particularly noteworthy that we found the design ofthe translator component  an almost trivial task; nomodification of this component will be required evenwhen the parser is expanded to handle slash categoriesand coordination directly.
Encouraged by these re-suits, we have begun to build a full-scale left-cornerparser.
A morphological analyzer that can work witharbitrary sets of formal affix rules is partially imple-mented; this work, as well as some ideas on the con-ventional translation of negative adjective prefixes,plurals, and tense/aspect  structure, is reported inSchubert (1982).6.
Concluding RemarksFrom the point of view of theoretical and com-putational inguistics, Gazdar 's  approach to grammaroffers profound advantages over traditional ap-proaches: it dispenses with transformations withoutloss of insight, offers large linguistic coverage, andcouples simple, semantical ly wel l -motivated rules oftranslation to the syntactic rules.We have attempted to show that the advantages ofGazdar 's  approach to grammar can be secured withoutcommitment  o an intensional target logic for thetranslations of natural language sentences.
To moti-vate this endeavour,  we have argued that there arephilosophical and practical reasons for preferr ing aconventional target logic, and that there are as yet nocompelling reasons for abandoning such logics in fav-our of intensional ones.
More concretely, we haveshown how to reformulate Gazdar 's  semantic rulesto yield conventional translations, and have brieflydescribed some extant PSG parsers, including one thatis capable of parsing and translating in accordancewith the reformulated Gazdar grammar (minus metal-inguistic constructs).We believe that a parser- interpreter of this typewill prove very useful as the first stage of a naturallanguage understanding system.
Since the grammarrules are expressed in a concise, individually compre-hensible form, such a system will be easy to expandindefinitely.
The assignment of a well-defined logicalform to input sentences, compatible with favouredknowledge representation formalisms, should help to42 American Journal  of Computational Linguistics, Vo lume 8, Number 1, January-March 1982Lenhart K. Schubert and Francis Jeffry Pelletier From English to Logicbr ing  a measure  of  p rec is ion  and  c lar i ty  to  the  ra thermurky  area  of  natura l  language in terpretat ion  by  ma-ch ine .AcknowledgementsThe authors  are  indebted  to  Ivan  Sag fo r  a ser ies  ofvery  s t imu la t ing  seminars  he ld  by  h im at the  Un ivers i -ty of  A lber ta  on  his l ingu is t i c  research ,  and  va luab lefo l low-up  d iscuss ions .
The  he lp fu l  comments  of  there ferees  and  of  Lot f i  Zadeh are  a lso  apprec ia ted .
Theresearch  was  suppor ted  in par t  by  NSERC Operat ingGrants  A8818 and  A2252;  p re l iminary  work  on  thele f t -corner  parser  was  car r ied  out  by  one  of  the  au-thors  (LKS)  under  an  A lexander  von  Humboldt  fe l -l owsh ip  in 1978-79 .ReferencesBach, E. 1976 An extension of classical transformational gram-mar.
Mimeo, Univ.
of Massachusetts, Amherst, MA.Bartsch, R. 1976 The Grammar of Adverbials.
North-Holland,Amsterdam.Bennett, M. 1974 Some extensions of a Montague fragment ofEnglish.
Ph.D. dissertation, UCLA; available from the IndianaUniversity Linguistics Club.Brame, M.K.
1978 Base Generated Syntax.
Noit Amrofer, Seattle,WA.Bresnan, J.W.
1976 On the form and functioning of transforma-tions.
Linguistic Inquiry 7 3-40.Bresnan, J.W.
1978 A realistic transformational grammar.
InHalle, M., Bresnan, J.W., and Miller, G.A., Ed., LinguisticTheory and Psychological Reality MIT Press, Cambridge, MA.Chierchia, G. 1981 Nominalization and Montague grammar.
Asemantics without types for natural languages.
MS, Dept.
ofLinguistics, Univ.
of Massachusetts, Amherst, MA.Church, A.
1941 The Calculi of Lambda Conversion.
PrincetonUniv.
Press, Princeton, NJ.Cooper, R., and Parsons, T. 1976 Montague grammar, generativesemantics and interpretive semantics.
In Partee 1976a, 311-362.Craig, J.A., Berezner, S.C., Carney, H.C., and Longyear, C.R.1966 DEACON: Direct English access and control.
Fall JointComp.
Conf., Nov. 7-10, San Francisco, CA, AFIPS Conf.Proc.
vol.
29.
Spartan Books, Washington, D.C.: 365-380.Cresswell, M.J. 1973 Logics and Languages.
Methuen, London.Dowty, D.R.
1978 A guide to Montague's PTQ.
Indiana Univ.Linguistics Club, Bloomington, IN.Dowty, D.R.
1979 Word Meaning and Montague Grammar: TheSemantics of Verbs and Times in Generative Semantics and inMontague's PTQ.
D. Reidel, Dortrecht.Dowty, D.R., Wall, R., and Peters, S. 1981.
An Introduction toMontague Semantics.
D. Reidel, Dortrecht.Fodor, J.A.
1978 Propositional attitudes.
The Monist 61, 501-523.Gawron, J.M., King, J.J., Lamping, J., Loebner, E.E., Paulson, E.A., Pullum, G.K., Sag, I.A., and Wasow, T.A.
1982 ProcessingEnglish with a generalized phrase structure grammar.
CLS-82-5, Comp.
Science Lab.
Tech.
Note Series, Hewlett Packard,Palo Alto, CA.
Presented at the 20th Ann.
Meet.
of the Assoc.for Computational Linguistics, June 16-18, Univ.
of Toronto,Toronto, Ont.Gazdar, G. 1980a A phrase structure syntax for comparativeclauses.
Glot-Lexical Grammar 165-179.Gazdar, G. 1980b A cross-categorical semantics for coordinationLinguistics and Philosophy 3, 407-409.Gazdar, G. 1981a Phrase structure grammar.
To appear in Jacob-son, P. and Pullum, G.K., Ed., The Nature of  SyntacticRepresentation.
D Reidel, Dortrecht.Gazdar, G. 1981b Unbounded ependencies and coordinate struc-?
ture.
Linguistic Inquiry 12.2.Gazdar, G., Klein, E., Pullum, G. K., and Sag, I. to appear Eng-lish Syntax.Gazdar, G., Pullum, G.K., and Sag, I.
1980 A phrase structuregrammar of the English auxiliary system.
Unpublished paper.A slightly different version entitled "Auxiliaries and relatedphenomena in a restricted theory of grammar" is available fromIndiana Univ.
Linguistics Club; to appear as "Auxiliaries andrelated phenomena" in Language.Gazdar, G. and Sag, I.
1980 Passive and reflexives in phrasestructure grammar.
In Groenendijk, J., Janssen, T., and Stok-hof, M., Ed., Formal Methods in the Study of Language, Proc.
3rdAmsterdam Coll., March 25-28, 1980.
Mathematical CentreTracts, Amsterdam.Goebel, R. 1982 Forthcoming Ph.D. thesis, Dept.
of ComputerScience, Univ.
of British Columbia, Vancouver, B.C.Grice, H.P.
1975 Logic and conversation.
In Davidson, D. andHarman, G., Ed., The Logic of Grammar.
Dickenson, Encino,CA: 64-75.Guenthner, F. 1978 Systems of intensional logic and the semanticsof natural language.
In Guenther, F. and Rohrer, C., Ed.,Studies in Formal Semantics.
North-Holland, Amsterdam: 41-74.Harman, G. 1975 Logical form.
In Davidson, D. and Harman, G.,Ed., The Logic of Grammar.
Dickenson, Encino, CA: 289-307.Hughes, G.E.
and Cresswell, M.J. 1968 An Introduction to ModalLogic.
Methuen, London.Jackendoff, R. 1977 X Syntax: A Study of Phrase Structure.
MITPress, Cambridge, MA.Kaplan, R.M.
(panelist) 1981 A view of parsing.
Proc.
19th Ann.Meet.
of the Assoc.
for Computational Linguistics, June 29 - July1.
Stanford Univ., Stanford, CA, 103-104.Katz, J., and Fodor, J.A.
1963 The structure of a semantic theory.Language 39, 170-210.Knuth, D.E.
1968 Semantics of context-free languages.
Mathemat-ical Systems Theory 2, 127-145.Lakoff, G. 1971 On generative semantics.
In Steinberg, D.D.
andJakobvitz, L.A., Ed., Semantics: An Interdisciplinary Reader inPhilosophy, Linguistics and Psychology.
Cambridge Univ.
Press,New York: 232-296.Langendoen, T. 1979 On the assignment of constituent structuresto the sentences generated by a transformational grammar.
CityUniv.
of New York Forum.
New York, NY.Lapointe, S. 1977 Recursiveness and deletion.
Linguistic Analysis3, 227-266.McCarthy, J.
1979 First-order theories of individual concepts andpropositions.
In Michie, D., Ed., Expert Systems in the MicroElectronic Age.
Edinburgh Univ.
Press, Edinburgh: 271-287.McCord, M.C.
1981 Foealizers, the scoping problem, and seman-tic interpretation rules in logic grammars.
Tech.
Rep. No.81-81.
Univ.
of Kentucky, Lexington, KY. To appear in Proc.of the Int.
Workshop on Logic Programming for Expert Systems,Logicon, Woodland Hills, CA, Aug. 1981.McCord, M.C.
1982 Using slots and modifiers in logic grammarsfor natural anguage.
Artificial Intelligence 18, 327-367.Montague, R. 1970a English as a formal language.
In Thomason1974a, 188-221.Montague, R. 1970b Universal grammar.
In Thomason 1974a,222-246.Montague, R. 1970c The proper treatment of quantification inordinary English.
In Thomason 1974a, 247-270.American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982 43Lenhart K. Schubert and Francis Jeffry Pelletier From English to LogicPartee, B.H.
1974 Opacity and scope.
In Munitz, M.K., andUnger, P.K., Ed., Semantics and Philosophy.
New York Univ.Press, New York: 81-101.Partee, B.H., Ed.
1976a Montague Grammar.
Academic Press,New York.Partee, B.H.
1976b Some transformational extensions of Montaguegrammar.
InPartee 1976a, 51-76.Peters, P.S., and Ritchie, R.W.
1969 Context-sensitive immediateconstituent analysis: context-free languages revisited.
In FirstAnn.
Symp.
on Theory of Computing, ACM, New York, 1-8.Also in Math.
Systems Theory 6 (1973) 324-333.Quine, W.v.O.
1960 Word and Object.
MIT Press, Cambridge,MA.Robinson, J.J.
(chr.)
1981 Panel: perspectives on parsing issues.Proc.
19th Ann.
Meet.
of the Assoc.
for Computational Linguistics,June 29-July 1, Stanford Univ., Stanford, CA, 95-106.Rosenschein, S.J., and Shieber, S.M.
1982 Translating English intological form.
Presented at the 20th Ann.
Meet.
of the Assoc.for Computational Linguistics, June 16-18, Univ.
of Toronto,Toronto, Ont.Sag, I.
1980 A semantic theory of NP-movement dependencies.To appear in Jacobson, P. and Pullum, G.K., Ed., The Nature ofSyntactic Representation.
D. Reidel, Dortrecht.Schank, R.C.
1973 Identification of conceptualizations underlyingnatural anguage.
In Schank, R.C.
and Colby, K.M., Ed., Com-puter Models of Thought and Language.
W.H.
Freeman, SanFrancisco: 187-247.Schank, R.C.
1975 The primitive ACTs of conceptual dependen-cy.
In Advance Papers of Theoretical Issues in Natural LanguageProcessing Workshop, June 10-13, MIT, Cambridge, MA, 34-37.Schoenfinkel, M. 1924 Ueber die Bausteine der mathematischenLogik.
Math.
Annalen 92, 305-316.Schubert, L.K.
1976 Extending the expressive power of semanticnetworks.
Artificial Intelligence 7, 163-198.Schubert, L.K.
1982 An approach to the syntax and semantics ofaffixes in 'conventionalized' phrase structure grammar.
Proc.
ofthe 4th Biennial Conf.
of the Can.
Soc.
for Computational Studiesof Intelligence (CSCSI/SCEIO), 17-19 May 1982, Univ.
ofSaskatchewan, Saskatoon, Sask.
: 189-195.Schwind, C. 1978a A formalism for the description of questionanswering systems.
In Bolc, L., Ed., Natural Language Commu-nication with Computers.
Springer-Verlag, Berlin, Heidelberg &New York: 1-48.Schwind, C. 1978b The translation of natural anguage texts intostate logic formulae.
Tech.
Rep. TUM-INFO-7806, TechnischeUniv.
Muenchen, available from Bibliothek des FachbereichsMathematik, Technische Univ.
Muenchen, D-8000 Muenchen2, W. Germany.Siegel, M.E.A.
1979 Measure adjectives in Montague grammar.In Davis, S., and Mithun, M., Eds., Linguistics, Philosophy, andMontague Grammar.
Univ.
of Texas Press, Austin, TX: 223-262.Thomason, R.H. ed.
1974a Formal Philosophy: Selected Papers ofRichard Montague.
Yale Univ.
Press, New Haven, CT.Thomason, R.H. 1974b Introduction to Thomason 1974a, 1-69.Thomason, R.H. 1980 A model theory for propositional ttitudes.Linguistics and Philosophy 4, 47-70.Thompson, F.B.
1966 English for the computer.
Fall Joint Comp.Conf., Nov. 7-10, San Francisco, CA.
AFIPS Conf.
Proc.
Vol.29, Spartan Books, Washington, D.C., 349-356.Thompson, H. 1981 Chart parsing and rule schemata in PSG.Proc.
19th Ann.
Meet.
of the Assoc.
for ComputationalLinguistics, June 29-July 1, Stanford Univ., Stanford, CA: 167-172.Wilks, Y.
1974 An artificial intelligence approach to machinetranslation.
In Schank, R.C., and Colby, K.M.
Ed., ComputerModels of Thought and Language.
W.H.
Freeman, San Francis-co: 114-151.Winograd, T. 1972 Understanding Natural Language.
AcademicPress, New York.Woods, W.A.
1977 Lunar rocks in natural English: Explorationsin natural language question answering.
In Zampolli, A., Ed.,Linguistic Structures Processing.
North-Holland, Amsterdam:521-569.Lenhart K. Schubert is an associate professor o fcomputer science at the University o f  Alberta, Edmonton.He received the Ph.D. degree in computer science f romthe University o f  Toronto.Francis Jeffry Pelletier is a professor o f  philosophy atthe University o f  Alberta.
He received the Ph.D. degreef rom the University o f  California at Los Angeles.44 American Journal of Computational Linguistics, Volume 8, Number 1, January-March 1982
