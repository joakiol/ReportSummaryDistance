Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 77?81,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsFurther Experiments with Shallow Hybrid MT SystemsChristian Federmann1, Andreas Eisele1, Hans Uszkoreit1,2,Yu Chen1, Sabine Hunsicker1, Jia Xu11: Deutsches Forschungszentrum fu?r Ku?nstliche Intelligenz GmbH, Saarbru?cken, Germany2: Universita?t des Saarlandes, Saarbru?cken, Germany{cfedermann,eisele,uszkoreit,yuchen,sabine.hunsicker,jia.xu}@dfki.deAbstractWe describe our hybrid machine trans-lation system which has been developedfor and used in the WMT10 shared task.We compute translations from a rule-based MT system and combine the re-sulting translation ?templates?
with par-tial phrases from a state-of-the-art phrase-based, statistical MT engine.
Phrase sub-stitution is guided by several decisionfactors, a continuation of previous workwithin our group.
For the shared task,we have computed translations for six lan-guage pairs including English, German,French and Spanish.
Our experimentshave shown that our shallow substitu-tion approach can effectively improve thetranslation result from the RBMT system;however it has also become clear that adeeper integration is needed to further im-prove translation quality.1 IntroductionIn recent years the quality of machine translation(MT) output has improved greatly, although eachparadigm suffers from its own particular kind oferrors: statistical machine translation (SMT) of-ten shows poor syntax, while rule-based engines(RBMT) experience a lack in vocabulary.
Hybridsystems try to avoid these typical errors by com-bining techniques from both paradigms in a mostuseful manner.In this paper we present the improved version ofthe hybrid system we developed last year?s sharedtask (Federmann et al, 2009).
We take the out-put from an RBMT engine as basis for our hybridtranslations and substitute noun phrases by trans-lations from an SMT engine.
Even though a gen-eral increase in quality could be observed, our sys-tem introduced errors of its own during the substi-tution process.
In an internal error analysis, thesedegradations were classified as follows:- the translation by the SMT engine is incorrect- the structure degrades through substitution(because of e.g.
capitalization errors, doubleprepositions, etc.
)- the phrase substitution goes astray (caused byalignment problems, etc.
)Errors of the first class cannot be corrected, aswe have no way of knowing when the translationby the SMT engine is incorrect.
The other twoclasses could be eliminated, however, by introduc-ing additional steps for pre- and post-processingas well as improving the hybrid algorithm itself.Our current error analysis based on the results ofthis year?s shared task does not show these typesof errors anymore.Additionally, we extended our coverage to alsoinclude the language pairs English?French andEnglish?Spanish in both directions as well asEnglish?German, compared to last year?s initialexperiments for German?English only.
We wereable to achieve an increase in translation qualityfor this language set, which shows that the substi-tution method works for different language config-urations.2 ArchitectureOur hybrid translation system takes translationoutput from a) the Lucy RBMT system (Alonsoand Thurmair, 2003) and b) a Moses-based SMTsystem (Koehn et al, 2007).
We then identifynoun phrases inside the rule-based translation andcompute the most likely correspondences in thestatistical translation output.
For these, we apply afactored substitution method that decides whetherthe original RBMT phrase should be kept or ratherbe replaced by the Moses phrase.
As this shallowsubstitution process may introduce problems at77phrase boundaries, we afterwards perform severalpost-processing steps to cleanup and finalize thehybrid translation result.
A schematic overviewof our hybrid system and its main components isgiven in figure 1.Figure 1: Schematic overview of the hybrid MTsystem architecture.2.1 Input to the Hybrid SystemLucy RBMT System We obtain the translationas well as linguistic structures from the RBMTsystem.
An internal evaluation has shown thatthese structures are usually of a high quality whichsupports our initial decision to consider the RBMToutput as an appropriate ?template?
for our hybridtranslation approach.
The Lucy translation outputcan include additional markup that allows to iden-tify unknown words or other, local phenomena.The Lucy system is a transfer-based MT systemthat performs translation in three phases, namelyanalysis, transfer, and generation.
Intermediatetree structures for each of the translation phasescan be extracted from the Lucy system to guidethe hybrid system.
Sadly, only the 1-best paththrough these three phases is given, so no alterna-tive translation possibilities can be extracted fromthe given data; a fact that clearly limits the poten-tial for more deeply integrated hybrid translationapproaches.
Nevertheless, the availability of the1-best trees already allows to improve the transla-tion quality of the RBMT system as we will showin this paper.Moses SMT System We used a state-of-the-artMoses SMT system to create statistical phrase-based translations of our input text.
Moses hasbeen modified so that it returns the translation re-sults together with the bidirectional word align-ments between the source texts and the transla-tions.
Again, we make use of markup which helpsto identify unknown words as these will later guidethe factored substitution method.
Both of thetranslation models and the language models withinour SMT systems were only trained with lower-cased and tokenized Europarl training data.
Thesystem used sets of feature weights determined us-ing data sets also from Europarl (test2008).
Inaddition, we used LDC gigaword corpus to trainlarge scale n-gram language models to be used inour hybrid system.
We tokenized the source textsusing the standard tokenizers available from theshared task website.
The SMT translations are re-cased before being fed into the hybrid system to-gether with the word alignment information.Thehybrid system can easily be adapted to supportother statistical translation engines.
If the align-ment information is not available, a suitable align-ment tool would be necessary to compute it as thealignment is a key requirement for the hybrid sys-tem.2.2 Aligning RBMT and SMT OutputWe compute alignment in several components ofthe hybrid system, namely:source-text-to-tree: we first find an alignmentbetween the source text and the correspond-ing analysis tree(s).
As Lucy tends to sub-divide large sentences into several smallerunits, it sometimes becomes necessary toalign more than one tree structure to a givensource sentence.analysis-transfer-generation: for each of theanalysis trees, we re-construct the path fromits tree nodes, via the transfer tree, and theircorresponding generation tree nodes.tree-to-target-text: similarly to the first align-ment process, we find a mapping betweengeneration tree nodes and the actual transla-tion output of the RBMT system.source-text-to-tokenized: as the Lucy RBMTsystem works on non-tokenized input textand our Moses system takes tokenized input,78we need to align the source text to its tok-enized form.Given the aforementioned alignments, we can thencorrelate phrases from the rule-based translationwith their counterparts from the statistical trans-lation, both on source or target side.
As ourhybrid approach relies on the identification ofsuch phrase pairs, the computation of the differentalignments is critical to obtain good combinationperformance.Please note that all these tree-based alignmentscan be computed with a very high accuracy.
How-ever, due to the nature of statistical word align-ment, the same does not hold for the alignmentobtained from the Moses system.
If the alignmentprocess has produced erroneous phrase tables, it isvery likely that Lucy phrases and their ?aligned?SMT matches simply will not fit.
Or put the otherway round: the better the underlying SMT wordalignment, the greater the potential of the hybridsubstitution approach.2.3 Factored SubstitutionGiven the results of the alignment process, we canthen identify ?interesting?
phrases for substitution.Following our experimental setup from last year?sshared task, we again decided to focus on nounphrases as these seem to be best-suited for in-placeswapping of phrases.
Our initial assumption is thatSMT phrases are better on a lexical level, hencewe aim to replace Lucy?s noun phrases by theirMoses counterparts.Still, we want to perform the substitution in acontrolled manner in order to avoid problems ornon-matching insertions.
For this, we have (man-ually) derived a set of factors that are checked foreach of the phrase pairs that are processed.
Thefactors are described briefly below:identical?
simply checks whether two candidatephrases are identical.too complex?
a Lucy phrase is ?too complex?to substitute if it contains more than 2embedded noun phrases.many-to-one?
this factor checks if a Lucy phrasecontaining more than one word is mapped toa Moses phrase with only one token.contains pronoun?
checks if the Lucy phrasecontains a pronoun.contains verb?
checks if the Lucy phrase con-tains a verb.unknown?
checks whether one of the phrases ismarked as ?unknown?.length mismatch computes the number of wordsfor both phrases and checks if the absolutedifference is too large.language model computes language modelscores for both phrases and checks which ismore likely according to the LM.All of these factors have been designed and ad-justed during an internal development phase usingdata from previous shared tasks.2.4 Post-processing StepsAfter the hybrid translation has been computed,we perform several post-processing steps to cleanup and finalize the result:cleanup first, we perform basic cleanup opera-tions such as whitespace normalization, cap-italizing the first word in each sentence, etc.multi-words then, we take care of proper han-dling of multi-word expressions.
Using thetree structures from the RBMT system weeliminate superfluous whitespace and joinmulti-words, even if they were separated inthe SMT phrase.prepositions finally, we give prepositions a spe-cial treatment.
Experience from last year?sshared task had shown that things like doubleprepositions contributed to a large extent tothe amount of avoidable errors.
We tried tocircumvent this class of error by identifyingthe correct prepositions; erroneous preposi-tions are removed.3 Hybrid Translation AnalysisWe evaluated the intermediate outputs usingBLEU (Papineni et al, 2001) against human refer-ences as in table 3.
The BLEU score is calculatedin lower case after the text tokenization.
The trans-lation systems compared are Moses, Lucy, Googleand our hybrid system with different configura-tions:Hybrid: we use the language model with caseinformation and substitute some NPs in Lucyoutputs by Moses outputs.Hybrid LLM: same as Hybrid but we use alarger language model.79Table 1: Intermediate results of BLEU[%] scores for WMT10 shared task.System de?en en?de fr?en en?fr es?en en?esMoses 18.32 12.66 22.26 20.06 24.28 24.72Lucy 16.85 12.38 18.49 17.61 21.09 20.85Google 25.64 18.51 28.53 28.70 32.77 32.20Hybrid 17.29 13.05 18.92 19.58 22.53 23.55Hybrid LLM 17.37 13.73 18.93 19.76 22.61 23.66Hybrid SG 17.43 14.40 19.67 20.55 24.37 24.99Hybrid NCLM 17.38 14.42 19.56 20.55 24.41 24.92Hybrid SG: same as Hybrid but the NP substitu-tions are based on Google output instead ofMoses translations.Hybrid NCLM: same as Hybrid but we use thelanguage model without case information.We participated in the translation evaluation insix language pairs: German to English (de?en),English to German (en?de), French to English(fr?en), English to French (en?fr), Spanish toEnglish (es?en) and English to Spanish (en?es).As shown in table 3, the Moses translation sys-tem achieves better results overall than the Lucysystem does.
Google?s system outperforms othersystems in all language pairs.
The hybrid transla-tion as described in section 2 improves the Lucytranslation quality with a BLEU score up to 2.7%absolutely.As we apply a larger language model or a lan-guage model without case information, the trans-lation performance can be improved further.
Onemajor problem in the hybrid translation is that theMoses outputs are still not good enough to replacethe Lucy outputs, therefore we experimented ona hybrid translation of Google and Lucy systemsand substitute some unrelaible NP translations bythe Google?s translations.
The results in the lineof ?Hybrid SG?
shows that the hybrid translationquality can be enhanced if the translation systemwhere we select substitutions is better.4 Internal Evaluation of ResultsIn the analysis of the remaining issues, the fol-lowing main sources of problems can be distin-guished:- Lucy?s output contains structural errors thatcannot be fixed by the chosen approach.- Lucy results contain errors that could havebeen corrected by alternative expressionsfrom SMT, but the constraints in our systemwere too restrictive to let that happen.- The SMT engine we use generates subopti-mal results that find their way into the hybridresult.- SMT results that are good are incorporatedinto the hybrid results in a wrong way.We have inspected a part of the results and classi-fied the problems according to these criteria.
Asthis work is still ongoing, it is too early to reportnumerical results for the relative frequencies of thedifferent causes of the error.
However, we canalready see that three of these four cases appearfrequently enough to justify further attention.
Weobserved several cases in which the parser in theLucy system was confused by unknown expres-sions and delivered results that could have beensignificantly improved by a more robust parsingapproach.
We also encountered several cases inwhich an expression from SMT was used althoughthe original Lucy output would have been better.Also we still observe problems finding to correctcorrespondences between Lucy output and SMToutput, which leads to situations where material isinserted in the wrong place, which can lead to theloss of content words in the output.5 Conclusion and OutlookIn our contribution to the shared task we have ap-plied the hybrid architecture from (Federmann etal., 2009) to six language pairs.
We have identi-fied and fixed many of the problems we had ob-served last year, and we think that, in addition tothe increased coverage in laguage pairs, the overallquality has been significantly increased.However, in the last section we characterizedthree main sources of problems that will requirefurther attention.
We will address these problemsin the near future in the following way:801.
We will investigate in more detail the align-ment issue that leads to occasional loss ofcontent words, and we expect that a carefulinspection and correction of the code will inall likelihood give us a good remedy.2.
The problem of picking expressions from theSMT output that appear more probable to thelanguage model although they are inferior tothe original expression from the RBMT sys-tem is more difficult to fix.
We will try to findbetter thresholds and biases that can at leastreduce the number of cases in which this typeof degradation happen.3.
Finally, we will also address the robustnessissue that leads to suboptimal structures fromthe RBMT engine caused by parsing failures.Our close collaboration with Lucy enables us toaddress these issues in a very effective way via theinspection and classification of intermediate struc-tures and, if these structures indicate parsing prob-lems, the generation of variants of the input sen-tence that facilitate correct parsing.AcknowledgmentsThis work was supported by the EuroMatrixPlusproject (IST-231720) which is funded by the Eu-ropean Commission under the Seventh FrameworkProgramme.
The authors want to thank MichaelJellinghaus and Bastian Simon for help with theinspection of intermediate results and classifica-tion of errors.ReferencesJuan A. Alonso and Gregor Thurmair.
2003.
The Com-prendium Translator system.
In Proc.
of the NinthMT Summit.Christian Federmann, Silke Theison, Andreas Eisele,Hans Uszkoreit, Yu Chen, Michael Jellinghaus, andSabine Hunsicker.
2009.
Translation combinationusing factored word substitution.
In Proceedings ofthe Fourth Workshop on Statistical Machine Translation, pages 70?74, Athens, Greece, March.
Associa-tion for Computational Linguistics.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: Opensource toolkit for statistical machine translation.
InProc.
of ACL Demo and Poster Sessions, pages 177?180, June.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2001.
Bleu: a method for automatic eval-uation of machine translation.
IBM Research ReportRC22176(W0109-022), IBM.81
