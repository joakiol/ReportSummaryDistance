Proceedings of the ACL Student Research Workshop, pages 25?30,Ann Arbor, Michigan, June 2005. c?2005 Association for Computational LinguisticsExploiting Named Entity Taggers in a Second LanguageThamar SolorioComputer Science DepartmentNational Institute of Astrophysics, Optics and ElectronicsLuis Enrique Erro #1, Tonantzintla, Puebla72840, MexicoAbstractIn this work we present a method forNamed Entity Recognition (NER).
Ourmethod does not rely on complex linguis-tic resources, and apart from a hand codedsystem, we do not use any language-dependent tools.
The only informationwe use is automatically extracted from thedocuments, without human intervention.Moreover, the method performs well evenwithout the use of the hand coded system.The experimental results are very encour-aging.
Our approach even outperformedthe hand coded system on NER in Span-ish, and it achieved high accuracies in Por-tuguese.1 IntroductionGiven the usefulness of Named Entities (NEs) inmany natural language processing tasks, there hasbeen a lot of work aimed at developing accuratenamed entity extractors (Borthwick, 1999; Velardi etal., 2001; Are?valo et al, 2002; Zhou and Su, 2002;Florian, 2002; Zhang and Johnson, 2003).
Most ap-proaches however, have very low portability, theyare designed to perform well over a particular collec-tion or type of document, and their accuracies willdrop considerably when used in different domains.The reason for this is that many NE extractor sys-tems rely heavily on complex linguistic resources,which are typically hand coded, for example regu-lar expressions, grammars, gazetteers and the like.Adapting a system of this nature to a different col-lection or language requires a lot of human effort,involving tasks such as rewriting the grammars, ac-quiring new dictionaries, searching trigger words,and so on.
Even if one has the human resources andthe time needed for the adaptation process, there arelanguages that lack the linguistic resources needed,for instance, dictionaries are available in electronicform for only a handful of languages.
We believethat, by using machine learning techniques, we canadapt an existing hand coded system to different do-mains and languages with little human effort.Our goal is to present a method that will facilitatethe task of increasing the coverage of named entityextractor systems.
In this setting, we assume thatwe have available an NE extractor system for Span-ish, and we want to adapt it so that it can performNER accurately in documents from a different lan-guage, namely Portuguese.
It is important to empha-size here that we try to avoid the use of complex andcostly linguistic tools or techniques, besides the ex-isting NER system, given the language restrictionsthey pose.
Although, we do need a corpus of thetarget language.
However, we consider the task ofgathering a corpus much easier and faster than thatof developing linguistic tools such as parsers, part-of-speech taggers, grammars and the like.In the next section we present some recent workrelated to NER.
Section 3 describes the data setsused in our experiments.
Section 4 introduces ourapproach to NER, and we conclude in Section 5 giv-ing a brief discussion of our findings and proposingresearch lines for future work.252 Related WorkThere has been a lot of work on NER, and there is aremarkable trend towards the use of machine learn-ing algorithms.
Hidden Markov Models (HMM) area common choice in this setting.
For instance, Zhouand Su trained HMM with a set of attributes combin-ing internal features such as gazetteer information,and external features such as the context of otherNEs already recognized (Zhou and Su, 2002).
(Bikelet al, 1997) and (Bikel et al, 1999) are other exam-ples of the use of HMMs.Previous methods for increasing the coverageof hand coded systems include that of Borthwick,he used a maximum entropy approach where hecombined the output of three hand coded systemswith dictionaries and other orthographic information(Borthwick, 1999).
He also adapted his system toperform NER in Japanese achieving impressive re-sults.Spanish resources for NER have been used pre-viously to perform NER on a different language.Carreras et al presented results of a NER systemfor Catalan using Spanish resources (Carreras et al,2003a).
They explored several methods for build-ing NER for Catalan.
Their best results are achievedusing cross-linguistic features.
In this method theNER system is trained on mixed corpora and per-forms reasonably well on both languages.
Our workfollows Carreras et al approach, but differs in thatwe apply directly the NER system for Spanish toPortuguese and train a classifier using the output andthe real classes.In (Petasis et al, 2000) a new method for automat-ing the task of extending a proper noun dictionary ispresented.
The method combines two learning ap-proaches: an inductive decision-tree classifier andunsupervised probabilistic learning of syntactic andsemantic context.
The attributes selected for the ex-periments include POS tags as well as morphologi-cal information whenever available.One work focused on NE recognition for Span-ish is based on discriminating among different kindsof named entities: core NEs, which contain a trig-ger word as nucleus, syntactically simple weakNEs, formed by single noun phrases, and syntacti-cally complex named entities, comprised of complexnoun phrases.
Are?valo and colleagues focused onthe first two kinds of NEs (Are?valo et al, 2002).
Themethod is a sequence of processes that uses simpleattributes combined with external information pro-vided by gazetteers and lists of trigger words.
Acontext free grammar, manually coded, is used forrecognizing syntactic patterns.3 Data setsIn this paper we report results of experimenting withtwo data sets.
The corpus in Spanish is that usedin the CoNLL 2002 competitions for the NE extrac-tion task.
This corpus is divided into three sets: atraining set consisting of 20,308 NEs and two differ-ent sets for testing, testa which has 4,634 NEs andtestb with 3,948 NEs, the former was designated totune the parameters of the classifiers (developmentset), while testb was designated to compare the re-sults of the competitors.
We performed experimentswith testa only.For evaluating NER on Portuguese we used thecorpus provided by ?HAREM: Evaluation conteston named entity recognition for Portuguese?.
Thiscorpus contains newspaper articles and consists of8,551 words with 648 NEs.4 Two-step Named Entity RecognitionOur approach to NER consists in dividing the prob-lem into two subproblems that are addressed sequen-tially.
We first solve the problem of determiningboundaries of named entities, we called this processNamed Entity Delimitation (NED).
Once we havedetermined which words belong to named entities,we then get to the task of classifying the named en-tities into categories, this process is what we calledNamed Entity Classification (NEC).
We explain thetwo procedures in the following subsections.4.1 Named Entity DelimitationWe used the BIO scheme for delimiting named enti-ties.
In this approach each word in the text is labeledwith one out of three possible classes: The B tag isassigned to words believed to be the beginning of aNE, the I tag is for words that belong to an entitybut that are not at the beginning, and the O tag is forall words that do not satisfy any of the previous twoconditions.26Table 1: An example of the attributes used in thelearning setting for NER in Spanish.
The fragmentpresented in the table, ?El Eje?rcito Mexicano pusoen marcha el Plan DN-III?, translates as ?The Mex-ican Army launched the DN-III plan?Internal Features External FeaturesWord Caps Position POS tag BIO tag ClassEl 3 1 DA O OEje?rcito 2 2 NC B BMexicano 2 3 NC I Ipuso 2 4 VM O Oen 2 5 SP O Omarcha 2 6 NC O Oel 3 7 DA O OPlan 2 8 NC B BDN-III 3 9 NC I IIn our approach, NED is tackled as a learningtask.
The features used as attributes are automati-cally extracted from the documents and are used totrain a machine learning algorithm.
We used a mod-ified version of C4.5 algorithm (Quinlan, 1993) im-plemented within the WEKA environment (Wittenand Frank, 1999).For each word we combined two types of fea-tures: internal and external; we consider as inter-nal features the word itself, orthographic informa-tion and the position in the sentence.
The externalfeatures are provided by the hand coded NER systemfor Spanish, these are the Part-of-Speech tag and theBIO tag.
Then, the attributes for a given word w areextracted using a window of five words anchored inthe word w, each word described by the internal andexternal features mentioned previously.Within the orthographic information we consider6 possible states of a word.
A value of 1 in this at-tribute means that the letters in the word are all cap-italized.
A value of 2 means the opposite: all lettersare lower case.
The value 3 is for words that have theinitial letter capitalized.
4 means the word has dig-its, 5 is for punctuation marks and 6 refers to marksrepresenting the beginning and end of sentences.The hand coded system used in this work was de-veloped by the TALP research center (Carreras andPadro?, 2002).
They have developed a set of NLP an-alyzers for Spanish, English and Catalan that includepractical tools such as POS taggers, semantic ana-lyzers and NE extractors.
This NER system is basedon hand-coded grammars, lists of trigger words andgazetteer information.In contrast to other methods we do not perform bi-nary classifications, as (Carreras et al, 2003b), thuswe do not build specialized classifiers for each of thetags.
Our classifier learns to discriminate among thethree classes and assigns labels to all the words, pro-cessing them sequentially.
In Table 1 we present anexample taken from the data used in the experimentswhere internal and external features are extracted foreach word in a sentence.4.1.1 Experimental ResultsFor all results reported here we show the overallaverage of several runs of 10-fold cross-validation.We used common measures from information re-trieval: precision, recall and F1 and we present re-sults from individual classes as we believe it is im-portant in a learning setting such as this, wherenearly 90% of the instances belong to one class.Table 2 presents comparative results using theSpanish corpus.
We show four different sets of re-sults, the first ones are from the hand coded sys-tem, they are labeled NER system for Spanish.
Thenwe present results of training a classifier with onlythe internal features described above, these resultsare labeled Internal features.
In a third experimentwe trained the classifier using only the output of theNER system, these are under column External fea-tures.
Finally, the results of our system are presentedin column labeled Our method.
We can see that eventhough the NER system performs very well by it-self, by training the C4.5 algorithm on its outputs weimprove performance in all the cases, with the ex-ception of precision for class B.
Given that the handcoded system was built for this collection, it is veryencouraging to see our method outperforming thissystem.
In Table 3 we show results of applying ourmethod to the Portuguese corpus.
In this case theimprovements are much more impressive, particu-larly for class B, in all the cases the best results areobtained from our technique.
This was expected aswe are using a system developed for a different lan-guage.
But we can see that our method yields verycompetitive results for Portuguese, and although byusing only the internal features we can outperformthe hand coded system, by combining the informa-tion using our method we can increase accuracies.27Table 2: Comparison of results for Spanish NE delimitationNER system for Spanish Internal features External features Our methodClass P R F1 P R F1 P R F1 P R F1B 92.8 89.3 91.7 87.1 89.3 88.2 93.9 91.5 92.7 93.5 92.9 93.2I 84.3 85.2 84.7 89.5 77.1 82.9 87.8 87.8 85.7 90.6 87.4 89.0O 98.6 98.9 98.8 98.1 98.9 98.5 98.7 99 98.9 98.9 99.2 99.1overall 91.9 91.1 91.7 91.5 88.4 89.8 93.4 92.7 92.4 94.3 93.1 93.7Table 3: Experimental results for NE delimitation in PortugueseNER system for Spanish Internal features External features Our methodClass P R F1 P R F1 P R F1 P R F1B 60.0 68.8 64.1 82.4 85.8 84.1 75.9 81.0 78.4 82.1 87.8 84.9I 64.5 73.3 68.6 80.1 76.8 78.4 73.8 70.3 72.0 80.9 77.8 79.3O 97.2 95.5 96.4 98.7 98.5 98.6 98.1 97.7 97.9 98.8 98.4 98.6overall 73.9 79.2 76.3 87.0 87.0 87.0 82.6 83.0 82.7 87.2 88.0 87.6From the results presented above, it is clear thatthe method can perform NED in Spanish and Por-tuguese with very high accuracy.
Another insightsuggested by these results is that in order to performNED in Portuguese we do not need an existing NEDsystem for Spanish, the internal features performedwell by themselves, but if we have one available,we can use the information provided by it to builda more accurate NED method.4.2 Named Entity ClassificationAs mentioned previously, we build our NE classi-fiers using the output of a hand coded system.
Ourassumption is that by using machine learning algo-rithms we can improve performance of NE extrac-tors without a considerable effort, as opposed to thatinvolved in extending or rewriting grammars andlists of trigger words and gazetteers.
Another as-sumption underlying this approach is that of believ-ing that the misclassifications of the hand coded sys-tem for Spanish will not affect the learner.
We be-lieve that by having available the correct NE classesin the training corpus, the learner will be capable ofgeneralizing error patterns that will be used to as-sign the correct NE.
If this assumption holds, learn-ing from other?s mistakes, the learner will end upoutperforming the hand coded system.In order to build a training set for the learner, eachinstance is described with the same attributes as forthe NED task described in section 4.1, with the addi-tion of a new attribute.
Since NEC is a more difficulttask, we consider useful adding as attribute the suf-fix of each word.
Then, for each instance word weconsider its suffix, with a maximum size of 5 char-acters.Another important difference between this clas-sification task and NED relies in the set of targetvalues.
For the Spanish corpus the possible classvalues are the same as those used in CoNLL-2002competition task: person, organization, location andmiscellaneous.
However, for the Portuguese corpuswe have 10 possible classes: person, object, quan-tity, event, organization, artifact, location, date, ab-straction and miscellaneous.
Thus the task of adapt-ing the system for Spanish to perform NEC in Por-tuguese is much more complex than that of NEDgiven that the Spanish system only discerns the fourNE classes defined on the CoNLL-2002.
Regardlessof this, we believe that the learner will be capableof achieving good accuracies by using the other at-tributes in the learning task.4.2.1 Experimental ResultsSimilarly to the NED case we trained C4.5 clas-sifiers for the NEC task, results are presented in Ta-bles 4 and 5.
Again, we perform comparisons be-tween the hand coded system and the use of differentsubsets of attributes.
For the case of Spanish NEC,we can see in Table 4, that our method using internaland external features presents the best results.
Theimprovements are impressive, specially for the NEclass Miscellaneous where the hand coded systemachieved an F measure below 1 while our systemachieved an F measure of 56.7.
In the case of NECin Portuguese the results are very encouraging.
The28Table 4: NEC performance on the Spanish development setNER system for Spanish Internal features External features Our methodClass P R F1 P R F1 P R F1 P R F1Per 84.7 93.2 88.2 94.0 62.9 75.3 88.3 93.1 90.6 88.2 95.4 91.7Org 78.7 88.7 82.9 61.7 90.0 73.2 77.7 91.9 84.2 83.4 89.0 86.1Loc 78.7 76.2 76.9 78.4 65.1 71.2 80.3 80.3 80.3 82.0 82.5 82.2Misc 24.9 .004 .008 75.5 42.0 54.0 52.9 23.4 33.5 71.6 46.9 56.7overall 66.7 64.5 62.0 77.4 65.0 68.4 74.8 72.1 72.1 81.3 78.4 79.1hand coded system performed poorly but by traininga C4.5 algorithm results are improved considerably,even for the classes that the hand coded system wasnot capable of recognizing.
As expected, the exter-nal features did not solve the NEC by themselves butcontribute for improving the performance.
This, andthe results from using only internal features, suggestthat we do not need complex linguistic resources inorder to achieve good results.
Additionally, we cansee that for some cases the classifiers were not ableof performing an accurate classification, as in thecase of classes object and miscellaneous.
This maybe due to a poor representation of the classes in thetraining set, for instance the class object has only 4instances.
We believe that if we have more instancesavailable the learners will improve these results.5 ConclusionsNamed entities have a wide usage in natural lan-guage processing tasks.
For instance, it has beenshown that indexing NEs within documents can helpincrease precision of information retrieval systems(Mihalcea and Moldovan, 2001).
Other applicationsof NEs are in Question Answering (Mann, 2002;Pe?rez-Coutin?o et al, 2004) and Machine Translation(Babych and Hartley, 2003).
Thus it is important tohave accurate NER systems, but these systems mustbe easy to port and robust, given the great variety ofdocuments and languages for which it is desirable tohave these tools available.In this work we have presented a method for per-forming named entity recognition.
The method usesa hand coded system and a set of lexical and or-thographic features to train a machine learning al-gorithm.
Apart from the hand coded system ourmethod does not require any language dependentfeatures, we do not make use of lists of triggerwords, neither we use any gazetteer information.The only information used in this approach is auto-matically extracted from the documents, without hu-man intervention.
Yet, the results presented here arevery encouraging.
We were able to achieve good ac-curacies for NEC in Portuguese, where we needed toclassify NEs into 10 possible classes, by exploitinga hand-coded system for Spanish targeted to only 4classes.
This achievement gives evidence of the flex-ibility of our method.
Additionally we outperformthe hand coded system on NER in Spanish.
Thus,our method has shown to be robust and easy to portto other languages.
The only requirement for usingour method is a tokenizer for languages that do notseparate words with white spaces, the rest can beused pretty straightforward.We are interested in exploring the use of thismethod to perform NER in English, we would liketo determine to what extent our system is capableof achieving competitive results without the use oflanguage dependent resources, such as dictionariesand lists of words.
Another research direction is theadaptation of this method to cross language NER.We are very interested in exploring if, by traininga classifier with mixed language corpora, we canperform NER in more than one language simulta-neously.ReferencesMontse Are?valo, Xavier Carreras, Llu?
?s Ma`rquez, ToniMart?
?, Llu?
?s Padro?, and Maria Jose?
Simon.
2002.A proposal for wide-coverage Spanish named en-tity recognition.
Sociedad Espan?ola para el Proce-samiento del Lenguaje Natural, (28):63?80, May.Bogdan Babych and Anthony Hartley.
2003.
Improv-ing machine translation quality with automatic namedentity recognition.
In Proceedings of the EACL 2003Workshop on MT and Other Language TechnologyTools, pages 1?8.Daniel M. Bikel, Scott Miller, Richard Schwartz, andRalph Weischedel.
1997.
Nymble: a high perfor-29Table 5: NEC performance on the Portuguese setNER system for Spanish Internal features External features Our methodClass P R F1 P R F1 P R F1 P R F1Pessoa (Person) 34.8 72.5 46.6 49.1 92.0 64.0 46.9 64.6 54.4 45.5 91.1 60.7Coisa (Object) 0 0 0 0 0 0 0 0 0 0 0 0Valor (Quantity) 0 0 0 82.1 47.1 59.8 74.6 69.1 71.8 77.6 76.5 77.0Acontecimento (Event) 0 0 0 33.3 21.4 26.1 14.3 7.1 9.5 50.0 21.4 30.0Organizac?a?o (Organization) 41.4 38.4 39.3 70.7 56.9 63.1 45.7 56.9 50.7 79.3 49.2 60.8Obra (Artifact) 0 0 0 76.6 64.3 69.9 29.4 8.9 13.7 74.4 57.1 64.6Local (Location) 52.5 16.5 24.8 72.6 32.6 45.0 43.6 38.5 40.9 67.4 32.1 43.5Tempo (Date) 0 0 0 74.0 86.6 79.8 85.5 83.9 84.7 87.0 83.9 85.5Abstracc?a?o (Abstraction) 0 0 0 82.1 41.8 55.4 22.2 3.6 6.3 79.3 41.8 54.8Variado (Miscellaneous) 0 0 0 1 15.4 26.7 0 0 0 1 15.4 26.7overall 12.8 12.7 11.0 54.1 45.8 48.9 36.2 33.2 33.2 56.1 46.8 50.3mance learning name-finder.
In Proceedings of theFifth Conference on Applied Natural Language Pro-cessing, pages 194?201.Daniel M. Bikel, Richard Schwartz, and RalphWeischedel.
1999.
An algorithm that learns what?s ina name.
Machine Learning, Special Issue on NaturalLanguage Learning, 34(1?3):211?231, February.Andrew Borthwick.
1999.
A Maximum Entropy Ap-proach to Named Entity Recognition.
Ph.D. thesis,New York University, New York, September.Xavier Carreras and Llu?
?s Padro?.
2002.
A flexible dis-tributed architecture for natural language analyzers.
InProceedings of LREC?02, Las Palmas de Gran Ca-naria, Spain.Xavier Carreras, Llu?
?s Ma`rquez, and Llu?
?s Padro?.
2003a.Named entity recognition for Catalan using Spanishresources.
In 10th Conference of the European Chap-ter of the Association for Computational Linguistics(EACL?03), Budapest, Hungary, April.Xavier Carreras, Llu?
?s Ma`rquez, and Llu?
?s Padro?.
2003b.A simple named entity extractor using adaboost.
InWalter Daelemans and Miles Osborne, editors, Pro-ceedings of CoNLL-2003, pages 152?155.
Edmonton,Canada.Radu Florian.
2002.
Named entity recognition as ahouse of cards: Classifier stacking.
In Proceedingsof CoNLL-2002, pages 175?178.
Taipei, Taiwan.Gideon S. Mann.
2002.
Fine-grained proper nounontologies for question answering.
In SemaNet?02:Building and Using Semantic Networks, Taipei, Tai-wan.Rada Mihalcea and Dan Moldovan.
2001.
Documentindexing using named entities.
Studies in Informaticsand Control, 10(1), January.Manuel Pe?rez-Coutin?o, Thamar Solorio, Manuel Montesy Go?mez, Aurelio Lo?pez Lo?pez, and Luis Villasen?orPineda.
2004.
Question answering for Spanishbased on lexical and context annotation.
In ChristianLema?
?tre, Carlos Reyes, and Jesu?s A. Gonza?lez, edi-tors, Advances in Artificial Intelligence ?
IBERAMIA2004, Lecture Notes in Artificial Intelligence 3315,pages 325?333, Puebla, Mexico, November.
Springer.Georgios Petasis, Alessandro Cucchiarelli, Paola Velardi,Georgios Paliouras, Vangelis Karkaletsis, and Con-stantine D. Spyropoulos.
2000.
Automatic adaptationof proper noun dictionaries through cooperation of ma-chine learning and probabilistic methods.
In Proceed-ings of the 23rd annual international ACM SIGIR con-ference on Research and development in informationretrieval, pages 128?135.
ACM Press.J.
R. Quinlan.
1993.
C4.5: Programs for machine learn-ing.
San Mateo, CA: Morgan Kaufmann.Thamar Solorio.
2005.
Improvement of Named EntityTagging by Machine Learning.
Ph.D. thesis, Insti-tuto Nacional de Astrof?
?sica, ?Optica y Electro?nica, To-nantzintla, Puebla, Mexico, (to appear).Paola Velardi, Paolo Fabriani, and Michel Missikoff.2001.
Using text processing techniques to automati-cally enrich a domain ontology.
In Proceedings of theinternational conference on Formal Ontology in Infor-mation Systems, pages 270?284.
ACM Press.Ian H. Witten and Eibe Frank.
1999.
Data Mining, Prac-tical Machine Learning Tools and Techniques withJava Implementations.
The Morgan Kaufmann Seriesin Data Management Systems.
Morgan Kaufmann.Tong Zhang and David Johnson.
2003.
A robust riskminimization based named entity recognition system.In Walter Daelemans and Miles Osborne, editors, Pro-ceedings of CoNLL-2003, pages 204?207.
Edmonton,Canada.Guodong Zhou and Jian Su.
2002.
Named entity recog-nition using an HMM-based chunk tagger.
In Proceed-ings of ACL?02, pages 473?480.30
