Proceedings of The First Workshop on Computational Approaches to Code Switching, pages 1?12,October 25, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsForeign Words and the Automatic Processingof Arabic Social Media Text Written in Roman ScriptRamy Eskander, Mohamed Al-Badrashiny?, Nizar Habash?and Owen RambowCenter for Computational Learning Systems, Columbia University{reskander,rambow}@ccls.columbia.edu?Department of Computer Science, The George Washington University?badrashiny@gwu.edu?Computer Science Department, New York University Abu Dhabi?nizar.habash@nyu.eduAbstractArabic on social media has all the prop-erties of any language on social mediathat make it tough for natural languageprocessing, plus some specific problems.These include diglossia, the use of analternative alphabet (Roman), and codeswitching with foreign languages.
In thispaper, we present a system which canprocess Arabic written in Roman alpha-bet (?Arabizi?).
It identifies whether eachword is a foreign word or one of an-other four categories (Arabic, name, punc-tuation, sound), and transliterates Arabicwords and names into the Arabic alphabet.We obtain an overall system performanceof 83.8% on an unseen test set.1 IntroductionWritten language used in social media shows dif-ferences from that in other written genres: thevocabulary is informal (and sometimes the syn-tax is as well); there are intentional deviationsfrom standard orthography (such as repeated let-ters for emphasis); there are typos; writers usenon-standard abbreviations; non-linguistic soundsare written (haha); punctuation is used creatively;non-linguistic signs such as emoticons often com-pensate for the absence of a broader communica-tion channel in written communication (which ex-cludes, for example, prosody or visual feedback);and, most importantly for this paper, there fre-quently is code switching.
These facts pose a well-known problem for natural language processing ofsocial media texts, which has become an area ofinterest as applications such as sentiment analy-sis, information extraction, and machine transla-tion turn to this genre.This situation is exacerbated in the case of Ara-bic social media.
There are three principal rea-sons.
First, the Arabic language is a collection ofvarieties: Modern Standard Arabic (MSA), whichis used in formal settings, and different forms ofDialectal Arabic (DA), which are commonly usedinformally.
This situation is referred to as ?diglos-sia?.
MSA has a standard orthography, whilethe dialects do not.
What is used in Arabic so-cial media is typically DA.
This means that thereis no standard orthography to begin with, result-ing in an even broader variation in orthographicforms found.
Diglossia is seen in other linguisticcommunities as well, including German-speakingSwitzerland, in the Czech Republic, or to a some-what lesser extent among French speakers.
Sec-ond, while both MSA and DA are commonly writ-ten in the Arabic script, DA is sometimes writ-ten in the Roman script.
Arabic written in Romanis often called ?Arabizi?.
It is common in otherlinguistic communities as well to write informalcommunication in the Roman alphabet rather thanin the native writing system, for example, amongSouth Asians.
And third, educated speakers ofArabic are often bilingual or near-bilingual speak-ers of another language as well (such as Englishor French), and will code switch between DA andthe foreign language in the same utterance (andsometimes MSA as well).
As is well known, codeswitching is common in many linguistic commu-nities, for example among South Asians.In this paper, we investigate the issue of pro-cessing Arabizi input with code switching.
Thereare two tasks: identification of tokens that arenot DA or MSA (and should not be transliteratedinto Arabic script for downstream processing), andthen the transliteration into Arabic script of theparts identified as DA or MSA.
In this paper, we1use as a black box an existing component that wedeveloped to transliterate from Arabizi to Arabicscript (Al-Badrashiny et al., 2014).
This paperconcentrates on the task of identifying which to-kens should be transliterated.
A recent releaseof annotated data by the Linguistic Data Consor-tium (LDC, 2014c; Bies et al., 2014) has enablednovel research on this topic.
The corpus pro-vides each token with a tag, as well as a translit-eration if appropriate.
The tags identify foreignwords, as well as Arabic words, names, punctua-tion, and sounds.
Only Arabic words and namesare transliterated.
(Note that code switching is notdistinguished from borrowing.)
Emoticons, whichmay be isolated or part of an input token, are alsoidentified, and converted into a conventional sym-bol (#).
This paper presents taggers for the tags,and an end-to-end system which takes Arabizi in-put and produces a complex output which consistsof a tag for each input token and a transliterationof Arabic words and names into the Arabic script.To our knowledge, this is the first system that han-dles the complete task as defined by the LDC data.This paper focuses on the task of identifying for-eign words (as well as the other tags), on creatinga single system, and on evaluating the system as awhole.This paper makes three main contributions.First, we clearly define the computational prob-lem of dealing with social media Arabizi, and pro-pose a new formulation of the evaluation metricfor the LDC corpus.
Second, we present novelmodules for the detection of foreign words as wellas of emoticons, sounds, punctuation marks, andnames in Arabizi.
Third, we compose a single sys-tem from the various components, and evaluate thecomplete system.This paper is structured as follows.
We start bypresenting related work (Section 2), and then wepresent relevant linguistic facts and explain howthe data is annotated (Section 3).
After summariz-ing our system architecture (Section 4) and exper-imental setup (Section 5), we present our systemsfor tagging in Sections 6, 7 and 8.
The evaluationresults are presented in Section 9.2 Related WorkWhile natural language processing for English insocial media has attracted considerable attentionrecently (Clark and Araki, 2011; Gimpel et al.,2011; Gouws et al., 2011; Ritter et al., 2011; Der-czynski et al., 2013), there has not been muchwork on Arabic yet.
We give a brief summary ofrelevant work on Arabic.Darwish et al.
(2012) discuss NLP problems inretrieving Arabic microblogs (tweets).
They dis-cuss many of the same issues we do, notably theproblems arising from the use of DA such as thelack of a standard orthography.
However, they donot deal with DA written in the Roman alphabet(though they do discuss non-Arabic characters).There is some work on code switching be-tween Modern Standard Arabic (MSA) and di-alectal Arabic (DA).
Zaidan and Callison-Burch(2011) are interested in this problem at the inter-sentence level.
They crawl a large dataset ofMSA-DA news commentaries.
They use Ama-zon Mechanical Turk to annotate the dataset at thesentence level.
Then they use a language model-ing approach to predict the class (MSA or DA)for an unseen sentence.
There is other work ondialect identification, such as AIDA (Elfardy etal., 2013; Elfardy et al., 2014).
In AIDA, somestatistical and morphological analyses are appliedto capture code switching between MSA and DAwithin the same sentence.
Each word in the sen-tence is tagged to be either DA or MSA basedon the context.
The tagging process mainly de-pends on the language modeling (LM) approach,but if a word is unknown in the LM, then its tag isassigned through MADAMIRA, a morphologicaldisambiguator Pasha et al.
(2014).Lui et al.
(2014) proposed a system that doeslanguage identification in multilingual documents,using a generative mixture model that is basedon supervised topic modeling algorithms.
This issimilar to our work in terms of identifying codeswitching.
However, our system deals with Ara-bizi, a non-standard orthography with high vari-ability, making the identification task much harder.Concerning specifically NLP for Arabizi, Dar-wish (2013) (published in an updated version as(Darwish, 2014)) is similar to our work in thathe identifies English in Arabizi text and he alsotransliterates Arabic text from Arabizi to Arabicscript.
We compare our transliteration method tohis in Al-Badrashiny et al.
(2014).
For identifi-cation of non-Arabic words in Arabizi, Darwish(2013) uses word and sequence-level features withCRF modeling; while we use SVMs and decisiontrees.
Darwish (2013) identifies three tags: Ara-bic, foreign and others (such as email addressesand URLs).
In contrast, we identify a biggerset: Arabic, foreign, names, sounds, punctuation2and emoticons.
Furthermore, Darwish (2013) usesaround 5K words for training his taggers and 3.5Kwords for testing; this is considerably smaller thanour training and test sets of 113K and 32K words,respectively.Chalabi and Gerges (2012) presented a hybridapproach for Arabizi transliteration.
Their workdoes not address the detection of English words,punctuation, emoticons, and so on.
They also donot handle English when mixed with Arabizi.Voss et al.
(2014) deal with exactly the prob-lem of classifying tokens in Arabizi as Arabic ornot.
More specifically, they deal with MoroccanArabic, and with both French and English, mean-ing they do a three-way classification.
There aremany differences between our work and theirs:they have noisy training data, and they have amuch more balanced test set.
They also only dealwith foreignness, and do not address the other tagswe deal with, nor do they actually discuss translit-eration itself.3 Linguistic Facts and Data Annotation3.1 ArabiziArabizi refers to Arabic written using the Romanscript (Darwish, 2013; Voss et al., 2014).
Ara-bizi orthography is spontaneous and has no stan-dard references, although there are numerous com-monly used conventions making specific usage ofthe so-called Arabic numerals and punctuation inaddition to Roman script letters.
Arabizi is com-monly used by Arabic speakers to write mostly indialectal Arabic in social media, SMS and chat ap-plications.Arabizi orthography decisions mainly dependon a phoneme-to-grapheme mapping between theArabic pronunciation and the Roman script.
Thisis largely based on the phoneme-to-graphememapping used in English (in Middle Eastern Arabcountries) or French (in Western North AfricanArab countries).
Since there is no standard or-thography for Arabizi, it is not a simple translit-eration of Arabic.
For example, in Arabizi, wordsomit vowels far less frequently than is done whenwriters follow standard Arabic orthography.
Fur-thermore, there are several cases of many-to-manymappings between Arabic phonemes and Romanscript letters: for example, the letter ?t?
is used torepresent the sound of the Arabic lettersH t1and1Arabic transliteration is presented in the Habash-Soudi-Buckwalter scheme (Habash et al., 2007): (in alphabetical?
T (which itself can be also be represented usingthe digit ?6?
).Text written in Arabizi also tends to have a largenumber of foreign words, that are either borrow-ings such as telephone, or code switching, suchas love you!.
Note that Arabizi often uses thesource language orthography for borrowings (es-pecially recent borrowings), even if the Arabicpronunciation is somewhat modified.
As a re-sult, distinguishing borrowings from code switch-ing is, as is usually the case, hard.
And, as in anylanguage used in social media and chat, Arabizimay also include abbreviations, such as isa whichmeans ?<?
@ Z A??
@?An ?A?
Allh ?God willing?
andlol ?laugh out loud?.The rows marked with Arabizi in Figure 1demonstrate some of the salient features of Ara-bizi.
The constructed example in the figure is ofan SMS conversation in Egyptian Arabic.3.2 Data AnnotationThe data set we use in this paper was created bythe Linguistic Data Consortium (Bies et al., 2014;LDC, 2014a; LDC, 2014b; LDC, 2014c).
Wesummarize below the annotation decisions.
Thesystem we present in this paper aims at predictingexactly this annotation automatically.
The inputtext is initially segregated into Arabic script andArabizi.
Arabic script text is not modified in anyway.
Arabizi text undergoes two sets of annotationdecisions: Arabizi word tagging and Arabizi-to-Arabic transliteration.
All of the Arabizi annota-tions are initially done using an automatic process(Al-Badrashiny et al., 2014) and then followed bymanual correction and validation.Arabizi Word Tagging Each Arabizi word re-ceives one of the following five tags:?
Foreign All words from languages other thanArabic are tagged as Foreign if they wouldbe kept in the same orthographic form whentranslated into their source language (whichin our corpus is almost always English).Thus, non-Arabic words that include Arabicaffixes are not tagged as Foreign.
The defini-tion of ?foreign?
thus means that uninflectedborrowings spelled as in the source languageorthography are tagged as ?foreign?, whileborrowings that are spelled differently, aswell as borrowing that have been inflectedorder) Abt?jHxd?rzs?SDT?D?
?fqklmnhwy and the additionalsymbols: ?
Z, ?
@,?A @,?A@, ?w?
', ?y Z?
', h??, ?
?.3(1) Arabizi Youmna i need to know anti gaya wala la2 ?Tag Name Foreign Foreign Foreign Foreign Arabic Arabic Arabic Arabic PunctArabic ?????
@ YJK ?K ?K ??K @?KAg.B?B ?ymn?
Ay nyd tw nw Anty jAyh?
wlA l?
?English Youmna I need to know you coming or not ?
(2) Arabizi Mmmm ok ana 7aseb el sho3?l now w ageelk isa :-)Tag Sound Foreign Arabic Arabic Arabic Arabic Foreign Arabic Arabic Arabic ArabicArabic ????J??
@ AK @ I.?Ag [+]?
@ ???
?AK [+]?
??[-]?k.
@ ?<?
@[-]ZA?[-]?
@ #mmm Awkyh AnA HAsyb Al[+] ?gl nAw w[+] Ajy[-]lk An[-]?A?
[-]Allh #English mmm OK I will-leave the work now and I-come-to-you God-willing :-)(3) Arabizi qishta!
:DTag ArabicArabic #[-]!????q?Th?!
[-]#English cream!
:D (slang for cool!
)Figure 1: A short constructed SMS conversation written in Arabizi together with annotation of wordtags and transliteration into Arabic script.
A Romanized transliteration of the Arabic script and Englishglosses are provided for clarity.
The cells with gray background are the parts of the output that weevaluate.following Arabic morphology, are not taggedas ?foreign?
(even if the stem is spelled as inthe source language, such as Almobile).
TheArabic transliterations of these words are notmanually corrected.?
Punct Punctuation marks are a set of conven-tional signs that are used to aid interpretationby indicating division of text into sentencesand clauses, etc.
Examples of punctuationmarks are the semicolon ;, the exclamationmark !
and the right brace }.
Emoticons arenot considered punctuation and are handledas part of the transliteration task discussedbelow.?
Sound Sounds are a list of interjections thathave no grammatical meaning, but mimicnon-linguistic sounds that humans make, andthat often signify emotions.
Examples ofsounds are hahaha (laughing), hmm (wonder-ing) and eww (being disgusted).
It is commonto stretch sounds out to make them stronger,i.e., to express more intense emotions.
Forexample, hmm could be stretched out intohmmmmm to express a stronger feeling ofwondering.
The Arabic transliterations ofthese words are not manually corrected.?
Name Proper names are tagged as such andlater manually corrected.?
Arabic All other words are tagged as Arabicand are later manually corrected.See the rows marked with Tag in Figure 1 forexamples of these different tags.
It is impor-tant to point out that the annotation of this datawas intended to serve a project focusing on ma-chine translation from dialectal Arabic into En-glish.
This goal influenced some of the annotationdecisions and was part of the reason for this selec-tion of word tags.Arabizi-to-Arabic Transliteration The secondannotation task is about converting Arabizi to anArabic-script-based orthography.
Since, dialectalArabic including Egyptian Arabic has no standardorthography in Arabic script, the annotation uses aconventionalized orthography for Dialectal Arabiccalled CODA (Habash et al., 2012a; Eskander etal., 2013; Zribi et al., 2014).
Every word has asingle orthographic representation in CODA.In the corpus we use, only words tagged asArabic or Name are manually checked and cor-rected.
The transliteration respects the white-space boundaries of the original Arabizi words.
Incases where an Arabizi word represents a prefixor suffix that should be joined in CODA to thenext or previous word, a [+] symbol is added tomark this decision.
Similarly, for Arabizi wordsthat should be split into multiple CODA words,the CODA words are written with added [-] sym-bol delimiting the word boundaries.The Arabic transliteration task also includeshandling emoticons.
Emoticons are digital iconsor sequences of keyboard symbols serving to rep-resent facial expressions or to convey the writer?semotions.
Examples of emoticons are :d, :-(, O.Oand ?
used to represent laughing, sadness, beingsurprised and positive emotion, respectively.
Allemoticons, whether free-standing or attached to a4word, are replaced by a single hash symbol (#).Free-standing emoticons are tagged as Arabic.
At-tached emoticons are not tagged separately; theword they are attached to is tagged according tothe usual rules.
See Figure 1 for examples of thesedifferent decisions.Since words tagged as Foreign, Punct, or Soundare not manually transliterated in the corpus, inour performance evaluation we combine the de-cisions of tags and transliteration.
For foreignwords, punctuation and sounds, we only considerthe tags for accuracy computations; in contrast, fornames and Arabic words, we consider both the tagand transliteration.4 System ArchitectureFigure 2 represent the overall architecture of oursystem.
We distinguish below between existingcomponents that we use and novel extensions thatwe contribute in this paper.4.1 Existing Arabization SystemFor the core component of Arabizi-to-Arabictransliteration, we use a previously published sys-tem (Al-Badrashiny et al., 2014), which convertsArabizi into Arabic text following CODA conven-tions (see Section 3).
The existing system uses afinite state transducer trained on 8,500 Arabizi-to-Arabic transliteration pairs at the character level toobtain a large number of possible transliterationsfor the input Arabizi words.
The generated list isthen filtered using a dialectal Arabic morphologi-cal analyzer.
Finally, the best choice for each inputword is selected using a language model.
We usethis component as a black box except that we re-train it using additional training data.
In Figure 2,this component is represented using a central blackbox.4.2 Novel ExtensionIn this paper, we add Word Type Tagging as anew set of modules.
We tag the Arabizi words intofive categories as discussed above: Arabic, For-eign, Names, Sounds, and Punctuation.
Figure 2illustrates the full proposed system.
First, we pro-cess the Arabizi input to do punctuation and soundtagging, along with emoticon detection.
Then werun the transliteration system to produce the cor-responding Arabic transliteration.
The Arabizi in-put and Arabic output are then used together todo name tagging and foreign word tagging.
TheArabic tag is assigned to all untagged words, i.e.,words not tagged as Foreign, Names, Sounds, orPunctuation.
The outputs from all steps are thencombined to produce the final Arabic translitera-tion along with the tag.5 Experimental Setup5.1 Data SetsWe define the following sets of data:?
Train-S: A small size dataset that is used totrain all taggers in all experiments to deter-mine the best performing setup (feature engi-neering).?
Train-L: A larger size dataset that is used totrain the best performing setup.?
Dev: The development set that is used tomeasure the system performance in all exper-iments?
Test: A blind set that is used to test the bestsystem (LDC, 2014a).The training and development sets are extractedfrom (LDC, 2014b).
Table 1 represents the tagsdistribution in each dataset.
Almost one of everyfive words is not Arabic text and around one ofevery 10 words is foreign.5.2 Arabizi-to-Arabic TransliterationAccuracyFor the Arabizi-to-Arabic transliteration system,we report on using the two training data setswith two modifications.
First, we include the8,500 word pairs from Al-Badrashiny et al.
(2014),namely 2,200 Arabizi-to-Arabic script pairs fromthe training data used by Darwish (2013) (man-ually revised to be CODA-compliant) and about6,300 pairs of proper names in Arabic and En-glish from the Buckwalter Arabic Morphologi-cal Analyzer (Buckwalter, 2004).
(Since thesepairs are not tagged, we do not use them to trainthe taggers.)
Second, we exclude all the foreigntagged words from training the transliteration sys-tem since they were not manually corrected.Table 2 shows the overall transliteration accu-racy of Arabic words and names only, using dif-ferent training data sets and evaluating on Dev(as determined by the gold standard).
The ac-curacy when using the original Arabizi-to-Arabictransliteration system from Al-Badrashiny et al.
(2014) gives an accuracy of 68.6%.
Retraining iton Train-S improves the accuracy to 76.9%.
Theaccuracy goes up further to 79.5% when using the5Arabizi-to-ArabicTransliteration ArabiziPunctuation,Sound &EmoticonDetectionName TaggerForeign WordTaggerCombinerArabic&TaggedArabiziFigure 2: The architecture of our complete Arabizi processing system.
The "Punctuation, Sound andEmoticon Detection" component does labeling that is read by the "Name" and "Foreign Word" taggers,While the actual Aribizi-to-Arabic transliteration system is used as a black box.Data # Words Arabic Foreign Name Sound Punct EmoticonTrain-S 21,950 80.5% 12.1% 2.8% 1.7% 1.3% 1.6%Train-L 113,490 82.3% 9.8% 2.4% 1.8% 1.1% 2.6%Dev 5,061 76.3% 16.2% 2.9% 1.8% 1.2% 1.5%Test 31,717 86.1% 6.0% 2.7% 1.6% 0.9% 2.8%Table 1: Dataset StatisticsData Translit.
Acc.Al-Badrashiny et al.
(2014) 68.6%Train-S 76.9%Train-L 79.5%Table 2: Transliteration accuracy of Arabic wordsand names when using different training sets andevaluating on Devbigger training set Train-L.
The overall transliter-ation accuracy of Arabic words and names on Testusing the bigger training set Train-L is 83.6%.6 Tagging Punctuation, Emoticons andSounds6.1 ApproachWe start the tagging process by detecting threetypes of closed classes: punctuation, sounds andemoticons.
Simple regular expressions performvery well at detecting their occurrence in text.
Theregular expressions are applied to the Arabizi in-put, word by word, after lower-casing, since bothemoticons and sounds could contain either smallor capital letters.Since emoticons can be composed of just con-catenated punctuation marks, their detection is re-quired before punctuation is tagged.
Once de-tected, emoticons are replaced by #.
Then punctu-ation marks are detected.
If a non-emoticon wordis only composed of punctuation marks, then itgets tagged as Punct.
Sounds are targeted next.A word gets tagged as Sound if it matches thesound detection expression, after stripping out anyattached punctuation marks and/or emoticons.6.2 ResultsTable 6 in Section 9 shows the accuracy, recall,precision and F-score for the classification of thePunct and Sound tags and detection of emoticons.Since emoticons can be part of another word, andin that case do not receive a specific tag (as spec-ified in the annotation guidelines by the LDC),emoticon evaluation is concerned with the num-ber of detected emoticons within an Arabizi word,as opposed to a binary tagging decision.
In otherwords, emoticon identification is counted as cor-rect (?positive?)
if the number of detected emoti-cons in a word is correct in the test token.
ThePunct and Sound tags represent standard binaryclassification tasks and are evaluated in the usualway.7 Tagging Names7.1 ApproachWe consider the following set of binary featuresfor learning a model of name tagging.
The fea-tures are used either separately or combined usinga modeling classifier implemented with decisiontrees.?
Capitalization A word is considered a nameif the first letter in Arabizi is capitalized.6?
MADAMIRA MADAMIRA is a system formorphological analysis and disambiguationof Arabic (Pasha et al., 2014).
We runMADAMIRA on the Arabic output after run-ning the Arabizi-to-Arabic transliteration.
Ifthe selected part-of-speech (POS) of a wordis proper noun (NOUN_PROP), then theword is tagged as Name.?
CALIMA CALIMA is a morphological an-alyzer for Egyptian Arabic (Habash et al.,2012b).
If the Arabic transliteration of agiven Arabizi word has a possible propernoun analysis in CALIMA, then the word istagged as Name.?
Maximum Likelihood Estimate (MLE) AnArabizi word gets assigned the Name tag ifName is the most associated tag for that wordin the training set.?
Tharwa Tharwa is a large scale EgyptianArabic-MSA-English lexicon that includesPOS tag information (Diab et al., 2014).
Ifan Arabizi word appears in Tharwa as an En-glish gloss with a proper noun POS, then it istagged as Name.?
Name Language Model We use a list of280K unique lower-cased English words as-sociated with their probability of appearingcapitalized (Habash, 2009).
When using thisfeature, any probability that is not equal toone is rounded to zero.All the features above are modeled after case-lowering the Arabizi input, and removing speecheffects.
Any attached punctuation marks and/oremoticons are stripped out.
One exception is thecapitalization feature, where the case of the firstletter of the Arabizi word is preserved.
The tech-niques above are then combined together using de-cision trees.
In this approach, the words tagged asName are given a weight that balances their infre-quent occurrence in the data.7.2 ResultsTable 3 shows the performance of the Name tag-ging on Dev using Train-S.
The best results areobtained when looking up the MLE value in thetraining data, with an accuracy and F-score of97.8% and 56.0%, respectively.
When usingTrain-L, the accuracy and F-score given by MLEgo up to 98.1% and 63.9%, respectively.
See Ta-ble 6.
The performance of the combined approachFeature Accuracy Recall Precision F-ScoreCapitalization 85.6 28.3 6.4 10.4MADAMIRA 95.9 24.8 28.3 26.5CALIMA 86.3 50.3 10.9 17.9MLE 97.8 46.9 69.4 56.0THARWA 96.3 22.8 33.0 26.9NAME-LM 84.5 30.3 6.3 10.4All Combined 97.7 49.7 63.2 55.6(Decision Trees)Table 3: Name tagging results on Dev with Train-Sdoes not outperform the most effective single clas-sifier, MLE.
This is because adding other featuresdecreases the precision by an amount that exceedsthe increase in the recall.8 Tagging Foreign WordsAs shown earlier, around 10% of all words in Ara-bizi text are foreign, mostly English in our data set.Tagging foreign words is challenging since thereare many words that can be either Arabic (in Ara-bizi) or a word in a foreign languages.
For exam-ple the Arabizi word mesh can refer to the Englishreading or the Arabic word??
m?
?not?.
There-fore, simple dictionary lookup is not sufficient todetermine whether a word is Arabic or Foreign.Our target in this section is to identify the foreignwords in the input Arabizi text .8.1 Baseline ExperimentsWe define a foreignness index formula that giveseach word a score given its unigram probabili-ties against Arabic and English language models(LMs).?
(w) = ?PE(w) + (1?
?)
(1?
PA(wt)) (1)?
(w) is the foreignness score of the Arabizi wordw.
PE(w) is the unigram probability of w in theEnglish LM, and PA(wt) is the unigram proba-bility in the Arabic LM of the transliteration intoArabic (wt) proposed by our system for the Ara-bizi word w. ?
is a tuning parameter varying fromzero to one.
From equation 1 we define the mini-mum and maximum ?
values as follows:?min= ?PEmin+ (1?
?)
(1?
PAmax)?max= ?PEmax+ (1?
?)
(1?
PAmin)(2)Where PEminand PEmaxare the minimum andmaximum uni-gram probabilities in the EnglishLM.
And PAminand PAmaxare the minimum7and maximum uni-gram probabilities in the Ara-bic LM.
The foreignness index Foreignness(w)is the normalized foreignness score derived usingequations 1 and 2 as follow:Foreignness (w) =?
(w)?
?min?max?
?min(3)If the foreignness index of a word is higher thana certain threshold ?, we consider the word For-eign.
We define three baseline experiments as fol-lows:?
FW-index-manual: Use brute force searchto find the best ?
and ?
that maximize theforeign words tagging on Dev.?
FW-index-SVM: Use the best ?
from aboveand train an SVM model using the foreign-ness index as sole feature.
Then use thismodel to classify each word in Dev.?
LM-lookup: The word is said to be Foreignif it exists in the English LM and does notexist in the Arabic LM.8.2 Machine Learning ExperimentsWe conducted a suite of experiments by train-ing different machine learning techniques usingWEKA (Hall et al., 2009) on the following groupsof features.
We performed a two-stage feature ex-ploration, where we did an exhaustive search overall features in each group in the first phase, andthen exhaustively searched over all retained fea-ture groups.
In addition, we also performed an ex-haustive search over all features in the first threegroups.?
Word n-gram features: Run the input Ara-bizi word through an English LM and the cor-responding Arabic transliteration through anArabic LM to get the set of features that aredefined in "Group1" in Table 4.
Then find thebest combination of features that maximizesthe F-score on Dev.?
FW-char-n-gram features: Run the inputArabizi word through a character-level n-gram LM of the Arabizi words that are taggedas foreign in the training data.
We get the setof features that are defined in "Group2" in Ta-ble 4.
Then find the best feature combinationfrom this group that maximizes the F-scoreon Dev.?
AR-char-n-gram features: Run the inputArabizi word through a character-level n-gram LM of the Arabizi words that are taggedGroup DescriptionGroup1 Uni and bi-grams probabilities from English andArabic LMsGroup2 1,2,3,4, and 5 characters level n-grams of foreignwordsGroup3 1,2,3,4, and 5 characters level n-grams of ArabicwordsUse the Arabizi word itself as a featureGroup4 Was the input Arabizi word tagged as foreign inthe gold training data?Was the input Arabizi word tagged as Arabic in thegold training data?Does the input word has speech effects?Group5 Word lengthIs the Arabizi word capitalized?Table 4: List of the different features that are usedin the foreign word taggingas non-foreign in the training data.
We get theset of features that are defined in "Group3" inTable 4.
Then find the best feature that maxi-mizes the F-score on Dev.?
Word identity: Use the input Arabizi wordto get all features that are defined in "Group4"in Table 4.
Then find the best combination offeatures that maximizes the F-score on Dev.?
Word properties: Use the input Arabiziword to get all features that are defined in"Group5" in Table 4.
Then find the best com-bination of features that maximizes the F-score on Dev.?
Best-of-all-groups: Use the best selected setof features from each of the above experi-ments.
Then find the best combination ofthese features that maximizes the F-score onDev.?
All-features: Use all features from allgroups.?
Probabilistic-features-only: Find the bestcombination of features from "Group1","Group2", and "Group3" in Table 4 that max-imizes the F-score on Dev.8.3 ResultsTable 5 shows the results on Dev using Train-S.It can be seen that the decision tree classifier isdoing better than the SVM except in the "Wordproperties" and "All-features" experiments.
Thebest performing setup is "Probabilistic-features-only" with decision trees which has 87.3% F-score.
The best selected features are EN-Unigram,AR-char-2-grams, FW-char-1-grams, FW-char-2-grams, FW-char-5-grams.8Experiment Recall Precision F-Score Classifier Selected FeaturesLM-lookup 7.6 95.4 14.1FW-index-manual 75.0 51.0 60.7 ?
=0.8 , ?
= 0.23FW-index-SVM 4.0 89.0 7.7 SVMWord n-gram features 76.7 73.2 74.9 AR-unigram, EN-unigramAR-char-n-gram features 55.4 34.8 42.8 AR-char-4-gramsFW-char-n-gram features 42.4 52.2 46.8 FW-char-3-gramsWord properties 2.4 28.6 4.5 Has-speech-effect, Word-length, Is-capitalizedWord identity 70.3 63.0 66.4 SVM FW-tagged-listBest-of-all-groups 82.1 76.1 79.0 AR-unigram, EN-unigram, Word-lengthAll-features 69.4 87.7 77.5 All features from all groupsProbabilistic-features-only 84.5 80.6 82.5 AR-unigram, EN-unigram, AR-char-3-grams, FW-char-3-gramsWord n-gram features 82.8 80.5 81.6 AR-unigram, EN-unigramAR-char-n-gram features 80.6 63.2 70.8 AR-char-5-gramsFW-char-n-gram features 73.8 76.3 75.0 FW-char-3-gramsWord properties 1.9 25.4 3.6 Has-speech-effect, Word-lengthWord identity 73.2 60.9 66.5 Decision-Tree FW-tagged-listBest-of-all-groups 87.0 81.5 84.1 AR-unigram, EN-unigram, AR-char-5-grams, FW-char-3-gramsAll-features 92.0 53.4 67.6 All features from all groupsProbabilistic-features-only89.9 84.9 87.3 EN-Unigram, AR-char-2-grams, FW-char-1-grams, FW-char-2-grams, FW-char-5-gramsTable 5: Foreign words tagging results on Dev in terms of F-score (%).9 System Evaluation9.1 Development and Blind Test ResultsWe report the results on Dev using Train-L andwith the best settings determined in the previousthree sections.
Table 6 summarizes the recall, pre-cision and F-score results for the classification ofthe Punct, Sound, Foreign, Name and Arabic tags,in addition to emoticon detection.We report our results on Test, our blind testset, using Train-L and with the best settings de-termined in the previous three sections in Table 7.The punctuation, sounds and emoticons havehigh F-scores but lower than expected.
This islikely due to the limitations of the regular expres-sions used.
The performance on these tags dropsfurther on the test set.
A similar drop is seen forthe Foreign tag.
Name is the hardest tag overall.But it performs slightly better in test compared tothe development set, and so does the Arabic tag.Tag Accuracy Recall Precision F-ScorePunct 99.8 100.0 88.7 94.0Sound 99.4 93.5 78.9 85.6Foreign 95.8 91.6 84.0 87.6Name 98.1 57.5 71.8 63.9Arabic 94.5 95.6 97.3 96.4Emoticon 100.0 97.5 98.7 98.1DetectionTable 6: Tagging results on Dev using Train-LTag Accuracy Recall Precision F-ScorePunct 99.8 98.2 80.1 88.3Sound 99.3 87.4 74.2 80.3Foreign 96.5 92.3 64.3 75.8Name 98.6 53.7 90.2 67.3Arabic 95.4 96.3 98.5 97.4Emoticon 99.2 85.3 93.6 89.3DetectionTable 7: Tagging results on Test using Train-L9.2 Overall System EvaluationIn this subsection we report on evaluating the over-all system accuracy.
This includes the correct tag-ging and Arabizi to Arabic transliteration.
How-ever, since there is no manually annotated goldtransliteration for foreign words, punctuation, orsounds into Arabic, we cannot compare the systemtransliteration of foreign words to the gold translit-eration.
Thus, we define the following metric tojudge the overall system accuracy.Overall System Accuracy Metric A word issaid to be correctly transliterated according to thefollowing rules:1.
If the gold tag is anything other than Arabicand Name, the produced tag must match thegold tag.2.
If the gold tag is either Arabic or Name, theproduced tag and the produced transliterationmust both match the gold.9Data Baseline Accuracy System AccuracyDev 65.7% 82.5%Test 76.8% 83.8%Table 8: Baseline vs. System AccuracyTagGold Errors System ErrorsTyposNot Over Not OverTagged generated Tagged generatedPunct 100.0 0.0 0.0 0.0 0.0Sound 79.3 10.3 10.3 0.0 0.0Foreign 47.2 1.9 12.3 20.3 18.4Name 26.3 13.7 45.3 8.4 6.3Table 9: Error Analysis of tag classification errorsAs a baseline, we use the most frequent tag,which is Arabic in our case, along with the translit-eration of the word using our black box system.Then we apply the above evaluation metric on bothDev and Test.
The results are shown in table 8.
Thebaseline accuracies on Dev and Test are 65.7% and76.8% respectively.
By considering the actual out-put of our system, the accuracy on the Dev and Testdata increases to 82.5% and 83.8% respectively.9.3 Error AnalysisWe conducted an error analysis for tag classifica-tion on the development set.
The analysis is donefor the tags that we built models for, which arePunct, Sound, Foreign and Name.2Table 9 showsthe different error types for classifying the tags.Tagging errors could be either gold errors or sys-tem errors.
These errors could be either due totag over-generation or because the correct tag isnot detected.
Additionally, there are typos in theinput Arabizi that sometimes prevent the systemfrom assigning the correct tags.
Gold errors con-tribute to a large portion of the tagging errors, rep-resenting 100.0%, 89.6%, 49.1% and 40.0% forthe Punct, Sound, Foreign and Name tags, respec-tively.10 Conclusion and Future WorkWe presented a system for automatic processing ofArabic social media text written in Roman script,or Arabizi.
Our system not only transliterates theArabizi text in the Egyptian Arabic dialect but alsoclassifies input Arabizi tokens as sounds, punc-tuation marks, names, foreign words, or Arabicwords, and detects emoticons.
We define a new2As mentioned in Section 4, the Arabic tag is assigned toany remaining untagged words after running the classificationmodels.task-specific metric for evaluating the completesystem.
Our best setting achieves an overall per-formance accuracy of 83.8% on a blind test set.In the future, we plan to extend our work toother Arabic dialects and other language contextssuch as Judeo-Arabic (Arabic written in Hebrewscript with code switching between Arabic andHebrew).
We plan to explore the use of this com-ponent in the context of specific applications suchas machine translation from Arabizi Arabic to En-glish, and sentiment analysis in social media.
Wealso plan to make the system public so it can beused by other people working on Arabic NLP tasksrelated to Arabizi.AcknowledgementThis paper is based upon work supported byDARPA Contract No.
HR0011-12-C-0014.
Anyopinions, findings and conclusions or recommen-dations expressed in this paper are those of the au-thors and do not necessarily reflect the views ofDARPA.
Nizar Habash performed most of his con-tribution to this paper while he was at the Centerfor Computational Learning Systems at ColumbiaUniversity.ReferencesMohamed Al-Badrashiny, Ramy Eskander, NizarHabash, and Owen Rambow.
2014.
AutomaticTransliteration of Romanized Dialectal Arabic.
InProceedings of the Eighteenth Conference on Com-putational Natural Language Learning, pages 30?38, Ann Arbor, Michigan, June.
Association forComputational Linguistics.Ann Bies, Zhiyi Song, Mohamed Maamouri, StephenGrimes, Haejoong Lee, Jonathan Wright, StephanieStrassel, Nizar Habash, Ramy Eskander, and OwenRabmow.
2014.
Transliteration of Arabizi into Ara-bic Orthography: Developing a Parallel AnnotatedArabizi-Arabic Script SMS/Chat Corpus.
In ArabicNatural Language Processing Workshop, EMNLP,Doha, Qatar.Tim Buckwalter.
2004.
Buckwalter Arabic Morpho-logical Analyzer Version 2.0.
LDC catalog numberLDC2004L02, ISBN 1-58563-324-0.Achraf Chalabi and Hany Gerges.
2012.
RomanizedArabic Transliteration.
In Proceedings of the Sec-ond Workshop on Advances in Text Input Methods(WTIM 2012).Eleanor Clark and Kenji Araki.
2011.
Text normal-ization in social media: Progress, problems and ap-plications for a pre-processing system of casual en-glish.
Procedia - Social and Behavioral Sciences,27(0):2 ?
11.
Computational Linguistics and Re-lated Fields.10Kareem Darwish, Walid Magdy, and Ahmed Mourad.2012.
Language Processing for Arabic MicroblogRetrieval.
In Proceedings of the 21st ACM Inter-national Conference on Information and KnowledgeManagement, CIKM ?12, pages 2427?2430, NewYork, NY, USA.
ACM.Kareem Darwish.
2013.
Arabizi Detection and Con-version to Arabic.
CoRR.Kareem Darwish.
2014.
Arabizi Detection and Con-version to Arabic .
In Arabic Natural Language Pro-cessing Workshop, EMNLP, Doha, Qatar.Leon Derczynski, Alan Ritter, Sam Clark, and KalinaBontcheva.
2013.
Twitter part-of-speech taggingfor all: Overcoming sparse and noisy data.
InProceedings of the International Conference RecentAdvances in Natural Language Processing RANLP2013, pages 198?206, Hissar, Bulgaria, September.INCOMA Ltd. Shoumen, BULGARIA.Mona Diab, Mohamed Al-Badrashiny, MaryamAminian, Mohammed Attia, Pradeep Dasigi, HebaElfardy, Ramy Eskander, Nizar Habash, AbdelatiHawwari, and Wael Salloum.
2014.
Tharwa: ALarge Scale Dialectal Arabic - Standard Arabic - En-glish Lexicon.
In Proceedings of the Language Re-sources and Evaluation Conference (LREC), Reyk-javik, Iceland.Heba Elfardy, Mohamed Al-Badrashiny, and MonaDiab.
2013.
Code Switch Point Detection in Arabic.In Proceedings of the 18th International Conferenceon Application of Natural Language to InformationSystems (NLDB2013), MediaCity, UK, June.Heba Elfardy, Mohamed Al-Badrashiny, and MonaDiab.
2014.
AIDA: Identifying Code Switchingin Informal Arabic Text.
In Workshop on Compu-tational Approaches to Linguistic Code Switching,EMNLP, Doha, Qatar, October.Ramy Eskander, Nizar Habash, Owen Rambow, andNadi Tomeh.
2013.
Processing Spontaneous Or-thography.
In Proceedings of the 2013 Conferenceof the North American Chapter of the Associationfor Computational Linguistics: Human LanguageTechnologies (NAACL-HLT), Atlanta, GA.Kevin Gimpel, Nathan Schneider, Brendan O?Connor,Dipanjan Das, Daniel Mills, Jacob Eisenstein,Michael Heilman, Dani Yogatama, Jeffrey Flanigan,and Noah A. Smith.
2011.
Part-of-speech taggingfor twitter: Annotation, features, and experiments.In Proceedings of the 49th Annual Meeting of theAssociation for Computational Linguistics: HumanLanguage Technologies: Short Papers - Volume 2,HLT ?11, pages 42?47, Stroudsburg, PA, USA.
As-sociation for Computational Linguistics.Stephan Gouws, Donald Metzler, Congxing Cai, andEduard Hovy.
2011.
Contextual bearing on lin-guistic variation in social media.
In Proceedings ofthe Workshop on Languages in Social Media, LSM?11, pages 20?29, Stroudsburg, PA, USA.
Associa-tion for Computational Linguistics.Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter.2007.
On Arabic Transliteration.
In A. van denBosch and A. Soudi, editors, Arabic Computa-tional Morphology: Knowledge-based and Empiri-cal Methods.
Springer.Nizar Habash, Mona Diab, and Owen Rabmow.
2012a.Conventional Orthography for Dialectal Arabic.
InProceedings of the Language Resources and Evalu-ation Conference (LREC), Istanbul.Nizar Habash, Ramy Eskander, and Abdelati Hawwari.2012b.
A Morphological Analyzer for EgyptianArabic.
In Proceedings of the Twelfth Meeting of theSpecial Interest Group on Computational Morphol-ogy and Phonology, pages 1?9, Montr?al, Canada.Nizar Habash.
2009.
REMOOV: A tool for online han-dling of out-of-vocabulary words in machine trans-lation.
In Khalid Choukri and Bente Maegaard, ed-itors, Proceedings of the Second International Con-ference on Arabic Language Resources and Tools.The MEDAR Consortium, April.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H. Witten.2009.
The WEKA data mining software: an update.SIGKDD Explorations, 11(1):10?18.LDC.
2014a.
BOLT Phase 2 SMS and Chat Ara-bic DevTest Data ?
Source Annotation, Translit-eration and Translation.
LDC catalog numberLDC2014E28.LDC.
2014b.
BOLT Phase 2 SMS and Chat Ara-bic Training Data ?
Source Annotation, Translit-eration and Translation R1.
LDC catalog numberLDC2014E48.LDC.
2014c.
BOLT Program: Romanized Arabic(Arabizi) to Arabic Transliteration and Normaliza-tion Guidelines.
Version 3.
Linguistic Data Consor-tium.Marco Lui, Jey Han Lau, and Timothy Baldwin.
2014.Automatic detection and language identification ofmultilingual documents.
In Proceedings of LREC.Arfath Pasha, Mohamed Al-Badrashiny, Mona Diab,Ahmed El Kholy, Ramy Eskander, Nizar Habash,Manoj Pooleery, Owen Rambow, and Ryan M. Roth.2014.
MADAMIRA: A Fast, Comprehensive Toolfor Morphological Analysis and Disambiguation ofArabic.
In Proceedings of the Language Resourcesand Evaluation Conference (LREC), Reykjavik, Ice-land.Alan Ritter, Sam Clark, Mausam, and Oren Etzioni.2011.
Named entity recognition in tweets: An ex-perimental study.
In Proceedings of the Conferenceon Empirical Methods in Natural Language Pro-cessing, EMNLP ?11, pages 1524?1534, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Clare Voss, Stephen Tratz, Jamal Laoudi, and Dou-glas Briesch.
2014.
Finding Romanized ArabicDialect in Code-Mixed Tweets.
In Nicoletta Cal-zolari (Conference Chair), Khalid Choukri, ThierryDeclerck, Hrafn Loftsson, Bente Maegaard, JosephMariani, Asuncion Moreno, Jan Odijk, and Stelios11Piperidis, editors, Proceedings of the Ninth Interna-tional Conference on Language Resources and Eval-uation (LREC?14), Reykjavik, Iceland, may.
Euro-pean Language Resources Association (ELRA).Omar F Zaidan and Chris Callison-Burch.
2011.
TheArabic online commentary dataset: an annotateddataset of informal Arabic with high dialectal con-tent.
In Proceedings of ACL, pages 37?41.Ines Zribi, Rahma Boujelbane, Abir Masmoudi,Mariem Ellouze, Lamia Belguith, and Nizar Habash.2014.
A Conventional Orthography for TunisianArabic.
In Proceedings of the Language Resourcesand Evaluation Conference (LREC), Reykjavik, Ice-land.12
