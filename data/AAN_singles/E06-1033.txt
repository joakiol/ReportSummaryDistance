Adaptive Transformation-based Learning forImproving Dictionary TaggingBurcu Karagol-Ayan, David Doermann, and Amy WeinbergInstitute for Advanced Computer Studies (UMIACS)University of MarylandCollege Park, MD 20742{burcu,doermann,weinberg}@umiacs.umd.eduAbstractWe present an adaptive technique that en-ables users to produce a high quality dic-tionary parsed into its lexicographic com-ponents (headwords, pronunciations, partsof speech, translations, etc.)
using anextremely small amount of user providedtraining data.
We use transformation-based learning (TBL) as a postprocessor attwo points in our system to improve per-formance.
The results using two dictio-naries show that the tagging accuracy in-creases from 83% and 91% to 93% and94% for individual words or ?tokens?, andfrom 64% and 83% to 90% and 93% forcontiguous ?phrases?
such as definitionsor examples of usage.1 IntroductionThe availability and use of electronic resourcessuch as electronic dictionaries has increased tre-mendously in recent years and their use inNatural Language Processing (NLP) systems iswidespread.
For languages with limited electronicresources, i.e.
low-density languages, however,we cannot use automated techniques based on par-allel corpora (Gale and Church, 1991; Melamed,2000; Resnik, 1999; Utsuro et al, 2002), compa-rable corpora (Fung and Yee, 1998), or multilin-gual thesauri (Vossen, 1998).
Yet for these low-density languages, printed bilingual dictionariesoften offer effective mapping from the low-densitylanguage to a high-density language, such as En-glish.Dictionaries can have different formats and canprovide a variety of information.
However, theytypically have a consistent layout of entries and a1 Headword 5 Translation2 POS 6 Example of usage3 Sense number 7 Example of usage translation4 Synonym 8 SubcategorizationFigure 1: Sample tagged dictionary entries.
Eighttags are identified and tagged in the given entries.consistent structure within entries.
Publishers ofdictionaries often use a combination of features toimpose this structure including (1) changes in fontstyle, font-size, etc.
that make implicit the lexico-graphic information1, such as headwords, pronun-ciations, parts of speech (POS), and translations,(2) keywords that provide an explicit interpreta-tion of the lexicographic information, and (3) var-ious separators that impose an overall structure onthe entry.
For example, a boldface font may in-dicate a headword, italics may indicate an exam-ple of usage, keywords may designate the POS,commas may separate different translations, and anumbering system may identify different senses ofa word.We developed an entry tagging system that rec-ognizes, parses, and tags the entries of a printeddictionary to reproduce the representation elec-tronically (Karagol-Ayan et al, 2003).
The sys-tem aims to use features as described above andthe consistent layout and structure of the dictio-1For the purposes of this paper, we will refer to the lexi-cographic information as tag when necessary.257naries to capture and recover the lexicographic in-formation in the entries.
Each token2 or group oftokens (phrase)3 in an entry associates with a tagindicating its lexicographic information in the en-try.
Figure 1 shows sample tagged entries in whicheight different types of lexicographic informationare identified and marked.
The system gets for-mat and style information from a document imageanalyzer module (Ma and Doermann, 2003) andis retargeted at many levels with minimal humanassistance.A major requirement for a human aided dic-tionary tagging application is the need to mini-mize human generated training data.4 This re-quirement limits the effectiveness of data drivenmethods for initial training.
We chose rule-basedtagging that uses the structure to analyze and tagtokens as our baseline, because it outperformedthe baseline results of an HMM tagger.
The ap-proach has demonstrated promising results, but wewill show its shortcomings can be improved by ap-plying a transformation-based learning (TBL) postprocessing technique.TBL (Brill, 1995) is a rule-based machine learn-ing method with some attractive qualities thatmake it suitable for language related tasks.
First,the resulting rules are easily reviewed and under-stood.
Second, it is error-driven, thus directly min-imizes the error rate (Florian and Ngai, 2001).Furthermore, TBL can be applied to other annota-tion systems?
output to improve performance.
Fi-nally, it makes use of the features of the token andthose in the neighborhood surrounding it.In this paper, we describe an adaptive TBLbased technique to improve the performance of therule-based entry tagger, especially targeting cer-tain shortcomings.
We first investigate how usingTBL to improve the accurate rendering of tokens?font style affects the rule-based tagging accuracy.We then apply TBL on tags of the tokens.
In ourexperiments with two dictionaries, the range offont style accuracies is increased from 84%-94%to 97%-98%, and the range of tagging accuraciesis increased from 83%-90% to 93%-94% for to-kens, and from 64%-83% to 90%-93% for phrases.Section 2 discusses the rule-based entry tagging2Token is a set of glyphs (i.e., a visual representation of aset of characters) in the OCRed output.
Each punctuation iscounted as a token as well.3In Figure 1, not on time is a phrase consisting of 3 tokens.4For our experiments we required hand tagging of nomore than eight pages that took around three hours of humaneffort.method.
In Section 3, we briefly describe TBL,and Section 4 recounts how we apply TBL to im-prove the performance of the rule-based method.Section 5 explains the experiments and results, andwe conclude with future work.2 A Rule-based Dictionary Entry TaggerThe rule-based entry tagger (Karagol-Ayan et al,2003) utilizes the repeating structure of the dic-tionaries to identify and tag the linguistic roleof tokens or sets of tokens.
Rule-based tagginguses three different types of clues?font style, key-words and separators?to tag the entries in a sys-tematic way.
The method accommodates noise in-troduced by the document analyzer by allowingfor a relaxed matching of OCRed output to tags.For each dictionary, a human operator must spec-ify the lexicographic information used in that par-ticular dictionary, along with the clues for eachtag.
This process can be performed in a few hours.The rule-based method alone achieved token accu-racy between 73%-87% and phrase accuracy be-tween 75%-89% in experiments conducted usingthree different dictionaries5.The rule-based method has demonstrated prom-ising results, but has two shortcomings.
First, themethod does not consider the relations betweendifferent tags in the entries.
While not a prob-lem for some dictionaries, for others ordering therelations between tags may be the only informa-tion that will tag a token correctly.
Consider thedictionary entries in Figure 1.
In this dictionary,the word ?a?
represents POS when in italic font,and part of a translation if in normal font.
How-ever if the font is incorrect (font errors are morelikely to happen with short tokens), the only wayto mark correctly the tag involves checking theneighboring tokens and tags to determine its rel-ative position within the entry.
When the tokenhas an incorrect font or OCR errors exist, andthe other clues are ambiguous or inconclusive, therule-based method may yield incorrect results.Second, the rule-based method can produce in-correct splitting and/or merging of phrases.
An er-roneous merge of two tokens as a phrase may takeplace either because of a font error in one of thetokens or the lack of a separator, such as a punctu-ation mark.
A phrase may split erroneously either5Using HMMs for entry tagging on the same set of dic-tionaries produced slightly lower performance, resulting intoken accuracy between 73%-88% and phrase accuracy be-tween 57%-85%.258as a result of a font error or an ambiguous separa-tor.
For instance, a comma may be used after anexample of usage to separate it from its translationor within it as a normal punctuation mark.3 TBLTBL (Brill, 1995), a rule-based machine learningalgorithm, has been applied to various NLP tasks.TBL starts with an initial state, and it requires acorrectly annotated training corpus, or truth, forthe learning (or training) process.
The iterativelearning process acquires an ordered list of rulesor transformations that correct the errors in thisinitial state.
At each iteration, the transformationwhich achieved the largest benefit during appli-cation is selected.
During the learning process,the templates of allowable transformations limitthe search space for possible transformation rules.The proposed transformations are formed by in-stantiation of the transformation templates in thecontext of erroneous tags.
The learning algorithmstops when no improvement can be made to thecurrent state of the training data or when a pre-specified threshold is reached.A transformation modifies a tag when its con-text (such as neighboring tags or tokens) matchesthe context described by the transformation.
Twoparts comprise a transformation: a rewrite rule?what to replace?
and a triggering environment?when to replace.
A typical rewrite rule is: Changethe annotation from aa to ab, and a typical trig-gering environment is: The preceding word is wa.The system?s output is the final state of this dataafter applying all transformations in the order theyare produced.To overcome the lengthy training time associ-ated with this approach, we used fnTBL, a fast ver-sion of TBL that preserves the performance of thealgorithm (Ngai and Florian, 2001).
Our researchcontribution shows this method is effective whenapplied to a miniscule set of training data.4 Application of TBL to Entry TaggingIn this section, we describe how we used TBL inthe context of tagging dictionary entries.We apply TBL at two points: to render correctlythe font style of the tokens and to label correctlythe tags of the tokens6.
Although our ultimate goal6In reality, TBL improves the accuracy of tags and phraseboundary flags.
In this paper, whenever we say ?applicationof TBL to tagging?, we mean tags and phrase boundary flags  	 	 	fiffffifl 	fiffffifl 	fiffffifl 	 	 !"#	%$ !"#	'& !"#	'( !"#	') !"#	'*Figure 2: Phases of TBL applicationis improving tagging results, font style plays a cru-cial role in identifying tags.
The rule-based entrytagger relies on font style, which can be also incor-rect.
Therefore we also investigate whether im-proving font style accuracy will further improvetagging results.
We apply TBL in three configu-rations: (1) to improve font style, (2) to improvetagging and (3) to improve both, one after another.Figure 2 shows the phases of TBL application.First we have the rule-based entry tagging resultswith the font style assigned by document imageanalysis (Result1), then we apply TBL to taggingusing this result (Result2).
We also apply TBL toimprove the font style accuracy, and we feed thesechanged font styles to the rule-based method (Re-sult3).
We then apply TBL to tagging using thisresult (Result4).
Finally, in order to find the upperbound when we use the manually corrected fontstyles in the ground truth data, we feed correct fontstyles to the rule-based method (Result5), and thenapply TBL to tagging using this result (Result6).In the transformation templates, we use the to-kens themselves as features, i.e.
the items in thetriggering environment, because the token?s con-tent is useful in indicating the role.
For instancea comma and a period may have different func-tionalities when tagging the dictionary.
However,when transformations are allowed to make refer-ence to tokens, i.e., when lexicalized transforma-tions are allowed, some relevant information maybe lost because of sparsity.
To overcome the datasparseness problem, we also assign a type to eachtoken that classifies the token?s content.
We useeight types: punctuation, symbol, numeric, upper-case, capitalized, lowercase, non-Latin, and other.For TBL on font style, the transformation tem-plates contain three features: the token, the token?stype, and the token?s font.
For TBL on tagging, wetogether.259use four features: the token, the token?s type, thetoken?s font style, and the token?s tag.The initial state annotations for font style areassigned by document image analysis.
The rule-based entry tagging method assigns the initial stateof the tokens?
tags.
The templates for font style ac-curacy improvement consist of those from study-ing the data and all templates using all featureswithin a window of five tokens (i.e., two preced-ing tokens, the current token, and two followingtokens).
For tagging accuracy improvement, weprepared the transformation templates by studyingdictionaries and errors in the entry tagging results.The objective function for evaluating transforma-tions in both cases is the classification accuracy,and the objective is to minimize the number of er-rors.5 ExperimentsWe performed our experiments on a Cebuano-English dictionary (Wolff, 1972) consisting of1163 pages, 4 font styles, and 18 tags, and onan Iraqi Arabic-English dictionary (Woodhead andBeene, 2003) consisting of 507 pages, 3 fontstyles, and 26 tags.
For our experiments, we useda publicly available implementation of TBL?s fastversion, fnTBL7, described in Section 3.We used eight randomly selected pages from thedictionaries to train TBL, and six additional ran-domly selected pages for testing.
The font styleand tag of each token on these pages are manuallycorrected from an initial run.
Our goal is to mea-sure the effect of TBL on font style and taggingthat have the same noisy input.
For the Cebuanodictionary, the training data contains 156 entries,8370 tokens, and 6691 non-punctuation tokens,and the test data contains 137 entries, 6251 tokens,and 4940 non-punctuation tokens.
For the IraqiArabic dictionary, the training data contains 232entries, 6130 tokens, and 4621 non-punctuationtokens, and the test data contains 175 entries, 4708tokens, 3467 non-punctuation tokens.For evaluation, we used the percentage of accu-racy for non-punctuation tokens, i.e., the numberof correctly identified tags divided by total num-ber of tokens/phrases.
The learning phase of TBLtook less than one minute for each run, and ap-plication of learned transformations to the wholedictionary less than two minutes.We report how TBL affects accuracy of tagging7http://nlp.cs.jhu.edu/rflorian/fntblwhen applied to font styles, tags, and font stylesand tags together.
To find the upper bound tag-ging results with correct font styles, we also ranrule-based entry tagger using manually correctedfont styles, and applied TBL for tagging accuracyimprovement to these results.
We should note thatfeeding the correct font to the rule-based entry tag-ger does not necessarily mean the data is totallycorrect, it may still contain noise from documentimage analysis or ambiguity in the entry.We conducted three sets of experiments to ob-serve the effects of TBL (Section 5.1), the effectsof different training data (Section 5.2), and the ef-fects of training data size (Section 5.3).5.1 TBL on Font Styles and TagsCebuano Iraqi ArabicOriginal 84.43 94.15TBL(font) 97.07 98.13Table 1: Font style accuracy results for non-punctuation tokensWe report the accuracy of font styles on the testdata before and after applying TBL to the fontstyle of the non-punctuation tokens in Table 1.
Theinitial font style accuracy of Cebuano dictionarywas much less than the Iraqi Arabic dictionary, butapplying TBL resulted in similar font style accu-racy for both dictionaries (97% and 98%).Cebuano Iraqi ArabicToken Phrase Token PhraseRB 83.25 64.08 90.89 82.72RB+TBL(tag) 91.44 87.37 94.05 92.33TBL(font)+RB 87.99 72.44 91.46 83.48TBL(font)+RB+TBL(tag) 93.06 90.19 94.30 92.58GT(font)+RB 90.76 74.71 91.74 83.90GT(font)+RB+TBL(tag) 95.74 92.29 94.54 93.11Table 2: Tagging accuracy results for non-punctu-ation tokens and phrases for two dictionariesThe results of tagging accuracy experimentsare presented in Table 2.
In the tables, RB isrule-based method, TBL(tag) is the TBL run ontags, TBL(font) is the TBL run on font style, andGT(font) is the ground truth font style.
In eachcase, we begin with font style information pro-vided by document image analysis.
We tabulatepercentages of tagging accuracy of individual non-punctuation tokens and phrases8.
The results for8In phrase accuracy, if a group of consequent tokens isassigned one tag as a phrase in the ground truth, the taggingof the phrase is considered correct only if the same group of260token and phrase accuracy are presented for threedifferent sets: The entry tagger using the fontstyle (1) provided by document image analysis,(2) after TBL is applied to font style, and (3) cor-rected manually, i.e.
the ground truth.
All re-sults reported, except the token accuracies for twocases for the Iraqi Arabic dictionary, namely us-ing TBL(font) vs. GT(font) and using TBL(font)and TBL(tag) together vs. using GT(font) andTBL(tag), are statistically significant within the95% confidence interval with two-tailed paired t-tests9.Using TBL(font) instead of initial font stylesimproved initial accuracy as much as 4.74% fortokens, and 8.36% for phrases in the Cebuano dic-tionary which has a much lower initial font styleaccuracy than the Iraqi Arabic dictionary.
Usingthe GT(font) further increased the tagging accu-racy by 2.77% for tokens and 2.27% for phrasesfor the Cebuano dictionary.
As for the Iraqi Ara-bic dictionary, using TBL(font) and GT(font) re-sulted in an improvement of 0.57% and 0.85% fortokens and 0.74% and 1.18% for phrases respec-tively.
The improvements in these two dictionar-ies differ because the initial font style accuracyfor the Iraqi Arabic dictionary is very high whilefor the Cebuano dictionary potentially very usefulfont style information (namely, the font style forPOS tokens) is often incorrect in the initial run.Using TBL(tag) alone improved rule-basedmethod results by 8.19% and 3.16% for tokensand by 23.25% and 9.61% for phrases in Cebuanoand Iraqi Arabic dictionaries respectively.
The lasttwo rows in Table 2 show the upper bound.
Forthe two dictionaries, our results using TBL(font)and TBL(tag) together is 2.68% and 0.24% fortoken accuracy and 2.10% and 0.53% for phraseaccuracy less than the upper bound of using theGT(font) and TBL(tag) together.Applying TBL to font styles resulted in a higheraccuracy than applying TBL to tagging.
Since thenumber of tag types (18 and 26) is much largerthan that of font style types (4 and 3), TBL appli-cation on tags requires more training data than thefont style to perform as well as TBL applicationon font style.In summary, applying TBL using the same tem-plates to two different dictionaries using very lim-ited training data resulted in performance increase,tokens was assigned the same tag as a phrase in the result.9We did the t-tests on the results of individual entries.and the greatest increases we observed are inphrase accuracy.
Applying TBL to font style firstincreased the accuracy even further.5.2 Effect of Training DataWe conducted experiments to measure the robust-ness of our method with different training data.For this purpose, we trained TBL on eight pagesrandomly selected from the 14 pages for which wehave ground truth, for each dictionary.
We usedthe remaining six pages for testing.
We did this tentimes, and calculated the average accuracy and thestandard deviation.
Table 3 presents the averageaccuracy and standard deviation.
The accuracy re-sults are consistent with the results we presentedin Table 2, and the standard deviation is between0.56-2.28.
These results suggest that using differ-ent training data does not affect the performancedramatically.5.3 Effect of Training Data SizeThe problem to which we apply TBL has one im-portant challenge and differs from other tasks inwhich TBL has been applied.
Each dictionary hasa different structure and different noise patterns,hence, TBL must be trained for each dictionary.This requires preparing ground truth manually foreach dictionary before applying TBL.
Moreover,although each dictionary has hundreds of pages, itis not feasible to use a significant portion of thedictionary for training.
Therefore the training datashould be small enough for someone to annotateground truth in a short amount of time.
One of ourgoals is to calculate the quantity of training datanecessary for a reasonable improvement in taggingaccuracy.
For this purpose, we investigated theeffect of the training data size by increasing thetraining data size for TBL one entry at a time.
Theentries are added in the order of the number of er-rors they contain, starting with the entry with max-imum errors.
We then tested the system trainedwith these entries on two test pages10.Figure 3 shows the number of font style and tag-ging errors for non-punctuation tokens on two testpages as a function of the number of entries in thetraining data.
The tagging results are presentedwhen using font style from document image anal-ysis and font style after TBL.
In these graphs, the10We used two test data pages because if such a methodwill determine the minimum training data required to obtaina reasonable performance, the test data should be extremelylimited to reduce human provided data.261Cebuano Iraqi ArabicToken Phrase Token PhraseRB 81.46?1.14 62.38?1.09 92.10?0.69 85.05?1.64RB + TBL(tag) 89.34?0.96 85.17?1.55 94.94?0.56 93.25?0.87TBL(font) + RB 87.40?1.69 71.97?1.26 93.20?1.02 85.49?1.13TBL(font) + RB + TBL(tag) 93.13?1.58 90.48?0.80 94.88?0.56 93.03?0.70GT(font) + RB 89.25?1.57 73.13?1.02 93.02?0.58 85.03?2.28GT(font) + RB + TBL(tag) 95.31?1.43 91.89?1.80 95.32?0.65 93.36?0.81Table 3: Average tagging accuracy results with standard deviation for ten runs using different eight pagesfor training, and six pages for testing0501001502002503000 20 40 60 80 100 120 140Number of ErrorsNumber of Entries in Training Data for Cebuano Dictionary# of Errors in Font Style# of Errors in Tagging with TBL(tag)# of Errors in Tagging with TBL(font)-TBL(tag)0204060801001201401600 20 40 60 80 100 120Number of ErrorsinTest DataNumber of Entries in Training Data for Iraqi Arabic Dictionary# of Errors in Font Style# of Errors in Tagging with TBL(tag)# of Errors in Tagging with TBL(font)-TBL(tag)Figure 3: The number of errors in two test pages as a function of the number of entries in the trainingdata for two dictionariesnumber of errors declines dramatically with theaddition of the first entries.
For the tags, the de-cline is not as steep as the decline in font style.
Themain reason involves the number of tags (18 and26), which are more than the number of font styles(4 and 3).
The method of adding entries to train-ing data one by one, and finding the point whenthe number of errors on selected entries stabilizes,can determine minimum training data size to get areasonable performance increase.
lexicalized5.4 Example ResultsTable 4 presents some learned transformations forCebuano dictionary.
Table 5 shows how thesetransformations change the font style and tags oftokens from Figure 4.
The first column gives thetagging results before applying TBL.
The con-secutive columns shows how different TBL runschanges these results.
The tags with * indicateincorrect tags, the tags with + indicate correctedtags, and the tags with - indicate introduced er-rors.
The font style of tokens is also represented.The No column in Tables 4 and 5 gives the appliedtransformation number.For these entries, using TBL on font styles andtagging together gives correct results in all cases.Using TBL only on tagging gives the correct tag-ging only for the last entry.TBL introduces new errors in some cases.
Oneerror we observed occurs when an example of us-age translation is assigned a tag before any exam-ple of usage tag in an entry.
This case is illustratedwhen applying transformation 9 to the token Abaabecause of a misrecognized comma before the to-ken.6 ConclusionIn this paper, we introduced a new dictionary en-try tagging system in which TBL improves tag-ging accuracy.
TBL is applied at two points, ?on font style and tagging?
and yields high per-formance even with limited user provided trainingdata.
For two different dictionaries, we achievedan increase from 84% and 94% to 97% and 98%in font style accuracy, from 83% and 91% to 93%and 94% in tagging accuracy of tokens, and from64% and 83% to 90% and 93% in tagging accu-racy of phrases.
If the initial font style is not ac-curate, first improving font style with TBL furtherassisted the tagging accuracy as much as 2.62%for tokens and 2.82% for phrases compared to us-ing TBL only for tagging.
This result cannot be262No Triggering Environment Change To10 typen?2 = lowercase and typen?1 = punctuation and typen = capitalized and normalfontn+1 = normal and fontn+2 = normal15 fontn?1 = italic and typen = lowercase and typen+1 = lowercase and fontn+2 = italic italic18 tokenn = the first token in the entry bold1 tokenn = a and tagn?1 = translation and tagn+1 = translation translation4 tag[n?7,n?1] = example and tokenn?1 = , and fontn = bold example translation2 typen = lowercase and fontn = normal and tagn?1 = translation and fontn?1 = normal translation9 tokenn?1 = , and fontn = italic and typen = capitalized example translation8 tagn?2 = example translation and tagn?1 = separator and continuationtagn = example translation and typen = capitalized of a phrase11 tagn?2 = example and tagn?1 = separator and tagn = example and typen = capitalized continuation of a phraseTable 4: Some sample transformations used for Cebuano dictionary entries in Figure 4.
Here, continua-tion of a phrase indicates this token merges with the previous one to form a phrase.attributed to a low rule-based baseline as a simi-lar, even a slightly lower baseline is obtained froman HMM trained system.
Results came from amethod used to compensate for extremely lim-ited training data.
The similarity of performanceacross two different dictionaries shows the methodas adaptive and able to be applied genericly.In the future, we plan to investigate the sourcesof errors introduced by TBL and whether thesecan be avoided by post-processing TBL results us-ing heuristics.
We will also examine the effectsof using TBL to increase the training data size ina bootstrapped manner.
We will apply TBL toa few pages, then correct these and use them asnew training data in another run.
Since TBL im-proves accuracy, manually preparing training datawill take less time.AcknowledgementsThe partial support of this research under contractMDA-9040-2C-0406 is gratefully acknowledged.ReferencesEric Brill.
1995.
Transformation-based error-drivenlearning and natural language processing: A casestudy in part of speech tagging.
Computational Lin-guistics, 4(21):543?565.Radu Florian and Grace Ngai.
2001.
Multidimen-sional transformational-based learning.
Proceed-ings of the 5th Conference on Computational Nat-ural Language Learning, CoNLL 2001, pages 1?8,July.Pascale Fung and Lo Yuen Yee.
1998.
An IR approachfor translating new words from nonparallel, com-parable texts.
In Christian Boitet and Pete White-lock, editors, Proceedings of the 36th Annual Meet-ing of the Association for Computational Linguis-tics and 17th International Conference on Compu-tational Linguistics, pages 414?420, San Francisco,California.
Morgan Kaufmann Publishers.William A. Gale and Kenneth W. Church.
1991.
Aprogram for aligning sentences in bilingual corpora.In Proceedings of the 29th Annual Meeting of theACL, pages 177?184, Berkeley, California, June.Burcu Karagol-Ayan, David Doermann, and BonnieDorr.
2003.
Acquisition of bilingual MT lexiconsfrom OCRed dictionaries.
In Proceedings of the9th MT Summit, pages 208?215, New Orleans, LA,September.Huanfeng Ma and David Doermann.
2003.
Bootstrap-ping structured page segmentation.
In Proceedingsof SPIE Conference Document Recognition and Re-trieval, Santa Clara, CA, January.I.
Dan Melamed.
2000.
Models of translational equiv-alence among words.
Computational Linguistics,26(2):221?249, June.Grace Ngai and Radu Florian.
2001.
Transformation-based learning in the fast lane.
In Proceedings ofthe 2nd Conference of the North American Chap-ter of the Association for Computational Linguistics(NAACL), pages 40?47, Pittsburgh, PA, June.Philip Resnik.
1999.
Mining the web for bilingual text.In Proceedings of the 37th Annual Meeting of the As-sociation for Computational Linguistics (ACL?99),University of Maryland, College Park, Maryland,June.Takehito Utsuro, Takashi Horiuchi, Yasunobu Chiba,and Takeshi Hamamoto.
2002.
Semi-automaticcompilation of bilingual lexicon entries from cross-lingually relevant news articles on WWW newssites.
In Fifth Conference of the Association forMachine Translation in the Americas, AMTA-2002,pages 165?176, Tiburon, California.Piek Vossen.
1998.
EuroWordNet: A MultilingualDatabase with Lexical Semantic Networks.
KluwerAcademic Publishers, Dordrecht.John U. Wolff.
1972.
A Dictionary of Cebuano Visaya.Southeast Asia Program, Cornell University.
Ithaca,New York.D.
R. Woodhead and Wayne Beene, editors.
2003.A Dictionary of Iraqi Arabic: Arabic?English Dic-tionary.
Georgetown University Press, WashingtonD.C.263Figure 4: Cebuano-English dictionary entry samplesRB RB + TBL (tag) TBL (font) + RB TBL (font) + RB + TBL (tag)Tag Token(s) No Tag Token(s) No Tag Token(s) No Tag Token(s)abaa particle abaa particle 18 +hw abaa hw abaa*hw indicating *hw indicating +tr particle indicating tr particle indicatingdisapproval disapproval disapproval disapproval*ex Abaa!
9 -ex-tr Abaa!
*ex Abaa!
Abaa!
*ex Mahu?g ka *ex Mahu?g ka *ex Mahu?g ka 11 +ex Mahu?g kagani diha`!
gani diha`!
gani diha`!
gani diha`!
*ex-tr Stop that!
8 +ex-tr Stop that!
*ex-tr Stop that!
8 +ex-tr Stop that!
*ex-tr You might fall!
You might fall!
*ex-tr You might fall!
You might fall!
*tr emit emit a short grunt *tr emit emit a short grunt*pos a 1 when hit in *pos a 2 when hit inshort grunt when the pit of the short grunt when the pit of the*tr hit in the pit +tr stomach or *tr hit in the pit +tr stomach orof the stomach or when exerting of the stomach or when exertingwhen exerting an effort an effort when exerting an effort an effort*ex Miaguntu?
*ex Miaguntu?
Miaguntu?
Miaguntu?
*al-sp siya *al-sp siya 15 +ex siya ex siya*ex dihang naig *ex dihang naig dihang naig dihang naigsa kutukutu, sa kutukutu, sa kutukutu, sa kutukutu,*al-sp The 4 The 10 The The*ex-tr basketball court +ex-tr basketball court +ex-tr basketball court ex-tr basketball courtwill be asphalted.
will be asphalted.
will be asphalted.
will be asphalted.hw: headword; tr: translation; al-sp: alternative spelling of headword; pos: POS; ex: example of usage; ex-tr: example of usage translationTable 5: Illustration of TBL application to the incorrect tags in the sample entries shown in Figure 4.
* indicates incorrect tags, + indicates corrected tags, and - indicates introduced errors.264
