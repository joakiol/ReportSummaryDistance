Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 78?87,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsSITS: A Hierarchical Nonparametric Model using Speaker Identity forTopic Segmentation in Multiparty ConversationsViet-An NguyenDepartment of Computer Scienceand UMIACSUniversity of MarylandCollege Park, MDvietan@cs.umd.eduJordan Boyd-GraberiSchooland UMIACSUniversity of MarylandCollege Park, MDjbg@umiacs.umd.eduPhilip ResnikDepartment of Linguisticsand UMIACSUniversity of MarylandCollege Park, MDresnik@umd.eduAbstractOne of the key tasks for analyzing conversa-tional data is segmenting it into coherent topicsegments.
However, most models of topicsegmentation ignore the social aspect of con-versations, focusing only on the words used.We introduce a hierarchical Bayesian nonpara-metric model, Speaker Identity for Topic Seg-mentation (SITS), that discovers (1) the top-ics used in a conversation, (2) how these top-ics are shared across conversations, (3) whenthese topics shift, and (4) a person-specifictendency to introduce new topics.
We eval-uate against current unsupervised segmenta-tion models to show that including person-specific information improves segmentationperformance on meeting corpora and on po-litical debates.
Moreover, we provide evidencethat SITS captures an individual?s tendency tointroduce new topics in political contexts, viaanalysis of the 2008 US presidential debatesand the television program Crossfire.1 Topic Segmentation as a Social ProcessConversation, interactive discussion between two ormore people, is one of the most essential and com-mon forms of communication.
Whether in an in-formal situation or in more formal settings such asa political debate or business meeting, a conversa-tion is often not about just one thing: topics evolveand are replaced as the conversation unfolds.
Dis-covering this hidden structure in conversations is akey problem for conversational assistants (Tur et al,2010) and tools that summarize (Murray et al, 2005)and display (Ehlen et al, 2007) conversational data.Topic segmentation also can illuminate individuals?agendas (Boydstun et al, 2011), patterns of agree-ment and disagreement (Hawes et al, 2009; Abbottet al, 2011), and relationships among conversationalparticipants (Ireland et al, 2011).One of the most natural ways to capture conversa-tional structure is topic segmentation (Reynar, 1998;Purver, 2011).
Topic segmentation approaches rangefrom simple heuristic methods based on lexical simi-larity (Morris and Hirst, 1991; Hearst, 1997) to moreintricate generative models and supervised meth-ods (Georgescul et al, 2006; Purver et al, 2006;Gruber et al, 2007; Eisenstein and Barzilay, 2008),which have been shown to outperform the establishedheuristics.However, previous computational work on con-versational structure, particularly in topic discoveryand topic segmentation, focuses primarily on con-tent, ignoring the speakers.
We argue that, becauseconversation is a social process, we can understandconversational phenomena better by explicitly model-ing behaviors of conversational participants.
In Sec-tion 2, we incorporate participant identity in a newmodel we call Speaker Identity for Topic Segmen-tation (SITS), which discovers topical structure inconversation while jointly incorporating a participant-level social component.
Specifically, we explicitlymodel an individual?s tendency to introduce a topic.After outlining inference in Section 3 and introducingdata in Section 4, we use SITS to improve state-of-the-art-topic segmentation and topic identificationmodels in Section 5.
In addition, in Section 6, wealso show that the per-speaker model is able to dis-cover individuals who shape and influence the courseof a conversation.
Finally, we discuss related workand conclude the paper in Section 7.2 Modeling Multiparty DiscussionsData Properties We are interested in turn-taking,multiparty discussion.
This is a broad category, in-78cluding political debates, business meetings, and on-line chats.
More formally, such datasets contain Cconversations.
A conversation c has Tc turns, each ofwhich is a maximal uninterrupted utterance by onespeaker.1 In each turn t ?
[1, Tc], a speaker ac,t uttersN words {wc,t,n}.
Each word is from a vocabularyof size V , and there are M distinct speakers.Modeling Approaches The key insight of topicsegmentation is that segments evince lexical cohe-sion (Galley et al, 2003; Olney and Cai, 2005).Words within a segment will look more like theirneighbors than other words.
This insight has beenused to tune supervised methods (Hsueh et al, 2006)and inspire unsupervised models of lexical cohesionusing bags of words (Purver et al, 2006) and lan-guage models (Eisenstein and Barzilay, 2008).We too take the unsupervised statistical approach.It requires few resources and is applicable in manydomains without extensive training.
Like previ-ous approaches, we consider each turn to be a bagof words generated from an admixture of topics.Topics?after the topic modeling literature (Blei andLafferty, 2009)?are multinomial distributions overterms.
These topics are part of a generative modelposited to have produced a corpus.However, topic models alone cannot model the dy-namics of a conversation.
Topic models typically donot model the temporal dynamics of individual docu-ments, and those that do (Wang et al, 2008; Gerrishand Blei, 2010) are designed for larger documentsand are not applicable here because they assume thatmost topics appear in every time slice.Instead, we endow each turn with a binary latentvariable lc,t, called the topic shift.
This latent variablesignifies whether the speaker changed the topic of theconversation.
To capture the topic-controlling behav-ior of the speakers across different conversations, wefurther associate each speaker m with a latent topicshift tendency, pim.
Informally, this variable is in-tended to capture the propensity of a speaker to effecta topic shift.
Formally, it represents the probabilitythat the speakerm will change the topic (distribution)of a conversation.We take a Bayesian nonparametric ap-proach (Mu?ller and Quintana, 2004).
Unlike1Note the distinction with phonetic utterances, which bydefinition are bounded by silence.parametric models, which a priori fix the number oftopics, nonparametric models use a flexible numberof topics to better represent data.
Nonparametricdistributions such as the Dirichlet process (Ferguson,1973) share statistical strength among conversationsusing a hierarchical model, such as the hierarchicalDirichlet process (HDP) (Teh et al, 2006).2.1 Generative ProcessIn this section, we develop SITS, a generative modelof multiparty discourse that jointly discovers topicsand speaker-specific topic shifts from an unannotatedcorpus (Figure 1a).
As in the hierarchical Dirichletprocess (Teh et al, 2006), we allow an unboundednumber of topics to be shared among the turns of thecorpus.
Topics are drawn from a base distributionH over multinomial distributions over the vocabu-lary, a finite Dirichlet with symmetric prior ?.
Unlikethe HDP, where every document (here, every turn)draws a new multinomial distribution from a Dirich-let process, the social and temporal dynamics of aconversation, as specified by the binary topic shiftindicator lc,t, determine when new draws happen.The full generative process is as follows:1.
For speaker m ?
[1,M ], draw speaker shift probabilitypim ?
Beta(?)2.
Draw global probability measure G0 ?
DP(?,H)3.
For each conversation c ?
[1, C](a) Draw conversation distribution Gc ?
DP(?0, G0)(b) For each turn t ?
[1, Tc] with speaker ac,ti.
If t = 1, set the topic shift lc,t = 1.
Otherwise,draw lc,t ?
Bernoulli(piac,t).ii.
If lc,t = 1, draw Gc,t ?
DP (?c, Gc).
Other-wise, set Gc,t ?
Gc,t?1.iii.
For each word index n ?
[1, Nc,t]?
Draw ?c,t,n ?
Gc,t?
Draw wc,t,n ?
Multinomial(?c,t,n)The hierarchy of Dirichlet processes allows sta-tistical strength to be shared across contexts; withina conversation and across conversations.
The per-speaker topic shift tendency pim allows speaker iden-tity to influence the evolution of topics.To make notation concrete and aligned with thetopic segmentation, we introduce notation for seg-ments in a conversation.
A segment s of conver-sation c is a sequence of turns [?, ?
?]
such thatlc,?
= lc,?
?+1 = 1 and lc,t = 0, ?t ?
(?, ?
?].
Whenlc,t = 0, Gc,t is the same as Gc,t?1 and all topics (i.e.multinomial distributions over words) {?c,t,n} thatgenerate words in turn t and the topics {?c,t?1,n}that generate words in turn t?
1 come from the same79pim ?ac,2 ac,Tcwc,1,n wc,2,n wc,Tc,n?c,1,n ?c,2,n ?c,Tc,nGc,1 Gc,2 Gc,Tc?c lc,2 lc,TcGc?0G0?
HCMNc,1 Nc,2 Nc,Tc(a)?k??
pim ?ac,2 ac,Tcwc,1,nzc,1,n?c,1wc,2,nzc,2,n?c,2lc,2wc,Tc,nzc,Tc,n?c,Tclc,TcCKMNc,1 Nc,2 Nc,Tc(b)Figure 1: Graphical model representations of our proposed models: (a) the nonparametric version; (b) theparametric version.
Nodes represent random variables (shaded ones are observed), lines are probabilisticdependencies.
Plates represent repetition.
The innermost plates are turns, grouped in conversations.distribution.
Thus all topics used in a segment s aredrawn from a single distribution, Gc,s,Gc,s | lc,1, lc,2, ?
?
?
, lc,Tc , ?c, Gc ?
DP(?c, Gc) (1)For notational convenience, Sc denotes the num-ber of segments in conversation c, and st denotesthe segment index of turn t. We emphasize that allsegment-related notations are derived from the poste-rior over the topic shifts l and not part of the modelitself.Parametric Version SITS is a generalization of aparametric model (Figure 1b) where each turn hasa multinomial distribution over K topics.
In theparametric case, the number of topics K is fixed.Each topic, as before, is a multinomial distribution?1 .
.
.
?K .
In the parametric case, each turn t in con-versation c has an explicit multinomial distributionover K topics ?c,t, identical for turns within a seg-ment.
A new topic distribution ?
is drawn from aDirichlet distribution parameterized by ?
when thetopic shift indicator l is 1.The parametric version does not share strengthwithin or across conversations, unlike SITS.
Whenapplied on a single conversation without speaker iden-tity (all speakers are identical) it is equivalent to(Purver et al, 2006).
In our experiments (Section 5),we compare against both.3 InferenceTo find the latent variables that best explain observeddata, we use Gibbs sampling, a widely used Markovchain Monte Carlo inference technique (Neal, 2000;Resnik and Hardisty, 2010).
The state space is latentvariables for topic indices assigned to all tokens z ={zc,t,n} and topic shifts assigned to turns l = {lc,t}.We marginalize over all other latent variables.
Here,we only present the conditional sampling equations;for more details, see our supplement.23.1 Sampling Topic AssignmentsTo sample zc,t,n, the index of the shared topic as-signed to token n of turn t in conversation c, we needto sample the path assigning each word token to asegment-specific topic, each segment-specific topicto a conversational topic and each conversationaltopic to a shared topic.
For efficiency, we make useof the minimal path assumption (Wallach, 2008) togenerate these assignments.3 Under the minimal pathassumption, an observation is assumed to have beengenerated by using a new distribution if and only ifthere is no existing distribution with the same value.2 http://www.cs.umd.edu/?vietan/topicshift/appendix.pdf3We also investigated using the maximal assumption andfully sampling assignments.
We found the minimal path assump-tion worked as well as explicitly sampling seating assignmentsand that the maximal path assumption worked less well.80We use Nc,s,k to denote the number of tokens insegment s in conversation c assigned topic k; Nc,kdenotes the total number of segment-specific top-ics in conversation c assigned topic k and Nk de-notes the number of conversational topics assignedtopic k. TWk,w denotes the number of times theshared topic k is assigned to word w in the vocab-ulary.
Marginal counts are represented with ?
and?
represents all hyperparameters.
The conditionaldistribution for zc,t,n is P (zc,t,n = k | wc,t,n =w, z?c,t,n,w?c,t,n, l, ?)
?N?c,t,nc,st,k + ?cN?c,t,nc,k +?0N?c,t,nk +?KN?c,t,n?
+?N?c,t,nc,?
+?0N?c,t,nc,st,?
+ ?c?????
?TW?c,t,nk,w + ?TW?c,t,nk,?
+ V ?,1Vk new.
(2)Here V is the size of the vocabulary, K is the currentnumber of shared topics and the superscript ?c,t,ndenotes counts without considering wc,t,n.
In Equa-tion 2, the first factor is proportional to the probabilityof sampling a path according to the minimal path as-sumption; the second factor is proportional to thelikelihood of observing w given the sampled topic.Since an uninformed prior is used, when a new topicis sampled, all tokens are equiprobable.3.2 Sampling Topic ShiftsSampling the topic shift variable lc,t requires us toconsider merging or splitting segments.
We use kc,tto denote the shared topic indices of all tokens inturn t of conversation c; Sac,t,x to denote the num-ber of times speaker ac,t is assigned the topic shiftwith value x ?
{0, 1}; Jxc,s to denote the number oftopics in segment s of conversation c if lc,t = x andNxc,s,j to denote the number of tokens assigned to thesegment-specific topic j when lc,t = x.4 Again, thesuperscript ?c,t is used to denote exclusion of turn tof conversation c in the corresponding counts.Recall that the topic shift is a binary variable.
Weuse 0 to represent the case that the topic distributionis identical to the previous turn.
We sample thisassignment P (lc,t = 0 | l?c,t,w,k,a, ?)
?S?c,tac,t,0 + ?S?c,tac,t,?
+ 2??
?J0c,stc?J0c,stj=1 (N0c,st,j ?
1)!
?N0c,st,?x=1 (x?
1 + ?c).
(3)4Deterministically knowing the path assignments is the pri-mary efficiency motivation for using the minimal path assump-tion.
The alternative is to explicitly sample the path assignments,which is more complicated (for both notation and computation).This option is spelled in full detail in the supplementary material.In Equation 3, the first factor is proportional to theprobability of assigning a topic shift of value 0 tospeaker ac,t and the second factor is proportional tothe joint probability of all topics in segment st ofconversation c when lc,t = 0.The other alternative is for the topic shift to be1, which represents the introduction of a new distri-bution over topics inside an existing segment.
Wesample this as P (lc,t = 1 | l?c,t,w,k,a, ?)
?S?c,tac,t,1 + ?S?c,tac,t,?
+ 2????
?J1c,(st?1)c?J1c,(st?1)j=1 (N1c,(st?1),j ?
1)!
?N1c,(st?1),?x=1 (x?
1 + ?c)?J1c,stc?J1c,stj=1 (N1c,stj ?
1)!
?N1c,st,?x=1 (x?
1 + ?c)??
.
(4)As above, the first factor in Equation 4 is propor-tional to the probability of assigning a topic shift ofvalue 1 to speaker ac,t; the second factor in the bigbracket is proportional to the joint distribution of thetopics in segments st ?
1 and st.
In this case lc,t = 1means splitting the current segment, which results intwo joint probabilities for two segments.4 DatasetsThis section introduces the three corpora we use.
Wepreprocess the data to remove stopwords and removeturns containing fewer than five tokens.The ICSI Meeting Corpus: The ICSI MeetingCorpus (Janin et al, 2003) is 75 transcribed meetings.For evaluation, we used a standard set of referencesegmentations (Galley et al, 2003) of 25 meetings.Segmentations are binary, i.e., each point of the doc-ument is either a segment boundary or not, and onaverage each meeting has 8 segment boundaries.
Af-ter preprocessing, there are 60 unique speakers andthe vocabulary contains 3346 non-stopword tokens.The 2008 Presidential Election Debates Our sec-ond dataset contains three annotated presidential de-bates (Boydstun et al, 2011) between Barack Obamaand John McCain and a vice presidential debate be-tween Joe Biden and Sarah Palin.
Each turn is oneof two types: questions (Q) from the moderator orresponses (R) from a candidate.
Each clause in aturn is coded with a Question Topic (TQ) and a Re-sponse Topic (TR).
Thus, a turn has a list of TQ?s andTR?s both of length equal to the number of clauses inthe turn.
Topics are from the Policy Agendas Topics81Speaker Type Turn clauses TQ TRBrokaw Q Sen. Obama, [.
.
. ]
Are you saying [.
.
. ]
that the American economy is going to get much worsebefore it gets better and they ought to be prepared for that?1 N/AObama RNo, I am confident about the American economy.
1 1[.
.
. ]
But most importantly, we?re going to have to help ordinary families be able to stay in theirhomes, make sure that they can pay their bills [.
.
.
]1 14Brokaw Q Sen. McCain, in all candor, do you think the economy is going to get worse before it gets better?
1 N/AMcCain R[.
.
. ]
I think if we act effectively, if we stabilize the housing market?which I believe we can, 1 14if we go out and buy up these bad loans, so that people can have a new mortgage at the new valueof their home1 14I think if we get rid of the cronyism and special interest influence in Washington so we can actmore effectively.
[.
.
.
]1 20Table 1: Example turns from the annotated 2008 election debates.
The topics (TQ and TR) are from the PolicyAgendas Topics Codebook which contains the following codes of topic: Macroeconomics (1), Housing &Community Development (14), Government Operations (20).Codebook, a manual inventory of 19 major topicsand 225 subtopics.5 Table 1 shows an example anno-tation.To get reference segmentations, we assign eachturn a real value from 0 to 1 indicating how much aturn changes the topic.
For a question-typed turn, thescore is the fraction of clause topics not appearing inthe previous turn; for response-typed turns, the scoreis the fraction of clause topics that do not appear inthe corresponding question.
This results in a set ofnon-binary reference segmentations.
For evaluationmetrics that require binary segmentations, we createa binary segmentation by setting a turn as a segmentboundary if the computed score is 1.
This thresholdis chosen to include only true segment boundaries.CNN?s Crossfire Crossfire was a weekly U.S. tele-vision ?talking heads?
program engineered to inciteheated arguments (hence the name).
Each episodefeatures two recurring hosts, two guests, and clipsfrom the week?s news.
Our Crossfire dataset con-tains 1134 transcribed episodes aired between 2000and 2004.6 There are 2567 unique speakers.
Unlikethe previous two datasets, Crossfire does not haveexplicit topic segmentations, so we use it to explorespeaker-specific characteristics (Section 6).5 Topic Segmentation ExperimentsIn this section, we examine how well SITS can repli-cate annotations of when new topics are introduced.5 http://www.policyagendas.org/page/topic-codebook6 http://www.cs.umd.edu/?vietan/topicshift/crossfire.zipWe discuss metrics for evaluating an algorithm?s seg-mentation against a gold annotation, describe ourexperimental setup, and report those results.Evaluation Metrics To evaluate segmentations,we use Pk (Beeferman et al, 1999) and WindowDiff(WD) (Pevzner and Hearst, 2002).
Both metrics mea-sure the probability that two points in a documentwill be incorrectly separated by a segment boundary.Both techniques consider all spans of length k in thedocument and count whether the two endpoints ofthe window are (im)properly segmented against thegold segmentation.However, these metrics have drawbacks.
First,they require both hypothesized and reference seg-mentations to be binary.
Many algorithms (e.g., prob-abilistic approaches) give non-binary segmentationswhere candidate boundaries have real-valued scores(e.g., probability or confidence).
Thus, evaluationrequires arbitrary thresholding to binarize soft scores.To be fair, thresholds are set so the number of seg-ments are equal to a predefined value (Purver et al,2006; Galley et al, 2003).To overcome these limitations, we also use EarthMover?s Distance (EMD) (Rubner et al, 2000), ametric that measures the distance between two distri-butions.
The EMD is the minimal cost to transformone distribution into the other.
Each segmentationcan be considered a multi-dimensional distributionwhere each candidate boundary is a dimension.
InEMD, a distance function across features allows par-tial credit for ?near miss?
segment boundaries.
In82addition, because EMD operates on distributions, wecan compute the distance between non-binary hy-pothesized segmentations with binary or real-valuedreference segmentations.
We use the FastEMD im-plementation (Pele and Werman, 2009).Experimental Methods We applied the followingmethods to discover topic segmentations in a docu-ment:?
TextTiling (Hearst, 1997) is one of the earliest general-purpose topic segmentation algorithms, sliding a fixed-width window to detect major changes in lexical similarity.?
P-NoSpeaker-S: parametric version without speaker iden-tity run on each conversation (Purver et al, 2006)?
P-NoSpeaker-M: parametric version without speakeridentity run on all conversations?
P-SITS: the parametric version of SITS with speaker iden-tity run on all conversations?
NP-HMM: the HMM-based nonparametric model whicha single topic per turn.
This model can be considered aSticky HDP-HMM (Fox et al, 2008) with speaker identity.?
NP-SITS: the nonparametric version of SITS with speakeridentity run on all conversations.Parameter Settings and Implementations In ourexperiment, all parameters of TextTiling are thesame as in (Hearst, 1997).
For statistical models,Gibbs sampling with 10 randomly initialized chainsis used.
Initial hyperparameter values are sampledfrom U(0, 1) to favor sparsity; statistics are collectedafter 500 burn-in iterations with a lag of 25 itera-tions over a total of 5000 iterations; and slice sam-pling (Neal, 2003) optimizes hyperparameters.Results and Analysis Table 2 shows the perfor-mance of various models on the topic segmentationproblem, using the ICSI corpus and the 2008 debates.Consistent with previous results, probabilisticmodels outperform TextTiling.
In addition, amongthe probabilistic models, the models that had accessto speaker information consistently segment betterthan those lacking such information, supporting ourassertion that there is benefit to modeling conversa-tion as a social process.
Furthermore, NP-SITS out-performs NP-HMM in both experiments, suggestingthat using a distribution over topics to turns is bet-ter than using a single topic.
This is consistent withparametric results reported in (Purver et al, 2006).The contribution of speaker identity seems morevaluable in the debate setting.
Debates are character-ized by strong rewards for setting the agenda; dodg-ing a question or moving the debate toward an oppo-nent?s weakness can be useful strategies (Boydstunet al, 2011).
In contrast, meetings (particularly low-stakes ICSI meetings) are characterized by pragmaticrather than strategic topic shifts.
Second, agenda-setting roles are clearer in formal debates; a modera-tor is tasked with setting the agenda and ensuring theconversation does not wander too much.The nonparametric model does best on the smallerdebate dataset.
We suspect that an evaluation thatdirectly accessed the topic quality, either via predic-tion (Teh et al, 2006) or interpretability (Chang et al,2009) would favor the nonparametric model more.6 Evaluating Topic Shift TendencyIn this section, we focus on the ability of SITS tocapture speaker-level attributes.
Recall that SITSassociates with each speaker a topic shift tendencypi that represents the probability of asserting a newtopic in the conversation.
While topic segmentationis a well studied problem, there are no establishedquantitative measurements of an individual?s abilityto control a conversation.
To evaluate whether thetendency is capturing meaningful characteristics ofspeakers, we compare our inferred tendencies againstinsights from political science.2008 Elections To obtain a posterior estimate of pi(Figure 3) we create 10 chains with hyperparameterssampled from the uniform distribution U(0, 1) andaveraged pi over 10 chains (as described in Section 5).In these debates, Ifill is the moderator of the debatebetween Biden and Palin; Brokaw, Lehrer and Schief-fer are the three moderators of three debates betweenObama and McCain.
Here ?Question?
denotes ques-tions from audiences in ?town hall?
debate.
The roleof this ?speaker?
can be considered equivalent to thedebate moderator.The topic shift tendencies of moderators aremuch higher than for candidates.
In the three de-bates between Obama and McCain, the moderators?Brokaw, Lehrer and Schieffer?have significantlyhigher scores than both candidates.
This is a usefulreality check, since in a debate the moderators arethe ones asking questions and literally controlling thetopical focus.
Interestingly, in the vice-presidentialdebate, the score of moderator Ifill is only slightlyhigher than those of Palin and Biden; this is consis-tent with media commentary characterizing her as a83Model EMDPk WindowDiffk = 5 10 15 k = 5 10 15ICSIDatasetTextTiling 2.507 .289 .388 .451 .318 .477 .561P-NoSpeaker-S 1.949 .222 .283 .342 .269 .393 .485P-NoSpeaker-M 1.935 .207 .279 .335 .253 .371 .468P-SITS 1.807 .211 .251 .289 .256 .363 .434NP-HMM 2.189 .232 .257 .263 .267 .377 .444NP-SITS 2.126 .228 .253 .259 .262 .372 .440DebatesDataset TextTiling 2.821 .433 .548 .633 .534 .674 .760P-NoSpeaker-S 2.822 .426 .543 .653 .482 .650 .756P-NoSpeaker-M 2.712 .411 .522 .589 .479 .644 .745P-SITS 2.269 .380 .405 .402 .482 .625 .719NP-HMM 2.132 .362 .348 .323 .486 .629 .723NP-SITS 1.813 .332 .269 .231 .470 .600 .692Table 2: Results on the topic segmentation task.Lower is better.
The parameter k is the windowsize of the metrics Pk and WindowDiff chosen toreplicate previous results.0 0.1 0.2 0.3 0.4IFILLBIDENPALINOBAMAMCCAINBROKAWLEHRERSCHIEFFERQUESTIONTable 3: Topic shift tendency pi of speakers in the2008 Presidential Election Debates (larger meansgreater tendency)weak moderator.7 Similarly, the ?Question?
speakerhad a relatively high variance, consistent with anamalgamation of many distinct speakers.These topic shift tendencies suggest that all can-didates manage to succeed at some points in settingand controlling the debate topics.
Our model givesObama a slightly higher score than McCain, consis-tent with social science claims (Boydstun et al, 2011)that Obama had the lead in setting the agenda overMcCain.
Table 4 shows of SITS-detected topic shifts.Crossfire Crossfire, unlike the debates, has manyspeakers.
This allows us to examine more closelywhat we can learn about speakers?
topic shift ten-dency.
We verified that SITS can segment topics,and assuming that changing the topic is useful for aspeaker, how can we characterize who does so effec-tively?
We examine the relationship between topicshift tendency, social roles, and political ideology.To focus on frequent speakers, we filter out speak-ers with fewer than 30 turns.
Most speakers haverelatively small pi, with the mode around 0.3.
Thereare, however, speakers with very high topic shifttendencies.
Table 5 shows the speakers having thehighest values according to SITS.We find that there are three general patterns forwho influences the course of a conversation in Cross-fire.
First, there are structural ?speakers?
the showuses to frame and propose new topics.
These are7 http://harpers.org/archive/2008/10/hbc-90003659audience questions, news clips (e.g.
many of Gore?sand Bush?s turns from 2000), and voice overs.
ThatSITS is able to recover these is reassuring.
Second,the stable of regular hosts receives high topic shifttendencies, which is reasonable given their experi-ence with the format and ostensible moderation roles(in practice they also stoke lively discussion).The remaining class is more interesting.
The re-maining non-hosts with high topic shift tendency arerelative moderates on the political spectrum:?
John Kasich, one of few Republicans to support the assaultweapons ban and now governor of Ohio, a swing state?
Christine Todd Whitman, former Republican governor ofNew Jersey, a very Democratic state?
John McCain, who before 2008 was known as a ?maverick?for working with Democrats (e.g.
Russ Feingold)This suggests that, despite Crossfire?s tendency tocreate highly partisan debates, those who are able towork across the political spectrum may best be ableto influence the topic under discussion in highly po-larized contexts.
Table 4 shows detected topic shiftsfrom these speakers; two of these examples (McCainand Whitman) show disagreement of Republicanswith President Bush.
In the other, Kasich is defend-ing a Republican plan (school vouchers) popular withtraditional Democratic constituencies.7 Related and Future WorkIn the realm of statistical models, a number of tech-niques incorporate social connections and identity toexplain content in social networks (Chang and Blei,84Previous turn Turn detected as shifting topicDebatesDatasetPALIN: Your question to him was whether he sup-ported gay marriage and my answer is the same ashis and it is that I do not.IFILL: Wonderful.
You agree.
On that note, let?s move to foreign policy.
Youboth have sons who are in Iraq or on their way to Iraq.
You, Governor Palin,have said that you would like to see a real clear plan for an exit strategy.
[.
.
.
]MCCAIN: I think that Joe Biden is qualified inmany respects.
.
.
.SCHIEFFER: [.
.
. ]
Let?s talk about energy and climate control.
Every presidentsince Nixon has said what both of you [.
.
.
]IFILL: So, Governor, as vice president, there?snothing that you have promised [.
.
. ]
that youwouldn?t take off the table because of this finan-cial crisis we?re in?BIDEN: Again, let me?let?s talk about those tax breaks.
[Obama] voted for anenergy bill because, for the first time, it had real support for alternative energy.[.
.
. ]
on eliminating the tax breaks for the oil companies, Barack Obama votedto eliminate them.
[.
.
.
]CrossfireDatasetPRESS: But what do you say, governor, to Gov-ernor Bush and [.
.
. ]
your party who would letpoliticians and not medical scientists decide whatdrugs are distributed [.
.
.
]WHITMAN: Well I disagree with them on this particular issues [.
.
. ]
that?simportant to me that George Bush stands for education of our children [.
.
. ]
Icare about tax policy, I care about the environment.
I care about all the issueswhere he has a proven record in Texas [.
.
.
]WEXLER: [.
.
. ]
They need a Medicare prescrip-tion drug plan [.
.
. ]
Talk about schools, [.
.
. ]
AlGore has got a real plan.
George Bush offers usvouchers.
Talk about the environment.
[.
.
. ]
AlGore is right on in terms of the majority of Ameri-cans, but George Bush [.
.
.
]KASICH: [.
.
. ]
I want to talk about choice.
[.
.
. ]
George Bush believes that, ifschools fail, parents ought to have a right to get their kids out of those schoolsand give them a chance and an opportunity for success.
Gore says ?no way?
[.
.
.
]Social Security.
George Bush says [.
.
. ]
direct it the way federal employees do[.
.
. ]
Al Gore says ?No way?
[.
.
. ]
That?s real choice.
That?s real bottom-up,not a bureaucratic approach, the way we run this country.PRESS: Senator, Senator Breaux mentioned thatit?s President Bush?s aim to start on education [.
.
.
][McCain] [.
.
. ]
said he was going to do introducethe legislation the first day of the first week of thenew administration.
[.
.
.
]MCCAIN: After one of closest elections in our nation?s history, there is onething the American people are unanimous about They want their governmentback.
We can do that by ridding politics of large, unregulated contributions thatgive special interests a seat at the table while average Americans are stuck in theback of the room.Table 4: Example of turns designated as a topic shift by SITS.
Turns were chosen with speakers to giveexamples of those with high topic shift tendency pi.Rank Speaker pi Rank Speaker pi1 Announcer .884 10 Kasich .5702 Male .876 11 Carville?
.5503 Question .755 12 Carlson?
.5504 G. W. Bush?
.751 13 Begala?
.5455 Press?
.651 14 Whitman .5336 Female .650 15 McAuliffe .5297 Gore?
.650 16 Matalin?
.5278 Narrator .642 17 McCain .5249 Novak?
.587 18 Fleischer .522Table 5: Top speakers by topic shift tendencies.
Wemark hosts (?)
and ?speakers?
who often (but not al-ways) appeared in clips (?).
Apart from those groups,speakers with the highest tendency were politicalmoderates.2009) and scientific corpora (Rosen-Zvi et al, 2004).However, these models ignore the temporal evolutionof content, treating documents as static.Models that do investigate the evolution of topicsover time typically ignore the identify of the speaker.For example: models having sticky topics over n-grams (Johnson, 2010), sticky HDP-HMM (Fox et al,2008); models that are an amalgam of sequentialmodels and topic models (Griffiths et al, 2005; Wal-lach, 2006; Gruber et al, 2007; Ahmed and Xing,2008; Boyd-Graber and Blei, 2008; Du et al, 2010);or explicit models of time or other relevant featuresas a distinct latent variable (Wang and McCallum,2006; Eisenstein et al, 2010).In contrast, SITS jointly models topic and individ-uals?
tendency to control a conversation.
Not onlydoes SITS outperform other models using standardcomputational linguistics baselines, but it also pro-poses intriguing hypotheses for social scientists.Associating each speaker with a scalar that mod-els their tendency to change the topic does improveperformance on standard tasks, but it?s inadequate tofully describe an individual.
Modeling individuals?perspective (Paul and Girju, 2010), ?side?
(Thomaset al, 2006), or personal preferences for topics (Grim-mer, 2009) would enrich the model and better illumi-nate the interaction of influence and topic.Statistical analysis of political discourse can helpdiscover patterns that political scientists, who oftenwork via a ?close reading,?
might otherwise miss.We plan to work with social scientists to validateour implicit hypothesis that our topic shift tendencycorrelates well with intuitive measures of ?influence.
?85AcknowledgementsThis research was funded in part by the Army Re-search Laboratory through ARL Cooperative Agree-ment W911NF-09-2-0072 and by the Office of theDirector of National Intelligence (ODNI), Intelli-gence Advanced Research Projects Activity (IARPA),through the Army Research Laboratory.
JordanBoyd-Graber and Philip Resnik are also supportedby US National Science Foundation Grant NSF grant#1018625.
Any opinions, findings, conclusions, orrecommendations expressed are the authors?
and donot necessarily reflect those of the sponsors.References[Abbott et al, 2011] Abbott, R., Walker, M., Anand, P.,Fox Tree, J. E., Bowmani, R., and King, J.
(2011).
Howcan you say such things?!?
: Recognizing disagreementin informal political argument.
In Proceedings of theWorkshop on Language in Social Media (LSM 2011),pages 2?11.
[Ahmed and Xing, 2008] Ahmed, A. and Xing, E. P.(2008).
Dynamic non-parametric mixture models andthe recurrent Chinese restaurant process: with applica-tions to evolutionary clustering.
In SDM, pages 219?230.
[Beeferman et al, 1999] Beeferman, D., Berger, A., andLafferty, J.
(1999).
Statistical models for text segmen-tation.
Mach.
Learn., 34:177?210.
[Blei and Lafferty, 2009] Blei, D. M. and Lafferty, J.(2009).
Text Mining: Theory and Applications, chapterTopic Models.
Taylor and Francis, London.
[Boyd-Graber and Blei, 2008] Boyd-Graber, J. and Blei,D.
M. (2008).
Syntactic topic models.
In Proceedingsof Advances in Neural Information Processing Systems.
[Boydstun et al, 2011] Boydstun, A. E., Phillips, C., andGlazier, R. A.
(2011).
It?s the economy again, stupid:Agenda control in the 2008 presidential debates.
Forth-coming.
[Chang and Blei, 2009] Chang, J. and Blei, D. M. (2009).Relational topic models for document networks.
InProceedings of Artificial Intelligence and Statistics.
[Chang et al, 2009] Chang, J., Boyd-Graber, J., Wang, C.,Gerrish, S., and Blei, D. M. (2009).
Reading tea leaves:How humans interpret topic models.
In Neural Infor-mation Processing Systems.
[Du et al, 2010] Du, L., Buntine, W., and Jin, H. (2010).Sequential latent dirichlet alocation: Discover underly-ing topic structures within a document.
In Data Mining(ICDM), 2010 IEEE 10th International Conference on,pages 148 ?157.
[Ehlen et al, 2007] Ehlen, P., Purver, M., and Niekrasz, J.(2007).
A meeting browser that learns.
In In: Pro-ceedings of the AAAI Spring Symposium on InteractionChallenges for Intelligent Assistants.
[Eisenstein and Barzilay, 2008] Eisenstein, J. and Barzi-lay, R. (2008).
Bayesian unsupervised topic segmenta-tion.
In Proceedings of the Conference on EmpiricalMethods in Natural Language Processing, Proceedingsof Emperical Methods in Natural Language Processing.
[Eisenstein et al, 2010] Eisenstein, J., O?Connor, B.,Smith, N. A., and Xing, E. P. (2010).
A latent variablemodel for geographic lexical variation.
In EMNLP?10,pages 1277?1287.
[Ferguson, 1973] Ferguson, T. S. (1973).
A Bayesian anal-ysis of some nonparametric problems.
The Annals ofStatistics, 1(2):209?230.
[Fox et al, 2008] Fox, E. B., Sudderth, E. B., Jordan, M. I.,and Willsky, A. S. (2008).
An hdp-hmm for systemswith state persistence.
In Proceedings of InternationalConference of Machine Learning.
[Galley et al, 2003] Galley, M., McKeown, K., Fosler-Lussier, E., and Jing, H. (2003).
Discourse segmenta-tion of multi-party conversation.
In Proceedings of theAssociation for Computational Linguistics.
[Georgescul et al, 2006] Georgescul, M., Clark, A., andArmstrong, S. (2006).
Word distributions for thematicsegmentation in a support vector machine approach.In Conference on Computational Natural LanguageLearning.
[Gerrish and Blei, 2010] Gerrish, S. and Blei, D. M.(2010).
A language-based approach to measuring schol-arly impact.
In Proceedings of International Confer-ence of Machine Learning.
[Griffiths et al, 2005] Griffiths, T. L., Steyvers, M., Blei,D.
M., and Tenenbaum, J.
B.
(2005).
Integrating topicsand syntax.
In Proceedings of Advances in NeuralInformation Processing Systems.
[Grimmer, 2009] Grimmer, J.
(2009).
A Bayesian Hier-archical Topic Model for Political Texts: MeasuringExpressed Agendas in Senate Press Releases.
PoliticalAnalysis, 18:1?35.
[Gruber et al, 2007] Gruber, A., Rosen-Zvi, M., andWeiss, Y.
(2007).
Hidden topic Markov models.
InArtificial Intelligence and Statistics.
[Hawes et al, 2009] Hawes, T., Lin, J., and Resnik, P.(2009).
Elements of a computational model for multi-party discourse: The turn-taking behavior of SupremeCourt justices.
Journal of the American Society for In-formation Science and Technology, 60(8):1607?1615.
[Hearst, 1997] Hearst, M. A.
(1997).
TextTiling: Segment-ing text into multi-paragraph subtopic passages.
Com-putational Linguistics, 23(1):33?64.86[Hsueh et al, 2006] Hsueh, P.-y., Moore, J. D., and Renals,S.
(2006).
Automatic segmentation of multiparty dia-logue.
In Proceedings of the European Chapter of theAssociation for Computational Linguistics.
[Ireland et al, 2011] Ireland, M. E., Slatcher, R. B., East-wick, P. W., Scissors, L. E., Finkel, E. J., and Pen-nebaker, J. W. (2011).
Language style matching pre-dicts relationship initiation and stability.
PsychologicalScience, 22(1):39?44.
[Janin et al, 2003] Janin, A., Baron, D., Edwards, J., El-lis, D., Gelbart, D., Morgan, N., Peskin, B., Pfau, T.,Shriberg, E., Stolcke, A., and Wooters, C. (2003).
TheICSI meeting corpus.
In IEEE International Confer-ence on Acoustics, Speech, and Signal Processing.
[Johnson, 2010] Johnson, M. (2010).
PCFGs, topic mod-els, adaptor grammars and learning topical collocationsand the structure of proper names.
In Proceedings ofthe Association for Computational Linguistics.
[Morris and Hirst, 1991] Morris, J. and Hirst, G. (1991).Lexical cohesion computed by thesaural relations asan indicator of the structure of text.
ComputationalLinguistics, 17:21?48.
[Mu?ller and Quintana, 2004] Mu?ller, P. and Quintana,F.
A.
(2004).
Nonparametric Bayesian data analysis.Statistical Science, 19(1):95?110.
[Murray et al, 2005] Murray, G., Renals, S., and Carletta,J.
(2005).
Extractive summarization of meeting record-ings.
In European Conference on Speech Communica-tion and Technology.
[Neal, 2000] Neal, R. M. (2000).
Markov chain samplingmethods for Dirichlet process mixture models.
Journalof Computational and Graphical Statistics, 9(2):249?265.
[Neal, 2003] Neal, R. M. (2003).
Slice sampling.
Annalsof Statistics, 31:705?767.
[Olney and Cai, 2005] Olney, A. and Cai, Z.
(2005).
Anorthonormal basis for topic segmentation in tutorial di-alogue.
In Proceedings of the Human Language Tech-nology Conference.
[Paul and Girju, 2010] Paul, M. and Girju, R. (2010).
Atwo-dimensional topic-aspect model for discoveringmulti-faceted topics.
In Association for the Advance-ment of Artificial Intelligence.
[Pele and Werman, 2009] Pele, O. and Werman, M.(2009).
Fast and robust earth mover?s distances.
InInternational Conference on Computer Vision.
[Pevzner and Hearst, 2002] Pevzner, L. and Hearst, M.
A.(2002).
A critique and improvement of an evaluationmetric for text segmentation.
Computational Linguis-tics, 28.
[Purver, 2011] Purver, M. (2011).
Topic segmentation.
InTur, G. and de Mori, R., editors, Spoken LanguageUnderstanding: Systems for Extracting Semantic Infor-mation from Speech, pages 291?317.
Wiley.
[Purver et al, 2006] Purver, M., Ko?rding, K., Griffiths,T.
L., and Tenenbaum, J.
(2006).
Unsupervised topicmodelling for multi-party spoken discourse.
In Pro-ceedings of the Association for Computational Linguis-tics.
[Resnik and Hardisty, 2010] Resnik, P. and Hardisty, E.(2010).
Gibbs sampling for the uninitiated.
TechnicalReport UMIACS-TR-2010-04, University of Maryland.http://www.lib.umd.edu/drum/handle/1903/10058.
[Reynar, 1998] Reynar, J. C. (1998).
Topic Segmentation:Algorithms and Applications.
PhD thesis, University ofPennsylvania.
[Rosen-Zvi et al, 2004] Rosen-Zvi, M., Griffiths, T. L.,Steyvers, M., and Smyth, P. (2004).
The author-topicmodel for authors and documents.
In Proceedings ofUncertainty in Artificial Intelligence.
[Rubner et al, 2000] Rubner, Y., Tomasi, C., and Guibas,L.
J.
(2000).
The earth mover?s distance as a metricfor image retrieval.
International Journal of ComputerVision, 40:99?121.
[Teh et al, 2006] Teh, Y. W., Jordan, M. I., Beal, M. J.,and Blei, D. M. (2006).
Hierarchical Dirichlet pro-cesses.
Journal of the American Statistical Association,101(476):1566?1581.
[Thomas et al, 2006] Thomas, M., Pang, B., and Lee, L.(2006).
Get out the vote: Determining support or op-position from Congressional floor-debate transcripts.In Proceedings of Emperical Methods in Natural Lan-guage Processing.
[Tur et al, 2010] Tur, G., Stolcke, A., Voss, L., Peters, S.,Hakkani-Tu?r, D., Dowding, J., Favre, B., Ferna?ndez,R., Frampton, M., Frandsen, M., Frederickson, C., Gra-ciarena, M., Kintzing, D., Leveque, K., Mason, S.,Niekrasz, J., Purver, M., Riedhammer, K., Shriberg, E.,Tien, J., Vergyri, D., and Yang, F. (2010).
The CALOmeeting assistant system.
Trans.
Audio, Speech andLang.
Proc., 18:1601?1611.
[Wallach, 2006] Wallach, H. M. (2006).
Topic modeling:Beyond bag-of-words.
In Proceedings of InternationalConference of Machine Learning.
[Wallach, 2008] Wallach, H. M. (2008).
Structured TopicModels for Language.
PhD thesis, University of Cam-bridge.
[Wang et al, 2008] Wang, C., Blei, D. M., and Heckerman,D.
(2008).
Continuous time dynamic topic models.
InProceedings of Uncertainty in Artificial Intelligence.
[Wang and McCallum, 2006] Wang, X. and McCallum, A.(2006).
Topics over time: a non-Markov continuous-time model of topical trends.
In Knowledge Discoveryand Data Mining, Knowledge Discovery and Data Min-ing.87
