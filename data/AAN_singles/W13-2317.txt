Proceedings of the 7th Linguistic Annotation Workshop & Interoperability with Discourse, pages 135?139,Sofia, Bulgaria, August 8-9, 2013. c?2013 Association for Computational LinguisticsTweet Conversation Annotation Toolwith a Focus on an Arabic Dialect, Moroccan DarijaStephen Tratz?, Douglas Briesch?, Jamal Laoudi?, and Clare Voss?
?Army Research Laboratory, Adelphi, MD 20783?ArtisTech, Inc., Fairfax, VA 22030{stephen.c.tratz.civ,douglas.m.briesch.civ,jamal.laoudi.ctr,clare.r.voss.civ}@mail.milAbstractThis paper presents the DATOOL, a graph-ical tool for annotating conversations con-sisting of short messages (i.e., tweets), andthe results we obtain in using it to annotatetweets for Darija, an historically unwrittenArabic dialect spoken by millions but nottaught in schools and lacking standardiza-tion and linguistic resources.With the DATOOL, a native-Darijaspeaker annotated hundreds of mixed-language and mixed-script conversationsat approximately 250 tweets per hour.
Theresulting corpus was used in developingand evaluating Arabic dialect classifiersdescribed briefly herein.The DATOOL supports downstream dis-course analysis of tweeted ?conversations?by mapping extracted relations such as,who tweets to whom in which language,into graph markup formats for analysis innetwork visualization tools.1 OverviewFor historically unwritten languages, few textualresources exist for developing NLP applicationssuch as machine translation engines.
Even whenaudio resources are available, difficulties arisewhen converting sound to text (Robinson andGadelii, 2003).
Increasingly, however, with thewidespread use of mobile phones, these languagesare being written in social media such as Twitter.Not only can these languages be written in multi-ple scripts, but conversations, and even individualmessages, often involve multiple languages.
Tobuild useful textual resources for documenting andtranslating these languages (e.g., bilingual dictio-naries), tools are needed to assist in language an-notation for this noisy, multiscript, multilingualform of communication.This paper presents the Dialect Annotation Tool(DATOOL), a graphical tool for annotating conver-sations consisting of short messages (i.e., tweets),and the results we obtain in using it to annotatetweets for Darija, an historically unwritten NorthAfrican Arabic dialect spoken by millions but nottaught in schools and lacking in standardardiza-tion and linguistic resources.
The DATOOL canretrieve the conversation for each tweet on a user?stimeline or via Apollo (Le et al 2011) and displaythe discourse, enabling annotators to make moreinformed decisions.
It has integrated classifiers forautomatically annotating data so a user can eitherverify or alter the automatically-generated annota-tions rather than start from scratch.
The tool canalso export annotated data to GEPHI (Bastian etal., 2009), an open source network visualizationtool with many layout algorithms, which will fa-cilitate future ?code-switching?
research.2 Tool Description2.1 Version 1.0The first version of the tool is depicted in Figure1.
It is capable of loading a collection of tweetsand extracting the full conversations they belongto.
Each conversation is displayed within its ownblock in the conversation display table.
An anno-tator can mark multiple tweets as Darija (or otherlanguage) by selecting multiple checkboxes in thelefthand side of the table.
Also, if a tweet is writ-ten in multiple languages, the annotator can anno-tate the different sections using the Message textbox below the conversation display table.The tool also calculates user and collection levelsummary statistics, which it displays below themain annotation section.We worked with a Darija-speaking annotatorduring the tool?s development, who providedvaluable feedback, helping to shape the overalldesign of the tool and improve its functionality.135Figure 1: The Dialect Annotation Tool (DATOOL) displaying a possible Twitter conversation.Data Annotation Using version 1.0, the annotatormarked up 3013 tweets from 3 users for the pres-ence of the Darija (approximately 1,000 per user),averaging about 250 tweets per hour.
Of the 1,400tweets with Arabic script, 1,013 contained Darija.This annotated data is used to evaluate the Arabicdialect classifier discussed in Section 3.2.2 Version 2.0The second version of the tool contains the ad-ditional ability to invoke pre-trained classificationmodels to automatically annotate tweets.
The tooldisplays the classifier?s judgment confidence nextto each tweet, and the user can set a minimal con-fidence threshold, below which automatic annota-tions are hidden.
Figure 2 illustrates the new clas-sification functionality.2.3 XML OutputThe DATOOL stores data in an XML-based for-mat that can be reloaded for continuing or re-vising annotation.
It can also export four differ-ent views of the data in Graph Exchange XMLFormat (GEXF), a format that can be read byGEPHI.
In the social network view, users arerepresented by nodes, and tweets are representedas directed edges between the nodes.
The in-formation network view displays tweets as nodeswith directed edges between time-ordered tweetswithin a conversation.
In the social-informationnetwork view, both users and tweets are repre-sented by nodes, and there are directed edges bothfrom tweet senders to their tweets and from tweetsto recipients.
The social-information network plusview provides all the information of both the so-cial network and the information network.3 ClassifierFor the second version of the DATOOL, we inte-grated an Arabic dialect classifier capable of dis-tinguishing among Darija, Egyptian, Gulf, Lev-antine and MSA with the goal of improving thespeed and consistency of the annotation process.Though language classification is sometimesviewed as a solved problem (McNamee, 2005),with some experiments achieving over 99% ac-curacy (Cavnar and Trenkle, 1994), it is signifi-cantly more difficult when distinguishing closely-related languages or short texts (Vatanen et al2010; da Silva and Lopes, 2006).
The only lan-guage classification work for distinguishing be-tween these closely-related Arabic dialects thatwe are aware of was performed by Zaidan andCallison-Burch (2013).
They collected web com-mentary data written in MSA, Egyptian, Levan-tine, and Gulf and performed dialect identifica-tion experiments, their strongest classifier achiev-136Figure 2: Screenshot showcasing the automatic classification output, including confidence values.ing 81.0% accuracy.3.1 Training DataSince Zaidan and Callison-Burch?s dataset in-cludes no Darija, we collected Darija exam-ples from the following sources to augment theirdataset: Moroccan jokes from noktazwina.com, web pages collected using Darija-specificquery terms with a popular search engine, and37,538 Arabic script commentary entries fromhespress.com (a Moroccan news website).Nearly all the joke (N=399) and query term(N=874) data contained Darija.
By contrast, thecommentary data was mostly MSA.
To extracta subset of the commentary entries most likelyto contain Darija, we applied an iterative, semi-supervised approach similar to that described byTratz and Sanfilippo (2007), in which the joke andquery term data were treated as initial seeds and,in each iteration, a small portion of commentarydata with the highest Darija scores were added tothe training set.
After having run this process toits completion, we examined 131 examples at in-tervals of 45 from the resulting ranked list of com-mentary.
The 62nd example was the first of theseto have been incorrectly classified as containingDarija.
We thus elected to assume all examples upto the 61st of the 131 contain Darija, for a total of2,745 examples (61*45=2,745).
As an additionalcheck, we examined two more commentary entriesfrom each of the 61 blocks, finding that 118 of 122contain Darija.3.2 Initial ClassifierThe integrated dialect classifier is a Maximum En-tropy model (Berger et al 1996) that we train us-ing the LIBLINEAR (Fan et al 2008) toolkit.In preprocessing, Arabic diacritics are removed,all non-alphabetic and non-Arabic script charac-ters are converted to whitespace, and sequences ofany repeating character are collapsed to a singlecharacter.
The following set of feature templatesare applied to each of the resulting whitespace-separated tokens:?
The full token?
?Shape?
of the token?all consonants are replaced bythe letter C, alefs by A, and waws and yehs by W?
First character plus the last character (if length ?
2)?
Character unigrams, bigrams, and trigrams?
The last character of the token plus the first characterof the next token?
Prefixes of length 1, 2, and 3?
Indicators that token starts with mA and?
ends with $?
the next token ends with $?
is length 5 or greater3.3 LDA ModelAs an exploratory effort, we investigated using La-tent Direchlet Allocation (LDA) (Blei et al 2003)as a method of language identification.
Unfor-tunately, using the aforementioned feature tem-plates, LDA produced topics that correspondedpoorly with the training data labels.
But, afterseveral iterations of feature engineering, the topicsbegan to reflect the dialect distinctions.
Our finalLDA model feature templates are listed below.?
The full token?
Indicators that the token contains?
theh; thal; zah; theh, thal, or zah?
Indicators the token is of length 5+ and starts with?
hah plus yeh, teh, noon, or alef?
seen plus yeh, teh, noon, or alef?
beh plus yeh, teh, noon, or alef?
ghain plus yeh, teh, or noon?
or kaf plus yeh, teh, or noon?
Indicators that token starts with mA and?
ends with $?
the next token ends with $?
is length 5 or greaterThe following features produced using the LDAmodel for each document are given to the Maxi-mum Entropy classifier: 1) indicator of the most-likely cluster, 2) product of scores for each pair ofclusters.3.4 Classifier EvaluationWe evaluated the versions of the classifier by ap-plying them to the annotated data discussed in137Section 2.1.
The initial classifier without theLDA-derived features achieved 96.9% precisionand 24.1% recall.
The version with LDA-derivedfeatures achieved 97.2% precision and 44.1% re-call, a substantial improvement.
Upon review, weconcluded that most cases where the classifier ?in-correctly?
selected the Darija label were due to er-rors in the gold standard.4 Analysis of Annotated ConversationsVisualization of Darija in ConversationsThe DATOOL may recover the conversation inwhich a tweet occurs, providing the annotator withthe tweet?s full, potentially-multilingual context.To visualize the distribution of Darija1 by scriptin ?1K tweets from each user?s conversations, theDATOOL transforms and exports annotated datainto a GEXF information network (cf.
Figure 3),which can be displayed in GEPHI.2 Currently,GEPHI displays at most one edge between any twonodes?GEPHI automatically augments the edge?sweight for each additional copy of the edge.The Darija in this user?s conversations, unlikeour two other users, is predominantly Romanized.With more data, we plan to assess the impact ofone user?s script and language choice on others.Figure 3: Information network visualization.Red?contains Romanized Darija; green?contains Arabic-script Darija; blue?no Darija.Code-SwitchingThe alternation of Darija with non-Darija in the1In our initial annotation work, words and tweets in lan-guages other than Darija received no markup.2GEPHI?s Force Atlas layout automatically positions sub-graphs by size, with larger ones further away from the center.information network (red and green nodes vs.blue nodes) within conversations is consistent withwell-known code-switching among Arabic speak-ers, extending spoken discourse into informalwriting (Bentahila and Davies, 1983; Redouane,2005).
Code-switching also appears within ourtweet corpus where Romanized Darija frequentlyalternates with French.
Given the prevalence ofcode-switching within tweets, future work will en-tail training a Roman-script classifier at the to-ken level.3 Since our DATOOL already supportstoken-level as well as multi-token, tweet-internalannotation in the mid-screen Message box, ourcurrent corpus provides a seed set for this effort.5 Conclusion and Future WorkThe DATOOL now supports semi-automated an-notation of tweet conversations for Darija.
Aswe scale the process of building low-resource lan-guage corpora, we will document its impact on an-notation time when few native speakers are avail-able, a condition also relevant and critical to pre-serving endangered languages.
We have begun ex-tending the classifier to support additional Arabicscript languages (e.g., Farsi, Urdu), leveraging re-sources from others (Bergsma et al 2012).Many other open questions remain regardingthe annotation process, the visualizations, and thehuman expert.
Which classified examples shouldthe language expert review?
When should an an-notator adjust the confidence threshold in the DA-TOOL?
For deeper linguistic analysis and code-switching prediction, would seeing participantsand tweets, turn by turn, in network diagrams suchas Figure 4 help experts understand new patternsemerging in tweet conversations?Figure 4: Social-Information Network Plus.3As described in Section 3, our current classifier works atthe tweet level and only on Arabic-script tweets.138AcknowledgmentsWe would like to thank Tarek Abdelzaher for allhis feedback regarding our work and guidance inusing Apollo.
We would also like to thank our re-viewers for their valuable comments and sugges-tions.ReferencesMathieu Bastian, Sebastien Heymann, and Mathieu Ja-comy.
2009.
Gephi: An Open Source Software forExploring and Manipulating Networks.
In Interna-tional AAAI Conference on Weblogs and Social Me-dia.Abdelali Bentahila and Eirlys E Davies.
1983.
TheSyntax of Arabic-French Code-Switching.
Lingua,59(4):301?330.Adam L. Berger, Vincent J. Della Pietra, andStephen A. Della Pietra.
1996.
A Maximum En-tropy Approach to Natural Language Processing.Computational Linguistics, 22(1):39?71.Shane Bergsma, Paul McNamee, Mossaab Bagdouri,Clayton Fink, and Theresa Wilson.
2012.
LanguageIdentification for Creating Language-Specific Twit-ter Collections.
In Proceedings of the 2012 Work-shop on Language in Social Media (LSM 2012),pages 65?74.David Blei, Andrew Ng, and Michael Jordan.
2003.Latent dirichlet alcation.
The Journal of MachineLearning Research, 3:993?1022.William B Cavnar and John M Trenkle.
1994.
N-gram-based text categorization.
Ann Arbor MI,48113(2):161?175.Joaquim Ferreira da Silva and Gabriel Pereira Lopes.2006.
Identification of document language is not yeta completely solved problem.
In Computational In-telligence for Modelling, Control and Automation,2006 and International Conference on IntelligentAgents, Web Technologies and Internet Commerce,International Conference on, pages 212?212.
IEEE.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin.
2008.
LIBLINEAR:A Library for Large Linear Classification.
Journalof Machine Learning Research, 9:1871?1874.Hieu Khac Le, Jeff Pasternack, Hossein Ahmadi,M.
Gupta, Y.
Sun, Tarek F. Abdelzaher, Jiawei Han,Dan Roth, Boleslaw K. Szymanski, and Sibel Adali.2011.
Apollo: Towards factfinding in participatorysensing.
In IPSN, pages 129?130.Paul McNamee.
2005.
Language identification: Asolved problem suitable for undergraduate instruc-tion.
Journal of Computing Sciences in Colleges,20(3):94?101.Rabia Redouane.
2005.
Linguistic constraints oncodeswitching and codemixing of bilingual Moroc-can Arabic-French speakers in Canada.
In ISB4:Proceedings of the 4th International Symposium onBilingualism, pages 1921?1933.Clinton Robinson and Karl Gadelii.
2003.
WritingUnwritten Languages, A Guide to the Process.http://portal.unesco.org/education/en/ev.php-URLID=28300&URL DO=DO TOPIC&URL SECTION=201.html, UNESCO, Paris, France.
December.Stephen Tratz and Antonio Sanfilippo.
2007.
AHigh Accuracy Method for Semi-supervised Infor-mation Extraction.
In Human Language Technolo-gies 2007: The Conference of the North AmericanChapter of the Association for Computational Lin-guistics; Companion Volume, Short Papers, pages169?172.Tommi Vatanen, Jaakko J Va?yrynen, and Sami Virpi-oja.
2010.
Language identification of short text seg-ments with n-gram models.
In Proceedings of theSeventh International Conference on Language Re-sources and Evaluation LREC?10.Omar Zaidan and Chris Callison-Burch.
2013.
Ara-bic dialect identification.
Computational Linguistics(To Appear).139
