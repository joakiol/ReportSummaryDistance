Proceedings of the 12th Conference of the European Chapter of the ACL, pages 675?682,Athens, Greece, 30 March ?
3 April 2009. c?2009 Association for Computational LinguisticsSemi-Supervised Polarity Lexicon InductionDelip Rao?Department of Computer ScienceJohns Hopkins UniversityBaltimore, MDdelip@cs.jhu.eduDeepak RavichandranGoogle Inc.1600 Amphitheatre ParkwayMountain View, CAdeepakr@google.comAbstractWe present an extensive study on the prob-lem of detecting polarity of words.
Weconsider the polarity of a word to be ei-ther positive or negative.
For example,words such as good, beautiful , and won-derful are considered as positive words;whereas words such as bad, ugly, and sadare considered negative words.
We treatpolarity detection as a semi-supervised la-bel propagation problem in a graph.
Inthe graph, each node represents a wordwhose polarity is to be determined.
Eachweighted edge encodes a relation that ex-ists between two words.
Each node (word)can have two labels: positive or negative.We study this framework in two differ-ent resource availability scenarios usingWordNet and OpenOffice thesaurus whenWordNet is not available.
We report ourresults on three different languages: En-glish, French, and Hindi.
Our results in-dicate that label propagation improves sig-nificantly over the baseline and other semi-supervised learning methods like Mincutsand Randomized Mincuts for this task.1 IntroductionOpinionated texts are characterized by words orphrases that communicate positive or negative sen-timent.
Consider the following example of twomovie reviews1 shown in Figure 1.
The posi-tive review is peppered with words such as enjoy-able, likeable, decent, breathtakingly and the negative?Work done as a summer intern at Google Inc.1Source: Live Free or Die Hard,rottentomatoes.comFigure 1: Movie Reviews with positive (left) andnegative (right) sentiment.comment uses words like ear-shattering, humorless,unbearable.
These terms and prior knowledge oftheir polarity could be used as features in a su-pervised classification framework to determine thesentiment of the opinionated text (E.g., (Esuli andSebastiani, 2006)).
Thus lexicons indicating po-larity of such words are indispensable resourcesnot only in automatic sentiment analysis but alsoin other natural language understanding tasks liketextual entailment.
This motivation was seen inthe General Enquirer effort by Stone et al (1966)and several others who manually construct suchlexicons for the English language.2 While it ispossible to manually build these resources for alanguage, the ensuing effort is onerous.
This mo-tivates the need for automatic language-agnosticmethods for building sentiment lexicons.
The im-portance of this problem has warranted several ef-forts in the past, some of which will be reviewedhere.We demonstrate the application of graph-basedsemi-supervised learning for induction of polar-ity lexicons.
We try several graph-based semi-2The General Inquirer tries to classify English wordsalong several dimensions, including polarity.675supervised learning methods like Mincuts, Ran-domized Mincuts, and Label Propagation.
In par-ticular, we define a graph with nodes consistingof the words or phrases to be classified either aspositive or negative.
The edges between the nodesencode some notion of similarity.
In a transduc-tive fashion, a few of these nodes are labeled us-ing seed examples and the labels for the remainingnodes are derived using these seeds.
We explorenatural word-graph sources like WordNet and ex-ploit different relations within WordNet like syn-onymy and hypernymy.
Our method is not justconfined to WordNet; any source listing synonymscould be used.
To demonstrate this, we showthe use of OpenOffice thesaurus ?
a free resourceavailable in several languages.3We begin by discussing some related work inSection 2 and briefly describe the learning meth-ods we use, in Section 3.
Section 4 details ourevaluation methodology along with detailed ex-periments for English.
In Section 5 we demon-strate results in French and Hindi, as an exampleof how the method could be easily applied to otherlanguages as well.2 Related WorkThe literature on sentiment polarity lexicon induc-tion can be broadly classified into two categories,those based on corpora and the ones using Word-Net.2.1 Corpora based approachesOne of the earliest work on learning polarityof terms was by Hatzivassiloglou and McKeown(1997) who deduce polarity by exploiting con-straints on conjoined adjectives in the Wall StreetJournal corpus.
For example, the conjunction?and?
links adjectives of the same polarity while?but?
links adjectives of opposite polarity.
How-ever the applicability of this method for other im-portant classes of sentiment terms like nouns andverbs is yet to be demonstrated.
Further they as-sume linguistic features specific to English.Wiebe (2000) uses Lin (1998a) style distribu-tionally similar adjectives in a cluster-and-labelprocess to generate sentiment lexicon of adjec-tives.In a different work, Riloff et al (2003) use man-ually derived pattern templates to extract subjec-tive nouns by bootstrapping.3http://www.openoffice.orgAnother corpora based method due to Turneyand Littman (2003) tries to measure the semanticorientation O(t) for a term t byO(t) =?ti?S+PMI(t, ti) ?
?tj?S?PMI(t, tj)where S+ and S?
are minimal sets of polar termsthat contain prototypical positive and negativeterms respectively, and PMI(t, ti) is the point-wise mutual information (Lin, 1998b) betweenthe terms t and ti.
While this method is generalenough to be applied to several languages our aimwas to develop methods that exploit more struc-tured sources like WordNet to leverage benefitsfrom the rich network structure.Kaji and Kitsuregawa (2007) outline a methodof building sentiment lexicons for Japanese us-ing structural cues from HTML documents.
Apartfrom being very specific to Japanese, excessive de-pendence on HTML structure makes their methodbrittle.2.2 WordNet based approachesThese approaches use lexical relations defined inWordNet to derive sentiment lexicons.
A sim-ple but high-precision method proposed by Kimand Hovy (2006) is to add all synonyms of a po-lar word with the same polarity and its antonymswith reverse polarity.
As demonstrated later, themethod suffers from low recall and is unsuitable insituations when the seed polar words are too few ?not uncommon in low resource languages.In line with Turney?s work, Kamps et.
al.
(2004)try to determine sentiments of adjectives in Word-Net by measuring relative distance of the termfrom exemplars, such as ?good?
and ?bad?.
Thepolarity orientation of a term t is measured as fol-lowsO(t) = d(t, good) ?
d(t, bad)d(good, bad)where d(.)
is a WordNet based relatedness mea-sure (Pedersen et al, 2004).
Again they report re-sults for adjectives alone.Another relevant example is the recent work byMihalcea et.
al.
(2007) on multilingual sentimentanalysis using cross-lingual projections.
This isachieved by using bridge resources like dictionar-ies and parallel corpora to build sentence subjec-tivity classifiers for the target language (Roma-nian).
An interesting result from their work is that676only a small fraction of the lexicon entries pre-serve their polarities under translation.The primary contributions of this paper are :?
An application of graph-based semi-supervised learning methods for inducingsentiment lexicons from WordNet and otherthesauri.
The label propagation methodnaturally allows combining several relationsfrom WordNet.?
Our approach works on all classes of wordsand not just adjectives?
Though we report results for English, Hindi,and French, our methods can be easily repli-cated for other languages where WordNet isavailable.4 In the absence of WordNet, anythesaurus listing synonyms could be used.We present one such result using the OpenOf-fice thesaurus ?
a freely available multilin-gual resource scarcely used in NLP literature.3 Graph based semi-supervised learningMost natural language data has some structure thatcould be exploited even in the absence of fully an-notated data.
For instance, documents are simi-lar in the terms they contain, words could be syn-onyms of each other, and so on.
Such informa-tion can be readily encoded as a graph where thepresence of an edge between two nodes would in-dicate a relationship between the two nodes and,optionally, the weight on the edge could encodestrength of the relationship.
This additional infor-mation aids learning when very few annotated ex-amples are present.
We review three well knowngraph based semi-supervised learning methods ?mincuts, randomized mincuts, and label propaga-tion ?
that we use in induction of polarity lexicons.3.1 MincutsA mincut of a weighted graph G(V,E) is a par-titioning the vertices V into V1 and V2 such thatsum of the edge weights of all edges between V1and V2 is minimal (Figure 2).Mincuts for semi-supervised learning proposedby Blum and Chawla (2001) tries to classify data-points by partitioning the similarity graph suchthat it minimizes the number of similar points be-ing labeled differently.
Mincuts have been used4As of this writing, WordNet is available for more than 40world languages (http://www.globalwordnet.org)Figure 2: Semi-supervised classification usingmincutsin semi-supervised learning for various tasks, in-cluding document level sentiment analysis (Pangand Lee, 2004).
We explore the use of mincuts forthe task of sentiment lexicon learning.3.2 Randomized MincutsAn improvement to the basic mincut algorithmwas proposed by Blum et.
al.
(2004).
The deter-ministic mincut algorithm, solved using max-flow,produces only one of the several possible mincuts.Some of these cuts could be skewed thereby nega-tively effecting the results.
As an extreme exampleconsider the graph in Figure 3a.
Let the nodes withdegree one be labeled as positive and negative re-spectively, and for the purpose of illustration letall edges be of the same weight.
The graph in Fig-ure 3a.
can be partitioned in four equal cost cuts ?two of which are shown in (b) and (c).
The min-Figure 3: Problem with mincutscut algorithm, depending on the implementation,will return only one of the extreme cuts (as in (b))while the desired classification might be as shownin Figure 3c.The randomized mincut approach tries to ad-dress this problem by randomly perturbing the ad-jacency matrix by adding random noise.5 Mincutis then performed on this perturbed graph.
This is5We use a Gaussian noise N (0, 1).677repeated several times and unbalanced partitionsare discarded.
Finally the remaining partitions areused to deduce the final classification by majorityvoting.
In the unlikely event of the voting result-ing in a tie, we refrain from making a decision thusfavoring precision over recall.3.3 Label propagationAnother semi-supervised learning method we useis label propagation by Zhu and Ghahramani(2002).
The label propagation algorithm is a trans-ductive learning framework which uses a few ex-amples, or seeds, to label a large number of un-labeled examples.
In addition to the seed exam-ples, the algorithm also uses a relation between theexamples.
This relation should have two require-ments:1.
It should be transitive.2.
It should encode some notion of relatednessbetween the examples.To name a few, examples of such relations in-clude, synonymy, hypernymy, and similarity insome metric space.
This relation between the ex-amples can be easily encoded as a graph.
Thus ev-ery node in the graph is an example and the edgerepresents the relation.
Also associated with eachnode, is a probability distribution over the labelsfor the node.
For the seed nodes, this distributionis known and kept fixed.
The aim is to derive thedistributions for the remaining nodes.Consider a graph G(V,E,W ) with vertices V ,edges E, and an n ?
n edge weight matrix W =[wij ], where n = |V |.
The label propagation algo-rithm minimizes a quadratic energy functionE = 12?
(i, j) ?
Ewij(yi ?
yj)2where yi and yj are the labels assigned to thenodes i and j respectively.6 Thus, to derive thelabels at yi, we set ?
?yiE = 0 to obtain the follow-ing update equationyi =?(i,j)?Ewijyj?
(i,j)?EwijIn practice, we use the following iterative algo-rithm as noted by Zhu and Ghahramani (2002).
A6For binary classification yk ?
{?1, +1}.n ?
n stochastic transition matrix T is derived byrow-normalizing W as follows:Tij = P (j ?
i) =wij?nk=1 wkjwhere Tij can be viewed as the transition probabil-ity from node j to node i.
The algorithm proceedsas follows:1.
Assign a n ?
C matrix Y with the initial as-signment of labels, where C is the number ofclasses.2.
Propagate labels for all nodes by computingY = TY3.
Row-normalize Y such that each row adds upto one.4.
Clamp the seed examples in Y to their origi-nal values5.
Repeat 2-5 until Y converges.There are several points to be noted.
First, we adda special label ?DEFAULT?
to existing set of la-bels and set P (DEFAULT | node = u) = 1 for allunlabeled nodes u.
For all the seed nodes s withclass label Lwe define P (L | node = s) = 1.
Thisensures nodes that cannot be labeled at all7 will re-tain P (DEFAULT) = 1 thereby leading to a quickconvergence.
Second, the algorithm produces aprobability distribution over the labels for all un-labeled points.
This makes this method speciallysuitable for classifier combination approaches.
Forthis paper, we simply select the most likely labelas the predicted label for the point.
Third, the al-gorithm eventually converges.
For details on theproof for convergence we refer the reader to Zhuand Ghahramani (2002).4 Evaluation and ExperimentsWe use the General Inquirer (GI)8 data for eval-uation.
General Inquirer is lexicon of Englishwords hand-labeled with categorical informationalong several dimensions.
One such dimension iscalled valence, with 1915 words labeled ?Positiv?
(sic) and 2291 words labeled ?Negativ?
for wordswith positive and negative sentiments respectively.Since we want to evaluate the performance of the7As an example of such a situation, consider a discon-nected component of unlabeled nodes with no seed in it.8http://www.wjh.harvard.edu/?inquirer/678algorithms alone and not the recall issues in us-ing WordNet, we only consider words from GI thatalso occur in WordNet.
This leaves us the distri-bution of words as enumerated in Table 1.PoS type No.
of Positives No.
of NegativesNouns 517 579Verbs 319 562Adjectives 547 438Table 1: English evaluation data from General In-quirerAll experiments reported in Sections 4.1 to 4.5use the data described above with a 50-50 splitso that the first half is used as seeds and the sec-ond half is used for test.
Note that all the exper-iments described below did not involve any pa-rameter tuning thus obviating the need for a sepa-rate development test set.
The effect of number ofseeds on learning is described in Section 4.6.4.1 Kim-Hovy method and improvementsKim and Hovy (2006) enrich their sentiment lexi-con from WordNet as follows.
Synonyms of a pos-itive word are positive while antonyms are treatedas negative.
This basic version suffers from a verypoor recall as shown in the Figure 4 for adjectives(see iteration 1).
The recall can be improved for aslight trade-off in precision if we re-run the abovealgorithm on the output produced at the previouslevel.
This could be repeated iteratively until thereis no noticeable change in precision/recall.
Weconsider this as the best possible F1-score pro-duced by the Kim-Hovy method.
The classwiseF1 for this method is shown in Table 2.
We usethese scores as our baseline.Figure 4: Kim-Hovy methodPoS type P R F1Nouns 92.59 21.43 34.80Verbs 87.89 38.31 53.36Adjectives 92.95 31.71 47.28Table 2: Precision/Recall/F1-scores for Kim-Hovy method4.2 Using prototypesWe now consider measuring semantic orientationfrom WordNet using prototypical examples suchas ?good?
and ?bad?
similar to Kamps et al(2004).
Kamps et.
al., report results only foradjectives though their method could be used forother part-of-speech types.
The results for us-ing prototypes are listed in Table 3.
Note thatthe seed data was fully unused except for the ex-amples ?good?
and ?bad?.
We still test on thesame test data as earlier for comparing results.Also note that the recall need not be 100 in thiscase as we refrain from making a decision whend(t,good) = d(t,bad).PoS type P R F1Nouns 48.03 99.82 64.86Verbs 58.12 100.00 73.51Adjectives 57.35 99.59 72.78Table 3: Precision/Recall/F1-scores for prototypemethod4.3 Using mincuts and randomized mincutsWe now report results for mincuts and random-ized mincuts algorithm using the WordNet syn-onym graph.
As seen in Table 4, we only observeda marginal improvement (for verbs) over mincutsby using randomized mincuts.But the overall improvement of using graph-based semi-supervised learning methods over theKim-Hovy and Prototype methods is quite signifi-cant.4.4 Using label propagationWe extract the synonym graph from WordNet withan edge between two nodes being defined iff oneis a synonym of the other.
When label propaga-tion is performed on this graph results in Table5 are observed.
The results presented in Tables2-5 need deeper inspection.
The iterated Kim-Hovy method suffers from poor recall.
Howeverboth mincut methods and the prototype method by679P R F1NounsMincut 68.25 100.00 81.13RandMincut 68.32 99.09 80.08VerbsMincut 72.34 100.00 83.95RandMincut 73.06 99.02 84.19AdjectivesMincut 73.78 100.00 84.91RandMincut 73.58 100.00 84.78Table 4: Precision/Recall/F1-scores using mincutsand randomized mincutsPoS type P R F1Nouns 82.55 58.58 58.53Verbs 81.00 85.94 83.40Adjectives 84.76 64.02 72.95Table 5: Precision/Recall/F1-scores for Label Pro-pogationKamps et.
al., have high recall as they end upclassifying every node as either positive or nega-tive.
Note that the recall for randomized mincutis not 100 as we do not make a classification de-cision when there is a tie in majority voting (referSection 3.2).
Observe that the label propagationmethod performs significantly better than previ-ous graph based methods in precision.
The rea-son for lower recall is attributed to the lack of con-nectivity between plausibly related nodes, therebynot facilitating the ?spread?
of labels from the la-beled seed nodes to the unlabeled nodes.
We ad-dress this problem by adding additional edges tothe synonym graph in the next section.4.5 Incorporating hypernymsThe main reason for low recall in label propaga-tion is that the WordNet synonym graph is highlydisconnected.
Even nodes which are logically re-lated have paths missing between them.
For exam-ple the positive nouns compliment and laud belongto different synonym subgraphs without a pathbetween them.
But incorporating the hypernymedges the two are connected by the noun praise.So, we incorporated hypernyms of every node toimprove connectivity.
Performing label propaga-tion on this combined graph gives much better re-sults (Table 6) with much higher recall and evenslightly better precision.
In Table 6., we do notreport results for adjectives as WordNet does notdefine hypernyms for adjectives.
A natural ques-PoS type P R F1Nouns 83.88 99.64 91.08Verbs 85.49 100.00 92.18Adjectives N/A N/A N/ATable 6: Effect of adding hypernymstion to ask is if we can use other WordNet relationstoo.
We will defer this until section 6.4.6 Effect of number of seedsThe results reported in Sections 4.1 to 4.5 fixedthe number of seeds.
We now investigate the per-formance of the various methods on the numberof seeds used.
In particular, we are interested inperformance under conditions when the number ofseeds are few ?
which is the motivation for usingsemi-supervised learning in the first place.
Fig-ure 5 presents our results for English.
Observe thatLabel Propagation performs much better than ourbaseline even when the number of seeds is as lowas ten.
Thus label propagation is especially suitedwhen annotation data is extremely sparse.One reason for mincuts performing badly withfew seeds is because they generate degenrate cuts.5 Adapting to other languagesIn order to demonstrate the ease of adaptability ofour method for other languages, we used the HindiWordNet9 to derive the adjective synonym graph.We selected 489 adjectives at random from a listof 10656 adjectives and this list was annotated bytwo native speakers of the language.
The anno-tated list was then split 50-50 into seed and testsets.
Label propagation was performed using theseed list and evaluated on the test list.
The resultsare listed in Table 7.Hindi P R F190.99 95.10 93.00Table 7: Evaluation on Hindi datasetWordNet might not be freely available for alllanguages or may not exist.
In such cases build-ing graph from an existing thesaurus might alsosuffice.
As an example, we consider French.
Al-though the French WordNet is available10 , we9http://www.cfilt.iitb.ac.in/wordnet/webhwn/10http://www.illc.uva.nl/EuroWordNet/consortium-ewn.html680Figure 5: Effect of number of seeds on the F-score for Nouns, Verbs, and Adjectives.
The X-axis isnumber of seeds and the Y-axis is the F-score.found the cost prohibitive to obtain it.
Observethat if we are using only the synonymy relation inWordNet then any thesaurus can be used instead.To demonstrate this, we consider the OpenOfficethesaurus for French, that is freely available.
Thesynonym graph of French adjectives has 9707 ver-tices and 1.6M edges.
We manually annotated alist of 316 adjectives and derived seed and test setsusing a 50-50 split.
The results of label propaga-tion on such a graph is shown in Table 8.French P R F173.65 93.67 82.46Table 8: Evaluation on French datasetThe reason for better results in Hindi comparedto French can be attributed to (1) higher inter-annotator agreement (?
= 0.7) in Hindi comparedthat in French (?
= 0.55).11 (2) The Hindi ex-periment, like English, used WordNet while theFrench experiment was performed on graphs de-rived from the OpenOffice thesaurus due lack offreely available French WordNet.11We do not have ?
scores for English dataset derived fromthe Harvard Inquirer project.6 Conclusions and Future WorkThis paper demonstrated the utility of graph-basedsemi-supervised learning framework for buildingsentiment lexicons in a variety of resource avail-ability situations.
We explored how the struc-ture of WordNet could be leveraged to derivepolarity lexicons.
The paper combines, for thefirst time, relationships like synonymy and hyper-nymy to improve label propagation results.
Allof our methods are independent of language asshown in the French and Hindi cases.
We demon-strated applicability of our approach on alterna-tive thesaurus-derived graphs when WordNet isnot freely available, as in the case of French.Although our current work uses WordNet andother thesauri, in resource poor situations whenonly monolingual raw text is available we can per-form label propagation on nearest neighbor graphsderived directly from raw text using distributionalsimilarity methods.
This is work in progress.We are also currently working on the possibil-ity of including WordNet relations other than syn-onymy and hypernymy.
One relation that is in-teresting and useful is antonymy.
Antonym edgescannot be added in a straight-forward way to the681graph for label propagation as antonymy encodesnegative similarity (or dissimilarity) and the dis-similarity relation is not transitive.References[Blum and Chawla2001] Avrim Blum and ShuchiChawla.
2001.
Learning from labeled and un-labeled data using graph mincuts.
In Proc.
18thInternational Conf.
on Machine Learning, pages19?26.
[Blum et al2004] Blum, Lafferty, Rwebangira, andReddy.
2004.
Semi-supervised learning using ran-domized mincuts.
In Proceedings of the ICML.
[Esuli and Sebastiani2006] Andrea Esuli and FabrizioSebastiani.
2006.
Determining term subjectivityand term orientation for opinion mining.
In Pro-ceedings of the 11th Conference of the EuropeanChapter of the Association for Computational Lin-guistics, pages 193?200.
[Hatzivassiloglou and McKeown1997] Vasileios Hatzi-vassiloglou and Kathleen McKeown.
1997.
Predict-ing the semantic orientation of adjectives.
In Pro-ceedings of the ACL, pages 174?181.
[Kaji and Kitsuregawa2007] Nobuhiro Kaji and MasaruKitsuregawa.
2007.
Building lexicon for sentimentanalysis from massive collection of HTML docu-ments.
In Proceedings of the Joint Conference onEmpirical Methods in Natural Language Process-ing and Computational Natural Language Learning(EMNLP-CoNLL), pages 1075?1083.
[Kamps et al2004] Jaap Kamps, Maarten Marx, R. ort.Mokken, and Maarten de Rijke.
2004.
UsingWordNet to measure semantic orientation of adjec-tives.
In Proceedings of LREC-04, 4th InternationalConference on Language Resources and Evaluation,volume IV.
[Kim and Hovy2006] Soo-Min Kim and Eduard H.Hovy.
2006.
Identifying and analyzing judgmentopinions.
In Proceedings of the HLT-NAACL.
[Lin1998a] Dekang Lin.
1998a.
Automatic retrievaland clustering of similar words.
In Proceedings ofCOLING, pages 768?774.
[Lin1998b] Dekang Lin.
1998b.
An information-theoretic definition of similarity.
In Proceedingsof the 15th International Conference in MachineLearning, pages 296?304.
[Mihalcea et al2007] Rada Mihalcea, Carmen Banea,and Janyce Wiebe.
2007.
Learning multilingualsubjective language via cross-lingual projections.
InProceedings of the 45th Annual Meeting of the As-sociation of Computational Linguistics, pages 976?983.
[Pang and Lee2004] Bo Pang and Lillian Lee.
2004.A sentimental education: Sentiment analysis usingsubjectivity summarization based on minimum cuts.In Proceedings of the ACL, pages 271?278.
[Pedersen et al2004] Ted Pedersen, Siddharth Patward-han, and Jason Michelizzi.
2004.
Word-net::similarity - measuring the relatedness of con-cepts.
In Proceeding of the HLT-NAACL.
[Riloff et al2003] Ellen Riloff, Janyce Wiebe, andTheresa Wilson.
2003.
Learning subjective nounsusing extraction pattern bootstrapping.
In Proceed-ings of the 7th Conference on Natural LanguageLearning, pages 25?32.
[Stone et al1966] Philip J.
Stone, Dexter C. Dunphy,Marshall S. Smith, and Daniel M. Ogilvie.
1966.The General Inquirer: A Computer Approach toContent Analysis.
MIT Press.
[Turney and Littman2003] Peter D. Turney andMichael L. Littman.
2003.
Measuring praise andcriticism: Inference of semantic orientation fromassociation.
ACM Transactions on InformationSystems, 21(4):315?346.
[Wiebe2000] Janyce M. Wiebe.
2000.
Learning sub-jective adjectives from corpora.
In Proceedings ofthe 2000 National Conference on Artificial Intelli-gence.
AAAI.
[Zhu and Ghahramani2002] Xiaojin Zhu and ZoubinGhahramani.
2002.
Learning from labeled and un-labeled data with label propagation.
Technical Re-port CMU-CALD-02-107, Carnegie Mellon Univer-sity.682
