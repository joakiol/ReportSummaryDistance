CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 218?222Manchester, August 2008Discriminative Learning of Syntactic and Semantic DependenciesLu Li1, Shixi Fan2, Xuan Wang1, Xiaolong Wang1Shenzhen Graduate School, Harbin Institute of Technology,Xili, Shenzhen 518055, China1{lli,wangxuan,wangxl}@insun.hit.edu.cn2fanshixi@hit.edu.cnAbstractA Maximum Entropy Model based systemfor discriminative learning of syntactic andsemantic dependencies submitted to theCoNLL-2008 shared task (Surdeanu, et al,2008) is presented in this paper.
The sys-tem converts the dependency learning taskto classification issues and reconstructs thedependent relations based on classificationresults.
Finally F1 scores of 86.69, 69.95and 78.35 are obtained for syntactic depen-dencies, semantic dependencies and thewhole system respectively in closed chal-lenge.
For open challenge the correspond-ing F1 scores are 86.69, 68.99 and 77.84.1 IntroductionGiven sentences and corresponding part-of-speechof each word, the learning of syntactic and seman-tic dependency contains two separable goals: (1)building a dependency tree that defines the syn-tactic dependency relationships between separatedwords; (2) specifying predicates (no matter verbsor nouns) of the sentences and labeling the seman-tic dependents for each predicate.In this paper a discriminative parser is pro-posed to implement maximum entropy (ME) mod-els (Berger, et al, 1996) to address the learningtask.
The system is divided into two main subsys-tems: syntactic dependency parsing and semanticdependency labeling.
The former is used to find awell-formed syntactic dependency tree that occu-pies all the words in the sentence.
If edges areadded between any two words, a full-connectedc?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.graph is constructed and the dependency tree couldbe found using a maximum spanning tree (MST)algorithm (McDonald, et al, 2005).
The latter fo-cuses on separable predicates whose semantic de-pendents could be determined using classificationtools, such as ME models1etc..We participated in both closed and open chal-lenge of the CoNLL-2008 shared task (Surdeanu,et al, 2008).
Results are reported on both develop-ment and test sets in this paper.2 System Description2.1 Syntactic ParsingThe goal of syntactic parsing is to create a la-beled syntactic dependency parse y for input sen-tence x including words and their parts of speech(POS).
Inspired by the parsing model that imple-ments maximum spanning tree (MST) algorithmto induce the dependency parsing tree (McDonald,et al, 2005), the system employs the same frame-work.
The incorporated features are defined overparts of speech of words occurring between andaround a possible head-dependent relation.Suppose G = (V, E) is a directed graph, whereV is the set of vertices denoting the words in sen-tence x and E is the set of directed edges betweenany two vertices with some scores.
The MST al-gorithm is to find the most probable subgraph of Gthat satisfies tree constraints over all vertices.
Thescore function of the parsing tree y is defined ass(y) =?
(i,j)?ys(i, j) (1)where (i, j) ?
y indicates an edge in y from wordi to word j and s(i, j) denotes its score.
Suppose Y1http://homepages.inf.ed.ac.uk/s0450736/maxent.html218wiwjpipj(wi, pi) (wj, pj)(wi, wj) (pi, pj)(wi, pj) (wj, pi)(wi, wj, pi) (wi, wj, pj)(pi, pj, wi) (pi, pj, wj)(wi, wj, pi, pj) (pi, pk, pj), i < k < j(pi, pi+1, pj?1, pj) (pi?1, pi, pj?1, pj)(pi, pi+1, pj, pj+1) (pi?1, pi, pj, pj+1)Table 1: Features for syntactic parsing.is the set of syntactic dependency labels, the scorefunction of edges is defined ass(i, j) = maxl?YPr(l|x, i, j) (2)ME models are used to calculate the value ofPr(l|x, i, j), where the features are extracted frominput sentence x.
Given i and j as the subscriptsof words in the sentence and word i is the parentof word j, the features can be illustrated in table1.
wiand piare denoted as the ith word and theith part of speech respectively in the sentence.
Thetuples define integrated features, such as (wi, pi)indicates the feature combining the ith word andith part of speech.
Besides these features, the dis-tant between word i and word j in sentence x isconsidered as a single feature.
The distant is alsocombined with features in table 1 to produce com-plex features.2.2 Semantic Dependency LabelingSemantic dependencies are always concerningwith specific predicates.
Unlike syntactic depen-dencies, semantic dependency relationships usu-ally can not be represented as a tree.
Thus, themethod used for semantic dependency labelingis somewhat different from syntactic dependencyparsing.
The work of semantic labeling can be di-vided into two stages: predicate tagging and de-pendents recognizing.2.2.1 Predicate TaggingAccording to PropBank (Palmer, et al, 2005)and NomBank (Meyers, et al, 2004), predicatesusually have several rolesets corresponding to dif-ferent meanings.
For example, the verb abandonhas three rolesets marked as ordinal numbers 01,02 and 03 as described below.wipipi?1pi+1(pi?1, pi) (pi, pi+1)(pi?2, pi) (pi, pi+2)(pi?3, pi) (pi, pi+3)(pi?1, pi, pi+1) (wi, pi)(wi, pi?1, pi) (wi, pi, pi+1)(wi, pi?2, pi) (wi, pi, pi+2)(wi, pi?3, pi) (wi, pi, pi+3)(wi, pi?1, pi, pi+1)Table 2: Features used for predicate tagging.<frameset><predicate lemma=?abandon?><roleset id=?abandon.01?
name=?leavebehind?
vncls=?51.2?>.
.
.</roleset><roleset id=?abandon.02?name=?exchange?
vncls=?51.2?>.
.
.</roleset><roleset id=?abandon.03?name=?surrender, give over?
vncls=?-?>.
.
.</roleset></predicate></frameset>The goal of this part is to identify the predicatesin the sentences and to determine the roleset foreach of them.
It should be cleared that the ordi-nal numbers are only used to distinguish differentmeanings of a predicate.
However, if these num-bers are treated as tags for predicates, some statisti-cal properties will be obtained as illustrated in Fig-ure 1.
As can be seen, the distribution of the traindata would be quite informative for representingthe distribution of other three data sets.
Based onthis idea, a classification framework is introducedfor predicate tagging.Suppose the tag set is chosen to be T ={01, 02, ..., 22} according to the horizontal axis ofFigure 1 and 00 is added to indicate that the ex-amining word is not a predicate.
Suppose tiis avariable indicating the tag of word at position i insentences x.
ME models are implemented to tagthe predicates.ti= argmaxt?
TPr(t|x, i) (3)2190 5 10 15 20024681012Ordinal Numbers of PredicatesLogarithmical Number of Occurrencetraindevelbrownws jFigure 1: Distribution of the ordinal numbers ofpredicates on different data sets.
01 - 21 are at-tached with the predicates in the corpus and 22stands for ?SU?.The features for predicate tagging are listed in ta-ble 2, where the symbols share the same mean-ing as in table 1.
Experiments show that this purestatistic processing method is effective for predi-cate tagging.2.2.2 Dependents RecognizingThis subtask depends deeply on the results ofsyntactic parsing and predicate tagging describedearlier in the system.
Predicate tagging identifiescentral words and syntactic parsing provides syn-tactic features for its dependents identification andclassification.Generally speaking, given a specific predicate ina sentence, only a few of words are associated as itssemantic dependents.
By statistical analysis a listof part of speech tuples that are appearing to be se-mantic dependency are collected.
All other tuplesare filtered out to improve system performance.Suppose (p, d) is a couple of predicate and oneof its possible dependents, T is the dependencytree generated by syntactic parsing, L is the set ofsemantic dependency labels.
The dependents canbe recognized by using a classification model, MEmodels are chosen as before.l(p,d)= argmaxl?LPr(l|p, d, T ) (4)Besides the semantic dependency labels, null is in-cluded as a special tag to indicate that there is nosemantic dependency between p and d. As a result,dependents identification (binary classification)and dependents tagging (multi-classification) canbe solved together within one multi-classificationframework.The selected features are listed below.1.
Predicate Features?
Lemma and POS of predicate, pred-icate?s parent in syntactic dependencytree.?
Voice active or passive.?
Syntactic dependency label of edge be-tween predicate and its parent.?
POS framework POS list of predicate?ssiblings, POS list of predicate?s children.?
Syntactic dependency framework syn-tactic dependency label list of the edgesbetween predicate?s parent and its sib-lings.?
Parent framework syntactic depen-dency label list of edges connecting topredicate?s parent.2.
Dependent Features?
Lemma and POS of dependent, depen-dent?s parent.?
POS framework POS list of depen-dent?s siblings.?
Number of children of dependent?s par-ent.3.
In Between Features?
Position of dependent according topredicate: before or after.?
POS pair of predicate and dependent.?
Family relation between predicate anddependent: ancestor or descendant.?
Path length between predicate and de-pendent.?
Path POS POS list of all words appear-ing on the path from predicate to depen-dent.?
Path syntactic dependency label list ofdependency label of edges of path be-tween predicate and dependent.3 Experiment resultsThe classification models were trained using all thetraining data.
The detailed information are shownin table 3.
All experiments ran on 32-bit Intel(R)Pentium(R) D CPU 3.00GHz processors with 2.0Gmemory.220Feature Number Training TimeSyn.
7,488,533 30hPrd.
1,484,398 8hSem.
3,588,514 12hTable 3: Details of ME models.
Syn.
is for syntac-tic parsing, Prd.
is for predicate tagging and Sem.is for semantic dependents recognizing.Syntactic Semantic Overalldevel 85.29 69.60 77.49brown 80.80 59.17 70.01wsj 87.42 71.27 79.38brown+wsj 86.69 69.95 78.35(a) Closed ChallengeSyntactic Semantic Overalldevel 85.29 68.45 76.87brown 80.80 58.22 69.51wsj 87.42 70.32 78.87brown+wsj 86.69 68.99 77.84(b) Open ChallengeTable 4: Scores for joint learning of syntactic andsemantic dependencies.3.1 Closed ChallengeThe system for closed challenge is designed as atwo-stage parser: syntactic parsing and semanticdependency labeling as described previously.
Ta-ble 4(a) shows the results on different corpus.
Asshown in table 4(a), the scores of semantic depen-dency labeling are quite low, that are influencingthe overall scores.
The reason could be inferredfrom the description in section 2.2.2 since seman-tic dependent labeling inherits the errors from theoutput of syntactic parsing and predicate tagging.Following evaluates each part independently.Besides the multiple classification model de-scribed in table 3, a binary classification modelwas built based on ME for predicate tagging.
Thebinary model can?t distinguish different rolesets ofpredicate, but can identify which words are predi-cates in sentences.
The precision and recall for bi-nary model are 90.80 and 88.87 respectively, whilefor multiple model, the values are 84.60 and 85.60.For semantic dependent labeling, experimentswere performed under conditions that the gold syn-tactic dependency tree and predicates list weregiven as input.
The semantic scores became 80.09,77.08 and 82.25 for devel, brown and wsj respec-tively.
This implies that the error of syntactic pars-ing and predicate tagging could be probably aug-mented in semantic dependent labeling.
In order toimprove the performance of the whole system, thedeep dependence between the two stages should bebroken up in future research.3.2 Open ChallengeIn open challenge, the same models are used forsyntactic parsing and predicate tagging as in closedchallenge and two other models are trained for se-mantic dependent labeling.
Suppose Mmst, Mmaltand Mchunkare denoted as these three semanticmodels, where Mmstis the model used in closedchallenge, Mmaltis trained on the syntactic de-pendency tree provided by the open corpus withthe same feature set as Mmst, and Mchunkistrained using features extracted from name entityand wordnet super senses results provided by theopen corpus.Considering a possible dependent given a spe-cific predicate, the feature set used for Mchunkcontains only six elements:?
Whether the dependent is in name entitychunk: True or False.?
Name entity label of the dependent.?
Whether the dependent is in BBN name entitychunk: True or False.?
BBN name entity label of the dependent.?
Whether the dependent is in wordnet supersense chunk: True or False.?
Wordnet super sense label of the dependent.After implementing these three models on se-mantic dependents recognizing, the results weremerged to generate the scores described in table4(b).The merging strategy is quite simple.
Given acouple of predicate and dependent (p, d), the sys-tem produces three semantic dependency labelsdenoting as lmst, lmaltand lchunk, the result la-bel is chosen to be most frequent semantic labelamong the three.Comparing the scores of open challenge andclosed challenge, it can be found that the score ofthe former is less than the latter, which is quitestrange since more resources were used in openchallenge.
To examine the influences of differ-ent semantic dependents recognizing models, each221MmstMmaltMchunkdevel 69.60 64.48 41.72brown 59.17 56.52 34.04wsj 71.27 66.40 41.83Table 5: Semantic scores of different models.model was implemented in the closed challengeand the results are shown in table 5.
Specially,model Mchunkgenerated too low scores and gave aheavy negative influence on the final results.
Find-ing a good way to combine several results requiresfurther research.4 ConclusionsThis paper have presented a simple discriminativesystem submitted to the CoNLL-2008 shared taskto address the learning task of syntactic and se-mantic dependencies.
The system was divided intosyntactic parsing and semantic dependents label-ing.
Maximum spanning tree was used to finda syntactic dependency tree in the full-connectedgraph constructed over the words of a sentence.Maximum entropy models were implemented toclassify syntactic dependency edges, predicatesand their semantic dependents.
A brief analysishas also been given on the results of both closedchallenge and open challenge.AcknowledgementThis research has been partially supported by theNational Natural Science Foundation of China(No.
60435020 and No.
90612005), the Goal-oriented Lessons from the National 863 Programof China (No.2006AA01Z197) and Project of Mi-crosoft Research Asia.
We would like to thankZhixin Hao, Xiao Xin, Languang He and Tao Qianfor their wise suggestion and great help.
Thanksalso to Muhammad Waqas Anwar for English im-provement.ReferencesAdam Berger, Stephen Della Pietra, Vincent DellaPietra 1996.
A Maximum Entropy Approach to Nat-ural Language Processing.
Computational Linguis-tics, 22(1):39-71.Adam Meyers, Ruth Reeves, Catherine Macleod,Rachel Szekely, Veronika Zielinska, Brian Youngand Ralph Grishman 2004.
The NomBank Project:An Interim Report HLT-NAACL 2004 Workshop:Frontiers in Corpus Annotation, 24-31.Martha Palmer, Daniel Gildea, Paul Kingsbury 2005.The Proposition Bank: An Annotated Corpus of Se-mantic Roles Computational Linguistics, 31(1):71-106.Mihai Surdeanu, Richard Johansson, Adam Meyers,Llu?
?s M`arquez and Joakim Nivre 2008.
TheCoNLL-2008 Shared Task on Joint Parsing of Syn-tactic and Semantic Dependencies.
Proceedings ofthe 12th Conference on Computational Natural Lan-guage Learning (CoNLL-2008)Ryan McDonald, Fernando Pereira, Kiril Ribarov, andJan Haji?c 2005.
Non-projective Dependency Pars-ing using Spanning Tree Algorithms.
Proceedings ofHLT/EMNLP, 523-530.222
