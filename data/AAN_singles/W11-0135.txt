Towards Component-Based Textual EntailmentElena Cabrio1,2 and Bernardo Magnini11FBK-irst, Trento, Italy2University of Trento, Italy{cabrio,magnini}@fbk.euAbstractIn the Textual Entailment community, a shared effort towards a deeper understanding of the corephenomena involved in textual inference is recently arose.
To analyse how the common intuitionthat decomposing TE would allow a better comprehension of the problem from both a linguisticand a computational viewpoint, we propose a definition for strong component-based TE, where eachcomponent is in itself a complete TE system, able to address a TE task on a specific phenomenonin isolation.
We review the literature according to our definition, trying to position relevant work asmore or less close to our idea of strong component-based TE.
Several dimensions of the problem arediscussed: i) the implementation of system components to address specific inference types, ii) theanalysis of the phenomena relevant to component-based TE, and iii) the development of evaluationmethodologies to assess TE systems capabilities to address single phenomena in a pair.1 IntroductionThe Recognizing Textual Entailment (RTE) task (Dagan et al (2009)) aims at capturing a broad rangeof inferences that are relevant for several Natural Language Processing applications, and consists ofdeciding, given two text fragments, whether the meaning of one text (the hypothesis H) is entailed, i.e.can be inferred, from another text (the text T).Although several approaches to face this task have been experimented, and progresses in TE tech-nologies have been shown in RTE evaluation campaigns, a renewed interest is rising in the TE communitytowards a deeper and better understanding of the core phenomena involved in textual inference.
In linewith this direction, we are convinced that crucial progress may derive from a focus on decomposing thecomplexity of the TE task into basic phenomena and on their combination.
This belief demonstratedto be shared by the RTE community, and a number of recently published works (e.g.
Sammons et al(2010), Bentivogli et al (2010)) agree that incremental advances in local entailment phenomena areneeded to make significant progress in the main task, which is perceived as omnicomprehensive and notfully understood yet.
According to this premise, the aim of this work is to systematize and delve into thework done so far in component-based TE, focusing on the aspects that contribute to highlight a commonframework and to define a clear research direction that deserves further investigation.Basing on the original definition of TE, that allows to fomulate textual inferences in an applicationindependent way and to take advantage of available datasets for training provided in the RTE evaluationcampaigns, we intend to analyse how the common intuition of decomposing TE would allow a bettercomprehension of the problem from both a linguistic and a computational viewpoint.
Aspects related tomeaning compositionality, which are absent in the original proposal, could potentially be introduced intoTE and may bring new light into textual inference.In this direction, we propose a definition for ?strong?
component-based TE, where each componentis in itself a complete TE system, able to address a TE task on a specific phenomenon in isolation.Then, we review the literature in the TE field according to our definition, trying to position relevantwork as more or less close to our idea of strong component-based TE.
We have analysed and carriedout research on several dimensions of the problem, including: i) the definition and implementation of320system components able to address specific inference types (Section 2); ii) the analysis of the phenomenarelevant to component-based TE (Section 3); iii) the development of methodologies for the analysis ofcomponent-based TE systems, providing a number of qualitative indicators to assess the capabilities thatsystems have to address single phenomena in a pair and to combine them (Section 4).2 Component-based TE frameworkWe define a component-based TE architecture as a set of clearly identifiable TE modules that can besingly used on specific entailment sub-problems and can be then combined to produce a global entailmentjudgement.
Each component receives a certain example pair as input, and outputs an entailment judgmentconcerning the inference type it is built to address.
In other words, each component is in turn a TEsystem, that performs the same task focusing only on a certain sub-aspect of entailment.
Accordingto our proposal the following requirements need to be fulfilled in component-based TE architecture: i)each compenent must provide a 3-way judgment (i.e.
entailment, contradiction, unknown) on a specificaspect underlying entailment, where the unknown judgement might be interpreted as the absence of thephenomenon in the TE pair; ii) in a component-based architecure, the same inference type (e.g.
temporal,spatial inferences) can not be covered by more than one component; this is because in the combinationphase we do not want that the same phenomen is counted more than one time.No specific constraints are defined with respect to how such components should be implemented,i.e.
they can be either a set of classifiers or rule-based modules.
In addition, linguistic processing andannotation of the input data (e.g.
parsing, NER, semantic role labeling) can be required by a componentaccording to the phenomenon it considers.
An algorithm is then applied to judge the entailment relationbetween T and H with respect to that specific aspect.
Unlike similarity algorithms, with whom algorithmsperforming entailment are often associated in the literature, the latter are characterized by the fact thatthe relation on which they are asked to judge is directional.
According to such definition, the natureof the TE task is not modified, since each sub-task independently performed by the system componentskeeps on being an entailment task.
Suitable composition mechanisms should then be applied to combinethe output of each single module to obtain a global judgment for a pair.The definition presented above provides a strong interpretation of the compositional framework forTE, that can be described as a continuum that tends towards systems developed combining identifiableand separable components addressing specific inference types.
A number of works in the literature canbe placed along this continuum, according to how much they get closer to this interpretation.Systems addressing TE exploiting machine learning techniques with a variety of features, includinglexical-syntactic and semantic features (e.g.
Kozareva and Montoyo (2006), Zanzotto et al (2007)) tendtowards the opposite extreme of this framework, since even if linguistic features are used, they bringinformation about a specific aspect relevant to the inference task but they do not provide an independentjudgment on it.
These systems are not modular, and it is difficult to assess the contribution of a cer-tain feature in providing the correct overall judgment for a pair.
A step closer towards the direction ofcomponent-based TE is done by Bar-Haim et al (2008), that model semantic inference as applicationof entailment rules specifying the generation of entailed sentences from a source sentence.
Such rulescapture semantic knowledge about linguistic phenomena (e.g.
paraphrases, synonyms), and are appliedin a transformation-based framework.
Even if these rules are clearly identifiable, their application per sedoes not provide any judgment about an existing entailment relation between T and H.A component-based system has been developed by Wang and Neumann (2008), based on three spe-cialized RTE-modules: (i) to tackle temporal expressions; (ii) to deal with other types of NEs; (iii) to dealwith cases with two arguments for each event.
Besides these precision-oriented modules, two robust butless accurate backup strategies are considered, to deal with not yet covered cases.
In the final stage, theresults of all specialized and backup modules are joint together, applying a weighted voting mechanism.Getting closer to the definition of component-based TE presented at the beginning of this Section, inMagnini and Cabrio (2009) we propose a framework for the definition and combination of specializedentailment engines, each of which able to deal with a certain aspect of language variability.
A distance-321based framework is assumed, where the distance d between T and H is inversely proportional to theentailment relation in the pair.
We assume an edit distance approach (Kouylekov and Magnini (2005)),where d is estimated as the sum of the costs of the edit operations (i.e.
insertion, deletion, substitution),which are necessary to transform T into H. Issues underlying the combination of the specialized entail-ment engines are discussed, i.e.
the order of application and the combination of individual results inorder to produce a global result.3 Linguistic analysis and resources for component-based TEThe idea underlying component-based TE is that each component should independently solve the en-tailment relation on a specific phenomenon relevant to inference, and then the judgments provided byall the modules are combined to obtain an overall judgment for a pair.
Our definition abstracts from thedifferent theories underlying the categorization of linguistic phenomena, so a straightforward relationbetween TE component and linguistic phenomena cannot be defined a priori.
Some work has alreadybeen done in investigating in depth sub-aspects of entailment, and in developing ad hoc resources toassess the impact of systems components created to address specific inference types.
Earlier works in thefield (e.g.
Vanderwende et al (2005), Clark et al (2007)) carried out partial analysis of the data sets inorder to evaluate how many entailment examples could be accurately predicted relying only on lexical,syntactic or world knowledge.
Bar-Haim et al (2005) defined two intermediate models of textual entail-ment, corresponding to lexical and lexical-syntactic levels of representation, and a sample from RTE-1data set was annotated according to each model.A step further, other RTE groups have developed focused data sets with the aim of investigatingand experimenting on specific phenomena underlying language variability.
For instance, to evaluate acontradiction detection module Marneffe et al (2008) created a corpus where contradictions arise fromnegation, by adding negative markers to the RTE-2 test data.
Kirk (2009) describes his work of buildingan inference corpus for spatial inference about motion, while Akhmatova and Dras (2009) experimentcurrent approaches on hypernymy acquisition to improve entailment classification.The first systematic work of annotation of TE data sets is done by Garoufi (2007), that propose ascheme for manual annotation of textual entailment data sets (ARTE).
The aim is to highlight a widevariety of entailment phenomena in the data, in relation to three levels, i.e.
Alignment, Context andCoreference.
23 different features are extracted for positive entailment annotation, while for the negativepairs a more basic scheme is conceived.
The ARTE scheme has been applied to the complete positiveentailment RTE-2 Test Set (400 pairs), and to a random 25% portion of the negative entailment Test Set.More recently, in Bentivogli et al (2010) we present a methodology for the creation of specializedTE data sets, made of monothematic T-H pairs, i.e.
pairs in which a certain phenomenon relevant to theentailment relation is highlighted and isolated (Magnini and Cabrio (2009)).
Such monothematic pairsare created basing on the phenomena that are actually present in the RTE pairs, so that the distribution ofthe linguistic phenomena involved in the entailment relation emerges.
A number of steps are carried outmanually, starting from a T-H pair taken from one of the RTE data sets, and decomposing it in a number ofmonothematic pairs T-Hi, where T is the original text and Hi are the hypotheses created for each linguisticphenomenon relevant for judging the entailment relation in T-H. Phenomena are grouped using both fine-grained and broader categories (e.g.
lexical, syntactic, lexical-syntactic, discourse and reasoning).
Afterapplying the proposed methodology, all the monothematic pairs T-Hi relative to the same phenomenon iare grouped together, resulting in several data sets specialized for phenomenon i.
Unlike previous workof analysis of RTE data, the result of this study is a resource that allows evaluation of TE systems onspecific phenomena relevant to inference, both when isolated and when interacting with the others (theannotation of RTE data with the linguistic phenomena underlying the entailment/contradiction relationsin the pairs is also provided).
A pilot study has been carried out on 90 pairs from RTE-5 data set.1Highlighting the need of resources for solving textual inference problems in the context of RTE,Sammons et al (2010) challenge the NLP community to contribute to a joint, long term effort in this1The resulting data sets are freely available at http://hlt.fbk.eu/en/Technology/TE_Specialized_Data322direction, making progress both in the analysis of relevant linguistic phenomena and their interaction, anddeveloping resources and approaches that allow more detailed assessment of RTE systems.
The authorspropose a linguistically-motivated analysis of entailment data based on a step-wise procedure to resolveentailment decision, by first identifying parts of T that match parts of H, and then identifying connectingstructure.
Their inherent assumption is that the meanings of T and H could be represented as sets ofn-ary relations, where relations could be connected to other relations (i.e.
could take other relations asarguments).
The authors carried out a feasibility study applying the procedure to 210 examples fromRTE-5, marking for each example the entailment phenomena that are required for the inference.4 Evaluation in component-based TEThe evaluation measure adopted in the RTE challenges is accuracy, i.e.
the percentage of pairs correctlyjudged by a TE system.
In the last RTE-5 and RTE-6 campaigns, participating groups were asked torun ablation tests, to evaluate the contribution of publicly available knowledge resources to the systems?performances.
Such ablation tests consist of removing one module at a time from a system, and rerunningthe system on the test set with the other modules, except the one tested.
The results obtained were notsatisfactory, since the impact of a certain resource on system performances is really dependent on how itis used by the system.
In some cases, resources like WordNet demonstrated to be very useful, while forother systems their contribution is limited or even damaging, as observed also in Sammons et al (2010).To provide a more detailed evaluation of the capabilities of a TE system to address specific infer-ence types, in Cabrio and Magnini (2010) we propose a methodology for a qualitative evaluation of TEsystems, that takes advantage of the decomposition of T-H pairs into monothematic pairs (described inSection 3).
The assumption is that the more a system is able to correctly solve the linguistic phenomenaunderlying the entailment relation separately, the more the system should be able to correctly judge morecomplex pairs, in which different phenomena are present and interact in a complex way.
According tosuch assumption, the higher the accuracy of a system on the monothematic pairs and the compositionalstrategy, the better its performances on the original RTE pairs.
The precision a system gains on singlephenomena should be maintained over the general data set, thanks to suitable mechanisms of meaningcombination.
A number of quantitative and qualitative indicators about strength and weaknesses of TEsystems result from the application of this methodology.
Comparing the qualitative analysis obtainedfor two TE systems, the authors show that several systems?
behaviors can be explained in terms of thecorrelation between the accuracy on monothematic pairs and the accuracy on the corresponding originalpairs.
In a component based framework, such analysis would allow a separate evaluation of TE modules,focusing on their ability to correctly address the inference types they are built to deal with.5 ConclusionsThis paper provides a definition for strong component-based TE framework, exploiting the commonintuition that decomposing the complexity of TE would allow a better comprehension of the problemfrom both a linguistic and a computational viewpoint.
We have reviewed the literature according toour definition, trying to position relevant works as more or less close to our idea of strong component-based TE.
We hope that the analysis of the different dimensions of the problem we provided may bringinteresting elements for future research works.
In this direction, we propose a research program inwhich for different applications (e.g.
domain, genre) specific TE component-based architectures couldbe optimized, i.e.
composed by modules that meet the requirements of that specific genre/domain.ReferencesAkhmatova, E. and M. Dras (2009).
Using hypernymy acquisition to tackle (part of) textual entailment.In Proceedings of TextInfer 2009, Singapore.
6 August.323Bar-Haim, R., J. Berant, I. Dagan, I. Greental, S. Mirkin, E. Shnarch, and I. Szpektor (2008).
Efficientsemantic deduction and approximate matching over compact parse forests.
In Proceedings of the TAC2008 Workshop on TE, Gaithersburg, Maryland, USA.
17 November.Bar-Haim, R., I. Szpektor, and O. Glickman (2005).
Definition and analysis of intermediate entailmentlevels.
In Proceedings of the ACL 2005 Workshop on Empirical Modeling of Semantic Equivalenceand Entailment, Ann Arbor, Michigan.
30 June.Bentivogli, L., E. Cabrio, I. Dagan, D. Giampiccolo, M. L. Leggio, and B. Magnini (2010).
Buildingtextual entailment specialized data sets: a methodology for isolating linguistic phenomena relevant toinference.
In Proceedings of LREC 2010, Valletta, Malta.
19-21 May.Bentivogli, L., B. Magnini, I. Dagan, H. Dang, and D. Giampiccolo (2009).
The fifth pascal recogniz-ing textual entailment challenge.
In Proceedings of the TAC 2009 Workshop on TE, Gaithersburg,Maryland.
17 November.Cabrio, E. and B. Magnini (2010).
Toward qualitative evaluation of textual entailment systems.
InProceedings of COLING 2010: Posters, Beijing, China.
23-27 August.Clark, P., P. Harrison, J. Thompson, W. Murray, J. Hobbs, and C. Fellbaum (2007).
On the role of lexicaland world knowledge in rte3.
In Proceedings of the ACL-07 Workshop on TE and Paraphrasing,Prague, Czech Republic.
28-29 June.Dagan, I., B. Dolan, B. Magnini, and D. Roth (2009).
Recognizing textual entailment: Rational, evalua-tion and approaches.
Natural Language Engineering (JNLE) 15(Special Issue 04), i?xvii.Garoufi, K. (2007).
Towards a better understanding of applied textual entailment.
In Master Thesis,Saarland University.
Saarbru?cken, Germany.Kirk, R. (2009).
Building an annotated textual inference corpus for motion and space.
In Proceedings ofTextInfer 2009, Singapore.
6 August.Kouylekov, M. and B. Magnini (2005).
Tree edit distance for textual entailment.
In Proceedings ofRALNP-2005, Borovets, Bulgaria.
21-23 September.Kozareva, Z. and A. Montoyo (2006).
Mlent: The machine learning entailment system of the universityof alicante.
In Proc.
of the second PASCAL Challenge Workshop on RTE, Venice, Italy.
10 April.Magnini, B. and E. Cabrio (2009).
Combining specialized entailment engines.
In Proceedings of LTC?09,Poznan, Poland.
6-8 November.Marneffe, M. D., A. Rafferty, and C. Manning (2008).
Finding contradictions in text.
In Proceedings ofACL-08, Columbus, OH, 15-20 June.Sammons, M., V. Vydiswaran, and D. Roth (2010).
Ask not what textual entailment can do for you... InProceedings of ACL-10, Uppsala, Sweden.
11-16 July.Vanderwende, L., D. Coughlin, and B. Dolan (2005).
What syntax can contribute in entailment task.
InProceedings of the First PASCAL Challenges Workshop on RTE, Southampton, U.K., 11-13 April.Wang, R. and G. Neumann (2008).
An accuracy-oriented divide-and-conquer strategy.
In Proceedingsof the TAC 2008 Workshop on TE, Gaithersburg, Maryland.
17 November.Zanzotto, F., M. Pennacchiotti, and A. Moschitti (2007).
Shallow semantics in fast textual entailmentrule learners.
In Proceedings of the ACL-PASCAL Workshop on TE and Paraphrasing, Prague, CzechRepublic.
23-30 June.324
