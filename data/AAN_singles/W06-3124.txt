Proceedings of the Workshop on Statistical Machine Translation, pages 158?161,New York City, June 2006. c?2006 Association for Computational LinguisticsMicrosoft Research Treelet Translation System:NAACL 2006 Europarl EvaluationArul Menezes, Kristina Toutanova and Chris QuirkMicrosoft ResearchOne Microsoft WayRedmond, WA 98052{arulm,kristout,chrisq}@microsoft.comAbstractThe  Microsoft  Research  translation  system  is  asyntactically  informed  phrasal  SMT  system  thatuses  a  phrase  translation  model  based  ondependency treelets and a global reordering modelbased  on  the  source  dependency  tree.
Thesemodels  are  combined  with  several  otherknowledge  sources  in  a  log-linear  manner.
Theweights of the individual components in the log-linear model  are set  by an automatic  parameter-tuning method.
We give a brief  overview of thecomponents  of  the  system  and  discuss  ourexperience with the Europarl data translating fromEnglish to Spanish.1.
IntroductionThe  dependency  treelet  translation  systemdeveloped at MSR is a statistical MT system thattakes  advantage  of  linguistic  tools,  namely  asource language dependency parser,  as well as aword alignment component.
[1]To  train  a  translation  system,  we  require  asentence-aligned parallel  corpus.
First  the sourceside is parsed to obtain dependency trees.
Next thecorpus  is  word-aligned,  and  the  sourcedependencies  are  projected  onto  the  targetsentences  using  the  word  alignments.
From  thealigned dependency corpus we extract  all  treelettranslation pairs,  and train an order model and abi-lexical dependency model.To translate, we parse the input sentence, andemploy  a  decoder  to  find  a  combination  andordering of treelet translation pairs that cover thesource tree and are optimal according to a set ofmodels.
In  a  now-common generalization  of  theclassic  noisy-channel  framework,  we  use  a  log-linear combination of models [2], as in below:translation?S , F ,?
?=argmaxT {?f ?F ?
f f ?S ,T ?
}Such an approach toward translation scoring hasproven  very  effective  in  practice,  as  it  allows  atranslation system to incorporate information froma  variety  of  probabilistic  or  non-probabilisticsources.
The weights  ?
= {  ?f } are selected bydiscriminatively training against held out data.2.
System DetailsA brief word on notation: s and t represent sourceand target lexical nodes; S and T represent sourceand target trees; s and t represent source and targettreelets  (connected  subgraphs  of  the  dependencytree).
The  expression  ?t?
T refers  to  all  thelexical items in the target language tree T and |T|refers to the count of lexical items in  T. We usesubscripts to indicate selected words: Tn representsthe nthlexical item in an in-order traversal of T.2.1.
TrainingWe  use  the  broad  coverage  dependency  parserNLPWIN  [3]  to  obtain  source  languagedependency  trees,  and  we  use  GIZA++  [4]  toproduce  word  alignments.
The  GIZA++ trainingregimen  and  parameters  are  tuned  to  optimizeBLEU [5] scores on held-out data.
Using the wordalignments,  we  follow a  set  of  dependency  treeprojection  heuristics  [1]  to  construct  targetdependency  trees,  producing  a  word-alignedparallel  dependency  tree  corpus.
Treelettranslation pairs are extracted by enumerating allsource treelets (to a maximum size) aligned to atarget treelet.2.2.
DecodingWe use a tree-based decoder, inspired by dynamicprogramming.
It searches for an approximation of158the n-best translations of each subtree of the inputdependency  tree.
Translation  candidates  arecomposed from treelet  translation pairs  extractedfrom the training corpus.
This process is describedin more detail in [1].2.3.
Models2.3.1.
Channel modelsWe  employ  several  channel  models:  a  directmaximum likelihood estimate of the probability oftarget  given  source,  as  well  as  an  estimate  ofsource given target and target given source usingthe word-based IBM Model 1 [6].
For MLE, weuse  absolute  discounting  to  smooth  theprobabilities:PMLE ?
t?s ?= c ?
s , t ??
?c ?
s ,* ?Here,  c represents  the  count  of  instances  of  thetreelet pair  ?s, t?
in the training corpus, and  ?
isdetermined empirically.For Model 1 probabilities we compute the sumover all possible alignments of the treelet withoutnormalizing for length.
The calculation of sourcegiven  target  is  presented  below;  target  givensource is calculated symmetrically.PM1?
t?s ?=?t?t ?s?s P ?
t?s ?2.3.2.
Bilingual n-gram channel modelsTraditional  phrasal  SMT systems  are  beset  by anumber of theoretical problems, such as the ad hocestimation  of  phrasal  probability,  the  failure  tomodel  the  partition  probability,  and  the  tenuousconnection  between  the  phrases  and  theunderlying  word-based  alignment  model.
Instring-based  SMT  systems,  these  problems  areoutweighed by the key role played by phrases incapturing  ?local?
order.
In  the  absence  of  goodglobal  ordering  models,  this  has  led  to  aninexorable  push  towards  longer  and  longerphrases, resulting in serious practical problems ofscale, without, in the end, obviating the need for areal global ordering story.In [13] we discuss these issues in greater detailand  also  present  our  approach  to  this  problem.Briefly,  we  take  as  our  basic  unit  the  MinimalTranslation Unit (MTU) which we define as a setof source and target word pairs such that there areno word alignment links between distinct MTUs,and  no  smaller  MTUs  can  be  extracted  withoutviolating the previous constraint.
In other words,these are the minimal non-compositional phrases.We then build models based on n-grams of MTUsin  source  string,  target  string  and  sourcedependency  tree  order.
These  bilingual  n-grammodels  in  combination  with  our  global  orderingmodel allow us to use shorter phrases without anyloss  in  quality,  or  alternately  to  improve  qualitywhile keeping phrase size constant.As an example,  consider the aligned sentencepair in Figure 1.
There are seven MTUs:m1 = <we should / hemos>m2 = <NULL / de>m3 = <follow / cumplir>m4 = <the / el>m5 = <Rio / Rio>m6 = <agenda / programa>m7 = <NULL / de>We can then predict the probability of each MTUin the context of (a) the previous MTUs in sourceorder,  (b) the previous MTUs in target order,  or(c) the ancestor MTUs in the tree.
We consider allof these traversal orders, each acting as a separatefeature function in the log linear combination.
Forsource and target traversal order we use a trigrammodel, and a bigram model for tree order.2.3.3.
Target language modelsWe  use  both  a  surface  level  trigram  languagemodel  and a dependency-based bigram languagemodel  [7],  similar  to  the  bilexical  dependencymodes  used  in  some  English  Treebank  parsers(e.g.
[8]).Psurf ?T ?=?i=1?T?Ptrisurf ?T i?T i?2 ,T i?1 ?Pbilex ?T ?=?i=1?T?Pbidep ?T i?parent ?T i ?
?Ptrisurf is a Kneser-Ney smoothed trigram languagemodel  trained  on  the  target  side  of  the  trainingcorpus,  and  Pbilex is  a  Kneser-Ney  smoothedwe?
?2 should?
?1 follow the?
?2 Rio?
?1 agenda?+1hemos?
?1 de?+1 cumplir el?
?1 programa?+1 de?
?1 R?o?+1Figure 1: Aligned dependency tree pair, annotated with head-relative positions159bigram language model trained on target languagedependencies  extracted  from the aligned  paralleldependency tree corpus.2.3.4.
Order modelThe  order  model  assigns  a  probability  to  theposition  (pos)  of  each target  node relative  to itshead based on information in both the source andtarget trees:Porder ?order ?T ?
?S ,T ?=?t?T P ?
pos ?
t , parent ?
t ??
?S ,T ?Here, position is modeled in terms of closeness tothe head in the dependency tree.
The closest pre-modifier  of  a  given  head  has  position  -1;  theclosest  post-modifier  has  a  position  1.
Figure  1shows an example dependency tree pair annotatedwith head-relative positions.We use a small set of features reflecting localinformation in the dependency tree to model P(pos(t,parent(t)) | S, T):?
Lexical items of t and parent(t), the parent of tin the dependency tree.?
Lexical items of the source nodes aligned to tand head(t).?
Part-of-speech  ("cat")  of  the  source  nodesaligned to the head and modifier.?
Head-relative  position  of  the  source  nodealigned to the source modifier.These  features  along  with  the  target  feature  aregathered  from  the  word-aligned  paralleldependency  tree  corpus  and  used  to  train  astatistical  model.
In  previous  versions  of  thesystem,  we trained a decision tree model  [9].
Inthe  current  version,  we  explored  log-linearmodels.
In addition to providing a different way ofcombining  information  from  multiple  features,log-linear models allow us to model the similarityamong different classes (target positions), which isadvantageous for our task.We  implemented  a  method  for  automaticselection  of  features  and  feature  conjunctions  inthe log-linear model.
The method greedily selectsfeature  conjunction  templates  that  maximize  theaccuracy  on  a  development  set.
Our  featureselection  study  showed  that  the  part-of-speechlabels of the source nodes aligned to the head andthe modifier and the head-relative position of thesource  node  corresponding  to  the  modifier  werethe  most  important  features.
It  was  useful  toconcatenate the part-of-speech of the source headwith  every  feature.
This  effectively  achieveslearning  of  separate  movement  models  for  eachsource head category.
Lexical information on thepairs  of  head  and  dependent  in  the  source  andtarget was also very useful.To model the similarity among different targetclasses  and  to  achieve  pooling  of  data  acrosssimilar classes, we added multiple features of thetarget position.
These features let our model know,for  example,  that  position  -5  looks  more  likeposition  -6  than  like  position  3.
We  added  afeature  ?positive?/?negative?
which  is  shared  byall  positive/negative  positions.
We  also  added  afeature looking at the displacement of a position inthe target from the corresponding position in thesource  and  features  which  group  the  targetpositions  into  bins.
These  features  of  the  targetposition are combined with features of the input.This  model  was  trained  on  the  providedparallel  corpus.
As  described  in  Section  2.1  weparsed the source sentences,  and projected targetdependencies.
Each  head-modifier  pair  in  theresulting target trees constituted a training instancefor the order model.The  score  computed  by  the  log-linear  ordermodel is used as a single feature in the overall log-linear  combination  of  models  (see  Section  1),whose  parameters  were  optimized  usingMaxBLEU  [2].
This  order  model  replaced  thedecision tree-based model described in [1].We compared  the  decision  tree  model  to  thelog-linear  model  on  predicting  the  position  of  amodifier  using  reference  parallel  sentences,independent of the full MT system.
The decisiontree  achieved  per  decision  accuracy  of  69%whereas  the  log-linear  model  achieved  perdecision accuracy of 79%.1In the context of thefull  MT system,  however,  the  new order  modelprovided  a  more  modest  improvement  in  theBLEU score of 0.39%.2.3.5.
Other modelsWe include two pseudo-models that help balancecertain biases inherent in our other models.?
Treelet  count.
This  feature  is  a  count  oftreelets  used  to  construct  the  candidate.
Itacts as a bias toward translations that use asmaller  number  of  treelets;  hence  towardlarger  sized  treelets  incorporating  morecontext.?
Word count.
We also include a count of thewords  in  the  target  sentence.
This  feature1The per-decision accuracy numbers were obtained ondifferent (random) splits of training and test data.160helps  to  offset  the  bias  of  the  targetlanguage model toward shorter sentences.3.
DiscussionWe participated in  the English to  Spanish  track,using  the  supplied  bilingual  data  only.
We usedonly the target side of the bilingual corpus for thetarget  language  model,  rather  than  the  largersupplied  language  model.
We  did  find  thatincreasing the target language order from 3 to 4had a noticeable impact on translation quality.
It islikely that a larger target language corpus wouldhave an impact, but we did not explore this.BLEUBaseline treelet system 27.60Add bilingual MTU models 28.42Replace DT order model with log-linear model 28.81Table 1: Results on development setWe found  that  the  addition of  bilingual  n-grambased  models  had  a  substantial  impact  ontranslation  quality.
Adding  these  models  raisedBLEU scores about 0.8%, but anecdotal evidencesuggests  that  human-evaluated  quality  rose  bymuch more than the BLEU score difference wouldsuggest.
In general, we felt that in this corpus, dueto the great diversity in translations for the samesource language words and phrases, and given justone reference translation, BLEU score correlatedrather  poorly  with  human  judgments.
This  wasborne out in the human evaluation of the final testresults.
Humans  ranked  our  system  first  andsecond,  in-domain  and  out-of-domainrespectively, even though it was in the middle of afield of ten systems by BLEU score.
Furthermore,n-gram  channel  models  may  provide  greaterrobustness.
While our BLEU score dropped 3.61%on out-of-domain data, the average BLEU score ofthe other nine competing systems dropped 5.11%.4.
References[1] Quirk,  C.,  Menezes,  A.,  and Cherry,  C.,  "DependencyTree Translation: Syntactically Informed Phrasal SMT",Proceedings of ACL 2005, Ann Arbor, MI, USA, 2005.
[2] Och, F.  J.,  and Ney, H.,  "Discriminative  Training andMaximum  Entropy  Models  for  Statistical  MachineTranslation",  Proceedings  of  ACL  2002,  Philadelphia,PA, USA, 2002.
[3] Heidorn, G., ?Intelligent writing assistance?, in Dale etal.
Handbook of Natural Language Processing, MarcelDekker, 2000.
[4] Och, F.  J.,  and Ney H.,  "A Systematic Comparison ofVarious  Statistical  Alignment  Models",  ComputationalLinguistics, 29(1):19-51, March 2003.
[5] Papineni,  K.,  Roukos,  S.,  Ward,  T.,  and  Zhu,  W.-J.,"BLEU: a method for automatic evaluation of machinetranslation",  Proceedings  of  ACL  2002,  Philadelphia,PA, USA, 2002.
[6] Brown,  P.  F.,  Della Pietra,  S.,  Della Pietra,  V. J.,  andMercer, R. L., "The Mathematics of Statistical MachineTranslation:  Parameter  Estimation",  ComputationalLinguistics 19(2): 263-311, 1994.
[7] Aue,  A.,  Menezes,  A.,  Moore,  R.,  Quirk,  C.,  andRingger,  E.,  "Statistical  Machine  Translation  UsingLabeled Semantic Dependency Graphs."
Proceedings ofTMI 2004, Baltimore, MD, USA, 2004.
[8] Collins,  M.,  "Three  generative,  lexicalised  models  forstatistical  parsing",  Proceedings of ACL 1997,  Madrid,Spain, 1997.
[9] Chickering,  D.M.,  "The  WinMine  Toolkit",  MicrosoftResearch  Technical  Report  MSR-TR-2002-103,Redmond, WA, USA, 2002.
[10] Och,  F.  J.,  Gildea,  D.,  Khudanpur,  S.,  Sarkar,  A.,Yamada, K., Fraser, A., Kumar, S., Shen, L., Smith, D.,Eng,  K.,  Jain,  V.,  Jin,  Z.,  and  Radev,  D.,  "ASmorgasbord  of  Features  for  Statistical  MachineTranslation".
Proceedings of HLT/NAACL 2004, Boston,MA, USA, 2004.
[11] Bender,  O.,  Zens,  R.,  Matsuov,  E.  and  Ney,  H.,"Alignment  Templates:  the  RWTH  SMT  System".IWSLT Workshop at INTERSPEECH 2004, Jeju Island,Korea, 2004.
[12] Och, F. J., "Minimum Error Rate Training for StatisticalMachine  Translation",  Proceedings  of  ACL  2003,Sapporo, Japan, 2003.
[13] Quirk,  C  and  Menezes,  A,  ?Do  we  need  phrases?Challenging  the  conventional  wisdom  in  StatisticalMachine  Translation?,  Proceedings  of  HLT/NAACL2006, New York, NY, USA, 2006161
