Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 1064?1073,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsImproving social relationships in face-to-face human-agent interactions:when the agent wants to know user?s likes and dislikesCaroline LangletInstitut Mines-T?el?ecomT?el?ecom ParisTechCNRS LTCIcaroline.langlet@telecom-paristech.frChlo?e ClavelInstitut Mines-T?el?ecomT?el?ecom ParisTechCNRS LTCIchloe.clavel@telecom-paristech.frAbstractThis paper tackles the issue of the detec-tion of user?s verbal expressions of likesand dislikes in a human-agent interaction.We present a system grounded on the theo-retical framework provided by (Martin andWhite, 2005) that integrates the interac-tion context by jointly processing agent?sand user?s utterances.
It is designed asa rule-based and bottom-up process basedon a symbolic representation of the struc-ture of the sentence.
This article alsodescribes the annotation campaign ?
car-ried out through Amazon Mechanical Turk?
for the creation of the evaluation data-set.
Finally, we present all measures forrating agreement between our system andthe human reference and obtain agreementscores that are equal or higher than sub-stantial agreements.1 IntroductionIn the research field of the embodied conversa-tional agents (ECA), detecting sentiment-relatedphenomena1appears as a key task to improvehuman-agent interactions and to build long-termsocial relationships (Pecune et al, 2013).
Sev-eral models and applications have been proposedwhich mostly take into account non-verbal cues(acoustic features, facial or bodily expressions)to determine the user?s emotions (Schuller et al,2011).
The verbal content is more and more inte-grated but still partially exploited in human-agentinteractions.
The very infrequent works, integrat-ing the detection of user?s sentiments in ECAs1The term sentiment-related phenomena is used in (Clavelet al, 2013) to regroup all the phenomena related to sentimentin the literature, from opinion to affect and emotion.based on linguistic cues, concern avatars and vi-sualisation issues rather than face-to-face interac-tion, (Zhang et al, 2008; Neviarouskaya et al,2010b).
We identify so far two studies that in-tegrate a sentiment detection module for human-agent interaction (Smith et al, 2011; Yildirim etal., 2011).However, the research field of sentiment anal-ysis and opinion mining provides a set of inter-esting works dealing with the subjective informa-tion conveyed by the verbal content.
Three typesof approaches are considered: machine-learning,rule-based approaches and hybrid approaches thatare a combination of the first two types.
Machinelearning methods have proven their worth for thepositive and negative classification of sentencesor texts (Pang and Lee, 2008).
Rule-based ap-proaches are grounded on syntactic and semanticanalyses of the sentence and provide deeper anal-yses of sentiment-related phenomena.
For exam-ple, (Neviarouskaya et al, 2010a) and (Moilanenand Pulman, 2007) provide linguistic rules deal-ing with the principle of compositionality in or-der to improve the detection of opinion targets andthe resolution of polarity.
Similarly, (Shaikh et al,2009) provide a linguistic adaptation of the OCCmodel (Ortony, Clore and Collins (Ortony et al,1990) based on logic and semantic rules.
Hybridapproaches also begin to be used for more fine-grained opinion and sentiment analysis (Yang andCardie, 2013)Sentiment/opinion detection methods used inhuman-agent interaction are rare and, when theyare employed, they are not different from the onesused in opinion mining: they are consequentlynot designed for socio-affective interactions.
In-deed, the development of a module for the detec-tion of sentiment-related phenomena in face-to-face human-agent interactions requires to tackle1064various scientific issues: the delimitation of therelevant sentiment-phenomenon to detect, the in-tegration of the multi-modal context and the man-agement of the spontaneous and conversationalspeech.The present paper tackles two of the issues: theintegration of the conversational context and thedelimitation of the relevant phenomenon.
Regard-ing the first issue, we propose a system relying ona rule-based method that allows us to model theagent?s utterances in order to help the detection ofuser?s sentiment-related phenomena.Then, we delimit and specify the linguistic phe-nomenon to detect by focusing on one specific as-pect required by ECAs for modelling social rela-tionships: the user?s likings that are given by theexpressions of user?s likes and dislikes in the ver-bal content.This paper is organised as follows: first, wepresent the theoretical model which our system isgrounded on (Section 2).
Then, we provide a de-scription of the system: each stage of the bottom-up process is described, including the linguisticrules and the patterns used by the system.
In Sec-tion 4, we introduce the annotation campaign welaunched on Amazon Mechanical Turk (AMT) inorder to create a data-set for the evaluation of oursystem.
Finally, we present and discuss the resultsof the system evaluation (Section 5).2 Theoretical backgroundThe liking is one of the key dimensions usedfor the modelling of social relationships (Pecuneet al, 2013).
The definition of this concept isgrounded on the Heider?s Balance Theory (Heider,1958) and is defined as: ?the way relations amongpersons involving some impersonal entity are cog-nitively experienced by the individual?
(Zajonc,1960).
Heider?s theory is integrated in social agentcomputational models by defining scenarios wherethe agent and the user?s likings toward each otherare determined by their liking toward other entities(things, process or events).
In such scenarios, theanalysis of user?s verbal content has a key role asa major source of information for determining ofthe user?s likes and dislikes.
Therefore, a linguis-tic description of this phenomenon is required todesign a detection system.In the research field of Opinion Mining and Sen-timent Analysis, the majority of opinion/sentimentdetection systems focus on the positive/negativedistinction or on the classification of a restrictednumber of emotion categories.
Other in-depth ap-proaches, as (Wiebe et al, 2005; Breck et al,2007), refer to the Private State Theory, whichdefines mental states as involving opinions, be-liefs, judgements, appraisals and affects.
Besidethose models, the model proposed by (Martin andWhite, 2005) is increasingly used in several works(Neviarouskaya et al, 2010a; Bloom et al, 2007;Whitelaw et al, 2005).
This model provides a lin-guistic description and a focus on the verbal ex-pressions of sentiment and opinion and proposes acomplex framework, for describing how attitudesare expressed in English.
It distinguishes affects?
which are concerned with emotional reactions?
from judgements and appreciations ?
which re-late to evaluations toward people?s behaviours andsemiotic or natural phenomena.
Finally, it mod-els attitudinal expressions as relying on three ele-ments: a source, the person evaluating or experi-encing, a target, the entity which is evaluated orwhich triggers an affect and a linguistic clue ex-pressing the evaluation.In this model, likes and dislikes can be consid-ered as a subcategory of the Attitudes.
This subcat-egory overlaps the three categories (affect, judg-ment, appreciation) defined by (Martin and White,2005).
For example, the sentence ?This paintingmakes me sad?
is considered as an affect, whilethe sentence ?This painting is a master-work?
isconsidered as an appreciation.
But, in both cases,we can consider them as a user?s like.
How-ever, among the expressions of attitudes where thesource is the user, some of them do not refer toa like or dislike.
For example, ?I?m very happy?refers to an affect and does not give any clue re-garding a possible like or dislike.
Thus, a selec-tion of relevant attitudes have to be done.
Therules used for this selection are presented in thenext section.3 A rule-based and symbolic methodOn the basis of the Martin and White?s model de-scribed in the previous section, we design a systemable to detect expressions of attitudes correspond-ing to the user?s likes and dislikes.
It is groundedon linguistic rules modelling the syntactic and se-mantic structure of the sentences.3.1 Integrating the interaction contextThe system presented in Figure 1 successivelyprocesses each adjacency pair (AP) of the dialogue1065Figure 1: Process overview(Sacks et al, 1974), i.e.
each user?s speech turnand the agent?s one immediately preceding it.
Weaim to detect two kinds of user?s attitudinal expres-sions that can occur during the interaction: the firstones which are spontaneous and do not depend onthe agent?s sentence (Agent: What did you do to-day?
User: I saw a great movie); and the secondones which are triggered by the agent?s sentence(Agent: Do you like outdoors activities?
User:Yeah very much).In the last case, the detection of the attitude ex-pressed in the agent?s sentence appears as a neces-sary step for the detection of the user?s ones.
Thisdetection has to be done in an automatic way as,in the agent platform we use (the Greta platform,(Bevacqua et al, 2010), the agent?s speech turnsare not automatically generated but scripted.
Thus,we cannot obtain the linguistic and semantic infor-mation about attitude by using the generation data.Furthermore, in order to make the dialogue settingas light as possible, it is not possible to script suchvalues for each agent?s sentence.3.2 A bottom-Up processThe relevant expressions of attitudes are de-tected by using a bottom-up and rule-basedprocess, which launches successively the differentlevels of analysis: lexical level, chunk level,sentence level.
These three stages compriseformal grammars, which are implemented withinthe Unitex plateform (Paumier, 2015).
Duringthese various stages, values are assigned to thethree boolean variables which are finally used todecide whether the user is expressing a like or adislike: RelevantAttExpr(agtSentence),RelevantAttExpr(usrSentence),Y esNoAnswer(usrSentence).3.2.1 Lexical levelAfter a tokenisation and a POS-tagging, the sys-tem checks whether the sentence (the user orthe agent?s one) contains lexical clues of atti-tudinal expressions.
Three parts of speech aretaken into account: the nouns, the adjectivesand the verbs.
We use a re-adaptation of theWordnet-affect lexicon (Valitutti, 2004).
In or-der to adapt this lexicon to our goal, a selec-tion of relevant lexical entries has to be done.Among all the synsets, we select those which canbe linked to like and dislike and that belong tothe following main categories: positive-emotion,negative-emotion, neutral-emotion.
As the lexi-1066Figure 2: Patterns and polarity rules used for the chunk levelcon is applied by the Unitex plateform, we turnthe Wordnet-Affect lexicon into a unitex dictio-nary format.
Finally, this transformation providesthree dictionaries: one for the nouns, one for theadjectives and one for the verbs.
If the lexical pro-cessing has found one or several lexical clues ofattitude, the system continues the analysis and getto the next stage, else RelevantAttExpr(X) =False and the system quits the analysis of the sen-tence.
Regarding the user?s sentence, the systemalso checks if one or several tokens of sentencematch with a yes or a no word, by using a shortlexicon manually built which comprises less thanten words for each sentence type.
If the test suc-ceeds Y esNoAnswer(usrSentence) = True,else Y esNoAnswer(usrSentence) = False.3.2.2 Chunk levelAt this level, we design formal grammar ?
imple-mented as finite state automatons within the Uni-tex plateform.
Three main chunks are defined: theverbal, the adjectival and the nominal chunks.
Allthese chunks can imply a lexical unit of attitude.
Insuch case, a polarity value is assigned to the entirechunk by applying rules which consider valenceshifters and polarity conflict (see Figure 2).3.2.3 Sentence levelAttitudinal value The system parse of each sen-tence for checking if the sentence matches withan attitudinal expression, according to its syntacticstructure.
This parsing phase is grounded on a setof patterns (see Figure 3).
Among the attitudinalpatterns provided in the literature (Neviarouskayaet al, 2010a; ?
), we selected those expressinga like or dislike according to a previous corpus-based study (Langlet and Clavel, 2014) (develop-ment corpus presented in Section 4.1).
Depend-ing on the speaker of the processed sentence ?
theagent or the user ?
sentence structures can be in-terrogative or affirmative surface structures.
In theagent?s sentence, the system looks for both affir-mative and interrogative forms, while in the user?ssentences, it only takes into account affirmativestructures.Type of the source Simultaneously, the systemchecks the source of the attitude.
The type of arelevant source varies depending on the sentenceprocessed: in the agent?s sentence, the systemaims to detect attitudes able to be validated or in-validated by the user and whose source is eitherthe agent ?
lexically represented by a first personpronoun (Src(agt) ?
?I?|?me?)
?
or the user ?lexically represented by a second person pronoun(Src(usr) ?
?you?
); in the user?s sentence, thesystem aims to detect only the attitudes whosesource is the user ?
represented by a first personpronoun (Src(usr)?
?I?|?me?
).Target and polarity At this stage, the system isalso able to define the polarity of the expression1067Figure 3: Patterns and polarity rules used for the sentence level: the second column presents examplesof sentences matching with the patterns detailed in the first column.
The rules introduced in the thirdcolumn are applied according to the sentence pattern detected.by detecting the valence shifters which can modifythe polarity of the attitudinal chunk and by apply-ing the appropriate polarity rules described in Fig-ure 3.
Regarding the target, the system is only ableto assign to the target one of four generic classes.The first two classes concern the two members ofthe conversation ?
agent and user.
The third class,called other, deals with all entities and processeswhich are neither the agent or the user.
The lastone ?
unknown ?
concerns all the target referringby a pronoun, and whose class ?
even generic ?cannot be known.
In a future work, the other cate-gory could be detailed by using an ontological re-source, and unknown category by referring to ananaphora resolution.3.2.4 User?s utterance level within the APGenerating attitude feature set Once the sen-tence level is done, the True value is assigned tothe relevantAttExpr(usrSentence) variable intwo steps.Firstly, the syntactic structure of the user?ssentence matches with one of the attitudinalpatterns (Figure 3) whose source is the user(Src(user)).
The feature set of the atti-tudinal expression is generated according tothe information found at the parsing stage:source ?
{user, agent}, polarity ?
{neg, pos},targetType ?
{user, agent, other, unknown}.Secondly, if the agent?s sentence matches withone of the attitudinal patterns whose source iseither the user or the agent (Src(user|agent)),then relevantAttExpr(agtSentence) =True.
In this second case, ifY esNoAnswer(usrSentence) == True,the user validates or invalidates theattitude.
Thus, the system definesrelevantAttExpr(usrSentence) == True,even if any sentence matching with a relevantpattern has been found in the user?s sentence.The feature set associated to the user?s attitude isbuilt according to those assigned to the attitudinalexpression found is the agent?s sentence.
Sincethe user assumes or rejects the attitude expressedby the agent, the system considers that he/sheutters an attitudinal expression that he/she isthe source.
Regarding the polarity, if the uservalidates the statement expressed by the agent,the polarity of his/her attitude is the same as theagent?s one.
Otherwise, if the user expresses a noanswer, the polarity is the opposite of the agent?sone.1068Converting attitude into like-dislike The pat-terns used for the parsing phase refer toattitudes that are good candidates for ex-pressions of like or dislike.
When therelevantAttExpr(usrSentence) == True, thesystem converts the attitude into a like or a dis-like on the basis of the feature set associated tothe expression of attitude: an attitude with a pos-itive polarity (attitude(pol : pos)) is consideredas a like, and an attitude with a negative polarity(attitude(pol : neg)) is considered as a dislike.The target is the same as the attitudinal expression.4 Corpus for evaluating the system4.1 Semaine corpusIn order to evaluate our system, an annotated dataset of sentences extracted from the Semaine cor-pus (McKeown et al, 2011) has been created.This corpus comprises 65 manually-transcribedsessions where a human user interacts with a hu-man operator playing the role of the virtual agent.These interactions are based on a scenario involv-ing four agent characters: Poppy, happy and out-going, Prudence, sensible and level-headed, Spike,angry and confrontational and Obadiah, depres-sive and gloomy.
Agent?s sentences are con-strained by a script (however, some deviations tothe script occur in the database) aimed at puttingthe user in the same state as the one of the playedcharacter.
30 sessions of the corpus have beenused for the development set.
The rest of the datahas been considered to build the evaluation corpusfollowing the protocol described in the next para-graph.4.2 Annotation protocol on AMTWe use AMT platform to carry out the annota-tion campaign.
It allows us to easily recruit alarge number of English native speakers.
Recentworks have shown the reliability of the annota-tions provided by this platform.
For various tasksof language annotation ?
evaluation of machinetranslation (Callison-Burch, 2009), affect recogni-tion (Snow et al, 2008), or dictionary validation(Taboada et al, 2011) ?
they observe a high agree-ment of non-expert raters with the gold standards.For our annotation protocol, the recruited anno-tators are put in the same conditions as the system:each annotator has to label the user?s likes anddislikes by only considering the AP (without thewhole interaction) and the verbal content (with-out the audio and video).
Among the pairs havingless than thirty words in the evaluation corpus, werandomly selected 600 APs ?
made of an agent?sspeech turn and a user?s one (see Section 3.1).This length of the sentence has been restricted toavoid annotation difficulties.The dataset is divided in 60 subsets of 10 APs.In order to secure the annotation and to preventthe annotators from doing the annotation task twotimes, we use TurkGate tool (Goldin and Darlow,2013).
The AMT workers have been selected ac-cording to their approval rate ?
greater than orequal to 99% ?
and to the number of task approved?
greater than or equal to 10000.
Each subset ofthe corpus is randomly assigned to one annotator,and the order in which the AP are presented toeach annotator is also randomly defined.
A train-ing phase is previously subjected to each annotatorin order to familiarise him/her to the annotationprinciples.
Finally, 240 AMT workers have par-ticipated to the annotation campaign (4 for eachsubset).Questionnaire As the annotation is done bynon-expert annotators, we design a simplified andintuitive annotation process: for each pair, the an-notators have to answer to a set of questions fea-tured in Figure 4.
The goal of the questionnaireis to determine whether the annotator is able todeduce a user?s like or dislike from the APs.
Inorder to facilitate the annotation and to make theinterpretation of each sentence as spontaneous aspossible, the question have been designed withoutlinguistic technical word.
In this way, the task ismore functional for the annotator and it is easierfor him/her to put his/herself to the place of thehearer.
Each question of the questionnaire focuseson one of the outputs of the detection system:?
The first question examines the presence ofan expression of like or dislike and providesa yes/no answer.?
the second question deals with the multipleoccurrences of like/dislike expressions in thesame speech turn.
We limited the answerto ?4?
(maximum number of like/dislike ex-pressions observed in the dataset).
If the an-notator detects more than one expression oflike/dislike, the questions 3 to 4 are asked foreach expression of like/dislike.?
the third question deals with the type of thetarget.
As answers, only the four types ?1069Figure 4: Annotation process on AMTthose the system is able to detect ?
are pro-posed.?
The fourth question concerns the polarityof the expression: positive (like) or negative(dislike).4.3 Inter-annotator agreement andconsistencyWe measure the inter-annotators agreement orconsistency at each stage of the questionnaire.
Allthe measures presented in the section have beenapplied for each subset of the corpus (60 subsetsof 10 APs, 4 annotators for each subset).Fleiss?
Kappa Cronbach?s alphaMax 0.79 0.90Median 0.32 0.72Average 0.25 0.59Table 1: Fleiss?
kappa scores and Cronbach?s al-pha coefficients obtained in on the 60 subsetsRegarding the answer to the first question ofthe questionnaire, we measure how the annota-tors are agreeing on the presence of at least oneuser expression of like or dislike by using theFleiss?
Kappa (Fleiss, 1971) (see Table 1).
Sec-ond, we measure the consistency on the annotationof the number of user?s expressions to each pairby using the Cronbach?s alpha coefficient (Cron-bach, 1951).
As, for labeling the number of likes-dislikes expressed in each pair, the crowd-workershave to select a value on a scale (from 1 to 4), it ap-pears as suitable to measure the relative similaritybetween ratings rather than the agreement aboutan exact value.
The Cronbach?s alpha is designedfor evaluating the internal consistency of a scaleannotation.
In this way, it measures the degree towhich different raters or observers make consis-tent estimates of the same phenomenon.The obtained scores are encouraging.
Regard-ing the agreement on the presence of an expres-sion of like or dislike, even if the median scoreis comprised between 0.30 and 0.40, the maxi-mal value equals to 0.79.
Moreover, 40% of thesubsets has a kappa score comprised between 0.40and 0.60.
The consistency score is also significant:51% of the annotated sub-corpus has a score equalor higher than 0.7, which is considered as an ac-ceptable level of agreement (George and Mallery,2010).For the polarity and the target type, we selectthe pairs where at least two annotators agree onthe presence of an expression of like or dislike,and we consider only the annotations provided bythese annotators.
After this selection, we obtaina sub-set of ratings with a unfixed set of annota-tors.
As the Fleiss?
Kappa must be applied on datawith an invariable and fixed set of raters, we con-sider the percent agreement (Gwet, 2010) as moreappropriate.
Even though, it seems sometimesdifficult for the annotators to agree on the pres-ence of a user?s expression of like or dislike, theiragreement on the polarity of such expressions ap-pears as more significant: 41% of the sub-corpushas a percentage of agreement between 50% and75% and 52% of the sub-corpus has a percentageof agreement upper than 75%.
The agreement is1070also significant regarding the target: 61% of thesub-corpus has a percentage of agreement upperthan 50%.
All these results are quite positive fora system-oriented annotation of a such subjectivephenomenon.5 Evaluation of the system5.1 ProtocolFrom the 600 pairs of the previously annotatedcorpus, we keep 503 pairs for the evaluation of thesystem by removing the pairs where a consensuscan not be found between the 4 annotators ?
thatis that we keep as a reference the majority votecorresponding to the data where at least three an-notators agree.
We use three different measuresto evaluate the system performance relying on theagreement measures presented in Section 4.3: thedetection of the presence of a user?s expression oflike or dislike is evaluated by the Fleiss?
kappabetween the system output and the reference; theconsistency on the number of detected expressionsis evaluated by the Cronbach?s alpha coefficient;the agreement on the polarity is measured by us-ing the Fleiss?
kappa; and the agreement on thetarget type with the percentage of agreement.5.2 ResultsTable 2 presents the results obtained for each de-tection task (presence of a like/dislike expression,detection of the correct number of expressionscontained in an sentence, and correct classificationbetween like and dislike).
The agreement betweenNo Expr-Expr k = 0.61Nb of expressions rated ?
= 0.67Polarity k = 0.84Target type p = 53%Table 2: Agreement scores between the systemoutput and the referencethe system output and the reference is substantialfor the detection of the presence of a user expres-sion (k = 0.61) and the number of user expres-sions is also correctly detected by the system (ac-ceptable ?
largely higher than 0.6).
However, themajor part of the corpus contains no more than 1like/dislike expression (98% of the pairs are an-notated by the reference and the system as con-taining 0 or 1 like/dislike expression).
4% of thepairs (25 pairs) is annotated by the system as con-taining 1 expression, while the referred annotationdoes not indicate the presence of any like/dislikeexpression.
For 8% of the pairs (43 pairs), it is theopposite phenomenon (1 expression annotated bythe reference but not by the system).
The Fleiss?kappa score obtained for the polarity is really en-couraging since it equals 0.844.
Regarding thetarget type, we obtain a percentage of agreementat 53%.
The disagreement frequently concerns aconfusion between the unknown and other cate-gories.5.3 DiscussionWe have carried out an in-depth analysis of thedisagreement between the system outputs and thehuman annotations in order to identify tracks forthe improvement of the system.
We identified twomain types of difficulties.The first difficulty concerns the processing ofspontaneous speech.
The Semaine corpus con-tains a great number of disfluent utterances thatdisrupt the syntactical structure of the speech turnand thus hinder both the annotation process andthe detection system.
In the following pair, Agent:??Oh!?
?
User: ?
?are just very good really goodfilm and read a book?, the grammatical structureof the user sentence is fuzzy (absence of the sub-ject, presence of repairs) which makes the pars-ing of the sentence and thus the detection of atti-tudinal patterns difficult.
However, the annotatorshave here correctly identified the presence of a likeand the type of the target (?the film?
in the Otherscategory), which is not the case for all the anno-tations of the disfluent utterances.
To handle thisdifficulty, it would be interesting to integrate a sys-tem able to automatically label disfluencies, suchas the one presented in (Dutrey et al, 2014).
Thedisfluent structure of the sentence could thus be in-tegrated to our syntactic and semantic rules.
How-ever, the automatic detection of disfluencies is stillan open challenge, in particular in the case of editdisfluencies where the speaker corrects or altersthe utterance or abandons it entirely and starts over(Strassel, 2004).The second difficulty concerns the lack of con-text provided by some of the APs.
Our system of-fers a first step in the integration of the interac-tion context by considering jointly the user?s ut-terance and the previous agent?s one that allow usto correctly analyse a large scale of expressions.However, the system and the annotators have to fo-cus on the APs without considering the preceding1071speech turns, which can cause disagreements notonly between the system outputs and the humanannotations, but also between the human annota-tors.
In the following example, Agent: ?good.
ahgood?
?
User: ?my favourite emotion?, the source(here, the user) can be easily identified but the in-formation contained in the AP is not sufficient toidentify the target.
An interesting answer to thisissue is to take into account the whole conversa-tion preceding a user?s utterance as a significantcontext for the latter.
This will imply the designof new complex rules taking into account a largerinteraction context.6 Conclusion and future worksWe have introduced a NLP-based system able todetect user?s expressions of likes and dislikes inthe conversation with an ECA.
This system re-lies on syntactic and semantic rules integratingthe interaction context by analysing the content ofthe agent?s utterances to help the analysis of theuser?s ones.
It is designed as a bottom-up andrule-based process.
The system has been evalu-ated by using an evaluation data set created underAMT platform.
This first and pioneering versionof the system shows encouraging results for thedifferent tasks performed by the system that con-cern the detection of relevant like/dislike expres-sions (substantial agreement with a Fleiss kappaat 0.61), the categorization of the expressions be-tween like and dislike (almost perfect agreementwith a Fleiss kappa at 0.84) ?
polarity assignment?
and the identification of the target type (53%of agreement between the reference and the sys-tem output).
Beyond these quite optimistic results,we have provided some tracks for the system im-provement that concerns a deeper integration ofthe interaction context and the processing of spon-taneous speech features.AcknowledgmentsThe authors would like to thank the GRETA teamfor its contributions to the Greta and Vib plat-forms.
This work has been supported by the eu-ropean project ARIA-VALUSPA, and performedwithin the Labex SMART (ANR-11-LABX-65)supported by French state funds managed by theANR within the Investissements d?Avenir pro-gramme under reference ANR-11-IDEX-0004-02.ReferencesElisabetta Bevacqua, Ken Prepin, RadoslawNiewiadomski, Etienne de Sevin, and Cather-ine Pelachaud.
2010.
Greta: Towards an interactiveconversational virtual companion.
Artificial Com-panions in Society: perspectives on the Present andFuture, pages 143?156.K.
Bloom, N. Garg, and S. Argamon.
2007.
Extract-ing appraisal expressions.
HLT-NAACL, pages 165?192, April.E.
Breck, Y. Choi, and C. Cardie.
2007.
Identifying ex-pressions of opinion in context.
In Sangal S., MehtaH., and Bagga R. K., editors, International JointConference On Artifical Intelligence, pages 2683?2688, San Francisco, CA.
Morgan KoffMann Pub-lishers.C.
Callison-Burch.
2009.
Fast, cheap, and creative:Evaluating translation quality using amazon?s me-chanical turk.
In Proceedings of the 2009 Confer-ence on Empirical Methods in Natural LanguageProcessing, EMNLP ?09, Stroudsburg, PA, USA.Association for Computational Linguistics.C.
Clavel, C. Pelachaud, and M. Ochs.
2013.
User?ssentiment analysis in face-to-face human-agent in-teractions prospects.
In Workshop on Affective So-cial Signal Computing, Satellite of Interspeech.
As-sociation for Computational Linguistics, August.L.J Cronbach.
1951.
Coefficient alpha and the internalstructure of tests.
Psychometrika, 16(3):297?334.C.
Dutrey, C. Clavel, S. Rosset, I. Vasilescu, andM.
Adda-Decker.
2014.
A crf-based approach to au-tomatic disfluency detection in a french call-centrecorpus.
In Interspeech, page to appear.J.L.
Fleiss.
1971.
Measuring nominal scale agree-ment among many raters.
Psychological Bulletin,76(5):378?382.D.
George and P. Mallery.
2010.
SPSS for WindowsStep by Step: A Simple Guide and Reference 18.0Update.
Prentice Hall Press, Upper Saddle River,NJ, USA, 11th edition.G.
Goldin and A. Darlow.
2013.
Turkgate (version0.4.0) [software].
http://gideongoldin.github.com/TurkGate/.K.
L. Gwet.
2010.
Handbook of Inter-Rater Reliabil-ity.
11th edition.F.
Heider.
1958.
The psychology of interpersonal rela-tions.
Lawrence Erlbaum associates Inc.C.
Langlet and C. Clavel.
2014.
Modelling user?s at-titudinal reactions to the agent utterances: focus onthe verbal content.
In 5th International Workshopon Corpora for Research on Emotion, Sentiment &Social Signals (ES3 2014), Reykjavik, Iceland, May.1072J.
R. Martin and P. R. White.
2005.
The Language ofEvaluation.
Appraisal in English.
Macmillan Bas-ingstoke, London and New York.G.
McKeown, M. Valstar, R. Cowie, M. Pantic, andM.
Schroder.
2011.
The semaine database: An-notated multimodal records of emotionally coloredconversations between a person and a limited agent.IEEE Transactions on Affective Computing, 3(1):5?17, Jan-March.K.
Moilanen and S. Pulman.
2007.
Sentiment com-position.
In Proceedings of Recent Advances inNatural Language Processing (RANLP 2007), pages378?382, September 27-29.A.
Neviarouskaya, H. Prendinger, and M. Ishizuka.2010a.
Recognition of affect, judgment, and ap-preciation in text.
In Proceedings of the 23rd In-ternational Conference on Computational Linguis-tics, COLING ?10, pages 806?814, Stroudsburg, PA,USA.
Association for Computational Linguistics.A.
Neviarouskaya, H. Prendinger, and M. Ishizuka.2010b.
User study on AffectIM, an avatar-based In-stant Messaging system employing rule-based affectsensing from text.
International Journal of Human-Computer Studies, 68(7):432?450.A.
Ortony, G.L.
Clore, and A. Collins.
1990.
The Cog-nitive Structure of Emotions.
Cambridge, UniversityPress.B.
Pang and L. Lee.
2008.
Opinion mining and senti-ment analysis.
Foundations and Trends in Informa-tion Retrieval, 2(1-2):1?135, January.S.
Paumier.
2015.
Unitex user manual.
Universit?e deParis-Est Marne-la-Vall?ee.F.
Pecune, M. Ochs, and C. Pelachaud.
2013.
A formalmodel of social relations for articial companions.
InEUMAS 2013, December.H.
Sacks, E.A.
Schegloff, and G. Jefferson.
1974.
Asimplest systematics for the organization of turn-taking for conversation.
Language, 50(9-10):696?735, November.B.
Schuller, A. Batliner, S. Steidl, and D. Seppi.
2011.Recognising realistic emotions and affect in speech:State of the art and lessons learnt from the firstchallenge.
Speech Communication, 53(9-10):1062?1087, November.M.
Shaikh, H. Prendinger, and M. Ishizuka.
2009.
Alinguistic interpretation of the occ emotion modelfor affect sensing from text.
In Affective Informa-tion Processing, pages 378?382.
Springer London,May.C.
Smith, N. Crook, S. Dobnik, and D. Charlton.
2011.Interaction strategies for an affective conversationalagent.
In Presence: Teleoperators and Virtual Envi-ronments, volume 20, pages 395?411.
MIT Press.R.
Snow, B. O?Connor, D. Jurafsky, and Y. Andrew.2008.
Cheap and fast?but is it good?
: Evalu-ating non-expert annotations for natural languagetasks.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing,EMNLP ?08, Stroudsburg, PA, USA.
Association forComputational Linguistics.S.
Strassel, 2004.
Simple Metadata Annotation Speci-fication.
Linguistic Data Consortium.M.
Taboada, J. Brooke, M. Tofiloski, K. Voll, andM.
Stede.
2011.
Lexicon-based methods for sen-timent analysis.
Computational Linguistics, 37(2),June.R.
Valitutti.
2004.
Wordnet-affect: an affective exten-sion of wordnet.
In In Proceedings of the 4th In-ternational Conference on Language Resources andEvaluation, pages 1083?1086.C.
Whitelaw, N. Garg, and S. Argamon.
2005.
Usingappraisal taxonomies for sentiment analysis.
Pro-ceedings of CIKM-05, the ACM SIGIR Conferenceon Information and Knowledge Management, April.J.
Wiebe, T. Wilson, and C. Cardie.
2005.
Anno-tation expressions of opinion and emotions in lan-guage.
Language Resources and Evaluation, pages165?210, Vol.
39/2-3.B.
Yang and C. Cardie.
2013.
Joint inference for fine-grained opinion extraction.
In Proceedings of the51st Annual Meeting of the Association for Compu-tational Linguistics (Volume 1: Long Papers), pages1640?1649, Sofia, Bulgaria, August.
Association forComputational Linguistics.S.
Yildirim, S. Narayanan, and A. Potamianos.
2011.Detecting emotional state of a child in a conversa-tional computer game.
Computer Speech and Lan-guage, 25(1):29?44.R.B.
Zajonc.
1960.
The psychology of interpersonalrelations.
Public Opinion Quarterly, 24(2).L.
Zhang, J. Barnden, R.J. Hendley, M.G.
Lee, A.M.Wallington, and Zhigang Wen.
2008.
Affect detec-tion and metaphor in e-drama.
International Journalof Continuing Engineering Education and Life-LongLearning, 18(2):234.1073
