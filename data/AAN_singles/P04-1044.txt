Combining Acoustic and Pragmatic Features to Predict RecognitionPerformance in Spoken Dialogue SystemsMalte GabsdilDepartment of Computational LinguisticsSaarland UniversityGermanygabsdil@coli.uni-sb.deOliver LemonSchool of InformaticsEdinburgh UniversityScotlandolemon@inf.ed.ac.ukAbstractWe use machine learners trained on a combina-tion of acoustic confidence and pragmatic plausi-bility features computed from dialogue context topredict the accuracy of incoming n-best recogni-tion hypotheses to a spoken dialogue system.
Ourbest results show a 25% weighted f-score improve-ment over a baseline system that implements a?grammar-switching?
approach to context-sensitivespeech recognition.1 IntroductionA crucial problem in the design of spoken dialoguesystems is to decide for incoming recognition hy-potheses whether a system should accept (considercorrectly recognized), reject (assume misrecogni-tion), or ignore (classify as noise or speech not di-rected to the system) them.
In addition, a more so-phisticated dialogue system might decide whetherto clarify or confirm certain hypotheses.Obviously, incorrect decisions at this point canhave serious negative effects on system usabilityand user satisfaction.
On the one hand, acceptingmisrecognized hypotheses leads to misunderstand-ings and unintended system behaviors which areusually difficult to recover from.
On the other hand,users might get frustrated with a system that be-haves too cautiously and rejects or ignores too manyutterances.
Thus an important feature in dialoguesystem engineering is the tradeoff between avoidingtask failure (due to misrecognitions) and promotingoverall dialogue efficiency, flow, and naturalness.In this paper, we investigate the use of machinelearners trained on a combination of acoustic confi-dence and pragmatic plausibility features (i.e.
com-puted from dialogue context) to predict the qual-ity of incoming n-best recognition hypotheses toa spoken dialogue system.
These predictions arethen used to select a ?best?
hypothesis and to de-cide on appropriate system reactions.
We evalu-ate this approach in comparison with a baselinesystem that combines fixed recognition confidencerejection thresholds with dialogue-state dependentrecognition grammars (Lemon, 2004).The paper is organized as follows.
After a shortrelation to previous work, Section 3 introduces theWITAS multimodal dialogue system, which we useto collect data (Section 4) and to derive baseline re-sults (Section 5).
Section 6 describes our learningexperiments for classifying and selecting from n-best recognition hypotheses and Section 7 reportsour results.2 Relation to Previous Work(Litman et al, 2000) use acoustic-prosodic infor-mation extracted from speech waveforms, togetherwith information derived from their speech recog-nizer, to automatically predict misrecognized turnsin a corpus of train-timetable information dialogues.In our experiments, we also use recognizer con-fidence scores and a limited number of acoustic-prosodic features (e.g.
amplitude in the speech sig-nal) for hypothesis classification.
(Walker et al,2000) use a combination of features from the speechrecognizer, natural language understanding, and di-alogue manager/discourse history to classify hy-potheses as correct, partially correct, or misrecog-nized.
Our work is related to these experiments inthat we also combine confidence scores and higher-level features for classification.
However, both (Lit-man et al, 2000) and (Walker et al, 2000) con-sider only single-best recognition results and thususe their classifiers as ?filters?
to decide whether thebest recognition hypothesis for a user utterance iscorrect or not.
We go a step further in that we clas-sify n-best hypotheses and then select among the al-ternatives.
We also explore the use of more dialogueand task-oriented features (e.g.
the dialogue movetype of a recognition hypothesis) for classification.The main difference between our approach andwork on hypothesis reordering (e.g.
(Chotimongkoland Rudnicky, 2001)) is that we make a decision re-garding whether a dialogue system should accept,clarify, reject, or ignore a user utterance.
Fur-thermore, our approach is more generally applica-ble than preceding research, since we frame ourmethodology in the Information State Update (ISU)approach to dialogue management (Traum et al,1999) and therefore expect it to be applicable to arange of related multimodal dialogue systems.3 The WITAS Dialogue SystemThe WITAS dialogue system (Lemon et al, 2002)is a multimodal command and control dialogue sys-tem that allows a human operator to interact witha simulated ?unmanned aerial vehicle?
(UAV): asmall robotic helicopter.
The human operator is pro-vided with a GUI ?
an interactive (i.e.
mouse click-able) map ?
and specifies mission goals using nat-ural language commands spoken into a headset, orby using combinations of GUI actions and spokencommands.
The simulated UAV can carry out dif-ferent activities such as flying to locations, follow-ing vehicles, and delivering objects.
The dialoguesystem uses the Nuance 8.0 speech recognizer withlanguage models compiled from a grammar (writtenusing the Gemini system (Dowding et al, 1993)),which is also used for parsing and generation.3.1 WITAS Information StatesThe WITAS dialogue system is part of a largerfamily of systems that implement the InformationState Update (ISU) approach to dialogue manage-ment (Traum et al, 1999).
The ISU approach hasbeen used to formalize different theories of dia-logue and forms the basis of several dialogue sys-tem implementations in domains such as route plan-ning, home automation, and tutorial dialogue.
TheISU approach is a particularly useful testbed forour technique because it collects information rele-vant to dialogue context in a central data structurefrom which it can be easily extracted.
(Lemon et al,2002) describe in detail the components of Informa-tion States (IS) and the update procedures for pro-cessing user input and generating system responses.Here, we briefly introduce parts of the IS which areneeded to understand the system?s basic workings,and from which we will extract dialogue-level andtask-level information for our learning experiments:?
Dialogue Move Tree (DMT): a tree-structure,in which each subtree of the root node repre-sents a ?thread?
in the conversation, and whereeach node in a subtree represents an utterancemade either by the system or the user.
1?
Active Node List (ANL): a list that records all?active?
nodes in the DMT; active nodes indi-1A tree is used in order to overcome the limitations of stack-based processing, see (Lemon and Gruenstein, 2004).cate conversational contributions that are stillin some sense open, and to which new utter-ances can attach.?
Activity Tree (AT): a tree-structure represent-ing the current, past, and planned activities thatthe back-end system (in this case a UAV) per-forms.?
Salience List (SL): a list of NPs introduced inthe current dialogue ordered by recency.?
Modality Buffer (MB): a temporary store thatregisters click events on the GUI.The DMT and AT are the core components of In-formation States.
The SL and MB are subsidiarydata-structures needed for interpreting and generat-ing anaphoric expressions and definite NPs.
Finally,the ANL plays a crucial role in integrating new userutterances into the DMT.4 Data CollectionFor our experiments, we use data collected in asmall user study with the grammar-switching ver-sion of the WITAS dialogue system (Lemon, 2004).In this study, six subjects from Edinburgh Univer-sity (4 male, 2 female) had to solve five simple taskswith the system, resulting in 30 complete dialogues.The subjects?
utterances were recorded as 8kHz16bit waveform files and all aspects of the Informa-tion State transitions during the interactions werelogged as html files.
Altogether, 303 utteranceswere recorded in the user study (?
10 user utter-ances/dialogue).4.1 LabelingWe transcribed all user utterances and parsed thetranscriptions offline using WITAS?
natural lan-guage understanding component in order to get agold-standard labeling of the data.
Each utter-ance was labeled as either in-grammar or out-of-grammar (oog), depending on whether its transcrip-tion could be parsed or not, or as crosstalk: a spe-cial marker that indicated that the input was not di-rected to the system (e.g.
noise, laughter, self-talk,the system accidentally recording itself).
For allin-grammar utterances we stored their interpreta-tions (quasi-logical forms) as computed by WITAS?parser.
Since the parser uses a domain-specific se-mantic grammar designed for this particular appli-cation, each in-grammar utterance had an interpre-tation that is ?correct?
with respect to the WITASapplication.4.2 Simplifying AssumptionsThe evaluations in the following sections make twosimplifying assumptions.
First, we consider a userutterance correctly recognized only if the logicalform of the transcription is the same as the logicalform of the recognition hypothesis.
This assump-tion can be too strong because the system might re-act appropriately even if the logical forms are notliterally the same.
Second, if a transcribed utter-ance is out-of-grammar, we assume that the systemcannot react appropriately.
Again, this assumptionmight be too strong because the recognizer can ac-cidentally map an utterance to a logical form that isequivalent to the one intended by the user.5 The Baseline SystemThe baseline for our experiments is the behavior ofthe WITAS dialogue system that was used to col-lect the experimental data (using dialogue contextas a predictor of language models for speech recog-nition, see below).
We chose this baseline because ithas been shown to perform significantly better thanan earlier version of the system that always used thesame (i.e.
full) grammar for recognition (Lemon,2004).We evaluate the performance of the baseline byanalyzing the dialogue logs from the user study.With this information, it is possible to decide howthe system reacted to each user utterance.
We dis-tinguish between the following three cases:1. accept: the system accepted the recognitionhypothesis of a user utterance as correct.2.
reject: the system rejected the recognition hy-pothesis of a user utterance given a fixed con-fidence rejection threshold.3.
ignore: the system did not react to a user utter-ance at all.These three classes map naturally to the gold-standard labels of the transcribed user utterances:the system should accept in-grammar utterances, re-ject out-of-grammar input, and ignore crosstalk.5.1 Context-sensitive Speech RecognitionIn the the WITAS dialogue system, the ?grammar-switching?
approach to context-sensitive speechrecognition (Lemon, 2004) is implemented usingthe ANL.
At any point in the dialogue, there is a?most active node?
at the top of the ANL.
The dia-logue move type of this node defines the name of alanguage model that is used for recognizing the nextuser utterance.
For instance, if the most active nodeis a system yes-no-question then the appropriatelanguage model is defined by a small context-freegrammar covering phrases such as ?yes?, ?that?sright?, ?okay?, ?negative?, ?maybe?, and so on.The WITAS dialogue system with context-sensitive speech recognition showed significantlybetter recognition rates than a previous version ofthe system that used the full grammar for recogni-tion at all times ((Lemon, 2004) reports a 11.5%reduction in overall utterance recognition errorrate).
Note however that an inherent danger withgrammar-switching is that the system may havewrong expectations and thus might activate a lan-guage model which is not appropriate for the user?snext utterance, leading to misrecognitions or incor-rect rejections.5.2 ResultsTable 1 summarizes the evaluation of the baselinesystem.System behaviorUser utterance accept reject ignorein-grammar 154/22 8 4out-of-grammar 45 43 4crosstalk 12 9 2Accuracy: 65.68%Weighted f-score: 61.81%Table 1: WITAS dialogue system baseline resultsTable 1 should be read as follows: looking at thefirst row, in 154 cases the system understood andaccepted the correct logical form of an in-grammarutterance by the user.
In 22 cases, the system ac-cepted a logical form that differed from the one forthe transcribed utterance.2 In 8 cases, the system re-jected an in-grammar utterance and in 4 cases it didnot react to an in-grammar utterance at all.
The sec-ond row of Table 1 shows that the system accepted45, rejected 43, and ignored 4 user utterances whosetranscriptions were out-of-grammar and could notbe parsed.
Finally, the third row of the table showsthat the baseline system accepted 12 utterances thatwere not addressed to it, rejected 9, and ignored 2.Table 1 shows that a major problem with the base-line system is that it accepts too many user utter-ances.
In particular, the baseline system accepts thewrong interpretation for 22 in-grammar utterances,45 utterances which it should have rejected as out-of-grammar, and 12 utterances which it should have2For the computation of accuracy and weighted f-scores,these were counted as wrongly accepted out-of-grammar ut-terances.ignored.
All of these cases will generally lead tounintended actions by the system.6 Classifying and Selecting N-bestRecognition HypothesesWe aim at improving over the baseline results byconsidering the n-best recognition hypotheses foreach user utterance.
Our methodology consists oftwo steps: i) we automatically classify the n-bestrecognition hypotheses for an utterance as eithercorrectly or incorrectly recognized and ii) we use asimple selection procedure to choose the ?best?
hy-pothesis based on this classification.
In order to getmultiple recognition hypotheses for all utterancesin the experimental data, we re-ran the speech rec-ognizer with the full recognition grammar and 10-best output and processed the results offline withWITAS?
parser, obtaining a logical form for eachrecognition hypothesis (every hypothesis has a log-ical form since language models are compiled fromthe parsing grammar).6.1 Hypothesis LabelingWe labeled all hypotheses with one of the follow-ing four classes, based on the manual transcriptionsof the experimental data: in-grammar, oog (WER ?50), oog (WER > 50), or crosstalk.
The in-grammarand crosstalk classes correspond to those describedfor the baseline.
However, we decided to divide upthe out-of-grammar class into the two classes oog(WER?
50) and oog (WER > 50) to get a more fine-grained classification.
In order to assign hypothesesto the two oog classes, we compute the word er-ror rate (WER) between recognition hypotheses andthe transcription of corresponding user utterances.If the WER is ?
50%, we label the hypothesis asoog (WER ?
50), otherwise as oog (WER > 50).We also annotate all misrecognized hypotheses ofin-grammar utterances with their respective WERscores.The motivation behind splitting the out-of-grammar class into two subclasses and for anno-tating misrecognized in-grammar hypotheses withtheir WER scores is that we want to distinguish be-tween different ?degrees?
of misrecognition that canbe used by the dialogue system to decide whetherit should initiate clarification instead of rejection.3We use a threshold (50%) on a hypothesis?
WERas an indicator for whether hypotheses should be3The WITAS dialogue system currently does not supportthis type of clarification dialogue; the WER annotations aretherefore only of theoretical interest.
However, an extendedsystem could easily use this information to decide when clari-fication should be initiated.clarified or rejected.
This is adopted from (Gabs-dil, 2003), based on the fact that WER correlateswith concept accuracy (CA, (Boros et al, 1996)).The WER threshold can be set differently accordingto the needs of an application.
However, one wouldideally set a threshold directly on CA scores for thislabeling, but these are currently not available for ourdata.We also introduce the distinction between out-of-grammar (WER ?
50) and out-of-grammar (WER> 50) in the gold standard for the classificationof (whole) user utterances.
We split the out-of-grammar class into two sub-classes depending onwhether the 10-best recognition results include atleast one hypothesis with a WER ?
50 comparedto the corresponding transcription.
Thus, if there isa recognition hypothesis which is close to the tran-scription, an utterance is labeled as oog (WER ?50).
In order to relate these classes to different sys-tem behaviors, we define that utterances labeled asoog (WER ?
50) should be clarified and utteranceslabeled as oog (WER > 50) should be rejected bythe system.
The same is done for all in-grammarutterances for which only misrecognized hypothe-ses are available.6.2 Classification: Feature GroupsWe represent recognition hypotheses as 20-dimensional feature vectors for automatic classifica-tion.
The feature vectors combine recognizer con-fidence scores, low-level acoustic information, in-formation from WITAS system Information States,and domain knowledge about the different tasks inthe scenario.
The following list gives an overviewof all features (described in more detail below).1.
Recognition (6): nbestRank, hypothe-sisLength, confidence, confidenceZScore,confidence-StandardDeviation, minWordCon-fidence2.
Utterance (3): minAmp, meanAmp, RMS-amp3.
Dialogue (9): currentDM, currentCommand,mostActiveNode, DMBigramFrequency, qa-Match, aqMatch, #unresolvedNPs, #unre-solvedPronouns, #uniqueIndefinites4.
Task (2): taskConflict, #taskConstraintCon-flictAll features are extracted automatically from theoutput of the speech recognizer, utterance wave-forms, IS logs, and a small library of plan operatorsdescribing the actions the UAV can perform.
Therecognition (REC) feature group includes the posi-tion of a hypothesis in the n-best list (nbestRank),its length in words (hypothesisLength), and five fea-tures representing the recognizer?s confidence as-sessment.
Similar features have been used in theliterature (e.g.
(Litman et al, 2000)).
The minWord-Confidence and standard deviation/zScore featuresare computed from individual word confidences inthe recognition output.
We expect them to help themachine learners decide between the different WERclasses (e.g.
a high overall confidence score cansometimes be misleading).
The utterance (UTT)feature group reflects information about the ampli-tude in the speech signal (all features are extractedwith the UNIX sox utility).
The motivation forincluding the amplitude features is that they mightbe useful for detecting crosstalk utterances whichare not directly spoken into the headset microphone(e.g.
the system accidentally recognizing itself).The dialogue features (DIAL) represent informa-tion derived from Information States and can becoarsely divided into two sub-groups.
The firstgroup includes features representing general co-herence constraints on the dialogue: the dialoguemove types of the current utterance (currentDM)and of the most active node in the ANL (mostAc-tiveNode), the command type of the current utter-ance (currentCommand, if it is a command, nullotherwise), statistics on which move types typi-cally follow each other (DMBigramFrequency), andtwo features (qaMatch and aqMatch) that explic-itly encode whether the current and the previousutterance form a valid question answer pair (e.g.yn-question followed by yn-answer).
The secondgroup includes features that indicate how many def-inite NPs and pronouns cannot be resolved in thecurrent Information State (#unresolvedNP, #unre-solvedPronouns, e.g.
?the car?
if no car was men-tioned before) and a feature indicating the numberof indefinite NPs that can be uniquely resolved inthe Information State (#uniqueIndefinites, e.g.
?atower?
where there is only one tower in the do-main).
We include these features because (short)determiners are often confused by speech recogniz-ers.
In the WITAS scenario, a misrecognized deter-miner/demonstrative pronoun can lead to confusingsystem behavior (e.g.
a wrongly recognized ?there?will cause the system to ask ?Where is that??
).Finally, the task features (TASK) reflect conflict-ing instructions in the domain.
The feature taskCon-flict indicates a conflict if the current dialogue movetype is a command and that command already ap-pears as an active task in the AT.
#taskConstraint-Conflict counts the number of conflicts that arisebetween the currently active tasks in the AT and thehypothesis.
For example, if the UAV is already fly-ing somewhere the preconditions of the action op-erator for take off (altitude = 0) conflict withthose for fly (altitude 6= 0), so that ?take off?would be an unlikely command in this context.6.3 Learners and Selection ProcedureWe use the memory based learner TiMBL (Daele-mans et al, 2002) and the rule induction learnerRIPPER (Cohen, 1995) to predict the class of eachof the 10-best recognition hypotheses for a given ut-terance.
We chose these two learners because theyimplement different learning strategies, are well es-tablished, fast, freely available, and easy to use.
In asecond step, we decide which (if any) of the classi-fied hypotheses we actually want to pick as the bestresult and how the user utterance should be classi-fied as a whole.
This task is decided by the follow-ing selection procedure (see Figure 1) which imple-ments a preference ordering accept > clarify > re-ject > ignore.41.
Scan the list of classified n-best recognitionhypotheses top-down.
Return the first resultthat is classified as accept and classify theutterance as accept.2.
If 1. fails, scan the list of classified n-bestrecognition hypotheses top-down.
Returnthe first result that is classified as clarify andclassify the utterance as clarify.3.
If 2. fails, count the number of rejects andignores in the classified recognition hypothe-ses.
If the number of rejects is larger or equalthan the number of ignores classify the utter-ance as reject.4.
Else classify the utterance as ignore.Figure 1: Selection procedureThis procedure is applied to choose from the clas-sified n-best hypotheses for an utterance, indepen-dent of the particular machine learner, in all of thefollowing experiments.Since we have a limited amount experimentaldata in this study (10 hypotheses for each of the 303user utterances), we use a ?leave-one-out?
crossval-idation setup for classification.
This means that weclassify the 10-best hypotheses for a particular ut-terance based on the 10-best hypotheses of all 302other utterances and repeat this 303 times.4Note that in a dialogue application one would not alwaysneed to classify all n-best hypotheses in order to select a resultbut could stop as soon as a hypothesis is classified as correct,which can save processing time.7 Results and EvaluationThe middle part of Table 2 shows the classifica-tion results for TiMBL and RIPPER when run withdefault parameter settings (the other results are in-cluded for comparison).
The individual rows showthe performance when different combinations offeature groups are used for training.
The results forthe three-way classification are included for com-parison with the baseline system and are obtainedby combining the two classes clarify and reject.Note that we do not evaluate the performance of thelearners for classifying the individual recognitionhypotheses but the classification of (whole) user ut-terances (i.e.
including the selection procedure tochoose from the classified hypotheses).The results show that both learners profit fromthe addition of more features concerning dialoguecontext and task context for classifying user speechinput appropriately.
The only exception from thistrend is a slight performance decrease when taskfeatures are added in the four-way classification forRIPPER.
Note that both learners already outperformthe baseline results even when only recognition fea-tures are considered.
The most striking result is theperformance gain for TiMBL (almost 10%) whenwe include the dialogue features.
As soon as dia-logue features are included, TiMBL also performsslightly better than RIPPER.Note that the introduction of (limited) task fea-tures, in addition to the DIAL and UTT features, didnot have dramatic impact in this study.
One aim forfuture work is to define and analyze the influence offurther task related features for classification.7.1 Optimizing TiMBL ParametersIn all of the above experiments we ran the machinelearners with their default parameter settings.However, recent research (Daelemans and Hoste,2002; Marsi et al, 2003) has shown that machinelearners often profit from parameter optimization(i.e.
finding the best performing parameters onsome development data).
We therefore selected40 possible parameter combinations for TiMBL(varying the number of nearest neighbors, featureweighting, and class voting weights) and nested aparameter optimization step into the ?leave-one-out?
evaluation paradigm (cf.
Figure 2).5Note that our optimization method is not as so-phisticated as the ?Iterative Deepening?
approach5We only optimized parameters for TiMBL because it per-formed better with default settings than RIPPER and becausethe findings in (Daelemans and Hoste, 2002) indicate thatTiMBL profits more from parameter optimization.1.
Set aside the recognition hypotheses for oneof the user utterances.2.
Randomly split the remaining data into an80% training and 20% test set.3.
Run TiMBL with all possible parameter set-tings on the generated training and test setsand store the best performing settings.4.
Classify the left-out hypotheses with therecorded parameter settings.5.
Iterate.Figure 2: Parameter optimizationdescribed by (Marsi et al, 2003) but is similar in thesense that it computes a best-performing parametersetting for each data fold.Table 3 shows the classification results when werun TiMBL with optimized parameter settings andusing all feature groups for training.System BehaviorUser Utterance accept clarify reject ignorein-grammar 159/2 11 16 0out-of-grammar 0 25 5 0(WER ?
50)out-of-grammar 6 6 50 0(WER > 50)crosstalk 2 5 0 16Acc/wf-score (3 classes): 86.14/86.39%Acc/wf-score (4 classes): 82.51/83.29%Table 3: TiMBL classification results with opti-mized parametersTable 3 shows a remarkable 9% improvement forthe 3-way and 4-way classification in both accuracyand weighted f-score, compared to using TiMBLwith default parameter settings.
In terms of WER,the baseline system (cf.
Table 1) accepted 233 userutterances with a WER of 21.51%, and in contrast,TiMBL with optimized parameters (Ti OP) only ac-cepted 169 user utterances with a WER of 4.05%.This low WER reflects the fact that if the machinelearning system accepts an user utterance, it is al-most certainly the correct one.
Note that althoughthe machine learning system in total accepted farfewer utterances (169 vs. 233) it accepted more cor-rect utterances than the baseline (159 vs. 154).7.2 EvaluationThe baseline accuracy for the 3-class problem is65.68% (61.81% weighted f-score).
Our best re-sults, obtained by using TiMBL with parameter op-System or features used Acc/wf-score Acc/wf-score Acc/wf-score Acc/wf-scorefor classification (3 classes) (4 classes) (3 classes) (4 classes)Baseline 65.68/61.81%TiMBL RIPPERREC 67.66/67.51% 63.04/63.03% 69.31/69.03% 66.67/65.14%REC+UTT 68.98/68.32% 64.03/63.08% 72.61/72.33% 70.30/68.61%REC+UTT+DIAL 77.56/77.59% 72.94/73.70% 74.92/75.34% 71.29/71.62%REC+UTT+DIAL+TASK 77.89/77.91% 73.27/74.12% 75.25/75.61% 70.63/71.54%TiMBL (optimized params.)
86.14/86.39% 82.51/83.29%Oracle 94.06/94.17% 94.06/94.18%Table 2: Classification Resultstimization, show a 25% weighted f-score improve-ment over the baseline system.We can compare these results to a hypothetical?oracle?
system in order to obtain an upper boundon classification performance.
This is an imagi-nary system which performs perfectly on the ex-perimental data given the 10-best recognition out-put.
The oracle results reveal that for 18 of thein-grammar utterances the 10-best recognition hy-potheses do not include the correct logical form atall and therefore have to be classified as clarify orreject (i.e.
it is not possible to achieve 100% accu-racy on the experimental data).
Table 2 shows thatour best results are only 8%/12% (absolute) awayfrom the optimal performance.7.2.1 Costs and ?2 Levels of SignificanceWe use the ?2 test of independence to statisticallycompare the different classification results.
How-ever, since ?2 only tells us whether two classifica-tions are different from each other, we introduce asimple cost measure (Table 4) for the 3-way classi-fication problem to complement the ?2 results.6System behaviorUser utterance accept reject ignorein-grammar 0 2 2out-of-grammar 4 2 2crosstalk 4 2 0Table 4: Cost measureTable 4 captures the intuition that the correct be-havior of a dialogue system is to accept correctlyrecognized utterances and ignore crosstalk (cost 0).The worst a system can do is to accept misrec-ognized utterances or utterances that were not ad-dressed to the system.
The remaining classes are as-6We only evaluate the 3-way classification problem becausethere are no baseline results for the 4-way classification avail-able.signed a value in-between these two extremes.
Notethat the cost assignment is not validated against userjudgments.
We only use the costs to interpret the ?2levels of significance (i.e.
as an indicator to comparethe relative quality of different systems).Table 5 shows the differences in cost and ?2 lev-els of significance when we compare the classifica-tion results.
Here, Ti OP stands for TiMBL with op-timized parameters and the stars indicate the level ofstatistical significance as computed by the ?2 statis-tics (???
indicates significance at p = .001, ??
atp = .01, and ?
at p = .05).7Baseline RIPPER TiMBL Ti OPOracle ?232???
?116???
?100???
?56Ti OP ?176???
?60?
?44TiMBL ?132???
?16RIPPER ?116??
?Table 5: Cost comparisons and ?2 levels of signifi-cance for 3-way classificationThe cost measure shows the strict ordering: Or-acle < Ti OP < TiMBL < RIPPER < Baseline.Note however that according to the ?2 test there isno significant difference between the oracle systemand TiMBL with optimized parameters.
Table 5 alsoshows that all of our experiments significantly out-perform the baseline system.8 ConclusionWe used a combination of acoustic confidence andpragmatic plausibility features (i.e.
computed fromdialogue context) to predict the quality of incom-ing recognition hypotheses to a multi-modal dia-logue system.
We classified hypotheses as accept,(clarify), reject, or ignore: functional categories that7Following (Hinton, 1995), we leave out categories with ex-pected frequencies < 5 in the ?2 computation and reduce thedegrees of freedom accordingly.can be used by a dialogue manager to decide appro-priate system reactions.
The approach is novel incombining machine learning with n-best processingfor spoken dialogue systems using the InformationState Update approach.Our best results, obtained using TiMBL with op-timized parameters, show a 25% weighted f-scoreimprovement over a baseline system that uses a?grammar-switching?
approach to context-sensitivespeech recognition, and are only 8% away from theoptimal performance that can be achieved on thedata.
Clearly, this improvement would result in bet-ter dialogue system performance overall.
Parameteroptimization improved the classification results by9% compared to using the learner with default set-tings, which shows the importance of such tuning.Future work points in two directions: first, inte-grating our methodology into working ISU-baseddialogue systems and determining whether or notthey improve in terms of standard dialogue eval-uation metrics (e.g.
task completion).
The ISUapproach is a particularly useful testbed for ourmethodology because it collects information per-taining to dialogue context in a central data struc-ture from which it can be easily extracted.
This av-enue will be further explored in the TALK project8.Second, it will be interesting to investigate the im-pact of different dialogue and task features for clas-sification and to introduce a distinction between?generic?
features that are domain independent and?application-specific?
features which reflect proper-ties of individual systems and application scenarios.AcknowledgmentsWe thank Nuance Communications Inc. for the useof their speech recognition and synthesis softwareand Alexander Koller and Dan Shapiro for read-ing draft versions of this paper.
Oliver Lemon waspartially supported by Scottish Enterprise under theEdinburgh-Stanford Link programme.ReferencesM.
Boros, W. Eckert, F. Gallwitz, G. Go?rz, G. Han-rieder, and H. Niemann.
1996.
Towards Under-standing Spontaneous Speech: Word Accuracyvs.
Concept Accuracy.
In Proc.
ICSLP-96.Ananlada Chotimongkol and Alexander I. Rud-nicky.
2001.
N-best Speech Hypotheses Re-ordering Using Linear Regression.
In Proceed-ings of EuroSpeech 2001, pages 1829?1832.William W. Cohen.
1995.
Fast Effective Rule In-duction.
In Proceedings of the 12th InternationalConference on Machine Learning.8EC FP6 IST-507802, http://www.talk-project.orgWalter Daelemans and Ve?ronique Hoste.
2002.Evaluation of Machine Learning Methods forNatural Language Processing Tasks.
In Proceed-ings of LREC-02.Walter Daelemans, Jakub Zavrel, Ko van der Sloot,and Antal van den Bosch.
2002.
TIMBL: TilburgMemory Based Learner, version 4.2, ReferenceGuide.
In ILK Technical Report 02-01.John Dowding, Jean Mark Gawron, Doug Appelt,John Bear, Lynn Cherny, Robert Moore, andDouglas Moran.
1993.
GEMINI: a natural lan-guage system for spoken-language understand-ing.
In Proceedings of ACL-93.Malte Gabsdil.
2003.
Classifying Recognition Re-sults for Spoken Dialogue Systems.
In Proceed-ings of the Student Research Workshop at ACL-03.Perry R. Hinton.
1995.
Statistics Explained ?
AGuide For Social Science Students.
Routledge.Oliver Lemon and Alexander Gruenstein.
2004.Multithreaded context for robust conversationalinterfaces: context-sensitive speech recognitionand interpretation of corrective fragments.
ACMTransactions on Computer-Human Interaction.
(to appear).Oliver Lemon, Alexander Gruenstein, and StanleyPeters.
2002.
Collaborative activities and multi-tasking in dialogue systems.
Traitement Automa-tique des Langues, 43(2):131?154.Oliver Lemon.
2004.
Context-sensitive speechrecognition in ISU dialogue systems: results forthe grammar switching approach.
In Proceedingsof the 8th Workshop on the Semantics and Prag-matics of Dialogue, CATALOG?04.Diane J. Litman, Julia Hirschberg, and Marc Swerts.2000.
Predicting Automatic Speech RecognitionPerformance Using Prosodic Cues.
In Proceed-ings of NAACL-00.Erwin Marsi, Martin Reynaert, Antal van denBosch, Walter Daelemans, and Ve?ronique Hoste.2003.
Learning to predict pitch accents andprosodic boundaries in Dutch.
In Proceedings ofACL-03.David Traum, Johan Bos, Robin Cooper, StaffanLarsson, Ian Lewin, Colin Matheson, and Mas-simo Poesio.
1999.
A Model of Dialogue Movesand Information State Revision.
Technical Re-port D2.1, Trindi Project.Marilyn Walker, Jerry Wright, and Irene Langkilde.2000.
Using Natural Language Processing andDiscourse Features to Identify Understanding Er-rors in a Spoken Dialogue System.
In Proceed-ings of ICML-2000.
