Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 136?144,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsLearning Translation Boundaries for Phrase-Based DecodingDeyi Xiong, Min Zhang, Haizhou LiHuman Language TechnologyInstitute for Infocomm Research1 Fusionopolis Way, #21-01 Connexis, Singapore 138632.
{dyxiong, mzhang, hli}@i2r.a-star.edu.sgAbstractConstrained decoding is of great importancenot only for speed but also for translation qual-ity.
Previous efforts explore soft syntactic con-straints which are based on constituent bound-aries deduced from parse trees of the sourcelanguage.
We present a new framework to es-tablish soft constraints based on a more nat-ural alternative: translation boundary ratherthan constituent boundary.
We propose sim-ple classifiers to learn translation boundariesfor any source sentences.
The classifiers aretrained directly on word-aligned corpus with-out using any additional resources.
We reportthe accuracy of our translation boundary clas-sifiers.
We show that using constraints basedon translation boundaries predicted by ourclassifiers achieves significant improvementsover the baseline on large-scale Chinese-to-English translation experiments.
The newconstraints also significantly outperform con-stituent boundary based syntactic constrains.1 IntroductionIt has been known that phrase-based decoding(phrase segmentation/translation/reordering (Chi-ang, 2005)) should be constrained to some extent notonly for transferring the NP-hard problem (Knight,1999) into a tractable one in practice but also for im-proving translation quality.
For example, Xiong etal.
(2008) find that translation quality can be signif-icantly improved by either prohibiting reorderingsaround punctuation or restricting reorderings withina 15-word window.Recently, more linguistically motivated con-straints are introduced to improve phrase-based de-coding.
(Cherry, 2008) and (Marton and Resnik,2008) introduce syntactic constraints into the stan-dard phrase-based decoding (Koehn et al, 2003) andhierarchical phrase-based decoding (Chiang, 2005)respectively by using a counting feature which ac-cumulates whenever hypotheses violate syntacticboundaries of source-side parse trees.
(Xiong et al,2009) further presents a bracketing model to includethousands of context-sensitive syntactic constraints.All of these approaches achieve their improvementsby guiding the phrase-based decoder to prefer trans-lations which respect source-side parse trees.One major problem with such constituent bound-ary based constraints is that syntactic structures ofthe source language do not necessarily reflect trans-lation structures where the source and target lan-guage correspond to each other.
In this paper,we investigate building classifiers that directly ad-dress the problem of translation boundary, ratherthan extracting constituent boundary from source-side parsers built for a different purpose.
A trans-lation boundary is a position in the source sequencewhich begins or ends a translation zone 1 spanningmultiple source words.
In a translation zone, thesource phrase is translated as a unit.
Reorderingswhich cross translation zones are not desirable.Inspired by (Roark and Hollingshead, 2008)which introduces classifiers to decide if a word canbegin/end a multi-word constituent, we build twodiscriminative classifiers to tag each word in thesource sequence with a binary class label.
The firstclassifier decides if a word can begin a multi-source-word translation zone; the second classifier decidesif a word can end a multi-source-word translation1We will give a formal definition of translation zone in Sec-tion 2.136zone.
Given a partial translation covering source se-quence (i, j) with start word ci and end word cj 2,this translation can be penalized if the first classifierdecides that the start word ci can not be a beginningtranslation boundary or the second classifier decidesthat the end word cj can not be an ending translationboundary.
In such a way, we can guide the decoderto boost hypotheses that respect translation bound-aries and therefore the common translation structureshared by the source and target language, rather thanthe syntactic structure of the source language.We report the accuracy of such classifiers by com-paring their outputs with ?gold?
translation bound-aries obtained from reference translations on the de-velopment set.
We integrate translation boundarybased constraints into phrase-based decoding anddisplay that they improve translation quality signif-icantly in large-scale experiments.
Furthermore, weconfirm that they also significantly outperform con-stituent boundary based syntactic constraints.2 Beginning and Ending Translation ZonesTo better understand the particular task that we ad-dress in this paper, we study the distribution ofclasses of translation boundaries in real-world data.First, we introduce some notations.
Given a sourcesentence c1...cn, we will say that a word ci (1 < i <n) is in the class By if there is a translation zone ?spanning ci...cj for some j > i; and ci ?
Bn oth-erwise.
Similarly, we will say that a word cj is inthe class Ey if there is a translation zone spanningci...cj for some j > i; and cj ?
En otherwise.Here, a translation zone ?
is a pair of alignedsource phrase and target phrase?
= (cji , eqp)where ?
must be consistent with the word alignmentM?
(u, v) ?
M, i ?
u ?
j ?
p ?
v ?
qBy this, we require that no words inside the sourcephrase cji are aligned to words outside the targetphrase eqp and that no words outside the sourcephrase are aligned to words inside the target phrase.2In this paper, we use c to denote the source language and ethe target language.Item Count (M) P (%)Sentences 3.8 ?Words 96.9 ?Words ?
By 22.7 23.4Words ?
Ey 41.0 42.3Words /?
By and /?
Ey 33.2 34.3Table 1: Statistics on word classes from our bilingualtraining data.
All numbers are calculated on the sourceside.
P means the percentage.This means, in other words, that the source phrasecji is mapped as a unit onto the target phrase eqp.When defining the By and Ey class, we also re-quire that the source phrase cji in the translation zonemust contain multiple words (j > i).
Our interestis the question of whether a sequence of consecu-tive source words can be translated as a unit (i.e.whether there is a translation zone covering thesesource words).
For a single-word source phrase, ifit can be translated separately, it is always translatedas a unit in the context of phrase-based decoding.Therefore this question does not exist.Note that the first word c1 and the last word cnare unambiguous in terms of whether they begin orend a translation zone.
The first word c1 must begina translation zone spanning the whole source sen-tence.
The last word cn must end a translation zonespanning the whole source sentence.
Therefore, ourclassifiers only need to predict the other n?2 wordsfor a source sentence of length n.Table 1 shows statistics of word classes from ourtraining data which contain nearly 100M words inapproximately 4M sentences.
Among these words,only 22.7M words can begin a translation zonewhich covers multiple source words.
41M wordscan end a translation zone spanning multiple sourcewords, which accounts for more than 42% in allwords.
We still have more than 33M words, ac-counting for 34.3%, which neither begin nor enda multi-source-word translation zone.
Apparently,translations that begin/end on words ?
By/?
Ey arepreferable to those which begin/end on other words.Yet another interesting study is to compare trans-lation boundaries with constituent boundaries de-duced from source-side parse trees.
In doing so,we can know further how well constituent boundary137Classification Task Avg.
Accuracy (%)By/Bn 46.9Ey/En 52.2Table 2: Average classification accuracy on the develop-ment set when we treat constituent boundary deducer (ac-cording to source-side parse trees) as a translation bound-ary classifier.based syntactic constraints can improve translationquality.
We pair the source sentences of our devel-opment set with each of the reference translationsand include the created sentence pairs in our bilin-gual training corpus.
Then we obtain word align-ments on the new corpus (see Section 5.1 for the de-tails of learning word alignments).
From the wordalignments we obtain translation boundaries (see de-tails in the next section).
We parse the source sen-tences of our development set and obtain constituentboundaries from parse trees.To make a clear comparison with our transla-tion boundary classifiers (see Section 3.3), we treatconstituent boundaries deduced from source-sideparse trees as output from beginning/ending bound-ary classifiers: the constituent beginning boundarycorresponds to By; the constituent ending boundarycorresponds to Ey.
We have four reference transla-tions for each source sentence.
Therefore we havefour translation boundary sets, each of which is pro-duced from word alignments between source sen-tences and one reference translation set.
Each ofthe four translation boundary sets will be used as agold standard.
We calculate classification accuracyfor our constituent boundary deducer on each goldstandard and average them finally.Table 2 shows the accuracy results.
The averageaccuracies on the four gold standard sets are verylow, especially for the By/Bn classification task.
Insection 3.3, we will show that our translation bound-ary classifiers achieve higher accuracy than that ofconstituent boundary deducer.
This suggests thatpure constituent boundary based constraints are notthe best choice to constrain phrase-based decoding.3 Learning Translation BoundariesIn this section, we investigate building classifiersto predict translation boundaries.
First, we elabo-rate the acquisition of training instances from wordalignments.
Second, we build two classifiers withsimple features on the obtained training instances.Finally, we evaluate our classifiers on the develop-ment set using the ?gold?
translation boundaries ob-tained from reference translations.3.1 Obtaining Translation Boundaries fromWord AlignmentsWe can easily obtain constituent boundaries fromparse trees.
Similarly, if we have a tree coveringboth source and target sentence, we can easily gettranslation boundaries from this tree.
Fortunately,we can build such a tree directly from word align-ments.
We use (Zhang et al, 2008)?s shift-reduce al-gorithm (SRA) to decompose word alignments intohierarchical trees.Given an arbitrary word-level alignment as an in-put, SRA is able to output a tree representation of theword alignment (a.k.a decomposition tree).
Eachnode of the tree is a translation zone as we definedin the Section 2.
Therefore the first word on thesource side of each multi-source-word node is a be-ginning translation boundary (?
By); the last wordon the source side of each multi-source-word nodeis an ending translation boundary (?
Ey).Figure 1a shows an example of many-to-manyalignment, where the source language is Chineseand the target language is English.
Each word isindexed with their occurring position from left toright.
Figure 1b is the tree representation of the wordalignment after hierarchical analysis using SRA.
Weuse ([i, j], [p, q]) to denote a tree node, where i, jand p, q are the beginning and ending index in thesource and target language, respectively.
By check-ing nodes which cover multiple source words, wecan easily decide that the source words {?
?, ?,??}
are in the class By and any other words arein the class Bn if we want to train a By/Bn classi-fier with class labels {By, Bn}.
Similarly, the sourcewords {?,??,?,??}
are in the class Ey andany other words are in the class En when we train aEy/En classifier with class labels {Ey, En}.By using SRA on each word-aligned bilingualsentence, as described above, we can tag each sourceword with two sets of class labels: {By, Bn} and{Ey, En}.
The tagged source sentences will be usedto train our two translation boundary classifiers.138??
???
?
??
?
?The last five flights all failed due to accidents?1 2 3 4 5 6 71 2 3 4 5 6 7 8 9([1, 7], [1, 9])([6, 7], [6, 9])([6, 6], [7, 9]) ([7, 7], [6, 6])([1, 5], [1, 5])([1, 4], [1, 4]) ([5, 5], [5, 5])([1, 3], [1, 3]) ([4, 4], [4, 4])([1, 1], [1, 2]) ([2, 3], [3, 3])a) b)Figure 1: An example of many-to-many word alignment and its tree representation produced by (Zhang et al, 2008)?sshift-reduce algorithm.3.2 Building Translation Boundary ClassifiersWe build two discriminative classifiers based onMaximum Entropy Markov Models (MEMM) (Mc-Callum et al, 2000).
One classifier is to predict theword class ?
?
{By, Bn} for each source word.
Theother is to predict the word class ?
?
{Ey, En}.These two classifiers are separately trained usingtraining instances obtained from our word-alignedtraining data as demonstrated in the last section.We use features from surrounding words, includ-ing 2 before and 2 after the current word position(c?2, c?1, c+1, c+2).
We also use class features totrain models with Markov order 1 (including classfeature ?c?1), and Markov order 2 (including classfeatures ?c?1 , ?c?2).3.3 Evaluating Translation BoundaryClassifiersHow well can we perform these binary classifica-tion tasks using the classifiers described above?
Canwe obtain better translation boundary predictionsthan extracting constituent boundary from source-side parse trees?
To investigate these questions, weevaluate our MEMM based classifiers.
We trainedthem on our 100M-word word-aligned corpus.
Weran the two trained classifiers on the developmentset separately to obtain the By/Bn words and Ey/Enwords.
Then we built our four gold standards usingfour reference translation sets as described in Sec-Avg.
Accuracy (%)Classification Task MEMM 1 MEMM 2By/Bn 71.7 70.2Ey/En 59.2 58.8Table 3: Average classification accuracy on the develop-ment set for our MEMM based translation boundary clas-sifiers with various Markov orders.tion 2.
The average classification accuracy resultsare shown in Table 3.Comparing Table 3 with Table 2, we find that ourMEMM based classifiers significantly outperformconstituent boundary deducer in predicting transla-tion boundaries, especially in the By/Bn classifi-cation task, where our MEMM based By/Bn clas-sifier (Markov order 1) achieves a relative increaseof 52.9% in accuracy over the constituent bound-ary deducer.
In the Ey/En classification task, ourclassifiers also perform much better than constituentboundary deducer.Then are our MEMM based translation boundaryclassifiers good enough?
The accuracies are still lowalthough they are higher than those of constituentboundary deducer.
One reason why we have lowaccuracies is that our gold standard based evalua-tion is not established on real gold standards.
Inother words, we don?t have gold standards in termsof translation boundary since different translations139Classification Task Avg.
Accuracy (%)By/Bn 80.6Ey/En 75.7Table 4: Average classification accuracy on the develop-ment set when treating each reference translation set as aboundary classifier.generate very different translation boundaries.
Wecan measure these differences in reference transla-tions using the same evaluation metric (classificationaccuracy).
We treat each reference translation setas a translation boundary classifier while the otherthree reference translation sets as gold standards.We calculate the classification accuracy for the cur-rent reference translation set and finally average allfour accuracies.
Table 4 presents the results.Comparing Table 4 with Table 3, we can see thatthe accuracy of our translation boundary classifica-tion approach is not that low when considering vastdivergences of reference translations.
The questionnow becomes, how can classifier output be used toconstrain phrase-based decoding, and what is theimpact on the system performance of using suchconstraints.4 Integrating Translation Boundaries intoDecodingBy running the two trained classifiers on the sourcesentence separately, we obtain two classified wordsets: By/Bn words, and Ey/En words.
We can pro-hibit any translations or reorderings spanning ci...cj(j > i) where ci /?
By according to the first classi-fier or cj /?
Ey according to the second classifier.
Insuch a way, we integrate translation boundaries intophrase-based decoding as hard constraints, which,however, is at the risk of producing no translationcovering the whole source sentence.Alternatively, we introduce soft constraints basedon translation boundary that our classifiers pre-dict, similar to constituent boundary based soft con-straints in (Cherry, 2008) and (Marton and Resnik,2008).
We add a new feature to the decoder?s log-linear model: translation boundary violation count-ing feature.
This counting feature accumulateswhenever hypotheses have a partial translation span-ning ci...cj (j > i) where ci /?
By or cj /?
Ey.
TheLDC ID DescriptionLDC2004E12 United NationsLDC2004T08 Hong Kong NewsLDC2005T10 Sinorama MagazineLDC2003E14 FBISLDC2002E18 Xinhua News V1 betaLDC2005T06 Chinese News TranslationLDC2003E07 Chinese TreebankLDC2004T07 Multiple Translation ChineseTable 5: Training corpora.weight ?v of this feature is tuned via minimal errorrate training (MERT) (Och, 2003) with other featureweights.Unlike hard constraints, which simply preventany hypotheses from violating translation bound-aries, soft constraints allow violations of translationboundaries but with a penalty of exp(?
?vCv) whereCv is the violation count.
By using soft constraints,we can enable the model to prefer hypotheses whichare consistent with translation boundaries.5 ExperimentOur baseline system is a phrase-based system us-ing BTGs (Wu, 1997), which includes a content-dependent reordering model discriminatively trainedusing reordering examples (Xiong et al, 2006).
Wecarried out various experiments to evaluate the im-pact of integrating translation boundary based softconstraints into decoding on the system performanceon the Chinese-to-English translation task of theNIST MT-05 using large scale training data.5.1 Experimental SetupOur training corpora are listed in Table 5.
Thewhole corpora consist of 96.9M Chinese words and109.5M English words in 3.8M sentence pairs.
Weran GIZA++ (Och and Ney, 2000) on the par-allel corpora in both directions and then appliedthe ?grow-diag-final?
refinement rule (Koehn et al,2005) to obtain many-to-many word alignments.From the word-aligned corpora, we extracted bilin-gual phrases and trained our translation model.We used all corpora in Table 5 except for theUnited Nations corpus to train our MaxEnt basedreordering model (Xiong et al, 2006), which con-140sist of 33.3M Chinese words and 35.8M Englishwords.
We built a four-gram language model us-ing the SRILM toolkit (Stolcke, 2002), which wastrained on Xinhua section of the English Gigawordcorpus (181.1M words).To train our translation boundary classifiers, weextract training instances from the whole word-aligned corpora, from which we obtain 96.9M train-ing instances for the By/Bn and Ey/En classifier.We ran the off-the-shelf MaxEnt toolkit (Zhang,2004) to tune classifier feature weights with Gaus-sian prior set to 1 to avoid overfitting.We used the NIST MT-03 evaluation test data asour development set (919 sentences in total, 27.1words per sentence).
The NIST MT-05 test set in-cludes 1082 sentences with an average of 27.4 wordsper sentence.
Both the reference corpus for the NISTMT-03 set and the reference corpus for the NISTMT-05 set contain 4 translations per source sen-tence.
To compare with constituent boundary basedconstraints, we parsed source sentences of both thedevelopment and test sets using a Chinese parser(Xiong et al, 2005) which was trained on the PennChinese Treebank with an F1-score of 79.4%.Our evaluation metric is case-insensitive BLEU-4(Papineni et al, 2002) using the shortest referencesentence length for the brevity penalty.
Statisticalsignificance in BLEU score differences was testedby paired bootstrap re-sampling (Koehn, 2004).5.2 Using Translation Boundaries fromReference TranslationsThe most direct way to investigate the impact on thesystem performance of using translation boundariesis to integrate ?right?
translation boundaries into de-coding which are directly obtained from referencetranslations.
For both the development set and testset, we have four reference translation sets, whichare named ref1, ref2, ref3 and ref4, respectively.For the development set, we used translation bound-aries obtained from ref1.
Based on these boundaries,we built our translation boundary violation countingfeature and tuned its feature weight with other fea-tures using MERT.
When we obtained the best fea-ture weights ?s, we evaluated on the test set usingtranslation boundaries produced from ref1, ref2, ref3and ref4 of the test set respectively.Table 6 shows the results.
We clearly see that us-System BLEU-4 (%)Base 33.05Ref1 33.99*Ref2 34.17*Ref3 33.93*Ref4 34.21*Table 6: Results of using translation boundaries obtainedfrom reference translations.
*: significantly better thanbaseline (p < 0.01).ing ?right?
translation boundaries to build soft con-straints significantly improve the performance mea-sured by BLEU score.
The best result comes fromref4, which achieves an absolute increase of 1.16BLEU points over the baseline.
We believe that thebest result here only indicates the lower bound ofpotential improvement when using right translationboundaries.
If we have consistent translation bound-aries on the development and test set (for example,we have the same 4 translators build reference trans-lations for both the development and test set), theperformance improvement will be higher.5.3 Using Automatically Learned TranslationBoundariesThe success of using translation boundaries fromreference translations inspires us to pursue trans-lation boundaries predicted by our MEMM basedclassifiers.
We ran our MEMM1 (Markov order 1)and MEMM2 (Markov order 2) By/Bn and Ey/Enclassifiers on both the development and test set.Based on translation boundaries output by MEMM1and MEMM2 classifiers, we built our translationboundary violation feature and tuned it on the de-velopment set.
The evaluation results on the test setare shown in Table 7.From Table 7 we observe that using soft con-straints based on translation boundaries from bothour MEMM 1 and MEMM 2 significantly outper-form the baseline.
Impressively, when using outputsfrom MEMM 2, we achieve an absolute improve-ment of almost 1 BLEU point over the baseline.
Thisresult is also very close to the best result of usingtranslation boundaries from reference translations.To compare with constituent boundary based syn-tactic constraints, we also carried out experimentsusing two kinds of such constraints.
One is the141System BLEU-4 (%)Base 33.05Condeducer 33.18XP+ 33.58*BestRef 34.21*+MEMM 1 33.70*MEMM 2 34.04*+Table 7: Results of using automatically learned trans-lation boundaries.
Condeducer means using pure con-stituent boundary based soft constraint.
XP+ is anotherconstituent boundary based soft constraint but with dis-tinction among special constituent types (Marton andResnik, 2008).
BestRef is the best result using referencetranslation boundaries in Table 6.
MEMM 1 and MEMM2 are our MEMM based translation boundary classifierswith Markov order 1 and 2.
*: significantly better thanbaseline (p < 0.01).
+: significantly better than XP+(p < 0.01).Condeducer which uses pure constituent bound-ary based syntactic constraint: any partial transla-tions which cross any constituent boundaries willbe penalized.
The other is the XP+ from (Martonand Resnik, 2008) which only penalizes hypotheseswhich violate the boundaries of a constituent witha label from {NP, VP, CP, IP, PP, ADVP, QP, LCP,DNP}.
The XP+ is the best syntactic constraintamong all constraints that Marton and Resnik (2008)use for Chinese-to-English translation.Still in Table 7, we find that both syntactic con-straint Condeducer and XP+ are better than the base-line.
But only XP+ is able to obtain significant im-provement.
Both our MEMM 1 and MEMM 2 out-perform Condeducer.
MEMM 2 achieves significantimprovement over XP+ by approximately 0.5 BLEUpoints.
This comparison suggests that translationboundary is a better option than constituent bound-ary when we build constraints to restrict phrase-based decoding.5.4 One Classifier vs. Two ClassifiersRevisiting the classification task in this paper, wecan also consider it as a sequence labeling taskwhere the first source word of a translation zoneis labeled ?B?, the last source word of the trans-lation zone is labeled ?E?, and other words are la-beled ?O?.
To complete such a sequence labelingtask, we built only one classifier which is still basedon MEMM (with Markov order 2) with the samefeatures as described in Section 3.2.
We built softconstraints based on the outputs of this classifier andevaluated them on the test set.
The case-insensitiveBLEU score is 33.62, which is lower than the per-formance of using two separate classifiers (34.04).We calculated the accuracy for class ?B?
by map-ping ?B?
to By and ?E?
and ?O?
to Bn.
The result is67.9%.
Similarly, we obtained the accuracy of class?E?, which is as low as 48.6%.
These two accura-cies are much lower than those of using two separateclassifiers, especially the accuracy of ?E?.
This sug-gests that the By and Ey are not interrelated tightly.It is better to learn them separately with two classi-fiers.Another advantage of using two separate classi-fiers is that we can explore more constraints.
A wordck can be possibly labeled asBy by the first classifierand Ey by the second classifier.
Therefore we canbuild soft constraints on span (ci, ck) (ci ?
By, ck ?Ey) and span (ck, cj) (ck ?
By, cj ?
Ey).
This isimpossible if we use only one classifier since eachword can have only one class label.
We can buildonly one constraint on span (ci, ck) or span (ck, cj).6 Related WorkVarious approaches incorporate constraints intophrase-based decoding in a soft or hard manner.
Ourintroduction has already briefly mentioned (Cherry,2008) and (Marton and Resnik, 2008), which utilizesource-side parse tree boundary violation countingfeature to build soft constraints for phrase-based de-coding, and (Xiong et al, 2009), which calculates ascore to indicate to what extent a source phrase canbe translated as a unit using a bracketing model withricher syntactic features.
More previously, (Chi-ang, 2005) rewards hypotheses whenever they ex-actly match constituent boundaries of parse trees onthe source side.In addition, hard linguistic constraints are also ex-plored.
(Wu and Ng, 1995) employs syntactic brack-eting information to constrain search in order to im-prove speed and accuracy.
(Collins et al, 2005) and(Wang et al, 2007) use hard syntactic constraints toperform reorderings according to source-side parsetrees.
(Xiong et al, 2008) prohibit any swappings142which violate punctuation based constraints.Non-linguistic constraints are also widely usedin phrase-based decoding.
The IBM and ITG con-straints (Zens et al, 2004) are used to restrict re-orderings in practical phrase-based systems.
(Berger et al, 1996) introduces the concept of riftinto a machine translation system, which is similarto our definition of translation boundary.
They alsouse a maximum entropy model to predict whether asource position is a rift based on features only fromsource sentences.
Our work differs from (Berger etal., 1996) in three major respects.1) We distinguish a segment boundary into twocategories: beginning and ending boundary dueto their different distributions (see Table 1).However, Berger et al ignore this difference.2) We train two classifiers to predict beginningand ending boundary respectively while Bergeret al build only one classifier.
Our experimentsshow that two separate classifiers outperformone classifier.3) The last difference is how segment bound-aries are integrated into a machine transla-tion system.
Berger et al use predictedrifts to divide a long source sentence into aseries of smaller segments, which are thentranslated sequentially in order to increase de-coding speed (Brown et al, 1992; Bergeret al, 1996).
This can be considered as ahard integration, which may undermine trans-lation accuracy given wrongly predicted rifts.We integrate predicted translation boundariesinto phrase-based decoding in a soft manner,which improves translation accuracy in termsof BLEU score.7 Conclusion and Future WorkIn this paper, we have presented a simple approachto learn translation boundaries on source sentences.The learned translation boundaries are used to con-strain phrase-based decoding in a soft manner.
Thewhole approach has several properties.?
First, it is based on a simple classification taskthat can achieve considerably high accuracywhen taking translation divergences into ac-count using simple models and features.?
Second, the classifier output can be straightfor-wardly used to constrain phrase-based decoder.?
Finally, we have empirically shown that, tobuild soft constraints for phrase-based decod-ing, translation boundary predicted by our clas-sifier is a better choice than constituent bound-ary deduced from source-side parse tree.Future work in this direction will involve tryingdifferent methods to define more informative trans-lation boundaries, such as a boundary to begin/enda swapping.
We would also like to investigate newmethods to incorporate automatically learned trans-lation boundaries more efficiently into decoding inan attempt to further improve search in both speedand accuracy.ReferencesAdam L. Berger, Stephen A. Della Pietra and Vincent J.Della Pietra.
1996.
A Maximum Entropy Approachto Natural Language Processing.
Computational Lin-guistics, 22(1):39-71.Peter F. Brown, Stephen A. Della Pietra, Vincent J.Della Pietra, Robert L. Mercer, and Surya Mohanty.1992.
Dividing and Conquering Long Sentences in aTranslation System.
In Proceedings of the workshopon Speech and Natural Language, Human LanguageTechnology.Colin Cherry.
2008.
Cohesive Phrase-based Decodingfor Statistical Machine Translation.
In Proceedings ofACL.David Chiang.
2005.
A Hierarchical Phrase-basedModel for Statistical Machine Translation.
In Pro-ceedings of ACL, pages 263?270.Michael Collins, Philipp Koehn and Ivona Kucerova.2005.
Clause Restructuring for Statistical MachineTranslation.
In Proceedings of ACL.Kevin Knight.
1999.
Decoding Complexity in Word Re-placement Translation Models.
In Computational Lin-guistics, 25(4):607?
615.Philipp Koehn, Franz Joseph Och, and Daniel Marcu.2003.
Statistical Phrase-based Translation.
In Pro-ceedings of HLT-NAACL.Philipp Koehn.
2004.
Statistical Significance Tests forMachine Translation Evaluation.
In Proceedings ofEMNLP.Philipp Koehn, Amittai Axelrod, Alexandra BirchMayne, Chris Callison-Burch, Miles Osborne andDavid Talbot.
2005.
Edinburgh System Descriptionfor the 2005 IWSLT Speech Translation Evaluation.In Proceedings of IWSLT.143Yuval Marton and Philip Resnik.
2008.
Soft SyntacticConstraints for Hierarchical Phrase-Based Translation.In Proceedings of ACL.Andrew McCallum, Dayne Freitag and Fernando Pereira2000.
Maximum Entropy Markov Models for Infor-mation Extraction and Segmentation.
In Proceedingsof the Seventeenth International Conference on Ma-chine Learning 2000.Franz Josef Och and Hermann Ney.
2000.
ImprovedStatistical Alignment Models.
In Proceedings of ACL2000.Franz Josef Och.
2003.
Minimum Error Rate Trainingin Statistical Machine Translation.
In Proceedings ofACL 2003.Kishore Papineni, Salim Roukos, Todd Ward and Wei-Jing Zhu.
2002.
BLEU: a Method for AutomaticallyEvaluation of Machine Translation.
In Proceedings ofACL 2002.Brian Roark and Kristy Hollingshead.
2008.
ClassifyingChart Cells for Quadratic Complexity Context-Free In-ference.
In Proceedings of COLING 2008.Andreas Stolcke.
2002.
SRILM - an Extensible Lan-guage Modeling Toolkit.
In Proceedings of Interna-tional Conference on Spoken Language Processing,volume 2, pages 901-904.Chao Wang, Michael Collins and Philipp Koehn 2007.Chinese Syntactic Reordering for Statistical MachineTranslation.
In Proceedings of EMNLP.Dekai Wu and Cindy Ng.
1995.
Using Brackets to Im-prove Search for Statistical Machine Translation InProceedings of PACLIC-IO, Pacific Asia Conferenceon Language, Information and Computation.Dekai Wu.
1997.
Stochastic Inversion TransductionGrammars and Bilingual Parsing of Parallel Corpora.Computational Linguistics, 23(3):377-403.Deyi Xiong, Shuanglong Li, Qun Liu, Shouxun Lin,Yueliang Qian.
2005.
Parsing the Penn Chinese Tree-bank with Semantic Knowledge.
In Proceedings ofIJCNLP, Jeju Island, Korea.Deyi Xiong, Qun Liu and Shouxun Lin.
2006.
Maxi-mum Entropy Based Phrase ReorderingModel for Sta-tistical Machine Translation.
In Proceedings of ACL-COLING 2006.Deyi Xiong, Min Zhang, Ai Ti Aw, Haitao Mi, Qun Liuand Shouxun Lin.
2008.
Refinements in BTG-basedStatistical Machine Translation.
In Proceedings ofIJCNLP 2008.Deyi Xiong, Min Zhang, Ai Ti Aw, and Haizhou Li.2009.
A Syntax-Driven Bracketing Model for Phrase-Based Translation.
In Proceedings of ACL-IJCNLP2009.Richard Zens, Hermann Ney, TaroWatanabe and EiichiroSumita 2004.
Reordering Constraints for Phrase-Based Statistical Machine Translation.
In Proceedingsof COLING.Hao Zhang, Daniel Gildea, and David Chiang.
2008.Extracting Synchronous Grammars Rules from Word-Level Alignments in Linear Time.
In Proceeding ofCOLING 2008.Le Zhang.
2004.
Maximum Entropy Model-ing Tooklkit for Python and C++.
Available athttp://homepages.inf.ed.ac.uk/s0450736/maxent toolkit.html.144
