Named Entity Recognition Using a Character-based Probabilistic ApproachCasey Whitelaw and Jon PatrickLanguage Technology Research GroupCapital Markets Co-operative Research CentreUniversity of Sydney{casey,jonpat}@it.usyd.edu.auAbstractWe present a named entity recognition andclassification system that uses only probabilis-tic character-level features.
Classifications bymultiple orthographic tries are combined in ahidden Markov model framework to incorpo-rate both internal and contextual evidence.
Aspart of the system, we perform a preprocess-ing stage in which capitalisation is restored tosentence-initial and all-caps words with highaccuracy.
We report f-values of 86.65 and79.78 for English, and 50.62 and 54.43 for theGerman datasets.1 IntroductionLanguage independent NER requires the development ofa metalinguistic model that is sufficiently broad to ac-commodate all languages, yet can be trained to exploitthe specific features of the target language.
Our aim inthis paper is to investigate the combination of a character-level model, orthographic tries, with a sentence-level hid-den Markov model.
The local model uses affix informa-tion from a word and its surrounds to classify each wordindependently, and relies on the sentence-level model todetermine a correct state sequence.Capitalisation is an often-used discriminator for NER,but can be misleading in sentence-initial or all-caps text.We choose to use a model that makes no assumptionsabout the capitalisation scheme, or indeed the characterset, of the target language.
We solve the problem of mis-leading case in a novel way by removing the effects ofsentence-initial or all-caps capitalisation.
This results in asimpler language model and easier recognition of namedentities while remaining strongly language independent.2 Probabilistic Classification usingOrthographic TriesTries are an efficient data structure for capturing statis-tical differences between strings in different categories.In an orthographic trie, a path from the root through nnodes represents a string a1a2 .
.
.
an.
The n-th nodein the path stores the occurrences (frequency) of thestring a1a2 .
.
.
an in each word category.
These fre-quencies can be used to calculate probability estimatesP (c | a1a2 .
.
.
an) for each category c. Tries have previ-ously been used in both supervised (Patrick et al, 2002)and unsupervised (Cucerzan and Yarowsky, 1999) namedentity recognition.Each node in an orthographic trie stores the cumula-tive frequency information for each category in which agiven string of characters occurs.
A heterogeneous noderepresents a string that occurs in more than one category,while a homogeneous node represents a string that occursin only one category.
If a string a1a2 .
.
.
an occurs inonly one category, all longer strings a1a2 .
.
.
an .
.
.
an+kare also of the same category.
This redundancy can beexploited when constructing a trie.
We build minimum-depth MD-tries which have the condition that all nodesare heterogeneous, and all leaves are homogeneous.
MD-tries are only as large as is necessary to capture the dif-ferences between categories, and can be built efficientlyto large depths.
MD-tries have been shown to give betterperformance than a standard trie with the same numberof nodes (Whitelaw and Patrick, 2002).Given a string a1a2 .
.
.
an and a category c an ortho-graphic trie yields a set of relative probabilities P (c | a1),P (c | a1a2), .
.
., P (c | a1a2 .
.
.
an).
The probability thata string indicates a particular class is estimated along thewhole trie path, which helps to smooth scores for rarestrings.
The contribution of each level in the trie is gov-erned by a linear weighting function of the formP (c | a1a2 .
.
.
an) =n?i=1?iP (c | a1a2 .
.
.
ai)where ?i ?
[0, 1] andn?i=1?i = 1Tries are highly language independent.
They make noassumptions about character set, or the relative impor-tance of different parts of a word or its context.
Tries usea progressive back-off and smoothing model that is wellsuited to the classification of previously unseen words.While each trie looks only at a single context, multipletries can be used together to capture both word-internaland external contextual evidence of class membership.3 Restoring Case InformationIn European languages, named entities are often distin-guished through their use of capitalisation.
However,capitalisation commonly plays another role, that of mark-ing the first word in a sentence.
In addition, some sen-tences such as newspaper headlines are written in all-capitals for emphasis.
In these environments, the caseinformation that has traditionally been so useful to NERsystems is lost.Previous work in NER has been aware of this prob-lem of dealing with words without accurate case informa-tion, and various workarounds have been exploited.
Mostcommonly, feature-based classifiers use a set of capitali-sation features and a sentence-initial feature (Bikel et al,1997).
Chieu and Ng used global information such as theoccurrence of the same word with other capitalisation inthe same document (Chieu and Ng, 2002a), and have alsoused a mixed-case classifier to teach a ?weaker?
classifierthat did not use case information at all (Chieu and Ng,2002b).We propose a different solution to the problem of case-less words.
Rather than noting their lack of case andtreating them separately, we propose to restore the cor-rect capitalisation as a preprocessing step, allowing allwords to be treated in the same manner.
If this processof case restoration is sufficiently accurate, capitalisationshould be more correctly associated with entities, result-ing in better recognition performance.Restoring case information is not equivalent to distin-guishing common nouns from proper nouns.
This is par-ticularly evident in German, where all types of nouns arewritten with an initial capital letter.
The purpose of caserestoration is simply to reveal the underlying capitalisa-tion model of the language, allowing machine learners tolearn more accurately from orthography.We propose two methods, each of which requires a cor-pus with accurate case information.
Such a corpus is eas-ily obtained; any unannotated corpus can be used oncePrecision Recall F?=1lowercase 98.58% 96.58% 97.57init-caps 89.76% 92.74% 91.22allcaps 54.01% 92.33% 68.15inner-caps 48.49% 80.00% 60.38Table 1: Case restoration performance using an MD-trie,English.sentence-initial words and allcaps sentences have beenexcluded.
For both languages, the training corpus con-sisted of the raw data, training and test data combined.The first method for case restoration is to replace acaseless word with its most frequent form.
Word capi-talisation frequencies can easily be computed for corporaof any size.
The major weakness of this technique is thateach word is classified individually without regard forits context.
For instance, ?new?
will always be writtenin lowercase, even when it is part of a valid capitalisedphrase such as ?New York?.The second method uses an MD-trie which, if allowedto extend over word boundaries, can effectively capturethe cases where a word has multiple possible forms.Since an MD-trie is only built as deep as is required tocapture differences between categories, most paths willstill be quite shallow.
As in other word categorisationtasks, tries can robustly deal with unseen words by per-forming classification on the longest matchable prefix.To test these recapitalisation methods, the raw, train-ing, and development sets were used as the training set.From the second test set, only words with known caseinformation were used for testing, resulting in corporaof 30484 and 39639 words for English and German re-spectively.
Each word was classified as either lowercase(?new?
), initial-caps (?New?
), all-caps(?U.S.?
), or inner-caps (?ex-English?).
On this test set, the word-frequencymethod and the trie-based method achieved accuracies of93.9% and 95.7% respectively for English, and 95.4%and 96.3% in German.
Table 1 shows the trie perfor-mance for English in more detail.
In practice, it is usu-ally possible to train on the same corpus as is being re-capitalised.
This will give more accurate informationfor those words which appear in both known-case andunknown-case positions, and should yield higher accu-racy.This process of restoring case information is languageindependent and requires only an unannotated corpus inthe target language.
It is a pre-processing step that canbe ignored for languages where case information is eithernot present or is not lost.NER Precision Recall F?=1English devel.
94.56% 91.31% 92.91English test 91.48% 88.16% 89.79German devel.
79.95% 45.02% 57.60German test 79.16% 49.30% 60.76Table 2: Recognition performance.4 Classification ProcessThe training data was converted to use the IOB2 phrasemodel (Tjong Kim Sang and Veenstra, 1999).
This phrasemodel was found to be more appropriate to the nature ofNE phrases in both languages, in that the first word inthe phrase may behave differently to consecutive words.MD-Tries were trained on the prefix and suffix of the cur-rent word, and the left and right surrounding contexts.Each trie Tx produces an independent probability esti-mate, PTx(c | context).
These probabilities are com-bined to produce a single estimateP (c | context) =n?i=0PTi(c | context)These probabilities are then used directly as obser-vation probabilities in a hidden Markov model (HMM)framework.
An HMM uses probability matrices ?, A,and B for the initial state, state transitions, and symbolemissions respectively (Manning and Schu?tze, 1999).
Wederive ?
and A from the training set.
Rather than explic-itly defining B, trie-based probability estimates are useddirectly within the standard Viterbi algorithm, which ex-ploits dynamic programming to efficiently search the en-tire space of state assignments.
Illegal assignments, suchas an I-PER without a preceding B-PER, cannot arise dueto the restrictions of the transition matrix.The datasets for both languages contained extra infor-mation including chunk and part-of-speech information,as well as lemmas for the German data.
While these arerich sources of data, and may help especially in the recog-nition phase, our aim was to investigate the feasibility ofa purely orthographic approach, and as such no extra in-formation was used.5 ResultsTable 2 shows how the system performs in terms ofrecognition.
There is a large discrepancy between recog-nition performance for English and German.
For Ger-man, it appears that there is insufficient morphologicalinformation in a word and its immediate context to reli-ably discriminate between NEs and common nouns.
Pre-cision is markedly higher than recall across all tests.
Themost common error in English was the misclassificationNER NECseen unseen seen unseenEng devel.
99.1% 92.7% 95.0% 71.6%Eng test 98.7% 89.5% 94.1% 70.5%German devel.
96.7% 73.7% 95.4% 80.7%German test 97.2% 80.8% 95.6% 85.7%Table 3: Accuracy on seen and unseen tokens.word-based trie-basedEnglish devel.
+0.67 +0.92English test +1.29 +0.90German devel.
+0.44 +0.78German test -0.12 +0.26Table 4: Improvement in f-score through restoring case.of a single-term entity as a non-entity, while multi-wordentities were more successfully identified.Table 3 shows the overall performance difference be-tween words present in the tagged training corpus andthose that only occurred in the test set.
For previouslyseen words, both recognition and classification performwell, aided by the variable depth of MD-tries.
The pro-gressive back-off model of tries is quite effective in clas-sifying new tokens, achieving up to 85% accuracy in clas-sification unseen entities.
It is interesting to note that,given a successful recognition phase, German NEs aremore successfully classified than English NEs.The effects of heuristically restoring case informationcan be seen in Table 4.
The contribution of recapitali-sation is limited by the proportion of entities in caselesspositions.
Both the word-based method and the trie-basedmethod produced improvements.
The higher accuracy ofthe trie-based approach gives better overall performance.The final results for each language and dataset aregiven in Table 5.
Both English datasets have the sameperformance profile: results for the PER and LOC cat-egories were markedly better than the MISC and ORGcategories.
Since seen and unseen performance remainedquite stable, the lower results for the second test set canbe explained by a higher percentage of previously unseenwords.
While MISC is traditionally the worst-performingcategory, the lowest results were for ORG.
This pattern ofperformance was different to that for German, in whichMISC was consistently identified less well than the othercategories.6 ConclusionWe have presented a very simple system that uses onlyinternal and contextual character-level evidence.
Thishighly language-independent model performs well onboth seen and unseen tokens despite using only the su-pervised training data.
The incorporation of trie-basedestimates into an HMM framework allows the optimal tagsequence to be found for each sentence.We have also shown that case information can be re-stored with high accuracy using simple machine learn-ing techniques, and that this restoration is beneficial tonamed entity recognition.
We would expect most NERsystems to benefit from this recapitalisation process, es-pecially in fields without accurate case information, suchas transcribed text or allcaps newswire.Trie-based classification yields probability estimatesthat are highly suitable for use as features in a furthermachine learning process.
This approach has the advan-tage of being highly language-independent, and requiringfewer features than traditional orthographic feature repre-sentations.ReferencesDaniel M. Bikel, Scott Miller, Richard Schwartz, andRalph Weischedel.
1997.
Nymble: a high-performance learning name-finder.
In Proceedings ofANLP-97, pages 194?201.Hai Leong Chieu and Hwee Tou Ng.
2002a.
Named En-tity Recognition: A Maximum Entropy Approach Us-ing Global Information.
In Proceedings of the 19th In-ternational Conference on Computational Linguistics(COLING 2002), pages 190?196.Hai Leong Chieu and Hwee Tou Ng.
2002b.
Teach-ing a Weaker Classifier: Named Entity Recognition onUpper Case Text.
In Proceedings of the 40th AnnualMeeting of the Association for Computational Linguis-tics (ACL-02), pages 481?488.S.
Cucerzan and D. Yarowsky.
1999.
Language indepen-dent named entity recognition combining morphologi-cal and contextual evidence.Christopher D. Manning and Hinrich Schu?tze.
1999.Foundations of Statistical Natural Language Process-ing.
The MIT Press, Cambridge, Massachusetts.Jon Patrick, Casey Whitelaw, and Robert Munro.2002.
SLINERC: The Sydney Language-IndependentNamed Entity Recogniser and Classifier.
In Proceed-ings of CoNLL-2002, pages 199?202.
Taipei, Taiwan.Erik F. Tjong Kim Sang and Jorn Veenstra.
1999.
Rep-resenting Text Chunks.
In Proceedings of EACL?99,pages 173?179.
Bergen, Norway.Casey Whitelaw and Jon Patrick.
2002.
Orthographictries in language independent named entity recogni-tion.
In Proceedings of ANLP02, pages 1?8.
Centrefor Language Technology, Macquarie University.English devel.
Precision Recall F?=1LOC 91.35% 89.06% 90.19MISC 88.09% 79.39% 83.51ORG 79.18% 81.66% 80.40PER 92.21% 86.70% 89.37Overall 88.20% 85.16% 86.65English test Precision Recall F?=1LOC 82.40% 85.07% 83.72MISC 75.93% 72.36% 74.11ORG 76.10% 71.88% 73.93PER 89.25% 79.59% 84.15Overall 81.60% 78.05% 79.78German devel.
Precision Recall F?=1LOC 68.95% 49.45% 57.59MISC 75.34% 32.67% 45.58ORG 63.58% 39.81% 48.96PER 77.11% 35.83% 48.93Overall 70.40% 39.52% 50.62German test Precision Recall F?=1LOC 64.46% 48.02% 55.04MISC 64.86% 30.30% 41.30ORG 65.64% 44.24% 52.86PER 85.63% 48.37% 61.82Overall 71.05% 44.11% 54.43Table 5: Final results for English and German, develop-ment and test sets.
