Turn off the Radio and Call Again:How Acoustic Clues can Improve Dialogue ManagementChrist ian Lieske\]~cole Polytechnique F~d@derale Lausanne (EPFL)e-mail: lieske@di.epfl.ch1 In t roduct ionTraditionally, the most imPortant input tothe dialogue management component of anatural anguage system are semantic repre-sentations (e.g., formulae of first-order pre-dicate calculus).
Only recently, other kindsof information (e.g., phonetic transcriptionsof unknown words) has been used.
Thereis, however, room for the utilization of ad-ditional knowledge sources.
In what fol-lows, we first explicate how information fromthe accoustic level (e.g., the presence of cer-tain kinds of background noise from a radio)enables better system performance.
Our ar-gumentation is that this is possible since thedialogue manager can use acoustic clues, onthe one hand, to establish better recognitionconditions, and on the other hand to gene-rate more co-operative interactions.
Afterthis argumentation, we indicate how the aco-ustic cues for dialogue management compo-nents can be generated.2 State-of - the-art  in DialogueManagementToday, many dialogue management compo-nents base their operations on a combinationof dialogue history, a rule-based or statisti-Most of the ideas presented here were developed u-ring work at Forum Technology, Malvern.
I am indebtedto all of my colleagues there, especicially J6rg ~lberlaand David Bijl for providing valuable discussions.
I alsoowe thanks to Afzal Ballhn, and Yoshiki Mori for theircomments on drafts of this poster.45cal dialogue model, rule-based or statisticaldialogue act idenfication rules, and semanticrepresentations of user utterances.
For spo-ken language input, this repertoire of infor-mation ensues interactions like the (unsuc-cessful) dialogue in Figure 1 (from a traintimetable nquiry system).
1What happens in a dialogue like this isthe following: The dialogue manager triesto verify a value that is needed for a da-tabase query.
This attempt fails several ti-mes, since the incoming semantic represen-tations are inconsistent due to recognitionerrors.
After an arbitrary number of trials(two in the example), the dialogue managersurrenders.More advanced systems exploit additionalinformation to generate more intelligent fe-edback for the user.
The Verbmobil devicewhich translates poken utterances betweenGerman and English as well as betweenJapanese and English (see (Kay et al,1994)), e.g.
exploits representations ofunknown words and information about pho-netically similar words to generate clarifica-tion dialogues along the lines of Figure 2 (cf.
(Maier et al, 1997)).1 Apologies for the fact that all examples are relatedto German.userusersystemsystemuserusersystemsystemuserusersystemsystemIch mSchte gerne um zwei Uhrnach Hamburg fahren.I would like to travel to Hamburgat two o 'clock.Sie mSchten nach Homburgfahren?You would like to go to Homburg?Nein, nicht nach Homburg, son-dern nach Hamburg.No, not to Homburg but to Ham-burg.Sie mSchten nach Offenburgfahren?You would like to go to Often-burg?Nein, ich mSchte auch nicht nachOffenburg, sondern nach Ham-burg.No, I also don't want to go to Of-fenburg but to Hamburg.Es scheint ein Kommuni-kationsproblem zu geben.
Bitteversuchen Sie es sp~ter noch ein-mal.We seem to have a communica-tions problem.
Please try againlater.Figure 1: Communication failureuserusersystemsystemuserusersystemsystemuseruserMein Name ist Schwartz.
IchmSchte mit Ihnen einen Terminim Juli ausmachen.My name is Schwartz.
I wouldlike to arrange an appointment inJuly.Ist Schwartz ein Eigenname?Is Schwartz a proper name?Ja.Yes.Sagten Sie 'Juli' oder ' Juni'?Did you say 'July' or 'June'?Juli.July.Figure 2: Intelligent dialogue3 Dialogue Management withAcoustic CluesStill missing even from the more sophistica-ted systems like Verbmobil is a flow of in-formation all the way from the acoustic levelup to the dialogue management component.
2This kind of coupling will enable more suc-cessful systems for two reasons: impro-ved speech recognition and more informativeresponses to the user.Improvement in speech recognition willstem from the dialogue manager acting asa kind of mediator between the speech re-cognizer and the user.
In case of bad re-cognition rates (speech recognizers alreadydeliver confidence scores), the dialogue ma-nager could ask for acoustic lues concerningthe recognition conditions.
If it then receivessome clues about background noise (e.g., aradio), it might initiate a request o the userto establish a better acoustic environment.More specifically, the dialogue manager co-uld generate the concepts to ask Could youplease turn off the radio?The quality of responses to users equallywell can profit from information about theacoustic environment.
To see this, imagine asituation where a police officer reports fromthe scene of an accident: In this situation,the acoustic conditiohs presumably are soadverse that recognition accuracy is inacce-ptable.
Unlike in the scenario above, ho-wever~ little can be done to change the en-vironment.
The appropriate action of thedialogue manager thus would be to make itclear to the officer that he is wasting his timein trying to get his message through.Thus, with information on the acousticconditions/environment, the dialogue in Fi-gure 1 could become the one outlined in Fi-gure 3.2Take this as a metaphor.
The architecture might infact be black- or whiteboard-like.46userusersystemsystemuseruserIch mSchte gerne um zwei Uhrnach Hamburg fahren.I would like to travel to Hamburgat two o'clock.Sie sind wegen der Musik im Hin-tergrund leider schwer zu verste-hen.
W?re es mSglich, dat~ Sienochmals anrufen, wenn Sie dieMusik abgestellt haben?Unfortunately, I have got difficul-ties in understanding you due tothe music in the background.
Co-uld you call again after havingturned it off?Ja; bis gleich.Yes; until later.Figure 3: Dialogue utilizing acoustic clues4 Techniques for Detect ing  Acoust icCluesWork on the acoustic level that is suited forintegration into a dialogue framework likethat depicted above has not advanced farenough, yet.
Only recently, in the backgro-und of the DARPA evaluations for speechrecognition systems, the importance of thetype of noise tracking that is needed has beenrealized.
A component that not only dete-cts but also classifies noise (as, e.g., musicor street noise) has a good chance of beco-ming the first plug-and-play spoken languageinterface entity (SLIE), and seems to be re-alizable by well-mastered techniques for spe-ech recognition like Hidden Markov Models((Rabiner, 1989)).One approach for classifying acousticconditions into different categories (e.g.background music) would be to use techni-ques like the ones used for non-word ba-sed topic spotting (see (Nowell and Moore,1995)).
The different categories of noisewould correspond to topics, and typical se-ctions of acoustic material from each cate-gory would correspond to keywords.
Ba-sed on samples from each category/topic, ke-ywords which are most useful in identifyingthis topic would then be extracted automa-tically.
An incoming signal could then beclassified as belonging to one of the catego-ries, depending on which keywords appearmost frequently.Another approach is to build a simple Hid-den Markov Model which gets trained foreach category from the data in that category.An incoming signal could then be assignedto the category whose HMM gives the bestmatch.Research is also needed in the realm ofdialogue management.
It remains to be in-vestigated in exactly which ways the acousticinformation can be used.
Obvious requestsor follow-up questions like those exampli-fled above are one option; more clever qu-estions like Our communication may proceedmore smoothly if the system adapts to youracoustic conditions; shall this be done?
areanother.ReferencesMartin Kay, Jean Mark Gawron, and Peter Nor-vig.
1994.
Verbmobil: A Translation System forFace-to-Face Dialog.
Number 33 in Lecture No-tes.
CSLI, Stanford, CA.E.
Maier, N. Reithinger, and Alexandersson J.
1997.Clarification dialogues as measures toincrease ro-bustness in a spoken dialogue system.
In Proce-edings of the ACL/EACL Workshop on SpokenDialog Systems, Madrid.Peter Nowell and Roger Moore.
1995.
The applica-tion of dynamic programming techniques tonon-word based topic spotting.
In Proceedings ofthe4th European Conference on Speech Communica-tion and Technology, Madrid.Lawrence R. Rabiner.
1989.
A tutorial on hiddenMarkov models and selected applications in spe-ech recognition.
In Proceedings ofthe IEEE, pa-ges 257 - 286.47
