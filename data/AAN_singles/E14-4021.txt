Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 106?110,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsAutomatic Selection of Reference Pages in Wikipediafor Improving Targeted Entities DisambiguationTakuya MakinoFujitsu Laboratories Ltd.4-1-1 Kamikodanaka, Nakahara-ku, Kawasaki, Japanmakino.takuya@jp.fujitsu.comAbstractIn Targeted Entity Disambiguation setting,we take (i) a set of entity names which be-long to the same domain (target entities),(ii) candidate mentions of the given enti-ties which are texts that contain the tar-get entities as input, and then determinewhich ones are true mentions of ?targetentity?.
For example, given the names ofIT companies, including Apple, we deter-mine Apple in a mention denotes an ITcompany or not.
Prior work proposed agraph based model.
This model ranks allcandidate mentions based on scores whichdenote the degree of relevancy to targetentities.
Furthermore, this graph basedmodel could utilize reference pages of tar-get entities.
However, human annotatorsmust select reference pages in advance.We propose an automatic method that canselect reference pages.
We formalize theselection problem of reference pages as anInteger Linear Programming problem.
Weshow that our model works as well as theprior work that manually selected refer-ence pages.1 IntroductionThe enterprise is typically interested in customer?sopinions.
One of the methods to analyze cus-tomer?s opinions is to collect mentions which con-tain product names.
We would get a noisy mentioncollection if we use a simple method which ex-tracts mentions that contain product names, sincethe product names may be used as other meanings.Wang et al.
(2012) proposed a new task whichthey referred to as Targeted Entity Disambigua-tion (TED).
In this problem setting, we take (i) aset of entity names which belong to the same do-main (target entities), (ii) candidate mentions ofthe given entities which are texts that contain thetarget entity entities as input, and then determinewhich ones are true mentions for the target enti-ties.
TED is different from traditional Word SenseDisambiguation or Entity Linking.
Word SenseDisambiguation can be viewed as a classificationtask in which word senses are the classes (Nav-igli, 2009) and Entity Linking is the task of link-ing name in Web text with entities in Wikipedia(Han et al., 2011).
The uniqueness of this prob-lem is that the entities are all in the same domain(referred to as the target domain) and not necessar-ily included in a knowledge base such as DBpedia,Freebase or YAGO.Wang et al.
(2012) realized TED with a graphbased model.
In their graph based method, a targetentity in a mention is regarded as a node, and theweight of an edge is determined according to con-text similarity, and a prior score of node that is de-termined according to the unique number of targetentities in the mention.
This graph is called as amention graph.
Using mention graph, the author-ity of each mention is calculated with Mention-Rank which is a variant of PageRank (Page et al.,1999).
This authority denotes a score of how likelythis node is in the target domain.
In addition, Men-tionRank could integrate external knowledge suchas Wikipedia.
For each target entity, a referencepage is added as a virtual node to the graph.
Sincereference pages can be regarded as true mentions,the prior scores of virtual nodes are higher thanother mentions.
This extended method can prop-agate the score of the virtual node of each entityto candidate mentions which are likely true.
Al-though the use of reference pages works well, hu-man annotators must select these reference pages.InWord Sense Disambiguation and Entity Link-ing, there are some collective approaches (Hoffartet al., 2011; Kulkarni et al., 2009).
In this pa-per, we apply this technique to the selection prob-lem of reference pages for TED.
To select refer-106ence pages, we collect candidate reference pagesof target entities from Wikipedia in advance.
Ifthe name of a target entity has a disambiguationpage in Wikipedia, we have two or more candi-date reference pages.
Then we formalize the prob-lem of reference page selection as an Integer Lin-ear Programming problem.
Our model is going tomaximize the summation of similarities betweenselected pages under some constraints.
Thus, co-herent pages are selected as reference pages.
Ourmethod does not require any knowledge except fornames of target entities.
We give only target enti-ties as input to select reference pages.
Our methodshows competitive accuracy of the prior methodwith manually selected reference pages.2 Task DefinitionFollowing previous work, we assume that all oc-currences of a name in a mention refer to the sameentity (e.g., occurrences of the string ?Apple?
in asingle mention either all refer to the IT companyor all refer to the fruit) (Wang et al., 2012).TED is defined as follows.Definition 1 (Targeted Entity Disambiguation).Given input of a target entity set E = {e1, ..., en},a mention set D = {d1, ..., dn} and candidatementions R = {(ei, dj)|ei?
E, dj?
D}, out-put score rij?
[0, 1] for every candidate mention(ei, dj) ?
R.3 Related WorkWang et al.
(2012) proposed MentionRank to ad-dress TED.
MentionRank is similar to PageRank.This model is based on three hypotheses:1.
Context similarity: The true mentionsacross all the entities, across all the mentionswill have more similar contexts than the falsementions of different entities.2.
Co-Mention: If multiple target entities areco-mentioned in a mention, they are likely tobe true mentions.3.
Interdependency: If one or more men-tions among the ones with similar context isdeemed likely to be a true mention, they areall likely to be true mentions.In a mention graph, a node (ei, dj) denotes anentity eiin mention dj.
The weight of edge be-tween (ei, dj) and (e?i, d?j) is denoted as wij,i?j?which is a variable normalized by context similar-ity ?ij,i?j?.
Context similarities are normalized toavoid ?false-boost?
problem.
?false-boost?
prob-lem is boosting ranking score of false mentions ina false mentions group.
The normalized weight ofthe edge is defined as follows:wij,i?j?={zijkif i = i?,?i?j?,ijViZ+zijkotherwise.
(1)zij= 1 ??i??=i?j?
?i?j?,ijViZ, (2)Z = maxi,j?i??=i?j?
?i?j?,ijVi, (3)where, Videnotes the number of candidate men-tions that contain ei(i.e.
Vi= |{dj|(ei, dj) ?R}|).
k denotes the number of all candidate men-tions (i.e.
k = |R|).
Co-mention is representedby a prior score.
Wang et al.
(2012) definedprior score piijof (ei, dj) as the number of uniquenames of target entities occurred in dj.The final score of each mention is decided byits prior score estimation as well as the score ofthe other correlated mentions.rij= ?pij+ (1 ?
?
)?i?,j?wij,i?j?ri?j?, (4)where ?
is the dumping factor.
pijdenotes priorscore of (ei, dj): pij= piij/?i?,j?pii?j?Although this model works even if only thenames of entities are given as input, we can ex-tend this model to integrate external knowledgesuch as Wikipedia.
For example, we can add refer-ence pages for each entity as virtual nodes.
Sincewe can assume that the reference page of a tar-get entity is a true mention with a high confidence,we assign a high prior score than the other men-tions.
This causes the group of candidate men-tions which have similar contexts with the refer-ence pages to get higher scores.
One example ofusing reference pages is to add a set of referencepages {ai|1 ?
i ?
n} into the mention graph.
aidenotes the reference page of entity ei.4 Proposed MethodIn this section, we propose our approach for auto-matic selection of reference pages.
In the domainof Word Sense Disambiguation and Entity Link-ing, some researches proposed the methods which107Figure 1: Article ?Apple (disambiguation)?
inWikipediaare based on coherence between mentions (Hof-fart et al., 2011; Kulkarni et al., 2009; Han et al.,2011).
Our method does not require any knowl-edge except for the names of target entities.
Wegive only target entities as input.
Target entities inWikipedia have two characteristics.?
A name of an ambiguous target entity tendsto have a disambiguation page.?
The articles that are in the same domain havethe same categories or contain similar con-tents.In Wikipedia, there are disambiguation pages likeFigure 1.
?Apple (disambiguation)?
contains appleas a plant, an IT company, a music album, and soon.
To collect candidate reference pages, we usethese disambiguation pages.Kulkarni et al.
(2009) formalized entity linkingas an Integer Linear Programming problem andthen relaxed it as a Linear Programming problem.They considered a coherence score which takeshigher value if the selected articles have similarcontents.
Their framework can be used for entitylinking and word sense disambiguation.
In this pa-per, we use this coherence score to select referencepages.
We show an image of an automatic selec-tion of reference pages in Figure 2.
In Figure 2,the target entities are Apple, HP and Microsoft.Although we have only one page for Microsoft,we have two or more candidate reference pages,since Apple and HP have disambiguation pages.Then we need to select reference pages for Ap-ple and HP.
If the name of a target entity is notin Wikipedia, we have no reference page for thatFigure 2: Automatic selection of reference pagesfrom disambiguation pages in Wikipedia: selectedpages contains same categories or similar contents(They are connected by edge).target entity.
The goal of this example is to select?Apple Inc.?
for Apple and ?Hewlett-Packard?
forHP (Selecting ?Microsoft?
for Microsoft is triv-ial).
We regard these selected articles as referencepages for target entities.We assume that the number of true referencepage aifor target entity eiis one and select onereference page for each target entity.
For each tar-get entity, we select articles which the have samecategories or similar contents from the set of can-didate reference pages {cik|1 ?
k ?
l} since weassume that the articles in the same domain havethe same categories or contain similar contents.
Infact, our model is going to maximize the summa-tion of similarities between selected pages undersome constraints.
We formalize this selection asfollows:max .
?i,k?i?,k?eik,i?k?xik,i?k?,s.t .
?i,?kyik= 1, (5)yik?
xik,i?k?
; ?i, k, i?, k?, (6)yi?k??
xik,i?k?
; ?i, k, i?, k?, (7)xik,i?k??
{0, 1}; ?i, k, i?, k?, (8)yik?
{0, 1}; ?i, k, (9)eik,i?k?denotes the weight of the edge betweencandidate reference pages cikand ci?k?.
xik,i?k?takes 1 if cikis selected, 0 otherwise.
yiktakes1 if the edge between cikand ci?k?is selected, 0108n k #cand %PositiveCar 21 1809 21.5 29.9Magazine 28 2741 17.9 43.5Table 1: Datasets: n is # of entities, k is # of can-didate mentions, #cand is average # of candidatereference pages for each entity and %Positive is %of true mentions in all candidate mentionsn=5 Car MagazineMentionRank 39.74 61.07MentionRank+manVN 39.14 70.94?MentionRank+randomVN 37.85?
65.01Proposed method 44.21 65.86n=10MentionRank 49.23 65.90?MentionRank+manVN 47.21?
70.85MentionRank+randomVN 45.13?
68.38Proposed method 50.84 69.81n=15MentionRank 46.50?
65.77?MentionRank+manVN 44.29 69.38MentionRank+randomVN 39.21?
67.89Proposed method 42.77 69.02Table 2: Mean average precision for each datasetotherwise.
Constraint (5) ensures that always onearticle is selected for each entity.
Constraints (6)and (7) ensure that when xik,i?k?= 1, yikand yi?k?.In this paper, we defined eik,i?k?as cosine similar-ity of two vectors of words those weights are tfidf.5 ExperimentsWe used weblogs written in Japanese for experi-ments.
Following the previous work, we createdtwo datasets: Car and Magazine.
A summary ofeach dataset is shown in Table 1.?
Car: Target entities include car names suchas Prius and Harrier.?
Magazine: Target entities include magazinenames such as MORE and LEE.We randomly selected 5, 10 or 15 entities fromeach target entities for 10 times and conductedexperiment for each dataset with parameter ?= 0.15.
We conducted significance test usingWilcoxon signed-rank test.
Table 2 lists theexperimental results on these datasets.
In Ta-ble 2, MentionRank+manVN denotes Mention-Rank with virtual nodes that are selected manually(Wang et al., 2012).
MentionRank+randomVNdenotes MentionRank with virtual nodes that areselected randomly from candidate reference pagesin Wikipedia.
Proposed method denotes the Men-tionRank with virtual nodes that are selected auto-matically using ILP.
Values with ?in Table 2 indi-cate that there are significant differences betweenmean average precision of proposed method andthe others.
Five results of proposed methods arebetter than those of MentionRank, there are signif-icant differences on two results.
Furthermore, allthe results of proposed method is better than thoseof MentionRank+randomVN and there are signif-icant differences on three results.
Four results ofproposed method is worse than those of Mention-Rank+manVN, however there is a significant dif-ference on only one of those results.
From theseresults, we can see that use of reference pagesautomatically selected by our method improvesmean average precision.
In Magazine, several en-tities are not ambiguous and we could get true ref-erence pages easily.
Therefore, we think proposedmethod did not show any significant differencescompared with MentionRank+randomVN.
Also,in Car, several entities are not ambiguous but thesereference pages belong to domains other than Cardomain.
As a result, we think that some resultsare worse than MentionRank.
For example, entity?86?
which is a kind of car have only one referencepage that belongs to number domain.6 ConclusionIn this paper, we proposed an automatic selec-tion method of reference pages for Target En-tity Disambiguation.
Our method that uses au-tomatically selected reference pages showed bet-ter performance than MentionRank without ref-erence pages and competitive mean average pre-cision with MentionRank with manually selectedreference pages.Since our framework always selects one refer-ence page for each target entity even if a referencepage does not exist in Wikipedia or one or morereference pages exist in Wikipedia, we need to re-fine our framework in future work.
An another im-provement would be to assign prior scores for vir-tual nodes according to coherence score betweenthe other virtual nodes.109ReferencesXianpei Han, Le Sun, and Jun Zhao.
2011.
Collectiveentity linking in web text: a graph-based method.
InProceedings of the 34th international ACM SIGIRconference on Research and development in Infor-mation Retrieval, SIGIR ?11, pages 765?774, NewYork, NY, USA.
ACM.Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bor-dino, Hagen F?urstenau, Manfred Pinkal, Marc Span-iol, Bilyana Taneva, Stefan Thater, and GerhardWeikum.
2011.
Robust disambiguation of namedentities in text.
In Proceedings of the Conference onEmpirical Methods in Natural Language Process-ing, EMNLP ?11, pages 782?792, Stroudsburg, PA,USA.
Association for Computational Linguistics.Sayali Kulkarni, Amit Singh, Ganesh Ramakrishnan,and Soumen Chakrabarti.
2009.
Collective annota-tion of Wikipedia entities in web text.
In Proceed-ings of the 15th ACM SIGKDD international con-ference on Knowledge discovery and data mining,KDD ?09, pages 457?466, New York, NY, USA.ACM.Roberto Navigli.
2009.
Word sense disambiguation:A survey.
ACM Comput.
Surv., 41(2):10:1?10:69,February.Lawrence Page, Sergey Brin, Rajeev Motwani, andTerry Winograd.
1999.
The pagerank citation rank-ing: Bringing order to the web.
Technical Report1999-66, Stanford InfoLab, November.Chi Wang, Kaushik Chakrabarti, Tao Cheng, and Sura-jit Chaudhuri.
2012.
Targeted disambiguation ofad-hoc, homogeneous sets of named entities.
InProceedings of the 21st international conference onWorld Wide Web, WWW ?12, pages 719?728, NewYork, NY, USA.
ACM.110
