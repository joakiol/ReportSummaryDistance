An Unsupervised Method for Uncovering Morphological ChainsKarthik Narasimhan, Regina Barzilay and Tommi JaakkolaCSAIL, Massachusetts Institute of Technology{karthikn, regina, tommi}@csail.mit.eduAbstractMost state-of-the-art systems today producemorphological analysis based only on ortho-graphic patterns.
In contrast, we propose amodel for unsupervised morphological anal-ysis that integrates orthographic and seman-tic views of words.
We model word forma-tion in terms of morphological chains, frombase words to the observed words, breakingthe chains into parent-child relations.
We uselog-linear models with morpheme and word-level features to predict possible parents, in-cluding their modifications, for each word.The limited set of candidate parents for eachword render contrastive estimation feasible.Our model consistently matches or outper-forms five state-of-the-art systems on Arabic,English and Turkish.11 IntroductionMorphologically related words exhibit connectionsat multiple levels, ranging from orthographical pat-terns to semantic proximity.
For instance, the wordsplaying and played share the same stem, but alsocarry similar meaning.
Ideally, all these comple-mentary sources of information would be taken intoaccount when learning morphological structures.Most state-of-the-art unsupervised approaches tomorphological analysis are built primarily aroundorthographic patterns in morphologically-relatedwords (Goldwater and Johnson, 2004; Creutz andLagus, 2007; Snyder and Barzilay, 2008; Poon etal., 2009).
In these approaches, words are com-monly modeled as concatenations of morphemes.1Code is available at https://github.com/karthikncode/MorphoChain.This morpheme-centric view is well-suited for un-covering distributional properties of stems and af-fixes.
But it is not well-equipped to capture semanticrelatedness at the word level.In contrast, earlier approaches that capture se-mantic similarity in morphological variants oper-ate solely at the word level (Schone and Juraf-sky, 2000; Baroni et al., 2002).
Given two candi-date words, the proximity is assessed using standardword-distributional measures such as mutual infor-mation.
However, the fact that these models do notmodel morphemes directly greatly limits their per-formance.In this paper, we propose a model to integrate or-thographic and semantic views.
Our goal is to builda chain of derivations for a current word from itsbase form.
For instance, given a word playfully, thecorresponding chain is play ?
playful ?
playfully.The word play is a base form of this derivation asit cannot be reduced any further.
Individual deriva-tions are obtained by adding a morpheme (ex.
-ful )to a parent word (ex.
play).
This addition may beimplemented via a simple concatenation, or it mayinvolve transformations.
At every step of the chain,the model aims to find a parent-child pair (ex.
play-playful ) such that the parent also constitutes a validentry in the lexicon.
This allows the model to di-rectly compare the semantic similarity of the parent-child pair, while also considering the orthographicproperties of the morphemic combination.We model each step of a morphological chain bymeans of a log-linear model that enables us to in-corporate a wide range of features.
At the seman-tic level, we consider the relatedness between twowords using the corresponding vector embeddings.At the orthographic level, features capture whether157Transactions of the Association for Computational Linguistics, vol.
3, pp.
157?167, 2015.
Action Editor: Yuji Matsumoto.Submission batch: 9/2014; Revision batch: 12/2014; Revision batch 2/2015; Published 3/2015.c?2015 Association for Computational Linguistics.
Distributed under a CC-BY-NC-SA 4.0 license.the words in the chain actually occur in the corpus,how affixes are reused, as well as how the wordsare altered during the addition of morphemes.
Weuse Contrastive Estimation (Smith and Eisner, 2005)to efficiently learn this model in an unsupervisedmanner.
Specifically, we require that each word hasgreater support among its bounded set of candidateparents than an artificially constructed neighboringword would.We evaluate our model on datasets in three lan-guages: Arabic, English and Turkish.
We compareour performance against five state-of-the-art unsu-pervised systems: Morfessor Baseline (Virpioja etal., 2013), Morfessor CatMAP (Creutz and Lagus,2005), AGMorph (Sirts and Goldwater, 2013), theLee Segmenter (Lee et al., 2011; Stallard et al.,2012) and the system of Poon et al.
(2009).
Ourmodel consistently equals or outperforms these sys-tems across the three languages.
For instance, onEnglish, we obtain an 8.5% gain in F-measure overMorfessor.
Our experiments also demonstrate thevalue of semantic information.
While the contribu-tion varies from 3% on Turkish to 11% on the En-glish dataset, it nevertheless improves performanceacross all the languages.2 Related WorkCurrently, top performing unsupervised morpholog-ical analyzers are based on the orthographic prop-erties of sub-word units (Creutz and Lagus, 2005;Creutz and Lagus, 2007; Poon et al., 2009; Sirts andGoldwater, 2013).
Adding semantic information tothese systems is not an easy task, as they operate atthe level of individual morphemes, rather than mor-phologically related words.The value of semantic information has beendemonstrated in earlier work on morphological anal-ysis.
Schone and Jurafsky (2000) employ an LSA-based similarity measure to identify morphologicalvariants from a list of orthographically close wordpairs.
The filtered pairs are then used to identifystems and affixes.
Based on similar intuition, Baroniet al.
(2002) design a method that integrates thesesources of information, captured as two word pairlists, ranked based on edit distance and mutual in-formation.
These lists are subsequently combinedusing a deterministic weighting function.In both of these algorithms, orthographic related-ness is based on simple deterministic rules.
There-fore, semantic relatedness plays an essential role inthe success of these methods.
However, these al-gorithms do not capture distributional properties ofmorphemes that are critical to the success of currentstate-of-the-art algorithms.
In contrast, we utilizea single statistical framework that seamlessly com-bines both sources of information.
Moreover, it al-lows us to incorporate a wide range of additionalfeatures.Our work also relates to the log-linear model formorphological segmentation developed by Poon etal.
(2009).
They propose a joint model over allwords (observations) and their segmentations (hid-den), using morphemes and their contexts (charac-ter n-grams) for the features.
Since the space of allpossible segmentation sets is huge, learning and in-ference are quite involved.
They use techniques likeContrastive Estimation, sampling and simulated an-nealing.
In contrast, our formulation does not re-sult in such a large search space.
For each word,the number of parent candidates is bounded by itslength multiplied by the number of possible trans-formations.
Therefore, Contrastive Estimation canbe implemented via enumeration, and does not re-quire sampling.
Moreover, operating at the level ofwords (rather than morphemes) enables us to incor-porate semantic and word-level features.Most recently, work by Sirts and Goldwater(2013) uses Adaptor Grammars for minimally su-pervised segmentation.
By defining a morphologicalgrammar consisting of zero or more prefixes, stemsand suffixes, they induce segmentations over wordsin both unsupervised and semi-supervised settings.While their model (AGMorph) builds up a word bycombining morphemes in the form of a parse tree,we operate at the word level and build up the finalword via intermediate words in the chain.In other related work, Dreyer and Eisner (2011)tackle the problem of recovering morphologicalparadigms and inflectional principles.
They usea Bayesian generative model with a log-linearframework, using expressive features, over pairs ofstrings.
Their work, however, handles a differenttask from ours and requires a small amount of an-notated data to seed the model.In this work, we make use of semantic infor-158mation to help morphological analysis.
Lee et al.
(2011) present a model that takes advantage of syn-tactic context to perform better morphological seg-mentation.
Stallard et al.
(2012) improve on this ap-proach using the technique of Maximum Marginaldecoding to reduce noise.
Their best system con-siders entire sentences, while our approach (and themorphological analyzers described above) operatesat the vocabulary level without regarding sentencecontext.
Hence, though their work is not directlycomparable to ours, it presents an interesting orthog-onal view to the problem.3 Model3.1 Definitions and FrameworkWe use morphological chains to model words in thelanguage.
A morphological chain is a short sequenceof words that starts from the base word and ends upin a morphological variant.
Each node in the chainis, by assumption, a valid word.
We refer to the wordthat is morphologically changed as the parent wordand its morphological variant as the child word.
Aword that does not have any morphological parent isa base word (e.g., words like play, chat, run).2Words in a chain (other than the base word) arecreated from their parents by adding morphemes(prefixes, suffixes, or other words).
For example,a morphological chain that ends up in the word in-ternationally could be nation ?
national ?
inter-national ?
internationally.
The base word for thischain is nation.
Note that the same word can belongto multiple morphological chains.
For example, theword national appears also as part of another chainthat ends up in nationalize.
These chains are treatedseparately but with shared statistical support for thecommon parts.
For this reason, our model breaksmorphological chains into possible parent-child re-lations such as (nation, national ).We use a log-linear model for predicting parent-child pairs.
A log-linear model allows an easy, effi-cient way of incorporating several different featurespertaining to parent-child relations.
In our case, weleverage both orthographic and semantic patterns toencode representative features.2We distinguish base words from morphological roots whichdo not strictly speaking have to be valid words in the language.Segment Cosine Similarityp 0.095pl -0.037pla -0.041play 0.580playe 0.000player 1.000Table 1: Cosine similarities between word vectors ofvarious segments of the word player and the vectorof player.A log-linear model consists of a set of featuresrepresented by a feature vector ?
: W ?
Z ?
Rdand a corresponding weight vector ?
?
Rd.
Here,Wis a set of words and Z is the set of candidates forwords inW , that includes the parents as well as theirtypes.
Specifically, a candidate is a (parent, type)pair, where the type variable keeps track of the typeof morphological change (or the lack thereof if thereis no parent) as we go from the parent to the child.In our experiments, Z is obtained by collecting to-gether all sub-words created by splitting observedwords in W at all different points.
For instance, ifwe take the word cars, the candidates obtained bysplitting would include (car, Suffix), (ca, Suffix), (c,Suffix), (ars, Prefix), (rs, Prefix) and (s, Prefix).Note that the parent may undergo changes as itis joined with the affix and thus, there are morechoices for the parent than just the ones obtained bysplitting.
Hence, to the set of candidates, we alsoadd modified sub-words where transformations in-clude character repetition (plan ?
planning), dele-tion (decide ?
deciding) or replacement (carry ?carried ).3 Following the above example for theword cars, we get candidates like (cat, Modify) and(cart, Delete).
Each word also has a stop candidate(-, Stop), which is equivalent to considering it as abase word with no parent.Let us define the probability of a particular word-candidate pair (w ?
W, z ?
Z) as P (w, z) ?e???(w,z).
The conditional probability of a candidate3We found that restricting the set of parents to sub-wordsthat are at least half the length of the original word helped im-prove the performance of the system.159z given a word w is thenP (z|w) = e???(w,z)?z?
?C(w) e???(w,z?)
, z ?
C(w)where C(w) ?
Z refers to the set of possible candi-dates (parents and their types) for the word w ?
W .In order to generate a possible ancestral chain fora word, we recursively predict parents until the wordis predicted to be a base word.
In our model, thesechoices are included in the set of candidates for thespecific word, and their likelihood is controlled bythe type related features.
Details of these and otherfeatures are given in section 3.2.3.2 FeaturesThis section provides an overview of the featuresused in our model.
The features are defined for agiven word w, parent p and type t (recall that a can-didate z ?
Z is the pair (p, t)).
For computingsome of these features, we use an unannotated listof words with frequencies (details in section 4).
Ta-ble 2 provides a summary of the features.Semantic Similarity We hypothesize that mor-phologically related words exhibit semantic similar-ity.
To this end, we introduce a feature that mea-sures cosine similarity between the word vectors ofthe word (~w) and the parent (~p).
These word vectorsare learned from co-occurrence patterns from a largecorpus4 (see section 4 for details).To validate this measure, we computed the cosinesimilarity between words and their morphologicalparents from the CELEX2 database (Baayen et al.,1995).
On average, the resulting word-parent sim-ilarity score is 0.351, compared to 0.116 for ran-domly chosen word-parent combinations.5Affixes A distinctive feature of affixes is their fre-quent occurrence in multiple words.
To capturethis pattern, we automatically generate a list of fre-quently occurring candidate affixes.
These candi-dates are collected by considering the string differ-ence between a word and its parent candidates whichappear in the word list.
For example, for the wordpaints, possible suffixes include -s derived from the4For strings which do not have a vector learnt from the cor-pus, we set the cosine value to be -0.5.5The cosine values range from around -0.1 to 0.7 usually.Language Top suffixesEnglish -s, -?s, -d, -ed, -ing, -?, -s?, -ly, -er, -eTurkish -n, -i, -lar, -dir, -a, -den, -de, -in, -leri, -lerArabic -p, -A, -F, -y, -t, -AF, -h, -hA, -yp, -AtTable 3: Top ten suffixes in automatically producedsuffix lists.parent paint, -ts from the parent pain and -ints fromthe word pa.
Similarly, we compile a list of poten-tial prefixes.
These two lists are sorted by their fre-quency and thresholded.
For each affix in the lists,we have a corresponding indicator variable.
For un-seen affixes, we use an UNK (unknown) indicator.These automatically constructed lists act as aproxy for the gold affixes.
In English, choosing thetop 100 suffixes in this manner gives us 43 correctsuffixes (compared against gold suffixes).
Table 3gives some examples of suffixes generated this way.Affix Correlation While the previous feature con-siders one affix assignment at a time, there is aknown correlation between affixes attached to thesame stem.
For instance, in English, verbs that canbe modified by the suffix -ing, can also take therelated suffix -ed.
Therefore, we introduce a fea-ture that measures, whether for a given affix andparent, we also observe in the wordlist the sameparent modified by its related affix.
For exam-ple, for the pair (walking, walk), the feature in-stance AffixCorr(ing, ed) is set to 1, because theword walked is in the WordList.To construct pairs of related affixes, we computethe correlation between pairs in auto-generated affixlist described previously.
This correlation is propor-tional to the number of stems the two affixes share.For English, examples of such pairs include (inter-,re-), (under-, over-), (-ly, -s), and (-er, -ing).Presence in Wordlist We want to bias the modelto select parents that constitute valid words.6 More-over, we would like to take into account the fre-quency of the parent words.
We encode this infor-mation as the logarithm of their word counts in thewordlist (WordFreq).
For parents not in the wordlist,we set a binary OutOfVocab feature to 1.6This is not an absolute requirement in the model.160Feature type Word (w) Candidate (p,t) Feature ValueCosine painter (paint, Suffix) ~w ?
~p 0.58Affix painter (paint, Suffix) suffix=er 1Affix Correlation walking (walk, Suffix) AffixCorr(ing, ed) 1Wordlist painter (paint, Suffix) WordFreq 8.73OutOfVocab 0Transformations planning (plan, Repeat) type=Repeat ?
chars=(n,-) 1deciding (decide, Delete) type=Delete ?
chars=(e,-) 1carried (carry, Modify) type=Modify ?
chars=(y,i) 1Stop painter (-, Stop) begin=pa 1end=er 10.5 < MaxCos < 0.6 1length=7 1Table 2: Example of various types of features used in the model.
~w and ~p are the word vectors for the wordand parent, respectively.Transformations We also support transforma-tions to enable non-concatenative morphology.
Evenin English, which is mostly concatenative, suchtransformations are frequent.
We consider threekinds of transformations previously considered inthe literature (Goldwater and Johnson, 2004):?
repetition of the last character in the parent(ex.
plan ?
planning)?
deletion of the last character in the parent(ex.
decide ?
deciding)?
modification of the last character of the parent(ex.
carry ?
carried )We add features that are the cartesian prod-uct of the type of transformation and the charac-ter(s) involved.
For instance, for the parent-childpair (believe, believing), the feature type=Delete ?chars=(e,-) will be activated, while the rest of thetransformational features will be 0.Stop Condition Finally, we introduce featuresthat aim to identify base words which do not havea parent.
The features include the length of theword, and the starting and ending character uni-grams and bigrams.
In addition, we include a featurethat records the highest cosine similarity betweenthe word and any of its candidate parents.
This fea-ture will help, for example, to identify paint as abase word, instead of choosing pain as its parent.3.3 LearningWe learn the log-linear model in an unsupervisedmanner without explicit feedback about correct mor-phological segmentations.
We assume that we havean unannotated wordlist D for this purpose.
A typ-ical approach to learning such a model would be tomaximize the likelihood of all the observed wordsin D over the space of all strings constructible inthe alphabet, ?
?, by marginalizing over the hiddencandidates.7 In other words, we could use the EM-algorithm to maximizeL(?
;D) =?w?
?DP (w?)=?w??D?z?C(w?
)P (w?, z)=?w?
?D[ ?z?C(w?)
e???(w?,z)?w???
?z?C(w) e???
(w,z)](1)However, maximizing L(?
;D) is problematic sinceapproximate methods would be needed to sum over??
in order to calculate the normalization term in(1).
Moreover, we would like to encourage themodel to emphasize relevant parent-child pairs8 outof a smaller set of alternatives rather than those per-taining to all the words.7We also tried maximizing instead of marginalizing, but themodel gets stuck in one of the numerous local optima.8In other words, assign higher probability mass.161We employ Contrastive Estimation (Smith andEisner, 2005) and replace the normalization term bya sum over the neighbors of each word.
For eachword in the language, we create neighboring stringsin two sets.
For the first set, we transpose a singlepair of adjacent characters of the word.
We performthis transposition over the first k or the last k charac-ters of the word.9 For the second set, we transposetwo pairs of characters simultaneously ?
one fromthe first k characters and one from the last k.The combined set of artificially constructed wordsrepresents the events that we wish to move probabil-ity mass away from in favor of the actually observedwords.
The neighbors facilitate the learning of goodweights for the affix features by providing the re-quired contrast (at both ends of the words) to theactual words in the vocabulary.
A remaining con-cern is that the model may not distinguish any arbi-trary substring from a good suffix/prefix.
For exam-ple, -ng appears in all the words that end with -ing,and could be considered a valid suffix.
We includeother features to help make this distinction.
Specifi-cally, we include features such as word vector simi-larity and the presence of the parent in the observedwordlist.
For example, in the word painting, the par-ent candidate paint is likely to occur and also has ahigh cosine similarity with painting in terms of theirword vectors.
In contrast, painti does not.Given the list of words and their neighborhoods,we define the contrastive likelihood as follows:(2)LCE(?,D)=?w?
?D[ ?z?C(w?)
e???(w?,z)?w?N(w?
)?z?C(w) e???
(w,z)]where N(w?)
is the neighborhood of w?.
This like-lihood is much easier to evaluate and optimize.After adding in a standard regularization term, wemaximize the following log likelihood objective:(3)?w?
?D??log?z?C(w?)e???(w?,z)?
log?w?N(w?)?z?C(w)e???(w,z)???
?||?||29The performance increases with increasing k until k = 5,after which no gains were observed.The corresponding gradient can be derived as:?LCE(?;D)??j=?w??D[?z?C(w?)
?j(w?, z) ?
e???(w?,z)?z?C(w?)
e???(w?,z)??w?N(w?
)?z?C(w) ?j(w, z) ?
e???(w,z)?w?N(w?
)?z?C(w) e???(w,z)]?
2?
?j(4)We use LBFGS-B (Byrd et al., 1995) to optimizeLCE(?
;D) with gradients given above.3.4 PredictionGiven a test word, we predict a morphological chainin a greedy step by step fashion.
In each step, we usethe learnt weights to predict the best parent for thecurrent word (from the set of candidates), or chooseto stop and declare the current word as a base word ifthe stop case has the highest score.
Once we have thechain, we can derive a morphological segmentationby inserting a segmentation point (into the test word)appropriately for each edge in the chain.Algorithms 1 and 2 provide details on the predic-tion procedure.
In both algorithms, type refers tothe type of modification (or lack of) that the parentundergoes: Prefix/Suffix addition, types of transfor-mation like repetition, deletion, modification, or theStop case.Algorithm 1 Procedure to predict a parent for aword1: procedure PREDICT(word)2: candidates?
CANDIDATES(word)3: bestScore?
04: bestCand?
(?, STOP )5: for cand ?
candidates do6: features?
FEATURES(word, cand)7: score?
MODELSCORE(features)8: if score > bestScore then9: bestScore?
score10: bestCand?
cand11: return bestCand162Algorithm 2 Procedure to predict a morphologicalchain1: procedure GETCHAIN(word)2: candidate?
PREDICT(word)3: parent, type?
candidate4: if type = STOP then return[(word, STOP)]5: return GETCHAIN(parent)+[(parent, type)]Lang Train Test WordVec(# words) (# words) (# words)English MC-10 MC-05:10 Wikipedia(878K) (2218) (129M)Turkish MC-10 MC-05:10 BOUN(617K) (2534) (361M)Arabic Gigaword ATB Gigaword(3.83M) (119K) (1.22G)Table 4: Data corpora and statistics.
MC-10 = Mor-phoChallenge 201010, MC-05:10 = MorphoChal-lenges 2005-10 (aggregated), BOUN = BOUN cor-pus (Sak et al., 2008), Gigaword = Arabic Gigawordcorpus (Parker et al., 2011), ATB = Arabic Tree-bank (Maamouri et al., 2003)4 Experimental SetupData We run experiments on three different lan-guages: English, Turkish and Arabic.
For each lan-guage, we utilize corpora for training, testing andlearning word vectors.
The training data consists ofan unannotated wordlist with frequency information,while the test data is a set of gold morphologicalsegmentations.
For the word vectors, we train theword2vec tool (Mikolov et al., 2013) on large textcorpora and obtain 200-dimensional vectors for allthree languages.
Table 4 provides information abouteach dataset.Evaluation measure We test our model on thetask of morphological segmentation.
We evalu-ate performance on individual segmentation points,which is standard for this task (Virpioja et al., 2011).We compare predicted segmentations against thegold test data for each language and report overallPrecision, Recall and F-1 scores calculated across10http://research.ics.aalto.fi/events/morphochallenge/all segmentation points in the data.
As is commonin unsupervised segmentation (Poon et al., 2009;Sirts and Goldwater, 2013), we included the testwords (without their segmentations) with the train-ing words during parameter learning.Baselines We compare our model with five othersystems: Morfessor Baseline (Morf-Base), Morfes-sor CatMap (Morf-Cat), AGMorph, the Lee Seg-menter and the system of Poon et al.
(2009).
Mor-fessor has achieved excellent performance on theMorphoChallenge dataset, and is widely used forperforming unsupervised morphological analysis onvarious languages, even in fairly recent work (Lu-ong et al., 2013).
In our experiments, we employtwo variants of the system because their relative per-formance varies across languages.
We use publiclyavailable implementations of these variants (Virpi-oja et al., 2013; Creutz and Lagus, 2005).
Weperform several runs with various parameters, andchoose the run with the best performance on eachlanguage.We evaluate AGMorph by directly obtaining theposterior grammars from the authors.11 We showresults for the Compounding grammar, which wefind has the best average performance over the lan-guages.
The Lee Segmenter (Lee et al., 2011), im-proved upon by using Maximum Marginal decodingin Stallard et al.
(2012), has achieved excellent per-formance on the Arabic (ATB) dataset.
We performcomparison experiments with the model 2 (M2) ofthe segmenter, which employs latent POS tags, anddoes not require sentence context which is not avail-able for other languages in the dataset.
We obtainedthe code for the system, and run it on our Englishand Turkish datasets.12 We do not have access to animplementation of Poon et al?s system; hence, wedirectly report scores from their paper on the ATBdataset and test our model on the same data.5 ResultsTable 5 details the performance of the various mod-els on the segmentation task.
We can see thatour method outperforms both variants of Morfessor,11The grammars were trained using data we provided tothem.12We report numbers on Arabic directly from their paper.163Figure 1: Model performance vs data size obtainedby frequency thresholdingwith an absolute gain of 8.5%, 5.1% and 5% in F-score on English, Turkish and Arabic, respectively.On Arabic, we obtain a 2.2% absolute improvementover Poon et al.
?s model.
AGMorph doesn?t seg-ment better than Morfessor on English and Arabicbut does very well on Turkish (60.9% F1 comparedto our model?s 61.2%).
This could be due to the factthat the Compounding grammar is well suited to theagglutinative morphology in Turkish and hence pro-vides more gains than for English and Arabic.
TheLee Segmenter (M2) performs the best on Arabic(82% F1), but lags behind on English and Turkish.This result is consistent with the fact that the systemwas optimized for Arabic.The table also demonstrates the importance of theadded semantic information in our model.
For allthree languages, having the features that utilize co-sine similarity provides a significant boost in perfor-mance.
We also see that the transformation featuresand affix correlation features play a role in improv-ing the results, although a less important one.Next, we study the effect of data quality on theprediction of the algorithm.
A training set oftencontains misspellings, abbreviations and truncatedwords.
Thresholding based on frequency is com-monly used to reduce this noise.
Figure 1 shows theperformance of the algorithm as a function of thedata size obtained at various degrees of threshold-ing.
We note that the performance of the model onall three languages remains quite stable from aboutLang Method Prec Recall F-1EnglishMorf-Base 0.740 0.623 0.677Morf-Cat 0.673 0.587 0.627AGMorph 0.696 0.604 0.647Lee (M2) 0.825 0.525 0.642Model -C 0.555 0.792 0.653Model -T 0.831 0.664 0.738Model -A 0.810 0.713 0.758Full model 0.807 0.722 0.762TurkishMorf-Base 0.827 0.362 0.504Morf-Cat 0.522 0.607 0.561AGMorph 0.878 0.466 0.609Lee (M2) 0.787 0.355 0.489Model -C 0.516 0.652 0.576Model -T 0.665 0.521 0.584Model -A 0.668 0.543 0.599Full model 0.743 0.520 0.612ArabicMorf-Base 0.807 0.204 0.326Morf-Cat 0.774 0.726 0.749AGMorph 0.672 0.761 0.713Poon et al.
0.885 0.692 0.777Lee (M2) - - 0.820Model -C 0.626 0.912 0.743Model -T 0.774 0.807 0.790Model -A 0.775 0.808 0.791Full model 0.770 0.831 0.799Table 5: Results on unsupervised morphologicalsegmentation; scores are calculated across all seg-mentation points in the test data.
Baselines arein italics.
-C=without cosine features, -T=withouttransformation features, -A=without affix correla-tion features.
Numbers on Arabic for Poon et al.
andLee (M2) are reported directly from their papers.1000 to 10000 training words, after which the devia-tions are more apparent.
The plot also demonstratesthat the model works well even with a small amountof quality data (?3000 most frequent words).Error analysis We look at a random subset of 50incorrectly segmented words13 in the model?s outputfor each language.
Table 7 gives a breakup of errorsin all 3 languages due to over or under-segmentation.Table 6 provides examples of correct and incorrectsegmentations predicted by our model.13Words with at least one segmentation point incorrect164Language Correct Segmentations Incorrect SegmentationsWord Segmentation Word Predicted CorrectEnglishsalvoes salvo-es contempt con-tempt contemptnegotiations negotiat-ion-s sterilizing steriliz-ing steril-iz-ingtelephotograph tele-photo-graph desolating desolating desolat-ingunequivocally un-equivocal-ly storerooms storeroom-s store-room-scarsickness?s car-sick-ness-?s tattlers tattler-s tattl-er-sTurkishmoderni modern-i mektuplas?malar mektuplas?ma-lar mektup-las?-ma-larteknolojideki teknoloji-de-ki gelecektiniz gelecek-tiniz gel-ecek-ti-nizburas?yd?
bura-s?-yd?
aynalardan ayna-lar-da-n ayna-lar-danc?izgisine c?iz-gi-si-ne uyudug?unuzu uyudu-g?u-nuzu uyu-dug?-unuz-udeg?is?iklikte deg?is?ik-lik-te dirseg?e dirseg?e dirseg?-eArabicsy$Ark s-y-$Ark wryfAldw w-ry-fAldw w-ryfAldwnyqwsyA nyqwsyA bHlwlhA b-Hlwl-h-A b-Hlwl-hAAlmTrwHp Al-mTrwH-p jnwby jnwb-y jnwbyytEAmlwA y-tEAml-wA wbAyrn w-bAyr-n w-bAyrnlAtnZr lA-t-nZr rknyp rknyp rkny-pTable 6: Examples of correct and incorrect segmentations produced by our model on the three languages.Correct segmentations are taken directly from gold MorphoChallenge data.Lang Over-segment Under-segmentEnglish 10% 86%Turkish 12% 78 %Arabic 60% 40%Table 7: Types of errors in analysis of 50 randomlysampled incorrect segmentations for each language.The remaining errors are due to incorrect placementof segmentation points.In English, most errors are due to under-segmentation of a word.
We find that around 60% oferrors are due to roots that undergo transformationswhile morphing into a variant (see table 6 for exam-ples).
Errors in Turkish are also mostly due to under-segmentation.
On further investigation, we find thatmost such errors (58% of the 78%) are due to parentwords either not in vocabulary or having a very lowword count (?
10).
In contrast, we observe a ma-jority of over-segmentation errors in Arabic (60%).This is likely because of Arabic having more sin-gle character affixes than the other languages.
Wefind that 56% of errors in Arabic involve a single-character affix, which is much higher than the 24.6%that involve a two-letter affix.
In contrast, 25% of er-rors in English are due to single character affixes ?around the same number as the 24% of errors due totwo-letter affixes.Since our model is an unsupervised one, we makeseveral simplifying assumptions to keep the candi-date set size manageable for learning.
For instance,we do not explicitly model infixes, since we selectparent candidates by only modifying the ends of aword.
Also, the root-template morphology of Ara-bic, a Semitic language, presents a complexity wedo not directly handle.
For instance, words in Ara-bic can be formed using specific patterns (knownas binyanim) (ex.
nZr ?
yntZr).
However, ongoing through the errors, we find that only 14%are due to these binyanim patterns not being cap-tured.14 Adding in transformation rules to capturethese types of language-specific patterns can help in-crease both chain and segmentation accuracy.Analysis of learned distributions To investigatehow decisive the learnt model is, we examine thefinal probability distribution P (z|w) of parent can-didates for the words in the English wordlist.
Weobserve that the probability of the best candidate(maxzP (z|w)), averaged over all words, is 0.77.We also find that the average entropy of the distri-14This might be due to the fact that the gold segmentationsalso do not capture such patterns.
For example, the gold seg-mentation for yntZrwn is given as y-ntZr-wn, even though ntZris not a valid root.165Figure 2: Comparison of gold and predicted fre-quency distributions of the top 15 affixes for Englishbutions is 0.65, which is quite low considering thatthe average number of candidates is 10.76 per word,which would result in a max possible entropy ofaround 2.37 if the distributions were uniform.
Thisdemonstrates that the model tends to prefer a singleparent for every word,15 which is exactly the behav-ior we want.Affix analysis We also analyze the various affixesproduced by the model, and compare with the goldaffixes.
Particularly, we plot the frequency distri-butions of the affixes16 obtained from the gold and15Note that the candidate probability distribution may havemore than a single peak in some cases.16To conserve space, we only show the distribution of suf-fixes here, but we observe a similar trend for prefixes.predicted segmentations for the English test data infigure 2.From the figure, we can see that our model learnsto identify good affixes for the given language.
Sev-eral of the top affixes predicted are also present inthe gold list, and we also observe similarities in thefrequency distributions.6 ConclusionIn this work, we have proposed a discriminativemodel for unsupervised morphological segmenta-tion that seamlessly integrates orthographic and se-mantic properties of words.
We use morpholog-ical chains to model the word formation processand show how to employ the flexibility of log-linearmodels to incorporate both morpheme and word-level features, while handling transformations ofparent words.
Our model consistently equals or out-performs five state-of-the-art systems on Arabic, En-glish and Turkish.
Future directions of work in-clude using better neighborhood functions for con-trastive estimation, exploring other views of the datathat could be incorporated, examining better predic-tion schemes and employing morphological chainsin other applications in NLP.AcknowledgementsWe thank Kairit Sirts and Yoong Keok Lee forhelping run experiments with their unsupervisedmorphological analyzers, and Yonatan Belinkov forhelping with error analysis in Arabic.
We alsothank the anonymous TACL reviewers and mem-bers of MIT?s NLP group for their insightful com-ments and suggestions.
This work was supported bythe Intelligence Advanced Research Projects Activ-ity (IARPA) via Department of Defense US ArmyResearch Laboratory contract number W911NF-12-C-0013.
The U.S. Government is authorized toreproduce and distribute reprints for Governmen-tal purposes notwithstanding any copyright annota-tion thereon.
The views and conclusions containedherein are those of the authors and should not beinterpreted as necessarily representing the officialpolicies or endorsements, either expressed or im-plied, of IARPA, DoD/ARL, or the U.S. Govern-ment.166ReferencesR Baayen, R Piepenbrock, and L Gulikers.
1995.CELEX2 LDC96L14.
Philadelphia: Linguistic DataConsortium.Marco Baroni, Johannes Matiasek, and Harald Trost.2002.
Unsupervised discovery of morphologically re-lated words based on orthographic and semantic simi-larity.
CoRR, cs.CL/0205006.Richard H Byrd, Peihuang Lu, Jorge Nocedal, and CiyouZhu.
1995.
A limited memory algorithm for boundconstrained optimization.
SIAM Journal on ScientificComputing, 16(5):1190?1208.Mathias Creutz and Krista Lagus.
2005.
Inducingthe morphological lexicon of a natural language fromunannotated text.
In Proceedings of the Internationaland Interdisciplinary Conference on Adaptive Knowl-edge Representation and Reasoning (AKRR), pages106?113.Mathias Creutz and Krista Lagus.
2007.
Unsuper-vised models for morpheme segmentation and mor-phology learning.
ACM Trans.
Speech Lang.
Process.,4(1):3:1?3:34, February.Markus Dreyer and Jason Eisner.
2011.
Discover-ing morphological paradigms from plain text usinga dirichlet process mixture model.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing, pages 616?627.
Association forComputational Linguistics.Sharon Goldwater and Mark Johnson.
2004.
Priors inbayesian learning of phonological rules.
In Proceed-ings of the 7th Meeting of the ACL Special InterestGroup in Computational Phonology: Current Themesin Computational Phonology and Morphology, SIG-MorPhon ?04, pages 35?42, Stroudsburg, PA, USA.Association for Computational Linguistics.Yoong Keok Lee, Aria Haghighi, and Regina Barzi-lay.
2011.
Modeling syntactic context improvesmorphological segmentation.
In Proceedings of theFifteenth Conference on Computational Natural Lan-guage Learning, CoNLL ?11, pages 1?9, Stroudsburg,PA, USA.
Association for Computational Linguistics.Minh-Thang Luong, Richard Socher, and Christopher D.Manning.
2013.
Better word representations with re-cursive neural networks for morphology.
In CoNLL,Sofia, Bulgaria.Mohamed Maamouri, Ann Bies, Hubert Jin, and TimBuckwalter.
2003.
Arabic Treebank: Part 1 v 2.0LDC2003T06.
Philadelphia: Linguistic Data Consor-tium.Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado,and Jeffrey Dean.
2013.
Distributed representations ofwords and phrases and their compositionality.
CoRR,abs/1310.4546.Robert Parker, David Graff, Ke Chen, Junbo Kong, andKazuaki Maeda.
2011.
Arabic Gigaword fifth editionLDC2011T11.
Philadelphia: Linguistic Data Consor-tium.Hoifung Poon, Colin Cherry, and Kristina Toutanova.2009.
Unsupervised morphological segmentation withlog-linear models.
In Proceedings of Human Lan-guage Technologies: The 2009 Annual Conference ofthe North American Chapter of the Association forComputational Linguistics, NAACL ?09, pages 209?217, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.Has?im Sak, Tunga Gu?ngo?r, and Murat Sarac?lar.
2008.Turkish language resources: Morphological parser,morphological disambiguator and web corpus.
In Ad-vances in natural language processing, pages 417?427.
Springer.Patrick Schone and Daniel Jurafsky.
2000.
Knowledge-free induction of morphology using latent semanticanalysis.
In Proceedings of the 2nd Workshop onLearning Language in Logic and the 4th Conferenceon Computational Natural Language Learning - Vol-ume 7, ConLL ?00, pages 67?72, Stroudsburg, PA,USA.
Association for Computational Linguistics.Kairit Sirts and Sharon Goldwater.
2013.
Minimally-supervised morphological segmentation using adaptorgrammars.
TACL, 1:255?266.Noah A. Smith and Jason Eisner.
2005.
Contrastiveestimation: Training log-linear models on unlabeleddata.
In Proceedings of the 43rd Annual Meeting onAssociation for Computational Linguistics, ACL ?05,pages 354?362, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Benjamin Snyder and Regina Barzilay.
2008.
Unsuper-vised multilingual learning for morphological segmen-tation.
In The Annual Conference of the Associationfor Computational Linguistics.David Stallard, Jacob Devlin, Michael Kayser,Yoong Keok Lee, and Regina Barzilay.
2012.Unsupervised morphology rivals supervised mor-phology for arabic mt.
In Proceedings of the 50thAnnual Meeting of the Association for ComputationalLinguistics: Short Papers-Volume 2, pages 322?327.Association for Computational Linguistics.Sami Virpioja, Ville T. Turunen, Sebastian Spiegler, Os-kar Kohonen, and Mikko Kurimo.
2011.
Empiricalcomparison of evaluation methods for unsupervisedlearning of morphology.
TAL, 52(2):45?90.Sami Virpioja, Peter Smit, Stig-Arne Gro?nroos, andMikko Kurimo.
2013.
Morfessor 2.0: Python imple-mentation and extensions for Morfessor Baseline.
Re-port in Aalto University publication series SCIENCE+ TECHNOLOGY, Department of Signal Processingand Acoustics, Aalto University, Helsinki, Finland.167168
