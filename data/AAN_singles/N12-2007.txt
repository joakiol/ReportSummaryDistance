Proceedings of the NAACL HLT 2012 Student Research Workshop, pages 35?40,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsDomain-Specific Semantic Relatedness From Wikipedia:Can A Course Be Transferred?Beibei YangUniversity of Massachusetts LowellLowell, MA 01854byang1@cs.uml.eduJesse M. HeinesUniversity of Massachusetts LowellLowell, MA 01854heines@cs.uml.eduAbstractSemantic relatedness, or its inverse, seman-tic distance, measures the degree of close-ness between two pieces of text determined bytheir meaning.
Related work typically mea-sures semantics based on a sparse knowledgebase such as WordNet1 or CYC that requiresintensive manual efforts to build and main-tain.
Other work is based on the Brown cor-pus, or more recently, Wikipedia.
Wikipedia-based measures, however, typically do nottake into account the rapid growth of that re-source, which exponentially increases the timeto prepare and query the knowledge base.
Fur-thermore, the generalized knowledge domainmay be difficult to adapt to a specific domain.To address these problems, this paper pro-poses a domain-specific semantic relatednessmeasure based on part of Wikipedia that ana-lyzes course descriptions to suggest whether acourse can be transferred from one institutionto another.
We show that our results performwell when compared to previous work.1 IntroductionMany NLP techniques have been adapted to the ed-ucation field for building systems such as automatedscoring, intelligent tutoring, and learner cognition.Few, however, address the identification of transfercourse equivalencies.
A recent study by the Na-tional Association for College Admission Counsel-ing2 reveals that 1/3 of US college students trans-1http://wordnet.princeton.edu/2Special Report on the Transfer Admission Process:http://www.nacacnet.org/research/research-data/Documents/TransferFactSheet.pdffer to another institution.
Correspondingly, Univer-sity of Massachusetts Lowell (UML) accepts hun-dreds of transfer students every year.
Each trans-fer course must be evaluated for credits by manuallycomparing its course description to courses offeredat UML.
This process is labor-intensive and highlyinefficient.
There is a publicly available coursetransfer dictionary which lists course numbers fromhundreds of institutions and their equivalent coursesat UML, but the data set is sparse, non-uniform,and always out of date.
External institutions cancelcourses, change course numbers, etc., and such in-formation is virtually impossible to keep up to datein the transfer dictionary.
Furthermore, the transferdictionary does not list course descriptions.
Fromour experience, course descriptions change over theyears even when course numbers do not, and this ofcourse affect equivalencies.This work proposes a domain-specific semanticrelatedness measure using Wikipedia that automat-ically suggests whether two courses from differentinstitutions are equivalent by analyzing their coursedescriptions.
The goal is to assist transfer coordina-tors by suggesting equivalent courses within a rea-sonable amount of time on a standard laptop system.Our model is a mapping function: f : (C1, C2) ?n, n ?
[0, 1], where C1 is a Computer Science (CS)course from an external institution, and C2 is a CScourse offered at UML.
Output n is the semantic re-latedness score, where a bigger value indicates C1and C2 are more related.
Each course description isa short text passage:?
C1: [Analysis of Algorithms] Discusses basic methodsfor designing and analyzing efficient algorithms empha-35sizing methods used in practice.
Topics include sorting,searching, dynamic programming, greedy algorithms, ad-vanced data structures, graph algorithms (shortest path,spanning trees, tree traversals), matrix operations, stringmatching, NP completeness.?
C2: [Computing III] Object-oriented programming.Classes, methods, polymorphism, inheritance.
Object-oriented design.
C++.
UNIX.
Ethical and social issues.# nodes: 25WordNet  [Root: synset(??technology??
), #depth: 2]# nodes: 3583Wikipedia  [Centroid: ??Category:Technology?
?, #steps: 2]Fragments of WordNet and Wikipedia TaxonomiesFigure 1.
Fragments of WordNet 3.0 (top) andEnglish Wikipedia of 2011/7 (bottom) taxonomies.The root/centroid node is shown in red.1992 1996 2000 2004 2008 2012Year5000001000000150000020000002500000300000035000004000000Article/SynsetcountGrowth of English Wikipedia and WordNetArticles in WikipediaSynsets in WordNetFigure 2.
Growth of Wikipedia and WordNetWe choose Wikipedia as the knowledge basedue to its rich contents (Figure 1) and continu-ously coalescent growth (Bounova, 2011).
AlthoughWikipedia was launched 10 years later, it grew muchfaster than WordNet over the last decade (Figure 2).The contributions of this paper are twofold.
First,we address the problem of domain-specific semanticrelatedness using Wikipedia.
We propose a methodto suggest course equivalencies by computing se-mantic relatedness among Computer Science coursedescriptions.
Our approach can be easily modifiedfor other majors and even other languages.
Second,we evaluate the correlation of our approach and a hu-man judgment data set we built.
Both accuracy andcorrelation indicate that our approach outperformsprevious work.2 Related ResearchSemantic relatedness has been used in applicationssuch as word sense disambiguation, named entitydisambiguation, text summarization and annotation,lexical selection, automatic spelling correction, andtext structure evaluation.
WordNet is commonlyused as a lexicographic resource to calculate se-mantic relatedness (Budanitsky and Hirst, 2006).A WordNet-based method uses one or more edge-counting techniques in theWordNet taxonomy (Lea-cock and Chodorow, 1998; Hirst and St-Onge,1998).
The relatedness of two concept nodes is afunction of the minimum number of hops betweenthem.Some related work calculates co-occurrence onone or more large corpora to deduce semantic re-latedness (Sahami and Heilman, 2006; Cilibrasi andVitanyi, 2007).
Two words are likely to be related ifthey co-occur within similar contexts (Lin, 1998).Others combine lexicographic resources with cor-pus statistics (Jiang and Conrath, 1997).
It has beenshown that these composite methods generally out-perform lexicographic resource- and corpus- basedmethods (Budanitsky and Hirst, 2006; Curran, 2004;Mohammad, 2008).
Li et al (2006) propose a hybridmethod based on WordNet and the Brown corpus toincorporate semantic similarity between words, se-mantic similarity between sentences, and word ordersimilarity to measure the overall sentence similarity.Yang and Heines (2011) modify this work to suggesttransfer course equivalencies, but the experiment isbased on non-technical courses.
Due to theWordNetsparsity on technical terms, the experiment does notperform well on Computer Science courses.36In recent years, there has been increasing interestin applying Wikipedia and related resources to ques-tion answering (Buscaldi and Rosso, 2006), wordsense disambiguation (WSD) (Mihalcea and Cso-mai, 2007), name entity disambiguation (Ni et al,2010), ontology evaluation (Yu et al, 2007), seman-tic web (Wu, 2010), and computing semantic relat-edness (Ponzetto and Strube, 2007).
Ponzetto andStrube (2007) deduce semantic relatedness of wordsby modeling relations on the Wikipedia categorygraph.
Gabrilovich and Markovitch (2009) intro-duce the Explicit Semantic Analysis (ESA) modelwhich calculates TF-IDF (Manning et al, 2008) val-ues for every word in Wikipedia and further uses lo-cal linkage information to build a second-level se-mantic interpreter.Our approach is different from prior work onWikipedia.
While Mihalcea and Csomai (2007)use the annotation in the page title of a concept toperform WSD, our approach uses a page?s parentcategory as a cue to the correct sense.
Ponzettoand Strube (2007) limit their measurement to wordpairs, while our work focuses on text of any length.Gabrilovich and Markovitch (2009) computes TF-IDF statistics for every word and every documentof Wikipedia which is highly inefficient.
They alsoremove category pages and disambiguation pages.In contrast, our model is mainly based on the cate-gory taxonomy and the corpus statistics are limitedto metadata that are mostly available in Wikipedia.Furthermore, we compute concept relatedness ona domain-specific hierarchy that weighs both pathlengths and diversions from the topic.
The domain-specific hierarchy is much smaller than the entireWikipedia corpus.
As a result, our algorithm is moreefficient3 than previous work.3In our experiment, the average time needed to compareone pair of course descriptions ranged from 0.16 second (withpartial caching) to 1 minute (without caching) on a 2.6GhzQuad-Core PC.
The most time-consuming part before compar-ing courses was to index all the Wikipedia tables in a MySQLdatabase, which took overnight (same for ESA).
It only tookus 15 minutes to go through 19K pages to build a hierarchyof D = 4.
In contrast, ESA?s first level semantic interpreter(which tokenizes every Wikipedia page to compute TF-IDF)took 7 days to build over the same 19K pages.
Both imple-mentations were single-threaded, coded in Python, and testedover the English Wikipedia of July 2011.3 Proposed MethodOur method contains four modules.
Section 3.1 ex-plains how to construct a domain-specific hierarchyfromWikipedia.
Section 3.2 presents semantic relat-edness between concepts.
Section 3.3 describes thesteps to generate features from course descriptions.And section 3.4 evaluates course relatedness.3.1 Extract a Lexicographical HierarchyWhen a domain is specified (e.g., CS courses), westart from a generic Wikipedia category in this do-main, choose its parent as the root, and use a depth-limited search to recursively traverse each subcate-gory (including subpages) to build a lexicographicalhierarchy with depth D. For example, to find CScourse equivalencies, we built a hierarchy using theparent of ?Category:Computer science,?
i.e., ?Cat-egory:Applied sciences,?
as the root.
The genericcategory?s parent is chosen as the root to make surethe hierarchy not only covers the terms in this do-main, but also those in neighbor domains.
The hier-archy of ?Category:Applied sciences?
not only cov-ers Computer Science, but also related fields such asComputational Linguistics and Mathematics.Both the number of nodes and number of edgesin the hierarchy grow exponentially4 as the depthincreases.
Therefore, D need not be a big numberto cover most terms in the domain.
We have foundthe hierarchy speeds up the semantic measurementdramatically and covers almost all the words in thespecific domain.
In our experiment on CS courses(D=6), we eliminated over 71% of Wikipedia arti-cles,5 yet the hierarchy covered over 90% of CS ter-minologies mentioned in the course descriptions.3.2 Semantic Relatedness Between ConceptsSimilar to the work of Li et al (2006), the seman-tic relatedness between two Wikipedia concepts,6 t1and t2 in the hierarchy is defined as:f ?
(t1, t2) = e?
?p ?e?d ?
e?
?de?d + e?
?d(?, ?
?
[0, 1]), (1)where p is the shortest path between t1 and t2, andd is the depth of the lowest common hypernym of t14In the hierarchy we built with ?Category:Applied sciences?as the root, the number of edges grows from 177,955 at D=4 to494,039 at D=5 and 1,848,052 at D=6.5The hierarchy contains 1,534,267 unique articles, as op-posed to 5,329,186 articles in Wikipedia.6Each concept corresponds to a Wikipedia page.37and t2 in the hierarchy (Section 3.1).
This is differ-ent from related work on semantic relatedness fromWikipedia (Ponzetto and Strube, 2007) in that wenot only consider the shortest path (p) between twoconcepts but also their common distance (d) fromthe topic, which in turn emphasizes domain aware-ness.3.3 Generate Course Description FeaturesThe built-in redirection in Wikipedia is useful forspelling corrections because variations of a termredirect to the same page.
To generate features froma course description C, we start by generating n-grams (n ?
[1, 3]) from C. We then query the redi-rection data to fetch all pages that match any of then-grams.The identified pages are still sparse.
We thereforequery the title data to fetch those that match any ofthe n-grams.
Page topics are not discriminated inthis step.
For example, unigram ?Java?
returns both?Java (software platform)?
and ?Java (dance).
?Wikipedia contains a collection of disambigua-tion pages.
Each disambiguation page includes a listof alternative uses of a term.
Note that there are twodifferent Wikipedia disambiguation pages: explicitand implicit.
A page is explicit when the page ti-tle is annotated by Wikipedia as ?disambiguation,?such as ?Oil (disambiguation).?
A page is implicitwhen it is not so annotated, but points to a categorysuch as ?Category:Disambiguation pages,?
or ?Cat-egory:All disambiguation pages.?
We iterate overthe pages fetched from the last step, using disam-biguation pages to enrich and refine the features of acourse description.Unlike the work of Mihalcea and Csomai (2007)which uses the annotation in the page title of a con-cept to perform WSD, our approach uses a page?sparent category as a cue to the correct sense.
Typi-cally, the sense of a concept depends on the senses ofother concepts in the context.
For example, a para-graph on programming languages and data typesensures that ?data?
more likely corresponds to apage under ?Category:Computer data?
than one un-der ?Category:Star Trek.
?Algorithm 1 explains the steps to generate fea-tures for a course C.Given the C1 and C2 in section 1, their generatedfeatures F1 and F2 are:F1: Shortest path problem, Tree traversal, Spanning tree, Tree,Analysis, List of algorithms, Completeness, Algorithm, Sort-ing, Data structure, Structure, Design, Data.F2: Unix, Social, Ethics, Object-oriented design, Computerprogramming, C++, Object-oriented programming, Design.Algorithm 1 Feature Generation (F ) for Course C1.
Tc ?
?
(clear terms), Ta ?
?
(ambiguous terms).2.
Generate all possible n-grams (n ?
[1, 3]) G from C.3.
Fetch the pages whose titles match any of g ?
Gfrom Wikipedia redirection data.
For each page pidof term t, Tc ?
Tc ?
{t : pid}.4.
Fetch the pages whose titles match any of g ?
Gfrom Wikipedia page title data.
If a disambiguationpage, include all the terms this page refers to.
If apage pid corresponds to a term t that is not ambigu-ous, Tc ?
Tc ?
{t : pid}, else Ta ?
Ta ?
{t : pid}.5.
For each term ta ?
Ta, find the disambiguation thatis on average most related (Equation 1) to the set ofclear terms.
If a page pid of ta is on average the mostrelated to the terms in Tc, and the relatedness score isabove a threshold ?
(?
?
[0, 1]), set Tc ?
Tc ?
{ta :pid}.
If ta and a clear term are different senses of thesame term, keep the one that is more related to all theother clear terms.6.
Return clear terms as features.Algorithm 2 Semantic Vector SV1 for F1 and J1.
for all words ti ?
J do2.
if ti ?
F1, set SV1i = 1 where SV1i ?
SV1.3.
if ti /?
F1, the semantic relatedness between ti andeach term t1j ?
F1 is calculated (Equation 1).
SetSV1i to the highest score if the score exceeds thepreset threshold ?, otherwise SV1i = 0.4. end for3.4 Determine Course RelatednessGiven two course descriptions C1 and C2, we useAlgorithm 1 to generate features F1 for C1, and F2forC2.
Next, the two feature lists are joined togetherinto a unique set of terms, namely J .
Similar to pre-vious work (Li et al, 2006), semantic vectors SV1(Algorithm 2) and SV2 are computed for F1 and F2.Each value of an entry of SV1 for features F1 isreweighed as:SV1i = SV1i ?
I(ti) ?
I(tj), (2)where SV1i is the semantic relatedness between ti ?F1 and tj ?
J .
I(ti) is the information content of ti,and I(tj) is the information content of tj .
Similarly,we reweigh each value for the semantic vector SV2of F2.38The information content I(t) of a term t is aweighed sum of the category information contentIc(t) and the linkage information content Il(t):I(t) = ?
?
Ic(t) + (1?
?)
?
Il(t).
(3)Inspired by related work (Seco et al, 2004), thecategory information content of term t is redefinedas a function of its siblings:Ic(t) = 1?log(siblings(t) + 1)log(N), (4)where siblings(t) is the number of siblings for t onaverage, and N is the total number of terms in thehierarchy (Section 3.1).The linkage information content is a function ofoutlinks and inlinks of the page pid that t corre-sponds to:Il(t) = 1?inlinks(pid)MAXIN?
outlinks(pid)MAXOUT, (5)where inlinks(pid) and outlinks(pid) are thenumbers of inlinks and outlinks of a page pid.MAXIN and MAXOUT are the maximum num-bers of inlinks and outlinks that a page has inWikipedia.7Finally, the relatedness of two courses is a cosinecoefficient of the two semantic vectors:f(C1, C2) =SV1 ?
SV2||SV1|| ?
||SV2||.
(6)4 Experimental ResultsWikipedia offers its content as database backupdumps (wikidumps) freely available to download.Our application is based on the English wikidump8of July 2011.
We have extracted redirections, ti-tles, categories, and links from the wikidump intoseparate tables in MySQL.
Using the steps outlinedin Section 3.1, we built a table for the hierarchywith ?Category:Applied sciences?
as the root.
Theattributes of each table were indexed to speed upqueries.
Our experiment used ?
= 0.2, ?
= 0.5,?
= 0.2, and ?
= 0.6.
These values were found7The computation of MAXIN and MAXOUT couldbe time-consuming.
They are therefore based on the entireWikipedia instead of the constructed hierarchy to avoid the re-calculation when the domain changes.
This also ensures themaximum linkage information is unbiased for every domain.For the July 2011 wikidump, page ?Geographic coordinate sys-tem?
has the most in-links, a total of 575,277.
Page ?List of Ital-ian communes (2009)?
has the most out-links, a total of 8,103.8http://dumps.wikimedia.org/enwiki/20110722/empirically to perform well over randomly selectedsamples.We randomly selected 25 CS courses from 19universities that can be transferred to Universityof Massachusetts Lowell (UML) according to thetransfer dictionary.
Each transfer course was com-pared to all 44 CS courses offered at UML, a to-tal of 1,100 comparisons.
The result was consid-ered correct for each course if the real equivalentcourse in UML appears among the top 3 in the listof highest scores.
We excluded all Wikipedia pageswhose titles contained specific dates or were anno-tated as ?magazine?, ?journal?, or ?album.?
We re-moved both general and domain stop words (suchas ?course,?
?book,?
and ?student?)
from course de-scriptions.
If a course description contains the key-words ?not?
or ?no,?
e.g., ?This course requires nocomputer programming skills,?
the segment aftersuch keyword is ignored.We tested our approach against the work by Liet al (2006) and TF-IDF on the same data set ofcourse descriptions.
The accuracy of our proposedapproach is 72%, compared to 52% using Li et al(2006), and 32% using TF-IDF.Algorithm Pearson?s correlation p-valueOur approach 0.85 6.6 ?
10?10Li et al (2006) 0.57 0.0006TF-IDF 0.73 2 ?
10?6Table 1.
Pearson?s correlation of course relatednessscores with human judgments.Since the transfer dictionary is always out of date,we found a few equivalent course pairs that were un-intuitive.
To make a more meaningful evaluation,we set up a human judgment data set.
We gave6 annotators (CS students and professors) a list of32 pairs of courses, with only course titles and de-scriptions.
They independently evaluated whethereach pair is equivalent on a scale from 1 to 5.
Weaveraged their evaluations for each pair and con-verted the scale from [1,5] to [0,1].
Next, we ranour approach, the work by Li et al (2006), and TF-IDF on the same 32 course pairs.
Table 1 reportsthe Pearson?s correlation coefficient of course relat-edness scores with human judgment, and statisticalsignificances.
Our approach has a higher correlationto the human judgment data set compared to previ-39ous work.
Furthermore, a smaller p-value indicatesour approach is more likely to correlate with humanjudgment.During the experiment, we have found some mis-classified categories in the wikidump.9 For example,?Category:Software?
has over 350 subcategorieswith names similar to ?Category:A-Class BritneySpears articles,?
or ?Category:FA-Class Coca-Colaarticles.?
None of these appears in the Wikipediawebsite or the Wikipedia API10 as a subcategoryof ?Category:Software.?
More study is required onhow they are formed.5 ConclusionThis paper presents a domain-specific algorithm tosuggest equivalent courses based on analyzing theirsemantic relatedness using Wikipedia.
Both accu-racy and correlation suggest our approach outper-forms previous work.
Future work includes com-paring our approach with ESA, experimenting onmore courses from more universities, and adaptingour work to courses in other languages.AcknowledgmentsThe authors thank Dr. Karen M. Daniels for review-ing drafts of this paper.
We also appreciate the in-sightful suggestions from Dr. Saif Mohammad at theearly stage of our work.
Last, but not least, we thankthe reviewers for their comments that guided im-provement of the contents of this paper.ReferencesGergana Bounova.
2011.
Topological Evolution of Net-works: Case Studies in the US Airlines and LanguageWikipedias.
Ph.D. thesis, MIT.Alexander Budanitsky and Graeme Hirst.
2006.
Evalu-ating Wordnet-based measures of lexical semantic re-latedness.
Computational Linguistics, 32:13?47.David Buscaldi and Paolo Rosso.
2006.
Mining knowl-edge from Wikipedia from the question answeringtask.
In Proc.
5th Int?l.
Conf.
on Language Resources& Evaluation, Genoa, Italy.Rudi L. Cilibrasi and Paul M. B. Vitanyi.
2007.
Thegoogle similarity distance.
IEEE Trans.
on Knowledge& Data Engineering, 19:370?383.James R. Curran.
2004.
From Distributional to SemanticSimilarity.
Ph.D. thesis, Univ.
of Edinburgh.9We have analyzed wikidumps of July 2011 and Oct 2010and the problem persists in both versions.10https://www.mediawiki.org/wiki/APIEvgeniy Gabrilovich and Shaul Markovitch.
2009.Wikipedia-based semantic interpretation for NLP.
J.AI Research, 34:443?498.Graeme Hirst and David St-Onge, 1998.
Lexical Chainsas Representation of Context for the Detection andCorrection Malapropisms.
The MIT Press.Jay J. Jiang and David W. Conrath.
1997.
Semanticsimilarity based on corpus statistics and lexical taxon-omy.
In Proc.
Int?l.
Conf.
on Research in Computa-tional Linguistics, pages 19?33.Claudia Leacock and Martin Chodorow.
1998.
Usingcorpus statistics and Wordnet relations for sense iden-tification.
Computational Linguistics, 24:147?165.Yuhua Li, David McLean, Zuhair A. Bandar, James D.O?Shea, and Keeley Crockett.
2006.
Sentence similar-ity based on semantic nets and corpus statistics.
IEEETrans.
on Knowledge and Data Engineering, 18.Dekang Lin.
1998.
Extracting collocations from text cor-pora.
In Workshop on Computational Terminology.Christopher D. Manning, Prabhakar Raghavan, and Hin-rich Schu?tze.
2008.
Introduction to Information Re-trieval.
Cambridge University Press.RadaMihalcea and Andras Csomai.
2007.
Wikify!
: link-ing documents to encyclopedic knowledge.
In Proc.16th ACM Conf.
on Information & Knowledge Man-agement, pages 233?242.Saif Mohammad.
2008.
Measuring Semantic DistanceUsing Distributional Profiles of Concepts.
Ph.D. the-sis, Univ.
of Toronto, Toronto, Canada.Yuan Ni, Lei Zhang, Zhaoming Qiu, and Wang Chen.2010.
Enhancing the open-domain classification ofnamed entity using linked open data.
In Proc.
9th Int?l.Conf.
on the Semantic Web, pages 566?581.Simone Paolo Ponzetto and Michael Strube.
2007.Knowledge derived from Wikipedia for computing se-mantic relatedness.
J. AI Research, 30:181?212, Oc-tober.Mehran Sahami and Timothy D. Heilman.
2006.
A web-based kernel function for measuring the similarity ofshort text snippets.
In Proc.
15th Int?l.
Conf.
on WWW.Nuno Seco, Tony Veale, and Jer Hayes.
2004.
An intrin-sic information content metric for semantic similarityin Wordnet.
In Proc.
16th European Conf.
on AI.Fei Wu.
2010.
Machine Reading: from Wikipedia to theWeb.
Ph.D. thesis, Univ.
of Washington.Beibei Yang and Jesse M. Heines.
2011.
Using seman-tic distance to automatically suggest transfer courseequivalencies.
In Proc.
6th Workshop on InnovativeUse of NLP for Building Educational Applications,pages 142?151.Jonathan Yu, James A. Thom, and Audrey Tam.
2007.Ontology evaluation using Wikipedia categories forbrowsing.
In Proc.
16th ACM Conf.
on Informationand Knowledge Management, pages 223?232.40
