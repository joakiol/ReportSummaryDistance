Squibs and DiscussionsMemoization in Top-Down ParsingMark  Johnson"Brown University1.
IntroductionIn a paper published in this journal, Norvig (1991) pointed out that memoization of atop-down recognizer program produces a program that behaves imiliarly to a chartparser.
This is not surprising to anyone familiar with logic-programming approaches tonatural anguage processing (NLP).
For example, the Earley deduction proof procedureis essentially a memoizing version of the top-down selected literal deletion (SLD) proofprocedure mployed by Prolog.
Pereira and Warren (1983) showed that the steps ofthe Earley Deduction proof procedure proving the well-formedness of a string S fromthe standard 'top-down' definite clause grammar (DCG) axiomatization of a context-free grammar (CFG) G correspond irectly to those of Earley's algorithm recognizingS using G.Yet as Norvig notes in passing, using his approach the resulting parsers in generalfail to terminate on left-recursive grammars, even with memoization.
The goal ofthis paper is to discover why this is the case and present a functional formalizationof memoized top-down parsing for which this is not so.
Specifically, I show howto formulate top-down parsers in a 'continuation-passing style,' which incrementallyenumerates the right string positions of a category, rather than returning a set of suchpositions as a single value.
This permits a type of memoization ot described to myknowledge in the context of functional programming before.
This kind of memoizationis akin to that used in logic programming, and yields terminating parsers even in theface of left recursion.In this paper, algorithms are expressed in the Scheme programming language (Reesand Clinger 1991).
Scheme was chosen because it is a popular, widely known languagethat many readers find easy to understand.
Scheme's 'first-class' treatment of functionssimplifies the functional abstraction used in this paper, but the basic approach can beimplemented in more conventional languages as well.
Admittedly elegance is a matterof taste, but personally I find the functional specification of CFGs described here assimple and elegant as the more widely known logical (DCG) formalization, and I hopethat the presentation of working code will encourage readers to experiment with theideas described here and in more substantial works such as Leermakers (1993).
Infact, my own observations suggest hat with minor modifications (such as the use ofintegers rather than lists to indicate string positions, and vectors indexed by stringpositions rather than lists in the memoization routines) an extremely efficient chartparser can be obtained from the code presented here.Ideas related to the ones discussed here have been presented on numerous occa-sions.
Almost 20 years ago Shiel (1976) noticed the relationship between chart parsingand top-down parsing.
Leermakers (1993) presents a more abstract discussion of thefunctional treatment of parsing, and avoids the left-recursion problem for memoized?
Cognitive Science Department, Brown University, Box 1978, Providence, RI 02912(~) 1995 Association for Computational LinguisticsComputational Linguistics Volume 21, Number 3functional parsers by using a 'recursive ascent' or PLR parsing strategy instead of atop-down strategy.
At a more abstract level than that of this paper, Shieber, Schabes,and Pereira (1994) show that a variety of well-known parsing algorithms can be viewedas computing the closure of a set of basic parsing operations on a representation fthe input string.2.
Formalizing Context-Free GrammarsIt is fairly straightforward to implement a top-down parser in a functional program-ming language.
The key insight is that a nonterminal category A in a grammar definesa function fA that maps a string position 1 in the input string 7 to a set of string po-sitions fA(l) such that r C fA(1) iff A can derive the substring of "7 spanning stringpositions I to r (see e.g., Leermakers \[1993\] for discussion).For example, suppose V, gP, and S are already bound to fv, fwP and fs, and thegrammar contains the following productions with VP on the left hand side.
(1) VP --+ V NP VP --+ V SThen the following Scheme definition binds vp to fvP.
(2) (define (VP p)(union (reduce union '() (map NP (V p)))(reduce union '() (map S (V p))))))If sets are represented by unordered lists, union can be given the following defini-tion.
The function reduce is defined such that an expression of the form (reducef e' (xl ... Xn)) evaluates to ( f  (... 0 c e Xl)...)Xn).
(3)(4)(define (reduce fn init args)(if (null?
args)init(reduce fn (fn init (car args))(car args))))(define (union set1 set2)(if (null?
set1)set2(if (member (car set1) set2)(union (cdr set1) set2)(cons (car set1)(union (cdr set1) set2)))))When evaluated using Scheme's applicative-order reduction rule, such a system be-haves as a depth-first, op-down recognizer in which nondeterminism is simulated bybacktracking.
For example, in (2) the sequence V NP is first investigated asa potentialanalysis of VP, and then the sequence V S is investigated.Rather than defining the functions f by hand as in (2), higher-order functions canbe introduced to automate this task.
It is convenient to use suffixes of the input stringto represent the string positions of the input string (as in DCGs).The expression (terminal x) evaluates to a function that maps a string position I tothe singleton set { r } iff the terminal x spans from I to r, and the empty set otherwise.406Mark Johnson Memoization in Top-Down Parsing(5) (define (terminal X)(lambda (p)(if (and (pair?
p)(eq?
(car p) X))(list (cdr p))' ( ) ) ) )The expression (seq fA fB) evaluates to a function that maps a string position 1 to theset of string positions {ri} such that there exists an m 6 fA(1), and ri 6 fB(rrl).
Informally,the resulting function recognizes substrings that are the concatenation f a substringrecognized by fA and a substring recognized by f~.
(6) (define (seq A B)(lambda (p)(reduce union '() (map B (A p)))))The expression (alt fA fB) evaluates to a function that maps a string position 1 tofa(l) U fB(1).
Informally, the resulting function recognizes the union of the substringsrecognized by fA and fB.
(7) (define (alt A B)(lambda (p)(union (A p) (B p))))While terminal, seq, and a l t  suffice to define (epsilon-free) context-free grammars,we can easily define other useful higher-order functions.
For example, epsi lon recog-nizes the empty string (i.e., it maps every string position 1 into the singleton set {1}),(opt fA) recognizes an optional constituent, and (k* f,O recognizes zero or more occur-rences of the substrings recognized by fA.
(8)(9)(10)(define epsilon list)(define (opt A) (alt epsilon A))(define (k* A)(alt epsilon(seq A (k* A))))These higher-order functions can be used to provide simpler definitions, such as (2a)or (2b), for the function VP defined in (2) above.
(2a)(2b)(define VP (alt (seq V NP) (seq V S)))(define VP (seq V (alt NP S)))This method of defining the functions corresponding to categories i quite appealing.Unfortunately, Scheme is deficient in that it does not allow mutually recursive func-tional definitions of the kind in (2a) or (2b).
For example, suppose S is defined as in(11) and VP is defined as in (2a).
(11) (define S (seq NP VP))407Computational Linguistics Volume 21, Number 3Further, suppose (11) precedes (2a) textually in the program.
Then the variable VP in(11) will be incorrectly interpreted as unbound.
Changing the order of the definitionswill not help, as then the variable S will be unbound.
~ A work-around is to add a vac-uous lambda abstraction and application as in (11a), in effect delaying the evaluationof function definition.
(11a) (define S (lambda args (apply (seq NP VP) args)))With a macro definition such as (12) (named to remind us of this deficiency in thecurrent Scheme specification and perhaps encourage the language designers to dobetter in the future), the definition of functions such as (11a) can be written as (11b).
(12) (define-syntax vacuous(syntax-rules ()((vacuous fn)(lambda args (apply fn args)))))(11b) (define S (vacuous (seq NP VP)))Figure 1 contains a fragment defined in this way.
After these definitions have beenloaded, an expression such as the one in (13) can be evaluated.
It returns a list of theinput string's suffixes that correspond to the right string position of an S.(13) > (s '(Kim knows every student likes Sandy))((likes sandy) ())In example (13), the list resulting from the evaluation contains two suffixes, corre-sponding to the fact that both Kim knows every student and Kim knows every student likesSandy can be analysed as Ss.Finally, the recogn ize  predicate can be defined as follows.
The expression (recog-n ize words) is true iff words is a list of words that can be analysed as an S, i.e., if theempty string is a one of right string positions of an S whose left string position is thewhole string to be recognized.
(14) (define (recognize words)(member '() (S words)))3.
Memoizat ion  and Left RecursionAs noted above, the Scheme functions defined in this way behave as top-down, back-tracking recognizers.
It is well known that such parsing methods suffer from twomajor problems.1 This problem can arise even if syntactic onstructions specifically designed to express mutual recursionare used, such as letrec.
Although these variables are closed over, their values are not applied whenthe defining expressions are evaluated, so such definitions hould not be problematic for anapplicative-order evaluator.
Apparently Scheme requires that mutually recursive functional expressionssyntactically contain a lambda expression.
Note that this is not a question of reduction strategy (e.g.,normal-order versus applicative-order), but an issue about he syntactic scope of variables.408Mark Johnson Memoization in Top-Down Parsing(define S (vacuous (seq NP VP))) ;S--~NP VP(define VP (vacuous (alt (seq V NP) ; VP-+VNP(seq (V S))))) ; \ ]VS(define NP (vacuous (alt PN ;NP--*PN(seq Det N)))) ;\[DetN(define PN (alt (terminal 'Kim) (terminal 'Sandy)))(define V (alt (terminal 'likes) (terminal 'knows)))(define Det (alt (terminal 'every) (terminal 'no)))(define N (alt (terminal 'student) (terminal 'professor)))Figure 1A CFG &agmentdefined using the highe~orderconstructors.First, a top-down parser using a left-recursive grammar  typically fails to terminateon some inputs.
This is true for recognizers defined in the manner just described; left-recursive grammars  yield programs that contain il l-founded recursive definitions.
2Second, backtracking parsers typically involve a significant amount of redundantcomputation, and parsing time is exponential in the length of the input string in theworst case.
Again, this is also true for the recognizers just described.Memoization is a standard technique for avoiding redundant computation, and asNorvig (1991) noted, it can be applied to top-down recognizers to convert exponential-time recognizers into polynomial-t ime r cognizers.A general way of doing this is by defining a higher-order procedure memo that takesa function as an argument and returns a memoized version of it.
3 This procedure isessentially the same as the memoize predicate that is extensively discussed in Abelsonand Sussman (1985).
(15) (def ine  (memo fn)(let ((alist ' ( ) ) )(launbda args(let ((entry (assoc args alist)))(if entry(cdr entry)(let ((result (apply fn args)))(set!
alist (cons (cons args result)alist))result))))))To memoize the recognizer, the original definitions of the functions hould be replacedwith their memoized counterparts; e.g., ( l lb) should be replaced with (11c).
Clearlythese definitions could be further simplified with suitable macro definitions or other'syntactic sugar.
'2 Specifically, if A is a Scheme variable bound to the function corresponding toa left-recursive category,then for any string position p the expression (A p) reduces to another expression containing (A p).
Thusthe (applicative-order) reduction of such expressions does not terminate.3 For simplicity, the memo procedure presented in (15) stores the memo table as an association list, ingeneral resulting in a less than optimal implementation.
As Norvig notes, more specialized atastructures, uch as hash tables, can improve performance.
In the parsing context here, optimalperformance would probably be obtained by encoding string positions with integers, allowing memotable lookup to be a single array reference.409Computational Linguistics Volume 21, Number 3(11c) (def ine S (memo (vacuous (seq NP VP))))As an aside, it is interesting to note that memoization can be applied selectively in thisapproach.
For example, because of the overhead of table lookup in complex feature-based grammars, it might be more efficient not to memoize all categories, but ratherrestrict memoization to particular categories such as NP and S.Now we turn to the problem of left recursion.
In a logic programming setting,memoization (specifically, the use of Earley deduction) avoids the nonterminationproblems associated with left recursion, even when used with the DCG axiomati-zation of a left-recursive grammar.
But as Norvig mentions in passing, with parsersdefined in the manner just described, the memoized versions of programs derivedfrom left-recursive grammars fail to terminate.It is easy to see why.
A memo-ed procedure constructs an entry in a memo tableonly after the result of applying the unmemoized function to its arguments has beencomputed.
Thus in cases of left recursion, memoization does nothing to prevent heil l-founded recursion that leads to nontermination.In fact it is not clear how memoization could help in these cases, given that werequire that memo behaves emantically as the identity function; i.e., that (memo f )  andf are the same function.
Of course, we could try to weaken this identity requirement(e.g., by only requiring that ( fx )  and ((memo f)  x) are identical when the reductionof the former terminates), but it is not clear how to do this systematically.Procedurally speaking, it seems as if memoization is applying 'too late' in theleft-recursive cases; reasoning by analogy with Earley deduction, we need to constructan entry in the memo table when such a function is called; not when the result ofits evaluation is known.
Of course, in the left recursive cases this seems to lead toan inconsistency, since these are cases where the value of an expression is required tocompute that very value.Readers familiar with Abelson and Sussman (1985) will know that in many casesit is possible to circumvent such apparent circularity by using asynchronous 'lazystreams' in place of the list representations (of string positions) used above.
Thecontinuation-passing style encoding of CFGs discussed in the next section can beseen as a more functionally oriented instantiation of this kind of approach.4.
Formalizing Relations in Continuation-Passing StyleThe apparent circularity in the definition of the functions corresponding to left-recur-sive categories suggests that it may be worthwhile reformulating the recognition prob-lem in such a way that the string position results are produced incrementally, rather thanin one fell swoop, as in the formalization just described.
The key insight is that eachnonterminal category A in a grammar defines a relation rA such that rA(l, r) iff A canderive the substring of the input string spanning string positions I to r .
4 Informallyspeaking, the r can be enumerated one at a time, so the fact that the calculation ofrA(l, r) requires the result rA(l, r') need not lead to a vicious circularity.One way to implement his in a functional programming language is to use a'Continuation-Passing Style' (CPS) of programming, s It turns out that a memoized4 The relation rA and the function fA mentioned above satisfy V r ~/l rA(l, r) ~ r C f(l).5 Several readers of this paper, including areviewer, suggested that this can be formulated moresuccinctly using Scheme's call/cc continuation-constructing primitive.
After this paper was acceptedfor publication, Jeff Sisskind evised an implementation based on call/cc which does not requirecontinuations to be explicitly passed as arguments ofunctions.410Mark Johnson Memoization in Top-Down Parsingtop-down parser written in continuation-passing style will in fact terminate, evenin the face of left recursion.
Additionally, the treatment of memoization in a CPS isinstructive because it shows the types of table lookup operations needed in chartparsing.Informally, in a CPS program an additional argument, call it c, is added to allfunctions and procedures.
When these functions and procedures are called c is alwaysbound to a procedure (called the continuation); the idea is that a result value v is'returned' by evaluating (c v).
For example, the standard definition of the functionsquare in (16) would be rewritten in CPS as in (17).
(18) shows how this definitioncould be used to compute and display (using the Scheme builtin d isp lay)  the squareof the number 3.
(16) (def ine (square x) (* x x))(17) (def ine (square cont x) (cont (* x x ) ) )(18) > (square d i sp lay  3)9Thus whereas result values in a non-CPS program flow 'upwards' in the procedurecall tree, in a CPS program result values flow 'downwards'  in the procedure call tree.
6,7The CPS style of programming can be used to formalize relations in a pure functionallanguage as procedures that can be thought of as 'returning' multiply valued resultsany number of times.These features of CPS can be used to encode CFGs as follows.
Each category A isassociated with a function gA that represents the relation rA, i.e., (gA C I) reduces (in anapplicative-order reduction) in such a fashion that at some stage in the reduction theexpression (c r) is reduced iff A can derive the substring spanning string positions Ito r of the input string.
(The value of (gA c I) is immaterial and therefore unspecified,but see footnote 8 below).
That is, if (gA C I) is evaluated with l bound to the left stringposition of category A, then (c r) will be evaluated zero or more times with r boundto each of A's right string positions r corresponding to I.For example, a CPS function recognizing the terminal item 'will' (arguably a futureauxiliary in a class of its own) could be written as in (19).
(19) (define (future-aux continuation pos)(if (and (pair?
pos) (eq?
(car pos)(continuation (cdr pos))))'will))For a more complicated example, consider the two rules defining VP in the fragmentabove, repeated here as (20).
These could be formalized as the CPS function definedin (21).
(20)(21)VP --+ V NP VP --+ V S(define (VP continuation pos)(begin(V (lambda (posl) (NP continuation posl)) pos)(V (lambda (posl) (S continuation posl)) pos)))6 Tail recursion optimization prevents the procedure call stack from growing unboundedly.7 This CPS formalization ofCFGs is closely related to the 'downward success passing' method oftranslating Prolog into Lisp discussed by Kahn and Carlsson (1984).411Computational Linguistics Volume 21, Number 3In this example V, NP, and S are assumed to have CPS definitions.
Informally, theexpression (lambda (poe1) (NP continuation posl))  is a continuation that specifieswhat to do if a V is found, viz., pass the V's right string position posl to the NPrecognizer as its left-hand string position, and instruct the NP recognizer in turn topass its right string positions to continuation.The recognition process begins by passing the function corresponding to the rootcategory the string to be recognized, and a continuation (to be evaluated after suc-cessful recognition) that records the successful analysis.
8(22) (define (recognize words)( le t  ((recognized #f))(S (lambda (pos)( i f  (null?
pos)words)recognized))(set!
recognized #t)))Thus rather than constructing a set of all the right string positions (as in the previousencoding), this encoding exploits the ability of the CPS approach to 'return' a valuezero, one or more times (corresponding to the number of right string positions).
Andalthough it is not demonstrated in this paper, the ability of a CPS procedure to 'return'more than one value at a time can be used to pass other information besides right stringposition, such as additional syntactic features or semantic values.Again, higher-order functions can be used to simplify the definitions of the CPSfunctions corresponding to categories.
The CPS versions of the terminal, se% and a l tfunctions are given as (23), (25), and (24) respectively.
(23) (define (terminal word)(lambda (continuation poe)(if (and (pair?
poe) (eq?
(car poe) word))(continuation (cdr poe)))))8 Thus this formaliza~on makes use of mutability to return final results, and so cannot be expressed in apurely func~onal language.
Howeve~ it is possible to construct a similiar formalization i the purelyfunctional subset of Scheme by passing around an additional 'result' argument (here the lastargument).
The examples above would be rewritten as the following under this approach.
(19') (define (future-aux continuation poe result)(if (and (pair?
poe) (eq?
(car poe) 'will))(continuation (cdr poe) result)))(21') (define (VP continuation poe result)(V (lambda (posl resultl)(NP continuation posl resultl))poe(V (lambda (posl resultl)(S continuation posl result1))poeresult)))(22') (define (recognize words)(S (lambda (poe result)(if (null?
poe) #t result))words))412Mark Johnson Memoization in Top-Down Parsing(24)(25)(define (alt altl alt2)(lambda (continuation pos)(begin (altl continuation pos)(alt2 continuation pos))))(define (seq seql seq2)(lambda (cont pos)(seql (lambda (posl)pos)))(seq2 cent posl))If these three functions definitions replace the earlier definitions given in (5), (6), and(7), the fragment in Figure I defines a CPS recognizer.
Note that just as in the first CFGencoding, the resulting program behaves as a top-down recognizer.
Thus in generalthese progams fail to terminate when faced with a left-recursive grammar for es-sentially the same reason: the procedures that correspond to left-recursive categoriesinvolve ill-founded recursion.5.
Memoization in Continuation-Passing StyleThe memo procedure defined in (15) is not appropriate for CPS programs because it as-sociates the arguments of the functional expression with the value that the expressionreduces to, but in a CPS program the 'results' produced by an expression are the val-ues it passes on to the continuation, rather than the value that the expression reducesto.
That is, a memoization procedure for a CPS procedure should associate argumentvalues with the set of values that the unmemoized procedure passes to its continua-tion.
Because an unmemoized CPS procedure can produce multiple result values, itsmemoized version must store not only these results, but also the continuations passedto it by its callers, which must receive any additional results produced by the originalunmemoized procedure.The cps-memo procedure in (26) achieves this by associating a table entry witheach set of argument values that has two components; a list of caller continuationsand a list of result values.
The caller continuation entries are constructed when thememoized procedure is called, and the result values are entered and propagated backto callers each time the unmemoized procedure 'returns' a new value.
99 The dolist form used in (26) behaves as the dolist form in CommonLisp.
It can be defined in termsof Scheme primitives as follows:(define-syntax dolist(syntax-rules ()((dolist (var list) .
body)(do ((to-do list))((null?
to-do))(let ((var (car to-do)))?
body)))))413Computational Linguistics Volume 21, Number 3(26) (define (memo cps-fn)(let ((table (make-table)))(lambda (continuation .
args)(let ((entry (table-tel table args)))(cond ((null?
(entry-continuations entry));fi~ttime memo~ed procedu~has been called with args(push-continuation!
entry continuation)(apply cps-fn(lambda result(when (not (result-subsumed?
entry result))(push-result!
entry result)(dolist (cont (entry-continuations entry))(apply cont result))))args))(else; memoizedprocedu~hasbeen called with args befo~(push-continuation!
entry continuation)(dolist (result (entry-results entry))(apply continuation result))))))))Specifically, when the memoized procedure is called, continuation is bound to thecontinuation passed by the caller that should receive 'return' values, and args is boundto a list of arguments that index the entry in the memo table and are passed to theunmemoized procedure cps-fn if evaluation isneeded.
The memo table table initiallyassociates every set of arguments with empty caller continuation and empty resultvalue sets.
The local variable entry is bound to the table entry that corresponds toargs; the set of caller continuations stored in entry is null iff the memoized functionhas not been called with this particular set of arguments before.The cond clause determines if the memoized function has been called with argsbefore by checking if the continuations component of the table entry is nonempty.In either case, the caller continuation needs to be stored in the continuations compo-nent of the table entry, so that it can receive any additional results produced by theunmemoized procedure.If the memoized procedure has not been called with args before, it is necessaryto call the unmemoized procedure cps-fn to produce the result values for args.
Thecontinuation passed to cps-fn checks to see if each resu l t  of this evaluation is sub-sumed by some other result already produced for this entry; if it is not, it is pushedonto the results component of this entry, and finally passed to each caller continuationassociated with this entry.If the memoized procedure has been called with args before, the results associ-ated with this table entry can be reused.
After storing the caller continuation i thetable entry, each result already accumulated in the table entry is passed to the callercontinuation.Efficient implementations of the table and entry manipulation procedures wouldbe specialized for the particular types of arguments and results used by the unmem-oized procedures.
Here we give a simple and general, but less than optimal, imple-mentation using association lists.
1?10 This formalization makes use of 'impure' features ofScheme, specifically destructive assignment to addan element tothe table list (which is why this list contains the dummy element "head*).
Arguably,414Mark Johnson Memoization i  Top-Down ParsingA table is a headed association list (27), which is extended as needed by tab le - re f(28).
In this fragment there are no partially specified arguments or results (such aswould be involved if the fragment used feature structures), so the subsumption relationis in fact equality.
(27)(28)(define (make-table) (list '~head~))(define (table-ref table key)(let ((pair (assoc key (cdr table))))( i f  pair  ;an entry alreadyexists(cdr pair) ; ~turnit(let ((new-entry (make-entry)))(set-cdr!
table (cons (cons key new-entry)(cdr table)))new-entry))))Entries are manipulated by the following procedures.
Again, because this fragmentdoes not produce partially specified results, the result subsumption check can be per-formed by the Scheme function member.
(29)(3O)(31)(32)(33)(34)(define (make-entry) (cons '() '()))(define entry-continuations car)(define entry-results cdr)(define (push-continuation!
entry continuation)(set-car!
entry (cons continuation (car entry))))(define (push-result!
entry result)(set-cdr!
entry (cons result (cdr entry))))(define (result-subsumed?
entry result)(member result (entry-results entry)))As claimed above, the memoized version of the CPS top-down parser does terminate,even if the grammar is left-recursive.
Informally, memoized CPS top-down parsersterminate in the face of left-recursion because they ensure that no unmemoized pro-cedure is ever called twice with the same arguments.
For example, we can replacethe definition of NP in the fragment with the left-recursive one given in (35) with-out compromising termination, as shown in (36) (where the input string is meant oapproximate Kim's professor knows every student).
(35)(36)(define NP (memo (vacuous(alt PN ;NP-+PN(alt (seq NP N) ; I NPN(seq Det N)))))) ; I DetN> (recognize '(Kim professor knows every student))#tthis is a case in which impure features result in a more comprehensible ov rall program.415Computational Linguistics Volume 21, Number 3Memoized CPS top-down recognizers do in fact correspond fairly closely to chartparsers.
Informally, the memo table for the procedure corresponding to a category Awill have an entry for an argument string position 1 just in case a predictive chartparser predicts a category A at position l, and that entry will contain string positionr as a result just in case the corresponding chart contains a complete dge spanningfrom l to r. Moreover, the evaluation of the procedure PA corresponding to a categoryA at string position l corresponds to predicting A at position l, and the evaluation ofthe caller continuations corresponds to the completion steps in chart parsing.
The CPSmemoization described here caches such evaluations in the same way that the chartcaches predictions, and the termination in the face of left recursive follows from thefact that no procedure PA is ever called with the same arguments twice.
Thus given aCPS formalization of the parsing problem and an appropriate memoization technique,it is in fact the case that "the maintenance of well-formed substring tables or chartscan be seen as a special case of a more general technique: memoization" (Norvig 1991),even if the grammar contains left recursion.6.
Conc lus ion and Future WorkThis paper has shown how to generalize Norvig's application of memoization totop-down recognizers to yield terminating recognizers for left recursive grammars.Although not discussed here, the techniques used to construct he CPS recognizerscan be generalized to parsers that construct parse trees, or associate categories with"semantic values" or "unification-based" feature structures.
Specifically, we add extraarguments to each (caller) continuation whose value is the feature structure, parse treeand/or the "semantic value" associated with each category.
Doing this raises other in-teresting questions not addressed by this paper.
As noted by a CL reviewer, while theuse of memoization described here achieves termination in the face of left recursionand polynomial recognition times for CFGs, it does not provide packed parse forestrepresentations of the strings analysed in the way that chart-based systems can (Lang1991; Tomita 1985).
Since the information that would be used to construct such packedparse forest representations in a chart is encapsulated in the state of the memoizedfunctions, a straightforward implementation attempt would probably be very compli-cated, and I suspect ultimately not very informative.
I suggest hat it might be morefruitful to try to develop an appropriate higher level of abstraction.
For example, thepacked parse forest representation exploits the fact that all that matters about a sub-tree is its root label and the substring it spans; its other internal details are irrelevant.This observation might be exploited by performing parse tree construction on streamsof subtrees with the same root labels and string positions (formulated using CPS asdescribed above) rather than individual subtrees; these operations would be 'delayed'until the stream is actually read, as is standard, so the parse trees would not actuallybe constructed uring the parsing process.
Whether or not this particular approach isviable is not that important, but it does seem as if a functional perspective providesuseful and insightful ways to think about the parsing process.416Mark Johnson Memoization in Top-Down ParsingAcknowledgmentsI would like to thank Jeff Sisskind, EdwardStabler, and the CL reviewers for theirstimulating comments.
This paper wasmade available via the CMP-LG pre-printserver after it was accepted by ComputationalLinguistics, and I thank my colleagues onthe Internet for their numerous uggestionsand technical improvements.ReferencesAbelson, Harold, and Sussman, Gerald Jay(1985).
Structure and Interpretation fComputer Programs.
MIT Press.Kahn, K. M., and Carlsson, M. (1984).
"Howto implement Prolog on a Lisp machine.
"In Implementations of Prolog, edited by J. A.Campbell, 117-134.
Ellis HorwoodLimited.Lang, Bernard (1991).
"Towards a uniformformal framework for parsing."
In CurrentIssues in Parsing Technology, edited byMasaru Tomita, 153-172.
KluwerAcademic Publishers.Leermakers, Ren4 (1993).
The FunctionalTreatment ofParsing, Kluwer AcademicPublishers.Norvig, Peter (1991).
"Techniques forautomatic memoization with applicationsto context-free parsing."
ComputationalLinguistics, 17(1), 91-98.Pereira, Fernando, and Warren, David H. D.(1983).
"Parsing as deduction."
InProceedings, 21st Annual Meeting of theAssociation for Computational Linguistics,137-144.Rees, Jonathan, and Clinger, William (1991).
"Revised report on the algorithmiclanguage scheme."
Technical Report 341,Computer Science Department, IndianaUniversity.Shell, B.
A.
(1976).
"Observations oncontext-free parsing."
Technical Report TR12-76, Center for Research in ComputingTechnology, Aiken ComputationLaboratory, Harvard University.Shieber, Stuart M.; Schabes, Yves; andPereira, Fernando C. N.
(1994).
"Principles and implementation fdeductive parsing."
Technical ReportTR-11-94, Center for Research inComputing Technology (also availablefrom the cmp-lg server), ComputerScience Department, Harvard University.Tomita, Masaru (1985).
Efficient Parsing forNatural Language, Kluwer AcademicPublishers.417
