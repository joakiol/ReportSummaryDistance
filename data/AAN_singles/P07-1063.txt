Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 496?503,Prague, Czech Republic, June 2007. c?2007 Association for Computational LinguisticsPERSONAGE: Personality Generation for DialogueFranc?ois MairesseDepartment of Computer ScienceUniversity of SheffieldSheffield, S1 4DP, United KingdomF.Mairesse@sheffield.ac.ukMarilyn WalkerDepartment of Computer ScienceUniversity of SheffieldSheffield, S1 4DP, United KingdomM.A.Walker@sheffield.ac.ukAbstractOver the last fifty years, the ?Big Five?model of personality traits has become astandard in psychology, and research hassystematically documented correlations be-tween a wide range of linguistic variablesand the Big Five traits.
A distinct line ofresearch has explored methods for automati-cally generating language that varies alongpersonality dimensions.
We present PER-SONAGE (PERSONAlity GEnerator), thefirst highly parametrizable language gener-ator for extraversion, an important aspectof personality.
We evaluate two personal-ity generation methods: (1) direct genera-tion with particular parameter settings sug-gested by the psychology literature; and (2)overgeneration and selection using statisticalmodels trained from judge?s ratings.
Resultsshow that both methods reliably generate ut-terances that vary along the extraversion di-mension, according to human judges.1 IntroductionOver the last fifty years, the ?Big Five?
model of per-sonality traits has become a standard in psychology(extraversion, neuroticism, agreeableness, conscien-tiousness, and openness to experience), and researchhas systematically documented correlations betweena wide range of linguistic variables and the Big Fivetraits (Mehl et al, 2006; Norman, 1963; Oberlan-der and Gill, 2006; Pennebaker and King, 1999).
Adistinct line of research has explored methods forautomatically generating language that varies alongpersonality dimensions, targeting applications suchas computer gaming and educational virtual worlds(Andre?
et al, 2000; Isard et al, 2006; Loyall andBates, 1997; Piwek, 2003; Walker et al, 1997) interalia.
Other work suggests a clear utility for gener-ating language manifesting personality (Reeves andNass, 1996).
However, to date, (1) research in gener-ation has not systematically exploited the psycholin-guistic findings; and (2) there has been little evalua-tion showing that automatic generators can producelanguage with recognizable personality variation.Alt Realization Extra5 Err... it seems to me that Le Marais isn?t as badas the others.1.834 Right, I mean, Le Marais is the only restaurantthat is any good.2.838 Ok, I mean, Le Marais is a quite french, kosherand steak house place, you know and the atmo-sphere isn?t nasty, it has nice atmosphere.
It hasfriendly service.
It seems to me that the serviceis nice.
It isn?t as bad as the others, is it?5.179 Well, it seems to me that I am sure you wouldlike Le Marais.
It has good food, the food issort of rather tasty, the ambience is nice, the at-mosphere isn?t sort of nasty, it features ratherfriendly servers and its price is around 44 dol-lars.5.833 I am sure you would like Le Marais, you know.The atmosphere is acceptable, the servers arenice and it?s a french, kosher and steak houseplace.
Actually, the food is good, even if its priceis 44 dollars.6.0010 It seems to me that Le Marais isn?t as bad asthe others.
It?s a french, kosher and steak houseplace.
It has friendly servers, you know but it?ssomewhat expensive, you know!6.172 Basically, actually, I am sure you would like LeMarais.
It features friendly service and accept-able atmosphere and it?s a french, kosher andsteak house place.
Even if its price is 44 dollars,it just has really good food, nice food.6.17Table 1: Recommendations along the extraver-sion dimension, with the average extraversion ratingfrom human judges on a scale from 1 to 7.
Alt-2 and3 are from the extravert set, Alt-4 and 5 are from theintrovert set, and others were randomly generated.Our aim is to produce a highly parameterizablegenerator whose outputs vary along personality di-mensions.
We hypothesize that such language can496be generated by varying parameters suggested bypsycholinguistic research.
So, we must first mapthe psychological findings to parameters of a naturallanguage generator (NLG).
However, this presentsseveral challenges: (1) The findings result fromstudies of genres of language, such as stream-of-consciousness essays (Pennebaker and King, 1999),and informal conversations (Mehl et al, 2006), andthus may not apply to fixed content domains used inNLG; (2) Most findings are based on self-reports ofpersonality, but we want to affect observer?s percep-tions; (3) The findings consist of weak but signifi-cant correlations, so that individual parameters maynot have a strong enough effect to produce recog-nizable variation within a single utterance; (4) Thereare many possible mappings of the findings to gen-eration parameters; and (5) It is unclear whetheronly specific speech-act types manifest personalityor whether all utterances do.Thus this paper makes several contributions.First, Section 2 summarizes the linguistic reflexes ofextraversion, organized by the modules in a standardNLG system, and propose a mapping from thesefindings to NLG parameters.
To our knowledge thisis the first attempt to put forward a systematic frame-work for generating language manifesting personal-ity.
We start with the extraversion dimension be-cause it is an important personality factor, with manyassociated linguistic variables.
We believe that ourframework will generalize to the other dimensionsin the Big Five model.
Second, Sections 3 and 4describe the PERSONAGE (PERSONAlity GEner-ator) generator and its 29 parameters.
Table 1 showsexamples generated by PERSONAGE for recom-mendations in the restaurant domain, along withhuman extraversion judgments.
Third, Sections 5and 6 describe experiments evaluating two genera-tion methods.
We first show that (1) the parame-ters generate utterances that vary significantly on theextraversion dimension, according to human judg-ments; and (2) we can train a statistical model thatmatches human performance in assigning extraver-sion ratings to generation outputs produced with ran-dom parameter settings.
Section 7 sums up and dis-cusses future work.2 Psycholinguistic Findings andPERSONAGE ParametersWe hypothesize that personality can be made man-ifest in evaluative speech acts in any dialogue do-main, i.e.
utterances responding to requests to REC-OMMEND or COMPARE domain entities, such asrestaurants or movies (Isard et al, 2006; Stent et al,2004).
Thus, we start with the SPaRKy genera-tor1, which produces evaluative recommendationsand comparisons in the restaurant domain, for adatabase of restaurants in New York City.
Thereare eight attributes for each restaurant: the name andaddress, scalar attributes for price, food quality, at-mosphere, and service and categorical attributes forneighborhood and type of cuisine.
SPaRKy is basedon the standard NLG architecture (Reiter and Dale,2000), and consists of the following modules:1.
Content Planning: refine communicative goals, select andstructure content;2.
Sentence planning; choose linguistic resources (lexicon,syntax) to achieve goals;3.
Realization: use grammar (syntax, morphology) to gen-erate surface utterances.Given the NLG architecture, speech-act types,and domain, the first step then is to summarise psy-chological findings on extraversion and map themto this architecture.
The column NLG modules ofTable 2 gives the proposed mapping.
The first rowspecifies findings for the content planning moduleand the other rows are aspects of sentence planning.Realization is achieved with the RealPro surface re-alizer (Lavoie and Rambow, 1997).
An examina-tion of the introvert and extravert findings in Table 2highlights the challenges above, i.e.
exploiting thesefindings in a systematic way within a parameteriz-able NLG system.The column Parameter in Table 2 proposes pa-rameters (explained in Sections 3 and 4) that are ma-nipulated within each module to realize the findingsin the other columns.
Each parameter varies con-tinuously from 0 to 1, where end points are meantto produce extreme but plausible output.
Given thechallenges above, it is important to note that theseparameters represent hypotheses about how a find-ing can be mapped into any NLG system.
The Introand Extra columns at the right hand side of the Pa-rameter column indicate a range of settings for thisparameter, suggested by the psychological findings,to produce introverted vs. extraverted language.SPaRKy produces content plans for restaurantrecommendations and comparisons that are modi-fied by the parameters.
The sample content planfor a recommendation in Figure 1 corresponds tothe outputs in Table 1.
While Table 1 shows thatPERSONAGE?s parameters have various pragmaticeffects, they preserve the meaning at the Gricean in-tention level (dialogue goal).
Each content plan con-tains a claim (nucleus) about the overall quality of1Available for download fromwww.dcs.shef.ac.uk/cogsys/sparky.html497NLG modules Introvert findings Extravert findings Parameter Intro ExtraContent Single topic Many topics VERBOSITY low highselection Strict selection Think out loud* RESTATEMENTS low highand REPETITIONS low lowstructure Problem talk, Pleasure talk, agreement, CONTENT POLARITY low highdissatisfaction compliment REPETITIONS POLARITY low highCLAIM POLARITY low highCONCESSIONS avg avgCONCESSIONS POLARITY low highPOLARISATION low highPOSITIVE CONTENT FIRST low highSyntactic Few self-references Many self-references SELF-REFERENCES low hightemplates Elaborated constructions Simple constructions* CLAIM COMPLEXITY high lowselection Many articles Few articlesAggregation Many words per Few words per RELATIVE CLAUSES high lowOperations sentence/clause sentence/clause WITH CUE WORD high lowCONJUNCTION low highMany unfilled pauses Few unfilled pauses PERIOD high low...PragmatictransformationsMany nouns, adjectives, prepo-sitions (explicit)Many verbs, adverbs, pronouns(implicit)SUBJECT IMPLICITNESS low highMany negations Few negations NEGATION INSERTION high lowMany tentative words Few tentative words DOWNTONER HEDGES:?SORT OF, SOMEWHAT, QUITE, RATHER,ERR, I THINK THAT, IT SEEMS THAT, ITSEEMS TO ME THAT, I MEANhigh low?AROUND avg avgFormal Informal ?KIND OF, LIKE low highACKNOWLEDGMENTS:?YEAH low high?RIGHT, OK, I SEE, WELL high lowRealism Exaggeration* EMPHASIZER HEDGES:?REALLY, BASICALLY, ACTUALLY, JUSTHAVE, JUST IS, EXCLAMATION low high?YOU KNOW low highNo politeness form Positive face redressment* TAG QUESTION INSERTION low highLower word count Higher word count HEDGE VARIATION low avgHEDGE REPETITION low lowLexical Rich Poor LEXICON FREQUENCY low highchoice Few positive emotion words Many positive emotion words see polarity parametersMany negative emotion words Few negative emotion words see polarity parametersTable 2: Summary of language cues for extraversion, based on Dewaele and Furnham (1999); Furnham(1990); Mehl et al (2006); Oberlander and Gill (2006); Pennebaker and King (1999), as well as PERSON-AGE?s corresponding generation parameters.
Asterisks indicate hypotheses, rather than results.
For detailson aggregation parameters, see Section 4.2.Relations: JUSTIFY (nuc:1, sat:2); JUSTIFY (nuc:1, sat:3);JUSTIFY (nuc:1, sat:4); JUSTIFY (nuc:1, sat:5);JUSTIFY (nuc:1, sat:6)Content: 1. assert(best (Le Marais))2. assert(is (Le Marais, cuisine (French)))3. assert(has (Le Marais, food-quality (good)))4. assert(has (Le Marais, service (good)))5. assert(has (Le Marais, decor (decent)))6. assert(is (Le Marais, price (44 dollars)))Figure 1: A content plan for a recommendation.the selected restaurant(s), supported by a set of satel-lite content items describing their attributes.
See Ta-ble 1.
Claims can be expressed in different ways,such as RESTAURANT NAME is the best, whilethe attribute satellites follow the pattern RESTAU-RANT NAME has MODIFIER ATTRIBUTE NAME,as in Le Marais has good food.
Recommendationsare characterized by a JUSTIFY rhetorical relationassociating the claim with all other content items,which are linked together through an INFER relation.In comparisons, the attributes of multiple restaurantsare compared using a CONTRAST relation.
An op-tional claim about the quality of all restaurants canalso be expressed as the nucleus of an ELABORATErelation, with the rest of the content plan tree as asatellite.3 Content PlanningContent planning selects and structures the contentto be communicated.
Table 2 specifies 10 param-eters hypothesized to affect this process which areexplained below.Content size: Extraverts are more talkative thanintroverts (Furnham, 1990; Pennebaker and King,1999), although it is not clear whether they actu-ally produce more content, or are just redundant andwordy.
Thus various parameters relate to the amountand type of content produced.
The VERBOSITY pa-rameter controls the number of content items se-lected from the content plan.
For example, Alt-5 inTable 1 is terse, while Alt-2 expresses all the items inthe content plan.
The REPETITION parameter addsan exact repetition: the content item is duplicatedand linked to the original content by a RESTATE498rhetorical relation.
In a similar way, the RESTATE-MENT parameter adds paraphrases of content itemsto the plan, that are obtained from the initial hand-crafted generation dictionary (see Section 4.1) andby automatically substituting content words with themost frequent WordNet synonym (see Section 4.4).Alt-9 in Table 1 contains restatements for the foodquality and the atmosphere attributes.Polarity: Extraverts tend to be more positive; in-troverts are characterized as engaging in more ?prob-lem talk?
and expressions of dissatisfaction (Thorne,1987).
To control for polarity, content items aredefined as positive or negative based on the scalarvalue of the corresponding attribute.
The type of cui-sine and neighborhood attributes have neutral polar-ity.
There are multiple parameters associated withpolarity.
The CONTENT POLARITY parameter con-trols whether the content is mostly negative (e.g.X has mediocre food), neutral (e.g.
X is a Thairestaurant), or positive.
From the filtered set ofcontent items, the POLARISATION parameter deter-mines whether the final content includes items withextreme scalar values (e.g.
X has fantastic staff).In addition, polarity can also be implied more sub-tly through rhetorical structure.
The CONCESSIONSparameter controls how negative and positive infor-mation is presented, i.e.
whether two content itemswith different polarity are presented objectively, or ifone is foregrounded and the other backgrounded.
Iftwo opposed content items are selected for a con-cession, a CONCESS rhetorical relation is insertedbetween them.
While the CONCESSIONS param-eter captures the tendency to put information intoperspective, the CONCESSION POLARITY parametercontrols whether the positive or the negative contentis concessed, i.e.
marked as the satellite of the CON-CESS relation.
The last sentence of Alt-3 in Table 1illustrates a positive concession, in which the goodfood quality is put before the high price.Content ordering: Although extraverts use morepositive language (Pennebaker and King, 1999;Thorne, 1987), it is unclear how they position thepositive content within their utterances.
Addition-ally, the position of the claim affects the persuasive-ness of an argument (Carenini and Moore, 2000):starting with the claim facilitates the hearer?s under-standing, while finishing with the claim is more ef-fective if the hearer disagrees.
The POSITIVE CON-TENT FIRST parameter therefore controls whetherpositive content items ?
including the claim ?
appearfirst or last, and the order in which the content itemsare aggregated.
However, some operations can stillimpose a specific ordering (e.g.
BECAUSE cue wordto realize the JUSTIFY relation, see Section 4.2).4 Sentence PlanningSentence planning chooses the linguistic resourcesfrom the lexicon and the syntactic and discoursestructures to achieve the communicative goals spec-ified in the input content plan.
Table 2 specifies foursets of findings and parameters for different aspectsof sentence planning discussed below.4.1 Syntactic template selectionPERSONAGE?s input generation dictionary is madeof 27 Deep Syntactic Structures (DSyntS): 9 forthe recommendation claim, 12 for the comparisonclaim, and one per attribute.
Selecting a DSyntS re-quires assigning it automatically to a point in a threedimensional space described below.
All parametervalues are normalized over all the DSyntS, so theDSyntS closest to the target value can be computed.Syntactic complexity: Furnham (1990) suggeststhat introverts produce more complex constructions:the CLAIM COMPLEXITY parameter controls thedepth of the syntactic structure chosen to representthe claim, e.g.
the claim X is the best is rated as lesscomplex than X is one of my favorite restaurants.Self-references: Extraverts make more self-references than introverts (Pennebaker and King,1999).
The SELF-REFERENCE parameter controlswhether the claim is made in the first person, basedon the speaker?s own experience, or whether theclaim is reported as objective or information ob-tained elsewhere.
The self-reference value is ob-tained from the syntactic structure by counting thenumber of first person pronouns.
For example, theclaim of Alt-2 in Table 1, i.e.
I am sure you wouldlike Le Marais, will be rated higher than Le Maraisisn?t as bad as the others in Alt-5.Polarity: While polarity can be expressed by con-tent selection and structure, it can also be directlyassociated with the DSyntS.
The CLAIM POLARITYparameter determines the DSyntS selected to realizethe claim.
DSyntS are manually annotated for po-larity.
For example, Alt-4?s claim in Table 1, i.e.
LeMarais is the only restaurant that is any good, has alower polarity than Alt-2.4.2 Aggregation operationsSPaRKy aggregation operations are used (See Stentet al (2004)), with additional operations for conces-sions and restatements.
See Table 2.
The probabil-ity of the operations biases the production of com-plex clauses, periods and formal cue words for in-troverts, to express their preference for complex syn-499tactic constructions, long pauses and rich vocabulary(Furnham, 1990).
Thus, the introvert parameters fa-vor operations such as RELATIVE CLAUSE for theINFER relation, PERIOD HOWEVER CUE WORD forCONTRAST, and ALTHOUGH ADVERBIAL CLAUSEfor CONCESS, that we hypothesize to result in moreformal language.
Extravert aggregation produceslonger sentences with simpler constructions and in-formal cue words.
Thus extravert utterances tend touse operations such as a CONJUNCTION to realizethe INFER and RESTATE relations, and the EVEN IFADVERBIAL CLAUSE for CONCESS relations.4.3 Pragmatic transformationsThis section describes the insertion of markers in theDSyntS to produce various pragmatic effects.Hedges: Hedges correlate with introversion (Pen-nebaker and King, 1999) and affect politeness(Brown and Levinson, 1987).
Thus there are param-eters for inserting a wide range of hedges, both af-fective and epistemic, such as kind of, sort of, quite,rather, somewhat, like, around, err, I think that, itseems that, it seems to me that, and I mean.
Alt-5 inTable 1 shows hedges err and it seems to me that.To model extraverts use of more social language,agreement and backchannel behavior (Dewaele andFurnham, 1999; Pennebaker and King, 1999), weuse informal acknowledgments such as yeah, right,ok.
Acknowledgments that may affect introversionare I see, expressing self-reference and cognitiveload, and the well cue word implying reservationfrom the speaker (see Alt-9).To model social connection and emotion weadded mechanisms for inserting emphasizers such asyou know, basically, actually, just have, just is, andexclamations.
Alt-3 in Table 1 shows the insertionof you know and actually.Although similar hedges can be grouped together,each hedge has a unique pragmatic effect.
For ex-ample, you know implies positive-face redressment,while actually doesn?t.
A parameter for each hedgecontrols the likelihood of its selection.To control the general level of hedging, a HEDGEVARIATION parameter defines how many differenthedges are selected (maximum of 5), while the fre-quency of an individual hedge is controlled by aHEDGE REPETITION parameter, up to a maximumof 2 identical hedges per utterance.The syntactic structure of hedges are defined aswell as constraints on their insertion point in the ut-terance?s syntactic structure.
Each time a hedge isselected, it is randomly inserted at one of the inser-tion points respecting the constraints, until the spec-ified frequency is reached.
For example, a constrainton the hedge kind of is that it modifies adjectives.Tag questions: Tag questions are also polite-ness markers (Brown and Levinson, 1987).
Theyredress the hearer?s positive face by claiming com-mon ground.
A TAG QUESTION INSERTION param-eter leads to negating the auxiliary of the verb andpronominalizing the subject, e.g.
X has great foodresults in the insertion of doesn?t it?, as in Alt-8.Negations: Introverts use significantly morenegations (Pennebaker and King, 1999).
Althoughthe content parameters select more negative polaritycontent items for introvert utterances, we also ma-nipulate negations, while keeping the content con-stant, by converting adjectives to the negative oftheir antonyms, e.g.
the atmosphere is nice wastransformed to not nasty in Alt-9 in Table 1.Subject implicitness: Heylighen and Dewaele(2002) found that extraverts use more implicit lan-guage than introverts.
To control the level of implic-itness, the SUBJECT IMPLICITNESS parameter deter-mines whether predicates describing restaurant at-tributes are expressed with the restaurant in the sub-ject, or with the attribute itself (e.g., it has good foodvs.
the food is tasty in Alt-9).4.4 Lexical choiceIntroverts use a richer vocabulary (Dewaele andFurnham, 1999), so the LEXICON FREQUENCY pa-rameter selects lexical items by their normalized fre-quency in the British National Corpus.
WordNetsynonyms are used to obtain a pool of synonyms, aswell as adjectives extracted from a corpus of restau-rant reviews for all levels of polarity (e.g.
the ad-jective tasty in Alt-9 is a high polarity modifier ofthe food attribute).
Synonyms are manually checkedto make sure they are interchangeable.
For example,the content item expressed originally as it has decentservice is transformed to it features friendly servicein Alt-2, and to the servers are nice in Alt-3.5 Experimental Method and HypothesesOur primary hypothesis is that language generatedby varying parameters suggested by psycholinguis-tic research can be recognized as extravert or in-trovert.
To test this hypothesis, three expert judgesevaluated a set of generated utterances as if they hadbeen uttered by a friend responding in a dialogue to arequest to recommend restaurants.
These utteranceshad been generated to systematically manipulate ex-traversion/introversion parameters.The judges rated each utterance for perceived ex-traversion, by answering the two questions measur-500ing that trait from the Ten-Item Personality Inven-tory, as this instrument was shown to be psychome-trically superior to a ?single item per trait?
question-naire (Gosling et al, 2003).
The answers are aver-aged to produce an extraversion rating ranging from1 (highly introvert) to 7 (highly extravert).
Becauseit was unclear whether the generation parameters inTable 2 would produce natural sounding utterances,the judges also evaluated the naturalness of each ut-terance on the same scale.
The judges rated 240 ut-terances, grouped into 20 sets of 12 utterances gen-erated from the same content plan.
They rated onerandomly ordered set at a time, but viewed all 12utterances in that set before rating them.
The ut-terances were generated to meet two experimentalgoals.
First, to test the direct control of the per-ception of extraversion.
2 introvert utterances and2 extravert utterances were generated for each con-tent plan (80 in total) using the parameter valuesin Table 2.
Multiple outputs were generated withboth parameter settings normally distributed with a15% standard deviation.
Second, 8 utterances foreach content plan (160 in total) were generated withrandom parameter values.
These random utterancesmake it possible to: (1) improve PERSONAGE?s di-rect output by calibrating its parameters more pre-cisely; and (2) build a statistical model that selectsutterances matching input personality values after anovergeneration phase (see Section 6.2).
The inter-rater agreement for extraversion between the judgesover all 240 utterances (average Pearson?s correla-tion of 0.57) shows that the magnitude of the differ-ences of perception between judges is almost con-stant (?
= .037).
A low agreement can yield a highcorrelation (e.g.
if all values differ by a constantfactor), so we also compute the intraclass correla-tion coefficient r based on a two-way random effectmodel.
We obtain a r of 0.79, which is significantat the p < .001 level (reliability of average mea-sures, identical to Cronbach?s alpha).
This is com-parable to the agreement of judgments of personalityin Mehl et al (2006) (mean r = 0.84).6 Experimental Results6.1 Hypothesized parameter settingsTable 1 provides examples of PERSONAGE?s out-put and extraversion ratings.
To assess whetherPERSONAGE generates language that can be rec-ognized as introvert and extravert, we did a indepen-dent sample t-test between the average ratings of the40 introvert and 40 extravert utterances (parameterswith 15% standard deviation as in Table 2).
Table 3Rating Introvert Extravert RandomExtraversion 2.96 5.98 5.02Naturalness 4.93 5.78 4.51Table 3: Average extraversion and naturalness rat-ings for the utterances generated with introvert, ex-travert, and random parameters.shows that introvert utterances have an average rat-ing of 2.96 out of 7 while extravert utterances havean average rating of 5.98.
These ratings are signifi-cantly different at the p < .001 level (two-tailed).In addition, if we divide the data into two equal-width bins around the neutral extravert rating (4 outof 7), then PERSONAGE?s utterance ratings fall inthe bin predicted by the parameter set 89.2% of thetime.
Extravert utterance are also slightly more nat-ural than the introvert ones (p < .001).Table 3 also shows that the 160 random parame-ter utterances produce an average extraversion ratingof 5.02, both significantly higher than the introvertset and lower than the extravert set (p < .001).
In-terestingly, the random utterances, which may com-bine linguistic variables associated with both intro-verts and extraverts, are less natural than the intro-vert (p = .059) and extravert sets (p < .001).6.2 Statistical models evaluationWe also investigate a second approach: overgener-ation with random parameter settings, followed byranking via a statistical model trained on the judges?feedback.
This approach supports generating utter-ances for any input extraversion value, as well as de-termining which parameters affect the judges?
per-ception.We model perceived personality ratings (1 .
.
.
7)with regression models from the Weka toolbox (Wit-ten and Frank, 2005).
We used the full dataset of160 averaged ratings for the random parameter utter-ances.
Each utterance was associated with a featurevector with the generation decisions for each param-eter in Section 2.
To reduce data sparsity, we selectfeatures that correlate significantly with the ratings(p < .10) with a coefficient higher than 0.1.Regression models are evaluated using the meanabsolute error and the correlation between the pre-dicted score and the actual average rating.
Table 4shows the mean absolute error on a scale from 1 to7 over ten 10-fold cross-validations for the 4 bestregression models: Linear Regression (LR), M5?model tree (M5), and Support Vector Machines (i.e.SMOreg) with linear kernels (SMO1) and radial-501basis function kernels (SMOr).
All models signif-icantly outperform the baseline (0.83 mean absoluteerror, p < .05), but surprisingly the linear modelperforms the best with a mean absolute error of 0.65.The best model produces a correlation coefficient of0.59 with the judges?
ratings, which is higher thanthe correlations between pairs of judges, suggestingthat the model performs as well as a human judge.Metric LR M5 SMO1 SMOrAbsolute error 0.65 0.66 0.72 0.70Correlation 0.59 0.56 0.54 0.57Table 4: Mean absolute regression errors (scale from1 to 7) and correlation coefficients over ten 10-foldcross-validations, for 4 models: Linear Regression(LR), M5?
model tree (M5), Support Vector Ma-chines with linear kernels (SMO1) and radial-basisfunction kernels (SMOr).
All models significantlyoutperform the mean baseline (0.83 error, p < .05).The M5?
regression tree in Figure 2 assigns a rat-ing given the features.
Verbosity plays the most im-portant role: utterances with 4 or more content itemsare modeled as more extravert.
Given a low ver-bosity, lexical frequency and restatements determinethe extraversion level, e.g.
utterances with less than4 content items and infrequent words are perceivedas very introverted (rating of 2.69 out of 7).
Forverbose utterances, the you know hedge indicatesextraversion, as well as concessions, restatements,self-references, and positive content.
Although rel-atively simple, these models are useful for identify-ing new personality markers, as well as calibratingparameters in the direct generation model.7 Discussion and ConclusionsWe present and evaluate PERSONAGE, a parame-terizable generator that produces outputs that varyalong the extraversion personality dimension.
Thispaper makes four contributions:1.
We present a systematic review of psycholinguistic find-ings, organized by the NLG reference architecture;2.
We propose a mapping from these findings to generationparameters for each NLG module and a real-time imple-mentation of a generator using these parameters2.
To ourknowledge this is the first attempt to put forward a sys-tematic framework for generating language that manifestspersonality;3.
We present an evaluation experiment showing that we cancontrol the parameters to produce recognizable linguis-tic variation along the extraversion personality dimen-sion.
Thus, we show that the weak correlations reported2An online demo is available atwww.dcs.shef.ac.uk/cogsys/personage.htmlin other genres of language, and for self-reports ratherthan observers, carry over to the production of single eval-uative utterances with recognizable personality in a re-stricted domain;4.
We present the results of a training experiment showingthat given an output, we can train a model that matcheshuman performance in assigning an extraversion rating tothat output.Some of the challenges discussed in the introduc-tion remain.
We have shown that evaluative utter-ances in the restaurant domain can manifest person-ality, but more research is needed on which speechacts recognisably manifest personality in a restricteddomain.
We also showed that the mapping we hy-pothesised of findings to generation parameters waseffective, but there may be additional parametersthat the psycholinguistic findings could be mappedto.Our work was partially inspired by the ICONO-CLAST and PAULINE parameterizable generators(Bouayad-Agha et al, 2000; Hovy, 1988), whichvary the style, rather than the personality, of the gen-erated texts.
Walker et al (1997) describe a gen-erator intended to affect perceptions of personality,based on Brown and Levinson?s theory of polite-ness (Brown and Levinson, 1987), that uses someof the linguistic constructions implemented here,such as tag questions and hedges, but it was neverevaluated.
Research by Andre?
et al (2000); Piwek(2003) uses personality variables to affect the lin-guistic behaviour of conversational agents, but theydid not systematically manipulate parameters, andtheir generators were not evaluated.
Reeves andNass (1996) demonstrate that manipulations of per-sonality affect many aspects of user?s perceptions,but their experiments use handcrafted utterances,rather than generated utterances.
Cassell and Bick-more (2003) show that extraverts prefer systems uti-lizing discourse plans that include small talk.
Paivaand Evans?
trainable generator (2005) produces out-puts that correspond to a set of linguistic variablesmeasured in a corpus of target texts.
Their methodis similar to our statistical method using regressiontrees, but provides direct control.
The method re-ported in Mairesse and Walker (2005) for trainingindividualized sentence planners ranks the outputsproduced by an overgeneration phase, rather than di-rectly predicting a scalar value, as we do here.
Theclosest work to ours is probably Isard et al?s CRAG-2 system (2006), which overgenerates and ranks us-ing ngram language models trained on a corpus la-belled for all Big Five personality dimensions.
How-ever, CRAG-2 has no explicit parameter control, andit has yet to be evaluated.502Max BNC Frequency RestatementsVerbosity> 0.022.69 3.52 4.474.123.26> 0.1> 2.5> 0.64<= 0.643.74Max BNC FrequencyConcessions> 0.87Self?references Restatements> 0.5 > 0.55.33 Verbosity5.08 5.53> 5.55.85> 0.55.00> 0.5.. <= 0.02<= 2.5<= 0.5<= 0.5<= 0.5<= 0.5<= 0.5<= 5.5> 0.5> 3.5<= 0.87> 0.5<= 0.1Max BNC FrequencyVerbosityVerbosity> 4.5<= 4.5.Infer aggregation:Period<= 0.54.52<= 3.5Hedge: ?you know?5.93Content5.54 5.78PolarityFigure 2: M5?
regression tree.
The output ranges from 1 to 7, where 7 means strongly extravert.In future work, we hope to directly compare thedirect generation method of Section 6.1 with theovergenerate and rank method of Section 6.2, and touse these results to refine PERSONAGE?s parame-ter settings.
We also hope to extend PERSONAGE?sgeneration capabilities to other Big Five traits, iden-tify additional features to improve the model?s per-formance, and evaluate the effect of personality vari-ation on user satisfaction in various applications.ReferencesE.
Andre?, T. Rist, S. van Mulken, M. Klesen, and S. Baldes.2000.
The automated design of believable dialogues foranimated presentation teams.
In Embodied conversationalagents, p. 220?255.
MIT Press, Cambridge, MA.N.
Bouayad-Agha, D. Scott, and R. Power.
2000.
Integratingcontent and style in documents: a case study of patient in-formation leaflets.
Information Design Journal, 9:161?176.P.
Brown and S. Levinson.
1987.
Politeness: Some universalsin language usage.
Cambridge University Press.G.
Carenini and J. D. Moore.
2000.
A strategy for generatingevaluative arguments.
In Proc.
of International Conferenceon Natural Language Generation, p. 47?54.J.
Cassell and T. Bickmore.
2003.
Negotiated collusion: Model-ing social language and its relationship effects in intelligentagents.
User Modeling and User-Adapted Interaction, 13(1-2):89?132.J-M. Dewaele and A. Furnham.
1999.
Extraversion: the unlovedvariable in applied linguistic research.
Language Learning,49(3):509?544.A.
Furnham.
1990.
Language and personality.
In Handbook ofLanguage and Social Psychology.
Winley.S.
D. Gosling, P. J. Rentfrow, and W. B. Swann Jr. 2003.
A verybrief measure of the big five personality domains.
Journal ofResearch in Personality, 37:504?528.F.
Heylighen and J-M. Dewaele.
2002.
Variation in the con-textuality of language: an empirical measure.
Context inContext, Foundations of Science, 7(3):293?340.E.
Hovy.
1988.
Generating Natural Language under PragmaticConstraints.
Lawrence Erlbaum Associates.A.
Isard, C. Brockmann, and J. Oberlander.
2006.
Individualityand alignment in generated dialogues.
In Proc.
of INLG.B.
Lavoie and O. Rambow.
1997.
A fast and portable realizerfor text generation systems.
In Proc.
of ANLP.A.
Loyall and J. Bates.
1997.
Personality-rich believable agentsthat use language.
In Proc.
of the First International Confer-ence on Autonomous Agents, p. 106?113.F.
Mairesse and M. Walker.
2005.
Learning to personalize spo-ken generation for dialogue systems.
In Proc.
of the Inter-speech - Eurospeech, p. 1881?1884.M.
Mehl, S. Gosling, and J. Pennebaker.
2006.
Personality inits natural habitat: Manifestations and implicit folk theoriesof personality in daily life.
Journal of Personality and SocialPsychology, 90:862?877.W.
T. Norman.
1963.
Toward an adequate taxonomy of per-sonality attributes: Replicated factor structure in peer nom-ination personality rating.
Journal of Abnormal and SocialPsychology, 66:574?583.J.
Oberlander and A. Gill.
2006.
Language with character: Astratified corpus comparison of individual differences in e-mail communication.
Discourse Processes, 42:239?270.D.
Paiva and R. Evans.
2005.
Empirically-based control of nat-ural language generation.
In Proc.
of ACL.J.
W. Pennebaker and L. A.
King.
1999.
Linguistic styles: Lan-guage use as an individual difference.
Journal of Personalityand Social Psychology, 77:1296?1312.P.
Piwek.
2003.
A flexible pragmatics-driven language genera-tor for animated agents.
In Proc.
of EACL.B.
Reeves and C. Nass.
1996.
The Media Equation.
Universityof Chicago Press.E.
Reiter and R. Dale.
2000.
Building Natural Language Gen-eration Systems.
Cambridge University Press.A.
Stent, R. Prasad, and M. Walker.
2004.
Trainable sentenceplanning for complex information presentation in spoken di-alog systems.
In Proc.
of ACL.A.
Thorne.
1987.
The press of personality: A study of conver-sations between introverts and extraverts.
Journal of Person-ality and Social Psychology, 53:718?726.M.
Walker, J. Cahn, and S. Whittaker.
1997.
Improvising lin-guistic style: Social and affective bases for agent personality.In Proc.
of the Conference on Autonomous Agents.I.
H. Witten and E. Frank.
2005.
Data Mining: Practical ma-chine learning tools and techniques.
Morgan Kaufmann.503
