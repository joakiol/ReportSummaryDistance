Coling 2008: Companion volume ?
Posters and Demonstrations, pages 31?34Manchester, August 2008Detecting Erroneous Uses of Complex Postpositions in anAgglutinative LanguageArantza D?az de Ilarraza Koldo Gojenola Maite OronozIXA NLP group.
University of the Basque Countryjipdisaa@si.ehu.es koldo.gojenola@ehu.es maite.oronoz@ehu.esAbstractThis work presents the development of asystem that detects incorrect uses of com-plex postpositions in Basque, an aggluti-native language.
Error detection in com-plex postpositions is interesting because:1) the context of detection is limited to afew words; 2) it implies the interaction ofmultiple levels of linguistic processing(morphology, syntax and semantics).
So,the system must deal with problems rang-ing from tokenization and ambiguity tosyntactic agreement and examination oflocal contexts.
The evaluation was per-formed in order to test both incorrect usesof postpositions and also false alarms.11 Structure of complex postpositionsBasque postpositions play a role similar toEnglish prepositions, with the difference thatthey appear at the end of noun phrases orpostpositional phrases.
They are defined as?forms that represent grammatical relationsamong phrases appearing in a sentence?
(Euskaltzaindia, 1994).
There are two main typesof postpositions in Basque: (1) a suffix appendedto a lemma and, (2) a suffix followed by a lemma(main element) that can also be inflected.
(1) etxe-tikhouse-(from the)from the house(2) etxe-aren gain-etikhouse-(of the)  top-(from the)from the top of the houseThe last type of elements has been termed ascomplex postposition.
We will use this term toname the whole sequence of two words involved,and not just to refer to the second element.
Com-?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.plex postpositions can be described as:(3) lemma1 + (suffix1 + lemma2 + suffix2)In these constructions, the second lemma is fixedfor each postposition, while the first lemma al-lows for much more variation, ranging fromevery noun to some specific semantic classes.The above description (3) is intended to stress(with parentheses) the fact that the combinationof both suffixes with the second lemma acts as acomplex case-suffix that is ?appended?
to thefirst lemma.
Both suffixes present different com-binations of number and case, which can agree inseveral ways, depending on the lemma, case orcontextual factors.
Table 1 shows the differentvariants of two complex postpositions, derivedfrom the lemmas bitarte and aurre.
For example,the lemma bitarte is polysemous (?means, bymeans of, instrument, while (temporal), be-tween?).
Multiple factors affect the correctnessof a postposition, including morphological andsyntactic constraints.
We also discovered a num-ber of relevant contextual factors, which are notexplicitly accounted for in standard grammars.2 The corpusThe detection of erroneous uses of complexpostpositions needs first a corpus that can servefor both development and evaluation of the sys-tem.
To obtain such a corpus is a labor-intensivetask, to which it must be added the examinationand markup of incorrect examples.
The use of abig ?correct?
corpus will allow us to test our sys-tem negatively, thoroughly testing the system?sbehavior in respect to false alarms.
We used anautomatic system for detecting complex postpo-sitions in order to get development and test data.There are two text types: Newspaper corpora(henceforth NC, 8,207,919 word-forms) that issubject to an edition process and style guides,and Learner corpora (LC, 994,658 word-forms),which come from texts written by learners ofBasque and University students.
These texts aremore ?susceptible?
of containing errors.31We decided to study those types of postpositionsthat appear most frequently in texts, those con-taining the following lemmas as their second ele-ment: arte, aurre, bitarte, buruz, and zehar2.
Weselected these postpositions given that they arewell documented in grammar books, with de-tailed descriptions of their correct and incorrectuses (e.g.
see Table 1 for bitarte), and also thatthey are very frequent in both types of texts.Each kind of syntactic error occurs with verylow frequency and, therefore, big corpora areneeded for evaluation and testing3.
Even if suchcorpora are available, to obtain naturally occur-ring test data, hundreds of texts should be manu-ally examined and marked.
As a result, we de-cided to only manually mark errors in Learners?Corpora (LC), because NC, an order of magni-tude bigger than LC, is presumed to contain lesserrors.
This implies that we will be able to meas-ure precision4 in both corpora, while recall5 willonly be evaluated in LC.
Table 2 shows thenumber of sentences used for development (60%of each corpus) and test (40%).
We treated LCand NC separately, as they presumably differ inthe number of errors.3 Linguistic Processing ToolsThe corpus was automatically analyzed by meansof several linguistic processors: a morphosyntac-tic analyzer (Aduriz et al, 2000), EUSTAGGER,the lemmatizer/tagger for Basque, and the Con-straint Grammar parser (CG, Tapanainen, 1996)for morphological disambiguation.2As each lemma has several meanings depending on eachvariant, we will not give their translation equivalence.3We made an estimate of more than 1% of elements ingeneral corpora being complex postpositions.4Number of errors correctly identified by the system / totalnumber of elements identified as erroneous.5Number of errors correctly identified by the system / totalnumber of real errors.Added to these, we also used other resources:?
Grammar books which describe errors inpostpositions (Zubiri & Zubiri, 1995).?
Place names.
Two of the selected postposi-tions (arte, aurre) are used in expressionsthat denote temporal and spatial coordinates,but their variants impose different restric-tions and agreement (case, number).
In orderto recognize common nouns that refer to aspatial context, we made use of a new lexicalresource: electronic versions of dictionaries(Sarasola, 2007; Elhuyar, 2000).
168 and 242words were automatically acquired fromeach dictionary.
To this, we added propernames corresponding to places.?
Animate/inanimate distinction.
Regardingpostpositions formed with aurre, Zubiri et al(1995) point out that ?typically the previousword takes the genitive case, although it canalso be used without a case mark with inani-mate nouns?.
For this reason, we used a dic-tionary enriched with semantic features, suchas animate/inanimate, time or instrument.We selected 1,642 animate words.
We alsoadded person names and pronouns.4 Rule designThe system will assign an error-tag to thoseword-forms that show the presence of an incor-rect use of a postposition.
We use the CG formal-ism (Tapanainen, 1996) for this task.
CG allowsNC LCDev Test Dev Testarte 7769 5179 1209 806aurre 8129 5420 1157 771bitarte 3846 2564 772 514buruz 5435 3623 560 373zehar 1500 1000 186 126Total 26679 17786 3884 2590Errors   60 29Table 2.
Number of sentences in developmentand test sets, including the errors in LC.lemma2 suffix1 suffix 2 Examples-en (genitive) -z (instrumental) etxearen bitartez  (by means of the house)-ra (alative) -n (inessive, sg.)
etxera bitartean  (while going to the house)-a (absolutive, sg.)
-n (inessive, sg.)
ordubata bitartean (around one o?clock)-?
(no case) -n (inessive, sg.)
meza bitartean (while attending mass)-en (genitive) -n (inessive, sg.)
mendeen bitartean (between those centuries)-?
(no case) -?
/ko (no case/genitive) Lau hektarea bitarte  (in a range of four hectares)-ak (absolutive, pl.)-?
/ko (no case/genitive) seiak bitarte (around six o?clock)bitarte(noun)-ra (alative)-?
/ko (no case/genitive) etxera bitarte (in the way home)-?
/-en (nocase/genitive)-n/-ra/-tik/-ko (inessive/ ala-tive/ ablative/ genitive)eliza aurrean (in front of the church) aurre(noun)-tik (ablative) -ra (alative) hemendik aurrera (from here onwards)Table 1.
Complex postpositions for bitarte and aurre.32the definition of complex contextual rules in or-der to detect error patterns by means of mappingrules and a notation akin to regular expressions.Fig.
1 shows a general overview of the system.Syntactic constraints are encoded by means ofCG rules using morphosyntactic categories (partof speech, case, number, ?).
Semantic restric-tions are enforced by lists of words belonging toa semantic group.
All of the five postpositionshave clear requirements about the combinationsof case and number in the surrounding context.Overall, the CG grammar contains 30 rules forthe set of 5 postpositions.
We found thatalthough the study of authoritative grammaticaldescriptions was exhaustive, the grammarians?descriptions of correct and incorrect uses refermainly to morphology and syntax.
Nevertheless,we discovered empirically that most of the rulesneeded to be extended with several classes ofsemantic restrictions.
Among others, distinctionswere needed for animate nouns, place names, orseveral classes of time expressions, depending oneach different variant of each postposition.5 EvaluationThe rules were applied both to the (presumably)correct newspapers texts (NC) and to the learn-ers?
texts (LC).
The actual errors in LC weremarked in advance but not in NC, which meansthat recall can only be evaluated in LC.
Table 3shows the main results including all the selectedfive postpositions.
The LC corpus contains 60and 29 error instances in development and testcorpus, respectively.
If we concentrate on preci-sion, Table 4 shows the overall precision resultsfor the total of errors detected in the test corpora.When we consider the whole set of postpositionsprecision is 50.5%, giving 42 false alarms out of85 detected elements.
We performed an analysisof false alarms which showed several causes:?
Morphological ambiguity (43% of alarms).?
Semantic ambiguity (28%).
We included setsof context words to identify the correctsenses, but it still causes many false alarms.?
Syntactic ambiguity (22%).
The false alarmsare mostly concerned with coordination.?
Tokenization errors (7%).As most of the false alarms came from postpo-sitions formed with arte, the most ambiguousone, we counted the errors when dealing onlywith the other four postpositions, giving a betterprecision (70.4%, second row in Table 4), al-though detecting less true errors.
If the systemonly deals with three postpositions (third row inTable 4), then precision reaches 78.3%.
Johan-nessen et al (2002) note that the acceptable num-ber of false alarms in a grammar checker shouldnot exceed 30%, that is, at least 70% of allalarms had to report true errors.
Our experimentsshow that our system performs within that limit,albeit restricting its application to the most ?prof-itable?
postpositions.
Although the number ofrules varies widely (from 15 rules for arte to 2rules in the case of zehar) their effectivenessgreatly depends on the complexity and ambiguityof the contextual factors.
For that reason, artepresents the worst precision results even when itcontains by far the biggest set of detection rules.On the other hand, zehar, with 2 rules, presentsthe best precision, due to its limited ambiguity.So, to deal with the full set postpositions (severalworks estimate more than 150), it will be moreprofitable to make a preliminary study on ambi-guities and variants for each postposition.6 Related workKukich (1992) surveys the state of the art in syn-tactic error detection.
She estimates that a pro-portion of all the errors varying between 25%and over 50% are valid words.
Atwell and ElliottPostpositions Precisionarte, aurre, bitarte, buruz, zehar 50.5% (43/85)aurre, bitarte, buruz, zehar 70.4% (31/44)bitarte, buruz, zehar 78.3% (29/37)Table 4.
Precision for the test sets (NC + LC).NC LCDev Test Dev TestSentences 26679 17786 3884 2590Errors - - 60 29Undetected - - 10 10Detected 30 24 50 19False alarms 45 33 2 9Recall - - 83% 65%Precision 40% 42% 96% 67%Table 3.
Evaluation results.SentencesMorphologicalanalysisConstraint GrammarparserNo Error / Error TypeFigure 1.
General architecture.Error detectiongrammarPlacenounsAnimatenouns?33(1987) concluded that 55% of them are local syn-tactic errors (detectable by an examination of thelocal syntactic context), 18% are due to globalsyntactic errors (which need a full parse of thesentence), and 27% are semantic errors.
Regard-ing their treatment, there have been proposalsranging from error patterns (Kukich 1992; Gold-ing and Schabes 1996), in the form of hand-coded rules or automatically learned ones, to sys-tems that integrate syntactic analysis.
(Chodorow et al, 2007) present a system fordetecting errors in English prepositions usingmachine learning.
Although both English prepo-sitions and Basque postpositions have in somepart relation with semantic features, Basquepostpositions are, in our opinion, qualitativelymore complex, as they are distributed across twowords, and they also show different kinds of syn-tactic agreement in case and number, togetherwith a high number of variants.
This is the mainreason why we chose a knowledge-based method.7 ConclusionsWe have presented a system for the detection oferrors in complex postpositions in Basque.
Al-though at first glance it could seem that postposi-tions imply the examination of two consecutivewords, a posterior analysis showed that they of-fer rich and varied contexts of application, re-quiring the inspection of several context words,albeit not enough to need a full syntactic or se-mantic analysis of sentences.
The system uses avaried set of linguistic resources, ranging frommorphological analysis to specialized lexical re-sources.
As the detection of these errors implies adetailed and expert linguistic knowledge, the sys-tem uses a purely knowledge-based approach.A considerable effort has been invested in thecompilation of a corpus that provides a testbedfor the system, which should be representativeenough as to predict the behaviour of the systemin an environment of a grammar checker.
Forthat reason, we have tried to put a real emphasison avoiding false alarms, that is, treating also lotsof correct instances.
The results show that goodprecision can be obtained.
Regarding recall, ourexperiments do not allow to make an estimation,as the NC test corpora is too big to perform adetailed examination.
However, the LC corporacan give us an upper bound of 65% (see Table 3).This work also shows that the use of purelymorphosyntactic information is not enough forthe detection of errors in postpositions.
For thatreason we were forced to also include severaltypes of semantic features into the system.
Onthe other hand, the process of automatic errordetection has also helped us to explore new setsof semantic distinctions.
So, the process of errordetection has helped us to organize concepts intosets of semantically related elements, and canserve to make explicit types of knowledge thatcan be used to enrich other linguistic resources.We can conclude saying that descriptive lin-guistics could benefit from error diagnosis anddetection, as this could help to deeply understandthe linguistic descriptions of postpositions, whichare done at the moment mainly by means ofmorphosyntactic information, insufficient to givean account of the involved phenomena.AcknowledgementsThis research is supported by the University ofthe Basque Country (GIU05/52) and the BasqueGovernment (ANHITZ project, IE06-185).ReferencesAduriz I., Agirre E., Aldezabal I., Alegria I., ArregiX., Arriola J., Artola X., Gojenola K., SarasolaK.
2000.
A Word-grammar based morphologicalanalyzer for agglutinative languages.
COLING-00.Atwell E., Elliott S. (1987) Dealing with Ill-FormedEnglish Text.
In The Computational Analysis ofEnglish: a Corpus-Based Approach.
Longman.Chodorow M., Tetreault J. and Han N. 2007.
Detec-tion of Grammatical Errors Involving Prepositions.4th ACL-SIGSEM Workshop on Prepositions.D?az de Ilarraza A., Gojenola K., Oronoz M.  2008.Detecting Erroneous Uses of Complex Postposi-tions in an Agglutinative Language.
Internal report(extended version).
(https://ixa.si.ehu.es/Ixa/Argitalpenak)Elhuyar.
2000.
Modern Basque Dictionary.
Elkar.Euskaltzaindia.
1994.
Basque Grammar: First Steps(in Basque).
Euskaltzaindia.Golding A. and Schabes.
Y.
(1996) Combining tri-gram-based and feature-based methods for context-sensitive spelling correction.
ACL 1996.Johannessen J.B., Hagen K., and Lane P. 2002.
Theperformance of a grammar checker with deviantlanguage input.
Proceedings of COLING, Taiwan.Kukich K. 1992.
Techniques for automatically cor-recting words in text.
ACM Computing Surveys.Tapanainen P. 1996.
The Constraint Grammar parserCG-2.
Publications of the Univ.
of Helsinki, 27.Sarasola, Ibon.
2007.
Basque Dictionary (in Basque).Donostia : Elkar, L.G.
ISBN 978-84-9783-258-8.Zubiri I. and  Zubiri E. 1995.
E. Euskal GramatikaOsoa (in Basque).
Didaktiker, Bilbo.34
