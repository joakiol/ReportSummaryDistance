Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 600?608,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsPrenominal Modifier Ordering via Multiple Sequence AlignmentAaron DunlopOregon Health & Science UniversityPortland, ORdunlopa@cslu.ogi.eduMargaret MitchellUniversity of AberdeenAberdeen, Scotland, U.K.m.mitchell@abdn.ac.ukBrian RoarkOregon Health & Science UniversityPortland, ORroark@cslu.ogi.eduAbstractProducing a fluent ordering for a set ofprenominal modifiers in a noun phrase(NP) is a problematic task for natural lan-guage generation and machine translationsystems.
We present a novel approachto this issue, adapting multiple sequencealignment techniques used in computa-tional biology to the alignment of modi-fiers.
We describe two training techniquesto create such alignments based on rawtext, and demonstrate ordering accuraciessuperior to earlier reported approaches.1 IntroductionNatural language generation and machine trans-lation systems must produce text which not onlyconforms to a reasonable grammatical model,but which also sounds smooth and natural toa human consumer.
Ordering prenominal mod-ifiers in noun phrases is particularly difficultin these applications, as the rules underlyingthese orderings are subtle and not well under-stood.
For example, the phrase ?big red ball?seems natural, while ?red big ball?
seems moremarked, suitable only in specific contexts.
Thereis some consensus that the order of prenom-inal modifiers in noun phrases is governed inpart by semantic constraints, but there is noagreement on the exact constraints necessary tospecify consistent orderings for any given set ofmodifiers.
General principles of modifier order-ing based on semantic constraints also fall shorton larger domains, where it is not always clearhow to map prenominal modifiers to proposedsemantic groups.With the recent advantages of large corporaand powerful computational resources, workon automatically ordering prenominal modifiershas moved away from approaches based on gen-eral principles, and towards learning orderingpreferences empirically from existing corpora.Such approaches have several advantages: (1)The predicted orderings are based on prior evi-dence from ?real-world?
texts, ensuring that theyare therefore reasonably natural.
(2) Many (ifnot all) prenominal modifiers can be ordered.
(3) Expanding the training data with more andlarger corpora often improves the system with-out requiring significant manual labor.In this paper, we introduce a novel approachto prenominal modifier ordering adapted frommultiple sequence alignment (MSA) techniquesused in computational biology.
MSA is generallyapplied to DNA, RNA, and protein sequences,aligning three or more biological sequences in or-der to determine, for example, common ancestry(Durbin et al, 1999; Gusfield, 1997; Carrillo andLipman, 1988).
MSA techniques have not beenwidely applied in NLP, but have produced somepromising results for building a generation map-ping dictionary (Barzilay and Lee, 2002), para-phrasing (Barzilay and Lee, 2003), and phonerecognition (White et al, 2006).We believe that multiple sequence alignmentis well-suited for aligning linguistic sequences,and that these alignments can be used to predictprenominal modifier ordering for any given setof modifiers.
Our technique utilizes simple fea-tures within the raw text, and does not requireany semantic information.
We achieve good per-formance using this approach, with results com-petitive with earlier work (Shaw and Hatzivas-siloglou, 1999; Malouf, 2000; Mitchell, 2009) andhigher recall and F-measure than that reportedin Mitchell (2009) when tested on the same cor-pus.6002 Related workIn one of the first attempts at automatically or-dering prenominal modifiers, Shaw and Hatzi-vassiloglou (1999) present three empirical meth-ods to order a variety of prenominal modifiertypes.
Their approach provides ordering deci-sions for adjectives, gerunds (such as ?running?in ?running man?
), and past participles (suchas ?heated?
in ?heated debate?
), as well as formodifying nouns (such as ?baseball?
in ?base-ball field?).
A morphology module transformsplural nouns and comparative/superlative formsinto their base forms, increasing the frequencycounts for each modifier.
We will briefly re-cap their three methods, which are categorizedas the direct evidence method, the transitivitymethod, and the clustering method.Given prenominal modifiers a and b in a train-ing corpus, the direct evidence method com-pares frequency counts of the ordered sequences<a,b> and <b,a>.
This approach works well,but is limited by data sparsity; groups of two ormore modifiers before a noun are relatively in-frequent in traditional corpora, and finding thesame pair of modifiers together more than onceis particularly rare.To overcome this issue, Shaw and Hatzi-vassiloglou?s transitivity and clustering meth-ods make inferences about unseen orderingsamong prenominal modifiers.
In the transitiv-ity method, given three modifiers a,b,c, where aprecedes b and b precedes c, the model concludesthat a precedes c. The clustering method calcu-lates a similarity score between modifiers basedon where the modifiers occur in relation to theother modifiers in the corpus.
Those modifiersthat are most similar are clustered together, andordering decisions can be made between modi-fiers in separate clusters.
All three approachesare designed to order pairs of modifiers; it is un-clear how to extend these approaches to ordergroups larger than a pair.Shaw and Hatzivassiloglou find that NPs withonly adjectives as modifiers (including gerundsand past participles) are considerably easier toorder than those which contain both adjectivesand nouns.
They also find large differences inaccuracy across domains; their systems achievemuch lower overall accuracy on financial text(the Wall Street Journal (WSJ) corpus (Marcuset al, 1999)) than on medical discharge sum-maries.Looking at all modifier pairs, the authorsachieve their highest prediction accuracy of90.7% using the transitivity technique on a med-ical corpus.
We do not have access to this cor-pus, but we do have access to the WSJ corpus,which provides a way to compare our methods.On this corpus, their model produces predic-tions for 62.5% of all modifier pairs and achieves83.6% accuracy when it is able to make a predic-tion.
Random guessing on the remainder yieldsan overall accuracy of 71.0%.Malouf (2000) also examines the problem ofprenominal modifier ordering.
He too proposesseveral statistical techniques, achieving resultsranging from 78.3% to 91.9% accuracy.
Heachieves his best results by combining memory-based learning and positional probability tomodifiers from the first 100 million tokens ofthe BNC.
However, this evaluation is limited tothe ordering of prenominal adjectives, which is aconsiderably simpler task than ordering all typesof prenominal modifiers.
Malouf?s approachesare also limited to ordering pairs of modifiers.Mitchell (2009) proposes another approach,grouping modifiers into classes and orderingbased on those classes.
A modifier?s class is as-signed based on its placement before a noun,relative to the other modifiers it appears with.Classes are composed of those modifiers thattend to be placed closer to the head noun, thosemodifiers that tend to be placed farther from thehead noun, etc., with each class correspondingto a general positional preference.
Unlike earlierwork, these classes allow more than one orderingto be proposed for some pairs of modifiers.Combining corpora of various genres,Mitchell?s system achieves a token precisionof 89.6% (see Section 4 for discussion andcomparison of various evaluation metrics).However, the model only makes predictions for74.1% of all modifier pairs in the test data, sorecall is quite low (see Tables 4 and 6).Overall, previous work in noun-phrase order-601ing has produced impressive accuracies in somedomains, but currently available systems tendto adapt poorly to unseen modifiers and do notgeneralize well to unseen domains.3 Methods3.1 Multiple Sequence AlignmentMultiple sequence alignment algorithms alignsequences of discrete tokens into a series ofcolumns.
They attempt to align identical oreasily-substitutable tokens within a column, in-serting gaps when such gaps will result in a bet-ter alignment (more homogeneous token assign-ments within each column).
For example, con-sider the simple alignment shown in Table 1.The two sequences ?GAACTGAT?
and ?AAGT-GTAT?
are aligned to maximize the number ofidentical items that appear in the same column,substituting tokens (column 3), and insertinggaps (columns 1 and 6)1.A full MSA is generally constructed by itera-tively aligning each new sequence with an identi-cal or similar sequence already in the MSA (so-called ?progressive alignment?).
The costs oftoken substitution are often taken from a hand-tuned substitution matrix.
A cost may also beassociated with inserting a gap into the exist-ing MSA (a ?gap penalty?).
Once the full MSAhas been constructed, a Position Specific ScoreMatrix (PSSM) can be induced, in which eachtoken (including a special gap token) is assigneda separate alignment cost for each column.
Anunseen sequence can then be aligned with thefull MSA by Viterbi search.Predicting sequence ordering within a nounphrase is a natural application for MSA tech-niques, and it seems reasonable to propose thataligning an unseen set of modifiers with such anMSA model will yield acceptable orderings.
Ta-ble 2 illustrates how MSA may be applied tomodifiers before a noun.
Given an NP precededby modifiers hungry, big, and Grizzly, alignmentof the modifiers with NPs seen in the trainingcorpus determines the prenominal ordering bighungry Grizzly.
We then align every permuta-1See Durbin et al (1999) for details on standard align-ment techniques.G A C T G - A T- A G T G T A T1 2 3 4 5 6 7 8Table 1: Alignment of the two DNA sequences?GAACTGAT?
and ?AAGTGTAT?.small clumsy black bearbig - black cowtwo-story - brown housebig clumsy - bullsmall fuzzy brown ducklarge - green housebig hungry Grizzly bearTable 2: Example noun-phrase alignment.tion of the NP and choose the best-scoring align-ment.The vocabulary for a linguistic alignment islarge enough to render a hand-tuned substitu-tion matrix impractical, so we instead constructa cost function based on features of the tokenunder consideration and those of the other to-kens already aligned in a column.We know of no prior work on methods fortraining such an alignment.
We present andcompare two training methods, each of whichproduces competitive ordering accuracies.
Bothtraining methods share the feature-set describedin Table 3.
In each case, we train an MSA byaligning each instance in the training data.3.2 Maximum Likelihood TrainingIn our alignment approach, the features listed inTable 3 are grouped into several classes.
All ob-served words are a class, all observed stems area class (Porter, 1980), and so on.
We treat eachindicator feature as a separate class, and makethe assumption that classes are independent ofone another.
This assumption is clearly false,but serves as a reasonable first approximation,similar to the independence assumption in Na?
?veBayesian analysis.
After aligning each instance,we estimate the probability of a feature appear-ing in a column as the simple maximum like-lihood estimate given the observed occurrences602Identity FeaturesWord TokenStem Word stem, derived by the Porter StemmerLength ?Binned?
length indicators: 1, 2, 3, 4, 5-6, 7-8, 9-12, 13-18, >18 charactersIndicator FeaturesCapitalized Token begins with a capitalAll-caps Entire token is capitalizedHyphenated Token contains a hyphenNumeric Entire token is numeric (e.g.
234)Initial Numeric Token begins with a numeral (e.g.
123, 2-sided)Endings Token ends with -al, -ble, -ed, -er, -est, -ic, -ing, -ive, -lyTable 3: Description of the feature-set.within its class.2 This produces a new PSSMwith which to align the next instance.Our problem differs from alignment of biolog-ical sequences in that we have little prior knowl-edge of the similarity between sequences.
?Sim-ilarity?
can be defined in many ways; for bio-logical sequences, a simple Levenshtein distanceis effective, using a matrix of substitution costsor simple token identity (equivalent to a ma-trix with cost 0 on the diagonal and 1 every-where else).
These matrices are constructed andtuned by domain experts, and are used both inchoosing alignment order (i.e., which sequenceto align next) and during the actual alignment.When aligning biological sequences, it is cus-tomary to first calculate the pairwise distancebetween each two sequences and then introducenew sequences into the MSA in order of simi-larity.
In this way, identical sequences may bealigned first, followed by less similar sequences(Durbin et al, 1999).However, we have no principled method of de-termining the ?similarity?
of two words in an NP.We have no a priori notion of what the costof substituting ?two-story?
for ?red?
should be.Lacking this prior knowledge, we have no opti-mal alignment order and we must in effect learnthe substitution costs as we construct the MSA.Therefore, we choose to add instances in the or-der they occur in the corpus, and to iterate overthe entire MSA, re-introducing each sequence.2We treat two special symbols for gaps and unknownwords as members of the word class.This allows a word to ?move?
from its originalcolumn to a column which became more likelyas more sequences were aligned.
Each iterationis similar to a step in the EM algorithm: create amodel (build up an MSA and PSSM), apply themodel to the data (re-align all sequences), andrepeat.
Randomly permuting the training cor-pus did not change our results significantly, sowe believe our results are not greatly dependenton the initial sequence order.Instead of assigning substitution costs, wecompute the cost of aligning a word into a par-ticular column, as follows:C = The set of i feature classes, Ci ?
Cj = Features 1 .
.
.
|Ci| from class Cicnt(i, j, k) = The count of instances offeature j from classi in column k?i = Laplace smoothing countfor feature class CiA = The number of aligned instancesf(w, i, j) =????
?1 if word w has feature j fromCi,0 otherwiseThese help define feature positional probabilitiesfor column k:p(i, j, k) =cnt(i, j, k) + ?iA+ ?i ?
|Ci|(1)603That is, the probability of feature j from classi occurring in column k is a simple maximum-likelihood estimate ?
count the number of timeswe have already aligned that feature in the col-umn and divide by the number of sequencesaligned.
We smooth that probability with sim-ple Laplace smoothing.We can now calculate the probability of align-ing a word w into column k by multiplying theproduct of the probabilities of aligning each ofthe word?s features.
Taking the negative log toconvert that probability into a cost function:c(w, k) = ?|C|?i=1|Ci|?j=1log (p(i, j, k) ?
f(w, i, j)) (2)Finally, we define the cost of inserting a newcolumn into the alignment to be equal to thenumber of columns in the existing alignment,thereby increasingly penalizing each insertedcolumn until additional columns become pro-hibitively expensive.i(j) = I ?
Length of existing alignment (3)The longest NPs aligned were 7 words, andmost ML MSAs ended with 12-14 columns.We experimented with various column insertioncosts and values for the smoothing ?
and foundno significant differences in overall performance.3.3 Discriminative TrainingWe also trained a discriminative model, us-ing the same feature-set.
Discriminative train-ing does not require division of the featuresinto classes or the independence assumption dis-cussed in Section 3.2.
We again produced a costvector for each column.
We fixed the alignmentlength at 8 columns, allowing alignment of thelongest instances in our test corpus.Our training data consists of ordered se-quences, but the model we are attempting tolearn is a set of column probabilities.
Since wehave no gold-standard MSAs, we instead alignthe ordered NPs with the current model andtreat the least cost alignment of the correct or-dering as the reference for training.We trained this model using the averaged per-ceptron algorithm (Collins, 2002).
A percep-tron learns from classifier errors, i.e., when itmisorders an NP.
At each training instance, wealign all possible permutations of the modifierswith the MSA.
If the least cost alignment doesnot correspond to the correct ordering of themodifiers, we update the perceptron to penal-ize features occurring in that alignment and toreward features occurring in the least cost align-ment corresponding to the correct ordering, us-ing standard perceptron updates.Examining every permutation of the NP in-volves a non-polynomial cost, but the sequencesunder consideration are quite short (less than1% of the NPs in our corpus have more than 3modifiers, and the longest has 6; see Table 7).
Soexhaustive search is practical for our problem; ifwe were to apply MSA to longer sequences, wewould need to prune heavily.34 EvaluationWe trained and tested on the same corpus usedby Mitchell (2009), including identical 10-foldcross-validation splits.
The corpus consists ofall NPs extracted from the Penn Treebank,the Brown corpus, and the Switchboard corpus(Marcus et al, 1999; Kucera and Francis, 1967;Godfrey et al, 1992).
The corpus is heavilybiased toward WSJ text (74%), with approxi-mately 13% of the NPs from each of the othercorpora.We evaluated our system using several relatedbut distinct metrics, and on both modifier pairsand full NPs.We define:T = The set of unique orderings found in thetest corpusP = The set of unique orderings predicted bythe systemType Precision (|P ?
T|/|P|) measures theprobability that a predicted ordering is ?reason-able?
(where ?reasonable?
is defined as orderingswhich are found in the test corpus).3The same issue arises when evaluating candidate or-derings; see Section 4.604Token Accuracy Type Precision Type Recall Type F-measureMitchell N/A 90.3% (2.2) 67.2% (3.4) 77.1%ML MSA 85.5% (1.0) 84.6% (1.1) 84.7% (1.1) 84.7%Perceptron MSA 88.9% (0.7) 88.2% (0.8) 88.1% (0.8) 88.2%Table 4: Results on the combined WSJ, Switchboard, and Brown corpus; averages and standard deviationsover a 10-fold cross validation.
Winning scores are in bold.Type Recall (|P?T|/|T|) measures the per-centage of ?reasonable?
orderings which the sys-tem recreates.Note that these two metrics differ only in no-tation from those used by Mitchell (2009).We also define a third metric, Token Accu-racy, which measures accuracy on each individ-ual ordering in the test corpus, rather than onunique orderings.
This penalizes producing or-derings which are legal, but uncommon.
For ex-ample, if {a,b} occurs eight times in the test cor-pus as <a,b> and two times as <b,a>, we willbe limited to a maximum accuracy of 80% (pre-suming our system correctly predicts the morecommon ordering).
However, even though sug-gesting <b,a> is not strictly incorrect, we gen-erally prefer to reward a system that producesmore common orderings, an attribute not em-phasized by type-based metrics.
Our test cor-pus does not contain many ambiguous pairings,so our theoretical maximum token accuracy is99.8%.We define:o1..N = All modifier orderings in thetest datapred(oi) = The predicted ordering formodifiers in oiai ={1 if pred(oi) = oi,0 otherwiseToken Accuracy =N?i=0aiN4.1 Pairwise OrderingMost earlier work has focused on ordering pairsof modifiers.
The results in Table 4 are di-rectly comparable to those found in Mitchell(2009).
Mitchell?s earlier approach does not gen-erate a prediction when the system has insuffi-cient evidence, and allows generation of multiplepredictions given conflicting evidence.
In the-ory, generating multiple predictions could im-prove recall, but in practice her system appearsbiased toward under-predicting, favoring preci-sion.
Our approach, in contrast, forces predic-tion of a single ordering for each test instance,occasionally costing some precision (in particu-lar in cross-domain trials; see Table 5), but con-sistently balancing recall and precision.Our measurement of Token Accuracy is com-parable to the accuracy measure reported inShaw and Hatzivassiloglou (1999) and Malouf(2000) (although we evaluate on a different cor-pus).
Their approaches produce a single order-ing for each test instance evaluated, so for eachincorrectly ordered modifier pair, there is a cor-responding modifier pair in the test data thatwas not predicted.Shaw and Hatzivassiloglou found financialtext particularly difficult to order, and reportedthat their performance dropped by 19% whenthey included nouns as well as adjectives.
Mal-ouf?s system surpasses theirs, achieving an accu-racy of 91.9%.
However, his corpus was derivedfrom the BNC ?
he did not attempt to order fi-nancial text ?
and he ordered only adjectives asmodifiers.
In contrast, our test corpus consistsmainly of WSJ text, and we test on all formsof prenominal modifiers.
We believe this to bea considerably more difficult task, so our peakperformance of 88.9% would appear to be ?
atworst ?
quite competitive.Table 5 presents an evaluation of cross-domain generalization, splitting the same cor-pus by genre ?
Brown, Switchboard, and WSJ.In each trial, we train on two genres and test on605Training Testing Token Type Type TypeCorpora Corpus Accuracy Precision Recall F-measureMitchellBrown+WSJ Swbd N/A 94.2% 58.2% 72.0%Swbd+WSJ Brown N/A 87.0% 51.2% 64.5%Swbd+Brown WSJ N/A 82.4% 27.2% 40.9%ML MSABrown+WSJ Swbd 74.6% 74.7% 75.3% 75.0%Swbd+WSJ Brown 75.3% 74.7% 74.9% 74.8%Swbd+Brown WSJ 70.2% 71.6% 71.8% 71.7%Perceptron MSABrown+WSJ Swbd 77.2% 78.2% 77.6% 77.9%Swbd+WSJ Brown 76.4% 76.7% 76.4% 76.5%Swbd+Brown WSJ 77.9% 77.5% 77.3% 77.4%Table 5: Cross-domain generalization.Token Accuracy Token Precision Token Recall Token F-measureMitchell N/A 94.4% 78.6% (1.2) 85.7%ML MSA 76.9% (1.6) 76.5% (1.4) 76.5% (1.4) 76.50%Perceptron MSA 86.7% (0.9) 86.7% (0.9) 86.7% (0.9) 86.7%Table 6: Full NP ordering accuracies; averages and standard deviations over a 10-fold cross validation.
Tocompare directly with Mitchell (2009), we report token precision and recall instead of type.
Our systemalways proposes one and only one ordering, so token accuracy, precision, and recall are identical.the third.4 Our results mirror those in the previ-ous trials ?
forcing a prediction costs some pre-cision (vis-a-vis Mitchell?s 2009 system), but ourrecall is dramatically higher, resulting in morebalanced performance overall.4.2 Full NP OrderingWe now extend our analysis to ordering en-tire NPs, a task we feel the MSA approachshould be particularly suited to, since (unlikepairwise models) it can model positional prob-abilities over an entire NP.
To our knowledge,the only previously reported work on this taskis Mitchell?s (2009).
We train this model onthe full NP instead of on modifier pairs; thismakes little difference in pairwise accuracy, butimproves full-NP ordering considerably.As seen in Table 6, both MSA models performquite well, the perceptron-trained MSA againoutperforming the maximum likelihood model.However, we were somewhat disappointed in theperformance on longer sequences.
We expectedthe MSA to encode enough global information4Note that the WSJ corpus is much larger than theother two, comprising approximately 84% of the total.Modifiers Frequency Token PairwiseAccuracy Accuracy2 89.1% 89.7% 89.7%3 10.0% 64.5% 84.4%4 0.9% 37.2% 80.7%Table 7: Descriminative model performance on NPsof various lengths, including pairwise measures.to perform accurate full sequence ordering, butfound the accuracy drops off dramatically onNPs with more modifiers.
In fact, the accu-racy on longer sequences is worse than we wouldexpect by simply extending a pairwise model.For instance, ordering three modifiers requiresthree pairwise decisions.
We predict pairwiseorderings with 88% accuracy, so we would ex-pect no worse than (.88)3, or 68% accuracy onsuch sequences.
However, the pairwise accu-racy declines on longer NPs, so it underperformseven that theoretical minimum.
Sparse trainingdata for longer NPs biases the model stronglytoward short sequences and transitivity (whichour model does not encode) may become impor-tant when ordering several modifiers.6065 Ablation TestsWe performed limited ablation testing on thediscriminative model, removing features individ-ually and comparing token accuracy (see Table8).
We found that few of the features providedgreat benefit individually; the overall systemperformance remains dominated by the word.The word and stem features appear to cap-ture essentially the same information; note thatperformance does not decline when the wordor stem features are ablated, but drops dras-tically when both are omitted.
Performance de-clines slightly more when ending features are ab-lated as well as words and stems, so it appearsthat ?
as expected ?
the information capturedby ending features overlaps somewhat with lex-ical identity.
The effects of individual featuresare all small and none are statistically signifi-cant.Feature(s) Gain/LossWord 0.0Stem 0.0Capitalization -0.1All-Caps 0.0Numeric -0.2Initial-numeral 0.0Length -0.1Hyphen 0.0-al 0.0-ble -0.4-ed -0.4-er 0.0-est -0.1-ic +0.1-ing 0.0-ive -0.1-ly 0.0Word and stem -22.9Word, stem, and endings -24.2Table 8: Ablation test results on the discriminativemodel.6 Summary and Future DirectionsWe adapted MSA approaches commonly usedin computational biology to linguistic problemsand presented two novel methods for trainingsuch alignments.
We applied these techniquesto the problem of ordering prenominal modi-fiers in noun phrases, and achieved performancecompetitive with ?
and in many cases, superiorto ?
the best results previously reported.In our current work, we have focused on rel-atively simple features, which should be adapt-able to other languages without expensive re-sources or much linguistic insight.
We are inter-ested in exploring richer sources of features forordering information.
We found simple morpho-logical features provided discriminative clues forotherwise ambiguous instances, and believe thatricher morphological features might be helpfuleven in a language as morphologically impover-ished as English.
Boleda et al (2005) achievedpromising preliminary results using morphologyfor classifying adjectives in Catalan.Further, we might be able to capture someof the semantic relationships noted by psycho-logical analyses (Ziff, 1960; Martin, 1969) bylabeling words which belong to known seman-tic classes (e.g., colors, size denominators, etc.
).We intend to explore deriving such labels fromresources such as WordNet or OntoNotes.We also plan to continue exploration of MSAtraining methods.
We see considerable roomfor refinement in generative MSA models; ourmaximum likelihood training provides a strongstarting point for EM optimization, conditionallikelihood, or gradient descent methods.
We arealso considering applying maximum entropy ap-proaches to improving the discriminative model.Finally (and perhaps most importantly), weexpect that our model would benefit from ad-ditional training data, and plan to train on alarger, automatically-parsed corpus.Even in its current form, our approach im-proves the state-of-the-art, and we believe MSAtechniques can be a useful tool for orderingprenominal modifiers in NLP tasks.7 AcknowledgementsThis research was supported in part by NSFGrant #IIS-0811745.
Any opinions, findings,conclusions or recommendations expressed inthis publication are those of the authors and donot necessarily reflect the views of the NSF.607ReferencesRegina Barzilay and Lillian Lee.
2002.
Bootstrap-ping lexical choice via multiple-sequence align-ment.
In Proceedings of the ACL-02 conference onEmpirical methods in natural language processing- Volume 10, pages 164?171, Philadelphia.
Asso-ciation for Computational Linguistics.Regina Barzilay and Lillian Lee.
2003.
Learningto paraphrase: An unsupervised approach usingmultiple-sequence alignment.
In Proceedings ofthe Human Language Technology Conference ofthe North American Chapter of the Association forComputational Linguistics (HLT-NAACL), vol-ume 15, pages 201?31, Edmonton, Canada.
As-sociation for Computational Linguistics.Gemma Boleda, Toni Badia, and Sabine Schulteim Walde.
2005.
Morphology vs. syntax in adjec-tive class acquisition.
In Proceedings of the ACL-SIGLEX Workshop on Deep Lexical Acquisition,pages 77?86, Ann Arbor, Michigan, June.
Associ-ation for Computational Linguistics.Humberto Carrillo and David Lipman.
1988.
Themultiple sequence alignment problem in biol-ogy.
SIAM Journal on Applied Mathematics,48(5):1073?1082, October.Michael Collins.
2002.
Discriminative training meth-ods for hidden markov models: theory and experi-ments with perceptron algorithms.
In Proceedingsof the ACL-02 conference on Empirical methods innatural language processing, volume 10, pages 1?8,Philadelphia, July.
Association for ComputationalLinguistics.Richard Durbin, Sean R. Eddy, Anders Krogh, andGraeme Mitchison.
1999.
Biological SequenceAnalysis: Probabilistic Models of Proteins and Nu-cleic Acids.
Cambridge University Press, WestNyack, NY, July.John J. Godfrey, Edward C. Holliman, and JaneMcDaniel.
1992.
SWITCHBOARD: telephonespeech corpus for research and development.
InAcoustics, Speech, and Signal Processing, IEEEInternational Conference on, volume 1, pages 517?520, Los Alamitos, CA, USA.
IEEE Computer So-ciety.Dan Gusfield.
1997.
Algorithms on Strings, Treesand Sequences: Computer Science and Computa-tional Biology.
Cambridge University Press, WestNyack, NY, May.H.
Kucera and W. N Francis.
1967.
Computationalanalysis of present-day American English.
BrownUniversity Press, Providence, RI.Robert Malouf.
2000.
The order of prenominal ad-jectives in natural language generation.
In Pro-ceedings of the 38th Annual Meeting of the Associ-ation for Computational Linguistics, pages 85?92,Hong Kong, October.
Association for Computa-tional Linguistics.Mitchell P Marcus, Beatrice Santorini, Mary AnnMarcinkiewicz, and Ann Taylor.
1999.
Treebank-3.
Linguistic Data Consortium, Philadelphia.J.
E. Martin.
1969.
Semantic determinants of pre-ferred adjective order.
Journal of Verbal Learning& Verbal Behavior.
Vol, 8(6):697?704.Margaret Mitchell.
2009.
Class-Based ordering ofprenominal modifiers.
In Proceedings of the 12thEuropean Workshop on Natural Language Gener-ation (ENLG 2009), pages 50?57, Athens, Greece,March.
Association for Computational Linguis-tics.M.F.
Porter.
1980.
An algorithm for suffix stripping.Program, 14(3):130?137.James Shaw and Vasileios Hatzivassiloglou.
1999.Ordering among premodifiers.
In Proceedings ofthe 37th Annual Meeting of the Association forComputational Linguistics, pages 135?143, Col-lege Park, Maryland, USA, June.
Association forComputational Linguistics.Christopher White, Izhak Shafran, and Jean lucGauvain.
2006.
Discriminative classifiers forlanguage recognition.
In Proceedings of the2006 IEEE International Conference on Acous-tics, Speech, and Signal Processing (ICASSP),pages 213?216, Toulouse, France.
IEEE.Paul Ziff.
1960.
Semantic Analysis.
Cornell Univer-sity Press, Ithaca, New York.608
