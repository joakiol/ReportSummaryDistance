First Joint Conference on Lexical and Computational Semantics (*SEM), pages 502?505,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsBUAP: A First Approximation to Relational Similarity MeasuringMireya Tovar, J. Alejandro Reyes,Azucena MontesCENIDET, Department ofComputer ScienceInt.
Internado Palmira S/N, Col. PalmiraCuernavaca, Morelos, Me?xico{mtovar, alexreyes06c, amr}@cenidet.edu.mxDarnes Vilarin?o, David Pinto,Saul Leo?nB.
Universidad Auto?noma de Puebla,Faculty of Computer Science14 Sur y Av.
San Claudio, CUPuebla, Puebla, Me?xico{darnes, dpinto}@cs.buap.mxsaul.ls@live.comAbstractWe describe a system proposed for measuringthe degree of relational similarity beetwen apair of words at the Task #2 of Semeval 2012.The approach presented is based on a vec-torial representation using the following fea-tures: i) the context surrounding the wordswith a windows size = 3, ii) knowledge ex-tracted from WordNet to discover several se-mantic relationships, such as meronymy, hy-ponymy, hypernymy, and part-whole betweenpair of words, iii) the description of the pairswith their POS tag, morphological informa-tion (gender, person), and iv) the average num-ber of words separating the two words in text.1 IntroductionThe Task # 2 of Semeval 2012 focuses on measuringthe degree of relational similarity between the ref-erence words pairs (training) and the test pairs for agiven class (Jurgens et al, 2012).The training data set consists of 10 classes andthe testing data set consists of the 69 classes.
Thesedatasets as well as the particularities of the task arebetter described at overview paper (Jurgens et al,2012).
In this paper we report the approach submit-ted to the competition, which is based on a vectorspace model representation for each pair (Salton etal., 1975).
With respect to the type of features used,we have observed that Fabio Celli (Celli, 2010) con-siders that contextual information is useful, as wellthe lexical and semantic information are in the ex-traction of semantic relationships task.
Additionally,in (Chen et al, 2010) and (Negri and Kouylekov,2010) are proposed WordNet based features with thesame purpose.In the experiments carried out in this paper, weuse a set of lexical, semantic, WordNet-based andcontextual features which allows to construct thevectors.
Actually, we have tested a subset of the 20contextual features proposed by Celli (Celli, 2010)and some of those proposed by Chen (Chen et al,2010) and Negri (Negri and Kouylekov, 2010).The cosine similarity measure is used for deter-mining the degree of relational similarity (Frakesand Baeza-Yates, 1992) among the vectors.The rest of this paper is structured as follows.Section 2 describes the system employed.
Section3 show the obtained results.
Finally, in Section 4 thefinal conclusions are given.2 System descriptionThe approach reported in this paper measures therelational similarity of a set of word pairs that be-long to the same semantic relationship.
Those wordpairs are represented by means of the vector spacemodel (Salton et al, 1975).
Each value of the vec-tor represents the average value of the correspond-ing feature.
This average is calculated using 100samples obtained from Internet by employing theGoogle search engine.
The search process is car-ried out assuming that those words co-occurring inthe same context contain some kind of semantic re-lationship.Let (w1, w2) be a word pair, then the vectorialrepresentation of this pair (~x) using semantic, con-textual, lexical, and WordNet-based features may beexpressed as it can be seen in Eq.
(1).502~x = (avg(f1), avg(f2), ..., avg(fn)) (1)where avg(fk) is the average value of the feature fk.The cardinality of the vector is 42, because weextracted 4 lexical features, 6 semantic features, 7WordNet-based features and 25 contextual features(n = 42).
Each word pair is then represented bya unique vector with values associated to each fea-ture.
In Figure 1, we show the vectorial represen-tation of the word pair (transportation, bus) usinga unique text sample (s).
In this example, the num-ber and type of features described below is followed,i.e., the first 4 values are lexical, the following 6 aresemantic and so on.s =?The Toyama Chih Railway is a transporta-tion company that operates railway, tram, andbus lines in the eastern part of the prefecture.
?~x = (6, 1, 0, 0, 27, 4, 4, 4, 4, 5, 2, 4, 5, 25, 0, 0,0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4,4, 0, 4, 4, 4, 4)Figure 1: Example of a feature vector for a word pair andits corresponding sentence s.The previous example is only illustrative, sincewe have gathered 100 sentence per word pair.
Intotal, we collected a corpus containing 2,054,687 to-kens, with a average class terms of 26,684 and withan average class vocabulary of 4,006.The features extracted are described as follows:2.1 Lexical featuresThe lexical features describe morphologically andsyntactically the word pair (w1, w2).
The lexicalfeatures extracted are the following:?
Average number of words separating the twowords (w1, w2) in the text.?
The position of w1 with respect to w2 in thetext.
If w1 appears before w2 then the featurevalue is 1, otherwise, the value is 2.?
The Part of Speech Tag for each word in thepair (two features).
We use the FreeLing PoS-tagger (Padro?
et al, 2010) for obtaining thegrammatical category.
The possible values arethe following: adjective=1; adverb=2; arti-cle=3; noun=4; verb=5; pronoun=6; conjunc-tion=7; preposition=82.2 Semantic featuresThe following four semantic features are booleanvalues (true or false) indicating:?
If w1 and w2 are named entities (two features)1.?
If w1 and w2 are entities defined (two fea-tures)2.The following two semantic features indicate:?
The type of prepositional phrase in case ofexisting for w1 and w2.
The feature val-ues are nominal: about=1; after=2; at=3; be-hind=4; between=5; by=6; except=7; from=8;into=9; near=10; of=11; over=12; through=13;until=14; under=15; upon=16; without=17;above=18; among=19; before=20; below=21;beside=22; but=23; down=24; for=25; in=26;on=27; since=28; to=29; with=30.2.3 WordNet-based featuresThe semantic features are boolean values (true orfalse) indicating whether or not w2 is contained in:?
the synonym set of w1?
the antonym set of w1?
the meronymy set of w1?
the hyponymy set of w1?
the hypernymy set of w1?
the part-whole set of w1?
the gloss set of w1We used WordNet (Fellbaum, 1998) in order to de-termine the relationship set for word w1.1A named entity is defined by a Proper Noun Phrase, whichwas detected using the module NER-Named Entity Recognitionof the FreeLing 2.1 tool.2A defined sentence is one that begins with a definite article.5032.4 Contextual featuresContextual features considers values for the wordsthat occur in the context of w1 and w2 (in a windowsize of 3).
The description of those features follows.?
Nominal values indicating the Part of SpeechTag (adjective=1; adverb=2; article=3; noun=4;verb=5; pronoun=6; conjunction=7; preposi-tion=8) for the three words at:?
the left context of w1 (three features).?
the right context of w1 (three features).?
the left context of w2 (three features).?
the right context of w2 (three features).?
A Nominal value indicating number of the fol-lowing grammatical categories between w1 andw2: verbs, adjectives and nouns (three fea-tures).?
Nominal values indicating the frequencies ofthe verbs: be, do, have, locate, know, make, use,become, include, take between w1 and w2 (tenfeatures).2.5 Feature selectionWe carried out a feature selection process with theaim of discarding irrelevant features.
In this step,we apply the attribute selection filter reported in(Hall, 1999), that evaluates the worth of a subsetof attributes by considering the individual predic-tive ability of each feature along with the degree ofredundancy between them and an exhaustive searchmethod.The following features were obtained as relevant:the average number of words between w1 and w2;Named Entity of w1 and w2; phrase defined of w1and w2; prepositional phrase type w1 and w2; partof speech tag w1 and w2; part of speech tag ofright context of w1 with a windows size of 3; oc-currences of verbs between w1 and w2; frequency ofverbs be, do, make, locate, take; synonym, antonym,meronymy, hyponymy, hypernymy, part-whole andgloss relationships between w1 and w2.After applying the aforementioned feature selec-tion method, we removed 17 features, and the vec-torial representation of each word pair will be donewith only 25 values (features).2.6 Determining the degree of similarityWe have used the features mentioned before for con-structing a prototype vector representing a given se-mantic class.
In order to do so, we have employedthe training corpus for gathering samples from Inter-net and, thereafter, we average the feature values inorder to construct such prototype vector.For each word pair in the test dataset, we ob-tained a vector using the same process explainedbefore.
We determined the similarity for each testfeature vector with respect to the prototype of thegiven class by using the cosine similarity coefficient(Frakes and Baeza-Yates, 1992), i.e., measuring thecosine of the angle between the two vectors.In this way, we obtain a similarity measure of eachtest word pair with respect to its corresponding class.Finally, we may output a ranking of all the wordpairs at the test dataset by sorting these similarityvalues obtained.3 Experimental resultsThe approach submitted to the Task #2 of SemEval2012 obtained very poor results.
The Spearman cor-relation coefficient, which measured the correlationof the approach with respect to the gold standard, itis quite low (see Table 1).Team-Algorithm Spearman MaxDiffUTD-NB 0.23 39.4UTD-SVM 0.12 34.7DULUTH-V0 0.05 32.4DULUTH-V1 0.04 31.5DULUTH-V2 0.04 31.1BUAP 0.01 31.7Random 0.02 31.2Table 1: Spearman and MaxDiff scores obtained at theTask #2 of Semeval 2012Actually, it shows that the run submitted does notcorrelate with the gold standard.
We consider thatthis behavior is derived from the nature of the sup-port corpus used for obtaining the features set.
Thenumber of sentences (100) used for representing theword pairs was not enough for constructing a realprototype of both, the semantic class and the wordpairs.
A further analysis will confirm this issue.504Despite this limitation we note that the MaxDiffscore was 31.7% slightly above the baseline (31.2%)and not far from the best score of the task (39.4%).That is, we achieved an average of 31.7% of ques-tions answered correctly.4 Discussion and conclusionIn this paper we report the set of features used inthe approach submitted for measuring the degrees ofrelational similarity between a given reference wordpair and a variety of other pairs.
The results obtainedare not encouraging with a Spearman correlation co-efficient close to zero, which mean that there arenot correlation between the run submitted and thegold standard.
A deeper analysis of the approach isneeded in order to determine if the limitation of thesystem falls in the features used, the similarity mea-sure, or the support corpus used for extracting thefeatures.AcknowledgmentsThis project has been partially supported by projectsCONACYT #106625, VIEP #PIAD-ING11-II and#VIAD-ING11-II.ReferencesFabio Celli.
2010.
Unitn: Part-of-speech counting inrelation extraction.
In Proceedings of the 5th Inter-national Workshop on Semantic Evaluation, SemEval?10, pages 198?201, Stroudsburg, PA, USA.
Associa-tion for Computational Linguistics.Yuan Chen, Man Lan, Jian Su, Zhi Min Zhou, andYu Xu.
2010.
Ecnu: Effective semantic relationsclassification without complicated features or multi-ple external corpora.
In Proceedings of the 5th Inter-national Workshop on Semantic Evaluation, SemEval?10, pages 226?229, Stroudsburg, PA, USA.
Associa-tion for Computational Linguistics.Christiane Fellbaum.
1998.
WordNet: an electronic lexi-cal database.
MIT Press.William B. Frakes and Ricardo A. Baeza-Yates, editors.1992.
Information Retrieval: Data Structures & Algo-rithms.
Prentice-Hall.Mark A.
Hall.
1999.
Correlation-based Feature Sub-set Selection for Machine Learning.
Ph.D. thesis, De-partment of Computer Science, University of Waikato,Hamilton, New Zealand.David A. Jurgens, Saif M. Mohammad, Peter D. Turney,and Keith J. Holyoak.
2012.
Semeval-2012 task 2:Measuring degrees of relational similarity.
In Pro-ceedings of the 6th International Workshop on Seman-tic Evaluation (SemEval 2012), Montreal, Canada.Matteo Negri and Milen Kouylekov.
2010.
Fbk nk: Awordnet-based system for multi-way classification ofsemantic relations.
In Proceedings of the 5th Inter-national Workshop on Semantic Evaluation, SemEval?10, pages 202?205, Stroudsburg, PA, USA.
Associa-tion for Computational Linguistics.Llu?
?s Padro?, Miquel Collado, Samuel Reese, MarinaLloberes, and Irene Castello?n.
2010.
Freeling2.1: Five years of open-source language processingtools.
In Proceedings of the Seventh InternationalConference on Language Resources and Evaluation(LREC?10), Valletta, Malta.
European Language Re-sources Association (ELRA).G.
Salton, A. Wong, and C. S. Yang.
1975.
A vectorspace model for automatic indexing.
Commun.
ACM,18(11):613?620, November.505
