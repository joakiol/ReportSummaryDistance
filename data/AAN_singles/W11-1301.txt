Proceedings of the Workshop on Distributional Semantics and Compositionality (DiSCo?2011), pages 1?9,Portland, Oregon, 24 June 2011. c?2011 Association for Computational Linguistics(Linear) Maps of the Impossible:Capturing semantic anomalies in distributional spaceEva Maria Vecchi and Marco Baroni and Roberto ZamparelliCenter for Mind/Brain Sciences, University of TrentoRovereto (TN), Italy{evamaria.vecchi-1,marco.baroni,roberto.zamparelli}@unitn.itAbstractIn this paper, we present a first attempt tocharacterize the semantic deviance of com-posite expressions in distributional seman-tics.
Specifically, we look for properties ofadjective-noun combinations within a vector-based semantic space that might cue their lackof meaning.
We evaluate four different com-positionality models shown to have variouslevels of success in representing the mean-ing of AN pairs: the simple additive andmultiplicative models of Mitchell and Lap-ata (2008), and the linear-map-based modelsof Guevara (2010) and Baroni and Zamparelli(2010).
For each model, we generate com-posite vectors for a set of AN combinationsunattested in the source corpus and whichhave been deemed either acceptable or seman-tically deviant.
We then compute measuresthat might cue semantic anomaly, and com-pare each model?s results for the two classes ofANs.
Our study shows that simple, unsuper-vised cues can indeed significantly tell unat-tested but acceptable ANs apart from impos-sible, or deviant, ANs, and that the simple ad-ditive and multiplicative models are the mosteffective in this task.1 IntroductionStatistical approaches to describe, represent and un-derstand natural language have been criticized asfailing to account for linguistic ?creativity?, a prop-erty which has been accredited to the compositionalnature of natural language.
Specifically, criticismsagainst statistical methods were based on the ar-gument that a corpus cannot significantly sample anatural language because natural language is infi-nite (Chomsky, 1957).
This cricticism also appliesto distributional semantic models that build seman-tic representations of words or phrases in terms ofvectors recording their distributional co-occurrencepatterns in a corpus (Turney and Pantel, 2010), buthave no obvious way to generalize to word combi-nations that have not been observed in the corpus.To address this problem, there have been several re-cent attempts to incorporate into distributional se-mantic models a component that generates vectorsfor unseen linguistic structures by compositional op-erations in the vector space (Baroni and Zamparelli,2010; Guevara, 2010; Mitchell and Lapata, 2010).The ability to work with unattested data leads tothe question of why a linguistic expression mightnot be attested in even an extremely large and well-balanced corpus.
Its absence might be motivatedby a number of factors: pure chance, the fact thatthe expression is ungrammatical, uses a rare struc-ture, describes false facts, or, finally, is nonsensi-cal.
One criticism from generative linguists is pre-cisely that statistical methods could not distinguishbetween these various possibilities.The difficulty of solving this problem can be il-lustrated by the difference in semantics between theadjective-noun pairs in (1a) and (1b):(1) a. blue roseb.
residential steakAlthough it may be the case that you have never ac-1tually seen a blue rose, the concept is not inconceiv-able.
On the other hand, the concept of a residen-tial steak is rather unimaginable, and intuitively itsabsence in a corpus is motivated by more than justchance or data sparseness.The present paper is a first attempt to use com-positionality and distributional measures to distin-guish nonsensical, or semantically deviant, linguis-tic expression from other types of unattested struc-tures.
The task of distinguishing between unattestedbut acceptable and unattested but semantically de-viant linguistic expressions is not only a way to ad-dress the criticism about the meaning of ?unattest-edness?, but also a task that could have a large im-pact on the (computational) linguistic community asa whole (see Section 2.1).Our specific goal is to automatically detect se-mantic deviance in attributive Adjective-Noun (AN)expressions, using a small number of simple cues inthe vectorial representation of an AN as it is gener-ated from the distributional vectors of its componentA and N by four compositional models found in theliterature.
The choice of AN as our testbed is moti-vated by two facts: first of all, ANs are common,small constituents containing no functional mate-rial, and secondly, ANs have already been studied incompositional distributional semantics (Baroni andZamparelli, 2010; Guevara, 2010; Mitchell and La-pata, 2010).It is important to note that in this research we talkabout ?semantically deviant?
expressions, but we donot exclude the possibility that such expressions areinterpreted as metaphors, via a chain of associations.In fact, distributional measures are desirable modelsto account for this, since they naturally lead to a gra-dient notion of semantic anomaly.The rest of this paper is structured as follows.Section 2 discusses relevant earlier work, introduc-ing the literature on semantic deviance as well ascompositional methods in distributional semantics.Section 3 presents some hypotheses about cues ofsemantic deviance in distributional space.
Our ex-perimental setup and procedure are detailed in Sec-tion 4, whereas the experiments?
results are pre-sented and analyzed in Section 5.
We conclude bysummarizing and proposing future directions in Sec-tion 6.2 Related work2.1 Semantic devianceAs far as we know, we are the first to try to modelsemantic deviance using distributional methods, butthe issue of when a complex linguistic expression issemantically deviant has been addressed since the1950?s in various areas of linguistics.
In compu-tational linguistics, the possibility of detecting se-mantic deviance has been seen as a prerequisite toaccess metaphorical/non-literal semantic interpreta-tions (Fass and Wilks, 1983; Zhou et al, 2007).
Inpsycholinguistics, it has been part of a wide debateon the point at which context can make us perceive a?literal?
vs. a ?figurative?
meaning (Giora, 2002).
Intheoretical generative linguistics, the issue was orig-inally part of a discussion on the boundaries betweensyntax and semantics.
Cases like Chomsky?s clas-sic ?Colorless green ideas sleep furiously?
can actu-ally be regarded as violations of very fine-grainedsyntactic selectional restrictions on the argumentsof verbs or modifiers, on the model of *much com-puter (arguably a failure of much to combine with anoun +COUNT).
By 1977, even Chomsky doubtedthat speakers could in general have intuitions aboutwhether ill-formedness was syntactic or semantic(Chomsky, 1977, p. 4).
The spirit of the selectionalapproach persists in Asher (2011), who proposes adetailed system of semantic types plus a theory oftype coercion, designed to account for the shift inmeaning seen in, e.g., (2) (lunch as food or as anevent).
(2) Lunch was delicious but took forever.A practical problem with this approach is that afull handmade specification of the features that de-termine semantic compatibility is a very expensiveand time-consuming enterprise, and it should bedone consistently across the whole content lexicon.Moreover, it is unclear how to model the intuitionthat naval fraction, musical North or institutionalacid sound odd, in the absence of very particularcontexts, while (2) sounds quite natural.
Whateverthe nature of coercion, we do not want it to run sosmoothly that any combination of A and N (or V andits arguments) becomes meaningful and completelyacceptable.22.2 Distributional approaches to meaningcompositionAlthough the issue of how to compose meaning hasattracted interest since the early days of distribu-tional semantics (Landauer and Dumais, 1997), re-cently a very general framework for modeling com-positionality has been proposed by Mitchell and La-pata (Mitchell and Lapata, 2008; Mitchell and La-pata, 2009; Mitchell and Lapata, 2010).
Given twovectors u and v, they identify two general classes ofcomposition models, (linear) additive models:p = Au + Bv (1)where A and B are weight matrices, and multiplica-tive models:p = Cuvwhere C is a weight tensor projecting the uv ten-sor product onto the space of p. Mitchell and La-pata derive two simplified models from these gen-eral forms: The simplified additive model given byp = ?u + ?v, and a simplified multiplicative ap-proach that reduces to component-wise multiplica-tion, where the i-th component of the composed vec-tor is given by: pi = uivi.
Mitchell and Lapataevaluate the simplified models on a wide range oftasks ranging from paraphrasing to statistical lan-guage modeling to predicting similarity intuitions.Both simple models fare quite well across tasksand alternative semantic representations, also whencompared to more complex methods derived fromthe equations above.
Given their overall simplic-ity, good performance and the fact that they havealso been extensively tested in other studies (Baroniand Zamparelli, 2010; Erk and Pado?, 2008; Guevara,2010; Kintsch, 2001; Landauer and Dumais, 1997),we re-implement here both the simplified additiveand simplified multiplicative methods (we do not,however, attempt to tune the weights of the additivemodel, although we do apply a scalar normalizationconstant to the adjective and noun vectors).Mitchell and Lapata (as well as earlier re-searchers) do not exploit corpus evidence aboutthe p vectors that result from composition, despitethe fact that it is straightforward (at least for shortconstructions) to extract direct distributional evi-dence about the composite items from the corpus(just collect co-occurrence information for the com-posite item from windows around the contexts inwhich it occurs).
The main innovation of Guevara(2010), who focuses on adjective-noun combina-tions (AN), is to use the co-occurrence vectors ofcorpus-observed ANs to train a supervised compo-sition model.
Guevara, whose approach we also re-implement here, adopts the full additive composi-tion form from Equation (1) and he estimates theA and B weights (concatenated into a single ma-trix, that acts as a linear map from the space of con-catenated adjective and noun vectors onto the ANvector space) using partial least squares regression.The training data are pairs of adjective-noun vec-tor concatenations, as input, and corpus-derived ANvectors, as output.
Guevara compares his modelto the simplified additive and multiplicative modelsof Mitchell and Lapata.
Corpus-observed ANs arenearer, in the space of observed and predicted testset ANs, to the ANs generated by his model thanto those from the alternative approaches.
The addi-tive model, on the other hand, is best in terms ofshared neighbor count between observed and pre-dicted ANs.The final approach we re-implement is the oneproposed by Baroni and Zamparelli (2010), whotreat attributive adjectives as functions from nounmeanings to noun meanings.
This is a standard ap-proach in Montague semantics (Thomason, 1974),except noun meanings here are distributional vec-tors, not denotations, and adjectives are (linear)functions learned from a large corpus.
Unlike inGuevara?s approach, a separate matrix is generatedfor each adjective using only examples of ANs con-taining that adjective, and no adjective vector isused: the adjective is represented entirely by the ma-trix mapping nouns to ANs.
In terms of Mitchelland Lapata?s general framework, this approach de-rives from the additive form in Equation (1) with thematrix multiplying the adjective vector (say, A) setto 0, the other matrix (B) representing the adjectiveat hand, and v a noun vector.
Baroni and Zamparelli(2010) show that their model significantly outper-forms other vector composition methods, includingaddition, multiplication and Guevara?s approach, inthe task of approximating the correct vectors for pre-viously unseen (but corpus-attested) ANs.
Simpleaddition emerges as the second best model.3See Section 4.3 below for details on our re-implementations.
Note that they follow very closelythe procedure of Baroni and Zamparelli (2010), in-cluding choices of source corpus and parameter val-ues, so that we expect their results on the quality ofthe various models in predicting ANs to also holdfor our re-implementations.3 Simple indices of semantic devianceWe consider here a few simple, unsupervised mea-sures to help us distinguish the representation that adistributional composition model generates for a se-mantically anomalous AN from the one it generatesfor a semantically acceptable AN.
In both cases, weassume that the AN is not already part of the modelsemantic space, just like you can distinguish be-tween parliamentary tomato (odd) and marble iPad(OK), although you probably never heard either ex-pression.We hypothesize that, since the values in the di-mensions of a semantic space are a distributionalproxy to the meaning of an expression, a mean-ingless expression should in general have low val-ues across the semantic space dimensions.
For ex-ample, a parliamentary tomato, no longer being avegetable but being an unlikely parliamentary event,might have low values on both dimensions char-acterizing vegetables and dimensions characterizingevents.
Thus, our first simple measure of seman-tic anomaly is the length of the model-generatedAN.
We hypothesize that anomalous AN vectors areshorter than acceptable ANs.Second, if deviant composition destroys or ran-domizes the meaning of a noun, as a side effect wemight expect the resulting AN to be more distant, inthe semantic space, from the component noun.
Al-though even a marble iPad might have lost some es-sential properties of iPads (it could for example bean iPad statue you cannot use as a tablet), to the ex-tent that we can make sense of it, it must retain atleast some characteristics of iPads (at the very least,it will be shaped like an iPad).
On the other hand, wecannot imagine what a parliamentary tomato shouldbe, and thus cannot attribute even a subset of the reg-ular tomato properties to it.
We thus hypothesize thatmodel-generated vectors of deviant ANs will forma wider angle (equivalently, will have a lower co-sine) with the corresponding N vectors than accept-able ANs.Finally, if an AN makes no sense, its model-generated vector should not have many neighboursin the semantic space, since our semantic space ispopulated by nouns, adjectives and ANs that arecommonly encountered in the corpus, and shouldthus be meaningful.
We expect deviant ANs tobe ?semantically isolated?, a notion that we opera-tionalize in terms of a (neighborhood) density mea-sure, namely the average cosine with the (top 10)nearest neighbours.
We hypothesize that model-generated vectors of deviant ANs will have lowerdensity than model-generated acceptable ANs.4 Experimental setup4.1 Semantic spaceOur initial step was to construct a semantic space forour experiments, consisting of a matrix where eachrow vector represents an adjective, noun or AN.
Wefirst introduce the source corpus, then the vocabularyof words and ANs that we represent in the space,and finally the procedure adopted to build the vec-tors representing the vocabulary items from corpusstatistics, in order to obtain the semantic space ma-trix.
We work here with a ?vanilla?
semantic space(essentially, we follow the steps of Baroni and Zam-parelli (2010)), since our focus is on the effect ofdifferent composition methods given a common se-mantic space.
We leave it to further work to studyhow choices in semantic space construction affectcomposition operations.4.1.1 Source corpusWe use as our source corpus the concate-nation of the Web-derived ukWaC corpus(http://wacky.sslmit.unibo.it/),a mid-2009 dump of the English Wikipedia(http://en.wikipedia.org) and the BritishNational Corpus (http://www.natcorp.ox.ac.uk/).
The corpus has been tokenized,POS-tagged and lemmatized with the TreeTagger(Schmid, 1995), and it contains about 2.8 billiontokens.
We extract all statistics at the lemma level,ignoring inflectional information.44.1.2 Semantic space vocabularyThe words/ANs in the semantic space must ofcourse include the items that we need for our exper-iments (adjectives, nouns and ANs used for modeltraining and as input to composition).
Moreover, inorder to study the behaviour of the test items we areinterested in (that is, model-generated AN vectors)within a large and less ad-hoc space, we also includemany more adjectives, nouns and ANs in our vocab-ulary not directly relevant to our experimental ma-nipulations.We populate our semantic space with the 8K mostfrequent nouns and 4K most frequent adjectivesfrom the corpus (excluding, in both cases, the top50 most frequent elements).
We extended this vo-cabulary to include two sets of ANs (33K ANs cu-mulatively), for a total of 45K vocabulary items inthe semantic space.To create the ANs needed to run and evaluate theexperiments described below, we focused on a setof adjectives which are very frequent in the corpusso that they will be in general able to combine withwide classes of nouns, making the unattested casesmore interesting, but not so frequent as to have sucha general meaning that would permit a free combi-nation with nearly any noun.
The ANs were there-fore generated by crossing a selected set of 200 veryfrequent adjectives (adjectives attested in the corpusat least 47K times, and at most 740K) and the setof the 8K nouns in our semantic space vocabulary,producing a set of 4.92M generated ANs.The first set of ANs included in the semanticspace vocabulary is a randomly sampled set of 30KANs from the generated set which are attested inthe corpus at least 200 times (to avoid noise and fo-cus on ANs for which we can extract reasonably ro-bust distributional data).
We also extracted any unat-tested ANs from the set of generated set (about 3.5Munattested ANs), putting them aside to later assem-ble our evaluation material, described in Section 4.2.To add further variety to the semantic space, weincluded a less controlled second set of 3K ANs ran-domly picked among those that are attested and areformed by the combination of any of the 4K adjec-tives and 8K nouns in the vocabulary.4.1.3 Semantic space constructionFor each of the items in our vocabulary, we firstbuild 10K-dimensional vectors by recording theirsentence-internal co-occurrence with the top 10Kmost frequent content words (nouns, adjectives orverbs) in the corpus.
The raw co-occurrence countsare then transformed into Local Mutual Informationscores (Local Mutual Information is an associationmeasure that closely approximates the commonlyused Log-Likelihood Ratio while being simpler tocompute (Baroni and Lenci, 2010; Evert, 2005)).Next, we reduce the full co-occurrence matrixapplying the Singular Value Decomposition (SVD)operation, like in LSA and related distributionalsemantic methods (Landauer and Dumais, 1997;Rapp, 2003; Schu?tze, 1997).
The original 45K-by-10K-dimensional matrix is reduced in this way to a45K-by-300 matrix, where vocabulary items are rep-resented by their coordinates in the space spannedby the first 300 right singular vectors of the SVDsolution.
This step is motivated by the fact that wewill estimate linear models to predict the values ofeach dimension of an AN from the dimensions of thecomponents.
We thus prefer to work in a smaller anddenser space.
As a sanity check, we verify that weobtain state-of-the-art-range results on various se-mantic tasks using this reduced semantic space (notreported here for space reason).4.2 Evaluation materialsOur goal is to study what happens when composi-tional methods are used to construct a distributionalrepresentation for ANs that are semantically deviant,compared to the AN representations they generatefor ANs they have not encountered before, but thatare semantically acceptable.In order to assemble these lists, we started fromthe set of 3.5M unattested ANs described in Sec-tion 4.1.2 above, focusing on 30 randomly chosenadjectives.
For each of these, we randomly picked100 ANs for manual inspection (3K ANs in total).Two authors went through this list, marking thoseANs that they found semantically highly anomalous,no matter how much effort one would put in con-structing metaphorical or context-dependent inter-pretations, as well as those they found completelyacceptable (so, rating was on a 3-way scale: deviant,5intermediate, acceptable).
The rating exercise re-sulted in rather low agreement (Cohen?s ?=0.32),but we reasoned that those relatively few cases (456over 3K) where both judges agreed the AN was oddshould indeed be odd, and similarly for the evenrarer cases in which they agreed an AN was com-pletely acceptable (334 over 3K).
We thus used theagreed deviant and acceptable ANs as test data.Of 30 adjectives, 5 were discarded for either tech-nical reasons or for having less than 5 agreed de-viant or acceptable ANs.
This left us with a de-viant AN test set comprising of 413 ANs, on av-erage 16 for each of the 25 remaining adjectives.Some examples of ANs in this set are: academicbladder, blind pronunciation, parliamentary potatoand sharp glue.
The acceptable (but unattested) ANtest set contains 280 ANs, on average 11 for each ofthe 25 studied adjectives.
Examples of ANs in thisset include: vulnerable gunman, huge joystick, aca-demic crusade and blind cook.
The evaluation setscan be downloaded from http://www.vecchi.com/eva/resources.html.There is no significant difference between thelength of the vectors of the component nouns in theacceptable vs. deviant AN sets (two-tailed Welch?s ttest; t=?0.25; p>0.8).
This is important, since atleast one of the potential cues to deviance we con-sider (AN vector length) is length-dependent, andwe do not want a trivial result that can simply beexplained by systematic differences in the length ofthe input vectors.4.3 Composition methodsAs discussed in Section 2.2, the experiment was car-ried out across four compositional methods.Additive AN vectors (add method) are simplyobtained by summing the corresponding adjectiveand noun vectors after normalizing them.
Multi-plicative vectors (mult method) were obtained bycomponent-wise multiplication of the adjective andnoun vectors, also after normalization.
Confirm-ing the results of Baroni and Zamparelli (2010),non-normalized versions of add and mult were alsotested, but did not produce significant results (inthe case of multiplication, normalization amounts tomultiplying the composite vector by a scalar, so itonly affects the length-dependent vector length mea-sure).
It is important to note that, as reported inBaroni and Zamparelli (2010), the mult method canbe expected to perform better in the original, non-reduced semantic space because the SVD dimen-sions can have negative values, leading to counter-intuitive results with component-wise multiplication(multiplying large opposite-sign values results inlarge negative values instead of being cancelled out).The tests of Section 5, however, are each run in theSVD-reduced space to remain consistent across allmodels.
We leave it to future work to explore theeffect on the performance of using the non-reducedspace for the models for which this option is com-putationally viable.In the linear map (lm) approach proposed byGuevara (2010), a composite AN vector is obtainedby multiplying a weight matrix by the concatenationof the adjective and noun vectors, so that each di-mension of the generated AN vector is a linear com-bination of dimensions of the corresponding adjec-tive and noun vectors.
That is, the 600 weights ineach of the 300 rows of the weight matrix are thecoefficients of a linear equation predicting the val-ues of a single dimension in the AN vector as a lin-ear combination (weighted sum) of the 300 adjectiveand 300 noun dimensions.
Following Guevara, weestimate the coefficients of the equation using (mul-tivariate) partial least squares regression (PLSR) asimplemented in the R pls package (Mevik andWehrens, 2007), with the latent dimension param-eter of PLSR set to 50, the same value used by Ba-roni and Zamparelli (2010).
Coefficient matrix es-timation is performed by feeding the PLSR a setof input-output examples, where the input is givenby concatenated adjective and noun vectors, and theoutput is the vector of the corresponding AN directlyextracted from our semantic space (i.e., the AN vec-tors used in training are not model-generated, butdirectly derived from corpus evidence about theirdistribution).
The matrix is estimated using a ran-dom sample of 2K adjective-noun-AN tuples wherethe AN belongs to the set of 30K frequently attestedANs in our vocabulary.Finally, in the adjective-specific linear map(alm) method of Baroni and Zamparelli (2010), anAN is generated by multiplying an adjective weightmatrix with a noun vector.
The weights of each ofthe 300 rows of the weight matrix are the coefficientsof a linear equation predicting the values of one of6the dimensions of the AN vector as a linear com-bination of the 300 dimensions of the componentnoun.
The linear equation coefficients are estimatedseparately for each of the 25 tested adjectives fromthe attested noun-AN pairs containing that adjective(observed adjective vectors are not used), again us-ing PLSR with the same parameter as above.
Foreach adjective, the training N-AN vector pairs cho-sen are those available in the semantic space for eachtest set adjective, and range from 100 to more than500 items across the 25 adjectives.4.4 Experimental procedureUsing each composition method, we generate com-posite vectors for all the ANs in the two (acceptableand deviant) evaluation sets (see Section 4.2 above).We then compute the measures that might cue se-mantic deviance discussed in Section 3 above, andcompare their values between the two AN sets.
Inorder to smooth out adjective-specific effects, we z-normalize the values of each measure across all theANs sharing an adjective before computing globalstatistics (i.e., the values for all ANs sharing an ad-jective from the two sets are transformed by sub-tracting their mean and dividing by their variance).We then compare the two sets, for each compositionmethod and deviance cue, by means of two-tailedWelch?s t tests.
We report the estimated t score,that is, the standardized difference between the meanacceptable and deviant AN values, with the corre-sponding significance level.
For all our cues, wepredict t to be significantly larger than 0: Accept-able AN vectors should be longer than deviant ones,they should be nearer ?
that is, have a higher cosinewith ?
the component N vectors and their neighbour-hood should be denser ?
that is, the average cosineswith their top neighbours should be higher than theones of deviant ANs with their top neighbours.5 ResultsThe results of our experiments are summarized inTable 1.
We see that add and mult provide signif-icant results in the expected direction for 2 over 3cues, only failing the cosine test.
With the lm model,acceptable and deviant ANs are indistinguishableacross the board, whereas alm captures the distinc-tion in terms of density.LENGTH COSINE DENSITYmethod t sig.
t sig.
t sig.add 7.89 * 0.31 2.63 *mult 3.16 * -0.56 2.68 *lm 0.16 0.55 -0.23alm 0.48 1.37 3.12 *Table 1: t scores for difference between acceptable anddeviant ANs with respect to 3 cues of deviance: lengthof the AN vector, cosine of the AN vector with the com-ponent noun vector and density, measured as the averagecosine of an AN vector with its nearest 10 neighbours insemantic space.
For all significant results, p<0.01.The high scores in the vector length analyses ofboth the addition and the multiplication models arean indication that semantically acceptable ANs tendto be composed of similar adjectives and nouns, i.e.,those which occur in similar contexts and we can as-sume are likely to belong to the same domain, whichsounds plausible.In Baroni and Zamparelli (2010), the alm modelperformed far better than add and mult in approxi-mating the correct vectors for unseen ANs, while onthis (in a sense, more metalinguistic) task add andmult work better, while alm is successful only in themore sophisticated measure of neighbor density.The lack of significant results for the cosine mea-sure is disappointing, but not entirely surprising.
Alarge angle between N and AN might be a feature ofimpossible ANs common to various types of pos-sible ANs: idioms (a red herring is probably farfrom herring in semantic space), non-subsective ad-jectives (stone lion vs. lion; fake butterfly vs. but-terfly), plus some metaphorical constructions (aca-demic crusade vs. crusade?one of several ANsjudged acceptable in our study, which can only betaken as metaphors).
Recall, finally, that the vectorfor the base N collapses together all the meaningsof an ambiguous N. The adjective might have a dis-ambiguating effect which would increase the cosinedistance.To gain a better understanding of the neighbor-hood density test we performed a detailed analysisof the nearest neighbors of the AN vectors generatedby the three models in which the difference in neigh-bor distance was significant across deviant and ac-ceptable ANs: alm, multiplication and addition.
For7each of the ANs, we looked at the top 10 semantic-space neighbors generated by each of the three mod-els, focusing on two aspects: whether the neighborwas a single A or N, rather than AN, and whetherthe neighbor contained the same A or N as the ANis was the neighbor of (as in blind regatta / blindathlete or biological derivative / partial derivative).The results are summarized in Table 2.method status A N A1= N1=only only A2 N2addaccept 11.9 8.7 14.6 2.4deviant 12.5 6.8 14.6 2.3multaccept 6.9 8.0 0.7 0.1deviant 2.7 7.3 0.5 0.1almaccept 4.9 17.7 7.0 0.0deviant 7.1 19.6 6.2 0.0Table 2: Percentage distributions of various properties ofthe top 10 neighbours of ANs in the acceptable (2800)and deviant (4130) sets for add, mult and alm.
The lasttwo columns express whether the neighbor contains thesame Adjective or Noun as the target AN.In terms of the properties we measured, neighbordistributions are quite similar across acceptable anddeviant ANs.
One interesting finding is that the sys-tem is quite ?adjective-driven?
: particularly for theadditive model (where we can imagine that some Nswith low dimensional values do not shift much theadjective position in the multidimensional space),less so in the alm method, and not at all for mult.
Toput the third and forth columns in context, the subsetof the semantic space used to generate the SVD fromwhich the neighbors are drawn contained 2.69% ad-jectives, 5.24% nouns and 92.07% ANs.
With re-spect to the last two columns, it is interesting to ob-serve that matching As are frequent for deviant ANseven in alm, a model which has never seen A-vectorsduring training.
Further qualitative evaluations showthat in many deviant AN cases the similarity is be-tween the A in the target AN and the N of the neigh-bor (e.g.
academic bladder / honorary lectureship),while the opposite effect seems to be much harder tofind.6 Conclusion and future workThe main aim of this paper was to propose a newchallenge to the computational distributional seman-tics community, namely that of characterizing whathappens, distributionally, when composition leadsto semantically anomalous composite expressions.The hope is, on the one hand, to bring further sup-port to the distributional approach by showing that itcan be both productive and constrained; and on theother, to provide a more general characterization ofthe somewhat elusive notion of semantic deviance ?a notion that the field of formal semantics acknowl-edges but might lack the right tools to model.Our results are very preliminary, but also very en-couraging, suggesting that simple unsupervised cuescan significantly tell unattested but acceptable ANsapart from impossible, or at least deviant, ones.
Al-though, somewhat disappointingly, the model thathas been shown in a previous study (Baroni andZamparelli, 2010) to be the best at capturing the se-mantics of well-formed ANs turns out to be worsethan simple addition and multiplication.Future avenues of research must include, first ofall, an exploration on the effect on each model whentested in the non-reduced space where computation-ally possible, or using different dimensionality re-duction methods.
A preliminary study demonstratesan enhanced performance of the mult method in thefull space.Second, we hope to provide a larger benchmarkof acceptable and deviant ANs, beyond the few hun-dreds we used here, and sampling a larger typologyof ANs across frequency ranges and adjective andnoun classes.
To this extent, we are implementinga crowd-sourcing study to collect human judgmentsfrom a large pool of speakers on a much larger set ofANs unattested in the corpus.
Averaging over mul-tiple judgments, we will also be able to characterizesemantic deviance as a gradient property, probablymore accurately.Next, the range of cues we used was quite limited,and we intend to extend the range to include moresophisticated methods such as 1) combining multi-ple cues in a single score; 2) training a supervisedclassifier from labeled acceptable and deviant ANs,and studying the most distinctive features discov-ered by the classifier; 3) trying more complex unsu-pervised techniques, such as using graph-theoreticalmethods to characterize the semantic neighborhoodof ANs beyond our simple density measure.Finally, we are currently not attempting a typol-8ogy of deviant ANs.
We do not distinguish casessuch as parliamentary tomato, where the adjectivedoes not apply to the conceptual semantic type ofthe noun (or at least, where it is completely undeter-mined which relation could bridge the two objects),from oxymorons such as dry water, or vacuouslyredundant ANs (liquid water) and so on.
We real-ize that, at a more advanced stage of the analysis,some of these categories might need to be explicitlydistinguished (for example, liquid water is odd butperfectly meaningful), leading to a multi-way task.Similarly, among acceptable ANs, there are spe-cial classes of expressions, such as idiomatic con-structions, metaphors or other rhetorical figures, thatmight be particularly difficult to distinguish fromdeviant ANs.
Again, more cogent tasks involvingsuch well-formed but non-literal constructions (be-yond the examples that ended up by chance in ouracceptable set) are left to future work.AcknowledgmentsWe thank Raffaella Bernardi, Gemma Boleda,Louise McNally and the anonymous reviewers fortheir advice and comments.ReferencesNicholas Asher.
2011.
Lexical Meaning in Context: AWeb of Words.
Cambridge University Press.Marco Baroni and Alessandro Lenci.
2010.
Dis-tributional Memory: A general framework forcorpus-based semantics.
Computational Linguistics,36(4):673?721.Marco Baroni and Roberto Zamparelli.
2010.
Nounsare vectors, adjectives are matrices: Representingadjective-noun constructions in semantic space.
InProceedings of EMNLP, pages 1183?1193, Boston,MA.Noam Chomsky.
1957.
Syntactic Structures.
Mouton.Noam Chomsky.
1977.
Essays on Form and Interpreta-tion.
North Holland, New York.Katrin Erk and Sebastian Pado?.
2008.
A structured vec-tor space model for word meaning in context.
In Pro-ceedings of EMNLP, pages 897?906, Honolulu, HI,USA.Stefan Evert.
2005.
The Statistics of Word Cooccur-rences.
Dissertation, Stuttgart University.Dan Fass and Yorick Wilks.
1983.
Preference seman-tics, ill-formedness, and metaphor.
ComputationalLinguistics, 9:178?187.Rachel Giora.
2002.
Literal vs. figurative language: Dif-ferent or equal?
Journal of Pragmatics, 34:487?506.Emiliano Guevara.
2010.
A regression model ofadjective-noun compositionality in distributional se-mantics.
In Proceedings of the ACL GEMS Workshop,pages 33?37, Uppsala, Sweden.Walter Kintsch.
2001.
Predication.
Cognitive Science,25(2):173?202.Thomas Landauer and Susan Dumais.
1997.
A solu-tion to Plato?s problem: The latent semantic analysistheory of acquisition, induction, and representation ofknowledge.
Psychological Review, 104(2):211?240.Bjo?rn-Helge Mevik and Ron Wehrens.
2007.
Thepls package: Principal component and partial leastsquares regression in R. Journal of Statistical Soft-ware, 18(2).
Published online: http://www.jstatsoft.org/v18/i02/.Jeff Mitchell and Mirella Lapata.
2008.
Vector-basedmodels of semantic composition.
In Proceedings ofACL, pages 236?244, Columbus, OH, USA.Jeff Mitchell and Mirella Lapata.
2009.
Language mod-els based on semantic composition.
In Proceedings ofEMNLP, pages 430?439, Singapore.Jeff Mitchell and Mirella Lapata.
2010.
Composition indistributional models of semantics.
Cognitive Science.Reinhard Rapp.
2003.
Word sense discovery based onsense descriptor dissimilarity.
In Proceedings of the9th MT Summit, pages 315?322, New Orleans, LA,USA.Helmut Schmid.
1995.
Improvements in part-of-speechtagging with an application to German.
In Proceed-ings of the EACL-SIGDAT Workshop, Dublin, Ireland.Hinrich Schu?tze.
1997.
Ambiguity Resolution in NaturalLanguage Learning.
CSLI, Stanford, CA.Richmond H Thomason, editor.
1974.
Formal Philoso-phy: Selected Papers of Richard Montague.
Yale Uni-versity Press, New York.Peter Turney and Patrick Pantel.
2010.
From frequencyto meaning: Vector space models of semantics.
Jour-nal of Artificial Intelligence Research, 37:141?188.Chang-Le Zhou, Yun Yang, and Xiao-Xi Huang.
2007.Computational mechanisms for metaphor in lan-guages: a survey.
Journal of Computer Science andTechnology, 22:308?319.9
