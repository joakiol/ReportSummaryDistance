Coling 2010: Poster Volume, pages 710?718,Beijing, August 2010Fast-Champollion: A Fast and RobustSentence Alignment AlgorithmPeng Li and Maosong SunDepartment of Computer Science and TechnologyState Key Lab on Intelligent Technology and SystemsNational Lab for Information Science and Technologypengli09@gmail.com, sms@tsinghua.edu.cnPing XueThe Boeing Companyping.xue@boeing.comAbstractSentence-level aligned parallel texts areimportant resources for a number of nat-ural language processing (NLP) tasks andapplications such as statistical machinetranslation and cross-language informa-tion retrieval.
With the rapid growthof online parallel texts, efficient and ro-bust sentence alignment algorithms be-come increasingly important.
In thispaper, we propose a fast and robustsentence alignment algorithm, i.e., Fast-Champollion, which employs a combi-nation of both length-based and lexicon-based algorithm.
By optimizing the pro-cess of splitting the input bilingual textsinto small fragments for alignment, Fast-Champollion, as our extensive experi-ments show, is 4.0 to 5.1 times as fastas the current baseline methods such asChampollion (Ma, 2006) on short textsand achieves about 39.4 times as fast onlong texts, and Fast-Champollion is as ro-bust as Champollion.1 IntroductionSentence level aligned parallel corpora are veryimportant resources for NLP tasks including ma-chine translation, cross-language information re-trieval and so on.
These tasks typically requiresupport by large aligned corpora.
In general, themore aligned text we have, the better result weachieve.
Although there is a huge amount of bilin-gual text on the Internet, most of them are eitheronly aligned at article level or even not alignedat all.
Sentence alignment is a process mappingsentences in the source text to their correspond-ing units in the translated text.
Manual sentencealignment operation is both expensive and time-consuming, and thus automated sentence align-ment techniques are necessary.
A sentence align-ment algorithm for practical use should be (1)fast enough to process large corpora, (2) robustenough to tackle noise commonly present in thereal data, and (3) effective enough to make as fewmistakes as possible.Various sentence alignment algorithms havebeen proposed, which generally fall into threetypes: length-based, lexicon-based, and the hy-brid of the above two types.
Length-based algo-rithms align sentences according to their length(measured by character or word).
The first length-based algorithm was proposed in (Brown et al,1991).
This algorithm is fast and has a good per-formance if there is minimal noise (e.g., sentenceor paragraph omission) in the input bilingual texts.As this algorithm does not use any lexical infor-mation, it is not robust.
Lexicon-based algorithmsare usually more robust than the length-based al-gorithm, because they use the lexical informationfrom source and translation lexicons instead ofsolely sentence length to determine the transla-tion relationship between sentences in the sourcetext and the target text.
However, lexicon-basedalgorithms are slower than length-based sentencealignment algorithms, because they require muchmore expensive computation.
Typical lexicon-based algorithms include (Ma, 2006; Chen, 1993;Utsuro et al, 1994; Melamed, 1996).
Sentencelength and lexical information are also combinedto achieve more efficient algorithms in two ways.One way is to use both sentence length and lex-710ical information together to determine whethertwo sentences should be directly aligned or not(Simard et al, 1993; Wu, 1994).
The other way isto produce a rough alignment based on sentencelength (and possibly some lexical information atthe same time), and then build more precise align-ment by using more effective lexicon-based algo-rithms (Moore, 2002; Varga et al, 2005).
But bothof the two ways suffer from high computationalcost and are not fast enough for processing largecorpora.Lexical information is necessary for improvingrobustness of a sentence alignment algorithm, butuse of lexical information will introduce highercomputational cost and cause a lower speed.
Acommon fact is that the shorter the text is, theless combination possibilities it would introduceand the less computational cost it would need.
Soif we can first split the input bilingual texts intosmall aligned fragments reliably with a reasonableamount of computational cost, and then furtheralign these fragments one by one, we can speedup these algorithms remarkably.
This is the mainidea of our algorithm Fast-Champollion.The rest of this paper is organized as fol-lows: Section 2 presents formal definitions of sen-tence alignment problem, and briefly reviews thelength-based sentence alignment algorithm andChampollion algorithm; Section 3 proposes theFast-Champollion algorithm.
Section 4 shows theexperiment results; and Section 5 is the conclu-sion.2 Definitions and Related Work2.1 Definitions and Key PointsA segment is one or more consecutive sen-tence(s).
A fragment consists of one segment ofthe source text (denoted by S) and one segment ofthe target text (denoted by T ), and a fragment canbe further divided into one or more beads.
A beadrepresents a group of one or more sentences inthe source text and the corresponding sentence(s)in the target text, denoted by Ai = (SAi;TAi) =(Sai?1+1, Sai?1+2, ?
?
?
, Sai ;Tbi?1+1, Tbi?1+2, ?
?
?
,Tbi), where Si and Tj are the ith and jth sentenceof S and T respectively.In practice, we rarely encounter crossing align-ment, e.g., sentences Si and Sj of the source lan-guage are aligned to the sentences Tj and Ti ofthe target language respectively.
But much moreeffort has to be taken for an algorithm to processcrossing alignment well.
So we do not considercrossing alignment here.In addition, only a few type of beads are fre-quently observed in the real world.
As it can savesignificantly in terms of computational cost and itwould not do significant harm to algorithm with-out considering rare bead types, a common prac-tice for designing sentence alignment algorithmsis to only consider the frequently observed typesof beads.
Following this practice, we only con-sider beads of 1-to-0, 0-to-1, 1-to-1, 1-to-2, 2-to-1, 1-to-3, 3-to-1, 1-to-4, 4-to-1 and 2-to-2 types inour algorithm, where n-to-m means the bead con-sists of n sentence(s) of the source language andm sentence(s) of the target language.2.2 Length-based Sentence AlignmentAlgorithmLength-based sentence alignment algorithm wasfirst proposed in (Brown et al, 1991).
This algo-rithm captures the idea that long or short sentencestend to be translated into long or short sentences.A probability is produced for each bead based onthe sentence length, and a dynamic programmingalgorithm is used to search for the alignment withthe highest probability, which is treated as the bestalignment.This algorithm is fast and can produce goodalignment when the input bilingual texts do notcontain too much noise, but it is not robust, be-cause it only uses the sentence length information.When there is too much noise in the input bilin-gual texts, sentence length information will be nolonger reliable.2.3 Champollion AlignerChampollion aligner was proposed in (Ma, 2006).It borrows the idea of tf-idf value, which is widelyused in information retrieval, to weight term1 pairsimilarity.
Greater weight is assigned to the lessfrequent translation term pairs, because these term1Here terms are not limited to linguistic words, but alsocan be tokens like ?QX6800?711pairs have much stronger evidence for two seg-ments to be aligned.
For any two segments, a sim-ilarity is assigned based on the term pair weight,sentence number and sentence length.
And the dy-namic programming algorithm is used to searchfor the alignment with the greatest total similarity.This alignment is treated as the best alignment.Champollion aligner can produce good align-ment even on noisy input as reported in (Ma,2006).
Its simplicity and robustness make it agood candidate for practical use.
But this aligneris slow.
Because its time complexity is O(n2) andit has to look up the dictionary multiple times ineach step of the dynamic programming algorithm,which needs higher computational cost.3 Fast-Champollion AlgorithmIn this section we propose a new sentence align-ment algorithm: Fast-Champollion.
Its basisis splitting the input bilingual texts into smallaligned fragments and then further aligning themone by one to reduce running time while maintain-ing Champollion-equivalent (or better) alignmentquality; it takes the advantages of both length-based and lexicon-based algorithms to the maxi-mum extent.
The outline of the algorithm is thatfirst the length-based splitting module is used tosplit the input bilingual texts into aligned frag-ments, and then the components of each of thesefragments will be identified and aligned by aChampollion-based algorithm.
The details are de-scribed in the following sections.3.1 Length-based Splitting ModuleAlthough length-based sentence alignment algo-rithm is not robust enough, it can produce roughalignment very fast with a certain number of re-liably translated beads.
Length-based splittingmodule is designed to select these reliably trans-lated beads to be used for delimiting and splittingthe input bilingual texts into fragments.
Thesebeads will be referred to as anchor beads in theremaining sections.There are four steps in this module as describedbelow in detail.Step 1: decide whether to skip step 2-4 or notWhen there is too much noise in the input bilin-gual texts, the percentage of reliably translatedbeads in the alignment produced by the length-based algorithm will be very low.
In this case, wewill skip step 2 through 4.An evidence for such a situation is that thedifference between the sentence numbers of thesource and target language is too big.
SupposeNS and NT are the number of sentences of thesource and target language respectively.
We spec-ify r = |NS ?
NT |/min{NS , NT } as a measureof the difference, where min means minimum.
Ifr is bigger than a threshold, we say the differenceis too big.
In our experiments, the threshold is setas 0.4 empirically.Step 2: align the input texts usinglength-based algorithmIn this step, length-based sentence alignmentalgorithm is used to align the input bilingual texts.Brown, et al (1991) models the process of sen-tence alignment as two steps.
First, a bead is gen-erated according to a fixed probability distributionover bead types, and then sentence length in thebead is generated according to this model: for the0-to-1 and 1-to-0 type of beads, it is assumed thatthe sentence lengths are distributed according toa probability distribution estimated from the data.For other type of beads, the lengths of sentences ofthe source language are generated independentlyfrom the probability distribution for the 0-to-1 and1-to-0 type of beads, and the total length of sen-tences of the target language is generated accord-ing to a probability distribution conditioned on thetotal length of sentences of the source language.For a bead Ai = (SAi;TAi), lSAi and lTAi arethe total lengths of sentences in SAi and TAi re-spectively, which are measured by word2.
Brown,et al (1991) assumed this conditioned probabilitydistribution isProb(lTAi |lSAi) = ?
exp(?
(?i ?
?
)22?2),where ?i = log(lTAi/lSAi) and ?
is a normal-ization factor.
Moore (2002) assumed the condi-2For Chinese, word segmentation should be done first toidentify words.712tioned probability distribution isProb(lTAi |lSAi) =exp (?lSAir) (lSAir)lTAilTAi !,where r is the ratio of the mean length of sen-tences of the target language to the mean lengthof sentences of the source language.
We tested thetwo models on our development corpus and the re-sult shows that the first model performs better, sowe choose the first one.Step 3: determine the anchor beadsIn this step, the reliably translated beads inthe alignment produced by the length-based algo-rithm in Step 2 will be selected as anchor beads.The length-based algorithm can generate aprobability for each bead it produces.
So a triv-ial way is to choose the beads with a probabilityabove certain threshold as anchor beads.
But aspointed out before, when there is too much noise,the alignment produced by the length-based algo-rithm is no longer reliable, and so is it with theprobability.
A fact is that if we select a non-translated bead as an anchor bead, we will splitthe input bilingual texts into wrong fragments andmay cause many errors.
So we have to make de-cision conservatively in this step and we decide touse lexical information instead of the probabilityto determine the anchor beads.For a bead Ai = (SAi;TAi), the proportion oftranslation term-pairs is a good measure for de-termine whether this bead is reliably translatedor not.
In addition, use of local information willalso be greatly helpful.
To explain the use of ?lo-cal information?, let?s define the fingerprint of asentence first.
Suppose we have a sequence ofsentences S1, S2, ?
?
?
, Sm, and W (Si)is the set ofdistinct words in Si, then the fingerprint of Si isf(Si) = W (Si)?W (Si?1)?W (Si+1),and speciallyf(S1) = W (S1)?W (S2),f(Sm) = W (Sm)?W (Sm?1).The fingerprints of SAi and TAi, denoted byf(SAi) and f(TAi), are the unions of all the fin-gerprints of sentences in SAi and TAi respectively.As you can see, the fingerprint of a sentence is theset of words in the sentence that do not appear inthe adjacent sentence(s), and thus can distinguishthis sentence from its neighbors.
So fingerprintis also a good measure.
By combining these twomeasures together, we can select out more reliablytranslated beads.For a word w, we use dD(w) to denote the setof all its translations in a bilingual dictionary D,and use tD(w) to denote the union of {w} anddD(w), i.e., tD(w) = {w} ?
dD(w).
Given twosets of words A and B.
We say a word w of A istranslated by B if either one of its translations inthe dictionary D or the word itself appears in B,i.e., tD(w)?B 6= ?.
The set of all the words of Athat are translated by B is:hD(A,B) = {w ?
A and tD(w) ?B 6= ?
}.Then the proportion of terms in A that are trans-lated by B isrD(A,B) =|hD(A,B)||A| .We specify the proportion of translation termpairs in a bead, denoted as arD(Ai), to bemin{rD(W (SAi),W (TAi)), rD(W (TAi),W (SAi))},where W (SAi) and W (TAi) are the sets of dis-tinct words in SAi and TAi respectively.
Also wespecify the proportion of translation term-pairsin the fingerprint, denoted as frD(Ai), to bemin{rD(f(SAi), f(TAi)), rD(f(TAi), f(SAi))}.Given thresholds THar and THfr, a bead isselected as an anchor bead when arD(Ai) andfrD(Ai) are not smaller than THar and THfrrespectively.
We will show that Fast-Champollionalgorithm is not sensitive to THar and THfr tosome extent in Section 4.2.Step 4: split the input bilingual textsThe anchor beads determined in Step 3 are usedto split the input texts into fragments.
The endinglocation of each anchor bead is regarded as a split-ting point, resulting in two fragments.3.2 Aligning Fragments with ChampollionAlignerThe similarity function used by Champollionaligner is defined as follows.
Given two (source713and target language) groups of sentences in afragment, denoted by GS=S1, S2,?
?
?
,Sm andGT=T1, T2,?
?
?
,Tn, suppose there are k pairsof translated terms in GS and GT denotedby (ws1, wt1),(ws2, wt2),?
?
?
,(wsk, wtk), wherewsi is in GS and wti is in GT .
For each pair ofthe translated terms (wsi, wti), define idtf(wsi)to beTotal # of terms in the whole document# occurrences of wsi in GS,and definestf(wsi, wti) = min{stf(wsi), stf(wti)},where stf(wsi) and stf(wti) are the frequencyof wsi and wti in GS and GT respectively.
Thesimilarity between GS and GT is defined ask?i=1log (idtf(wsi)?
stf(wsi, wti))?alignment penalty?length penalty,where alignment penalty is 1 for 1-to-1 align-ment type of beads and a number between 0 and 1for other type of beads, length penalty is a func-tion of the total sentence lengths of GS and GT .The reason for choosing Champollion alignerinstead of other algorithms will be given in Sec-tion 4.2.
And another question is how idtf valuesshould be calculated.
idtf is used to estimate howwidely a term is used.
An intuition is that idtfwill work better if the texts are longer, becauseif the texts are short, most words will have a lowfrequency and will seem to only appear locally.
InFast-Champollion, we calculate idtf according tothe whole document instead of each fragment.
Inthis way, a better performance is achieved.3.3 Parameter EstimationA development corpus is used to estimate the pa-rameters needed by Fast-Champollion.For the length-based algorithm, there are fiveparameters that need to be estimated.
The first oneis the probability distribution over bead types.
Theratio of different types of beads in the develop-ment corpus is used as the basis for the estimation.The second and third parameters are the proba-bility distributions over the sentence length of thesource language and the target language.
Thesedistributions are estimated as the distributions ob-served from the input bilingual texts.
That is tosay, these two distributions will not be the samefor different bilingual input texts.
The forth andfifth are ?
and ?.
They are estimated as the meanand variance of ?i over the development corpus.For Champollion aligner, alignment penaltyand length penalty need to be determined.
Be-cause the Perl version of Champollion aligner3is well developed, we borrow the two definitionsfrom it directly.4 Experiments4.1 Datasets and Evaluation MetricsWe have two English-Chinese parallel corpora,one for the development purpose and one for thetesting purpose.
Both of the two corpora are col-lected from the Internet and are manually aligned.The development corpus has 2,004 beads.Given the space constraint, detailed informationabout the development corpus is omitted here.The testing corpus contains 26 English-Chinesebilingual articles collected from the Internet, in-cluding news reports, novels, science articles,television documentary subtitles and the record ofgovernment meetings.
There are 9,130 Englishsentences and 9,052 Chinese sentences in these ar-ticles4.
The number of different type of beads inthe golden standard answer is shown in Table 1.Type Number Percentage(%)1:1 7275 83.191:2 2:1 846 9.671:3 3:1 77 0.881:4 4:1 16 0.182:2 32 0.371:0 0:1 482 5.51others 17 0.19total 8745 100.00Table 1: Types of beads in the golden standardBoth the Fast-Champollion algorithm and theChampollion aligner need a bilingual dictionaryand we supply the same bidirectional dictionary to3http://champollion.sourceforge.net4The definition of ?sentence?
is slightly different from thecommon sense here.
We also treat semicolon and colon as theend of a sentence.714them in the following evaluations.
This dictionarycontains 45,439 pair of English-Chinese transla-tion terms.We use four commonly used measures for eval-uating the performance of a sentence alignmentalgorithm, which are the running time,Precision = |GB ?
PB||PB| ,Recall = |GB ?
PB||GB| ,andF1-measure = 2?
Precision?RecallPrecision+Recall ,where GB is the set of beads in the golden stan-dard, and PB is the set of beads produced by thealgorithm.All the following experiments are taken on a PCwith an Intel QX6800 CPU and 8GB memory.4.2 Algorithm Design IssuesWhy Choose Champollion?We compared Champollion aligner with twoother sentence alignment algorithms which alsomake use of lexical information.
And the resultis shown in Table 2.
?Moore-1-to-1?
and ?Moore-all?
are corresponding to the algorithm proposedin (Moore, 2002).
The difference between them ishow Recall is calculated.
Moore?s algorithm canonly output 1-to-1 type of beads.
For ?Moore-1-to-1?, we only consider beads of 1-to-1 type inthe golden standard when calculating Recall, butall types of beads are considered for ?Moore-all?.The result suggests that ignoring the beads that arenot of 1-to-1 type does have much negative effecton the overall performance of Moore?s algorithm.Our goal is to design a general purpose sentencealignment algorithm that can process frequentlyobserved types of beads.
So Moore?s algorithm isnot a good choice.
Hunalign refers to the hunalignalgorithm proposed in (Varga et al, 2005).
The re-sources provided to Champollion aligner and hu-nalign algorithm are the same in the test, but hu-nalign algorithm?s performance is much lower.
Sohunalign algorithm is not a good choice either.Champollion algorithm is simple and has a highoverall performance.
So it is a better choice forus.Aligner Precision Recall F1-measureChampollion 0.9456 0.9546 0.9501Moore-1-to-1 0.9529 0.9436 0.9482Moore-all 0.9529 0.7680 0.8505Hunalign 0.8813 0.9037 0.8923Table 2: The performance of different aligners onthe development corpusThe Effect of THar and THfrTHar and THfr are two thresholds for select-ing anchor beads in Step 3 of length-based split-ting module.
In order to investigate the effect ofthese two thresholds on the performance of Fast-Champollion, we run Fast-Champollion on the de-velopment corpus with different THar and THfr.Both THar and THfr vary from 0 to 1 with step0.05.
And the running time and F1-measure areshown in Figure 1 and Figure 2 respectively.0 0.5100.51050100150200TH arTHfrRunning time(s)Figure 1: The running time corresponding to dif-ferent THar and THfr0 0.5100.510.80.850.90.951TH arTHfrF1?measureFigure 2: The F1-measure corresponding to dif-ferent THar and THfr715From Figure 1 and Figure 2, we see that for alarge range of the possible values of THar andTHfr, the running time of Fast-Champollion in-creases slowly while F1-measure are nearly thesame.
In other words, Fast-Champollion are notsensitive to THar and THfr to some extent.
Somaking choice for the exact values of THar andTHfr becomes simple.
And we use 0.5 for bothof them in the following experiments.4.3 Performance of Fast-ChampollionWe use three baselines in the following evalua-tions.
One is an implementation of the length-based algorithm in Java, one is a re-implementedChampollion aligner in Java according to the Perlversion, and the last one is Fast-Champollion-Recal.
Fast-Champollion-Recal is the same asFast-Champollion except that it calculates idtfvalues according to the fragments themselves in-dependently instead of the whole document, andthe Java versions of the length-based algorithmand Champollion aligner are used for evaluation.Performance on Texts from the InternetTable 3 shows the performance of Fast-Champollion and the baselines on the testing cor-pus.
The result shows that Fast-Champollionachieves slightly better performance than Fast-Champollion-Recal.
The running time of Cham-pollion is about 2.6 times longer than Fast-Champollion with lower Precision, Recall andF1-measure.
It should be pointed out that Fast-Champollion achieves better Precision, Recall andF1-measure than Champollion does because thesplitting process may split the regions hard toalign into different fragments and reduces thechance for making mistakes.
Because of the noisein the corpus, the F1-measure of the length-basedalgorithm is low.
This result suggests that Fast-Champollion is fast, robust and effective enoughfor aligning texts from the Internet.Robustness of Fast-ChampollionIn order to make a more precise investigationon the robustness of Fast-Champollion againstnoise, we made the following evaluation.
Firstwe manually removed all the 1-to-0 and 0-to-1 type of beads from the testing corpus to pro-duce a clean corpus.
This corpus contains 8,263beads.
Then we added 8263?n% 1-to-0 or 0-to-1 type of beads to this corpus at arbitrary posi-tions to produce a series of noisy corpora, withn having the values of 5,10,...,100.
Finally weran Fast-Champollion algorithm and the baselineson these corpora respectively and the results areshown in Figure 3 and Figure 4, which indi-cate that for Fast-Champollion, when n increases1, Precision drops 0.0021, Recall drops 0.0038and F1-measure drops 0.0030 on average, whichare very similar to those of Champollion, butFast-Champollion is 4.0 to 5.1 times as fast asChampollion.
This evaluation proves that Fast-Champollion is robust against noise and is a morereasonable choice for practical use.0 20 40 60 80 100050100150200250300Noisy LevelRunning time(s)Time of Fast?ChampollionTime of Fast?Champllion?RecalTime of ChampollionTime of length?based alignerFigure 3: Running Time of Fast-Champollion,Fast-Champollion-Recal, Champollion and thelength-based algorithm0 20 40 60 80 10000.20.40.60.81X: 100Y: 0.5427Noisy LevelF1 of FCF1 of FCRF1 of CF1 of LP of FCP of FCRP of CP of LR of FCR of FCRR of CR of LFigure 4: Precision (P), Recall (R) and F1-measure (F1) of Fast-Champollion (FC), Fast-Champollion-Recall (FCR), Champollion (C) andthe length-base algorithm (L)Performance on Long TextsIn order to test the scalability of Fast-Champollion algorithm, we evaluated it on longtexts.
We merged all the articles in the testing cor-716Aligner Precision Recall F1-measure Running time(s)Fast-Champollion 0.9458 0.9408 0.9433 48.0Fast-Champollion-Recal 0.9470 0.9373 0.9421 45.4Champollion 0.9450 0.9385 0.9417 173.5Length-based 0.8154 0.7878 0.8013 11.3Table 3: Performance on texts from the InternetAligner Precision Recall F1-measure Running time(s)Fast-Champollion 0.9457 0.9418 0.9437 51.5Fast-Champollion-Recall 0.9456 0.9362 0.9409 50.7Champollion 0.9464 0.9412 0.9438 2029.0Length-based 0.8031 0.7729 0.7877 23.8Table 4: Performance on long textpus into a single long ?article?.
Its length is com-parable to that of the novel of Wuthering Heights.Table 4 shows the evaluation results on this longarticle.
Fast-Champollion is about 39.4 times asfast as Champollion with slightly lower Precision,Recall and F1-measure, and is just about 1.2 timesslower than the length-based algorithm, which hasmuch lower Precision, Recall and F1-measure.
SoFast-Champollion is also applicable for long text,and has a significantly higher speed.4.4 Evaluation of the Length-based SplittingModuleThe reason for Fast-Champollion can achieve rel-atively high speed is that the length-based split-ting module can split the bilingual input texts intomany small fragments reliably.
We investigate thefragments produced by the length-based splittingmodule when aligning the long article used in Sec-tion 4.3.
The length-based splitting module splitsthe long article at 1,993 places, and 1,972 seg-ments are correct.
The numbers of Chinese andEnglish segments with no more than 30 Chineseand English sentences are shown in Figure 5.
Asthere are only 27 and 29 segments with more than30 sentences for Chinese and English respectively,we omit them in the figure.
We can conclude thatalthough the length-based splitting module is sim-ple, it is efficient and reliable.5 Conclusion and Future WorkIn this paper we propose a new sentence align-ment algorithm Fast-Champollion.
It reduces therunning time by first splitting the bilingual inputtexts into small aligned fragments and then furtheraligning them one by one.
The evaluations show0 5 10 15 20 25 300200400600800Number of Sentences Contained in a SegmentNumberEnglish SegmentChinese SegmentFigure 5: Numbers of Chinese/English segmentswith no more than 30 Chinese/English sentencesthat Fast-Champollion is fast, robust and effectiveenough for practical use, especially for aligninglarge amount of bilingual texts or long bilingualtexts.Fast-Champollion needs a dictionary for align-ing sentences, and shares the same problem ofChampollion aligner as indicated in (Ma, 2006),that is the precision and recall will drop as thesize of the dictionary decreases.
So how to buildbilingual dictionaries automatically is an impor-tant task for improving the performance of Fast-Champollion in practice, and is a critical problemfor applying Fast-Champollion on language pairswithout a ready to use dictionary.AcknowledgementThis research is supported by the Boeing-Tsinghua Joint Research Project ?Robust Chi-nese Word Segmentation and High PerformanceEnglish-Chinese Bilingual Text Alignment?.717ReferencesBrown, Peter F., Jennifer C. Lai, and Robert L. Mercer.1991.
Aligning sentences in parallel corpora.
InProceedings of the 29th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 169?176, Berkeley, California, USA, June.
Associationfor Computational Linguistics.Chen, Stanley F. 1993.
Aligning sentences in bilin-gual corpora using lexical information.
In Proceed-ings of the 31st Annual Meeting of the Associationfor Computational Linguistics, pages 9?16, Colum-bus, Ohio, USA, June.
Association for Computa-tional Linguistics.Ma, Xiaoyi.
2006.
Champollion: A robust paral-lel text sentence aligner.
In Proceedings of LREC-2006: Fifth International Conference on LanguageResources and Evaluation, pages 489?492.Melamed, I. Dan.
1996.
A geometric approach tomapping bitext correspondence.
In Proceedings ofthe First Conference on Empirical Methods in Nat-ural Language Processing, pages 1?12.Moore, Robert C. 2002.
Fast and accurate sentencealignment of bilingual corpora.
In Proceedings ofthe 5th Conference of the Association for MachineTranslation in the Americas on Machine Transla-tion: From Research to Real Users, pages 135?144,London, UK.
Springer-Verlag.Simard, Michel, George F. Foster, and Pierre Isabelle.1993.
Using cognates to align sentences in bilingualcorpora.
In Proceedings of the 1993 Conference ofthe Centre for Advanced Studies on CollaborativeResearch, pages 1071?1082.
IBM Press.Utsuro, Takehito, Hiroshi Ikeda, Masaya Yamane, YujiMatsumoto, and Makoto Nagao.
1994.
Bilingualtext matching using bilingual dictionary and statis-tics.
In Proceedings of the 15th Conference onComputational Linguistics, pages 1076?1082, Mor-ristown, NJ, USA.
Association for ComputationalLinguistics.Varga, D., L. Nmeth, P. Halcsy, A. Kornai, V. Trn, andNagy V. 2005.
Parallel corpora for medium den-sity languages.
In Proceedings of the RANLP 2005,pages 590?596.Wu, Dekai.
1994.
Aligning a parallel english-chinesecorpus statistically with lexical criteria.
In Proceed-ings of the 32nd Annual Meeting of the Associationfor Computational Linguistics, pages 80?87, LasCruces, New Mexico, USA, June.
Association forComputational Linguistics.718
