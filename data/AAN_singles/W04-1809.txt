Term Extraction from Korean Corpora via JapaneseAtsushi Fujii, Tetsuya IshikawaGraduate School of Library,Information and Media StudiesUniversity of Tsukuba1-2 Kasuga, Tsukuba305-8550, Japan{fujii,ishikawa}@slis.tsukuba.ac.jpJong-Hyeok LeeDivision of Electrical andComputer Engineering,Pohang University of Science and Technology,Advanced Information Technology Research CenterSan 31 Hyoja-dong Nam-gu,Pohang 790-784, Republic of Koreajhlee@postech.ac.krAbstractThis paper proposes a method to extract foreignwords, such as technical terms and proper nouns,from Korean corpora and produce a Japanese-Korean bilingual dictionary.
Specific words havebeen imported into multiple countries simultane-ously, if they are influential across cultures.
Thepronunciation of a source word is similar in differentlanguages.
Our method extracts words in Koreancorpora that are phonetically similar to Katakanawords, which can easily be identified in Japanese cor-pora.
We also show the effectiveness of our methodby means of experiments.1 IntroductionReflecting the rapid growth in science and tech-nology, new words have progressively been created.However, due to the limitation of manual compila-tion, new words are often out-of-dictionary wordsand decrease the quality of human language tech-nology, such as natural language processing, infor-mation retrieval, machine translation, and speechrecognition.
To resolve this problem, a numberof automatic methods to extract monolingual andbilingual lexicons from corpora have been proposedfor various languages.In this paper, we focus on extracting foreign words(or loanwords) in Korean.
Technical terms andproper nouns are often imported from foreign lan-guages and are spelled out (or transliterated) by theKorean alphabet system called Hangul .
The similartrend can be observable in Japanese and Chinese.
InJapanese, foreign words are spelled out by its specialphonetic alphabet (or phonogram) called Katakana.Thus, foreign words can be extracted from Japanesecorpora with a high accuracy, because the Katakanacharacters are seldom used to describe the conven-tional Japanese words, excepting proper nouns.However, extracting foreign words from Koreancorpora is more difficult, because in Korean boththe conventional and foreign words are written withHangul characters.
This problem remains a chal-lenging issue in computational linguistic research.It is often the case that specific words have beenimported into multiple countries simultaneously, be-cause the source words (or concepts) are usually in-fluential across cultures.
Thus, it is feasible that alarge number of foreign words in Korean can also beforeign words in Japanese.In addition, the foreign words in Korean andJapanese corresponding to the same source word arephonetically similar.
For example, the English word?system?
has been imported into both Japanese andKorean.
The romanized words are /sisutemu/ and/siseutem/ in both countries, respectively.Motivated by these assumptions, we propose amethod to extract foreign words in Korean corporaby means of Japanese.
In brief, our method per-forms as follows.
First, foreign words in Japaneseare collected, for which Katakana words in corporaand existing lexicons can be used.
Second, from Ko-rean corpora the words that are phonetically similarto Katakana words are extracted.
Finally, extractedKorean words are compiled in a lexicon with the cor-responding Japanese words.In summary, our method can extract foreign wordsin Korean and produce a Japanese-Korean bilinguallexicon in a single framework.2 Methodology2.1 OverviewFigure 1 exemplifies our extraction method, whichproduces a Japanese-Korean bilingual lexicon usinga Korean corpus and Japanese corpus and/or lexi-con.
The Japanese and Korean corpora do not haveto be parallel or comparable.
However, it is desir-able that both corpora are associated with the samedomain.
For the Japanese resource, the corpus andlexicon can alternatively be used or can be used to-gether.
Note that compiling Japanese monolinguallexicon is less expensive than that for a bilingual lex-icon.
In addition, new Katakana words can easily beextracted from a number of on-line resources, suchas the World Wide Web.
Thus, the use of Japaneselexicons does not decrease the utility of our method.First, we collect Katakana words from Japaneseresources.
This can systematically be performed bymeans of a Japanese character code, such as EUC-JP and SJIS.Second, we represent the Korean corpus andJapanese Katakana words by the Roman alphabet(i.e., romanization), so that the phonetic similaritycan easily be computed.
However, we use differentromanization methods for Japanese and Korean.CompuTerm 2004 Poster Session  -  3rd International Workshop on Computational Terminology 71Third, we extract candidates of foreign wordsfrom the romanized Korean corpus.
An alternativemethod is to first perform morphological analysison the corpus, extract candidate words based onmorphemes and parts-of-speech, and romanize theextracted words.
Our general model does not con-strain as to which method should be used in thethird step.
However, because the accuracy of anal-ysis often decreases for new words to be extracted,we experimentally adopt the former method.Finally, we compute the phonetic similarity be-tween each combination of the romanized Hanguland Katakana words, and select the combinationswhose score is above a predefined threshold.
As aresult, we can obtain a Japanese-Korean bilinguallexicon consisting of foreign words.It may be argued that English lexicons or cor-pora can be used as source information, instead ofJapanese resources.
However, because not all En-glish words have been imported into Korean, theextraction accuracy will decrease due to extraneouswords.Figure 1: Overview of our extraction method.2.2 Romanizing JapaneseBecause the number of phones consisting of JapaneseKatakana characters is limited, we manually pro-duced the correspondence between each phoneand its Roman representation.
The numbers ofKatakana characters and combined phones are 73and 109, respectively.
We also defined a symbol torepresent a long vowel.
In Japanese, the Hepbernand Kunrei systems are commonly used for roman-ization purposes.
We use the Hepburn system, be-cause its representation is similar to that in Korean,compared with the Kunrei system.However, specific Japanese phones, such as /ti/,do not exist in Korean.
Thus, to adapt the Hepburnsystem to Korean, /ti/ and /tu/ are converted to/chi/ and /chu/, respectively.2.3 Romanizing KoreanThe number of Korean Hangul characters is muchgreater than that of Japanese Katakana characters.Each Hangul character is a combination of morethan one consonant.
The pronunciation of each char-acter is determined by its component consonants.In Korean, there are types of consonant, i.e., thefirst consonant, vowel, and last consonant.
Thenumbers of these consonants are 19, 21, and 27, re-spectively.
The last consonant is optional.
Thus, thenumber of combined characters is 11,172.
However,to transliterate imported words, the official guide-line suggests that only seven consonants be used asthe last consonant.
In EUC-KR, which is a stan-dard coding system for Korean text, 2,350 commoncharacters are coded independent of the pronunci-ation.
Therefore, if we target corpora representedby EUC-KR, each of the 2,350 characters has to becorresponded to its Roman representation.We use Unicode, in which Hangul characters aresorted according to the pronunciation.
Figure 2 de-picts a fragment of the Unicode table for Korean,in which each line corresponds to a combinationof the first consonant and vowel and each columncorresponds to the last consonant.
The number ofcolumns is 28, i.e., the number of the last consonantsand the case in which the last consonant is not used.From this figure, the following rules can be found: the first consonant changes every 21 lines, whichcorresponds to the number of vowels, the vowel changes every line (i.e., 28 characters)and repeats every 21 lines, the last consonant changes every column.Based on these rules, each character and its pro-nunciation can be identified by the three consonanttypes.
Thus, we manually corresponded only the 68consonants to Roman alphabets.Figure 2: A fragment of the Unicode table for Ko-rean Hangul characters.We use the official romanization system for Ko-rean, but specific Korean phones are adapted toJapanese.
For example, /j/ and /l/ are convertedto /z/ and /r/, respectively.It should be noted that the adaptation is not in-vertible and thus is needed for both J-to-K and K-to-J directions.CompuTerm 2004 Poster Session  -  3rd International Workshop on Computational Terminology72For example, the English word ?cheese?, whichhas been imported to both Korean and Japanese asa foreign word, is romanized as /chiseu/ in Koreanand /ti:zu/ in Japanese.
Here, /:/ is the symbolrepresenting a Japanese long vowel.
Using the adap-tation, these expressions are converted to /chizu/and /chi:zu/, respectively, which look more similarto each other, compared with the original strings.2.4 Extracting term candidates fromKorean corporaTo extract candidates of foreign words from a Ko-rean corpus, we first extract phrases.
This can beperformed systematically, because Korean sentencesare segmented on a phrase-by-phrase basis.Second, because foreign words are usually nouns,we use hand-crafted rules to remove post-positionsuffixes (e.g., Josa) and extract nouns from phrases.Third, we discard nouns including the last con-sonants that are not recommended for translitera-tion purposes in the official guideline.
Although theguideline suggests other rules for transliteration, ex-isting foreign words in Korean are not necessarilyregulated by these rules.Finally, we consult a dictionary to discard exist-ing Korean words, because our purpose is to extractnew words.
For this purpose, we experimentallyuse the dictionary for SuperMorph-K morphologi-cal analyzer1, which includes approximately 50,000Korean words.2.5 Computing SimilarityGiven romanized Japanese and Korean words, wecompute the similarity between the two strings andselect the pairs associated with the score above athreshold as translations.
We use a DP (dynamicprogramming) matching method to identify thenumber of differences (i.e., insertion, deletion, andsubstitution) between two strings, on a alphabet-by-alphabet basis.In principle, if two strings are associated with asmaller number of differences, the similarity betweenthem becomes greater.
For this purpose, a Dice-stylecoefficient can be used.However, while the use of consonants in translit-eration is usually the same across languages, theuse of vowels can vary significantly depending onthe language.
For example, the English word ?sys-tem?
is romanized as /sisutemu/ and /siseutem/in Japanese and Korean, respectively.
Thus, the dif-ferences in consonants between two strings shouldbe penalized more than the differences in vowels.In view of the above discussion, we compute thesimilarity between two romanized words by Equa-tion (1).1 ?2 ?
(?
?
dc + dv)?
?
c + v (1)Here, dc and dv denote the numbers of differencesin consonants and vowels, respectively, and ?
is a1http://www.omronsoft.com/parametric constant used to control the importanceof the consonants.
We experimentally set ?
= 2.
Inaddition, c and v denote the numbers of all conso-nants and vowels in the two strings.
The similarityranges from 0 to 1.3 Experimentation3.1 Evaluating Extraction AccuracyWe collected 111,166 Katakana words (word types)from multiple Japanese lexicons, most of which weretechnical term dictionaries.We used the Korean document set in the NTCIR-3Cross-lingual Information Retrieval test collection2.This document set consists of 66,146 newspaper ar-ticles of Korean Economic Daily published in 1994.We randomly selected 50 newspaper articles andused them for our experiment.
We asked a grad-uate student excluding the authors of this paper toidentify foreign words in the target text.
As a result,124 foreign word types (205 word tokens) were iden-tified, which were less than we had expected.
Thiswas partially due to the fact that newspaper articlesgenerally do not contain a large number of foreignwords, compared with technical publications.We manually classified the extracted words andused only the words that were imported to bothJapan and Korea from other languages.
We dis-carded foreign words in Korea imported from Japan,because these words were often spelled out by non-Katakana characters, such as Kanji (Chinese charac-ter).
A sample of these words includes ?Tokyo (thecapital of Japan)?, ?Heisei (the current Japaneseera name)?, and ?enko (personal connection)?.
Inaddition, we discarded the foreign proper nouns forwhich the human subject was not able to identifythe source word.
As a result, we obtained 67 targetword types.
Examples of original English words forthese words are as follows:digital, group, dollar, re-engineering, line,polyester, Asia, service, class, card, com-puter, brand, liter, hotel.Thus, our method can potentially be applied toroughly a half of the foreign words in Korean text.We used the Japanese words to extract plausi-ble foreign words from the target Korean corpus.We first romanized the corpus and extracted nounsby removing post-position suffixes.
As a result, weobtained 3,106 words including all the 67 targetwords.
By discarding the words in the dictionaryfor SuperMorph-K, 958 words including 59 targetwords were remained.For each of the remaining 958 words, we computedthe similarity between each of the 111,166 Japanesewords.
For evaluation purposes, we varied a thresh-old for the similarity and investigated the relationbetween precision and recall.
Recall is the ratioof the number of target foreign words extracted byour method and the total number of target foreign2http://research.nii.ac.jp/ntcir/index-en.htmlCompuTerm 2004 Poster Session  -  3rd International Workshop on Computational Terminology 73words.
Precision is the ratio of the number of targetforeign words extracted by our method and the totalnumber of words obtained by our method.Table 1 shows the precision and recall for differ-ent methods.
While we varied a threshold of a sim-ilarity, we also varied the number of Korean wordscorresponded to a single Katakana word (N).
Bydecreasing the value of the threshold and increasingthe number of words extracted, the recall can be im-proved but the precision decreases.
In Table 1, theprecision and recall are in an extreme trade-off rela-tion.
For example, when the recall was 69.5%, theprecision was only 1.2%.We manually analyzed the words that were not ex-tracted by our method.
Out of the 59 target words,12 compound words consisting of both conventionaland foreign words were not extracted.
However,our method extracted compound words consistingof only foreign words.
In addition, the three wordsthat did not have counterparts in the input Japanesewords were not extracted.Table 1: Precision/Recall for term extraction.Threshold for similarity>0.9 >0.7 >0.5N=1 50.0/8.5 12.7/40.7 4.1/47.5N=10 50.0/8.5 7.4/47.5 1.2/69.53.2 Application-Oriented EvaluationDuring the first experiment, we determined a specificthreshold value for the similarity between Katakanaand Hangul words and selected the pairs whose sim-ilarity was above the threshold.
As a result, we ob-tained 667 Korean words, which were used to en-hance the dictionary for the SuperMorph-K morpho-logical analyzer.We performed morphological analysis on the 50articles used in the first experiment, which included1,213 sentences and 9,557 word tokens.
We also in-vestigated the degree to which the analytical accu-racy is improved by means of the additional dictio-nary.
Here, accuracy is the ratio of the number ofcorrect word segmentations and the total segmenta-tions generated by SuperMorph-K.
The same humansubject as in the first experiment identified the cor-rect word segmentations for the input articles.First, we focused on the accuracy of segmentingforeign words.
The accuracy was improved from75.8% to 79.8% by means of the additional dictio-nary.
The accuracy for all words was changed from94.6% to 94.8% by the additional dictionary.In summary, the additional dictionary was effec-tive for analyzing foreign words and was not asso-ciated with side effect for the overall accuracy.
Atthe same time, we concede that we need larger-scaleexperiments to draw firmer conclusions.4 Related WorkA number of corpus-based methods to extract bilin-gual lexicons have been proposed (Smadja et al,1996).
In general, these methods use statistics ob-tained from a parallel or comparable bilingual corpusand extract word or phrase pairs that are stronglyassociated with each other.
However, our methoduses a monolingual Korean corpus and a Japaneselexicon independent of the corpus, which can easilybe obtained, compared with parallel or comparablebilingual corpora.Jeong et al (1999) and Oh and Choi (2001) in-dependently explored a statistical approach to de-tect foreign words in Korean text.
Although the de-tection accuracy is reasonably high, these methodsrequire a training corpus in which conventional andforeign words are annotated.
Our approach does notrequire annotated corpora, but the detection accu-racy is not high enough as shown in Section 3.1.
Acombination of both approaches is expected to com-pensate the drawbacks of each approach.5 ConclusionWe proposed a method to extract foreign words,such as technical terms and proper nouns, from Ko-rean corpora and produce a Japanese-Korean bilin-gual dictionary.
Specific words, which have beenimported into multiple countries, are usually spelledout by special phonetic alphabets, such as Katakanain Japanese and Hangul in Korean.Because extracting foreign words spelled out byKatakana in Japanese lexicons and corpora can beperformed with a high accuracy, our method ex-tracts words in Korean corpora that are phoneticallysimilar to Japanese Katakana words.
Our methoddoes not require parallel or comparable bilingual cor-pora and human annotation for these corpora.We also performed experiments in which we ex-tracted foreign words from Korean newspaper arti-cles and used the resultant dictionary for morpho-logical analysis.
We found that our method did notcorrectly extract compound Korean words consist-ing of both conventional and foreign words.
Futurework includes larger-scale experiments to further in-vestigate the effectiveness of our method.ReferencesKil Soon Jeong, Sung Hyon Myaeng, Jae Sung Lee,and Key-Sun Choi.
1999.
Automatic identificationand back-transliteration of foreign words for informa-tion retrieval.
Information Processing & Management,35:523?540.Jong-Hoon Oh and Key sun Choi.
2001.
Automaticextraction of transliterated foreign words using hid-den markov model.
In Proceedings of ICCPOL-2001,pages 433?438.Frank Smadja, Kathleen R. McKeown, and VasileiosHatzivassiloglou.
1996.
Translating collocations forbilingual lexicons: A statistical approach.
Computa-tional Linguistics, 22(1):1?38.CompuTerm 2004 Poster Session  -  3rd International Workshop on Computational Terminology74
