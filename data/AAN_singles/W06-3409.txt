Proceedings of the Analyzing Conversations in Text and Speech (ACTS) Workshop at HLT-NAACL 2006, pages 58?61,New York City, New York, June 2006. c?2006 Association for Computational LinguisticsPragmatic Discourse Representation TheoryYafa Al-RahebNational Centre for Language TechnologyDublin City UniversityIrelandyafa.alraheb@gmail.comAbstractThis paper presents a pragmatic approach to Dis-course Representation Theory (DRT) in an attemptto address the pragmatic limitations of DRT (Werth1999; Simons 2003).
To achieve a more prag-matic DRT model, this paper extends standard DRTframework to incorporate more pragmatic elementssuch as representing agents?
cognitive states and thecomplex process through which agents recognizeutterances employing the linguistic content in form-ing mental representations of other agent?s cogni-tive states.
The paper gives focus to the usuallyignored link in DRT literature between speaker be-liefs and the linguistic content, and between the lin-guistic content and hearer?s beliefs.1 IntroductionDevelopments in dynamic semantics, resulting inDRT, have led to a framework suitable for the rep-resentation of linguistic phenomena (van Eijck andKamp 1997).
This is specifically due to the fact that,recognizing the importance of context, DRT concen-trates on updating the context with the processing ofeach utterance.
In addition, DRT can also be viewedas an agent?s mental model of the world and not justa representation of the discourse.
It is for these rea-sons that DRT holds great potential for incorporatingmore pragmatic phenomena.However, despite the suitability of DRT for repre-senting linguistic phenomena, some pragmatic lim-itations have been noted in the literature.
Simons(2003) remarks that DRT is a theory of seman-tics and not pragmatics.
Werth remarks that ?thereis no place in [DRT] for participant roles, setting,background knowledge, purposes, even inferences?
(Werth 1999: 65).
In general terms, we can say thatthe pragmatic dimension supplements semantic con-tent by using context and cognitive states of agentsin dialogue.
The discipline of pragmatics is, there-fore, concerned with the process by which agentsinfer information about elements of another agents?cognitive state such as their beliefs and intentions.Thus, this paper focuses on extending standard DRTpragmatically to model agents?
cognitive states inthe pragmatic context of dialogue.2 A More Pragmatic DRTThis section presents a more pragmatic DRT focus-ing on the relationship between speaker generationand the linguistic content, and between the linguisticcontent and hearer recognition.
Figure 1 representsthe link between our representation of the speaker?scognitive state, the speaker?s linguistic content andthe hearer?s cognitive state or DRS (Discourse Rep-resentation Structure).
This relationship has not toour knowledge been explored in the literature anddeserves investigation.Generally speaking, to generate an utterance,there would be some discrepancy between thespeaker?s beliefs and the speaker?s beliefs about thehearer?s beliefs.
The discrepancy leads to an utter-ance, i.e.
linguistic content.
The linguistic contentis the window the hearer has onto the speaker?s stateof mind.
It is what influences hearer recognition.By analysis of the linguistic content provided by thespeaker, the hearer can propose a hypothesis regard-ing the speaker?s state of mind.58Speaker Generation:i youattitude(i, ?BEL?, drs1)drs1:attitude(i, ?INT?, drs2)drs2:?
Linguistic contentSpeaker?s utterance ?
Hearer Recognition:i youattitude(i, ?BEL?, drs3)drs3:attitude(you, ?INT?, drs4)drs4:Figure 1: Speaker DRS, Linguistic Content and Hearer DRS2.1 New DR-StructuresThe DRT representation introduced here extendsstandard DRT language and structure resulting in asuitable pragmatic-based framework for represent-ing this pragmatic link.
Separate DRSs are createdto represent each agent.
DRSs get updated with eachnew utterance.
Each DRS representing an agent?scognitive state includes the two personal referencemarkers ?i?
and ?you?.
When ?i?
is used in a DRS, itrefers to the agent?s self within that DRS; i.e.
if theagent is the speaker, then ?i?
refers to the speaker inthe entire DRS.
To refer to the other agent, ?you?
isused.
To follow from the speaker?s example, ?you?
inthis case refers to the hearer.
To account for agents?cognitive states and their meta-beliefs, a sub-DRSrepresenting the agent?s cognitive state called the be-lief DRS is created to include the speaker?s beliefsabout the hearer?s beliefs.
Additionally, a new DRSfor representing weaker beliefs called acceptance isintroduced.
The same level of embedding offeredto belief DRSs is introduced in acceptance DRSs.Acceptance DRS includes the speaker?s acceptanceDRS as well as what the speaker takes the hearer toaccept.
Provided the speaker has sufficient informa-tion, the speaker can also have the embedded DRSwithin the acceptance DRS that represents what thehearer takes the speaker to accept.In addition to expanding the belief DRS, eachagent?s cognitive state contains an intention DRS.
In-tention in the sense used here refers to the agent?sgoals in making an utterance, which are representedby the corresponding dialogue act marked in theintention DRS.
The hearer?s intention DRS repre-sents the recognized utterance and contains elementsof utterance-making generally associated with prag-matics such as the function of an utterance, its dia-logue act.
This pragmatic enriching strengthens thelink between an agent?s intentions and the linguisticform uttered.
What is proposed is that the intentionDRS be designed to include the linguistic contentprovided within utterances.To further enhance the link between agents?
cog-nitive states and the linguistic content of their ut-terances, the intention DRS contains the rich prag-matic information offered by explicitly marking thepresupposition (given information) and the assertion(new information) of the current utterance.
The in-tention DRS is a separate DRS from the belief DRS.The beliefs of an agent give the motivation for mak-ing an utterance, and the intention DRS representsthe speaker?s intended message.
The recognitionof an utterance gives the hearer an insight into theagent?s beliefs.
Depending upon the particular dia-logue represented, the intention DRS could have thespeaker?s intention, the hearer?s intentions or both.The intention DRS functions as the immediate con-text, the one containing the utterance being gener-ated or recognized.
The belief and acceptance DRSsfunction as background context containing informa-tion pertaining to the dialogue and not just the cur-rent utterance.
This division of labour context-wiseis useful in that the information represented in theintention DRS directly feeds into the speaker?s ut-terance, and is then inferred by the hearer throughthe linguistic content.
The hearer?s intention DRSincludes the inferred speaker intentions in utteringthe current utterance.
This gives the flexibility ofbeing able to model information that the hearer hasinferred but has not yet decided to accept or believeand is, therefore, not yet included in either the beliefor acceptance DRS.
For instance, while the hearerin example (1) has recognized S1?s utterance, he hasnot yet accepted S1?s utterance.
This motivates sep-arating the representation of beliefs from intentions.59(1) S1: Bob?s trophy wife is cheating on him.H1: When did Bob get married?2.2 Extending DRT LanguageIn addition to the three DRSs introduced above, inorder to make the link between speaker generation,linguistic content, and hearer recognition more ex-plicit, labels, ?labeln?, n an integer, are introduced.The labels mark the distinction between presupposi-tion and assertion, and the distinction between weakand strong beliefs.
Furthermore, the labels can beused to refer to a particular predicate by anothercomplex predicate.
The labels increase the expres-sive power from an essentially first-order formal-ism to a higher-order formalism.
Presuppositionsare marked by a presupposition label ?pn?.
Simi-larly, DRSs inside the main speaker or hearer DRSare labeled ?drsn?.
Assertions are marked by ?an?to strengthen the connections between the linguisticform (in the separation between presupposition andassertion) and the representation of beliefs.
Believedinformation labeled ?bn?
inside a belief DRS or ac-cepted information labeled ?cn?
inside an acceptanceDRS can be either presupposed or asserted inside theintention DRS.
Thus, the labels in the intention DRScan only be ?p?
or ?a?.Conditions referring to attitudes (acceptance, be-liefs, and intentions) have been added to the ex-tended semantics of DRT.
Figure 2 shows three em-bedded DRSs, acceptance DRS, drs2, belief DRS,drs4, and intention DRS, drs6 representing:(2) A: Tom is buying Mary a puppy.B: That?s sweet.DRSs are referred to by the attitude describing them.For example, attitude(i,?BEL?, drs4) refers to theDRS containing the speaker?s beliefs, using the la-bel for the belief DRS, drs4.
Other conditionsare allowed to employ ?i?
as an argument.
Atti-tude(i,?accept?, drs2) refers to the DRS containingthe speaker?s acceptance DRS, using the label forthe acceptance DRS, drs2.
Attitude(i,?INT?, drs6)refers to the DRS containing the speaker?s intentionin uttering example (2), using the label for the inten-tion DRS, drs6.
The speaker?s acceptance DRS con-tains an embedded DRS for the hearer?s acceptanceDRS, drs2.
In this case, it is empty, as no weakly be-lieved propositions have been introduced yet.
Simi-larly, the belief DRS contains space for the speaker?sbeliefs about the hearer?s beliefs, drs5.
The intentionDRS contains the linguistic content of the utterancethat the speaker is about to make, drs6, as well as therelevant dialogue acts.drs1:i you t mdrs2:attitude(you, ?ACCEPT?, drs3)drs3:attitude(i, ?ACCEPT?, drs2)attitude(i, ?BEL?, drs4)drs4:pb1: tom(t)b2: mary(m)b3: puppy(p)b4: buy(t,m,p)attitude(you, ?BEL?, drs5)drs5: b5: tom(t)b6: mary(m)attitude(i, ?INT?, drs6)drs6:pp1: tom(t)p2: mary(m)a1: puppy(p)a2: buy(t,m,a1) inform(i,you,a2)Figure 2: A?s initial Cognitive StateIn Figure 2, there are essentially three levels ofembedding in a main DRS.
If we look at the beliefDRS, the first embedded DRS is the agent?s own be-lief DRS.
Level two is the agent?s beliefs about theother agent?s beliefs DRS.
Level three is insertedwhen necessary and represents the agent?s beliefsabout the other agent?s beliefs about the agent?s be-liefs DRS.
DRSs of the same level of embeddinghave similar status.
For example, the agent?s accep-tance and belief DRSs have equal status.
However,the only discourse referents in common are the onesin the main DRS?s universe.
Each equal-level em-bedding has its own set of discourse referents, aswell as its own conditions.Discourse referents of same and higher levels ofembedding are accessible to lower levels of embed-ding and are therefore not represented in the lowerlevel embedding universe.
This does not entail thatwhen a lower level embedding makes use of a dis-course referent introduced in a higher level embed-ding the agent and other agent share the same inter-nal or external anchors.
For example, when talkingabout a rabbit, the speaker?s representation of rabbit60will be: b1:rabbit(x), whereas the speaker?s repre-sentation of the hearer?s beliefs will be b2:rabbit(x).This is to replace Kamp and Reyle?s (1993) use ofdifferent discourse referents, where a new discoursereferent is used every time the same object or in-dividual is referred to in a new sentence (e.g.
rab-bit(x), then rabbit(y)).
The aim is to avoid havingto overtly use the x=y rule every time the same rab-bit is referred to.
The principles behind the equationpredicate are still in place; i.e.
every time rabbit isreferred to, it is bound to the rabbit already in thecontext.
However, we bind it to the previous proper-ties of rabbit already in context through attaching itto the same discourse referent, rabbit(x).Both Kamp and Reyle?s and our representationface revision when it transpires that the agents indialogue have different referents in mind.
For ex-ample, both the speaker and hearer might be talkingabout ?rabbit?.
However, they might have a differ-ent ?rabbit?
in mind, and assume the other partici-pant is thinking of the rabbit they have in mind.
Thespeaker might have a grey rabbit in mind, whereasthe hearer has a white rabbit in mind.
In this case,Kamp and Reyle?s revision would consist of deletingx=y predicate, and any previous equation predicatethat may have been introduced each time rabbit wasreferred to.
In our representation, the revision takesplace by changing the other agent?s discourse refer-ent, b2:rabbit(x) becomes label2:rabbit(y).Furthermore, the previous pragmatic extensionsto standard DRT have been implemented computa-tionally to approximate a computational model ofcommunication and to enable us to see whether theextended DRT works logically.
The implementationrelates the linguistic content of utterances to the be-liefs and intentions of the agents.
The implementa-tion operates with a specific dialogue, which can bemodified, within a restricted domain.
It seems rea-sonable to conclude on the basis of the implementa-tion that the conceptual and formal proposals madeprovide a basis for further development.3 Conclusion and Further ExtensionsThis paper pushes the treatment of linguisticphenomena in DRT more towards pragmatics,by bringing more pragmatic elements to thesemantic/pragmatic interface which is DRT.
It hasbeen the aim of this paper to achieve this by (a) ex-panding DRT structure to incorporate the pragmaticextensions introduced in this paper, (b) representingthe complex process of speakers recognizing utter-ances and using the linguistic information in form-ing mental representations of hearers?
mental repre-sentations, (c) enhancing the link between speakerbeliefs, and between the linguistic content and thelinguistic content and hearer?s beliefs and (d) puttingall these extensions and enhancements to the prag-matic side of DRT in a computational model.While the work presented in this paper offers amore pragmatic approach to DRT, there is still morework to be done on making DRT more pragmatic.The possibility of extending the present treatmentto include more agents remains for future work.In addition, future work can employ the intentionDRS introduced in this paper, in order to enhancethe complexity of the pragmatic representation ofspeaker/hearer intentions.
For instance, embeddingturn-taking acts within the intention DRS and relat-ing them to agents?
beliefs and intentions should bestraightforward.
It is also hoped that future workwill address more aspects of context than the twodetailed and implemented in this paper, namely, theimmediate and background context.
Furthermore,the sample implementation of the extensions sug-gested in this paper serves as an example of how theextensions to DRT can be implemented.
One wayof developing this implementation is to incorporateit into a dialogue system which aims to achieve amore balanced approach to the semantic/pragmaticinterface in representing linguistic phenomena.ReferencesKamp, H. and Reyle, U.
1993.
From Discourse to Logic: In-troduction to Model Theoretic Semantics of Natural Lan-guage, Formal Logic and Discourse Representation Theory.Boston, Dordrecht: Kluwer.van Eijck, J. and Kamp, H. 1997.
?Representing Discourse inContext?.
In: J. van Benthem and A. Ter Meulen (Eds.
).Handbook of Logic and Language.
pp.
179?237.
Amster-dam: Elsevier.Simons, M. 2003.
?Presupposition and Accommodation: Un-derstanding the Stalnakerian Picture?.
Philosophical Studies112, pp.
251?278.Werth, P. 1999.
Text Worlds: Representing Conceptual Spacein Discourse.
New York: Longman.61
