Pasteur's Quadrant, Computational Linguistics, LSA, EducationThomas K LandauerKnowledge Analysis Technologies.
4940 Pearl East Circle, Boulder, CO 80301landauer@psych.colorado.eduAbstractThis paper argues that computational cognitivepsychology and computational linguistics havemuch to offer the science of language byadopting the research strategy that DonaldStokes called Pasteur?s quadrant--starting andtesting success with important real worldproblems--and that education offers an idealvenue.
Some putative examples fromapplications of Latent Semantic Analysis(LSA) are presented, as well as some detail onhow LSA works, what it is and is not, andwhat it does and doesn?t do.
For example, LSAis used successfully in automatic essay gradingwith content coverage feedback, computingoptimal sequences of study materials, andpartially automating metadata tagging, but isinsufficient for scoring mathematical and shorttextual answers, for revealing reasons.
It isexplained that LSA is not construable asmeasuring co-occurrence, but rather measurethe similarity of words in their effect onpassage meaning,1     Credits.The research reported here has beensupported by NSF, the Army Research Institute, theAir Force Office of Scientific Research, the Office ofNaval Research, and the Institute of EducationalSciences.
Many people contributed to the researchincluding, but by no means limited to Susan Dumais,Peter Foltz, George Furnas, Walter Kintsch, DarrellLaham, Karen Lochbaum, Bob Rehder, and LynnStreeter,2     IntroductionIn my outsider?s opinion?I?m not a linguistand this is my first ACL meeting?this workshopmarks an important turn in the study of language.Here is why I think so.Donald Stokes, in Pasteur?s Quadrant(1997), argues that the standard view that scienceprogresses from pure to applied research toengineering implementations is often wrong.
Thisdoctrine was the brainchild of Vannevar Bush, whowas Roosevelt?s science advisor during war II.
It has,of course, since been enshrined in the DoD?s 6.1,2,3funding structure, and modeled in the nationalresearch institutes and large industrial laboratoriessuch as Bell Labs, IBM and Microsoft.
Stokes showsthat while this trajectory is sometimes followed, oftenwith dramatic success, over the whole course ofscientific advance it has been the exception ratherthan the rule, and for good reasons.
Stokessummarized his view of the real relations in a two bytwo table much like the one in the figure, in which Ihave made a few minor additions and modifications.Pure research Pasteur?s quadrant(random walk research) Pragmatic engineeringTable 1.
Donald Stokes?
(1997) illustration of hisconception of science, slightly modified.The upper left quadrant is ?pure?
research,driven by a desire to understand nature, its problemschosen by what natural phenomena are mostpervasive, mysterious or intuitively interesting.Particle physics is its standard bearer.
The lower rightquadrant is empirical engineering, incremental cutand try, each improvement based on lessons learnedfrom the successes and failures of previous attempts.Internal combustion engines are a type case.The upper right quadrant, Pasteur?s, isresearch driven by the desire to solve practicalproblems, for Pasteur preventing the spoilage ofvinegar, beer, wine and milk, and conqueringdiseases in silkworms, sheep, chickens, cattle andhumans.
Such problems inspire and set concretegoals for research.
To solve them it is often necessaryto delve into empirical facts and first causes.
Thequadrant also offers an important way to evaluatescientific success; because failure proves a lack offull understanding.Stokes doesn?t name the lower left quadrant,but it might be dubbed ?random walk?
science.
Itresembles theological scholasticism, where the nextproblem is chosen by flaws in the answer to the last.In my field, cognitive psychology, it is exemplifiedby 100 years of experiment, thousands of papers, anddozens of quantitative models about how peopleremember lists of words.Of course, these activities bleed into oneanother and sometimes evince the Bush progression.Even list learning has produced basic principles thatcan be used effectively in education and the treatmentof dementia.
Nonetheless, the argument is that effortsin Pasteur?s quadrant, because they avoid the dangersof excessive-abstraction, simplification andirrelevance, are the most productive, both ofscientific advance and of practical value.I believe that the Pasteur attitude isespecially important in psychology, becauseidentifying problems that are critical for understandthe human mind is anything but easy.
Human mindsdo many unique and currently unexplainable things.Their first-cause mechanisms are hidden deeply inthe intricate connections of billions neurons andbillions of experiences.
Better keys to the secrets ofthe mind are needed than hunches of the kind thathave motivated list-learning research.
To be surerthat what we study is actually relevant to the realtopic of interest we need to try to solve problems atthe level of normal, representative mental functions.Although there are other good candidates, such asautomobile driving and economic decision making,education is particularly apt.
This is partly becausecognitive psychology already knows quite a lot aboutlearning, but more importantly because education isthe primary venue in which society intentionallyfocuses on making a cognitive function happen well,and where success and failure can tell us what we doand do not know, and do so with some guarantee thatthe knowing is important to understanding the targetphenomena.It seems to me that computational linguisticsis in much the same position.
Much traditionallinguistics has concerned itself with descriptions ofabstract properties of language whose actual role inthe quotidian human use of language is not oftenstudied, and, therefore, whose promise to explainhow language is acquired and works for its users issometimes hard to evaluate.
Computationallinguistics itself appears to have been devoted mostlyto the upper left and lower right quadrants; on onehand it has spent much of its effort automating orsupporting traditional linguistic analyses such asparsing, part-of-speech tagging and semantic roleclassification.
On the other hand, it has developedpractical tools, such as dictionaries, ontologies and n-gram language models for doing practical languageengineering tasks, such as speech-to-text conversionand machine translation.
There has been relativelylittle effort to use the successes and failures ofcomputer automations to guide, illuminate, or testmodels of how human language works.This workshop, represents an important stepnortheast in Stokes?
map.
Not only is educationaccomplished primarily through the use of language,it is also a critical source of advanced abilities to uselanguage-- reading, writing, and thinking--and is theprimary medium by which the fruits of education aremade useful.
Thus trying to improve education is justthe kind of thing that the Pasteur approach exploits,compelling reasons to understand, a laboratory forexploration, and strong, broad, relevant tests ofsuccess.
Putting this argument starkly, it is too easyto treat language as an isolated abstract system andignore its functional role in human life, and it is tooeasy to treat education as a humanity, where abstractphilosophical arguments, ethical principles orhistorical precedent guide practice.
Attempts toenhance the role of language in education throughcomputation, which makes exquisitely specific whatwe are doing, should lead to new understanding ofthe nature of language--and vice versa.Now for a few words on my own work, andsome ways in which it has, at least in part, followedthe Pasteur path, plus a few words on howcomputational linguistics in education might makeuse of some of its outcomes.
This will be take theform of a review of Latent Semantic Analysis (LSA):its origins and history, its computationally simulatedmental mechanisms, its applications in education, andsome implications it may have for understanding howthe mind does language.
I?ll briefly describe whereLSA came from, how it works, what it does anddoesn?t do, some educational applications in whichwhat it does is useful, some things that limit itsusefulness and beg for better basic science, and somenitty-gritty on how and how not to apply it.3     The History and Nature of LSAIn the early eighties the management of BellTelephone Laboratories, where I was working, askedme to form a group to find out why secretaries in thelegal department were having trouble using UNIX, anobvious godsend, and fix them.
This led to trying tofind out why customers sometimes couldn?t find whatthey wanted in the Yellow Pages, why servicerepresentatives didn?t always give correct chargeseven thought they were plainly stated in well indexedmanuals, and why the new online databases for partsand circuits required so much training and yieldedonly small gains in speed and accuracy, if any.We undertook a series of lab experimentswhose details are skippable.
What we discovered wasthis.
In every case the words that people wanted touse, to give orders to computers, or to look things up,rarely matched the words the computer understood orthe manuals were indexed by.
Roughly, but almostalways, the data could be summarized as: ask 100people by what one word something should be calledand you will get 30 different answers.
Thedistribution is such that it takes five words to coverhalf the answers.
We called this the problem of?verbal disagreement?
(Furnas et al, 1987).Our first solution was brute force; find allthe words people would use for what we called an?information object?
and index by all of them, whichwe called ?unlimited aliasing?
(what do you think thechances are that anyone else would have named themthat way?).
Later, largely led by George Furnas(1985), we invented some ways to semi-automatethat process by what he called ?adaptive indexing?,having the computer ask people if the words they hadused unsuccessfully should be added as pointers tothings they eventually found.
Of course, we alsoworried about the problem of ambiguity, now knownas ?the Google problem?, that almost every word hasseveral very different meanings that will lead youastray.
At least under some circumstances that wasfixable by giving more context in the response, oneversion of which is Furnas?
?fisheye view?, to guidenavigation.
(Adaptive indexing also greatly reducesthe ambiguity problem because the pointers are oneway--from what people said to the one thing theyactually told the systems they meant.
)So what had we done here?
We?d used thepractical problem to lead to empirically explorationof how people actually used words in daily life(although computers were not as much of daily lifethen as now, and some of their persisting problemsmay be due to our failure to get our solutions widelyadopted.
Here I am, still trying.)
The surprisingextent and universality of verbal disagreement couldbe viewed as a baby step in language science, at leastas we construed language science.But just pinning down the nature of theproblem in the statistics of actual pragmatic wordusage (we called the new field ?statistical semantics?,which didn?t catch on), was only a start.
Clearly theproblems that computers were having understandingwhat people meant is special to computers.
Peopleunderstand each other much better.
(People also havetrouble, although less, with queries of one or twoisolated words, but they are very good at usingbaseline statistics of what people mean by a word(which is, of course, Google?s stock in trade, using anindirect version of adaptive indexing), and theyappear to use context when available in a much moreefficient manner (although this still needs research inthe style of statistical semantics.
)What was needed was a way to mimic whatpeople do so well--understand all the meanings of allthe words they know, and know just how much andhow any word is related to any other.
It is perfectlyobvious that people learn the meanings of the wordsin their language, only slightly less so that they mustdo so primarily from experiencing the words incontext and from how they are used in combinationto produce emergent meanings.
With these facts andclues in mind, the next step was to findcomputational techniques to do something similar,and see if it improved a computer?s understanding.
(An apology is in order for idiosyncratic use of thewords ?meaning?, ?understanding?, and ?semantics?.They are used here in special senses that differ frommyriad usages in linguistics and philosophy, and mayoffend some readers.
Because detailed definitions andcircumlocutions would be burdensome and of littlevalue, let us leave it to context.
)The best method we hit upon was what isnow called Latent Semantic Analysis, LSA (or, ininformation retrieval, Latent Semantic Indexing,LSI.)
Because there have been somemisinterpretations in the literature it may be useful togive a conceptual explanation of how LSA works.
Itassumes that the meaning of a passage (in practicetypically a paragraph) can be approximated by thesum of the meanings of its words.
That makes a largeprint corpus a huge system of simultaneous linearequations.
To solve such systems we used the matrixalgebraic technique of Singular Value Decomposition(SVD), the general method behind factor analysis andprincipal components analysis.
Applied to a corpus oftext, the result is a vector standing for every word inthe corpus, with any passage represented by thevector sum of its word vectors.
(At first we couldonly do that with rather small corpora, but withimproved algorithms and hardware, size is no longera barrier.
)The first applications of LSA were toinformation retrieval, which we conceived of as aproblem in the psychology of meaning, how tomeasure the similarity of meaning to a human of aquery and a document given pervasive verbaldisagreement.
The method was to compute thesimilarity of corresponding vectors, typically by theircosine (of their angle in a very high dimensional?semantic space?.)
The result was that, everythingelse equal (e.g.
tokenizing, term-weighting, etc.
), LSIgave about 20% better precision-for-recall results,largely because it could rightly judge meaningsimilarity despite differences in literal word use.
Italso does any language, and cross language retrievalhandily because its numerical vectors don?t carewhether the ?words?
are Chinese characters or Arabicscript.
If the training corpus contains a moderatenumber of known good translations, and is processedcorrectly, it does pretty well with no other help.Along the way we discovered that choosingthe right number of dimensions?the number of(independent) elements composing each vector--wascritical, three hundred to five hundred being stronglyoptimal.
One way of describing the value of reducingthe number of dimensions well below the number ofword types or passages is that it forces the system toinduce relations between every word and every otherrather than keeping track of the full pattern ofempirical occurrences of each, as standard vectorretrieval methods do.Because we like to think we are trying tomodel human minds as well as solve practicalproblems, we have also tested LSA on a variety ofhuman tasks.
For word meaning an early test was togive it a standardized multiple-choice vocabularytests (it chooses the word with the most similarmeaning by computing which has the highest cosine).Trained on text of similar volume and context to whatan American high school senior has read, it does wellon the Test of English as a Foreign Language(TOEFL), equaling successful non-native applicantsto U.S.
Colleges.
It also mimics the astounding tenwords per day vocabulary growth of middle schoolchildren as measured by multiple choice tests.
Toevaluate its representations of passage meaning,perhaps the most interesting and quantitative testshave been through its use in scoring the conceptualcontent of expository essays.
In actual essay scoringsystems we use a suite of analytic tools that includesother things.
However, for the present purpose weneed to consider how well LSA does when usedalone.
In doing this, LSA is used to predict the scorea human grader would give a new essay on the basisof its similarity to other essays on the same topic thathave previously been humanly scored.
The LSA-based score predicts very nearly as well as does thatof a second independent human reader.
Several otherevidences of passage-passage success will bedescribed later.The astute reader will be puzzled by howthis could happen, given the very strongsimplification of LSA?s additivity assumption, bywhich word order within passages is completelyignored.
We will return to this matter, and to more onessay grading later.Before going on, a few more commonmisinterpretations of LSA need dealing with.
First,LSA is not a measure of co-occurrence, at least as co-occurrence is usually conceived.
For LSA a passagemeaning is the combination of its word meanings.This does not imply that the words in a passage havethe same meaning; indeed that would not be veryuseful.
Empirically, over a typical large corpus, thecorrelation between the cosine between a random pairof words and the number of passages in which theyboth occurred is +.35, while the correlation with howoften they occur separately, which by the usualinterpretation should make them dissimilar, is +.30.By the same token--unlike n-gram language models--LSA estimates the probability that one word willfollow another only indirectly and very weakly.
(Although, surprisingly, LSA similarities haverecently been shown to account for much of whatgoes on in recalling word lists in order, but not byconditional probability effects (Howard and Kahana,2001)).
More correct interpretations are that LSAreflects the degree to which two words couldsubstitute for one another in similar contexts, thatthey tend to appear in similar (but not necessarilyidentical) contexts, and, most precisely, that theyhave the same effects on passage meanings.Now what about the fact that LSA ignoresword order and thus all syntactically conveyedgrammatical effects on sentential meaning?
First, itneeds emphasis that LSA is very good at measuringthe similarity of two words or two passages,sometimes good on sentence to sentence similarityand sometimes not, and least good on word tosentence, or word-to-passage meanings.
A good andbad feature of its word-to-word function is that itmerges all contextual effects (different senses) of aword into a frequency-weighted average.
LSA, as atheory of psychological meaning, proposes that aword is represented as a single central meaning that ismodified by context (see Kintsch (2002) for how thiscould play out in predication and metaphor).
Thereason it does well on passage-to-passage is thatpassages are redundant and complex, and that localsyntactic effects tend to average out.
(This is true forhumans too?e.g.
they ignore misplaced nots) LSAshould be used with all of this in mind.However, still, you might say, LSA?s lack ofunderstanding of prediction, attachment, binding, andconstituent structure, thus of representation of logicalpropositions--all traditional foci of linguisticsemantics and computational linguistics-- must surelyweaken if not cripple it.
Weaken surely, but by howmuch?
Here is one ?ballpark?
estimate.
A typicalcollege educated adult understands around 100,000word forms, an average sentence contains around 20tokens.
There are thus 100,00020 possiblecombinations of words in a sentence, therefore amaximum of log2 100,00020 = 332 bits of informationin word choice alone.
There are 20!
=2.4 x 1018possible orders of 20 words for and additionalmaximum of 61 bits from syntactic effects.
Of thepossible information in a sentence, then, the part thatbag-of-words LSA can use is 332/(61+ 332) = 84%.A substantial amount of human meaning ismissing from LSA, but a much larger component isapparently captured.
It turns out that, judiciouslyapplied, this component can be quite useful.Moreover, applying it can help pin down the roles ofwhat?s missing and not and thus advance ourunderstanding of the nature language as used.
Somesuccessful and less so applications to education aredescribed next, along with some implications, as wellas some radical conjectures.4      Applications of LSA in EducationFirst, a few more words on the use of LSAin information retrieval (IR) (and relevant to someeducational applications described later) and essayscoring.
What LSA captures in IR is the degree towhich two documents are about the same thing,independent of what equivalent wording may beused.
Thus it is useful for finding documents that talkabout something, even though it misses details--sometimes important ones--about what was saidabout the matter.
What kind of computation mightachieve a representation of the rest?To achieve a high degree of validity inrepresenting word meaning, LSA uses onlyinformation on how words are used, it does not needto assume or identify more primitive semanticfeatures.
A possible hint from its success may be thatthe meaning of groups of words in their order mayalso rely entirely on how they relate to other groupsof words in their orders.
(Unpublished work of thepsychologist Simon Dennis is pushing in thisdirection with very interesting results.)
Could it bepossible that word strings themselves actually are thedeepest, most fundamental representation of verbalmeaning, not some more abstract underlyingprimitive entities or structures?In essay grading, LSA information turns outto be almost, but not quite enough.
In practice weadd a number of primarily statistical measures, forexample n-gram model estimates of how well thewords have been ordered relative to standard Englishstatistics.
The remarkable thing is that even withoutany explicit extraction or representation of the logicor propositions in the essays, the methods usuallyproduce slightly more reliable scores than dohumans.
Is it possible that merely the joint choosingof a set of words and a normative order for arrangingthem (including nonlinear interactions) suffices toconvey all that?s needed, without needing any deeperlevel of representation?
Clearly, this is very doubtful,but perhaps worth thinking about?LSA?s text analysis and matching capability,originally devised for IR, has found several fairlydirect applications in education.
One automaticallymeasures the overlap between the content of coursesby the text in their exams--agreeing well with teacherjudgments on samples.
This is used to helprationalize curricula.
Another relates the content ofjob tasks, training materials, and work histories, allby placing their verbal descriptions in the samesemantic space, and uses the results to assign peopleto jobs and just-in-time compensatory training.
Anew application automatically matches test items andlearning materials to state achievement standards,with high agreement to human experts.
Anotherautomatically finds best-sentence summaries andcategories as an aid for meta-data tagging of learningobjects.
A kind of inversion of the LSArepresentation automatically generates candidatekeywords.The closest relative to essay grading isLSA?s role in the Summary Street program.
In thisapplication students read 4-10 page educationaldocuments, then write 100-200 word summaries.Using LSA, the system tells the student about howwell the summary covers each section of thedocument, how coherent it is--by measuring thesimilarity of successive sentences--and marksredundant and irrelevant sentences.
(Interestingly,experiments have shown that students learn morefrom text that is coherent, but not excessively so, andLSA can be used to determine the right degree,although no working application has yet been builtaround the capability.
)Another version of the Summary Street andessay analysis technology is a web based tool thatscores short essays written to summarize or discussthe content of chapters of college textbooks,providing feedback on what sections to re-read toimprove coverage.A somewhat different manner of extendingLSA?s text analytic properties lies behind anothergroup of applications.
Suppose that a student reads adocument about the human heart, then wants tochoose another to read that will best advance herknowledge.
Experiments have shown that the greatestlearning will occur if the next reading introducesneither too little nor too much new knowledge.
Wecall this the Goldilocks principle.
By LSA analysis ofhow all of a set of materials on a topic are related toone another it is possible to accurately place them ona continuum of conceptual sophistication andautomatically choose optimum steps.
For a largeelectronic maintenance model currently underdevelopment, the technique is being generalized toprovide optimum paths to knowledge?
in which userschoose a starting place and a target procedure theywant to know, and the system picks a sequence ofsections to read that is intended to introduce theneeded information in an effective and efficient orderfor understanding.
Combined with fisheye views,adaptive indexing, meaning-based LSA search,embedded LSA-based constructed responseassessments, and other guidance features the systemis a sort of midway, automatically constructed,intelligent tutor.Still another application combines aspects ofthe search and essay evaluation techniques to act as akind of automated mentor for a collaborative learningenvironment.
Its most interesting capabilities aremonitoring and continuously assessing the content ofthe individual and the total group contributions,connecting individuals with others who are havemade comments about similar things, posting alertswhen the discussion wanders, both on request andautonomously reaching out to repositories formaterials relevant to a discussion, and measuring theformation of consensus.
In one small experiment, thesystem?s automatic evaluation of individual contentcontributions over a semester had a correlation of .9with independent ratings by participating instructors.Still more applications are just entering theresearch stage.
One set is stimulated by the widelyperceived inadequacy of multiple choice testing;students need to be able to think of answers, not justchoose someone else?s.
The goal is to replace, forexample, missing word multiple choice vocabularytests with ones in which the student supplies the wordand the system evaluates how well it fits.That?s enough for successes.
What aboutfailures and limitations, what they teach, and wherethey point research?
First, it is true that manylaboratory tasks can reveal shortcomings and errorsin LSA.
Incorrect measures of similarity occurespecially for sentences to sentence comparisons inwhich syntax has strong effects, where broadercontextual information or pragmatic intent isinvolved, and where word meanings have strongrelations to perceptual sources to which LSA traininghas had no access.
In some of these cases, it isreasonable to suppose that the basic theoreticalfoundation is sound but the training data is notsufficient.
In other cases it is fairly obvious that morefundamental limitations are at fault, such as the lackof a purely computation process by which tocontextually disambiguate the phenomenatraditionally described as multiple word senses.But what about the lessons from trying tosolve educational problems promised earlier?
Thereare two glaring examples.
One is scoring answers tomath problems, or mathematical answers to problemsin physics and chemistry (never mind questionsrequiring drawings or diagrams), something we arefrequently asked to do.
Syntactic expressions withabstract symbols, where order is critical to logic andbindings are arbitrary, are simply beyond the powersof LSA.
How to get them into a fully computationalmodel, one that does not use human help in the form,for example, of manually constructed rules thatnatural humans could not know, preferably one inwhich the system learns the capability from the sameinteraction with the world that humans do, is thechallenge to computational cognitive psychology andlinguistics that forcefully presents itself, and whosesolution could not help but require important newscientific knowledge about language.A second educational soft spot for LSA isits weakness on sentences.
It would almost certainlybe better to be able to treat the meaning of an essayas the combination of the meaning of its sentencesand the propositional information that order, bothwithin and between sentences, helps to convey.Moreover, simply scoring short answers, anotherfrequent request is problematic.
The usual LSA-basedmethods are not useless, but they fall significantlyshort of human reliabilities.
There seem to be twoissues involved.
One is again the necessity ofaccounting for syntax, especially for negation,quantification, and binding.
?The price of cloth willgo up and the cost of plastics down?
is not handledby LSA.
The other is that short answer questionsoften require very specific responses in which somewords must be literal entities and others admit ofsynonyms, circumlocutions and ambiguity.
No onehas found a way to match humans with withoutadding what we consider ad hoc methods, rules andtriggers devised and coded by people who know theanswer.
What we want is a fully computationalmethod that might be a possible model of how naturalhuman minds represent knowledge and turn it into ananswer of a few words or sentences that can bereliably evaluated by a human who has also learnedthe needed knowledge in a computationally realisticway.
Finding one is another strong challenge whosesuccessful attack would almost have to reveal newscientific truth.Finally, it is worth noting that LSA has up tovery recently relied exclusively on SVD for itscentral engine.
There are certainly other possibilitiesfor doing the same job, and perhaps for doing itbetter, and for doing more.
For example, several newmatrix decomposition methods (that?s what LSA is)have recently been devised that have interesting newproperties, such as more interpretable representations.Other new approaches use entirely differentcomputations, for example the model of SimonDennis mentioned earlier relies on string-edit theory,computing what operations it takes to change onesentence into another.
There is no room, and as yetno results to warrant review of these here, but it isclear that the exploration of innovative computationalmodels of language, ones that, like LSA, are quitedifferent in spirit from linguistic tradition, is beingpushed by a desire to solve practical problems,featuring especially ones in education, and that theeffort has not nearly reached its limits.ReferencesSimon Dennis.
Unpublished.
A memory-basedTheory of verbal cognition.G.
W. Furnas.
1985.
Experience with an adaptiveindexing scheme.
In Proceedings of CHI?85, ACM,New York:  16-23.G.
W. Furnas, T. K. Landauer, L. M. Gomez,qnd  S. T. Dumais.
1987.
The vocabularyproblem in human system communication.Communications of the ACM, 30(11):  964-971.W.
Kintsch.
2001.
Predication.
Cognitive Science,25: 173-202T.
K. Landauer.
2002.
On the computational basis oflearning and cognition:  Arguments from LSA.
InN.
Ross   (Ed.
), The Psychology of Learning andMotivation, 41:  43-84.D.
E. Stokes.
1997.
Pasteur?s Quadrant: BasicScience and Technological Innovation, BrookingsInstitution Press, Washington, DC
