Book ReviewNatural Language Processing with PythonSteven Bird, Ewan Klein, and Edward Loper(University of Melbourne, University of Edinburgh, and BBN Technologies)Sebastopol, CA: O?Reilly Media, 2009, xx+482 pp; paperbound,ISBN 978-0-596-51649-9, $44.99; on-line free of charge at nltk.org/bookReviewed byMichael ElhadadBen-Gurion UniversityThis book comes with ?batteries included?
(a reference to the phrase often usedto explain the popularity of the Python programming language).
It is the compan-ion book to an impressive open-source software library called the Natural LanguageToolkit (NLTK), written in Python.
NLTK combines language processing tools (token-izers, stemmers, taggers, syntactic parsers, semantic analyzers) and standard data sets(corpora and tools to access the corpora in an efficient and uniform manner).
Al-though the book builds on the NLTK library, it covers only a relatively small partof what can be done with it.
The combination of the book with NLTK, a growingsystem of carefully designed, maintained, and documented code libraries, is an extra-ordinary resource that will dramatically influence the way computational linguisticsis taught.The book attempts to cater to a large audience: It is a textbook on computational lin-guistics for science and engineering students; it also serves as practical documentationfor the NLTK library, and it finally attempts to provide an introduction to programmingand algorithm design for humanities students.
I have used the book and its earlieron-line versions to teach advanced undergraduate and graduate students in computerscience in the past eight years.The book adopts the following approach: It is first a practical approach to computational linguistics.
It providesreaders with practical skills to solve concrete tasks related to language. It is a hands-on programming text: The ultimate goal of the book is toempower students to write programs that manipulate textual data andperform empirical experiments on large corpora.
Importantly, NLTKincludes a large set of corpora?this is one of the most useful andgame-changing contributions of the toolkit. It is principled: It exposes the theoretical underpinnings?bothcomputational and linguistic?of the algorithms and techniques thatare introduced. It attempts to strike a pragmatic balance between theory and applications.The goal is to introduce ?just enough theory?
to fit in a single semestercourse for advanced undergraduates, while still leaving room for practicalprogramming and experimentation. It aims to make working with language pleasurable.Computational Linguistics Volume 36, Number 4The book is not a reference to computational linguistics and it does not provide acomprehensive survey of the theory underlying computational linguistics.
The nichefor such a comprehensive review textbook in the field remains filled by Jurasky andMartin?s Speech and Language Processing (2008).
What the book does achieve very well isto bring the ?fun?
in building software tools to perform practical tasks and in exploringlarge textual corpora.As a programming book describing practical state-of-the-art techniques, it belongsto the glorious family of Charniak et al?s Artificial Intelligence Programming (1987),Pereira and Shieber?s Prolog and Natural Language Analysis (1987), and Norvig?s mind-expanding Paradigms of Artificial Programming (1992).
It differs from these books in itsscope (CL vs. AI) and the programming language used (Python vs. Lisp or Prolog).Another key difference is in its organization: Whereas the classical books have a strictdistinction between chapters covering programming techniques and chapters introduc-ing core algorithms or linguistic concepts, the authors here attempt to systematicallyblend, in each section, practical programming topics with linguistic and algorithmictopics.
This mixed approach works well for me.As the dates of these older classics indicate (they were published 20 to 25 yearsago), this book is important in closing a gap.
The transition of the field from a symbolicapproach to data-driven/statistical methods in the mid 1990s has transformed whatcounts as basic education in computational linguistics.
Correspondingly, textbooks ex-panded and introduced new material on probability, information theory, and machinelearning.
The trend started with Allen?s (1995) textbook, which introduced a singlechapter on statistical methods.
Charniak (1993) and Manning and Schu?tze (1999) fo-cused uniquely on statistical methods and provided thorough theoretical material?butthere was no corresponding focus on programming techniques.
Another impediment toteaching was the lack of easy access to large data sets (corpora and lexical resources).This made teaching statistical methods with hands-on exercises challenging.
Combiningstatistical methods for low-level tasks with higher levels (semantic analysis, discourseanalysis, pragmatics) within a one-semester course became an acrobatic exercise.Although deciding on the proper proportion among mathematical foundations,linguistic concepts, low-level programming techniques, advanced algorithmic methods,and methodological principles remains challenging, this book definitely makes the lifeof computational linguistics students and teachers more comfortable.
It is split into fivesections: Chapters 1 to 4 are a hand-holding introduction to the scope of ?languagetechnologies?
and Python programming.
Chapters 5 to 7 cover low-level tasks (tagging,sequence labeling, information extraction) and introduce machine learning tools andmethods (supervised learning, classifiers, evaluation metrics, error analysis).
Chapters8 and 9 cover parsing.
Chapter 10 introduces Montague-like semantic analysis.
Chap-ter 11 describes how to create and manage corpora?a nice addition that feels a bit outof place in the structure of the book.
Each chapter ends with a list of 20 to 50 exercises?ranging from clarification questions to mini-programming projects.The chapters all include a mix of code and concepts.
Chapter 1 sets the tone.
Ina few pages, the reader is led into an interactive session in Python, exploring textualcorpora, computing insightful statistics about various data sets, extracting collocations,computing a bigram model, and using it to generate random text.
The presentation isfun, exciting, and immediately piques the interest of the reader.Chapter 2 covers one of the most critical contributions of the book.
It presentscommonly used corpora packaged together with NLTK and Python code to read them.The corpora include the Gutenberg collection, the Brown corpus, a sample of the PennTreebank, CoNLL shared task collections, SemCor, and lexical resources (WordNet and768Book ReviewVerbnet).
The important factor is that these resources are made thoroughly accessi-ble, easily downloaded, and easily queried and explored using an excellent Pythonprogramming interface.
The NLTK Corpus Reader architecture is a brilliant piece ofsoftware that is well exploited in the rest of the book.Chapter 3 introduces programming techniques to deal with text, Unicode, down-loading documents from various sources (URLs, RSS feeds) and excellent practical cov-erage of regular expressions.
It is typical of the book?s approach that regular expressionsare taught by example and through useful applications, and not through an introductionto automata theory.
The chapter ends with an excellent introduction to more advancedtopics in sentence and word segmentation, with examples from Chinese.
Overall, thischapter is technical but extremely useful as a practical basis.I find Chapter 4 problematic.
It is a chapter fully focused on programming, whichintroduces some key techniques in Python (generators, higher-order functions) togetherwith basic material (what a function is, parameter passing).
In my experience teachinghumanities students, the material is not sufficient for non-programmers to become suf-ficiently proficient and not focused enough to be useful for experienced programmers.Chapters 5 to 7 introduce the data-driven methodology that has dominated thefield in the past 15 years.
Chapter 5 covers the task of part-of-speech tagging.
Thelinguistic concepts are clearly explained, the importance of the annotation schema iswell illustrated through examples (using a simplified 15-tag tagset and a complexone with 50 or more tags).
The chapter incrementally introduces taggers using dic-tionaries, morphological cues, and contextual information.
Students quickly grasp thedata-driven methodology: training and testing data, baseline, backoff, cross-validation,error analysis, confusion matrix, precision, recall, evaluation metrics, perplexity.
Theconcepts are introduced through concrete examples and help the student construct andimprove a practical tool.
Chapter 6 goes deeper into machine learning, with supervisedclassifiers.
The Python code that accompanies this chapter (the classifier interface andfeature extractors) is wonderful.
The chapter covers a wide range of tasks where theclassification method brings excellent results (it reviews POS tagging, document clas-sification, sequence labeling using BIO-tags, and more).
The theory behind classifiersis introduced lightly.
I was impressed by the clarity of the explanations of the firstmathematical concepts that appear in the book?the presentation of the concept ofentropy, naive Bayes, and maximum entropy classifiers builds strong intuition aboutthe methods.
(Although the book does not cover them, NLTK includes excellent codefor working with support vector machines and hidden Markov models.)
Chapter 7builds on the tools of the previous two chapters and develops competent chunkers andnamed-entity recognizers.
For a graduate course, the theoretical foundations would betoo superficial?and one would want to complement these chapters with theoreticalfoundations on information theory and statistics.
(I find that a few chapters from All ofStatistics [Wasserman 2010] and from Probabilistic Graphical Models [Koller and Friedman2009] together with Chapter 6 of Foundations of Statistical NLP [Manning and Schu?tze1999] on estimation methods are useful at this stage to consolidate the mathematical un-derstanding.)
Readers come out of this part of the book with an operational understand-ing of supervised statistical methods, and with a feeling of empowerment: They havebuilt robust software tools, run them on the same data sets big kids use, and measuredtheir accuracy.The next two chapters (8 and 9) cover syntax and parsing.
They start with CFGs andsimple parsing algorithms (recursive descent and shift-reduce).
CKY-type algorithmsare also covered.
A short section on dependency parsing appears (Section 8.5), butI found it too short to be useful.
A very brief section is devoted to weighted CFGs.769Computational Linguistics Volume 36, Number 4Chapter 9 expands CFGs into feature structures and unification grammars.
The au-thors take this opportunity to tackle more advanced syntax: inversion, unboundeddependency.The material on parsing is good, but too short.
In contrast to the section on tag-ging and chunking, the book does not conclude with a robust working parser.
Onthe conceptual side, I would have liked to see a more in-depth chapter on syntax?achapter similar in depth to Chapter 21 of Paradigms of AI Programming (Norvig 1992)or the legendary Appendix B of Language as a Cognitive Process (Winograd 1983).
In myexperience, students benefit from a description of clausal arguments, relative clauses,and complex nominal constructs before they can properly gauge the complexity ofsyntax.
On the algorithmic side, there is no coverage of probabilistic CFGs.
The materialon PCFGs is mature enough, and there is even excellent code in NLTK to perform treebinarization (Chomsky normal form) and node annotation, which makes it possible tobuild a competent PCFG constituent-based parser.
The connection between probabilisticindependence and context-freeness is a wonderful story that is missed in the book.Finally, I believe more could have been done with dependency parsing: transition-based parsing with perceptron learning a` la MaltParser (Nivre et al 2007) is also matureenough to be taught and reconstructed in didactic code in an effective manner.Chapter 10 is an introduction to computational semantics.
It adopts the didacticapproach of Blackburn and Bos (2005) and covers first-order logic, lambda calculus,Montague-like compositional analysis, and model-based inferencing.
The chapter ex-tends up to Discourse Representation Theory (DRT).
As usual, the presentation isbacked up by impressively readable code and concrete examples.
This is a very densechapter?with adequate theoretical material.
It could have been connected to the ma-terial on parsing, by combining a robust parser with the semantic analysis machinery.This would have had the benefit of creating more cohesion and illustrating the benefitsof syntactic analysis for higher-level tasks.Chapter 11 is an interesting addition on managing and constructing corpora.
Theskills required for collecting and annotating textual material are complex, and thechapter is a unique and welcome extension to the traditional scope of CL textbooks.Overall this book is an excellent practical introduction to modern computational lin-guistics.
As a textbook for graduate courses, it should be complemented by theoreticalmaterial from other sources, but the introduction the authors give is never too simplistic.The authors provide remarkably clear explanations on complex topics, together withconcrete applications.The book builds on high-quality code and makes significant corpora accessible.Although I still use Lisp in class to present algorithms in the most concise manner,I am happy to see how effective Python turns out to be as the main tool to conveypractical CL in an exciting, interactive, modern manner.
Python is a good choice for thisbook: It is easy to learn, open-source, portable across platforms, interactive (the authorsdo a brilliant job of exploiting the exploratory style that only interpreters can providein interspersing the book with short code snippets to make complex topics alive),and it supports Unicode, libraries for graph drawing and layout, and graphical userinterfaces.
This allows the authors to develop interactive visualization tools that vividlydemonstrate the workings of complex algorithms.
The authors exploit everything thissoftware development platform has to deliver in an extremely convincing manner.The decision of which material to include in the book is in general well founded.
Theauthors manage to cover a range of issues from word segmentation, tagging, chunking,parsing, to semantic analysis, and even briefly reach the world of discourse.
I lookforward to an expanded edition of the book that would cover probabilistic parsing, text770Book Reviewgeneration, summarization, and lexical semantics.
I would also have liked to see somecoverage of unsupervised and semi-supervised learning methods.For instructors, students, and researchers, this book, together with the excellentNLTK library, is an important milestone.
No one should learn computational linguisticswithout it.ReferencesAllen, James, 1995.
Natural LanguageUnderstanding.
Benjamin/Cummings,Menlo Park, CA, 2nd edition edition.Blackburn, Patrick, and Johan Bos.
2005.Representation and Inference for NaturalLanguage: A First Course in ComputationalSemantics.
CSLI Publications, Stanford, CA.Charniak, Eugene.
1993.
Statistical LanguageLearning.
The MIT Press, Cambridge, MA.Charniak, Eugene, Christopher K. Riesbeck,Drew V. McDermott, and James R. Meehan.1987.
Artificial Intelligence Programming.Lawrence Erlbaum Associates, Hillsdale,NJ, 2nd edition edition.Jurafsky, Daniel and James H. Martin.2008.
Speech and Language Processing: AnIntroduction to Natural Language Processing,Computational Linguistics, and SpeechRecognition.
Prentice Hall, Upper SaddleRiver, NJ, 2nd edition edition.Koller, Daphne and Nir Friedman.
2009.Probabilistic Graphical Models: Principles andTechniques.
The MIT Press, Cambridge, MA.Manning, Christopher D. and HinrichSchu?tze.
1999.
Foundations of StatisticalNatural Language Processing.
The MITPress, Cambridge, MA.Nivre, Joakim, Johan Hall, Jens Nilsson,Atanas Chanev, Gu?ls?en Eryig?it, SandraKu?bler, Svetoslav Marinov, and ErwinMarsi.
2007.
MaltParser: A language-independent system for data-drivendependency parsing.
Natural LanguageEngineering, 13(2):95?135.Norvig, Peter.
1992.
Paradigms of ArtificialIntelligence Programming: Case Studiesin Common Lisp.
Morgan Kaufmann,San Francisco, CA.Pereira, Fernando C. and Stuart M. Shieber.1987.
Prolog and Natural-Language Analysis.CSLI Publications, Stanford, CA.Wasserman, Larry.
2010.
All of Statistics:A Concise Course in Statistical Inference.Springer, New York, NY.Winograd, Terry.
1983.
Language as aCognitive Process.
Addison-Wesley,Reading, MA.Michael Elhadad is an associate professor at Ben-Gurion University, Israel.
He has been teach-ing computational linguistics for 15 years.
His research focuses on computational models ofModern Hebrew, text summarization, and text generation.
His address is Department of Com-puter Science, Ben-Gurion University, Beer Sheva, 84105, Israel; e-mail: elhadad@cs.bgu.ac.il.771
