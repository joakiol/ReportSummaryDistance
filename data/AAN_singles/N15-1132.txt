Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1238?1243,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsUnsupervised Most Frequent Sense Detection using Word EmbeddingsSudha Bhingardive Dhirendra Singh Rudra Murthy VHanumant Redkar and Pushpak BhattacharyyaDepartment of Computer Science and Engineering,Indian Institute of Technology Bombay.
{sudha,dhirendra,rudra,pb}@cse.iitb.ac.in{hanumantredkar}@gmail.comAbstractAn acid test for any new Word Sense Disam-biguation (WSD) algorithm is its performanceagainst the Most Frequent Sense (MFS).
Thefield of WSD has found the MFS baseline veryhard to beat.
Clearly, if WSD researchers hadaccess to MFS values, their striving to bet-ter this heuristic will push the WSD frontier.However, getting MFS values requires senseannotated corpus in enormous amounts, whichis out of bounds for most languages, even iftheir WordNets are available.
In this paper,we propose an unsupervised method for MFSdetection from the untagged corpora, whichexploits word embeddings.
We compare theword embedding of a word with all its senseembeddings and obtain the predominant sensewith the highest similarity.
We observe signif-icant performance gain for Hindi WSD overthe WordNet First Sense (WFS) baseline.
Asfor English, the SemCor baseline is betteredfor those words whose frequency is greaterthan 2.
Our approach is language and domainindependent.1 IntroductionThe MFS baseline is often hard to beat for any WSDsystem and it is considered as the strongest baselinein WSD (Agirre and Edmonds, 2007).
It has beenobserved that supervised WSD approaches gener-ally outperform the MFS baseline, whereas unsu-pervised WSD approaches fail to beat this baseline.The MFS baseline can be easily created if we havea large amount of sense annotated corpora.
The fre-quencies of word senses are obtained from the avail-able sense annotated corpora.
Creating such a costlyresource for all languages is infeasible, looking atthe amount of time and money required.
Hence, un-supervised approaches have received widespread at-tention as they do not use any sense annotated cor-pora.In this paper, we propose an unsupervised methodfor MFS detection.
We explore the use of word em-beddings for finding the most frequent sense.
Wehave restricted our approach only to nouns.
Our ap-proach can be easily ported to various domains andacross languages.The roadmap of the paper is as follows.
Section 2describes our approach - ?UMFS-WE?.
Experimentsare given in Section 3.
Results and Discussions aregiven in Section 4.
Section 5 mentions the relatedwork.
Finally, Section 6 concludes the paper andpoints to future work.2 Our Approach: UMFS-WEWord Embeddings have recently gained popular-ity among Natural Language Processing community(Bengio et al, 2003; Collobert et al, 2011).
Theyare based on Distributional Hypothesis which worksunder the assumption that similar words occur insimilar contexts (Harris, 1954).
Word Embeddingsrepresent each word with a low-dimensional realvalued vector with similar words occurring closer inthat space.In our approach, we use the word embedding of agiven word and compare it with all its sense embed-dings to find the most frequent sense of that word.Sense embeddings are created using the WordNetbased features in the light of the extended Lesk al-gorithm (Banerjee and Pedersen, 2003) as described1238later in this paper.2.1 Training of Word EmbeddingsWord embeddings for English and Hindi have beentrained using word2vec1tool (Mikolov et al, 2013).This tool provides two broad techniques for creat-ing word embeddings: Continuous Bag of Words(CBOW) and Skip-gram model.
The CBOW modelpredicts the current word based on the surroundingcontext, whereas, the Skip-gram model tries to max-imize the probability of a word based on other wordsin the same sentence (Mikolov et al, 2013).Word Embeddings for EnglishWe have used publicly available pre-trained wordembeddings for English which were trained onGoogle News dataset2(about 100 billion words).These word embeddings are available for around 3million words and phrases.
Each of these word em-beddings have 300-dimensions.Word Embeddings for HindiWord embeddings for Hindi have been trained onBojar?s (2014) corpus.
This corpus contains 44 mil-lion sentences.
Here, the Skip-gram model is usedfor obtaining word embeddings.
The dimensions areset as 200 and the window size as 7 (i.e.
w = 7).We used the test of similarity to establish the cor-rectness of these word embeddings.
We observedthat given a word and its embedding, the list ofwords ranked by similarity score had at the top ofthe list those words which were actually similar tothe given word.2.2 Sense EmbeddingsSense embeddings are similar to word embeddingswhich are low dimensional real valued vectors.Sense embeddings are obtained by taking the av-erage of word embeddings of each word in thesense-bag.
The sense-bag for each sense of aword is obtained by extracting the context wordsfrom the WordNet such as synset members (S),content words in the gloss (G), content words inthe example sentence (E), synset members of thehypernymy-hyponymy synsets (HS), content wordsin the gloss of the hypernymy-hyponymy synsets1https://code.google.com/p/word2vec/2Downloaded from https://code.google.com/p/word2vec/(HG) and content words in the example sentence ofthe hypernymy-hyponymy synsets (HE).We consider word embeddings of all words in thesense-bag as a cluster of points and choose the senseembedding as the centroid of this cluster.Consider a word w with k senseswS1, wS2, ....wSktaken from the WordNet.
Senseembeddings are created using the following formula,vec(wSi) =?x?SB(wSi)vec(x)N(1)where, N is the number of words present in thesense-bag SB(wSi) and SB(wSi) is the sense-bag forthe sense wSiwhich is given as,SB(wSi) = {x|x ?
Features(wSi)}where, Features(wSi) includes the WordNetbased features for wSiwhich are mentioned earlierin this section.As we can see in Figure 1, consider the sense-bag created for the senses of a word table.
Here,the word table has three senses, S1{a set of dataarranged in rows and columns}, S2{a piece of fur-niture having a smooth flat top that is usually sup-ported by one or more vertical legs} and S3{a com-pany of people assembled at a table for a meal orgame}.
The corresponding word embeddings of allwords in the sense-bag will act as a cluster as shownin the Figure.
Here, there are three clusters withcentroids C1, C2, C3which corresponds to the threesense embeddings of the word table.Figure 1: Most Frequent Sense (MFS) detection usingWord Embeddings and Sense Embeddings12392.3 Most Frequent Sense IdentificationFor a given word w, we obtain its word embeddingand sense embeddings as discussed earlier.
We treatthe most frequent sense identification problem asfinding the closest cluster centroid (i.e.
sense em-bedding) with respect to a given word.
We use thecosine similarity as the similarity measure.
The mostfrequent sense is obtained by using the followingformulation,MFSw= argmaxwSicos(vec(w),vec(wSi))where, vec(w) is the word embedding for word w,wSiis the ithsense of word w and vec(wSi) is thesense embedding for wSi.As seen in Figure 1, the word embedding of theword table is more closer to the centroid C2as com-pared to the centroids C1and C3.
Therefore, theMFS of the word table is chosen as S2{a piece offurniture having a smooth flat top that is usually sup-ported by one or more vertical legs}.3 ExperimentsWe have performed several experiments to comparethe accuracy of UMFS-WE for Hindi and EnglishWSD.
The experiments are restricted to only pol-ysemous nouns.
For Hindi, a newspaper sense-tagged dataset of around 80,000 polysemous nounentries was used.
This is an in-house data.
ForEnglish, SENSEVAL-2 and SENSEVAL-3 datasets3were used.
The accuracy of WSD experiments wasmeasured in terms of precision (P), recall (R) andF-Score (F-1).To compare the performance of UMFS-WE ap-proach, we have used the WFS baseline for Hindi,while the SemCor4baseline is used for English.
Inthe WFS baseline, the first sense in the WordNet isused for WSD.
For Hindi, the WFS is manually de-termined by a lexicographer based on his/her intu-ition.
In SemCor baseline, the most frequent senseobtained from the SemCor sense tagged corpus isused for WSD.
For English, the SemCor is consid-ered as the most powerful baseline for WSD.3SENSEVAL-2 and SENSEVAL-3 datasets are downloadedfrom http://web.eecs.umich.edu/ mihalcea/downloads.html4http://web.eecs.umich.edu/ ?mihalcea/downloads.html#semcor4 Results and DiscussionsIn this section, we present and discuss results of theexperiments performed on Hindi and English WSD.Results of Hindi WSD on the newspaper dataset aregiven in Table 1, while English WSD results onSENSEVAL-2 and SENSEVAL-3 datasets are givenin Table 2 and Table 3 respectively.
The UMFS-WEapproach achieves F-1 of 62% for the Hindi datasetand 52.34%, 43.28% for English SENSEVAL-2,SENSEVAL-3 datasets respectively.System P R F-1UMFS-WE 62.43 61.58 62.00WFS 61.73 59.31 60.49Table 1: Results of Hindi WSD on the newspaper datasetSystem P R F-1UMFS-WE 52.39 52.27 52.34SemCor 61.72 58.16 59.88Table 2: Results of English WSD on the SENSEVAL-2datasetSystem P R F-1UMFS-WE 43.34 43.22 43.28SemCor 66.57 64.89 65.72Table 3: Results of English WSD on the SENSEVAL-3datasetWe have performed several tests using variouscombinations of WordNet based features (refer Sec-tion 2.2) for Hindi and English WSD, as shown inTable 4 and Table 5 respectively.
We study its im-pact on the performance of the system for Hindi andEnglish WSD and present a detailed analysis below.4.1 HindiOur approach, UMFS-WE achieves better perfor-mance for Hindi WSD as compared to the WFSbaseline.
We have used various WordNet basedfeatures for comparing results.
It is observed thatsynset members alone are not sufficient for identify-ing the most frequent sense.
This is because someof synsets have a very small number of synset mem-bers.
Synset members along with gloss membersimprove results as gloss members are more direct in1240WordNet Features P R F-1S 51.73 38.13 43.89S+G 53.31 52.39 52.85S+G+E 56.61 55.84 56.22S+G+E+HS 59.53 58.72 59.12S+G+E+HG 60.57 59.75 60.16S+G+E+HE 60.12 59.3 59.71S+G+E+HS+HG 57.59 56.81 57.19S+G+E+HS+HE 58.93 58.13 58.52S+G+E+HG+HE 62.43 61.58 62.00S+G+E+HS+HG+HE 58.56 57.76 58.16Table 4: UMFS-WE accuracy on Hindi WSD with vari-ous WordNet featuresdefining the sense.
The other reason is to bring downthe impact of topic drift which may have occurredbecause of polysemous synset members.
Similarly,it is observed that adding hypernym/hyponym glossmembers gives better performance compared to hy-pernym/hyponym synset members.
Example sen-tence members also provide additional informationin determining the MFS of a word, which furtherimproves the results.On the whole, we achieve the best performancewhen S, G, E, HG and HE features are used together.This is shown in Table 4.WordNet Features P R F-1S 22.89 22.82 22.85S+G 32.72 32.64 32.68S+G+E 30.87 30.79 30.84S+G+E+HS 33.46 33.37 33.42S+G+E+HG 39.36 39.26 39.31S+G+E+HE 29.77 29.69 29.73S+G+E+HS+HG 46.00 45.89 45.95S+G+E+HS+HE 39.11 39.02 39.06S+G+E+HG+HE 41.82 41.72 41.77S+G+E+HS+HG+HE 52.39 52.27 52.34S+G+HS+HG 51.17 51.04 51.11Table 5: UMFS-WE accuracy on English WSD with var-ious WordNet features4.2 EnglishWe achieve good performance for English WSDon the SENSEVAL-2 dataset, whereas the perfor-mance on the SENSEVAL-3 dataset is compara-tively poor.
Here also, synset members alone per-form badly.
However, adding gloss members im-proves results.
The same is observed for hyper-nym/hyponym gloss members.
Using example sen-tence members of either synsets or their hyper-nymy/hyponymy synsets bring down the perfor-mance of the system.
This is also justified whenwe consider only synset members, gloss mem-bers, hypernym/hyponym synset members, hyper-nym/hyponym gloss members which give a scoreclose to the best obtained score.
All the features (S,G, E, HS, HG & HE), when used together, give thebest performance as shown in Table 5.Also, we have calculated the F-1 score for Hindiand English WSD for increasing thresholds on thefrequency of nouns appearing in the corpus.
Thisis depicted in Figure 2 and Figure 3 for Hindi andEnglish WSD respectively.
Here, in both plots, itis clearly shown that, as the frequency of nouns inthe corpus increases our approach outperforms base-lines for both Hindi and English WSD.
On the otherhand, SemCor baseline accuracy decreases for thosewords which occur more than 8 times in the testcorpus.
This is depicted in Figure 3.
There are15 such frequent word types.
The main reason forlow SemCor accuracy is that these words occur veryfew times with their MFS as listed by the SemCorbaseline.
For example, the word cell never appearswith its MFS (as listed by SemCor baseline) in theSENSEVAL-2 dataset.As opposed to baselines, our approach gives a fea-sible way to extract predominant senses in an unsu-pervised setup.
Our approach is domain independentsothat it can be very easily adapted to a domain spe-cific corpus.
To get the domain specific word em-beddings, we simply have to run the word2vec pro-gram on the domain specific corpus.
The domainspecific word embeddings can be used to get theMFS for the domain of interest.
Our approach is lan-guage independent.
However, due to time and spaceconstraints we have performed our experiments ononly Hindi and English languages.5 Related WorkMcCarthy et al (2007) proposed an unsupervisedapproach for finding the predominant sense using anautomatic thesaurus.
They used WordNet similar-ity for identifying the predominant sense.
Their ap-proach outperforms the SemCor baseline for words1241Figure 2: UMFS-WE accuracy on Hindi WSD for wordswith various frequency thresholds in Newspaper datasetwith SemCor frequency below five.
Buitelaar et al(2001) presented the knowledge based approach forranking GermaNet synsets on specific domains.
La-pata et al (2004) worked on detecting the predomi-nant sense of verbs where verb senses are taken fromthe Levin classes.
Our approach is similar to that ofMcCarthy et al (2007) as we are also learning pre-dominant senses from the untagged text.6 Conclusion and Future WorkIn our paper, we presented an unsupervised ap-proach for finding the most frequent sense for nounsby exploiting word embeddings.
Our approach istested on Hindi and English WSD.
It is found thatour approach outperforms the WFS baseline forHindi.
As the frequency of noun increases in the cor-pus, our approach outperforms the baseline for bothHindi and English WSD.
Our approach can be eas-ily ported to various domains and across languages.In future, we plan to improve on the performance ofour model for English, even for infrequent words.Also, we will explore this approach for other lan-guages and for other parts-of-speech.7 AcknowledgmentsWe would like to thank Mrs. Rajita Shukla, Mrs.Jaya Saraswati and Mrs. Laxmi Kashyap for theirenormous efforts in the creation of the WordNetFirst Baseline for the Hindi WordNet.
We also thankFigure 3: UMFS-WE accuracy on English WSD forwords with various frequency thresholds in SENSEVAL-2 datasetTDIL, DeitY for their continued support.ReferencesSatanjeev Banerjee and Ted Pedersen.
2003.
ExtendedGloss Overlaps as a Measure of Semantic Relatedness.In Proceedings of the Eighteenth International JointConference on Artificial Intelligence, pp 805-810.Mohit Bansal, Kevin Gimpel and Karen Livescu.
2014.Tailoring Continuous Word Representations for De-pendency Parsing.
Proceedings of ACL 2014.Ond?rej Bojar, Diatka Vojt?ech, Rychl?y Pavel, Stra?n?akPavel, Suchomel V?
?t, Tamchyna Ale?s and ZemanDaniel.
2014.
HindEnCorp - Hindi-English andHindi-only Corpus for Machine Translation.
Proceed-ings of the Ninth International Conference on Lan-guage Resources and Evaluation (LREC?14).Paul Buitelaar and Bogdan Sacaleanu.
2001.
Rank-ing and selecting synsets by domain relevance.
Pro-ceedings of WordNet and Other Lexical Resources,NAACL 2001 Workshop.Xinxiong Chen, Zhiyuan Liu and Maosong Sun.
2014.A Unified Model for Word Sense Representation andDisambiguation.
Proceedings of ACL 2014.Ronan Collobert, Jason Weston, L?eon Bottou, MichaelKarlen, Koray Kavukcuoglu, Pavel P. Kuksa.
2011.Natural Language Processing (almost) from Scratch.CoRR, http://arxiv.org/abs/1103.0398.Agirre Eneko and Edmonds Philip.
2007.
WordSense Disambiguation: Algorithms and Applica-tions.
Springer Publishing Company, Incorporated,ISBN:1402068700 9781402068706.1242Z.
Harris.
1954.
Distributional structure.
Word10(23):146-162.Tomas Mikolov, Chen Kai, Corrado Greg and Dean Jef-frey.
2013.
Efficient Estimation of Word Representa-tions in Vector Space.
In Proceedings of Workshop atICLR, 2013.Diana McCarthy, Rob Koeling, Julie Weeds and JohnCarroll.
2007.
Unsupervised Acquisition of Predomi-nant Word Senses.
Computational Linguistics, 33 (4)pp 553-590.Mirella Lapata and Chris Brew.
2004.
Verb class dis-ambiguation using informative priors.
ComputationalLinguistics, 30(1):45-75.Bengio Yoshua, Ducharme R?ejean, Vincent Pascal andJanvin Christian.
2003.
A Neural Probabilistic Lan-guage Model.
J. Mach.
Learn.
Res., issn = 1532-4435,pp 1137-1155.1243
