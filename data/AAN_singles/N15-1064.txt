Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 619?629,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsJointly Modeling Inter-Slot Relations by Random Walk on KnowledgeGraphs for Unsupervised Spoken Language UnderstandingYun-Nung Chen, William Yang Wang, and Alexander I. RudnickySchool of Computer Science, Carnegie Mellon University5000 Forbes Avenue, Pittsburgh, PA 15213-3891, USA{yvchen, yww, air}@cs.cmu.eduAbstractA key challenge of designing coherent seman-tic ontology for spoken language understand-ing is to consider inter-slot relations.
In prac-tice, however, it is difficult for domain expertsand professional annotators to define a coher-ent slot set, while considering various lexi-cal, syntactic, and semantic dependencies.
Inthis paper, we exploit the typed syntactic de-pendency theory for unsupervised inductionand filling of semantics slots in spoken dia-logue systems.
More specifically, we buildtwo knowledge graphs: a slot-based seman-tic graph, and a word-based lexical graph.To jointly consider word-to-word, word-to-slot, and slot-to-slot relations, we use a ran-dom walk inference algorithm to combine thetwo knowledge graphs, guided by dependencygrammars.
The experiments show that con-sidering inter-slot relations is crucial for gen-erating a more coherent and compete slot set,resulting in a better spoken language under-standing model, while enhancing the inter-pretability of semantic slots.1 IntroductionAn important requirement for building a success-ful spoken dialogue system (SDS) is to define a co-herent slot set and the corresponding slot-fillers forthe spoken language understanding (SLU) compo-nent.
Unfortunately, since the semantic slots are of-ten mutually-related, it is non-trivial for domain ex-perts and professional annotators to design a suchslot set for semantic representation of SLU.Considering a restaurant domain (Henderson etal., 2012), ?restaurant?
is the target slot, and impor-tant adjective modifiers such as ?Asian?
(the restau-rant type) and ?cheap?
(the price of the restaurant)should be included in the slot set, so that the se-mantic representation of SLU can be more coherentand complete.
In this case, it is challenging to de-sign such a coherent and complete slot set manually,while considering various lexical, syntactic, and se-mantic dependencies.Instead of considering slots independently, thispaper takes a data-driven approach to model word-to-word relations via syntactic dependencies andfurther infer slot-to-slot relations.
To do this, weincorporate the typed dependency grammar the-ory (De Marneffe and Manning, 2008) in a state-of-the-art frame-semantic driven unsupervised slotinduction framework (Chen et al, 2013b).
In par-ticular, we build two knowledge graphs: a slot-based semantic knowledge graph, and a word-basedlexical knowledge graph.
Using typed dependencytriples, we then study the stochastic relations be-tween slots and words, using a mutually-reinforcedrandom walk inference procedure to combine thetwo knowledge graphs.
In evaluations, we use thejointly learned inter-slot relations to induce a coher-ent slot set in an unsupervised fashion.
Our contri-butions are three-fold:?
We are among the first to consider unsuper-vised spoken language understanding combin-ing semantic and lexical knowledge graphs;?
We propose a novel typed syntactic dependencygrammar driven random walk model for rela-tion discovery;619?
Our experimental results suggest that jointlyconsidering inter-slot relations helps obtain amore coherent and complete semantic slot set.2 Related WorkWith the recent success of commercial dialogue sys-tems and personal assistants (e.g., Microsoft?s Cor-tana1, Google Now2, Apple?s Siri3, and Amazon?sEcho4), a key focus on developing spoken under-standing techniques is the scalability issue.From the knowledge management perspective,empowering the system with a large knowledge baseis of crucial significance to modern spoken dia-logue systems.
On this end, our work clearly alignswith recent studies on leveraging semantic knowl-edge graphs for SLU modeling (Heck et al, 2013;Hakkani-T?ur et al, 2013; Hakkani-T?ur et al, 2014;El-Kahky et al, 2014; Chen et al, 2014a).
Whileleveraging external knowledge is the trend, effi-cient inference algorithms, such as random walk, arestill less-studied for direct inference on knowledgegraphs of the spoken contents.In the natural language processing literature, Laoet al (2011) used a random walk algorithm to con-struct inference rules on large entity-based knowl-edge bases, and leveraged syntactic informationfor reading the Web (Lao et al, 2012).
Eventhough this work has important contributions, theproposed algorithm cannot learn mutually-recursiverelations, and does not to consider lexical items?in fact, more and more studies show that, in addi-tion to semantic knowledge graphs, lexical knowl-edge graphs (Inkpen and Hirst, 2006; Song et al,2011; Li et al, 2013b) that model surface-level natu-ral language realization, multiword expressions, andcontext (Li et al, 2013a), are also critical for shorttext understanding (Song et al, 2011; Wang et al,2014).From the engineering perspective, quick and easydevelopment turnaround time for domain-specificdialogue applications is also critical (Chen and Rud-nicky, 2014).
Prior work shows that it is possible touse the frame-semantics theory to automatically in-1http://www.windowsphone.com/en-us/how-to/wp8/cortana2http://www.google.com/landing/now3http://www.apple.com/ios/siri4http://www.amazon.com/oc/echoduce and fill semantic slots (Chen et al, 2013b), andthat leveraging distributional semantics helps im-proving the performance (Chen et al, 2014b).
How-ever, prior works treat each slot independently andhave not considered the inter-slot relations when in-ducing the semantic slots.
To the best of our knowl-edge, we are the first to use syntactically-informedrandom walk algorithms to combine the semanticand lexical knowledge graphs, and not individuallybut globally inducing the semantic slots for buildingbetter unsupervised SLU components.3 The Proposed FrameworkWe build our approach on top of the recent suc-cess of an unsupervised frame-semantic parsing ap-proach (Chen et al, 2013b).
The main motivationof prior work is to use a FrameNet-trained statis-tical probabilistic semantic parser to generate ini-tial frame-semantic parses from automatic speechrecognition (ASR) decodings of the raw audio con-versation files, and then adapt the FrameNet-styleframes to the semantic slots in the target semanticspace, so that they can be used practically in theSDSs.
Chen et al formulated the semantic map-ping and adaptation problem as a ranking problem todifferentiate generic semantic concepts from targetsemantic space for task-oriented dialogue systems.This paper improves the adaptation process by lever-aging distributed word embeddings associated withtyped syntactic dependencies between words to inferinter-slot relations (Mikolov et al, 2013b; Mikolovet al, 2013c; Levy and Goldberg, 2014).
The pro-posed framework is shown in Figure 1.
In the re-mainder of the section, we first introduce frame-semantic parsing to obtain slot candidates.
With slotcandidates, then we train the independent semanticdecoders.
The adaptation process, which is the mainfocus of this paper, is performed to decide outputtedslots.
Finally we can build an SLU model based onthe learned semantic decoders and induced slots.3.1 Probabilistic Semantic ParsingFrameNet is a linguistically-principled semantic re-source that offers annotations of predicate-argumentsemantics, and associated lexical units for En-glish (Baker et al, 1998).
FrameNet is developedbased on a semantic theory, Frame Semantics (Fill-620SlotRankingModelSLU ModelInduced SlotsSemanticRepresentation?can I have a cheap restaurant?Slot InductionSlotCandidatesFrame-Semantic ParsingSemantic DecoderTrainingUnlabeled CollectionSyntactic Dependency ParsingLexical Knowledge GraphSemantic Knowledge GraphFigure 1: The proposed frameworkcan i have a cheap restaurantFrame: capability FT LU: can FE Filler: iFrame: expensiveness FT LU: cheap Frame: locale_by_use FT/FE LU: restaurantFigure 2: An example of probabilistic frame-semanticparsing on ASR output.
FT: frame target.
FE: frame ele-ment.
LU: lexical unit.more, 1976), which holds that the meaning of mostwords can be expressed on the basis of semanticframes, which encompass three major components:frame (F), frame elements (FE), and lexical units(LU).
For example, the frame ?food?
contains wordsreferring to items of food.
A descriptor frame ele-ment within the food frame indicates the character-istic of the food.
For example, the phrase ?low fatmilk?
should be analyzed with ?milk?
evoking thefood frame and ?low fat?
filling the descriptor FE ofthat frame.In our approach, we parse all ASR-decoded ut-terances in our corpus using SEMAFOR5, a state-of-the-art semantic parser for frame-semantic pars-ing (Das et al, 2010; Das et al, 2013), and ex-tract all frames from semantic parsing results as slotcandidates, where the LUs that correspond to theframes are extracted for slot filling.
For example,Figure 2 shows an example of an ASR-decoded textoutput parsed by SEMAFOR.
SEMAFOR generatesthree frames (capability, expensiveness, and lo-cale by use) for the utterance, which we consideras slot candidates for training the SLU model.
Notethat for each slot candidate, SEMAFOR also in-cludes the corresponding lexical unit (can i, cheap,5http://www.ark.cs.cmu.edu/SEMAFOR/and restaurant), which we consider as possible slot-fillers.3.2 Independent Semantic DecoderWith outputted semantic parses, we extract theframes with the top 50 highest frequency as our slotcandidates for training SLU.
The features for train-ing are generated by word confusion network, whereconfusion network features are shown to be useful indeveloping more robust systems for SLU (Hakkani-T?ur et al, 2006; Henderson et al, 2012).
Webuild a vector representation of an utterance as u =[x1, ..., xj, ...].xj= E[Cu(n-gramj)]1/|n-gramj|, (1)where Cu(n-gramj) counts how many times n-gramjoccurs in the utterance u, E(Cu(n-gramj))is the expected frequency of n-gramjin u, and|n-gramj| is the number of words in n-gramj.For each slot candidate si, we generate a pseudotraining data Dito train a binary classifier Miforpredicting the existence of sigiven an utterance,Di= {(uk, lik) | uk?
R+, lik?
{?1,+1}}Kk=1,where lik= +1 when the utterance ukcontains theslot candidate siin its semantic parse, lik= ?1 oth-erwise, and K is the number of utterances.3.3 Adaptation Process and SLU ModelSince SEMAFOR was trained on FrameNet annota-tion, which has a more generic frame-semantic con-text, not all the frames from the parsing results canbe used as the actual slots in the domain-specific dia-logue systems.
For instance, in Figure 2, we see thatthe frames ?expensiveness?
and ?locale by use?are essentially the key slots for the purpose of un-derstanding in the restaurant query domain, whereas621w1w2w3w4w5w6w7Lexical Knowledge Graphs2Semantic Knowledge Graphs1 s3Figure 3: A simplified example of the two knowledgegraphs, where a slot candidate siis represented as a nodein a semantic knowledge graph and a word wjis repre-sented as a node in a lexical knowledge graph.the ?capability?
frame does not convey particularvaluable information for SLU.
With the trained in-dependent semantic decoders for all slot candidates,adaptation process computes the prominence of slotcandidates for ranking and then selects a list of in-duced slots associated with their corresponding se-mantic decoders for use in domain-specific dialoguesystems, where the detail is described in Section 4.Then with each induced slot siand its correspond-ing trained semantic decoderMi, an SLU model canbe built to predict whether the semantic slot occursin the given utterance in a fully unsupervised way.
Inother words, the SLU model is able to transform thetesting utterance into semantic representations with-out human involvement.4 Slot Ranking ModelThe purpose of the ranking model is to distinguishbetween generic semantic concepts and domain-specific concepts that are relevant to an SDS.
To in-duce meaningful slots for the purpose of SDS, wecompute the prominence of the slot candidates us-ing a slot ranking model described below.With the semantic parses from SEMAFOR, whereeach frame is viewed independently, so inter-slot re-lations are not included, the model ranks the slotcandidates by integrating two information: (1) thefrequency of each slot candidate in the corpus, sinceslots with higher frequency may be more important.
(2) the relations between slot candidates.
Assumingthat domain-specific concepts are usually related toeach other, globally considering inter-slot relationsinduces a more coherent slot set.
Here for baselinecan i have a cheap restaurantccompamod  dobj  nsubj  detcapability expensiveness locale_by_useFigure 4: The dependency parsing result on an utterance.scores, we only use the frequency of each slot can-didate as its prominence.First we construct two knowledge graphs, oneis a slot-based semantic knowledge graph and an-other is a word-based lexical knowledge graph, bothof which encode the typed dependency relations intheir edge weights.
We also connect two graphs tomodel the relations between slot-filler pairs.4.1 Knowledge GraphsWe construct two undirected graphs, semantic andlexical knowledge graphs.
Each node in the seman-tic knowledge graph is a slot candidate sioutputtedby the frame-semantic parser, and each node in thelexical knowledge graph is a word wj.?
Slot-based semantic knowledge graph is builtas Gs= ?Vs, Ess?, where Vs= {si} andEss= {eij| si, sj?
Vs}.?
Word-based lexical knowledge graph is builtas Gw= ?Vw, Eww?, where Vw= {wi} andEww= {eij| wi, wj?
Vw}.With two knowledge graphs, we build the edgesbetween slots and slot-fillers to integrate them asshown in Figure 3.
Thus the combined graph can beformulated as G = ?Vs, Vw, Ess, Eww, Ews?, whereEws= {eij| wi?
Vw, sj?
Vs}.
Ess, Eww,and Ewscorrespond to slot-to-slot relations, word-to-word relations, and word-to-slot relations respec-tively (Chen and Metze, 2012; Chen and Metze,2013).4.2 Edge Weight EstimationConsidering the relations in the knowledge graphs,the edge weights for Ewwand Essare measuredbased on the dependency parsing results.
Theexample utterance ?can i have a cheap restau-rant?
and its dependency parsing result are illus-trated in Figure 4.
The arrows denote the de-622Typed Dependency Relation Target Word ContextsWord ?restaurant, AMOD, cheap?restaurant cheap/AMODcheap restaurant/AMOD?1Slot ?locale by use, AMOD,expensiveness?locale by use expensiveness/AMODexpansiveness locale by use/AMOD?1Table 1: The contexts extracted for training dependency-based word/slot embeddings from the utterance of Fig.
2.pendency relations from headwords to their de-pendents, and words on arcs denote types of thedependencies.
All typed dependencies betweentwo words are encoded in triples and form aword-based dependency set Tw= {?wi, t, wj?
},where t is the typed dependency between theheadword wiand the dependent wj.
For exam-ple, Figure 4 generates ?restaurant, AMOD, cheap?,?have, DOBJ, restaurant?, etc.
for Tw.
Simi-larly, we build a slot-based dependency set Ts={?si, t, sj?}
by transforming dependencies betweenslot-fillers into ones between slots.
For example,?restaurant, AMOD, cheap?
from Twis transformedinto ?locale by use, AMOD,expensiveness?
forbuilding Ts, because both sides of the non-dottedline are parsed as slot-fillers by SEMAFOR.For the edges within a single knowledge graph,we assign a weight of the edge connecting nodes xiand xjas r?
(xi, xj), where x is either s or w. Sincethe weights are measured based on the relations be-tween nodes regardless of the directions, we com-bine the scores of two directional dependencies:r?
(xi, xj) = r(xi?
xj) + r(xj?
xi), (2)where r(xi?
xj) is the score estimating the de-pendency including xias a head and xjas a depen-dent.
In Section 4.2.1 and 4.2.2, we propose twoscoring functions for r(?
), frequency-based as r1(?
)and embedding-based as r2(?)
respectively.For the edges in Ews, we estimate the edgeweights based on the frequency that the slot candi-dates and the words are parsed as slot-filler pairs.
Inother words, the edge weight between the slot-fillerwiand the slot candidate sj, r?
(wi, sj), is equal tohow many times the filler wicorresponds to the slotcandidate sjin the parsing results.4.2.1 Frequency-Based MeasurementBased on the dependency set Tx, we use t?xi?xjtodenote the most frequent typed dependency with xias a head and xjas a dependent.t?xi?xj= argmaxtC(xi?
?txj), (3)where C(xi?
?txj) counts how many times the de-pendency ?xi, t, xj?
occurs in the dependency set Tx.Then the scoring function that estimates the de-pendency xi?
xjis measured asr1(xi?
xj) = C(xi????
?t?xi?xjxj), (4)which equals to the highest observed frequency ofthe dependency xi?
xjamong all types from Tx.4.2.2 Embedding-Based MeasurementMost neural embeddings use linear bag-of-wordscontexts, where a window size is defined to producecontexts of the target words (Mikolov et al, 2013c;Mikolov et al, 2013b; Mikolov et al, 2013a).
How-ever, some important contexts may be missing dueto smaller windows, while larger windows capturebroad topical content.
A dependency-based em-bedding approach was proposed to derive contextsbased on the syntactic relations the word participatesin for training embeddings, where the embeddingsare less topical but offer more functional similaritycompared to original embeddings (Levy and Gold-berg, 2014).Table 1 shows the extracted dependency-basedcontexts for each target word from the example inFigure 4, where headwords and their dependents canform the contexts by following the arc on a word inthe dependency tree, and?1 denotes the directional-ity of the dependency.
After replacing original bag-of-words contexts with dependency-based contexts,we can train dependency-based embeddings for alltarget words (Yih et al, 2014; Bordes et al, 2011;Bordes et al, 2013).For training dependency-based word embeddings,each word w is associated with a word vector vw?623Rdand each context c is represented as a contextvector vc?
Rd, where d is the embedding dimen-sionality.
We learn vector representations for bothwords and contexts such that the dot product vw?vcassociated with ?good?
word-context pairs belong-ing to the training data D is maximized, leading tothe objective function:arg maxvw,vc?
(w,c)?Dlog11 + exp(?vc?
vw), (5)which can be trained using stochastic-gradient up-dates (Levy and Goldberg, 2014).
Then we canobtain the dependency-based slot and word embed-dings using Tsand Twrespectively.With trained dependency-based embeddings, weestimate the probability that xiis the headword andxjis its dependent via the typed dependency t asP (xi?
?txj) =Sim(xi, xj/t) + Sim(xj, xi/t?1)2,(6)where Sim(xi, xj/t) is the cosine similarity be-tween the slot/word embeddings vxiand the contextembeddings vxj/tafter normalizing to [0, 1].
Thenwe can measure the scoring function r2(?)
asr2(xi?
xj) = C(xi????
?t?xi?xjxj)?P (xi????
?t?xi?xjxj),(7)which is similar to (4) but additionally weighted bythe estimated probability.
The estimated probabilitysmooths the observed frequency to avoid overfittingdue to a smaller dataset.4.3 Random Walk AlgorithmWe first compute Lww= [r?
(wi, wj)]|Vw|?|Vw|andLss= [r?
(si, sj)]|Vs|?|Vs|, where r?
(wi, wj) andr?
(si, sj) are either from frequency-based (r1(?
))or embedding-based measurements (r2(?)).
Sim-ilarly, Lws= [r?
(wi, sj)]|Vw|?|Vs|and Lsw=[r?
(wi, sj)]T|Vw|?|Vs|, where r?
(wi, sj) is the frequencythat sjand wiare a slot-filler pair computed inSection 4.2.
Then we only keep the top N high-est weights for each row in Lwwand Lss(N =10), which means that we filter out the edges withsmaller weights within the single knowledge graph.Column-normalization are performed for Lww, Lss,Lws, Lsw(Shi and Malik, 2000).
They can beviewed as word-to-word, slot-to-slot, and word-to-slot relation matrices.4.3.1 Single-Graph Random WalkHere we run random walk only on the semanticknowledge graph to propagate the scores based oninter-slot relations through the edges Ess.R(t+1)s= (1?
?
)R(0)s+ ?LssR(t)s, (8)where R(t)sdenotes the importance scores of theslot candidates Vsin t-th iteration.
In the algo-rithm, the score is the interpolation of two scores, thenormalized baseline importance of slot candidates(R(0)s), and the scores propagated from the neigh-boring nodes in the semantic knowledge graph basedon slot-to-slot relations via Lss.
The algorithm willconverge when R(t+1)s= R(t)s= R?sand (9) can besatisfied.R?s=((1?
?
)R(0)seT+ ?Lss)R?s= M1R?s,(9)where e = [1, 1, ..., 1]T. It has been shown thatthe closed-form solution R?sof (9) is the dominanteigenvector of M1(Langville and Meyer, 2005),the eigenvector corresponding to the largest abso-lute eigenvalue of M1.
The solution of R?sde-notes the updated importance scores for all utter-ances.
Similar to the PageRank algorithm (Brin andPage, 1998), the solution can also be obtained by it-eratively updating R(t)s.4.3.2 Double-Graph Random WalkHere we borrow the idea from two-layer mutu-ally reinforced random walk to propagate the scoresbased on not only internal importance propagationwithin the same graph but external mutual reinforce-ment between different knowledge graphs (Chenand Metze, 2012; Chen and Metze, 2013).
{R(t+1)s= (1?
?
)R(0)s+ ?LssLswR(t)wR(t+1)w= (1?
?
)R(0)w+ ?LwwLwsR(t)s(10)In the algorithm, they are the interpolations of twoscores, the normalized baseline importance (R(0)sand R(0)w) and the scores propagated from anothergraph.
For the semantic knowledge graph, LswR(t)wis the score from the word set weighted by slot-to-word relations, and then the scores are propagatedbased on slot-to-slot relations via Lss.
Similarly,nodes of the lexical knowledge graph also include624the scores propagated from the semantic knowledgegraph.
Then R(t+1)sand R(t+1)wcan be mutually up-dated by the latter parts in (10) iteratively.
When thealgorithm converges, we have R?sas follows.R?s= (1?
?
)R(0)s(11)+ ?LssLsw((1?
?
)R(0)w+ ?LwwLwsR?s)=((1?
?
)R(0)seT+ ?(1?
?
)LssLswR(0)weT+ ?2LssLswLwwLws)R?s= M2R?s.The closed-form solution R?sof (11) is the dominanteigenvector of M2.5 ExperimentsWe evaluate our approach in two ways.
First, we ex-amine the slot induction accuracy by comparing theranked list of induced slots with the reference slotscreated by system developers (Young, 2007).
Sec-ondly, with the ranked list of induced slots and theirassociated semantic decoders, we can evaluate theSLU performance.
For the experiments, we evaluateboth on ASR transcripts of the raw audio, and on themanual transcripts.5.1 Experimental SetupIn this experiment, we used the Cambridge Univer-sity SLU corpus, previously used on several otherSLU tasks (Henderson et al, 2012; Chen et al,2013a).
The domain of the corpus is about restaurantrecommendation in Cambridge; subjects were askedto interact with multiple SDSs in an in-car setting.The corpus contains a total number of 2,166 dia-logues, including 15,453 utterances (10,571 for self-training and 4,882 for testing).
The data is gender-balanced, with slightly more native than non-nativespeakers.
The vocabulary size is 1868.
An ASR sys-tem was used to transcribe the speech; the word errorrate was reported as 37%.
There are 10 slots cre-ated by domain experts: addr, area, food, name,phone, postcode, price range, signature, task,and type.For parameter setting, the damping factor for ran-dom walk ?
is empirically set as 0.9 for all exper-iments.
For training the semantic decoders, we useSVM with a linear kernel to predict each semanticslot.
We use Stanford Parser to obtain the collapsedspeak on topic  addr  areafoodphonepart orientationaldirectionlocalepart inner outerfoodorigincontactingpostcodeprice rangetasktypesendingcommerce scenarioexpensivenessrangeseekingd esiringlocatinglocale by usebuildingFigure 5: The mappings from induced slots (withinblocks) to reference slots (right sides of arrows).typed syntactic dependencies (Socher et al, 2013)and set the dimensionality of embeddings d = 300in all experiments.5.2 Evaluation MetricsTo eliminate the influence of threshold selectionwhen choosing induced slots, in the following met-rics, we take the whole ranking list into account andevaluate the performance by the metrics that are in-dependent of the selected threshold.5.2.1 Slot InductionTo evaluate the accuracy of the induced slots, wemeasure their quality as the proximity between in-duced slots and reference slots.
Figure 5 showsthe mappings that indicate semantically related in-duced slots and reference slots (Chen et al, 2013b).For example, ?expensiveness?
price?, ?food?food?, and ?direction ?
area?
show that these in-duced slots can be mapped into the reference slotsdefined by experts and carry important semantics inthe target domain for developing the task-orientedSDS.
Since we define the adaptation task as a rank-ing problem, with a ranked list of induced slots andassociated scores, we can use the standard averageprecision (AP) and the area under the precision-recall curve (PR-AUC) as our metrics, where the in-duced slot is counted as correct when it has a map-ping to a reference slot.5.2.2 SLU ModelWhile semantic slot induction is essential for pro-viding semantic categories and imposing semanticconstraints, we are also interested in understandingthe performance of our unsupervised SLU models.625ApproachASR ManualSlot Induction SLU Model Slot Induction SLU ModelAP PR-AUC WAP AF AP PR-AUC WAP AF(a) Baseline (Frequency) 56.69 54.67 35.82 43.28 53.01 50.80 36.78 44.20(b)SingleFrequency 63.88 62.05 41.67 47.38 63.02 61.10 43.76 48.53(c) Embedding 69.04 68.25 46.29 48.89 75.15 74.50 54.50 50.86(d)DoubleFrequency 56.83 55.31 32.64 44.91 52.12 50.54 34.01 45.05(e) Embedding 71.48 70.84 44.06 47.91 76.42 75.94 52.89 50.40Table 2: The performance of induced slots and corresponding SLU models (%)For each induced slot with the mapping to a ref-erence slot, we can compute an F-measure of thecorresponding semantic decoder, and weight the av-erage precision with corresponding F-measure asweighted average precision (WAP) to evaluate theperformance of slot induction and SLU tasks to-gether.
The metric scores the ranking result higherif the induced slots corresponding to better semanticdecoders are ranked higher.
Another metric is theaverage F-measure (AF), which is the average microF-measure of SLU models at all cut-off positions inthe ranked list.
Compared to WAP, AF additionallyconsiders the slot popularity in the dataset.5.3 Evaluation ResultsTable 5.1 shows the results on both ASR and manualtranscripts.
Rows (a) is the baseline only consider-ing the frequency of each slot candidate for rank-ing (Chen et al, 2013b).
Rows (b) and (c) showperformance after leveraging a semantic knowledgegraph through random walk.
Rows (d) and (e) arethe results after combining two knowledge graphs.We find almost all results are improved by addi-tionally considering inter-slot relations in terms ofsingle- and double-graph random walk for both ASRand manual transcripts.5.3.1 Slot InductionFor both ASR and manual transcripts, almostall results outperform the baseline, showing thatinter-slot relations significantly influence the perfor-mance of slot induction.
The best performance isfrom the results of double-graph random walk withthe embedding-based measurement, which integratea semantic knowledge graph and a lexical knowl-edge graph together and jointly consider slot-to-slot,word-to-word, and word-to-slot relations when scor-ing the prominence of slot candidates to generate acoherent slot set.5.3.2 SLU ModelFor both ASR and manual transcripts, almost allresults outperform the baseline, which shows thepractical usage for training dialogue systems.
Thebest performance is from the results of single-graphrandom walk with the embedding-based measure-ment, which only use the semantic knowledge graphto involve the inter-slot relations.
The semanticknowledge graph is not as precise as the lexical oneand may be influenced by the performance of the se-mantic parser more.
Although the row (e) does notshow better performance than the row (c), double-graph random walk may be more robust becauseit additionally includes the word relations to avoidonly relying on the relations tied with the slot candi-dates.5.4 Discussion and Analysis5.4.1 Comparing Frequency- andEmbedding-Based MeasurementsTable 5.1 shows that all results with theembedding-based measurement perform better thanthose with the frequency-based measurement.
Thefrequency-based measurement also brings large im-provement for single-graph approaches, but does notfor double-graph ones.
The reason is probably thatusing observed frequencies in the lexical knowledgegraph may result in overfitting issues due to thesmaller dataset.
Additionally including embeddinginformation can smooth the edge weights and dealwith data sparsity to improve the performance, es-pecially for the lexical knowledge graph.6265.4.2 Comparing Single- and Double-GraphApproachesConsidering that the embedding-based measure-ment performs better, we only compare the resultsof single- and double-graph random walk using thismeasurement (rows (c) and (e)).
It can be seenthat the difference between them is not consistentin terms of slot induction and SLU model.For evaluating slot induction (AP and PR-AUC),the double-graph random walk (row (e)) performsbetter on both ASR and manual results, which im-plies that additionally integrating the lexical knowl-edge graph helps decide a more coherent and com-plete slot set since we can model the score propa-gation more precisely (not only slot-level but word-level information).
However, for SLU evaluation(WAP and AF), the single-graph random walk (row(c)) performs better, which may imply that the slotscarrying the coherent relations from the row (e) maynot have good semantic decoder performance so thatthe performance is decreased a little.
For exam-ple, double-graph random walk scores the slots lo-cal by use and expensiveness higher than the slotcontacting, while the single-graph method ranksthe latter higher.
local by use and expensivenessare more important on this domain but contactinghas very good performance of its semantic decoder,so the double-graph approach does not show the im-provement when evaluating SLU models.
This al-lows us to try an improved method of jointly opti-mizing the slot coherence and SLU performance inthe future.5.4.3 Relation Discovery AnalysisTo interpret the inter-slot relations, we output theslot-to-slot relations with highest scores from thebest results (row (e) in Table 5.1) in Table 3, andthe automatically constructed ontology is shown inFigure 6.
It can be shown that the outputted inter-slot relations are reasonable and usually connect twoimportant semantic slots in this restaurant domain.This proves that inter-slot relations help decide acoherent and complete slot set and enhance the in-terpretability of semantic slots.
Therefore, from apractical perspective, developers are able to designthe framework of dialogue systems more easily, andthe development of SDS can be speeded up with lesshuman effort.Rank Relation1 ?locale by use, NN, food?2 ?food, AMOD,expensiveness?3 ?locale by use, AMOD,expensiveness?4 ?seeking, PREP FOR, food?5 ?food, AMOD, relational quantity?6 ?desiring, DOBJ, food?7 ?seeking, PREP FOR, locale by use?8 ?food, DET,quantity?Table 3: The top inter-slot relations learned from thetraining set of ASR outputs.locale_by_usefood  expensivenessseekingrelational_quantityPREP_FORPREP_FORNN AMODAMODAMOD desiringDOBJFigure 6: The automatically constructed domain-specificontology based on Table 3.6 ConclusionThe paper proposes an approach of jointly consid-ering inter-slot relations for slot induction to out-put a more coherent slot set, where two knowledgegraphs, a slot-based semantic knowledge graph anda word-based lexical knowledge graph, are built andcombined by a random walk algorithm.
The au-tomatically induced slots carry coherent and inter-pretable relations and can be used for training betterSLU models of SDSs in an unsupervised fashion.AcknowledgmentsWe thank Anatole Gershman for helpful discus-sions and anonymous reviewers for their useful com-ments.
We are also grateful to MetLife?s support.Any opinions, findings, and conclusions expressedin this publication are those of the authors and do notnecessarily reflect the views of funding agencies.627ReferencesCollin F Baker, Charles J Fillmore, and John B Lowe.1998.
The Berkeley FrameNet project.
In Proceed-ings of COLING, pages 86?90.Antoine Bordes, Jason Weston, Ronan Collobert, YoshuaBengio, et al 2011.
Learning structured embeddingsof knowledge bases.
In Proceedings of AAAI.Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran,Jason Weston, and Oksana Yakhnenko.
2013.
Trans-lating embeddings for modeling multi-relational data.In Advances in Neural Information Processing Sys-tems, pages 2787?2795.Sergey Brin and Lawrence Page.
1998.
The anatomy of alarge-scale hypertextual web search engine.
Computernetworks and ISDN systems, 30(1):107?117.Yun-Nung Chen and Florian Metze.
2012.
Two-layermutually reinforced random walk for improved multi-party meeting summarization.
In Proceedings of The4th IEEE Workshop on Spoken Language Tachnology,pages 461?466.Yun-Nung Chen and Florian Metze.
2013.
Multi-layermutually reinforced random walk with hidden parame-ters for improved multi-party meeting summarization.In INTERSPEECH, pages 485?489.Yun-Nung Chen and Alexander I. Rudnicky.
2014.
Dy-namically supporting unexplored domains in conversa-tional interactions by enriching semantics with neuralword embeddings.
In Proceedings of 2014 IEEE Spo-ken Language Technology Workshop (SLT),.Yun-Nung Chen, William Yang Wang, and Alexander I.Rudnicky.
2013a.
An empirical investigation ofsparse log-linear models for improved dialogue actclassification.
In Proceedings of ICASSP, pages 8317?8321.Yun-Nung Chen, William Yang Wang, and Alexander IRudnicky.
2013b.
Unsupervised induction and fillingof semantic slots for spoken dialogue systems usingframe-semantic parsing.
In Proceedings of 2013 IEEEWorkshop on Automatic Speech Recognition and Un-derstanding (ASRU), pages 120?125.
IEEE.Yun-Nung Chen, Dilek Hakkani-T?ur, and Gokhan Tur.2014a.
Deriving local relational surface forms fromdependency-based entity embeddings for unsuper-vised spoken language understanding.
In Proceedingsof 2014 IEEE Spoken Language Technology Workshop(SLT),.Yun-Nung Chen, William Yang Wang, and Alexander I.Rudnicky.
2014b.
Leveraging frame semantics anddistributional semantics for unsupervised semantic slotinduction in spoken dialogue systems.
In Proceedingsof 2014 IEEE Spoken Language Technology Workshop(SLT),.Dipanjan Das, Nathan Schneider, Desai Chen, andNoah A Smith.
2010.
Probabilistic frame-semanticparsing.
In Proceedings of The Conference of theNorth American Chapter of the Association for Com-putational Linguistics: Human Language Technolo-gies, pages 948?956.Dipanjan Das, Desai Chen, Andr?e F. T. Martins, NathanSchneider, and Noah A. Smith.
2013.
Frame-semanticparsing.
Computational Linguistics.Marie-Catherine De Marneffe and Christopher D Man-ning.
2008.
The Stanford typed dependencies repre-sentation.
In Coling 2008: Proceedings of the work-shop on Cross-Framework and Cross-Domain ParserEvaluation, pages 1?8.
Association for ComputationalLinguistics.Ali El-Kahky, Derek Liu, Ruhi Sarikaya, G?okhan T?ur,Dilek Hakkani-T?ur, and Larry Heck.
2014.
Extendingdomain coverage of language understanding systemsvia intent transfer between domains using knowledgegraphs and search query click logs.
In Proceedings ofICASSP.Charles J Fillmore.
1976.
Frame semantics and the na-ture of language.
Annals of the NYAS, 280(1):20?32.Dilek Hakkani-T?ur, Fr?ed?eric B?echet, Giuseppe Riccardi,and Gokhan Tur.
2006.
Beyond ASR 1-best: Usingword confusion networks in spoken language under-standing.
Computer Speech & Language, 20(4):495?514.Dilek Hakkani-T?ur, Larry Heck, and Gokhan Tur.
2013.Using a knowledge graph and query click logs for un-supervised learning of relation detection.
In Proceed-ings of ICASSP, pages 8327?8331.Dilek Hakkani-T?ur, Asli Celikyilmaz, Larry Heck,Gokhan Tur, and Geoff Zweig.
2014.
Probabilistic en-richment of knowledge graph entities for relation de-tection in conversational understanding.
In Proceed-ings of INTERSPEECH.Larry P Heck, Dilek Hakkani-T?ur, and Gokhan Tur.2013.
Leveraging knowledge graphs for web-scale un-supervised semantic parsing.
In Proceedings of IN-TERSPEECH.Matthew Henderson, Milica Gasic, Blaise Thomson, Pir-ros Tsiakoulis, Kai Yu, and Steve Young.
2012.Discriminative spoken language understanding usingword confusion networks.
In Proceedings of SLT,pages 176?181.Diana Inkpen and Graeme Hirst.
2006.
Building andusing a lexical knowledge base of near-synonym dif-ferences.
Computational Linguistics, 32(2):223?262.Amy N Langville and Carl D Meyer.
2005.
A surveyof eigenvector methods for web information retrieval.SIAM review, 47(1):135?161.Ni Lao, Tom Mitchell, and William W Cohen.
2011.Random walk inference and learning in a large scale628knowledge base.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing,pages 529?539.
Association for Computational Lin-guistics.Ni Lao, Amarnag Subramanya, Fernando Pereira, andWilliam W Cohen.
2012.
Reading the web withlearned syntactic-semantic inference rules.
In Pro-ceedings of the 2012 Joint Conference on EmpiricalMethods in Natural Language Processing and Com-putational Natural Language Learning, pages 1017?1026.
Association for Computational Linguistics.Omer Levy and Yoav Goldberg.
2014.
Dependency-based word embeddings.
In Proceedings of ACL.Peipei Li, Haixun Wang, Hongsong Li, and Xindong Wu.2013a.
Assessing sparse information extraction us-ing semantic contexts.
In Proceedings of the 22ndACM international conference on Conference on infor-mation & knowledge management, pages 1709?1714.ACM.Peipei Li, Haixun Wang, Kenny Q Zhu, ZhongyuanWang, and Xindong Wu.
2013b.
Computing termsimilarity by large probabilistic isa knowledge.
In Pro-ceedings of the 22nd ACM international conference onConference on information & knowledge management,pages 1401?1410.
ACM.Tomas Mikolov, Kai Chen, Greg Corrado, and JeffreyDean.
2013a.
Efficient estimation of word representa-tions in vector space.
In Proceedings of Workshop atICLR.Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-rado, and Jeff Dean.
2013b.
Distributed representa-tions of words and phrases and their compositional-ity.
In Proceedings of Advances in Neural InformationProcessing Systems, pages 3111?3119.Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.2013c.
Linguistic regularities in continuous spaceword representations.
In HLT-NAACL, pages 746?751.
Citeseer.Jianbo Shi and Jitendra Malik.
2000.
Normalized cutsand image segmentation.
Pattern Analysis and Ma-chine Intelligence, IEEE Transactions on, 22(8):888?905.Richard Socher, John Bauer, Christopher D Manning, andAndrew Y Ng.
2013.
Parsing with compositional vec-tor grammars.
In Proceedings of the ACL conference.Citeseer.Yangqiu Song, Haixun Wang, Zhongyuan Wang, Hong-song Li, and Weizhu Chen.
2011.
Short text con-ceptualization using a probabilistic knowledgebase.
InProceedings of the Twenty-Second international jointconference on Artificial Intelligence-Volume VolumeThree, pages 2330?2336.
AAAI Press.Fang Wang, Zhongyuan Wang, Zhoujun Li, and Ji-RongWen.
2014.
Concept-based short text classificationand ranking.
In Proceedings of the 23rd ACM Interna-tional Conference on Conference on Information andKnowledge Management, pages 1069?1078.
ACM.Wen-tau Yih, Xiaodong He, and Christopher Meek.2014.
Semantic parsing for single-relation questionanswering.
In Proceedings of ACL.Steve Young.
2007.
CUED standard dialogue acts.Technical report, Cambridge University EngineeringDepartment.629
