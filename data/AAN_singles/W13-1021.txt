Proceedings of the 9th Workshop on Multiword Expressions (MWE 2013), pages 139?144,Atlanta, Georgia, 13-14 June 2013. c?2013 Association for Computational LinguisticsConstruction of English MWE Dictionary andits Application to POS TaggingYutaro Shigeto, Ai Azuma, Sorami Hisamoto, Shuhei Kondo, Tomoya Kose,Keisuke Sakaguchi, Akifumi Yoshimoto, Frances Yung, Yuji MatsumotoNara Institute Science of Technology (NAIST)Ikoma, Nara 630-0192 Japanyutaro-s@is.naist.jpAbstractThis paper reports our ongoing project forconstructing an English multiword expression(MWE) dictionary and NLP tools based onthe developed dictionary.
We extracted func-tional MWEs from the English part of Wik-tionary, annotated the Penn Treebank (PTB)with MWE information, and conducted POStagging experiments.
We report how theMWE annotation is done on PTB and the re-sults of POS and MWE tagging experiments.1 IntroductionWhile there have been a great progress in POStagging and parsing of natural language sentencesthanks to the advancement of statistical and corpus-based methods, there still remains difficulty in sen-tence processing stemming from syntactic discrep-ancies.
One of such discrepancies is caused by mul-tiword expressions (MWEs), which are known anddefined as expressions having ?idiosyncratic inter-pretations that cross word boundaries (or spaces)?
(Sag et al 2002).Sag et al(2002) classifies MWEs largely into thefollowing categories:?
Lexicalized phrases?
fixed expressions: Those having fixedword order and form (e.g.
by and large).?
semi-fixed expressions: Those havingfixed word order with lexical variationsuch as inflection, determiner selection,etc.
(e.g.
come up with).?
syntactically flexible expressions: Thosehaving a wide range of syntactic variabil-ity (e.g.
phrasal verbs that take an NP ar-gument between or following the verb andthe particle).?
Institutionalized phrases?
Phrases that are semantically and syntac-tically compositional, such as collocations(e.g.
traffic light).This paper reports our ongoing project for devel-oping an English MWE dictionary of a broad cov-erage and MWE-aware natural language processingtools.
The main contributions of this paper are asfollows:1.
Construction of an English MWE dictionary(mainly consisting of functional expressions)through extraction from Wiktionary1.2.
Annotation of MWEs in the Penn Treebank(PTB).3.
Implementation of an MWE-aware POS taggerand evaluation of its performance.2 Related workWhile there is a variety of MWE researches only afew of them focus on MWE lexicon construction.Though some examples, such as French adverb dic-tionaries (Laporte and Voyatzi, 2008; Laporte et al2008), a Dutch MWE dictionary (Gre?goire, 2007)and a Japanese MWE dictionary (Shudo et al 2011)have been constructed, there is no freely availableEnglish MWE dictionary with a broad coverage.Moreover, MWE-annotated corpora are onlyavailable for a few languages, including French and1https://en.wiktionary.org139Swedish.
While the British National Corpus is anno-tated with MWEs, its coverage is far from complete.Considering this situation, we started constructionof an English MWE dictionary (with functional ex-pressions first) and classified their occurrences inPTB into MWE or literal usage, obtaining MWE-annotated version of PTB.The effect of MWE dictionaries have been re-ported for various NLP tasks.
Nivre and Nilsson(2004) investigated the effect of recognizing MWEsin syntactic dependency parsing of Swedish.
Ko-rkontzelos and Manandhar (2010) showed perfor-mance improvement of base phrase chunking by an-notating compound and proper nouns.
Finlaysonand Kulkarni (2011) reported the effect of recogniz-ing MWEs on word sense disambiguation.Most of the previous approaches to MWE recog-nition are based on frequency or collocation mea-sures of words in large scale corpora.
On the otherhand, some previous approaches tried to recognizenew MWEs using an MWE lexicon and MWE-annotated corpora.
Constant and Sigogne (2011)presented MWE recognition using a ConditionalRandom Fields (CRFs)-based tagger with the BIOschema.
Green et al(2011) proposed an MWErecognition method using Tree Substitution Gram-mars.
Constant et al(2012) compared two phrasestructure analysis methods, one that uses MWErecognition as preprocessing and the other that usesa reranking method.Although MWEs show a variety of flexibilitiesin their appearance, most of the linguistic analysesconsider the fixed type of MWEs.
For example, theexperiments by Nivre and Nilsson (2004) focus onfixed expressions that fall into the following cate-gories:1.
Multiword names2.
Numerical expressions3.
Compound function words(a) Adverbs(b) Prepositions(c) Subordinating conjunctions(d) Determiners(e) PronounsMultiword names and numerical expressions be-have as noun phrases and have limited syntacticfunctionalities.
On the other hand, compound func-tion words have a variety of functionalities that mayaffect language analyses such as POS tagging andparsing.
In this work, we extract compound func-tional expressions from the English part of Wik-tionary, and classify their occurrences in PTB intoeither literal or MWE usages.
We then build a POStagger that takes MWEs into account.
In implement-ing this, we use CRFs that can handle a sequence oftokens as a single item (Kudo et al 2004).
We eval-uate the performance of the tagger and compare itwith the method that uses the BIO schema for iden-tifying MWE usages (Constant and Sigogne, 2011).3 MWEs Extraction from WiktionaryTo construct an English MWE dictionary, we extractentries from the English part of Wiktionary (as ofJuly 14, 2012) that include white spaces.
We ex-tract only fixed expressions that are categorized ei-ther as adverbs, conjunctions, determiners, prepo-sitions, prepositional phrases or pronouns.
We ex-clude compound nouns and phrasal verbs since theformer are easily recognized by an existing methodsuch as chunking and the latter need more sophis-ticated analyzing methods because of their syntac-tic flexibility.
We also exclude multiword adjec-tives since many of them are semi-fixed and behavedifferently from lexical adjective, having predica-tive usage only.
Table 1 summarizes the numbersof MWE entries in Wiktionary and the numbers ofthem that appear at least once in PTB.4 Annotation of MWEs in PTBWhile it is usually not easy to identify the usage ofan MWE as either an MWE or a literal usage, weinitially thought that the phrase structure tree an-notations in PTB would have enough informationto identify their usages.
This assumption is cor-rect in many cases (Figures 1(a) and 1(b)).
TheMWE usage of ?a bit?
in Figure 1(a) is analyzed as?NP-ADV?, suggesting it is used as an adverb, andthe literal usage of ?a bit?
in Figure 1(b) is labeledas ?NP?, suggesting it is used literally.
However,there are a number of examples that are annotateddifferently while their usages are the same.
For ex-ample, Figures 1(c), 1(d) and 1(e) all show RB us-140Table 1: Number of MWE types in Wiktionary and Penn TreebankAdverb Conjunction Determiner Preposition Prepositional Phrase PronounWiktionary 1501 49 15 110 165 83PTB 468 35 9 77 66 18Examples after all as wll as a number of according to against the law no oneVPVBheatPRTupNP-ADVDTaNNbit(a) MWE usage as RBADVPNPDTaNNbitPPINofNPNNchromosomeCD13(b) Literal usage as NPADVPNP-ADVDTaRBbitJJRsmaller(c) MWE usage as RBADVPNPDTaNNbitRBRbetter(d) MWE usage as RBADJP-PRDNPDTaRBbitJJRisolated(e) MWE usage as RBFigure 1: Examples of phrase structures annotated to ?a bit?age of ?a bit?
while they are annotated differently 2.Sometimes, the same structure tree is annotated toinstances of different usages (Figures 1(b) and 1(d)).Therefore, for eachMWE candidate, we first clus-ter its occurrences in PTB according to their phrasetree structures.
Some of the clusters clearly indi-cate MWE usages (such as ?NP-ADV?
trees in Fig-ures 1(a) and 1(c)).
In such cases, we regarded all in-stances as MWE usages and annotated them as such.For inconsistent or ambiguous cases (such as ?NP?trees in Figures 1(b), 1(d) and 1(e)), we manuallyclassify each of them into either MWE or literal us-age (some MWEs have multiple MWE usages).
Wefind a number of inconsistent POS annotations onsome internal words of MWEs (e.g.
?bit?
in Fig-ures 1(c) and 1(e) are annotated as RB while theyshould be NN).
We correct such inconsistent cases(correction is only done on internal words of MWEs,selecting the majority POS tags as correct).
The totalnumber of POS tag corrections made on PTB (chap-ter 00-24) was 1084.2The POS tags in the trees are: RB(adverb), IN(preposition),DT(determiner), NN(common noun) ...5 Experiments of POS tagging and MWErecognition5.1 Experiment SettingWe conduct POS tagging experiments on the MWE-annotated PTB, using sections 0-18 for training andsections 22-24 for test as usual.For the experiments, we use four versions of PTBwith the following POS annotations.
(a) Original: PTB with the original POS annota-tion(b) Revised: PTB with correction of inconsistentPOS tags(c) BIO MWE: MWEs are annotated with the BIOschema(d) MWE: MWEs are annotated as single wordsConcerning the MWE annotation in (c) and (d),the total number of MWE tokens in PTB is 12131(9417 in the training chapters, 1396 in the testchapters, and 1319 for the remaining (development)chapters).Each word is annotated with the following in-141Figure 2: Example of lattice containing MWE (?about to/RB?)
(correct path is marked with bold boxes.
)Table 2: Examples of MWE annotations in four versionsVersion Word/POS(a) Original about/RB to/TO(b) Revised about/IN to/TO(c) BIO MWE about/RB-B to/RB-I(d) MWE about to/RBformation: coarse-grained POS tag (CPOS), fine-grained POS tag (FPOS) and surface form.
EachMWE is further annotated with its POS tag, surfaceform, its internal words with their POS tags.Table 2 shows sample annotations of MWE?about to?
in each of the four versions of PTB.
In(a), ?about/RB?
is annotated incorrectly, which iscorrected in (b).
In (c), ?-B?
indicates the beginningtoken of an MWE and ?-I?
indicates an inside posi-tion of an MWE.
In (d), ?about to?
is annotated asan RB (we omit the POS tags for its internal words,which are IN and TO).We use a CRF-based tagger for training and teston all the four PTB versions.
Our CRF can han-dle ?words with spaces?
(e.g.
?about to?
as a singletoken as well as separated tokens) as shown in Fig-ure 2.
This extension is only relevant to the case ofthe (d) MWE version.Table 3 summarizes the set of feature templatesused in the experiments.
In Table 3, ?Head POS?means the POS tag of the beginning token of anMWE.
In the same way, ?Tail POS?
means the POStag of the last token of an MWE.
For example, for?a lot of /DT?, its Head POS is DT and its Tail POSis IN.We evaluate POS tagging accuracy and MWErecognition accuracy.
In POS evaluation, each to-ken receives a tag in the cases of (a), (b) and (c), sothe tagging accuracy is straightforwardly calculated.Table 3: Feature templates used in CRF trainingUnigram featuresSurface formFPOS, Surface formCPOS, Surface formBigram features (left context / right context)Surface form / FPOS, Surface formFPOS, Surface form / Surface formTail POS, Surface form / Head POS, Surface formSurface form / Head POSTail POS / Head POSTail POS / Surface formIn the case of (d), since MWEs are analyzed as sin-gle words, they are expanded into the internal wordswith their POS tags and the evaluated on the tokenbasis.MWE recognition accuracy is evaluated for thecases of (c) and (d).
For the purpose of comparison,we employ a simple baseline as well.
This baselineassigns each occurrence of an MWE its most fre-quent usage in the training part of PTB.
Evaluationof MWE recognition accuracy is shown in precision,recall and F-measure.We use the standard set of features based on uni-gram/bi-gram of words/POS.
For our MWE version,we add the word forms and POS tags of the first andthe last internal words of MWEs as shown in Ta-ble 3.5.2 Experimental ResultsTable 4 shows the results of POS tagging.
A slightimprovement is observed in (b) compared with (a)because some of inconsistent tags are corrected.Further improvement is achieved in (d).
The exper-iment on (c) does not show improvement even over142Figure 3: Example of errors: ?after all /RB?
and ?a /DT bit /JJ.
?Table 4: Per token accuracy (precision)Version Accuracy(a) Original 97.54(b) Revised 97.56(c) BIO MWE 97.32(d) split MWE 97.62Table 5: Recognition performance of MWEsPrecision Recall F-measureBaseline 78.79 80.26 79.51(c) BIO 92.81 90.90 90.18(d) MWE 95.75 97.16 96.45(a).
The reason may attribute to the data sparsenesscaused by the increased size of POS tags.Table 5 shows the results of MWE recognition.Our MWE-aware CRF model (d) shows the best re-sults.
While the BIO model (c) significantly outper-forms the baseline, it gives significantly lower re-sults than our model.We investigated errors in (d) and categorized theminto three types.?
False Positive: System finds an MWE, while itis actually literal.?
False Negative: System misses to identify anMWE.?
Misrecognition: System finds an MWEwrongly (correct answer is another MWE).Table 6 shows number of recognition errors ofMWEs.An example of the False Positive is ?a bit /RB?
inFigure 3, which actually is a literal usage and shouldbe tagged as ?a /DT, bit /NN?.An example of the False Negative is ?in black andwhite /RB?, which is not recognized as an MWE.One reason of this type of errors is low or zero fre-quency of such MWEs in training data.
?after all/RB?
(in Figure 3) is another False Negative exam-ple.Table 6: Recognition error of MWEsError types # of errorsFalse Positives 33False Negatives 19Misrecognition 17One example of Misrecognition errors stems fromambiguous MWEs.
For example, while ?how much?only has MWE usages as RB, there are two RBusages of ?how much?
that have different POStag sequences for the internal words.
Other ex-amples of Misrecognition are due to zero or lowfrequency MWEs, whose substrings also matchesshorter MWEs: ?quite/RB, a few/PRP?
while cor-rect analysis is ?quite a few/RB?, and ?the hell /RB,out of /IN?
while the correct analysis is ?the hell outof /RB?.6 Conclusion and Future workThis paper presented our ongoing project for con-struction of an English MWE dictionary, and its ap-plication to MWE-aware POS tagging.
The exper-imental results show that the MWE-aware taggerachieved better performance on POS tagging andMWE recognition.
Although our current MWE dic-tionary only covers fixed types of functional MWEs,this dictionary and MWE annotation information onPTB will be made publicly available.We plan to handle a wider range of MWEs such asphrasal verbs and other semi-fixed and syntacticallyflexible MWEs, and to develop a POS tagger and asyntactic parser on top of them.ReferencesMatthieu Constant and Anthony Sigogne.
2011.
MWU-Aware Part-of-Speech Tagging with a CRF Model andLexical Resources.
In Proceedings of the Workshop onMultiword Expressions: from Parsing and Generationto the Real World, MWE ?11, pages 49?56.143Matthieu Constant, Anthony Sigogne, and Patrick Wa-trin.
2012.
Discriminative Strategies to Integrate Mul-tiword Expression Recognition and Parsing.
In Pro-ceedings of the 50th Annual Meeting of the Associationfor Computational Linguistics, ACL ?12, pages 204?212.Mark Alan Finlayson and Nidhi Kulkarni.
2011.
De-tecting Multi-Word Expressions improves Word SenseDisambiguation.
In Proceedings of the Workshop onMultiword Expressions: from Parsing and Generationto the Real World, MWE ?11, pages 20?24.Spence Green, Marie-Catherine deMarneffe, John Bauer,and Christopher D Manning.
2011.
Multiword Ex-pression Identification with Tree Substitution Gram-mars: A Parsing tour de force with French.
In Pro-ceedings of the Conference on Empirical Methods inNatural Language Processing, EMNLP ?11, pages725?735.Nicole Gre?goire.
2007.
Design and Implementation ofa Lexicon of Dutch Multiword Expressions.
In Pro-ceedings of the Workshop on a Broader Perspective onMultiword Expressions, MWE ?07, pages 17?24.Ioannis Korkontzelos and Suresh Manandhar.
2010.
CanRecognising Multiword Expressions Improve ShallowParsing?
In Human Language Technologies: The2010 Annual Conference of the North American Chap-ter of the Association for Computational Linguistics,HLT ?10, pages 636?644.Taku Kudo, Kaoru Yamamoto, and Yuji Matsumoto.2004.
Applying conditional random fields to japanesemorphological analysis.
In Proceedings of the Confer-ence on Empirical Methods in Natural Language Pro-cessing, EMNLP ?04, pages 230?237.Eric Laporte and Stavroula Voyatzi.
2008.
An ElectronicDictionary of French Multiword Adverbs.
In Lan-guage Resources and Evaluation Conference.
Work-shop Towards a Shared Task for Multiword Expres-sions, MWE ?08, pages 31?34.Eric Laporte, Takuya Nakamura, and Stavroula Voy-atzi.
2008.
A French Corpus Annotated for Mul-tiword Nouns.
In Proceedings of the Language Re-sources and Evaluation Conference.
Workshop To-wards a Shared Task on Multiword Expressions, MWE?08, pages 27?30.Joakim Nivre and Jens Nilsson.
2004.
Multiword Unitsin Syntactic Parsing.
In Workshop on Methodologiesand Evaluation of Multiword Units in Real-World Ap-plications, MEMURA ?04, pages 39?46.Ivan A Sag, Timothy Baldwin, Francis Bond, Ann ACopestake, and Dan Flickinger.
2002.
Multiword Ex-pressions: A Pain in the Neck for NLP.
In Proceed-ings of the Third International Conference on Com-putational Linguistics and Intelligent Text Processing,CICLing ?02, pages 1?15.Kosho Shudo, Akira Kurahone, and Toshifumi Tanabe.2011.
A Comprehensive Dictionary of Multiword Ex-pressions.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguistics:Human Language Technologies, HLT ?11, pages 161?170.144
