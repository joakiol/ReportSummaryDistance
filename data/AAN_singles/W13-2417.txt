Proceedings of the 4th Biennial International Workshop on Balto-Slavic Natural Language Processing, pages 119?128,Sofia, Bulgaria, 8-9 August 2013. c?2010 Association for Computational LinguisticsWordnet-Based Cross-Language Identification of Semantic RelationsIvelina Stoyanova Svetla Koeva Svetlozara LesevaDepartment of Computational Linguistics, IBL, BAS, Sofia, Bulgaria{iva,svetla,zarka}@dcl.bas.bgAbstractWe propose a method for cross-languageidentification of semantic relations basedon word similarity measurement and mor-phosemantic relations in WordNet.
Wetransfer these relations to pairs of deriva-tionally unrelated words and train a modelfor automatic classification of new in-stances of (morpho)semantic relations incontext based on the existing ones andthe general semantic classes of collocatedverb and noun senses.
Our experimentsare based on Bulgarian-English paralleland comparable texts but the method is toa great extent language-independent andparticularly suited to less-resourced lan-guages, since it does not need parsed or se-mantically annotated data.
The applicationof the method leads to an increase in thenumber of discovered semantic relationsby 58.35% and performs relatively consis-tently, with a small decrease in precisionbetween the baseline (based on morphose-mantic relations identified in wordnet) ?0.774, and the extended method (based onthe data obtained through machine learn-ing) ?
0.721.1 IntroductionNatural language semantics has begun to receivedue attention as many areas of natural languageprocessing have recognized the need for address-ing both the syntactic structure and the semanticrepresentation of sentence constituents.
Modellingconceptual and syntactic relationships such as se-mantic roles, semantic and syntactic frames, orsemantic and syntactic dependencies is known assemantic role labeling ?
SRL (Gildea and Juraf-sky, 2002), (shallow) semantic parsing (Pradhan etal., 2004), semantic role tagging (Xue and Palmer,2004), extraction of predicate-argument structures(Moschitti and Bejan, 2004), automatic extractionof semantic relations (Swier and Stevenson, 2005),among others.We propose a method for automatic semanticlabeling based on the morphosemantic relationsin Princeton WordNet (PWN).
A morphoseman-tic relation associates a verb synset Sv and a nounsynset Sn if there is a derivational relation betweena literal Lv in Sv and a literal Ln in Sn.
Mor-phosemantic relations inherit the semantics of thederivation.
Consider, for instance, the morphose-mantic relations agent, instrument, location, andvehicle, which link a verb to its agent (adminis-trate ?
administrator), instrument (collide ?
col-lider), location (settle ?
settlement), vehicle (bomb?
bomber).We apply word and clause similarity measure-ment to parallel and comparable texts in order toperform partial word sense disambiguation and toidentify candidates for labeling with semantic in-formation.
We enhance the WordNet morphose-mantic relations with semantic generalizations de-rived from the general semantic word classes ofthe synsets and use this knowledge to learn andassign different types of semantic information:?
semantic relations associated with the noun col-locates of a particular verb sense;?
general semantic noun classes that are eligibleto collocate with a particular verb sense.We apply this method to English and Bulgarianusing PWN and the Bulgarian WordNet (BulNet).An advantage of the proposed approach is that it isable to assign semantic labels to unstructured text.The paper is organised as follows.
We out-line the background against which we approachthe identification of semantic relations in Section2 where we present in brief groundbreaking andinfluential recent work in semantic role labeling(SRL).
In Section 3 we discuss the linguistic mo-tivation for the proposed approach.
In Section 4119we describe the method for wordnet-based iden-tification of semantic information and its imple-mentation.
Section 5 presents assessment of theresults, followed by conclusions and an outline ofdirections for future research in Section 6.2 Related WorkMany applications treat the assignment of seman-tic roles, semantic frames, and dependencies asa classification problem that involves the trainingof models on (large) manually annotated corpora,such as FrameNet text annotation (Ruppenhofer etal., 2010), the Prague Dependency Treebank (Ha-jic, 1998), or PropBank (Palmer et al 2005), andthe subsequent assignment of semantic labels toappropriate sentence constituents.A number of models have been developed us-ing the FrameNet corpus.
Undoubtedly the mostinfluential one has been Gildea and Jurafsky?smachine learning method (Gildea and Jurafsky,2002), which is based on the training of a SRLclassifier on a set of lexical, morpho-syntactic,syntactic and word order features extracted fromthe parsed FrameNet corpus in conjunction withknowledge of the predicates, prior probabilities ofvarious combinations of semantic roles, etc.PropBank spurred a lot of research in SRL(Pradhan et al 2004; Pradhan et al 2008;Toutanova et al 2008; Surdeanu et al 2003; Xueand Palmer, 2004), to mention but a few.
For in-stance, Pradhan et al(2004) and Pradhan et al(2008) propose SRL algorithms that augment pre-viously developed systems, such as Gildea and Ju-rafsky?s (2002) by replacing earlier classifiers withSVMs.
Xue and Palmer (2004) train a MaximumEntropy classifier on the PropBank using linguis-tic features that can be directly extracted from syn-tactic parse trees and achieve results comparable tothe best performing system at the time (Pradhan etal., 2004).Semantic role labeling based on (large) anno-tated corpora need to deal with a number of issues,such as the situation specificity of semantic roles,the manual selection of annotated examples, vari-ability in the sets of roles used across the compu-tational resources, among others (Marquez et al2008).
Pradhan et al(2008) have also shown thatthe transfer of such models to other domains leadsto substantial degradation in the results.Some researchers employ other resources as analternative.
Swier and Stevenson (2005) describean unsupervised SRL system that combines infor-mation from a verb lexicon ?
VerbNet with a sim-ple probability model.
Shi and Mihalcea (2005)propose the integration of VerbNet, WordNet andFrameNet into a knowledge base and use it in thebuilding of a semantic parser.
The system iden-tifies the FrameNet frame best corresponding toa parsed sentence either as a direct match, or viaVerbNet and/or WordNet relations.Despite these alternatives the dominant trendhas remained the corpus-based SRL, with un-supervised approaches gaining popularity as away of overcoming the deficiencies of supervisedmethods (Lang and Lapata, 2011a; Lang and Lap-ata, 2011b), among others.
Syntactic analysis hasbeen considered a prerequisite in SRL, with fullparsing winning over partial parsing, as demon-strated by the results in the CoNLL-2004 (Carrerasand Marquez, 2004) and the CoNLL-2005 (Car-reras and Marquez, 2005) shared tasks.
Syntac-tic analysis and SRL have been dealt with withintwo general frameworks.
In the ?pipeline?
ap-proach the systems first perform syntactic pars-ing followed by SRL, while In the joint parsingapproach syntactic and semantic parsing are per-formed together.
Joint parsing of syntactic andsemantic dependencies has been the focus of theCoNLL-2008 (Surdeanu et al 2008) and CoNLL-2009 (Hajic?
et al 2009) shared tasks.To sum up, a classical SRL system takes aparsed input and assigns semantic roles on thebasis of: i) a language model learnt from a pre-annotated semantically labeled corpus; ii) a framelexicon; or iii) a combination of different re-sources.
In the systems using annotated corporathe syntactically parsed sentences are usually se-mantically annotated using classifiers trained onthe corpus on the basis of linguistic features de-rived from the parses.
In the case of lexicon-basedsystems semantic roles are directly or indirectlyassigned from the lexicon.3 MotivationMorphosemantic relations in WordNet denote re-lations between (synset members) that are similarin meaning and where one word is derived fromthe other by means of a morphological affix (Fell-baum et al 2009).
The authors also note that mostof the morphosemantic relations connect wordsfrom different classes and go on to demonstratethat part of the noun-verb relations correspond to120semantic roles.
In fact, many of the noun-verbmorphosemantic links in WordNet designate typi-cal relations between a participant and a predicate,such as agent, instrument, material, location, un-dergoer, destination, etc.For instance the verb literal send (cause to bedirected or transmitted to another place) is re-lated to the noun sender (someone who transmitsa message) through the morphosemantic relationagent and to the noun sendee (the intended recip-ient of a message) through destination; train (ed-ucate for a future role or function) is connected totrainer (one who trains other persons or animals)through agent and to trainee (someone who is be-ing trained) through undergoer.
The noun mem-bers of these morphosemantic relations can func-tion as arguments of the particular verbs and bearthe respective semantic roles, i.e.
agent for senderand trainer, destination for sendee, and undergoerfor trainee.Further, we assume that if a noun and a verbenter into the same morphosemantic relation in-dividually, they are licensed for it and therefore,when they collocate, they enter into this relationif there is no other appropriate noun candidate forthe same relation.
As an example, consider thesentence: The author used the method of cost-effectiveness analysis.
The verb use is linked touser through the morphosemantic relation agent.The noun author is connected with the verb author(be the author of) by means of the same relation.By virtue of the above assumption we assign therelation agent between use and author in this par-ticular sentence.
In such a way the morphoseman-tic relation identified between the derivationallyrelated verb and noun may be inherited by syn-onyms, direct hypernyms, hyponyms, sister terms,etc.
Thus, given a morphosemantic relation andwords in the context that participate in such a re-lation independently of each other, we are able todiscover certain types of semantic relations.4 Method for Cross-Language Learningof Semantic RelationsThe goal of the study is to identify semantic rela-tions between a verb and collocated nouns1 withinsimilar clauses in Bulgarian and English (oftenbut not necessarily translational equivalents) andto assign a semantic matrix to the verb based on1Collocated here means that nouns are found within thesame clause as the verb.Bulgarian EnglishAdministrativePolitics 28,148 27,609Economy 25,800 28,436Health 26,912 30,721Ecology 27,886 36,227NewsPolitics 25,016 25,010Economy 25,010 25,127Culture 25,319 25,355Military 25,283 25,328FictionAdventure 25,053 29,241Humour 30,003 26,992Love 32,631 25,459Fantasy 30,200 32,393TOTAL 327,261 337,898Table 1: Distribution of texts (in terms of num-ber of words) in the Bulgarian-English compara-ble corpus applied in the studycollocational evidence and the WordNet hierarchy.The method is developed and tested on aBulgarian-English comparable corpus (Table 1)which is an excerpt from the Bulgarian NationalCorpus (Koeva et al 2012).4.1 WordNet Enhancement withMorphosemantic RelationsThe interest in morphosemantic relations has beenmotivated by the fact that they overlap to a greatextent across wordnets (Bilgin et al 2004) andthus improve the internal connectivity of the in-dividual wordnets, as well as by the fact that thederivational subnets reflect certain cognitive struc-tures in natural languages (Pala and Hlavackova,2007).
n approach to wordnet development basedon enrichment with morphosemantic relations hasbeen adopted for English (Fellbaum et al 2009),as well as for a number of other languages ?
Turk-ish (Bilgin et al 2004), Czech (Pala and Hlavack-ova, 2007), Bulgarian (Koeva et al 2008), Serbian(Koeva, 2008), Polish (Piasecki et al 2009), Ro-manian (Barbu Mititelu, 2012), to mention a few.Provided there is a mapping algorithm betweentwo or more wordnets, such as the cross-languagerelation of equivalence between synsets (Vossen,2004), a morphosemantic relation between a pairof synsets in a given language can be mappedto the corresponding synsets in a different lan-121guage, even if the latter language does not exhibita derivational relation between members of theseparticular synsets.We automatically expand BulNet with mor-phosemantic relations in the following two ways:(1) Morphosemantic relations are mapped fromthe morphosemantic database distributed with thePWN2 to the corresponding Bulgarian synsets.The morphosemantic relations currently encodedin Princeton WordNet 3.0.3 have relatively limitedcoverage ?
14,876 verb-noun synset pairs, whichinvolve 7,960 verb synsets and 9,704 noun synsets.The automatic transfer of morphosemantic links toBulNet resulted in the association of 5,002 verb-noun pairs involving 3,584 verb synsets and 4,938noun synsets.For example, the PWN synset hammer:2 (beatwith or as if with a hammer) is related to the nounsynset hammer:4 (a hand tool with a heavy rigidhead and a handle; used to deliver an impulsiveforce by striking) through the morphosemantic re-lation instrument.
We map this relation to thecorresponding pair in BulNet ?
the verb synsetchukam:1; kova:1 and the noun synset chuk:1.
Inthe particular case a derivational relation exists inBulgarian, as well, between chuk and chukam.
(2) In general, the task of detection and clas-sification of the identified relations includes au-tomatic generation of derivational pairs based onknowledge of language-specific derivational pat-terns followed by filtering of the results throughautomatic and/or manual validation.
Specificmethods are described in more detail in the re-search cited at the beginning of this subsection, aswell as in more recent proposals, such as the ma-chine learning approach to generation and classifi-cation of derivational pairs made by Piasecki et al(2012b) and Piasecki et al(2012a), respectively.We identify new pairs of verb-noun literals inBulNet that are potentially derivationally (and thusmorphosemantically) related by means of a set ofrules that describe the verb-noun and noun-verbderivational patterns in Bulgarian (we focus onpatterns affecting the end of the word, thus ig-noring prefixation) and assign the respective mor-phosemantic relations to the synsets that includethe related pairs.2http://wordnetcode.princeton.edu/standoff-files/morphosemantic-links.xls3http://wordnet.princeton.edu/wordnet/download/standoff/We identified 89 derivational noun endings(morphophonemic variants of suffixes) and 183derivational patterns (verb ending to noun endingcorrespondences), and associated them with themorphosemantic relation they indicate.
Only 39of the selected derivational endings were found tobe unambiguous.
Moreover, many of them provedto be highly ambiguous, denoting up to 10 of the14 morphosemantic relations.
In order to disam-biguate at least partially the possible morphose-mantic relations associated with a particular suf-fix, we filtered those meanings with the generalsemantic classes derived from the PWN lexicog-rapher files.
The PWN synsets are organized in45 lexicographer files based on syntactic categoryand general semantic word classes (26 for nounsand 15 for verbs)4.For instance, the Bulgarian noun suffix -nik is associated with the following relationsagent, instrument, location, undergoer, and event.By virtue of the fact that the synsets denot-ing locations are found in the lexicographer filenoun.location, the synset denoting agents?
in noun.person, and the instruments ?
innoun.artifact, we were able to disambiguatethe suffix at least partially.Initially, 57,211 new derivational relations werefound in BulNet.
These relations were eval-uated automatically on the basis of the mor-phosemantic relations transferred from PWN.Each triple <verb.label, noun.label,relation>5 was assigned a probability basedon the frequency of occurrence in the set ofmorphosemantic relations transferred from PWN.Those relations with a probability below 1% werefiltered out.
As a result 34,677 morphosemanticrelations between a noun literal and a verb lit-eral were assigned among 7,456 unique noun-verbsynset pairs, which involved 2,537 verb synsetsand 1,708 noun synsets.For example the noun synset kovach:1 (corre-sponding to blacksmith:1) is derivationally relatedwith the verb literal kova:1 through the suffix -ach,which is associated either with an agent or with aninstrument relation depending on the semantics ofthe noun ?
a person or an inanimate object.
In thiscase the meaning of the suffix is disambiguated4http://wordnet.princeton.edu/wordnet/man/lexnames.5WN.html5The verb.label and noun.label are descriptivelabels of the wordnet synsets which are listed in the respectivelexicographer files.122by virtue of the fact that kovach:1 is found in thenoun.person lexicographer file.
We link theliterals kova:1 and kovach:1 via a derivational re-lation suffix and assign the synsets the morphose-mantic relation agent.4.2 Preprocessing and Clause SplittingThe preprocessing of the Bulgarian-English cor-pus used in the study includes sentence-splitting,tokenization, POS-tagging and lemmatization, us-ing the Bulgarian Language Processing Chain6(Koeva and Genov, 2011) for the Bulgarian partand Stanford CoreNLP7 for the English part.The clause serves as the minimal context forthe realization of verb semantics, and hence ?the scope within which we carry out the cross-linguistic analysis and the assignment of relations.Clause splitting is applied using a general methodbased on POS tagging, lists of clause delimiters(clause linking words, multiword expressions, andpunctuation) and a set of language-specific rules.We define the clause as a sequence of words be-tween two potential clause delimiters where ex-actly one predicate (a simple or a complex verbform, which may be a lexical verb, an auxiliary,a copula, or a combination of a lexical verb ora copula with one or more auxiliaries) occurs.We identify the predicates in each sentence us-ing language-specific rules for Bulgarian and En-glish.
Each clause is labeled by a clause openingand a clause end.
The clause splitting algorithmmarks subordinating and coordinating clause link-ing words and phrases and punctuation clause de-limiters.
If no clause boundary has been identifiedbetween two predicates, a clause boundary is in-serted before the second one.
The nested clausesare detected, as well.4.3 Word-to-Word and Text-to-TextSemantic SimilarityWordNet has inspired the elaboration of metricsfor word similarity and relatedness that quantifythe degree to which words (concepts) are relatedusing properties of the WordNet structure.
Theso-called path-length based measures rely on thelength of the path between two nodes (synsets),possibly normalized.
For instance, the Leacock-Chodorow metric (Leacock and Chodorow, 1998)finds the shortest path between two concepts and6http://dcl.bas.bg/services/7http://nlp.stanford.edu/software/corenlp.shtmlscales the path length by the overall depth D of theWordNet taxonomy, while Wu-Palmer (Wu andPalmer, 1994) calculates the depth of the conceptsand their least common subsumer in the WordNettaxonomy.Information content based metrics augment thepath information with corpus statistics.
Resnik(1995) measures the similarity of two concepts bycalculating the information content (IC) of theirleast common subsumer (LCS).
Jiang-Conrath(Jiang and Conrath, 1997) and Lin (Lin, 1998)combine the information content of the LCS withthe information content of the individual concepts.Several relatedness metrics have also been pro-posed, such as Hirst-St-Onge (Hirst and St-Onge,1998), which measures semantic relatedness basedon the path length and its nature (the changes of di-rection in the path), and the algorithms proposedby Banerjee and Pederson (2002) and Patwardhanet al(2003), which rely on information obtainedfrom the synsets glosses.A number of researchers have addressed WSDbased on cross-lingual semantic similarity mea-surement, such as the application of monolingualWSD graph-based algorithms to multilingual co-occurrence graphs based on WordNet (Silbererand Ponzetto, 2010), or of multilingual WSD al-gorithms based on multilingual knowledge fromBabelNet (Navigli and Ponzetto, 2012).For the purposes of the extraction of seman-tic relations we are interested in correspondingpairs of clauses in Bulgarian and English satisfy-ing the following conditions: (a) the verbs in theclauses are similar (with respect to a certain simi-larity measure and threshold); and (b) the clausesare similar in meaning (with respect to a certainsimilarity measure and threshold).
Similar pairsof verbs and nouns are identified on the basis ofthe Wu-Palmer word-to-word similarity measure(Wu and Palmer, 1994).
Clause similarity is com-puted by means of the text similarity measurementproposed by Mihalcea et al(2006).Measuring semantic similarity cross-linguistically enables us to filter some of thesenses of a particular word in one language sincepotential semantic similarity of words withinsimilar clauses strongly suggests that these wordsare semantically related ?
translation equivalents,close synonyms, hypernyms, or hyponyms.In the application of the method described inSection 4.4, we assign semantic relations to the el-123ements of similar clauses in a comparable, not nec-essarily parallel, Bulgarian-English corpus.
More-over, we identify semantically similar rather thanparallel clauses, which enables us to experimentwith a greater number and diversity of contexts forthe identification of semantic relations.4.4 Method outlineWe select corresponding (comparable) pairs oftexts from the corpus ?
T1 in Bulgarian and T2 inEnglish on the basis of their detailed metadata de-scription (Koeva et al 2012), including parame-ters such as style, domain and genre.
For each pairof corresponding texts T1 and T2 we apply the fol-lowing algorithm:Step 1.
We identify semantically similar pairsof verbs and consider similarity between their re-spective clauses ?
v1 ?
cl1 and v2 ?
cl2, wherecl1 ?
T1 and cl2 ?
T2 and cl1 are also seman-tically similar (cf.
Section 4.3 for word-to-wordand clause-to-clause similarity).Step 2.
We identify semantically similar pairsof collocated nouns in the bi-clause (cl1, cl2) inthe same way as for verbs.Step 3.
We assign morphosemantic relationsto the verb and its collocated nouns using the en-hanced set of relations (cf.
Section 4.1) and mapall matching candidates (v1, n1, rel) in cl1(v1)and (v2, n2, rel) in cl(v2).Step 4.
Since co-occurrence of members of asingle instance of a morphosemantic relation arerelatively rare, we transfer the morphosemantic re-lations to non-derivationally related words, pro-vided a noun and a verb participate in the sametype of morphosemantic relation independently ofeach other.
In Example 1 the noun director en-ters into a morphosemantic relation (agent) withthe verb direct, while the verb send enters inde-pendently into the same type of relation with thenoun sender.
Since both director and send are li-censed for agent, we assign the relation.Example 1.Croatian director Zrinko Ogresta sent an invita-tion for the international film festival.send, 01437254-v, verb.contact{to cause or order to be taken directed or transmit-ted to another place}director, 10015215-n, noun.personVERB send: agent, NOUN director: agent invStep 5.
We hierarchize the candidates for aparticular morphosemantic relation and select themost probable one based on the general semanticword classes (verb.label and noun.label)and the relations they participate in.
Where two ormore morphosemantic relations are assigned be-tween a pair of words, priority is given to the re-lation which is most compatible with the generalsemantic class of the noun in the relation.Some relations, such as event, are very generaland therefore are not considered even if their prob-ability is higher, provided a more meaningful rela-tion is available.
Moreover, we incorporate somesyntactic and word-order dependencies.
For in-stance, a noun which is a complement of a prepo-sitional phrase and is thus found in the followingconfigurations: p(A)N (with any number of ad-jectives preceding the noun) is not licensed for themorphosemantic relation agent if the verb is ac-tive.Step 6.
Based on the general semantic class ofthe noun and/or the verb, some additional poten-tial relations are added to the respective synsets inthe model (Example 2).
For example, a noun be-longing to the class noun.location can poten-tially enter into a location relation with the verb,although the respective noun synset might not en-ter into this morphosemantic relation.Example 2.
Newly added relationsverb.label rolecontact agentmotion locationnoun.label roleperson agent invlocation location invattribute property invStep 7.
We extend the number of relations bylearning from previous occurrences.
Learning isperformed on the News subcorpus (see Table 1),and further experiments extend the information ac-quired in the learning phase with data from the en-tire corpus.Given a verb is licensed to enter into a particu-lar morphosemantic relation, we assign this rela-tion to a co-occurring verb-noun pair, even if thenoun in this pair does not enter into this type of re-lation, provided other nouns belonging to the samegeneral semantic class have been observed to co-occur with this verb.
This assumption is general-ized over all the members of the verb synset andthe noun synset to which the respective verb andnoun belong.124Example 3 shows how learning is applied:based on the occurrences of verbs from thesame synset (ID: 00974367-v, announce:2; de-clare:2) in a morphosemantic relation of typeagent with nouns belonging to the semantic classnoun.group (in 60.4% of the cases), we asso-ciate the verb announce with the noun Ministry(noun.group) through the agent relation de-spite the fact that Ministry is not linked to any verbthrough a morphosemantic relation.Example 3.Learned:Verb ID relation noun.label freq00974367-v by-means-of noun.artifact 500974367-v by-means-of noun.act 1400974367-v agent noun.person 900974367-v agent noun.group 16The Ministry of Defense announced on Wednesdayits new plans.announce, 00974367-v, verb.communication{make known, make an announcement}Ministry, 08114004-n, noun.groupVERB announce: agentNOUN Ministry: agent invAt a next stage of generalization we consideronly the general semantic classes of a verb and anoun which are candidates to enter in a morphose-mantic relation.
This step relies on the assumptionthat verbs from the same semantic class (e.g.
per-ception verbs) show preference to similar semanticpatterns.
The learned information is in a general-ized form, as presented in Example 4.Example 4.
A sample of semantic compatibil-ity information learned from the News subcorpus.verb.label relation noun.label freqverb.perception undergoer noun.person 15verb.perception undergoer noun.group 3verb.perception state noun.state 12verb.perception by-means-of noun.state 12verb.perception by-means-of noun.act 6verb.perception uses noun.group 3verb.perception agent noun.person 34.5 ImplementationWe implement the word-to-word similarities withthe ws4j package for Java8, which is based on theoriginal Perl package Wordnet::Similarity(Pedersen et al 2007).We use the Princeton WordNet 3.0 and access itthrough Java libraries such as JAWS9 and JWI10.8https://code.google.com/p/ws4j/9http://lyle.smu.edu/?tspell/jaws/10http://projects.csail.mit.edu/jwi/api/We also employ a list of morphosemantic relationsavailable for WordNet 3.0.
The access to BulNetis modeled roughly on PWN.
The correspondingsynsets in the two wordnets are linked by meansof synset IDs.5 Results and EvaluationEvaluation was performed with respect to the cov-erage of the morphosemantic relations, the preci-sion of the assigned relations, and the informa-tiveness of the extracted semantic patterns.
Test-ing was carried out on the News subcorpus (Ta-ble 1) totaling 100,628 tokens distributed in foursubdomains: Politics, Economy, Culture, and Mil-itary.
The corpus comprises 3,362 sentences and7,535 clauses for Bulgarian and 3,678 sentencesand 8,624 clauses for English.Method # clauses # relations1 Baseline 0 920 1, 1832 Baseline 951 1, 2463 Learned andtransferred tosynsets1, 032 1, 3534 Learned andtransferred tosemantic classes1, 395 1, 973Table 2: Coverage of relations in the News subcor-pus using the baseline method (2) and the extendedmethod (4)Table 2 presents: (1) the number of mor-phosemantic relations covered by the baseline 0method, i.e.
applying only the Princeton WordNetmorphosemantic relations; (2) the number of mor-phosemantic relations after adding those specificto Bulgarian; and (3, 4) the number of morphose-mantic relations learnt with the method describedin Step 7 (Section 4.4).
The results show that theextended method leads to an increase in coverageby 58.35% (compare the extended method (4) withthe baseline (2)).To assess the precision of the automatic relationassignment, we performed evaluation on five rela-tions: agent, undergoer, location, result, and state(Table 3).
The overall precision based on theserelations is 0.774 for the baseline and 0.721 forthe extended method, which shows that the per-formance of the method is relatively consistent.We also obtained two types of generalizationsbased on WordNet and confirmed by the corpus125Relation Precision(baseline)Precision(extendedmethod)Agent 0.963 0.950Undergoer 0.575 0.577Location 0.857 0.750Result 0.303 0.316State 0.750 0.667Table 3: Precision of the results for five seman-tic relations ?
baseline (Princeton and Bulgarianmorphosemantic relations) and extended method(transfer of morphosemantic relations to pairs ofnouns and verbs one of which does not participatein morphosemantic relations)data that can be used for further classification.
Thefirst one represents the combinatorial propertiesof general semantic verb classes with particular(morpho)semantic relations.
For example a verbof communication is more likely linked to anagent rather than to a result (Example 5).Example 5.
Frequency of relations in WordNetand the entire corpus.verb.label relation fr wn fr corverb.com agent 744 555verb.com undergoer 306 362verb.com by-means-of 244 560verb.com result 192 283Moreover, the nouns that are eligible to collo-cate as agents with a communication verb belongto a limited set of classes ?
noun.person ornoun.group (Example 6).Example 6.
Frequency of relations in WordNetand the entire corpus.verb.label relation noun label fr wn fr corverb.com agent noun.person 473 333verb.com agent noun.group 271 220The second generalization refers to the prob-ability of the association of a given verb sensewith a particular set of semantic relations and thegeneral noun classes eligible for these relations.For instance, the communication verb order(Example 7) in the sense of give instructionsto or direct somebody to do something withauthority connects with the highest probabilitywith an undergoer (noun.person) and anagent (noun.person).Example 7.
Relations of the verb order inWordNet and the entire corpus.verb.label relation noun label fr wn fr corverb.com undergoer noun.person 33 8verb.com agent noun.person 12 6verb.com by-means-of noun.phen 9 76 Conclusions and Future WorkIn this paper we have explored the applicabilityof the morphosemantic relations in WordNet forcross-language identification of semantic and insome cases syntactic dependencies between col-located verbs and nouns.
As morphosemantic re-lations are valid cross-linguistically, the method isapplicable for any language or a pair of languages.The limitations of the proposed method lie inthe insufficient connectivity of the nodes (synsetsand literals).
We have described an approach toautomatic wordnet enhancement, which has re-sulted in a substantial increase in the numberof morphosemantic relations.
Another inherentweakness is that some of the relations are verygeneral or vaguely defined.
We have addressedthis problem by considering relations jointly withthe general semantic classes associated with thesynsets in WordNet.The method has the advantage of using lim-ited linguistic annotation.
It does not require textalignment, syntactic parsing or word-sense disam-biguation.
The cross-linguistic similarity partiallydisambiguates the target words, so that the sensesfor which the clauses are not similar are discarded;the semantic restrictions imposed by the generalsemantic classes and their compatibility also con-tribute to semantic disambiguation.
The methodis thus to a large extent language-independent andwell suited to less-resourced languages.In order to improve the performance and over-come the limitations of the method, we plan toexplore deeper into the possibilities of predictingthe roles of the verb participants from their gen-eral semantic class and the semantic compatibilityof verb and noun classes, as well as from the com-patibility of the different types of morphosemanticrelations with the general semantic classes.Another line of research to pursue in the futureis the application of the proposed method and itssubtasks to other NLP tasks, such as clause split-ting, alignment based on wordnet relations, ex-traction of patterns from comparable corpora, andaugmentation and enhancement of training datafor MT.126ReferencesSatanjeev Banerjee and Ted Pedersen.
2002.
Anadapted lesk algorithm for word sense disambigua-tion using wordnet.
Lecture Notes In Computer Sci-ence, 2276:136?145.Verginica Barbu Mititelu.
2012.
Adding Morpho-Semantic Relations to the Romanian Wordnet.
InProceedings of the Eight International Conferenceon Language Resources and Evaluation (LREC?12),pages 2596?2601.Orhan Bilgin, O?zlem Cetinoug?lu, , and Kemal Oflazer.2004.
Morphosemantic Relations In and AcrossWordnets ?
A Study Based on Turkish.
In P. So-jka, K. Pala, P. Smrz, C. Fellbaum, and P. Vossen,editors, Proceedings of the Global Wordnet Confer-ence, pages 60?66.Xavier Carreras and Lluis Marquez.
2004.
Intro-duction to the CoNLL-2004 Shared Task: SemanticRole Labeling.
In Proceedings of CoNLL-2004.Xavier Carreras and Lluis Marquez.
2005.
Intro-duction to the CoNLL-2005 Shared Task: SemanticRole Labeling.
In Proceedings of CoNLL-2005.Christine Fellbaum, Anne Osherson, and Peter E.Clark.
2009.
Putting Semantics into Word-Net?s ?Morphosemantic?
Links.
In Z. Vetulani andH.
Uszkoreit, editors, Proceedings of the Third Lan-guage and Technology Conference, Poznan, Poland.Reprinted in: Responding to Information SocietyChallenges: New Advances in Human LanguageTechnologies, volume 5603 of Springer LectureNotes in Informatics, pages 350?358.Daniel Gildea and Daniel Jurafsky.
2002.
Automaticlabeling of semantic roles.
Computational Linguis-tics, 28(3):245?288, September.Jan Hajic.
1998.
Building a syntactically annotatedcorpus: The prague dependency treebank.
Issues ofValency and Meaning, pages 106?132.Jan Hajic?, Massimiliano Ciaramita, Richard Johans-son, Daisuke Kawahara, Maria Antnia Mart?
?, Llu?
?sMa?rquez, Adam Meyers, Joakim Nivre, SebastianPado?, Jan S?te?pa?nek, Pavel Stran?a?k, Mihai Surdeanu,Nianwen Xue, and Yi Zhang.
2009.
The CoNLL-2009 Shared Task: Syntactic and Semantic Depen-dencies in Multiple Languages.
In Proceedings ofthe Thirteenth Conference on Computational Nat-ural Language Learning (CoNLL 2009): SharedTask, pages 1?18.Graeme Hirst and David St-Onge.
1998.
Lexicalchains as representations of context for the detec-tion and correction of malapropisms.
In ChristianeFellbaum, editor, WordNet: An electronic lexicaldatabase, page 305332.
MIT Press.Jay J. Jiang and David W. Conrath.
1997.
Seman-tic similarity based on corpus statistics and lexicaltaxonomy.
In Proceedings on International Con-ference on Research in Computational Linguistics,page 1933.S.
Koeva and A. Genov.
2011.
Bulgarian languageprocessing chain.
In Proceedings of Integration ofmultilingual resources and tools in Web applica-tions.
Workshop in conjunction with GSCL 2011,University of Hamburg.Svetla Koeva, Cvetana Krstev, and Dusko Vitas.
2008.Morpho-semantic relations in wordnet - a case studyfor two slavic langages.
In Proceedings of theFourth Global WordNet Conference, pages 239?254.Svetla Koeva, Ivelina Stoyanova, Svetlozara Leseva,Tsvetana Dimitrova, Rositsa Dekova, and EkaterinaTarpomanova.
2012.
The Bulgarian National Cor-pus: Theory and Practice in Corpus Design.
Journalof Language Modelling, 0(1):65?110.Svetla Koeva.
2008.
Derivational and morphosemanticrelations in bulgarian wordnet.
Intelligent Informa-tion Systems, XVI:359?369.Joel Lang and Mirella Lapata.
2011a.
UnsupervisedSemantic Role Induction via Split-Merge Cluster-ing.
In Proceedings of ACL 2011, pages 1117?1126.Joel Lang and Mirella Lapata.
2011b.
UnsupervisedSemantic Role Induction with Graph Partitioning.In Proceedings of EMNLP 2011, pages 1320?1331.Claudia Leacock and Michael Chodorow.
1998.
Com-bining local context and WordNet similarity forword sense identification.
In C. Fellbaum, edi-tor, WordNet: An electronic lexical database, pages265?283.
MIT Press.Dekang Lin.
1998.
An information-theoretic defini-tion of similarity.
In Proceedings of the Interna-tional Conference on Machine Learning.Lluis Marquez, Xavier Carreras, Kenneth C.Litkowski, and Suzanne Stevenson.
2008.
Se-mantic role labeling: An introduction to the specialissue.
Computational Linguistics, 34(2):145?159.Rada Mihalcea, Courtney Corley, and Carlo Strappa-rava.
2006.
Corpus-based and Knowledge-basedMeasures of Text Semantic Similarity.
In Proceed-ings of the American Association for Artificial Intel-ligence (AAAI 2006), Boston.Alessandro Moschitti and Cosmin Adrian Bejan.
2004.A semantic kernel for predicate argument classica-tion.
In In Proceedings of CONLL 2004, pages 17?24.Roberto Navigli and Simone Paolo Ponzetto.
2012.Joining Forces Pays Off: Multilingual Joint WordSense Disambiguation.
In Proceedings of the 2012Joint Conference on Empirical Methods in Natu-ral Language Processing and Computational Natu-ral Language Learning, Jeju Island, Korea, pages1399?1410.127K.
Pala and D. Hlavackova.
2007.
Derivational rela-tions in Czech Wordnet.
In Proceedings of the Work-shop on Balto-Slavonic Natural Language Process-ing, pages 75?81.Martha Palmer, Paul Kingsbury, and Daniel Gildea.2005.
The proposition bank: An annotated cor-pus of semantic roles.
Computational Linguistics,31(1):71?106.Siddharth Patwardhan, Satanjeev Banerjee, and TedPedersen.
2003.
Using measures of semantic re-latedness for word sense disambiguation.
In Pro-ceedings of the Fourth International Conference onIntelligent Text Processing and Computational Lin-guistics, pages 241?257.Ted Pedersen, Serguei Pakhomov, Siddharth Patward-han, and Christopher G. Chute.
2007.
Measures ofsemantic similarity and relatedness in the biomed-ical domain.
Journal of Biomedical Informatics,40(3):288?299.Maciej Piasecki, Stanisaw Szpakowicz, and BartoszBroda.
2009.
A wordnet from the ground up.
InWroclaw: Oficyna Wydawnicza Politechniki Wro-clawskiej.Maciej Piasecki, Radoslaw Ramocki, and PawelMinda.
2012a.
Corpus-based semantic filtering indiscovering derivational relations.
In AIMSA, pages14?22.Maciej Piasecki, Radosaw Ramocki, and MarekMaziarz.
2012b.
Automated Generation of Deriva-tive Relations in the Wordnet Expansion Perspec-tive.
In Proceedings of the 6th Global Wordnet Con-ference, Matsue, Japan, January.Sameer Pradhan, Wayne Ward, Kadri Hacioglu, JamesMartin, and Daniel Jurafsky.
2004.
Shallow Seman-tic Parsing Using Support Vector Machines.
In Pro-ceedings of NAACL-HLT 2004.Sameer Pradhan, Wayne Ward, and James Martin.2008.
Towards Robust Semantic Role Labeling.Computational Linguistics, (34):289?310.Philip Resnik.
1995.
Using information content toevaluate semantic similarity in a taxonomy.
In Pro-ceedings of the 14th International Joint Conferenceon Artificial Intelligence, pages 448?453.Josef Ruppenhofer, Michael Ellsworth, Miriam R. L.Petruck, Christopher R. Johnson, and Jan Scheczyk.2010.
Framenet ii: Extended theory and practice.Web Publication.
http://framenet.icsi.berkeley.edu.Lei Shi and Rada Mihalcea.
2005.
Putting Pieces To-gether: Combining FrameNet, VerbNet and Word-Net for Robust Semantic Parsing.
In A. Gelbukh,editor, CICLing 2005, LNCS 3406, page 100111.Carina Silberer and Simone Paolo Ponzetto.
2010.UHD: Cross-lingual Word Sense Disambiguationusing multilingual co-occurrence graphs.
In Pro-ceedings of the 5th International Workshop on Se-mantic Evaluations (SemEval-2010), pages 134?137.Mihai Surdeanu, Sanda Harabagiu, John Williams, andPaul Aarseth.
2003.
Using predicate-argumentstructures for information extraction.
In Proceed-ings of ACL-2003, pages 8?15.Mihai Surdeanu, Richard Johansson, Adam Meyers,Llu?
?s Ma?rquez, and Joakim Nivre.
2008.
TheCoNLL-2008 Shared Task on Joint Parsing of Syn-tactic and Semantic Dependencies.
In CoNLL 2008:Proceedings of the Twelfth Conference on NaturalLanguage Learning, pages 159?177.Robert Swier and Suzanne Stevenson.
2005.
Exploit-ing a Verb Lexicon in Automatic Semantic RoleLabelling.
In In Proceedings of Human LanguageTechnology Conference and Conference on Empiri-cal Methods in Natural Language Processing 2005,pages 883?890.Kristina Toutanova, Aria Haghighi, and ChristopherManning.
2008.
A global joint model for seman-tic role labeling.
Computational Linguistics.Piek Vossen.
2004.
EuroWordNet: A MultilingualDatabase of Autonomous and Language-SpecificWordnets Connected via an Inter-Lingual Index.International Journal of Lexicography, 17(1):161?173, June.Zhibiao Wu and Martha Palmer.
1994.
Verb seman-tics and lexical selection.
In Proceedings of the32nd Annual Meeting of the Association for Com-putational Linguistics, pages 133?138.Nianwen Xue and Martha Palmer.
2004.
Calibratingfeatures for semantic role labeling.
In Dekang Linand Dekai Wu, editors, Proceedings of EMNLP04,Barcelona, Spain, July.128
