Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 192?202,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsJointly Embedding Knowledge Graphs and Logical RulesShu Guo?
?, Quan Wang??
?, Lihong Wang?, Bin Wang?
?, Li Guo??
?Institute of Information Engineering, Chinese Academy of Sciences, Beijing 100093, China?University of Chinese Academy of Sciences, Beijing 100049, China{guoshu,wangquan,wangbin,guoli}@iie.ac.cn?National Computer Network Emergency Response Technical TeamCoordination Center of China, Beijing 100029, Chinawlh@isc.org.cnAbstractEmbedding knowledge graphs into continuousvector spaces has recently attracted increasinginterest.
Most existing methods perform theembedding task using only fact triples.
Logi-cal rules, although containing rich backgroundinformation, have not been well studied in thistask.
This paper proposes a novel method ofjointly embedding knowledge graphs and log-ical rules.
The key idea is to represent andmodel triples and rules in a unified framework.Specifically, triples are represented as atomicformulae and modeled by the translation as-sumption, while rules represented as complexformulae and modeled by t-norm fuzzy logic-s. Embedding then amounts to minimizing aglobal loss over both atomic and complex for-mulae.
In this manner, we learn embeddingscompatible not only with triples but also withrules, which will certainly be more predictivefor knowledge acquisition and inference.
Weevaluate our method with link prediction andtriple classification tasks.
Experimental re-sults show that joint embedding brings signif-icant and consistent improvements over state-of-the-art methods.
Particularly, it enhancesthe prediction of new facts which cannot evenbe directly inferred by pure logical inference,demonstrating the capability of our method tolearn more predictive embeddings.1 IntroductionKnowledge graphs (KGs) provide rich structured in-formation and have become extremely useful re-sources for many NLP related applications like?Corresponding author: Quan Wang.word sense disambiguation (Wasserman-Pritsker etal., 2015) and information extraction (Hoffmann etal., 2011).
A typical KG represents knowledge asmulti-relational data, stored in triples of the for-m (head entity, relation, tail entity), e.g., (Paris,Capital-Of, France).
Although powerful inrepresenting structured data, the symbolic nature ofsuch triples makes KGs, especially large-scale KGs,hard to manipulate.Recently, a promising approach, namely knowl-edge graph embedding, has been proposed and suc-cessfully applied to various KGs (Nickel et al, 2012;Socher et al, 2013; Bordes et al, 2014).
The keyidea is to embed components of a KG including en-tities and relations into a continuous vector space,so as to simplify the manipulation while preservingthe inherent structure of the KG.
The embeddingscontain rich semantic information about entities andrelations, and can significantly enhance knowledgeacquisition and inference (Weston et al, 2013).Most existing methods perform the embeddingtask based solely on fact triples (Bordes et al, 2013;Wang et al, 2014; Nickel et al, 2016).
The only re-quirement is that the learned embeddings should becompatible with those facts.
While logical rules con-tain rich background information and are extreme-ly useful for knowledge acquisition and inference(Jiang et al, 2012; Pujara et al, 2013), they have notbeen well studied in this task.
Wang et al (2015)and Wei et al (2015) tried to leverage both em-bedding methods and logical rules for KG comple-tion.
In their work, however, rules are modeled sep-arately from embedding methods, serving as post-processing steps, and thus will not help to obtain192		Figure 1: Simple illustration of KALE.better embeddings.
Rockta?schel et al (2015) recent-ly proposed a joint model which injects first-orderlogic into embeddings.
But it focuses on the rela-tion extraction task, and creates vector embeddingsfor entity pairs rather than individual entities.
Sinceentities do not have their own embeddings, relationsbetween unpaired entities cannot be effectively dis-covered (Chang et al, 2014).In this paper we introduce KALE, a new approachthat learns entity and relation Embeddings by joint-ly modeling Knowledge And Logic.
Knowledgetriples are taken as atoms and modeled by the trans-lation assumption, i.e., relations act as translationsbetween head and tail entities (Bordes et al, 2013).A triple (ei, rk, ej) is scored by ?ei + rk ?
ej?1,where ei, rk, and ej are the vector embeddings forentities and relations.
The score is then mapped tothe unit interval [0, 1] to indicate the truth value ofthat triple.
Logical rules are taken as complex for-mulae constructed by combining atoms with logicalconnectives (e.g., ?
and?
), and modeled by t-normfuzzy logics (Ha?jek, 1998).
The truth value of a ruleis a composition of the truth values of the constituen-t atoms, defined by specific logical connectives.
Inthis way, KALE represents triples and rules in a uni-fied framework, as atomic and complex formulae re-spectively.
Figure 1 gives a simple illustration of theframework.
After unifying triples and rules, KALEminimizes a global loss involving both of them toobtain entity and relation embeddings.
The learnedembeddings are therefore compatible not only withtriples but also with rules, which will definitely bemore predictive for knowledge acquisition and in-ference.The main contributions of this paper are summa-rized as follows.
(i) We devise a unified frameworkthat jointly models triples and rules to obtain morepredictive entity and relation embeddings.
The newframework KALE is general enough to handle anytype of rules that can be represented as first-orderlogic formulae.
(ii) We evaluate KALE with linkprediction and triple classification tasks on WordNet(Miller, 1995) and Freebase (Bollacker et al, 2008).Experimental results show significant and consistentimprovements over state-of-the-art methods.
Partic-ularly, joint embedding enhances the prediction ofnew facts which cannot even be directly inferred bypure logical inference, demonstrating the capabilityof KALE to learn more predictive embeddings.2 Related WorkRecent years have seen rapid growth in KG em-bedding methods.
Given a KG, such methods aimto encode its entities and relations into a continu-ous vector space, by using neural network architec-tures (Socher et al, 2013; Bordes et al, 2013; Bor-des et al, 2014), matrix/tensor factorization tech-niques (Nickel et al, 2011; Riedel et al, 2013;Chang et al, 2014), or Bayesian clustering strate-gies (Kemp et al, 2006; Xu et al, 2006; Sutskever etal., 2009).
Among these methods, TransE (Bordes etal., 2013), which models relations as translating op-erations, achieves a good trade-off between predic-tion accuracy and computational efficiency.
Variousextensions like TransH (Wang et al, 2014) and Tran-sR (Lin et al, 2015b) are later proposed to furtherenhance the prediction accuracy of TransE.
Most ex-isting methods perform the embedding task basedsolely on triples contained in a KG.
Some recentwork tries to further incorporate other types of infor-mation available, e.g., relation paths (Neelakantan etal., 2015; Lin et al, 2015a; Luo et al, 2015), relationtype-constraints (Krompa?et al, 2015), entity type-s (Guo et al, 2015), and entity descriptions (Zhonget al, 2015), to learn better embeddings.Logical rules have been widely studied in knowl-edge acquisition and inference, usually on the basisof Markov logic networks (Richardson and Domin-gos, 2006; Bro?cheler et al, 2010; Pujara et al, 2013;Beltagy and Mooney, 2014).
Recently, there hasbeen growing interest in combining logical rules andembedding models.
Wang et al (2015) and Wei etal.
(2015) tried to utilize rules to refine predictions193made by embedding models, via integer linear pro-gramming or Markov logic networks.
In their work,however, rules are modeled separately from embed-ding models, and will not help obtain better embed-dings.
Rockta?schel et al (2015) proposed a jointmodel that injects first-order logic into embeddings.But their work focuses on relation extraction, cre-ating vector embeddings for entity pairs, and hencefails to discover relations between unpaired entities.This paper, in contrast, aims at learning more pre-dictive embeddings by jointly modeling knowledgeand logic.
Since each entity has its own embedding,our approach can successfully make predictions be-tween unpaired entities, providing greater flexibilityfor knowledge acquisition and inference.3 Jointly Embedding Knowledge and LogicWe first describe the formulation of joint embed-ding.
We are given a KG containing a set of triplesK = {(ei, rk, ej)}, with each triple composed of t-wo entities ei, ej ?
E and their relation rk ?
R.Here E is the entity vocabulary and R the relationset.
Besides the triples, we are given a set of logicalrules L, either specified manually or extracted auto-matically.
A logical rule is encoded, for example,in the form of ?x, y : (x, rs, y) ?
(x, rt, y), stat-ing that any two entities linked by relation rs shouldalso be linked by relation rt.
Entities and relationsare associated with vector embeddings, denoted bye, r ?
Rd, representing their latent semantics.
Theproposed method, KALE, aims to learn these em-beddings by jointly modeling knowledge triples Kand logical rules L.3.1 OverviewTo enable joint embedding, a key ingredient ofKALE is to unify triples and rules, in terms of first-order logic (Rockta?schel et al, 2014; Rockta?schel etal., 2015).
A triple (ei, rk, ej) is taken as a groundatom which applies a relation rk to a pair of entitiesei and ej .
Given a logical rule, it is first instantiatedwith concrete entities in the vocabulary E , resultingin a set of ground rules.
For example, a universal-ly quantified rule ?x, y : (x,Capital-Of, y) ?
(x,Located-In, y) might be instantiated with theconcrete entities of Paris and France, giving theground rule (Paris,Capital-Of,France) ?
(Paris,Located-In,France).1 A ground rulecan then be interpreted as a complex formula, con-structed by combining ground atoms with logicalconnectives (e.g.
?
and ?
).Let F denote the set of training formulae, bothatomic (triples) and complex (ground rules).
KALEfurther employs a truth function I : F ?
[0, 1] toassign a soft truth value to each formula, indicatinghow likely a triple holds or to what degree a groundrule is satisfied.
The truth value of a triple is deter-mined by the corresponding entity and relation em-beddings.
The truth value of a ground rule is deter-mined by the truth values of the constituent triples,via specific logical connectives.
In this way, KALEmodels triples and rules in a unified framework.
SeeFigure 1 for an overview.
Finally, KALE minimizesa global loss over the training formulae F to learnentity and relation embeddings compatible with bothtriples and rules.
In what follows, we describe thekey components of KALE, including triple model-ing, rule modeling, and joint learning.3.2 Triple ModelingTo model triples we follow TransE (Bordes et al,2013), as it is simple and efficient while achievingstate-of-the-art predictive performance.
Specifically,given a triple (ei, rk, ej), we model the relation em-bedding rk as a translation between the entity em-beddings ei and ej , i.e., we want ei + rk ?
ej whenthe triple holds.
The intuition here originates fromlinguistic regularities such as France?
Paris =Germany ?
Berlin (Mikolov et al, 2013).
Inrelational data, such analogy holds because of thecertain relation Capital-Of, through which wewill get Paris + Capital-Of = France andBerlin + Capital-Of = Germany.
Then, wescore each triple on the basis of ?ei + rk ?
ej?1,and define its soft truth value asI (ei, rk, ej) = 1?13?d?ei + rk ?
ej?1 , (1)where d is the dimension of the embedding space.It is easy to see that I (ei, rk, ej) ?
[0, 1] with theconstraints ?ei?2 ?
1, ?ej?2 ?
1, and ?rk?2 ?1Our approach actually takes as input rules represented infirst-order logic, i.e., those with quantifiers such as ?.
But itcould be hard to deal with quantifiers, so we use ground rules,i.e., propositional statements during learning.1941.2 I (ei, rk, ej) is expected to be large if the tripleholds, and small otherwise.3.3 Rule ModelingTo model rules we use t-norm fuzzy logics (Ha?jek,1998), which define the truth value of a complex for-mula as a composition of the truth values of its con-stituents, through specific t-norm based logical con-nectives.
We follow Rockta?schel et al (2015) anduse the product t-norm.
The compositions associat-ed with logical conjunction (?
), disjunction (?
), andnegation (?)
are defined as follow:I(f1 ?
f2) = I(f1)?I(f2),I(f1 ?
f2) = I(f1) + I(f2)?
I(f1)?I(f2),I(?f1) = 1?
I(f1),where f1 and f2 are two constituent formulae, eitheratomic or complex.
Given these compositions, thetruth value of any complex formula can be calculat-ed recursively, e.g.,I(?f1 ?
f2) = I(f2)?
I(f1)?I(f2),I(f1 ?
f2) = I(f1)?I(f2)?
I(f1) + 1.This paper considers two types of rules.
The firsttype is ?x, y : (x, rs, y)?
(x, rt, y).
Given a groundrule f , (em, rs, en) ?
(em, rt, en), the truth valueis calculated as:I(f)=I(em, rs, en)?I(em, rt, en)?I(em, rs, en) + 1, (2)where I(?,?,?)
is the truth value of a constituent triple,defined by Eq.
(1).
The second type is ?x, y, z :(x, rs1 , y)?
(y, rs2 , z) ?
(x, rt, z).
Given a groundrule f , (e?, rs1 , em)?
(em, rs2 , en) ?
(e?, rt, en),the truth value is:I(f)=I(e?, rs1 , em)?I(em, rs2 , en)?I(e?, rt, en)?I(e?, rs1 , em)?I(em, rs2 , en) + 1.
(3)The larger the truth values are, the better the groundrules are satisfied.
It is easy to see that besides thesetwo types of rules, the KALE framework is generalenough to handle any rules that can be representedas first-order logic formulae.
The investigation ofother types of rules will be left for future work.2Note that 0 ?
?ei + rk ?
ej?1 ?
?ei?1 + ?rk?1 +?ej?1 ?
3?d, where the last inequality holds because ?x?1 =?i |xi| ?
?d?i x2i =?d ?x?2 for any x ?
Rd, accordingto the Cauchy-Schwarz inequality.3.4 Joint LearningAfter unifying triples and rules as atomic and com-plex formulae, we minimize a global loss over thisgeneral representation to learn entity and relationembeddings.
We first construct a training set F con-taining all positive formulae, including (i) observedtriples, and (ii) ground rules in which at least oneconstituent triple is observed.
Then we minimizea margin-based ranking loss, enforcing positive for-mulae to have larger truth values than negative ones:min{e},{r}?f+?F?f??Nf+[?
?
I(f+) + I(f?
)]+ ,s.t.
?e?2 ?
1,?e ?
E ; ?r?2 ?
1, ?r ?
R. (4)Here f+ ?
F is a positive formula, f?
?
Nf+ anegative one constructed for f+, ?
a margin sepa-rating positive and negative formulae, and [x]+ ,max{0, x}.
If f+ , (ei, rk, ej) is a triple, we con-struct f?
by replacing either ei or ej with a randomentity e ?
E , and calculate its truth value accordingto Eq.
(1).
For example, we might generate a neg-ative instance (Paris,Capital-Of,Germany)for the triple (Paris,Capital-Of,France).
Iff+ , (em, rs, en) ?
(em, rt, en) or (e?, rs1 , em) ?
(em, rs2 , en) ?
(e?, rt, en) is a ground rule, we con-struct f?
by replacing rt in the consequent with arandom relation r ?
R, and calculate its truth valueaccording to Eq.
(2) or Eq.
(3).
For example, given aground rule (Paris,Capital-Of,France) ?
(Paris,Located-In,France), a possible neg-ative instance (Paris,Capital-Of,France)?
(Paris,Has-Spouse,France) could be gener-ated.
We believe that most instances (both triplesand ground rules) generated in this way are trulynegative.
Stochastic gradient descent in mini-batchmode is used to carry out the minimization.
To satis-fy the ?2-constraints, e and r are projected to the unit?2-ball before each mini-batch.
Embeddings learnedin this way are required to be compatible with notonly triples but also rules.3.5 DiscussionsComplexity.
We compare KALE with several state-of-the-art embedding methods in space complexityand time complexity (per iteration) during learning.Table 1 shows the results, where d is the dimension195Method Complexity (Space/Time)SE (Bordes et al, 2011) ned+2nrd2 O(ntd2)LFM (Jenatton et al, 2012) ned+nrd2 O(ntd2)TransE (Bordes et al, 2013) ned+nrd O(ntd)TransH (Wang et al, 2014) ned+2nrd O(ntd)TransR (Lin et al, 2015b) ned+nr(d2+d) O(ntd2)KALE (this paper) ned+nrd O(ntd+ngd)Table 1: Complexity of different embedding methods.of the embedding space, and ne/nr/nt/ng is the num-ber of entities/relations/triples/ground rules.
The re-sults indicate that incorporating additional rules willnot significantly increase the space or time complex-ity of KALE, keeping the model complexity almostthe same as that of TransE (optimal among the meth-ods listed in the table).
But please note that KALEneeds to ground universally quantified rules beforelearning, which further requiresO(nunt/nr) in timecomplexity.
Here, nu is the number of universallyquantified rules, and nt/nr is the averaged numberof observed triples per relation.
During grounding,we select those ground rules with at least one tripleobserved.
Grounding is required only once beforelearning, and is not included during the iterations.Extensions.
Actually, our approach is quite general.
(i) Besides TransE, a variety of embedding method-s, e.g., those listed in Table 1, can be used for triplemodeling (Section 3.2), as long as we further definea mapping f : R ?
[0, 1] to map original scores tosoft truth values.
(ii) Besides the two types of rulesintroduced in Section 3.3, other types of rules canalso be handled as long as they can be representedas first-order logic formulae.
(iii) Besides the prod-uct t-norm, other types of t-norm based fuzzy logicscan be used for rule modeling (Section 3.3), e.g., the?ukasiewicz t-norm used in probabilistic soft log-ic (Bro?cheler et al, 2010) and the minimum t-normused in fuzzy description logic (Stoilos et al, 2007).
(iv) Besides the pairwise ranking loss, other type-s of loss functions can be designed for joint learn-ing (Section 3.4), e.g., the pointwise squared loss orthe logarithmic loss (Rockta?schel et al, 2014; Rock-ta?schel et al, 2015).4 ExperimentsWe empirically evaluate KALE with two tasks: (i)link prediction and (ii) triple classification.Dataset # Ent # Rel # Train/Valid/Test-I/Test-II # RuleFB122 9,738 122 91,638 9,595 5,057 6,186 78,488WN18 40,943 18 141,442 5,000 1,394 3,606 119,222Table 3: Statistics of datasets.4.1 Experimental SetupDatasets.
We use two datasets: WN18 and FB122.WN18 is a subgraph of WordNet containing 18 rela-tions.
FB122 is composed of 122 Freebase relationsregarding the topics of ?people?, ?location?, and ?s-ports?, extracted from FB15K.
Both WN18 and F-B15K are released by Bordes et al (2013)3.
Tripleson each dataset are split into training/validation/testsets, used for model training, parameter tuning, andevaluation respectively.
For WN18 we use the o-riginal data split, and for FB122 we extract triplesassociated with the 122 relations from the training,validation, and test sets of FB15K.We further create logical rules for each dataset,in the form of ?x, y : (x, rs, y) ?
(x, rt, y) or?x, y, z : (x, rs1 , y) ?
(y, rs2 , z) ?
(x, rt, z).
Todo so, we first run TransE to get entity and relationembeddings, and calculate the truth value for eachof such rules according to Eq.
(2) or Eq.
(3).
Thenwe rank all such rules by their truth values and man-ually filter those ranked at the top.
We finally create47 rules on FB122, and 14 onWN18 (see Table 2 forexamples).
The rules are then instantiated with con-crete entities (grounding).
Ground rules in which atleast one constituent triple is observed in the train-ing set are used in joint learning.Note that some of the test triples can be inferredby directly applying these rules on the training set(pure logical inference).
On each dataset, we fur-ther split the test set into two parts, test-I and test-II.The former contains triples that cannot be directlyinferred by pure logical inference, and the latter theremaining test triples.
Table 3 gives some statisticsof the datasets, including the number of entities, re-lations, triples in training/validation/test-I/test-II set,and ground rules.Comparison settings.
As baselines we take the em-bedding techniques of TransE, TransH, and Tran-sR. TransE models relation embeddings as transla-tion operations between entity embeddings.
TransH3https://everest.hds.utc.fr/doku.php?id=en:smemlj12196?x, y : /sports/athlete/team(x, y) ?
/sports/sports team/player(y, x)?x, y : /location/country/capital(x, y) ?
/location/location/contains(x, y)?x, y, z : /people/person/nationality(x, y) ?
/location/country/official language(y, z) ?
/people/person/languages(x, z)?x, y, z : /country/administrative divisions(x, y) ?
/administrative division/capital(y, z) ?
/country/second level divisions(x, z)?x, y : hypernym(x, y) ?
hyponym(y, x)?x, y : instance hypernym(x, y) ?
instance hyponym(y, x)?x, y : synset domain topic of(x, y) ?
member of domain topic(y, x)Table 2: Examples of rules created.and TransR are extensions of TransE.
They furtherallow entities to have distinct embeddings when in-volved in different relations, by introducing relation-specific hyperplanes and projection matrices respec-tively.
All the three methods have been demonstrat-ed to perform well on WordNet and Freebase data.We further test our approach in three different sce-narios.
(i) KALE-Trip uses triples alone to performthe embedding task, i.e., only the training triples areincluded in the optimization Eq.
(4).
It is a linear-ly transformed version of TransE.
The only differ-ence is that relation embeddings are normalized inKALE-Trip, but not in TransE.
(ii) KALE-Pre firstrepeats pure logical inference on the training set andadds inferred triples as additional training data, untilno further triples can be inferred.
Both original andinferred triples are then included in the optimization.For example, given a logical rule ?x, y : (x, rs, y)?
(x, rt, y), a new triple (ei, rt, ej) can be inferred if(ei, rs, ej) is observed in the training set, and bothtriples will be used as training instances for embed-ding.
(iii) KALE-Joint is the joint learning scenari-o, which considers both training triples and groundrules in the optimization.
In the aforementionedexample, training triple (ei, rs, ej) and ground rule(ei, rs, ej) ?
(ei, rt, ej) will be used in the train-ing process of KALE-Joint, without explicitly in-corporating triple (ei, rt, ej).
Among the method-s, TransE/TransH/TransR and KALE-Trip use onlytriples, while KALE-Pre/KALE-Joint further incor-porates rules, before or during embedding.Implementation details.
We use the code provid-ed by Bordes et al (2013) for TransE4, and the codeprovided by Lin et al (2015b) for TransH and Tran-sR5.
KALE is implemented in Java.
Note that Linet al (2015b) initialized TransR with the results of4https://github.com/glorotxa/SME5https://github.com/mrlyk423/relation extractionTransE.
However, to ensure fair comparison, we ran-domly initialize all the methods in our experiments.For all the methods, we create 100 mini-batches oneach dataset, and tune the embedding dimension din {20, 50, 100}.
For TransE, TransH, and Tran-sR which score a triple by a distance in R+, wetune the learning rate ?
in {0.001, 0.01, 0.1}, andthe margin ?
in {1, 2, 3, 4}.
For KALE which s-cores a triple (as well as a ground rule) by a softtruth value in the unit interval [0, 1], we set the learn-ing rate ?
in {0.01, 0.02, 0.05, 0.1}, and the mar-gin ?
in {0.1, 0.12, 0.15, 0.2}.
KALE allows triplesand rules to have different weights, with the formerfixed to 1, and the latter (denoted by ?)
selected in{0.001, 0.01, 0.1, 1}.4.2 Link PredictionThis task is to complete a triple (ei, rk, ej) with ei orej missing, i.e., predict ei given (rk, ej) or predict ejgiven (ei, rk).Evaluation protocol.
We follow the same evalua-tion protocol used in TransE (Bordes et al, 2013).For each test triple (ei, rk, ej), we replace the headentity ei by every entity e?i in the dictionary, and cal-culate the truth value (or distance) for the corruptedtriple (e?i, rk, ej).
Ranking the truth values in de-scending order (or the distances in ascending order),we get the rank of the correct entity ei.
Similarly, wecan get another rank by corrupting the tail entity ej .Aggregated over all the test triples, we report threemetrics: (i) the mean reciprocal rank (MRR), (ii) themedian of the ranks (MED), and (iii) the proportionof ranks no larger than n (HITS@N).
We do not re-port the averaged rank (i.e., the ?Mean Rank?
metricused by Bordes et al (2013)), since it is usually sen-sitive to outliers (Nickel et al, 2016).Note that a corrupted triple may exist in KGs,which should also be taken as a valid triple.
Consid-er a test triple (Paris,Located-In,France)197Test-I Test-II Test-ALLMRR MED HITS@N (%) MRR MED HITS@N (%) MRR MED HITS@N (%)3 5 10 3 5 10 3 5 10FB122TransE 0.220 29.0 25.7 32.4 40.6 0.296 5.0 40.0 50.8 57.8 0.262 10.0 33.6 42.5 50.0TransH 0.218 29.0 25.0 31.3 39.2 0.297 6.0 37.5 48.5 56.3 0.249 12.0 31.9 40.7 48.6TransR 0.219 31.0 24.7 30.8 38.9 0.273 9.0 32.4 42.8 51.6 0.261 15.0 28.9 37.4 45.9KALE-Trip 0.201 25.0 23.9 31.6 40.1 0.309 5.0 40.9 51.3 58.0 0.261 11.0 33.3 42.4 50.0KALE-Pre 0.203 25.0 24.1 31.7 40.2 0.368 4.0 47.3 55.4 61.4 0.294 9.0 36.9 44.8 51.9KALE-Joint 0.229 21.0 26.3 33.8 42.2 0.357 4.0 44.0 53.0 59.3 0.299 9.0 36.1 44.3 51.6WN18TransE 0.248 4.0 40.9 60.6 77.0 0.363 3.0 59.4 70.8 81.4 0.331 3.0 54.3 67.9 80.2TransH 0.242 4.0 39.2 60.1 75.9 0.482 2.0 63.5 70.8 79.3 0.415 3.0 56.7 67.8 78.3TransR 0.240 4.0 40.1 57.7 71.6 0.449 3.0 55.7 64.5 74.3 0.391 3.0 51.3 62.6 73.5KALE-Trip 0.250 4.0 40.6 62.3 78.1 0.393 2.0 61.9 71.2 80.6 0.353 3.0 56.0 68.7 79.9KALE-Pre 0.248 4.0 40.4 61.5 78.2 0.451 3.0 69.6 77.5 85.3 0.395 3.0 61.4 73.0 83.3KALE-Joint 0.260 4.0 43.6 64.1 79.2 0.563 2.0 67.6 73.8 81.0 0.478 2.0 60.9 71.1 80.5Table 4: Link prediction results on the test-I, test-II, and test-all sets of FB122 and WN18 (raw setting).Test-I Test-II Test-ALLMRR MED HITS@N (%) MRR MED HITS@N (%) MRR MED HITS@N (%)3 5 10 3 5 10 3 5 10FB122TransE 0.296 13.0 36.0 41.5 48.1 0.630 2.0 77.5 82.8 88.4 0.480 2.0 58.9 64.2 70.2TransH 0.280 15.0 33.6 39.1 46.4 0.606 2.0 70.1 75.4 82.0 0.460 3.0 53.7 59.1 66.0TransR 0.283 16.0 33.4 39.2 46.0 0.499 2.0 57.0 63.2 70.1 0.401 5.0 46.4 52.4 59.3KALE-Trip 0.299 10.0 36.6 42.9 50.2 0.650 2.0 79.0 83.4 88.7 0.492 2.0 59.9 65.2 71.4KALE-Pre 0.291 11.0 35.8 41.9 49.8 0.713 1.0 82.9 86.1 89.9 0.523 2.0 61.7 66.2 71.8KALE-Joint 0.325 9.0 38.4 44.7 52.2 0.684 1.0 79.7 84.1 89.6 0.523 2.0 61.2 66.4 72.8WN18TransE 0.306 3.0 57.4 72.3 80.1 0.511 2.0 87.5 95.6 98.7 0.453 2.0 79.1 89.1 93.6TransH 0.318 3.0 61.7 72.4 78.2 0.653 2.0 87.1 91.4 94.6 0.560 2.0 80.0 86.1 90.0TransR 0.299 3.0 56.1 66.7 74.5 0.597 2.0 75.0 81.7 88.0 0.514 2.0 69.7 77.5 84.3KALE-Trip 0.322 3.0 61.0 73.9 80.8 0.555 2.0 90.6 96.3 98.8 0.490 2.0 82.3 90.1 93.8KALE-Pre 0.322 3.0 60.6 74.5 81.1 0.612 2.0 96.4 98.6 99.6 0.532 2.0 86.4 91.9 94.4KALE-Joint 0.338 3.0 65.5 76.3 82.1 0.787 1.0 93.3 95.4 97.2 0.662 2.0 85.5 90.1 93.0Table 5: Link prediction results on the test-I, test-II, and test-all sets of FB122 and WN18 (filtered setting).and a possible corruption (Lyon,Located-In,France).
Both triples are valid.
In this case, rank-ing Lyon before the correct answer Paris shouldnot be counted as an error.
To avoid such phenome-na, we follow Bordes et al (2013) and remove thosecorrupted triples which exist in either the training,validation, or test set before getting the ranks.
Thatmeans, we remove Lyon from the candidate list be-fore getting the rank of Paris in the aforemen-tioned example.
We call the original setting ?raw?and the new setting ?filtered?.Optimal configurations.
For each of the method-s to be compared, we tune its hyperparameters inthe ranges specified in Section 4.1, and select a bestmodel that leads to the highest filtered MRR scoreon the validation set (with a total of 500 epochs overthe training data).
The optimal configurations forKALE are: d = 100, ?
= 0.05, ?
= 0.12, and ?
= 1on FB122; d=50, ?=0.05, ?=0.2, and ?=0.1 onWN18.
To better see and understand the effects ofrules, we use the same configuration for KALE-Trip,KALE-Pre, and KALE-Joint on each dataset.Results.
Table 4 and Table 5 show the results in theraw setting and filtered setting respectively.
On eachdataset we report the metrics on three sets: test-I,test-II, and the whole test set (denoted by test-all).Test-I contains test triples that cannot be directly in-ferred by performing pure logical inference on thetraining set, and hence might be intrinsically more d-ifficult for the rules.
The remaining test triples (i.e.,the directly inferable ones) are included in Test-II.These triples have either been used directly as train-198Raw FilteredTest-Incl Test-Excl Test-Incl Test-ExclMEAN / MED / HITS@10 MEAN / MED / HITS@10 MEAN / MED / HITS@10 MEAN / MED / HITS@10FB122 KALE-Trip 0.150 49.0 34.2 0.235 17.0 44.1 0.267 14.0 46.2 0.321 8.0 52.9KALE-Joint 0.175 36.0 36.6 0.265 15.0 45.9 0.290 11.0 49.3 0.349 7.0 54.2WN18 KALE-Trip 0.062 239.0 15.1 0.285 4.0 90.0 0.072 186.0 17.3 0.369 2.0 92.9KALE-Joint 0.093 186.0 19.6 0.291 4.0 90.5 0.113 136.0 24.0 0.381 2.0 93.2Table 6: Comparison between KALE-Trip and KALE-Joint on Test-Incl and Test-Excl of FB122 and WN18.ing instances in KALE-Pre, or encoded explicitly intraining ground rules in KALE-Joint, making this settrivial for the rules to some extent.
From the result-s, we can see that in both settings: (i) KALE-Preand KALE-Joint outperform (or at least perform aswell as) the other methods which use triples aloneon almost all the test sets, demonstrating the superi-ority of incorporating logical rules.
(ii) On the test-Isets which contain triples beyond the scope of purelogical inference, KALE-Joint performs significant-ly better than KALE-Pre.
On these sets KALE-Jointcan still beat all the baselines by a significant marginin most cases, while KALE-Pre can hardly outper-form KALE-Trip.
It demonstrates the capability ofthe joint embedding scenario to learn more predic-tive embeddings, through which we can make betterpredictions even beyond the scope of pure logicalinference.
(iii) On the test-II sets which contain di-rectly inferable triples, KALE-Pre can easily beat allthe baselines (even KALE-Joint).
That means, fortriples covered by pure logical inference, it is trivialto improve the performance by directly incorporat-ing them as training instances.To better understand how the joint embedding s-cenario can learn more predictive embeddings, oneach dataset we further split the test-I set into twoparts.
Given a triple (ei, rk, ej) in the test-I set, weassign it to the first part if relation rk is covered bythe rules, and the second part otherwise.
We call thetwo parts Test-Incl and Test-Excl respectively.
Ta-ble 6 compares the performance of KALE-Trip andKALE-Joint on the two parts.
The results show thatKALE-Joint outperforms KALE-Trip on both parts,but the improvements on Test-Incl are much moresignificant than those on Test-Excl.
Take the fil-tered setting on WN18 as an example.
On Test-Incl,KALE-Joint increases the metric MRR by 55.7%,decreases the metric MED by 26.9%, and increas-es the metric HITS@10 by 38.2%.
On Test-Excl,however, MRR rises by 3.1%, MED remains thesame, and HITS@10 rises by only 0.3%.
This obser-vation indicates that jointly embedding triples andrules helps to learn more predictive embeddings, es-pecially for those relations that are used to constructthe rules.
This might be the main reason that KALE-Joint can make better predictions even beyond thescope of pure logical inference.4.3 Triple ClassificationThis task is to verify whether an unobserved triple(ei, rk, ej) is correct or not.Evaluation protocol.
We take the following evalu-ation protocol similar to that used in TransH (Wanget al, 2014).
We first create labeled data for evalua-tion.
For each triple in the test or validation set (i.e.,a positive triple), we construct 10 negative triplesfor it by randomly corrupting the entities, 5 at thehead position and the other 5 at the tail position.6 Tomake the negative triples as difficult as possible, wecorrupt a position using only entities that have ap-peared in that position, and further ensure that thecorrupted triples do not exist in either the training,validation, or test set.
We simply use the truth values(or distances) to classify triples.
Triples with largetruth values (or small distances) tend to be predict-ed as positive.
To evaluate, we first rank the triplesassociated with each specific relation (in descendingorder according to their truth values, or in ascendingorder according to the distances), and calculate theaverage precision for that relation.
We then reporton the test sets the mean average precision (MAP)6Previous work typically constructs only a single negativecase for each positive one.
We empirically found such a bal-anced classification task too simple for our datasets.
So we con-sider a highly unbalanced setting, with a positive-to-negative ra-tio of 1:10, for which the previously used metric accuracy is nolonger suitable.199FB122 WN18MAP (Test-I/II/ALL) MAP (Test-I/II/ALL)TransE 0.552 0.852 0.634 0.592 0.993 0.958TransH 0.576 0.758 0.641 0.604 0.978 0.947TransR 0.572 0.699 0.619 0.412 0.854 0.836KALE-Trip 0.578 0.829 0.652 0.618 0.995 0.953KALE-Pre 0.575 0.916 0.668 0.620 0.997 0.964KALE-Joint 0.599 0.870 0.677 0.627 0.997 0.961Table 7: Triple classification results on the test-I, test-II, andtest-all sets of FB122 and WN18.aggregated over different relations.Optimal configurations.
The hyperparameters ofeach method are again tuned in the ranges specifiedin Section 4.1, and the best models are selected bymaximizing MAP on the validation set.
The optimalconfigurations for KALE are: d=100, ?=0.1, ?
=0.2, and ?
= 0.1 on FB122; d = 100, ?
= 0.1, ?
=0.2, and ?
= 0.001 on WN18.
Again, we use thesame configuration for KALE-Trip, KALE-Pre, andKALE-Joint on each dataset.Results.
Table 7 shows the results on the test-I, test-II, and test-all sets of our datasets.
From the results,we can see that: (i) KALE-Pre and KALE-Joint out-perform the other methods which use triples aloneon almost all the test sets, demonstrating the superi-ority of incorporating logical rules.
(ii) KALE-Jointperforms better than KALE-Pre on the test-I sets,i.e., triples that cannot be directly inferred by per-forming pure logical inference on the training set.This observation is similar to that observed in thelink prediction task, demonstrating that the joint em-bedding scenario can learn more predictive embed-dings and make predictions beyond the capability ofpure logical inference.5 Conclusion and Future WorkIn this paper, we propose a new method for joint-ly embedding knowledge graphs and logical rules,referred to as KALE.
The key idea is to representand model triples and rules in a unified framework.Specifically, triples are represented as atomic for-mulae and modeled by the translation assumption,while rules as complex formulae and by the t-normfuzzy logics.
A global loss on both atomic and com-plex formulae is then minimized to perform the em-bedding task.
Embeddings learned in this way arecompatible not only with triples but also with rules,which are certainly more useful for knowledge ac-quisition and inference.
We evaluate KALE withthe link prediction and triple classification tasks onWordNet and Freebase data.
Experimental result-s show that joint embedding brings significant andconsistent improvements over state-of-the-art meth-ods.
More importantly, it can obtain more predic-tive embeddings and make better predictions evenbeyond the scope of pure logical inference.For future work, we would like to (i) Investigatethe efficacy of incorporating other types of logicalrules such as ?x, y, z : (x,Capital-Of, y) ??
(x,Capital-Of, z).
(ii) Investigate the possibil-ity of modeling logical rules using only relation em-beddings as suggested by Demeester et al (2016),e.g., modeling the above rule using only the embed-ding associated with Capital-Of.
This avoidsgrounding, which might be time and space ineffi-cient especially for complicated rules.
(iii) Inves-tigate the use of automatically extracted rules whichare no longer hard rules and tolerant of uncertainty.AcknowledgmentsWe would like to thank the anonymous reviewers fortheir insightful comments and suggestions.
This re-search is supported by the National Natural ScienceFoundation of China (grant No.
61402465) and theStrategic Priority Research Program of the ChineseAcademy of Sciences (grant No.
XDA06030200).ReferencesIslam Beltagy and Raymond J. Mooney.
2014.
Efficientmarkov logic inference for natural language semantics.In Proceedings of the 28th AAAI Conference on Arti-ficial Intelligence - Workshop on Statistical RelationalArtificial Intelligence, pages 9?14.Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim S-turge, and Jamie Taylor.
2008.
Freebase: a collab-oratively created graph database for structuring hu-man knowledge.
In Proceedings of the 2008 ACMSIGMOD International Conference on Management ofData, pages 1247?1250.Antoine Bordes, Jason Weston, Ronan Collobert, andYoshua Bengio.
2011.
Learning structured embed-dings of knowledge bases.
In Proceedings of the25th AAAI Conference on Artificial Intelligence, pages301?306.200Antoine Bordes, Nicolas Usunier, Alberto Garcia-Dura?n,Jason Weston, and Oksana Yakhnenko.
2013.
Trans-lating embeddings for modeling multi-relational da-ta.
In Proceedings of the 27th Annual Conference onNeural Information Processing Systems, pages 2787?2795.Antoine Bordes, Xavier Glorot, Jason Weston, andYoshua Bengio.
2014.
A semantic matching energyfunction for learning with multi-relational data.
Ma-chine Learning, 94(2):233?259.Matthias Bro?cheler, Lilyana Mihalkova, and Lise Getoor.2010.
Probabilistic similarity logic.
In Proceedings ofthe 26th Conference on Uncertainty in Artificial Intel-ligence, pages 73?82.Kai-wei Chang, Wen-tau Yih, Bishan Yang, and Christo-pher Meek.
2014.
Typed tensor decomposition ofknowledge bases for relation extraction.
In Proceed-ings of the 2014 Conference on Empirical Methods inNatural Language Processing, pages 1568?1579.Thomas Demeester, Tim Rockta?schel, and SebastianRiedel.
2016.
Regularizing relation representationsby first-order implications.
In Proceedings of the 2016Conference of the North American Chapter of the As-sociation for Computational Linguistics: Human Lan-guage Technologies - Workshop on Automated Knowl-edge Base Construction, pages 75?80.Shu Guo, Quan Wang, Lihong Wang, Bin Wang, andLi Guo.
2015.
Semantically smooth knowledge graphembedding.
In Proceedings of the 53rd Annual Meet-ing of the Association for Computational Linguisticsand the 7th International Joint Conference on NaturalLanguage Processing, pages 84?94.Petr Ha?jek.
1998.
The metamathematics of fuzzy logic.Kluwer.Raphael Hoffmann, Congle Zhang, Xiao Ling, LukeZettlemoyer, and Daniel S. Weld.
2011.
Knowledge-based weak supervision for information extraction ofoverlapping relations.
In Proceedings of the 49thAnnual Meeting of the Association for Computation-al Linguistics: Human Language Technologies, pages541?550.Rodolphe Jenatton, Nicolas L. Roux, Antoine Bordes,and Guillaume R. Obozinski.
2012.
A latent factormodel for highly multi-relational data.
In Proceedingsof the 26th Annual Conference on Neural InformationProcessing Systems, pages 3167?3175.Shangpu Jiang, Daniel Lowd, and Dejing Dou.
2012.Learning to refine an automatically extracted knowl-edge base using markov logic.
In Proceedings of 12thIEEE International Conference on Data Mining, pages912?917.Charles Kemp, Joshua B. Tenenbaum, Thomas L. Grif-fiths, Takeshi Yamada, and Naonori Ueda.
2006.Learning systems of concepts with an infinite relation-al model.
In Proceedings of the 21st AAAI Conferenceon Artificial Intelligence, pages 381?388.Denis Krompa?, Stephan Baier, and Volker Tresp.
2015.Type-constrained representation learning in knowl-edge graphs.
In Proceedings of the 14th InternationalSemantic Web Conference, pages 640?655.Yankai Lin, Zhiyuan Liu, Huanbo Luan, Maosong Sun,Siwei Rao, and Song Liu.
2015a.
Modeling relationpaths for representation learning of knowledge bases.In Proceedings of the 2015 Conference on EmpiricalMethods in Natural Language Processing, pages 705?714.Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, andXuan Zhu.
2015b.
Learning entity and relation em-beddings for knowledge graph completion.
In Pro-ceedings of the 29th AAAI Conference on Artificial In-telligence, pages 2181?2187.Yuanfei Luo, Quan Wang, Bin Wang, and Li Guo.2015.
Context-dependent knowledge graph embed-ding.
In Proceedings of the 2015 Conference onEmpirical Methods in Natural Language Processing,pages 1656?1661.Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.2013.
Linguistic regularities in continuous space wordrepresentations.
In Proceedings of the 2013 Confer-ence of the North American Chapter of the Associa-tion for Computational Linguistics: Human LanguageTechnologies, pages 746?751.George A. Miller.
1995.
Wordnet: a lexical database forenglish.
Communications of the ACM, 38(11):39?41.Arvind Neelakantan, Benjamin Roth, and Andrew Mc-Callum.
2015.
Compositional vector space model-s for knowledge base completion.
In Proceedings ofthe 53rd Annual Meeting of the Association for Com-putational Linguistics and the 7th International Join-t Conference on Natural Language Processing, pages156?166.Maximilian Nickel, Volker Tresp, and Hans P. Kriegel.2011.
A three-way model for collective learning onmulti-relational data.
In Proceedings of the 28th In-ternational Conference on Machine Learning, pages809?816.Maximilian Nickel, Volker Tresp, and Hans P. Kriegel.2012.
Factorizing yago: Scalable machine learning forlinked data.
In Proceedings of the 21st InternationalConference on World Wide Web, pages 271?280.Maximilian Nickel, Lorenzo Rosasco, and Tomaso Pog-gio.
2016.
Holographic embeddings of knowledgegraphs.
In Proceedings of the 30th AAAI Conferenceon Artificial Intelligence, pages 1955?1961.Jay Pujara, Hui Miao, Lise Getoor, and William Cohen.2013.
Knowledge graph identification.
In Proceed-201ings of the 12th International Semantic Web Confer-ence, pages 542?557.Matthew Richardson and Pedro Domingos.
2006.Markov logic networks.
Machine Learning, 62(1-2):107?136.Sebastian Riedel, Limin Yao, Andrew McCallum, andBenjamin M. Marlin.
2013.
Relation extraction withmatrix factorization and universal schemas.
In Pro-ceedings of the 2013 Conference on North AmericanChapter of the Association for Computational Linguis-tics: Human Language Technologies, pages 74?84.Tim Rockta?schel, Matko Bos?njak, Sameer Singh, and Se-bastian Riedel.
2014.
Low-dimensional embeddingsof logic.
In Proceedings of the 52nd Annual Meet-ing of the Association for Computational Linguistics -Workshop on Semantic Parsing, pages 45?49.Tim Rockta?schel, Sameer Singh, and Sebastian Riedel.2015.
Injecting logical background knowledge intoembeddings for relation extraction.
In Proceedings ofthe 2015 Conference of the North American Chapterof the Association for Computational Linguistics: Hu-man Language Technologies, pages 1119?1129.Richard Socher, Danqi Chen, Christopher D. Manning,and Andrew Y. Ng.
2013.
Reasoning with neural ten-sor networks for knowledge base completion.
In Pro-ceedings of the 27th Annual Conference on Neural In-formation Processing Systems, pages 926?934.Giorgos Stoilos, Giorgos B. Stamou, Jeff Z. Pan, VassilisTzouvaras, and Ian Horrocks.
2007.
Reasoning withvery expressive fuzzy description logics.
Journal ofArtificial Intelligence Research, 30:273?320.Ilya Sutskever, Joshua B. Tenenbaum, and Ruslan R.Salakhutdinov.
2009.
Modelling relational data usingbayesian clustered tensor factorization.
In Proceed-ings of the 23rd Annual Conference on Neural Infor-mation Processing Systems, pages 1821?1828.Zhen Wang, Jianwen Zhang, Jianlin Feng, and ZhengChen.
2014.
Knowledge graph embedding bytranslating on hyperplanes.
In Proceedings of the28th AAAI Conference on Artificial Intelligence, pages1112?1119.Quan Wang, Bin Wang, and Li Guo.
2015.
Knowledgebase completion using embeddings and rules.
In Pro-ceedings of the 24th International Joint Conference onArtificial Intelligence, pages 1859?1865.Evgenia Wasserman-Pritsker, William W. Cohen, andEinat Minkov.
2015.
Learning to identify the bestcontexts for knowledge-based wsd.
In Proceedings ofthe 2015 Conference on Empirical Methods in NaturalLanguage Processing, pages 1662?1667.Zhuoyu Wei, Jun Zhao, Kang Liu, Zhenyu Qi, ZhengyaSun, and Guanhua Tian.
2015.
Large-scale knowl-edge base completion: inferring via grounding net-work sampling over selected instances.
In Proceed-ings of the 24th ACM International on Conferenceon Information and Knowledge Management, pages1331?1340.Jason Weston, Antoine Bordes, Oksana Yakhnenko, andNicolas Usunier.
2013.
Connecting language andknowledge bases with embedding models for relationextraction.
In Proceedings of the 2013 Conference onEmpirical Methods in Natural Language Processing,pages 1366?1371.Zhao Xu, Volker Tresp, Kai Yu, and Hanspeter Kriegel.2006.
Infinite hidden relational models.
In Proceed-ings of Proceedings of the 22nd Conference on Uncer-tainty in Artificial Intelligence, pages 544?551.Huaping Zhong, Jianwen Zhang, Zhen Wang, Hai Wan,and Zheng Chen.
2015.
Aligning knowledge and textembeddings by entity descriptions.
In Proceedings ofthe 2015 Conference on Empirical Methods in NaturalLanguage Processing, pages 267?272.202
