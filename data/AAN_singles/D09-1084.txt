Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 803?812,Singapore, 6-7 August 2009.c?2009 ACL and AFNLPA Relational Model of Semantic Similarity between Words usingAutomatically Extracted Lexical Pattern Clusters from the WebDanushka Bollegala?danushka@mi.ci.i.u-tokyo.ac.jpYutaka Matsuomatsuo@biz-model.t.u-tokyo.ac.jpThe University of Tokyo7-3-1, Hongo, Tokyo, 113-8656, JapanMitsuru Ishizukaishizuka@i.u-tokyo.ac.jpAbstractSemantic similarity is a central conceptthat extends across numerous fields suchas artificial intelligence, natural languageprocessing, cognitive science and psychol-ogy.
Accurate measurement of semanticsimilarity between words is essential forvarious tasks such as, document cluster-ing, information retrieval, and synonymextraction.
We propose a novel modelof semantic similarity using the semanticrelations that exist among words.
Giventwo words, first, we represent the seman-tic relations that hold between those wordsusing automatically extracted lexical pat-tern clusters.
Next, the semantic similar-ity between the two words is computedusing a Mahalanobis distance measure.We compare the proposed similarity mea-sure against previously proposed seman-tic similarity measures on Miller-Charlesbenchmark dataset and WordSimilarity-353 collection.
The proposed method out-performs all existing web-based seman-tic similarity measures, achieving a Pear-son correlation coefficient of 0.867 on theMillet-Charles dataset.1 IntroductionSimilarity is a fundamental concept in theoriesof knowledge and behavior.
Psychological ex-periments have shown that similarity acts as anorganizing principle by which individuals clas-sify objects, and make generalizations (Goldstone,1994).
For example, a biologist would classifya newly found animal specimen based upon theproperties that it shares with existing categoriesof animals.
We can then make additional infer-ences on the new specimen using the properties?Research Fellow of the Japan Society for the Promotionof Science (JSPS)known for the existing category.
As the simi-larity between two objects X and Y increases,so does the probability of correctly inferring thatY has the property T upon knowing that X hasT (Tenenbaum, 1999).
Accurate measurement ofsemantic similarity between lexical units such aswords or phrases is important for numerous tasksin natural language processing such as word sensedisambiguation (Resnik, 1995), synonym extrac-tion (Lin, 1998a), and automatic thesauri gener-ation (Curran, 2002).
In information retrieval,similar or related words are used to expand userqueries to improve recall (Sahami and Heilman,2006).Semantic similarity is a context dependent anddynamic phenomenon.
New words are constantlybeing created and existing words are assigned withnew senses on the Web.
To decide whether twowords are semantically similar, it is important toknow the semantic relations that hold between thewords.
For example, the words horse and cow canbe considered semantically similar because bothhorses and cows are useful animals in agriculture.Similarly, a horse and a car can be considered se-mantically similar because cars, and historicallyhorses, are used for transportation.
Semantic re-lations such as X and Y are used in agriculture,or X and Y are used for transportation, exist be-tween two words X and Y in these examples.
Weuse bold-italics, X, to denote the slot of a word Xin a lexical pattern.We propose a relational model to compute thesemantic similarity between two words.
First, us-ing snippets retrieved from a web search engine,we present an automatic lexical pattern extractionalgorithm to represent the semantic relations thatexist between two words.
For example, given twowords ostrich and bird, we extract X is a Y, X isa large Y, and X is a flightless Y from the Web.Using a set of semantically related words as train-ing data, we evaluate the confidence of a lexical803pattern as an indicator of semantic similarity.
Forexample, the pattern X is a Y is a better indica-tor of semantic similarity between X and Y thanthe pattern X and Y. Consequently, we would liketo emphasize the former pattern by assigning it ahigher confidence score.
It is noteworthy that alllexical patterns are not independent ?
multiple lex-ical patterns can express the same semantic rela-tion.
For example, the pattern X is a large Y sub-sumes the more general pattern X is a Y and theyboth indicate a hypernymic relationship betweenX and Y.
By clustering the semantically relatedpatterns into groups, we can both overcome thedata sparseness problem, and reduce the numberof parameters during training.
To identify seman-tically related patterns, we use a sequential patternclustering algorithm that is based on the distribu-tional hypothesis (Harris, 1954).
We represent twowords by a feature vector defined over the clus-ters of patterns.
Finally, the semantic similarityis computed as the Mahalanobis distance betweenpoints corresponding to the feature vectors.
Byusing Mahalanobis distance instead of Euclideandistance, we can account for the inter-dependencebetween semantic relations.2 Related WorkGeometric models, such as multi-dimensionalscaling has been used in psychological ex-periments analyzing the properties of similar-ity (Krumhansl, 1978).
These models representobjects as points in some coordinate space suchthat the observed dissimilarities between objectscorrespond to the metric distances between the re-spective points.
Geometric models assume thatobjects can be adequately represented as points insome coordinate space and that dissimilarity be-haves like a metric distance function satisfyingminimality, symmetry, and triangle inequality as-sumptions.
However, both dimensional and metricassumptions are open to question.Tversky (1977) proposed the contrast model ofsimilarity to overcome the problems in geometricmodels.
The contrast model relies on featural rep-resentation of objects, and it is used to compute thesimilarity between the representations of two ob-jects.
Similarity is defined as an increasing func-tion of common features (i.e.
features in commonto the two objects), and as a decreasing function ofdistinctive features (i.e.
features that apply to oneobject but not the other).
The attributes of objectsare primal to contrast model and it does not ex-plicitly incorporate the relations between objectswhen measuring similarity.Hahn et al (2003) define similarity betweentwo representations as the complexity required totransform one representation into the other.
Theirmodel of similarity is based on the Representa-tional Distortion theory, which aims to providea theoretical framework of similarity judgments.Their experiments using pattern sequences and ge-ometric shapes show an inverse correlation be-tween the number of transformations required toconvert one pattern (or shape) to another, and theperceived similarity ratings by human subjects.How to represent an object, which transformationsare allowed on a representation, and how to mea-sure the complexity of a transformation, are allimportant decisions in the transformational modelof similarity.
Although distance measures such asedit distance have been used to find approximatematches in a dictionary, it is not obvious how tocompute semantic similarity between words usingrepresentational distortion theory.Given a taxonomy of concepts, a straightfor-ward method to calculate similarity between twowords (or concepts) is to find the length of theshortest path connecting the two words in the tax-onomy (Rada et al, 1989).
If a word is polyse-mous (i.e.
has more than one sense) then multi-ple paths might exist between the two words.
Insuch cases, only the shortest path between any twosenses of the words is considered for calculatingsimilarity.
A problem that is frequently acknowl-edged with this approach is that it relies on thenotion that all links in the taxonomy represent auniform distance.
As a solution to this problem,Schickel-Zuber and Faltings (2007) propose ontol-ogy structure based similarity (OSS) between twoconcepts in an ontology, which is an asymmetricdistance function.Resnik (1995) proposed a similarity measureusing information content.
He defined the similar-ity between two concepts C1and C2in the taxon-omy as the maximum of the information content ofall concepts C that subsume both C1and C2.
Thenthe similarity between two words is defined as themaximum of the similarity between any conceptsthat the words belong to.
He used WordNet as thetaxonomy; information content is calculated usingthe Brown corpus.Li et al, (2003) combined structural seman-804tic information from a lexical taxonomy, and in-formation content from a corpus, in a nonlinearmodel.
They proposed a similarity measure thatuses shortest path length, depth and local densityin a taxonomy.
Their experiments reported a Pear-son correlation coefficient of 0.8914 on the Miller-Charles benchmark dataset (Miller and Charles,1998).
Lin (1998b) defined the similarity betweentwo concepts as the information that is in commonto both concepts and the information contained ineach individual concept.Cilibrasi and Vitanyi (2007) proposed a distancemetric between words using page-counts retrievedfrom a web search engine.
The proposed metric isnamed Normalized Google Distance (NGD) and isdefined as the normalized information distance (Liet al, 2004) between two strings.
They evaluateNGD in a word classification task.
UnfortunatelyNGD only uses page-counts of words and ignoresthe context in which the words appear.
Therefore,it produces inaccurate similarity scores when oneor both words between which similarity is com-puted are polysemous.Sahami and Heilman (2006) measured semanticsimilarity between two queries using snippets re-turned for those queries by a search engine.
Foreach query, they collect snippets from a searchengine and represent each snippet as a TF-IDF-weighted term vector.
Each vector is L2normal-ized and the centroid of the set of vectors is com-puted.
Semantic similarity between two queriesis then defined as the inner product between thecorresponding centroid vectors.
They did notcompare their similarity measure with taxonomy-based similarity measures.Chen et al, (2006) propose a web-based double-checking model to compute the semantic similar-ity between words.
For two words X and Y , theycollect snippets for each word from a web searchengine.
Then they count the number of occur-rences of X in the snippets for Y , and Y in thesnippets for X .
The two values are combined non-linearly to compute the similarity between X andY .
This method heavily depends on the search en-gine?s ranking algorithm.
Although two words Xand Y may be very similar, there is no reason tobelieve that one can find Y in the snippets for X ,or vice versa.
This observation is confirmed by theexperimental results in their paper which reports 0similarity scores for many pairs of words in theMiller-Charles dataset.In our previous work (Bollegala et al, 2007),we proposed a semantic similarity measure usingpage counts and snippets retrieved from a Websearch engine.
To compute the similarity betweentwo words X and Y , we queried a web search en-gine using the query X AND Y and extract lex-ical patterns that combine X and Y from snip-pets.
A feature vector is formed using frequen-cies of 200 lexical patterns in snippets and fourco-occurrence measures: Dice coefficient, overlapcoefficient, Jaccard coefficient and pointwise mu-tual information.
We trained a two-class supportvector machine using automatically selected syn-onymous and non-synonymous word pairs fromWordNet.
This method reports a Pearson corre-lation coefficient of 0.837 with Miller-Charles rat-ings.
However, it does not consider the relatednessbetween patterns.Gabrilovich and Markovitch (2007) representwords using weighted vectors of Wikipedia-basedconcepts, and define the similarity between wordsas the cosine of the angle between the correspond-ing vectors.
Their method can be used to com-pute similarity between words as well as betweentexts.
Although Wikipedia is growing in popular-ity, not all concepts found on the Web have arti-cles in Wikipedia.
Specially, novel or not verypopular concepts are not adequately covered byWikipedia.
Moreover, their method requires theconcepts to be independent.
For non-independent,hierarchical taxonomies such as open directoryproject (ODP)1, their method produces suboptimalresults.3 Relational Model of SimilarityWe propose a model to compute the semantic sim-ilarity between two words a and b using the setof semantic relations R(a, b) that hold between aand b.
We call the proposed model the relationalmodel of semantic similarity and it is defined bythe following equation,sim(a, b) = ?
(R(a, b)).
(1)Here, sim(a, b) is the semantic similarity betweenthe two words a and b, and ?
is a weightingfunction defined over the set of semantic relationsR(a, b).
Given that a particular set of semanticrelations are known to hold between two words,the function ?
expresses our confidence on thosewords being semantically similar.1http://www.dmoz.org805A semantic relation can be expressed in a num-ber of ways.
For example, given a taxonomy ofwords such as the WordNet, semantic relations(i.e.
hypernymy, meronymy, synonymy etc.)
be-tween words can be directly looked up in the tax-onomy.
Alternatively, the labels of the edges inthe path connecting two words can be used assemantic relations.
However, in this paper wedo not assume the availability of manually cre-ated resources such as dictionaries or taxonomies.We represent semantic relations using automati-cally extracted lexical patterns.
Lexical patternshave been successfully used to represent varioussemantic relations between words such as hyper-nymy (Hearst, 1992), and meronymy (Berland andCharniak, 1999).
Following these previous ap-proaches, we represent R(a, b) as a set of lexicalpatterns.
Moreover, we denote the frequency of alexical pattern r for a word pair (a, b) by f(r, a, b).So far we have not defined the functional formof ?.
A straightforward approach is to use a lin-early weighted combination of relations as shownbelow,?
(R(a, b)) =?ri?R(a,b)wi?
f(ri, a, b).
(2)Here, wiis the weight associated with the lexicalpattern riand can be determined using trainingdata.
However, this formulation has two funda-mental drawbacks.
First, the number of weightparameters wiis equal to the number of lexicalpatterns.
Typically two words can co-occur in nu-merous patterns.
Consequently, we end up with alarge number of parameters in the model.
Com-plex models with a large number of parametersare difficult to train because they tend to overfit tothe training data.
Second, the linear combinationgiven in Equation 2 assumes the lexical patternsto be mutually independent.
However, in practicethis is not true.
For example, both patterns X is aY and Y such as X indicate a hypernymic relationbetween X and Y.To overcome the above mentioned limitations,we first cluster the lexical patterns to identify thesemantically related patterns.
Our clustering algo-rithm is detailed in section 3.2.
Next, we define ?using the formed clusters as follows,?
(R(a, b)) = xTab??.
(3)Here, xabis a feature vector representing thewords a and b.
Each formed cluster contributesa feature in vector xabas described later in Sec-tion 5.
The vector ?
is a prototypical vector rep-resenting synonymous word pairs.
We compute?
as the centroid of feature vectors representingsynonymous word pairs.
?
is the inter-cluster cor-relation matrix.
The (i, j)-th element of matrix ?denotes the correlation between the two clusters ciand cj.
Matrix ?
is expected to capture the de-pendence between semantic relations.
Intuitively,if two clusters i and j are highly correlated, thenthe (i, j)-th element of ?
will be closer to 1.
Equa-tion 3 computes the similarity between a word pair(a, b) and a set of synonymous word pairs.
In-tuitively, if the relations that exist between a andb are typical relations that hold between synony-mous word pairs, then Equation 3 returns a highsimilarity score for a and b.The proposed relational model of semantic sim-ilarity differs from feature models of similarity,such as the contrast model (Tversky, 1977), inthat it is defined over the set of semantic relationsthat exist between two words instead of the set offeatures for each word.
Specifically, in contrastmodel, the similarity S(a, b) between two objectsa and b is defined in terms of the features commonto a and b, A ?
B, the features that are distinctiveto a, A?B, and the features that are distinctive tob, B ?A.
The contrast model is formalized in thefollowing equation,S(a, b) = ?f(A ?B)?
?f(A?B)?
?f(B ?A).
(4)Here, the function f measures the salience of aparticular set of features, and non-negative param-eters ?, ?, and ?
determine the relative weightsassigned to the different components.
However, inthe relational model of similarity we do not focuson features of individual words but on relations be-tween two words.Modeling similarity as a phenomenon of rela-tions between objects rather than features of indi-vidual objects is central to computational modelsof analogy-making such as the structure mappingtheory (SMT) (Falkenhainer et al, 1989).
SMTclaims that an analogy is a mapping of knowl-edge from one domain (base) into another (target)which conveys that a system of relations knownto hold in the base also holds in the target.
Thetarget objects do not have to resemble their corre-sponding base objects.
During the mapping pro-cess, features of individual objects are droppedand only relations are mapped.
The proposed rela-tional model of similarity uses this relational view806Ostrich, a large, flightless bird that lives in the dry grass-lands of Africa.Figure 1: A snippet returned for the query ?ostrich* * * * * bird?.of similarity to compute semantic similarity be-tween words.3.1 Extracting Lexical PatternsTo compute semantic similarity between twowords using the relational model (Equation 3),we must first extract the numerous lexical pat-terns from contexts in which those two words ap-pear.
For this purpose, we propose a pattern ex-traction algorithm using snippets retrieved froma web search engine.
The proposed method re-quires no language-dependent preprocessing suchas part-of-speech tagging or dependency parsing,which can be both time consuming at Web scale,and likely to produce incorrect results because ofthe fragmented and ill-formed snippets.Given two words a and b, we query a web searchengine using the wildcard query ?a * * * * * b?and download snippets.
The ?*?
operator matchesone word or none in a web page.
Therefore, ourwildcard query retrieves snippets in which a andb appear within a window of seven words.
Weattempt to approximate the local context of twowords using wildcard queries.
For example, Fig-ure 1 shows a snippet retrieved for the query ?os-trich * * * * * bird?.For a snippet S, retrieved for a word pair (a, b),first, we replace the two words a and b, respec-tively, with two variables X and Y.
We replace allnumeric values by D, a marker for digits.
Next,we generate all subsequences of words from S thatsatisfy all of the following conditions.(i).
A subsequence must contain exactly one oc-currence of each X and Y(ii).
The maximum length of a subsequence is Lwords.(iii).
A subsequence is allowed to have gaps.
How-ever, we do not allow gaps of more than gnumber of words.
Moreover, the total lengthof all gaps in a subsequence should not ex-ceed G words.(iv).
We expand all negation contractions in a con-text.
For example, didn?t is expanded to didnot.
We do not skip the word not when gen-erating subsequences.
For example, this con-dition ensures that from the snippet X is not aY, we do not produce the subsequence X is aY.Finally, we count the frequency of all generatedsubsequences and only use subsequences that oc-cur more than N times as lexical patterns.The parameters L, g, G and N are set exper-imentally, as explained later in Section 6.
It isnoteworthy that the proposed pattern extraction al-gorithm considers all the words in a snippet, andis not limited to extracting patterns only from themid-fix (i.e., the portion of text in a snippet thatappears between the queried words).
Moreover,the consideration of gaps enables us to capture re-lations between distant words in a snippet.
We usea modified version of the prefixspan algorithm (Peiet al, 2004) to generate subsequences from a textsnippet.
Specifically, we use the constraints (ii)-(iv) to prune the search space of candidate sub-sequences.
For example, if a subsequence hasreached the maximum length L, or contains themaximum number of gaps G, then we will not ex-tend it further.
By pruning the search space, wecan speed up the pattern generation process.
How-ever, none of these modifications affect the accu-racy of the proposed semantic similarity measurebecause the modified version of the prefixspan al-gorithm still generates the exact set of patterns thatwe would obtain if we used the original prefixspanalgorithm (i.e.
without pruning) and subsequentlyremove patterns that violate the above mentionedconstraints.
For example, some patterns extractedform the snippet shown in Figure 1 are: X, a largeY, X a flightless Y, and X, large Y lives.3.2 Clustering Lexical PatternsA semantic relation can be expressed using morethan one pattern.
By grouping the semanticallyrelated patterns, we can both reduce the modelcomplexity in Equation 2, and consider the depen-dence among semantic relations in Equation 3.
Weuse the distributional hypothesis (Harris, 1954) tofind semantically related lexical patterns.
The dis-tributional hypothesis states that words that occurin the same context have similar meanings.
If twolexical patterns are similarly distributed over a setof word pairs, then from the distributional hypoth-esis it follows that the two patterns must be similar.We represent a pattern p by a vector p in which807the i-th element is the frequency f(ai, bi, p) of p ina word pair (ai, bi).
Given a set P of patterns anda similarity threshold ?, Algorithm 1 returns clus-ters of similar patterns.
First, the function SORTsorts the patterns in the descending order of theirtotal occurrences in all word pairs.
The total oc-currences of a pattern p is defined as ?
(p), and isgiven by,?
(p) =?
(a,b)?Wf(a, b, p).
(5)Here, W is the set of word pairs.
Then the outerfor-loop (starting at line 3), repeatedly takes a pat-tern pifrom the ordered set P , and in the inner for-loop (starting at line 6), finds the cluster, c?(?
C)that is most similar to pi.
Similarity between piand the cluster centroid cjis computed using co-sine similarity.
The centroid vector cjof cluster cjis defined as the vector sum of all pattern vectorsfor patterns in that cluster (i.e.
cj=?p?cjp).If the maximum similarity exceeds the threshold?, we append pito c?
(line 14).
Here, the op-erator ?
denotes vector addition.
Otherwise, weform a new cluster {pi} and append it to C, theset of clusters.
After all patterns are clustered,we compute the (i, j) element of the inter-clustercorrelation matrix ?
(Equation 3) as the inner-product between the centroid vectors ciand cjofthe corresponding clusters i and j.
The parame-ter ?
(?
[0, 1]) determines the purity of the formedclusters and is set experimentally in Section 5.
Al-gorithm 1 scales linearly with the number of pat-terns.
Moreover, sorting the patterns by their to-tal word pair frequency prior to clustering ensuresthat the final set of clusters contains the most com-mon relations in the dataset.4 Evaluation ProcedureEvaluating a semantic similarity measure is diffi-cult because the notion of semantic similarity issubjective.
Miller-Charles (1998) dataset has beenfrequently used to benchmark semantic similar-ity measures.
Miller-Charles dataset contains 30word pairs rated by a group of 38 human subjects.The word pairs are rated on a scale from 0 (no sim-ilarity) to 4 (perfect synonymy).
Because of theomission of two word pairs in earlier versions ofWordNet, most researchers had used only 28 pairsfor evaluations.
The degree of correlation betweenthe human ratings in the benchmark dataset andthe similarity scores produced by an automatic se-mantic similarity measure, can be considered as aAlgorithm 1 Sequential pattern clustering algo-rithm.Input: patterns P = {p1, .
.
.
,pn}, threshold ?Output: clusters C1: SORT(P )2: C ?
{}3: for pattern pi?
P do4: max ?
?
?5: c??
null6: for cluster cj?
C do7: sim ?
cosine(pi, cj)8: if sim > max then9: max ?
sim10: c??
cj11: end if12: end for13: if max ?
?
then14: c??
c??
pi15: else16: C ?
C ?
{pi}17: end if18: end for19: return Cmeasurement of how well the semantic similaritymeasure captures the notion of semantic similar-ity held by humans.
In addition to Miller-Charlesdataset we also evaluate on the WordSimilarity-353 (Finkelstein et al, 2002) dataset.
In con-trast to Miller-Charles dataset which has only 30word pairs, WordSimilarity-353 dataset contains353 word pairs.
Each pair has 13-16 human judg-ments, which were averaged for each pair to pro-duce a single relatedness score.
Following the pre-vious work, we use both Miller-Charles datasetand WordSimilarity-353 dataset to evaluate theproposed semantic similarity measure.5 Computing Semantic SimilarityTo extract lexical patterns that express numer-ous semantic relations, we first select synonymouswords from WordNet synsets.
A synset is a setof synonymous words assigned for a particularsense of a word in WordNet.
We randomly select2000 synsets of nouns from WordNet.
From eachsynset, a pair of synonymous words is selected.For polysemous nouns, we selected synonymsfrom the dominant sense.
To perform a fair evalu-ation, we do not select any words that appear in theMiller-Charles dataset or the WordSimilarity-3538080.30.40.50.60.70.80.911.11.21.31.40  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1AverageSimilarityClustering ThresholdFigure 2: Average similarity vs. clustering thresh-old ?00.10.20.30.40.50.60.70.80.910  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1Cluster SparsityClustering ThresholdFigure 3: Sparsity vs. clustering threshold ?dataset, which are used later for evaluation pur-poses.
As we describe later, the clustering thresh-old ?
is tuned using this set of 2000 word pairsselected from the WordNet.We use the YahooBOSS API2and download1000 snippets for each of those word pairs.
Ex-perimentally, we set the values for the parametersin the pattern extraction algorithm (Section 3.1):L = 5, g = 2, G = 4, and extract 5, 238, 637unique patterns.
However, only 1, 680, 914 ofthose patterns occur more than twice.
Low fre-quency patterns often contain misspellings and arenot suitable for training.
Therefore, we selectedpatterns that occur at least 10 times in the snip-pet collection.
Moreover, we remove very longpatterns (ca.
over 20 characters).
The final setcontains 140, 691 unique lexical patterns.
The re-mainder of the experiments described in the paperuse those patterns.2http://developer.yahoo.com/search/boss/We use the clustering Algorithm 1 to cluster theextracted patterns.
The only parameter in Algo-rithm 1, the clustering threshold ?, is set as fol-lows.
We vary the value of theta ?
from 0 to 1,and use Algorithm 1 to cluster the extracted setof patterns.
We use the resultant set of clusters torepresent a word pair by a feature vector.
We com-pute a feature from each cluster as follows.
First,we assign a weight wijto a pattern pithat is in acluster cjas follows,wij=?(pi)?q?cj?(q).
(6)Here, ?
(q) is the total frequency of a pattern, and itis given by Equation 5.
Because we perform a hardclustering on patterns, a pattern can belong to onlyone cluster (i.e.
wij= 0 for pi/?
cj).
Finally, wecompute the value of the j-th feature in the featurevector for word pair (a, b) as follows,?pi?cjwijf(a, b, pi).
(7)For each set of clusters, we compute the element?ijof the corresponding inter-cluster correlationmatrix ?
by the cosine similarity between the cen-troid vectors for clusters ciand cj.
The prototypevector ?
in Equation 3 is computed as the vectorsum of individual feature vectors for the synony-mous word pairs selected from the WordNet as de-scribed above.
We then use Equation 3 to computethe average of similarity scores for synonymousword pairs we selected from WordNet.We select the ?
that maximizes the averagesimilarity score between those synonymous wordpairs.
Formally, the optimal value of ?,??
is givenby the following Equation,??
= argmax??
[0,1](1|W |?
(a,b)?Wsim(a, b)).
(8)Here, W is the set of synonymous word pairs(a, b), |W | is the total number of synonymousword pairs (i.e.
2000 in our experiments), andsim(a, b) is given by Equation 3.
Because the av-erages are taken over 2000 word pairs this proce-dure gives a reliable estimate for ?.
Moreover,this method does not require negative traininginstances such as, non-synonymous word pairs,which are difficult to create manually.
Averagesimilarity scores for various ?
values are shownin Figure 2.
From Figure 2, we see that initiallyaverage similarity increases when ?
is increased.809This is because clustering of semantically relatedpatterns reduces the sparseness in feature vectors.Average similarity is stable within a range of ?
val-ues between 0.5 and 0.7.
However, increasing ?beyond 0.7 results in a rapid drop of average sim-ilarity.
To explain this behavior consider Figure3 where we plot the sparsity of the set of clusters(i.e.
the ratio between singletons to total clusters)against threshold ?.
As seen from Figure 3, high ?values result in a high percentage of singletons be-cause only highly similar patterns will form clus-ters.
Consequently, feature vectors for differentword pairs do not have many features in common.The maximum average similarity score of 1.303 isobtained with ?
= 0.7, corresponding to 17, 015total clusters out of which 12, 476 are singletonswith exactly one pattern (sparsity = 0.733).
Forthe remainder of the experiments in this paper weset ?
to this optimal value and use the correspond-ing set of clusters to compute semantic similarityby Equation 3.
Similarity scores computed us-ing Equation 3 can be greater than 1 (see Figure2) because of the terms corresponding to the non-diagonal elements in ?.
We do not normalize thesimilarity scores to [0, 1] range in our experimentsbecause the evaluation metrics we use are insensi-tive to linear transformations of similarity scores.6 ExperimentsTable 1 compares the proposed method againstMiller-Charles ratings (MC), and previously pro-posed web-based semantic similarity measures:Jaccard, Dice, Overlap, PMI (Bollegala et al,2007), Normalized Google Distance (NGD) (Cili-brasi and Vitanyi, 2007), Sahami and Heil-man (SH) (2006), co-occurrence double checkingmodel (CODC) (Chen et al, 2006), and supportvector machine-based (SVM) approach (Bollegalaet al, 2007).
The bottom row of Table 1 shows thePearson correlation coefficient of similarity scoresproduced by each algorithm with MC.
All similar-ity scores, except for the human-ratings in Miller-Charles dataset, are normalized to [0, 1] range forthe ease of comparison.
It is noteworthy that thePearson correlation coefficient is invariant under alinear transformation.
All similarity scores shownin Table 1 except for the proposed method aretaken from the original published papers.The highest correlation is reported by the pro-posed semantic similarity measure.
The improve-ment of the proposed method is statistically sig-nificant (confidence interval [0.73, 0.93]) againstall the similarity measures compared in Table 1except against the SVM approach.
From Table 1we see that measures that use contextual informa-tion from snippets (e.g.
SH, CODC, SVM, andproposed) outperform the ones that use only co-occurrence statistics (e.g.
Jaccard, overlap, Dice,PMI, and NGD) such as page-counts.
This is be-cause similarity measures that use contextual in-formation are better equipped to compute the sim-ilarity between polysemous words.
Although bothSVM and proposed methods use lexical patterns,unlike the proposed method, the SVM methoddoes not consider the relatedness between pat-terns.
The superior performance of the proposedmethod is attributable to its consideration of relat-edness of patterns.Table 2 summarizes the previously proposedWordNet-based semantic similarity measures.
De-spite the fact that the proposed method does notuse manually compiled resources such as Word-Net for computing similarity, its performance iscomparable to similarity measures that use Word-Net.
We believe that the proposed method willbe useful to compute the semantic similarity be-tween named-entities for which manually createdresources are either incomplete or do not exist.We evaluate the proposed method using theWordSimilarity-353 dataset.
Experimental re-sults are presented in Table 3.
Following pre-vious work, we use Spearman rank correlationcoefficient, which does not require ratings to belinearly dependent, for the evaluations on thisdataset.
Likewise with the Miller-Charles ratings,we measure the correlation between the similar-ity scores produced by the proposed method forword pairs in the WordSimilarity-353 dataset andthe human ratings.
A higher Spearman correla-tion coefficient (value=0.504, confidence interval[0.422, 0.578]) indicates a better agreement withthe human notion of semantic similarity.
From Ta-ble 3 we can see that the proposed method outper-forms a wide variety of semantic similarity mea-sures developed using numerous resources includ-ing lexical resources such as WordNet and knowl-edge sources such as Wikipedia (i.e.
WikiRe-late!).
In contrast to the Miller-Charles datasetwhich only contains common English words se-lected from the WordNet, the WordSimilarity-353dataset contains word pairs where one or bothwords are named entities (e.g.
(Maradona, foot-810Table 1: Semantic similarity scores on Miller-Charles datasetWord Pair MC Jaccrad Dice Overlap PMI NGD SH CODC SVM Proposedautomobile-car 3.920 0.650 0.664 0.831 0.427 0.466 0.225 0.008 0.980 0.918journey-voyage 3.840 0.408 0.424 0.164 0.468 0.556 0.121 0.005 0.996 1.000gem-jewel 3.840 0.287 0.300 0.075 0.688 0.566 0.052 0.012 0.686 0.817boy-lad 3.760 0.177 0.186 0.593 0.632 0.456 0.109 0.000 0.974 0.958coast-shore 3.700 0.783 0.794 0.510 0.561 0.603 0.089 0.006 0.945 0.975asylum-madhouse 3.610 0.013 0.014 0.082 0.813 0.782 0.052 0.000 0.773 0.794magician-wizard 3.500 0.287 0.301 0.370 0.863 0.572 0.057 0.008 1.000 0.997midday-noon 3.420 0.096 0.101 0.116 0.586 0.687 0.069 0.010 0.819 0.987furnace-stove 3.110 0.395 0.410 0.099 1.000 0.638 0.074 0.011 0.889 0.878food-fruit 3.080 0.751 0.763 1.000 0.449 0.616 0.045 0.004 0.998 0.940bird-cock 3.050 0.143 0.151 0.144 0.428 0.562 0.018 0.006 0.593 0.867bird-crane 2.970 0.227 0.238 0.209 0.516 0.563 0.055 0.000 0.879 0.846implement-tool 2.950 1.000 1.000 0.507 0.297 0.750 0.098 0.005 0.684 0.496brother-monk 2.820 0.253 0.265 0.326 0.623 0.495 0.064 0.007 0.377 0.265crane-implement 1.680 0.061 0.065 0.100 0.194 0.559 0.039 0.000 0.133 0.056brother-lad 1.660 0.179 0.189 0.356 0.645 0.505 0.058 0.005 0.344 0.132car-journey 1.160 0.438 0.454 0.365 0.205 0.410 0.047 0.004 0.286 0.165monk-oracle 1.100 0.004 0.005 0.002 0.000 0.579 0.015 0.000 0.328 0.798food-rooster 0.890 0.001 0.001 0.412 0.207 0.568 0.022 0.000 0.060 0.018coast-hill 0.870 0.963 0.965 0.263 0.350 0.669 0.070 0.000 0.874 0.356forest-graveyard 0.840 0.057 0.061 0.230 0.495 0.612 0.006 0.000 0.547 0.442monk-slave 0.550 0.172 0.181 0.047 0.611 0.698 0.026 0.000 0.375 0.243coast-forest 0.420 0.861 0.869 0.295 0.417 0.545 0.060 0.000 0.405 0.150lad-wizard 0.420 0.062 0.065 0.050 0.426 0.657 0.038 0.000 0.220 0.231cord-smile 0.130 0.092 0.097 0.015 0.208 0.460 0.025 0.000 0 0.006glass-magician 0.110 0.107 0.113 0.396 0.598 0.488 0.037 0.000 0.180 0.050rooster-voyage 0.080 0.000 0.000 0.000 0.228 0.487 0.049 0.000 0.017 0.052noon-string 0.080 0.116 0.123 0.040 0.102 0.488 0.024 0.000 0.018 0.000Correlation - 0.260 0.267 0.382 0.549 0.205 0.580 0.694 0.834 0.867Table 2: Comparison with WordNet-based simi-larity measures.Method CorrelationEdge-counting 0.664Jiang & Conrath (1998) 0.848Lin (1998a) 0.822Resnik (1995) 0.745Li et al (2003) 0.891ball) and (Jerusalem, Israel)).
Because the pro-posed method use snippets retrieved from a websearch engine, it is capable of extracting expres-sive lexical patterns that can explicitly state the re-lationship between two entities.If we must compare n objects using a featuremodel of similarity, then we only need to definefeatures for each of those n objects.
However, inthe proposed relational model we must define re-lations between all pairs of objects.
In the casewhere all n objects are different, this requires us todefine relations for n(n?1)/2 object pairs.
Defin-ing relations for all pairs can be computationallycostly for large n values.
Efficiently comparing nobjects using a relational model is an interestingfuture research direction of the current work.Table 3: Results on WordSimilarity-353 dataset.Method CorrelationWordNet Edges (Jarmasz, 1993) 0.27Hirst & St-Onge (1997) 0.34Jiang & Conrath (1998) 0.34WikiRelate!
(Strube and Ponzetto, 2006) 0.19-0.48Leacock & Chodrow (1998) 0.36Lin (1998b) 0.36Resnik (1995) 0.37Proposed 0.5047 ConclusionWe proposed a relational model to measure thesemantic similarity between two words.
First, torepresent the numerous semantic relations that ex-ist between two words, we extract lexical patternsfrom snippets retrieved from a web search engine.Second, we cluster the extracted patterns to iden-tify the semantically related patterns.
Third, us-ing the pattern clusters we define a feature vectorto represent two words and compute the semanticsimilarity by taking into account the inter-clustercorrelation.
The proposed method outperformedall existing web-based semantic similarity mea-sures on two benchmark datasets.811ReferencesM.
Berland and E. Charniak.
1999.
Finding parts invery large corpora.
In Proc.
of ACL?99, pages 57?64.D.
Bollegala, Y. Matsuo, and M. Ishizuka.
2007.
Mea-suring semantic similarity between words using websearch engines.
In Proc.
of WWW?07, pages 757?766.H.
Chen, M. Lin, and Y. Wei.
2006.
Novel associationmeasures using web search with double checking.
InProc.
of the COLING/ACL ?06, pages 1009?1016.R.L.
Cilibrasi and P.M.B.
Vitanyi.
2007.
The googlesimilarity distance.
IEEE Transactions on Knowl-edge and Data Engineering, 19(3):370?383.J.
Curran.
2002.
Ensemble menthods for automaticthesaurus extraction.
In Proc.
of EMNLP.B.
Falkenhainer, K.D.
Forbus, and D. Gentner.
1989.Structure mapping engine: Algorithm and examples.Artificial Intelligence, 41:1?63.L.
Finkelstein, E. Gabrilovich, Y. Matias, E. Rivlin,Z.
Solan, G. Wolfman, and E. Ruppin.
2002.
Plac-ing search in context: The concept revisited.
ACMTOIS, 20:116?131.E.
Gabrilovich and S. Markovitch.
2007.
Comput-ing semantic relatedness using wikipedia-based ex-plicit semantic analysis.
In Proc.
of IJCAI?07, pages1606?1611.R.
L. Goldstone.
1994.
The role of similarity in cat-egorization: providing a groundwork.
Cognition,52:125?157.U.
Hahn, N. Chater, and L. B. Richardson.
2003.
Sim-ilarity as transformation.
Cognition, 87:1?32.Z.
Harris.
1954.
Distributional structure.
Word,10:146?162.M.A.
Hearst.
1992.
Automatic acquisition of hy-ponyms from large text corpora.
In Proc.
of 14thCOLING, pages 539?545.G.
Hirst and D. St-Onge.
1997.
Lexical chains as rep-resentations of context for the detection and correc-tion of malapropisms.M.
Jarmasz.
1993.
Roget?s thesaurus as a lexical re-source for natural language processing.
Master?sthesis, University of Ottawa.J.J.
Jiang and D.W. Conrath.
1998.
Semantic similaritybased on corpus statistics and lexical taxonomy.
InProc.
of ROCLING?98.C.
L. Krumhansl.
1978.
Concerning the applicabilityof geometric models to similarity data: The inter-relationship between similarity and spatial density.Psychological Review, 85:445?463.C.
Leacock and M. Chodorow.
1998.
Combining Lo-cal Context and WordNet Similarity for Word SenseIdentification.
MIT.M.
Li, X. Chen, X. Li, B. Ma, and P.M.B.
Vitanyi.2004.
The similarity metric.
IEEE Transactions onInformation Theory, 50(12):3250?3264.D.
Lin.
1998a.
Automatic retreival and clustering ofsimilar words.
In Proc.
of the 17th COLING, pages768?774.D.
Lin.
1998b.
An information-theoretic definition ofsimilarity.
In Proc.
of the 15th ICML, pages 296?304.G.
Miller and W. Charles.
1998.
Contextual corre-lates of semantic similarity.
Language and Cogni-tive Processes, 6(1):1?28.J.
Pei, J. Han, B. Mortazavi-Asi, J. Wang, H. Pinto,Q.
Chen, U. Dayal, and M. Hsu.
2004.
Mining se-quential patterns by pattern-growth: the prefixspanapproach.
IEEE Transactions on Knowledge andData Engineering, 16(11):1424?1440.R.
Rada, H. Mili, E. Bichnell, and M. Blettner.
1989.Development and application of a metric on seman-tic nets.
IEEE Transactions on Systems, Man andCybernetics, 9(1):17?30.P.
Resnik.
1995.
Using information content to evalu-ate semantic similarity in a taxonomy.
In Proc.
ofIJCAI?95.M.
Sahami and T. Heilman.
2006.
A web-based kernelfunction for measuring the similarity of short textsnippets.
In Proc.
of WWW?06.V.
Schickel-Zuber and B. Faltings.
2007.
Oss: A se-mantic similarity function based on hierarchical on-tologies.
In Proc.
of IJCAI?07, pages 551?556.M.
Strube and S. P. Ponzetto.
2006.
Wikirelate!
com-puting semantic relatedness using wikipedia.
InProc.
of AAAI?
06.J.
B. Tenenbaum.
1999.
Bayesian modeling of humanconcept learning.
In NIPS?99.A.
Tversky.
1977.
Features of similarity.
Psychologi-cal Review, 84:327?652.D.
McLean Y. Li, Zuhair A. Bandar.
2003.
An ap-proch for measuring semantic similarity betweenwords using multiple information sources.
IEEETransactions on Knowledge and Data Engineering,15(4):871?882.812
