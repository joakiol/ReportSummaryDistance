THE PRC PAKTUS SYSTEM :MUC-4 TEST RESULTS AND ANALYSI SBruce 1:oatmanPRC Inc.Technology Division1500 PRC Drive, McLean, VA 22102loatman_bruce @po.gis.prc.comINTRODUCTIONIn commenting on PRC's performance in MUC-3, we reported [1] that the component of ou rsystem that could most improve performance was discourse analysis .
The MUC-4 exercise hasstrongly confirmed that view.
We added a new discourse module to PAKTUS, made very fe wchanges to the other system components, and the result was significantly improved performance .This paper discusses our test results, what we focused on for this task, what worked well, andwhat would improve performance further .
A companion paper in this volume describes how ou rsystem functions.KEY SYSTEM FEATURE SThe PRC PAKTUS system used for MUC-4 is essentially the same linguistic system that w eused for MUC-3, with the addition of a generic discourse analysis module .
PAKTUS applieslexical, syntactic, semantic, and discourse analysis to all text in each document.
The linguisticmodules for this are nearly independent of the task domain (i .e ., MUC-4, but some of the data ?lexical entries, and a few grammar rules ?
are tuned for the MUC-4 text corpus).
Task-specifictemplate filling and filtering operations are performed only after linguistic analysis is completed .The task-specific patterns that determine what to extract from the discourse structures wer eonly minimally defined due to the limited time and effort available .
The other task-specificadditions to the system were the location set list, and functions for better recognizing time andlocation of events.RESULTSFigure 1 summarizes PRC's scores for MUC-4.
The scoring notation is explained inAppendix G. Overall, we were pleased with the performance improvement since MUC-3, whichwas obtained with only about 4 person months of linguistic development effort, little of which wa sspecific to the MUC-4 task.
The most significant new development, compared to our MUC- 3system, is the addition of the discourse analysis module .
This module is generic for expositorydiscourse such as is found in news reports.
Application-specific extraction requirements ar emaintained separately from the discourse module, are applied only after it executes, and wereminimally specified for MUC-4.Our system generally had much better precision than recall in these tests .
We expected thisbecause it uses complete linguistic analysis designed for text understanding, and because it ha sonly a very limited amount of task-specific knowledge .
For example, its discourse analysi smodule was trained on only 8 of the MUC-4 pre-test corpus of 1500 reports .
For these same132reasons, we also expected a high degree of corpus independence, and this was supported by thesimilarity of scores on TST3 and TST4.The main limiting factors for PRC were time and availability of people for development.
Wedirected most of our energies to generic linguistic development, and the linguistic aspects of th etask have essentially been completed .
Because we had little time remaining to devote to MUC-4-specific issues, however, much of the information that PAKTUS produced through syntactic ,semantic, and discourse analysis did not find its way into the template fills .POSACTICOR PAR INCIICR IPAISPU MISNONIREC PRE OVG FAL------------------------------ ----------- ------- ----------- -------------- -TST3MATCHED/MISSING 1552 6411364 128851 8 73164 975 11661 28 67 1 0MATCHED/SPURIOUS 1009 10421364 128851 8 731465 432 12171 42 41 45MATCHED ONLY 1009 6411364 128851 8 73164 4326251 42 67 10ALL TEMPLATES 1552 10421364 128851 8 731465 975 17581 28 41 45SET FILLS ONLY 742 3031199 39391 0 20126 4655461 29 72 8 0STRING FILLS ONLY 401 129162 19241 7 19124 2963281 18 55 19TEXT FILTERING 66 56148 **I * *18 18261 73 86 14 24F-MEASURES P&R 2P&R P&2RAll Templates 33 .28 37 .52 29 .9 01ST 27 .87 24 .02 33 .171MT 39 .39 47 .02 33 .89NST 49 .52 57 .78 43 .3 32MT 26 .26 27 .84 24 .86----------------------------- ----------- ------- ----------- ---------------TSTQMATCHED/MISSING 1155 480127983 781 29 38140 715 7531 28 67 8MATCHED/SPURIOUS 703 803127983 781 29 381363 263 8891 46 40 45MATCHED ONLY 703 480127983 781 29 38140 263 4031 46 67 8ALL TEMPLATES 1155 803127983 781 29 381363 715 12391 28 40 45SET FILLS ONLY 566 239114529 441 7 14121 348 3371 28 67 9 0STRING FILLS ONLY 298 981629 151 13 9112 212 2141 22 68 12TEXT FILTERING 54 51139* *1 * *11215 341 72 76 24 26F-MEASURES.
P&R 2P&R P&2RAll Templates 32 .94 36 .84 29 .79Figure 1.
PRC Score SummaryDEVELOPMENT EFFORTThree PRC researchers participated in linguistic development that contributed to MUC-4performance.
Most of this development was generic, however, and will support applications otherthan MUC-4.
Figure 2 shows an estimate of our level of effort broken down by linguistic task.Our total linguistic development effort was about four months, with almost 40% of that ondiscourse analysis .
Significant effort also went into time and location grammar functions, althoughthis is small compared to the prior effort that went into the overall grammar.Lexicon entry was minimal, consisting primarily of semi-automatic entry of the MUC- 4location set list.
Many words from the MUC-4 corpus have never been entered into the PAKTU Slexicon.
Instead, heuristics based on word morphology make guesses about these unrecognizedwords.The specific changes and additions to the PAKTUS knowledge bases for MUC-4 areenumerated in Figure 3 .
Most of the lexical additions were from the MUC-4 location set list .These were added semi-automatically in batch mode.
Other lexical additions were based on short13 3lists of exceptions to our unknown word heuristics, derived by scanning traces from the entir e1500 document MUC-4 pre-test corpus .?
Discourse 1.65 months?
Output Template and Format 0 .25?
Lexicon Entry 0.25?
Time & Location grammar 1 .50-Preprocessor 0.16?
Lexicon Problem Identification 0 .25?Other Troubleshooting	 0 .31TOTAL4.37 monthsFigure 2.
Breakdown of Linguistic Development EffortsOne notable area that would have significantly improved performance was the definition o fMUC-4-specific conceptual patterns .
These are used to extract information from the discoursestructures.
Very little was done here, however, due to limited time and resources .
Only 88 ofthese patterns were added .
We had intended to define several hundred, but that would haverequired about another month of effort.Figure 3.
Additions/ Modifications to PAKTUS Knowledge Bases for MUC-4SYSTEM TRAINING AND PERFORMANCE IMPROVEMENTAs already noted, the most significant system improvement was in discourse analysis .
Thenew discourse module was trained on only 8 documents from the test2 set .
These were documents1, 3, 10, 11, 48, 63, 99, and 100 .
The time and location grammar and functional changes werebased on manual analysis of the 100 test2 documents .
The entire pre-test corpus was scanne dautomatically to identify words missing from our lexicon, but only a few of these were entered ?those more common words that did not conform to our unrecognized word heuristics .The improvement in PAKTUS's linguistic performance from MUC-3 up to the day of testin gfor MUC-4 can be seen in Figure 4, derived from the test runs on the test2 corpus, using the F-measure specified for MUC-4.
The development was carried out during April and May, 1992 .The basic functionality of the new discourse module was completed on May 6, and i tdramatically improved performance.
This module has two main functions : 1) it builds discoursetopic structures, and 2) it unifies noun phrases that refer to the same entity .
There is a ratherKnowledge Tvpe,Words (Stems)TokensCompoundsIdiomsVerb categoriesNominal categoriesAdverb categoriesClosed categoriesGrammar ArcsGrammar StatesConceptsSubconceptsConceptual PatternsDomain TemplateCore SystemNew/ Mod for MUC-46,3142,43610,3662,532237360712160407010041026547803860180318801134intricate interaction between these two functions, and this had to be carefully developed over th enext ten days (through May 17), so that improvement in one function did not impair the other .After completion of the two basic discourse functions, enhancements (pronoun reference, etc .
)were added to the discourse module, through May 25 .
This allowed only three days for MUC-4 -specific knowledge to be added that could take advantage of the new discourse module .It can be seen from figure 4 that, once the discourse functions were properly integrated (o nMay 17), performance improvement averaged one point per day over the last eleven days befor eofficial MUC-4 testing .
We believe that the system is far from the limit of its extraction capabilit ybased on its existing linguistic components .
This belief is supported by the ease with which weimproved performance on the MUC-4 conference walkthrough document (test2, document 48) byadding a few MUC-4-specific conceptual patterns .Figure 4.
Performance Improvement During Developmen tREUSABILITY OF THE SYSTEMAlmost all of PAKTUS is generic and can be applied to other applications .
All of itsprocesses, including the new discourse analysis module, are generic .
They operate on a set ofobject-oriented knowledge bases, some of which are generic (common English grammar andlexicon) and some of which are domain-specific (conceptual templates) .The primary tasks in applying PAKTUS to a new domain or improving its performance in anexisting domain, are lexicon addition and conceptual template specification, both of which ar erelatively easy (compared to changing the grammar, for example) .Two other tasks that must be done, but only once for each new domain, are specifying th einput document formats, and the output specifications.
These are template-driven in PAKTUS .40302 5201 51 050MUC-3 DryRun 4/30 5/1 5 17 18 19 21 2527 28356 12141 0Basic NewDiscourse Topic!Discourse Method	 NP Unification IntegrationTemporalReference\135For MUC-4 we used the template supplied by NRaD, adding a function for each template slot togather information from our generic discourse data structures .WHAT WE LEARNEDAbout PAKTUSWe learned that the current implementation of PAKTUS, including the new discourse module ,is robust and adaptable.
The more complex components (syntactic, semantic, and discours eanalysis modules) are stable and competent enough to apply the system to different domains an dproduce useful results, by adding domain-specific knowledge (lexicon and conceptual patterns) .We were particularly pleased to learn that it was not necessary to manually analyze much of th ecorpus in detail .
This was done for only eight documents for MUC-4.
The full developmentcorpus was used only for lexicon development and testing the system for overall performance an dlogic errors.About the TaskMUC-4 reinforced our appreciation of the importance of clearly defined output specifications ,and the utility of having answer keys against which to measure the system's progress .
We arealready using the MUC-4 task specifications as a model for a new application of our system .We have also come to appreciate the utility of an automated scoring program to thedevelopment effort.
This quickly eliminates much uncertainty about whether a new development i suseful or not, and thereby speeds system development.About EvaluationIt is difficult to define evaluation measures for a task of this nature .
Although the MUC-4measures seem better than those of MUC-3, they do not accurately convey the true performance insome situations .
For example, the system might correctly fill in 75% of the information for atemplate, but not report it because it got the wrong date (events over three months old are no treported), or the wrong country .
We would prefer to report all incidents, with an extra slotindicating whether they are considered relevant or not.
This seems more appropriate for evaluatin glinguistic competence .
We also suspect that many analysts using such a system would like to beable to identify "irrelevant" incidents, especially since, given the current limits of linguistictechnology, they may be relevant after all .REFERENCE[1] Kariya, C, "PRC PAKTUS: MUC-3 Test Results and Analysis", Proceedings of the 3rdMessage Understanding Conference, San Mateo, CA: Morgan Kaufmann, 1991 .136
