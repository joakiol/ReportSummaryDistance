Proceedings of Frame Semantics in NLP: A Workshop in Honor of Chuck Fillmore (1929?2014), pages 30?33,Baltimore, Maryland USA, June 27, 2014.c?2014 Association for Computational LinguisticsUsing Frame Semantics in Natural Language ProcessingApoorv AgarwalDept.
of Computer ScienceColumbia UniversityNew York, NYapoorv@cs.columbia.eduDaniel BauerDept.
of Computer ScienceColumbia UniversityNew York, NYbauer@cs.columbia.eduOwen RambowCCLSColumbia UniversityNew York, NYrambow@ccls.columbia.eduAbstractWe summarize our experience usingFrameNet in two rather different projectsin natural language processing (NLP).We conclude that NLP can benefit fromFrameNet in different ways, but we sketchsome problems that need to be overcome.1 IntroductionWe present two projects at Columbia in which weuse FrameNet.
In these projects, we do not de-velop basic NLP tools for FrameNet, and we donot develop FramNets for new languages: we sim-ply use FrameNet or a FrameNet parser in an NLPapplication.
The first application concerns the ex-traction of social networks from narrative texts.The second application aims at generating three-dimensional pictures from textual descriptions.The applications are very different: they differin terms of their goals, and they differ in termsof how they use FrameNet.
However, they havein common that they can use FrameNet because itprovides a particular level of semantic abstractionwhich is suited for both applications.
Considerverbs of saying, such as declare, deny, mention,remark, tell, or say: they do not have the samemeaning.
However, they share enough commonmeaning, and in particular they share the same setof participants, so that for our two applicationsthey can be considered as interchangeable: theyrepresent the communication of verbal informa-tion (the Message) from a Speaker to an Ad-dressee.
This is precisely what the Statementframe encodes.
We will use this example in thenext two sections, in which we discuss our twoprojects in more detail.2 Using an Off-the-Shelf FrameNetParserOur first application is SINNET, a system that ex-tracts a social network from narrative text.
It usesthe notion of a social event (Agarwal et al., 2010),a particular kind of event which involves (at least)two people such that at least one of them is awareof the other person.
If only one person is awareof the event, we call it Observation (OBS): forexample, someone is talking about someone elsein their absence.
If both people are aware of theevent, we call it Interaction (INR): for example,one person is telling the other a story.
Our claimis that links in social networks are in fact madeup of social events: OBS social events give riseto one-way links, and INR social events to two-way links.
For more information, see (Agarwaland Rambow, 2010; Agarwal et al., 2013a; Agar-wal et al., 2013b).From an NLP point of view, we have a difficultcluster of phenomena: we have a precise defini-tion of what we want to find, but it is based on thecognitive state of the event participants, which isalmost never described explicitly in the text.
Fur-thermore, the definitions cover a large number ofdiverse situations such as talking, spying, havinglunch, fist fighting, or kissing.
Furthermore, somesemantic differences are not relevant: verbs suchas talk, tell, deny, all have the same meaning withrespect to social events.
Finally, in order to de-code the events in terms of social events, we needto understand the roles: if I am talking to Sudeepabout Mae, Sudeep and I have an INR social eventwith each other, and we both have a OBS socialevent with Mae.
Thus, this problem sounds likean excellent application for frame semantics!We present initial results in (Agarwal et al.,2014), and summarize them here.
We use Semafor(Chen et al., 2010) as a black box to obtain the se-mantic parse of a sentence.
However, there areseveral problems:?
FrameNet does not yet have complete lexicalcoverage.?
Semafor does not produce a single semantic30representation for a sentence, as we wouldwant in order to perform subsequent process-ing.
Instead, it annotates separate, discon-nected frame structures for each frame evok-ing element it finds.?
The data annotated with FrameNet consistsof the example sentences as well as a compar-atively small corpus.
For this reason, it is noteasy to use standard machine learning tech-niques for frame semantic parsing.
As a re-sult, the output is fairly errorful (as comparedto, say, a state-of-the-art dependency parsertrained on nearly a million annotated words).Errors include mislabeled frames, mislabeledframe elements, and missing frame elements.To overcome these problems, we constructedseveral tree representations out of the partial an-notations returned by Semafor.
We then used treekernels on these syntactic and semantic tree rep-resentations, as well as bags of words.
The treekernels can automatically identify important sub-structures in the syntactic and semantic trees with-out the need for feature engineering on our part.Our hypothesis is that the kernels can learn whichparts of the semantic structures are reliable andcan be used for prediction.The tree structures are shown in Figure 1.
Thestructure on the left (FrameForest) is created bytaking all identified instances of frames, and col-lecting them under a common root node.
Theframe elements are filled in with dependency syn-tax.
The structure on the right (FrameTree) is ourattempt to create a single arborescent structure tocapture the semantics of the whole sentence.
Ourthird structure, FrameTreeProp (not shown), is de-rived from FrameTree by multiplying the nodes ofinterest up the path from their normal place to theroot.
This allows us to overcome problems withthe limited locality of the tree kernels.We present some results in Table 1.
Compar-ing lines ?Syntax?
with ?Synt FrameTreeProp?,we see a slight but statistically significant increase.This increase comes from using FrameNet seman-tics.
When we look at only the semantic structures,we see that they all perform worse than syntax onits own.
?BOF?
is simply a bag of frames; wesee that the arborescent structures outperform it,so semantic structure is useful in addition to se-mantic tags.
?RULES?
is a comprehensive set ofhand-written rules we attached to frames; if frameDetectionModel P R F1Syntax 0.464 0.751 0.574RULES 0.508 0.097 0.164BOF 0.296 0.416 0.346FrameForest 0.331 0.594 0.425FrameTree 0.295 0.594 0.395FrameTreeProp 0.308 0.554 0.396All 0.494 0.641 0.558Synt FrameTreeProp 0.484 0.740 0.585Table 1: Results for Social Event Detection.?Syntax?
is an optimized model using varioussyntactic representations (Agarwal and Rambow,2010).
The next five models are the novel se-mantic features and structures.
?All?
refers to themodel that uses all the listed structures together.
?Synt FrameTreeProp?
is a linear combination of?Syntax?
and FrameTreeProp.semantic parsing were perfect, these rules shouldperform pretty well.
They do in fact achieve thebest precision of all our systems, but the recall isso low that overall they are not useful.
We inter-pret this result as supporting our claim that part ofthe problem with using frame-semantic parsers isthe high error rate.Even though the gain so far from frame seman-tic parsing is small, we are encouraged by the factthat an off-the-shelf semantic parser can help atall.
We are currently exploring other semanticstructures we can create from the semantic parse,including structures which are dags rather thantrees.
We would like to point out that the com-bination of the parser, the creation of our seman-tic trees, and the training with tree kernels can beapplied to any other problem that is sensitive tothe meaning of text.
Based on our experience, weexpect to see an increase in ?black box?
uses ofFrameNet parsing for other applications in NLP.3 Extending the FrameNet ResourceFrameNet can be a useful starting point for a richerknowledge representation which is needed for aspecific task.
In our example, we need a repre-sentation that we can use in the WordsEye project(Coyne and Sproat, 2001), in which pictures arecreated automatically from text descriptions.
Thiscan be understood as providing a particular typeof decompositional semantics for the input text.31ROOTCommerce buyTarget4BuyerT1-IndSellerfromT2-GrpStatementTargetclaimed4SpeakerT1?-IndMessage4StatementSpeakerT1-IndColemanMessageCommerce buyBuyerT1?-IndheSellerT2-GrpdefendantsFigure 1: Semantic trees for the sentence ?Coleman claimed [he]T1?Indbought drugs from the[defendants]T2?Grp.?.
The tree on the left is FrameForest and the tree on the right is FrameTree.
4in FrameForest refers to the subtree (bought (T1-Ind) (from T2-Grp)).
Ind refers to individual and Grprefers to group.We extend FrameNet in two ways to obtain the re-source we need, which we call VigNet (Coyne etal., 2011).The pictures created by the WordsEye systemare based on spatial arrangements (scenes) of pre-defined 3D models.
At a low level, scenes are de-scribed by primitive spatial relations between setsof these models (The man is in front of the woman.He is looking at her.
His mouth is open.).
Wewould like to use WordsEye to depict scenarios,events, and actions (John told Mary his life story).These can be seen as complex relations betweenevent participants.We turn to FrameNet frames as representationsfor such relations.
FrameNet offers a large in-ventory of frames, together with additional struc-tured information about them in the form of framerelations.
Most importantly, FrameNet providesexample annotations illustrating the patterns inwhich frames are evoked and syntactic argumentsare mapped to frame elements.However, there are two main problems if wewant to turn frame annotations into pictures.
First,in frame annotations frame elements are only filledwith text spans, not with semantic objects.
Anno-tations are therefore restricted to individual predi-cate/argument structures and do not represent themeaning of a full sentence.
To address this prob-lem we essentially use FrameNet frames as an in-ventory of predicates in a graph-based semanticrepresentation.
We use semantic nodes, which areidentifiers representing events and entities that fillframe elements.
Frame instances then describe re-lations between these semantic nodes, building agraph structure that can represent a full text frag-ment (including coreference).
We are planningto develop parsers that convert text directly intosuch graph-based representations, inspired by re-cent work on semantic parsing (Jones et al., 2012).Second, FrameNet frames usually describefunctional relationships between frame elements,not graphical ones.
To turn a frame into its graphi-cal representation we therefore need (a) a set of ofgraphical frames and a formal way of decompos-ing these frames into primitives and (b) a mech-anism for relating FrameNet frames to graphi-cal frames.
Our solution is VigNet (Coyne etal., 2011), an extension of FrameNet.
VigNetmakes use of existing frame-to-frame relationsto extend FrameNet with a number of graphicalframes called Vignettes.
Vignettes are subframesof FrameNet frames, each representing a specificway in which a frame can be realized based on thespecific lexical unit or on context.
For instance,a proper visualization of the INGESTION framewill depend on the INGESTOR (human vs. ani-mals of different sizes), the INGESTIBLE (differ-ent types of foods and drinks are ingested accord-ing to different social conventions, each a differ-ent Vignette).
Note however, that many FrameNetframes provide useful abstractions that allow usto use a single Vignette as a good default visu-alization for the entire frame.
For instance, alllexical units in the STATEMENT frame can be de-picted as the SPEAKER standing opposite of theADDRESSEE with an open mouth.A new frame-to-frame relation, called subframeparallel, is used to decompose a Vignette into32graphical sub-relations, which are in turn frames(either graphical primitives or other vignettes).Like any frame-to-frame relation, it maps frameelements of the source frame to frame elementsof the target frame.
New frame elements can alsobe introduced.
For instance, one Vignette for IN-GESTION that can be used if the INGESTIBLE is aliquid contains a new frame element CONTAINER.The INGESTOR is holding the container and theliquid is in the container.We have populated the VigNet resource us-ing a number of different approaches (Coyne etal., 2012), including multiple choice questions onAmazon Mechanical Turk to define vignettes forlocations (rooms), using the system itself to definelocations, and a number of web-based annotationtools to define vignettes for actions.An ongoing project is exploring the use ofWordsEye and VigNet as a tool for field linguistsand for language documentation and preserva-tion.
The WordsEye Linguistics Toolkit (WELT,(Ulinski et al., 2014)) makes it easy to producepictures for field linguistic elicitation.
It willalso provide an environment to essentially de-velop language specific VigNets as models of thesyntax/semantics interface and conceptual cate-gories.
This work may be relevant to other projectsthat aim to build non-English and multi-lingualFrameNets.4 ConclusionWe have tried to motivate the claim that FrameNetprovides the right layer of semantic abstractionfor many NLP applications by summarizing twoongoing NLP projects at Columbia.
We havealso suggested that part of the problem in usingFrameNet in NLP projects is the lack of a singlestructure that is produced, either in manual anno-tations, or in the output of a FrameNet parser.
Wesuspect that research into how to construct suchunified semantic representations will continue tobe a major component of the use of FrameNet inNLP.AcknowledgmentsThis paper is based upon work supported in part bythe NSF (grants IIS-0713548 and IIS-0904361),and by the DARPA DEFT Program.
We thankour collaborators on the two projects used as ex-amples in this extended abstract.
We thank ChuckFillmore for FrameNet.ReferencesApoorv Agarwal and Owen Rambow.
2010.
Automatic de-tection and classification of social events.
In Proceedingsof the 2010 Conference on Empirical Methods in Natu-ral Language Processing, pages 1024?1034, Cambridge,MA, October.
Association for Computational Linguistics.Apoorv Agarwal, Owen C. Rambow, and Rebecca J. Passon-neau.
2010.
Annotation scheme for social network ex-traction from text.
In Proceedings of the Fourth LinguisticAnnotation Workshop.Apoorv Agarwal, Anup Kotalwar, and Owen Rambow.2013a.
Automatic extraction of social networks from lit-erary text: A case study on alice in wonderland.
In theProceedings of the 6th International Joint Conference onNatural Language Processing (IJCNLP 2013).Apoorv Agarwal, Anup Kotalwar, Jiehan Zheng, and OwenRambow.
2013b.
Sinnet: Social interaction network ex-tractor from text.
In Sixth International Joint Conferenceon Natural Language Processing, page 33.Apoorv Agarwal, Sriramkumar Balasubramanian, Anup Ko-talwar, Jiehan Zheng, and Owen Rambow.
2014.
Framesemantic tree kernels for social network extraction fromtext.
In Proceedings of the 14th Conference of the Euro-pean Chapter of the Association for Computational Lin-guistics, Gothenburg, Sweden.Desai Chen, Nathan Schneider, Dipanjan Das, and Noah A.Smith.
2010.
Semafor: Frame argument resolution withlog-linear models.
In Proceedings of the 5th InternationalWorkshop on Semantic Evaluation, pages 264?267, Up-psala, Sweden, July.
Association for Computational Lin-guistics.Bob Coyne and Richard Sproat.
2001.
Wordseye: an au-tomatic text-to-scene conversion system.
In 28th annualconference on Computer graphics and interactive tech-niques.Bob Coyne, Daniel Bauer, and Owen Rambow.
2011.
Vi-gnet: Grounding language in graphics using frame seman-tics.
In ACL Workshop on Relational Semantics (RELMS),Portland, Oregon.Bob Coyne, Alex Klapheke, Masoud Rouhizadeh, RichardSproat, and Daniel Bauer.
2012.
Annotation tools andknowledge representation for a text-to-scene system.
InCOLING, Mumbai, India.Bevan Jones, Jacob Andreas*, Daniel Bauer*, Karl MoritzHermann*, and Kevin Knight.
2012.
Semantics-basedmachine translation with hyperedge replacement gram-mars.
In COLING, Mumbai, India.
*first authorshipshared.Morgan Ulinski, Anusha Balakrishnan, Daniel Bauer, BobCoyne, Julia Hirschberg, and Owen Rambow.
2014.
Doc-umenting endangered languages with the wordseye lin-guistics tool.
In Proceedings of the ACL ComputEL work-shop: The use of computational methods in the study ofendangered languages, Baltimore, MD, USA.33
