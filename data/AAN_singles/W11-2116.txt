Proceedings of the 6th Workshop on Statistical Machine Translation, pages 140?144,Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational LinguisticsThe UPV-PRHLT combination system for WMT 2011Jesu?s Gonza?lez-Rubio and Francisco CasacubertaInstituto Tecnolo?gico de Informa?ticaDepartamento de Sistemas Informa?ticos y Computacio?nUniversitat Polite`cnica de Vale`ncia{jegonzalez|fcn}@dsic.upv.esAbstractThis paper presents the submissions of the pat-tern recognition and human language technol-ogy (PRHLT) group to the system combina-tion task of the sixth workshop on statisticalmachine translation (WMT 2011).
Each sub-missions is generated by a multi-system mini-mum Bayes risk (MBR) technique.
Our tech-nique uses the MBR decision rule and a linearcombination of the component systems?
prob-ability distributions to search for the minimumrisk translation among all the sentences in thetarget language.1 IntroductionThe UPV-PHRLT approach to machine translation(MT) system combination is based on the mini-mum Bayes risk system combination (MBRSC) al-gorithm (Gonzlez-Rubio et al, 2011).
A multi-system MBR technique that computes consensustranslations over multiple component systems.MBRSC operates directly on the outputs of thecomponent models.
We perform an MBR decod-ing using a linear combination of the componentmodels?
probability distributions.
Instead of re-ranking the translations provided by the componentsystems, we search for the hypothesis with the min-imum expected translation error among all the pos-sible finite-length strings in the target language.
Byusing a loss function based on BLEU (Papineni etal., 2002), we avoid the hypothesis alignment prob-lem that is central to standard system combinationapproaches (Rosti et al, 2007).
MBRSC assumesonly that each translation model can produce expec-tations of n-gram counts; the latent derivation struc-tures of the component systems can differ arbitrary.This flexibility allows us to combine a great varietyof MT systems.2 Minimum Bayes risk DecodingSMT can be described as a mapping of a word se-quence f in a source language to a word sequencee in a target language; this mapping is produced bythe MT decoder D(f).
If the reference translatione is known, the decoder performance can be mea-sured by the loss function L(e,D(f)).
Given such aloss function L(e, e?)
between an automatic transla-tion e?
and a reference e, and an underlying proba-bility model P (e|f), MBR decoding has the follow-ing form (Goel and Byrne, 2000; Kumar and Byrne,2004):e?
= arg mine??ER(e?)
(1)= arg mine?
?E?e?EP (e|f) ?
L(e, e?)
, (2)where R(e?)
denotes the Bayes risk of candidatetranslation e?
under loss function L, and E repre-sents the space of translations.If the loss function between any two hypothesescan be bounded: L(e, e?)
?
Lmax, the MBR de-coder can be rewritten in term of a similarity func-tion S(e, e?)
= Lmax ?
L(e, e?).
In this case, in-stead of minimizing the Bayes risk, we maximizethe Bayes gain G(e?):e?
= arg maxe??EG(e?)
(3)= arg maxe?
?E?e?EP (e|f) ?
S(e, e?)
.
(4)MBR decoding can use different spaces for hy-pothesis selection and gain computation (arg maxand sum in Eq.
(4)).
Therefore, the MBR decodercan be more generally written as follows:e?
= arg maxe?
?Eh?e?EeP (e|f) ?
S(e, e?)
, (5)140where Eh refers to the hypotheses space form wherethe translations are chosen and Ee refers to the evi-dences space that is used to compute the Bayes gain.We will investigate the expansion of the hypothesesspace while keeping the evidences space as providedby the decoder.3 MBR System CombinationMBRSC is a multi-system generalization of MBRdecoding.
It uses the MBR decision rule on a linearcombination of the probability distributions of thecomponent systems.
Unlike existing MBR decodingmethods that re-rank translation outputs, MBRSCsearch for the minimum risk hypotheses on the com-plete set of finite-length hypotheses over the out-put vocabulary.
We assume the component systemsto be statistically independent and define the Bayesgain as a linear combination of the Bayes gainsof the components.
Each system provides its ownspace of evidences Dn(f) and its posterior distribu-tion over translations Pn(e|f).
Given a sentence f inthe source language, MBRSC is written as follows:e?
= arg maxe??EhG(e?)
(6)?
arg maxe?
?EhN?n=1?n ?
Gn(e?)
(7)= arg maxe?
?EhN?n=1?n ?
?e?Dn(f)Pn(e|f) ?
S(e, e?)
, (8)where N is the total number of component systems,Eh represents the hypotheses space where the searchis performed, Gn(e?)
is the Bayes gain of hypothe-sis e?
given by the nth component system and ?n isa scaling factor introduced to take into account thedifferences in quality of the component models.
It isworth mentioning that by using a linear combinationinstead of a mixture model, we avoid the problemof component systems not sharing the same searchspace (Duan et al, 2010).3.1 Computing BLEU-based GainWe are interested in performing MBRSC underBLEU.
Therefore, we rewrite the gain function G(?
)using single evidence (or reference) BLEU (Pap-ineni et al, 2002) as the similarity function:Gn(e?)
=?e?Dn(f)Pn(e|f) ?
BLEU(e, e?)
(9)BLEU =4?k=1(mkck) 14?min(e1?rc , 1.0), (10)where r is the length of the evidence, c the length ofthe hypothesis, mk the number of n-gram matchesof size k, and ck the count of n-grams of size k inthe hypothesis.The evidences space Dn(f) may contain a hugenumber of hypotheses1 which often make impracti-cal to compute Eq.
(9) directly.
To avoid this prob-lem, Tromble et al (2008) propose linear BLEU, anapproximation to the BLEU score to efficiently per-form MBR decoding on the lattices provided by thecomponent systems.
However, we want to explore ahypotheses space not restricted to the evidences pro-vided by the systems.In Eq.
(9), we have one hypothesis e?
that is to becompared to a set of evidences e ?
Dn(f) whichfollow a probability distribution Pn(e|f).
Insteadof computing the expected BLEU score by calcu-lating the BLEU score with respect to each of theevidences, our approach will be to use the expectedn-gram counts and sentence length of the evidencesto compute a single-reference BLEU score.
We re-place the reference statistics (r and mn in Eq.
(10))by the expected statistics (r?
and m?n) given the pos-terior distribution Pn(e|f) over the evidences:Gn(e?)
=4?k=1(m?kck) 14?min(e1?r?c , 1.0)(11)r?
=?e?Dn(f)|e| ?
Pn(e|f) (12)m?k =?ng?Nk(e?)min(Ce?
(ng), C?
(ng)) (13)C ?
(ng) =?e?Dn(f)Ce(ng) ?
Pn(e|f) , (14)where Nk(e?)
is the set of n-grams of size k in thehypothesis, Ce?
(ng) is the count of the n-gram ng in1For example, in a lattice the number of hypotheses may beexponential in the size of its state set.141the hypothesis and C ?
(ng) is the expected count ofng in the evidences.
To compute the n-gram match-ings m?k, the count of each n-gram is truncated, ifnecessary, to not exceed the expected count for thatn-gram in the evidences.We have replaced a summation over a possibly ex-ponential number of items (e?
?
Dn(f) in Eq.
(9))with a summation over a polynomial number of n-grams that occur in the evidences2.
Both, the ex-pected length of the evidences r?
and their expectedn-gram counts m?k can be pre-computed efficientlyfrom N -best lists and translation lattices (Kumar etal., 2009; DeNero et al, 2010).3.2 Model TrainingThe scaling factors in Eq.
(8) denote the ?quality?
ofeach system with respect to the rest of them, i.e.
therelative importance of each system in the Bayes gaincomputation.
This scaling factors must be carefullytuned to obtain good translations.We compute the scaling factor of each system asthe number of times the hypothesis of the system isthe best TER-scoring translation in the tuning cor-pora.
Previous works show that this measure ob-tains the best translation results among other heuris-tic measures (Gonza?lez-Rubio et al, 2010) and evenas good results as more complex methods such asMERT (Och, 2003).
A normalization is performedto transform these counts into the range [0.0, 1.0].After the normalization, a weight value of 0.0 is as-signed to the lowest-scoring system, i.e.
the lowest-scoring system is discarded and not taken into ac-count in the computation of the Bayes gain.3.3 Model DecodingIn most MBR algorithms, the hypotheses space isequal to the evidences space.
However, we are inter-ested in extend the hypotheses space by includingnew sentences created using fragments of the hy-potheses in the evidences spaces of the componentmodels.
We perform the search (argmax opera-tion in Eq.
(8)) using the approximate median string(AMS) algorithm (Mart?
?nez et al, 2000).
AMSalgorithm perform a hill-climbing search on a hy-potheses space equal to the free monoid ??
of thevocabulary of the evidences ?
= V oc(Ee).2If Dn(f) is represented by a lattice, the number of n-gramsAlgorithm 1 MBRSC decoding algorithm.Require: Initial hypothesis eRequire: Vocabulary the evidences ?1: e??
e2: repeat3: ecur ?
e?4: for j = 1 to |ecur| do5: e?s ?
ecur6: for a ?
?
do7: e?s ?
Substitute(ecur, a, j)8: if G(e?s) > G(e?s) then9: e?s ?
e?s10: e?d ?
Delete(ecur, j)11: e?i ?
ecur12: for a ?
?
do13: e?i ?
Insert(ecur, a, j)14: if G(e?i) > G(e?i) then15: e?i ?
e?i16: e??
arg maxe??
{ecur,e?s,e?d,e?i} G(e?
)17: until G(e?)
6> G(ecur)18: return ecurEnsure: G(ecur) ?
G(e)The AMS algorithm is shown in Algorithm 1.AMS starts with an initial hypothesis e3 that is mod-ified using edit operations until there is no improve-ment in the Bayes gain (Lines 3?16).
On each posi-tion j of the current solution ecur, we apply all thepossible single edit operations: substitution of thejth word of ecur by each word a in the vocabulary(Lines 5?9), deletion of the jth word of ecur (Line10) and insertion of each word a in the vocabulary inthe jth position of ecur (Lines 11?15).
If the Bayesgain of any of the new edited hypotheses is higherthan the Bayes gain of the current hypothesis (Line17), we repeat the loop with this new hypotheses e?,in other case, we return the current hypothesis.AMS algorithm takes as input an initial hypothe-sis e and the combined vocabulary of the evidencesspaces ?.
Its output is a possibly new hypothesiswhose Bayes gain is assured to be higher or equalthan the Bayes gain of the initial hypothesis.The complexity of the main loop (lines 2-17) isO(|ecur| ?
|?| ?
CG), where CG is the cost of com-is polynomial in the number of edges in the lattice.3In the experimentation we use the evidence with minimumBayes?
risk as the initial hypothesis of the algorithm.142cz?en en?cz de?en en?de es?en en?es fr?en en?fr#systems 12 14 25 34 15 22 23 21devWorst 15.6 8.8 12.8 4.5 15.1 20.3 15.8 13.9Best 25.9 16.9 22.2 16.3 27.8 32.7 28.6 35.5MBRSC 26.7 15.9 22.2 17.1 30.5 33.3 30.2 34.7testWorst 13.3 9.1 12.9 5.1 14.7 20.7 16.1 13.0Best 27.2 18.6 21.9 16.7 27.4 32.5 28.1 33.5MBRSC 27.9 17.7 22.1 16.5 30.4 32.9 29.6 32.7Table 1: BLEU scores (case-sensitive) on the shared translation task development and test corpora of the best andworst single systems and MBRSC.
For each translation direction, we show the number of systems being combined.Best translation results are in bold.puting the gain of a hypothesis, and usually only amoderate number of iterations (< 10) is needed toconverge (Mart?
?nez et al, 2000).4 ResultsExperiments were conducted on all the 8 translationdirections of the shared translation task Czech?English (cz?en), German?English (de?en),Spanish?English (es?en) and French?English(fr?en) and also on the raw and clean versionsof the Haitian creole?English featured translationtask (ht?en).
All the experiments were carriedout with the true-cased, detokenized version of thetuning and test corpora, following the WMT 2011submission guidelines.4.1 Shared translation taskTable 1 shows the BLEU scores of MBRSC on thedevelopment and test corpora in comparison withthe score of the best and worst individual systems.In most of the translation directions, MBRSC im-proved the results of the best individual system,e.g.
+2.7/+3.0 BLEU point in es?en.
However,in en?cz and en?fr, MBRSC performs worse thanthe best individual system.
One thing we noticed isthat for these translation directions, the translationsfrom one provided single system (online-B) weremuch better in terms of BLEU than those of all othersystems (in the former case by more than 14% rel-ative in development).
In our experience, MBRSCrequires ?comparably good?
systems to be able toachieve significant improvements (particularly if us-ing heuristic scaling factors).
On the other hand, wewould have achieved improvements over all remain-ing systems leaving out online-B.4.2 Featured translation taskRegarding the ht?en featured translation task,MBRSC is not able to improve the results of thebest individual system in any case.
As in the en?czand en?fr translation directions, one of the systems(bm-i2r) perform much much better than all othersystems.
We can notice the surprisingly low scoreof one of the systems (umd-hu) in the clean task.The translations of this system are all equal (?N /A?)
so we suppose that some error occurred duringthe translation or submission processes.ht?enraw clean#systems 8 16worst 15.4 2.9best 29.6 33.1MBRSC 28.6 32.2Table 2: BLEU scores (case-sensitive) on the featuredtranslation task development corpora of the best andworst single systems and MBRSC.
Best translation re-sults are in bold.5 summaryThe UPV-PRHLT submissions for WMT 2011 sys-tem combination task were described in this paper.The combination was based on a multi-system MBRtechnique that uses the MBR decision rule and a lin-ear combination of the component systems?
proba-bility distributions to search for the minimum risktranslation among all the finite-length strings in theoutput vocabulary.
We introduced expected BLEU,143an approximation to the BLEU score that allows toefficiently apply MBR in these conditions.
In mostof the translation directions we were able to obtainBLEU gains over the best individual systems.AcknowledgementsThis paper is based upon work supported by the EC(FEDER/FSE) and the Spanish MEC/MICINN un-der the MIPRCV ?Consolider Ingenio 2010?
pro-gram (CSD2007-00018), the iTrans2 (TIN2009-14511) project and the UPV under grant 20091027.Also supported by the Spanish MITyC under theerudito.com (TSI-020110-2009-439) project and bythe Generalitat Valenciana under grant Prome-teo/2009/014.ReferencesJohn DeNero, Shankar Kumar, Ciprian Chelba, and FranzOch.
2010.
Model combination for machine trans-lation.
In Human Language Technologies: The 2010Annual Conference of the North American Chapter ofthe Association for Computational Linguistics, pages975?983, Morristown, NJ, USA.
Association for Com-putational Linguistics.Nan Duan, Mu Li, Dongdong Zhang, and Ming Zhou.2010.
Mixture model-based minimum bayes risk de-coding using multiple machine translation systems.
InProceedings of the 23rd International Conference onComputational Linguistics (Coling 2010), pages 313?321, Beijing, China, August.
Coling 2010 OrganizingCommittee.Vaibhava Goel and William J. Byrne.
2000.
Minimumbayes-risk automatic speech recognition.
ComputerSpeech & Language, 14(2):115?135.Jesu?s Gonza?lez-Rubio, Germa?n Sanchis-Trilles, Joan-Andreu Sa?nchez, Jesu?s Andre?s-Ferrer, Guillem Gasco?,Pascual Mart?
?nez-Go?mez, Martha-Alicia Rocha, andFrancisco Casacuberta.
2010.
The upv-prhlt combi-nation system for wmt 2010.
In Proceedings of theJoint Fifth Workshop on Statistical Machine Trans-lation and MetricsMATR, pages 296?300, Uppsala,Sweden, July.
Association for Computational Linguis-tics.Jess Gonzlez-Rubio, Alfons Juan, and Francisco Casacu-berta.
2011.
Minimum bayes-risk system combina-tion.
In Proceedings of the 49th Annual Meeting ofthe Association for Computational Linguistics: Hu-man Language Technologies, pages 1268?1277, Port-land, Oregon, USA, June.
Association for Computa-tional Linguistics.Shankar Kumar and William J. Byrne.
2004.
Minimumbayes-risk decoding for statistical machine translation.In HLT-NAACL, pages 169?176.Shankar Kumar, Wolfgang Macherey, Chris Dyer, andFranz Och.
2009.
Efficient minimum error rate train-ing and minimum bayes-risk decoding for translationhypergraphs and lattices.
In Proceedings of the JointConference of the 47th Annual Meeting of the ACL andthe 4th International Joint Conference on Natural Lan-guage Processing of the AFNLP: Volume 1 - Volume 1,pages 163?171, Morristown, NJ, USA.
Association forComputational Linguistics.C.
D.
Mart?
?nez, A. Juan, and F. Casacuberta.
2000.
Useof Median String for Classification.
In Proceedings ofthe 15th International Conference on Pattern Recog-nition, volume 2, pages 907?910, Barcelona (Spain),September.Franz J. Och.
2003.
Minimum error rate training instatistical machine translation.
In Proceedings of the41st Annual Meeting on Association for Computa-tional Linguistics - Volume 1, pages 160?167, Morris-town, NJ, USA.
Association for Computational Lin-guistics.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automaticevaluation of machine translation.
In Proceedings ofthe 40th Annual Meeting on Association for Compu-tational Linguistics, pages 311?318, Morristown, NJ,USA.
Association for Computational Linguistics.Antti-Veikko Rosti, Necip Fazil Ayan, Bing Xiang, Spy-ros Matsoukas, Richard Schwartz, and Bonnie Dorr.2007.
Combining outputs from multiple machinetranslation systems.
In Human Language Technolo-gies 2007: The Conference of the North AmericanChapter of the Association for Computational Lin-guistics; Proceedings of the Main Conference, pages228?235, Rochester, New York, April.
Association forComputational Linguistics.Roy W. Tromble, Shankar Kumar, Franz Och, and Wolf-gang Macherey.
2008.
Lattice minimum bayes-riskdecoding for statistical machine translation.
In Pro-ceedings of the Conference on Empirical Methods inNatural Language Processing, pages 620?629, Mor-ristown, NJ, USA.
Association for Computational Lin-guistics.144
