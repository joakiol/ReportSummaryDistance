Information Classification and NavigationBased on 5W1H of the Target InformationTakah i ro  Ikeda  and Ak i tosh i  Okumura  and Kazunor i  Murak iC&C Media Research Laboratories,  NEC Corporat ion4-1-1 Miyazaki,  Miyamae-ku,  Kawasaki,  Kanagawa 216Abst rac tThis paper proposes a method by which 5WlH (who,when, where, what, why, how, and predicate) infor-mation is used to classify and navigate Japanese-language texts.
5WlH information, extracted fromtext data, has an access platform with three func-tions: episodic retrieval, multi-dimensional classi-fication, and overall classification.
In a six-monthtrial, the platform was used by 50 people to access6400 newspaper articles.
The three functions provedto be effective for office documentation work and theprecision of extraction was approximately 82%.1 In t roduct ionIn recent years, we have seen an explosive growthin the volume of information available through on-line networks and from large capacity storage de-vices.
High-speed and large-scale retrieval tech-niques have made it possible to receive informationthrough information services such as news clippingand keyword-based retrieval.
However, informationretrieval is not a purpose in itself, but a means inmost cases.
In office work, users use retrieval ser-vices to create various documents such as proposalsand reports.Conventional retrieval services do not provideusers with a good access platform to help themachieve their practical purposes (Sakamoto, 1997;Lesk et al, 1997).
They have to repeat retrievaloperations and classify the data for themselves.To overcome this difficulty, this paper proposesa method by which 5WlH (who, when, where,what, why, how, and predicate) information canbe used to classify and navigate Japanese-languagetexts.
5WlH information provides users with easy-to-understand classification axes and retrieval keysbecause it has a set of fundamental elements neededto describe vents.In this paper, we discuss common informationretrieval requirements for office work and describethe three functions that our access platform us-ing 5WlH information provides: episodic retrieval,multi-dimensional classification, and overall classifi-cation.
We then discuss 5WlH extraction methods,and, finally, we report on the results of a six-monthtrial in which 50 people, linked to a company in-tranet, used the platform to access newspaper arti-cles.2 Ret r ieva l  Requ i rements  In  anOff iceInformation retrieval is an extremely important partof office work, and particularly crucial in the creationof office documents.
The retrieval requirements inoffice work can be classified into three types.Episodic viewpoint: We are often required tomake an episode, temporal transition data on a cer-tain event.
For example, "Company X succeededin developing a two-gigabyte memory" makes theuser want to investigate what kind of events wereannounced about Company X's memory before thisevent.
The user has to collect the related eventsand then arrange them in temporal order to makean episode.Comparat ive viewpoint: The comparative view-point is familiar to office workers.
For example,when the user fills out a purchase request form tobuy a product, he has to collect comparative infor-mation on price, performance and so on, from severalcompanies.
Here, the retrieval is done by changingretrieval viewpoints.Overall viewpoint: An overall viewpoint is neces-sary when there is a large amount of classificationdata.
When a user produces a technical analysis re-port after collecting electronics-related articles froma newspaper over one year, the amount of data istoo large to allow global tendencies tobe interpretedsuch as when the events occurred, what kind of com-panies were involved, and what type of action wasrequired.
Here, users have to repeat retrieval andclassification by choosing appropriate keywords tocondense classification so that it is not too broad-ranging to understand.571l EpisodicretrievalI Overall classification IFigure 1: 5WIH classification and navigation3 5WIH Classification andNavigat ionConventional keyword-based retrieval does not con-sider logical relationships between keywords.
For ex-ample, the condition, "NEC & semiconductor & pro-duce" retrieves an article containing "NEC formeda technical alliance with B company, and B com-pany produced semiconductor X."
Mine et al andSatoh et al reported that this problem leads to re-trieval noise and unnecessary results (Mine et al,1997; Satoh and Muraki, 1993).
This problem makesit difficult to meet the requirements of an office be-cause it produces retrieval noise in these three typesof operations.5WlH information is who, when, where, what,why, how, and predicate information extracted fromtext data through the 5WlH extraction module us-ing language dictionary and sentence analysis tech-niques.
5WlH extraction modules assign 5WlH in-dexes to the text data.
The indexes are stored in listform of predicates and arguments (when, who, what,why, where, how) (Lesk et ai., 1997).
The 5WlHindex can suppress retrieval noise because the in-dex considers the logical relationships between key-words.
For example, the 5WlH index makes it pos-sible to retrieve texts using the retrieval condition"who: NEC & what: semiconductor & predicate:produce."
It can filter out the article containing"NEC formed a technical alliance with B company,and B company produced semiconductor X.
"Based on 5WlH information, we propose a 5WlHclassification and navigation model which can meetoffice retrieval requirements.
The model has threefunctions: episodic retrieval, multi-dimensional clas-sification, and overall classification (Figure 1).3.1 Episodic Ret r ieva lThe 5WlH index can easily do episodic retrievalby choosing a set of related events and arranging96.10 NEC adjusts semiconductor production downward.96.1297.197.497.5NEC postpones emiconductor production plantconstruction.NEC shifts semiconductor production to 64 Megabit nextgeneration DRAMs.NEC invests ?
40 billion for next generationsemiconductor production.NEC semiconductor production 18% more thanexpected.Figure 2: Episodic retrieval exampleW ~  PC HD INEC .
.
.
.
.
.
.
.
.X~; .
.
.
.
.
.
.
.
.PC .
.
.
.
.
.~ .
.
.
.
.
.
.
.
.Figure 3: Multi-dimensional c assification examplethe events in temporal order.
The results are read-able by users as a kind of episode.
For example,an NEC semiconductor p oduction episode is madeby retrieving texts containing "who: NEC & what:semiconductor & predicate: product" indexes andsorting the retrieved texts in temporal order (Figure2).The 5WlH index can suppress retrieval noise byconventional keyword-based retrieval such as "NEC& semiconductor & produce."
Also, the result is aneasily readable series of events which is able to meetepisodic viewpoint requirements in office retrieval.3.2  Mu l t i -d imens iona l  C lass i f i ca t ionThe 5WlH index has seven-dimensionai axes forclassification.
Texts are classified into categories onthe basis of whether they contain a certain combi-nation of 5WlH elements or not.
Though 5WlHelements create seven-dimensional space, users areprovided with a two-dimensional matrix because thismakes it easier for them to understand text distri-bution.
Users can choose a fundamental viewpointfrom 5WlH elements to be the vertical axis.
Theother elements are arranged on the horizontal axisas the left matrix of Figure 3 shows.
Classificationmakes it possible to access data from a user's com-parative viewpoints by combining 5WlH elements.For example, the cell specified by NEC and PCshows the number of articles containing NEC as a"who" element and PC as a "what" element.Users can easily obtain comparable data byswitching their fundamental viewpoint from the572WhoNF~ opens anew internet service.Electric .
.
.
.
.Company " A ...... Cotp, develops a new computer.B Inc. puts a portable terminal on the market,Communi- J C Telecommunication starts a virtual market.cation ~,..~ D Telephone sells a communication adapter.Figure 4: Overall classification example"who" viewpoint o the "what" viewpoint, for ex-ample, as the right matrix of Figure 3 shows.
Thismeets comparative viewpoint requirements in officeretrieval.3.3 Overall Classif icationWhen there are a large number of 5WlH elements,the classification matrix can be packed by using athesaurus.
As 5WlH elements axe represented byupper concepts in the thesaurus, the matrix can becondensed.
Figure 4 has an example with six "who"elements which are represented by two categories.The matrix provides users with overall classificationas well as detailed sub-classification through the se-lection of appropriate hierarchical levels.
This meetsoverall classification requirements in office retrieval.4 5W1H In format ion  Ext rac t ion5W1H extraction was done by a case-based shal-low parsing (CBSP) model based on the algorithmused in the VENIEX, Japanese information extrac-tion system (Muraki et al, 1993).
CBSP is a robustand effective method of analysis which uses lexicalinformation, expression patterns and case-markersin sentences.
Figure 5 shows the detail on the algo-rithm for CBSP.In this algorithm, input sentences are first seg-mented into words by Japanese morphological nal-ysis (Japanese sentences have no blanks betweenwords.)
Lexical information is linked to each wordsuch as the part-of-speech, root forms and semanticcategories.Next, 5WlH elements are extracted by propernoun extraction, pattern expression matching andcase-maker matching.In the proper noun extraction phase, a 60 050-word proper noun dictionary made it possible toindicate people's names and organization names as"who" elements and place names as "where" ele-ments.
For example, NEC and China are respec-tively extracted as a "who" element and a "where"procedure CBSP;beginApply morphological nalysis to the sentence;foreach word in the sentence do beginif the word is a people's name oran organization name thenMark the word as a "who" element andpush it to the stack;else if the word is a place name thenMark the word as a "where" element andpush it to the stack;else if the word matches an organizationname pattern thenMark the word as a "who" element andpush it to the stack;else if the word matches a date pattern thenMark the word as a "when" element andpush it to the stack;else if the word is a noun thenif the next word is ?~?
or t2 thenMark the word and the kept unspecifiedelements as "who" elements andpush them to the stack;if the next word is ~: or ~= thenMark the word and the kept unspecifiedelements as "what" elements andpush them to the stack;elseKeep the word as an unspecified element;else if the word is a verb then beginFix the word as the predicate lement ofa 5WlH set;repeatPop one marked word from the stack;if the 5WlH elementcorresponding to the markof the word is not fixed thenFix the word as the 5WlH elementcorresponding to its mark;elsebreak repeat;unti l  stack is empty;endendendFigure 5: The algorithm for CBSPelement from the sentence, "NEC d ?
q~ ~ ~/ f i k*-No (NEC produces emiconductors in China.
)"In the pattern expression matching phase, the sys-tem extracts words matching predefined patterns as"who" and "when" elements.
There are several typ-573Table 1: The results of evaluation for "who," "what," and "predicate" elements and overall extractedinformation.
"Who" elements "What" elements "Predicate" elementsPresent Absent Total Present Absent Total Present Absent Total OverallCorrect 5423 71 5494 5653 50 5703 6042 5 6047 5270Error 414 490 904 681 14 695 55 296 351 1128Total 5837 561 6398 6334 64 6398 6097 301 6398 6396Precision 92.9% 12.7% 85.9% 89.2% 78.1% 89.1% 99.1% 1.7% 94.5% 82.4%ical patterns for organization ames and people'snames, dates, and places (Muraki et al, 1993).
Forexample, nouns followed by ~J :  (Co., Inc. Ltd.) and~-~ (Univ.)
mean they are organizations and "who"elements.
For example, 1998 ~ 4 J~ 18 ~ (April 18,1998) can be identified as a date.
"When" elementscan be recognized by focusing on the pattern for(year),)~ (month), and ~ (day).For words which are not extracted as 5WlH el-ements in previous phases, the system decides its5WlH index by case marker matching.
The systemchecks the relationships between Japanese particles(case markers) and verbs and assigns a 5W1H in-dex to each word according to rules such as 7~  is amarker of a "who" element and ~ is a marker of a"what" element.
In the example "A } J :7~ X ~r~ (Company A sells product X.
)," company A isidentified as a "who" element according to the casemarker 7) ~ if it is not specified as a "who" elementby proper noun extraction and pattern expressionmatching.5WlH elements followed by a verb (predicate) arefixed as a 5WlH set so that a 5WlH set does notinclude two elements for the same 5WlH index.
A5WlH element belongs to the same 5W1H set as thenearest predicate after it.5 In fo rmat ion  Access  P la t fo rm5WlH information classification and navigationworks in the information access platform.
The plat-form disseminates u ers with newspaper informationthrough the company intranet.
The platform struc-ture is shown in Figure 6.Web robots collect newspaper articles from spec-ified URLs every day.
The data is stored in thedatabase, and a 5WlH index data is made for thedata.
Currently, 6398 news articles are stored in thedatabases.
Some articles are disseminated to usersaccording to their profiles.
Users can browse all thedata through WWW browsers and use 5WlH classi-fication and navigation functions by typing sentencesor specifying regions in the browsing texts.l ~I Dissemination }~I fI ?
I I imoosi;o ,~a'ta~a~J IN'DEX \]l I retrievalUSERSFigure 6: Information access interface structure5WlH elements are automatically extracted fromthe typed sentences and specified regions.
The ex-tracted 5WlH elements are used as retrieval keys forepisodic retrieval, and as axes for multi-dimensionalclassification and overall classification.5.1 5W1H Information Extract ion"When," "who, .... what," and "predicate" informa-tion has been extracted from 6398 electronics in-dustry news articles since August, 1996.
We haveevaluated extracted information for 6398 news head-lines.
The headline average length is approximately12 words.
Table 1 shows the result of evaluating"who," "what," and "predicate" information andoverall extracted information.In this table, the results are classified with re-gard to the presence of corresponding elements in thenews headlines.
More than 90% of "who," "what,"and "predicate" elements can correctly be extractedwith our extraction algorithm from headlines havingsuch elements.
On the other hand, the algorithmis not highly precise when there is no correspond-ing element in the article.
The errors are causedby picking up other elements despite the absenceof the element o be extracted.
However, the er-rors hardly affect applications such as episodic re-574~ : ~ j  , .....
.~., .
.
.
.
.
[~/ lon~]  ": ~ ?
Wl[~/ l l lS ]  -~[~t~N~; ; 'X~'~4~n, 'DRAU' .
- :~/Yt  " -  -~ '~CMFigure 7: Episodic retrieval example (2)trieval and multi-dimensional classification becausethey only add unnecessary information and do notremove necessary information.The precision independent of the presence of theelement is from 85% to 95% for each, and the overallprecision is 82.4%.5.1.1 Episodic RetrievalFigure 7 is an actual screen of Figure 2, which showsan example of episodic retrieval based on headlinenews saying, "NEC ~)~-~?
)~: :~: J :  0 18%~(NEC produces 18% more semiconductors han ex-pected.)"
The user specifies the region, "NEC ~)?~ i~k?
)~i~ (NEC produces semiconductors)" nthe headline for episodic retrieval.
A "who" elementNEC, a "what" element ~ i~$ (semiconductor), anda "predicate" element ~ (produce) are episodic re-trieval keys.
The extracted results are NEC's semi-conductor production story.The upper frame of the window lists a set of head-lines arranged in temporal order.
In each article,NEC is a "who" element, the semiconductor is a"what" element and production is a "predicate" el-ement.
By tracing episodic headlines, the user canfind that the semiconductor market was not good atthe end of 1996 but that it began turning aroundin 1997.
The lower frame shows an article corre-sponding to the headline in the upper frame.
Whenthe user clicks the 96/10/21 headline, the completearticle is displayed in the lower frame.5.1.2 Mult i -dimensional  ClassificationFigures 8 and 9 show multi-dimensional classifica-tion results based on the headline, "NEC ?
A ~?
?B ~?
HB~-g"4'~Y-- ~ ?)
~]~J{~$~ ~ .
-~  (NEC, ACo., and B Co. are developing encoded data recov-.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
Hiilillllilll i IIIII1[11iiii111 I :~"======================~IFigure 8: Multi-dimensional classification example(2).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
III IHflfl I II II I II)[i1'~?~ i[96/0?/1T] D$~: I~i.|~.~g~'~{:l'C~x~'>Y,-7-~--~;~ ~Figure 9: Multi-dimensional classification example(3)ery techniques.)."
Who" elements are "NEC, ACo., and B Co." listed on the vertical axis which isthe fundamental xis in the upper frame of Figure8.
"What" elements are "~-~?.
(encode), ~*-(data), [ ]~  (recovery), and ~ (technique)."
h"predicate" element is a " r ,~  (develop)."
What"and "predicate" elements are both arranged on thehorizontal axis in the upper frame of Figure 8.
Whenclicking a cell for "who": NEC and "what": ~(encode), users can see the headlines of articles con-taining the above two keywords in the lower frameof Figure 8.When clicking on the "What" cell in the upper575I!! '
i i  ................... ?~"i IUI"'U ~~i~ ~ ,~, .
.
.
.
.
.~...
:~.
:~ ~::: :::::~:::~!
:::::::::::::::::::::::::::::::::: ~: : ~: ~: ~:~m~}t~.
i l  ....................... U........................... E !
: : : :  ............... ::::: "U  i !~  i ....... }; I l~,:11~1 ~ ~ .
.
.
.
.
.
~ : - :  .
.
.
.
.
.
.
.
: - i -  2 - - -~  7 - -  ~ .
.
.
.
.
.
: .
.
.
.
.
.
i - ~ .
.
.
.
.
.
[ : :~ IFT"""T : :  ............. ~" -  "? "
" ' :  - : ' -7 : : ' : :~  ............ : "  ~ .
.
.
.
.
.
.
.
.
.
~ ' "~:7  ' 'U  .
.
.
.
.
.
.
.
.
: ,~" " ' "  " .
.
.
.L }::~::; :::::::::::::::::::::::::::::::::::::::::::::::: :::::::::::::::::::::::::::::::::::::: : ~ : " ::: '::::::~:::: :::::::::::::::::} ~1~1~}""~ ..................... - ................................... ~ ....................... : ............ ' , ' T ' "~" : : - -~Y  ' 'm i " "~ "Figure 10: Overall classification for 97/4 newsFigure 11: Overall sub-classification for 97/4 newsframe of Figure 8, the user can switch the funda-mental axis from "who" to "what" (Figure 9, up-per frame).
By switching the fundamental xis, theuser can easily see classification from different view-points.
On clicking the cell for "what": ~{P .
(en-code) and "predicate": ~2~ (develop), the user findseight headlines (Figure 9, lower frame).
The usercan then see different company activities uch as the97/04/07 headline; "C ~i ~ o  fzf f ' -  ~' ~ .~~f~g@~:  ~ (C Company has developed atatransmission encoding technology using a satellite),"shown in the lower frame of Figure 9.In this way, a user can classify article headlines byswitching 5WlH viewpoints.5.1.3 Overall ClassificationOverall classification is condensed by using an orga-nization and a technical thesaurus.
The organizationthesaurus has three layers and 2800 items, and thetechnical thesaurus has two layers and 1000 techni-cal terms.
"Who" and "what" elements are respec-tively represented by the upper classes of the orga-nization thesaurus and the technical thesaurus.
Theupper classes are vertical and horizontal elements inthe multi-dimensional classification matrix.
"Pred-icate" elements are categorized by several frequentpredicates based on the user's priorities.Figure 10 shows the results of overall classifica-tion for 250 articles disseminated in April, 1997.Here, "who" elements on the vertical axis are rep-resented by industry categories instead of companynames, and "what" elements on the horizontal axisare represented by technical fields instead of tech-nical terms.
On clicking the second cell from thetop of the "who" elements, ~]~J t~ (electrical andmechanical) in Figure 10, the user can view subcat-egorized classification on electrical and mechanicalindustries as indicated in Figure 11.
Here, ~ :(electrical and mechanical) is expanded to the sub-categories; ~ J ~  (general electric) ~_~ (powerelectric), ~ I ~  (home electric), ~.
{~j~ (commu-nication), and so on.6 Cur rent  S ta tusThe information access platform was exploited dur-ing the MIIDAS (Multiple Indexed Information Dis-semination and Acquisition Service) project whichNEC used internally (Okumura et al, 1997).
TheDEC Alpha workstation (300 MHz) is a server ma-chine providing 5WlH classification and navigationfunctions for 50 users through WWW browsers.User interaction occurs through CGI and JAVA pro-grams.After a six-month trial by 50 users, four areas forimprovement become vident.1) 5WlH extraction: 5WlH extraction precision wasapproximately 82% for newspaper headlines.
Theextraction algorithm should be improved so that itcan deal with embedded sentences and compoundsentences.Also, dictionaries should be improved in order to beable to deal with different domains uch as patentdata and academic papers.2) Episodic retrieval: The interface should be im-proved so that the user can switch retrieval fromepisodic to normal retrieval in order to compare re-trieval data.Episodic retrieval is based on the temporal sortingof a set of related events.
At present, geographic ar-rangement is expected to become a branch functionfor episodic retrieval.
It is possible to arrange achevent on a map by using 5WlH index data.
Thiswould enable users to trace moving events uch asthe onset of a typhoon or the escape of a criminal.3) Multi-dimensional classification: Some users needto edit the matrix for themselves on the screen.576Moreover, it is necessary to insert new keywords anddelete unnecessary keywords.7 Related WorkSOM (Self-Organization Map) is an effective auto-matic classification method for any data representedby vectors (Kohonen, 1990).
However, the meaningof each cluster is difficult to understand intuitively.The clusters have no logical meaning because theydepend on a keyword set based on the frequency thatkeywords occur.Scatter/Gather is clustering information based onuser interaction (Hearst and Pederson, 1995; Hearstet al, 1995).
Initial cluster sets are based on key-word frequencies.GALOIS/ULYSSES is a lattice-based classifica-tion system and the user can browse information onthe lattice produced by the existence of keywords(Carpineto and Romano, 1995).5WlH classification and navigation is unique inthat it is based on keyword functions, not on theexistence of keywords.Lifestream manages e-mail by focusing on tempo-ral viewpoints (Freeman and Fertig, 1995).
In thissense, this idea is similar to our episodic retrievalthough the purpose and target are different.Mine et al and Hyodo and Ikeda reported on theeffectiveness of using dependency relations betweenkeywords for retrieval (Mine et al, 1997; Hyodo andIkeda, 1994).As the 5WlH index is more informative than sim-ple word dependency, it is possible to create morefunctions.
More informative indexing such as se-mantic indexing and conceptual indexing can the-oretically provide more sophisticated classification.However, this indexing is not always successful forpractical use because of semantic analysis difficul-ties.
Consequently 5WlH is the most appropriateindexing method from the practical viewpoint.8 ConclusionThis paper proposed a method by which 5WlH(who, when, where, what, why, how, and predi-cate) information is used to classify and navigateJapanese-language t xts.
5WlH information, ex-tracted from text data, provides an access plat-form with three functions: episodic retrieval, multi-dimensional classification, and overall classification.In a six-month trial, the platform was used by 50people to access 6400 newspaper articles.The three functions proved to be effective for of-fice documentation work and the extraction preci-sion was approximately 82%.We intend to make a more quantitative evaluationby surveying more users about the functions.
Wealso plan to improve the 5W1H extraction algorithm,dictionaries and the user interface.AcknowledgmentWe would like to thank Dr. Satoshi Goto and Dr.Takao Watanabe for their encouragement and con-tinued support hroughout this work.We also appreciate the contribution of Mr.Kenji Satoh, Mr. Takayoshi Ochiai, Mr. SatoshiShimokawara, nd Mr. Masahito Abe to this work.ReferencesC.
Carpineto and G. Romano.
1995.
A system forconceptual structuring and hybrid navigation of textdatabase.
In AAAI Fall Symposium on AI Applicationin Knowledge Navigation and Retrieval, pages 20-25.E.
Freeman and S. Fertig.
1995.
Lifestreams: Organiz-ing your electric life.
In AAAI Fall Symposium on AIApplication in Knowledge Navigation and Retrieval,pages 38-44.M.
A. Hearst and J. O. Pederson.
1995.
Revealing col-lection structure through information access interface.In Proceedings of IJCAI'95, pages 2047-2048.M.
A. Hearst, D. R. Karger, and J. O. Pederson.
1995.Scatter/gather as a tool for navigation of retrieval re-sults.
In AAAI Fall Symposium on AI Application inKnowledge Navigation and Retrieval, pages 65-71.Y.
Hyodo and T. Ikeda.
1994.
Text retrieval system usedon structure matching.
The Transactions of The Insti-tute of Electronics, Information and CommunicationEngineers, J77-D-II(5):1028-1030.T.
Kohonen.
1990.
The self-organizing map.
In Proceed-ings of IEEE, volume 78, pages 1059-1063.M.
Lesk, D. Cutting, J. Pedersen, T. Noreanlt, andM.
Koll.
1997.
Real life information retrieval: com-mercial search engines.
In Proceedings of SIGIR'97,page 333, July.T.
Mine, K. Aso, and M. Amamiya.
1997.
Japanesedocument retrieval system on www using depen-dency relations between words.
In Proceedings of PA-CLING'97, pages 290-215, September.K.
Muraki, S. Doi, and S. Ando.
1993.
Description ofthe veniex system as used for muc-r.
In Proceedingsof MUCS, pages 147-159, August.A.
Okumura, T. Ikeda, and K. Muraki.
1997.
Selec-tive dissemination finformation based on a multiple-ontology.
In Proceedings of IJCAI'97 Ontology Work-shop, pages 138-145, August.H.
Sakamoto.
1997.
Natural language processing tech-nology for information.
In JEIDA NLP Workshop,July.K.
Satoh and K. Muraki.
1993.
Penstation for idea pro-cessing.
In Proceedings of NLPRS'93, pages 153-158,December.577
