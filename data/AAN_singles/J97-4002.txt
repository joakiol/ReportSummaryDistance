An Empirical Approach to VP EllipsisDaniel Hardt"Villanova UniversityThis paper reports on an empirically based system that automatically resolves VP ellipsis in the644 examples identified in the parsed Penn Treebank.
The results reported here represent the firstsystematic corpus-based study of VP ellipsis resolution, and the performance of the system iscomparable to the best existing systems for pronoun resolution.
The methodology and utilitiesdescribed can be applied to other discourse-processing problems, such as other forms of ellipsisand anaphora resolution.The system determines potential antecedents for ellipsis by applying syntactic onstraints,and these antecedents are ranked by combining structural and discourse preference factors suchas recency, clausal relations, and parallelism.
The system is evaluated by comparing its outputto the choices of human coders.
The system achieves a success rate of 94.8%, where success isdefined as sharing of a head between the system choice and the coder choice, while a baselinerecency-based scheme achieves asuccess rate o,I:75.0% by this measure.
Other criteria for successare also examined.
When success is defined as an exact, word-for-word match with the coderchoice, the system performs with 76.0% accuracy, and the baseline approach achieves only 14.6%accuracy.
Analysis of the individual components ofthe system shows that each of the structuraland discourse constraints used are strong predictors of the antecedent of VP ellipsis.1.
IntroductionEllipsis is a pervasive phenomenon i  natural language, and it has been a major topicof study in theoretical linguistics and computational linguistics in the past severaldecades (Ross 1967; Sag 1976; Williams 1997; Hankamer and Sag 1976; Webber 1978;Lappin 1984; Sag and Hankamer 1984; Chao 1987; Ristad 1990; Harper 1990; Kitagawa1991; Dalrymple, Shieber, and Pereira 1991; Lappin 1992; Hardt 1993; Kehler 1993;Fiengo and May 1994).
While previous work provides important insight into the ab-stract syntactic and semantic representations that underlie ellipsis phenomena, therehas been little empirically oriented work on ellipsis.
The availability of parsed cor-pora such as the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993) makes itpossible to empirically investigate elliptical phenomena in a way not possible before.This paper reports on an empirically based system that automatically resolvesVP ellipsis in the 644 examples identified in the parsed Penn Treebank.
This workbuilds on structural constraints and discourse heuristics first proposed in Hardt (1992)and further developed in Hardt (1995).
The results reported here represent the firstsystematic corpus-based study of VP ellipsis resolution, and the performance of thesystem is comparable to the best existing systems for pronoun resolution.The VP elipsis resolution system (VPE-RES) operates on Penn Treebank parsetrees to determine the antecedent for VPE occurrences.
The system, implemented inCommon LISP, uses a Syntactic Filter to eliminate candidate antecedents in impossibleDepartment of Computing Science, Villanova University, Villanova, PA 19085Q 1997 Association for Computational LinguisticsComputational Linguistics Volume 23, Number 4syntactic configurations, and then ranks remaining candidates using Preference Factorsinvolving recency, parallelism, clausal relations, and quotation structure.All the examples of VPE in the Treebank were coded for the correct antecedent bytwo coders.
Also, a baseline scheme is implemented, which always selects the mostrecent full VP.
Both the system and the baseline are evaluated by comparison with thecoder output, with respect o three different definitions of success:...Head Overlap: either the head verb of the system choice is contained inthe coder choice, or the head verb of the coder choice is contained in thesystem choiceHead Match: the system choice and coder choice have the same headverb.Exact Match: the system choice and coder choice match word-for-word.Using the Head Overlap measure, the system achieves a success rate of 94.8%on a blind test of 96 Wall Street Journal examples, while the baseline recency schemeachieves a success rate of 75.0% by this measure.
Using the Exact Match measure,the system performs with 76.0% accuracy, and the baseline approach achieves 14.6%accuracy.In what follows, we first present background on the data set and the codingof that data.
Next, we describe the VPE-RES system, examining the Syntactic Filter,the Preference Factors, and the Post-Filter.
There follows an empirical analysis of thesystem, in which we compare the system output o coder choice, based on our threesuccess criteria.
Also, the subparts of the system are analyzed individually, in threedifferent ways.
Finally, we briefly discuss related work.2.
BackgroundIn this section, we describe the data set we collected from the Penn Treebank, and thecoding of that data.2.1 The Data: VPE in the Penn TreebankWe have identified 644 examples of VPE from the Brown Corpus and the Wall StreetJournal Corpus of the Penn Treebank.
Since the parsing schemes used in the PennTreebank do not explicitly label VPE occurrences, it is difficult to ensure that all oc-currences of VPE in the Treebank are found.
However, this data set is the first largeset of ellipsis examples we are aware of, and it provides a solid empirical foundationnot only for the current study, but for future research on ellipsis.We used several techniques to identify ellipsis occurrences in the Treebank, allinvolving the tree pattern-matching utility tgrep.
1 In the Wall Street Journal Corpus,the -NONE- category is used to represent a variety of empty expressions, includingVPE.
We searched for the following pattern:(VP (-NONE- , ?
, ) )which resulted in a set of 260 examples from the Wall Street Journal corpus.1 The utility tgrep is written by Rich Pito of the University of Pennsylvania, and is distributed togetherwith the Penn Treebank CD-ROM.526Hardt VP EllipsisTable 1Identification of VPE occurrences.Actual Number Number Found False Hits Recall Precision48 21 19 21/48 (44%) 21/40 (53%)Table 2Success rates on missed examples.Success Definition Missed Examples (27) Complete Treebank (644)Number Correct Number CorrectHead Overlap 25(93%) 594(92.2%)Head Match 23(85%) 537(83.4%)Exact Match 19(70%) 489(75.9%)Table 3Coder agreement.Success Definition Coder AgreementHead Overlap 99%Head Match 97%Exact Match 93%In the Brown Corpus, VPE occurrences are not labeled in this way.
We searchedfor occurrences of a sentence (S) with an auxiliary (AUX) but no VP.To evaluate our identification criteria, we performed a manual search for VPEoccurrences in a sample of files constituting about 3.2% of the Treebank.
2 In this sample,we found that the Recall was 44%, and the Precision was 53%, as depicted in Table 1.In this sample, there were 27 valid VPE occurrences that were missed.
We testedVPE-RES on these examples, and found that its performance was comparable to itsperformance on the examples that were automatically identified.
The results are givenin Table 2, which also includes results on the complete corpus, for ease of comparison.
32.2 Coding the DataAll the examples of VPE were coded for the correct antecedent by two human coders.We performed some comparisons of coder responses with one another, based on ourthree success criteria.
On a sample of 162 examples, the results were as shown inTable 3.In this sample, there was only one example in which coder agreement failed ac-cording to the Head Overlap criterion:(1) Gold still acts as a haven when uncertainty prevails in the financialmarkets as it did yesterday.2 This percentage was computed using the parsed version of both the Brown Corpus and Wall StreetJournal Corpus.
The sample contained 155,000 words, out of a total of approximately 4,799,845 in theTreebank.3 The numbers for the missed examples reflect apost hoc analysis of the program output, rather thancomparison with coder files.527Computational Linguistics Volume 23, Number 4Here are the two choices:Coder 1: prevails in the financial marketsCoder 2: acts as a havenThe following is an example where the coders disagreed according to Head Match,although they agreed according to Head Overlap:(2) By contrast, in 19th-century Russia, an authoritarian government ownedthe bank and had the power to revoke payment whenever it chose,much as it would in today's Soviet Union.Coder 1: revoke payment whenever it choseCoder 2: owned the bank and had the power to revoke paymentwhenever it choseIn the following example, the coders disagreed according to Exact Match, althoughthey agreed according to the other two success criteria:(3) When bank financing for the buy-out collapsed last week, so did UAUsstock.Coder 1: collapsedCoder 2: collapsed last week3.
VPE-RES SystemThe VPE-RES system has the following subparts:1.
Syntactic Filter2.
Preference Factors3.
Post-FilterThe candidates for VPE antecedents are all full VPs appearing within a three sen-tence window--the current sentence and the two preceding sentences.
4 The SyntacticFilter eliminates all VPs that contain the VPE in an improper fashion.
A preferenceordering is imposed upon the remaining candidate antecedents, based on recency,clausal relations, parallelism, and quotation structure.
After the candidates have beenweighted according to these Preference Factors, the highest-rated candidate is selected,and its form is modified by a Post-Filter.4 The limitation to three sentences is arbitrary.
However, no examples were found in the Treebank inwhich the antecedent was more distant.528Hardt VP EllipsisSNP VPPRP VBD SBARshe said -NONE- S0 NP VPE NEGI IPRP MD RBshe would notFigure 1Parse tree for She said she would not.3.1 Syntactic FilterThe Syntact ic Fi l ter rules out  antecedents  hat improper ly  conta in  the VPE occurrence,  sWhi le  the prec ise def in i t ion of improper  conta inment  is an act ive area of theoret icalresearch, 6 we rule out  antecedents  that conta in  the VPE in a sentential complement.
Anexample  of this is g iven in F igure 1, the parse  tree for the sentence in (4).
7(4) She said she wou ld  not.Here,  the VPE occurrence would cannot  select as its antecedent  the conta in ing VPheaded by  said.
This is ru led  out  by  the Syntact ic Filter, because the VPE is conta inedin SBar, a sentent ia l  complement  o said.Pronoun reso lut ion  systems often incorporate  a syntact ic f i l ter - -a  mechan ism toremove certain antecedents  based  on syntact ic structure.
The basic syntact ic onstra intfor p ronouns  is that  they cannot  take a " local" antecedent ,  as descr ibed,  for example ,in Pr inc ip le  B of the b ind ing  theory  (Chomsky,  1981).
8 The Syntact ic Fi lter for VPE alsorules out  " local"  antecedents  in a sense: it rules out  antecedents  in certain conta inmentconf igurat ions.The imp lementat ion  of the Syntact ic Fi lter is compl icated  by  two factors: first,there are certain cases in wh ich  a conta in ing antecedent  is possible,  where  the VPE is5 This constraint is discussed in Hardt (1992) as a way of ruling out antecedents for VPE.6 See, for example Sag (1976) and May (1985) for discussion, and for example Lappin and McCord (1990)and Jacobson (1992) for alternative views.7 Parse trees display the exact category labels and structure represented in the Penn Treebank parses.
Wehave added a label, VPE, for VPE occurrences.
See Appendix A for a list of Penn Treebank tags; formore information, see Marcus, Santorini, and Marcinkiewicz (1993).8 While the precise formulation of Principle B remains controversial, it is generally agreed to rule out, forexample, the binding of a pronoun in object position by an NP in subject position.
Such constraints onpronoun resolution have been incorporated into several computational approaches topronounresolution, such as Brennan, Friedman, and Pollard (1987), Lappin and McCord (1990), and Lappin andLeass (1994).529Computational Linguistics Volume 23, Number 4VB NPPP SBAR-2IN NP WHNP Sfrom PRP WDT NP VPit that PRP VBD Sshe used NP VPEL-NONE- TOI* totake NPDT NNI Lthe pleasureFigure 2Parse tree for She was getting too old to take the pleasure from it that she used to.contained in an NP argument of the containing VP, as in Figure 2, the parse tree forthe following example:(5) She was getting too old to take the pleasure from it that she used to.Here, the (circled) VP headed by take is the antecedent for the VPE, despite thecontainment relation.The second complication results from a basic limitation in Treebank parses; thereis no distinction between arguments and adjuncts.
A VP must be ruled out if the VPEis within a nonquantificational argument; when a VPE occurs in an adjunct position,the "containing" VP is a permissible antecedent.
The following sentence, whose parsetree is in Figure 3, is an example of this:(6) get to the corner of Adams and Clark just as fast as you canIn this case, the (circled) VP headed by get is the antecedent for the VPE, despitethe appearance ofcontainment.
Since the VPE is contained in an adjunct (an adverbialphrase), there is in fact a nonmaximal VP headed by get that does not contain the VPE:this is the VP get to the corner of Adams and Clark.
However, because of the approachtaken in annotating the Penn Treebank, this nonmaximal VP is not displayed as a VP.To capture the above data, the Syntactic Filter rules out VPs that contain the VPEin a sentential complement; any other antecedent-containment rela ion is permitted.530Hardt VP EllipsisVB PPget TO NPto DT NNthe comerADVPRB RB RB PPPP just as fast IN SIN NP as NP  VPEof NP CC NP PRP MDI I r I INNP and NNP you canI IAdams ClarkFigure 3Parse tree for get to the corner of Adams and Clark just as fast as you can.This correctly rules out the containing antecedent in (4), and permits it in (5) and (6).
93.2 Preference FactorsRemaining candidates are ordered according to the following four Preference Factors:1.
Recency2.
Clausal Relations3.
Parallelism4.
Quotation9 An anonymous CL reviewer suggests that the filter may be overly restrictive, because of examples likethe following:A: It's an important issue, and I'm very concerned about it.B: Well, frankly, I don't care that you do.
(Italicized expressions receive pitch accents.)
Here, the antecedent for the VPE is care; this would not bepermitted by the filter.
The reviewer suggests that examples like this should not be categoricallyexcluded, although they are perhaps less than fully acceptable.
If this is true, it raises interestingtheoretical issues about the acceptability of antecedent-containment co figurations.
However, thereviewer notes that "such examples are no doubt rare and perhaps the proposed containment filterdoes enough work in correctly excluding ill-formed instances of ellipsis to justify the categoricalexclusion of these cases."
Based on our empirical research up to this point, we concur with this.
Noexamples of this sort have been observed among the 644 VPE examples in the Penn Treebank, and theSyntactic Filter as currently formulated contributes significantly to the overall performance of thesystem (see Section 4 for figures on this).531Computational Linguistics Volume 23, Number 4Each candidate is initialized with a weight of 1.
This weight is modified by anyapplicable Preference Factors.3.2.1 Recency.
The simplest and most important factor is recency: if no other PreferenceFactors obtain, the most recent (syntactically possible) antecedent is always chosen.The weights are modified as follows: the first VP weight is set to be the recencyfactor, 1.15.
Moving rightward, toward the VPE, the weight of each subsequent VPis multiplied by the recency factor.
Thus, if there are three VPs preceding the VPE,we have (1.15 1.32 1.52).
If a VP contains another VP, the two VPs are set at the samelevel.
Finally, VPs following the VPE are penalized in a symmetrical fashion.
~?3.2.2 Clausal Relations.
There is a strong preference for a VP antecedent that is in aclausal relation to the VPE.
n Consider the following example:(7) tells you what the characters are thinking and feeling \[ADVP far moreprecisely than intertitles, or even words, \[VPE would\]\].The VP headed by tells is modified by the adverbial phrase (labeled ADVP) con-taining the VPE.
This VP is the correct antecedent.
A VP in such a relation is givena very high weight, by the Preference Factor Clause-Rel, which in practice makes itan obligatory antecedent.
If Clause-Rel is deactivated, the system incorrectly selectsfeeling as the antecedent, because it is the most recent VP.The modification relation can also be a comparative r lation, as illustrated by thefollowing example, whose parse tree is given in Figure 4:(8) All felt freer to discuss things than students had previously.Here, the correct antecedent is the (circled) VP headed by felt.
This VP is modifiedby the comparative clause containing the VPE, and thus is correctly selected by thesystem.
With Clause-Rel deactivated, the system incorrectly selects the more recent VPdiscuss things.Note that such VPs are parsed as containing the VPE, but they are not removedby the Syntactic Filter.
Thus, the effect of this constraint is best observed in conjunc-tion with the Syntactic Filter.
In the testing of the system, we examined each systemcomponent separately, as described below.
However, we also examined Clause-Rel incombination with the Syntactic Filter, because of their close connection.
We did thisby defining a Composite system component, consisting of Syntactic Filter, Clause-Rel,and Post-Filter.3.2.3 Parallelism.
There is a preference for similar parallel elements, that is, the el-ements urrounding the ellipsis site, and the elements that correspond to them sur-rounding the antecedent.
Notions of parallelism figure prominently in many theoreticalstudies of ellipsis.
12 However, the proposal that similarity of parallel elements can be10 This reflects he fact hat VPE, like pronominal naphora, permits the antecedent to follow, rather thanprecede, the VPE occurrence.11 This constraint is discussed in Hardt (1992).12 The term parallel elements is from Dalrymple, Shieber, and Pereira (1991), where parallelism isemphasized in the interpretation of ellipsis.
Parallelism is also important inmany other treatments ofellipsis, such as Priest, Scha, and van den Berg (1991), Asher (1993), and Fiengo and May (1994).532Hardt VP EllipsisSDT VBD /All felt JJR SfleerPPNP AUX VP IN S-NONE- TO VB NP than NP VPE ADVPI I I I I I* to discuss NNS NNS VBD RBrthings students had previouslyFigure 4Parse tree for All felt freer to discuss things than students had previously.used to guide ellipsis resolution is, to our knowledge, a new one)  3 Our current resultsinvolving parallelism provide support  for this claim.
14 We are continuing to experimentwith more sophisticated ways of measuring the similarity of parallel elements.In the case of VPE, the subject and auxiliary are parallel elements.
Currently, thesystem only examines the form of the auxiliary.
In Hardt  (1992) a preference for VPEwith coreferential subjects is suggested.
This information is not available in the PennTreebank, and we do not use any forms of subject matching in the current version ofthe system.Aux-Match (Form of Auxiliary).
There is a preference for a similar base form of auxiliaryin antecedent and VPE.
The categories for auxiliary forms we use are: do, be, have, can,would, should, to.
We prefer an antecedent that shares the same category of auxiliaryform as the VPE.
The weights of all potential antecedents hat do not match the VPEauxiliary category are multipl ied by our Standard Penalty Value, which is .667.This preference is illustrated by the following example:(9) Someone with a master 's  degree in classical arts who works in a deliwould \[vP be ideal\], litigation sciences \[vP advises\].
So \[VPE would\]someone recently divorced or widowed.13 The importance of similar parallel elements in discourse relations is emphasized in Hobbs (1979), andit is applied to VPE resolution in Hobbs and Kehler (1997), in a rather different context than that of thispaper.14 As discussed in Section 4, the Parallelism Preference Factor makes an important contribution to thesystem performance.533Computational Linguistics Volume 23, Number 4Here, the correct antecedent is be ideal.
It is selected because it has a would auxiliary,which is the same category as the VPE.
Without this constraint, he system incorrectlyselects the VP advises.Another example is the following:(10) In the past, customers had to \[VP go to IBM when they \[vp outgrew theVax\]\].
Now they don't have \[vPE to\].Here, the correct antecedent is the matrix VP headed by go.
It has a to auxiliary, asdoes the VPE.
Without this constraint, the VP outgrew the VAX is incorrectly selectedby the system.Parallel-Match (Be-do conflict).
There is an additional penalty for a VP antecedent witha be-form auxiliary, if the VPE is a do-form.
15 This is implemented by multiplying theVP by our Standard Penalty Value of .667.
Consider the following example:(11) You \[VP know what the law of averages \[VP is\]\], don't you VPE?Here, neither potential antecedent matches the auxiliary category of the VPE, andtherefore both are penalized by the general auxiliary match constraint.
However, thenearer antecedent, is, is a be-form, and is thus subject o an additional penalty.
Thisallows the matrix antecedent, know what the law of averages is, to be correctly selected.3.2.4 Quotation.
If the VPE occurs within quoted material, there is a preference foran antecedent that also occurs within quoted material.
16 This is illustrated by thefollowing example:(12) "We \[vP have good times\]."
This happy bulletin \[VP convulsedMr.
Gorboduc\].
"You \[VPE do\] ?
", he asked between wheezes of laughter.Here, the correct antecedent is have good times.
The VP convulsed Mr. Gorboduc ispenalized by the Standard Penalty Value, because it is not within quotations, while theVPE is within quotations.
Without the application of the quote preference, the systemincorrectly selects convulsed Mr. Gorboduc.3.3 Post-FilterOnce the highest-rated antecedent has been identified, it may be necessary to modifyit by removing an argument or adjunct that is incorrectly included.
If the selectedVP contains the VPE in an argument or adjunct, that argument or adjunct must beeliminated.
For example,(13) Different as our minds are, yours has \[VP nourished mine \[pp as no othersocial influence \[VPE has \]\]\].The antecedent VP selected is nourished mine as no other social influence ver has.The PP containing the VPE must be eliminated, leaving the correct antecedent nour-ished mine.
This Preference Factor is extremely important in achieving success by the15 This constraint is suggested in Hardt (1992).16 A preference of this sort is discussed inMalt (1984).534Hardt VP EllipsisExact-Match criterion, and it results in a great deal of improvement over the baselineapproach (see results in Section 4).4.
Empirical Evaluation4.1 Success CriteriaTo test the performance of the system, we first obtained a coded file, which indicates ahuman coder's preferred antecedent for each example.
Then we compared the outputof the system with the coder's elections.As mentioned in Section 1, we define three criteria for success:...Head Overlap: either the head verb of the system choice is contained inthe coder choice, or the head verb of the coder choice is contained in thesystem choice.Head Match: the system choice and coder choice have the same headverb.Exact Match: the system choice and coder choice match word-for-word.To illustrate these criteria, we give three examples, one for each success criterion.Note that the success criteria are increasingly strict--if an example satisfies ExactMatch, it will also satisfy the other two criteria, and if an example satisfies HeadMatch, it will also satisfy Head Overlap.Example: Head Overlap(14) In July, Par and a 60% owned unit agreed to plead guilty in that inquiry,as did another former Par official.System output: plead guilty in that inquiryCoder selection: agreed to plead guilty in that inquiryAccording to Head Overlap, the system choice is correct, since its head verb, plead,is contained in the coder selection.
This would not be considered correct according toHead Match, since the head of the coder selection is agreed.Example: Head Match(15) The question is, if group conflicts till exist, as undeniably they do,System output: existCoder selection: still existHere, both the system output and the coder selection have the head verb exist, butthere is not an exact, word-for-word match.Example: Exact Match(16) It is difficult if not impossible for anyone who has not pored over thethousands of pages of court pleadings and transcripts to have aworthwhile opinion on the underlying merits of the controversy.Certainly I do not.535Computational Linguistics Volume 23, Number 4Table 4VPE-RES system.SuccessDefinition Total (644)Number CorrectWSJ (260)Number CorrectBrown (384)Number CorrectBlind Test (96)Number CorrectHead Overlap 594(92.2%) 248(95.4%) 346(90.1%) 91(94.8%)Head Match 537(83.4%) 224(86.2%) 313(81.5%) 81(84.4%)Exact Match 489(75.9%) 212(81.5%) 277(72.1%) 73(76.0%)Table 5Baseline (Recency-Only).SuccessDefinition Total (644) WSJ (260) Brown (384) Blind Test (96)Number Correct Number Correct Number Correct Number CorrectHead Overlap 495(76.9%) 196(75.4%) 299(77.9%) 72(75.0%)Head Match 420(65.2%) 166(63.8%) 254(66.1%) 59(61.5%)Exact Match 188(29.2%) 52(20.0%) 136(35.4%) 14(14.6%)System output: have a worthwhile opinion on the underlying merits ofthe controversyCoder selection: have a worthwhile opinion on the underlying merits ofthe controversy4.2 Test ResultsAfter identifying 644 examples of VPE in the Treebank, we reserved 96 randomlyselected examples from the Wall Street Journal corpus for a blind test.
In Table 4, wegive results for the blind test and for the entire Penn Treebank, and we report separatefigures on the Brown Corpus and Wall Street Journal Corpus} 7As a baseline, we alsoreport results (Table 5) on a simple recency-based approach: the most recent VP isalways chosen.
No Preference Factors or filters are applied.The difference between the VPE-RES performance and the baseline is statisticallysignificant by all three criteria, based on a ~2 analysis, p < .001.4.3 Evaluating System SubpartsIn Tables 6, 7, and 8, we present results on each major subpart of the program.
For thisevaluation, we used the Exact Match criterion.
We evaluated subparts in three ways:first, we began with the baseline (recency) approach, and activated a single additionalcomponent, to see how the system performance changed based on that component.Second, we began with the complete system, and deactivated a single component.Finally, we evaluated system components in an incremental fashion, beginning withPost-Filter, then activating Syntactic Filter with Post-Filter still activated, etc.
The Com-posite Factor is a combination of Post-Filter, Syntactic Filter, and Clause-Rel.17 Since the blind test examples are all taken from the Wall Street Journal corpus, it is most appropriate ocompare the blind test results directly to the results on the Wall Street Journal Corpus.
Notsurprisingly, the blind test results are slightly lower than the results on the complete Wall StreetJournal Corpus, since this contains the examples that functioned as training data.536Hardt VP EllipsisTable 6Recency-only with single factor activated.System Subpart Total (644) WSJ (260) Brown (384) Blind Test (96)Number Correct Number Correct Number Correct Number CorrectRecency-Only 188(29.2%) 52(20.0%) 136(35.4%) 14(14.6%)Post-Filter 383(59.5%) 155(59 .6%)  228(59.4%) 51(53.1%)Syntactic Filter 232(36.0%) 73(28.1%) 159(41.4%) 21(21.9%)Clause-Rel 181(28.1%) 49(18.8%) 132(34.4%) 14(14.6%)Quotes 193(30.0%) 53(20.4%) 140(36.5%) 14(14.6%)Aux-Match 221 (34.3%) 64(24.6%) 157(40.9%) 16(16.7%)Parallel-Match 201(31.2%) 56(21.5%) 145(37.8%) 14(14.6%)Composite 461 (71.6%) 200(76.9%) 261 (68.0%) 71 (74.0%)Table 7Complete system with single factor de-activated.System Subpart Total (644) WSJ (260) Brown (384) Blind Test (96)Number Correct Number Correct Number Correct Number CorrectFull VPE-RESSystem 489(75.9%) 212(81 .5%)  277(72.1%) 73(76.0%)Post-Filter 258 (40.1%) 82(31.5%) 176(45.8%) 23(24.0%)Syntactic Filter 431(66.9%) 185(71 .2%)  246(64.1%) 61(63.5%)Clause-Rel 469(72.8%) 195(75 .0%)  274(71.4%) 65(67.7%)Quotes 488(75.8%) 212(81 .5%)  276(71.9%) 73(76.0%)Aux-Match 479(74.4%) 205(78 .8%)  274(71.4%) 71(74.0%)Parallel-Match 479(74.4%) 209(80 .4%)  270(70.3%) 73(76.0%)Composite 232(36.0%) 67(25.8%) 165(43.0%) 16(16.7%)Table 8Factors activated incrementally.System Subpart Total (644) WSJ (260) Brown (384) Blind Test (96)Number Correct Number Correct Number Correct Number CorrectRecency-Only 188(29.2%) 52(20.0%) 136(35.4%) 14(14.6%)Post-Filter 383(59.5%) 155(59 .6%)  228(59.4%) 51(53.1%)Syntactic Filter 445(69.1%) 187(71 .9%)  258(67.2%) 63(65.6%)Clause-Rel 461 (71.6%) 200(76.9%) 261 (68.0%) 71 (74.0%)Quotes 467(72.5%) 201 (77.3%) 266(69.3%) 71 (74.0%)Aux-Match 479(74.4%) 209(80 .4%)  270(70.3%) 73(76.0%)Parallel-Match 489(75.9%) 212(81 .5%)  277(72.1%) 73(76.0%)Full VPE-RESSystem 489(75.9%) 212(81 .5%)  277(72.1%) 73(76.0%)4.4 System ComponentsThe most important system component is the Composite Factor, which is a combinationof the Syntactic Filter, the Post-Filter, and Clause-Rel.
The contribution of Clause-Rel isnot evident individually; if it is the only factor activated together with Recency-Only,performance in the complete corpus actually declines from 29.2% to 28.1%.
However,this is because Clause-Rel requires the Syntactic Filter to make a contribution.
Thiscan be observed from the fact that Composite performs better than its individual com-ponents.
Also, when Clause-Rel is the deactivated factor, performance declines from75.9% to 72.8%.
The Parallelism Preference Factors, Aux-Match and Parallel-Match,537Computational Linguistics Volume 23, Number 4also make an important contribution: when they are activated in the incremental nal-ysis, there are 22 additional correct selections in the complete corpus, an improvementof 3.4%.4.5 Errors and Evaluation CriteriaMany of the errors occurring under the Exact Match criterion involve alternatives thatare virtually identical in meaning, as in the following example:(17) Stephen Vincent Benet's John Brown's Body \[VP comes immediately tomind\] \[pp in this connection\], as does John Steinbeck's The Grapes OfWrath and Carl Sandburg's The People, Yes.Here, VPE-RES selected comes immediately tomind, since the PP in this connectionis parsed as a sister to the VP.
One coder selected comes immediately to mind in thisconnection, while the other coder made the same selection as VPE-RES.
It is difficultto see any difference in meaning between the two choices.Because of examples like this, we believe Head Overlap or Head Match are prefer-able criteria for success.
Even with the Head Match criterion, there are errors thatinvolve very subtle differences, uch as the following example:(18) We were there at a moment when the situation in Laos threatened toignite another war among the world's giants.
Even if it did not, howwould this little world of gentle people cope with its new reality ofgrenades and submachine guns?The coder selected ignite another war among the world's giants, while VPE-RES selectedthreatened to ignite another war among the world's giants.Some errors result from problems with the Syntactic Filter.
The following exampleillustrates a case of antecedent containment that is not recognized by the filter ascurrently formulated.
(19) All the generals who held important commands in World War 2, did notwrite books.
It only seems as if they did.The VPE-RES system incorrectly selects eems as the antecedent, because it doesnot recognize that the VP headed by seems improperly contains the VPE.5.
Related WorkThere is no comparable work we are aware of dealing with VPE resolution; to ourknowledge, this is the first empirical study of a VPE resolution algorithm.
There is,however, a large body of empirically oriented work on pronoun resolution.
A promi-nent recent example is Lappin and Leass (1994), in which a pronoun resolution systemis evaluated on 360 examples taken from computer manuals, with a success rate of86%.
This work involves a post hoc evaluation of the system output, and it appearsthat evaluation is based on Head Match, although this is not discussed explicitly.
TheVPE-RES system achieves an 84.4% success rate according to Head Match in the BlindTest data from the Wall Street Journal corpus.
This compares favorably with Lappinand Leass's result, especially considering that computer manual text is a good dealmore restricted than newspaper text.
It is also likely that the VPE-RES success ratewould be higher using a post hoc evaluation scheme.538Hardt VP EllipsisPrevious work on pronoun resolution (Hobbs 1978, Walker 1989) reports highersuccess rates.
However, these involved hand-tested algorithms on rather small datasets.
Lappin and Leass (1994) implemented and tested Hobbs's algorithm, and reportedresults that were about 4% less than that of Lappin and Leass (1994).6.
Conclusions and Future WorkWe have described the first empirical study of VP ellipsis resolution, using a data set of644 examples from the Penn Treebank to develop and test a VPE resolution system.
Thesystem performance is comparable to the best existing systems for pronoun resolution.The Preference Factors in the system were selected and developed in an itera-tive testing and refinement process.
In future work, we will explore the relationship ofthese factors to more fundamental nd general features of discourse interpretation.
Wesuspect hat the preferences for clausal relations, parallelism, and quotation structureall involve clues to the underlying discourse structure, reflecting a general preferencefor configurations where the VPE clause and antecedent clause participate in a dis-course relation.
TM A clausal relation is simply an explicit syntactic lue that there is adiscourse relation between two clauses, while similarity of parallel elements i another,more indirect clue of a discourse relation, as discussed for example in Hobbs (1979)and Hobbs and Kehler (1997).We plan to apply the general approach to other discourse-processing problems,such as other forms of ellipsis, and pronoun resolution.
We conjecture that suitablygeneralized versions of the constraints and heuristics in the current system can beapplied to a broad range of discourse-processing problems.Appendix A: Treebank TagsIn this appendix we include a list of the Penn Treebank part-of-speech tags (Ta-ble 9) and syntactic ategory labels (Table 10), taken from Marcus, Santorini, andMarcinkiewicz (1993).Table 9The Penn Treebank POS tagset.1.
CC Coordinating conjunction 14.
NNP Proper noun, singular2.
CD Cardinal number 15.
NNPS Proper noun, plural3.
DT Determiner 16.
PDT Predeterminer4.
EX Existential there 17.
POS Possessive ending5.
FW Foreign word 18.
PRP Personal pronoun6.
IN Preposition/subord.
conjunction 19.
PP$ Possessive pronoun7.
JJ Adjective 20.
RB Adverb8.
JJR Adjective, comparative 21.
RBR Adverb, comparative9.
JJS Adjective, superlative 22.
RBS Adverb, superlative10.
LS List item marker 23.
RP Particle11.
MD Modal 24.
SYM Symbol (mathematical or scientific)12.
NN Noun, singular or mass 25.
TO to13.
NNS Noun, plural 26.
UH Interjection18 For example, Asher (1993) claims that VPE requires a discourse r lation between VPE and antecedentclauses.539Computational Linguistics Volume 23, Number 4Table 9Continued.27.
VB Verb, base form28.
VBD Verb, past tense29.
VBG Verb, gerund/present participle30.
VBN Verb, past participle31.
VBP Verb, non-3rd ps.
sing.
present32.
VBZ Verb, 3rd ps.
sing.
present33.
WDT wh-determiner34.
WP wh-pronoun35.
WP$ Possessive wh-pronoun36.
WRB wh-adverb37.
# Pound sign38.
$ Dollar sign39.. Sentence-final punctuation40., Comma41.
: Colon, semi-colon42.
( Left bracket character43. )
Right bracket character44. "
Straight double quote45. '
Left open single quote46. "
Left open double quote47. '
Right close single quote48. "
Right close double quoteTable 10The Penn Treebank syntactic tagset.Tags1.
ADJP2.
ADVP3.
NP4.
PP5.
S6.
SBAR7.
SBARQ8.
SINV9.
SQ10.
VP11.
WHADVP12.
WHNP13.
WHPP14.
XNull elements2.
03.
T4.
NILAdjective phraseAdverb phraseNoun phrasePrepositional phraseSimple declarative clauseClause introduced by subordinating conjunction or 0 (see below)Direct question introduced by wh-word or wh-phraseDeclarative sentence with subject-aux inversionSubconstituent of SBARQ excluding wh-word or wh-phraseVerb phraseWh-adverb phraseWh-noun phraseWh-prepositional phraseConstituent of unknown or uncertain category"Understood" subject of infinitive or imperativeZero variant of that in subordinate clausesTrace--marks position where moved wh-constituent is interpretedMarks position where preposition is interpreted in pied-piping contextsAcknowledgmentsThis work was partially supported by aVillanova University Summer ResearchGrant, and National Science FoundationCareer Grant IRI-9502257.
Thanks to GreggDavis, who did a substantial mount of LISPcoding, improving the system performancegreatly.
Thanks also to Gar Donecker forinvaluable help in analysis,coding and organization.
Michael Feeneyimplemented comparison and extractionutilities, and also did coding.
RebeccaPassoneau first suggested the use of coders,and also contributed some coding.
BonnieWebber, Mark Steedman, Aravind Joshi, andMarilyn Walker provided important adviceand feedback, and useful and constructivesuggestions were given by three anonymousCL reviewers.540Hardt VP EllipsisReferencesAsher, Nicholas.
1993.
Reference toAbstractObjects in English.
Dordrecht.Brennan, Susan E., Marilyn WalkerFriedman, and Carl J. Pollard.
1987.
Acentering approach to pronouns.
InProceedings ofthe 25th Annual Meeting.Association for ComputationalLinguistics.Chao, Wynn.
1987.
On Ellipsis.
Ph.D. thesis,University of Massachusetts-Amherst.Chomsky, Noam.
1981.
Lectures onGovernment and Binding.
Foris.Dalrymple, Mary, Stuart Shieber, andFernando Pereira.
1991.
Ellipsis andhigher-order unification.
Linguistics andPhilosophy, 14(4).Fiengo, Robert and Robert May.
1994.
Indicesand Identity.
MIT Press, Cambridge, MA.Hankamer, Jorge and Ivan Sag.
1976.
Deepand surface anaphora.
Linguistic Inquiry,7(3).Hardt, Daniel.
1992.
An Algorithm for VPEllipsis.
In Proceedings ofthe 30th AnnualMeeting, Newark, DE.
Association forComputational Linguisitics.Hardt, Daniel.
1993.
Verb Phrase Ellipsis:Form, Meaning, and Processing.
Ph.D. thesis,University of Pennsylvania.Hardt, Daniel.
1995.
An empirical approachto VP ellipsis.
In Proceedings, AAAISymposium on Empirical Approaches inDiscourse and Generation, Palo Alto, CA.Harper, Mary Patricia.
1990.
TheRepresentation f Noun Phrases in LogicalForm.
Ph.D. thesis, Brown University.Hobbs, Jerry.
1978.
Resolving pronounreferences.
Lingua, 44:311-338.Hobbs, Jerry.
1979.
Coherence andcoreference.
Cognitive Science, 3:67-90.Hobbs, Jerry and Andrew Kehler.
1997.
ATheory of Parallelism and the Case of VPellipsis.
In Proceedings ofthe 35th AnnualMeeting, Madrid, Spain.
Association forComputational Linguisitics.Jacobson, Pauline.
1992.
Antecedentcontained eletion in a variable-freesemantics.
In Proceedings ofthe SecondConference on Semantics and LinguisticTheory, Columbus, Ohio.Kehler, Andrew.
1993.
The effect ofestablishing coherence in ellipsis andanaphora resolution.
In Proceedings ofthe31st Annual Meeting, Columbus, OH.Association for ComputationalLinguistics.Kitagawa, Yoshihisa.
1991.
Copying identity.Natural Language and Linguistic Theory,9(3):497-536.Lappin, Shalom.
1984.
VP anaphora,quantifier scope, and logical form.Linguistic Analysis, 13(4):273-315.Lappin, Shalom.
1992.
The syntactic basis ofellipsis resolution.
In Proceedings oftheStuttgart Ellipsis Workshop, Stuttgart,Germany.Lappin, Shalom and Herbert J. Leass.
1994.An algorithm for pronominal anaphoraresolution.
Computational Linguistics.Lappin, Shalom and Michael McCord.
1990.Anaphora resolution in slot grammar.Computational Linguistics, 16(4).Malt, Barbara.
1984.
The role of discoursestructure in understanding anaphora.Journal of Memory and Language, 24:271-289.Marcus, Mitchell P., Beatrice Santorini, andMary Ann Marcinkiewicz.
1993.
Buildinga large annotated corpus of English: ThePenn Treebank.
Computational Linguistics,19(2).May, Robert.
1985.
Logical Form: Its Structureand Derivation.
MIT Press, Cambridge,MA.Priist, Hub, Remko Scha, and Martinvan den Berg.
1991.
A discourseperspective on verb phrase anaphora.Linguistics and Philosophy, 17(3):261-327.Ristad, E. S. 1990.
Computational Structure ofHuman Language.
Ph.D. thesis,Massachusetts Institute of Technology.Ross, H. 1967.
Constraints on variables insyntax.
MIT Department of Linguisticsand Philosophy.Sag, Ivan and Jorge Hankamer.
1984.Towards a theory of anaphoric processing.Linguistics and Philosophy, 7:325-345.Sag, Ivan A.
1976.
Deletion and Logical Form.Ph.D.
thesis, Massachusetts Institute ofTechnology.
(Published 1980 by GarlandPublishing, New York).Walker, Marilyn.
1989.
Evaluating discourseprocessing algorithms.
In Proceedings ofthe27th Annual Meeting, Vancouver, Canada.Association for ComputationalLinguistics.Webber, Bonnie Lynn.
1978.
A FormalApproach to Discourse Anaphora.
Ph.D.thesis, Harvard University.
(Published1979 by Garland Publishing, New York).Williams, Edwin.
1977.
Discourse andlogical form.
Linguistic Inquiry,8(1):101-139.541
