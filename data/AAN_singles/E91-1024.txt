DATR AS A LEX ICAL  COMPONENT FOR PATRJames Kilbury, Petra Naerger, Ingrid RenzSeminar f/lr AUgemeine SprachwissenschaftHeinrich-Heine-Universit,'tt DilsseldorfUniversitatsstrai\]e 1D-4000 l:Ydsseldorf 1Federal Republic of Germanye-mail: kilbury@dd0rud81 .bimetnaerger@dd0rud81.bitnetrenz@ dd0rud81 .bitnetABSTRACTThe representation f lexical entriesrequires pecial means which basic PATR sys-tems do not include.
The language DATR,however, can be used to define an inheritancenetwork serving as the lexical component.
Theintegration of such a module into an existingPATR system leads to various problems whichare discussed together with possible solutionsin this paper.means that associated information isrepresentedtogether or bundled.
One advantage of thisbundled information is its reusability, whichallows redundancy tobe reduced.
The represen-tation of lexical information should enable usto express a further kind of generalization,namely the relations between regularity, sub-regularity, and irregularity.
Furthermore, therepresentation has to be computationaUy tracta-ble and -- possibly with the addition of"syntac-tic sugar" -- more or less readable for humanusers.1 MOTIVATIONIn the project "Simulation of LexicalAcquisition" (SIMLEX) unification is used tocreate new lexical entries through the monoto-nic accumulation of contextual grammaticalinformation during parsing.
The system whichwe implemented for this purpose is a variant ofPATR as described in (Shieber, 1986).Besides collecting the appropriate infor-marion for an unknown word, i.e.
a lexeme notalready specified in the given lexicon, the cre-ation of its new lexical entry is a major goal.In this context questions about the nature oflexical information, the structuring, and therepresentation f this information must be an-swered.
The present paper is mainly concernedwith the structuring and representation f infor-marion in lexical entries.2 REPRESENTATION OF LEXICALINFORMATIONThe formalism of PATR offers twopossible means of representing lexical informa-tion.
First of all, the information can be encod-ed in feature structures directly.
Except forcomputational tractability, none of the othercriteria re met.
The second facility consists ofmacros or templates which assemble the lin-gnistic information so that it can be reused invarious places in the lexicon.
This meets themost important of the above-mentioned condi-tions and reduces redundancy.
But the encodedinformation is inherited monotonically, i.e.
onlyregularities can be expressed.
In order to struc-ture lexical information adequately, other ela-tions like subregularities and exceptions shouldalso be expressible.Macros fail to achieve this, whereasdefault inheritance networks are well-suited forthe purpose.
In the following section we givean overview of one such network formalismwhich was primarily designed for representinglexical information.We assume that certain conditions mustbe met by an adequate r presentation f lexicalinformation.
The most important of these is thatit captures linguistic generalizations, which- 137  -3 OVERVIEW OF DATRDATR (described in detail by Evans/Gazdar, 1989a; 1989b; 1990)is a declarativelanguage for the definition of semantic net-works which allows for defaults as well asmultiple inheritance.
Its general properties arenon-monotonicity, functionality, and determinis-tic search.A DATR theory (or network descrip-tion) is a set of axthms (or expressions) whichare related to each other by references.
Togeth-er they define a hierarchical structure, a net.Both regularities and exceptions can be ex-pressed, regularities using default inheritance,and exceptions, overriding.DATR axioms consist of node-pathpairs associated with a right-hand side.
Thiscan be a value (atomic or lis0, or an evaluableDATR expression if the value is to be inherit-ed from another node, path, or node-path pair.The following DATR theory comprising threenode definitions I encodes familiar linguisticinformation to illustrate some relevant DATRfeatures:(1)LEXIC.AL: <syn major bar> ~ zero.NOUN:  <> == LEXICAL<syn major nv n> == yes<syn major nv v> == no.ADJ: o == LEXICAL<syn major nv n> == NOUN<syn major nv v> ==<syn major nv n>.The represented information can beretrieved with special DATR queries.
Thesealso consist of a node-path pair, whose evalua-tion returns the value sought.
With the aboveDATR description the following examples showsensible DATR queries and their correspondingvalues:(2)NOUN:<syn major nv n> 7yes (atomic value)NOUN:<syn major nv v> ?no (atomic value)NOUN:<syn major bar> ?zero (inherited from node LEXICAL)ADJ:<syn major nv n> ?yes (inherited from node NOUN)ADJ:<syn major nv v> ?yes (inherited from node NOUN via path<syn major nv n> in node ADJ)ADJ:<syn major bar> ?zero (inherited from node LEXICAL)Seven inference rules and a defaultmechanism are given for the evaluation ofDATR queries.
Their precise semantics andproperties are described in (Evans/Gazdar,1989b; 1990).A major feature of DATR is its distinc-tion between global and local inheritance.
Inthe above example only local inheritance isinvolved, but global inheritance plays a crucialrole in one of the later examples.
Variablesconstitute an additional device available inDATR but are assumed to have the status ofabbreviations.Despite their syntactic similarities,DATR and PATR differ completely in theirsemantics, o that there is no obvious way ofrelating the two formalisms to each other.
Someapproaches are discussed in the next section.4 RELAT ING DATR AND PATRA PATR system needs to have thelexical information it uses encoded in featurestructures consisting of attribute-value pairs.The lexical information represented in theDATR theory above (1) would appear as fol-lows when stated in feature structures:- 138 -(3)information specific to NO:syn . '
or.
~nv r ;  \[" '1/11tv: nOllllinformation specific to ADJO:~ n:  najor.
r InThe question that arises is how to relateDATR and PATR so that the hierarchicallystructured lexical information i  DATR can bemade available in PATR-usable feature struc-tures.4.1  A DATR-PATR INTERFACEThe first idea that one might have is toexploit the syntactic similarities between thetwo formalisms and encode the lexical informa-tion in a DATR description like (1).
In this waya DATR axiom like NOUN: <~yn major nv n>== yes would be directly equivalent to the pathequation <NOUN syn major nv n> = yes inPATR, where the node name in DATR corre-sponds to the variable name for a feature struc-ture in PATR.
Although this looks reasonable,one major problem arises: You must knowexactly the path you want to query, i.e.
all itsattributes and their precise order.
If such aquery is posed, the answer will be the atomicvalue yielded by the DATR evaluation.Such an approach requires an interfacewith the following functions: Queries that thegrammar writer has stated explicitly have to bepassed on to DATR.
Every query together withthe resulthag value has to be transformed intoa PATR path equation (that partially describesa feature structure) and passed on to the PATRsystem.
What is most disturbing about thisstrategy is the fact that for every distinct PATRpath you have to know the correspondingDATR query.
It is tempting to think one couldsimply check which paths are defined for agiven node, but this doesn't work because ofinheritance: the entire network is potentiallyrelevant.
So in effect all the PATR structuresexcept he atomic values have to be definedtwice: once in the DATR statements and oncein the queries.
This redundancy annot be elim-inated unless types for the feature structure aredeclared which are consulted in formulating thequeries.4.2 USING DATR OUTPUT DIRECTLYA completely different approach is toformulate a DATR theory which gives thelexical information in a PATR-usable format(i.e.
a feature structure) as the result of theevaluation of a DATR query.
Thus, the DATRdescription reflects the hierarchical structure ofthe lexical information and consequently meet.~one of the main requirements for an adequaterepresentation that cannot be met by a simplePATR formalism.
The resulting feature struc-tures include all the information ecessary forPATR but neglect he inheritance structure,although the latter is involved in their construc-tion (i.e.
the evaluation of queries).
There arevarious DATR-programming techniques thatrealize these ideas.
Three examples will b::presented here which cover the lexical informa-tion encoded in (1).The first technique, which is illustratedin (4) 2 , uses global inheritance (representedwith double quotation marks) to store the nodeat which the query originates.
This also allowsother information in the global node to be.accessed.- 139  -(4)SYNTAX:MAJOR:( maj ' : 'NV:( nv ':' \[NOUN:ADJ:<> == ( \[ syn ' : '  \[ "<synpaths>" \] \] ).<> == SYNTAX<synpaths> ==\[ "<tmj~ths>" \] ).<> == MAJOR<majpafils> ==n ' : '  "<n>" ,  v ' : '  "<v>" \]).o == NV<n> == yes~'W> == no.<> == NV<n> == yes<v> == yes .BAR:  <> == MAJOR<majpaths> == ( bar ':' "<bar>" ).BAR0: o == BAR<bar> ~ zero.This DATR theory makes it possible toget the feature structure associated with thenode NOUN, i.e.
the evaluation of the DATRquery NOUN:<>.To evaluate this DATR query the nodesNV, MAJOR, and SYNTAX are visited.
In thenode SYNTAX part of the corresponding featurespecification is constructed and the evaluablepath <synpaths> refers back to the originalnode NOUN.
Then the query NOUN:<synpaths> is evaluated in the same way up tothe node MAJOR, where the next part of thefeature structure is built and the evaluable path<majpaths> refers again to the global nodeNOUN.
At the end of the evaluation the featurestructure \[syn:\[maj:\[nv: ln:yes,v:no1111 emer-ges.Lexical entries defined with the DATRnetwork above have the form FROG: <> ==("NOUN .... BARO"), which means intuitivelythat the lexeme frog is an nO.
Given the net-work in (4), the value of the query FROG:<>will inherit the information of the global nodesNOUN and BARO.
Thus, the global environ-ment is changed in the course of the evaluation.As a declarative language, DATR isindependent of the procedural evaluation strate-gies embodied in particular DATR-implementa-tions.
Nevertheless, DATR theories like (4)may themselves reflect different evaluationstrategies (just as different search strategiesmay be implemented in pure PROLOG, inde-pendently of the particular PROLOG implemen-tation).The evaluation strategy in (4) can bedescribed as top-down depth-first and is rathercostly because of the cyclic returns to the glob-al nodes.
A more efficient strategy is illustratedin (5).
This DATR description embodies abreadth-first search and uses variables (desig-nated by the prefix $) instead of changing theglobal environment.
(5)SYNTAX:  <$NV $BAR> ==( \[ syn ':' \[ MAJOR:<$NV $BAR> \] \] ).MAJOR:  <$NV $BAR> ==( maj ' : '  \[ NV:<$NV>,  BAR:<$BAR> \] ).NV:N:V:N VAL:V VAL:( nv *" \[<$NV> ==N:<$NV>, V:<$NV> \] ).<$NV> == ( n ':' N_VAL:<$NV> ).<$NV> == ( v ':' V_VAL:<$NV> ).<noun> == yea<adj> ~ yes?~ ~---~ 110.<verb> ~ yes<adj> ~ yes~ -~--= no.BAR:  <$BAR>( bar ':' BAR_VAL:<$BAR> ).BAR_VAL: <barO> == zero<bar l> = ono<bar2> =ffi two.Here an appropriate query would beSYNTAX: <noun barO>.
At the origin of thequery the outer layer of  the feature structure isalready constructed.
The rest of the featurestructure results from evaluating MAJOR:<$NV$BAR>, where SNV is instantiated with nounand $BAR with barO as in the original query.We then obtain the feature structure\[syn:\[maj:\[nv:\[n:yes,v:no\],bar:zero\]\]\] as theresult of the evaluation.
Unlike the network in(4), it is not possible to ask for just a part ofthis feature structure: Neither the informationabout the N/V-scheme nor the informationabout the bar level can be queried separately.An entry for the lexeme frog given thenetwork (5) would have the form FROG:<>== SYNTAX::<noun barO>, which of .coursealso means that the lexeme frog is an nO.
Butthis time the information is inherited from the- 140  -node SYNTAX, where the value provides theframe for the resulting PATR feature structure.Apart from the differing DATR tech-niques employed, the resulting feature struc-tures for a lexical entry also differ slightly.While the first is nearer to a set of PATR pathswhich has to be collapsed into a single featurestructure, the second has exactly the form re-quired by the PATR system we use.The third technique is illustrated in (6).
(6)SYNTAX:MAJOR:NV:BAR:N:V:<> == ( syn ':' \[ MAJOR \] ).<> == (maj ':' \[ NV, BAR 1).<> == (nv ':' \ [N ,V\ ] ) .<> == ( bar ':' "<bar>" ).== ( n ':' <value "<eat>"> )<value nO'> == yes<value adj0> ~ yes<value> =--- rio.0 == ( v ' : '  <value "<cat>"> )<value vO> == yes<value adjO> == yes<value> == no.LEX ICAL :  ~:> == ( \[ SYNTAX \] )<bar> ~ zero.NOUN: <> == LEXICAL<Cat> == riO.ADJ :  <> == LEXICAL<cat> == adjO.An appropriate query for this DATRtheory would be NOUN:<>, the value of whichis \[syn:lmaj:\[nv:\[n:yes,v:no1,bar:zero111.
Theevaluation of this query is similar to the one in(5) in that the value of SYNTAX:<> constitutesthe frame of the resulting PATR-usable featurestructure.
Unlike (5), no variables are used;instead, information from the global node isused via global path inheritance to specify thevalues.
Notice that whereas with (4) the globalnode is changed, it remains unchanged duringthe evaluations with (6).The advantages of (6) are obvious.Since neither variables nor global nodes areused, fewer DATR facilities are involved.
Nev-ertheless, the required PATR feature structuresCan be defined.
For example, the lexical entryfor frog would be FROG:<>==NOUN, wherethe noun-specific nformation is inherited fromNOUN.This third approach forms the base forour current lexicon.
Some of the related issuesare raised in the next section.5 THE DATR LEX ICONIt has been shown above that DATRtheories can serve as a lexicon for a PAT Rsystem where the lexemes are represented asDATR nodes and the returned values of queriesare the corresponding feature structures.
In alexicon which is formulated as in (6), aparl;from the lexical nodes (i.e.
nodes like FROGwhich define lexemes) two other kinds of nodescan be distinguished: nodes like SYNTAX orNV, which correspond to PATR attributes, andnodes like NOUN or LEX/CAL, which representa kind of type information (see Pollard/Sag,1987).
The lexemes inherit this informationthrough reference to the type nodes, while thelexeme-specific information is as~ciated direct.ly with the lexical nodes.There are several differences betweenthese three kinds of nodes.
Whereas it is appro.priate to pose a query like FROG:<> orNOUN:<>, such queries make no sense fornodes like SYNTAX.
In this respect lexemes andtypes are related.Another property distinguishes lexicalnodes from type nodes.
The latter are hierarchi-cally structured, while the former are unstruc-tured in the sense that they refer to types butnot to other lexemes.
The structuring of thetype nodes reflects the above mentioned regu-larities as well as irregularities.The following DATR theory is a lexi-con fragment for a possible classification ofintransitive verbs in German.
Regular verbs(e.g.
schlafen ',sleep') take a nominative subjectand inherit all type-specific information fromthe node INTRANS_VERB.
One exception areverbs with expletive subject (e.g.
regnen 'rain'),another those with nonnominative (accusativeor dative) subject (e.g.
dilrsten 'suffer fromthirst' with accusative).
These verbs refer to thetypes nodes INTRANS_VERB_EXPL and IN-TRANS_VERB_ACC, respectively.
The lattertypes inherit from the node INTRANS_VERBbut override some of its information.141 -(7)INTRANS_VERB:INTRANS_VERB_EXPL:INTRANS_VERB_ACC:<> == VERB<cat subject> =ffi n2<case subject> ~ nm~a~e<status subject> ~ norm.== INTRANS_VERB<status subject> ~ expletive.<> == INTRANS VERB<case subject> ~ accusative.6 CONCLUDING REMARKSWe have seen that it is possible toformulate the lexicon of a PATR system as aDATR theory.
That is, given a lexical entry inDATR, a corresponding feature structure can bederived.
A system postulating new entries forunknown words on the basis of contextualinformation during parsing (Kilbury, 1990)must be able to convert a given feature struc-ture into a corresponding lexical entry in DATRso that the new lexeme is located and integratedin the lexical network.
To solve this problemthe concept of type nodes can be exploited.A final difficulty involves certainPATR-specific devices like disjunctions andreentrancies for which no obvious DATR facili-ties are available.
At present we still have onlyad hoc solutions to these problems.FOOTNOTES1.
NOUN:abbreviatesNOUN:NOUN:<> == LEXICAL<syn major nv n> == yes.== LEXICAL<syn major nv n> == yes.2.
The colons in single quotes, the commas, and the squarebrackets are DATR atoms, not part of the language itself.Incontrast, he parentheses of DATR enclose a list value.ACKNOWLEDGEMENTSThe research project SLMLEX is supported bythe DFG under grant number Ki 374/1.
Theauthors are indebted to the participants of theWorkshop on Inheritance, Tilburg 1990.REFERENCESDaelemans, Walter / Oazdar, Gerald(eds.)
(1990)Proc.
of the Workshop on Inheri-tance in Natural Language Processing.
1TKTilburg, The Netherlands.Evans, Roger / Gazdar, Gerald (1989a)Inference in DATR.
In Proc.
of the 4th Confer-ence of the European Chapter of the Associa-tion for Computational Linguistics, 66-71.Evans, Roger/Gazdar,  Gerald (1989b)The Semantics of DATR.
In A. Cohn (ed.
)AISB89, Proc.
:of the 7th Conference of theSociety for the Study of Artificial Intelligenceand Simulation of Behaviour, 79-87.
London:Pitman.Evans, Roger / Gazdar, Gerald (eds.
)(1990) The DATR Papers: February 1990 (=Cognitive Science Research Paper 139).
Schoolof Cognitive and Computing Sciences, Univer-sity of Sussex, Brighton, England.Gazdar, Gerald (1987) Linguistic appli-cation of default inheritance mechanisms.
InPeter J. Whitelock et al (eds.)
Linguistic Theo-ry and Computer Applications, 37-67.
London:Academic Press.Kilbury, James (1990) Simulation ofLexical Acquisition.
In Proc.
of ALLC-ACH 90:The New Medium, 129-130.
University ofSiegen, FRG.Pollard, Cad / Sag, Ivan (1987) Infor-mation-Based Syntax and Semantics, I: Funda-mentals.
Stanford, Calif.: CSLI.Shieber, Smart M. (1986) An Introduc-tion to Unification-Based Approaches toGram-mar.
Stanford, Calif.: CSLI.142 -
