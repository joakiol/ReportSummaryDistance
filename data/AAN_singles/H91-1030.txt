AUTODIRECTIVE MICROPHONE SYSTEMSFOR NATURAL COMMUNICATION WITH SPEECH RECOGNIZERSJ.
L. Flanagan and R. MammoneCAIP Center, Rutgers University, New Brunswick, New JerseyG.
W. ElkoAT&T Bell Laboratories, Murray Hill, New JerseyAbstractTwo technological dvances upport new sophis-tication in sound capture; namely, high-quality low-cost electret microphones and high-speed economicalsignal processors.
Combined with new understand-ing in acoustic beamforming, these technologies per-mit spatially-selective transduction of speech signalsseveral octaves in bandwidth.
Spatial selectivity mk-igates the effects of noise and reverberation, and digi-tal processing provides the capability for speech-seeking, autodirective performance.
This report out-lines the principles of autodirective beamforming foracoustic arrays, and it describes two experimental im-plementations.
It also summarizes the direction andemphasis of continuing research.IntroductionIn many applications of automatic speech recog-nition, it is desirable for the talker to have hands andeyes free for concurrent tasks.
Typical examples in-clude parcel sorting, product assembly and inspec-tion, voice dialing for cellular telephones, and dataplotting and manipulation i  a situation room.
Theuser frequently needs to move around in theworkspace, which often is noisy and reverberant,while issuing commands to the speech recognizer.Electrical tethers, close-talking microphones andbody-worn sound equipment represent undesirableencumbrances.
Ideally, one would like an acousticsystem able to capture high-quality sound from natu-ral conversational exchanges inthe work space.Speech-seeking autodirective microphone arraysenable unencumbered freedom of movement, whileproviding sound pickup quality approaching that ofclose-talking microphones.
Low-cost high-qualityelectret microphones, in combination with economi-cal signal processing, permit sophisticated beam-forming and dynamic beam positioning for tracking amoving talker.
Multiple beam formation permits"track while scan" performance, similar to phased-array navigational radars, so that multiple soundsources can be monitored and algorithmic decisionsmade about he signals \[1,2\].
Beamforming has beenfound to be more useful than adaptive noise filteringfor sound pickup in noisy, reverberant enclosures \[3\].This report mentions the acoustic principles in-volved in dynamic beamforming and the design fac-tors governing the ability of steered arrays to combatnoise and room reverberation.
It discusses the as-yetrudimentary algorithms for sound source location andspeech/non-speech detection.
It then describes an ini-tial application of an autodirective array and alimited-vocabulary connected-word speech recog-nizer for voice control of a video/audio teleconferenc-ing system.
It concludes by indicating the directionsfor research needed to refine further the capabilitiesof hands-free natural sound pickup.?
Acoustic BeamformingThe signal output H from an arbitrary array of Ndiscrete omnidirectional coustic sensors due to atime-harmonic plane wave with wavevector k isN-1H(k,  r )  = ~ a n e - j k ' r "  , (1)n=Owhere an is the amplitude weighting of sensor n, r,tis the position vector of sensor n with respect to somedefined origin, and the bold case indicates a vectorquantity.
The time-harmonic term is omitted forcompactness.The array can be steered to wave arrivals fromdifferent directions by intro4ucing a variable timedelay x,~ for each sensor element.
The response ofthe steered array is170N-1H(k, r ) = ~ an e - j (k ' r '+?~x ' )  , (2),q=0where ?o = 2nf  is the radian frequency.
It isconvenient to make a change of variables and definek' as k'  = ~ k',  where k' is the unit vector in theCwavevector k' direction, c is the speed of sound, andAtrn  " k = - cxn  .
(3)Equation (2) can then be rewritten asN-  1 - j k "  ?
r .H(k , r )  = ~ ane  , (4)n=0where k"  = k -k ' .
Equation (4) shows that thearray response is maximum when \ [k" l  is 0, orwhen the delays have been adjusted to co-phase thewave arrival at all sensors.
The received spat ia lfrequency is 0 (or DC), and the array has a maximumN-1response which is equal to ~ an.
For wavesn=Opropagating from directions other than k '  theresponse is diminished.This principle has been used to design one-dimensional and two-dimensional rrays of sensorsspaced by d distance.
The element spacing dictatesthe highest frequency for which spatial aliasing (or,ambiguity in directivity) does not occur.
Thisfrequency also depends upon the steering parametersbut has a lower bound offupp~r = c /2d .
Alternativelythe spacing is chosen as d=Xupper /2 .
The  lowestfrequency for which useful spatial discriminationoccurs depends upon the overall dimensions of thearray.For speech pickup applications, the desiredbandwidth of the array is greater than three octaves.The magnitude of k"  in (4) is proportional tofrequency, hence the beamwidth and directivity areinversely proportional tofrequency.A design artifice to combat this frequencydependence is to use "harmonic nesting" \[1,2\] ofthe sensors, so that different harmonically-spacedgroups of sensors are used to cover contiguousoctaves.
Some sensors in the nest serve every octaveband.
Figure 1 shows a nested two-dimensionalarray of sensors, its directivity index as a function offrequency, and its beam pattern when the a,,'s of (4)are Chebyshev weighted for - 30 dB sidelobes.Using these relations one-dimensional and two-dimensional arrays have been designed forconferencing and voice-control applications (seeFig.
2).
Digitally-addressable ucket brigade chipson each sensor provide the delay steering undercontrol of a 386 computer.Algorithms for Speech-Seeking AutodirectivePerformanceBecause of limited computational power in thecontrol computer, algorithms for sound-source loca-tion and speech detection are, as yet, rudimentary.Sources are located by a blind search and energy de-tection, and speech/non-speech decisions are made bywaveform heuristics.
Beams can be positioned inless than a millisecond, but speech decisions requireabout wenty milliseconds in a given position.Full digital designs are in progress having enoughsignal processing power to make computations ofcorrelations and cepstral coefficients.
This will en-able more sophistication i both source location andspeech detection.Experimental ApplicationsThe large two-dimensional rray, consisting ofover 400 electret microphones, has been in use forthe past year and a half for interlocation conferencingfrom an auditorium seating more than 300 persons.Performance greatly surpasses the traditional isolatedmicrophones in the room, and speech quality compa-rable to Lavalier pickups can be achieved (Fig.
3a).The small one-dimensional rray, consisting of21 pressure-gradient elements, is being used for anexperimental multimedia conferencing system (Hu-MaNet) designed for ISDN telephone communica-tions \[4\], (Fig.
3b).Research DirectionsWith continued progress in arithmetic apabilityand economy of single-chip digital signal processors,substantial refinement and expanded performance arepossible for autodirective microphone systems.
Fourareas in particular are receiving research effort.
Theyare:?
accurate spatial location of multiple soundsources171?
reliable speech/non-speech discrimination?
spatial volume selectivity in sound capture (andprojection)?
characterization f array performance in noisyreverberant enclosuresProperties of three-dimensional microphonearrays appear to provide advantages in some of theseareas, and are presently being studied.
In particular,3D arrays can be delay-steered to beamforrn over 4 pisteradians without spatial ambiguity and withbeamwidth independent of steering direction \[5\].As with linear and planar arrays, harmonicnesting of the receiving elements in 3D arrays can beused to make beamwidth weakly dependent uponbandwidth coverage.
For example, a uniform cubicarray, shown in Fig.
4, provides unique, constant-width beam patterns over 4pi steradians.
The 3Dgeometry can also provide range selectivity that goesbeyond the point-focusing capabilities of 1D and 2Darrays.
These properties are currently under study.0 0 0 0 0 0 0 0 0 0 0 0 00 0 0 0 0 0 0 0 0 0 0 0 00 0 0 0 0 0 0 0 0 0 0 0 00 0 0 0o0o0o0o0o0o0 0 0 00 0 0 0 0 0 0 0 0 0 0  O00 0 0 0o0o0o0o0o0o0 0 0 00 0 0 e ,o .e -e .e ,e ,e  o o oo o o o o 00 0 0 I ' I ' I ' I ' I .
I .
I  0 0 0 o0o+ + + +o0o o o o 0 0 00 0 0 B ,e ,e*O,Q*Q*Q 0 0 0o o o 0 0 00 0 0  I * I * I * I , I , I * I  0 0 00 0 0 0o0o0o0o0o0o0 0 0 00 0 0 0 0  O0 O 0 0 0 0 00 0 0 0o0o0o0o0o0o0 0 0 00 0 0 0 0 0 0 0 0 0 0 0 00 0 0 0 0 0 0 0 0 0 0 0 00 0 0 0 0 0 0 0 0 0 0 0 0Fig.
1.
(a) Harmonic nesting of acoustic sensors forthree octaves.
Low-frequency elements are shownby the largest circles.
Mid and high frequencyelements are indicated by smaller and smallestcircles, respectively.
(b)Directivity index as afunction of frequency for nested sensors.
(c) Chebyshev weighted beam at broadside(sidelobes are - 30 dB down).References1.
J.L.
Flanagan, J. D. Johnston, R. Zahn, G. W.Elko, "Computer-steered microphone arraysfor sound transduction in large morns, J.Acoust.
Soc.
Amer.
78, 1508-1518 (1985).2.
J.L.
Flanagan, D. A. Berldey, G. W. Elko, J.E.
West, M. M. Sondhi, "Autodirective micro-phone systems," Acustica, February 1991 (inpress).3.
M.M.
Goulding and J. S. Bird, "Speech en-hancement for mobile telephony," IEEETrans.
Vehic.
Tech.
39, no.
4, 316-326(November 1990).4.
J.L.
Flanagan, D. A. Berkley, K. L. Shipley,"Integrated information modalities forHuman/Machine communications: 'HuMaNet',an experimental system for conferencing,"Jour.
Visual Communication a d Image Repre-sentation 1, 113-126 (November 1990).5.
J.L.
Flanagan, "Three-dimensional micro-phone arrays," J. Acoust.
Soc.
Amer.
82(1),$39 (1987).vXUJZ>-I-->i--UI,IJ550 I I I I !
I I I I !
I I I I I I I I I0 I I I I I I I I I I I I I I I I "1 I I300 4300FREOUENCY (Hz)172Fig.
2.
(a) One-dimensional nd(b) two-dimensional nested arraysof electret microphones.173Fig.
3.
(a) Auditorium installation of a 2D autodirective array.
(b)Teleconferencing application of a 1Dautodirective array.
The array provides input to a connected-word speech recognizer for controlling systemfeatures [4].Ys, zs)0d, , , , , , , , , , , , ,9= 45(~" = 135-8/= 45F = 200080, , .
.
, , ,80-8-= 0e '=0F = 2000' 191~ ' 'Fig.
4.
(a) geometry of a cubic array, unique beampattems for steering the cubic array to (b ~) ~' = 135 ?,0' =45 ?, and (c) t~' =45 ?
and 0' =0, respectively.175
