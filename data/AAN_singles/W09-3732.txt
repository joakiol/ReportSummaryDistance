Proceedings of the 8th International Conference on Computational Semantics, pages 299?304,Tilburg, January 2009. c?2009 International Conference on Computational SemanticsA Study of a Segmentation Technique for DialogueAct Assignation?Carlos-D.
Mart?
?nez-HinarejosInstituto Tecnolo?gico de Informa?tica, Universidad Polite?cnica de ValenciaValencia, Spaincmartine@dsic.upv.es1 IntroductionA dialogue system is usually defined as a computer system that interactswith a human user to achieve a task using dialogue [5].
In these systems,the computer must know the meaning and intention of the user input, inorder to give the appropriate answer.
The user turns must be interpretedby the system, taking only into account the essential information, i.e, theirsemantics for the dialogue process and the task to be accomplished.
Thisinformation is usually represented by labels called Dialogue Acts (DA) [2]which label different segments of the turn known as utterances [8].
The DAlabels usually take into account the semantics of the utterance with respectto the dialogue process, but they can include semantic information relatedto the task the dialogue is about.Therefore, the correct assignation of DA to a user turn is crucial to thecorrect behaviour of the dialogue system.
Several models have been proposedto perform this assignation.
In the recent years, probabilistic models havegained importance in this task [8].
In the assignation task, these modelsare applied on non-annotated dialogues.
Most of the previous work done onthe assignation of DA is performed on user turns segmented into utterances,although the availability of the segmentation is not usual in the dialoguecorpora nor in a real dialogue system.The proposed assignation models can be easily adapted to the lack ofsegmentation into utterances.
In this article, we present a model based on?Work supported by the EC (FEDER) and the Spanish MEC under grant TIN2006-15694-CO2-01 and by the Spanish research programme Consolider Ingenio 2010: MIPRCV(CSD2007-00018)1299Hidden Markov Model (HMM) and N-grams that can be applied to seg-mented and unsegmented turns.
The results show that the lack of segmen-tation causes many errors in the assignation of DA.
Therefore, we proposeanother model based on N-grams (NGT model) that segments a user turninto utterances previously to the DA assignation.2 ModelsThe statistical model that provides the DA assignation uses the currentturn word sequence W and the previous DA sequence U?to obtain theoptimum DA sequence?U that maximises the posterior probability of U , i.e.,?U = argmaxUPr(U |W,U?).
This formula can be developed as presentedin [6] to obtain:?U = argmaxU?r,sr1r?k=1Pr(uk|uk?1k?n?1) Pr(Wsksk?1+1|uk) (1)In this equation, Pr(uk|uk?1k?n?1) can be modelled as an N-gram (of degreen) and Pr(Wsksk?1+1|uk) as a HMM.
This model can be used when there is anavailable segmentation by simply eliminating the sum and prod operatorsand fixing the skvalues to those provided by the segmentation.The NGT model [7] can provide a segmentation of a dialogue turn.
Thismodel is inspired in the GIATI methodology [3], which relies on the conceptof alignment between the input and the output sentences.
In our case, theinput sequence is the dialogue turn, and the output sequence is the utter-ances boundaries.
A re-labelling process is applied on this pair of sequencesto convert them to an unique sequence where input and output are joined.From this sequence that includes the utterance boundaries, an N-gramcan be inferred.
We implemented the Viterbi search to work directly on theN-gram that acts as a transducer, and gives the name to the model: N-gramtransducers (NGT).Therefore, given an NGT model and an unsegmented turn, a segmenta-tion of the turn into utterances can be obtained by using the Viterbi search.In the next section we present the experiments that verify the accuracy ofthe segmentations provided by this model along with the results the HMM-based model provides with these segmentations.23003 Experiments and discussionIn this section, we compare the performance of the HMM-based model whenusing the correct segmentation into utterances, the NGT segmentation andwhen no segmentation of the turns is given.
The experiments were performedon the SwitchBoard corpus [4] and on the Dihana corpus [1] (with the twoand three-level labels).
All the experiments were performed using a cross-validation approach.
Some simplifications were performed on the corporabefore training the models and performing the experiments.The HMM model is trained for each DA label from the utterances ofthe training dialogues annotated with the corresponding label.
The N-grammodel is trained from the sequences of DA labels in the training dialogues.In the NGT model, the training dialogues were re-labelled to obtain thesequences of words with the attached utterance boundaries.
From these se-quences, different N-grams were inferred with N values from 2 to 5.
TheseN-grams were used to obtain the segmentation of the turns in the test dia-logues into utterances.The decoding step was performed using the Viterbi algorithm.
In thecase of the segmented dialogues, the segmentation was fixed to that pro-vided in the manual annotation or by NGT.
In the case of the unsegmentedturns, the search was performed on the complete turn and the optimal DAassignation provided the segmentation as a by-product.We can compute the accuracy of the segmentation given by the NGTmodel and the HMM-based model from the reference segmentation.
Theseresults are presented in Table 1, along with the error in the number of ut-terances (for bigram).
In general, the NGT model provides a more accuratesegmentation of the dialogue turns.
The reduction of the segmentation er-rors is quite significant, with relative reductions of more than a 20%.
This isin general true for the estimation of the correct number of utterances (exceptfor Dihana 2-levels).
With these results, we can expect that the decodingof the HMM-based model using the NGT segmentation would be of higherquality than the decodings on the unsegmented turns.The results are shown in Table 2.
The evaluation is done with twomeasures: complete turn DA error (all the labels must be coincident) andDAER (like WER for speech recognition systems but at the DA level).
Aswas expected, the number of erroneously labelled turns increases with theunsegmented approach for both measures.
This relative increase is lower inthe simpler dialogue corpora than in the more complex corpora.
The resultsfor the NGT model are with a bigram, and they show that in the case ofthe SwitchBoard corpus, the quality of the DA assignation is quite better,3301Table 1: Segmentation errors for complete turn with the NGT and HMM-based model, and errors in the number of estimated utterances for bigrams.Best results for each corpus are shown in boldface.Model Corpus / Ngram dgr.
2 3 4 5 Utt.
errorSwitchBoard 26.1 26.8 28.9 31.6 23.0NGT Dihana 2-levels 9.6 10.0 10.1 9.7 9.6Dihana 3-levels 13.6 11.9 12.4 11.3 12.8SwitchBoard 41.4 41.6 41.8 42.1 34.7HMM Dihana 2-levels 14.2 13.9 13.9 13.8 6.0Dihana 3-levels 38.8 38.6 38.6 38.6 17.3but in the rest of cases the improvement is not significant or even negative(Dihana 2-level).The results show that the clearest source of errors in DA assignationthat the NGT model can produce is due to the split of the turn into awrong number of utterances.
This clearly induces an erroneous assignmentof the DA sequence to the turn, as the number of labels will be differentto the reference and, consequently, the turn will be counted as erroneous.Even in the case of DAER error, this fact is present: for Dihana 2-levels, theunsegmented labelling provides a lower error rate than the NGT-segmentedone.
This is sound with the error in the number of segments that providethe HMM-based and the NGT model (Table 1, last column).Therefore, we can see a clear correlation between the assignation of anincorrect number of utterances and the error rates in DA assignation whenusing NGT-segmented turns or unsegmented turns.
Consequently, we canconclude that segmenting into the correct number of utterances is criticalto obtain a correct assignation of DA.
The DAER rate presented in Table 2confirms that considering only the turns with an incorrect segmentation buta correct number of utterances, many of them present a correct assignationof DA.The main conclusion we can extract from these experiments and resultsis that a correct hypothesis on the number of utterances of a dialogue turnis needed to obtain a correct assignation of DA to that turn, and that theaccuracy of the segmentation is not so important.Following these conclusions, future work will be directed to the obtain-ment of models that, given a dialogue turn, provide its number of utterances.4302Table 2: Errors for complete turn DA assignation and DAER results (forbigrams) with different segmentation conditions.
Best results for each corpusare shown in boldface.Segmentation Corpus / Ngram dgr.
2 3 4 5 DAERSwitchBoard 38.3 38.1 38.7 39.7 38.3Correct Dihana 2-levels 21.6 21.1 20.8 21.0 20.1Dihana 3-levels 24.6 24.0 24.2 24.8 24.7SwitchBoard 48.1 48.0 48.5 49.3 43.2NGT Dihana 2-levels 27.1 26.8 26.6 26.4 29.0Dihana 3-levels 30.6 30.0 30.1 30.7 30.6SwitchBoard 59.6 59.0 59.6 61.0 60.7Unsegmented Dihana 2-levels 24.6 24.3 24.4 24.6 24.0Dihana 3-levels 32.5 31.6 31.9 32.4 33.2This hypothesis on the number of utterances can be used to restrict the ex-ploration of possible segmentations in both the presented models and it canhelp to obtain better results.Other work can be done to improve the models or the use of other seg-mentation models.
This can help us to obtain more general conclusions onthe importance of segmentation for the DA assignation task.References[1] N. Alcacer, J.M.
Bened?
?, F.Blat, R.Granell, C.D.
Mart?
?nez, andF.Torres.
Acquisition and Labelling of a Spontaneous Speech DialogueCorpus.
In SPECOM, pages 583?586, Patras,Grecia, 2005.
[2] H. Aust, M. Oerder, F. Seide, and V. Steinbiss.
The philips automatictrain timetable information system.
Speech Communication, 17:249?263,1995.
[3] F. Casacuberta, E. Vidal, and D. Pico?.
Inference of finite-state trans-ducers from regular languages.
Pattern Recognition, 38:1431?1443, 2005.
[4] J. Godfrey, E. Holliman, and J. McDaniel.
Switchboard: Telephonespeech corpus for research and development.
In Proc.
ICASSP-92, pages517?520, 1992.5303[5] J.
Van Kuppevelt and R. W. Smith.
Current and New Directions inDiscourse and Dialogue, volume 22 of Text, Speech and Language Tech.Springer, 2003.
[6] C-D. Martinez-Hinarejos, J-M. Benedi, and R. Granell.
Statistical frame-work for a spanish spoken dialogue corpus.
Speech Comm., 50:992?1008,2008.
[7] C.D.
Mart??nez-Hinarejos.
Automatic annotation of dialogues using n-grams.
In Proceedings of TSD 2006, LNCS/LNAI 4188, pages 653?660,Brno, Czech Republic, Sep 2006.
Springer-Verlag.
[8] A. Stolcke, N. Coccaro, R. Bates, P. Taylor, C. van Ess-Dykema, K. Ries,E.
Shriberg, D. Jurafsky, R. Martin, and M. Meteer.
Dialogue act mod-elling for automatic tagging and recognition of conversational speech.Computational Linguistics, 26(3):1?34, 2000.6304
