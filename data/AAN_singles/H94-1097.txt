RESEARCH IN  LARGE VOCABULARYCONTINUOUS SPEECH RECOGNIT ION*Janet Baker, Larry Gillick, and Robert RothDragon Systems, Inc.320 Nevada St.Newton, MA 02160PROJECT GOALSThe primary long term goal of speech research at DragonSystems is to develop algorithms that are capable ofachieving very high performance large vocabulary con-tinuous speech recognition.
At the same time, we arealso concerned to keep the demands of those algorithmsfor computational power and memory as modest as pos-sible, so that the results of our research can be incorpo-rated into products that will run on moderately pricedpersonal computers.RECENT RESULTSThis past year's effort has been devoted to further workon speaker independent training and recognition, as wellas to the problem of adapting to new speakers and newmicrophones.
Important projects in the past year haveincluded the incorporation of a trigram language modelinto the forward pass, the use of phonetically tied mix-ture models, studies in adaptation, and experiments in-volving time resolution issues including the effects of theframe rate, the number of nodes per triphone model, andthe skipping of nodes.We implemented our trigram language model in the for-ward pass of our time synchronous decoder.
This wasdone in an attempt o avoid the search errors being re-ported at the last HLT meeting when using them onlyin the final pass of a multipass algorithm.
This archi-tecture, however, required much more memory than amultipass implementation.
As a result, we hit againstthe memory limitations of our machines while we stillhad a significant percentage of search errors.
In spiteof this, we obtained a substantiM reduction in the er-ror rate with trigrams.
We also developed our own codefor constructing trigram language models from a bodyof training text.Our experiments with phonetically tied mixture mod-els showed that these models appear to have an ad-vantage over ordinary tied mixture models in terms oftheir speaker independent recognition performance as*This work was sponsored by the Defense Advanced ResearchProjects Agency under contract m,mher J-FBI-92-060.well as in the area of speaker and microphone adaptation.By adapting the phonetically specific basis distributions,one can, in essence, obtain phonetically specific nonpara-metric transformations of acoustic space so as to quicklycapture important speaker or microphone characteris-tics and correct for them.
In addition, phonetically tiedmixture models generally require less memory since theytend to need fewer components per mixture.Unlike most other sites, Dragon continues to favor theuse of 20 ms frames over that of 10 ms frames.
Ourrecent experiments indicate that as long as we retain theability to skip nodes in our triphone models, there islittle advantage to the faster frame rate.
We also havegenerally found that there is an advantage to allowingthe number of nodes to be variable across triphones.
Theuse of as many as 5 nodes per triphone has been foundto be useful for some contexts of some phonemes.A number of attempts to improve the signal processingof our system led to negative results.
We have not yetobtained any benefit from the use of second differenceparameters, nor did we obtain any advantage from theapplication of linear discriminant analysis to a series ofconcatenated frames.
On the other hand, we did findthat it was important for us to use gender dependentlinear discriminant based transformations.PLANS FOR THE COMING YEARWe intend to explore the use of decision trees and gen-eral mixture models.
In addition we hope to compare thevalue of full Baum-Welch training to that of the methodwe currently use, which relies on explicit phoneme align-ments.
Multipass algorithms will also be implemented,as a vehicle for a more efficient implementation of tri-grams and other longer context language models, as wellas for speeding up the recognizer.
Since the phonemealignments off of which we build our models do not cor-respond as closely to human judgement as we mighthave expected, we plan to explore the question of howdifference parameters may influence alignments, espe-cially when mediated through linear discriminant analy-sis based transformations.454
