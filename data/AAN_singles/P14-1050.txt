Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 531?541,Baltimore, Maryland, USA, June 23-25 2014. c?2014 Association for Computational LinguisticsNew Word Detection for Sentiment AnalysisMinlie Huang, Borui Ye*, Yichen Wang, Haiqiang Chen**, Junjun Cheng**, Xiaoyan ZhuState Key Lab.
of Intelligent Technology and Systems, National Lab.
for Information Scienceand Technology, Dept.
of Computer Science and Technology, Tsinghua University, Beijing 100084, PR China*Dept.
of Communication Engineering, Beijing University of Posts and Telecommunications**China Information Technology Security Evaluation Centeraihuang@tsinghua.edu.cnAbstractAutomatic extraction of new words isan indispensable precursor to many NLPtasks such as Chinese word segmentation,named entity extraction, and sentimen-t analysis.
This paper aims at extract-ing new sentiment words from large-scaleuser-generated content.
We propose a ful-ly unsupervised, purely data-driven frame-work for this purpose.
We design statisti-cal measures respectively to quantify theutility of a lexical pattern and to measurethe possibility of a word being a newword.The method is almost free of linguistic re-sources (except POS tags), and requiresno elaborated linguistic rules.
We alsodemonstrate how new sentiment word willbenefit sentiment analysis.
Experiment re-sults demonstrate the effectiveness of theproposed method.1 IntroductionNew words on the Internet have been emerg-ing all the time, particularly in user-generated con-tent.
Users like to update and share their infor-mation on social websites with their own languagestyles, among which new political/social/culturalwords are constantly used.However, such new words have made manynatural language processing tasks more challeng-ing.
Automatic extraction of new words is indis-pensable to many tasks such as Chinese word seg-mentation, machine translation, named entity ex-traction, question answering, and sentiment analy-sis.
New word detection is one of the most criticalissues in Chinese word segmentation.
Recent stud-ies (Sproat and Emerson, 2003) (Chen, 2003) haveshown that more than 60% of word segmentationerrors result from new words.
Statistics show thatmore than 1000 new Chinese words appear everyyear (Thesaurus Research Center, 2003).
Thesewords are mostly domain-specific technical termsand time-sensitive political/social /cultural terms.Most of them are not yet correctly recognized bythe segmentation algorithm, and remain as out ofvocabulary (OOV) words.New word detection is also important for sen-timent analysis such as opinionated phrase ex-traction and polarity classification.
A sentimentphrase with complete meaning should have a cor-rect boundary, however, characters in a new wordmay be broken up.
For example, in a sentence" ?
?/ n ?
?/ adv ?/ v ?/ n?artists' perfor-mance is very impressive?"
the two Chinese char-acters?
?/v?/n(cool; powerful)?should alwaysbe extracted together.
In polarity classification,new words can be informative features for clas-sification models.
In the previous example, "??
(cool; powerful)" is a strong feature for clas-sification models while each single character isnot.
Adding new words as feature in classificationmodels will improve the performance of polarityclassification, as demonstrated later in this paper.This paper aims to detect new word for senti-ment analysis.
We are particulary interested in ex-tracting new sentiment word that can express opin-ions or sentiment, which is of high value toward-s sentiment analysis.
New sentiment word, as ex-emplified in Table 1, is a sub-class of multi-wordexpressions which is a sequence of neighboringwords "whose exact and unambiguous meaningor connotation cannot be derived from the mean-ing or connotation of its components" (Choueka,1988).
Such new words cannot be directly iden-tified using grammatical rules, which poses a ma-jor challenge to automatic analysis.
Moreover, ex-isting lexical resources never have adequate andtimely coverage since new words appear constant-ly.
People thus resort to statistical methods such asPointwise Mutual Information (Church and Han-ks, 1990), Symmetrical Conditional Probability531(da Silva and Lopes, 1999), Mutual Expectation(Dias et al, 2000), Enhanced Mutual Information(Zhang et al, 2009), and Multi-word ExpressionDistance (Bu et al, 2010).New word English Translation Polarity??
lovely positive??
tragic/tragedy negative??
very cool; powerful positive??
reverse one's expectation negativeTable 1: Examples of new sentiment word.Our central idea for new sentiment word de-tection is as follows: Starting from very few seedwords (for example, just one seed word), we canextract lexical patterns that have strong statisticalassociation with the seed words; the extracted lex-ical patterns can be further used in finding morenew words, and the most probable new words canbe added into the seed word set for the next iter-ation; and the process can be run iteratively un-til a stop condition is met.
The key issues are tomeasure the utility of a pattern and to quantify thepossibility of a word being a new word.
The maincontributions of this paper are summarized as fol-lows:?
We propose a novel framework for new worddetection from large-scale user-generated da-ta.
This framework is fully unsupervisedand purely data-driven, and requires verylightweight linguistic resources (i.e., onlyPOS tags).?
We design statistical measures to quantify theutility of a pattern and to quantify the possi-bility of a word being a newword, respective-ly.
No elaborated linguistic rules are neededto filter undesirable results.
This feature mayenable our approach to be portable to otherlanguages.?
We investigate the problem of polarity predic-tion of new sentiment word and demonstratethat inclusion of new sentiment word benefitssentiment classification tasks.The rest of the paper is structured as follows:we will introduce related work in the next section.Wewill describe the proposedmethod in Section 3,including definitions, the overview of the algorith-m, and the statistical measures for addressing thetwo key issues.
We then present the experimentsin Section 4.
Finally, the work is summarized inSection 5.2 Related WorkNew word detection has been usually inter-weaved with word segmentation, particularly inChinese NLP.
In these works, new word detectionis considered as an integral part of segmentation,where new words are identified as the most proba-ble segments inferred by the probabilistic models;and the detected new word can be further used toimprove word segmentation.
Typical models in-clude conditional random fields proposed by (Penget al, 2004), and a joint model trained with adap-tive online gradient descent based on feature fre-quency information (Sun et al, 2012).Another line is to treat new word detection asa separate task, usually preceded by part-of-speechtagging.
The first genre of such studies is to lever-age complex linguistic rules or knowledge.
Forexample, Justeson and Katz (1995) extracted tech-nical terminologies from documents using a regu-lar expression.
Argamon et al (1998) segmentedthe POS sequence of a multi-word into small POStiles, counted tile frequency in the new word andnon-new-word on the training set respectively, anddetected new words using these counts.
Chen andMa (2002) employed morphological and statisti-cal rules to extract Chinese new word.
The sec-ond genre of the studies is to treat new word de-tection as a classification problem.
Zhou (2005)proposed a discriminative Markov Model to de-tect new words by chunking one or more separat-ed words.
In (Li et al, 2005), new word detec-tion was viewed as a binary classification problem.However, these supervisedmodels requires not on-ly heavy engineering of linguistic features, but alsoexpensive annotation of training data.User behavior data has recently been exploredfor finding new words.
Zheng et al (2009) ex-plored user typing behaviors in Sogou ChinesePinyin input method to detect new words.
Zhanget al (2010) proposed to use dynamic time warp-ing to detect new words from query logs.
Howev-er, both of the work are limited due to the publicunavailability of expensive commercial resources.Statistical methods for new word detectionhave been extensively studied, and in some senseexhibit advantages over linguistics-based method-s.
In this setting, new word detection is mostly532known as multi-word expression extraction.
Tomeasure multi-word association, the first modelis Pointwise Mutual Information (PMI) (Churchand Hanks, 1990).
Since then, a variety of sta-tistical methods have been proposed to measurebi-gram association, such as Log-likelihood (Dun-ning, 1993) and Symmetrical Conditional Proba-bility (SCP) (da Silva and Lopes, 1999).
Amongall the 84 bi-gram association measures, PMI hasbeen reported to be the best one in Czech data(Pecina, 2005).
In order to measure arbitrary n-grams, most common strategies are to separate n-gram into two parts X and Y so that existing bi-gram methods can be used (da Silva and Lopes,1999; Dias et al, 2000; Schone and Jurafsky,2001).
Zhang et al (2009) proposed EnhancedMutual Information (EMI) which measures the co-hesion of n-gram by the frequency of itself and thefrequency of each single word.
Based on the in-formation distance theory, Bu et al (2010) pro-posed multi-word expression distance (MED) andthe normalized version, and reported superior per-formance to EMI, SCP, and other measures.3 Methodology3.1 DefinitionsDefinition 3.1 (Adverbial word).
Words that areused mainly to modify a verb or an adjective, suchas "?
(too)", "??
(very)", "??
(very)", and "??
(specially)".Definition 3.2 (Auxiliary word).
Words that areauxiliaries, model particles, or punctuation marks.In Chinese, such words are like "?,?,?,?,?
",and punctuation marks include "??????"
andso on.Definition 3.3 (Lexical Pattern).
A lexical pat-tern is a triplet < AD, ?, AU >, where AD is anadverbial word, the wildcard ?
means an arbitrarynumber of words 1, and AU denotes an auxiliaryword.Table 2 gives some examples of lexical pat-terns.
In order to obtain lexical patterns, we candefine regular expressions with POS tags 2 and ap-ply the regular expressions on POS tagged texts.Since the tags of adverbial and auxiliary words are1We set the number to 3 words in this work consideringcomputation costs.2Such expressions are very simple and easy to write be-cause we only need to consider POS tags of adverbial andauxiliary word.relatively static and can be easily identified, sucha method can safely obtain lexical patterns.Pattern Frequency<"?",*,"?
"> 562,057<"?",*,"?
"> 387,649<"?",*,"?
"> 380,470<"?",*,"?
"> 369,702Table 2: Examples of lexical pattern.
The frequen-cy is counted on 237,108,977 Weibo posts.3.2 The Algorithm OverviewThe algorithm works as follows: startingfrom very few seed words (for example, a wordin Table 1), the algorithm can find lexical pattern-s that have strong statistical association with theseed words in which the likelihood ratio test (L-RT) is used to quantify the degree of association.Subsequently, the extracted lexical patterns can befurther used in finding more new words.
We de-sign several measures to quantify the possibility ofa candidate word being a new word, and the top-ranked words will be added into the seed word setfor the next iteration.
The process can be run iter-atively until a stop condition is met.
Note that wedo not augment the pattern set (P) at each iteration,instead, we keep a fixed small number of patternsduring iteration because this strategy produces op-timal results.From linguistic perspectives, new sentimentwords are commonly modified by adverbial wordsand thus can be extracted by lexical patterns.
Thisis the reason why the algorithm will work.
Our al-gorithm is in spirit to double propagation (Qiu etal., 2011), however, the differences are apparen-t in that: firstly, we use very lightweight linguis-tic information (except POS tags); secondly, ourmajor contributions are to propose statistical mea-sures to address the following key issues: first, tomeasure the utility of lexical patterns; second, tomeasure the possibility of a candidate word beinga new word.3.3 Measuring the Utility of a PatternThe first key issue is to quantify the utility ofa pattern at each iteration.
This can be measuredby the association of a pattern to the current wordset used in the algorithm.
The likelihood ratio test-s (Dunning, 1993) is used for this purpose.
Thisassociation model has also been used to model as-sociation between opinion target words by (Hai et533Algorithm 1: New word detection algorithmInput:D: a large set of POS tagged postsWs: a set of seed wordskp: the number of patterns chosen at eachiterationkc: the number of patterns in the candidatepattern setkw: the number of words added at eachiterationK: the number of words returnedOutput: A list of ranked new wordsW1 Obtain all lexical patterns using regularexpressions on D;2 Count the frequency of each lexical patternand extract words matched by each pattern ;3 Obtain top kcfrequent patterns as candidatepattern set Pcand top 5,000 frequent words ascandidate word setWc;4 P = ?
;W=Ws; t = 0 ;5 for |W| < K do6 UseW to score each pattern in PcwithU(p) ;7 P = {top kppatterns} ;8 Use P to extract new words and if thewords are inWc, score them with F (w) ;9 W = W?
{top kwwords} ;10 Wc=Wc-W ;11 Sort words inW with F (w) ;12 Output the ranked list of words inW ;al., 2012).The LRT is well known for not relying crit-ically on the assumption of normality, instead, ituses the asymptotic assumption of the generalizedlikelihood ratio.
In practice, the use of likelihoodratios tends to result in significant improvementsin text-analysis performance.In our problem, LRT computes a contingencytable of a pattern p and a word w, derived fromthe corpus statistics, as given in Table 3, wherek1(w, p) is the number of documents thatwmatch-es pattern p, k2(w, p?)
is the number of documentsthat w occurs while p does not, k3(w?, p) is thenumber of documents that p occurs while w doesnot, and k4(w?, p?)
is the number of documents con-taining neither p nor w.Statistics p p?w k1(w, p) k2(w, p?)w?
k3(w?, p) k4(w?, p?
)Table 3: Contingency table for likelihood ratio test(LRT).Based on the statistics shown in Table 3, thelikelihood ratio tests (LRT) model captures the sta-tistical association between a pattern p and a wordw by employing the following formula:LRT (p, w) = logL(?1, k1, n1) ?
L(?2, k2, n2)L(?, k1, n1) ?
L(?, k2, n2)(1)where:L(?, k, n) = ?k?
(1 ?
?
)n?k; n1= k1+ k3;n2= k2+ k4; ?1= k1/n1; ?2= k2/n2; ?
=(k1+ k2)/(n1+ n2).Thus, the utility of a pattern can be measuredas follows:U(p) =?wi?WLRT (p, wi) (2)where W is the current word set used in the algo-rithm (see Algorithm 1).3.4 Measuring the Possibility of Being NewWordsAnother key issue in the proposed algorithmis to quantify the possibility of a candidate wordbeing a new word.
We consider several factors forthis purpose.3.4.1 Likelihood Ratio TestVery similar to the pattern utility measure, L-RT can also be used to measure the association ofa candidate word to a given pattern set, as follows:LRT (w) =?pi?PLRT (w, pi) (3)where P is the current pattern set used in the algo-rithm (see Algorithm 1), and piis a lexical pattern.This measure only quantifies the associationof a candidate word to the given pattern set.
Ittells nothing about the possibility of a word be-ing a new word, however, a new sentiment word,should have close association with the lexical pat-terns.
This has linguistic interpretations becausenew sentiment words are commonly modified byadverbial words and thus should have close associ-ation with lexical patterns.
This measure is provedto be an influential factor by our experiments inSection 4.3.5343.4.2 Left Pattern EntropyIf a candidate word is a new word, it will bemore commonly used with diversified lexical pat-terns since the non-compositionality of new wordmeans that the word can be used in many differ-ent linguistic scenarios.
This can be measured byinformation entropy, as follows:LPE(w) = ?
?li?L(Pc,w)c(li, w)N(w)?
logc(li, w)N(w)(4)where L(Pc, w) is the set of left word of all pat-terns by which word w can be matched in Pc,c(li, w) is the count that word w can be matchedby patterns whose left word is li, and N(w) is thecount that word w can be matched by the patternsin Pc.
Note that we use Pc, instead of P , becausethe latter set is very small while computing entropyneeds a large number of patterns.
Tuning the sizeof Pcwill be further discussed in Section 4.4.3.4.3 New Word ProbabilitySome words occur very frequently and can bewidely matched by lexical patterns, but they arenot new words.
For example, "??
(love to eat)"and "??
(love to talk)" can be matched by manylexical patterns, however, they are not new wordsdue to the lack of non-compositionality.
In suchwords, each single character has high probabilityto be a word.
Thus, we design the following mea-sure to favor this observation.NWP (w) =n?i=1p(wi)1?
p(wi)(5)where w = w1w2.
.
.
wn, each wiis a single char-acter, and p(wi) is the probability of the characterwibeing a word, as computed as follows:p(wi) =all(wi)?
s(wi)all(wi)where all(wi) is the total frequency of wi, ands(wi) is the frequency of wibeing a single char-acter word.
Obviously, in order to obtain the valueof s(wi), some particular Chinese word segmen-tation tool is required.
In this work, we resort toICTCLAS (Zhang et al, 2003), a widely used toolin the literature.3.4.4 Non-compositionality MeasuresNew words are usually multi-word expres-sions, where a variety of statistical measures havebeen proposed to detect multi-word expressions.Thus, such measures can be naturally incorporatedinto our algorithm.The first measure is enhanced mutual infor-mation (EMI) (Zhang et al, 2009):EMI(w) = log2F/N?ni=1Fi?FN(6)where F is the number of posts in which a multi-word expression w = w1w2.
.
.
wnoccurs, Fiisthe number of posts where wioccurs, andN is thetotal number of posts.
The key idea of EMI is tomeasure word pair?s dependency as the ratio of itsprobability of being a multi-word to its probabilityof not being amulti-word.
The larger the value, themore possible the expression will be a multi-wordexpression.The second measure we take into account isnormalized multi-word expression distance (Bu etal., 2010), which has been proposed to measure thenon-compositionality of multi-word expressions.NMED(w) =log|?
(w)| ?
log|?
(w)|logN ?
log|?
(w)|(7)where ?
(w) is the set of documents in which allsingle words in w = w1w2.
.
.
wnco-occur, ?
(w)is the set of documents in which word w occursas a whole, and N is the total number of docu-ments.
Different from EMI, this measure is a strictdistance metric, meaning that a smaller value in-dicates a larger possibility of being a multi-wordexpression.
As can be seen from the formula, thekey idea of this metric is to compute the ratio of theco-occurrence of all words in a multi-word expres-sions to the occurrence of the whole expression.3.4.5 Configurations to Combine VariousFactorsTaking into account the aforementioned fac-tors, we have different settings to score a newword, as follows:FLRT(w) = LRT (w) (8)FLPE(w) = LRT (w) ?
LPE(w) (9)FNWP(w) = LRT (w) ?
LPE(w) ?NWP (w) (10)FEMI(w) = LRT (w) ?
LPE(w) ?
EMI(w) (11)FNMED(w) =LRT (w) ?
LPE(w)NMED(w)(12)5354 ExperimentIn this section, we will conduct the followingexperiments: first, we will compare our methodto several baselines, and perform parameter tun-ing with extensive experiments; second, we willclassify polarity of new sentiment words using t-wo methods; third, we will demonstrate how newsentiment words will benefit sentiment classifica-tion.4.1 Data PreparationWe crawled 237,108,977 Weibo posts fromhttp://www.weibo.com, the largest social websitein China.
These posts range from January of 2011to December of 2012.
The posts were then part-of-speech tagged using a Chinese word segmentationtool named ICTCLAS (Zhang et al, 2003).Then, we asked two annotators to label the top5,000 frequent words that were extracted by lexi-cal patterns as described in Algorithm 1.
The an-notators were requested to judge whether a candi-date word is a new word, and also to judge the po-larity of a new word (positive, negative, and neu-tral).
If there is a disagreement on either of thetwo tasks, discussions are required to make the fi-nal decision.
The annotation led to 323 new word-s, among which there are 116 positive words, 112negative words, and 95 neutral words3.4.2 Evaluation MetricAs our algorithm outputs a ranked list ofwords, we adapt average precision to evaluatethe performance of new sentiment word detection.The metric is computed as follows:AP (K) =?Kk=1P (k) ?
rel(k)?Kk=1rel(k)where P (k) is the precision at cut-off k, rel(k) is1 if the word at position k is a new word and 0 oth-erwise, andK is the number of words in the rankedlist.
A perfect list (all topK items are correct) hasan AP value of 1.0.4.3 Evaluation of Different Measures andComparison to BaselinesFirst, we assess the influence of likelihood ra-tio test, which measures the association of a wordto the pattern set.
As can be seen from Table 4,the associationmodel (LRT) remarkably boosts the3All the resources are available upon request.performance of new word detection, indicating L-RT is a key factor for new sentiment word extrac-tion.
From linguistic perspectives, new sentimentwords are commonly modified by adverbial wordsand thus should have close association with lexicalpatterns.Second, we compare different settings of ourmethod to two baselines.
The first one is en-hanced mutual information (EMI) where we setF (w) = EMI(w) (Zhang et al, 2009) and thesecond baseline is normalized multi-word expres-sion distance (NMED) (Bu et al, 2010) where weset F (w) = NMED(w).
The results are shownin Figure 1.
As can be seen, all the proposedmeasures outperform the two baselines (EMI andNMED) remarkably and consistently.
The set-ting of FNMEDproduces the best performance.AddingNMED orEMI leads to remarkable im-provements because of their capability of measur-ing non-compositionality of new words.
Only us-ingLRT can obtain a fairly good results whenK issmall, however, the performance drops sharply be-cause it's unable to measure non-compositionality.Comparison between LRT + LPE (or LRT +LPE + NWP ) and LRT shows that inclusionof left pattern entropy also boosts the performanceapparently.
However, the new word probabili-ty (NWP ) has only marginal contribution to im-provement.In the above experiments, we set kp= 5 (thenumber of patterns chosen at each iteration) andkw= 10 (the number of words added at each iter-ation), which is the optimal setting and will be dis-cussed in the next subsection.
And only one seedword "??
(reverse one's expectation)" is used.Figure 1: Comparative results of different measuresettings.
X-axis is the number of words returned(K), and Y-axis is average precision (AP (K)).536top K words ?
100 200 300 400 500LPE 0.366 0.324 0.286 0.270 0.259LRT+LPE 0.743 0.652 0.613 0.582 0.548LPE+NWP 0.467 0.400 0.350 0.330 0.320LRT+LPE+NWP 0.755 0.680 0.612 0.571 0.543LPE+EMI 0.608 0.551 0.519 0.486 0.467LRT+LPE+EMI 0.859 0.759 0.717 0.662 0.632LPE+NMED 0.749 0.690 0.641 0.612 0.576LRT+LPE+NMED 0.907 0.808 0.741 0.723 0.699Table 4: Results with vs. without likelihood ratio test (LRT).4.4 Parameter TuningFirstly, we will show how to obtain the op-timal settings of kpand kw.
The measure settingwe take here is FNMED(w), as shown in Formula(12).
Again, we choose only one seed word "??
(reverse one's expectation)", and the number ofwords returned is set to K = 300.
Results in Ta-ble 5 show that the performance drops consistent-ly across different kwsettings when the number ofpatterns increases.
Note that at the early stage ofAlgorithm 1, larger kp(perhaps with noisy pattern-s) may lead to lower quality of new words; whilelarger kw(perhaps with noisy seed words) maylead to lower quality of lexical patterns.
Therefore,we choose the optimal setting to small numbers, askp= 5, kw= 10.Secondly, we justify whether the proposed al-gorithm is sensitive to the number of seed words.We set kp= 5 and kw= 10, and take FNMEDas the weighting measure of new word.
We exper-imented with only one seed word, two, three, andfour seed words, respectively.
The results in Ta-ble 6 show very stable performance when differentnumbers of seed words are chosen.
It's interestingthat the performance is totally the same with dif-ferent numbers of seed words.
By looking into thepattern set and the selected words at each iteration,we found that the pattern set (P) converges soonto the same set after a few iterations; and at the be-ginning several iterations, the selected words arealmost the same although the order of adding thewords is different.
Since the algorithm will finallysort the words at step (11) and P is the same, theranking of the words becomes all the same.Lastly, we need to decide the optimal numberof patterns in Pc(that is, kcin Algorithm 1) be-cause the set has been used in computing left pat-tern entropy, see Formula (4).
Too small size ofPcmay lead to insufficient estimation of left pat-tern entropy.
Results in Table 7 shows that larg-er Pcdecrease the performance, particularly whenthe number of words returned (K) becomes larger.Therefore, we set |Pc| = 100.4.5 Polarity Prediction of New SentimentWordsIn this section, we attempt to classifying thepolarity of the annotated 323 new words.
Twomethods are adapted with different settings for thispurpose.
The first one is majority vote (MV), andthe second one is pointwise mutual information,similar to (Turney and Littman, 2003).
The ma-jority vote method is formulated as below:MV (w) =?wp?PW#(w,wp)|PW |?
?wn?NW#(w,wn)|NW |where PW and NW are a positive and negativeset of emoticons (or seed words) respectively, and#(w,wp) is the co-occurrence count of the inputwordw and the itemwp.
The polarity is judged ac-cording to this rule: ifMV (w) > th1, the word wis positive; ifMV (w) < ?th1the word negative;otherwise neutral.
The threshold th1is manuallytuned.And PMI is computed as follows:PMI(w) =?wp?PWPMI(w,wp)|PW |?
?wn?NWPMI(w,wn)|NW |where PMI(x, y) = log2(Pr(x,y)Pr(x)?Pr(y)), andPr(?)
denotes probability.
The polarity is judgedaccording to the rule: if PMI(w) > th2, w ispositive; if PMI(w) < ?th2negative; otherwiseneutral.
The threshold th2is manually tuned.As for the resources PW and NW , wehave three settings.
The first setting (denoted by537HHHHHHkwkp 2 3 4 5 10 20 505 0.753 0.738 0.746 0.741 0.741 0.734 0.71510 0.753 0.738 0.746 0.741 0.741 0.728 0.71215 0.753 0.738 0.746 0.741 0.754 0.734 0.71820 0.763 0.738 0.744 0.749 0.749 0.735 0.717Table 5: Parameter tuning results for kpand kw.
The measure setting is FNMED(w), the seed word setis {"??
(reverse one's expectation)"}, and the number of words returned isK = 300.# seeds ?
1 2 3 4K=100 0.907 0.907 0.907 0.907K=200 0.808 0.808 0.808 0.808K=300 0.741 0.741 0.741 0.741K=400 0.709 0.709 0.709 0.709K=500 0.685 0.685 0.685 0.685Table 6: Performance with different numbers ofseed words.
The measure setting is FNMED(w),and kp= 5, kw= 10.
The seed words are chosenfrom Table 1.Large_Emo) is a set of most frequent 36 emoticonsin which there are 21 positive and 15 negative e-moticons respectively.
The second one (denotedby Small_Emo) is a set of 10 emoticons, whichare chosen from the 36 emoticons, as shown inTable 8.
The third one (denoted by Opin_Words)is two sets of seed opinion words, where PW={??(happy),??(generous),??
(beautiful), ??(kind),??
(smart)} and NW ={??(sad),??(mean),??(ugly),??(wicked),?
(stupid)}.The performance of polarity prediction isshown in Table 9.
In two-class polarity classifi-cation, we remove neutral words and only makeprediction with positive/negative classes.
The firstobservation is that the performance of using emoti-cons is much better than that of using seed opin-ion words.
We conjecture that this may be be-cause new sentiment words are more frequentlyco-occurring with emoticons than with these opin-ion words.
The second observation is that three-class polarity classification is much more diffi-cult than two-class polarity classification becausemany extracted new words are nouns such as "??(gay)","??
(girl)", and "??(friend)".
Suchnouns are more difficult to classify sentiment ori-entation.4.6 Application of New Sentiment Words toSentiment ClassificationIn this section, we justifywhether inclusion ofnew sentiment word would benefit sentiment clas-sification.
For this purpose, we randomly sampledand annotated 4,500 Weibo posts that contain atleast one opinion word in the union of the Hownet4 opinion lexicons and our annotated new word-s. We apply two models for polarity classification.The first model is a lexicon-based model (denot-ed by Lexicon) that counts the number of positiveand negative opinion words in a post respective-ly, and classifies a post to be positive if there aremore positive words than negative ones, and to benegative otherwise.
The second model is a SVMmodel in which opinion words are used as feature,and 5-fold cross validation is conducted.We experiment with different settings ofHownet lexicon resources:?
Hownet opinion words (denoted by Hownet):After removing some obviously inappropri-ate words, the left lexicons have 627 posi-tive opinion words and 1,038 negative opin-ion words, respectively.?
Compact Hownet opinion words (denoted bycptHownet): we count the frequency of theabove opinion words on the training data andremove words whose document frequency isless than 2.
This results in 138 positive wordsand 125 negative words.Then, we add into the above resources the la-beled new polar words(denoted byNW , including116 positive and 112 negative words) and the top100 words produced by the algorithm (denoted byT100), respectively.
Note that the lexicon-basedmodel requires the sentiment orientation of eachdictionary entry 5, we thus manually label the po-4http://www.keenage.com/html/c_index.html.5This is not necessary for the SVM model.
All words inthe top 100 words can be used as feature.538|Pc| ?
50 100 200 300 400 500K=100 0.907 0.905 0.916 0.916 0.888 0.887K=200 0.808 0.810 0.778 0.776 0.766 0.764K=300 0.741 0.731 0.722 0.726 0.712 0.713K=400 0.709 0.708 0.677 0.675 0.656 0.655K=500 0.685 0.683 0.653 0.646 0.626 0.627Table 7: Tuning the number of patterns in Pc.
The measure setting is FNMED(w), kp= 5, kw= 10,and the seed word set is {"??
(reverse one's expectation)"}.Emoticon Polarity Emoticon Polaritypositive negativepositive negativepositive negativepositive negativepositive negativeTable 8: The ten emoticons used for polarity pre-diction.Methods?
Majority vote PMITwo-class polarity classificationLarge_Emo 0.861 0.865Small_Emo 0.846 0.851Opin_Words 0.697 0.654Three-class polarity classificationLarge_Emo 0.598 0.632Small_Emo 0.551 0.635Opin_Words 0.449 0.486Table 9: The accuracy of two/three-class polarityclassification.larity of all top 100 words (we did NOT removeincorrect new word).
This results in 52 positiveand 34 negative words.Results in Table 10 show that inclusion ofnew words in both models improves the perfor-mance remarkably.
In the setting of the originallexicon (Hownet), both models obtain 2-3% gainsfrom the inclusion of newwords.
Similar improve-ment is observed in the setting of the compact lex-icon.
Note, that T100 is automatically obtainedfrom Algorithm 1 so that it may contain words thatare not new sentiment words, but the resource alsoimproves performance remarkably.5 ConclusionIn order to extract new sentiment words fromlarge-scale user-generated content, this paper pro-poses a fully unsupervised, purely data-driven, and# Pos/Neg Lexicon SVMHownet 627/1,038 0.737 0.756Hownet+NW 743/1,150 0.770 0.779Hownet+T100 679/1,172 0.761 0.774cptHownet 138/125 0.738 0.758cptHownet+NW 254/237 0.774 0.782cptHownet+T100 190/159 0.764 0.775Table 10: The accuracy of polarity classfication ofWeibo post with/without new sentiment words.
N-W includes 116/112 positive/negative words, andT100 contains 52/34 positive/negative words.almost knowledge-free (except POS tags) frame-work.
We design statistical measures to quantifythe utility of a lexical pattern and to measure thepossibility of a word being a new word, respec-tively.
The method is almost free of linguistic re-sources (except POS tags), and does not rely onelaborated linguistic rules.
We conduct extensiveexperiments to reveal the influence of different sta-tistical measures in new word finding.
Compara-tive experiments show that our proposed methodoutperforms baselines remarkably.
Experimentsalso demonstrate that inclusion of new sentimentwords benefits sentiment classification definitely.From linguistic perspectives, our frameworkis capable to extract adjective new words becausethe lexical patterns usually modify adjective word-s. As future work, we are considering how to ex-tract other types of new sentiment words, such asnounal new words that can express sentiment.AcknowledgmentsThis work was partly supported by the fol-lowing grants from: the National Basic Re-search Program (973 Program) under grant No.2012CB316301 and 2013CB329403, the NationalScience Foundation of China project under grantNo.
61332007 and No.
60803075, and the BeijingHigher Education Young Elite Teacher Project.539ReferencesShlomo Argamon, Ido Dagan, and Yuval Krymolows-ki.
1998.
A memory-based approach tolearning shallow natural language patterns.
InProceedings of the 17th International Conferenceon Computational Linguistics - Volume 1, COL-ING '98, pages 67--73, Stroudsburg, PA, USA.Association for Computational Linguistics.Fan Bu, Xiaoyan Zhu, and Ming Li.
2010.
Measuringthe non-compositionality of multiword expres-sions.
In Proceedings of the 23rd InternationalConference on Computational Linguistics, COL-ING '10, pages 116--124, Stroudsburg, PA, USA.Association for Computational Linguistics.Keh-Jiann Chen and Wei-Yun Ma.
2002.
Un-known word extraction for chinese documents.
InProceedings of the 19th International Conferenceon Computational Linguistics - Volume 1, COL-ING '02, pages 1--7, Stroudsburg, PA, USA.
As-sociation for Computational Linguistics.Aitao Chen.
2003.
Chinese word segmentation us-ingminimal linguistic knowledge.
In Proceedingsof the Second SIGHAN Workshop on ChineseLanguage Processing - Volume 17, SIGHAN '03,pages 148--151, Stroudsburg, PA, USA.
Associa-tion for Computational Linguistics.Yaacov Choueka.
1988.
Looking for nee-dles in a haystack or locating interesting col-location expressions in large textual databas-es.
In Proceeding of the RIAO'88 Conferenceon User-Oriented Content-Based Text and ImageHandling, pages 21--24.Kenneth Ward Church and Patrick Hanks.
1990.
Wordassociation norms, mutual information, and lex-icography.
Comput.
Linguist., 16(1): 22--29,March.J Ferreira da Silva and G Pereira Lopes.
1999.
A localmaxima method and a fair dispersion normaliza-tion for extracting multi-word units from corpora.In Sixth Meeting on Mathematics of Language,pages 369--381.Ga?l Dias, Sylvie Guillor?, and Jos?
Gabriel PereiraLopes.
2000.
Mining textual associations in textcorpora.
6th ACM SIGKDD Work.
Text Mining.TedDunning.
1993.
Accurate methods for the statisticsof surprise and coincidence.
Comput.
Linguist.,19(1):61--74, March.Zhen Hai, Kuiyu Chang, and Gao Cong.
2012.One seed to find them all: Mining opinion fea-tures via association.
In Proceedings of the 21stACM International Conference on Informationand Knowledge Management, CIKM '12, pages255--264, New York, NY, USA.
ACM.John S Justeson and SlavaMKatz.
1995.
Technical ter-minology: some linguistic properties and an algo-rithm for identification in text.
Natural languageengineering, 1(1):9--27.Hongqiao Li, Chang-Ning Huang, Jianfeng Gao, andXiaozhong Fan.
2005.
The use of svm forchinese new word identification.
In NaturalLanguage Processing--IJCNLP 2004, pages 723--732.
Springer.Pavel Pecina.
2005.
An extensive empirical study ofcollocation extraction methods.
In Proceedingsof the ACL Student ResearchWorkshop, ACLstu-dent '05, pages 13--18, Stroudsburg, PA, USA.Association for Computational Linguistics.Fuchun Peng, Fangfang Feng, and Andrew McCal-lum.
2004.
Chinese segmentation and newword detection using conditional random field-s.
In Proceedings of the 20th InternationalConference on Computational Linguistics, COL-ING '04, Stroudsburg, PA, USA.
Association forComputational Linguistics.Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.2011.
Opinion word expansion and target extrac-tion through double propagation.
Computationallinguistics, 37(1):9--27.Patrick Schone and Daniel Jurafsky.
2001.
Isknowledge-free induction of multiword unit dic-tionary headwords a solved problem.
In Proc.of the 6th Conference on Empirical Methods inNatural Language Processing (EMNLP 2001),pages 100--108.Richard Sproat and Thomas Emerson.
2003.
The firstinternational chinese word segmentation bakeoff.In Proceedings of the Second SIGHANWorkshopon Chinese Language Processing - Volume 17,SIGHAN '03, pages 133--143, Stroudsburg, PA,USA.
Association for Computational Linguistics.Xu Sun, Houfeng Wang, and Wenjie Li.
2012.Fast online training with frequency-adaptivelearning rates for chinese word segmentationand new word detection.
In Proceedings ofthe 50th Annual Meeting of the Associationfor Computational Linguistics: Long Papers -Volume 1, ACL '12, pages 253--262, Strouds-burg, PA, USA.
Association for ComputationalLinguistics.Beijing Thesaurus Research Center.
2003.
Xinhua XinCiyu Cidian.
Commercial Press, Beijing.Peter D. Turney and Michael L. Littman.
2003.
Mea-suring praise and criticism: Inference of seman-tic orientation from association.
ACM Trans.
Inf.Syst., 21(4):315--346, October.Hua-Ping Zhang, Hong-Kui Yu, De-Yi Xiong, and QunLiu.
2003.
Hhmm-based chinese lexical analyzerictclas.
In Proceedings of the Second SIGHANWorkshop on Chinese Language Processing -540Volume 17, SIGHAN '03, pages 184--187,Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.Wen Zhang, Taketoshi Yoshida, Xijin Tang, and Tu-Bao Ho.
2009.
Improving effectiveness ofmutual information for substantival multiwordexpression extraction.
Expert Systems withApplications, 36(8):10919--10930.Yan Zhang, Maosong Sun, and Yang Zhang.
2010.Chinese new word detection from query logs.
InAdvanced Data Mining and Applications, pages233--243.
Springer.Yabin Zheng, Zhiyuan Liu, Maosong Sun, Liyun Ru,and Yang Zhang.
2009.
Incorporating user be-haviors in new word detection.
In Proceedings ofthe 21st International Jont Conference onArtificalIntelligence, IJCAI'09, pages 2101--2106, SanFrancisco, CA, USA.Morgan Kaufmann Publish-ers Inc.GuoDong Zhou.
2005.
A chunking strategy towardsunknownword detection in chinese word segmen-tation.
In Natural Language Processing--IJCNLP2005, pages 530--541.
Springer.541
