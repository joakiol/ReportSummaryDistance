Proceedings of the 2009 Workshop on Language Generation and Summarisation, ACL-IJCNLP 2009, pages 107?108,Suntec, Singapore, 6 August 2009. c?2009 ACL and AFNLPWLV: A confidence-based machine learning method for theGREC-NEG?09 taskConstantin Ora?sanRIILPUniversity of Wolverhampton, UKC.Orasan@wlv.ac.ukIustin DornescuRIILPUniversity of Wolverhampton, UKI.Dornescu@wlv.ac.ukAbstractThis article presents the machine learningapproach used by the University ofWolverhampton in the GREC-NEG?09task.
A classifier based on J48 decisiontree and a meta-classifier were used toproduce two runs.
Evaluation on thedevelopment set shows that the meta-classifier achieves a better performance.1 IntroductionThe solution adopted by the University ofWolverhampton to solve the GREC-NEG taskrelies on machine learning.
To this end, weassumed that it is possible to learn which is thecorrect form for a referential expression given thecontext in which it appears.
The remainder of thepaper is structured as follows: Section 2 presentsthe method used in this paper.
Section 3 presentsthe evaluation results on the development set.
Thepaper finishes with conclusions.2 MethodThe method used to solve the GREC-NEG taskwas inspired by the machine learning approachesemployed for coreference resolution.
In thesemethods, pairs of entities are classified ascoreferential or not on the basis of a set of features(Mitkov, 2002).
In the same manner, each REFelement from the text to be processed is pairedwith all the REFEX elements in its chain andmachine learning is used to determine the lexicalform of which candidate REFEX element can beused in the given context.
To achieve this, a set offeatures was derived after a corpus investigation.As can be seen, some of these features aresimilar to those used by resolution algorithms(e.g.
distance between entities), whilst others arespecific for the task (e.g.
empty markers).
Thefeatures used for a (REF, REFEX) pair are:?
Whether the REF element is the first mentionin the chain.
We noticed that in most casesit corresponds to the longest REFEX elementin the plain case.?
Whether the REFEX element is the longeststring.?
Whether the REF element is the first word inthe sentence as this word is very likely to bethe subject (i.e.
nominative or plain case).?
Whether the words before the REF elementcan signal a possible empty element.Example of such phrases are ?, but?
and ?andthen?.
These phrases were extracted afteranalysing the training corpus.?
The distance in sentences to the previousREF element in the chain.
This feature wasused because a pronoun is more likely tobe used when several mentions are in thesame sentence, whilst full noun phrases arenormally used if the mentions are far away orin different paragraphs.?
The REG08-TYPE of the REFEX tagsthat were assigned by the program to theprevious 2 REF elements in the chain.
Thisinformation can prove useful in conjunctionwith the previous feature.?
The part-of-speech tags of the four wordsbefore and three words after the REF elementas a way to indicate the context in which theelement appears.?
A compatibility feature which indicates pairsof SYNFUNC and CASE that are highlycorrelated.
This correlation was determinedby extracting the most frequent SYNFUNCand CASE pairs from the training corpus.107?
The size of the chain in elements as longerchains are more likely to contain pronouns.?
The values of SEMCAT, SYNCAT andSYNFUNC attributes of REF elementand REG08-TYPE and CASE of REFEXelement.?
The number of words in the REFEX value.?
Whether REF is in the first chain of thedocument.The last two features were introduced in orderto discriminate between candidate REFEX valuesthat have the same type and case.
For example,the number of words proved very useful whenselecting genitive case names and chi-squaredstatistic ranks it as one of the best features togetherwith the compatibility feature, information aboutprevious elements in the chain and the longestREFEX candidate.Before the features are calculated, the text issplit into sentences and enriched with part-of-speech information using the OpenNLP library.1 The instances are fed into a binary classifierthat indicates whether the (REF, REFEX) pair isgood (i.e.
the REFEX element is a good filler forthe REF element).
Since each pair is classifiedindependently, it is possible to have zero, one ormore good REFEX candidates for a given REF.Therefore, the system uses the confidence returnedby the classifier to rank the candidates and selectsthe one that has the highest probability of beinggood, regardless of the class assigned by theclassifier.
In this way the system selects exactlyone REFEX for each REF.3 EvaluationThe method proposed in this paper was evaluatedusing two classifiers, both trained on the sameset of features.
The first classifier is the standardJ48 decision tree algorithm implemented in Weka(Witten and Frank, 2005).
The run that used thisclassifier is referred to in the rest of the paper asstandard run.
Given the large number of negativeexamples present in our training data, a meta-classifier that is cost-sensitive was used for thesecond run.
In our case, the meta-classifier relieson J48 and reweights training instances accordingto the total cost assigned to each class.
After1http://opennlp.sourceforge.net/experimenting with different cost matrices, wedecided to assign a cost of 3 to false negativesand 1 to false positives, in this way biasing theclassifier towards a higher recall for YES answers.The results obtained using this meta-classifier arereferred to as biased run.
Our results on thedevelopment set are presented in Table 1.Measure Standard Biasedclassification accuracy 94.40% 92.09%total pairs 907 907reg08 type matches 621 728reg08 type accuracy 68.46% 80.26%reg08 type precision 68.46% 80.26%reg08 type recall 66.20% 77.61%string matches 568 667string accuracy 62.62% 73.53%mean edit distance 0.845 0.613mean normalised edit distance 0.351 0.239Table 1: The evaluation results on thedevelopment setThe first row in the table presents the accuracyof the classifier on the training data using 10-foldcross-validation.
The very high accuracy is dueto the large number of negative instances in thetraining data: assigning all the instances to theclass NO achieves a baseline accuracy of 88.96%.The rest of the table presents the accuracy of thesystem on the development set using the scriptprovided by the GREC-NEG organisers.
As canbe seen, the best results are obtained by the biasedclassifier despite performing worse at the levelof classification accuracy.
This can be explainedby the fact that we do not use the output of theclassifier directly, instead using the classificationconfidence.4 ConclusionsThis paper has presented our participation in theGREC-NEG task with a machine learning system.Currently the system tries to predict whether a(REF, REFEX) pair is valid, but in the futurewe plan to approach the task by using machinelearning methods to determine the values ofREG08-TYPE and CASE attributes.ReferencesRuslan Mitkov.
2002.
Anaphora resolution.Longman.Ian H. Witten and Eibe Frank.
2005.
Data Mining:Practical Machine Learning Tools and Techniques.Morgan Kaufmann Publishers.108
