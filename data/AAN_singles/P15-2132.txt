Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 806?811,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsCompact Lexicon Selection with Spectral MethodsYoung-Bum Kim?Karl Stratos?Xiaohu Liu?Ruhi Sarikaya?
?Microsoft Corporation, Redmond, WA?Columbia University, New York, NY{ybkim, derekliu, ruhi.sarikaya}@microsoft.comstratos@cs.columbia.eduAbstractIn this paper, we introduce the task of se-lecting compact lexicon from large, noisygazetteers.
This scenario arises often inpractice, in particular spoken language un-derstanding (SLU).
We propose a simpleand effective solution based on matrix de-composition techniques: canonical corre-lation analysis (CCA) and rank-revealingQR (RRQR) factorization.
CCA is firstused to derive low-dimensional gazetteerembeddings from domain-specific searchlogs.
Then RRQR is used to find a sub-set of these embeddings whose span ap-proximates the entire lexicon space.
Ex-periments on slot tagging show that ourmethod yields a small set of lexicon en-tities with average relative error reductionof > 50% over randomly selected lexicon.1 IntroductionDiscriminative models trained with large quanti-ties of arbitrary features are a dominant paradigmin spoken language understanding (SLU) (Li etal., 2009; Hillard et al., 2011; Celikyilmaz et al.,2013; Liu and Sarikaya, 2014; Sarikaya et al.,2014; Anastasakos et al., 2014; Xu and Sarikaya,2014; Celikyilmaz et al., 2015; Kim et al., 2015a;Kim et al., 2015c; Kim et al., 2015b).
An impor-tant category of these features comes from entitydictionaries or gazetteers?lists of phrases whoselabels are given.
For instance, they can be listsof movies, music titles, actors, restaurants, andcities.
These features enable SLU models to ro-bustly handle unseen entities at test time.However, these lists are often massive and verynoisy.
This is because they are typically obtainedautomatically by mining the web for recent en-tries (such as newly launched movie names).
Ide-ally, we would like an SLU model to have accessto this vast source of information at deployment.But this is difficult in practice because an SLUmodel needs to be light-weight to support fast userinteraction.
It becomes more challenging whenwe consider multiple domains, languages, and lo-cales.In this paper, we introduce the task of selectinga small, representative subset of noisy gazetteersthat will nevertheless improve model performancenearly as much as the original lexicon.
This willallow an SLU model to take full advantage ofgazetteer resources at test time without being over-whelmed by their scale.Our selection method is two steps.
First, wegather relevant information for each gazetteer ele-ment using domain-specific search logs.
Then weperform CCA using this information to derive low-dimensional gazetteer embeddings (Hotelling,1936).
Second, we use a subset selection methodbased on RRQR to locate gazetteer embeddingswhose span approximates the the entire lexiconspace (Boutsidis et al., 2009; Kim and Snyder,2013).
We show in slot tagging experiments thatthe gazetteer elements selected by our method notonly preserve the performance of using full lexi-con but even improve it in some cases.
Comparedto random selection, our method achieves averagerelative error reduction of > 50%.2 MotivationWe motivate our task by describing the processof lexicon construction.
Entity dictionaries areusually automatically mined from the web us-ing resources that provide typed entities.
Ona regular basis, these dictionaries are automati-cally updated and accumulated based on local datafeeds and knowledge graphs.
Local data feedsare generated from various origins (e.g., yellowpages, Yelp).
Knowledge graphs such as www.freebase.com are resources that define a se-mantic space of entities (e.g., movie names, per-806sons, places and organizations) and their relations.Because of the need to keep dictionaries up-dated to handle newly emerging entities, lexiconconstruction is designed to aim for high recall atthe expense of precision.
Consequently, the result-ing gazetteers are noisy.
For example, a movie dic-tionary may contain hundreds of thousands movienames, but many of them are false positives.While this large base of entities is useful as awhole, it is challenging to take advantage of at testtime.
This is because we normally cannot affordto consume so much memory when we deploy anSLU model in practice.
In the next section, wewill describe a way to filter these entities whileretaining their overall benefit.3 Method3.1 Row subset selection problemWe frame gazetteer element selection as the rowsubset selection problem.
In this framework, weorganize n gazetteer elements as matrixA ?
Rn?dwhose rows Ai?
Rdare some representationsof the gazetteer members.
Given m ?
n, letS(A,m) := {B ?
Rm?d: Bi= Api(i)} be a setof matrices whose rows are a subset of the rowsof A.
Note that |S(A,m)| =(nm).
Our goal is toselect1B?= arg minB?S(A,m)????A?AB+B???
?FThat is, we want B to satisfy range(B>) ?range(A>).
We can solve for B?exactly withexhaustive search in O(nm), but this brute-forceapproach is clearly not scalable.
Instead, we turnto the O(nd2) algorithm of Boutsidis et al.
(2009)which we review below.3.1.1 RRQR factorizationA key ingredient in the algorithm of Boutsidis etal.
(2009) is the use of RRQR factorization.
Recallthat a (thin) QR factorization of A expresses A =QR where Q ?
Rn?dhas orthonormal columnsand R ?
Rd?dis an upper triangular matrix.
Alimitation of QR factorization is that it does notassign a score to each of the d components.
This isin contrast to singular value decomposition (SVD)which assigns a score (singular value) indicatingthe importance of these components.1The Frobenius norm ||M ||Fis defined as the entry-wiseL2norm:??i,jm2ij.
B+is the Moore-Penrose pseudo-inverse of BInput: d-dimensional gazetteer representations A ?
Rn?d,number of gazetteer elements to select m ?
nOutput: m rows of A, call B ?
Rm?d, such that????A?AB+B???
?Fis small?
Perform SVD on A and let U ?
Rd?mbe a ma-trix whose columns are the left singular vectors cor-responding to the largest m singular values.?
Associate a probability piwith the i-th row of A asfollows:pi:= min{1, bm logmc||Ui||2m}?
Discard the i-th row of A with probability 1 ?
pi.If kept, the row is multiplied by 1/?pi.
Let theseO(m logm) rows form the columns of a new matrix?A ?
Rd?O(m logm).?
Perform RRQR on?A to obtain?A?
= QR.?
Return the m rows of the original A corresponding tothe top m columns of?A?.Figure 1: Gazetteer selection based on the algo-rithm of Boutsidis et al.
(2009).RRQR factorization is a less well-known vari-ant of QR that addresses this limitation.
Let?i(M) denote the i-th largest singular value ofmatrix M .
Given A, RRQR jointly finds apermutation matrix ?
?
{0, 1}d?d, orthonor-mal Q ?
Rn?d, and upper triangular R =[R11R12; 0 R22] ?
Rd?dsuch thatA?
= Q[R11R12R22]satisfying ?k(R11) = O(?k(A)) and ?1(R22) =?
(?k+1(A)) for k = 1 .
.
.
d. Because of this rank-ing property, RRQR ?reveals?
the numerical rankof A.
Furthermore, the columns of A?
are sortedin the order of decreasing importance.3.1.2 Gazetteer selection algorithmThe algorithm is a two-stage procedure.
In the firststep, we randomly sample O(m logm) rows of Awith carefully chosen probabilities and scale themto form columns of matrix?A ?
Rd?O(m logm).In the second step, we perform RRQR factoriza-tion on?A and collect the gazetteer elements cor-responding to the top components given by theRRQR permutation.
The algorithm is shown inFigure 1.
The first stage involves random sam-pling and scaling of rows, but it is shown that?A807has O(m logm) columns with constant probabil-ity.This algorithm has the following optimalityguarantee:Theorem 3.1 (Boutsidis et al.
(2009)).
Let?B ?Rm?dbe the matrix returned by the algorithm inFigure 1.
Then with probability at least 0.7,??????A?A?B+?B??????F?
O(m?logm)?min?A?Rn?d:rank(?A)=m??????A??A?????
?FIn other words, the selected rows are not arbi-trarily worse than the best rank-m approximationof A (given by SVD) with high probability.3.2 Gazetteer embeddings via CCAIn order to perform the selection algorithm in Fig-ure 1, we need a d-dimensional representation foreach of n gazetteer elements.
We use CCA for itssimplicity and generality.3.2.1 Canonical Correlation Analysis (CCA)CCA is a general statistical technique that char-acterizes the linear relationship between a pair ofmulti-dimensional variables.
CCA seeks to find kdimensions (k is a parameter to be specified) inwhich these variables are maximally correlated.Let x1.
.
.
xn?
Rdand y1.
.
.
yn?
Rd?be nsamples of the two variables.
For simplicity, as-sume that these variables have zero mean.
ThenCCA computes the following for i = 1 .
.
.
k:arg maxui?Rd, vi?Rd?
:u>iui?=0 ?i?<iv>ivi?=0 ?i?<i?nl=1(u>ixl)(v>iyl)??nl=1(u>ixl)2?
?nl=1(v>iyl)2In other words, each (ui, vi) is a pair of projec-tion vectors such that the correlation between theprojected variables u>ixland v>iylis maximized,under the constraint that this projection is uncor-related with the previous i?
1 projections.This is a non-convex problem due to the inter-action between uiand vi.
However, a methodbased on singular value decomposition (SVD) pro-vides an efficient and exact solution to this prob-lem (Hotelling, 1936).
The resulting solutionu1.
.
.
uk?
Rdand v1.
.
.
vk?
Rd?can be usedto project the variables from the original d- andd?-dimensional spaces to a k-dimensional space:x ?
Rd??
x?
?
Rk: x?i= u>ixy ?
Rd???
y?
?
Rk: y?i= v>iyThe new k-dimensional representation of eachvariable now contains information about the othervariable.
The value of k is usually selected to bemuch smaller than d or d?, so the representation istypically also low-dimensional.3.2.2 Inducing gazetteer embeddingsWe now describe how to use CCA to induce vec-tor representations for gazetteer elements.
Usingthe same notation, let n be the number of elementsin the entire gazetteers.
Let x1.
.
.
xnbe the orig-inal representations of the element samples andy1.
.
.
ynbe the original representations of the as-sociated features in the element.We employ the following definition for the orig-inal representations.
Let d be the number of dis-tinct element types and d?be the number of distinctfeature types.?
xl?
Rdis a zero vector in which the entrycorresponding to the element type of the l-thinstance is set to 1.?
yl?
Rd?is a zero vector in which the en-tries corresponding to features generated bythe element are set to 1.In our case, we want to induce gazetteer (ele-ment) embeddings that correlate with the relevantfeatures about gazetteers.
For this purpose, we usethree types of features: context features, searchclick log features, and knowledge graph features.Context features: For each gazetteer element gof domain l, we take sentences from search logson domain l containing g and extract five wordseach to the left and the right of the element g inthe sentences.
For instance, if g = ?The Matrix?is a gazetteer element of domain l = ?Movie?,we collect sentences from movie-specific searchlogs involving the phrase ?The Matrix?.
Suchdomain-specific search logs are collected using apre-trained domain classifier.Search click log features: Large-scale searchengines such as Bing and Google process mil-lions of queries on a daily basis.
Together withthe search queries, user clicked URLs are alsologged anonymously.
These click logs have been808used for extracting semantic information for var-ious NLP tasks (Kim et al., 2015a; Tseng et al.,2009; Hakkani-T?ur et al., 2011).
We used theclicked URLs as features to determine the likeli-hood of an entity being a member of a dictionary.These features are useful because common URLsare shared across different names such as movie,business and music.
Table 1 shows the top fivemost frequently clicked URLs for movies ?Furi-ous 7?
and ?The age of adaline?.Furious 7 The age of adalineimdb.com imdb.comen.wikipedia.org en.wikipedia.orgfurious7.com youtube.comrottentomatoes.com rottentomatoes.comwww.msn.com movieinsider.comTable 1: Top clicked URLs of two movies.One issue with using only click logs is that someentities may not be covered in the query logs sincelogs are extracted from a limited time frame (e.g.six months).
Even the big search engines employa moving time window for processing and stor-ing search logs.
Consequently, click logs are notnecessarily good evidence.
For example, ?apollothirteen?
is a movie name appearing in the movietraining data, but it does not appear in search logs.One way to solve the issue of missing logs for en-tities is to search bing.com at real time.
Giventhat the search engine is updated on a daily ba-sis, real-time search can make sure we capture thenewest entities.
We run live search for all entitiesno matter if they appear in search logs or not.
EachURL returned from the live search is considered tohave an additional click.Knowledge graph features: The graph inwww.freebase.com contains a large set of tu-ples in a resource description framework (RDF)defined by W3C.
A tuple typically consists of twoentities: a subject and an object linked by somerelation.An interesting part of this resource is the entitytype defined in the graph for each entity.
In theknowledge graph, the ?type?
relation representsthe entity type.
Table 2 shows some examples ofentities and their relations in the knowledge graph.From the graph, we learn that ?Romeo & Juliet?could be a film name or a music album since it hastwo types: ?film.film?
and ?music.album?.Subject Relation ObjectJason Statham type film.actorJason Statham type tv.actorJason Statham type film.producerRomeo & Juliet type film.filmRomeo & Juliet type music.albumTable 2: Entities & relation in the knowledge graph.4 ExperimentsTo test the effectiveness of the proposed gazetteerselection method, we conduct slot tagging experi-ments across a test suite of three domains: Movies,Music and Places, which are very sensitive do-mains to gazetteer features.
The task of slot tag-ging is to find the correct sequence of tags ofwords given a user utterance.
For example, inPlaces domain, a user could say ?search for homedepot in kingsport?
and the phrase ?home depot?and ?kingsport?
are tagged with Place Nameand Location respectively.
The data statisticsare shown in Table 3.
One domain can have var-ious kinds of gazetteers.
For example, Places do-main has business name, restaurant name, schoolname and etc.
Candidate dictionaries are minedfrom the web and search logs automatically usingbasic pattern matching approaches (e.g.
entitiessharing the same or similar context in queries ordocuments) and consequently contain significantamount of noise.
As the table indicates, the num-ber of elements in total across all the gazetteers(#total gazet elements) in each domain are toolarge for models to consume.In all our experiments, we trained conditionalrandom fields (CRFs) (Lafferty et al., 2001) withthe following features: (1) n-gram features up ton = 3, (2) regular expression features, and (3)Brown clusters (Brown et al., 1992) induced fromsearch logs.
With these features, we compare thefollowing methods to demonstrate the importanceof adding appropriate gazetteers:?
NoG: train without gazetteer features.?
AllG: train with all gazetteers.?
RandG: train with randomly selectedgazetteers.?
RRQRG: train with gazetteers selected fromRRQR.?
RankAllG: train with all ranked gazetteers.809Domains #labels #kinds of gazets #total gazet elements #training queries #test queriesMovies 25 21 14,188,527 43,784 12,179Music 7 13 62,231,869 31,853 8,615Places 32 31 34,227,612 22,345 6,143Table 3: Data statisticsHere gazetteer features are activated when aphrase contains an entity in a dictionary.
ForRandG, we first sample a category of gazetteersuniformly and then choose a lexicon fromgazetteers in that category.
The results when weuse selected gazetteer randomly in whole cate-gories are very low and did not include them here.For selecting gazetteer methods (NoG, RnadG andRRQRG), we select 500,000 elements in total.Places Music Movies AVG.NoG 89.10 81.53 84.78 85.14AllG 92.11 84.24 88.56 88.30RRQRG 91.80 83.83 87.41 87.68RandG 86.20 76.53 77.23 79.99Table 4: Comparison of models evaluated on three do-mains.
The numbers are F1-scores.4.1 Results across DomainsFirst, we evaluate all models across three do-mains.
Note that the both training and test dataare collected from the United States.
The resultsare shown in Table 4.
Not surprisingly, usingall gazetteer features (AllG) boosts the F1 scorefrom 85.14 % to 88.30%, confirming the powerof gazetteer features.
However, with a randomselection of gazetteers, the model does not per-form well, only achieving 79.99% F1-score.
In-terestingly, we see that across all domains ourmethod (RRQRG) fares better than both RandGand NoG, almost reaching the AllG performancewith gazetteer size dramatically reduced.4.2 Results across LocalesIn the next experiments, we run experimentsacross three different locales in Places domain:United Kingdom (GB), Australia (AU), and In-dia (IN).
The Places is a very sensitive domain tolocales2.
For example, restaurant names in Indiaare very different from Australia.
Here we assumethat unlike the previous experiments, the trainingdata is collected from the United States and testdata is collected from different locales.
We usedsame training data in the previous experiments and2Since it is very difficult to create all locale specific train-ing data, gazetteer features are very crucial.the size of test data is about 5k for each locale.The results are shown in Table 5.
Interestingly, theRRQR even outperforms the AllG.
This is becausesome noisy entities are filtered.Finally, we show that the proposed method isuseful even in all gazetteer scenario (AllG).
Us-ing RRQR, we can order entities according totheir importance and transform a gazetteer fea-ture into a few ones by binning the entities withtheir rankings.
For example, instead of havingone single big business names gazetteer, we candivide them into lexicon with first 1000 entities,10000 entities and so on.
Results using rankedgazetteers are shown in Table 6.
We see that theRanked gazetteers approach (RankAllG) has con-sistent gains across domains over AllG.GB AU INNoG 87.70 82.20 80.30AllG 90.12 86.98 89.77RRQRG 90.18 87.48 90.28RandG 86.20 65.34 64.20Table 5: Comparison of models across different locales.Places Music Movies AVG.AllG 92.11 84.24 88.56 88.30RankAllG 92.78 86.30 89.1 89.40Table 6: Comparison of models with or without rankedgazetteers.
These are evaluated on three domains collectedin the United States.5 ConclusionWe proposed the task of selecting compact lexi-cons from large and noisy gazetteers.
This sce-nario arises often in practice.
We introduced a sim-ple and effective solution based on matrix decom-position techniques: CCA is used to derive low-dimensional gazetteer embeddings and RRQR isused to find a subset of these embeddings.
Experi-ments on slot tagging show that our method yieldsrelative error reduction of > 50% on average overthe random selection method.810ReferencesTasos Anastasakos, Young-Bum Kim, and Anoop Deo-ras.
2014.
Task specific continuous word represen-tations for mono and multi-lingual spoken languageunderstanding.
In ICASSP, pages 3246?3250.
IEEE.Christos Boutsidis, Michael W Mahoney, and PetrosDrineas.
2009.
An improved approximation al-gorithm for the column subset selection problem.In Proceedings of the twentieth Annual ACM-SIAMSymposium on Discrete Algorithms, pages 968?977.Society for Industrial and Applied Mathematics.Peter F Brown, Peter V Desouza, Robert L Mercer,Vincent J Della Pietra, and Jenifer C Lai.
1992.Class-based n-gram models of natural language.Computational linguistics, 18(4):467?479.Asli Celikyilmaz, Dilek Z Hakkani-T?ur, G?okhan T?ur,and Ruhi Sarikaya.
2013.
Semi-supervised seman-tic tagging of conversational understanding usingmarkov topic regression.
In ACL (1), pages 914?923.Asli Celikyilmaz, Dilek Hakkani-Tur, Panupong Pasu-pat, and Ruhi Sarikaya.
2015.
Enriching word em-beddings using knowledge graph for semantic tag-ging in conversational dialog systems.
AAAI - As-sociation for the Advancement of Artificial Intelli-gence, January.Dilek Hakkani-T?ur, Gokhan Tur, Larry Heck, Asli Ce-likyilmaz, Ashley Fidler, Dustin Hillard, RukminiIyer, and S. Parthasarathy.
2011.
Employing websearch query click logs for multi-domain spokenlanguage understanding.
IEEE Automatic SpeechRecognition and Understanding Workshop, Decem-ber.Dustin Hillard, Asli Celikyilmaz, Dilek Z Hakkani-T?ur, and G?okhan T?ur.
2011.
Learning weightedentity lists from web click logs for spoken languageunderstanding.
In INTERSPEECH, pages 705?708.Harold Hotelling.
1936.
Relations between two sets ofvariates.
Biometrika, 28(3/4):321?377.Young-Bum Kim and Benjamin Snyder.
2013.
Opti-mal data set selection: An application to grapheme-to-phoneme conversion.
In HLT-NAACL, pages1196?1205.
Association for Computational Linguis-tics.Young-Bum Kim, Jeong Minwoo, Karl Startos, andRuhi Sarikaya.
2015a.
Weakly supervised slottagging with partially labeled sequences from websearch click logs.
In HLT-NAACL, pages 84?92.
As-sociation for Computational Linguistics.Young-Bum Kim, Karl Stratos, and Ruhi Sarikaya.2015b.
Pre-training of hidden-unit crfs.
In ACL.Association for Computational Linguistics.Young-Bum Kim, Karl Stratos, Ruhi Sarikaya, andMinwoo Jeong.
2015c.
New transfer learning tech-niques for disparate label sets.
In ACL.
Associationfor Computational Linguistics.John Lafferty, Andrew McCallum, and Fernando CNPereira.
2001.
Conditional random fields: Prob-abilistic models for segmenting and labeling se-quence data.
In ICML, pages 282?289.Xiao Li, Ye-Yi Wang, and Alex Acero.
2009.
Extract-ing structured information from user queries withsemi-supervised conditional random fields.
In Pro-ceedings of the 32nd international ACM SIGIR con-ference on Research and development in informationretrieval.Xiaohu Liu and Ruhi Sarikaya.
2014.
A discriminativemodel based entity dictionary weighting approachfor spoken language understanding.
In Spoken Lan-guage Technology Workshop (SLT), pages 195?199.IEEE.Ruhi Sarikaya, Asli C, Anoop Deoras, and MinwooJeong.
2014.
Shrinkage based features for slot tag-ging with conditional random fields.
In Proceedingof ISCA - International Speech Communication As-sociation, September.Huihsin Tseng, Longbin Chen, Fan Li, Ziming Zhuang,Lei Duan, and Belle Tseng.
2009.
Mining searchengine clickthrough log for matching n-gram fea-tures.
In Proceedings of the 2009 Conference onEmpirical Methods in Natural Language Process-ing: Volume 2-Volume 2, pages 524?533.
Associa-tion for Computational Linguistics.Puyang Xu and Ruhi Sarikaya.
2014.
Targeted featuredropout for robust slot filling in natural language un-derstanding.
In ISCA - International Speech Com-munication Association, September.811
