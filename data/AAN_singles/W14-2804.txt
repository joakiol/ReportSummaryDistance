Proceedings of the 2014 Joint Meeting of SIGMORPHON and SIGFSM, pages 29?36,Baltimore, Maryland USA, June 27 2014.c?2014 Association for Computational LinguisticsGeneralizing inflection tables into paradigms with finite state operationsMans HuldenUniversity of Helsinkimans.hulden@helsinki.fiAbstractExtracting and performing an alignmentof the longest common subsequence in in-flection tables has been shown to be afruitful approach to supervised learningof morphological paradigms.
However,finding the longest subsequence commonto multiple strings is well known to bean intractable problem.
Additional con-straints on the solution sought complicatethe problem further?such as requiringthat the particular subsequence extracted,if there is ambiguity, be one that is bestalignable in an inflection table.
In this pa-per we present and discuss the design of atool that performs the extraction throughsome advanced techniques in finite statecalculus and does so efficiently enough forthe practical purposes of inflection tablegeneralization.1 IntroductionSupervised learning of morphological paradigmsfrom inflection tables has recently been ap-proached from a number of directions.
One ap-proach is given in Hulden et al.
(2014), wheremorphological paradigm induction is performedby extracting the longest common subsequence(LCS) from a set of words representing an in-flection table.
Although that work presents en-couraging results as regards learning morphologi-cal paradigms from inflection tables, no details aregiven as to how the paradigms themselves are ex-tracted.
The purpose of this paper is to describehow such a paradigm extraction procedure can beperformed using only finite state operations.Extracting the longest common subsequencefrom a large number of strings is known as themultiple longest common subsequence problem(MLCS), and is computationally intractable.
Infields like bioinformatics specialized heuristic al-gorithms have been developed for efficiently ex-tracting common subsequences from DNA se-quences.
In linguistics applications where the goalis to extract common patterns in an inflection ta-ble, however, the problem manifests itself in adifferent guise.
While most applications in otherfields work with a small number of fairly long se-quences, inflection tables may contain hundreds ofshort sequences.
Additionally, it is not enough toextract the LCS from an inflection table.
The LCSitself is often ambiguous and may be factorized inseveral different ways in a table.
This means thatwe operate under the additional constraint that theLCS must not only be found, but, in case of ambi-guity, its most contiguous factorization must alsobe indicated, as this often produces linguisticallyinteresting generalizations.In this paper we will address the problem ofextracting the minimal MLCS through entirely fi-nite state means.
Finite state methods lend them-selves to solving this kind of an optimization prob-lem concisely, and, as it turns out, also efficientlyenough for practical purposes.This paper is laid out as follows.
First, weoutline the MLCS-based approach to supervisedlearning of morphological paradigms in section2.
We then describe in broad strokes the algo-rithm required for generalizing inflection tablesinto paradigms in section 3.
Next, we give a finitestate implementation of the algorithm in section4, followed by a brief discussion of a stand-alonesoftware tool based on this that extracts paradigmsfrom collections of inflection tables in section 5.2 Supervised learning of morphologicalparadigmsIn the following, we operate with the central ideaof a model of word formation that organizes wordforms and their inflection patterns into paradigms(Hockett, 1954; Robins, 1959; Matthews, 1972;29Stump, 2001).
In particular, we model paradigmsin a slightly more abstract manner than is custom-arily done.
For the purposes of this paper, we dif-ferentiate between a paradigm and an inflectiontable in the following way: an inflection table issimply a list of words that represents a concretemanifestation, or instantiation, of a paradigm.
Aparadigm is also a list of words, but with spe-cial symbols that represent variables interspersed.These variables, when instantiated, represent par-ticular strings shared across an inflection table.In our representation, this kind of an abstractparadigm is an ordered collection of strings,where each string may additionally contain in-terspersed variables denoted x1, x2, .
.
.
, xn.
Thestrings represent fixed, obligatory parts of aparadigm, while the variables represent mutableparts.
A complete abstract paradigm capturessome generalization where the mutable parts rep-resented by variables are instantiated the sameway for all forms in one particular inflection table.For example, the fairly simple paradigmx1x1+s x1+ed x1+ingcould represent a set of English verb forms, wherex1in this case would coincide with the infinitiveform of the verb?walk, climb, look, etc.12.1 Learning paradigms from inflectiontablesAs is seen from the above example, a generalenough paradigm can encode the inflection pat-tern of a large number of words.
When learningsuch paradigms from data?i.e.
complete inflec-tion tables?we intuitively want to find the ?com-mon?
elements of a table and generalize those.The core of the method is to factor the wordforms in an inflection table in such a manner thatthe elements common to all entries are declaredvariables, while the non-common elements are as-sumed to be part of the inflection pattern.
To illus-trate the idea with an example, consider a short-ened inflection table for the regular German verbholen (to fetch):21Our formalization of a paradigm of strings and interven-ing variables bears many similarities to so-called pattern lan-guages (Angluin, 1980).
In fact, each entry in a paradigmcould be considered a separate pattern language.
Addition-ally, all the individual pattern languages in one paradigm areconstrained to share the same variables and the variables areconstrained to collectively be instantiated the same way.2We follow the convention that entries in an inflection ta-ble are separated by #.hole#holst#holt#holen#holt#holen#geholt (1)Obviously, in this example, the element com-mon to each entry in the inflection table is hol.Declaring hol to be a variable, we can rewrite theinflection table as:x1+e#x1+st#x1+t#x1+en#x1+t#x1+en#ge+x1+t (2)This extraction of the ?common elements?
isformalized in Hulden et al.
(2014) to be equivalentto extraction of the longest common subsequenceof the strings w1, .
.
.
, wnin an inflection table.3The purpose of extracting the common parts andlabeling them variables is to provide a model forgeneralization of inflection patterns.
Under the as-sumption that a variable xiin this paradigm rep-resentation corresponds to a nonempty string, wecan instantiate an inflection table by simply pro-viding the variable strings x1, .
.
.
, xn.
Thus, wecan talk about a paradigm-generating functionf : (x1, .
.
.
, xn)?
?
?that maps instantiations of variables to a string rep-resenting the complete inflection table, in this casea string where entries are #-separated.To illustrate this, consider the simple paradigmin (2).
It implicitly defines a function f where, forexample, f(kauf) maps to the stringkaufe#kaufst#kauft#kaufen#kauft#kaufen#gekauft (3)i.e.
produces the inflection table for the regularverb kaufen (to buy), which behaves like holen.Likewise, we can also consider the inverse func-tion.
Given an unknown word form, e.g.
macht(to make, 3pSg), we can see that the only way itfits the paradigm in (2) is if it comes from an in-flection table:mache#machst#macht#machen#macht#machen#gemacht(4)that is, if macht is part of the output for f (mach).3Not to be confused with the longest common substring,which is a different problem, solvable in polynomial timefor n strings.
Subsequences may be discontinuous whilesubstrings may not.
For example, assume s = abcaa andt = dbcadaa.
The longest common substring shared by thetwo is bca obtained from s by abcaa and t by dbcadaa.
Bycontrast, the longest common subsequence is bcaa, obtainedfrom s by abcaa and t by dbcadaa or dbcadaa or dbcadaa.30ringrangrung[r]i[ng][r]a[ng][r]u[ng]rng?
Extract     LCS ?
Fit LCS      to table ?
Generalize     to paradigmsInput:inflectiontablesswimswamswumswm[sw]i[m][sw]a[m][sw]u[m]x1+i+x2x1+a+x2x1+u+x2x1+i+x2x1+a+x2x1+u+x2?
Collapse     paradigmsx1+i+x2x1+a+x2x1+u+x2}} }}Figure 1: Paradigm extraction strategy.In other words, the extraction of multiple com-mon longest subsequences (MLCS) from inflec-tion tables immediately provides a (simple) gener-alization mechanism of a grammar, and also sug-gests a supervised learning strategy for morpho-logical paradigms.
In conjunction with statisticalmachine learning methods, Hulden et al.
(2014)has shown that the paradigm extraction and gen-eralization method provides competitive resultsin various supervised and semi-supervised NLPlearning tasks.
One such task is to provide a hy-pothetical reconstruction of a complete inflectiontable from an unseen base form after first witness-ing a number of complete inflection tables.
An-other task is the semi-supervised collection of lex-ical entries and matching them to paradigms byobserving distributions of word forms across allthe possible paradigms they can fit into.
In gen-eral, there is much current interest in similar tasksin NLP; see e.g.
Dreyer and Eisner (2011); Dur-rett and DeNero (2013); Eskander et al.
(2013) fora variety of current methods.3 Learning methodThe basic procedure as outlined by Hulden et al.
(2014) for learning paradigms from inflection ta-bles can be represented by the four-step proceduregiven in figure 1.
Here, multiple inflection tablesare gathered, and the LCS to each table is foundindividually.
Following that, the LCS is fit intothe table, and contiguous segments that participatein the LCS are labeled variables.
After paradigmgeneralization, it may turn out that several identi-cal paradigms have been learned, which may thenbe collapsed.The first two steps of the method dictate thatone:1.
Extract the longest common subsequence(LCS) to all the entries in the inflection table.2.
Split the LCS(s)?of which there may beseveral?into variables in such a way that thenumber of variables is minimized.
Two seg-ments xy are always part of the same variableif they occur together in every form of an in-flection table.
If some substring z intervenesbetween x and y in some form, x and y mustbe assigned separate variables.These steps represent steps ?
and ?
in figure1.
After the variables have been identified, steps?
and ?
in the figure are easily accomplished bynon-finite-state means.In the following, we will focus on the previ-ously unaddressed problem of finding the LCS ofan inflection table (?
), and of distributing possiblevariables corresponding to contiguous sequencesof the LCS in a way that gives rise to the mini-mum number of variables (?
).4 Finite-state implementationThe main challenge in producing a paradigm froman inflection table is not the extraction of thelongest common subsequences, but rather, doingso with the added criterion of minimizing the num-ber of variables used.
Extracting the LCS frommultiple strings is known to be NP-hard (Maier,1978) and naive implementations will fail quicklyfor even a moderate number of strings found in in-flection tables.
While there exist specialized algo-rithms that attempt to efficiently either calculate(Irving and Fraser, 1992) or approximate (Wanget al., 2010) the LCS, we find that extraction caneasily be accomplished with a simple transducercalculation.
The task of ascertaining that the LCSis distributed in such a way as to minimize thenumber of variables turns out to be more challeng-ing; at the same time, however, it is a problem towhich the finite state calculus is particularly wellsuited, as will be seen below.4.1 Notation and toolThe paradigm extraction tool was implementedwith the help of the foma toolkit (Hulden, 2009).In the actual implementation, instead of directlycompiling regular expressions, we make use offoma?s programming API, but in the following wegive regular expression equivalents to the methodused.
Table 1 contains a summary of the regularexpression notation used.310 Empty string?
Any symbol in alphabet.#.
End or beginning of string{xyz} StringAB ConcatenationA*, A+ Kleene star, Kleene plusA|B UnionA & B IntersectionA - B Difference?A ComplementA .o.
B Composition% Escape symbol[ and ] Grouping bracketsA:B Cross productT.2 Output projection of TA -> B Rewrite A as Beq(X,L,R) Strings between L,R are equaldef W {word} Define FSM constantdef F(X,Y) X Y Regular expression macroTable 1: Regular expression notation in foma.4.2 LCS extractionAs the first step, we assume that we have encodedeach word w1, .
.
.
, wnin an inflection table as anautomaton that accepts that word.4In general, we can define the set of subse-quences of any word by a general regular expres-sion technique:def SS(X) [X .o.
[?|?
:0]*].2;SS(w) then contains all of the subsequencesof some word w. Taking advantage of this, wemay calculate the intersection of each set of sub-sequences SS(w1) & ...& SS(wn), produc-ing the language that contains all the commonsubsequences to w1, .
.
.
, wn.
From this, extract-ing the longest subsequence or sequences could inprinciple be performed by inspecting the resultingautomaton, but the same can also be done alge-braically for finite sets:def Max(X) X -[[X .o.
[?:a]*[?
:0]+].2 .o.
[a:?
]*].2;Here, Max(X) is a regular expression tech-nique of extracting the set of longest strings froman automaton.
We achieve this in practice by firstchanging all symbols in X to an arbitrary sym-bol (a in this case), removing at least one symbolfrom the end, and using this intermediate result to4We abuse notation slightly by representing by wiboth aword and an automaton that accepts that word.remove from X all strings shorter than the maxi-mum.5An automaton that contains all LCSs for a set ofwords w1, .
.
.
, wncan thus be calculated as:Max(SS(w1) & ... & SS(wn)) (5)The above two lines together represent asurprisingly efficient manner of calculating theMLCS for a large number of relatively similarshort sequences (less than 100 characters) andis essentially equivalent to performing the samecalculation through dynamic programming algo-rithms with some additional search heuristics.4.3 Minimizing variablesWe can then assume that we have calculated theLCS or LCSs for an inflection table and can rep-resent it as an automaton.
The following step is toassign variables to segments that can correspondto the LCS in a minimal way.
The minimality re-quirement is crucial for good generalization as isseen in the illustration here:comprarcompracompro{ x1comprarcompracompro{{x1 x2(a) (b){ {x1 x2x1 {The above shows two ways of breaking up theLCS compr in the hypothetical three-word inflec-tion table for Spanish.
In case (a) the comprhas been located contiguously in inflection entries,while in (b) there is a gap in the first form, leadingto the inevitable use of two variables to generalizethe table.In the finite-state string encoding, the overallintent of our effort to calculate the minimum-variable MLCS assignment in the table is toproduce an automaton that contains the divi-sions of variables marked up with brackets.For example, given a hypothetical two-word ta-ble holen#geholt, the LCS is obviously hol.Now, there are several valid divisions of holinto variables, e.g.
[ho][l]en#ge[ho][l]t, whichwould represent a two-variable division, while5This is a rather inefficient way of extracting the set oflongest strings from an automaton.
However, as the runtimeof this part represents only a minute fraction of the completeprocedure, we do so to preserve the benefit of clarity that us-ing finite-state calculus offers.32pextract example1 def SS(X) [X .o.
[?|?
:0]*].2;2 def Max(X) X - [[X .o.
?:a*?
:0+].2 .o.
a:?
*].2;3 def RedupN(X,Y) [_eq([LEFT X RIGHT [Y LEFT X RIGHT]*], LEFT, RIGHT) .o.
LEFT|RIGHT -> 0].l;4 def NOBR ?
- %[ - %] - %#;5 def Order(X) [[X .o.
0:%# ?
*0:%# .o.6 ?
*%# [NOBR | %[:%< | %]:%>]*%# ?
*.o.7 %[|%] -> 0 .o.8 [?
*0:%> 0:%< \[%<|%>|%[|%] ]+ %> ?
*]*.o.9 %#:0 ?
*%#:0 .o.10 0 -> %[|%] .o.
%< -> %[ .o.
%> -> %]] .o.
X ].2;11 def MarkRoot(X) [X .o.
[?|0:%[ ?+ 0:%]]*].2;12 def RandomBracketing(X) [X .o.
[?
| 0:%[ NOBR*0:%]]*].2;13 def AddExtraSegments(X) [X .o.
[0:NOBR*| %[ \%]*%] | %#]*].2;14 def Filter(X) X - Order(X);1516 def Table {hole#holst#holt#holen#holt#holen#geholt};17 def MLCS Max(SS({hole}) & SS({holst}) & SS({holt}) & SS({holen}) & SS({holt}) & SS({holen}) & SS({geholt}));18 def BracketedMLCS AddExtraSegments(RedupN(MarkRoot(MLCS), %#));19 def BracketedTable RandomBracketing(Table);2021 regex Filter(BracketedMLCS & BracketedTable);22 print wordsFigure 2: Complete implementation of the extraction of the minimum-variable longest common subse-quences as a foma-script.
Here, a small German verb table is hard-coded for illustration purposes onlines 16 and 17.
The output is [hol]e#[hol]st#[hol]t#[hol]en#[hol]t#[hol]en#ge[hol]t[hol]en#ge[hol]t would represent a one-variabledivision.Naturally, these brackets will have to be dividedin such a way that there is no better way to achievethe division?i.e.
no markup such that fewer vari-ables are instantiated.The crux of the method used here is to first pro-duce an automaton that accepts the set of all validmarkups of the MLCS in the table string, and thenuse that set to in turn define the set of suboptimalmarkups.
Similar finite-state techniques have beenused by Gerdemann and van Noord (2000); Eisner(2002); Karttunen (2010); Gerdemann and Hulden(2012), to, among other things, define suboptimalcandidates in Optimality Theory.
The trick is to setup a transducer T that contains the input-outputpair (x, x?
), iff x?represents a worse division ofvariables than x does.
In effect, T captures thetransitive closure of an ordering relation  of thevarious factorizations of the strings into variables,and T contains the string pair (x, x?)
when x+x?.
In general, supposing that we have an identitytransducer, i.e.
automaton A, and a transducer Tthat maps strings in A according to the transitiveclosure of an ordering relation , then we can al-ways remove the suboptimal strings according tofrom A by calculating A?
range(A ?
T ).Apart from this central idea, some bookkeep-ing is required because we are working with stringrepresentations of inflection tables.
A completefoma listing that captures the behavior of our im-plementation is given in figure 2.
The main com-plication in the program is to produce the transitiveclosure of the ordering by setting up a transducerOrder that, given some bracketed string, breaksup continuous sequences of brackets into disconti-nuities, e.g.
[xyz]?
[x][yz],[xy][z], [x][y][z].The main logic of the program appears on lines18?21.
The BracketedMLCS is the languagewhere the MLCS has been bracketed in variousways and extra segments inserted arbitrarily.
Anextra complication is that the MLCS must alwaysbe bracketed the same way within a string, e.g.
[xy][z]#...#[xy][z], or [x][yz]#...#[x][yz] etc.
Thatis, the variable splits have to be equal across en-tries.The BracketedTable language is the lan-guage that contains a string that represents the in-flection table at hand, but with arbitrary bracket-ings.
The intersection of the two languages thencontain the valid MLCS bracketings of the inflec-tion table.
After the intersection is calculated, weapply the ordering transducer and filter out thosestrings with suboptimal bracket markup.
Figure 3illustrates the process.4.4 Optimizations and additionsIn addition to the description given above, theactual implementation contains a number of sec-ondary optimization strategies.
The foremost oneis the simple preprocessing move to locate firstthe longest common prefix p in the inflection ta-ble before any processing is done.
This can, ofcourse, be discovered very efficiently.
The prefix33[ho][l]e#[ho][l]st#[ho][l]t#[ho][l]en#[ho][l]t#[ho][l]en#ge[ho][l]t[hol]e#[hol]st#[hol]t#[hol]en#[hol]t#[hol]en#ge[hol]t[h][o][l]e#[h][o][l]st#[h][o][l]t#[h][o][l]en#[h][o][l]t#[h][o][l]en#ge[h][o][l]t[h][ol]e#[h][ol]st#[h][ol]t#[h][ol]en#[h][ol]t#[h][ol]en#ge[h][ol]t[hol]e#[hol]st#[hol]t#[hol]en#[hol]t#[hol]en#ge[hol]tFilter(BracketedMLCS & BracketedTable)BracketedMLCS & BracketedTable[h]ole#ho[ls][t]#holt#h[o]len#ho[lt]#[ho][le][n]#[ge]h[ol][t]h[o]le#h[ol][st]#[h]olt#holen#[hol]t#h[o][l]e[n]#g[eh]o[lt]hole#[h]ol[st]#[ho]l[t]#[h][o][len]#holt#hol[en]#[g][eh][o]l[t]...BracketedTable X[ho]X[l]X#X[ho]X[l]X#X[ho]X[l]X#X[ho]X[l]X#X[ho]X[l]X#X[ho]X[l]X#X[ho]X[l]XX[hol]X#X[hol]X#X[hol]X#X[hol]X#X[hol]X#X[hol]X#X[hol]XX[h]X[ol]X#X[h]X[ol]X#X[h]X[ol]X#X[h]X[ol]X#X[h]X[ol]X#X[h]X[ol]X#X[h]X[ol]XX[h]X[o]X[l]X#X[h]X[o]X[l]X#X[h]X[o]X[l]X#X[h]X[o]X[l]X#X[h]X[o]X[l]X#X[h]X[o]X[l]XBracketedMLCSholMLCSFigure 3: Illustrated steps in the process of extracting and identifying the MLCS.
The MLCS languagecontains only the longest common subsequence(s).
From that language, the language BracketedMLCSis generated, which contains arbitrary strings with the MLCS bracketed in different ways (X here repre-sents any string from ??).
Intersecting that language with the BracketedTable language and filteringout suboptimal bracketings yields the final generalization.can be set aside until the main algorithm is com-pleted, and then attached as a separate variable tothe paradigm that was extracted without p. Thishas little noticeable effect in most cases, but doesspeed up the variable minimization with large ta-bles that contains words more than 30 characterslong.
Although not included in the implementa-tion, the same maneuver can subsequently be per-formed on the longest common suffix of the re-maining string after the prefix is extracted.Additionally, there are still residual caseswhere the LCS may be located in several wayswith the same number of variables.
An ac-tual example comes from a Swedish paradigmwith two options: [sege]l#[seg]l[e]n#[seg]l[e]t vs.[seg]e[l]#[segl]en#[segl]et.
The ambiguity hereis due to the two equally long LCSs sege andsegl.
These are resolved in our implementationthrough non-finite-state means by choosing the di-vision that results in the smallest number of infix-segments.5 ImplementationWe have implemented the above paradigm ex-tractor as a freely available stand-alone toolpextract.6The utility reads inflection tables,generalizes them into paradigms and collapses re-sulting identical paradigms.
Steps ?
and ?
infigure 1 are trivially performed by non-finite statemeans.
After paradigm generalization, bracketedsequences are replaced by variable symbols (step?).
As each paradigm is then represented as a sin-6http://pextract.googlecode.comgle string, paradigm collapsing can be performedby simply testing string equivalence.The tool also implements some further globalrestrictions on the nature of the generalizations al-lowed.
These include, for example, a linguisticallymotivated attempt to minimize the number of in-fixes in paradigms.
It also stores information (seefigure 4) about the components of generalizations:the variable instantiations seen, etc., which may beuseful for subsequent tools that take advantage ofits output.7Figure 4 briefly illustrates through a toy exam-ple the input and output to the extraction tool:inputs are simply lists of entries in inflection ta-bles, with or without morphological information,and the output is a list of paradigms where num-bers correspond to variables.
In the event that sev-eral paradigms can be collapsed, the tool collapsesthem (as indeed is seen in figure 4).
The actual in-stantiations of the variables seen are also stored,represented by the digits 1, .
.
.
as are the completefirst (often base) forms, represented by 0.
In effect,all the seen inflection tables can in principle be re-constructed from the resulting abstract paradigms.Table 2 shows how the pextract tool gener-alizes with five data sets covering German (DE),Spanish (ES), and Finnish (FI), provided by Dur-rett and DeNero (2013), along with running times.Here, among other things, we see that the toolhas generalized 3,855 Spanish verb inflection ta-7Statistical information about what the variables lookedlike during generalization can be useful information whenperforming classifying tasks, such as attempting to fit pre-viously unseen words to already learned paradigms, etc.34katabtu  perf-1-sgkatabta  perf-2-m-sgkutibu   pass-perf-3-m-plkutibna  pass-perf-3-f-pldarastu  perf-1-sgdarasta  perf-2-m-sgdurisu   pass-perf-3-m-pldurisna  pass-perf-3-f-pl1+a+2+a+3+tu#1+a+2+a+3+ta#1+u+2+i+3+u#1+u+2+i+3+na0=katabtu1=k2=t3=b0=darastu1=d2=r3=spextractFigure 4: Paradigm extraction tool.
For the two toy Arabic inflection tables on the left, the pextracttool produces one three-variable paradigm as output, and reports how the three variables have beeninstantiated in the example data, and also how the first form (presumably often the base form) appearedin its entirety.bles into 97 distinct paradigms, and 6,200 Finnishnouns and adjectives have been reduced to 258paradigms.
For comparison, the fairly com-plete Thompson (1998) lists 79 classes of Span-ish verbs, while the Kotus (2007) grammar de-scription counts 51 Finnish noun and adjectiveparadigms.Much of the remaining redundancy in resultingparadigms can be attributed to lack of phonologi-cal modeling.
That is, paradigms could be furthercollapsed if phonological alternations were addedsubsequently to paradigm extraction.
Consider aselection of four forms from the inflection tablefor the Finnish verb aidata (to fence):aidata#aitaan#aitaat#aitasin (6)This is generalized by the tool intox1+d+x2+ta#x1+t+x2+an#x1+t+x2+at#x1+t+x2+sin(7)The generalization is indeed correct, but themethod does not take into account a gen-eral phonological process of consonant gradationwhere t and d alternate depending on the syllabletype.
With this additional information, paradigmtables could in principle be collapsed further andthis particular paradigm merged with a more gen-eral paradigm learned for Finnish verbs.
Thesame goes for other phonological processes whichsometimes cause the tool to produce superficiallydifferent paradigms that could be collapsed furtherby modeling vowel harmony and other phenom-ena.We may note that the word lengths and inflec-tion table sizes encountered in the wild are farlarger than the examples used in this article.
Forthe Wiktionary data, for example, many inflectiontables have more than 50 entries and word lengthsof 50 characters.Input: Output: Comp.Data inflection abstract time(s)tables paradigmsDE-VERBS 1,827 140 123.6DE-NOUNS 2,564 70 73.5ES-VERBS 3,855 97 144.9FI-VERBS 7,049 282 432.2FI-NOUNS-ADJS 6,200 258 374.1Table 2: Paradigm generalization fromWiktionary-gathered inflection tables.6 ConclusionIn this work, we have presented a method forextracting general paradigms from inflection ta-bles through entirely finite state means.
This in-volves solving a constrained longest common sub-sequence problem, for which the calculus offeredby modern finite state toolkits is well suited.
Al-though the problem in no way requires a finitestate solution, we find that addressing it with ageneral-purpose programming language appearsfar more complex a route.We further note that finite state transducers canbe profitably employed after paradigm generaliza-tion has occurred?to find all possible paradigmsand slots that an unknown word form might fitinto, to generate paradigms from base forms, andso forth.An interesting further potential optimization isto try to address ambiguous LCS assignments withthe completely different strategy of attempting tomaximize similarity across paradigms, or mini-mize the number of resulting paradigms, assumingone is generalizing a batch of inflection tables atthe same time.
Additionally, modeling phonolog-ical phenomena as a separate step after morpho-logical paradigm generalization provides opportu-nities for further development of the system.35AcknowledgementsThis article was much improved by the insightfulcomments provided by the anonymous reviewers.The research was partially funded by the Academyof Finland under grant agreement 258373, Ma-chine learning of rules in natural language mor-phology and phonology.
Additional importantsupport was provided by the Centre for LanguageTechnology and Spr?akbanken at the University ofGothenburg, where part of this research was un-dertaken.ReferencesAngluin, D. (1980).
Finding patterns common to aset of strings.
Journal of Computer and SystemSciences, 21(1):46?62.Dreyer, M. and Eisner, J.
(2011).
Discoveringmorphological paradigms from plain text usinga Dirichlet process mixture model.
In Proceed-ings of the Conference on Empirical Methods inNatural Language Processing, pages 616?627.Association for Computational Linguistics.Durrett, G. and DeNero, J.
(2013).
Supervisedlearning of complete morphological paradigms.In Proceedings of NAACL-HLT, pages 1185?1195.Eisner, J.
(2002).
Comprehension and compilationin optimality theory.
In Proceedings of the 40thAnnual Meeting on Association for Computa-tional Linguistics, pages 56?63.
Association forComputational Linguistics.Eskander, R., Habash, N., and Rambow, O.(2013).
Automatic extraction of morpholog-ical lexicons from morphologically annotatedcorpora.
In Proceedings of the 2013 Confer-ence on Empirical Methods in Natural Lan-guage Processing, pages 1032?1043.
Associa-tion for Computational Linguistics.Gerdemann, D. and Hulden, M. (2012).
Practi-cal finite state optimality theory.
In 10th Inter-national Workshop on Finite State Methods andNatural Language Processing, page 10.Gerdemann, D. and van Noord, G. (2000).
Ap-proximation and exactness in finite state opti-mality theory.
In Proceedings of the Fifth Work-shop of the ACL Special Interest Group in Com-putational Phonology.Hockett, C. F. (1954).
Two models of grammaticaldescription.
Morphology: Critical Concepts inLinguistics, 1:110?138.Hulden, M. (2009).
Foma: a finite-state compilerand library.
In Proceedings of the 12th Confer-ence of the European Chapter of the EuropeanChapter of the Association for ComputationalLinguistics: Demonstrations Session, pages 29?32, Athens, Greece.
Association for Computa-tional Linguistics.Hulden, M., Forsberg, M., and Ahlberg, M.(2014).
Semi-supervised learning of morpho-logical paradigms and lexicons.
In Proceedingsof the 14th Conference of the European Chap-ter of the Association for Computational Lin-guistics, pages 569?578, Gothenburg, Sweden.Association for Computational Linguistics.Irving, R. W. and Fraser, C. B.
(1992).
Two algo-rithms for the longest common subsequence ofthree (or more) strings.
In Combinatorial Pat-tern Matching, pages 214?229.
Springer.Karttunen, L. (2010).
Update on finite state mor-phology tools.
Ms., Palo Alto Research Center.Kotus (2007).
Nykysuomen sanalista [Lexicon ofmodern Finnish].
Kotus.Maier, D. (1978).
The complexity of someproblems on subsequences and supersequences.Journal of the ACM (JACM), 25(2):322?336.Matthews, P. H. (1972).
Inflectional morphology:A theoretical study based on aspects of Latinverb conjugation.
Cambridge University Press.Robins, R. H. (1959).
In defence of WP.
Trans-actions of the Philological Society, 58(1):116?144.Stump, G. T. (2001).
A theory of paradigm struc-ture.
Cambridge University Press.Thompson, S. J.
(1998).
15,000 Spanish verbs:fully conjugated in all the tenses using patternverbs.
Center for Innovative Language Learn-ing.Wang, Q., Pan, M., Shang, Y., and Korkin, D.(2010).
A fast heuristic search algorithm forfinding the longest common subsequence ofmultiple strings.
In AAAI Proc.36
