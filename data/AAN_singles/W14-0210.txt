Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 58?62,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsNavigation Dialog of Blind People: Recovery from Getting LostJan Vystrcil, Ivo Maly, Jan Balata and Zdenek MikovecCzech Technical University in Prague, Faculty Of Electrical EngineeringKarlovo nam.
13, 121 35 Praha 2Czech Republic{vystrjan, malyi1, balatjan, xmikovec}@fel.cvut.czAbstractNavigation of blind people is differentfrom the navigation of sighted people andthere is also difference when the blind per-son is recovering from getting lost.
In thispaper we focus on qualitative analysis ofdialogs between lost blind person and nav-igator, which is done through the mobilephone.
The research was done in two out-door and one indoor location.
The analy-sis revealed several areas where the dialogmodel must focus on detailed information,like evaluation of instructions provided byblind person and his/her ability to reliablylocate navigation points.1 IntroductionWhen blind people travel independently, it mayhappen that they get lost.
This happens when theycan not find any useful navigation points.
Use ofexisting GPS based navigation systems is of no useas the maps do not provide appropriate navigationpoints and the GPS localization is imprecise (tensof meters, where the lost blind person needs preci-sion at highest in meters).
In such situation blindpeople typically use one of two following meth-ods to recover.
First they can ask people in theirsurrounding for help.
Second they can call friendor dedicated assistance center.
The first methodis currently more favorable for blind people, butthey have experience with both methods.
In eachmethod the dialog has different structure due to thedifferent context information available to the help-ing person (called navigator) and lost blind person.In our research we focus on the second method,navigation through mobile phone call.
Balata etal.
(2013b) showed that such method is usable andnavigator can successfully guide blind person inoutdoor environment.
This is because the blindperson is able to efficiently describe his/her po-sition.
Balata et al.
(2013a) found that there isquite good coverage of locations that are very wellknown to blind persons and that they should beable to navigate other lost blind person there.These findings show that building some kind ofassistance center where blind people can help eachother is a promising idea.
Our intention is to ex-tend such a center in a way that the helping per-son will be replaced by natural language based di-alog system.
According to Pittermann (2005) thisdialog system belongs to the category ?Dialog aspurposeful activity?
with overlapping to the cate-gory ?Dialogue as collaborative activity?.
The keyquestions we focus on are:?
How the selection of an appropriate form oflanguage depends on aspects of the environ-ment??
What is the structure of the dialog with re-spect to the environment?In the initial step of this work-in-progress re-search, we want to analyze the communication be-tween lost blind person and the navigator in or-der to analyze the dialog structure and make ini-tial observation about the context information in-terchange and verification dialog.
Such dialog isvery important for navigator to find out, where ex-actly the blind person get lost.
With the knowl-edge of the way of communication between lostblind person and navigator we will be able in thefuture replace the navigator with a navigation sys-tem based on natural language understanding.In order to gather and analyze initial data weran an experiment in which the blind person gotlost and was asked to call the assistance centerwhich mediated connection to suitable navigator.Together, they tried to find the actual position ofblind person and they tried to navigate him/her toend of the track.582 Related WorkMany current dialog systems are based on statisti-cal approach when analyzing the semantics of spo-ken dialog as presented by Jurcicek (2007).
Us-ing belief state tracking provides better results forcases of noisy input.
Ma et al.
(2012) introducedsystem that is combining geographical knowledgeof landmarks with dialog system itself and workwith probabilities of particular locations.Recovering from lost scenario can be also com-pared to robot localization problem as presentedby Thrun (1998) and Thrun et al.
(2001), moreexactly to kidnapped robot problem, where robotwith knowledge of its position is moved to differ-ent location without providing this information tothe robot.
This scenario is testing the ability ofrobot to recover from being lost while expectingto be on another place.
These methods are basedon probabilistic algorithms, working with proba-bilities of measurement while being on a certainplace.However we do not expect blind person to wearany precise sensors for distance measurements andlocalization, we can benefit from his/her senses(touch, hearing and olfaction) that can provide setof reliable observations.3 Experiment Description3.1 Collected DataWe set up an experiment in order to collect and an-alyze initial data about the dialog structure of lostblind person and sighted navigator person.
Duringthe experiment we recorded the course of the testwith two cameras, one was on the blind person?sshoulder and one was used for 3rd person view ofthe scene in order to show context (environment)of the test.
Moreover, we recorded the blind per-son?s position using GPS coordinates in outdoorand blind person?s interaction with mobile naviga-tion application.
Camera recordings and GPS logswere used only for post-test evaluation.
The di-alog between the blind person and navigator wasrecorded and annotated.3.2 ParticipantsFor the experiment, 13 blind people, 8 femaleand 5 male, were invited by e-mail and followingsnowball effect.
All the participants had blindnessof category 4 and 5 ?
according to ICD-10 WHOclassification.3.3 ProcedureIn the experiment, we focused on three types oflocation, two outdoor and one indoor: city cen-ter streets (track A), open city park (track B) anduniversity building (track C).
We selected thesethree types of location in order to analyze possi-ble differences in the dialog structure or types ofprovided information.The script of the experiment was similar foreach type of location.
The participant was given amobile phone with mobile navigation applicationfor blind called NaviTerier Vystrcil et al.
(2012).NaviTerier provides TTS synthesized descriptionof the predefined track divided into segments.
Foreach segment the description of the environmentand navigation to the next segment was tailoredwith respect to the way how blind people navi-gate.
Borders of segments are selected on placesthat could be easily recognizable by blind people(e.g.
corner of building, doors, etc.).
Each partici-pant had a goal to go from start point to the end ofthe track using the mobile navigation applicationfor blind.
In order to put the participant into the?recovery from lost?
situation, the navigation in-structions were intentionally modified to representa mistake in the track description (a realistic mis-take), which caused that the participant get lost.When the participant realized that he/she is lost,a navigator from assistance center was called andthey tried to find out the location of blind personand navigate him/her to the end of the track.Navigator was seated in an office without visualcontact to lost blind person.
He knew all threeroutes very well.
The only source of informationabout the lost blind person was dialog done by aphone call.3.3.1 Track A - City Center StreetsIn track A the participant was asked to navigateto the Vaclavska passage, see Figure 1.
The nav-igation instruction were changed so that the twostreets (Trojanova and Jenstejnska) were switchedso that the participant get lost at the T crossing ofJenstejnska and Vaclavska street.
The navigationusing the mobile navigation application for blindin this type of environment was easy for partici-pants and they all get lost at the desired location.The navigator and participant had several nav-igation points there to get oriented.
First of all,there was a nearby busy street Resslova, which canbe heard.
Next there was a closed gateway with59metal gate, which is quite unique for this location.There were also waste bins (containers), phonebooth and entrance to the underground garage.3.3.2 Track B - Open City ParkIn track B the participant was asked to navigatethrough the park to the restaurant, see Figure 1.The navigation instruction were changed so thatthe two junctions were skipped and the participantended near the middle of the park, where fountainis located.In this type of location, there were also notmany unique navigation points.
The most us-able were two perpendicular streets with trams, thefountain in the middle of the park and two uniquestairs.
There were also multiple benches and grassplots.3.3.3 Track C - BuildingIn track C the participant was asked to navigatethrough the building from the entrance to the yard,see Figure 1.
The navigation instructions werechanged so that instead of taking stairs down, theparticipant was asked to take stairs up and he/shegot lost in the small corridor, where the last doorsshould be located but they were not there.
Thenavigation using the NaviTerier application in thistype of environment was easy for the participantsand they all get lost at the desired location.At the place, where the participant got lost,there were several navigation points.
First pointwas showcase from metal and glass at the expectedlocation of doors to the yard.
Then there waswooden door secured with metal bars and woodenstairs going up and down.4 Results and DiscussionIn the track A and track C, the participants got lostat location very well known to the navigator, thusthe identification of lost blind person location wasmostly fast and easy.
In the track B, participantsgot sometimes lost at locations unfamiliar for thenavigator due to the ambiguity of the environmentand thus the location identification process wascomplicated.The dialog structure of the communication be-tween lost blind person and the navigator corre-sponds to the model introduced by Balata et al.(2013b).
At the beginning the blind person de-scribes his/her location, track instructions and theproblem description, i.e.
what is the difference be-tween instructions of navigation application andFigure 1: Visualization of individual tracks A, Band C used in the experiment.
The intended pathis shown by solid line.
Path shown by dashed lineshows the real path leading to the point, where theparticipant got lost ?
yellow exclamation mark ?and from where the participant was navigated backto the path.reality.
After the beginning the dialog continuesby iterative searching of unique navigation pointsthat may help the navigator to find the position andorientation of the lost blind person, until he/shegets to the location from which he/she can con-tinue with the track.
The dialog system shouldtake into account following findings about the di-alog structure.When the blind person get lost, he/she uses in-formation, provided by navigation application forsections that seemed to him/her correct and cor-responding with reality, for description of his/hercurrent position, e.g.
?I am in the Vaclavskastreet.?
The dialog system should take into ac-count uncertainty of information provided by lostblind person, possibility that the blind person gotlost much earlier and the navigation instructionsfor next several segments were corresponding withthe reality by coincidence.The fact that the blind person gets lost is lit-tle bit stressy for him/her.
Therefor he/she mayprovide illogical answers to some questions, e.g.60Q: ?Could you provide me with the description ofyour current position??
and A: ?I would rather goto the start of the track and describe the track fromthe beginning.
?Description of current position of blind personis very different from the description of sightedperson.
The dialog system should take into ac-count that the blind person may not find partic-ular navigation point, but it does not mean thatthe navigation point is not there.
Moreover, somenavigation points may be difficult or impossible tofind by blind person.
Similar issue is identifica-tion of particular navigation points.
The blind per-son may have difficulties to distinguish betweenbend, turning, intersection and end of pavement.This may be misleading to dialog system.
On theother hand, when the blind person confirms thatparticular navigation point was found, the systemshould check, if it is really the one, e.g.
whendoors are found, the system should check the ma-terial or type of the doors.Blind persons use other senses than sight to scanthe current position and navigation points.
Eventhough the senses are more sensitive, the providedinformation may not be accurate, e.g.
the blindperson is reporting inclining pavement and in real-ity there is flat pavement.It seems that the preferred sense is connectedwith the type of environment.
In the track B withlow density of navigation points which are am-biguous the blind persons preferred hearing.Some navigation points are not permanent andmay by varying.
E.g.
when there are two streets,one near (not busy) and one far (busy) and theblind person is asked to locate busy street, thisinformation will depend on the current traffic onboth streets.
Together with the fact that term busyis subjective, the blind person may locate wrongstreet.Some blind persons (the ones with high con-fidence of independency and orientation skills)tended to get oriented independently to the dialogwith navigator.
That means they provided the nav-igator with required information, but at the sametime they were moving and they were disruptingthe navigators mental model of the blind person?slocation.There is not a standardized vocabulary howblind persons describe objects.
Therefore theytend to use wide range of words and alsometaphoric descriptions to describe the same ob-ject.5 Conclusion and Future WorkIn this paper, we did initial analysis of dialogs be-tween blind person, who got lost when walking ona track with the instructions from mobile naviga-tion application, and navigator, who is trying tohelp him get oriented.
The research was done inthree different locations, in city center streets, inopen city park and in building.
The dialog be-tween blind person and navigator was recordedand qualitatively analyzed in order to reveal dialogfeatures which can be used for improvement of thenavigation itself and later it can help to replace thehuman navigator with automated system.Initial analysis showed that the type of locationmay have impact on strategy, how the blind per-son explore his/her surroundings and how he/shetries to get oriented.
In city center streets (trackA) and in building (track C) the blind personswere able to explore their surroundings and theyallowed the navigator to find out, where they prob-ably are.
In open city park (track B) the blindpersons had problem to find navigation points andsometimes they were trying to get oriented inde-pendently, which led to the difficulties for naviga-tor to find their position.
In many cases, the blindpersons were using the information from mobilenavigation application until the point where theygot lost.
Unfortunately, such information may al-ready be misleading.
As a general finding, the dia-log should focus also on verification of navigationpoints, which may not be permanent (e.g.
findingbusy street, when there are more streets around) orwhich may be not identified in not enough detail.In future, we would like to focus on individualaspects found in qualitative analysis and designstrategies into the dialog model between lost blindperson and navigator and evaluate it quantitatively.AcknowledgmentsThis research has been supported by the projectDesign of special user interfaces funded bygrant no.
SGS13/213/OHK3/3T/13 (FIS 161 ?832130C000).ReferencesJ.
Balata, J.
Franc, Z. Mikovec, and P. Slavik.
2013a.Collaborative navigation of visually impaired.
Jour-nal on Multimodal User Interfaces, pages 1?11.61J.
Balata, Z. Mikovec, and J. Novacek.
2013b.
Fieldstudy: How Blind People Communicate While Re-covering From Loss of Orientation.
In CognitiveInfocommunications (CogInfoCom), 2013 IEEE 4thInternational Conference on, pages 313?317, Bu-dapest.
IEEE Hungary Section, University Obuda.Filip Jurcicek.
2007.
Statistical approach to the se-mantic analysis of spoken dialogues.Yi Ma, Antoine Raux, Deepak Ramachandran, andRakesh Gupta.
2012.
Landmark-based location be-lief tracking in a spoken dialog system.
In Proceed-ings of the 13th Annual Meeting of the Special In-terest Group on Discourse and Dialogue, SIGDIAL?12, pages 169?178, Stroudsburg, PA, USA.
Associ-ation for Computational Linguistics.Johannes Pittermann.
2005.
Spoken dialogue tech-nology: Toward the conversational user interface bymichael f. mctear.
Comput.
Linguist., 31(3):403?406, September.Sebastian Thrun, Dieter Fox, Wolfram Burgard, andFrank Dellaert.
2001.
Robust monte carlo local-ization for mobile robots.
Artificial Intelligence,128(12):99 ?
141.Sebastian Thrun.
1998.
Bayesian landmark learningfor mobile robot localization.
Machine Learning,33(1):41?76.J.
Vystrcil, Z. Mikovec, and P. Slavik.
2012.
Naviterier?
indoor navigation system for visually impaired.
InSMART HOMES 2012, pages 25?28.
Czech Techni-cal University.62
