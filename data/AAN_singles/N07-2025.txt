Proceedings of NAACL HLT 2007, Companion Volume, pages 97?100,Rochester, NY, April 2007. c?2007 Association for Computational LinguisticsExploiting Rich Syntactic Information for RelationExtraction from Biomedical Articles?Yudong Liu and Zhongmin Shi and Anoop SarkarSchool of Computing ScienceSimon Fraser University{yudongl,zshi1,anoop}@cs.sfu.caAbstractThis paper proposes a ternary relationextraction method primarily based onrich syntactic information.
We identifyPROTEIN-ORGANISM-LOCATION re-lations in the text of biomedical articles.Different kernel functions are used withan SVM learner to integrate two sourcesof information from syntactic parse trees:(i) a large number of syntactic featuresthat have been shown useful for Seman-tic Role Labeling (SRL) and applied hereto the relation extraction task, and (ii) fea-tures from the entire parse tree using atree kernel.
Our experiments show that theuse of rich syntactic features significantlyoutperforms shallow word-based features.The best accuracy is obtained by combin-ing SRL features with tree kernels.1 IntroductionBiomedical functional relations (relations for short)state interactions among biomedical substances.
Forinstance, the PROTEIN-ORGANISM-LOCATION(POL) relation that we study in this paper providesinformation about where a PROTEIN is located inan ORGANISM, giving a valuable clue to the bi-ological function of the PROTEIN and helping toidentify suitable drug, vaccine and diagnostic tar-gets.
Fig.
1 illustrates possible locations of proteinsin Gram+ and Gram?
bacteria.
Previous work inbiomedical relation extraction task (Sekimizu et al,1998; Blaschke et al, 1999; Feldman et al, 2002)suggested the use of predicate-argument structure bytaking verbs as the center of the relation ?
in con-trast, in this paper we directly link protein named en-tities (NEs) to their locations; in other related work,(Claudio et al, 2006) proposed an approach that?This research was partially supported by NSERC, Canada.cytoplasm cytoplasmGram+ Gram-cytoplasmicmembranecell wallperiplasmoutermembrane secreted inner membraneFigure 1: Illustration of bacterial locationssolely considers the shallow semantic features ex-tracted from sentences.For relation extraction in the newswire domain,syntactic features have been used in a generativemodel (Miller et al, 2000) and in a discriminativelog-linear model (Kambhatla, 2004).
In comparison,we use a much larger set of syntactic features ex-tracted from parse trees, many of which have beenshown useful in SRL task.
Kernel-based methodshave also been used for relation extraction (Zelenkoet al, 2003; Culotta and Sorensen, 2004; Bunescuand Mooney, 2005) on various syntactic represen-tations, such as dependency trees or constituency-based parse trees.
In contrast, we explore a muchwider variety of syntactic features in this work.
Tobenefit from both views, a composite kernel (Zhanget al, 2006) integrates the flat features from enti-ties and structured features from parse trees.
In ourwork, we also combine a linear kernel with a treekernel for improved performance.2 SRL Features for Information ExtractionFig.
2 shows one example illustrating the ternary re-lation we are identifying.
In this example, ?Exoen-zyme S?
is a PROTEIN name, ?extracellular?
a LO-CATION name and ?Pseudomonas aeruginosa?
anORGANISM name.
Our task is to identify if thereexists a ?PROTEIN-ORGANISM-LOCATION?
re-lation among these three NEs.To simplify the problem, we first reduce the POL97SPROTEIN/NPPROTEIN/NNPExoenzymePROTEIN/NNP-HSVP-HVBZ-HisNPNP-HDTanLOCATION/JJextracellularNN-HproductPPIN-HofORGANISM/NPORGANISM/FWPseudomonasORGANISM/FW-HaeruginosaFigure 2: An example of POL ternary relation in a parse treeternary relation extraction problem into two binaryrelation extraction problems.
Specifically, we splitthe POL ternary relation into binary relations as: (1)PO: PROTEIN and ORGANISM, and (2) PL: PRO-TEIN and LOCATION.The ORGANISM-LOCATION relation is ignoredbecause it does not consider the PROTEIN and isless meaningful than the PO and PL relations.
Basedon this simplification, and following the idea ofSRL, we take the PROTEIN name in the role of thepredicate (verb) and the ORGANISM/LOCATIONname as its argument candidates in question.
Thenthe problem of identifying the binary relations of POand PL has been reduced to the problem of argu-ment classification problem given the predicate andthe argument candidates.
The reason we pick PRO-TEIN names as predicates is that we assume PRO-TEIN names play a more central role in linking thebinary relations to the final ternary relations.Compared to a corpus for the standard SRL task,there are some differences in this task: first is therelative position of PROTEIN names and ORGAN-ISM/LOCATION names.
Unlike the case in SRL,where arguments locate either before or after thepredicate, in this application it is possible that oneNE is embedded in another.
A second difference isthat a predicate in SRL scenario typically consists ofonly one word; here a PROTEIN name can containup to 8 words.We do not use PropBank data in our model at all.All of our training data and test data is annotated bydomain expert biologists and parsed by Charniak-Johnson?s parser (released in 2006).
When there isa misalignment between the NE and the constituentin the parse tree, we insert a new NP parent node forthe NE.3 System DescriptionFigure 3: High-level system architectureFig.
3 shows the system overview.
The input toour system consists of titles and abstracts that areextracted from MEDLINE records.
These extractedsentences have been annotated with the NE infor-mation (PROTEIN, ORGANISM and LOCATION).The Syntactic Annotator parses the sentences and in-serts the head information to the parse trees by usingthe Magerman/Collins head percolation rules.
Themain component of the system is our SRL-basedrelation extraction module, where we first manu-ally extract features along the path from the PRO-TEIN name to the ORGANISM/LOCATION nameand then train a binary SVM classifier for the binaryrelation extraction.
Finally, we fuse the extractedbinary relations into a ternary relation.
In contrastwith our discriminative model, a statistical parsingbased generative model (Shi et al, 2007) has beenproposed for a related task on this data set where theNEs and their relations are extracted together andused to identify which NEs are relevant in a particu-lar sentence.
Since our final goal is to facilitate thebiologists to generate the annotated corpus, in future98?
each word and its Part-of-Speech (POS) tag of PRO name?
head word (hw) and its POS of PRO name?
subcategorization that records the immediate structure thatexpands from PRO name.
Non-PRO daughters will be elim-inated?
POS of parent node of PRO name?
hw and its POS of the parent node of PRO name?
each word and its POS of ORG name (in the case of ?PO ?relation extraction).?
hw and its POS of ORG name?
POS of parent node of ORG name?
hw and its POS of the parent node of ORG name?
POS of the word immediately before/after ORG name?
punctuation immediately before/after ORG name?
feature combinations: hw of PRO name hw of ORG name,hw of PRO name POS of hw of ORG name, POS of hw ofPRO name POS of hw of ORG name?
path from PRO name to ORG name and the length of thepath?
trigrams of the path.
We consider up to 9 trigrams?
lowest common ancestor node of PRO name and ORGname along the path?
LCA (Lowest Common Ancestor) path that is from ORGname to its lowest common ancestor with PRO name?
relative position of PRO name and ORG name.
In parsetrees, we consider 4 types of positions that ORGs are relativeto PROs: before, after, inside, otherTable 1: Features adopted from the SRL task.
PRO:PROTEIN; ORG: ORGANISMwork we plan to take the relevant labeled NEs fromthe generative model as our input.Table 1 and Table 2 list the features that are usedin the system.4 Experiments and Evaluation4.1 Data setOur experimental data set is derived from a smallexpert-curated corpus, where the POL relations andrelevant PROTEIN, ORGANISM and LOCATIONNEs are labeled.
It contains ?150k words, 565 rela-tion instances for POL, 371 for PO and 431 for PL.4.2 Systems and Experimental ResultsWe built several models to compare the relative util-ity of various types of rich syntactic features thatwe can exploit for this task.
For various represen-tations, such as feature vectors, trees and their com-binations, we applied different kernels in a SupportVector Machine (SVM) learner.
We use Joachims??
subcategorization that records the immediate structure thatexpands from ORG name.
Non-ORG daughters will be elim-inated?
if there is an VP node along the path as ancestor of ORGname?
if there is an VP node as sibling of ORG name?
path from PRO name to LCA and the path length (L1)?
path from ORG name to LCA and the path length (L2)?
combination of L1 and L2?
sibling relation of PRO and ORG?
distance between PRO name and ORG name in the sen-tence.
( 3 valued: 0 if nw (number of words) = 0; 1 if 0 <nw <= 5; 2 if nw > 5)?
combination of distance and sibling relationTable 2: New features used in the SRL-based rela-tion extraction system.SVM light1 with default linear kernel to feature vec-tors and Moschetti?s SVM-light-TK-1.22 with thedefault tree kernel.
The models are:Baseline1 is a purely word-based system, wherethe features consist of the unigrams and bigramsbetween the PROTEIN name and the ORGAN-ISM/LOCATION names inclusively, where the stop-words are selectively eliminated.Baseline2 is a naive approach that assumes that anyexample containing PROTEIN, LOCATION nameshas the PL relation.
The same assumption is madefor PO and POL relations.PAK system uses predicate-argument structure ker-nel (PAK) based method.
PAKwas defined in (Mos-chitti, 2004) and only considers the path from thepredicate to the target argument, which in our set-ting is the path from the PROTEIN to the ORGAN-ISM or LOCATION names.SRL is an SRL system which is adapted to use ournew feature set.
A default linear kernel is appliedwith SVM learning.TRK system is similar to PAK system except thatthe input is an entire parse tree instead of a PAKpath.TRK+SRL combines full parse trees and manuallyextracted features and uses the kernel combination.1http://svmlight.joachims.org/2http://ai-nlp.info.uniroma2.it/moschitti/TK1.2-software/Tree-Kernel.htm99Method PL PO POLMeasure Prec Rec F Acc Prec Rec F Acc Prec Rec F AccBaseline1 98.1 61.0 75.3 60.6 88.4 59.7 71.3 58.5 57.1 90.9 70.1 56.3Baseline2 61.9 100.0 76.5 61.9 48.8 100.0 65.6 48.9 59.8 100.0 74.8 59.8PAK 71.0 71.0 71.0 64.6 69.0 66.7 67.8 61.8 66.0 69.9 67.9 62.6SRL 72.9 77.1 74.9 70.3 66.0 71.0 68.4 64.5 70.6 67.5 69.0 65.8TRK 69.8 81.6 75.3 72.0 64.2 84.1 72.8 72.0 79.6 66.2 72.3 71.3TRK+SRL 74.9 79.4 77.1 72.8 73.9 78.1 75.9 72.6 75.3 74.5 74.9 71.8Table 3: Percent scores of Precision/Recall/F-score/Accuracy for identifying PL, PO and POL relations.4.3 Fusion of Binary relationsWe predict the POL ternary relation by fusing PLand PO binary relations if they belong to the samesentence and have the same PROTEIN NE.
The pre-diction is made by the sum of confidence scores(produced by the SVM) of the PL and PO relations.This is similar to the postprocessing step in SRL taskin which the semantic roles assigned to the argu-ments have to realize a legal final semantic framefor the given predicate.4.4 DiscussionTable 3 shows the results using 5-fold cross valida-tion.
We report figures on ternary relation extractionand extraction of the two binary relations.
Compari-son between the PAK model and SRL model showsthat manually specified features are more discrimi-native for binary relation extraction; they boost pre-cision and accuracy for ternary relation extraction.In contrast to the SRL model for binary relation ex-traction, the TRK model obtains lower recall buthigher precision.
The combination of SRL with theTRK system gives best overall accuracy of 71.8%outperforming shallow word based features.5 ConclusionIn this paper we explored the use of rich syntac-tic features for the relation extraction task.
In con-trast with the previously used set of syntactic fea-tures for this task, we use a large number of fea-tures originally proposed for the Semantic Role La-beling task.
We provide comprehensive experimentsusing many different models that use features fromparse trees.
Using rich syntactic features by com-bining SRL features with tree kernels over the en-tire tree obtains 71.8% accuracy which significantlyoutperforms shallow word-based features which ob-tains 56.3% accuracy.ReferencesC.
Blaschke, M. Andrade, C. Ouzounis, and A. Valencia.
1999.Automatic extraction of biological information from scien-tific text: Protein-protein interactions.
In AAAI-ISMB 1999.R.
C. Bunescu and R. J. Mooney.
2005.
A shortest path depen-dency kernel for relation extraction.
In Proc.
HLT/EMNLP-2005.G.
Claudio, A. Lavelli, and L. Romano.
2006.
ExploitingShallow Linguistic Information for Relation Extraction fromBiomedical Literature.
In Proc.
EACL 2006.A.
Culotta and J. Sorensen.
2004.
Dependency tree kernels forrelation extraction.
In Proc.
ACL-2004.R.
Feldman, Y. Regev, M. Finkelstein-Landau, E. Hurvitz, andB.
Kogan.
2002.
Mining biomedical literature using infor-mation extraction.
Current Drug Discovery.N.
Kambhatla.
2004.
Combining lexical, syntactic, and seman-tic features with maximum entropy models for informationextraction.
In Proc.
ACL-2004 (poster session).S.
Miller, H. Fox, L. Ramshaw, and R. Weischedel.
2000.
Anovel use of statistical parsing to extract information fromtext.
Proc.
NAACL-2000.A.
Moschitti.
2004.
A study on convolution kernels for shallowsemantic parsing.
In Proc.
ACL-2004.T.
Sekimizu, H.S.
Park, and J. Tsujii.
1998.
Identifying theinteraction between genes and gene products based on fre-quently seen verbs in medline abstracts.
In Genome Infor-matics.
62-71.Z.
Shi, A. Sarkar, and F. Popowich.
2007.
Simultaneous Iden-tification of Biomedical Named-Entity and Functional Re-lation UsingStatistical Parsing Techniques.
In NAACL-HLT2007 (short paper).D.
Zelenko, C. Aone, and A. Richardella.
2003.
Kernel meth-ods for relation extraction.
Journal of Machine LearningResearch.M.
Zhang, J. Zhang, J. Su, and G.D. Zhou.
2006.
A CompositeKernel to Extract Relations between Entities with Both Flatand Structured Features.
In Proc.
ACL-2006.100
