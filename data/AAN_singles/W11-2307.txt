Proceedings of the 2nd Workshop on Speech and Language Processing for Assistive Technologies, pages 63?72,Edinburgh, Scotland, UK, July 30, 2011. c?2011 Association for Computational LinguisticsIndian Language Screen Readers and Syllable Based Festival Text-to-SpeechSynthesis SystemAnila Susan Kurian, Badri Narayan, Nagarajan Madasamy, Ashwin Bellur,Raghava Krishnan, Kasthuri G., Vinodh M.V., Hema A. MurthyIIT-Madras, India{anila,badri,nagarajan,ashwin,raghav,kasthuri,vinodh}@lantana.tenet.res.inhema@cse.iitm.ac.inKishore PrahalladIIIT-Hyderabad, Indiakishore@iiit.ac.inAbstractThis paper describes the integration of com-monly used screen readers, namely, NVDA[NVDA 2011] and ORCA [ORCA 2011] withText to Speech (TTS) systems for Indian lan-guages.
A participatory design approach wasfollowed in the development of the integratedsystem to ensure that the expectations of vi-sually challenged people are met.
Given thatIndia is a multilingual country (22 official lan-guages), a uniform framework for an inte-grated text-to-speech synthesis systems withscreen readers across six Indian languages aredeveloped, which can be easily extended toother languages as well.
Since Indian lan-guages are syllable centred, syllable-basedconcatenative speech synthesizers are built.This paper describes the development andevaluation of syllable-based Indian lan-guage Text-To-Speech (TTS) synthesis sys-tem (around festival TTS) with ORCA andNVDA, for Linux and Windows environmentsrespectively.
TTS systems for six Indian Lan-guages, namely, Hindi, Tamil, Marathi, Ben-gali, Malayalam and Telugu were built.
Us-ability studies of the screen readers were per-formed.
The system usability was evaluatedby a group of visually challenged people basedon a questionnaire provided to them.
Anda Mean Opinion Score(MoS) of 62.27% wasachieved.1 IntroductionIndia is home to the world?s largest number of vi-sually challenged (VC) population [Chetna India2010].
No longer do VC persons need to dependon others to access common information that oth-ers take for granted, such as newspapers, bank state-ments, and scholastic transcripts.
Assistive tech-nologies (AT), enable physically challenged personsto become part of the mainstream in the society.A screen reader is an assistive technology poten-tially useful to people who are visually challenged,visually impaired, illiterate or learning disabled,to use/access standard computer software, such asWord Processors, Spreadsheets, Email and the Inter-net.Over the last three years, Indian Institute of Tech-nology, Madras (IIT Madras) [Training for VC,IITM 2008 ], has been conducting a training pro-gramme for visually challenged people, to enablethem to use the computer using a screen reader.
Thescreen reader used was JAWS [JAWS 2011], withEnglish as the language.
Although, the VC personshave benefited from this programme, most of themfelt that:?
The English accent was difficult to understand.?
Most students would have preferred a reader intheir native language.?
They would prefer English spoken in Indian ac-cent.?
The price for the individual purchase of JAWSwas very high.Although some Indian languages have been incor-porated with screen readers like JAWS and NVDA,no concerted effort has been made to test the efficacy63of the screen readers.
Some screen readers, read In-dian languages using a non native phone set [acharya2007].
The candidates were forced to learn by-heartthe sounds and their correspondence to Indian lan-guages.
It has therefore been a dream for VC peo-ple to have screen readers that read using the nativetongue using a keyboard of their choice.Given this feedback and the large VC popula-tion (?
15%) (amongst 6% physically challenged)in India, a consortium consisting of five institutionswere formed to work on building TTS for six In-dian languages namely Hindi, Telugu, Tamil, Ben-gali, Marathi and Malayalam.
This led to the de-velopment of screen readers that support Indian lan-guages, one that can be made freely available to thecommunity.This paper is organized as follows.
Section 2 ex-plains the selection of a speech engine, details ofspeech corpus, selection of screen readers and thetyping tools for Indian languages.
Section 3 dis-cusses the integration of screen readers with Indianlanguage festival TTS voices.
Although the integra-tion is quite easy, a number of issues had to be ad-dressed to make the screen reader user-friendly.
Todo this, a participatory design [Participatory DesignConference 2011], approach was followed in the de-velopment of the system.
Section 4 summarises theparticipation of the user community in the design ofthe system.
To evaluate the TTS system, differenttests over and above the conventional MOS [ITU-TRec, P.85 1994], [ITU-T Rec, P.800 1996] were per-formed.
Section 4 also describes different quality at-tributes that were used in the design of the tests.
Sec-tion 5 provides the results of the System UsabilityTest.
Section 6 provides details of the MOS evalu-ation conducted for the visually challenged commu-nity.
Section 7 describes the future work and Section8 concludes the paper.2 Primary components in the proposedTTS framework2.1 Selection of Speech EngineOne of the most widely used speech engine is eS-peak [espeak speech synthesis2011].
eSpeak uses?formant synthesis?
method, which allows manylanguages to be provided with a small footprint.The speech synthesized is intelligible, and providesquick responses, but lacks naturalness.
As discussedin Section 1 the demand is for a high quality naturalsounding TTS system.We have used festival speech synthesis system de-veloped at The Centre for Speech Technology Re-search, University of Edinburgh, which provides aframework for building speech synthesis systemsand offers full text to speech support through a num-ber of APIs [Festival 1998].
A large corpus basedunit selection paradigm has been employed.
Thisparadigm is known to produce [Kishore and Black2003], [Rao et al 2005] intelligible natural sound-ing speech output, but has a larger foot print.2.2 Details of Speech CorpusAs part of the consortium project, we recorded aspeech corpus of about 10 hours per language, whichwas used to develop TTS systems for the selected sixIndian languages.
The speech corpus was recordedin a noise free studio environment, rendered by aprofessional speaker.
The sentences and words thatwere used for recording were optimized to achievemaximal syllable coverage.
Table 1 shows the sylla-ble coverage attained by the recorded speech corpusfor different languages.
The syllable level databaseunits that will be used for concatenative synthesis,are stored in the form of indexed files, under the fes-tival framework.Language Hours No.Syll CoveredMalayalam 13 6543Marathi 14 8136Hindi 9 7963Tamil 9 6807Telugu 34 2770Bengali 14 4374Table 1: Syllable coverage for six languages.2.3 Selection of Screen ReadersThe role of a screen reader is to identify and inter-pret what is being displayed on the screen and trans-fer it to the speech engine for synthesis.
JAWS isthe most popular screen reader used worldwide forMicrosoft Windows based systems.
But the maindrawback of this software is its high cost, approx-imately 1300 USD, whereas the average per capita64income in India is 1045 USD [per capita Income ofIndia 2011]Different open source screen readers are freelyavailable.
We chose ORCA for Linux based systemsand NVDA for Windows based systems.
ORCA isa flexible screen reader that provides access to thegraphical desktop via user-customizable combina-tions of speech, braille and magnification.
ORCAsupports the Festival GNOME speech synthesizerand comes bundled with popular Linux distibutionslike Ubuntu and Fedora.NVDA is a free screen reader which enables vi-sion impaired people to access computers runningWindows.
NVDA is popular among the membersof the AccessIndia community.
AccessIndia is amailing list which provides an opportunity for vi-sually impaired computer users in India to exchangeinformation as well as conduct discussions relatedto assistive technology and other accessibility issues[Access India 2011].
NVDA has already been inter-gated with Festival speech Engine by Olga Yakovl-eva [NVDA 2011]2.4 Selection of typing tool for IndianLanguagesThe typing tools map the qwerty keyboard to In-dian language characters.
Widely used tools to inputdata in Indian languages are Smart Common InputMethod(SCIM) [SCIM Input method 2009] and in-built InScript keyboard, for Linux and Windows sys-tems respectively.
Same has been used for our TTSsystems, as well.3 Integration of Festival TTS with ScreenreadersORCA and NVDA were integrated with six Indianlanguage Festival TTS systems.
Preliminary adapta-tions to the system for Indian languages are as fol-lows.?
Though syllable based systems produce goodquality speech output for syllabic Indian lan-guages, syllables being larger units, require alarge speech corpus to maximize syllable cov-erage.
This means a larger footprint.?
In the paradigm being used, text processingmodules are required to provide the syllableFigure 1: Mapping of vowel modifiersor phoneme sequence for the word to be syn-thesized.
With input text for Indian languagesbeing UTF-8 encoded, Indian language festi-val TTS systems have to be modified to ac-cept UTF-8 input.
A module was included infestival to parse the input text and give the ap-propriate syllable sequence.
With grapheme tophoneme conversion being non-trivial, a set ofgrapheme to phoneme rules were included aspart of the module.?
Indian languages have a special representationfor vowel modifiers, which do not have a soundunit as opposed to that in Latin script lan-guages.
Hence, to deal with such characterswhile typing, they were mapped to sound unitsof their corresponding full vowels.
An examplein Hindi is shown in Figure 1.To enable the newly built voice to be listed inthe list of festival voices under ORCA preferencesmenu, it has to be proclaimed as UTF-8 encodingin the lexicon scheme file of the voice [Nepali TTS2008].To integrate festival UTF-8 voice with NVDA,the existing driver, Festival synthDriver for NVDAby Olga Yakovleva was used [NVDA festival driver2008].
To implement the rules for syllabifying In-dian language text, a new C module was added tofestival.
Hence, festival [Festival compilation inWindows 2011] and synthDriver had to be recom-piled [Compilation of NVDA Synthdriver 2011], forthe new voice to be completely integrated with fes-tival and usable under NVDA.4 Participatory designThe design of the TTS system was arrived at, by ac-tive participation of visually challenged people, who65Figure 2: Flow of Development processare the end users of the system.
An educationallyqualified visually challenged person was employedto test the integrated TTS system.
The person iswell versed in using JAWS screen reader on Win-dows.
The quality attributes tested, were irrespectiveof languages.
Hence, as a study, these tests were ex-clusively conducted on Tamil festival voice for bothNVDA and ORCA.When a new version of the system was released,it was provided to the in-house tester for evaluation.The suggestions and issues reported were then in-corporated in the next release of the system.
Thisprocess was done on an iterative basis.
This helpedin enhancing the system to meet the expectationsof visually challenged people.
Finally, the overallsystem performance was evaluated by conducting aMean Opinion Score(MOS) test by visually chal-lenged people, which is explained in detail in Sec-tions 6.
Figure 2 describes this development pro-cess.The various quality attributes tested for, are :?
Usability of the TTS system?
Adaptability of users to the new system?
Navigation through desktop and webpages?
Availability of the TTS system?
Performance of the TTS system?
Loading of voices?
Response time for typing and reading4.1 Usability of the TTS system?
Adaptability of users to the new systemAs the common screenreader used among thevisually challenged community is JAWS, astudy was conducted to find out the ease ofadaptability for the user to the new system.Since the front end for the system are screenreaders, the parameter used in this testing wasprimarily the learning involved in switchingfrom JAWS to ORCA or NVDA.
As JAWS andNVDA are Windows based screen readers, allthe keystokes and shortcut keys are the same.A computer literate who has used JAWS, willlearn NVDA quicker than others.
As ORCAis a Linux based screen reader, the shortcutkeys, key strokes and navigation through thesystem are different compared to that of JAWS.It takes more time for a JAWS user to famil-iarize with the Linux operating system, ORCAsettings and keystokes.?
Navigation of desktop and web pages usingthe screen readerWhen default English locale is selected forWindows and Linux systems, all the programmenus and navigational keys are in English.The initial version of the TTS system was notable to parse these English words.
As a solu-tion, switching of voices between English andthe selected Indian language was tried.
Thesystem was made to switch between Festival?sEnglish Kal diphone voice and one of the In-dian language voices.
When an English wordis given as input, the English voice would beloaded and when an Indian language word isgiven as input, it switches to the respective In-dian language, loads the voice and speaks theword.
This frequent switching of voices de-graded the performance of the system and hear-ing two different voices, without continuity wasannoying to the listener.
This led to the devel-opment of a bilingual voice.Bilingual Voice: Each Indian language voice isprovided with an English pronunciation dictio-66nary, so that when an English word is providedto the system, speech is synthesized using theIndian language voice itself.
Following are theenhancements made to better the TTS system.?
Pronunciation Dictionary for Englishwords in native sound unitsThe English dictionary from CarnegieMellon University(CMU) with phone pro-nunciation was used to create Englishto Native language pronounciation dictio-nary.
An entry in the CMU dictionary :(?abolish?
ax b aa l ih sh).
These Englishphones were mapped to phones in nativelanguage.
An example mapping from En-glish to Hindi language :ax=a , b=b^ , aa=aA, l=l^ , ih=i , sh=?^.For all the English words in the dictio-nary, the native language representationwas created, abolish = abAEl?^.
Thepronunciation dictionary was then createdby breaking these words down into sylla-bles and phone sequences present in thedatabase.
(?abolish?a bA El?^)All such English words that are requiredto navigate through a desktop(includingspecial keys) and web, were collected andadded to the pronunciation dictionary.
Thedrawback of this method is that if an En-glish word which is not present in the pro-nunciation dictionary, is provided as input,the TTS system cannot synthesize it.
Inorder to overcome this, English Letter ToSound (LTS) rules were implemented.?
Implementation of English LTS RulesInputs can be in English or the native lan-guage.
In the case of a word being ab-sent in the pronunciation dictionary, LTSrules should supplement.
LTS rules havebeen developed for English in festival us-ing a pronunciation dictionary of around100000 words as the training set [Blacket al 1998].
These LTS rules generate asequence of phones for the English word.By mapping the English phones to phonesin the native language, one can provide aFigure 3: CART for letter dphone sequence in terms of the Indian lan-guage, for an English word.
For exam-ple, a part of the Classification and Re-gression Tree(CART) for letter ?d?
in aword, by looking at the context in whichit is occuring is shown in Figure 3.
Thefirst part of the figure is a partial tree inEnglish.
The second part of the figure isthe corresponding entry for the Indian lan-guage.
If ?d?
is followed by another ?d?, nosound(?epsilon;) is assigned.
If it is fol-lowed by ?i?
and ?r?
?phone d?
is assignedfor English, whereas ?phone d?
is mappedto X for Hindi language.?
Recording of Common English wordsMost of the English words when spokenin the Indian language voice did not soundintelligible enough.
This is because, manyEnglish sounds were not available in In-dian languages.
Hence frequently seenEnglish words while navigating a Win-dows/Linux desktop were recorded.
In-stead of concatenating Indian phones tosynthesize the English word, the naturallyuttered English word is spoken.
This in-creased the usability of the system.4.2 Availability of the TTS systemThe system was tested to check if it responded toeach and every input provided to it.
Words, sen-67tences and paragraphs were provided as input tothe system using commonly used applications likenotepad, word processor and browser.
The systemwas able to read the words whose syllables werepresent in the database.
The testing was done ex-tensively for each language which resulted in somewords not being spoken, which helped in the identi-fication of those syllables which need to be includedin the database.
Some of the major issues identifiedduring this test were:?
Issues during typingThe evaluator tested the system by typing us-ing SCIM in Linux systems and the inbuilt In-Script keyboard in Windows systems.
As it isunit selection based synthesis, the sound unitsfor the corresponding characters that are pickedup from the database may not be clear or audi-ble.
Also, the prosody of these individual char-acters, when taken from different contexts willvary.
While typing, flat and prosodically neu-tral sounds are preffered.
This led to recordingof all aksharas (alphabets) in all six languages,in a prosodically neutral flat tone.
It was alsoobserved that the system was not reading vowelmodifiers.
This issue was solved by adding en-tries for vowel modifiers in the pronunciationdictionary.
The vowel modifiers were mappedto the corresponding vowel pronunciation.?
Issues during reading web pagesThe system was tested for reading content fromweb pages.
It was found that when a linewith any special character(for example <,>,?
)is given as input, the system would fail to readthe entire line.
This led to the handling of spe-cial characters in the Indian language voice.
Ifanything outside the unicode range of the lan-guage is provided to the system, it is ignored.In this way, even if some special or junk char-acters are present in a line, the system will readthe whole line ignoring these characters.4.3 Performance of the TTS systemThe evaluator noted the response time of the systemwhile loading the voice, typing, navigation throughdesktop and web pages.?
Loading of voicesIn the unit selection paradigm, we have a largerepository of multiple realizations of a unit(syllables) in different contexts.
The text to bespoken is broken down into these units.
Sylla-ble speech units are then indexed with their lin-guistic and phonetic features using clusteringtechniques (CART) to capture the context inwhich they are uttered.
With many realizationsof the same syllable being present, CART areused to select a smaller set of candidate unitsfor the syllable to be spoken.
These CART builtas part of the voice building process, attempt topredict the acoustic properties of the unit usingits phonetic and linguistic features at the timeof synthesis [Black and Taylor 1997].When the festival engine loads a voice, al-though the speech waveforms are saved on thehard disk, the CART gets loaded into the heapmemory.
As the size of this tree file exceedsthe default heap size set in the festival frame-work, the initial version of the Indian languageTTS voices failed to load.
Hence, a larger heapsize was provided as a runtime argument for thefestival synthesizer.?
Response time for typing and readingThe user expects the system to respond in areasonable amount of time (approx 125 mil-liseconds).
For the initial system, the responsetime for a sentence with 5 to 10 words was 1to 2 seconds.
To improve the response timeof the system, the voice(s) had to be pruned.In the case of unit selection paradigm, a largedatabase with multiple realizations is used toproduce natural speech.
Around 300000 unitswith multiple realizations of syllables includingthe ?silence?
unit are present in the database.
Inthe cluster unit framework [Black and Taylor1997], these syllables are clustered into simi-lar sounding groups and form the leaves of theCART built.
This resulted in a large CART filewhich in turn slowed down the system.With around 300000 realizations of syllablesbeing present, it is seen that there are far toomany realizations of frequently occuring syl-lables.
So it was vital to prune the CART68built.
To effectively capture prosody for syl-lables, after experimenting heuristically withvarious cluster sizes, a leaf size of eight wasused, i.e syllables are clustered into groups ofeight.
To prune the tree using the tools avail-able within festival [Black and Lenzo 2000],within each cluster only two units closest tothe centroid were retained and the rest were re-moved, hence reducing the tree size.
Even afterpruning the voice, it was seen that there werestill a very large number (around 20000) of si-lence units, which are used to annotate phraseand sentence boundaries, in the speech corpus.It was seen that the silence units could be quan-tized into two units, one to denote end of phraseand another for end of sentence, without affect-ing the performance.
Hence silence trees wereremoved from the CART retaining just the twoquantized units, further pruning the tree andimproving the speed.
After pruning, the size ofthe tree for Tamil language was reduced froman 8 MB file to 1.7 MB file.
The response timefor sentences having word rate between 5 to10 for the pruned system was 200millisecondsto 900 milliseconds.
On an average there was61% improvement in the response time.5 System Usability RatingFor comparing the overall usability of the TTS sys-tem, before and after carrying out all the modifica-tions listed in Section 4, a Usability test was con-ducted using screen readers by a group of visuallychallenged people.
The System Usability Scale de-veloped by John Brooke [Brooke 1996], which usesthe Likert scale for providing a global view of sub-jective assessments of usability was used.
The eval-uators were provided with a questionnaire for whichthey have to provide Likert scale ratings.
Table 2shows the Likert scale used for the evaluation.Questionnaire used for evaluation.1.
I found the system easy to use.2.
I need the support of a technical/non visuallychallenged person to be able to use the system.3.
I am able to navigate through Desktop and in-ternet using the system without any help.Scores Scales5 Strongly agree4 Agree3 Neither agree nor disagree2 Disagree1 Strongly disagreeTable 2: Likert Scales.4.
System is not able to clearly read each and ev-ery character I type.5.
Availability of the system is more than 90%.i.e.
the system provides appropriate responseto more than 90% of the input given to it.6.
Response time of the system is good and iswithin my tolerable limits.7.
I feel that most of the visually challenged peo-ple, having basic knowledge on computers, canlearn this system quickly.8.
The system is not natural sounding.9.
The overall understanding/comprehensibilityof the content read out by the system is high.10.
The system is very useful for the VC commu-nity.The rating of the system was calculated as fol-lows [Brooke 1996].
First, the score contributionsfrom each item were summed up.
Each item?s scorecontribution will range from 0 to 4.
The score con-tribution for positive questions 1,3,5,6,7,9 and 10 isthe scale position minus 1.
The score contributionfor negative questions 2,4 and 8 is 5 minus the scaleposition.
Multiply the sum of the scores by 2.5 to ob-tain the overall value of System Usability out of 100.A group of visually challenged people evaluated theinitial and final system based on the questionnaire.The average System Usability score for the initialsystem was 35.63 and that of the final system was89.38.
Thus an improvement of around 50% in Sys-tem Usability scores were seen due to the changesmade in Section 4.696 MOS EvaluationMOS( [ITU-T Rec, P.85 1994], [ITU-T Rec, P.8001996]) and Degradation MOS (DMOS) tests wereconducted for six Indian languages, across variouscenters in India.
Synthesized speech files wereplayed to the evaluators.
Sentences belonging to dif-ferent domains were chosen for quality evaluation,in order to test the performance of TTS system(s)upon receiving input text from varied domains.The various factors that were considered, whileadministering the quality evaluation tests were:?
The MOS evaluators were chosen, such thatthey should not have participated in any listen-ing quality test for synthetic speech, at least forthe last 6 months and are well versed with thelanguage.?
The tests were done up to a maximum of 30-40minutes, in order to avoid listener fatigue.?
A reasonable number of MOS evaluators (aminimum of 20) were involved for evaluatingthe quality.?
The tests were conducted in a quiet room andthe content to be evaluated was played througha good quality speaker.?
For MOS tests, the sentences belonging to vari-ous domains were grouped into various sets andthe order of these sets were randomized in or-der to avoid any learning effects.?
Randomized sentences were played one afterthe other, with a brief pause for listeners to pro-vide the quality score, based on the scales pro-vided in Table 3.?
In the case of DMOS tests, a natural sen-tence followed by its synthesized counterpart isplayed after a brief pause and the listeners haveto rate the amount of degradation in the synthe-sized sentence, relative to the natural sentence.This rating is based on the scales provided inTable 3.?
DMOS tests were conducted first, so that theparticipants get a feeling of how natural andsynthesized sentences sound.Figure 4: Active discussion among Visually Challengedcandidates, during a training session?
40 sentences were used to conduct the MOStest and 10 sentences for DMOS test.The MOS and DMOS scores for the six Indianlanguages are provided in Table 4.
Overall compre-hension was also considered important, as the pri-mary goal or aim of the TTS system was to be ableto communicate information to the user.
Thus, a pre-liminary comprehension based MOS test was con-ducted, which involved playing out a paragraph tothe MOS evaluators and testing their level of com-prehension.Scores Quality scalesMOS DMOS5 Excellent Imperceptible4 Good Perceptible butnot annoying3 Fair Slightly annoying2 Poor Annoying1 Bad Very annoyingTable 3: MOS and DMOS Scales.7 Future WorkAs a second phase of the project, we plan to carryout the following tasks?
To improve the prosody of synthetic speech.?
Enable the system to synthesize emotionalspeech.70Language No.
of MosevaluatorsNews Natural Sports InDomain Science DMOS OverallMOSHindi 40 2.64 4.48 - 2.63 2.99 2.9 2.75Bengali 8 3.31 - 2.91 3.18 2.85 3.14 3.06Marathi 26 - 4.73 3.25 3.03 3.03 3.06 3.1Telugu 23 - 4.66 2.46 2.89 2.83 3.68 2.73Malayalam 27 3.95 4.13 3.73 3.77 - 3.91 3.82Tamil 22 3.13 - - 3.54 3.2 2.81 3.22Table 4: Mos scores for six Indian languages.?
Build a small footprint TTS system, so that itcan be used in applications for mobile, PDA,ATM etc.?
Evaluate the TTS system by conducting objec-tive tests for intelligibility and naturalness, us-ing different measures including the Semanti-cally Unpredictable Sentence (SUS) test.?
To extend this effort to other Indian languages.?
To develop full-fledged Bilingual voices.
In thecurrent system we use the Indian language cor-pus to synthesize English words.
The completebilingual voice would have an English corpusrecorded in the same voice as the Indian lan-guage, so that the same speech quality can beprovided to both English and Indian languageinput.8 ConclusionIn this paper, we have briefly discussed the effortstaken towards integrating TTS systems in six Indianlanguages, with screen readers ORCA and NVDA.We have also described the issues that were facedwhile testing the system and the solutions to improvethe system.
Further, results of the subjective listen-ing tests (MOS and DMOS evaluation) and SystemUsability tests conducted were discussed.With the completion of this project, training pro-gramme in IIT Madras, can be conducted for vi-sually challenged community, using screen readersNVDA and ORCA for Indian Languages, instead ofJAWS.
Figure 4 shows an active discussion amongvisually challenged candidates during the computertraining using screen readers at IIT Madras.9 AcknowledgementThe authors would like to acknowledge the contri-butions of the Consortium members, namely IIIThyderabad, IIT Kharagpur, CDAC Thiruvanantha-puram and CDAC Mumbai, towards the project.This project has been supported by the Depart-ment of Information Technology, India.
(Projectnumber - CSE0809107DITXHEMA).ReferencesS.P.
Kishore and A.W.
Black 2003.Unit size in unit selection speech synthesis, proceed-ings of EUROSPEECH, pp.
1317-1320, 2003A.W.
Black and P. Taylor 1997Automatically clustering similar units for unit se-lection in speech synthesis Eurospeech97 (Rhodes,Greece, 1997), vol.
2, pp.
601-604M.
Nageshwara Rao,S.
Thomas, T. Nagarajan and HemaA.
Murthy 2005Text-to-speech synthesis using syllable like units, pro-ceedings of National Conference on Communication(NCC) 2005, pp.
227-280, IIT Kharagpur, India, Jan2005.ITU-T Rec, P.85 1997Method for Subjective Performance Assessment of theQuality of Speech Voice Output Devices, ITU-T Rec,P.85, 1994, Int.
Telecom.
UnionITU-T Rec, P.800 1996Methods for subjective determination of transmissionquality, ITU-T Rec, P.800, 1996, Int.
Telecom.
UnionA.
Black and K. Lenzo 2000 Building voices in the Fes-tival speech synthesis systemhttp://festvox.org/bsv/A.
Black, P. Taylor, and R. Caley 1998 The Festivalspeech synthesis systemhttp://festvox.org/festival71Festival Speech Synthesis Systemhttp://www.cstr.ed.ac.uk/projects/festival/ORCA Screen reader.http://live.gnome.org/OrcaNVDA Screen reader.http://www.nvda-project.org/Festival synthDriver for NVDA by Olga Yakovleva:http://www.box.net/shared/jcnnzz7xu6SCIM Input method.http://apps.sourceforge.net/mediawiki/scim/index.phphttps://help.Ubuntu.com/community/SCIMFestival compilation in Windows.http://www.eguidedog.net/doc_build_win_festival.phpParticipatory Design Conferencehttp://www.publicsphereproject.org/drupal/node/235J.
Brooke 1996 ?SUS: a ?quick and dirty?
usabilityscale?.
In P. W. Jordan, B. Thomas, B.
A. Weerd-meester, A. L. McClelland.
Usability Evaluation inIndustry.http://hell.meiert.org/core/pdf/sus.pdfNepali TTS User Manual.
2008.http://www.bhashasanchar.org/textspeech_intro.phpJAWS Screen reader.http://www.freedomscientific.com/jaws-hq.aspespeak speech synthesishttp://espeak.sourceforge.net/Training for Visually Challenged by IIT Madrashttp://www.lantana.tenet.res.in/TTSconsortiumWiki/doku.php?id=start/Acharya Multilingual Computing for literacy and educa-tionhttp://acharya.iitm.ac.in/ Last updatedon 2007-03-19Chetna Indiahttp://chetnaindia.org/our_values.htmPer capita Income of India, 2011http://www.financialexpress.com/news/Per-capita-income-in-India-is-Rs-46-492/744155/Access India mailing listhttp://accessindia.org.in/mailman/listinfo/accessindia_accessindia.org.inCompilation of NVDA Synthdriverhttp://www.lantana.tenet.res.in/TTSconsortiumWiki/doku.php?id=start72
