Proceedings of the Third Workshop on Statistical Machine Translation, pages 123?126,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsThe University of Washington Machine Translation System forACL WMT 2008Amittai Axelrod, Mei Yang, Kevin Duh, Katrin KirchhoffDepartment of Electrical EngineeringUniversity of WashingtonSeattle, WA 98195{amittai,yangmei,kevinduh,katrin} @ee.washington.eduAbstractThis paper present the University of Washing-ton?s submission to the 2008 ACL SMT shared ma-chine translation task.
Two systems, for English-to-Spanish and German-to-Spanish translation are de-scribed.
Our main focus was on testing a novelboosting framework for N-best list reranking andon handling German morphology in the German-to-Spanish system.
While boosted N-best list rerankingdid not yield any improvements for this task, simpli-fying German morphology as part of the preprocess-ing step did result in significant gains.1 IntroductionThe University of Washington submitted systemsto two data tracks in the WMT 2008 shared taskcompetition, English-to-Spanish and German-to-Spanish.
In both cases, we focused on the in-domaintest set only.
Our main interest this year was on in-vestigating an improved weight training scheme forN-best list reranking that had previously shown im-provements on a smaller machine translation task.For German-to-Spanish translation we additionallyinvestigated simplifications of German morphology,which is known to be fairly complex due to a largenumber of compounds and inflections.
In the fol-lowing sections we first describe the data, baselinesystem and postprocessing steps before describingboosted N-best list reranking and morphology-basedpreprocessing for German.2 Data and Basic PreprocessingWe used the Europarl data as provided (version 3b,1.25 million sentence pairs) for training the transla-tion model for use in the shared task.
The data waslowercased and tokenized with the auxiliary scriptsprovided, and filtered according to the ratio of thesentence lengths in order to eliminate mismatchedsentence pairs.
This resulted in about 965k paral-lel sentences for English-Spanish and 950k sentencepairs for German-Spanish.
Additional preprocess-ing was applied to the German corpus, as describedin Section 5.
For language modeling, we addition-ally used about 82M words of Spanish newswire textfrom the Linguistic Data Consortium (LDC), datingfrom 1995 to 1998.3 System Overview3.1 Translation modelThe system developed for this year?s shared taskis a state-of-the-art, two-pass phrase-based statisti-cal machine translation system based on a log-lineartranslation model (Koehn et al 2003).
The trans-lation models and training method follow the stan-dard Moses (Koehn et al 2007) setup distributed aspart of the shared task.
We used the training methodsuggested in the Moses documentation, with lexical-ized reordering (the msd-bidirectional-feoption) enabled.
The system was tuned via Mini-mum Error Rate Training (MERT) on the first 500sentences of the devtest2006 dataset.1233.2 DecodingOur system used the Moses decoder to generate2000 output hypotheses per input sentence duringthe first translation pass.
For the second pass, theN-best lists were rescored with the additional lan-guage models described below.
We re-optimized themodel combination weights with a parallelized im-plementation of MERT over 16 model scores on thetest2007 dataset.
Two of these model scores foreach hypothesis were from the two language modelsused in our second-pass system, and the rest corre-spond to the 14 Moses model weights (for reorder-ing, language model, translation model, and wordpenalty).3.3 Language modelsWe built all of our language models using theSRILM toolkit (Stolcke, 2002) with modifiedKneser-Ney discounting and interpolating all n-gram estimates of order > 1.
For first-pass de-coding we used a 4-gram language model trainedon the Spanish side of the Europarl v3b data.
Theoptimal n-gram order was determined by testinglanguage models with varying orders (3 to 5) ondevtest2006; BLEU scores obtained using thevarious language models are shown in Table 1.
The4-gram model performed best.Table 1: LM ngram size vs. output BLEU on the dev sets.order devtest2006 test20073-gram 30.54 30.694-gram 31.03 30.945-gram 30.85 30.84Two additional language models were used forsecond pass rescoring.
First, we trained a large out-of-domain language model on Spanish newswiretext obtained from the LDC, dating from 1995 to1998.We used a perplexity-filtering method to filter outthe least relevant half of the out-of-domain text, inorder to significantly reduce the training time ofthe large language model and accelerate the rescor-ing process.
This was done by computing the per-plexity of an in-domain language model on eachnewswire sentence, and then discarding all sen-tences with greater than average perplexity.
Thisreduced the size of the training set from 5.8M sen-tences and 166M tokens to 2.8M sentences and 82Mtokens.
We then further restricted the vocabulary tothe union of the vocabulary lists of the Spanish sidesof the de-es and en-es parallel training corpora.
Theremaining text was used to train the language model.The second language model used for rescoringwas a 5-gram model over part-of-speech (POS) tags.This model was built using the Spanish side of theEnglish-Spanish parallel training corpus.
The POStags were obtained from the corpus using Freelingv2.0 (Atserias et al 2006).We selected the language models for our transla-tion system were selected based on performance onthe English-to-Spanish task, and reused them for theGerman-to-Spanish task.4 Boosted RerankingWe submitted an alternative system, based on adifferent re-ranking method, called BoostedMERT(Duh and Kirchhoff, 2008), for each task.
Boosted-MERT is a novel boosting algorithm that uses Mini-mum Error Rate Training (MERT) as a weak learnerto build a re-ranker that is richer than the standardlog-linear models.
This is motivated by the obser-vation that log-linear models, as trained by MERT,often do not attain the oracle BLEU scores of the N-best lists in the development set.
While this may bedue to a local optimum in MERT, we hypothesizethat log-linear models based on our K re-rankingfeatures are also not sufficiently expressive.BoostedMERT is inspired by the idea of Boosting(for classification), which has been shown to achievelow training (and generalization) error due to classi-fier combination.
In BoostedMERT, we maintain aweight for each N-best list in the development set.In each iteration, MERT is performed to find the bestranker on weighted data.
Then, the weights are up-dated based on whether the current ranker achievesoracle BLEU.
For N-best lists that achieve BLEUscores far lower than the oracle, the weights are in-creased so that they become the emphasis of nextiteration?s MERT.
We currently use the factor e?rto update the N-best list distribution, where r is theratio of the oracle hypothesis?
BLEU to the BLEUof the selected hypothesis.
The final ranker is a124weighted combination of many such rankers.More precisely, let wi be the weights trained byMERT at iteration i.
Given any wi, we can gener-ate a ranking yi over an N-best list where yi is anN-dimensional vector of predicted ranks.
The finalranking vector is a weighted sum: y =?Ti=1 ?iyi,where ?i are parameters estimated during the boost-ing process.
These parameters are optimized formaximum BLEU score on the development set.
Theonly user-specified parameter is T , the number ofboosting iterations.
Here, we choose T by divid-ing the dev set in half: dev1 and dev2.
First, wetrain BoostedMERT on dev1 for 50 iterations, thenpick the T with the best BLEU score on dev2.
Sec-ond, we train BoostedMERT on dev2 and choose theoptimal T from dev1.
Following the philosophy ofclassifier combination, we sum the final rank vectorsy from each of the dev1- and dev2-trained Boosted-MERT to obtain our final ranking result.5 German ?
Spanish PreprocessingGerman is a morphologically complex language,characterized by a high number of noun compoundsand rich inflectional paradigms.
Simplification ofmorphology can produce better word alignment, andthus better phrasal translations, and can also signifi-cantly reduce the out-of-vocabulary rate.
We there-fore applied two operations: (a) splitting of com-pound words and (b) stemming.After basic preprocessing, the German half of thetraining corpus was first tagged by the German ver-sion of TreeTagger (Schmid, 1994), to identify part-of-speech tags.
All nouns were then collected intoa noun list, which was used by a simple compoundsplitter, as described in (Yang and Kirchhoff, 2006).This splitter scans the compound word, hypothesiz-ing segmentations, and selects the first segmentationthat produces two nouns that occur individually inthe corpus.
After splitting the compound nouns inthe filtered corpus, we used the TreeTagger again,only this time to lemmatize the (filtered) trainingcorpus.The stemmed version of the German text was usedto train the translation system?s word alignments(through the end of step 3 in the Moses trainingscript).
After training the alignments, they were pro-jected back onto the unstemmed corpus.
The parallelphrases were then extracted using the standard pro-cedure.
Stemming is only used during the trainingstage, in order to simplify word alignment.
Duringthe evaluation phase, only the compound-splitter isapplied to the German input.6 Results6.1 English ?
SpanishThe unofficial results of our 2nd-pass system for the2008 test set are shown in Table 2, for recased, unto-kenized output.
We note that the basic second-passmodel was better than the first-pass system on the2008 task, but not on the 2007 task, whereas Boost-edMERT provided a minor improvement in the 2007task but not the 2008 task.
This is contrary to previ-ous results in the Arabic-English IWSLT 2007 task,where boosted MERT gave an appreciable improve-ment.
This result is perhaps due to the difference inmagnitude between the IWSLT and WMT transla-tion tasks.Table 2: En?Es system on the test2007 and test2008sets.System test2007 test2008First-Pass 30.95 31.83Second-Pass 30.94 32.72BoostedMERT 31.05 32.626.2 German ?
SpanishAs previously described, we trained two German-Spanish translation systems: one via the defaultmethod provided in the Moses scripts, and an-other using word stems to train the word align-ments and then projecting these alignments ontothe unstemmed corpus and finishing the trainingprocess in the standard manner.
Table 3 demon-strates that the word alignments generated withword-stems markedly improved first-pass transla-tion performance on the dev2006 dataset.
How-ever, during the evaluation period, the worse of thetwo systems was accidentally used, resulting in alarger number of out-of-vocabulary words in thesystem output and hence a poorer score.
Rerun-ning our German-Spanish translation system cor-rectly yielded significantly better system results,also shown in Table 3.125Table 3: De?Es first-pass system on the developmentand 2008 test set.System dev2006 test2008Baseline 23.9 21.2Stemmed Alignments 26.3 24.46.3 Boosted MERTBoostedMERT is still in an early stage of experi-mentation, and we were interested to see whether itimproved over traditional MERT in re-ranking.
As itturns out, the BLEU scores on test2008 and test2007data for the En-Es track are very similar for both re-rankers.
In our post-evaluation analysis, we attemptto understand the reasons for similar BLEU scores,since the weights wi for both re-rankers are quali-tatively different.
We found that out of 2000 En-EsN-best lists, BoostedMERT and MERT differed on1478 lists in terms of the final hypothesis that waschosen.
However, although the rankers are choosingdifferent hypotheses, the chosen strings appear verysimilar.
The PER of BoostedMERT vs. MERT re-sults is only 0.077, and manual observation indicatesthat the differences between the two are often singlephrase differences in a sentence.We also computed the sentence-level BLEU foreach ranker with respect to the true reference.
Thisis meant to check whether BoostedMERT improvedover MERT in some sentences but not others: if theimprovements and degradations occur in the sameproportions, a similar corpus-level BLEU may beobserved.
However, this is not the case.
For a major-ity of the 2000 sentences, the sentence-level BLEUfor both systems are the same.
Only 10% of sen-tences have absolute BLEU difference greater than0.1, and the proportion of improvement/degradationis similar (each 5%).
For BLEU differences greaterthan 0.2, the percentage drops to 4%.Thus we conclude that although BoostedMERTand MERT choose different hypotheses quite of-ten, the string differences between their hypothesesare negligible, leading to similar final BLEU scores.BoostedMERT has found yet another local optimumduring training, but has not improved upon MERTin this dataset.
We hypothesize that dividing up theoriginal development set into halves may have hurtBoostedMERT.7 ConclusionWe have presented the University of Washing-ton systems for English-to-Spanish and German-to-Spanish for the 2008 WMT shared translation task.A novel method for reranking N-best lists based onboosted MERT training was tested, as was morpho-logical simplification in the preprocessing compo-nent for the German-to-Spanish system.
Our con-clusions are that boosted MERT, though successfulon other translation tasks, did not yield any improve-ment here.
Morphological simplification, however,did result in significant improvements in translationquality.AcknowledgementsThis work was funded by NSF grants IIS-0308297and IIS-0326276.ReferencesAtserias, J. et al 2006.
FreeLing 1.3: Syntacticand semantic services in an open-source NLP library.Proceedings of the 5th International Conference onLanguage Resources and Evaluation (LREC 2006).Genoa, Italy.Duh, K., and Kirchhoff, K. 2008.
Beyond Log-LinearModels: Boosted Minimum Error Rate Training forMT Re-ranking.
To appear, Proceedings of the Associ-ation for Computational Linguistics (ACL).
Columbus,Ohio.Koehn, P. and Och, F.J. and Marcu, D. 2003.
Statisticalphrase-based translation.
Proceedings of the HumanLanguage Technology Conference of the North Ameri-can Chapter of the Association for Computational Lin-guistics, (HLT/NAACL).
Edmonton, Canada.Koehn, P. 2005.
Europarl: A Parallel Corpus for Statis-tical Machine Translation Proceedings of MT Summit.Koehn, P. et al 2007.
Moses: Open Source Toolkitfor Statistical Machine Translation.
Annual Meeting ofthe Association for Computational Linguistics (ACL),demonstration session.
Prague, Czech Republic.Schmid, H. 1994.
Probabilistic part-of-speech taggingusing decision trees.
International Conference on NewMethods in Language Processing, Manchester, UK.Stolcke, A.
2002.
SRILM - An extensible language mod-eling toolkit.
Proceedings of ICSLP.Yang, M. and K. Kirchhoff.
2006.
Phrase-based backoffmodels for machine translation of highly inflected lan-guages.
Proceedings of the 11th Conference of the Eu-ropean Chapter of the Association for ComputationalLinguistics (EACL 2006).
Trento, Italy.126
