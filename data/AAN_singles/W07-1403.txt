Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 16?21,Prague, June 2007. c?2007 Association for Computational LinguisticsPrecision-focused Textual InferenceD.
G. Bobrow, C. Condoravdi, R. Crouch, V. de Paiva, L. Karttunen, T. H. King, R. Nairn, L. Price, A. ZaenenPalo Alto Research CenterAbstractThis paper describes our system as used inthe RTE3 task.
The system maps premise andhypothesis pairs into an abstract knowledgerepresentation (AKR) and then performs en-tailment and contradiction detection (ECD)on the resulting AKRs.
Two versions of ECDwere used in RTE3, one with strict ECD andone with looser ECD.1 IntroductionIn the RTE textual entailment challenge, one is givena source text T and a hypothesis H, and the task is todecide whether H can be inferred from T. Our sys-tem interprets inference in a strict way.
Given theknowledge of the language embedded in the system,does the hypothesis logically follow from the infor-mation embedded in the text?
Thus we are empha-sizing precision, particularly in question-answering.This was reflected in our results in the RTE3 chal-lenge.
We responded correctly with YES to relativelyfew of the examples, but on the QA-type examples,we achieved 90-95% average precision.The methodology employed is to use the linguis-tic information to map T and H onto a logical form inAKR, our Abstract Knowledge Representation.
TheAKR is designed to capture the propositions the au-thor of a statement is committed to.
For the sake ofECD, the representation of T may include elementsthat are not directly expressed in the text.
For ex-ample, in the AKR of John bought a car includes thefact that the car was sold.
The AKR of John forgot tobuy milk includes the fact that John did not buy milk.Our reasoning algorithm tries to determine whetherthe AKR of H is subsumed by the AKR of T and detectcases when they are in conflict.The Entailment and Contradiction Detection(ECD) algorithm makes a distinction that is not partof the basic RTE challenge.
If T entails the negationof H, we answer NO (Contradiction).
On the otherProcess OutputText-Breaking Delimited sentencesNamed-entity recognition Type-marked EntitiesMorphological Analysis Word stems plus featuresLFG Parsing Functional StructureSemantic processing Scope, Predicate-argument structureAKR rules Conceptual, Contextual,Temporal StructureFigure 1: The processing pipeline: processes withtheir ambiguity-enabled packed outputshand, if there is no direct entailment we answer UN-KNOWN.
We do not try to construct a likely scenariothat would link T and H. Nor have we tried to col-lect data on phrases that would tend to indicate suchlikely associations between T and H. That approachis clearly very useful (e.g.
(Hickl et al, 2006)), andcould be used as a backup strategy with our moreformal entailment approach.
We have chosen to fo-cus on strict structural and lexical entailments.This paper describes the processing pipeline formapping to AKR, the ECD algorithm, the challengeswe faced in processing the RTE data and a summaryof our results on RTE3.2 Process PipelineFigure 1 shows the processing pipeline for mappingtexts to AKR.
The input is a text of one or moresentences.All components of the system are ?ambiguity en-abled?
(Maxwell and Kaplan, 1991).
This allowseach component to accept ambiguous input in a?packed?
format, process it without unpacking theambiguities, and then pass packed input to the nextstage.
The syntactic component, LFG Parsing, alsohas a stochastic disambiguation system which al-lows us to pass the n-best on to the semantics (Rie-zler et al, 2002); for the RTE3 challenge, we used16n=50.The parser takes the output of the morphology(i.e.
a series of lemmata with their tags) and pro-duces a tree (constituent-structure) and a depen-dency structure (functional-structure) represented asan attribute-value matrix.
The functional-structureis of primary importance for the semantics andAKR.
In particular, it encodes predicate-argumentrelations, including long-distance dependencies, andprovides other syntactic features (e.g.
number, tense,noun type).The output of the syntax is input for the seman-tics that is produced by an ambiguity enabled packedrewriting system.
The semantics is described in de-tail in (Crouch and King, 2006).
Semantic process-ing assigns scope to scope-bearing elements such asnegation and normalizes the output of the syntax.This normalization includes reformulating syntacticpassives as actives (e.g.
The cake was eaten by Mary./ Mary ate the cake.
), resolving many null pronouns(e.g.
Laughing, John entered the room / Johni laugh-ing, Johni entered the room.
), and canonicalizingmeasure phrases, comparatives, and dates.
Morecomplex normalizations involve converting nominaldeverbals into the equivalent verbal form, identify-ing arguments of the verb from the arguments ofthe nominal (Gurevich et al, 2006).
For example,the semantic representation of Iraq?s destruction ofits WMD is similar to the representation of Iraq de-stroyed its WMD.The final main task of the semantics rules is toconvert words into concepts and syntactic grammat-ical functions into roles.
The mapping onto conceptsuses WordNet (Fellbaum, 1998) to map words intolists of synsets.
The named entity types provided bythe morphology and syntax are used to create moreaccurate mapping of proper nouns since these arenot systematically represented in WordNet.
The se-mantic rules use the grammatical function subcat-egorization information from the verb and the roleinformation found in extended VerbNet (Kipper etal., 2000) to map syntactic subjects, objects, andobliques into more abstract thematic roles such asAgent, Theme, and Goal (Crouch and King, 2005).This mapping into thematic-style roles allows thesystem to correctly align the arguments in pairs like(1) and (2), something which is impossible using justsyntactic functions.
In the first, the object and sub-ject have a common thematic role in the alternationbetween transitive and intransitive; while in the sec-ond, the common role is shared by the subjects.
(1) John broke the vasesyn:object,sem:patient.The vasesyn:subject,sem:patient broke.
(2) Johnsyn:subject,sem:agent ate the cake.Johnsyn:subject,sem:agent ate.The goal of these semantic normalizations is toabstract away from the syntactic representation sothat sentences with similar meaning have similar se-mantic representations.
However, the semantics isstill fundamentally a linguistic level of representa-tion; further abstraction towards the meaning is donein the mapping from semantics to AKR.
The AKRis the level of representation that is used to deter-mine entailment and contradiction in our RTE3 sys-tem.
A preliminary description of its logic was pro-vided in (Bobrow et al, 2005).
The AKR mappingconverts grammatical tense and temporal modifiersinto temporal relations, identifies anaphoric refer-ents and makes explicit the implied relation betweencomplement clauses and the main verb (e.g.
formanage, fail) (Nairn et al, 2006).
AKR also dealswith standard phrases that are equivalent to simplevocabulary terms.
For example, take a flight to NewYork is equivalent to fly to New York.
These usesof ?light?
verbs (e.g.
take, give) are not includedin synonyms found in WordNet.
Another class ofphrasal synonyms involve inchoatives (e.g.
take aturn for the worse/worsen).
We included a specialset of transformation rules for phrasal synonyms:some of the rules are part of the mapping from se-mantics to AKR while others are part of the ECDmodule.
The mapping to AKR is done using the sameambiguity-enabled ordered rewriting system that thesemantics uses, allowing the AKR mapping systemto efficiently process the packed output of the se-mantics.The AKR for a sentence like Bush claimed thatIraq possessed WMDs in Figure 2 introduces twocontexts: a top level context t, representing the com-mitments of the speaker of sentence, and an embed-ded context claim cx:37 representing the state of af-fairs according to Bush?s claim.
The two contextsare related via the Topic role of the claim event.The representation contains terms like claim:37 or17Conceptual Structuresubconcept(claim:37,[claim-1,.
.
.,claim-5])role(Topic,claim:37,claim cx:37)role(Agent,claim:37,Bush:1)subconcept(Bush:1,[person-1])alias(Bush:1,[Bush])role(cardinality restriction,Bush:1,sg)subconcept(possess:24,[possess-1,own-1,possess-3])role(Destination,possess:24,wmd:34)role(Agent,possess:24,Iraq:19)subconcept(Iraq:19,[location-1,location-4])alias(Iraq:19,[Iraq])role(cardinality restriction,Iraq:19,sg)subconcept(wmd:34,[weapon of mass destruction-1])role(cardinality restriction,wmd:34,pl)Contextual Structurecontext(t)context(claim cx:37)context relation(t,claim cx:37,crel(Topic,claim:37))instantiable(Bush:1,t)instantiable(Iraq:19,t)instantiable(claim:37,t)instantiable(Iraq:19,claim cx:37)instantiable(possess:24,claim cx:37)instantiable(wmd:34,claim cx:37)Temporal StructuretemporalRel(After,Now,claim:37)temporalRel(After,claim:37,possess:24)Figure 2: AKR for Bush claimed that Iraq possessedWMDs.Bush:1 which refer to the kinds of object that thesentence is talking about.
The subconcept facts ex-plicitly link these terms to their concepts in Word-Net.
Thus claim:37 is stated to be some subkindof the type claim-1, etc., and wmd:34 to be somesubkind of the type weapon of mass destruction-1.
Terms like claim:37 and wmd:34 do not referto individuals, but to concepts (or types or kinds).Saying that there is some subconcept of the kindweapon of mass destruction-1, where this subcon-cept is further restricted to be a kind of WMD pos-sessed by Iraq, does not commit you to saying thatthere are any instances of this subconcept.The instantiable assertions capture the commit-ments about the existence of the kinds of object de-scribed.
In the top-level context t, there is a com-mitment to an instance of Bush and of a claim:37event made by him.
However, there is no top-levelcommitment to any instances of wmd:34 possessedby Iraq:19.
These commitments are only made inthe embedded claim cx:37 context.
It is left openwhether these embedded commitments correspond,or not, to the beliefs of the speaker.
Two distinctlevels of structure can thus be discerned in AKR: aconceptual structure and a contextual structure.
Theconceptual structure, through use of subconcept androle assertions, indicates the subject matter.
Thecontextual structure indicates commitments as to theexistence of the subject matter via instantiability as-sertions linking concepts to contexts, and via contextrelations linking contexts to contexts.
In addition,there is a temporal structure that situates the eventsdescribed with respect to the time of utterance andtemporally relates them to one another.3 Entailment and Contradiction DetectionECD is implemented as another set of rewrite rules,running on the same packed rewrite system used togenerate the AKR representations.
The rules (i) alignconcept and context terms in text (T) and hypoth-esis (H) AKRs, (ii) calculate concept subsumptionorderings between aligned T and H terms, and (iii)check instantiability and uninstantiability claims inthe light of subsumption orderings to determinewhether T entails H, T contradicts H, or T neitherentails not contradicts H. For the purposes of RTE3,both contradiction and neither contradiction nor en-tailment are collapsed into a NO (does not follow)judgment.One of the novel features of this approach is thatT and H representations do not need to be disam-biguated before checking for entailment or contra-diction.
The approach is able to detect if there is onereading of T that entails (or contradicts) one readingof H. The T and H passages can in effect mutuallydisambiguate one another through the ECD.
For ex-ample, although plane and level both have multiplereadings, they can both refer to a horizontal surface,and in that sense The plane is dry entails The level isdry, and vice versa.The first phase of ECD aligns concepts and con-text terms in the T and H AKRs.
Concepts are repre-18sented as lists of WordNet hypernym lists, in Word-Net sense order.
Two concept terms can be alignedif a sense synset of one term (i.e.
the first elementof one of the term?s hypernym lists) is contained ina hypernym list of the other term.
The alignmentcan be weighted according to word sense; so a con-cept overlap on the first senses of a T and H termcounts for more than a concept overlap on the n andmth senses.
However, no weightings were used inRTE3.
For named entities, alignment demands notonly a concept overlap, but also an intersection inthe ?alias?
forms of the proper nouns.
For exam-ple,?George Bush?
may be aligned with ?George?or with ?Bush?.
Context alignment relies on associ-ating each context with an indexing concept, usuallythe concept for the main verb in the clause headingthe context.
Contexts are then aligned on the basisof these concept indices.Typically, an H term can align with more than oneT term.
In such cases all possible alignments areproposed, but the alignment rules put the alternativealignments in different parts of the choice space.Having aligned T and H terms, rules are applied todetermine concept specificity and subsumption rela-tions between aligned terms.
Preliminary judgmentsof specificity are made by looking for hypernym in-clusion.
For example, an H term denoting the con-cept ?person?
is less specific than a T term denot-ing ?woman?.
These preliminary judgments need tobe revised in the light of role restrictions modifyingthe terms: a ?tall person?
is neither more nor lessspecific than a ?woman?.
Revisions to specificityjudgments also take into account cardinality modi-fiers: while ?person?
is less specific than ?woman?,?all persons?
is judged to be more specific than ?allwomen?.With judgments of concept specificity in place,it is possible to determine entailment relations onthe basis of (un)instantiability claims in the T andH AKRs.
For example, suppose the T and H AKRscontain the facts in (3).
(3) T: instantiable(C T, Ctx T)H: instantiable(C H, Ctx H)where concept C T is aligned with C H, C T isjudged to be more specific than C H, and contextCtx T is aligned with context Ctx H. In this case,the hypothesis instantiability claim is entailed bythe text instantiability claim (existence of somethingmore specific entails existence of something moregeneral).
This being so, the H instantiability claimcan be deleted without loss of information.If instead we had the (un)instantiability claims in(4) for the same alignments and specificity relations,(4) T: instantiable(C T, Ctx T)H: uninstantiable(C H, Ctx H)we would have a contradiction: the text says thatthere is something of the more specific type C T,whereas the hypothesis says there are no things ofthe more general type C H. In this case, the rulesexplicitly flag a contradiction.Once all (un)instantiability claims have beencompared, it is possible to judge whether the text en-tails or contradicts the hypothesis.
Entailed hypothe-sis (un)instantiability assertions are deleted from therepresentation.
Consequently, if there is one T and HAKR readings and one set of alignments under whichall the H (un)instantiability assertions have been re-moved, then there is an entailment of H by T. Ifthere is a pair of readings and a set of alignmentsunder which a contradiction is flagged, then thereis a contradiction.
If there is no pair of readings orset of alignments under which there is either an en-tailment or a contradiction, then T and H are merelyconsistent with one another.
There are exceptionalcases such as (5) where one reading of T entails Hand another reading contradicts it.
(5) T: John did not wait to call for help.H: John called for help.Our ECD rules detect such cases.WordNet often misses synonyms needed for thealignment in the ECD.
In particular, the hierarchyand synsets for verbs are one of WordNet?s least de-veloped parts.
To test the impact of the missing syn-onyms, we developed a variation on the ECD algo-rithm that allows loose matching.First, in concept alignment, if a verb concept in Hdoes not align with any verb concept in T, then wepermit it to (separately) align with all the text verbconcepts.
We do not permit the same loose align-ment for noun concepts, since we judge WordNetinformation to be more reliable for nouns.
This freealignment of verbs might sound risky, but in gen-eral these alignments will not lead to useful concept19specificity judgments unless the T and H verbs havevery similar arguments / role restrictions.When such a loose verb alignment is made, weexplicitly record this fact in a justification term in-cluded in the alignment fact.
Similarly, when judg-ing concept specificity, each rule that applies adds aterm to a list of justifications recorded as part of thefact indicating the specificity relation.
This meansthat when the final specificity judgments are deter-mined, each judgment has a record of the sequenceof decisions made to reach it.
(Un)instantiability comparisons are made as instrict matching.
However, the criteria for detect-ing an entailment are selectively loosened.
If nocontradiction is flagged, and there is a pairing ofreadings and alignments under which just a singleH instantiability assertion is left standing, then thisis allowed through as a loose entailment.
However,further rules are applied to block those loose entail-ments that are deemed inappropriate.
These block-ing rules look at the form of the justification termsgathered based on specificity judgments.These blocking rules are manually selected.
First,a loose matching run is made without any block-ing rules.
Results are dumped for each T-H pair,recording the expected logical relation and the jus-tifications collected.
Blocking rules are created bydetecting patterns of justification that are associatedwith labeled non-entailments.
One such blockingrule says that if you have just a single H instantia-bility left, but the specificity justifications leading tothis have been shown to be reliable on training data,then the instantiability should not be eliminated as aloose entailment.4 Challenges in Processing the RTE DataThe RTE3 data set contains inconsistencies inspelling and punctuation between the text and thehypothesis.
To handle these, we did an automaticprepass where we compared the strings in the pas-sage text to those in the hypothesis.
Some of thespecial cases that we handled include:?
Normalize capitalization and spacing?
Identify acronyms and shorten names?
Title identification?
Spelling correctionRole names in VerbNet are in part intended to cap-ture the relation of the argument to the event be-ing described by the verb.
For example, an objectplaying an Agent role is causally involved in theevent, while an object playing a Theme or Patientrole is only supposed to be affected.
This allowsparticipants in an action to be identified regardlessof the syntactic frame chosen to represent the verb;this was seen in (1) and (2).
Sometimes the rolesfrom VerbNet are not assigned in such a way as toallow such transparent identification across framesor related verbs.
Consider an example.
In Ed trav-els/goes to Boston VerbNet identifies Ed as playing aTheme role.
However, in Ed flies to Boston VerbNetassigns Ed an Agent role; this difference can makedetermining contradiction and entailment between Tand H difficult.
We have tried to compensate in ourECD, by using a backoff strategy where fewer rolenames are used (by projecting down role names tothe smaller set).
As we develop the system further,we continue to experiment with which set of rolesworks best for which tasks.Another open issue involves identifying alterna-tive ways vague relations among objects appear intext.
We do not match the expression the Bostonteam with the team from Boston.
To improve our re-call, we are considering loose matching techniques.5 Summary of our results on RTE3We participated in the RTE challenge as a way tounderstand what our particular techniques could dowith respect to a more general version of textual en-tailment.
The overall experiment was quite enlight-ening.
Tables 1 and 2 summarize how we did on theRTE3 challenge.
System 1 is our standard systemwith strict ECD.
System 2 used the looser set of ECDrules.Gold Sys Cor- R P FYES YES rectIE 105 6 5 0.048 0.83 0.20IR 87 4 4 0.046 1.00 0.21QA 106 10 9 0.085 0.90 0.28SUM 112 11 7 0.063 0.64 0.20Total 410 31 25 0.060 0.84 0.22Table 1: System 1 with Strict ECD20Gold Sys Cor- R P FYES YES rectIE 105 15 10 0.095 0.67 0.25IR 87 6 4 0.046 0.67 0.18QA 106 14 13 0.12 0.93 0.34SUM 112 17 10 0.089 0.59 0.23Total 410 52 37 0.088 0.71 0.25Table 2: System 2 with Loose ECDAs can be seen, we answered very few of the ques-tions; only 31 of the possible 410 with a YES answer.However, for those we did answer (requiring onlylinguistic, and not world knowledge), we achievedhigh precision: up to 90% on QA.
However, we werenot perfect even from this perspective.
Here are sim-plified versions of the errors where our system an-swered YES, and the answer should be NO with ananalysis of what is needed in the system to correctthe error.The wrong result in (6) is due to our incompletecoverage of intensional verbs (seek, want, look for,need, etc.).
(6) T: The US sought the release of hostages.H: Hostages were released.The object of an intensional verb cannot be assumedto exist or to occur.
Intensional verbs need to bemarked systematically in our lexicon.The problem with (7) lies in the lack of treatmentfor generic sentences.
(7) T: Girls and boys are segregated in high schoolduring sex education class.H: Girls and boys are segregated in high school.The natural interpretation of H is that girls and boysare segregated in high school ALL THE TIME.
Be-cause we do not yet handle generic sentences prop-erly, our algorithm for calculating specificity pro-duces the wrong result here.
It judges segregation inH to be less specific than in T whereas the oppositeis in fact the case.
Adding the word ?sometimes?
toH would make our YES the correct answer.The distinction between generic and episodicreadings is difficult to make but crucial for the in-terpretation of bare plural noun phrases such as girlsand boys.
For example, the most likely interpreta-tion of Counselors are available is episodic: SOMEcounselors are available.
But Experts are highlypaid is weighted towards a generic reading: MOSTIF NOT ALL experts get a good salary.These examples are indicative of the subtlety ofanalysis necessary for high precision textual infer-ence.ReferencesDanny Bobrow, Cleo Condoravdi, Richard Crouch,Ronald Kaplan, Lauri Karttunen, Tracy HollowayKing, Valeria de Paiva, and Annie Zaenen.
2005.
Abasic logic for textual inference.
In Proceedings of theAAAI Workshop on Inference for Textual Question An-swering.Dick Crouch and Tracy Holloway King.
2005.
Unify-ing lexical resources.
In Proceedings of the Interdisci-plinary Workshop on the Identification and Represen-tation of Verb Features and Verb Classes.Dick Crouch and Tracy Holloway King.
2006.
Se-mantics via F-structure rewriting.
In Proceedings ofLFG06.
CSLI On-line Publications.Dick Crouch, Mary Dalrymple, Ron Kaplan, Tracy King,John Maxwell, and Paula Newman.
2007.
XLE docu-mentation.
Available on-line.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
The MIT Press.Olga Gurevich, Richard Crouch, Tracy Holloway King,and Valeria de Paiva.
2006.
Deverbal nouns in knowl-edge representation.
In Proceedings of FLAIRS 2006.Andres Hickl, John Williams, Jeremy Bensley, KirkRoberts, Bryan Rink, and Ying Shi.
2006.
Recog-nizing textual entailment with LCC?s GROUNDHOGsystem.
In The Second PASCAL Recognising TextualEntailment Challenge.Karin Kipper, Hoa Trang Dang, and Martha Palmer.2000.
Class-based construction of a verb lexicon.
InAAAI-2000 17th National Conference on Artificial In-telligence.John Maxwell and Ron Kaplan.
1991.
A method fordisjunctive constraint satisfaction.
Current Issues inParsing Technologies.Rowan Nairn, Cleo Condoravdi, and Lauri Karttunen.2006.
Computing relative polarity for textual infer-ence.
In Proceedings of ICoS-5.Stefan Riezler, Tracy Holloway King, Ron Kaplan, DickCrouch, John Maxwell, and Mark Johnson.
2002.Parsing the Wall Street Journal using a Lexical-Functional Grammar and discriminative estimationtechniques.
In Proceedings of the Annual Meeting ofthe Association for Computational Linguistics.21
