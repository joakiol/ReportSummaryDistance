Two-Phase Biomedical Named EntityRecognition Using A Hybrid MethodSeonho Kim1, Juntae Yoon2, Kyung-Mi Park1, and Hae-Chang Rim11 Dept.
of Computer Science and Engineering,Korea University, Seoul, Korea2 NLP Lab.
Daumsoft Inc. Seoul, KoreaAbstract.
Biomedical named entity recognition (NER) is a difficultproblem in biomedical information processing due to the widespread am-biguity of terms out of context and extensive lexical variations.
This pa-per presents a two-phase biomedical NER consisting of term boundarydetection and semantic labeling.
By dividing the problem, we can adoptan effective model for each process.
In our study, we use two exponentialmodels, conditional random fields and maximum entropy, at each phase.Moreover, results by this machine learning based model are refined byrule-based postprocessing implemented using a finite state method.
Ex-periments show it achieves the performance of F-score 71.19% on theJNLPBA 2004 shared task of identifying 5 classes of biomedical NEs.1 IntroductionDue to dynamic progress in biomedical literature, a vast amount of new infor-mation and research results have been published and many of them are availablein the electronic form - for example, like the PubMed MedLine database.
Thus,automatic knowledge discovery and efficient information access are strongly de-manded to curate domain databases, to find out relevant information, and tointegrate/update new information across an increasingly large body of scien-tific articles.
In particular, since most biomedical texts introduce specific no-tations, acronyms, and innovative names to represent new concepts, relations,processes, functions, locations, and events, automatic extraction of biomedicalterminologies and mining of their diverse usage are major challenges in biomed-ical information processing system.
In these processes, biomedical named entityrecognition (NER) is the core step to access the higher level of information.In fact, there has been a wide range of research on NER like the NER task onthe standard newswire domain in the Message Understanding Conference (MUC-6).
In this task, the best system reported 95% accuracy in identifying seven typesof named entities (person, organization, location, time, date, money, and per-cent).
While the performance in the standard domain turned out to be quite goodas shown in the papers, that in the biomedical domain is not still satisfactory,which is mainly due to the following characteristics of biomedical terminologies:First, NEs have various naming conventions.
For instance, some entities havedescriptive and expanded forms such as ?activated B cell lines, 47 kDa sterolR.
Dale et al (Eds.
): IJCNLP 2005, LNAI 3651, pp.
646?657, 2005.c?
Springer-Verlag Berlin Heidelberg 2005Two-Phase Biomedical Named Entity Recognition 647regulatory element binding factor?, whereas some entities appear in shortenedor abbreviated forms like ?EGFR?
and ?EGF receptor?
representing epidermalgrowth factor receptor.
Second, biomedical NEs have the widespread ambiguityout of context.
For instance, ?IL-2?
can be doubly classified as ?protein?
and?DNA?
according to its context.
Third, biomedical NEs often comprise a nestedstructure, for example ??DNA?
?protein?TNF alpha?/protein?gene?/DNA??.
Ac-cording to [13], 16.57% of biomedical terms in GENIA have cascaded construc-tions.
In the case, recognition of the longest terms is the main target in general.However, in our evaluation task, when the embedded part of a term is regardedas the meaningful or important class in the context, the term is labeled only withthe class of embedded one.
Thus, identification of internal structures of NEs ishelpful to recognize correct NEs.
In addition, more than one NE often share thesame head noun with a conjunction/disjunction or enumeration structure, forinstance, ?IFN-gamma and GM-CSF mRNA?, ?CD33+, CD56+, CD16- acuteleukemia?or ?antigen- or cAMP-activated Th2 cell?.
Last, there is a lot of inter-annotator disagreement.
[7] reported that the inter-annotator agreement rate ofhuman experts was just 77.6% when performing gene/protein/mRNA classifica-tion task manually.Thus, a lot of term occurrences in real text would not be identified with sim-ple dictionary look-up, despite the availability of many terminological databases,as claimed in [12].
That is one of the reasons why machine learning approachesare more dominant in biomedical NER than rule-based or dictionary-based ap-proaches [5], even though existence of reliable training resources is very critical.Accordingly, much work has been done on biomedical NER, based on ma-chine learning techniques.
[3] and [13] have used hidden Markov Model (HMM)for biomedical NER where state transitions are made by semantic trigger fea-tures.
[4] and [11] have applied maximum entropy plus Markovian sequence basedmodels such as maximum entropy markov model (MEMM) and conditional ran-dom fields (CRFs), which present a way for integrating different features suchas internal word spellings and morphological clues within an NE string and con-textual clues surrounding the string in the sentence.These works took an one-phase based approach where boundary detectionof named entities and semantic labeling come together.
On the other hand, [9]proposed a two-phase model in which the biomedical named entity recognitionprocess is divided into two processes of distinguishing biomedical named entitiesfrom general terms and labeling the named entities with semantic classes thatthey belong to.
They use support vector machines (SVM) for each phase.
How-ever, the SVM does not provide an easy way for labeling Markov sequence datalike B following O and I following B in named entities.
Furthermore, since thissystem is tested on the GENIA corpus rather than JNLPBA 2004 shared task, wecannot confirm the effectiveness of this approach on the ground of experimentsfor common resources.In this paper, we present a two-phase named entity recognition model: (1)boundary detection for NEs and (2) term classification by semantic labeling.The advantage of dividing the recognition process into two phase is that we can648 S. Kim et alselect separately a discriminative feature set for each subtask, and moreover canmeasure effectiveness of models at each phase.
We use two exponential modelsfor this work, namely conditional random fields for boundary detection havingMarkov sequence, and the maximum entropy model for semantic labeling.
In ad-dition, results from the machine learning based model are refined by a rule-basedpostprocessing, which is implemented using a finite state transducer (FST).
TheFST is constructed with the GENIA 3.02 corpus.
We here focus on identificationof five classes of NEs, i.e.
?protein?, ?RNA?, ?DNA?, ?cell line?, and ?cell type?and experiments are conducted on the training and evaluation set provided bythe shared task in COLING 2004 JNLPBA.2 Training2.1 Maximum Entropy and Conditional Random FieldsBefore we describe the features used in our model, we briefly introduce the MEand CRF model which we make use of.
In the ME framework, the conditionalprobability of predicting an outcome o given a history h is defined as follows:p?
(o|h) =1Z?
(h)exp(k?i=1?ifi(h, o))(1)where fi(h, o) is a binary-valued feature function, ?i is the weighting parameterof fi(h, o), k is the number of features, and Z?
(h) is a normalization factorfor ?op?(o|h)=1.
That is, the probability p?
(o|h) is calculated by the weightedsum of active features.
Given an exponential model with k features and a setof training data, empirical distribution, weights of the k features are trained tomaximize the model?s log-likelihood:L(p) =?o,hp?
(h, o)log(o|h) (2)Although the maximum entropy model above provides a powerful tool forclassification by integrating different features, it is not easy to model the Markovsequence data.
In this case, the CRF is used for a task of assigning label sequencesto a set of observation sequences.
Based on the principle of maximum entropy,a CRF has a single exponential model for the joint probability of the entiresequence of labels given the observation sequence.
The CRF is a special case ofthe linear chain that corresponds to conditionally trained finite-state machineand define conditional probability distributions of a particular label sequence sgiven observation sequence op?
(s|o) = 1Z(o)exp(?kj=1 ?jFj(s,o))Fj(s,o) =?ni=1 fj(si?1, si,o, i)(3)Two-Phase Biomedical Named Entity Recognition 649where s = s1 .
.
.
sn, and o = o1 .
.
.
on, Z(o) is a normalization factor, and eachfeature is a transition function [8].
For example, we can think of the followingfeature function.fj(si?1, si,o, i) =??
?1 if si?1=B and si=I,and the observation word at position i is ?gene?
?0 otherwise(4)Our CRFs for term boundary detection have a first-order Markov dependencybetween output tags.
The label at position i, si is one of B, I and O.
In contrastto the ME model, since B is the beginning of a term, the transition from O to Iis not possible.
CRFs constrain results to consider only reasonable paths.
Thus,total 8 combinations are possible for (si?1,si) and the most likely s can be foundwith the Viterbi algorithm.
The weights are set to maximize the conditional loglikelihood of labeled sequences in the training set using a quasi-Newton methodcalled L-BFGS [2].2.2 Features for Term Boundary DetectionTable 1 shows features for the step of finding the boundary of biomedical terms.Here, we give a supplementary description of a part of the features.Table 1.
Feature set for boundary detection (+:conjunction)Model Feature DescriptionCRF, MEmarkov Word wi?1, wi?2, wi, wi+1, wi+2CRF, MEmarkov Word Normalization normalization forms of the 5 wordsCRF, MEmarkov POS POSwi?1 , POSwi , POSwi+1CRF, MEmarkov Word Construction form WFwiCRF, MEmarkov Word Characteristics WCwi?1 , WCwi , WCwi+1CRF, MEmarkov Contextual Bigrams wi?1 + wiwi + wi+1wi+1 + wi+2CRF, MEmarkov Contextual Trigrams wi?1 + wi + wi+1CRF, MEmarkov Bigram POS POSwi?1 + POSwiPOSwi + POSwi+1CRF, MEmarkov Trigram POS POSwi?1 + POSwi + POSwi+1CRF, MEmarkov Modifier MODI(wi)CRF, MEmarkov Header HEAD(wi)CRF, MEmarkov SUFFIX SUFFIX(wi)CRF, MEmarkov Chunk Type CTypewiCRF, MEmarkov Chunk Type + Pre POS CTypewi + POSwi?1MEmarkov Pre label labelwi?1MEmarkov Pre label + Cur Word labelwi?1 + wi?
word and POS: 5 words(target word(wi), left two words, and right twowords) and three POS(POSwi?1 , POSwi , POSwi+1) are considered.650 S. Kim et al?
word normalization: This feature contributes to word normalization.
Weattempt to reduce a word to its stem or root form with a simple algorithmwhich has rules for words containing plural, hyphen, and alphanumeric let-ters.
Specifically, the following patterns are considered.
(1) ?lymphocytes?, ?cells?
?
?lymphocyte?, ?cell?
(2) ?il-2?, ?il-2a?, ?il2a?
?
?il?
(3) ?5-lipoxygenase?, ?v-Abl?
?
?lipoxygenase?, ?abl?
(4) ?peri-kappa?or ?t-cell?
has two normalization forms of ?peri?and?kappa?and ?t?
and ?cell?
respectively.
(5) ?Ca2+-independent?
has two roots of ?ca?
and ?independent?.
(6) The root of digits is ?D?.?
informative suffix: This feature appears if a target word has a salient suffixfor boundary detection.
The list of salient suffixes is obtained by relativeentropy [10].?
word construction form: This feature indicates how a target word is or-thographically constructed.
Word shapes refer to a mapping of each wordon equivalence classes that encodes with dashes, numerals, capitalizations,lower letters, symbols, and so on.
All spellings are represented with combina-tions of the attributes1.
For instance, the word construction form of ?IL-2?would become ?IDASH-ALPNUM?.?
word characteristics: This feature appears if a word represents a DNAsequence of ?A?,?C?,?G?,?T?
or Greek letter such as beta or alpha, ordinalindex such as I, II or unit such as BU/ml, micron/mL.
It is encoded with?ACGT?, ?GREEK?, ?INDEX?, ?UNIT?.?
head/modifying information: If a word prefers the rightmost positionof terminologies, we regard it has the property of a head noun.
On theother hand, if a word frequently occurs in other positions, we regard it hasthe property of a modifying noun.
It can help to establish the beginningand ending point of multi-word entities.
We automatically extract 4,382head nouns and 7,072 modifying nouns from the training data as shown inTable 2.?
chunk-type information: This feature is also effective in determining theposition of a word in NEs, ?B?, ?I?, ?O?
which means ?begin chunk?, ?inchunk?
and ?others?, respectively.
We consider the chunk type of a targetword and the conjunction of the current chunk type and the POS of theprevious word to represent the structure of an NE.We also tested an ME-based model for boundary detection.
For this, we addtwo special features : previous state (label) and conjunction of previous label1 ?IDASH?
(inter dash), ?EDASH?
(end dash), ?SDASH?
(start dash),?CAP?
(capitalization), ?LOW?
(lowercase), ?MIX?
(lowercase and capitaliza-tion letters), ?NUM?
(digit), ?ALPNUM?
(alpha-numeric), ?SYM?(symbol),?PUNC?
(punctuation),and ?COMMA?
(comma)Two-Phase Biomedical Named Entity Recognition 651Table 2.
Examples of Head/Modifying NounsModifying Nouns Head Nounsnf-kappa cytokinesnuclear elementsactivated assaysnormal complexesphorbol macrophagesviral moleculesinflammatory pathwaysmurine extractselectrophoretic glucocorticoidsacute levelsintracellular responsesepstein-barr clonescytoplasmic motifsand current word to consider state transition.
That is, a previous label can berepresented as a feature function in our model as follows:fi(h, o) ={1 if pre label+tw=B+gene,o=I0 otherwise(5)It means that the target word is likely to be inside a term (I), when the wordis ?gene?
and the previous label is ?B?.
In our model, the current label is de-terministically assigned to the target word with considering the previous statewith the highest probability.2.3 Features for Semantic LabelingTable 3 shows features for semantic labeling with respect to recognized NEs.?
word contextual feature: We make use of three kinds of internal and ex-ternal contextual features: words within identified NEs, their word normal-ization forms, and words surrounding the NEs.
In Table 3, NEw0 denotesthe rightmost word in an identified NE region.
Moreover, the presence ofspecific head nouns acting as functional words takes precedence when de-termining the term class, even though many terms do not contain explicitterm category information.
For example, functional words, such as ?factor?,?receptor?, and ?protein?
are very useful in determining protein class, and?gene?, ?promoter?, and ?motif ?
are clues for classifying DNA [5].
In gen-eral, such functional words are often the last word of an entity.
This is thereason we consider the position where a word occurs in NEs along with theword.
For inside context features, we use non-positional word features aswell.
As non-positional features, all words inside NEs are used.?
internal bigrams and trigrams: We consider the rightmost bigrams/trigrams inside identified NEs and the normalized bigrams/trigrams.652 S. Kim et alTable 3.
Feature Set for Semantic ClassificationFeature descriptionWord Features (positional) NEwothers , NEw?3 , NEw?2 , NEw?1 , NEw0Word Features (non-positional) AllNEwWord Normalization (positional) WFNEw?3 , WFNEw?2 , WFNEw?1 , WFNEw0Left Context(Words Surrounding an NE) LCW?2, LCW?1Right Context RCW+1, RCW+2Internal Bigrams NEw?1 + NEw0Internal Trigrams NEw?2 + NEw?1 + NEw0Normalized Internal Bigrams WFNEw?1 + WFNEw0Normalized Internal Trigrams NEw?2 + NEw?1 + NEw0IDASH-word related Bigrams/TrigramsKeyword KEYWORD(NEi)?
IDASH-word related bigrams/trigrams: This feature appears if NEw0or NEw?1 contains dash characters.
In this case, the bigram/trigram areadditionally formed by removing all dashes from the spelling.
It is useful todeal with lexical variants.?
keywords: This feature appears if the identified NE is informative key-word with respect to a specific class.
The keywords set comprises termsobtained by the relative entropy between general and biomedical domaincorpora.3 Rule-Based PostprocessingA rule-based method can be used to correct errors by NER based on machinelearning.
For example, the CRFs tag ?IL-2 receptor expression?
as ?B I I?,since the NEs ended with ?receptor expression?
in training data almost belongto ?other name?
class even if the NEs ended with ?receptor?
belong to ?pro-tein?
class.
It should be actually tagged as ?B I O?.
That kind of errors iscaused mainly by the cascaded phenomenon in biomedical names.
Since our sys-tem considers all NEs belonging to other classes in the recognition phase, ittends to recognize the longest ones.
That is, in the term classification phase,such NEs are classified as ?other?
class and are ignored.
Thus, the systemlosts embedded NEs although the training and evaluation set in fact tends toconsider only the embedded NE when the embedded one is more meaningfulor important.This error correction is conducted by the rule-based method, i.e.
If condi-tion THEN action.
For example, the rule ?IF wi?2=IL-2, wi?1=receptor andwi=expression THEN replace the tag of wi with O?
can be applied for the abovecase.
We use a finite state transducer for this rule-based transformation, whichis easy to understand with given lexical rules, and very efficient.
Rules used forthe FST are acquired from the GENIA corpus.
We first retrieved all NEs in-cluding embedded NEs and longest NEs from GENIA 3.02 corpus and changeTwo-Phase Biomedical Named Entity Recognition 653IL-2/B gene/IIL-2/O gene/O expression/OFig.
1.
Non-Deterministic FSTIL-2/?
gene/ ?expression/OOO?
/BIFig.
2.
Deterministic FSTthe outputs of all other classes except the target 5 classes to O.
That is, theinput of FST is a sequence of words in a sentence and the output is categoriescorresponding to the words.Then, we removed the rules in conflict with NE information from the trainingcorpus.
These rules are non-deterministic (Figure 1), and we can change it tothe deterministic FST (Figure 2) since the lengths of NEs are finite.
The deter-ministic FST is made by defining the final output function for the deterministicbehavior of the transducer, delaying the output.
The deterministic FST is de-fined as follows: (?1, ?2, Q, i, F, ?, ?, ?
), where ?1 is a finite input alphabet; ?2is a finite output alphabet; Q is a finite set of states or vertices; i ?
Q is theinitial state; F ?
Q is the set of final states; ?
is the deterministic state transi-tion function that maps Q ?
?1 on Q; ?
is the deterministic emission functionthat maps Q ?
?1 on ?
?2 and ?
: F ?
?
?2 is the final output function for thedeterministic behavior of the transducer.4 Evaluation4.1 Experimental EnvironmentsIn the shared task, only biomedical named entities which belong to 5 specificclasses are annotated in the given training data.
That is, terms belonging toother classes in GENIA are excluded from the recognition target.
However, weconsider all NEs in the boundary detection step since we separate the NERtask into two phases.
Thus, in order to utilize other class terms, we additionallyannotated ?O?
class words in the training data where they corresponds to otherclasses such as other organic compound, lipid, and multi cell in GENIA 3.02pversion corpus.
During the annotation, we only consider the longest NEs on654 S. Kim et alTable 4.
Number of training examplesRNA DNA cell line cell type protein other472 5,370 2,236 2,084 16,042 11,475GENIA.
As a consequence, we find all biomedical named entities in text at theterm detection phase.
Then, biomedical NEs classified as other class are changedto O at the semantic labeling phase.
The total words that belong to other classturned out to be 25,987.
Table 4 shows the number of NEs with respect to eachclass on the training data.
In our experiments, a quasi-Newton method called theL-BFGS with Gaussian Prior smoothing is applied for parameter estimation [2].4.2 Experimental ResultsTable 5 shows the overall performance on the evaluation data.
Our systemachieves an F-score of 71.19%.
As shown in the table, the performance of NERfor cell line class was not good, because its boundary recognition is not so goodas other classes.
Also, Table 6 shows the results of semantic classification.
In par-ticular, the system often confuses protein with DNA, and cell line with cell type.Among the correctly identified 7,093 terms, 790 terms were misclassified.Table 7 shows the performance of each phase.
Our system obtains 76.88%F-score in the boundary detection task and, using 100% correctly recognizedterms from annotated test data, 90.54% F-score in the semantic classificationtask.
Currently, since we cannot directly assess the accuracy of the term detectionprocess on the evaluation set because of other class words, the 75% of the trainingdata were used for training and the rest for testing.Table 5.
Overall performance on the evaluation dataFully Correct Left Correct Right CorrectClass Recall Precision F-score F-score F-scoreprotein 76.30 69.71 72.85 77.60 79.15DNA 67.80 64.91 66.33 68.36 74.57RNA 73.73 63.04 67.97 71.09 74.22cell line 57.40 54.88 56.11 59.04 65.69cell type 70.12 77.64 73.69 74.89 81.51overall 72.77 69.68 71.19 74.75 78.23Table 6.
Confusion matrix over evaluation datagold/sys protein DNA RNA cell line cell type otherprotein 0 72 3 1 4 267DNA 97 0 0 0 0 49RNA 11 0 0 0 0 0cell line 10 1 0 0 63 37cell type 21 0 0 92 0 57Two-Phase Biomedical Named Entity Recognition 655Table 7.
Performance of term detection and semantic classificationRecall Precision F-scoreterm detection (MEMarkov) 74.03 75.31 74.67term detection (CRF) 76.14 77.64 76.88semantic classification 87.50 93.81 90.54overall NER 72.77 69.68 71.19Table 8.
Performance of NE recognition methods (one-phase vs. two-phase)method Recall Precision F-scoreone-phase 64.23 63.13 63.68two-phase(baseline2) 66.24 64.54 65.38(only 5 classes)two-phase(baseline2) 68.51 67.58 68.04(5 classes+other class)Also, we compared our model with the one-phase model.
The detailed resultsare presented in Table 8.
Both of them have pros and cons.
The best-reportedsystem presented by [13] uses one-phase strategy.
In our evaluation, the two-phase method shows a better result than the one-phase method, although directcomparison is not possible since we tested with a maximum entropy based expo-nential models in all cases.
The features for one-phase method are identical withthe recognition features except that the local context of a word is extended asprevious 4 words and next 4 words.
In addition, we investigate whether the con-sideration of ?other?
class words is helpful in the recognition performance.
Table8 shows explicit annotations of other NE classes much improve the performanceof existing entity types.In the next experiment, we test how individual methods have an effect on theperformance in the term detection step.
Table 9 shows the results obtained by com-bining different methods in the NER process.
At the semantic labeling phase, allmethods employed the ME model using the features described in 2.3.
Baseline1is the two-phase ME model which restrict the inspection of NE candidates to theNPs which include at least one biomedical salient word.
Baseline2 is the two-phaseME model considering all words.
In order to retrieve domain salient words, weutilized a relative frequency ratio of word distribution in the domain corpus andthat in the general corpus [10].
We used the Penn II raw corpus as out-of-domaincorpus.
Both models do not use the features related to previous labels.
As a re-sult, usage of salient words decrease the performance and it only speeds up thetraining process.
Baseline2+FST indicates boundary extension/contraction usingFST are applied as postprocessing step in baseline2 recognition.
In addition, wecompared use of CRFs and ME with Markov process features.
For this, we addedfeatures of previous labels to the feature set for ME.
Baseline2+MEMarkov is thetwo-phase ME model considering all features including previous label related fea-tures.
Baseline2+CRF is a model exploiting CRFs and baseline2+CRF+FST is amodel using CRFand FST as postprocessing.As shown in Table 9, the CRFs based656 S. Kim et alTable 9.
F-score for different methodsMethod Recall Precision F-scorebaseline1(salientNP ) 66.21 66.34 66.27baseline2(all) 68.51 67.58 68.04baseline2 + FST 68.89 68.53 68.71baseline2 + MEMarkov 70.30 67.65 68.95baseline2 + MEMarkov + FST 70.61 68.40 69.49baseline2 + CRF 72.44 68.77 70.56baseline2 + CRF + FST 72.77 69.68 71.19Table 10.
Comparisons with other systemsSystem Precision Recall F-scoreZhou et.
al (2004) 69.42 75.99 72.55Our system 72.77 69.68 71.19Finkel et.
al (2004) 71.62 68.56 70.06Settles (2004) 70.0 69.0 69.5model outperforms the ME based model.
Our system reached F-score 71.19% onthe baseline2 + CRF + FST model.Table 10 shows the comparison with top-ranked systems in JNLPBA 2004shared task.
The top-ranked systems made use of external knowledge fromgazetteers and abbreviation handling routines, which were reported to be ef-fective.
Zhou et.
al reported the usage of gazetteers and abbreviation handlingimproves the performance of the NER system by 4.8% in F-score [13].
Finkelet.
al made use of a number of external resources, including gazetteers, web-querying, use of the surrounding abstract, abbreviation handling, and frequencycounts from BNC corpus [4].
Settles utilized semantic domain knowledge of 17kinds of lexicons [11].
Although the performance of our system is a bit lower thanthe best system, the results are very promising since most systems use externalgazetteers, and abbreviation and conjunction/disjunction handling scheme.
Thissuggests areas for further work.5 Conclusion and DiscussionWe presented a two-phase biomedical NE recognition model, term boundarydetection and semantic labeling.
We proposed two exponential models for eachphase.
That is, CRFs are used for term detection phase including Markov processand ME is used for semantic labeling.
The benefit of dividing the whole processinto two processes is that, by separating the processes with different characteris-tics, we can select separately the discriminative feature set for each subtask, andmoreover measure effectiveness of models at each phase.
Furthermore, we usethe rule-based method as postprocessing to refine the result.
The rules are ex-tracted from the GENIA corpus, which is represented by the deterministic FST.The rule-based approach is effective to correct errors by cascading structuresTwo-Phase Biomedical Named Entity Recognition 657of biomedical NEs.
The experimental results are quite promising.
The systemachieved 71.19% F-score without Gazetteers or abbreviation handling process.The performance could be improved by utilizing lexical database and testingvarious classification models.AcknowledgementsThis work was supported by Korea Research Foundation Grant, KRF-2004-037-D00017.References1.
Thorten Brants.
TnT A Statistical Part-of-Speech Tagger.
In Proceedings of the6th Applied Natural Language Processing.
; 2000.2.
Stanley F. Chen and Ronald Rosenfeld.
A Gaussian prior for smoothing maximumentropy models.
Technical Report CMUCS-99-108, Carnegie Mellon University.3.
Nigel Collier, Chikashi Nobata and Jun-ichi Tsujii.
Extracting the Names of Genesand Gene Products with a Hidden Markov Model.
In Proceedings of COLING 2000;201-207.4.
Jenny Finkel, Shipra Dingare, and Huy Nguyen.
Exploiting Context for BiomedicalEntity Recognition From Syntax to thw Web.
In Proceedings of JNLPBA/BioNLP2004; 88-91.5.
K. Fukuda, T. Tsunoda, A. Tamura, and T. Takagi.
Toward information extrac-tion: identifying protein names from biological papers.
In Proceedins of the PacificSymposium on Biocomputing 98; 707-718.6.
Junichi Kazama, Takaki Makino, Yoshihiro Ohta and Junichi Tsujii.
Tuning Sup-port Vector Machines for Biomedical Named Entity Recognition, Proceedings of theACL Workshop on Natural Language Processing in the Biomedical Domain 2002;1-8.7.
Michael Krauthammer and Goran Nenadic.
Term Identification in the Biomedicalliterature.
Journal of Biomedical Informatics.
2004; 37(6):512-526.8.
John Lafferty, Andrew McCallum, and Fernando Pereira.
Conditional RandomFields: probabilistic models for segmenting and labeling sequence data.
In Proceed-ings of ICML-01; 282-289.9.
Ki-Joong Lee, Young-Sook Hwang, Seonho Kim, Hae-Chang Rim.
Biomedicalnamed entity recognition using two-phase model based on SVMs.
Journal ofBiomedical Informatics 2004; 37(6):436-447.10.
Kyung-Mi Park, Seonho Kim, Ki-Joong Lee, Do-Gil Lee, and Hae-Chang Rim.Incorportating Lexical Knowledge into Biomedical NE Recognition.
In Proceedingsof Natural Language Processing in Biomedicine and its Applications Post-COLINGWorkshop 2004; 76-79.11.
Burr Settles.
Biomedical Named Entity Recognition Using Conditional RandomFields and Rich Feature Sets.
In Proceedings of JNLPBA/BioNLP 2004; 104-107.12.
Olivia Tuason, Lifeng Chen, Hongfang Liu, Judith A. Blake, Carol Friedman.
Bi-ological Nomenclatures: A Source of Lexical Knowledge and Ambiguity.
In PacificSymposium on Biocomputing 2004; 238-249.13.
GuoDong Zhou, Jie Zhang, Jian Su, Chew-Lim Tan.
Exploring Deep KnowledgeResources in Biomedical Name Recognition.
In Proceedings of JNLPBA/BioNLP2004; 99-102.
