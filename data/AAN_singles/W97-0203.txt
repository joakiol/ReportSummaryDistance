Desiderata for Tagging with WordNet Synsets or MCCA CategoriesKenneth C. LitkowskiCL Research20239 Lea Pond PlaceGaithersburg, MD 20879(Email: ken@tires.corn)(Web site: http://www.clres.com)1 AbstractMinnesota Contextual Content Analysis(MCCA) is a technique for characterizing theconcepts and themes occurring in text(sentences, paragraphs, interview transcripts,books).
MCCA tags each word with acategory and examines the distribution ofcategories against norms representing generalusage of categories.
MCCA also scores textsin terms of social contexts that are similar todifferent functions of language.
Distributionscan be analyzed using non-agglomerativeclustering to characterize the concepts andthemes.
MCCA categories have been mappedto WordNet senses.
The &finingcharacteristics that emerge from the mappingand the statistical techniques used in MCCAfor analyzing concepts and themes suggestthat tagging with WordNet synsets or MCCAcategories may produce piphenomenal resultsthat are misleading.
We suggest that WordNetsynsets and MCCA categories be augmentedwith further lexical semantic information foruse after text is tagged or categorized.
Wesuggest hat such information is useful notonly for the primary purposes ofdisambiguation in parsing and textclassification in content analysis andinformation retrieval, but also for tasks incorpus analysis, discourse analysis, andautomatic text summarization.2 IntroductionContent analysis provides distributional methods foranalyzing characteristics of textual material.
Its rootsare the same as computational linguistics (CL), but ithas been largely ignored in CL until recently (Dunning,1993; Carletta, 1996; Kilgarriff, 1996).
One contentanalysis approach, Minnesota Contextual ContentAnalysis (MCCA)  (McTavish & Pirro, 1990), in use forover 20 years and with a well-developed dictionarycategory system, contains analysis methods that provideinsights into the use of WordNet (Miller, et al, 1990)for tagging.We describe the unique characteristics of MCCA,  howits categories relate to WordNet synsets, the analysismethods used in MCCA to provide quantitativeinformation about texts, what implications this has forthe use of WordNet in tagging, and how thesetechniques may contribute to lexical semantic tagging.Specifically, we show that WordNet provides abackbone, but that additional lexical semanticinformation needs to be associated with WordNetsynsets.
We describe novel perspectives on how thisinformation can be used in various NLP tasks.3 Minnesota Contextual Content AnalysisMCCA differs from other content analysis techniquesin using a norm for examining the distribution of itscategories in a given text.
The 116 categories used inthe dictionary to characterize words) like other contentanalysis category systems, are heuristic in nature.
Eachcategory has a name (e.g., activiO~, fellow feeling, aboutchanging, human roles, expresaion arena).The distinguishing characteristic of MCCA is that theemphasis of each category is normed in two ways.Categories that are emphasized in a text (E-scores) arenormed against expected general usage of categoriesbased on the Brown corpus (Kucera & Francis, 1967).The second way is based on relative usage of categoriesexpected in four broad institutional areas.
The latter isbased on some initial research and subsequent workwhich essentially factor-analyzed profiles of categoryusage for texts representing a broad range oforganizations and social situations (Cleveland, et al,1974).
These are referred to as context scores(C-scores) and labelled traditional (judicial andreligious texts),practical (business texts), emotional(leisure, recreational, and fictional texts), and analytic1A word may have more than one category and isdisambignated in tagging.121Iinmmmnnimnnmimmmmiim(scientific writings).
These contexts correspond well tothe functions of language (Nida, 1975: 201-5).After tagging a text and determining categoryfi'equencies, the C-scores are calculated by comparisonwith the expected istribution of the contexts and theE-scores are calculated by comparison with theexpected istribution of each category.
2 These are thequantitative bases for analysis of the concepts andthemes.Unlike other techniques for determining which wordsare characteristic ofa text (Kilgm'riff, 1996), such as thex'-test and mutual information, the C-scores andE-scores are examined not only for differences amongtexts, but also for over- and under-emphasis against thenorms.
This provides greater sensitivity to the analysisof concepts and themes.4 MCCA Categories andWordNet Synsets(McTavish, et al, 1995) and (2?IcTavish, et al, 1997)suggest hat MCCA categories recapitulate WordNetsynsets.
We used WordNet synsets in examiningMCCA categories to determine their coherence, tocharacterize their relations with WordNet, and tounderstand the si~ificance of these relations in theMCCA analysis of concepts and themes and in taggingwith WordNet synsets.In the MCCA dictionary of I 1,000 words, s the averagenumber of words in a category is 95, with a range fromI to about 300.
Using the D IMAP soRware (CLResearch, 1997 - in preparation), ~ we createdsublexicons of individual categories, extractedWordNet synsets for these sublexicons, extracted2Disambiguation is based on a running context score.Each category has a frequency of occurrence in acontext.
The category selected for an ambiguousword is the one with the smallest difference from therunning context score.3This dictionary has tagged 85 to 95 percent of thewords in about 1500 analyses covering 45 m/Ilionwords over the last 15 years.4A suite of programs for creating and maintaininglexicons for natural language processing, availablefrom CL Research.
Procedures used in this paper,applicable to any category analysis using DIMAP, areavailable at http:I/www.clres.com.
The generalprinciples of category development followed in theseprocedures are described in (Litkowski, in preparation).information from the Merriam-Webster ConciseElectronic Dictionary integrated with DIMAP, andattached lexical semantic information from otherresources to entries in these sublexicons.We began with the hypothesis that the categoriescorrespond to those developed by (Hearst & Sch0tze,1996) in creating categories from the WordNet nounhierarchy.
We found that the MCCA categories weregenerally internally consistent, but with characteristicsnot intuitively obvious) As a result, we needed toarticulate firm principles for characterizing thecategories.Eleven categories (such as Have, Prepositions, You, l--Me, He, A-An, The) consist of only a few words fromclosed classes.
The category The contains one wordwith an average expected fiequency of 6 percent (witha range over the four contexts of 5.5 to 6.5).
Thecategory Prepositions contains 18 words with anaverage expected fi'equency of I I.I percent (with arange over the four contexts of 9.5 to 12.3 percent).About 20 categories (Implication, If, Colors, Object,Being) consist of a relatively small number of words(34, 22, 65, I I, 12, respectively) taken primarily fromsyntactically or semantically closed-class words(subordinating conjunctions, relativizers, the tops ofWordNet, colors).The remaining 80 or so categories consist primarily ofopen-class words (nouns, verbs, adjectives, andadverbs), sprinkled with closed-class words (auxiliaries,subordinating conjunctions).
These categories requiremore detailed analyses:Several categories correspond well to the Hearst &SchOtze model.
The categories Functional roles,Detached roles, and Human roles align with subtreesrooted at particular nodes in the WordNet hierarchies.For exRmple, Detached ro/es has a total of 66 words,with an average xpected fi-equency of.16 percent anda range fi'om .10 to .35 percent.
The .35 percentfrequency is for the ana~#c ontext; each of the otherthree contexts have expected fi'equencies of about.
10percent.
The words in this category include:ACADEMIC, ARTIST, BIOLOGIST, CREATOR, CRITIC,HIffIDRIAN, INSTRUCTOR, OBSERVER, PHILOSOPHER,Sin general, we have found that assignment of onlyabout 5 to 10 percent of the words in a category isquestionable.6Analysis of MCCA categories i a continuing process.13PHYSICIST, PROFESSOR, RESEARCHER, REVIEWER,SCIENTIST, SOCIOLOGISTThese words are a subset of the WordNet synsetsheaded at PERSON, in particular, s)n~sets headed byCREATOR;EXPERT: AUTHORITY: PROFESSION/~,INTELLECTUAL.
7Other synsets under EXPERT and AlYrI-IORITY do not fallinto this category.
Thus, the heuristic Detached rolesis like a Hearst & SchCttze super-category, but notconstructed on a statistical metric, rather on underlyingsemantic components.Other categories do not fall out so neatly.
The categorySanction (120 words) has an average expectedfrequency of .08 percent, with a range over the fourcontexts of.06 to .10 percent.
It includes the followingwords (and their inflected forms):APPLAUD, APPLAUSE, APPROVE, CONGRATUI.ATE,CONGRATULATION, CONVICT, CONVICTION,DISAPPROVAL, DISAPPROVE, HONOR, JUDGE,JUDGMENT, JUDGMENTAL, MERIT, MISTREAT,REJECT, RF_JECTION, RIDICULE, SANCTION, SCORN,SCORNFUL, SHAME, SHAMEFULLYExamination of the WordNet symets is similarlysuccessful here, identifying many words (particularlyverbs) in a subtrce rooted at RJDOE.
However, the setis defined as well by including a dcrivational lexicalrule to allow forms in other parts of speech.
Anothermeaning component is seen in APPROVE andDISAPPROVE, namely, the negative or pejorative prefix,again requiring a lexical rule as part of the category'sdefinition.
Such lexical rules would be encoded asdescribed in (Copcstake & Briscoe, 199 I).
This set ofwords (rooted primarily in the verbs of the set)corresponds to the (Levin, 1993) Characterize (class29.2), Declare (29.4), Admire (31.2), and Judgmentverbs (33) and hence may have particular syntactic andsemantic patterning.
The verb flames attached toWordNet verb synsets are not sufficiently detailed tocover the granularity necessary to characterize anMCCA category.
Instead, the definition of this classmight, following (Davis, 1996), inherit a sort notion-rel, which has a "perceiver" and a "perceived"argument (thus capturing syntactic patterning) with71dentification of these synscts facilitates extension ofthe MCCA dictionary to include further hyponyms ofthese symets.perhaps a selectional restriction on the "perceiver" thatthe type of action is an evaluative one (thus providingsemantic patterning).Another complex category is Normaave, consisting of76 words, with an average expected frequency of .60percent and a range over the four contexts of.37 to .79percent.
This category also has words fi'om all parts ofspeech and thus will entail the use of derivationallexical rules in its definition.
This category includesthe following (along with various inflectional forms):ABSOLUTE, ABSOLUTELY, CONSEQUENCE,CONSEQUENTLY, CORRECT, CORRECTLY,DOGMATISM, HABITUAL, HABITUALLY,IDEOI.DGICALLY, IDEOLOGY, NECESSARILY,NECESSARY, NORM, OBVIOUSLY, PROMINENT,PROMINENTLY, REOULARITY, REGULARLY,UNEQUIVOCALLY, UNUSUAL, UNUSUALLYThe use of the heuristic Normatiw to label this categoryclearly reflects the presence in these words of asernRntic omponent oriented around characterizingsomething in terms of expectations.
But, of particularinterest here, are the adverb forms.
McTavish has alsoused the heuristic Reasoning for this category.
Theseadverbs are content disjuncta (Quirk, et al, 1985:8.127-33), that is, words betokening a speaker'scomment on the content of what he speaker is saying,in this case, compared to some norm or standard.
Thus,part of the defining characteristics for this category is aspecification for lexical items that have a \[content-disjunct +\] feature.These examples of words in the Sanction andNormaave categories (repeated in other categories)indicates a need to define categories not only in termsof supercategories using the Hearst & Schtze model,but also with additional lexical semantic informationnot present in WordNet or MCCA categories.
Inparticular, we se?
the need for encoding derivationaland morphological relations, finer-grainedcharacterization of government patterns, featurespecifications, and primitive semantic components.In any event, we have seen that MCCA categories areconsistent with WordNet synsets.
They recapitulate heWordNet synsets by acting as supemategories similar tothose identified in Hearst & Sch(ltze.
To this extent,results from MCCA tagging would be similar to thoseof Hearst & Schtttze.
The MCCA methods uggestfurther insights based on what purposes we are trying toachieve from tagging.14mmmmmmmimmmmmUmmm5 Analysis of Tagged TextsThe important questions at this point are why there isvalue in having additional lexical semantic informationassociated with tagging and why MCCA categories andWordNet synsets are insufficienL The answer to thesequestions beans to emerge by considering the furtheranalysis performed after a text has been "classified" onthe basis of the MCCA tagging.
As described above,MCCA produces a set of C-seores and E-scores foreach text.
These scores are then subjected to analysisto provide additional results useful in social seience andinformation retrieval applications.The two sets of scores are used for computing thedistance among texts.
This distance is used directly orin exploration of the differences between texts.
Unlikeother content analysis techniques (or classificationtechniques used for measuring the distance betweendocuments in information retrieval), MCCA uses thenon-agglomerative technique of multidimensionalsealing (MDS).
s This technique (Kruskal & Wish,1977) produces a map when given a matrix ofdistances.MDS does not presume that a 2-climensionalrepresentation displays the distances between texts.Rather, it unfolds the dimensions one-by-one, startingwith 2, examines statistically how "stressed" thesolution is, and then adds furthor dim~asions until thestress shows signs of reaching an asymptote.
Outputfrom the sealing provides "rotation" maps at eachdimension projected onto 2-dimensional space.McTavish, et al illustrates the simple and the morecomplex use of these distance metrics.
In the simpleuse, the distance between transcripts of nursing homepatients, staff, and administrators was used as ameasure of social distance among these three groups.This measure was combined with variousch~terist/cs of nursing homes (size, type, location,etc.)
for further analysis, using standard statisticaltechniques such as correlation and diseriminantanalysis.In the more complex use, the MDS results identify theconcepts and themes that are different and similar in thetranscripts.
This is accomplished by visually inspectingthe MDS graphical output.
Examination of the 4-8Agglomerative techniques cluster the two closesttexts (with whatever distance metric) and thensuccessively add texts one-by-one as they are closestto the existing cluster.dimensional context vectors provides an initialcharacterization of the texts.
The analyst identifies thecontextual focus (traditional, practical, emotional, oranMytic) and the ways in which the texts differ fromone another.
This provides general themes and pointersfor identifying the conceptual differences among thetexts.MDS analysis of the E-score vectors identifies themajor concepts that differentiate the texts.
The analystexamines the graphical output to label points with thedominant MCCA categories.
The "meaning" (that is,the underlying concepts) of the MDS graph is thendescribed in terms of category and word emphases.These are the results an investigator uses in reportingon the content analysis using MCCA.This is the point at which the insufficieney of MCCAcategories (and WordNet synsets) becomes visible.
Inexamining the MDS output, the analysis is subjectiveand based only on identification of particular sets ofwords that distinguish the concepts in each text (muchlike the techniques described in (I~lgamff, 1996) thatare used in authorship attribution).
If the MCCAcategories had richer definitions based on additionallexical semantic information, the analysis could beperformed based on less subjective and more rigorouslydefined principles.
(Burstein, et al, 1996) describe techniques for usinglexical semantics to classify responses totest questions.An essential component of this classification process isthe identification of sublc',dcens that cut across parts of~h,  along with conc,~t grammars based oncollapsing phrasal and constituent nodes into ageneralized XP  representation.
As seen above in theprocedures for defining MCCA categories, addition oflexical semantic information in the form of derivationaland morphological relations and semantic componentscommon across part of speech boundaries--informationnow lacking in WordNet synsets--would facilitate thedevelopment ofconcept grammars.
(Briscoe & Carroll, 1997) describe novel techniquesfor constructing a subcategorization dictionary fromanalysis of corpora.
They note that their system needsfurther refinement, suggesting that adding informationto lexical entries about diathesis alternation possibilitiesand semantic selectional preferences on argument headsis likely to improve their results.
Again, the proceduresfor analyzing MCCA categories seem to require thistype of information.We have diseussed elsewhere (Litkowski & Harris,1997) extension of a discourse analysis algorithm15incorporating lexical cohesion l:,rinciples.
In thisextension, we found it necessary to require use of theAGENTIVE and CONSTITLrHVE qtmlia of nouns (see(Pustejovsky, 1995: 76)) as selectional specifications onverbs to maintain lexical cohesion.
With suchinformation, we were able not only to provide a morecoherent discourse analysis of a text segment, but alsopossibly to summarize the text better.6 Discussion and Future WorkWe have shown how MCCA categories generallyrecapitulate WordNet synsets and how MCCA analysisleads to thematic and conceptual characterization oftexts.
Since MCCA categories do not exactlycorrespond to WordNet subtrees, but frequentlyrepresent a bundle of syntactic and semantic properties,we believe that the tagging results are epiphenomenal.Since the MCCA results eem more robust han taggingwith WordNet synsets (q.v.
(Voorhees, 1994)), wesuggest that this is due to more specific meaningcomponents underlying the MC C A categories.
('Nida, 1975: 174) characterized a semantic domain asconsisting of words sharing semantic components.However, he also suggests (Nida, 1975: 193) thatdomains represent an arbitrary grouping of theunderlying semantic features.
We suggest hat theMCCA categories and WordNet synsets represent twosuch systems of domains, each reflecting particularperspectives.This suggests that categorical systems used for taggingneed to be augmented with more precise lexicalsemantic information.
This information can besemantic features, semantic roles, subeategorizationpatterns, syntactic alternations (e.g., see (Don', inpress)), and semantic omponents.
We suggest that theuse of this lexical semantic information in tagging mayprovide considerable benefit in analyzing taggingresults.We are continuing analysis of the MCCA categories tocharacterize them in terms of lexical semanticinformation.
We are using a variety of lexicalresources, including WordNet, the database by (Doff,in press) based on (Levin, 1993), and COMLEX(Maeleod & Grishrnan, 1994; Wolff, et al, 1995).
Wewill propagate these meaning components othe lexicalitems.After automating the MDS analysis, we will examinethe extent o which the lexical semantic information iscorrelated with the thematic analyses.
We hypothesizethat the additional information will provide greatersensitivity for characterizing the concepts and themes.7 AcknowledgmentsI would like to thank Don McTavish, Thomas Potter,Robert Amsler, Mary Dee Harris, some WordNet folks(George Miller, Shari Landes, and Randee Tengi),Tony Davis, and anonymous reviewers for theirdiscussions .and comments on issues relating to thispaper and its initial draft.8 ReferencesBriscoe, T., & Carroll, 3.
(1997).
Automatic extractionof subcategorization from corpora.
5th Conferenceon Applied Natural Language Processing.Washington, DC: Association for ComputationalLinguistics.Burstein, J., Kaplan, R., Wolff, S., & Lu, C. (1996,June).
Using Icxical semantic informationtechniques to classify free responses.
In E. Viegas& M. Palmer (Eds.
), Breadth and Depth ofSemantic Lexicons.
Workshop Sponsored by theSpecial Interest Group on the Lexicon.
Santa Cruz,CA: Association for Computational Linguistics.Carletta, J.
(1996).
Assessing agreement onclassification tasks: The Kappa statistic.Computational Linguistics, 22(2), 249-254.CL Research.
(1997 - in preparation).
DIMAP-3 user~manual.
Gaithersburg, MD.Cleveland, C. E., McTavish, D. G., & Pirro, E.
B.
(1974, September 5-13).
Contextual contentanalysis.
ISSC/CISS Workshop on ContentAnalysis In the Social Sciences.
Pisa, Italy:Standing Committee on Social Science Data of theInternational Social Science Council, UNESCO,Centrol Nazionalc Universitario de CalcoloEleettronico (CUNCE).Copestake, A.
A., & Briscoe, E. J.
(1991, June 17).Lexical operations in a unification-basedframework.
ACL  SIGLEX Workshop on LexicalSemantics and Knowledge Representation.Berkeley, CA: Association for ComputationalLinguistics.Davis, A. R. (1996).
Lex/cal semantics and linking inthe hierarchical lexicon \[diss\], Stanford, CA:Stanford University.Dorr, B.
(in press).
Large-scale dictionary constructionfor foreign language tutoring and interlingualmachine translation.
Journal of MachineTranslation.Dunning, T. (1993).
Accurate methods for the statisticsof surprise and coincidence.
ComputationalLinguistics, 19(1 ), 61-74.mmmmmmmmmmm16Hearst, M. A., & Schotze, H. (1996).
Cnstowizing alexicon to better suit a computational task.
In B.Boguraev & J. Pustejovsky (Eds.
), Corpusprocessing for lexical acquisition (pp.
77-96).Cambridge, MA: The MIT Press.Kilgarriff, A.
(1996, April).
Which words areparticularly characteristic of a text?
A survey ofstatistical approaches.
European Conference onArtificial Intelligence.Kruskal, J.
B., & Wish, M. (1977).
Multidimensionalscaling.
Beverly Hills, CA: Sage Publications.Kucera, H., & Francis, W. H. (1967).
Computerizeddictionary of present-day American English.Providence, RI: Brown University Press.Levin, B.
(1993).
English verb classes andalternations: A preliminary investigation.Chicago, IL: The University of Chicago Press.Litkowski, K. C. (in preparation).
Categorydevelopment based on semantic principles.
SocialScience Computer Review.Litkowski, K. C., & Harris, lvt D. (1997).
Categorydevelopment using complete semantic networks.Gaithersburg, MD: CL Research.Macleod, C., & Grishman, R. (1994).
COMLEXsyntaxreference manual.
Philadelphia, PA: LinguisticData Consortium, University of Pennsylvania.McTavish, D. G., Litkowski, K. C., & Schrader, S.(1995, September).
A computer content analysisapproach to measuring social distance inresidential organizations for older people.
Societyfor Content Analysis by Computer.
Mannheim,Gemumy.McTavish, D. G., Litkowski, K. C., & Schrader, S.(1997).
A computer content analysis approach tomeasuring social distance in residentialorganizations for older people.
Social ScienceComputer Review, in press.McTavish, D. O., & Pin'o, E. B.
(1990).
Contextualcontent analysis.
Quality & Quantity, 24, 245-265.Miller, G. A., Beekwith, R., Fellbatma, C., Gross, D., &Miller, K. J.
(1990).
Introduction to WordNet: Anon-line lexical database.
International Journal ofLexicography, 3(4), 235-244.Nida, E. A.
(1975).
Componential analysis of meaning.The Hague: Mouton.Pustejovsky, J.
(1995): The generative lexicon.Cambridge, MA: The MIT Press.Quirk, R., Oreenbaum, S., Leech, O., & Svartik, J.(1985).
A comprehensive grammar of the Englishlanguage.
London: Longman.Voorhees, E. M. (1994, July 3-6).
Query expansionusing lexieal-semantie relations.
In W. B. Croft &C. J. van Rijsbergen (F.~ls.
), Proceedings of the17th Annual lnternational ACM-SIG1R Conferenceon Research and Development i  InformationRetrieval (pp.
61-69).
Dublin, Ireland:Springer-Verlag.Wolff, S. R., Macleod, C., & Meyers, A.
(1995).COMLF_~ word classes.
Philadelphia, PA:Linguistic Data Consortium, University ofPennsylvania.17
