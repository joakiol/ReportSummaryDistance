Homonymy and Polysemy in Information RetrievalRober t  K rovetzNEC Research Institute"4 Independence WayPrinceton, NJ.
08540krovetz@research.nj.nec.comAbst rac tThis paper discusses research on distin-guishing word meanings in the context ofinformation retrieval systems.
We conduc-ted experiments with three sources of evid-ence for making these distinctions: mor-phology, part-of-speech, and phrases.
Wehave focused on the distinction betweenhomonymy and polysemy (unrelated vs. re-lated meanings).
Our results support theneed to distinguish homonymy and poly-semy.
We found: 1) grouping morpholo-gical variants makes a significant improve-ment in retrieval performance, 2) that morethan half of all words in a dictionary thatdiffer in part-of-speech are related in mean-ing, and 3) that it is crucial to assign creditto the component words of a phrase.
Theseexperiments provide a better understandingof word-based methods, and suggest wherenatural language processing can providefurther improvements in retrieval perform-ance.1 IntroductionLexical ambiguity is a fundamental problem in nat-ural language processing, but relatively little quant-itative information is available about the extent ofthe problem, or about the impact that it has on spe-cific applications.
We report on our experiments toresolve lexical ambiguity in the context of informa-tion retrieval (IR).
Our approach to disambiguationis to treat the information associated with dictionaryThis paper is based on work that was done at theCenter for Intelligent Information Retrieval at the Uni-versity of Massachusetts.
It was supported by the Na-tional Science Foundation, Library of Congress, andDepartment of Commerce raider cooperative agreementnumber EEC-9209623.
I am grateful for their support.senses (morphology.
part of speech, and phrases) asmultiple sources of evidence.
1 Experiments were de-signed to test each source of evidence independently,and to identify areas of interaction.
Our hypothesisis:Hypothes is  1 Resolving lexical ambiguity will leadto an improvement in retrieval performance.There are many issues involved in determininghow word senses should be used in information re-trieval.
The most basic issue is one of identity - -what is a word sense?
In previous work, research-ers have usually made distinctions based on theirintuition.
This is not satisfactory for two reasons.First, it is difficult to scale up; researchers have gen-erally focused on only two or three words.
Second,they have used very coarse grained distinctions (e.g.,'river bank' v. 'commercial bank').
In practice it isoften difficult to determine how many senses a wordshould have, and meanings are often related (Kilgar-rift 91).A related issue is sense granularity.
Dictionar-ies often make very fine distinctions between wordmeanings, and it isn't clear whether these distinc-tions are important in the context of a particularapplication.
For example, the sentence They dancedacross the lvom is ambiguous with respect to theword dance.
It can be paraphrased as They wereacross the room and they were dancing, or as Theycrossed the tvom as they danced.
The sentence isnot.
ambiguous in Romance languages, and can onlyhave the former meaning.
Machine translation sys-t.ems therefore need to be aware of this ambiguity andtranslate the sentence appropriately.
This is a sys-tematic class of ambiguity, and applies to all "verbsof translatory motion" (e.g., The bottle floated ~mderthe bridge will exhibit the same distinction (Talmy85)).
Such distinctions are unlikely to have an im-pact on information retrieval.
However, there are1We used the Longman Dictionary as our source ofinformation about word senses (Procter 78).
"/2also distinctions that are important in informationretrieval that are unlikely to be important in ma-chine translation.
For example, the word west canbe used in the context the East versus the West, or inthe context West Germany.
These two senses werefound to provide a good separation between relevantand non-relevant documents, but the distinction isprobably not important for machine translation.
Itis likely that different applications will require differ-ent types of distinctions, and the type of distinctionsrequired in information retrieval is an open question.Finally, there are questions about how word sensesshould be used in a retrieval system.
In general,word senses should be used to supplement word-based indexing rather than indexing on word sensesalone.
This is because of the uncertainty involvedwith sense representation, and the degree to whichwe can identify a particular sense with the use of aword in context.
If we replace words with senses, weare making an assertion that we are very certain thatthe replacement does not lose any of the informationimportant in making relevance judgments, and thatthe sense we are choosing for a word is in fact cor-rect.
Both of these are problematic.
Until more islearned about sense distinctions, and until very ac-curate methods are developed for identifying senses,it is probably best to adopt a more conservative ap-proach (i.e., uses senses as a supplement to word-based indexing).The following section will provide an overview oflexical ambiguity and information retrieval.
Thiswill be followed by a discussion of our experiments.The paper will conclude with a summary of what hasbeen accomplished, and what work remains for thefuture.2 Lex ica l  Ambigu i ty  andIn fo rmat ion  Ret r ieva l2.1 BackgroundMany retrieval systems represent documents andqueries by the words they contain.
There are twoproblems with using words to represent he contentof documents.
The first problem is that words areambiguous, and this ambiguity can cause documentsto be retrieved that are not relevant.
Consider thefollowing description of a search that was performedusing the keyword "AIDS':Unfortunately, not all 34 \[references\] wereabout AIDS, the disease.
The referencesincluded "two helpful aids during the firstthree months after total hip replacemenC,and "aids in diagnosing abnormal voidingpatterns".
(Helm 83)One response to this problem is to use phrasesto reduce ambiguity (e.g., specifying "hearing aids"if that is the desired sense).
It is not always pos-sible, however, to provide phrases in which the wordoccurs only with the desired sense.
In addition, therequirement for phrases imposes a significant burdenon the user.The second problem is that a document can berelevant even though it does not use the same wordsas those that are provided in the query.
The useris generally not interested in retrieving documentswith exactly the same words, but with the conceptsthat those words represent.
Retrieval systems ad-dress this problem by expanding the query words us-ing related words from a thesaurus (Salton and Mc-Gill 83).
The relationships described in a thesaurus,however, are really between word senses rather thanwords.
For example, the word "term" could be syn-onymous with 'word' (as in a vocabulary term), "sen-tence' (as in a prison term), or "condition' (as in'terms of agreement').
If we expand the query withwords from a thesaurus, we must be careful to usethe right senses of those words.
We not only haveto know the sense of the word in the query (in thisexample, the sense of the word "term'), but the senseof the word that is being used to augment it (e.g., theappropriate sense of the word 'sentence') (Chodorowet al88).2.2 Types  o f  Lexlcal  Ambigu i tyLexical ambiguity can be divided into homonymyand polysemy, depending on whether or not themeanings are related.
The bark of a dog versus thebark of a tree is an example of homonymy; review asa noun and as a verb is an example of polysemy.The distinction between homonymy and polysemyis central.
Homonymy is important because it sep-arates unrelated concepts.
If we have a query about"AIDS' (tile disease), and a document contains "aids"in the sense of a hearing aid, then the word aidsshould not contribute to our belief that the docu-ment is relevant o the query.
Polysemy is importantbecause the related senses constitute a partial repres-entation of the overall concept.
If we fail to grouprelated senses, it is as if we are ignoring some of theoccurrences of a query word in a document.
So forexample, if we are distinguishing words by part-of-speech, and the query contains 'diabetic' as a noun,the retrieval system will exclude instances in which'diabetic' occurs as an adjective unless we recognizethat the noun and adjective senses for that word arerelated and group them together.Although there is a theoretical distinction betweenhomonymy and polysemy, it is not always easy to tell73them apart in practice.
What determines whetherthe senses are related?
Dictionaries group sensesbased on part-of-speech and etymology, but as illus-trated by the word review, senses can be related eventhough they differ in syntactic ategory.
Senses mayalso be related etymologically, but be perceived asdistinct at the present ime (e.g., the "cardinal' of achurch and "cardinal' numbers are etymologically re-lated).
We investigated several methods to identifyrelated senses both across part of speech and withina single homograph, and these will be described inmore detail in Section 3.2.1.3 Exper iments  on  Word-SenseD isambiguat ion3.1 P re l iminary  Exper imentsOur initial experiments were designed to investigatethe following two hypotheses:Hypothes is  2 Word senses provide an effectiveseparation between relevant and non-relevant docu-ments.As we saw earlier in the paper, it is possible fora query about 'AIDS' the disease to retrieve docu-ments about 'hearing aids'.
But to what extent aresuch inappropriate matches associated with relevancejudgments?
This hypothesis predicts that sense mis-matches will be more likely to appear in documentsthat are not relevant han in those that are relevant.Hypothes is  3 Even a small domain-specific collec-tion of documents exhibits a significant degree of lex-ical ambiguity.Little quantitative data is available about lexicalambiguity, and such data as is available is often con-fined to only a small number of words.
In addition,it is generally assumed that lexical ambiguity doesnot occur very often in domain-specific text.
Thishypothesis was tested by quantifying the ambiguityfor a large number of words in such a collection, andchallenging the assumption that ambiguity does notoccur very often.To investigate these hypotheses we conducted ex-periments with two standard test collections, oneconsisting of titles and abstracts in Computer Sci-ence, and the other consisting of short articles fromTime magazine.The first experiment was concerned with determ-ining how often sense mismatches occur betweena query and a document, and whether these mis-matches indicate that the document is not relevant.To test this hypothesis we manually identified thesenses of the words in the queries for two collec-tions (Computer Science and Time).
These wordswere then manually checked against the words theymatched in the top ten ranked documents for eachquery (the ranking was produced using a probabil-istic retrieval system).
The number of sense mis-matches was then computed, and the mismatches inthe relevant documents were identified.The second experiment involved quantifying thedegree of ambiguity found in the test collections.
Wemanually examined the word tokens in the corpus foreach query word, and estimated the distribution ofthe senses.
The number of word types with morethan one meaning was determined.
Because of thevolume of data analysis, only one collection was ex-amined (Computer Science), and the distribution ofsenses was only coarsely estimated; there were ap-proximately 300 unique query words, and they con-stituted 35,000 tokens in the corpus.These experiments provided strong support forHypotheses 2 and 3.
Word meanings are highly cor-related with relevance judgements, and the corpusstudy showed that there is a high degree of lexicalambiguity even in a small collection of scientific text(over 40% of the query words were found to be am-biguous in the corpus).
These experiments provideda clear indication of the potential of word mean-ings to improve the performance of a retrieval sys-tem.
The experiments are described in more detailin (Krovetz and Croft 92).3.2 Exper iments  with di f ferent sources ofev idenceThe next set of experiments were concerned withdetermining the effectiveness of different sourcesof evidence for distinguishing word senses.
Wewere also interested in the extent with which adifference in form corresponded to a difference inmeaning.
For example, words can differ in mor-phology (authorize/authorized), or part-of-speech(diabetic \[noun\]/diabetic \[adj\]), or in their abil-ity to appear in a phrase (database/data base).They can also exhibit such differences, but rep-resent different concepts, such as author/authorize.sink\[noun\]/sink\[verb\], o  stone wall/stonewall.
Ourdefault assumption was that a difference in form isassociated with a difference in meaning unless wecould establish that the different word forms wererelated.3.2.1 L ink ing re la ted  word mean ingsWe investigated two approaches for relating senseswith respect to morphology and part of speech: 1)exploiting the presence of a variant of a term withinits dictionary definition, and 2) using the overlap ofthe words in the definitions of suspected variants.74For example, liable appears within the definition ofliability, and this is used as evidence that those wordsare related.
Similarly, flat as a noun is defined as "aflat tire', and the presence of the word in its owndefinition, but with a different part of speech, istaken as evidence that the noun and adjective mean-ings are related.
We can also compute the overlapbetween the definitions of liable and liability, andif they have a significant number of words in com-mon then that is evidence that those meanings arerelated.
These two strategies could potentially beused for phrases as well, but phrases are one of theareas where dictionaries are incomplete, and othermethods are needed for determining when phrasesare related.
We will discuss this in Section 3.2.4.We conducted experiments to determine the effect-iveness of the two methods for linking word senses.In the first experiment we investigated the perform-ance of a part-of-speech tagger for identifying therelated forms.
These related forms (e.g., fiat as anoun and an adjective) are referred to as instances ofzero-affix morphology, or functional shift (Marchand63).
We first tagged all definitions in the dictionaryfor words that began with the letter 'W'.
This pro-duced a list of 209 words that appeared in their owndefinitions with a different part of speech.
However,we found that only 51 (24%) were actual cases ofrelated meanings.
This low success rate was almostentirely due to tagging error.
That is, we had a falsepositive rate of 76% because the tagger indicated thewrong part of speech.
We conducted a failure ana-lysis and it indicated that 91% the errors occurred inidiomatic expressions (45 instances) or example sen-tences associated with the definitions (98 instances).We therefore omitted idiomatic senses and examplesentences from further processing and tagged therest of the dictionary.
2The result of this experiment is that the dictionarycontains at least 1726 senses in which the headwordwas mentioned, but with a different part of speech,of which 1566 were in fact related (90.7%).
We ana-lyzed the distribution of the connections, and this isgiven in Table 1 (n = 1566).However, Table 1 does not include cases in whichthe word appears in its definition, but in an inflectedform.
For example, 'cook' as a noun is defined as'a person who prepares and cooks food'.
Unless werecognize the inflected form, we will not capture all ofthe instances.
We therefore repeated the procedure,but allowing for inflectional variants.
The result isgiven in Table 2 (n = 1054).We also conducted an experiment o determine~Idiomatic senses were identified by the use of fontcodes.the effectiveness of capturing related senses via wordoverlap.
The result is that if the definitions for theroot and variant had two or more words in common ,393% of the pairs were semantically related.
However,of the sense-pairs that were actually related, two-thirds had only one word in common.
We foundthat 65% of the sense-pairs with one word in com-mon were related.
Having only one word in commonbetween senses is very weak evidence that the sensesare related, and it is not surprising that there is agreater degree of error.Tile two experiments, tagging and word overlap,were found to be to be highly effective once the com-mon causes of error were removed.
In the case oftagging the error was due to idiomatic senses and ex-ample sentences, and in the case of word overlap theerror was links due to a single word in common.
Bothmethods have approximately a 90% success rate inpairing the senses of morphological variants if thoseproblems are removed.
The next section will discussour experiments with morphology.3.2.2 Exper iments  wi th  Morpho logyWe conducted several experiments to determinethe impact of grouping morphological variants onretrieval performance.
These experiments are de-scribed in detail in (Krovetz 93), so we will onlysummarize them here.Our experiments compared a baseline (no stem-ming) against several different morphology routines:1) a routine that grouped only inflectional variants(plurals and tensed verb forms), 2) a routine thatgrouped inflectional as well as derivational variants(e.g.,- ize,- ity),  and 3) the Porter stemmer (Porter80).
These experiments were done with four differenttest collections which varied in both size and subjectarea.
We found that there was a significant improve-ment over the baseline performance from groupingmorphological variants.Earlier experiments with morphology in IR did notreport improvements in performance (Harman 91).We attribute these differences to the use of differenttest collections, and in part to the use of differentretrieval systems.
We found that the improvementvaries depending on the test collection, and that col-lections that were made up of shorter documents weremore likely to improve.
This is because morpholo-gical variants can occur within the same document,but they are less likely to do so in documents thatare short.
By grouping morphological variants, weare helping to improve access to the shorter docu-ments.
However, we also found improvements evenaExcluding closed class words, such as of and for.75in a collection of legal documents which had an av-erage length of more than 3000 words.We also found it was very difficult to improveretrieval performance over the performance of thePorter stemmer, which does not use a lexicon.
Theabsence of a lexicon causes the Porter stemmerto make errors by grouping morphological "falsefriends" (e.g.. author/authority, or police/policy).We found that there were three reasons why thePorter stemmer improves performance despite suchgroupings.
The first two reasons are associated withthe heuristics used by the stemmer: 1) some wordforms will be grouped when one of the forms hasa combination of endings (e.g., -ization and -ize).We empirically found that the word forms in thesegroups are almost always related in meaning.
2) thestemmer uses a constraint on the form of the res-ulting stem based on a sequence of consonants andvowels; we found that this constraint is surprisinglyeffective at separating unrelated variants.
The thirdreason has to do with the nature of morphologicalvariants.
We found that when a word form appearsto be a variant, it often is a variant.
For example,consider the grouping of police and policy.
We ex-amined all words in the dictionary in which a wordended in 'y', and in which the 'y' could be replacedby 'e' and still yield a word in the dictionary.
Therewere 175 such words, but only 39 were clearly un-related in meaning to the presumed root (i.e., caseslike policy/police).
Of the 39 unrelated word pairs,only 14 were grouped by the Porter stemmer becauseof the consonant/vowel constraints.
We also identi-fied the morphological "'false friends" for the 10 mostfrequent suffixes.
We found that out of 911 incorrectword pairs, only 303 were grouped by the Porterstemmer.Finally, we found that conflating inflectional vari-ants harmed the performance of about a third ofthe queries.
This is partially a result of the inter-action between morphology and part-of-speech (e.g.,a query that contains work in the sense of theoreticalwork will be grouped with all of the variants asso-ciated with the the verb- worked, working, works);we note that some instances of works can be relatedto the singular form work (although not necessarilythe right meaning of work), and some can be relatedto the untensed verb form.
Grouping inflectionalvariants also harms retrieval performance becauseof an overlap between inflected forms and uninflec-ted forms (e.g., arms can occur as a reference toweapons, or as an inflected form of arm).
Conflat-ing these forms has the effect of grouping unrelatedconcepts, and thus increases the net ambiguity.Our experiments with morphology support our at-gument about distinguishing homonymy and poly-semy.
Grouping related morphological variantsmakes a significant improvement in retrieval per-formance.
Morphological false friends (policy/police)often provide a strong separation between relevantand non-relevant documents ( ee (Krovetz and Croft92)).
There are no morphology routines that cancurrently handle the problems we encountered withinflectional variants, and it is likely that separatingrelated from unrelated forms will make further im-provements in performance.3.2.3 Exper iments  with Par t  of  SpeechRelatively little attention has been paid in IR tothe differences in a word's part of speech.
Thesedifferences have been used to help identify phrases(Dillon and Gray 83), and as a means of filteringfor word sense disambiguation (to only consider themeanings of nouns (Voorhees 93)).
To the best of ourknowledge the differences have never been examinedfor distinguishing meanings within the context of IR.The aim of our experiments was to determine howwell part of speech differences correlate with differ-ences in word meanings, and to what extent the useof meanings determined by these differences will af-fect the performance of a retrieval system.
We con-ducted two sets of experiments, one concerned withhomonymy, and one concerned with polysemy.
Inthe first experiment the Church tagger was used toidentify part-of-speech of the words in documentsand queries.
The collections were then indexed bythe word tagged with the part of speech (i.e., in-stead of indexing 'book', we indexed 'book/noun'and 'book/verb').
4 A baseline was established inwhich all variants of a word were present in thequery, regardless of part of speech variation; thebaseline did not include any morphological variantsof the query words because we wanted to test the in-teraction between morphology and part-of-speech ina separate xperiment.
The baseline was then com-pared against a version of the query in which all vari-ations were eliminated except for the part of speechthat was correct (i.e., if the word was used as a nounill the original query, all other variants were elimin-ated).
This constituted the experiment that testedhomonymy.
We then identified words that were re-lated in spite of a difference in part of speech; thiswas based on the data that was produced by taggingthe dictionary (see Section 3.2.1).
Another version ofthe queries was constructed in which part of speechvariants were retained if the meaning was related,4in actuality, we indexed it with whatever tags wereused by the tagger; we are just using 'noun' and 'verb'for purposes of illustration.76and this was compared to the previous version.When we ran the experiments, we found thatperformance decreased compared with the baseline.However, we found many cases where the tagger wasincorrect.
5 We were unable to determine whetherthe results of the experiment were due to the incor-rectness of the hypothesis being tested (that distinc-tions in part of speech can lead to an improvementin performance), or to the errors made by the tagger.We also assumed that a difference in part-of-speechwould correspond to a difference in meaning.
Thedata in Table 1 and Table 2 shows that many wordsare related in meaning despite a difference in part-of-speech.
Not all errors made by the tagger causedecreases in retrieval performance, and we are in theprocess of determining the error rate of the tagger onthose words in which part-of-speech differences arealso associated with a difference in concepts (e.g.,novel as a noun and as an adjective).
63.2.4 Experiments with PhrasesPhrases are an important and poorly understoodarea of IR.
They generally improve retrieval perform-ance, but the improvements are not consistent.
Mostresearch to date has focused on syntactic phrases,in which words are grouped together because theyare in a specific syntactic relationship (Fagan 87),(Smeaton and Van Rijsbergen 88).
The researchin this section is concerned with a subset of thesephrases, namely those that are lexical.
A lexicalphrase is a phrase that might be defined in a dic-tionary, such as hot line or back end.
Lexical phrasescan be distinguished from a phrases such as sanc-tions against South Africa in that the meaning of alexical phrase cannot necessarily be determined fromthe meaning of its parts.Lexical phrases are generally made up of only twoor three words (overwhelmingly just two), and theyusually occur in a fixed order.
The literature men-tions examples uch as blind venetians vs. venetianblinds, or science library vs. library science, butthese are primarily just cute examples.
It is veryrare that the order could be reversed to produce adifferent concept.Although dictionaries contain a large number ofphrasal entries, there are many lexical phrases thatare missing.
These are typically proper nouns(United States, Great Britain, United Nations) ortechnical concepts (operating system, specific heat,5See (Krovetz 95) for more details about these errors.~There are approximately 4000 words in the Long-man dictionary which have more than one part-of-speech.Less than half of those words will be like novel, and weare examining them by hand.due process, strict liability).
We manually identifiedthe lexical phrases in four different test collections(the phrases were based on our judgement), and wefound that 92 out of 120 phrases (77%) were notfound in the Longman dictionary.
A breakdown ofthe phrases is given in (h:rovetz 95).For the phrase experiment we not only had toidentify the lexical phrases, we also had to identiL'any related forms, such as database~data b se.
Thiswas done via brute force - -  a program simply con-catenated every adjacent word in the database, andif it was also a single word in the collection it primted out the pair.
We tested this with the ComputerScience and Time collections, and used those resultsto develop an exception list for filtering the pairs(e.g., do not consider "special ties/specialties').
Werepresented the phrases using a proximity operator:and tried several experiments to include the relatedform when it was found in the corpus.We found that retrieval performance decreased for118 out of 120 phrases.
A failure analysis indic-ated that this was due to the need to assign partialcredit to individual words of a phrase.
The com-ponent words were always related to the meaning ofthe compound as a whole (e.g., Britain and GreatBritain).We also found that most of the instances ofopen/closed compounds (e.g., database~data b se)were related.
Cases like "stone wall/stonewall' or'bottle neck/bottleneck' are infrequent.
The effect ollperformance of grouping the compounds i related tothe relative distribution of the open and closed forms.Database~data b se occurred in about a 50/50 distri-bution, and the queries in which they occurred weresignificantly improved when the related form was in-cluded.3.2.5 In teract ions  between Sources  o fEv idenceWe found many interactions between the differentsources of evidence.
The most striking is the inter-action between phrases and morphology.
We foundthat the use of phrases acts as a filter for the group-ing of morphological variants.
Errors in morphologygenerally do not hurt performance within the restric-ted context.
For example, the Porter stemmer willreduce department to depart, but this has no effectin the context of the phrase 'Justice department'.~The proximity operator specifies that the querywords must be adjacent and in order, or occur withina specific number of words of each other.774 Conc lus ionMost of the research on lexical ambiguity has notbeen done in the context of an application.
Wehave conducted experiments with hundreds of uniquequery words, and tens of thousands of word occur-rences.
The research described in this paper is one ofthe largest studies ever done.
We have examined thelexicon as a whole, and focused on the distinctionbetween homonymy and polysemy.
Other researchon resolving lexical ambiguity for IR (e.g., (Sander-son 94) and (Voorhees 93)) does not take this dis-tinction into account.Our research supports the argument that it is im-portant o distinguish omonymy and polysemy.
Wehave shown that natural language processing res-ults in an improvement in retrieval performance (viagrouping related morphological variants), and ourexperiments suggest where further improvements canbe made.
We have also provided an explanation forthe performance of the Porter stemmer, and shownit is surprisingly effective at distinguishing variantword forms that are unrelated in meaning.
The ex-periment with part-of-speech tagging also high-lighted the importance of polysemy; more than halfof all words in the dictionary that differ in part ofspeech are also related in meaning.
Finally, our ex-periments with lexical phrases how that it is crucialto assign partial credit to the component words ofa phrase.
Our experiment with open/closed com-pounds indicated that these forms are almost alwaysrelated in meaning.The experiment with part-of-speech tagging in-dicated that taggers make a number of errors, andour current work is concerned with identifying thosewords in which a difference in part of speech is as-sociated with a difference in meaning (e.g., train asa noun and as a verb).
The words that exhibit suchdifferences are likely to affect retrieval performance.We are also examining lexical phrases to decide howto assign partial credit to the component words.This work will give us a better idea of how languageprocessing can provide further improvements in IR,and a better understanding of language in general.Part of Speech within DefinitionVNgdjAdvV63 (32.6%)15 (15.2%)N1167 (95%)82 (82.8%)23 (41.8%)Adj57 (4.6%)126 (65.3%)31 (56.4%)Adv3 (0.4%)4 (2.0%)Proportion77.8%12.2%6.3%3.3%Table 1: Distribution of zero-affix morphology within dictionary definitionsVNidjAdvPart of Speech within DefinitionV486 (85%)15 (14%)2 (2%)N239 (97%)87 (81%)4 (3%)Adj7 (3.O%)87 (15%)119 (95%)Adv1 (0.1%)4 (3.7%)Proportion23%54%10%12%Table 2: Distribution of zero-affix morphology (inflected)78AcknowledgementsI am grateful to Dave Waltz for his comments andsuggestions.Re ferencesChodorow M and Y Ravin and H Sachar, "'Tool forInvestigating the Synonymy Relation in a SenseDisambiguated Thesaurus", in Proceedings of theSecond Conference on Applied Natural LanguageProcessing, pp.
144-151, 1988.Church K, "A Stochastic Parts Program and NounPhrase Parser for Unrestricted Text", in Proceed-ings of the Second Conference on Applied NaturalLanguage Processing, pp.
136-143, 1988.Dagan I and A Itai, "Word Sense DisambiguationUsing a Second Language Monolingual Corpus",Computational Linguistics, Vol.
20, No.
4, 1994.Dillon M and A Gray, "FASIT: a Fully .AutomaticSyntactically Based Indexing System", Journal ofthe American Society of Information Science, Vol.34(2), 1983.Fagan J, "Experiments in Automatic Phrase Index-ing for Document Retrieval: A Comparison ofSyntactic and Non-Syntactic Methods", PhD dis-sertation, Cornell University, 1987.Grishman R and Kittredge R (eds), Analyzing Lan-guage in Restricted Domains, LEA Press, 1986.Halliday M A K, "Lexis as a Linguistic Level", inIn Memory of J. R. Firth, Bazell, Catford andHalliday (eds), Longman, pp.
148-162, 1966.Harman D, "'How Effective is Suffixing?
", Journalof the American Society for Information Science,Vol 42(1), pp.
7-15, 1991Helm S., "Closer Than You Think", Medicine andComputer, Vol.
1, No.
1., 1983Kilgarriff A, "Corpus Word Usages and DictionaryWord Senses: What is the Match?
An Empir-ical Study", in Proceedings of the Seventh AnnualConference of the UW Centre for the New OEDand Text Research: Using Corpora, pp.
23-39,1991.Krovetz R and W B Croft, "Lexical Ambiguity andInformation Retrieval", ACM Transactions on In-formation Systems, pp.
145-161, 1992.Krovetz R, "Viewing Morphology as an InferenceProcess", in Proceedings of the Sixteenth AnnualInternational ACM SIGIR Conference on Re-search and Development in Information Retrieval,pp.
191-202, 1993.Krovetz R, "Word Sense Disambiguation for LargeText Databases", PhD dissertation, University ofMassachusetts.
1995.Marchand H, "'On a Question of Contrary Analysiswith Derivational Connected but MorphologicallyUncharacterized Words", English Studies.
Vol.
44.pp.
176-187, 1963.Popovic M and P Witlet, "The Effectiveness ofStem-ming for Natural Language Access to Slovene Tex-tual Data", in Journal of the American Societyfor Information Science, Vol.
43(5), pp.
384-390,1992.Porter M, "An Algorithm for Suffix Stripping", Pro-gram, Vol.
14 (3), pp.
130-137, 1980.Proctor P., Longman Dictionary of ContemporaryEnglish, Longman, 1978.Salton G., Automatic Information Organization andRetrieval, McGraw-Hill, 1968.Salton G. and McGill M., Introduction to ModernInformation Retrieval, McGraw-Hill, 1983.Sanderson M, "Word Sense Disambiguation a d In-formation Retrieval", in Proceedings of the Seven-teenth A nnual International ACM SIGIR Confer-ence on Research and Development in InformationRetrieval, pp.
142-151, 1994.Small S., Cottrell G., and Tannenhaus M. (eds).Lexical Ambiguity Resolution, Morgan Kaufmann,1988.Smeaton A and C J Van Rijsbergen, "Experimentson Incorporating Syntactic Processing of UserQueries into a Document Retrieval Strategy", inProceedings of the Eleventh Annual InternationalACM SIGIR Conference on Research and Devel-opment in Information Retrieval, pp.
31-51, 1988.Talmy L, "Lexicalization Patterns: Semantic Struc-ture in Lexical Forms", in Language Typologyand Syntactic Description.
Volume Ill: Gram,nat-ical Categories and the Lexicon, T Shopen (ed),pp.
57-160, Cambridge University Press, 1985.Van Rijsbergan C. J., Information Retrieval, But-terworths, 1979.Voorhees E, "Using WordNet o Disambiguate WordSenses for Text Retrieval", in Proceedings of theSixteen Annual International ACM SIG1R Con-ference on Research and Development in Inform-ation Retrieval, pp.
171-180, 1993.Yarowsky D, "Word Sense Disambiguation Us-ing Statistical Models of Roget's CategoriesTrained on Large Corpora", in Proceedings of the14th Conference on Computational Linguistics,COLING-9& pp.
454-450, 1992.79
