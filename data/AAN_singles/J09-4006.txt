Punctuation as Implicit Annotationsfor Chinese Word SegmentationZhongguo Li?Tsinghua UniversityMaosong Sun?
?Tsinghua UniversityWe present a Chinese word segmentation model learned from punctuation marks which areperfect word delimiters.
The learning is aided by a manually segmented corpus.
Our methodis considerably more effective than previous methods in unknown word recognition.
This is astep toward addressing one of the toughest problems in Chinese word segmentation.1.
IntroductionParagraphs are composed of sentences.
Hence when a paragraph begins, a sentencemust begin, and as a paragraph closes, some sentence must finish.
This observationis the basis of the sentence boundary detection method proposed by Riley (1989).Similarly, sentences consist of words.
As a sentence begins or ends there must be wordboundaries.Inspired by this notion, we invent a method to learn a Chinese word segmenta-tion model with punctuation marks in a large raw corpus.
The learning is guided bya segmented corpus (Section 3.2).
Section 4 demonstrates that our method improvesnotably the recognition of out-of-vocabulary (OOV) words with respect to approacheswhich use only annotated data (Xue 2003; Low, Ng, and Guo 2005).
This work haspractical implications in that the OOV problem has long been a big challenge for theresearch community.2.
Segmentation as TaggingWe call the first character of a Chinese word its left boundary L, and the last characterits right boundary R. If we regard L and R as random events, then we can derive fourevents (or tags) from them:b = L ?R, m = L ?
R, s = L ?R, e = L ?
R?
Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China.E-mail: eemath@gmail.com.??
Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China.E-mail: sms@mail.thu.edu.cn.Submission received: 16 July 2008; revised submission received: 26 March 2009; accepted for publication:4 May 2009.?
2009 Association for Computational LinguisticsComputational Linguistics Volume 35, Number 4Here R means not R, and thus tag b represents the left but not the right boundary ofa word.
The other tags can be interpreted similarly.
This coding scheme was used byBorthwick (1999) and Xue (2003), where b, m, s, and e stand for begin, middle, onlymember, and end of a word, respectively.
We reformulate them in terms of L and R tofacilitate the presentation of our method.For a sentence S = c1c2 ?
?
?
cn and a sequence T = t1t2 ?
?
?
tn of b, m, s, e tags, wedefineP (T|S) =n?i=1Pr(ti|contexti) (1)where contexti is ci with up to four surrounding characters.
The legal tag sequence(e.g., tag b followed by s is illegal) with highest P gives the segmentation result ofS.
Then from Equation (1) it is obvious that knowing the probability distribution ofb, m, s, and e given context is adequate for carrying out Chinese word segmentation.
Thepurpose of this article is to show that punctuation can play a major role in estimatingthis distribution.We use the maximum entropy approach to model the conditional probabilityPr(y|x), which has the following parametric form according to Berger, Della Pietra, andDella Pietra (1996):Pr(y|x) = 1Z(x) exp(?i?i fi(x, y))(2)Z(x) =?yexp(?i?i fi(x, y))(3)For Chinese word segmentation, the binary valued functions fi are defined through the10 features shown in Table 2.
Xue (2003) explains how these features map to the featurefunctions in Equations (2) and (3).3.
MethodOur key idea is to approximate probabilities of b, m, s, and e with those of L and R.To do this, we assume L and R are conditionally independent given context.
Then wehavePr(b |context) = Pr(L ?R|context) (definition of b)= Pr(L |context) ?
Pr(R|context) (independence)= Pr(L |context) ?
(1 ?
Pr(R |context)) (4)Probabilities for m, s, and e can be derived in the same way and so their derivations arenot provided here.
As mentioned earlier, these probabilities are sufficient for Chineseword segmentation.
Now to model Pr(L |context) and Pr(R |context) with the maximum506Li and Sun Punctuation as Implicit Annotationsentropy technique, we must have positive and negative examples of L and R. It is herethat punctuation comes into play.3.1 Positive ExamplesPunctuation offers directly positive examples of L and R. For instance, we can extractfour training examples from the sentence in Table 1, as listed in Table 2.3.2 Negative ExamplesSuppose for the moment we know the real probability distribution of tags b, m, s, and egiven context.
Then a character in context is itself a word and should be tagged s ifPr(s |context) > maxy?
{b,m,e}Pr(y|context) (5)Each positive example given by punctuation is subjected to the test in (5).
If an examplelabeled L passes this test, then it is also a positive example of R because s = L ?R, andfailing this test gives a negative R. In a similar way we obtain negative examples of L.This process is summarized in Figure 1.A segmented corpus is needed to estimate the probabilities in test (5) with maxi-mum entropy modeling.
Here we use the data provided by Microsoft Research in theSIGHAN 2005 Bakeoff.
The trained model (the MSR model) was used in earlier work(Low, Ng, and Guo 2005) and is one of the state-of-the-art models for Chinese wordsegmentation.With the MSR model, only the last example in Table 2 passes test (5).
Hence we getthe three negative examples shown in Table 3.
Examples like 1, 3, 6, and 8 are used toestimate Pr(L |context) and those like 2, 4, 5, and 7 are used to estimate Pr(R |context).Appendix A provides more details on this issue.Table 1Illustration of word boundaries near punctuation in a simple sentence.?
means the label is unknown with only the help of punctuation.sentence 3 I  ?
0  G ?
word boundary L ?
?
R L ?
?
RTable 2Positive training examples extracted from the sentence in Table 1.features of contextNo.
label c?2 c?1 c0 c1 c2 c?1c1 c?2c?1 c?1c0 c0c1 c1c21 L 3 I  3I I2 R I  ?
0  0 I ?
?0 03 L  ?
0  G ? ?
?0 0 G4 R  G ?
G G?507Computational Linguistics Volume 35, Number 4Figure 1How to get negative examples of L and R. Test (5) is applied to all positive examples given bypunctuation.
Those failing this test are negative training examples.
It is test (5) that invokes theneed of a manually segmented corpus.Table 3Training examples derived from those in Table 2.
We have 1?5, 2?6, 3?7, and 4?8.features of contextNo.
label c?2 c?1 c0 c1 c2 c?1c1 c?2c?1 c?1c0 c0c1 c1c25 R 3 I  3I I6 L I  ?
0  0 I ?
?0 07 R  ?
0  G ? ?
?0 0 G8 L  G ?
G G?3.3 TrainingIn all, we collected 10 billion L-L and R-R examples, each from a comprehensive Webcorpus.1 To cope with so much training data, we use the partitioning method of Yamadaand Matsumoto (2003).
An alternative is the Vowpal Wabbit (fast on-line learning)algorithm.2 Such an algorithm allows incremental training as more raw texts becomeavailable.4.
EvaluationWe evaluate our method with the data and scoring script provided by the SIGHAN 2005Bakeoff.
The data sets of Academia Sinica and City University of Hong Kong, which arein Traditional Chinese, are not used here because the raw corpus is mainly in SimplifiedChinese.
Table 4 gives the evaluation results on the data from Microsoft Research (MSR)and Peking University (PKU).It seems our method is over 10% below state of the art in precision on the MSR data.However, we find that multiword expressions are consistently segmented into smallerwords.
Take the one multiword ?-?z/vb-??v@?
[Institute of Chinese1 Freely available for research purposes.
See www.sogou.com/labs.2 http://hunch.net/?vw/.
We thank one of the anonymous reviewers for telling us about thisimplementation.508Li and Sun Punctuation as Implicit AnnotationsCulture, Chinese Academy of Arts] in the standard answer of the test data as an example.Our method segments it into six correct words ?-?
z/ vb -?
? v@?
[China, art, academy, China, culture, institute], all of which are considered wrong by thescoring script.
This is arguable because the only difference is the granularity of thesegmentation.4.1 Influence of GranularityWe check every error detected by the scoring script on the MSR data, and find thatfor our method, 15,071 errors are actually correct segmentations of 5,463 multiwords,whereas for the MSR model, the corresponding counts are 858 and 355, respectively.
Thegold standard contains 106,873 words.
These statistics combined with Table 4 allow usto calculate the metrics as in Table 5, if errors caused by correctly segmented multiwordsare not counted.We see that, when the influence of granularity is considered, our method is slightlybetter than the MSR model.
However, as Table 4 shows, both models degrade on thePKU data due to the difference in segmentation standards.
This kind of degradationwas also documented by Peng, Feng, and McCallum (2004).4.2 Named Entity List RecoveryThe SIGHAN data sets contain relatively few OOV words (2.6% for the MSR data).
Whatif the rate is much higher than that?
We expect our model to be less vulnerable to OOVproblems because it is trained with billions of examples from a large corpus.
To verifythis, we generate four data sets from each of these lists of names:(a) 702 cities and counties of China seen in the MSR data(b) 1,634 cities and counties of China not seen in the MSR data(c) 7,470 Chinese personal names seen in the MSR data(d) 20,000 Chinese personal names not seen in the MSR dataTable 4Evaluation results on SIGHAN Bakeoff 2005 data sets.our method the MSR modeldata set P R F P R FMSR 84.8 91.3 87.9 96.0 95.6 95.8PKU 84.2 86.1 85.1 85.2 82.3 83.7Table 5Amended evaluation results for MSR data.P R Four method 98.0 96.7 97.3the MSR model 96.7 96.0 96.3509Computational Linguistics Volume 35, Number 4Table 6Results on tasks of named entity list recovery.our method the MSR modeldata set P R F P R F(a) 91.0 93.8 92.4 43.3 29.1 34.8(b) 79.4 85.3 82.2 25.1 16.9 20.2(c) 74.9 85.0 79.6 69.4 66.5 67.9(d) 86.3 91.5 88.8 65.4 61.0 63.1The generation method is: Randomly permute each list and then put the result into lines,with each line having about 30 names, and repeat this process until we get 1 milliontokens for each data set.
We use the MSR model and our method to segment these datasets.
The results are in Table 6.It is clear that our method performs better on these data sets.
This provides evidencethat it could handle situations where many OOV words turn up.
Table 6 also indicatesthat, especially for the MSR model, recognition of Chinese personal names is easierthan location names.
This is reasonable because the former has more regularity than thelatter.
Besides, although there are no OOV words in data sets (a) and (c), many wordsoccur very sparsely in the MSR data.
Hence the MSR model doesn?t do well even onthese two data sets.4.3 Unknown Words RecognitionTo further test our model?s ability to recognize unknown words, we make 27,470 sen-tences with the pattern ?X / Y ?
X ?"
Y ?
(X is a resident of Y, and X lovesY), where X and Y are the personal and location names in Section 4.2.
The results onthis data set are in Table 7.
Again our method outperforms the MSR model by a largemargin, proving once more that it is stronger in unknown word recognition.
For bothmethods, the metrics in Table 7 are better than those in Table 6, reflecting the fact thatunknown word recognition here is easier than the named entity list recovery task.4.4 SummaryEvaluation shows that when there are many new words, the improvement of ourmethod is obvious.
In addition, a model is of limited use if it fits the SIGHAN data well,but can?t maintain that accuracy elsewhere.
Our model has a wider coverage throughTable 7Results of unknown word recognition in 24,470 sentences.P R Four method 96.2 97.9 97.1the MSR model 88.3 84.5 86.3510Li and Sun Punctuation as Implicit Annotationsmining the Web.
It tends to segment long multiword expressions into their componentwords.
This is not a disadvantage as long as the result is consistent.5.
Related WorkPunctuation gives naturally occurring unambiguous word boundaries.
Gao et al (2005)described how to remove overlapping ambiguities in an annotated corpus to train amodel for resolving these ambiguities.
A raw corpus doesn?t play a role in that method,and the model involves no punctuation marks.Chinese word segmentation based on position tagging was initiated by Xue (2003).This method and its subsequent developments have achieved state-of-the-art perfor-mance in word segmentation (Peng, Feng, and McCallum 2004; Low, Ng, and Guo 2005;Zhao, Huang, and Li 2006).
Yet the system degrades when there are lots of previouslyunknown words, whereas our method performs particular well in this case thanks tothe use of a huge Web corpus.In the past decade, much work has been done in unsupervised word segmentation(Sun, Shen, and Tsou 1998; Peng and Schuurmans 2001; Feng et al 2004; Goldwater,Griffiths, and Johnson 2006; Jin and Tanaka-Ishii 2006).
These methods could also takeadvantage of the ever-growing amount of online text to model Chinese word segmen-tation, but usually are less accurate and more complicated than ours.6.
ConclusionWith a virtually unlimited supply of raw corpus data, punctuation marks give us ampletraining examples and thus can be quite useful as implicit annotations for Chineseword segmentation.
We also note that shallow parsing (Sha and Pereira 2003) is a closeanalogy to word segmentation.
Hence our method can potentially be applied to thistask as well.Appendix A: Input to the Training AlgorithmWe give readers a feel for the input data used to train our probability models.
First, toestimate Pr(L |context), the input to the learning algorithm for the maximum entropymodels looks like this:+L C0=3 C1=I C2= C0C1=3I C1C2=I+L C0=0 C1= C2=G C0C1=0 C1C2=G-L C-2=I C-1= C0=?
C-2C-1=I C-1C0=?+L C-2= C-1=G C0=?
C-2C-1=G C-1C0=G?Whereas to estimate Pr(R | context), the input data are something like the following+R C-2=I C-1= C0=?
C-2C-1=I C-1C0=?+R C-2= C-1=G C0=?
C-2C-1=G C-1C0=G?-R C0=3 C1=I C2= C0C1=3I C1C2=I-R C0=0 C1= C2=G C0C1=0 C1C2=GTo save space, not all features in Table 2 are included here.
From this illustration,interested readers can get a general idea of our input to the learning algorithm inSection 3.3.511Computational Linguistics Volume 35, Number 4AcknowledgmentsThis work is supported by the NationalScience Foundation of China under GrantNo.
60621062 and 60873174, and the National863 Project under Grant No.
2007AA01Z148.We thank our reviewers sincerely for manyhelpful comments and suggestions whichgreatly improved this article.
Thanks also goto sogou.com for sharing their Web corporaand entity names.
The maximum entropymodeling toolkit used here is contributed byZhang Le of the University of Edinburgh.ReferencesBerger, Adam L., Vincent J. Della Pietra, andStephen A. Della Pietra.
1996.
A maximumentropy approach to natural languageprocessing.
Computational Linguistics,22(1):39?71.Borthwick, Andrew.
1999.
A MaximumEntropy Approach to Named EntityRecognition.
Ph.D. thesis, New YorkUniversity.Feng, Haodi, Kang Chen, Xiaotie Deng, andWeimin Zheng.
2004.
Accessor varietycriteria for Chinese word extraction.Computational Linguistics, 30(1):75?93.Gao, Jianfeng, Mu Li, Andi Wu, andChang-Ning Huang.
2005.
Chinese wordsegmentation and named entityrecognition: A pragmatic approach.Computational Linguistics, 31(4):531?574.Goldwater, Sharon, Thomas L. Griffiths,and Mark Johnson.
2006.
Contextualdependencies in unsupervised wordsegmentation.
In Proceedings of the 21stInternational Conference on ComputationalLinguistics and 44th Annual Meeting of theAssociation for Computational Linguistics,pages 673?680, Sydney.Jin, Zhihui and Kumiko Tanaka-Ishii.
2006.Unsupervised segmentation of Chinesetext by use of branching entropy.
InProceedings of the COLING/ACL on MainConference Poster Sessions, pages 428?435,Morristown, NJ.Low, Jim Kiat, Hwee Tou Ng, and WenyuanGuo.
2005.
A maximum entropyapproach to Chinese word segmentation.In Proceedings of the Fourth SIGHANWorkshop on Chinese Language Processing,pages 161?164, Jeju Island.Peng, Fuchun, Fangfang Feng, and AndrewMcCallum.
2004.
Chinese segmentationand new word detection using conditionalrandom fields.
In COLING ?04: Proceedingsof the 20th International Conference onComputational Linguistics, pages 562?569,Morristown, NJ.Peng, Fuchun and Dale Schuurmans.2001.
Self-supervised Chinese wordsegmentation.
Lecture Notes in ComputerScience, 2189:238?249.Riley, Michael D. 1989.
Some applicationsof tree-based modelling to speech andlanguage.
In HLT ?89: Proceedings of theWorkshop on Speech and Natural Language,pages 339?352, Morristown, NJ.Sha, Fei and Fernando Pereira.
2003.Shallow parsing with conditionalrandom fields.
In NAACL ?03: Proceedingsof the 2003 Conference of the NorthAmerican Chapter of the Association forComputational Linguistics on HumanLanguage Technology, pages 134?141,Morristown, NJ.Sun, Maosong, Dayang Shen, andBenjamin K. Tsou.
1998.
Chinese wordsegmentation without using lexicon andhand-crafted training data.
In Proceedingsof the 17th International Conference onComputational Linguistics, pages 1265?1271,Morristown, NJ.Xue, Nianwen.
2003.
Chinese wordsegmentation as character tagging.Computational Linguistics and ChineseLanguage Processing, 8(1):29?48.Yamada, Hiroyasu and Yuji Matsumoto.2003.
Statistical dependency analysiswith support vector machines.
InProceedings of the 8th International Workshopon Parsing Technologies (IWPT2003),pages 195?206, Nancy.Zhao, Hai, Chang-Ning Huang, and Mu Li.2006.
An improved Chinese wordsegmentation system with conditionalrandom field.
In Proceedings of the FifthSIGHAN Workshop on Chinese LanguageProcessing, pages 162?165, Sydney.512
