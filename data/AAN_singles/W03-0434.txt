A Robust Risk Minimization based Named Entity Recognition SystemTong ZhangIBM T.J. Watson Research CenterYorktown HeightsNew York, 10598, USAtzhang@watson.ibm.comDavid JohnsonIBM T.J. Watson Research CenterYorktown HeightsNew York, 10598, USAdejohns@us.ibm.comAbstractThis paper describes a robust linear classifica-tion system for Named Entity Recognition.
Asimilar system has been applied to the CoNLLtext chunking shared task with state of the artperformance.
By using different linguistic fea-tures, we can easily adapt this system to othertoken-based linguistic tagging problems.
Themain focus of the current paper is to investigatethe impact of various local linguistic featuresfor named entity recognition on the CoNLL-2003 (Tjong Kim Sang and De Meulder, 2003)shared task data.
We show that the system per-formance can be enhanced significantly withsome relative simple token-based features thatare available for many languages.
Althoughmore sophisticated linguistic features will alsobe helpful, they provide much less improve-ment than might be expected.1 IntroductionAn important research area in the field of information ex-traction is Named Entity Recognition.
This topic was acentral theme in the message understanding conferences(MUCs).
It has become more important nowadays dueto the large amount of available electronic text, whichmakes it necessary to build systems that can automati-cally process and extract information from text.In spite of significant work in this area, the problemitself has not been solved.
Although some earlier re-ports suggested accuracy (F1-number) of machine learn-ing based systems to be in the lower 90s with relativelysmall amount of labeled data (for example, (Bikel et al,1999; Mikheev et al, 1998; Sundheim, 1995)), thesestudies were often performed on relatively restricted do-mains.
Our experience indicates that the performance ofa statistically based named entity extraction system canvary significantly depending on the underlying domain.There are still open challenges to make the performanceof a statistical system consistent across different types ofdata sources.In this paper we present a system for named entityrecognition based on our earlier work on text chunking(Zhang et al, 2002).
One advantage of the proposed sys-tem is that it can easily incorporate a large number of lin-guistic features.
This advantage is similar to a number ofother approaches, such as the maximum entropy method,which has been widely used to solve NLP problems, see(Borthwick, 1999; Ratnaparkhi, 1999) for example.The performance of our system can be significantly af-fected by the choice of available linguistic features.
Themain focus of this paper is to investigate the impact ofsome local features.
Specifically we show that the systemperformance can be enhanced significantly with somerelatively simple token-based features.
More sophisti-cated linguistic features, although helpful, yield muchless improvement in system performance than might beexpected.We believe that this study provides useful insight intothe usefulness of various available local linguistic fea-tures.
Since these simple features are readily availablefor many languages, it suggests the possibility of settingup a language independent named entity recognition sys-tem quickly so that its performance is close to a systemthat uses much more sophisticated, language dependentfeatures.2 System descriptionFollowing the approach employed in our text chunkingsystem (Zhang et al, 2002), we treat the named entityrecognition problem as a sequential token-based taggingproblem.
We denote by {wi} (i = 0, 1, .
.
.
,m) the se-quence of tokenized text, which is the input to our system.In token-based tagging, the goal is to assign a class-labelti, taking its value from a predefined set of labels, to ev-ery token wi.For named entity recognition, and text segmentationin general, the entities (segments) can be encoded as atoken-based tagging problem by using various encodingschemes.
In this paper, we shall only use the IOB1 encod-ing scheme which is provided in the CoNLL-2003 sharedtask.The goal of our learning system is to predict the class-label value ti associated with each token wi.
In our sys-tem, this is achieved by estimating the conditional proba-bility P (ti = c|xi) for every possible class-label value c,where xi is a feature vector associated with token i.
It isessentially a sufficient statistic in our model: we assumethat P (ti = c|xi) = P (ti = c|{wi}, {tj}j?i).
The fea-ture vector xi can depend on previously predicted class-labels {tj}j?i, but the dependency is typically assumedto be local.
Given such a conditional probability model,in the decoding stage, we estimate the best possible se-quence of ti?s using a dynamic programming approach,similar to what is described in (Zhang et al, 2002).In our system, the conditional probability model hasthe following parametric form:P (ti = c|xi, {ti?`, .
.
.
, ti?1}) = T (wTc xi + bc),where T (y) = min(1,max(0, y)) is the truncation of yinto the interval [0, 1].
wc is a linear weight vector andbc is a constant.
Parameters wc and bc can be estimatedfrom the training data.Given training data (xi, ti) for i = 1, .
.
.
, n. It wasshown in (Zhang et al, 2002) that such a model can beestimated by solving the following optimization problemfor each c:infw,b1nn?i=1f(wTc xi + bc, yic),where yic = 1 when ti = c and yic = ?1 otherwise.
Thefunction f is defined as:f(p, y) =?????
?2py py < ?112 (py ?
1)2 py ?
[?1, 1]0 py > 1.This risk function is closely related to Huber?s lossfunction in robust estimation.
We shall call a classifica-tion method that is based on approximately minimizingthis risk function robust risk minimization.
The general-ized Winnow method in (Zhang et al, 2002) implementssuch a method.
The numerical algorithm used for exper-iments in this paper is a variant, and is similar to the onegiven in (Damerau et al, 2003).The main purpose of the paper is to investigate the im-pact of local linguistic features for the Named Entity de-tection task.
The basic linguistic features considered hereare all aligned with the tokens.
Specifically we will con-sider features listed in Table 1.
These features are repre-sented using a binary encoding scheme where each com-ponent of the feature vector x corresponds to an occur-rence of a feature that is listed above.
We use a windowof ?1 centered at the current token unless indicated oth-erwise in Table 1.3 Experimental ResultsWe study the performance of our system with differentfeature combinations on the English development set.Our results are presented in Table 2.
All of these resultsare significantly better than the baseline performance of71.18.
We will now discuss the implications of these ex-perimental results.The small difference between Experiment 1 and Ex-periment 2 implies that tokens by themselves, whetherrepresented as mixed case text or not, do not significantlyaffect the system performance.Experiment 3 shows that even without case informa-tion, the performance of a statistical named entity recog-nition system can be greatly enhanced with token prefixand suffix information.
Intuitively, such information al-lows us to build a character-based token-model which canpredict whether an (unseen) English word looks like anentity-type or not.
The performance of this experimentis comparable to that of the mixed-case English text pluscapitalization feature reported in Experiment 4.Experiment 4 suggests that capitalization is a very use-ful feature for mixed case text, and can greatly enhancethe perform of a named entity recognition system.
Withtoken prefix and suffix information that incorporates acharacter-based entity model, the system performance isfurther enhanced, as reported in Experiment 5.Up to Experiment 5, we have only used very simpletoken-based linguistic features.
Despite their simplicity,these features give very significant performance enhance-ment.
In addition, such features are readily availablefor many languages, implying that they can be used ina language independent statistical named entity recogni-tion system.In Experiment 6, we added the provided part-of-speechand chunking information.
Clearly they only lead to arelatively small improvement.
We believe that most in-formation contained in part-of-speech has already beencaptured in the capitalization and prefix/suffix features.The chunking information might be more useful, thoughits value is still quite limited.By adding the four supplied dictionaries, we observe asmall, but statistically significant improvement.
The per-formance is reported in Experiment 7.
At this point wehave only used information provided by the shared task.Further performance enhancement can be achieved byusing extra information that is not provided in the sharedFeature ID Feature descriptionA Tokens that are turned into all upper-case, in a window of ?2.B Tokens themselves, in a window of ?2.C The previous two predicted tags, andthe conjunction of the previous tag and the current token.D Initial capitalization of tokens in a window of ?2.E More elaborated word type information:initial capitalization, all capitalization, all digitals, or digitals containing punctuations.F Token prefix (length three and four), and token suffix (length from one to four).G POS tagged information provided in shared the task.H chunking information provided in the shared task:we use a bag-of-word representation of the chunk at the current token.I The four dictionaries provided in the shared task: PER, ORG, LOC, and MISC.J A number of additional dictionaries from different sources:some trigger words for ORG, PER, LOC; lists of location, person, and organizations.Table 1: feature definitionExperiment ID Features used Precision Recall F?=11 A+C 91.94 74.25 82.152 B+C 93.70 74.89 83.253 A+F 89.96 82.50 86.074 B+C+D 88.79 86.01 87.385 B+C+D+E+F 90.11 88.67 89.396 B+C+D+E+F+G+H 91.00 89.53 90.267 B+C+D+E+F+G+H+I 92.14 90.73 91.438 B+C+D+E+F+G+H+I+J 92.76 91.42 92.08Table 2: Performance with different features on the English development settask.
In this study, we will only report performance withadditional dictionaries we have gathered from various dif-ferent sources.
With these additional dictionaries, oursystem achieved a performance of 92, as reported in Ex-periment 8.
Table 4 presents the performance of eachentity type separately.Clearly the construction of extra linguistic features isopen ended.
It is possible to improve system performancewith additional and higher quality dictionaries.
Althoughdictionaries are language dependent, they are often fairlyreadily available and providing them does not pose a ma-jor impediment to customizing a language independentsystem.
However, for more difficult cases, it may benecessary to provide high precision, manually developedrules to capture particular linguistic patterns.
Languagedependent features of this kind are harder to develop thandictionaries and correspondingly pose a greater obstacleto customizing a language independent system.
We havefound that such features can appreciably improve the per-formance of our system, but discussion is beyond thescope of this paper.
A related idea is to combine the out-puts of different systems.
See (Florian et al, 2003) forsuch a study.
Fortunately, as our experiments indicate,special purpose patterns may not be necessary for quitereasonable accuracy.In Table 4, we report the performance of our system onthe German data.
We shall note that the performance issignificantly lower than the corresponding English per-formance.
Our experience indicates that even for En-glish, the real-world performance of a statistical namedentity recognizer can be very low.
The performance wereported for the German data is achieved by using thefollowing features: B+C+D+E+F+G+H+I+J (with somesmall modifications), plus the German word lemma fea-ture provided by the task.The additional German dictionaries were provided tous by Radu Florian.
Without these additional dictionaries(in this case, all information we use is provided by theCoNLL task), the overall performance is listed in Table 3.It is also interesting to note that without any dictionaryinformation, the overall performance drops to an F?=1score of 65.5 on the development set, and to 70.2 on thetest set.
Clearly for this data, dictionary information helpsmore on the development data than on the test data.Precision Recall F?=1devel.
set 82.49 61.22 70.29test set 81.59 62.73 70.93Table 3: System performance with only features that areprovided by the CoNLL task on German data.4 ConclusionIn this paper, we presented a general token-based NLPtagging system using a robust risk minimization classifi-cation method.
The system can take advantage of differ-ent kinds of linguistic features.We have studied the impact of various local linguisticfeatures on the performance of our system.
It is interest-ing to note that most performance improvement can beachieved with some relatively simple token features thatare easy to construct.
Although more sophisticated lin-guistic features will also be helpful, they provide muchless improvement than might be expected.
This observa-tion supports the view that language independent namedentity recognition systems can, with relatively small ef-fort, achieve competitive levels of accuracy.AcknowledgmentsThe authors would like to thank Radu Florian for prepar-ing the German data and for providing additional Germandictionaries that helped to achieve the performance pre-sented in the paper.ReferencesDaniel M. Bikel, Richard L. Schwartz, and Ralph M.Weischedel.
1999.
An algorithm that learns what?sin a name.
Machine Learning, 34(1-3):211?231.Andrew Borthwick.
1999.
A Maximum Entropy Ap-proach to Named Entity Recognition.
Ph.D. thesis,New York University.Fred J. Damerau, Tong Zhang, Sholom M. Weiss, andNitin Indurkhya.
2003.
Text categorization for a com-prehensive time-dependent benchmark.
InformationProcessing & Management, to appear.Radu Florian, Abe Ittycheriah, Hongyan Jing, and TongZhang.
2003.
Named entity recognition through clas-sifier combination.
In Proceedings CoNLL-2003.A.
Mikheev, C. Grover, and M. Moens.
1998.
Descrip-tion of the ltg system used for MUC-7.
In Proceed-ings of the Seventh Message Understanding Confer-ence (MUC-7).Adwait Ratnaparkhi.
1999.
Learning to parse naturallanguage with maximum entropy models.
MachineLearning, 34:151?175.English devel.
Precision Recall F?=1LOC 95.65 94.56 95.10MISC 90.15 84.38 87.17ORG 89.03 86.50 87.75PER 93.76 95.39 94.56Overall 92.76 91.42 92.08English test Precision Recall F?=1LOC 89.51 89.57 89.54MISC 77.45 74.36 75.87ORG 82.57 78.45 80.46PER 89.67 91.22 90.44Overall 86.13 84.88 85.50German devel.
Precision Recall F?=1LOC 80.69 72.90 76.60MISC 80.38 42.18 55.32ORG 83.19 61.40 70.65PER 86.36 65.95 74.79Overall 82.98 61.51 70.65German test Precision Recall F?=1LOC 77.71 71.40 74.42MISC 71.51 39.70 51.06ORG 79.55 55.37 65.29PER 91.68 73.81 81.78Overall 82.00 63.03 71.27Table 4: System performance with all features on the En-glish and the German dataErik F. Tjong Kim Sang and Fien De Meulder.
2003.Introduction to the conll-2003 shared task: Languageindependent named entity recognition.
In WalterDaelemans and Miles Osborne, editors, Proceedingsof CoNLL-2003.B.M.
Sundheim.
1995.
Overview of results of the MUC-6 evaluation.
In Proceedings of the Sixth Message Un-derstanding Conference (MUC-6).Tong Zhang, Fred Damerau, and David E. Johnson.2002.
Text chunking based on a generalization of Win-now.
Journal of Machine Learning Research, 2:615?637.
