Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions, pages 52?57,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsMeeting TempEval-2: Shallow Approach for Temporal TaggerOleksandr KolomiyetsKatholieke Universiteit LeuvenDepartment of Computer ScienceCelestijnenlaan 200A, Heverlee, Belgiumoleksandr.kolomiyets@cs.kuleuven.beMarie-Francine MoensKatholieke Universiteit LeuvenDepartment of Computer ScienceCelestijnenlaan 200A, Heverlee, Belgiumsien.moens@cs.kuleuven.beAbstractTemporal expressions are one of the importantstructures in natural language.
In order to un-derstand text, temporal expressions have to beidentified and normalized by providing ISO-based values.
In this paper we present a shal-low approach for automatic recognition oftemporal expressions based on a supervisedmachine learning approach trained on an an-notated corpus for temporal information,namely TimeBank.
Our experiments demon-strate a performance level comparable to arule-based implementation and achieve thescores of 0.872, 0.836 and 0.852 for precision,recall and F1-measure for the detection taskrespectively, and 0.866, 0.796, 0.828 when anexact match is required.1 IntroductionThe task of recognizing temporal expressions(sometimes also referred as time expressions orsimply TIMEX) was first introduced in the Mes-sage Understanding Conference (MUC) in 1995.Temporal expressions were treated as a part of theNamed Entity Recognition (NER) task, in whichcapitalized tokens in text were labeled with one ofthe predefined semantic labels, such as Date, Time,Person, Organization, Location, Percentage, andMoney.
As the types of temporal entities identifiedin this way were too restricted and provided littlefurther information, the Automated Content Ex-traction (ACE) launched a competition campaignfor Temporal Expression Recognition and Norma-lization (TERN 2004).
The tasks were to identifytemporal expressions in free text and normalizethem providing an ISO-based date-time value.
Lat-er evaluations of ACE in 2005, 2006 and 2007 un-fortunately did not set new challenges for temporalexpression recognition and thus the participationinterest in this particular task decreased.TempEval-2 is a successor of TempEval-2007and will take place in 2010.
The new evaluationinitiative sets new challenges for temporal textanalysis.
While TempEval-2007 was solely fo-cused on recognition of temporal links, theTempEval-2 tasks aim at an all-around temporalprocessing with separate evaluations for recogni-tion of temporal expressions and events, for theestimation of temporal relations between eventsand times in the same sentence, between eventsand document creation time, between two events inconsecutive sentences and between two events,where one of them syntactically dominates the oth-er (Pustejovsky et al, 2009).
These evaluationsbecame possible with a new freely available corpuswith annotated temporal information, TimeBank(Pustejovsky et al, 2003a), and an annotationschema, called TimeML (Pustejovsky et al,2003b).For us all the tasks of TempEval-2 seem to beinteresting.
In this paper we make the first steptowards a comprehensive temporal analysis andaddress the problem of temporal expression recog-nition as it is set in TempEval-2.
Despite a numberof previous implementations mainly done in thecontext of the ACE TERN competition, very few,52and exclusively rule-based methods were reportedfor temporal taggers on TimeBank developed byusing the TimeML annotation scheme.
As a mainresult of the deep analysis of relevant work (Sec-tion 2), we decided to employ a machine learningapproach for constituent-based classifications withgeneric syntactic and lexical features.The remainder of the paper is organized as fol-lows: in Section 2 we provide the details of rele-vant work done in this field along with corpora andannotations schemes used; Section 3 describes theapproach; experimental setup, results and erroranalysis are provided in Section 4.
Finally, Section5 gives an outlook for further improvements andresearch.2 Related WorkFor better understanding of the performance levelsprovided in the paper we first describe evaluationmetrics defined for the temporal expression recog-nition task and then the methods and datasets usedin previous research.2.1 Evaluation metricsWith the start of the ACE TERN competition in2004, two major evaluation conditions were pro-posed: Recognition+Normalization (full task) andRecognition only (TERN, 2004).Detection (Recognition): Detection is a prelimi-nary task towards the full TERN task, in whichtemporally relevant expressions have to be found.The scoring is very generous and implies a minim-al overlap in the extent of the reference and thesystem output tags.
As long as there is at least oneoverlapping character, the tags will be aligned.Any alignment of the system output tags are scoredas a correct detection.Sloopy span: Spans usually refer to strict match ofboth boundaries (the extent) of a temporal expres-sion (see Exact Match).
?Sloopy?
admits recog-nized temporal expressions as long as their rightboundary is the same as in the correspondingTimeBank?s extents (Boguraev and Ando, 2005).The motivation was to assess the correctness oftemporal expressions recognized in TimeBank,which was reported as inconsistent with respect tosome left boundary items, such as determiners andpre-determiners.Exact Match (Bracketing or Extent Recogni-tion): Exact match measures the ability to correct-ly identify the extent of the TIMEX.
The extent ofthe reference and the system output tags mustmatch exactly the system output tag to be scored ascorrect.2.2 DatasetsTo date, there are two annotated corpora used fortemporal evaluations, the ACE TERN corpus andTimeBank (Pustejovsky et al, 2003a).
In this sec-tion we provide a brief description of the temporalcorpora and annotation standards, which can sub-stantially influence recognition results.Most of the implementations referred as thestate-of-the-art were developed in the scope of theACE TERN 2004.
For evaluations, a training cor-pus of 862 documents with about 306 thousandwords was provided.
Each document represents anews article formatted in XML, in which TIMEX2tags denote temporal expressions.
The total num-ber of temporal expressions for training is 8047TIMEX2 tags with an average of 10.5 per docu-ment.
The test set comprises 192 documents with1828 TIMEX2 tags (Ferro, 2004).The annotation of temporal expressions in theACE corpus was done with respect to the TIDESannotation guidelines (Ferro et al, 2003).
TheTIDES standard specifies so-called markable ex-pressions, whose syntactic head must be an appro-priate lexical trigger, e.g.
?minute?, ?afternoon?,?Monday?, ?8:00?, ?future?
etc.
When tagged, thefull extent of the tag must correspond to one of thegrammatical categories: nouns (NN, NNP), nounphrases (NP), adjectives (JJ), adjective phrases(ADJP), adverbs (RB) and adverb phrases(ADVP).
According to this, all pre- and postmo-difiers as well as dependent clauses are also in-cluded to the TIMEX2 extent, e.g.
?five days afterhe came back?, ?nearly four decades of expe-rience?.
Such a broad extent for annotations is ofcourse necessary for correct normalization, but onthe other hand, introduces difficulties for exactmatch.
Another important characteristic of theTIDES standard are the nested temporal expres-sions as for example:<TIMEX2>The<TIMEX2 VAL = "1994">1994</TIMEX2> baseball season </TIMEX2>53The most recent annotation language for tem-poral expressions, TimeML (Pustejovsky et al,2003b), with an underlying corpus TimeBank(Pustejovsky et al, 2003a), opens up new possibili-ties for processing temporal information in text.Besides the specification for temporal expressions,i.e.
TIMEX3, which is to a large extent inheritedfrom TIDES, TimeML provides a means to capturetemporal semantics by annotations with suitablydefined attributes for fine-grained specification ofanalytical detail (Boguraev et al, 2007).
The anno-tation schema establishes new entity and relationmarking tags along with numerous attributes forthem.
This advancement influenced the extent forevent-based temporal expression, in which depen-dent clauses are no longer included into TIMEX3tags.
The TimeBank corpus includes 186 docu-ments with 68.5 thousand words and 1423TIMEX3 tags.2.3 Approaches for temporal processingAs for any recognition problem, there are two ma-jor ways to solve it.
Historically, rule-based sys-tems were first implemented.
Such systems arecharacterized by a great human effort in data anal-ysis and rule writing.
With a high precision suchsystems can be successfully employed for recogni-tion of temporal expressions, whereas the recallreflects the effort put into the rule development.
Bycontrast, machine learning methods require an an-notated training set, and with a decent feature de-sign and a minimal human effort can providecomparable or even better results than rule-basedimplementations.
As the temporal expression rec-ognition is not only about to detect them but also toprovide an exact match, machine learning ap-proaches can be divided into token-by-token classi-fication following B(egin)-I(nside)-O(utside)encoding and binary constituent-based classifica-tion, in which an entire chunk-phrase is under con-sideration to be classified as a temporal expressionor not.
In this case, exact segmentation is the re-sponsibility of the chunker or the parser used.Rule-based systems: One of the first well-knownimplementations of temporal taggers was presentedin (Many and Wilson, 2000).
The approach relieson a set of hand-crafted and machine-discoveredrules, which are based upon shallow lexical fea-tures.
On average the system achieved a value of83.2% for F1-measure against hand-annotated da-ta.
The dataset used comprised a set of 22 NewYork Times articles and 199 transcripts of Voice ofAmerica taken from the TDT2 collection (Graff etal., 1999).
It should be noted that the reported per-formance was provided in terms of an exact match.Another example of rule-based temporal taggers isChronos described in (Negri and Marseglia, 2004),which achieved the highest scores (F1-measure) inthe TERN 2004 of 0.926 and 0.878 for recognitionand exact match.Recognition of temporal expressions usingTimeBank as an annotated corpus, is reported in(Boguraev and Ando, 2005) based on a cascadedfinite-state grammar (500 stages and 16000 transi-tions).
A complex approach achieved an F1-measure value of 0.817 for exact match and 0.896for detecting ?sloopy?
spans.
Another known im-plementation for TimeBank is an adaptation of(Mani and Wilson, 2000) from TIMEX2 toTIMEX3 with no reported performance level.Machine learning recognition systems: Success-ful machine learning TIMEX recognition systemsare described in (Ahn et al, 2005; Hacioglu et al,2005; Poveda et al, 2007).
Proposed approachesmade use of a token-by-token classification fortemporal expressions represented by B-I-O encod-ing with a set of lexical and syntactic features, e.g.,token itself, part-of-speech tag, label in the chunkphrase and the same features for each token in thecontext window.
The performance levels are pre-sented in Table 1.
All the results were obtained onthe ACE TERN dataset.Approach F1 (detection) F1 (exact match)Ahn et al, 2005 0.914 0.798Hacioglu et al,2005 0.935 0.878Poveda et al,2007 0.986 0.757Table 1.
Performance of Machine Learning Ap-proaches with B-I-O EncodingConstituent-based classification approach fortemporal expression recognition was presented in(Ahn et al, 2007).
By comparing to the previouswork (Ahn et al, 2005) on the same ACE TERNdataset, the method demonstrates a slight decreasein detection with F1-measure of 0.844 and a nearlyequivalent F1-measure value for exact match of0.787.54The major characteristic of machine learningapproaches was a simple system design with a mi-nimal human effort.
Machine-learning based rec-ognition systems have proven to have acomparable recognition performance level to state-of-the-art rule-based detectors.3 ApproachThe approach we describe in this section employs amachine-learning technique and more specificallya binary constituent based classification.
In thiscase the entire phrase is under consideration to belabeled as a TIMEX or not.
We restrict the classifi-cation for the following phrase types and grammat-ical categories: NN, NNP, CD, NP, JJ, ADJP, RB,ADVP and PP.
In order to make it possible, foreach sentence we parse the initial input line with aMaximum Entropy parser (Ratnaparkhi, 1998) andextract all phrase candidates with respect the typesdefined above.
Each phrase candidate is examinedagainst the manual annotations for temporal ex-pressions found in the sentence.
Those phrases,which correspond to the temporal expressions inthe sentence are taken as positive examples, whilethe rest are considered as negative ones.
Only onesub-tree from a parse is marked as positive for adistinct TIMEX at once.
After that, for each can-didate we produce a feature vector, which includesthe following features: head phrase, head word,part-of-speech for head word, character type andcharacter type pattern for head word as well as forthe entire phrase.
Character type and character typepattern1 features are implemented following Ahn etal.
(2005).
The patterns are defined by using thesymbols X, x and 9.
X and x are used for charactertype as well as for character type patterns forrepresenting capital and lower-case letters for atoken.
9 is used for representing numeric tokens.Once the character types are computed, the corres-ponding character patterns are produced.
A patternconsists of the same symbols as character types,and contains no sequential redundant occurrencesof the same symbol.
For example, the constituent?January 30th?
has character type ?Xxxxxxx99xx?
and pattern ?X(x) (9)(x)?.On this basis, we employ a classifier that im-plements a Maximum Entropy model2 and per-1In literature such patterns are also known as shorttypes.2http://maxent.sourceforge.net/forms categorization of constituent-phrases ex-tracted from the input.4 Experiments, Results and Error Analy-sisAfter processing the TimeBank corpus of 183documents we had 2612 parsed sentences with1224 temporal expressions in them.
2612 sentencesresulted in 49656 phrase candidates.
We separatedthe data in order to perform 10-fold cross valida-tion, train the classifier and test it on an unseendataset.
The evaluations were conducted with re-spect to the TERN 2004 evaluation plan (TERN,2004) and described in Section 2.1.After running experiments the classifier demon-strated the performance in detection of TIMEX3tags with a minimal overlap of one character withprecision, recall and F1-measure at 0.872, 0.836and 0.852 respectively.
Since the candidate phrasesprovided by the parser do not always exactly alignannotated temporal expressions, the results for theexact match experiments are constrained by an es-timated upper-bound recall of 0.919.
The experi-ments on exact match demonstrated a small declineof performance level and received scores of 0.866,0.796 and 0.828 for precision, recall and F1-measure respectively.Putting the received figures in context, we cansay that with a very few shallow features and astandard machine learning algorithm the recogniz-er of temporal expressions performed at a compa-rable operational level to the rule-based approachof (Boguraev and Ando, 2005) and outperformed itin exact match.
A comparative performance sum-mary is presented in Table 2.Sometimes it is very hard even for humans toidentify the use of obvious temporal triggers in aspecific context.
As a result, many occurrences ofsuch triggers remained unannotated for whichTIMEX3 identification could not be properly car-ried out.
Apart of obvious incorrect parses, in-exact alignment between temporal expressions andcandidate phrases was caused by annotations thatoccurred at the middle of a phrase, for example?eight-years-long?, ?overnight?, ?yesterday?s?.
Intotal there are 99 TIMEX3 tags (or 8.1%) misa-ligned with the parser output, which resulted in 53(or 4.3%) undetected TIMEX3s.55P R F1DetectionOur approach 0.872 0.836 0.852Sloopy Span(Boguraev andAndo, 2005) 0.852 0.952 0.896Exact MatchOur approach 0.866 0.796 0.828(Boguraev andAndo, 2005) 0.776 0.861 0.817Table 2.
Comparative Performance SummaryDefinite and indefinite articles are unsystemati-cally left out or included into TIMEX3 extent,which may introduce an additional bias in classifi-cation.5 Conclusion and Future WorkIn this paper we presented a machine learningapproach for detecting temporal expression using arecent annotated corpus for temporal information,TimeBank.
Employing shallow syntactic and lexi-cal features, the performance level of the methodachieved comparable results to a rule-based ap-proach of Boguraev and Ando (2005) and for theexact match task even outperforms it.
Although adirect comparison with other state-of-the-art sys-tems is not possible, due to different evaluationcorpora, annotation standards and size in particu-lar, our experiments disclose a very important cha-racteristic.
While the recognition systems in theTERN 2004 reported a substantial drop of F1-measure between detection and exact match results(6.5 ?
11.6%), our phrase-based detector demon-strates a light decrease in F1-measure (2.4%), whe-reas the precision declines only by 0.6%.
Thisimportant finding leads us to the conclusion thatmost of TIMEX3s in TimeBank can be detected ata phrase-based level with a reasonably high per-formance.Despite a good recognition performance levelthere is, of course, room for improvement.
Manyimplementations in the TERN 2004 employ a setof apparent temporal tokens as one of the features.In our implementation, the classifier has difficul-ties with very simple temporal expressions such as?now?, ?future?, ?current?, ?currently?, ?recent?,?recently?.
A direct employment of vocabularieswith temporal tokens may substantially increasethe F1-measure of the method, however, it yet hasto be proven.
As reported in (Ahn et al, 2007) aprecise recognition of temporal expressions is aprerequisite for accurate normalization.With our detector and a future normalizer weare able make the first step towards solving theTempEval-2 tasks, which introduce new challengesin temporal information processing: identificationof events, identification of temporal expressionsand identification of temporal relations (Puste-jovsky et al, 2009).
Our future work will be fo-cused on improving current results by a newfeature design, finalizing the normalization taskand identification of temporal relations.
All thesecomponents will result in a solid system infrastruc-ture for all-around temporal analysis.AcknowledgmentsThis work has been partly funded by the Flemishgovernment (through IWT) and by Space Applica-tions Services NV as part of the ITEA2 projectLINDO (ITEA2-06011).ReferencesAhn, D., Adafre, S. F., and de Rijke, M. 2005.
Extract-ing Temporal Information from Open Domain Text:A Comparative Exploration.
Digital InformationManagement, 3(1):14-20, 2005.Ahn, D., van Rantwijk, J., and de Rijke, M. 2007.
ACascaded Machine Learning Approach to Interpret-ing Temporal Expressions.
In Proceedings NAACL-HLT 2007.Boguraev, B., and Ando, R. K. 2005.
TimeBank-DrivenTimeML Analysis.
In Annotating, Extracting andReasoning about Time and Events.
Dagstuhl SeminarProceedings.
Dagstuhl, GermanyBoguraev, B., Pustejovsky, J., Ando, R., and Verhagen,M.
2007.
TimeBank Evolution as a Community Re-source for TimeML Parsing.
Language Resource andEvaluation, 41(1): 91?115.Ferro, L., Gerber, L., Mani, I., Sundheim, B., and Wil-son, G. 2003.
TIDES 2003 Standard for the Annota-tion of Temporal Expressions.
Sept. 2003.timex2.mitre.org.Ferro, L. 2004.
TERN Evaluation Task Overview andCorpus,<http://fofoca.mitre.org/tern_2004/ferro1_TERN2004_task_corpus.pdf> (accessed: 5.03.2009)56Graff, D., Cieri, C., Strassel, S., and Martey, N. 1999.The TDT-2 Text and Speech Corpus.
In Proceedingsof DARPA Broadcast News Workshop, pp.
57-60.Hacioglu, K., Chen, Y., and Douglas, B.
2005.
Auto-matic Time Expression Labeling for English andChinese Text.
In Proceedings of CICLing-2005, pp.348-359; Springer-Verlag, Lecture Notes in Comput-er Science, vol.
3406.Mani, I. and Wilson, G. 2000.
Robust TemporalProcessing of News.
In Proceedings of the 38th An-nual Meeting on Association for Computational Lin-guistics (Hong Kong, October 03 - 06, 2000).
AnnualMeeting of the ACL.
Association for ComputationalLinguistics, Morristown, NJ, pp.
69-76.Negri, M. and Marseglia, L. 2004.
Recognition andNormalization of Time Expressions: ITC-irst atTERN 2004.
Technical Report, ITC-irst, Trento.Poveda, J., Surdeanu, M., and Turmo, J.
2007.
A Com-parison of Statistical and Rule-Induction Learners forAutomatic Tagging of Time Expressions in English.In Proceedings of the International Symposium onTemporal Representation and Reasoning, pp.
141-149.Pustejovsky, J., Hanks, P., Saur?, R., See, A., Day, D.,Ferro, L., Gaizauskas, R., Lazo, M., Setzer, A., andSundheim, B.
2003a.
The TimeBank Corpus.
In Pro-ceedings of Corpus Linguistics 2003, pp.
647-656.Pustejovsky, J., Casta?o, J., Ingria, R., Saur?, R., Gai-zauskas, R., Setzer, A., and Katz, G. 2003b.
Time-ML: Robust Specification of Event and TemporalExpressions in Text.
In Proceedings of IWCS-5, FifthInternational Workshop on Computational Seman-tics.Pustejovsky, J., Verhagen, M., Nianwen, X., Gai-zauskas, R., Hepple, M., Schilder, F., Katz, G., Saur?,R., Saquete, E., Caselli, T., Calzolari, N., Lee, K.,and Im, S. 2009.
TempEval2: Evaluating Events,Time Expressions and Temporal Relations.<http://www.timeml.org/tempeval2/tempeval2-proposal.pdf> (accessed: 5.03.2009)Ratnaparkhi, A.
1999.
Learning to Parse Natural Lan-guage with Maximum Entropy Models.
MachineLearning, 34(1): 151-175.TERN 2004 Evaluation Plan, 2004,<http://fofoca.mitre.org/tern_2004/tern_evalplan-2004.29apr04.pdf> (accessed: 5.03.2009)57
