Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 216?226,Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational LinguisticsUsing Performance Trajectories to Analyze the Immediate Impact of UserState Misclassification in an Adaptive Spoken Dialogue SystemKate Forbes-RileyLearning Research & Development Ctr (LRDC)University of PittsburghPittsburgh, PA 15260forbesk@cs.pitt.eduDiane LitmanDept.
Computer Science & LRDCUniversity of PittsburghPittsburgh, PA 15260litman@cs.pitt.eduAbstractWe present a method of evaluating the imme-diate performance impact of user state mis-classifications in spoken dialogue systems.We illustrate the method with a tutoring sys-tem that adapts to student uncertainty over andabove correctness.
First we define a rank-ing of user states representing local perfor-mance.
Second, we compare user state trajec-tories when the first state is accurately clas-sified versus misclassified.
Trajectories arequantified using a previously proposed met-ric representing the likelihood of transitioningfrom one user state to another.
Comparison ofthe two sets of trajectories shows whether userstate misclassifications change the likelihoodof subsequent higher or lower ranked states,relative to accurate classification.
Our tutoringsystem results illustrate the case where userstate misclassification increases the likelihoodof negative performance trajectories as com-pared to accurate classification.1 IntroductionSpoken dialogue systems research has shown thatnatural language processing errors can negativelyimpact global system performance.
For exam-ple, automatic speech recognition errors have beenshown to negatively correlate with user satisfactionsurveys taken after the system interaction is over(e.g., (Walker et al, 2000a; Pon-Barry et al, 2004)).Automatic user state classification errors havealso been shown to negatively impact global per-formance in spoken dialogue systems (e.g., (Pon-Barry et al, 2006)).
For example, in our prior workwith an uncertainty-adaptive spoken dialogue com-puter tutoring system, we found that recognizing andadapting to the user?s state of uncertainty, over andabove his/her state of correctness, significantly im-proved global learning over all users (as measuredby tests taken before and after the system interac-tion).
However, this was only true when the useruncertainty was manually labeled during the inter-action by an unseen human ?wizard of oz?
(Forbes-Riley and Litman, 2011b); it was not true when theuncertainty was automatically labeled by the system.Further analysis showed that uncertainty classifica-tion errors largely accounted for the global perfor-mance decrease in our fully automated system.
Inparticular, only a small proportion of users?
actualuncertainty was being accurately classified by thesystem (Forbes-Riley and Litman, 2011a).1The question we address in this study is how toanalyze the impact of automatic user state classifi-cation errors when analyzing performance at a locallevel.
In particular, is there a measurable local per-formance difference when one compares what hap-pens in a dialogue after a turn is accurately classi-fied versus misclassified?
We show here how userstate trajectories can be used to answer this ques-tion.
First, a ranking of user states is defined (Sec-tion 3.1).
Second, user state trajectories are com-puted from two sets of system dialogue: one in1In natural language processing (NLP) research, the terms?(in)correct?
and ?(un)certain?
can have multiple interpreta-tions.
To avoid confusion, we reserve these terms in this paperonly to refer to the semantic content and affective/attitudinal ex-pression of user answers (respectively).
When referring to theNLP performance of our system, we use the terms ?accuratelyclassified?
and ?misclassified?.216which the user state of interest is accurately clas-sified in the first turn in the trajectory, and anotherin which it is misclassified (Section 3.2).
Trajec-tories are quantified as the likelihood of transition-ing from one user state to another (D?Mello et al,2007).
Comparison of the two sets of trajectories in-dicates how user state misclassifications change therelative likelihood of subsequent states.
Transitionsto higher ranked states indicate improved local per-formance while transitions to lower ranked states in-dicate decreased local performance.In our research, we are interested in this questionbecause we hypothesize that accurate and inaccurateuser state classification in our uncertainty-adaptivesystem yielded immediate differences in user behav-ior.
We further hypothesize that our uncertainty-adaptive system had a negative immediate impacton the user?s state when (un)certainty was misclas-sified, as compared to when (un)certainty was ac-curately classified.
Our user state trajectory resultssupport these hypotheses.
We find that (un)certaintymisclassifications increased the likelihood of transi-tioning to the lowest ranked user state in the nextturn.
In contrast, accurate (un)certainty classifica-tion yielded an increased likelihood of more positiveperformance trajectories (Section 4).More generally, this question is relevant to otherautomatically classified user states and other typesof dialogue systems, whenever the goal is to un-derstand the immediate impact of user state classi-fication errors on user behavior during the dialogue(Sections 3.1 and Section 5).2 The System and DialoguesWe apply this local performance analysis to dia-logues between college students and our fully auto-mated spoken dialogue tutoring system, ITSPOKE.2Two sets of dialogues are used here, which comefrom two versions of ITSPOKE: the uncertainty-adaptive and non-adaptive versions.
Both ver-sions automatically classify user (un)certainty and(in)correctness for each turn.
However, the non-adaptive version?s responses are based only on(in)correctness, while the uncertainty-adaptive ver-sion provides an uncertainty adaptation to uncer-2ITSPOKE(Intelligent Tutoring SPOKEn dialogue) is aspoken, modified version ofWhy2-Atlas (VanLehn et al, 2002).tain+correct answers.
All dialogues were collectedin our prior experiment comparing global learn-ing across the uncertainty-adaptive and non-adaptivesystem versions (see Section 1).
The uncertainty-adaptive system yielded 120 dialogues (1957 studentturns) from 24 subjects.
The non-adaptive systemyielded 125 dialogues (2065 student turns) from 25subjects.
Our analysis will focus on the dialoguesfrom the uncertainty-adaptive system (Section 4.1);the dialogues from the non-adaptive system will beused for comparison (Section 4.2).Briefly, ITSPOKE tutors 5 physics problems (oneper dialogue), in a Tutor Question - Student Answer- Tutor Response format.
The tutor questions seri-ally present topics needed to solve each problem; ad-jacent questions concern identical or closely relatedtopics.
After each tutor question, the student answeris digitized from head-mounted microphone inputand sent to the Sphinx2 recognizer, which yields anautomatic transcript.
The answer?s (in)correctness isthen automatically classified based on this transcript,using the TuTalk semantic analyzer (Jordan et al,2007).
Simultaneously, the answer?s (un)certaintyis automatically classified by inputting features ofthe speech signal, the automatic transcript, and thedialogue context into a logistic regression model.3All natural language processing components weretrained using prior ITSPOKE corpora.The dialogue manager determines the appropriatetutor response and sends it to the Cepstral text-to-speech system.
The uncertainty-adaptive and non-adaptive system versions give the same response toincorrect answers (regardless of (un)certainty): in-correctness feedback (e.g., ?That?s not right?)
fol-lowed by additional remedial content to help stu-dents understand why their answer was incorrect.Both versions also give the same response to cer-tain+correct answers: correctness feedback only(e.g., ?That?s right?).
The two versions differ in theirresponse to uncertain+correct answers.
The non-adaptive version responds with correctness feed-back only, while the uncertainty-adaptive version re-sponds with correctness feedback followed by addi-tional remedial content to help students resolve theiruncertainty.
This uncertainty adaptation is based on3The uncertainty model includes lexical, pitch, temporal,and energy features as well as tutor question and user gender,and is described further in (Forbes-Riley and Litman, 2011a).217tutor1: Let?s begin by looking at the motion of the man and his keys while he?s holding them.
How does his velocitycompare to that of his keys?student-automatic1: his also the is the same as that of his keys points force (certain+incorrect)student-manual1: his velocity is the same as that of his keys while he?s holding them (uncertain+correct)tutor2: Actually... Their velocities must be the same, because the man?s holding his keys, so they?re not moving withrespect to each other.
[...] What are the forces exerted on the man after he releases his keys?student-automatic2: gravity (uncertain+correct)student-manual2: gravity??
(uncertain+correct)non-adaptive-tutor3: Right.
So what?s the direction of the force of gravity on the man (e.g., vertically up)?uncertainty-adaptive-tutor3: Right.
Gravity is the only force acting on the man.
This force is also called the weightof the man.
It?s always present when an object is in earth?s gravitational field.
So what?s the direction of the force ofgravity on the man (e.g., vertically up)?Figure 1: Annotated Dialogue Example Showing Uncertainty Adaptation and User State Classificationsprior tutoring research, which argues that incorrect-ness and uncertainty are both signals of a ?learn-ing impasse?, i.e., an opportunity to better learn thematerial (VanLehn et al, 2003).
Our uncertaintyadaptation only provides additional remedial con-tent after the uncertain+correct impasse, because in-correctness impasses (uncertain and certain) alreadyreceive remedial content from the non-adaptive sys-tem.
It is assumed that this content helps resolveboth incorrectness and uncertainty (when present).After the experiment, each student answer(turn) was manually transcribed and labeled for(un)certainty and (in)correctness.
One labelerperformed the annotation based on schemes devel-oped and evaluated on prior ITSPOKE corpora,where this labeler and another labeler displayedinterannotator reliability of 0.85 and 0.62 Kappaon (in)correctness and (un)certainty, respec-tively (Forbes-Riley and Litman, 2011a).4 Com-parison of the automatic and manual labels yielded84.7% accuracy for automatic (in)correctnessclassification and 80.3% accuracy for auto-matic (un)certainty classification.
However, the(un)certainty model had an uncertainty recall ofonly about 20%, while the (in)correctness modelhad a correctness recall of about 80% (Forbes-Rileyand Litman, 2011a).54Because these evaluations showed that this trained labelercould reliably annotate (un)certainty and (in)correctness in IT-SPOKE dialogues, no further evaluations were performed.5The lower recall for predicting uncertainty is neverthe-Figure 1 illustrates ITSPOKE?s natural languageprocessing components and the two system versions.The first answer is classified as certain+incorrect(student-automatic1) but manually labeled as un-certain+correct (student-manual1); the manual andautomatic transcripts are also substantially differ-ent.
Because this answer was misclassified as in-correct, both versions give the same response (tu-tor2).
The second answer is accurately classified asuncertain+correct.
The non-adaptive system thus ig-nores the uncertainty and only provides correctnessfeedback (non-adaptive-tutor3), while the adaptivesystem responds with correctness feedback and ad-ditional remedial content to help resolve the uncer-tainty (uncertainty-adaptive-tutor3).3 Local Performance EvaluationHere we discuss how to evaluate the local impact ofuser state misclassification in dialogue systems.3.1 Defining a User State Severity RankingBuilding on tutoring research that views both uncer-tainty and incorrectness as signals of learning im-passes (Section 2), we previously defined a sever-ity ranking for the four impasse states correspond-ing to all combinations of binary (in)correctnessless higher than always predicting no uncertainty (a majorityclass baseline has 0% recall), and is on par with prior work inaffect-adaptive tutoring systems, e.g.
(Walonoski and Heffer-nan, 2006); in general affective systems research has found itdifficult to accurately predict positive occurrences of affect.218Impasse State: certain+incorrect uncertain+incorrect uncertain+correct certain+correctSeverity: most less least noneFigure 2: User Impasse State Severity Rankingand (un)certainty (Forbes-Riley and Litman, 2011a).This ranking, shown in Figure 2, reflects the as-sumption that a student must perceive an impasse inorder to resolve it.
A state of uncertainty reflects thisawareness.
Therefore, the most severe type of learn-ing impasse occurs when a student is incorrect butnot aware of it.
Impasse states of decreasing sever-ity occur when the student is incorrect but aware thats/he might be, and correct but believes s/he may notbe, respectively.
No impasse exists when a studentis correct and not uncertain about it.In our prior work, this ranking of user states wasindependently validated by showing that average im-passe state severity negatively correlates with globallearning gain in our system dialogues (Forbes-Rileyand Litman, 2011a).
In other words, a higher pro-portion of user states with less severe or no impassesdirectly relates to higher global learning gain.More generally, the idea of ranking user states interms of those that do or do not represent communi-cation impasses applies to other dialogue system do-mains and other user state dimensions as well.
Forexample, in information-seeking domains, frustra-tion and anger are common affective states whoseoccurrence during the dialogue signals severe com-munication problems (Batliner et al, 2003), whilehang-ups and turns requesting a human operator areother types of user states whose occurrence dur-ing the dialogue signals severe communication prob-lems (Walker et al, 2000b).Moreover, state trajectories can be used to repre-sent abstractions over other types of user (or system)behaviors.
In our tutoring system analysis, repre-senting user states in terms of only (un)certainty and(in)correctness is an abstraction that we find usefulfor analyzing impasse trajectories.
However, dur-ing run-time, a finite-state dialogue manager con-sisting of 142 states actually controls the system?soperation, and uses many other features besides useruncertainty and incorrectness to determine the sys-tem?s response (e.g.
the physics concepts related tothe current system question, the history of prior stu-dent answers to similar questions, etc.).
Any of thesestates could be analyzed as well to understand theirlocal performance impact, as could their analogs inother system domains.
For example, in a train di-alogue system, while the actual state representationused during operation could be quite complex, fora trajectory analysis a simpler representation couldbe suitable, one which tracks whether the systemknows the values of the n attributes needed to querythe database.
The state ranking in this case wouldbe over equivalence classes of states: states with nattributes known > states with n-1 attributes known> ... > initial state with 0 attributes known.3.2 Computing User State TrajectoriesLocal trajectories of user states during a dialoguecan be computed as the likelihood of transitioningfrom the user state in turn n to the user state in turnn+1.
Here we use D?Mello et al?s metric, transitionlikelihood L (D?Mello et al, 2007).Transition likelihood L is computed as shown be-low, where n refers to the impasse state in turn nand n+1 refers to the impasse state in turn n+1.
Asshown, L is computed as the conditional probabil-ity that the user state in turn n+1 will occur giventhat the user state in turn n has occurred, adjustedfor the base rate of occurrence of the user state inturn n+1.
The denominator normalizes the result sothat L ranges from -?
to 1.
L=1 indicates that n+1always follows n over and above the probability ofn+1 occurring.
L=0 indicates that n+1 follows n atthe chance level.
L<0 indicate that the likelihood ofn+1 following n is much lower than the base rate ofn+1 occurring.6L(n?n+1) = P (n+1|n)?P (n+1)1?P (n+1)Transition likelihood L has previously been usedto compute the likelihood of transitioning from oneaffective state to another (e.g., from confusion to6Note that this metric, which assesses the adjusted probabil-ity of one user state following another, is equivalent to Kappain computing agreement among annotators after adjusting forchance (D?Mello et al, 2007).219frustration) in a single set of dialogues betweenstudent and computer tutor (D?Mello et al, 2007).Transition likelihood L has also been used to com-pare how the likelihoods of transitioning from oneaffective state to another vary across two differ-ent sets of dialogues collected with two differentversions of an affect-adaptive tutoring system (Mc-Quiggan et al, 2008).
Our analysis is based onthis analysis, but extends it in three ways: 1) ourtransitions involve complex user states composed oftwo dimensions ((un)certainty and (in)correctness),2) the user states in our transitions are ranked toenable a local performance analysis, 3) our perfor-mance analysis is applied to the question of how userstate misclassification impacts local performance,by comparing transition likelihoods after accurateand inaccurate user state classifications.In this prior work and in our work, likelihoodsfor each transition are computed for each user (overall dialogues of a user).
ANOVAs with post-hocpairwise tests can then determine if there were sig-nificant differences between all possible transitionsfrom the current user state in turn n.To investigate how user state misclassificationsimpact local performance, two user trajectories arecomputed per user for each n?n+1 transition: onewhen the manual and automatic user state labelsfor turn n agreed, and another when they did notagree.
In both cases, using the manual label for turnn+1 enables the true final user state to be comparedacross the two sets of trajectories.
Comparison ofthe final state in the two sets of trajectories indicateshow user state misclassifications change the relativelikelihood of the subsequent user states.
Transitionsto higher ranked states indicate improved local per-formance while transitions to lower ranked states in-dicate decreased local performance.4 Impact of User State Misclassificationsin Uncertainty-Adaptive ITSPOKEWe now apply this analysis to the uncertainty-adaptive ITSPOKE dialogues, to investigate howuser state misclassification impacts the local perfor-mance of the uncertainty adaptation.Since the complex user state of uncertain+correcttriggers the uncertainty adaptation, misclassifying(un)certainty or (in)correctness can potentially im-pact the local performance of the adaptation.
How-ever, as noted in Section 2, we previously foundthat uncertainty misclassifications in our systemwere more severe than correctness misclassifica-tions.
Thus, to streamline our analysis and avoiddata skew issues, we focus on how (un)certaintymisclassifications in manually labeled correct an-swers impact our local performance trajectories.There are 1270 manually labeled correct turns inthe dialogues collected with uncertainty-adaptiveITSPOKE.
In the dialogues collected with non-adaptive ITSPOKE (which we will use for compari-son), there are 1353 manually labeled correct turns.We hypothesize that when (un)certainty misclas-sification in correct answers causes the uncertaintyadaptation to be erroneously triggered or blocked,we will see a negative performance impact, in termsof an increased likelihood of transitioning to a moresevere impasse state when uncertainty is misclassi-fied as compared to when it is accurately classified.4.1 Uncertainty-Adaptive ITSPOKE ResultsAccurate Uncertainty Classification: Figure 3presents descriptive statistics for the likelihood (L)that a manually labeled uncertain+correct answeraccurately classified as uncertain in turn n will tran-sition to each of the four manually labeled impassestates in turn n+1.
As noted in Section 3.2, L=0 indi-cates that the transition likelihood is equal to chance,while L>0 and L<0 indicate likelihoods greater andless than chance, respectively.An ANOVA indicated that there were statisticallysignificant differences among the likelihoods in Fig-ure 3 (F(3,56)=3.87, p=.02).
The most likely transi-tions are shown with stripes.
Specifically, post-hocpairwise tests showed that in turn n+1, an uncer-tain+incorrect answer (p<.01) or uncertain+correctanswer (p=.02) is significantly more likely than acertain+correct answer (but are themselves equallylikely).
In addition, an uncertain+incorrect answeris significantly more likely than a certain+incorrectanswer (p=.05), in turn n+1.
A dialogue example ofthe most likely transition after accurately classifieduncertainty is shown in Figure 5, where it is com-pared with the misclassified minimal pair in Figure 6(see Appendix).These results indicate that accurately classifying(and thus accurately adapting to) uncertain+correct220Figure 3: Turn n?
Turn n+1 Transition Likelihoods (L)after a manually labeled uncertain+correct answer in turnn is accurately classified as uncertain and receives the un-certainty adaptationanswers is most likely to yield continued uncertainty(regardless of correctness) in turn n+1.
Prior re-search (Craig et al, 2004; Kort et al, 2001) hasshown that uncertainty and questioning are positiveand crucial aspects of the learning process.
Thecontinued uncertainty suggests that the uncertaintyadaptation keeps the student engaged in the learn-ing process, and the equal likelihood of correctnessor incorrectness accompanying this uncertainty sug-gests that they have not yet unreservedly adopted ei-ther the correct or incorrect line of reasoning aboutthe topic under discussion.To determine whether any of these transitions aredirectly tied to global performance, we computedPearson?s correlations over all students between thepercentage of each transition and global learninggain.7 Interestingly, transitioning from an accu-rately classified correct+uncertain answer to a cor-rect+certain answer is negatively related to globallearning gain (R=-.458, p=.025).
This indicates thatcontinued uncertainty after the uncertainty adapta-tion is provided is more beneficial, in the long run,than no uncertainty.
No other trajectories are di-rectly related to global learning.
Although our priorresult, that average impasse severity negatively cor-relates with global learning gain (Section 3.1), indi-cates it is better from a global perspective for a stu-dent to be in a state of no impasse (correct+certain),it does not tell us the best way for the student to at-7normalized learning gain = (posttest-pretest)/(1-pretest).tain this state.
The results of our transition correla-tions shed light on this - they tell us that transitioningdirectly from correct+uncertain is not the best wayto attain the no impasse state.
We hypothesize thatlooking at wider transition windows (e.g., trigrams)will shed light on what is the best way to attain thisstate.
For example, it may be that the best way totransition to a state of no impasse is to do so aftersustained uncertainty (as in Figure 3).Uncertainty Misclassification: Considering nowuser state misclassifications, our results for accu-rately classified uncertain+correct answers are insharp contrast to those for manually labeled uncer-tain+correct answers misclassified as certain in turnn.
In particular, an ANOVA indicated that all manu-ally labeled impasse states are equally likely in n+1(F(3,88)=1.22, p=.32) after a misclassified uncer-tain+correct answer.8These results indicate that misclassifying (anderroneously not adapting to) uncertain+correct an-swers is as likely to have an immediate negative im-pact on learning as it is to have a neutral or positiveimpact.
In particular, the misclassification is likelyto cause some students to transition from the leastsevere impasse about the concept in turn n to themost severe impasse about the concept in turn n+1.9When they do not receive the uncertainty adaptation,these students adopt an incorrect line of reasoning inturn n+1, without any uncertainty about it at all.As illustration, compare the example in Figure 5,where uncertainty is accurately classified, with theexample in Figure 6, where uncertainty is misclas-sified (see Appendix).
As shown, the uncertainty instudent-manual1 signals that further explanation isneeded.
When received (Figure 5) the student stillmakes a math error on the next question, but s/heappears to understand the task.
In contrast, when theuncertainty adaptation is erroneously not received(Figure 6), there is no indication that the student?sunderstanding has increased; s/he appears to be sim-ply repeating the number 9.8 (a number which ap-pears frequently in Newtonian physics).
User uncer-tainty misclassification in other domains could have8Since the ANOVA results were non-significant, no figureor correlations are discussed.9As noted in Section 2, adjacent turns within a dialogue willeither address the same or closely related topics.221similar effects; in general, if a user is uncertain inturn n about how to perform a task, and the systemmoves on without supplying information to resolvethis uncertainty, there may be an immediate negativeimpact if that knowledge is required or presupposedagain in turn n+1.Accurate Certainty Classification: Turning nowto manually labeled certain+correct answers, Fig-ure 4 presents descriptive statistics for the likelihoodthat when accurately classified as certain in turnn, certain+correct answers will transition to eachof the four manually labeled impasse states in turnn+1.
An ANOVA indicated that there were statisti-cally significant differences among these likelihoods(F(3,92)=17.96, p<.01).
The most likely transitionsare shown with stripes.
More specifically, post-hocpairwise tests showed that in turn n+1, a manuallylabeled certain+correct answer is significantly morelikely than any other impasse state (p<.01), and allother impasse states were equally likely.
A dialogueexample of the most likely transition after accuratelyclassified certainty is shown in Figure 7, where it iscompared with the misclassified minimal pair in Fig-ure 8 (see Appendix).These results indicate that accurately classifyingand not adapting to certain+correct answers has animmediate positive impact on the learning process,by not introducing learning impasses about conceptsalready understood.
Note however that Pearson?scorrelations for these transitions showed no signif-icant relation to global performance.Certainty Misclassification: Again, our resultsfor accurately classified certain+correct answers arein sharp contrast with those found for manually la-beled certain+correct answers misclassified as un-certain in turn n. An ANOVA indicated that all man-ually labeled impasse states are equally likely in turnn+1 (F(3,72)=0.33, p=.80).
These results indicatethat misclassifying and erroneously adapting to cer-tain+correct answers is as likely to have an imme-diate negative impact on learning as it is to have aneutral or positive impact.
In particular, the misclas-sification is likely to cause some students to tran-sition from no impasse to the most severe impassestate.
When they erroneously receive the uncertaintyadaptation, these students go from no impasse at allin turn n to an incorrect line of reasoning in turn n+1,Figure 4: Turn n?
Turn n+1 Transition Likelihoods (L)after a manually labeled certain+correct answer in turn nis accurately classified as certain and does not receive theuncertainty adaptationwithout any uncertainty about it at all.As illustration, compare the example in Figure 7,where certainty is accurately classified, with the ex-ample in in Figure 8, where certainty is misclas-sified (see Appendix).
As shown, the certainty instudent-manual1 signals that no further explanationis needed so the system can move on (Figure 7).When the uncertainty adaptation is erroneously re-ceived even though the student is certain (Figure 8),this appears to have caused the student to stop pay-ing close attention and thus provide an obviously in-correct answer to an easy question.
User certaintymisclassification in other domains could have simi-lar effects; in general, if a user is already certain inturn n about how to perform a task, and the system?wastes?
his/her time by resupplying informationthat is already understood, there may be an imme-diate negative impact in terms of loss of focus, dis-engagement, or even decreased understanding, thatcause the task in turn n+1 to be performed incor-rectly.4.2 Comparing Non-Adaptive ITSPOKEAs a sanity check, we performed the same trajec-tory analysis on the dialogues from the non-adaptiveversion of the system.
The purpose here was to con-firm the presupposition of the above analysis, thatuncertainty-adaptive ITSPOKE was actually pro-ducing different local behaviors than non-adaptiveITSPOKE.
In other words, since the non-adaptive222system ignores uncertainty, there should be no dif-ference in transition likelihoods when uncertainty isaccurately classified versus when it is misclassified.This expectation was borne out.
ANOVAs indi-cated that in the non-adaptive system, a manuallylabeled uncertain+correct answer is equally likelyto transition to any of the four manually labeledimpasse states in turn n+1, regardless of whetherit was accurately classified as uncertain in turn n(F(3,48)=0.25, p=.86) or misclassified as certain inturn n (F(3,92)=0.07, p=.98).
Thus as expected, un-certain+correct answers in the non-adaptive systempattern like uncertain+correct answers misclassifiedas certain in the uncertainty-adaptive system.
Inboth cases, we see the same negative immediate per-formance impact of not giving uncertain+correct an-swers the uncertainty adaptation.ANOVAs with post-hoc pairwise tests further in-dicated that in the non-adaptive system, a manuallylabeled certain+correct answer is significantly morelikely to transition to a certain+correct answer thanto any other manually labeled impasse state, regard-less of whether it was accurately classified as certainin turn n (ANOVA:(F(3,96)=20.81, p<.001), post-hoc tests: p<.001) or misclassified as uncertain inturn n (ANOVA:(F(3,80)=14.00, p<.001), post-hoctests: p<.001).
Thus as expected, certain+correctanswers in the non-adaptive system pattern like ac-curately classified certain+correct answers in theuncertainty-adaptive system.
In both cases, we seethe same positive immediate performance impact ofnot giving manually labeled certain+correct answersthe uncertainty adaptation.4.3 Comparing Local and Global PerformanceResultsFinally, in analyses such as this one, comparing lo-cal and global performance results can help pinpointspecific areas for future system redesign.
In ourcase, this comparison suggests the most importantaspect to focus on with respect to improving our un-certainty model.In particular, as noted in Section 1, we previ-ously found that the low uncertainty recall of oursystem (approximately 20%) had a negative globalperformance impact; mistaking so much true uncer-tainty for certainty substantially reduced the amountusers learned (Forbes-Riley and Litman, 2011a).We also showed in this prior work that mistakingcertainty for uncertainty did not negatively impactthe amount users learned.
These results suggestedthat the system should be less cautious in applyingthe uncertainty-adaptive behavior; i.e., applying itwhenever there is some possibility that the user is ac-tually uncertain, even if it means applying it to someturns that are actually certain.On the other hand, our local performance analy-sis in this paper showed that (un)certainty misclas-sification increased the likelihood of an immediatenegative impact on learning.
These results suggestthat the system should be more cautious in applyingthe uncertainty-adaptive behavior; i.e., only apply-ing it when there is a high probability that the useris actually uncertain.Together these local and global results suggestthat we should focus on improving uncertainty re-call without decreasing uncertainty precision, in ouruncertainty model.
With this goal in mind, we arecurrently exploring the use of features and methodsfrom recent INTERSPEECH emotion and paralin-guistic challenges (Schuller et al, 2009; Schuller etal., 2010).5 Conclusion and Future DirectionsThis paper presents an approach for analyzing theimmediate impact of user state misclassifications indialogue systems.
A ranking of user states is de-fined, and then user state trajectories are comparedwhen the first state is accurately classified versusmisclassified.
Trajectories are quantified using apreviously proposed metric representing the likeli-hood of transitioning between states.
Comparisonof the two sets of trajectories shows whether mis-classifications change the likelihood of subsequenthigher or lower ranked states, relative to accurateclassification.
We illustrated the approach with anadaptive tutoring system that automatically detectsand adapts to student uncertainty.As our results indicate, the approach can be usedto answer questions which global performance anal-yses overlook.
First, the analysis shows whetheruser state misclassifications actually matter locally- whether these errors have an immediate effect onuser behavior or not.
Moreover, the analysis can de-termine whether this effect is positive or negative or223neutral.
In our tutoring system data, we found thatmisclassifying user uncertainty had a negative im-mediate impact on user behavior, relative to accurateclassification.The analysis can also confirm that a dialogue in-tervention actually changes user behaviors.
In ourtutoring system data, we found that the adaptive sys-tem yielded significantly different user state trajec-tories than the non-adaptive system, even though,as noted in Section 1, our prior global performanceanalysis did not show any overall differences amongthe global performance metrics that we examinedacross the adaptive and non-adaptive systems.In addition, the analysis can confirm that a dia-logue intervention shifts user behaviors in the de-sired direction.
In our tutoring system data, wefound that the immediate effect of accurately adapt-ing to uncertainty was most likely to be continueduncertainty.
Although the adaptation does not yieldan immediate transition to the highest ranked userstate, the outcome is clearly more positive than thatof ignoring uncertainty, which increases the likeli-hood of transitioning to the lowest ranked user state.Finally, the local performance results can shedlight on the steps needed to improve global perfor-mance, by investigating how the two are related.
Inour tutoring system data, we found that there is not aone-to-one relationship between the most beneficiallocal and global outcomes.
In particular, transition-ing directly to the highest ranked (no impasse) stateafter receiving the uncertainty adaptation was neg-atively correlated to global learning gain.
We hy-pothesized that looking at wider transition windows(e.g., trigrams) will shed light on what is the bestlocal path to the highest ranked state.We conclude by emphasizing that state trajecto-ries can be used to represent abstractions over var-ious types of user (or system) behaviors, in variousdomains, whenever their local performance impactis viewed as important to understand.AcknowledgmentsThis work is funded by NSF awards #0914615 and#0631930.
We thank Reva Freedman and the IT-SPOKE group for comments.ReferencesA.
Batliner, K. Fischer, R. Huber, J. Spilker, and E. Noth.2003.
How to find trouble in communication.
SpeechCommunication, 40:117?143.S.
Craig, A. Graesser, J. Sullins, and B. Gholson.
2004.Affect and learning: an exploratory look into the roleof affect in learning with AutoTutor.
Journal of Edu-cational Media, 29(3).S.
D?Mello, R. S. Taylor, and A. Graesser.
2007.
Mon-itoring affective trajectories during complex learning.In Proc.
Cognitive Science Society.K.
Forbes-Riley and D. Litman.
2011a.
Benefits andchallenges of real-time uncertainty detection and adap-tation in a spoken dialogue computer tutor.
SpeechCommunication.
In Press.K.
Forbes-Riley and D. Litman.
2011b.
Designing andevaluating a wizarded uncertainty-adaptive spoken di-alogue tutoring system.
Computer Speech and Lan-guage, 25(1):105?126.P.
Jordan, B.
Hall, M. Ringenberg, Y. Cui, and C.P.
Rose.2007.
Tools for authoring a dialogue agent that par-ticipates in learning studies.
In Proc.
Artificial Intelli-gence in Education.B.
Kort, R. Reilly, and R. Picard.
2001.
An affectivemodel of interplay between emotions and learning :Reengineering educational pedagogy-building a learn-ing companion.
In Proc.
IEEE Conference on Ad-vanced Learning Technology.S.
W. McQuiggan, J. L Robison, and J. C. Lester.
2008.Affective transitions in narrative-centered learning en-vironments.
In Proc.
Intelligent Tutoring SystemsConference.Heather Pon-Barry, Brady Clark, Elizabeth Owen Bratt,Karl Schultz, and Stanley Peters.
2004.
Evaluating theeffectiveness of SCoT:a spoken conversational tutor.In Proceedings of ITS Workshop on Dialogue-basedIntelligent Tutoring Systems.H.
Pon-Barry, K. Schultz, E. Bratt, B. Clark, and S. Pe-ters.
2006.
Responding to student uncertainty in spo-ken tutorial dialogue systems.
International Journalof Artificial Intelligence in Education, 16.B.
Schuller, S. Steidl, and A. Batliner.
2009.
The Inter-speech 2009 emotion challenge.
In Proc.
Interspeech.B.
Schuller, S. Steidl, A. Batliner, F. Burkhardt, L. Dev-illers, C. Muller, and S. Narayanan.
2010.
The IN-TERSPEECH 2010 paralinguistic challenge.
In Proc.Interspeech.K.
VanLehn, P. Jordan, C.
Rose?, D. Bhembe, M. Bo?ttner,A.
Gaydos, M. Makatchev, U. Pappuswamy, M. Rin-genberg, A. Roque, S. Siler, R. Srivastava, and R. Wil-son.
2002.
The architecture of Why2-Atlas: A coachfor qualitative physics essay writing.
In Proc.
Intelli-gent Tutoring Systems Conference.224K.
VanLehn, S. Siler, and C. Murray.
2003.
Why doonly some events cause learning during human tutor-ing?
Cognition and Instruction, 21(3).Marilyn A. Walker, Candace A. Kamm, and Diane J. Lit-man.
2000a.
Towards developing general models ofusability with PARADISE.
Natural Language Engi-neering, 6(3).Marilyn A. Walker, Irene Langkilde, Jerry Wright, AllenGorin, and Diane Litman.
2000b.
Learning to pre-dict problematic situations in a spoken dialogue sys-tem: Experiments with How May I Help You?
InProceedings of the 1st Meeting of the North AmericanChapter of the Association of Computational Linguis-tics (NAACL).J.
A. Walonoski and N. T. Heffernan.
2006.
Detec-tion and analysis of off-task gaming behavior in in-telligent tutoring systems.
In Proceedings of the 8thInternational Conference on Intelligent Tutoring Sys-tems (ITS), pages 382?391, Jhongli, Taiwan.225APPENDIXtutor1: If an object in freefall begins with a velocity of zero, what?ll its velocity be a second later?
Please specify theunits too.student-automatic1: 9.8 meters per second (uncertain+correct)student-manual1: 9.8 meters per second??
(uncertain+correct)tutor2: Fine.
Because it?s in freefall, its acceleration is 9.8m/s2.
This tells us that every second, its velocity increasesby 9.8 m/s.
Therefore, at one second its velocity is 0 m/s, and a second later, its velocity is 9.8m/s.
So, what?ll itsvelocity be a second after that?student-manual2: 18.6 meters per second??
(uncertain+incorrect)Figure 5: Annotated Dialogue Example of Most Likely Transition after Accurate Uncertainty Classificationtutor1: If an object in freefall begins with a velocity of zero, what?ll its velocity be a second later?
Please specify theunits too.student-automatic1: 9.8 meters per second (certain+correct)student-manual1: 9.8 meters per second??
(uncertain+correct)tutor2: Fine.
So, what?ll its velocity be a second after that?student-manual2: 9.8 meters per second (certain+incorrect)Figure 6: Annotated Dialogue Example of Negative Impact of Uncertainty Misclassificationtutor1: There?s only one horizontal force exerted on the truck during the collision with the car.
What is it?student-automatic1: impact force (certain+correct)student-manual1: the impact force (certain+correct)tutor2: Right.
Now let?s find the forces exerted on the truck in the vertical direction during the collision.
First, whatvertical force is always exerted on an object near the surface of the earth?student-manual2: gravity (certain+correct)Figure 7: Annotated Dialogue Example Showing Most Likely Transition after Accurate Certainty Classificationtutor1: There?s only one horizontal force exerted on the truck during the collision with the car.
What is it?student-automatic1: impact force (uncertain+correct)student-manual1: the impact force (certain+correct)tutor2: Right.
The problem statement says the car and the truck are both traveling in a straight horizontal line whenthey collide.
So the impact force of the truck on the truck must be in the horizontal direction.
It also says they aredriving on a patch of frictionless ice when they collide.
So there is no friction to take into account.
This means thatthe impact force is the only horizontal force on the truck.
Now let?s find the forces exerted on the truck in the verticaldirection during the collision.
First, what vertical force is always exerted on an object near the surface of the earth?student-manual2: normal force (certain+incorrect)Figure 8: Annotated Dialogue Example Showing Negative Impact of Certainty Misclassification226
