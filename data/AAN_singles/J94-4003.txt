Word Sense Disambiguation Using aSecond Language Monolingual CorpusIdo Dagan*AT&T Bell LaboratoriesAlon Itai tTechnion--Israel Institute of TechnologyThis paper presents a new approach for resolving lexical ambiguities in one language using statis-tical data from a monolingual corpus of another language.
This approach exploits the differencesbetween mappings of words to senses in different languages.
The paper concentrates on the prob-lem of target word selection in machine translation, for which the approach is directly applicable.The presented algorithm identifies yntactic relations between words, using a source languageparser, and maps the alternative interpretations ofthese relations to the target language, using abilingual exicon.
The preferred senses are then selected according to statistics on lexical relationsin the target language.
The selection is based on a statistical model and on a constraint prop-agation algorithm, which simultaneously handles all ambiguities in the sentence.
The methodwas evaluated using three sets of Hebrew and German examples and was found to be very use-ful for disambiguation.
The paper includes a detailed comparative analysis of statistical sensedisambiguation methods.1.
IntroductionThe resolution of lexical ambiguities in nonrestricted text is one of the most difficulttasks of natural anguage processing.
A related task in machine translation, on whichwe focus in this paper, is target word selection.
This is the task of deciding whichtarget language word is the most appropriate quivalent of a source language wordin context.
In addition to the alternatives introduced by the different word senses ofthe source language word, the target language may specify additional alternatives thatdiffer mainly in their usage.Traditionally, several inguistic levels were used to deal with this problem: syn-tactic, semantic, and pragmatic.
Computationally, the syntactic methods are the mostaffordable, but are of no avail in the frequent situation when the different senses of theword show the same syntactic behavior, having the same part of speech and even thesame subcategorization frame.
Substantial pplication of semantic or pragmatic knowl-edge about the word and its context requires compiling huge amounts of knowledge,the usefulness of which for practical applications in broad domains has not yet beenproven (e.g., Lenat et al 1990; Nirenburg et al 1988; Chodorow, Byrd, and Heidron1985).
Moreover, such methods usually do not reflect word usages.Statistical approaches, which were popular several decades ago, have recentlyreawakened and were found to be useful for computational linguistics.
Within thisframework, a possible (though partial) alternative to using manually constructed* AT&T Bell Laboratories, 600 Mountain Avenue, Murray Hill, NJ 07974, USA.
E-mail:dagan@research.att.com.
The work reported here was done while the author was at theTechnion--Israel Institute of Technology.t Department of Computer Science, Technion--Israel Institute of Technology, Haifa 32000, Israel.
E-maihitai@cs.technion.ac.il.
(~) 1994 Association for Computational LinguisticsComputational Linguistics Volume 20, Number 4knowledge can be found in the use of statistical data on the occurrence of lexical re-lations in large corpora (e.g., Grishman, Hirschman, and Nhan 1986).
The use of suchrelations (mainly relations between verbs or nouns and their arguments and modi-fiers) for various purposes has received growing attention in recent research (Churchand Hanks 1990; Zernik and Jacobs 1990; Hindle 1990; Smadja 1993).
More specifically,two recent works have suggested using statistical data on lexical relations for resolvingambiguity of prepositional phrase attachment (Hindle and Rooth 1991) and pronounreferences (Dagan and Itai 1990, 1991).Clearly, statistics on lexical relations can also be useful for target word selection.Consider, for example, the Hebrew sentence xtracted from the foreign news sectionof the daily Ha-Aretz, September 1990 (transcripted to Latin letters):(1) Nose ze mana" mi-shtei ha-mdinot mi-lahtom "al hoze shalom.issue this prevented from-two the-countries from-signing on treaty peace\[This sentence would translate into English as(2) This issue prevented the two countries from signing a peace treaty.The verb lahtom has four senses: 'sign,' 'seal,' finish,' and 'close.'
The noun hozemeans both 'contract' and 'treaty,' where the difference is mainly in usage rather thanin the meaning (in Hebrew the word h.oze is used for both sub-senses).One possible solution is to consult a Hebrew corpus tagged with word senses,from which we would probably learn that the sense 'sign' of lahtom appears morefrequently with hoze as its object han all the other senses.
Thus we should prefer thatsense.
However, the size of corpora required to identify lexical relations in a broaddomain is very large, and therefore it is usually not feasible to have such corporamanually tagged with word senses) The problem of choosing between 'treaty' and'contract' cannot be solved using only information on Hebrew, because Hebrew doesnot distinguish between them.The solution suggested in this paper is to identify the lexical relations in corporaof the target language, instead of the source language.
We consider word combinationsand count how often they appear in the same syntactic relation as in the ambiguoussentence.
For the above example, the noun compound 'peace treaty' appeared 49 timesin our corpus (see Section 4.3 for details on our corpus), whereas the compound 'peacecontract' did not appear at all; the verb-obj combination 'to sign a treaty' appeared 79times, whereas none of the other three alternatives appeared more than twice.
Thus,we first prefer 'treaty' to 'contract' because of the noun compound 'peace treaty' andthen proceed to prefer 'sign' since it appears most frequently having the object 'treaty.
'The order of selection is determined by a constraint propagation algorithm.
In bothcases, the correctly selected word is not the most frequent one: 'close' is more frequentin our corpus than 'sign' and 'contract' is more frequent than 'treaty.'
Also, by usinga model of statistical confidence, the algorithm avoids a decision in cases in which noalternative is significantly better than the others.Our approach can be analyzed from two different points of view.
From that ofmonolingual sense disambiguation, we exploit the fact that the mapping betweenwords and word senses varies significantly among different languages.
This enables1 Hearst (1991) suggests a sense disambiguation scheme along this line.
See Section 7 for a comparisonof several sense disambiguation methods.564Ido Dagan and Alon Itai Word Sense DisambiguationUS to map an ambiguous construct from one language to another, obtaining repre-sentations in which each sense corresponds to a distinct word.
Now it is possibleto collect co-occurrence statistics automatically from a corpus of the other language,without requiring manual tagging of senses.
2From the point of view of machine translation, we suggest hat some ambigu-ity problems are easier to solve at the level of the target language than the sourcelanguage.
The source language sentences are considered a noisy source for target lan-guage sentences, and our task is to devise a target language model that prefers themost reasonable translation.
Machine translation is thus viewed in part as a recogni-tion problem, and the statistical model we use specifically for target word selectionmay be compared with other language models in recognition tasks (e.g., Katz 1987;Jelinek 1990, for speech recognition).
To a limited extent, this view is shared with thestatistical machine translation system of Brown et al (1990), which employs a targetlanguage n-gram model (see Section 8 for a comparison with this system).
In contrastto this view, previous approaches in machine translation typically resolve exampleslike (1) by stating various constraints in terms of the source language (Nirenburg 1987).As explained above, such constraints cannot be acquired automatically and thereforeare usually limited in their coverage.The experiments we conducted clearly show that statistics on lexical relations arevery useful for disambiguation.
Most notable is the result for the set of examplesof Hebrew to English translation, which was picked randomly from foreign newssections in the Israeli press.
For this set, the statistical model was applicable for 70%of the ambiguous words, and its selection was then correct for 91% of the cases.
Wecite also the results of a later experiment (Dagan, Marcus, and Markovitch 1993) thattested a weaker variant of our method on texts in the computer domain, achieving aprecision of 85%.
Both results significantly improve upon a naive method that usesonly a priori word probabilities.
These results are comparable to recent reports inthe literature (see Section 7).
It should be emphasized, though, that our results wereachieved for a realistic simulation of a broad coverage machine translation system, onrandomly selected examples.
We therefore believe that our figures reflect he expectedperformance of the algorithm in a practical implementation.
On the other hand, mostother results relate to a small number of words and senses that were determined bythe experimenters.Section 2 of the paper describes the linguistic model we use, employing a syntac-tic parser and a bilingual lexicon.
Section 3 presents the statistical model, assuminga multinomial model for a single lexical relation and then using a constraint propa-gation algorithm to account simultaneously for all relations in the sentence.
Section 4describes the experimental Setting.
Section 5 presents and analyzes the results of theexperiment and cites additional results (Dagan, Marcus, and Markovitch 1993).
InSection 6 we analyze the limitations of the algorithm in different cases and suggestenhancements to improve it.
We also discuss the possibility of adopting the algorithmfor monolingual applications.
Finally, in Section 7 we present a comparative analysisof statistical sense disambiguation methods and then conclude in Section 8.2 A similar observation underlies the use of parallel bilingual corpora for sense disambiguation (Brownet al 1991; Gale, Church, and Yarowsky 1992).
As we explain in Section 7, these corpora re a form of amanually tagged corpus and are more difficult o obtain than monolingual corpora.
Erroneously, thepreliminary publication of our method (Dagan, Itai, and Schwall 1991) was cited several times asrequiring aparallel bilingual corpus,565Computational Linguistics Volume 20, Number 42.
The Linguistic ModelOur approach is first to use a bilingual exicon to find all possible translations of eachlexically ambiguous word in the source sentence and then use statistical informationgathered from target language corpora to choose the most appropriate alternative.
Tocarry out this task we need the following linguistic tools, which are discussed in detailin the following sections:Section 2.1: Parsers for both the source language and the target language.These parsers hould be capable of locating relevant syntactic relations,such as subj-verb, verb-obj, etc.Section 2.2: A bilingual exicon that lists alternative translations for eachsource language word.
If a word belongs to several syntactic ategories,there should be a separate list for each one.Section 2.3: A procedure for mapping the source language syntacticrelations to those of the target language.Such tools have been implemented within the framework of many computationallinguistic theories.
We have used McCord's implementation f Slot Grammars (McCord1990, 1991).
However, our method could have proceeded just as well using otherlinguistic models.The linguistic model will be illustrated by the following Hebrew example, takenfrom the Ha-Aretz daily newspaper f om September, 1990 (transcripted toLatin letters):(3) Diplomatim svurim ki hitztarrfuto shell Hon Sun magdiladiplomats believe that the joining of Hon Sun increaseset ha-sikkuyim l-hassagat hitqaddmut ba-sihot.the-chances for-achieving progress in the-talksHere, the ambiguous words in translation to English are magdila, hitqaddmut, and sihot.To facilitate the reading, we give the translation of the sentence into English, andin each case of an ambiguous election, all the alternatives are listed within curlybrackets, the first alternative being the correct one.
(4) Diplomats believe that the joining of Hon Sun {increases I enlarges Imagnifies} the chances for achieving {progress I advance I advancement}in the {talks I conversations I calls}.The following subsections describe in detail the processing steps of the linguis-tic model.
These include locating the ambiguous words and the relevant syntacticrelations among them in the source language sentence, mapping these relations toalternative relations in the target language, and finally, counting occurrences of thesealternatives in a target language corpus.2.1 Locating the Ambiguous Words in the Source LanguageOur model defines the different "senses" of a source word to be all its possible trans-lations to the target language, as listed in a bilingual lexicon.
Some translations canbe eliminated by the syntactic environment of the word in the source language.
Forexample, in the following two sentences the word 'consider' should be translated566Ido Dagan and Alon Itai Word Sense Disambiguationdifferently into Hebrew, owing to the different subcategorization frame in each case:(5) I consider him smart.
(6) I consider going to Japan.In these examples, the different syntactic subcategorization frames determine two dif-ferent translations to Hebrew (mah.shiv ersus shoqel), thus eliminating some of theambiguity.
Such syntactic rules that allow us to resolve some of the ambiguities maybe encoded in the lexicon (e.g., Golan, Lappin, and Rimon 1988).
However, manyambiguities cannot be resolved on syntactic grounds.
The purpose of this work is toresolve the remaining ambiguities using lexical co-occurrence preferences, obtained bystatistical methods.2.2 Locating Syntactic Tuples in Source Language SentencesOur basic concept is the syntactic tuple, which denotes a syntactic relation betweentwo or more words.
It is denoted by the name of the syntactic relation followed bya sequence of words that satisfies the relation, appearing in their base form (with-out morphological inflections).
For example (subj-verb: man walk) is a syntactic tuple,which occurs in the sentence 'The man walked home.
'We assume that our parser (or an auxilliary program) can locate the syntacticrelation corresponding toa given syntactic tuple in a sentence.
The use of the base formof words is justified by the additional assumption that morphological inflections donot affect the probability of syntactic tuples.
This assumption is not entirely accurate,but it has proven practically useful and reduces the number of distinct tuples.In our experience, the following syntactic relations proved useful for resolvingambiguities:?
Relations between a verb and its subject, complements, and adjuncts,including direct and indirect objects, adverbs, and modifyingprepositional phrases.?
Relations between a noun and its complements and adjuncts, includingadjectives, modifying nouns in noun compounds, and modifyingprepositional phrases.?
Relations between adjectives or adverbs and their modifiers.4As mentioned earlier, the full list of syntactic relations depends on the syntactic the-ory of the parser.
Our model is general and does not depend on any particular list.However, we have found some desired properties in defining the relevant syntac-tic relations.
One such property is the use of deep, or canonical, relations, as wasalready identified by Grishman, Hirschman, and Nhan (1986).
This property was di-rectly available from the ESG parser (McCord 1990, 1991), which identifies the under-lying syntactic function in constructs uch as passives and relative clauses.
We havealso implemented an additional routine, which modified or filtered some of the rela-tions received from the parser.
This postprocessing routine dealt mainly with functionwords and prepositional phrases to get a set of more informative relations.
For exam-ple, it combined the subject and complement of the verb 'be' (as in 'the man is happy')into a single relation.
Likewise, a verb with its preposition and the head noun of amodifying prepositional phrase (as in sit on the chair) were also combined.
The routinewas designed to choose relations that impose considerable r strictions on the possible567Computational Linguistics Volume 20, Number 4(or probable) syntactic tuples.
On the other hand, these relations should not be toospecific, to allow statistically meaningful samples.The first step in resolving an ambiguity is to find all the syntactic tuples containingthe ambiguous words.
For (3) we get the following syntactic tuples:(7) .2.3.4.
(subj-verb: hitztarrfut higdil)(verb-obj: higdil sikkuy)(verb-obj: hissig hitqaddmut)(noun-pp: hitqaddmut b- sih.a)(these tuples translate as joining-increase, increase-chance, achieve-progress, and progress-in-talks).
In using these tuples, we expect o capture lexical constraints that are imposedby syntactic relations.2.3 Mapping Syntactic Tuples to the Target LanguageThe set of syntactic tuples in the source language sentence is reflected in its translationto the target language.
As a syntactic tuple is defined by both its syntactic relation andthe words that appear in it, we need to map both components to the target language.By definition, every ambiguous ource language word maps to several target lan-guage words.
We thus get several alternative target language tuples for each sourcelanguage tuple that involves an ambiguous word.
For example, for tuple 3 in (7)we obtain three alternatives, corresponding to the three different ranslations of theword hitqaddmut.
For tuple 4 we obtain nine alternative target uples, since each of thewords hitqaddmut and siha maps to three different English words.
The full mapping ofthe Hebrew tuples in (7) to English tuples appears in Table 1 (the rightmost columnshould be ignored for the moment).
Each of the tuple sets (a-d) in this table denotesthe alternatives for translating the corresponding Hebrew tuple.From a theoretical point of view, the mapping of syntactic relations is more prob-lematic.
There need not be a one-to-one mapping from source language relations totarget language ones.
In many cases the mapping depends on the words of the syn-tactic tuple, as seen in the following example of translating from German to English.
(8) Der Tisch gefaellt mir.--I like the table.In this example the source language subject (Tisch) becomes the direct object (table) inthe target, whereas the direct object (mir) in the source language becomes the subject(I) in the target.
Therefore, the German syntactic tuples(9) (subj-verb: Tisch gefaellt)(verb-obj: gefaellt mir)are mapped to the following English syntactic tuples(10) (verb-obj: like table)(subj-verb: I like)(The Hebrew equivalent is similar to the German structure).In practice this is less of a problem.
In most cases, the source language relationhas a direct equivalent in the target language.
In many other cases, transformationrules can be encoded, either in the lexicon (if they are word dependent) or as syntactictransformations.
These rules are usually available in machine translation systems that568Ido Dagan and Alon Itai Word Sense DisambiguationTable 1The alternative target syntactic tuples with their counts in the target language corpusSource Tuples Target Tuples Countsa.
(subj-verb: hitztarrfut higdil) (subj-verb: joining increase) 0(subj-verb: joining enlarge) 0(subj-verb: joining magnify) 0b.C.d.
(verb-obj: higdil sikkuy)(verb-obj: hissig hitqaddmut)(noun-pp: hitqaddmut b-sih.a)(verb-obj: increase chance) 20(verb-obj: enlarge chance) 0(verb-obj: magnify chance) 0(verb-obj: achieve progress) 29(verb-obj: achieve advance) 5(verb-obj: achieve advancement) 1(noun-pp: progress in talk) 7(noun-pp: progress in conversation) 0(noun-pp: progress in call) 0(noun-pp: advance in talk) 2(noun-pp: advance in conversation) 0(noun-pp: advance in call) 2(noun-pp: advancement i  talk) 0(noun-pp: advancement i  conversation) 0(noun-pp: advancement i  call) 0use the transfer method, as this knowledge is required to generate target languagestructures.To facilitate further the mapping of syntactic relations and to avoid errors due tofine distinctions between them, we grouped related syntactic relations into a single"general class" and mapped this class to the target language.
The important classesused were relations between a verb and its arguments and modifiers (counting as oneclass all objects, indirect objects, complements, and nouns in modifying prepositionalphrases) and between a noun and its arguments and modifiers (counting as one classall modifying nouns in compounds and nouns in modifying prepositional phrases).The classification enables us to get more statistical data for each class, as it reducesthe number of relations.
The success of using this general level of syntactic relationsindicates that even a rough mapping of source to target language relations is usefulfor the statistical model.2.4 Counting Syntactic Tuples in the Target Language CorpusWe now wish to determine the plausibility of each alternative target word being thetranslation of an ambiguous ource word.
In our model, the plausibility of selectinga target word is determined by the plausibility of the tuples that are obtained fromit.
The plausibility of alternative target uples is in turn determined by their relativefrequency in the corpus.Target syntactic tuples are identified in the corpus similarly to source languagetuples, i.e., by a target language parser and a companion routine as described in Section2.1.
The right column of Table 1 shows the counts obtained for the syntactic tuplesof our example in the corpora we used.
The table reveals that the tuples containingthe correct arget word ('talk,' 'progress,' and 'increase') are indeed more frequent.569Computational Linguistics Volume 20, Number 4However, we still need a decision algorithm to analyze the statistical significance ofthe data and choose the appropriate word accordingly.3.
The Statistical ModelAs seen in the previous ection, the linguistic model maps each source language syn-tactic tuple to several alternative target uples, in which each alternative correspondsto a different selection of target words.
We wish to select the most plausible targetlanguage word for each ambiguous source language word, basing our decision on thecounts obtained from the target corpus, as illustrated in Table 1.
To that end, we shoulddefine a selection algorithm whose outcome depends on all the syntactic tuples in thesentence.
If the data obtained from the corpus do not substantially support any oneof the alternatives, the algorithm should notify the translation system that it cannotreach a statistically meaningful decision.Our algorithm is based on a statistical model.
However, we wish to point outthat we do not see the statistical considerations, as expressed in the model, as fullyreflecting the linguistic considerations ( yntactic, semantic, or pragmatic) that deter-mine the correct ranslation.
The model reflects only part of the relevant data andin addition makes statistical assumptions that are only partially satisfied.
Therefore,a statistically based model need not make the correct linguistic choices.
The perfor-mance of the model can only be empirically evaluated, the statistical considerationsserve only as heuristics.
The role of the statistical considerations is therefore to guideus in constructing heuristics that make use of the linguistic data of the sample (thecorpus).
Our experience shows that the statistical methods are indeed very helpfulin establishing and comparing useful decision criteria that reflect various linguisticconsiderations.3.1 The Probabilistic ModelFirst we discuss decisions based on a single syntactic tuple (as when only one syntactictuple in the sentence contains an ambiguous word).
Denote the source language syn-tactic tuple T and let there be k alternative target uples for T, denoted by T1,..
?, Tk.Let the counts obtained for the target uples be nl,.
?., nk.
For notational convenience,we number the tuples by decreasing frequency, i.e., nl ~ y/2 ~ "'"  ~ nk-Since our goal is to choose for T one of the target uples Ti, we can consider Ta discrete random variable with multinomial distribution, 3 whose possible values areT1, .
.
.
,  Tk.
Let Pi be the probability of obtaining Ti, i.e., the probability that Ti is thecorrect ranslation for T. We estimate the probabilities Pi by the counts ni in the obviousway, using the maximum likelihood estimator (Agresti 1990, pp.
40-41).
The estimator \]9ifo r  Pi isHi/~i -- k " (1)Y~q=l njThe precision of the estimator depends, of course, on the size of the counts in thecomputation.
We will incorporate this consideration i to the decision algorithm byusing confidence intervals.
43 A variable that can have one of a finite set of values, each of them having a fixed probability.4 The max imum likelihood estimator is known to give poor estimates when small counts are involved,and there are several methods to improve it (see Church and Gale 1991, for a presentation anddiscussion of several methods).
For our needs this is not necessary in most cases, since we are notgoing to use the estimate itself, but rather a confidence interval for the ratio between two estimations(see below).570Ido Dagan and Alon Itai Word Sense DisambiguationWe now have to establish the criterion for choosing the preferred target languagesyntactic tuple.
The most reasonable assumption is to choose the tuple with the high-est estimated probability, that is Tl--the tuple with the largest observed frequency.According to the model, the probability that T1 is the right choice is estimated as Pl.This criterion should be subject o the condition that the difference between the alter-native probabilities i significant.
For example, if/Yl = 0.51 and/52 = 0.49, the expectedsuccess rate in choosing T1 is approximately 0.5.
To prevent he system from makinga decision in such cases, we need to impose some conditions on the probabilities Pi.One possible such condition is that \]Jl exceeds a prespecified threshold (or, as weshall describe below, that the threshold requirement be applied to a confidence inter-val).
According to the model, this requirement ensures that the success probability ofevery decision exceeds the threshold.
Even though this method satisfies the proba-bilistic model, it is vulnerable to noise in the data, which often causes ome relativelysmall counts to be larger than their true value in the sample.
The noise is introducedin part by inaccuracies in the model and in part because of errors during the auto-matic collection of the statistical data.
Consequently, the estimated value of Pl maybe smaller than its true value, because other counts in Equation 1 are too large, thus,preventing Pl from passing the threshold.To deal with this problem, we have chosen another criterion for significance--theodds ratio.
We choose the alternative T1 only if all the ratiosr;2'exceed a prespecified threshold.
Note that 15i/lfij -- ni/nj, and since nl _~ n2 _) ... ~_ nk,the ratio tYl/lY2 is less than or equal to all the other ratios.
Therefore, it suffices tocheck the odds ratio only for ill/P2.
This criterion is less sensitive to noise of theabove-mentioned type than/)1, since it depends only on the two largest counts.3.1.1 Underlying Assumptions.
The use of a probabilistic model necessarily intro-duces several assumptions on the structure of the corresponding linguistic data.
It isimportant to point out these assumptions, in order to be aware of possible inconsis-tencies between the model and the linguistic phenomena for which it is used.The first assumption is introduced by the use of a multinomial model, whichpresupposes the following:Assumption 1The events Ti are mutually disjoint.This assumption is not entirely valid, since sometimes it is possible to translate a sourcelanguage word to several target language words, such that all the translations arevalid.
For example, consider the Hebrew sentence (from the Ha-Aretz daily newspaper,November 27, 1990) whose English translation is(11) The resignation of Thatcher is not {related I connected} to the negotia-tions with Damascus.In this sentence (but not in others), the ambiguous word qshura can equally well betranslated to either 'related' or 'connected.'
In terms of the probabilistic model, the twocorresponding events, i.e., the two alternative English tuples that contain these words,T1 -- (verb-comp: relate to negotiation) and T2 = (verb-comp: connect o negotiation) are571Computational Linguistics Volume 20, Number 4both correct, thus the events T1 and T2 both occur (they are not disjoint).
However, wehave to make this assumption, since the counts we have, ni, from which we estimatethe probabilities of the Ti values, count actual occurrences of single syntactic tuples.In other words, we count the number of times that each of Zl and T2 actually occur,not the number of times in which each of them could occur.Two additional assumptions are introduced by using counts of the occurrences ofsyntactic tuples of the target language in order to estimate the translation probabilitiesof source language tuples:Assumption 2An occurrence of the source language syntactic tuple T can indeed be translated toone of Zl~...~ Tk.Assumption 3Every occurrence of the target uple Ti can be the translation of only the source tuple T.Assumption 2 is an assumption on the completeness of the linguistic model.
It is ratherreasonable and depends on the completeness of our bilingual exicon: if the lexicongives all possible translations ofeach ambiguous word, then this assumption will hold,since for each syntactic tuple T we will produce all possible translations3Assumption 3, which may be viewed as a soundness assumption, does not alwayshold, since a target language word may be the translation of several source languagewords.
Consider, for example, the Hebrew tuple T = (verb-obj: heh.ziq lul).
Lul is am-biguous, meaning either a playpen or a chicken pen.
Accordingly, T can be translatedto either T1 = (verb-obj: hold playpen) or T2 = (verb-obj: hold pen).
In the context of'hold' the first translation is more likely, and we can therefore xpect our model toprefer T1.
However, this might not be the case because Assumption 3 is contradicted.
'Pen' can also be the translation of the Hebrew word "et (the writing instrument), andthus T2 can be the translation of another Hebrew tuple, T' = (verb~bj: heh.ziq 'et).
Thismeans that when translating T we are counting occurrences of T2 that correspondto both T and T', "misleading" the selection criterion.
Section 6.3 illustrates anotherexample in which the assumption is not valid, causing the algorithm to fail to selectthe correct ranslation.We must make this assumption since we use only a target language corpus, whichis not related to any source language information.
6 Therefore, when seeing an occur-rence of the target language word w, we do not know which source language word isappropriate in the current context.
Consequently, we count its occurrence as a transla-tion of all the source language words for which w is a possible translation.
This impliesthat sometimes we use inaccurate data, which introduce noise into the statistical model(see Section 6.3 for a discussion of an alternative, but expensive, solution, using a bilin-gual corpus).
As we shall see, even though the assumption does not always hold, inmost cases this noise does not interfere with the decision algorithm.5 The problem of constructing a bilingual exicon that is as complete as possible is beyond the scope ofthis paper.
A promising approach may be to use aligned bilingual corpora, especially for augmentingexisting lexicons with domain-specific terminology (Brown et al 1993; Dagan, Church, and Gale 1993).In any case, it seems that any translation system is limited by the completeness of its bilingual exicon,which makes our assumption a reasonable one.6 As explained in the introduction, this is a very important advantage of our method over other methodsthat use bilingual corpora.572Ido Dagan and Alon Itai Word Sense Disambiguation3.2 Statistical Significance of the DecisionAnother problem we should address is the statistical significance of the data--whatconfidence do we have that the data indeed reflect he phenomenon.
If the decision isbased on small counts, then the difference in the counts might be due to chance.
Forexample, we should have more confidence in the odds ratio 151/152 = 3 when nl = 30and //2 = 10 than when nl = 3 and n2 = 1.
Consequently, we shall use a dynamicthreshold for 151/152, which is large when the counts are small and decreases as thecounts increase.A common method for determining the statistical significance of estimates i theuse of confidence intervals.
Rather than finding a confidence interval for 151/152, wewill bound the log odds ratio, ln(151/152).
Since the variance Of the log odds ratio isindependent of the mean, it converges to the normal distribution faster than the oddsratio itself (Agresti 1990).
We use a one-tailed interval, as we want only to decidewhether ln(151/152) is greater than a specific threshold (i.e., we need only a lower boundfor ln(151/152)).
Using this method, for each desired error probability 0 < ~ < 1, we maydetermine a value B~ and state that with a probability of at least 1 - c~ the true value,ln(pl/p2), is greater than B~.The confidence interval of a random variable X with normal distribution isZ I -~ ,  where ZI-~ is the confidence coefficient, which may be found in sta-tistical tables, and var is the variance.
In our case, the size of the confidence intervalisZ1-~/var\[ln~221"In the appendix we approximate the variance by the following\[ ~22\] 1 1 var  in 151 ~ __  _}_ - - .//1 //2The bound we get is thus151 //1 Since ~ - //2 we getln(P~2 ) >ln(pP-~)-Z l -~V~n~ + 1//2l n /P~)  ~>ln/n,~-~)-Zl-c,V/n~+ 1//2;o(2)B~(nl,n2) (or B~ when nl and n2 are understood from the context) is defined tobe the right-hand side of Equation 2.
The meaning of the inequality is that for everygiven pair nl~ n2 we know with confidence 1 - c~ thatIn pl ~ B~ (3)P2or in other words, B,~ is a lower bound for ln(pl/P2) with this confidence level.To obtain a decision criterion, we choose a threshold 0, for B~, and decide tochoose T1 only ifB~ > 0.
(4)573Computational Linguistics Volume 20, Number 4If Equation 4 does not hold, the algorithm makes no decision.
The meaning of thiscriterion is that only if we know with confidence of at least 1 - ~ that ln(pl/p2) > O,will we select he most frequent uple T1 as the appropriate one.
In terms of statisticaldecision theory, we say that our null hypothesis is that ln(pl/P2) < 0, and we willmake a decision only if we can reject this hypothesis with confidence at least 1 - ~.Note that we cannot compute B~ when one of the counts is zero.
In this case we haveused the common correction method of adding 0.5 to each of the counts (Agresti 1990,p.
249).
7We shall now demonstrate the use of the decision criterion.
In the experimentwe conducted we chose the parameters ~ = 0.1, for which Z~ = 1.282, and 0 = 0.2.Thus, to choose T1 we require that with confidence level of at least 90% the hypothesisshould satisfy ln(pl/P2) > 0.2 (i.e., Pl/P2 >_ e 02 = 1.22).
For the alternative translationsof tuple c in Table 1 we got nl = 29 and n2 = 5.
For these values Be = 1.137.
In thiscase Equation 4 is satisfied for 0 = 0.2, and the algorithm selects the word 'progress'as the translation of the Hebrew word hitqaddmut.In another case we had to translate the Hebrew word ro'sh, which can be translatedto either 'top' or 'head,' in the sentence whose translation is(12) Sihanuk stood at the {top \] head} of a coalition of underground groups.The two alternative syntactic tuples were(a) (verb-pp: standat head) 10(b) (verb-pp: stand at top) 5For nl = 10 and n2 = 5, we get Be = -0.009 (a negative value means that it isimpossible to ensure with a 90% confidence level that Pl > P2).
Since Be G 0.2, thealgorithm will refrain from making a decision in this case.
This abstention reflects thefact that the difference between the counts is not statistically significant, and choosingthe first alternative can be wrong in many of the cases (as seen in the five cases thatwere observed in the corpus).As mentioned above, our motivation was to find a criterion that depends on adynamic threshold for ~1/\]Y2 (or alternatively n l /n2)  , so  that the threshold will behigher when nl and n2 are smaller.
Our criterion indeed satisfies this requirement.
Ifwe substitute B~ in Equation 4, we get the following equivalent criterion:In nl > 0 + Zl_c~/n~ q- 1//2 //2The above inequality clarifies the roles of the two parameters, ~ and 0 :0  specifiesa lower bound on In(nl/n2), which is independent of the sample size; c~ reflects thestatistical significance.
If c~ is decreased (i.e., we require more confidence), ZI_~ willincrease, and therefore, the component dependent on the sample size will increase.Since this component is in inverse relation to nl and n2, the penalty for decreasingc~ increases when the sample size decreases.
From this analysis we can derive thecriterion for choosing the parameters: if we wish to use small counts, then c~ shouldbe small, and 0 depends on the required ratio between l and n2.
The optimal valuesof the parameters should be determined empirically and might depend on the corporaand parsers we use.7 In this case, smoothing methods (Church and Gale 1991) may improve the correction method.574Ido Dagan and Alon Itai Word Sense Disambiguation3.3 Sentences with Several Syntactic RelationsIn the previous section, we assumed that the source sentence contains only one am-biguous syntactic tuple.
In general there may be several ambiguous words that appearin several tuples.
We should take advantage of the occurrence patterns of all of thetuples to reach a decision.
Since different relations may favor different ranslations foran ambiguous word, we should devise a strategy for selecting a consistent translationfor all words in the sentence.
We have used the following constraint propagation algo-rithm, which receives as input the list of all source tuples along with their alternativetranslations to target uples:....Compute B~ of each source tuple.
If the largest B~ is less than thethreshold, 8, then stop.Let T be the source tuple for which B~ is maximal.
Select the translationfor the ambiguous words (or word) in T according to T1 (the mostfrequent arget alernative for T).
Remove T from the list of source tuples.Propagate the constraint: eliminate target uples that are inconsistentwith this decision.
If now some source tuples become unambiguous,remove them from the list of source tuples.Repeat his procedure for the remaining list of source tuples, until allambiguities have been resolved, or the maximal B~ is less than 8.To illustrate the algorithm, we consider Table 1 using the parameters c~ = 0.1and 0 = 0.2.
The largest value of B~ occurs for the tuple (verb-obj: higdil sikkuy), forwhich higdil can be translated to ;increase,' 'magnify,' or 'enlarge.'
The first alternativeappeared nl = 20 times, and the other alternatives did not appear at all, (n2 = n3 =0).
Adding the correction factor and computing B~ yields B~(nl + 0.5~n2 q-0.5) =B,~(20.5, 0.5) = 1.879 > 0.2 = 8.
Therefore, the word 'increase' was chosen as thetranslation of higdil.
Since this word appears also in the tuple (subj-verb: hitztarrfuthigdil), the' target tuples that include alternative translations of higdil were deleted.Thus(13) (subj-verb: joining enlarge)(subj-verb: joining magnify)were deleted.
This leaves us with only one alternative (subj-verb: joining increase) as apossible translation of this Hebrew tuple, which is therefore removed from the inputlist.We now recompute the values of B~ for the remaining tuples.
The maximal valueis obtained for the tuple(14) (verb-obj: hissig hitqaddmut)where B~ (29, 5) = 1.137 > 8.
We, therefore, choose the word 'progress' as a translationfor hitqaddmut.
Since this word, hitqaddmut, also appears in the tuple (noun-pp: hitqad-dmut b- sih.a), we delete the Six target tuples that are inconsistent with the selectionof 'progress' (those containing the words 'advance' and 'advancement').
There nowremain only three alternative target uples for hitqaddmut b- sih.a.We now recompute the values of B~.
The maximum value is B~ (7.5~ 0.5) = 0.836 >0 (note that because tuples inconsistent with the previous decisions were eliminated,575Computational Linguistics Volume 20, Number 4n2 dropped from 2 to 0, thus increasing B~).
Thus, 'talk' is selected as the translationof siha.
Now all the ambiguities have been resolved and the procedure stops.In the above example all the ambiguities were resolved since in each stage thevalue of B~ exceeded the threshold 0 = 0.2.
In some cases not all ambiguities areresolved, though the number of ambiguities may decrease.It should be noted that other methods may be proposed for combining the statis-tics of several syntactic relations.
For example, it may make sense to multiply estimatesof conditional probabilities of tuples in different relations, in a way that is analogousto n-gram language modeling (Jelinek, Mercer, and Roukos 1992).
However, such anapproach will make it harder to take into account he statistical significance of theestimate (a criterion that is missing in standard n-gram models).
In our set of exam-ples, the constraint propagation method proved to be successful and did not seem tointroduce any errors.
Further experimentation,  much larger data sets, is needed todetermine which of the two methods (if any) is substantially superior to the other.4.
The ExperimentTo evaluate the proposed isambiguation method, we implemented and tested themethod on a random set of examples.
The examples consisted of a set of Hebrewparagraphs and a set of German paragraphs.
In both cases the target language wasEnglish.
The Hebrew examples consisted of ten paragraphs picked at random fromforeign news sections of the Israeli press.
The paragraphs were selected from severalnews items and articles that appeared in several daily newspapers.
The target lan-guage corpus consisted of American newspaper articles, and the Hansard corpus ofthe proceedings of the Canadian Parliament.
The domain of foreign news articles waschosen to correspond to some of the topics that appear in the English corpus, s TheGerman examples were chosen at random from the German press, without restrictingthe topic.
9Since we did not have a translation system from Hebrew or German to English,we simulated the steps such a system would perform.
Hence, the results we reportmeasure the performance of just the target word selection module and not the perfor-mance of a complete translation system.
The latter can be expected to be somewhatlower for a real system, depending on the performance of its other components.
Note,however, that since the disambiguation module is highly immune to noise, it mightbe more useful in a real system: in such a system some of the alternatives wouldbe totally erroneous.
Since the corresponding syntactic tuples would typically not befound in the corpora, they would be eliminated by our module.The experiment is described in detail in the following subsections.
It providesan example for a thorough evaluation that is carried out without having a completesystem available.
We specifically describe the processing of the Hebrew data, whichwas performed by a professional translator, supervised by the authors.
The Germanexamples were processed very similarly.4.1 Locating Ambiguous WordsTo locate ambiguous words, we simulated a bilingual exicon and syntactic filters of atranslation system.
For every source language word, the translator searched all possible8 The corpus includes many irrelevant topics as well, which introduce noisy data with respect o thegiven domain.9 The German examples were prepared by Ulrike Schwall from the IBM Scientific Center, Heidelberg,Germany.576Ido Dagan and Alon Itai Word Sense Disambiguationtranslations using a Hebrew-English dictionary (Alcalay 1990).
The list of translationsproposed by the dictionary was modified according to the following guidelines, toreflect better the lexicon of a practical translation system:..3...Eliminate translations that would be ruled out for syntactic reasons, asexplained in Section 2.1.Consider only content words, ignoring function words and proper nouns.Assume that multi-word terms, such as 'prime minister,' appear in thelexicon as complete terms.
Thus we did not consider each of theirconstituents separately.
Also, we did not consider source language wordsthat should be translated to a multi-word target phrase.Eliminate rare and archaic translations that are not expected in thecontext of foreign affairs in the current press.The professional translator added translations that were missing in thedictionary.In addition, each of the remaining target alernatives for each source word was eval-uated as to whether it is a suitable translation in the current context.
This evaluationwas later used to judge the selections of the algorithm.
If all the alternatives wereconsidered suitable, then the source word was eliminated from the test set, since anydecision for it would have been considered successful.We ended up with 103 Hebrew and 54 German ambiguous words.
For each He-brew word we had an average of 3.27 alternative translations and an average of 1.44correct ranslations.
The average number of translations of a German word was 3.26,and there were 1.33 correct ranslations.4.2 Determining the Syntactic Tuples and Mapping Them to EnglishSince we did not have a Hebrew parser, we have simulated the two steps of deter-mining the source syntactic tuples and mapping them to English by reversing theorder of these steps, in the following way: First, the sample sentences were translatedmanually, as literally as possible, into English.
Then, the resulting English sentenceswere analyzed, using the ESG parser and the postprocessing routine (see Section 2.2),to identify the relevant syntactic tuples.
The tuples were further classified into "gen-eral classes," as described in Section 2.3.
The use of these general classes, which wasintended to facilitate the mapping of syntactic relations from one language to another,also facilitated our simulation method and caused it to produce realistic output.At the end of the procedure, we had, for each sample sentence, a data structuresimilar to Table 1 (without the counts).4.3 Acquiring the Statistical DataThe statistical data were acquired from the following corpora:?
Texts from The Washington Post ~0 million words.?
The Hansard corpus of protocols of the Canadian Parl iament--85 millionwords.?
Associated Press news items--24 million words.577Computational Linguistics Volume 20, Number 4However, the effective size of the corpora was only about 25 million words, owing totwo filtering criteria.
First, we considered only sentences whose length did not exceed25 words, since longer sentences required excessive parse time and contained manyparsing errors.
Second, even 35% of the shorter sentences failed to parse and had to beeliminated.
The syntactic tuples were located by the ESG parser and the postprocessingroutine mentioned earlier.For the purpose of evaluation, we gathered only the data required for the giventest examples.
Within a practical machine translation system, the disambiguation mod-ule would require a database containing all the syntactic tuples of the corpus withtheir frequency counts.
In the current research project we did not have the computingresources necessary for constructing the complete database (the major cost being pars-ing time).
However, such resources are not needed in order to evaluate the proposedmethod.
Since we evaluated the method only on a relatively small number of randomsentences, we first constructed the set of all "relevant" target uples, i.e., tuples thatshould be considered for the test sentences.
Then we scanned the entire corpus andextracted only sentences that contain both words from at least one of the relevanttuples.
Only the extracted sentences were parsed, and their counts were recorded inour database.
Even though this database is much smaller than the full database, forthe ambiguous words of the test sentences, both databases provide the same informa-tion.
Thus, the success rate for the test sentences i  the same for both methods, whilerequiring a considerably smaller amount of resources at the research phase.The problem with this method is that for every set of sample sentences the entirecorpus has to be scanned.
Thus, a practical system would have to preprocess thecorpus to construct a database of the entire corpus.
Then, to resolve ambiguities, onlythis database need be consulted.After acquiring all the relevant data, the algorithm of Section 3.3 was executed foreach of the test sentences.5.
EvaluationTwo measurements, applicability and precision, are used to evaluate the performance ofthe algorithm.
The applicability (coverage) denotes the proportion of cases for whichthe model performed a selection, i.e., those cases for which the bound B~ passedthe threshold.
The precision denotes the proportion of cases for which the modelperformed a correct selection out of all the applicable cases.We compare the precision of our method, which we term TWS (for Target WordSelection), with that of the Word Frequencies procedure, which always selects themost frequent arget word.
In  other words, the Word Frequencies method prefersthe alternative that has the highest a priori probability of appearing in the targetlanguage corpus.
This naive "straw-man" is less sophisticated than other methodssuggested in the literature, but it is useful as a common benchmark since it can beeasily implemented.
The success rate of the Word Frequencies procedure can serve asa measure for the degree of lexical ambiguity in a given set of examples, and thusdifferent methods can be partly compared by their degree of success relative to thisprocedure.Out of the 103 ambiguous Hebrew words, for 33 the bound B~ did not passthe threshold, achieving an applicability of 68%.
The remaining 70 examples weredistributed according to Table 2.
Thus the precision of the statistical model was 91%578Ido Dagan and Alon Itai Word Sense DisambiguationTable 2Hebrew-English translation: Comparison of TWS andWord Frequencies methods for the 70 applicable xamplesWord FrequenciesCorrect Incorrect TotalCorrect 42 22 64TWS Incorrect 2 4 6Total 44 26 70(64/70), 1?
whereas relying just on Word Frequencies yields 63% (44/70), providing animprovement of28%.
The table demonstrates that our algorithm corrects 22 erroneousdecisions of the Word Frequencies method, but makes only 2 errors that the WordFrequencies method translates correctly.
This implies that with high confidence ourmethod greatly improves the Word Frequencies method.The number of Hebrew examples i large enough to permit a meaningful analysisof the statistical significance of the results.
By computing confidence intervals for thedistribution of proportions, we claim that with 95% confidence our method succeedsin at least 86% of the applicable xamples.
This means that though the figure of 91%might be due to a lucky selection of the random examples, there is only a 5% chancethat the real figure is less than 86% (for the given domain and corpus).
The confidenceinterval was computed as follows:p~f~_Z l_c~f~)  64 f-~4 .
6-70  1"65V 7?-7-07?
- 0"86'where a = 0.05 and the variance is estimated by \]~(1 - f))/n.With the same confidence, our method improves the Word Frequencies methodby at least 18% (relative to the actual improvement of28% in the given test set).
Let Plbe the proportion of cases for which our method succeeds and the Word Frequenciesmethod fails (Pl = 22/70) and P2 be the proportion of cases for which the WordFrequencies method succeeds and ours fails (P2 = 2/70).
The confidence interval is forthe difference of proportions in multinomial distribution and is computed as follows:Pl  - -  P2 (-- lYl - -  P2 -- Z l -o~ v/var(151 - 152)= ~1 -/~2 - Zl_c~ --~ V/~t (1 - ~t) + ~2(1 - ~2) + 2~1~222 2 65 1 4/22.
(70 -22)+2.
(70-2)+2.22 .2  =0.18.- 70 70 1.
~V 702Out of the 54 ambiguous German words, for 27 the bound B~ did not pass thethreshold (applicability of 50%).
The remaining 27 examples were distributed accord-ing to Table 3.
Thus, the precision of the statistical model was 78% (21/27), whereas10 An a posteriori observation showed that in three of the six errors the selection of the model wasactually acceptable, and the a priori judgment of the human translator was too restrictive.
For example,in one of these cases the statistics elected the expression 'to begin the talks,' whereas the humantranslator regarded this expression as incorrect and selected 'to start the talks.'
If we consider thesecases as correct, then there are only three selection errors, getting 96% precision.579Computational Linguistics Volume 20, Number 4Table 3German-English translation: Comparison of TWS andWord Frequencies methods for the 27 applicable xamplesWord FrequenciesCorrect Incorrect TotalCorrect 15 6 21TWS Incorrect 0 6 6Total 15 12 27relying just on Word Frequencies yields 56% (15/27).
Here our method corrected 6errors of the Word Frequencies method, without causing any new errors.
We attributethe lower success rate for the German examples to the fact that they were not re-stricted to topics that are well represented in the corpus.
This poor correspondencebetween the training and testing texts is reflected also by the low precision of the WordFrequencies method.
This means that the a priori probability of the target words, asestimated from the training corpora, provides a very poor prediction of the correctselection in the test examples.
Relative to the a priori probability, the precision of ourmethod is still 22% higher.5.1 Addit ional  ResultsRecently, Dagan, Marcus, and Markovitch ave implemented a variant of the disam-biguation method of the current paper.
This variant was developed for evaluating amethod that estimates the probability of word combinations which do not occur inthe training corpus (Dagan, Marcus, and Markovitch 1993).
In this section we quotetheir results, providing additional evidence for the effectiveness of the TWS method.The major difference between the TWS method, as presented in this paper, andthe variant described by Dagan, Marcus, and Markovitch (1993), which we term TWS ~,is that the latter does not use any parsing for collecting the statistics from the corpus.Instead, the counts of syntactic tuples are approximated by counting co-occurrences ofthe given words of the tuple within a short distance in a sentence.
The approximationtakes into account he relative order between the words of the tuple, such that occur-rences of a certain syntactic relation are approximated only by word co-occurrencesthat preserve the most frequent word order for that relation (e.g., an adjective precedesthe noun it modifies).The TWS ~ method still assumes that the source sentence to be translated is beingparsed, in order to identify the words that are syntactically related to an ambiguousword.
This model is therefore relevant for translation systems that use a parser for thesource language, but may not have available a robust arget language parser.The corpus used for evaluating the TWS' method consists of articles posted tothe USENET news system.
The articles were collected from news groups that discusscomputer-related topics.
The length of the corpus is 8,871,125 words (tokens), and thelexicon size (distinct ypes, at the string level) is 95,559.
The type of text in this corpusis quite noisy, including short and incomplete sentences as well as much irrelevantinformation, such as person and device names.
The test set used for the experimentconsists of 78 Hebrew sentences that were taken out of a book about computers.
Thesesentences were processed as described in Section 4, obtaining a set of 269 ambiguousHebrew words.
The average number of alternative translations per ambiguous wordin this set is 5.8, and there are 1.35 correct ranslations.580Ido Dagan and Alon Itai Word Sense DisambiguationTable 4Comparison of TWS' and Word Frequencies methods forthe 173 applicable xamplesWord Frequenciescorrect incorrect Totalcorrect 120 28 148TWS' incorrect 3 22 25Total 123 50 173Out of the 269 ambiguous Hebrew words, for 96 the bound B~ did not passthe threshold, achieving an applicability of 64.3%.
The remaining 173 examples weredistributed according to Table 4.
For the words that are covered by the TWS' method,the Word Frequencies method has a precision of 71.1% (123/173), whereas the TWS'method has a precision of 85.5%(148/173).
As can be seen in the table, the TWS' methodis correct in almost all the cases it disagrees with the Word Frequencies method (28 outof 31).
The applicability and precision figures in this experiment are somewhat lowerthan those achieved for the Hebrew set in our original evaluation of the TWS method(Table 2).
We attribute this to the fact that the original results were achieved usinga parsed corpus, which was about 2.5 times larger and of much higher quality thanthe one used in the second experiment.
Yet, the new results give additional supportfor the usefulness of the TWS method, even for noisy data provided by a low qualitycorpus, without any parsing or tagging, u6.
Analysis and Possible EnhancementsIn this section we give a detailed analysis of the selections performed by the algorithmand, in particular, analyze the cases when it failed.
The analysis of these modes sug-gests possible improvements of the model and indicates its limitations.
As describedearlier, the algorithm's failure includes either the cases for which the method was notapplicable (no selection), or the cases for which it made an incorrect selection.
Thefollowing paragraphs list various reasons for both types.
At the end of the section, wediscuss the possibility of adapting our approach to monolingual pplications.6.1 Correct SelectionIn the cases that were treated correctly by our method, such as the examples given inthe previous ections, the statistics ucceeded in capturing two major types of disam-biguating data.
In preferring 'sign-treaty' upon 'seal-treaty' (in Example 1), the statis-tics reflect he relevant semantic onstraint.
In preferring 'peace-treaty' upon 'peace-contract,' the statistics reflect he lexical usage of 'treaty' in English which differs fromthe usage of 'contract.
'6.2 Inapplicability6.2.1 Insufficient Data.
This was the reason for nearly all the cases of inapplicability.In one of our examples, for instance, none of the alternative relations, 'an investiga-tor of corruption' (the correct one) or 'researcher of corruption' (the incorrect one),11 It should be mentioned that the work of Dagan, Marcus, and Markovitch (1993) includes furtherresults, evaluating an enhancement of the TWS method using their similarity-based stimation method.This enhancement is beyond the scope of the current paper and is referred to in the next section.581Computational Linguistics Volume 20, Number 4was observed in the parsed corpus.
In this case it is possible to perform the correctselection if we used only statistics about the co-occurrence of 'corruption' with either'investigator' or 'researcher' in the same local context, without requiring any syntacticrelation.
Statistics on co-occurrence of words in a local context were used recently formonolingual word sense disambiguation (Gale, Church, and Yarowsky 1992b, 1993;Sch6tze 1992, 1993) (see Section 7 for more details and Church and Hanks 1990; Smadja1993, for other applications of these statistics).
It is possible to apply these methodsusing statistics of the target language and thus incorporate them within the frame-work proposed here for target word selection.
Finding an optimal way of combiningthe different methods is a subject for further esearch.
Our intuition, though, as wellas some of our initial data, suggests that statistics on word co-occurrence in the localcontext can substantially increase the applicability of the selection method.Another way to deal with the lack of statistical data for the specific words inquestion is to use statistics about similar words.
This is the basis for Sadler's Ana-logical Semantics (Sadler 1989), which according to his report has not proved effective.His results may be improved if more sophisticated methods and larger corpora areused to establish similarity between words (such as in Hindle 1990).
In particular, anenhancement of our disambiguation method, using similarity-based stimation (Da-gan, Marcus, and Markovitch 1993), was evaluated recently.
In this evaluation theapplicability of the disambiguation method was increased by 15%, with only a slightdecrease in the precision.
The increased applicability was achieved by disambiguatingadditional cases in which statistical data were not available for any of the alternativetuples, whereas data were available for other tuples containing similar words.6.2.2 Conflicting Data.
In very few cases two alternatives were supported equallyby the statistical data, thus preventing a selection.
In such cases, both alternativesare valid at the independent level of the syntactic relation, but may be inappropriatefor the specific context.
For instance, the two alternatives of 'to take a job' or 'totake a position' appeared in one of the examples, but since the general context wasabout the position of a prime minister, only the latter was appropriate.
To resolvesuch ambiguities, it may be useful to consider also co-occurrences of the ambiguousword with other words in the broader context (e.g., Gale, Church, and Yarowsky 1993;Yarkowsky 1992).
For instance, the word 'minister' seems to co-occur in the samecontext more frequently with 'position' than with 'job.
'In another example both alternatives were appropriate also for the specific ontext.This happened with the German verb werfen, which may be translated (among otheroptions) as 'throw,' cast,' or 'score.'
In our example, werfen, appeared in the contextof 'to throw/cast light,' and these two correct alternatives had equal frequencies inthe corpus ('score' was successfully eliminated): In such situations any selection be-tween the alternatives will be appropriate, and therefore, any algorithm that handlesconflicting data would work properly.
However, it is difficult to decide automaticallywhen both alternatives are acceptable and when only one of them is.6.3 Incorrect Selection6.3.1 Using an Inappropriate Relation.
One of the examples contained the Hebrewword matzav.
This word has several translations, two of which are 'state' and 'position.
'The phrase that contained this word was 'to put an end to the {statelposition } of war'.The ambiguous word is involved in two syntactic relations, being a complement of'put' and also modified by 'war'.
The corresponding frequencies were582Ido Dagan and Alon Itai Word Sense Disambiguation(15) (verb-comp: put-position) 320(verb-comp: put-state) 18(noun-nobj: state-war) 13(noun-nobj: position-war) 2The bound of the odds ratio (B~) for the first relation was higher than for the sec-ond, and therefore, this relation determined the translation as 'position'.
However, thecorrect ranslation should be 'state', as determined by the second relation.These data suggest that while ordering the relations (or using any other Weightingmechanism) it may be necessary to give different weights to the different ypes ofsyntactic relations.
For instance, it seems reasonable that the object of a noun shouldreceive greater weight in selecting the noun's sense than the verb for which this nounserves as a complement.Further examination of the example suggests another efinement of our method:it turns out that most of the 320 instances of the tuple (verb-comp: put position) in-clude the preposition 'in,' as part of the common phrase 'put in a position.'
Therefore,these instances should not be considered for the current example, which includes thepreposition 'to.'
However, the distinction between different prepositions was lost byour program, as a result of using equivalence classes of syntactic tuples (see Sec-tion 2.3).
This suggests that we should not use an equivalence class when there isenough statistical data for specific tuples.
126.3.2 Confusing Senses.
In another example, the Hebrew adjective qatann modifiedthe noun sikkuy, which means 'prospect' or 'chance.'
The word qatann has severaltranslations, two of which are 'small' and 'young.'
In this Hebrew word combination,the correct sense of qatann is necessarily 'small.'
However, the relation that was ob-served in the corpus was 'young prospect,' relating to the human sense of 'prospect'that appeared in sports articles (a promising young person).
This borrowed sense of'prospect' is necessarily inappropriate, since in Hebrew it is represented by the equiv-alent of 'hope' (tiqwa) and not by sikkuy.The source of this problem is Assumption 3: a target uple T might be a translationof several source tuples, and while gathering statistics for T, we cannot distinguishbetween the different sources, since we use only a target language corpus.A possible solution is to use an aligned bilingual corpus, as suggested by Sadler(1989), Brown et al (1991), and Gale et al (1992a).
In such a corpus the occurrences ofthe relation 'young prospect' will be aligned to the corresponding occurrences of theHebrew word tiqwa and will not be used when the Hebrew word sikkuy is involved.Yet, it should be brought o mind that an aligned corpus is the result of manual transla-tion, which can be viewed as including amanual tagging of the ambiguous words withtheir equivalent senses in the target language.
This resource is much more expensiveand less available than an untagged monolingual corpus, and it seems to be neces-sary only for relatively rare situations.
Therefore, considering the trade-off betweenapplicability and precision, it seems better to rely on a significantly larger monolin-gual corpus than on a smaller bilingual corpus.
An optimal method may exploit bothtypes of corpora, in which the somewhat more accurate, but more expensive, data ofa bilingual corpus are augmented by the data of a much larger monolingual corpus.
1312 We thank the anonymous reviewer for suggesting this point.13 Even though there are large quantities of translated texts, experience has shown that it is much harderto obtain large bilingual corpora than large monolingual corpora.
As mentioned earlier, a bilingual583Computational Linguistics Volume 20, Number 46.3.3 Lack of Deep Understanding.
By their nature, statistical methods rely on largequantities of shallow information.
Thus, they are doomed to fail when disambiguationcan rely only on deep understanding of the text and no other surface cues are available.This happened in one of the Hebrew examples, in which the two alternatives wereeither 'emigration law' or 'immigration law' (the Hebrew word hagira is used for bothsubsenses).
While the context indicated that the first alternative is correct (emigrationfrom the Soviet Union), the statistics (which were extracted from texts related to NorthAmerica) preferred the second alternative.
To translate the above phrase, the programwould need deep knowledge, to an extent hat seems to far exceed the capabilities ofcurrent systems.
Fortunately, our results uggest that such cases are quite rare.6.4 Monolingual ApplicationsThe results of our experiments in the context of machine translation suggest the util-ity of a similar mechanism even for in word sense disambiguation within a singlelanguage.
To select he right sense of a word, in a broad coverage application, it isuseful to identify lexical relations between word senses.
However, within corpora ofa single language it is possible to identify automatically only relations at the wordlevel, which are, of course, not useful for selecting word senses in that language.
Thisis where other languages can supply the solution, exploiting the fact that the mappingbetween words and word senses varies significantly between different languages.
Forinstance, the English words 'sign' and 'seal' (from Example 1 in the introduction) cor-respond to two distinct senses of the Hebrew word lahtom.
These senses hould bedistinguished by most applications of Hebrew understanding programs.
To make thisdistinction, it is possible to perform the same process that is performed for target wordselection, by producing all the English alternatives for the lexical relations involvinglahtom.
Then the Hebrew sense that corresponds to the most plausible English lexicalrelations is preferred.
This process requires a bilingual lexicon that maps each Hebrewsense separately into its possible translations, imilar to a Hebrew-Hebrew-Englishlexicon (analogous to the Oxford English-English-Hebrew dictionary of Hornby et al\[1986\], which lists the senses of an English word, along with the possible Hebrewtranslations for each of them).In some cases, different senses of a Hebrew word map to the same word also inEnglish.
In these cases, the lexical relations of each sense cannot be identified in anEnglish corpus, and a third language is required to distinguish among these senses.Alternatively, it is possible to combine our method with other disambiguation meth-ods that have been developed in a monolingual context (see the next section).
As along-term vision, one can imagine a multilingual corpora-based environment, whichexploits the differences between languages to facilitate the acquisition of knowledgeabout word senses.7.
Comparative Analysis of Statistical Sense Disambiguation MethodsUntil recently, word sense disambiguation seemed to be a problem for which thereis no satisfactory solution for broad coverage applications.
Recently, several statisti-cal methods have been developed for solving this problem, suggesting the possibilityof robust, yet feasible, disambiguation.
I  this section we identify and analyze basicaspects of a statistical sense disambiguation method and compare several proposedcorpus of moderate size can be valuable when constructing a bil ingual lexicon, thus justifying theeffort of maintaining such a corpus.584Ido Dagan and Alon Itai Word Sense Disambiguationmethods (including ours) along these aspects.
TM This analysis may be useful for futureresearch on sense disambiguation, as well as for the development of sense disam-biguation modules in practical systems.
The basic aspects that will be reviewed are.2.3.4.Information sources used by the disambiguation method.Acquisition of the required information from training texts.The computational decision model.Performance evaluation.The first three aspects deal with the components ofa disambiguation method, as wouldbe implemented for a practical application.
The fourth is a methodological issue, whichis relevant for developing, testing, and comparing disambiguation methods.7.1 Information SourcesWe identify three major types of information that were used in statistical methods forsense disambiguation:..3.Words appearing in the local, syntactically related, context of theambiguous word.Words appearing in the global context of the ambiguous word.Probabilistic syntactic and morphological characteristics of theambiguous word.The first type of information is the one used in the current paper, in which wordsthat are syntactically related to an ambiguous word are used to indicate its mostprobable sense.
Statistical data on the co-occurrence of syntactically related words witheach of the alternative senses reflect semantic and lexical preferences and constraintsof these senses.
In addition, these statistics may provide information about the topicsof discourse that are typical for each sense.Ideally, the syntactic relations between words should be identified using a syntac-tic parser, in both the training and the disambiguation phases.
Since robust syntacticparsers are not widely available, and those that exist are not always accurate, it is pos-sible to use various approximations to identify relevant syntactic relations betweenwords.
Hearst (1991) uses a stochastic part of speech tagger and a simple scheme forpartial parsing of short phrases.
The structures achieved by this analysis are used toidentify approximated syntactic relations between words.
Brown et al (1991) makeeven weaker approximations, using only a stochastic part of speech tagger, and defin-ing relations uch as "the first verb to the right" or "the first noun to the left."
Finally,Dagan et al (1993) (see Section 5.1) assume full parsing at the disambiguation phase,but no preprocessing at the training phase, in which a higher level of noise can beaccommodated.A second type of information is provided by words that occur in the global con-text of the ambiguous word (Gale, Church, and Yarowsky 1992b, 1993; Yarowsky 1992;Sch6tze 1992).
Gale et al and Yarowsky use words that appear within 50 words in each14 The reader is referred to some of these recent papers for thorough surveys of work on sensedisambiguation (Hearst 1991; Gale, Church, and Yarowsky 1992a; Yarowsky 1992).585Computational Linguistics Volume 20, Number 4direction of the ambiguous word.
is Statistical data are stored about the occurrence ofwords in the context of each sense and are matched against the context in the dis-ambiguated sentence.
Co-occurrence in the global context provides information abouttypical topics associated with each sense, in which a topic is represented by words thatcommonly occur in it.
Schiitze (1992, 1993) uses a variant of this type of information,in which contextvectors are maintained for character four-grams, instead of words.In addition, the context of an occurrence of an ambiguous word is represented byco-occurrence information of a second order, as a set of context vectors (instead of aset of context words).Compared with co-occurrence within syntactic relations, information about theglobal context is less sensitive to fine semantic and lexical distinctions and is lessuseful when different senses of a word appear in similar contexts.
On the other hand,the global context contains more words and is therefore more likely to provide enoughdisambiguating information, in cases in which this distinction can be based ~on the topicof discourse.
From a general perspective, these two types of information represent acommon trade-off in statistical language processing: the first type is related to a limitedamount of deeper, and more precise linguistic information, whereas the second typeprovides a large amount of shallow information, which can be applied in a morerobust manner.
The two sources of information seem to complement each other andmay both be combined in future disambiguation methods.
16Hearst (1991) incorporates a third type of statistical information to distinguishbetween different senses of nouns (in addition to the first type discussed above).For each occurrence of a sense, several syntactic and morphological characteristics arerecorded, such as whether the noun modifies or is modified by another word, whetherit is capitalized, and whether it is related to certain prepositional phrases.
Then, in thedisambiguation phase, a best match is sought between the information recorded foreach sense and the syntactic ontext of the current occurrence of the noun.
This typeof information resembles the information that is defined for lexical items in lexicalistapproaches for grammars, such as possible subcategorization frames of a word.
Themajor difference is that Hearst captures probabilistic preferences of senses for suchsyntactic onstructs.
Grammatical formalisms, on the other hand, usually specify onlywhich constructs are possible and at most distinguish between optional and obliga-tory ones.
Therefore the information recorded in such grammars cannot distinguishbetween different senses of a word that potentially have the same subcategorizationframes, though in practice each sense might have different probabilistic preferencesfor different syntactic onstructs.It is clear that each of the different ypes of information provides some informa-tion that is not captured by the others.
However, as the acquisition and manipulationof each type of information requires different ools and resources, it is important oassess the relative contribution, and the "cost effectiveness," of each of them.
Suchcomparative valuations are not available yet, not even for systems that incorporateseveral types of data (e.g., McRoy 1992).
Further research is therefore needed to com-15 The size of the context was determined experimentally, based on evaluations ofdifferent sizes ofcontext.
This optimization was performed for the Hansard corpus of the proceedings ofthe CanadianParliament.
In general, the size of the global context depends on the corpus and typically consists of ahomogeneous nit of discourse.16 See also Gale, Church, and Yarowsky 1992b (pp.
58-59), and Sch~itze, 1992, 1993, for methods ofreducing the number of parameters when using global contexts and Dagan, Marcus, and Markovitch1993, for increasing the applicability of the use of local context, in cases in which there is no directstatistical evidence.586Ido Dagan and Alon Itai Word Sense Disambiguationpare the relative importance of different information types and to find optimal waysof combining them.7.2 Acquisition of Training InformationWhen training a statistical model for sense disambiguation, it is necessary to associatethe acquired statistics with word senses.
This seems to require manual tagging of thetraining corpus with the appropriate sense for each occurrence ofan ambiguous word.A similar approach is being used for stochastic part of speech taggers and probabilisticparsers, relying on the availability of large, manually tagged (or parsed), corpora fortraining.
However, this approach is less feasible for sense disambiguation, for tworeasons.
First, the size of corpora required to acquire sufficient statistics on lexical co-occurrence is usually much larger than that used for acquiring statistics on syntacticconstructs or sequences of parts of speech.
Second, lexical co-occurrence patterns, aswell as the definition of senses, may vary a great deal across different domains ofdiscourse.
Consequently, it is usually not sufficient o acquire the statistics from onewidely available "balanced" corpus, as is common for syntactic applications.
A sensedisambiguation model should be trained on the same type of texts for which it willbe applied, thus increasing the cost of manual tagging.The need to disambiguate a training corpus before acquiring a statistical model fordisambiguation is often termed as the circularity problem.
In the following paragraphswe discuss different methods that were proposed to overcome the circularity problem,without exhaustive manual tagging of the training corpus.
In our opinion, this is themost critical issue in developing feasible sense disambiguation methods.7.2.1 Bootstrapping.
Bootstrapping, which is a general scheme for reducing the amountof manual tagging, was proposed also for sense disambiguation (Hearst 1991).
The ideais to tag manually an initial set of occurrences for each sense in the lexicon, acquiringinitial training statistics from these instances.
Then, using these statistics, the systemtries to disambiguate additional occurrences of ambiguous words.
If such an occur-rence can be disambiguated automatically with high confidence, the system acquiresadditional statistics from this occurrence, as if it were tagged by hand.
Hopefully, thesystem will incrementally acquire all the relevant statistics, demanding just a smallamount of manual tagging.
The results of Hearst (1991) show that at least 10 occur-rences of each sense have to be tagged by hand, and in most cases 20-30 occurrencesare required to get high precision.
These results, which were achieved for a small setof preselected ambiguous words, suggest hat the cost of the bootstrapping approachis still very high.7.2.2 Clustering Occurrences of an Ambiguous Word.
Sch6tze (1992, 1993) proposes amethod that can be viewed as an efficient way of manual tagging.
Instead of presentingall occurrences ofan ambiguous word to a human, these occurrences are first clusteredusing automatic lustering algorithms.
17Then a human is asked to assign one of thesenses of the word to each cluster, by observing several members of the cluster.
Eachsense is thus represented by one or more clusters.
At the disambiguation phase, a newoccurrence of an ambiguous word is matched against he contexts that were recordedfor these clusters, selecting the sense of that cluster which provides the best match.It is interesting to note that the number of occurrences that had to be observed bya human in the experiments of Sch/itze is of the same order as in the bootstrapping17 Each occurrence is represented as a context vector, and the vectors are then clustered,587Computational Linguistics Volume 20, Number 4approach: 10-20 members of a cluster were observed, with an average of 2.8 clustersper sense.
As both approaches were tested only on a small number of preselectedwords, further evaluation is necessary to predict he actual cost of their application tobroad domains.
The methods described below, on the other hand, rely on resourcesthat were already available on a large scale, and it is therefore possible to estimate theexpected cost of their broad application.7.2.3 Word Classification.
Yarowsky (1992) proposes a method that completely avoidsmanual tagging of the training corpus.
This is achieved by estimating parametersfor classes of words rather than for individual word senses.
In his work, Yarowskyconsidered the semantic ategories defined in Roget's Thesaurus as classes.
He thenmapped (manually) each of the senses of an ambiguous word to one or several ofthe categories under which this word is listed in the thesaurus.
The task of sensedisambiguation thus becomes the task of selecting the appropriate category for eachoccurrence of an ambiguous word.
18When estimating the parameters of a category/9 any occurrence of a word that be-longs to that category is counted as an occurrence of the category.
This means that eachoccurrence of an ambiguous word is counted as an occurrence of all the categories towhich the word belongs and not just the category that corresponds to the specific oc-currence.
A substantial mount of noise is introduced by this training method, whichis a consequence of the circularity problem.
To avoid the noise, it would be neces-sary to tag each occurrence of an ambiguous word with the appropriate category.
Asexplained by Yarowsky, however, this noise can usually be tolerated.
The "correct"parameters of a certain class are acquired from all its occurrences, whereas the "in-correct" parameters are distributed through occurrences of many different classes andusually do not produce statistically significant patterns.
To reduce the noise further,Yarowsky uses a system of weights that assigns lower weights to frequent words, sincesuch words may introduce more noise.
2?
The word class method thus overcomes thecircularity problem by mapping word senses to classes of words.
However, because ofthis mapping, the method cannot distinguish between senses that belong to the sameclass, and it also introduces ome level of noise.7.2.4 A Bilingual Corpus.
Brown et al (1991) were concerned with sense disambigua-tion for machine translation.
Having a large aligned bilingual corpus available, theynoticed that the target word which corresponds to an occurrence of an ambiguoussource word can serve as a tag of the appropriate sense.
This kind of tagging providessense distinctions when different senses of a source word translate to different argetwords.
For the purpose of translation, these are exactly the cases for which sense dis-tinction is required.
Conceptually, the use of a bilingual corpus does not eliminate (orreduce) manual tagging of the training corpus.
Such a corpus is a result of manualtranslation, and it is the translator who provides tagging of senses as a side effect ofthe translation process.
Practically, whenever a bilingual corpus is available, it pro-18 In some cases, the Roget index was found to be incomplete, and a missing category had to be added tothe list of possibilities for a word.19 Yarowsky uses statistics on occurrences of specific words in the global context of the category, but themethod can be used to collect other types of statistics, such as the co-occurrence of the category withother categories.20 The method of acquiring parameters from ambiguous occurrences in a corpus, relying on the"spreading" of noise, can be used in many  contexts.
For example, it was used for acquiring statisticsfor d isambiguat ing prepositional phrase attachments, counting ambiguous occurrences of prepositionalphrases as representing both noun-pp  and verb-pp constructs (Hindle and Rooth 1991).588Ido Dagan and Alon Itai Word Sense Disambiguationvides a useful source of a sense tagged corpus.
Gale, Church, and Yarowsky (1992a)have also exploited this resource for achieving large amounts of testing and trainingmaterials.7.2.5 A Bilingual Lexicon and a Monolingual Corpus.
The method of the current pa-per also exploits the fact that different senses of a word are usually mapped to differentwords in another language.
However, our work shows that the differences betweenlanguages enable us to avoid any form of manual tagging of the corpus (includingtranslation).
This is achieved by a bilingual exicon that maps a source language wordto all its possible equivalents in the target language.
This approach as practical ad-vantages for the purpose of machine translation, in which a bilingual exicon needsto be constructed in any case, and very large bilingual corpora are not usually avail-able.
From a theoretical point of view, the difference between the two methods can bemade clear if we assume that the bilingual lexicon contains exactly all the differenttranslations of a word which occur in a bilingual corpus.
For a given set of senses thatneed to be disambiguated, our method requires a bilingual corpus of size k, in whicheach sense occurs at least once, in order to establish its mapping to a target word.
Inaddition, a larger monolingual corpus, of size n, is required, to provide enough train-ing examples of typical contexts for each sense.
On the other hand, using a bilingualcorpus for training the disambiguation model would require a bilingual corpus of sizen, which is significantly larger than k. The savings in resources i achieved since themapping between the languages i done at the level of single words.
The larger amountof information about word combinations, on the other hand, is acquired from an un-tagged monolingual corpus, after the mapping has been performed.
Our results showthat the precision of the selection algorithm is high despite the additional noise whichis introduced by mapping single words independently of their context.
As mentionedin Section 6.3, an optimal method may combine the two methods.In some sense, the use of a bilingual lexicon resembles the use of a thesaurusin Yarowsky's approach.
Both rely on a manually established mapping of senses toother concepts (classes of words or words in another language) and collect informationabout the target concepts from an untagged corpus.
In both cases, ambiguous wordsin the corpus introduce some level of noise: counting an occurrence of a word as anoccurrence of all the classes to which it belongs, or counting an occurrence of a targetword as an occurrence of all the source words to which it may correspond (a smalleramount of noise is introduced in the latter case, as a mapping to target words is muchmore finely grained than a mapping to Roget's categories).
Also, both methods candistinguish only between senses that are distinguished by the mappings they use: ei-ther senses that belong to different classes, or senses that correspond to different targetwords.
An interesting difference, though, relates to the feasibility of implementing thetwo methods for a new domain of texts (in particular technical domains).
The con-struction of a bilingual exicon for a new domain is relatively straightforward and isoften carried out for translation purposes.
The construction of an appropriate classifi-cation for the words of a new domain is more complex, and furthermore, it is not clearwhether it is possible in every domain to construct a classification that is sufficient forthe purpose of sense disambiguation.7.3 The Computational Decision ModelSense disambiguation methods require a decision model that evaluates the relevantstatistics.
Sense disambiguation thus resembles many other decision tasks, and notsurprisingly, several common decision algorithms were employed in different works.These include a Bayesian classifier (Gale, Church, and Yarowsky 1993) and a distance589Computational Linguistics Volume 20, Number 4metric between vectors (Schiitze 1993), both inspired from methods in informationretrieval; the use of the flip-flop algorithm for ordering possible informants about hepreferred sense, trying to maximize the mutual information between the informantand the ambiguous word (Brown et al 1991); and the use of confidence intervals toestablish the degree of confidence in a certain preference, combined with a constraintpropagation algorithm (the current paper).
At the present stage of research on sensedisambiguation, it is difficult to judge whether a certain decision algorithm is signifi-cantly superior to others.
21 Yet, these decision models can be characterized by severalcriteria, which clarify the similarities and differences between them.
As will be ex-plained below, many of the differences are correlated with the different informationsources employed by these models.?
Combining several informants: The methods described by Brown et al(1991) and in the current paper combine several informants (i.e., statisticsabout several context words) by choosing the informant that seems mostindicative for the selection.
The effect of other, less significant, informantsis then discarded.
The Bayesian classifier and the vector distance metriccombine all informants simultaneously, in a multiplicative or additivemanner, possibly assigning a certain weight to each informant.?
Reducing the number of parameters: Since sense disambiguation relieson statistics about lexical co-occurrence, the number of relevantparameters i  very high, especially when co-occurrence in the globalcontext is considered.
For this reason, Schiitze uses two compactionmethods: First, 5000 "informative" four-grams are used instead of words.Second, the 5000 dimensions are decomposed to97 dimensions, usingsingular value decomposition.
This method reduces the number ofparameters significantly, but has the disadvantage that it is impossible totrace the meaning of the entries in the resulting vectors or to associatethem directly with the original co-occurrence statistics.
Gale, Church,and Yarowsky (1992b, pp.
58-59) propose another approach and reducethe number of parameters by selecting the most informative contextwords for each sense.
The selection of context words is based on atheoretically motivated criterion, borrowed from Mosteller and Wallace(1964, pp.
55-56).
Finally, Yarowsky's method further educes thenumber of parameters, asit records co-occurrences between individualwords and word classes.?
Statistical significance of the selection: In the current paper, we useconfidence intervals to test whether the statistical preference for a certainsense is significant.
In a simple multiplicative preference score, on theother hand, it is not possible to distinguish whether preferences rely onsmall or large counts.
The method of Gale et al remedies this problemindirectly (in most cases) by introducing a sophisticated interpolationbetween the actual counts of the co-occurrence parameters and thefrequency counts of the individual words (see Gale, Church, andYarowsky 1993, for details).
In Schiitze's method it is not possible totrace the statistical significance of the parameters since they are the resultof extensive processing and compaction of the original statistical data.21 Once the important information sources for sense selection have been identified, it is possible thatdifferent decision algorithms would achieve comparable r sults.590Ido Dagan and Alon Itai Word Sense DisambiguationResolving all ambiguities simultaneously: In the current paper, theselection of a sense for one word affects the selection for another wordthrough a constraint propagation algorithm.
This property is absent inmost other methods.The differences between various disambiguation methods correlate with the dif-ference in information sources, in particular, whether they use local or global context.When local context is used, only few syntactically related informants may provide re-liable information about he selection.
It is therefore reasonable tobase the selection ononly one, the most informative informant, and it is also important to test the statisticalsignificance of that informant.
The problem of parameter explosion is less severe, andthe number of parameters i  comparable to that of a bi-gram language model (andeven smaller).
When using the global context, on the other hand, the number of po-tential parameters i  significantly larger, but each of them is usually less informative.It is therefore important to take into account as many parameters as possible in eachambiguous case, but it is less important to test for detailed statistical significance, orto worry about the mutual effects of sense selections for adjacent words.7.4 Performance EvaluationIn most of the above-mentioned papers, experimental results are reported for a smallset of up to 12 preselected words, usually with two or three senses per word.
Inthe current paper we have evaluated our method using a random set of examplesentences, with no a priori selection of the words.
This standard evaluation method,which is commonly used for other natural language processing tasks, provides adirectprediction for the expected success rate of the method when employed in a practicalapplication.To compare results on different est data, it is useful to compare the precisionof the disambiguation method with some a priori figure that reflects the degree ofambiguity in the text.
Reporting the number of senses per example word correspondsto the expected success rate of random selection.
A more informative figure is thesuccess rate of a naive method that always selects the most frequent sense (the WordFrequencies method in our evaluations).
The success rate of this naive method is higherthan that of random selection and thus provides a tighter lower bound for the desiredprecision of a proposed isambiguation method.An important practical issue in evaluation is how to get the test examples, whichshould be tagged with the correct sense.
In most papers (including ours) the taggingof the test data was done by hand, which limits the size of the testing set.
Preparingone test set by hand may still be reasonable, though time consuming.
However, it isuseful to have more than one set, such that results will be reported on a new, unseen,set, while another set is used for developing and tuning the system.
One useful sourceof tagged examples i  an aligned bilingual corpus, which can be used for testing anysense disambiguation method, including methods that do not use bilingual materialfor training.
Gale proposes to use "pseudo-words" asanother practical source of test-ing examples (Gale, Church, and Yarowsky 1992b) (equivalently, Schfitze \[1992\] uses"artificial ambiguous words").
Pseudo-words are constructed artificially as a union ofseveral different words (say, wl, w2, and w3 define three "senses" of the pseudo-wordx).
The disambiguation method is presented with texts in which all occurrences ofwl, w2, and w3 are considered as occurrences of x and should then select he originalword (sense) for each occurrence.
Though testing with this method does not provideresults for real ambiguities that occur in the text, it can be very useful while develop-591Computational Linguistics Volume 20, Number 4ing and tuning the method (Gale shows high correlation between the performance ofhis method on real sense ambiguities and pseudo-words).8.
ConclusionsThe method presented in this paper takes advantage of two linguistic phenomena, bothproven to be very useful for sense disambiguation: the different mapping betweenwords and word senses among different languages, and the importance of lexicalco-occurrence within syntactic relations.
The first phenomenon provides the solutionfor the circularity problem in acquiring sense disambiguation data.
Using a bilinguallexicon and a monolingual corpus of the target language, we can acquire statistics onword senses automatically, without manual tagging.
As explained in Section 7, thismethod has significant practical and theoretical advantages over the use of alignedbilingual corpora.
We pay for these advantages by introducing an additional evelof noise, in mapping individual words independently to the other language.
Ourresults show, however, that the precision of the selection algorithm is high despite thisadditional noise.This work also emphasizes the importance of lexical co-occurrence within syntac-tic relations for the resolution of lexical ambiguity.
Co-occurrences found in a largecorpus reflect a huge amount of semantic knowledge, which was traditionally con-structed by hand.
Moreover, frequency data for such co-occurrences reflect both lin-guistic and domain-specific preferences, thus indicating not only what is possible, butalso what is probable.
It is important o notice that frequency information on lexicalco-occurrence was found to be much more predictive than single word frequency.
Inthe three experiments we reported, there were 61 cases in which the two types ofinformation contradicted each other, favoring different arget words.
In 56 of thesecases (92%), it was the most frequent lexical co-occurrence, and not the most frequentword, that predicted the correct ranslation.
This result may raise relevant hypothesesfor psycholinguistic research, which has indicated the relevance of word frequenciesto human sense disambiguation (e.g., Simpson and Burgess 1988).We suggest hat the high precision achieved in the experiments relies on twocharacteristics of the ambiguity phenomena, namely the sparseness and redundancyof the disambiguating data.
By sparseness we mean that within the large space ofalternative interpretations produced by ambiguous utterances, only a small portion iscommonly used.
Therefore, the chance that an inappropriate interpretation is observedin the corpus (in other contexts) is low.
Redundancy relates to the fact that differentinformants (such as different lexical relations or deep understanding) tend to supportrather than contradict one another, and therefore the chance of picking a "wrong"informant is low.It is interesting to compare our method with some aspects of the statistical machinetranslation system of Brown et al (1990).
As mentioned in the introduction, this systemalso incorporates target language statistics in the translation process.
To translate aFrench sentence, f, they choose the English sentence, ,that maximizes the term Pr(e) ?Pr(f I e).
The first factor in this product, which represents the target language model,may thus affect any aspect of the translation, including target word selection.It seems, however, that Brown et al expect hat target word selection would bedetermined mainly by translation probabilities (the second factor in the above term),which should be derived from a bilingual corpus (Brown et al 1990, p. 79).
Thisview is reflected also in their elaborate method for target word selection (Brown et al1991), in which better estimates of translation probabilities are achieved as a resultof word sense disambiguation.
Our method, on the other hand, incorporates only592Ido Dagan and Alon Itai Word Sense Disambiguationtarget language probabilities and ignores any notion of translation probabilities.
Itthus demonstrates a possible trade-off between these two types of probabilities: usingmore informative statistics of the target language may compensate for the lack oftranslation probabilities.
For our system, the more informative statistics are achievedby syntactic analysis of both the source and target languages, instead of the simpletri-gram model used by Brown et al In a broader sense, this can be viewed as a trade-off between the different components of a translation system: having better analysisand generation models may reduce some burden from the transfer model.In our opinion, the method proposed in this paper may have immediate practicalvalue, beyond its theoretical spects.
As we argue below, we believe that the methodis feasible for practical machine translation systems and can provide a cost-effectiveimprovement on target word selection methods.
The identification of syntactic rela-tions in the source sentence is available in any machine translation system that usessome form of syntactic parsing.
Trivially, a bilingual exicon is available.
A parser forthe target language becomes common in many systems that offer bidirectional transla-tion capabilities, requiring parsers for several languages ( ee Miller 1993, for availablelanguage pairs in several commercial machine translation systems).
If a parser for thetarget language corpus is not available, it is possible to approximate he statistics usingword co-occurrence in a window, as was demonstrated by a variant of our method(Dagan, Marcus, and Markovitch 1993) (see Section 5.1).
In both cases, the statisticalmodel was shown to handle successfully the noise produced in automatic acquisitionof the data.
Substantial effort may be required for collecting a sufficiently large tar-get language corpus.
We have not studied the relation between the corpus size andthe performance of the algorithm, but it is our impression that a corpus of severalhundred thousand words will prove useful for translation i  a well-defined omain.With current availability of texts in electronic form, = a corpus of this size is feasiblein many domains.
The effort of assembling this corpus should be compared with theeffort of manually coding sense disambiguation information.
Finally, our method wasevaluated by simulating realistic machine translation lexicons, on randomly selectedexamples, and yielded high performance in two different broad domains (foreign ewsarticles and a software manual).
It is therefore xpected that the results reported herewill be reproduced in other domains and systems.To improve the performance of target word selection further, our method maybe combined with other sense disambiguation methods.
As discussed in Section 6.2,it is possible to increase the applicability (coverage) of the selection method by con-sidering word co-occurrence in a limited context and/or by using similarity-basedmethods that reduce the problem of data sparseness.
To a lesser extent, the use of abilingual corpus may further increase the precision of the selection (see Section 6.3).
Apractical strategy may be to use a bilingual corpus for enriching the bilingual lexicon,while relying mainly on co-occurrence statistics from a larger monolingual corpus fordisambiguation.In a broader context, his paper promotes the combination ofstatistical nd linguis-tic models in natural language processing.
It provides an example of how a problemcan be first defined in detailed linguistic terms, using an implemented linguistic tool(a syntactic parser, in our case).
Then, having a well-defined linguistic scenario, weapply a suitable statistical model to highly informative linguistic structures.
Accordingto this view, a complex task, such as machine translation, should be first decomposed22 Optical character recognition can also be used to acquire relevant exts in electronic form.
In this case,it may  be necessary to approximate the statistics us ing word co-occurrence in a window, since parsingnoisy output from optical character recognition is difficult.593Computational Linguistics Volume 20, Number 4on a linguistic basis.
Then, appropriate statistical models can be developed for eachsub-problem.
We believe that this approach provides abeneficial compromise b tweentwo extremes innatural language processing: either using linguistic models that ignorequantitative information, or using statistical models that are linguistically ignorant.Append ixApprox imat ingvar \ [ ln (~) lTo approximate var \[In (~)\] ,  we first approximate In (~)by  the first order derivatives(the first term of the Taylor series):(\]91) ~__  ln( pI )__ \[~Xl (X1/\]~22 In  ~ '}- (Pl -- ,1 ) Inpl ,p2q-(\]92--P2) \[~-~21n(X~22)\]pl,p2: ln(P~2) q- fil--p~lpl \]92--P2p2: ln(P~2)q-\]91 -\] 2"pl P2 (5)We use the following equations ( ee Agresti 1990):var(x+c) = var(x),var(xl - x2) = var(xl) + var(x2) - 2. covariance(xl,x2),var(~) -- p(1-p) ,  n(c )  - var(x) va r C2 ,covariance(fii, l~j ) - PiPjncovariance( x l , x2) ?
r x1 x2covamance( ~ , ~2 ) = clc2Using (5) we getvar\[ln(~22)\] ~ var\[ln(P~221 +l~lp, ~21= varI~11-~221\[\]91\] \[lY2\]_2.covariance\[lYl,tY2 \] = var Pll +var P2 \[pl ~22_ 1 p1(1 -Pl)  + 1 p2(1 -P2) +2 PiP2p2 n p2 n nplP21 1 1 1 1 1 - +__~ + =--+- - .npl np2 np~l nl~ nl n2594Ido Dagan and Alon Itai Word Sense DisambiguationAcknowledgmentsSpecial thanks are due to Ulrike Schwall forher fruitful collaboration.
We are grateful toMori Rimon, Peter Brown, Ayala Cohen,Ulrike Rackow, Herb Leass, and Bill Galefor their help and comments.
We also thankthe anonymous reviewers for their detailedcomments, which resulted in additionaldiscussions and clarifications.
This researchwas partially supported by grant number120-741 of the Israel Council for Researchand Development.ReferencesAgresti, Alan (1990).
Categorical DataAnalysis.
New York: John Wiley & Sons.Alcalay, R. (1990).
The CompleteHebrew-English Dictionary.
Massada.Brown, P.; Cocke, J.; Della Pietra, S.;Della Pietra, V.; Jelinek, E; Mercer, R. L.;and Roossin, P. C. (1990).
A statisticalapproach to language translation.Computational Linguistics 16(2):79-85.Brown, P.; Della Pietra, S.; Della Pietra, V.;and Mercer, R. (1991).
"Word sensedisambiguation using statisticalmethods."
In Proceedings, Annual Meetingof the Association for ComputationalLinguistics, 264-270.Brown, Peter; Della Pietra, Stephen; DellaPietra, Vincent; and Mercer, Robert (1993).
"But dictionaries are data too."
InProceedings, ARPA Workshop on HumanLanguage Technology, 202-205.Chodorow, M. S.; Byrd, R. J.; and Heidron,G.
E. (1985).
"Extracting semantichierarchies from a large on-linedictionary."
In Proceedings, Annual Meetingof the Association for ComputationalLinguistics, 299-304.Church, Kenneth W., and Gale, William A.(1991).
"A comparison of the enhancedGood-Turing and deleted estimationmethods for estimating probabilities ofEnglish bigrams."
Computer Speech andLanguage 5:19-54.Church, Kenneth W., and Hanks, Patrick(1990).
"Word association orms, mutualinformation, and lexicography.
"Computational Linguistics 16(1):22-29.Dagan, Ido; Church, Kenneth; and Gale,William (1993).
"Robust bilingual wordalignment for machine aided translation.
"In Proceedings, Workshop on Very LargeCorpora: Academic and IndustrialPerspectives, 1-8.Dagan, Ido, and Itai, Alon (1990).
"Automatic acquisition of constraints forthe resolution of anaphora references andsyntactic ambiguities."
In Proceedings,International Conference on ComputationalLf::,ouistics, Volume 3, 330-332.Dagan, Ido, and Itai, Alon (1991).
"Astatistical filter for resolving pronounreferences."
In Artificial Intelligence andComputer Vision (Proceedings, 7th IsraeliSymposium on Artificial Intelligence andComputer Vision, 1990), edited byY.
A. Feldman and A. Bruckstein,125-135.
Elsevier Science Publishers B.V.Dagan, Ido; Itai, Alon; and Schwall, Ulrike(1991).
"Two languages are moreinformative than one."
In Proceedings,Annual Meeting of the Association forComputational Linguistics, 130-137.Dagan, Ido; Marcus, Shaul; and Markovitch,Shaul (1993).
"Contextual word similarityand estimation from sparse data."
InProceedings, Annual Meeting of theAssociation for Computational Linguistics,164-171.Gale, William; Church, Kenneth; andYarowsky, David (1992a).
"Usingbilingual materials to develop word sensedisambiguation methods."
In Proceedings,International Conference on Theoretical ndMethodolgical Issues in Machine Translation,101-112.Gale, William; Church, Kenneth; andYarowsky, David (1992b).
"Work onstatistcal methods for word sensedisambiguation."
In Working Notes, AAAIFall Symposium Series, ProbabilisticApproaches toNatural Language, 54-60.Gale, William; Church, Kenneth; andYarowsky, David (1993).
"A method fordisambiguating word senses in a largecorpus."
Computers and the Humanities26:415-439.Golan, Igal; Lappin, Shalom; and Rimon,Mori (1988).
"An active bilingual exiconfor machine translation."
In Proceedings,Conference on Computational Linguistics,205-211.Grishman, R.; Hirschman, L.; and ThanhNhan, Ngo (1986).
"Discovery proceduresfor sublanguage s lectional patterns -initial experiments."
ComputationalLinguistics 12:205-214.Hearst, Marti (1991).
"Noun homographdisambiguation using local context inlarge text corpora."
In Proceedings, AnnualConference ofthe UW Center for the NewOED and Text Research, 1-22.Hindle, D. (1990).
"Noun classification frompredicate-argument structures."
InProceedings, Annual Meeting of theAssociation for Computational Linguistics,595Computational Linguistics Volume 20, Number 4268-275.Hindle, D., and Rooth, M.
(1991).
"Structural ambiguity and lexicalrelations."
In Proceedings, Annual Meetingof the Association for ComputationalLinguistics, 229-236.Hornby, A. S.; Ruse, C.; Reif, J.
A.; andLevy, Y.
(1986).
Oxford Student's Dictionaryfor Hebrew Speakers.
Kernerman PublishingLtd., Lonnie Kahn & Co. Ltd.Jelinek, Frederick (1990).
"Self-organizedlanguage modeling for speechrecognition."
In Readings in SpeechRecognition, edited by Alex Waibel andKai-Fu Lee, 450-506.
San Mateo,California: Morgan Kaufmann Publishers,Inc.Jelinek, Frederick; Mercer, Robert L.; andRoukos, Salim (1992).
"Principles oflexical anguage modeling for speechrecognition."
In Advances in Speech SignalProcessing, edited by Sadaoki Furui andM.
Mohan Sondhi, 651-699.
MercerDekker, Inc.Katz, Slava M. (1987).
"Estimation ofprobabilities from sparse data for thelanguage model component of a speechrecognizer."
IEEE Transactions on Acoustics,Speech, and Signal Processing 35(3):400-401.Lenat, D. B.; Guha, R. V.; Pittman, K.; Pratt,D.
; and Shepherd, M. (1990).
"Cyc:Toward programs with common sense.
"Communications of the ACM 33(8):30-49.McCord, M. C. (1990).
"Slot grammar: Asystem for simpler construction ofpractical natural language grammars."
InNatural Language and Logic: InternationalScientific Symposium.
Lecture Notes inComputer Science, edited by R. Studer,118-145.
Berlin: Springer Verlag.McCord, M. C. (1991).
"The slot grammarsystem."
Technical report RC 17313, IBMResearch Report.
In Unification inGrammar, edited by J. Wedekind andC.
Rohrer, in press.
Cambridge, MA: MITPress.McRoy, Susan W. (1992).
"Using multipleknowledge sources for word sensedisambiguation."
Computational Linguistics18(1):1-30.Miller, L. Chris.
(1993).
"Bableware for thedesktop."
BYTE January:177-183.Mosteller, Frederick, and Wallace, David(1964).
Inference and Disputed Authorship:The Federalist.
Readifig, Massachusetts:Addison-Wesley.National Language Research Institute(1964).
Bunrui Goi Hyou (Word List bySemantic Principles).
Shuuel Publishing.Nirenburg, S., editor (1987).
MachineTranslation.
Cambridge: CambridgeUniversity Press.Nirenburg, S.; Monarch, I.; Kaufmann, T.;Nirenburg, I.; and Carbonell, J.
(1988).
"Acquisition of very large knowledgebases: Methodology, tools andapplications."
Technical reportCMU-CMT-88-108, Center for MachineTranslation, Carnegie-Mellon.Sadler, V. (1989).
Working with AnalogicalSemantics: Disambiguation Techniques inDLT.
Foris Publications.Schfitze, Hinrich (1992a).
"Context space.
"In Working Notes, AAAI Fall Symposium onProbabilistic Approaches toNatural Language.Schiitze, Hinrich (1992).
"Dimensions ofmeaning."
In Proceedings, Supercomputing,787-796.Schfitze, Hinrich (1993).
"Word space."
InAdvances in Neural Information ProcessingSystems 5, edited by S. J. Hanson,J.
D. Cowan, and C. L. Giles, 895-902.
SanMateo, California: Morgan KaufmanPublishers.Simpson, Greg B., and Burgess, Curt (1988).
"Implications of lexical ambiguityresolution for word recognition."
InLexical Ambiguity Resolution, edited byG.
W. Cotrell, S. L. Small, andM.
K. Tanenhaus, 271-288.
San Mateo,California: Morgan Kaufman Publishers.Smadja, Frank (1993).
"Retrievingcollocations from text: Xtract.
"Computational Linguistics 19(1):143-177.Woods, W. A.
(1973).
"An experimentalparsing system for transition etworkgrammars."
In Natural LanguageProcessing, edited by R. Rustin, 111-154.Algorithmics Press.Yarowsky, David (1992).
"Word sensedisambiguation using statistical models ofRoget's categories trained on largecorpora."
In Proceedings, InternationalConference on Computational Linguistics,454-460.Zernik, U., and Jacobs, P. (1990).
"Taggingfor learning: Collecting thematic relationsfrom corpus."
In Proceedings, InternationalConference on Computational Linguistics,Volume 1, 34-39.596
