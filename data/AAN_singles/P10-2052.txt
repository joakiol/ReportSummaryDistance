Proceedings of the ACL 2010 Conference Short Papers, pages 281?285,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsArabic Named Entity Recognition:Using Features Extracted from Noisy DataYassine Benajiba1 Imed Zitouni2 Mona Diab1 Paolo Rosso31 Center for Computational Learning Systems, Columbia University2 IBM T.J. Watson Research Center, Yorktown Heights3 Natural Language Engineering Lab.
- ELiRF, Universidad Polite?cnica de Valencia{ybenajiba,mdiab}@ccls.columbia.edu, izitouni@us.ibm.com, prosso@dsic.upv.esAbstractBuilding an accurate Named EntityRecognition (NER) system for languageswith complex morphology is a challeng-ing task.
In this paper, we present researchthat explores the feature space using bothgold and bootstrapped noisy features tobuild an improved highly accurate ArabicNER system.
We bootstrap noisy featuresby projection from an Arabic-English par-allel corpus that is automatically taggedwith a baseline NER system.
The featurespace covers lexical, morphological, andsyntactic features.
The proposed approachyields an improvement of up to 1.64F-measure (absolute).1 IntroductionNamed Entity Recognition (NER) has earned animportant place in Natural Language Processing(NLP) as an enabling process for other tasks.When explicitly taken into account, researchshows that it helps such applications achieve bet-ter performance levels (Babych and Hartley, 2003;Thompson and Dozier, 1997).
NER is defined asthe computational identification and classificationof Named Entities (NEs) in running text.
For in-stance, consider the following text:Barack Obama is visiting the Middle East.A NER system should be able to identify BarackObama and Middle East as NEs and classify themas Person (PER) and Geo-Political Entity (GPE),respectively.
The class-set used to tag NEs mayvary according to user needs.
In this research,we adopt the Automatic Content Extraction (ACE)2007 nomenclature1.According to (Nadeau and Sekine, 2007), opti-mization of the feature set is the key component inenhancing the performance of a global NER sys-tem.
In this paper we investigate the possibil-ity of building a high performance Arabic NERsystem by using a large space of available featuresets that go beyond the explored shallow featuresets used to date in the literature for Arabic NER.1http://www.nist.gov/speech/tests/ace/index.htmGiven current state-of-the-art syntactic processingof Arabic text and the relative small size of man-ually annotated Arabic NER data, we set out toexplore a main concrete research goal: to fully ex-ploit the level of advancement in Arabic lexicaland syntactic processing to explore deeper linguis-tic features for the NER task.
Realizing that thegold data available for NER is quite limited in sizeespecially given the diverse genres in the set, wedevise a method to bootstrap additional instancesfor the new features of interest from noisily NERtagged Arabic data.2 Our ApproachWe use our state-of-the-art NER system describedin (Benajiba et al, 2008) as our baseline sys-tem (BASE) since it yields, to our knowledge, thebest performance for Arabic NER .
BASE em-ploys Support Vector Machines (SVMs) and Con-ditional Random Fields (CRFs) as Machine Learn-ing (ML) approaches.
BASE uses lexical, syn-tactic and morphological features extracted usinghighly accurate automatic Arabic POS-taggers.BASE employs a multi-classifier approach whereeach classifier is tagging a NE class separately.The feature selection is performed by using an in-cremental approach selecting the top n features(the features are ranked according to their individ-ual impact) at each iteration and keeping the setthat yields the best results.
In case of conflict - aword is classified with more than one class/tag si-multaneously - the global NER system selects theoutput of the classifier with the highest precision.The following is the feature set used in (Bena-jiba et al, 2008) and accordingly in the BASE sys-tem.
1.
Context: a?/+1 token window; 2.
Lex-ical: character n ?
grams where n ranges from1?
3; 3.
Gazetteers: automatically harvested andmanually cleaned Person NE class (PER), Geopo-litical Entity NE class (GPE), and OrganizationNE class (ORG) lexica; 4.
POS-tag and BasePhrase Chunk (BPC): automatically tagged us-ing AMIRA (Diab et al, 2007) which yields F-measures for both tasks in the high 90?s; 5.
Mor-phological features: automatically tagged usingthe Morphological Analysis and Disambiguationfor Arabic (MADA) tool to extract informationabout gender, number, person, definiteness and as-281pect for each word (Habash and Rambow, 2005);6.
Capitalization: derived as a side effect fromrunning MADA.
MADA chooses a specific mor-phological analysis given the context of a givenword.
As part of the morphological informationavailable in the underlying lexicon that MADA ex-ploits.
As part of the information present, the un-derlying lexicon has an English gloss associatedwith each entry.
More often than not, if the wordis a NE in Arabic then the gloss will also be a NEin English and hence capitalized.We devise an extended Arabic NER system (EX-TENDED) that uses the same architecture asBASE but employs additional features to those inBASE.
EXTENDED defines new additional syn-tagmatic features.We specifically investigate the space of the sur-rounding context for the NEs.
We explore gener-alizations over the kinds of words that occur withNEs and the syntactic relations NEs engage in.
Weuse an off-the-shelf Arabic syntactic parser.
State-of-the-art for Arabic syntactic parsing for the mostcommon genre (with the most training data) ofArabic data, newswire, is in the low 80%s.
Hence,we acknowledge that some of the derived syntacticfeatures will be noisy.Similar to all supervised ML problems, it is de-sirable to have sufficient training data for the rele-vant phenomena.
The size of the manually anno-tated gold data typically used for training ArabicNER systems poses a significant challenge for ro-bustly exploring deeper syntactic and lexical fea-tures.
Accordingly, we bootstrap more NE taggeddata via projection over Arabic-English paralleldata.
The role of this data is simply to give us moreinstances of the newly defined features (namelythe syntagmatic features) in the EXTENDED sys-tem as well as more instances for the Gazetteersand Context features defined in BASE.
It is worthnoting that we do not use the bootstrapped NEtagged data directly as training data with the golddata.2.1 Syntagmatic FeaturesFor deriving our deeper linguistic features, weparse the Arabic sentences that contain an NE.
Foreach of the NEs, we extract a number of featuresdescribed as follows:- Syntactic head-word (SHW): The idea hereis to look for a broader relevant context.Whereas the feature lexical n-gram context fea-ture used in BASE, and hence here for EX-TENDED, considers the linearly adjacent neigh-boring words of a NE, SHW uses a parse treeto look at farther, yet related, words.
Forinstance, in the Arabic phrase ?SrH Ams AnFigure 1: Example for the head word and syntacticenvironment featurebArAk AwbAma ytrAs?, which means ?de-clared yesterday that Barack Obama governs...?, glossed ?SrH/declared Ams/yesterday An/thatbArAk/Barack AwbAmA/Obama ytrAs/governs...?, is parsed in Figure 1.
According to the phrasestructure parse, the first parent sub-tree headwordof the NE ?bArAk AwbAmA?
is the verb ?ytrAs?
(governs), the second one is ?An?
(that) and thethird one is the verb ?SrH?
(declared).
This exam-ple illustrates that the word ?Ams?
is ignored forthis feature set since it is not a syntactic head.
Thisis a lexicalized feature.- Syntactic Environment (SE): This follows in thesame spirit as SHW, but expands the idea in thatit looks at the parent non-terminal instead of theparent head word, hence it is not a lexicalized fea-ture.
The goal being to use a more abstract repre-sentation level of the context in which a NE ap-pears.
For instance, for the same example pre-sented in Figure 1, the first, second, and third non-terminal parents of the NE ?bArAk AwbAmA?
are?S?, ?SBAR?
and ?VP?, respectively.In our experiments we use the Bikel implementa-tion (Bikel, 2004) of the Collins parser (Collins,1999) which is freely available on the web2.
It is ahead-driven CFG-style parser trained to parse En-glish, Arabic, and Chinese.2.2 Bootstrapping Noisy Arabic NER DataExtracting the syntagmatic features from thetraining data yields relatively small number ofinstances.
Hence the need for additional taggeddata.
The new Arabic NER tagged data is derivedvia projection exploiting parallel Arabic Englishdata.
The process depends on the availabilityof two key components: a large Arabic Englishparallel corpus that is sentence and word aligned,and a robust high performing English NERsystem.
The process is as follows.
We NE tag the2http://www.cis.upenn.edu/?dbikel/software.html#stat-parser282English side of the parallel corpus.
We projectthe automatically tagged NER tags from theEnglish side to the Arabic side of the parallelcorpus.
In our case, we have access to a largemanually aligned parallel corpus, therefore theNER projection is direct.
However, the Englishside of the parallel corpus is not NER tagged,hence we use an off-the-shelf competitive robustautomatic English NER system which has apublished performance of 92% (Zitouni andFlorian, 2009).
The result of these two processesis a large Arabic NER, albeit noisy, tagged dataset.
As mentioned earlier this data is used onlyfor deriving additional instances for trainingfor the syntagmatic features and for the contextand gazetteer features.3 Given this additionalsource of data, we changed the lexical featuresextracted from the BASE to the EXTENDED.
Weadded two other lexical features: CBG and NGC,described as follows: - Class Based Gazetteers(CBG): This feature focuses on the surface formof the NEs.
We group the NEs encountered on theArabic side of the parallel corpus by class as theyare found in different dictionaries.
The differencebetween this feature and that in BASE is that theGazetteers are not restricted to Wikipedia sources.- N-gram context (NGC): Here we disregardthe surface form of the NE, instead we focus on itslexical context.
For each n, where n varies from 1to 3, we compile a list of the ?n, +n, and ?/+ nwords surrounding the NE.
Similar to the CBGfeature, these lists are also separated by NE class.It is worth highlighting that the NCG feature isdifferent from the Context feature in BASE inthat the window size is different +/ ?
1 ?
3 forEXTENDED versus +/?
1 for BASE.3 Experiments and Results3.1 Gold Data for training and evaluationWe use the standard sets of ACE 2003, ACE2004 and ACE 2005.4 The ACE data is annotatedfor many tasks: Entity Detection and Tracking(EDT), Relation Detection and Recognition(RDR), Event Detection and Recognition (EDR).All the data sets comprise Broadcast News(BN) and Newswire (NW) genres.
ACE 2004includes an additional NW data set from theArabic TreeBank (ATB).
ACE 2005 includesa different genre of Weblogs (WL).
The NEclasses adopted in the annotation of the ACE2003 data are: Person (PER), Geo Political Entity(GPE), Organization (ORG) and Facility (FAC).3Therefore, we did not do the full feature extraction forthe other features described in BASE for this data.4http://www.nist.gov/speech/tests/ace/Additionally for the ACE 2004 and 2005 data, twoNE classes are added to the ACE 2003 tag-set:Vehicles (e.g.
Rotterdam Ship) and Weapons (e.g.Kalashnikof).
We use the same split for train, de-velopment, and test used in (Benajiba et al, 2008).3.2 Parallel DataMost of the hand-aligned Arabic-English paralleldata used in our experiments is from the LanguageData Consortium (LDC).5.
Another set of the par-allel data is annotated in-house by professional an-notators.
The corpus has texts of five different gen-res, namely: newswire, news groups, broadcastnews, broadcast conversation and weblogs corre-sponding to the data genres in the ACE gold data.The Arabic side of the parallel corpus contains941,282 tokens.
After projecting the NE tags fromthe English side to the Arabic side of the paral-lel corpus, we obtain a total of 57,290 Arabic NEinstances.
Table 1 shows the number of NEs foreach class.Class Number of NEs Class Number of NEsFAC 998 PER 17,964LOC 27,651 VEH 85ORG 10,572 WEA 20Table 1: Number of NEs per class in the Arabicside of the parallel corpus3.3 Individual Feature ImpactAcross the board, all the features yield improvedperformance.
The highest obtained result is ob-served where the first non-terminal parent is usedas a feature, a Syntactic Environment (SE) fea-ture, yielding an improvement of up to 4 pointsover the baseline.
We experiment with differentsizes for the SE, i.e.
taking the first parent versusadding neighboring non-terminal parents.
We notethat even though we observe an overall increasein performance, considering both the {first, sec-ond} or the {first, second, and third} non-terminalparents decreases performance by 0.5 and 1.5 F-measure points, respectively, compared to consid-ering the first parent information alone.
The headword features, SHW, show a higher positive im-pact than the lexical context feature, NGC.
Finally,the Gazetteer feature, CBG, impact is comparableto the obtained improvement of the lexical contextfeature.3.4 Feature Combination ExperimentsTable 2 illustrates the final results.
It shows foreach data set and each genre the F-measure ob-tained using the best feature set and ML approach.It shows results for both the dev and test data us-ing the optimal number of features selected from5All the LDC data are publicly available283ACE 2003 ACE 2004 ACE 2005BN NW BN NW ATB BN NW WLFreqBaseline 73.74 67.61 62.17 51.67 62.94 70.18 57.17 27.66devAll-Synt.
83.41 79.11 76.90 72.90 74.82 81.42 76.07 54.49All 83.93 79.72 78.54 72.80 74.97 81.82 75.92 55.65testAll-Synt.
83.50 78.90 76.70 72.40 73.50 81.31 75.30 57.30All 84.32 79.4 78.12 72.13 74.54 81.73 75.67 58.11Table 2: Final Results obtained with selected features contrasted against all features combinedthe all the features except the syntagmatic ones(All-Synt.)
contrasted against the system in-cluding the semantic features, i.e.
All the features,per class All .
The baseline results, FreqBaseline,assigns a test token the most frequent tag observedfor it in the gold training data, if a test token isnot observed in the training data, it is assigned themost frequent tag which is the O tag.4 Results DiscussionIndividual feature impact results show that thesyntagmatic features are helpful for most of thedata sets.
The highest improvements are obtainedfor the 2003 BN and 2005 WL data-sets.
The im-provement varies significantly from one data-setto another because it highly depends on the num-ber of NEs which the model has not been able tocapture using the contextual, lexical, syntactic andmorphological features.Impact of the features extracted from the paral-lel corpus per class: The syntagmatic featureshave varied in their influence on the different NEclasses.
Generally, the LOC and PER classes ben-efitted more from the head word features, SHW),than the other classes.
On the other hand for thesyntactic environment feature (SE), the PER classseemed not to benefit much from the presence ofthis feature.
Weblogs: Our results show that therandom contexts in which the NEs tend to ap-pear in the WL documents stand against obtain-ing a significant improvement.
Consequently, thefeatures which use a more global context (syntac-tic environment, SE, and head word, SHW, fea-tures) have helped obtain better results than theones which we have obtained using local contextnamely CBG and NGC.5 Related WorkProjecting explicit linguistic tags from anotherlanguage via parallel corpora has been widely usedin the NLP tasks and has proved to contribute sig-nificantly to achieving better performance.
Dif-ferent research works report positive results whenusing this technique to enhance WSD (Diab andResnik, 2002; Ng et al, 2003).
In the latter twoworks, they augment training data from paralleldata for training supervised systems.
In (Diab,2004), the author uses projections from Englishinto Arabic to bootstrap a sense tagging systemfor Arabic as well as a seed Arabic WordNetthrough projection.
In (Hwa et al, 2002), theauthors report promising results of inducing Chi-nese dependency trees from English.
The ob-tained model outperformed the baseline.
More re-cently, in (Chen and Ji, 2009), the authors reporttheir comparative study between monolingual andcross-lingual bootstrapping.
Finally, in MentionDetection (MD), a task which includes NER andadds the identification and classification of nom-inal and pronominal mentions, (Zitouni and Flo-rian, 2008) show the impact of using a MT sys-tem to enhance the performance of an Arabic MDmodel.
The authors report an improvement of upto 1.6F when the baseline system uses lexical fea-tures only.
Unlike the work we present here, theirapproach requires the availability of an accurateMT system which is a more expensive process.6 Conclusion and Future DirectionsIn this paper we investigate the possibility ofbuilding a high performance Arabic NER systemby using lexical, syntactic and morphological fea-tures and augmenting the model with deeper lexi-cal features and more syntagmatic features.
Theseextra features are extracted from noisy data ob-tained via projection from an Arabic-English par-allel corpus.
Our results show that we achieve asignificantly high performance for almost all thedata-sets.
The greatest impact of the syntagmaticfeatures (1.64 points of F-measure) is obtained forthe ACE 2004, BN genre.
Also, the WL genreyields an improvement of 1.16 F1 points absolute.AcknowledgmentsThis work has been partially funded by DARPA GALEproject.
The research of the last author was fundedby MICINN research project TEXT-ENTERPRISE 2.0TIN2009-13391-C04-03 (Plan I+D+i).284ReferencesB.
Babych and A. Hartley.
2003.
Improving MachineTranslation Quality with Automatic Named EntityRecognition.
In Proc.
of EACL-EAMT.Y.
Benajiba, M. Diab, and P. Rosso.
2008.
Ara-bic named entity recognition using optimized featuresets.
In Proceedings of EMNLP?08, pages 284?293.Daniel M. Bikel.
2004.
On the parameter spaceof generative lexicalized statistical parsing models.University of Pennsylvania, Philadelphia, PA, USA.Supervisor-Marcus, Mitchell P.Z.
Chen and H. Ji.
2009.
Can one language bootstrapthe other: A case study of event extraction.
In Pro-ceedings of NAACL?09.M.
Collins.
1999.
Head-Driven Statistical Models forNat- ural Language Parsing.
University of Pennsyl-vania, Philadelphia, PA, USA.Mona Diab and Philip Resnik.
2002.
An unsuper-vised method for word sense tagging using parallelcorpora.
In Proceedings of 40th Annual Meetingof the Association for Computational Linguistics,pages 255?262, Philadelphia, Pennsylvania, USA,July.
Association for Computational Linguistics.M.
Diab, K. Hacioglu, and D. Jurafsky, 2007.
ArabicComputational Morphology: Knowledge-based andEmpirical Methods, chapter 9.
Springer.Mona Diab.
2004.
Bootstrapping a wordnet taxonomyfor arabic.
In Proceedings of First Arabic LanguageTechnology Conference (NEMLAR), Cairo Egypt,.N.
Habash and O. Rambow.
2005.
Arabic Tok-enization, Part-of-Speech Tagging and Morpholog-ical Disambiguation in One Fell Swoop.
In Proc.of the 43rd Annual Meeting of the Association forComputational Linguistics (ACL?05), pages 573?580, Ann Arbor, Michigan, June.
Association forComputational Linguistics.R.
Hwa, P. Resnik, and A. Weinberg.
2002.
Break-ing the resource bottleneck for multilingual parsing.In In Proceedings of the Workshop on LinguisticKnowledge Acquisition and Representation: Boot-strapping Annotated Language Data.D.
Nadeau and S. Sekine.
2007.
A Survey of NamedEntity Recognition and Classification.
LinguisticaeInvestigationes, 30(7).H.-T. Ng, B. Wang, and Y.-S. Chan.
2003.
Exploit-ing parallel texts for word sense disambiguation: Anempirical study.
In ACL?03, pages 455?462, Sap-poro, Japan.P.
Thompson and C. Dozier.
1997.
Name Searchingand Information Retrieval.
In In Proc.
of SecondConference on Empirical Methods in Natural Lan-guage Processing, Providence, Rhode Island.I.
Zitouni and R. Florian.
2008.
Mention detectioncrossing the language barrier.
In Proceedings ofEMNLP?08, Honolulu, Hawaii, October.Imed Zitouni and Radu Florian.
2009.
Cross languageinformation propagation for arabic mention detec-tion.
Journal of ACM Transactions on Asian Lan-guage Information Processing, December.285
