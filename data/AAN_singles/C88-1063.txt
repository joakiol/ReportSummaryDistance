An Exper imenta l  Parser  for  Sys temic  GrammarsRobert T. KASPERUSC/information Sciences Institute4676 Admiralty Way, Suite 1001Marina del Rey, CA 90292 U.S.A.AbstractWe descrlbe a general parsing method for systemic gram-mars.
Systemic grammars contain a paradigmatic analysis oflanguage in addition to structural information, so a parsermust assign a set of  grammatical features and functions toeach constituent in addition to producing a constituent s ruc-ture.
Our method constructs a parser by compiling systemicgrammars into the notation of Functional Unification Gram-mar.
The existing methods for parsing with unification gram-mars hace been extended to  handle a fuller range of paradig-matic descriptions.
In particular, the PATR-II system has beenextended by using disjunctive and conditional information infunctional descriptions that are attached to phrase structurerules.
The method has been tested with a large grammar of En-glish w:hich was originally developed for text generation.
Thistesting is the basis for some observations about the bidirec-tional m~e of  a grammar.1 IntroductionMany computational linguists have found systemic grammar (SG)to be quite useful, because it provides an explicit representation offeatures that determine how a sentence functions in the context ofcommunication.
SG has been used directly as the basis for severalcomputer tex~ generation programs \[Mann 82\], but it has only beenused indirectly for computational parsers.
Winograd used principlesfrom SG in designing SHRDLU \[Winograd 72\], a successful naturallanguage understanding program, but his program did not containan explicit representation of the grammar's system network.
Instead,he used a special purpose programming language to encode gram-matical knowledge in a procedural form tailored specifically to thelanguage understanding task.
Another procedural implementation ofSG was developed by McCord \[McCord 77\].
Both of these methodswould require a significant progranmfing step before a parser couldbe produced for a different grammar.
Our goal has been to developa general parsing method using a declarative representation of SG,and to determine to what extent a grammar that is adequate fortext generation can also be used for text analysis.
Our parser hasbeen developed and tested using Nigel \[Mann 83\], a large grammarof English that has previously been used as part of a text generationsystem.Systemic l;nguistics builds on the foundation of Hailiday's con..cept of the system Setwork \[Halliday 76\].
A systemic grammar isorganized around choices between grammatical features that reflectthe structure and content of aconstituent.
Each choice between fea-tures is called a system.
Thus, a systemic grammar has two majorcomponents:I. a system network of feature choices, and2.
structurM realization statements corresponding to each feature.The feature Choices define the options available to be expressed inRANK-Clause ~-...MOODTYPEa language, and may be regarded as "hooks" into a semanticcomponent.
The realization statements determine the constituentstructure.
There are realization statements o declare the presenceof constituents, conflate constituents, pecify feature constraints onconstituents, and specify ordering constraints among constituents.Consider, for example, the fragment of a grammar of Englishclauses shown in Figure 1.
There are two systems, labeled byMood-type and Indicative-type.
Each system has an input conditionto its left, specifying when its options are applicable.
The input con-dition for Indicative-type is the single feature, Indicative, but inputconditions may also be expressed by boolean combinations of fea-tures.
In each system, exactly one of the features to the right of thevertical bar must be chosen.
For example, in the Indicative-type sys-tem, either Declarative or Interrogative must be chosen.
Under eachfeature are realization statements, such as SUBJECT A FINITE un-der the Declarative feature.
This statement specifies that the SUB-JECT constituent must precede the FINITE constituent in declara-tive clauses.
Each realization statement is associated with a particu-lar feature, so that structural constraints are distributed throughoutthe system network.
The distributed nature of structural informa-tion in SG presents a challenge to the design of a parser, which wewill address in Section 3.In addition to building a constituent structure for a sentence, asdo most syntactic approaches to natural anguage parsing, a parserfor SO must also perform the following tasks:1. determine the set of systemic features for each constituent,2.
assign grammatical functions to each constituent.Other theories of grammar also make use of features and grammat-ical functions, however they have a distinct significance in systemictheory.
The feature set associated with a constituent plays an impor-tant role in specifying its meaning (i.e., the features are not simplydiscarded after syntactic analysis), so a relatively I~,rge number (e.g.,over 50) of features may need to be assigned to eac!, constituent.Each constituent may also be assigned to several grammatical func-tions, because of the multifunctional nature of systemic analysis.
Forexample, it is common to describe a single constituent simultaneouslyas SUBJECT, ACTOR and TOPIC.
Therefore, in order to determinethat a clause has an ACTOR, it may be necessary to check whetherthe clause has a SUBJECT and whether the SUBJECT of the clauseis conflatable with the.
ACTOR function.An example of the type of output produced by the parser is shownin Figure 2.
This example shows only the functional structure thatthe parser assigns to the sentence.
In addition, each constituentis assigned a set of grammatical features, such as Indicative andDeclarative.
These features are also accessible in the data structuresproduced by the parser, but they are too numerous to display in thisshort paper.t-ImperativeNONFINITIVE~Stem~ -Declaratlve SUBJECT A FINITE -Indicative- INDICAT IVE  TYPESUBJECT:Nominatlve-InterrogativeFigure I: The  Mood- type  and Indicative-type Systems.309/TOPICAL / SUBJECT / MEDIUM GOAL 7 ,./,DEICTIC-- --thlsdet/ ~".THING-- --document//TEMPO0 / VOICE I FINITE-~-~ --b~.~uxII, PROCESS / LEXVERB / VOICEDEPENDENT---v --crQate--/eFD-- ~""'AGENT / ACTOR-- .-(-'wAGE-'-/ - - r ,  sw~,' .,SUBJECT / J / <"ON'TE/ / /  /~PREDIOATOR-- ../VOIOEI /"'.
LEXVERBFigure 2: Functional Structure of: "This document was created bya new computer.
"2 CompUatlon into Functional Unif icat ionGrammarThe basic method used to construct the parser has been to developa compiled representation f systemic grammars in the notation ofFunctional Unification Grammar (FUG).
The parsing process itselfis then derived by extending methods already developed for pars-ing With FUG \[Kay 85\].
In FUG, a grammar can be regarded as aspecial kind of logical formula \[Rounds 87\], and the parsing prob-lem is reduced to finding the set of feature structures that satisfythe formula subject o the constraints of the words in a particularsentence.
Using the feature description logic (FDL) of Kasper andRounds \[Kasper 86\], the types of formula used to define a grammarinclude: 1NIL denoting no i~formatloa;a where a E A, to describe atomic values;l : ~b where I E L and ~ E FDL~ to describe structuresin which the feature labeled by l has a value described by ~;ql or l : ANY where l E L, to describe asliructure in which I hasa substantive (non-NIL I value;< p > where p E L*, to describe a structure that sharesa common value with the path p;\[~bl ... ~ \ ]  where ~b~ E FDL, denoting conjunction;{~bl ... ~b,~} where ~b~ E FDL, denoting disjunction;~1 --* ~ where ~b~ E FDL, denoting classical implication.The last type of formula, denoting implication, is an extension toFUG that enables a more efficient modeling of systemic descriptionsthan is possible in Kay's version of FUG IKasper 87d\].The compilation of systems into FUG is relatively straightfor-ward.
Each system is represented by a disjunction containing alter.natives for each feature that can be chosen in the system.
These al-ternatives also contain attributes that represent constraints on gram-matical functions imposed by realization statements.
For example,the Mood-type and Indicative-type systems can be represented bythe description shown in Figure 3.
System input conditions are bidi-rectional: they are represented by the embedding of descriptions,and also by feature xistence conditions.In the FUG representation there is one functional description(FD) corresponding to each m~ior constituent category of the sys-temic grammar.
Major constituent categories for English includeclause, nominal-group, and prepositional-phrase.
The method of rep-resenting a systemic grammar as a set of FDs in FUG is described ingreater detail in \[Kasper 87b,Kasper 87d\].
A program has been im-plemented to automatically translate any system network into FDs,verifying the effectiveness and generality of this compilation proce-dure.
This program has been used to compile the entire Nigel gram-mar, which contains over 500 systems, into FUG many different timesas changes to the grammar have been made.
:Let A and L be sets of symbols used to denote atomic valueJ and featurelabels, respectively.Rank : ClauseMood-type : ImperativeNONFINITIVE : \[ Form : Stem \] 1Mood-type : IndicativeSUBJECT : \[ Case : Nominative \]pattern : (.
,.
SUBJECT FINITE ...)\[ Indlcatlve-type : Interrogative \]3 M-cod-type ----* \[ Rank : Clause \]3 Indicative-type ~ \[ Mood-type : Indicative \]Figure 3: The Mood-type and Indicative-type Systems in ex-tended-FUG notation.3 Parser Implementation:Extending PATR-IIOur early experiments using the Nigel grammar showed that theexisting methods for parsing with FUG had several shortcomingswhen applied to a large grammar.
Kay's method for parsing withFUG \[Kay 85\] cannot be applied directly to our grammar because itrequires:1. expanding the grammar FD to disjunctive normal form (DNF);2. creating a disjunct for each possible ordered combination ofconstituents hat is compatible with pattern features.
Each ofthese dlsjunets can be regarded as equivalent to an annotatedphrase structure rule.In bath cases our grammar contains too many alternatives to carryout the procedure:1.
Our grammar of English clauses contains over 100 systems.Since each system is represented by a disjunction in PUG, theDNF expansion of the clause grammar might require over 2100disjunetsl2.
Our grammar contains many optional grammatical functions.A particularly striking example concerns the large number ofoptional adjunct ypes that may be used to modify an Englishclause.
2 These adjuncts occur most frequently at the endof the clause, although other orders are possible.
Assumingthat there are at least 10 optional adjunct ypes, "we have 2 l?different combinations ofadjuncts, not counting any additionalcombinations resulting from order variation.The first problem has been solved by a new unification algorithm fordisjunctive descriptions that does not require expansionto DNF \[Kasper 87c\].
The second problem has been solved by addinga small phrase structure component to the grammar and using thePATR-II active chart parsing algorithm, which was developed byShieber et alat SRI \[Shieber 84\].3.1 Ske le ta l  Phrase  S t ructure  ComponentThe role of phrase structure (PS) rules in our parser is similar totheir role in Lexical Functional Grammar \[Kaplan 83\], however theyhave less theoretical significance in our parser, We use the PS com-ponent o recognize possible patterns for each major constituent cat-egory, but the unification component builds the functional structureand assigns a feature set to each constituent.
The PS component issomething like a skeleton that  cannot be seen in the final descril~.t ions produced by the p~ser.
Not very many PS rules are required,because they only need to encode broad category distinctions.
Finecategory distinctions are encoded by the FDs that are attached torules.
Each major constituent category of the grammar has a specialrule that is annotated with the FD produced by compilation fromthe systemic grammar for that category.
For example, the categoryCLAUSE has a rule of the form:=A partlal ilt of adjunct ypes lnclude~: MANNF_~ CAUSE, ACCOMPA-NIMENT, SPACE-LOCATIVE, SPACE-EXTENT, TIMF~LOCATIVE, TIME-EXTENT, MATTER, ROLE, ATTITUDE.310CLAUSE --~ CLAUSE~PS:<CLAUSE> = <OLAUSF_,-PS fd><CLAUSE> = \[ compiled FD for CLAUSE \].CLAUSF~PS is a non-tarminal that can derive any valid constituentpattern for cl~.uscs.
The first unification of this rule identifies any fea-tures that are known from the constituents derived by CLAUSF~'PSwith features of the CLAUSE nonterminaL The second unificationprovides the functional description that must be satisfied for anyclause.Consider again the problem of optional adjuncts.
Instead of pro-ducing a distinct disj'unct for each combination of adjuncts, it is muchmore efficient o describe all possible combinations using a single re-cursive PS rule.
This rule is annotated with a disjunctive descriptionthat contains a single alternative for each adjunct ype:CLAUSE-PS~ --* CLAUSE-PS2 ADJUNCT:<CLAUSE-PS-I> = { \[ MANNER : <ADJUNCT> 1\[ CAUSE : <ADJUNCT>\].
.
.
other alternatives }.The PS component is the only part of the grammar used by thePATR-II parser that is not produced automatically from a systemicgrammar.
The pars!ng grammar for Nigel currently contains about6D PS rules.3 .2 Extens ions  to  PATR-HThe PATR-II system has been extended in several significant waysto carry out c~ur implementation:1. handling disjunctive andconditional descriptions \[Kasper 87c,Kasper 87d\];2. using t~bles compiled from the realization statements of SG.These tables include the possible confiations for each gram-matical function, and lexical items that are associated withparticular features in the grammar.The compiled tables and skeletal phrase structure component enablethe parser to directly deduce structural information about a sentence,despite the distributed nature of structural constraints in SG.grammar that require an inordinate amount of time to resolve.
Sys-temic grammars can exhibit ambiguity between grammatical fea-tures, in addition to the well known types of lexieal and structuralambiguity.Unintended ambiguities between grammatical features often arisefrom underspecified parts of the grammar, i.e., the grammar containsan alternation between two or more features with insufficient realiza-tion information to determine which features apply in many eases.Usually the solution to this problem is to add realization informationfor those features.
Sometimes the realization of those features maydepend on other features and the modification is somewhat complex.In such cases, it is possible to temporarily disable the underspeeifiadalternatives while parsing until a more complete solution is devel-oped.Some features may have realizations that are formally adequateand efficient for generation, but quite inefficient for parsing.
For ex-ample, the Nigel grammar for nominal groups contains the Pronomi-nal feature to indicate that the head constituent is a pronoun.
Thereis no explicit realization statement associated with this feature, butthe system network contains more specific features for each of type ofpronoun.
These more specific features have realizations that specifyparticular lexical items for the head constituent.
Since English pro-nouns are a closed class, there is a finite number of features that needto be examined to determine whether a nominal group is pronominal.However, it is quite inefficient o consider each member of the classindividually.
Obviously, we can improve the parsing efficiency of thegrammar by adding a realization to the Pronominal feature that con-strains the head to be a member of the class of pronouns.
We havefound a significant number of similar cases, where the grammar wasadequate for generation, but was missing some useful generalizationfor analysis.It seems reasonable to expect hat most grammars that are orig-inally developed specifically for generation or parsing tasks will needsimilar kinds of tuning before they can be used effectively for theinverse task.
A bidirectional grammar seems to be a reachable goal,but it will probably have some specifications that are superfluous foreither parsing or generation.
These specifications can be marked ifnecessary for efficiency, so that the parser or generator does not haveto examine unnecessary information.5 Conc lus ions4 Bid i rect ional  GrammarBidirectional grammar, i.e.
using the same grammatical knowledgetbr both parsing and generation of a language, has been a real butsometimes elusive goal in computational linguistics.
The goal of bidi-rectional grantmar was clearly a motivation for Kay's formulation ofFUG \[Kay 85 I. Kay has shown that if a declarative representationis used to encode the grammatical knowledge of a language, then itshould be possible to compile that knowledge into appropriate datastructures for parsing or generation.
We have followed this method inconstructing ~ parser for systemic grammars by compiling the gram-mar into a notation like FUG.
Our discussion in this section tbcuscson other issues besides compilation that have been identified in oureffort to dew.
'lop a bidirectional systemic grammar.Our experience with the Nigel grammar has indicated that itis possible to develop a bidirectional grammar within the systemie-functional framework, although a substantial amount of effort maybe required to tune the grammar for both parsing and generation.In other wordsj the framework of systemic grammars is potentiallyinvertible, bui; particular grammars may require some modificationbefore they cun be used effectively for both parsing and generation.Generally, parsing places greater demands on the realization com-ponent of the grammar, while generation places greater demands onthe systems of choice.
The Nigel grammar was originally developedfor use ins  text generation program, so our observations deal mostlywith problenm that can arise when inverting a grammar that is ade-quate for gem~ration but untested for analysis.Most pnodifications that we have made to enable parsing involveeliminating u~dntended ambiguities or disjunctive alternatives in theWe have developed a general method for parsing systemic grammarsby extending the techniques of FUG and the PATR-II system.
Theparser is reasonably efficient for grammar testing and use as a lin-guistic research tool, but further refinement would be necessary forapplications demanding real-time performance.
Using the full Nigclgrammar, it currently requires less than a minute to parse simplesingle-clause sentences, and several minutes to parse more complexsentences.
It should be noted that parsing speed depends heavilyon grammar size, and we are using a graznmar that is significantlylarger than most grammars that have been implemented to this datewith unification-based methods.We have only investigated an exhaustive bottom-up strategy, inwhich the parser produces all possible parses for a sentence.
ThisStrategy is well-suited to g ramm~ testing, but other strategies shouldbe developed for applications demanding more selectivity and effi-ciency.
We have not yet attempted to incorporate xtra-grammatical(i.e., semantic and pragmatic) information for ambiguity resolution,but this would also be necessary for most practical applications.It would be very desirable to discover a way to produce the phrasestructure component of the parsing grammar, or some functionallyequivalent mechanism, automatically from a systemic description.If accomplished, this would make it possible to fully automate theproduction of a parsing grammar, but this appears to be a difficultproblem.
It is currently much easier to 15reduce a small phrase struc-ture component manually from one's knowledge of the grammar.AcknowledgementsI would like to thank Bill Mann for originally suggesting and eneouroaging this topic of research.
I would also like to thank Christian311Matthiessen, Martin Kay, Lanri Karttunen, John Bateman and BillRounds for helpful comments on the design of the parser, and StuartShieber for providing help in the use of the PATR-II system.This research was sponsored in part by the United States AirForce Office of Scientific Research contract F49620-87-C-0005, andin part by the United States Defense Advanced Research ProjectsAgency under contract MDAY03-81-C-0335; the opinions expressedhere are solely those of the author.References\[Kaplan 83\]\[Kasper 87a\]\[Kasper 87b1\[Kasper 87c\]\[Kasper 87d\]\[Kasper 86\]Kaplan, R. andJ.
Bresnan.
Lexical Functional Gram-mar: A Formal System for Grammatical Represen-tation.
In J. Bresnan, editor, The Mental Represen-tation of Grammatical Relations.
MIT Press, Cam-bridge, Massachusetts, 1983.Kasper, R. Feature Structures: A Logical Theory withApplication to Language Analysis.
PhD dissertation,University of Michigan, 1987.Kasper, R. Systemic Grammar and Functional Unifi-cation Grammar.
In J. Benson and W. Greaves, ed-itors, Systemic Functional Approaches to Discourse,Norwood, New Jersey: Ablex (in press).
Also avail-able as USC/Information Sciences Institute ReprintRS-87-179.Kasper, R. A Unification Method for Disjunctive Fea-ture Descriptions.
In Proceedings of the 25 ~h AnnualMeeting of the Association for Computational Lin-guistics, Stanford University, Stanford, CA, July 6-9,1987.
Also available as USC/Information Sciences In-stitute Reprint RS-87-187.Kasper, R. Conditional Descriptions in FunctionalUnification Grammar.
USC/Information.Scienees In-stitute Research Report RR-87-191, November, 1987.Kasper, ~.
and W. Reuncls.
A Logical Semantics forFeature Structures.
In Proceedings ofthe 24 ~h AnnualMeeting of the Association for Computational Lin-guistics, Columbia University, New York, NY, JuneI0-13, 1986.\[Kay 85\]\[Halliday 76\]\[Mann 82\]\[Mann 83\]\[McOord 77\]\[Rounds 87\]\[Shieber 84\]\[Winograd 72\]Kay, M. Parsing in Functional Unification Grammar.In D. Dowry, L. Karttunen, and A. Zwicky, edi-tors, Natural Language Parsing.
Cambridge Univer-sity Press, Cambridge, England, 1985.G.R.
Kress, editor.
Halliday: System and Functionin Language.
Oxford University Press, London, Eng-land, 1976.Mann, W.C.
Text Generation.
Section of AppliedComputational Linguistics in Perspective: Proceed-ings of the Workshop, In American Journal of Com-putational Linguistics, Vol.
8:2, 1982.Mann, W.C. mad C. Matthisssen.
Nigeh A Sys-temic Grammar for Text Generation.
USC / Infor-mation Sciences Institute, RR-83-105.
Also appearsin R. Bunsen and J. Greaves, editors, Systemic Per-spectives on Discourse: Selected Papers Papers fromthe Ninth International Systemics Workshop, Ablex,London, England, 1985.McCord, Michael C. Procedural systemic grammars.In International Journal of Man-Machine Studies,Vol.
9, pp.
255-286, 1977.Rounds, W. C. and Manaster-Reaner, A.
A LogicalVersion of Functional Unification Grammar.
In Pro-ceedings of the 25 th Annual Meeting of the Associa.tion for Computational Linguistics, Stanford Univer-sity, Stanford, CA, July 6-9, 1987.Shieber, S. M. The design of a computer languagefor linguistic information.
In Proceedings ofthe TenthInternational Conference on Computational Linguis-tics: COLING 8.~, Stanford University, Stanford,California, July 2-7, 1984.Winograd, T. Understanding Natural Language, NewYork: Academics Press, 1972.312
