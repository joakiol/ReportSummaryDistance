Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 494?503,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsDialogue focus tracking for zero pronoun resolutionSudha Rao1,3, Allyson Ettinger2, Hal Daum?e III1,3, Philip Resnik2,31Computer Science,2Linguistics,3UMIACSUniversity of Marylandraosudha@cs.umd.edu, aetting@umd.edu, hal@cs.umd.edu, resnik@umd.eduAbstractWe take a novel approach to zero pronoun res-olution in Chinese: our model explicitly tracksthe flow of focus in a discourse.
Our approach,which generalizes to deictic references, is notreliant on the presence of overt noun phraseantecedents to resolve to, and allows us to ad-dress the large percentage of ?non-anaphoric?pronouns filtered out in other approaches.We furthermore train our model using read-ily available parallel Chinese/English corpora,allowing for training without hand-annotateddata.
Our results demonstrate improvementson two test sets, as well as the usefulness oflinguistically motivated features.1 Introduction?Pro-drop?
languages like Chinese, Japanese andTurkish allow for dropping of pronouns when thereferents of those pronouns can be inferred.
Englishis typically not pro-drop, but is unusual in that re-gard: two thirds of languages documented in WALS(Haspelmath et al, 2005) can be categorized as pro-drop.
In such languages, sentences are frequentlycharacterized by ?zero pronouns?
: gaps in the sen-tence which in English would hold an overt pro-noun.
In some languages, verbal morphology or cl-itics elsewhere in the sentence are sufficient to re-solve the ambiguity of dropped pronouns; in otherlanguages, there is no overt marking at all in the sen-tence and the referent of the dropped pronoun mustbe resolved using pragmatic information.Our work departs from mainstream work on zeropronoun resolution in that we focus primarily onthe resolution of deictic zero pronouns.
Unlike anFigure 1: A conversation between a student and a teacher.The text has been translated from Mandarin, but zeropronouns are retained and indexed with their referent:(T)eacher or (S)tudent.anaphoric zero pronoun (Section 2), whose refer-ence must be specified by a noun phrase occurringpreviously in the text, a non-anaphoric zero pro-noun refers to an entity that is salient from largerunits of discourse (such as full sentences or pas-sages) or from the extralinguistic environment (out-side of the text altogether).
Although anaphoric zeropronoun resolution has been the focus of most pastwork (Yeh and Chen, 2007; Chen and Ng, 2014),50% or fewer of zero pronouns in natural Chinesetext are anaphoric (Zhao and Ng, 2007; Kong andZhou, 2010).
Our approach allows for generaliza-tion to non-anaphoric pronouns, focusing in partic-ular on deictic non-anaphoric zero pronouns, which494refer to salient entities in the environment (such asthe speaker, hearer or pragmatically accessible ref-erent) without requiring any introduction in the pre-ceding text.
Figure 1 shows an example conversa-tion in which zero pronouns are frequently used torefer to speaker or listener, and would be translatedto English as ?I?
or ?you.
?We propose a model for resolving deictic zeropronouns that draws inspiration from ideas in Cen-tering Theory (Grosz et al, 1995): discourses tend tosettle on a particular focus for a time, before switch-ing.
Furthermore, we presume that when a switchhappens, there is likely to be an overt cue of this.For example, in Figure 1, the initial focus on T issignaled with the overt second person pronoun in thefirst utterance; the switch of focus to S in the thirdutterance is also signaled by an overt ?you.?
How-ever, at that point, the focus remains on S for severalutterances until ?The last round.
.
.
?
at which point itswitches away from the speakers.
It is brought backto S in the last utterance, which can be inferred fromthe fact that S is the most recent focus that fits therequired semantic constraints.To account for these phenomena, we develop anovel sequential model for zero pronoun resolu-tion that explicitly tracks the conversation focusin a dialogue (Section 3).
We test, using data fromChinese SMS (?texting?)
dialogues, the hypothesisthat our model can predict the identity of pronouns(at a granularity of the person attribute: first, second,or third person?with particular focus on first andsecond person) based on a variety of features of theutterance context, without reference to a particularantecedent (Section 4.3).
In this way, we address amuch higher percentage of the zero pronouns foundin Chinese texts, and particularly in dialogue.Our second contribution is to show that one cantrain a zero pronoun resolution system using su-pervision coming from English translations of theChinese text (Section 2.2).
This obviates the needfor expensive linguistic annotation of Chinese andallows us to use plentiful parallel data to train ourmodel.
Our results confirm that even though this?translation as annotation?
process is noisy, it is stillpossible to learn on large amounts of ?bronze stan-dard?
data.2 Linguistic motivationHandling zero pronouns in Chinese (or other pro-drop language) involves two separate tasks: (1) Zeropronoun identification: locating and marking thegaps corresponding to zero pronouns; and (2) Zeropronoun resolution: determining the entity referredto by the zero pronoun.
Our focus is the latter task.Zero pronoun resolution, like general pronounresolution, is almost universally approached as aproblem of linking a pronoun to an overt nounphrase antecedent in the text.
However, whilesome zero pronouns do have overt noun phrase an-tecedents, many other zero pronouns do not.
Infact, (Zhao and Ng, 2007) report that just 52% ofzero pronouns in their training set (and 46% of zeropronouns in their test set) are ?anaphoric.?
Kongand Zhou (Kong and Zhou, 2010) report just 41%.Some zero pronouns fail to link to an antecedentbecause they refer to facts or events described bylarger phrases or full sentences earlier in the text,preventing coreference with a single noun phrase.Other zero pronouns, particularly in dialogue set-tings, are deictic, pointing to salient entities in theenvironment without requiring introduction by anovert mention in the text.2.1 Dialogue focusA central principle of document cohesion that under-lies frameworks such as Centering Theory (Grosz etal., 1995) states that discourses tend to settle on aparticular focus for a time, before eventually switch-ing to a new one.
The status of a particular focuswithin this flow of discourse is typically signaledby the form of the expression chosen to point to it.When a focus is introduced (or returned to), a full(overt) noun phrase is generally used to indicate it.While that entity remains in focus, subsequent men-tions can be realized with less explicit forms.
In En-glish, these less explicit forms are overt pronouns.
InChinese (and pro-drop languages more generally),these focus continuations are generally realized aszero pronouns.We see in this example an illustration of these dis-course principles:1.
In pro-drop languages (Chinese), overt pro-nouns introduce switches in focus, while zero495pronouns are used while an established focuscontinues.2.
In non-pro-drop languages (English), overt pro-nouns serve the focus-continuation function.3.
There are ?deictic?
exceptions to these rules,licensed by environmental salience of the ref-erent and inferable from the meaning of the ut-terance (final question of the example).Importantly, these continuations and switches offoci occur for the most part at the level of the syntac-tic clause.
This is thus the level at which we model,assigning labels to individual clauses, which will inturn indicate the identity of any dropped subject pro-noun in that clause.1In identifying focus, we remainat the granularity of the ?person?
attribute (first, sec-ond, or third person).
This is the most relevant gran-ularity for deictic pronoun resolution, as the intentis to capture the alternation between speakers withinthat dialogue (first and second person), along withswitches of focus to any referents external to the di-alogue (third person).2.2 Translation as annotationCurrently, most state-of-the-art machine learningsystems for Chinese zero pronoun resolution aresupervised, requiring manually resolved pronounsfor training.
We hypothesize comparable distri-bution between zero pronouns in a pro-drop lan-guage, and overt pronouns in a non-pro-drop lan-guage.
More specifically, because non-pro-drop lan-guages lack zero pronouns, the discourse functionsthat are served by zero pronouns in pro-drop lan-guages must in non-pro-drop languages be served byovert pronouns.To be more concrete, the original Mandarin SMSconversation from Figure 1 is reproduced in Table 1,together with a human translation into English.
In-deed, we see in the example in Figure 1 that thezero pronouns on the Chinese side correspond toovert pronouns on the English side.
For this rea-1Although Mandarin does license dropped object pronouns,we focus in this paper only on subject pronouns, as the syntac-tic subject is (a) more consistently dropped in Mandarin, and(b) more tightly tied to the notion of focus of conversation thatmotivates our model; see also a discussion of the centering hi-erarchy in Chinese (Wang, 2011).
Relatedly, we filter out pos-sessive pronouns in subject position, as they do not point to thetopical entity represented by the full noun phrase.son we make use of a parallel (Chinese/English) cor-pus for training of our sequence labeling model, de-riving the identities of missing pronouns from theEnglish translation of the Chinese text rather thanfrom coreference relations with antecedents in theChinese text.
Our model thus does not rely on theavailability of hand-annotated data for training.3 Our focus tracking modelGiven a Chinese dialogue, our goal is to identifyzero pronouns and resolve them either as deictic(first or second person) or non-deictic (third person).We use off-the-shelf tools for the identification ofthe zero pronouns (described in Section 4.1) and fo-cus on the resolution task.In our implementation, we jointly predict the fo-cus and identify the number of the pronoun thatwould be used.
For instance, when S is speakingabout herself, we consider this a ?1?
label; when Sis speaking about her conversation partner, we con-sider this a ?2?
label.
This numbering correspondsto which pronominal form would be required in En-glish.23.1 Supervision via bronze standard dataWe obtain ?bronze?
standard (as opposed to ?gold?standard) data by looking at human-produced En-glish translations of Chinese utterances, such asthose seen in Table 1.
Our label set consists of twoproperties: the person being referred to (first person,second person or third person), and whether the ref-erence is overt or not (visible or hidden).
The ?vis-ible?
three labels correspond to clauses in which anovert subject pronoun appears on the English side.Chinese clauses bearing this label may have an overtor a zero pronoun subject?if the Chinese side con-tains a zero pronoun subject, then this label will beused to determine the correct person attribute (first,second, or third) of the unseen pronoun.1v: Overt English first person pronoun: ?I?
or ?we?2v: Overt English second person pronoun: ?you?3v: Overt English third person pronoun: ?he?,?she?, ?it?, ?they?2We ignore morphological issues in English dealing withpossession and grammatical role, since these are exogenous tothe resolution task.496Original Mandarin English Translation Label1) Student??????
?How are you, Teacher Chen?
2v2) Teacher???
,????
?I am fine.
You have not left yet?
1v, 2v3) Student????????
???
?I have been back for a month.
1v, 1vI didn?t dare to chat with you.4) Student?
?Not yet.
1h5) Student?????????
4 ?
?I have gone through 4 rounds of interviews for theAmerican (company).1v6) Teacher???Why?
2h7) Student???????
?The last round of interview is with the general manager.
3v8) Student???????
?There are also two online tests.
3h9) Teacher???????
?Are you still in the interview phase?
2vTable 1: Sample Chinese SMS conversation with English translation and derived labels.However, there are plenty of utterances (e.g., Ta-ble 1 lines 4 and 6) in which the English transla-tion does not contain an overt subject.
This can hap-pen in English in imperative constructions, (some)questions, and general informal communication.3Inthese cases, we introduce ?hidden?
person labelswhose role is to carry forward the focus from theprevious utterance.
For instance, in utterance 4, eventhough there is no subject on the English side, wecarry forward the fact that the most-recent referentwas ?first person?
and denote this with ?1h.
?Because we are jointly modeling the focus shiftand the pronoun realization aspects, when thespeaker shifts, the ?hidden?
person must flip.
Forexample, in utterance (5) the Student overtly refersto herself, yielding a label of ?1v.?
The next utter-ance is by the Teacher but lacks an English subject.The focus remains on the Student and therefore thisutterance is labeled ?2h?
meaning that the focus ison the other speaker, and it is non-overt in English.1h: subject being continued is first person2h: subject being continued is second person3h: subject being continued is anything elseFinally, we introduced a seventh label for instancesin which no overt subject pronoun appears on theEnglish side, and no focus has yet been establishedfrom prior clauses (this applies only at the beginningof a discourse).None: no subject and no focus yet established3This can also happen due to imperfect zero pronoun identi-fication (Section 4.1).In Table 1, the rightmost column shows the label as-signment for the sample SMS exchange.
(The utter-ances on lines 2 and 3 contain two clauses each, andthus two labels each.
)3.2 FeaturesWe included in our model the following features.Note that these features are based solely on the Chi-nese side.
Linguistic motivations for each featurecategory are described.Subject continuation: a value indicating the per-son (1, 2, 3) of the most recent overt NP that wasa direct descendent of an IP node (the most recentovert NP in structural subject position?including,if overt, the subject of the current clause).
The mostrecent overt NP subject is a strong candidate forcoreference with a zero pronoun.
This feature comesclosest to attempting antecedent selection.Verb: the first verb in the VP that is sister to thesubject NP (the VP of which that NP is the subject).The nature of the verb can provide information rel-evant to inferring the identity of deictic forms.
Forexample: the Chinese verb guji (?reckon?)
is intu-itively biased toward first-person subject; our train-ing data accordingly show 68% of clauses with gujias verb feature were assigned first-person subject la-bels.Participant index: a value indicating the index ofthe conversational participant.
To capture regular-ities, if any exist, in the pronoun use of a speaker.Participant switch: a binary value indicatingwhether the current utterance represents a change ofspeaker relative to the previous clause.
Switches in497speaker may, particularly in tandem with other fea-tures, be informative about topic.Object (downstream): the direct object of the VPsister to the subject (if any).
This feature exploits thefact that pronouns occurring as direct objects withina clause cannot be the same as the (zero) pronoun insubject position of that clause.Has question particle: a binary value indicatingwhether the clause contains a) a question particleor wh-word, or b) a question mark.
This feature islikely to be a strong indicator of that the subject pro-noun is not first person (also used by (Chen and Ng,2013)).
For example, in our training data we foundthat only 16% of the clauses with question particlewere marked with first person label i.e.
1v or 1h.Bag of words: all words occurring in the clause.Apart from the verb, other words can also be highlyinformative about the nature of the subject.Bag of parts of speech: all parts of speech occur-ring in the clause.
The structural make-up of clausemay be informative about focus, for instance in thecase of passive or possessive constructions.Hidden subject particles: a feature indicatingwhether the clause consists of a list of phrases con-sistently tagged with empty categories on the Chi-nese side, but consistently translated without subjectpronouns on the English side (thus likely to corre-spond to labels 1h-3h).
This feature is intended tohelp the model in recognizing clauses consistentlycorresponding to ?hidden?
labels.In addition, for the features that consist of se-quence (bag of words, bag of part of speech, object,etc.)
we additionally compute bigrams and trigrams.3.3 Structured predictionWe cast the above model as a sequence labelingproblem over visible and hidden labels.
We considereach conversation segment in the SMS as an inputdata sequence x = ?x1, x2, .
.
.
, xn?
where each xicorresponds to a clause in Chinese.
Each clause inChinese is assigned a label from the label space Y= {1v, 2v, 3v, 1h, 2h, 3h, none}.
The task then is toassign labels y = ?y1, y2, .
.
.
, yn?
to the input datasequence from the label space Y based on the fea-tures described in Section 3.2.
At training time weassign labels to the input sequence using the ?bronzestandard?
method described in Section 3.1.To train the sequence labeling model, we use anonline variant of the DAgger imitation learning al-gorithm (Ross et al, 2011) as implemented in theVowpal Wabbit machine learning library (Langfordet al, 2007; Daum?e III et al, 2014).
DAgger, likeits predecessor SEARN (Daum?e III et al, 2009),solves structured prediction problems by transform-ing them into sequential decision making problems.In the case of sequence labeling, the natural orderfor sequence decision making is left-to-right.
At testtime, inference is performed greedily.
At trainingtime, the learning algorithm attempts to balance be-tween training on ?oracle?
states (prefixes of deci-sions made optimally according to the true labels)and training on ?system?
states (prefixes of deci-sions made sub-optimally according to the learnedmodel).
The online variant of DAgger balances thistrade-off by slowly transitioning from making pastdecisions optimally to making them using the cur-rently learned predictor.4 ExperimentsOur goal in our experiments is to answer the follow-ing questions:1.
How well does the bronze-standard annotationcapture the underlying truth?
(Section 4.2).2.
Is our model able to leverage both dialoguestructure and semantic content to accurately re-solve pronouns?
(Section 4.3)3.
How important are the different componentsin our model in making effective predictions?
(Section 4.4)In the following sections, we describe the exper-iments we perform aimed at answering these ques-tions.
First, we describe the data we use for experi-mentation.4.1 Experimental setupFor training our focus-tracking model, we useChinese-English parallel data from the SMS/chatdomain available as part of training data used in theMachine Translation task under the DARPA BOLTproject.
The training data consisted of 117k sen-tences.
We test our model on heldout SMS/Chatdata consisting of 1152 sentences (hand-annotated,498Bronze SMS OntoNotesTraining Test Test# tokens 1, 007, 722 8104 108, 531# sents 129, 190 1152 9607# dialog 3309 34 257# types 26, 519 1747 4753Table 2: Dataset statistics; numbers are for the Chi-nese side of the data.
English has 25% more tokens androughly as many types.as described in Section 4.2), and on telephone con-versation data from the OntoNotes corpus (Hovy etal., 2006), consisting of 5000 sentences.
Full datastatistics are provided in Table 2.We perform zero pronoun identification using themethod of (Cai et al, 2011), which automatically re-covers empty categories corresponding to droppedpronouns, integrating these empty categories intosyntactic parses.
Syntactic parses were obtainedwith the Berkeley parser (Petrov and Klein, 2007).These parses were then used to split the Chinese ut-terances into single-clause units, based on IP andCP clausal nodes.
These clauses were aligned withclauses in the English translation, which were usedto determine the identity of the clausal subject, forextracting the 1v, 2v, .
.
.
label for each utterance.4For our machine learning systems, we use VowpalWabbit (Langford et al, 2007) with default hyper-parameter settings.
We train on 75% of the trainingdata and retain 25% as development data on which toperform early stopping.
We run 20 iterations by de-fault and take the parameters with best developmentperformance based on sequence labeling accuracy.4.2 Gold standard test setAlthough we can use ?bronze standard?
annota-tions for learning, evaluating against a bronze stan-dard is not directly useful.
Therefore, we annotatedour test set (1152 utterances) by hand.
In partic-ular, for the SMS/chat test set, we recruited threelinguistically-informed native Mandarin speakers toannotate Chinese clauses containing empty cate-gories.
The clauses were labeled with a person num-ber (1,2,3) when the empty category corresponded to4Sometimes English syntactic parses were not well-alignedwith the Chinese IP/CP nodes; in practice, we split the Englishutterances based on end-of-clause punctuation and aligned Chi-nese and English clauses based on a simple order heuristic.Pronoun Precision Recall F-measure1p 0.75 0.43 0.552p 0.61 0.32 0.423p 0.52 0.45 0.49Micro-avg 0.62 0.41 0.50Table 3: Bronze vs Gold labelssuch a pronoun; or ?none?
in spurious cases.5In our annotated data,632% of identified zero pro-nouns were first person, 17% were second person,25% were third person and 26% do not have a refer-ent (were spurious).
Of the correctly identified zeropronouns, a majority of pronouns (about 2/3) are de-ictic: referring either to the speaker or listener.
Theremainder are third person and mostly anaphoric.7Since the annotators labeled the empty categoriesobtained from an automatic zero pronoun identifi-cation method (Cai et al, 2011), 26% spurious casessuggest that the accuracy of this method is only 74%on the SMS test data set.We then used these annotations to evaluate ourbronze standard label assignment method against thegold standard judgments.
Table 3 shows the pre-cision, recall and F-measure of the bronze annota-tions when evaluated against the gold annotations.We use micro-averaging to average the precision, re-call and F-measure values against different sets.
Inthis method we sum up the individual true positives(TP), false positives (FP), and false negatives (FN)of the system for different sets and then apply themto get the statistics.
For example, precision acrosstwo sets 1 and 2 is given by (TP1 + TP2)/(TP1 +TP2 + FP1 + FP2).
We can see a fairly significantdiscrepancy between our bronze labels and the goldlabels.
One major?and unfortunately inevitable?reason for this discrepancy is a high proportion of ut-terances in the English translation data which have5Note that under this annotation scheme, our evaluationswill be partially constrained by (Cai et al, 2011) perfor-mance, in including no zero pronouns that were missed by thatmethod?however, use of the ?none?
label allows filtering outof any spuriously-identified zero pronouns.6Annotations are available atwww.umiacs.umd.edu/?raosudha/LDC2013E83-BOLT-P2R2-cmn-SMS-CHT-dev.annotated.7In an in-person dialogue, a third person pronoun might beused in a deictic manner, as in ?She is really smart?
while point-ing at someone.
This rarely occurs in SMS/chat because thereis no shared environment beyond the two dialogue participants.499been translated with the subject pronouns still ab-sent.
This is partially due to the casual nature of thetext, and partially because the quality (fluency) ofEnglish translations in this data is at times dubious.While there may be a systematicity to this kind ofsubject omission on the English side, this was nota factor taken into account by our human annota-tors.
So while our own model may stand a chanceat predicting ?hidden?
labels (no overt pronoun onEnglish side) in such instances, the annotators willnever assign a label of ?none?
to a location at whicha pronoun could reasonably have been inserted.4.3 Overall system efficacyIn this section we discuss the overall efficacy of ourproposed method in comparison to a few alterna-tives.
These alternatives are:Random guessing baseline.
A na?
?ve system thatmakes predictions uniformly at random.Subject continuation baseline.
This is a rule-based approach that mimics the intuitions describedin Section 2.
In particular, for a Chinese utterance,we check whether the current utterance has an overtpronominal subject.
If so, we assign a label of 1v, 2vor 3v depending on the person of this subject.
If thecurrent utterance has a non-pronominal subject, weassign 3h.
Otherwise we ?carry forward?
the sub-ject from the previous utterance, flipping the 1p/2pas necessary when the speaker changes; these are la-beled as 1h, 2h or 3h.Minimal model baseline.
In the minimal model,we restrict our model to use just three features: par-ticipant index, participant switch and subject contin-uation feature.
This is a machine learning variant ofthe rule-based subject continuation baseline.Oracle upper bound.
None of the proposed mod-els can hope to achieve 100% accuracy on this taskbecause the gold annotation data consists of 26%?no pronoun?
cases.
Since all of our approachesmust predict a pronoun when a zero pronoun hasbeen identified, their performance (namely, theirprecision) is upper-bounded away from 100%.The summary of results (micro-averaged across1p, 2p and 3p) are shown in Table 5.
These resultsshow that on both the SMS data (on which the modelwas developed) and the OntoNotes data (on whichSMS/chat OntoNotesMicro-average Micro-averageSystem Pre Rec F Pre Rec FRandom 0.24 0.25 0.24 0.18 0.26 0.22Minimal 0.42 0.23 0.30 0.30 0.07 0.11SubjCont 0.32 0.42 0.36 0.31 0.15 0.20Full Model 0.59 0.31 0.41 0.30 0.36 0.33Upper Bound 0.74 1.00 0.85 0.55 1.00 0.71Table 5: Summary of results for different comparatormodels against the gold standard labels from SMS data(left) and OntoNotes (right).the model was applied blindly), our full model isable to substantially outperform the baselines.
Infact, on OntoNotes, despite a potential domain mis-match (from SMS/chat to telephone conversations),our full model was the only baseline to beat ran-dom guessing!
Across both data sets, the minimalmodel tends to have high precision and low recall;the behavior of the other approaches varies acrossthe tasks.
On the SMS/chat data, our model achievesa 14% relative improvement over the best baseline;on an OntoNotes data, a 50% relative improvement.More specific breakdowns of performance by dif-ferent pronouns (1p, 2p and 3p) are shown for thesubject continuation baseline and the full model inTable 4.
In these tables, we also report results whenevaluated on the OntoNotes test set in these Tables.As we can see, the subject continuation baselinemassively overpredicts third person pronouns in theSMS data, leading to an overall low score.
In com-parison, our model tends to have much higher pre-cision (at the expense of recall) across the board onthe SMS data, leading to a 14% relative improve-ment over the subject continuation baseline.Since, to our knowledge, no prior work (seeSection 5) has focused on deictic pronoun restora-tion, it is not possible to directly compare our re-sults to previously published results.
Although itis an apples-to-oranges comparison, a state-of-the-art anaphoric zero pronoun resolution system (Chenand Ng, 2014) achieves a precision of 13.3, a re-call of 32.2 and an F-measure of 18.8 on the tele-phone conversation part of the OntoNotes data, butdoes so addressing the complementary problem ofcorrectly choosing antecedents from previous overtnoun phrases.Another reasonable comparison would be with a500Subject Continuation BaselineSMS Test set OntoNotes Test setPronoun Precision Recall F-measure Precision Recall F-measure1p 0.43 0.28 0.34 0.29 0.08 0.132p 0.27 0.19 0.22 0.28 0.11 0.163p 0.29 0.75 0.42 0.32 0.21 0.25Micro-avg 0.32 0.42 0.36 0.31 0.15 0.20Our Full ModelSMS Test set OntoNotes Test setPronoun Precision Recall F-measure Precision Recall F-measure1p 0.64 0.47 0.54 0.27 0.58 0.372p 0.55 0.21 0.31 0.25 0.23 0.243p 0.50 0.18 0.27 0.40 0.28 0.33Micro-avg 0.59 0.31 0.41 0.30 0.36 0.33Table 4: Results across different pronoun categories for (top) subject continuation and (bottom) our full model.SMS/chat OntoNotesMicro-average Micro-averageSystem Pre Rec F Pre Rec FMinimal (M) 0.42 0.23 0.30 0.30 0.07 0.11M + question 0.44 0.23 0.30 0.31 0.07 0.12M + object 0.43 0.23 0.30 0.30 0.07 0.12M + verb 0.58 0.29 0.39 0.32 0.13 0.18M + pos 0.52 0.30 0.38 0.23 0.27 0.25M + bow 0.59 0.28 0.38 0.30 0.35 0.32Full Model 0.59 0.31 0.41 0.30 0.36 0.33Table 6: Summary of results for feature ablationagainst the gold standard labels from SMS data (left) andOntoNotes (right).model trained on gold annotated data (instead ofbronze data).
Owing to cost, we could not obtaingold annotations for the full training set; however, aleave-one-out cross validation on the gold annotatedtest set (of SMS data) gave an F-measure of 0.47,versus 0.41 for our model trained on bronze labels.This suggests the noisy bronze labels are indeed use-ful for this task.4.4 Feature ablationsIn order to investigate the individual contributions ofeach of our features, we performed feature ablationexperiments, pairing our Minimal Model with a sin-gle feature at a time and retraining the model withthis pairing.
The results of these experiments can beseen in Table 6.
We see in this table that for the SMSdata, the Verb feature creates the greatest improve-ment over the Minimal Model, followed by Bag ofWords and Bag of POS.
This supports the hypoth-esis that the verb is informative with respect to thenature of its subject, as are the other words of theclause, and their parts of speech.
For the OntoNotescorpus, however, the Bag of Words feature performsbest by a large margin.
Interesting, although theBag of Words features are clearly the most useful,the linguistically motivated features (verb/question)performing well supports our linguistic intuitions.5 Discussion and related workPast approaches to zero pronoun resolution focus ex-clusively on anaphoric zero pronouns approached asa task of antecedent identification.
Almost all workmakes use of syntactic structure, with differencesprimarily in how that structure is used.
(Yeh andChen, 2007) take a rule-based, Centering Theory-inspired approach based on a system of constraintsto guide selection of zero pronoun antecedents.
Inthe same year, (Zhao and Ng, 2007) introduced asupervised learning approach for both zero pronounidentification and antecedent selection based on en-gineered features; these engineered features werereplaced with a tree-kernel by (Kong and Zhou,2010), who jointly perform zero pronoun identifi-cation, anaphoricity determination, and antecedentselection.
Recently, (Chen and Ng, 2013) builtupon the model introduced by Zhao and Ng, intro-ducing additional features and allowing coreferencelinks between multiple zero pronouns.
Chen andNg (2013) also test their model on automaticallyidentified zero pronouns and automatically gener-501ated parse trees, thus presenting the first end-to-endChinese zero pronoun resolver.These approaches are mostly complementary toour task, since they focus on resolving anaphoriczero pronouns (the minority!)
while we focus on re-solving deictic non-anaphoric zero pronouns.
In par-ticular, for an end-to-end system that resolves bothdeictic and anaphoric zero pronouns, one could firsttake our approach and whenever our model predicts?third person,?
which is often an anaphoric refer-ence, one could apply one of these prior approachesfor further reference resolution.The only work we are aware of that does notrequire linguistically annotated data for zero pro-noun resolution is that of (Chen and Ng, 2014).They hypothesize that zero pronouns and overt pro-nouns have similar distributions, and train an unsu-pervised model on overt pronouns and then applythis model to zero pronouns.
This model performson par with their previous (2013) supervised model.Despite this, their unsupervised model only agreeswith their supervised model on 55% of zero pronounantecedents, suggesting that this hypothesis is weak.In particular, the complementarity of zero versusovert pronoun usage has been studied within variousdomains of linguistics.
The Position of AntecedentHypothesis (Carminati, 2002) states that null andovert pronouns have different antecedent selectionpreferences: null pronouns prefer antecedents insubject positions, while overt pronouns prefer an-tecedents in non-subject positions.
This hypothesishas been supported by studies in a variety of pro-drop languages (e.g., (Alonso-Ovalle et al, 2002)(Kweon, 2011)).
Switching of reference has beenidentified as one of the main constraints regulatinguse of zero versus overt pronouns in the variationistliterature (see (Cameron, 1992) for sociolinguisticstudies of the phenomenon in Spanish).
The impor-tance of topically-coherent discourse sequences?and the role of linguistic and extralinguistic indica-tors of such sequences?has also been examined inchild language acquisition, e.g., (Rohde and Frank,2014).Our main result shows that although our bronzestandard labels are noisy (Section 4.3), they arenonetheless useful for learning to resolve deicticpronouns.
Moreover, one oft-heralded advantage ofthe translation-as-annotation scheme (Carpuat andWu, 2007) is that it naturally integrates into a ma-chine translation framework, since one is learningto predict precisely what is necessary for success-ful translation; evaluating whether this hypothesis istrue is currently an open question.
One limitation ofour approach is the coarseness of the labeling gran-ularity (1p, 2p, 3p).
Our ultimate plan is to provideall possibilities (e.g., both singular and plural for 1p,weighted) to a machine translation system, and letother components (e.g., language model) determineselection.
For now, we believe that there is signifi-cant value in intrinsic evaluation of our approach fora problem that has not previously received signifi-cant attention.AcknowledgmentsThis research was supported in part by the BOLTprogram of the Defense Advanced Research ProjectsAgency, Contract No.
HR0012-12-C-0015.
Anyopinions, findings, conclusions or recommendationsexpressed in this paper are those of the authors anddo not necessarily reflect the view of DARPA.
Theauthors would like to thank three anonymous re-viewers for providing helpful comments and also ac-knowledge people from Computational Linguisticsand Information Processing (CLIP) lab at Universityof Maryland for helpful discussions.References[Alonso-Ovalle et al2002] Luis Alonso-Ovalle, SusanaFern?andez-Solera, Lyn Frazier, and Charles Clifton.2002.
Null vs. overt pronouns and the topic-focus ar-ticulation in Spanish.
Journal of Italian Linguistics,14:151?170.
[Cai et al2011] Shu Cai, David Chiang, and Yoav Gold-berg.
2011.
Language-independent parsing withempty elements.
In Proceedings of the 49th AnnualMeeting of the Association for Computational Linguis-tics: Human Language Technologies: short papers-Volume 2, pages 212?216.
Association for Computa-tional Linguistics.
[Cameron1992] Richard Cameron.
1992.
Pronominaland null subject variation in Spanish: Constraints,dialects, and functional compensation.
Ph.D. thesis,University of Pennsylvania.
[Carminati2002] Maria Nella Carminati.
2002.
The pro-cessing of Italian subject pronouns.
Ph.D. thesis, Uni-versity of Massachusetts at Amherst.
[Carpuat and Wu2007] Marine Carpuat and Dekai Wu.5022007.
Improving statistical machine translation usingword sense disambiguation.
In In EMNLP.
[Chen and Ng2013] Chen Chen and Vincent Ng.
2013.Chinese zero pronoun resolution: Some recent ad-vances.
In Proceedings of the 2013 Conference onEmpirical Methods in Natural Language Processing,pages 1360?1365.
[Chen and Ng2014] Chen Chen and Vincent Ng.
2014.Chinese zero pronoun resolution: An unsupervisedprobabilistic model rivaling supervised resolvers.
InProceedings of the 2014 Conference on EmpiricalMethods in Natural Language Processing.
Associationfor Computational Linguistics.
[Daum?e III et al2009] Hal Daum?e III, John Langford,and Daniel Marcu.
2009.
Search-based structured pre-diction.
Machine learning, 75(3):297?325.
[Daum?e III et al2014] Hal Daum?e III, John Langford,and Stephane Ross.
2014.
Efficient programmablelearning to search.
arXiv preprint arXiv:1406.1837.
[Grosz et al1995] Barbara J Grosz, Scott Weinstein, andAravind K Joshi.
1995.
Centering: A framework formodeling the local coherence of discourse.
Computa-tional linguistics, 21(2):203?225.
[Haspelmath et al2005] Martin Haspelmath, MatthewDryer, David Gil, and Bernard Comrie, editors.
2005.The World Atlas of Language Structures.
Oxford Uni-versity Press.
[Hovy et al2006] Eduard Hovy, Mitchell Marcus, MarthaPalmer, Lance Ramshaw, and Ralph Weischedel.2006.
Ontonotes: the 90% solution.
In NAACL.
[Kong and Zhou2010] Fang Kong and Guodong Zhou.2010.
A tree kernel-based unified framework for Chi-nese zero anaphora resolution.
In Proceedings of the2010 Conference on Empirical Methods in NaturalLanguage Processing, pages 882?891.
Association forComputational Linguistics.
[Kweon2011] Soo-Ok Kweon.
2011.
Processing null andovert pronoun subject in ambiguous sentences in Ko-rean.
International Journal of Linguistics, 3(1).
[Langford et al2007] John Langford, Lihong Li, andAlexander Strehl.
2007.
Vowpal wabbit online learn-ing project.
http://hunch.net/?p=309.
[Petrov and Klein2007] S. Petrov and D. Klein.
2007.Improved inference for unlexicalized parsing.
In Pro-ceedings of NAACL HLT 2007, pages 404?411.
[Rohde and Frank2014] Hannah Rohde and Michael CFrank.
2014.
Markers of topical discourse in child-directed speech.
Cognitive science, 38(8):1634?1661.
[Ross et al2011] St?ephane Ross, Geoff J. Gordon, andJ.
Andrew Bagnell.
2011.
A reduction of imitationlearning and structured prediction to no-regret onlinelearning.
In Proceedings of the Workshop on ArtificialIntelligence and Statistics (AIStats).
[Wang2011] Deliang Wang.
2011.
Anaphora Resolutionin Chinese from the Centering Perspective.
ForeignLanguage Teaching and Research Press.
[Yeh and Chen2007] Ching-Long Yeh and Yi-Chun Chen.2007.
Zero anaphora resolution in Chinese with shal-low parsing.
Journal of Chinese Language and Com-puting, 17(1):41?56.
[Zhao and Ng2007] Shanheng Zhao and Hwee Tou Ng.2007.
Identification and resolution of Chinese zeropronouns: A machine learning approach.
In Proceed-ings of the 2007 Joint Conference on Empirical Meth-ods on Natural Language Processing and Computa-tional Natural Language Learning, pages 541?550.503
