Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 1322?1330, Dublin, Ireland, August 23-29 2014.Reducing Over-Weighting in Supervised Term Weighting forSentiment AnalysisHaibing WuDepartment of Electronic EngineeringFudan UniversityShanghai, Chinahaibingwu13@fudan.edu.cnXiaodong GuDepartment of Electronic EngineeringFudan UniversityShanghai, Chinaxdgu@fudan.edu.cnAbstractRecently the research on supervised term weighting has attracted growing attention in the field of Tradi-tional Text Categorization (TTC) and Sentiment Analysis (SA).
Despite their impressive achievements,we show that existing methods more or less suffer from the problem of over-weighting.
Overlooked byprior studies, over-weighting is a new concept proposed in this paper.
To address this problem, tworegularization techniques, singular term cutting and bias term, are integrated into our framework of su-pervised term weighting schemes.
Using the concepts of over-weighting and regularization, we providenew insights into existing methods and present their regularized versions.
Moreover, under the guidanceof our framework, we develop a novel supervised term weighting scheme, regularized entropy (re).
Theproposed framework is evaluated on three datasets widely used in SA.
The experimental results indicatethat our re enjoys the best results in comparisons with existing methods, and regularization techniquescan significantly improve the performances of existing supervised weighting methods.1 IntroductionSentiment Analysis (SA), also known as opinion mining, has enjoyed a burst of research interest withgrowing avenues (e.g., social networks and e-commerce websites) for people to express their senti-ments on the Internet.
A typical sentiment-analysis application mainly involves three key subtasks,namely holder detection, target extraction and sentiment classification (Liu, 2012; Hu and Liu, 2004).A simple and most extensively studied case of sentiment classification is sentiment polarity classifica-tion, which is the binary classification task of labelling the polarity of a sentiment-oriented documentas positive or negative.
Sentiment classification can be performed at the document, sentence, phase orword level.
In this paper, we focus on sentiment polarity classification at document level.Just like Information Retrieval (IR) and TTC, in sentiment classification, the content of an opinion-orientated document can be represented as a vector of terms in light of Vector Space Model (VSM).
InVSM, each dimension of the vector corresponds to a term and different terms have different weights,thus the term weight represents the contribution of the term to the sentiment of a document in senti-ment classification.
Term weighting is the task of assigning appropriate weights to terms according totheir correlations with the category concept.
Term weighting schemes fall into two categories (Lan etal., 2009; Debole and Sebastiani, 2003).
The first one, known as unsupervised term weighting method,does not take category information into account.
The second one referred to as supervised termweighting method embraces the category label information of training documents in the categorizationtasks.
Although most term weighting approaches to text categorization, including sentiment classifica-tion, are borrowed from IR, recently several new supervised term weighting schemes have been stud-ied and achieved significant successes in TTC and SA (Lan et al., 2009; Martineau and Finin, 2009;Paltoglou and Thelwall, 2010).Despite the impressive achievements in the current field of supervised term weighting for TTC andSA, we indentify that existing supervised methods, more or less, suffer from over-weighting problemand thus develop a robust framework to address this problem.
Over-weighting, overlooked by priorstudies, is a new concept introduced in this paper.
It would occur due to the presence of many noisyThis work is licensed under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organisers.
License details: http://creativecommons.org/licenses/by/4.0/1322words and the unreasonably too large ratios between weights of different terms.
Thus, it could result inpoor representations of sentiments containing in documents.
In order to reduce over-weighting prob-lem for supervised term weighting, two regularization techniques called singular term cutting and biasterm are proposed and integrated into our framework of supervised term weighting schemes.
Singularterm cutting is introduced to cut down the weights of noisy or unusual terms, and bias term is added toshrink the ratios between weights of different terms.Using the concepts of over-weighting and regularization, we provide new insights into existing su-pervised weighting methods and then present their regularized versions.
We also propose a novel termweighting scheme called regularized entropy (re) under the guidance of our framework.
The formula-tion of re bases on entropy, which is used to measure the distribution of terms over different categories,and the terms with smaller entropy value have larger weights.After presenting our framework, the regularized versions of existing methods and re in detail, ex-periments are conducted on three publicly available datasets widely used in SA.
In our experiments, reis compared against many existing methods appearing in IR, TTC and SA.
We also compare the per-formances of existing supervised weighting methods against their regularized versions.
The results ofcomparative experiments indicate that re clearly outperform existing methods, the introduction ofregularization techniques significantly improves the performances of existing supervised weightingmethods.2 Review of Term Weighting Schemes in IR, TTC and SAIn IR, TTC and SA, one of the main issues is the representation of documents.
VSM provides a simpli-fying representation by representing documents as vector of terms.
Term weighting aims to evaluatethe relative importance of different terms in VSM.
There are three components in a term weightingscheme, namely local weight, global weight and normalization factor (Salton and Buckley, 1988; Lanet al., 2009).
Final term weight is the product of the three components:jiijij nglt ??
?,                                                                    (1)where tij is the final weight of ith term in the jth document, lij is the local weight of ith term in the jthdocument, gi is the global weight of the ith term, and nj is the normalization factor for the jth document.2.1 Local Term Weighting SchemesLocal weight component is derived only from frequencies within the document.
Table 1 lists threecommon local weighting methods, namely raw term frequency (tf ), term presence (tp) and augmentedterm  frequency (atf ).
In IR and TTC, the  most widely used local weight is tf , but pioneering researchLocal weight Notation Descriptiontf tf Raw term frequency.???
?otherwise,0 0if,1 tftp Term presence, 1 for presence and 0 for absence.
)(max)1( tftfkkt?
?atfAugmented term frequency, maxt(tf) is the maximumfrequency of any term in the document, k is set to 0.5for short documents (Salton and Buckley, 1988).Table 1: Local term weighting schemes.Notation DescriptionaPositive document frequency, i.e., number of documents in positive category containingterm ti.b Number of documents in positive category which do not contain term ti.cNegative document frequency, i.e., number of documents in negative category containingterm ti.d Number of documents in negative category which do not contain term ti.N Total number of documents in document collection, N = a +b + c+ d.??
NN ,N+is number of documents in  positive category, and N?is number of documents in nega-tive category.
N+= a+b, N?=c+d.Table 2: Notations used to formulate global term weighting schemes.1323on SA by Pang et al.
(2002) showed that much better performance was achieved by using tp, not tf.This conclusion for SA was opposite to TTC, so tp was preferred in subsequent SA research.2.2 Global Term Weighting SchemesIn contrast to local weight, global weight depends on the whole document collection.
To formulatedifferent global weighting schemes, some notations are first introduced in table 2.
By using these nota-tions, table 3 presents several representative global weighting schemes in IR, TTC and SA, includinginverse document frequency (idf), probabilistic idf (pidf), BM25 idf (bidf), information gain (ig), deltaidf (didf), dsidf?, delta BM25 idf (dbidf), dbidf?
and relevance frequency (rf).
Among these globalweighting methods, idf, pidf and bidf are unsupervised methods because they do not utilize the cate-gory label information of document collection.
The common idea behind them is that a term that oc-curs rarely is good at discriminating between documents.Other global weighting schemes in table 3 are supervised term weighting methods.
Among thesesupervised factors, feature selection methods, ig and mi are studied earliest.
In TTC field, Debole andSebastiani (2003) replaced idf with ig and other feature selection methods, gr and chi, for global termweighting.
They concluded that these feature selection methods did not give a consistent superiorityover the standard idf.
In SA field, Deng et al.
(2013) also employed several feature selection methods,including ig and mi, to learn the global weight of each term from training documents with categorylabels.
The experimental results showed that compared with bidf, mi produced better accuracy on twoof three datasets but ig provided very poor results.For the rest of supervised term weighting schemes in table 3, rf is published in TTC literature, didfand dbidf are published in SA literature.
The intuitive consideration of rf is that the more concentrateda high frequency term is in the positive category than in the negative category, the more contributionsGlobal weight Notation DescriptioncaN?2logidfInverse document frequency(Jones, 1972)??????
??
1log 2 caN  pidfProbabilistic idf (Wu and Salton,1981)5.05.0log 2 ???
?cadb  bidf BM 25 idf (Jones et al., 2000)))((log))((log))((log))((log2222dcdbdNNddccacNNcdbbabNNbcabaaNNa??????????
?ig Information gain????????
??
))(,)(max(log 2 NcacNNcaaNmi Mutual informationcNaN?
?2logdidfDelta idf (Martineau and Finin,2009)5.05.0log2 ???
?cNaN  dsidfDelta smoothed idf (Paltoglouand Thelwall, 2010))5.0()5.0(log2 ???
?cNaN  dsidf?
Another version of dsidf5.0)5.0(5.0)5.0(log2 ???????
?caNacNdbidfDelta BM25 idf (Paltoglou andThelwall, 2010))5.0)(5.0()5.0)(5.0(log2 ???????
?caNacN  dbidf?
Another version of dbidf????????
?
),1max(2log 2 carfRelevance frequency (Lan et al.,2009)Table 3: Global term weighting schemes.1324it makes in selecting the positive samples from the negative samples.
Driven by this intuition, rf wasproposed to capture this basic idea.
The experimental results showed that when combined with the lo-cal component tf, rf consistently and significantly outperformed other term weighting methods, includ-ing idf and ig.
Due to the asymmetry of rf, it only boosts the weights of terms that appear more fre-quently in the positive category.
In other words, rf discriminates against terms appearing more fre-quently in negative category.
The asymmetry of rf is reasonable for TTC because it only cares whethera document belongs to a topic or not and a single document can concentrate on different topics.
How-ever, it is not the case for binary sentiment classification since terms appear in positive or negativereviews are of the same importance.In SA field, The first published supervised term weighing scheme, introduced by Martineau andFinin (2009), is called delta idf.
Instead of only using tf as term weights, the authors assigned termweights for a document by calculating the difference of that term?s idf values in the positive and nega-tive training documents.
Obviously, didf boosts the importance of terms that are unevenly distributedbetween the positive and negative categories and discounts evenly distributed words.
It is known thatthe distribution of sentimental words is more uneven than stop words, as a result, didf assign muchgreater weights to sentimental words than stop words.
The produced results showed that didf providedhigher classification accuracy than the simple tf or the binary weighting scheme tp.
Nonetheless, didfis susceptible to the errors caused by the case that a = 0 or c = 0, and the authors did not provide anydetail that how they deal with this problem.
Following the idea of didf and to rectify the problem ofdidf, Paltoglou and Thelwall (2010) presented a smoothed version of didf, delta smoothed idf (dsidf),and explored other more sophisticated global term weighting methods originated from IR includingBM25 idf (bidf) and delta BM25 idf (dbidf).
The formulas of these schemes are also presented in table3.
They showed that these variants of the classic tf-idf scheme provided significant increases over thebest term weighting methods for SA in terms of accuracy.
The idea of introducing smoothness tech-nique is wonderful and can indeed avoid the computational errors in didf, but due to the unsuitableimplementation, the smoothed version of didf provided by Paltoglou and Thelwall (2010) severely en-counters the problem of over-weighting.
We provide another version of dsidf, namely dsidf?.
Besidesdsidf, over-weighting is also severely encountered by dbidf, and our versions of it is denoted as dbidf?.3 Research DesignBased on our review of term weighting schemes above, we believe that supervised term weighting can,but not always, boost the performances of text categorization.
Actually, the somewhat successful ones,such as rf, didf and dsidf, follow the same intuition that the more imbalanced a term?s distribution isacross different categories, the more contribution it makes in discriminating between the positive andnegative documents.
The only difference between them lies in the quantification of the imbalance of aterm?s distribution.
However, existing methods more or less suffer from the problem of over-weighting.
We argue that a successful supervised weighting method should satisfy the following twocriteria and develop a robust framework of supervised term weighting schemes.Criterion 1: Assign large weights to terms that unevenly distribute across different categories.Criterion 2: Avoid the over-weighting problem.3.1 Our FrameworkOver-weighting is somewhat like over-fitting in statistical machine learning, so we name it over-weighting.
It is known that over-fitting occurs when a statistical model describes random error or noiseinstead of the underlying relationship.
Similarly, over-weighting could occur in supervised termweighting.
In practice we indentify that over-weighting is caused by the presence of noisy terms andthe unsuitable quantification of the degree of the imbalance of a term?s distribution.The presence of noisy terms would lead to the problem of over-weighting.
To illustrate this phe-nomenon, suppose that the training document collection contains 10,000 documents and evenly dis-tributes over the positive and negative category, the number of documents containing the strange term?leoni?
belonging to positive category is 5, i.e., a = 5, and no document belonging to negative categorycontains ?leoni?, i.e., c = 0, according to the formulation of most existing supervised methods such asdsidf, the weight of ?leoni?
should be large since ?leoni?
unevenly distributes over different categories.However, since the total number of documents containing ?leoni?
is so trivial compared to the size of1325training collection, ?leoni?
could be an unusual word.
We call the terms like ?leoni?
singular terms.Statistically, singular terms account for a great part of the whole terms in the dictionary constructedbased on the training documents even if we filter out low frequency words.
As singular terms do notembody any sentiment and the weights of them are supposed to be small, we formulate the globalweight of term ti as????????
otherwise, /)(and)0or(0if,0r Ncacagi ?
(2)where r is a variable quantifying the imbalance of a term?s distribution across different categories andits value ranges from 0 to 1, ?
is a very small number, here we set ?
to 0.005.
As formula (2) cutsdown the weights of singular terms, we name the first regularization technique singular term cutting.Also, an unsuitable quantification of a term?s distribution would lead to unreasonably too large ra-tios between different weights and thus results in over-weighting, although the term weight calculatedby (2) is no more than 1.
This finding leads us to introduce the second regularization technique, biasterm, to the weight of term ti, so our framework of supervised term weighting schemes is modified as???
?
?????
otherwise, /)(and)0or(0if,00 rbNcacagi ?
(3)where b0 is the bias term, it shrinks the ratios between different weights of terms, the value of it con-trols the trade-off between weighting the terms freely and preventing over-weighting.
If b0 is too large,supervised term weighting would make no difference and under-weighting would occur.
If b0 is toosmall, over-weighting would occur.
The optimal value of b0 can be obtained via cross-validation, amodel selection technique widely used in machine learning.3.2 Regularized Versions of Existing MethodsAs mentioned before, the somewhat successful ones of existing supervised weighting methods try toquantify the imbalance of a term?s distribution.
Recall that in our framework, r is just right a variablesharing this purpose, so we can make improvement on existing supervised weighting methods by re-placing r with them.
Ahead of the improvement of existing methods, we first provide new insights intoexisting methods using the concepts of over-weighting and regularization.Because r quantifies the degree of the imbalance of a term?s distribution across different categories,existing methods are required to satisfy Criterion 1.
It has been clear that didf, dsidf, dsidf?, dbidf,dbidf?, mi and rf satisfy Criterion 1 via the review of existing methods in section 2.
Another propertyshared by them is that the formulations of them base on logarithmic function.
It is known that loga-rithmic function plays the role of shrinking the ratios between different term weights, so they implic-itly satisfy Criterion 2 and in some degree reduce the over-weighting problem.
In actuality, dsidf, dsidf?and rf can be treated as the further regularized versions of didf since the constant 2+ in rf and thesmoothness in dsidf and dsidf?
can be treated as regularization techniques.
We have pointed out in sec-tion 2 that due to the unreasonable implementation of smoothness, dsidf and dbidf do not reduce, butaggravate over-weighting.
As to dsidf?
and dbidf?, they limit over-weighting in a very great degree viathe introduction of smoothness technique and logarithmic function, but over-weighting is still notovercome completely, experimental results in section 4 will show that the performances of them canbe further enhanced by cutting the weights of singular terms and adding a bias term.Method Regularized versiondidfdsidfdsidf?rf ??????????otherwise,}),min(),max(log{max),min(),max(log/)(and)0or(0if,2200cacacacabNcacabt?dbidfdbidf???????????????otherwise,}),min()),max((log{max),max()),min((log/)(and)0or(0if,2200cacaNcacaNbNcacabt?mi?????????
?otherwise,}{maxlog/)(and)0or(0if,200mimibNcacabt?Table 4: Regularized versions of existing supervised term weighting schemes.1326Up to present we have known that existing supervised methods encounter over-weighting in differ-ent degree.
In order to make improvements on existing methods and under the guidance of our frame-work, we present the regularized versions of didf, dsidf, dsidf?, dbidf, dbidf?
and mi in table 4.
Thesemethods are selected to improve due to their typical representations and diversities.Note that the regularized versions of didf, dsidf, dsidf?
and rf and are the same one due to the fact thatdsidf, dsidf?
and rf are same as didf if there is no smoothness or constant in them.
For the same reason,dbidf and dbidf?
are grouped together.3.3 Regularized EntropyInspired by the derivation of our framework for supervised term weighting, we propose a novel super-vised term weighting scheme called regularized entropy (re).
For re, entropy is exploited to measurethe degree of the imbalance of a term?s distribution across different categories.
According to informa-tion theory (Shannon, 1948), for a random variable X with m outcomes {x1,?, xm}, the entropy, ameasure of uncertainty and denoted by H(X), is  defined as)(log)()( 21iimixpxpXH ???
?,                                                     (4)where p(xi) is the probability that X equals to xi.
Let p+ and p?denote the probability of documentswhere term ti occurs and belonging to positive and negative category respectively, then p+ and p?canbe estimated ascacpcaap ??????
,.
(5)According to formula (4), if term ti occurs in a document, the degree of uncertainty of this documentbelonging to a category iscaccaccaacaapppph ??????????????
2222 loglogloglog.
(6)Obviously, if the documents containing term ti distribute evenly over different categories, the entropyh will be large.
In contrast, if the documents containing term ti distribute unevenly over different cate-gories, the entropy h will be relatively small.
However, we hope that the more uneven the distributionof documents where term ti occurs, the larger the weight of ti is.
And that the entropy h is between 0and 1, so the original formula of the weight of term ti ishgi ?
?1 .
(7)We call the scheme formulated by the (7) nature entropy (ne).
It seems that ne can be used as theweights of terms directly and will perform well.
Unfortunately, ne suffers from the same problem withexisting methods.
Under the guidance of our framework, the regularized version of ne is formulated as???
??
?????
otherwise),1( /)(and)0or(0if,00 hbNcacagi ?.
(8)We name the proposed method formulated by (8) regularized entropy (re), which literally indicatesthe idea behind the scheme.4 Experimental ResultsWe conduct sentiment classification experiments on three document-level datasets.
The first one is Cornellmovie review dataset introduced by Pang and Lee (2004).
This sentiment polarity dataset consists of 1,000positive and 1,000 negative movie reviews.
The second dataset is taken from Multi-Domain SentimentDataset (MDSD) of product reviews (Blitzer et al., 2007).
MDSD is initially released for the research onsentiment domain adaption but can also be used for sentiment polarity classification.
It contains Amazonproduct reviews for different product types, we select camera reviews and thus refer the second corpus asAmazon camera review dataset.
Also, it consists of 1,000 positive and 1,000 negative camera reviews.For the above two datasets, the results are based on the standard 10-fold cross validation.
Term weight-ing is performed on the 1,800 training reviews for each fold and the remaining 200 are used to evaluate thepredicting accuracy.
The overall classification accuracy is the average accuracy across 10 folds.We also use the Stanford large movie review dataset developed by Mass et al.
(2011).
It contains 50,000movie reviews, split equally into 25,000 training and 25,000 testing set.
For this dataset,  due to the original1327split, no cross validation is used.
Term weighting is only implemented on the training set, and the classifi-cation accuracy is reported based on the testing set.We only use unigrams as the features.
Support Vector Machine (SVM) is used as the classifier.
Specially,we adopt the L2-regularized L2-loss linear SVM and the implementation software is LIBLINEAR (Fan etal., 2008).
In all our experiments, cross-validation is performed on training document collection to ob-tain optimal value of b0.
On Cornell and Stanford movie review dataset, b0 is set to 0.1 for re, 0.05 forthe improved versions of didf, dsidf, dsidf?
and rf, 0.02 for that of mi, and 0.01 for those of dbidf anddbidf?.
On Amazon camera review dataset, b0 is set to 0.05 for re 0.03 for the improved versions ofdidf, dsidf, dsidf?
and rf, 0.02 for that of mi, and 0.01 for those of dbidf and dbidf?.4.1 Experiment 1: Comparisons of re Against Existing MethodsTable 5 reports the classification accuracies of re and other term weighting schemes.
On the Cornellmovie review dataset, the local weighting method tp outperforms tf significantly in general except thecase that dbidf and dsidf are used as the global weighting methods.
There is no distinct difference be-tween tp and atf, neither of them consistently performs better than each other when combined withvarious global weighting methods.Compared to the change of local weighting methods, global weighting methods lead to more sig-nificant difference on classification accuracy.
Combined with different local weighting schemes, theproposed global weighting method, re, has always been shown to clearly perform better than otherglobal weighting methods.
Specially, the highest classification accuracy, 89.65%, is achieved by thecombination of re and atf, i.e., atf-re.
Compared to no, re shows apparent superiorities, the increasesof accuracy are +1.55% (from 88.05% to 89.60%) and +1.50% (from 88.15% to 89.65%) respectivelywhen the local methods are tp and atf.
The most popular idf in IR field is not a good choice for senti-ment classification.
For the methods originated from TTC field, the feature selection approaches, miperforms well and the classification accuracies produced by it is higher than the others except re inapparent advantages.
Unlike mi, ig is instead a disappointing performer, the accuracy 87.65%, pro-vided by ig when combined with tp, is far lower than that of mi, this observation is entirely predictabledue to the fact that ig does not follow Criterion 1 and suffers over-weighting.
As for rf, it do not per-form well, the highest accuracy provided by them is only 88.00% respectively.
It is not surprising thatrf does not even outperform no since its discrimination against the terms that appear more frequentlyin the negative reviews.
When it comes to the approaches that recently appeared in SA literature, bothdsidf and dbidf performs very poorly because of over-weighting problem caused by the unreasonableimplementation.
But both dsidf?
and dbidf?
are shown to give slightly better results than no.On the Amazon camera review dataset, the performances of local weighting methods agree with thoseon Cornell movie review dataset.
Again, tp and atf yield comparable classification accuracy and bothof them outperform tf.
The performances on this dataset produced by global weighting methods are,generally, in accordance to those on the previous dataset, but some differences deserve our attention.First, re outperforms no with greater superiorities compared to the previous dataset, the increase ofaccuracy is +2.20% (from 87.25% to 89.45%) and +2.00% (from 87.50% to 89.50%) respectivelywhen the local methods are tp and atf .
Another one is that dsidf?
provides more apparent advantagesover no compared to the previous dataset but differences between re and dsidf?
become smaller.Cornell movie review Amazon camera review  Stanford movie reviewtf tp atf  tf tp atf  tf tp atfno 85.20 88.05 88.15 no 86.80 87.25 87.50 no 88.38 88.72 88.71idf 84.15 84.90 85.10 idf 85.70 85.75 86.10 idf 88.30 88.24 88.26ig 86.40 87.65 87.90 ig 87.25 87.85 87.65 ig 88.71 88.40 88.45mi 86.90 88.85 88.85 mi 88.95 89.05 89.15 mi 89.23 89.45 89.52dsidf 80.25 80.20 80.10 dsidf 83.15 82.80 83.30 dsidf 86.72 86.89 86.77dsidf?
86.65 88.20 88.15 dsidf?
88.20 88.95 89.10 dsidf?
89.23 89.25 89.32dbidf 81.20 81.10 81.10 dbidf 86.60 87.00 86.90 dbidf 86.80 86.73 86.78dbidf?
87.30 88.30 88.40 dbidf?
88.85 89.10 89.00 dbidf?
89.41 89.39 89.52rf 85.10 88.00 87.75 rf 86.95 87.35 87.85 rf 87.84 88.36 88.46re 87.85 89.60 89.65 re 89.15 89.45 89.50 re 89.53 89.81 89.80Table 5: Classification accuracy of local and global weighting methods.1328On the Stanford large movie review dataset, differences in accuracy are smaller than those on theprevious ones, but the testing set contains 25,000 documents, the variance of the performance estimateis quite low (Maas et al., 2011).
Interestingly, unlike the conclusion on the Cornell movie review data-set, tp does not show significant advantages over tf and even slightly underperforms tf when the globalmethods are idf, ig, dbidf, and dbidf?.
The performances of tp and atf are still comparable but atf re-veals a slight superiority over tp.
In spite of the smaller differences, among the global weighting meth-ods, re still embraces the highest classification accuracy, 89.81%, when combined with tp.
In accor-dance to the observations on the previous two datasets, mi, dsidf?
and dbidf?
yield higher classificationaccuracies than no.
Again, the other global methods, idf, ig, rf, dsidf and dbidf still produce compara-ble or lower accuracies in comparison with no.4.2 Experiment 2: Comparisons Existing Methods Against Their Regularized VersionsWe also compare the performances of some representative supervised methods, i.e., didf, dsidf, dsidf?,dbidf, dbidf?, rf, and mi against their regularized versions.
In this experiment, we only use tp as thelocal weighting method.
Table 6 records the classification accuracies of original versions of thesemethods and their improved versions.
We can observe that the regularized versions of existing meth-ods consistently have much better accuracy.
Regularized version of dsidf yields the most significantimprovements, the accuracy difference to original version is +9.30%, +6.80% and +2.82% on threedatasets respectively.
The accuracy difference between dbidf and its regularized version is also re-markable and significant.
These observations validate our analysis in section 2 that dsidf and dbidf se-verely encounters over-weighting problem.
Note that the improvements of the regularized versions ofdsidf?, dbidf?
and mi over their originals are trivial as they are much less subjected to over-weighting.Significance test will be included for these methods to test if the improvements are statistically reliable.5 Conclusion and Future WorkIn this study we have proposed a robust framework of supervised term weighting schemes.
Thisframework is developed based on the techniques introduced to reduce over-weighting problem com-monly suffered by existing supervised weighting methods.Over-weighting is a new concept proposed in this paper, which is caused by the presence of manynoisy words and the unreasonably too large ratios between weights of different terms.
To reduce over-weighting, we have introduced two regularization techniques, singular term cutting and bias term.
Sin-gular term cutting cuts down the weights of noisy or strange words, and bias term shrinks the ratiosbetween weights of different terms.
Comparative experiments have shown that regularization tech-niques significantly enhance the performances of existing supervised methods.More over, a novel supervised term weighting scheme, re, is proposed under our framework.
Theformulation of re bases on entropy, which is used to measure a term?s distribution across differentcategories.
The experimental results have shown that re not only outperforms its original version, ne,with great advantage but also consistently outperforms existing methods appearing in IR, TTC and SA.In the future, we would like to extend our work to other tasks such as multi-class classification andtraditional text categorization.Cornell movie review Amazon camera review  Stanford movie reviewMethodOrigi-nalver-sionRegu-larizedver-sionDiffer-ence tooriginalversionMethodOrigi-nalver-sionRegu-larizedver-sionDiffer-ence tooriginalversionMethodOrigi-nalversionRegu-larizedver-sionDiffer-ence tooriginalversiondidf N/A 89.50 N/A didf N/A 89.60 N/A didf N/A 89.71 N/Adsidf 80.20 89.50 +9.30 dsidf 82.80 89.60 +6.80 dsidf 86.89 89.71 +2.82dsidf?
88.20 89.50 +1.30 dsidf?
88.95 89.60 +0.65 dsidf?
89.25 89.71 +0.46rf 88.00 89.50 +1.50 rf 87.35 89.60 +2.25 rf 88.36 89.71 +1.35dbidf 81.10 89.25 +8.15 dbidf 87.00 89.65 +2.65 dbidf 86.83 89.49 +2.66dbidf?
88.30 89.25 +0.95 dbidf?
89.10 89.65 +0.55 dbidf?
89.39 89.49 +0.10mi 88.85 89.10 +0.25 mi 89.05 89.55 +0.50 mi 89.45 89.59 +0.14ne 83.45 89.60 +6.15 ne 87.85 89.45 +1.60 ne 87.32 89.81 +2.49Table 6: Classification accuracies of original versions of ne and some existing supervised termweighting schemes and their regularized versions under our framework.1329AcknowledgementsThis work was supported in part by National Natural Science Foundation of China under grant61371148 and Shanghai National Natural Science Foundation under grant 12ZR1402500.ReferencesAndrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts.2011.
Learning Word Vectors for Sentiment Analysis.
In Proceedings of ACL, Pages 142-150.Bing Liu.
2012.
Sentiment Analysis and Opinion Mining.
Morgan and Claypool Publishers.Bo Pang and Lillian Lee.
2004.
A Sentimental Education: Sentiment Analysis Using Subjectivity SummarizationBased on Minimum Cuts, In Proceedings of ACL, pages 271-278.Bo Pang, Lillian Lee and Shivakumar Vaithyanathan.
2002.
Thumbs up?
Sentiment Classification Using Ma-chine Learning Techniques, In Proceedings of EMNLP, pages 79-86.Claude E. Shannon.
1948.
A Mathematical Theory of Communication.
Bell System Technical Jour-nal, 27 (3):379-423.Franca Debole and Fabrizio Sebastiani.
2003.
Supervised Term Weighting for Automated Text Categorization.In Proceedings of ACM Symposium on Applied Computing, pages 784-788.Georgios  Paltoglou and Mike Thelwall.
2010.
A Study of Information Retrieval Weighting Schemes for Senti-ment Analysis.
In Proceedings of ACL, pages 1386-1395.Gerard Salton and Christopher Buckley.
1988.
Term Weighting Approaches in Automatic Text Retrieval.
Infor-mation Processing and Management, 24(5):513-523.Gerard Salton and Michael J. McGill.
1983.
Introduction to Modern Information Retrieval.
McGraw Hill BookInc., New York.Harry Wu and Gerard Salton.
1981.
A Comparison of Search Term Weighting: Term Relevance vs. InverseDocument Frequency.
In Proceeding of ACM SIGIR, pages 30-39.John Blitzer, Mark Dredze and Fernando Pereira.
2007.
Biographies, Bollywood, Boom-boxes and Blenders:Domain Adaptation for Sentiment Classification.
In Proceedings of ACL, pages 440-447.Justin Martineau and Tim Finin.
2009.
Delta TFIDF: An Improved Feature Space for Sentiment Analysis.
InProceedings of  Third AAAI International Conference on Weblogs and Social Media, pages 258-261.Karen S. Jones, Stephen Walker and Stephen E. Robertson.
2000.
A Probabilistic Model of Information Re-trieval: Development and Comparative Experiments.
Information Processing and Management, 36(6):779-808.Man Lan, Chew L. Tan, Jian Su and Yue Lu.
2009.
Supervised and Traditional Term Weighting Methods forAutomatic Text Categorization.
IEEE Trans.
on Pattern Analysis and Machine Intelligence, 31(4):721-735.Mingqing Hu and Bing Liu.
2004.
Mining and Summarizing Customer Reviews.
In Proceedings of ACMSIGKDD, pages 168-177.Rong E. Fan, Kai W. Chang, Cho J. Hsieh, Xiang R. Wang, and Chih J. Lin.
2008.
LIBLINEAR: A Library forLarge Linear Classification.
Journal of Machine Learning Research, 9:1871-1874.Sparck K. Jones.
1972.
A Statistical Interpretation of Term Specificity and Its Application in Retrieval.
Journalof Documentation, 28:11-21.William B. Croft.
1983.
Experiments with Representation in A Document Retrieval System.
Information Tech-nology: Research and Development, 2:1-21.Zhi H. Deng, Kun H. Luo and Hong L. Yu.
2013.
A Study of Supervised Term Weighting Scheme for SentimentAnalysis.
Expert Systems with Applications, 41(7):3506-3513.1330
