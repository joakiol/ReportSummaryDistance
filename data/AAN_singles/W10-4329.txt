Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 165?174,The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational LinguisticsThe Dynamics of Action Corrections in Situated InteractionAntoine RauxHonda Research Institute USAMountain View, CA, USA.araux@honda-ri.comMikio NakanoHonda Research Institute JapanWako, Japannakano@jp.honda-ri.comAbstractIn spoken communications, correction ut-terances, which are utterances correct-ing other participants utterances and be-haviors, play crucial roles, and detectingthem is one of the key issues.
Previ-ously, much work has been done on au-tomatic detection of correction utterancesin human-human and human-computer di-alogs, but they mostly dealt with the cor-rection of erroneous utterances.
How-ever, in many real situations, especially incommunications between humans and mo-bile robots, the misunderstandings man-ifest themselves not only through utter-ances but also through physical actionsperformed by the participants.
In this pa-per, we focus on action corrections andpropose a classification of such utterancesinto Omission, Commission, and Degreecorrections.
We present the results of ouranalysis of correction utterances in dialogsbetween two humans who were engagingin a kind of on-line computer game, whereone participant plays the role of the re-mote manager of a convenience store, andthe other plays the role of a robot storeclerk.
We analyze the linguistic content,prosody as well as the timing of correctionutterances and found that all features weresignificantly correlated with action correc-tions.1 IntroductionRecent progress in robot technology made it a re-ality to have robots work in offices and homes, andspoken dialog is considered to be one of the mostdesired interface for such robots.
Our goal is tobuild a spoken dialog interface for robots that canmove around in an office or a house and executetasks according to humans?
requests.Building such spoken dialog interface for robotsraises new problems different from those of tra-ditional spoken/multimodal dialog systems.
Theintentions behind human utterances may vary de-pending on the situation where the robot is and thesituation changes continuously not only becausethe robot moves but also because humans and ob-jects move, and human requests change.
In thissense human-robot interaction is situated.Of the many aspects of situated interaction, wefocus on the timing structure of interaction.
Al-though traditional spoken dialog systems deal withsome timing issues such as turn-taking and han-dling barge-ins, timing structure in human-robotinteraction is far more complex because the robotcan execute physical actions and those actions canoccur in parallel with utterances.In this work we are concerned specifically withcorrections in situated interaction.
In joint physi-cal tasks, human corrective behavior, which allowsto repair discrepancies in participants?
mutual un-derstanding, is tightly tied to actions.While past work on non-situated spoken dialogsystems has shown the necessity and feasibility ofdetecting and handling corrections (Kitaoka et al,2003; Litman et al, 2006; Gieselman and Osten-dorf, 2007; Cevik et al, 2008), most of these mod-els assume that corrections target past utterancesand rely on a strict turn-based structure which isfrequently violated in situated interaction.
Whendialog is interleaved with physical actions, the spe-cific timing of an utterance relative to other utter-ances and actions is more relevant than the turnsequence.In this paper, we propose a classification of er-rors and corrections in physical tasks and analyzethe properties of different types of corrections inthe context of human-human task-oriented inter-actions in a virtual environment.
The next sectiongives some characteristics of corrections in situ-ated interaction.
Section 3 describes our experi-165Alice : Put it right above (1)the lamp standBob : Here?
(2)Alice : A little bit more (3)to the right.
(Bob Moves the frame left) (4)Alice : No the right!
(5)(Bob Moves the frame right) (6)Alice : More... (7)Alright, that?s ... (8)(A bee flies next to Bob) (9)Alice : Watch out!
That bee isgoing to sting you!
(10)Figure 1: Example dialog from a situated task.mental set up and data collection effort.
Section 4presents the results of our analysis of correctionsin terms of timing, prosodic, and lexical features.These results are discussed in Section 5.2 Corrections in Situated Tasks2.1 Situated TasksWe define a situated task as one for which two ormore agents interact in order to perform physicalactions in the (real or virtual) world.
Physical ac-tions involve moving from one place to another,as well as manipulating objects.
In many cases,interaction happens simultaneously with physicalactions and can be affected by them, or by otherexternal events happening in the world.
For exam-ple, Figure 1 shows an extract of a (constructed)dialog where one person (Alice) assists another(Bob) while he hangs a picture frame on a wall.This interaction presents some similarities anddifferences with unimodal, non-situated dialogs.In addition to standard back-and-forth turn-takingas in turns 1-3, this example features utterancesby Alice which are not motivated by Bob?s ut-terances, but rather by (her perception of) his ac-tions (e.g.
utterance 5 is a reaction to action 4),as well as external events such as 9, which trig-gered response 10 from Alice.
Therefore the con-tent of Alice?s utterances is dependent not only onBob?s, but also on events happening in the world.Similarly, the timing of Alice?s utterances is notonly conditioned on Bob?s speech, prosody, etc,but also on asynchronous world events.Robots and other agents that interact with peo-ple in real world situations need to be able to ac-count for the impact of physical actions and worldevents on dialog.
In the next section and the restof this paper, we focus on correction utterancesand how situational context affects how and whenspeakers produce them.2.2 CorrectionsGenerally speaking, a correction is an utterancewhich aims at signaling or remedying a misunder-standing between the participants of a conversa-tion.
In other word, corrections help (re)establishcommon ground (Clark, 1996).2.2.1 Previous WorkThere are many dimensions along which correc-tions can be analyzed and many researchers haveaddressed this issue.
Conversational Analysis(CA) has, from its early days, 1 concerned it-self with corrections (usually called repairs in CAwork) (Schegloff et al, 1977).More recently, spoken dialog systems re-searchers have investigated ways to automaticallyrecognize corrections.
For instance, Litman et al(2006) exploited features to automatically detectcorrection utterances.
In addition, several attemptshave been made to exploit the similarity in speechsounds and speech recognition results of a correc-tion and the previous user utterance to detect cor-rections (Kitaoka et al, 2003; Cevik et al, 2008).Going beyond a binary correction/non-correction classification scheme, Levow (1998)distinguished corrections of misrecognition errorsfrom corrections of rejection errors and foundthem to have different prosodic features.
Rog-driguez and Schlangen (2004) and Rieser andMoore (2005) classify corrections according totheir form (e.g.
Repetition, Paraphrase, Additionof information...) and function.
The latter aspectis mostly characterized in terms of the source ofthe problem that is being corrected using modelsof communication such as that of Clark (1996).In all of this very rich literature, corrections areassumed to target utterances from another partic-ipant (or even oneself, in the case of self-repair)that conflict with the hearer?s expectations.
Whilesome work on embodied conversational agents(Cassell et al, 2001; Traum and Rickel, 2002)does consider physical actions as possible cuesto errors and corrections, the actions are typicallycommunicative in nature (e.g.
nods, glances, ges-tures).
Comparatively, there is extremely littlework on corrections that target task actions.166A couple of exceptions are Traum et al (1999),who discuss the type of context representationneeded to handle action corrections, and Fu-nakoshi and Tokunaga (2006), who present amodel for identifying repair targets in human-robot command-and-control dialogs.
While im-portant, these papers focus on theoretical planningaspects of corrections whereas this paper focuseson an empirical analysis of human conversationalbehavior.2.2.2 Action Corrections in SituatedInteractionAs seen above, the vast majority of prior work oncorrections concerned corrections of previous (er-roneous) utterances (i.e.
utterance corrections).
Incontrast, in this paper, we focus exclusively oncorrections that target previous physical actions(i.e.
action corrections).While some classification schemes of utterancecorrections are applicable to task corrections (e.g.those based on the form of the correction itself),we focus on differences that are specific to actioncorrections.Namely, we distinguish three types of action er-rors and their related action corrections:Commission errors occur when Bob performs anaction that conflicts with Alice?s expectation.Action 4 of Figure 1 is a commission error,which is corrected in turn 5.Omission errors occur when Bob fails to react toone of Alice?s utterances.
A typical way forAlice to correct an omission error is to repeatthe utterance to which Bob did not react.Degree errors occur when Bob reacts with an ap-propriate action to Alice?s utterance but failsto completely fulfill Alice?s goal.
This is il-lustrated by Alice?s use of ?More?
in turn 7in response to Bob?s insufficient action 6.Figure 3 illustrates the three error categoriesbased on extracts from the corpus.In some ways, the dichotomy Commission er-rors/Omission errors parallels that of Misrecogni-tions/Rejections by Levow (1998).
This type ofclassification is also commonly used to analyzehuman errors in human factors research (Wick-ens et al, 1998).
In addition to these two cat-egories, we added the Degree category based onour observation of the data we collected.
This as-pect is somewhat specific to certain kinds of phys-ical actions (those that can be performed to differ-ent degrees, as opposed to binary actions such as?opening the door?).
However, it seems generalenough to be applied to many collaborative tasksrelevant to robots such as guidance, tele-operation,and joint construction.For an automated agent, being able to classifya user utterance into one of these four categories(including non-action-correction utterances) couldbe very useful to make fast, appropriate decisionssuch as canceling the current action, or asking aclarification question to the user.
This is impor-tant because in human-robot interaction, respon-siveness to a correction can be critical in avoidingphysical accidents.
For instance, if the robot de-tects that the user issued a commission error cor-rection, it can stop performing its current actioneven before understanding the details of the cor-rection.In the rest of the paper, we analyze some lexi-cal, prosodic and temporal characteristics of actioncorrections in the context of human-human con-versations in a virtual world.3 The Konbini Domain and System3.1 Simulated Environments forHuman-Robot Interaction ResearchOne obstacle to the empirical study of situated in-teraction is that it requires a fully functional so-phisticated robot to collect data and conduct ex-periments.
Most such complex robots are stillfragile and thus it is typically challenging to runuser studies with naive subjects without severelylimiting the tasks or the scope of the interaction.Another issue which comes with real world inter-action is that it is difficult for the experimenter tocontrol or monitor the events that affect the inter-action.
Most of the time, an expensive manualannotation of events and actions is required (seeOkita et al (2009) for an example of such an ex-perimental setup).To avoid these issues, robot simulators havebeen used.
Koulouri and Lauria (2009) devel-oped a simulator to collect dialogs between hu-man and simulated robot using a Wizard-of-Ozmethod.
The human can see a map of a town andteaches the robot a route and the operator oper-ates the robot but he/she can see only a small areaaround the robot in the map.
However, the dialog167is keyboard-based, and the situation does not dy-namically change in this setting, making this ap-proach unsuitable to the study of timing aspects.Byron and Fosler-Lussier (2006) describe a cor-pus of spoken dialogs collected in a setting verysimilar to the one we are using but, again, the en-vironment appears to be static, thus limiting theimportance of the timing of actions and utterances.In this section, we describe a realistic, PC-basedvirtual world that we used to collect human-humansituated dialogs.3.2 Experimental SetupIn our experiment, two human participants collab-orate in order to perform certain tasks pertainingto the management of a small convenience store ina virtual world.
The two participants sit in differ-ent rooms, both facing a computer that presentsa view of the virtual store.
One of the partici-pants, the Operator (O) controls a (simulated) hu-manoid robot whose role is to answer all customerrequests.
The other participant plays the role of aremote Manager (M) who sees the whole store butcan only interact with O through speech.Figure 2 shows the Operator and Managerviews.
M can see the whole store at any time, in-cluding how many customers there are and wherethey are.
In addition, M knows when a particu-lar customer has a request because the customer?scharacter starts blinking (initially green, then yel-low, then red, as time passes).
M?s role is then toguide O towards the customers needing attention.On the other hand, O sees the world through the?eyes?
of the robot, whose vision is limited bothin terms of field of view (90 degrees) and depth(degradation of vision with depth is produced byadding a virtual ?fog?
to the view).
When ap-proaching a customer who has a pending request,O?s view display the customer?s request in theform of a caption.1 O can act upon the virtualworld by clicking on certain object such as itemson the counter (to check them out), machines inthe store (to repair them when needed), and vari-ous objects littering the floor (to clean them up).Each action takes a certain amount of time to per-form (between 3 and 45 seconds), indicated by aprogress bar that decreases as O keeps the pointeron the target object and the left mouse buttondown.
Once the counter goes to zero the action is1No actual speech interaction happens between the Oper-ator and the simulated customers.completed and the participants receive 50 (for par-tially fulfilling a customer request) or 100 points(for completely fulfilling a request).When the session begins, customers start enter-ing the store at random intervals, with a maximumof 4 customers in the store at any time.
Each cus-tomer follows one of 14 predefined scenarios, eachinvolving between 1 and 5 requests.
Scenariosrepresent the customer?s moves in terms of fixedway points.
As a simplification, we did not imple-ment any reactive path planning.
Rather, the ex-perimenter, sitting in a different room than eithersubject has the ability to temporarily take controlof any customer to make them avoid obstacles.3.3 System Implementation: the SirosarchitectureThe experimental system described above was im-plemented using Siros (SItuated RObot Simula-tor) a new client/server architecture developed atHonda Research Institute USA to conduct human-robot interaction research in virtual worlds.
Sirosis similar to the architectures used by certain on-line video games.
The server?s role is to managethe virtual world and broadcast world updates toall clients so that they can be rendered to the hu-man participants.
The server receives commandsfrom the Operator client (robot moves), runs thesimulated customers according to the scenarios,and maintains the timer and the score.
Anytimethe trajectory of an entity (robot, customer, object)changes, the server broadcasts the related infor-mation, including entity location, orientation, andspeed, to all clients.Clients are in charge of rendering a given viewof the virtual world.
Rendering itself is performedby the open source Ogre 3D engine (Open Source3D Graphics Engine, 2010).
In addition, clientshandle all required user interaction such as robotcontrol and mouse-based object selection.
All net-work messages and user actions are logged intoa text file for further processing.
Finally, clientshave the ability to log incoming audio to a wavefile, allowing synchronization between the audiosignal, the user actions, and virtual world events.Spoken communication itself is handled by an ex-ternal VoIP client.22We used the open source Mumble/Murmur (Mum-ble/Murmur Project, 2010) system.168(a) Manager View (b) Robot ViewFigure 2: Screenshots of the Konbini data collection system.3.4 The Konbini Corpus3.4.1 Data CollectionUsing the system described above, we collecteddata from 18 participants.
There were 15 male and3 female participants.
All were adults living in theUnited States, fluent in English.
All were regularusers of computers but their experience with on-line games was diverse (from none at all to regu-lar player).
All were co-workers (associates or in-terns) at Honda Research Institute USA, and thusthey knew each other fairly well.Participants were randomly paired into teams.After being given the chance to read a brief in-troduction to the experiment?s design and goals,the participants did two two-minute practice ses-sions to familiarize themselves with the task andcontrol.
To avoid providing too much informa-tion about the layout of the store from the start,the practice sessions used a different virtual worldthan the experimental sessions.
The participantsswitched roles between the two practice sessionsto get a sense of what both roles entailed (Man-ager and Operator).
After these sessions, theteam did one 10-minute experimental session, thenswitched roles once again and did another 10-minute session.
Because the layout of the storewas kept the same between the two experimentalsessions, the first session represents a condition inwhich the Operator learns the store layout as theyare performing the tasks, whereas the second ses-sion corresponds to a case where the Operator al-ready has knowledge of the layout.
Overall, 18 10-minute sessions were collected, including audiorecordings as well as timestamped logs of worldupdates and operator actions.3.4.2 AnnotationAll recordings were orthographically transcribedand checked.
The first author then segmented thetranscripts into dialog acts (DAs).
A DA label wasattached to each act, though this information is notused in the present paper.Subsequently, the first author annotated eachsemantic unit with the action correction labelsdescribed in section 2: Non-correction, Omis-sion Correction, Commission Correction, DegreeCorrection.
This annotation was done using theAnvil video annotation tool,3 which presented au-dio recordings, transcripts, a timeline of operatoractions, as well as videos of the computer screensof the participants.
Only Manager DAs were anno-tated for corrections.
The second author also anno-tated a subset of the data in the same way to evalu-ate inter-annotator agreement.
Cohen?s kappa be-tween the two annotators was 0.67 for the 4-classtask, and 0.76 for the binary task of any-action-correction vs non-action-correction, which is rea-sonable, though not very high, indicating that cor-rection annotation on this type of dialogs is a non-trivial task, even for human annotators.4 Analysis of Action Corrections4.1 OverviewThe total number of DAs in the corpus is 6170.Of those, 826 are corrections and 5303 are non-corrections.
Overall, corrections account thus for13.4% of the dialog acts.
The split among the dif-ferent correction classes is roughly equal as shownin Table 5 given in appendix.
We found howeversignificant differences across participants, in terms3http://www.anvil-software.de169of total number of DAs (form 162 to 516), propor-tion of corrections among those DAs (from 6.8%to 30.6%), as well as distribution among the threetypes of action corrections.In this section, we present the results of our sta-tistical analysis of the correlation between a num-ber of features and correction type.
To evaluatestatistical significance, we performed a one-wayANOVA using each feature as dependent variableand the correction type as independent variable.All features described here were found to signifi-cantly correlate with correction type.4.2 Features Affecting Corrections4.2.1 TimingFor each manager DA, we computed the time sincethe beginning/end of the previous manager andoperator DAs, as well as of operator?s actions(walk/turn).
To account for reaction time, andbased on our observations we ignored events hap-pening less than 1 second before a DA.Table 1 shows the mean durations between theseevents and a Manager DA, depending on the act?scorrection class.
All corrections happen closer toManager dialog acts than non-corrections, whichreflects the fact that corrections typically occur inphases when the Manager gives instructions, aswell as the fact that the Manager often repeatscorrections.
Commission and Degree correctionsare produced closer to Operator actions than eithernon-corrections or Omission corrections.
This re-flects the fact that both Commission and Degreecorrections are a reaction to an event that occurred(the Operator moved or stopped moving unex-pectedly), whereas Omission corrections addressa lack of action from the Operator, and act there-fore as a ?time-out?
mechanism.To better understand the relationship betweenmoves and the timing of corrections, we computedthe probability of a given DA to be an Omission,Commission and Degree correction as a functionTime since last... NC O C DMgr.
DA 3.4 s 2.4 s 2.8 s 2.6 sOpe.
DA 5.8 s 6.7 s 6.5 s 7.5 sOpe.
move start 3.8 s 3.1 s 2.3 s 2.5 sOpe.
move end 3.9 s 3.3 s 2.7 s 2.3 sTable 1: Mean duration between dialog acts andOperator movements and the beginning of differ-ent corrections.Feature Non-Corr Om Com DegPerc.
voiced 0.48 0.46 0.55 0.53Min F0 -0.61 -0.41 -0.40 -0.56Max F0 0.81 0.68 1.02 0.46Mean F0 -0.03 0.12 0.28 -0.05Min Power -1.35 -1.24 -1.18 -1.55Max Power 0.85 0.89 1.14 0.62Mean Power -0.03 0.09 0.24 -0.2Table 2: Mean Z-score of prosodic features for dif-ferent correction classes.of the time elapsed since the Operator last startedto move.
Figure 4 shows the results.The probability of a DA being an Omission cor-rection is relatively stable over time.
This is con-sistent with the fact that Omission corrections arerelated to lack of action rather than to a specificaction to which the Manager reacts.
On the otherhand, the probability of a Commission, and tolesser extent, Degree correction sharply decreaseswith time after an action.4.2.2 ProsodyWe extracted F0 and intensity from all manageraudio files using the Praat software (Boersma andWeenink, 2010).
We then normalized pitch and in-tensity for each speaker using a Z-transform in or-der to account for individual differences in meanand standard deviation.
For each DA, we com-puted the minimum, maximum, and mean pitchand intensity, using values from voiced frames.Table 2 shows the mean Z-score of the prosodicfeatures for the different correction classes.
Com-mission corrections feature higher pitch and inten-sity than all other classes.
This is due to the factthat such corrections typically involve a higheremotional level, when the Manager is surprisedor even frustrated by the behavior of the Operator.In contrast, Degree corrections, which represent asmaller mismatch between the Operator?s actionand the Manager?s expectations are more subdued,with mean power and intensity values lower thaneven those of non-corrections.4.2.3 Lexical FeaturesIn order to identify potential lexical characteristicsof correction utterances, we created binary vari-ables indicating that a specific word from the vo-cabulary (804 distinct words in total) appears ina given DA based on the manual transcripts.
Wecomputed the mutual information of those binary170variables with DA?s correction label.Figure 3 shows the 10 words with highestmutual information.
Not surprisingly, negativewords (?NO?, ?DON?T?
), continuation words(?MORE?, ?KEEP?)
are correlated with respec-tively commission and degree corrections.
On theother hand, positive words (?OKAY?, ?YEAH?
)are strong indicators that a DA is not a correction.Another lexical feature we computed was a flagindicating that a certain Manager DA is an ex-act repetition of the immediately preceding Man-ager DA.
The intuition behind this feature is thatcorrections often involve repetitions (e.g.
?Turnleft [Operator turns right] Turn left!?).
Overall,10.6% of the DAs are repetitions.
This num-ber is only 6.4% on non-corrections but jumps to45.6%, 22.5%, and 43.4% on, respectively, Omis-sion, Commission, and Degree corrections.
Thisconfirms that, as for utterance corrections, detect-ing exact repetitions could prove useful for correc-tion classification.4.2.4 ASR FeaturesSince our goal is to build artificial agents, weinvestigated features related to automatic speechrecognition.
We used the Nuance Speech Recog-nition System v8.5.
Using cross-validation, wetrained a statistical language model for each cor-rection category on the transcripts of the trainingportion of the data.
We then ran the recognizer se-quentially with all 4 language models, which gen-erated a confidence score for each category.Table 4 shows the mean confidence scores ob-tained on DAs of each class using a languagemodel trained on specific classes.
While thematching LM gives the highest score for any givenclass, some classes have consistently higher scoresthan others.
In particular, Commission correctionsreceive low confidence scores, which might hurtthe effectiveness of these features.
Indeed, lexi-cal content alone might not be not enough to dis-tinguish non-corrections and various categories ofcorrections since the same expression (e.g.
?Turnleft?)
can express a simple instruction, or any kindof correction, depending on context.5 DiscussionThe results provide support for the correctionclassification scheme we proposed.
Not onlydo corrections differ in many respects from non-correction utterances, but there are also signifi-cant differences between Omission, Commission,PPPPPPPPLMCorr.NC O C DNon-Correction 32.3 28.5 25.0 29.5Omission 24.0 30.0 23.3 27.2Commission 26.6 29.8 25.7 27.9Degree 24.2 28.7 23.9 32.6Table 4: Mean ASR confidence score using class-specific LMs.and Degree corrections.
Timing features seemmost useful to distinguish Commission and De-gree corrections from Omission corrections andnon-corrections.
Emphasized prosody (high pitchand energy) is a particularly strong indicator ofCommission, as well as Omission corrections.Lexical cues could be useful to all categories, pro-vided the speech recognizer is accurate enough torecognize them, which is particularly challengingon this data given the very conversational natureof the speech.
Finally, ASR scores are also po-tentially useful features, particularly for Omissionand Degree corrections.One advantage of timing over all other featuresdiscussed here is that timing information is avail-able before the correction is actually uttered.
Thismeans that such information could be used to al-low fast reaction, or to prime the speech recog-nizer based on the instantaneous probability of thedifferent classes of correction.6 ConclusionIn this paper, we analyzed correction utterances inthe context of situated spoken interaction withina virtual world.
We proposed a classification ofaction correction utterances into Omission, Com-mission, and Degree corrections.
Our analysisof human-human data collected using a PC-basedsimulated environment shows that the three typesof corrections have unique characteristics in termsof prosody, lexical features, as well as timing withregards to physical actions.
These results canserve as the basis for further investigations into au-tomatic detection and understanding of correctionutterances in situated interaction.ReferencesPaul Boersma and David Weenink.
2010.Praat: doing phonetics by computer,http://www.fon.hum.uva.nl/praat.171Word (W) P (Non?
Corr|W ) P (Om|W ) P (Com|W ) P (Deg|W )MORE 0.41 0.01 0.02 0.56NO 0.55 0.04 0.33 0.07RIGHT 0.67 0.15 0.04 0.14TURN 0.69 0.17 0.06 0.08LEFT 0.65 0.18 0.07 0.10OKAY 0.99 0.00 0.00 0.00YEAH 0.99 0.00 0.00 0.00DON?T 0.59 0.01 0.33 0.07WAY 0.49 0.05 0.42 0.04KEEP 0.79 0.03 0.03 0.15Table 3: Keywords with highest mutual information with correction category.Donna K. Byron and Eric Fosler-Lussier.
2006.The OSU Quake 2004 corpus of two-party situatedproblem-solving dialogs.
In Proc.
15th LanguageResource and Evaluation Conference (LREC?06).Justine Cassell, Timothy Bickmore, Hannes HgniVilhja?msson, and Hao Yan.
2001.
More Than Just aPretty Face: Conversational Protocols and the Affor-dances of Embodiment.
Knowledge-Based Systems,14:55?64.Mert Cevik, Fuliang Weng, and Chin hui Lee.
2008.Detection of repetitions in spontaneous speech di-alogue sessions.
In Proc.
Interspeech 2008, pages471?474.Herbert Clark.
1996.
Using Language.
CambridgeUniversity Press.Kotaro Funakoshi and Takenobu Tokunaga.
2006.Identifying repair targets in action control dialogue.In Proc.
EACL 2006, pages 177?184.Petra Gieselman and Mari Ostendorf.
2007.
Problem-Sensitive Response Generation in Human-Robot Di-alogs.
In Proc.
SIGDIAL 2002.Norihide Kitaoka, Naoko Kakutani, and Seiichi Naka-gawa.
2003.
Detection and Recognition of Correc-tion Utterance in Spontaneously Spoken Dialog.
InProc.
Eurospeech 2003, pages 625?628.Theodora Koulouri and Stanislao Lauria.
2009.
Ex-ploring miscommunication and collaborative be-haviour in human-robot interaction.
In Proc.
SIG-DIAL 2009, pages 111?119.Gina-Anne Levow.
1998.
Characterizing and recog-nizing spoken corrections in human-computer dia-logue.
In Proc.
COLING-ACL ?98, pages 736?742.Diane Litman, Julia Hirschberg, and Marc Swerts.2006.
Characterizing and predicting corrections inspoken dialogue systems.
Computational Linguis-tics, 32(3):417?438.The Mumble/Murmur Project.
2010.http://mumble.sourceforge.net.Sandra Y Okita, Victor Ng-Thow-Hing, and Ravi KSarvadevabhatla.
2009.
Learning Together:ASIMO Developing an Interactive Learning Partner-ship with Children.
In Proc.
RO-MAN 2009.OGRE Open Source 3D Graphics Engine.
2010.http://www.ogre3d.org.Verena Rieser and Johanna Moore.
2005.
Implicationsfor generating clarification requests in task-orienteddialogues.
In Proc.
43rd Annual Meeting of the As-sociation for Computational Linguistics (ACL-05),pages 239?246.Kepa Josepa Rogdriguez and David Schlangen.
2004.Form, intonation and function of clarification re-quests in german task-oriented spoken dialogues.
InProc.
8th Workshop on the Semantics and Pragmat-ics of Dialogue (CATALOG?04).Emanuel A. Schegloff, Gail Jefferson, and HarveySacks.
1977.
The preference for self-correctionin the organization of repair in conversation.
Lan-guage, 53(2):361?382.David Traum and Jeff Rickel.
2002.
Embodiedagents for multiparty dialogue in immersive virtualworlds.
In Proc.
International Joint Conference onAutonomous Agents and Multi-agent Systems (AA-MAS 2002), pages 766?773.David R. Traum, Carl F. Andersen, Waiyian Chong,Darsana P. Josyula, Yoshi Okamoto, Khemdut Pu-rang, Michael O?Donovan-Anderson, and DonaldPerlis.
1999.
Representations of Dialogue Statefor Domain and Task Independent Meta-Dialogue.Electron.
Trans.
Artif.
Intell., 3(D):125?152.Christopher D. Wickens, Sallie E. Gordon, and YiliLiu.
1998.
An Introduction to Human Factors En-gineering.
Addison-Wesley Educational PublishersInc.172operatoractionoperatorutterancemanagerutterancewalkturnto yourrightforwardleftomissioncorrection3?13?
?to yourrightturn to yourright3?14??
3?15??
3?16?
?stop and ..ah too late(a) Omission correctionoperatoractionoperatorutterancemanagerutterancewalkturnforwardright2?49??
2?50??
2?51??commissioncorrection2?52?
?keep on going straight and then uhno nothe other way(b) Commission correctionoperatoractionoperatorutterancemanagerutterancewalkturnforwardright0?11??
0?12??
0?13??
0?14??leftdegreecorrection0?15??
0?16?
?morerightmorerightmorerightturn slightly right(c) Degree correctionFigure 3: Example omission, commission, and degree errors and corrections.
The corresponding videoscan be found at http://sites.google.com/site/antoineraux/konbini.1732 4 6 800.010.020.030.040.050.060.070.08Time since last move (s)P(Om)(a) Omissions2 4 6 800.010.020.030.040.050.06Time since last move (s)P(Com)(b) Commissions2 4 6 800.010.020.030.040.050.06Time since last move (s)P(Deg)(c) DegreeFigure 4: Evolution of the probability of occurrence of corrections over time after an Operator move.Participant Total Non-Corr Omission Commission DegreeTotal 6170 5303 (86.6%) 298 (4.8%) 277 (4.5%) 251 (4.1%)1 338 299 (88.5%) 19 (5.6%) 15 (4.4%) 5 (1.5%)2 249 232 (93.1%) 10 (4.0%) 2 (0.8%) 0 (0.0%)3 440 383 (87.0%) 25 (5.7%) 11 (2.5%) 9 (2.0%)4 265 247 (93.2%) 4 (1.5%) 8 (3.0%) 0 (0.0%)5 313 270 (86.3%) 15 (4.8%) 5 (1.6%) 17 (5.4%)6 238 198 (83.2%) 22 (9.2%) 13 (5.5%) 5 (2.1%)7 426 361 (84.7%) 30 (7.0%) 10 (2.3%) 23 (5.4%)8 244 218 (89.3%) 3 (1.2%) 13 (5.3%) 9 (3.7%)9 162 137 (84.6%) 4 (2.5%) 13 (8.0%) 8 (4.9%)10 229 202 (88.2%) 6 (2.6%) 3 (1.3%) 12 (5.2%)11 380 326 (85.8%) 16 (4.2%) 19 (5.0%) 19 (5.0%)12 427 385 (90.2%) 16 (3.7%) 11 (2.6%) 15 (3.5%)13 327 281 (85.9%) 5 (1.5%) 14 (4.3%) 27 (8.3%)14 516 358 (69.4%) 38 (7.4%) 79 (15.3%) 39 (7.6%)15 362 332 (91.7%) 13 (3.6%) 6 (1.7%) 11 (3.0%)16 392 321 (81.9%) 34 (8.7%) 27 (6.9%) 10 (2.6%)17 362 338 (85.4%) 19 (4.8%) 22 (5.6%) 17 (4.3%)18 466 415 (89.1%) 19 (4.1%) 6 (1.3%) 25 (5.4%)Table 5: Frequency of the different types of corrections per participant.174
