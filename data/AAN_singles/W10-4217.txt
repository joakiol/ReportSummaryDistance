Extracting Parallel Fragments from Comparable Corpora forData-to-text GenerationAnja Belz Eric KowNatural Language Technology GroupSchool of Computing, Mathematical and Information SciencesUniversity of BrightonBrighton BN2 4GJ, UK{asb,eykk10}@bton.ac.ukAbstractBuilding NLG systems, in particular sta-tistical ones, requires parallel data (pairedinputs and outputs) which do not gener-ally occur naturally.
In this paper, we in-vestigate the idea of automatically extract-ing parallel resources for data-to-text gen-eration from comparable corpora obtainedfrom the Web.
We describe our compa-rable corpus of data and texts relating toBritish hills and the techniques for extract-ing paired input/output fragments we havedeveloped so far.1 IntroductionStarting with Knight, Langkilde and Hatzivas-siloglou?s work on Nitrogen and its successorHalogen (Knight and Hatzivassiloglou, 1995;Knight and Langkilde, 2000), NLG has over thepast 15 years moved towards using statistical tech-niques, in particular in surface realisation (Langk-ilde, 2002; White, 2004), referring expressiongeneration (most of the sytems submitted to theTUNA and GREC shared task evaluation challengesare statistical, see Gatt et al (2008), for example),and data-to-text generation (Belz, 2008).The impetus for introducing statistical tech-niques in NLG can be said to have originally comefrom machine translation (MT),1 but unlike MT,where parallel corpora of inputs (source languagetexts) and outputs (translated texts) occur naturallyat least in some domains,2 NLG on the whole hasto use manually created input/output pairs.Data-to-text generation (D2T) is the type of NLGthat perhaps comes closest to having naturally oc-curing inputs and outputs at its disposal.
Workin D2T has involved different domains includinggenerating weather forecasts from meteorological1Nitrogen was conceived as an MT system component.2Canadian and European parliamentary proceedings, etc.data (Sripada et al, 2003), nursing reports from in-tensive care data (Portet et al, 2009), and museumexhibit descriptions from database records (Isardet al, 2003; Stock et al, 2007); types of data in-clude dynamic time-series data (e.g.
medical data)and static database entries (museum exhibits).While data and texts in the three example do-mains cited above do occur naturally, two factorsmean they cannot be used directly as example cor-pora or training data for building D2T systems:one, most are not freely available to researchers(e.g.
by simply being available on the Web), andtwo, more problematically, for the most part, thereis no direct correspondence between inputs andoutputs as there is, say, between a source languagetext and its translation.
On the whole, naturallyoccurring resources of data and related texts arenot strictly parallel, but are merely what has be-come known as comparable in the MT literature,with only a subset of data having correspondingtext fragments, and other text fragments havingno obvious corresponding data items.
Moreover,data transformations may be necessary before cor-responding text fragments can be identified.In this report, we look at the possibility of au-tomatically extracting parallel data-text fragmentsfrom comparable corpora in the case of D2T fromstatic database records.
Such a parallel data-textresource could then be used to train an existingD2T generation system, or even build a new statis-tical generator from scratch, e.g.
using techniquesfrom statistical MT (Belz and Kow, 2009).
Thesteps involved in going from comparable data andtext resources to generators that produce texts sim-ilar to those in the text resource are then as fol-lows: (1) identify sources on the Web for com-parable data and texts; (2) pair up data recordsand texts; (3) extract parallel fragments (sets ofdata fields paired with word strings); (4) train aD2T generator using the parallel fragments; and(5) feed data inputs to the generator which thenFigure 1: Overview of processing steps.generates new texts describing them.
Figure 1 il-lustrates steps 1?3 which this paper focuses on.
InSection 3 we look at steps 1 and 2; in Section 4 atstep 3.
First we briefly survey related work in MT.2 Related work in MTIn statistical MT, the expense of manually creat-ing new parallel MT corpora, and the need for verylarge amounts of parallel training data, has ledto a sizeable research effort to develop methodsfor automatically constructing parallel resources.This work typically starts by identifying compara-ble corpora.
Much of it has focused on identify-ing word translations in comparable corpora, e.g.Rapp?s approach was based on the simple and el-egant assumption that if words Af and Bf havea higher than chance co-occurrence frequency inone language, then two appropriate translationsAe and Be in another language will also havea higher than chance co-occurrence frequency(Rapp, 1995; Rapp, 1999).
At the other end ofthe spectrum, Resnik & Smith (2003) search theWeb to detect web pages that are translations ofeach other.
Other approaches aim to identify pairsof sentences (Munteanu and Marcu, 2005) or sub-sentential fragments (Munteanu and Marcu, 2006)that are parallel within comparable corpora.The latter approach is particularly relevant toour work.
They start by translating each docu-ment in the source language (SL) word for wordinto the target language (TL).
The result is givento an information retrieval (IR) system as a query,and the top 20 results are retained and paired withthe given SL document.
They then obtain all sen-tence pairs from each pair of SL and TL docu-ments, and discard those sentence pairs with fewwords that are translations of each other.
To the re-maining sentences they then apply a fragment de-tection method which tries to distinguish betweensource fragments that have a translation on the tar-get side, and fragments that do not.The biggest difference between the MT situationand the D2T situation is that in the latter sentence-aligned parallel resources exist and can be used asa starting point.
E.g.
Munteanu & Marcu use anexisting parallel Romanian-English corpus to (au-tomatically) create a lexicon from which is thenused in various ways in their method.In D2T we have no analogous resources to helpus get started, and the methods described in thispaper use no such prior knowledge.3 A Comparable Corpus of British HillsAs a source of data, we use the Database of BritishHills (BHDB) created by Chris Crocker,3 version11.3, which currently contains measurements andother information about 5,614 British hills.
Ad-ditionally, we perform reverse geocoding via theGoogle Map API4 which allows us to convertlatitude and longitude information from the hillsdatabase into country and region names.
We addthe latter to each database entry.On the text side, we use Wikipedia texts in theWikiProject British and Irish Hills (retrieved on2009-11-09).
There are currently 899 pages cov-ered by this WikiProject, 242 of which are of qual-ity category B or above.5Matching up data records and documents:Matching up the data records in the BHDB witharticles in Wikipedia is not trivial: not all BHDBentries have corresponding Wikipedia articles, dif-ferent hills often share the same name, and thesame hill can have different names and spellings.We perform a search of Wikipedia with the hill?sname as the search term, using the Mediawiki API,and then retain the top n search results returned(currently n = 1).
The top search result is notalways a correct match for the database record.
We3http://www.biber.fsnet.co.uk4http://code.google.com/apis/maps/5B = The article is mostly complete and without majorissues, but requires some further work.
{ "id": 1679, "main-name-info": {"name": "Hill of Stake", "notes": "","parent": "", "parent-notes": ""},"alt-name-info": [], "raw-name": "Hill of Stake", "rhb-section": "27A", "area": "Ayr to River Clyde","height-metres": 522, "height-feet": 1713, "map-1to50k": "63", "map-1to25k": "341N", "gridref": "NS273630","col-gridref": "NS320527", "col-height": 33, "drop": 489, "gridref10": "NS 27360 62998", "feature": "trig point","observations": "", "survey": "", "date-climbed": "", "classification": "Ma,CoH,CoU","county-name": "Renfrewshire(CoH); Renfrewshire(CoU)", "revision": "28-Oct-2001", "comments": "","streetmap": "http://www.streetmap.co.uk/newmap.srf?x=227356&y=663005&z=3&sv=227356,663005&st=4&tl=?&bi=?&lu=N&ar=n","ordanancesurvey-map": "http://getamap.ordnancesurvey.co.uk/getamap/frames.htm?mapAction=gaz&gazName=g&gazString=NS273630","x-coord": 227356, "y-coord": 663005, "latitude": 55.82931,"longitude": -4.75789, "country": "Scotland", "region": "Renfrewshire" }Hill of Stake is a hill on the boundary between North Ayrshire and Renfrewshire , Scotland .
It is 522 metres ( 1712 feet ) high.
It is one of the Marilyns of Lowland Scotland .
It is the highest point of the relatively low-lying county of Renfrewshire andindeed the entire Clyde Muirshiel Regional Park of which it is a part .Table 1: Output of step 1: data record from British Hills DB and matched Wikipedia text (Hill of Stake).manually selected the pairs we are confident are acorrect match.
This left us with 759 matched pairsout of a possible 899.Table 1 shows an example of an automaticallymatched database entry and Wikipedia article.
Itillustrates the non-parallelism discussed in the pre-ceding section; e.g.
there is no information in thedatabase corresponding to the last sentence.4 Towards a Parallelised Corpus4.1 Aligning data fields and sentencesIn the second processing step, we pair up datafields and sentences.
Related methods in MT havetranslation lexicons and thesauri that can be usedas bridges between SL and TL texts, but there isno equivalents in NLG.
Our current method asso-ciates each data field with a hand-written ?matchpredicate?.
For example, the match predicate forheight-metres returns True if the sentence con-tains the words ?X metres?
(among other patterns),where X is some number within 5% of the heightof the hill in the database.
We retain only the sen-tences that match at least one data field.
Table 2shows what the data field/sentence alignment pro-cedure outputs for the Hill of Stake.4.2 Identifying Parallel FragmentsWhile it was fine for step 2 to produce some roughmatches, in step 3, parallel fragment detection, theaim is to retain only those parts of a sentence thatcan be said to realise some data field(s) in the setof data fields with which it has been matched.Computing data-text associations: Followingsome preprocessing of sentences where each oc-currence of a hill?s name and height is replacedby lexical class tokens NAME , HEIGHT METRESor HEIGHT FEET , the first step is to construct akind of lexicon of pairs (d,w) of data fields d andwords w, such that w is often seen in the realisa-tion of d. For this purpose we adapt Munteanu& Marcu?s (2006) method for (language to lan-guage) lexicon construction.
For this purpose wecompute a measure of the strength of associationbetween data fields and words; we use the G2 log-likelihood ratio which has been widely used forthis sort of purpose (especially lexical association)since it was introduced to NLP (Dunning, 1993).Following Moore (2004a) rather than Munteanu &Marcu, our current notion of cooccurrence is thata data field and word cooccur if they are presentin the same pair of data fields and sentence (asidentified by the method described in Section 4.1above).
We then obtain counts for the number oftimes each word cooccurs with each data field, andthe number of times it occurs without the data fieldbeing present (and conversely).
This allows us tocompute the G2 score, for which we use the for-mulation from Moore (2004b) shown in Figure 2.If the G2 score for a given (d,w) pair is greaterthan p(d)p(w), then the association is taken to bepositive, i.e.
w is likely to be a realisation of d,otherwise the association is taken to be negative,i.e.
w is likely not to be part of a realisation of d.For each d we then convert G2 scores to proba-bilities by dividing G2 by the appropriate normal-ising factor (the sum over all negative G2 scoresfor d for obtaining the negative association proba-bilities, and analogously for positive associations).Table 3 shows the three words with the highestpositive association probabilities for each of oursix data fields.
Note that these are not the threemost likely alternative ?translations?
of each datakey, but rather the three words which are mostlikely to be part of a realisation of a data field, ifseen in conjunction with it.
"main-name-only": "Hill of Stake", NAME is a hill on the boundary between North Ayrshire and Renfrewshire,"country": "Scotland" Scotland.
"height-metres": 522, It is HEIGHT METERS metres ( HEIGHT FEET feet) high.
"height-feet": 1713"country": "Scotland", It is one of the Marilyns of Lowland Scotland.
"classification": ["Ma", "CoH", "CoU"]"main-name-only": "Hill of Stake" It is the highest point of the relatively low-lying county of Renfrewshire andindeed the entire Clyde Muirshiel Regional Park of which it is a part.Table 2: Output of step 2: aligned data fields and sentences, for Hill of Stake.2N(p(d,w)log p(d,w)p(d)p(w) + p(d,?w)logp(d,?w)p(d)p(?w) + p(?d,w)logp(?d,w)p(?d)p(w) + p(?d,?w)logp(?d,?w)p(?d)p(?w))Figure 2: Formula for computing G2 from Moore (2004b) (N is the sample size).Data key d Word w P+(w|d)main-name-only NAME 0.1355a 0.0742in 0.0660classification as 0.0412adjoining 0.0193qualifies 0.0177region District 0.1855Lake 0.1661area 0.1095country in 0.1640NAME 0.1122Scotland 0.0732height-metres metres 0.1255m 0.0791height 0.0679height-feet feet 0.1511HEIGHT METERS 0.0974( 0.0900Table 3: Data keys with 3 most likely words.Identifying realisations: The next step is to ap-ply these probabilities to identify those parts of asentence that are likely to be a valid realisation ofthe data fields in the input.
In Figure 3 we plotthe positive and negative association probabilitiesfor one of the sentences from our running exam-ple, Hill of Stake.
The light grey graph representsthe association probabilities between each wordin the sentence and height-feet, the dark greyline those between the words in the sentence andheight-metres.
We plot the negative associationprobabilities simply by multiplying each by ?1.The part of the sentence that one wouldwant to extract as a possible realisation of{ height-metres, height-feet }, namely?
HEIGHT METRES metres ( HEIGHT FEET feet )high?, shows up clearly as a sequence of relativelystrong positive association values.
Our currentapproach identifies such contiguous positiveFigure 3: Positive and negative association prob-abilities plotted against the words they were com-puted for.association scores and extracts the correspondingsentence fragments.
This works well in manycases, but is too simple as a general approach; weare currently developing this method further.5 Concluding RemarksIn this paper we have been interested in the prob-lem of automatically obtaining parallel corpora fordata-to-text generation.
We presented our com-parable corpus of 759 paired database entries andhuman-authored articles about British Hills.
Wedescribed the three techniques which we have im-plemented so far and which we combine to extractparallel data-text fragments from the corpus: (i)identification of candidate pairs of data fields andsentences; (ii) computing scores for the strengthof association between data and words; and (iii)identifying sequences of words in sentences thathave positive association scores with the givendata fields.ReferencesAnja Belz and Eric Kow.
2009.
System building costvs.
output quality in data-to-text generation.
In Pro-ceedings of the 12th European Workshop on NaturalLanguage Generation, pages 16?24.A.
Belz.
2008.
Automatic generation of weatherforecast texts using comprehensive probabilisticgeneration-space models.
Natural Language Engi-neering, 14(4):431?455.Ted Dunning.
1993.
Accurate methods for the statis-tics of surprise and coincidence.
ComputationalLinguistics, 1:61?74.A.
Gatt, A. Belz, and E. Kow.
2008.
The TUNAChallenge 2008: Overview and evaluation results.In Proceedings of the 5th International NaturalLanguage Generation Conference (INLG?08), pages198?206.A.
Isard, J. Oberlander, I. Androutsopoulos, andC.
Matheson.
2003.
Speaking the users?
languages.18(1):40?45.K.
Knight and V. Hatzivassiloglou.
1995.
Two-level,many-paths generation.
In Proceedings of the 33rdAnnual Meeting of the Association for Computa-tional Linguistics (ACL ?95).Kevin Knight and Irene Langkilde.
2000.
Preservingambiguity in generation via automata intersection.In Proceedings of AAAI/IAAI, pages 697?702.I.
Langkilde.
2002.
An empirical verification of cover-age and correctness for a general-purpose sentencegenerator.
In Proc.
2nd International Natural Lan-guage Generation Conference (INLG ?02).Robert C. Moore.
2004a.
Improving ibm word-alignment model 1.
In Proceedings of the 42nd An-nual Meeting of the Association for ComputationalLinguistics, pages 519?526.Robert C. Moore.
2004b.
On log-likelihood-ratios andthe significance of rare events.
In Proceedings ofthe 9th Converence on Empirical Methods in Natu-ral Language Processing (EMNLP?04), pages 333?340.Dragos Munteanu and Daniel Marcu.
2005.
Improv-ing machine translation performance by exploitingnon-parallel corpora.
Computational Linguistics,31:477?504.Dragos Stefan Munteanu and Daniel Marcu.
2006.
Ex-tracting parallel sub-sentential fragments from non-parallel corpora.
In Proceedings of the 21st In-ternational Conference on Computational Linguis-tics and the 44th annual meeting of the Associationfor Computational Linguistics (COLING-ACL?06),pages 81?88, Morristown, NJ, USA.
Association forComputational Linguistics.F.
Portet, E. Reiter, A. Gatt, J.
Hunter, S. Sripada,Y.
Freer, and C. Sykes.
2009.
Automatic gener-ation of textual summaries from neonatal intensivecare data.
Artificial Intelligence, 173:789?816.Reinhard Rapp.
1995.
Identifying word translations innon-parallel texts.
In Proceedings of the 33rd an-nual meeting on Association for Computational Lin-guistics, pages 320?322, Morristown, NJ, USA.
As-sociation for Computational Linguistics.Reinhard Rapp.
1999.
Automatic identification ofword translations from unrelated english and germancorpora.
In Proceedings of the 37th annual meetingof the Association for Computational Linguistics onComputational Linguistics, pages 519?526, Morris-town, NJ, USA.
Association for Computational Lin-guistics.Philip Resnik and Noah Smith.
2003.
The web as aparallel corpus.
Computational Linguistics, 29:349?380.S.
Sripada, E. Reiter, J.
Hunter, and J. Yu.
2003.
Ex-ploiting a parallel text-data corpus.
In Proceedingsof Corpus Linguistics 2003, pages 734?743.Oliviero Stock, Massimo Zancanaro, Paolo Busettaadn Charles Callaway, Anbtonio Kru?ger, MichaelKruppa, Tsvi Kuflik, Elena Not, and Cesare Rocchi.2007.
Adaptive, intelligent presentation of informa-tion for the museum visitor in PEACH.
User Mod-eling and User-Adapted Interaction, 17(3):257?304.M.
White.
2004.
Reining in CCG chart realization.
InA.
Belz, R. Evans, and P. Piwek, editors, Proceed-ings INLG?04, volume 3123 of LNAI, pages 182?191.
Springer.
