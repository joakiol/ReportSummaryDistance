A Synopsis of Learning to Recognize Names Across LanguagesAnthony F. GallippiUnivers i ty  o f  Southern Cal i forniaUnivers i ty  Park, EEB 234Los  Angeles,  CA  90089USAgall ippi @ aludra.usc.eduAbstractThe development ofnatural language processing (NLP)systems that perform machine translation (MT) andinformation retrieval (IR) has highlighted the need forthe automatic recognition of proper names.
While vari-ous name recognizers have been developed, they sufferfrom being too limited; some only recognize one nameclass, and all are language specific.
This work devel-ops an approach to multilingual name recognition thatuses machine learning and a portable framework tosimplify the porting task by maximizing reuse and au-tomation.1 IntroductionProper names represent a unique challenge for MT andIR systems.
They are not found in dictionaries, arevery large in number, come and go every day, and ap-pear in many alias forms.
For these reasons, list basedmatching schemes do not achieve desired performancelevels.
Hand coded heuristics can be developed toachieve high accuracy, however this approach lacksportability.
Much human effort is needed to port thesystem to a new domain.A desirable approach is one that maximizes reuseand minimizes human effort.
This paper presents anapproach to proper name recognition that uses machinelearning and a language independent framework.Knowledge incorporated into the framework is basedon a set of measurable inguistic characteristics, or fea-tures.
Some of this knowledge is constant across lan-guages.
The rest can be generated automaticallythrough machine learning techniques.Whether a phrase (or word) is a proper name, andwhat type of proper name it is (company name, loca-tion name, person name, date, other) depends on (1) theinternal structure of the phrase, and (2) the surroundingcontext.Internal: 'qVlr.
Brandon"Context: 'The new compan.~= Safetek, will makeair bags.
"The person title "Mr." reliably shows "Mr. Brandon" tobe a person name.
"Safetek" can be recognized as acompany name by utilizing the preceding contextualphrase and appositive "The new company,".The recognition task can be broken down into de-l imitation and classi f icat ion.
Delimitation is the de-termination of the boundaries of the proper name,while classification serves to provide a more specificcategory.Original:Delimit:John Smith, chairman of Safetek, announcedhis resignation yesterday.<PN> John Smith </PN>, chairman of <PN>Safetek </PN> , announced his resignationyesterday.Classify: <person> John Smith </person>, chairman of<company> Safetek </company>, announcedhis resignation yesterday.During the delimit step, proper name boundaries areidentified.
Next, the delimited names are categorized.2 MethodThe approach taken here is to utilize a data-drivenknowledge acquisition strategy based on decision treeswhich uses contextual information.
This differs fromother approaches (Farwell et al, 1994; Kitani & Mita-mura, 1994; McDonald, 1993; Rau, 1992) whichattempt to achieve this task by: (1) hand-coded heuris-tics, (2) list-based matching schemes, (3) human-gen-erated knowledge bases, and (4) combinations thereof.Delimitation occurs through the application ofphrasal templates.
These templates, built by hand, uselogical operators (AND, OR, etc.)
to combine featuresstrongly associated with proper names, including:proper noun, ampersand, hyphen, and comma.
In addi-tion, ambiguities with delimitation are handled by in-cluding other predictive features within the templates.To acquire the knowledge required for classifica-tion, each word is tagged with all of its associated fea-tures.
Various types of features indicate the type ofname: parts of speech (POS), designators,357Figure 1.
Multilingual development system.morphology, syntax, semantics, and more.
Designatorsare features which alone provide strong evidence for oragainst a particular name type.
Examples include"Co." (company), "Dr." (person), and "County"(location).Features are derived through automated and manualtechniques.
On-line lists can quickly provide usefulfeatures uch as cities, family names, nationalities, etc.Proven POS taggers (Farwell et al, 1994; Brill, 1992;Matsumoto et al, 1992) predetermine POS features.Other features are derived through statistical measuresand hand analysis.A decision tree is built (for each name class) fromthe initial feature set using a recursive partitioning al-gorithm (Quinlan, 1986; Breiman et al, 1984) that usesthe following function as its splitting criterion:-p*log2(p) - (1-p)*log2(1-p) (1)where p represents the proportion of names within atree node belonging to the class for which the tree isbuilt.
The feature which minimizes the weighted sumof this function across both child nodes resulting froma split is chosen.
A multitree approach was chosenover learning a single tree for all name classes becauseit allows for the straightforward association of featureswithin the tree with specific name classes, and facili-tates troubleshooting.
Once built, the trees are all ap-plied individually, and then the results are merged.Trees typically contained 100 or more nodes.In order to work with another language, the follow-ing resources are needed: (1) pre-tagged training textin the new language using same tags as before, (2) atokenizer for non-token languages, (3) a POS tagger(plus translation of the tags to a standard POS conven-tion), and (4) translation of designators and lexical(list-based) features.Figure 1 shows the working development system.The starting point is training text which has been pre-tagged with the locations of all proper names.
The tok-enizer separates punctuation from words.
For non-to-ken languages (no spaces between words), it also sepa-rates contiguous characters into constituent words.
ThePOS tagger (Brill, 1992; Farwell et.
al., 1994; Matsu-moto et al 1992) attaches parts of speech.
The set ofderived features is attached.
Names are delimitedusing a set of POS based hand-coded templates.
A de-cision tree is built based on the existing feature set andthe specified level of context o be considered.
Thegenerated tree is applied to test data and scored.
Handanalysis of results leads to the discovery of new fea-tures.
The new features are added to the tokenizedtraining text, and the process repeats.Language-specific modules are highlighted withbold borders.
Feature translation occurs through theutilization of: on-line resources, dictionaries, atlases,bilingual speakers, etc.
The remainder is constantacross languages: a language independent core, and anoptimally derived feature set for English.
Parts of thedevelopment system that are executed by hand appearshaded.
Everything else is automatic.3 ExperimentThe system was first built for English and then portedto Spanish and Japanese.
For English, the training textconsisted of 50 messages obtained from the EnglishJoint Ventures (E/V) domain MUC-5 corpus of the USAdvanced Research Projects Agency (ARPA).
Thisdata was hand-tagged with the locations of companies,persons, locations, dates, and "other".
The test set con-sisted of 10 new messages from the same corpus.Experimental results were obtained by applying thegenerated trees to test texts.
Proper names which arevoted into more than one class are handled by choosingthe highest priority class.
Priorities are determinedbased on the independent accuracy of each tree.
Themetrics used were recall (R), precision (P), and anaveraging measure, P&R, defined as:P&R = 2*P*R/(P+R) (2)Obtained results for English compare to the English re-suits of Rau (1992) and McDonald (1993).
The358weighted average of P&R for companies, persons, lo-cations, and dates is 94.0% (see Table 2).The date grammar is rather small in comparison toother name classes, hence the performance for dateswas perfect.
Locations, by contrast, exhibited the low-est performance.
This can be attributed mainly to: (I)locations are commonly associated with commas,which can create ambiguities with delimitation, and (2)locations made up a small percentage of all names inthe training set, which could have resulted in overfit-ting of the built tree to the training data.Three experiments were conducted for Spanish.First, the English trees, generated from the feature setoptimized for English, are applied to the Spanish text(E-E-S).
In the second experiment, new Spanish-specific trees are generated from the feature setoptimized for English and applied to the Spanish testtext (S-E-S).
The third experiment proceeds like thesecond, except hat minor adjustments and additionsare made to the feature set with the goal of improvingperformance (S-S-S).The additional resources required for the firstSpanish experiment (E-E-S) are a Spanish POS tagger(Farwell et aL, 1994) and also the translated feature set(including POS) optimally derived for English.
Thesecond and third Spanish experiments (S-E-S, S-S-S)require in addition pre-tagged Spanish training text us-ing the same tags as for English.The additional features derived for S-S-S are shownin Table 1 (FN/LN=given/family name, NNP=propernoun, DE="de").
Only a few new features allows forsignificant performance improvement.Table 1.
Spanish specific features for S-S-S.Type Feature Instances How manyList Companies "IBM", "AT&T', ... 100Keyword "del" (OF THE) 1Template Person < FN DE LN > 1Person < FN DE NNP > 1Date < Num OF MM > 1Date <Num OF MM OF Num> 1The same three experiments are being conductedfor Japanese.
The first two, E-E-J and J-E-J, have beencompleted; J-J-J is in progress.
Table 2 summarizesperformance r sults and compares them to other work.AcknowledgmentsThe author would like to offer special thanks and grati-tude to Eduard Hovy for all ofhis support, direction,and encouragement from the onset of this work.Thanks also to Kevin Knight for his early suggestions,and to the Information Sciences Institute for use oftheir facilities and resources.Table 2.
Performance comparison to other work.System Language Class R P P&RRan English Com NA 95 NAPNF English Com NA NA "Near(McDonald) Pets 100%"LocDatePanglyzer Spanish NA NA 80 NAMAJESTY Japanese Corn 84.3 81.4 82,8Pers 93.1 98.6 95,8Loc 92.6 96.8 94.7MNR English Corn 97.6 91.6 94.5(Gallippi) Pers 98.2 100 99.1Loc 85.7 91.7 88.6Date 100 100 100(Avg) 94.0MNR Spanish Corn 74.1 90.9 81.6Pers 97.4 79.2 87.4Loc 93.1 87.5 89.4Date 100 100 100(Avg) 89.2MNR Japanese Corn 60.0 60.0 60.0Pers 86.5 84.9 85.7Loc 80.4 82.1 81.3Date 90.0 94.7 92.3(Avg) 83.1ReferencesBreiman, L., Friedman, J.H., Olshen, R.A., and Stone,C.J.
1984.
Classification and Regression Trees.Wadsworth International Group.Brill, E. 1992.
A Simple Rule-Based Part ofSpeech Tagger.
In Proceedings of the ThirdConference on Applied Natural Language Processing,ACL.Farwell, D., Helmreich, S., Jin, W., Casper, M.,Hargrave, J., Molina-Salgado, H., and Weng, F. 1994.Panglyzer: Spanish Language Analysis System.
InProceedings of the Conference of the Association ofMachine Translation in the Americas (ATMA).Columbia, MD.Kitani, T. and Mitamura, T. 1994.
An AccurateMorphological  Analysis and Proper NameIdentification for Japanese Text Processing.
InTransactions of Information Processing Society ofJapan, Vol.
35, No.
3, pp.
404-413.Matsumoto, Y., Kurohashi, S., Taegi, H. andNagao, M. 1992.
JUMAN Users' Manual Version 0.8,Nagao Laboratory, Kyoto University.McDonald, D. 1993.
Internal and ExternalEvidence in the Identification and SemanticCategorization of Proper Names.
In Proceedings oftheSINGLEX workshop on "Acquisition of LexicalKnowledge from Text", pp.
32-43.Quinlan, J.R. 1986.
Induction of Decision Trees.In Machine Learning, pp.
81-106.359
