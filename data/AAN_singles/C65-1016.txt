161965 International Conference on Computational LinguisticsSETS OF GRAMMARS BETWEEN CONTEXT-FREEAND CONTEXT-SENSITIVEPeter KugelTechnical Operations ResearchSouth AvenueBurlington, Mass.U.S.A., : ;~ '  ' e / %,' # .A B S T R A C TWe discuss some sets of g rammars  whose generative power liesbetween that of the set of context-free grammars  and that of the set of context-sensitive grammars .
These sets are developed by subjecting eneratorsof context-sensitive grammars  to abstract versions of a "hardware" restr ict ionto which the users  of natural anguages, unlike the descr ibers  of natural angu-ages, might be subject.Kugel 1The notion of a formal grammar was first introduced to provide formalmodels of techniques used by the descr ibers of natural anguages (linguists)(1).
Later, formal grammars  have been used as models of the capabilitiesof users of natural anguages (See (2) for a review).
Language users differfrom language descr ibers in being subject o restr ict ions on the amount ofnhardwareW that they have available to them and the amount of time that theyhave to perform their operations.
Where the linguist has available (at leasttheoretically) an unlimited amount of material  with which (pencil) and on which(paper) to store his intermediate r sults, it is probable that the internal organi-zation of the natural anguage user may not permit him the use of such unlimitedre source s.Therefore, when one uses a formal grammar as a model of the languageuser, one may consider the effects of subjecting such grammars  to abstractversions of certain types of hardware limitations.
One model in this vein ist hat of Yngve (3) which considers the natural anguage user to be like a devicecapable of dealing with context-free languages and then subjects it to furtherlimitations.
However, there are reasons for thinking that natural anguageusers may have available to them powers beyond those of the context-freegrammars.
According to current views, these additional powers are those thatare required to construct transformational grammars.
Among these one mightinclude the ability to permute the order of elements in a string and the abilityto erase elements (4).The ability to effect the permutation of elements is a property of context-sensitive grammars.
However, context-sensitive grammars  have additionaldrawbacks as models for the capabilities of the users of natural anguages (1).Permitt ing erasure as an element the generation of a phrase marker has thedifficulty that it is not always clear whether the resulting rewrit ing systems.generate only recursive sets of strings.
These considerations suggest hat oneThus, any semi-Thue system (For a definition see (5), p. 84) can be lookedat as a context-free grammar which permits the shortening of strings (erasure).But semi-Thue systems are capable of generating non-recursive sets of strings((5), Theorem 2.6, p. 93).Kugel 2might want some context-sensit ivity and some erasure but not enough to pro-duce the undesirable features of context-sensit ive grammar  or of semi-Thuesystems.One way of getting at such grammars  might be to consider a device forgenerating context-sensit ive languages and subjecting it to abstract versions oft he types of hardware l imitations to which the users of natural anguage usersmight be sjubect.Assume that users  of natural languages are information processing systemsorganized in the manner of the present-day digital computer.
They have astorage unit (memory),a processing unit, and some input/output equipment.
Oneway of suggesting the roles of these parts is to say that they correspond roughlyto those parts of the handling of a natural anguage that are described by thesemantic, syntactic and phonetic omponents of a language description respect -ively.
Since our concern in this paper is largely with the syntactic omponent,we will consider l imitations on the effects of l imitations on the processing unit.Suppose that the processing unit has the machinery for applying the rewrit ingrules of context-sensit ive grammar ,  but that this application has to be done bychanging the state of something like a reg ister  in the arithmetic unit of a present-day computer.
Such a reg ister  can be looked at as a sequence of pigeon holes intowhich symbols can be placed.
A rule then is applied to change the contents of thepigeonholes and the results  are returned to the memory or output.
To say thatthe reg is ters  have a given size is to say that there is only a fixed number of such.pigeon-holes .
Such an assumption finds a formal analogue in the notion of aformal grammar  as a restr ict ion on the length of the str ings that can appear oneither side of the arrow in a rewrit ing rule.
To say that a reg is ter  has only npigeon-holes i  to say that the str ings on either side of the arrow can contain at**most n symbols.
However, such a restr ict ion does not accomplish much thatWe are also assuming that there is no way of doing anything like multipleprecision arithmetic.
**Or, equivalently, that the string on the right hand side of the arrow cancontain at most n symbols.Kugel 3/is of interest, for it is easy to prove that:Theorem 1: The set of all g rammars  that contain strings of no more thantwo symbols on either side of their rewrit ing rules has the generative power ofthe set of context-sensit ive grammars .
The set of all g rammars  that containno more than three symbols in any rewrit ing rule has the generative power of.the set of context-f lee grammars .It is c lear from an examination of the proof of the f irst part of this theoremthat the restr ict ion on the length of the strings used in stating rules of thegrammar is overcome by introducing new letters.
Such an introduction ofadditional letters is common in proofs of theorems about formal g rammars  andit is reasonable so long as one is considering these grammars  as models of theprocedures used by language descr ibers  who have available to them a medium(pencil marks on paper} which is unlimited not only in amount, but which permitsan unlimited variety of symbols within a given space (at least in theory}.The fact that language users  might have to represent their grammaticalcatagories in a discrete rather  than continuous medium suggests that one mightl imit the number of available (distinct) symbols that can appear in a rule ofgrammar.
However, this restr ict ion also is of no great interest since we canprove the following:Theorem 2: There is a sense in which the generative power of grammars  whoserules can be expressed using only two distinct symbols in its vocabulary is equiv-alent to the set of all context-sensit ive grammars.Suppose, therefore, that one attempts to limit both of these simultaneously.Thus, let us define a "grammar of size (m, p)S as a grammar  whose rules areconstructed of strings (on either side of the rewrit ing ru le 's  arrows) such thatno string contains more than m occurrences of letters and such that the non-$Definitions and proofs of theorems can be found in the appendix.Explicated in the appendix.Kugel 4terminal  vocabulary of the grammars  contains no more than p distinct letters.Let us f irst consider such grammars  as augmented simply by dictionaries.These grammars  turn out to be curious hybrids.
For one thing, given a size,there is only a finite number of g rammars  of that size (if one equates traight-forward re letter ings of the same grammars) .
Furthermore:Theorem 3: The set of g rammars  of size (m, p) with dictionaries, forsufficiently large m and p, cannot generate all context-free languages and cangenerate some languages which are not context f lee.Nevertheless, it is obvious that the union of the grammars  of size(m, p) for all values of m and p has the generative power of the set of allcontext-sensit ive grammars  (since any context-sensit ive grammar  has somefinite size).These grammars  are not part icularly interesting because we have putl imits on the amount of recurs ion that can appear in them.
This can be over-come by permitting some recurs ion either in a pre-  or post-processor,  l imitingrecurs ion to context-free ru les only.
Thus, we are led to consider systemsconsisting of three parts in tandem.
The f irst part is a context-free grammar,the second part is a g rammar  of size (m, p), and the third is a dictionary.Although such systems appear to be rather ad ho% one can give some argumentsfor considering them.
The arguments for the two grammars  in tandem areroughly those for a context-free grammar  followed by a transformationalcomponent.
If we allow erasure  in the final processing we can permit our inter-mediate string generated by the context-free grammar  to be the phrase markerin something approximating Polish notation.
Thus, the phrase marker:/ \Kugel 5could be represented by the string SACxDyBz.
The context-sensitive grammarof restr icted size could operate on these markers in the manner of a trans-formational component.
The dictionary would contain rules of the form X--*, A--*,etc.
,  to erase the non-terminal symbols.
This argument suggests that if onewants such a system as a model for a natural anguage user one might considerdifferent primitive operations in the part of the system that was to represent thetransformational component.
Thus, using the suggestion of (4) one might permitnot only what we have been calling grammar ules but also rules which permutethe order of strings directly such as rules of the form: XYZ--*ZYX.
By makingthese primitive one makes them cost less of the "size" of the underlying rammar.The argument for allowing something like a dictionary is that something of thissort appears to be required for the phonetic omponent of a language descriptionanyway.Let us call such systems "grammar systems of size (m, p). "
Those systemswhich have primitive permutation rules we might call "permutation systems.
"We can prove:Theorem 4: Grammar systems define infinite hierarchies of languagesL 0.
.. L i.
.. such that (a) L 0 is the set of context-free languages; (2) L i~  Ljfor j sufficiently greater than i and (3) the sum of the L i for all i is the set ofcontext- sensitive language s.We have suggested that if a natural anguage user is organized like a present-day digital computer he might find that the size of the registers in what correspondsto his "processing unit" might have an effect on the kinds of languages with whichhe could deal.
We have given a rather prel iminary sketch of how this mightoccur.
Such effects appear however, to be crit ically dependent on the "machinecode" of such a system, and in view of the current lack of knowledge as to whatthis code might be, it is not clear whether the kinds of notions that we havediscussed have any applications in computational linguistics, even if the under-lying notion of some sort of a "register" limitation applies to the competenceof natural anguage users.Kugel 6APPENDIXThis appendix contains definit ions of some of the te rms used in the bodyof the paper and proofs of the theorems.
We begin by defining some basicnotions.
A rewr i t ing  rule is a ru le of the form PhQ-*PHQ where  P, Q, h, andH are (possibly empty*) str ings.
If h is a single le t ter  and H is a non-emptystr ing of le t te rs  a rewr i t ing  ru le is ca l led a grammar  ru le .
A grammar  (or acontext-sens i t ive grammar  ) G is a single letter  S together with a finite set ofg rammar  ru les .
The @phabet of G is the set of all l e t te rs  in rewr i t ing ru lesof G. The non- termina l  vocabulary of G is the set of all l e t te rs  appearing on theleft hand side of some grammar  rule in G. The termina l  vocabulary of G is thealphabet of G minus the non- termina l  vocabulary of G. We wil l  assume that Sis always in the non- termina l  vocabulary of G.A set of rewr i t ing  ru les  which contains no non- termina l  le t ters  on the r ight-hand side of a rewr i t ing rule is cal led a dict ionary.
If P and Q in all the grammarru les  of G are  empty,then G is a context- f ree grammar .
A der ivat ion of a str ingS n in a grammar  G is a sequence of str ings S 1, .
.
.
,  S n such that S 1 is S and suchthat S i +1 is the resu l t  of replac ing some sequence of le t te rs  L in S i by a sequenceof le t ters  L' such that L - -L '  is one of the grammar  ru les  of G. The languagegenerated by a grammar  G is the set of all str ings M such that there exists ader ivat ion of M in G, and such that M cons ists  of only le t ters  in the terminalvocabulary of G. Two sets of g rammars  that generate the same sets of languagesare said to have t_he same generat ive power.Theorem h (a) The set of g rammars  , none of whose ru les  contain morethan four le t ters ,  has the same generat ive power as the set of context-sensi t ivegrammars .
(b) The set of g rammars  none of whose ru les  contain more thanthree le t ters  has the generat ive power of the set of all context f ree grammars .PhQ, however,  is not empty (i. e .
,  not all of P, h, and Q can be empty).Kugel 7Proof: (a) In order  to prove this part of the theorem we need only presentan effective procedure for replacing each of the ru les  of an arb i t rary  context-sensit ive grammar  G with a set of ru les  containing no more  than two let ters  one i ther  side of the arrow, and such that the generat ive power of the resul t inggrammar  G' remains  the same.
Consider an arb i t rary  rule of the form L--R,where L=a 1 .
.
.a  i .
.
.
a j  andR=al .
.
.a .
l _ lb  1 .
.
.bka i+ 1 .
.
.a j .
Replace this bythe following new ru les  in which the c and d are new let ters  not in the alphabet m mof G:Rulesa la2_a lc  2c2a3-'*c2c 3Cnan+ ~'CnCn + 1c i _ l'ai-*Ci_lCiaj _ laj--,-dj lajaj 2dj - l"*dj - 2dj - 1andn + l"*dndn + 1$cidi - 1-'*didi - 1Effect of Added Rulesa l '  " ' ai(ai+ 1" " "aj )-~alc 2.
.. ci(a i + 1" " ' aj)(ale2" " ' )ciai+ 1" " "aj-"(c 1" ' ' )di" ' "dj _ laj$In schematiz ing the effects of a sequence of ru les  we have assumed anorder  in their  application.
However, where the order  of application is arb i t raryparts of the str ings might be dif ferent if the order  of application were  different.These parts are indicated by surrounding them with parentheses.Kugel 8Rules Effect of Added Rulesdi-'bld'i + 1d ) d'i+ n-~bn- 1 i+n+ld'i+k_ l-'b k( .
.
.
)d i ( .
.. ) - * ( .
.
.
)b l .
.
.bc ( .
.
.
)c2-*a2:' ' lci - l~a i  - 1a lc  2.
?.
c i _ 1 (.. ?
)-*a 1.
.. a i _ l ( .
?
?
)di+ l-~ai+.
1 1d.--a.
J J( " ' )d i+ l ' "d j  -'~ ( ' ' ' )a i+ l ' ' '  ajThe equivalence in the other direct ion (i. e .
,  the fact that all four letterg rammars  are at most  context sensit ive) is obvious.
(b) Because of the definit ion of a "grammar  ule n ru les  containing threele t ters  can only be of the form a-*bc (and not ab~c)  so c lear ly  all three letterru les  are context- f ree.
To produce a three letter  equivalent of a longer context-f ree rule, say a---a 1. .
a one replaces it by the ru les  a-~ala~, .. ~ , -~ a' 1'?
n ' - i  - i  i + ' " 'a'-*a where the a?
are new letters.
n n }Theorem 2: The set of g rammars  containing only two letter  together wi thadict ionary has the generat ive power of the set of all context sensit ive grammars .Proof: Let the two le t ters  be 0 and 1.
Again, it is only necessary  to providean effective procedure for replacing any rule in a given context-sens i t ive grammarwith a new set of ru les  containing only two letter,  plus some dict ionary rules.Kugel 9Suppose that G contains m rules and that the alphabet of G contains n letters.Let each rule be of the form Li-*R i (for the i-th rule).
We construct G' asfollows:To replace each rule Li--*R i we add new rules as follows:Rewrite each letter a. in L i by the string: \]~/jth position011... 1100011... O... 110 (= a!
)m t imes n t imeslth positionThe first replacing rule takes the revised L i into 0111..~0... 11000... Theeffect of this is to tag the string as being subjected to rule number i.
The secondreplacing rule takes the 0 in the n-tuple of ones of the letter being replaced, andit turns it into a 1.
If the only effect of the rule is to simply replace this letterby another letter, the rest  of the new rules place the 0 in the n-tuple appropriatelyand then erase the tag in the left-most m--tuple to signal the end of the applica-tion of the rule.
If the replaced letter is expanded then the replacements areadded one letter at a time and the process is finished off by "untagging" the left-most m-tuple in the replacement for L i.The dictionary has the job of translating back into the vocabulary of G. Itlacks any procedures for dealing with letters whose m-tuple is not all one's sothat no intermediate product of a rule can be terminal.
The dictionary is simplythe set of rules a!-~a, for each a. in the terminal vocabulary of G. It is clear thatJ J JG' generates exactly the same language as G.This proof suggests a problem that might be of some interest.
In devisinga procedure for reducing the number of letters in what is, in some sense, aprogram, one is required to add new rules.
These rules introduce intermediateproducts (strings), and the basic problem in the proof was that of devising a wayin which these intermediate products can be prevented from being caught up byrules other than those that are intended to apply to them.
We have used anextremely straightforward technique for doing this but this technique is costlyin the size of the required strings.Kugel 10One might ask what more efficient general procedures there are for suchreduction.
A reason for asking this question (other than a theoretic interest} isthat the world as seen by a biological organism can be looked at as consistingof an arbi t rary alphabet, the units (or letters} of v&ich are the basic perceptsof that organism.
However, the organismTs brain might have a fixed alphabetinto which the processing of this (probably larger} alphabet has to be encoded.Such encoding would probably have to be done by an algorithm that avoided thiscrossing of intermediate products.We define a grammar  of size (m, p) as a set of g rammar  ules which hasa non-terminal  vocabulary of no more than m letters and such that no rulecontains a string of more than p occurrences of letters on the right handside of the arrow.Theorem 3: The set of g rammars  of size (m, p) plus an arb i t rary  number ofdictionary rules for sufficiently large m and p, cannot generate all context-freelanguages and can generate some languages that are not context-free.Proof: Consider the language that consists of the str ingsbi repeated an arbitrary number of t imesaib i.
?.
bia ifor some range r of i, (1 ..< i :.< r}.
If r > im then this language cannot bei=1generated by a grammar  of size (m, p) since all the recurs ion must be in thei=pcontext-sensit ive part.
But there are only ~, im distinct left hand sides ofi=1such rules so that the grammar  must generate some string of the formaib i. .
.
bia i for i ?
j.
Since any context sensitive grammar  is a g rammar  ofsize (m, p) and since Chomsky has proved that not all context-sensit ive languagesare context free (6), it is obvious that there are languages generated by grammarsof size (m, p} for sufficiently large (m, p) that are not context-free.
We define agrammar  system of size (m, p) as three rewrit ing systems, the f irst of which isa context-free grammar,  the second of which is a g rammar  of size (m, p} and thethird of which is a dictionary.
The language generated by such a system is definedin the obvious way.Kugel 11Theorem 4: The sets of languages generated by grammar systems of size(mxp),where mxp = y, define a hierarchy of languages L such that (a) L 0 is theYset of context-free languages, (b) L. ~ L. for j sufficiently greater than i, and1 j(c) such that the sum of the L is the set of context-sensit ive languages.YProof: The set of languages whose strings are of the form PhP, where his a fixed string and P are arbitrary strings on a given alphabet A, are context-sensitive and not context-free (6).
Therefore, in a grammar system whichgenerates such a language,the part that generates such strings must be in thecontext-sensitive part.
Although the dictionary can introduce arbitrary newletters it cannot insure that if the substitution for some given letter a i is to beaj at one time and a k at another, that the substitutions in a given string will beuniform (i. e. ,  always aj and never ak) for the entire length of an arbitrari ly longstring.
Therefore, the rules of the context-sensitive part of the grammarsystem generating PhP must have different letters (or distinct strings representingdifferent letters) in the left-hand side of its rules.
But in the grammar generatingthe copy of a given string P there must be at least one rule to produce the effectof copying each letter of A.
If we let the alphabet of A be larger than mxp, thenthis cannot occur in a grammar of size (m, p).Therefore, for every grammar of size (m, p) there is a context-sensit ivelanguage that cannot be generated by a grammar system limited to a grammar ofthat size.
But clearly this language can be generated by a system having agrammar of some finite size.
This proves part (b).
Part (a) of the theorem isproved by observing that the set of context free languages are generated by agrammar system with a grammar of size (0, 0).
This is so because the content-sensitive part is empty and the amount of erasure that can be produced by anydictionary is always finite and therefore its effect can be incorporated into acontext-free grammar.
Part (c) of the theorem is obvious.Kugel 12R E F E R E N C E Sl o2...e6.Chomsky, N., Syntactic Structures, Mouton, 1957.Miller, G.A.
and Chomsky, N., "Finitary Models of Language Users"in Handbook of Mathematical.Psychology r (Luce, Bush andGalanter eds. )
Volume 2, John Wiley, 1963.Yngve, V.H., "A Model and an Hypothesis for Language Structure",Proceedings of the American Philosophical Society, Volume 104,pp.
444-466, 1960.Fraser, J .B .
,  "Some Remarks on Elementary Transformations", inQuarterly Progress Report of the Research Laboratory ofElectronics (M. I. T. ), No.
71.Davis, M., Computability and Unsolvabilityj McGraw-Hil l ,  1958.Chomsky, N., "On Certain Formal Properties of Grammars", Infor-mation and Control, Volume 2, pp, 137-167, 1959.
