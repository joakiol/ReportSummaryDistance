Proceedings of the Sixth Workshop on Innovative Use of NLP for Building Educational Applications, pages 1?9,Portland, Oregon, 24 June 2011. c?2011 Association for Computational LinguisticsAutomatic Question Generation using Discourse CuesManish Agarwal?, Rakshit Shah?
and Prashanth MannemLanguage Technologies Research CenterInternational Institute of Information TechnologyHyderabad, AP, India - 500032{manish.agarwal, rakshit.shah, prashanth}@research.iiit.ac.inAbstractIn this paper, we present a system that au-tomatically generates questions from naturallanguage text using discourse connectives.
Weexplore the usefulness of the discourse con-nectives for Question Generation (QG) thatlooks at the problem beyond sentence level.Our work divides the QG task into content se-lection and question formation.
Content se-lection consists of finding the relevant part intext to frame question from while question for-mation involves sense disambiguation of thediscourse connectives, identification of ques-tion type and applying syntactic transforma-tions on the content.
The system is evaluatedmanually for syntactic and semantic correct-ness.1 IntroductionAutomatic QG from sentences and paragraphs hascaught the attention of the NLP community in thelast few years through the question generation work-shops and the shared task in 2010 (QGSTEC, 2010).Previous work in this area has concentrated on gen-erating questions from individual sentences (Vargaand Ha, 2010; Paland et al, 2010; Ali et al, 2010).Sneiders and E. (2002) used question templates andHeilman et al (2009) used general-purpose rulesto transform sentences into questions.
A notableexception is Mannem et al (2010) who generatedquestions of various scopes (general, medium andspecific) ?
1 from paragraphs instead of individual?First two authors contributed equally to this work1General scope - entire or almost entire paragraph, Mediumscope - multiple clauses or sentences, and Specific scope - sen-sentences.
They boil down the QG from paragraphstask into first identifying the sentences in the para-graph with general, medium and specific scopes andthen generating the corresponding questions fromthese sentences using semantic roles of predicates.Discourse connectives play a vital role in mak-ing the text coherent.
They connect two clausesor sentences exhibiting discourse relations such astemporal, causal, elaboration, contrast, result,etc.
Discourse relations have been shown to be use-ful to generate questions (Prasad and Joshi, 2008)but identifying these relations in the text is a difficulttask (Pitler et al, 2009).
So in this work, instead ofidentifying discourse relations and generating ques-tions using them, we explore the usefulness of dis-course connectives for QG.
We do this by analyzingthe senses of the connectives that help in QG andpropose a system that makes use of this analysis togenerate questions of the type why, when, give anexample and yes/no.The two main problems in QG are identifying thecontent to ask a question on and finding the corre-sponding question type for that content.
We ana-lyze the connectives in terms of the content usefulfor question generation based on the senses they ex-hibit.
We show that the senses of the connectivesfurther help in choosing the relevant question typefor the content.In this paper, we present an end-to-end QG sys-tem that takes a document as input and outputs allthe questions generated using the selected discourseconnectives.
The system has been evaluated man-ually by two evaluators for syntactic and semantictence or less1correctness of the generated questions.
The over-all system has been rated 6.3 out of 8 for QGSTECdevelopment dataset and 5.8 out of 8 for Wikipediadataset.2 OverviewQuestion Generation involves two tasks, contentselection (the text selected for question generation)and question formation (transformations on the con-tent to get the question).
Question formation furtherhas the subtasks of (i) finding suitable question type(wh-word), (ii) auxiliary and main verb transforma-tions and (iii) rearranging the phrases to get the finalquestion.There are 100 distinct types of discourse connec-tives listed in PDTB manual (PDTB, 2007).
Themost frequent connectives in PDTB are and, or,but, when, because, since, also, although, forexample, however and as a result.
In this paper,we provide analysis for four subordinating conjunc-tions, since, when, because and although, and threeadverbials, for example, for instance and as a re-sult.
Connectives such as and, or and also show-ing conjunction relation have not been found tobe good candidates for generating wh-type ques-tions and hence have not been discussed in the pa-per.
Leaving aside and, or and also, the selectedconnectives cover 52.05 per cent of the total numberof the connectives in QGSTEC-2010 2 dataset and41.97 per cent in Wikipedia articles.
Connective-wise coverage in both the datasets is shown in Table1.
Though but and however denoting contrast re-lation occur frequently in the data, it has not beenfeasible to generate wh-questions using them.QGSTEC-2010 Dev.
Data Wikipedia DatasetConnective count % count %because 20 16.53 36 10.28since 9 7.44 18 5.14when 23 19.00 35 10.00although 4 3.30 22 6.28as a result 5 4.13 6 1.71for example 2 1.65 30 8.28for instance 0 0.00 1 0.28Total 121 52.05 350 41.97Table 1: Coverage of the selected discourse connec-tives in the dataThe system goes through the entire document and2QGSTEC 2010 data set involves Wikipedia, Yahoo An-swers and OpenLearn articles.identifies the sentences containing at least one of theseven discourse connectives.
In our approach, suit-able content for each discourse connective which isreferred to as target argument is decided based onthe properties of discourse connective.
The systemfinds the question type on the basis of discourse re-lation shown by discourse connective.3 Discourse connectives for QGIn this section, we provide an analysis of dis-course connectives with respect to their target argu-ments and the question types they take.3.1 Question type identificationThe sense of the discourse connective influencesthe question-type (Q-type).
Since few discourseconnectives such as when, since and althoughamong the selected ones can show multiple senses,the task of sense disambiguation of the connectivesis essential for finding the question type.Since: The connective can show temporal, causalor temporal + causal relation in a sentence.
Sen-tence exhibits temporal relation in presence of key-words like time(7 am), year (1989 or 1980s), start,begin, end, date(9/11), month (January) etc.
If therelation is temporal then the question-type is whenwhereas in case of causal relation it would be why.1.
Single wicket has rarely been played since lim-ited overs cricket began.Q-type: when2.
Half-court games require less cardiovascularstamina , since players need not run back andforth a full court.Q-type: whyIn examples 1 and 2, 1 is identified to show tem-poral relation because it has the keyword beganwhereas there is no keyword in the context of ex-ample 2 that gives the hint of temporal relation andso the relation here is identified as causal.When: Consider the sentences with connec-tive when in Figure 1.
Although when showsmultiple senses (temporal, temporal+causal andconditional), we can frame questions by a singlequestion type, when.
Given a new instance ofthe connective, finding the correct sense of when2Sentence:  The San?Francisco earthquake hit when resources in the field already were stetched.
(Temporal)Sentence:  Venice?s long decline started in the 15th century, when it first made an unsuccessful attempt to hold ThessalonicaSentence:   Earthquake mainly occurs when the different blocks or plates that make up the Earth?s surface move relative toQuestion:   When do earthquake mainly occur ?each other, causing distortion in the rock.
( Conditional )Question:   When did San?Francisco earthquake hit ?against the Ottomans (1423?1430).
( Temporal + Causal )Question:  When did Venice?s long decline start in the 15th century ?Figure 1: Questions for discourse connective whenDiscourse Sense Q-typeconnectivesbecause causal whysince temporal whencausal whywhencausal + temporalwhentemporalconditionalalthough contrast yes/ noconcessionas a result result whyfor example instantiation give an examplewherefor instance instantiation give an instancewhereTable 2: Question type for discourse connectivesbecomes unnecessary as a result of using discourseconnectives.Although: The connective can show concessionor contrast discourse relations.
It is difficult to framea wh-question on contrast or concession relations.So, system generates a yes/no type question for al-though.
Moreover, yes/no question-type adds to thevariety of questions generated by the system.3.
Greek colonies were not politically controlledby their founding cities , although they oftenretained religious and commercial links withthem .Q-type: Yes/NoA yes/no question could have been asked forconnectives but and however denoting a contrast re-lation but it was not done to preserve the question-type variety in the final output of the QG system.Y es/no questions have been asked for occurrencesof although since they occur less frequently thanbut and however.Identifying the question types for other selecteddiscourse connectives is straight forward becausethey broadly show only one discourse relation(Pitler and Nenkova, 2009).
Based on the relationsexhibited by these connectives, Table 2 shows thequestion types for each discourse connective.3.2 Target arguments for discourse connectivesA discourse connective can realize its two argu-ments, Arg1 and Arg2, structurally and anaphori-cally.
Arg2 is always realized structurally whereasArg1 can be either structural or anaphoric (PDTB,2007; Prasad et al, 2010).4.
[Arg1 Organisms inherit the characteristics oftheir parents] because [Arg2 the cells of theoffspring contain copies of the genes in theirparents?
cells.
](Intra-sentential connective be-cause)5.
[Arg1 The scorers are directed by the hand sig-nals of an umpire.]
For example, [Arg2 theumpire raises a forefinger to signal that thebatsman is out (has been dismissed); he raisesboth arms above his head if the batsman hashit the ball for six runs.
](Inter-sentential con-nective for example)Consider examples 4 and 5.
In 4, Arg1 and Arg2are the structural arguments of the connective be-cause whereas in 5, Arg2 is the structural argumentand Arg1 is realized anaphorically.The task of content selection involves finding thetarget argument (either Arg1 or Arg2) of the dis-course connective.
Since both the arguments are po-tential candidates for QG, we analyze the data toidentify which argument makes better content foreach of the connectives.
Our system selects one ofthe two arguments based on the properties of the dis-course connectives.
Table 3 shows the target argu-3Discourse connective Target argumentbecause Arg1since Arg1when Arg1although Arg1as a result Arg2for example Arg1for instance Arg1Table 3: Target argument for discourse connectivesment i.e.
either Arg1 or Arg2, which is used as con-tent for QG.4 Target Argument IdentificationTarget argument for a discourse connective canbe a clause(s) or a sentence(s).
It could be one ormore sentences in case of inter-sentential3 discourseconnectives, whereas one or more clauses in case ofintra-sentential4 connectives.Discourse connectives for example and for in-stance can realize its Arg1 anywhere in the prior dis-course (Elwell and Baldridge, 2008).
So the systemconsiders only those sentences in which the connec-tives occur at the beginning of the sentence and theimmediate previous sentence is assumed to be theArg1 of the connective (which is the target argumentfor QG).In case of intra-sentential connectives (because,since, although and when) and as a result (target ar-gument is Arg2 which would be a clause), identifi-cation of target argument is done in two steps.
Thesystem first locates the syntactic head or head verbof the target argument and then extracts it from thedependency tree of the sentence.4.1 Locate syntactic headApproach for locating the syntactic head of tar-get argument is explained with the help of Figure 2(generic dependency trees) and an example shownin Figure 3.
Syntactic head of Arg2 is the first fi-nite verb while percolating up in the dependency treestarting from the discourse connective.
In case ofintra-sentential connectives where Arg1 is the targetargument, the system percolates up until it gets thesecond finite verb which is assumed to be target head3Connectives that realize its Arg1 anaphorically and Arg2structurally4Connectives that realize both of its arguments structurallyX          P         ZDC        A(a)                                            (b)1   1V                                           V2  X          V           ZV2DC         A                                     QFigure 2: Head selection of the target argumentfor intra-sentential connectives (V1,V2: finite verbs;X,Z: subtrees of V1; A: subtree of V2; P,Q:Not verbs;DC:discourse connective(child of V2))of Arg1.
Number of percolations entirely depend onstructure and complexity of the sentence.
Figure 2shows two dependency trees (a) and (b).
Startingfrom the discourse connective DC and percolatingup, the system identifies that the head of Arg2 is V2and that of Arg1 is V1.aux : "is"playedcompetitivebadmintonis    indoorsby     because   flight    iswind                shuttlecockWhy is competitive badminton played indoors ?affectedBecause(From section 2.1)                      (From section 2.2)qtype : "Why"                        Target Arg Head : "played"(section 2.3)[Arg2 shuttlecock flight is affected by wind],[Arg1 competitive badminton is played indoors].
(content)Figure 3: Question Generation processSince the discourse connective in the example ofFigure 3 is because, the target argument is Arg1(from Table 2).
By percolating up the tree startingfrom because, the head of Arg2 is affected and thatof Arg1 is played.
Once we locate the head of thetarget argument, we find the auxiliary as Mannemet al (2010) does.
For the example in Figure 3, theauxiliary for question generation is is.4.2 Target Argument ExtractionThe extraction of the target argument is done af-ter identifying its syntactic head.
For as a result,the target argument, Arg2, is the subtree with head4Score Description Example4 The question is grammatically correct and idiomatic/natural.
In which type of animals are phagocytes highly developed?3 The question is grammatically correct but does not read as In which type of animals are phagocytes, which are importantfluently as we would like.
throughout the animal kingdom, highly developed?2 There are some grammatical errors in the question.
In which type of animals is phagocytes, which are importantthroughout the animal kingdom, highly developed?1 The question is grammatically unacceptable.
On which type of animals is phagocytes, which are importantthroughout the animal kingdom, developed?Table 4: Evaluation guidelines for syntactic correctness measureas the head of the connective.
For intra-sententialconnectives, the target argument, Arg1, is the treeremaining after removing the subtree that containsArg2.In Figures 2 (a) and (b) both, a tree with headV1 and its children, X and Z, is left after removingArg2 from dependency trees, which is the contentrequired for generating the question.
Note that in thetree of Figure 2(b), the child P of the head verb V1 isremoved with its entire subtree that contains Arg2.Thus, subtree with head V2 is the unwanted part forthe tree in Figure 2(a) whereas subtree with head Pis the unwanted part for the tree in Figure 2(b) whenthe target argument is Arg1.In Figure 3, after removing the unwanted argu-ment Arg2 (subtree with head affected), the systemgets competitive badminton is played indoors whichis the required clause (content) for question genera-tion.
The next section describes how the content istransformed into a question.5 Syntactic Transformations and QuestionGenerationThe syntactic transformations used in this workare similar to those by Mannem et al (2010).
At thisstage, the system has the question type, auxiliary andthe content.
The following set of transformationsare applied on the content to get the final question.
(1) If the auxiliary is present in the sentence itselfthen it is moved to the beginning of the sentence;otherwise auxiliary is added at the beginning of thesentence.
(2) If a wh-question is to be formed, thequestion word is added just before the auxiliary.
Incase of Yes/No questions, the question starts withthe auxiliary itself as no question word is needed.
(3)A question-mark(?)
is added at the end to completethe question.Consider the example in Figure 3.
Here the con-tent is competitive badminton is played indoors.Applying the transformations, the auxiliary is firstmoved at the start of the sentence to get is compet-itive badminton played indoors.
Then the questiontype Why is added just before the auxiliary is, anda question-mark is added at the end to get the finalquestion, Why is competitive badminton played in-doors ?Scope: In QGSTEC 2010 the question had to beassigned a scope, specific, medium or general.
Thescope is defined as: general - entire input paragraph,medium - one or more clauses or sentences and spe-cific - phrase or less.
Questions generated using dis-course connectives are usually of the scope specificor medium.
Mannem et al (2010) assigned mediumscope to the questions generated using the seman-tic roles such as ARGM-DIS (result), ARGM-CAU(causal) and ARGM-PNC (purpose) given by theSRL.
However, most of the times, the scope of theanswer to these questions is just a clause or a sen-tence and should have been assigned specific scopeinstead of medium.6 Evaluation and ResultsAutomatic evaluation of any natural languagegenerated text is difficult.
So, our system is eval-uated manually.
The evaluation was performedby two graduate students with good English profi-ciency.
Evaluators were asked to rate the questionson the scale of 1 to 4 (4 being the best score) on syn-tactic and semantic correctness (Evalguide, 2010)of the question and an overall rating on the scale of8 (4+4) is assigned to each question.The syntactic correctness is rated to ensure thatthe system can generate grammatical output.
In ad-dition, those questions which read fluently are givengreater score.
The syntactic correctness and fluencyis evaluated using the following scores: 4 - gram-5Discourse ExampleConnectivebecauseOne-handed backhand players move to the net with greater ease than two-handed playersbecause the shot permits greater forward momentum and has greater similarities in musclememory to the preferred type of backhand volley (one-handed, for greater reach ).Why do one-handed backhand players move to the net with greater ease than two-handedplayers ?
(Causal)sinceHalf-court games require less cardiovascular stamina, since players need not run back andforth a full court.Why do half-court games require less cardiovascular stamina ?
(Causal)Single wicket has rarely been played since limited overs cricket began.Since when has single wicket rarely been played ?
(Temporal)when A one-point shot can be earned when shooting from the foul line after a foul is made.When can a one-point shot be earned ?
(Conditional)althoughA bowler cannot bowl two successive overs, although a bowler can bowl unchanged atend for several overs.Can a bowler bowl unchanged at the same end for several overs?
(Contrast, concession)as a resultIn the United States sleep deprivation is common with students because almost all schoolsbegin early in the morning and many of these students either choose to stay up awake late intothe night or cannot do otherwise due to delayed sleep phase syndrome.
As a result, studentsthat should be getting between 8.5 and 9.25 hours of sleep are getting only 7 hours.Why are students that should be getting between 8.5 and 9.25 hours of sleep gettingonly 7 hours?
(Result)As a result of studies showing the effects of sleep-deprivation on grades , and the differentsleep patterns for teenagers , a school in New Zealand , changed its start time to 10:30,in 2006, to allow students to keep to a schedule that allowed more sleep.Why did a school in New Zealand change its start time ?
(Result)for exampleSlicing also causes the shuttlecock to travel much slower than the arm movement suggests.For example, a good cross court sliced drop shot will use a hitting action that suggests a straightclear or smash, deceiving the opponent about both the power and direction of the shuttlecock.Give an example where slicing also causes the shuttlecock to travel much slower thanthe arm movement suggests.
(Instantiation)for instanceIf the team that bats last scores enough runs to win, it is said to have ?won by n wickets?,where n is the number of wickets left to fall.
For instance a team that passes its opponents?score having only lost six wickets would have won ?by four wickets?.Give an instance where if the team that bats last scores enough runs to win, it is said to have?won by n wickets?,where n is the number of wickets left to fall.
(Instantiation)Table 5: Examplesmatically correct and idiomatic/natural, 3 - gram-matically correct, 2 - some grammar problems, 1 -grammatically unacceptable.
Table 4 shows syntac-tic correctness measure with examples.The semantic correctness is evaluated using thefollowing scores: 4 - semantically correct and id-iomatic/natural, 3 - semantically correct and close tothe text or other questions, 2 - some semantic issues,1 - semantically unacceptable.Table 5 shows questions generated by the systemfor each connective.
The results of our system onQGSTEC-2010 development dataset are shown inTable 6.
The overall system is rated 6.3 out of 8 onthis dataset and the total number of questions gen-erated for this dataset is 61.
The instances of theconnectives were less in the QGSTEC-2010 devel-opment dataset.
So, the system is further tested onfive Wikipedia articles (football, cricket, basketball,badminton and tennis) for effective evaluation.
Re-sults on this dataset are presented in Table 7.
Overallrating of the system is 5.8 out of 8 for this datasetand 150 are the total number of questions generatedfor this dataset.
The ratings presented in the Tables 6and 7 are the average of the ratings given by both theevaluators.
The inter-evaluator agreement (Cohen?skappa coefficient) for the QGSTEC-2010 develop-6ment dataset for syntactic correctness measure is 0.6and is 0.5 for semantic correctness measure, and incase of Wikipedia articles the agreement is 0.7 and0.6 for syntactic and semantic correctness measuresrespectively.Discourse No.
of Syntactic Semantic Overallconnective questions Correctness(4) Correctness(4) Rating(8)because 20 3.6 3.6 7.2since 9 3.8 3.2 7when 23 2.3 2.2 4.5although 4 4 3.8 7.8as a result 5 4 4 8Overall 61 3.2 3.1 6.3Table 6: Results on QGSTEC-2010 developmentdatasetDiscourse No.
of Syntactic Semantic Overallconnective questions Correctness(4) Correctness(4) Rating(8)because 36 3.3 3.2 6.5since 18 3.1 3 6.1when 35 2.4 2.0 4.4although 22 3.1 2.8 5.9as a result 6 3.6 3.2 6.8for example 16 3.1 2.9 6.0for instance 2 4 3 7Overall 135 3.0 2.8 5.8Table 7: Results on the Wikipedia data(cricket, foot-ball, basketball, badminton, tennis)On analyzing the data, we found that theWikipedia articles have more complex sentences(with unusual structure as well as more number ofclauses) than QGSTEC-2010 development dataset.As a result, the system?s performance consistentlydrops for all the connectives in case of Wikipediadataset.No comparable evaluation was done as none ofthe earlier works in QG exploited the discourse con-nectives in text to generate questions.7 Error AnalysisAn error analysis was carried out on the system?soutput and the four most frequent types of errors arediscussed in this section.7.1 Coreference resolutionThe system doesn?t handle coreference resolutionand as a result of this, many questions have beenrated low for semantic correctness by the evalua-tors.
Greater the number of pronouns in the ques-tion, lesser is the semantic rating of the question.6.
They grow in height when they reach shallowerwater, in a wave shoaling process.Question: When do they grow in height?Although the above example 6 is syntacticallycorrect, such questions are rated semantically lowbecause the context is not sufficient to answer thequestion due to the pronouns in it.
13.54% ofthe generated questions on the Wikipedia datasethave pronouns without their antecedents, making thequestions semantically insufficient.7.2 Parsing ErrorsSometimes the parser fails to give a correct parsefor the sentences with complex structure.
In suchcases, the system generates a question that is unac-ceptable.
Consider the examples below.7.
In a family who know that both parents are car-riers of CF , either because they already have aCF child or as a result of carrier testing , PNDallows the conversion of a probable risk of thedisease affecting an unborn child to nearer acertainty that it will or will not be affected.Question: Why do in a family who know thatboth parents are carriers of CF , either or willnot be affected ?In example 7 above, the sentence has a com-plex structure containing paired connective, either-or, where the argument of either has because andthat of or has as a result in it.
Here the question isformed using because which is correct neither syn-tactically nor semantically due to the complex natureof the sentence.
9.38% sentences in the datasets arecomplex with either three or more discourse connec-tives.7.3 Errors due to the inter-sententialconnectivesFor inter-sentential connectives, system considersonly those sentences in which the connectives occurat the beginning of the sentence and the immediateprevious sentence is assumed to be the Arg1 of theconnective (which is the target argument for QG).But this assumption is not always true.
Of the totalnumber of instances of these connectives, 52.94%(for Wikipedia dataset) connectives occur at the be-ginning of the sentences.
Consider the paragraph be-low.8.
A game point occurs in tennis whenever the7player who is in the lead in the game needs onlyone more point to win the game.
The termi-nology is extended to sets (set point), matches(match point), and even championships (cham-pionship point).
For example, if the player whois serving has a score of 40-love, the player hasa triple game point (triple set point, etc.)
as theplayer has three consecutive chances to win thegame.Here in example 8, the third sentence in which theexample is specified is related to the first sentencebut not the immediately previous sentence.
For theseconnectives, the assumption that immediate previ-ous sentence is Arg1 is false 14.29% of the times.7.4 Fluency issuesThe system does not handle the removal of pred-icative adjuncts.
So the questions with optionalphrases in it are rated low for syntactic correctnessmeasure.8 Conclusions and Future WorkOur QG system generates questions using dis-course connectives for different question types.
Inthis work, we present an end-to-end system thattakes a document as input and outputs all the ques-tions for selected discourse connectives.
The systemhas been evaluated for syntactic and semantic sound-ness of the question by two evaluators.
We haveshown that some specific discourse relations are im-portant such as causal, temporal and result thanothers from the QG point of view.
This work alsoshows that discourse connectives are good enoughfor QG and that there is no need for full fledged dis-course parsing.
In the near future, we plan to im-plement coreference resolution and sentences withmore than two connectives.
We aim to improve thesystem with respect to the sentence complexity andalso incorporate other discourse connectives.AcknowledgementsWe would like to thank Suman Yelati and SudheerKolachina from LTRC, IIIT-Hyderabad for theirhelpful discussions and pointers during the course ofthis work.
Thanks also to the anonymous reviewersfor useful feedback.References2010 Question generation shared task and evaluationchallenge, http://questiongeneration.org/QG2010Andrea Varga and Le An Ha 2010 WLV: A QuestionGeneration System for the QGSTEC 2010 Task B,Proceedings of QG2010: The Third Workshop onQuestion GenerationSantanu Paland Tapabrata Mondal, Partha Pakray,Dipankar Das and Sivaji Bandyopadhyay 2010QGSTEC System Description JUQGG: A Rule basedapproach , Proceedings of QG2010: The ThirdWorkshop on Question GenerationHusam Ali, Yllias Chali, and Sadid A. Hasan 2010Automation of Question Generation From Sentences,Proceedings of QG2010: The Third Workshop onQuestion GenerationEriks Sneiders 2002.
Automated question answeringusing question templates that cover the conceptualmodel of the database.
In Proceedings of the 6thInternational Conference on Applications of NaturalLanguage to Information Systems (pp.
235-239).Michael Heilman, Noah A. Smith.
2009 Question gener-ation via overgenerating transformations and rankingTechnical Report CMU-LTI-09-013, Carnegie MellonUniversity.Prashanth Mannem, Rashmi Prasad and Aravind Joshi2010 Question Generation from Paragraphs atUPenn: QGSTEC System Discription, Proceedings ofQG2010: The Third Workshop on Question Genera-tionRashmi Prasad and Aravind Joshi 2008 A Discourse-based Approach to Generating why-Questions fromtext, Proceedings of the Workshop on the QuestionGeneration Shared Task and Evaluation ChallengeArlington, VA, September 2008Emily Pitler, Annie Louis and Ani Nenkova 2009 Auto-matic sense prediction for implicit discourse relationsin text , ACL ?09 Proceedings of the Joint Conferenceof the 47th Annual Meeting of the ACL and the4th International Joint Conference on Natural Lan-guage Processing of the AFNLP: Volume 2 - Volume 22007 PDTB 2.0 Annotation Manual,http://www.seas.upenn.edu/ pdtb/PDTBAPI/pdtb-annotation-manual.pdf8Emily Pitler and Ani Nenkova 2009 Using syntax toDisambiguate Explicit Discourse Connectives in Text,ACLShort ?09 Proceedings of the ACL-IJCNLP 2009Conference Short PapersRashmi Prasad and Aravind Joshi and Bonnie Webber2010 Exploiting Scope for Shallow discourse Parsing,LREC2010Robert Elwell and Jason Baldridge 2008 Discourseconnective argument identification with connectivespecific rankers, In Proceedings of ICSC-2008Evaluation guidelines 2010 In QGSTEC-2010 Task Bevaluation guidelines, http://www.question genera-tion.org/QGSTEC2010/ uploads/QG-fromSentences-v2.doc9
