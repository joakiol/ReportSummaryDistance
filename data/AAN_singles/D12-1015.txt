Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 160?170, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsCollocation Polarity Disambiguation Using Web-based Pseudo ContextsYanyan Zhao, Bing Qin and Ting Liu?Harbin Institute of Technology, Harbin, China{yyzhao, bqin, tliu}@ir.hit.edu.cnAbstractThis paper focuses on the task of colloca-tion polarity disambiguation.
The collocationrefers to a binary tuple of a polarity word anda target (such as ?long, battery life?
or ?long,startup?
), in which the sentiment orientation ofthe polarity word (?long?)
changes along withdifferent targets (?battery life?
or ?startup?
).To disambiguate a collocation?s polarity, pre-vious work always turned to investigate thepolarities of its surrounding contexts, and thenassigned the majority polarity to the collo-cation.
However, these contexts are limited,thus the resulting polarity is insufficient to bereliable.
We therefore propose an unsuper-vised three-component framework to expandsome pseudo contexts from web, to help dis-ambiguate a collocation?s polarity.Without us-ing any additional labeled data, experimentsshow that our method is effective.1 IntroductionIn recent years, more attention has been paid tosentiment analysis as it has been widely used invarious natural language processing applications,such as question answering (Wiebe et al2003;Yu and Hatzivassiloglou, 2003), information extrac-tion (Riloff et al2005) and opinion-oriented sum-marization (Hu and Liu, 2004; Liu et al2005).Meanwhile, it also brings us lots of interesting andchallenging research topics, such as subjectivityanalysis (Riloff and Wiebe, 2003), sentiment clas-sification (Pang et al2002; Kim and Hovy, 2005;?Correspondence author: tliu@ir.hit.edu.cnWilson et al2009; He et al2011), opinion re-trieval (Zhang et al2007; Zhang and Ye, 2008;Li et al2010) and so on.One fundamental task for sentiment analysis isto determine the semantic orientations of words.For example, the word ?beautiful?
is positive, while?ugly?
is negative.
Many researchers have devel-oped several algorithms for this purpose and gener-ated large static lexicons of words marked with priorpolarities (Hatzivassiloglou and McKeown, 1997;Turney et al2003; Esuli, 2008; Mohammad et al2009; Velikovich et al2010).
However, there existsome polarity-ambiguous words, which can dynam-ically reflect different polarities along with differentcontexts.
A typical polarity-ambiguous word ???(?long?
in English) is shown with two example sen-tences as follows.1.
????[????]t?[?]p?
(Positive)Translated as: The [battery life]t of this camerais [long]p. (Positive)2.
????[????]t?[?]p?
(Negative)Translated as: This camera has [long]p[startup]t. (Negative)The phrases marked with p superscript are thepolarity-ambiguous words, and the phrases markedwith t superscript are targets modified by the polar-ity words.
In the above two sentences, the sentimentorientation of the polarity word ???
(?long?
in En-glish) changes along with different targets.
Whenmodifying the target ??????
(?battery life?
inEnglish), its polarity is positive; and when modify-ing ??????
(?startup?
in English), its polarity is160negative.
In this paper, we especially define the col-location as a binary tuple of the polarity-ambiguousword and its modified target, such as ??,?????
(?long, battery life?
in English) or ??,?????
(?long, startup?
in English).
This paper concentrateson the task of collocation polarity disambiguation.This is an important task as the problem ofpolarity-ambiguity is frequent.
We analyze 4,861common binary tuples of polarity words and theirmodified targets from 478 reviews1, and find thatover 20% of them are the collocations defined in thispaper.
Therefore, the task of collocation polarity dis-ambiguation is worthy of study.For a sentence s containing such a collocation c,since the in-sentence features are always ambiguous,it is difficult to disambiguate the polarity of c by us-ing them.
Thus some previous work turned to in-vestigate its surrounding contexts?
polarities (suchas the sentences before or after s), and then assignedthe majority polarity to the collocation c (Hatzivas-siloglou and McKeown, 1997; Hu and Liu, 2004;Kanayama and Nasukawa, 2006).
However, sincethe amount of contexts from the original review isvery limited, the final resulting polarity for the col-location c is insufficient to be reliable.Fortunately, most collocations may appear multi-ple times, in different forms, both within the samereview and within topically-related reviews.
Thusfor a collocation, we can collect large amounts ofcontexts from other reviews to improve its polaritydisambiguation.
These expanded contexts are calledpseudo contexts in this paper.
Some previous workused the similar methods.
For example, Ding (Dinget al2008) expanded some pseudo contexts froma topically-related review set.
But since the reviewset is limited, the expanded contexts are still lim-ited and unreliable.
In order to overcome this prob-lem, we propose an unsupervised three-componentframework to expand more pseudo contexts fromweb for the collocation polarity disambiguation.Without using any labeled data, experiments ona Chinese data set from four product domains showthat the three-component framework is feasible andthe web-based pseudo contexts are useful for thecollocation polarity disambiguation.
Compared toother previous work, our method achieves an F11The dataset will be introduced in Section 4.1 in detail.score of 72.02%, which is about 15% higher.The remainder of this paper is organized as fol-lows.
Section 2 introduces the related work.
Section3 shows the proposed approach including three in-dependent components.
Section 4 and 5 presents theexperiments and results.
Finally we conclude thispaper in Section 6.2 Related WorkThe key of the collocation polarity disambigua-tion task is to recognize the polarity word?s sen-timent orientation of a collocation.
There are ba-sically two types of approaches for word polar-ity recognition: corpus-based and dictionary-basedapproaches.
Corpus-based approaches find co-occurrence patterns of words in the large corporato determine the word sentiments, such as the workin (Hatzivassiloglou and McKeown, 1997; Wiebe,2000; Riloff and Wiebe, 2003; Turney et al2003;Kaji and Kitsuregawa, 2007; Velikovich et al2010).
On the other hand, dictionary-based ap-proaches use synonyms and antonyms in WordNetto determine word sentiments based on a set of seedpolarity words.
Such approaches are studied in (Kimand Hovy, 2006; Esuli and Sebastiani, 2005; Kampset al2004).
Overall, most of the above approachesaim to generate a large static polarity word lexiconmarked with prior polarities.However, it is not sensible to predict a word?s sen-timent orientation without considering its context.In fact, even in the same domain, a word may indi-cate different polarities depending on what targets itis applied to, especially for the polarity-ambiguouswords, such as ???
(?long?
in English) shown inSection 1.
Based on these, we need to consider boththe polarity words and their modified targets, i.e.,the collocations mentioned in this paper, rather thanonly the polarity words.To date, the task in this paper is similar withmuch previous work.
Some researchers exploitedthe features of the sentences containing colloca-tions to help disambiguate the polarity of thepolarity-ambiguous word.
For example, Hatzivas-siloglou (Hatzivassiloglou and McKeown, 1997)and Kanayama (Kanayama and Nasukawa, 2006)used conjunction rules to solve this problem fromlarge domain corpora.
Suzuki (Suzuki et al2006)161took into account many contextual information ofthe word within the sentence, such as exclamationwords, emoticons and so on.
However, the experi-mental results show that these in-sentence featuresare not rich enough.Instead of considering the current sentence alone,some researchers exploited external information andevidences in other sentences or other reviews to inferthe collocation?s polarity.
For a collocation, Hu (Huand Liu, 2004) analyzed its surrounding sentences?polarities to disambiguate its polarity.
Ding (Dinget al2008) proposed a holistic lexicon-based ap-proach of using global information to solve thisproblem.
However, the contexts or evidences fromthese two methods are limited and unreliable.
Ex-cept for the above unsupervised methods, some re-searchers (Wilson et al2005; Wilson et al2009)proposed supervised methods for this task, whichneed large annotated corpora.In addition, many related works tried to learnword polarity in a specific domain, but ignored theproblem that even the same word in the same do-main may indicate different polarities (Jijkoun et al2010; Bollegala et al2011).
And some work (Lu etal., 2011) combined difference sources of informa-tion, especially the lexicons and heuristic rules forthis task, but ignored the important role of the con-text.
Besides, there exists some research focusingon word sense subjectivity disambiguation, whichaims to classify a word sense into subjective or ob-jective (Wiebe and Mihalcea, 2006; Su and Markert,2009).
Obviously, this task is different from ours.3 The Proposed Approach3.1 OverviewThe motivation of our approach is to make full use ofweb sources to collect more useful pseudo contextsfor a collocation, whose original contexts are lim-ited or unreliable.
The framework of our approachis illustrated in Figure 1.In order to disambiguate a collocation?s polarity,three components are carried out:1.
Query Expansion and Pseudo Context Ac-quisition: This paper uses the collocation as query.For a collocation, three heuristic query expansionstrategies are used to generate more flexible queries,which have the same or completely opposite polar-A Chinesecollocationin a reviewQueryexpansionSearchingWebsnippetsOriginal contextacquisitionSentimentanalysisPseudo contextacquisitionSentimentanalysisCombination Pos/NegstartendFigure 1: The framework of our approach.ity with this collocation.
Searching these queries inthe domain-related websites, lots of snippets can beacquired.
Then we can extract the pseudo contextsfrom these snippets.2.
Sentiment Analysis: For both original con-texts and the expanded pseudo contexts from web, asimple lexicon-based sentiment computing methodis used to recognize each context?s polarity.3.
Combination: Two strategies are designed tointegrate the polarities of the original and pseudocontexts, under the assumption that these two kindsof contexts can be complementary to each other.It is worth noting that this three-componentframework is flexible and we can try to design dif-ferent strategies for each component.
Next sectionswill give a simple example strategy for each compo-nent to show its feasibility and effectiveness.3.2 Query Expansion and Pseudo ContextAcquisition3.2.1 Why Expanding QueriesFor a collocation, such as ??,?????
(?long,battery life?
in English), the most intuitive queryused for searching is constructed by the form of ?tar-get + polarity word?, i.e., ?????
(batterylife long in English).
Even if we search this queryalone, a great many web snippets covering the po-larity word and target will be retrieved.
But why dowe still need to expand the queries?In fact, for a collocation, though the amount of theretrieved snippets is large, lots of them cannot pro-vide accurate pseudo contexts.
The reason is that the162polarity words in some snippets do not really mod-ify the targets, such as in the sentence ?The batterylife is short, and finds few buyers for a long time.
?There exist no modifying relation between ?batterylife?
and ?long?.In order to filter these meaningless snippets, wecan simply search with a new query ??????
?by surrounding it with quotes (noted as Strategy0).However, this can drastically decline the amount ofsnippets.
In addition, as the new query is short, inmany retrieved snippets, there also exist no modify-ing relations between the polarity words and targets.As a result, if we just use this query strategy, the ex-panded pseudo contexts are limited and cannot yieldideal performance.Therefore, we need to design some effectivequery expansion strategies to ensure that (1) the po-larity words do modify the targets in the retrievedweb snippets, and (2) the snippets are more enough.3.2.2 Query Expansion StrategyWe first investigate the modifying relations be-tween polarity words and the targets, and then con-struct effective queries.Observed from previous work (Bloom et al2007; Kobayashi et al2004; Popescu and Etzioni,2005), there are two kinds of common relations be-tween the polarity words and their targets.
One isthe ?subject-copula-predicate?
relation, such as therelationship between ?long?
and ?battery life?
in thesentence ?The battery life of this camera is long?.The other is the ?attribute-head?
relation, such asthe relationship between them in the sentence ?Thiscamera has long battery life?.As a result, three heuristic query expansion strate-gies are adopted to construct efficient queries forsearching.
Take the collocation ??,?????
(?long, battery life?
in English) as an example, thestrategies are described as follows.Strategy1: target + modifier + polarity word:Such as the query ????????
or ?????????
(?the battery life is very long?
in English).Different from Strategy0, this strategy adds a mod-ifier element.
It refers to the words that are used tochange the degree of a polarity word, such as ???
or????
(?very?
in English).
Due to the usage of themodifiers, the queries from this strategy can satisfythe ?subject-copula-predicate?
relation.Strategy2: modifier + polarity word + ?+ tar-get: Such as the query ?????????
or ??????????
(?very long battery life?
in En-glish).
This strategy also uses modifiers to modifypolarity words, and the generated queries can satisfythe ?attribute-head?
relation.Strategy3: negation word + polarity word +?+target: Such as the query ?????????
or ??????????
(?not long battery life?
in En-glish).
This strategy uses negation words to modifythe polarity words.
And the queries from this strat-egy can satisfy the ?attribute-head?
relation.
Theonly difference is that the polarity of this kind ofqueries is opposite to that of the collocation.Similar to the queries from Strategy0, the queriesgenerated by Strategy1?3 are all searched withquotes.
In addition, note that the modifier and thenegation word are taken from Modifier Lexicon andNegation Lexicon introduced in Table 2.3.2.3 Pseudo Context AcquisitionFor each query from Strategy0?3, we search it insome websites to acquire the related snippets.
If wedirectly search it using Google without site restric-tions, it does return all the snippets containing thequery, but lots of them are non-reviews.
Further, thepseudo contexts generated by these non-reviews areuseless or even harmful.
To overcome this problem,the advanced search of Google is used to search thequery within the forum sites of the product domain.We can flexibly choose several popular forum sitesfor each domain.
The URLs of the forum sites usedin this paper are listed in Table 1.Formally, given a collocation c, the expandedpseudo contexts Conx(c) can be obtained using thefollowing function:Conx(c) =?3i=0 f(Queryi)=?3i=0?nj=1 f(queryij)(1)Here, Queryi is the query set generated by the ithquery expansion strategy; queryij is the jth querygenerated by the ith strategy.
And the parameter n isthe total number of queries from the ith query expan-sion strategy.
From this function, we can collect thecontexts of c by summing up all the pseudo contextsfrom every queryij .163Domain URLCamerahttp://www.qqdc.com.cnhttp://forums.nphoto.nethttp://dc.pconline.com.cnhttp://photobbs.it168.comhttp://club.tech.sina.com.cn/dcCarhttp://bbs.chetx.comhttp://bbs.pcauto.com.cnhttp://club.autohome.com.cnhttp://bbs.cheshi.comhttp://www.xcar.com.cnhttp://www.autohome.com.cnNotebookhttp://benyouhui.it168.com/index.phphttp://nbbbs.zol.com.cnhttp://www.ibijiben.comhttp://notebook.pconline.com.cnhttp://nbbbs.enet.com.cnPhonehttp://bbs.imobile.com.cnhttp://sjbbs.zol.com.cnhttp://bbs.shouji.com.cnhttp://bbs.cnmo.comhttp://forum.younet.comTable 1: The URLs used in context expansion for differ-ent domains.In detail, the pseudo context acquisition algorithmfor a collocation c is illustrated in Figure 2.
Notethat, the original context acquisition of c can be con-sidered as a simplified version of the pseudo contextacquisition.
That?s because the current review con-taining c can be considered as only one snippet inpseudo context acquisition.
Thus, we can just carryout the two steps in (2) of Figure 2 to obtain the orig-inal contexts.Analyzing either the pseudo contexts or the orig-inal contexts, we can find that not all of them areuseful contexts.
Thus we will simply filter the noisyones by context sentiment computation, and choosethe contexts showing sentiment orientations as theuseful contexts.3.3 Sentiment AnalysisFor both the original and expanded pseudo contexts,we employ the lexicon-based sentiment computingmethod (Hu and Liu, 2004) to compute the polarityvalue for each context.
This unsupervised approachis quite straightforward and makes use of the senti-ment lexicons in Table 2.The polarity value Polarity(con) for a context conAlgorithm: Pseudo Context Expansion AlgorithmInput: A collocation c and the URL listOutput: The pseudo context set Conx(c)1.
Use Strategy0~3 to expand c and the expanded queriesare saved as a set Query(c).2.
For any query q Query(c),   acquire its pseudocontexts Conx(q) as follows:(1) search q in the domain-related URL list, the top 100retrieved snippets for each URL are collected as Snip(q)(2) for each snippet sp Snip(q)find the sentence s containing qobtain the two sentences before and after s as thecontexts of q in this sp, noted as Conx(q, sp)Conx(q) =3.
Conx(c) =                      =?
?U)(),(qSnipspspqConx?U)()(cQueryqqConx?U U)( )(),(cQueryq qSnipspspqConx?
?Figure 2: The algorithm for pseudo context acquisition.Lexicon ContentModifier Lexicon?,??,??,??,?,?,??,?,??,??,??(?very?
or ?quite?
in English)Negation Lexicon ??,?,??(?no?
or ?not?
in English)Positive Lexicon There are 3,730 Chinese wordsare collected from HOWNET1.Negative Lexicon There are 3,116 Chinese wordsare collected from HOWNET.1 http://www.keenage.com/html/e index.html.Table 2: The lexicons used in this paper.is computed by summing up the polarity values of allwords in con, making use of both the word polaritydefined in the positive and negative lexicons and thecontextual shifters defined in the negation lexicon.The algorithm is illustrated in Figure 3.In this algorithm, n is the parameter controllingthe window size within which the negation wordshave influence on the polarity words, and here n isset to 3.Normally, if the polarity value Polarity(con) ismore than 0, the context con is labeled as positive; ifless than 0, the context is negative.
We also considerthe transitional words, such as ????
(?but?
in En-glish).
Finally, the contexts with positive/negativepolarities are used as the useful contexts.164Domain # of reviews # of c # of single c Sig / All # of multiple c(All) (Sig) (%) / kinds of multiple cCamera 138 295 183 62.03 112 / 35Car 161 232 131 56.47 101 / 33Notebook 56 147 94 63.95 53 / 20Phone 123 327 192 58.72 135 / 35Total 478 1001 600 59.94 401 / 123 ?
3.3Table 3: Statistics for the Chinese collocation corpus.Algorithm: Sentiment AnalysisInput: a context con, and three lexicons: Positive_Dic,Negative_Dic, Negation_DicOutput: Polarity value Polarity(con)1.
Segment con into word set W(con)2.
For each word w W(con), compute its polarity valuePolarity(w) as follows:(1) if w Positive_Dic, Polarity(w) = 1;(2) if w Negative_Dic, Polarity(w) = -1;(3) otherwise, Polarity(w) = 0;(4) Within the window of n words previous to w, ifthere is a word w?
Negation_Dic,Polarity(w) = -Polarity(w)3.
Polarity(con)  =????
)()(conWwwPolarity?
?Figure 3: The algorithm for context polarity computation.3.4 CombinationAfter the pseudo context acquisition and polaritycomputation, two kinds of effective contexts: orig-inal contexts and pseudo contexts, and their corre-sponding polarities can be obtained.In order to yield a relatively accurate polarity Po-larity(c) for a collocation c, we exploit the followingcombination methods:1.
Majority Voting: Rather than considering thedifference between the two kinds of contexts, thiscombination method relies on the polarity tag ofeach context.
Suppose c has n effective contexts(including original and pseudo contexts), it can ob-tain n polarity tags based on the individual sentimentanalysis algorithm.
The polarity tag receiving morevotes is chosen as the final polarity of c.2.
Complementation: For a collocation c, wefirst employ ?Majority Voting?
method just on theexpanded pseudo contexts to obtain the polarity tag.If the polarity of c cannot be recognized2, the ma-jority polarity tag voted on the original contexts ischosen as the final polarity tag.4 Experimental Setup4.1 Dataset and Evaluation MetricsWe conduct the experiments on a Chinese colloca-tion corpus of four product domains, which is fromthe Task3 of the Chinese Opinion Analysis Evalua-tion (COAE)3 (Zhao et al2008).
Table 3 describesthe corpus in detail.From 478 reviews, 1,001 collocations (454 pos-itive and 547 negative) with polarity-ambiguouswords are found and manually annotated by two an-notators.
Cohen?s kappa (Cohen, 1960), a measureof inter-annotator agreement ranging from zero toone, is 0.83, indicating a good strength of agree-ment 4.
In Table 3, Sig of the fourth column denotesthe collocations that appear once in all the domain-related reviews.
And multiple in the last columndenotes the collocations that appear several times.From Table 3, we can find that among all the re-views, nearly 60% collocations only appear once.Even for the multiple collocations, they averagelyappear less than 4 times.
Therefore, for a colloca-tion, if we only consider its original contexts aloneor the expanded pseudo contexts from the domain-related review set al, the contexts are obviouslylimited and unreliable.Instead of using accuracy, we use precision (P),recall (R) and F-measure (F1) to measure the perfor-mance of this task.
That?s because two kinds of col-locations?
polarities cannot be disambiguated.
One2The reason will be explained in the last paragraph of Sec-tion 4.1.3http://www.ir-china.org.cn/coae2008.html4A small number of collocations are still difficult to be dis-ambiguated from contexts.165is the sparse collocations, which obtain no effectivecontexts.
The other is the collocations that acquirethe same amount of positive and negative contexts.The metrics are defined as follows.P = correctly disambiguated collocationsdisambiguated collocations(2)R = correctly disambiguated collocationsall collocations(3)F1 = 2PRP +R(4)4.2 System DescriptionIn order to compare our method with previous work,we build several systems as follows:NoExp: Following the method proposed byHu (Hu and Liu, 2004), without using the expandedpseudo contexts, we only consider the two originalcontexts Senbef and Senaft of a collocation c in thecurrent review.
If Senbef expresses the polarity po-lar, then Polarity(ac) = polar.
Else if Senaftexpresses the polarity polar?, then Polarity(ac) =polar?.
Else, this method cannot disambiguate thepolarity of c. In this method, the transitional words,such as ????
(?but?
in English) are considered.Expdataset: Following the method proposed byDing (Ding et al2008), we solve this task with thehelp of the pseudo contexts in the domain-related re-view dataset.
For a collocation c appearing in manydomain-related reviews, this method refers to the po-larities of the same c in other reviews.
The majoritypolarity is chosen as final polarity.Expweb+sig: This method is the same as ourmethod in this paper, except for (1) not combiningthe original contexts, and (2) not using all the threequery expansion strategies, but just using the sin-gle (abbv.
sig) Strategy0.
This method expands thepseudo contexts from the web.
The majority polarityis chosen as the final polarity.Expweb+exp: This method is the same as our pro-posed method in this paper, except for not combin-ing the original contexts.
It expands the pseudo con-texts from the web.
And the ?exp?
in the subscriptmeans that this method uses all the query expansionstrategies.
The majority polarity of all the pseudocontexts is chosen as the final polarity.Expmv/cweb+exp+com: This is the method proposedin this paper, which combines the original and ex-panded pseudo contexts.
The superscript ?mv/c?
isshort for the two combination methods: MajorityVoting and Complementation.5 Results5.1 Comparisons among All the SystemsIn fact, all the systems shown in Section 4.2 can beconsidered as context based methods.
The essentialdifference among them lies in the contexts they used.For a collocation, the contexts for NoExp are twooriginal contexts from the current review.
Breakingdown the boundary of the current review,Expdatasetexplores the pseudo contexts from other domain-related reviews.
Further, Expweb+sig, Expweb+expand Expmv/cweb+exp+com expand the pseudo contextsfrom web, which can be considered as a large corpusand can provide more evidences for the collocationpolarity disambiguation.System P(%) R(%) F1(%)NoExp 67.32 41.16 51.08Expdataset 68.14 47.85 56.22Expweb+sig 70.00 53.85 60.87Expweb+exp 74.97 63.14 68.55Expmvweb+exp+com 75.53 67.83 71.47Expcweb+exp+com 74.36 69.83 72.02Table 4: Comparative results for the collocation polaritydisambiguation task.Table 4 illustrates the comparative results of allsystems for collocation polarity disambiguation.
Itcan be observed that our system Expmvweb+exp+comand Expcweb+exp+com outperform all the other sys-tems.
We discuss the experimental results as fol-lows:NoExp yields the worst performance, especiallyon the recall.
The reason is that the original con-texts used in this system are limited, and some ofthem are even noisy.
In comparison, Expdatasetadds a post-processing step of expanding pseudocontexts from the topically-related review dataset,which achieves a better result with an absolute im-provement of 5.14% (F1).
This suggests that thecontexts expanded from other reviews are helpful indisambiguating the collocation?s polarity.166However, Expdataset is just effective in disam-biguating the polarity of such a collocation c, whichappears many times in the domain-related reviews.From Table 3, we can notice that this kind of collo-cations only accounts for 40% in all the collocations,and further they appear less than 4 times on average.Thus, for such a collocation c, the pseudo contextsexpanded from other reviews that contain the samec are still far from enough, since the review set sizein this system is not very large.In order to avoid the context limitation problem,we expand more pseudo contexts from web for eachcollocation.
We first try to use a simple queryform (Strategy0) for web mining.
Table 4 illustratesthat the corresponding system Expweb+sig outper-forms the system Expdataset.
It can demonstratethat our web mining based pseudo context expan-sion is useful for disambiguating the collocation?spolarity, since this system can explore more con-texts.
However, we can find that the performanceis not very ideal.
This system can generate someharmful contexts for the reason of the wrong mod-ifying relations between polarity words and targetsin the retrieved snippets.Thus this paper adds three query expansion strate-gies to generate more and accurate pseudo con-texts.
Table 4 shows that the corresponding sys-tem Expweb+exp can achieve a better result with F1= 68.55%, which is significantly (?2 test with p <0.01) outperforms Expweb+sig.
It demonstrates thatthe query expansion strategies are useful.Finally, Table 4 gives the results of our method inthis paper, Expmvweb+exp+com and Expcweb+exp+com,which combines the original and expanded pseudocontexts to yield a final polarity.
We can ob-serve that both of these systems outperform the sys-tem NoExp of just using the original contexts andthe system Expweb+exp of just using the expandedpseudo contexts.
This can illustrate that the twokinds of contexts are complementary to each other.In addition, we can also find that the two combi-nation methods produce similar results.
In detail,Expmvweb+exp+com disambiguates 899 collocations,679 of them are correct; Expcweb+exp+com disam-biguates 940 collocations, 699 of them are correct.We can further find that, although the amount oforiginal contexts is small, it also plays an importantrole in disambiguating the polarities of the collo-cations that cannot be recognized by the expandedpseudo contexts.5.2 The Contributions of the Query ExpansionStrategiesThe expanded pseudo contexts from our method canbe partly credited to the query expansion strategies.Based on this, this section aims to analyze the differ-ent contributions of the query expansion strategies inour method.Strategy P(%) R(%) F1(%) Avg(#)Strategy0 70.00 53.85 60.87 71Strategy1 74.14 55.84 63.70 112Strategy2 61.84 37.56 46.74 26Strategy3 64.34 33.17 43.77 20Expweb+exp 74.97 63.14 68.55 229Table 5: The performance of our method based on eachquery expansion strategy for collocation polarity disam-biguation.Table 5 provides the performance of our methodbased on each query expansion strategy for collo-cation polarity disambiguation.
For each strategy,?Avg?
in Table 5 denotes the average number ofthe expanded pseudo contexts for each collocation.From this table, we can find that the larger the ?Avg?is, the better (F1) the strategy is.
In detail, Strategy1with the largest ?Avg?
has the best performance; andStrategy3 with the fewest ?Avg?
has the worst per-formance.
This can further demonstrate our ideathat more and effective pseudo contexts can improvethe performance of the collocation polarity disam-biguation task.
Expweb+exp integrates all the queryexpansion strategies and obtains much more ?Avg?.Therefore, this can significantly increase the recallvalue, and further produce a better result.
On theother hand, the results in Table 5 show that theseheuristic query expansion strategies are effective.5.3 Deep Experiments in theThree-Component FrameworkIn order to do a detailed analysis into our three-component framework, some deep experiments aremade:Query Expansion The aim of query expansionis to retrieve lots of relative snippets, from whichwe can extract the useful pseudo contexts.
For each167Strategy0 Strategy1 Strategy2 Strategy3(%) (%) (%) (%)Query Expansion 76.75 94.50 85.50 85.25Pseudo Context 71.25 73.50 67.50 74.50Sentiment Analysis 63.00 68.25 59.00 69.75Table 6: The accuracies of the query expansion, pseudo context and sentiment analysis for each strategy.snippet, if the polarity word of the collocation doesmodify the target, we consider this snippet as a cor-rect query expansion result.Pseudo Context For each expanded pseudo con-text from web, if it shows the same sentiment ori-entation with the collocation (or opposite with thecollocation?s polarity because of the usage of transi-tional words), we consider this context as a correctpseudo context.Sentiment Analysis For each expanded pseudocontext, if its polarity can be correctly recognizedby the polarity computation method in Figure 3, andmeanwhile it shows the same sentiment orientationwith the collocation, we consider this context as acorrect one.Table 6 illustrates the accuracy of each experi-ment for each strategy in detail, where 400 web re-trieved snippets for Query Expansion and 400 ex-panded pseudo contexts for Pseudo Context andSentiment Analysis are randomly selected and man-ually evaluated for each strategy.Seen from Table 6, we can find that:1.
For Query Expansion, all strategies yield goodaccuracies except for Strategy0.
This can draw asame conclusion with our analysis in Section 3.2.1.The queries from Strategy0 are short, thus in manyretrieved snippets, there exist no modifying relationsbetween the polarity words and targets.
Accord-ingly, the pseudo contexts from these snippets areincorrect.
This can result in the low accuracy ofStrategy0.
On the other hand, we can find that theother three query expansion strategies perform well.2.
Although the final result of our three-component framework is good, the accuracies ofPseudo Context and Sentiment Analysis for eachstrategy is not very high.
This is perhaps caused byunrefined work on the specific sub-stages.
For ex-ample, we get alhe pseudo contexts using the al-gorithm in Figure 2.
However, in some reviews, thetwo sentences before and after the target sentencehave no polarity relation with the target sentence it-self.
This can bring in some noises.
On the otherhand, the context polarity computation algorithm inFigure 3 is just a simple attempt, which is not thebest way to compute the context?s polarity.In fact, this paper aims to try some simple algo-rithms for each component to validate the effective-ness of the three-component framework.
We willpolish every component of our framework in future.6 Conclusion and Future WorkThis paper proposes a web-based context expan-sion framework for collocation polarity disambigua-tion.
The basic assumption of this framework isthat, if a collocation appears in different forms, bothwithin the same review and within topically-relatedreviews, then the large amounts of pseudo contextsfrom these reviews can help to disambiguate sucha collocation?s polarity.
Based on this assumption,this framework includes three independent compo-nents.
First, the heuristic query expansion strate-gies are adopted to expand pseudo contexts fromweb; then a simple but effective polarity computa-tion method is used to recognize the polarities forboth the original contexts and the expanded pseudocontexts; and finally, we integrate the polarities fromthe original and pseudo contexts as the collocation?spolarity.
Without using any additional labeled data,experiments on a Chinese data set from four productdomains show that the proposed framework outper-forms other previous work.This paper can be concluded as follows:1.
A framework including three independent com-ponents is proposed for collocation polaritydisambiguation.
We can try other different al-gorithms for each component.2.
Web-based pseudo contexts are effective fordisambiguating a collocation?s polarity.1683.
The query expansion strategies are promising,which can generate more useful and correctcontexts.4.
The initial contexts from current reviews andthe expanded contexts from web are comple-mentary to each other.The immediate extension of our work is to polisheach component of this framework, such as improv-ing the accuracy of query expansion and pseudo con-text acquisition, using other effective polarity com-puting methods for each context and so on.
In ad-dition, we will explore other query expansion strate-gies to generate more effective contexts.AcknowledgmentsWe thank the anonymous reviewers for their helpfulcomments.
This work was supported by NationalNatural Science Foundation of China (NSFC) viagrant 61133012, the National ?863?
Leading Tech-nology Research Project via grant 2012AA011102,the Ministry of Education Research of Social Sci-ences Youth funded projects via grant 12YJCZH304and the Fundamental Research Funds for the CentralUniversities via grant No.HIT.NSRIF.2013090.ReferencesKenneth Bloom, Navendu Garg, and Shlomo Argamon.2007.
Extracting appraisal expressions.
In HLT-NAACL 2007, pages 308?315.D.
Bollegala, D. Weir, and J. Carroll.
2011.
Using mul-tiple sources to construct a sentiment sensitive the-saurus for cross-domain sentiment classification.
InProceedings of the 49th Annual Meeting of the Asso-ciation for Computational Linguistics: Human Lan-guage Technologies-Volume 1, pages 132?141.
Asso-ciation for Computational Linguistics.Jacob Cohen.
1960.
A coefficient of agreement for nom-inal scales.
Educational and Psychological Measure-ment, 20(1):37?46.Xiaowen Ding, Bing Liu, and Philip S. Yu.
2008.
Aholistic lexicon-based approach to opinion mining.
InProceedings of the Conference onWeb Search andWebData Mining (WSDM), pages 231?240.A.
Esuli and F. Sebastiani.
2005.
Determining the se-mantic orientation of terms through gloss analysis.
InProceedings of the ACM SIGIR Conference on Infor-mation and Knowledge Management (CIKM), pages617?624.A.
Esuli.
2008.
Automatic generation of lexical re-sources for opinion mining: models, algorithms andapplications.
In ACM SIGIR Forum, volume 42, pages105?106.
ACM.V.
Hatzivassiloglou and K.R.
McKeown.
1997.
Predict-ing the semantic orientation of adjectives.
In Proceed-ings of the eighth conference on European chapter ofthe Association for Computational Linguistics, pages174?181.
Association for Computational Linguistics.Yulan He, Chenghua Lin, and Harith Alani.
2011.
Auto-matically extracting polarity-bearing topics for cross-domain sentiment classification.
In Proceedings of the49th Annual Meeting of the Association for Compu-tational Linguistics: Human Language Technologies,pages 123?131, Portland, Oregon, USA, June.
Associ-ation for Computational Linguistics.M.
Hu and B. Liu.
2004.
Mining and summarizingcustomer reviews.
In Proceedings of the tenth ACMSIGKDD international conference on Knowledge dis-covery and data mining, pages 168?177.
ACM.V.
Jijkoun, M. De Rijke, and W. Weerkamp.
2010.
Gen-erating focused topic-specific sentiment lexicons.
InProceedings of the 48th Annual Meeting of the Associ-ation for Computational Linguistics, pages 585?594.Association for Computational Linguistics.N.
Kaji and M. Kitsuregawa.
2007.
Building lexiconfor sentiment analysis from massive collection of htmldocuments.
In Proceedings of the Joint Conferenceon Empirical Methods in Natural Language Process-ing and Computational Natural Language Learning(EMNLP-CoNLL), pages 1075?1083.Jaap Kamps, Maarten Marx, R. ort.
Mokken, andMaarten de Rijke.
2004.
Using wordnet to measuresemantic orientation of adjectives.
In Proceedings ofLREC-2004, pages 1115?1118.H.
Kanayama and T. Nasukawa.
2006.
Fully auto-matic lexicon expansion for domain-oriented senti-ment analysis.
In Proceedings of the 2006 Conferenceon Empirical Methods in Natural Language Process-ing, pages 355?363.
Association for ComputationalLinguistics.Soo-Min Kim and Eduard Hovy.
2005.
Automatic detec-tion of opinion bearing words and sentences.
In Pro-ceedings of IJCNLP-2005, pages 61?66.S.-M. Kim and E. Hovy.
2006.
Identifying and analyz-ing judgment opinions.
In Proceedings of the JointHuman Language Technology/North American Chap-ter of the ACL Conference (HLT-NAACL), pages 200?207.Nozomi Kobayashi, Kentaro Inui, Yuji Matsumoto, KenjiTateishi, and Toshikazu Fukushima.
2004.
Collectingevaluative expressions for opinion extraction.
In Pro-ceedings of the International Joint Conference on Nat-ural Language Processing (IJCNLP), pages 584?589.169Binyang Li, Lanjun Zhou, Shi Feng, and Kam-Fai Wong.2010.
A unified graph model for sentence-based opin-ion retrieval.
In Proceedings of the 48th Annual Meet-ing of the Association for Computational Linguistics,page 1367?1375.Bing Liu, Minqing Hu, and Junsheng Cheng.
2005.Opinion observer: analyzing and comparing opinionson the web.
In Proceedings of WWW-2005, pages342?351.Y.
Lu, M. Castellanos, U. Dayal, and C.X.
Zhai.
2011.Automatic construction of a context-aware sentimentlexicon: an optimization approach.
In Proceedings ofthe 20th international conference on World wide web,pages 347?356.
ACM.S.
Mohammad, C. Dunne, and B. Dorr.
2009.
Generat-ing high-coverage semantic orientation lexicons fromovertly marked words and a thesaurus.
In Proceedingsof the 2009 Conference on Empirical Methods in Nat-ural Language Processing: Volume 2-Volume 2, pages599?608.
Association for Computational Linguistics.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
sentiment classification using ma-chine learning techniques.
In Proceedings of EMNLP-2002, pages 79?86.Ana-Maria Popescu and Oren Etzioni.
2005.
Extract-ing product features and opinions from reviews.
Inhltemnlp2005, pages 339?346.Ellen Riloff and Janyce Wiebe.
2003.
Learning extrac-tion patterns for subjective expressions.
In Proceed-ings of EMNLP-2003, pages 105?112.Ellen Riloff, Janyce Wiebe, and William Phillips.
2005.Exploiting subjectivity classification to improve in-formation extraction.
In Proceedings of AAAI-2005,pages 1106?1111.Fangzhong Su and Katja Markert.
2009.
Subjectivityrecognition on word senses via semi-supervised min-cuts.
In Human Language Technologies: The 2009Annual Conference of the North American Chapter ofthe ACL, pages 1?9.Yasuhiro Suzuki, Hiroya Takamura, and Manabu Oku-mura.
2006.
Application of semi-supervised learn-ing to evaluative expression classification.
In Com-putational Linguistics and Intelligent Text Processing,pages 502?513.P.
Turney, M.L.
Littman, et al003.
Measuring praiseand criticism: Inference of semantic orientation fromassociation.
ACM Transactions on Information Sys-tems (TOIS), 21(4):315?346.Leonid Velikovich, Sasha Blair-Goldensohn, Kerry Han-nan, and RyanMcDonald.
2010.
The viability of web-derived polarity lexicons.
In The 2010 Annual Confer-ence of the North American Chapter of the Associationfor Computational Linguistics, pages 777?785.Jan Wiebe and Rada Mihalcea.
2006.
Word sense andsubjectivity.
In Proceedings of the Conference onComputational Linguistics / Association for Computa-tional Linguistics (COLING/ACL), pages 1065?1072.Janyce Wiebe, Eric Breck, and Chris Buckley.
2003.Recognizing and Organizing Opinions Expressed inthe World Press.
In Papers from the AAAI SpringSymposium on New Directions in Question Answering,pages 24?26.Janyce Wiebe.
2000.
Learning subjective adjectivesfrom corpora.
In Proceedings of AAAI, pages 735?740.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity in phrase-levelsentiment analysis.
In Proceedings of HLT/EMNLP-2005, pages 347?354.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2009.
Recognizing contextual polarity: an explorationof features for phrase-level sentiment analysis.
Com-putational Linguistics, 35(3).Hong Yu and Vasileios Hatzivassiloglou.
2003.
Towardsanswering opinion questions: separating facts fromopinions and identifying the polarity of opinion sen-tences.
In Proceedings of EMNLP-2003, pages 129?136.Min Zhang and Xingyao Ye.
2008.
A generation modelto unify topic relevance and lexicon-based sentimentfor opinion retrieval.
In Proceedings of the ACM Spe-cial Interest Group on Information Retrieval (SIGIR),pages 411?419.Wei Zhang, Clement Yu, and Weiyi Meng.
2007.
Opin-ion retrieval from blogs.
In In proceedings of CIKM,page 831?840.Jun Zhao, Hongbo Xu, Xuanjing Huang, Songbo Tan,Kang Liu, and Qi Zhang.
2008.
Overview of chineseopinion analysis evaluation 2008.170
