A Class-based Approach to WordAlignmentSue J. Ker"National Tsing Hua UniversityJason S. Chang*National Tsing Hua UniversityThis paper presents an algorithm capable of identifying the translation for each word in a bilingualcorpus.
Previously proposed methods rely heavily on word-based statistics.
Under a word-basedapproach, frequent words with a consistent translation can be aligned at a high rate of precision.However, words that are less frequent or exhibit diverse translations generally do not have sta-tistically significant evidence for confident alignment, hereby leading to incomplete or incorrectalignments.
The algorithm proposed herein attempts to broaden coverage by exploiting lexico-graphic resources.
To this end, we draw on the two classification systems of words in LongmanLexicon of Contemporary English (LLOCE) and Tongyici Cilin (Synonym Forest, CILIN).
Au-tomatically acquired class-based alignment rules are used to compensate for what is lacking in abilingual dictionary such as the English-Chinese version of the Longman Dictionary of Contem-porary English (LecDOCE).
In addition, this alignment method is implemented using LecDOCEexamples and their translations for training and testing, while further examples from a technicalmanual in both English and Chinese are used for an open test.
Quantitative r sults of the closedand open tests are also summarized.1.
IntroductionBrown, Cocke, Della Pietra, Della Pietra, Jelinek, Laffert~ Mercer, and Roosin (1990)advocate a statistical pproach to machine translation (MT) and initiate much of therecent interest in bilingual corpora.
Statistical machine translation (SMT) can be un-derstood as a word-by-word model consisting of two submodels: a language modelfor generating a source text segment S and a translation model for mapping S to itstranslation T. They recommend using a bilingual corpus to train the parameters oftranslation probability, Pr(S I T) in the translation model.
For MT and other pur-poses, many methods have been proposed for sentence alignment of the Hansards,an English-French corpus of Canadian parliamentary debates (Brown, Lai, and Mer-cer 1991; Gale and Church 1991a; Sirnard, Foster, and Isabelle 1992; Chen 1993; Galeand Church 1993), and for other language pairs, including English-German, English-Chinese, and English-Japanese (Kay and ROscheisen 1993; Church, Dagan, Gale, Fung,Helfman, and Satish 1993; Fung and McKeown 1994; Wu 1994).
Alignment at otherlevels of resolution is obviously useful.
A section, paragraph, sentence, phrase, col-location, or word can be aligned to its translation (Kupiec 1993; Smadja, McKeown,and Hatzivassiloglou 1996).
Other logical approaches involve aligning parse trees ofa sentence and its translation (Matsumoto, Ishimoto, and Utsuro 1993; Meyers, Yan-garber, and Grishman 1996), or simultaneously generating parse trees and alignmentarrangements (Wu 1995).?
Department ofComputer Science, National Tsing Hua University, Hsinchu, 30043, Taiwan, ROC.E-mail: ksj@volans.cs.scu.edu.tw; jschang@cs.nthu.edu.tw(~) 1997 Association for Computational LinguisticsComputational Linguistics Volume 23, Number 2In addition to machine translation, many applications for aligned corpora havebeen suggested, including machine-aided translation (Shemtov 1993), translation as-sessment and critiquing tools (Isabelle 1992; des Tombe and Armstrong-Warwick 1993;Macklovitch 1994), text generation (Smadja 1992; Smadja, McKeown, and Hatzivas-siloglou 1996), bilingual exicography (Klavans and Tzoukermann 1990; Church andGale 1991; Daille, Gaussier, and Lange 1994; Kupiec 1993; van der Eijk 1993; Li 1994;Wu and Xia 1994), and word-sense disambiguation (Gale, Church, and Yarowsky 1992;Chang, Chen, Sheng, and Ker 1996).
For these applications, we must go one step fur-ther from sentence alignment and identify alignment at the word level.
In the processof word alignment, he translation of each source word is identified.
This study con-centrates primarily on identifying alignment at the word level for a given sentenceand its translation.In the context of SMT, Brown et al (1993) present aseries of five models of Pr(S I T)for word alignment.
Model 1 assumes that Pr(S \] T) depends only on lexical transla-tion probability (LTP) t(s I t), that is, the probability that the ith word s in S translatesinto the jth word t in T. The pair of words (s, t), or more precisely (s, t, i,j) since therecould be more than one instance of s or t, is called a connection.
Model 2 enhancesModel I by considering the dependence of Pr(S I T) on the distortion probability (DP)d(i I J, l, m) where I and m are the respective l ngths of S and T measured in number ofwords.
Brown et al (1990) propose using an adaptive Expectation and Maximization(EM) algorithm to estimate the parameters for LTP and DP from a bilingual corpus.The EM algorithm iterates between two phases to estimate LTP and DP until bothfunctions converge.
In the expectation phase, the parameters t(s I t) and d(i I J, l, m) inthe SMT model for all possible values of s, t, i, j, I, and m are estimated from the sampleof an aligned bilingual corpus.
In the maximization phase, each sentence-translationpair in the corpus is aligned by maximizing the translation probability, Pr(S I T).
Theyexamine the feasibility of aligning the English-French Hansards corpus using the SMTmodel, on both the sentence l vel and the word level.
The SMT model is then testedfor the task of machine translation.
The model produces 35 acceptable translations for73 sentences.
However, to our knowledge, the degree of success of word alignmenthas not yet been explored.Dagan, Church, and Gale (1993) observe that reliably distinguishing sentenceboundaries for a noisy bilingual text scanned by an OCR device is quite difficult.
Insuch a circumstance, they recommend aligning words directly without he preprocess-ing phase of sentence alignment.
Under that proposal, a rough character-by-characteralignment is first performed.
Based on the character alignment, words are subsequentlyaligned based on a modified version of Brown et al's Model 2.
The authors reportthat 60.5% of 65,000 words in a noisy document are correctly aligned.
For 84% of thewords, the offset from correct alignment is at most 3.Gale and Church (1991b) present an alternative algorithm that does not estimateand store probabilities for all word pairs to reduce memory requirement and to ensurerobustness ofprobability estimation.
Instead, for each source word s, only a handful oftarget words strongly associated with s are found and stored.
Such a task is achievedby applying a X2-1ike statistic.
They report that the method produces highly precise(95%) alignment for 61% of the words in the 800 sentences tested.This paper is motivated by the following observations: First, the above surveydearly reveals that word-based methods offer only limited coverage ven after theyare trained with an extremely large bilingual corpus.
Second, we believe that for mostapplications, low coverage is just as serious as low precision.
For aligned corpora tobe useful for NLP tasks such as machine translation and word-sense disambiguation,a coverage rate higher than 60% is desirable, even at the expense of a slightly lowerprecision rate.314Sue J. Ker and Jason S. Chang Word AlignmentThis paper presents a word alignment algorithm based on classification i existingthesauri.
The proposed algorithm, called ClassAlign, relies on an automatic procedureto acquire class-based alignment rules; it does not employ word-by-word translationprobabilities, nor does it use an iterative EM algorithm for estimating such proba-bilities.
Experimental results indicate that classification based on existing thesauri ishighly effective in broadening coverage while maintaining a high precision rate.The rest of this paper is organized as follows: In Section 2 we briefly discuss thenature of text and translation that justifies a class-based approach.
A set of three al-gorithms leading to class-based alignment are outlined in Section 3.
The algorithms'effectiveness i  demonstrated through examples and their translations in the LecDOCE(Longman Group 1992), a bilingual version of the Longman Dictionary of Contempo-rary English (LDOCE, Proctor 1988), as well as sentences from bilingual texts in theLightShip User's Guide (Pilot Software Inc. 1993; Galaxy Software Services 1994).
Theexperiments we undertook to assess the performance of these algorithms are the topicof Section 4.
Quantitative experimental results are also summarized.
In Section 5, weanalyze the experimental results and consider ways in which the proposed algorithmsmight be extended and improved.
Concluding remarks are made in Section 6.2.
Text and Translation as a Class-to-Class MappingThe discussion in Section 1 indicates the limitations of statistical methods.
As analternative, we examine the feasibility of using an everyday bilingual dictionary inmachine-readable form for word alignment.
With tens of thousands of headword-and-translation pairs that can be used to propose high-precision connections, a bilingualmachine-readable dictionary (MRD) surprisingly leads to even lower coverage than astatistically-derived l xicon.
Below, observations are made to account for the reasonwhy a substantial portion of translations deviate from what is listed in the bilingualMRD or what is statistically probable.
Such deviations inhibit word-based methods 'from achieving broad coverage.
We contend that a word's translational deviation ismostly bounded within the relevant semantic lasses, thus justifying a class-basedapproach to word alignment.2.1 Diverse In-Context TranslationsGiven that the translations for a headword (dictionary translations, DTs for short) canbe extracted from a bilingual MRD such as the LecDOCE, a word in S can be alignedat a high precision rate with its DTs found in T. Headword-and-translation pairs area reliable knowledge source for word alignment.
However, they cover only a smallpart of the connections in an average sentence and its translation.
Our experimentsreveal that the translations ofa word in context (in-context translations, ICTs for short)are frequently more diversified than the offerings in an everyday bilingual dictionary.More specifically, less than 30% of the English words in the context of LecDOCEexamples translate into one of the relevant DTs in the same dictionary.Translations in an everyday dictionary are meant o provide the reader with theidea of what is implied by the headword out of context; they are frequently more ofan explanation than a translation.
For instance, one LecDOCE sense entry defines theword boy as 'infml esp.
AmE a male person, of any age, from a given place' and gives~Z~,) , .
(modi lai zhi nanren) as the translation relevant o this particular sense.Such a 'translation' per se seems unlikely to appear as the ICT of boy.
Aside from thisfundamental difference, behind the disparity between DT and ICT are a plethora offactors.
These include (1) a failure on the dictionary's (or the statistically derived lexi-con's) part to cover a needed word sense, (2) mismatches in sense specificity between315Computational Linguistics Volume 23, Number 2the two languages, (3) collocation pattern, and (4) frequent use of interchangeable syn-onymous translation ot covered in the dictionary.
These factors are the reasons whymany translations are statistically unlikely, thereby leading to a low coverage rate forword-based methods.Sense Gaps.
Dictionary and statistically derived translations might not cover the wordsense appropriate to a given word in context.
This is particularly true when using aneveryday dictionary for aligning bilingual technical manuals.
For instance, the Lec-DOCE lists four senses and relevant translations for the word click, including (1) ~~ ~ { ~  'to make a slight and short sound', (2 ) /~ 'to succeed', (3) { ,~~ 'to fall into place', (4) ~ ,K~,~ 'to be a quick success, esp.
with members ofthe opposite sex', none of which is the right sense for ~ 'to press', the translation ofclick in the context of (El):(El) Click anywhere lse on the screen background or press ESC.
(C1) ~ i~ l~f l J~ : l~ i '~__ - -F \ ]~ ESCoMismatch in Sense Specificity.
Dictionary treatment of word senses in the source lan-guage might not correspond to the level of specificity for the relevant concepts in thetarget language.
For instance, the LecDOCE differentiates two word senses for theword news by the means in which it is reported: whether it is via electronic (radio ortelevision) or non-electronic (newspaper) media.
In Chinese, the relevant concept isalso differentiated according to how it is reported; however, the difference is betweenmass media (translated as ~r~)  and personal communication (translated as ~,~,).The following examples (E2, C2) and (E3, C3) demonstrate his particular instance ofmismatch in sense specificity.
(E2) to listen to the 7 o'clock news broadcast.
(C2) ~ t ~ t i ~ ~ o(E3) Our latest news of our son was a letter a month ago.
(C3) ~ J  ~-~ ~ ~i i~ l .~  ~ f~I-- ~ ~J ~/0~J ~ ~l~ oCollocation Pattern.
The collocation pattern often forces the choice of an ICT quite dif-ferent from the DTs.
For instance, the LecDOCE lists ~r~ 'news' and ~ r ~  'newsreportage' as the translations for news.
However, the translation for news modifiedby bad is usually ~j0~, 'message'.
Similarly, lady modified by old almost surely trans-lates into 5~ 'wife' rather than the DTs, ~ 'lady' or ~;~f'~ 'woman' given in theLecDOCE.
The following examples provide further details.
(E4) Nothing but bad news in the newspaper today.
(C4) @3~.~_L~ ~ 0g, o(C4') ~@~W,~ l - .~~r~ o(E5) He was very attentive to the old lady and did everything for her.316Sue J. Ker and Jason S. Chang Word Alignment(c5)(cs')(c5")(E6)(c6)(C6')He abdicated all responsibility for the care of the child.
?~ ~'~ -~,J~ Fx ~-  t .B~ oInterchangeable Synonymous Translation.
Disparity might arise simply because an in-terchangeable synonym of a DT is used.
For instance, for the following LecDOCEexamples, the synonyms ~| ,  ~g,  and ,~oF,~ are present in the translations, insteadof the respective DTs, ~| ,  ~ J ,  and ,~,~.
If these ICTs in (C7, C8, C9) are replacedby the DTs, the subsequent translations (C7 ~, C8', C9') remain correct.
(E7) I caught a fish yesterday.
(c7') ~f J~\ ] -~.
o(E8) I have never met so nice a girl.
(C8) ~ .
~  ~_~J~x-T"  o(c8') ~ ~ J  ~ ~ o(E9) He abandoned himself to grief.
(C9) f l~m,~ ~ o(C9') { t~J j ,~  oA statistically-derived l xicon generally fares better than MRDs in covering such syn-onymous translations.
However, this is limited to synonyms that appear as an alter-native translation frequently and consistently in a bilingual corpus.Bounding the ICTs.
An ICT may deviate from the relevant DTs for a variety of reasons,but the deviation is not without constraints.
Table 1 lists some examples of deviatingtranslations taken from the LecDOCE.
Examples include the words news, meet, lady,grief, care, and child and their respective translations ~j,~,, ~ j~,  ~,  ,~ ,  ~,and q~.
Notice that most in-context and dictionary translations of source wordsare bounded within the same category in a typical thesaurus uch as the LLOCE(McArthur 1992) and CILIN (Mei et al 1993).
For instance, Da19-class words in CILIN(news and messages), ~J~,~,, ~r~,  ~ appear as the translations (DTs and ICTs) forGe194-words in LLOCE (information and news) such as news and report.
Similarl3~Idl8-class words (hitting, touching, meeting, and missing), ~ ,  ~ J ,  ~ ,  Mi~appear as the translations for McO72-words (meeting people and things) such as meetand encounter.
This finding suggests that LTP can be estimated more robustly via class-to-class mapping.
Furthermore, such ICTs and DTs are often synonymous compounds317Computational Linguistics Volume 23, Number 2Table 1Disparity between ICT and DT is bounded within thesaurus categories.Example Sentences Word ICT DTWhat wonderful news: the painting on my wall is a news ~\]~0~, ~ '~Rembrandt!~_  ~ ~j~  ,~.
~J~J~_L ~\ ]~  ;l~ ~ ~J ~ ~ ~ o (Gel94) (Dal9) (Dal9)Reports that the general is to be dismissed are gaining report ~\]~?~, ~currency among government ministers.~ i  ~J\] ~ ~ J~ I~ ~J ~\]~ o~.
~ ~ ~J~ -~ ~ j~ ~Jl ~ ~ ~ ~ o (Gel94) (Dal9) (Da19)I have never met so nice a girl.~ ~ _ ~ ~ oHe encountered many difficulties.meet ~ ~\ ](Mc072) (Idl8) (Id18)encounter ~|  ~;  i~(Mc072) (Id18) (Id18)He was very attentive to the old lady and did everything lady ~k~5~for her.~d~J ~\]~ ~ ~ ~ ~ ~ ~1~,/'.~, 3u~j$~ t "~ o (Ca005) (Ab01)She's a very wealthy woman, and moves in the highest woman 2~circles of society.~_~ ~\[~;J~ J~ ,  ~\ ]~,  ~,~?~.~\ ]  o (Ca002) (Ab01)~?
(Ab01)~t~; ~;(Ab01)He abandoned himself to grief.~$~L~.~ oThe sad man was in an abyss of hopelessness.grief ,~  ,~, {~(Fd082) (Ga01) (Ga01)sad ,~{~ ~,/'.,; ,~ ;(Fd080) (Ga01) (Ga01)He abdicated all responsibility for the care of the child, care ~1~ ~- \ [{l~\]J~ ~ IF ~(~  -~ tJ' ~ ~J -- fg-J ~/r~ o (N1366) (Hi37) (Hi37)We should advertise for someone to look after the look after ,~$a~ ~?~garden.~ J~ ~,, ;~F~ ~ ~ I~.K.
~ ~ ~5~ .
\[~ o (Nf162) (Hi37) (Hi37)He abdicated all responsibility for the care of the child, child t\]~\]~ ~'~~t~\]j~ ~ ~" ~ ~ -~ sJ, ~ ~J -- fd-J ~ ~J~ o (Ca003) (Ab04) (Ab04)John Smith?
Yes - he's a local boy, I believe, boy ,/k ~J,K,,,~tJ~\]~I~r~J~?
~\[~J, ~J~,~,~d~:~:i~.Jk o (CaO02) (Ab02) (Ab01)that share a common morpheme.
For instance, the (ICT, DT) pairs, ( ,~  and ,~{~) and(~ and ~)  share a common morpheme ,~ 'sad' and ~ 'female', respectively.
Fujiiand Croft (1993) also point out a similar thesaurus effect of Mandarin morphemes inJapanese information retrieval (IR)JDictionary-based Alignment.
The above observations suggest that a DT-based algorithm,coupled with morpheme-level partial matching, can be adopted to obtain a substantial1 Fujii and Croft observe that a document is likely to be relevant if it contains an index term that has amorpheme (kanji) in common with a query term.
More often than not, the index term and the queryterm are synonyms that might appear under the same category in a thesaurus.
The authors call thisphenomenon the thesaurus effect of kanji.318Sue J. Ker and Jason S. Chang Word AlignmentTable 2Complete and partial matches against dictionary translations.Example Sentences and TranslationsI only know it was a dog andnot a cat that bit me.I have made you an absolutepromise that I will help you.There was an acute lack of food.~ _ ~  oHe added the wood to the fire.Complete Matches(Headword, DT=ICT)(know, ~1~/),(bit, \[\]~),(dog, ~), (cat, ~)(help, ~Jl~J ),(you, ~) ,(will, ~)(lack, ~ ),(food, ~J.~)(he, fl~),(fire, ~)Partial Matches(Headword, DT, ICT)(only, ~ ' ,  ~)(have, ~ ,  ~..~),(absolute,~ ,  ~:~)(acute, ~ ~,  ~)(wood, ~:~, :~)(wood, ~,  ~)number of high-precision connections.
Experimental results indicate that a DT-basedmethod connects over 40% of words in LecDOCE examples with their ICTs using thisrudimentary method.
Table 2 presents ome examples from the experiments, indicatingthe connections that are attributed to a complete or partial match using headword-and-DT pairs extracted from the LecDOCE.
For instance, partial match enables the methodto pair up only and F~ according to its DT J~ ' .
These connections can be subsequ6ntlyused as the basis for generalizing to a class-based alignment rule in the form of (X, Y),which stipulate the connection between an X-class word and a Y-class word.2.2 Class-based Word AlignmentTo ensure broad coverage, the class-based approach seems to be a promising alter-native to word-based methods.
Classes can be formed from words in more than oneway.
Automatic statistical methods for derived classes (Brown, Della Pietra, deSouza,Lai, and Mercer 1992) are not appropriate, since they also suffer low coverage due todata sparseness.
Classes formed from morphologically related words are easy to de-rive and apply.
Morphological classes can be formed, either from words that start withthe same five-character p efix as in Gale and Church (1991b), or rigorous analysis assuggested in Brown, Della Pietra, Della Pietra, Lafferty, and Mercer (1992).
Althougheasily applicable, morphological classes are not particularly effective in broadeningcoverage of word alignment.
Chang and Chen (1994) also examine the feasibility ofusing part-of-speech lasses.
A potential alternative involves adopting categories avail-able in machine-readable lexicographic resources such as Roget's thesaurus (Chapman1977) or hand-crafted computer lexicons (Miller, Beckwith, Fellbaum, Gross, and Miller1990; McRoy 1992).3.
Algorithms Leading to Class-based Word AlignmentThis section describes a series of three algorithms leading to a class-based systemfor word alignment.
The first algorithm attempts to obtain reliable connections.
Thesecond algorithm generalizes the connections into a list of class-based rules, whichstipulate that a pair of classes of words in the source and target languages are likelymutual translations.
The third algorithm performs the actual word alignment basedon the acquired rules, in addition to DTs.319Computational Linguistics Volume 23, Number 23.1 Dictionary-based Word AlignmentThis section describes a rudimentary word-alignment algorithm, DictAlign, based onthe DTs from a bilingual MRD such as the LecDOCE.
Consider a text and translationpair (S, T), a word s in S, and its ICT, t in T. Let DTs denote the set of translationslisted in the LecDOCE for the headword s. Recall that if for a word t in T, there is a dtin DTs such that t matches dt completely or partially, then, t is likely to be the ICT ofs.
Taking advantage of this phenomenon, DictAlign computes the set WT = {t \] t is aword in T} and calculates the similarity between each t and the DTs relevant o S. Asimilarity measure based on the unweighted Dice coefficient (Dice 1945) can be givenas follows:2 x Id n tl (1)Sim(d, t) - id \[ + it Iwhere d, tIdlItlla n tl= Mandarin morpheme strings,= the number of the morphemes in d,= the number of the morphemes in t,= the number of the morphemes in the intersection of d and t.Based on this similarity measure, the likelihood of a connection can be associated withthe following formulation that links the likelihood of a connection to similarity witha DT:DTSim(s, t) = max Sire(d, t) (2)dEDTsFor instance, consider the following sentence and its Mandarin translation, focusingon the word encounter:S = He encountered many difficulties.T =We will have the following:Ws = {he, encounter, many, difficulty}wT = 2 ,  iil, Iil , }DTencounter = {~,  ~11~, ~ }.Therefore, the connections relevant o encounter with nonzero DTSim values based onunweighted Dice coefficient are as follows:DTSim( encounter, ~ )DTSim( encounter, ~\ ]  )= max{S im(~,  ~),Sim(itl l~, ~),Sim(~tl~, ~)}2x l  0 2x l~= max 1+2,1_T_2, i_T_~j=0.67= max{S im(~,  ~t \ ]  ),Sim(i~t~, ~f \ ] ) ,S im(~,  ~!
\ ]  )}{2x l  0 2x1~= max 2+2'2+2'2+2j=0"5The head morpheme in a word is usually more relevant in determining a word'smeaning, just as content words carry more meaning than function words.
Matchingsuch a morpheme often implies a higher likelihood of finding the ICT.
For instance,is the head morpheme of the DT ~I \ ] ,  and should be given a heavier weight.
Our320Sue J. Ker and Jason S. Chang Word Alignmentexperiments indicate that by weighting morphemes, ICT ambiguity can be resolvedmore successfull3a Assuming that such weights can be obtained in a manner similarto what is done in IR when assigning weights to index terms, the weighted Dicecoefficient can be used by substituting weights for counts in equation (1) to arrive atthe following:2 x \[d A t\[ (3)Sim(d,t) - jd l+ it\]where d, tlalitllantl= the Mandarin morpheme strings,= total weights for the morphemes in d,= total weights for the morphemes in t,= total weights for the morphemes in the intersection of d and t.The above descriptions are summarized as the DictAlign Algorithm:Algorithm 1 (DictAlign) Align each word s in S with the ICT t in T based on DTs.Step 1: Remove all stop words in S to obtain a list of keywords, Ws.Step 2: Lookup all possible words WT of T in a dictionary.Step 3: For each s in Ws, look up the root of s in a bilingual dictionary to obtain DTs.Step 4: For all d E DTs and all t E WT, calculate Sire(d, t) according to equation (3).Step 5: For each (s, t) E Ws x WT, calculate DTSim(s, t) according to equation (2).Step 6: For each word s, produce a connection (s, t), if DTSim(s, t) is maximized overt E WT and DTSim(s, t) > hi where hi is a preset hreshold.Step 7: Compile the list of Connections and denote the list as CONN.To illustrate how DictAlign works, consider the sentence pair (El0, C10).
After thestopwords are removed, we obtain Ws = {old, lady, clad,fur, coat}.
The list of wordsin T is also obtained by consulting a Chinese dictionary.
2 Subsequently, for each s inWs, we lookup s in the LecDOCE to obtain DTs.
Table 3 shows dictionary translationsrelevant o (El0).
Table 4 lists all Ws words along with the relevant DTs, possibletranslation t, as well as the values of Sim(d, t) and DTSim(s, t).
Table 5 displays theresult CONN for various values of threshold hi.
(El0) The old lady was clad in a fur coat.
(C10) ~.~i~  ~,K.
~J~ F ~ ~ o3.2 Acquisition of Mutually Translatable Class PairsClassAlign is conceived to capture the diversity of translations for broad-coveragealignment.
One way to do so is via the classification of words in thesauri.
Morespecifically, one can generalize from a connection (s, t) to a class-to-class mapping(X, Y) where X and Y are thesaurus classes containing s and t respectively.
However,this simple intuition is complicated by the fact that a word might belong to morethan one class, that is, if the classification is based on a thesaurus that allows forword-sense ambiguity.
For a word in a particular context, if one considers classes thatare not intended for the context, noise can be introduced.
For instance, consider the2 The dictionary used in this study is a combination f CILIN and an on-line dictionary developed bythe CKIP group, Academy Sinica, Nankang, Taiwan.321Computational Linguistics Volume 23, Number 2Table 3The DT~ for each word s in INs for example (El0, C10).Word Root Stopword Dictionary Translations of Words in Sthe the yes None (all sense ntries have an explanation i brackets;not a translation)old no l-'-~l~,,~l~J, J~.,~Jl~J, ~J~l~J, ~1~1~I, ~l~i~fftJ, ~l~J,~ ~  .
.
.
.~:t: ,  ~ ,  9~.K, ~ ,  ~/~i~I ,  ~-.K,~_, i '~ ,  ~ .
.
.
~_1:,  ~ .
.
.
~M .
.
.
.~ ,  t~-_~,~- _~_~,~'  ~ --.
~,, ~ .
.
.
~ ,  ~, ~, ,  ..-~ ,  -~ ,  ,~  ~, ~-  ~ ....~ ,  ~ ,  ~,  ~,  ~ ~ ,  ~oldlady lady nowas be yesclad clad noin in yesa a yesfur fur nocoat coat noTable 4All connection candidates and DTSim values in (El0, C10).s E Ws t E WT dt E DTs Sim(dt, t) DTSim(s, t)old ~ ~ l~J  0.54 0.74old ~ ~l~l 0.74 0.74old ~ ~EI~ fl~J 0.41 0.51old ~ ~l~J 0.51 0.51old ~.h .
~ I~ 0.35 0.42old ~.
)k  ~l~J 0.42 0.42lady ~ ~; ;~ ~\[tl 0.30 0.30lady ~,h ,  ~ j l~t t  0.27 0.31lady ~.K .
~.K.
0.30 0.31lady ~ j~,  ~ j~ 0.31 0.31lady ~J~ j~~tt  0.31 0.39lady ~,h.
~,j~ 0.37 0.39lady ~j~, ~,h~ 0.39 0.39lady ~ ~J l~ J  0.34 0.34lady J~ ~,/k 0.52 0.56lady .h.
51~.
)k 0.56 0.56clad ~ ~j~ 0.71 0.71clad ~I~ ~'~ 1.00 1.00clad ~ ~ ~ 0.62 0.62fur ~ ~ J ~  ~1~ 0.31 0.67fur ~ ~j~/~ 0.53 0.67fur /~ ~ 0.67 0.67fur /~ ~!~ 0.67 0.67coat ~ ~P~IJ~JyJ  ~ L~ ~\[~ 0.31 0.31322Sue J. Ker and Jason S. Chang Word AlignmentTable 5The results of running DictAlign on(El0, C10) under various thresholds.Threshold = 0.7Word s Translation t DTSim(s, t)old ~ 0.74clad ~ j~ 1.00Threshold = 0.67Word s Translation t DTSim(s, t)old ~ 0.74clad ~ 1.00fur }J~ 0.67Threshold = 0.5Word s Translation t DTSim(s, t)old ~ 0.74lady ,K, 0.56clad ~ j~ 1.00fur /~ 0.67connection (have, ?Z) found in the context of Example (Ell, Cll).
According to theLLOCE, have belongs to the following topical sets: Cb024 (relating to sex), De081 (hav-ing and owning), EaO03 (eating and drinking), Li273 (auxiliary related to time), andNil59 (making necessary).
The LLOCE class EaO03 and CILIN class Fc06 (to eat, chew,suck, and drink) are intended for this context.
However, without hat information, thefollowing noisy rules might be introduced: (Cb024, Fc06), (De081, Fc06), (Li273, Fc06),(Nf/59, Fc06), along with the signal (EaO03, Fc06).
(Ell) Let's have breakfast early for a change.
(Cll) ~J~31~l~qk, -~- -~ i l~-~oThe noise is usually distributed randomly while the signal tends to repeat itself.Nevertheless, connections (s, t) related to some ambiguous words s or t may causenoise to accumulate, leading to erroneous generalization.
Therefore, one should try tothrow away such noise.
Moreover, any signal that gets thrown away by not considering(s, t) is often filled by a connection (s', t) where s' is a synonym of s. For instance, get ismany ways ambiguous, as indicated in diversified ICTs in the LecDOCE examples inTable 6.
However, each of these ICTs seems to form a connection with a less-ambiguoussynonym of get such as receive, reach, and understand in LecDOCE examples.
Table 6provides further details.As is typical in IR research, highly frequent and ambiguous words (known asstopwords in the IR literature) can be thrown out to reduce such noise.
A list ofstopwords used in the experiments includes the following:a, at, be, drive, eye, field, fix, for, from, function, get, go, have, head, idea, in, into,lot, of, on, place, the, to, up, with .
.
.
.
33 Stopwords include ye, field, and fix, which are not usually member of stopword lists in IR.
They are323Computational Linguistics Volume 23, Number 2Table 6Some sentence-translation pairs containing the word get.Example and Translation Source/Class ICTI got a letter today, get I~l\]~@ ~ ~ ~J -~  {~ o (De083, Getting and earning)It is unpleasant toreceive anonymous letters.
receive I\[~\[\](De083, Getting and earning)We got there at 8 o'clock.His hunger was not appeased until hereached the hotel.get ~\ ]~(MaO05, Arriving and reaching)reach ~|~(Ma005, Arriving and reaching)I don't ge___tt you; what do you mean?
get ~\]1~(Gb031, Understand and realize)I understood that it was time to leave.~t~ ~)~  ~-~3"  ounderstand(Gb031, Understand and realize)With the difficulties of finding appropriate classification systems and suppress-ing noise now resolved, the question remains: How can class-to-class mapping beacquired?
Just as with the derivation of a bilingual lexicon from a corpus, acquisitionof such mapping requires a statistical measure.
The Dice coefficient (Dice 1945) is asimilarity measure that gauges the ratio of the members in one collection being iden-tical to those of another collection.
Smadja, McKeown, and Hatzivassiloglou (1996)propose to link co-occurrence to the Dice coefficient in their study of bilingual collo-cations.
They observe that, unlike statistical measures related to mutual  information,the Dice coefficient is insensitive to sample size and, thus, more effective for acquiringbilingual collocations from a bilingual corpus.
Our experimental results confirm theirobservation.
Under a formulation linking translation to conceptual similarity, the Dicecoefficient is a very useful estimator of the class-to-class mapping.Therefore, in this work, we measure the likelihood of class-to-class translationmapping in terms of the ratio of member pairs that are connections observed in abilingual corpus.
This ratio can be easily measured using the Dice coefficient as follows:From(a, Y) + ~ To(X, b)ClassSim(X, Y) = acx bEYIX\[ + \]Y\](4)where IXI = the total number of the words in X,IYI = the total number of the words in Y,From(a,Y) = 1, if (3y E Y)(a,y) E ALLCONN,= 0, otherwise,treated as such because of their high frequency in the LDOCE and their involvement indiverse LLOCEtopics and CILIN categories.
For instance, the LLOCE lists eye under the following topical sets: Ac051(part of an animal), Aj151 (part of a plant), Bc023 (part of human body), Dg152 (part of a shoe), Hd126(part of a needle), etc.324Sue J. Ker and Jason S. Chang Word AlignmentTo(X, b) = 1, if (3x E X)(x, b) E ALLCONN,= 0, otherwise,ALLCONN = the word-translation pairs compiled from the results of runningDictAlign on all sentence-translation pairs of a bilingual corpus.This naive estimator works efficiently for classes of compatible sizes.
Occasion-ally, for extremely small or large classes, the coefficient does not accurately reflecthow likely words in one class are to translate to words in another class.
To remedythis problem, we explore the feasibility of weighting the member words.
Accordingto our result, weighting eradicates most instances of the problem caused by unevenclassification.
The weight assigned to each word should positively correlate to thefrequency of the word so it reflects the expected ratio of word-translation pairs.
As-suming that such weights can be obtained on the basis of each word's frequency ina bilingual corpus, weights can substitute for counts in equation (4) to arrive at theweighted version of the Dice coefficient shown below:~ From(a, Y)+ y~To(X,b)ClassSim(X, Y) = a~x bEYIXI + IYI (5)where IXI = the total weights of the words in X,IYI = the total weights of the words in Y,From (a,Y) = the weight of a, if (3y E Y)(a,y) E ALLCONN,= 0, otherwise,To(X,b) -- the weight of b, if (3x E X)(x,b) E ALLCONN,= 0, otherwise,ALLCONN = the source-translation pairs obtained for all sentences andtranslations in the training corpus using Algorithm 1.Algorithm 2 summarizes the ClassRule algorithm for acquiring class-based rules.Table 7 presents a random sample of class-based rules acquired from connectionsfound in LecDOCE examples and translations.Algorithm 2.
(ClassRule) Acquisition of pairs of mutually translatable classes (X, Y).Step 1: Run DictAlign on the sentences in a bilingual corpus to obtain a list of initialconnections ALLCONN.Step 2: For all X E CX and all Y E CY, compute similarity ClassSim(X, Y) based onweighted Dice coefficient given in (5), where CX and CY are some classifica-tion of words in the source and target languages, respectively.Step 3: Produce an alignment rule (X, Y),if ClassSirn(X, Y) > hi, a preset hreshold,or if ClassSim(X, Y) is maximized over all X in CX or all Y in CY.Step 4: Compile the list of such class pairs satisfying the conditions in Step 3 anddenote the list as RULES.325Computat iona l  L ingu is t i cs  Vo lume 23, Number  2L~0~Jz~Jo<~ ,  ._..~_ ~ - ~,~~- - '~-  .
_ , ~  ~ ' ~  .
.~"  -~ ,~o ~:  ~ ~= .o ~ ~ .~ ~~ o~ ~~?xl L?~ L?3 03 C) ~ C'1 "~ "~ t'~c5 c~ c~ c5 c~ c~ c~ c~ c~ c~326Sue J. Ker and Jason S. Chang Word AlignmentClass (CaO05) = {Mrs, Ms, broad, dame, female, girl, lad~ Madam, missis, miss,missus}Class (Ab01) = {~,  Yi~, ~'~,  ~,  ~.h., ~.K.~X, ~ff:, ~ ,  ~ ,  ~,~,  7, ,J,~l,9~A, ~,  '~ ,  ~ ,  '~ ,  ~ ,  ~: ,~ ,  ~JA, ~ ,  ~3~, ~1~,  ~,  ~ ,  -~, ~ ,  ~A,~,  ~t~X, ~ , .
}From (x, Ab01) = 1, for all x ~ {dame, female, girl, lady, Madam, miss}To (CaO05, x) = 1, for all x ~ {~.h., ~ ,  ~d~, ~-~,  ~\[~,  ~J'~\[~, 5~.h.
}7+6ClassSim(CaOO5,Ab01) - 11 + 9-----2 - 0.13Figure 1The word classes CaO05 and Ab01 and their conceptual similarity.The main step in ClassRule is illustrated through the calculation of the ClassSimvalue between LLOCE topical set CaO05 (kinds of woman) and CILIN category Ab01(man and woman, ~\].h., ~ ,  ~) .
For simplicity, the unweighted value of Class-Sim(CaO05, Ab01) is calculated.
CaO05 and Ab01 contain 11 and 92 words, respectively.In ALLCONN, six words in CaO05, i.e.
dame, female, girl, lady, Madam, and miss, trans-late into words listed under AbO1.
In the other direction, seven words listed underAb01, i.e.
!~J~, !~, !~,  ~-~,  ~,  t J~ ,  and 5~.h., are the translations from wordslisted under CaO05.
Thus, the ClassSim value between CaO05 and Ab01 can be valuedat (7 + 6)/(11 + 92) = 0.13.
Figure 1 presents further details.3.3 Class-based Word AlignmentThe proposed alignment algorithm ClassAlign is based on the following observations:First, dictionary translations can be used to produce high-precision connections.
Thus,DictAlign should be employed to produce initial connections whose translations ex-hibit a high similarity to a DT.
That is, a relatively high threshold, 0.7 should be used.Second, the class-based rules acquired through the ClassRule Algorithm should cap-ture the diversity of translations to a large extent.
According to the observations inSection 2, the rules should stipulate most of the connections left out in the DictAlignstep.
Nevertheless, conflicting connections do occasionally arise.
Such conflicts can beresolved according to an additional consideration of distortion mentioned in Section IEstimating the Likelihood of a Connection Candidate.
The above observations can be statedformally from the perspective of Brown et al's (1993) Model 2.
As mentioned earlier,the model stipulates that a connection be given a probability value Pr(s, t), the productof lexical translation probability t(s I t) and distortion probability, d(i I j, 1, m).
Alsoaccording to the model, we give each connection candidate a probabilistic value basedon lexical and positional considerations:Pr(s, t) = t(s, t) x d(i,j) (6)We argue, however, that it is difficult to robustly estimate t(s, t) and d(i,j) for all thevalues of s, t, i, and j.
Therefore, the two functions are defined and estimated by alimited number of cases, according to lexical, conceptual, and positional conditions.327Computational Linguistics Volume 23, Number 2For this purpose, we define conceptual similarity between s and t as follows:ConceptSim(s, t) = max ClassSim(X, Y) (7)sE X, tE YLexical and conceptual conditions are set up based on DTSim and ConceptSim, whilepositional conditions are set up based on dislocation, a distortion measure relative toboth left and right context.Estimation of LTP Based on Lexical and Conceptual Conditions.
The LTP t(s, t) is defined bythe following cases:Case 1.Case 2.Case 3.Case 4.Connection (s, t) exhibits high lexical and conceptual similarit)5i.e., ConceptSim (s, t) ~ hi and DTSim(s, t) > h2.Connection (s, t) exhibits high conceptual similarity, i.e.,ConceptSim (s, t) _> hi and DTSim(s, t) < h2.Connection (s, t) exhibits high lexical similarity, i.e.,ConceptSim (s, t) < hi and DTSim(s, t) _> h2.Otherwise, ConceptSim (s, t) < hi and DTSim(s, t) < h2.The connections satisfying each condition are given the same probability valuedetermined by maximal likelihood estimation (MLE).
For instance, if there are k trueconnections in a sample of n candidates (s, t) such that ConceptSim(s, t) > hi andDTSim(s, t) > h2, then all these candidates are given the same MLE value for LTP, i.e.,t(s, t) = tl = k/n.
Equation (8) sums up the above discussion:t(s,t) = {tl if ConceptSim (s, t) _> hi and DtSim(s, t) _> h2,t2 if ConceptSim (s, t) > hi and DtSim(s, t) < h2,t3 if ConceptSim (s, t) < hi and DtSim(s, t) ~ h2,t4 if ConceptSim (s, t) < hi and DtSim(s, t) < h2.
(8)Estimation of Distortion Probability (DP).
In a similar fashion, we formulate the distor-tion function by cases related to the monotonicity of translational position with respectto context.
Such a formulation is inspired by Gale and Church's (1991b) treatment ofdistortion.
In their study, the authors replace the distortion probability with a proba-bility function defined by different values of slope, a measure of the position of t withrespect o the left context of s. This measure is generally quite accurate, leading toa distribution function concentrating at slope 1.
Nevertheless, room for improvementstill exists, as can be illustrated using the concept of a binary inversion transductiontree (ITT) proposed by Wu (1995).
The ITT is a shared parse tree depicting the struc-tural difference between a sentence S and its translation T. Figure 2 presents the ITTof (E12, C12).
The horizontal bar denotes that the noun phrase such a lazy mortal andthe prepositional phrase as you are inverted when translated into Mandarin.
The slopeof the first word in such an inverted structure is typically quite large, making the dis-tribution of the slope function slightly fiat.
If multiword structural inversion occurs,as it frequently does, then the slope of the first word according to the right context isstill very small.
(E12) I1 've2 never3 known4 such5 a6 lazy7 mortal8 as9 you10.11(C12) ~1 ~2 ~-~:~3 .~4 ~J~5 ~/'\]\]~6 -~7 ~8 \[~J9 .
}klO o n328Sue J. Ker and Jason S. Chang Word AlignmentTable 8Alignment connections for example (El2, C12).i 0 1 2 3 4 5 6 7 8 9 10 11s $ I 're never known such a lazy mortal as yout $ ~J~ ~\[~ ~?.~ ~" ~il~ l .~  ~Jl ~ ,K. ~J/j 1 2 3 4 7 8 9 10 5 6 ~1I 've never known such a lazy mortal as you~?.
,~  ~ i~)~ '~!
(~.~) ,~ ~ 4.7,Figure 2ITT of the example-translation pair (E12, C12).For instance, the first word as in the inverted structure as you has a high slope valuewith respect o its left context such a lazy mortal.
However, since the words as and youtranslate into the fifth and sixth words in (C12), the word as has a slope value of 1with respect o its right context, you.We believe that by considering the translational position relative to both the leftand right contexts, one obtains a distribution function with a smaller deviation, therebymaking a tighter estimation possible for d(i,j).
To this end, we define dislocation, dis,for the connection (s, t) of the ith and jth words in S and T to denote I(J - j ' )  - (i - i')\[,where i' is the position of a word s' sharing the minimum syntactic structure withs, and s' translates into t', the j 'th word in T. Short of syntactic analysis, dis(i,j) canbe calculated with respect o a nearby connection in CONN, the initial connectionsestablished by DictAlign.
Such treatment closely approximates the dislocation value.In light of this, dislocation can be defined as follows:dis(i,j) = ( \[j - j ' \ [  if 3(j')(i,j') E CONN,min(\[dL\[, \[dR\[) otherwise, (9)where i = the sequence number of s in S,j = the sequence number of t in T, 4dL = ( j - - jL ) - - ( i - - iL ) ,dR = ( j - - jR) - - ( i - - iR) ,(iL,jL) = argmax(i,,j,)ecoNN<i i',(&,jR) = argmin(i,,j,)ecoNN>i /',CONN<i = {(k,l) \[kth and Ith word in (S,T) form a connection in CONN, k < i},329Computational Linguistics Volume 23, Number 2::::i.~;z:: :: : .
: :.
:::I i:..::: 've never known such a \[:::::1~:.
:::, mb:h~!
as ~i:i:,~you~ ::~::~::~:~ ........:.i?:.lii.
::: i:: 2 3 4 5 6 : :i:::::8::::i::~: i::i~:.O:.
::!i:i 5 :ii:.i:~:~:::i!~:ili ~:.
:i~::::~.
:~\]:~::.i?.i!w: : : !
: : : : : : : : : : : : : : : : : : : : : : : : :  i : : : i .
: :  : :::::::: : : : : :  ii:.::::.
::: ::::::::::::::::::::::::::::: ::::::::::::::::::::::::::::::::~ 0 1 2 3 4 3 ' ::i:~ :  i~:~i:::: ::: i~ ~i, i: :!
:: i z:~:::~!
i  i ::~!~::::i,~ :::: :::3!i:::;:::ii ii~i::;2::i-:: 0 0 1 2 3 j z::::!:~::~:~:~:~i:!
:i: 2 !i:ilili:\]~::::~:!ii::i.i~i.
!i::i.~.i~-i~8:.i~:i~:~.ii~: -: : : . '
:  ?
!
: : .
.
~ ' : "  . '
: .
.
:x:.
: :::::::::::::::::::::: .
.
::::::::::::::::::::::::5,  4 3 2 \] 3 ~::~ iii: ii : 2 :: i.i ::.~.
::i ' :: ~ii:i:.
::.ii::~ !~::~:i !
!ii: ', .
, .
:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::0 : : ::: :: : ' : ' " ' :  : : :  ": , : : : : ' , : : " "  : :  ? '
: :" ::::: i;"\[': :': ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::o :::: i::1:1::::: ::i;I0 i~: 8 7 6 5 4 ~::: 3::::i::: :::::::::::::::::::: 0 l:~:.~::~)~:: $:~}i~:i:.i i!
!.i~i:i~ii~iO::i.~;i~i~:i~}:iFigure 3Dislocation values for the example-translation pair (E12, C12).
Each connection candidate in(E12, C12) is represented as a cell.
The connections in CONN are shown as a bold face 0.
Eachof these zero dislocation values extends vertically, incrementing by one for each upward ordownward move, resulting in a shaded vertical bar of dislocation values.
All otherconnections take their dislocation values from the minimum diagonal projection of the relatedcell on the two bounding bars.
For instance, the projections of the connection (such, ~_~ )(shaded in figure) on the left and right bounding bars (/-connections and lazy-connections) are2 and 1, respectively.
Therefore, the dislocation value is 1, the minimum of 2 and 1.CONN>i = {(k, I) I kth and Ith word  in (S, T) form a connect ion in CONN, k > i},CONN = the initial connections establ ished according to DT.The distort ion funct ion def ined by cases can now be given according to dislocationvalues.
{ dl if dis(i, j) = 0,d(i, j) = d2 if dis(i, j) 1, (10)d3 if dis(i,j) 2,d4 if dis(i,j) > 3.The connect ion candidates with small  dislocation values tend to be true connec-tions.
For instance, 8 out of 15 zero-dislocation connections for (E12, C12) are correct,whi le only 1 out of 20 candidates with a dislocation of 1 is a true connection.
Allcandidates wi th  dislocation values greater than 1 are false.
Figure 3 provides furtherdetails.
Again, all connections atisfying a certain case in equat ion (10) are given thesame MLE value.
For instance, if there are k true connections in a sample of n can-didates (i,j) with 0 dislocation, then all of these candidates are given the same MLEvalue for DP, i.e., d(i, j) = dl = k/n for all i and j such that dis(i,j) = 0.By using a small  sample of 200 sentences from the LecDOCE, the LTP and DPvalues ti and di for 1 < i < 4 can be est imated by  the max imum l ikel ihood princi-ple.
Tables 9 and 10 summar izes  the MLE probabil istic values associated with lexical,4 The sequence number of Mandarin words is assigned according to the segmentation that satisfies thelong-word-first heuristic and is consistent with the established connections in CONN.330Sue J. Ker and Jason S. Chang Word AlignmentTable 9Maximum likelihood estimation (MLE) of LTP.# TrueConceptual nd Lexical Condictions # Candidates Connections MLE of t(s, t)ConceptSim(s, t) ~ 0.05 and DTSim(s, t) ~ 0.3 508ConceptSim(s, t) ~ 0.05 and DTSim(s, t) < 0.3 167ConceptSim(s, t) < 0.05 and DTSim(s, t) > 0.3 1,589ConceptSim(s, t) < 0.05 and DTSim(s, t) < 0.3 14,687481 h 0.94784 t2 0.503499 t3 0.193165 t4 0.011Table 10Maximum likelihood estimation (MLE) of DEDislocation # Candidates # True Connections MLE of d(i,j)dis = 0 2,158 893 dl 0.414dis = 1 3,445 210 d2 0.061dis = 2 2,805 31 d3 0.011dis > 3 9,543 95 d4 0.010conceptual, and positional factors.
The above description of word alignment is sum-marized as the ClassAlign algorithm.Algorithm 3.
(ClassAlign) Class-based word alignment for a pair of sentences (S, T).Step 1: Tag each word in S with POS information and convert each word to theroot form to obtain the set Ws of words in S.Step 2: Initialize the result ANS to an empty list.
Run DictAlign on (S, T) to obtaina list of initial connections, CONN.Step 3: Look up the dictionary to obtain the set WT of possible words in T.Step 4: For each connection candidate (s, t) E Ws x WT, compute Pr(s, t) accordingto equations (6) through (10).Step 5: Add to ANS the connection (s*,t*) that maximizes Pr(s,t) over alls, t E Ws x Ww with a value greater than h3.
5 Remove all conflictingcandidates involving s* and t* from subsequent consideration.
This steprepeats itself until the candidates run out or every remaining candidate(s, t) is associated with a Pr(s, t) value lower than h 3.Step 6: Output ANS as the final result of word alignment.3.4 An Illustrative ExampleIn the following, we demonstrate how ClassAlign works using example (El0, C10),reproduced below with the sequence number of each word denoted by a subscriptnumber.
(El0) The1 old2 lady3 was4 clads in6 a7 fur8 coat9.10(C10) ~1 ~2 ~3 ~.~4 ~5 ~6 ~7 o 8As demonstrated earlier in Section 3.1, DictAlign produces connections (old, ~)  and(clad, ~)  from (El0, C10) using a threshold value of 0.7 for DTSim.
Table 11 lists5 Ties are resolved in favor of the longer, leftmost Mandarin word.331Computational Linguistics Volume 23, Number 2Table 11Classes listed in LLOCE for Ws in (El0).Word POS Classes in LLOCEthe det Gh285old adj Lg200, Lg208, Lh241lady n Ci157, Ci158, Ci160, Ca005be v Aa001, De080, Li273, Na001, Nf159clad adj Dg136in prep Li272, Mh204a det Nd098fur n Hc088coat n Dg142, Hc093Table 12Classes listed in CILIN for WT in (C10).Word POS Classes in LLOCE~_ det Ed61~.~ n Ca31, Ka08~ n Cb01, Di15, Di17~ cl Dn08n Ab02adj Eb15, Eb24, Eb29, Eb36, Ec05, Ed51, Ee21~,h.
n Ab01n Ab01, Ah15),.
n Aa01, Dd17, De01, Dn03~j~ v Fa18n Bb04, Bc02, Bkl0, Bml0, Bin13adj Ee09n Bq03cl Dn08the Ws words and their relevant POS and topical sets in the LLOCE.
Table 12 displaysthe WT words and their relevant CILIN categories.
Table 13 presents the dislocationvalues for all connection candidates in Ws x WT.
The cells with a boldface 0 in Table 13represent the initial connections in CONN and two dummy connections placed at thebeginning and end of both sentences.
Table 14 lists the connection candidates withhigher Pr(s, t) values.After executing Step 5, ClassAlign selects the candidates, (lady, ~,k.)
,  6 (fur, ~.
), both with Pr(s, t) value of 0.392, in terms at Step 6.
These connections are addedto ANS and the conflicting candidates uch as (old, ~i~),  (old, ~, \ ]k ) ,  (old, ~A,),(lady, ~),  (lady, Jk), (in, gl,), (coat, gF.
), (fur, ~l~), etc.
are removed.
In the subsequentiterations, connections (coat, ~)  (Pr(s, t) = 0.208), (old, ~)  (Pr(s, t) = 0.080), (clad, ~)(Pr(s, t) = 0.080), and (The, ~)7 (Pr(s, t) = 0.005), are selected.
ClassAlign stops afterrunning out of connections with a probabilistic value greater than h3, 0.005.
Table 15summarizes the connections chosen to form the solution.
The success rate is evaluated6 This candidate ties with (lady, ~).
The conflict is resolved in favor of the longer Mandarin word.7 This candidate ties with (The, ~).
The conflict is resolved in favor of the leftmost Mandarin word.332Sue J. Ker and Jason S. Chang Word AlignmentTable 13Dislocation values for connection candidates ( , t) in (El0, C10)..iiiiliiii{ii@i{i{ii~i The ii~jiiiiii~iaii{i::::::::::::::::::::::::::: ::iiii!iiiiiii!i~ilil;iii!iilru - t~:E"  .
L !33~,~ iii@ililliiiiiiii!i!i!ii 0 bi','~sll::::::::::::::::::::::::::::::::::  : : :  : : r : .
.
.
.
.
.
: .
:+ : :iiiii!ii:ii:ii!ii!~iiiii 8 i ................ .
.
.
.
.
.
.
.
.
; .
.
.
.
.
.
.
.
.~A !i!iiiiiiii.i~i.
{.i.ii!i 2 \[iiiiii{iiiiiiiii{iiiiii{iiiii{i{\]~ iiiiiili!{iiiii',iiii'j!
~ iiiiiiii!ii{~:,~','~{ iI~,!i',~'~ii{i~iiii~!i@ili@':l 4 li~ iiii!Ui~ii!{iiiiiiiiiiil:+:.:+x+:+:'ii::iii;:ii?
:i::i~::iii::iii:: : :?o ,iiiiiiiiiiiiii{!iiiUi, 6 ii!!iiiiii~iiii~',~ili'~!;!
;lady was 'iiiii~!~!iiiiil ' in a3 4 ' ililiiiiiiiiii~iiii!iiiiiiiiii ' 4 52 3 ' iiiiiiiiiiiiii~iiiiiiiiiiiii{i ' 3 41 2 Liiii@ii~\[iiiiiiiiiiiilil ' 2 30 1 iiiiiiiiiiiii!i~ii{{{il 1 2o o ,, o -iiiiiii!
iiiiiiiii ?
, o2 1 '  iiiiii!iiji{{iiiii{i!i@ii' 0 13 2 "ii!ii{iiiiiiiii~iiii{{i{:i 1 04 3 ~ 2 1:::::::::::::::::::::fur coat iiiiiiii!iiii!iiiiiiii6 7 \[iliiiiiii!ilili~ili!iii!i!iil5 6 iiiiii!iiii!iiii~iiiiiiiiiiiiii'!J!iriiii i jili!i!ii!ii3 4 iiiiii!i{iiii!.~.iiiiiiii2 3 iiiiiii.iji.
!~iiiiiiii1 2 'ii:!:iiJi!iii~iiiii!ili!ii!iii'!97!'!??!?????????
{o 1 .iii!iiiiiii{ii i{ iiiiiiiiiiiil o !
!i!i!iiii!ii!i!i!i!i!iiio 1 liiiiiiiiiiiiii~iiiiiiiillaccording to how many English words are correctly aligned.
8 Evaluation is based on100% coverage, i.e., each word in the English sentence is checked for correct alignment.A word not given a connection is considered a failure if it should be connected to aMandarin word; otherwise it is considered a success.
For this example, all nine wordsare aligned correctly.
Therefore, the success rate is 9/9 = 100%.4.
Experiments with ClassAlignTo assess the proposed method's effectiveness, we have implemented the algorithmsdescribed in Section 3 and conducted a series of experiments.
Tests are performed onthe sentences found in the LecDOCE and a user's manual available in both languagesto assess the method's robustness and generality.
The similarities and differences be-tween English and Mandarin texts are briefly reviewed, since our experiments involvethe alignment of English-Mandarin parallel corpora.
A general description of the ma-terials used in the experiments follows.
Finally, the success rates are quantitativelyevaluated.4.1 Contrastive Analysis of English and Mandarin ChineseLanguage typology is the study of similarities and differences between languages,formalized in terms of parameters such as word order and morphological structure.Li and Thompson (1981) examine Mandarin Chinese according to four typologicalparameters that reveal the basic structure of Mandarin Chinese as compared to thoseof other languages, English in particular.
These four parameters are the morphologicalstructure of words, the number of syllables per word, topic prominence, and wordorder.
Li and Thompson's typological description of Mandarin is described below,from the perspective of the task of word alignment.8 A small percentage of connections (7.8%) in our evaluation are incomplete ones and are considered tobe correct.
Melamed (1996) takes the same stance in his study of deriving a probabilistic lexicon.
Heobserves that even incomplete entries are useful for many applications and there are ways of expandingincomplete morphemes orwords in a connection, sothat they become complete (Smadja 1992).333Computational Linguistics Volume 23, Number 2Table 14The connection candidates ( , t) in (El0, C10) with higher Pr(s, t) values.Connection Candidates Lexical Translation Probability Distortion Prob TPi j s t ConceptSim(i,j) DTSim(i,j) t(s,t) dis(i,j) d(i,j) Pr (s,t)1 1 The ~t~ 0 0 0.011 0 0.414 0.0051 2 The ~i~ 0 0 0.011 0 0.414 0.0052 3 old ~ 0 0.74 0.193 0 0.414 0.0802 3 old ~;~ 0 0.51 0.193 0 0.414 0.0802 3 old ~,~ 0 0.42 0.193 0 0.414 0.0803 3 lady ~ 0 0.30 0.193 0 0.414 0.0803 4 lady ~,\]k 0.21 0.39 0.947 0 0.414 0.3923 3 lady ~ j~ 0 0.31 0.193 0 0.414 0.0803 4 lady ~ 0.21 0.34 0.947 0 0.414 0.3923 4 lady ,h. 0 0.56 0.193 0 0.414 0.0804 3 was ~ 0 0 0.011 0 0.414 0.0054 4 was ~,\]k 0 0 0.011 0 0.414 0.0055 5 clad ~ 0 0.71 0.193 0 0.414 0.0805 5 clad ~\ ]~ 0 1.00 0.193 0 0.414 0.0805 5 clad ~ 0 0.62 0.193 0 0.414 0.0806 6 in g~ 0 0 0.011 0 0.414 0.0057 7 a ~ 0 0 0.011 0 0.414 0.0058 6 fur /~ 0.28 0.67 0.947 0 0.414 0.3929 6 coat ~ 0 0.31 0.193 1 0.061 0.0129 7 coat ~ 0.14 0 0.503 0 0.414 0.208Table 15Final alignment of example (El0, C10).
Initial alignment connections are shown in shaded cells.i ::i.O:::.i: 1 .
:.2.7 .
3?
.
x : : :  " : : .
: .s The :~bld : ladyt .
:i$:11:_ ~ ~ ' i i~ ~)~,\ [ : : :  ij 1 2 ::::3 !i:.
4?
.
:77"  " v .4was::5:1!i!i!
6 7 8 9 iiiiiiliiii~ii~i~\]i01~iiii~iiiiil;.
: .
.
.
.~  : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :  171::ieladi.~:~il in a fur coat .......................... :::::i:;::,i .
: ?
: : ?
: : .
l  : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :.
.
:-:" ?
: : .
.
i \ ] \ [ "  " .
.
.
.
.
.
.
.
.:.
: ~!53!..
:!3;~ ~ 6 7 lii!
!ii!iii;i!iiiiiSilil;i!iiiiiii!iii:lMorphological Structure of Words.
The most striking feature of Mandarin as compared toEnglish is the relative simplicity of word structure.
That is, most Mandarin words arecomprised of a single morpheme rather than a stem morpheme and a suffix servinggrammatical functions uch as case (as in Turkish and Japanese), number, agreement, ortense (as in many other languages including English).
Mandarin verbs do have aspectmorphemes, including -j" (-le, perfective), ~ (-guo, experienced action) and ,~(-zhe,durative).
Other grammatical functions are either non-existent or expressed throughan additional function word.
In contrast o this lack of inflectional morphologicalcomplexity, Mandarin is relatively rich in other types of morphological combinations,including compounding.These morphological differences result in a difference in the number of words inan English sentence and its Mandarin translation.
In terms of alignment, this word-number difference means that mult iword connections must be considered, a task which334Sue J. Ker and Jason S. Chang Word Alignmentis beyond the reach of methods proposed in recent alignment works based on Brownet al's (1993) Model 1 and 2.Basic Orientation of the Sentence: Topic vs. Subject.
Another feature distinguishing Man-darin from other languages i topic prominence.
In addition to the grammatical rela-tion of subject, a description of Mandarin must include the topic element, which canbe characterized asfollows: First, a topic always comes first in the sentence and is op-tionally followed by a pause in speech.
Second, a topic is the old information of whichboth the speaker and listener have some knowledge.
Third, what distinguishes a topicfrom a subject is that the subject must always have a direct syntactic and semanticrelation with the verb, but the topic does not need to.
For instance, in the sentence(E13, C13), the first word ~ (daxiang, 'elephant') is the topic and the second word~ (bizi, 'nose') is the subject; ~ 'elephant' is the focus of the discourse, but it isthe subject ~ 'nose' that is very long; not ~ 'elephant'.
(E13) The elephant has a very long nose.
(C13) ~ ~:~ ql~ ~oDaxiang bizi hen changElephant nose very longThe topic prominence of Mandarin sentences represents alignment connectionswith a large distortion in position, leading to difficulty in estimating the likelihood ofa connection according to translational position.Word Order.
Greenberg (1963) stated that the world's languages fall into three wordorder groups according to the order of the subject (S), verb (V), and object (O) in asimple transitive sentence.
A language, in general, belongs to one of three basic wordorder types, SVO, SOV, and VSO.
By this notion, English is an SVO language in whichthe verb typically follows the subject and precedes the object.
For most languages,other aspects of word order, such as that of modifier and modified elements, correlatewith the order of V and O.
However, Mandarin is not an easy language to classifyaccording to this typology for a number of reasons.
First, the notion of subject is notwell-defined.
Second, unlike in English, word order in Mandarin is not determinedsolely on grammatical grounds but rather depends on semantics.
For instance, whetheran adverbial expression appears in pre- or postverbal position depends on subtlesemantic differences.
More specificall~ a time phrase in preverbal position tends todenote punctual time, while that in postverbal position signals durative time, as in:(E14) I have a meeting at three o'clock.
(C14) ~J~ -~ ~d~ ~\]~oI three o'clock have-a-meeting(E15) I slept for three hours.
(C15) ~  T ---~ ~i~oI sleep ASPECT three o'clock(C15') ~ ~ ~!
t~ m ToI three o'clock sleep ASPECTIn contrast, both kinds of time phrase appear in postverbal position in English.
As aresult of facts such as these, many linguists contend that Mandarin is a language intransition from SVO to SOV.
Further details can be found in Li and Thompson (1981).335Computational Linguistics Volume 23, Number 2Similar to the situation created for topic prominent sentences, the SOV featuresof Mandarin represent a deviation from the SVO order of English.
Such a deviationfurther worsens our ability to estimate the likelihood of a connection according totranslational position.4.2 The Experimental SetupThe experimental results obtained from the proposed algorithm with respect o wordalignment are presented in this section.
Nearly 42,000 example sentences and theirtranslations from the LecDOCE were used as training data, primarily to acquire rulesand to determine MLE estimates for the cases of LTP and DP.
The algorithm's per-formance was evaluated using the two sets of data.
The closed test set consists of200 examples and their Mandarin translations randomly selected from the LecDOCE.The English examples range from 8 to 23 words long; average xample length is 11.5words.
There are, on average, 1.56 inversions per example-translation pair.
The opentest set consists of 200 sentences randomly drawn from the English and Chinese ver-sions of the LightShip User's Guide.
The English sentences in this test set range from4 to 34 words long; average sentence length is 11.8 words.
There are, on average, 1.60inversions per sentence pair.
Table 16 provides some examples from the LightShipUser's Guides.The two thesauri, LLOCE and CILIN, are used as the classification systems ofsource and target words.
The LLOCE contains 23,769 entries and CILIN contains 63,754entries.
Both thesauri cover just over 90% of the words in the test sets.4.3 EvaluationThe first three experiments were designed to demonstrate the effectiveness of thenaive DictAlign algorithm based on a bilingual MRD.
According to the experimentalresults, although DictAlign produces high-precision alignment, the coverage for bothtest sets is below 30%.
However, if the thesaurus effect is exploited, the coverage canbe increased considerably, atthe cost of a decrease of less than 4% in precision.
Table 17provides further details.In the fourth experiment, he ClassAlign algorithm is employed to align both setsof test data again.
Table 18 reveals that the acquired conceptual information compen-sates for what is lacking in the LecDOCE to yield optimum alignment results.
TheClassAlign algorithm expands coverage almost twofold to over 80%, while maintain-ing the same level of precision.
The generality of the approach is evident from theopen test's comparably high coverage and precision rates.
As shown in Table 18, over80% of the source words in both test sets are connected to a target and over 90% ofthe connections are true ones.5.
DiscussionThis section thoroughly analyzes the alignment results from the experiments describedin Section 4 and, in particular, the data relating to cases where the algorithms failed.Analytical results demonstrate he strengths and limitations of the methods and sug-gest possible improvements o the algorithms.5.1 Compounding in MandarinAs stated earlier, the compounding effect in Mandarin frequently results in a changein the number of words between an English sentence and its Mandarin translation.The correct alignment decision for a Mandarin compound frequently involves morethan one English word.
ClassAlign often fails under such circumstances.
For instance,336Sue J. Ker and  Jason S. Chang Word A l ignment.o~J\[.jr1~J~?~m~ ~ o~ ~ ~ ~ o~a o .~ o~ '~'  ~ , ,~ 0~ ~ ~ ~ .~ .~  .?
~ 0 ~ ~.~  ~o ~_ ~ ~ ~ _ ~ .
~~.~ ~.~ ~.~ _~.
=~ ~0.~ ~'F~ =o ~.~O O "~ .~"  '~  ~ n o ~ ?
~.~ ~ ~ ~ ~a ~ ~ u~ ~'~  ~ ~' ?
'~ ~ ~-~ 0 '~  g.l.~ 0 ~ ~.~ ~..~ ..~ .~ t-....~ .m~337Computational Linguistics Volume 23, Number 2Table 17Experimental results for DictAlign.Test Set #1: LecDOCE Examples Test Set #2: LightShip Manual# Matched # Correct Coverage Precision # Matched # Correct Coverage PrecisionDictAlign 525 505 28.8% 96.2% 604 576 25.6% 95.4% (DTSim = 1.0)DictAlign 808 755 44.3% 93.4% 767 705 32.5% 91.9% (DTSim > 0.7)DictAlign 937 822 51.4% 87.7% 1023 825 43.4% 80.7% (DTSim > 0.5)Table 18Experimental results for ClassAlign.Test Set #1: LecDOCE Examples Test Set #2: LightShip Manual# of Words # Correct Coverage Precision # of Words # Correct Coverage PrecisionAll words 1,823 1,460 100% 80.1% 2,359 1,800 100% 76.3%Matched words 1,561 1,460 85.6% 93.5% 1,965 1,800 83.3% 91.6%ClassAlign incorrectly connects the compound @Ira in (C16) to a single English wordcompany according to the alignment rule (Co292, Din07).
(E16) She is a star with the theatre company.
(C16) ~1~ I~l I~ i~,,~ i!
oOther methods for aligning English and Mandarin texts in the literature also fallprey to the problem of Mandarin compounds.
For instance, the following partiallycorrect connections complicated by compounding are reported in a recent study onalignment of Hong Kong Basic Law (Fung and McKeown 1994).
(E17) monoxide(C17) - -~q~ ('carbon monoxide')(E18) Basic(C18) : ~  ('Basic Law')(E19) second(C19) - '~  ('second reading')Because it is not limited to the connections involved in a presegmented target sen-tence (Fung and McKeown 1994; Wu and Xai 1994), ClassAlign avoids most instances ofthese errors.
In addition, with elaborate preprocessing such as parsing, phrase group-ing, and collocation analysis (Smadja 1992), the problem of word-number difference338Sue J. Ker and Jason S. Chang Word AlignmentTable 19The final alignment of example (E20, C20).1 2 3 4 5 6 7 9 10He abdicated all responsibility the care i.
0~:: ', the child1 2 8 9 3 4 5 6can be averted by performing alignment at various levels: parse tree (Matsumoto,Ishimoto, and Utsuro 1993; Meyers, Yangarber, and Grishman 1996), phrase (Kupiec1993), and collocation (Smadja, McKeown, and Hatzivassiloglou 1996).5.2 Funct ion Words,  Co l locat ion ,  and Free Translat ionLanguage-Specific Function Words.
The morphological differences between English andMandarin give rise to many language-specific function words.
Such Mandarin functionwords are often quite ambiguous in part of speech as well as in word sense, leading tonumerous alignment errors.
For instance, ClassAlign connects the words for and of in(E20) erroneously to the morphemes T and ~ in (C20), respectively.
Table 19 presentsfurther details.
(E20) He abdicated all responsibility for the care of the child.
(C20) ~ ~ iF ~, @-~,\], ~x ~- -  ty-J ~ ~ oCollocation.
As mentioned in the previous section, collocation is one of the reasonswhy in-context translation usually deviates from the dictionary translation.
However,unlike other deviations, bilingual collocation is not easily bounded within a coupleof classes.
For instance, the translation for take (Mb051, carrying, taking and bring) inthe collocation take effect is usually ~ ('see') (Fc04, seeing and looking), as in example(E21, C21).
However, there is insufficient evidence to support a class-to-class mappingfrom Mb051 to Fc04.
In any case, deriving the MbO51-to-Fc04 mapping would be anovergeneralization.
(E21) How soon does the medicine take effect?
(C21) :~  3K~_ ~ ?Paraphrased and Free Translations.
For various reasons, such as language typology, style,and cultural differences, a translator does not always translate literally on a word-by-word basis.
Adding and deleting words is commonplace, sometimes resulting in aparaphrased or free translation.
Such translations obviously create problems for wordalignment.
For instance, in example (E24, C24), only one word, I, is translated literally,into ~.
The main verb angle in example (E25) is given a paraphrased translation~g~ ('to change the angle').
The noun phrase the people she is speaking to in (E25)is paraphrased as ~ 'audience.'
A significant amount of free translation arises dueto the use of four-morpheme Mandarin idioms for stylistic reasons.
For instance, theclause as long as I breathe in (E22) translates into an idiom ~'al~.%Zde~ and the sentence339Computational Linguistics Volume 23, Number 2(E23) translates into , , k ,~) .
Such free or paraphrased translations are beyond thereach of the proposed method.
(E22) I shall love you as long as I breathe!
(C22) ?
'?~- ~ ;2 ~I~ J~ :t~-~ ~ ~ o(E23) When in Rome, do as the Romans do.
(C23) .
, k .~  ~ o(E24) I don't care who wins.
(C24) ~?~rh~JMk~ ~ o(E25) She angles her reports to suit the people she is speaking to.
(C25) ~ g ~ ~ ~ @ ,  J ; ~ ~ o5.3 Class-based versus Word-based ModelsClassAlign achieves a degree of generality in the sense that a true connection canbe identified, even when it occurs only rarel}~ or not at all, in the training corpus.This kind of generality is unattainable with statistically trained word-based models.Moreover, class-based models offer the advantages of a smaller storage requirementand higher system efficiency.
Unfortunately, they have the disadvantage of erroneousovergeneralization from word-specific onnections.
For instance, due to the acquiredmapping from Gg273 (element of sound in language) to Bg07 (sound, tone, etc.
), theverb accent in (E26) is connected erroneously to ~\ [~ ('syllable') in (C26).
(E26) The accent in the word "important" is on the second syllable.
(C26) Important ~.~-~-~i~3~?~?~\[~.~ oNevertheless, our experiment has shown that the advantages outweigh the disadvan-tages, at least for this particular formulation of a class-based approach to alignment.6.
Concluding RemarksIn this paper, we have presented an algorithm capable of identifying words and theirin-context ranslations in a bilingual corpus.
The algorithm is effective for specificlinguistic reasons.
First, a significant majority of words have diversified translationsthat are not found in a bilingual dictionary or statistically-derived l xicon but that arelargely bounded within the word classes in thesauri.
Therefore, we contend that a moresuccessful alignment can be achieved using a class-based approach.
Our assumptionseems to hold, for the experiments in this study demonstrate hat the method providesbroad-coverage alignment with almost no loss in precision.In a broader sense, we have shown that thesauri and corpora can be used incombination to address the critical issues of generality and efficiency.
The thesaurusprovides classification that can be used to generalize the empirical knowledge gleaned340Sue J. Ker and Jason S. Chang Word Alignmentfrom a corpus.
The corpus provides training and testing materials, thereby allowingknowledge to be derived and evaluated objectively.The algorithm's performance could definitely be improved by enhancing the var-ious modules of the algorithms, e.g., morphological analyses, bilingual dictionar~monolingual thesauri, and rule acquisition.
Nevertheless, this work presents a func-tional core for processing bilingual corpora at lexical and conceptual levels.While this paper has specifically addressed English-Chinese corpora, the linguisticissues motivating the algorithms eem to be quite general and are, to a large extent,language independent, which means that the algorithm presented here should beadaptable to other language pairs.
The prospects for English-Japanese or Chinese-Japanese, in particular, seem highly promising.AcknowledgmentsThis work was partially supported by ROCNSC grants 82-0408-E-007-195,83-0408-E-007-010, 84-2213-E-007-023.
Weare grateful to Keh-Yih Su for hissuggestions and comments at the earlystage in the development of this work.
Weare also thankful to J-P Chanod and theanonymous reviewers for many usefulsuggestions.
We would like to thank LimingYu from Zebra English Service Union, BettyTeng and Nora Liu from Longman AsiaLimited, Keh-Jiann Chen and Chu-RenHuang from Academy Sinica, and PerryChang from Galaxy Software Services formaking the dictionaries, thesauri, andcorpora vailable to us.ReferencesBrown, P. F., J. Cocke, S. A. Della Pietra,V.
J. Della Pietra, F. Jelinek, J. D. Lafferty,R.
L. Mercer, and P. S. Roosin.
1990.
Astatistical approach to machinetranslation.
Computational Linguistics,16(2):79-85.Brown, P. F., S. A. Della Pietra, V. J. DellaPietra, J. D. Lafferty, and R. L. Mercer.1992.
Analysis, statistical transfer, andsynthesis in machine translation.
InProceedings ofthe Fourth InternationalConference on Theoretic and MethodologicalIssues in Machine Translation, pages 83-100.Brown, P. F., S. A. Della Pietra, V. J. DeliaPietra, and R. L. Mercer.
1993.
Themathematics of statistical machinetranslation: Parameter estimation.Computational Linguistics, 19(2):263-311.Brown, P. F., V. J. Della Pietra, P. V. deSouza,J.
C. Lai, and R. L. Mercer.
1992.Class-based n-gram models of naturallanguage.
Computational Linguistics,18(4):467-479.Brown, P. F., J. C. Lai, and R. L. Mercer.1991.
Aligning sentences in parallelcorpora.
In Proceedings ofthe 29th AnnualMeeting, pages 169-176, Berkeley, CA.Association for ComputationalLinguistics.Chang, J. S. and M. H. C. Chen.
1994.
Usingpartial aligned parallel text andpart-of-speech information in wordalignment.
In Proceedings ofthe FirstConference ofthe Association for MachineTranslation i  the Americas (AMTA),pages 16-23, Columbia, MD.Chang, J. S., J. N. Chen, H. H. Sheng andS.
J. Ker.
1996.
Combining machinereadable lexical resources and bilingualcorpora for broad word sensedisambiguation.
I  Proceedings oftheSecond Conference ofthe Association forMachine Translation i the Americas (AMTA),pages 115-124, Montreal, Canada.Chapman, R. 1977.
Roget's InternationalThesaurus.
Harper and Row, New York.Chen, Stanley F. 1993.
Aligning sentences inbilingual corpora using lexicalinformation.
In Proceedings ofthe 31stAnnual Meeting, pages 9-16, Ohio.Association for ComputationalLinguistics.Church, K. W., I. Dagan, W. A. Gale,P.
Fung, J. Helfman, and B. Satish.
1993.Aligning parallel texts: Do methodsdeveloped for English-French generalizeto Asian languages?
In Proceedings oftheFirst Pacific Asia Conference on Formal andComputational Linguistics, pages 1-12.Church, K. W. and W. A. Gale.
1991.Concordances for parallel text.
InProceedings ofthe 7th Annual Conference ofthe UW Centre for the New OED and TextResearch, pages 40-62, St. Catherine'sCollege, Oxford, England.Dagan, I., K. W. Church, and W. A. Gale.1993.
Robust bilingual word alignmentfor machine aided translation.
InProceedings ofthe Workshop on Very LargeCorpora: Academic and IndustrialPerspectives, pages 1-8, Columbus, OH.Daille, B., E. Gaussier, and J.-M. Lange.341Computational Linguistics Volume 23, Number 21994.
Towards automatic extraction ofmonolingual and bilingual terminology.In Proceedings ofthe 15th InternationalConference on Computational Linguistics,pages 515-521, Kyoto, Japan.Dice, L. R. 1945.
Measures of the amount ofecologic association between species.Journal of Ecology, 26:297-302.van der Eijk, P. 1993.
Automating theacquisition of bilingual terminology.
InProceedings ofthe Sixth Conference oftheEuropean Chapter of the Association forComputational Linguistics, pages 113-119,Utrecht, The Netherlands.Fujii, H. and W. Bruce Croft.
1993.
Acomparison of indexing techniques forJapanese text retrieval.
In Proceedings ofthe16th International ACM SIGIR Conference onResearch and Development i  InformationRetrieval, pages 237-246.Fung, P. and K. McKeown.
1994.
Aligningnoisy parallel corpora across languagegroups: Word pair feature matching bydynamic time warping.
In Proceedings ofthe First Conference ofthe Association forMachine Translation i  the Americas(AMTA-94), pages 81-88, Columbia, MD.Galaxy Software Services.
1994.
LightshipUser's Guide (in Chinese).
Galaxy SoftwareServices, Taiwan.Gale, W. A. and K. W. Church.
1991a.
Aprogram for aligning sentences inbilingual corpora.
In Proceedings ofthe 29thAnnual Meeting, pages 177-184, Berkeley,CA.
Association for ComputationalLinguistics.Gale, W. A. and K. W. Church.
1991b.Identifying word correspondences inparallel texts.
In Proceedings ofthe FourthDARPA Speech and Natural LanguageWorkshop, pages 152-157, Pacific Grove,CA.Gale, W. A. and K. W. Church.
1993.
Aprogram for aligning sentences inbilingual corpora.
ComputationalLinguistics, 19(1):75-102.Gale, W. A., K. W. Church, and D. Yarowsky.1992.
Using bilingual materials to developword sense disambiguation methods.
InProceedings ofthe Fourth InternationalConference on Theoretical nd MethodologicalIssues in Machine Translation,pages 101-112, Montreal, Canada.Greenberg, J. H. 1963.
Universals of Language.MIT Press, Cambridge, MA.Isabelle, P. 1992.
Bi-textual aids fortranslators.
In Proceedings ofthe EighthAnnual Conference ofthe UW Centre for theNew OED and Text Research, pages 76-89,Waterloo, Canada.Kay, M. and M. ROscheisen.
1993.Text-translation alignment.
ComputationalLinguistics, 19(1):121-142.Klavans, J. L. and E. Tzoukermann.
1990.The BICORD system.
In Proceedings ofthe13th International Conference onComputational Linguistics, pages 174-179,Helsinki, Finland.Kupiec, J. M. 1993.
An algorithm for findingnoun phrase correspondences in bilingualcorpora.
In Proceedings ofthe 31st AnnualMeeting, pages 17-22, Columbus, OH.Association for ComputationalLinguistics.Li, C. N. and S. A. Thompson.
1981.Mandarin Chinese--A Functional ReferenceGrammar.
University of California Press,Los Angeles, CA.Li, Hung-Wen.
1994.
Word Alignment andRefinement of Transfer Dictionary.
Masterthesis, Institute of Computer Science andInformation Engineering, National ChiaoTung University, Taiwan, R.O.C.Longman Group.
1992.
LongmanEnglish-Chinese Dictionary of ContemporaryEnglish.
Longman Group (Far East) Ltd.,Hong Kong.Macklovitch, E. 1994.
Using bi-textualalignment for translation validation: TheTransCheck system.
In Proceedings oftheFirst Conference ofthe Association forMachine Translation i  the Americas (AMTA),pages 157-168, Columbia, MD.Matsumoto, Y., H. Ishimoto, and T. Utsuro.1993.
Structural matching of parallel texts.In Proceedings ofthe 31st Annual Meeting,pages 22-30, Columbus, OH.
Associationfor Computational Linguistics.McArthur, T. 1992.
Longman Lexicon ofContemporary English.
Longman Group(Far East) Ltd., Hong Kong.McRoy, Susan W. 1992.
Using multipleknowledge sources for word sensediscrimination.
Computational Linguistics,18(1):1-30.Mei, J. J., I. M. Zhu, Y. C. Gao, and H. S. Yin.1993.
Tongyici Cilin (Word Forest ofSynonyms).
Tong Hua, Taipei.
(TraditionalChinese edition of a simplified Chineseedition published in 1984.
)Melamed, I. Dan.
1996.
Automaticconstruction of clean broad-coveragetranslation lexicons.
In Proceedings oftheSecond Conference ofthe Association forMachine Translation in the Americas (AMTA),pages 125-134, Montreal, Canada.Meyers, A., R. Yangarber, and R. Grishman.1996.
Alignment of shared forests forbilingual corpora.
In Proceedings ofthe 16thInternational Conference on ComputationalLinguistics, pages 460-465, Copenhagen,Denmark.
COLING-96.342Sue J. Ker and Jason S. Chang Word AlignmentMiller, G. A., R. Beckwith, C. Fellbaum,D.
Gross, and K. J. Miller.
1990.Introduction to Wordnet: An on-linelexical database.
Journal of Lexicography,3(4):235-244.Pilot Software Inc. 1993.
LightShip User'sGuide, Pilot Software Inc., Boston.Proctor, P. 1988.
Longman English-ChineseDictionary of Contemporary English.Longman Group (Far East), Hong Kong.Shemtov, H. 1993.
Text alignment in a toolfor translating revised documents.
InProceedings ofthe Sixth Conference oftheEuropean Chapter of the Association forComputational Linguistics, pages 449-453,Utrecht, The Netherlands.Simard, M., G. F. Foster, and P. Isabelle.1992.
Using cognates to align sentences inbilingual corpora.
In Proceedings oftheFourth International Conference on Theoreticaland Methodological Issues in MachineTranslation (TMI-92), pages 67-81,Montreal, Canada.Smadja, F. 1992.
How to compile a bilingualcollocation lexicon automatically.
InProceedings ofthe AAAI-92 Workshop onStatistically-Based NLP Techniques,pages 65-71, San Jose, CA.
AmericanAssociation for Artificial Intelligence.Smadja, F., K. R. McKeown, andV.
Hatzivassiloglou.
1996.
Translatingcollocations for bilingual exicons: Astatistical approach.
ComputationalLinguistics, 22(1):1-38.des Tombe, L. and S. Armstrong-Warwick.1993.
Using function words to measuretranslation quality.
In Proceedings oftheNinth Annual Conference ofthe UW Centre forthe New OED and Text Research, pages 1-17.Wu, D. 1994.
Aligning a parallelEnglish-Chinese corpus statistically withlexical criteria.
In Proceedings ofthe 32ndAnnual Meeting, pages 80-87, Las Cruces,NM.
Association for ComputationalLinguistics.Wu, D. 1995.
Gramrnarless extraction ofphrasal translation examples from paralleltexts.
In Proceedings ofthe SixthInternational Conference on Theoretical ndMethodological Issues in Machine Translation,pages 354-372, Belgium.Wu, D. and X. Xia.
1994.
Learning anEnglish-Chinese l xicon from a parallelcorpus.
In Proceedings ofthe First Conferenceof the Association for Machine Translation ithe Americas (AMTA), pages 206-213,Columbia, MD.343
