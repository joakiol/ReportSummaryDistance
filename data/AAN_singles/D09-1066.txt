Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 628?637,Singapore, 6-7 August 2009.c?2009 ACL and AFNLPA Comparison of Windowless and Window-Based ComputationalAssociation Measures as Predictors of Syntagmatic Human AssociationsJustin WashtellSchool of ComputingUniversity of Leedswashtell@comp.leeds.ac.ukKatja MarkertSchool of ComputingUniversity of Leedsmarkert@comp.leeds.ac.ukAbstractDistance-based (windowless) word asso-cation measures have only very recentlyappeared in the NLP literature and theirperformance compared to existing win-dowed or frequency-based measures islargely unknown.
We conduct a large-scale empirical comparison of a variety ofdistance-based and frequency-based mea-sures for the reproduction of syntagmatichuman assocation norms.
Overall, ourresults show an improvement in the pre-dictive power of windowless over win-dowed measures.
This provides supportto some of the previously published the-oretical advantages and makes window-less approaches a promising avenue toexplore further.
This study also servesas a first comparison of windowed meth-ods across numerous human associationdatasets.
During this comparison wealso introduce some novel variations ofwindow-based measures which perform aswell as or better in the human associationnorm task than established measures.1 IntroductionAutomatic discovery of semantically associatedwords has attracted a large amount of attention inthe last decades and a host of computational asso-ciation measures have been proposed to deal withthis task (see Section 2).
These measures tradi-tionally rely on the co-ocurrence frequency of twowords in a corpus to estimate a relatedness score.There has been a recent emergence of distance-based language modelling techiques in NLP (Sav-icki and Hlavacova, 2002; Terra and Clarke, 2004)in which the number of tokens separating wordsis the essential quantity.
While some of this workhas considered distance-based alternatives to con-ventional association measures (Hardcastle, 2005;Washtell, 2009), there has been no principled em-pirical evaluation of these measures as predictorsof human association.
We remedy this by conduct-ing a thorough comparison of a wide variety offrequency-based and distance-based measures aspredictors of human association scores as elicitedin several different free word association tasks.In this work we focus on first-order associ-ation measures as predictors of syntagmatic as-sociations.
This is in contrast to second andhigher-order measures which are better predictorsof paradigmatic associations, or word similarity.The distinction between syntagmatic and paradig-matic relationship types is neither exact nor mu-tually exclusive, and many paradigmatic relation-ships can be observed syntagmatically in the text.Roughly in keeping with (Rapp, 2002), we herebyregard paradigmatic assocations as those basedlargely on word similarity (i.e.
including thosetypically classed as synonyms, antonyms, hyper-nyms, hyponyms etc), whereas syntagmatic as-sociations are all those words which strongly in-voke one another yet which cannot readily besaid to be similar.
Typically these will have anidentifiable semantic or grammatical relationship(meronym/holonym: stem ?
flower, verb/object:eat ?
food etc), or may have harder-to-classify top-ical or idiomatic relationships (family ?
Christmas,rock ?
roll).We will show in Section 3.2 that syntagmaticrelations by themselves constitute a substantial25-40% of the strongest human responses to cuewords.
Although the automatic detection of theseassocations in text has received less attentionthan that of paradigmatic associations, they arenonetheless important in applications such as theresolution of bridging anaphora (Vieira and Poe-sio, 2000).1Furthermore, first-order associations1where for example resolving my house ?
the windows tothe windows of my house can be aided by the knowledge thatwindows are often (syntagmatically) associated with houses.628are often the basis of higher-order vector word-space models used for predicting paradigmaticrelationships: i.e.
through the observation ofwords which share similar sets of syntagmatic as-sociations.
Therefore improvements made at thelevel we are concerned with may reasonably beexpected to carry through to applications whichhinge on the identification of paradigmatic rela-tionships.After a discussion of previous work in Sec-tion 2, we formulate the exact association mea-sures and parameter settings which we comparein Section 3, where we also introduce the corporaand human association sets used.
Then, by usingevaluations similar to those described in (Baroniet al, 2008) and by Rapp (2002), we show thatthe best distance-based measures correlate betteroverall with human association scores than do thebest window based configurations (see Section 4),and that they also serve as better predictors of thestrongest human associations (see Section 5).2 Related WorkMeasures based on co-ocurrence frequency.The standard way of estimating the syntagmaticassociation of word pairs in a corpus is to ex-amine the frequency of their co-occurence, andthen usually to compare this to some expected fre-quency.
There are a host of measures which ex-ist for this purpose.
After raw co-occurrence fre-quency, the simplest and most prevalent in theliterature is Pointwise Mutual Information, fa-mously used by Church (1989) (as the associa-tion ratio).
This is defined as the log of the ra-tio of the observed co-occurrence frequency to thefrequency expected under independence.
Moresophisticated and statistically-informed measuresinclude t-Score, z-Score, Chi-Squared and Log-Likelihood (see Evert (2005) for a thorough re-view).All of these measures have in common that theyrequire co-occurrence frequency to be specified,and therefore require some definition of a regionwithin which to count co-occurrences.
This re-gion might be the entirety of a document at oneextreme, or a bigram at the other.
A versatile andhugely popular generalised approach is thereforeto consider a ??window??
of w words, where w canbe varied to suit the application.
Unsurprisingly,it has been found that this is a parameter whichcan have a significant impact upon performance(Yarowsky and Florian, 2002; Lamjiri et al, 2004;Wang, 2005).
While choosing an optimum win-dow size for an application is often subject totrial and error, there are some generally recog-nized trade-offs between small versus large win-dows, such as the impact of data-sparseness, andthe nature of the associations retrieved (Churchand Hanks, 1989; Church and Hanks, 1991; Rapp,2002)Measures based on distance between words inthe text.
The idea of using distance as an al-ternative to frequency for modelling language hasbeen touched upon in recent literature (Savicki andHlavacova, 2002; Terra and Clarke, 2004; Hard-castle, 2005).
Washtell (2009) showed that it ispossible to build distance-based analogues of ex-isting syntagmatic association measures, by usingthe notions of mean and expected distance ratherthan of frequency.
These measures have certaintheoretical qualities - notably scale-independenceand relative resilience to data-sparseness - whichmight be expected to provide gains in tasks suchas the reproduction of human association normsfrom corpus data.
The specific measure introducedby Washtell, called Co-Dispersion, is based uponan established biogeographic dispersion measure(Clark and Evans, 1954).
We provide a thor-ough empirical investigation of Co-Dispersion andsome of its derivatives herein.Measures based on syntactic relations.
Sev-eral researchers (Lin, 1998; Curran, 2003; Padoand Lapata, 2007) have used word space modelsbased on grammatical relationships for detectingand quantifying (mostly paradigmatic) word asso-ciations.
In this paper, we will not use syntacticrelation measures for two main reasons.
Firstlythese depend on the availability of parsers, whichis not a given for many languages.
Secondly, thismay not be the most pertinent approach for pre-dicting human free associations, in which certainobserved relationsips can be hard to express interms of syntactic relationships.3 MethodologySimilar to (Rapp, 2002; Baroni et al, 2008, amongothers), we use comparison to human assocationdatasets as a test bed for the scores produced bycomputational association measures.
An alterna-tive might be to validate scores against those de-rived from a structured resource such as WordNet.629Table 1: Human association datasetsName Origin Cues RespondentsKent Kent & Rosanoff (1910) 100 ?
1000Minnesota Russell & Jenkins (1954) 100 ?
1000EAT Kiss et al(1973) 8400 100Florida Nelson et al(1980) 5019 ?
140However, relatedness measures for WordNet aremany and varied and are themselves the subject ofevaluation (Pedersen et al, 2004).
Although hu-man association datasets have their own peculiari-ties, they do at least provide some kind of definiteGold Standard.
Yet another alternative might be toincorporate our computational association scoresinto an application (such as anaphora resolution),and measure the performance of that, but noisefrom other submodules would complicate evalu-ation.
We leave such extensions to possible futurework.We use evaluations similar to those used before(Rapp, 2002; Pado and Lapata, 2007; Baroni etal., 2008, among others).
However, whereas mostexisting studies use only one dataset, or hand-selected parts thereof, we aim to evaluate mea-sures across four different human datasets.
In thisway we hope to get as unbiased a picture as possi-ble.3.1 Association dataThe datasets used are listed in Table 1.
Whilethe exact experimental conditions may differ, thedatasets used were all elicited using the same ba-sic methodology: by presenting individual words(cues) to a number of healthy human subjects andasking in each case for the word that is most imme-diately or strongly evoked.
An association scorecan then be derived for each cue/response pair in adataset by dividing the number of participants pro-viding a given response by the number who werepresented with the cue word.
In Table 1, respon-dents refers to the number of people from whoma response was solicited for each cue word in astudy (this is not to be confused with the numberof unique responses).Of these four datasets, one (Kent & Rosanoff)appears not to have been previously used in anypeer-reviewed study of corpus-derived lexical as-sociation.
It is worth noting that some of thesedatasets are quite dated, which might affect corre-lations with corpus-derived scores, as culture andcontemporary language have a fundamental im-pact upon the associations humans form (Whiteand Abrams, 2004).3.2 Frequency of Syntagmatic AssociationsTo verify that strong human associations do in-clude a large number of syntagmatic associations,we manually annotated all pairs consisting ofa cue and its strongest human response in theMinnesota and Kent datasets as expressing ei-ther a syntagmatic or a paradigmatic relationship.The overall set to be annotated consisted of 200pairs.Annotators were given short (half-page) guide-lines on syntagmatic and paradigmatic assoca-tions, stating that very similar items (includinghyponyms/hypernyms) as well as antonyms wereto be judged as paradigmatic whereas words thatdo not fulfil this criterion are to be judged assyntagmatic.
The two annotators were the au-thors of this paper (one native and one near-nativespeaker).
After independent annotation, agree-ment was measured at a percentage agreement of91/93% and a kappa of 0.80/0.82 for Minnesotaand Kent, respectively.
Therefore, the distinctioncan be made with high reliability.Overall, 27/39% of the human responseswere syntagmatic in the Kent/Minnesota datasets,showing that syntagmatic relations make up alarge proportion of even the strongest human as-sociations.3.3 CorporaWe use two randomized subsets of the British Na-tional Corpus (BNC), a representative 100 millionword corpus of British English (Burnard, 1995):one 10 million word sample, and a 1 million wordsample.
A vocabulary of approximately 33,000word types was used.
The selected words includedapproximately 24,000 word types comprising allcue and target words from the multiple sets of hu-man association norms to be used in this study.
Tothese were added a top-cut of the most frequentwords in the BNC, until the total of 33,000 wordtypes was reached.
The resultant set included ap-630proximately the 24,000 most common word typesin the BNC, with the remaining 9000 words typestherefore comprising relatively uncommon wordstaken from the human associative responses.The words included in the vocabulary ac-counted for over 94.5% of tokens in the corpus.Although statistics for the remaining word typesin the BNC were not gathered, their correspond-ing tokens were left in the corpus so that thesecould be properly accounted for when calculatingdistances and window spans.In order to maximize matching between wordtypes in the corpus and association norms, allwords in both were normalized by converting tolower-case and removing hyphens and periods.Words consisting entirely of numerals, or numer-als and punctuation, and all ?phrasal?
associa-tive responses (those containing spaces) were dis-carded.
The 33,000 word count was satisfied aftermaking these normalizations.In order to maximize the variety of the languagein the samples, the subsets were built from ap-proximately the first 2000 words only of each ran-domly selected document from the BNC (a similarstrategy to that used in constructing the 1 millionword Brown Corpus).
Both a 10 million word anda 1 million word sample were constructed in thisfashion, allowing us to also examine the effects ofvarying corpus size and content.3.4 Association measures used3.4.1 Frequency-based measuresIn the following, x is the cue word and y a (possi-ble) response word.
Therefore p(x) is the proba-bility of observing x, and p(x?)
refers to the prob-ability of not observing x.Pointwise Mutual Information (hereonin PMI)was introduced in Section 2.
For ranking wordpairs, we can neglect the usual logarithm.PMI =p(x, y)p(x)p(y)PMI is infamous for its tendency to attribute veryhigh association scores to pairs involving low fre-quency words, as the denominator is small in suchcases, even though the evidence for association insuch cases is also small.
This can result in someunlikely associations.
There exist a number of al-ternative measures which factor in the amount ofevidence to give an estimate of the significance ofassociation.
One popular and statistically appeal-ing such measure is Log-Likelihood (LL) (Dun-ning, 1993).
LL works on a similar principle toPMI but considers the ratio of the observed to ex-pected co-occurrence frequencies for all contin-gencies (i.e.
including those where the words donot co-occur).
LL, as it most frequently appears inthe literature, is not actually a measure of positiveassociation: it also responds to significant negativeassociation.
Therefore LL is arguably not suited tothe task in hand.
Krenn & Evert (2001) experimentwith one-tailed variants of LL and Chi-Squaredmeasures, although they do not define these vari-ants.
Here, we construct a one-tailed variant of LLby simply reversing the signs of the terms whichrespond to negative association.LL1tail= p(x, y) logp(x, y)p(x)p(y)?
p(x, y?)
logp(x, y?)p(x)p(y?)?
p(x?, y) logp(x?, y)p(x?
)p(y)+ p(x?, y?)
logp(x?, y?)p(x?)p(y?
)LL does not have a clear analogue amongstthe distance-based measures (introduced in Sec-tion 3.4.2), whereas PMI for instance does.
Wetherefore construct variants of PMI and other mea-sures which take the amount of evidence into ac-count in a way which can be directly reproducedin the distance domain.
For this we borrow fromSackett (2001) who asserts that, all other thingsbeing equal, statistical significance is proportionalto the square root of the sample size.
There are anumber of ways one might quantify sample size.We take a consistent approach across the variousdistance-based and frequency-based measures: weassume sample size to be equivalent to the lesser ofthe frequencies of the two words as this representsthe total number of words available for pairing,with fewer observed pairs therefore being consid-ered to constitute negative evidence.PMIsig=?min(p(x), p(y))p(x, y)p(x)p(y)All of the above measures are symmetric.
Humanassociative responses however are not (Michel-bacher et al, 2007): a person?s tendency to givethe response because to the cue why does not nec-essarily reflect their tendency to give the responsewhy to the cue because.2A simple asymmetric as-sociation measure is conditional probability (CP)2This notion of assymmetry is not to be confused with631- the probability of observing the response, giventhat the cue has already occurred.CP = p(y|x) =p(x, y)p(x)CP suffers from the fact that it does not accountat all for the general frequency of the responseword.
It therefore tends to favour very frequentwords, such as function words.
An obvious so-lution would be to divide CP by the frequency ofthe response word, however this merely results inPMI which is symmetric.
By multiplying CP withPMI (and taking the root, to simplify) we obtain ameasure which is asymmetric yet does not overtlyfavour frequent response words.3We refer to thisherein as Semi-Conditional Information (SCI).SCI =p(x, y)p(x)?p(y)We also explore variants of both CP and SCI withthe additional significance correction presented forPMIsig.
These can be easily inferred from the for-mulae above.3.4.2 Distance-based MeasuresCo-Dispersion (herein CD), introduced byWashtell (2009), is defined as the ratio of themean observed distance to the expected distance,where the expected distance is derived fromthe frequency of the more frequent word type.Distance refers to the number of tokens separat-ing an occurrence of one word and the nearestoccurrence of another word.
Pairs spanning anintervening occurrence of either word type or adocument boundary are not considered.
Note thathere we specify only the generalised mean M , aswe wish to keep the specific choice of mean as aparameter to be explored,CD =1/max(p(x), p(y))M(distxy1.
.
.
distxyn)that of direction in the text.
While the two may correlate, onecan find ample counter-examples: jerky triggers beef morestrongly than beef triggers jerky.3Note that Wettler & Rapp (1993) introduced a more gen-eral asymmetric measure for predicting human associations,by employing an exponent parameter to p(y).
Our formuli-sation is equivalent to their measure with an exponent of 0.5,whereas they found an exponent of 0.66 to be most effectivein their empirical study.
Exponents of 0 and 1 result in CPand PMI respectively.where distxyiis ithobserved distance betweensome occurrence of word type x and its nearestpreceding or following occurrence of word typey, and n is the total number of such distances ob-served (being at most equal to the frequency of therarer word).In cases where many occurrences of the lessfrequent word were not able to be paired, rawCD gives midleading results.
This is because un-pairable words themselves provide useful nega-tive evidence which CD ignores.
A more ap-propriate measure can be formed in which themean distance is calculated using the frequency ofthe less frequent word, regardless of whether thismany distances were actually observed.
This givesus Neutrally-Weighted Co-Dispersion (NWCD).Note that for convenience, we keep the standarddefinition of the mean and introduce a correctionfactor instead.NWCD =nmin(p(x), p(y))1/max(p(x), p(y))M(distxy1.
.
.
distxyn)An asymmetric association measure can beformed in a similar manner.
Instead of calculat-ing the mean using the frequency of the less fre-quent word as described above, we explicitly usethe frequency of the cue word (which in somecases may actually exceed the number of dis-tances observed).
This gives us Cue-Weighted Co-Dispersion (CWCD).CWCD =np(x)1/max(p(x), p(y))M(distxy1.
.
.
distxyn)(1)In addition to these measures, we also ex-plore significance-corrected forms NWCDsigandCWCDsig, by introducing the same sample sizeterm employed by PMIsig, CPsigand SCIsig.Again, these can readily be inferred from the ex-isting formulae in the above two sections.3.5 Co-occurrence ParametersFor frequency-based co-occurrence statistics, theprinciple parameter is the window size.
We willuse five window sizes separated by a constant scal-ing factor, chosen so as to span those most com-monly encountered in the literature, with some ex-tension towards the upper end.
We use w to rep-resent this parameter, with w = 2 implying a win-dow size of +/-2.
The parameter values explored632are w = 2, w = 10, w = 50, w = 250 andw = 1250.
We examine such large window sizesso as to give a fairer comparison with the distanceapproach which is not bounded by a window, andin acknowledgement of the fact that the entire doc-ument as context has been used with some successin other application areas (most notably informa-tion retrieval).For distance-based statistics, the principle pa-rameter is the function via which the various ob-served distances between tokens are reduced to asingle mean value.
In this investigation we will ex-plore five means.
These are the power means withexponents (which herein we refer to as m) rang-ing from -2 to +2.
These give us the quadraticmean or RMS (m = 2), the arithmetic mean(m = 1), the geometric mean (m = 0), the har-monic mean (m = ?1), and the inverse quadraticmean (m = ?2).4 Task I: Correlations on word pairsOne of the ESSLLI Workshop shared tasks (Ba-roni et al, 2008) required the evaluation of cor-relation between a small, manually selected sub-set of human cue-response scores from the EATdataset and automatic scores for the same wordpairs.
Here, tather than focusing on word pairswhich meet certain grammatical and frequencycriteria we test on all pairs.
For the EAT andFlorida datasets, this amounts to many tens ofthousands of cue-response pairs.
Although thismakes the task of correlation harder, it means wecan attribute a great deal of statistical significanceto the results and make our observations as generalas possible.4.1 Evaluation Measures, Upper Bounds andBaselinesFor evaluating agreement between corpus-derivedassociations and human associations, we useSpearman?s Rank correlation.
This is appropri-ate because we are primarily interested in the rel-ative ranking of word pair associations (in orderto predict particularly strong responses, for exam-ple).
Although some studies have used Pearson?scorrelation, the various association measures ex-plored here are not linear within each another andit would be inappropriate to evaluate them underthe assumption of a linear relationship with the hu-man norms.Two of the human datasets, Kent andMinnesota, though collected independently, arebased on the same set of 100 cue words establishedby Kent (1910).
Therefore by performing a rankcorrelation of these two datasets with one another,(each of which was produced by pooling the re-sponses of some 1000 people) we can get a usefulupper-bound for correlations: if a computer-basedsystem were to exceed this upper-bound in corre-lations with either dataset, then we would need tosuspect it of over-fitting.As a baseline, we use the corpus frequency ofthe response word.
The simple assumption is thatthe more frequent a word is, the more likely it isto appear as a human response independent of thecue given.
This is also the simplest formulationwhich does not assign equal scores to the variouspossible responses, and which is therefore capableof producing a rank-list of predictions.4.2 Task I ResultsFigure 1 shows the Spearman?s rank correlationco-efficients across all paramaterisations of all as-sociation measures (frequency-based on the left,and distance-based on the right), with each humandataset, for the 10 million word corpus.
Embold-ened are the best performing windowed and win-dowless configurations for each dataset.
The dif-ference of these figures over the baseline is highlysignificant (p < 0.0001 in most cases).
The panelsto the right show summary statistics for these fig-ures, and for the 1 million word corpus (for whichfull figures are not included owing to space limita-tions).
These statistics include the performance ofthe baseline, where relevant the estimated upper-bound (see Section 4.1), and the difference in per-formance of the distance-based method over thewindow-based.
The accuracy and error figures arebased on the co-efficients of determination (r2)and are expressed both as a relative improvementin accuracy (how much closer (r2) is to 1 under thedistance-based approach) and reduction in error(how much further r2is from zero).
Also the sig-nificance of the difference in the r values is given.4.3 DiscussionThe two-way Spearman?s rank correlations be-tween the Kent and Minesota datasets sug-gested an upper bound of r = 0.4.
In theory,a large proportion of this agreement is accountedfor by paradigmatic associations which we arenot likely to fully reproduce with these first-ordermeasures.
By this standard, the general levels of633Figure 1: Correlations for window-based and windowless measures on a 10 million word corpuscorrelation seen here (for these datasets r = 0.235and r = 0.239 respectively) seem very reasonable.What is immediately clear from Figure 1 is that,for the range of parameters tested here, we seea relatively small but statistically significant im-provement across four of the five datasets whenadopting the distance-based approach.The correlations are unsurprisingly lower acrossthe board for the much smaller 1 million word cor-pus.
Here, the best distance-based measure statis-tically significantly outperforms the best window-based one (with a significance level of p <0.0001) on one out of four datasets, while the dif-ferences are not great enough to be considered sta-tistically significant on the other three datasets.There is therefore some evidence that the bene-fits observed with the larger corpus hold in thepresence of limited data, which is in support ofthe general theory that distance-based methodscapture more information from the corpus at theco-occurrence level (Washtell, 2009).
It remainsclear, however, that no method is presently a sub-stitute for using a larger corpus.In terms of optimum configurations, we findthat for the frequency-based approach with thelarger corpus, a window size of around +/-10 to+/-50 words more or less consistently produces thebest results, irrespective of association the mea-sure.
Interestingly on the small corpus the ten-dency appears to be towards a somewhat largerwindow size than with the larger corpus.
Thismay be related to the larger windows?
increasedresilience to data-sparseness.
Somewhat surpris-ingly, we also see that our assymmetric associa-tion measures SCI and SCIsigperform the bestoverall amongst the windowed measures, largelyirrespective of the window or corpus, size.In the large corpus, the best distance-basedmeasure is the asymmetric CWCD, with the sig-nificance corrected measure CWCDsigshowinggreater strength in the small corpus: perhaps,again, for its improved reliability in the presenceof very low-frequency data.
The optimum meanfor the distance-based parameterisations is some-where around m = ?1 (the harmonic) to m = 0(the geometric).
We find this unsurprising as thetypical distribution of inter-word distances in acorpus is heavily skewed towards the smaller dis-tances - indeed even a random corpus exhibits thischaracteristic with the distances following a geo-metric distribution.5 Task II: Agreement with strongesthuman associationsThe correlation evalation presented considers allword pairs present in the human datasets.
How-ever, human association norms tend to containa very long tail of hapax legomena - responseswhich were given by only one individual.
Suchresponses are extremely difficult for corpus-based634association measures to predict, and given thatthere is so little consensus amongst human respon-dents over these items, it is probably not partic-ularly useful to do so.
Rather, it might be mostuseful to predict common or majority human re-sponses.5.1 Evaluation measure and Upper BoundFor the strongest human response to each cuein the human datasets, its rank was calculatedamongst all 33, 000 possible responses to thatcue, according to each association measure andparameterisation.
Where there were tied scoresfor various responses, a median rank was assigned.As a rough upper bound, we would be impressedby a computer system which was able to predictthe most popular human response as often as arandomly selected individual in the human exper-iments happened to chose the most popular re-sponse.5.2 Task II ResultsFigure 2 illustrates the range of computational as-sociation scores attributed to only the strongesthuman responses.
The position of the strongesthuman response to each cue word, within thecomputationally-ranked lists of all possible re-sponses, is plotted on the y-axis.
For each asso-ciation measure the points are ordered from bestto worst along the x-axis.
In the ideal case there-fore, the most popular human response for ev-ery cue word would appear at rank 1 amongst thecomputer-generated responses, resulting in a hori-zonal line at y=1.
Generally speaking therefore,the smaller the area above a line the better the per-formance of a measure.Three summary statistics can be derived fromFigure 2:1) The number of most popular human re-sponses that are correctly predicted by a measureis indicated by the x-position at which its line de-parts from y=1.
This can be seen to be around 11%for CWCDsigand is zero for the two best PMIparameterizations, with other illustrated measuresperforming intermediately.2) The width of the flat horizontal tails at the op-posite corner of the figure indicate the proportionof the cue words for which a measure was unableto differentiate the strongest human response fromthe large contingent of zero association scores re-sulting from unobservable co-occurrences.
Thistail is non-existent for CWCDsig, but afflicts some25% and 62% of cue words under the two bestPMI parameterizations, again with other illus-trated measures performing intermediately.3) The median rank of the most popular humanresponse for each measure can be read of on they-axis at the horizontal mid-point (indicated by afeint vertical line).Figure 2: Agreement of computational measureswith strongest human responsesFigure 3: Relative agreement of computationalmeasures with strongest human responsesThe results shown are for the Kent dataset, andare highly typical.
Included in the figure arethe three frequency-based configurations with thehighest median rank: SCIsigat window sizes w =10 and w = 50, and standard LL at w = 10.
Three635other frequency-based configurations are includedfor contrast.
Also included is the single window-less configuration with the highest median rank -in this case CWCDsigusing the harmonic mean.Several other windowless configurations (notablyCWCD and the nearby means) and had very simi-lar profiles.Figure 3 shows the magnitude of the differencein the ranking of each of the same 100 strong hu-man cue/response pairs, between the best window-less versus best windowed method.
Points abovethe axis represent those cue/response pairs whichthe windowless method ranked more highly, andvice-versa.
The points have been ordered on thex-axis according the the cue word frequency.5.3 DiscussionNoteworthy, studying Figure 2, is the great sen-sitivity of the frequency-based measures to thewindow size parameter.
There exists a cut-offpoint, linked to window size, beyond which thefrequency-based measures are unable to makeany differentiation between the desired human re-sponse and a large portion of the 33, 000 candidateresponses.
This is almost certainly due to a lackof evidence in the presence of very low frequencywords.
Log-Likelihood performs somewhat betterin this respect, as it takes negative information intoaccount.Although the distance-based approach followsthe same general trend as the other measures, itis nonetheless able to generate a distinct non-zeroassociation score for every strong human responseand overall it aptly ranks them more highly.
Alarger number these responses are actually rankedfirst (i.e.
successfully predicted) by the distance-based approach.
In fact this number is compara-ble to, and sometimes exceeds, the upper-boundof 10% implied by taking the average proportionof human respondents who give the most popularresponse to a given cue.Whilst Figure 2 showed that overall the win-dowless method fairs better, on a per-cue basis(Figure 3) things are a little more interesting: Fora little over a third of cue-words the windowedmethod actually appears to perform somewhat bet-ter.
For the majority however, the windowless ap-proach performs considerably better (note that they-axis scale is logarithmic).
It can also be seenthat the difference between the methods is mostpronounced for low frequency cue words, with re-sponses to some cues exhibiting a relative rankingof around one-hundred times lower for the win-dowed method.
This further supports the theorythat the windowless methods are better able to ex-ploit sparse data.6 Conclusions and Future workThis paper presented the first empirical compar-ison of window-based and the relatively recentlyintroduced windowless association measures, us-ing their ability to reproduce human associationscores as a testbed.
We show that the best win-dowless measures are always at least as good asthe best window-based measures, both when itcomes to overall correlation with human associ-ation scores and predicting the strongest humanresponse.
In addition, for several human associ-ation sets, they perform significantly better.
Al-though not all parameter settings and corpus sizescould be explored, we conclude that it is worth-while investigating windowless association mea-sures further.
As a side-benefit, we have also in-troduced new variants of existing frequency-basedassociation measures and shown them to performas well as or better than their existing counterparts.Although these measures were semi-principled intheir construction, a deeper understanding of whythey work so well is needed.
This may in turn leadto the construction of superior windowless mea-sures.In our own future work, we are especially in-terested in using higher-order windowless associa-tion measures for retrieving paradigmatic relationsas well as exploring their use in various NLP ap-plications.7 AcknowledgementsWe would like to extend sincere thanks to Rein-hard Rapp for providing us with the Minnesotadataset in digital form, and additional thanks toEric Atwell for his support.ReferencesM.
Baroni, S. Evert, and A. Lenci, editors.
2008.
EsslliWorkshop on Distributional Lexical Semantics.L.
Burnard, 1995.
Users?
Reference Guide, British Na-tional Corpus.
British National Corpus Consortium,Oxford, England.K.
Church and P. Hanks.
1989.
Word associationnorms, mutual information, and lexicography.
InProc.
of ACL-89, pages 76?83.636K.
Church and P. Hanks.
1991.
Word associationnorms, mutual information and lexicography.
Com-putational Linguistics, 16(1):22?29.P.
Clark and F.C.
Evans.
1954.
Distance to near-est neighbor as a measure of spatial relationships inpopulations.
Ecology, 35:445?453.J.
Curran.
2003.
From distributional to semantic simi-larity.
Ph.D. thesis, University of Edinburgh.Ted Dunning.
1993.
Accurate methods for the statis-tics of surprise and coincidence.
ComputationalLinguistics, 19:61?74.S.
Evert.
2005.
The Statistics of Word Cooccurrences:Word Pairs and Collocations.
Ph.D. thesis, Insti-tut fr maschinelle Sprachverarbeitung, University ofStuttgart.D.
Hardcastle.
2005.
Using the distributional hypothe-sis to derive coocurrence scores from the British Na-tional Corpus.
In Proc.
of Corpus Linguistics.J.
Jenkins.
1970.
The 1952 Minnesota word associa-tion norms.
In L. Postman and G. Keppel, editors,Norms of word associations, pages 1?38.
Academicpress.G.
Kent and A. Rosanoff.
1910.
A study of associationin insanity.
Amer.
J. of Insanity, pages 317?390.G.
Kiss, C. Armstrong, R. Milroy, and J. Piper.
1973.An associative thesaurus of English and its computeranalysis.
In A. Aitken, R. Bailey, and N. Hamilton-Smith, editors, The Computer and Literary Studies.Edinburgh University Press.B.
Krenn and S. Evert.
2001.
Cam we do better thanfrequency?
a case study on extracting pp-verb collo-cations.
In Proc.
of the ACL Workshop on Colloca-tions.A.
Lamjiri, O. El Demerdash, and L. Kosseim.
2004.Simple features for statistical word sense disam-biguation.
In Proc.
of SENSEVAL-2004.D.
Lin.
1998.
Automatic retrieval and clustering ofsimilar words.
In Proc.
of COLING-ACL-98.Lukas Michelbacher, Stefan Evert, and HinrichSch?utze.
2007.
Asymmetric association measures.In Proc.
of RANLP-2007.D.
Nelson, C. McEvoy, J. Walling, and J. Wheeler.1980.
The University of South Florida homographnorms.
Behaviour Research Methods and Instru-mentation, 12:16?37.S.
Pado and M. Lapata.
2007.
Dependency-based con-struction of semantic space models.
ComputationalLinguistics, 33(2):161?199.T.
Pedersen, S. Patwardhan, and J. Michelizzi.
2004.Wordnet::similarity - measuring the relatedness ofconcepts.
In Proc.
of the 21stNational Conferenceon Artificial Intelligence; 2004.R.
Rapp.
2002.
The computation of word associa-tions: comparing syntagmatic and paradigmatic ap-proaches.
In Proc of COLING 2002.D.L.
Sackett.
2001.
Why randomized controlled tri-als fail but needn?t: 2. failure to employ physiolog-ical statistics, or the only formula a clinician-trialistis every likely to need (or understand).
CanadianMedical Association Journal, 165(9):1226?1237.P.
Savicki and J. Hlavacova.
2002.
Measures of wordcommonness.
Journal of Quantitative Linguistcs,9(3):215?231.E.
Terra and C. Clarke.
2004.
Fast computation oflexical affinity models.
In Proc of COLING 2004.Renata Vieira and Massimo Poesio.
2000.
Anempirically-based system for processing definite de-scriptions.
Computational Linguistics, 26(4), De-cember.X.
Wang, 2005.
Robust Utilization of Context in WordSense Disambiguation, chapter Modeling and UsingContext, pages 529?541.
Springer Lecture Notes inComputer Science.J.
Washtell.
2009.
Co-dispersion: A windowless ap-proach to lexical association.
In Proc.
of EACL-2009.M.
Wettler and R. Rapp.
1993.
Computation of wordassociations based on the co-ocurrences of words inlarge corpora.
In Proc.
of the First Workshop on VeryLarge Corpora.K.
White and L. Abrams.
2004.
Free associations anddominance ratings of homophones for young andolder adults.
Behaviour Research Methods, Instru-ments and Computers, 36:408?420.D.
Yarowsky and R Florian.
2002.
Evaluating sensedisambiguation across diverse parameter spaces.Natural Language Engineering, 8(4):293?310.637
