Proceedings of the ACL-SIGLEX Workshop on Deep Lexical Acquisition, pages 10?17,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsVerb subcategorization kernels for automatic semantic labelingAlessandro Moschitti and Roberto BasiliDepartment of Computer ScienceUniversity of Rome ?Tor Vergata?Rome, Italy{moschitti,basili}@info.uniroma2.itAbstractRecently, many researches in natural lan-guage learning have considered the repre-sentation of complex linguistic phenom-ena by means of structural kernels.
Inparticular, tree kernels have been used torepresent verbal subcategorization frame(SCF) information for predicate argumentclassification.
As the SCF is a relevantclue to learn the relation between syn-tax and semantic, the classification algo-rithm accuracy was remarkable enhanced.In this article, we extend such work bystudying the impact of the SCF tree kernelon both PropBank and FrameNet seman-tic roles.
The experiments with SupportVector Machines (SVMs) confirm a stronglink between the SCF and the semantics ofthe verbal predicates as well as the bene-fit of using kernels in diverse and complextest conditions, e.g.
classification of un-seen verbs.1 IntroductionSome theories of verb meaning are based on syn-tactic properties, e.g.
the alternations of verb argu-ments (Levin, 1993).
In turn, Verb Subcategoriza-tion Frame (SCF) characterizes different syntacticalternations, thus, it plays a central role in the link-ing theory between verb semantics and their syntac-tic structures.Figure 1 shows the parse tree for the sentence"John rented a room in Boston" alongPredicateArg.
0Arg.
MSNNPD NVPV JohninrentedaroomPPIN NBostonArg.
1Figure 1: A predicate argument structure in a parse-tree rep-resentation.with the semantic shallow information embodied bythe verbal predicate to rent and its three arguments:Arg0, Arg1 and ArgM.
The SCF of such verb, i.e.NP-PP, provides a synthesis of the predicate argu-ment structure.Currently, the systems which aim to derive se-mantic shallow information from texts recognize theSCF of a target verb and represent it as a flat feature(e.g.
(Xue and Palmer, 2004; Pradhan et al, 2004))in the learning algorithm.
To achieve this goal, a lex-icon which describes the SCFs for each verb, is re-quired.
Such a resource is difficult to find especiallyfor specific domains, thus, several methods to auto-matically extract SCF have been proposed (Korho-nen, 2003).
In (Moschitti, 2004), an alternative tothe SCF extraction was proposed, i.e.
the SCF ker-nel (SK).
The subcategorization frame of verbs wasimplicitly represented by means of the syntactic sub-trees which include the predicate with its arguments.The similarity between such syntactic structures wasevaluated by means of convolution kernels.Convolution kernels are machine learning ap-proaches which aim to describe structured data in10terms of its substructures.
The similarity betweentwo structures is carried out by kernel functionswhich determine the number of common substruc-tures without evaluating the overall substructurespace.
Thus, if we associate two SCFs with twosubtrees, we can measure their similarity with suchfunctions applied to the two trees.
This approachdetermines a more syntactically motivated verb par-tition than the traditional method based on flat SCFrepresentations (e.g.
the NP-PP of Figure 1).
Thesubtrees associated with SCF group the verbs whichhave similar syntactic realizations, in turn, accord-ing to Levin?s theories, this would suggest that theyare semantically related.A preliminary study on the benefit of such ker-nels was measured on the classification accuracy ofsemantic arguments in (Moschitti, 2004).
In suchwork, the improvement on the PropBank arguments(Kingsbury and Palmer, 2002) classification sug-gests that SK adds information to the predictionof semantic structures.
On the contrary, the perfor-mance decrease on the FrameNet data classificationshows the limit of such approach, i.e.
when the syn-tactic structures are shared among several semanticroles SK seems to be useless.In this article, we use Support Vector Machines(SVMs) to deeply analyze the role of SK in the au-tomatic predicate argument classification.
The ma-jor novelty of the article relates to the extensive ex-perimentation carried out on the PropBank (Kings-bury and Palmer, 2002) and FrameNet (Fillmore,1982) corpora with diverse levels of task complex-ity, e.g.
test instances of unseen predicates (typi-cal of free-text processing).
The results show that:(1) once a structural representation of a linguisticobject, e.g.
SCF, is available we can use convolu-tion kernels to study its connections with anotherlinguistic phenomenon, e.g.
the semantic predicatearguments.
(2) The tree kernels automatically derivethe features (structures) which support also a sort ofback-off estimation in case of unseen verbs.
(3) Thestructural features are in general robust in all testingconditions.The remainder of this article is organized as fol-lows: Section 2 defines the Predicate Argument Ex-traction problem and the standard solution to solveit.
In Section 3 we present our kernels whereasin Section 4 we show comparative results amongSVMs using standard features and the proposed ker-nels.
Finally, Section 5 summarizes the conclusions.2 Parsing of Semantic Roles and SemanticArgumentsThere are two main resources that relate to predicateargument structures: PropBank (PB) and FrameNet(FN).
PB is a 300,000 word corpus annotated withpredicative information on top of the Penn Treebank2 Wall Street Journal texts.
For any given pred-icate, the expected arguments are labeled sequen-tially from Arg 0 to Arg 9, ArgA and ArgM.
TheFigure 1 shows an example of the PB predicate an-notation.
Predicates in PB are only embodied byverbs whereas most of the times Arg 0 is the subject,Arg 1 is the direct object and ArgM may indicate lo-cations, as in our example.FrameNet alo describes predicate/argumentstructures but for this purpose it uses richer se-mantic structures called frames.
These latter areschematic representations of situations involvingvarious participants, properties and roles, in whicha word may be typically used.
Frame elements orsemantic roles are arguments of target words thatcan be verbs or nouns or adjectives.
In FrameNet,the argument names are local to the target frames.For example, assuming that attach is the target wordand Attaching is the target frame, a typical sentenceannotation is the following.
[Agent They] attachTgt [Item themselves][Connector with their mouthparts] and thenrelease a digestive enzyme secretion whicheats into the skin.Several machine learning approaches for argu-ment identification and classification have been de-veloped, e.g.
(Gildea and Jurasfky, 2002; Gildea andPalmer, ; Gildea and Hockenmaier, 2003; Pradhan etal., 2004).
Their common characteristic is the adop-tion of feature spaces that model predicate-argumentstructures in a flat feature representation.
In the nextsection we present the common parse tree-based ap-proach to this problem.2.1 Predicate Argument ExtractionGiven a sentence in natural language, all the predi-cates associated with the verbs have to be identified11along with their arguments.
This problem can bedivided into two subtasks: (a) the detection of thetarget argument boundaries, i.e.
all its compound-ing words, and (b) the classification of the argumenttype, e.g.
Arg0 or ArgM in PropBank or Agent andGoal in FrameNet.The standard approach to learn both the detectionand the classification of predicate arguments is sum-marized by the following steps:1.
Given a sentence from the training-set, gener-ate a full syntactic parse-tree;2. let P and A be the set of predicates and theset of parse-tree nodes (i.e.
the potential argu-ments), respectively;3. for each pair <p, a> ?
P ?A:?
extract the feature representation set, Fp,a;?
if the subtree rooted in a covers exactlythe words of one argument of p, put Fp,ain T+ (positive examples), otherwise putit in T?
(negative examples).For instance, in Figure 1, for each combination ofthe predicate rent with the nodes N, S, VP, V, NP,PP, D or IN the instances Frent,a are generated.
Incase the node a exactly covers ?Paul?, ?a room?
or?in Boston?, it will be a positive instance otherwiseit will be a negative one, e.g.
Frent,IN .The T+ and T?
sets can be re-organized as posi-tive T+argi and negative T?argi examples for each argu-ment i.
In this way, an individual ONE-vs-ALL clas-sifier for each argument i can be trained.
We adoptedthis solution as it is simple and effective (Pradhan etal., 2004).
In the classification phase, given a sen-tence of the test-set, all its Fp,a are generated andclassified by each individual classifier Ci.
As a finaldecision, we select the argument associated with themaximum value among the scores provided by theindividual classifiers.2.2 Standard feature spaceThe discovery of relevant features is, as usual, acomplex task, nevertheless, there is a common con-sensus on the basic features that should be adopted.These standard features, firstly proposed in (Gildeaand Jurasfky, 2002), refer to a flat information de-rived from parse trees, i.e.
Phrase Type, PredicateWord, Head Word, Governing Category, Positionand Voice.
For example, the Phrase Type indicatesthe syntactic type of the phrase labeled as a predi-cate argument, e.g.
NP for Arg1 in Figure 1.
TheParse Tree Path contains the path in the parse treebetween the predicate and the argument phrase, ex-pressed as a sequence of non-terminal labels linkedby direction (up or down) symbols, e.g.
V ?
VP ?NP for Arg1 in Figure 1.
The Predicate Word is thesurface form of the verbal predicate, e.g.
rent for allarguments.In the next section we describe the SVM approachand the basic kernel theory for the predicate argu-ment classification.2.3 Learning with Support Vector MachinesGiven a vector space in <n and a set of positive andnegative points, SVMs classify vectors according toa separating hyperplane, H(~x) = ~w ?
~x + b = 0,where ~w ?
<n and b ?
< are learned by applyingthe Structural Risk Minimization principle (Vapnik,1995).To apply the SVM algorithm to Predicate Argu-ment Classification, we need a function ?
: F ?
<nto map our features space F = {f1, .., f|F|} and ourpredicate/argument pair representation, Fp,a = Fz ,into <n, such that:Fz ?
?
(Fz) = (?1(Fz), .., ?n(Fz))From the kernel theory we have that:H(~x) =( ?i=1..l?i~xi)?
~x+ b =?i=1..l?i~xi ?
~x+ b =?i=1..l?i?
(Fi) ?
?
(Fz) + b.where, Fi ?i ?
{1, .., l} are the training instancesand the product KT (Fi, Fz) =<?
(Fi) ?
?
(Fz)> isthe kernel function associated with the mapping ?.The simplest mapping that we can apply is?
(Fz) = ~z = (z1, ..., zn) where zi = 1 if fi ?
Fzand zi = 0 otherwise, i.e.
the characteristic vectorof the set Fz with respect to F .
If we choose thescalar product as a kernel function we obtain the lin-ear kernel KL(Fx, Fz) = ~x ?
~z.Another function that has shown high ac-curacy for the predicate argument classification(Pradhan et al, 2004) is the polynomial kernel:12SNP VPVP VPCCVB NPtook DT NNthe bookand VB NPread PRP$ NNits titlePRPJohnSNP VPVPVB NPtookSNP VPVPVB NPreadArg.
0 Arg.
0Arg.
1 Arg.
1Sentence Parse-Tree Ftook FreadFigure 2: Subcategorization frame structure for two predicateargument structures.SNP VPVPVB NPtook SNP VPVPVB NPtookVPVB NPSNP VPVPVB NP SNP VPVPVBtookVPVPVB NPtookVPVPVB NPVPVPFigure 3: All 10 valid fragments of the SCFS associated withthe arguments of Ftook of Figure 2.KPoly(Fx, Fz) = (c+ ~x ?
~z)d, where c is a constantand d is the degree of the polynom.The interesting property is that we do not need toevaluate the ?
function to compute the above vector;only the K(~x, ~z) values are required.
This allowsus to define efficient classifiers in a huge (possibleinfinite) feature set, provided that the kernel is pro-cessed in an efficient way.
In the next section, weintroduce the convolution kernel that we used to rep-resent subcategorization structures.3 Subcategorization Frame Kernel (SK)The convolution kernel that we have experimentedwas devised in (Moschitti, 2004) and is character-ized by two aspects: the semantic space of the sub-categorization structures and the kernel function thatmeasure their similarities.3.1 Subcategorization Frame Structure (SCFS)We consider the predicate argument structures an-notated in PropBank or FrameNet as our semanticspace.
As we assume that semantic structures arecorrelated to syntactic structures, we used a ker-nel that selects semantic information according tothe syntactic structure of a predicate.
The subparsetree which describes the subcategorization frame ofthe target verbal predicate defines the target Sub-categorization Frame Structure (SCFS).
For exam-ple, Figure 2 shows the parse tree of the sentence"John took the book and read its title" to-gether with two SCFS structures, Ftook and Freadassociated with the two predicates took and read, re-spectively.
Note that SCFS includes also the externalargument (i.e.
the subject) although some linguistictheories do not consider it being part of the SCFs.Once the semantic representation is defined, weneed to design a tree kernel function to estimate thesimilarity between our objects.3.2 The tree kernel functionThe main idea of tree kernels is to model aK(T1, T2) function which computes the number ofthe common substructures between two trees T1 andT2.
For example, Figure 3 shows all the fragmentsof the argument structure Ftook (see Figure 2) whichwill be matched against the fragment of anotherSCFS.Given the set of fragments {f1, f2, ..} = F ex-tracted from all SCFSs of the training set, we definethe indicator function Ii(n) which is equal 1 if thetarget fi is rooted at node n and 0 otherwise.
It fol-lows that:K(T1, T2) =?n1?NT1?n2?NT2?
(n1, n2) (1)where NT1 and NT2 are the sets of the T1?sand T2?s nodes, respectively and ?
(n1, n2) =?|F|i=1 Ii(n1)Ii(n2).
This latter is equal to the num-ber of common fragments rooted in the n1 and n2nodes.
We can compute ?
as follows:1. if the productions at n1 and n2 are differentthen ?
(n1, n2) = 0;2. if the productions at n1 and n2 are the same,and n1 and n2 have only leaf children (i.e.
theyare pre-terminals symbols) then ?
(n1, n2) =1;3. if the productions at n1 and n2 are the same,and n1 and n2 are not pre-terminals then?
(n1, n2) =nc(n1)?j=1(1 + ?
(cjn1 , cjn2)) (2)where ?
?
{0, 1}, nc(n1) is the number of the chil-dren of n1 and cjn is the j-th child of the node n.13Note that, as the productions are the same nc(n1) =nc(n2).The above kernel has the drawback of assigninghigher weights to larger structures1.
To overcomethis problem we can scale the relative importance ofthe tree fragments using a parameter ?
in the con-ditions 2 and 3 as follows: ?
(nx, nz) = ?
and?
(nx, nz) = ?
?nc(nx)j=1 (?
+?
(cjn1 , cjn2)).The set of fragments that belongs to SCFs arederived by human annotators according to seman-tic considerations, thus they generate a semanticsubcategorization frame kernel (SK).
We alsonote that SK estimates the similarity betweentwo SCFSs by counting the number of fragmentsthat are in common.
For example, in Figure 2,KT (?
(Ftook), ?
(Fread)) is quite high (i.e.
6 out 10substructures) as the two verbs have the same syn-tactic realization.In other words the fragments encode semantic in-formation which is measured by SK.
This providesthe argument classifiers with important clues aboutthe possible set of arguments suited for a target ver-bal predicate.
To support this hypothesis the nextsection presents the experiments on the predicate ar-gument type of FrameNet and ProbBank.4 The ExperimentsA clustering algorithm which uses SK would grouptogether verbs that show a similar syntactic struc-ture.
To study the properties of such clusters we ex-perimented SK in combination with the traditionalkernel used for the predicate argument classification.As the polynomial kernel with degree 3 was shownto be the most accurate for the argument classifica-tion (Pradhan et al, 2004; Moschitti, 2004) we useit to build two kernel combinations:?
Poly + SK: KPoly|KPoly| + ?KT|KT | , i.e.
the sum be-tween the normalized polynomial kernel (seeSection 2.3) and the normalized SK2.?
Poly ?
SK: KPoly?KT|KPoly |?|KT | , i.e.
the normal-ized product between the polynomial kernel1With a similar aim and to have a similarity score between 0and 1, we also apply the normalization in the kernel space, i.e.K?
(T1, T2) = K(T1,T2)?K(T1,T1)?K(T2,T2) .2To normalize a kernel K(~x, ~z) we can divide it by?K(~x, ~x)?K(~z, ~z).and SK.For the experiments we adopted two corporaPropBank (PB) and FrameNet (FN).
PB, avail-able at www.cis.upenn.edu/?ace, is used alongwith the Penn TreeBank 2 (www.cis.upenn.edu/?treebank) (Marcus et al, 1993).
This corpuscontains about 53,700 sentences and a fixed split be-tween training and testing which has been used inother researches, e.g.
(Pradhan et al, 2004; Gildeaand Palmer, ).
In this split, Sections from 02 to 21are used for training, section 23 for testing and sec-tions 1 and 22 as development set.
We considered all12 arguments from Arg0 to Arg9, ArgA and ArgM fora total of 123,918 and 7,426 arguments in the train-ing and test sets, respectively.
It is worth noting thatin the experiments we used the gold standard parsingfrom the Penn TreeBank, thus our kernel structuresare derived with high precision.The second corpus was obtained by extract-ing from FrameNet (www.icsi.berkeley.edu/?framenet/) all 24,558 sentences from 40 framesof the Senseval 3 (http://www.senseval.org) Au-tomatic Labeling of Semantic Role task.
We con-sidered 18 of the most frequent roles for a total of37,948 arguments3.
Only verbs are selected to bepredicates in our evaluations.
Moreover, as there isno fixed split between training and testing, we ran-domly selected 30% of the sentences for testing and30% for validation-set, respectively.
Both trainingand testing sentences were processed using Collins?parser (Collins, 1997) to generate parse-tree auto-matically.
This means that our shallow semanticparser for FrameNet is fully automated.4.1 The Classification set-upThe evaluations were carried out with the SVM-light-TK software (Moschitti, 2004) available athttp://ai-nlp.info.uniroma2.it/moschitti/which encodes the tree kernels in the SVM-lightsoftware (Joachims, 1999).The classification performance was measured us-ing the F1 measure4 for the individual argumentsand the accuracy for the final multi-class classifier.This latter choice allows us to compare the results3We mapped together roles having the same name4F1 assigns equal importance to Precision P and Recall R,i.e.
F1 = 2P?RP+R .14with previous literature works, e.g.
(Gildea andJurasfky, 2002; Pradhan et al, 2004; Gildea andPalmer, ).For the evaluation of SVMs, we used the defaultregularization parameter (e.g., C = 1 for normal-ized kernels) and we tried a few cost-factor values(i.e., j ?
{1, 2, 3, 5, 7, 10, 100}) to adjust the ratebetween Precision and Recall.
We chose the pa-rameters by evaluating the SVMs using the KPolykernel (degree = 3) over the validation-set.
Both ?
(see Section 3.2) and ?
parameters were evaluatedin a similar way by maximizing the performance ofSVM using Poly+SK.
We found that the best valueswere 0.4 and 0.3, respectively.4.2 Comparative resultsTo study the impact of the subcategorization framekernel we experimented the three models Poly,Poly + SK and Poly ?
SK on different trainingconditions.First, we run the above models using all the verbalpredicates available in the training and test sets.
Ta-bles 1 and 2 report the F1 measure and the globalaccuracy for PB and FN, respectively.
Column 2shows the accuracy of Poly (90.5%) which is sub-stantially equal to the accuracy obtained in (Prad-han et al, 2004) on the same training and test setswith the same SVM model.
Columns 3 and 4show that the kernel combinations Poly + SK andPoly ?
SK remarkably improve Poly accuracy,i.e.
2.7% (93.2% vs. 90.5%) whereas on FN onlyPoly+SK produces a small accuracy increase, i.e.0.7% (86.2% vs. 85.5%).This outcome is lower since the FN classificationrequires dealing with a higher variability of its se-mantic roles.
For example, in ProbBank most of thetime, the PB Arg0 and Arg1 corresponds to the log-ical subject and logical direct object, respectively.On the contrary, the FN Cause and Agent roles areoften both associated with the logical subject andshare similar syntactic realizations, making SCFSless effective to distinguish between them.
More-over, the training data available for FrameNet issmaller than that used for PropBank, thus, the treekernel may not have enough examples to generalize,correctly.Second, we carried out other experiments usinga subset of the total verbs for training and anotherArgs All Verbs Disjoint VerbsPoly +SK ?SK Poly +SK ?SKArg0 90.8 94.6 94.7 86.8 90.9 91.1Arg1 91.1 92.9 94.1 81.7 86.8 88.3Arg2 80.0 77.4 82.0 49.9 49.5 47.6Arg3 57.9 56.2 56.4 20.3 22.9 20.6Arg4 70.5 69.6 71.1 0 0 0ArgM 95.4 96.1 96.3 90.3 93.4 93.7Acc.
90.5 92.4 93.2 82.1 86.3 86.9Table 1: Kernel accuracies on PropBank.Role All Verbs Disjoint VerbsPoly +SK ?SK Poly +SK ?SKagent 91.7 94.4 94.0 82.5 84.8 84.7cause 57.4 60.6 56.4 29.1 28.1 26.9degree 77.1 77.2 60.9 40.6 44.6 22.6depict.
85.8 86.2 85.9 73.6 74.0 71.2instrum.
67.1 69.1 64.6 13.3 13.0 12.8manner 80.5 79.7 77.7 74.8 74.3 72.3Acc.
85.5 86.2 85.0 72.8 74.6 74.2Table 2: Kernel accuracies on 18 FrameNet semantic roles.disjoint subset for testing.
In these conditions, theimpact of SK is amplified: on PB, SK ?Poly out-performs Poly by 4.8% (86.9% vs. 82.1%), whereas,on FN, SK increases Poly of about 2%, i.e.
74.6%vs.
72.8%.
These results suggest that (a) when test-set verbs are not observed during training, the clas-sification task is harder, e.g.
82.1% vs. 90.5% onPB and (b) the syntactic structures of the verbs, i.e.the SCFSs, allow the SVMs to better generalize onunseen verbs.To verify that the kernel representation is supe-rior to the traditional representation we carried outan experiment using a flat feature representation ofthe SCFs, i.e.
we used the syntactic frame featuredescribed (Xue and Palmer, 2004) in place of SK.The result as well as other literature findings, e.g.
(Pradhan et al, 2004) show an improvement on PBof about 0.7% only.
Evidently flat features cannotderive the same information of a convolution kernel.Finally, to study how the verb complexity impactson the usefulness of SK, we carried out additionalexperiments with different verb sets.
One dimensionof complexity is the frequency of the verbs in thetarget corpus.
Infrequent verbs are associated withpredicate argument structures poorly represented inthe training set thus they are more difficult to clas-sify.
Another dimension of the verb complexity isthe number of different SCFs that they show in dif-ferent contexts.
Intuitively, the higher is the number15(a) PropBank Multi-classifier0.830.850.870.890.910.930.950.971-5 6-10 11-15 16-30 31-60 61-100 101-300301-400401-600601-700701-1000>1000Verb FrequencyAccuracyPolyPoly+SK(b) Arg0 Classifier0.850.870.890.910.930.950.971-5 6-10 11-15 16-30 31-60 61-100 101-300 301-400 401-600 601-700 701-1000>1000Verb FrequencyF1PolyPoly+SK(c) PropBank Multi-classifier0.800.820.840.860.880.900.920.941 2-3 4-5 6-10 11-15 16-20 21-25 26-30 31-35 36-40 41-45 46-50 >50# SCF TypeAccuracyPolyPoly+SK(d) Arg0 Classifier0.800.820.840.860.880.900.920.941 2-3 4-5 6-10 11-15 16-20 21-25 26-30 31-35 36-40 41-45 46-50 >50# SCF TypeF1PolyPoly+SK(e) FrameNet Multi-classifier0.600.650.700.750.800.850.901 2-3 4-5 6-10 11-15 16-20 21-25 26-30 31-35 36-40 41-45 46-50 >50# SCF TypeAccuracyPolyPoly+SK(f) Agent Classifier0.650.700.750.800.850.900.951.001 2-3 4-5 6-10 11-15 16-20 21-25 26-30 31-35 36-40 41-45 46-50 >50# SCF TypeF1PolyPoly+SKFigure 4: The impact of SCF on the classification accuracy of the semantic arguments and semantic roles according to the verbcomplexity.of verb?s SCF types the more difficult is the classifi-cation of its arguments.Figure 4.a, reports the accuracy along with thetrend line plot of Poly and SK + Poly accordingto subsets of different verb frequency.
For example,the label 1-5 refers to the class of verbal predicateswhose frequency ranges from 1 to 5.
The associatedaccuracy is evaluated on the portions of the trainingand test-sets which contain only the verbs in suchclass.
We note that SK improves Poly for any verbfrequency.
Such improvement decreases when thefrequency becomes very high, i.e.
when there aremany training instances that can suggest the correctclassification.
A similar behavior is shown in Figure4.b where the F1 measure for Arg0 of PB is reported.Figures 4.c and 4.d illustrate the accuracy and theF1 measure for all arguments and Arg0 of PB ac-cording to the number of SCF types, respectively.We observe that the Semantic Kernel does not pro-duce any improvement on the verbs which are syn-tactically expressed by only one type of SCF.
As thenumber of SCF types increases (> 1) Poly + SKoutperforms Poly for any verb class, i.e.
when theverb is enough complex SK always produces use-ful information independently of the number of thetraining set instances.
On the one hand, a high num-ber of verb instances reduces the complexity of theclassification task.
On the other hand, as the num-ber of verb type increases the complexity of the taskincreases as well.A similar behavior can be noted on the FN data(Figure 4.e) even if the not so strict correlation be-tween syntax and semantics prevents SK to producehigh improvements.
Figure 4.f shows the impact ofSK on the Agent role.
We note that, the F1 increasesmore than the global accuracy (Figure 4.e) as theAgent most of the time corresponds to Arg0.
This isconfirmed by the Table 2 which shows an improve-ment for the Agent of up to 2% when SK is usedalong with the polynomial kernel.5 Conclusive RemarksIn this article, we used Support Vector Machines(SVMs) to deeply analyze the role of the subcat-egorization frame kernel (SK) in the automaticpredicate argument classification of PropBank and16FrameNet corpora.
To study the SK?s verb clas-sification properties we have combined it with thepolynomial kernel on standard flat features.We run the SVMs on diverse levels of task com-plexity.
The results show that: (1) in general SKremarkably improves the classification accuracy.
(2)When there are no training instances of the test-set verbs the improvement of SK is almost double.This suggests that tree kernels automatically derivefeatures which support also a sort of back-off esti-mation in case of unseen verbs.
(3) In all complexityconditions the structural features are in general veryrobust, maintaining a high improvement over the ba-sic accuracy.
(4) The semantic role classification inFrameNet is affected with more noisy data as it isbased on the output of a statistical parser.
As a con-sequence the improvement is lower.
Anyway, thesystematic superiority of SK suggests that it is lesssensible to parsing errors than other models.
Thisopens promising direction for a more weakly super-vised application of the statistical semantic taggingsupported by SK.In summary, the extensive experimentation hasshown that the SK provides information robust withrespect to the complexity of the task, i.e.
verbs withricher syntactic structures and sparse training data.An important observation on the use of tree ker-nels has been pointed out in (Cumby and Roth,2003).
Both computational efficiency and classifi-cation accuracy can often be superior if we selectthe most informative tree fragments and carry outthe learning in the feature space.
Nevertheless, thecase studied in this paper is well suited for using ker-nels as: (1) it is difficult to guess which fragmentfrom an SCF should be retained and which shouldbe discarded, (2) it may be the case that all frag-ments are useful as SCFs are small structures and alltheirs substructures may serve as different back-offlevels and (3) small structures do not heavily penal-ize efficiency.Future research may be addressed to (a) the useof SK kernel to explicitly generate verb clusters and(b) the use of convolution kernels to study other lin-guistic phenomena: we can use tree kernels to in-vestigate which syntactic features are suited for anunknown phenomenon.AcknowledgementWe would like to thank the anonymous reviewers fortheir competence and commitment showed in the re-view of this paper.ReferencesMichael Collins.
1997.
Three generative, lexicalizedmodels for statistical parsing.
In Proceedings of theACL?97,Somerset, New Jersey.Chad Cumby and Dan Roth.
2003.
Kernel methods forrelational learning.
In Proceedings of ICML?03, Wash-ington, DC, USA.Charles J. Fillmore.
1982.
Frame semantics.
In Linguis-tics in the Morning Calm, pages 111?137.Daniel Gildea and Julia Hockenmaier.
2003.
Identifyingsemantic roles using combinatory categorial grammar.In Proceedings of EMNLP?03, Sapporo, Japan.Daniel Gildea and Daniel Jurasfky.
2002.
Automatic la-beling of semantic roles.
Computational Linguistic,28(3):496?530.Daniel Gildea and Martha Palmer.
The necessity of pars-ing for predicate argument recognition.
In Proceed-ings of ACL?02.T.
Joachims.
1999.
Making large-scale SVM learningpractical.
In B. Scho?lkopf, C. Burges, and A. Smola,editors, Advances in Kernel Methods - Support VectorLearning.Paul Kingsbury and Martha Palmer.
2002.
From Tree-bank to PropBank.
In Proceedings of LREC?02.Anna Korhonen.
2003.
Subcategorization Acquisi-tion.
Ph.D. thesis, Techical Report UCAM-CL-TR-530.
Computer Laboratory, University of Cambridge.Beth Levin.
1993.
English Verb Classes and Alterna-tions A Preliminary Investigation.
Chicago: Univer-sity of Chicago Press.M.
P. Marcus, B. Santorini, and M. A. Marcinkiewicz.1993.
Building a large annotated corpus of en-glish: The Penn Treebank.
Computational Linguistics,19:313?330.Alessandro Moschitti.
2004.
A study on convolutionkernels for shallow semantic parsing.
In proceedingsACL?04, Barcelona, Spain.Sameer Pradhan, Kadri Hacioglu, Valeri Krugler, WayneWard, James H. Martin, and Daniel Jurafsky.
2005.Support vector learning for semantic argument classi-fication.
to appear in the Machine Learning Journal.V.
Vapnik.
1995.
The Nature of Statistical Learning The-ory.
Springer.Nianwen Xue and Martha Palmer.
2004.
Calibratingfeatures for semantic role labeling.
In Dekang Linand Dekai Wu, editors, Proceedings of EMNLP?04,Barcelona, Spain, July.17
