What Prompts Translators to Modify Draft Translations?An Analysis of Basic Modification Patterns for Use inthe Automatic Notification of Awkwardly Translated TextTakeshi Abekawa and Kyo KageuraLibrary and Information Science CourseGraduate School of Education,University of Tokyo{abekawa,kyo}@p.u-tokyo.ac.jpAbstractIn human translation, translators first makedraft translations and then modify them.This paper analyses these modifications, inorder to identify the features that triggermodification.
Our goal is to construct a sys-tem that notifies (English-to-Japanese) vol-unteer translators of awkward translations.After manually classifying the basic modifi-cation patterns, we analysed the factors thattrigger a change in verb voice from passiveto active using SVM.
An experimental re-sult shows good prospects for the automaticidentification of candidates for modification.1 IntroductionWe are currently developing an English-to-Japanesetranslation aid system aimed at volunteer transla-tors mainly working online (Abekawa and Kageura,2007), As part of this project, we are developing amodule that notifies (inexperienced) translators ofawkwardly translated expressions that may need re-finement or editing.In most cases, translators first make draft trans-lations, and then examine and edit them later, oftenrepeatedly.
Thus there are normally at least two ver-sions of a given translation, i.e.
a draft and the finaltranslation.
In commercial translation environments,it is sometimes the case that texts are first translatedby inexperienced translators and then edited by ex-perienced translators.
However, this does not ap-ply to voluntary translation.
In addition, volunteertranslators tend to be less experienced than commer-cial translators, and devote less time to editing.
Itwould therefore be of great help to these translatorsif the CAT system automatically pointed out awk-ward translations for possible modification.
In orderto realise such a system, it is necessary to first clarify(i) the basic types of modification made by transla-tors to draft translations, and (ii) what triggers thesemodifications.In section 2 we introduce the data used in thisstudy.
In section 3, we clarify the nature of modifica-tion in the translation process.
In section 4, we iden-tify the actual modification patterns in the data.
Insection 5, focusing on ?the change from the passiveto the active voice?
pattern, we analyse and clarifythe triggers that may lead to modification.
Section 6is devoted to an experiment in which machine learn-ing methods are used to detect modification candi-dates.
The importance of the various triggers is ex-amined, and the performance of the system is evalu-ated.2 The dataThe data used in the present study is the Japanesetranslation of an English book about the problem ofpeak oil (Leggett, 2005).
The book is aimed at apopular audience and is relevant to the sort of textswe have in mind, because the majority of texts vol-unteer translators translate deal with current affairs,social issues, politics, culture and sports, and/or eco-nomic issues for a popular audience1.
The data con-sists of the English original (henceforth ?English?
),the draft Japanese translation (?Draft?)
and the fi-nal Japanese translation (?Final?).
The ?Draft?
wasmade by two translators (one with two years?
experi-ence and the other with five years?
experience), and1Software localisation is another area of translation in whichvolunteers are heavily involved.
We do not include it in ourtarget because it has different characteristics.241??????
??
????
?
?
??
?
??
?
???
??
?
???
?
?
?
???
?
????
?
??
?
???
??
?
??
??
?
??????????
?
??
?
?
??
??
?
??
?
??
?
??
?
?
?
???
?
??
??
????
?
???
??
??
??
??
?
?Figure 1: An example of word alignment using GIZA++the ?Final?
was made by a translator with 12 years?experience.
Table 1 gives the quantities of the data.?English?
?Draft?
?Final?Number of sentences 4,587 4,629 4,648Number of words 92,300 127,838 132,989(Average per sentence) 20.1 27.6 28.6Table 1: Basic quantities of the data3 Nature of the modification processState Cause1.
Mistranslation English is complex2.
Text is confusing English is complex / Trans-lation is too literal3.
Text is unnatural Translation is too literal /Japanese is underexamined4.
Against modi-fiers?
tasteDifferent Japanese ?model?is assumed5.
Against editorialpolicyLack of surface editingTable 2: States in the draft and their causesAs little research has been carried out into the pro-cess by which translators modify draft translations,we manually analysed a part of the data in whichmodifications were made, in consultation with atranslator.
In the modification process, the translatorfirst recognises (though often not consciously) oneof a number of states in a draft translation and theunderlying cause of the state.
S/he then modifies thedraft translation if necessary.
Table 2 shows the ba-sic classification of states and possible causes.
Al-though the states are conceptually clear, it is not nec-essarily the case that translators can judge the stateof a given translation consistently, because judginga sentence as being ?natural?
or ?confusing?
is nota binary process but a graded one, and the distinc-tion between different states is often not immedi-ately clear.
Many concrete modification patternsfound in the data are covered in translation textbooks(Anzai, 1995; Nakamura, 2003).
However, althoughit is obvious in some cases that a section of trans-lated text needs to be modified, in other cases it isless clear, and judgments will vary according to thetranslator.
The task that automatic notification ad-dresses, therefore, is essentially an ambiguous one,even though the actual system output may be binary.We also identified the distinction between twotypes of modification: (i) ?generative?
modification,in which the modified translation is generated on thespot, with reference to the English original; and (ii)?considered?
modification, in which alternate ex-pressions (phrases, collocations, etc.)
are retrievedfrom the depository of useful, elegant, or conven-tional expressions in the translator?s mind.
Thesetwo types of modification can be activated in the faceof one token of modification at once.4 Modification patternsThe most natural way to classify modification pat-terns is by means of basic linguistic labels such as?change of voice?
or ?change from nominal modifi-cation to adverbial modification?
(cf.
Anzai, 1995).These modification patterns consist of one or moreprimitive operations.
For instance, a ?change ofvoice?
may consist of such primitive operations as?changing the case-marker of the subject,?
?swap-ping the position of subject and object,?
etc.As preparation, we extracted modification pat-terns from the data2.
In order to do so, we firstaligned the ?Draft?
and the ?Final?
at the sentencelevel using DP matching, and then at the morphemelevel using GIZA++ (Och and Ney, 2003).
Figure1 illustrates an example of word/morpheme level2This task is similar to the acquisition of paraphrase knowl-edge (Barzilay and McKeown, 2001; Shinyama et al, 2002;Quirk et al 2004; Barzilay and Lee, 2003; Dolan et al, 2004).However, our aim here is to clarify basic modification patternsand not automatic identification.242English: If it was perceived to be true by the majority of Thinkers, ...?Draft?
: ???
??????
???
??????
??????
?JINRUI-NO TASUU-NIYOTTE SORE-GA SINJITU-DE-ARU-TO NINSIKI-SA-RERE-BA(thinkersgenitive) (majorityablative) (itsubject) (to be true) (be perceived)?Final?
: ???
???
???
???
?????
?JINRUI-NO TASUU-GA SORE-WO SINJITU-TO NINSIKI-SURE-BA(thinkersgenitive) (majoritysubject) (itobject) (to be true) (perceive)Primitive replace(?NIYOTTE?, replace(?GA?, delete(?DE?)
delete(?RARERU?
)operations: ?GA?)
?WO?)
delete(?ARU?
)Table 3: An example of a primitive modification operationalignment.
Changes in word order occur frequently,as is shown in Figure 1, and the ?Final?
and the?Draft?
are not completely parallel at the word ormorpheme level.
As a result, GIZA++ sometimesmisaligns the units.From the aligned ?Draft?
and ?Final?
data, weidentified the primitive operations.
We limited theseoperations to syntactic operations and semantic op-erations such as the changing of content words, be-cause the latter is hard to generalise with a smallamount of data.
Primitive operations were extractedby calculating the difference between correspond-ing bunsetsu, which basically consist of a contentword and postpositions/suffixes, in the ?Draft?
andin the ?Final?.
An example is given in Table 3.
Ta-ble 4 shows the five most frequent changes in verbinflections and case markers, which are two domi-nant classes of primitive operation.
In addition, weobserved deletions and insertions of Sahen verbs.Modification patterns were identified by observ-ing the degree of co-occurrence among these prim-itive operations.
We used Cabocha3 to identify thesyntactic dependencies and used the log-likelihoodratio (LLR) to calculate the degree of co-occurrenceof primitive operations that occupy syntactically de-pendent positions.
Table 5 shows the top five pair-wise co-occurrence patterns.inflection del.
ins.
case marker del.
ins.DA 379 291 NI 476 384TE 269 358 GA 387 502TA 247 306 NO 366 204RARERU 224 122 WO 293 421IRU 197 267 DE 203 193Table 4: Frequent primitive operations3http://chasen.org/?taku/software/cabocha/Three main modification patterns were identified:(i) a change from the passive to the active voice (226cases); (ii) a change from a Sahen verb to a Sa-hen noun (208 cases); and (iii) a change from nom-inal modification to clausal structure.
These pat-terns have been discussed in studies of paraphrases(Inui and Fujita, 2004) and in translation textbooks(Anzai, 1995; Nakamura, 2003).
We focus on ?thechange from the passive to the active voice?.
It isone of the most important and interesting modifica-tion patterns because (i) it is mostly concerned withthe main clausal structure in which other modifica-tions are embedded; and (ii) the use of active andpassive voices differs greatly between English andJapanese and thus there will be much to reveal.5 Triggers that lead to modificationGiven a draft translation, an experienced translatorwill be able to recognise any problematic states in it(see Table 2), identify the causes of these states anddeal with them.
As computers (and inexperiencedtranslators) cannot do the same (cf.
Sun et al, 2007),it is necessary to break these causes down into com-putationally tractable triggers.
Keeping in mind thenature of the modification process discussed in sec-tion 3, we analysed the actual data, this time withthe help of a translator and a linguist.At the topmost level, two types of triggers wereidentified: (i) ?pushing?
triggers that are identifiedas negative characteristics of the draft translation ex-pressions themselves; and (ii) ?pulling?
triggers thatcome from outside (from the depository of expres-sions in the translator?s mind) and work as concrete?model translations?.
The distinction is not entirelyclear, because a model is needed in order to iden-tify negative characteristics, and some sort of neg-ative impression is needed for the ?model transla-tion?
to be called up.
The distinction is nevertheless243LLR f(a,b) f(a) f(b) operation a operation b plain expression146.2 28 35 224 replace(NIYOTTE,GA) delete(RARERU) A NIYOTTE B SARERU?A GA B SURU105.2 34 90 224 replace(GA,WO) delete(RARERU) A GA B SARERU?A WO B SURU91.7 34 115 208 replace(NO,GA) delete(SAHEN) A NO B?A GA B SURU90.9 26 61 208 replace(NO,WO) delete(SAHEN) A NO B?A WO B SURU36.3 15 68 168 replace(NI,WO) intransitive?transitive A NI B SURU?A WO C SURUTable 5: Five of the most frequent co-occurrence patterns between two primitive operationsimportant, both theoretically and practically.
Theo-retically, it corresponds to the types of modificationobserved in section 3.
From the practical point ofview, the first type is related to the general structuralmodelling (in its broad sense) of language, while thesecond is closely related to the status of individuallexicalised expressions.
Correspondingly, an NLPsystem that addresses the first type needs to assumea language model, while a system that addresses thesecond type needs to call on the relevant externaldata on the spot.
We address the first type of trig-ger, because we can hypothesise that the modifica-tion by change of voice is mainly related to the struc-tural nature of expressions.
It should also be notedthat, from the machine learning point of view, thereare positive and negative features which respectivelypromote and restrict the modification.We classified the features that may represent po-tential triggers into five groups:(A) Features related to the readability of the En-glish, because the complexity of English sentences(cf.
Fry, 1968; Gunning, 1959) can affect the qual-ity of draft translations.
Thus the number of wordsin a sentence, length of words, number of verbs ina sentence, number of commas, etc.
can be used astractable features for automatic treatment.
(B) Features reflecting the correspondence be-tween the English and the draft Japanese trans-lation.
Translations that are very literal, either lex-ically or structurally, are often also awkward.
Onthe other hand, a high degree of word order corre-spondence can be a positive sign (cf.
Anzai, 1995),because it indicates that the information flow in En-glish is maintained and the Japanese translation iswell examined.
(C) Features related to the Japanese target verbs.The characteristics of the target verbs should affectthe environments in which they occur.
(D) Features related to the ?naturalness?
of theJapanese.
Repetitions or redundancies of elementsor sound patterns may lead to unnatural Japanesesentences.
(E) Features related to the complexity of theJapanese.
If a draft translation is too complex, itmay be confusing or hard to read.
Structural com-plexity, the length of a sentence, the number of com-mas, etc.
can be used as triggers that reflect the com-plexity of the Japanese translation.Table 6 shows the computationally tractable fea-tures we defined within this framework.
Featureswith ?#?
in their name are numeric features and theothers are binary features (taking either 0 or 1).6 Detecting modification candidatesUsing these features, we carried out an experimentof automatic identification of modification candi-dates.
As a machine learning method, we usedSVM (Vapnik, 1995).
The aim of the experimentwas twofold: (i) to observe the feasibility of auto-matic notification of modification candidates, and(ii) to examine the factors that trigger modificationsin more detail.6.1 Experimental setupIn the application of SVM, we reduced the numberof binary features by using those that have highercorrelations with positive and negative examples, us-ing mutual information (MI).
Table 7 shows featuresthat have high correlations with positive and nega-tive features (eight for each).SVM settings: The liner kernel was used.
For anumeric feature X , the value x is normalized by z-score, norm(x) = x?avg(X)?var(X), where avg(x) is theempirical mean of X and var(X) is the variance ofX.Data: The numbers of positive and negative casesin the data are 226 and 894, respectively (1120 intotal).
In order to balance the positive and negativeexamples, we used an equal number of examples fortraining.244(A)EN#word: the number of words in the English sentenceEN#pause: the number of delimiters in the English sen-tenceEN#verb: the number of verbs in the English sentenceEN#VVN: the number of VNN verbs in the English sen-tenceEN#word len: the average number of characters in a word(B)EPOS: POS of the English word correspondingto the target Japanese verbEPOS before: POS of a word before the English wordcorresponding to the target Japanese verbEPOS after: POS of a word after the English word cor-responding to the target Japanese verbEPOS before:POS : a bigram of EPOS before and EPOSEPOS:POS after: a bigram of EPOS and EPOS afterEJ#translation: translation probability between thesource and target language sentences(C)Fsuffix: a suffix following the target verbFparticle: a particle following the target verbFpause park: a pause mark following the target verbDmodifying case: case marker of the element that modifies thetarget verbDmodifying agent: case marker of the element that modifies thetarget verb, if its case element has an AGENTattributeDfunctional: functional noun which is modified by the tar-get verbDmodified case: case marker of the element that is modified bythe target verbSfirst agent: first case element in the sentence has anAGENT attributeSbefore passive: Is there a passive verb before the targetverb in the sentence?Safter passive: Is there a passive verb after the target verbin the sentence?
(D)Nmodifying voice: the voice of the verb that modifies thetarget verbNmodifying voice: the voice of the verb that is modifiedby the target verbNgrandparent voice: the voice of the grandparent verb ofthe target verbNgrandchild voice: the voice of the grandchild verb of thetarget verbNcase adjacency; bigram consists of a particle of the tar-get verb and a particle of the adja-cency bunsetsu chunk(E)J#morpheme: the number of morphemes in the targetJapanese sentenceJ#pause: the number of pause marks in the targetJapanese sentenceJ#verb: the number of verbs in the target JapanesesentenceJ#passive: the number of verbs with passive voice in thetarget Japanese sentenceJ#depth: depth of the modifier which modifies the tar-get verbTable 6: FeaturesMethods of evaluation: We used (i) 10-fold crossvalidation to check the power of classifiers for un-known data and (ii) a partially closed test in whichthe 226 positive and negative examples were usedfor training and 1120 data were evaluated, in orderto observe the realistic prospects for actual use.6.2 Result of experiment and feature analysisTable 8 shows the results.
Though they are reason-able, the overall accuracy, especially for the partiallyclosed test, shows that the method is in need of im-provement.In order to evaluate the effectiveness of the fea-ture sets, we carried out experiments only using andwithout using each feature set.
Table 9 shows thathow efficient is each feature set defined in Table 6.The left-hand column in Table 9 shows the resultwith all feature sets except focal feature set, and theright-hand column shows the result when only thefocal feature set was used.The experiment showed that the feature set thatcontributed most was C (features related to theJapanese target verbs).
We also carried out an exper-iment to check which features are effective amongthis set, in the same manner as the experiments forchecking the effectiveness of the feature sets.
Theresult showed that the feature Dmodifying case is thefeature that contributed the most by far.
In Japanese,case markers are strongly correlated with the voiceof verbs, and the coverage of this feature for tokensrelated to voice is high because it is common for averb to be modified by the case element with the casemarker.It became clear that the numeric features A andE contribute little to the overall accuracy.
Table 10shows the correlation coefficient between the nu-meric features and correct answers.
The table showsthat there is no noticeable relation between the nu-245accuracy (+)precision (+)recall (-)precision (-)recallCross validation 0.646 (291/452) 0.656 (138/214) 0.614 (138/226) 0.643 (153/238) 0.677 (153/226)Partially closed 0.521 (583/1120) 0.277 (193/697) 0.854 (193/226) 0.922 (390/423) 0.436 (390/894)Table 8: The accuracy of classificationwithout this feature set using only this feature setfeature set accuracy (+)precision (+)recall accuracy (+)precision (+)recall(A) 0.638 0.638 (144/226) 0.639 (144/226) 0.521 0.541 (62/115) 0.277 (62/226)(B) 0.634 0.649 (132/203) 0.584 (132/226) 0.563 0.549 (159/290) 0.705 (159/226)(C) 0.579 0.576 (136/237) 0.604 (136/226) 0.610 0.620 (128/207) 0.570 (128/226)(D) 0.645 0.654 (138/212) 0.615 (138/226) 0.523 0.679 (19/29) 0.087 (19/226)(E) 0.629 0.666 (117/175) 0.518 (117/226) 0.492 0.491 (101/205) 0.447 (101/226)Table 9: The evaluation result for each feature setfeature MI f(+) f(-)Dmodifying agent=NIYOTTE 0.843 15 17EPOS:POS after=VVN:NN 0.656 14 22EPOS before=IN 0.536 10 19EPOS before=JJ 0.530 12 23Dmodified case=GA 0.428 13 29Ngrandparent voice=passive 0.408 17 39Ngrandchild voice=passive 0.368 14 34EPOS=VVZ 0.368 14 34Fsuffix=NARU 0.225 0 23Ncase adjacency=GA:TO 0.225 0 12Fsuffix=SHIMAU 0.225 0 16EPOS=RB 0.225 0 10EPOS:POS after=VVG:DT 0.225 0 10EPOS:POS after=VVN:TO 0.179 2 42EPOS:POS after=VVN:SENT 0.159 3 44Dmodifying agent=NI 0.154 4 54Table 7: Features which have high correlation withpositive and negative examplesmeric features and the correct results.
We introducedmost numeric features based on the study of read-ability.
In readability studies, however, these fea-tures are defined in terms of the overall document,and not in terms of individual sentences or of verbphrases.
It would be preferable to develop numer-ical features that can properly reflect the nature ofindividual sentences or smaller constructions.Table 9 shows that the result when only using thefeature set D has a very low recall, but the highestfeature set (A)EN#word 0.038EN#pause -0.069EN#verb -0.003EN#VVN -0.061EN#word len 0.033feature set (E)J#morpheme 0.083J#pause 0.011J#verb 0.056J#passive 0.035J#depth 0.098Table 10: The correlation coefficient between eachfeature and correct answerprecision of all the feature sets.
This mean that thereare not many occasions on which the feature set Dcan be applied, but when it is applied, the result is re-liable.
The feature set D thus is efficient as a triggeronce it is applied, and the different treatment of thetokens that contain this feature set may contribute tothe performance improvement.6.3 DiagnosisThe critical cases from the point of view of improv-ing the performance are the false positives and falsenegatives.
We thus manually analysed the false pos-itives and false negatives obtained in the partiallyclosed experiment (in the actual application envi-ronment, as much training data as available shouldbe used; we thus used the results of the partially246closed experiment here).
For the false positive, weextracted 100 sample sentences from 504 sentences.For the false negative we used all 33 sentences.
Weasked two translators to judge whether (i) it would bebetter to modify the draft translations or (ii) it wouldnot be necessary to modify the draft translations.6.3.1 False positivesFrom the 100 sample sentences, we excluded 23cases, 18 of which were judged as in need of mod-ification by one of the translators and 5 of whichwere judged as in need of modification by both ofthe translators.
We manually analysed the remaining77 cases.
Rather than the problems with the featuresthat we used, we identified the potential factors thatwould contribute to the restriction of modification.Three types of restricting factor were recognised:1.
The nature of individual verbs allows or re-quires the passive voice.
Within the data, threesubtypes were identified, i.e.
(i) the use of thepassive is natural irrespective of context, as in ?????
(consumed)?
(48 cases); (ii) the use ofthe passive is natural within certain fixed syn-tactic patterns, as in ?X ?????
Y (Y calledX)?
(10 cases); and (iii) the passive is used aspart of a common collocation, as in ????????
(attacked by anxiety)?
(2 cases);2.
The use of the active voice is blocked by selec-tional restrictions, as in ????????
(a sedi-ment made by ...)?
(1 case); and3.
The structure of the sentence requires the pas-sive, as in ???????????????????????????????????????
(Thebiggest companies were all companies makingcars, in which most of the oil was consumed)?
(16 cases).Together they cover 73 cases (in 4 out of 77 caseswe could not identify the factor, and in 4 of the 73cases two of the above factors were identified).
It isanticipated that the first type (60 cases; about 85%)could be dealt with by introducing ?pulling?
trig-gers, i.e.
using large corpora to identify the char-acteristics of the use of voice for individual verbs,in order to enable the system to judge the desirabil-ity of given expressions vis-a`-vis the conventionalalternatives.
To deal with the second type requiresa detailed semantic description of nouns, which isdifficult to achieve, though in some cases it couldbe approximated by collocational tendencies.
Inregards to the third type of false positive, we ex-pected that the type of features used in the experi-ment would have been sufficient to eliminate them,but this was not the case.
In fact, many of the fea-tures require discourse level information, such as thechoice of subject within the flow of discourse, in or-der to function properly, which we did not take intoaccount.
Although high-performance discourse pro-cessing is still in an embryonic stage, in the settingof the present study the correspondence between keyinformation in English and that in Japanese could beused to deal with this type of false positive.6.3.2 False negativesHere, it is necessary to find factors that would pro-mote modification.
Among the 33 false negatives, 4were judged as not in need of modification by boththe translators.
We thus examined the remaining 29cases.
In 13 cases, the verb was replaced by anotherverb.
Including these cases, we identified four basicfactors that are related to triggering modification:1.
The nature of the individual verbs strongly re-quires the active voice, either independently orwithin the particular context, as in ??????????
(was asked by)?
(9 cases);2.
The structure of the sentence is rendered ratherawkward by the use of passives, as in ????????????????????????
(a reportpublished in ...... by analysts)?
(4 cases);3.
A given lexical collocation is unnatural or awk-ward, as in ??????????????????????????
(that all investments be screenedis collectively insisted)?
(2 cases); and4.
A lexicalised collocation in the draft was sub-tly awkward and there is a better collocation orexpression that fits the situation (14 cases).Together they cover 26 cases.
We could not iden-tify features in 3 cases.
As in false positives, the first,second and fourth types (22 cases or about 85% arefully covered by these three types) could be dealtwith by introducing ?pulling?
triggers, using largeexternal corpora.For the overall data, we would expect that around85% of 388 (77% of 504 cases) false positives (330247cases) could be dealt with by introducing ?pulling?triggers.
If these false positives could be removedcompletely, the precision would become well over0.5 (193/(697-330)) and the ratio of notified caseswould become about one third ((697-330)/1120) ofthe total relevant cases.
Though it is unreasonable toassume this ideal case, this indicates that the fea-tures we defined and introduced in this study ?though limited to those related to ?pushing?
triggers?
were effective, and that what we have achievedby using these features is very promising in termsof realising a system that notifies users of awkwardtranslations.7 ConclusionsIn this paper, we examined the factors that trig-ger modifications when translators are revisingdraft translations, and identified computationallytractable features relevant to the modification.
Wecarried out an experiment for automatic detectionof modification candidates.
The result was highlypromising, though it revealed several issues thatneed to be addressed further.Following the results reported in this paper, weare currently working on.
(i) extending the experiment by introducing out-side data to carry out open experiments (wehave obtained draft and final translations ofthree more books);(ii) introducing the degree of necessity for modifi-cations by asking translators to judge the data;and(iii) further examining the features used in the ex-periment for the improvement of performance.In addition, we are experimenting with a method formaking use of large-scale external corpora in orderto deal with ?pulling?-type triggers, with additionalfeatures taken from large external corpora.AcknowledgementThis research is partly supported by grant-in-aid (A)17200018 ?Construction of online multilingual ref-erence tools for aiding translators?
by the JapanSociety for the Promotion of Sciences (JSPS), andalso by grant-in-aid from The HAKUHO FOUNDA-TION, Tokyo.ReferencesAbekawa, T. and Kageura, K. 2007.
A translation aidsystem with a stratified lookup interface.
In Proc.
ofACL 2007 Demos and Poster Sessions, p. 5?8.Anzai, T. 1995.
Eibun Hon?yaku Jutu (in Japanese).Tokyo: Chikuma.Barzilay, R. and McKeown, K. R. 2001.
Extracting para-phrases from a parallel corpus.
In Proc.
of ACL 2001,p.
50-57.Barzilay, R. and Lee, L. 2003.
Learning to paraphrase:An unsupervised approach using multiple-sequencealignment.
In Proc.
of HLT-NAACL 2003, p. 16-23.Dolan, B. et.
al.
2004.
Unsupervised construction oflarge paraphrase corpora: Exploiting massively paral-lel news sources alignment.
In Proc.
of COLING 2004,p.
350-356.Fry, E. 1968.
A readability formula that saves time.Journal of Reading, 11, p. 513-516, 575-578.Gunning, R. 1959.
The Technique of Clear Writing.New York: McGraw-Hill.Haruno, M. and Yamazaki, T. 1996.
High-performancebilingual text alignment using statistical and dictionaryinformation.
In Proc.
of ACL 1996, p. 131-138.Inui, K. and Fujita, A.
2004.
A survey on paraphrasegeneration and recognition.
Journal of Natural Lan-guage Processing, 11(5), p. 131-138.Leggett, J.
2005.
Half Gone.
London: Portobello.
[Ma-suoka, K. et.
al.
trans.
2006.
Peak Oil Panic.
Tokyo:Sakuhinsha.
]Nakamura, Y.
2003.
Eiwa Hon?yaku no Genri Gihou (inJapanese).
Tokyo: Nichigai Associates.Och, F. J. and Ney, H. 2003.
A systematic comparison ofvarious statistical alignment models.
ComputationalLinguistics, 29(1), p. 19-51.Quirk, C., Brocktt, C. and Dolan, W. B.
2004 Monolin-gual machine translation for paraphrase generation.
InProc.
of EMNLP 2004, p. 142-149.Schmid, H. 1994.
Probabilistic part-of-speech taggingusing decision trees.
In Proc.
of NeMLAP, p. 44-49.Shinyama, Y. et.
al.
2002.
Automatic paraphrase acqui-sition from news articles.
In Proc.
of HLT 2002, p.40-46.Sun, et.
al.
2007.
Detecting erroneous sentences usingautomatically mined sequential patterns.
In Proc.
ofACL 2007, p. 81-88.Vapnik, V. N. 1995.
The Nature of Statistical LearningTheory.
New York: Springer.248
