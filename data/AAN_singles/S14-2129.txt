Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 722?726,Dublin, Ireland, August 23-24, 2014.UMCC_DLSI_Prob: A Probabilistic Automata for Aspect BasedSentiment AnalysisYenier Casta?edaArmando CollazoElvis CregoJorge L. GarciaYoan Guti?rrezDavid Tom?sAndr?s MontoyoRafael Mu?ozDI, University of MatanzasMatanzas, CubaDLSI, University of AlicanteAlicante, Spain{yenier.castaneda,armando.collazo}@umcc.cu,elvis.crego@mtz.cu,jorge.garcia@infonet.umcc.cu{ygutierrez,dtomas,montoyo,rafael}@dlsi.ua.esAbstractThis work introduces a new approach foraspect based sentiment analysis task.
Its mainpurpose is to automatically assign the correctpolarity for the aspect term in a phrase.
It is aprobabilistic automata where each stateconsists of all the nouns, adjectives, verbs andadverbs found in an annotated corpora.
Eachone of them contains the number ofoccurrences in the annotated corpora for thefour required polarities (i.e.
positive, negative,neutral and conflict).
Also, the transitionsbetween states have been taken into account.These values were used to assign the predictedpolarity when a pattern was found in asentence; if a pattern cannot be applied, theprobabilities of the polarities between stateswere computed in order to predict the rightpolarity.
The system achieved results around66% and 57% of recall for the restaurant andlaptop domain respectively.1 IntroductionSentiment analysis is increasingly viewed as avital task from both an academic and acommercial standpoint.
Textual information hasbecome one of the most important sources of datato extract useful and heterogeneous knowledge.
?Texts can provide factual information, such as:descriptions, lists of characteristics, or eveninstructions to opinion-based information, whichwould include reviews, emotions, or feelings.These facts have motivated dealing with theidentification and extraction of opinions andsentiments in texts that require special attention.?
(Guti?rrez, et al., 2014).
Sentiment Analysis or?Subjectivity Analysis?
in (Liu, 2010) is definedas the computational treatment of opinions,sentiments and emotions expressed in a text.
Inorder to automatically treat the subjectivity, weneed lexical resources that allow the detection andevaluation of the affective/ subjective charges intexts, its polarity and intensity.Regarding research carried out for linguisticpatterns identification and its polarity in texts, it isworth mentioning works on: adjectives(Hatzivassiloglou and McKeown, 1997) (Wiebe,2000); adjectives and verbs (Turney, 2002)(Wilson, et al., 2005) (Takamura, et al., 2007);and also verbs and names (Esuli and Sebastini,2006).
WordNet (Fellbaum, 1998) has also beenused for the collection of opinion adjectives andverbs (Kim and Hovy, 2005) to determine thesemantic orientation of the terms depending ontheir notes (Esuli and Sebastiani, 2005), for theadjective extraction (Andreevskaia and Bergler,2006) or opinion mining (Esuli and Sebastiani,2007).Inspired on Hidden Markov models (Baumand Petrie, 1966) and following the idea thatwords combinations are finite in an evaluationtext, we decided to create a finite automata ingraph form to represent all these relationsextracted from a training corpus.
For the creationof this automata we utilised different resources,such as WordNet and OpinionFinder SubjectivityLexicon.
Also, different extracted patterns basedon (Cazab?n, 1973) were applied.This paper is structured as follows: In section1.1 is described the task 4 of SemEval2014(Pontiki, et al., 2014) where this system waspresented.
Section 2 presents the description ofthe automata and how it was built.
The polarityassignation method using the trained automata is_________________________This work is licensed under a Creative CommonsAttribution 4.0 International Licence.
Page numbers andproceedings footer are added by the organisers.
Licencedetails: http://creativecommons.org/licenses/by/4.0/722described in section 3.
Finally, in section 4 and 5are shown the results and conclusions,respectively.1.1 Task DescriptionThe SemEval2014 task 4 (Pontiki, et al., 2014)was divided into four subtasks: 4.1 Aspect termextraction; 4.2 Aspect term polarity; 4.3 Aspectcategory detection; and 4.4 Aspect categorypolarity.This paper is focused on subtask 4.2 which isdescribed as follows:Given one or more Aspect Terms within asentence, it is necessary to determine whether thepolarity of each Aspect Term is positive, negative,neutral or conflict (i.e., both positive andnegative).
For example:?I loved their fajitas?
??fajitas?
: positive?I hated their fajitas, buttheir salads were great?
??fajitas?
: negative,?salads?
: positive?The fajitas are their firstplate?
?
?fajitas?
: neutral?The fajitas were great totaste, but not to see?
??fajitas?
: conflict.Each participant was permitted to submit twokinds of runs for this task:Constrained: Using only the provided trainingdata and other resources, such as lexicons.Unconstrained: Using additional data fortraining.
Teams were asked to report whatresources they used for each submitted run.The training dataset, provided by the organiser ofthe Task 4 challenge, consists of two domain-specific datasets which contain over 6,500sentences with fine-grained aspect-level human-authored annotations.
These domains are:Restaurant reviews: This dataset consists ofover 3000 English sentences from the restaurantreviews of (Ganu, et al., 2009) that were adaptedto the task.Laptop reviews: This dataset consists of over3000 English sentences extracted from customerreviews of laptops.2 The automataThe automata was represented as a graph ?
=(?, ?)
whose vertexes constitute the group offinite states ?
=  [?1, ?2, ?3, ?
, ??]
while the1http://alt.qcri.org/semeval2014/task4/edges represent the transitions ?
=[?1, ?2, ?3, ?
, ??]
of going from one state toanother.Our finite automata involves the followingfeatures:1.
Group of finite states: all the verbs, nouns,adverbs, adjectives that were extracted fromthe training dataset (see Section 2.1) usingFreeling 3.1 language analyser (Atserias, etal., 2006), or Aspect Terms (that may beformed by several words).
In every state theautomata stores the occurrences ??
?, wherep is one of the following polarity classes:positive, negative, neutral, conflict orundefined, i being the index of the currentstate in the graph.2.
Finite alphabet: a sentences set whichcontains one or more Aspect Terms towhich should be assigned a polarity.3.
Initial state: first word of the sentence.4.
Transition state (???,?
and ???,?
): eachtransition between two states contains ??,?
?and ??,?
?, where p is  positive, negative,neutral  or conflict, i is the current state, andj is the next state.5.
End state: last word of the sentence.If we could not determine the polarityclassification for a state or transition, then we setit as undefined polarity.2.1 Training the automataIn order to create the automata the training datasetprovided for the SemEval2014 taks 41 was used.In the automata, each word of a sentence formsa state which is connected to the following word.This connection forms a transition between thetwo words.
This method is repeated until the lastword of the sentence is reached.
If the wordalready exists in the automata, both its state andall the transitions (from and to that word) areadjusted, increasing in one the ??
?, ??,?
?and ??,?
?of the polarity value initially assigned in thecorpus.The transitions from words to Aspect Termswith their respective polarities allow to go throughthose words with undefined polarities to the targetAspect Terms.
This event is done for finding themost probably polarity according to the trainingdiscoveries.
Same thing happens with transitionsfrom an Aspect Term to a word, but in this casefrom the polarity of the Aspect Term to undefinedpolarity.723On the other hand, if the word is not an AspectTerm its state do not change at all, since thedataset only annotates the Aspect Terms, so we donot know the polarity of those words that are notan Aspect Term.To solve this issue we decided to make use ofother resources to enhance the automata, so thatthe probability for finding a polarity for a word inthe automata increases with the expansion of thedictionary.
We used the Opinion FinderSubjectivity Lexicon (OFSL) (Wilson, et al.,2005) to adjust the state and transitions of thewords in the automata.
To address the adjustment,for every word of OFSL (according to theclassification of the sentiment polarity) that existsin the graph represented by automata, therespective value of polarity of ???,??,?
?and ??,?
?isincreased in one.
We also used WordNet 3.0 toobtain the synonyms and antonyms of the wordsin the automata to form new states and transitions.Synonyms were given the same polarity as therelated word, whereas antonyms took the oppositepolarity.
The subjectivity clues extracted by thepatterns detected in the training dataset were usedas well (See section 3.2).In Table 1 we show the terminology used forthe patterns.Symbol Description[] Optional word/!
Subjectivity clue/l Compare by lemmaAT Aspect TermTable 1: Pattern symbolsExamples:[DT] AT [PRP] [RB] be/l [VBG/!]RB/!
[JJ/!]
[RB/!][RB/!]
[DT] JJS/!
[DT] [NN] AT [VB][NN/!
][DT] JJ/!
NN PRP VBD VB [DT] ATAT be/l [DT/!]
JJ/!
[PRP/!]
[RB/!
]Note the use of the POS tags such as DT, NN,VBD, and others were taken from the result of thepos-tagging process performed by Freeling 3.1.Using this tool the incoming texts were split intoparts (sentences) for the following processes.For instance, in the sentence ?This MacBookPro is excellent?
the subjectivity clue for theAspect Term MacBook Pro is excellent; so itsstates and transitions get adjusted the same way asthe Aspect Term.
Figure 1 describes this example,where pi is ??
?, pij is ??,?
?and pji is ??,?
?means theoccurrence for positive polarity (negative, neutraland conflict polarities were omitted by lack ofspace).
Both states and transitions are represented.Figure 1: Adjusting states and transitions afterpattern analysis.3 Polarity AssignationBefore predicting the polarity of the AspectTerms, each sentence is divided by its connectors(conjunctions, prepositions and adverbs, extractedusing Freeling), forming the correspondingphrases.
For instance, the sentence ?WhereGabriela personally greets you and recommendsyou what to eat?
is divided into the phrase ?WhereGabriela personally greets you?
and the phrase?recommends you what to eat?
by connector and.3.1 Selection criteriaIf only one polarity is found then that is thepolarity for the Aspect Term.
On the other hand,if more than one polarity is found, the polarity forthe Aspect Term is the most repeated one.Note that if both positive and negative are themost repeated polarities we set conflict as thepolarity for the Aspect Term.If no polarities are found at all, we assigneeneutral to the Aspect Term.3.2 Assigning polarity using patternsWe detected different patterns which allowed usto extract those words that influence on the AspectTerm polarity in the phrase (See section 2.1).For each phrase subjectivity clue i, wecalculate the most probable polarity???=????(???
), if i has a state in the automata.After that, we apply our selection criteriadescribed in section 3.1.If no polarities are found at all, we process thephrase in the next steps.3.3 Assigning polarity using the automataFor each Aspect Term in the phrase we get thesentence it belongs to and we calculate ???,?=??,?????,??
in that sentence, where ???,?
is the mostprobable polarity of ???,?
(j being the AspectTerm), if such a transition existed.
If no polarity724is found, then we calculate ??
?,?=??,?????,??
again ifsuch a transition existed.In case of applying aforementioned processeswithout finding out a concrete polarity for thetarget Aspect Terms, we perform other steps to tryto find one or more polarities for the Aspect Term.First, we verify whether the Aspect Term ispart of a phrase which was matched to a patternbut no polarity was found as explained in section3.2, if so we get the subjectivity clues of thephrase and for each subjectivity clue we calculate??
?,?, where i is the Aspect Term index and jcorresponds to the subjectivity clue index.
If nopolarity is found, then we calculate ??
?,?.If no polarities are found after this step, weproceed to do the same as above, but this time foreach word in the sentence.Lastly, if no polarities are found, ???
isobtained for each word i in the sentence if i has astate in the automata.After performing these steps we apply ourselection criteria to assign the polarity to theAspect Term in question.
As can be seen, ourproposal is focused on the application of anexhaustive exploration of the automata in order toclassify Aspect Terms with the target polarities.4 Results and DiscussionIn order to evaluate the accuracy of the systemseveral tests were run.
Table 2 shows some of thetests using SemEval2014 task4 Baseline for theRestaurant reviews.
We did the same evaluationfor Laptop reviews and the results obtained werevery similar to those shown in Table 2 forRestaurant.
We used semeval_base.py2 script tosplit the dataset into a train and a test part using an80:20 ratio.
Despite tests 1, 2 and 3 results do notvary much, it is evident that using the threetraining resources yields our best accuracy.Training EvaluationTest Patterns WordNet OFSL Pattern/Automata only Automata only Accuracy (%)1 X X X X  58.02 X   X  57.93 X  X X  57.94 X X X  X 54.0Table 2: Evaluation over restaurant domainWith test 4 it is evident that it is better to usetwo methods combined than only one of them,since the patterns indicate the words that assignpolarity to the Aspect Term, making the automatamore precise with this information at the time ofassigning the correct polarity.
Otherwise, if apattern is not encountered we need to analyse thewords that are closer to the Aspect Termdetermining the polarity according to the context.In addition, not always is assigned a polarity to itin case of the pattern found in the context isempty.
Table 3 shows the results of our system incomparison with the best of the challengeSemEval2014 subtask 4.2.Test ConstrainedAccuracy (%)UnconstrainedAccuracy (%) Rest 66.5 66.8Laptop 56.1 57.0BRR 80.9 77.6BRL 70.4 66.6Table 3: Test subtask 4.2 (BRR: Best Ranked forRestaurant; BRL Best Ranked for Laptop)The system behaved the same as the trainingstage on the competition although the accuracyincreased.2 http://alt.qcri.org/semeval2014/task4/data/semeval14-absa-base-eval-valid.zip5 Conclusions and future worksThis work introduces a new approach for aspectbased sentiment analysis.
For that, a probabilisticautomata was created where the states are formedby the nouns, adjectives, verbs and adverbs foundin the annotated corpora, based on theiroccurrence.
The transitions between states arealso taken into account.
A set of patterns weredefined in order to extract the words that influenceon an Aspect Term, also known as subjectivityclues, and then we predicted their polarity usingthe automata?s probabilities.
A system wasdeveloped following this approach to participateon SemEval2014 competition, obtaining anaccuracy of 66% for restaurant reviews and 57%for laptop reviews.As future works we plan to deal with the factthat this automata only involves states representedby the words lack extracted from the training data.So, the previously unseen aspect terms which donot correspond to any state in the automata, arenot recognised in many cases as far as the polarityis concerned.
To address this issue we plan to725expand the aspect term dictionary usingWikipedia definitions.
On the other hand, we planto use a disambiguation method to select the exactWordNet synset and then to reduce the polysemyof the automata?s words.
Finally, to smooth theprobabilities it would be interesting to studydifferent balances in order to get newimprovements for the system.AcknowledgmentsThis research work has been partially funded bythe University of Alicante, GeneralitatValenciana, Spanish Government and theEuropean Commission through the projects,?Tratamiento inteligente de la informaci?n para laayuda a la toma de decisiones?
(GRE12-44),ATTOS (TIN2012-38536-C03-03), LEGOLANG(TIN2012-31224), SAM (FP7-611312), FIRST(FP7-287607) and ACOMP/2013/067.ReferencesAlina Andreevskaia and Sabine Bergler, 2006.
MiningWordNet for Fuzzy Sentiment: Sentiment TagExtraction from WordNet Glosses.
Trento, Italia,s.n.Jordi Atserias et al., 2006.
FreeLing 1.3: Syntactic andsemantic services in an opensource NLP library.Genoa, Italy, s.n.Leonard  Baum and Ted Petrie, 1966.
StatisticalInference for Probabilistic Functions of Finite StateMarkov Chains.
The Annals of MathematicalStatistics, pp.
1554--1563.Mar?a Cazab?n, 1973.
Patterns of English.s.l.
:Editorial Pueblo y Educaci?n.Andrea Esuli and Fabrizio Sebastiani , 2005.Determining the semantic orientation of termsthrough gloss classification.
Proceedings of the14th ACM International Conference onInformation and Knowledge Management, pp.
617-624.Andrea Esuli and Fabrizio Sebastiani, 2007.PageRanking WordNet Synsets: An Application toOpinion Mining.
Prague, Czeck Republic, s.n., pp.424-431.Andrea Esuli and Fabrizio Sebastiani, 2006.SentiWordNet: A Publicly Available LexicalResource for Opinion Mining.
Genova, IT, s.n., pp.417-422.Christiane Fellbaum, 1998.
WordNet.
An ElectronicLexical Database.
University of Cambridge: s.n.Gayatree Ganu, Noemie Elhadad and Am?lie Marian,2009.
Beyond the stars: Improving ratingpredictions using review text content.
Rhode Island,s.n.Yoan Guti?rrez, Andy Gonz?lez, Roger P?rez, Jos?
I.Abreu, Antonio Fern?ndez Orqu?n, AlejandroMosquera, Andr?s Montoyo, Rafael Mu?oz andFranc Camara, 2014.
UMCC_DLSI-(SA): Using aranking algorithm and informal features to solveSentiment Analysis in Twitter.
Second JointConference on Lexical and ComputationalSemantics (*SEM), Volume 2: Proceedings of theSeventh International Workshop on SemanticEvaluation (SemEval 2013), pp.
443--449.Vasileios Hatzivassiloglou and Kathleen McKeown,1997.
Predicting the Semantic Orientation ofAdjectives.
Madrid, Spain, s.n., pp.
174-181.Soo-Min Kim and Eduard Hovy, 2005.
AutomaticDetection of Opinion Bearing Words andSentences.
Jeju Island, Republic of Korea, s.n.Bing Liu, 2010.
Sentiment Analysis and Subjectivity.In: Handbook of Natural Language Processing.Boca Raton: s.n., pp.
627-666.Maria Pontiki, Dimitrios Galanis, John Pavlopoulos,Haris Papageorgiou, Ion Androutsopoulos,and Suresh Manandhar, 2014.
SemEval-2014 Task 4:Aspect Based Sentiment Analysis.
In Proceedingsof the 8th International Workshop on SemanticEvaluation (SemEval 2014), Dublin, Ireland.Hiroya Takamura, Takashi Inui and Manabu Okumura,2007.
Extracting Semantic Orientations of Phrasesfrom Dictionary.
s.l., s.n., pp.
292-299.Peter Turney, 2002.
Thumbs up or thumbs down?Semantic orientation applied to unsupervisedclassification of reviews.
Philadelphia,Pennsylvania, s.n., pp.
417-424.Janyce Wiebe, 2000.
Learning Subjective Adjectivesfrom Corpora.
Austin, Texas, s.n.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann,2005.
Recognizing Contextual Polarity in Phrase-Level Sentiment Analysis.
Vancouver, Canada., s.n.726
