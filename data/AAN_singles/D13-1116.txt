Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1158?1169,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsCombining PCFG-LA Models with Dual Decomposition: A Case Study withFunction Labels and BinarizationJoseph Le Roux?, Antoine Rozenknop?, Jennifer Foster??
Universite?
Paris 13, Sorbonne Paris Cite?, LIPN, F-93430, Villetaneuse, France?
NCLT/CNGL, School of Computing, Dublin City University, Dublin 9, Irelandjoseph.leroux@lipn.fr antoine.rozenknop@lipn.fr jfoster@computing.dcu.ieAbstractIt has recently been shown that different NLPmodels can be effectively combined usingdual decomposition.
In this paper we demon-strate that PCFG-LA parsing models are suit-able for combination in this way.
We exper-iment with the different models which resultfrom alternative methods of extracting a gram-mar from a treebank (retaining or discardingfunction labels, left binarization versus rightbinarization) and achieve a labeled ParsevalF-score of 92.4 on Wall Street Journal Sec-tion 23 ?
this represents an absolute improve-ment of 0.7 and an error reduction rate of 7%over a strong PCFG-LA product-model base-line.
Although we experiment only with bina-rization and function labels in this study, thereis much scope for applying this approach toother grammar extraction strategies.1 IntroductionBecause of the large amount of possibly contra-dictory information contained in a treebank, learn-ing a phrase-structure-based parser implies makingseveral choices regarding the prevalent annotationswhich have to be kept ?
or discarded ?
in order toguide the learning algorithm.
These choices, whichinclude whether to keep function labels and emptynodes, how to binarize the trees and whether to alterthe granularity of the tagset, are often motivated em-pirically by parsing performance rather than by thedifferent aspects of the language they may be able tocapture.Recently Rush et al(2010), Martins et al(2011)and Koo et al(2010) have shown that Dual De-composition or Lagrangian Relaxation is an elegantSfedcb(a) Original exampleS?S??S?
?S?fedcb(b) Left Binarized exampleSf?S?e?S?d?S?cb(c) Right Binarized exampleFigure 1: Binarization with markovizationframework for combining different types of NLPtasks or for building parsers from simple slave pro-cesses that only check partial well-formedness.
Herewe propose to follow this idea, but with a differentobjective.
We want to mix different parsers trainedon different versions of a treebank each of whichmakes some annotation choices in order to learnmore specific or richer information.
We will usestate-of-the-art unlexicalized probabilistic context-free grammars with latent annotations (PCFG-LA)in order to compare our approach with a strong base-line of high-quality parses.
Dual Decomposition isused to mix several systems (between two and four)that may in turn be combinations of grammars, hereproducts of PCFG-LAs (Petrov, 2010).
The systemsbeing combined make different choices with regardto i) function labels and ii) grammar binarization.Common sense would suggest that information inthe form of function labels ?
syntactic labels such asSBJ and PRD and semantic labels such as TMP andLOC ?
might help in obtaining a fine-grained anal-ysis.
On the other hand, the independence hypothe-1158sis on which CFGs rely and on which most popularparsers are based may be too strong to learn the de-pendencies between functions across the parse trees.Also, the number of parameters increases with theuse of function labels and this can affect the learn-ing process.At first glance, binarization need not be an is-sue, as CFGs admit a binarized form recognizingexactly the same language.
But binarization can beassociated with horizontal markovization and in thiscase the recognized language will differ.
Further-more this can impose an unwanted emphasis on whatfrontier information is more relevant to learning (be-ginning or end of constituents).
In the toy exam-ple of Figure 1, the original grammar consisting of aunique rule extracted from one tree only recognizesthe string bcdef, while the grammar learned fromthe left binarized and markovized tree recognizes(among others) bcdef and bdcef and the gram-mar learned from the right binarized and markovizedtree recognizes (among others) bcdef and bcedf.We find that i) retaining the function labels in non-terminal categories loses its negative impact on pars-ing as the number of grammars increases in PCFG-LA product models, ii) the function labels them-selves can be recovered with near state-of-the-art-accuracy, iii) combining grammars with and withoutfunction labels using dual decomposition is bene-ficial, iv) combining left and right-binarized gram-mars using dual decomposition also leads to bet-ter trees and, v) our best results (a Parseval la-beled F-score of 92.4, a Stanford labeled attach-ment score (LAS) of 93.0 and a penn2malt unla-beled attachment score (UAS) of 94.3 on Section 23of the Wall Street Journal) are obtained by combin-ing three grammars which encode different functionlabel/binarization decisions.The paper is organized as follows.
?
2 reviewsrelated work.
?
3 presents approximate PCFG-LAparsers as linear models, while ?
4 shows how wecan use dual decomposition to derive an algorithmfor combining these models.
Experimental resultsare presented and discussed in ?
5.2 Related WorkParser Model Combination It is well known thatimproved parsing performance can be achieved byleveraging the alternative perspectives provided byseveral parsing models rather than relying on justone.
Examples are parser co-training (Steedmanet al 2003; Sagae and Tsujii, 2007), voting overphrase structure constituents or dependency arcs(Henderson and Brill, 1999; Sagae and Tsujii, 2007;Surdeanu and Manning, 2010), dependency pars-ing stacking (Nivre and McDonald, 2008), productmodel PCFG-LA parsing (Petrov, 2010), using dualdecomposition to combine dependency and phrasestructure models (Rush et al 2010) or several non-projective dependency parsing models (Koo et al2010; Martins et al 2011), and using expecta-tion propagation, a related approach to dual decom-position, to combine lexicalized, unlexicalized andPCFG-LA models (Hall and Klein, 2012).
In thislast example, the models must factor in the sameway: in other words, the grammars must use thesame binarization scheme.
In our study, we employPCFG-LA product models with dual decomposition,and we relax the constraints on factorization, as werequire only a loose coupling of the models.Function Label Parsing Although function labelshave been available in the Penn Treebank (PTB) foralmost twenty years (Marcus et al 1994), they havebeen to a large extent overlooked in English parsingresearch ?
most studies that report parsing resultson Section 23 of the Wall Street Journal (WSJ) useparsing models that are trained on a version of theWSJ trees where the function labels have been re-moved.
Notable exceptions are Merlo and Musillo(2005) and Gabbard et al(2006) who each traineda parsing model on a version of the PTB with func-tion labels intact.
Gabbard et al(2006) found thatparsing accuracy was not affected by keeping thefunction labels.
There have also been attempts touse machine learning to recover the function labelspost-parsing (Blaheta and Charniak, 2000; Chrupalaet al 2007).
We recover function labels as part ofthe parsing process, and use dual decomposition tocombine parsing models with and without functionlabels.
We are not aware of any other work thatleverages the benefits of both types of models.Grammar Binarization Matsuzaki et al(2005)compare binarization strategies for PCFG-LA pars-ing, and conclude that the differences between themhave a minor effect on parsing accuracy as the num-1159ber of latent annotations increases beyond two.
Halland Klein (2012) are forced to use head binarizationwhen combining their lexicalized and unlexicalizedparsers.
Dual decomposition allows us to combinemodels with different binarization schemes.3 Approximation of PCFG-LAs as LinearModelsIn this section, we explain how we can use PCFG-LAs to devise linear models suitable for the dual de-composition framework.3.1 PCFG-LALet us recall that PCFG-LAs are defined as tuplesG = (N , T ,H,RH, S, p) where:?
N is a set of observed non-terminals, amongwhich S is the distinguished initial symbol,?
T is a set of terminals (words),?
H is a set of latent annotations or hidden states,?
RH is a set of annotated rules, of the forma[h1] ?
b[h2] c[h3] for internal rules1 anda[h1] ?
w for lexical rules.
Here a, b, c ?
Nare non-terminals, w ?
T is a terminal andh1, h2, h3 ?
H are latent annotations.
Follow-ing Cohen et al(2012) we also define the set ofskeletal rules R, in other words, rules withouthidden states, of the form a?
b c or a?
w.?
p : RH ?
R?0 defines the probabilities asso-ciated with rules conditioned on their left-handside.
Like Petrov and Klein (2007), we imposethat the initial symbol S has only one latent an-notation.
In other words, among rules with Son the left-hand side, only those of the formS[0]?
?
are inRH.With such a grammar G we can define probabil-ities over trees in the following way.
We will con-sider two types of trees, annotated trees and skeletaltrees.
An annotated tree is a sequence of rules fromRH, while a skeletal tree is a sequence of skeletalrules from R. An annotated tree TH is obtained byleft-most derivation from S[0].
Its probability is:1For brevity and without loss of generality, we omit unaryand n-ary rules, as PCFG-LA admit a Chomsky normal form.p(TH) =?r?THp(r) (1)We define a projection ?
from annotated trees toskeletal trees.
?
(TH) is a tree T isomorphic to THwith the same terminal and non-terminal symbols la-beling nodes, without hidden states.
The probabilityof a skeletal tree T is a sum of the probabilities ofall annotated trees that admit T as their projection.p(T ) =?TH??
?1(T )?r?THp(r) (2)PCFG-LA parsing amounts to, given a sequenceof words, finding the most probable skeletal treewith this sequence as its yield according to a gram-mar G:T ?
= arg maxT?TH??
?1(T )?r?THp(r) (3)Because of this alternation of sum and products,the parsing problem is intractable.
Moreover, thePCFG-LAs do not belong to the family of linearmodels that are assumed in the Lagrangian frame-work of (Rush and Collins, 2012).
We now turn toapproximations for the parsing problem in order toaddress both issues.3.2 Variational Inference and MaxRuleVariational inference is a common technique to ap-proximate a probability distribution p with a cruderone q, as close as possible to the original one,by minimizing the Kullback-Liebler divergence be-tween the two ?
see for instance (Smith, 2011),chapter 5 for an introduction.
Matsuzaki et al(2005) showed that one can easily find such a cruderdistribution for PCFG-LAs and demonstrated exper-imentally that this approximation gives good results.More precisely, they find a PCFG that only rec-ognizes the input sentence where the probabilitiesq(rs) of the rules are set according to their marginalprobabilities in the original PCFG-LA parse forest.The parameters rs are skeletal rules with span infor-mation.
Distribution q is defined in Figure 2.Other approximations are possible.
In particu-lar, Petrov and Klein (2007) found that normaliz-ing by the forest probability (in other words the in-side probability of the root node) give better exper-1160score(a?
b c, i, j, k) =?x,y,z?HP i,kout(a[x])?
p(a[x]?
b[y] c[z])?
P i,jin(b[y])?
P j,kin(c[z])norm(a?
b c, i, j, k) =?x?HP i,kin(a[x])?
P i,kout(a[x])score(a?
w, i) =?x?HP i,iout(a[x])?
p(a[x]?
w)norm(a?
w, i) =?x?HP i,iin(a[x])?
P i,iout(a[x])q(rs) =[score(rs)norm(rs)(Variational Inference)]or[score(rs)P 0,nin (S[0])(MaxRule-Product)]Figure 2: Variational Inference for PCFG-LA.
Pin and Pout denote inside and outside probabilities.imental results although its interpretation as varia-tional inference is still unclear.
This approximationis called MaxRule-Product and amounts to replacingthe norm function (see Figure 2).In both cases, the probability of a skeletal treenow becomes a simple product of parameters asso-ciated with anchored skeletal rules.
For our purpose,the consequence is twofold:1.
The parsing problem becomes tractable by ap-plying standard PCFG algorithms relying ondynamic programming (CKY for example).2.
Equivalent to probability, a score ?
can be de-fined as the logarithm of the probability.
Theparsing problem becomes2:T ?
= arg maxT?rs?Tq(rs)= arg maxT?rs?Tlog q(rs)= arg maxT?rs?Fwrs ?
1{rs ?
T}= arg maxT?
(T )Thus, from a PCFG-LA we are able to de-fine a linear model whose parameters are the log-probabilities of the rules in distribution q.2We denote the parse forest of a sentence by F and the char-acteristic function of a set by 1.3.3 Products of PCFG-LAsAlthough PCFG-LA training is beyond the scopeof this paper, it is worthwhile mentioning that themost common way to learn their parameters relieson Expectation-Maximization which is not guaran-teed to find the optimal estimation.
Fortunately, thiscan be partly overcome by combining grammars thatonly differ on the initial parameterization of the EMalgorithm.
The probability of a skeletal tree is theproduct of the probabilities assigned by each singlegrammar Gi.T ?
= arg maxTn?i=1qGi(T ) (4)Since grammars only differ by their numerical pa-rameters (i.e.
skeletal rules are the same), inferencecan be efficiently implemented using dynamic pro-gramming (Petrov, 2010).Scoring with n such grammars now becomes:T ?
= arg maxTn?i=1?r?Tlog qGi(r) (5)= arg maxT?r?Tn?i=1log qGi(r) (6)The distributions qGi still have to be computed in-dependently ?
and possibly in parallel ?
but the finaldecoding can be performed jointly.
This is still alinear model for PCFG-LA parsing, but restricted togrammars that share the same skeletal rules.11614 Dual DecompositionIn this section, we show how we derive an algorithmto work out the best parse according to a set of ngrammars that do not share the exact same skele-tal rules.
As such, the grammars?
product cannotbe easily conducted inside the parser to produce andscore a same and unique best tree, and we now con-sider a c(ompound)-parse as a tuple (T1 .
.
.
Tn) ofn compatible trees.
Each grammar Gi is responsi-ble for scoring tree Ti, and we seek to obtain thec-parse that maximizes the sum of the scores of itsdifferent trees.
For a c-parse to be consistent, wehave to precisely define the parts on which the treesmust agree to be compatible with each other, so thatwe can model these as agreement constraints.4.1 Compound Parse ConsistencyLet us suppose we have a set of phrase-structureparsers trained on different versions of the sametreebank.
Hence, some elements in the charts willeither be the same or can be mapped to each otherprovided an equivalence relation and we define con-sensus between parsers on these elements.When the grammar is not functionally annotated,phrase-structure trees can be decomposed into a setof anchored (syntactical) categories Xs, assertingthat a category X is in the tree at position3 s. Thus,such a tree T can be described by means of a booleanvector z(T ) indexed by anchored labels Xs, wherez(T )Xs = 1 if Xs is in T and 0 otherwise.We will differentiate the set of natural non-terminals that occur in the treebanks from the setof artificial non-terminals that do not occur in thetreebank and are the results of a binarization withmarkovization.
As these artificial non-terminals dis-appear after reversing binarization in solution trees,they do not play any role in the consensus betweenparsers, and we only consider natural non-terminalsin the set of anchored labels.When the grammar is functionally annotated,each label X?
in a tree is a pair (X,F ), where Xis a syntactical category and F is a function label.In this case, in order to manage the consensus with3The anchor s of a label is composed of the span (i, j), de-noting that the label covers terminals of the input sentence fromindex i to index j.
In case the grammar contains unary non-lexical rules, the anchor also discriminates the different posi-tions in a sequence of unary rules.non-functional grammars, we decompose such a treeinto two sets: a set of anchored categories Xs and aset of anchored function labels Fs.
Thus, a tree Tcan be described by means of two boolean vectors:?
z(T ) indexed by anchored categories Xs,z(T )Xs = 1 if there exists a function label Fso that (X,F )s is in T , and 0 otherwise;?
?
(T ) indexed by anchored function labels Fs,?
(T )Fs = 1 if there exists a category X so that(X,F )s is in T , and 0 otherwise.In the present work, a compound parse (T1 .
.
.
Tn)is said to be consistent iff every tree shares the sameset of anchored categories, i.e.
iff:?
(i, j) ?
J1, nK2, z(Ti) = z(Tj)4.2 Combining Parsers through DualDecompositionLike previous applications, we base our reasoningon the assumption that computing the optimal scorewith each grammar Gi can be efficiently calculated,which is the case for approximate PCFG-LA pars-ing.
We follow the presentation of the decomposi-tion from (Martins et al 2011) to explain how wecan combine several PCFG-LA parsers together.For a sentence s, we want to obtain the best con-sistent compound parse from a set of n parsers:(P ) : find arg max(T1...Tn)?Cn?p=1?p(Tp) (7)s.t.
?
(i, j) ?
J1, nK2, z(Ti) = z(Tj) (8)where C = F1(s) ?
... ?
Fn(s) is the product ofparse forests F i(s), and F i(s) is the set of trees ingrammar Gi whose yields are the input sentence s.Solving this problem with an exact algorithm isintractable.
While artificial nodes could be inferredusing a traditional parsing algorithm based on dy-namic programming (i.e.
CKY), the natural nodesrequire a coupling of the parsers?
items to enforcethe fact that natural daughter nodes must be identical(or equivalent) with the same spans for all parsers.Since the debinarization of markovized rules enablesthe creation of arbitrarily long n-ary rules, in theworst case the number of natural daughters to checkis exponential in the size of the span to infer.
Even if1162we bound the length of debinarized rules, the prob-lem is hardly tractable.As this problem is intractable, even for approxi-mate PCFG-LA parsing, we apply the iterate methodpresented in (Komodakis et al 2007) for MRFs,also applied for joint tasks in NLP such as combinedparsing and POS tagging in (Rush et al 2010).First, we introduce a witness vector u in order tosimplify constraints in (8).
Problem (P ) can then bewritten in an equivalent form :(P ) : find oP = max(T1...Tn)?Cn?i=1?i(Ti) (9)s.t.
?i ?
J1, nK, z(Ti) = u (10)Next, we proceed to a Lagrangian decomposition.This decomposition is a two-step process:Step 1 (Relaxation): the coupling constraints (10)are removed by introducing a vector of Lagrangemultipliers ?i = (?i,Xs)Xs for each parser i, in-dexed by anchored categories Xs, and writing theequivalent problem:(RP ) : oRP = maxu, T1...nmin?f(u, T1...n,?
)where:f(u, T1...n,?)
=?i?i(Ti) +?i(z(Ti)?
u) ?
?iIntuitively, we can see the equivalence of (RP )and (P ) with the following reasoning:?
whenever all constraints (10) are met, the sec-ond sum in f is nullified and f(u, T1...n,?)
=?i ?i(Ti), which is a finite value and preciselythe objective function maximized in (P );?
if there is at least one (i,X, s) such thatz(Ti)Xs 6= uXs , then the value of?i(z(Ti) ?u) ?
?i can be made arbitrarily small byan appropriate choice of ?i,Xs ; in this case,min?
f(u, T1...n,?)
= ??.
Thus, (RP ) cannot reach its maximum at a point where con-straints (10) are not satisfied.Step 2 (dualization): the dual problem (LP ) is ob-tained by permuting max and min in (RP ):(LP1) : oLP = min?maxu, T1...nf(u, T1...n,?
)Finally, u can be removed from (LP1) by addingthe constraint:?i ?i = 0.
As a matter of fact,one can see that if this constraint is not matched,maxu,T1...n f(u, T1...n,?)
= +?
and (LP1) cannot reach its minimum on such a point.
We can nowfind the maximum of f by maxing each Ti indepen-dently of each other.
The dual problem becomes:(LP ) : oLP = min?n?i=1maxTi?Fi(?i(Ti) + z(Ti) ?
?i)s.t.
?i?i = 0Minimization in (LP ) can be solved iterativelyusing the projected subgradient method.
Finding asubgradient amounts to computing the optimal so-lution (Rush and Collins, 2012) for each of the nsubproblems (the slave problems in the terminol-ogy of (Martins et al 2011) and (Komodakis et al2007)) which can be done efficiently, by incorpo-rating the calculation of the penalties in the parsingalgorithm, and in parallel.
Until the agreement con-straints are met (or a maximal number of iterations?
), the Lagrangian multipliers are updated accordingto the deviations from the average solutions (i.e.
up-dates are zeros for a natural span if the parsers agreeon it).
This leads to Algorithm 1.It should be noted that the DP charts are built andpruned during the first iteration only (t = 0); fur-ther iterations do not require recreating the DP chart,which is memory intensive and time consuming, norrecomputing the approximate distribution for varia-tional inference.
As DP on the pruned charts is a fastprocess, the bottleneck of the algorithm still is in thefirst calculation of slave solutions.The stepsize sequence (?t)0?t must be diminish-ing and non-summable, that is to say: ?t, ?t ?
0,limt??
?t = 0 and?
?t=0 ?t = ?.
In practice, weset ?t = 11+c(t) where c(t) is the number of times theobjective function oP has increased since iterationsbegan.Solving (P): it is easy to see that oLP is an up-per bound of oP , but we do not necessarily have1163Algorithm 1 Find best compound parse with con-straints on natural spansRequire: n parsers {pi}1?i?nfor all i, syntactical category X , anchor s do?
(0)i,Xs = 0end forfor t = 0?
?
dofor all parsers pi doT (t)i ?
arg maxT?Fi(?i(T ) + z(T ) ?
?
(t)i)end forfor all parsers pi do?
(t)i ?
?t(z(T (t)i)?
?1?j?n z(T (t)j)n)?
(t+1)i ?
?
(t)i + ?
(t)iend forif ?
(t)i = 0 for all i thenExit loopend ifend forreturn (T (?
)1 , ?
?
?
, T(?
)n )strong duality (i.e.
oLP = oP ) due to the facts thatparse forests are discrete sets.
Furthermore, they getpruned independently of each other.
Thus, the algo-rithm is not guaranteed to find a t such that z(T (t)i )is the same for every parser i.
However ?
see (Kooet al 2010) ?
if it does reach such a state, then wehave the guarantee of having found an exact solutionof the primal problem (P ).
We show in the experi-ments that this occurs very frequently.5 Experiments5.1 Experimental SetupWe perform our experiments on the WSJ sections ofthe PTB with the usual split: sections 2 to 21 fortraining, section 23 for testing, and we run bench-marks on section 22. evalb is used for evaluation.We use the LORG parser modified with Algo-rithm 1.
4 All grammars are trained using 6split/merge EM cycles.
For the handling of unknownwords, we removed all words occurring once in thetraining set and replaced them by their morpholog-ical signature (Attia et al 2010).
Grammars forproducts are obtained by training with 16 randomseeds for each setting.
We use the approximate al-4The LORG parser is available at https://github.com/CNGLdlab/LORG-Release and the modification athttps://github.com/jihelhere/LORG-Release/tree/functional_c11.gorithm MaxRule-Product (Petrov and Klein, 2007).The basic settings are a combination of the twofollowing parameters:left or right binarization: we conjecture that thisaffects the quality of the parsers by impacting therecognition of left and right constituent frontiers.We set vertical markovization to 1 (no parent anno-tation) and horizontal markovization to 0 (we dropall left/right annotations).with or without functional annotations: in par-ticular when non-terminals are annotated with mul-tiple functions, all are kept.5.2 Products of GrammarsWe first evaluate each setting on its own before com-bining them.
We test the 4 different settings on thedevelopment set, using a single grammar or a prod-uct of n grammars.
Results are reported on Figure 3.We can see that right binarization performs betterthan left binarization.
Contrary to the results of Gab-bard et al(2006), function labels are detrimental forparsing performance for one grammar only.
How-ever, they do not penalize performance when usingthe product model with 8 grammars or more.nF1 2 4 8 168990919293Func RightNo Func RightNo Func LeftFunc LeftFigure 3: F1 for products of n grammars on the dev.
setEM is not guaranteed to find the optimal modeland the problem is made harder by the increasednumber of parameters.
Product models effectivelyalleviate this curse of dimensionality by letting somemodels compensate for the errors made by others.On the other hand, as differences between leftand right binarization settings remain over all prod-uct sizes, right binarization seems more useful onits own.
The first part of Table 1 gives F-score and1164Exact Match results of the product models with 16grammars on the development set.5.3 Combinations with Dual DecompositionWe now turn to a series of experiments combiningproduct models of 16 grammars.
In all these experi-ments, we set the maximum number of iterations inAlgorithm 1 to 1000.
The system then returns thefirst element of the c-parse.
We first try to combinetwo settings in four different combinations:DD Right Bin the two right-binarized systems ?with and without functions ?
the system returnsthe function-labeled parse;DD Left Bin the two left-binarized systems ?
withand without functions ?
the system returns thefunction-labeled parse;DD Func the two systems with functions ?
left andright binarization ?
the system returns the right-binarized parse;DD No Func the two systems without functions ?left and right binarization ?
the system returnsthe right-binarized parse;Results are in the second part of Table 1.
Un-surprisingly, the best configuration is the one com-bining the two best product systems (with right bi-narization) but all combined systems perform betterthan their single components.Setting F EXNo Func Right 92.26 42.97No Func Left 91.92 42.91Func Right 92.37 43.35Func Left 91.95 43.15DD Right Bin 92.71 44.44DD Left Bin 92.23 43.97DD Func 92.51 44.79DD No Func 92.52 44.08DD3 92.86 45.03DD4 92.82 45.14Table 1: Parse evaluation on development set.We also combine 3 and 4 parsers to see if combin-ing the above DD Right Bin setting with informa-tion that could improve the recognition of beginningof constituents can be helpful.
We have 2 settings:DD3 The 2 right-binarized parsers combined withthe left binarized parser without functions,DD4 The 4 parsers together.In both cases the system returns the right-binarized function annotated parse.
The results areshown in the last part of Table 1.
These 2 new con-figurations give similar F-scores, better than all 2-parser configurations.We conclude from these results that left-binarization and right-binarization capture differentlinguistic aspects, even in the case of heavy horizon-tal markovization, and that the method we proposeenables a practical integration of these models.Table 2 shows for each setting how often the sys-tems agree before 1000 iterations of Algorithm 1.As one might expect, the more diverse the systemsare, the lower the rate of agreement.Setting RateDD Right Bin 99.24DD Left Bin 99.12DD Func 98.53DD No Func 99.12DD3 96.18DD4 94.53Table 2: Rate of certificates of optimality on the dev set.5.4 Evaluation of Function LabelingWe also evaluate the quality of the function labels.We compare the results obtained directly from theparser output with results obtained with Funtag, astate-of-the-art functional tagger that is applied onparser output, using a gold model trained on sections02 to 21 of the WSJ (Chrupala et al 2007).Setting SYSTEM FUN FUNTAGNo Func Right ?
90.41No Func Left ?
90.26Func Right 89.61 90.37Func Left 89.29 90.40DD Right Bin 89.50 90.38DD Left Bin 89.11 90.31DD Func 89.54 90.49DD No Func ?
90.36DD3 89.48 90.42DD4 89.57 90.45Table 3: Function labeling F1 on development set.The results are shown in Table 3.
First, we cansee that the parser output is always outperformed byFuntag.
This is expected from a context-free parser1165that has a limited domain of locality with strong in-dependence constraints, compared to a voted-SVMclassifier that can rely on arbitrarily rich features.Second, the quality of the Funtag prediction seemsto be influenced by the fact that parser already han-dle functions and by the accuracy of the parser (Par-seval F-score).
This is because we use a modeltrained on the gold reference and so the closer theparser output is from the reference, the better theprediction.
On the other hand, this is not the casewith parser predicted functions, where the best sys-tem is the right-binarized product model with func-tions, with very similar performance obtained by thecombinations consisting of 2 function parsers, set-tings DD Func and DD4.
This tends to indicatethat the constraints we have set to define consisten-cies in c-parses, focusing on syntactical categories,do not help in retrieving better function labels.
Thissuggests some possible further improvements whereparsers with functional annotations should be forcedto agree on these too.5.5 Evaluation of DependenciesSetting Stanford LTH p2mLAS UAS LAS UAS UASFunc Right 92.18 94.32 89.51 93.92 94.2No Func Right 92.03 94.47 65.31 92.22 94.2Func Left 91.86 94.06 89.28 93.75 93.9No Func Left 91.83 94.29 65.33 92.18 94.1DD Right Bin 92.56 94.60 89.81 94.17 94.5DD Left Bin 92.01 94.38 89.62 94.05 94.2DD Func 92.19 94.36 89.67 94.06 94.2DD No Func 92.19 94.57 65.44 92.37 94.3DD3 92.77 94.79 90.04 94.33 94.5DD4 92.59 94.62 89.95 94.24 94.4Table 4: Dependency accuracies on the dev setDependency-based evaluation of phrase structureparser output has been used in recent years to pro-vide a more rounded view on parser performanceand to compare with direct dependency parsers (Ceret al 2010; Petrov et al 2010; Nivre et al 2010;Foster et al 2011; Petrov and McDonald, 2012).We evaluate our various parsing models on theirability to recover three types of dependencies: basicStanford dependencies (de Marneffe and Manning,2008)5, LTH dependencies (Johansson and Nugues,5We used the latest version at the time of writing, i.e.
3.20.2007)6 and penn2malt dependencies.7 The latterare a simpler version of the LTH dependencies butare still used when reporting unlabeled attachmentscores for dependency parsing.The results, shown in Table 4, mirror the con-stituency evaluation results in that the dual decom-position results tend to outperform the basic productmodel results, and combining three or four gram-mars using dual decomposition yields the highestscores.
The differences between the Func and NoFunc results highlight an important difference be-tween the Stanford and LTH dependency schemes.The tool used to produce Stanford dependencies hasbeen designed to work with phrase structure treesthat do not contain function labels.
In contrast, theLTH tool makes use of function label informationin phrase structure trees.
Thus, their availability re-sults in only a moderate improvement in LAS for theStanford dependencies and a very striking improve-ment for the LTH dependencies.
By retaining func-tion labels during parsing, we have shown that LTHdependencies can be recovered with a high level ofaccuracy without having to resort to a post-parsingfunction labeling step.5.6 Test Set ResultsWe now evaluate our various systems on the test set(the first half of Table 5) and compare these resultswith state-of-the-art systems (the second half of Ta-ble 5).
We present parser accuracy results, measuredusing Parseval F-score and penn2malt UAS, and, forour systems, function label accuracy for labels pro-duced during parsing and after parsing using Funtag.We also carried out statistical significance testing8on the F-score differences between our various sys-tems on the development and test sets.
The results6nlp.cs.lth.se/software/treebank_converter.
Itis recommended that LTH is used with the version of the PennTreebank which contains the more detailed NP bracketing pro-vided by Vadas and Curran (2007).
However, to facilitate com-parison with other parsers and dependency schemes, we did notuse it in our experiments.
We ran the converter with the right-Branching=false option to indicate that we are using the versionwithout extra noun phrase bracketing.7stp.lingfil.uu.se/?nivre/research/Penn2Malt.The English head-finding rules of Yamada and Mat-sumoto (2003), supplied on the website, are employed.8We used Dan Bikel?s compare.pl script which usesstratified shuffling to compute significance.
We consider a pvalue < 0.05 to indicate a statistically significant difference.1166Setting F UAS Fun FuntagFunc Right 91.73 93.9 91.02 91.88No Func Right 91.76 93.8 ?
91.80Func Left 91.45 93.7 90.41 91.80No Func Left 91.57 93.7 ?
91.74DD Right Bin 92.16 94.1 90.85 91.86DD Left Bin 91.89 93.9 90.10 91.85DD Func 92.23 94.1 91.02 91.91DD No Func 92.09 94.0 ?
91.86DD3 92.45 94.3 90.86 91.98DD4 92.44 94.3 90.97 92.04(Shindo et al 2012) 92.4(Zhang et al 2009) 92.3(Petrov, 2010) 91.8(Huang, 2008) 91.7(Bohnet and Nivre, 2012) 93.7Table 5: Test Set Results: Parseval F-score, penn2maltUAS, Function Label Accuracy and Funtag Function La-bel Accuracyare shown in Table 6.Comparison Dev TestFunc Right vs. No Func Right 7 7Func Left vs. No Func Left 7 7Func Right vs. Func Left X 7No Func Right vs. No Func Left 7 7DD Right Bin vs. Func Right X XDD Right Bin vs. No Func Right X XDD Left Bin vs. Func Left X XDD Left Bin vs. No Func Left X XDD Right Bin vs DD Left Bin X XDD Func vs. Func Right 7 XDD Func vs. Func Left X XDD No Func vs. No Func Right X XDD No Func vs. No Func Left X XDD Func vs. DD No Func 7 7DD3 vs. DD Right Bin 7 XDD3 vs. No Func Left X XDD3 vs. DD Func X XDD4 vs. DD.
Right Bin 7 XDD4 vs. DD.
Left Bin X XDD4 vs. DD Func X XDD4 vs. DD3 7 7Table 6: Statistical Significance TestingWe measured the performance of DD4 on the testset.
It is approximately 3 times slower than theslowest product model (left binarization with func-tion labels) and 7 slower than the fastest one (rightbinarization without function labels).
This systemperforms on average 85.5 iterations of the DD al-gorithm.
If we exclude the non-converging cases(5.1% of the cases), this drops to 39.4.Finally we compare our results with systemstrained and evaluated on the PTB, see the lower halfof Table 5.
Our product models are not differentfrom those presented in (Petrov, 2010) and it is notsurprising to see that the F-scores are similar.
Moreinterestingly our DD4 setting improves on these re-sults and compares favorably with systems relyingon richer syntactic information, such as the discrim-inative parser of (Huang, 2008) that makes use ofnon-local features to score trees and the TSG parserof (Shindo et al 2012) that can take into accountlarger tree fragments: this would indicate that bycombining our parsers we extend the domain of lo-cality, horizontally with binarization schemes andvertically with function labels.
Our system also per-forms better than the combination system presentedin (Zhang et al 2009) that only relies on materialfrom the PTB9 but a more detailed comparison isdifficult: this system does not use products of la-tent models and more generally their method is or-thogonal to ours.
We also include for comparisonstate-of-the-art dependency parsing results (Bohnetand Nivre, 2012).6 ConclusionWe presented an algorithm and a set of experimentsshowing that grammar extraction strategies can becombined in an elegant way and give state-of-the-artresults when applied to high-quality phrase-basedparsers.
As well as repeating these experiments forlanguages which rely more on function annotation,we also plan to apply our method to other types ofannotations, e.g.
more linguistically motivated bina-rization strategies or ?
of particular interest to us ?annotation of empty elements.AcknowledgmentsWe are grateful to the reviewers for their helpfulcomments.
We also thank Joachim Wagner for pro-viding feedback on an early version of the paper.This work has been partially funded by the LabexEFL (ANR/CGI).9Their other system relying on the self-trained version of theBLLIP parser achieves 92.6 F1.1167ReferencesMohammed Attia, Jennifer Foster, Deirdre Hogan,Joseph Le Roux, Lamia Tounsi, and Josef van Gen-abith.
2010.
Handling unknown words in statisticallatent-variable parsing models for Arabic, English andFrench.
In Proceedings of the First Workshop on Sta-tistical Parsing of Morphologically Rich Languages(SPMRL 2010).Don Blaheta and Eugene Charniak.
2000.
Assigningfunction tags to parsed text.
In Proceedings of the 1stAnnual Meeting of the North American chapter of theACL.Bernd Bohnet and Joakim Nivre.
2012.
A transition-based system for joint part-of-speech tagging and la-beled non-projective dependency parsing.
In Proceed-ings of the 2012 Joint Conference on Empirical Meth-ods in Natural Language Processing and Computa-tional Natural Language Learning, pages 1455?1465.Daniel Cer, Marie-Catherine de Marneffe, Daniel Juraf-sky, and Christopher D. Manning.
2010.
Parsing toStanford Dependencies: Trade-offs between speed andaccuracy.
In Proceedings of LREC.Grzegorz Chrupala, Nicolas Stroppa, Josef van Genabith,and Georgiana Dinu.
2007.
Better training for func-tion labeling.
In Proceedings of the 2007 Conferenceon Recent Advances in Natural Language Processing(RANLP).Shay B. Cohen, Karl Stratos, Michael Collins, Dean P.Foster, and Lyle Ungar.
2012.
Spectral learning oflatent-variable PCFGs.
In Proceedings of the 50thAnnual Meeting of the Association for ComputationalLinguistics (ACL?12).Marie-Catherine de Marneffe and Christopher D. Man-ning.
2008.
The Stanford typed dependencies repre-sentation.
In Proceedings of the COLING Workshopon Cross-Framework and Cross-Domain Parser Eval-uation.Jennifer Foster, Ozlem Cetinoglu, Joachim Wagner,Joseph Le Roux, Joakim Nivre, Deirdre Hogan, andJosef van Genabith.
2011.
From news to comment:Resources and benchmarks for parsing the languageof web 2.0.
In Proceedings of IJCNLP.Ryan Gabbard, Mitchell Marcus, and Seth Kulick.
2006.Fully parsing the penn treebank.
In Proceedings of theHuman Language Technology Conference of the NorthAmerican Chapter of the ACL, pages 184?191.David Hall and Dan Klein.
2012.
Training factoredPCFGs with expectation propagation.
In Proceedingsof the 2012 Conference on Empirical Methods in Nat-ural Language Processing, pages 649?652.John C. Henderson and Eric Brill.
1999.
Exploitingdiversity in natural language processing: Combiningparsers.
In Proceedings of the 1999 Conference onEmpirical Methods in Natural Language Processing,pages 187?194.Liang Huang.
2008.
Forest reranking: Discriminativeparsing with non-local features.
In Proceedings ofACL-08: HLT, pages 586?594.Richard Johansson and Pierre Nugues.
2007.
Extendedconstituent-to-dependency conversion for english.
InJoakim Nivre, Heiki-Jaan Kaalep, Kadri Muischnek,and Mare Koit, editors, Proceedings of NODALIDA2007, pages 105?112.Nikos Komodakis, Nikos Paragios, and Georgios Tziri-tas.
2007.
MRF optimization via dual decomposition:Message-passing revisited.
In Computer Vision, 2007.ICCV 2007.
IEEE 11th International Conference on,pages 1?8.
IEEE.Terry Koo, Alexander M. Rush, Michael Collins, TommiJaakkola, and David Sontag.
2010.
Dual decompo-sition for parsing with non-projective head automata.In Proceedings of the 2010 Conference on EmpiricalMethods in Natural Language Processing.Mitchell Marcus, Grace Kim, Mary Ann Marcinkiewicz,Robert MacIntyre, Ann Bies, Mark Ferguson, KarenKatz, and Britta Schasberger.
1994.
The penn tree-bank: Annotating predicate argument structure.
InProceedings of the 1994 ARPA Speech and NaturalLanguage Workshop, pages 114?119.Andre?
FT Martins, Noah A Smith, Pedro MQ Aguiar,and Ma?rio AT Figueiredo.
2011.
Dual decompositionwith many overlapping components.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing, pages 238?249.Takuya Matsuzaki, Yusuke Miyao, and Jun?ichi Tsujii.2005.
Probabilistic CFG with latent annotations.
InProceedings of the 43rd Annual Meeting of the Asso-ciation for Computational Linguistics (ACL?05), pages75?82.Paola Merlo and Gabriele Musillo.
2005.
Accu-rate function parsing.
In Proceedings of HumanLanguage Technology Conference and Conference onEmpirical Methods in Natural Language Processing(HLT/EMNLP), pages 620?627.Joakim Nivre and Ryan McDonald.
2008.
Integratinggraph-based and transition-based dependency parsers.In Proceedings of ACL-08: HLT, pages 950?958.Joakim Nivre, Laura Rimell, Ryan Mc Donald, and Car-los Go?mez-Rodr??guez.
2010.
Evaluation of depen-dency parsers on unbounded dependencies.
In Pro-ceedings of COLING.Slav Petrov and Dan Klein.
2007.
Improved infer-ence for unlexicalized parsing.
In Proceedings ofthe conference on Human Language Technologies andthe conference of the North American Chapter ofthe Association for Computational Linguistics (HLT-NAACL?07).1168Slav Petrov and Ryan McDonald.
2012.
Overview ofthe 2012 shared task on parsing the web.
In WorkingNotes of the SANCL Workshop (NAACL-HLT).Slav Petrov, Pi-Chuan Chang, Michael Ringgaard, andHiyan Alshawi.
2010.
Uptraining for accurate deter-ministic question parsing.
In Proceedings of EMNLP.Slav Petrov.
2010.
Products of random latent variablegrammars.
In Proceedings of the conference on Hu-man Language Technologies and the conference of theNorth American Chapter of the Association for Com-putational Linguistics (HLT-NAACL?10), pages 19?27.Alexander Rush and Michael Collins.
2012.
A tutorialon dual decomposition and lagrangian relaxation forinference in natural language processing.
Journal ofArtificial Intelligence Research, 45:305?362.Alexander M Rush, David Sontag, Michael Collins, andTommi Jaakkola.
2010.
On dual decomposition andlinear programming relaxations for natural languageprocessing.
In Proceedings of the 2010 Conference onEmpirical Methods in Natural Language Processing,pages 1?11.Kenji Sagae and Jun?ichi Tsujii.
2007.
Dependency pars-ing and domain adaptation with LR models and parserensembles.
In Proceedings of the CoNLL shared tasksession of EMNLP-CoNLL, pages 1044?1050.Hiroyuki Shindo, Yusuke Miyao, Akinori Fujino, andMasaaki Nagata.
2012.
Bayesian symbol-refined treesubstitution grammars for syntactic parsing.
In Pro-ceedings of the 50th Annual Meeting of the Associationfor Computational Linguistics: Long Papers-Volume1, pages 440?448.Noah A. Smith.
2011.
Linguistic Structure Predic-tion.
Synthesis Lectures on Human Language Tech-nologies.
Morgan and Claypool, May.Mark Steedman, Miles Osbourne, Anoop Sarkar, StephenClark, Rebecca Hwa, Julia Hockenmaier, Paul Ruhlen,Steven Baker, and Jeremiah Crim.
2003.
Boot-strapping statistical parsers from small datasets.
InProceedings of EACL, pages 759?763.Mihai Surdeanu and Christopher D. Manning.
2010.
En-semble models for dependency parsing: Cheap andgood?
In Proceedings of the conference on Hu-man Language Technologies and the conference of theNorth American Chapter of the Association for Com-putational Linguistics (HLT-NAACL?10), pages 649?652.David Vadas and James R. Curran.
2007.
Adding nounphrase structure to the penn treebank.
In Proceedingsof ACL, pages 240?247.Hiroyasu Yamada and Yuji Matsumoto.
2003.
Statisticaldependency analysis with support vector machines.
InProceedings of IWPT, pages 195?206.Hui Zhang, Min Zhang, Chew Lim Tan, and HaizhouLi.
2009.
K-best combination of syntactic parsers.In Proceedings of the 2009 Conference on Empiri-cal Methods in Natural Language Processing, pages1552?1560.1169
