Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 250?258,Beijing, August 2010Comparison of different algebras for inducingthe temporal structure of textsPascal Denis??
Alpage Project-TeamINRIA & Universit?
Paris 7pascal.denis@inria.frPhilippe Muller?, IRITUniversit?
de Toulousemuller@irit.frAbstractThis paper investigates the impact of us-ing different temporal algebras for learn-ing temporal relations between events.Specifically, we compare three interval-based algebras: Allen (1983) algebra,Bruce (1972) algebra, and the algebra de-rived from the TempEval-07 campaign.These algebras encode different granular-ities of relations and have different infer-ential properties.
They in turn behave dif-ferently when used to enforce global con-sistency constraints on the building of atemporal representation.
Through variousexperiments on the TimeBank/AQUAINTcorpus, we show that although the TempE-val relation set leads to the best classifica-tion accuracy performance, it is too vagueto be used for enforcing consistency.
Bycontrast, the other two relation sets aresimilarly harder to learn, but more use-ful when global consistency is important.Overall, the Bruce algebra is shown togive the best compromise between learn-ability and expressive power.1 IntroductionBeing able to recover the temporal relations (e.g.,precedence, inclusion) that hold between eventsand other time-denoting expressions in a docu-ment is an essential part of natural language un-derstanding.
Success in this task has importantimplications for other NLP applications, such astext summarization, information extraction, andquestion answering.Interest for this problem within the NLP com-munity is not new (Passonneau, 1988; Webber,1988; Lascarides and Asher, 1993), but has beenrecently revived by the creation of the TimeBankcorpus (Pustejovsky et al, 2003), and the orga-nization of the TempEval-07 campaign (Verhagenet al, 2007).
These have seen the developmentof machine learning inspired systems (Bramsen etal., 2006; Mani et al, 2006; Tatu and Srikanth,2008; Chambers and Jurafsky, 2008).Learning the temporal stucture from texts is adifficult problem because there are numerous in-formation sources at play (in particular, seman-tic and pragmatic ones) (Lascarides and Asher,1993).
An additional difficulty comes from thefact that temporal relations have logical proper-ties that restrict the consistent graphs that can bebuilt for a set of temporal entities (for instancethe transitivity of inclusion and temporal prece-dence).
Previous work do not attempt to directlypredict globally coherent temporal graphs, but in-stead focus on the the simpler problem of label-ing pre-selected pairs of events (i.e., a task thatdirectly lends itself to the use of standard classifi-cation techniques).
That is, they do not considerthe problem of linking pairs of events (i.e., of de-termining which pairs of events are related).Given the importance of temporal reasoningfor determining the temporal structure of texts,a natural question is how to best use it withina machine-based learning approach.
Following(Mani et al, 2006), prior approaches exploit tem-poral inferences to enrich the set of training in-stances used for learning.
By contrast, (Bramsenet al, 2006) use temporal relation compositions toprovide constraints in a global inference problem(on the slightly different task of ordering passagesin medical history records).
(Tatu and Srikanth,2008) and (Chambers and Jurafsky, 2008) com-bine both approaches and use temporal reasoningboth during training and decoding.
Interestingly,these approaches use different inventories of re-lations: (Mani et al, 2006) use the TimeML 13relation set, while (Chambers and Jurafsky, 2008;250Bramsen et al, 2006) use subset of these relations,namely precedence and the absence of relation.This paper adopts a more systematic perspec-tive and directly assesses the impact of differ-ent relation sets (and their underlying algebras)in terms of learning and inferential properties.Specifically, we compare three interval-based al-gebras for building classification-based systems,namely: Allen (1983)?s 13 relation algebra, Bruce(1972)?s 7 relations algebra, and the algebraunderlying Tempeval-07 3 relations (henceforth,TempEval algebra).
We wish to determine thebest trade-off between: (i) how easy it is to learna given set of relations, (ii) how informative arethe representations produced by each relation set,and (iii) how much information can be drawn fromthe predicted relations using knowledge encodedin the representation.
These algebras indeed dif-fer in the number of relations they encode, and inturn in how expressive each of these relations is.From a machine learning point of view of learn-ing, it is arguably easier to learn a model thathas to decide among fewer relations (i.e., that hasfewer classes).
But from a representational pointof view, it is better to predict relations that are asspecific as possible, for composing them may re-strict the prediction to more accurate descriptionsof the situation.
However, while specific relationspotentially trigger more inferences, they are alsomore likely to predict inconsistent constraints.
Inorder to evaluate these differences, we design a setof experiments on the Timebank/AQUAINT cor-pus, wherein we learn precise relations and vaguerones, and evaluate them with respect to each other(when a correspondence is possible).Section 2 briefly presents the Time-bank/AQUAINT corpus.
In section 3, wedescribe the task of temporal ordering through anexample, and discuss how it should be evaluated.Section 4 then goes into more detail about thedifferent representation possibilities for temporalrelations, and some of their formal properties.Section 5 presents our methods for building tem-poral structures, that combines relation classifierswith global constraints on whole documents.Finally, we discuss our experimental results insection 6.2 The Timebank/AQUAINT corpusLike (Mani et al, 2006) and (Chambers and Ju-rafsky, 2008), we use the so-called OTC corpus,a corpus of 259 documents obtained by com-bining the Timebank corpus (Pustejovsky et al,2003) (we use version 1.1 of the corpus) and theAQUAINT corpus.1 The Timebank corpus con-sists of 186 newswire articles (and around 65, 000words), while AQUAINT has 73 documents (andaround 40, 000 words).Both corpora are annotated using the TimeMLscheme for tagging eventualities (events andstates), dates/times, and their temporal relations.Eventualities can be denoted by verbs, nouns, andsome specific constructions.
The temporal rela-tions (i.e., the so-called TLINKS) encode topolog-ical information between the time intervals of oc-curring eventualities.
TimeML distinguishes threetypes of TLINKS: event-event, event-time, andtime-time, giving rise to different subtasks.
In thispaper, we will focus on predicting event-event re-lations (see (Filatova and Hovy, 2001; Boguraevand Ando, 2005) for work on the other tasks).
Theset of temporal relations used in TLINKS mirrorsthe 13 Allen relations (see next section), and in-cludes the following six relations: before, begins,ends, ibefore, includes, simultaneous and their in-verses.
The combined OTC corpus comprises atotal of 6, 139 annotated event-event TLINKS.
Wealso make use of the additional TLINKS indepen-dently provided by (Bethard et al, 2007) for 129of the 186 Timebank documents.3 Task presentation and evaluation3.1 An exampleWe illustrate the task of event ordering using asmall fabricated, simplified example:Fortis bank investede1 in junk bondsbefore the financial crisise2 , butgot ride3 of most of them duringthe crisise2bis .
However, the insti-tution still went bankrupte4 a yearlater.1Both corpora are freely available from http://www.timeml.org/site/timebank/timebank.html.251The annotation for this temporal structure wouldinclude the following relations: e1 is temporallybefore e2, e3 is temporally included in e2, and e3is before e4.
The coreference relation between e2and e2bis implies the equality of their temporal ex-tension.
Of course all these events may in theorybe related temporally to almost any other event inthe text.
Events are also anchored to temporal ex-pressions explicitly, and this is usually consideredas a separate, much easier task.
We will use thisexample throughout the rest of our presentation.3.2 Comparing temporal annotationsDue to possible inferences, there are often manyequivalent ways to express the same ordering ofevents, so comparisons between annotation andreference event-event pairs cannot rely on simpleprecision/recall measures.Consider the above example and assume thefollowing annotation: e1 is before e2, e3 is in-cluded in e2, and e3 is before e3.
Without goinginto too much detail about the semantics of the re-lations used, one expects annotators to agree withthe fact that it entails that e1 is before e3, amongother things.
So the annotation is equivalent to alarger set of relations.
In some cases, the inferredinformation is disjunctive (the relation holding be-tween two events is a subset of possible ?simple?relations, such as ?before or included?
).Nowadays, the given practice is to computesome sort of transitive closure over the network ofconstraints on temporal events (usually expressedin the well-studied Allen algebra (Allen, 1983)),and compute agreements over the saturated struc-tures.
Specifically, we can compare the sets ofsimple temporal relations that are deduced fromit (henceforth, the ?strict?
metric), or measure theagreement between the whole graphs, includingdisjunctions (Verhagen et al, 2007) (henceforth,the ?relaxed?
metric).2 Under this latter met-ric, precision (resp.
recall) of a prediction for apair of events consisting of a set S of relationswith respect to a set of relations R inferred fromthe reference, is computed as |S ?
R|/|S| (resp.|S ?R|/|R|).2Taking into account disjunctions means giving partialcredit to disjunctions approximating the reference relation(possibly disjunctive itself), see next section.e1e2e3e4bdibe1e2e3e4bbdi,fi,o,me1e2e3e4bdibbe1e2e3e4bbFigure 1: Two non-equivalent annotations of thesame situations (left) and their transitive closurein Allen?s algebra (right, with new relations only).b stands for Allen?s before relation, m for meet, ofor overlap, di and fi for the inverses of during andfinish, respectively.Figure 1 illustrates the point of these ?satu-rated?
representations, showing two raw annota-tions of our example on the left (top and bottom)and their closures on the right.
The raw annota-tions share only 2 relations (between e1 and e2,and e3 and e4), but their transitive closures agreealso on the relations between e1 and e3, e1 ande4, and e3 and e4.
They still differ on the rela-tion between e2 and e4, but only because one ismuch more specific than the other, something thatcan only be taken into account by a partial creditscoring function.For this example, the ?strict?
metric yields pre-cision and recall scores of 5/5 and 5/6, whencomparing the top annotation against the bottomone.
By contrast, the ?relaxed?
metric (introducedin the TempEval-07) yields precision and recallscores of (5+0.2)/6 and 6/6, respectively.We now turn to the issue of the set of relationschosen for the task of expressing temporal infor-mation in texts.4 Temporal representationsBecause of the inferential properties of temporalrelations, we have seen that the same situation canbe expressed in different ways, and some rela-tions can be deduced from others.
The need for252a precise reasoning framework has been presentin previous attempts at the task (Setzer et al,2006), and people have moved to a set of hand-made rules over ad hoc relations to more widelyaccepted temporal reasoning frameworks, such asalgebras of temporal relations, the most famousbeing Allen?s interval algebra.An algebra of relations can be defined on anyset of relations that are mutually exclusive (tworelations cannot hold at the same time betweentwo entities) and exhaustive (at least one relationmust hold between two given entities).
The alge-bra starts from a set of simple, atomic, relationsU = {r1, r2, ...}, and a general relation is a sub-set of U , interpreted as a disjunction of the rela-tions it contains.
From there, we can define unionand intersection of relations as classical set unionand intersection of the base relations they consistof.
Moreover, one can define a composition of re-lations as follows:(r1 ?
r2)(x, z)?
?y r1(x, y) ?
r2(y, z)In words, a relation between x and z can becomputed from what is known between (x andy) and (y and z).
By computing beforehand then?n compositions of base relations of U , we cancompute the composition of any two general rela-tions (because r ?
r?
=?
when r, r?
are basic andr 6= r?
):{r1, r2, ...rk} ?
{s1, s2, ...sm} =?i,j(ri ?
sj)Saturating the graph of temporal constraintsmeans applying these rules to all compatible pairsof constraints in the graph and iterating until afixpoint is reached.
In Allen?s algebra there are13 relations, determined by the different relationsthat can hold between two intervals endpoints (be-fore, equals, after).
These relations are: b (be-fore), m (meet), o (overlap), s (start), f (finish), d(during), their inverses (bi, mi, oi, si, fi, di) and =(equal), see figure 2.3It is important to see that a general approachto temporal ordering of events cannot restrict it-self to a subset of these and still use the power of3TimeML uses somewhat different names, with obviousmappings, except ibefore (?immediately before?)
for m, andiafter (?immediately after?)
for mi.XYXXXYYYfinishesbeforemeetsoverlapsXXYYequalsduringstartsXYFigure 2: Allen?s thirteen relations between twotemporal intervalsinferences to complete a situation, because com-position of information is stable only on restrictedsubsets.
And using all of them means generatingnumerous disjunctions of relations.Allen relations are convenient for reason-ing purposes, but might too precise for rep-resenting natural language expressions, andthat?s why recent evaluation campaigns such asTempEval-07 have settled on vaguer representa-tions.
TempEval-07 uses three relations called be-fore, overlaps and after, which we note bt, ot,and bit.4 These all correspond to disjunctionsof Allen relations: {b,m}a, {o,d,s,=,f}a and itsinverse, and {bi,mi}a, respectively.
These rep-resentations can be converted to Allen relations,over which the same inference procedures can beapplied, and then expressed back as (potentiallydisjunctive) TempEval relations.
They thus forma sub-algebra of Allen?s algebra, if we add theirpossible disjunctions.In fact, starting from the base relations, only{b,o}t, {bi,o}t, and vague (i.e., the disjunction ofall relations) can be inferred (besides the base re-lations).
This is a consequence of the stability ofso-called convex relations in Allen algebra.
Notethat an even simpler schema is used in (Chambersand Jurafsky, 2008), where only TempEval beforeand after and the vague relation are used.We propose to consider yet another set of rela-tion, namely relations from (Bruce, 1972).
Theseprovide an intermediate level of representation,since they include 7 simple relations.
These are4When it is not obvious, we will use subscript symbolsto indicate the particular algebra that is used (e.g., bt is thebefore relation in TempEval).253also expressible as disjunctions of Allen relations;they are: before (bb), after (bib) (with the samesemantics as TempEval?s bt and bit), equals (=b,same as =a), includes (i, same as Allen?s {s,d,f}a),overlaps (ob, same as oa), included (ii) and is-overlapped (oib), their inverse relations.
Theequivalences between the three algebras is showntable 1.Allen Bruce Tempevalbefore before beforemeetoverlaps overlapsoverlapsstartsincludedduringfinishesoverlapsi is-overlappedstartsiincludesduringifinishesimeeti after afterbeforeiequals equals equalsTable 1: Correspondances between temporal al-gebras.
A relation ranging over multiple cellsis equivalent to a disjunction of all the relationswithin these cells.Considering a vaguer set is arguably more ad-equate for natural language expressions while atthe same time this specific set preserves at leastthe notions of temporal order and inclusion (con-trary to the TempEval scheme), which have stronginferential properties: they are both transitive, andtheir composition yields simple relations; over-lap allows for much weaker inferences.
Figure 3shows part of our example from the introductionexpressed in the three cases: with Allen relations,the most precise, with Bruce relations and Tem-pEval relations, with dotted lines showing the ex-tent of the vagueness of the temporal situations ineach case (with respect to the most precise Allendescription).
We can see that TempEval relationslose quickly all information that is not before orafter, while Bruce preserves inference combiningprecedence and temporal inclusion.Information can be converted from one algebrato the other, since vaguer algebras are based on re-lations equivalent to disjunctions in Allen algebra.But conversion from a precise relation to a vaguerone and back to a more precise algebra leads toinformation loss.
Hence on figure 3, the originalAllen relation: e3 da e2 is converted to: e3 ot e2in TempEval, which converts back into the muchless informative: e3 {o,d, s,=, f,oi, si, fi,di}a e2.We will use these translations during our systemevaluation to have a common comparison pointbetween representations.5 Models5.1 Algebra-based classifiersIn order to compare the impact of the different al-gebras described in section 4, we build three eventpair classification models corresponding to eachrelation set.
The resulting Allen-based, Bruce-based, and Tempeval-based models therefore con-tain 13, 7, and 3 class labels, respectively.5 Forobvious sparsity issues, we did not include classescorresponding to disjunctive relations, as there are2|R| possible disjunctions for each relation set R.For training our models, we experiment with 4various configurations that correspond to ways ofexpanding the set of training examples.
Specifi-cally, these configurations vary in: (i) whether ornot we added the additional ?Bethard relations?
tothe initial OTC annotations (Bethard et al, 2007),(ii) whether or not we applied saturation over theset of annotated relations.5.2 FeaturesOur feature set for the various models is similarto that used by previous work, including binaryfeatures that encode event string as well as the fiveTimeML attributes and their possible values:?
aspect: none, prog, perfect, prog perfect?
class: report, aspectual, state, I-state I-action, perception, occurrence?
modality: none, to, should, would, couldcan, might?
polarity: positive, negative?
tense: none, present, past, future5Our TempEval model actually has a fourth label for theidentity relation.
The motivations behind the inclusion of thisextra label are: (i) this relation is linguistically motivated andcomparatively easy to learn (for a lot of instances of this rela-tion are cases of anaphora, which are often signaled by iden-tical strings) (ii) this relation triggers a lot of specific infer-ences.254e1Timee3e2(a) Allen:(e1bae2 ?
e3dae2) ?
e1bae3e1Timee3e2(b) Bruce:(e1bbe2 ?
e3dbe2) ?
e1bbe3e1Timee3e2(c) Tempeval:(e1bte2 ?
e3ote2) ?
e1{bt, ot}e3Figure 3: Comparing loss of inferential power in algebras: hard lines show the actual temporalmodel, exactly expressed in Allen relations (a); dotted lines show the vagueness induced by alterna-tive schemes, and the inference that can or cannot still be made in each algebra, (b) and (c).Additional binary features check agreement forsame attribute (e.g., the same tense).
Finally, weadd features that represent the distance betweentwo events (in number of sentences, and in num-ber of intervening events).
65.3 Training set generationOur generic training procedure works as follows.For each document, we scan events in their orderof appearance in the text.
We create a traininginstance inst(ei,ej) for each ordered pair of events(ei, ej): if (ei, ej) (resp.
(ej , ei)) corresponds toan annotated relation r, then we label inst(ei,ej)with the label r (resp.
its inverse r?1).5.4 Parameter estimationAll of these classifiers are maximum entropy mod-els (Berger et al, 1996).
Parameter estimationwas performed with the Limited Memory VariableMetric algorithm (Malouf, 2002) implemented inthe Megam package.75.5 DecodingWe consider two different decoding procedures.The first one simply mirrors the training proce-dure just described, scanning pairs of events in theorder of the text, and sending each pair to the clas-sifier.
The pair is then labeled with the label out-putted by the classifier (i.e., the label receiving the6These were also encoded as binary features, and the var-ious feature values were binned in order to avoid sparseness.7Available from http://www.cs.utah.edu/~hal/megam/.highest probability).
No attempt is made to guar-antee the consistency of the final temporal graph.Our second inference procedure works as fol-lows.
As in the previous method, we scan theevents in the order of the text, and create orderedpairs of events that we then submit to the classifier.But the difference is that we saturate the graph af-ter each classification decision to make sure thatthe graph created so far is coherent.
In case wherethe classifier predicts a relation whose addition re-sults in an incoherent graph, we try the next high-est probability relation, and so on, until we finda coherent graph.
This greedy procedure is simi-lar to the Natural Reading Order (NRO) inferenceprocedure described by (Bramsen et al, 2006).6 Experiments and resultsWe perform two main series of experiments forcomparing our different models.
In the first series,we measure the accuracy of the Allen-, Bruce-, and Tempeval-based models on predicting thecorrect relation for the event-event TLINKS an-notated in the corpus.
In the second series, wesaturate the event pair relations produced by theclassifiers (combined with NRO search to en-force global coherence) and compare the pre-dicted graphs against the saturated event-eventTLINKS.6.1 Experiment settingsAll our models are trained and tested with 5-foldcross-validation on the OTC documents.
For eval-255uation, we use simple accuracy for the first se-ries of experiments, and two ?strict?
and ?relaxed?precision/recall measures described in section 3for the other series.
For each type of measures,we report scores with respect to both Allen andTemEval relation sets.
All scores are reportedusing macro-averaging.
Out of the 259 tempo-ral graphs present in OTC, we found that 54 ofthem were actually inconsistent when saturated;the corresponding documents were therefore leftout of the evaluation.8 Given the rather expensiveprocedure involved in the NRO decoding (saturat-ing an inconsistent graph ?erases?
all relations),we skipped 8 documents wich were much longerthan the rest, leaving us with 197 documents forour final experiments.6.2 Event-event classificationTable 2 summarizes the accuracy scores of thedifferent classifiers on the event-event TLINKSof OTC.
We only report the best configurationfor each model.
For the TempEval-based model,we found that the best training setting was whenBethard annotations were added to the originalTimeML annotations, but with no saturation.9 ForAllen and Bruce models, neither Bethard?s re-lations nor saturation helps improve classifica-tion accuracy.
In fact, saturation degrades per-formance, which can be explained by the factthat saturation reinforces the bias towards alreadyover-represented relations.10 The best accuracyperformances are obtained by the Allen-based andTempEval-based classifiers, each one performingbetter in its own algebra (with 47.0% and 54.0%).This is not surprising, since these classifiers werespecifically trained to optimize their respectivemetrics.
The Bruce-based classifier is slightly bet-ter than the Allen-based one in TempEval, but alsoslightly worse than TempEval-based classifier inAllen.8Because there is no way to trace the relation(s) respon-sible for an inconsistency without analysing the whole set ofannotations of a text, and considering that it usually happenson very long texts, we did not attempt to manually correctthe annotations.9This is actually consistent with similar findings made by(Chambers and Jurafsky, 2008).10For instance, for Allen relations, there are roughly 50%of before-after relations before saturation but 73% of themafter saturation.Allen Acc.
TempEval Acc.Allen 47.0 48.9Bruce N/A 49.3TempEval N/A 54.0Table 2: Accuracy scores for Allen, Bruce, andTempEval classifiers on event-event TLINKS, ex-pressed in Allen or TempEval algebra.
Scores forBruce and TempEval models into Allen are leftout, since they predict (through conversion) dis-junctive relations for all relations but equality.Our accuracy scores for Allen, and TempEval-based classifiers are somewhat lower than the onesreported for similar systems by (Mani et al, 2006)and (Chambers and Jurafsky, 2008), respectively.These differences are likely to come from the factthat: (i) (Mani et al, 2006) perform a 6-way clas-sification, and not a 13-way classification11, and(ii) (Chambers and Jurafsky, 2008) use a relationset that is even more restrictive than TempEval?s.6.3 Saturated graphsTable 3 summarizes the various precision/recallscores of the graph obtained by saturating the clas-sifiers predictions (potentially altered by NRO)against the event-event saturated graph.
These re-sults contrast with the accuracy results presentedin table 2: while the TempEval-based model wasthe best model in classification accuracy in Tem-pEval, it is now outperformed by both the Allen-and Bruce-based systems (this with or with us-ing NRO).
The best system in TempEval is actu-ally Bruce-based system, with 52.9 and 62.8 forthe strict/relaxed metrics, respectively.
The re-sults suggest that this algebra might actually of-fer the best trade-off between learnanility and ex-pressive power.
The use of NRO to restore globalcoherence yields important gains (10 points) inthe relaxed metric for both Allen- and Bruce-based systems (although they do not convert intogains in the strict metric).
Unsuprisingly, thebest model on the Allen set remains Allen-basedmodel (and this time the use of NRO results ingains on the strict metric).
Predictions without11This is only possible because they order the event-eventpairs before submitting them to the classifier.256System Allen TempevalRELAX STRICT RELAX STRICTR P F1 R P F1 R P F1 R P F1Allen 57.5 46.7 51.5 49.6 56.2 52.7 62.0 50.3 55.5 50.4 57.1 53.6Bruce 46.0 39.0 42.1 18.0 44.0 25.9 62.9 52.6 57.3 50.9 57.0 53.8Tempeval 37.1 35.9 36.5 14.0 44.0 21.2 49.3 47.1 48.2 21.7 44.2 29.1AllenNRO 44.8 60.1 51.3 57.2 62.9 59.9 63.8 67.0 65.3 45.2 60.6 51.8BruceNRO 46.3 53.1 49.5 13.9 45.3 21.2 65.5 71.8 68.5 46.6 61.1 52.9TempevalNRO 37.1 35.9 36.5 13.9 44.3 21.2 49.3 47.1 48.2 21.7 44.2 29.1Table 3: Comparing Allen-, Bruce-, Tempeval-based classifiers saturated predictions on saturated event-event graph.
The NRO subscript indicates whether the system uses NRO or not.
Evaluation are givenwith respect to both Allen and Tempeval relation sets.NRO yielded between 7.5 and 9% of inconsistentsaturated graphs that were ignored by the evalua-tion, which means this impacted recall measuresonly.7 Related workEarly work on temporal ordering (Passonneau,1988; Webber, 1988; Lascarides and Asher, 1993)concentrated on studying the knowledge sourcesat play (such as tense, aspect, lexical semantics,rhetorical relations).
The development of anno-tated resources like the TimeBank corpus (Puste-jovsky et al, 2003) has triggered the developmentof machine learning systems (Mani et al, 2006;Tatu and Srikanth, 2008; Chambers and Jurafsky,2008).More recent work uses automatic classifica-tion methods, based on the TimeBank and Ac-quaint corpus, either as is, with inferential enrich-ment for training (Mani et al, 2006; Chamberset al, 2007), or supplied with the corrections of(Bethard et al, 2007), or are restricted to selectedcontexts, such as intra-sentential event relations(Li et al, 2004; Lapata and Lascarides, 2006).
Allof these assume that event pairs are preselected,so the task is only to determine what is the mostlikely relation between them.
The best scoresare obtained with the added assumption that theevent-event pair can be pre-ordered (thus reduc-ing the number of possible labels by 2).More recently, (Bramsen et al, 2006) and sub-sequently (Chambers and Jurafsky, 2008) pro-pose to use an Integer Linear Programming solverto enforce the consistency of a network of con-straints while maximizing the score of local clas-sification decisions.
But these are restricted to therelations BEFORE and AFTER, which have verystrong inference properties that cannot be gener-alised to other relations.
The ILP strategy is notlikely to scale up very well for richer relation sets,for the number of possible relations between twoevents (and thus the number of variables to put inthe LP solver for each pair) is the order of 2|R|(where R is the relation set), and each transitiv-ity constraints generates an enormous amount ofconstraints.8 ConclusionWe have investigated the role played by ontolog-ical choices in temporal representations by com-paring three algebras with different granularitiesof relations and inferential powers.
Our experi-ments on the Timebank/AQUAINT reveal that theTempEval relation set provides the best overallclassification accuracy, but it provides much lessinformative temporal structures, and it does notprovide enough inferences for being useful for en-forcing consistency.
By contrast, the other tworelation sets are significantly harder to learn, butprovide more richer inferences and are thereforemore useful when global consistency is important.Bruce?s 7 relations-based model appears to per-form best in the TempEval evaluation, suggestingthat this algebra provides the best trade-off be-tween learnability and expressive power.257ReferencesAllen, James.
1983.
Maintaining Knowledge aboutTemporal Intervals.
Communications of the ACM,pages 832?843.Berger, A., S. Della Pietra, and V. Della Pietra.
1996.A maximum entropy approach to natural languageprocessing.
Computational Linguistics, 22(1):39?71.Bethard, Steven, James H. Martin, and Sara Klingen-stein.
2007.
Timelines from text: Identification ofsyntactic temporal relations.
In International Con-ference on Semantic Computing, pages 11?18, LosAlamitos, CA, USA.
IEEE Computer Society.Boguraev, Branimir and Rie Ando.
2005.
TimeML-compliant text analysis for temporal reasoning.
InKaelbling, Leslie Pack and Fausto Giunchiglia, edi-tors, Proceedings of IJCAI05, pages 997?1003.Bramsen, Philip, Pawan Deshpande, Yoong Keok Lee,and Regina Barzilay.
2006.
Inducing temporalgraphs.
In Proceedings of the 2006 Conference onEmpirical Methods in Natural Language Process-ing, pages 189?198, Sydney, Australia, July.
Asso-ciation for Computational Linguistics.Bruce, B.
1972.
A model for temporal references andits application in a question answering program.
Ar-tificial Intelligence, 3(1-3):1?25.Chambers, Nathanael and Daniel Jurafsky.
2008.Jointly combining implicit constraints improvestemporal ordering.
In Proceedings of the 2008 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 698?706, Honolulu, Hawaii, Oc-tober.
Association for Computational Linguistics.Chambers, Nathanael, Shan Wang, and Daniel Juraf-sky.
2007.
Classifying temporal relations betweenevents.
In ACL.
The Association for Computer Lin-guistics.Filatova, Elena and Eduard Hovy.
2001.
Assigningtime-stamps to event-clauses.
In Mani, I., J. Puste-jovsky, and R Gaizauskas, editors, The Language ofTime: A Reader.
Oxford University Press.Lapata, Maria and Alex Lascarides.
2006.
Learningsentence-internal temporal relations.
J. Artif.
Intell.Res.
(JAIR), 27:85?117.Lascarides, Alex and Nicholas Asher.
1993.
Tem-poral interpretation, discourse relations and com-mon sense entailment.
Linguistics and Philosophy,16:437?493.Li, Wenjie, Kam-Fai Wong, Guihong Cao, and ChunfaYuan.
2004.
Applying machine learning to chi-nese temporal relation resolution.
In Proceedingsof the 42nd Meeting of the Association for Compu-tational Linguistics (ACL?04), Main Volume, pages582?588, Barcelona, Spain, July.Malouf, Robert.
2002.
A comparison of algorithmsfor maximum entropy parameter estimation.
In Pro-ceedings of the Sixth Workshop on Natural Lan-guage Learning, pages 49?55, Taipei, Taiwan.Mani, Inderjeet, Marc Verhagen, Ben Wellner,Chong Min Lee, and James Pustejovsky.
2006.
Ma-chine learning of temporal relations.
In Proceedingsof the 21st International Conference on Computa-tional Linguistics and 44th Annual Meeting of theAssociation for Computational Linguistics, pages753?760, Sydney, Australia, July.
Association forComputational Linguistics.Passonneau, Rebecca J.
1988.
A computational modelof the semantics of tense and aspect.
ComputationalLinguistics, 14(2):44?60.Pustejovsky, James, Patrick Hanks, Roser Saur?,Andrew See, Robert Gaizauskas, Andrea Setzer,Dragomir Radev, Beth Sundheim, David Day, LisaFerro, and Marcia Lazo.
2003.
The TIMEBANKCorpus.
In Proceedings of Corpus Linguistics,pages 647?656, Lancaster University, UK, March.Setzer, Andrea, Robert Gaizauskas, and Mark Hepple.2006.
The Role of Inference in the Temporal An-notation and Analysis of Text.
Language Resourcesand Evaluation, 39:243?265.Tatu, Marta and Munirathnam Srikanth.
2008.
Ex-periments with reasoning for temporal relations be-tween events.
In Proceedings of the 22nd Inter-national Conference on Computational Linguistics(Coling 2008), pages 857?864, Manchester, UK,August.
Coling 2008 Organizing Committee.Verhagen, Marc, Robert Gaizauskas, Franck Schilder,Mark Hepple, Graham Katz, and James Puste-jovsky.
2007.
SemEval-2007 - 15: TempEval Tem-poral Relation Identification.
In Proceedings of Se-mEval workshop at ACL 2007, Prague, Czech Re-public, June.
Association for Computational Lin-guistics, Morristown, NJ, USA.Webber, Bonnie Lynn.
1988.
Tense as discourseanaphor.
Computational Linguistics, 14(2):61?73.258
