Proceedings of EACL '99New Models for Improving Supertag DisambiguationJohn Chen*Department ofComputerand Information SciencesUniversity of DelawareNewark, DE 19716jchen@cis.udel.eduSrinivas BangaloreAT&T Labs Research180 Park AvenueP.O.
Box 971Florham Park, NJ 07932srini@research.att.comK.
Vijay-ShankerDepartment ofComputerand Information SciencesUniversity of DelawareNewark, DE 19716vijay~cis.udel.eduAbstractIn previous work, supertag disambigua-tion has been presented as a robust, par-tial parsing technique.
In this paperwe present wo approaches: contextualmodels, which exploit a variety of fea-tures in order to improve supertag per-formance, and class-based models, whichassign sets of supertags to words in orderto substantially improve accuracy withonly a slight increase in ambiguity.1 IntroductionMany natural language applications are beginningto exploit some underlying structure of the lan-guage.
Roukos (1996) and Jurafsky et al (1995)use structure-based language models in thecontext of speech applications.
Grishman (1995)and Hobbs et al (1995) use phrasal informationin information extraction.
Alshawi (1996) usesdependency information in a machine translationsystem.
The need to impose structure leads tothe need to have robust parsers.
There havebeen two main robust parsing paradigms: Fi-nite State Grammar-based approaches (suchas Abney (1990), Grishman (1995), andHobbs et al (1997)) and Statistical Parsing(such as Charniak (1996), Magerman (1995), andCollins (1996)).Srinivas (1997a) has presented a different ap-proach called supertagging that integrates linguis-tically motivated lexical descriptions with the ro-bustness of statistical techniques.
The idea un-derlying the approach is that the computationof linguistic structure can be localized if lexicalitems are associated with rich descriptions (Su-pertags) that impose complex constraints in a lo-cal context.
Supertag disambiguation is resolved"Supported by NSF grants ~SBR-9710411 and~GER-9354869by using statistical distributions of supertag co-occurrences collected from a corpus of parses.
Itresults in a representation that is effectively aparse (almost parse).Supertagging has been found useful for a num-ber of applications.
For instance, it can beused to speed up conventional chart parsers be-cause it reduces the ambiguity which a parsermust face, as described in Srinivas (1997a).Chandrasekhar nd Srinivas (1997) has shownthat supertagging may be employed in informa-tion retrieval.
Furthermore, given a sentencealigned parallel corpus of two languages and al-most parse information for the sentences of oneof the languages, one can rapidly develop a gram-mar for the other language using supertagging, assuggested by Bangalore (1998).In contrast o the aforementioned work in su-pertag disambiguation, where the objective wasto provide a-direct comparison between trigrammodels for part-of-speech tagging and supertag-ging, in this paper our goal is to improve the per-formance of supertagging using local techniqueswhich avoid full parsing.
These supertag disam-biguation models can be grouped into contextualmodels and class based models.
Contextual mod-els use different features in frameworks that ex-ploit the information those features provide inorder to achieve higher accuracies in supertag-ging.
For class based models, supertags are firstgrouped into clusters and words are tagged withclusters of supertags.
We develop several auto-mated clustering techniques.
We then demon-strate that with a slight increase in supertag ambi-guity that supertagging accuracy can be substan-tially improved.The layout of the paper is as follows.
In Sec-tion 2, we briefly review the task of supertaggingand the results from previous work.
In Section 3,we explore contextual models.
In Section 4, weoutline various class based approaches.
Ideas forfuture work are presented in Section 5.
Lastly, we188vProceedings of EACL '99present our conclusions in Section 6.2 Super tagg ingSupertags, the primary elements of the LTAGformalism, attempt o localize dependencies, in-cluding long distance dependencies.
This is ac-complished by grouping syntactically or semanti-cally dependent elements to be within the samestructure.
Thus, as seen in Figure 1, supertagscontain more information than standard part-of-speech tags, and there are many more supertagsper word than part-of-speech tags.
In fact, su-pertag disambiguation may be characterized asproviding an almost parse, as shown in the bottompart of Figure 1.Local statistical information, in the form of atrigram model based on the distribution of su-pertags in an LTAG parsed corpus, can be usedto choose the most appropriate supertag for anygiven word.
Joshi and Srinivas (1994) define su-pertagging as the process of assigning the bestsupertag to each word.
Srinivas (1997b) andSrinivas (1997a) have tested the performance of atrigram model, typically used for part-of-speechtagging on supertagging, on restricted domainssuch as ATIS and less restricted omains uch asWall Street Journal (WSJ).In this work, we explore a variety of localtechniques in order to improve the performanceof supertagging.
All of the models presentedhere perform smoothing using a Good-Turing dis-counting technique with Katz's backoff model.With exceptions where noted, our models weretrained on one million words of Wall Street Jour-nal data and tested on 48K words.
The dataand evaluation procedure are similar to that usedin Srinivas (1997b).
The data was derived bymapping structural information from the PennTreebank WSJ corpus into supertags from theXTAG grammar (The XTAG-Group (1995)) us-ing heuristics (Srinivas (1997a)).
Using this data,the trigram model for supertagging achieves anaccuracy of 91.37%, meaning that 91.37% of thewords in the test corpus were assigned the correctsupertag.13 Contextua l  Mode lsAs noted in Srinivas (1997b), a trigram model of-ten fails to capture the cooccurrence d pendencies1The supertagging accuracy of 92.2% reportedin Srinivas (1997b) was based on a different supertagtagset; specifically, the supertag corpus was reanno-tated with detailed supertags for punctuation andwith a different analysis for subordinating conjunc-tions.between a head and its dependents--dependentswhich might not appear within a trigram's windowsize.
For example, in the sentence "Many Indians\]eared their country might split again" the pres-ence of might influences the choice of the supertagfor \]eared, an influence that is not accounted for bythe trigram model.
As described below, we showthat the introduction of features which take intoaccount aspects of head-dependency relationshipsimproves the accuracy of supertagging.3.1 One Pass Head Tr ig ram Mode lIn a head model, the prediction of the current su-pertag is conditioned not on the immediately pre-ceding two supertags, but on the supertags for thetwo previous head words.
This model may thusbe considered to be using a context of variablelength.
2 The sentence "Many Indians feared theircountry might split again" shows a head model'sstrengths over the trigram model.
There are atleast two frequently assigned supertags for theword \]eared: a more frequent one correspondingto a subcategorization f NP object (as ~n ofFigure 1) and a less frequent one to a S comple-ment.
The supertag for the word might, highlyprobable to be modeled as an auxiliary verb inthis case, provides trong evidence for the latter.Notice that might and \]eared appear within a headmodel's two head window, but not within the tri-gram model's two word window.
We may there-fore expect hat a head model would make a moreaccurate prediction.Srinivas (1997b) presents a two pass head tri-gram model.
In the first pass, it tags words aseither head words or non-head words.
Trainingdata for this pass is obtained using a head percola-tion table (Magerman (1995)) on bracketed PennTreebank sentences.
After training, head taggingis performed according to Equation 1, where 15 isthe estimated probability and H(i) is a charac-teristic function which is true iff word i is a headword.nH ~ argmaxH H~(wilH(i))~(H(i) lH(i-1)H(i-2))i=1(1)The second pass then takes the words with thishead information and supertags them accordingto Equation 2, where tH(io) is the supertag of theePart of speech tagging models have not used headsin this manner to achieve variable length contexts.Variable length n-gram models, one of which is de-scribed in Niesler and Woodland (1996), have beenused instead.189Proceedings of EACL '99NP ANP* S ANP VPV NPJ JNP ND NP* N N*I Ithe pa~lmsehS S A ANP SNP NP VP V AP NPN ~ T NP ~ iA Nprice includes E ancillary companiesou 2 0 3 o~ 4 cc 5S SNP S NP SNP VP ~ NP VP~ V NP NP VP NP NN ~ V NP D NP* A N* E NI I ine/deslu I I price two ancillary companies?t6 c~7 h 134 cc8SNP SS NT VP / ,~NP N ~ VP ~ v Ap NP VPN N N* V NP ~ A V NPI I I / Ipurcha~ price includes ancil lary companies?
a9 1310 all  a12 ct13i i i "sNP N NP NP VP NP N NPD NP* N N* N V NP D NP* A N ~ NI I I I I I Ithe purchase price includes two anci l lary companiesh h c?2 C~ll ~3 ~4 a5the purchase price includes two ancillary companiesFigure 1: A selection of the supertags associated with each word of the sentence: the purchase priceincludes two ancillary companiesj th  head from word i.nT ,~ argmaxT l l  g(wilti)~(tiItH(i,_HtH(i--2))i= l(2)This model achieves an accuracy of 87%, lowerthan the trigram model's accuracy.Our current approach differs significantly.
In-stead of having heads be defined through the useof the head percolation table on the Penn Tree-bank, we define headedness in terms of the su-pertags themselves.
The set of supertags can nat-urally be partitioned into head and non-head su-pertags.
Head supertags correspond to those thatrepresent a predicate and its arguments, such asa3 and a7.
Conversely, non-head supertags corre-spond to those supertags that represent modifiersor adjuncts, such as ~1 and ~2.Now, the tree that is assigned to a word duringsupertagging determines whether or not it is tobe a head word.
Thus, a simple adaptation of theViterbi algorithm suffices to compute Equation 2in a single pass, yielding a one pass head trigrammodel.
Using the same training and test data, theone pass head model achieved 90.75% accuracy,constituting a 28.8% reduction in error over thetwo pass head trigram model.
This improvementmay come from a reduction in error propagationor the richer context hat is being used to predictheads.3.2 Mixed Head and Trigram ModelsThe head mod.el skips words that it does not con-sider to be head words and hence may lose valu-able information.
The lack of immediate local con-text hurts the head model in many cases, such asselection between head noun and noun modifier,and is a reason for its lower performance relativeto the trigram model.
Consider the phrase " .
.
.
,or $ 2.48 a share."
The word 2.48 may either beassociated with a determiner phrase supertag (~1)or a noun phrase supertag (ag).
Notice that 2.48is immediately preceded by $ which is extremelylikely to be supertagged as a determiner phrase031).
This is strong evidence that 2.48 should besupertagged as a9.
A pure head model cannotconsider this particular fact, however, because 131is not a head supertag.
Thus, local context andlong distance head dependency relationships areboth important for accurate supertagging.A 5-gram mixed model that includes both thetrigram and the head trigram context is one ap-proach to this problem.
This model achieves aperformance of 91.50%, an improvement over both190Proceedings of EACL '99Previous Current NextContext Supertag ContexttH(i _2) tH(i _~)tH(i,_2) tH(i _~)tH(i,_2) tH(i,_~)tH(i _~) tLM(~ _~)tH(i,_l) tLM(i _l)tH(i.-l} tLM(i,-1)tH(i,o)tLM(~,o)tRM(I,o)tH(i,o)tLM(i,o)tRMii.o)tH(i, - * ) tH(i,o)tH(i _,)  tLM(i,o)tH(i _2) tH(i _1)tH(i,_,) tH(i,o)tH(.
,_ t) tLM(I,o)tH(i ._ ~ ~ tRM(i,o)Table 1: In the 3-gram mixed model, previous con-ditioning context and the current supertag deter-ministically establish the next conditioning con-text.
H, LM,  and RM denote the entities head,left modifier, and right modifier, respectively.the trigram model and the head trigram model.We hypothesize that the improvement is limitedbecause of a large increase in the number of pa-rameters to be estimated.As an alternative, we explore a 3-gram mixedmodel that incorporates nearly all of the relevantinformation.
This mixed model may be describedas follows.
Recall that we partition the set ofall supertags into heads and modifiers.
Modifiershave been defined so as to share the characteristicthat each one either modifies exactly one item tothe right or one item to the left .
Consequently,we further divide modifiers into left modifiers (134)and right modifiers.
Now, instead of fixing theconditioning context o be either the two previoustags (as in the trigram model) or the two pre-vious head tags (as in the head trigram model)we allow it to vary according to the identity ofthe current ag and the previous conditioning con-text, as shown in Table 1.
Intuitively, the mixedmodel is like the trigram model except hat a mod-ifier tag is discarded from the conditioning contextwhen it has found an object of modification.
Themixed model achieves an accuracy of 91.79%, asignificant improvement over both the head tri-gram model's and the trigram model's accuracies,p < 0.05.
Furthermore, this mixed model is com-putationally more efficient as well as more accu-rate than the 5-gram model.3.3 Head Word  Mode lsRather than head supertags, head words oftenseem to be more predictive of dependency rela-tions.
Based upon this reflection, we have imple-mented models where head words have been usedas features.
The head word model predicts the cur-rent supertag based on two previous head words(backing off to their supertags) as shown in Equa-Model ContextTrigram ti- 1 ti-2HeadTrigram5-gramMix3-gramMixHeadWordMixWordtH(i,-1)tH(i,-2)t i - l t i -2tH(i,--1)tH(i,-2)tcntzt(i,-1)tcntzt(i,-2)W(i,--1)W(i,-2)ti- 1 ti-2WH(i,-1)WH(i,-2)Accuracy91.3790.7591.5091.7988.1689.46Table 2: Single classifier contextual models thathave been explored along with the contexts theyconsider and their accuraciestion 3.T ~ argmaxT rXP(wilti)p(ti\]WH(i,_l)WH(i,_2))i=l(3)The mixed trigram and head word model takes intoaccount local (supertag) context and long distance(head word) context.
Both of these models ap-pear to suffer from severe sparse data problems.It is not surprising, then, that the head wordmodel achieves an accuracy of only 88.16%, andthe mixed trigram and head word model achievesan accuracy of 89.46%.
We were only able totrain the latter model with 250K of training databecause of memory problems that were causedby computing the large parameter space of thatmodel.The salient characteristics of models that havebeen discussed in this subsection are summarizedin Table 2.3.4 Classif ier Combinat ionWhile the features that our new models have con-sidered are useful, an n-gram model that considersall of them would run into severe sparse data prob-lems.
This difficulty may be surmounted throughthe use of more elaborate backoff techniques.
Onthe other hand, we could consider using decisiontrees at choice points in order to decide which fea-tures are most relevant at each point.
However, wehave currently experimented with classifier combi-nation as a means of ameliorating the sparse dataproblem while making use of the feature combina-tions that we have introduced.In this approach, a selection of the discussedmodels is treated as a different classifier and istrained on the same data.
Subsequently, each clas-sifter supertags the test corpus separately.
Finally,191Proceedings of EACL '99Trigram Head Trigram Head Word 3-gram Mix Mix WordTrigram 91.37 91.87" 91.65 91.96 91.55Head TrigramHead Word3-gram MixMix Word90.75 90.9688.1691.9591.8891.7991.35"90.51"91.8789.46Table 3: Accuracies of Single Classifiers and Pairwise Combination of Classifiers.their predictions are combined using various vot-ing strategies.The same 1000K word test corpus is used inmodels of classifier combination as is used in pre-vious models.
We created three distinct partitionsof this 1000K word corpus, each partition consist-ing of a 900K word training corpus and a 100Kword tune corpus.
In this manner, we ended upwith a total of 300K word tuning data.We consider three voting strategies uggestedby van Halteren et al (1998): equal vote, whereeach classifier's vote is weighted equally, overallaccuracy, where the weight depends on the over-all accuracy of a classifier, and pair'wise voting.Pairwise voting works as follows.
First, for eachpair of classifiers a and b, the empirical prob-ability ~(tcorrectltctassilier_atclassiyier_b) is com-puted from tuning data, where tclassiyier-a andtct~ssiy~e~-b are classifier a's and classifier b's su-pertag assignment for a particular word respec-tively, and t .
.
.
.
ect is the correct supertag.
Sub-sequently, on the test data, each classifier pairvotes, weighted by overall accuracy, for the su-pertag with the highest empirical probability asdetermined in the previous tep, given each indi-vidual classifier's guess.The results from these voting strategies are pos-itive.
Equal vote yields an accuracy of 91.89%.Overall accuracy vote has an accuracy of 91:93%.Pairwise voting yields an accuracy of 92.19%,the highest supertagging accuracy that has beenachieved, a 9.5% reduction in error over the tri-gram model.The table of accuracy of combinations of pairsof classifiers is shown in Table 3.
3 The effi-cacy of pairwise combination (which has signifi-cantly fewer parameters toestimate) in ameliorat-ing the sparse data problem can be seen clearly.For example, the accuracy of pairwise combina-tion of head classifier and trigram classifier ex-ceeds that of the 5-gram mixed model.
It is also3Entries marked with an asterisk ("*") correspondto cases where the pairwise combination of classifierswas significantly better than either of their componentclassifiers, p < 0.05.marginally, but not significantly, higher than the3-gram mixed model.
It is also notable that thepairwise combination of the head word classifierand the mix word classifier yields a significant im-provement over either classifier, p < 0.05, consid-ering the disparity between the accuracies of itscomponent classifiers.3.5 Further EvaluationWe also compare various models' performanceon base-NP detection and PP attachment disam-biguation.
The results will underscore the adroit-ness of the classifier combination model in usingboth local and long distance features.
They willalso show that, depending on the ultimate appli-cation, one model may be more appropriate thananother model.A base-NP is a non-recursive NP structurewhose detection is useful in many applications,such as information extraction.
We extend our su-pertagging models to perform this task in a fash-ion similar to that described in Srinivas (1997b).Selected models have been trained on 200K words.Subsequently, after a model has supertagged thetest corpus, a procedure detects base-NPs by scan-ning for appropriate sequences of supertags.
Re-sults for base-NP detection are shown in Table 4.Note that the mixed model performs nearly as wellas the trigram model.
Note also that the headtrigram model is outperformed by the other mod-els.
We suspect hat unlike the trigram model, thehead model does not perform the accurate mod-eling of local context which is important for base-NP detection.In contrast, information about long distance de-pendencies are more important for the the PP at-tachment ask.
In this task, a model must de-cide whether a PP attaches at the NP or the VPlevel.
This corresponds to a choice between twoPP supertags: one associated with NP attach-ment, and another associated with VP attach-ment.
The trigram model, head trigram model,3-gram mixed model, and classifier combinationmodel perform at accuracies of 78.53%, 79.56%,80.16%, and 82.10%, respectively, on the PP at-192Proceedings of EACL '99Trigram3-gram MixHead TrigramClassifier CombinationRecall Precision93.75 93.0093.65 92.6391.17 89.7294.00 93.17Table 4: Some contextual models' results on base-NP chunkingtachment ask.
As may be expected, the trigrammodel performs the worst on this task, presum-ably because it is restricted to considering purelylocal information.4 Class Based Mode lsContextual models tag each word with the sin-gle most appropriate supertag.
In many applica-tions, however, it is sufficient o reduce ambiguityto a small number of supertags per word.
Forexample, using traditional TAG parsing methods,such are described in Schabes (1990), it is ineffi-cient to parse with a large LTAG grammar for En-glish such as XTAG (The XTAG-Group (1995)).In these circumstances, a single word may be as-sociated with hundreds of supertags.
Reducingambiguity to some small number k, say k < 5 su-pertags per word 4 would accelerate parsing con-siderably.
5 As an alternative, once such a reduc-tion in ambiguity has been achieved, partial pars-ing or other techniques could be employed to iden-tify the best single supertag.
These are the aimsof class based models, which assign a small set ofsupertags to each word.
It is related to work byBrown et al (1992) where mutual information isused to cluster words into classes for languagemodeling.
In our work with class based models,we have considered only trigram based approachesso far.4.1 Context  Class Mode lOne reason why the trigram model of supertag-ging is limited in its accuracy is because it con-siders only a small contextual window aroundthe word to be supertagged when making itstagging decision.
Instead of using this limitedcontext to pinpoint the exact supertag, we pos-tulate that it may be used to predict certain4For example, the n-best model, described below,achieves 98.4% accuracy with on average 4.8 supertagsper word.5An alternate approach to TAG parsing that ef-fectively shares the computation associated with eachlexicalized elementary tree (supertag) is described inEvans and Weir (1998).
It would be worth comparingboth approaches.structural characteristics of the correct supertagwith much higher accuracy.
In the context classmodel, supertags that share the same character-istics are grouped into classes and these classes,rather than individual supertags, are predictedby a trigram model.
This is reminiscent ofSamuelsson and Reich (1999) where some part ofspeech tags have been compounded so that eachword is deterministically in one class.The grouping procedure may be described asfollows.
Recall that each supertag corresponds toa lexicalized tree t E G, where G is a particu-lar LTAG.
Using standard FIRST and FOLLOWtechniques, we may associate t with FOLLOWand PRECEDE sets, FOLLOW(t) being the setof supertags that can immediately follow t andPRECEDE(t)  being those supertags that can im-mediately precede t. For example, an NP tree suchas 81 would be in the FOLLOW set of a supertagof a verb that subcategorizes for an NP comple-ment.
We partition the set of all supertags intoclasses uch that all of the supertags in a particu-lar class are associated with lexicalized trees withthe same PRECEDE and FOLLOW sets.
For in-stance, the supertags tx and t2 corresponding re-spectively to the NP and S subcategorizations ofa verb \]eared would be associated with the sameclass.
(Note that a head NP tree would be a mem-ber of both FOLLOW(t1) and FOLLOW(t2).
)The context class model predicts sets of su-pertags for words as follows.
First, the trigrammodel supertags each word wi with supertag tithat belongs to class Ci.6 Furthermore, using thetraining corpus, we obtain set D~ which containsall supertags t such that ~(wilt) > 0.
The wordwi is relabeled with the set of supertags C~ N Di.The context class model trades off an increasedambiguity of 1.65 supertags per word on average,for a higher 92.51% accuracy.
For the purpose ofcomparison, we may compare this model againsta baseline model that partitions the set of all su-pertags into classes o that all of the supertags inone class share the same preterminal symbol, i.e.,they are anchored by words which share the samepart of speech.
With classes defined in this man-ner, call C~ the set of supertags that belong tothe class which is associated with word w~ in thetest corpus.
We may then associate with word w~the set of supertags C~ gl Di, where Di is definedas above.
This baseline procedure yields an aver-6For class models, we have also exper-imented with a variant Where the classesare assigned to words through the modelc ~ aTgmaxcl-I~=,~(w, IC~)~(C, IC~_lC,_2).
Ingeneral, we have found this procedure to give slightlyworse results.193Proceedings of EACL '99age ambiguity of 5.64 supertags per word with anaccuracy of 97.96%.4.2 Confusion Class ModelThe confusion class model partitions supertagsinto classes according to an alternate procedure.Here, classes are derived from a confusion matrixanalysis of errors which the trigram model makeswhile supertagging.
First, the trigram model su-pertags a tune set.
A confusion matrix is con-structed, recording the number of times supertagt~ was confused for supertag tj, or vice versa,in the tune set.
Based on the top k pairs ofsupertags that are most confused, we constructclasses of supertags that are confused with oneanother.
For example, let tl and t2 be two PPsupertags which modify an NP and VP respec-tively.
The most common kind of mistake thatthe trigram model made on the tune data was tomistag tl as t2, and vice versa.
Hence, tl and t2are clustered by our method into the same con-fusion class.
The second most common mistakewas to confuse supertags that represent verb mod-ifier PPs and those that represent verb argumentPPs, while the third most common mistake was toconfuse supertags that represent head nouns andnoun modifiers.
These, too, would form their ownclasses.The confusion class model predicts sets of su-pertags for words in a manner similar to the con-text class model.
Unlike the context class model,however, in this model we have to choose k, thenumber of pairs of supertags which are extractedfrom the confusion matrix over which confusionclasses are formed.
In our experiments, we havefound that with k = 10, k = 20, and k = 40,the resulting models attain 94.61% accuracy and1.86 tags per word, 95.76% accurate and 2.23 tagsper word, and 97.03% accurate and 3.38 tags perword, respectively/Results of these, as well as other models dis-cussed below, are plotted in Figure 2.
The n-bestmodel is a modification of the trigram model inwhich the n most probable supertags per word arechosen.
The classifier union result is obtained byassigning a word wi a set of supertags til,.+.
,tikwhere to tij is the j th classifier's upertag assign-ment for word wl, the classifiers being the modelsdiscussed in Section 3.
It achieves an accuracy of95.21% with 1.26 supertags per word.<980"99 0"96.0 "950 "94.0 "93.0"920"910"J /SI "P 3Ambigui ty  (Tags Per Word)0 ContextCMssConfusionClassClassffmrUnion-~(" N-BestFigure 2: Ambiguity versus Accuracy for VariousClass Models5 Future  WorkWe are considering extending our work in sev-eral directions.
Srinivas (1997b) discussed alightweight dependency analyzer which assigns de-pendencies assuming that each word has been as-signed a unique supertag.
We are extending thisalgorithm to work with class based models whichnarrows down the number of supertags per wordwith much higher accuracy.
Aside from the n-gram modeling that was a focus of this paper,we would also like to explore using other kindsof models, such as maximum entropy.6 Conc lus ionsWe have introduced two different kinds of modelsfor the task of supertagging.
Contextual mod-els show that features for accurate supertaggingonly produce improvements when they are appro-priately combined.
Among these models were: aone pass head model that reduces propagation ofhead detection errors of previous models by usingsupertags themselves to identify heads; a mixedmodel that combines use of local and long distanceinformation; and a classifier combination modelthat ameliorates the sparse data problem that isworsened by the introduction of many new fea-tures.
These models achieve better supertaggingaccuracies than previously obtained.
We have alsointroduced class based models which trade a slightincrease in ambiguity for significantly higher accu-racy.
Different class based methods are discussed,and the tradeoff between accuracy and ambiguityis demonstrated.7Again, for the class C assign to a given word w~,we consider only those tags ti E C for which/5(wdti) >0.Re ferencesSteven Abney.
1990.
Rapid Incremental parsing194Proceedings of EACL '99with repair.
In Proceedings of the 6th New OEDConference: Electronic Text Research, pages 1-9, University of Waterloo, Waterloo, Canada.Hiyan Alshawi.
1996.
Head automata nd bilin-gual tiling: translation with minimal represen-tations.
In Proceedings of the 34th AnnualMeeting Association for Computational Lin-guistics, Santa Cruz, California.Srinivas Bangalore.
1998.
Transplanting Su-pertags from English to Spanish.
In Proceedingsof the TAG+4 Workshop, Philadelphia, USA.Peter F. Brown, Vincent J. Della Pietra, Peter V.deSouza, Jennifer Lai, and Robert L. Mercer.1992.
Class-based n-gram models of naturallanguage Computational Linguistics, 18.4:467-479.R.
Chandrasekhar nd B. Srinivas.
1997.
Usingsupertags in document filtering: the effect ofincreased context on information retrieval InProceedings of Recent Advances in NLP '97.Eugene Charniak.
1996.
Tree-bank Grammars.Technical Report CS-96-02, Brown University,Providence, RI.Michael Collins.
1996.
A New Statistical ParserBased on Bigram Lexical Dependencies.
In Pro-ceedings of the 3~ th Annual Meeting of the As-sociation for Computational Linguistics, SantaCruz.Roger Evans and David Weir.
1998.
A Structure-sharing Parser for Lexicalized Grammars.
InProceedings of the 17 eh International Confer-ence on Computational Linguistics and the 36 thAnnual Meeting of the Association for Compu-tational Linguistics, Montreal.Ralph Grishman.
1995.
Where's the Syntax?The New York University MUC-6 System.
InProceedings of the Sixth Message Understand-ing Conference, Columbia, Maryland.H.
van Halteren, J. Zavrel, and W. Daelmans.1998.
Improving Data Driven Wordctass Tag-ging by System Combination.
In Proceedings ofCOLING-ACL 98, Montreal.Jerry R. Hobbs, Douglas E. Appelt, JohnBear, David Israel, Andy Kehler, Megumi Ka-mayama, David Martin, Karen Myers, andMarby Tyson.
1995.
SRI International FAS-TUS system MUC-6 test results and analy-sis.
In Proceedings of the Sixth Message Un-derstanding Conference, Columbia, Maryland.Jerry R. Hobbs, Douglas Appelt, John Bear,David Israel, Megumi Kameyama, Mark Stickel,and Mabry Tyson.
1997.
FASTUS: A Cas-caded Finite-State Transducer for ExtractingInformation from Natural-Language Text.
InE.
Roche and Schabes Y., editors, Finite StateDevices for Natural Language Processing.
MITPress, Cambridge, Massachusetts.Aravind K. Joshi and B. Srinivas.
1994.
Dis-ambiguation of Super Parts of Speech (or Su-pertags): Almost Parsing.
In Proceedings ofthe 17 th International Conference on Com-putational Linguistics (COLING '9~), Kyoto,Japan, August.D.
Jurafsky, Chuck Wooters, Jonathan Segal, An-dreas Stolcke, Eric Fosler, Gary Tajchman, andNelson Morgan.
1995.
Using a Stochastic CFGas a Language Model for Speech Recognition.In Proceedings, IEEE ICASSP, Detroit, Michi-gan.David M. Magerman.
1995.
Statistical Decision-Tree Models for Parsing.
In Proceedings ofthe 33 ~d Annual Meeting of the Association forComputational Linguistics.T.R.
Niesler and P.C.
Woodland.
1996.
Avariable-length category-based N-gram lan-guage model.
In Proceedings, IEEE ICASSP.S.
Roukos.
1996.
Phrase structure language mod-els.
In Proc.
ICSLP '96, volume supplement,Philadelphia, PA, October.Christer Samuelsson and Wolfgang Reich.
1999.A Class-based Language Model for Large Vo-cabulary Speech Recognition Extracted fromPart-of-Speech Statistics.
In Proceedings, IEEEICASSP.Yves Schabes.
1990.
Mathematical nd Computa-tional Aspects of Lexicalized Grammars.
Ph.D.thesis, University of Pennsylvania, Philadel-phia, PA.B.
Srinivas.
1997a.
Complexity of Lexical De-scriptions and its Relevance to Partial Pars-ing.
Ph.D. thesis, University of Pennsylvania,Philadelphia, PA, August.B.
Srinivas.
1997b.
Performance Evaluation ofSupertagging for Partial Parsing.
In Proceed-ings of Fifth International Workshop on Pars-ing Technology, Boston, USA, September.R.
Weischedel., R. Schwartz, J. Palmucci, M.Meteer, and L. Ramshaw.
1993.
Coping withambiguity and unknown words through prob-abilistic models.
Computational Linguistics,19.2:359-382.The XTAG-Group.
1995.
A Lexicalized Tree Ad-joining Grammar for English.
Technical Re-port IRCS 95-03, University of Pennsylvania,Philadelphia, PA.195
