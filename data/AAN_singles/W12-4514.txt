Proceedings of the Joint Conference on EMNLP and CoNLL: Shared Task, pages 118?121,Jeju Island, Korea, July 13, 2012. c?2012 Association for Computational LinguisticsHybrid Rule-based Algorithm for Coreference Resolution ?Heming Shou1,2 Hai Zhao1,2?1Center for Brain-Like Computing and Machine Intelligence,Department of Computer Science and Engineering, Shanghai Jiao Tong University2MOE-Microsoft Key Laboratory for Intelligent Computing and Intelligent SystemsShanghai Jiao Tong Universityshouhm@gmail.com, zhaohai@cs.sjtu.edu.cnAbstractThis paper describes our coreference resolu-tion system for the CoNLL-2012 shared task.Our system is based on the Stanford?s dcore-f deterministic system which applies multiplesieves with the order from high precision tolow precision to generate coreference chains.We introduce the newly added constraints andsieves and discuss the improvement on the o-riginal system.
We evaluate the system usingOntoNotes data set and report our results ofaverage F-score 58.25 in the closed track.1 IntroductionIn this paper, our coreference resolution system forCoNLL-2012 shared task (Pradhan et al, 2012) issummarized.
Our system is an extension of Stan-ford?s multi-pass sieve system, (Raghunathan et al,2010) and (Lee et al, 2011), by adding novel con-straints and sieves.
In the original model , sieves aresorted in decreasing order of precision.
Initially eachmention is in its own cluster.
Mention clusters arecombined by satisfying the condition of each sievein the scan pass.
Through empirical studies, we pro-posed some extensions and algorithms for further-more enhancing the performance.
?This work was partially supported by the National NaturalScience Foundation of China (Grant No.
60903119 and GrantNo.
61170114), the National Research Foundation for the Doc-toral Program of Higher Education of China under Grant No.20110073120022, the National Basic Research Program of Chi-na (Grant No.
2009CB320901) and the European Union Sev-enth Framework Program (Grant No.
247619).
?corresponding authorMany other existing systems applied supervisedor unsupervised (Haghighi and Klein, 2010) learn-ing models.
The classical resolution algorithm wasproposed by (Soon et al, 2001).
Semantic knowl-edge like word associations was involved by (Kob-dani et al, 2011).
Most of the supervised learningmodels in CoNLL-2011 shared task (Chang et al,2011)(Bjo?rkelund and Nugues, 2011) used classi-fiers (Maximum Entropy or SVM) to train the mod-els for obtaining the pairwise mention scores.
How-ever, the training process usually takes much longertime than unsupervised or deterministic systems.
Incontrast, (Raghunathan et al, 2010) proposed a rule-based model which obtained competitive result withless time.Two considerable extensions to the Stanford mod-el in this paper are made to guarantee higher pre-cision and recall.
First, we recorded error pattern-s from outputs of the original Stanford system andfound that the usual errors are mention boundarymismatches, pronoun mismatches and so on.
Toavoid the irrational coreference errors, we addedsome constraints to the mention detection for elim-inating some unreasonable mention boundary mis-matches.
Second, we added some constraints in thecoreference sieves based on the errors on the trainingset and the development set.We participated in the closed track and receivedan official F-score (unweighted mean of MUC,BCUBED and CEAF(E) metric) of 58.25 for En-glish.
The system with our extensions is briefly in-troduced in Section 2.
We report our evaluation re-sults and discuss in Section 3.1182 System ArchitectureThe original Stanford system consists of threestages: mention detection, coreference resolutionand post-processing.
The mention detection stageis for extracting mentions with a relative high re-call.
The coreference resolution stage uses multiplesieves to generate coreference clusters.
The post-processing stage makes the output compatible withthe shared task and OntoNotes specifications (Prad-han et al, 2007), e.g.
removing singletons, apposi-tive, predicate nominatives and relative pronouns.2.1 Mention DetectionOur system mainly focuses on making extension-s for mention detection and coreference resolution.From error analysis, we found that mention bound-aries caused many precision and recall errors.
Forexample, for the gold mention Robert H. Chandross,an economist for Lloyd?s Bank in New York, the o-riginal system only extracts Robert H. Chandross asthe mention and links it with he in the following sen-tence.
This mismatch leads to both precision and re-call errors since the mention with longer boundaryis not detected but the shorter one is used.
Anotherexample which omits today in the phrase for the pre-dicted mention is mentioned in (Lee et al, 2011) andthis boundary mismatch also accounts for precisionand recall errors.
Some other examples may be likethis: Auto prices had a big effect in the PPI, and atthe CPI level they won?t, the gold mentions are Au-to prices, the PPI, the CPI level and they while theoriginal system only finds out auto prices.
Consid-ering these boundary mismatches, it is not hard forus to categorize the error types.By observation, most boundary problems happenin the following cases:?
The predicted mention is embedded in the goldmention.?
The gold mention is embedded in the predictedmention.?
Some gold mentions are totally omitted.It is very rare for the case that predicted mentionoverlaps with the gold mention but no one includesthe other.For the first and second cases, some analysis andconstraint about prefix and postfix of phrases are ap-plied to get predicted mentions as precise as goldmentions.
For the example mentioned above, theclause ,an economist ... which modifies the personRobert H. Chandross is annexed to the person namemention.
We also append time and other modifiersto the original mention.
As for the third case, we al-low more pronouns and proper nouns to be added tothe list of mentions.2.2 Sieve CoreferenceLike the constraints on the extension to the mentiondetection stage, our system also generates error re-ports for the sieve passes.
While our system is rule-based and it also works without training data sets,some statistical information is also helpful to detectand avoid errors.The first extension we used is a direct way to uti-lize the training data and the development data.
Wesimply record the erroneous mention pairs in thetrain and development sets with distance and sieveinformation.
One of the most common errors is thatwhen mentions with particular types appear twicein the same sentence, the original system often putsthem into the same cluster.
For example, there areoften two or more you or person names in the dia-logue, however, the different occurrences are treat-ed as coreference which produces precision errors.To address this problem, we convert proper noun-s to type designator, e.g.
Paul as Man Name.
Thenwe use the formatted error pairs as constraints on thesieve passes since some pairs mostly cause precisionerrors.
If the checking pair matches up some recordsin the errors with the same sieve information and theerror frequency is over a threshold, we must discardthis pair in this sieve pass.Another difference between our system and the S-tanford system is the semantic similarity sieve.
Foreach sieve pass, the current clusters are built bystronger sieves ( sieves in the earlier passes ).
The S-tanford system selects the most representative men-tion from a mention cluster to query for semanticinformation.
The preference order is:1. mentions headed by proper nouns2.
mentions headed by common nouns1193.
nominal mentions4.
pronominal mentionsIn our system, we not only select the most rep-resentative one but compare all the types above, i.e,select the longest string in each type of this clus-ter.
When applying semantic sieves, we also com-pare representative mention for each type and makesynthesized decisions by the number of types whichhave similar semantic meanings.We also made some modifications on the sievesand their ordering in the original system.
For Prop-er HeadWordMatch mentioned in (Lee et al, 2011),the Pronoun distance which indicates sentence dis-tance limit between a pronoun and its antecedent.We change the value from 3 to 2.3 Experiments and ResultsTable 1: CoNLL-2012 Shared Task Test ResultsMetric Recall Precision F1MD 75.35 72.08 73.68MUC 63.46 62.39 62.92BCUBED 65.31 68.90 67.05CEAF(M) 55.68 55.68 55.68CEAF(E) 44.20 45.35 44.77BLANC 69.43 75.08 71.81OFFICIAL - - 58.25Table 2: Comparison between original system and oursystem on the development setmetric original our systemMUC F 61.64 62.31MUC P 58.65 59.58MUC R 64.95 65.29BCUBED F 68.61 69.87BCUBED P 67.23 68.81BCUBED R 70.04 70.97Our system enhanced the precision and recall ofthe original system of (Lee et al, 2011).
The table 1.shows the official result for the CoNLL-2012 sharedtask.
The recall of our mention detection approachis 75.35% while the precision is 72.08%.
The fi-nal official score 58.25 is the unweighed mean ofMUC, BCUBED and CEAF(E).
Although the testset is different from that of the previous year, com-paring with the original system, our result of MDand MUC shows that our improvement is meaning-ful.
The table 2. indicates the improvement fromour system over the original system evaluated by thedevelopment set.
Since experiments with seman-tic knowledge like WordNet and Wikipedia cannotgive better performance, we omit the semantic func-tion for generating test result.
Our explanation isthat the predicted mentions are still not precise e-nough and the fuzziness of the semantic knowledgemight cause conflicts with our sieves.
If the seman-tic knowledge tells that two mentions are similar andpossibly can be combined while they do not satisfythe sieve constraints, it will be very hard to make adecision since we cannot find an appropriate thresh-old to let the semantic suggestion pass through.4 ConclusionIn this paper we made a series of improvements onthe existing Stanford system which only uses deter-ministic rules.
Since the rules are high dimensional,i.e., the rules that are adopted in the system may de-pend on the states of the ongoing clustering process,it is not feasible to apply it in the statistical learningmethods since take the intermediate results into con-sideration will be.
The experimental results showthat our improvements are effective.
For this task,we added constraints on the mention detection stageand the coreference resolution stage.
We also addednew sieves and conduct a group of empirical studieson semantic knowledge.
Our results give a demon-stration that the deterministic model for coreferenceresolution is not only simple and competitive but al-so has high extendibility.ReferencesAnders Bjo?rkelund and Pierre Nugues.
2011.
Exploringlexicalized features for coreference resolution.
In Pro-ceedings of the Fifteenth Conference on Computation-al Natural Language Learning: Shared Task, pages45?50, Portland, Oregon, USA, June.
Association forComputational Linguistics.Kai-Wei Chang, Rajhans Samdani, Alla Rozovskaya,Nick Rizzolo, Mark Sammons, and Dan Roth.
2011.Inference protocols for coreference resolution.
In Pro-ceedings of the Fifteenth Conference on Computation-120al Natural Language Learning: Shared Task, pages40?44, Portland, Oregon, USA, June.
Association forComputational Linguistics.Aria Haghighi and Dan Klein.
2010.
Coreference reso-lution in a modular, entity-centered model.
In HumanLanguage Technologies: The 2010 Annual Conferenceof the North American Chapter of the Association forComputational Linguistics, pages 385?393, Los An-geles, California, June.
Association for ComputationalLinguistics.Hamidreza Kobdani, Hinrich Schuetze, MichaelSchiehlen, and Hans Kamp.
2011.
Bootstrappingcoreference resolution using word associations.
InProceedings of the 49th Annual Meeting of theAssociation for Computational Linguistics: HumanLanguage Technologies, pages 783?792, Portland,Oregon, USA, June.
Association for ComputationalLinguistics.Heeyoung Lee, Yves Peirsman, Angel Chang, NathanaelChambers, Mihai Surdeanu, and Dan Jurafsky.
2011.Stanford?s multi-pass sieve coreference resolution sys-tem at the conll-2011 shared task.
In Proceedings ofthe Fifteenth Conference on Computational NaturalLanguage Learning: Shared Task, pages 28?34, Port-land, Oregon, USA, June.
Association for Computa-tional Linguistics.Sameer S. Pradhan, Lance A. Ramshaw, Ralph M.Weischedel, Jessica MacBride, and Linnea Micciulla.2007.
Unrestricted coreference: Identifying entitiesand events in ontonotes.
In ICSC, pages 446?453.Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,Olga Uryupina, and Yuchen Zhang.
2012.
CoNLL-2012 shared task: Modeling multilingual unrestrict-ed coreference in OntoNotes.
In Proceedings of theSixteenth Conference on Computational Natural Lan-guage Learning (CoNLL 2012), Jeju, Korea.Karthik Raghunathan, Heeyoung Lee, Sudarshan Ran-garajan, Nathanael Chambers, Mihai Surdeanu, DanJurafsky, and Christopher Manning.
2010.
A multi-pass sieve for coreference resolution.
In Proceedingsof EMNLP 2010.Wee Meng Soon, Hwee Tou Ng, and Daniel Chung YongLim.
2001.
A machine learning approach to coref-erence resolution of noun phrases.
Comput.
Linguist.,27(4):521?544, December.121
