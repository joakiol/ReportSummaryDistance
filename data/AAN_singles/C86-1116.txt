Incremental Construction of C- and F-Structure in a LFG-ParserHans-Ulrich Block Rudolf HunzeZTI INF 3, Siemens AG, MQnchen, West GermanyIn this paper we present a parser for Lexical FunctionalGrammar (LFG) which is characterised by incrementallyconstructing the c- and f-structure of a sentence duringthe parse.
We then discuss the possibilities of theearliest check on consistency, coherence andcompleteness.
Incremental construction of f-structureleads to an early detection and abortion of incorrectpaths and so increases parsing efficiency.
Furthermorethose semantic interpretation processes that operate onpartial structures can be triggered at an earlier state.This also leads to a considerable improvement in parsingtime.
LFG seems to be well suited for such an approachbecause it provides for locality principles by thedefinition of coherence and completeness.1.
LFG consists of acontext free grammar with rules inthe usual format such as (1):(1) A - -> (B) C* {D/E} FThe context free analysis of a sentence is refined byattaching a set of equations to each nonterminal nodeon the right side of a production.
They refer tosyntactical features of a constituent such as number(NUM), gender (GEN) etc.
and to grammatical functionsof a constituent such a subject (SUB J), object (OBJ) etc.,establishing relations between a node on the right sideof a production and its predecessor.
An f-structurewhich includes this addditional information isassociated with each nonterminal node.
F-structures canbe regarded as lists of attribute-value pairs.
Theattributes are the syntactical features and grammaticalfunctions described above.
The values can be f-structures as well as symbols such as singular (SG), yes( + ), baby etc., or semantic forms, the latter serving as alink between syntax and semantics.When writing down an equation we use themetavariables 1`  to refer to the parent's node f-structureand J, to refer to the node's f-structure.
If we look atthe equation(2) S--> NP VP( t  SUBJ)=$ ~=$this means that the subject of the sentence is the NP's f-structure and that S and VP have the same f-structure.F-structures can be used to detect ungrammaticalsentences and to discard incorrect analysis of asentence.
Three possible reasons may lead to thedecision to prune an interpretation of a sentence:i) the f-structure can be inconsistent.This is the case when information from differentconstituents leads to contradictory results.
For instancein the sentence "the men dies" the lexical entry formen "men": (~ PRED) = man , (1' NUM) = PL, wouldassure that the NUM-attribute in the NP s f-structure hasPI as its value.On the other hand we have from thelexical entry of dies "dies" : (1' PRED) = (SEM-FORM die(~SUBJ)), ( t  NUM) = SG and the value of the NUM-attribute of the VP's f-structure would be SG.
But thesentence and the VP have the same f-structure fromwhere we get the contradiction that the NUM-attributeof the SUB J-attribute of the sentence's f-structure is SGand PI atthe same time.ii) the f-structure can be incoherent.Some of the attributes such asSUBJ orOBJ are markedas grammatical functions.It is an impo~ant pr!nciple ofthe LFG-theory that the value of the verbs PRED-attribute which is always a semantic-form shouldcontain all grammatical functions.
In a sentence as"The men dies the apple" we have an OBJ in thesentence but not in the lexical entry of the word "dies".Therefore this sentence is ungrammatical.iii) the f-structure can be incomplete.A further principle of the LFG-theory demands that allgrammatical roles which appear in the verb s semanticform should be contained in the f-structure of theconstituent he verb is part of.
In a sentence like "PeteriVes " the lexical entry for gives "gives": ( t  PRED) =EM-FORM give(tSUBJ)(  t OBJ)(1` OBJ2)) calls fortwo objects but none of them exists.2.
The parser we have developped is based on Earley'salgorithm.
It operates on a single ordered set of statesto the end of which constantly new states which are stillto be worked on are added.
A state is a tupef (<t ree><le f t> <r ight> <dot> <pred.- l ist>)<t ree> is the current parsetree of that path< le f t> is a pointer to the input string theconstituent begins with<r ight>is  a pointer to the input string thatimmedeatty fol lowsthe constituent<dot> marks the current position in the right sideof the cfgrammar rule<pred.- l ist> is a set of pointers to all preceedingstates who's tree nodes mightbecome the mother of the currentstates' tree.A tree node is a complex data structure that containsthe node's label (i.e.
his syntactic category), a list of itsdaughters and a pointer to the f-structure attached toit.The basic actions are predict, scan and complete whichare close to the definit ion in Earley (1970).
For theconstruction of the c-structure these actions areaugmented in the fol lowing way: predict creates anempty tree node labeled with the predicted category,scan attaches the next input word as the rightmostdaughter to the state's <tree >, and complete attachesthe state's <t ree> as the rightmost daughter to alltreenodes in the states of the current state's <pred.-list>.
For the construction of the f-structure thefol lowing augmentations are performed: The <dot>part of a state not only marks the position in the cf-.rule's right hand side, but also contains the functionalequations associated with that position.
Whenpredicting a constituent an empty f-structure is attachedto it and incremented by scanning a word or completingthe phrase.
The parser then instantiates the up- anddown-arrow of the equations with copies of themother's and daughter's f-structure.
(In the former caseonly the mother's f-structure is needed.)
After beingaugmented by evaluation of the equations the f-structure associated with the up-arrow becomes the f-.structure of the new state's tree.
As an example weshow how the f-structure of the sentence this manloved Mary g rows.state of analysis f-structu repredicting S \[\]spredicting NP \[\]NP490scanning this \[DET = DPRONNUM = SG \]NPscanning man \[DET = DPRONNUM = SGPRED = MAN \]NPcompletingNP \[SUBJ = \[DET = DPRONNUM = SGPRED = MAN \]\]Spredicting VP \[\]vPscanningloved \[TENSE = PASTPRED = love( 1' SUB J) ( 1' ORJ)\]vppredicting NP \[\]NPscanning Mary \[ PRED = MARYNUM = SG \]NPcompleting NP \[TENSE =PASTPRED = love( I' SUB J) ( 1  `OBJ)\]vpOBJ = \[PRED = MARYNUM = SG \]\]vPcomptetingVP \[SUBJ = \[DET = DPRONNUM = SGPRED = MAN\]TENSE = PASTPRED =love( 1' SUB J)( I' OBJ)OBJ = \[PRED = MARYNUM = SG \]\]sBuilding f-structures in this incremental way allowsruling out paths that would lead to inappropriate fostructures earlier than in a sequential process that buildsc-structure and f-structure.3.1.
When :;canning or completing a cf-grammar rulethe parser can detect inconsistencies.
Look at thesentence these man loved Mary while he was waitingfor a bus.
When scanning man the parser tries to mergethe information from the lexical entry of man with thef-structure of the NP-node so far constructed.
Theinconsistency in number is noticed and the analysis failseffecting a considerable abbreviation of parsing time.On the other hand in the sentence these men loves Marywhile ...the inconsistency in number can be revealed atthe moment the completer tries to attach the VP--nodeto the S-node.
It would be very effective and moreplausible under the aspect of a cognitive model ofparsing if one could finish the analysis of a sentence likethis after storming the verb loves.
This would imply thatf-structures are partially built on the predictor as in:predicting S \[\]spredicting NPscanning these\[\]NP\[DET = DPRONNUM = PL\]Npscanning men \[DET = DPRONNUM = PLPRED = MAN\]NpcompletingNP \[SUB\] = \[DET = DPRONNUM = SGPRED = MAN \]\]spredictingVP \[SUBJ = \[DET = DPRONNUM = SGPRED = MAN \]\]vPWhereas examples like this at first glance can be takenas an argument to build f-structures on the predictorthe architecture of the Earley algorithm gives goodreason not to do so.
Remember that in the Earleyalgorithm the same completed constituent can not onlybe attached to one node, but to a set of predecessingnodes.
Therefore the predictor must not open a newconstituent at a certain input position if a constituent ofthe same type is already there.
So if we al low new openconstituents to inherit f-structures from theirpredecessors, the predictor has to check if a constituentof a certain type and with a certain partial f-structurehas already been opened at the current position.
Butchecking f-structures is a very costy and clumsy processthat should be used sparingly.Furthermore, if we take into account that the realprofits of incremental f-structure building consists indecreasing the combinatorial explosion of c-structurallyambiguous sentences by detecting incorrect paths at anearly stage, building f-structures on the completer is notas bad as it seems to be at first glance.
If we look forexample at the sentence (3) we cannot decide from apurely c-structure oriented point of view which of thestructures in (4) isthe correct reading.
(3) well Karl die BLicher seinem Voter gibtbecause.
Charles the books his father givesbecause Charles gives the books to his father(4) a.
\[S well \[NP Karl\] \[VP \[NP \[NP die BOcher\]\[NP seinem Voters\] \] \[v gibt\]\]\]b.
\[s well \[NP Karl\] \[vP \[NP die Bucher\]\[ Npseinem Voters\] \[v gibt\]\]\]But if we use f-structure information from a rule like theone in (5) we can decide from completing the NPseinern Voter that CASE is not GEN and thereforeexclude the second reading.
(5) NP --~ NP NP( 1' HEAD) = ~ ( 1" CASE) = GENOf course, if we would check the equations on thepredictor the wrong path could be detected earlier,namely when scarming the non-GEN determiner seinem.But what would then happen?
The parse of the same NPhas to continue, this time induced by the correct \[VP\[NPdie B6cher\] \[ NP seinem ...-path.
It seems that wheneverthere is a constituent hai: is inconsistent with one of itspredecessors there is good chance that it is consistentwith some other element in its predecessor set.3.2.
Whereas the check for consistency is a by-product ofbuilding the f-structure, the check for coherence is notas simple as that.
Checking coherence as soon aspossible augments the efficiency of the parser by anearly abortion of incorrect paths.
Suppose for a momentthat our grammar does not treat adjuncts and take thefol lowing lexicon-entries in (6) and rules in (7).
(6) put PRED=(Semform'PUT <tSUBJ> <tOBJ>< tON>)book PRED = 'BOOK)book PRED = (Semform 'BOOK < 1" ON >)review PRED = 'REVIEW)review PRED= (Semform 'REVIEW < ?
ON>)(7) VP-~ V (NP) PP*(?
OBJ)= ~, (1" ($ PCASE))= $NP-.
{DET N PP* I PN}(t (~ PCASE))=For the VP in a sentence like (8) the parser would firstconstruct he two partial readings in (9),(8) He put the book on Chomskyon the table(9) a. put \[the book on Chomsky\]b. put \[the book\] \[on Chomsky\]491The attachment of the PP on the table now leads to thestructures in (10), but only (10b.)
is coherent.
(10) a.
*put \[the book on Chomskyon the table\]not coherent with bookb.
put \[the book on Chomsky\] \[on the table\]c. *put \[the book\] \[on Chomsky\] \[on the table\]not coherent with puttn a more realistic scenario no such strong constraintscan be established as VPs and especially NPs normallynot only contain objects but as well a rather largenumber of adjuncts.
But even then checking coherenceas soon as possible reduces the number of paths tofollow.
For example if we assume that in Englishadjuncts follow prepositional objects, for the sentencein (11) the parser develops 19 readings whereas withouta coherence-check it had to pursue 42 different paths.The sum of 19 paths is computed out of the 14 readingsof the NP in (12a.)
where on the table is regarded as anadjunct of NP, plus the 5 readings of the complex NP in(12b.
), where on the table is regarded as a grammaticalfunction of the VP.
(See below for the rote ofcompleteness in these examples).
(11) He has put the basket with the flowers for thefather of his mother's boyfriend on the table(12) a. the basket with the flowers for the father of hismother's boyfriend on the tableb.
the basket with the flowers for the father of hismother's boyfriendIn languages that have a (partial) SOV ordering, such asGerman, checking for coherence does not contributethat much to the reduction of the combinatorialcomplexity.
Only in cases like (13) where the accusativecase within the PP marks the PP as a grammaticalfunction (of either the verb or the noun) some readingsmay be excluded without having seen the verb.
(13) dal3 die Sekret~rin den Brief an den Direktor anden Abteilungsleiter weiterleitetethat the typist the letter to the director to thehead of the department handed(14) a.
*\[denBriefan\[denDirektorandenAbtei lungs-leiter\]\]not coherent with Direktorb.
*\[den Brief an den Direktor an den Abteilungs-leiter\]not coherent with Briefc.
\[\[den Brief an den Direktor\] an den Abteilungs-leiter\]From our considerations above we can extract somemore formal principles that are apt to check forcoherence as soon as possible in all languages,independently of the position of the verb:Let F denote the VPs f-structure, Semform be thesemantic form associated with the verb, ARG(Semform)the set of its arguments and let Gramfunc be the set ofsubcategorisable grammatical functions.
( Thismechanism holds for N and NP, P and PP etc.analogously.
)Three cases may occur in the coherencecheck:1) Assume that the verb has already been processed andwe want to attach a phrase, say an NP to which theequation (~ ATTR) = $ is attached.coherence condition: IfATTR ( Gramfunc then ATTR EARG(Semform)4922) Assume that the verb is being processed.coherence condition: IfATTR ~ Gramfuncand ATTR isan attribute in F then ATTR (ARG(Semform)3) Assume that the VP is going to be completed.
We arethen forced from the trivial equation t = ~ to mergethe VP's and S' f-structure that is we must apply thecoherence condition as it appears in 2) again.Finally we want to mention that there is no need for acoherence check of the whole sentence as done inearlier works.
It is just sufficient to take the threeconditions above into account since in LFG globalcoherence (and completeness) is defined in terms oflocal coherence (completeness).3.3.
In a sentence like (15} that is c-structurallyambiguous in two ways the ambiguity concerning theattachment of the PP on the table is local within therelative clause (16).
(15) The boy that had put the book on the table camein.
(16) a.
\[had put \[the book on the table\]\]b.
\[had put \[the book\] on the table\]It cannot be solved either by means of consistency or bymeans of coherence checking.
On the table is as good anadjunct for book as it is a grammatical function for put.It can be solved if we take into account thecompleteness requirement (see 1.iii).
Unfortunately, atthe current state of LFG an argument may be mergedinto a verb's surrounding f-structure at a later state ofthe parse.
Consider for example (17) where theprepositional object (realized as where) may be mergedinto the clause he put the book by a Ioncl-distancemovement equation or by a simple equation of the form(t  FOCUS) = (~ ON).
(17) I don't know \[s, where \[s he put the book\]\].This implies that whenever the completer closes theclause, it can't be guaranteed that its f-structure iscomplete.We can circumvent his deficiency by a reinterpretationof the notion of 'bounding node'.
We introducebounding categories and assume that they define strictislands.
No equation of the type (t  ...) = ($ ...) may beassociated with a bounding category in the grammar.We state the island-principle as follows:The value of a grammatical function in a boundingnode's f-structure is the f-structure of a constituent hatis dominated by that bounding node.We can then formulate the completeness checkingmechanism: Let Cat(DOWN) be the category andF(DOWN) be the f-structure of the node that is to beattached in the completer.
Let ARG(DOWN) be theARG(Semform) of the PRED of F(DOWN).
LetBOUNDINGCATEGORIES be the set of boundingcategories in the grammar.Then, if the completer is called in the situation such thatCat(DOWN) ( BOUNDINGCATEGORIES, then continueonly if ARG(DOWN) c_ {AI A is an attribute in F(DOWN)}.We have argued above that in a sentence like (11) abovethe parser could abort 21 wrong paths under theassumption that in English all PPs that are grammatica|functions (i.e.
all prepositional objects, PO) precede alladjuncts.
As the verb selects on as a grammaticalfunction none of the PPs preceding the PP on the tablecan be either adjunct or a grammatical function of theVP+ It is obvious that this restriction only holds Jf theverb has an obligatory prepositional object that occurswithin the VP.
Unfortunately, at the current state of thedevelopment of the LFG-formalism we cannot force thePO to occur within the VP.
Even if the verb selects a PO,theoretically, this PO may come into the verbs f-structure by some equation of the form in 0 or by thetrivial equation t = $.
(18) ( t  VCOMPON) = (t  X)In practice, however, except in cases of long distancemovement, only the SUBJ is merged into the VPs f-structure.
This implies, given an adequate treatment oflong-distance movement, that VPs form an island exceptfor their SUBjects.
We therefore suggest to change theabove definition of the completeness-checker in thefollowing way: Let EXTERNALS be the set ofgrammatical functions that may not be realized withinthe VP.
(trivially EXTERNALS = {SUBJ}).Then, if the completer is called in the situation such thatCat(DOWN) ~ BOUNDINGCATEGORIES, then continueonly if ARG(DOWN)- EXTERNALS C {AI  A is anattribute in F(DOWN)}.4.We hope to have shown that with the aid of localityprinciples incremental construction of f-structures canachieve an enormous reduction of the ambiguity factorof a sentence.The problem of wether the f-structure of a sentence iswellformed can be decomposed by applying localityprinciples.
This makes it possible to check thewellformedness of f-structures of phrases and facilitatesespecially the completeness test for the VP.A further reduction of the VP's ambiguity can beobtained by additional considerations on the possibleorder of grammatical functions and adjuncts.As a last examples, consider:The boy that has put the basket with the flowers for thefather of his mother's boyfriend on the table hasforgotten to remove the vase with the flowers for themother of his sister's boyfriend from the table in thekitchen.From the theory of catalan numbers we get anambiguity of 42 for the embedded relative clause .This ismultiplied with the ambiguity 132 for the main clauseresulting in a c-structure that is 5544 ambiguous.
If weexploit all the facilities mentioned above we can reducethe relative clause to be 5 times ambiguous (includingcompleteness check that rules out the 14 readings of(12 a)) whereas the main clause is 10 = 52 ambiguous(the factor 2 resulting from in the kitchen which can beadjunct to the VP as well as adjunct to the NP) and theambiguity of the whole sentence decreases to 50.LiteratureChurch,K., PatiI,R.
82Copingwith syntactic ambiguity or how to put the blockin thebox on the tablejacl Vol 8, nunnber 3-4, July-December 1982Kaplan,R., Bresnan,J.
82Lexical-functional grammar: a formal system for.grammatical representationm Bresnan,J., ed., the mental representation ofgrammatical relationsMIT press series on cognitive theory and mentalrepresentation 1982AcknowledgementsWe are greatly indepted to our colleagues HansHaugeneder and Manfred Gehrke.493
