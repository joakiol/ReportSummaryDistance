Proceedings of the 2nd Workshop on Building and Using Comparable Corpora, ACL-IJCNLP 2009, pages 55?63,Suntec, Singapore, 6 August 2009. c?2009 ACL and AFNLPCompilation of Specialized Comparable Corpora in French and JapaneseLorraine Goeuriot, Emmanuel Morin and B?atrice DailleLINA - Universit?
de NantesFrancefirstname.lastname@univ-nantes.frAbstractWe present in this paper the developmentof a specialized comparable corpora com-pilation tool, for which quality would beclose to a manually compiled corpus.
Thecomparability is based on three levels: do-main, topic and type of discourse.
Domainand topic can be filtered with the keywordsused through web search.
But the detec-tion of the type of discourse needs a widelinguistic analysis.
The first step of ourwork is to automate the detection of thetype of discourse that can be found in ascientific domain (science and popular sci-ence) in French and Japanese languages.First, a contrastive stylistic analysis of thetwo types of discourse is done on both lan-guages.
This analysis leads to the creationof a reusable, generic and robust typology.Machine learning algorithms are then ap-plied to the typology, using shallow pars-ing.
We obtain good results, with an av-erage precision of 80% and an average re-call of 70% that demonstrate the efficiencyof this typology.
This classification toolis then inserted in a corpus compilationtool which is a text collection treatmentchain realized through IBM UIMA system.Starting from two specialized web docu-ments collection in French and Japanese,this tool creates the corresponding corpus.1 IntroductionComparable corpora are sets of texts in differ-ent languages, that are not translations, but sharesome characteristics (Bowker and Pearson, 2002).They represent useful resources from which areextracted multilingual terminologies (D?jean etal., 2002) or multilingual lexicons (Fung and Yee,1998).
Comparable corpora are also used incontrastive multilingual studies framework (Petersand Picchi, 1997), they constitute a precious re-source for translators (Laviosa, 1998) and teachers(Zanettin, 1998), as they provide a way to observelanguages in use.Their compilation is easier than parallel corporacompilation, because translated resources are rareand there is a lack of resources when the languagesinvolved do not include English.
Furthermore, theamount of multilingual documents available on theWeb ensures the possibility of automatically com-piling them.
Nevertheless, this task can not besummarized to a simple collection of documentssharing vocabulary.
It is necessary to respect thecommon characteristics of texts in corpora, es-tablished before the compilation, according to thecorpus finality (McEnery and Xiao, 2007).
Manyworks are about compilation of corpora from theWeb (Baroni and Kilgarriff, 2006) but none, in ourknowledge, focuses on compilation of compara-ble corpora, which has to satisfy many constraints.We fix three comparability levels: domain, topicand type of discourse.
Our goal is to automaterecognition of these comparability levels in docu-ments, in order to include them into a corpus.
Wework on Web documents on specialized scientificdomains in French and Japanese languages.
Asdocument topics can be filtered with keywords inthe Web search (Chakrabarti et al, 1999), we fo-cus in this paper on automatic recognition of typesof discourse that can be found in scientific docu-ments: science and popular science.
This classi-fication tool is then inserted in a specialized com-parable corpora compilation tool, which is devel-opped through the Unstructured Information Man-55agement Architecture (UIMA) (Ferrucci and Lally,2004).This paper is structured as follows.
After an in-troduction of related works in section 2, stylisticanalysis of our corpus will be presented in sec-tion 3.
This analysis will lead to the creation ofa typology of scientific and popular science dis-course type in specifialized domains.
The appli-cation of learning algorithms to the typology willbe described in section 4, and the results will bepresented in section 5.
We will show that our ty-pology, based on linguistically motivated features,can characterize science and popular science dis-courses in French and Japanese documents, andthat the use of our three comparablility levels canimprove corpora comparability.
Finally, we de-scribe the development of the corpus compilationtool.2 Background?A comparable corpus can be defined as a corpuscontaining components that are collected usingthe same sampling frame and similar balance andrepresentativeness?
(McEnery and Xiao, 2007, p.20).
Comparability is ensured using character-istics which can refer to the text creation con-text (period, author...), or to the text itself (topic,genre...).
The choice of the common characteris-tics, which define the content of corpora, affectsthe degree of comparability, notion used to quan-tify how two corpora can be comparable.
Thechoice of these characteristics depends on the fi-nality of the corpus.
Among papers on comparablecorpora, we distinguish two types of works, whichinduces different choices:?
General language works, where texts of cor-pora usually share a domain and a period.Fung and Yee (1998) used a corpus composedof newspaper in English and Chinese on aspecific period to extract words translations,using IR and NLP methods.
Rapp (1999)used a English / German corpus, composed ofdocuments coming from newspapers as wellas scientific papers to study alignment meth-ods and bilingual lexicon extraction fromnon-parallel corpora (which can be consid-ered as comparable);?
Specialized language works, where choice ofcriteria is various.
D?jean et al (2002) used acorpus composed of scientific abstracts fromMedline, a medical portal, in English andGerman.
Thus they used documents sharing adomain and a genre to extract bilingual termi-nology.
Chiao (2002) used a corpus of docu-ments of medical domain on a specific topicto work on the extraction of specialized ter-minologies.In general language works, documents of compa-rable corpora often share characteristics like do-main or topic.
As they are usually extracted fromnewspapers, it is important to limit them to a cer-tain period to guarantee their comparability.In specialized corpora, first levels of compara-bility can be achieved with the domain and thetopic.
Moreover, several communicative settingsappear in specialized language (Bowker and Pear-son, 2002): expert-expert, expert-initiate, relativeexpert to the uninitiated, teacher-pupil.
Malrieuand Rastier (2002) specify several levels of tex-tual classification, each of which corresponding toa certain granularity.
The first level is discourse,defined as a set of utterances from a enunciatorcharacterized by a global topical unit (Ducrot andTodorov, 1972).
The second level is genre, de-fined as text categories distinguished by maturedspeakers.
For example, to literary discourse corre-spond several genres: drama, poetry, prose.
.
.
In-spired by these communicative settings and tex-tual categories, we choose to distinguish two com-municative settings or type of discourse in spe-cialized domains: science (texts written by ex-perts to experts) and popular science (texts writtento non-experts, by experts, semi-experts or non-experts).
This comparability level, the type of dis-course, reflects the context of production or usageof the documents, and guarantees a lexical homo-geneity in corpora (Bowker and Pearson, 2002, p.27).
Furthermore, Morin et al (2007) proved thatcomparable corpora sharing a topic and a type ofdiscourse are well adapted for multilingual termi-nologies extraction.Our goal is to create a tool to compile compa-rable corpora in French and Japanese which docu-ments are extracted from the Web.
We investigateautomatic categorization of documents accordingto their type of discourse.
This categorization isbased on a typology of elements characterizingthese types of discourse.
To this end, we carryout a stylistic and contrastive analysis (Karlgren,1998).
This analysis aims to highlight linguis-tically motivated features through several dimen-56sions (structural, modal and lexical), whose com-bination characterizes scientific or popular sciencediscourse.
A specialized comparable corpus canbe compiled from a single type of discourse docu-ment collection through several steps.
Last part ofthis paper focuses on the automation of these stepsusing the IBM Unstructured Information Manage-ment Architecture (UIMA).3 Analysis of Types of DiscourseThe recognition of types of discourse is basedon a stylistic analysis adapted from a deductiveand contrastive method, which purpose is to raisediscriminant and linguistically motivated featurescharacterizing these two types of discourse.
Maindifficulty here is to find relevant features which fitevery language involved.
These features, gatheredin a typology, will be used to adapt machine learn-ing algorithms to compilation of corpora.
Thistypology thus needs to be robust, generic andreusable in other languages and domains.
Gener-icity is ensured by a broad typology composed offeatures covering a wide range of documents char-acteristics, while robustness is guaranteed withoperational (computable) features and treatmentadaptable to Web documents as well as texts.Sinclair (1996) distinguishes two levels of anal-ysis in his report on text typologies: external level,characterizing the context of creation of the docu-ment; and internal level, corresponding to linguis-tic characteristics of document.
Because our cor-pora are composed of documents extracted fromthe Web, we consider external level features asall the features related to the creation of docu-ments and their structure (non-linguistic features)and call them structural features.
Stylistic analy-sis raises several granularity levels among linguis-tic characteristics of the texts.
We thus distinguishtwo levels in the internal dimension.
Firstly, inorder to distinguish between scientific and pop-ular science documents, we need to consider thespeaker in his speech: the modality.
Secondly, sci-entific discourse can be characterized by vocabu-lary, word length and other lexical features.
There-fore our typology is based on three analysis levels:structural, modal and lexical.3.1 Structural DimensionWhen documents are extracted from the Web, thestructure and the context of creation of the doc-uments should be considered.
In the frameworkFeature French JapaneseURL pattern ?Document?s format ?
?Meta tags ?
?Title tag ?
?Pages layout ?
?Pages background ?
?Images ?
?Links ?
?Paragraphs ?
?Item lists ?
?Number of sentences ?
?Typography ?
?Document?s length ?
?Table 1: Structural dimension featuresof Web documents classification, several elementsbring useful information: pictures, videos andother multimedia contents (Asirvatham and Ravi,2001); meta-information, title and HTML struc-ture (Riboni, 2002).
While those information arenot often used in comparable corpora, they can beused to classify them.
Table 1 shows structuralfeatures.3.2 Modal DimensionThe degree of specialization required by the recip-ient or reader is characterized by the relation builtin the utterance between the speaker or author andthe recipient or reader1.
The tone and linguisticelements in texts define this relation.
The modal-isation is an interpretation of the author?s attitudetoward the content of his/her assertion.
Modali-sation is characterized by many textual markers:verbs, adverbs, politeness forms, etc.
Presence ofthe speaker and his position towards his speechare quite different in scientific and popular sciencediscourse.
Thus we think modalisation markerscan be relevant.
For example, the speaker directlyspeaks to the reader in some popular science doc-uments: ?By eating well, you?ll also help to pre-vent diabetes problems that can occur later in life,like heart disease?.
Whereas a scientific documentwould have a neutral tone: ?Obesity plays a cen-tral role in the insulin resistance syndrome, whichincludes hyperinsulinemia, [.
.
. ]
and an increasedrisk of atherosclerotic cardiovascular disease?.Most of the modal theories are language de-pendent, and use description phenomena that arespecific to each language.
Conversely, the theoryexposed in (Charaudeau, 1992) is rather indepen-1Since we work on a scientific domain, we will considerthe speaker as the author of texts, and the recipient as thereader.57dent of the language and operational for Frenchand Japanese (Ishimaru, 2006).
According to Cha-raudeau (1992, p.572), modalisation clarifies theposition of the speaker with respect to his reader,to himself and to his speech.
Modalisation is com-posed of locutive acts, particular positions of theauthor in his speech, and each locutive act is char-acterized by modalities.
We kept in his theory twolocutive acts involving the author:Allocutive act: the author gets the reader in-volved in the speech (ex.
: ?You have to dothis.?
);Elocutive act: the author is involved in his ownspeech, he reveals his position regarding hisspeech (ex.
: ?I would like to do this.?
).Each of these acts are then divided into severalmodalities.
These modalities are presented in ta-ble 2 with English examples.
Some of the modali-ties are not used in a language or another, becausethey are not frequent or too ambiguous.3.3 Lexical DimensionBiber (1988) uses lexical information to observevariations between texts, especially between gen-res and types of texts.
Karlgren (1998) also uselexical information to characterize text genres, anduse them to observe stylistic variations amongtexts.
Thus, we assume that lexical informationis relevant in the distinction between science andpopular science discourse.
Firstly, because a spe-cialized vocabulary is a principal characteristic ofspecialized domain texts (Bowker and Pearson,2002, p. 26).
Secondly, because scientific docu-ments contain more complex lexical units, nomi-nal compounds or nominal sentences than popularscience documents (Sager, 1990).Table 3 presents the lexical dimension features.Note that these features show a higher languagedependency than other dimension features.4 Automatic Classification by Type ofDiscourseThe process of documents classification can be di-vided into three steps: document indexing, classi-fier learning and classifier evaluation (Sebastiani,2002).
Document indexing consists in buildinga compact representation of documents that canbe interpreted by a classifier.
In our case, eachdocument di is represented as a vector of fea-tures weight: ~di = {w1i, .
.
.
, wni} where n is theFeature French JapaneseSpecialized vocabulary ?
?Numerals ?
?Units of measurement ?
?Words length ?Bibliography ?
?Bibliographic quotes ?
?Punctuation ?
?Sentences end ?Brackets ?
?Other alphabets (latin, ?hiragana, katakana)Symbols ?Table 3: Lexical dimension featuresDimension MethodStructural Pattern matchingModal Lexical and lexico-syntactic patternsLexical Lexical patternsTable 4: Markers detection methodsnumber of features of the typology and wij is theweight of the jth feature in the ith document.
Eachfeature weight is normalized, dividing the weightby the total.
Documents indexing is characterizedby our typology (section 3) and features imple-mentation.4.1 Features ImplementationIn order to get a fast classification system, we priv-ileged for the implementation of our typology fea-tures shallow parsing such as lexical markers andlexico-syntactic patterns (method for each dimen-sion is detailed in table 4).Structural Features We used 12 structural fea-tures introduced in section 3.1.
Most of these fea-tures are achieved through pattern matching.
Forexample, URL patterns can determine is the docu-ment belongs to websites such as hospital (http://www.chu-***.fr) or universities websites(http://www.univ-***.fr), etc.
As forparagraphs, images, links, etc., one simple searchof HTML tags was made.Modal Features Locutor presence markers ina text can be implicit or ambiguous.
We fo-cused here on simple markers of his presence inorder to avoid noise in our results (high preci-sion but weak recall).
Thus we don?t recognizeall modal markers in a text but those recognizedare correct.
There are pronouns which are spe-cific to the speech act: for instance, for the eloc-utive act, the French pronouns je (I) and nous(we), and the Japanese pronouns?
(I),??
(we)58Feature Example French JapaneseAllocutive modalityAllocutive personal pronouns You ?Injunction modality Don?t do this ?
?Authorization modality You can do this ?Judgement modality Congratulations for doing it!
?Suggestion modality You should do this ?
?Interrogation modality When do you arrive?
?
?Interjection modality How are you, Sir?
?Request modality Please, do this ?
?Elocutive modalityElocutive personal I, we ?
?Noticing modality We notice that he left ?
?Knowledge modality I know that he left ?
?Opinion modality I think he left ?
?Will modality I would like him to leave ?
?Promise modality I promise to be here ?
?Declaration modality I affirm he left ?Appreciation modality I like this ?Commitment modality We have to do this ?Possibility modality I can inform them ?Table 2: Modal dimension featuresand ??
(we).
The modalities are also com-puted with lexical markers.
For example, themodality of knowledge can be detected in Frenchwith verbs like savoir, conna?tre (know), and inJapanese with the verb ??
(know), with po-lite form ??????
and with neutral form????
?.Lexical Features Some of our lexical criteriaare specific to the scientific documents, like bib-liographies and bibliographic quotations, special-ized vocabulary or the measurement units.
Tomeasure the terminological density (proportion ofspecialized vocabulary in the text) in French, weevaluate terms with stems of Greek-Latin (Namerand Baud, 2007) and suffix characters of rela-tional adjectives that are particularly frequent inscientific domains (Daille, 2000).
We listed about50 stems such as inter-, auto- or nano-, and the10 relational suffixes such such as -ique or -al.For Japanese, we listed prefix characteristics ofnames of disease or symptoms (???
(congen-ital), ???
(hereditary), etc.).
These stems canbe found in both type of discourse, but not in thesame proportions.
Specialized terms are used inboth type of discourse in different ways.
For ex-ample, the term ?ovarectomie?
(ovarectomy) canbe frequent in a scientific document and used oncein a popular science documents to explain it andthen replaced by ?ablation des ovaires?
(ovary ab-lation).
Sentences end are specific ending particlesused in japanese, for example the particle?
is of-ten used at the end of an interrogative sentence.4.2 Learning AlgorithmsClassifier learning is a process which observes fea-tures weight of documents classified in a classc or c and determine characteristics that a newdocument should have to be classified in one ofthese two classes 2.
Given a document indexing,there are some well-known algorithms that canachieve this process (neural network, Bayes clas-sifiers, SVM, etc.)
of which Sebastiani (2002) car-ried out a research about the assemblage and com-parison.
Applied to a Reuters newswires corpus,these techniques showed variable performances inthe usage level of supervised or unsupervised ap-proaches, of the size of the corpus, of the numberof categories, etc.
We decided to use SVMlight(Joachims, 2002) and C4.5 (Quinlan, 1993), sinceboth of them seem to be the most appropriate toour data (small corpora, binary classification, lessthan 100 features).5 ExperimentsIn this section, we describe the two comparablecorpora used and present the two experiments car-ried out with each of them.
The first compara-ble corpus is used to train the classifier in orderto learn a classification model based on our typol-ogy (i.e.
training task).
The second comparablecorpus is used to evaluate the impact of the clas-sification model when applied on new documents(i.e.
evaluation task).2This is the binary case.
See (Sebastiani, 2002) for othercases.595.1 Comparable CorporaThe corpora used in our experiments are bothcomposed of French and Japanese documents har-vested from the Web.
The documents were takenfrom the medical domain, within the topic of di-abetes and nutrition for training task, and breastcancer for the evaluation task.
Document harvest-ing was carried out with a domain-based searchand a manual selection.
Documents topic is fil-tered using keywords reflecting the specializeddomain: for example alimentation, diab?te andob?sit?
3 for French part and ???
and ??
4for the Japanese part of the training task corpus.Those keywords are directly related to the topic orthey can be synonyms (found on thesaurus) or se-mantically linked terms (found in Web documentscollected).
Then the documents were manually se-lected by native speakers of each language who arenot domain specialists, and classified with respectto their type of discourse: science (SC) or pop-ular science (PS).
Manual classification is basedon the following heuristics, to decide their type ofdiscourse:?
A scientific document is written by special-ists to specialists.?
We distinguish two levels of popular science:texts written by specialists for the generalpublic and texts written by the general pub-lic for the general public.
Without distinctionof these last two levels, we privileged doc-uments written by specialists, assuming thatthey may be richer in content and vocabulary(for example advices from a doctor would bericher and longer than forum discussions).Our manual classification is based on the twoprevious heuristics, and endorsed by several em-pirical elements: website?s origin, vocabularyused, etc.
The classification of ambiguous docu-ments has been validated by linguists.
A few doc-uments for which it was difficult to decide on thetype of discourse, such as those written by peo-ple whose specialist status was not clear, were notretained.We thus created two comparable corpora:?
[DIAB_CP] related to the topic of diabetesand nutrition and used to train the classifier.3nutrition, diabetes, and obesity4diabetes and overweight?
[BC_CP] related to the topic of breast cancerand used to evaluate the effectiveness of theclassifier.Table 5 shows the main features of each compa-rable corpora: the number of documents, and thenumber of words5 for each language and each typeof discourse.# docs # words[DIAB_CP]FR SC 65 425,781PS 183 267,885JP SC 119 234,857PS 419 572,430[BC_CP]FR SC 50 443,741PS 42 71,980JP SC 48 211,122PS 51 123,277Table 5: Basic data on each comparable corpora5.2 ResultsWe present in this section two classification tasks:?
the first one consists in training and test-ing classifiers with [DIAB_CP], using N-foldcross validation method that consists in divid-ing the corpus into n sub-samples of the samesize (we fix N = 5).
Results are for 5 parti-tioning on average;?
the second one consists in testing on [BC_CP]the best classifier learned on [DIAB_CP], inorder to evaluate its impact on new docu-ments.Tables 6 and 7 show results of these two tasks.On both table we present precision and recallmetrics with the two learning systems used.
Ontable 6, we can see that the results concerningthe French documents are quite satisfactory alto-gether, with a recall on average of 87%, and a pre-cision on average of 90% as for the classifier C4.5(more than 215 documents are well classified from248 French documents of [DIAB_CP]).
The re-sults of the classification in Japanese are also goodwith the classifier C.4.5.
More than 90% of doc-uments are correctly classified, and the precisionreaches on average 80%.
Some of the lower resultscan be explained, especially in Japanese by thehigh range of document genres in the corpus (re-search papers, newspapers, scientific magazines,recipes, job offers, forum discussions.
.
.
).5For Japanese, the number of words is the number of oc-currences recognized by ChaSen (Matsumoto et al, 1999)60French JapanesePrec.
Rec.
Prec.
Rec.SC 1.00 0.36 0.70 0.65svmlPS 0.80 1,00 0.72 0.80SC 0.89 0.80 0.76 0.96c4.5PS 0.91 0.94 0.95 0.99Table 6: Precision and recall for each language,each classifier, on [DIAB_CP]Table 7 shows results on [BC_CP].
In general,we note a decrease of the results with [BC_CP],although results are still satisfactory.
French doc-uments are well classified whatever the classifieris, with a precision higher than 75% and a recallhigher than 75%, which represent more than 70well classified documents on 92.
Japanese docu-ments are well classified too, with 76% precisionand 77% recall on average, with 23 documentswrong classified on 99.
This classification modelis effective when it is applied to a different medi-cal topic.
This classification model seems efficientto recognize scientific discourse from popular sci-ence one in French and Japanese documents on aparticular topic.French JapanesePrec.
Rec.
Prec.
Rec.SC 0.92 0.53 0.90 0.61svmlPS 0.64 0.95 0.66 0.98SC 0.70 0.92 0.76 0.70c4.5PS 0.87 0.56 0.75 0.80Table 7: Precision and recall for each language,each classifier, on [BC_CP]6 Comparable Corpora CompilationToolCompilation of a corpus, whatever type it is, iscomposed of several steps.1.
Corpus Specifications: they must be definedby the creator or user of the corpus.
It in-cludes decisions on its type, languages in-volved, resources from which are extracteddocuments, its size, etc.
In the case of spe-cialized comparable corpora, specificationsconcern languages involved, size, resourcesand documents domain, theme and type ofdiscourse.
This step depends on the applica-tive goals of the corpus and has to be donecarefully.2.
Documents Selection and Collection:according to the resource, size and othercorpus criteria chosen during the first step,documents are collected.3.
Documents Normalization and Annotation:cleaning and linguistic treatments are appliedto documents in order to convert them intoraw texts and annotated texts.4.
Corpus Documentation: compilation of acorpus that can be used in a durable waymust include this step.
Documentationof the corpus includes information aboutthe compilation (creator, date, method,resources, etc.)
and information about thecorpus documents.
Text Encoding Initiative(TEI) standard has been created in order toconserve in an uniformed way this kind ofinformation in a corpus 6.A corpus quality highly depends on the first twosteps.
Moreover, these steps are directly linked tothe creator use of the corpus.
The first step mustbe realized by the user to create an relevant corpus.Although second step can be computerizable (Ro-gelio Nazar and Cabr?, 2008), we choose to keepit manual in order to guarantee corpus quality.
Wedecided to work on a system which realizes thelast steps, i.e.
normalization, annotation and docu-mentation, starting from a collection of documentsselected by a user.Our tool has been developed on UnstructuredInformation Management Architecture (UIMA)that has been created by IBM Research Divi-sion (Ferrucci and Lally, 2004).
Unstructureddata (texts, images, etc.)
collections can be eas-ily treated on this platform and many libraries areavailable.
Our tool starts with a web documents ortexts collection and is composed of several com-ponents realizing each part of the creation of thecorpus:1. the collection is loaded and documents areconverted to texts (with conversion toolsfrom pdf or html to text mainly);2. all texts are cleaned and normalized (noisefrom the conversion is cleaned, all texts areconverted into the same encoding, etc.);6http://www.tei-c.org/index.xml613.
a pre-syntactic treatment is applied on texts(segmentation mainly) to prepare them forthe following step;4. morphologic and morpho-syntactic taggingtools are applied on the texts (Brill tagger(Brill, 1994) and Flemm lemmer (Namer,2000) for French texts, Chasen (Matsumotoet al, 1999) for Japanese);5. texts are classified according to their typeof discourse: we use here the most efficientSVMlight classifier.
In fact, two corpus arecreated, on for each type of discourse, thenthe user can choose one of them.
A vecto-rial representation of each document is com-puted, then these vectors are classified withthe classifier selected.6.
documentation is produced for the corpus, acertain amount of information are includedand they can be easily completed by the user.In reality, this tool is more a compilation assis-tant than a compilator.
It facilitates the compila-tion task: the user is in charge of the most im-portant part of the compilation, but the technicalpart (treatment of each document) is realized bythe system.
This guarantee a high quality in thecorpus.7 ConclusionThis article has described a first attempt of com-piling smart comparable corpora.
The quality isclose to a manually collected corpus, and the highdegree of comparability is guaranteed by a com-mon domain and topic, but also by a same type ofdiscourse.
In order to detect automatically some ofthe comparability levels, we carried out a stylisticand contrastive analysis and elaborated a typologyfor the characterization of scientific and popularscience types of discourse on the Web.
This typol-ogy is based on three aspects of Web documents:the structural aspect, the modal aspect and lexi-cal aspect.
From the modality part, this distinctionis operational even on linguistically distant lan-guages, as we proved by the validation on Frenchand Japanese.
Our typology, implemented usingSVMlight and C4.5 learning algorithms broughtsatisfactory results of classification, not only onthe training corpus but also on an evaluation cor-pus, since we obtained a precision on average of80% and a recall of 70%.
This classifier has thenbeen included into a tool to assist specialized com-parable corpora compilation.
Starting from a Webdocuments collection selected by the user, thistool realizes cleaning, normalization and linguis-tic treatment of each document and ?physically?creates the corpus.This tool is a first attempt and can be improved.In a first time, we would like to assist the selectionand collection of documents, which could be real-ized through the tool.
Moreover, we would like toinvestigate needs of comparable corpora users inorder to adapt our tool.
Finally, others languagescould be added to the system, which represents aquite time-consuming task: a classifier would haveto be created so all the linguistic analysis and clas-sification tasks would have to be done again forother languages.AcknowledgementThis research program has been funded by theFrench National Research Agency (ANR) throughthe C-mantic project (ANR-07-MDCO-002-01)2008-2010.
We thank Yukie Nakao for thejapanese corpus and linguistic resources.ReferencesArul Prakash Asirvatham and Kranthi Kumar Ravi.2001.
Web page classification based on documentstructure.
IEEE National Convention.Marco Baroni and Adam Kilgarriff.
2006.
Largelinguistically-processed web corpora for multiplelanguages.
In EACL?06, pages 87?90.
The Associa-tion for Computer Linguistics.Douglas Biber.
1988.
Variation across Speech andWriting.
Cambridge University Press.Lynne Bowker and Jennifer Pearson.
2002.
Workingwith Specialized Language: A Practical Guide toUsing Corpora.
London/New York, Routeledge.Eric Brill.
1994.
Some advances in transformation-based part of speech tagging.
In Proceedings of the12th National Conference on Artificial Intelligence(AAAI?94), pages 722?727, Seattle, WA, USA.Soumen Chakrabarti, Martin van den Berg, and ByronDom.
1999.
Focused crawling: a new approachto topic-specific Web resource discovery.
ComputerNetworks (Amsterdam, Netherlands: 1999), 31(11?16):1623?1640.Patrick Charaudeau.
1992.
Grammaire du sens et del?expression.
Hachette.62Yun-Chuang Chiao and Pierre Zweigenbaum.
2002.Looking for candidate translational equivalents inspecialized, comparable corpora.
In COLING?02,pages 1208?1212, Tapei, Taiwan.B?atrice Daille.
2000.
Morphological rule inductionfor terminology acquisition.
In COLING?00, pages215?221, Sarrbrucken, Germany.Herv?
D?jean, ?ric Gaussier, and Fatia Sadat.
2002.An approach based on multilingual thesauri andmodel combination for bilingual lexicon extraction.In COLING?02.Oswald Ducrot and Tzvetan Todorov.
1972.
Diction-naire encyclop?dique des sciences du langage.
?di-tions du Seuil.David Ferrucci and Adam Lally.
2004.
Uima: Anarchitectural approach to unstructured informationprocessing in the corporate research environment.Natural Language Engineering, 10:327?348.Pascale Fung and Lo Yuen Yee.
1998.
An ir approachfor translating new words from nonparallel, com-parable texts.
In Christian Boitet and Pete White-lock, editors, COLING?98, volume 1, pages 414?420, Montreal, Quebec, Canada.Kumiko Ishimaru.
2006.
Comparative study on thediscourse of advertisement in France and Japan:beauty products.
Ph.D. thesis, Osaka University,Japan.Thorsten Joachims.
2002.
Learning to Classify Textusing Support Vector Machines.
Kluwer AcademicPublishers.Jussi Karlgren, 1998.
Natural Language InformationRetrieval, chapter Stylistic Experiments in Informa-tion Retrieval.
Tomek, Kluwer.Sarah Laviosa.
1998.
Corpus-based approaches tocontrastive linguistics and translation studies.
Meta,43(4):474?479.Denise Malrieu and Francois Rastier.
2002.
Genres etvariations morphosyntaxiques.
Traitement Automa-tique des Langues (TAL), 42(2):548?577.Yuji Matsumoto, Akira Kitauchi, Tatsuo Yamashita,and Yoshitaka Hirano.
1999.
Japanese Morpho-logical Analysis System ChaSen 2.0 Users Manual.Technical report, Nara Institute of Science and Tech-nology (NAIST).Anthony McEnery and Zhonghua Xiao.
2007.
Par-allel and comparable corpora: What is happening?In Gunilla Anderman and Margaret Rogers, editors,Incorporating Corpora: The Linguist and the Trans-lator.
Clevedon: Multilingual Matters.Fiammetta Namer and Robert Baud.
2007.
Defin-ing and relating biomedical terms: Towards a cross-language morphosemantics-based system.
Interna-tional Journal of Medical Informatics, 76(2-3):226?233.Fiametta Namer.
2000.
Flemm : Un analyseur flexion-nel du fran?ais ?
base de r?gles.
Traitement Automa-tique des Langues (TAL), 41(2):523?548.Carol Peters and Eugenio Picchi.
1997.
Using lin-guistic tools and resources in cross-language re-trieval.
In David Hull and Doug Oard, editors,Cross-Language Text and Speech Retrieval.
Papersfrom the 1997 AAAI Spring Symposium, TechnicalReport SS-97-05, pages 179?188.J.
Ross Quinlan.
1993.
C4.5: Programs for MachineLearning.
Morgan Kaufmann Publishers, San Fran-cisco, CA, USA.Reinhard Rapp.
1999.
Automatic Identification ofWord Translations from Unrelated English and Ger-man Corpora.
In ACL?99, pages 519?526, CollegePark, Maryland, USA.Daniele Riboni.
2002.
Feature selection for webpage classification.
In Hassan Shafazand and A MinTjoa, editors, Proceedings of the 1st EurAsian Con-ference on Advances in Information and Communi-cation Technology (EURASIA-ICT), pages 473?478,Shiraz, Iran.
Springer.Jorge Vivaldi Rogelio Nazar and Teresa Cabr?.
2008.A suite to compile and analyze an lsp corpus.
InNicoletta Calzolari, Khalid Choukri, Bente Mae-gaard, Joseph Mariani, Jan Odjik, Stelios Piperidis,and Daniel Tapias, editors, Proceedings of the SixthInternational Language Resources and Evaluation(LREC?08), Marrakech, Morocco, may.
EuropeanLanguage Resources Association (ELRA).J.
C. Sager.
1990.
A Pratical Course in TerminologyProcessing.
John Benjamins, Amsterdam.Fabrizio Sebastiani.
2002.
Machine learning in au-tomated text categorization.
ACM Computing Sur-veys, 34(1):1?47.John Sinclair.
1996.
Preliminary recommendations ontext typology.
Technical report, EAGLES (ExpertAdvisory Group on Language Engineering Stan-dards).Federico Zanettin.
1998.
Bilingual comparablecorpora and the training of translators.
Meta,43(4):616?630.63
