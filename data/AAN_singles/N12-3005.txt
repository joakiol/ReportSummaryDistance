Proceedings of the NAACL-HLT 2012: Demonstration Session, pages 17?20,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsAn Interactive Humanoid Robot Exhibiting Flexible Sub-Dialogues?Heriberto Cuaya?huitlDFKI GmbHhecu01@dfki.deIvana Kruijff-Korbayova?DFKI GmbHivana.kruijff@dfki.deAbstractWe demonstrate a conversational humanoidrobot that allows users to follow their owndialogue structures.
Our system uses a hi-erarchy of reinforcement learning dialogueagents, which support transitions acrosssub-dialogues in order to relax the strict-ness of hierarchical control and thereforesupport flexible interactions.
We demon-strate our system with the Nao robot play-ing two versions of a Quiz game.
Whilstlanguage input and dialogue control is au-tonomous or wizarded, language output isprovided by the robot combining verbal andnon-verbal contributions.
The novel fea-tures in our system are (a) the flexibilitygiven to users to navigate flexibly in the in-teraction; and (b) a framework for investi-gating adaptive and flexible dialogues.1 IntroductionHierarchical Dialogue Control (HDC) consists ofbehaviours or discourse segments at different lev-els of granularity executed from higher to lowerlevel.
For example, a dialogue agent can invoke asub-dialogue agent, which can also invoke a sub-sub-dialogue agent, and so on.
Task-oriented di-alogues have shown evidence of following hierar-chical structures (Grosz and Sidner, 1986; Litmanand Allen, 1987; Clark, 1996).
Practically speak-ing, HDC offers the following benefits.
First,modularity helps to specify sub-dialogues thatmay be easier to specify than the entire full dia-logues.
Second, sub-dialogues may include onlyrelevant dialogue knowledge (e.g.
subsets of dia-logue acts), thus reducing significantly their com-?
*Funding by the EU-FP7 project ALIZ-E (ICT-248116)is gratefully acknowledged.
(a) strict hierachicaldialogue controlDialogueSub-dialogue1 Sub-dialogue2(b) flexible hierachicaldialogue controlDialogueSub-dialogue1 Sub-dialogue2Figure 1: Hierarchies of dialogue agents with strict(top down) and flexible control (partial top down).plexity.
Third, sub-dialogues can be reused whendealing with new behaviours.
In this paper we dis-tinguish two types of hierarchical dialogue con-trol: strict and flexible.
These two forms of dia-logue control are shown in Figure 1.
It can be ob-served that strict HDC is based on a pure top downexecution, and flexible HDC is based on a com-bined hierarchical and graph-based execution.The main limitation of strict HDC is thathuman-machine interactions are rigid, i.e.
theuser cannot change the imposed dialogue struc-ture.
A more natural way of interaction is by re-laxing the dialogue structure imposed by the con-versational machine.
The advantage of flexibleHDC is that interactions become less rigid be-cause it follows a partially specified hierarchicalcontrol, i.e.
the user is allowed to navigate acrossthe available sub-dialogues.
In addition, anotherimportant property of the latter form of HDC isthat we can model flexible dialogue structures notonly driven by the user but also by the machine.The latter requires the machine to learn the dia-logue structure in order to behave in an adaptiveway.
The rest of the paper describes a demo sys-tem exhibiting both types of behaviour, based ona reinforcement learning dialogue framework.172 Hierarchical Reinforcement LearningDialogue Agents with Flexible ControlOur dialogue controllers use hierarchical rein-forcement learning as in (Cuaya?huitl et al, 2010).We extend such a formalization through a hierar-chy of dialogue agents defined with the followingtuples: M ij = <Sij , Aij , T ij , Rij , Lij , U ij , ?ij , ?ij>,where Sij is a set of states, Aij is a set of actions,T ij is a stochastic state transition function, Rij isa reward function, Lij is a grammar that specifiestree-based state representations, U ij is a finite setof user actions (e.g.
user dialogue acts), ?ij is afinite set of models that subtask M ij is being al-lowed to transition to, and ?ij = P (m?
?
?ij |m ?
?ij , u ?
U ij) is a stochastic model transition func-tion1 that specifies the next model m?
given modelm and user action u.
Although the hierarchy ofagents can be fully-connected when all modelsare allowed to transition from a given particu-lar model (avoiding self-transitions), in practice,we may want our hierarchy of agents partially-connected, i.e.
when ?ij is a subset of subtasksthat agent M ij is allowed to transition to.We implemented a modified version of theHSMQ-Learning algorithm (Dietterich, 2000) tosimultaneously learn a hierarchy of policies piij .This algorithm uses a stack of subtasks and op-erates as illustrated in Figure 2.
If during the ex-ecution of a subtask the user decides to jump toanother subtask, i.e.
to change to another sub-dialogue, the flexible execution of subtasks allowseach subtask to be interrupted in two ways.
In thefirst case, we check whether the new (active) sub-task is already on the stack of subtasks to execute.This would be the case if it was a parent of thecurrent subtask.
In this case, we terminate exe-cution of all intervening subtasks until we reachthe parent subtask, which would be the new ac-tive subtask.
Notice that termination of all inter-vening subtasks prevents the stack from growinginfinitely.
In the second case, the current subtaskis put on hold, and if the new active subtask isnot already on the stack of subtasks to execute, itis pushed onto the stack and control is passed toit.
Once the new subtask terminates its execution,control is transferred back to the subtask on hold.1This is a very relevant feature in dialogue agents in orderto allow users to say and/or do anything at anytime, and thelearning agents have to behave accordingly.InitialstackPushing'dialogue'Pushing'sub-dialogue1'Pushing'sub-dialogue2'(two siblingsin the stack)Popping'sub-dialogue2'Popping'sub-dialogue1'Popping'dialogue'dialogue dialogue dialogue dialogue dialoguesub-dialogue1sub-dialogue1sub-dialogue2sub-dialogue1Figure 2: Hypothetical operations of stack-based hier-archical dialogue controllers.
Whilst the fourth opera-tion from left to right is not allowed in strict HDC, allstack operations are allowed in flexible HDC.These kinds of transitions can be seen as high-level transitions in the state space.
They can alsobe seen as the mechanism to transition from anystate to any other in the hierarchy.
To do that wemaintain an activity status for each subtask M ij ,where only one subtask is allowed to be active ata time.
We maintain a knowledge-rich state thatkeeps the dialogue history in order to initializeor reinitialize states of each subtask accordingly.Since there is learning when new subtasks are in-voked and no learning when they are interrupted,this algorithm maintains its convergence proper-ties to optimal context-independent policies.3 A Hierarchy of Dialogue Agents forPlaying Quiz GamesWe use a small hierarchy of dialogue agents?for illustration purposes?with one parent agentand two children agents (?robot asks?
and ?userasks?).
Thus, the hierarchy of agents can ask theuser questions, and vice-versa, the user can askthe robot questions (described in the next section).Both conversants can play multiple rounds with apredefined number of questions.Due to space restrictions, we describe the hi-erarchy of agents only briefly.
The set of statesand actions use relational representations (theycan be seen as trees) in order to specify thestate-action space compactly, which can grow asmore features or games are integrated.
Dialogueand game features are included so as to informthe agents of possible situations in the interac-tion.
The action sets use constrained spaces, i.e.only a subset of actions is available at each statebased on the relational representations.
For ex-ample, the action Request(PlayGame) ?
x0is valid for the dialogue state x0 expressed asSalutation(greeting)?UserName(known)?PlayGame(unknown).
The sets of primitiveactions (80 in total) assume verbal behaviours18with a mapping to non-verbal ones, some sam-ple dialogue act types are as follows: requests,apologies, confirmations, provide information,acknowledgements, feedback, non-verbal expres-sions, game-related actions.
The transition func-tions use pre-defined parameters, their trainingfrom data is left as future work.
The reward func-tion addresses efficient and effective interactionsby penalizing dialogue length and encouraging tocontinue playing.
The dialogue agents learnt theirbehaviour by interacting with a stochastic simu-lated user, where the user responses eventuallyrequired transitions across agents.
A sample dia-logue with flexible interaction is shown in Fig.
3.4 A Humanoid Robot Integrated SystemFigure 4 shows the robot?s integrated system,which equips the robot with the following capa-bilities: listening, talking, seeing and moving.2 Asample interaction assuming wizarded behaviouris as follows.
The user says something to the robot(e.g.
?ask me a question?)
and the wizard selectsa user dialogue act for the corresponding utter-ance such as ?Request(Question)?.
Then the di-alogue manager selects and executes the learnedaction by querying/updating the game move gen-erator and user model components, and by pass-ing a dialogue act to the language generation andmotor control components.
The former providesthe corresponding text to the speech synthesizerand the latter provides the corresponding non-verbal behaviour.
Then the dialogue manager ob-serves its new dialogue state, and suggests thenext actions?based on its dialogue policies anduser simulations?in the wizard-of-Oz GUI, seeFigure 5.
From this setting, if we remove thewizard then the system can behave autonomously,where user inputs are derived from the languageand gesture understanding components.The attractiveness of this kind of set-up is thesmooth transition from purely wizarded conver-sational behaviour to fully autonomous behaviour,where the dialogue policies can be tested and eval-2We use off-the-shelf technologies such as Sphinx /Julius / HTK for speech recognition, OpenCV for ges-ture recognition, Acapela and Mary for speech synthe-sis, HRL-based dialogue management (as described above),OpenCCG for language parsing and language generation,Weka and JavaBayes for maintaining a probabilistic and per-sonalized user profile of asked and answered questions, theURBI middleware (www.gostai.com), and the NAO hu-manoid robot (www.aldebaran-robotics.com).SYS Hi, my name is NAO, and you?USR I am PeterSYS Nice to meet you PeterDo you want to Play a Quiz game?USR Ask me questions [jump to ?robot asks?
]SYS The first question is.What is a typical magic instrument?Your choices are: One, guitar.
Two, drums.Three ,violin.
Four, flute.
What is your choice?USR Number twoSYS That is not quite right.
Do you have another choice?USR Maybe number threeSYS The correct answer is number four, flute.The next question is: which one of these isan important artificial channel of the central America?Your choices are: One, channel five.
Two, Panama canal.Three, Suez canal.
Four, English channel.What is your choice?USR Now I want to ask you questions [jump to ?user asks?
]SYS Ask me the first question.USR What does water become at the temperature ofzero degrees?SYS What are my choices?USR Your choices are:One, condensation.
Two, ice.
Three, steam.SYS I choose number oneUSR That is incorrect.SYS So what is the right answer?USR The correct answer is number two.SYS Okay, ask me another question.USR The next question is: through which breach didthe Italian army entered into Rome in 1870?Your choices are: One, porta venezia.
Two, porta pia.Three, porta pazienza.
Four, porta nuova.What is your choice?SYS ParisUSR Let?s stop playing.
[jump to ?root?
]SYS Did you like playing the Quiz Game?USR YesSYS I am glad to hear that.SYS It was nice playing with you, see you soon.
Bye!Figure 3: Sample dialogue with non-strict hierarchicalcontrol.
The groups of utterances represent activityin different sub-dialogues in the hierarchy of agents.Note that the user is allowed to override the imposeddialogue structure.
For instance, when the user says?Ask me questions?
the agent interrupts the executionof the root subtask and transitions to the subtask ?robotasks?.
Similarly, the sub-dialogues do not need to followtheir imposed structure and the user is allowed to talkabout previous and unadressed sub-dialogues such asthe sudden switch from ?robot asks?
to ?user asks?.MiddlewareSpeech Recognizer,Voice Act.
Detector,Audio Front EndGestureRecognizerMotorControlSpeechSynthesizerGame MoveGeneratorDialogue ManagerParser,Dialogue ActClassifierLanguageGeneratorUserModelWizard-of-OzGUIASRresultGestureactSystemDialogueactTextASRresultGestureActSystemdialogueActTextUserdialogueactDialogue acts Systemdialogueactuser,gameresultsquery,questions,answersFigure 4: High-level architecture of our talking robot.19Figure 5: Screen shot of the wizard-of-Oz GUI, wherethe dialogue policies and user simulations suggesthighlighted actions to the wizard.
This setting allowsfully-wizarded and (semi-) autonomous behaviour.Figure 6: The Nao robot greeting a user prior to play-ing a Quiz game.
The pieces of paper on the table arethe Quiz questions the child asks the robot.uated with (semi-) autonomous behaviour.
We usethis framework to investigate long-term human-robot interaction, in particular child-robot inter-actions for educational purposes.
Figure 6 showsa scene from a pilot evaluation, where the robotand a child are visibly engaged with each other.
Acomplete evaluation with simulated and real dia-logues will be reported in a forthcoming paper.5 Discussion and SummaryTypically, conversational interfaces impose a di-alogue structure on the user.
Even in dialoguesystems with mixed-initiative interaction that giveflexibility to the user in terms of providing morethan one piece of information at a time, theuser is hardly allowed to navigate flexibly duringthe interaction.
Notable exceptions without dia-logue optimization are (Rudnicky and Wu, 1999;Lemon et al, 2001; Larsson, 2002; Foster et al,2006).
We believe that Hierarchical Reinforce-ment Learning with global state transitions is aninteresting method to optimize (sub-) dialogues atdifferent levels of granularity, where the design ofaction selection might not be easy to hand-craft.On the one hand, our HDCs can be applied todialogues with user-driven topic shift, where theuser can take control of the interaction by navigat-ing across sub-dialogues and the system has to re-spond accordingly.
On the other hand, our HDCscan be applied to dialogues with system-driventopic shift, where the system can itself terminate asub-dialogue, perhaps by inferring the user?s emo-tional and/or situational state, and the system hasto switch itself to another sub-dialogue.We have described a conversational humanoidrobot that allows users to follow their own dia-logue structures.
The novelty in our system isits flexible hierarchical dialogue controller, whichextends strict hierarchical control with transitionsacross sub-controllers.
Suggested future workconsists in training and evaluating our humanoidrobot from real interactions using either partiallyspecified or fully learnt dialogue structures.ReferencesH.
Clark.
1996.
Using Language.
Cambridge Univer-sity Press.H.
Cuaya?huitl, S. Renals, O.
Lemon, and H. Shi-modaira.
2010.
Evaluation of a hierarchical rein-forcement learning spoken dialogue system.
Com-puter Speech and Language, 24(2):395?429.T.
Dietterich.
2000.
An overview of MAXQ hi-erarchical reinforcement learning.
In Symposiumon Abstraction, Reformulation, and Approximation(SARA), pages 26?44.M.
E. Foster, T. By, M. Rickert, and A. Knoll.
2006.Human-robot dialogue for joint construction tasks.In ICMI, pages 68?71.B.
Grosz and C. Sidner.
1986.
Attention, intentionsand the structure of discourse.
Computational Lin-guistics, 12(3):175?204.S.
Larsson.
2002.
Issue-Based Dialogue Manage-ment.
Ph.D. thesis, University of Goteborg.O.
Lemon, A. Bracy, A. Gruenstein, and S. Peters.2001.
The WITAS multi-modal dialogue system I.In EUROSPEECH, Aalborg, Denmark.D.
Litman and J. Allen.
1987.
A plan recognitionmodel for subdialogues in conversations.
CognitiveScience, 11:163?200.A.
Rudnicky and W. Wu.
1999.
An agenda-baseddialogue management architecture for spoken lan-guage systems.
In IEEE Workshop on AutomaticSpeech Recognition and Understanding (ASRU),pages 337?340, Keystone, Colorado, USA, Dec.20
