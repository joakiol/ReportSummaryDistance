COMPUTATIONAL COMPLEXITY  IN TWO-LEVELMORPHOLOGYG.
Edward Barton, Jr.M.I.T.
Artificial Intelligence Laboratory545 Technology SquareCambridge, MA 02139ABSTRACTMorphological analysis must take into account thespelling-change processes of a language as well as its possi-ble configurations of stems, affixes, and inflectional mark-ings.
The computational difficulty of the task can be clari-fied by investigating specific models of morphological pro-cessing.
The use of finite-state machinery in the "two-level" model by K immo Koskenniemi gives it the appear-ance of computational efficiency, but closer examinationshows the model does not guarantee efficient processing.Reductions of the satisfiability problem show that findingthe proper lexical/surface correspondence in a two-levelgeneration or recognition problem can be computationallydifficult.
The difficulty increases if unrestricted deletions(null characters) are allowed.INTRODUCTIONThe "dictionary lookup" stage in a natural-languagesystem can involve much more than simple retrieval.
In-flectional endings, prefixes, suffixes, spelling-change pro-cesses, reduplication, on-concatenative morphology, andclitics may cause familiar words to show up in heavily dis-guised form, requiring substantial morphological nalysis.Superficially, it seems that word recognition might poten-tially be complicated and difficult.This paper examines the question more formally by in-vestigating the computational characteristics of the "two-level" model of morphological processes.
Given the kindsof constraints that can be encoded in two-level systems,how difficult could it be to translate between lexical andsurface forms?
Although the use of finite-state machin-ery in the two-level model gives it the appearance of com-putational efficiency, the model itself does not guaranteeefficient processing.
Taking the Kimmo system (Kart-tunen, 1983) for concreteness, it will be shown that thegeneral problem of mapping between \]exical and surfaceforms in two-level systems is computationally difficult inthe worst case; extensive backtracking is possible.
If nullcharacters are excluded, the generation and recognitionproblems are NP-complete in the worst case.
If null charac-ters are completely unrestricted, the problems is PSPACE-complete, thus probably even harder.
The fundamentaldifficulty of the problems does not seem to be a precompi-lation effect.In addition to knowing the stems, affixes, and co-occurrence restrictions of a language, a successful morpho-logical analyzer must take into account he spelling-changeprocesses that often accompany affixation.
In English,the program must expect love+ing to appear as loving,fly+s as flies, lie+ing as lying, and big+er as bigger.Its knowledge must be sufficiently sophisticated to distin-guish such surface forms as hopped and hoped.
Cross-linguistically, spelllng-change processes may span either alimited or a more extended range of characters, and thematerial that triggers a change may occur either before orafter the character that is affected.
(Reduplication, a com-plex copying process that may also be found, will not beconsidered here.
)The K immo system described by Karttunen (1983} isattractive for putting morphological knowledge to use inprocessing.
K immo is an implementation of the "two-level"model of morphology that K immo Koskenniemi proposedand developed in his Ph.D. thesis.
I A system of lexicons inthe dictionary component  regulates the sequence of rootsand affixes at the lexical level, while several finite-statetransducers in the automaton component -- ~ 20 transduc-ers for Finnish, for instance -- mediate the correspondencebetween lexical and surface forms.
Null characters allowthe automata to handle insertion and deletion processes.The overall system can be used either for generation or forrecognition.The finite-state transducers of the automaton compo-nent serve to implement spelling changes, which may betriggered by either left or right context and which mayignore irrelevant intervening characters.
As an example,the following automaton describes a simplified "Y-change"process that changes y to i before suffix es:IUniversity of Helsinki, Finland, circa Fall 1983.53"Y-Change" 5 5y y * s = ( lexicalcharacters)i y = s = (surface characters)state 1: 2 4 1 1 1 (normal state)state 2.
0 0 3 0 0 (require *s)state 3.
0 0 0 1 0 (require s)state 4: 2 4 8 1 1 ( forb id+s)state S: 2 4 1 0 1 ( fo rb ids )The details of this notation will not be explained here;basic familiarity with the Kimmo system is assumed.
Forfurther introduction, see Barton (1985), Karttunen (1983),and references cited therein.THE SEEDSOF  COMPLEXITYAt first glance, the finite-state machines of the two-level model appear to promise unfailing computational ef-ficiency.
Both recognition and generation are built on thesimple process of stepping the machines through the input.Lexical lookup is also fast, interleaved character by charac-ter with the quick left-to-right steps of the automata.
Thefundamental efficiency of finite-state machines promises tomake the speed of Kimmo processing largely independentof the nature of the constraints hat the automata encode:The most important technical feature of Kosken-niemi's and our implementation f the Two-levelmodel is that morphological rules are representedin the processor as automata, more specifically, asfinite state transducers .
.
.
.
One important conse-quence of compiling \[the grammar ules into au-tomata\] is that the complexity of the linguistic de-scription of a language has no significant effect onthe speed at which the forms of that language canbe recognized or generated.
This is due to the factthat finite state machines are very fast to operatebecause of their simplicity .
.
.
.
Although Finnish,for example, is morphologically a much more com-plicated language than English, there is no differ-ence of the same magnitude in the processing timesfor the two languages .
.
.
.
\[This fact\] has some psy-cholinguistie nterest because of the common senseobservation that we talk about "simple" and "com-plex" languages but not about "fast" and "slow"ones.
(Karttunen, 1983:166f)For this kind of interest in the model to be sustained, itmust be the model itself that wipes out processing diffi-culty, rather than some accidental property of the encodedmorphological constraints.Examined in detail, the runtime complexity of Kimmoprocessing can be traced to three main sources.
The rec-ognizer and generator must both run the finite-state ma-chines of the automaton component; in addition, the recog-nizer must descend the letter trees that make up a lexicon.The recognizer must also decide which suffix lexicon to ex-plore at the end of an entry.
Finally, both the recognizerand the generator must discover the correct lexical-surfacecorrespondence.All these aspects of runtime processing are apparentin traces of implemented Kimmo recognition, for instancewhen the recognizer analyzes the English surface formsp ie l  (in 61 steps) according to Karttunen and Witten-burg's (1983) analysis (Figure 1).
The stepping of trans-ducers and letter-trees i ubiquitous.
The search for thelexical-surface orrespondence is also clearly displayed; forexample, before backtracking to discover the correct lexi-cal entry sp ie l ,  the recognizer considers the lexical stringspy+ with y surfacing as i and + as e. Finally, after findingthe putative root spy the recognizer must decide whetherto search the lexicon I that contains the zero verbal endingof the present indicative, the lexicon AG storing the agen-tive suffix *er, or one of several other lexicons inhabitedby inflectional endings uch as +ed.The finite-state framework makes it easy to step theautomata; the letter-trees are likewise computationallywell-behaved.
It is more troublesome to navigate throughthe lexicons of the dictionary component, and the cur-rent implementation spends considerable time wanderingabout.
However, changing the implementation f the dic-tionary component can sharply reduce this source of com-plexity; a merged dictionary with bit-vectors reduces thenumber of choices among alternative l xicons by allowingseveral to be searched at once (Barton, 1985).More ominous with respect o worst-case behavior isthe backtracking that results from local ambiguity in theconstruction of the lexical-surface correspondence.
Evenif only one possibility is globally compatible with the con-straints imposed by the lexicon and the automata, theremay not be enough evidence at every point in processingto choose the correct lexical-surface pair.
Search behaviorresults.In English examples, misguided search subtrees arenecessarily shallow because the relevant spelling-changeprocesses are local in character.
Since long-distance har-mony processes are also possible, there can potentially bea long interval before the acceptability of a lexical-surfaeepair is ultimately determined.
For instance, when vowelalternations within a verb stem are conditioned by the oc-currence of particular tense suffixes, the recognizer mustsometimes see the end of the word before making final de-cisions about the stem.54Recognizing surface form "sp ie l " .1 s 1 .4 .1 .2 .1 .12 sp 1 .1 .1 .2 .1 .13 spy 1.3 .4 .3 .1 .14 "spy" ends, new lelXlCOn N5 "0" ends.
new lex icon C16 spy XXX extra  input7 (5) spy+ 1.5.16.4.1.18 spy+ XXX9 (5) spy + 1.8.1.4.1.110 spy+ XXX11 (4) "spy" ends, new lextcon 112 spy XXX extra  tnput13 (4) "spy" ends, new lex icon P314 spy+ 1.6.1.4.1.115 spy+ XXX16 (14) spy+ 1,8 .18.4 .1 .117 spy+ XXX18 (4) "spy" ends, new lextcon PS19 spy+ 1.6.1.4.1.120 spy+e 1.1.1.1.4.1Zl spy+e XXX22 (20) spy?e 1.1 .4 .1 .3 .123 spy+e XXX24 (19) spy+ 1.8.16.4.1.125 spy+e XXX Epenthesls26 (4) "spy" ends, new lex icon PP27 spy+ 1.6.1.4.1.128 spy+e 1.1.1.1.4.1zg spy+e XXX30 (28) spy+e 1.1.4.1.3.131 spy+e XXX32 (27) spy+ 1.8.18.4.1.133 spy+e XXX Epenthests34 (4) "spy" ends.
new lex icon PR35 spy+ 1 .6 .1 .4 ,1 ,136 spy+ XXX37 (38) spy+ 1.8.16.4.1.138 spy+ XXX39 (4) "spy" ends.
new lextcon AG40 spy+ 1 .6 .1 .4 .1 .
I41 spy+e 1.1.1.1.4.142 spy+e XXX43 (41) spy+e 1 .1 .4 ,1 .3 ,144 spy+e XXX45 (40) spy+ 1.8.16.4.1.146 spy+e XXX Epenthests47 (4) "spy" ends.
new lextcon AB48 spy+ 1,8.1.4.1.149 spy+ XXX50 (48) Spy+ 1 ,5 .18 .4 .1 .151 spy?
XXX52 (3) spt 1 .1 .4 .1 .2 .853 spte 1.1.16.1.6.154 spte XXX58 (53) sple 1.1.16.1.5.656 spiel  1.1.16.2, I. I57 "sp ie l "  ends.
new lextcon N58 "0" ends.
new lex icon Cl59 "spiel" *** resu l t60 (58) spie l+ 1.1.18.1.1.161 spiel+ XXX" - -+- - '+- - -+ ILL+LLL+I I I+-~-+xxx+ l---+XXX+LLL+\]H+ILLL?---+XXX?-~-+XXX+LLL+---+-*-+XXX+_l_+xxx?-o-+AAA+LLL+---+---+XXX+!
:i:: ,x,.LLL+---+XXX+-!-+XXX+LLL+---+---?XXX+I ---?XlX+- - -+---+XXX+I- - -+-- -+LLL+LLL+**-?I ---+XXX+Key to t ree nodes:- - -  normal t reversa lLLL new lexiconAAA blocking by automataXXX no lexlcal-surface pai rscompatible with surfacechar and dictionaryIII blocking by leftover input*'* analys is  found(("spiel" (N SG)))Figure \]: These traces show the steps that the KIMMOrecognizer for English goes through whileanalyzing the surface form sp ie l .
Each llne of the table oil the left shows the le\]dcal string andautomaton states at the end of a step.
If some autoz,mton blocked, the automaton states axe replacedby ~, XXI entry.
An XXX entry with no autonmto,, n:une indicates that the \]exical string could notbc extended becau,~e the surface c\],aracter .
'tnd h,xical letter tree together ruh'd out ,-dl feasible p,'drs.After xn XXX or *** entry, the recognizer backtracks and picks up from a previous choice point.indicated by the paxenthesized step l*lU,zl)er before the lexical .~tring.
The tree Ol, the right depictsthe search graphically, reading from left to right and top t .
\])ottoln with vertir;d b;trs linking thechoices at each choice point  The flhntres were generated witl, a \](IM M() hnplen*entation written i ,  an;I.llgll*t,llter| version of MACI,ISI'I,t,sed initiMly on Kltrttllnel*',,?
(1983:182ff) ;dgorithni description; thediction;n'y m.l antomaton contpouents for E,glish were taken front 1.;artt,ne, and Wittenlmrg (1983)with minor ('llikllgCS.
This iJz*ple*l*Vl*tatio*) se;u'?h(.s del.th-tlr,~t a,s Kmttu ,en 's  does, but explores theMternatives at a giwm depth in a different order from Karttttnen's.55?
IIgnoring the problem of choosing among alternativelexicons, it is easy to see that the use of finite-state ma-chinery helps control only one of the two remaining sourcesof complexity.
Stepping the automata should be fast, butthe finite-state framework does not guarantee speed in thetask of guessing the correct lexical-surface orrespondence.The search required to find the correspondence may pre-dominate.
In fact, the Kimmo recognition and generationproblems bear an uncomfortable r semblance to problemsin the computational class NP.
Informally, problems in NPhave solutions that may be hard to guess but are easy toverify - -  just the situation that might hold in the discov-ery of a Kimmo lexical-surface correspondence, since theautomata can verify an acceptable correspondence quicklybut may need search to discover one.THE COMPLEXITYOFTWO-LEVEL  MORPHOLOGYThe Kimmo algorithms contain the seeds of complex-ity, for local evidence does not always show how to con-struct a lexical-surface correspondence that will satisfythe constraints expressed in a set of two-level automata.These seeds can be exploited in mathematical reductionsto show that two-level automata can describe computa-tionally difficult problems in a very natural way.
It fol-lows that the finite-state two-level framework itself cannotguarantee computational efficiency.
If the words of naturallanguages are easy to analyze, the efficiency of processingmust result from some additional property that naturallanguages have, beyond those that are captured in the two-level model.
Otherwise, computationally difficult problemsmight turn up in the two-level automata for some naturallanguage, just as they do in the artificially constructed lan-guages here.
In fact, the reductions are abstractly modeledon the Kimmo treatment of harmony processes and otherlong-distance dependencies in natural anguages.The reductions use the computationally difficultBoolean satisfiability problems SAT and 3SAT, which in-volve deciding whether a CNF formula has a satisfyingtruth-assignment.
It is easy to encode an arbitrary SATproblem as a Kimmo generation problem, hence the gen-eral problem of mapping from lexical to surface forms inKimmo systems i  NP-complete.
2 Given a CNF formula ~,first construct a string o by notational translation: use aminus sign for negation, a comma for conjunction, and noexplicit operator for disjunction.
Then the o correspondingto the formula (~ v y)&(~ v z)&(x  v y v z) is -xy .
-yz  .xyz.2Membership in NP is also required for this conclusion.
A latersection ("The Effect of Nulls ~) shows membership in NP by sketchinghow a nondeterministic machine could quickly solve Kimmo generationand recognition problems.The notation is unambiguous without parentheses becauseis required to be in CNF.
Second, construct a Kimmoautomaton component A in three parts.
(A varies fromformula to formula only when the formulas involve differ-ent sets of variables.)
The alphabet specification shouldlist the variables in a together with the special charactersT, F, minus sign, and comma; the equals sign should bedeclared as the Kimmo wildcard character, as usual.
Theconsistency automata, one for each variable in a, shouldbe constructed on the following model:"x-consistency" 3 3x x = (lezical characters)T F = (surface characters}1: 2 3 1 (x undecided}2: 2 0 2 (x true}3: 0 3 3 (xfa lsc}The consistency automaton for variable x constrains themapping from variables in the lexical string to truth-valuesin the surface string, ensuring that whatever value is as-signed to x in one occurrence must be assigned to x inevery occurrence.
Finally, use the following satisfactionautomaton, which does not vary from formula to formula:"satisfaction" 3 4= = , (lexical characters}T F , (surface characters}1.
2 1 3 0 (no true seen in this group)2: 2 2 2 1 (true seen in this group}3.
1 2 0 0 (-F counts as true)The satisfaction automaton determines whether the truth-values assigned to the variables cause the formula to comeout true.
Since the formula is in CNF, the requirement isthat the groups between commas must all contain at leastone true value.The net result of the constraints imposed by the consis-tency and satisfaction automata is that some surface stringcan be generated from a just in case the original formulahas a satisfying truth-assignment.
Furthermore, A and ocan be constructed in time polynomial in the length of ~;thus SAT is polynomial-time reduced to the Kimmo gener-ation problem, and the general case of Kimmo generationis at least as hard as SAT.
Incidentally, note that it is localrather than global ambiguity that causes trouble; the gen-erator system in the reduction can go through quite a bit ofsearch even when there is just one final answer.
Figure 2traces the operation of the Kimmo generation algorithmon a (uniquely) satisfiable formula.Like the generator, the Kimmo recognizer can also beused to solve computationally difficult problems.
One easyreduction treats 3SAT rather than SAT, uses negated al-phabet symbols instead of a negation sign, and replacesthe satisfaction automaton with constraints from the dic-tionary component; see Barton (1985) for details.56Generating from lexical form "-xy.
-yz.
-y-z,xyz"1 1,1 .1 ,3  38 +234567 +8g10l l12 +131415 +161718 +l g20 +2122 +2324 (8)25262728 +293031 +323334 +3536 +37-F-FF-FF,-FF, --FF, -T-FF, -F-FF, -FF-FF, -FF.-FF, -FF,-FF, -FF,-FF, -FF,-FF -FF,-FF -FF,-FF -FF,-FF -FF,-FF-FF-FF-FF-FF-FF-FF-FF-FF-FF-FF-FF-FF-FF-FF-FF-FF-FF-FF-FF-FF3 ,1 ,1 ,2  3g3 .3 ,1 ,2  40 (3)3 ,3 ,1 .1  413 ,3 ,1 ,3  42XXX y-con.
433,3,1 ,2  44 +3,3 ,3 ,2  453 ,3 .3 ,1  46- 3,3 ,3 ,3  47 (45)-T XXX y-con.
48-F 3,3 ,3 ,2  49-F- 3,3 ,3 ,2  50-F-T XXX z-con.
51 +-F-F 3 ,3 ,3 ,2  52-F -F ,  3,3 .3 ,1  53-FF, -F-F,T XXX x-con.
54 +-FF,-F-F,F 3 ,3 ,3 ,1  55-FF,-F-F,FT XXX y-con.
56 (2)-FF, -F-F,FF 3,3,3,1 57-FF,-F-F,FFT XXX z-con.
58-FF,-F-F,FFF 3,3,3,1 5g (57)-FF,-F-F,FFF XXX satis, nf.
60-FT 3,3 ,2 ,2  61-FT, 3,3,2,1 62-FT,- 3 ,3 ,2 ,3  63 +-FT,-T XXX y-con.
64-FT,-F 3 ,3 ,2 ,2  65-FT,-F- 3 ,3 ,2 ,2  66 (64)-FT,-F-F XXX z-con.
67-FT,-F-T 3 ,3 ,2 ,2  68-FT,-F-T. 3,3,2,1 6g-FT,-F-T,T XXX x-con.
70 +-FT,-F-T,F 3,3,2,1 71-FT,-F-T,FT XXX y-con.
72-FT,-F-T,FF 3,3,2,1 73 +-FT,-F-T,FFF XXX z-con.
74-FF,-FT,-F-T,FFT 3,3,2,2"-FF,-FT,-F-T,FFT" *** result-FT-FT,-FT, --FT, -F-FT, -T-FT -TF-FT -TF,-FT -TT-FT -TT,-FT -TT, --FT -TT, -F-FT -TT, -T-FT -TT,-T--FT -TT,-T-F-FT -TT,-T-T-FT -TT,-T-T,-T-TF-TF,-TT-TT-TT --TT -F-TT -T-TT -TF-TT -TF,-TT -TT-TT -TT.-TT -TT, --TT -TT, -F-TT -TT, -T-TT -TT,-T--TT -TT,-T-F-TT -TT.-T-T-TT -TT,-T-T,3,2,1 ,23,2,1,13,2,1,3XXX y-con.3.2,1,13,2,3,1XXX satis.3,2,2,23,2,2,13,2,2,3XXX y-con.3,2,2,13,2 ,2 .3XXX z-con.3,2 ,2 ,1XXX saris.2,1,1,12,3 ,1 ,1XXX saris.2,2,1 ,22,2,1,12,2,1,3XXX y-con.2,2,1,12,2,3,1XXX sar i s .2 ,2,2,22,2,2,12,2,2,3XXX y-con.2,2,2,12,2.2,3XXXz-eon.2,2,2,1XXX satis.
("-FF,-FT,-F-T, FFT" )Figure 2: The generator system for deciding the satisfiability of Boolean formulas in x, y,and z goes through these steps when applied to the encoded version of the (satisfiable) formula(5 V y)&(~ V z)&(~ V ~)&(z V y V z).
Though only one truth-assignment will satisfy the formula,it takes quite a bit of backtracking to find it.
The notation used here for describing enerator actions issimilar to that used to describe recognizer actions in Figure ?
?, but a surface rather than a lexical stringis the goal.
A *-entry in the backtracking column indicates backtracking from an immediate failure in thepreceding step, which does not require the full backtracking mechanism to be invoked.THE EFFECTOF PRECOMPILAT IONSince the above reductions require both the lan-guage description and the input string to vary with theSAT/3SAT problem to be solved, there arises the questionof whether some computational ly intensive form of pre-compilation could blunt the force of the reduction, payinga large compilation cost once and allowing Kimmo run-t ime for a fixed grammar to be uniformly fast thereafter.This section considers four aspects of the precompilationquestion.First, the external description of a K immo automatoror lexicon is not the same as the form used at runtime.
In-stead, the external descriptions are converted to internalforms: RMACHINE and GMACHINE forms for automata,letter trees for lexicons (Gajek et al, 1983).
Hence thecomplexity implied by the reduction might actually applyto the construction of these internal forms; the complexityof the generation problem (for instance) might be concen-trated in the construction of the "feasible-pair list" andthe GMACHINE.
This possibility can be disposed of byreformulating the reduction so that the formal problemsand the construction specify machines in terms of their in-ternal forms rather than their external descriptions.
TheGMACHINEs for the class of machines created in the con-struction have a regular structure, and it is easy to buildthem directly instead of building descriptions in external"format.
As traces of recognizer operation suggest, it isruntime processing that makes translated SAT problemsdifficult for a K immo system to solve.Second, there is another kind of preprocessing thatmight be expected to help.
It is possible to compile aset of K immo automata into a single large automaton (aB IGMACHINE)  that will run faster than the original set.The system will usually run faster with one large automa-ton than with several small ones, since it has only onemachine to step and the speed of stepping a machine islargely independent of its size.
Since it can take exponen-tial t ime to build the B IGMACHINE for a translated SATproblem, the reduction formally allows the possibility thatB IGMACHINE precompilation could make runtime pro-57cessing uniformly efficient.
However, an expensive BIG-MACH\]NE precompilation step does not help runtime pro-cessing enough to change the fundamental complexity ofthe algorithms.
Recall that the main ingredients of Kimmoruntime complexity are the mechanical operation of theautomata, the difficulty of finding the right lexical-surfacecorrespondence, and the necessity of choosing among alter-native lexicons.
BIGMACHINE precompilation will speedup the mechanical operation of the automata, but it willnot help in the difficult task of deciding which lexical-surface pair will be globally acceptable.
Precompilationoils the machinery, but accomplishes no radical changes.Third, BIGMACHINE precompilation also sheds lighton another precompilation question.
Though B\]GMA-CHINE precompilation i volves exponential b owup in theworst case (for example, with the SAT automata), in prac-tice the size of the BIGMACHINE varies - -  thus naturallyraising the question of what distinguishes the "explosive"sets of automata from those with more civilized behav-ior.
It is sometimes suggested that the degree of inter-action among constraints determines the amount of BIG-MACHINE blowup.
Since the computational difficulty ofSAT problems results in large measure from their "global"character, the size of the BIGMACHINE for the SAT sys-tem comes as no surprise under the interaction theory.However, a slight change in the SAT automata demon-strates that BIGMACHINE size is not a good measureof interaction among constraints.
Eliminate the satisfac-tion automaton from the generator system, leaving onlythe consistency automata for the variables.
Then the sys-tem will not search for a satisfying truth-assignment, butmerely for one that is internally consistent.
This changeentirely eliminates interactions among the automata; yetthe BIGMACHINE must still be exponentially larger thanthe collection of individual automata, for its states mustdistinguish all the possible truth-assignments to the vari-ables in order to enforce consistency.
In fact, the lack ofinteractions can actually increase the size of the BIGMA-CHINE, since interactions constrain the set of reachablestate-combinations.Finally, it is worth considering whether the nondeter-minism involved in constructing the lexical-surface cor-respondence can be removed by standard determiniza-tion techniques.
Every nondeterministic f nite-state ma-chine has a deterministic counterpart that is equivalent inthe weak sense that it accepts the same language; aren'tKimmo automata just ordinary finite-state machines op-erating over an alphabet that consists of pairs of ordinarycharacters?
Ignoring subtleties associated with null char-acters, Kimmo automata can indeed be viewed in this waywhen they are used to verify or reject hypothesized pairs oflexical and surface strings.
However, in this use they do notneed determinizing, for each cell of an automaton descrip-tion already lists just one state.
In the cases of primaryinterest - -  generation and recognition - - the machines areused as genuine transducers rather than acceptors.The determinizing algorithms that apply to finite-stateacceptors will not work on transducers, and in fact manyfinite-state transducers are not determinizable at all.
Uponseeing the first occurrence of a variable in a SAT problem,a deterministic transducer cannot know in general whetherto output T or F. It also cannot wait and output a truth-value later, since the variable might occur an unboundednumber of times before there was sufficient evidence toassign the truth-value.
A finite-state transducer would notbe able in general to remember how many outputs hadbeen deferred.THE EFFECT OF  NULLSSince Kimmo systems can encode NP-complete prob-lems, the general Kimmo generation and recognition prob-lems are at least as hard as the difficult problems in NP.But could they be even harder?
The answer depends onwhether null characters are allowed.
If nulls are completelyforbidden, the problems are in NP, hence (given the pre-vious result) NP-complete.
If nulls are completely unre-stricted, the problems are PSPACE-complete, thus prob-ably even harder than.
the problems in NP.
However, thefull power of unrestricted null characters i not needed forlinguistically relevant processing.If null characters are disallowed, the generation prob-lem for Kimmo systems can be solved quickly on a nonde-terministic machine.
Given a set of automata nd a lex-ical string, the basic nondeterminism of the machine canbe used to guess the lexical-surface orrespondence, whichthe automata can then quickly verify.
Since nulls are notpermitted, the size of the guess cannot get out of hand;the lexical and surface strings will have the same length.The recognition problem can be solved in the same wayexcept that the machine must also guess a path throughthe dictionary.If null characters are completely unrestricted, theabove argument fails; the lexical and surface strings maydiffer so radically in length that the lexical-surface cor-respondence annot be proposed or verified in time poly-nomial in input length.
The problem becomes PSPACE-complete - -  as hard as checking for a forced win fromcertain N x N Go configurations, for instance, and prob-ably even harder than NP-complete problems (cf.
Gareyand Johnson, 1979:171ff).
The proof involves howing thatKimmo systems with unrestricted nulls can easily be in-duced to work out, in the space between two input char-acters, a solution to the difficult Finite State AutomataIntersection problem.58The PSPACE-completeness reduction shows that iftwo-level morphology is formally characterized in a waythat leaves null characters completely unrestricted, it canbe very hard for the recognizer to reconstruct the superfi-cially null characters that may lexically intervene betweentwo surface characters.
However, unrestricted nulls surelyare not needed for linguistically relevant Kimmo systems.Processing complexity can be reduced by any restrictionthat prevents the number of nulls between surface charac-ters from getting too large.
As a crude approximation toa reasonable constraint, he PSPACE-completeness reduc-tion could be ruled out by forbidding entire lexicon entriesfrom being deleted on the surface.
A suitable restrictionwould make the general Kimmo recognition problems onlyNP-complete.Both of the reductions remind us that problems involv-ing finite-state machines can be hard.
Determining mem-bership in a finite-state language may be easy, but usingfinite-state machines for different asks such as parsing ortransduction can lead to problems that are computation-ally more difficult.REFERENCESBarton, E. (1985).
"The Computational Complexity ofTwo-Level Morphology," A.I.
Memo No.
856, M.I.T.Artificial Intelligence Laboratory, Cambridge, Mass.Gajek, O., H. Beck, D. Elder, and G. Whittemore (1983).
"LISP Implementation \[of the KIMMO system\]," TexasLinguistic Forum 22:187-202.Garey, M., and D. Johnson (1979).
Computers and In-tractability.
San Francisco: W. H. Freeman and Co.Karttunen, L. (1983).
"KIMMO: A Two-Level Morpho-?
logical Analyzer," Texas Linguistic Forum 22:165-186.Karttunen, L., and K. Wittenburg (1983).
"A Two-LevelMorphological Analysis of English," Texas LinguisticForum 22:217-228.ACKNOWLEDGEMENTSThis report describes research done at the ArtificialIntelligence Laboratory of the Massachusetts Institute ofTechnology.
Support for the Laboratory's artificial intel-ligence research has been provided in part by the Ad-vanced Research Projects Agency of the Department ofDefense under Office of Naval Research contract N00014-80-C-0505.
A version of this paper was presented tothe Workshop on Finite-State Morphology, Center for theStudy of Language and Information, Stanford University,July 29-30, 1985; the author is grateful to Lauri Kart-tunen for making that presentation possible.
This researchhas benefited from guidance and commentary from BobBerwick, and Bonnie Dorr and Eric Grimson have alsohelped improve the paper.59
