SESS ION 4: NATURAL LANGUAGERobert C. Moore, ChairArti f ic ial  Intel l igence CenterSRI  In ternat iona lMenlo Park ,  CA 94025Collectively, the papers in this session are mainly con-cerned with parsing, semantic interpretation, and infer-ence.
Interest in these processes can be motivated if werecognize that the overall goal of the field of NLP is themanipulation of natural language in ways that dependon meaning.
Parsing, the recovery of the linguistic orgrammatical structure of a natural-language utterance,is of concern to NLP because, in general, the meaning ofa natural-language utterance depends on its structure.An example that illustrates this point is the sentenceThe man with the umbrella opened the door.
If we triedto process this sentence without paying attention to itsgrammatical structure, we could easily be misled by thefact that it contains the substring ~he umbrella opened.But this sentence has nothing to do with umbrellas open-ing.
Because of the structure of the sentence, the um-brella must be grouped with with and not with opened.If the central concern of NLP is the manipulation ofnat-ural language in ways that depend on meaning, thensemantic interpretation would naturally be expected toplay a central role.
In practice, semantic interpreta-tion in NLP usually means recovering a representationof the meaning of an utterance that encodes that mean-ing in a more transparent way than does the utteranceitself.
IIow does this contribute to the goal of manipu-lating language in meaning-dependent ways?
We wantto have algorithms that manipulate language accordingto meaning, but meaning is ultimately an abstractionthat algorithms can have no direct access to.
Algorithmscan directly manipulate xpressions only according totheir structure.
Thus we need expressions whose struc-ture corresponds in a very direct way to their mean-ing.
While, as we have argued above, the meaning ofa natural-language expression is dependent on its struc-ture, this dependence an be very indirect.
By recoveringan expression that encodes the meaning of an utterancemore directly, we can create modular algorithms thatconsist of interacting pieces that each look only at a smallpiece of the structure of the meaning representation.
Ifthe pieces of the meaning representation fit together in anatural way that reflects the overall meaning of the ut-terance, then the algorithms that manipulate them willalso be able to fit together in a natural way that reflectsthe overall meaning of the utterance.Finally, inference is the pay-off or the previous phases ofparsing and semantic interpretation, being the canonicalexample of a form of manipulation of natural-languagethat depends on the meaning of utterances.
In fact, astrong argument could be made that inference is a pro-cess on meanings and not on natural-language expres-sions per se.With this as background, we can briefly consider someof the major issues raised by the papers in this ses-sion.
Some of the most important issues currently beingraised about parsing are how complete it needs to beand how complex a structure needs to be recovered fordifferent applications.
The paper by McCord takes afairly traditional view, attempting to recover a completestructural description of any sentence presented to theparser.
In the paper by ttobbs, et al, parsing is muchmore fragmentary, attempting only to recover the struc-ture of pieces of a text that are criticM for the particularapplication.
Moreover, the structures recovered in thettobbs paper are simple enough to be characterized byfinite-state automata, while the structures described inthe McCord paper are more complex.
A second parsingissue, which forms the focus of the McCord paper, is theproblem of ambiguity.
In parsing, we are given a string ofwords or tokens, and we have to recover the grammaticalstructure, but there may be many structures compatiblewith a given string.
McCord, then, addresses the issueof how to find the most likely stucture out of all the onesthat are possible.Issues of semantic interpretation are of greatest con-cern in the paper by IIwang and Schubert.
The type ofwork reported in this paper can perhaps be best appre-ciated by keeping in mind some central methodologicalprinciples that are ofter used to guide work on seman-tics.
flaying such principles is important because of thelack of clear intuititive agreement about the adequacyof semantic representations.
Speech recognition, in con-trast, is methodologically much simpler than semanticsbecause of the enormous intersubjective agreement as to125what strings of words most speech signals correspond to.While there are particular cases where the proper tran-scription of a signal can be argued about, in most casesthis is simply not a problem.
No such intuitive agree-ment exists in the field of semantics.
It is somethinglike speech recognition might be if there were no writtenlanguages and no general agreement on segmentation fspeech into words.So, in semantic interpretation, there are two method-ological principles that have come to be used as a meansof evaluating the adequacy of proposed analyses.
Thefirst is that one should be able to give a mathematical,"model theoretic" interpretation of the formal expres-sions used to represent the meaning of natural-languageexpressions.
This gives a way to decide whether thereis really any basis for the claim that the representa-tions in question actually do capture the meaning ofthe corresponding natural-language.
The main alterna-tive seems to be what is sometimes referred to as "pre-tend it's English" semantics, where one reads the tokensthat appear in the representation as if they are Englishwords and sees whether it sounds like it means whatis desired--not a very satisfactory state of affairs.
Asecond methodological principle in semantic interpreta-tion is that of compositionality--the slogan being, "themeaning of the whole must be a function of the mean-ing of the parts."
This principle reflects the fact thatit is not sufficient just to be able to represent formallythe meaning of natural-language expressions; it must bepossible to produce them in a systematic way from thenatural anguage.
In the Hwang and Schubert paper, therepresentations u ed may seem quite complex to some--one outside the field, but that complexity is motivatedby the need to satisfy these methodological constraints.In Vilain's paper, the major issue adressed is the trade-off between expressiveness in a representation formalismand the tractability of the inference problem for that for-malism.
It is notorious that the more expressive a repre-sentation language is, the more computationally complexthe inference problem for it is.
Vilain looks at whetherfor a certain type of application, the expressions in therepresentation language can be limited to a normal formwhich is known to be computationally tractable.There are also a number of issues that cut across allphases of processing.
One such issue is to what de-gree systems can be made language and domain indepen-dent.
The ideal is for the algorithms to be both languageand domain independent, with a declaratively specifiedgrammar and lexicon that is language dependent but do-main independent, and a final domain-dependent mod-ule that interfaces the language processing to the appli-cation.
The paper by Aone, et al, explores how wellthis model works in a real multi-lingual data extractionsystem.
A second issue is that of hand coding versusautomatic extraction of the knowledge required for NLPsystems.
Almost all the knowledge mbodied in the sys-tems described in this session is hand-coded, while theemphasis in Session 8 is on systems that use methods forautomatic extraction.
Often this issue is conflated withthe issue of whether the knowledge in question is rep-resented by symbolic rules or by numerical parameterssuch as probabilities, but it is worth pointing out thatthe paper by Brill in Session 8 uses symbolic rules, butextracts them automatically from a corpus.
Finally, sev-eral of these papers raise the question of how to evaluatethe work reported on.
This has come to be recognized asa central methodological issue in the field, and the Mc-Cord, Hobbs, and Vilain papers all address the problemin one way or another.126
