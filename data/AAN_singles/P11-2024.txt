Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 135?140,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsSearch in the Lost Sense of ?Query?
: Question Formulation in Web SearchQueries and its Temporal ChangesBo Pang Ravi KumarYahoo!
Research701 First AveSunnyvale, CA 94089{bopang,ravikumar}@yahoo-inc.comAbstractWeb search is an information-seeking activ-ity.
Often times, this amounts to a user seek-ing answers to a question.
However, queries,which encode user?s information need, aretypically not expressed as full-length naturallanguage sentences ?
in particular, as ques-tions.
Rather, they consist of one or more textfragments.
As humans become more search-engine-savvy, do natural-language questionsstill have a role to play in web search?Through a systematic, large-scale study, wefind to our surprise that as time goes by, webusers are more likely to use questions to ex-press their search intent.1 IntroductionA web search query is the text users enter into thesearch box of a search engine to describe their infor-mation need.
By dictionary definition, a ?query?
isa question.
Indeed, a natural way to seek informa-tion is to pose questions in a natural-language form(?how many calories in a banana?).
Present day websearch queries, however, have largely lost the orig-inal semantics of the word query: they tend to befragmented phrases (?banana calories?)
instead ofquestions.
This could be a result of users learningto express their information need in search-engine-friendly forms: shorter queries fetch more resultsand content words determine relevance.We ask a simple question: as users becomemore familiar with the nuances of web search,are question-queries ?
natural-language questionsposed as queries ?
gradually disappearing from thesearch vernacular?
If true, then the need for searchengines to understand question-queries is moot.Anecdotal evidence from Google trends suggestsit could be the opposite.
For specific phrases, onecan observe how the fraction of query traffic con-taining the phrase1 changes over time.
For instance,as shown next, the fraction of query traffic contain-ing ?how to?
has in fact been going up since 2007.However, such anecdotal evidence cannot fullysupport claims about general behavior in query for-mulation.
In particular, this upward trend couldbe due to changes in the kind of information usersare now seeking from the Web, e.g., as a result ofgrowing popularity of Q&A sites or as people en-trust search engines with more complex informationneeds; supporting the latter, in a very recent study,Aula et al (2010) noted that users tend to formu-late more question-queries when faced with difficultsearch tasks.
We, on the other hand, are interested ina more subtle trend: for content that could easily bereached via non-question-queries, are people morelikely to use question-queries over time?We perform a systematic study of question-queries in web search.
We find that question-queriesaccount for ?
2% of all the query traffic and ?
6%of all unique queries.
Even when averaged over in-tents, the fraction of question-queries to reach the1www.google.com/intl/en/trends/about.html135same content is growing over the course of one year.The growth is measured but statistically significant.The study of long-term temporal behavior ofquestion-queries, we believe, is novel.
Previouswork has explored building question-answering sys-tems using web knowledge and Wikipedia (see Du-mais et al (2002) and the references therein).
Ourfindings call for a greater synergy between QA andIR in the web search context and an improved un-derstanding of question-queries by search engines.2 Related workThere has been some work on studying and exploit-ing linguistic structure in web queries.
Spink andOzmultu (2002) investigate the difference in userbehavior between a search engine that encouragedquestions and one that did not; they did not exploreintent aspects.
Barr et al (2008) analyze the occur-rence of POS tags in queries.Query log analysis is an active research area.While we also analyze queries, our goal is very dif-ferent: we are interested in certain linguistic aspectsof queries, which are usually secondary in log anal-ysis.
For a comprehensive survey on this topic, seethe monograph of Silvestri (2010).
There has beensome work on short-term (hourly) temporal analysisof query logs, e.g., Beitzel et al (2004) and on longqueries, e.g., Bendersky and Croft (2009).Using co-clicking to infer query-query relation-ships was proposed by Baeza-Yates and Tiberi(2007).
Their work, however, is more about thequery-click graph and its properties.
There has alsobeen a lot of work on query clustering by commonintent using this graph, e.g., Yi and Maghoul (2009)and Wen et al (2002).
We focus not on clusteringbut on understanding the expression of intent.3 MethodWe address the main thesis of the work by retrospec-tively studying queries issued to a search engine overthe course of 12 consecutive months.Q-queries.
First we define a notion of questionqueries based on the standard definition of questionsin English.
A query is a Q-query if it contains atleast two tokens and satisfies one of the followingcriteria.
(i) Starts with one of the interrogative words, orQ-words (?how, what, which, why, where, when,who, whose?).
(ii) Starts with ?do, does, did, can, could, has,have, is, was, are, were, should?.
While this ensuresa legitimate question in well-formed English texts,in queries, we may get ?do not call list?.
Thus, weinsist that the second token cannot be ?not?.
(iii) Ends with a question mark (???
).Otherwise it is a Q-query.
The list of key-words (Q-words) is chosen using an English lexi-con.
Words such as ?shall?
and ?will?, even thoughinterrogative in nature, introduce more ambiguity(e.g., ?shall we dance lyrics?
or ?will smith?)
anddo not account for much traffic in general; discard-ing such words will not impact the findings.Co-click data on ?stable?
URLs.
We work with theset of queries collected between Dec 2009 and Nov2010 from the Yahoo!
querylog.
We gradually refinethis raw data to study changes in query formulationover comparable and consistent search intents.1.
Sall consists of all incoming search queries af-ter preprocessing: browser cookies2 that correspondto possible robots/automated queries and querieswith non-alphanumeric characters are discarded; allpunctuations, with the exception of ??
?, are re-moved; all remaining tokens are lower-cased, withthe original word ordering preserved.2.
Call consists of queries formulated for similarsearch intent, where intent was approximated by theresult URL clicked in response to the query.
That is,we assume queries that lead to a click on the sameURL are issued with similar information need.
Toreduce the noise introduced by this approximationwhen users explore beyond their original intent, wefocus on (query, URL) pairs where the URL u wasclicked from top-10 search results3 for query q.3.
Uc50Q is our final dataset with queries groupedover ?stable?
intents.
First, for each month m, wecollect the multiset Ci of all (q, ui) pairs for eachclicked URL ui, where the size of Ci is the to-tal number of clicks received by ui during m. Let2We approximate user identity via the browser cookie(which are anonymized for privacy).
While browser cookiescan be unreliable (e.g, they can be cleared), in practice, they arethe best proxy for unique users.3In any case, clicks beyond top-10 results (i.e., the first resultpage) only account for a small fraction of click traffic.136U (m) be all URLs for month m. We restrict toU =?m U(m).
This set represents intents and con-tents that persist over the 12-month period, allowingus to examine query formulation changes over time.We then extract a subset UQ of U consisting ofthe URLs associated with at least one Q-query inone of the months.
Interestingly, we observe that|UQ||U | = 0.55: roughly half of the ?stable?
URLs areassociated with at least one Q-query!Finally, we restrict to URLs with at least 50clicks in each month to obtain reliable statistics lateron.
U c50Q consists of a random sample of suchURLs, with 423,672 unique URLs and 231M uniquequeries (of which 21M (9%) are Q-queries).Q-level.
For each search intent (i.e., a click on u), tocapture the degree to which people express that in-tent via Q-queries, we define its Q-level as the frac-tion of clicks on u from Q-queries.
Since we areinterested in general query formulation behavior, wedo not want our analysis to be dominated by trendsin popular intents.
Thus, we take macro-averageof Q-level over different URLs in a given month,and our main aim is to explore long-term temporalchanges in this value.4 Results4.1 Characteristics of Q-queriesAre Q-queries really questions?
We examine 100random queries from the least frequent Q-queriesin our dataset.
Only two are false-positives: ?whowants to be a millionaire game?
(TV show-basedgame) and ?can tho nail florida?
(a local business).The rest are indeed question-like: while they are notnecessarily grammatical, the desire to express the in-tent by posing it as a question is unmistakable.Still, are they mostly ostensible questions like?how find network key?, or well-formed full-lengthquestions like ?where can i watch one tree hill sea-son 7 episode 2??
(Both are present in our dataset.
)Given the lack of syntactic parsers that are ap-propriate for search queries, we address this ques-tion using a more robust measure: the probabilitymass of function words.
In contrast to content words(open class words), function words (closed classwords) have little lexical meaning ?
they mainlyprovide grammatical information and are defined bytheir syntactic behavior.
As a result, most functionwords are treated as stopwords in IR systems, andweb users often exclude them from queries.
A highfraction of function words is a signal of queries be-having more like normal texts in terms of the amountof tokens ?spent?
to be structurally complete.We use the list of function words from SequencePublishing4, and augment the auxiliary verbs witha list from Wikipedia5.
Since most of the Q-wordsused to identifyQ-queries are function words them-selves, a higher fraction of function words in Q-queries is immediate.
We remove the word used forQ-query identification from the input string to avoidtrivial observations.
That is, ?how find network key?becomes ?find network key?, with zero contributionto the probability mass of function words.The following table summarizes the probabil-ity mass of function words in all unique Q-queries and Q-queries in U c50Q , compared to twonatural-language corpora: a sample of 6.6M ques-tions posted by web users on a community-basedquestion-answering site, Yahoo!
Answers (QY!A),and the Brown corpus6 (Br).
All datasets wentthrough the same query preprocessing steps, as wellas the Q-word-removal step described above.Type Q-q Q-q QY!A BrAuxiliary verbs 0.4 8.5 8.1 5.8Conjunctions 1.2 1.4 3.4 4.5Determiners 2.0 8.7 8.2 10.1Prepositions 6.5 13.7 10.1 13.3Pronouns 0.7 3.4 9.1 5.9Quantifiers 0.1 0.7 0.4 0.6Ambiguous 2.1 2.7 4.6 7.0Total 12.9 39.0 43.9 47.1Clearly, Q-queries are more similar to the twonatural-language corpora in terms of this shallowmeasure of structural completeness.
Notably, theycontain a much higher fraction of function wordscompared to Q-queries, even though they expresssimilar search intent.This trend is consistent when we break down bytype, except that Q-queries contain fewer conjunc-tions and pronouns compared to QY!A and Br.
Thishappens since Q-queries do not tend to have com-plex sentence or discourse structures.
Our results4www.sequencepublishing.com/academic.html.5en.wikipedia.org/wiki/List_of_English_auxiliary_verbs6khnt.aksis.uib.no/icame/manuals/brown/137suggest that if users express their information needin a question form, they are more likely to express itin a structurally complete fashion.Lastly, we examine the length of Q-queries andQ-queries in each multiset Ci.
If Q-queries con-tain other content words in place of Q-words to ex-press similar intent (e.g., ?steps to publish a book?vs.
?how to publish a book?
), we should observe asimilar length distribution.
Instead, we find that onaverage Q-queries tend to be longer than Q-queriesby 3.58 tokens.
Even if we remove theQ-word and acompanion function word, Q-queries would still beone to two words longer.
In web search, where theoverall query traffic averages at shorter than 3 to-kens, this is a significant difference in length ?
ap-parently people are more generous with words whenthey write in the question mode.4.2 Trend of Q-levelWe have just confirmed that Q-queries resemblenatural-language questions to a certain degree.
Nextwe turn to our central question: how does Q-level(macro-averaged over different intents) change overtime?
To this end, we compute a linear regressionof Q-level across 12 months, conduct a hypothesistest (with the null hypothesis being the slope of theregression equal to zero), and report the P -value fortwo-tailed t-test.As shown in Figure 1(a), there is a mid-range cor-relation between Q-level and time in U c50Q (corre-lation coefficient r = 0.78).
While the trend ismeasured with slope = 0.000678 (it would be sur-prising if the slope for the average behavior of thismany users were any steeper!
), it is statistically sig-nificant that Q-level is growing over time: the nullhypothesis is rejected with P < 0.001.
That is, overa large collection of intents and contents, users arebecoming more likely to formulate queries in ques-tion forms, even though such content could easily bereached via non-question-queries.One may question if this is an artifact of using?stable?
clicked URLs.
Could it be that search en-gines learn from user behavior data and graduallypresent such URLs in lower ranks (i.e., shown ear-lier in the page; e.g., first result returned), which in-creases the chance of them being seen and clicked?This is indeed true, but it holds for both Q-queriesandQ-queries.
More specifically, if we consider the0.0390.0410.0452  4  6  8  10  12Q-levelmonthslope = 0.000678(a) Q-level0.0130.0150.0170.0190.0211  10  100  1000averageQ-rateuser activity level in a month(b) Q-rateFigure 1: Q-level for different months in U c50Q ; Q-ratefor users with different activity levels in Sall.rank of the clicked URL as a measure of search re-sult quality (the lower the better), we observe im-provements for both Q-queries and Q-queries overtime (and the gap is shortening).
However, the av-erage click position for Q-queries is consistentlyhigher in rank throughout the time.
Thus, it isnot because the search engine is answering the Q-queries better than Q-queries that users start to useQ-queries more.
While we might still postulate thatthe decreasing gap in search quality (as measuredby click positions) might have contributed to the in-crease in Q-level, if we examine the co-click datawithout the stability constraint, we observe the fol-lowing: an increasing click traffic from Q-queriesand an increasing gap in click positions between Q-queries and Q-queries.In addition, we also observe an upward trend forthe overall incoming query traffic accounted for byQ-queries in Sall (slope = 0.000142, r = 0.618,P < 0.05).
The upward trend in the fraction ofunique queries coming fromQ-queries is even morepronounced (slope = 0.000626, r = 0.888, P <0.001).
While this trend could be partly due to dif-138ferences in search intent, it nonetheless reinforcesthe general message of increases inQ-queries usage.This is also consistent with the anecdotal evidencefrom Google trends (Section 1) suggesting that thetrends we observe are not search-engine specific andhave been in existence for over a year.74.3 Observations in the overall query trafficNote that in U c50Q , Q-level averages ?
4%; recallalso for a rather significant portion of the web con-tent, at least one user chose to formulate his/her in-tent in Q-queries ( |UQ||U | = 0.55).
Both reflect theprevalence of Q-queries.
Is that specific to well-constrained datasets like U c50Q ?
We examine theoverall incoming queries represented in Sall.
On av-erage, Q-queries account for 1.8% of query traffic.5.7% of all unique queries are Q-queries, indicatinggreater diversity in Q-queries.What types of questions do users ask?
The tablebelow shows the top Q-words in the query traffic;?how?
and ?what?
lead the chart.word % word % word %how 0.7444 what 0.4360 where 0.0928?
0.0715 who 0.0684 is 0.0676can 0.0658 why 0.0648 when 0.0549do 0.0295 does 0.0294 are 0.0193which 0.0172 did 0.0075 should 0.0072How does the query traffic associated with differ-ent Q-words change over time?
We observe that allslopes are positive (though not all are statisticallysignificant), indicating that the increase inQ-querieshappens for different types of questions.Is it only a small number of amateur users whopersist withQ-queries?
We defineQ-rate for a givenuser (approximated by browser cookie b) as the frac-tion of query traffic accounted for byQ-queries.
Weplot this against b?s activity level, measured by thenumber of queries issued by b in a month.
We binnedusers by their activity levels on the log2-scale andcompute the average Q-rate for that bin.
As shownin Figure 1(b), relatively light users who issue upto 30 queries per month do not differ much in Q-rate on an aggregate level.
Interestingly, mid-rangeusers (around 300 queries per month) exhibit higher7An explanation of why the upward trend starts at the endof 2007 is beyond the scope of this work; we postulate that thiscoincides with the rise in popularity of community-based Q&Asites.Q-rate than the light users.
And for the most heavyusers, the Q-rate tapers down.Furthermore, taking the data from the last monthin Sall, we observe that for users who issued at least258 queries, more than half of them have issued atleast one Q-query in that month ?
using Q-queriesis rather prevalent among non-amateur users.5 Concluding remarksIn this paper we study the prevalence and charac-teristics of natural-language questions in web searchqueries.
To the best of our knowledge, this is thefirst study of such kind.
Our study shows that ques-tions in web search queries are both prevalent andtemporally increasing.
Our central observation isthat this trend holds in terms of how people formu-late queries for the same search intent (in the care-fully constructed dataset U c50Q ).
The message is re-inforced as we observe a similar trend in the per-centage of overall incoming query traffic being Q-queries; in addition, anectodal evidence can be ob-tained from Google trends.We recall the following two findings from ourstudy.
(a) Given the construction of U c50Q , the up-ward trend we observe is not a direct result of userslooking for different types of information, althoughit is possible that the rise of Q&A sites and usersentrusting search engines with more complex infor-mation needs could have indirect influences.
(b) Theresults in Section 4.2 suggest that in U c50Q ,Q-queriesreceive inferior results than Q-queries (i.e., higheraverage rank for clicked results for Q-queries forsimilar search intents), thus the rise in the use ofQ-queries is not a direct result of users learning themost effective query formulation for the search en-gine.
These suggest an interesting research question:what is causing the rise in question-query usage?Irrespective of the cause, given that there is anincreased use of Q-queries in spite of the seem-ingly inferior search results, there is a strong needfor the search engines to improve their handling ofquestion-queries.AcknowledgmentsWe thank Evgeniy Gabrilovich, Lillian Lee, D.Sivakumar, and the anonymous reviewers for manyuseful suggestions.139ReferencesAnne Aula, Rehan M. Khan, and Zhiwei Guan.
2010.How does search behavior change as search becomesmore difficult?
In Proc.
28th CHI, pages 35?44.Ricardo Baeza-Yates and Alessandro Tiberi.
2007.
Ex-tracting semantic relations from query logs.
In Proc.13th KDD, pages 76?85.Cory Barr, Rosie Jones, and Moira Regelson.
2008.
Thelinguistic structure of English web-search queries.
InProc.
EMNLP, pages 1021?1030.Steven M. Beitzel, Eric C. Jensen, Abdur Chowdhury,David Grossman, and Ophir Frieder.
2004.
Hourlyanalysis of a very large topically categorized webquery log.
In Proc.
27th SIGIR, pages 321?328.M.
Bendersky and W. B. Croft.
2009.
Analysis of longqueries in a large scale search log.
In Proc.
WSDMWorkshop on Web Search Click Data.Susan Dumais, Michele Banko, Eric Brill, Jimmy Lin,and Andrew Ng.
2002.
Web question answering: Ismore always better?
In Proc.
25th SIGIR, pages 291?298.Mark Kro?ll and Markus Strohmaier.
2009.
Analyzinghuman intentions in natural language text.
In Proc.5th K-CAP, pages 197?198.Cody Kwok, Oren Etzioni, and Daniel S. Weld.
2001.Scaling question answering to the web.
ACM TOIS,19:242?262.Josiane Mothe and Ludovic Tanguy.
2005.
Linguisticfeatures to predict query difficulty.
In Proc.
SIGIRWorkshop on Predicting Query Difficulty - Methodsand Applications.Marius Pasca.
2007.
Weakly-supervised discovery ofnamed entities using web search queries.
In Proc.
16thCIKM, pages 683?690.Fabrizio Silvestri.
2010.
Mining Query Logs: TurningSearch Usage Data into Knowledge.
Foundations andTrends in Information Retrieval, 4(1):1?174.Amanda Spink and H. Cenk Ozmultu.
2002.
Char-acteristics of question format web queries: An ex-ploratory study.
Information Processing and Manage-ment, 38(4):453?471.Markus Strohmaier and Mark Kro?ll.
2009.
Studyingdatabases of intentions: do search query logs captureknowledge about common human goals?
In Proc.
5thK-CAP, pages 89?96.Ji-Rong Wen, Jian-Yun Nie, and Hong-Jiang Zhang.2002.
Query clustering using user logs.
ACM TOIS,20:59?81.Jeonghee Yi and Farzin Maghoul.
2009.
Query cluster-ing using click-through graph.
In Proc.
18th WWW,pages 1055?1056.140
