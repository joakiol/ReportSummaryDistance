Language Resources for a Network-based DictionaryVeit ReuerInstitute of Cognitive ScienceUniversity of Osnabru?ckGermanyvreuer@uos.deAbstractIn order to facilitate the use of a dictionary for lan-guage production and language learning we proposethe construction of a new network-based electronicdictionary along the lines of Zock (2002).
How-ever, contrary to Zock who proposes just a paradig-matic network with information about the variousways in which words are similar we would like topresent several existing language resources (LRs)which will be integrated in such a network result-ing in more linguistic levels than one with paradig-matically associated words.
We argue that just asthe mental lexicon exhibits various, possibly inter-woven layers of networks, electronic LRs contain-ing syntagmatic, morphological and phonologicalinformation need to be integrated into an associa-tive electronic dictionary.1 IntroductionTraditional dictionaries are mainly used for lan-guage reception, even though they were also de-veloped to be used for language production.
How-ever the form-based structure following ortho-graphic conventions which could also be called?one-dimensional?, makes it difficult to access theinformation by meaning.
Therefore the usage ofa traditional dictionary for text production is quitelimited as opposed to, for example, a thesaurus.The main advantage of a thesaurus is the structuringbased on the semantic relation between words in anentry.
This allows for the availability of a differenttype of information.Therefore our proposal is to construct an elec-tronic dictionary which has a network-like structureand whose content is drawn from various existinglexical resources.
The dictionary will represent bothparadigmatic information - information about thevarious ways in which words are similar - as well assyntagmatic information - information about the re-lationships among words that appear together.
Ad-ditionally information from other types of resourcessuch as morphology and phonology will be inte-grated as they are also relevant in models of themental lexicon.
In these models ?associations?
be-tween words are based not only on meaning but alsoon phonological or morphological properties of theconnected words.
Following Brown and McNeill(1966) and subsequent research people in the so-called ?tip-of-the-tongue?-state (TOT-state) are ableto clearly recall the properties of the missing wordsuch as the number of syllables or the meaning, andcan easily identify the target word when it is pre-sented to them.berryhyperTTTTT TTherbhyper IIIbirthmarkhyper%%chocolatewwwwwwwwshortcakegggggggggggggarden strwb.
hypobbstrawberry creamwild strwb.hyposss jamRRRRRRRRRRRRRR fruitZZZZZZZZZZZZZZZZZZZZZZZZZZbeach strwb.hypo??????
?Virginia Strwb.hypo???????
?Figure 1: Example network with data from Word-Net (?)
and Deutscher Wortschatz (=)Figure 1 exemplifies the visualization of a singlenode with related information from two LRs1.
Herea user would be able to find the term ?shortcake?even if s/he only knows only one part, namely straw-berries.2 A click on a neighbouring node should e.g.re-center the structure and hence allow the user to?explore?
the network.As mentioned above the most obvious usageseems to be in language production where infor-mation can be provided not only for words alreadyactivated in the mind of the language producer butalso for alternatives, specifications or for words notdirectly accessible because of a TOT-state.
Thisseems reasonable in light of the fact that speaker?spassively vocabularies are known to be larger than1http://www.cogsci.princeton.edu/?wnhttp://www.wortschatz.uni-leipzig.de2LDOCE (1987) mentions ?cream?
and ?jam?
but not?shortcake?
as part of the entry for ?strawberry?.
The entry for?shortcake?
however lists specifically ?strawberry shortcake?.their active vocabularies.
The range of informationavailable of course depends on the material inte-grated into the dictionary from the various resourceswhich are explored more closely below.A second area of application of such a dictio-nary is language learning.
Apart from specify-ing paradigmatic information which is usually alsopart of the definition of a lemma, syntagmatic in-formation representing collocations and cooccur-rances is an important resource for language learn-ers.
Knowledge about collocations is a kind of lin-guistic knowledge which is language-specific andnot systematically derivable making collocations es-pecially difficult to learn.Even though there are some studies that comparethe results from statistically computed associationmeasures with word association norms from psy-cholinguistic experiments (Landauer et al, 1998;Rapp, 2002) there has not been any research onthe usage of a digital, network-based dictionary re-flecting the organisation of the mental lexicon toour knowledge.
Apart from studies using so calledMind Maps or Concept Maps to visualize ?worldknowledge?3 (Novak, 1998) nothing is known aboutthe psycholinguistic aspects which need to be con-sidered for the construction of a network-based dic-tionary.In the following section we will summarize theinformation made available by the various LRs weplan to integrate into our system.
The ideas pre-sented here were developed in preparation of aproject at the University of Osnabru?ck.2 Language ResourcesZock (2002) proposes the use of only one type of in-formation structure in his network, namely a type ofsemantic information.
There are, however, a num-ber of other types of information structures that mayalso be relevant for a user.
Psychological experi-ments show that almost all levels of linguistic de-scription reveal priming effects.
Strong mental be-tween words are based not only on a semantic rela-tionship but also on morphological an phonologicalrelationships.
These types of relationships shouldalso be included in a network based dictionary aswell.A number of LRs that are suitable in this scenarioalready provide some sort of network-like structurepossibly closely related to networks meaningful toa human user.
All areas are large research fields oftheir own and we will therefore only touch upon afew aspects.3The maps constitute a representation of the world ratherthan reflecting the mental lexicon.2.1 Manually Constructed NetworksManually constructed networks usually consist ofparadigmatic information since words of the samepart-of-speech are related to each other.
In ontolo-gies usually only nouns are considered and are inte-grated into these in order to structure the knowledgeto be covered.The main advantage of such networks, since theyare hand-built, is the presumable correctness (if notcompleteness) of the content.
Additionally, thesesemantic nets usually include typed relations be-tween nodes, such as e.g.
?hyperonymy?
and ?is a?and therefore provides additional information for auser.
It is safe to rely on the structure of a networkcoded by humans to a certain extend even if it hascertain disadvantages, too.
For example networkstend to be selective on the amount of data included,i.e.
sometimes only one restricted area of know-ledge is covered.
Furthermore they include basi-cally only paradigmatic information with some ex-ceptions.
This however is only part of the greaterstructure of lexical networks.The most famous example is WordNet (Fellbaum,1998) for English ?
which has been visualized al-ready at http://www.visualthesaurus.com ?
and itsvarious sisters for other languages.
It reflects a cer-tain cognitive claim and was designed to be usedin computational tasks such as word sense disam-biguation.
Furthermore ontologies may be used as aresource, because in ontologies usually single wordsor NPs are used to label the nodes in the network.An example is the ?Universal Decimal Classifica-tion?4 which was originally designed to classify allprinted and electronic publications in libraries withthe help of some 60,000 classes.
However one canalso think of it as a knowledge representation sys-tem as the information is coded in order to reflectthe knowledge about the topics covered.2.2 Automatically Generated ParadigmaticNetworksA common approach to the automatic generation ofsemantic networks is to use some form of the socalled vector-space-model in order to map semanti-cally similar words closely together in vector spaceif they occur in similar contexts in a corpus (Man-ning and Schu?tze, 1999).
One example, Latent Se-mantic Analysis (Landauer et al, 1998, LSA) hasbeen accepted as a model of the mental lexicon andis even used by psycholinguists as a basis for thecategorization and evaluation of test-items.
The re-sults from this line of research seem to describe notonly relations between words but seem to provide4http://www.udcc.orgthe basis for a network which could be integratedinto a network-based dictionary.
A disadvantage ofLSA is the positioning of polysemous words at aposition between the two extremes, i.e.
between thetwo senses which makes the approach worthless forpolysemous words in the data.There are several other approaches such as Jiand Ploux (2003) and the already mentioned Rapp(2002).
Ji and Ploux also develop a statistics-basedmethod in order to determine so called ?contex-onyms?.
This method allows one to determine dif-ferent senses of a word as it connects to differentclusters for the various senses, which can be seenas automatically derived SynSets as they are knownfrom WordNet.
Furthermore her group developed avisualization tool, that presents the results in a wayunseen before.
Even though they claim to have de-veloped an ?organisation model?
of the mental lex-icon only the restricted class of paradigmatic rela-tions shows up in their calculations.Common to almost all the automatically derivedsemantic networks is the problem of the unknownrelation between items as opposed to manually con-structed networks.
On the one hand a typed rela-tion provides additional information for a user abouttwo connected nodes but on the other hand it seemsquestionable if a known relation would really helpto actually infer the meaning of a connected node(contrary to Zock (2002)).2.3 Automatically Generated SyntagmaticNetworksSubstantial parts of the mental lexicon probablyalso consist of syntagmatic relations between wordswhich are even more important for the interpre-tation of collocations.5 The automatic extractionof collocations, i.e.
syntagmatic relations betweenwords, from large corpora has been an area of inter-est in recent years as it provides a basis for the au-tomatic enrichment of electronic lexicons and alsodictionaries.
Usually attempts have been made atextracting verb-noun-, verb-PP- or adjective-noun-combinations.
Noteworthy are the works by Krennand Evert (2001) who have tried to compare thedifferent lexical association measures used for theextraction of collocations.
Even though most ap-proaches are purely statistics-based and use littlelinguistic information, there are a few cases wherea parser was applied in order to enhance the recog-nition of collocations with the relevant words not5We define collocations as a syntactically more or less fixedcombination of words where the meaning of one word is usu-ally altered so that a compositional construction of the meaningis prevented.being next to each other (Seretan et al, 2003).The data available from the collocation extrac-tion research of course cannot be put together togive a complete and comprehensive network.
How-ever certain examples such as the German project?Deutscher Wortschatz?6 and the visualization tech-nique used there suggest a network like structurealso in this area useful for example in the languagelearning scenario as mentioned above.2.4 Phonological/Morphological NetworksElectronic lexica and rule systems for the phonolog-ical representation of words can be used for spell-checking as has been done e.g.
in the Soundex ap-proach (Mitton, 1996).
In this approach a word notcontained in the lexicon is mapped onto a simpli-fied and reduced phonological representation andcompared with the representations of words in thelexicon.
The correct words coming close to themisspelled word on the basis of the comparisonare then chosen as possible correction candidates.However this approach makes some drastic assump-tions about the phonology of a language in order tokeep the system simple.
With a more elaborate setof rules describing the phonology of a language amore complex analysis is possible which even al-lows the determination of words that rhyme.7 Set-ting a suitable threshold for some measure of simi-larity a network should evolve with phonologicallysimilar words being connected with each other.
Arelated approach to spelling correction is the use ofso called ?tries?
for the efficient storage of lexicaldata (Oflazer, 1996).
The calculation of a minimalediting distance between an unknown word and aword in a trie determines a possible correct candi-date.Contrary to Zock (2002) who suggests this as ananalysis step on its own we think that the phonolo-gical and morphological similarity can be exploitedto form yet another layer in a network-based dictio-nary.
Zock?s example of the looked-for ?relegate?may than be connected to ?renegade?
and ?dele-gate?
via a single link and thus found easily.
Hereagain, probably only partial nets are created but theymay nevertheless help a user looking for a certainword whose spelling s/he is not sure of.Finally there are even more types of LRs contain-ing network-like structures which may contributeto a network-based dictionary.
One example to bementioned here is the content of machine-readable6Note however that the use of the term ?Kollokation?
in thisproject is strictly based on statistics and has no relation to acollocation in a linguistic sense (see figure 1).7Dissertation project of Tobias Thelen: personal communi-cation.dictionaries.
The words in definitions contained inthe dictionary entries ?
especially for nouns ?
areusually on the one hand semantically connected tothe lemma and on the other hand are mostly entriesthemselves which again may provide data for a net-work.
In research in computational linguistics therelation between the lemma and the definition hasbeen utilized especially for word sense disambigua-tion tasks and for the automatic enrichment of lan-guage processing systems (Ide and Ve?ronis, 1994).3 Open Issues and ConclusionSo far we have said nothing about two further im-portant parts of such a dictionary: the representationand the visualization of the data.
There are a num-ber of questions which still need to be answered inorder to build a comprehensive dictionary suitablefor an evaluation.
With respect to the representationtwo major questions seem to be the following.?
As statistical methods for the analysis of cor-pora and for the extraction of frequent cooccur-rance phenomena tend to use non-lemmatizeddata, the question is whether it makes senseto provide the user with the more specific databased on inflected material.?
Secondly the question arises how to integratedifferent senses of a word into the representa-tion, if the data provides for this information(as WordNet does).With regard to visualization especially the dynamicaspects of the presentation need to be considered.There are various techniques that can be used to fo-cus on parts of the network and suppress others inorder to make the network-based dictionary man-ageable for a user which need to be evaluated in us-ability studies.
Among these are hyperbolic viewsand so-called cone treesAs we have shown a number of LRs, espe-cially those including syntagmatic, morphologicaland phonological information, provide suitable datato be included into a network-based dictionary.
Thedata in these LRs either correspond to the presumedcontent of the mental lexicon or seem especiallysuited for the intended usage.
One major prop-erty of the new type of dictionary proposed hereis the disintegration of the macro- and the micro-structure of a traditional dictionary because partsof the micro-structure (the definition of the entries)become part of the macro-structure (primary linksto related nodes) of the new dictionary.
Reflect-ing the structure of the mental lexicon this dictio-nary should allow new ways to access the lexicaldata and support language production and languagelearning.ReferencesR.
Brown and D. McNeill.
1966.
The ?tip-of-the-tongue?
phenomenon.
Journal of Verbal Learn-ing and Verbal Behavior, 5:325?337.C.
Fellbaum, editor.
1998.
WordNet: an electroniclexical database.
MIT Press, Cambridge, MA.N.
Ide and J.
Ve?ronis.
1994.
Machine readable dic-tionaries: What have we learned, where do we go.In Proceedings of the post-COLING94 interna-tional workshop on directions of lexical research,Beijing.H.
Ji and S. Ploux.
2003.
A mental lexicon organi-zation model.
In Proceedings of the Joint Inter-national Conference on Cognitive Science, pages240?245, Sydney.B.
Krenn and S. Evert.
2001.
Can we do bet-ter than frequency?
A case study on extract-ing PP-verb collocations.
In Proceedings of theACL-Workshop on Collocations, pages 39?46,Toulouse.T.
K. Landauer, P. W. Foltz, and D. Laham.
1998.An introduction to latent semantic analysis.
Dis-course Processes, 25:259?284.LDOCE.
1987.
Longman Dictionary of Contempo-rary English.
Langenscheidt, Berlin, 2. edition.C.
D. Manning and H. Schu?tze.
1999.
Foundationsof Statistical Natural Language Processing.
MITPress, Cambridge, MA.R.
Mitton.
1996.
English Spelling and the Com-puter.
Longman, London.J.
D. Novak.
1998.
Learning, Creating and UsingKnowledge: Concept Maps as Facilitative Toolsin Schools and Corporations.
Erlbaum, Mahwah,NJ.K.
Oflazer.
1996.
Error-tolerant finite-state recog-nition with applications to morphological analy-sis and spelling correction.
Computational Lin-guistics, 22(1):73?89.R.
Rapp.
2002.
The computation of word associa-tions: Comparing syntagmatic and paradigmaticapproaches.
In Proc.
19th Int.
Conference onComputational Linguistics (COLING), Taipeh.V.
Seretan, L. Nerima, and E. Wehrli.
2003.
Extrac-tion of multi-word collocations using syntacticbigram composition.
In Proceedings of the Inter-national Conference on Recent Advances in NLP(RANLP-2003), Borovets, Bulgaria.M.
Zock.
2002.
Sorry, but what was your nameagain, or, how to overcome the tip-of-the tongueproblem with the help of a computer?
In Pro-ceedings of the COLING-Workshop on Buildingand Using Semantic Networks, Taipeh.
