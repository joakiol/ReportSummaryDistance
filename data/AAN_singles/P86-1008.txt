CONSTRAINT PROPAGATION IN  K IMMO SYSTEMSG.
Edward Barton, Jr.M.I.T.
Artificial Intelligence Laboratory545 Technology SquareCambridge, MA 02139ABSTRACTTaken abstractly, the two-level (Kimmo) morphologicalframework allows computationally difficult problems toarise.
For example, N + 1 small automata re sufficientto encode the Boolean satisfiability problem (SAT) for for-mulas in N variables.
However, the suspicion arises thatnatural-language problems may have a special structure - -not shared with SAT - -  that is not directly captured inthe two-level model.
In particular, the natural problemsmay generally have a modular and local nature that dis-tinguishes them from more "global" SAT problems.
Byexploiting this structure, it may be possible to solve thenatural problems by methods that do not involve combi-natorial search.We have explored this possibility in a preliminary wayby applying constraint propagation methods to Kimmo gen-eration and recognition.
Constraint propagation can suc-ceed when the solution falls into place step-by-step througha chain of limited and local inferences, but it is insuffi-ciently powerful to solve unnaturally hard SAT problems.Limited tests indicate that the constraint-propagation al-gorithm for Kimmo generation works for English, Turkish,and Warlpiri.
When applied to a Kimmo system that en-codes SAT problems, the algorithm succeeds on "easy"SAT problems but fails (as desired) on "hard" problems.INTRODUCTIONA formal computational model of a linguistic processmakes explicit a set of assumptions about the nature of theprocess and the kind of information that it fundamentallyinvolves.
At the same time, the formal model will ignoresome details and introduce others that are only artifactsof formalization.
Thus, whenever the formal model andthe actual process eem to differ markedly in properties, anatural assumption is that something has been missed informalization - -  though it may be difficult to say exactlywhat.When the difference is one of worst-case complexity,with the formal framework allowing problems to arise thatare too difficult to be consistent with the received diffi-culty of actual problems, one suspects that the naturalcomputational task might have significant features thatthe formalized version does not capture and exploit ef-fectively.
This paper introduces a constraint propagationmethod for "two-lever' morphology that represents a pre-liminary attempt o exploit the features of local in\]orrna-tion flow and linear separability that we believe are foundin natural morphological-analysis problems.
Such a localcharacter is not shared by more difficult computationalproblems uch as Boolean satisfiability, though such prob-lems can be encoded in the unrestricted two-level model.Constraint propagation is less powerful than backtrackingsearch, but does not allow possibilities to build up in com-binatorial fashion.TWO-LEVELMORPHOLOGYThe mod~l of morphology developed by "two-level"Kimmo Koskenniemi is att~'active for putting morphologicalknowledge to use in processing.
Two-level rules mediatethe relationship between a lexieal string made up of mor-phemes from the dictionary and a surface string corre-sponding to the form a wo~d would have in text.
Equiva-lently, the rules correspond, jto finite-state transducers that?
?
?
~ ~)"  ?
s , .r1?
.
.
t z ' l  e s  .
.
.Figure 1: The automaton component of the Kimmo sys-tem consists of several two-headed finite-state automatathat inspect the lexical/surface correspondence in paral-lel.
The automata move together from left to right.
(FromKarttunen, 1983:176.
)45ALPHABET x y z T F -ANY =ENDFigure 2: This is the complete Kimmo genera-tor system for solving SAT problems in the vari-ables x, y, and z.
The system includes a con-sistency automaton for each variable in additionto a satisfaction automaton that does not varyfrom problem to problem.
"x-consistency" 3 3x x =T F =1: 2 3 12:  2 0 23: 0 3 3"y-consistency" 3 31: 2 3 12: 2 0 23: 0 3 3"z-consistency" 3 3Z Z =T F =I: 2 3 12: 2 0 23: 0 3 3"satisfact ion" 3 4= _-T Fi.
2 1 32: 2 2 2 13.
1 2 0 0ENDcan be used in generation and recognition algorithms asimplemented in Karttunen's (1983) Kimmo system (andothers).
As shown in Figure 1, the transducers in the "au-tomaton component" (~ 20 for Finnish, for instance) allinspect he lexical/surface orrespondence at once in orderto implement the insertions, deletions, and other spellingchanges that may accompany affixation or inflection.
In-sertions and deletions are handled through null charactersthat are visible only to the automata.
A complete Kimmosystem also has a "dictionary component" that regulatesthe sequence of roots and affixes at the lexical level.Despite initial appearances to the contrary, the straight-forward interpretation f the two-level model in terms offinite*state transducers leads to generation and recogni-tion algorithms that can theoretically do quite a bit ofbacktracking and search.
For illustration we will considerthe Kimmo system in Figure 2, which encodes Booleansatisfiability for formulas in three variables x, y, and z.The Kimmo generation algorithm backtracks extensivelywhile determining truth-assignments for formulas accord-ing to this system.
(See Barton (1986) and references citedtherein for further details of the Kimmo system and of thesystem in Figure 2.
)Taken in the abstract, the two-level model allows com-putationally difficult situations to arise despite initial ap-pearances to the contrary, so why shouldn't they also turnup in the analysis of natural anguages?
It may be thatthey do turn up; indeed, the relevant mathematical re-ductions are abstractly based on the Kimmo treatment ofvowel harmony and other linguistic phenomena.
Yet onefeels that the artificial systems used in the mathematicalreductions are unnatural in some significant way - -  thatsimilar problems are not likely to turn up in the analysisof Finnish, Turkish, or Warlpiri.
If this is so, then the re-ductions ay more about what is thus-far unexpressed inthe formal model than about he difficulty of morphologicalanalysis; it would be impossible to crank the difficult prob-lems through the formal machinery, if the machinery couldbe infused with more knowledge of the special propertiesof natural anguage.
1MODULARINFORMATION STRUCTUREThe ability to use particular epresentations and pro-cessing methods is underwritten by what may be called the"information structure" of a task - -  more abstract than aparticular implementation, and concerned with such ques-tions as whether a certain body of information suffices formaking certain decisions, given the constraints of the prob-lem.
What is it about he information structure of morpho-logical systems that is not captured when they are encoded1The systems under consideration in this paper deal with ortho-graphic representations, which are somewhat remote from the "morenatural" linguist~ level of phonology and contain both more and lessinformation than phonological representations.46as Kimmo systems?
Are there significant locality princi-ples and so forth that hold in natural languages but not inmathematical systems that encode CNF Boolean satisfac-tion problems (SAT)?
Y'erhaps a better understanding ofthe information relationships of the natural problem canlead to more specialized processing methods that requireless searching, allow more parallelism, run more efficiently,or are more satisfying in some other way.A lack of modular information structure may be oneway in which SAT problems are unnatural compared tomorphological-analysis problems.
Making this idea preciseis rather tricky, for the Kimmo systems that encode SATproblems are modular in the sense that they involve vari-ous independent Kimmo automata ssembled in the usualway.
However, the essential notion is that the Boolean sat-isfaction problem has a more interconnected and "global"character than morphological nalysis.
The solution toa satisfaction problem generally cannot be deduced pieceby piece from local evidence.
Instead, the acceptabilityof each part of the solution may depend on the wholeproblem.
In the worst case, the solution is determinedby a complex conspiracy among the problem constraintsinstead of being composed of independently derivable sub-parts.
There is little alternative to running through thepossible cases in a combinatorial way.In contrast o this picture, in a morphological naly-sis problem it seems more likely that some pieces of thesolution can be read off relatively directly from the input,with other pieces falling into place step-by-step througha chain of limited and local inferences and without thekind of "argument by cases" that search represents.
Webelieve the usual situation is for the various complicatingprocesses to operate in separate domains - -  defined for in-stance by separate feature-groups - -  instead of conspiringclosely together.The idea can be illustrated with a hypotheticallanguage that has no processes affecting consonants butseveral right-to-left harmony processes affecting differentfeatures of vowels.
By hypothesis, underlying consonantscan be read off directly.
The right-to-left harmony pro-cesses mean that underlying vowels cannot always be iden-tified when the vowels are first seen.
However, since theprocesses affect different features, uncertainty in one areawill not block conclusions in others.
For instance, the pro-cessing of consonants i  not derailed by uncertainty aboutvowels, so information about underlying consonants canpotentially be used to help identify the vowels.
In such ascenario, the solution to an analysis problem is constructedmore by superposition than by trying out solutions to in-tertwined constraints.A SAT problem can have either a local or global infor-mation structure; not all SAT problems are difficult.
Theunique satisfying assignment for the formula (~ v z)&(x vy)&:5 is forced piece by piece; the conjunct ~ forces x tobe false, so y must be true, so finally z must be true.
Incontrast, it is harder to see that the formulais unsatisfiable.
The problem is not just increased length;a different method of argument is required.
Conclusionsabout the difficult formula are not forced step by step aswith the easy formula.
Instead, the lack of "local informa-tion channels" seems to force an argument by cases.A search procedure of the sort used in the Kimmo sys-tem embodies few assumptions about possible modularityin natural-language phonology.
Instead, the implicit as-sumption is that any part of an analysis may depend onanything to its left.
For example, consider the treatment ofa right-to-left long-distance harmony process, which makesit impossible to determine the interpretation of a vowelwhen it is first encountered in a left-to-right scan.
Facedwith such a vowel, the current Kimmo system will choosean arbitrary possible interpretation a d arrange for even-tual rejection if the required right context never shows up.In the event of rejection, the system will carry out chrono-logical backtracking until it eventually backs up to the er-roneous choice point.
Another choice will then be made,but the entire analysis to the right of the choice point willbe recomputed - - thus revealing the implicit assumptionof possible dependence.By making few assumptions, uch a search procedureis able to succeed even in the difficult case of SAT prob-lems.
On the other hand, if modularity, local constraint,and limited information flow are more typical than difficultglobal problems, it is appropriate to explore methods thatmight reduce search by exploiting this aspect of informa-tion structure.We have begun exploring such methods in a prelim-inary and approximate way by implementing a modular,non-searching constraint-propagation algorithm (see Win-ston (1984) and other sources) for Kimmo generation andrecognition.
The deductive capabilities of the algorithmare limited and local, reflecting the belief that morpho-logical analyses can generally be determined piece by piecethrough local processes.
The automata re largely decou-pied from each other, reflecting an expectation that phono-logical constraints generally will not conspire together incomplicated ways.The algorithm will succeed when a solution can bebuilt up, piece by superimposed piece, by individual au-tomata - -  but by design, in more difficult cases the con-straints of the automata will be enforced only in an approx-imate way, with some nonsolutions accepted (as is usual47with this kind of algorithm).
In general, the guiding as-sumption is that morphological nalysis problems actuallyhave the kind of modular and superpositional informationstructure that will allow constraint propagation to suc-ceed, so that the complexity of a high-powered algorithmis not needed.
(Such a modular structure seems consonantwith the picture suggested by autosegmental phonology,in which various separate tiers flesh out the skeletal slotsof a central core of CV timing slots; see Halle (1985) andreferences cited thereQSUMMARIZ ING COMBINAT IONSOF  POSSIB IL IT IESThe constraint-propagation algorithm differs from theKimmo algorithms in its treatment of nondeterminism.
Interms of Figure 1, nondeterminism cannot arise if boththe lexical surface strings have already been determined.This is true because a Kimmo automaton lists only onenext state for a given lexical/surface pair.
However, in themore common tasks of generation and recognition, onlyone of the two strings is given.
The generation task thatwill be the focus here uses the automata to find the surfacestring (e.g.
t r iea)  that corresponds to a lexical string (e.g.t ry+a) that is supplied as input.As the Kimmo automata progress through the input,they step over one lexical/surface pair at a time.
Somelexical characters will uniquely determine a lexical/surfacepair; in generation from try+a the first two pairs must bet / t  and r / r .
But at various points, more than one lex-ical/surface pair will be admissible given the evidence sofar.
If y /y  and y/?
are both possible, the Kimmo searchmachinery tries both pairs in subcomputations that havenothing to do with each other.
The choice points can po-tentially build on each other to define a search space thatis exponential in the number of independent choice points.This is true regardless of whether the search is carried outdepth-first or breadth-first.
~For example, return to the artificial Kimmo systemthat decides Boolean satisfiability for formulas in variablesx, y, and z (Figure 2).
When the initial y of the for-mula yz .x -y -z  , -x .
-y  is seen, there is nothing to decidebetween the pairs y/T and y/F.
If the system chooses y/Tfirst, the choice will be remembered by the y-consistencyautomaton, which will enter state 2.
Alternatively, if thepossibility /F is explored first, the y-consistency automa-ton will enter state 3.
After yz .x .
.
,  has been seen, thex-, y-, and z-consistency automata may be in any of the2See Karttunen {1983:184} on the difference in search order be-tween Karttunen's Kimmo algorithms and the equivalent proceduresoriginally presented by Koskenniemi.following state-combinations:(3,3,2) (2,3,2)(3,2,3) (2,2,3)<3,2,2) (2,2,2)(The combinations (3, 3, 3) and (2, 3, 3) are not reachablebecause the disjunction yz that will have been processedrules out both y and z being false, but on a slightly dif-ferent problem those combinations would be reachable aswell.)
The search mechanism will consider these possiblecombinations individually.Thus, the Kimmo machinery applied to a k-variableSAT problem explores a search space whose elements arek-tuples of truth-values for the variables, represented in theform of k-tuples of automaton states.
If there are k = 3variables, the search space distinguishes among (T, T, T),(T, T, F),  and so forth - -  among 2 k elements in general.Roughly speaking, the Kimmo machinery considers the el-ements of the search space one at a time, and in the worstcase it will enumerate all the elements.Instead of considering the tuples in this space indi-vidually, the constraint-propagation algorithm summarizeswhole sets of tuples in slightly imprecise form.
For exam-ple, the above set of state-combinations would be summa-rized by the single vector<{2,3}, {2,3}, {2,3)>representing the truth-assignment possibilities(x Z {T,F},y ?
{T,F},z ?
{T,F}).The summary is less precise than the full set of state-tuplesabout the global constraints among the automata; here,the summary does not indicate that the state-combinations(3, 3, 3) and (2, 3, 3) are excluded.
The constraint-propa-gation algorithm never enumerates the set of possibilitiescovered by its summary, but works with the summary it-self.The imprecision that arises from listing the possiblestates of each automaton instead of listing the possiblecombinations of states represents a decoupling of the au-tomata.
In addition to helping avoid combinatorial b owup,this decoupling allows the state-possibilities for differentautomata to be adjusted individually.
We do not expectthat the corresponding imprecision will matter for naturallanguage: instead, we expect hat the decoupled automatawill individually determine unique states for themselves, asituation in which the summary is precise.
3 For instance,aObviously, this can be true ill a recognition problem only if theinput is morphologically unambiguous, in which case it can still fail tohold if the constraint-propagation method is insufficiently powerful to48x-consistency 1 ...y-consistency 1 " "z-consistency 1 ....sa t i s fac t ion  1 """ "  1 " ' "? "
1 .
.
.
.
.
.
.
2,3-..?
-'1,2 .
.
.
.
.
.
~,2""I.... 1 ""t.... 2,3""x/T' / '  x/Finput y z , x""2,3"""'2,3"""'2,3""""1,2"..F igure 3: The constraint-propagation algorithm produces this representation when processingthe first few characters of the formula yz .x -y -z .
-x , -y  using the automata from Figure 2.
Atthis point no truth-values have been definitely determined.in the case of generation involving right-to-left vowel har-mony, only the vowel harmony automaton should exhibitnondeterminism, which should be resolved upon process-ing of the necessary right context.
The imprecision alsowill not matter  if two constraints are so independent thattheir solutions can be freely combined, since the summarywill not lose any information in that case.CONSTRAINT  PROPAGATIONLike the Kimmo machinery, the constraint-propagationmachinery is concerned with the states of the automata tintercharacter positions.
But when nondeterminism akesmore than one state-combination possible at some position,the constraint-propagation method summarizes the possi-bilities and continues instead of trying a single guess.
Theresult is a two-dimensional multi-valued tableau containingone row for each automaton and one column for each inter-character position in the input)  Figure 3 shows the firstfew columns that are produced in generating from the SATrule out invalid possibilities.
Note that many cases of morphologicalambiguity involve bracketing (e.g.
un\[loadableJ/\[unloadJable)rather than the identity of lexical characters.
Though the matter is notdiscussed here, we propose to handle bracketing ambiguity and lexical-string anabiguity by different mechanisms.
In addition, for discussionsof morphological mbiguity, it becomes very important whether theinput representation is phonetic or non-phonetically orthographic,4An extra column is needed at each position where a null might beinserted.formula yz ,x -y -z ,  -x .
-y .
The initial y can be interpretedas either y/T or y/F,  and consequently the y-consistencyautomaton can end up in either state 2 or state 3.
Simi-larly, depending on which pair is chosen, the satisfactionautomaton can end up in either state 1 (no true value seen)or state 2 (a true value seen).In addition to the states of the automata, the tableaucontains a pair set for each character, initialized to con-tain all feasible lexical/surface pairs (el.
Gajek et al, 1983)that match the input character.
As Figure 3 suggests, thepair set is common to all the automata; each pair in thepair set must be acceptable to every automaton.
If oneautomaton has concluded that there cannot be a surfaceg at the current position, it makes no sense to let anotherautomaton assume there might be one.
The automata retherefore not completely decoupled, and effects may prop-agate to other automata when one automaton eliminates apair from consideration.
Such propagation will occur onlyif more than one automaton distinguishes among the pos-sible pairs at a given position.
For example, an automatonconcerned solely with consonants would be unaffected bynew information about the identity of a vowel.Wahz's line-labelling procedure, the best-known earlyexample of a constraint-propagation procedure (el.
Win-ston, 1984), proceeds from an underconstrained initial la-belling by eliminating impossible junction labels.
A label isimpossible if it is incompatible with every possible label atsome adjacent junction.
The constraint-propagation pro-cedure for Kimrno systems proceeds in much the same way.49A possible state of an automaton can be eliminated in fourways:?
The only possible predecessor f the state (given thepair set) is ruled out in the previous tate set.?
The only possible successor of the state (given the pairset) is ruled out in the next state set.?
Every pair that allows a transition out of the state iseliminated at the rightward character position.?
Every pair that allows a transition into the state iseliminated at the leftward character position.Similarly, a pair is ruled out whenever any automaton be-comes unable to traverse it given the possible starting andending states for the transition.
(There are special rulesfor the first and last character position.
Null charactersalso require special treatment, which will not be describedhere.
)The configuration shown in Figure 3 is in need of con-straint propagation according to these rules.
State 1 of thesatisfaction automaton does not accept he comma/commapair, so state 1 is eliminated from the possible states { 1,2}of the satisfaction automaton after z.
State 1 has there-fore been shown as cancelled.
However, the elimination ofstate 1 causes no further effects at this point.The current implementation simplifies the checkingof the elimination conditions by associating setsof triples with character positions.
Each triple(old state, pair, new state) is a complete description of onetransition of a particular automaton.
The left, right, andcenter projections of each triple set must agree with thestate sets to the left and right and with the pair set for theposition, respectively.
Figure 4 shows two of the triple-setsassociated with the z-position in Figure 3.The nondeterminism of Figure 3 is finally resolved whenthe trivial clauses at the end of the formula yz .x -y-z .
-x, -yare processed.
After x in the clause -x all of the consistencyautomata re noncommittal, i.e.
can be in either state 2 orstate 3.
The satisfaction automaton was in state 3 beforethe x because of the minus sign and it can use either ofthe triples (3,x/T, 1) or (3,x/F,2).
However, on the nextstep it is discovered that only state 2 will allow it to tra-verse the comma that follows the x.
The triple (3,x/T, 1)is eliminated and the pair x/T goes with it.
The elimina-tion of x/T is propagated to the x-consistency automaton,which loses the triple (2,x/T,2) and can no longer sup-port state 2 in the left and right state sets.
The loss ofstate 2, in turn, propagates leftward on the x-satisfactionline back to the initial occurrence of x.
The possibility x/Tis eliminated everywhere it occurs along the way.
Finally,processing resumes at the right edge.In similar fashion, the trivial clause -y eliminates thepossibility /T throughout the formula.
However, this timethe effects pread beyond the y-automaton.
When the pos-sibility y/T is eliminated from the first pair-set in Figure 3,the satisfaction automaton can no longer support state 2between the y and z.
This leaves (1,z/T,2) as the onlyactive triple for the satisfaction automaton at the secondcharacter position.
Thus z/F is eliminated and z is forcedto truth.
When everything settles down, the "easy" for-mula yz ,x -y -z , -x , -y  has received the satisfying truth-assignment FT, F-F-T, -F, -F.ALGORITHMCHARACTERIST ICSThe constraint-propagation algorithm shares with theWaltz labelling procedure a number of characteristics thatprevent combinatorial b owup: 5?
The initial possibilities at each point are limited andnon-combinatorial; in this case, the triples at some po-sition for an automaton can do no worse than to encodethe whole automaton, and there will usually be only afew triples.
\]t is particularly significant that the num-ber of triples does not grow combinatorially as moreautomata re added.?
Possibilities are eliminated monotonically, so the lim-ited number of initial possibilities guarantees a limitednumber of eliminations.?
After initialization, propagation to the neighbors of avisited element takes place only if a possibility is elim-inated, so the limited number of eliminations guaran-tees a limited number of visits.?
Limited effort is required for each propagator visit.However, we have not done a formal analysis of our im-plementation, i  part because many details are subject ochange.
It would be desirable to replace the weak notionof monotonic possibility-elimination with some (stronger)notion of indelible construction of representation, based ifpossible on phonological features.
Methods have also beenenvisioned for reducing the distance that information mustbe propagated in the algorithm.The relative decoupling of the automata nd the gen-eral nature of constrain~-propagation methods uggests thata significantly parallel implementation is feasible.
How-ever, it is uncertain whether the constraint-propagationmethod enjoys an advanlage on serial machines.
It isclear that the Kimmo machinery does combinatorial searchwhile the constraint-propagation machinery does not, butSThroughout this paper, we are ignoring complications related tothe possibility of nulls.50y-cons is tency  .... 2,3""z -cons is tency  .... 1 ""z/Tz/F.... 2,3 .
.
.
.
.
.
.
.
2,3""?
"2,3 .
.
.
.
.
.
.
.
1 ""(2, z/T,2)<3, z/T,3)<2, z/F, 2)(3, z/F,3)(1,z/T,2)<1, z/F, 3>.... 2,3 ........ 2,3 ....Figure 4: When the active transitions of each automaton are represented by triples, it is easyto enforce the constraints that relate the left and right state-sets and the pair set.
The leftconfiguration is excerpted from Figure 3, while the right configuration shows the underlyingtriples.
The set of triples for the y-consistency automaton could easily be represented in moreconcise form.we have not investigated such questions as whether an ana-logue to BIGMACHINE precompilation (Gajek et al, 1983)is possible for the constraint-propagation method.
BIG-MACHINE precompilation speeds up the Kimmo machin-ery at a potentially large cost in storage space, though itdoes not reduce the amount of search.The constraint-propagation algorithm for generationhas been tested with previously constructed Kimmo au-tomata for English, Warlpiri, and Turkish.
Preliminary re-sults suggest that the method works.
However, we have notbeen able to test our recognition algorithm with previouslyconstructed automata.
The reason is that existing Kimmoautomata rely heavily on the dictionary when used forrecognition.
We do not yet have our Kimmo dictionarieshooked up to the constraint-propagation algorithms, andconsequently an attempt at recognition produces mean-ingless results.
For instance, without constraints fromthe dictionary the machinery may choose to insert suffix-boundary markers + anywhere because the automata donot seriously constrain their occurrence.Figure 5 shows the columns visited by the algorithmwhen running the Warlpiri generator on a typical example,in this case a past-tense verb form ('scatter-PAST') takenfrom Nash (1980:85).
The special exical characters I and<u2> implement a right-to-left vowel assimilation process.The last two occurrences of I surface as u under the influ-ence of <u2>, but the boundary # blocks assimilation of thefirst two occurrences.
Here the propagation of constraintshas gone backwards twice, once to resolve each of the twosets of I-characters.
The final result is ambiguous becauseour automata optionally allow underlying hyphens to ap-pear on the surface, in accordance with the way morphemeboundaries are indicated in many articles on Warlpiri.The generation and recognition algorithms have alsobeen run on mathematical SAT formulas, with the de-sired result that they can handle "easy" but not "diffi-cult" formulas as described above.
~ For the easy formula(~ v z)&(x v y)&~ constraint propagation determines thesolution (T V T)&(F V T)&F. But for the hard formulaconstraint propagation produces only the wholly uninfor-mative truth-assignment({T,F} v {T,F} V {T, F})&({T, F} V {T,F})&({T,F} v {T,F})a({T,F} V {T,F})&({T,F} v {T, FI)&({T,F} v {T,F})Since we believe linguistic problems are likely to be morelike the easy problem than the hard one, we believe theconstraint-propagation system is an appropriate step to-ward the goal of developing algorithms that exploit theinformation structure of linguistic prob\]ems.6Note that the current classification f formulas as "easy" is dif-ferent from polynomial-time satisfiability.
Inparticular, the restrictedproblem 2SAT can be solved in polynomial time by resolution, but notevery 2SAT formula is "easy ~ in the current sense.5101234512342345678910111213789101112891011121314pIrrI#kIjI-rn<u2>: result ambiguous, pirri{O,-}kuju{-.O}rnuFigure 5: This display shows the columns visited by the constraint-propagation algorithm whenthe Warlpiri generator is used on the form p l r r I#k I j I - rn<u2> 'scatter-PAST'.
Each reversalof direction begins a new line.
Leftward movement always begins with a position adjacent othe current position, but it is an accidental property of this example that rightward movementdoes also.
The final result is ambiguous because the automata re written to allow underlyinghyphens to appear optionally on the surface.ACKNOWLEDGEMENTSThis report describes research done at the ArtificialIntelligence Laboratory of the Massachusetts Institute ofTechnology.
Support for the Laboratory's artificial intel-ligence research has been provided in part by the Ad-vanced Research Projects Agency of the Department ofDefense under Office of Naval Research contract N00014-80-C-0505.
This research as benefited from guidance andcommentary from Bob Berwick.REFERENCESBarton, E. (1986).
"Computational Complexity in Two-Level Morphology," ACL-86 proceedings (this volume).Gajek, O., H. Beck, D. Elder, and G. Whittemore (1983).
"LISP Implementation \[of the KIMMO system\]," TexasLinguistic Forum 22:187-202.Halle, M. (1985).
"Speculations about the Representa-tion of Words in Memory," in V. Fromkin, ed., Pho-netic Linguistics: Essays in Honor of Peter Ladefoged,pp.
101-114.
New York: Academic Press.Karttunen, L. (1983).
"KIMMO: A Two-Level Morpho-logical Analyzer," Tezas Linguistic Forum 22:165-186.Nash, D. (1980).
Topics in Warlpiri Grammar.
Ph.D. the-sis, Department of Linguistics and Philosophy, M.I.T.,Cambridge, Mass.Winston, P. (1984).
Artificial Intelligence, second edition.Reading, Mass.
: Addison-Wesley.52
