Coling 2010: Poster Volume, pages 782?790,Beijing, August 2010Opinion Target Extraction in Chinese News CommentsTengfei MaXiaojun Wan*AbstractNews Comments on the web expressreaders?
attitudes or opinions about anevent or object in the correspondingnews article.
And opinion target extrac-tion from news comments is very impor-tant for many useful Web applications.However, many sentences in the com-ments are irregular and informal, andsometimes the opinion targets are impli-cit.
Thus the task is very challenging andit has not been investigated yet.
In thispaper, we propose a new approach to un-iformly extracting explicit and implicitopinion targets from news comments byusing Centering Theory.
The approachuses global information in news articlesas well as contextual information in ad-jacent sentences of comments.
Our expe-rimental results verify the effectivenessof the proposed approach.1 IntroductionWith the dramatic development of web 2.0, thereare more and more news web sites allowingusers to comment on news events.
Thesecomments have become valuable resources forresearchers to make advanced opinion analysis,such as tracking the attitudes to a focused event,person or corporation.
In these advanced opinionanalysis tasks, opinion target extraction is anecessary step.
Unfortunately, former works didnot focus on the domain of news comments.Though some researchers and workshops haveinvestigated the task of opinion target extractionin product reviews and news articles, the* Contact authormethods cannot perform well on news comments.Actually, target extraction in news commentssignificantly differs from that in product reviewsand news articles in the following ways.1) Products usually have a set of definiteattributes (e.g.
size) and related opinion words(e.g.
large), and thus researchers can use a smallfixed set of keywords to recognize frequent fea-ture words (Zhuang et al, 2006), or leverage theassociated rules between feature words and opi-nion words to improve the performance (Hu andLiu, 2004; Su et al, 2008; Jin and Ho, 2009; Duand Tan, 2009).
But news comments are morecomplicated.
There are much more potentialopinion targets in news comments.
In otherwords, the candidate targets are in a much moreopen domain.
On the other hand, the opiniontargets in news comments are not strongly asso-ciated with the opinion words.
We cannot judgea target by a special opinion word as easily as inproduct reviews.2) The opinionated sentences in news articlesmostly contain opinion operators (e.g.
believe,realize), which can be used to find the positionsof opinion expressions.
However, news com-ments have already been considered to be de-clared by readers and they do not have manyoperators to indicate the positions of opiniontargets.3) Furthermore, many comment sentences areof free style.
In many cases, there are even nomanifest targets in the comment sentences.
Forexample, a news article and its relational com-ment are as follows:News: ??????????????????
(Dubai will build the highest skyscraper in theworld)Comment:???????????????
(Really high, but what (is it) used for?
)Institute of Compute Science and TechnologyThe MOE Key Laboratory of Computational LinguisticsPeking University{matengfei, wanxiaojun}@icst.pku.edu.cn782The comment sentence obviously commentson ?skyscraper?
by human understanding, but inthe sentence we cannot find the word or an alter-native.
Instead, the real target is included in thenews article.
Now we give two definitions of thephenomenon.Implicit targets: The implicit targets arethose opinion targets which do not occur in thecurrent sentence.
The sentence is called implicitsentence.Explicit targets: The explicit targets are thoseopinion targets which occur in the current rightsentence, and the sentence is called explicit sen-tence.In Chinese comments, the phenomena of im-plicit targets are fairly common.
In our dataset,the sentences with implicit targets make up near-ly 30 percents of the total.In this paper, we focus on opinion target ex-traction from news comments and propose anovel framework uniformly extracting explicitand implicit opinion targets.
The method usesboth information in news articles and informa-tion in comment contexts to improve the result.We extract focused concepts in news articles ascandidate implicit targets, and exploit a new ap-proach based on Centering Theory to taking ad-vantage of comment contexts.We evaluate our system on a test corpus con-taining different topics.
The results show that itimproves the baseline by 8.8%, and the accuracyis also 8.1% higher over the popular SVM-basedmethod.The rest of this paper is organized as follows:The next section gives an overview of the relatedwork in opinion analysis.
Section 3 introducesthe background of Centering Theory and Section4 describes our framework based on CenteringTheory.
In Section 5 we test the results and givea discussion on the errors.
Finally Section 6draws a conclusion.2 Related WorkThe early research of opinion mining only fo-cused on the sentiment classification (Turney etal., 2002; Pang et al, 2002).
However, for manyapplications only judging the sentiment orienta-tion is not sufficient (eg.
Hu and Liu, 2004).Fine-grained opinion analysis has attracted moreand more attention these years.
It mainly in-cludes these types: opinion holder extraction(Kim and Hovy, 2005; Choi et al, 2005), opi-nion target extraction (Kim and Hovy, 2006;Ruppenhofer et al, 2008), and the identificationof opinion proposals (Bethard et al, 2004) andsome special opinion expressions (Bloom et al,2007).
Also, there are some other related tasks,such as detecting users?
needs and wants (Ka-nayama and Nasukawa, 2008).
However, thesegeneral systems are different from ours becausethey do not have or use any contextual informa-tion, and implicit opinion targets are not recog-nized and handled there.A more special domain of feature extraction isproduct and movie reviews.
Hu and Liu (2004)design a system to mine product features andgenerate opinion summaries of customer reviews.Frequent features are extracted by a statisticalapproach, and infrequent features are generatedby the associated opinion words.
The productfeatures are limited in amount and they arestrongly associated with specific opinion words,so researchers can use a fixed set of keywords ortemplates to extract frequent features (Zhuang etal., 2006; Popescu and Etzioni, 2005) or try var-ious methods to augment the database of productfeatures and improve the extraction accuracy byusing the relations between attributes and opi-nions (Ghani et al, 2006; Su et al, 2008; Jin andHo, 2009; Du and Tan, 2009).
However, in newscomments, the opinion targets are not stronglyassociated with specific opinion words and thesetechniques cannot be used.There are also some works focusing on thetarget extraction in news articles, such asNTCIR7-MOAT (Seki et al, 2008).
Differentfrom the news comments, there are opinion indi-cators in the subjective sentences.
However, inour task of this paper, the opinion holders arepre-assigned as the reviewers, so few opinionindicators and holders can be found.To our best knowledge, this paper is the firstwork of extracting opinion targets in news com-ments.
We analyze the complex phenomena innews comments and propose a framework tosolve the problems of implicit targets.
Our me-thod synthesizes the information from relatedarticles and contexts of comments, and it caneffectively improve the extracting results.7833 Background of Centering TheoryCentering Theory (Grosz, Joshi and Weinstein,1995) was developed for an original purpose ofindicating the coherence of a discourse andchoosing a referring expression.
In the theory,the term ?centers?
of an utterance is used torefer to the entities serving to link this utteranceto another utterance in a discourse.
But this isnot the only function of centers, and there aresome other useful characteristics of centers to berecognized.
Our observation shows that a centeralways represents the focus of attention, and thesalience of a center indicates the significance ofthe component as a commented target.
In newscomments, we consider a comment as adiscourse and a sentence as an utterance.
If anutterance has a ?center?, then the center can beregarded as the target of the sentence.Before introducing the common process ofchoosing the centers in utterances, several defi-nitions are elaborated as follows:Forward-looking center: Given an utter-ance U, there is a set of forward-looking cen-ters Cf(U) assigned.
The set is a collection ofall potential centers that may be realized bythe next utterance.Backward-looking center: Each utteranceis assigned exactly one (in fact at most one)backward-looking center Cb.
The backward-looking center of utterance Un+1 connects withone of the forward-looking centers of Un.
TheCb is the real focus of the utterance.Rank: The rank is the salience of an ele-ment of Cf.
Ranking of elements in Cf(Un)guides determination of Cb(Un+1).
The morehighly ranked an element of Cf(Un ), the morelikely it is to be Cb(Un+1).
The most highlyranked element of Cf(Un) that is realized inUn+1 is the Cb(Un+1).
The rank is affected byseveral factors, the most important of whichdepends on the grammatical role, with SUB-JECT > OBJECT(S) > OTHER.Preferred center: In the set of Cf(Un), theelement with the highest rank is a preferredcenter Cp(Un).
This means that it has the high-est probability to be Cb(Un+1).Table 1 is an example of the centers.
In theexample, the target of the first sentence is ?Jack?,which is exactly the preferred center; while inthe second sentence, it is easy to see that ?him?gets more attention than ?the company?
in thisenvironment and thus the backward-looking cen-ter is more likely to be the target.
So we assumethat if Cb(Un) exists, it can be regarded as theopinion target of Un, otherwise the Cp(Un) is thetarget.Utterance CenterU1:????????????????
(Jack regards the com-pany as his life.
)Cf: ??(Jack)/??
(the company)/??
(life)Cb: null Cp: ??
(Jack) U2: ???????????????
(It attributes to him thatthe company can obtaintoday?s achievement.
)Cf: ??
(the company)/??(achievement)/?(??)
(him(Jack))Cb:?(??)
(him(Jack)) Cp:??
(the company)Table 1 Example of different centers.4 Proposed ApproachDue to the problems we introduced in Section 1,the techniques of target extraction in other do-mains are not appropriate in news comments,and general approaches encounter the problemsof free style sentences and implicit targets.
For-tunately, news comments have their own charac-teristics, which can be used to improve the targetextraction performance.One important characteristic is that though po-tential opinion targets may be in large quantities,most comments focus on several central con-cepts in the corresponding news article, especial-ly in the title.
So we can extract the focused con-cepts in the news and use them as potential im-plicit targets for the comments.784The other useful information comes from thefact that the sentences in one comment are usual-ly coherent.
As the comments may be long andeach comment contains several sentences, thesentences within one comment are relevant andcoherent.
So the opinion targets in previous sen-tences have some influence on that in subsequentsentences.
Using this kind of contextual informa-tion, we can eliminate noisy candidates and relaxthe dependence on an unreliable syntactic parser.Considering the above characteristics, wepropose a framework of target extraction basedon focused concepts recognition and CenteringTheory, as shown in Figure 1.Given a news article and its relevant com-ments, we first adopt some syntactic rules toclassify the comment sentences into implicit orexplicit type.
Whether a sentence includes anexplicit target is mainly decided by whether itowns a subject.
A few heuristic rules, such as theappearance of the subject, the combination of thePOS, and the position of the predicate, are usedbased on the parse result by using a ChineseNLP toolkit1, and the rule-based classificationcan attain an accuracy of 77.33%.Then we exploit two different approaches fordealing with the two types of sentences, respec-tively.
For the implicit type, we extract the fo-1 LTP, http://ir.hit.edu.cn/demo/ltp/Sharing_Plan.htmLTP is an integrated NLP toolkit which contains segmenta-tion, parsing, semantic role labeling, and etc.cused concepts in the news article as candidateimplicit targets, and rank them by calculating thesemantic relatedness between the targets and thesentence.
For the explicit type, all nouns andpronouns in the sentence are extracted as candi-date targets and ranked mainly by their gram-matical roles.
At last, Centering Theory is usedto choose the best candidate using the ranks andcontextual information.The details of the main parts are explained inthe following sections.4.1 Focused Concepts (FC) RecognitionAs the comments usually point to the newsarticle, it is highly probable that the implicittargets appear in the news article.
Generally, thefocused concepts of the news article are morelikely to be the commented targets.
Thus, if weextract the focused concepts of the news article,we will get the candidate implicit targets.In general, the focused concepts are namedentities (Zhang et al 2004) or specific nounphrases.
Taking the news?????????????????
(Dubai will build the highest skyscraper in theworld)?
----NEWS1as an example, ???(Dubai)?
and?????(skyscraper)?
are the potential opi-nion targets.
?Dubai?
is a named entity, and?skyscraper?
is a specific noun phrase.
In addi-tion, the focused concepts may also appear in thecontent of the news article, if they attract enoughattention or have strong relations with the fo-cused named entities in the title.As the number of noun phrases is usuallylarge, if we extract the two types of conceptstogether, there must be much noise to impact thefinal result.
To be simple and accurate, we firstextract focused named entities (FNE), and thenexpand them with other focused noun phrases,for the reason that the focused noun phrasesusually have a strong relation with the focusednamed entities.Entity Type Person, Location, Organization,TimeTitle In title or notFrequency The number of occurrenceRelativeFrequencyFrequency/the number of totalwordsNews Article News CommentsSentencesofImplicitTypeSentencesofExplicitTypeFocused namedentity classifierFocusedConceptsImplicitcandidatetargetsExplicitcandidatetargetsChoosing a best target viaCentering TheoryRankingWikipedia-basedESAGrammar RoleAnalysisOpiniontargetsRule BasedClassifierFigure 1: Framework of opinion target ex-traction in news comments785DistributionEntropy(Here we takeN=5 accordingto the length ofarticles)1logNiEntropy p pi i==?
, wherethiOccurrence in the i  Sectionp= Occurrence in TotalTable 2 Features of FNE classificationExtracting FNEs can be seen as a classifica-tion problem.
In this work, we choose the fea-tures in Table 2.Given a news document, we first recognize allnamed entities with our own named entity re-cognizer (NER).Then all named entities are clas-sified based on the above mentioned features.The noun phrases in the title are also extractedand filtered by their frequency in the news ar-ticle and co-occurrences with FNEs.
The filter-ing threshold is set to a relatively high value toguarantee that not much noise is brought in.Thus we can get a small set of focused conceptsin the news article.4.2 Ranking Implicit TargetsWe use the semantic relatedness to decide whichpotential target is most likely to be the right im-plicit target.
There are many methods to calcu-late the semantic relatedness.
We choose theWikipedia-base explicit semantic analysis (ESA)(Gabrilovich and Markovitch, 2007), for itsadaptability and effectiveness for Chinese lan-guage.
The method converts a word or a sen-tence to a series of wiki concepts, and then cal-culates the similarity between words or sen-tences.Input:  a Focused Concept t0 in the news Output: a vector C with a length of N.  C=<(cj,wj)>, where cj is a Wikipedia concept, and wj is the weight of cj 1.
Find all nouns, adjectives and verbs co-occurringwith t0 in the same sentence, and put them into the set S= {ti}.
2.
Compute MI (Mutual information) of each ti with t0.
3.
Choose 10 words in S with the highest MI (ac-cording to the total number of words, 10 is aproper value).
Combine them with t0 into a word vector and assign each word ti a weight of its frequency vi in the news article.
The vec-tor V= <(ti,vi)>, |V|?11.
4.
Let <kij> be an inverted index entry for ti, where kij quantifies the strength of association of ti with Wikipedia concept cj.
Then the vector V can be interpreted as a vector constructed byAll Wikipedia concepts.
Each concept cj has aweight wj= i i ijVt v k??
.5.
Select N concepts with the highest weights.Table 3: Algorithm that converts a focusedconcept to a vector of Wikipedia conceptsChinese Wikipedia is not as large as EnglishWikipedia.
When some words are not includedin the database, the original ESA algorithm willfail.
To solve the problem, we first expand theinput FC with a few words extracted from thenews article.
The words represent the semanticinformation related to the article, so they aremore informative than a single concept whileeasily recognized by the Wikipedia database.The details of the algorithm are shown in Table3.On the other hand, when given a commentsentence, we segment it to words and remove thestop words (e.g.
??
(of)?).
Then the serial ofwords are also converted by ESA into a vector ofWikipedia concepts.After getting the vectors of wiki concepts forfocused concepts and the comment sentence, weuse the cosine metric to obtain their relatednessscores.
In this way, the focused concepts areranked by their relatedness scores with the sen-tence.4.3 Ranking Explicit TargetsA comment sentence with explicit targets usual-ly has a complete syntactic structure.
Accordingto Centering Theory, the ranks of explicit targetsare decided mainly by their grammatical roles.Generally, a subject is most likely to be the opi-nion target, and the rank can be heuristically as-signed by SUBJECT > OBJECT(S) > OTHER.4.4 Choosing Best Candidate target viaCentering Theory (CT)After getting the candidate targets and theirranks, we start the matching step to make use ofcontextual information.
The algorithm originatesfrom the process of choosing preferred centersand backward-looking centers.
A subtle adaptionis that we add some global information in thenews article as the context when dealing with thefirst sentence in a comment.
The details of thealgorithm are represented in Table 4.Now we give an example to show the wholeprocess of the framework.
The following com-ment is associated with NEWS1 in Section 4.1.U1:???????????????
?786(Dubai is developing travel and trades.)U2:???????????
((It) is an active city.)U3:??????????????
(In Dubai you can encounter many miracles.
)First, U1, U2 and U3 are classified as explicit,implicit and explicit, respectively.
Then for U1and U3 we choose noun phrases and pronouns inthe sentence as candidate targets and rank themaccording to their grammatical roles.
U2 choosesFC as candidates, and ?Dubai?
is more relatedthan ?skyscraper?.
At last, the final target is cho-sen by the algorithm in Table 4 and the wholeprocess is illustrated in Table5.Input: A comment with M sentences S={si}, each sentence has a candidate target set Cf(si)={ci}; The Focused Concepts set FC in the news article.Output: A target set {ti}, where each ti is the opinion target of sentence si.
1.
For each si in S 2.
If i=1 (si is the first sentence) 3.
For each  ci in Cf(si) 4.
If ci is contained in FC 5.
Add ci into the set Cb(si) 6.
If Cb(si) is not void  7.
Choose the highest ranked ele-ment in Cb(si) as ti  8.
Else9.
Choose the highest ranked ele-ment in Cf(si) as ti 10.
Else11.
For each  ci in Cf(si)  12.
If ci realizes (equals or refers to) an element c?i in Cf(si-1) 13.
Add c?i into the set Cb(si) 14.
If Cb(si) is not void  15.
Choose the highest ranked ele-ment in Cb(si) as ti  16.
Else 17.
Choose the highest ranked elementin Cf(si) as tiTable 4 Algorithm of choosing the best candi-date target via CTtype ranks of candidates targetU1 Explicit ??>??>????
(Dubai >travel >trade)??
(Dubai)U2 Implicit ??>????(Dubai>skyscraper)??
(Dubai)U3 Explicit ?>??>??(you>miracles>Dubai)??
(Dubai)Table 5 Example of the extraction process5 Experiments5.1 Evaluation SetupTo evaluate the whole system, we evaluate notonly the result of the final target extraction butalso some key steps.
This makes the analysis ofthe bottleneck possible.We first build a FNE dataset to evaluate theFNE classification result.
As our target extrac-tion task focuses on news comments, we collect1000 news articles and the associated user com-ments from http://comment.news.sohu.com,which is a famous website offering a platformfor users to comment on the news.
Every newsarticles are annotated with its focused namedentities, which are also the most possible com-mented targets.Then we build the target dataset to evaluatethe final target extraction.
9 articles and asso-ciated comments are randomly chosen from theFNE dataset, and each of their comment sen-tences is annotated with the opinion target.
Thetarget dataset focuses on 3 different topics: eco-nomics, technology and sports.
Each documentcontains a news article and about 100 relevantcomments, and there are 1597 comment sen-tences in total.We assume that each comment sentence hasone opinion target, but 108 sentences have morethan one focused objects.
In that case, we anno-tate all targets for evaluation and the result isregarded as true if we extract only one of theannotated targets.In the target dataset, there are 444 sentenceswith implicit targets.
This demonstrates that theimplicit target extraction problem is prevalentand worth solving.For the final target extraction, we use the ac-curacy metric to evaluate the result.
It is definedas follows:We do not use the precision and recall metricbecause every comment sentence in our datasetmust have a target after extracting.
The precisionand the recall are both equal to the accuracy.5.2 Evaluation Results5.2.1 FNE ResultsNumber of sentences with right extractionAccuracy= Number of total sentences787We perform a 4:1 cross-validation on the FNEdataset using a commonly used classifier SVM-light2 and gain a mean f-measure of 80.43%.Then, to assess the improvement by the FNEstep and the classification of implicit and explicitsentences, we estimate the theoretic upper limitof the following three target extractions on thetarget dataset.
Test 1 assumes every noun phras-es or nouns in the sentence can be possible to beextracted as the target.
So if there is one candi-date matching the target, we can recognize thesentence as extractable.
Test 2 adopts the anno-tation results of the classification of explicit andimplicit sentences.
For the manually annotatedimplicit targets, we adapt the candidate to be FC.Then, as same as Test 1, all candidates are de-termined whether to be the target.
In Test 3, wefollow the ruled-based classification of implicitand explicit sentences in our system and thenjudge the sentences whether extractable or not.Proportion of extractable sentencesTest 1 55.0%Test 2 69.6%Test 3 61.7%Table 6 Improvement of the proportion of ex-tractable sentences by FNE classification andexplicit/implicit sentence classificationTable 6 shows the proportions of extractablesentences in the three tests.
It is easy to see thatthe proportion of extractable sentences meansthe theoretic optimization of target extraction.
So,by Test 2 we can see the extracted FC set is aneffective complement of the candidate targets,while Test 3 demonstrates that the system stillhas much potential to improve the baseline afterthe rule-based classification of explicit and im-plicit sentences.5.2.2 Target Extraction ResultsTo demonstrate the effectiveness of our ap-proach, we design two baselines.Baseline 1 treats all sentences as explicit type.In the method, we extract all noun phrases andpronouns in a sentence as candidates and obtaintheir ranks according to their grammatical roles.Baseline 2, a SVM-based approach, is offeredto compare with the popular target extractionmethods.
In this method we regard the target2 http://svmlight.joachims.org/extraction as a classification problem.
We ex-tract the candidate noun phrases in a sentencefirst, and then use the semantic features to classi-fy them as targets or not.
The features mainlyinclude: POS, whether or not a Named Entity,the positions in the sentence, the syntactic rela-tions with the verb, and etc.
As it is a supervisedapproach, the result is tested by a 2:1 cross vali-dation.Then we use a method called FC-only (usingonly Focused Concepts) to improve Baseline 1by using the global information in news articles.For sentences of explicit type, we use the me-thod in Baseline1.
For sentences of implicit type,we take focused concepts in news articles as po-tential targets, and choose the highest rankedelement as the final target.Finally, our proposed approach CT (usingCentering Theory) uses both Focused Conceptsand Centering Theory.
When the size of Wiki-pedia concept vector is set to be 800, the com-parison results of the four approaches are shownin Table 7:AccuracyBaseline1 34.38%Baseline2(SVM-based) 35.13%FC-only 37.25%CT 43.20%Table 7 Comparison resultsFC-only is better than Baseline1, which de-monstrates that the focused concepts are usefulto provide information to implicit targets extrac-tion.
444 implicit sentences are a large propor-tion of the total corpus.
And the focused con-cepts do represent the global information andhave influence on the target extraction.Centering Theory is naturally another im-provement.
It mainly takes advantage of the in-formation of contexts within a comment, using arule of coherence to decide the center of atten-tion.
And the result indicates that it is very help-ful.Compared with the SVM-based approach, ourapproach is also much better.
The SVM-basedapproach is only a little higher than Baseline 1.It seems that the manually annotated informationis not very useful in target extraction in newscomments.
The reason may be that the targetrules are complicated and exist not only in thecurrent sentence.
Using global and contextual788information is a more economic and effectiveway to improve the result.In the Wikipedia-based ESA algorithm,thereis a parameter of N, which is the vector size ofthe expanded vector.
It is important to choose aproper parameter value to achieve a high accura-cy and meanwhile keep a low computationalcomplexity.
The accuracy curves for FC and CTwith different values of N are represented inFigure 2.
Apparently, when N exceeds 600, theextraction performance almost does not changeany more.
So we finally take 800 as the value ofN .5.3 Error AnalysisGenerally there are two major types of errorsin the extraction results.
One common error isthat the target is not in our extracted candidatenouns or noun phrases.
For example:??????????????????.?
(Itis a disaster of Chinese beverage that Coca Colabuys HuiYuan.
)The sentence comments on the event of ?CocaCola buys HuiYuan?
but not a single concept?Coca Cola?
or ?HuiYuan?.
But our system can-not recognize this type of targets properly.
Alsothere are some cases that the noun phrasesmissed to be extracted by the LTP toolkit.
Itcauses that the target is not matched by the can-didates.Another error originates from the wrong clas-sification of explicit and implicit sentences.
Forexample,?????????????????.?
(Re-turning profits to civilians can get through thecrisis of little companies.
)In this sentence, ?????
(Returning profitsto civilians)?
is the opinion target and the sen-tence has a explicit target.
But the rules based onthe Chinese parser failed to recognize the phraseas a subject and thus the sentence is consideredas implicit type by our approach.
And lastly thetarget is extracted incorrectly.In 5.2.1, we test the theoretic upper limit ofthe target extraction and prove the potential ef-fectiveness of two steps.
The tests also can beused to estimate the proportion of the types oferrors and analyze the bottleneck.
In Test 2,there are 298 un-extractable sentences amongthe annotated explicit sentences.
It shows thatthere is at least 18.6% loss in accuracy caused bythe candidate recognition, which accounts for thefirst error type.
As for the second error type, itsproportion can be computed by the reductionfrom Test 2 to Test 3, which is 7.9%.6 Conclusion and Future WorkIn this paper, we propose a novel approach toextracting opinion targets in Chinese newscomments.
In order to solve the problem of im-plicit target extraction, we extract focused con-cepts and rank their importance by computingthe semantic relatedness with sentences via Wi-kipedia.
In addition, we apply Centering Theoryto the target extraction system, for utilizing con-textual information.
The experiment resultsdemonstrate that our approach is effective.Currently, the result does not reach an abso-lutely high accuracy.
One bottleneck is that Chi-nese parsing results are far from satisfactory.Actually this bottleneck has impacted the gener-al target extraction long, such as the low perfor-mances of all participants in the target extractiontask of NTCIR7-MOAT-CS.
We hope to im-prove our results by avoid this disadvantage.Moreover, the phenomenon of implicit opiniontargets exists not only in Chinese but also inEnglish and other languages, while sometimes itis similar to zero anaphora.
So the approach inthis paper can be extended to news comments inother languages.AcknowledgementThis work was supported by NSFC (60873155),Beijing Nova Program (2008B03), NCET(NCET-08-0006) and National High-tech R&DProgram (2008AA01Z421).
We thank the ano-nymous reviewers for their useful comments.Figure 2: Accuracy vs. vector size N789ReferencesBethard, Steven, Hong Yu, Ashley Thornton, Vasi-leios Hatzivassiloglou, and Dan Jurafsky.
2004.Automatic Extraction of Opinion Propositions andtheir Holders.
In Proceedings of AAAI SpringSymposium on Exploring Attitude and Affect inText: Theories and Applications.Choi, Yejin, Claire Cardie, Ellen Riloff, and Sidd-harth Patwardhan.
2005.
Identifying Sources ofOpinions with Conditional Random Fields and Ex-traction Patterns.
In Proceeding of HLT/EMNLP?05.Ding Xiaowen, Bing Liu, Philip S. Yu.
2008.
A Ho-listic Lexicon based Approach to Opinion Mining.Proceeding of the international conference on WebSearch and Web Data Mining (WSDM?08), 231-239.Du, Weifu.
and Songbo Tan.
2009.
An Iterative Rein-forcement Approach for Fine-Grained OpinionMining.
The 2009 Annual Conference of the NorthAmerican Chapter of the ACLGabrilovich, Evgeniy.
and Shaul Markovitch.
2007.Computing Semantic Relatedness using Wikipedia-based Explicit Semantic Analysis.
In Proceedingsof the 20th International Joint Conference on Ar-tificial Intelligence (IJCAI).Ghani, Rayid, Katharina Probst, Yan Liu, MarkoKrema, and Andrew Fano.
2006.
Text Mining forProduct Attribute Extraction.
The Twelfth ACMSIGKDD International Conference on KnowledgeDiscovery and Data Mining.Grosz, Barbara J., Scott Winstein, and Aravind K.Joshi.
(1995).
Centering: A Framework for Model-ing the Local Coherence of Discourse.
In Compu-tational Linguistics, 21(2).Hu, Minqing and Bing Liu.
2004.
Mining OpinionFeatures in Customer Reviews.
In Proceedings ofNineteenth National Conference on Artificial Intel-ligence (AAAI-2004)Jin, Wei and Hung Hay Ho.
2009.
A Novel Lexica-lized HMM-based Learning Framework for WebOpinion Mining.
In Proceedings of the 26th Inter-national Conference on Machine Learning (ICML2009).Jin, Wei and Hung Hay Ho, Rohini K. Srihari.
2009.OpinionMiner: A Novel Machine Learning Systemfor Web Opinion Mining and Extraction.
In The15th ACM SIGKDD International Conference onKnowledge Discovery and Data Mining.Kim, Soo-Min.
and Eduard Hovy.
2006.
ExtractingOpinions, Opinion Holders, and Topics Expressedin Online News Media Text.
In ACL Workshop onSentiment and Subjectivity in Text.Kim, Soo-Min.
and Eduard Hovy.
2005.
IdentifyingOpinion Holders for Question Answering in Opi-nion Texts.
In Proceedings of AAAI-05 Workshopon Question Answering in Restricted Domains.Pang, Bo and Lillian Lee, and Vaithyanathan, S. 2002.Thumbs up?
Sentiment classification using ma-chine learning techniques.
In EMNLP 2002.Popescu, Ana-Maria.
and Oren Etzioni.
2005.
Ex-tracting Product Features and Opinions from Re-views.
In Proceeding of 2005 Conference on Em-pirical Methods in Natural Language Processing(EMNLP?05), 339-346.Riloff, Ellen and Janyce Wiebe.
2003.
Learning Ex-traction Patterns for Subjective Expressions.
Pro-ceedings of the 2003 Conference on EMNLP.Ruppenhofer, Josef, Swapna Somasundaran, and Ja-nyce Wiebe.
2008.
Finding the Sources and Tar-gets of Subjective Expressions.
In LREC08.Seki, Yohei, David K. Evans, Lun-Wei Ku, Le Sun,Hsin-Hsi Chen, and Noriko Kando.
2008.
Over-view of Multilingual Opinion Analysis Task atNTCIR-7.
The 7th NTCIR workshop (2007/2008).Su Qi, Xinying Xu, Honglei Guo, Zhili Guo, XianWu,Xiaoxun Zhang, Bin Swen and Zhong Su.
2008.Hidden Sentiment Association in Chinese WebO-pinion Mining.
In The 17th International WorldWide Web Conference (WWW).Turney, Peter D. 2002.
Thumbs up or thumbs down?Semantic orientation applied to unsupervised clas-sification of reviews.
In Proceedings of the 40thAnnual Meeting of the Association for Computa-tional Linguistics (ACL).Zhang, Li, Yue Pan, and Tong Zhang.
2004.
FocusedNamed Entity Recognition using Machine Learn-ing.
The 27th Annual International ACM SIGIRConference.Zhuang, Li, Feng Jing.
and Xiao-yan Zhu.
2006.Movie Review Mining and Summarization.
In Pro-ceedings of the 15th ACM International Confe-rence on Information and Knowledge Management(CIKM?06), 43-50.790
