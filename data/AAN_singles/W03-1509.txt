Chinese Named Entity Recognition Combining a Statistical Model withHuman KnowledgeYouzheng WU Jun ZHAO Bo XUNational Laboratory of Pattern RecognitionInstitute of Automation Chinese Academy of SciencesNo.95 Zhongguancun East Road, 100080, Beijing, China(yzwu, jzhao,boxu)@nlpr.ia.ac.cnAbstractNamed Entity Recognition is one of thekey techniques in the fields of naturallanguage processing, information retrieval,question answering and so on.Unfortunately, Chinese Named EntityRecognition (NER) is more difficult forthe lack of capitalization information andthe uncertainty in word segmentation.
Inthis paper, we present a hybrid algorithmwhich can combine a class-basedstatistical model with various types ofhuman knowledge very well.
In order toavoid data sparseness problem, weemploy a back-off model and?????
?/TONG YI CI CI LIN?
, a Chinesethesaurus, to smooth the parameters in themodel.
The F-measure of person names,location names, and organization nameson the newswire test data for the 1999IEER evaluation in Mandarin is 86.84%,84.40% and 76.22% respectively.1 IntroductionThe NER task was first introduced as MessageUnderstanding Conference (MUC) subtask in 1995(MUC-6).
Named Entities were defined as entitynames (organizations, persons and locations),temporal expressions (dates and times) and numberexpressions (monetary values and percentages).Compared with the entity name recognition, therecognition of temporal and number expressions issimpler.
So, our research focuses on therecognition of person, location and organizationnames.The Multilingual NE task first started in1995(MET-1), including Chinese, Japanese, andSpanish in that year, and continued for Chinese,Japanese in 1998(MET-2).
Compared with EnglishNER, Chinese NER is more difficult.
We think themain differences between Chinese NER andEnglish NER lie in:First, unlike English, Chinese lacks thecapitalization information that plays an importantrole in signaling named entities.Second, there is no space between words inChinese, and we have to segment the text beforeNER.
However, the errors in word segmentationwill affect the result of NER.Third, Different types of named entities havedifferent structures, especially for abbreviativeentities.
Therefore, a single unified model can?tcapture all the types of entities.
Typical structuresof Chinese person name (CN), location name (LN)and organization name (ON) are as follows:CN--><surname> <given name>LN--><name part>* <a salient word>ON-->{[person name] [organization name] [placename] [kernel name] }*  [organization type] <asalient word>Here <>* means repeating one or several times.
{}* means selecting at least one of items.Fourth, there are few openly available resourcesfor Chinese NER.
Thus we have to resort to thealgorithm that doesn?t rely on large NER-taggedtext corpus.Based on the above analysis, we present ahybrid algorithm that incorporating various typesof human knowledge into a statistical model.
Theinnovative points of our paper are as follows.First, the hybrid algorithm can make the bestuse of existing limited resources to develop aneffective NER system.
These resources includeone-month?s Chinese People?s Daily tagged withNER tags by Peking University (which containsabout two-million Chinese characters) and varioustypes of human knowledge.Second, in order to compensate for the lack oflabeled corpus, we use several types of humanknowledge, such as?????
?/TONG YI CICI LIN?
[Mei.J.J, et al 1983], a general locationnames list, the list of the salient words in locationname, the list of the salient words in organizationnames, a Chinese surnames list, the list of Chinesecharacters that could be included in transliteratedperson names, and so on.Third, we emphasize that human knowledgeand statistical information should be combinedvery well.
For example, a general LN list and ageneral famous ON list are used in our system.However, we only accept words in the lists asentity candidates with a probability.
Whether it isa LN or ON depends on the context.
This isdifferent from other systems which accept them asa LN or ON once the system meets them.
Moredetails refer to section 4.This paper will be organized as follows.
Section2 is the background of NER.
Section 3 describesthe class-based statistical baseline Chinese NERmodel.
Section 4 describes different types ofhuman knowledge for different named entitiesrecognitions and how to combine them with astatistical model organically in details.
Section 5 isthe evaluation and section 6 is the conclusion.2 BackgroudThe researches on English NER have madeimpressive achievement.
The best NER system[Mikheev, et al 1999] in MUC7 achieved 95%precision and 92% recall.
Recent methods forEnglish NER focus on machine-learningalgorithms such as DL-CoTrain, CoBoost [Collinsand Singer 1999], HMM [Daniel M. Bikel 1997],maximum entropy model [Borthwick, et al 1999]and so on.However, Chinese NER is still at its immaturephase.
Typical Chinese NER systems are asfollows.NTU system [Hsin-His Chen, et al 1997] reliedon a statistical model when recognizing personnames, but rules when recognizing location andorganization names.
In the formal run of MET-2,the total F-measure is 79.61%.
As a result, theymay miss the person names whose probability islower than the threshold, the location andorganization names may also be missed for thosewhich don?t accord with the rules.
[Yu et al 1998] uses both a contextual modeland a morphological model.
However, their systemrequires information of POS tags, semantic tagsand NE lists.
The system obtains 86.38% F-measure.
[CHUA et al 2000] employs a combination oftemplate-based rules supplemented by the default-exception trees and decision tree that obtains over91% F-measure on MET-2 test data.
It also usesHowNet [Dong & Dong 2000] to clustersemantically related words.
[Jian Sun, 2002] presents a class-basedlanguage model for Chinese NER which achieves81.79% F-measure on MET-2 test set and 78.75%F-measure on IEER test data.
However, the modelheavily depends on statistical information, andmust be trained on large labeled corpus.For Chinese NER, we can?t achieve satisfactoryperformance if we use only a statistical model orhandcrafted heuristic rules.
Therefore, we have toresort to the algorithm that can incorporate humanknowledge into a statistical model.In the following sections, we will introduce astatistical Chinese NER model first, and thenincorporate various types of human knowledge intothe statistical model in order to show the power ofhuman knowledge for Chinese NER.3 The Baseline Class-based StatisticalModelWe regard NER as a tagging problem.
Given asequence of Chinese string nwwwW L21= , the taskof NER is to find the most likely sequence of classsequence ( )nmcccC m <== L21*  that maximizesthe probability ( )WCP | .
We use Bayes?
Rule torewrite ( )WCP |  as equation (3.1):( ) ( )( )( )( )WPCPCWPWPWCPWCP ?== )|(,|             (3.1)So, the class-based baseline model can beexpressed as equation (3.2).
( ) ( )( )( ) ( )( )( ) ( )????????
??
?=?=?=?miiiiijiCmmnCCccPcwwPcccPcccwwwPCPCWPC111212121||maxarg|maxarg|maxarg*LLLL (3.2)We call ( )CP  as the contextual model and( )CWP |  as the morphological model.
Formally, wecan regard such a class-based statistical model asHMM.
The classes used in our model are shown inTable 1, where |V| means the size of vocabularyused for word segmentation.Class DescriptionPN Person NameLN Location NameON Organization NameTM Time NameNM Number NameOther One word is on ClassTotal |V| + 5Table 1 Classes used in our model3.1 Contextual ModelDue to our small-sized labeled corpus, we use astatistical bi-gram language model as thecontextual model.
This model can be described asequation (3.3).
( ) ( )?==?
?miiii ccPCP11|                                       (3.3)Theoretically, trigram is more powerful forNER than bi-gram, however when training corpusis small, trigram can?t work effectively.
Using bi-gram model, we still need ( )25+V  transmissionprobabilities, some of which can?t be observed inour small-sized labeled corpus and some of whichare unauthentic.
That is, data sparseness is stillserious.
We will explain how to resolve datasparseness problem in details in section 3 and 4.3.2 Morphological ModelRecognition of Person NamesThe model of person names recognition(including Chinese person names abbreviated toCN and Transliterated person names abbreviated toTN) is a character-based tri-states unigram model.In principle, Chinese person name is composedof a surname (including single-character surnamelike "?/wu" and double-character surname like"??
/Ouyang") and a given name (one or twocharacters like "?/peng" or "??/youzheng").
Sowe divide Chinese name words into three parts asthe surname (surCN), the middle name (midCN)and the end name (endCN), which means theprobability of a specific character used in differentposition in person names isn?t equal.
For example, ( ) ( )( )endCNc|?/wuCNsc|?/wusurCNc|?/wujjj=?=?=PecPP         (3.4)The model for three-character-CN recognitionis described as equation (3.5).
( )( ) ( )( )endCNcwPmidCNcwPsurCNcwPCNcwwwPjjjjjjjjjj=?=?=?=||||321321(3.5)The model for two-character-CN recognition isdescribed as equation (3.6).
( )( ) ( )endCNwPsurCNwPCNcwwPjjjjj|||2121?
?=        (3.6)where ( )CNcwwwP jjjj =|321  means the probabilityof emitting the candidate person name 321 jjj wwwunder the state of CN.For TN, we don?t divide transliterated namewords into several different parts.
That is, theprobability of a word used in different position inTN is same.
The model is as follows.
( ) ( )?===?=kiijjijjkjj TNcwPTNcwwwP121 ||L (3.7)Must be mentioned is that all these probabilitiesare estimated from labeled corpus using maximumlikelihood estimation.Recognition of Location NamesFor location names recognition, we use a word-based bi-state unigram model, and divide wordsused in the location name into two parts: location-end-words (LE) and non-location-end words(NLE).
That means the probability of the wordused in the end position of location name isdifferent from that of in other position.The model for location name recognition isshown in equation (3.8).
( )( ) ( )LEcwPNLEcwPLNcwwwPjjkkiijjijjkjj=?=?=?
?==|||1121 L(3.8)The parameters in equation (3.8) are alsoestimated from labeled training corpus.Recognition of Organization NamesFor the model of organization namesrecognition, we use bi-state unigram that is similarto the location morphological model shown asequation (3.9): ( )( ) ( )NOEcwPOEcwPONcwwwPjjkkiijjijjkjj=?===?
?==|||1121 L(3.9)where OE means the word used in the end positionof organization name, while NOE is not.The parameters in equation (3.9) are alsoestimated from the labeled training corpus.Back-off Models to SmoothData sparseness problem still exists.
As someparameters were never observed in trained corpus,the model will back off to a less-powerful model.We employ escape probability to smooth thestatistical model [Teahan, et al 1999].An escape probability is the probability that apreviously unseen character will occur.
There is notheoretical basis for choosing the escapeprobability optimally.
Here we estimate the escapeprobability in a particular context as:nd5.0=?
(3.10)The probability of a word ci that has occurred ctimes in that context ci-1 is:( )ncccP ii5.0| 1?=?
(3.11)While the probability of a word that has neveroccurred in that context is:( ) ( )iii cPccP ?=?
?1|                                     (3.12)where n is the number of times that context hasappeared and d is the number of different symbolsthat have directly followed it.As a example, if we observe the bi-gram "A B"once in training corpus and ?A C" three times, andnowhere else did we see the word "A", then( )315.03| +?=ACP , while the escape probability3125.0+?=?
and unseen transition probability of( ) ( )DPADP ?= ?| .The Evaluation for the BaselineThe baseline model was evaluated in terms ofprecision (P), recall (R) and F-measure (F) metrics.responsesofnumberresponsescorrectofnumberP =NEallofnumberresponsescorrectofnumberR =( )( ) RPRPF +??
?+= ??
12                                       (3.13)where ?
is a weighted constant often set to 1.We test the baseline system on the newswiretest data for the 1999 IEER evaluation in Mandarin(http://www.nist.gov/speech/tests/ie-r/er_99/er_ 99.htm).
Table 2 in section 4 summarizes the result ofbaseline model.Precision Recall F-measurePN 80.23% 89.55% 84.63%LN 45.05% 66.96% 53.86%ON 42.98% 61.45% 50.58%Total 52.61% 71.53% 60.63%Table 2 The Performance of The Baseline4 The Hybrid Model IncorporatingHuman Knowledge into the BaselineFrom table 1, we find that the performance ofthe above statistical baseline model isn?tsatisfactory.
The problems mainly lie in:?
Data sparseness is still serious though weonly use bi-gram contextual model, unigrammorphological model and smooth the parameterswith a back-off model.?
In order to recognize the named entities,we have to estimate the probability of every wordin text as named entities.
Thus redundantcandidates not only enlarge search space but alsoresult in many unpredictable errors.?
Abbreviative named entities especiallyorganization abbreviation can?t be resolved by thebaseline model.
Because abbreviations have weakstatistical regularities, so can?t be captured by sucha baseline model.We try to resolve these problems byincorporating human knowledge.
In fact, humanbeing usually uses prior knowledge whenrecognizing named entities.
In this section, weintroduce the human knowledge that is used forNER and the method of how to incorporate theminto the baseline model.Given a sequence of Chinese characters, therecognition process after combined with humanknowledge consists of the five steps shown in Figure1.Figure 1 Recognition Process of the Hybrid Model4.1 Incorporate Knowledge for Person NameRecognitionChinese person names are composed of asurname and a given name.
Usually the charactersused for Chinese person names are limited.
[Maosong Sun, Changning Huang, 1994] presents365 most high frequently used surnames cover99% Chinese surnames.
1141 most high frequentlyused characters cover 99% Chinese given names.Similarly the characters used for transliteratednames are also limited.
We extract about 476transliterated characters from the training corpus.The following is the human knowledge used forperson name recognition and the method of how toincorporate them into the baseline.?
A Chinese single and plural surname list:Only those characters in the surname list cantrigger person name recognition.?
A list of person title list: Only when thecurrent character belongs to the surname list andthe next word is in the title list, candidates areaccepted.?
A transliterated character list: Onlythose consecutive characters in the transliteratedcharacter list form a candidate transliterated name.?
Person name can?t span any punctuationand the length of CN can?t exceed 8 characterswhile the length of TN is unrestrained.All these knowledge are used for restrictingsearch space.4.2 Incorporate Knowledge for LocationName RecognitionA complete location name is composed of thename part and a salient word.
For the locationname "??
?/Beijing City", the name part is "??
/Beijing" and the salient word is "?
/city".Unfortunately, the salient word is omitted in manyoccasions.
So it is unfeasible to trigger LNrecognition only depending on the salient words inlocation name.
In order to improve the precisionand recall of LN recognition, we use the followinghuman knowledge.
The method of incorporatingthem is also explained.?
A general location name list: The listincludes the names of Chinese provinces andcounties, foreign country and its capitals, somefamous geographical names and foreign cities.
Ifthe current word is in the list, we accept it as acandidate LN.?
A location salient word list: If the wordwi belongs to the list, 2~6 words before the salientword are accepted as candidate LNs.?
A general word list (such as verbs andprepositions) which usually is followed by alocation name, such as "?
/at", "?
/go".
If theword wi is in the list, 2~6 words following it areaccepted as candidate LNs.?
An abbreviative location name list: If thecurrent word is in the list, we accept it as acandidate LN such as "?/China", "?/America".PN and LNGenerateNE CandidatesRecognition NestedOrganization NamesNamed EntitiesHuman KnowledgeTONG YI CI CI LINExtractOrganization KernelWord SegmentationNested OrganizationName TemplatesNE PoolsTextSearch the Max.P(C|W)?
Coordinate LN recognition: If wi-2 is acandidate LN and wi-1 is "?
"(a punctuationdenoting coordinate relation), LN recognition istriggered at the position of word wi.?
Location name can?t span punctuations andits length couldn?t exceed 6 words.Knowledge ?, ?, ?, ?, ?
can restrictsearch space while knowledge ?
deals withabbreviative location name.4.3 Incorporate Knowledge for OrganizationName RecognitionThe organization names recognition is the mostdifficult task.
The reasons lie in nested ONs andabbreviative ONs especially.Nested ON means there are one or morelocation names, person names and/or organizationnames embedded in organization name.
Typicalstructure of ON has been given in section 1.
Wecan capture most of the nested organization namesby several ON templates mentioned in thefollowing section.Abbreviative ONs include continuous anddiscrete abbreviation which omits some words inthe full name.
Take "????????????"
as example, abbreviative ON of it may omit LN "??
/Shanghai", organization types like"?
?/supermarket", "?
?/stock", "?
?/limited", andsalient word like "?
?/company" from full namesbut usually remains organization kernel "??/Hualian".
Table 3 lists some examples ofabbreviative ONs.???????????
?Shanghai HualianCo.,Ltd???
?ShanghaiHualian Continuous Abbreviation???
?Tsinghua niversity??Tsinghua??????
?Shanghai StockExchange?
?ShanghaiStock Discrete Abbreviation ???
?Peking University?
?Bei DaTable 3 Nest Organization Full Names and ItsAbbreviative NamesSo it is important to extract organization kernelfrom the full name in order to recognizeabbreviative ON like "????".
Moreover, anorganization's abbreviative names usually occurafter its' full name, unless it is a well-knownorganization.
So this strategy for abbreviationorganization name recognition is effective.The following is the human knowledge used forON recognition and the method of how toincorporate them.?
An organization salient word (OrgSws)list: If the current word wi is in OrgSws list, 2~6words before OrgSw are accepted as the candidateONs.?
A general famous organization name list:If the current word is in the list, we accept it as acandidate ON such as "??
?/ State Department","??
?/ U.N.
".?
An organization names template list: Wemainly use organization name templates torecognize the nested ONs.
Some of these templatesare as follows:ON-->LN D* OrgSwON-->PN D* OrgSwON-->ON OrgSwD means words used in the middle of organizationnames.
D* means repeating zero or more times.This component runs in the end stage ofrecognition process shown in Figure 1.?
An organization type list: The list is usedto extract organization kernels from recognizedONs.
We have a pool which memorizes ONsrecognized in current paragraph and its kernel.
Ifthe current word belongs to organization kernel inpool, we accept it as a candidate ON.
The idea iseffective especially in financial domain whichcontains many stocks such as"???
?/ShanghaiHualian", "???
?/Changjiang Technology".Knowledge ?, ?, ?
restrict search spacewhile knowledge ?
deals with abbreviativeorganization name.4.4 Semantic Similarity Computation forData Sparseness?????
?/TONG YI CI CI LIN?classifiesthe words in terms of semantic similarity.
Here weuse it to resolve data sparseness problem.
If currenttransmission probability doesn?t exist, we resort toits synonym transmission.
In statistical sense,synonym transmissions are approximate.
Take anexample, the probability of P(A|B) doesn?t exist,but there has P(C|B), meanwhile, the word A andC are thesaurus according to ?????
?/TONGYI CI CI LIN?, then we use P(C|B) to replaceP(A|B).5 Results of EvaluationWe also test our hybrid model on IEER-99 neswiretest data.
The performance is shown in Table 4.Precision Recall F-measurePN 83.30% 92.28% 87.56%LN 88.31% 84.69% 86.47%ON 84.49% 71.08% 77.21%Total 86.09% 83.18% 84.61%Table 4 The Performance of the Hybrid ModelComparing Table 1 with 4, we find that theperformance of the hybrid model increasesremarkably.
More specifically, the precision andthe recall of PNs increase from 80.23% to 83.30%and from 89.55% to 92.28% respectively.
Theprecision and recall of LNs increase from 45.05%to 82.18% and from 66.96% to 86.74%respectively.
The precision and recall of ONsincrease from 42.98% to 80.86% and from 61.45%to 72.09% respectively.
The reason that theimprovement of PNs is slighter than that of ONsand LNs is that the statistical informationestimated from labeled corpus for PNs is goodenough but not for LNs and ONs.Must be mentioned is that, in our evaluation,only NEs with both correct boundary and correcttype label are considered as the correctrecognitions, which is a little different from otherevaluation systems.We also test our system on data set of sport,finance, news and entertainment domains.
Thesetest data are downloaded from Internet shown inTable 4.Number of NEDomainPN LN ONFilesizeSport(S) 954 510 609 91KFinance(F) 212 406 461 80KNews(N) 526 961 437 76KEntertainment(E) 1016 511 133 100KTotal 2708 2388 1640 247KTable 4 Statistic of Multi-field Test DataThe results are shown in Table 5.Precision Recall F-measureS 80.17% 91.10% 85.28%F 61.35% 94.34% 74.35%N 88.66% 83.27% 85.88%PNE 82.20% 82.28% 82.24%S 82.90% 81.76% 82.33%F 83.72% 81.03% 82.35%N 91.95% 91.56% 91.75%LNE 81.64% 87.87% 84.64%S 73.43% 67.16% 70.15%F 65.88% 60.30% 62.97%N 92.52% 84.70% 88.44%ONE 78.30% 62.41% 69.46%Total 81.01% 81.24% 81.12%Table 5 Results on different domainTable 5 shows that the performance on financialdomain is much lower.
The reason is that, infinancial domain, there are many stock nameswhich are the abbreviation of organization names.Moreover, organization full name never appear inthe text.
So the system can?t recognize them as anorganization name.
However, on many occasions,they are recognized as person names.
As a result,the precision of PNs declines, meanwhile, theprecision and recall of ONs can?t be high.Based on the above analysis, we find that themain sources of errors in our system are as follows.First, we still have not found a good strategy forthe abbreviation location names and organizationnames.
Because abbreviative LNs and ONssometimes appear before full LN, sometimes not,so the pool strategy can?t work well.Second, some famous organization names thatalways appear in the shape of abbreviation can?t berecognized as ON because the full name neverappear such as ??
/GaoTong, ??
/Xinlang.However, these ONs are often recognized as PNs.Such errors are especially serious in financedomain shown Table 5.Third, many words can?t be found in ?????
?/TONG YI CI CI LIN?.6 ConclusionsChinese NER is a more difficult task than EnglishNER.
Though many approaches have been tried,the result is still not satisfactory.
In this paper, wepresent a hybrid algorithm of incorporating humanknowledge into statistical model.
Thus we onlyneed a relative small-sized labeled corpus (one-month?s Chinese People?s Daily tagged with NERtags at Peking University) and human knowledge,but can achieve better performance.
The maincontribution of this paper is putting forward anapproach which can make up for the limitation ofusing the statistical model or human knowledgepurely by combining them organically.Our lab was mainly devoted to cross-languageinformation processing and its application.
So inthe future we will shift our algorithm to otherlanguages.
And fine-tune to a specific domain suchas sports.ACKNOWLEDGEMENTThis paper is supported by the National ?973?project G1998030501A-06 and the Natural ScienceFoundation of China 60272041.ReferencesJian Sun, et al 2002.
Chinese Named EntityIdentification Using Class-based Language Model.Proceedings of the 19th International Conference onComputational LinguisticsHsin-His Chen, et al 1997.
Description of the NTUSystem Used for MET2.
Proceedings of the SeventhMessage Understanding ConferenceTat-Seng Chua, et al 2002.
Learning Pattern Rules forChinese Named Entity Extraction.
Proceedings ofAAAI?02W.J.Teahan, et al 1999.
A Compression-basedAlgorithm for Chinese Word Segmentation.Computational Linguistic 26(2000) 375-393Maosong Sun, et al 1994.
Identifying Chinese Names inUnrestricted Texts.
Journal of Chinese InformationProcessing.
1994,8(2)Collins, Singer.
1999.
Unsupervised Models for NamedEntity Classification.
Proceedings of 1999 JointSIGDAT Conference on Empirical Methods in NLPand Very Large CorporaDaniel M. Bikel, et al 1997.
Nymble: a High-Performance Learning Name-finder.
Proceedings ofANLP-97, page 194-201, 1997Yu et al 1998.
Description of the Kent Ridge DigitalLabs System Used for MUC-7.
Proceedings of theSeventh Message Understanding ConferenceSilviu Cucerzan, David Yarowsky.
1999.
LanguageIndependent Named Entity Recognition CombiningMorphological and Contextual Evidence.Proceedings 1999 Joint SIGDAT Conference onEMNLP and VLCPeter F.Brown, et al 1992.
Class-Based n-gram Modelof Natural Language.
1992 Association forComputational LinguisticsA.Mikheev, M.Moens, and C.Grover.
1999.
Namedentity recognition without gazetteers.
Proceedings ofthe Ninth Conference of the European Chapter of theAssociation for Computational Linguistics.
Bergen,NorwayBorthwich.
A.
1999.
A Maximum Entropy Approach toNamed Entity Recognition.
PhD DissertationDong & Dong.
2000.
Hownet.
At: http://www.keenage.comYu.S.W.
1999.
The Specification and Manual ofChinese Word Segmentation and Part of SpeechTagging.
At: http://www.icl.pku.edu.cn/Introduction/corpustagging.
htmMei.J.J, et al 1983.
?????
?/TONG YI CI CILIN?.
Shanghai CISHU Press
