ADAPTATION TO NEW MICROPHONESUSING TIED-MIXTURE NORMALIZATIONAnastasios Anastasakost, Francis Kubala, John Makhoul, Richard SchwartzABSTRACTBBN Systems and Techno log iesCambr idge  MA 02138tNor theastem Un ivers i tyBoston  MA 02115In this paper, we present several approaches designed to increasethe robustness of BYBLOS, the BBN continuous peech recogni-tion system.
We address the problem of increased egradation i ?performance when there is mismatch in the characteristics of thetraining and the test microphones.
We introduce a new supervisedadaptafi.~n algor/thm that computes a transformation from the train-hag microphone codebook to that of a new microphone, given someinformation about the new microphone.
Results are reported forthe development and evaluation test sets of the 1993 ARPA CSRSpoke 6 WSJ task, which consist of speech recorded with two al- ?temate microphones, a stand-mount and a telephone microphone.The proposed algorithm improves the performance of the system ?
?when tested with the stand-mount microphone by reducing the dif-ference ha error rate between the high quality training microphoneand the alternate stand-mount microphone recordings by a factorof 2.
Several results are presented for the telephone speech leading ?to important conclusions: a) the performance on telephone speechis dramaticaUy improved by simply retraining the system on thehigh-quality training data after they have been bandlimited in thetelephone bandwith; and b) additional training data recorded withthe high quality microphone give luther substantial improvementha performance.1.
INTRODUCTIONInteractive speech recognition systems are usually trainedon substantial mounts of speech data collected with a highquality close-talking microphone.
During recognition, thesesystems require the same type of microphone to be used inorder to achieve their standard accuracy.
This is a highly re-stdcting condition for practical applications of speech recog-nition systems.
One can imagine a situation, where it wouldbe desirable to use a different microphone for recognitionthan the one with which the training speech was collected.For example, some users may not want to wear a head-molmted microphone.
Others may not want to pay for ahigh quality microphone.
Additionally, many applicationsinvolve recognition of speech over telephone lines and tele-phone sets with high variability in quality and characteristics.However, we know that even highly accurate speech recog-nition systems perform very poorly when they are tested withmicrophones with different characteristics than the ones thatthey were trained on \[1\].There is a wide range of approaches in order to compensatefor this degradation i performance including:Retrain the HMMs with data collected with the newmicrophone ncountered during the recognition stage,a rather expensive approach for real applications, or bytraining on a large number of microphones in the hopethat the system will obtain the necessary robustness.Use robust signal processing algorithms.Develop a feature transformation that maps the alternatemicrophone data to training microphone data.Use statistical methods in order to adapt he parametersof the acoustic models.In previous work we had discussed the use of CepstmmMean Subtraction and the RASTA algorithm as two simplesignal processing algorithms to compensate he degradationcaused by an alternate channel \[7\].
In this pape r, we presentan approach towards feature mapping by modeling the dif-ference between the test and the training microphone, priorto reco tion.We have developed the Tied-Mixture Normalization Algo-rithm, a technique for adaptation to a new microphone basedon modifying the continuous densities in a tied-mixtureI-IMM system, using a relatively small amount of stereotraining speech.
This method is presented in detail in Sec-tion 2.
In Section 3 we describe several experiments ona known microphone task and the effect of the adaptationmethod in the performance of the recognition system.2.
T IED MIXTURE NORMALIZAT IONIn a Tied-Mixture Hidden Markov Model (TM-HMM) sys-tem \[2, 6\], speech is represented using an ensemble of Gaus-sian mixture densities.
Every frame of speech is representedas a Gaussian nfixture model.
Specifically the probabilitydensity function for an observation conditioned on the H/vIMstate is expressed as:325cb,, = Pr(ztlst) = ~ ck N(z+; #k, Ek)k=lwhere zt, st, C, ck, #k, Zk are the observed speech flame attime ~, the HMM state at time t, the number of clustersof the codebook, and for k-th mixture density, the mixtureweight, the mean and the covariance matrix respectively.The vector quantization (VQ) codebook which consists ofthese mean vectors and covariance matrices, has been de-rived from a subset of the training data, therefore it is mostlychaaacteristic of the location and distribution of the train-ing data and the training microphone in the acoustic space.However if the codebook was created with data collectedwith some other microphone, due to the additive and convo-lutional effect on speech specific to this new microphone, thedata would be disl~ibuted ifferently in the acoustic spaceand the ensemble of means and covariances of the code-book would reflect the characteristics of the new micro-phone.
This is the case of the mismatch in training andtesting microphone.
Without any compensation, we quan-tize the test data, recorded with the new microphone, usingthe mixture codebook generated from recordings with thetraining microphone.
This inevitably results in a degrada-tiun in performance, since the codebook does not model thetest data.We introduce a new algorithm, called Tied Mixture Normal-ization (TMN) to compute the codebook transformation fromthe training microphone to the new test microphone.
TheTIV~N algorithm requires a relatively small amount of stereospeech adaptation data, recorded with the microphone usedfor training (primary microphone) and the new microphone(alternate microphone).
Then using the stereo data, we canadapt he existing HMM model to work well on the new testcondition despite the mismatch with the training.Figure 1 provides a schematic description of the TMN al-gorithm.
We assume that we have a tied-mixture densitiescodebook (set of Gaussians distributions), derived from asubset of the training data that was recorded with the pri-mary microphone.
We quantize the adaptation data fromthe primary channel and label each frame of speech withthe index of the most likely Gaussian distribution in thetied-mixture codebook.
Since there is an one-to-one corre-spondence between data of the primary and alternate channelwe use the VQ indices of the frames of the data of the pri-mary channel to label the corresponding frames of the dataof the alternate channel.
Then for each of the VQ clus-ters, from all the frames of the alternate microphone datawith the same VQ label, we compute the sample mean andthe sample covariance of the cepstrum vectors that representa possible shift and scaling of this cluster in the acousticC.n,o+t, Wotor VO'n+ i +a+Parameters~ I Quantizer GaussianAlternate Input CodebookParametersAlternateCodebookFigure 1: Estimation of alternate microphone Gaussian mix-ture densities codebookspace (Fig.
2).
These are the new means and covariances ofthe Gaussian distributions of the new normalized codebook.Original Codebook Mapped Codebook, ~ ?.,..., .
.
.
.
.
.
.
.
,..,..,%.~ ~-,.-"-,-, ~ 1 ~ r-,--' ' " " - '~ '+ t~,  Lt, "..r~ ".if' +.r t re2 3 :I \+ .1"k+ pg +% '.-.--.
.
.
.
_..,...j ~++i+.
+j PFigure 2: The mapped Gaussian codebook is a shifted andscaled version of the original codebookThe new Gaussian densities are used in conjunction withthe mixture weights ck (sometimes called the discrete prob-abilities) of the original model to compute the observationprobability density function as expressed previously.One of the possible weaknesses of the TMN algorithm isthat each cluster of the original codebook is transformed in-dependently of all the others.
This assumption goes againstour intuition that a codebook transformation, due to differ-ent microphone characteristics, should maintain continuitybetween adjacent codebook clusters and shift all the clus-ters in the same general direction.
Additionally, a potentialproblem may arise when a particular cluster does not haveenough samples to compute its statistics.
Hence, we maynot estimate the correct ransformation due to insufficientor distorted ata by modeling each codebook cluster inde-pendently.
To alleviate this problem we use the followingapproach, originally suggested for speaker adaptation \[4\]:when the centroid of the ith codebook cluster is denoted byrn~ and that of the transformed alternate microphone by #i,326the deviation vector between these two centroids isdi = pi - ra/ i = 1, 2, ..., C (1)where C is the size of the codebook.
For each cluster cen-troid ci, the deviation vectors of all clusters {d~} are summedwith weighting factors {wik} to produce the shift vector zli:C CZli = (Z  wikdi)/(~ wlk) (2)k=l k=lThe weighting factor wik is the probability {P(mklra.i)} ~of centroid mk of the original codebook to belong to theith cluster aised to the a power.
This weight is a measureof vicinity among clusters and the exponentiation controlsthe amount of smoothing between the clusters.
Finally, thecentroid c~ of the ith duster of the transformed codebook is:c~ = ci + zSi (3)Similarly the covariances of the clusters of the new codebooka~-e computed as the averaged summations over all samplecovariances computed in the first implementation f TMN.the development and evaluation sets of Spoke 6 of the WSJIcorpus and consists of stereo recordings with the Sennheisermicrophone and the Audio-Technica microphone or a tele-phone handset over external telephone lines.
Adaptationdata was supplied separately consisting of a total of 800stereo recorded utterances from 10 speakers; 400 sentencesrecorded simultaneously with the Sennheiser and the Audio-Technica and 400 sentences recorded with the Sennheiserand the telephone handset.We evaluated the TMN algorithm for each of the two newmicrophones and we present he resuRs on the developmentand the 1993 ARPA WSJ official evaluation test sets.3.1.
Audio-Technica (AT) MicrophoneWe applied the TMN algorithm, as described in Section 2, onthe 400 adaptation sentences simultaneously recorded withthe Sennheiser and the Audio-Technica (AT) microphones tocompute the codebook transformation for the alternate mi-crophone.
For the evaluation of the system, the comparativeexperiments include:3.
DESCRIPT ION OF  EXPERIMENTSIn this section we describe the results we obtained applyingthe TMN algorithm for the Spoke 6 of the Wall Street Jour-nal (WSJ) speech corpus.
This is the known alternate mi-crophone 5000-word closed recognition vocabulary, speakerindependent speech recognition task.
It addresses two differ-ent alternate microphones, the Audio-Technica 853a, a highquality directional, stand-mount microphone, and a standardtelephone handset ( the AT&T 720 speaker phone).
Theadaptation and test database includes simultaneous record-ings of high quality speech using the primary microphone(Sennheiser HMD-414 head-mounted microphone with noisecanceling element) and speech recorded with each of the twoalternate microphones.Recognition on the Sennheiser recorded portion of thetest data to access the lower bound on the error rate, thatthe baseline system can achieve with matched trainingand testing microphone.Recognition on the Audio-Technica recorded po~onof the test data to access the degradation i the perfor-mance of the baseline system for the mismatch condi-tion when no adaptation is used, other than the standardcepstram ean subtraction.Recognition on the Audio-Technica recorded portion ofthe test data, using the proposed adaptation scheme todetermine the improvement on the system performancedue to the adaptation algorithm.All of the experiments hat will be described were performedusing the BBN BYBLOS speech recognition system \[3\].
Thefront end of the system computes teady-state, first- andsecond-order derivative Mel-frequency cepstral coefficients(MFCC) and energy features over an analysis range of 80 to6000 Hz.
Cepstrum mean subtraction is a standard featureof the system used to compensate for the unknown channeltransfer function.
In cepstmm ean subtraction we computethe sample mean of the cepstrum vector over the utterance,and then subtract this mean from the cepstrum vector at eachframe.
No distinction is made between speech and non-speech frames.
The acoustic models are trained on 62 hoursof speech (37000 sentences) from the WSJ0 and WSJ1 cor-pora, collected from 37 speakers, with the Sennheiser highquality close-talking microphone.
The recognition is doneusing trigrarn language models.
The test data comes fromIn Table 1, we list the word error rates for these experi-ments.
The mismatch between the Audio-Technica nd theSystem ConfigurationSennheiserAT with no adaptationAT with TMN adaptationDev.
Test I Eval.
Test8.3% 7.9%10.5% 10.6%9.0% 9.6%Table 1: Comparison of word error rate (%) for microphoneadaptation using the Sennheiser or the Audio-Technica mi-crophoneSennheiser microphone does not cause a serious degrada-tion, even when no adaptation is used to account for the327channel mismatch.
The TMN adaptation reduces the addi-tional degradation due to the channel mismatch by about afactor of 2 in both test sets.3.2.
Te lephone SpeechThe telephone handset (TH) differs radically from the othertwo microphones, having the main characteristic of allowinga much narrower band of frequencies than the others.
There-fore, prior to applying any adaptation scheme, we chose tobandlimit the Sennheiser t aining data between 300-3300 Hz,to create new bandlimited phonetic word models.
This wasaccomplished by retaining the DFT coefficients of the featureanalysis in the range 300-3300 Hz to compute the MFCCcoefficients.
We bandlimited the stereo adaptation and testdata in the same way.
We applied the TMN algorithm onthe bandlimited adaptation data to compute the codebooktransformation for the telephone speech.
During testing, thedata is bandlimited as described, and quanfized using thenormalized telephone codebook.
In evaluating the adapta-tion algorithm for the telephone speech we performed thesame series of experiments as with the Audio-Technica mi-crophone.
We consider using full bandwidth phonetic mod-els as the baseline system and the generation of bandlimitedphonetic models as part of the scheme for adaptation to thetelephone speech.
In Table 2 we list the word error rates forthese experiments.
The degradation i performance due toSystem Dev.
Eval.Configuration test testSennheiser 8.9% 8.7%TH with no adaptation - 29.5%TH with Bandlimiting and TMN 12.7% 12.8%Table 2: Comparison of word error rate (%) for microphoneadaptation using the Sennheiser or the Telephone handsetmicrophonelected with the primary microphone and comprise theWSJ0 and WSJ1 corpora with 12 and 50 hours ofrecorded speech respectively.
We trained two sets ofphonetic models using the WSJ0 corpus and the com-bined WSJ0+WSJ1 training data to determine the im-pact of additional training data collected with the pri-mary microphone.Bandlimitedphonetic models: Determine the effect ofbandlimiting separately from and in combination withthe TMN algorithm.TMN Adaptation: Determine the effect the TMN al-gorithm separately from and in combination with ofbandlimiting.The results are shown in Tables 3 and Tables 4.
We haveno clear explanation for the surprising result that additionaltraining speech recorded with a high quality microphone im-proves the performance of the system on telephone speech.However the error ate reduces by a factor of 2 for some con-ditions by adding 50 hours of training high quality recordedspeech.
Furthermore bandlimiting is essential for the goodperformance of the system for telephone speech, as in allconditions reduces the error rate by a factor of 2.
As a con-trast, we also computed the error rate of the WSJ0+WSJ1bandlimited system on the bandlimited Sennheiser recordeddata portion of the test and found that to be 11.0%.
The latterresult compared with 8.9% (Table 2) which is the error rateof the full bandwidth system on the same speech impliesthat most of the loss in performance between recognizinghigh-quality Sennlaeiser recordings and telephone speech isdue to the loss of information outside the telephone band-width.
Using the telephone bandwith, switching from thehigh-quality Sennheiser microphone to the telephone hand-set increases the error rate only by a small factor, from11.0% to 13.9%.
Finally the effect of the TMN algorithmis much more significant when telephone bandwidth is notused.the mismatch between the Sennheiser recorded speech andthe telephone speech is severe (the error rate goes from 8.9%to 29.5%).
The combined effect of bandlimiting the data andthe TMN adaptation reduces the error rate by a factor of 2.3bringing the error rate of recognition of telephone speechclose to that of high quality microphone recordings.Since the telephone speech is radically different from speechcollected with the primary microphone, we conducted somemore experiments o access the contribution of the bandlim-iting process, the adaptation algorithm and the amount oftraining separately in the performance of the system.
Specif-ically we tested the following conditions:?
Amount of training data: All training data is col-WSJ0-12 hoursNo bandlirnitingWith bandlimitingWithout TMN With TMN41.8% 36.3%26.8% 24.0%Table 3: Comparative experiments u ing 12 hours of trainingspeech recorded with the primary microphone t sted on WSJSpoke 6 development test set telephone recordings.4.
CONCLUSIONSWe have presented a supervised adaptation algorithm thatimproves the recognition accuracy of the BYBLOS speechrecognition system when there is a microphone mismatchbetween training and testing conditions.328WSJ0+WSJ1-62 hours Without TMN With TMNNo bandlimiting \] 31.8% 22.9%With bandlimiting 13.9% 12.7%Table 4: Comparative experiments u ing 62 hours of trainingspeech recorded with the primary microphone tested on WSJSpoke 6 development test set telephone recordings.Proc.
International Conference inSpoken Language Process-ing, 1992, pp.
85-88.6.
X. Huang, K. Lee H. Hon, "On Semi-Continuous HiddenMadcov Modeling", Proc.
IEEE Int.
Conf.
Acoustics, Speechand Signal Processing, April 1990, paper S13.3.7.
R. Schwartz, Anastasakos T., F. Kubala, J. Makhoul, L.Nguyen, and G. Zavaliagkos, "Comparative Experiments onLarge Vocabulary Speech Recognition", Proc.
ARPA HumanLanguage Technology Workshop, March 1993.We tested the algorithm on two different alternate micro-phones, a high-quality stand-mount microphone and a tele-phone handset.
TMN adaptation reduces the degradationdue to mismatch between the Sennheiser and the Audio-Technica microphone by a factor of 2.
The results on thetelephone handset were more dramatic as the error rate re-duced from 29.3% to 12.5% using bandlimited phoneticmodels and TMN adaptation.
We showed that bandlimitedphonetic models are essential, as most of the degradation isdue to the loss of information outside the narrow bandwidthof the telephone.
The 12.5% word error rate is close to theerror rate achieved using the primary microphone, which isconsidered the best performance the system can achieve fora microphone.
However the overall good performance of thesystem of telephone speech may also be an artifact of thedata collection procedure, as the speech was only sent overa local loop, there was no long distance calling for example,and the telephone handset did not vary, as the case wouldbe in a conventional pplication.5.
ACKNOWLEDGMENTThis work was supported by the Defense Advanced Re-search Projects Agency and monitored by the Office ofNaval Research under Contract Nos.
N00014-91-C-0115,and N00014-92-C-0035.References1.
A. Acero, and R.M.
Stem, "Environmental Robustness inAu-tomatic Speech Recognition", Proc.
IEEE Int.
Conf.
Acous-tics, Speech and Signal Processing, April 1987, pp.
849-852.2.
J. Bellegard, D. Nahamoo, '"I~ed Mixture Continuous Param-eter Modeling for Speech Recognition", IEEE Transactionson Acoustics, Speech and Signal Processing, Dec. 1990, vol.38, No.
12.3.
Y.L.
Chow, M.O.
Dunham, O.A.
Kimball, M.A.
Krasner,G.F.
Kubala, L Makhoul, P. J.
Price, S. Roucos, and R. M.Schwartz, "BYBLOS: The BBN Continuous Speech Recog-nition System", Proc.
IEEE Int.
Conf.
Acoustics, Speech andSignal Processing, April 1987, pp.
89-93.4.
S, Furui, "Unsupervised Speaker Adaptation Method Basedon Hierarchical Spectral Clustering", Proc.
IEEE Int.
Conf.Acoustics, Speech and Signal Processing, May 1989, pp.
286-289.5.
H. Hermansky, and N. Morgan, "Towards Handling theAcoustic Environment in Spoken Language Processing",329
