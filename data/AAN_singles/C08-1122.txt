Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 969?976Manchester, August 2008CollabRank: Towards a Collaborative Approach to Single-DocumentKeyphrase ExtractionXiaojun Wan and Jianguo XiaoInstitute of Computer Science and TechnologyPeking University, Beijing 100871, China{wanxiaojun,xiaojianguo}@icst.pku.edu.cnAbstractPrevious methods usually conduct thekeyphrase extraction task for single docu-ments separately without interactions foreach document, under the assumptionthat the documents are considered inde-pendent of each other.
This paper pro-poses a novel approach named Col-labRank to collaborative single-documentkeyphrase extraction by making use ofmutual influences of multiple documentswithin a cluster context.
CollabRank isimplemented by first employing the clus-tering algorithm to obtain appropriatedocument clusters, and then using thegraph-based ranking algorithm for col-laborative single-document keyphrase ex-traction within each cluster.
Experimentalresults demonstrate the encouraging per-formance of the proposed approach.
Dif-ferent clustering algorithms have beeninvestigated and we find that the systemperformance relies positively on the qual-ity of document clusters.1 IntroductionA keyphrase is defined as a meaningful and sig-nificant expression consisting of one or morewords in a document.
Appropriate keyphrasescan be considered as a highly condensed sum-mary for a document, and they can be used as alabel for the document to supplement or replacethe title or summary, thus facilitating users?
fastbrowsing and reading.
Moreover, document key-phrases have been successfully used in the fol-lowing IR and NLP tasks: document indexing(Gutwin et al, 1999), document classification(Krulwich and Burkey, 1996), document cluster-?
2008.
Licensed under the Creative Commons Attri-bution-Noncommercial-Share Alike 3.0 Unportedlicense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.ing (Zhang et al, 2004; Hammouda et al, 2005)and document summarization (Berger and Mittal,2000; Buyukkokten et al, 2001).Keyphrases are usually manually assigned byauthors, especially for journal or conference arti-cles.
However, the vast majority of documents(e.g.
news articles, magazine articles) do nothave keyphrases, therefore it is beneficial toautomatically extract a few keyphrases from agiven document to deliver the main content ofthe document.
Here, keyphrases are selectedfrom within the body of the input document,without a predefined list (i.e.
controlled vocabu-lary).
Most previous work focuses on keyphraseextraction for journal or conference articles,while this paper focus on keyphrase extractionfor news articles because news article is one ofthe most popular document genres on the weband most news articles have no author-assignedkeyphrases.Very often, keyphrases of all single documentsin a document set are required to be extracted.However, all previous methods extract key-phrases for a specified document based only onthe information contained in that document, suchas the phrase?s TFIDF, position and other syntac-tic information in the document.
One commonassumption of existing methods is that the docu-ments are independent of each other.
Hence thekeyphrase extraction task is conducted separatelywithout interactions for each document.
However,the multiple documents within an appropriatecluster context usually have mutual influencesand contain useful clues which can help to ex-tract keyphrases from each other.
For example,two documents about the same topic ?earth-quake?
would share a few common phrases, e.g.
?earthquake?, ?victim?, and they can provideadditional knowledge for each other to betterevaluate and extract salient keyphrases from eachother.
The idea is borrowed from human?s per-ception that a user would better understand atopic expressed in a document if the user readsmore documents about the same topic.969Based on the above assumption, we propose anovel framework for collaborative single-document keyphrase extraction by making use ofthe additional information from multiple docu-ments within an appropriate cluster context.
Thecollaborative framework for keyphrase extractionconsists of the step of obtaining the cluster con-text and the step of collaborative keyphrase ex-traction in each cluster.
In this study, the clustercontext is obtained by applying the clusteringalgorithm on the document set, and we have in-vestigated how the cluster context influences thekeyphrase extraction performance by employingdifferent clustering algorithms.
The graph-basedranking algorithm is employed for collaborativekeyphrase extraction for each document in aspecified cluster.
Instead of making only use ofthe word relationships in a single document, thealgorithm can incorporate the ?voting?
or ?rec-ommendations?
between words in all the docu-ments of the cluster, thus making use of theglobal information existing in the cluster context.The above implementation of the collaborativeframework is denoted as CollabRank in this pa-per.Experiments have been performed on a datasetconsisting of 308 news articles with human-annotated keyphrases, and the results demon-strate the good effectiveness of the CollabRankapproach.
We also find that the extraction per-formance is positively correlated with the qualityof cluster context, and existing clustering algo-rithms can yield appropriate cluster context forcollaborative keyphrase extraction.The rest of this paper is organized as follows:Section 2 introduces the related work.
The pro-posed CollabRank is described in detail in Sec-tion 3.
Empirical evaluation is demonstrated inSection 4 and lastly we conclude this paper inSection 5.2 Related WorkThe methods for keyphrase (or keyword) extrac-tion can be roughly categorized into either unsu-pervised or supervised.Unsupervised methods usually involve assign-ing a saliency score to each candidate phrases byconsidering various features.
Krulwich and Bur-key (1996) use heuristics based on syntacticclues to extract keyphrases from a document.Barker and Cornacchia (2000) propose a simplesystem for choosing noun phrases from a docu-ment as keyphrases.
Mu?oz (1996) uses an unsu-pervised learning algorithm to discover two-wordkeyphrases.
The algorithm is based on AdaptiveResonance Theory (ART) neural networks.Steier and Belew (1993) use the mutual informa-tion statistics to discover two-word keyphrases.Tomokiyo and Hurst (2003) use pointwise KL-divergence between multiple language modelsfor scoring both phraseness and informativenessof phrases.
More recently, Mihalcea and Tarau(2004) propose the TextRank model to rank key-words based on the co-occurrence links betweenwords.
Such algorithms make use of ?voting?
or?recommendations?
between words to extractkeyphrases.Supervised machine learning algorithms havebeen proposed to classify a candidate phrase intoeither keyphrase or not.
GenEx (Turney, 2000)and Kea (Frank et al, 1999; Witten et al, 1999)are two typical systems, and the most importantfeatures for classifying a candidate phrase are thefrequency and location of the phrase in thedocument.
More linguistic knowledge has beenexplored by Hulth (2003).
Statistical associationsbetween keyphrases have been used to enhancethe coherence of the extracted keyphrases (Tur-ney, 2003).
Song et al (2003) present an infor-mation gain-based keyphrase extraction systemcalled KPSpotter.
Medelyan and Witten (2006)propose KEA++ that enhances automatic key-phrase extraction by using semantic informationon terms and phrases gleaned from a domain-specific thesaurus.
Nguyen and Kan (2007) focuson keyphrase extraction in scientific publicationsby using new features that capture salient mor-phological phenomena found in scientific key-phrases.The tasks of keyphrase extraction and docu-ment summarization are similar and thus theyhave been conducted in a uniform framework.Zha (2002) proposes a method for simultaneouskeyphrase extraction and text summarization byusing the heterogeneous sentence-to-word rela-tionships.
Wan et al (2007a) propose an iterativereinforcement approach to simultaneous key-phrase extraction and text summarization.
Otherrelated works include web page keyword extrac-tion (Kelleher and Luz, 2005; Zhang et al, 2005;Chen et al, 2005), advertising keywords finding(Yih et al, 2006).To the best of our knowledge, all previouswork conducts the task of keyphrase extractionfor each single document independently, withoutmaking use of the collaborative knowledge inmultiple documents.
We focus on unsupervisedmethods in this study.9703 The Proposed CollabRank Approach3.1 Framework DescriptionGiven a document set for keyphrase extraction ofeach single document, CollabRank first employsthe clustering algorithm to group the documentsinto a few clusters.
The documents within eachcluster are expected to be topic-related and eachcluster can be considered as a context for anydocument in the cluster.
Given a document clus-ter, CollabRank makes use of the global wordrelationships in the cluster to evaluate and rankcandidate phrases for each single document inthe cluster based on the graph-based ranking al-gorithm.
Figure 1 gives the framework of theproposed approach.1.
Document Clustering: Group the documents in thedocument set D into a few clusters using the cluster-ing algorithm;2.
Collaborative Keyphrase Extraction: For eachcluster C, perform the following steps respectivelyto extract keyphrases for single documents in thecluster in a batch mode:1) Cluster-level Word Evaluation: Build aglobal affinity graph G based on all candidatewords restricted by syntactic filters in the documentsof the given cluster C, and employ the graph-rankingbased algorithm to compute the cluster-level sali-ency score for each word.2) Document-level Keyphase Extraction: Forany single document d in the cluster, evaluate thecandidate phrases in the document based on thescores of the words contained in the phrases, and fi-nally choose a few phrases with highest scores asthe keyphrases of the document.Figure 1.
The Framework of CollabRankIn the first step of the above framework, dif-ferent clustering algorithms will yield differentclusters.
The documents in a high-quality clusterare usually deemed to be highly topic-related (i.e.appropriate cluster context), while the documentsin a low-quality cluster are usually not topic-related (i.e.
inappropriate cluster context).
Thequality of a cluster will influence the reliabilityof the contextual information for evaluating thewords in the cluster.
A number of clustering al-gorithms will be investigated in the experiments,including the agglomerative algorithm (both av-erage-link and complete-link), the divisive algo-rithm, and the kmeans algorithm (Jain et al,1999), whose details will be described in theevalution section.In the second step of the above framework,substep 1) aims to evaluate all candidate wordsin the cluster based on the graph-based rankingalgorithm.
The global affinity graph aims to re-flect the cluster-level co-occurrence relationshipsbetween all candidate words in the documents ofthe given cluster.
The saliency scores of thewords are computed based on the global affinitygraph to indicate how much information aboutthe main topic the words reflect.
Substep 2) aimsto evaluate candidate phrases of each singledocument based on the cluster-level word scores,and then choose a few salient phrases as key-phrases of the document.
Substep 1) is performedon all documents in the cluster in order to evalu-ate the words from a global perspective, whilesubstep 2) is performed on each single documentin order to extract keyphrases from a local per-spective.
A keyphrase of a document is expectedto include highly salient words.
We can see thatthe keyphrase extraction tasks are conducted in abatch mode for each cluster.
The substeps of 1)and 2) will be described in next sections respec-tively.
If substep 1) is performed on each singledocument without considering the cluster context,the approach is degenerated into the simple Tex-tRank model (Mihalcea and Tarau, 2004), whichis denoted as SingleRank in this paper.It is noteworthy that in addition to the graph-based ranking algorithm, other keyphrase extrac-tion methods can also be integrated in the pro-posed collaborative framework to exploit the col-laborative knowledge in the cluster context.3.2 Cluster-Level Word EvaluationLike the PageRank algorithm (Page et al, 1998),the graph-based ranking algorithm employed inthis study is essentially a way of deciding theimportance of a vertex within a graph based onglobal information recursively drawn from theentire graph.
The basic idea is that of ?voting?
or?recommendation?
between the vertices.
A linkbetween two vertices is considered as a vote castfrom one vertex to the other vertex.
The scoreassociated with a vertex is determined by thevotes that are cast for it, and the score of the ver-tices casting these votes.Formally, given a specified cluster C, let G=(V,E) be an undirected graph to reflect the relation-ships between words in the cluster.
V is the set ofvertices and each vertex is a candidate word2 inthe cluster.
Because not all words in the docu-ments are good indicators of keyphrases, thewords added to the graph are restricted with syn-tactic filters, i.e., only the words with a certainpart of speech are added.
As in Mihalcea andTarau (2004), the documents are tagged by a2 The original words are used without stemming.971POS tagger, and only the nouns and adjectivesare added into the vertex set3.
E is the set ofedges, which is a subset of V?V.
Each edge eij inE is associated with an affinity weight aff(vi,vj)between words vi and vj.
The weight is computedbased on the co-occurrence relation between thetwo words, controlled by the distance betweenword occurrences.
The co-occurrence relationcan express cohesion relationships betweenwords.
Two vertices are connected if the corre-sponding words co-occur at least once within awindow of maximum k words, where k can be setanywhere from 2 to 20 words.
The affinityweight aff(vi,vj) is simply set to be the count ofthe controlled co-occurrences between the wordsvi and vj in the whole cluster as follows:)()( jiCddji ,vvcount,vvaff ?
?=  (1)where countd(vi,vj) is the count of the controlledco-occurrences between words vi and vj  in docu-ment d.The graph is built based on the whole clusterand it is called Global Affinity Graph.
The big-gest difference between CollabRank andSingleRank is that SingleRank builds a localgraph based on each single document.We use an affinity matrix M to describe Gwith each entry corresponding to the weight ofan edge in the graph.
M = (Mi,j)|V|?|V| is defined asfollows:otherwise0;  and   with  links if)(???
?=,jiv v,   ,vvaffM jijii,j(2)Then M is normalized to M~ as follows to makethe sum of each row equal to 1:??????=?
?==otherwise00if~|V|1|V|1,M ,   MMM ji,jji,ji,ji,j(3)Based on the global affinity graph G, the clus-ter-level saliency score WordScoreclus(vi) forword vi can be deduced from those of all otherwords linked with it and it can be formulated in arecursive form as in the PageRank algorithm:???+?
?=iall jj,ijclusiclus VMvWordScorevWordScore||)1(~)()( ??
(4)And the matrix form is:eV?M?
T rrr||)1(~ ??
?+=   (5)3 The corresponding POS tags of the candidate wordsinclude ?JJ?, ?NN?, ?NNS?, ?NNP?, ?NNPS?.
Weused the Stanford log-linear POS tagger (Toutanovaand Manning, 2000) in this study.where 1||)]([ ?= Viclus vWordScore?ris the vector ofword saliency scores.
er  is a vector with all ele-ments equaling to 1. ?
is the damping factor usu-ally set to 0.85, as in the PageRank algorithm.The above process can be considered as aMarkov chain by taking the words as the statesand the corresponding transition matrix is givenby TT ee|V|M rr)1(~ ??
?+ .
The stationary probabil-ity distribution of each state is obtained by theprincipal eigenvector of the transition matrix.For implementation, the initial scores of thewords are set to 1 and the iteration algorithm inEquation (4) is adopted to compute the newscores of the words.
Usually the convergence ofthe iteration algorithm is achieved when the dif-ference between the scores computed at two suc-cessive iterations for any words falls below agiven threshold (0.0001 in this study).For SingleRank, the saliency score Word-Scoredoc(vi) for word vi is computed in the sameiterative way based on the local graph for thesingle document.3.3 Document-Level Keyphrase ExtractionAfter the scores of all candidate words in thecluster have been computed, candidate phrasesare selected and evaluated for each single docu-ment in the cluster.
The candidate words (i.e.nouns and adjectives) of a specified document din the cluster, which is a subset of V, are markedin the document text, and sequences of adjacentcandidate words are collapsed into a multi-wordphrase.
The phrases ending with an adjective arenot allowed, and only the phrases ending with anoun are collected as the candidate phrases forthe document.
For instance, in the following sen-tence: ?Mad/JJ cow/NN disease/NN has/VBZkilled/VBN 10,000/CD cattle/NNS?, the candi-date phrases are ?Mad cow disease?
and ?cattle?.The score of a candidate phrase pi is computedby summing the cluster-level saliency scores ofthe words contained in the phrase.?
?=ij pvjclusi vWordScorepePhraseScor )()(  (6)All the candidate phrases in the document areranked in decreasing order of the phrase scoresand the top n phrases are selected as the key-phrases of the document.
n ranges from 1 to 20 inthis study.
Similarly for SingleRank, the phrasescore is computed based on the document-levelsaliency scores of the words.9724 Empirical Evaluation4.1 Data SetTo our knowledge, there is no gold standardnews dataset with assigned keyphrases forevaluation.
So we manually annotated theDUC2001 dataset   (Over, 2001) and used theannotated dataset for evaluation in this study.The dataset was originally used for documentsummarization.
It consisted of 309 news articlescollected from TREC-9, in which two articleswere duplicate (i.e.
d05a\FBIS-41815 andd05a\FBIS-41815~).
The average length of thedocuments was 740 words.
Two graduate stu-dents were employed to manually label the key-phrases for each document.
At most 10 key-phrases could be assigned to each document.
Theannotation process lasted two weeks.
The Kappastatistic for measuring inter-agreement amongannotators was 0.70.
And the annotation conflictsbetween the two subjects were solved by discus-sion.
Finally, 2488 keyphrases were labeled forthe dataset.
The average keyphrase number perdocument was 8.08 and the average word num-ber per keyphrase was 2.09.The articles have been grouped into 30 clustersmanually by NIST annotators for multi-document summarization, and the documentswithin each cluster were topic-related or relevant.The manually labeled clusters were considered asthe ground truth clusters or gold clusters.
In orderto investigate existing clustering algorithms, thedocuments in the clusters were mixed together toform the whole document set for automatic clus-tering.4.2 Document Clustering AlgorithmIn the experiments, several popular clusteringalgorithms and random clustering algorithms areexplored to produce cluster contexts.
Note thatwe have already known the number (i.e.
30) ofthe clusters for the dataset beforehand and thuswe simply use it as input for the following clus-tering algorithms4.Gold Standard Clustering: It is a pseudoclustering algorithm by manually grouping thedocuments.
We use the ground truth clusters asthe upperbound of the following automatic clus-tering algorithms.Kmeans Clustering: It is a partition basedclustering algorithm.
The algorithm randomly4 How to obtain the number of desired clusters is notthe focus of this study.selects 30 documents as the initial centroids ofthe 30 clusters and then iteratively assigns alldocuments to the closest cluster, and recomputesthe centroid of each cluster, until the centroids donot change.
The similarity between a documentand a cluster centroid is computed using thestandard Cosine measure.Agglomerative (AverageLink) Clustering: Itis a bottom-up hierarchical clustering algorithmand starts with the points as individual clustersand, at each step, merges the most similar orclosest pair of clusters, until the number of theclusters reduces to the desired number 30.
Thesimilarity between two clusters is computed us-ing the AverageLink method, which computesthe average of the Cosine similarity values be-tween any pair of documents belonging to thetwo clusters respectively as follows:211 121)()(cc,ddsim,ccsimminjji?=?
?= =(7)where di, dj are two documents in cluster c1 andcluster c2 respectively, and |c1| and |c2| are respec-tively the numbers of documents in clusters c1and c2.Agglomerative (CompleteLink) Clustering:It differs from the above agglomerative (Aver-ageLink) clustering algorithm only in that thesimilarity between two clusters is computed us-ing the CompleteLink method, which computesthe minimum of the Cosine similarity values be-tween any pair of documents belonging to thetwo clusters respectively as follows:)}({min)(2121 jic,dcd,ddsim,ccsimji ?
?=  (8)Divisive Clustering: It is a top-down hierar-chical clustering algorithm and starts with one,all-inclusive cluster and, at each step, splits thelargest cluster (i.e.
the cluster with most docu-ments) into two small clusters using the Kmeansalgorithm until the number of clusters increasesto the desired number 30.Random Clustering: It produces 30 clustersby randomly assigning each document into oneof the k clusters.
Three different randomizationprocesses are performed and we denote them asRandom1, Random2 and Random3, respectively.CollabRank relies on the clustering algorithmfor document clustering, and the combination ofCollabRank and any clustering algorithm will beinvestigated.4.3 Evaluation MetricFor evaluation of document clustering results, weadopt the widely used F-Measure to measure the973performance of the clustering algorithm (i.e.
thequality of the clusters) by comparing the pro-duced clusters with the gold clusters (classes)(Jain et al, 1999).For evaluation of keyphrase extraction results,the automatic extracted keyphrases are comparedwith the manually labeled keyphrases.
The wordsare converted to their corresponding basic formsusing word stemming before comparison.
Theprecision p=countcorrect/countsystem, recallr=countcorrect/counthuman, F-measure (F=2pr/(p+r))are used as evaluation metrics, where countcorrectis the total number of correct keyphrases ex-tracted by the system, and countsystem is the totalnumber of automatic extracted keyphrases, andcounthuman is the total number of human-labeledkeyphrases.4.4 Evaluation ResultsFirst of all, we show the document clusteringresults in Table 1.
The gold standard clusteringresult is the upperbound of all automatic cluster-ing results.
Seen from the table, all the fourpopular clustering algorithms (i.e.
CompleteLink,AverageLink, KMeans and Divisive) performmuch better than the three random clustering al-gorithms (i.e.
Random1, Random2 and Ran-dom3).
Different clustering results lead to differ-ent document relationships and a high-qualitycluster produced by popular algorithms isdeemed to build an appropriate cluster contextfor collaborative keyphrase extraction.Clustering Algorithm F-MeasureGold 1.000CompleteLink 0.907AverageLink 0.877Divisive 0.924Kmeans 0.866Random1 0.187Random2 0.189Random3 0.183Table 1.
Clustering ResultsNow we show the results for keyphrase extrac-tion.
In the experiments, the keyphrase number istypically set to 10 and the co-occurrence windowsize is also simply set to 10.
Table 2 gives thecomparison results of baseline methods and theproposed CollabRank methods with differentclustering algorithms.
The TFIDF baseline com-putes the word scores for each single documentbased on the word?s TFIDF value.
The SingleR-ank baseline computes the word scores for eachsingle document based on the graph-based rank-ing algorithm.
The two baselines do not makeuse of the cluster context.Seen from Table 2, the CollabRank methodswith the gold standard clustering algorithm orpopular clustering algorithms (i.e.
Kmeans,CompleteLink, AverageLink and Divisive) per-form much better than the baseline methods overall three metrics.
The results demonstrate thegood effectiveness of the proposed collaborativeframework.
We can also see that the performanceis positively correlated with the clustering results.The CollabRank method with the best perform-ing gold standard clustering results achieves thebest performance.
While the methods with low-quality clustering results (i.e.
the three randomclustering results) do not perform well, evenmuch worse than the baseline SingleRankmethod.
This is because that the documents in alow-quality cluster are not truly topic-related,and the mutual influences between the docu-ments are not reliable for evaluating words froma global perspective.System Precision Recall F-measureTFIDF 0.232 0.281 0.254SingleRank 0.247 0.303 0.272CollabRank(Gold) 0.283 0.348 0.312CollabRank(Kmeans) 0.276 0.339 0.304CollabRank(CompleteLink) 0.281 0.345 0.310CollabRank(AverageLink) 0.277 0.340 0.306CollabRank(Divisive) 0.274 0.337 0.302CollabRank(Random1) 0.210 0.258 0.232CollabRank(Random2) 0.216 0.265 0.238CollabRank(Random3) 0.209 0.257 0.231Table 2.
Keyphrase Extraction ResultsIn order to investigate how the co-occurrencewindow size k and the keyphrase number n influ-ence the performance, we first vary k from 2 to20 when n is fixed as 10 and the results areshown in Figures 2-4 over three metrics respec-tively.
The results demonstrate that all the meth-ods are not significantly affected by the windowsize.
We then vary n from 1 to 20 when k is fixedas 10 and the results are shown in Figures 5-7.The results demonstrate that the precision valuesdecrease with the increase of n, and the recallvalues increases with the increase of n, while theF-measure values first increase and then tend todecrease with the increase of n.We can also see from Figures 2-7 that the Col-labRank methods with high-quality clusteringresults always perform better than the baseline974SingleRank method under different window sizesand different keyphrase numbers, and they al-ways  lead to poor performance with low-qualityclustering results.
This further proves that an ap-propriate cluster context is very important for theCollabRank method.
Fortunately, existing clus-tering algorithms can obtain the desired clustercontext.0 .
1 71 8 1 6K e y p h r a s e  n u m b e r  nPrecisionSingleRank CollabRank(Gold) CollabRank(Kmeans)CollabRank(CompleteLink) CollabRank(AverageLink) CollabRank(Divisive)CollabRank(Random1) CollabRank(Random2) CollabRank(Random3)0.190.210.230.250.270.292 4 6 8 10 12 14 16 18 20Window size kPrecisionFigure 2.
Precision vs.
Window Size k0.230.250.270.290.310.330.352 4 6 8 10 12 14 16 18 20Window size kRecallFigure 3.
Recall vs.
Window Size k0.20.220.240.260.280.30.322 4 6 8 10 12 14 16 18 20Window size kF-measureFigure 4.
F-measure vs.
Window Size k0.170.220.270.320.370.420.471 2 4 6 8 10 12 14 16 18 20Keyphrase number nPrecisionFigure 5.
Precision vs. Keyphrase Numbern0.020.070.120.170.220.270.320.370.420.471 2 4 6 8 10 12 14 16 18 20Keyphrase number nRecallFigure 6.
Recall vs. Keyphrase Number n0.050.10.150.20.250.31 2 4 6 8 10 12 14 16 18 20Keyphrase number nF-measureFigure 7.
F-measure vs. Keyphrase Num-ber nThe proposed CollabRank method makes onlyuse of the global information based on the globalgraph for the cluster.
In order to investigate therelative contributions from the whole cluster andthe single document to the final performance, weexperiment with the method named RankFusionwhich makes both of the cluster-level global in-formation and the document-level local informa-tion.
The overall word score WordScorefusion(vi)for word vi in a document in RankFusion is a lin-ear combination of the global word score and thelocal word score as follows:where ??
[0,1] is the fusion weight.
Then thephrase score is computed based on the fusionscores of the words.
The RankFusion method isthe same with CollabRank if ?=1 and it is thesame with SingleRank if ?=0.Figure 8 shows the F-measure curves for theRankFusion methods with different high-qualityclustering algorithms under different fusionweights.
We can see that when ??
(0.5,1), theRankFusion methods with high-quality clusterscan outperform both the corresponding SingleR-ank and the corresponding CollabRank.
However,the performance improvements of RankFusionover CollabRank are not significant.
We canconclude that the cluster-level global informationplays the key role for evaluating the true saliencyof the words.0.270.280.290.30.310.320 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Fusion weight ?F-measureGold Kmeans CompleteLinkAverageLink DivisiveFigure 8.
RankFusion Results (F-measure) vs. FusionWeight ?5 Conclusion and Future WorkIn this paper, we propose a novel approachnamed CollabRank for collaborative single-document keyphrase extraction, which makes useof the mutual influences between documents inappropriate cluster context to better evaluate thesaliency of words and phrases.
Experimental re-)()1()()( idociclusifusion vWordScorevWordScorevWordScore ?
?+?= ??
(9)975sults demonstrate the good effectiveness of Col-labRank.
We also find that the clustering algo-rithm is important for obtaining the appropriatecluster context and the low-quality clusteringresults will deteriorate the extraction perform-ance.
It is encouraging that most existing popularclustering algorithms can meet the demands ofthe proposed approach.The proposed collaborative framework hasmore implementations than the implementationbased on the graph-based ranking algorithm inthis study.
In future work, we will explore otherkeyphrase extraction methods in the proposedcollaborative framework to validate the robust-ness of the framework.AcknowledgementsThis work was supported by the National ScienceFoundation of China (No.60703064), the Re-search Fund for the Doctoral Program of HigherEducation of China (No.20070001059) and theNational High Technology Research and Devel-opment Program of China (No.2008AA01Z421).ReferencesA.
Berger and V. Mittal.
2000.
OCELOT: A system forsummarizing Web Pages.
In Proceedings of SIGIR2000.K.
Barker and N. Cornacchia.
2000.
Using nounphraseheads to extract document keyphrases.
In Canadian Confer-ence on AI.O.
Buyukkokten, H. Garcia-Molina, and A. Paepcke.
2001.Seeing the whole in parts: text summarization for webbrowsing on handheld devices.
In Proceedings ofWWW2001.M.
Chen, J.-T. Sun, H.-J.
Zeng and K.-Y.
Lam.
2005.
Apractical system for keyphrase extraction for web pages.
InProceedings of CIKM2005.E.
Frank, G. W. Paynter, I. H. Witten, C. Gutwin, and C. G.Nevill-Manning.
1999.
Domain-specific keyphrase extrac-tion.
Proceedings of IJCAI-99, pp.
668-673.C.
Gutwin, G. W. Paynter, I. H. Witten, C. G. Nevill-Manning and E. Frank.
1999.
Improving browsing in digitallibraries with keyphrase indexes.
Journal of Decision Sup-port Systems, 27, 81-104.K.
M. Hammouda, D. N. Matute and M. S. Kamel.
2005.CorePhrase: keyphrase extraction for document clustering.In Proceedings of MLDM2005.A.
Hulth.
2003.
Improved automatic keyword extractiongiven more linguistic knowledge.
In Proceedings ofEMNLP2003, Japan, August.A.
K. Jain, M. N. Murty and P. J. Flynn.
1999.
Data cluster-ing: a review.
ACM Computing Surveys, 31(3):264-323.D.
Kelleher and S. Luz.
2005.
Automatic hypertext key-phrase detection.
In Proceedings of IJCAI2005.B.
Krulwich and C. Burkey.
1996.
Learning user informa-tion interests through the extraction of semantically signifi-cant phrases.
In AAAI 1996 Spring Symposium on MachineLearning in Information Access.O.
Medelyan and I. H. Witten.
2006.
Thesaurus based auto-matic keyphrase indexing.
In Proceedings of JCDL2006.R.
Mihalcea and P. Tarau.
2004.
TextRank: Bringing orderinto texts.
In Proceedings of EMNLP2004.A.
Mu?oz.
1996.
Compound key word generation fromdocument databases using a hierarchical clustering ARTmodel.
Intelligent Data Analysis, 1(1).T.
D. Nguyen and M.-Y.
Kan. 2007.
Keyphrase extractionin scientific publications.
In Proceedings of ICADL2007.P.
Over.
2001.
Introduction to DUC-2001: an intrinsicevaluation of generic news text summarization systems.
InProceedings of DUC2001.L.
Page, S. Brin, R. Motwani, and T. Winograd.
1998.
Thepagerank citation ranking: Bringing order to the web.
Tech-nical report, Stanford Digital Libraries.M.
Song, I.-Y.
Song and X. Hu.
2003.
KPSpotter: a flexibleinformation gain-based keyphrase extraction system.
InProceedings of WIDM2003.A.
M. Steier and R. K. Belew.
1993.
Exportingphrases: A statistical analysis of topical language.
InProceedings of Second Symposium on Document Analysisand Information Retrieval, pp.
179-190.T.
Tomokiyo and M. Hurst.
2003.
A language model ap-proach to keyphrase extraction.
In: Proceedings of ACLWorkshop on Multiword Expressions.K.
Toutanova and C. D. Manning.
2000.
Enriching theknowledge sources used in a maximum entropy Part-of-Speech tagger.
In Proceedings of EMNLP/VLC-2000.P.
D. Turney.
2000.
Learning algorithms for keyphrase ex-traction.
Information Retrieval, 2:303-336.P.
D. Turney.
2003.
Coherent keyphrase extraction via webmining.
In Proc.
of IJCAI-03, pages 434?439.X.
Wan, J. Yang and J. Xiao.
2007a.
Towards an iterativereinforcement approach for simultaneous document summa-rization and keyword extraction.
In Proceedings ofACL2007.I.
H. Witten, G. W. Paynter, E. Frank, C. Gutwin, and C. G.Nevill-Manning.
1999.
KEA: Practical automatic keyphraseextraction.
Proceedings of Digital Libraries 99 (DL'99), pp.254-256.W.-T. Yih, J. Goodman and V. R. Carvalho.
2006.
Findingadvertising keywords on web pages.
In Proceedings ofWWW2006.H.
Y. Zha.
2002.
Generic summarization and keyphraseextraction using mutual reinforcement principle and sen-tence clustering.
In Proceedings of SIGIR2002, pp.
113-120.Y.
Zhang, N. Zincir-Heywood, and E. Milios.
2004.
Term-Based Clustering and Summarization of Web Page Collec-tions.
In Proceedings of the Seventeenth Conference of theCanadian Society for Computational Studies of Intelligence.Y.
Zhang, N. Zincir-Heywood and E. Milios.
2005.
Narra-tive text classification for automatic key phrase extraction inweb document corpora.
In Proceedings of WIDM2005.976
