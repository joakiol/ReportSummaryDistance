Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 832?840,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsA Multi-Domain Translation Model Frameworkfor Statistical Machine TranslationRico SennrichInstitute of Computational LinguisticsUniversity of ZurichBinzmu?hlestr.
14CH-8050 Zu?richsennrich@cl.uzh.chHolger Schwenk and Walid AransaLIUM, University of Le Mans72085 Le Mans cedex 9, Francelastname@lium.univ-lemans.frAbstractWhile domain adaptation techniques forSMT have proven to be effective at im-proving translation quality, their practical-ity for a multi-domain environment is of-ten limited because of the computationaland human costs of developing and main-taining multiple systems adapted to differ-ent domains.
We present an architecturethat delays the computation of translationmodel features until decoding, allowingfor the application of mixture-modelingtechniques at decoding time.
We also de-scribe a method for unsupervised adapta-tion with development and test data frommultiple domains.
Experimental results ontwo language pairs demonstrate the effec-tiveness of both our translation model ar-chitecture and automatic clustering, withgains of up to 1 BLEU over unadapted sys-tems and single-domain adaptation.1 IntroductionThe effectiveness of domain adaptation ap-proaches such as mixture-modeling (Foster andKuhn, 2007) has been established, and has led toresearch on a wide array of adaptation techniquesin SMT, for instance (Matsoukas et al, 2009; Shahet al, 2012).
In all these approaches, adaptation isperformed during model training, with respect to arepresentative development corpus, and the mod-els are kept unchanged when then system is de-ployed.
Therefore, when working with multipleand/or unlabelled domains, domain adaptation isoften impractical for a number of reasons.
Firstly,maintaining multiple systems for each languagepair, each adapted to a different domain, is costlyin terms of computational and human resources:the full system development pipeline needs to beperformed for all identified domains, all the mod-els are separately stored and need to be switched atruntime.
This is impractical in many real applica-tions, in particular a web translation service whichis faced with texts coming from many different do-mains.
Secondly, domain adaptation bears a riskof performance loss.
If there is a mismatch be-tween the domain of the development set and thetest set, domain adaptation can potentially harmperformance compared to an unadapted baseline.We introduce a translation model architecturethat delays the computation of features to the de-coding phase.
The calculation is based on a vec-tor of component models, with each componentproviding the sufficient statistics necessary for thecomputation of the features.
With this framework,adaptation to a new domain simply consists of up-dating a weight vector, and multiple domains canbe supported by the same system.We also present a clustering approach for un-supervised adaptation in a multi-domain environ-ment.
In the development phase, a set of develop-ment data is clustered, and the models are adaptedto each cluster.
For each sentence that is beingdecoded, we choose the weight vector that is op-timized on the closest cluster, allowing for adap-tation even with unlabelled and heterogeneous testdata.2 Related Work(Ortiz-Mart?
?nez et al, 2010) delay the compu-tation of translation model features for the pur-pose of interactive machine translation with onlinetraining.
The main difference to our approach isthat we store sufficient statistics not for a singlemodel, but a vector of models, which allows us to832weight the contribution of each component modelto the feature calculation.
The similarity suggeststhat our framework could also be used for inter-active learning, with the ability to learn a modelincrementally from user feedback, and weight itdifferently than the static models, opening new re-search opportunities.
(Sennrich, 2012b) perform instance weightingof translation models, based on the sufficientstatistics.
Our framework implements this idea,with the main difference that the actual combina-tion is delayed until decoding, to support adapta-tion to multiple domains in a single system.
(Razmara et al, 2012) describe an ensemble de-coding framework which combines several trans-lation models in the decoding step.
Our work issimilar to theirs in that the combination is doneat runtime, but we also delay the computation oftranslation model probabilities, and thus have ac-cess to richer sufficient statistics.
In principle,our architecture can support all mixture operationsthat (Razmara et al, 2012) describe, plus addi-tional ones such as forms of instance weighting,which are not possible after the translation proba-bilities have been computed.
(Banerjee et al, 2010) focus on the problem ofdomain identification in a multi-domain setting.They use separate translation systems for each do-main, and a supervised setting, whereas we aimfor a system that integrates support for multipledomains, with or without supervision.
(Yamamoto and Sumita, 2007) propose unsu-pervised clustering at both training and decodingtime.
The training text is divided into a numberof clusters, a model is trained on each, and duringdecoding, each sentence is assigned to the clos-est cluster-specific model.
Our approach bears re-semblance to this clustering, but is different in thatYamamoto and Sumita assign each sentence to theclosest model, and use this model for decoding,whereas in our approach, each cluster is associ-ated with a mixture of models that is optimized tothe cluster, and the number of clusters need not beequal to the number of component models.3 Translation Model ArchitectureThis section covers the architecture of the multi-domain translation model framework.
Our transla-tion model is embedded in a log-linear model as iscommon for SMT, and treated as a single transla-tion model in this log-linear combination.
We im-plemented this architecture for phrase-based mod-els, and will use this terminology to describe it,but in principle, it can be extended to hierarchicalor syntactic models.The architecture has two goals: move the calcu-lation of translation model features to the decodingphase, and allow for multiple knowledge sources(e.g.
bitexts or user-provided data) to contribute totheir calculation.
Our immediate purpose for thispaper is domain adaptation in a multi-domain en-vironment, but the delay of the feature computa-tion has other potential applications, e.g.
in inter-active MT.We are concerned with calculating four featuresduring decoding, henceforth just referred to as thetranslation model features: p(s|t), lex(s|t), p(t|s)and lex(t|s).
s and t denote the source and targetphrase.
We follow the definitions in (Koehn et al,2003).Traditionally, the phrase translation probabili-ties p(s|t) and p(t|s) are estimated through un-smoothed maximum likelihood estimation (MLE).p(x|y) = c(x, y)c(y) =c(x, y)?x?
c(x?, y)(1)where c denotes the count of an observation, andp the model probability.The lexical weights lex(s|t) and lex(t|s) arecalculated as follows, using a set of word align-ments a between s and t:1lex(s|t, a) =n?i=11|{j|(i, j) ?
a}|??
(i,j)?aw(si|tj)(2)A special NULL token is added to t and aligned toeach unaligned word in s. w(si|tj) is calculatedthrough MLE, as in equation 1, but based on theword (pair) frequencies.To combine statistics from a vector of n com-ponent corpora, we can use a weighted version ofequation 1, which adds a weight vector ?
of lengthn (Sennrich, 2012b):p(x|y;?)
=?ni=1 ?ici(x, y)?ni=1?x?
?ici(x?, y)(3)The word translation probabilities w(ti|sj) are de-fined analogously, and used in equation 2 for aweighted version.1The equation shows lex(s|t); lex(t|s) is computed anal-ogously.833In order to compute the translation model fea-tures online, a number of sufficient statistics needto be accessible at decoding time.
For p(s|t)and p(t|s), we require the statistics c(s), c(t) andc(s, t).
For accessing them during decoding, wesimply store them in the decoder?s data struc-ture, rather than storing pre-computed translationmodel features.
This means that we can use exist-ing, compact data formats for storing and access-ing them.2The statistics are accessed when the decodercollects all translation options for a phrase s in thesource sentence.
We then access all translation op-tions for each component table, obtaining a vectorof statistics c(s) for the source phrase, and c(t) andc(s, t) for each potential target phrase.
For phrasepairs which are not found, c(s, t) and c(t) are ini-tially set to 0.Note that c(t) is potentially incorrect at thispoint, since a phrase pair not being found doesnot entail that c(t) is 0.
After all tables have beenaccessed, and we thus know the full set of possi-ble translation options (s, t), we perform a secondround of lookups for all c(t) in the vector whichare still set to 0.
We introduce a second table foraccessing c(t) efficiently, again storing it in the de-coder?s data structure.
We can easily create such atable by inverting the source and target phrases,deduplicating it for compactness (we only needone entry per target phrase), and storing c(t) asonly feature.For lex(s|t), we require an alignment a, plusc(tj) and c(si, tj) for all pairs (i, j) in a. lex(t|s)can be based on the same alignment a (with the ex-ception of NULL alignments, which can be addedonline), but uses statistics c(sj) and c(ti, sj).
Forestimating the lexical probabilities, we load thefrequencies into a vector of four hash tables.3Both space and time complexity of the lookupis linear to the number of component tables.
Wedeem it is still practical because the collection oftranslation options is typically only a small frac-tion of total decoding time, with search makingup the largest part.
For storing and accessing thesufficient statistics (except for the word (pair) fre-quencies), we use an on-disk data structure pro-2We have released an implementation of the architectureas part of the Moses decoder.3c(s, t) and c(t, s) are not identical since the lexicalprobabilities are based on the unsymmetrized word align-ment frequencies (in the Moses implementation which we re-implement).phrase (pair) c1(x) c2(x)row 300 80(row, Zeile) 240 20(row, Reihe) 60 60?
p(Zeile|row) p(Reihe|row)(1, 1) 0.68 0.32(1, 10) 0.40 0.60(10, 1) 0.79 0.21Table 1: Illustration of instance weighting withweight vectors for two corpora.vided by Moses, which reduces the memory re-quirements.
Still, the number of components mayneed to be reduced, for instance through clusteringof training data (Sennrich, 2012a).With a small modification, our framework couldbe changed to use a single table that stores a vec-tor of n statistics instead of a vector of n tables.While this would be more compact in terms ofmemory, and keep the number of table lookups in-dependent of the number of components, we chosea vector of n tables for its flexibility.
With a vec-tor of tables, tables can be quickly added to or re-moved from the system (conceivable even at run-time), and can be polymorph.
One applicationswhere this could be desirable is interactive ma-chine translation, where one could work with amix of compact, static tables, and tables designedto be incrementally trainable.In the unweighted variant, the resulting fea-tures are equivalent to training on the concatena-tion of all training data, excepting differences inword alignment, pruning4 and rounding.
The ar-chitecture can thus be used as a drop-in replace-ment for a baseline system that is trained on con-catenated training data, with non-uniform weightsonly being used for texts for which better weightshave been established.
This can be done either us-ing domain labels or unsupervised methods as de-scribed in the next section.As a weighted combination method, we imple-mented instance weighting as described in equa-tion 3.
Table 1 shows the effect of weighting twocorpora on the probability estimates for the trans-lation of row.
German Zeile (row in a table) is pre-dominant in a bitext from the domain IT, whereas4We prune the tables to the most frequent 50 phrase pairsper source phrase before combining them, since calculat-ing the features for all phrase pairs of very common sourcephrases causes a significant slow-down.
We found that thishad no significant effects on BLEU.8340 1 2 3 4 5 60123456entropy with KDE LM (IT)entropywithAcquisLM(LEGAL)gold clusters0 1 2 3 4 5 60123456entropy with KDE LM (IT)entropywithAcquisLM(LEGAL)clustering with Euclidean distance0 1 2 3 4 5 60123456entropy with KDE LM (IT)entropywithAcquisLM(LEGAL)clustering with cosine similarityFigure 1: Clustering of data set which contains sentences from two domains: LEGAL and IT.
Compari-son between gold segmentation, and clustering with two alternative distance/similarity measures.
Black:IT; grey: LEGAL.Reihe (line of objects) occurs more often in a legalcorpus.
Note that the larger corpus (or more pre-cisely, the one in which row occurs more often)has a stronger impact on the probability distribu-tion with uniform weights (or in a concatenation ofdata sets).
Instance weighting allows us to modifythe contribution of each corpus.
In our implemen-tation, the weight vector is set globally, but can beoverridden on a per-sentence basis.
In principle,using different weight vectors for different phrasepairs in a sentence is conceivable.
The frameworkcan also be extended to support other combinationmethods, such as a linear interpolation of models.4 Unsupervised Clustering for OnlineTranslation Model AdaptationThe framework supports decoding each sentencewith a separate weight vector of size 4n, 4 beingthe number of translation model features whosecomputation can be weighted, and n the numberof model components.
We now address the ques-tion of how to automatically select good weights ina multi-domain task.
As a way of optimizing in-stance weights, (Sennrich, 2012b) minimize trans-lation model perplexity on a set of phrase pairs,automatically extracted from a parallel develop-ment set.
We follow this technique, but want tohave multiple weight vectors, adapted to differenttexts, between which the system switches at de-coding time.
The goal is to perform domain adap-tation without requiring domain labels or user in-put, neither for development nor decoding.The basic idea consists of three steps:1.
Cluster a development set into k clusters.2.
Optimize translation model weights for eachcluster.3.
For each sentence in the test set, assign itto the nearest cluster and use the translationmodel weights associated with the cluster.For step 2, we use the algorithm by (Sennrich,2012b), implemented in the decoder to allow for aquick optimization of a running system.
We willhere discuss steps 1 and 3 in more detail.4.1 Clustering the Development SetWe use k-means clustering to cluster the sentencesof the development set.
We train a language modelon the source language side of each of the ncomponent bitexts, and compute an n-dimensionalvector for each sentence by computing its entropywith each language model.
Our aim is not to dis-criminate between sentences that are more likelyand unlikely in general, but to cluster on the ba-sis of relative differences between the languagemodel entropies.
For this purpose, we choosethe cosine as our similarity measure.
Figure 1illustrates clustering in a two-dimensional vectorspace, and demonstrates that Euclidean distance isunsuitable because it may perform a clustering thatis irrelevant to our purposes.As a result of development set clustering, weobtain a bitext for each cluster, which we use tooptimize the model weights, and a centroid percluster.
At decoding time, we need only performan assignment step.
Each test set sentence is as-signed to the centroid that is closest to it in thevector space.4.2 Scalability ConsiderationsOur theoretical expectation is that domain adapta-tion will fail to perform well if the test data is from835a different domain than the development data, orif the development data is a heterogeneous mixof domains.
A multi-domain setup can mitigatethis risk, but only if the relevant domain is repre-sented in the development data, and if the devel-opment data is adequately segmented for the op-timization.
We thus suggest that the developmentdata should contain enough data from all domainsthat one wants to adapt to, and a high number ofclusters.While the resource requirements increase withthe number of component models, increasing thenumber of clusters is computationally cheap atruntime.
Only the clustering of the develop-ment set and optimization of the translation modelweights for each clusters is affected by k. Thismeans that the approach can in principle be scaledto a high number of clusters, and support a highnumber of domains.5The biggest risk of increasing the number ofclusters is that if the clusters become too small,perplexity minimization may overfit these smallclusters.
We will experiment with different num-bers of clusters, but since we expect the optimalnumber of clusters to depend on the amount ofdevelopment data, and the number of domains,we cannot make generalized statements about theideal number of k.While it is not the focus of this paper, we alsoevaluate language model adaptation.
We performa linear interpolation of models for each clus-ter, with interpolation coefficients optimized us-ing perplexity minimization on the developmentset.
The cost of moving language model interpo-lation into the decoding phase is far greater thanfor translation models, since the number of hy-potheses that need to be evaluated by the languagemodel is several orders of magnitudes higher thanthe number of phrase pairs used during the trans-lation.
For the experiments with language modeladaptation, we have chosen to perform linear in-terpolation offline, and perform language modelswitching during decoding.
While model switch-ing is a fast operation, it also makes the space com-plexity of storing the language models linear to thenumber of clusters.
For scaling the approach to ahigh number of clusters, we envision that multi-5If the development set is labelled, one can also use a goldsegmentation of development sets instead of k-means cluster-ing.
At decoding time, cluster assignment can be performedby automatically assigning each sentence to the closest cen-troid, or again through gold labels, if available.data set sentences words (de)kde 216 000 1 990 000kdedoc 2880 41 000kdegb 51 300 450 000oo 41 000 434 000oo3 56 800 432 000php 38 500 301 000tm 146 000 2 740 000acquis 2 660 000 58 900 000dgt 372 000 8 770 000ecb 110 000 2 850 000ep7 1 920 000 50 500 000nc7 159 000 3 950 000total (train) 5 780 000 131 000 000dev (IT) 3500 47 000dev (LEGAL) 2000 46 800test (IT) 5520 51 800test (LEGAL) 9780 250 000Table 2: Parallel data sets English?German.data set sentences words (en)eu 1 270 000 25 600 000fiction 830 000 13 700 000navajo 30 000 490 000news 110 000 2 550 000paraweb 370 000 3 930 000subtitles 2 840 000 21 200 000techdoc 970 000 7 270 000total (train) 6 420 000 74 700 000dev 3500 50 700test 3500 49 600Table 3: Parallel data sets Czech?English.pass decoding, with an unadapted language modelin the first phase, and rescoring with a languagemodel adapted online, could perform adequately,and keep the complexity independent of the num-ber of clusters.5 Evaluation5.1 Data and MethodsWe conduct all experiments with Moses (Koehn etal., 2007), SRILM (Stolcke, 2002), and GIZA++(Och and Ney, 2003).
Log-linear weights are op-timized using MERT (Och and Ney, 2003).
Wekeep the word alignment and lexical reorderingmodels constant through the experiments to min-imize the number of confounding factors.
We re-port translation quality using BLEU (Papineni et836system TM adaptation LM adaptation TM+LM adaptationIT LEGAL IT LEGAL IT LEGALbaseline 21.1 49.9 21.1 49.9 21.1 49.91 cluster (no split) 21.3* 49.9 21.8* 49.7 21.8* 49.82 clusters 21.6* 49.9 22.2* 50.4* 22.8* 50.2*4 clusters 21.7* 49.9 23.1* 50.2* 22.6* 50.2*8 clusters 22.1* 49.9 23.1* 50.1* 22.7* 50.3*16 clusters 21.1 49.9 22.6* 50.3* 21.9* 50.1*gold clusters 21.8* 50.1* 22.4* 50.1* 23.2* 49.9Table 4: Translation experiments EN?DE.
BLEU scores reported.al., 2002).
We account for optimizer instabilityby running 3 independent MERT runs per system,and performing significance testing with MultEval(Clark et al, 2011).
Systems significantly betterthan the baseline with p < 0.01 are marked with(*).We conduct experiments on two data sets.
Thefirst is an English?German translation task withtwo domains, texts related to information technol-ogy (IT) and legal documents (LEGAL).
We usedata sets from both domains, plus out-of-domaincorpora, as shown in table 2.
7 data sets come fromthe domain IT: 6 from OPUS (Tiedemann, 2009)and a translation memory (tm) provided by our in-dustry partner.
3 data sets are from the legal do-main: the ECB corpus from OPUS, plus the JRC-Acquis (Steinberger et al, 2006) and DGT-TM(Steinberger et al, 2012).
2 data sets are out-of-domain, made available by the 2012 Workshop onStatistical Machine Translation (Callison-Burch etal., 2012).
The development sets are random sam-ples from the respective in-domain bitexts (held-out from training).
The test sets have been pro-vided by Translated, our industry partner in theMATECAT project.Our second data set is CzEng 0.9, a Czech?English parallel corpus (Bojar and Zabokrtsky?,2009).
It contains text from 7 different sources, onwhich we train separate component models.
Thesize of the corpora is shown in table 3.
As de-velopment and test sets, we use 500 sentences ofheld-out data per source.For both data sets, language models are trainedon the target side of the bitexts.
In all experiments,we keep the number of component models con-stant: 12 for EN?DE, 7 for CZ?EN.
We vary thenumber of clusters k from 1, which corresponds toadapting the models to the full development set, to16.
The baseline is the concatenation of all train-Data set ?IT ?LEGAL ?cluster 1 ?cluster 2kde 1.0 1.0 1.0 1.0kdedoc 0.64 12.0 86.0 6.4kdegb 1.6 2.3 1.7 2.7oo 0.76 1.6 0.73 1.7oo3 1.8 4.7 2.4 2.7php 0.79 6.3 0.69 3.5tm 1.3 1.3 1.5 1.1acquis 0.024 3.5 0.018 1.9dgt 0.053 4.5 0.033 2.4ecb 0.071 2.3 0.039 1.2ep7 0.037 0.53 0.024 0.29nc7 0.1 1.1 0.063 0.62Table 5: Weight vectors for feature p(t|s) opti-mized on four development sets (from gold splitand clustering with k = 2).ing data, with no adaptation performed.
We alsoevaluate the labelled setting, where instead of un-supervised clustering, we use gold labels to splitthe development and test sets, and adapt the mod-els to each labelled domain.5.2 ResultsTable 4 shows results for the EN?DE data set.
Forour clustering experiments, the development set isthe concatenation of the LEGAL and IT develop-ment sets.
However, we always use the gold seg-mentation between LEGAL and IT for MERT andtesting.
This allows for a detailed analysis of theeffect of development data clustering for the pur-pose of model adaptation.
In an unlabelled setting,one would have to run MERT either on the full de-velopment set (as we will do for the CZ?EN task)or separately on each cluster, or use an alternativeapproach to optimize log-linear weights in a multi-domain setting, such as feature augmentation asdescribed by (Clark et al, 2012).837system TM adaptation LM adaptation TM+LM adaptationbaseline 34.4 34.4 34.41 cluster (no split) 34.5 33.7 34.12 clusters 34.6 34.0 34.44 clusters 34.7* 34.3 34.68 clusters 34.7* 34.5 34.9*16 clusters 34.7* 34.7* 35.0*gold clusters 35.0* 35.0* 35.4*Table 6: Translation experiments CZ?EN.
BLEU scores reported.We find that an adaptation of the TM and LMto the full development set (system ?1 cluster?
)yields the smallest improvements over the un-adapted baseline.
The reason for this is that themixed-domain development set is not representa-tive for the respective test sets.
Using multipleadapted systems yields better performance.
Forthe IT test set, the system with gold labels and TMadaptation yields an improvement of 0.7 BLEU(21.1 ?
21.8), LM adaptation yields 1.3 BLEU(21.1 ?
22.4), and adapting both models outper-forms the baseline by 2.1 BLEU (21.1 ?
23.2).The systems that use unsupervised clusters reacha similar level of performance than those withgold clusters, with best results being achievedby the systems with 2?8 clusters.
Some sys-tems outperform both the baseline and the goldclusters, e.g.
TM adaptation with 8 clusters(21.1 ?
21.8 ?
22.1), or LM adaptation with 4or 8 clusters (21.1 ?
22.4 ?
23.1).Results with 16 clusters are slightly worse thanthose with 2?8 clusters due to two effects.
Firstly,for the system with adapted TM, one of the threeMERT runs is an outlier, and the reported BLEUscore of 21.1 is averaged from the three MERTruns achieving 22.1, 21.6, and 19.6 BLEU, respec-tively.
Secondly, about one third of the IT testset is assigned to a cluster that is not IT-specific,which weakens the effect of domain adaptation forthe systems with 16 clusters.For the LEGAL subset, gains are smaller.
Thiscan be explained by the fact that the majority oftraining data is already from the legal domain,which makes it unnecessary to boost its impact onthe probability distribution even further.Table 5 shows the automatically obtained trans-lation model weight vectors for two systems,?gold clusters?
and ?2 clusters?, for the featurep(t|s).
It illustrates that all the corpora that weconsider out-of-domain for IT are penalized bya factor of 10?50 (relative to the in-domain kdecorpus) for the computation of this feature.
Forthe LEGAL domain, the weights are more uni-form, which is congruent with our observation thatBLEU changes little.Table 6 shows results for the CZ?EN data set.For each system, MERT is performed on the fulldevelopment set.
As in the first task, adaptation tothe full development set is least effective.
The sys-tems with unsupervised clusters significantly out-perform the baseline.
For the system with 16 clus-ters, we observe an improvement of 0.3 BLEU forTM adaptation, and 0.6 BLEU for adapting bothmodels (34.4 ?
34.7 ?
35.0).
The labelled sys-tem, i.e.
the system with 7 clusters correspondingto the 7 data sources, both for the development andtest set, performs best.
We observe gains of 0.6BLEU (34.4 ?
35.0) for TM or LM adaptation,and 1 BLEU (34.4 ?
35.4) when both models areadapted.We conclude that the translation model archi-tecture is effective in a multi-domain setting, bothwith unsupervised clusters and labelled domains.The fact that language model adaptation yields anadditional improvement in our experiments sug-gests that it it would be worthwhile to also inves-tigate a language model data structure that effi-ciently supports multiple domains.6 ConclusionWe have presented a novel translation model ar-chitecture that delays the computation of trans-lation model features to the decoding phase, anduses a vector of component models for this com-putation.
We have also described a usage scenariofor this architecture, namely its ability to quicklyswitch between weight vectors in order to serve asan adapted model for multiple domains.
A sim-ple, unsupervised clustering of development datais sufficient to make use of this ability and imple-838ment a multi-domain translation system.
If avail-able, one can also use the architecture in a labelledsetting.Future work could involve merging our trans-lation model framework with the online adapta-tion of other models, or the log-linear weights.Our approach is orthogonal to that of (Clark etal., 2012), who perform feature augmentation toobtain multiple sets of adapted log-linear weights.While (Clark et al, 2012) use labelled data, theirapproach could in principle also be applied afterunsupervised clustering.The translation model framework could alsoserve as the basis of real-time adaptation of trans-lation systems, e.g.
by using incremental means toupdate the weight vector, or having an incremen-tally trainable component model that learns fromthe post-edits by the user, and is assigned a suit-able weight.AcknowledgmentsThis research was partially funded by theSwiss National Science Foundation under grant105215 126999, the European Commission(MATECAT, ICT-2011.4.2 287688) and theDARPA BOLT project.ReferencesPratyush Banerjee, Jinhua Du, Baoli Li, Sudip KumarNaskar, Andy Way, and Josef Van Genabith.
2010.Combining multi-domain statistical machine trans-lation models using automatic classifiers.
In 9thConference of the Association for Machine Trans-lation in the Americas (AMTA 2010), Denver, Col-orado, USA.Ondrej Bojar and Zdenek Zabokrtsky?.
2009.
Czeng0.9: Large parallel treebank with rich annotation.Prague Bull.
Math.
Linguistics, 92:63?84.Chris Callison-Burch, Philipp Koehn, Christof Monz,Matt Post, Radu Soricut, and Lucia Specia.
2012.Findings of the 2012 workshop on statistical ma-chine translation.
In Proceedings of the SeventhWorkshop on Statistical Machine Translation, pages10?51, Montre?al, Canada, June.
Association forComputational Linguistics.Jonathan H. Clark, Chris Dyer, Alon Lavie, andNoah A. Smith.
2011.
Better hypothesis testing forstatistical machine translation: Controlling for op-timizer instability.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies, pages176?181, Portland, Oregon, USA, June.
Associationfor Computational Linguistics.Jonathan H. Clark, Alon Lavie, and Chris Dyer.
2012.One system, many domains: Open-domain statisti-cal machine translation via feature augmentation.
InConference of the Association for Machine Transla-tion in the Americas 2012 (AMTA 2012), San Diego,California, USA.George Foster and Roland Kuhn.
2007.
Mixture-model adaptation for SMT.
In Proceedings of theSecond Workshop on Statistical Machine Transla-tion, StatMT ?07, pages 128?135, Prague, CzechRepublic.
Association for Computational Linguis-tics.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
InNAACL ?03: Proceedings of the 2003 Conferenceof the North American Chapter of the Associationfor Computational Linguistics on Human LanguageTechnology, pages 48?54, Edmonton, Canada.
As-sociation for Computational Linguistics.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondr?ej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: OpenSource Toolkit for Statistical Machine Translation.In ACL 2007, Proceedings of the 45th Annual Meet-ing of the Association for Computational Linguis-tics Companion Volume Proceedings of the Demoand Poster Sessions, pages 177?180, Prague, CzechRepublic, June.
Association for Computational Lin-guistics.Spyros Matsoukas, Antti-Veikko I. Rosti, and BingZhang.
2009.
Discriminative corpus weight estima-tion for machine translation.
In Proceedings of the2009 Conference on Empirical Methods in NaturalLanguage Processing: Volume 2 - Volume 2, pages708?717, Singapore.
Association for ComputationalLinguistics.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.Daniel Ortiz-Mart?
?nez, Ismael Garc?
?a-Varea, and Fran-cisco Casacuberta.
2010.
Online learning for in-teractive statistical machine translation.
In HLT-NAACL, pages 546?554.
The Association for Com-putational Linguistics.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: A method for automaticevaluation of machine translation.
In ACL ?02: Pro-ceedings of the 40th Annual Meeting on Associa-tion for Computational Linguistics, pages 311?318,Philadelphia, Pennsylvania, USA.
Association forComputational Linguistics.Majid Razmara, George Foster, Baskaran Sankaran,and Anoop Sarkar.
2012.
Mixing multiple trans-lation models in statistical machine translation.
In839Proceedings of the 50th Annual Meeting of the As-sociation for Computational Linguistics, Jeju, Re-public of Korea.
Association for Computational Lin-guistics.Rico Sennrich.
2012a.
Mixture-modeling with unsu-pervised clusters for domain adaptation in statisticalmachine translation.
In 16th Annual Conference ofthe European Association for Machine Translation(EAMT 2012), pages 185?192, Trento, Italy.Rico Sennrich.
2012b.
Perplexity minimization fortranslation model domain adaptation in statisticalmachine translation.
In Proceedings of the 13thConference of the European Chapter of the Asso-ciation for Computational Linguistics, pages 539?549, Avignon, France.
Association for Computa-tional Linguistics.Kashif Shah, Loc Barrault, and Holger Schwenk.2012.
A general framework to weight heteroge-neous parallel data for model adaptation in statisticalmachine translation.
In Conference of the Associa-tion for Machine Translation in the Americas 2012(AMTA 2012), San Diego, California, USA.Ralf Steinberger, Bruno Pouliquen, Anna Widiger,Camelia Ignat, Tomaz Erjavec, Dan Tufis, andDaniel Varga.
2006.
The JRC-Acquis: A multilin-gual aligned parallel corpus with 20+ languages.
InProceedings of the 5th International Conference onLanguage Resources and Evaluation (LREC?2006),Genoa, Italy.Ralf Steinberger, Andreas Eisele, Szymon Klocek,Spyridon Pilos, and Patrick Schlu?ter.
2012.
DGT-TM: A freely available translation memory in 22 lan-guages.
In Proceedings of the Eight InternationalConference on Language Resources and Evaluation(LREC?12), Istanbul, Turkey.
European LanguageResources Association (ELRA).Andreas Stolcke.
2002.
SRILM ?
An Extensible Lan-guage Modeling Toolkit.
In Seventh InternationalConference on Spoken Language Processing, pages901?904, Denver, CO, USA.Jo?rg Tiedemann.
2009.
News from OPUS - a col-lection of multilingual parallel corpora with toolsand interfaces.
In N. Nicolov, K. Bontcheva,G.
Angelova, and R. Mitkov, editors, RecentAdvances in Natural Language Processing, vol-ume V, pages 237?248.
John Benjamins, Amster-dam/Philadelphia, Borovets, Bulgaria.Hirofumi Yamamoto and Eiichiro Sumita.
2007.
Bilin-gual cluster based models for statistical machinetranslation.
In Proceedings of the 2007 Joint Con-ference on Empirical Methods in Natural LanguageProcessing and Computational Natural LanguageLearning, pages 514?523, Prague, Czech Republic.840
