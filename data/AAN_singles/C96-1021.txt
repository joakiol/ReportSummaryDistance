Anaphora for Everyone:Pronominal Anaphora Resolution without a ParserChristopher KennedyBoard of Studies in LinguisticsUniversity of CaliforniaSanta Cruz, CA 95064kennedy~ 11ing.
ucsc.
eduBranimir BoguraevAdvanced Technologies GroupApple Computer, Inc.Cupertino, CA 95014bkb(4 app  i e. comAbstractWe present an algorithm for anaphora res-olutkm which is a modified and extendedversion of that developed by (Lappin andLeass,/994).
In contrast to that work, our al-gorithm does not require in-depth, full, syn..tactic parsing of text.
Instead, with minimalcompromise in output quality, the modifica-tions enable the resolution process to workfrom tile output of a part of speech tag-ge~; enriched only with annotations of gram-matica\] functkm of lexical items in the in-put text stream.
Evaluation of the resultsof our in-tplementation demonstrates that ac-curate anaphora resolution can be realizedwithin natural anguage processing fl'ame-works which do not--~,)r cannot- employ ro-bust and rcqiable parsing components.1 Overview(l,appin and Leass, 1994) describe an algorithm forpronominal anaphora resolution with high rate of cor-rect analyses.
While one of the strong points of thisalgorithm is that it operates primarily on syntactic in-formation ahme, this also turns out to be a limitingfactor for its wide use: current state-of-the-art of prac-tically applicable parsing technology still falls short ofrobust and reliable delivery of syntactic analysis of realtexts to the level of detail and precision that the filtersa nd constraints described by I ,appin and l ,eass assume.We are particularly interested in a class of text pro-cessing applications, capable of delivery of contentanalysis to a depth inw~lving non-trivial amount ofdiscourse processing, including anaphora resolution.The operational context prohibits us from making anyassumptions concerning domain, style, and genre ofinput; as a result, we have developed a text processingframework which builds its capabilities entirely on thebasis of a considerably shallower linguistic analysis ofthe input stream, thus trading off depth of base levelanalysis for breadth of cown:age.In this paper, we present work on modifying the lmp-pin/Leass algorithm in a way which enables it to workoff a flat morpho-syntactic analysis of the sentences ofa text, while retaining a degree of quality and accuracyin pronorainal anaphora resolution comparable to thatreported in (Lappin and l,eass, 1994).
The modifica-tions discussed below make the algorithm available toa wide range of text processing frameworks, which,due to the lack of full syntactic parsing capability, nor-really would have been unable to use this high preci-sion anap hora resolution tool.
The work is additionallyimportant, we feel, as it shows that informatkm aboutthe content and logical structure of a text, in princi-.pie a core requirement for higher level semantic anddiscourse processes, can be effectively approximatedby the right mix of constituent analysis and inferencesabout functional relations.2 General outline of the algorithmThe base level linguistic analysis for actaphora resolu-tion is the output of a part of speech tagger, augmentedwith syntactic function annotatkms for each input to.ken; this kind of analysis is generated by the mor-pbosyntactic tagging system described in (Voutilainenet al, 1992), (Karlsson et al, 1995) (hencehvth 1,1NC:-~;olq').
In addition to extremely high levels of accuracyin recall and precision of tag assignment ((VoutiJainenet al, 1992) report 99.77?/,, overall recall and 95.54%overall preciskm, over a variety of text genres, andin comparison with other state-of-the-art tagging sys-tems), the primary motivation for adopting this systemis the requirement todevelop a robust ext processor-with anaphora resolution being just one of its discourseanalysis functkms capable of reliably handling arbi-trary kinds of input.The tagger provides a very simple analysis of thestructure of the text: for each lexical item in each sen-tence, it provides a set of values which indicate themorphological, lexical, grammatical nd syntactic fea-tures of the item in tile context in which it appears.
Inaddition, the modified algorithm we present requh:esannota tion of the input text stream by a simple position--identification function which associates an integer witheach token in a text sequentially (we will refer to a to-ken's integer value as its oJ~et).As an example, given the text"For 1995 the company set up its headquar-ters in Hall \] l, the newest and most presti-.gious of CeBIT's 23 hal Is.
"tile anaphora resolutkm algorithm would be presentedwith the h}llowing analysis tream.
Note, in particu-.lar, the grammatical function information (e.g., @SUl~J,O)q.FMAINV) and the integer values (e.g., "offt 39") asso-cia ted with each token.
"For /o f f139"  "for" PREP @ADVL"1995/o f f140 .... 1995" NUM CARD @<P" the/o f f l41"  "the" DET CENTRAL ART SG/PL @DN>"company/o f f142"  "company" N NOM SG/PL @SUBJ"set/off143" "set" V PAST VF IN  @+FMAINV"up/of f144" "up" ADV ADVL @ADVL" i t s /o f f145 .... it" PRON GEN SG3 @GN>"headquar ters /o f f146  .... headquar ters"  N NOM SG/PL @OBJ" in /o f f147 .... in" PREP @<NOM @ADVL"Ha l l /o f f148 .... hal l"  N NOM SG @NN>" l l /o f f149" "Ii" NUM CARD @<P"$ , /o f f l50  .... ," PUNCT" the/o f f l51"  "the" DET CENTRAL ART SG/PL  @DN>"newest /o f f152  .... new" A SUP @PCOMPL-O"and/of f153 .... and" CC @CC"most /o f f154"  "much" ADV SUP @AD-A>"pres t ig ious /o f f155  .... p res t ig ious"  A ABS @<P"of /o f f156 .... of" PREP @<NOM-OF"CeBIT ' s /o f f157"  "cebit" N GEN SG @GN>"23/0f f158 .... 23" NUM CARD @QN>"ha l l s /o f f159  .... hal l"  N NOM PL @<P"$ .
/o f f160 ....
."
PUNCT2.1 Data collectionAlthough LINGSOFT does not provide specific infor-mation about constituent structure, partial constituen-cy-specifically, identification of sequences of tokensas phrasal units--can be inferred from the analysis byrunning the tagged text through a set of filters, whichare stated as regular expressions over metatokens suchas the ones illustrated above.For the purposes of anaphora resolution, the pri-mary data set consists of a complete listing of all nounphrases, reduced to modifier-head sequences.
Thisdata set is obtained by means of a phrasal grammarwhose patterns characterize the composition of a nounphrase (NP) in terms of possible token sequences.
Theoutput of NP identification is a set of token/featurematrix/offset sequences, where offset value is deter-mined by the offset of the first token in the sequence.The offset indicates the position of the NP in the text,and so provides crucial information about precedencerelations.A secondary data set consists of observations aboutthe syntactic ontexts in which the NPs identified bythe phrasal grammar appear.
These observations arederived using a set of patterns designed to detect nom-inal sequences in two subordinate syntactic environ-ments: containment in an adverbial adjunct and con-tainment in an NP (i.e., containment in a prepositionalor clausal complement of a noun, or containment in arelative clause).
This is accomplished by running a setof patterns which identify NPs that occur locally to ad-verbs, relative pronouns, and noun-preposition r noun-complementizer sequences over the tagged text in con-junction with the basic NP patterns described above.Because the syntactic,patterns are stated as regular ex-pressions, misanalyses are inevitable.
In practice, how-ever, the extent o which incorrect analyses of syntacticcontext affect the overall accuracy of the algorithm isnot large; we will return to a discussion of this point insection 4.A third set of patterns identifies and tags occurrencesof "expletive" it.
These patterns target occurrences ofthe pronoun it in certain contexts, e.g., as the subject ofmembers of a specific set of verbs (seem, appear, etc.
), oras the subject of adjectives with clausal complements.Once the extraction procedures are complete and theresults unified, a set of discourse referents--abstract ob-jects which represent the participants inthe discourse--is generated from the set of NP observations.
A particu-larly convenient implementation f discourse referentsis to represent them as objects in the Common LispObject System, with slots which encode the followinginformation parameters (where ADJUNCT and EMBEDindicate whether a discourse referent was observed ineither of the two syntactic ontexts discussed above):TEXT: text formTYPE: referential type (e.g., REF, PRO, RFLX)AGR: person, number, genderGFUN: grammatical functionADJUNCT: T o r  NILEMBED: T o r  NILPOS: text positionNote that each discourse referent contains informationabout itself and the context in which it appears, butthe only information about its relation to other dis-course referents is in the form of precedence r lations(as determined by text position).
The absence of explicitinformation about configurational relations marks thecrucial difference between our algorithm and the Lap-pin/Leass algorithm.
(Lappin and Leass, 1994) useconfigurational information in two ways: as a factor inthe determination of the salience of a discourse refer-ent (discussed below), and as input to a set of disjointreference filters.
Our implementation seeks to performexactly the same tasks by inferring hierarchical rela-tions from a less rich base.
The modifications andassumptions required to accomplish this goal will behighlighted in the following discussion.2.2 Anaphora resolutionOnce the representation f the text has been recast as aset of discourse referents (ordered by offset value), it issent to the anaphora resolution algorithm proper.
Thebasic logic of the algorithm parallels that of the Lap-pin/Leass algorithm.
The interpretation procedure in-volves moving through the text sentence by sentenceand interpreting the discourse referents in each sen-tence from left to right.
There are two possible in-terpretations of a discourse referent: either it is takento introduce a new participant in the discourse, or itis taken to refer to a previously interpreted iscoursereferent.
Coreference is determined by first eliminatingfrom consideration those discourse referents to whichan anaphoric expression cannot possibly refer, then se-lecting the optimal antecedent from the candidates thatremain, where optimality is determined by a saliencemeasure.In order to present the details of anaphora resolution,we define below our notions--and implementations--of coreference and salience.2.2.1 CoreferenceAs in the Lappin and Leass algorithm, the anaphor-antecedent relation is established between two dis-course referents (cf.
(Helm, 1982), (Kamp, 1981)), @hilethe more general notion of coreference is representedin terms of equivalence classes of anaphorically re-lated discourse referents, which we will refer to as"COREF classes".
Thus, the problem of interpreting ananaphoric expression boils down to the problem of es-tablishing an anaphoric link between the anaphor andsome previously interpreted iscourse referent (pos-sibly another anaphor); a consequence of establishing114this link is that the anaphor becomes a member of theCOREF class already associated with its antecedent.In our implementation, COREF classes are repre-sented as objects in the Common Lisp Object Systemwhich contain information about the COREF class asa whole, including canonical form (typically deter-mined by the discourse referent which introduces theclass), membership, and, most importantly, salience(discussed below).
1 The connection between a dis-course referent and its COREF class is mediated throughthe COREF object as follows: every discourse referentincludes an information parameter which is a pointerto a COREF object; discourse referents which have beendetermined to be coreferential share the same COREFvalue (and so literally point to the same object).
Imple-menting coreference in this way provides a means ofgetting from any discourse referent in a COREF class toinformation about the class as a whole.2.2.2 SalienceThe information parameter of a COREF object most cru-cial to anaphora resolution is its salience, which is de-termined by the status of the members of the COREFclass it re.presents with respect to 10 contextual, gram-matical, and syntactic onstraints.
Following (Lappinand Leass, 1994), we will refer to these constraints as"salience factors".
Individual salience factors are asso-ciated with numerical values; the overall salience, or"salience weight" of a COREF is the sum of the values ofthe salience factors that are satisfied by some memberof the COREF class (note that values may be satisfied atmost once by each member of the class).
The saliencefactors used by our algorithm are defined below withtheir values.
Our salience factors mirror those used by(Lappin and Leass, 1994), with the exception of Poss-s,discussed below, and CNTX-S, which is sensitive to thecontext in which a discourse referent appears, where acontext is a topically coherent segment of text, as deter-mined by a text-segmentation algorithm which follows(Hearst, 1994).SENT-S: 100 iff in the current sentenceCNTX-S: 50 iff in the current contextSUBJ-S: 80 iff GFUN = subjectEXST-S: 70 iff in an existential constructionPOSS-S: 65 iff GFUN = possessiveACC-S: 50 iff GFUN = direct objectDAT-S: 40 iff GFUN = indirect objectOBLQ-S: 30 iff the complement of a prepositionHEAD-S: 80 iff EMBED = NILARG-S: 50 iff ADJUNCT = NILNote that the values of salience factors are arbitrary;what is crucial, as pointed out by (Lappin and Leass,1994), is the relational structure imposed on the factorsby these values.
The relative ranking of the factors isjustified both linguistically, as a reflection of the roleof the functional hierarchy in determining anaphoricrelations (cf.
(Keenan and Comrie, 1977)), as well asby experimental results--both Lappin and Leass' andour own.
For all factors except CNTX-S and POSS-S, weadopt the values derived from a series of experimentsdescribed in (Lappin and Leass, 1994) which used dif-ferent settings to determine the relative importance of1The implementation of aCOREF object needs to be aware of po-tenlial circularities, thus a COREF does not actually contain its memberdiscourse r ferents, but rather alisting of their offsets,each factor as a function of the overall success of thealgorithm.
Our values for CNTX-S and POSS-S were de-termined using similar tests.An important feature of our implementation ofsalience, following that of Lappin and Leass, is that itis variable: the salience of a COREF class decreases andincreases according to the frequency of reference to theclass.
When an anaphoric link is established between apronoun and a previously introduced iscourse refer-ent, the pronoun is added to the COREF class associatedwith the discourse referent, its COREF value is set to theCOREF value of the antecedent (i.e., to the COREF ob-ject which represents he class), and the salience of theCOREF object is recalculated according to how the newmember satisfies the set of salience factors.
This finalstep raises the overall salience of the COREF, since thenew member will minimally satisfy SENT-S and CNTX-S.Salience is not stable, however: in order to realisti-cally represent the local prominence of discourse ref-erents in a text, a decay function is built into the algo-rithm, so that salience weight decreases over time.
Ifnew members are not added, the salience weight of aCOREF eventually reduces to zero.
The consequence ofthis variability in salience is that a very general heuris-tic for anaphora resolution is established: resolve apronoun to the most salient candidate antecedent.2.2.3 InterpretationAs noted above, in terms of overall strategy, the resolu-tion procedure follows that of Lappin and Leass.
Thefirst step in interpreting the discourse referents in a newsentence isto decrease the salience weights of the COREFclasses that have already been established by a factor oftwo.
Next, the algorithm locates all non-anaphoric dis-course referents in the sentence under consideration,generates a new COREF class for each one, and calcu-lates its salience weight according to how the discoursereferent satisfies the set of salience factors.The second step involves the interpretation f lexicalanaphors (reflexives and reciprocals).
A list of candi-date antecedent-anaphor pairs is generated for everylexical anaphor, based on the hypothesis that a lexicalanaphor must refer to a coargument.
In the absenceof configurational information, coarguments are iden-tified using grammatical function information (as de-termined by LINGSOFT) and precedence relations.
Areflexive can have one of three possible grammaticalfunction values: direct object, indirect object, or oblique.In the first case, the closest preceding discourse referentwith grammatical function value subject is identified asa possible antecedent.
In the latter cases, both the clos-est preceding subject and the closest preceding directobject hat is not separated from the anaphor by a sub-ject are identified as possible antecedents.
If more thanone possible antecedent is located for a lexical anaphor,the one with the highest salience weight is determinedto be the actual antecedent.
Once an antecedent hasbeen located, the anaphor is added to the COREF classassociated with the antecedent, and the salience of theCOREF class is recalculatec~ accordingly.The final step is the interpretation f pronouns.
Thebasic resolution heuristic, as noted above, is quite sim-ple: generate a set of candidate antecedents, then es-tablish coreference with the candidate which has thegreatest salience weight (in the event of a tie, the clos-est candidateis chosen).
In order to generate the candi-date set, however, those discourse referents with which115a pronoun cannot refer must be eliminated from consid-eration.
This is accomplished by running the overallcandidate pool (the set of interpreted iscourse ref-erents whose salience values exceed an arbitrarily setthreshold) through two sets of filters: a set of morpho-logical agreement filters, which eliminate from consid-eration any discourse referent which disagrees in per-son, numbeb or gender with the pronoun, and a set ofdisjoint reference filters.The determination f disjoint reference represents asignificant point of divergence between our algorithmand the Lappin/Leass algorithm, because, as is wellknown, configurational relations play a prominent rolein determining which constituents in a sentence a pro-noun may refer to.
Three conditions are of particularrelevance to the anaphora resolution algorithm:Condition \]: A pronoun cannot corefer with acoargument.Condition 2: A pronoun cannot corefer with anonpronominal constituent which it bothcommands and precedes.Condition 3: A pronoun cannot corefer with aconstituent which contains it.In the absence of configurafional information, our al-gorithm relies on inferences from grammatical func-tion and precedence todetermine disjoint reference.
Inpractice, even without accurate information about con-stituent structure, the syntactic filters described beloware extremely accurate (see the discussion of this pointin section 4).Condition i is implemented bylocating all discoursereferents with GFUN value direct object, indirect object, oroblique which follow a pronoun with GFUN value subjector direct object, as long as no subject intervenes (thehypothesis being that a subject indicates the beginningof the next clause).
Discourse referents which satisfythese conditions are identified as disjoint.Condition 2 is implemented by locating for ev-ery non-adjunct and non-embedded pronoun the setof non-pronominal discourse referents in its sentencewhich follow it, and eliminating these as potential an-tecedents.
In effect, the command relation is inferredfrom precedence and the information provided by thesyntactic patterns: an argument which is neither con-tained in an adjunct nor embedded in another nominalcommands those expressions which it precedes.Condition 3 makes use of the observation that a dis-course referent contains every object o its right with anon-nil EMBED value.
The algorithm identifies as dis-joint a discourse referent and every pronoun which fol-lows it and has a non-nil EMBED value, until a discoursereferent with EMBED value NIL is located (marking theend of the containment domain).
Condiditon 3 alsorules out coreference between a genitive pronoun andthe NP it modifies.After the morphological nd syntactic filters havebeen applied, the set of discourse referents that remainconstitute the set of candidate antecedents for the pro-noun.
The candidate set is subjected to a final evalu-ation procedure which performs two functions: it de-creases the salience of candidates which the pronounprecedes (cataphora is penalized), and it increases thesa li ence of candida tes which satisfy either a locality or aparallelism condition (described below), both of whichapply to intrasentential c ndidates.The h)cality heuristic isdesigned to negate the effectsof subordinationwhen both candidate and anaphor ap-pear in the same subordinate context, the assumptionbeing that the prominence of a candidate should be de-termined with respect o the position of the anaphor.This is a point of difference between our algorithm andthe one described in (Lappin and Leass, 1994).
Thesalience of a candidate which is determined tobe in thesame subordinate context as a pronoun (determinedas a function of precedence r lations and EMBED andADJUNCT values) is temporarily increased to the levelit would have were the candidate not in the subordi-nate context; the level is returned to normal after theanaphor is resolved.The parallelism heuristic rewards candidates whichare such that the pair consisting of the GFUN values ofcandidate and anaphor are identical to GFUN values ofa previously identified anaphor-antecedent pair.
Thisparallelism heuristic differs from a similar one usedby the Lappin/Leass algorithm, which rewards candi-dates whose grammatical function is identical to thatof an anaphor.Once the generation and evaluation of the candidateset is complete, the candidates are ranked accordingto salience weight, and the candidate with the high-est salience weight is determined tobe the antecedentof the pronoun under consideration.
In the event ofa tie, the candidate which most immediately precedesthe anaphor is selected as the antededent (where prece-dence is determined by comparing offset values).
TheCOREF value of the pronoun is set to that of the an-tecedent, adding it to the the antecedent's COREF class,and the salience of the class is recalculated accordingly.3 Example outputThe larger context from which the sample analysis inthe beginning of Section 2 was taken is as follows:"...while Apple and its PowerPC partnersclaimed some prime real estate on the showfloor, Apple's most interesting offerings de-buted behind the scenes.
Gone was the nar-row corner booth that Apple shoehorned itsproducts into last year.
For 1995 the com-pany set up its headquarters in Hall 11, thenewest and most prestigious of CeNT's 23halls.
"The anaphora resolution algorithm generates the fol-lowing analysis for the first italicized pronoun.
Foreach candidate, ~ the annotation i square brackets in-dicates its offset value, and the number to the rightindicates its salience weight at the point of interpreta-tkm of the pronoun.ANA: its \[@off/\]33\]CND: Apple \[@of 1/131\] 432Apple \[/aol f/10\] \] 352its \[@off/\].03\] 352App\]e's \[@offf/\] I 5\] 1352prilne real estat(!
\[@off/\]08\] 165show f loor  \ [ (aof f /1 \ ]2 l  \]55year \[@o~f/137 I 310/3The candidate set illustrates several important points.First, the equality in salience weights of the candi-dates at offsets 101, 103, and 115 is a consequence of2Note that our syntactic filters are quite capable of discarding anumber of configurationally inappropriate antecedents, which appearto satisfy the precedence r lation.116the fact that these discourse referents are members ofthe same COP, Et ~' class.
Their unification into a singleclass indicates both successful anaphora resolution (ofthe pronoun at offset 103), as well as the operation ofhigherqevel discourse processing designed to identifyall references to a particular COREF class, not just theanaphoric ones (cf.
(Kennedy and Boguraev, :1996)).The higher salience of the optimal candidate--whichix also a member of this COREF class--shows the effectof the locality heuristic described in section 2.2.3.
Boththe pronoun and the candidate appear in the same sub-ordinate context (within a relative clause); as a resultthe salience of the candidate (but not of the class towhich it bekmgs) is temporarily boosted to negate theeffect of subordinatkm.An abbreviated candidate set for the second itali-cized pronoun is given below:ANA: i t s  {61of f /145\ ]CND: company \[(,)ot I / 142 \] :H,0App l  e ((,!of 17/ 13 / \] 192it:~:; {(aof I / I 3 ~ \] 192This set is interesting because it illustrates the promi-nent role of SENT-S in controlling salience: company ixcorrectly identified as the antecedent of the pronotm,despite the frequency of mention of members of theCOREF class containing Apple and its, because it occursin the same sentence as the anaphor.
Of course, this ex-ample also indicates the need fl~r additional heuristicsdesigned to connect company with Apple, since thesediscourse referents clearly make reference to the sameobject.
We are currentlyworking towards this goal; see(Kennedy and Boguraev, \]996) for discussion.
'l'he following text segment illust rates the resolutionof in tersen ten tia l a napho ra.
"Sun's prototype lntemet access device usesa 1-10-Mhz MicroSPARCprocesso~; and isdiskless.
Its dimensions are 5.5 inches x 9inches x 2inches.
"ANA: \]its \[\[aol f /347\ ]CNI): IAlte~:ileL access  devic() \[(,!o~\[/33\[i\] 180M i c KOf;PARCI)rOC e!s sot \[(4oEI /34\] \] 16!i~;un 's  \[<4o1 f /3 : t3  I \ [40The first sentence in this fl'agment introduces three dis-course referents bearing different grammatical func-tions, none of which appear in subordinate contexts.Since the sentence in which the anaphor occurs doesnot contain any candidates (the discourse referent in-troduced by dimensions ix eliminated from considera-tion by both the morphok)gical nct disjoint referencefilters), only those from the previous entence are con-sidered (each is compatible with the morphologicalrequirements of the anaphor).
These are ranked ac-cording to salience weight, where the crucial factor isgrammatical function value.
The result of the rankingis that Internet access device--the candidate which satis-fies the highest-weighted salience facto1, SUBl-S--is theoptimal candidate, and so correctly identified as thean tecedent4 EvaluationQuantitative evaluation shows the anaphora resolutionalgorithm described here to run at a rate of 75'70 accu-racy.
The data set on which the evaluatkm was basedconsisted of 27 texts, taken from a random selectionof genres, including press releases, product annotmce-meats, news stories, magazine articles, and other doc-uments existing as World Wide Web pages.
Withinthese texts, we counted 3(16 third person anaphoric pro-nouns; of these, 231l were correctly resolved to the dis-course referent identified as the antecedent by the firstauthor.
3 This rate of accuracy is clearly comparableto that of the Lappin/Leass algorithm, which (Lappinand Leass, \] 994) report as 85?/,,.Several observations about he results and the com-parison with (lmppin and I,eass, 1994) are in order.First, and most obviously, some deterioratkm in qual-ity is to be expected, given the relatively impoverishedlinguistic base we start with.Second, it is important to note that this is not just amatter of simple comparison.
The results in (l.appinand Leass, 1994) describe the output of the procedttreapplied to a singh,' text genre: computer manuals.
Ar-guably, this is an example of a particularly well be-haved text; in any case, it is not clear how the figurewould be normalized over a wide range of text types,some of them not completely 'clean', as is the case withour data.Third, close analysis of the most common types oferror our algorithm currently makes reveals two spe-cific configurations in the input which confuse the pro-cedure and contribute to the error rate: gender mis-match (35% of errors) and certain long range contextttal(stylistic) phenomena, best exemplified by text contain-ing quoted passages in-line (14% of errors).Implementing a gender (dis-)agreement fil er is nottechnically complex; as noted above, the current algo-rithrn contains one.
The persistence of gender mis-matches in the output simply reflects the lack of a con-sistent gender slot in the I,\[NGSOFT tagger output.
Aug-menting the algorithm with a lexical database whichincludes more detailed gender information will resultin improved accuracy.Ensuring proper interpretatkm of anaphors bothwithin and outside of quoted text requires, in effect,a method of evaluating quoted speech separately fromits surrotmdingcnntext.
Al hough acomplex problem,we feel that this is possible, given that our input datastream embodies a richer notkm of position and con-text, as a resu\[t of an independent text segmentationprocedure adapted from (\[ learst, 1994) (and discussedabove in section 2.2.2).What is worth noting is the small number of errorswhich can be directly attributed to the absence of con-figurational inh~rmation.
Of the 75 misinterpreted pro-nouns, only 2 inw~lved a failure to establish configu-ratkmally determined disjoint reference (both of theseinw~lved Condition 3), and only an additional severalerrors could be tmambiguously traced to a failure tocorrectly identify the syntactic ontext in which a dis~course referent appeared (as determined by a misfireofthe salience factors ensitive to syntactic context, I lEAD-S and ARC:S).Overall, these considerations lead to two conchl-.sions.
First, with the incorporation of more explicitmorphological nd contextual information, it should3The set of 306 "anaphoric" pronouns excluded 30 occurrencesof "expletive" it not identified by the expletive patterns (prhnari lyoccurrences in object position), as well as 6 occurrences of it whichreferred to a VP or propositional constituent.
We are currently mfinin gthe existing expletive patterns for improved accuracy.117be possible to increase the overall quality of our out-put, bringing it much closer in line with Lappin andLeass' results.
Again, straight comparison would notbe trivial, as e.g.
quoted text passages are not a naturalpart of computer manuals, and are, on the other hand,an extremely common occurrence in the types of textwe are dealing with.Second, and most importantly, the absence of ex-plicit configurational information does not result in asubstantial degradation i the accuracy of an anaphoraresolution algorithm that is otherwise similar to thatdescribed in (Lappin and Leass, 1994).5 Conc lus ionLappin and Leass' algorithm for pronominal anaphoraresolution is capable of high accuracy, but requires in-depth, full, syntactic parsing of text.
The modificationsof that algorithm that we have developed make it avail-able to a larger set of text processing frameworks, aswe assume a considerably 'poorer' analysis ubstrate.While adaptations to the input format and interpreta-tion procedures have necessarily addressed the issuesof coping with a less rich level of linguistic analysis,there is only a small compromise in the quality of theresults.
Our evaluation indicates that the problemswith the current implementation donot stem from theabsence of a parse, but rather from factors which canbe addressed within the constraints imposed by theshallow base analysis.
The overall success of the algo-rithm is important, then, not only for the immediateutility of the particular modifications, but also becausethe strategy we have developed for circumventing theneed for full syntactic analysis is applicable to other in-terpretation tasks which, like the problem of anaphoraresolution, lie in the space of higher level semantic anddiscourse analysis.ReferencesMarti Hearst.
1994.
Multi-paragraph segmentation fexpository text.
In 32nd Annual Meeting of the Associ-ation for Computational Linguistics, Las Cruces, NewMexico.
Association for Computational Linguistics,Morristown, New Jersey.Irene Heim.
1982.
The Semantics of Definite and IndefiniteNoun Phrases.
Doctoral dissertation, University ofMassachusetts, Amherst.Hans Kamp.
1981.
A theory of truth and semanticrepresentation.
I  J. Groenendijk, T.Janssen, and M.Stokhof (eds.
), Formal Methods in the Study of Lan-guage.
Mathematisch Centrum Tracts, Amsterdam.Fred Karlsson, Atro Voutilainen, Juha Heikkila, andArto Antilla.
1995.
Constraint grammar: A language-independent system for parsing free text.
Mouton deGruyter, Berlin/New York.Edward Keenan and Bernard Comrie.
1977.
Nounphrase accessibility and universal grammar.
Linguis-tic Inquiry, 8:62-100.Christopher Kennedy and Branimir Boguraev.
1996.Anaphora in a wider context: Tracking discoursereferents.
In W. Wahlster (ed.
), I2th European Con-ference on Artificial Intelligence.
John Wiley and Sons,Ltd, London/New York.Shalom Lappin and Herb Leass.
1994.
An algorithmfor pronominal anaphora resolution.
ComputationalLinguistics, 20(4):535-561.Atro Voutilainen, Juha Heikkila, and Arto Antilla.1992.
A constraint grammar of English: A performance-oriented approach.
University of Helsinki, PublicationNo.
21, Helsinki, Finland.118
