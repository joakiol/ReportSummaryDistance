Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1077?1088,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsMonolingual Marginal Matching for Translation Model AdaptationAnn IrvineJohns Hopkins Universityanni@jhu.eduChris QuirkMicrosoft Researchchrisq@microsoft.comHal Daume?
IIIUniversity of Marylandme@hal3.nameAbstractWhen using a machine translation (MT)model trained on OLD-domain parallel data totranslate NEW-domain text, one major chal-lenge is the large number of out-of-vocabulary(OOV) and new-translation-sense words.
Wepresent a method to identify new translationsof both known and unknown source languagewords that uses NEW-domain comparable doc-ument pairs.
Starting with a joint distributionof source-target word pairs derived from theOLD-domain parallel corpus, our method re-covers a new joint distribution that matchesthe marginal distributions of the NEW-domaincomparable document pairs, while minimiz-ing the divergence from the OLD-domain dis-tribution.
Adding learned translations to ourFrench-English MT model results in gains ofabout 2 BLEU points over strong baselines.1 IntroductionWhen a statistical machine translation (SMT) modeltrained on OLD-domain (e.g.
parliamentary proceed-ings) parallel text is used to translate text in a NEW-domain (e.g.
medical or scientific), performance de-grades drastically.
One of the major causes is thelarge number of NEW-domain words that are out-of-vocabulary (OOV) with respect to the OLD-domaintext.
Figure 1 shows the OOV rate for text in severalNEW-domains, with respect to OLD-domain parlia-mentary proceedings.
Even more challenging arethe difficult-to-detect new-translation-sense (NTS)words: French words that are present in both theOLD and NEW domains but that are translated dif-ferently in each domain.
For example, the FrenchParliament Subtitles Medical SciencePercentof WordTypes thatareOOV01020304050603.9527.0341.4250.93Figure 1: Percent of test set word types by domain thatare OOV with respect to five million tokens of OLD-domain French parliamentary proceedings data.word enceinte is mostly translated in parliamentaryproceedings as place, house, or chamber; in medicaltext, the translation is mostly pregnant; in scientifictext, enclosures.One potential remedy is to collect parallel data inthe NEW-domain, from which we can train a newSMT model.
Smith et al(2010), for example, mineparallel text from comparable corpora.
Parallel sen-tences are informative but also rare: in the data re-leased by Smith et al(2010), only 21% of the for-eign sentences have a near-parallel counterpart in theEnglish article.1 Furthermore, these sentences donot capture all terms.
In that same dataset, we findthat on average only 20% of foreign and 28% of En-glish word types in a given article are represented inthe parallel sentence pairs.In this work, we seek to learn a joint distribu-1Only 12% of sentences from generally longer English arti-cles have a near-parallel counterpart in the foreign language.1077tion of translation probabilities over all source andtarget word pairs in the NEW-domain.
We beginwith a maximum likelihood estimate of the jointbased on a word aligned OLD-domain corpus andupdate this distribution using NEW-domain compa-rable data.
We define a model based on a single com-parable corpus and then extend it to learn from doc-ument aligned comparable corpora with any numberof comparable document pairs.
This approach al-lows us to identify translations for OOV words in theOLD-domain (e.g.
French cisaillement and perc?age,which translate as shear and drilling, in the scien-tific domain) as well as new translations for previ-ously observed NTS words (e.g.
enceinte translatesas enclosures, not place, in the scientific domain).In our MT experiments, we use the learned NEW-domain joint distribution to update our SMT modelwith translations of OOV and low frequency words;we leave the integration of new translations for NTSwords to future work.Our approach crucially depends on finding com-parable document pairs relevant to the NEW-domain.Such pairs could be derived from a number ofsources, with document pairings inferred fromtimestamps (e.g.
news articles) or topics (inferred ormanually labeled).
We use Wikipedia2 as a sourceof comparable pairs.
So-called ?interwiki links?
(which link Wikipedia articles written on the sametopic but in different languages) act as rough guid-ance that pages may contain similar information.Our approach does not exploit any Wikipedia struc-ture beyond this signal, and thus is portable to alter-nate sources of comparable articles, such as multi-lingual news articles covering the same event.Our model also relies on the assumption that eachcomparable document pair describes generally thesame concepts, though the order and structure ofpresentation may differ significantly.
The efficacyof this method likely depends on the degree of com-parability of the data; exploring the correlation be-tween comparability and MT performance is an in-teresting question for future work.2 Previous WorkIn prior work (Irvine et al 2013), we presented asystematic analysis of errors that occur when shift-2www.wikipedia.orging domains in machine translation.
That work con-cludes that errors resulting from unseen (OOV) andnew translation sense words cause the majority ofthe degradation in translation performance that oc-curs when an MT model trained on OLD-domaindata is used to translate data in a NEW-domain.
Here,we target OOV errors, though our marginal match-ing method is also applicable to learning translationsfor NTS words.A plethora of prior work learns bilingual lex-icons from monolingual and comparable corporawith many signals including distributional, tempo-ral, and topic similarity (Rapp, 1995; Fung and Yee,1998; Rapp, 1999; Schafer and Yarowsky, 2002;Schafer, 2006; Klementiev and Roth, 2006; Koehnand Knight, 2002; Haghighi et al 2008; Mimnoet al 2009; Mausam et al 2010; Prochassonand Fung, 2011; Irvine and Callison-Burch, 2013).However, this prior work stops short of using theselexicons in translation.
We augment a baseline MTsystem with learned translations.Our approach bears some similarity to Ravi andKnight (2011), Dou and Knight (2012), and Nuhnet al(2012); we learn a translation distribution de-spite a lack of parallel data.
However, we focus onthe domain adaptation setting.
Parallel data in anOLD-domain acts as a starting point (prior) for thistranslation distribution.
It is reasonable to assume aninitial bilingual dictionary can be obtained even inlow resource settings, for example by crowdsourc-ing (Callison-Burch and Dredze, 2010) or pivotingthrough related languages (Schafer and Yarowsky,2002; Nakov and Ng, 2009).Daume?
III and Jagarlamudi (2011) mine trans-lations for high frequency OOV words in NEW-domain text in order to do domain adaptation.
Al-though that work shows significant MT improve-ments, it is based primarily on distributional simi-larity, thus making it difficult to learn translations forlow frequency source words with sparse word con-text counts.
Additionally, that work reports resultsusing artificially created monolingual corpora takenfrom separate source and target halves of a NEW-domain parallel corpus, which may have more lexi-cal overlap with the corresponding test set than wecould expect from true monolingual corpora.
Ourwork mines NEW-domain-like document pairs fromWikipedia.
In this work, we show that, keeping1078data resources constant, our model drastically out-performs this previous approach.
Razmara et al(2013) take a fundamentally different approach andconstruct a graph using source language monolin-gual text and identify translations for source lan-guage OOV words by pivoting through paraphrases.Della Pietra et al(1992) and Federico (1999) ex-plore models for combining foreground and back-ground distributions for the purpose of languagemodeling, and their approaches are somewhat simi-lar to ours.
However, our focus is on translation.3 ModelOur goal is to recover a probabilistic translation dic-tionary in a NEW-domain, represented as a jointprobability distribution pnew(s, t) over source/targetword pairs.
At our disposal, we have access to a jointdistribution pold(s, t) from the OLD-domain (com-puted from word alignments), plus comparable doc-ument pairs in the NEW-domain.
From these com-parable documents, we can extract raw word fre-quencies on both the source and target side, repre-sented as marginal distributions q(s) and q(t).
Thekey idea is to estimate this NEW-domain joint dis-tribution to be as similar to the OLD-domain distri-bution as possible, subject to the constraint that itsmarginals match those of q.To illustrate our goal, consider an example.
Imag-ine in the OLD-domain parallel data we find that ac-corder translates as grant 10 times and as tune 1time.
In the NEW-domain comparable data, we findthat accorder occurs 5 times, but grant occurs onlyonce, and tune occurs 4 times.
Clearly accorder nolonger translates as grant most of the time; perhapswe should shift much of its mass onto the translationtune instead.
Figure 2 shows the intuition.First, we present an objective function and set ofconstraints over joint distributions to minimize thedivergence from the OLD-domain distribution whilematching both the source and target NEW-domainmarginal distributions.
Next, we augment the objec-tive with information about word string similarity,which is particularly useful for the French-Englishlanguage pair.
Optimizing this objective with a sin-gle pair of source and target marginals can be per-formed using an off-the-shelf solver.
In practice,though, we have a large set of document pairs, eachof which can induce a pair of marginals.
Usingthese per-document marginals provides additionalinformation to the learning function but would over-whelm a common solver.
Therefore, we present a se-quential learning method for approximately match-ing the large set of document pair marginal distribu-tions.
Finally, we describe how we identify compa-rable document pairs relevant to the NEW-domain.3.1 Marginal Matching ObjectiveGiven word-aligned parallel data in the OLD-domainand source and target comparable corpora in theNEW-domain, we first estimate a joint distributionpold(s, t) over word pairs (s, t) in the OLD-domain,where s and t range over source and target lan-guage words, respectively.
For the OLD-domainjoint distribution, we use a simple maximum like-lihood estimate based on non-null automatic wordalignments (using grow-diag-final GIZA++ align-ments (Och and Ney, 2003)).
Next, we find sourceand target marginal distributions, q(s) and q(t), byrelative frequency estimates over the source and tar-get comparable corpora.
Our goal is to recover ajoint distribution pnew(s, t) for the new domain thatmatches the marginals, q(s) and q(t), but is mini-mally different from the original joint distribution,pold(s, t).We cast this as a linear programming problem:pnew = arg minp???p?
pold??
?1(1)subject to:?s,tp(s, t) = 1, p(s, t) ?
0?sp(s, t) = q(t),?tp(s, t) = q(s)In the objective function, the joint probability matri-ces p and pold are interpreted as large vectors overall word pairs (s, t).
The first two constraints forcethe result to be a well-formed distribution, and thefinal two force the marginals to match.Following prior work (Ravi and Knight, 2011),we would like the matrix to remain as sparse as pos-sible; that is, introduce the smallest number of newtranslation pairs necessary.
A regularization termcaptures this goal:?
(p) =?s,t:pold(s,t)=0?r ?
p(s, t) (2)1079house place pregnant dressqold(s)enceinte 0.30 0.40 0.10 00.80habiller 0 0 0 0.200.20qold(t)0.30 0.40 0.10 0.20(a) OLD-Domain Joint (b) NEW-Domain Marginalshouse place pregnant dress girlq(s)enceinte?0.60habiller0.20fille0.20q(t)0.12 0.08 0.40 0.20 0.20(c) Inferred NEW-Domain Jointhouse place pregnant dress girl qnew(s)enceinte0.12 0.08 0.40 0 00.60habiller 0 0 0 0.20 0 0.20fille 0 0 0 0 0.20 0.20qnew(t)0.12 0.08 0.40 0.20 0.20=MatchedMarginalsFigure 2: Starting with a joint distribution derived from OLD-domain data, we infer a NEW-domain joint distributionbased on the intuition that the new joint should match the marginals that we observe in NEW-domain comparablecorpora.
In this example, a translation is learned for the previously OOV word fille, and pregnant becomes a preferredtranslation for enceinte.If the old domain joint probability pold(s, t) wasnonzero, there is no penalty.
Otherwise, the penaltyis ?r times the new joint probability p(s, t).
To dis-courage the addition of translation pairs that are un-necessary in the new domain, we use a value of ?rgreater than one.
Thus, the benefit of a more sparsematrix overwhelms the desire for preventing change.Any value greater than one seems to suffice; we use?r = 1.1 in our experiments.Inspired by the preference for sparse matricescaptured by ?
(p), we include another orthogonalcue that words are translations of one another: theirstring similarity.
In prior work, string similarity wasa valuable signal for inducing translations, particu-larly for closely related languages such as Frenchand English (Daume?
III and Jagarlamudi, 2011).
Wedefine a penalty function f(p) as follows: if the nor-malized Levenshtein edit distance between swithoutaccents and t is less than 0.2, no penalty is applied;a penalty of 1 is applied otherwise.
We chose the0.2 threshold manually by inspecting results on ourdevelopment sets.f(p) =?s,tp(s, t) ?
{0 if lev(t,strip(s))len(s)+len(t) < 0.21 otherwiseThe objective function including this penalty is:pnew = arg minp???p?
pold??
?1+ ?
(p) + f(p)In principle, additional penalties could be encodedin a similar way.3 This objective can be optimizedby any standard LP solver; we use the Gurobi pack-age (Gurobi Optimization Inc., 2013).3.2 Document Pair ModificationThe above formulation applies whenever we haveaccess to comparable corpora.
However, often wehave access to comparable documents, such as thosegiven by Wikipedia inter-language links.
We modifyour approach to take advantage of the document cor-respondences within our comparable corpus.
In par-ticular, we would like to match the marginals for alldocument pairs.4 By maintaining separate marginaldistributions, our algorithm is presented with more3We experimented with penalties measuring document-pairco-occurrence and monolingual frequency differences but didnot see gains on our development sets.4This situation is not unique to our application; multiplemarginals are likely to exist in many cases.1080information.
For example, imagine that one doc-ument pair uses ?dog?
and ?chien?, where anotherdocument pair uses ?cat?
and ?chat?, each with sim-ilar frequency.
If we sum these marginals to producea single marginal distribution, it is now difficult toidentify that ?dog?
should correspond to ?chien?
andnot ?chat.?
Document pair alignments add informa-tion at the cost of additional constraints.An initial formulation of our problem with mul-tiple comparable document pairs might requirethe pnew marginals to match all of the documentmarginals.
In general, this constraint set is likelyto result in an infeasible problem.
Instead, we takean incremental, online solution, considering a sin-gle comparable document pair at a time.
For docu-ment pair k, we solve the optimization problem inEq (1) to find the joint distribution minimally dif-ferent from pk-1, while matching the marginals ofthis pair only.
This gives a new joint distribution,tuned specifically for this pair.
We then update ourcurrent guess of the new domain joint toward thisdocument-pair-specific distribution, much like a stepin stochastic gradient ascent.More formally, suppose that before processing thekth document we have a guess at the NEW-domainjoint distribution, pnew1:k?1 (the subscript indicates thatit includes all document pairs up to and includingdocument k ?
1).
We first solve Eq (1) solely onthe basis of this document pair, finding a joint dis-tribution pnewk that matches the marginals of the kthdocument pair only and is minimally different frompnew1:k?1.
Finally, we form a new estimate of the jointdistribution by moving pnew1:k?1 in the direction ofpnewk , via:pnew1:k = pnew1:k?1 + ?u[pnewk ?
pnew1:k?1]The learning rate ?u is set to 0.001.5This incremental update of parameters is simi-lar to the margin infused relaxed algorithm (MIRA)(Crammer et al 2006).
Like MIRA and the percep-tron, there is not an overall ?objective?
function thatwe are attempting to optimize (as one would in manystochastic gradient steps).
Instead, we?re aiming for5We tuned ?u on semi-extrinsic results on the developmentset.
Note that although 0.001 seems small, the values we aremoving are joint probabilities, which are tiny and so smalllearning rates make sense.a solution that makes a small amount of progresson each example, in such a way if it received thatexample again, it would ?do better?
(in this case:have a closer match of marginals).
Also like MIRA,our learning rate is constant.
We parallelize learningwith mini-batches for increased speed.
Eight paral-lel learners update an initial joint distribution basedon 100 document pairs (i.e.
each learner makes 100incremental updates), and then we merge results us-ing an average over the 8 learned joint distributions.3.3 Comparable Data SelectionIt remains to select comparable document pairs.
Weassume that we have enough monolingual NEW-domain data in one language to rank comparabledocument pairs (here, Wikipedia pages) accordingto how NEW-domain-like they are.
In particular, weestimate the similarity to a source language (here,French) corpus in the NEW domain.
For our experi-ments, we use the French side of a NEW-domain par-allel corpus.6 We could have targeted our learningeven more by using our NEW-domain MT test sets.Doing so would increase the chances that our sourcelanguage words of interest appear in the comparablecorpus.
However, to avoid overfitting any particulartest set, we use the French side of the training data.For each Wikipedia document pair, we com-pute the percent of French phrases up to lengthfour that are observed in the French monolingualNEW-domain corpus and rank document pairs bythe geometric mean of the four overlap measures.More sophisticated ways to identify NEW-domain-like Wikipedia pages (e.g.
Moore and Lewis (2010))may yield additional performance gains, but, quali-tatively, the ranked Wikipedia pages seemed reason-able to the authors.4 Experimental setup4.1 DataWe use French-English Hansard parliamentary pro-ceedings7 as our OLD-domain parallel corpus.
Withover 8 million parallel lines of text, it is one of thelargest freely available parallel corpora for any lan-6We could have, analogously, used the target language (En-glish) side of the parallel corpus and measure overlap with theEnglish Wikipedia documents, or even used both.7http://www.parl.gc.ca1081guage pair.
In order to simulate more typical datasettings, we sample every 32nd line, using the result-ing parallel corpus of 253, 387 lines and 5, 051, 016tokens to train our baseline model.We test our model using three NEW-domain cor-pora: (1) the EMEA medical corpus (Tiedemann,2009), (2) a corpus of scientific abstracts (Carpuatet al 2013a), and (3) a corpus of translated moviesubtitles (Tiedemann, 2009).
We use developmentand test sets to tune and evaluate our MT mod-els.
We use the NEW-domain parallel training cor-pora only for language modeling and for identifyingNEW-domain-like comparable documents.4.2 Machine translationWe use the Moses MT framework (Koehn et al2007) to build a standard statistical phrase-basedMT model using our OLD-domain training data.
Us-ing Moses, we extract a phrase table with a phraselimit of five words and estimate the standard set offive feature functions (phrase and lexical translationprobabilities in each direction and a constant phrasepenalty feature).
We also use a standard lexicalizedreordering model and two language models based onthe English side of the Hansard data and the givenNEW-domain training corpora.
Features are com-bined using a log-linear model optimized for BLEU,using the n-best batch MIRA algorithm (Cherry andFoster, 2012).
We call this the ?simple baseline.?
InSection 5.2 we describe several other baseline ap-proaches.4.3 ExperimentsFor each domain, we use the marginal matchingmethod described in Section 3 to learn a new,domain-adapted joint distribution, pnewk (s, t), overall French and English words.
We use the learnedjoint to compute conditional probabilities, pnewk (t|s),for each French word s and rank English translationst accordingly.
First, we evaluate the learned jointdirectly using the distribution based on the word-aligned NEW-domain development set as a goldstandard.
Then, we perform end-to-end MT exper-iments.
We supplement phrase tables with transla-tions for OOV and low frequency words (we ex-periment with training data frequencies less than101, 11, and 1) and include pnewk (t|s) and pnewk (s|t)as new translation features for those supplementaltranslations.
For these new phrase pairs, we use theaverage lexicalized reordering values from the ex-isting reordering tables.
For phrase pairs extractedbilingually, we use the bilingually estimated trans-lation probabilities and uniform scores for the newtranslation features.
We experimented with usingpnewk (t|s) and pnewk (s|t) to estimate additional lex-ical translation probabilities for the bilingually ex-tracted phrase pairs but did not observe any gains(experimental details omitted due to space con-straints).
We re-run tuning in all experiments.We also perform oracle experiments in whichwe identify translations for French words in word-aligned development and test sets and append thesetranslations to baseline phrase tables.5 Results5.1 Semi-extrinsic evaluationBefore doing end-to-end MT experiments, we eval-uate our learned joint distribution, pnewk (s, t), bycomparing it to the joint distribution taken from aword aligned NEW-domain parallel development set,pgold(s, t).
We call this evaluation semi-extrinsicbecause it involves neither end-to-end MT (our ex-trinsic task) nor an intrinsic evaluation based on ourtraining objective (L1 norm).
We find it informa-tive to evaluate the models using bilingual lexiconinduction metrics before integrating our output intofull MT.
That is, we do not compare the full joint dis-tributions, but, rather, for a given French word, howour learned model ranks the word?s most probabletranslation under the gold distribution.
In particular,because we are primarily concerned with learningtranslations for previously unseen words, we eval-uate over OOV French word types.
In some cases,the correct translation for OOV words is the identi-cal string (e.g.
na+, lycium).
Because it is trivialto produce these translations,8 we evaluate over thesubset of OOV development set French words forwhich the correct translation is not the same string.Figure 3 shows the mean reciprocal rank for thelearned distribution, pnewk (s, t), for each domains asa function of the number of comparable documentpairs used in learning.
In all domains, the compara-ble document pairs are sorted according to their sim-8And, indeed, by default our decoder copies OOV stringsinto its output directly.10820 10000 20000 30000 40000 500000.00.10.20.30.40.50.6Number of Document PairsMean Reciprocal Rank0 10000 20000 30000 40000 500000.00.10.20.30.40.50.6Number of Document PairsMean Reciprocal Rank0 10000 20000 30000 40000 500000.00.10.20.30.40.50.6?Number of Document PairsMean Reciprocal Rank ?Full modelEdit distance baselineCCA BaselineModel without ED penalty 0.38MeanReciprocalRank0.220.140.110.080.260.390.070.050.03(a) Science (b) EMEA (c) SubtitlesFigure 3: Semi-extrinsic bilingual lexicon induction results.
Mean reciprocal rank is computed over all OOV devel-opment set words for which identity is not the correct translation.ilarity with the NEW-domain.
Figure 3 also showsthe performance of baseline models and our learnerwithout the edit distance penalty.
For each sourceword s, the edit distance (ED) baseline ranks all En-glish words t in our monolingual data by their editdistance with s.9 The Canonical Correlation Analy-sis (CCA) baseline uses the approach of Daume?
IIIand Jagarlamudi (2011) and the top 25, 000 rankeddocument pairs as a comparable corpus.
That modelperforms poorly largely because of sparse word con-text counts.
Interestingly, for Science and EMEA,the performance of our full model at 50, 000 doc-ument pairs is higher than the sum of the edit dis-tance baseline and the model without the edit dis-tance penalty, indicating that our approach effec-tively combines the marginal matching and edit dis-tance signals.The learning curves for the three domains varysubstantially.
For Science, learning is gradual andit appears that additional gains could be made byiterating over even more document pairs.
In con-trast, the model learns quickly for the EMEA do-main; performance is stable after 20, 000 documentpairs.
Given these results and our experience withthe two domains, we hypothesize that the differenceis due to the fact that the Science data is much moreheterogenous than the EMEA data.
The Science data9In particular, for each domain and each OOV French word,we ranked the set of all English words that appeared at least fivetimes in the set of 50,000 most NEW-domain like Wikipediapages.
Using a frequency threshold of five helped eliminateFrench words and improperly tokenized English words from theset of candidates.includes physics, chemistry, and biology abstracts,among others.
The drug labels that make up most ofthe EMEA data are more homogeneous.
In Section6 we comment on the poor Subtitles performance,which persists in our MT experiments.We experimented with making multiple learningpasses over the document pairs and observed rela-tively small gains from doing so.
In all experiments,learning from some number of additional new doc-ument pairs resulted in higher semi-extrinsic per-formance gains than passing over document pairswhich were already observed.In the case of OOV words, it?s clear that learningsomething about how to translate a previously un-observed French word is beneficial.
However, ourlearning method also learns domain-specific new-translation senses (NTS).
Table 1 shows some exam-ples of what the marginal matching method learnsfor different types of source words (OOVs, low fre-quency, and NTS).5.2 MT evaluationBy default, the Moses decoder copies OOV wordsdirectly into its translated output.
In some cases,this is correct (e.g.
ensembles, blumeria, google).In other cases, French words can be translated intoEnglish correctly by simply stripping accent marksoff of the OOV word and then copying it to the out-put (e.g.
came?ra, e?le?ments, mole?cules).
In the Sci-ence and EMEA domains, we found that our base-line BLEU scores improved from 21.91 to 22.20and 23.67 to 24.45, respectively, when we changedthe default handling of OOVs to strip accents before1083French OLD top pold(t|s) NEW top pgold(t|s) MM-learned top pnew(t|s)OOV wordscisaillement - shear strength shearing shear viscous newtoniancourbure - curvature bending curvatures curvature curved manifoldLow frequency wordsline?aires linear linear nonlinear non-linear linear linearly nonlinearre?cepteur receiver receptor receiver y1 receptor receiver receptorsNew translation sense wordschamp field jurisdiction scope field magnetic near-field field magnetic fieldsmarche working march work walk step walking march walk walkingTable 1: Hand-picked examples of Science-domain French words and their top English translations in the OLD-domain, NEW-domain, and marginal matching distributions.
The first two are OOVs.
The next two only appeared fourand one time, respectively, in the training data and only aligned to a single English word.
The last two are NTS Frenchwords: words that appeared frequently in the training data but for which the word?s sense in the new domain shifts.copying into the output.
Interestingly, performanceon the Subtitles domain text did not change at allwith this baseline modification.
This is likely dueto the fact that there are fewer technical OOVs (theterms typically captured by this accent-stripping pat-tern) in the subtitles domain.Throughout our experiments, we found it criti-cal to retain correct ?freebie?
OOV translations.
Inthe results presented below, including the baselines,we supplement phrase tables with a new candidatetranslation but also include accent-stripped identity,or ?freebie,?
translations in the table for all OOVwords.
We experimented with classifying Frenchwords as freebies or needing a new translation, butoracle experiments showed very little improvement(about 0.2 BLEU improvement in the Science do-main), so instead we simply include both types oftranslations in the phrase tables.In addition to the strip-accents baseline, we com-pare results with four other baselines.
First, wedrop OOVs from the output translations.
Second,like our semi-extrinsic baseline, we rank Englishwords by their edit distance away from each FrenchOOV word (ED baseline).
Third, we rank En-glish words by their document-pair co-occurrencescore with each French OOV word.
That is, forall words w, we compute D(w), the vector indicat-ing the document pairs in which w occurs, over theset of 50,000 document-pairs which are most NEW-domain-like.
For French and English words s and t,ifD(s) andD(t) are dissimilar, it is less likely (s, t)is a valid translation pair.
We weight D(w) entrieswith BM25 (Robertson et al 1994).
For all FrenchOOVs, we rank all English translations according tothe cosine similarity between the pair of D(w) vec-tors.
The fourth baseline uses the CCA model de-scribed in Daume?
III and Jagarlamudi (2011) to rankEnglish words according to their distributional sim-ilarity with each French word.
For the CCA base-line comparison, we only learned translations using25,000 Science-domain document pairs, rather thanthe full 50,000 and for all domains.
However, it?sunlikely that learning over more data would over-come the low performance observed so far.
For thefinal three baselines, we append French OOV wordsand their highest ranked English translation to thephrase table.
Along with each new translation pair,we include one new phrase table feature with therelevant translation score (edit distance, documentsimilarity, or CCA distributional similarity).
For allbaselines other than drop-OOVs, we also includeaccent-stripped translation pairs with an additionalindicator feature.Table 3 shows results appending the top rankedEnglish translation for each OOV French word usingeach baseline method.
None of the alternate base-lines outperform the simplest baseline on the subti-tles data.
Using document pair co-occurrences is thestrongest baseline for the Science and EMEA do-mains.
This confirms our intuition that taking ad-vantage of document pair alignments is worthwhile.For Science and EMEA, supplementing a modelwith OOV translations learned through our marginalmatching method drastically outperforms all base-1084OOVs translated correctly and incorrectlyInput les re?sistances au cisaillement par poinc?onnement ...Ref the punching shear strengths...Baseline the resistances in cisaillement by poinconnement ...MM the resistances in shear reinforcement...OOV translated incorrectlyInput pre?sentation d?
un logiciel permettant de ge?rer les donne?es temporelles .Ref presentation of software which makes it possible to manage temporal data .Baseline introduction of a software to manage temporelles data .MM introduction of a software to manage data plugged .Low frequency French wordsInput ...limite est lie?e a` la de?croissance tre`s rapide du couplage e?lectron-phonon avec la tempe?rature .Ref ...limit is linked to the rapid decrease of the electron-phonon coupling with temperature .Baseline ...limit is linked to the decline very rapid electron-phonon linkage with the temperature .MM ...limit is linked to the linear very rapid electron-phonon coupling with the temperature .Table 2: Example MT outputs for Science domain.
The baseline strips accents (Table 3).
In the first example, thepreviously OOV word cisaillement is translated correctly by an MM-supplemented model.
The OOV poinc?onnementis translated as reinforcement instead of strengths, which is incorrect with respect to the reference but arguably notbad.
In the second example, temporelles is not translated correctly in the MM output.
In the third example, the MM-hypothesized correct translation of low frequency word couplage, coupling, is chosen instead of incorrect linkage.
Alsoin the third example, the low frequency word de?croissance is translated as the MM-hypothesized incorrect translationlinear.
In the case of de?croissance, the baseline?s translation, decline, is much better than the MM translation linear.lines.
Using our model to translate OOV wordsyields scores of 23.62 and 26.97 in the Science andEMEA domains, or 1.19 and 1.94 BLEU points, re-spectively, above the strongest baseline.
We observeadditional gains by also supplementing the modelwith translations for low frequency French words.For example, when we use our approach to translatesource words in the Science domain which appearten or fewer times in our OLD-domain training data,the BLEU score increases to 24.28.We tried appending top-k translations, varying k.However, we found that for the baselines as well asour MM translations, using only the top-1 Englishtranslations outperformed using more.Table 3 also shows the result of supplementing abaseline phrase table with oracle OOV translations.Using the marginal matching learned OOV transla-tions takes us 30% and 40% of the way from thebaseline to the oracle upper bound for Science andEMEA, respectively.We have focused on supplementing an SMTmodel trained on a sample of the Hansard parallelcorpus in order to mimic typical data conditions, butwe have also performed experiments supplementingScience EMEA SubsSimple Baseline 21.91 23.67 13.18Drop OOVs 20.22 18.95 11.86Accent-Stripped 22.20 24.45 13.13ED Baseline 22.10 24.35 12.95Doc Sim Baseline.
22.43 25.03 13.02CCA Baseline 21.41 - -MM Freq<1 (OOV) 23.62 26.97 13.07MM Freq<11 24.28 27.26 12.97MM Freq<101 23.96 26.82 12.92Oracle OOV 26.38 29.99 15.06Table 3: BLEU results using: (1) baselines, (2) phrasetables augmented with top-1 translations for Frenchwords with indicated OLD training data frequencies, (3)phrase tables augmented with OOV oracle translations.a model trained on the full dataset.10 Beginning withthe larger model, we observe performance gains of0.8 BLEU points for both the EMEA and the Sci-ence domains over the strongest baselines, which arebased on document similarity, when we add OOV10We still use the joint that was learned starting with the oneestimated over the sample; we may observe greater gains overthe full Hansard baseline with a stronger initial joint.1085translations.
As expected, these gains are less thanwhat we observe when our baseline model is esti-mated over less data, but they are still substantial.In all experiments, we have assumed that we haveno NEW-domain parallel training data, which is thecase for the vast majority of language pairs and do-mains.
However, In the case that we do have someNEW-domain parallel data, OOV rates will be some-what lower, but our method is still applicable.
Forexample, we would need 2.3 million words of Sci-ence (NEW-domain) parallel data to cover just 50%of the OOVs in our Science test set, and 4.3 millionwords to cover 70%.6 DiscussionBLEU score performance gains are substantial forthe Science and EMEA domains, but we don?t ob-serve gains on the subtitles text.
We believe this dif-ference relates to the difference between a corpusdomain and a corpus register.
As Lee (2002) ex-plains, a text?s domain is most related to its topic,while a text?s register is related to its type and pur-pose.
For example, religious, scientific, and dia-logue texts may be classified as separate registers,while political and scientific expositions may have asingle register but different domains.
Our scienceand EMEA corpora are certainly different in do-main from the OLD-domain parliamentary proceed-ings, and our success in boosting MT performancewith our methods indicates that the Wikipedia com-parable corpora that we mined match those domainswell.
In contrast, the subtitles data differs from theOLD-domain parliamentary proceedings in both do-main and register.
Although the Wikipedia data thatwe mined may be closer in domain to the subtitlesdata than the parliamentary proceedings,11 its regis-ter is certainly not film dialogues.Although the use of marginal matching is, to thebest of our knowledge, novel in MT, there are relatedthreads of research that might inspire future work.The intuition that we should match marginal distri-butions is similar to work using no example labelsbut only label proportions to estimate labels, for ex-ample in Quadrianto et al(2008).
Unlike that work,11In fact, we believe that it is.
Wikipedia pages that rankedvery high in our subtitles-like list included, for example, themovie The Other Side of Heaven and actor Frank Sutton.our label set corresponds to entire vocabularies, andwe have multiple observed label proportions.
Also,while the marginal matching objective seems effec-tive in practice, it is difficult to optimize.
A numberof recently developed approximate inference meth-ods use a decomposition that bears a strong resem-blance to this objective function.
Considering themarginal distributions from each document pair tobe a separate subproblem, we could approach theglobal objective of satisfying all subproblems as aninstance of dual decomposition (Sontag et al 2010)or ADMM (Gabay and Mercier, 1976; Glowinskiand Marrocco, 1975).We experiment with French-English because tun-ing and test sets are available in several domains forthat language pair.
However, our techniques are di-rectly applicable to other language pairs, includingthose that are less related.
We have observed thatmany domain-specific terms, particularly in medi-cal and science domains, are borrowed across lan-guages, whether or not the languages are related.Even for languages with different character sets,one could do transliteration before measuring ortho-graphical similarity.Although we were able to identify translations forsome NTS words (Table 1), we did not make use ofthem in our MT experiments.
Recent work has iden-tified NTS words in NEW-domain corpora (Carpuatet al 2013b), and in future work we plan to incorpo-rate discovered translations for such words into MT.7 ConclusionsWe proposed a model for learning a joint distribu-tion of source-target word pairs based on the ideathat its marginals should match those observed inNEW-domain comparable corpora.
Supplementinga baseline phrase-based SMT model with learnedtranslations results in BLEU score gains of abouttwo points in the medical and science domains.AcknowledgmentsWe gratefully acknowledge the support of the2012 JHU Summer Workshop and NSF Grant No1005411.
We would like to thank the entire DAMTteam (http://hal3.name/damt/) and San-jeev Khudanpur for their help and suggestions.We also acknowledge partial support from DARPA1086CSSG Grant D11AP00279 and DARPA BOLT Con-tract HR0011-12-C-0015 for Hal Daume?
III andsupport from the Johns Hopkins University HumanLanguage Technology Center of Excellence for AnnIrvine.
The views and conclusions contained in thispublication are those of the authors and should notbe interpreted as representing official policies or en-dorsements of DARPA or the U.S. Government.ReferencesChris Callison-Burch and Mark Dredze.
2010.
Creatingspeech and language data with Amazon?s MechanicalTurk.
In Proceedings of the NAACL Workshop on Cre-ating Speech and Language Data with Amazon?s Me-chanical Turk.Marine Carpuat, Hal Daume?
III, Alexander Fraser, ChrisQuirk, Fabienne Braune, Ann Clifton, Ann Irvine,Jagadeesh Jagarlamudi, John Morgan, Majid Raz-mara, Ales?
Tamchyna, Katharine Henry, and RachelRudinger.
2013a.
Domain adaptation in machinetranslation: Final report.
In 2012 Johns Hopkins Sum-mer Workshop Final Report.Marine Carpuat, Hal Daume?
III, Katharine Henry, AnnIrvine, Jagadeesh Jagarlamudi, and Rachel Rudinger.2013b.
Sensespotting: Never let your parallel data tieyou to an old domain.
In Proceedings of the Confer-ence of the Association for Computational Linguistics(ACL).Colin Cherry and George Foster.
2012.
Batch tun-ing strategies for statistical machine translation.
InProceedings of the Conference of the North AmericanChapter of the Association for Computational Linguis-tics (NAACL).Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer.
2006.
Online passive-aggressive algorithms.
J. Mach.
Learn.
Res., 7:551?585, December.Hal Daume?
III and Jagadeesh Jagarlamudi.
2011.
Do-main adaptation for machine translation by mining un-seen words.
In Proceedings of the Conference of theAssociation for Computational Linguistics (ACL).S.
Della Pietra, V. Della Pietra, R. L. Mercer, andS.
Roukos.
1992.
Adaptive language modeling us-ing minimum discriminant estimation.
Proceedingsof the International Conference on Acoustics, Speech,and Signal Processing (ICASSP).Qing Dou and Kevin Knight.
2012.
Large scale deci-pherment for out-of-domain machine translation.
InProceedings of the Conference on Empirical Methodsin Natural Language Processing (EMNLP).Marcello Federico.
1999.
Efficient language modeladaptation through mdi estimation.
In Proceedings ofEUROSPEECH.Pascale Fung and Lo Yuen Yee.
1998.
An IR approachfor translating new words from nonparallel, compara-ble texts.
In Proceedings of the Conference of the As-sociation for Computational Linguistics (ACL).Daniel Gabay and Bertrand Mercier.
1976.
A dual al-gorithm for the solution of nonlinear variational prob-lems via finite element approximation.
Computers andMathematics with Applications, 2(1):17 ?
40.Roland Glowinski and A. Marrocco.
1975.
Surl?approximation, par e?le?ments finis d?ordre un, et lare?solution, par pe?nalisation-dualite?, d?une classe deproble`mes de dirichlet non line?aires.
Rev.
Franc.
Au-tomat.
Inform.
Rech.
Operat., 140:41?76.Gurobi Optimization Inc. 2013.
Gurobi optimizer refer-ence manual.Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,and Dan Klein.
2008.
Learning bilingual lexiconsfrom monolingual corpora.
In Proceedings of the Con-ference of the Association for Computational Linguis-tics (ACL).Ann Irvine and Chris Callison-Burch.
2013.
Supervisedbilingual lexicon induction with multiple monolingualsignals.
In Proceedings of the Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics (NAACL).Ann Irvine, John Morgan, Marine Carpuat, Hal Daume?III, and Dragos Munteanu.
2013.
Measuring machinetranslation errors in new domains.
Transactions of theAssociation for Computational Linguistics (TACL).Alexandre Klementiev and Dan Roth.
2006.
Weaklysupervised named entity transliteration and discoveryfrom multilingual comparable corpora.
In Proceed-ings of the Conference of the Association for Compu-tational Linguistics (ACL).Philipp Koehn and Kevin Knight.
2002.
Learning atranslation lexicon from monolingual corpora.
In ACLWorkshop on Unsupervised Lexical Acquisition.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Proceed-ings of the Conference of the Association for Compu-tational Linguistics (ACL).David Lee.
2002.
Genres, registers, text types, domainsand styles: Clarifying the concepts and navigating apath through the bnc jungle.
Language and Comput-ers, 42(1):247?292.Mausam, Stephen Soderland, Oren Etzioni, Daniel S.Weld, Kobi Reiter, Michael Skinner, Marcus Sammer,1087and Jeff Bilmes.
2010.
Panlingual lexical transla-tion via probabilistic inference.
Artificial Intelligence,174:619?637, June.David Mimno, Hanna Wallach, Jason Naradowsky, DavidSmith, and Andrew McCallum.
2009.
Polylingualtopic models.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing(EMNLP).Robert C. Moore and William Lewis.
2010.
Intelligentselection of language model training data.
In Proceed-ings of the Conference of the Association for Compu-tational Linguistics (ACL).Preslav Nakov and Hwee Tou Ng.
2009.
Improved statis-tical machine translation for resource-poor languagesusing related resource-rich languages.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing (EMNLP).Malte Nuhn, Arne Mauser, and Hermann Ney.
2012.Deciphering foreign language by combining languagemodels and context vectors.
In Proceedings of theConference of the Association for Computational Lin-guistics (ACL).Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51, March.Emmanuel Prochasson and Pascale Fung.
2011.
Rareword translation extraction from aligned comparabledocuments.
In Proceedings of the Conference of theAssociation for Computational Linguistics (ACL).Novi Quadrianto, Alex J. Smola, Tiberio S. Caetano, andQuoc V. Le.
2008.
Estimating labels from label pro-portions.
In Proceedings of the International Confer-ence on Machine Learning (ICML).Reinhard Rapp.
1995.
Identifying word translations innon-parallel texts.
In Proceedings of the Conference ofthe Association for Computational Linguistics (ACL).Reinhard Rapp.
1999.
Automatic identification of wordtranslations from unrelated English and German cor-pora.
In Proceedings of the Conference of the Associ-ation for Computational Linguistics (ACL).Sujith Ravi and Kevin Knight.
2011.
Deciphering for-eign language.
In Proceedings of the Conference ofthe Association for Computational Linguistics (ACL).Majid Razmara, Maryam Siahbani, Gholamreza Haffari,and Anoop Sarkar.
2013.
Graph propagation for para-phrasing out-of-vocabulary words in statistical ma-chine translation.
In Proceedings of the Conference ofthe Association for Computational Linguistics (ACL).S.E.
Robertson, S. Walker, S. Jones, M.M.
Hancock-Beaulieu, and M. Gatford.
1994.
Okapi at TREC-3.In Proceedings of the Text REtrieval Conference.Charles Schafer and David Yarowsky.
2002.
Induc-ing translation lexicons via diverse similarity measuresand bridge languages.
In Proceedings of the Confer-ence on Natural Language Learning (CoNLL).Charles Schafer.
2006.
Translation Discovery Using Di-verse Similarity Measures.
Ph.D. thesis, Johns Hop-kins University.Jason R. Smith, Chris Quirk, and Kristina Toutanova.2010.
Extracting parallel sentences from comparablecorpora using document level alignment.
In Proceed-ings of the Conference of the North American Chap-ter of the Association for Computational Linguistics(NAACL).David Sontag, A. Globerson, and Tommi Jaakola, 2010.Introduction to dual decomposition for inference,chapter 1.
MIT Press.Jo?rg Tiedemann.
2009.
News from OPUS - A collectionof multilingual parallel corpora with tools and inter-faces.
In N. Nicolov, K. Bontcheva, G. Angelova, andR.
Mitkov, editors, Recent Advances in Natural Lan-guage Processing (RANLP).1088
