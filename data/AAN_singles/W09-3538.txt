Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 194?201,Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLPCzech Named Entity Corpus and SVM-based RecognizerJana Kravalova?Charles University in PragueInstitute of Formal and Applied Linguisticskravalova@ufal.mff.cuni.czZdene?k Z?abokrtsky?Charles University in PragueInstitute of Formal and Applied Linguisticszabokrtsky@ufal.mff.cuni.czAbstractThis paper deals with recognition ofnamed entities in Czech texts.
We presenta recently released corpus of Czech sen-tences with manually annotated named en-tities, in which a rich two-level classifica-tion scheme was used.
There are around6000 sentences in the corpus with roughly33000 marked named entity instances.
Weuse the data for training and evaluating anamed entity recognizer based on SupportVector Machine classification technique.The presented recognizer outperforms theresults previously reported for NE recog-nition in Czech.1 IntroductionAfter the series of Message UnderstandingConferences (MUC; (Grishman and Sundheim,1996)), processing of named entities (NEs) be-came a well established discipline within the NLPdomain, usually motivated by the needs of Infor-mation Extraction, Question Answering, or Ma-chine Translation.
For English, one can find liter-ature about attempts at rule-based solutions for theNE task as well as machine-learning approaches,be they dependent on the existence of labeled data(such as CoNLL-2003 shared task data), unsuper-vised (using redundancy in NE expressions andtheir contexts, see e.g.
(Collins and Singer, 1999))or a combination of both (such as (Talukdar et al,2006), in which labeled data are used as a sourceof seed for an unsupervised procedure exploitinghuge unlabeled data).
A survey of research onnamed entity recognition is available in (Ekbal andBandyopadhyay, 2008).There has been considerably less researchdone in the NE field in Czech, as discussed in(S?evc???kova?
et al, 2007b).
Therefore we focus onit in this paper, which is structured as follows.
InSection 2 we present a recently released corpusof Czech sentences with manually annotated in-stances of named entities, in which a rich classi-fication scheme is used.
In Section 3 we describea new NE recognizer developed for Czech, basedon the Support Vector Machine (SVM) classifi-cation technique.
Evaluation of such approach ispresented in Section 4.
The summary is given inSection 5.2 Manually Annotated Corpus2.1 Data SelectionWe have randomly selected 6000 sentencesfrom the Czech National Corpus1 from the re-sult of the query ([word=".*[a-z0-9]"][word="[A-Z].*"]).
This query makes therelative frequency of NEs in the selection higherthan the corpus average, which makes the sub-sequent manual annotation much more effective,even if it may slightly bias the distribution of NEtypes and their observed density.22.2 Annotation NE Instances with Two-levelNE ClassificationThere is no generally accepted typology of NamedEntities.
One can see two trends: from the view-point of unsupervised learning, it is advantageousto have just a few coarse-grained categories (cf.the NE classification developed for MUC confer-ences or the classification proposed in (Collinsand Singer, 1999), where only persons, locations,and organizations were distinguished), whereasthose interested in semantically oriented applica-tions prefer more informative (finer-grained) cat-egories (e.g.
(Fleischman and Hovy, 2002) with1http://ucnk.ff.cuni.cz2The query is trivially motivated by the fact that NEs inCzech (as well as in many other languages) are often markedby capitalization of the first letter.
Annotation of NEs in a cor-pus without such selection would lower the bias, but wouldbe more expensive due to the lower density of NE instancesin the annotated material.194Types of NEa - Numbers in addressesc - Bibliographic itemsg - Geographical namesi - Institutionsm - Media namesn - Specific number usageso - Artifact namesp - Personal namesq - Quantitative expressionst - Time expressionsah - street numbers at - phone/fax numbersaz - zip codescb - volume numbers cn - chapt./sect./fig.
numberscp - page numbers cr - legisl.
act numberscs - article titlesgc - states gh - hydronymsgl - nature areas / objects gp - planets, cosmic objectsgq - urban parts gr - territorial namesgs - streets, squares gt - continentsgu - cities/towns g_ - underspecifiedia - conferences/contests ic - cult./educ./scient.
inst.if - companies, concerns... io - government/political inst.i_ - underspecifiedmi - internet links mn - periodicalmr - radio stations mt - TV stationsna - age nc - sport scoreni - itemizer nm - in formulanp - part of personal name nq - town quarternr - ratio nw - flat sizen_ - underspecifiedoa - cultural artifacts (books, movies) oc - chemicaloe - measure units om - currency unitsop - products or - directives, normso_ - underspecifiedpb - animal names pc - inhabitant namespd - (academic) titles pf - first namespm - second names pp - relig./myth personsps - surnames p_ - underspecifiedqc - cardinal numbers qo - ordinal numberstc - centuries td - daystf - feasts th - hourstm - months tn - minutestp - epochs ts - secondsty - yearsFigure 1: Two-level hierarchical classification of NEs used in the corpus.
Note that the (detailed) NEtypes are divided into two columns just because of the space reasons here.195eight types of person labels, or Sekine?s ExtendedNE Hierarchy, cf.
(Sekine, 2003)).In our corpus, we use a two-level NE classifi-cation depicted in Figure 1.
The first level corre-sponds to rough categories (called NE supertypes)such as person names, geographical names etc.The second level provides a more detailed classi-fication: e.g.
within the supertype of geographi-cal names, the NE types of names of cities/towns,names of states, names of rivers/seas/lakes etc.are distinguished.3 If more robust processing isnecessary, only the first level (NE supertypes)can be used, while the second level (NE types)comes into play when more subtle information isneeded.
Each NE type is encoded by a unique two-character tag (e.g., gu for names of cities/towns,gc for names of states; a special tag, such as g ,makes it possible to leave the NE type underspec-ified).Besides the terms of NE type and supertype, weuse also the term NE instance, which stands for acontinuous subsequence of tokens expressing theentity in a given text.
In the simple plain-text for-mat, which we use for manual annotations, the NEinstances are marked as follows: the word or thespan of words belonging to the NE is delimited bysymbols < and >, with the former one immediatelyfollowed by the NE type tag (e.g.
<pf John> loves<pf Mary>).The annotation scheme allows for the embed-ding of NE instances.
There are two types of em-bedding.
In the first case, the NE of a certaintype can be embedded in another NE (e.g., theriver name can be part of a name of a city as in<gu U?st??
nad <gh Labem>>).
In the second case,two or more NEs are parts of a (so-called) con-tainer NE (e.g., two NEs, a first name and a sur-name, form together a person name container NEsuch as in <P<pf Paul> <ps Newman>>).
Thecontainer NEs are marked with a capital one-lettertag: P for (complex) person names, T for tempo-ral expressions, A for addresses, and C for biblio-graphic items.
A more detailed description of theNE classification can be found in (S?evc???kova?
et al,2007b).3Given the size of the annotated data, further subdivi-sion into even finer classes (such as persons divided into cat-egories such as lawyer, politician, scientist used in (Fleis-chman and Hovy, 2002)) would result in too sparse annota-tions.2.3 Annotated Data CleaningAfter collecting all the sentences annotated by theannotators, it was necessary to clean the data in or-der to improve the data quality.
For this purpose,a set of tests was implemented.
The tests revealedwrong or ?suspicious?
spots in the data (based e.g.on the assumption that the same lemma shouldmanifest an entity of the same type in most its oc-currences), which were manually checked and cor-rected if necessary.
Some noisy sentences causede.g.
by wrong sentence segmentation in the origi-nal resource were deleted; the final size of the cor-pus is 5870 sentences.2.4 Morphological Analysis of AnnotatedDataThe sentences have been enriched with morpho-logical tags and lemmas using Jan Hajic?
?s taggershipped with Prague Dependency Treebank 2.0(Hajic?
et al, 2006) integrated into the TectoMTenvironment (Z?abokrtsky?
et al, 2008).
Motivationfor this step was twofold?
Czech is a morphologically rich language,and named entities might be subject toparadigms with rich inflection too.
Forexample, male first name Toma?s?
(Thomas)migh appear also in one of the followingforms: Toma?s?e, Toma?s?ovi, Toma?s?i, Toma?s?em,Toma?s?ove?, Toma?s?u?m .
.
.
(according to gram-matical case and number), which would makethe training data without lemmatization muchsparser.?
Additional features (useful for SVM as wellas for any other Machine Learning approach)can be mined from the lemma and tag se-quences, as shown in Section 3.2.2.5 Public Data ReleaseManually annotated and cleaned 6000 sentenceswith roughly 33000 named entities were releasedas Czech Named Entity Corpus 1.0.
The corpusconsists of manually annotated sentences and mor-phological analysis in several formats: a simpleplain text format, a simple xml format, a morecomplex xml format based on the Prague MarkupLanguage (Pajas and S?te?pa?nek, 2006) and contain-ing also the above mentioned morphological anal-ysis, and the html format with visually highlightedNE instances.For the purposes of supervised machine learn-ing, division of data into training, development196and evaluation subset is provided in the corpus.The division into training, development and evalu-ation subsets was made by random division of sen-tences into three sets, in proportion 80% (training),10% (development) and 10% (evaluation), see Ta-ble 1.
Other basic quantitative properties are sum-marized in Table 2 and Table 3.The resulting data collection, calledCzech Named Entity Corpus 1.0, isnow publicly available on the Internet athttp://ufal.mff.cuni.cz/tectomt.Set #Sentences #Words #NE instancestrain 4696 119921 26491dtest 587 14982 3476etest 587 15119 3615total 5870 150022 33582Table 1: Division of the annotated corpus intotraining, development test, and evaluation test sets.Lenght #Occurrences Proportionone-word 23057 68.66%two-word 6885 20.50%three-word 1961 5.84%longer 1679 5.00%total 33582 100.00%Table 2: Occurrences of NE instances of differentlength in the annotated corpus.3 SVM-based Recognizer3.1 NER as a classification taskIn this section, we formulate named entity recog-nition as a classification problem.
The task ofnamed entity recognition as a whole includes sev-eral problems to be solved:?
detecting ?basic?
one-word, two-word andmultiword named entities,?
detecting complex entities containing otherentities (e.g.
an institution name containinga personal name).Furthermore, one can have different require-ments on what a correctly recognized named entityis (and train a separate recognizer for each case):?
an entity whose span and type are correctlyrecognized,NE type #Occurrences Proportionps 4040 12.03%pf 3072 9.15%P 2722 8.11%gu 2685 8.00%qc 2040 6.07%oa 1695 5.05%ic 1410 4.20%ty 1325 3.95%th 1325 3.95%s 1285 3.83%gc 1107 3.30%if 834 2.48%io 830 2.47%tm 559 1.66%n 512 1.52%f 506 1.51%Table 3: Distribution of several most frequent NEtypes in the annotated corpus.?
an entity whose span and supertype are cor-rectly recognized,?
an entity whose span is correctly recognized(without regard to its type).Therefore, we subdivide the classification prob-lem into a few subproblems.
Firstly, we indepen-dently evaluate the recognition system for one-word named entities, for two-word named enti-ties and for multiword named entities.
For eachof these three problems, we define three tasks, or-dered from the easiest to the most difficult:?
Named entity span recognition ?
all words ofnamed entity must be found but the type isnot relevant.
For one-word entities, this re-duces to 0/1 classification problem, that is,each word is either marked as named entity(1) or as regular word (0).
For two-word en-tities, this 0/1 decision is made for each cou-ple of subsequent words (bigram) in the sen-tence.?
Named entity supertype recognition ?
allwords of named entity must be found and thesupertype must be correct.
This is a multi-class classification problem, where classesare named entity classes of the first level inhierarchy (p, g, i, ...) plus one classfor regular words.197?
Named entity type recognition ?
all wordsof named entity must be found and the typemust be correct.In our solution, a separate SVM classifieris built for one-word named entities, two-wordnamed entities and three-word named entities.Then, as we proceed through the text, we apply theclassifier on each ?window?
or ?n-gram?
of words?
one-word, two-word and three-word, classifyingthe n-gram with the corresponding SVM classi-fier.
We deliberately omit named entities contain-ing four and more words, as they represent only asmall portion of the instances (5%).3.2 FeaturesClassification features which were used by theSVM classifier(s), are as follows:?
morphological features ?
part of speech, gen-der, case and number,?
orthographic features ?
boolean featuressuch as capital letter at the beginning of theword or regular expression for time and year,?
lists of known named entities ?
boolean fea-tures describing whether the word is listedin lists of Czech most used names and sur-names, Czech cities, countries or famous in-stitutions,?
lemma ?
some lemmas contain shortcuts de-scribing the property of lemma, for example?Prahou?
(Prague, 7th case) would lemma-tize to ?Praha ;G?
with mark ?
;G?
hintingthat ?Praha?
is a geographical name,?
context features ?
similar features for pre-ceding and following words, that is, part ofspeech, gender, case and number for the pre-ceding and following word, orthographic fea-tures, membership in a list of known entitiesand lemma hints for the preceding and fol-lowing word.All classification features were transformed intobinary (boolean) features, resulting in roughly200-dimensional binary feature space.3.3 Classifier implementationFor the classification task, we decided to use Sup-port Vector Machine classification method.
First,this solution has been repeatedly shown to givebetter scores in NE recognition in comparison toother Machine Learning methods, see e.g.
(Isozakiand Kazawa, 2002) and (Ekbal and Bandyopad-hyay, 2008).
Second, in our preliminary experi-ments on our data it outperformed all other solu-tions too (based on naive Bayes, k nearest neigh-bors, and decision trees).As an SVM classifier, we used its CPAN Perlimplementation Algorithm-SVM.4Technically, the NE recognizer is implementedas a Perl module included into TectoMT, which isa modular open source software framework for im-plementing NLP applications, (Z?abokrtsky?
et al,2008).54 Evaluation4.1 Evaluation metricsWe use the following standard quantities for eval-uating performance of the presented classifier:?
precision ?
the number of correctly predictedNEs divided by the number of all predictedNEs,?
recall ?
the number of correctly predictedNEs divided by the number of all NEs in thedata,?
f-score ?
harmonic mean of precision and re-call.In our opinion, simpler quantities such as accu-racy (the percentage of correctly marked words)are not suitable for this task, since the numberof NE instances to be found is not known in ad-vance.64.2 ResultsThe results for SVM classifier when applied onthe evaluation test set of the corpus are summa-rized in Table 4.
The table evaluates all subtasksas defined in Section 3.1, that is, for combination4http://www.cpan.org/authors/id/L/LA/LAIRDM/5One of the reasons for integrating the classifier into Tec-toMT is the fact that it requires the input texts to be sentence-segmented, tokenized, tagged and lemmatized; all the nec-essary tools for such preprocessing are already available inTectoMT.6Counting also all non-NEwords predicted as non-entitiesas a success would lead to very high accuracy value withoutmuch information content (obviously most words are not NEinstances).198All NEs One-word NEs Two-word NEsP R F P R F P R Fspan+type 0.75 0.62 0.68 0.80 0.71 0.75 0.68 0.62 0.65span+supertype 0.75 0.67 0.71 0.87 0.78 0.82 0.71 0.64 0.67span 0.84 0.70 0.76 0.89 0.80 0.84 0.76 0.69 0.72Table 4: Summary of the SVM classifier performance (P=precision, R=recall, F=f-measure).
Recogni-tion of NEs of different length is evaluated separately.
The other dimension corresponds to the graduallyreleased correctness requirements.true type predicted type true type description predicted type description errorsoa x cultural artifacts (books, movies) no entity 184ic x cult./educ./scient.
inst.
no entity 74x gu no entity cities/towns 71x P no entity personal name container 66if x companies, concerns .
.
.
no entity 60x ic no entity cult./educ./scient.
inst.
59io x government/political inst.
no entity 57x ps no entity surnames 47P x personal name container no entity 43ps x surnames no entity 41gu x cities/towns no entity 37x td no entity days 35op x products no entity 33x pf no entity first names 31T x time container no entity 30Table 5: The most frequent types of errors in NE recognition made by the SVM classifier.of subtask defined for all entities, one-word enti-ties and two-word entities and with gradually re-leased requirements for correctness: correct spanand correct (detailed) type, correct span and cor-rect supertype, correct span only.The most common SVM classification errorsare shown in Table 5.4.3 DiscussionAs we can see in Table 4, the classifier recognizesspan and type of all named entities in text withf-measure = 0.68.
This improves the results re-ported on this data in (S?evc???kova?
et al, 2007a),which was 0.62.
For one-word named entities, theimprovement is also noticeable, from 0.70 to 0.75.In our opinion, the improvement is caused bybetter feature selection on one hand.
We do notuse as many classification features as the authorsof (S?evc???kova?
et al, 2007a), instead we made apreliminary manual selection of features we con-sidered to be helpful.
For example, we do not usethe whole variety of 15 Czech morphological cat-egories for every word in context, but we use onlypart of speech, gender, case and number.
Also,we avoided using features based on storing wordswhich occurred in training data, such as booleanfeature, which is true for words, which appearedin training data as named entity.
We tried employ-ing such features, but in our opinion, they result insparsity in space searched by SVM.It would be highly difficult to correctly comparethe achieved results with results reported on otherlanguages (such as f-score 88.76% achieved forEnglish in (Zhang and Johnson, 2003)), especiallybecause of different task granularity (and obvi-ously highly different baselines).
Furthermore, inCzech the task is more complicated due to inflec-tion: many named entities can appear in severalmany different forms.
For example, the Czechcapital city ?Praha?
appeared in these forms intraining data: Praha, Prahy, Prahou, Prahu.Table 5 describes the most common errors madeby classifier.
Clearly, the most problematic classesare objects (oa) and institutions (ic, if, io),199which mostly remain unrecognized.
The problemis that, cultural artifacts like books or movies, orinstitutions, tend to have quite new and unusualnames, as opposed to personal names, for whichfairly limited amount of choice exists, and cities,which do not change and can be listed easily.Institutions also tend to have long and com-plicated names, for which it is especially diffi-cult to find the ending frontier.
We believe thatdependency syntax analysis (such as dependencytrees resulting from the maximum spanning treeparser, (McDonald et al, 2005)) might providesome clues here.
By determining the head of theclause, e.g.
theatre, university, gallery and it?s de-pendants, we might get some hints about whichwords are part of the name and which are not.Yet another improvement in overall perfor-mance could be achieved by incorporating hyper-nym discovery (making use e.g.
of Wikipedia) asproposed in (Kliegr et al, 2008).5 ConclusionsWe have presented a new recently published cor-pus of Czech sentences with manually annotatednamed entities with fine-grained two-level annota-tion.
We used the data for training and evaluating anamed entity recognizer based on Support VectorMachines classification technique.
Our classifierreached f-measure 0.68 in recognizing and classi-fying Czech named entities into 62 categories andthus outperformed the results previously reportedfor NE recognition in Czech in (S?evc???kova?
et al,2007a).We intend to further improve our classifier,especially recognition of institution and objectnames, by employing dependency syntax features.Another improvement is hoped to be achieved us-ing WWW-based ontologies.AcknowledgmentsThis research was supported by MSM0021620838, GAAV C?R 1ET101120503, andMS?MT C?R LC536.ReferencesMichael Collins and Yoram Singer.
1999.
Unsuper-vised Models for Named Entity Classification.
InProceedings of the Conference on Empirical Meth-ods in Natural Language Processing and Very LargeCorpora (EMNLP/VLC), pages 189?196.Asif Ekbal and Sivaji Bandyopadhyay.
2008.
NamedEntity Recognition using Support Vector Machine:A Language Independent Approach .
InternationalJournal of Computer Systems Science and Engineer-ing, 4(2):155?170.Michael Fleischman and Eduard Hovy.
2002.
FineGrained Classification of Named Entities .
In Pro-ceedings of the 19th International Conference onComputational Linguistics (COLING), volume I,pages 267?273.Ralph Grishman and Beth Sundheim.
1996.
Mes-sage Understanding Conference - 6: A Brief History.In Proceedings of the 16th International Conferenceon Computational Linguistics (COLING), volume I,pages 466?471.Jan Hajic?, Jarmila Panevova?, Eva Hajic?ova?, PetrSgall, Petr Pajas, Jan S?te?pa?nek, Jir???
Havelka,Marie Mikulova?, Zdene?k Z?abokrtsky?, and MagdaS?evc???kova?.
2006.
Prague Dependency Treebank2.0.Hideki Isozaki and Hideto Kazawa.
2002.
Effi-cient Support Vector Classifiers For Named EntityRecognition.
In Proceedings of the 19th Inter-national Conference on Computational Linguistics(COLING?02).Tomas Kliegr, Krishna Chandramouli, Jan Nemrava,Vojtech Svatek, and Ebroul Izquierdo.
2008.Wikipedia as the premiere source for targeted hy-pernym discovery.
WBBT ECML08.Ryan McDonald, Fernando Pereira, Kiril Ribarov, andJan Hajic?.
2005.
Non-Projective Dependency Pars-ing using Spanning Tree Algorithms.
In Proceed-ings of Human Langauge Technology Conferenceand Conference on Empirical Methods in NaturalLanguage Processing (HTL/EMNLP), pages 523?530, Vancouver, BC, Canada.Petr Pajas and Jan S?te?pa?nek.
2006.
XML-based rep-resentation of multi-layered annotation in the PDT2.0.
In Richard Erhard Hinrichs, Nancy Ide, MarthaPalmer, and James Pustejovsky, editors, Proceed-ings of the LREC Workshop on Merging and Layer-ing Linguistic Information (LREC 2006), pages 40?47, Paris, France.Satoshi Sekine.
2003.
Sekine?s Extended Named En-tity Hierarchy.
http://nlp.cs.nyu.edu/ene/.Magda S?evc??
?kova?, Zdene?k Z?abokrtsky?, and Oldr?ichKru?za.
2007.
Named Entities in Czech: Annotat-ing Data and Developing NE Tagger.
In Va?clav Ma-tous?ek and Pavel Mautner, editors, Lecture Notes inArtificial Intelligence, Proceedings of the 10th Inter-national Conference on Text, Speech and Dialogue,volume 4629 of Lecture Notes in Computer Science,pages 188?195, Pilsen, Czech Republic.
SpringerScience+Business Media Deutschland GmbH.200Partha Pratim Talukdar, Thorsten Brants, Mark Liber-man, and Fernando Pereira.
2006.
A Context Pat-tern Induction Method for Named Entity Extraction.In Proceedings of the 10th Conference on Com-putational Natural Language Learning (CoNLL-X),pages 141?148.Magda S?evc??
?kova?, Zdene?k Z?abokrtsky?, and Oldr?ichKru?za.
2007.
Zpracova?n??
pojmenovany?ch entitv c?esky?ch textech.
Technical report, U?FAL MFFUK, Praha.Zdene?k Z?abokrtsky?, Jan Pta?c?ek, and Petr Pajas.
2008.TectoMT: Highly Modular MT System with Tec-togrammatics Used as Transfer Layer.
In Proceed-ings of the 3rd Workshop on Statistical MachineTranslation, ACL.Tong Zhang and David Johnson.
2003.
A robust riskminimization based named entity recognition sys-tem.
In Walter Daelemans and Miles Osborne, ed-itors, Proceedings of CoNLL-2003, pages 204?207.Edmonton, Canada.201
