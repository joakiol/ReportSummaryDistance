Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 68?76,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsReengineering a domain-independent frameworkfor Spoken Dialogue SystemsFilipe M. Martins, Ana Mendes, Ma?rcio Viveiros, Joana Paulo Pardal,Pedro Arez, Nuno J. Mamede and Joa?o Paulo NetoSpoken Language Systems Laboratory, L2F ?
INESC-IDDepartment of Computer Science and Engineering,Instituto Superior Te?cnico, Technical University of LisbonR.
Alves Redol, 9 - 2?
?
1000-029 Lisboa, Portugal{fmfm,acbm,mviveiros,joana,pedro,njm,jpn}@l2f.inesc-id.pthttp://www.l2f.inesc-id.ptAbstractOur work in this area started as a re-search project but when L2F joined TecnoVoz,a Portuguese national consortium includingAcademia and Industry partners, our focusshifted to real-time professional solutions.The integration of our domain-independentSpoken Dialogue System (SDS) frameworkinto commercial products led to a majorreengineering process.This paper describes the changes that theframework went through and that deeply af-fected its entire architecture.
The communi-cation core was enhanced, the modules inter-faces were redefined for an easier integration,the SDS deployment process was optimizedand the framework robustness was improved.The work was done according to software en-gineering guidelines and making use of designpatterns.1 IntroductionOur SDS framework was created back in2000 (Moura?o et al, 2004), as the result ofthree graduation theses (Cassaca and Maia, 2002;Moura?o et al, 2002; Viveiros, 2004), one of whichevolved into a masters thesis (Moura?o, 2005).The framework is highly inspired on the TRIPSarchitecture (Allen et al, 2000): it is a frame-baseddomain-independent framework that can be usedto build domain-specific dialogue systems.
Everydomain is described by a frame, composed bydomain slots that are filled with user requests.When a set of domain slots is filled, a service isexecuted.
In order to do so, the dialogue systeminteracts with the user until enough information isprovided.From the initial version of the framework twosystems were created for two different domains: abus ticket vending system, which provides an in-terface to access bus timetables; and a digital vir-tual butler named Ambro?sio that controls home de-vices, such as TVs (volume and channel), acclima-tization systems, and lights (switch on/off and in-tensity) through the X10 electrical protocol and theIrDA (Infrared Data Association) standard.
Since2003, Ambro?sio is publicly available in the ?Houseof the Future?1, on the Portuguese Telecommunica-tions Museum2.As proof of concept, we have also built a pro-totype system that helps the user while performingsome task.
This was tested for the cooking domainand the automobile reparation domain.After the successful deployment of the mentionedsystems, we began developing two new automatictelephone-based systems: a home banking systemand a personal assistant.
These are part of a projectof the TecnoVoz3 consortium technology migrationto enterprises.
To answer to the challenges that thecreation of those new systems brought to light, thefocus of the framework shifted from academic issuesto interactive use, real-time response and real users.Since our goal was to integrate our SDS frameworkinto enterprise products, we started the developmentof a commercial solution.
Nevertheless, despite this1http://www.casadofuturo.org/2http://www.fpc.pt/3http://www.tecnovoz.pt/68new focus, we wanted to maintain the research fea-tures of the framework.
This situation led to deepchanges in the framework development process: asmore robust techniques needed to be used to ensurethat new systems could easily be created to respondto client requests.
From this point of view, the goalof the reengineering process was to create a frame-work that provides means of rapid prototyping simi-lar to those of Nuance4, Loquendo5 or Artificial So-lutions6.Also, the new systems we wanted to built carrieda significant change on the paradigm of the frame-work: while in the first systems the effects of users?actions were visible (as they could watch the lightsturning on and off, for instance) and a virtual agentface provided feedback, in the new scenarios com-munication is established only through a phone and,being so, voice is the only feedback.The new paradigm was the trigger to this pro-cess and whenever a new issue needed to be solvedthe best practices in similar successful systems werestudied.
Not all can be mentioned.
The most rele-vant are described in what follows.As it was previously mentioned, TRIPS wasthe main inspiration for this framework.
It is awell known and stable architecture that has provenits merits in accommodating a range of differenttasks (Allen et al, 2007; Jung et al, 2007).
Themain modules of the system interact through aFacilitator (Ferguson et al, 1996), similar to theGalaxy HUB7 (Polifroni and Seneff, 2000) withKQML (Labrou and Finin, 1997) messages.
How-ever, in TRIPS, the routing task is decentralizedsince the sender modules decide where to send itsmessages.
At the same time, any module can sub-scribe to selected messages through the Facilitatoraccording to the sender, the type of message or itscontents.
This mechanism makes it easier to inte-grate new modules that subscribe the relevant mes-sages without the senders?
acknowledgment.Like our framework, the CMU Olympus is a clas-sical pipeline dialog system architecture (Bohus et4http://www.nuance.com/5http://www.loquendo.com/6http://www.artificial-solutions.com/7The Galaxy Hub maintains connections to modules (parser,speech recognizer, back-end, etc.
), and routes messages amongthem.
See http://communicator.sourceforge.net/al., 2007) where the modules are connected via aGalaxy HUB that uses a central hub and a set ofrules for relaying messages from one component tothe other.
It has the three usual main blocks: Lan-guage Understanding, through Phoenix parser andHelios confidence-based annotation module, Dia-logue Management, through RavenClaw (Raux etal., 2005; Bohus, 2004), and Language Generation,through Rosetta.
Recognition is made with Sphinxand synthesis with Theta.
The back-end applicationsare directly connected to the HUB through an in-cluded stub.Some of our recent developments are also inspiredin Voice XML8, in an effort to simplify the frame-work parameterization and development, required inthe enterprise context.
Voice XML provides stan-dard means of declarative configuration of new sys-tems reducing the need of coding to the related de-vices implementation (Nyberg et al, 2002).Our reengineering work aimed at: i) making theframework more robust and flexible, enhancing thecreation of new systems for different domains; ii)simplifying the system?s development, debug anddeployment processes through common techniquesfrom software engineering areas, such as design pat-terns (Gamma et al, 1994; Freeman et al, 2004).By doing this, we are trying to promote the de-velopment and deployment of new dialogue systemswith our framework.This paper is organized as follows: Section 2presents the initial version of the framework; Sec-tion 3 describes its problems and limitations, as wellas the techniques we adopted to solve them; Sec-tion 4 describes a brief empirical evaluation of thereengineering work; finally, Section 5 closes the pa-per with conclusions and some remarks about futurework directions.2 Framework descriptionThis section briefly presents our architecture, at itsinitial stage, before the reengineering process.
Wealso introduce some problems of the initial architec-ture, as they will be later explained in the next sec-tion.8http://www.w3.org/Voice/692.1 Domain ModelThe domain model that characterizes our frameworkis composed by the following entities:Domain, which includes a frame realization andgeneralizes the information about several de-vices;Frame, which states the subset of slots to fill for agiven domain;Device, which represents a real device with severalstates and services.
Only one active state exists,at each time, for each device;State, which includes a subset of services that areactive when the state is active;Service, which instantiates a defined frame andspecifies a set of slots type of data and restric-tions for that service.When developing a new domain all these entitieshave to be defined and instantiated.2.2 Framework architectureOur initial framework came into existence as the re-sult of the integration of three main modules:Input/Output Manager, that controls an AutomaticSpeech Recognition (ASR) module (Meinedo,2008), a Text-To-Speech (TTS) module (Pauloet al, 2008) and provides a virtual agentface (Viveiros, 2004);Dialogue Manager, that interprets the user inten-tions and generates output messages (Moura?oet al, 2002; Moura?o, 2005);Service Manager, that provides a dialogue man-ager interface to execute the requested services,and an external application interface throughthe device concept (Cassaca and Maia, 2002).2.3 Input/Output ManagerThe Input/Output Manager (IOManager) controls anASR module and a TTS module.
It also integratesa virtual agent face, providing a more realistic in-teraction with the user.
The synchronization be-tween the TTS output and the animated face is doneby an audio?face synchronization manager, whichgenerates the visemes9 for the corresponding TTSphonemes information.
The provided virtual agentface is based on a state machine that informs, amongothers, when the system is ?thinking?
or when whatthe user said was not understood.Besides, a Graphical User Interface (GUI) existsfor text interactions between the user and the system.Although this input interface is usually only used fortest and debug proposes (as it skips the ASR mod-ule), it could be used in combination with speech,if requested by any specific multi-modal system im-plementation.The IOManager provides an interface to the Di-alogue Manager that only includes text input andoutput functions.
However, the Dialogue Managerneeds to rely on other information, such as the in-stant the user starts to speak or the moment a syn-thesized sentence ends.
These events are useful, forinstance, to set and trigger for user input timeouts.2.4 Dialogue ManagerThe architecture of the Dialogue Manager (Figure 1)has seven main modules: a Parser, an InterpretationManager, a Task Manager, a Behavior Agent, a Gen-eration Manager, a Surface Generation and a Dis-course Context.HUBSurfaceGeneration[16, 19]GenerationManager[13, 15]DiscourseContext[4, 14]Input/OutputManager[1, 20]ServiceManager[7,10,18]BehaviorAgent[12]Parser[2]InterpretationManager[3, 5, 8, 11]TaskManager[6, 9, 17]ExternalApplicationsFigure 1: Dialogue Manager architecture through thecentral HUB.
Numbers show the execution sequence.9A viseme is the visual representation of a phoneme and isusually associated with muscles positioned near the region ofthe mouth (Neto et al, 2006).70These modules have specific code from the im-plementations of the two first systems (the bus ticketvending system and the butler).
When building ageneric dialogue framework, this situation turns outto be a problem since domain-dependent code wasbeing used that was not appropriate in new systems.Also, the modules have many code for HUBmessag-ing, which makes debug and development harder.2.5 Service ManagerThe Service Manager (Figure 2) was initially devel-oped to handle all domain specific information.
Ithas the following components:Service Manager Galaxy Server, that works like aHUB stub, managing the interface with the de-vices and the Dialogue Manager;Device Manager, that stores information related toall devices.
This information is used by the Di-alogue Manager to find the service that shouldbe executed after an interaction;Access Manager, that controls the user access tosome devices registered in the system;Domain Manager, that stores all the informationabout the domains.
This information is used tobuild interpretations and for the language gen-eration process;Object Recognition Manager, that recognizes thediscourse objects associated with a device;Device Proxy, abstracts all communication withthe Device Core and device specific informa-tion protocol.
This is done through the VirtualProxy design patternDevice Core, that implements the other part of thecommunication protocol with the Service Man-ager and the Dialogue Manager.Since the Service Manager interface is shared bythe Dialogue Manager and all devices, a device canexecute a service that belongs to another device oreven access to internal Dialogue Manager informa-tion.ExternalApplicationHUBDatabaseServiceManagerGalaxyServerDomainManagerDeviceManagerAccessManagerObjectRecognitionManagerDeviceProxyDevice CoreDevicespecificImplementationFigure 2: Service Manager architecture.3 Reengineering a frameworkWhen the challenge of building two new SDSs onour framework appeared, some of the mentioned ar-chitectural problems were highlighted.
A reengi-neering process was critical.
A starting point for thereengineering process was needed, even though thatdecision was not clear.By observing the framework?s data and controlflow, we noticed that part of the code in the differentmodules was related with HUB messaging, namelythe creation of messages to send, and the conversionof received messages into internal structures (mar-shalling).
A considerable amount of time was spentin this task that was repeated across the framework.Based on that, we decided that the first step shouldbe the analysis of the Galaxy HUB communicationflow and the XML structures used to encode thosemessages, replacing them with more appropriate andefficient protocols.3.1 Galaxy HUB and XMLThe Galaxy HUB protocol is based in generic XMLmessages.
That allows new modules to be easilyplugged into the framework, written in any program-ming language, without modifying any line of code.However, we needed to improve the developmentand debugging processes of the existing modules,71and having a time consuming task that was repeatedwhenever two modules needed to communicate wasa serious drawback.Considering this, we decided to remove theGalaxy HUB.
This decision was enforced by thefact that all the framework modules were writtenin the Java programming language, which alreadyprovides direct invocations and objects serializationthrough Java Remote Method Invocation (RMI).The major advantage associated with the use ofthis protocol, was the possibility of removing all theXML-based messaging that repeatedly forced thecreation and interpretation of generic messages inexecution time.
With the use of RMI, these struc-tures were replaced by Java objects that are inter-changed between modules transparently.
Not onlyRMI is native to Java.This was not a simple task, as the team that wasresponsible for this process was not the team whooriginally developed the framework.
Because ofthis, the new team lacked familiarity with the overallcode structure.
In order to reduce the complexity ofthe process, it was necessary to create a proper in-terface for each module removing the several entrypoints that each one had.
To better understand thereal flow and to minimize the introduction of newbugs while refactoring the code we made the infor-mation flow temporarily synchronous.The internal structure of each module was re-designed and every block of code with unknownfunctionality was commented out.This substitution improved the code quality andboth the development and the debugging processes.We believe that it also improved the runtime effi-ciency of the system, even though no evaluation ofthe performance was made.
Empirically, we can saythat in the new version of the system less time isneeded to complete a task since no explicit conver-sion of the objects into generic messages is made.3.2 Domain dependent codeThe code of the Parser, the Interpretation Managerand the Surface Generation modules had domain de-pendent code and it was necessary to clean it out.Since we were modifying the Galaxy HUB code,we took the opportunity and redesigned that code inthe aforementioned modules to make it more generic(and, consequently less domain dependent).
Beingso, the code cleaning process took place while theGalaxy HUB was being replaced.We were unable to redesign the domain dependentcode.
Cases like hard-coded word replacement, usedboth to provide a richer interpretation of the user ut-terances and to allow giving a natural response to theuser.
In such cases, we either isolated the domainspecific portions of the code or deleted them, even ifthe interpretation or generation processes were de-graded.
It can be recovered in the future by includ-ing the domain specific knowledge in the dynamicconfiguration of the Interpretation and Generationmanagers as suggested by Paulo Pardal (2007)An example of this process is the split-ting of the parser specific code into severalparsers: some domain-dependent, some domain-independent, while creating a mechanism to com-bine them in a configurable chain (through a pipesand filters architecture).
This allows the buildingof smaller data-type specific parsers that the Inter-pretation Manager selects to achieve the best pars-ing result, according to the expectations of the sys-tem (Martins et al, 2008).
These expectations arecreated according to the assumption that the userwill follow the mixed-initiative dialogue flow thatthe system ?suggests?
during its turn in the interac-tion.
The strategy also handles those cases were theuser does not keep up with those expectations.3.3 Dialogue Manager InterfaceThe enhancements introduced at the IOManagerlevel augmented the amount of the information in-terchanged between this module and the DialogueManager, as it could deal with more data comingfrom the ASR, TTS and the virtual agent face.However, the Dialogue Manager Interface wascontinuously evolving and changing.
This lack ofstability made it harder to maintain the successiveversions completely functional during the process.Following the software engineering practices, andusing the Template Method design pattern, westarted with the definition of modules interfaces andonly after that the implementation code of the meth-ods was written.
This allows the simultaneous de-velopment of different modules that interact.
Onlywhen some conflict is reported, the parallel develop-ment processes need to be synchronized resulting inthe possible revision of the interfaces.
Even when72an interface was not fully supported by the DialogueManager, it was useful since it lead the IOManagercontinuous improvements and allowed simultaneousdevelopments in the Dialogue Manager.In order to ease the creation of this interface,an Input/Output adapter was created.
This adaptermakes the conversion of the information sent by theIOManager to the Dialogue Manager specific for-mat.
Having this, when the information exchangedwith the Dialogue Manager changes, the DialogueManager Interface does not need any transforma-tion.
In addition, the Dialogue Manager is able tointeract with other Input/Output platforms withoutthe need of internal changes.This solution for the interfaces follows the Facadedesign pattern, which provides an unique interfacefor several internal modules.3.4 File system reorganizationWhen the different dialogue systems were fully im-plemented in the new version of the framework, wewanted to keep providing simultaneous access to theseveral available domains during the same executionof the system.In fact, in our initial framework it was alreadypossible to have several different domains running inparallel.
When an interaction is domain ambiguous,the system tries to solve the ambiguity by asking theuser which domain is being referred.User: LigarSystem: O que deseja fazer:ligar um electrodome?sticoou fazer um telefonema?Figure 3: Example of a domain ambiguous interactionwhile running with two different running domains.
InPortuguese ?ligar?
means ?switch on?
and ?call?Consider the example on Figure 3: an user inter-action with two different running domains, the but-ler and the personal digital assistant.
In Portuguese,the verb ?ligar?
means ?to switch something on?
or?to make a phone call?.
Since there are two runningdomains, and the user utterance is domain ambigu-ous, the systems requests for a disambiguation in itsnext turn (O que deseja fazer), by asking if the userwants to switch on a home device (ligar um elec-trodome?stico) or make a phone call (fazer um tele-fonema).While using this feature, it came to our attentionthat it was necessary to reorganize the file system:the system folder held the code of all domains, andevery time we needed to change a specific domainproperty, we had hundreds of properties files to lookat.
This situation was even harder for novice frame-work developers, since it was difficult to find ex-actly which files needed to be modified in that densefile system structure.
Moreover, the ASR, TTS andvirtual agent configurations were shared by all do-mains.To solve this problem we applied the conceptof system?instance.
A system?instance has one ormore domains.
When the system starts, it receivesa parameter that specifies which instance we wantto run.
The configuration of the existing instancesis split across different folders.
A library folderwas created and organized in external libraries (li-braries from an external source), internal libraries(library developed internally at our laboratory) andinstance specific libraries (specific libraries of asystem?instance).With this organization we improved the version-ing management and updates.
The conflicting con-figuration was removed since each system?instancehas now its own configuration.
The configurationfiles are organized and whenever we need to delivera new version of a system?instance, we simply needto select the files related with it.3.5 Service Manager redesignThe Service Manager code had too many dependen-cies with different modules.
The Service Managerdesign was based on the Virtual Proxy design pat-tern.
However, it was not possible to develop newdevices without creating dependencies on all of theService Manager code, as the Device Core code re-lied heavily on some classes of the Service Manager.This situation created difficulties in the SDSs de-velopment process and affected new developmentssince the Service Manager code needed to be copiedwhenever a Device Core was running in anothercomputer or in a web container.
This is a knownbad practice in software engineering, since the codeis scattered, making it harder to maintain updatedcode in all the relevant locations.It was necessary to split the Service Manager code73for the communication protocol between communi-cation itself and the device specific code.Also, the Service Manager class10 interface wasshared by the DialogueManager and all devices.
Be-ing so, it was possible that a device requested theexecution of a service in other device, as well as toaccess the internal information exchanged betweenthe Service Manager and the Dialogue Manager.Example DeviceDevice CoreDevicespecificImplementationDialogueManagerService ManagerDialogueManagerInterfaceDevicesInterfaceServiceManagerClassAccessManagerDeviceManagerFigure 4: Service Manager architecture.Like we did with the Dialogue Manager, we spec-ified a coherent interface for the different ServiceManager modules, removing the unwanted entrypoints.
The Service Manager class interface wassplit and the Device Manager is now the interfacebetween the Service Manager and the devices (Fig-ure 4).
Also, the Service Manager class interface isonly accessed by the Dialogue Manager.
The classesbetween the Service Manager and the Device imple-mentation were organized in a small library, contain-ing the classes and the Device Core code.
This li-brary is all what is needed to create a new deviceand to connect it to both the Service Manager andthe Dialogue Manager.Finally, we changed the Access Manager to con-trol not only user access to registered devices, butalso the registry of devices in the system.
Thisprevents a device which is running on a specificsystem?instance to be registered in some other run-ning system?instance.
This module changed its po-sition in the framework architecture: now it is be-10The Service Manager Galaxy Server was renamed to Ser-vice Manager.
However, we decided to call it here by ServiceManager class so it will not be mistaken with the Service Man-ager module.tween the Service Manager class and the DeviceManager.3.6 Event ManagerIn the initial stage, when the Galaxy HUB wasremoved, all the communication was made syn-chronous.
After that, to enhance the framework andallowmixed initiative interactions, a mechanism thatprovides asynchronous communication was needed.Also, it was necessary to propagate information be-tween the ASR, TTS, GUI and the Dialogue System,crucial for the error handling and recovery tasks.We came to the conclusion that most of the frame-works deal with these problems by using event man-agement dedicated modules.
Although TRIPS, theframework that initially inspired ours, has an EventManager, that was not available in ours.
The ASRand TTS modules provided already an event-basedinformation propagation, and we needed to imple-ment a dedicated module to make the access to thissort of information simpler.
This decision was en-forced by the existence of a requirement on han-dling events originated by an external Private BrancheXchange (PBX) system, like incoming call andclosed call events.
The PBX system was integratedwith the personal assistant that is available througha phone connection.
SDS.We decided to create an Event Manager in theIOManager.
The Dialogue Manager implements anevent handler that receives events from the EventManager and knows where to deliver them.
Quicklywe understood that the event handler needed to bedependent of the system?instance since the eventsand their handling are different across systems (likea telephone system and kiosk system).
With this inmind, we implemented the event handler module,following the Simple Factory design pattern, by del-egating the events handling to the specific system-instance handler.
If this specific system?instanceevent handler is not specified, the system will usea default event handler with ?generic?
behavior.This developments were responsible for the con-tinuous developments in the IOManager, referred insection 3.3, and occurred at the same time.With this approach, we can propagate and handleall the ASR events, the TTS events, GUI events andexternal applications events.The Event Manager has evolved to a decentral-74ized HUB.
Through this, the sender can set identi-fiers in some events.
These identifiers are used byother modules to identify messages relevant to them.In TRIPS a similar service is provided by the Facil-itator, that routes messages according to the recipi-ents specified by the sender, and following the sub-scriptions that modules can do by informing the Fa-cilitator.
This approach eases the integration of newmodules without changing the existing ones, just bysubscribing the relevant type of messages.3.7 Dialogue Manager distributionCurrently, there are some clients interested in ourframework to create their own SDS.
However, sincethe code is completely written in Java, distributionsare made available through jar files that can be eas-ily decoded, giving access to the source of our code.To avoid this we need to obfuscate the code.Even though obfuscation is an interesting solu-tion, our code used Java?s reflexion in several points.This technique enables dynamic retrieval of classesand data structures by name.
By doing so, it needs toknow the specific name of the classes being reflectedso that the Java class loader knows where to findthem.
Obfuscation, among other things, changesclass names and locations, preventing the Java classloader from finding them.To cope with this additional challenge, the codethat makes use of reflexion was replaced using theSimple Factory design pattern.
This change allowsthe translation of the hard-coded names to the newobfuscated names in obfuscation time.
After that,when some class needs to instantiate one of thoseclasses that used reflection, that instance can be cre-ated through the proper factory.4 EvaluationAlthough a SDS was successfully deployed in ourinitial framework, which is publicly available at aMuseum since 2003, no formal evaluation was madeat that initial time.
Due to this, effective or numericcomparison between the framework as it was beforethe reengineering work and as it is now, is not possi-ble.
Previous performance parameters are not avail-able.
However, some empirical evaluation is pos-sible, based on generic principles of Software (re)Engineering.In the baseline framework, each improvement,like modifications in the dialogue flow or at theparser level, was a process that took more than twoweeks of work, of two software engineers.
With thenew version, similar changes are done in less thanone week, by the same team.
This includes internalimprovements, and external developments made byentities using the system.
The system is more stableand reliable now: in the beginning, the system hadan incorrect behavior after some hours of runningtime; currently with a similar load, it runs for morethan one month without needing to be restarted.This is one great step for the adoption of ourframework.
This stability, reliability and develop-ment speed convinced our partners to create theirSpoken Dialogue Systems with our framework.5 Conclusions and Future WorkCurrently, our efforts are concentrated on interpreta-tion improvement and on error handling and recov-ery (Harris et al, 2004).Currently, we are working on representing emo-tions within the SDS framework.
We want to testthe integration, and how people will react to a sys-tem with desires and moods.The next big step will be the inclusion of an ef-ficient morpho-syntactic parser which generates andprovides more information (based on speech acts) tothe Interpretation Manager.Another step we have in mind is to investigatehow the events and probabilistic information that theASR module injects in the system can be used to re-cover recognition errors.The integration of a Question-Answering (QA)system (Mendes et al, 2007) in this framework isalso in our horizon.
This might require architecturalchanges in order to bring together the interpretationand disambiguation features from the SDS with theInformation Retrieval (IR) features of QA systems.This would provide information-providing systemsthrough voice interaction (Mendes, 2008).Another ongoing work is the study of whetherontologies can enrich a SDS.
Namely, if they canbe used to abstract knowledge sources allowing thesystem to focus only on dialogue phenomena ratherthan architecture adaptation, when including newdomains (Paulo Pardal, 2007).75AcknowledgmentsThis work was partially funded by TECNOVOZ,PRIME National Project number 03/165.It was also partially funded by DIGA, projectPOSI/PLP/14319/2001 of Fundac?a?o para aCie?ncia e Tecnologia (FCT).Joana Paulo Pardal is supported by a PhD fellow-ship from FCT (SFRH/BD/30791/2006).ReferencesJames Allen, Donna Byron, Myroslava Dzikovska,George Ferguson, Lucian Galescu, and Amanda Stent.2000.
An architecture for a generic dialogue shell.Natural Language Engineering, Cambridge Univer-sity Press, 6.James Allen, Nathanael Chambers, George Ferguson,Lucian Galescu, Hyuckchul Jung, Mary Swift, andWilliam Taysom.
2007.
Plow: A collaborative tasklearning agent.
In Proc.
22th AAAI Conf.
AAAI Press.Dan Bohus, Antoine Raux, Thomas Harris, Maxine Es-kenazi, and Alexander Rudnicky.
2007.
Olympus:an open-source framework for conversational spokenlanguage interface research.
In Workshop on Bridgingthe Gap: Academic and Industrial Research in DialogTechnology, HLT-NAACL.Dan Bohus.
2004.
Building spoken dialog systems withthe RavenClaw/Communicator architecture.
Presenta-tion at Sphinx Lunch Talk, CMU, Fall.Renato Cassaca and Rui Maia.
2002.
Assistente electro?-nica.
Instituto Superior Te?cnico (IST), UniversidadeTe?cnica de Lisboa (UTL), Graduation Thesis.George Ferguson, James Allen, Brad Miller, and EricRingger.
1996.
The design and implementation ofthe TRAINS-96 system: A prototype mixed-initiativeplanning assistant.
Technical Report TN96-5.Elisabeth Freeman, Eric Freeman, Bert Bates, and KathySierra.
2004.
Head First Design Patterns.
O?Reilly.Erich Gamma, Richard Helm, Ralph Johnson, and JohnVlissides.
1994.
Design Patterns: Elements ofReusable Object-Oriented Software.
Addison-WesleyProfessional Computing Series.Thomas Harris, Satanjeev Banerjee, Alexander Rud-nicky, June Sison, Kerry Bodine, and Alan Black.2004.
A research platform for multi-agent dialoguedynamics.
In 13th IEEE Intl.
Workshop on Robot andHuman Interactive Communication (ROMAN).Hyuckchul Jung, James Allen, Nathanael Chambers, Lu-cian Galescu, Mary Swift, and William Taysom.
2007.Utilizing natural language for one-shot task learning.Journal of Logic and Computation.Yannis Labrou and Tim Finin.
1997.
A proposal for anew KQML specification.
Technical Report CS-97-03, Computer Science and Electrical Engineering De-partment, Univ.
of Maryland Baltimore County.Filipe M. Martins, Ana Mendes, Joana Paulo Pardal,Nuno J. Mamede, and Joa?o Paulo Neto.
2008.
Us-ing system expectations to manage user interactions.In Proc.
PROPOR 2008 (to appear), LNCS.
Springer.Hugo Meinedo.
2008.
Audio Pre-processing and SpeechRecognition for Broadcast News.
Ph.D. thesis, IST,UTL.Ana Mendes, Lu?
?sa Coheur, Nuno J. Mamede, Lu?
?sRoma?o, Joa?o Loureiro, Ricardo Daniel Ribeiro, Fer-nando Batista, and David Martins de Matos.
2007.QA@L2F@QA@CLEF.
In Cross Language Evalua-tion Forum: Working Notes - CLEF 2007 Workshop.Ana Mendes.
2008.
Introducing dialogue in a QA sys-tem.
In Doctoral Symposium of 13th Intl.
Conf.
Apps.Nat.
Lang.
to Information Systems, NLDB (to appear).Ma?rcio Moura?o, Pedro Madeira, and Miguel Rodrigues.2002.
Dialog manager.
IST, UTL, Graduation Thesis.Ma?rcio Moura?o, Renato Cassaca, and Nuno J. Mamede.2004.
An independent domain dialogue systemthrough a service manager.
In EsTAL, volume 3230of LNCS.
Springer.Ma?rcio Moura?o.
2005.
Gesta?o e representac?a?o de do-m?
?nios em sistemas de dia?logo.
Master?s thesis, IST,UTL.Joa?o Paulo Neto, Renato Cassaca, Ma?rcio Viveiros, andMa?rcio Moura?o.
2006.
Design of a Multimodal InputInterface for a Dialogue System.
In Proc.
PROPOR2006, volume 3960 of LNCS.
Springer.Eric Nyberg, Teruko Mitamura, and Nobuo Hataoka.2002.
DialogXML: extending Voice XML for dy-namic dialog management.
In Proc.
2th Int.
Conf.on Human Language Technology Research.
MorganKaufmann Publishers Inc.Se?rgio Paulo, Lu?
?s C. Oliveira, Carlos Mendes, Lu?
?sFigueira, Renato Cassaca, Ce?u Viana, and Helena Mo-niz.
2008.
DIXI - A Generic Text-to-Speech Systemfor European Portuguese.
In Proc.
PROPOR 2008 (toappear), LNCS.
Springer.Joana Paulo Pardal.
2007.
Dynamic use of ontologies indialogue systems.
In NAACL-HLT Doctoral Consor-tium.Joseph Polifroni and Stephanie Seneff.
2000.
GALAXY-II as an architecture for spoken dialogue evaluation.
InProc.
2nd Int.
Conf.
Language Resources and Evalua-tion (LREC).Antoine Raux, Brian Langner, Dan Bohus, Alan Black,and Maxine Eskenazi.
2005.
Let?s go public!
tak-ing a spoken dialog system to the real world.
In Proc.INTERSPEECH.Ma?rcio Viveiros.
2004.
Cara falante ?
uma interface vi-sual para um sistema de dia?logo falado.
IST, UTL,Graduation Thesis.76
