Interactive Incremental Chart ParsingMats WirdnDepartment of Computer and Information ScienceLinkSping UniversityS-58183 LinkSping, Swedenmgw@ida.liu.seAbst ractThis paper presents an algorithm for incrementalchart parsing, outlines how this could be embed-ded in an interactive parsing system, and discusseswhy this might be useful.
Incremental parsing heremeans that input i8 analysed in a piecemeal fash-ion, in particular allowing arbitrary changes of previ-ous input without exhaustive reanalysis.
Interactiveparsing means that the analysis process is promptedimmediately at the onset of new input, and possiblythat the system then may interact with the user inorder to resolve problems that occur.
The combina-tion of these techniques could be used as a parsingkernel for highly interactive and ~reactive" natural-language processors, such as parsers for dialoguesystems, interactive computer-aided translation sys-tems, and language-sensitive text editors.
An  incre-mental chart parser embodying the ideas put for-ward in this paper has been implemented, and anembedding of this in an interactive parsing systemis near completion.1 Backgroundand Introduction1.1 The Prob lemIdeally, a parser for an interactive natural-languagesystem ought to analyse input in real time in such away that the system produces an analysis of the in-put while this is being received.
One aspect of thisis that the system should be able to gkeep up ~ withThis research has been supported by the National SwedishBoard for Technical Development.
The system is imple-mented on machines donated by the Xerox Corporationthrough their University Grants Program.I would like to thank several people for fruitful discussionson the topics of this paper, in particular Lars Ahrenberg (alsofor commenting on drafts), Bernt Nilsson, and Peter Fritzson;furthermore Nile D~Ibiick, Arne JSnsson, Magnus Merkel,Henry Thompson, and an anonymous referee.
In addition, Iwould like to thank Ulf Dahl~n, Ass Detterfelt, Mikael Karle-son, Per Larsee, Jukka Nylund, and Michael Spicar for imple-menting (the interactive portion of) LIPS.new input that, piece by piece, is entered from leftto right.
Another aspect is that it ought to be ableto keep up also with piecemeal changes of previousinput.
For example, in changing one word in the be-ginning of some utterance(s), one would not wantall the input (either from the beginning or from thechange point) to be completely reanalysed.
Fromthe perspective of efficiency as well as of modellingintelligent behaviour, the amount of processing re-quired to analyse an update ought to be somehowcorrelated with the difficulty of this update.
Thus,a necessary (but not sufficient) condition for realiz-ing a real-time parsing system as suggested above isan interactive and incremental parsing system.
Thegoal of this paper is to develop a basic machineryfor incremental chart parsing and to outline how thiscould be embedded in an interactive parsing system.1.2 Incrementa l  Pars ingThe word "incremental ~ has been used in two dif-fering senses in the (parsing) literature.
The firstsense stresses that input should be analysed in apiecemeal fashion, for example Bobrow and Webber(1980), Mellish (1985), Pulman (1085, 1987), Hirst(1987), Haddock (1987).
According to this view, anincremental parser constructs the analysis of an ut-terance bit by bit (typically from left to right), ratherthan in one go when it has come to an end.The other sense of "incremental" stresses thenecessity of e~ciently handling arbitrary changeswithin current input.
Thus, according to this view,an incremental parser should be able to efficientlyhandle not only piecemeal additions to a sentence,but, more generally, arbitrary insertions and dele-tions in it.
This view of incremental parsing is typi-cal of research on interactive programming environ-ments, e.g.
Lindstrom (1970), Earley and Caisergues(1972), Ghezzi and Mandrioli (1979, 1980), Reps andTeitelbaum (1987).As indicated above, we are here interested in thelatter view, which we summarize in the followingworking definition.- 241 -Incremental parser.
A parser capable of handlingchanges of previous input while expending anamount of effort which is proportional to thecomplexity of the changes.
1It should be pointed out that we are here limit-ing ourselves to a machinery for incremental parsingas opposed to incremental interpretation.
In otherwords, the derivation of an utterance here takesinto account only %ontext-free" (lexical, syntactic,compositional-semantic) information obtained fromgrammar  and dictionary.
Nevertheless, I believe thatthis framework may be of some value also when ap-proaching the more difficult problem of incrementalinterpretation.1 .3  In teract ive  Pars ingWe adopt the following working definition.Interactive parser.
(Synonym: on-line parser.)
Aparser which monitors a text-input process,starting to parse immediately at the onset ofnew input, thereby achieving enhanced effi-ciency as well as a potential for dynamic im-provement of its performance, for example bypromptly reporting errors, asking for clarifica-tions, etc.
2Within the area of programming environments,(generators for) language-based editors have beendeveloped that make use of interactive (and incre-mental} parsing and compilation to perform pro-gram analysis, to report errors, and to generate codewhile the program is being edited, for example Men-tor, Gandalf, and the Synthesizer Generator (Repsand Teitelbanm 1987).Within natural-language processing, Tomita (1985)and Yonezawa and Ohsawa (1988) have reportedparsers which operate on-line, but, incidentally, notincrementally in the sense adopted here.
3IThis definition is formed partly in analogy with a defini-tion of "incremental compilation" by Earley and Caizergues(1972:1040).
We use "complexity" instead of "size" becausedifferent updates of the same size may cause differing process-ing efforts depending on the degree of grammatical complexity(ambiguity, context-sensitiveness) constraining the updates inquestion.21ncidentally, interactive parsing could be seen as one ex-ample of a general trend towards imrnatiate computation (Repsand Teitelbaum 1987:31), also manifest in applications uchas WYSIWYG word processing and spreadsheet programs,and sparked off by the availability of personal workstationswith dedicated processors.SThe user may delete input from right to left, causing thesystems to Uunparsen this input.
This means that if the userwants to update some small fragment in the beginning of asentence, the system has to reparse xhaustively from thisupdate and on.
(Of course, in reality the user has to firstbackspace and then retype verything from the change.
)1.4 Out l ine of PaperSection 2 presents an algorithm for incremental chartparsing.
Section 3 discusses ome additional aspectsand alternative strategies.
Section 4 gives a briefoutline of the combined interactive and incrementalparsing system, and section 5 summarizes the con-clusions.2 Incremental Chart Parsing2.1 Char t  Pars ingThe incremental parser has been grounded in achart-parsing framework (Kay 1980, Thompson1981, Thompson and Ritchie 1984) for the follow-ing reasons:?
chart parsing is an efficient, open-ended, wellunderstood, and frequently adopted techniquein natural-language processing;?
chart parsing gives us a previously unexploredpossibility of embedding incrementality at a lowcost.2.2 Edge DependenciesThe idea of incremental chart parsing, as put for-ward here, is based on the following observation:The chart, while constituting a record of partialanalyses (chart edges), may easily be provided withinformation also about the dependencies betweenthose analyses.
This is just what we need in in-cremental parsing since we want to propagate theeffects of a change precisely to those parts of theprevious analysis that, directly or indirectly, dependon the updated information.In what ways could chart edges be said to dependon each other?
Put simply, an edge depends uponanother edge if it is formed using the latter edge.Thus, an edge formed through a prediction step de-pends on the (one) edge that triggered it.
4 Likewise,an edge formed through a combination 5 depends onthe active-inactive edge pair that generated it.
Ascanned edge, on the other hand, does not dependupon any other edge, as scanning can be seen as akind of initialization of the chart, eIn order to account for edge dependencies we asso-ciate with each edge the set of its immediate source4In the case of an initial top-down prediction, the sourcewould be non-existent.SThe ~raldeter operation in Earley (1970); the ~ndarnentadrule in Thompson (1981:2).sit might be argued that a dependency should be estab-lished also in the case of an edge being proposed but rejected(owing to a redundancy test) because it already exists.
How-ever, as long as updates affect all preterminal edges extendingfrom a vertex, this appears not to be crucial.- 242 -edges (~back pointers").
This information could beused to derive the corresponding sets of dependentedges (gforward pointers ") that we are interested in.For example, when a word in the previous input hasbeen deleted, we want to remove all edges whichdepend on the preterminal (lexical) edge(s) corre-sponding to this word, as well as those preterminaledges themselves.Formally, let P be a binary dependency relationsuch that e P e ~ if and only if e t is a dependant ofe, i.e., e' has been formed (directly) using e. If D*is the reflexive transitive closure of P, all edges e"should be removed for which e D* e" holds, i.e., alledges which directly or indirectly depend on e, aswell as e itself.
In addition, we are going to makeuse of the transitive closure of D, D +.The resulting style of incremental parsing resem-bles truth (or reason) maintenance, in particularATMS (de Kleer 1986).
A chart edge here corre-sponds to an ATMS node, a preterminal edge corre-sponds to an assurnption ode, the immediate sourceinformation of an edge corresponds to a justifica-tion, the dependency relation D* provides informa-tion corresponding to ATMS labels, etc.2.3  Techn ica l  Preliminaries2.3.1 The  Char tThe chart is a directed graph.
The nodes, or ver-tices, vl, .
.
.
,  Vn+l correspond to the positions ur-rounding the words of an n-word sentence t01 .. ?
ton.A pair of vertices vl,vy may be connected by arcs,or edges, bearing information about (partially) anal-ysed constituents between v~ and vy.
We will takean edge to be a tuple(s, t, X0 --* a.#, D, E)starting from vertex v~ and ending at vertex vt withdotted rule X0--* a .~/  a dag D (cf.
section 2.3.3),and the set of immediately dependent edges, E. sIn order to lay the ground for easy splitting andjoining of chart fragments, we will take a vertex toconsist of three parts, (L, Aioop, R), left, middle, andright.
L and R will have internal structure, so thatthe full vertex structure will come out likeThe left part, (Ain, Ii~), consists of the incomingactive and inactive edges which will remain withthe left portion of the chart when it is split dueVA dotted rule Xo --* a.~ corresponds to an (active) X0edge containing an analysis of constituent(s) a, requiring con-stituent(s) ~in order to yield an inactive dge.Sin other words, the set E of an edge e consists of all edgesel for which e P el holds.to some internal sentence-editing operation.
Cor-respondingly, the right part, (Aost, Io,t), consists ofthe outgoing active and inactive edges which willremain with the right portion of the chart.
Themiddle part, Aioop, consists of the active loopingedges which, depending on the rule-invocation strat-egy, should remain either with the left or the rightportion of the chart (cf.
section 3.1).We will make use of dots for qualifying within el-ements of tuples.
For example, e.s will stand for thestarting vertex of edge e. Likewise, vi.L will standfor the set of edges belonging to the left half of vertexnumber i, and vi.Ai~ will denote the set of its activeincoming edges.
In addition, we will use vi.Po~t asa shorthand for the set of inactive outgoing edges atvi which are also preterminal (lexical).2.3.2 Ed i t ing  Operat ionsIn general, parsing could be seen as a mapping froma sentence to a structure representing the analysisof the sentence - -  in this case a chart.
Incrementalparsing requires a more complex mappingF( .
,  ~, r, Co) ~ clfrom an edit operation ~7, a pair of cursor positions ~;,a sequence of words r (empty in the case of deletion),and an initial chart Co to a new chart cl (and usinga grammar and dictionary as usual).We are going to assume three kinds of editing op-eration, insert, delete, and replace.
Furthermore, weassume that every operation applies to a continuoussequence of words tot.. ,  tot, each of which maps toone or several preterminal edges extending from ver-tices vt, ?
.
.
,  vr, respectively.
?Thus, ~ may here take the values insert, delete,or replace; ~ is a pair of positions l, r such that thesequence of positions l, .
.
.
,  r map directly to ver-tices vi, .
.
.
,  W, and r is the corresponding sequenceof words wt .
.
.
tot.In addition, we will make use of the constant 6 =r - l + 1, denoting the number of words affected bythe editing operation.2.8 .3  Grammat ica l  Formal i smIn the algorithm below, as well as in the actual im-plementation, we have adopted a unification-basedgrammatical formalism with a context-free base,PATR (Shieber et al 1983, Shieber 1986), becausethis seems to be the best candidate for a lingua/ranca in current natural-language processing.
How-ever, this formalism here shows up only within theedges, where we have an extra dag element (D), andwhen referring to rules, each of which consists of a?Character editing is processed by the scanner; cf.
section3.3.- 243  -pair IX0 ~ ~, D) of a production and a dag.
Inthe dag representation of the rule, we will store thecontext-free base under cat features as usual.
Weassume that the grammar is cycle-free.2.4 An A lgor i thmfor Incrementa l  Char t  Pars ing2.4.1 In t roduct ionThis section states an algorithm for incrementalchart parsing, divided into update routines, subrou-tines, and an underlying chart parser.
It handlesupdate of the chart according to one edit operation;hence, it should be repeated for each such opera-tion.
The underlying chart parser specified in theend of section 2.4.2 makes use of a bottom-up rule-invocation strategy.
Top-clown rule invocation willbe discussed in section 3.1.2.4.2 Incrementa l  Char t -Pars ing  A lgor i thmInput :  An edit operation ~7, a pair of vertex num-bers l, r, a sequence of words tot ..- t0r, and a chartco.
We assume that chart co consists of verticesul, .
.
.
,  v~a,t, where last ~_ 1.
We furthermore as-sume the constant 6 = r - l + 1 to be available.Output :  A chart cl.Method:  On the basis of the input, select and exe-cute the appropriate update routine below.Update  Rout inesInser t l :  Insertion at right end of Cofor  i :-- l, .
.
.
,  r do  Scan(w~);last := last + 8;RunChar t .This case occurs when 6 words wt""  tv~ havebeen inserted at the right end of previous input(i.e., l = last).
This is the special case corre-sponding to ordinary left-to-right chart parsing,causing the original chart co to be extended 6steps to the right.Deletel :  Deletion at right end of cofo r i  :-- l, .
.
.
,  rdoVe: e E vi.Po~t RemoveEdges InD*  (e);last := l as t -  6.This case occurs when 5 words w~... t0r havebeen deleted up to and including the right endof previous input (i.e., r = last - 1).
It is han-dled by removing the preterminal edges corre-sponding to the deleted words along with alltheir dependent edges.Delete2:  Deletion before right end of cofor i : -  l, .
.
.
,  r doVe: e E ~.Po~t RemoveEdges InD*(e) ;MoveVer tex /R ightHa l f ( r  + 1, l, -5 ) ;fo r i  : - - l+ l to  l as t -6  doMoveVer tex  (i + 5, i, -5 ) ;last := las t -  5;RunChar t .This case occurs when 6 words wt" .
wr havebeen deleted in an interval within or at the leftend of previous input (i.e., r < last - 1).
Itis handled by removing the preterminal edgescorresponding to the deleted words along withall their dependent edges, and then collapsingthe chart, moving all edges from vertex vr+land on 6 steps to the left.Insert2:  Insertion before right end of coRemoveCross ingEdges  (l);for  i := last downto  l + 1 doMoveVer tex( i ,  i + 5, 5);MoveVer tex /R ightHa l f ( l ,  r + 1, 6);for  i := l, .
.
.
,  r do Scan(t0t);last := last -{- 5;RunChar t .This case occurs when 6 words wt- ' .
wr havebeen inserted at a position within or at the leftend of previous input (i.e., I < last).
It is han-dled by first removing all edges that %ross ~ ver-tex v~ (the vertex at which the new insertion isabout to start).
Secondly, the chart is split atvertex vl by moving all edges extending fromthis vertex or some vertex to the right of it 5steps to the right.
Finally, the new input isscanned and the resulting edges inserted intothe chart.Replace: Replacement within cofor i :-- I, ..., r doVe: c e v~.Po~t RemoveEdges lnD*  (e);for i :---- 1, .
.
.
,  r do Scan(wi) ;RunChar t .This case occurs when 8 words wt- .
.
Wr havebeen replaced by 6 other words at the corre-sponding positions within previous input (i.e.,1 ~_ I and r ~_ last; typically I -- r).
It is handledby first removing the preterminal edges corre-sponding to the replaced words along with alltheir dependent edges, and then scan the newwords and insert the resulting edges into thechart.Alternatively, we could of course realize replacethrough delete and insert, but having a dedi-cated replace operation is more efficient.- 244  -Subrout inesRemoveEdges InD*  (e):Vd: e D* d remove d.This routine removes all edges that are in the re-flexive transitive dependency closure of a givenedge e. 1?MoveVertex(from, to, ~):t;to :=  V/rom;Ve: e E Vto.Atooo UVto.Re.s := e.s + 6;e.t := e.t + 6.This routine moves the contents of a vertex fromv#om to vto and assigns new connectivity infor-mation to the affected (outgoing) edges.Move Vertex /R igh tHalf(frora, to, 6):V~o.R := vlrora.R;Vto.Atoop :=  UHom.Atoop;v/rom.R := ~;vSrom.Atoop :=  ~;Ve: e E uto.Aiooo U Vto.Re.s :=  e.e + 6;e.t := e.t + 6.This routine moves the contents of the right half(including active looping edges) of a vertex fromvy,o,n to vto and assigns new connectivity infor-mation to the affected (outgoing) edges.RemoveCross ingEdges  ( ):VeV/Vg:.f ~ vi- l.Po,tg E vt.Po~ts {/D+d n {gD+dremove e.The purpose of this routine, which is called fromInsert2,  is to remove all edges that %ross" ver-tex vt where the new insertion is about to start.This can be done in different ways.
The solu-tion above makes use of dependency informa-tion, removing every edge which is a dependantof both some preterminal edge incident to thechange vertex and some preterminal edge ex-tending from it.
t l  Alternatively, one could sim-ply remove every edge e whose left connectione.s < l and whose right connection e.t > l.l?It may sometimes be the case that not all edges in thedependency closure need to be removed because, in the courseof updating, some edge receives the same value as previously.This happens for example if a word is replaced by itself, or,given a grammar with atomic categories, if (say) a noun isreplaced by another noun.
One could reformulate the routinesin such a way that they check for thiJ before removing an edge.11For simplicity, we presuppo~ that preterminal edges onlyextend between adjacent vertices.Char t  ParserScan(~):If wl = a, then, for all lexical entries of theform (Xo--,a,D), add the edge ( i , i+ 1, X0--,a., D, ?
).Informally, this means adding an inactive,preterminal edge for each word sense of theword.RunChar t :For each vertex v~, do the following two stepsuntil no more edges can be added to the chart.1.
P red ic t /Bot tomUp:  For each edge estarting at vi of the form (i, j, X0 --~ a., D,E) and each rule of the form (Y0 ~ Yx/~,D') such that D'((Y1 cat)) = D((Xo cat)),add an edge of the form (i, i, Yo --* .\]/1/3,D', {e)) if this edge is not subsumed 1~ byanother edge.Informally, this means predicting an edgeaccording to each rule whose first right-hand-side category matches the categoryof the inactive edge under consideration.2.
Combine:  For each edge e of the form(i, 3", Xo --* a.X,n~, D, E) and each edge e sof the form (3", k, Yo --* ~/., D', El), add theedge (i, k, Xo ---, aX, n.~, D U \[Xm: D'(Yo)\],{e, e'}) if the unification succeeds and thisedge is not subsumed by another edge.Informally, this means forming a new edgewhenever the category of the first neededconstituent of an active edge matches thecategory of an inactive edge, 13 and the dagof the inactive edge can be unified in withthe dag of the needed constituent.3 D iscuss ion3 .1  Top-Down Pars ingThe algorithm given in section 2.4.2 could be mod-ified to top-down parsing by changing the predic-tor (see e.g.
Wirdn 1988) and by having Move-Ver tex /R ightHa l f  not move active looping edges(vt.AIooo) since, in top-clown, these "belong" to theleft portion of the chart where the predictions ofthem were generated.In general, the algorithm works better bottom-upthan top-down because bottom-up predictions are12One edge subsumes another edge if and only if the firstthree elements of the edges are identical and the fourth ele-ment of the first edge subsumes that of the second edge.
Fora definition of subsumption, see Shieber (1986:14).lSNote that this condition is tested by the unification whichspecifically ensures that D( (Xm cat}) = E( (Yo eat}).- 245 -made "locally ~ at the starting vertex of the trigger-ing (inactive) edge in question.
Therefore, a changedpreterminal edge will typically have its dependantslocally, and, as a consequence, the whole updatecan be kept local.
In top-down parsing, on theother hand, predictions are Uforward-directed', be-ing made at the ending vertex of the triggering (ac-tive) edge.
As a result of this, an update will, inparticular, cause all predicted and combined edgesafter the change to be removed.
The reason for thisis that we have forward-directed predictions havinggenerated active and inactive edges, the former ofwhich in turn have generated forward-directed pre-dictions, and so on through the chart.On  the one hand, one might accept this, argu-ing that this is simply the way top-down works: Itgenerates forward-directed hypotheses based on thepreceding context, and if we change the precedingcontext, the forward hypotheses should change aswell.
Also, it is still slightly more well-behaved thanexhaustive reanalysis from the change.On  the other hand, the point of incremental pars-ing is to keep updates local, and if we want to takethis seriously, it seems like a waste to destroy possi-bly usable structure to the right of the change.
Forexample, in changing the sentence "Sarah gave K ima green apple s to "Sarah gave a green apple to Kim s,there is no need for the phrase "a green apple s to bereanalysed.One approach to this problem would be for theedge-removal process to introduce a "cut s whenevera top-down prediction having some dependant edgeis encountered, mark it as "uncertain ~, and repeat-edly, at some later points in time, try to find a newsource for it.
Eventually, if such a source cannot befound, the edge (along with dependants) should beUgarbage-collected ~ because there is no way for thenormal update machinery to remove an edge with-out a source (except for preterminal edges).In sum, it would be desirable if we were able toretain the open-endedness of chart parsing also withrespect to rule invocation while still providing forefficient incremental update.
However, the precisestrategy for best achieving this remains to be workedout (also in the light of a fully testable interactivesystem}.3.2 A l te rnat ive  Wayso f  Determin ing  A f fec ted  Edges3.2.1 Maintain Sources OnlyHenry Thompson (personal communication 1988)has pointed out that, instead of computing sets ofdependants from source edges, it might suffice tosimply record the latter, provided that the frequencyof updates is small and the total number of edges isnot too large.
The idea is to sweep the whole edgespace each time there is an update, repeatedly delet-ing anything with a non-existent source edge, and it-erating until one gets through a whole pass with nonew deletions.3.2.2 Mainta in  Neither SourcesNor DependenciesIf we confine ourselves to bottom-up arsing, and ifwe accept hat an update will unconditionally causeall edges in the dependency closure to be removed(not allowing the kind of refinements discussed infootnote 10, it is in fact not necessary to recordsources or dependencies at all.
The reason for this isthat, in effect, removing all dependants of all preter-minal edges extending between vertices v|, .
.
.
,  Vr+lin the bottom-up case amounts to removing all edgesthat extend somewhere within this interval (exceptfor bottom-up redictions at vertex W+l which aretriggered by edges outside of the interval).
Given asuitable matrix representation for the chart (whereedges are simultaneously indexed with respect ostarting and ending vertices}, this may provide for avery efficient solution.3.2.3 Mainta in  Dependenciesbetween FeaturesThere is a trade-off between updating as local a unitas possible and the complexity of the algorithm fordoing so.
Given a complex-feature-based formalismlike PATR,  one extreme would be to maintain de-pendencies between feature instances of the chartinstead of between chart edges.
In principle, thisis the approach of the Synthesizer Generator (Repsand Teitelbaum 1987), which adopts attribute gram-mar for the language specification and maintains de-pendencies between the attribute instances of thederivation tree.3.3 Lex ica l  ComponentAn  approach to the lexical component which seemsparticularly suitable with respect to this type ofparser, and which is adopted in the actual implemen-tation, is the letter-tree format.
14 This approachtakes advantage of the fact that words normally areentered from left to right, and supports the idea of adynamic pointer which follows branches of the treeas a word is entered, immediately calling for reactionwhen an illegal string is detected.
In particular, thisallows you to distinguish an incomplete word from a(definitely) illegal word.
Another advantage of this14 Tr/e according tothe terminology of Aho, Hopcroft, andUllman (1987:163).- 246 -approach is that one may easily add two-level mor-phology (Koskenniemi 1983) as an additional filter.A radical approach, not pursued here, would be toemploy the same type of incremental chart-parsingmachinery at the lexical level as we do at the sen-tence level.3.4  Dependenc ies  across  SentencesIncremental parsing would be even more beneficial ifit were extended to handle dependencies across mul-tiple sentences, for example with respect to noun-phrases.
Considering a language-sensitive text edi-tor, the purpose of which would be to keep track ofan input text, to detect (and maybe correct) certainlinguistic errors, a change in one sentence often re-quires changes also in the surrounding text as in thefollowing examples:The house is full of mould.
It has beenjudged insanitary by the public health com-mittee.
They say it has to be torn down.The salmon jumped.
It likes to play.In the first example, changing the number of~house ~ forces several grammatical changes in thesubsequent sentences, requiring reanalysis.
In thesecond example, changing "it (likes) ~ to ~they (like) ~constrains the noun-phrase of the previous sentenceto be interpreted as plural, which could be reflectedfor example by putting the edges of the singular anal-ysis to sleep.Cross-sentence dependencies require a level of in-cremental interpretation and a database with non-monotonic reasoning capabilities.
For a recent ap-proach in this direction, see Zernik and Brown(1988).Text editorI Lexicon ScannerIncrementalI Grammar chart parser Chart IFigure I.
Main components of the LIPS systemIt is planned to maintain a dynamic agenda of up-date tasks (either at the level of update functionsor, preferably, at the level of individual edges), re-moving tasks which are no longer needed becausethe user has made them obsolete (for example byimmediately deleting an inserted text).In the long run, an interactive parsing systemprobably has to have some built-in notion of time, forexample through time-stamped editing operationsand (adjustable) strategies for timing of update op-erations.5 ConclusionThis paper has demonstrated how a chart parser bysimple means could be augmented to perform in-cremental parsing, and has suggested how this sys-tem in turn could be embedded in an interactiveparsing system.
Incrementality and interactivity aretwo independent properties, but, in practice, an in-cremental system that is not interactive would bepointless, and an interactive system that is not in-cremental would at least be less efficient than itcould be.
Although exhaustive recomputation canbe fast enough for small problems, incrementality isultimately needed in order to cope with longer andmore complex texts.
In addition, incremental pars-ing brings to the system a certain ~naturainess ~analyses are put together piece by piece, and thereis a built-in correlation between the amount of pro-ceasing required for a task and its difficulty.
"Easy things should be easy... ~ (Alan Kay).4 Interactive ParsingThis section outlines how the incremental parser isembedded in an interactive parsing system, calledLIPS.
15Figure 1 shows the main components of the sys-tem.
The user types a sentence into the editor (aXerox TEDIT  text editor).
The words are analysedon-line by the scanner and handed over to the parserproper which keeps the chart consistent with the in-put sentence.
Unknown words are marked as illegalin the edit window.
The system displays the chartincrementally, drawing and erasing individual edgesin tandem with the parsing process.lSLink~iping Interactive Parsing System.ReferencesAho, Alfred V., John E. Hopcroft, and Jeffrey D.Ullman (1987).
Data Structures and Algorithms.Addison-Wesley, Reading, Massachusetts.Bobrow, Robert J. and Bonnie Lynn Webber (1980).Knowledge Representation for Syntactic/SemanticProcessing.
Proc.
First Annual National Conferenceon Artificial Intelligence, Stanford, California: 316-323.de Kleer, Johan (1986).
An Assumption-based TMS.Artificial Intelligence 28(2):127-162.Earley, Jay (1970).Parsing Algorithm.13(2).94-102.An Efficient Context-FreeCommunications of the ACM~- , ,  - 247  -Earley, Jay and Paul Caizergues (1972).
A Methodfor Incrementally Compiling Languages with NestedStatement Structure.
Communications of the ACM15(12):1040-1044.Ghezzi, Carlo and Dino Mandrioli (1979).
Incremen-tal Parsing.
ACM Transactions on ProgrammingLanguages and Systems 1(1):58-70.Ghezzi, Carlo and Dino Mandrioli (1980).
Aug-menting Parsers to Support Incrementality.
Jour-nal of the Association for Computing Machinery27(3):564-579.Haddock, Nicholas J.
(1987).
Incremental Interpre-tation and Combinatory Categorial Grammar.
Proc.Tenth International Joint Conference on ArtificialIntelligence, Milan, Italy: 661-663.Hirst, Graeme (1987).
Semantic Interpretation andthe Resolution of Ambiguity.
Cambridge UniversityPress, Cambridge, England.Kay, Martin (1980).
Algorithm Schemata and DataStructures in Syntactic Processing.
Report CSL-80-12, Xerox PARC, Palo Alto, California.
Also in:Sture Alldn, ed.
(1982), Tezt Processing.
Proceed-ings of Nobel Symposium 51.
Almqvist & WiksellInternational, Stockholm, Sweden: 327-358.Koskenniemi, Kimmo (1983).
Two-Level Morphol-ogy: A General Computational Model for Word-Form Recognition and Production.
Publication No.11, Department ofGeneral Linguistics, University ofHelsinki, Helsinki, Finland.Lindstrom, G. (1970).
The Design of Parsers forIncremental Language Processors.
Proc.
Pad ACMSymposium on Theory of Computing, Northampton,Massachusetts: 81-91.Melllsh, Christopher S. (1985).
Computer Interpre-tation of Natural Language Descriptions.
Ellis Hor-wood, Chichester, England.Pulman, Steven G. (1985).
A Parser That Doesn't.Proc.
Second Conference of the European Chapterof the Association for Computational Linguistics,Geneva, Switzerland: 128-135.Pulman, Steven G. (1987).
The Syntax-SemanticsInterface.
In: Pete Whitelock, Mary McGee Wood,Harold Somers, Rod Johnson, and Paul Bennett, ed.,Linguistic Theory and Computer Applications.
Aca-demic Press, London, England: 189-224.Reps, Thomas and Tim Teitelbanm (1987).
Lan-guage Processing in Program Editors.
Computer20(11):29-40.Shleber, Stuart M. (1986).
An Introduction toUnification-Based Approaches to Grammar.
CSLILecture Notes No.
4.
University of Chicago Press,Chicago, Illinois.Shieber, Stuart M., Hans Uszkorelt, Fernando C. N.Pereira, Jane J. Robinson, and Mabry Tyson (1983).The Formalism and Implementation f PATR-II.
In:Barbara Grosz and Mark Stickel, eds., Research onInteractive Acquisition and Use of Knowledge.
SRIFinal Report 1894, SRI International, Menlo Park,California.Thompson, Henry (1981).
Chart Parsing and RuleSchemata in GPSG.
Research Paper No.
165, De-partment of Artificial Intelligence, University of Ed-inburgh, Edinburgh, Scotland.
Also in: Proc.
19thAnnual Meeting of the Association for Computa-tional Linguistics, Stanford, California: 167-172.Thompson, Henry and Grasme Ritchie (1984).
Im-plementing Natural Language Parsers.
In: TimO'Shea and Marc Eisenstadt, Artificial Intelligence:Tools, Techniques, and Applications.
Harper & Row,New York, New York: 245-300.Tomita, Masaru (1985).
An Efficient Context-FreeParsing Algorithm for Natural Languages.
Proc.Ninth International Joint Conference on ArtificialIntelligence, Los Angeles, California: 756--764.Yonezawa, Akinori and Ichiro Ohsawa (1988).Object-Oriented Parallel Parsing for Context-FreeGrammars.
Proc.
ll~th International Conferenceon Computational Linguistics, Budapest, Hungary:773-778.Wires, Mats (1988).
A Control-Strategy-Indepen-dent Parser for PATR.
Proc.
First ScandinavianConference on Artificial Intelligence, Troms?, Nor-way: 161-172.
Also research report LiTH-IDA-R-88-10, Department of Computer and InformationScience, Link~ping University, Link6ping, Sweden.Zernlk, Uri and Allen Brown (1988).
Default Rea-soning in Natural Language Processing.
Proc.
ll~thInternational Conference on Computational Linguis-tics, Budapest, Hungary: 801-805.- 248  -
