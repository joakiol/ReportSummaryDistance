Dependency and relational structure in treebank annotationCristina BOSCO, Vincenzo LOMBARDODipartimento di Informatica, Universita` di TorinoCorso Svizzera 18510149 Torino,Italia,bosco,vincenzo@di.unito.itAbstractAmong the variety of proposals currently mak-ing the dependency perspective on grammarmore concrete, there are several treebankswhose annotation exploits some form of Rela-tional Structure that we can consider a general-ization of the fundamental idea of dependencyat various degrees and with reference to differ-ent types of linguistic knowledge.The paper describes the Relational Structure asthe common underlying representation of tree-banks which is motivated by both theoreticaland task-dependent considerations.
Then itpresents a system for the annotation of the Rela-tional Structure in treebanks, called AugmentedRelational Structure, which allows for a system-atic annotation of various components of lin-guistic knowledge crucial in several tasks.
Fi-nally, it shows a dependency-based annotationfor an Italian treebank, i.e.
the Turin Univer-sity Treebank, that implements the AugmentedRelational Structure.1 IntroductionDifferent treebanks use different annotationschemes which make explicit two distinct butinterrelated aspects of the structure of the sen-tence, i.e.
the function of the syntactic unitsand their organization according to a part-wholeparadigm.
The first aspect refers to a form ofRelational Structure (RS), the second refers toits constituent or Phrase Structure (PS).
Themajor difference between the two structures isthat the RS allows for several types of rela-tions to link the syntactic units, whilst the PSinvolves a single relation ?part-of?.
The RScan be seen as a generalization of the depen-dency syntax with the syntactic units instanti-ated to individual words in the dependency tree(Mel?c?uk, 1988).
As described in many theo-retical linguistic frameworks, the RS provides auseful interface between syntax and a seman-tic or conceptual representation of predicate-argument structure.
For example, Lexical Func-tional Grammar (LFG) (Bresnan, 1982) collo-cates relations at the interface between lexiconand syntax, Relational Grammar (RG) (Perl-mutter, 1983) provides a description of the sen-tence structure exclusively based on relationsand syntactic units not structured beyond thestring level.This paper investigates how the notion of RShas been applied in the annotation of tree-banks, in terms of syntactic units and typesof relations, and presents a system for thedefinition of the RS that encompasses severaluses in treebank schemata and can be viewedas a common underlying representation.
Thesystem, called Augmented Relational Struc-ture (ARS) allows for an explicit representa-tion of the three major components of linguisticstructures, i.e.
morpho-syntactic, functional-syntactic and semantic.
Then the paper showshow a dependency-based annotation can de-scend on ARS, and describes the ARS-based an-notation of a dependency treebank for Italian,the Turin University Treebank (TUT), which isthe first available treebank for Italian, with afew quantitative results.The paper is organized as follows.
The nextsection investigates both the annotation of RSin treebanks and the major motivations for theuse of RS from language-specific issues and NLPtasks implementation; then we present the ARSsystem; finally, we show the dependency anno-tation of the TUT corpus.2 Annotation of the RelationalStructureIn practice, all the existing treebank schemataimplement some form of relational structure.Annotation schemata range from pure (depen-dency) RS-based approaches to RS-PS combi-nations (Abeille?, 2003).Some treebanks consider the relational infor-mation as the exclusive basis of the annotation.The Prague Dependency Treebank ((Hajic?ova?and Ceplova?, 2000), (Bo?hmova?
et al, 2003))implements a three level annotation schemewhere both the analytical (surface syntactic)and tectogrammatical level (deep syntactic andtopic-focus articulation) are dependency-based;the English Dependency Treebank (Rambowet al, 2002) implements a dependency-basedmono-stratal analysis which encompasses sur-face and deep syntax and directly represents thepredicate-argument structure.
Other projectsadopt mixed formalisms where the sentence issplit in syntactic subunits (phrases), but linkedby functional or semantic relations, e.g.
the Ne-gra Treebank for German ((Brants et al, 2003),(Skut et al, 1998)), the Alpino Treebank forDutch (van der Beek et al, 2002), and the LingoRedwood Treebank for English (Oepen et al,2002).
Also in the Penn Treebank ((Marcuset al, 1993), (Marcus et al, 1994)) a limitedset of relations is placed over the constituency-based annotation in order to make explicit the(morpho-syntactic or semantic) roles that theconstituents play.The choice of a RS-based annotation schemacan depend on theoretical linguistic motivations(a RS-based schema allows for an explicit, fine-grained representation of several linguistic phe-nomena), task-dependent motivations (the RS-based schema represents the linguistic informa-tion involved in the task(s) at hand), language-dependent motivations (the relational structureis traditionally considered as the most adequaterepresentation of the object language).Theoretical motivations for exploiting repre-sentations based on forms of RS was developedin the several RS-based theoretical linguisticframeworks (e.g.
Lexical Functional Grammar,Relaional Grammar and dependency grammar),which allow for capturing information involvedat various level (e.g.
syntactic and semantic)in linguistic structures, and grammatical for-malisms have been proposed with the aim tocapture the linguistic knowledge represented inthese frameworks.
Since the most immediateway to build wide-coverage grammars is toextract them directly from linguistic data (i.e.from treebanks), the type of annotation used inthe data is a factor of primary importance, i.e.a RS-based annotation allows for the extractionof a more descriptive grammar1.1See (Mazzei and Lombardo, 2004a) and (Mazzei andLombardo, 2004b) for experiments of LTAG extractionfrom TUT.Task-dependent motivations rely on how theannotation of the RS can facilitate someprocessing aspects of NLP applications.
Theexplicit representation of predicative structuresallowed by the RS can be a powerful sourceof disambiguation.
In fact, a large amount ofambiguity (such as coordination, Noun-Nouncompounds and relative clause attachment) canbe resolved using such a kind of information,and relations can provide a useful interfacebetween syntax and semantics.
(Hindle andRooth, 1991) had shown the use of dependencyin Prepositional Phrase disambiguation, andthe experimental results reported in (Hock-enmaier, 2003) demonstrate that a languagemodel which encodes a rich notion of predicateargument structure (e.g.
including long-rangerelations arising through coordination) cansignificantly improve the parsing performances.Moreover, the notion of predicate argumentstructure has been advocated as useful ina number of different large-scale language-processing tasks, and the RS is a convenientintermediate representation in several applica-tions (see (Bosco, 2004) for a survey on thistopic).
For instance, in Information Extractionrelations allows for recognizing different guisesin which an event can appear regardless of theseveral different syntactic patterns that can beused to specify it (Palmer et al, 2001)2.
InQuestion Answering, systems usually use formsof relation-based structured representations ofthe input texts (i.e.
questions and answers)and try to match those representations (seee.g.
(Litkowski, 1999), (Buchholz, 2002)).Also the in-depth understanding of the text,necessary in Machine Translation task, requiresthe use of relation-based representations wherean accurate predicate argument structure is acritical factor (Han et al, 2000)3.Language-dependent motivations rely on thefact that the dependency-based formalisms hasbeen traditionally considered as the most ade-quate for the representation of free word orderlanguages.
With respect to constituency-based2Various approaches to IE (Collins and Miller, 1997)address this issue by using relational representations,that is forms of ?concept nodes?
which specifies a trig-ger word (usually a Verb) and also forms of mappingbetween the syntactic and the semantic relations of thetrigger.3The system presented in (Han et al, 2000) gener-ates the dependency trees of the source language (Ko-rean) sentences, then directly maps them to the trans-lated (English) sentences.formalisms, free word order languages involves alarge amount of discontinuous constituents (i.e.constituents whose parts are not contiguous inthe linear order of the sentence).
In practice, aconstituency-based representation was adoptedfor languages with rather fixed word orderpatterns, like English (Penn Treebank), whilea dependency representation for languageswhich allow variable degrees of word orderfreedom, such as Czech (see Prague Depen-dency Treebank) or Italian (as we will see later,TUT).
Nevertheless, in principle, since therepresentation of a discontinuous constituent Xcan be addressed in various ways (e.g.
by in-troducing lexically empty elements co-indexedwith the moved parts of X ), the presence toa certain extent of word order freedom doesnot necessarily mean that a language has to benecessarily annotated according to a relation-based format rather than a constituency-basedone.
Moreover, free word order languages canpresent difficulties for dependency-based aswell as for constituency-based frameworks (e.g.non-projective structures).
The developmentof dependency-based treebanks for English (seeEnglish Dependency Treebank) together withthe inclusion of relations in constituency-basedtreebanks (see Penn Treebank) too, confirmsthe strongly prevailing relevance of motivationsbeyond the language-dependent ones.The types of knowledge that many applica-tions actually need are RS-based representa-tions where predicate argument structure andthe associated morphological and syntactic in-formation can operate as an interface to asemantic-conceptual representation.
All thesetypes of knowledge have in common the factthat they can be described according to the de-pendency paradigm, rather than according tothe constituency paradigm.
The many applica-tions (in particular those referring to the PennTreebank) which use heuristics-based transla-tion schemes from the phrase structure to lexicaldependency (?head percolation tables?)
(Ram-bow et al, 2002) show that the access to com-prehensive and accurate extended dependency-based representations has to be currently con-sidered as a critical issue for the development ofrobust and accurate NLP technologies.Now we define our proposal for the representa-tion of the RS in treebank annotation.3 The Augmented RelationalStructureA RS consists of syntactic units linked by re-lations.
An Augmented Relational Structure(ARS) organizes and systematizes the informa-tion usually associated in existing annotationsto the RS, and includes not only syntactic ,but also linguistic information that can be rep-resented according to a dependency paradigmand that is proximate to semantics and un-derlies syntax and morphology.
Therefore theeatsJohn the applerel2rel1Figure 1: A simple RS.ARS expresses the relations and syntactic unitsin terms of multiple components.
We describethe ARS as a dag where each relation is afeature structure including three components.Each component of the ARS-relations is use-morphfsyntsemv1v2v3Figure 2: An ARS relation.ful in marking both similarities and differencesamong the behavior of units linked by the de-pendency relations.The morpho-syntactic component of the ARSdescribes morpho-syntactic features of thewords involved in relations, such as their gram-matical category.
This component is useful formaking explicit the morpho-syntactic variantsof predicative structures.
Instances of this kindof variants often occur in intransitive, tran-sitive and di-transitive predicative structures,e.g.
esplosione-esplodere (explosion - to ex-plode) are respectively nominal and verbal vari-ants of the intransitive structure ?something ex-plodes?.
By referring to the TUT, we can evalu-ate the frequency of this phenomenon: in 1,500sentences 944 Verbs occur (for a total of 4169occurrences) and around the 30% of them arepresent in the nominal variant too4.The functional-syntactic component identifiesthe subcategorized elements, that is it keepsapart arguments and modifiers in the pred-icative structures.
Moreover, this componentmakes explicit the similarity of a same predica-tive structure when it occurs in the sentence indifferent morpho-syntactic variants.
In fact, thefunctional-syntactic components involved, e.g.,in the transitive predicative structure ?some-one declares something?, are the same in boththe nominal (dichiarazione [di innocenza]OBJ[di John]SUBJ- John?s declaration of innocence)and verbal realization ([John]SUBJdichiara [lasua innocenza]OBJ- John declares his inno-cence) of such a predication, i.e.
SUBJ andOBJ.
The distinction between arguments andmodifiers has been considered as quite problem-atic in the practice of the annotation, even if rel-evant from the applicative and theoretical pointof view5, and is not systematically annotated inthe Penn Treebank (only in clear cases, the useof semantic roles allows for the annotation ofargument and modifier) and in the Negra Tree-bank.
This distinction is instead usually markedin dependency representations, e.g.
in the En-glish Dependency Treebank and in the PragueDependency Treebank.The semantic component of the ARS-relationsspecifies the role of words in the syntax-semantics interface and discriminates amongdifferent kinds of modifiers and oblique com-plements.
We can identify at least three levelsof generality: verb-specific roles (e.g.
Runner,Killer, Bearer); thematic roles (e.g.
Agent, In-strument, Experiencer, Theme, Patient); gener-alized roles (e.g.
Actor and Undergoer).
Theuse of specific roles can cause the loss of usefulgeneralizations, whilst too generic roles do notdescribe with accuracy the data.
An example ofannotation of semantic roles is the tectogram-matical layer of the Prague Dependency Tree-bank.ARS features a mono-stratal approach.
By fol-lowing this strategy, the annotation process canbe easier, and the result is a direct represen-tation of a complete predicate argument struc-ture, that is a RS where all the information(morpho-syntactic, functional-syntactic and se-mantic) are immediately available.
An alterna-tive approach has been followed by the Prague4This statistics does not take into consideration thepossible polysemic nature of words involved.5See, for instance, in LFG and RG.Dependency Treebank, which is featured bya three levels annotation.
This case showsthat the major difference between the syntactic(analytic) and the semantic (tectogrammatical)layer consists in the inclusion of empty nodesfor recovering forms of deletion ((Bo?hmova etal., 1999), (Hajic?ova?
and Ceplova?, 2000)).
Butthis kind of information does not necessarily re-quires a separated semantic layer and can beannotated as well in a mono-stratal represen-tation, like the English Dependency Treebank(Rambow et al, 2002) does.The tripartite structure of the relations in ARSguarantees that different components can be ac-cessed separately and analyzed independently(like in (Montemagni et al, 2003) or in (Ram-bow et al, 2002)).
Furthermore, the ARS al-lows for forms of annotation of relations wherenot all the features are specified too.
In fact, theARS-relations which specify only a part of com-ponents allow for the description of syntacticgrammatical relations which do not correspondwith any semantic relation, either because theyhave a void semantic content or because theyhave a different structure from any possible cor-responding semantic relation (i.e.
there is nosemantic relation linking the same ARS-unitslinked by the syntactic one).
Typical relationsvoid of semantic content can link the parts of ex-pressions not compositionally interpretable (id-ioms), for instance together with with in to-gether with.
While a classic example of a non-isomorphic syntactic and semantic structure isone which involves the meaning of quantifiers:a determiner within a NP extends its scope be-yond the semantic concept that results from theinterpretation of the NP.
Another example isthe coordination where the semantic and syn-tactic structure are often considered as non iso-morphic in several forms of representation.The ARS-relations including values for bothfunctional-syntactic and semantic componentsmay be used in the representation of grammat-ical relations which participate into argumentstructures and the so-called oblique cases (seeFillmore and (Hudson, 1990)), i.e.
where thesemantic structures are completely isomorphicto the syntactic structures.
For example, alocative adjunct like in the garden in John waseating fish in the garden is represented at thesyntactic level as a Prepositional Phrase play-ing the syntactic function locative in the VerbPhrase (in the Penn Treebank it could be an-notated as a PP-LOC); the semantic conceptcorresponding to the garden plays the semanticrole LOCATION in the ?eating?
event statedby the sentence.4 TUT: a dependency-basedtreebank for ItalianThe TUT is the first available tree-bank of Italian (freely downloadable athttp://www.di.unito.it/?tutreeb/).
The cur-rent release of TUT includes 1,500 sentencescorresponding to 38,653 tokens (33,868 wordsand 4,785 punctuation marks).
The averagesentence length is of 22,57 words and 3,2punctuation marks.In this section, we concentrate on the majorfeatures of TUT annotation schema, i.e.
howthe ARS system can describe a dependencystructure.4.1 A dependency-based schemaIn Italian the order of words is fixed in nonverbal phrases, but verbal arguments and mod-ifiers can be freely distributed without affect-ing the semantic interpretation of the sentence.A study on a set of sentences of TUT showsthat the basic word order for Italian is Subject-Verb-Complement (SVC), as known in litera-ture (Renzi, 1988), (Stock, 1989), but in morethan a quarter of declarative sentences it is vi-olated (see the following table6).
Although thePermutations OccurrencesS V C 74,26%V C S 11,38%S C V 7,98%C S V 3,23%V S C 2,29%C V S 0,77%Table 1: Italian word orderSVC order is well over the others, the fact thatall the other orders are represented quantita-tively confirms the assumption of partial con-figurationality intuitively set in the literature.The partial configurationality of Italian can beconsidered as a language-dependent motivationfor the choice of a dependency-based annota-tion for an Italian treebank.
The schema issimilar to that of the Prague Dependency Tree-bank analytical-syntactic level with which TUT6The data reported in the table refer to 1,200 anno-tated sentences where 1,092 verbal predicate argumentstructures involving Subject and at least one other Com-plement occur.shares the following basic design principles typ-ical of the dependency paradigm: the sentence is represented by a tree whereeach node represents a word and eachedge represents a dependency labelled by agrammatical relation which involves a headand a dependent, each single word and punctuation markis represented by a single node, the so-called amalgamated words, which are wordscomposed by lexical units that can occurboth in compounds and alone, e.g.
Verbswith clitic suffixes (amarti (to love-you) orPrepositions with Article (dal (from-the)),are split in more lexical units7, since the constituent structure of the sen-tence is implicit in dependency trees, nophrases are annotated8.If the partial configurationality makes thedependency-based annotation more adequatefor Italian, other features of this languageshould be well represented by exploiting aNegra-like format where the syntactic units arephrases rather than single words.
For instance,in Italian, Nouns are in most cases introducedby the Article: the relation between Noun andDeterminer is not very relevant in a dependencyperspective, while it contributes to the defini-tion of a clearer notion of NP in Italian thanin languages poorer of Determiners like, e.g.,Czech.
The major motivation of a dependency-based schema is therefore theoretical and, inparticular, to make explicit in the treebank an-notation a variety of structures typical of theobject language.Moreover, in order to make explicit in casesof deletion and ellipsis the predicate argumentstructure, we annotate in the TUT null ele-ments.
These elements allow for the annota-tion of a variety of phenomena: from the ?equi?deletion which affects the subject of infinitiveVerb depending on a tensed Verb (e.g.
John(1)vuole T(1) andare a casa - John(1) want toT(1) go home), to the various forms of gap-ping that can affect parts of the structure ofthe sentence (e.g.
John va(1) a casa e MarioT(1) al cinema - John goes(1) home and Mario7Referring to the current TUT corpus, we see thataround 7,7% words are amalgamated.8If phrase structure is needed for a particular appli-cation, it is possible to automatically derive it from thedependency structure along with the surface word order.dichiaravaIn SudjaVERB,PREPRMODTIMEilVERB,NOUNSUBJAGENTVERB,DET+DEFOBJTHEMEquei laPREP,DET+DEFARG#fallimentoNOUN,DET+DEFAPPOSITIONDENOMDET+DEF,NOUNARG#giorni zingaraDET+DEF,NOUNARG#DET+DEF,NOUNARG#Figure 3: The TUT representation of In queigiorni Sudja la zingara dichiarava il fallimento(In those days Sudja the gipsy declared thebankruptcy).T(1) to the cinema), to the pro-dropped sub-jects typical of Italian (as well as of Portugueseand Spanish), i.e.
the subject of tensed Verbswhich are not lexically realized in the sentence(e.g.
T Va a casa - T goes home).
For phenom-ena such as equi and gapping TUT implementsco-indexed traces, while it implements non co-indexed traces for phenomena such as the pro-drop subject.4.2 An ARS-based schemaIn TUT the dependency relations form theskeleton of the trees and the ARS tripartite fea-ture structures which are associated to these re-lations resolve the interface between the mor-phology, syntax and semantics.
The ARS al-lows for some form of annotation also of rela-tions where only parts of the features are spec-ified.
In TUT this has been useful for under-specifying relations both in automatic analysisof the treebank (i.e.
we can automatically ex-clude the analysis of a specific component ofthe relations) and in the annotation process (i.e.when the annotator is not confident of a specificcomponent of a relation, he/she can leave sucha component void).In the figure 3 we see a TUT tree.All the relations annotated in the tree in-clude the morpho-syntactic component, formedby the morphological categories of the words in-volved in the relation separated by a comma,e.g.
VERB,PREP for the relation linking theroot of the sentence with its leftmost child(In).
Some relation involves a morpho-syntacticcomponent where morphological categories arecomposed by more elements, e.g.
DET+DEF(in DET+DEF,NOUN) for the relation linkingquei with giorni.
The elements of the morpho-syntactic component of TUT includes, in fact,10 ?primary?
tags that represent morphologi-cal categories of words (e.g.
DET for Deter-miner, NOUN for Noun, and VERB for Verb),and that can be augmented with 20 ?secondary?tags (specific of the primary tags) which furtherdescribe them by showing specific features, e.g.DEF which specifies the definiteness of the De-terminer or INF which specifies infiniteness ofVerb.
Valid values of the elements involved inTUT morpho-syntactic tags are 40.By using the values of the functional-syntacticcomponent, TUT distinguishes among a varietyof dependency relations.
In figure 3 we see thedistinction between argument, e.g.
the relationSUBJ linking the argument Sudja with the ver-bal root of the sentence dichiarava, and the rela-tion RMOD which represents a restrictive mod-ifier and links the verbal root dichiarava within quei giorni.
The dependents of Prepositionsand determiners are annotated as argument too,according to arguments presented in (Hudson,1990).
Another distinction which is exploitedin the annotation of the sentence is that be-tween restrictive modifier (i.e.
RMOD whichlinks dichiarava with in quei giorni) and AP-POSITION (i.e.
non restrictive modifier linkingSudja with la zingara), which are modifiers thatrestrict the meaning of the head.
Beyond thesebasic distinctions, TUT schema draws other dis-tinctions among the functional-syntactic rela-tions and includes a large set of tags for a totalof 55 items, which are compounds of 27 pri-mary and 23 secondary tags.
These tags areorganized in a hierarchy (Bosco, 2004) accord-ing to their different degree of specification.
Inthe hierarchy of relations, Arguments (ARG) in-clude Subject (SUBJ), Object (OBJ), IndirectObject (INDOBJ), Indirect Complement (IN-DCOMPL), Predicative Complements (of theSubject (PREDCOMPL+SUBJ) and of the Ob-ject (PREDCOMPL+OBJ)).
The direct conse-quence of its hierarchical organization is theavailability of another mechanisms of under-specification in the annotation or in the anal-ysis of annotated data.
In fact, by referring tothe hierarchy we can both annotate and analyzerelations at various degrees of specificity.The semantic component discriminates amongdifferent kinds of modifiers and oblique com-plements.
The approach pursued in TUT hasbeen to annotate very specific semantic rolesonly when they are immediately and neatlydistinguishable.
For instance, by referring tothe prepositional dependents introduced by da9(from/by), we find the following six differentvalues for the semantic component:- REASONCAUSE, e.g., in gli investitori sonoimpazziti dalle prospettive di guadagno (the in-vestors are crazy because of the perspectives ofgain)- SOURCE, e.g., in traggono benefici dallabonifica ([they] gain benefit from the drainage)- AGENT, e.g., l?iniziativa e` appoggiata dagliUSA (the venture is supported by USA)- TIME, e.g., dal ?91 sono stati stanziati 450miliardi (since ?91 has been allocated 450 bil-lions)- THEME, e.g., cio` distingue l?Albania dalloZaire (that distinguishes the Albany fromZaire)- LOC, which can be further specialized inLOC+FROM, e.g., in da qui e` partito l?assalto(from here started the attack), LOC+IN, e.g., inquello che succedeva dall?altra parte del mondo(what happened in the other side of the world),LOC+METAPH, e.g., in l?Albania e` passata dallancio dei sassi alle mitragliatrici (the Albanyhas passed from the stone-throwing to the ma-chineguns).In figure 3 the semantic component has beenannotated only in four relations, which respec-tively represent the temporal modifier In queigiorni of the main Verb dichiarava, the appo-sition la zingara of the Noun Sudja, and thearguments of the Verb, i.e.
the subject Sudja lazingara which plays the semantic role AGENTand the object il fallimento which plays the se-mantic role THEME.
In the other relations in-volved in this sentence a value for the semanticcomponent cannot be identified10, e.g.
the ar-gument of a Preposition or Determiner cannotbe semantically specified as in the case of theverbal arguments.5 ConclusionsThe paper analyzes the annotation of the RS inthe existing treebanks by referring to a notionof RS which is a generalization of dependency.9In 1,500 TUT sentences we find 591 occurrences ofthis Preposition.10In figure 3, we marked the semantic component ofthese cases with .According to this notion, the RS includes typesof linguistic knowledge which are different, butwhich have in common that they can be repre-sented by a dependency paradigm rather thanto a constituency-based one.The paper identifies two major motivationsfor exploiting RS in treebank annotation:language-dependent motivations that have de-termined the use of dependency for the repre-sentation of treebanks of free word order lan-guages, and task-dependent motivations thathave determined a wider use of relations in tree-banks.In the second part of the paper, we show a sys-tem for the annotation of RS, i.e.
the ARS,and how the ARS can be used for the an-notation of a dependency-based treebank, theTUT whose schema augments classical depen-dency (functional-syntactic) relations with mor-phological and semantic knowledge according tothe above mentioned notion of RS.ReferencesA.
Abeille?, editor.
2003.
Building and usingsyntactically annotated corpora.
Kluwer, Dor-drecht.A.
Bo?hmova, J.
Panevova?, and P. Sgall.
1999.Syntactic tagging: procedure for the transi-tion from analytic to the tectogrammaticaltreestructures.
In Proc.
of 2nd Workshop onText, speech and dialog, pages 34?38.A.
Bo?hmova?, J.
Hajic?, E.
Hajic?ova?, andB.
Hladka?.
2003.
The Prague DependencyTreebank: A three level annotation scenario.In Abeille?
(Abeille?, 2003), pages 103?127.C.
Bosco.
2004.
A grammatical rela-tion system for treebank annotation.Ph.D.
thesis, University of Torino.http://www.di.unito.it/?bosco/.T.
Brants, W. Skut, and H. Uszkoreit.
2003.Syntactic annotation of a German newspapercorpus.
In Abeille?
(Abeille?, 2003), pages 73?87.J.
Bresnan, editor.
1982.
The mental represen-tation of grammatical relations.
MIT Press,Cambridge.S.
Buchholz.
2002.
Using grammatical rela-tions, answer frequencies and the World WideWeb for TREC Question Answering.
In Proc.of TREC 2001, pages 502?509.M.
Collins and S. Miller.
1997.
Semantic tag-ging using a probabilistic context free gram-mar.
In Proc.
of 6th Workshop on Very LargeCorpora.E.
Hajic?ova?
and M. Ceplova?.
2000.
Deletionsand their reconstruction in tectogrammaticalsyntactic tagging of very large corpora.
InPorc.
of COLING 2000, pages 278?284.C.
Han, B. Lavoie, M. Palmer, O. Rambow,R.
Kittredge, T. Korelsky, N. Kim, andM.
Kim.
2000.
Handling structural diver-gences and recovering dropped arguments in aKorean/English machine translation system.In Proc.
of AMTA 2000, pages 40?54.D.
Hindle and M. Rooth.
1991.
Structural am-biguity and lexical relations.
In Proc.
of ACL91, pages 229?236.J.
Hockenmaier.
2003.
Parsing with generativemodels of predicate-argument structure.
InProc.
of ACL 2003.R.
Hudson.
1990.
English Word Grammar.Basil Blackwell, Oxford and Cambridge.K.C.
Litkowski.
1999.
Question-answering us-ing semantic relation triples.
In Proc.
ofTREC-8, pages 349?356.M.
Marcus, B. Santorini, and M.A.Marcinkiewicz.
1993.
Building a largeannotated corpus of English: The PennTreebank.
Computational Linguistics,19:313?330.M.
Marcus, G. Kim, M.A.
Marcinkiewicz,R.
MacIntyre, A. Bies, M. Ferguson, K. Katz,and B. Schasberger.
1994.
The Penn Tree-bank: Annotating predicate argument struc-ture.
In Proc.
of HLT-94.A.
Mazzei and V. Lombardo.
2004a.
Building alarge grammar for Italian.
In Proc.
of LREC2004, pages 51?54.A.
Mazzei and V. Lombardo.
2004b.
A com-parative analysis of extracted grammars.
InProc.
of ECAI 2004.I.A.
Mel?c?uk.
1988.
Dependency Syntax: theoryand practice.
SUNY, Albany.S.
Montemagni, F. Barsotti, M. Battista,and N. Calzolari.
2003.
Building the Ital-ian syntactic-semantic treebank.
In Abeille?
(Abeille?, 2003), pages 189?210.S.
Oepen, K. Toutanova, S. Shieber, C.D.
Man-ning, D. Flickinger, and T. Brants.
2002.
TheLinGO Redwoods treebank: motivation andprliminary applications.
In Proc.
of COLING2002, pages 1253?1257.M.
Palmer, J. Rosenzweig, and S. Cotton.
2001.Automatic predicate argument analysis of thePenn Treebank.
In Proc.
of HLT 2001.D.M.
Perlmutter.
1983.
Studies in RelationalGrammar 1.
University of Chicago Press.O.
Rambow, C. Creswell, R. Szekely, H. Taber,and M. Walker.
2002.
A dependency tree-bank for English.
In Proc.
of LREC 2002,pages 857?863.L.
Renzi, editor.
1988.
Grande grammaticaitaliana di consultazione, vol.
I. Il Mulino,Bologna.W.
Skut, T. Brants, B. Krenn, and H. Uszkor-eit.
1998.
A linguistically interpreted corpusof German in newspaper texts.
In Proc.
ofLREC 98, pages 705?713.O.
Stock.
1989.
Parsing with flexibility, dy-namic strategies, and idioms in mind.
Com-putational Linguistics, 15(1):1?17.L.
van der Beek, G. Bouma, R. Malouf, andG.
van der Noord.
2002.
The Alpino depen-dency treebank.
In Proc.
of CLIN 2001.
