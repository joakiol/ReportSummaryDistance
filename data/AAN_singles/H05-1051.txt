Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 403?410, Vancouver, October 2005. c?2005 Association for Computational LinguisticsDifferentiating Homonymy and Polysemyin Information RetrievalChristopher StokoeSchool of Computing and TechnologyUniversity of SunderlandUKchristopher.stokoe@sunderland.ac.ukAbstractRecent studies into Web retrieval haveshown that word sense disambiguationcan increase retrieval effectiveness.
How-ever, it remains unclear as to the mini-mum disambiguation accuracy requiredand the granularity with which one mustdefine word sense in order to maximizethese benefits.
This study answers thesequestions using a simulation of the effectsof ambiguity on information retrieval.
Itgoes beyond previous studies by differen-tiating between homonymy andpolysemy.
Results show that retrieval ismore sensitive to polysemy than ho-monymy and that, when resolvingpolysemy, accuracy as low as 55% canpotentially lead to increased performance.1 IntroductionLexical ambiguity refers to words that share thesame orthography but have different meanings(word senses).
It can be sub-divided into two dis-tinct types, homonymy and polysemy.
Homonymydescribes when two senses of a given word (orderivation) are distinct.
Typically, they are sepa-rated by etymology and are therefore entirely unre-lated in meaning.
One classic example (Kilgarriff,1992) is ?bat?
as in an airborne mammal (from theMiddle English word ?bakke?
meaning flying ro-dent) vs. ?bat?
as in an instrument used in the gameof cricket (from the Celtic for stick or cudgel).There is no underlying relationship between thesetwo meanings which have come about independ-ently from differing root languages.
Alternatively,polysemy describes where two senses of a wordare related in that they share membership of a sub-suming semantic classification.
Consider the word?mouth?
as in a part of the body vs. ?mouth?
as inthe outlet of a river.
Both meanings are subsumedby a higher concept (in this case they both describean opening).
Homonymy and polysemy are differ-entiated in most dictionaries by the major (homo-nyms) and minor (polysemes) entries for a givenword.
Where a lexical resource is described interms of granularity a coarse-grained approachonly differentiates between homonymy whereas afine-grained approach also considers polysemy.The use of word sense disambiguation in In-formation Retrieval (IR) has been an active field ofstudy for the past 30 years.
Despite several failures(described in Sanderson, 2000) recent studies havebegun to show increased retrieval effectiveness,particularly in Web retrieval.
However, two keyquestions remain: (1) to what accuracy must dis-ambiguation be performed in order to show in-creased retrieval effectiveness and (2) to what levelof granularity should disambiguation be performedin order to maximize these gains?
This study an-swers these questions by simulating the impact ofambiguity and its subsequent resolution on re-trieval effectiveness.2 Related WorkThe motivation for this research is taken from re-cent studies (section 2.1) which have demonstratedincreased retrieval effectiveness by accounting forword sense.
The methodology is derived from pre-vious studies (section 2.2) which model the impactthat ambiguity and its subsequent resolution haveon IR.4032.1 Accounting for Sense in IROne of the first studies to show increased retrievaleffectiveness through resolving ambiguity wasSch?tze and Pederson (1995).
They used clusteringto discriminate between alternate uses of a word.The clusters they produced were apparently fine-grained, although it is not clear if this observationwas made with reference to a particular lexical re-source.
In terms of the accuracy to which theycould discriminate meaning, a limited evaluationusing a 10 word sample demonstrated accuracyapproaching 90%.
Results showed that retrievaleffectiveness increased when documents were in-dexed by cluster as opposed to raw terms.
Per-formance further increased when a word in thecollection was assigned membership of its threemost likely clusters.
However, it is not clear if as-signing multiple senses leads to coarser granularityor simply reduces the impact of erroneous disam-biguation.Stokoe et al (2003) showed increased retrievaleffectiveness through fine-grained disambiguationwhere a word occurrence in the collection was as-signed one of the sense definitions contained inWordNet.
The accuracy of their disambiguationwas reported at 62% based on its performance overa large subset of SemCor (a collection of manuallydisambiguated documents).
It remains unclear howaccuracy figures produced on different collectionscan be compared.
Stokoe et al (2003) did notmeasure the actual performance of their disam-biguation when it was applied to the WT10G (theIR collection used in their experiments).
This high-lights the difficulty involved in quantifying theeffects of disambiguation within an IR collectiongiven that the size of modern collections precludesmanual disambiguation.Finally, Kim et al (2004) showed gains throughcoarse-grained disambiguation by assigning allnouns in the WT10G collection (section 3) mem-bership to 25 top level semantic categories inWordNet (for more detail about the composition ofWordNet see section 4).
The motivation behindcoarse-grained disambiguation in IR is that higheraccuracy is achieved when only differentiating be-tween homonyms.
Several authors (Sanderson,2000; Kim et al, 2004) postulate that fine-graineddisambiguation may not offer any benefits overcoarse-grained disambiguation which can be per-formed to a higher level of accuracy.2.2 The Effects of Ambiguity on IRThe studies described in section 2.1 provide em-pirical evidence of the benefits of disambiguation.Unfortunately, they do not indicate the minimumaccuracy or the optimal level of granularity re-quired in order to bring about these benefits.
Per-haps more telling are studies which have attemptedto quantify the effects of ambiguity on IR.Sanderson (1994) used pseudowords to add ad-ditional ambiguity to an IR collection.
Pseu-dowords (Gale et al, 1992) are created by joiningtogether randomly selected constituent words tocreate a unique term that has multiple controlledmeanings.
Sanderson (1994) offers the example of?banana/kalashnikov?.
This new term features twopseudosenses ?banana?
and ?kalashnikov?
and isused to replace any occurrences of the constituentwords in the collection, thus introducing additionalambiguity.
In his study, Sanderson experimentedwith adding ambiguity to the Reuters collection.Results showed that even introducing largeamounts of additional ambiguity (size 10 pseu-dowords - indicating they had 10 constituents) hadvery little impact on retrieval effectiveness.
Fur-thermore, attempts to resolve this ambiguity withless than 90% accuracy proved extremely detri-mental.Sanderson (1999) acknowledged that pseu-dowords are unlike real words as the random selec-tion of their constituents ensures that thepseudosenses produced are unlikely to be related,in effect only modeling homonymy.
Several stud-ies (Sch?tze, 1998; Gaustad, 2001) suggest thatthis failure to model polysemy has a significantimpact.
Disambiguation algorithms evaluated us-ing pseudowords show much better performancethan when subsequently applied to real words.Gonzalo et al (1998) cite this failure to model re-lated senses in order to explain why their studyinto the effects of ambiguity showed radically dif-ferent results to Sanderson (1994).
They performedknown item retrieval on 256 manually disambigu-ated documents and showed increased retrievaleffectiveness where disambiguation was over 60%accurate.
Whilst Sanderson?s results no longer fitthe empirical data, his pseudoword methodologydoes allow us to explore the effects of ambiguitywithout the overhead of manual disambiguation.Gaustad (2001) highlighted that the challenge liesin adapting pseudowords to account for polysemy.404Krovetz (1997) performed the only study todate which has explicitly attempted to differentiatebetween homonymy and polysemy in IR.
Using theLongmans dictionary he grouped related sensesbased on any overlap that existed between twosense definitions for a given word.
His results sup-port the idea that grouping together related sensescan increase retrieval effectiveness.
However, thestudy does not contrast the relative merits of thistechnique against fine-grained approaches, thushighlighting that the question of granularity re-mains open.
Which is the optimal approach?Grouping related senses or attempting to makefine-grained sense distinctions?3 Experimental SetupThe experiments in this study use the WT10G cor-pus (Hawking and Craswell, 2002), an IR web testcollection consisting of 1.69 million documents.There are two available Query / Relevance Judg-ments sets each consisting of 50 queries.
Thisstudy uses the TREC 10 Web Track Ad-Hoc queryset (NIST topics 501 ?
550).
The relevance judg-ments for these queries were produced using pool-ing based on the top 100 ranked documentsretrieved by each of the systems that participated inthe TREC 10 Web Track.Initially the author produced an index of theWT10G and performed retrieval on this unmodi-fied collection in order to measure baseline re-trieval effectiveness.
The ranking algorithm waslength normalized TF.IDF (Salton and McGill,1983) which is comparable to the studies in section2.
Next, two modified versions of the collectionwere produced where additional ambiguity in theform of pseudowords had been added.
The firstused pseudowords created by selecting constituentpseudosenses which are unrelated, thus introducingadditional homonymy.
The second used a newmethod of generating pseudowords that exhibitpolysemy (the methodology is described in section4.1).
Contrasting retrieval performance over thesethree indexes quantifies the relative impact of bothhomonymy and polysemy on retrieval effective-ness.
The final step was to measure the effects ofattempting to resolve the additional ambiguitywhich had been added to the collection.
In order todo this, the author simulated disambiguation tovarying degrees of accuracy and measured the im-pact that this had on retrieval effectiveness.4 MethodologyTo date only Nakov and Hearst (2003) have lookedinto creating more plausible pseudowords.
Work-ing with medical abstracts (MEDLINE) and thecontrolled vocabulary contained in the MESH hi-erarchy they created pseudosense pairings that arerelated.
By identifying pairs of MESH subjectcategories which frequently co-occurred and se-lecting constituents for their pseudowords fromthese pairings they produced a disambiguation testcollection.
Their results showed that categorybased pseudowords provided a more realistic testdata set for disambiguation, in that evaluation us-ing them more closely resembled real words.
Thechallenge in this study lay in adapting these ideasfor open domain text.4.1 Pseudoword GenerationThis study used WordNet (Miller et al, 1990) toinform the production of pseudowords.
WordNet(2.0) is a hierarchical semantic network developedat Princeton University.
Concepts in WordNet arerepresented by synsets and links between synsetsrepresent hypernmy (subsumes) and hyponymy(subsumed) relationships in order to form a hierar-chical structure.
A unique word sense consists of alemma and the particular synset in which thatlemma occurs.
WordNet is a fine-grained lexicalresource and polysemy can be derived to varyingdegrees of granularity by traversing the link struc-ture between synsets (figure 1).Figure 1.
A Subsection of the Noun Hierarchyin WordNet405An important feature of pseudowords is thenumber of constituents as this controls the amountof additional ambiguity created.
A feature of allprevious studies is that they generate pseudowordswith a uniform number of constituents, e.g.
size 2,size 5 or size 10, thus introducing uniform levels ofadditional ambiguity.
It is clear that such an ap-proach does not reflect real words given that theydo not exhibit uniform levels of ambiguity.
Theapproach taken in this study was to generate pseu-dowords where the number of constituents wasvariable.
As each of the pseudowords in this studycontain one query word from the IR collection thenthe number of constituents was linked directly tothe number of senses of that word contained inWordNet.
This effectively doubles the level of am-biguity expressed by the original query word.
If aquery word was not contained in WordNet thenthis was taken to be a proper name and exemptedfrom the process of adding ambiguity.
It was feltthat to destroy any unambiguous proper names,which might act to anchor a query, would dramati-cally overstate the effects of ambiguity in terms ofthe IR simulation.
The average size of the pseu-dowords produced in these experiments was 6.4pseudosenses.When producing the traditional pseudowordbased collection the only modification to Sander-son?s (1994) approach (described in section 2),other than the variable size, involved formalizinghis observation that the constituent words wereunlikely to be related.
Given access to WordNet itwas possible to guarantee that this is the case byrejecting constituents which could be linkedthrough its inheritance hierarchy.
This ensures thatthe pseudowords produced only display ho-monymy.In order to produce pseudowords that modelpolysemy it was essential to devise a method forselecting constituents that have the property of re-latedness.
The approach taken was to deliberatelyselect constituent words that could be linked to asense of the original query word through WordNet.Thus the additional ambiguity added to the collec-tion models any underlying relatedness expressedby the original senses of the query word.
Pseu-dowords produced in this way will now be referredto as root pseudowords as this reflects that the am-biguity introduced is modeled around one rootconstituent.
Consider the following worked exam-ple for the query ?How are tornadoes formed?
?After the removal of stopwords we are left with?tornadoes?
and ?formed?
each of which is thentransformed into a root pseudoword.
The first stepinvolves identifying any potential senses of thetarget word from WordNet.
If we consider theword ?tornado?
it appears in two synsets:1. tornado, twister -- (a localized and violentlydestructive windstorm occurring over landcharacterized by a funnel-shaped cloud ex-tending toward the ground)2. crack, tornado -- (a purified and potent formof cocaine that is smoked rather than snorted)For each sense of the target word the system ex-pands WordNet?s inheritance hierarchy to producea directed graph of its hypernyms.
Figure 2 showsan example of this graph for the first sense of theword ?tornado?.
In order to ensure a related sensepair the system builds a pool of words which aresubsumed by concepts contained in this graph.This is generated by recursively moving up thehierarchy until the pool contains at least one viablecandidate.
For a candidate to be viable it must meetthe following criteria:1) It must exist in the IR collection.2) It must not be part of another pseudoword.3) It can not be linked (through WordNet) toanother constituent of the pseudoword.The pool for sense 1 of ?tornado?
consists of [hur-ricane|typhoon], one of which is selected at ran-dom.Figure 2.
A Graph of the Hypernyms for theFirst Sense of the Word ?tornado?406This process is repeated for each noun and verbsense of the query word.
In this example there isone remaining sense of the word ?tornado?
- aslang term used to refer to the drug crack cocaine.For this sense the system produced a pool consist-ing of [diacetylemorphine|heroin].
Once all sensesof the query word have been expanded the result-ing pseudoword, ?tornadoes/hurricane/heroin?, isthen used to replace all occurrences of its constitu-ents within the collection.
Through this process thesystem produces pseudowords with pseudosensepairings which have subsuming relationships, e.g.?tornadoes/hurricane?
are subsumed by the highercategory of ?cyclone?
whilst ?tornadoes/heroin?
aresubsumed by the higher semantic category of?hard_drug?.4.2 Pseudo-disambiguationIn order to perform pseudo-disambiguation theunmodified collection acts as a gold standardmodel answer.
Through reducing each instance ofa pseudoword back to one of its constituent com-ponents this models the selection process made bya disambiguation system.
Obviously, the correctpseudosense for a given instance is the originalword which appeared at that point in the collection.Variable levels of accuracy are introduced using aweighted probability model where the correctpseudosense for a given test instance is seededwith a fixed probability equivalent to the desiredaccuracy being simulated.
When a disambiguationerror is simulated one of the incorrect pseu-dosenses is selected randomly.5 ResultsThe first set of results (section 5.1) addresses thequestion of granularity by quantifying the impactthat adding either additional homonymy orpolysemy has on retrieval effectiveness.
The sec-ond set of results (section 5.2) looks at the questionof disambiguation accuracy by simulating the im-pact that varied levels of accuracy have on retrievaleffectiveness.5.1 Homonymy vs. PolysemyLet us first consider the impact of adding addi-tional homonymy.
Figure 3 graphs precision acrossthe 11 standard points of recall for retrieval fromboth the baseline collection and one where addi-tional homonymy has been added.
Note that theintroduction of additional homonymy brings abouta small drop in retrieval effectiveness.
With regardto the single value measures contained in table 1,this is a decrease of 2.5% in terms of absolute R-Precision (average precision after the total numberof known relevant documents in the collection hasbeen retrieved).
This is a relative decrease of14.3%.
Similar drops in both precision@10 (preci-sion after the first 10 documents retrieved) andaverage precision are also seen.Next let us consider retrieval effectiveness overthe root pseudoword collection where additionalpolysemy has been added (figure 4).
Note that theintroduction of additional polysemy has a moresubstantive impact upon retrieval effectiveness.
Interms of R-Precision this decrease is 5.3% in abso-lute terms, a relative decrease of 30% compared tobaseline retrieval from the unmodified collection.In addition, an even larger decrease in preci-sion@10 occurs where the introduction of addi-tional polysemy brings about a 7% drop in retrievaleffectiveness.In terms of the relative effects of homonymyand polysemy on retrieval effectiveness then notethat adding additional polysemy has over doublethe impact of adding homonymy.
This provides aclear indication that the retrieval process is moresubstantially affected by polysemy than ho-monymy.00.10.20.30.40.50 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1RecallPrecisionBaselineHomonymyFigure 3.
Precision across the 11 Standard Pointsof Recall for the Baseline and the Collection Con-taining Additional Homonymy40700.10.20.30.40.50 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1RecallPrecisionBaselinePolysemy5.2 The Impact of DisambiguationWe now address the second part of the researchquestion: to what accuracy should disambiguationbe performed in order to enhance retrieval effec-tiveness?
Figure 5 plots the impact, in terms of R-Precision, of performing disambiguation to varyingdegrees of accuracy after additional homonymyhas been added to the collection.
The dotted linerepresents the breakeven point, with R-Precisionbelow this line indicating reduced performance asa result of disambiguation.
Results show thatwhere additional homonymy has been added to thecollection disambiguation accuracy at or above76% is required in order for disambiguation to beof benefit.
Performing disambiguation which isless than 76% accurate leads to lower performancethan if the additional homonymy had been left un-resolved.Moving on to consider the root pseudowordcollection (figure 6) note that the breakeven pointis only 55% where additional polysemy has beenadded.
Consider that the results in section 5.1showed that the introduction of additionalpolysemy had over double the impact of introduc-ing additional homonymy.
This is reflected in therelative effects of disambiguation in that the break-even point is considerably lower for polysemy thanhomonymy.0.10.110.120.130.140.150.160.170.18100% 90% 80% 70% 60% 50% 40%Disambiguation AccuracyR-Precision0.10.110.120.130.140.150.160.170.18100% 90% 80% 70% 60% 50% 40%Disambiguation AccuracyR-Precision6 DiscussionThe results in section 5.1 show that retrieval effec-tiveness is more sensitive to polysemy than ho-monymy.
One explanation for this can beR-Precision Precision@10Avg.PrecisionBaseline 0.1732 0.2583 0.1334Homonymy 0.1485 0.2208 0.1145Polysemy 0.1206 0.1875 0.0951Figure 4.
Precision across the 11 Standard Pointsof Recall for the Baseline and the Collection Con-taining Additional PolysemyTable 1.
R-Precision, Precision@10 and Aver-age Precision for all Three Versions of theCollectionFigure 5.
The Impact of Disambiguation on Effec-tiveness after the Addition of Homonymy(Note the dashed line is the breakeven point)Figure 6.
The Impact of Disambiguation on Effec-tiveness after the Addition of Polysemy(Note the dashed line is the breakeven point)408hypothesized from previous studies (Krovetz andCroft, 1992; Sanderson and Van Rijsbergen, 1999)which highlight the importance of co-occurrencebetween query words.
Where two (or more) wordsappear together in a query, statistical retrieval in-herently performs some element of disambigua-tion.
However, in the case of a word with manyclosely related senses, co-occurrence betweenquery words may not be sufficient for a givensense to become apparent.
This is particularly ex-asperated in Web retrieval given that the averagequery length in these experiments was 2.9 words.Clearly, the inherent disambiguation performed bystatistical IR techniques is sensitive to polysemy inthe same way as systems which explicitly performdisambiguation.With regard to disambiguation accuracy and IR(section 5.2) these experiments establish that per-formance gains begin to occur where disambigua-tion is between 55% and 76%.
Where within thisrange the actual breakeven point lies is dependenton the granularity of the disambiguation and thebalance between polysemy and homonymy in agiven collection.
Consider that coarse-grained dis-ambiguation is frequently advocated on the basisthat it can be performed more accurately.
Whilstthis is undoubtedly true these results suggest thathomonymy has to be resolved to a much higherlevel of accuracy than polysemy in order to be ofbenefit in IR.It would seem prudent to consider the results ofthis study in relation to the state-of-the-art in dis-ambiguation.
At Senseval-3 (Mihalcea et al, 2004)the top systems were considered to have reached aceiling, in terms of performance, at 72% for fine-grained disambiguation and 80% for coarse-grained.
When producing the English language testcollections the rate of agreement between humansperforming manual disambiguation was approxi-mately 74%.
This suggests that machine disam-biguation has reached levels comparable to theperformance of humans.
In parallel with this the IRcommunity has begun to report increased retrievaleffectiveness through explicitly performing disam-biguation to varying levels of granularity.A final point of discussion is the way in whichwe simulate disambiguation both in this study andthose previously (Sanderson, 1994; Gonzalo et al,1998).
There is growing evidence (Leacock et al,1998; Agirre and Martinez, 2004) to suggest thatsimulating uniform rates of accuracy and erroracross both words and senses may not reflect theperformance of modern disambiguation systems.Supervised approaches are known to exhibit inher-ent bias that exists in their training data.
Examplesinclude Zipf?s law (Zipf, 1949) which denotes thata small number of words make up a large percent-age of word use and Krovetz and Croft?s (1992)observation that one sense of a word accounts forthe majority of all use.
It would seem logical topresume that supervised systems show their bestperformance over the most frequent senses of themost frequent words in their training data.
Notenough is known about the potential impact ofthese biases to allow for them to be incorporatedinto this simulation.
Still, it should be noted thatStokoe et al (2003) utilized frequency statistics intheir disambiguator and that a by-product ofSch?tze and Pederson?s (1992) approach was thatthey eliminated infrequently observed senses.There is supporting evidence from Sanderson andVan Rijsbergen (1999) to suggest that accountingfor this frequency bias is in some way advanta-geous.
Therefore, it is worth considering that simu-lating a uniform accuracy and error rate across allwords and senses might actually offer a pessimisticpicture of the potential for disambiguation and IR.Whilst this merits further study, the focus of thisresearch was contrasting the relative effects of twotypes of ambiguity and both models were subjectto the same uniform disambiguation.7 ConclusionsThis study has highlighted that retrieval systemsare more sensitive to polysemy than homonymy.This leads the author to conclude that making fine-grained sense distinctions can offer increased re-trieval effectiveness in addition to any benefitsbrought about by coarse-grained disambiguation.
Italso emphasises that although coarse-grained dis-ambiguation can be performed to a higher degreeof accuracy, this might not directly translate to in-creased IR performance compared to fine-grainedapproaches.
This is in contrast to current thinkingwhich suggests that coarse-grained approaches aremore likely to bring about retrieval performancebecause of their increased accuracy.In terms of disambiguation accuracy and in-creased retrieval effectiveness, results show poten-tial benefits where accuracy is as low as 55% whendealing with just polysemy and rises to 76% when409dealing with just homonymy.
Obviously this studyhas simulated two extremes (polysemy or ho-monymy) and the exact point where performanceincreases will occur is likely to be dependent onthe interaction between homonymy and polysemyin a given query.With regard to simulation a more empirical ex-ploration of the ideas expressed in this work wouldbe desirable.
However, the size of modern IR testcollections dictates that future studies will need torely more heavily on simulation.
Therefore, untilsuch time that a significant manually disambigu-ated IR collection exists pseudowords remain aninteresting way to explore the effects of ambiguitywithin a large collection.
The challenge lies in pro-ducing pseudowords that better model real words.ReferencesAgirre E. and Martinez D. 2004.
Unsupervised WSDbased on automatically retrieved examples: the im-portance of bias, in Proceedings of the Conferenceon Empirical Methods in Natural Language Process-ing (EMNLP).
Barcelona, Spain.Gale, W; Church, K. W; Yarowsky, D. 1992 Work onStatistical Methods for Word Sense Disambiguation,in Intelligent Probabilistic Approaches to NaturalLanguage Papers,  AAAI Press, Pp.
54 ?
60.Gaustad, T. 2001.
Statistical Corpus-based Word SenseDisambiguation: Pseudowords vs. Real AmbiguousWords, in Companion Volume to the Proceedings ofthe 36th annual meeting of the ACL, Toulouse,France.
Proceedings of the Student Research Work-shop, ACL Press, Pp.
61 ?
66.Gonzalo, J; Verdejo, F; Chugur, I; Cigarran, J.
1998.Indexing with WordNet Synsets Can Improve TextRetrieval, in Proceedings of COLING / ACL ?98Workshop on the Usage of WordNet for NLP, Mont-real, Canada, ACL Press, Pp.
38 ?
44.Hawking, D and Craswell, N. 2002.
Overview of theTREC-2001 Web Track, in Proceedings of the 10thText REtrieval Conference, Gaithersburg, MD.
NISTSpecial Publication 500-250, Pp.
61 ?
67.Kilgarriff, A.
1992.
Polysemy, Ph.D. Thesis, School ofCognitive and Computing Sciences, University ofSussex, Report CSRP 261Kim, S; Seo, H; Rim, H. 2004.
Information RetrievalUsing Word Senses: Root Sense Tagging Approach,in Proceedings of the 27th ACM SIGIR, Sheffield,UK.
Pp.
258 ?
265.Krovetz, R and Croft, W. B.
1992.
Lexical Ambiguityand Information Retrieval, ACM Transactions on In-formation Systems, 10(2), Pp.
115 ?
141.Krovetz, R 1997.
Homonymy and Polysemy in Informa-tion Retrieval, NEC Institute, Princeton.Leacock, C; Chodorow, M; Miller, G. A.
1998 UsingCorpus Statistics and WordNet Relations for SenseIdentification.
Computational Linguistics, 24(1), Pp.147 ?
165.Mihalcea, R; Chklovski, T; Kilgarriff, A.
2004.
TheSenseval-3 English Lexical Sample Task, in Proceed-ings of the 3rd International Workshop on the Evalua-tion of Systems for the Semantic Analysis of Text,Barcelona, Spain, Pp.
25 ?
28.Miller, G; Beckwith, R; Fellbaum, C; Gross, D; Miller,K.
1990.
WordNet: An On-line Lexical Database, In-ternational journal of lexicography, 3(4), OxfordUniversity Press, Pp 235 ?
244.Nakov, P. and Hearst , M. 2003.
Category-based Pseu-dowords, in Proceedings of the Human LanguageTechnology Conference (HLT-NAACL 2003), Ed-monton.
Pp.
67?69.Salton G and McGill, M. J.
1983.
Introduction to Mod-ern Information Retrieval, McGraw-Hill.Sanderson, M. 1994.
Word Sense Disambiguation andInformation Retrieval, in Proceedings of the 17thACM SIGIR, Dublin, Ireland, ACM Press, Pp.
142 ?151.Sanderson, M and Van Rijsbergen, C. J.
1999.
The Im-pact on Retrieval Effectiveness of Skewed FrequencyDistributions, ACM Transactions in Information Sys-tems 17(4), ACM Press, Pp.
440 ?
465.Sanderson, M. 2000.
Retrieving with Good Sense inInformation Retrieval 2(1), Kluwer AcademicPublishing, Pp.
49 ?
69.Sch?tze, H. 1998.
Automatic Word Sense Disambigua-tion, Computational Linguistics 24(1), Pp.
113-120.Sch?tze, H and Pederson, J. O.
1995.
Information Re-trieval Based on Word Senses, in Proceedings of the4th Symposium on Document Analysis and Informa-tion Retrieval, Pp.
161 -175.Stokoe, C. M; Oakes, M J; Tait, J I.
2003.
Word SenseDisambiguation in Information Retrieval Revisited inProceedings of the 26th ACM SIGIR, Toronto, Can-ada, Pp.
159 ?
166.Zipf, G. K. 1949.
Human Behavior and the Principle ofLeast-Effort, Cambridge MA, U.S.A., Addison-Wesley410
