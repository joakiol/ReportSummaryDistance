Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 108?111,Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLPA Hybrid Approach to English-Korean Name TransliterationGumwon Hong?, Min-Jeong Kim?, Do-Gil Lee+ and Hae-Chang Rim?
?Department of Computer Science & Engineering, Korea University, Seoul 136-713, Korea{gwhong,mjkim,rim}@nlp.korea.ac.kr+Institute of Korean Culture, Korea University, Seoul 136-701, Koreamotdg@korea.ac.krAbstractThis paper presents a hybrid approach toEnglish-Korean name transliteration.
Thebase system is built on MOSES with en-abled factored translation features.
Weexpand the base system by combiningwith various transliteration methods in-cluding a Web-based n-best re-ranking, adictionary-based method, and a rule-basedmethod.
Our standard run and best non-standard run achieve 45.1 and 78.5, re-spectively, in top-1 accuracy.
Experimen-tal results show that expanding trainingdata size significantly contributes to theperformance.
Also we discover that theWeb-based re-ranking method can be suc-cessfully applied to the English-Koreantransliteration.1 IntroductionOften, named entities such as person names orplace names from foreign origin do not appear inthe dictionary, and such out of vocabulary wordsare a common source of errors in processing nat-ural languages.
For example, in statistical ma-chine translation (SMT), if a new word occursin the input source sentence, the decoder will atbest drop the unknown word or directly copy thesource word to the target sentence.
Transliteration,a method of mapping phonemes or graphemes ofsource language into those of target language, canbe used in this case in order to identify a possibletranslation of the word.The approaches to automatic transliteration be-tween English and Korean can be performedthrough the following ways: First, in learning howto write the names of foreign origin, we can re-fer to a transliteration standard which is estab-lished by the government or some official linguis-tic organizations.
No matter where the standardcomes from, the basic principle of the standardis based on the correct pronunciation of foreignwords.
Second, since constructing such rules arevery costly in terms of time and money, we canrely on a statistical method such as SMT.
We be-lieve that the rule-based method can guarantee toincrease accuracy for known cases, and the statis-tical method can be robust to handle various ex-ceptions.In this paper, we present a variety of tech-niques for English-Korean name transliteration.First, we use a phrase-base SMT model with somefactored translation features for the transliterationtask.
Second, we expand the base system by ap-plying Web-based n-best re-ranking of the results.Third, we apply a pronouncing dictionary-basedmethod to the base system which utilizes the pro-nunciation symbols which is motivated by linguis-tic knowledge.
Finally, we introduce a phonics-based method which is originally designed forteaching speakers of English to read and write thatlanguage.2 Proposed ApproachIn order to build our base system, we use MOSES(Koehn et al, 2007), a well-known phrase-basedsystem designed for SMT.
MOSES offers a con-venient framework which can be directly appliedto machine transliteration experiments.
In thisframework, the transliteration can be performedin a very similar process of SMT task except thefollowing changes.
First, the unit of translationis changed from words to characters.
Second, aphrase in transliteration refers to any contiguousblock of character sequence which can be directlymatched from a source word to a target word.Also, we do not have to worry about any distortionparameters because decoding can be performed ina totally monotonic way.The process of the general transliteration ap-proach begins by matching the unit of a source108LetterAlignmentBilingual CorpusFactored Phrase-based TrainingTrained ModelEumjeolDecomposition MOSESDecoderInput WordEumjeolRe-compositionTarget WordEumjeolDecompositionN-bestRe-rankingWebDictionaryPhonicsFigure 1: System Architectureword to the unit of a target word.
The unit can bebased on graphemes or phonemes, depending onlanguage pairs or approaches.
In English-Koreantransliteration, both grapheme-to-grapheme andgrapheme-to-phoneme approaches are possible.
Inour method, we select grapheme-to-grapheme ap-proach as a base system, and we apply grapheme-to-phoneme functions in pronouncing dictionary-based approach.The transliteration between Korean and otherlanguages requires some special preprocessingtechniques.
First of all, Korean alphabet is or-ganized into syllabic blocks called Eumjeol.
Ko-rean transliteration standard allows each Eumjeolto consist of either two or three of the 24 Koreanletters, with (1) leading 14 consonants, (2) inter-mediate 10 vowels, and (3) optionally, trailing 7consonants (out of the possible 14).
Therefore,Korean Eumjeol should be decomposed into lettersbefore performing training or decoding any input.Consequently, after the letter-unit transliteration isfinished, all the letters should be re-composed toform a correct sequence of Eumjeols.Figure 1 shows the overall architecture of oursystem.
The alignment between English letter andKorean letter is performed using GIZA++ (Ochand Ney, 2003).
We use MOSES decoder in or-der to search the best sequence of transliteration.In this paper we focus on describing factoredphrase-based training and n-best re-ranking tech-niques including a Web-based method, a pro-nouncing dictionary-based method, and a phonics-based method.Figure 2: Alignment example between ?Knight?and ?s??
[naiteu]?2.1 Factored Phrase-based TrainingKoehn and Hoang (2007) introduces an integrationof different information for phrase-based SMTmodel.
We report on experiments with three fac-tors: surface form, positional information, andthe type of a letter.
Surface form indicates aletter itself.
For positional information, we adda BIO label to each input character in both thesource words and the target words.
The intuition isthat certain character is differently pronounced de-pending on its position in a word.
For example, ?k?in ?Knight?
or ?h?
in ?Sarah?
are not pronounced.The type of a letter is used to classify whether agiven letter is a vowel or a consonant.
We assumethat a consonant in source word would more likelybe linked to a consonant in a target word.
Figure 2shows an example of alignment with factored fea-tures.2.2 Web-based Re-rankingWe re-ranked the top n results of the decoder byreferring to how many times both source word andtarget word co-occur on the Web.
In news articleson the Web, a translation of a foreign name is of-ten provided near the foreign name to describe itspronunciation or description.
To reflect this obser-vation, we use Google?s proximity search by re-stricting two terms should occur within four-worddistance.
The frequency is adjusted as relative fre-quency form by dividing each frequency by totalfrequency of all n-best results.Also, we linearly interpolate the n-best scorewith the relative frequency of candidate output.
Tomake fair interpolation, we adjust both scores to bebetween 0 and 1.
Also, in this method, we decideto remove all the candidates whose frequencies arezero.2.3 Pronouncing Dictionary-based MethodAccording to ?Oeraeeo pyogibeop1?
(Korean or-thography and writing method of borrowed for-1http://www.korean.go.kr/08 new/data/rule03.jsp109Methods Acc.1 Mean F1 Mean Fdec MRR MAPref MAP10 MAPsysBS 0.451 0.720 0.852 0.576 0.451 0.181 0.181ER 0.740 0.868 0.930 0.806 0.740 0.243 0.243WR 0.784 0.889 0.944 0.840 0.784 0.252 0.484PD 0.781 0.885 0.941 0.839 0.781 0.252 0.460PB 0.785 0.887 0.943 0.840 0.785 0.252 0.441Table 1: Experimental Results (EnKo)eign words), the primary principle of English-to-Korean transliteration is to spell according to themapping table between the international phoneticalphabets and the Korean alphabets.
Therefore,we can say that a pronouncing dictionary-basedmethod is very suitable for this principle.We use the following two resources for build-ing a pronouncing dictionary: one is an English-Korean dictionary that contains 130,000 words.The other is the CMU pronouncing dictionary2created by Carnegie Mellon University that con-tains over 125,000 words and their transcriptions.Phonetic symbols for English words in thedictionaries are transformed to their pronuncia-tion information by using an internal code table.The internal code table represents mappings fromeach phonetic symbol to a single character withinASCII code table.
Our pronouncing dictionary in-cludes a list of words and their pronunciation in-formation.For a given English word, if the word existsin the pronouncing dictionary, then its pronunci-ations are translated to Korean graphemes by amapping table and transformation rules, which aredefined by ?Oeraeeo pyogibeop?.2.4 Phonics-based MethodPhonics is a pronunciation-based linguistic teach-ing method, especially for children (Strickland,1998).
Originally, it was designed to connect thesounds of spoken English with group of Englishletters.
In this research, we modify the phonicsin order to connect English sounds to Korean let-ter because in Korean there is nearly a one-to-onecorrespondence between sounds and the letter pat-terns that represent them.
For example, alpha-bet ?b?
can be pronounced to ??
(bieup) in Ko-rean.
Consequently, we construct about 150 ruleswhich map English alphabet into one or more sev-eral Korean graphemes, by referring to the phon-ics.
Though phonics cannot reveal all of the pro-2http://www.speech.cs.cmu.edu/cgi-bin/cmudictnunciation of English words, the conversion fromEnglish alphabet into Korean letter is performedsimply and efficiently.
We apply the phonics inserial order from left to right of each input word.If multiple rules are applicable, the most specificrules are fist applied.3 Experiments3.1 Experimental SetupWe participate in both standard and non-standardtracks for English-Korean name transliteration inNEWS 2009 Machine Transliteration Shared Task(Li et al, 2009).
Experimenting on the develop-ment data, we determine the best performing pa-rameters for MOSES as follows.?
Maximum Phrase Length: 3?
Language Model N-gram Order: 3?
Language Model Smoothing: Kneser-Ney?
Phrase Alignment Heuristic: grow-diag-final?
Reordering: Monotone?
Maximum Distortion Length: 0With above parameter setup, the results are pro-duced from the following five different systems.?
Baseline System (BS): For the standard task,we use only given official training data 3 to con-struct translation model and language model forour base system.?
Expanded Resource (ER): For all four non-standard tasks, we use the examples of writing for-eign names as additional training data.
The ex-amples are provided from the National Institute ofthe Korean Language4.
The data originally con-sists of around 27,000 person names and around7,000 place names including non-Ascii charactersfor English side words as well as duplicate entries.We preprocess the data in order to use 13,194 dis-3Refer to Website http://www.cjk.org for more informa-tion4The resource is open to public.
Seehttp://www.korean.go.kr/eng for more information.110tinct pairs of English names and Korean transliter-ation.?
Web-based Re-ranking (WR): We re-rank theresult of ER by applying the method described insection 2.2.?
Pronouncing Dictionary-based Method (PD):The re-ranking of WR by combining with themethod described in section 2.3.?
Phonics-based Method (PB): The re-rankingof WR by combining with the method described insection 2.4.The last two methods re-rank the WR methodby applying pronouncing dictionary-based methodand Phonics-based method.
We restrict thatthe pronouncing dictionary-based method andPhonics-based method can produce only one out-put, and use the outputs of the two methods to re-rank (again) the result of Web-based re-ranking.When re-ranking the results, we heuristically com-bined the outputs of PD or PB with the n-best re-sult of WR.
If the outputs of the two methods existin the result of WR, we add some positive scores tothe original scores of WR.
Otherwise, we insertedthe result into fixed position of the rank.
The fixedposition of rank is empirically decided using de-velopment set.
We inserted the output of PD andPB at second rank and at sixth rank, respectively.3.2 Experimental ResultsTable 1 shows our experimental results of the fivesystems on the test data.
We found that the useof additional training data (ER) and web-based re-ranking (WR) have a strong effect on translitera-tion performance.
However, the integration of thePD or PB with WB proves not to significantly con-tribute the performance.
To find more elaborateintegration of those results will be one of our fu-ture work.The MAPsys value of the three re-rankingmethods WR, PD, and PB are relatively higherthan other methods because we filter out somecandidates in n-best by their Web frequencies.
Inaddition to the standard evaluation measures, weinclude the Mean Fdec to measure the Levenshteindistance between reference and the output of thedecoder (decomposed result).4 ConclusionsIn this paper, we proposed a hybrid approach toEnglish-Korean name transliteration.
The systemis built on MOSES with factored translation fea-tures.
When evaluating the proposed methods,we found that the use of additional training datacan significantly outperforms the baseline system.Also, the experimental result of using three n-bestre-ranking techniques shows that the Web-basedre-ranking is proved to be a useful method.
How-ever, our two integration methods with dictionary-based or rule-based method does not show the sig-nificant gain over the Web-based re-ranking.For future work, we plan to devise more elab-orate way to integrate statistical method and dic-tionary or rule-based method to further improvethe transliteration performance.
Also, we will ap-ply the proposed techniques to possible applica-tions such as SMT or Cross Lingual InformationRetrieval.ReferencesPhilipp Koehn and Hieu Hoang.
2007.
Factored trans-lation models.
In Proceedings of the 2007 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning (EMNLP-CoNLL), pages 868?876,Prague, Czech Republic, June.
Association for Com-putational Linguistics.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondr?ej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: OpenSource Toolkit for Statistical Machine Translation.In ACL 2007, Demo and Poster Sessions, June.Haizhou Li, A Kumaran, Min Zhang, and VladimirPervouchine.
2009.
Whitepaper of news 2009machine transliteration shared task.
In Proceed-ings of ACL-IJCNLP 2009 Named Entities Work-shop (NEWS 2009), Singapore.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29.D.S.
Strickland.
1998.
Teaching phonics today: Aprimer for educators.
International Reading Asso-ciation.111
