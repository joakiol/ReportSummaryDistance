Japanese Unknown Word Identification by Character-based ChunkingMasayuki Asahara and Yuji MatsumotoGraduate School of Information ScienceNara Institute of Science and Technology, Japan{masayu-a,matsu}@is.naist.jpAbstractWe introduce a character-based chunking for un-known word identification in Japanese text.
A majoradvantage of our method is an ability to detect lowfrequency unknown words of unrestricted charactertype patterns.
The method is built upon SVM-basedchunking, by use of character n-gram and surround-ing context of n-best word segmentation candidatesfrom statistical morphological analysis as features.It is applied to newspapers and patent texts, achiev-ing 95% precision and 55-70% recall for newspa-pers and more than 85% precision for patent texts.1 IntroductionJapanese and Chinese sentences are written withoutspaces between words.
A word segmentation pro-cess is a prerequisite for natural language process-ing (NLP) of non-segmented language family.
Sta-tistical morphological analyzers are often used forword segmentation in Japanese NLP, which achieveover 96% precision.
However, unknown word pro-cessing still remains an issue to be addressed inthose morphological analyzers.
Unknown wordprocessing in non-segmented languages are morechallenging, as it first needs to identify boundariesof unknown words in texts, prior to assignment ofcorrespoinding part-of-speech.Unknown word processing in morphologicalanalysis of non-segmented language can follow oneof either approaches: modular or embedded.
Inthe modular approach, a separate off-line moduleis used to extract unknown words from text (Mori1996; Ikeya 2000).
They are checked and added tothe lexicon of morphological analyzers.
In the em-bedded approach, an on-line module which statisti-cally induces the likelihood of a particular string be-ing a word is embedded in a morphological analyzer(Nagata, 1999; Uchimoto et al, 2001).
A modularapproach is generally preferable in practice, sinceit allows developers to maintain a high quality lex-icon which is crucial for good performance.
Previ-ous work of the modular approach was either un-able to detect low frequency unknown words (Mori1996) or limited to predefined character patterns forlow frequency unknown words (Ikeya 2000).We propose a general-purpose unknown wordidentification based on character-based chunking inorder to address these shortcomings.
A cascademodel of a morphological analyzer (trained withMarkov Model) and a chunker (trained with Sup-port Vector Machines) is applied.
The morpho-logical analyzer produces n-best word segmenta-tion candidates, from which candidate segmentationboundaries, character n-gram and surrounding con-texts are extracted as features for each character.The chunker determines the boundaries of unknownwords based on the features.The rest of this paper is as follows.
We describeour method in Section 2, and present experimentalresults on newspaper articles and patent text in Sec-tion 3.
Related work is provided in Section 4, and asummary and future directions are given in Section5.2 MethodWe describe our method for unknown word identifi-cation.
The method is based on the following threesteps:1.
A statistical morphological analyzer is appliedto the input sentence and produces n-best seg-mentation candidates with their correspoindingpart-of-speech (POS).2.
Features for each character in the sentence areannotated as the character type and multiplePOS tag information according to the n-bestword candidates.3.
Unknown words are identified by a supportvector machine (SVM)-based chunker basedon annotated features.Now, we illustrate each of these three steps inmore detail.2.1 Japanese Morphological AnalysisJapanese morphological analysis is based onMarkov model.
The goal is to find the word andPOS tag sequences W and T that maximize the fol-lowing probability:T = argmaxW,TP (T |W ).Bayes?
rule allows P (T |W ) to be decomposed asthe product of tag and word probabilities.argmaxW,TP (T |W ) = argmaxW,TP (W |T )P (T ).We introduce approximations that the word prob-ability is conditioned only on the tag of the word,and the tag probability is determined only by the im-mediately preceding tag.
The probabilities are esti-mated from the frequencies in tagged corpora usingMaximum Likelihood Estimation.
Using these pa-rameters, the most probable tag and word sequencesare determined by the Viterbi algorithm.In practice, we use log likelihood as cost.
Max-imizing probabilities means minimizing costs.
Re-dundant analysis outputs in our method mean thetop n-best word candidates within a certain costwidth.
The n-best word candidates are picked upfor each character in the ascending order of the ac-cumulated cost from the beginning of the sentence.Note that, if the difference between the costs ofthe best candidate and n-th best candidate exceedsa predefined cost width, we abandon the n-th bestcandidate.
The cost width is defined as the lowestprobability in all events which occur in the train-ing data.
We use ChaSen 1 as the morphologicalanalyzer.
ChaSen induces the n-best segmentationwithin a user-defined width.2.2 Feature for ChunkingThere are two general indicators of unknown wordsin Japanese texts.
First, they have highly ambiguousboundaries.
Thus, a morphological analyzer, whichis trained only with known words, often produces aconfused segmentation and POS assignment for anunknown word.
If we inspect the lattice built duringthe analysis, subgraphs around unknown words areoften dense with many equally plausible paths.
Weintend to reflect this observation as a feature and dothis by use of n-best candidates from the morpho-logical analyzer.
As shown Figure 1, each charac-ter (Char.)
in an input sentence is annotated with a1http://chasen.naist.jp/feature encoded as a pair of segmentation tag andPOS tag.
For example, the best POS of the char-acter ???
is ?GeneralNoun-B?.
This renders as thePOS is a common noun (General Noun) and its seg-mentation makes the character be the first one in amulti-character token.
The POS tagset is based onIPADIC (Asahara and Matsumoto, 2002) and thesegmentation tag is summarized in Table 1.
The 3-best candidates from the morphological analyzer isused.
The second indicator of Japanese unknownwords is the character type.
Unknown words oc-cur around long Katakana sequences and alphabet-ical characters.
We use character type (Char.
Type)as feature, as shown in Figure 1.
Seven charac-ter types ar defined: Space, Digit, Lowercase al-phabet, Uppercase alphabet, Hiragana, Katakana,Other (Kanji).
The character type is directly or in-directly used in most of previous work and appearsan important feature to characterize unknown wordsin Japanese texts.Table 1: Tags for positions in a wordTag DescriptionS one-character wordB first character in a multi-character wordE last character in a multi-character wordI intermediate character in a multi-characterword (only for words longer than 2 chars)2.3 Support Vector Machine-based ChunkingWe use the chunker YamCha (Kudo and Matsumoto,2001), which is based on SVMs (Vapnik, 1998).Suppose we have a set of training data for a bi-nary class problem: (x1, y1), .
.
.
, (xN , yN ), wherexi ?
Rn is a feature vector of the i th sample inthe training data and yi ?
{+1,?1} is the label ofthe sample.
The goal is to find a decision functionwhich accurately predicts y for an unseen x. Ansupport vector machine classifier gives a decisionfunction f(x) = sign(g(x)) for an input vector xwhereg(x) =?zi?SV?iyiK(x, zi) + b.K(x, z) is a kernel function which maps vec-tors into a higher dimensional space.
We use apolynomial kernel of degree 2 given by K(x, z) =(1 + x ?
z)2.SVMs are binary classifiers.
We extend binaryclassifiers to an n-class classifier in order to com-pose chunking rules.
Two methods are often usedChar.
id Char.
Char.
Type POS(Best) POS(2nd) POS(3rd) unknown word tagi?
2 ?
Other PrefixNoun-S GeneralNoun-S SuffixNoun-S Bi?
1 ?
Other GeneralNoun-B GeneralNoun-S SuffixVerbalNoun-S Ii ?
Other GeneralNoun-E SuffixNoun-S GeneralNoun-S Ii + 1 ?
Hiragana CaseParticle-S Auxil.Verb-S ConjunctiveParticle-Si + 2 ?
Other VerbalNoun-B * *Figure 1: An example of features for chunkingfor the extension, the ?One vs. Rest method?
andthe ?Pairwise method?.
In the ?One vs. Rest meth-ods?, we prepare n binary classifiers between oneclass and the remain classes.
Whereas in the ?Pair-wise method?, we prepare nC2 binary classifiersbetween all pairs of classes.
We use ?Pairwisemethod?
since it is efficient to train than the ?Onevs.
Rest method?.Chunking is performed by deterministically an-notating a tag on each character.
Table 2 shows theunknown word tags for chunking, which are knownas the IOB2 model (Ramshaw and Marcus, 1995).Table 2: Tags for unknown word chunkingTag DescriptionB first character in an unknown wordI character in an unknown word (except B)O character in a known wordWe perform chunking either from the beginningor from the end of the sentence.
Figure 1 illustratesa snapshot of chunking procedure.
Two charactercontexts on both sides are referred to.
Informationof two preceding unknown word tags is also usedsince the chunker has already determined them andthey are available.
In the example, the chunker usesthe features appearing within the solid box to inferthe unknown word tag (?I?)
at the position i.We perform chunking either from the beginningof a sentence (forward direction) or from the end ofa sentence (backward direction).3 Experiments and Evaluation3.1 Experiments for measuring RecallFirstly, we evaluate recall of our method.
We useRWCP text corpus (Real World Computing Partner-ship, 1998) as the gold standard and IPADIC (Ver-sion 2.6.3) (Asahara and Matsumoto, 2002) as thebase lexicon.
We set up two data sets based on thehit number of a web search engine which is shownin Appendix A.
Table 3 shows the two data sets.Words with lower hit number than the threshold areregarded as unknown.
We evaluate how many un-known words in the corpus are identified.Table 3: Two data for recall evaluationdata threshold # of word in thelexicon (rate)# of unknown wordin the corpus (rate)A 1,000 108,471 (44.2%) 9,814 (1.06%)B 10,000 52,069 (21.2%) 33,201 (3.60%)Table 4: Results ?
Recall by NewspaperToken TypeSetting Rec.
Prec.
Rec.
Prec.A/for 55.9% 75.3% 55.8% 69.5%A/back 53.5% 73.4% 53.8% 68.0%B/for 74.5% 82.2% 74.2% 75.8%B/back 72.0% 80.9% 72.0% 74.3%We perform five fold cross validation and averagethe five results.
We carefully separate the data intothe training and test data.
The training and test datado not share any unknown word.
We evaluate recalland precision on both token and type as follows:Recall = # of words correctly identified# of words in Gold Std.
DataPrecision = # of words correctly identified# of words identifiedThe experiment is conducted only for recall,since it is difficult to make fair judgment of preci-sion in this setting.
The accuracy is estimated by theword segmentation defined in the corpus.
Neverthe-less, there are ambiguities of word segmentation inthe corpus.
For example, while ?????
(KyotoUniversity)?
is defined as one word in a corpus, ???/??
(Osaka University)?
is defined as two wordsin the same corpus.
Our analyzer identifies ??????
as one word based on generalization of ??????.
Then, it will be judged as false in this exper-iment.
We make fairer precision evaluation in thenext section.
However, since several related worksmake evaluation in this setting, we also present pre-cision for reference.Table 4 shows the result of recall evaluation.
ForTable 5: Results ?
Recall of each POSPOS # of token RecallGeneralNoun 9,009 67.1PN (First Name) 3,938 86.8PN (Organization) 3,800 63.8PN (Last Name) 3,717 90.4Verb 3,446 73.4VerbalNoun 2,895 87.5PN (Location) 1,911 79.3PN (Other) 1,864 58.3AdjectiveNoun 624 83.2PN (Country) 449 88.4?PN?
stands for ?Proper Noun?
Data Set B, forward direction.Shown POSs are higher than the rank 11th by the token sizes.example, an experimental setting ?A/for?
stands forthe data set A with a forward direction chunking,while ?A/Back?
stands for the data set A with abackward direction chunking.
Since there is nosignificant difference between token and type, ourmethod can detect both high and low frequencywords in the corpus.
Table 5 shows the recall ofeach POS in the setting data set B and forward di-rection chunking.
While the recall is slightly poorfor the words which include compounds such as or-ganization names and case particle collocations, itachieves high scores for the words which include nocompounds such as person names.
There are typi-cal errors of conjugational words such as verbs andadjectives which are caused by ambiguities betweenconjugational suffixes and auxiliary verbs.3.2 Experiments for measuring PrecisionSecondly, we evaluate precision of our method man-ually.
We perform unknown word identification onnewspaper articles and patent texts.3.2.1 Unknown Word Identification inNewspapersFirstly, we examine unknown word identificationexperiment in newspaper articles.
We use articlesof Mainichi Shinbun in January 1999 (116,863 sen-tences).
Note that, the model is made by RWCP textcorpus, which consists of articles of Mainichi Shin-bun in 1994 (about 35,000 sentences).We evaluate the models by the number of iden-tified words and precisions.
The number of iden-tified words are counted in both token and type.To estimate the precision, 1,000 samples are se-lected at random with the surrounding context andare showed in KWIC (KeyWord in Context) format.One human judge checks the samples.
When the se-lected string can be used as a word, we regard it asa correct answer.
The precision is the percentage ofcorrect answers over extracted candidates.Concerning with compound words, we reject thewords which do not match any constituent of the de-pendency structure of the largest compound word.Figure 2 illustrates judgment for compound words.In this example, we permit ?????
(overseasstudy)?.
However, we reject ?????
(short-termoverseas)?
since it does not compose any constitu-tent in the compound word.?????
?Short-term overseas study??Short-term???
?overseas study??overseas?
?study abroadOK????????????????NG???
?Figure 2: Judgement for compound wordsWe make two models: Model A is composed bydata set A in Table 3 and model B is composed bydata set B.
We make two settings for the directionof chunking, forward (from BOS to EOS) and back-ward (from EOS to BOS).Table 6 shows the precision for newspaper arti-cles.
It shows that our method achieves around 95%precision in both models.
There is almost no differ-ence in the several settings of the direction and thecontextual feature.Table 6: Results ?
Precision by Newspaper# of identified words PrecisionSetting Token TypeA/For 58,708 19,880 94.6%A/Back 59,029 19,658 94.0%B/For 142,591 41,068 95.3%B/Back 142,696 41,035 95.5%3.2.2 Unknown Word Identification fromPatent TextsWe also examine word identification experimentwith patent texts.
We use patent texts (25,084 sen-tences), which are OCR recognized.
We evaluatemodels by the number of extracted words and pre-cisions as in the preceding experiment.
In this ex-periments, the extracted tokens may contain errorsof the OCR reader.
Thus, we define three categoriesfor the judgment: Correct, Wrong and OCR Error.We use the rate of three categories for evaluation.Note that, our method does not categorize the out-puts into Correct and OCR Error.Table 7 shows the precision for patent texts.
Thebackward direction of chunking gets better scorethan the forward one.
Since suffixes are criticalclues for the long word identification, the backwarddirection is effective for this task.Table 7: Results ?
Precision by Patent Texts# of identified words AccuracySetting Token|Type Correct|Wrong|OCR ErrorA/For 56,008|12,263 83.9%|15.4%|0.7%A/Back 56,004|10,505 89.2%|10.0%|0.8%B/For 97,296|16,526 85.6%|13.7%|0.7%B/Back 98,826|15,895 87.0%|11.8%|1.2%3.3 Word Segmentation AccuracyThirdly, we evaluate how our method improvesword segmentation accuracy.
In the preceding ex-periments, we do chunking with tags in Table 2.We can do word segmentation with unknown wordprocessing by annotating B and I tags to knownwords and rejecting O tag.
RWCP text corpus andIPADIC are used for the experiment.
We define sin-gle occurrence words as unknown words in the cor-pus.
50% of the corpus (unknown words/all words=8,274/461,137) is reserved for Markov Model esti-mation.
40% of the corpus (7,485/368,587) is usedfor chunking model estimation.
10% of the corpus(1,637/92,222) is used for evaluation.
As the base-line model for comparison, we make simple MarkovModel using 50% and 90% of the corpus.
The re-sults of Table 8 show that the unknown word pro-cessing improves word segmentation accuracy.Table 8: Results ?
Word SegmentationRec.
Prec.
F-MeasureBaseline (50%) 97.7% 96.5% 97.1Baseline (90%) 97.8% 96.6% 97.2Our Method 98.5% 98.1% 98.34 Related WorkMori (1996) presents a statistical method based onn-grammodel for unknownword identification.
Themethod estimates how likely the input string is to bea word.
The method cannot cover low frequency un-known words.
Their method achieves 87.4% preci-sion and 73.2% recall by token, 57.1% precision and69.1% recall by type2 on EDR corpus.
Ikeya (2000)presents a method to find unknown word boundariesfor strings composed by only kanji characters.
The2The evaluation of their method depends on the threshold ofthe confidence Fminin their definition.
We refer the precisionand recall at Fmin= 0.25.method also uses the likelihood based on n-grammodel.
Their method achieves 62.8 (F-Measure) fortwo kanji character words and 18.2 (F-Measure) forthree kanji character words in newspapers domain.Nagata (1999) classifies unknown word typesbased on the character type combination in an un-known word.
They define likelihood for each com-bination.
The context POS information is also used.The method achieves 42.0% recall and 66.4% pre-cision on EDR corpus 3.Uchimoto (2001) presents Maximum Entropybased methods.
They extract all strings less thansix characters as the word candidates.
Then, theydo morphological analysis based on words in lexi-con and extracted strings.
They use Kyoto Univer-sity text corpus (Version 2) (Kurohashi and Nagao,1997) as the text and JUMAN dictionary (Version3.61) (Kurohashi and Nagao, 1999) as the base lex-icon 4.
The recall of Uchimoto?s method is 82.4%(1,138/1,381) with major POS estimation.
We alsoperform nearly same experiment 5.
The result ofour method is 48.8% precision and 36.2% recall(293/809) with the same training data (newspaperarticles from Jan. 1 to Jan. 8, 1995) and test data(articles on Jan. 9, 1995).
When we use all of thecorpus excluding the test data, the result is 53.7%precision and 42.7% recall (345/809).Uchimoto (2003) also adopts their method forCSJ Corpus (Maekawa et al 2000) 6.
They presentthat the recall for short words on the corpus is 55.7%(928/1,667) (without POS information).
We try toperform the same experiment.
However, we cannotget same version of the corpus.
Then, we use CSJCorpus ?
Monitor Edition (2002).
It only containsshort word by the definition of the National Instituteof Japanese Language.
80 % of the corpus is usedfor training and the rest 20 % is for test.
The resultis 68.4% precision and 61.1% recall (810/1,326) 7.3They do not assume any base lexicon.
Base lexicon size45,027 words (composed by only the words in the corpus),training corpus size 100,000 sentences, test corpus size 100,000sentences.
Unknown words are defined by single occurrencewords in the corpus.4Base lexicon size 180,000 words, training corpus size7,958 sentences, test corpus size 1,246 sentences OOV (out-of-vocabulary) rate 17.7%.
Unknown words are defined by singleoccurrence words in the corpus.5The difference is the definition of unknown words.Whereas they define unknown words by the possible word formfrequency, we define ones by the stem form frequency.6Training corpus size 744,244 tokens, test corpus size63,037 tokens, OOV rate 1.66%.7Training corpus size 678,649 tokens, 83,819 utterances,test corpus size 185,573 tokens, 20,955 utterances OOV rate0.71%.
Single occurence word by the stem form is defined asthe unknown word.Note, the version of the corpus and the definitionof unknown word are different between Uchimoto?sone and ours.The difference of the result may come from theword unit definition.
The word unit in Kyoto Uni-versity Corpus is longer than the word unit in RWCPtext Corpus and the short word of CSJ Corpus.Though our method is good at shorter unknownwords, the method is poor at longer words includ-ing compounds.For Chinese language, Chen (2002) introduces amethod using statistical methods and human-aidedrules.
Their method achieves 89% precision and68% recall on CKIP lexicon.
Zhang (2002) showsa method with role (position) tagging on charac-ters in sentences.
Their tagging method is basedon Markov model.
The role tagging resembles ourmethod in that it is a character-based tagging.
Theirmethod achieves 69.88% presicion and 91.65% re-call for the Chinese person names recognition in thePeople?s Daily.
Goh (2003) also uses a character-based position tagging method by support vectormachines.
Their method achieves 63.8% precisionand 58.4% recall for the Chinese general unknownwords in the People?s Daily.
Our method is one vari-ation of the Goh?s method with redundant outputs ofa morphological analysis.5 Summary and Future DirectionWe introduce a character-based chunking methodfor general unknown word identification in Japanesetexts.
Our method is based on cascading a mor-phological analyzer and a chunker.
The methodcan identify unknown words regardless of their oc-curence frequencies.Our research need to include POS guessing forthe identified words.
One would argue that, oncethe word boundaries are identified, the POS guess-ing method in European language can be applied(Brants 2000; Nakagawa 2001).
In our preliminaryexperiments of POS guessing, both SVM and Maxi-mum Entropy with contextual information achieves93% with a coarse-grained POS set evaluation, butreaches only around 65% with a fine-grained POSset evaluation.The poor result may be due to the ?possibility-based POS tagset?.
The tagset is not necessarilyfriendly for statistical morphological analyzer de-velopment, but is widely used in Japanese corpusannotation.
In the scheme, the fine-grained POSVerbal Noun in Japanese means that the word canbe used both as Verbal Noun with verb and GeneralNoun without verb.
It is difficult to estimate the POSVerbal Noun, if the word appear in the context with-out verb.
We are currently pursuing the research tobetter estimate fine-grained POS for the possibility-based POS tagset.???????????
?A Unknown Word Definition by SearchEngine HitsUnknown words mean out-of-vocabulary (hereafterOOV) words.
The definition of the unknown wordsdepends on the base lexicon.
We investigate therelationship between the base lexicon size and thenumber of OOV words.
We examine how the reduc-tion of lexicon size affects the OOV rate in a corpus.When we reduce the size of lexicon, we reject thewords in increasing order of frequency in a corpus.Then, we use hits on a web search engine as substi-tutes for frequencies.
We use goo8 as the search en-gine and IPADIC (Asahara and Matsumoto, 2002)as the base lexicon.
Figure 3 shows the distributionof the hit numbers.
The x-axis is the number of hitsin the search engine.
The y-axis is the number ofwords which get the number of hits.
The curve onthe graph is distorted at 100 at which round-off be-gins.Figure 3: The hits of the words in IPADICWe reduce the size of lexicon according to thenumber of hits.
The rate of known words in a corpusis also reduced along the size of lexicon.
Figure 4shows the rate of known words in RWCP text corpus(Real World Computing Partnership, 1998).
The x-axis is the threshold of the hit number.
When the hitnumber of a word is less than the threshold, we re-gard the word as an unknown word.
The left y-axisis the number of known words in the corpus.
Theright y-axis is the rate of known words in the cor-pus.
Note, when the hit number of a word is 0, wedo not remove the word from the corpus, becausethe word may be a stop word of the web search en-gine.When we reject the words less than 1,000 hitsfrom the lexicon, the lexicon size becomes 1/3 and8http://www.goo.ne.jp/Figure 4: The rate of the known wordsthe OOV rate is 1%.
When we reject the words lessthan 10,000 hits from the lexicon, the lexicon sizebecomes 1/6 and the OOV rate is 3.5%.
We usethese two data set, namely the lexicons and the defi-nition of out-of-vocabulary words, for evaluation insection 3.1 and 3.2.ReferencesMasayuki Asahara and Yuji Matsumoto.
2002.IPADIC User Manual.
Nara Institute of Scienceand Technology, Japan.Masayuki Asahara and Yuji Matsumoto.
2003.Japanese Named Entity Extraction with Redun-dant Morphological Analysis.
In Proc.
of HLT-NAACL 2003, pages 8?15.Thorsten Brants.
2000.
TnT ?
A Statistical Part-of-Speech Tagger In Proc.
of ANLP-2000,Keh-Jiann Chen and Wei-Yun Ma.
2002.
Un-known Word Extraction for Chinese Documents.In Proc.
of COLING-2002, pages 169?175.Chooi-Ling Goh, Masayuki Asahara and Yuji Mat-sumoto.
2003.
Chinese Unknown Word Identifi-cation Using Position Tagging and Chunking.
InProc.
of ACL-2003 Interactive Poster/Demo Ses-sions, Companion volume, pages 197?200.Masanori Ikeya and Hiroyuki Shinnou.
2000.
Ex-traction of Unknown Words by the Probabilityto Accept the Kanji Character Sequence as OneWord (in Japanese).
In IPSJ SIG Notes NL-135,pages 49?54.Taku Kudo and Yuji Matsumoto.
2001.
Chunk-ing with Support Vector Machines.
In Proc.
ofNAACL 2001, pages 192?199.Sadao Kurohashi and Makoto Nagao.
1997.
Build-ing a Japanese Parsed Corpus while Improv-ing the Parsing System.
In Proc.
of NLPRS-97,pages 451?456.Sadao Kurohashi and Makoto Nagao.
1999.Japanese Morphological Analysis System JU-MAN Version 3.61.
Department of Informatics,Kyoto University, Japan.Kikuo Maekawa, Hanae Koiso, Sasaoki Furui andHiroshi Isahara.
2000.
Spontaneous Speech Cor-pus of Japanese.
In Proc.
of LREC-2000, pages947?952.Shinsuke Mori and Makoto Nagao.
1996.
WordExtraction from Corpora and Its Part-of-SpeechEstimation Using Distributional Analysis.
InProc.
of COLING-96, pages 1119?1122.Masaaki Nagata.
1999.
A Part of Speech Estima-tion Method for Japanese Unknown Words usinga Statistical Model of Morphology and Context.In Proc.
of ACL-99, pages 277?284.Tetsuji Nakagawa, Taku Kudoh and Yuji Mat-sumoto.
2001 Unknown Word Guessing andPart-of-Speech Tagging Using Support VectorMachines.
In Proc.
of NLPRS-2001, pages 325?331.Lance Ramshaw and Mitchell Marcus.
1995.
TextChunking using Transformation-based Learning.In Proc.
of the 3rd Workshop on Very Large Cor-pora, pages 83?94.Real World Computing Partnership.
1998.
RWCText Database.Kiyotaka Uchimoto, Satoshi Sekine and Hitoshi Isa-hara.
2001.
The Unknown Word Problem: aMorphological Analysis of Japanese Using Max-imum Entropy Aided by a Dictionary.
In Proc.
ofEMNLP-2001, pages 91?99.Kiyotaka Uchimoto, Chikashi Nobata, AtsushiYamada, Satoshi Sekine and Hiroshi Isahara.2002.
Morphological Analysis of the Sponta-neous Speech Corpus.
In Proc.
of COLING-2002, pages 1298?1302.Kiyotaka Uchimoto, Chikashi Nobata, Atsushi Ya-mada, Satoshi Sekine and Hiroshi Isahara.
2003.Morphological Analysis of a Large SpontaneousSpeech Corpus in Japanese.
In Proc.
of ACL-2003, pages 479?488.Vladimir Naumovich Vapnik.
1998.
StatisticalLearning Theory.
A Wiley-Interscience Publica-tion.Kevin Zhang, Qun Liu, Hao Zhang and Xue-QiCheng.
2002.
Automatic Recognition of Chi-nese Unknown Words Based on Roles Tagging.In Proc.
of 1st SIGHAN Workshop on ChineseLanguage Processing, pages 71?77.
