Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 121?126,Baltimore, Maryland USA, June 23-24, 2014.c?2014 Association for Computational LinguisticsSimplified Dependency Annotations with GFL-WebMichael T. Mordowanec Nathan Schneider Chris Dyer Noah A. SmithSchool of Computer ScienceCarnegie Mellon UniversityPittsburgh, PA 15213, USAmichael.mordowanec@gmail.com, {nschneid,cdyer,nasmith}@cs.cmu.eduAbstractWe present GFL-Web, a web-based in-terface for syntactic dependency annota-tion with the lightweight FUDG/GFL for-malism.
Syntactic attachments are spec-ified in GFL notation and visualized asa graph.
A one-day pilot of this work-flow with 26 annotators established thateven novices were, with a bit of training,able to rapidly annotate the syntax of En-glish Twitter messages.
The open-sourcetool is easily installed and configured; itis available at: https://github.com/Mordeaux/gfl_web1 IntroductionHigh-quality syntactic annotation of natural lan-guage is expensive to produce.
Well-known large-scale syntactic annotation projects, such as thePenn Treebank (Marcus et al., 1993), the En-glish Web Treebank (Bies et al., 2012), the PennArabic Treebank (Maamouri et al., 2004), andthe Prague dependency treebanks (Haji?c, 1998;?Cmejrek et al., 2005), have relied on expert lin-guists to produce carefully-controlled annotateddata.
Because this process is costly, such anno-tation projects have been undertaken for only ahandful of important languages.
Therefore, devel-oping syntactic resources for less-studied, lower-resource, or politically less important languagesand genres will require alternative methods.
Toaddress this, simplified annotation schemes thattrade cost for detail have been proposed (Habashand Roth, 2009).11These can be especially effective when some details ofthe syntax can be predicted automatically with high accuracy(Alkuhlani et al., 2013).The Fragmentary Unlabeled DependencyGrammar (FUDG) formalism (Schneider et al.,2013) was proposed as a simplified framework forannotating dependency syntax.
Annotation effortis reduced by relaxing a number of constraintsplaced on traditional annotators: partial fragmentscan be specified where the annotator is uncertainof part of the structure or wishes to focus onlyon certain phenomena (such as verbal argumentstructure).
FUDG also offers mechanisms forexcluding extraneous tokens from the annotation,for marking multiword units, and for describingcoordinate structures.
FUDG is written in anASCII-based notation for annotations calledGraph Fragment Language (GFL), and text-basedtools for verifying, converting, and rendering GFLannotations are provided.Although GFL offers a number of conveniencesto annotators, the text-based UI is limiting: theexisting tools require constant switching betweena text editor and executing commands, and thereare no tools for managing a large-scale annotationeffort.
Additionally, user interface research hasfound marked preferences for and better perfor-mance with graphical tools relative to text-basedinterfaces?particularly for less computer-savvyusers (Staggers and Kobus, 2000).
In this paper,we present the GFL-Web tool, a web-based inter-face for FUDG/GFL annotation.
The simple inter-face provides instantaneous feedback on the well-formedness of a GFL annotation, and by wrappingSchneider et al.
?s notation parsing and renderingsoftware, gives a user-friendly visualization of theannotated sentence.
The tool itself is lightweight,multi-user, and easily deployed with few softwaredependencies.
Sentences are assigned to anno-tators via an administrative interface, which alsorecords progress and provides for a text dump of121(a) @Bryan_wright11 i lost all my contacts , smh .
(b) Texas Rangers are in the World Series !
GoRangers !!!!!!!!!
http://fb.me/D2LsXBJxFigure 1: FUDG annotation graphs for two tweets.all annotations.
The interface for annotators is de-signed to be as simple as possible.We provide an overview of the FUDG/GFLframework (?2), detail how the tool is set up andutilized (?3), and discuss a pilot exercise in which26 users provided nearly 1,000 annotations of En-glish Twitter messages (?4).
Finally, we note someof the technical aspects of the tool (?5) and relatedsyntactic annotation software (?6).2 BackgroundGFL-Web is designed to simplify the creationof dependency treebanks from noisy or under-resourced data; to that end, it exploits thelightweight FUDG/GFL framework of Schneideret al.
(2013).
Here we outline how FUDG differsfrom traditional Dependency Grammar (?2.1) anddetail major aspects of GFL (?2.2).2.1 FUDGFigure 1 displays two FUDG graphs of annota-tions of Twitter messages (?tweets?, shown belowin tokenized form).
Arrows point upwards fromdependents to their heads.
These tweets illustrateseveral characteristics of the formalism, including:?
The input may contain multiple independentsyntactic units, or ?utterances?
; the annotationindicates these by attaching their heads to a spe-cial root node called **.?
Some input tokens are omitted if deemed ex-trinsic to the syntax; by convention, these in-clude most punctuation, hashtags, usernames,and URLs.?
Multiword units may be joined to form com-posite lexical nodes (e.g., World_Series in fig-ure 1b).
These nodes are not annotated with anyinternal syntactic structure.?
Tokens that are used in the FUDG parse must beunambiguous.
If a word appears multiple timesin the input, it is disambiguated with ~ and anindex (e.g., Rangers~2 in figure 1b).
(Some of the other mechanisms in FUDG, such ascoordinate structures and underspecification, arenot shown here; they are not important for pur-poses of this paper.
)2.2 GFLThe Graph Fragment Language is a simple ASCII-based language for FUDG annotations.
Its normsare designed to be familiar to users with basic pro-gramming language proficiency, and they are intu-itive and easy to learn even for those without.
Theannotation in figure 1a may be expressed in GFLas:2i > lost** < ({all my} > contacts)smh**In GFL, angle brackets point from a dependent(child) to its head (parent).
Parentheses groupnodes together; the head of this group is then at-tached to another node.
The double asterisk (**)marks a root node in an annotations containingmultiple utterances.
Curly braces group nodes thatmodify the same head.GFL corresponding to Figure 1b is:2The abbreviation smh stands for shaking my head.122Sentence: Texas Rangers are in the World Series !
Go Rangers !!!!!!!!!
http://fb.me/D2LsXBJxInput format:---% ID data_set_name:417% TEXTTexas Rangers~1 are in the World Series !
Go Rangers~2 !!!!!!!!
!http://fb.me/D2LsXBJx% ANNOTexas Rangers~1 are in the World Series Go Rangers~2http://fb.me/D2LsXBJxFigure 2: Illustration of the GFL-Web input format for a tweet.
The ANNO section will be shown to the user as the defaultannotation; punctuation has been stripped out automatically to save time.Figure 3: User home screen showing assigned batches for annotation, with links to the training set and blank annotation form.
[Texas Rangers~1] > are** < inin < (the > [World Series])Go** < Rangers~2This uses square brackets for multiword expres-sions.
Similar to a programming language, thereare often many equivalent GFL annotation optionsfor a given sentence.
The annotation can be splitacross multiple lines so that annotators can ap-proach smaller units first and then link them to-gether.3 Using GFL-WebThe GFL-Web tool uses the Python programminglanguage?s Flask microframework for server-sidescripting.
This allows it to be deployed on a webserver, locally or via the Internet.
This also en-ables the interface to rely on scripts previouslycreated for analyzing GFL.
Once installed, the re-searcher need only configure a few settings and be-gin entering data to be annotated.3.1 SetupThere are a few simple configuration options.
Themost useful of these options specify how manysentences should be in each batch that is assignedto an annotator, and how many sentences in eachbatch should be doubly annotated, for the purposeof assessing inter-annotator agreement.
By de-fault, the batch size is 10, and the first 2 sentencesof each batch overlap with the previous batch, so4/10 of the sentences in the batch will be annotatedby someone else (assuming no two consecutivebatches are assigned to the same user).
The pro-gram requires tokenized input, with indices addedto distinguish between words that appear twice(easily automated).
The input format, figure 2, al-lows for easy editing with a text editor if so de-sired.Once the input files have been placed in a des-ignated directory, an admin interface can be usedto assign batches of data to specific users (annota-tors).3.2 AnnotationAnnotators log in with their username and see ahome screen, figure 3.
The home screen alwaysoffers links to a training set to get them up tospeed, as well as a blank annotation form intowhich they can enter and annotate any sentence.Beneath these is a table of batches of sentenceswhich have been assigned to the user.
Clicking123Figure 4: A well-formed GFL annotation is indicated by agreen background and visualization of the analysis graph.any of these will take the annotator to an annota-tion page, which displays the text to be annotated,an input field, and a comments box.The annotation interface is simple and intuitiveand provides instant feedback, preventing the an-notator from submitting ill-formed annotations.Annotators press the Analyze button and receivefeedback before submitting annotations (figure 4).Common GFL errors such as unbalanced paren-theses are caught by the program and brought tothe attention of the annotator with an informativeerror message (figure 5).
The annotator can thenfix the error, and will be able to submit once allerrors are resolved.The training set consists of 15 sentences se-lected from Rossman and Mills (1922), shown inthe same annotation interface.
Examples becomeincreasingly more complicated in order to famil-iarize the user with different syntactic phenomenaand the entry-analyze-review workflow.
A buttondisplays the FUDG graph from an expert annota-tion so the novice can compare it to her own andconsult the guidelines (or ask for help) where thetwo graphs deviate.4 Pilot User StudyWe conducted a pilot annotation project in which26 annotators were trained on GFL-Web and askedto annotate English Twitter messages from thedaily547 and oct27 Twitter datasets of Gimpelet al.
(2011).
The overwhelming majority were alltrained on the same day, having no prior knowl-edge of GFL.
Most, but not all, were native speak-ers of English.
Those who had no prior knowl-edge of dependency grammar in general receiveda short tutorial on the fundamentals before beingintroduced to the annotation workflow.
All par-ticipants who were new to FUDG/GFL workedthrough the training set before moving on to theTwitter data.
Annotators were furnished with theEnglish annotation guidelines of Schneider et al.
(2013).34.1 ResultsIn the one-day event, 906 annotations were gen-erated.
Inter-annotator agreement was high?.9according to the softComPrec measure (Schnei-der et al., 2013)?and an expert?s examination of asample of the annotations found that 75% of con-tained no major error.Annotators used the analysis feature of theinterface?which displays either a visual represen-tation of the tree or an error message?an aver-age of 3.06 times per annotation.
The interface re-quires they analyze each annotation at least once.Annotators have the ability to resubmit annota-tions if they later realize they made an error, andeach annotation was submitted an average of 1.16times.
Disregarding instances that took over 1,000seconds (under the assumption that these repre-sent annotators taking breaks), the median timebetween the first analysis and the first submissionof an annotation was 30 seconds.
We take thisas evidence that annotators found the instant feed-back features useful in refining their annotations.4.2 Post-Pilot ImprovementsAnnotator feedback prompted some changes to theinterface.
The annotation input box was changedto incorporate bracket-matching.
The graph visu-alization for a correct annotation was added foreach example in the training set so new annota-tors could compare their tree to an example.
Pre-sumably these changes would further reduce anno-tators?
training time and improve their efficiency.Progress bars were added to the user home screento show per-batch completion information.4.3 Other LanguagesIn addition to English, guidelines for Swahili,Zulu, and Mandarin are currently in development.3https://github.com/brendano/gfl_syntax/blob/master/guidelines/guidelines.md124Figure 5: An example error notification.
The red background indicates an error, and the cause of the error is displayed at thebottom of the screen.5 Technical ArchitectureGFL-Web and its software dependencies for ana-lyzing and visualizing GFL are largely written inPython.
The tool is built with Flask, a Pythonframework for web applications.
Data is storedand transmitted to and from the browser in theJavascript Object Notation (JSON) format, whichis supported by libraries in most programming lan-guages.
The browser interface uses AJAX tech-niques to interact dynamically with the server.GFL-Web is written for Python version 2.7.It wraps scripts previously written for the analy-sis and visualization of GFL (Schneider et al.,2013).
These in turn require Graphviz (Ellsonet al., 2002), which is freely available.Flask provides a built-in server, but can also bedeployed in Apache, via WSGI or CGI, etc.6 Other ToolsIn treebanking, a good user interface is essen-tial for annotator productivity and accuracy.
Sev-eral existing tools support dependency annota-tion; GFL-Web is the first designed specifi-cally for the FUDG/GFL framework.
Some,including WebAnno (Yimam et al., 2013) andbrat (Stenetorp et al., 2012), are browser-based,while WordFreak (Morton and LaCivita, 2003),Abar-Hitz (Ilarraza et al., 2004), and TrEd (Pa-jas and Fabian, 2000?2011) are client-side appli-cations.
All offer tree visualizations; to the bestof our knowledge, ours is the only dependencyannotation interface that has text as the exclu-sive mode of entry.
Some, such as WebAnnoand brat, aim to be fairly general-purpose, sup-porting a wide range of annotation schemes; bycontrast, GFL-Web supports a single annotationscheme, which keeps the configuration (and code-base) simple.
In the future, GFL-Web might in-corporate elements of monitoring progress, suchas display of evaluation measures computed withexisting FUDG/GFL scripts.Certain elements of the FUDG/GFL frameworkcan be found in other annotation systems, suchas the PASSAGE syntactic representation (Vilnatet al., 2010), which allows for grouping of wordsinto units, but still requires dependency relationsto be labeled.Finally, we note that new approaches to corpusannotation of semantic dependencies also comewith rich browser-based annotation interfaces (Ba-narescu et al., 2013; Abend and Rappoport, 2013).7 ConclusionWhile the creation of high-quality, highly speci-fied, syntactically annotated corpora is a goal thatis out of reach for most languages and genres,GFL-Web facilitates a rapid annotation workflowwithin a simple framework for dependency syn-tax.
More information on FUDG/GFL is avail-able at http://www.ark.cs.cmu.edu/FUDG/,and the source code for GFL-Web is available athttps://github.com/Mordeaux/gfl_web.125AcknowledgmentsThe authors thank Archna Bhatia, Lori Levin, Ja-son Baldridge, Dan Garrette, Jason Mielens, LiangSun, Shay Cohen, Spencer Onuffer, Nora Ka-zour, Manaal Faruqui, Wang Ling, Waleed Am-mar, David Bamman, Dallas Card, Jeff Flani-gan, Lingpeng Kong, Bill McDowell, BrendanO?Connor, Tobi Owoputi, Yanchuan Sim, SwabhaSwayamdipta, and Dani Yogatama for annotatingdata, and anonymous reviewers for helpful feed-back.
This research was supported by NSF grantIIS-1352440.ReferencesOmri Abend and Ari Rappoport.
2013.
Universal Con-ceptual Cognitive Annotation (UCCA).
In Proc.
ofACL, pages 228?238.
Sofia, Bulgaria.Sarah Alkuhlani, Nizar Habash, and Ryan Roth.
2013.Automatic morphological enrichment of a mor-phologically underspecified treebank.
In Proc.
ofNAACL-HLT, pages 460?470.
Atlanta, Georgia.Laura Banarescu, Claire Bonial, Shu Cai, MadalinaGeorgescu, Kira Griffitt, Ulf Hermjakob, KevinKnight, Philipp Koehn, Martha Palmer, and NathanSchneider.
2013.
Abstract Meaning Representationfor sembanking.
In Proc.
of the 7th Linguistic An-notation Workshop and Interoperability with Dis-course, pages 178?186.
Sofia, Bulgaria.Ann Bies, Justin Mott, Colin Warner, and Seth Kulick.2012.
English Web Treebank.
Technical Re-port LDC2012T13, Linguistic Data Consortium,Philadelphia, PA.Martin?Cmejrek, Jan Cu?r?n, Jan Haji?c, and Ji?r?
Havelka.2005.
Prague Czech-English Dependency Treebank:resource for structure-based MT.
In Proc.
of EAMT,pages 73?78.
Budapest, Hungary.John Ellson, Emden Gansner, Lefteris Koutsofios,Stephen C. North, and Gordon Woodhull.
2002.Graphviz?open source graph drawing tools.
In Pe-tra Mutzel, Michael J?nger, and Sebastian Leipert,editors, Graph Drawing, pages 483?484.
Springer,Berlin.Kevin Gimpel, Nathan Schneider, Brendan O?Connor,Dipanjan Das, Daniel Mills, Jacob Eisenstein,Michael Heilman, Dani Yogatama, Jeffrey Flanigan,and Noah A. Smith.
2011.
Part-of-speech taggingfor Twitter: annotation, features, and experiments.In Proc.
of ACL-HLT, pages 42?47.
Portland, Ore-gon.Nizar Habash and Ryan Roth.
2009.
CATiB: TheColumbia Arabic Treebank.
In Proc.
of ACL-IJCNLP, pages 221?224.
Suntec, Singapore.Jan Haji?c.
1998.
Building a syntactically annotatedcorpus: the Prague Dependency Treebank.
In EvaHaji?cov?, editor, Issues of Valency and Meaning.Studies in Honor of Jarmila Panevov?, pages 12?19.
Prague Karolinum, Charles University Press,Prague.Arantza D?az De Ilarraza, Aitzpea Garmendia, andMaite Oronoz.
2004.
Abar-Hitz: An annotation toolfor the Basque dependency treebank.
In Proc.
ofLREC, pages 251?254.
Lisbon, Portugal.Mohamed Maamouri, Ann Bies, Tim Buckwalter, andWigdan Mekki.
2004.
The Penn Arabic Tree-bank: building a large-scale annotated Arabic cor-pus.
In NEMLAR Conference on Arabic LanguageResources and Tools, pages 102?109.
Cairo.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotatedcorpus of English: the Penn Treebank.
Computa-tional Linguistics, 19(2):313?330.Thomas Morton and Jeremy LaCivita.
2003.WordFreak: An open tool for linguistic anno-tation.
In Proc.
of HLT-NAACL: Demonstrations,pages 17?18.
Edmonton, Canada.Petr Pajas and Peter Fabian.
2000?2011.
Tree EditorTrEd 2.0. http://ufal.mff.cuni.cz/tred/.Mary Blanche Rossman and Mary Wilda Mills.
1922.Graded Sentences for Analysis, Selected from theBest Literature and Systematically Graded for ClassUse.
L. A. Noble.Nathan Schneider, Brendan O?Connor, Naomi Saphra,David Bamman, Manaal Faruqui, Noah A. Smith,Chris Dyer, and Jason Baldridge.
2013.
A frame-work for (under)specifying dependency syntax with-out overloading annotators.
In Proc.
of the 7th Lin-guistic Annotation Workshop and Interoperabilitywith Discourse, pages 51?60.
Sofia, Bulgaria.Nancy Staggers and David Kobus.
2000.
Comparingresponse time, errors, and satisfaction between text-based and graphical user interfaces during nursingorder tasks.
Journal of the American Medical Infor-matics Association, 7(2):164?176.Pontus Stenetorp, Sampo Pyysalo, Goran Topi?c,Tomoko Ohta, Sophia Ananiadou, and Jun?ichi Tsu-jii.
2012. brat: a web-based tool for NLP-assistedtext annotation.
In Proc.
of EACL: Demonstrations,pages 102?107.
Avignon, France.Anne Vilnat, Patrick Paroubek, Eric Villemontede la Clergerie, Gil Francopoulo, and Marie-LaureGu?not.
2010.
PASSAGE syntactic representation:a minimal common ground for evaluation.
In Proc.of LREC, pages 2478?2485.
Valletta, Malta.Seid Muhie Yimam, Iryna Gurevych, RichardEckart de Castilho, and Chris Biemann.
2013.WebAnno: A flexible, web-based and visuallysupported system for distributed annotations.
InProc.
of ACL: Demonstrations, pages 1?6.
Sofia,Bulgaria.126
