Proceedings of the Eighteenth Conference on Computational Language Learning, pages 119?129,Baltimore, Maryland USA, June 26-27 2014. c?2014 Association for Computational LinguisticsDistributed Word Representation Learning for Cross-LingualDependency ParsingMin Xiao and Yuhong GuoDepartment of Computer and Information SciencesTemple UniversityPhiladelphia, PA 19122, USA{minxiao,yuhong}@temple.eduAbstractThis paper proposes to learn language-independent word representations to ad-dress cross-lingual dependency parsing,which aims to predict the dependencyparsing trees for sentences in the targetlanguage by training a dependency parserwith labeled sentences from a source lan-guage.
We first combine all sentencesfrom both languages to induce real-valueddistributed representation of words undera deep neural network architecture, whichis expected to capture semantic similari-ties of words not only within the same lan-guage but also across different languages.We then use the induced interlingual wordrepresentation as augmenting features totrain a delexicalized dependency parser onlabeled sentences in the source languageand apply it to the target sentences.
To in-vestigate the effectiveness of the proposedtechnique, extensive experiments are con-ducted on cross-lingual dependency pars-ing tasks with nine different languages.The experimental results demonstrate thesuperior cross-lingual generalizability ofthe word representation induced by theproposed approach, comparing to alterna-tive comparison methods.1 IntroductionWith the rapid development of linguistic resourcesand tools in multiple languages, it is very im-portant to develop cross-lingual natural languageprocessing (NLP) systems.
Cross-lingual depen-dency parsing is the task of inferring dependencytrees for observed sentences in a target languagewhere there are few or no labeled training sen-tences by using a dependency parser trained ona large amount of sentences with annotated de-pendency trees in a source language (Durrett etal., 2012; McDonald et al., 2011; Zhao et al.,2009).
Cross-lingual dependency parsing is pop-ularly studied in natural language processing areaas it can greatly reduce the expensive manual an-notation effort in the target language by exploit-ing the dependency annotations from a source lan-guage (Durrett et al., 2012; McDonald et al., 2011;Ta?ckstro?m et al., 2012).One fundamental challenge of cross-lingual de-pendency parsing stems from the word-level rep-resentation divergence across languages.
Sincesentences in different languages are expressedusing different vocabularies, if we train a de-pendency parser on the word-level features ofsentences from a source language, it will failto parse the sentences in a different target lan-guage.
A variety of work in the literature has at-tempted to bridge the word-level representation di-vergence across languages.
One intuitive methoddelexicalizes the dependency parser by replac-ing the language-specific word-level features withlanguage-independent features such as universalpart-of-speech tags (Petrov et al., 2012).
With theuniversal POS tag features, this method providesa possible way to transfer dependency parsing in-formation from the source language to the targetlanguage and has demonstrated some good empir-ical results (McDonald et al., 2011).
However, thenumber of universal POS tags is small, which lim-its their discriminative capacity as input featuresfor dependency parsing.
A few other works hencepropose to improve the delexicalized system bylearning more effective cross-lingual features suchas bilingual word clusters (Ta?ckstro?m et al., 2012)and other interlingual representations (Durrett etal., 2012).In this paper, we propose to address cross-lingual dependency parsing by learning distributedinterlingual word representations using a deepneural network architecture.
We first combineall the sentences from two language domains and119build cross language word connections based onWikitionary, which works as a free bilingual dic-tionary.
Then by exploiting a deep learning archi-tecture, we learn real-valued dense feature vectorsfor the words in the given sentences as the high-level interlingual representations, which capturesemantic similarities across languages.
Finally, weuse the induced distributed word representation asaugmenting features to train a delexicalized de-pendency parser on the annotated sentences in thesource language and applied it on the sentences inthe target language.
In order to evaluate the pro-posed cross-lingual learning technique, we con-duct extensive experiments on eight cross-lingualdependency parsing tasks with nine different lan-guages.
The experimental results demonstrate theefficacy of the proposed approach in transferringdependency parsers across languages, comparingto other methods.The remainder of the paper is organized as fol-lows.
Section 2 reviews related work.
Section3 describes the main approach of cross-lingualword representation learning with deep neural net-works and cross-lingual dependency parsing withinduced interlingual features.
Section 4 presentsthe empirical study on eight cross language depen-dency parsing tasks.
We then conclude the paperin Section 5.2 Related WorkPrevious works developed in the literature havetackled cross-lingual dependency parsing by us-ing cross-lingual annotation projection methods,multilingual model learning methods, and cross-lingual representation learning methods.Cross-lingual annotation projection methodsuse parallel sentences to project the annotationsfrom the source language side to the target lan-guage side and then train dependency parsers onthe target data with projected annotations (Hwaet al., 2005; Liu et al., 2013; Smith and Eis-ner, 2009; Zhao et al., 2009).
For cross-lingualannotation projection methods, both the wordalignment training step and the annotation pro-jection step can introduce errors or noise.
Thusmuch work developed in the literature has fo-cused on designing robust projection algorithmssuch as graph-based projection with label prop-agations (Das and Petrov, 2011), improving pro-jection performance by using auxiliary resourcessuch as Wikipedia metadata (Kim and Lee, 2012)or WordNet (Khapra et al., 2010), or boosting pro-jection performance by heuristically modifying orcorrecting the projected annotations (Hwa et al.,2005; Kim et al., 2010).
Some work has alsoproposed to project the discrete dependency arcinstances instead of treebank as the training set(Liu et al., 2013).
Moreover, besides cross-lingualdependency parsing, cross-lingual annotation pro-jection methods have also demonstrated successin various other sequence labeling tasks includ-ing POS tagging (Das and Petrov, 2011; Yarowskyand Ngai, 2001), relation extraction (Kim et al.,2012), named entity recognition (Kim et al., 2010;Kim and Lee, 2012), constituent syntax parsing(Jiang et al., 2011), and word sense disambigua-tion (Khapra et al., 2010).Multilingual model learning methods traincross-lingual dependency parsers with parameterconstraints obtained from parallel data (Liu et al.,2013; Ganchev et al., 2009) or linguistic knowl-edges (Naseem et al., 2010; Naseem et al., 2012).Among these methods, some proposed to traina joint dependency parsing system with parame-ters shared across the dependency parsing modelsin individual languages (Liu et al., 2013).
Otherworks used posterior regularization techniques toencode the linguistic constraints in learning de-pendency parsing models (Ganchev et al., 2009;Naseem et al., 2010; Naseem et al., 2012).
Thelinguistic constraints may either come from man-ually constructed universal dependency parsingrules (Naseem et al., 2010) or manually specifiedtypological features (Naseem et al., 2012), or belearned from parallel sentences (Ganchev et al.,2009).
Besides cross-lingual dependency parsing,multilingual model learning methods have alsoachieved good empirical results for other multilin-gual NLP tasks, including named entity recogni-tion (Burkett et al., 2010; Che et al., 2013; Wangand Manning, 2014), syntactic parsing (Burkettet al., 2010), semantic role labeling (Zhuang andZong, 2010; Kozhevnikov and Titov, 2012), andword sense disambiguation (Guo and Diab, 2010).Cross-lingual representation learning methodsinduce language-independent features to bridgethe cross-lingual difference in the original word-level representation space and build connectionsacross different languages.
They train a depen-dency parser in the induced representation spaceby exploiting labeled data from the source lan-guage and apply it in the target language (Dur-120rett et al., 2012; Ta?ckstro?m et al., 2012; Zhanget al., 2012).
A variety of auxiliary resourceshave been used to induce interlingual features, in-cluding bilingual lexicon (Durrett et al., 2012),and unlabeled parallel sentences (Ta?ckstro?m et al.,2013).
Based on different learning mechanisms(whether or not using labeled data) for induc-ing language-independent features, cross-lingualrepresentation learning methods can be cate-gorized into unsupervised representation learn-ing (Ta?ckstro?m et al., 2013) and supervisedrepresentation learning (Durrett et al., 2012).The language-independent features include bilin-gual word clusters (Ta?ckstro?m et al., 2012),language-independent projection features (Durrettet al., 2012), and automatically induced language-independent POS tags (Zhang et al., 2012).
Be-sides cross-lingual dependency parsing, in the lit-erature cross-lingual representation learning meth-ods have also demonstrated efficacy in differentNLP applications such as cross language namedentity recognition (Ta?ckstro?m et al., 2012) andcross language semantic role labeling (Titov andKlementiev, 2012).
Our work shares similaritywith these cross-lingual representation learningmethods on inducing new language-independentfeatures, but differs from them in that we learncross-lingual word embeddings.
Though multilin-gual word embeddings have been employed in theliterature, they are developed for other NLP taskssuch as cross-lingual sentiment analysis (Klemen-tiev et al., 2012), and machine translation (Zouet al., 2013).
Moreover, the method in (Klemen-tiev et al., 2012) requires parallel sentences withobserved word-level alignments, and the methodin (Zou et al., 2013) first learns language-specificword embeddings in each language separatelyand then transforms representations from one lan-guage to another language with machine trans-lation alignments, while we jointly learn cross-lingual word embeddings in the two languages byonly exploiting a small set of bilingual word pairs.From the perspective of applying deep networksin natural language processing systems, there area number of works in the literature (Collobert andWeston, 2008; Collobert et al., 2011; Henderson,2004; Socher et al., 2011; Titov and Henderson,2010; Turian et al., 2010).
Socher et al.
(2011) ap-plied recursive autoencoders to address sentence-level sentiment classification problems.
Collobertand Weston (2008) and Collobert et al.
(2011)employed a deep learning framework for jointlymulti-task learning and empirically evaluated itwith four NLP tasks, including part-of-speech tag-ging, chunking, named entity recognition, and se-mantic role labeling.
Henderson (2004) proposeddiscriminative training methods for learning a neu-ral network statistical parser.
Titov and Hender-son (2010) extended the incremental sigmoid Be-lief networks (Titov and Henderson, 2007) to agenerative latent variable model for dependencyparsing.
Turian et al.
(2010) employed neural net-works to induce word representations for sequencelabeling tasks such as named entity recognition.3 Cross-Lingual Dependency Parsingwith Word Representation LearningIn this work, we aim to tackle cross-lingual depen-dency parsing by learning language-independentdistributed word representations with deep neuralnetworks.
We first build connections across lan-guages using free bilingual dictionaries.
Then weintroduce the deep neural network framework forcross-lingual word representation learning and de-scribe how to employ the induced dense word em-beddings for cross-lingual dependency parsing.3.1 Building Cross Language ConnectionsTo induce cross-lingual word representations, wefirst need to build connections between the sourceand target languages.
In this work, we producesuch connections by finding cross-lingual wordpairs using the Wikitionary1, which works as freebilingual dictionaries between language pairs.Specifically, we first constructed a source lan-guage dictionary with all words that appeared inthe sentences from the source language domainand translate these words to the target languageusing the Wikitionary.
Then we filtered the pro-duced word-to-word translations by dropping theones where either the same source language wordhas multiple different word translations in the tar-get language or the same target language wordcorresponds to multiple different source languagewords.
We further dropped the word pairs wherethe translated word in the target language does notappear in the given sentences in the target lan-guage domain.
After the processing, we have a setof one-to-one bilingual word pairs to build con-nections between the two language domains.
Fi-nally, we built a unified bilingual vocabulary V1http://en.wikitionary.org121Figure 1: The architecture of the deep neural net-work for learning cross-lingual word representa-tions.
Each word wifrom the training sample xis mapped to an interlingual representation vectorR(wi) through the embedding matrix R.with words from all sentences of the two languagedomains.
For each one-to-one bilingual word pairwe constructed, we assume the two words haveequivalent semantic meaning and map them to thesame entry in V .
Next we will learn a distributedvector representation for each entry of the bilin-gual vocabulary V using deep neural networks.By sharing the same representation vectors, theconstructed bilingual word pairs will serve as thebridge across languages.3.2 Interlingual Word RepresentationLearning with Deep Neural NetworksGiven the constructed bilingual vocabulary V withv entries, we will learn a latent word embeddingmatrix R ?
Rk?v over the sentences in the twolanguage domains by using a deep neural networkmodel.
This embedding matrix will map eachword w in the vocabulary V into a real valued rep-resentation vector R(w) with length k. For eachbilingual pair of words that are mapped into thesame entry of V , they will be mapped into thesame vector in R as well.
Following the strat-egy of (Collobert et al., 2011), we construct asimple two-class classification problem over thegiven sentences.
We use the sub-sentences withfixed window size c constructed from the givensentences in the two language domains as posi-tive samples and construct the negative samples byreplacing the middle word of each positive sub-sentence with a random word from V .
We thentrain a deep neural network for this two-class clas-sification problem, while simultaneously learningthe latent embedding matrix R.The deep neural network architecture is givenin Figure 1.
The bottom layer of the deep archi-tecture is the input layer, which takes a sequenceof word tokens, x = w1, w2, .
.
.
, wc, with a fixedwindow size c as the input instance.
Then we mapeach word wiin this sequence to an embeddingvector R(wi) by treating the bilingual embeddingmatrix R as a look-up table.
The embedding vec-tors of the sequence of words x will be concate-nated into a long vector R(x) ?
Rck such thatR(x) = [R(w1);R(w2); .
.
.
;R(wc)].
(1)R(x) will then be used as input for the hiddenlayer above it.
The deep neural network has mul-tiple hidden layers.
The first hidden layer appliesa nonlinear hyperbolic tangent activation functionover the linear transformation of its input vectorR(x), such thatH1(x) = tanh (W1?R(x) + b1) (2)where W1?
Rh1?ck is the weight parametermatrix, b1?
Rh1 is the bias parameter vector,H1(x) ?
Rh1 is the output vector, and h1is thenumber of hidden units in the first hidden layer.Similarly, each of the other hidden layers takes theprevious layer?s output as its input and performsa nonlinear transformation to produce an outputvector.
For example, for the i-th hidden layer, weused Hi?1(x) as its input and Hi(x) as its outputsuch thatHi(x) = tanh (Wi?Hi?1(x) + bi) (3)where Wi?
Rhi?hi?1 is the weight parameter ma-trix and biis the bias parameter vector for the i-th hidden layer; hidenotes the number of hiddenunits of the i-th hidden layer.Given t hidden layers, the output representationof the last layer will then be used to generate afinal score value for the prediction task, such thats(x) = ?
?Ht(x) + u (4)122where ?
?
Rht is the weight parameter vector andu is the bias parameter for the output layer.In summary, the model parameters of the deepneural network architecture include the look-up ta-ble R, the parameters {Wi,bi}ti=1for the hiddenlayers, and the output layer parameters (?, u).3.3 The Training ProcedureThe model parameters of the deep network archi-tecture are learned by training a two-class classifi-cation model over the the constructed positive andnegative samples.
Let D = {xi,?xi}Ni=1denotethe constructed training set, where xiis a positivesample and ?xiis a negative sample constructed byreplacing the middle word of xiwith a randomword from V .
It is desirable for the model to pro-duce an output score s(xi) that is much larger thanthe score s(?xi) for each pair of training instances.Thus we perform training to maximize the separa-tion margins between the pairs of scores over pos-itive and negative samples under a hinge loss; thatis we minimize the following training lossJ(D) =1NN?i=1max(0, 1?
s(xi) + s(?xi)) (5)We perform a random initialization over thelook-up table and weight model parameters, andset all the bias model parameters to zeros.
Then weuse a stochastic gradient descent (Bottou, 1991)algorithm to perform optimization.3.4 Cross-Lingual Dependency ParsingThe training of deep network model above willproduce a word embedding matrix R for all wordsin the two language domains.
Moreover, by hav-ing each translated bilingual pair of words shar-ing the same representation vector in R in thetraining process, the embedding matrix R is ex-pected to capture consistent and comparable se-mantic meanings across languages, and provide alanguage-independent and distributed representa-tion for each word in the bilingual dictionary V .Given R, for each sentence x = w1, w2, .
.
.
, wnfrom the two language domains, we retrieved therepresentation vector R(wi) for each word wi.Moreover, we further delexicalized the sentenceby replacing the sequence of language-specificwords with a sequence of universal POS tags(Petrov et al., 2012).
Finally we train a delexical-ized dependency parser on the labeled sentencesin the source language based on the universal POStag features and the learned distributed features.and apply it to perform dependency parsing on thesentences in the target language domain.4 ExperimentsWe empirically evaluated the proposed cross-lingual word representation learning for cross-lingual dependency parsing.
In this section, wepresent the experimental setup and the results.4.1 DatasetWe used the dataset from the CoNLL shared task(Buchholz and Marsi, 2006; Nivre et al., 2007) forcross-lingual dependency parsing.
We conductedexperiments with the following nine languages:English (EN), Danish (DA), German (DE), Greek(EL), Spanish (ES), Italian (IT), Dutch (NL), Por-tuguese (PT) and Swedish (SV).
For each lan-guage, there is a separate training set and a test set.We used English, which usually has more labeledresources, as the source language, while treat-ing the others as target languages.
We thus con-structed eight cross-lingual dependency parsingtasks (EN2DA, EN2DE, EN2EL, EN2ES, EN2IT,EN2NL, EN2PT, EN2SV), one for each of theeight target languages.
For example, the taskEN2DA means that we used Danish (DA) as thetarget language while using English (EN) as thesource language.
For each cross language de-pendency parsing task, we first performed repre-sentation learning and then conducted dependencyparsing training and test.In this dataset, each sentence is labeled withgold standard part-of-speech tags.
To producedelexicalized cross-lingual dependency parsers,we mapped these language-specific part-of-speechtags into twelve universal POS tags (Petrov et al.,2012): ADJ (adjectives), ADP (prepositions orpostpositions), ADV (adverbs), CONJ (conjunc-tions), DET (determiners), NOUN (nouns), NUM(numerals), PRON (pronouns), PRT (particles),PUNC (punctuation marks), VERB (verbs) and X(for others).4.2 Representation LearningFor each language pair, we produced a set of one-to-one bilingual word pairs using Wikitionary tobuild cross language connections.
The numbersof bilingual word pairs produced for all the eightlanguage pairs and the numbers of words in eachlanguage are given in Table 1.123Table 1: The number of words in each language and the number of selected bilingual word pairs for eachof the eight language pairs.Language Pairs # Source Words # Target Words # Bilingual Word PairsEnglish vs Danish 26599 17934 1140English vs Dutch 26599 27829 2976English vs German 26599 69336 1905English vs Greek 26599 13318 869English vs Italian 26599 13523 2347English vs Portuguese 26599 27782 2408English vs Spanish 26599 16465 2910English vs Swedish 26599 19072 1779Table 2: The feature templates used for the cross-lingual dependency parsing.
dir denotes the directionof the dependency relationship, which has two values {left, right}.
dist denotes the distance betweenthe head word and the dependent word, which has five values {1, 2, 3-5, 6-10, 11+}.Feature Template Feature DescriptionUPOS(wh) the head word?s universal POS tagUPOS(wd) the dependent word?s universal POS tagUPOS(wh, wd) the universal POS tag pair of the head and dependent wordR(wh) the head word?s distributed representationR(wd) the dependent word?s distributed representationdir&UPOS conjunction features related to the dependency directiondist&UPOS conjunction features related to the dependency distancedir&dist&UPOS conjunction features related to the dependency direction and distanceTo perform distributed cross-lingual representa-tion learning using the proposed deep network ar-chitecture, we first constructed the two-class train-ing dataset from all the sentences (training andtest sentences) of the two language domains.
Thisrequires the creation of sub-sentences with fixedwindow size c from the given sentences.
We usedwindow size c = 5 in the experiments.
For ex-ample, for a given sentence ?I visited New York.?
, we can produce a number of sub-sentences,including ?<PAD> <S> I visited New?, ?<S> Ivisited New York?, ?I visited New York .
?, ?vis-ited New York .
</S>?, and ?New York .
</S><PAD>?, where <PAD> is special token to fillthe length requirement.
Negative samples are con-structed by simply replace the middle word of eachsub-sentence with a random word.With the constructed training data, we then per-formed training over the deep neural network.
Weused 3 hidden layers with 100 hidden units ineach layer, considering the model capacity and thetraining effort.
The dimension k of the embeddingword vectors in R is set as 200.4.3 Cross-lingual Dependency ParsingWe used the MSTParser (McDonald et al., 2005a;McDonald et al., 2005b) as the basic dependencyparsing model.
MSTParser uses spanning treealgorithms to seek for the candidate dependencytrees and employs an online large margin train-ing optimization algorithm.
MSTParser is widelyused in the literature for dependency parsing tasksand has demonstrated good empirical results in theCoNLL shared tasks on multilingual dependencyparsing (Buchholz and Marsi, 2006; Nivre et al.,2007).
For this dependency parsing model, thereare a few parameters to be set: the number of max-imum iterations for the perceptron training, andthe number of best-k dependency tree candidates.We set the number of iterations to be 10 and onlyconsidered the best-1 dependency tree candidate.For the proposed cross-lingual dependencyparsing approach, we used both the delexi-124Table 3: Test performance in terms of UAS (unlabeled attachment score) on the eight cross-lingualdependency parsing tasks.
?
denotes the improvements of each method over the Baseline method.Tasks Baseline Proj ?
Proposed ?
X-lingualEN2DA 36.53 41.25 4.72 42.56 6.03 38.70EN2DE 46.24 49.15 2.91 49.54 3.30 50.70EN2EL 61.53 62.36 0.83 62.96 1.43 63.00EN2ES 52.05 54.54 2.49 55.72 3.67 62.90EN2IT 56.37 57.71 1.34 59.05 2.68 68.80EN2NL 61.96 64.41 2.45 65.13 3.17 54.30EN2PT 68.68 71.47 2.79 72.38 3.70 71.00EN2SV 57.79 60.99 3.20 61.88 4.09 56.90Average 55.14 57.74 2.60 58.90 3.51 58.29calized universal POS tag based features andthe language-independent word features producedfrom the deep learning as input features for theMSTParser.
The set of universal POS tag basedfeature templates is given in Table 2.
For eachdependency relationship between a head word whand a dependent word wd, a set of features canbe produced from the feature templates in Ta-ble 2, which can be further augmented by R(wh)and R(wd).
We compared our proposed approach(Proposed) with three other methods, Baseline,Proj and X-lingual.
The Baseline method uses adelexicalized MSTParser based only on the uni-versal POS tag features.
The Proj method is devel-oped in (Durrett et al., 2012), which uses a bilin-gual dictionary to learn cross-lingual features andthen uses them as augmenting features to train adelexicalized MSTParser.
The X-lingual methoduses unlabeled parallel sentences to learn cross-lingual word clusters and used them as augment-ing features to train a delexicalized MSTParser(Ta?ckstro?m et al., 2012).
All parsers except X-lingual are trained on the labeled sentences in thesource language domain and tested on the testsentences in the target language domain in thegiven dataset.
The performance is measured usingthe standard unlabeled attachment score (UAS).The X-lingual method uses different auxiliary re-sources (parallel sentences), and we hence directlycited the results reported in (Ta?ckstro?m et al.,2012) on the same dataset.4.4 Results and DiscussionsWe reported the empirical comparison results interms of unlabeled attachment score (UAS) in Ta-ble 3.
We can see that the Baseline method per-Table 4: Statistic differences.
For each task, wereport the percentage of sentences in the test datafrom the target language which share the same se-quence of universal POS tags with some sentencesin the source language but with different depen-dency trees.Target Language Sentence DifferenceDanish 0.31%Dutch 1.81%German 1.40%Greek 1.20%Italian 2.40%Portuguese 1.04%Spanish 0.97%Swedish 2.31%forms poorly across all the tasks.
The average un-labeled attachment score for this approach acrossall the eight tasks is very low (about 55.14), whichsuggests that the twelve universal POS tags are farfrom enough to produce a good cross-lingual de-pendency parser.
Considering the small numberof universal POS tags, its limited discriminativecapacity as input features for dependency pars-ing is understandable.
To further verify this, wecalculated the percentage of sentences in the testdata which share the same sequence of universalPOS tags with a training sentence in the sourcelanguage but have different dependency parsingstructures.
The values for the eight tasks are pre-sented in Table 4.
The non-trivial values reportedverified the universal POS tags?
drawback on lack-ing discriminative capacity.By relexicalizing the delexicalized MSTParser125via augmenting the POS tag sequences withlearned interlingual features, both the Proj methodand the proposed method overcome the draw-back of using solely universal POS tags and pro-duce significant improvements over the Baselinemethod across all the tasks.
Moreover, the pro-posed method consistently outperforms both Base-line and Proj for all the eight tasks.
By exploit-ing only free bilingual dictionaries, the proposedmethod achieves similar average performance tothe X-lingual method which requires additionalparallel sentences.
All these results demonstratedthe efficacy of our word representation learningmethod for cross-lingual dependency parsing.4.5 Impact of Labeled Training Data inTarget LanguageIn the experiments above, all the labeled sen-tences for dependency parsing training are fromthe source language.
We wonder how much bene-fit we can get if there are a small number of labeledsentences in the target language as well.
To answerthis question, we conducted experiments by usinga small number (?t) of labeled sentences in thetarget language domain together with the labeledsentences in the source language domain to traincross-lingual dependency parsers.
Again the per-formance of the parsers are evaluated on the testsentences in the target language.
We tested a fewdifferent ?tvalues with ?t?
{500, 1000, 1500}.We reported the unlabeled attachment score for allthe eight cross-lingual dependency parsing tasksin Figure 2.
We can see that the Baseline methodstill performs poorly across the range of differentsetting for all the eight tasks.
The Proj methodand the proposed method again consistently out-perform the baseline method across all the tasks,while the proposed method achieves the best re-sults across all the eight tasks.4.6 Impact of the Number of Bilingual WordPairsFor the eight language pairs, we have reportedthe numbers of words in each language domainand the numbers of selected bilingual word pairsin Table 1.
Next we investigated how the num-ber of word pairs affects the performance of theproposed cross-lingual dependency parsing.
Withthe selected full set of bilingual word pairs inTable 1, we random selected m% of them withm ?
{50, 75, 100} to conduct experiments.
Notewhen m = 50, we only used 435 word pairs forthe EN2EL (English vs. Greek) task, which is1.6% of the number of source words and 3.3% ofthe number of target words.
The results are re-ported in Figure 3.
We can see that by reducing thenumber of bilingual word pairs, the performanceof the proposed cross-lingual dependency parsingmethod degrades on all tasks.
This is reasonablesince the word pairs serve as the pivots for learn-ing cross-lingual word embeddings.
Nevertheless,by preserving 75% of the selected word pairs, theproposed approach can still outperform the Projmethod across all the tasks.
Even with only 50%of the word pairs, our method still outperformsthe Proj method on most tasks.
These results sug-gest that the proposed cross-lingual word embed-ding method only requires a reasonable amount ofbilingual word pairs to effectively transfer a de-pendency parser from the source language to thetarget language.EN2DA EN2DE EN2EL EN2ES EN2IT EN2NL EN2PT EN2SV4045505560657075UAS vs # of Bilingual Word PairsTaskUASProj Proposed?50% Proposed?75% Proposed?100%Figure 3: Test performance in terms of UAS (unla-beled attachment score) in the target language withdifferent numbers of bilingual word pairs.5 ConclusionIn this paper, we proposed to automatically learnlanguage-independent features within a deep neu-ral network architecture to address cross-lingualdependency parsing problems.
We first con-structed a set of bilingual word pairs with Wiki-tionary, which serve as the pivots in the bilingualvocabulary for building connections across lan-guages.
We then conducted distributed word rep-resentation learning by training a constructed aux-iliary classifier using deep neural networks, whichinduced a real-valued embedding vector for eachword of the bilingual vocabulary to capture con-1260 500 1000 1500353637383940414243EN2DALabeled target training dataUASBaselineProjProposed0 500 1000 1500454647484950EN2DELabeled target training dataUASBaselineProjProposed0 500 1000 15006060.56161.56262.56363.564EN2ELLabeled target training dataUASBaselineProjProposed0 500 1000 1500515253545556EN2ESLabeled target training dataUASBaselineProjProposed0 500 1000 1500555657585960EN2ITLabeled target training dataUASBaselineProjProposed0 500 1000 150060616263646566EN2NLLabeled target training dataUASBaselineProjProposed0 500 1000 150067686970717273EN2PTLabeled target training dataUASBaselineProjProposed0 500 1000 150056575859606162EN2SVLabeled target training dataUASBaselineProjProposedFigure 2: Unlabeled attachment score (UAS) on the test sentences in the target language by using differ-ent number of additional labeled training sentences in the target language.sistent semantic similarities for words in the twolanguage domains.
The distributed word embed-ding vectors were then used to augment the uni-versal POS tags to train cross-lingual dependencyparsers.
We empirically evaluated the proposedmethod on eight cross-lingual dependency parsingtasks between eight language pairs.
The experi-mental results demonstrated the effectiveness ofthe proposed method, comparing to other cross-lingual dependency parsing methods.ReferencesL.
Bottou.
1991.
Stochastic gradient learning in neuralnetworks.
In Proceedings of Neuro-N??mes.S.
Buchholz and E. Marsi.
2006.
Conll-x shared taskon multilingual dependency parsing.
In Proceedingsof the Conference on Computational Natural Lan-guage Learning (CoNLL).D.
Burkett, S. Petrov, J. Blitzer, and D. Klein.
2010.Learning better monolingual models with unanno-tated bilingual text.
In Proceedings of the Confer-ence on Computational Natural Language Learning(CoNLL).W.
Che, M. Wang, C. Manning, and T. Liu.
2013.Named entity recognition with bilingual constraints.In Proceedings of Conference of the North AmericanChapter of the Association for Computational Lin-guistics: Human Language Technologies (NAACL).R.
Collobert and J. Weston.
2008.
A unified architec-ture for natural language processing: Deep neural127networks with multitask learning.
In Proceedings ofthe International Conference on Machine Learning(ICML).R.
Collobert, J. Weston, L. Bottou, M. Karlen,K.
Kavukcuoglu, and P. Kuksa.
2011.
Natural lan-guage processing (almost) from scratch.
Journalof Machine Learning Research (JMLR), 12:2493?2537.D.
Das and S. Petrov.
2011.
Unsupervised part-of-speech tagging with bilingual graph-based projec-tions.
In Proceedings of the Annual Meeting of theAssociation for Computational Linguistics: HumanLanguage Technologies (ACL).G.
Durrett, A. Pauls, and D. Klein.
2012.
Syntactictransfer using a bilingual lexicon.
In Proceedings ofthe Joint Conference on Empirical Methods in Nat-ural Language Processing and Computational Nat-ural Language Learning (EMNLP-CoNLL).K.
Ganchev, J. Gillenwater, and B. Taskar.
2009.
De-pendency grammar induction via bitext projectionconstraints.
In Proceedings of the Joint Conferenceof the Annual Meeting of the ACL and the Interna-tional Joint Conference on Natural Language Pro-cessing of the AFNLP (ACL-IJCNLP).W.
Guo and M. Diab.
2010.
Combining orthogonalmonolingual and multilingual sources of evidencefor all words wsd.
In Proceedings of the AnnualMeeting of the Association for Computational Lin-guistics (ACL).J.
Henderson.
2004.
Discriminative training of a neu-ral network statistical parser.
In Proceedings of theAnnual Meeting of the Association for Computa-tional Linguistics (ACL).R.
Hwa, P. Resnik, A. Weinberg, C. Cabezas, andO.
Kolak.
2005.
Bootstrapping parsers via syntacticprojection across parallel texts.
Natural LanguageEngineering, 11:11?311.W.
Jiang, Q. Liu, and Y. Lu?.
2011.
Relaxed cross-lingual projection of constituent syntax.
In Proceed-ings of the Conference on Empirical Methods in Nat-ural Language Processing (EMNLP).M.
Khapra, S. Sohoney, A. Kulkarni, and P. Bhat-tacharyya.
2010.
Value for money: Balancing an-notation effort, lexicon building and accuracy formultilingual wsd.
In Proceedings of the Inter-national Conference on Computational Linguistics(COLING).S.
Kim and G. Lee.
2012.
A graph-based cross-lingual projection approach for weakly supervisedrelation extraction.
In Proceedings of the AnnualMeeting of the Association for Computational Lin-guistics (ACL).S.
Kim, M. Jeong, J. Lee, and G. Lee.
2010.
A cross-lingual annotation projection approach for relationdetection.
In Proceedings of the International Con-ference on Computational Linguistics (COLING).S.
Kim, K. Toutanova, and H. Yu.
2012.
Multilin-gual named entity recognition using parallel dataand metadata from wikipedia.
In Proceedings ofthe Annual Meeting of the Association for Compu-tational Linguistics (ACL).A.
Klementiev, I. Titov, and B. Bhattarai.
2012.
In-ducing crosslingual distributed representations ofwords.
In Proceedings of the International Confer-ence on Computational Linguistics (COLING).M.
Kozhevnikov and I. Titov.
2012.
Cross-lingualbootstrapping for semantic role labeling.
In Pro-ceedings of the NIPS Workshop on CrosslingualTechnologies (XLITE).K.
Liu, Y.
Lu?, W. Jiang, and Q. Liu.
2013.
Bilingually-guided monolingual dependency parsing grammarinduction.
In Proceedings of the Conference on An-nual Meeting of the Association for ComputationalLinguistics (ACL).R.
McDonald, K. Crammer, and F. Pereira.
2005a.
On-line large-margin training of dependency parsers.
InProceedings of the Annual Meeting on Associationfor Computational Linguistics (ACL).R.
McDonald, F. Pereira, K. Ribarov, and J. Hajic?.2005b.
Non-projective dependency parsing usingspanning tree algorithms.
In Proceedings of theConference on Human Language Technology andEmpirical Methods in Natural Language Processing(HLT-EMNLP).R.
McDonald, S. Petrov, and K. Hall.
2011.Multi-source transfer of delexicalized dependencyparsers.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing(EMNLP).T.
Naseem, H. Chen, R. Barzilay, and M. Johnson.2010.
Using universal linguistic knowledge to guidegrammar induction.
In Proceedings of the Confer-ence on Empirical Methods in Natural LanguageProcessing (EMNLP).T.
Naseem, R. Barzilay, and A. Globerson.
2012.
Se-lective sharing for multilingual dependency parsing.In Proceedings of the Annual Meeting of the Associ-ation for Computational Linguistics (ACL).J.
Nivre, J.
Hall, S. Ku?bler, R. McDonald, J. Nilsson,S.
Riedel, and D. Yuret.
2007.
The conll 2007shared task on dependency parsing.
In Proceed-ings of the Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning (EMNLP-CoNLL).S.
Petrov, D. Das, and R. McDonald.
2012.
A univer-sal part-of-speech tagset.
In Proceedings of the In-ternational Conference on Language Resources andEvaluation (LREC).128D.
Smith and J. Eisner.
2009.
Parser adaptation andprojection with quasi-synchronous grammar fea-tures.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing(EMNLP).R.
Socher, J. Pennington, E. Huang, A. Ng, andC.
Manning.
2011.
Semi-supervised recursive au-toencoders for predicting sentiment distributions.
InProceedings of the Conference on Empirical Meth-ods in Natural Language Processing (EMNLP).O.
Ta?ckstro?m, R. McDonald, and J. Uszkoreit.
2012.Cross-lingual word clusters for direct transfer of lin-guistic structure.
In Proceedings of the Conferenceof the North American Chapter of the Associationfor Computational Linguistics: Human LanguageTechnologies (NAACL).O.
Ta?ckstro?m, R. McDonald, and J. Nivre.
2013.Target language adaptation of discriminative trans-fer parsers.
In Proceedings of the Conference ofthe North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies (NAACL).I.
Titov and J. Henderson.
2007.
Constituent parsingwith incremental sigmoid belief networks.
In Pro-ceedings of the Annual Meeting of the Associationfor Computational Linguistics (ACL).I.
Titov and J. Henderson.
2010.
A latent variablemodel for generative dependency parsing.
In Pro-ceedings of the International Conference on ParsingTechnology (IWPT).I.
Titov and A. Klementiev.
2012.
Crosslingual induc-tion of semantic roles.
In Proceedings of the AnnualMeeting of the Association for Computational Lin-guistics (ACL).J.
Turian, L. Ratinov, and Y. Bengio.
2010.
Word rep-resentations: a simple and general method for semi-supervised learning.
In Proceedings of the AnnualMeeting of the Association for Computational Lin-guistics (ACL).M.
Wang and C. Manning.
2014.
Cross-lingual pseudo-projected expectation regularizationfor weakly supervised learning.
Transactions of theAssociation for Computational Linguistics (TACL),2:55?66.D.
Yarowsky and G. Ngai.
2001.
Inducing multilin-gual pos taggers and np bracketers via robust pro-jection across aligned corpora.
In Proceedings of theMeeting of the North American Chapter of the Asso-ciation for Computational Linguistics on LanguageTechnologies (NAACL).Y.
Zhang, R. Reichart, R. Barzilay, and A. Glober-son.
2012.
Learning to map into a universal postagset.
In Proceedings of the Joint Conference onEmpirical Methods in Natural Language Process-ing and Computational Natural Language Learning(EMNLP-CoNLL).H.
Zhao, Y.
Song, C. Kit, and G. Zhou.
2009.
Crosslanguage dependency parsing using a bilingual lex-icon.
In Proceedings of the Joint Conference of theAnnual Meeting of the ACL and the InternationalJoint Conference on Natural Language Processingof the AFNLP (ACL-IJCNLP).T.
Zhuang and C. Zong.
2010.
Joint inference for bilin-gual semantic role labeling.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing (EMNLP).W.
Zou, R. Socher, D. Cer, and C. Manning.
2013.Bilingual word embeddings for phrase-based ma-chine translation.
In Proceedings of the Conferenceon Empirical Methods in Natural Language Pro-cessing (EMNLP).129
