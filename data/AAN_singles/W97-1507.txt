Application-driven automatic subgrammar extractionRenate  Hensche lCentre for Cognitive Science2 Buccleuch Place, Edinburgh,  UK(henschel?cogsci.
ed.
ac.
uk)J ohn  BatemanLanguage and Communicat ion  ResearchUniversity of Stirling, Stirling, UK(j .
a. bat eman~st ir.
ac.
uk)Abst rac tThe space and run-time requirements ofbroad coverage grammars appear for manyapplications unreasonably large in relationto the relative simplicity of the task athand.
On the other hand, handcrafted de-velopment of application-dependent gram-mars is in danger of duplicating work whichis then difficult to re-use in other contextsof application.
To overcome this problem,we present in this paper a procedure for theautomatic extraction of application-tunedconsistent subgrammars f om proved large-scale generation grammars.
The proce-dure has been implemented for large-scalesystemic grammars and builds on the for-mal equivalence between systemic gram-mars and typed unification based gram-mars.
Its evaluation for the generation ofencyclopedia entries is described, and di-rections of future development, applicabil-ity, and extensions are discussed.
11 In t roduct ionAlthough we have reached a situation in computa-tional inguistics where large coverage grammars arewell developed and available in several formal tra-ditions, the use of these research results in actualapplications and for application to specific domainsis still unsatisfactory.
One reason for this is thatlarge-scale grammar specifications incur a seeminglyunnecessarily large burden of space and processingtime that often does not stand in relation to thesimplicity of the particular task.
The usual alterna-tives for natural anguage generation to date havebeen the handcrafted development of application or1This work was partially supported by the DAADthrough grant D/96/17139.sublanguage specific grammars or the use of tem-plate based generation grammars.
In (Busemann,1996) both approaches are combined resulting in apractical small generation grammar tool.
But stillthe grammars are handwritten or, if extracted fromlarge grammars, must be adapted by hand.
In gen-eral, both - the template and the handwritten ap-plication grammar approach - compromise the ideaof a general NLP system architecture with reusablebodies of general linguistic resources.We argue that this customization bottleneckcan be overcome by the automatic extraction ofapplication-tuned consistent generation subgram-mars from proved given large-scale grammars.
Inthis paper we present such an automatic subgram-mar extraction tool.
The underlying procedure isvalid for grammars written in typed unification for-malisms; it is here carried out for systemic grammarswithin the development environment for text gener-ation KPML (Bateman, 1997).
The input is a set ofsemantic specifications covering the intended appli-cation.
This can either be provided by generating apredefined test suite or be automatically producedby running the particular application during a train-ing phase.The paper is structured as follows.
First, an al-gorithm for automatic subgrammar extraction forarbitrary systemic grammars will be given, and sec-ond the application of the algorithm for generationin the domain of 'encyclopedia entries' will be illus-trated.
To conclude, we discuss everal issues raisedby the work described, including its relevance fortyped unification based grammar descriptions andthe possibilities for further improvements in genera-tion time.2 Grammar  ext rac t ion  a lgor i thmSystemic Functional Grammar (SFG) (Halliday,1985) is based on the assumption that the differ-entiation of syntactic phenomena is always deter-46mined by its function in the communicative context.This functional orientation has lead to the creationof detailed linguistic resources that are character-ized by an integrated treatment of content-related,textual and pragmatic aspects.
Computational in-stances of systemic grammar are successfully em-ployed in some of the largest and most influen-tial text generation projects--such as, for example,PENMAN (Mann, 1983), COMMUNAL (Fawcettand Tucker, 1990), TECHDOC (KSsner and Stede,1994), Drafter (Paris and Vander Linden , 1996),and Gist (Not and Stock, 1994).For our present purposes, however, it is the for-mal characteristics of systemic grammar and its im-plementations that are more important.
Systemicgrammar assumes multifunctional constituent s ruc-turesrepresentable as feature structures with corefer-ences.
As shown in the following function structureexample for the sentence "The people that buy sil-ver love it.
", different functions can be filled by oneand the same constituent:clauseSenser: \[-~ nominal-groupDeictic: det \[ Spelling: "the" \]Thing: noun \[ Spelling: "people" \]Qualifier: dependent-clause\[Spelling: \]"that buy silver"Process: /initeJ_ SpeUing: "love"\]Phenomenon: 2~\] nominal-group\[ SpeUing: "it" \]Subject: DTheme: \["i'\]Directcomplement: \[7\]Given the notational equivalence of HPSG andsystemic grammar first mentioned by (Carpenter,1992) and (Zajac, 1992), and further elaborated in(Henschel, 1995), one can characterize a systemicgrammar as a large type hierarchy with multiple(conjunctive and disjunctive) and multi-dimensionalinheritance with an open-world semantics.
Thebasic element of a systemic grammar--a so-calledsystem--is a type axiom of the form (adopting thenotation of CUF (DSrre et al, 1996)):entry  = type_ l  I type_2  I .
.
.
I type_n .where type1 to typen are exhaustive and disjoint sub-types of type entry, entry need not necessarily be asingle type; it can be a logical expression over typesformed with the connectors AND and oR.
A sys-temic grammar therefore resembles more a type lat-tice than a type hierarchy in the HPSG tradition.
Insystemic grammar, these basic type axioms, the sys-tems, are named; we will use entry(s) to denote theleft-hand side of some named system s, and out(s) todenote the set of subtypes {type1, type2, ..., type,}-the output of the system.
The following type ax-ioms taken from the large systemic English grammarNXGI~L (Matthiessen, 1983) shall illustrate the natureof systems in a systemic grammar:nominal_group = class_name \[ individual_name.nominal_group = wh_nominal \[ nonwh_nominal.
(OR class_name wh_nominal) = singular \[ plural.The meaning of these type axioms is fairly obvi-ous: Nominal groups can be subcategorized in class-names and individual-names on the one hand, theycan be subcategorized with respect to their WH-containment into WH-containing nominal-groupsand nominal-groups without WH-element on theother hand.
The singular/plural opposition is validfor class-names as well as for WH-containing nomi-nal groups (be they class or individual names), butnot for individual-names without WH-element.Systemic types inherit constraints with respect oappropriate features, their filler types, coreferencesand order.
Here are the constraints for some of thetypes defined above:nominal-group \[Thing: noun\]class-name \[Thing: common-noun,Deictic: top\]individual-name \[Thing: proper-noun\]wh-nominal \[Wh: top\]Universal principles and rules are in systemicgrammar not factored out.
The lexicon containsstem forms and has a detailed word class type hi-erarchy at its top.
Morphology is also organized asa monotonic type hierarchy.
Currently used imple-mentations of SFG are the PENMAN system (Pen-man Project, 1989), the KPML system (Bateman,1997) and WAG-KRL (O'Donnell, 1994).Our subgrammar extraction has been applied andtested in the context of the KPML environment.KPML adopts the processing strategy of the PEN-MAN system and so it is necessary to briefly de-scribe this strategy.
PENMAN performs a semanticdriven top-down traversal through the grammaticaltype hierarchy for every constituent.
Passed typesare collected and their feature constraints are unifiedto build a resulting feature structure.
Substructuregeneration requires an additional grammar traversalcontrolled by the feature values given in the super-structure.
In addition to the grammar in its orig-inal sense, the PENMAN system provides a par-ticular interface between grammar and semantics.This interface is organized with the help of so-called47choosers--these are decision trees associated witheach system of the grammar which control the se-lection of an appropriate subtype during traversal.Choosers hould be seen as a practical means of en-abling applications (including text planners) to in-teract with the grammar using purely semantic spec-ifications even though a fully specified semantic the-ory may not yet be available for certain importantareas necessary for coherent, fluent text generation.They also serve to enforce deterministic choice animportant property for practical generation (cf.
(Re-iter, 1994)).The basic form of a chooser node is as follows.
(ask query(answer1 actions)(answer2 actions)...)The nodes in a chooser are queries to the seman-tics, the branches contain a set of actions includingembedded queries.
Possible chooser actions are thefollowing:( sk query ( .
. )
... ( .
. )
)(choose type)( ident i fy  function concept)(copyhub functionl functionP)A choose action of a chooser explicitly selects one ofthe output types of its associated system.
In general,there can be several paths through a given chooserthat lead to the selection of a single grammaticaltype: each such path corresponds to a particularconfiguration of semantic properties sufficient o mo-tivate the grammatical type selected.
Besides this(choose type), choosers erve to create a binding be-tween given semantic objects and grammatical con-stituents to be generated.
This is performed by theaction ( ident i fy  function concept).
Because of themultifunctionality assumed for the constituent struc-ture in systemic grammar, two grammatical func-tions can be realized by one and the same constituentwith one and the same underlying semantics.
Theaction (eopyhub functionl function2) is responsiblefor identifying the semantics of both grammaticalfunctions.Within such a framework, the first stage of sub-grammar extraction is to ascertain a representativeset of grammatical types covering the texts for theintended application.
This can be obtained by run-ning the text generation system within the appli-cation with the full unconstrained grammar.
Allgrammatical types used during this training stageare collected to form the backbone for the subgram-mar to be extracted.
We call this cumulative typeset the goal-types.The list of goal-types then gives the point of depar-ture for the second stage, the automatic extraction ofa consistent subgrammar, goal-types i  used as a fil-ter against which systems (type axioms) are tested.Types not in goal-types have to be excised from thesubgrammar being extracted.
This is carried outfor the entries of the systems in a preparatory step.We assume that the entries are given in disjunctivenormal form.
First, every conjunction containinga type which is not in goal-types i removed.
Af-ter this deletion of unsatisfiable conjunctions, ev-ery type in an entry which is not in goal-types iremoved.
The restriction of the outputs of everysystem to the goal-types i  done during a simulateddepth-first raversal through the entire grammati-cal type lattice.
The procedure works on the typelattice with the revised entries.
Starting with themost general type start (and the most general sys-tem called rank which is the system with start as en-try), a hierarchy traversal looks for systems which al-though restricted to the type set goal-types actuallybranch, i.e.
have more than one type in their out-put.
These systems constitute the new subgrammar.In essence, each grammatical system s is examinedto see how many of its possible subtypes in out(s)are used within the target grammar.
Those typeswhich are not used are excised from the subgram-mar being extracted.
More specific types that aredependent on any excised types are not consideredfurther during the traversal.
Grammatical systemswhere there is only a single remaining unexcised sub-type collapse to form a degenerated pseudo-systemindicating that no grammatical variation is possiblein the considered application domain.
For example,in the application described in section 3 the systemindicative = declarative I interrogative.collapses intoindicative = declarative.because questions do not occur in the applicationdomain.
Pseudo-systems of this kind are not kept inthe subgrammar.
The types on their right-hand side(pseudotypes) are excised accordingly, although theyare used for deeper traversal, thus defining a pathto more specific systems.
Such a path can consist ofmore than one pseudotype, if the repeated traver-sal steps find further degenerated systems.
Con-straints defined for pseudo-types are raised, chooseractions are percolated own--i.e., more precisely,constraints belonging to a pseudo-type are unifiedwith the constraints of the most general not pseudotype at the beginning of the path.
Chooser actionsfrom systems on the path are collected and extendthe chooser associated with the final (and first notpseudo) system of the path.
However, in the case48extract-subgrammar(goaltypes)1 for all s E systemsdo entry(s) := remove-unsatisfiable-features(entry(s))2 .subgrammar.
:= 03 traverse-system(rank, start, start, O,goaltypes)traverse-system(s, type, supertype, inheritedconstraints, goaltypes)1 inter := out(s) A goaltypes2 i f  inter # 0then  i f  lentry(s)l = 1 and  linterl = 1then  do out := the single element in interconstraints := unify(constraints(out), inheritedconstraints)traverse-type(out, supertype, constraints, goaltypes)else do entry(s) := dnf-substitute( supertype, type, entry(s))out(s) := interpush(s, *subgrammar* )for  all out E interdo traverse-type(out, out, 0, goaltypes)constraints( upertype ) :=unify (constraint s( supert ype ),in herit edr eal iz at ions )traverse-type(type, supertype, inheritedconstraints, goaltypes) 1 who := who-has-in-entry(type)2 if  who = 0 and inheritedconstraints # 0then  do constraints(supertype) :=unify( constraints( upertype), inheritedconstraints)3 for  all s E whodo traverse-system(s, type, supertype, inheritedconstraints, goaltypes )Figure 1: Subgrammar extraction algorithmthat a maximal type is reached which is not in goal-types, chooser actions have to be raised too.
Thenumber of goal-types is then usually larger than thenumber of the types in the extracted subgrammarbecause all pseudotypes in goal-types are excised.As the recursion criteria in the traversal, we firstsimply look for a system which has the actual typein its revised entry regardless of the fact if it occursin a conjunction or not.
This on its own, however,oversimplifies the real logical relations between thetypes and would create an inconsistent subgrammar.The problem is the conjunctive inheritance.
If thecurrent type occurs in an entry of another systemwhere it is conjunctively bound, a deeper traversalis in fact only licensed if the other types of the con-junctions are chosen as well.
In order to performsuch a traversal, a breadth traversal with compila-tion of all crowns of the lattice (see (A~t-Kaci et al,1989)) would be necessary.
In order to avoid this po-tentially computationally very expensive operation,but not to give up the consistency of the subgram-mar, the implemented subgrammar extraction pro-cedure sketched in Figure 1 maintains all systemswith complex entries (be they conjunctive or disjunc-tive) for the subgrammar even if they do not reallybranch and collapse to a single-subtype system.
2 Arelated approach can be found in (O'Donnell, 1992)for the extraction of smaller systemic subgrammarsfor analysis.If the lexicon is organized as or under a com-plex type hierarchy, the extraction of an application-tuned lexicon is carried out similarly.
This has theeffect that closed class words are removed from thelexicon if they are not covered in the application do-main.
Open class words belonging to word classesnot covered by the subgrammar type set are re-moved.
Some applications do not need their own lex-icon for open class words because they can be linkedto an externally provided domain-specific thesaurus(as is the case for the examples discussed below).
Inthis case, a sublexicon extraction is not necessary.2 Keeping the disjunctive systems is not necessary forthe consistency, but saves multiple raising of one and thesame constraint.493 App l i ca t ion  fo r  text  type  ' lex iconb iograph ies 'The first trial application of the automatic subgram-mar extraction tool has been carried out for an in-formation system with an output component thatgenerates integrated text and graphics.
This in-formation system has been developed for the do-main of art history and is capable of providing shortbiography articles for around l0 000 artists.
Theunderlying knowledge base, comprising half a mil-lion semantic oncepts, includes automatically ex-tracted information from 14 000 encyclopedia r-ticles from McMillans planned publication "Dictio-nary of Art" combined with several additional infor-mation sources such as the Getty "Art and Archi-tecture Thesaurus"; the application is described indetail in (Kamps et al, 1996).
As input the userclicks on an artist name.
The system then performscontent selection, text planning, text and diagramgeneration and page layout automatically.
Possibleoutput languages are English and German.The grammar necessary for short biographicalarticles is, however, naturally much more con-strained than that supported by general bro i l -coverage grammars.
There are two main reasonsfor this: first, because of the relatively fixed texttype "encyclopedia biography" involved, and sec-ond, particularly in the example information system,because of the relatively simple nature of the knowl-edge base--this does not support more sophisticatedtext generation as might appear in full encyclopediaarticles.
Without extensive mpirical analysis, onecan already state that such a gram:mar is restrictedto main clauses, only coordinative complex clauses,and temporal and spatial prepositional phrases.
Itwould probably be possible to produce the generatedtexts with relatively complex templates and aggre-gation heuristics: but the full grammars for Englishand German available in KPML already covered therequired linguistic phenomena.The application of the automatic subgrammar ex-traction tool to this scenario is as follows.In the training phase, the information system runswith the full generation grammar.
All grammaticaltypes used during this stage are collected to yieldthe cumulative type set goal-types.
How many textexamples must be generated in this phase dependson the relative increase of new infi)rmation (occur-rence of new types) obtained with every additionalsentence generated.
We show here the results fortwo related text types: 'short artist biographies' and'artist biography notes'.Figure 2 shows the growth curve for the type set0 ~0260250240230 x220 <210200190180170 x1601501401301200x 30 60Example texts:60 90 120 150 1RO 21026050~11 ~111~ ~ m m mllll~90 120 150 180Roger Hilton was an English painter.
He wasborn at Northwood on 23 March 1911, and hedied at BotaUack on 23 February 1975.
Hestudied at Slade School in 1929 - 1931.
He cre-ated "February - March 1954", "Grey figure","Oi yoi yoi" and "June 1953 (deep cadmium)".Anni Albers is American, and she is a tex-tile designer, a draughtsman and a print-maker.
She was born in Berlin on 12 June1899.
She studied art in 1916 - 1919 withBrandenburg.
Also, she studied art at theKunstgewerbeschule in Hamburg in 1919 -1920 and the Bauhaus at Weimar and Dessanin 1922 - 1925 and 1925 - 1929.
In 1933 shesettled in the USA.
In 1933 - 1949 she taughtat Black Mountain College in North Carolina.23022021020019018017016015014013020Figure 2: Cumulative type use with sentences fromthe short biography text type(vertical axis) with each additional semantic specifi-cation passed from the text planner to the sentencegenerator (horizontal axis) for the first of these texttypes.
The graph shows the cumulative type usagefor the first 90 biographies generated, involving some230 sentences.
3 The subgrammar extraction for the"short artist biographies" text type can therefore beperformed with respect to the 246 types that arerequired by the generated texts, applying the algo-rithm described above.
The resulting extracted sub-grammar is a type lattice with only 144 types.
Thesize of the extracted subgrammar is only 11% of thatof the original grammar.
Run times for sentence gen-eration with this extracted grammar typically range3This represented the current extent of the knowledgebase when the test was performed.
It is therefore possiblethat with more texts, the size of the cumulative set wouldincrease slightly since the curve has not quite 'flattenedout'.
Explicit procedures for handling this situation aredescribed below.50n220210200190180170160150 ?140130120 0"~N 60 QN l~n 1 Kn i an '~ln= 220" ~ 2001901801701601501401302030 60 '90 120 150 180Example text:Nathan Drake was an English painter.
He wasborn at Lincoln in 1728, and he died at Yorkon 19 February 1778.Figure 3: Cumulative type use with sentences fromthe note biography text typefrom 55%-75% of that of the full grammar (see Ta-ble 1)--in most cases, therefore, less than one sec-ond with the regular KPML generation environment(i.e., unoptimized with full debugging facilities resi-dent).The generation times are indicative of the styleof generation implemented by KPML.
Clause typeswith more subtypes are likely to cause longer pro-cessing times than those with fewer subtypes.
Whenthere are in any case fewer subtypes available inthe full grammar (as in the existential shown in Ta-ble 1), then there will be a less noticeable improve-ment compared with the extracted grammar.
In ad-dition, the run times reflect he fact that the numberof queries being asked by choosers has not yet beenmaximally reduced in the current evaluation.
Notingthe cumulative set of inquiry responses during thetraining phase would provide sufficient informationfor more effective pruning of the extracted choosers.The second example shows similar improvements.The very short biography entry is appropriate morefor figure headings, margin notes, etc.
The cumu-lative type use graph is shown in Figure 3.
Withthis 'smaller' text type, the cumulative use stabilizesvery quickly (i.e., after 39 sentences) at 205 types.This remained stable for a test set of 500 sentences.Extracting the corresponding subgrammar yields agrammar involving only 101 types, which is 7% ofthe original grammar.
Sentence generation time isaccordingly faster, ranging from 40%-60% of that ofthe full grammar.
In both cases, it is clear that thesize of the resulting subgrammar is dramatically re-duced.
The generation run-time is cut to 2/3.
Therun-time space requirements are cut similarly.
Theprocessing time for subgrammar extraction is lessthan one minute, and is therefore not a significantissue for improvement.4 Conc lus ions  and  d i scuss ionIn this paper, we have described how generation re-sources for restricted applications can be developeddrawing on large-scale general generation grammars.This enables both re-use of those resources and pro-gressive growth as new applications are met.
Thegrammar extraction tool then makes it a simple taskto extract from the large-scale resources peciallytuned subgrammars for particular applications.
Ourapproach shows some similarities to that proposedby (Rayner and Carter, 1996) for improving parsingperformance by grammar pruning and specializationwith respect o a training corpus.
Rule componentsare 'chunked' and pruned when they are unlikely tocontribute to a successful parse.
Here we have shownhow improvements in generation performance can beachieved for generation grammars by removing partsof the grammar specification that are not used insome particular sublanguage.
The extracted gram-mar is generally known to cover the target sublan-guage and so there is no loss of required coverage.Another motivation for this work is the need forsmaller, but not toy-sized, systemic grammars fortheir experimental compilation into state-of-the-artfeature logics.
The ready access to consistent sub-grammars of arbitrary size given with the automaticsubgrammar extraction reported here allows us toinvestigate further the size to which feature logicrepresentations of systemic grammar can grow whileremaining practically usable.
The compilation of thefull grammar NIGEL has so far only proved possiblefor CUF (see (Henschel, 1995)), and the resultingtype deduction runs too slowly for practical applica-tions.It is likely that further improvements in gener-ation performance will be achieved when both thegrammatical structures and the extracted choosersare pruned.
The current results have focused pri-marily on the improvements brought by reconfig-uring the type lattice that defines the grammar.The structures generated are still the 'full' gram-matical structures that are produced by the cor-responding full grammar: if, however, certain con-stituent descriptions are always unified (conflated insystemic terminology) then, analogously to (Raynerand Carter, 1996), they are candidates for replace-ment by a single constituent description in theextracted subgrammar.
Moreover, the extractedchoosers can also be pruned directly with respectto the sublanguage.
Currently the pruning carried51improvement sentenceworst case 80best case 1430average caserun time (in ms)full grammar subgrammar380 3003250 1830ca.
900 ca.
590 310"There is Patti Delaroche.
""John Foster was born in Liverpoolon 1 January c 1787, and he died atBirkenhead on 21 August 1846.
"e.g., "Mary Moser was an Englishpainter."
"George Richmond stud-ied at Royal Academy in 1824.
"(Under Allegro Common Lisp running on a Sparcl0.
)Table 1: Example run times for "short artist biographies"out is only that entailed by the type lattice, It isalso possible however to maintain a record of theclassificatory inquiry responses that are used in asubgrammar: esponses that do not occur can thenmotivate further reductions in the choosers that arekept in the extracted grammar.
Evaluation of theimprovements in performance that these strategiesbring are in progress.One possible benefit of not pruning the chooser de-cision trees completely is to provide a fall-back posi-tion for when the input to the generation componentin fact strays outside of that expected by the target-ted subgrammar.
Paths in the chooser decision treethat do not correspond to types in the subgrammarcan be maintained and marked explicitly as 'out ofbounds' for that subgrammar.
This provides a se-mantic check that the semantic inputs to the genera-tor remain within the limits inherent in the extractedsubgrammar.
If it sufficiently clear that these lim-its will be adhered to, then further extraction willbe free of problems.
However if the demands of anapplication change over time, then it is also possibleto use the semantic hecks to trigger regenerationwith the full grammar: this offers improved averagethroughput while maintaining complete generation.Noting exceptions can also be used to trigger newsubgrammar extractions to adapt to the new appli-cations demands.
A number of strategies thereforepresent themselves for incorporatiug rammar ex-traction into the application development cycle.Although we have focused here on run-time im-provements, it is clear that the grammar extractiontool has other possible uses.
For example, the ex-istence of small grammars is one important contri-bution to providing teaching materials.
Also, theability to extract consistent subcomponents shouldmake it more straightforward to combine grammarfragments as required for particular needs.
Furthervalidation in both areas forms part of our ongoing re-search.
Moreover, a significantly larger reduction ofthe type lattice can be expected by starting not fromthe cumulative set of goal-types for the grammar e-duction, but from a detailed protocol of jointly usedtypes for every generated sentence of the trainingcorpus.
A clustering technique applied to such aprotocol is under development.Finally, the proposed procedure is not bound tosystemic grammar and can also be used to extractcommon typed unification subgrammars.
Here,however, the gain will probably not be as remark-able as in systemic grammar.
The universal prin-ciples of, for example, an HPSG cannot be excised.HPSG type hierarchies usually contain mainly gen-eral types, so that they will not be affected sub-stantially.
In the end, the degree of improvementachieved epends on the extent o which a grammarexplicitly includes in its type hierarchy distinctionsthat are fine enough to vary depending on text type.ReferencesHassan Ai't-Kaci, Robert Boyer, Patrick Lincoln, andRoger Nasr.
1989.
Efficient implementation of lat-tice operations.
A CM Transactions on ProgrammingLanguages and Systems, 11(1):115 - 146.John A. Bateman, 1997.
KPML Development Envi-ronment: multilinguai linguistic resource developmentand sentence generation.
German National Centerfor Information Technology (GMD), Institute for in-tegrated publication and information systems (IPSI),Darmstadt, Germany, January.
(Release 1.1).Stephan Busemann.
1996.
Best-first surface realization.In Proceedings o\] the 8th.
International Workshop onNatural Language Generation (INLG '96), pages 101-110, Herstmonceux, England, June.Bob Carpenter.
1992.
The Logic of Typed Feature Struc-tures.
Cambridge University Press, Cambridge, Eng-land.Jochen D6rre, Michael Dorna, and J5rg Junger,1996.
The CUF User's Manual.
Institut fiir52maschineile Sprachverarbeitung (IMS), UniversithtStuttgart, Germany.Robin P. Fawcett and Gordon H. Tucker.
1990.
Demon-stration of GENESYS: a very large, semantically basedsystemic functional grammar.
In 13th.
InternationalConference on Computational Linguistics (COLING-90), volume I, pages 47 - 49, Helsinki, Finland.Michael A.K.
Halliday.
1985.
An Introduction to Func-tional Grammar.
Edward Arnold, London.Renate Henschel.
1995.
Traversing the Labyrinth of Fea-ture Logics for a Declarative Implementation of LargeScale Systemic Grammars.
In Suresh Manandhar, ed-itor, Proceedings of the CLNLP 95.
April 1995, SouthQueens ferry.Thomas Kamps, Christoph Hiiser, Wiebke M/Shr, andIngrid Schmidt.
1996.
Knowledge-based informationacess for hypermedia reference works: exploring thespread of the bauhaus movement.
In Maristella Agostiand Alan F. Smeaton, editors, Information retrievaland hypertext, pages 225-255.
Kluwer Academic Pub-fishers, Boston/London/Dordrecht.William C. Mann.
1983.
An overview of the PENMANtext generation system.
Technical Report ISI/RR-83-114, USC/Information Sciences Institute, Marina delRey, CA.Christian M.I.M.
Matthiessen.
1983.
Systemic grammarin computation: the Nigel case.
In Proceedings of theFirst Annual Conference of the European Chapter ofthe Association for Computational Linguistics.Elena Not and Oliviero Stock.
1994.
Automatic gen-eration of instructions for citizens in a multilingualcommunity.
In Proceedings of the European LanguageEngineering Convention, Paris, France, July.Michael O'Donnell.
1992.
Prototype Electronic Dis-course Analyzer (EDA) Reference Guide, Computa-tional Processes I: Parser.
Technical report, FujitsuLimited, Tokyo, Japan.
(Internal report of projectcarried out at Fujitsu Australia Ltd., Sydney, ProjectLeader: Guenter Plum, Document Engineering Cen-tre).Michael O'Donnell.
1994.
Sentence analysis and genera-tion: a systemic perspective.
Ph.D. thesis, Universityof Sydney, Department of Linguistics, Sydney, Aus-tralia.C~cile L. Paris and Keith Vander Linden.
1996.DRAFTER: an interactive support ool for writing mul-tifingual instructions.
IEEE Computer.Penman Project.
1989.
PENMAN documentation: thePrimer, the User Guide, the Reference Manual, andthe Nigel manual.
Technical report, USC/InformationSciences Institute, Marina del Rey, California.Manny Rayner and David Carter.
1996.
Fast parsingusing pruning and grammar specialization.
In Pro-ceedings of A CL '96.Ehud Reiter.
1994.
Has a consensus NL generation ar-chitecture appeared, and is it psychologically plausi-ble?
In Proceedings of the 7th.
International Work-shop on Natural Language generation (INLGW '9~),pages 163-170, Kennebunkport, Maine.Dietmar RSsner and Manfred Stede.
1994.
Generat-ing multifingual documents from a knowledge base:the TECHDOC project.
In Proceedings of the 15th.International Conference on Computational Linguis-tics (CoLING 94), volume I, pages 339 - 346, Kyoto,Japan.R~mi Zajac.
1992.
Inheritance and constraint-basedgrammar formalisms.
Computational Linguistics,18(2):159 - 182, June.
(Special issue on inheritance:1).53
