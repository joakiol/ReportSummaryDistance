Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 289?293,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsMining Equivalent Relations from Linked DataZiqi Zhang1 Anna Lisa Gentile1 Isabelle Augenstein1Eva Blomqvist2 Fabio Ciravegna11 Department of Computer Science,University of Sheffield, UK2 Department of Computer and InformationScience, Link?ping University, Sweden{z.zhang, a.l.gentile, i.augenstein,f.ciravegna}@dcs.shef.ac.uk, eva.blomqvist@liu.seAbstractLinking heterogeneous resources is a major re-search challenge in the Semantic Web.
Thispaper studies the task of mining equivalent re-lations from Linked Data, which was insuffi-ciently addressed before.
We introduce an un-supervised method to measure equivalency ofrelation pairs and cluster equivalent relations.Early experiments have shown encouragingresults with an average of 0.75~0.87 precisionin predicting relation pair equivalency and0.78~0.98 precision in relation clustering.1 IntroductionLinked Data defines best practices for exposing,sharing, and connecting data on the SemanticWeb using uniform means such as URIs andRDF.
It constitutes the conjunction between theWeb and the Semantic Web, balancing the rich-ness of semantics offered by Semantic Web withthe easiness of data publishing.
For the last fewyears Linked Open Data has grown to a giganticknowledge base, which, as of 2013, comprised31 billion triples in 295 datasets1.A major research question concerning LinkedData is linking heterogeneous resources, the factthat publishers may describe analogous infor-mation using different vocabulary, or may assigndifferent identifiers to the same referents.
Amongsuch work, many study mappings between ontol-ogy concepts and data instances (e.g., Isaac et al2007; Mi et al, 2009; Le et al, 2010; Duan et al,2012).
An insufficiently addressed problem islinking heterogeneous relations, which is alsowidely found in data and can cause problems ininformation retrieval (Fu et al, 2012).
Existingwork in linking relations typically employ stringsimilarity metrics or semantic similarity mea-1 http://lod-cloud.net/state/sures that require a-priori domain knowledge andare limited in different ways (Zhong et al, 2002;Volz et al, 2009; Han et al, 2011; Zhao andIchise, 2011; Zhao and Ichise, 2012).This paper introduces a novel method to dis-cover equivalent groups of relations for LinkedData concepts.
It consists of two components: 1)a measure of equivalency between pairs of rela-tions of a concept and 2) a clustering process togroup equivalent relations.
The method is unsu-pervised; completely data-driven requiring no a-priori domain knowledge; and also language in-dependent.
Two types of experiments have beencarried out using two major Linked Data sets: 1)evaluating the precision of predicting equivalen-cy of relation pairs and 2) evaluating the preci-sion of clustering equivalent relations.
Prelimi-nary results have shown encouraging results asthe method achieves between 0.75~0.85 preci-sion in the first set of experiments while0.78~0.98 in the latter.2 Related WorkResearch on linking heterogeneous ontologicalresources mostly addresses mapping classes (orconcepts) and instances (Isaac et al 2007; Mi etal., 2009; Le et al, 2010; Duan et al, 2012;Schopman et al, 2012), typically based on thenotions of similarity.
This is often evaluated bystring similarity (e.g.
string edit distance), se-mantic similarity (Budanitsky and Hirst, 2006),and distributional similarity based on the overlapin data usage (Duan et al, 2012; Schopman etal., 2012).
There have been insufficient studieson mapping relations (or properties) across on-tologies.
Typical methods make use of a combi-nation of string similarity and semantic similaritymetrics (Zhong et al, 2002; Volz et al, 2009;Han et al, 2011; Zhao and Ichise, 2012).
Whilestring similarity fails to identify equivalent rela-tions if their lexicalizations are distinct, semanticsimilarity often depends on taxonomic structures289in existing ontologies (Budanitsky and Hirst,2006).
Unfortunately many Linked Data instanc-es use relations that are invented arbitrarily ororiginate in rudimentary ontologies (Parundekaret al, 2012).
Distributional similarity has alsobeen used to discover equivalent or similar rela-tions.
Mauge et al (2012) extract product proper-ties from an e-commerce website and alignequivalent properties using a supervised maxi-mum entropy classification method.
We studylinking relations on Linked Data and propose anunsupervised method.
Fu et al (2012) identifysimilar relations using the overlap of the subjectsof two relations and the overlap of their objects.On the contrary, we aim at identifying strictlyequivalent relations rather than similarity in gen-eral.
Additionally, the techniques introduced ourwork is also related to work on aligning multilin-gual Wikipedia resources (Adar et al, 2009;Bouma et al, 2009) and semantic relatedness(Budanitsky and Hirst, 2006).3 MethodLet t denote a 3-tuple (triple) consisting of a sub-ject (ts), predicate (tp) and object (to).
Linked Da-ta resources are typed and its type is called class.We write type (ts) = c meaning that ts is of class c.p denotes a relation and rp is a set of tripleswhose tp=p, i.e., rp={t | tp = p}.Given a specific class c, and its pairs of rela-tions (p, p?)
such that rp={t|tp=p, type(ts)=c} andrp?={t|tp=p?, type (ts)=c}, we measure the equiv-alency of p and p?
and then cluster equivalentrelations.
The equivalency is calculated locally(within same class c) rather than globally (acrossall classes) because two relations can have iden-tical meaning in specific class context but notnecessarily so in general.
For example, for theclass Book, the relations dbpp:title and foaf:nameare used with the same meaning, however forActor, dbpp:title is used interchangeably withawards dbpp:awards (e.g., Oscar best actor).In practice, given a class c, our method startswith retrieving all t from a Linked Data setwhere type(ts)=c, using the universal query lan-guage SPARQL with any SPARQL data end-point.
This data is then used to measure equiva-lency for each pair of relations (Section 3.1).
Theequivalence scores are then used to group rela-tions in equivalent clusters (Section 3.2).3.1 Measure of equivalenceThe equivalence for each distinct pair of rela-tions depends on three components.Triple overlap evaluates the degree of over-lap2 in terms of the usage of relations in triples.Let SO(p) be the collection of subject-objectpairs from rp and SOint the intersection)r(SO)r(SO)'p,p(SO 'ppint ??
[1]then the triple overlap TO(p, p?)
is calculated as}|r||)r,r(SO|,|r||)r,r(SO|{MAX'p'ppintp'ppint[2]Intuitively, if two relations p and p?
have alarge overlap of subject-object pairs in their datainstances, they are likely to have identical mean-ing.
The MAX function allows addressing infre-quently used, but still equivalent relations (i.e.,where the overlap covers most triples of an in-frequently used relation but only a very smallproportion of a much more frequently used).Subject agreement While triple overlap looksat the data in general, subject agreement looks atthe overlap of subjects of two relations, and thedegree to which these subjects have overlappingobjects.
Let S(p) return the set of subjects of rela-tion p, and O(p|s) returns the set of objects ofrelation p whose subjects are s, i.e.
:}st,pt|t{)s|r(O)s|p(O spop ????
[3]we define:)r(S)r(S)'p,p(S 'ppint ??
[4]|)'p,p(S|otherwise,|)s|'p(O)s|p(O|if,int)'p,p(Ss int?????
?001[5]|)'p(S)p(S|/|)'p,p(S| int ???
[6]then the agreement AG(p, p?)
is????
)'p,p(AG            [7]Equation [5] counts the number of overlappingsubjects whose objects have at least one overlap.The higher the value of ?, the more the two rela-tions ?agree?
in terms of their shared subjects.For each shared subject of p and p?
we count 1 ifthey have at least 1 overlapping object and 0 oth-erwise.
This is because both p and p?
can be1:many relations and a low overlap value couldmean that one is densely populated while theother is not, which does not necessarily meanthey do not ?agree?.
Equation [6] evaluates thedegree to which two relations share the same setof subjects.
The agreement AG(p, p?)
balancesthe two factors by taking the product.
As a result,2 In this paper overlap is based on ?exact?
match.290relations that have high level of agreement willhave more subjects in common, and higher pro-portion of shared subjects with shared objects.Cardinality ratio is a ratio between cardinali-ty of the two relations.
Cardinality of a relationCD(p) is calculated based on data:|)r(S||r|)p(CDpp?
[8]and the cardinality ratio is calculated as)}'p(CD),p(CD{MAX)}'p(CD),p(CD{IN)'p,p(CDR ?
[9]The final equivalency measure integrates allthe three components to return a value in [0, 2]:)'p,p(CDR)'p,p(AG)'p,p(TO)'p,p(E ??
[10]The measure will favor two relations that havesimilar cardinality.3.2 ClusteringWe apply the measure to every pair of relationsof a concept, and keep those with a non-zeroequivalence score.
The goal of clustering is tocreate groups of equivalent relations based on thepair-wise equivalence scores.
We use a simplerule-based agglomerative clustering algorithmfor this purpose.
First, we rank all relation pairsby their equivalence score, then we keep a pair if(i) its score and (ii) the number of triples coveredby each relation are above a certain threshold,TminEqvl and TminTP respectively.
Each pair formsan initial cluster.
To merge clusters, given anexisting cluster c and a new pair (p, p?)
whereeither p?c or p?
?c, the pair is added to c if E(p,p?)
is close (as a fractional number above thethreshold TminEqvlRel) to the average scores of allconnected pairs in c. This preserves the strongconnectivity in a cluster.
This is repeated until nomerge action is taken.
Adjusting these thresholdsallows balancing between precision and recall.4 Experiment DesignTo our knowledge, there is no publically availa-ble gold standard for relation equivalency usingLinked Data.
We randomly selected 21 concepts(Figure 1) from the DBpedia ontology (v3.8):Actor, Aircraft, Airline, Airport, Automobile,Band, BasketballPlayer, Book, Bridge, Comedian,Film, Hospital, Magazine, Museum, Restaurant,Scientist, TelevisionShow, TennisPlayer, Theatre,University, WriterFigure 1.
Concepts selected for evaluation.We apply our method to each concept to dis-cover clusters of equivalent relations, using asSPARQL endpoint both DBpedia3 and Sindice4and report results separately.
This is to studyhow the method performs in different conditions:on one hand on a smaller and cleaner dataset(DBpedia); on the other hand on a larger andmulti-lingual dataset (Sindice) to also test cross-lingual capability of our method.
We chose rela-tively low thresholds, i.e.
TminEqvl=0.1, TminTP=0.01% and TminEqvlRel=0.6, in order to ensure highrecall without sacrificing much precision.Four human annotators manually annotatedthe output for each concept.
For this preliminaryevaluation, we have limited the amount of anno-tations to a maximum of 100 top scoring pairs ofrelations per concept, resulting in 16~100 pairsper concept (avg.
40) for DBpedia experimentand 29~100 pairs for Sindice (avg.
91).
The an-notators were asked to rate each edge in eachcluster with -1 (wrong), 1 (correct) or 0 (cannotdecide).
Pairs with 0 are ignored in the evalua-tion (about 12% for DBpedia; and 17% for Sin-dice mainly due to unreadable encoded URLs forcertain languages).
To evaluate cross-lingualpairs, we asked annotators to use translationtools.
Inter-Annotator-Agreement (observedIAA) is shown in Table 1.
Also using this data,we derived a gold standard for clustering basedon edge connectivity and we evaluate (i) the pre-cision of top n% (p@n%) ranked equivalent rela-tion pairs and (ii) the precision of clustering foreach concept.Mean High LowDBpedia 0.79 0.89 0.72Sindice 0.75 0.82 0.63Table 1.
IAA on annotating pair equivalencySo far the output of 13 concepts has been an-notated.
This dataset 5  contains ?1800 relationpairs and is larger than the one by Fu et al(2012).
Annotation process shows that over 75%of relation pairs in the Sindice experiment con-tain non-English relations and mostly are cross-lingual.
We used this data to report performance,although the method has been applied to all the21 concepts, and the complete results can be vis-ualized at our demo website link.
Some examplesare shown in Figure 2.3 http://dbpedia.org/sparql4 http://sparql.sindice.com/5 http://staffwww.dcs.shef.ac.uk/people/Z.Zhang/ re-sources/paper/acl2013short/web/291Figure 2.
Examples of visualized clusters5 Result and DiscussionFigure 3 shows p@n% for pair equivalency6 andFigure 4 shows clustering precision.Figure 3. p@n%.
The box plots show the ranges ofprecision at each n%; the lines show the average.Figure 4.
Clustering precisionAs it is shown in Figure 2, Linked Data rela-tions are often heterogeneous.
Therefore, findingequivalent relations to improve coverage is im-portant.
Results in Figure 3 show that in mostcases the method identifies equivalent relationswith high precision.
It is effective for both sin-gle- and cross-language relation pairs.
The worstperforming case for DBpedia is Aircraft (for alln%), mostly due to duplicating numeric valuedobjects of different relations (e.g., weight, length,capacity).
The decreasing precision with respectto n% suggests the measure effectively rankscorrect pairs to the top.
This is a useful featurefrom IR point of view.
Figure 4 shows that themethod effectively clusters equivalent relationswith very high precision: 0.8~0.98 in most cases.6 Per-concept results are available on our website.Overall we believe the results of this early proof-of-concept are encouraging.
As a concrete exam-ple to compare against Fu et al (2012), for Bas-ketballPlayer, our method creates separate clus-ters for relations meaning ?draft team?
and ?for-mer team?
because although they are ?similar?they are not ?equivalent?.We noticed that annotating equivalent rela-tions is a non-trivial task.
Sometimes relationsand their corresponding schemata (if any) arepoorly documented and it is impossible to under-stand the meaning of relations (e.g., due to acro-nyms) and even very difficult to reason based ondata.
Analyses of the evaluation output show thaterrors are typically found between highly similarrelations, or whose object values are numerictypes.
In both cases, there is a very high proba-bility of having a high overlap of subject-objectpairs between relations.
For example, for Air-craft, the relations dbpp:heightIn and dbpp:weight are predicted to be equivalent becausemany instances have the same numeric value forthe properties.
Another example are the Airportproperties dbpp:runwaySurface, dbpp:r1Surface,dbpp:r2Surface etc., which according to the dataseem to describe the construction material (e.g.,concrete, asphalt) of airport runways.
The rela-tions are semantically highly similar and the ob-ject values have a high overlap.
A potential solu-tion to such issues is incorporating ontologicalknowledge if available.
For example, if an ontol-ogy defines the two distinct properties of Airportwithout explicitly defining an ?equivalence?
re-lation between them, they are unlikely to beequivalent even if the data suggests the opposite.6 ConclusionThis paper introduced a data-driven, unsuper-vised and domain and language independentmethod to learn equivalent relations for LinkedData concepts.
Preliminary experiments showencouraging results as it effectively discoversequivalent relations in both single- and multi-lingual settings.
In future, we will revise theequivalence measure and also experiment withclustering algorithms such as (Beeferman et al,2000).
We will also study the contribution ofindividual components of the measure in suchtask.
Large scale comparative evaluations (incl.recall) are planned and this work will be extend-ed to address other tasks such as ontology map-ping and ontology pattern mining (Nuzzolese etal., 2011).292AcknowledgementPart of this research has been sponsored by theEPSRC funded project LODIE: Linked OpenData for Information Extraction, EP/J019488/1.Additionally, we also thank the reviewers fortheir valuable comments given for this work.ReferencesEytan Adar, Michael Skinner, Daniel Weld.2009.
Information Arbitrage across Multi-lingual Wikipedia.
Proceedings of the SecondACM International Conference on WebSearch and Data Mining, pp.
94 ?
103.Gosse Bouma, Sergio Duarte, Zahurul Islam.2009.
Cross-lingual Alignment and Comple-tion of Wikipedia Templates.
Proceedings ofthe Third International Workshop on CrossLingual Information Access: Addressing theInformation Need of Multilingual Societies,pp.
61 ?
69Doug Beeferman, Adam Berger.
2000.
Agglom-erative clustering of a search engine query log.Proceedings of the sixth ACM SIGKDD inter-national conference on Knowledge discoveryand data mining, pp.
407-416.Alexander Budanitsky and Graeme Hirst.
2006.Evaluating WordNet-based Measures of Se-mantic Distance.
Computational Linguistics,32(1), pp.13-47.Songyun Duan, Achille Fokoue, Oktie Has-sanzadeh, Anastasios Kementsietsidis, KavithaSrinivas, and Michael J.
Ward.
2012.
In-stance-Based Matching of Large OntologiesUsing Locality-Sensitive Hashing.
ISWC2012, pp.
46 ?
64Linyun Fu, Haofen Wang, Wei Jin, Yong Yu.2012.
Towards better understanding and uti-lizing relations in DBpedia.
Web Intelligenceand Agent Systems , Volume 10 (3)Andrea Nuzzolese, Aldo Gangemi, ValentinaPresutti, Paolo Ciancarini.
2011.
EncyclopedicKnowledge Patterns from Wikipedia Links.Proceedings of the 10th International SemanticWeb Conference, pp.
520-536Lushan Han, Tim Finin and Anupam Joshi.
2011.GoRelations: An Intuitive Query System forDBpedia.
Proceedings of the Joint Internation-al Semantic Technology ConferenceAntoine Isaac, Lourens van der Meij, StefanSchlobach, Shenghui Wang.
2007.
An empiri-cal study of instance-based ontology match-ing.
Proceedings of the 6th International Se-mantic Web Conference and the 2nd Asianconference on Asian Semantic Web Confer-ence, pp.
253-266Ngoc-Thanh Le, Ryutaro Ichise, Hoai-Bac Le.2010.
Detecting hidden relations in geograph-ic data.
Proceedings of the 4th InternationalConference on Advances in Semantic Pro-cessing, pp.
61 ?
68Karin Mauge, Khash Rohanimanesh, Jean-DavidRuvini.
2012.
Structuring E-Commerce Inven-tory.
Proceedings of ACL2012, pp.
805-814Jinhua Mi, Huajun Chen, Bin Lu, Tong Yu,Gang Pan.
2009.
Deriving similarity graphsfrom open linked data on semantic web.
Pro-ceedings of the 10th IEEE International Con-ference on Information Reuse and Integration,pp.
157?162.Rahul Parundekar, Craig Knoblock,  Jos?
Luis.Ambite.
2012.
Discovering Concept Cover-ings in Ontologies of Linked Data Sources.Proceedings of ISWC2012, pp.
427?443.Balthasar Schopman, Shenghui Wang, AntoineIsaac, Stefan Schlobach.
2012.
Instance-BasedOntology Matching by Instance Enrichment.Journal on Data Semantics, 1(4), pp 219-236Julius Volz, Christian Bizer, Martin Gaedke,Georgi Kobilarov.
2009.
Silk ?
A Link Discov-ery Framework for the Web of Data.
Proceed-ings of the 2nd Workshop on Linked Data onthe WebLihua Zhao, Ryutaro Ichise.
2011.
Mid-ontologylearning from linked data.
Proceedings of theJoint International Semantic Technology Con-ference, pp.
112 ?
127.Lihua Zhao, Ryutaro Ichise.
2012.
Graph-basedontology analysis in the linked open data.
Pro-ceedings of the 8th International Conferenceon Semantic Systems, pp.
56 ?
63Jiwei Zhong, Haiping Zhu, Jianming Li andYong Yu.
2002.
Conceptual Graph Matchingfor Semantic Search.
The 2002 InternationalConference on Computational Science.293
