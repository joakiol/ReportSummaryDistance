Proceedings of the ACL-SIGLEX Workshop on Deep Lexical Acquisition, pages 97?104,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsApproximate Searching for Distributional SimilarityJames Gorman and James R. CurranSchool of Information TechnologiesUniversity of SydneyNSW 2006, Australia{jgorman2,james}@it.usyd.edu.auAbstractDistributional similarity requires largevolumes of data to accurately representinfrequent words.
However, the nearest-neighbour approach to finding synonymssuffers from poor scalability.
The Spa-tial Approximation Sample Hierarchy(SASH), proposed by Houle (2003b), isa data structure for approximate nearest-neighbour queries that balances the effi-ciency/approximation trade-off.
We haveintergrated this into an existing distribu-tional similarity system, tripling efficiencywith a minor accuracy penalty.1 IntroductionWith the development of WordNet (Fellbaum, 1998)and large electronic thesauri, information from lex-ical semantic resources is regularly used to solveNLP problems.
These problems include collocationdiscovery (Pearce, 2001), smoothing and estimation(Brown et al, 1992; Clark and Weir, 2001) and ques-tion answering (Pasca and Harabagiu, 2001).Unfortunately, these resources are expensive andtime-consuming to create manually, and tend to suf-fer from problems of bias, inconsistency, and limitedcoverage.
In addition, lexicographers cannot keepup with constantly evolving language use and can-not afford to build new resources for the many sub-domains that NLP techniques are being applied to.There is a clear need for methods to extract lexicalsemantic resources automatically or tools that assistin their manual creation and maintenance.Much of the existing work on automatically ex-tracting resources is based on the distributional hy-pothesis that similar words appear in similar con-texts.
Existing approaches differ primarily in theirdefinition of ?context?, e.g.
the surrounding wordsor the entire document, and their choice of distancemetric for calculating similarity between the vectorof contexts representing each term.
Finding syn-onyms using distributional similarity involves per-forming a nearest-neighbour search over the contextvectors for each term.
This is very computation-ally intensive and scales according to the vocabularysize and the number of contexts for each term.
Cur-ran and Moens (2002b) have demonstrated that dra-matically increasing the quantity of text used to ex-tract contexts significantly improves synonym qual-ity.
Unfortunately, this also increases the vocabularysize and the number of contexts for each term, mak-ing the use of huge datasets infeasible.There have been many data structures and ap-proximation algorithms proposed to reduce the com-putational complexity of nearest-neighbour search(Cha?vez et al, 2001).
Many of these approaches re-duce the search space by using clustering techniquesto generate an index of near-neighbours.
We use theSpacial Approximation Sample Hierarchy (SASH)data structure developed by Houle (2003b) as it al-lows more control over the efficiency-approximationtrade-off than other approximation methods.This paper describes integrating the SASH intoan existing distributional similarity system (Cur-ran, 2004).
We show that replacing the nearest-neighbour search improves efficiency by a factor ofthree with only a minor accuracy penalty.972 Distributional SimilarityDistributional similarity systems can be separatedinto two components.
The first component extractsthe contexts from raw text and compiles them into astatistical description of the contexts each term ap-pears in.
The second component performs nearest-neighbour search or clustering to determine whichterms are similar, based on distance calculations be-tween their context vectors.
The approach used inthis paper follows Curran (2004).2.1 Extraction MethodA context relation is defined as a tuple (w, r,w?
)where w is a term, which occurs in some grammati-cal relation r with another word w?
in some sentence.We refer to the tuple (r,w?)
as an attribute of w. Forexample, (dog, diect-obj, walk) indicates that dogwas the direct object of walk in a sentence.Context extraction begins with a Maximum En-tropy POS tagger and chunker (Ratnaparkhi, 1996).The Grefenstette (1994) relation extractor producescontext relations that are then lemmatised using theMinnen et al (2000) morphological analyser.
Therelations for each term are collected together andcounted, producing a context vector of attributes andtheir frequencies in the corpus.2.2 Measures and WeightsBoth nearest-neighbour and cluster analysis meth-ods require a distance measure that calculates thesimilarity between context vectors.
Curran (2004)decomposes this measure into measure and weightfunctions.
The measure function calculates the sim-ilarity between two weighted context vectors and theweight function calculates a weight from the raw fre-quency information for each context relation.The SASH requires a distance measure that pre-serves metric space (see Section 4.1).
For these ex-periments we use the JACCARD (1) measure and theTTEST (2) weight, as Curran and Moens (2002a)found them to have the best performance in theircomparison of many distance measures.?(r,w?)
min(wgt(wm, ?r, ?w?
),wgt(wn, ?r, ?w?))?(r,w?)
max(wgt(wm, ?r, ?w?
),wgt(wn, ?r, ?w?
))(1)p(w, r,w?)
?
p(?, r,w?
)p(w, ?, ?
)?p(?, r,w?
)p(w, ?, ?
)(2)3 Nearest-neighbour searchThe simplest algorithm for finding synonyms isnearest-neighbour search, which involves pairwisevector comparison of the target term with every termin the vocabulary.
Given an n term vocabulary andup to m attributes for each term, the asymptotic timecomplexity of nearest-neighbour search is O(n2m).This is very expensive with even a moderate vocab-ulary and small attribute vectors making the use ofhuge datasets infeasible.3.1 HeuristicUsing cutoff to remove low frequency terms can sig-nificantly reduce the value of n. In these experi-ments, we used a cutoff of 5.
However, a solutionis still needed to reduce the factor m. Unfortunately,reducing m by eliminating low frequency contextshas a significant impact on the quality of the results.Curran and Moens (2002a) propose an initialheuristic comparison to reduce the number offull O(m) vector comparisons.
They introduce abounded vector (length k) of canonical attributes,selected from the full vector, to represent theterm.
The selected attributes are the most stronglyweighted verb attributes: Curran and Moens chosethese relations as they generally constrain the se-mantics of the term more and partake in fewer id-iomatic collocations.If a pair of terms share at least one canonicalattribute then a full similarity comparison is per-formed, otherwise the terms are not considered sim-ilar.
If a maximum of p positive results are returned,our complexity becomes O(n2k+npm), which, sincek is constant, is O(n2 + npm).4 The SASHThe SASH approximates a nearest-neighbour searchby pre-computing some of the near-neighbours ofeach node (terms in our case).
It is arranged as amulti-leveled pyramid, where each node is linkedto its (approximate) near-neighbours on the levelsabove and below.
This produces multiple paths be-tween nodes, allowing the SASH to shape itself tothe data set (Houle, 2003a).
This graph is searchedby finding the near-neighbours of the target nodeat each level.
The following description is adaptedfrom Houle (2003b).98AB C DE F G HI JK L12345Figure 1: A SASH, where p = 2, c = 3 and k = 24.1 Metric SpacesThe SASH organises nodes that can be measured inmetric space.
Although it is not necessary for theSASH to work, only in this space can performancebe guaranteed.
Our meaures produce a metric-likespace for the terms derived from large datasets.A domain D is a metric space if there exists afunction dist : D ?
D ?
R?0 such that:1. dist(p, q) ?
0 ?
p, q ?
D (non-negativity)2. dist(p, q) = 0 iff p = q ?
p, q ?
D (equality)3. dist(p, q) = dist(q, p) ?
p, q ?
D (symmetry)4. dist(p, q) + dist(q, r) ?
dist(p, r)?
p, q, r ?
D (triangle inequality)We invert the similarity measure to produce a dis-tance, resulting in condition 2 not being satisfiedsince dist(p, p) = x, x > 0.
For most measures xis constant, so dist(p, q) > dist(p, p) if p , q and pand q do not occur in exactly the same contexts.
Forsome measures, e.g.
DICE, dist(p, p) > dist(p, q),that is, p is closer to q than it is to itself.
These donot preserve metric space in any way, so cannot beused with the SASH.Cha?vez et al (2001) divides condition 2 into:5. dist(p, p) = 0 ?
p ?
D (reflexivity)6. dist(p, q) > 0 iff p , q ?
p, q ?
D(strict positiveness)If strict positiveness is not satisfied the space iscalled pseudometric.
In theory, our measures do notsatisfy this condition, however in practice most largedatasets will satisfy this condition.4.2 StructureThe SASH is a directed, edge-weighted graph withthe following properties:?
Each term corresponds to a unique node.?
The nodes are arranged into a hierarchy of lev-els, with the bottom level containing n2 nodesand the top containing a single root node.
Eachlevel, except the top, will contain half as manynodes as the level below.
These are numberedfrom 1 (top) to h.?
Edges between nodes are linked from consecu-tive levels.
Each node will have at most p par-ent nodes in the level above, and c child nodesin the level below.?
Every node must have at least one parent so thatall nodes are reachable from the root.Figure 1 shows a SASH which will be used below.4.3 ConstructionThe SASH is constructed iteratively by finding thenearest parents in the level above.
The nodes arefirst randomly distributed to reduce any clusteringeffects.
They are then split into the levels describedabove, with level h having n2 nodes, level 2 at most cnodes and level 1 having a single root node.The root node has all nodes at level 2 as childrenand each node at level 2 has the root as its sole par-ent.
Then for each node in each level i from 3 toh, we find the set of p nearest parent nodes in level(i ?
1).
The node then asks that parent if it can bea child.
As only the closest c nodes can be childrenof a node, it may be the case that a requested parentrejects a child.99DIST c LOAD TIMERANDOM 16 21.0hrRANDOM 64 15.6hrRANDOM 128 21.1hrFOLD1500 16 50.2hrFOLD1500 64 33.4hrFOLD1500 128 25.7hrSORT 16 75.5hrSORT 64 23.8hrSORT 128 33.8hrTable 1: Load time distributions and values of cIf a child is left without any parents it is said to beorphaned.
Any orphaned nodes must now find theclosest node in the above level that has fewer thanc children.
Once all nodes have at least one parent,we move to the next level.
This proceeds iterativelythrough the levels.4.4 SearchSearching the SASH is also performed iteratively.
Tofind the k nearest neighbours of a node q, we firstfind the k nearest neighbours at each level.
At level 1we take the single root node to be nearest.
Then, foreach level after, we find the k nearest unique childrenof the nodes found in the level above.
When thelast level has been searched, we return the closest knodes from all the sets of near neighbours returned.In Figure 1, the filled nodes demonstrate a searchfor the near-neighbours of some node q, using k = 2.Our search begins with the root node A.
As we areusing k = 2, we must find the two nearest children ofA using our similarity measure.
In this case, C andD are closer than B.
We now find the closest twochildren of C and D. E is not checked as it is onlya child of B.
All other nodes are checked, includingF and G, which are shared as children by B and C.From this level we chose G and H. We then considerthe fourth and fifth levels similarly.At this point we now have the list of near nodesA, C, D, G, H, I, J, K and L. From this we chosethe two nodes closest to q: H and I marked in black.These are returned as the near-neighbours of q.k can also be varied at each level to force a largernumber of elements to be tested at the base of theSASH using, for instance, the equation:ki = max{ k1?h?ilog2 n ,12pc } (3)We use this geometric function in our experiments.4.5 ComplexityWhen measuring the time complexity, we considerthe number of distance measurements as these dom-inate the computation.
If we do not consider theproblem of assigning parents to orphans, for nnodes, p parents per child, at most c children perparent and a search returning k elements, the looseupper bounds are:SASH constructionpcn log2 n (4)Approx.
k-NN query (uniform)ck log2 n (5)Approx.
k-NN query (geometric)k1+1log2 nk1log2 n?1+pc22log2 n (6)Since the average number of children per node isapproximately 2p, practical complexities can be de-rived using c = 2p.In Houle?s experiments, typically less than 5% ofcomputation time was spent assigning parents to or-phans, even for relatively small c. In some of ourexperiments we found that low values of c producedsignificantly worse load times that for higher values,but this was highly dependant on the distribution ofnodes.
Table 1 shows this with respect to severaldistributions and values of c.5 EvaluationThe simplest method of evaluation is direct com-parison of the extracted synonyms with a manually-created gold standard (Grefenstette, 1994).
How-ever, on small corpora, rare direct matches providelimited information for evaluation, and thesauruscoverage is a problem.
Our evaluation uses a com-bination of three electronic thesauri: the Macquarie(Bernard, 1990), Roget?s (Roget, 1911) and Moby(Ward, 1996) thesauri.100With this gold standard in place, it is possibleto use precision and recall measures to evaluate thequality of the extracted thesaurus.
To help overcomethe problems of direct comparisons we use severalmeasures of system performance: direct matches(DIRECT), inverse rank (INVR), and precision of thetop n synonyms (P(n)), for n = 1, 5 and 10.INVR is the sum of the inverse rank of eachmatching synonym, e.g.
matching synonyms atranks 3, 5 and 28 give an inverse rank score of13 +15 +128 , and with at most 100 synonyms, the max-imum INVR score is 5.187.
Precision of the top n isthe percentage of matching synonyms in the top nextracted synonyms.The same 70 single-word nouns were used for theevaluation as in Curran and Moens (2002a).
Thesewere chosen randomly from WordNet such that theycovered a range over the following properties:frequency Penn Treebank and BNC frequencies;number of senses WordNet and Macquarie senses;specificity depth in the WordNet hierarchy;concreteness distribution across WordNet subtrees.For each of these terms, the closest 100 terms andtheir similarity score were extracted.6 ExperimentsThe contexts were extracted from the non-speechportion of the British National Corpus (Burnard,1995).
All experiments used the JACCARD measurefunction, the TTEST weight function and a cutofffrequency of 5.
The SASH was constructed using thegeometric equation for ki described in Section 4.4.When the heuristic was applied, the TTESTLOGweight function was used with a canonical set sizeof 100 and a maximum frequency cutoff of 10,000.The values 4?16, 8?32, 16?64, and 32?128 werechosen for p and c. This gives a range of branch-ing factors to test the balance between sparseness,where there is potential for erroneous fragmentationof large clusters, and bushiness, where more testsmust be made to find near children.
The c = 4p re-lationship is derived from the simple hashing ruleof thumb that says that a hash table should haveroughly twice the size required to store all its ele-ments (Houle, 2003b).DIST FREQUENCY # RELATIONSMean Median Mean MedianRANDOM 342 18 126 13FOLD500 915 865.5 500 500FOLD1000 2155 1970.5 1001 1001.5FOLD1500 3656 3444 1506 1510.5SORT 44753 37937.5 8290 7583.5Table 2: Top 3 SASH level averages with c = 12800.20.40.60.811.21.41.60  1000  2000  3000  4000  5000  6000  7000InvRAvg Search Time (ms)randomfold1500sortFigure 2: INVR against average search timeOur initial experiments showed that the randomdistribution of nodes (RANDOM) in SASH construc-tion caused the nearest-neighbour approximation tobe very inaccurate for distributional similarity.
Al-though the speed was improved by two orders ofmagnitude when c = 16, it achieved only 13% of theINVR of the na?
?ve implementation.
The best RAN-DOM result was less than three times faster then thena?
?ve solution and only 60% INVR.In accordance with Zipf?s law the majority ofterms have very low frequencies.
Similarity mea-surements made against these low frequency termsare less reliable, as accuracy increases with the num-ber of relations and their frequencies (Curran andMoens, 2002b).
This led to the idea that orderingthe nodes by frequency before generating the SASHwould improve accuracy.The SASH was then generated with the highestfrequency terms were near the root so that the initialsearch paths would be more accurate.
This has theunfortunate side-effect of slowing search by up tofour times because comparisons with high frequencyterms take longer than with low frequency terms asthey have a larger number of relations.101DIST c DIRECT P(1) P(5) P(10) INVR SEARCH TIMENAIVE 2.83 49% 41% 32% 1.43 12217msRANDOM 16 0.17 9% 6% 3% 0.18 13% 120msRANDOM 64 1.09 30% 21% 15% 0.72 50% 1388msRANDOM 128 1.53 31% 24% 20% 0.86 60% 4488msSORT 16 1.51 33% 25% 20% 0.90 63% 490msSORT 64 2.55 47% 38% 31% 1.34 94% 2197msSORT 128 2.81 49% 41% 33% 1.43 100% 6960msTable 3: Evaluation of different random and fully sorted distributionsThis led to updating our original frequency order-ing idea by recognising that we did not need the mostaccurately comparable terms at the top of the SASH,only more accurately comparable terms than thoserandomly selected.As a first attempt, we constructed SASHs with fre-quency orderings that were folded about a chosennumber of relations M. For each term, if its num-ber of relations mi was greater than M, it was givena new ranking based on the score M2mi.
In this way,very high and very low frequency terms were pushedaway from the root.
The folding points this wastested for were 500, 1000 and 1500.
There are manyother node organising schemes we are yet to explore.The frequency distributions over the top three lev-els for each ordering scheme are shown in Table 2.Zipf?s law results in a large difference between themean and median frequency values in the RANDOMresults: most of the nodes have low frequency, butsome high frequency results push the mean up.
Thefour-fold reduction in efficiency for SORT (see Ta-ble 3) is a result of the mean number of relationsbeing over 65 times that of RANDOM.Experiments covering the full set of permutationsof these parameters were run, with and without theheuristic applied.
In the cases where the heuristicrejected pairs of terms, the SASH treated the rejectedpairs as being as infinitely far apart.
In addition, thebrute force solutions were generated with (NAIVEHEURISTIC) and without (NAIVE) the heuristic.We have assumed that all weights and measuresintroduce similar distribution properties into theSASH, so that the best weight and measure when per-forming a brute-force search will also produce thebest results when combined with the SASH.
Futureexperiments will explore SASH behaviour with othersimilarity measures.7 ResultsTable 3 presents the results for the initial experi-ments.
SORT was consistently more accurate thanRANDOM, and when c = 128, performed as well asNAIVE for all evaluation measures except for directmatches.
Both SASH solutions outperformed NAIVEin efficiency.The trade-off between efficiency and approxima-tion accuracy is evident in these results.
The mostefficient result is 100 times faster than NAIVE, butonly 13% accurate on INVR, with 6% of directmatches.
The most accurate result is 100% accu-rate on INVR, with 99% of direct matches, but isless than twice as fast.Table 4 shows the trade-off for folded distribu-tions.
The least accurate FOLD500 result is 30%accurate but 50 times faster than NAIVE, while themost accurate is 87% but less than two times faster.The least accurate FOLD1500 result is 43% accuratebut 71 times faster than NAIVE, while the most ac-curate is 101% and two and half times faster.
Theseresults show the impact of moving high frequencyterms away from the root.Figure 2 plots the trade-off using search time andINVR at c = 16, 32, 64 and 128.
For c = 16 everySASH has very poor accuracy.
By c = 64 their ac-curacy has improved dramatically, but their searchtime also increased somewhat.
At c = 128, thereis only a small improvement in accuracy, coincidingwith a large increase in search time.
The best trade-off between efficiency and approximation accuracyoccurs at the knee of the curve where c = 64.When c = 128 both SORT and FOLD1500 performas well as, or slightly outperform NAIVE on someevaluation measures.
These evaluation measures in-volve the rank of correct synonyms, so if the SASH102DIST c DIRECT P(1) P(5) P(10) INVR SEARCH TIMEFOLD500 16 0.53 23% 11% 8% 0.43 30% 243msFOLD500 64 1.69 49% 29% 23% 1.09 76% 2880msFOLD500 128 2.29 50% 35% 27% 1.25 87% 6848msFOLD1000 16 0.61 29% 14% 9% 0.51 35% 228msFOLD1000 64 2.07 49% 36% 26% 1.21 84% 3192msFOLD1000 128 2.57 50% 39% 31% 1.40 98% 4330msFOLD1500 16 0.90 30% 17% 13% 0.62 43% 171msFOLD1500 64 2.36 57% 39% 30% 1.36 95% 3193msFOLD1500 128 2.67 53% 42% 32% 1.44 101% 4739msTable 4: Evaluation of folded distributionsapproximation was to fail to find some incorrectlyproposed synonyms ranked above some other cor-rect synonyms, those correct synonyms would havetheir ranking pushed up.
In this way, the approxima-tion can potentially outperform the original nearest-neighbour algorithm.From Tables 3 and 4 we also see that as the valueof c increases, so does the accuracy across all ofthe experiments.
This is because as c increases thenumber of paths between nodes increases and wehave a solution closer to a true nearest-neighboursearch, that is, there are more ways of finding thetrue nearest-neighbour nodes.Table 5 presents the results of combining thecanonical attributes heuristic (see Section 3.1) withthe SASH approximation.
This NAIVE HEURISTIC is14 times faster than NAIVE and 97% accurate, with96% of direct matches.
The combination has com-parable accuracy and is much more efficient than thebest of the SASH solutions.
The best heuristic SASHresults used the SORT ordering with c = 16, whichwas 37 times faster than NAIVE and 2.5 times fasterthan NAIVE HEURISTIC.
Its performance was statis-tically indistinguishable from NAIVE HEURISTIC.Using the heuristic changes the impact of thenumber of children c on the SASH performance char-acteristics.
It seems that beyond c = 16 the onlysignificant effect is to reduce the efficiency (often toslower than NAIVE HEURISTIC).The heuristic interacts in an interesting way withthe ordering of the nodes in the SASH.
This is mostobvious with the RANDOM results.
The RANDOMheuristic INVR results are eight times better than thefull RANDOM results.
Similar, though less dramatic,results are seen with other orderings.
It appears thatusing the heuristic changes the clustering of nearest-neighbours within the SASH so that better matchingpaths are chosen and more noisy matches are elimi-nated entirely by the heuristic.It may seem that there are no major advantagesto using the SASH with the already efficient heuris-tic matching method.
However, our experimentshave used small canonical attribute vectors (maxi-mum length 100).
Increasing the canonical vectorsize allows us to increase the accuracy of heuristicsolutions at the cost of efficiency.
Using a SASH so-lution would offset some of this efficiency penalty.This has the potential for a solution that is more thanan order of magnitude faster than NAIVE and is al-most as accurate.8 ConclusionWe have integrated a nearest-neighbour approxima-tion data structure, the Spacial Approximation Sam-ple Hierarchy (SASH), with a state-of-the-art distri-butional similarity system.
In the process we haveextended the original SASH construction algorithms(Houle, 2003b) to deal with the non-uniform distri-bution of words within semantic space.We intend to test other similarity measures andnode ordering strategies, including a more linguisticanalysis using WordNet, and further explore the in-teraction between the canonical vector heuristic andthe SASH.
The larger 300 word evaluation set usedby Curran (2004) will be used, and combined with amore detailed analyis.
Finally, we plan to optimiseour SASH implementation so that it is comparablewith the highly optimised nearest-neighbour code.103DIST c DIRECT P(1) P(5) P(10) INVR SEARCH TIMENAIVE HEURISTIC 2.72 49% 40% 32% 1.40 827msRANDOM 16 2.61 50% 40% 31% 1.39 99% 388msRANDOM 64 2.72 49% 40% 32% 1.40 100% 1254msRANDOM 128 2.71 49% 40% 32% 1.40 100% 1231msFOLD1500 16 2.53 49% 40% 31% 1.36 97% 363msFOLD1500 64 2.72 49% 40% 32% 1.40 100% 900msFOLD1500 128 2.72 49% 40% 32% 1.40 100% 974msSORT 16 2.78 49% 40% 32% 1.41 100% 323msSORT 64 2.73 49% 40% 32% 1.40 100% 1238msSORT 128 2.73 49% 40% 32% 1.40 100% 1049msTable 5: Evaluation of different distributions using the approximationThe result is distributional similarity calculatedthree times faster than existing systems with only aminor accuracy penalty.AcknowledgementsWe would like to thank the anonymous reviewersfor their helpful feedback and corrections.
Thiswork has been supported by the Australian ResearchCouncil under Discovery Project DP0453131.ReferencesJohn R. L. Bernard, editor.
1990.
The Macquarie EncyclopedicThesaurus.
The Macquarie Library, Sydney, Australia.Peter F. Brown, Vincent J. Della Pietra, Peter V. deSouza, Jen-nifer C. Lai, and Robert L. Mercer.
1992.
Class-based n-gram models of natural language.
Computational Linguis-tics, 18(4):467?479, December.Lou Burnard, editor.
1995.
Users Reference Guide British Na-tional Corpus Version 1.0.
Oxford University ComputingServices.Edgar Cha?vez, Gonzalo Navarro, Ricardo Baeza-Yates, andJose?
L.
Marroqu??n.
2001.
Searching in metric spaces.
ACMComputing Surveys, 33(3):273?321, September.Stephen Clark and David Weir.
2001.
Class-based probabilityestimation using a semantic hierarchy.
In Proceedings of theSecond Meeting of the North American Chapter of the Asso-ciation for Computational Linguistics, pages 95?102, Pitts-burgh, PA USA, 2?7 June.James R. Curran and Marc Moens.
2002a.
Improvementsin automatic thesaurus extraction.
In Proceedings of theWorkshop of the ACL Special Interest Group on the Lexicon(SIGLEX), pages 59?66, Philadelphia, USA, 12 July.James R. Curran and Marc Moens.
2002b.
Scaling contextspace.
In Proceedings of the 40th annual meeting of theAssociation for Computational Linguistics, pages 231?238,Philadelphia, USA, 7?12 July.James R. Curran.
2004.
From Distributional to Semantic Simi-larity.
Ph.D. thesis, University of Edinburgh.Christiane Fellbaum, editor.
1998.
WordNet: an electronic lex-ical database.
The MIT Press, Cambridge, MA USA.Gregory Grefenstette.
1994.
Explorations in Automatic The-saurus Discovery.
Kluwer Academic Publishers, Boston,USA.Michael E. Houle.
2003a.
Navigating massive data sets via lo-cal clustering.
In Proceedings of the ninth ACM SIGKDDinternational conference on Knowledge discovery and datamining, pages 547?552, Washington, DC, USA, 24?27 Au-gust.Michael E. Houle.
2003b.
SASH: a saptial approximationsample hierarchy for similarity search.
Technical ReportRT0517, IBM Reasearch, Tokyo Research Laboratory, Yam-ato Kanagawa, Japan, March.Guido Minnen, John Carroll, and Darren Pearce.
2000.
Ro-bust applied morphological generation.
In Proceedings ofthe First International Natural Language Generation Con-ference, pages 201?208, Mitzpe Ramon, Israel, 12?16 June.Marius Pasca and Sanda Harabagiu.
2001.
The informativerole of wordnet in open-domain question answering.
In Pro-ceedings of the Workshop on WordNet and Other LexicalResources: Applications, Extensions and Customizations,pages 138?143, Pittsburgh, PA USA, 2?7 June.Darren Pearce.
2001.
Synonymy in collocation extraction.
InProceedings of the Workshop on WordNet and Other Lex-ical Resources: Applications, Extensions and Customiza-tions, pages 41?46, Pittsburgh, PA USA, 2?7 June.Adwait Ratnaparkhi.
1996.
A maximum entropy part-of-speech tagger.
In Proceedings of the Conference on Empir-ical Methods in Natural Language Processing, pages 133?142, 17?18 May.Peter Roget.
1911.
Thesaurus of English words and phrases.Longmans, Green and Co., London, UK.Grady Ward.
1996.
Moby Thesaurus.
Moby Project.104
