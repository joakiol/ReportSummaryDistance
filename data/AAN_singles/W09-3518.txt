Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 84?87,Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLPImproving transliteration accuracy using word-origin detection andlexicon lookupMitesh M. KhapraIIT Bombaymiteshk@cse.iitb.ac.inPushpak BhattacharyyaIIT Bombaypb@cse.iitb.ac.inAbstractWe propose a framework for translit-eration which uses (i) a word-origindetection engine (pre-processing) (ii) aCRF based transliteration engine and (iii)a re-ranking model based on lexicon-lookup (post-processing).
The resultsobtained for English-Hindi and English-Kannada transliteration show that the pre-processing and post-processing modulesimprove the top-1 accuracy by 7.1%.1 IntroductionMachine transliteration is the method of automati-cally converting Out-Of-Vocabulary (OOV) wordsin one language to their phonetic equivalents inanother language.
An attempt is made to retainthe original pronunciation of the source word toas great an extent as allowed by the orthographicand phonological rules of the target language.
Thisis not a great challenge for language pairs likeHindi-Marathi which have very similar alphabeticand phonetic sets.
However, the problem becomesnon-trivial for language pairs like English-Hindiand English-Kannada which have reasonably dif-ferent alphabet sets and sound systems.Machine transliteration find its application inCross-Lingual Information Retrieval (CLIR) andMachine Translation (MT).
In CLIR, machinetransliteration can help in translating the OOVterms like proper names and technical terms whichfrequently appear in the source language queries(e.g.
Jaipur in ?Jaipur palace?).
Similarly it canhelp improve the performance of MT by translat-ing proper names and technical terms which arenot present in the translation dictionary.Current models for transliteration can be clas-sified as grapheme-based models, phoneme-basedmodels and hybrid models.
Grapheme-based mod-els like source channel model (Lee and Choi,1998), Maximum Entropy Model (Goto et al,2003), Conditional Random Fields (Veeravalli etal., 2008) and Decision Trees (Kang and Choi,2000) treat transliteration as an orthographic pro-cess and try to map the source graphemes di-rectly to the target graphemes.
Phoneme basedmodels like the ones based on Weighted FiniteState Transducers (WFST) (Knight and Graehl,1997) and extended Markov window (Jung et al,2000) treat transliteration as a phonetic processrather than an orthographic process.
Under thisframework, transliteration is treated as a conver-sion from source grapheme to source phonemefollowed by a conversion from source phonemeto target grapheme.
Hybrid models either use acombination of a grapheme based model and aphoneme based model (Stalls and Knight, 1998)or capture the correspondence between sourcegraphemes and source phonemes to produce targetlanguage graphemes (Oh and Choi, 2002).Combining any of the above transliteration en-gines with pre-processing modules like word-origin detection (Oh and Choi, 2002) and/orpost-processing modules like re-ranking usingclues from monolingual resources (Al-Onaizanand Knight, 2002) can enhance the performance ofthe system.
We propose such a framework whichuses (i) language model based word-origin detec-tion (ii) CRF based transliteration engine and (iii)a re-ranking model based on lexicon lookup on thetarget language (Hindi and Kannada in our case).The roadmap of the paper is as follows.
Insection 2 we describe the 3 components of theproposed framework.
In section 3 we presentthe results for English-Hindi and English-Kannadatransliteration on the datasets (Kumaran andKellner, 2007) released for NEWS 2009 Ma-chine Transliteration Shared Task1(Haizhou et al,2009).
Section 4 concludes the paper.1https://translit.i2r.a-star.edu.sg/news2009/842 Proposed framework forTransliterationFigure 1: Proposed framework for transliteration.2.1 Word Origin DetectionTo emphasize the importance of Word Origin De-tection we consider the example of letter ?d?.When ?d?
appears in a name of Western origin (e.g.Daniel, Durban) and is not followed by the letter?h?, it invariably gets transliterated as Hindi letterX, whereas, if it appears in a name of Indic origin(e.g.
Indore, Jharkhand) then it is equally likely tobe transliterated as d or X.
This shows that the de-cision is influenced by the origin of the word.
TheIndic dataset (Hindi, Kannada, and Tamil) for theShared Task consisted of a mix of Indic and West-ern names.
We therefore felt the need of train-ing separate models for words of Indic origin andwords of Western origin.For this we needed to separate the words inthe training data based on their origin.
We firstmanually classified 3000 words from the trainingset into words of Indic origin and Western origin.These words were used as seed input for the boot-strapping algorithm described below:1.
Build two n-gram language models: one forthe already classified names of Indic originand another for the names of Western origin.Here, by n-gram we mean n-character ob-tained by splitting the words into a sequenceof characters.2.
Split each of the remaining words into a se-quence of characters and find the probabilityof this sequence using the two language mod-els constructed in step 1.3.
If the probability of a word (i.e.
a sequenceof characters) is higher in the Indic languagemodel than in the Western language modelthen classify it as Indic word else classify itas Western word.4.
Repeat steps 1-3 till all words have been clas-sified.Thus, we classified the entire training set intowords of Indic origin and words of Western origin.The two language models (one for words of Indicorigin and another for words of Western origin)thus obtained were then used to classify the testdata using steps 2 and 3 of the above algorithm.Manual verification showed that this method wasable to determine the origin of the words in the testdata with an accuracy of 97%.2.2 CRF based transliteration engineConditional Random Fields (Lafferty et al, 2001)are undirected graphical models used for labelingsequential data.
Under this model, the conditionalprobability distribution of the target word giventhe source word is given by,P (Y |X;?)
= 1Z(X) ?
ePTt=1PKk=1 ?kfk(Yt?1,Yt,X,t)(1)where,X = source word (English)Y = target word (Hindi,Kannada)T = length of source word (English)K = number of features?k = feature weightZ(X) = normalization constantCRF++2 which is an open source implemen-tation of CRF was used for training and decod-ing.
GIZA++ (Och and Ney, 2000), which is afreely available implementation of the IBM align-ment models (Brown et al, 1993) was used to getcharacter level alignments for English-Hindi wordpairs in the training data.
Under this alignment,each character in the English word is aligned tozero or more characters in the corresponding Hindiword.
The following features are then generatedusing this character-aligned data (here ei and hiare the characters at position i of the source wordand target word respectively):?
hi and ej such that i ?
2 ?
j ?
i + 2?
hi and source character bigrams ( {ei?1, ei}or {ei, ei+1})?
hi and source character trigrams ( {ei?2,ei?1, ei} or {ei?1, ei, ei+1} or {ei, ei+1,ei+2})2http://crfpp.sourceforge.net/85?
hi, hi?1 and ej such that i ?
2 ?
j ?
i + 2?
hi, hi?1 and source character bigrams?
hi, hi?1 and source character trigramsTwo separate models were trained: one for thewords of Indic origin and another for the wordsof Western origin.
At the time of testing, thewords were first classified as Indic origin wordsand Western origin words using the classifier de-scribed in section 2.1.
The top-10 transliterationsfor each word were then generated using the cor-rect CRF model depending on the origin of theword.2.3 Re-ranking using lexicon lookupSince the dataset for the Shared Task containswords of Indic origin there is a possibility that thecorrect transliteration of some of these words maybe found in a Hindi lexicon.
Such a lexicon con-taining 90677 unique words was constructed byextracting words from the Hindi Wordnet3.
If acandidate transliteration generated by the CRF en-gine is found in this lexicon then its rank is in-creased and it is moved towards the top of the list.If multiple outputs are found in the lexicon then allsuch outputs are moved towards the top of the listand the relative ranking of these outputs remainsthe same as that assigned by the CRF engine.
Forexample, if the 4th and 6th candidate generated bythe CRF engine are found in the lexicon then thesetwo candidates will be moved to positions 1 and 2respectively.
We admit that this way of movingcandidates to the top of the list is adhoc.
Ideally, ifthe lexicon also stored the frequency of each wordthen the candidates could be re-ranked using thesefrequencies.
But unfortunately the lexicon doesnot store such frequency counts.3 ResultsThe system was tested for English-Hindi andEnglish-Kannada transliteration using the dataset(Kumaran and Kellner, 2007) released for NEWS2009 Machine Transliteration Shared Task.
Wesubmitted one standard run and one non-standardrun for the English-Hindi task and one standardrun for the English-Kannada task.
The re-rankingmodule was used only for the non-standard run asit uses resources (lexicon) other than those pro-vided for the task.
We did not have a lexicon3http://www.cfilt.iitb.ac.in/wordnet/webhwnfor Kannada so were not able to apply the re-ranking module for English-Kannada task.
Theperformance of the system was evaluated us-ing 6 measures, viz., Word Accuracy in Top-1 (ACC), Fuzziness in Top-1 (Mean F-score),Mean Reciprocal Rank (MRR), MAPref , MAP10and MAPsys.
Please refer to the white paper ofNEWS 2009 Machine Transliteration Shared Task(Haizhou et al, 2009) for more details of thesemeasures.Table 1 and Table 2 report the results4 forEnglish-Hindi and English-Kannada translitera-tion respectively.
For English-Hindi we report3 results: (i) without any pre-processing (word-origin detection) or post-processing (re-ranking)(ii) with pre-processing but no post-processing and(iii) with both pre-processing and post-processing.The results clearly show that the addition of thesemodules boosts the performance.
The use ofword-origin detection boosts the top-1 accuracy byaround 0.9% and the use of lexicon lookup basedre-ranking boosts the accuracy by another 6.2%.Thus, together these two modules give an incre-ment of 7.1% in the accuracy.
Corresponding im-provements are also seen in the other 5 metrics.4 ConclusionWe presented a framework for transliterationwhich uses (i) a word-origin detection engine(pre-processing) (ii) a CRF based transliterationengine and (iii) a re-ranking model based onlexicon-lookup (post-processing).
The resultsshow that this kind of pre-processing and post-processing helps to boost the performance ofthe transliteration engine.
The re-ranking usinglexicon lookup is slightly adhoc as ideally there-ranking should take into account the frequencyof the words in the lexicon.
Since such frequencycounts are not available it would be useful to findthe web counts for each transliteration candidateusing a search engine and use these web counts tore-rank the candidates.4Please note that the results reported in this paper are bet-ter than the results we submitted to the shared task.
This im-provement was due to the correction of an error in the tem-plate file given as input to CRF++.86Method ACC MeanF-scoreMRR MAPref MAP10 MAPsysCRF Engine(no word origin detection, no re-ranking)0.408 0.878 0.534 0.403 0.188 0.188CRF Engine +Word-Origin detection(no re-ranking)Standard run0.417 0.877 0.546 0.409 0.192 0.192CRF Engine +Word-Origin detection +Re-rankingNon-Standard run0.479 0.884 0.588 0.475 0.208 0.208Table 1: Results for English-Kannada transliteration.Method Accuracy(top1)MeanF-scoreMRR MAPref MAP10 MAPsysCRF Engine +Word-Origin detection(no re-ranking)Standard run0.335 0.859 0.453 0.327 0.154 0.154Table 2: Results for English-Kannada transliteration.ReferencesB.
J. Kang and K. S. Choi 2000.
Automatic translitera-tion and back-transliteration by decision tree learn-ing.
Proceedings of the 2nd International Confer-ence on Language Resources and Evaluation, 1135-1411.Bonnie Glover Stalls and Kevin Knight 1998.
Trans-lating Names and Technical Terms in Arabic Text.Proceedings of COLING/ACL Workshop on Com-putational Approaches to Semitic Languages, 34-41.Haizhou Li, A Kumaran, Min Zhang, Vladimir Pervou-chine 2009.
Whitepaper of NEWS 2009 MachineTransliteration Shared Task.
Proceedings of ACL-IJCNLP 2009 Named Entities Workshop (NEWS2009).I.
Goto and N. Kato and N. Uratani and T. Ehara2003.
Transliteration considering context informa-tion based on the maximum entropy method.
Pro-ceedings of MT-Summit IX, 125132.J.
S. Lee and K. S. Choi.
1998.
English to Koreanstatistical transliteration for information retrieval.Computer Processing of Oriental Languages, 17-37.John Lafferty, Andrew McCallum, Fernando Pereira2001.
Conditional Random Fields: Probabilis-tic Models for Segmenting and Labeling SequenceData.
In Proceedings of the Eighteenth InternationalConference on Machine Learning.Jong-hoon Oh and Key-sun Choi 2002.
An English-Korean Transliteration Model Using Pronunciationand Contextual Rules.
Proceedings of the 19th Inter-national Conference on Computational Linguistics(COLING), 758-764.Kevin Knight and Jonathan Graehl 1997.
Machinetransliteration.
Computational Linguistics, 128-135.Kumaran, A. and Kellner, Tobias 2007.
A genericframework for machine transliteration.
SIGIR ?07:Proceedings of the 30th annual international ACMSIGIR conference on Research and development ininformation retrieval, 721-722.Och Franz Josef and Hermann Ney 2000.
ImprovedStatistical Alignment Models.
Proc.
of the 38th An-nual Meeting of the Association for ComputationalLinguistics, pp.
440-447P.
F. Brown, S. A. Della Pietra, and R. L. Mercer 1993.The mathematics of statistical machine translation:Parameter estimation.
Computational Linguistics,19(2):263-311.Sung Young Jung and SungLim Hong and Eunok Paek2000.
An English to Korean transliteration model ofextended Markov window.
Proceedings of the 18thconference on Computational linguistics, 383-389.Suryaganesh Veeravalli and Sreeharsha Yella andPrasad Pingali and Vasudeva Varma 2008.
Statisti-cal Transliteration for Cross Language InformationRetrieval using HMM alignment model and CRF.Proceedings of the 2nd workshop on Cross LingualInformation Access (CLIA) Addressing the Infor-mation Need of Multilingual Societies.Yaser Al-Onaizan and Kevin Knight 2001.
Translatingnamed entities using monolingual and bilingual re-sources.
ACL ?02: Proceedings of the 40th AnnualMeeting on Association for Computational Linguis-tics, 400-408.87
