Proceedings of the NAACL HLT 2010: Tutorial Abstracts, pages 3?4,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsMarkov Logic in Natural Language Processing: Theory, Algorithms, andApplicationsHoifung Poon, University of WashingtonNatural languages are characterized by rich relational structures andtight integration with world knowledge.
As the field of NLP/CL movestowards more complex and challenging tasks, there has been increasinginterest in applying joint inference to leverage such relations andprior knowledge.
Recent work in statistical relational learning(a.k.a.
structured prediction) has shown that joint inference can notonly substantially improve predictive accuracy, but also enableeffective learning with little or no labeled information.
Markov logicis the unifying framework for statistical relational learning, and hasspawned a series of successful NLP applications, ranging frominformation extraction to unsupervised semantic parsing.
In thistutorial, I will introduce Markov logic to the NLP community andsurvey existing NLP applications.
The target audience of the tutorialis all NLP researchers, students and practitioners.
The audience willgain the ability to efficiently develop state-of-the-art solutions toNLP problems using Markov logic and the Alchemy open-source software.1.
StructureThe tutorial will be structured as follows:Part One: Markov LogicIn the first part I will motivate statistical relational learning(SRL) for NLP problems, and introduce Markov logic as the unifyingframework.
I will present state-of-the-art learning and inferencealgorithms in Markov logic, and give an overview of the Alchemyopen-source software package.
The duration of this part will beapproximately one hour and half.Part Two: NLP Applications: Supervised LearningIn the second part I will describe how to use Markov logic andAlchemy to develop state-of-the-art solutions very efficiently for avariety of NLP problems, including: logistic regression, text andhypertext classification, vector-space and link-based informationretrieval, entity resolution, information integration, hidden Markovmodels, Bayesian networks, information extraction, semantic rolelabeling, and biomedical text mining.
This part will also coverpractical tips on using Markov logic and Alchemy ?
the kind ofinformation that is rarely found in research papers, but is key to3developing successful applications.
This part will focus on supervisedlearning and the duration will be approximately an hour.Part Three: NLP Applications: Unsupervised LearningIn the third and final part I will introduce the emerging directionfor statistical relation learning that leverages prior knowledge andrelational structures to enable effective learning with little or nolabeled data.
As examples I will present recent work in applyingMarkov logic to unsupervised coreference resolution and unsupervisedsemantic parsing.
I will also briefly touch on the exciting prospectof machine reading from the Web.
The duration will be about half anhour.2.
InstructorHoifung PoonDepartment of Computer Science and EngineeringUniversity of WashingtonSeattle, WA 98195, USAhoifung@cs.washington.eduHoifung Poon is a fifth-year Ph.D. student at the University ofWashington, working with Pedro Domingos.
His main research interestlies in advancing machine learning methods to handle both complexityand uncertainty, and in applying them to solving challenging NLPproblems with little or no labeled data.
His most recent workdeveloped unsupervised learning methods for a number of NLP problemsranging from morphological segmentation to semantic parsing, andreceived the Best Paper Awards in NAACL-09 and EMNLP-09.
AtWashington, he helped design course materials for the first offeringof the undergraduate machine learning course, and gave guest lecturesin both undergraduate and graduate machine learning classes.
His priorexperience includes teaching undergraduate math classes in WestVirginia University, for which he was awarded the Outstanding GraduateTeaching Assistant by the University.4
