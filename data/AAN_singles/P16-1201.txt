Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 2134?2143,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsLeveraging FrameNet to Improve Automatic Event DetectionShulin Liu, Yubo Chen, Shizhu He, Kang Liu and Jun ZhaoNational Laboratory of Pattern RecognitionInstitute of Automation, Chinese Academy of Sciences, Beijing, 100190, China{shulin.liu, yubo.chen, shizhu.he, kliu, jzhao}@nlpr.ia.ac.cnAbstractFrames defined in FrameNet (FN) sharehighly similar structures with events inACE event extraction program.
An even-t in ACE is composed of an event trig-ger and a set of arguments.
Analogously,a frame in FN is composed of a lexical u-nit and a set of frame elements, which playsimilar roles as triggers and arguments ofACE events respectively.
Besides havingsimilar structures, many frames in FN ac-tually express certain types of events.
Theabove observations motivate us to explorewhether there exists a good mapping fromframes to event-types and if it is possibleto improve event detection by using FN.In this paper, we propose a global infer-ence approach to detect events in FN.
Fur-ther, based on the detected results, we an-alyze possible mappings from frames toevent-types.
Finally, we improve the per-formance of event detection and achievea new state-of-the-art result by using theevents automatically detected from FN.1 IntroductionIn the ACE (Automatic Context Extraction) even-t extraction program, an event is represented as astructure consisting of an event trigger and a set ofarguments.
This paper tackles with the event de-tection (ED) task, which is a crucial component inthe overall task of event extraction.
The goal of EDis to identify event triggers and their correspond-ing event types from the given documents.FrameNet (FN) (Baker et al, 1998; Fillmoreet al, 2003) is a linguistic resource storing con-siderable information about lexical and predicate-argument semantics.
In FN, a frame is defined asa composition of a Lexical Unit (LU) and a setof Frame Elements (FE).
Most frames contain aset of exemplars with annotated LUs and FEs (seeFigure 2 and Section 2.2 for details).From the above definitions of events andframes, it is not hard to find that the frames definedin FN share highly similar structures as the eventsdefined in ACE.
Firstly, the LU of a Frame playsa similar role as the trigger of an event.
ACE de-fines the trigger of an event as the word or phrasewhich most clearly expresses an event occurrence.For example, the following sentence ?He died inthe hospital.?
expresses a Die event, whose trig-ger is the word died.
Analogously, the LU of aframe is also the word or phrase which is capa-ble of indicating the occurrence of the expressedsemantic frame.
For example, the sentence ?Aero-planes bombed London.?
expresses an Attack1frame, whose LU is the word bombed.
Secondly,the FEs of a frame also play similar roles as argu-ments of an event.
Both of them indicate the par-ticipants involved in the corresponding frame orevent.
For example, in the first sentence, He andhospital are the arguments, and in the second sen-tence, Aeroplanes and London are the FEs.Besides having similar structure as events,many frames in FN actually express certain type-s of events defined in ACE.
Table 1 shows someexamples of frames which also express events.Frame Event Sample in FNAttack Attack Aeroplanes bombed London.Invading Attack Hitler invaded Austria .Fining Fine The court fined her $40.Execution Execute He was executed yesterday.Table 1: Examples of frames expressing events.The aforementioned observations motivate us to1The notation of frames distinguishes from that of eventsby the italic decoration.2134explore: (1) whether there exists a good mappingfrom frames to event-types, and (2) whether it ispossible to improve ED by using FN.Figure 1: Our framework for detecting events inFN (including training and detecting processes).For the first issue, we investigate whether aframe could be mapped to an event-type based onevents expressed by exemplars annotated for thatframe.
Therefore the key is to detect events fromthe given exemplar sentences in FN.
To achievethis goal, we propose a global inference approach(see figure 1).
We firstly learn a basic ED modelbased on the ACE labeled corpus and employ it toyield initial judgements for each sentence in FN.Then, we apply a set of soft constraints for globalinference based on the following hypotheses: 1).Sentences belonging to the same LU tend to ex-press events of the same type; 2).
Sentences be-longing to related frames tend to express events ofthe same type; 3).
Sentences belonging to the sameframe tend to express events of the same type.
Allof the above constraints and initial judgments areformalized as first-order logic formulas and mod-eled by Probabilistic Soft Logic (PSL) (Kimmiget al, 2012; Bach et al, 2013).
Finally, we obtainthe final results via PSL-based global inference.We conduct both manual and automatic evalua-tions for the detected results.For the second issue, ED generally suffer-s from data sparseness due to lack of labeledsamples.
Some types, such as Nominate andExtradite, contain even less than 10 labeledsamples.
Apparently, from such a small scale oftraining data is difficult to yield a satisfying perfor-mance.
We notice that ACE corpus only containsabout 6,000 labeled instances, while FN containsmore than 150,000 exemplars.
Thus, a straightfor-ward solution to alleviate the data sparseness prob-lem is to expand the ACE training data by usingevents detected from FN.
The experimental result-s show that events from FN significantly improvethe performance of the event detection task.Figure 2: The hierarchy of FN corpus, where eachSkunder a LU is a exemplar annotated for thatLU.
Inheritance is a semantic relation between theframes Invading and Attack.To sum up, our main contributions are: (1) Toour knowledge, this is the first work perform-ing event detection over ACE and FN to explorethe relationships between frames and events.
(2)We propose a global inference approach to detectevents in FN, which is demonstrated very effectiveby our experiments.
Moreover, based on the de-tected results, we analyze possible mappings fromframes to event-types (all the detecting and map-ping results are released for further use by the NLPcommunity2).
(3) We improve the performance ofevent detection significantly and achieve a newstate-of-the-art result by using events automatical-ly detected from FN as extra training data.2 Background2.1 ACE Event ExtractionIn ACE evaluations, an event is defined as a specif-ic occurrence involving several participants.
ACEevent evaluation includes 8 types of events, with33 subtypes.
Following previous work, we treatthem simply as 33 separate event types and ignorethe hierarchical structure among them.
In this pa-per, we use the ACE 2005 corpus3in our experi-ments.
It contains 599 documents, which includeabout 6,000 labeled events.2.2 FrameNetThe FrameNet is a taxonomy of manually identi-fied semantic frames for English4.
Figure 2 shows2Available at https://github.com/subacl/acl163https://catalog.ldc.upenn.edu/LDC2006T064We use the latest released version, FrameNet 1.5 in thiswork (http://framenet.icsi.berkeley.edu).2135the hierarchy of FN corpus.
Listed in the FNwith each frame are a set of lemmas with part ofspeech (i.e ?invade.v?)
that can evoke the frame,which are called lexical units (LUs).
Accompany-ing most LUs in the FN is a set of exemplars anno-tated for them.
Moreover, there are a set of labeledrelations between frames, such as Inheritance.FN contains more than 1,000 various framesand 10,000 LUs with 150,000 annotated exem-plars.
Eight relations are defined between framesin FN, but in this paper we only use the followingthree of them because the others do not satisfy ourhypotheses (see section 4.2):Inheritance: A inherited from B indicates that Amust correspond to an equally or more specificfact about B.
It is a directional relation.See also: A and B connected by this relation indi-cates that they are similar frames.Perspective on: A and B connected by this relationmeans that they are different points-of-view aboutthe same fact (i.e.
Receiving vs.
Transfer).2.3 Related WorkEvent extraction is an increasingly hot and chal-lenging research topic in NLP.
Many approacheshave been proposed for this task.
Nearly all the ex-isting methods on ACE event task use supervisedparadigm.
We further divide them into feature-based methods and representation-based methods.In feature-based methods, a diverse set of s-trategies has been exploited to convert classifica-tion clues into feature vectors.
Ahn (2006) us-es the lexical features(e.g., full word), syntacticfeatures (e.g., dependency features) and external-knowledge features(WordNet (Miller, 1995)) toextract the event.
Inspired by the hypothesis ofOne Sense Per Discourse (Yarowsky, 1995), Jiand Grishman (2008) combined global evidencefrom related documents with local decisions forthe event extraction.
To capture more clues fromthe texts, Gupta and Ji (2009), Liao and Grishman(2010) and Hong et al (2011) proposed the cross-event and cross-entity inference for the ACE even-t task.
Li et al (2013) proposed a joint model tocapture the combinational features of triggers andarguments.
Liu et al (2016) proposed a global in-ference approach to employ both latent local andglobal information for event detection.In representation-based methods, candidateevent mentions are represented by embedding,which typically are fed into neural networks.
T-wo similarly related work has been proposed onevent detection (Chen et al, 2015; Nguyen and Gr-ishman, 2015).
Nguyen and Grishman (2015) em-ployed Convolutional Neural Networks (CNNs) toautomatically extract sentence-level features forevent detection.
Chen et al (2015) proposed dy-namic multi-pooling operation on CNNs to cap-ture better sentence-level features.FrameNet is a typical resource for frame-semantic parsing, which consists of the resolutionof predicate sense into a frame, and the analy-sis of the frame?s participants (Thompson et al,2003; Giuglea and Moschitti, 2006; Hermann etal., 2014; Das et al, 2014).
Other tasks which havebeen studied based on FN include question an-swering (Narayanan and Harabagiu, 2004; Shenand Lapata, 2007), textual entailment (Burchardtet al, 2009) and paraphrase recognition (Pad?o andLapata, 2005).
This is the first work to explore theapplication of FN to event detection.3 Basic Event Detection ModelAlike to existing work, we model event detection(ED) as a word classification task.
In the ED task,each word in the given sentence is treated as a can-didate trigger and the goal is to classify each ofthese candidates into one of 34 classes (33 eventtypes plus a NA class).
However, in this work, aswe assumed that the LU of a frame is analogical tothe trigger of an event, we only treat the LU anno-tated in the given sentence as a trigger candidate.Each sentence in FN only contains one candidatetrigger, thus ?the candidate?
denotes both the can-didate trigger of a sentence and the sentence itselffor FN in the remainder of this paper.
Another no-table difference is that we train the detection mod-el on one corpus (ACE) but apply it on another(FN).
That means our task is also a cross-domainproblem.
To tackle with it, our basic ED approachfollows representation-based paradigm, which hasbeen demonstrated effective in the cross-domainsituation (Nguyen and Grishman, 2015).3.1 ModelWe employ a simple three-layer (a input layer, ahidden layer and a soft-max output layer) ArtificialNeural Networks (ANNs) (Hagan et al, 1996) tomodel the ED task.
In our model, adjacent layersare fully connected.Word embeddings learned from large amount ofunlabeled data have been shown to be able to cap-ture the meaningful semantic regularities of words2136(Bengio et al, 2003; Erhan et al, 2010).
This pa-per uses unsupervised learned word embeddingsas the source of base features.
We use the Skip-gram model (Mikolov et al, 2013) to learn wordembeddings on the NYT corpus5.Given a sentence, we concatenate the embed-ding vector of the candidate trigger and the aver-age embedding vector of the words in the sentenceas the input to our model.
We train the model usinga simple optimization technique called stochasticgradient descent (SGD) over shuffled mini-batcheswith the Adadelta update rule (Zeiler, 2012).
Reg-ularization is implemented by a dropout (Kim,2014; Hinton et al, 2012).
The experiments showthat this simple model is surprisingly effective forevent detection.4 Event Detection in FrameNetTo detect events in FN, we first learned the basicED model based on ACE labeled corpus and thenemploy it to generate initial judgements (possibleevent types with confidence values) for each sen-tence in FN.
Then, we apply a set of constraintsfor global inference based on the PSL model.4.1 Probabilistic Soft LogicPSL is a framework for collective, probabilisticreasoning in relational domains (Kimmig et al,2012; Bach et al, 2013).
Similar to Markov Log-ic Networks (MLNs) (Richardson and Domingos,2006), it uses weighted first-order logic formulasto compactly encode complex undirected proba-bilistic graphical models.
However, PSL brings t-wo remarkable advantages compared with MLNs.First, PSL relaxes the boolean truth values ofMLNs to continuous, soft truth values.
This allowsfor easy integration of continuous values, such assimilarity scores.
Second, PSL restricts the syntaxof first order formulas to that of rules with con-junctive bodies.
Together with the soft truth valuesconstraint, the inference in PSL is a convex op-timization problem in continuous space and thuscan be solved using efficient inference approach-es.
For further details, see the references (Kimmiget al, 2012; Bach et al, 2013).4.2 Global ConstraintsOur global inference approach is based on thefollowing three hypotheses.5https://catalog.ldc.upenn.edu/LDC2008T19H1: Same Frame Same EventThis hypothesis indicates that sentences under thesame frame tend to express events of the sametype.
For example, all exemplars annotated for theframe Rape express events of type Attack, andall sentences under the frame Clothing expressNA (none) events.
With this hypothesis, sentencesannotated for the same frame help each other toinfer their event types during global inference.H2: Related Frame Same EventThis hypothesis is an extension of H1, whichrelaxes ?the same frame?
constraint to ?relatedframes?.
In this paper, frames are considered tobe related if and only if they are connected byone of the following three relations: Inheritance,See also and Perspective on (see section 2.2).For example, the frame Invading is inheritedfrom Attack, and they actually express the sametype of event, Attack.
With this hypothesis,sentences under related frames help each other toinfer their event types during global inference.The previous two hypotheses are basically truefor most frames but not perfect.
For example, forthe frame Dead or alive, only a few of thesentences under it express Die events while theremainder do not.
To amend the this flaw, we in-troduce the third hypothesis.H3: Same LU Same EventThis hypothesis indicates that sentences under thesame LU tend to express events of the same type(as a remind, LUs are under frames).
It is loos-er than the previous two hypotheses thus hold-s true in more situations.
For example, H3 holdstrue for the frame Dead or alive which vio-lates H1 and H2.
In FN, LUs annotated for thatframe are alive.a, dead.a, deceased.a, lifeless.a,living.n, undead.a and undead.n.
All exemplarsunder dead.a, deceased.a and lifeless.a expressDie events.
Therefore, this hypothesis amends theflaws of the former two hypotheses.On the other hand, the first two hypotheses al-so help H3 in some cases.
For example, most ofthe sentences belonging to the LU suit.n under theframe Clothing are misidentified as Sue eventsdue to the ambiguity of the word ?suit?.
However,in this situation, H1 can help to rectify it becausethe majority of LUs under Clothing are not am-biguous words.
Thus, under the first hypothesis,the misidentified results are expected to be correct-ed by the the results of other exemplars belongingto Clothing.21374.3 InferenceTo model the above hypotheses as logic formulasin PSL, we introduce a set of predicates (see Ta-ble 2), which are grouped into two categories: ob-served predicates and target predicates.
Observedpredicates are used to encode evidences, which arealways assumed to be known during the inference,while target predicates are unknown and thus needto be predicted.CandEvt(c, t) is introduced to represen-t conf(c, t), which is the confidence value gener-ated by the basic ED model for classifying the can-didate c as an event of the type t. SameFr(c1, c2)indicates whether the candidates c1and c2belongto the same frame.
It is initialized by the indicatorfunction Isf(c1, c2), which is defined as follows:Isf(c1, c2) ={1 c1, c2from the same frame0 otherwise(1)SameLU(c1, c2) is similar, but applies for candi-dates under the same LU.
The last three observedpredicates in Table 2 are used to encode the afore-mentioned semantic relations between frames.
Forexample, Inherit(c1, c2) indicates whether theframe of c1is inherited from that of c2, and itis initialized by the indicator function Iih(c1, c2),which is set to 1 if and only if the frame of c1isinherited from that of c2, otherwise 0.
Evt(c, t) isthe only target predicate, which indicates that thecandidate c triggers an event of type t.Type Predicate AssignmentObservedCandEvt(c, t) conf(c, t)SameFr(c1, c2) Isf(c1, c2)SameLU(c1, c2) Isl(c1, c2)Inherit(c1, c2) Iih(c1, c2)SeeAlso(c1, c2) Isa(c1, c2)Perspect(c1, c2) Ipe(c1, c2)Target Evt(c, t) ?Table 2: Predicates and their initial assignments.Putting all the predicates together, we design aset of formulas to apply the aforementioned hy-potheses in PSL (see Table 3).
Formula f1con-nects the target predicate with the initial judge-ments from the basic ED model.
Formulas f2andf3respectively encode H1 and H3.
Finally, the re-maining formulas are designed for various rela-tions between frames in H2.
We tune the formu-las?s weights via grid search (see Section 5.4).
Theinference results provide us with the most likelyFormulasf1CandEvt(c, t) ?
Evt(c, t)f2SameFr(c1, c2) ?
Evt(c1, t) ?
Evt(c2, t)f3SameLU(c1, c2) ?
Evt(c1, t) ?
Evt(c2, t)f4Inherit(c1, c2) ?
Evt(c1, t) ?
Evt(c2, t)f5SeeAlso(c1, c2) ?
Evt(c1, t) ?
Evt(c2, t)f6Perspect(c1, c2) ?
Evt(c1, t) ?
Evt(c2, t)Table 3: Formulas in the PSL modelinterpretation, that is, the soft-truth values of thepredicate Evt.
The final detected event type t ofcandidate c is decided by the the equation:t = argmaxt?Evt(c, t?)
(2)5 EvaluationsIn this section, we present the experiments andthe results achieved.
We first manually evaluateour novel PSL-based ED model on the FN corpus.Then, we also conduct automatic evaluations forthe events detected from FN based on ACE cor-pus.
Finally, we analyze possible mappings fromframes/LUs to event types.5.1 DataWe learned the basic ED model on ACE2005dataset.
In order to evaluate the learned model, wefollowed the evaluation of (Li et al, 2013): ran-domly selected 30 articles from different genresas the development set, and we subsequently con-ducted a test on a separate set of 40 ACE 2005newswire documents.
We used the remaining 529articles as the training data set.We apply our proposed PSL-based approachto detect events in FrameNet.
Via collecting al-l exemplars annotated in FN, we totally obtain154,484 sentences for detection.5.2 Setup and Performance of Basic ModelWe have presented the basic ED model in Section3.
Hyperparameters were tuned by grid search onthe development data set.
In our experiments, weset the size of the hidden layer to 300, the size ofword embedding to 200, the batch size to 100 andthe dropout rate to 0.5.Table 4 shows the experimental results, fromwhich we can see that the three-layer ANN modelis surprisingly effective for event detection, whicheven yields competitive results compared with N-guyen?s CNN and Chen?s DMCNN.
We believe thereason is that, compared with CNN and DMCNN,2138Methods Pre Rec F1Nguyen?s CNN (2015) 71.8 66.4 69.0Chen?s DMCNN (2015) 75.6 63.6 69.1Liu?s Approach (2016) 75.3 64.4 69.4ANN (ours) 79.5 60.7 68.8ANN-Random (ours) 81.0 49.5 61.5Table 4: Performance of the basic ED model.
AN-N uses pre-trained word embeddings while ANN-Random uses randomly initialized embeddings.ANN focuses on capturing lexical features whichhave been proved much more important than sen-tence features for the ED task by (Chen et al,2015).
Moreover, our basic model achieves muchhigher precision than state-of-the-art approaches(79.5% vs. 75.6%).We also investigate the performance of the basicED model without pre-trained word embeddings6(denoted by ANN-Random).
The result shows thatrandomly initialized word embeddings decreasethe F1score by 7.3 (61.5 vs. 68.8).
The mainreasons are: 1).
ACE corpus only contains 599articles, which are far insufficient to train goodembeddings.
2).
Words only existing in the testdataset alays retain random embeddings.5.3 BaselinesFor comparison, we designed four baseline sys-tems that utilize different hypotheses to detec-t events in FN.
(1) ANN is the first baseline, which directly usesa basic ED model learned on ACE training corpusto detect events in FN.
This system does not applyany hypotheses between frames and events.
(2) SameFrame (SF) is the second baseline sys-tem, which applies H1 over the results from AN-N. For each frame, we introduce a score function?
(f, t) to estimate the probability that the frame fcould be mapped to the event type t as follows:?
(f, t) =1||Sf||?c?SfI(c, t) (3)where Sfis the set of sentences under the framef ; I(c, t) is an indicator function which is true ifand only if ANN predicts the candidate c as anevent of type t. Then for each frame f satisfying?
(f, t) > ?, we mapped it to event type t, where?
is a hyperparameter.
Finally, all sentences undermapped frames are labeled as events.
Note that,6We thank the anonymous reviewer for this suggestion.unlike the PSL-based approach which applies con-straints as soft rules, this system utilizes H1 as ahard constraint.
(3) RelatedFrame (RF) is the third baseline sys-tem, which applies H2 over the results from AN-N. For each frame f , we merge it and its relatedframes into a super frame, f?.
Similar with SF,a score function ?
(f?, t), which shares the sameexpression to equation 3, is introduced.
For themerged frame satisfying ?
(f?, t) > ?, we mappedit to the event type t. Finally, all sentences underf?are labeled as events.
(4) SameLU (SL) is the last baseline, which ap-plies the hypothesis H3 over the results from ANN.Also, a score function ?
(l, t) is introduced:?
(l, t) =1||Sl||?c?SlI(c, t) (4)where Slis the set of sentences under the LU l. Foreach LU satisfying ?
(l, t) > ?, we mapped it tothe event type t. Finally, all sentences under l arelabeled as events.5.4 Manual EvaluationsIn this section, we manually evaluate the precisionof the baseline systems and our proposed PSL-based approach.
For fair comparison, we set ?, ?and ?
to 0.32, 0.29 and 0.42 respectively to en-sure they yield approximately the same amount ofevents as the first baseline system ANN.
We tunethe weights of formulas in PSL via grid searchby using ACE development dataset.
In details, wefirstly detect events in FN under different config-urations of formulas?
weights and add them toACE training dataset, respectively.
Consequent-ly, we obtain several different expanded trainingdatasets.
Then, we separately train a set of basicED models based on each of these training dataset-s and evaluate them over the development corpus.Finally, the best weights are selected accordingto their performances on the development dataset.The weights of f1:f5used in this work are 100,10, 100, 5, 5 and 1, respectively.Manual AnnotationsFirstly, we randomly select 200 samples from theresults of each system.
Each selected sample is asentence with a highlighted trigger and a predictedevent type.
Figure 3 illustrates three samples.
Thefirst line of each sample is a sentence labeled withthe trigger.
The next line is the predicted event2139type of that sentence.
Annotators are asked to as-sign one of two labels to each sample (annotatingin the third line):Y: the word highlighted in the given sentenceindeed triggers an event of the predicted type.N: the word highlighted in the given sentencedoes not trigger any event of the predicted type.We can see that, it is very easy to annotate a sam-ple for annotators, thus the annotated results areexpected to be of high quality.Figure 3: Examples of manual annotations.To make the annotation more credible, eachsample is independently annotated by three anno-tators7(including one of the authors and two ofour colleagues who are familiar with ACE eventtask) and the final decision is made by voting.ResultsTable 5 shows the results of manual evaluations.Through the comparison of ANN and SF, we cansee that the application of H1 caused a loss of 5.5point.
It happens mainly because the performanceof SF is very sensitive to the wrongly mappedframes.
That is, if a frame is mismapped, then allsentences under it would be mislabeled as events.Thus, even a single mismapped frame could sig-nificantly hurt the performance.
This result alsoproves that H1 is inappropriate to be used as a hardconstraint.
As H2 is only an extension of H1, RFperforms similarly with SF.
Moreover, SL obtainsa gain of 2.0% improvement compared with ANN,which demonstrates that the ?same LU?
hypoth-esis is very useful.
Finally, with all the hypothe-ses, the PSL-based approach achieves the best per-formance, which demonstrates that our hypothesesare useful and it is an effective way to jointly uti-lize them as soft constraints through PSL for eventdetection in FN.5.5 Automatic EvaluationsTo prepare for automatic evaluations, we respec-tively add the events detected from FN by eachof the aforementioned five systems to ACE train-ing corpus.
Consequently, we obtain five ex-7The inter-agreement rate is 86.1%Methods Precision (%)BaselinesANN 77.5SF 72.0RF 71.0SL 79.5PSL-based Approach 81.0Table 5: Results of manual evaluations.panded training datasets: ACE-ANN-FN, ACE-SF-FN, ACE-RF-FN, ACE-SL-FN and ACE-PSL-FN.Then, we separately train five basic ED models oneach of these corpus and evaluate them on the ACEtesting data set.
This experiment is an indirect e-valuation of the events detected from FN, which isbased on the intuition that events with higher ac-curacy are expected to bring more improvementsto the basic model.Training Corpus Pre Rec F1ACE-ANN-FN 77.2 63.5 69.7ACE-SF-FN 73.2 64.1 68.4ACE-RF-FN 72.6 63.9 68.0ACE-SL-FN 77.5 64.3 70.3ACE-PSL-FN 77.6 65.2 70.7Table 6: Automatic evaluations of events from FN.Table 6 presents the results where we measureprecision, recall and F1.
Compared with ACE-ANN-FN, events from SF and RF hurt the perfor-mance.
As analyzed in previous section, SF and R-F yield quite a few false events, which dramatical-ly hurt the accuracy.
Moreover, ACE-SL-FN ob-tains a score of 70.3% in F1measure, which out-performs ACE-ANN-FN.
This result illustrates theeffectiveness of our ?same LU?
hypothesis.
Final-ly and most importantly, consistent with the resultsof manual evaluations, ACE-PSL-FN performs thebest, which further proves the effectiveness of ourproposed approach for event detection in FN.5.6 Improving Event Detection Using FNEvent detection generally suffers from data sparse-ness due to lack of labeled samples.
In this section,we investigate the effects of alleviating the afore-mentioned problem by using the events detectedfrom FN as extra training data.
Our investigationis conducted by the comparison of two basic EDmodels, ANN and ANN-FN: the former is trainedon ACE training corpus and the latter is trained onthe new training corpus ACE-PSL-FN (introducedin the previous section), which contains 3,816 ex-tra events detected from FN.2140Methods Pre Rec F1Nguyen?s CNN(2015) 71.8 66.4 69.0Chen?s DMCNN(2015) 75.6 63.6 69.1Liu?s Approach(2016) 75.3 64.4 69.4ANN (Ours) 79.5 60.7 68.8ANN-FN (Ours) 77.6 65.2 70.7Table 7: Effects of expanding training data usingevents automatically detected from FN.Table 7 presents the experimental results.
Com-pared with ANN, ANN-FN achieves a significantimprovement of 1.9% in F1measure.
It happensmainly because that the high accurate extra train-ing data makes the model obtain a higher recall(from 60.7% to 65.2%) with less decrease of pre-cision (from 79.5% to 77.6%).
The result demon-strates the effectiveness of alleviating the data s-parseness problem of ED by using events detect-ed from FN.
Moreover, compared with state-of-the-art methods, ANN-FN outperforms all of themwith remarkable improvements (more than 1.3%).5.7 Analysis of Frame-Event MappingIn this section, we illustrate the details of map-pings from frames to event types.
The mappingpairs are obtained by computing the function ?
(see Section 5.3) for each (frame, event-type) pair(f , t) based on the events detected by the PSL-based approach.
Table 8 presents the top 10 map-pings.
We manually evaluate their quality by in-vestigating: (1) whether the definition of eachframe is compatible with its mapped event type;(2) whether exemplars annotated for each frameactually express events of its mapped event type.For the first issue, we manually comparethe definitions of each mapped pair.
Excep-t Relational nat features8, definitions ofall the mapped pairs are compatible.
For the sec-ond issue, we randomly sample 20 exemplars (ifpossible) from each frame and manually annotatethem.
Except the above frame and Invading,exemplars of the remaining frames all express theright events.
The only exemplar of Invadingfailing to express its mapped event is as follows:?The invasion of China by western culture has hada number of far-reaching effects on Confucianis-m.?
ACE requires an Attack event to be a phys-ical act, while the invasion of culture is unphysi-cal.
Thus, the above sentence does not express an8The full name is Relational natural relations in FN.Frame Event Ne/||Sf|| ?Hit target Attack 2/2 1.0Relationalnat featuresMeet 1/1 1.0Invading Attack 120/121 0.99Fining Fine 26/27 0.96Being born Be-Born 32/36 0.88Rape Attack 104/125 0.83Sentencing Sentence 57/70 0.81Attack Attack 99/129 0.77Quitting End-Position 102/137 0.74Notificationof chargesCharge-Indict 73/103 0.71Table 8: Top 10 mappings from frames to even-t types.
Neis the number of exemplars detectedas events; ||Sf|| and ?
hold the same meanings asmentioned in Section 5.3.Attack event.
To sum up, the quality of our map-pings is good, which demonstrates that the hypoth-esis H1 is basically true.5.8 Analysis of LU-Event MappingThis section illustrates the details of mappingsfrom LUs to event types.
The mapping pairs areobtained by computing the function ?
(see Section5.3).
Table 9 presents the top 10 mappings.
In FN,each LU belongs to a frame.
In table 9, we omit theframe of each LU because of space limitation9.LU Event Ne/||Sl|| ?gunfight.n Attack 14/14 1.0injure.v Injure 14/14 1.0divorce.n Divorce 11/11 1.0decapitation.n Die 5/5 1.0trial.n Trial-Hearing 25/25 1.0assault.v Attack 21/21 1.0fight.v Attack 12/12 1.0arrest.n Arrest-Jail 38/38 1.0divorce.v Divorce 35/35 1.0shoot.v Attack 2/2 1.0Table 9: Top 10 mappings from LUs to even-t types.
Neis the number of exemplars detectedas events; ||Sl|| and ?
hold the same meanings asmentioned in Section 5.3.To investigate the mapping quality, we manu-9Their frames separately are Hostile encounter,Cause harm, Forming relationships, Killing, Trial, Attack,Quarreling, Arrest, Forming relationships and Hit target.2141ally annotate the exemplars under these LUs.
Theresult shows that all exemplars are rightly mapped.These mappings are quite good.
We believe thereason is that an LU is hardly ambiguous due toits high specificity, which is not only specified bya lemma but also by a frame and a part of speechtag.
Table 9 only presents the top 10 mappings.
Infact, we obtain 54 mappings in total with ?
= 1.0.We released all the detected events and mappingresults for further use by the NLP community.6 Conclusions and Future WorkMotivated by the high similarity between framesand events, we conduct this work to study theirrelations.
The key of this research is to detec-t events in FN.
To solve this problem, we proposeda PSL-based global inference approach based onthree hypotheses between frames and events.
Forevaluation, we first conduct manual evaluations onevents detected from FN.
The results reveal thatour hypotheses are very useful and it is an effectiveway to jointly utilize them as soft rules through P-SL.
In addition, we also perform automatic evalu-ations.
The results further demonstrate the effec-tiveness of our proposed approach for detectingevents in FN.
Furthermore, based on the detectedresults, we analyze the mappings from frames/LUsto event types.
Finally, we alleviate the data s-parseness problem of ED by using events detectedfrom FN as extra training data.
Consequently, weobtain a remarkable improvement and achieve anew state-of-the-art result for the ED task.Event detection is only a component of the over-all task of event extraction, which also includesevent role detection.
In the future, we will ex-tend this work to the complete event extractiontask.
Furthermore, event schemas in ACE are quitecoarse.
For example, all kinds of violent acts, suchas street fights and wars, are treated as a singleevent type Attack.
We plan to refine the eventschemas by the finer-grained frames defined in FN(i.e.
Attack may be divided into Terrorism,Invading, etc.
).AcknowledgementsThis work was supported by the Natural Sci-ence Foundation of China (No.
61533018), theNational Basic Research Program of China (No.2014CB340503) and the National Natural ScienceFoundation of China (No.
61272332).
And thiswork was also supported by Google through fo-cused research awards program.ReferencesDavid Ahn.
2006.
The stages of event extraction.In Proceedings of the Workshop on Annotating andReasoning about Time and Events, pages 1?8.Stephen Bach, Bert Huang, Ben London, and LiseGetoor.
2013.
Hinge-loss markov random fields:convex inference for structured prediction.
In Pro-ceedings of 29th Annual Meeting of the Associationfor Uncertainty in Artificial Inteligence, pages 1?10.Collin F Baker, Charles J Fillmore, and John B Lowe.1998.
The berkeley framenet project.
In Proceed-ings of 17th Annual Meeting of the Association forComputational Linguistics, pages 86?90.Yoshua Bengio, R?ejean Ducharme, Pascal Vincent, andChristian Janvin.
2003.
A neural probabilistic lan-guage model.
The Journal of Machine Learning Re-search, 3:1137?1155.Aljoscha Burchardt, Marco Pennacchiotti, StefanThater, and Manfred Pinkal.
2009.
Assessing theimpact of frame semantics on textual entailment.Natural Language Engineering, 15(04):527?550.Yubo Chen, Liheng Xu, Kang Liu, Daojian Zeng, andJun Zhao.
2015.
Event extraction via dynam-ic multi-pooling convolutional neural networks.
InProceedings of 53rd Annual Meeting of the Associa-tion for Computational Linguistics, pages 167?176.Dipanjan Das, Desai Chen, Andr?e FT Martins, NathanSchneider, and Noah A Smith.
2014.
Frame-semantic parsing.
Computational Linguistics,40(1):9?56.Dumitru Erhan, Yoshua Bengio, Aaron Courville,Pierre-Antoine Manzagol, Pascal Vincent, and SamyBengio.
2010.
Why does unsupervised pre-traininghelp deep learning?
The Journal of Machine Learn-ing Research, 11:625?660.Charles J Fillmore, Christopher R Johnson, and Miri-am RL Petruck.
2003.
Background to framenet.International Journal of Lexicography, 16(3):235?250.Ana-Maria Giuglea and Alessandro Moschitti.
2006.Shallow semantic parsing based on framenet, verb-net and propbank.
European Conference on Artifi-cial Intelligence, 141:563?567.Prashant Gupta and Heng Ji.
2009.
Predicting un-known time arguments based on cross-event prop-agation.
In Proceedings of the Joint Conference ofthe 47th Annual Meeting of the ACL and the 4th In-ternational Joint Conference on Natural LanguageProcessing of the AFNLP, pages 369?372.2142Martin T Hagan, Howard B Demuth, Mark H Beale,et al 1996.
Neural network design.
Pws Pub.Boston.Karl Moritz Hermann, Dipanjan Das, Jason Weston,and Kuzman Ganchev.
2014.
Semantic frame iden-tification with distributed word representations.
InProceedings of 52nd Annual Meeting of the Asso-ciation for Computational Linguistics, pages 1448?1458.Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky,Ilya Sutskever, and Ruslan R Salakhutdinov.
2012.Improving neural networks by preventing co-adaptation of feature detectors.
arXiv preprint arX-iv:1207.0580.Yu Hong, Jianfeng Zhang, Bin Ma, Jianmin Yao,Guodong Zhou, and Qiaoming Zhu.
2011.
Usingcross-entity inference to improve event extraction.In Proceedings of 49th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 1127?1136.Heng Ji and Ralph Grishman.
2008.
Refining even-t extraction through cross-document inference.
InProceedings of 46th Annual Meeting of the Associa-tion for Computational Linguistics, pages 254?262.Yoon Kim.
2014.
Convolutional neural networks forsentence classification.
In Proceedings of the 2014Conference on Empirical Methods in Natural Lan-guage Processing, pages 1746?1751.Angelika Kimmig, Stephen Bach, Matthias Broecheler,Bert Huang, and Lise Getoor.
2012.
A short intro-duction to probabilistic soft logic.
In Proceedings ofthe NIPS Workshop on Probabilistic Programming:Foundations and Applications, pages 1?4.Qi Li, Heng Ji, and Liang Huang.
2013.
Joint eventextraction via structured prediction with global fea-tures.
In Proceedings of 51st Annual Meeting of theAssociation for Computational Linguistics, pages73?82.Shasha Liao and Ralph Grishman.
2010.
Using doc-ument level cross-event inference to improve even-t extraction.
In Proceedings of 48th Annual Meet-ing of the Association for Computational Linguistic-s, pages 789?797.Shulin Liu, Kang Liu, Shizhu He, and Jun Zhao.
2016.A probabilistic soft logic based approach to exploit-ing latent and global information in event classifica-tion.
In Proceedings of the thirtieth AAAI Confer-ence on Artificail Intelligence.Tomas Mikolov, Kai Chen, Greg Corrado, and JeffreyDean.
2013.
Efficient estimation of word rep-resentations in vector space.
arXiv preprint arX-iv:1301.3781.George A. Miller.
1995.
Wordnet: a lexicaldatabase for english.
Communications of the Acm,38(11):39?41.Srini Narayanan and Sanda Harabagiu.
2004.
Ques-tion answering based on semantic structures.
Inter-national Conference on Computational Linguistics.Thien Huu Nguyen and Ralph Grishman.
2015.
Eventdetection and domain adaptation with convolution-al neural networks.
In Proceedings of 53rd AnnualMeeting of the Association for Computational Lin-guistics, pages 365?371.Sebastian Pad?o and Mirella Lapata.
2005.
Cross-linguistic projection of role-semantic information.In Proceedings of the conference on human lan-guage technology and empirical methods in natu-ral language processing, pages 859?866.
Associa-tion for Computational Linguistics.Matthew Richardson and Pedro Domingos.
2006.Markov logic networks.
Machine learning, pages107?136.Dan Shen and Mirella Lapata.
2007.
Using seman-tic roles to improve question answering.
In Pro-ceedings of the 2007 Joint Conference on Empiri-cal Methods in Natural Language Processing andComputational Natural Language Learning, pages12?21.Cynthia A Thompson, Roger Levy, and Christopher DManning.
2003.
A generative model for seman-tic role labeling.
European Conference on MachineLearning, pages 397?408.David Yarowsky.
1995.
Unsupervised word sense dis-ambiguation rivaling supervised methods.
In Pro-ceedings of 14th Annual Meeting of the Associationfor Computational Linguistics, pages 189?196.Matthew D Zeiler.
2012.
Adadelta: An adaptive learn-ing rate method.
arXiv preprint arXiv:1212.5701.2143
