Modelling GroundingCo l in  MathesonUniversity of EdinburghEdinburgh,  Scotlandcolin, mat  heson @ed.
ac.
ukand Discourse Obligations Using UpdateRulesMass imo Poes ioUniversity of EdinburghEdinburgh, Scotlandmassimo.poesio@ed.ac.ukDav id  T raumUniversity of Mary landMaryland,  USAt raum@cs.umd.eduAbst rac tThis paper describes an implementation f some keyaspects of a theory of dialogue processing whosemain concerns are to provide models of GROUND-ING and of the role of DISCOURSE OBLIGATIONS inan agent's deliberation processes.
Our system usesthe TrindiKit dialogue move engine toolkit, whichassumes a model of dialogue in which a participan.t's knowledge is characterised in terms of INFORMA-TION STATES which are subject o various kinds ofupdating mechanisms.1 I n t roduct ionIn this paper we describe a preliminary implemen-tation of a 'middle-level' dialogue management sys-tem.
The key tasks of a dialogue manager are toupdate the representation f dialogue on the basis ofprocessed input (generally, but not exclusively, lan-guage utterances), and to decide what (if anything)the system should do next.
There is a wide range ofopinions concerning how these tasks should be per-formed, and in particular, how the ongoing dialoguestate should be represented: e.g., as something veryspecific to a particular domain, or according to somemore general theory of (human or human inspired)dialogue processing.
At one extreme, some systemsrepresent only the (typically very rigid) transitionspossible in a perceived ialogue for the given task,often using finite states in a transition etwork torepresent the dialogue: examples of this are sys-tems built using Nuance's DialogueBuilder or theCSLU's Rapid Application Prototyper.
The otherextreme is to build the dialogue processing theory ontop of a full model of rational agency (e.g., (Bretierand Sadek, 1996)).
The approach we take here liesin between these two extremes: we use rich repre-sentations of information states, but simpler, moredialogue-specific deliberation methods, rather thana deductive reasoner working on the basis of an ax-iomatic theory of rational agency.
We show in thispaper that the theory of information states we pro-pose can, nevertheless, beused to give a character-isation of dialogue acts such as those proposed bythe Discourse Resource Initiative precise nough toformalise the deliberation process of a dialogue man-ager in a completely declarative fashion.Our implementation is based on the approach todialogue developed in (Traum, 1994; Poesio andTraum, 1997; Poesio and Traum, 1998; Traum et al,1999).
This theory, like other action-based theoriesof dialogue, views dialogue participation i terms ofagents performing dialogue acts, the effects of whichare to update the information state of the partici-pants in a dialogue.
However, our view of dialogueact effects is closer in some respects to that of (All-wood, 1976; Allwood, 1994) and (Singh, 1998) thanto the belief and intention model of (Sadek, 1991;Grosz and Sidner, 1990; Cohen and Levesque, 1990).Particular emphasis i placed on the social commit-ments of the dialogue participants (obligations toact and commitments to propositions) without mak-ing explicit claims about the actual beliefs and in-tentions of the participants.
Also, heavy empha-sis is placed on how dialogue participants sociallyGROUND (Clark and Wilkes-Gibbs, 1986) the infor-mation expressed in dialogue: the information stateassumed in this theory specifies which information isassumed to be already part of the common ground ata given point, and which part has been introduced,but not yet been established.The rest of this paper is structured as follows.
Thetheory of dialogue underlying the implementation isdescribed in more detail in Section 2.
Section 3 de-scribes the implementation itself.
Section 4 showshow the system updates its information state whileparticipating in a fairly simple dialogue.2 Theoret i ca l  BackgroundOne basic assumption underlying this work is thatit is useful to analyse dialogues by describing therelevant 'information' that is available to each par-ticipant.
The notion of INFORMATION STATE (IS) istherefore mployed in deciding what the next actionshould be, and the effects of utterances are describedin terms of the changes they bring about in ISs.
Aparticular instantiation ofa dialogue manager, fromthis point of view, consists of a definition of the con-tents of ISs plus a description of the update processeswhich map from IS to IS.
Updates are typically trig-gered by 'full' dialogue acts such as assertions ordirectives, 1 of course, but the theory allows parts ofutterances, including individual words and even sub-parts of words, to be the trigger.
The update rulesfor dialogue acts that we assume here are a simpli-fied version of the formalisations proposed in (Poesioand Traum, 1998; Traum et al, 1999) (henceforth,PTT).The main aspects of PTT which have been im-plemented concern the way discourse obligations arehandled and the manner in which dialogue partic-ipants interact o add information to the commonground.
Obligations are essentially social in nature,and directly characterise poken dialogue; a typicalexample of a discourse obligation concerns the rela-tionship between questions and answers.
Poesio andTraum follow (Traum and Allen, 1994) in suggestingthat the utterance of a question imposes an obliga-tion on the hearer to address the question (e.g., byproviding an answer), irrespective of intentions.As for the process by which common ground is es-tablished, or GROUNDING (Clark and Schaefer, 1989;Traum, 1994), the assumption i PTT is that classi-cal speech act theory is inherently too simplistic inthat it ignores the fact that co-operative interactionis essential in discourse; thus, for instance, simply as-serting something does not make it become mutually'known' (part of the common ground).
It is actuallynecessary for the hearer to provide some kind of ac-knowledgement that the assertion has been received,understood or not understood, accepted or rejected,and so on.
Poesio and Traum view the public in-formation state as including both material that hasalready been grounded, indicated by GND here, andmaterial that hasn't been grounded yet.
These com-ponents of the information state are updated whenGROUNDING ACTS such as acknowledgement areper-formed.
Each new contribution results in a new DIS-COURSE UNIT (DU) being added to the informationstate (Traum, 1994) and recorded in a list of 'un-grounded iscourse units' (UDUS); these DUs canthen be subsequently grounded as the result, e.g., of(implicit or explicit) acknowledgements.3 Imp lement ing  PTTIn this section, we describe the details of the im-plementation.
First, in Section 3.1, we describe theTrindiKit tool for building dialogue managers thatwe used to build our system.
In Section 3.2, we de-scribe the information states used in the implemen-tation, an extension and simplification of the ideasfrom PTT discussed in the previous ection.
Then,in Section 3.3, we discuss how the information stateis updated when dialogue acts are observed.
Finally,1We assume here the DRI classification f dialogue acts(Discourse Resource Initiative, 1997)./ . '
? "
.. -,. '
" .
.
,I.lol'lP.lllit~ ~;l{lle (i$)'E 1Figure 1: TrindiKit Architecturein Section 3.4, we describe the rules used by the sys-tem to adopt intentions and perform its own actions.An extended example of how these mechanisms areused to track and participate in a dialogue is pre-sented in Section 4.3.1 TrindiKitThe basis for our implementation is the TrindiKitdialogue move engine toolkit implemented as partof the TRINDI project (Larsson et al, 1999).
Thetoolkit provides upport for developing dialogue sys-tems, focusing on the central dialogue managementcomponents.The system architecture assumed by the TrindiKitis shown in Figure 1.
A prominent feature of this ar-chitecture is the information state, which serves as acentral 'blackboard' that processing modules can ex-amine (by means of defined CONDITIONS) or change(by means of defined OPERATIONS).
The structureof the IS for a particular dialogue system is defined'by the developer who uses the TrindiKit to buildthat system, on the basis of his/her own theory ofdialogue processing; no predefined notion of infor-mation state is provided.
2 The toolkit provides anumber of abstract data-types such as lists, stacks,and records, along with associated conditions andoperations, that can be used to implement the user'stheory of information states; other abstract ypescan also be defined.
In addition to this customis-able notion of information state, TrindiKit providesa few system variables that can also used for inter-module communication.
These include input for theraw observed (language) input, latest_moves which2In TRINDI we are experimenting with multiple instanti-ations of three different theories of information state (Traumet al, 1999).2contains the dialogue moves observed in the mostrecent urn, la tes t_speaker ,  and next_moves, con-taining the dialogue moves to be performed by thesystem in the next turn.A complete system is assumed to consist of sev-eral modules interacting via the IS.
(See Figure 1again.)
The central component is called the DIA-LOGUE MOVE ENGINE (DME).
The DME performsthe processing needed to integrate the observed i-alogue moves with the IS, and to select new movesfor the system to perform.
These two functions areencapsulated in the UPDATE and SELECTION sub-modules of the DME.
The update and select mod-ules are specified by means of typed rules, as well assequencing procedures to determine when to applythe rules.
We are here mainly concerned with UP-DATE RULES (urules) ,  which consist of four parts: aname, a type, a list of conditions to check in the in-formation state, and a list of operations to performon the information state, u ru les  are described inmore detail below, in Section 3.3.
There are alsotwo modules outside the DME proper, but still cru-cial to a complete system: INTERPRETATION, whichconsumes the input and produces a list of dialogueacts in the latest_moves variable (potentially mak-ing reference to the current information state), andGENERATION, which produces NL output from thedialogue acts in the next_moves variable.
Finally,there is a CONTROL module, that governs the se-quencing (or parallel invocation) of the other mod-ules.
In this paper we focus on the IS and the DME;our current implementation only uses very simpleinterpretation and generation components.3.2 Information States in PTTIn this section we discuss the information state usedin the current implementation.
The main differencebetween the implemented IS and the theoretical pro-posal in (Poesio and Traum, 1998) is that in the im-plementation the information state is partitioned infields, each containing information of different ypes,whereas in the theoretical version the informationstate is a single repository of facts (a DISCOURSEREPRESENTATION STRUCTURE).
Other differencesare discussed below.
An example IS with some fieldsfilled is shown in Figure 2; this is the IS which resultsfrom the second utterance in the example dialoguediscussed in Section 4, A route please.
3The IS in Figure 2 is a record with two mainparts, W and C. The first of these represents thesystem's (Wizard) view of his own mental state andof the (semi-)public information discussed in the di-alogue; the second, his view of the user's (Caller)information state.
This second part is needed to3All diagrams in this paper are automatically generatedfrom TrindiKit system internal representations and displayedusing the Thistle dialogue editor (Calder, 1998).
Some havebeen subsequently edited for brevity and clarity.r \] understandingAct( W,DU3 )\ 1 ~1\[OBL: ~lddre~(C,CA2 ) \] / //~.
.
/ .
.
/CAS:C2 ,~..,~g.
(C.DU2) \ /  I I. .
.
.
.
/ .... \c^:: ' / /  I I/ sc : < " !
H\[COND: < > J HUDUS: <DU3> H\[ \[OBL: <,ddri~z(C.CA2 ) > \ ] \ ]  HDH: <CA2: C2.
into requi~t( W.?help fore1 ):>/ / LCOND: < > J/ If: | LID: DU2 J I I/ \[ lilt / / / /CA5: C2.
dil c,(C ivemule(W)  \ / /H/ / /DH: (CAS: C2.
a,swer( C.CA2.CA4 ) ) //11ko,, //11I / IIII / \[ LCOND: <IICIpt(W.CA6)-> obl(W~iveroutc(W))>J III/ LID: DU3 JII1 /,,,,o_,..,,,.,( w.:,,.-, )\ I I/ ; l i~oute(W )t ~,,*~,~,d~(W.bU3)/ JIlINT: <letrome(C)>\] JFigure 2: Structure of Information Statesmodel misunderstandings arising from the dialogueparticipants having differing views on what has beengrounded; as we are not concerned with this problemhere, we will ignore C in what follows.w contains information on the grounded mate-rial (GND), on the ungrounded information (UDUS,PDU and CDU), and on W's intentions (INT).
GNDcontains the information that has already beengrounded; the other fields contain information aboutthe contributions still to be grounded.
As noticedabove, in PTT  it is assumed that for each new ut-terance, a new DU is created and added to the IS.The current implementation differs from the full the-ory in that only two DUs are retained at each point;the current DU (CDU) and the previous DU (PDU).The CDU contains the information in the latest con-tribution, while the PDU contains information fromthe penultimate contribution.
Information is movedf rom PDU to GND as a result of an ack (acknowl-edgement) dialogue act (see below.
)The DUs and the GND field contain four fields,representing obligations (OBL), the dialogue history(DH), propositions to which agents are socially com-mitted (scP),  and conditional updates (COND).
Thevalue of OBL is a list of action types: actions thatagents are obliged to perform.
An action type isspecified by a PREDICATE, a DIALOGUE PARTICI-PANT, and a list of ARGUMENTS.
The value of seeis a list of a particular type of mental states, so-cial commitments of agents to propositions.
4 Theseare specified by a DIALOGUE PARTICIPANT, and aPROPOSITION.
Finally, the elements in DH are dia-4SCPs play much the same role in PTT as do beliefs inmany BDI accounts of speech acts.3logue actions, which are instances of dialogue actiontypes.
A dialogue action is specified by an actiontype, a dialogue act id, and a confidence level CONF(the confidence that an agent has that that dialogueact has been observed).The situation in Figure 2 is the result of updates tothe IS caused by utterance \[2\] in the dialogue in (6),which is assumed to generate a d i rect  act as well asan assert  act and an answer  act.
5 That utteranceis also assumed to contain an implicit acknowledge-ment of the original question; this understanding acthas resulted in the contents of DU2 being grounded(and subsequently merged with GND), as discussedbelow.GND.OBL in Figure 2 includes two obligations.The first is an obligation on W to perform an under-standing act (the predicate is unders tand ingAct ,the participant is W, and there is just one argument,DU3, which identifies the DU in CDU by referring toits ID).
The second obligation is an obligation on Cto address  conversational ct CA2; this ID pointsto the appropriate info_request  in the DH list bymeans of the ID number.
Obligations are specifiedin CDU and PDU, as well.
Those in PDU are simplya subset of those in GND, since at point in the up-date process shown in Figure 2 this field containsinformation that has already been grounded (notethat DU2 is not in UDUS anymore); but CDU con-tains obligations that have not been grounded yet -in particular, the obligation on W to address  CA6.GND.DH in this IS contains a list of dialogue ac-tions whose occurrence has already been grounded:the info_request  performed by utterance 1, with ar-gument a question, 6 and the implicit acknowledgeperformed by utterance 2.
7 The DH field in CDU con-tains dialogue acts performed by utterance 2 that doneed to be grounded: a directive by C to W to per-form an action of type g iveroute,  and an assertby C of the proposition want(C,  route), by which Cprovides an answer  to the previous info_requestCA2.The COND field in CDU contains a conditional up-date resulting from the directive performed by thatutterance.
The idea is that directives do not imme-diately lead to obligations to perform the mentionedaction: instead (in addition to an obligation to ad-dress the action with some sort of response), their ef-fect is to add to the common ground the informationthat if the directive is accepted  by the addressee,SThe fact that the utterance of a route please constitutesan answer is explicitly assumed; however, it should be possibleto derive this information automatically (perhaps along thelines suggested by Kreutel (Kreutel, 1998)).6We use the notation ?p to indicate a question of the form?
(\[x\],p(x)).7We assume here, as in (Traum, 1994) and (Poesio andTraum, 1998), that understanding acts do not have to begrounded themselves, which would result in a infinite regress.then he or she has the obligation to perform the ac-tion type requested.
(In this case, to give a route toC.
)3.3 Update  Rules  in PTTWe are now in a position to examine the updatemechanisms which are performed when new dia-logue acts are recognised.
When a dialogue par-ticipant takes a turn and produces an utterance,the interpretation module sets the system variablelatest_moves to contain a representation f the di-alogue acts performed with the utterance.
The up-dating procedure then uses update rules to modifythe IS on the basis of the contents of latest_movesand of the previous IS.
The basic procedure is de-scribed in (1) below, s(1) 1.
Create a new DU and push it on top ofUDUs.2.
Perform updates on the basis of backwardsgrounding acts..
If any other type of act is observed, recordit in the dialogue history in CDU and applythe update rules for this kind of act4.
Apply update rules to all parts of the ISwhich contain newly added acts.The first step involves moving the contents of CDUto PDU (losing direct access to the former PDU con-tents) and putting in CDU a new empty DU witha new identifier.
The second and third steps dealexplicitly with the contents of la test .moves,  ap-plying one urule (of possibly a larger set) for eachact in latest_moves.
The relevant effects for eachact are summarised in (2), where the variables havethe following types:IDxDUxDPqPROPActo(DP)P(ID)Q(ID)Dialogue Act Identification NumberDU Identification NumberDialogue Participant (i.e., the speaker)A QuestionA PropositionAn ActionThe other dialogue participantThe content of the ID, a propositionThe content of the ID, a questionSSee (Poesio et al, 1999; Traum et al, 1999) for differentversions of this update procedure used for slightly differentversions of the theory.4(2) act ID:2, accept (DP, ID2)effect accomplished via rule resolutionact ID:2, ack(DP, DU1)effect peRec(w.Gnd,w.pdu.tognd)effect remove(DU1,UDUS)act ID:2, agree(DP, ID2)effect push(scP,scp(DP,P(ID2)))act ID:2, answer(DP,ID2,ID3)effect push(scP,ans(DP, Q(ID2),P(ID2)))act ID:2, assert (DP,PROP)effect push(scP,sep(DP, PROP))effect push (COND,accept (o(DP),ID)-+scp(o(DP),PROP))act ID:I, assert(DP,PROP)effect push (COND,accept (o(DP),ID)-~scp(o(DP),PROP))act ID:2, check(DP,PROP)effect push(OSL,address(o(DP),ID))effect push(COND,agree(o(DP),ID) --~scp(DP, PROP))act ID:2, direct (DP, Act)effect push(OBL,address(o(DP),ID))effect push(CONI),accept (o(DP),ID) -~obl(o(DP),Act))act ID:2, info_request (DP, Q)effect push(osL,address(o(DP),ID))The ack act is the only backward grounding actimplemented at the moment.
The main effect of anack is to merge the information i the acknowledgedDU (assumed to be PDU) into GND, also removingthis DU from UDUS.
Unlike the other acts describedbelow, ack acts are recorded irectly into GND.DH,rather than into CDU.TOGND.DH.All of the other updates are performed in the thirdstep of the procedure in (1).
The only effect of ac-cept acts is to enable the conditional rules whichare part of the effect of assert and direct, leadingto social commitments and obligations, respectively.agree acts also trigger conditional rules introducedby check; in addition, they result in the agent be-ing socially committed to the proposition i troducedby the act with which the agent agrees.
Perform-ing an answer to question ID2 by asserting propo-sition P(ID3) commits the dialogue participant tothe proposition that P(ID3) is indeed an answer toQ(ID2).The two rules for assert are where the confidencelevels are actually used, to implement a simple ver-ification strategy.
The idea is that the system onlyassumes that the user is committed to the assertedproposition when a confidence l vel of 2 is observed,while some asserts are assumed not to have beensufficiently well understood, and are only assigned aconfidence l vel 1.
This leads the system to performa check, as we will see shortly.The next three update rules, for check, direct,and info_req, all impose an obligation on the otherdialogue participant to address the dialogue act.
Inaddition, the direct rule introduces a conditionalact: acceptance of the directive will impose an obli-gation on the hearer to act on its contents.In addition, all FORWARD ACTS 9 in the DRIscheme (Discourse Resource Initiative, 1997) imposean obligation to perform an understanding act (e.g.,an acknowledgement):(3) 1 acteffectID:c, forward-looking-act (DP)push(OBL,u-act (o(DP),CDU.id)) IThe internal urules implementing the updates in(2) have the format shown in (4), which is the urulefor info_request.
(4) =uxe( doZnfoR, q. rulet~.S,\[ hearer(DP),latest_moves: in(Hove},Move:valEec(pred,inforeq) \],\[ incr_set(update_cycles,_),incr_set (next.dh_id, HID),next _du_name (ID),pushRec (w'cdu'tognd'dh,record ( \[atype=Move, c level=2, id=HID \ ] ) ) ,pushRec (e'cdu~tosnd'obl,record ( \[pred~address, dp=DP,argsfstackset (\[record ( \[i%em=IIID\] )\] ) \] ) ),pushRec (w'gnd" obl,record ( \[pred=uact, dp=P,args=stackset (\[rocord(\[item=ID\] ) \] ) \] )) \ ] ) .As noted above, these rules have four parts; aname, a type, a list of conditions, and a list of ef-fects.
The conditions in (4) state that there must bea move in latest_moves whose predicate is inforeq.The effects l?
state that the move should be recordedin the dialogue history in CDU, that an obligation toaddress the request should be pushed into OBL inCDU, and that the requirement for an understand-ing act by W should be pushed irectly into the listin W.GND.The fourth and final step of the algorithm cyclesthrough the updating process in case recently addedfacts have further implications.
For instance, whenan action has been performed that matches the an-tecedent of a rule in COND, the consequent is es-tablished.
Likewise, when an action is performedit releases any obligations to perform that action.Thus, accept, answer, and agree are all ways ofreleasing an obligation to address, since these areall appropriate backward looking actions.
Similarly,an agent will drop intentions to perform actions ithas already (successfully) performed.3.4 DeliberationWe assume, in common with BDI-approaches toagency (e.g., (Bratman et al, 1988)) that intentions9Forward acts include assert, check, direct, andinfo_request.l?The ID and HID values simply contain numbers identifyingthe discourse units and conversational acts.5are the primary mental attitude leading to an agen-t's actions.
The main issues to explain then becomehow such intentions are adopted given the rest ofthe information state, and how an agent gets fromintentions to actual performance.For the latter question, we take a fairly simplisticapproach here: all the intentions to perform dia-logue acts are simply transferred to the next_movessystem variable, with the assumption that the gen-eration module can realise all of them as a single ut-terance.
A more sophisticated approach would be toweight the importance of (immediate) realisation ofsets of intentions and compare this to the likelihoodthat particular utterances will achieve these effectsat minimal cost, and choose accordingly.
We leavethis for future work (see (Traum and Dillenbourg,1998) for some preliminary ideas along these lines),concentrating here on the first issue - how the sys-tem adopts intentions to perform dialogue acts fromother aspects of the mental state.The current system takes the following factors intoaccount:?
obligations (to perform understanding acts, toaddress previous dialogue acts, to perform otheractions)?
potential obligations (that would result if an-other act were performed, as represented in theCOND field)?
insufficiently understood ialogue acts (with a1 confidence level in CDU.DH)?
intentions to perform complex actsThe current deliberation process assumes maxi-mal cooperativity, in that the system always choosesto meet its obligations whenever possible, and alsochooses to provide a maximally helpful responsewhen possible.
Thus, when obliged to address  aprevious dialogue act such as a question or direc-tive, it will choose to actually return the answer orperform the action, if possible, rather than reject ornegotiate such a performance, which would also beacting in accordance with the obligations (see (Kreu-tel, 1998) on how acts might be rejected).In the current implementation, the following rulesare used to adopt new intentions (i.e., to update theINT field):(5) 1. add an intention to acknowl-edge(W,CDU), given an obligation toperform a u-act,  if everything in CDU issufficiently understood (i.e., to level 2);2. add an intention to accept a directive or an-swer a question as the result of an obligationto address a dialogue act;3. add an intention to perform an action ifCOND contains a conditional that will estab-lish an obligation to perform the action, andthe antecedent of this conditional is anotheraction that is already intended.
(This an-ticipatory planning allows the obligation tobe discharged at the same time it is invoked,e.g., without giving an intermediate accep-tance of an directive.)4.
add an intention to perform a (dialogue) ac-tion motivated by the intention to performthe current task.
In the case of the Au-toroute domain, we have two cases: the sys-tem may decide(a) to check any dialogue acts in CDU atconfidence level 1, which contain infor-mation needed to discharge the intentionto give a route; or(b) to perform a question asking about a newpiece of information that has not been es-tablished (this is decided by inspectingGND.SCP and CDU.SCP).
For example,it may decide to ask about the startingpoint, the time of departure, etc.4 Extended ExampleIn this section, we discuss more examples of how theinformation state changes as a result of processingand performing dialogue acts.
It is useful to do thisby looking briefly at a typical Autoroute dialogue,shown in (6).
11 Our implementation can process thissort of dialogue using very simple interpretation andgeneration routines that provide the dialogue actsin latest_moves from the text strings, and produceW's output text from the dialogue acts which thesystem places in next_moves.
(6) W \[1\]: How can I help?C \[2\]: A route pleaseW \[3\]: Where would you like to start?C \[4\]: MalvernW \[5\]: Great Malvern?C \[6\]: YesW \[7\]: Where do you want to go?C \[8\]: EdwinstoweW \[9\]: Edwinstowe in Nottingham?C \[10\]: YesW \[11\]: When do you want to leave?C \[12\]: Six pmW \[13\]: Leaving at 6 p.m.?C \[14\]: YesW \[15\]: Do you want the quickest or theshortest route?C \[16\]: QuickestW \[17\]: Please wait while your route is cal-culated.We assume that before the dialogue starts, W hasthe intention to ask C what kind of help is required,liThe interchanges have been cleaned up to some extenthere, mainly by removing pauses and hesitations.6W:I \[ /gi .
.
.
.
.
,e(W, \ I OBL: ~understandlngAet(W,DU5)) / \address(C,CA8 ) \[ \[ / CA I0: C2, acknowledge(C.DU4 ) \ iGND: /DH: (CAg: C2, accept( W.CA6 ) ~/ / SCP: < ?\[COND: < >UDUS: <DU5>\[ /CA9:C2 .
.
.
.
pt(W,CA6) \ / /TOGND: OH: \CAS: C2.
info request( W,?start ) I l l  PDU: / /LCOND: < >LID: DU4DH: ~/CA 12: C2, a~wer( C,CA8,CAI 1 )CDU: TOGND: \CA 11: Cl, assert( C.s 'tart(malvem) )SCP: < >LCOND: < >LID: DU5/ check (W.,start(malvern ) ) \INT: ~acknowledge( W.DU5 )\giveroute( W ) /I INT: <getroute( C ) ?
lFigure 3: Information State Prompting Check in \[5\]and that C has the intention to find a route.
We alsoassume that W has the turn, and that the presenceof the how can I help intention triggers an utterancedirectly.
Figure 2, presented above, shows the in-formation state after utterance \[2\].
The intentionsin that figure lead directly to the system producingutterance \[3\].Looking a little further ahead in the dialogue, Fig-ure 3 shows the information state after utterance\[4\].
12 Here we can see in CDU.TOGND.DH (along withthe ack act CA10, in GND.DH) the dialogue movesthat this utterance has generated.
Note that the as-sert, CA l l ,  is only at confidence level 1, indicatinglack of sufficient certainty in this interpretation asthe town 'Great Malvern'.
This lack of certainty andthe resulting lack of a relevant SCP in CDU.TOGNDlead the deliberation routines to produce an inten-tion to check this proposition rather than to movedirectly on to another information request.
Thisintention leads to utterance \[5\], which, after inter-pretation and updating on the new dialogue acts,leads to the information state in Figure 4.
The in-teresting thing here is the condition which appearsin CDU.TOGND.COND as a result of the check; theinterpretation of this is that, if C agrees with thecheck, then W will be committed to the propositionthat the starting place is Malvern (C would also becommitted to this by way of the direct effects of anagree act).12The actual information state contains all the previouslyestablished ialogue acts, SCPs and Obligations in GND~ fromFigure 2 and intermediate utterances.
Here we have deletedthese aspects from the figures for brevity and clarity.OBL: \glveroute(W ) / \[/CAI3: C2.
acknowledge( W.DU5 ) \ \ [GND: /DH: ~ CA 12: C2, answer(C.CA8 ) }/  / \CA 11 :C 1, assert(C.start(malvem) ) / \ [SCP: < ?LCOND: < > JUDUS: <DU6>IOBL: < ?W: TOGND: DFt: \CA i i: Ci, as~rt(C,s~t(malvem) ) i i iPDU: SCP: < >LID: DU5r r?BL: <address(C.CAl4)>\]TOGND: \[DH: <CA 14: C2, check (W.,smrt(rnalvern)) >CDU: / /SOP: < >LCOND: <agree(C,CAl4 \] .> scp(W,start(malvern) };L In: DU6INT: ,:giveroute(W )>C: lINT: <getroute(C)>lFigure 4: Information State Following Check in \[5\]I r /..<,.,..,.,,..,~.
?,,,,,=.,:>,.,8>\ 1 11 / ?BL: \gi .
.
.
.
.
l ,(w) / / / //,--,,-, /c , , .
:c2  .,~,.>,,~=<W.DU~>\/ / /GND: \[----: \CA 16: C2.
igi~e( C,CA 14 ) / /  / /Is<:,> ,/,,<,,< c~,.,,,.,<,.,,=,,.<,,.. > > ~, / / /  i : \scp(W,slirl( malvcrn D/  / / /l.CO~D: < > J Nuous: <oul> / /I loB, .
.
.
.
11 l/ W: TOGND" DH: <CA 16: C2.
agree(C,CA 14 ) >iPDU: \[ " \[SCP: < sop( C,start( malvern ) } > H | // / LCOND: < > J/ l /\] LID: DO7 J / // \[ \[OBL: <Iddress(C.CAI8 )> 11ll/ /TOGND" / DH: <CAIS: C2.
info_nequesi(W.?dest )>///// c~U: / / sc~: < > / IN/ / L~oNo: < > ill // uo: ,~  .illC: lINT: <getroute(C)>l JFigure 5: Information state following \[7\]After C's agreement in \[6\], the deliberation rou-tine is able to move past discussion of the start-ing point, and add an intention to ask about thenext piece of information, the destination.
Thisleads to producing utterance \[7\], which also implic-itly acknowledges \[6\], after which C's agreement isgrounded, leading to the IS shown in Figure 5.
Notethat the list in W.GND.SCP in Figure 5 indicates thatboth C and W are committed to the proposition thatthe starting place is Malvern.5 Conc lus ionsIt has only been possible here to introduce the basicconcerns of the PTT account of dialogue modellingand to pick out one or two illustrative examples tohighlight the implementational approach which has7been assumed.
Current and future work is directedtowards measuring the theory against more challeng-ing data to test its validity; cases where ground-ing is less automatic are an obvious source of suchtests, and we have identified a few relevant problemcases in the Autoroute dialogues.
We do claim, how-ever, that the implementation as it stands validatesa number of key aspects of the theory and providesa good basis for future work in dialogue modelling.AcknowledgmentsThe TRINDI (Task Oriented Instructional Dia-logue) project is supported by the Telematics Appli-cations Programme, Language Engineering ProjectLE4-8314.
Massimo Poesio is supported by an EP-SRC Advanced Research Fellowship.Re ferencesJ.
Allwood.
1976.
Linguistic Communication asAction and Cooperation.
Ph.D. thesis, GSteborgUniversity, Department of Linguistics.J.
Allwood.
1994.
Obligations and options in dia-logue.
Think Quarterly, 3:9-18.M.
E. Bratman, D. J. Israel and M. E. Pollack.
1988.Plans and Resource-Bounded Practical Reason-ing.
Computational Intelligence, 4(4).P.
Bretier and M. D. Sadek.
1996.
A rational agentas the kernel of a cooperative spoken dialoguesystem: Implementing a logical theory of inter-action.
In J. P. Miiller, M. J. Wooldridge, andN.
R. Jennings, editors, Intelligent Agents III --Proceedings of the Third International Workshopon Agent Theories, Architectures, and Languages(ATAL-96), Lecture Notes in Artificial Intelli-gence.
Springer-Verlag, Heidelberg.J.
Calder.
1998.
Thistle: diagram display en-gines and editors.
Technical Report HCRC/TR-97, HCRC, University of Edinburgh, Edinburgh.H.
H. Clark and E. F. Schaefer.
1989.
Contributingto discourse.
Cognitive Science, 13:259-294.H.
H. Clark and D. Wilkes-Gibbs.
1986.
Referringas a collaborative process.
Cognition, 22:1-39.Also appears as Chapter 4 in (Clark, 1992).H.
H. Clark.
1992.
Arenas of Language Use.
Uni-versity of Chicago Press.P.
R. Cohen and H. J. Levesque.
1990.
Rational in-teraction as the basis for communication.
I  P. R.Cohen, J. Morgan, and M. E. Pollack, editors, In-tentions in Communication.
MIT Press.Discourse Resource Initiative.
1997.
Standards fordialogue coding in natural anguage processing.Report no.
167, Dagstuhl-Seminar.B.
J. Grosz and C. L. Sidner.
1990.
Plans for dis-course.
In P. R. Cohen, J. Morgan, and M. E. Pol-lack, editors, Intentions in Communication.
MITPress.J.
Kreutel.
1998.
An obligation-driven computa-tional model for questions and assertions in dia-logue.
Master's thesis, Department ofLinguistics,University of Edinburgh, Edinburgh.S.
Larsson, P. Bohlin, J. Bos, and D. Traum.
1999.Trindikit manual.
Technical Report DeliverableD2.2 - Manual, Trindi.M.
Poesio, R. Cooper, S. Larsson, D. Traum, andC.
Matheson.
1999.
Annotating conversations forinformation state update.
In Proceedings of Am-stelogue 99, 3rd Workshop on the Semantics andPragmatics of Dialogues.M.
Poesio and D. R. Tranm.
1997.
Conversationalactions and discourse situations.
ComputationalIntelligence, 13(3).M.
Poesio and D. R. Traum.
1998.
Towards an ax-iomatization of dialogue acts.
In Proceedings ofTwendial'98, 13th Twente Workshop on LanguageTechnology, pages 207-222.M.
D. Sadek.
1991.
Dialogue acts are rational plans.In Proceedings o\] the ESCA/ETR workshop onmulti-modal dialogue.M.
P. Singh.
1998.
Agent communication lan-guages: Rethinking the principles.
IEEE Com-puter, 31(12):40-47.D.
R. Traum and J. F. Allen.
1992.
A speech actsapproach to grounding in conversation.
In Pro-ceedings 2nd International Conference on SpokenLanguage Processing (ICSLP-92), pages 137-40,October.D.
R. Traum and J. F. Allen.
1994.
Discourse obli-gations in dialogue processing.
In Proceedings ofthe 32nd Annual meeting of the Association forComputational Linguistics, pages 1-8, June.D.
R. Traum, J. Bos, R. Cooper, S. Larsson, I.Lewin, C. Matheson, and M. Poesio.
1999.
Amodel of dialogue moves and information state re-vision.
Technical Report Deliverable D2.1, Trindi.D.
R. Traum and P. Dillenbourg.
1998.
Towards aNormative Model of Grounding in Collaboration.In Proceedings of the ESSLLI98 workshop on Mu-tual Knowledge, Common Ground and Public In-formation.D.
R. Traum.
1994.
A computational theoryof grounding in natural language conversation.Ph.D.
thesis, Computer Science, University ofRochester, New York, December.8
