Constraints on strong generative powerDavid ChiangUniversity of PennsylvaniaDept of Computer and Information Science200 S 33rd StPhiladelphia, PA 19104 USAdchiang@cis.upenn.eduAbstractWe consider the question ?Howmuch strong generative power canbe squeezed out of a formal systemwithout increasing its weak generativepower??
and propose some theoret-ical and practical constraints on thisproblem.
We then introduce a formal-ism which, under these constraints,maximally squeezes strong generativepower out of context-free grammar.Finally, we generalize this result toformalisms beyond CFG.1 Introduction?How much strong generative power can besqueezed out of a formal system without increas-ing its weak generative power??
This question,posed by Joshi (2000), is important for both lin-guistic description and natural language process-ing.
The extension of tree adjoining grammar(TAG) to tree-local multicomponent TAG (Joshi,1987), or the extension of context free gram-mar (CFG) to tree insertion grammar (Schabesand Waters, 1993) or regular form TAG (Rogers,1994) can be seen as steps toward answering thisquestion.
But this question is difficult to answerwith much finality unless we pin its terms downmore precisely.First, what is meant by strong generativepower?
In the standard definition (Chomsky,1965) a grammar G weakly generates a set ofsentences L(G) and strongly generates a set ofstructural descriptions ?
(G); the strong genera-tive capacity of a formalism F is then f?
(G) jF provides Gg.
There is some vagueness in theliterature, however, over what structural descrip-tions are and how they can reasonably be com-pared across theories (Miller (1999) gives a goodsynopsis).
(a) XXX aXX b(b) XNAa Xb X abFigure 1: Example of weakly context-free TAG.The approach that Vijay-Shanker et al (1987)and Weir (1988) take, elaborated on by Beckeret al (1992), is to identify a very general classof formalisms, which they call linear context-free rewriting systems (CFRSs), and define forthis class a large space of structural descriptionswhich serves as a common ground in which thestrong generative capacities of these formalismscan be compared.
Similarly, if we want to talkabout squeezing strong generative power out ofa formal system, we need to do so in the contextof some larger space of structural descriptions.Second, why is preservation of weak generativepower important?
If we interpret this constraint tothe letter, it is almost vacuous.
For example, theclass of all tree adjoining grammars which gen-erate context-free languages includes the gram-mar shown in Figure 1a (which generates the lan-guage fa, bg).
We can also add the tree shown inFigure 1b without increasing the grammar?s weakgenerative capacity; indeed, we can add any treeswe please, provided they yield only as and bs.
In-tuitively, the constraint of weak context-freenesshas little force.This intuition is verified if we consider thatweak context-freeness is desirable for computa-tional efficiency.
Though a weakly context-freeTAG might be recognizable in cubic time (if weknow the equivalent CFG), it need not be parsablein cubic time?that is, given a string, to computeall its possible structural descriptions will takeO(n6) time in general.
If we are interested in com-puting structural descriptions from strings, thenDerivations StructuraldescriptionsSentencesFigure 2: Simulation: structural descriptions asderived structures.we need a tighter constraint than preservation ofweak generative power.In Section 3 below we examine some restric-tions on tree adjoining grammar which are weaklycontext-free, and observe that their parsers allwork in the same way: though given a TAG G,they implicitly parse using a CFG G0 which de-rives the same strings as G, but also their corre-sponding structural descriptions under G, in sucha way that preserves the dynamic-programmingstructure of the parsing algorithm.Based on this observation, we replace the con-straint of preservation of weak generative powerwith a constraint of simulability: essentially, agrammar G0 simulates another grammar G if itgenerates the same strings that G does, as well astheir corresponding structural descriptions underG (see Figure 2).So then, within the class of context-free rewrit-ing systems, how does this constraint of simu-lability limit strong generative power?
In Sec-tion 4.1 we define a formalism called multicom-ponent multifoot TAG (MMTAG) which, whenrestricted to a regular form, characterizes pre-cisely those CFRSs which are simulable by aCFG.
Thus, in the sense we have set forth, thisformalism can be said to squeeze as much stronggenerative power out of CFG as is possible.
Fi-nally, we generalize this result to formalisms be-yond CFG.2 Characterizing structural descriptionsFirst we define context-free rewriting systems.What these formalisms have in common is thattheir derivation sets are all local sets (that is, gen-erable by a CFG).
These derivations are taken asstructural descriptions.
The following definitionsare adapted from Weir (1988).Definition 1 A generalized context-free gram-mar G is a tuple hV, S , F, Pi, where1.
V is a finite set of variables,2.
S 2 V is a distinguished start symbol,3.
F is a finite set of function symbols, andXYXNAa X dYNAb Y cS !
?
(X, Y) ?
(hx1, x2i, hy1, y2i) = x1y1y2x2X !
?1(X) ?1(hx1, x2i) = hax1, x2diX !
() () = h, iY !
?2(Y) ?2(hy1, y2i) = hby1, y2ciY !
() () = h, iFigure 3: Example of TAG with correspondingGCFG and interpretation.
Here adjunction at footnodes is allowed.4.
P is a finite set of productions of the formA!
f (A1, .
.
.
, An)where n  0, f 2 F, and A, Ai 2 V .A generalized CFG G generates a set T (G) ofterms, which are interpreted as derivations undersome formalism.
In this paper we require that Gbe free of spurious ambiguity, that is, that eachterm be uniquely generated.Definition 2 We say that a formalism F is acontext-free rewriting system (CFRS) if its deriva-tion sets can be characterized by generalizedCFGs, and its derived structures are produced bya function ~F from terms to strings such that foreach function symbol f , there is a yield functionfF such that~ f (t1, .
.
.
, tn)F = fF (~t1F , .
.
.
, ~tnF )(A linear CFRS is subject to further restrictions,which we do not make use of.
)As an example, Figure 3 shows a simple TAGwith a corresponding GCFG and interpretation.A nice property of CFRS is that any formal-ism which can be defined as a CFRS immedi-ately lends itself to several extensions, which arisewhen we give additional interpretations to thefunction symbols.
For example, we can interpretthe functions as ranging over probabilities, cre-ating a stochastic grammar; or we can interpretthem as yield functions of another grammar, cre-ating a synchronous grammar.Now we define strong generative capacity asthe relationship between strings and structural de-scriptions.11This is similar in spirit, but not the same as, the notionof derivational generative capacity (Becker et al, 1992).Definition 3 The strong generative capacity of agrammar G a CFRS F is the relationfh~tF , ti j t 2 T (G)g.For example, the strong generative capacity of thegrammar of Figure 3 isfhambncndm, ?
(?m1 (()), ?n2(()))igwhereas any equivalent CFG must have a stronggenerative capacity of the formfhambncndm, f m(gn(e()))igThat is, in a CFG the n bs and cs must appear laterin the derivation than the m as and ds, whereas inour example they appear in parallel.3 Simulating structural descriptionsWe now take a closer look at some examples of?squeezed?
context-free formalisms to illustratehow a CFG can be used to simulate formalismswith greater strong generative power than CFG.3.1 MotivationTree substitution grammar (TSG), tree insertiongrammar (TIG), and regular-form TAG (RF-TAG)are all weakly context free formalisms which canadditionally be parsed in cubic time (with a caveatfor RF-TAG below).
For each of these formalismsa CKY-style parser can be written whose items areof the form [X, i, j] and are combined in variousways, but always according to the schema[X, i, j] [Y, j, k][Z, i, k]just as in the CKY parser for CFG.
In effect theparser dynamically converts the TSG, TIG, or RF-TAG into an equivalent CFG?each parser rule ofthe above form corresponds to the rule schemaZ !
XY .More importantly, given a grammar G and astring w, a parser can reconstruct all possiblederivations of w under G by storing inside eachchart item how that item was inferred.
If we thinkof the parser as dynamically converting G into aCFG G0, then this CFG is likewise able to com-positionally reconstruct TSG, TIG, or RF-TAGderivations?we say that G0 simulates G.Note that the parser specifies how to convert Ginto G0, but G0 is not itself a parser.
Thus thesethree formalisms have a special relationship toCFG that is independent of any particular pars-ing algorithm: for any TSG, TIG, or RF-TAG G,there is a CFG that simulates G. We make this no-tion more precise below.3.2 Excursus: regular form TAGStrictly speaking, the recognition algorithmRogers gives cannot be extended to parsing; thatis, it generates all possible derived trees for agiven string, but not all possible derivations.
Itis correct, however, as a parser for a further re-stricted subclass of TAGs:Definition 4 We say that a TAG is in strict reg-ular form if there exists some partial ordering over the nonterminal alphabet such that for ev-ery auxiliary tree ?, if the root and foot of ?
arelabeled X, then for every node ?
along ?
?s spinewhere adjunction is allowed, X  label(?
), andX = label(?)
only if ?
is a foot node.
(In this vari-ant adjunction at foot nodes is permitted.
)Thus the only kinds of adjunction which can oc-cur to unbounded depth are off-spine adjunctionand adjunction at foot nodes.This stricter definition still has greater stronggenerative capacity than CFG.
For example, theTAG in Figure 3 is in strict regular form, becausethe only nodes along spines where adjunction isallowed are foot nodes.3.3 SimulabilitySo far we have not placed any restrictions onhow these structural descriptions are computed.Even though we might imagine attaching arbi-trary functions to the rules of a parser, an algo-rithm like CKY is only really capable of com-puting values of bounded size, or else structure-sharing in the chart will be lost, increasing thecomplexity of the algorithm possibly to exponen-tial complexity.For a parser to compute arbitrary-sized objects,such as the derivations themselves, it must useback-pointers, references to the values of sub-computations but not the values themselves.
Theonly functions on a back-pointer the parser cancompute online are the identity function (by copy-ing the back-pointer) and constant functions (byreplacing the back-pointer); any other functionwould have to dereference the back-pointer anddestroy the structure of the algorithm.
Thereforesuch functions must be computed offline.Definition 5 A simulating interpretation ~ is abijection between two recognizable sets of termssuch that1.
For each function symbol ?, there is a func-tion ??
such that~?
(t1, .
.
.
, tn) = ??
(~t1, .
.
.
, ~tn)2.
Each ??
is definable as:??
(hx11, .
.
.
, x1m1)i), .
.
.
, hxn1, .
.
.
, xmnmi) =hw1, .
.
.
,wmiwhere each wi can take one of the followingforms:(a) a variable xi j, or(b) a function application f (xi1 j1 , .
.
.
xin jn),n  03.
Furthermore, we require that for any recog-nizable set T , ~T is also a recognizable set.We say that ~ is trivial if every ??
is definable as??
(x1, .
.
.
xn) = f (xpi(1), .
.
.
xpi(n))where pi is a permutation of f1, .
.
.
, ng.2The rationale for requirement (3) is that itshould not be possible, simply by imposing localconstraints on the simulating grammar, to producea simulated grammar which does not even comefrom a CFRS.3Definition 6 We say that a grammar G from aCFRS F is (trivially) simulable by a grammar G?from another CFRS F if there is a (trivial) simu-lating interpretation ~s : T (G0) !
T (G) whichsatisfies ~tF 0 = ~~tsF for all t 2 T (G0).As an example, a CFG which simulates theTAG of Figure 3 is shown in Figure 4.
Note thatif we give additional interpretations to the simu-lated yield functions ?, ?1, and ?2, this CFG cancompute any probabilities, translations, etc., thatthe original TAG can.Note that if G0 trivially simulates G, they arevery nearly strongly equivalent, except that theyield functions of G0 might take their argumentsin a different order thanG, and there might be sev-eral yield functions of G0 which correspond to asingle yield function ofG used in several differentcontexts.
In fact, for technical reasons we will usethis notion instead of strong equivalence for test-ing the strong generative power of a formal sys-tem.Thus the original problem, which was, givena formalism F , to find a formalism that has asmuch strong generative power as possible but re-mains weakly equivalent to F , is now recast as2Simulating interpretations and trivial simulating inter-pretations are similar to the generalized and ?ungeneralized?syntax-directed translations, respectively, of Aho and Ull-man (1969; 1971).3Without this requirement, there are certain pathologicalcases that cause the construction of Section 4.2 to produceinfinite MM-TAGs.S !
?0 ?
(x1, x2)   hx1, x2i?0 !
?0 h(), x2i    h?, x2i?0 !
?1 h?, x2i    h?, x2i?1 !
?1 h?, ()i    h?,?i?1 !
 h?,?i    h?,?i?0 !
?01[?0] h?1(x1), x2i    hx1, x2i?01[?0]!
a ?21[?0] d hx1, x2i    hx1, x2i?21[?0]!
?01[?0] h?1(x1), x2i    hx1, x2i?21[?0]!
?0 h(), x2i    h?, x2i?1 !
?02[?1] h?, ?2(x2)i    h?, x2i?02[?1]!
b ?22[?1] c h?, x2i    h?, x2i?22[?1]!
?12[?1] h?, ?2(x2)i    h?, x2i?22[?1]!
?1 h?, ()i    h?,?iFigure 4: CFG which simulates the grammarof Figure 3.
Here we leave the yield functionsanonymous; y    x denotes the function whichmaps x to y.the following problem: find a formalism that triv-ially simulates as many grammars as possible butremains simulable by F .3.4 ResultsThe following is easy to show:Proposition 1 Simulability is reflexive and tran-sitive.Because of transitivity, it is impossible that a for-malism which is simulable by F could simulatea grammar that is not simulable by F .
So we arelooking for a formalism that can trivially simulateexactly those grammars that F can.In Section 4.1 we define a formalism calledmulticomponent multifoot TAG (MMTAG), andthen in Section 4.2 we prove the following result:Proposition 2 A grammar G from a CFRS issimulable by a CFG if and only if it is triviallysimulable by an MMTAG in regular form.The ?if?
direction (() implies (because simu-lability is reflexive) that RF-MMTAG is simula-ble by a CFG, and therefore cubic-time parsable.
(The proof below does give an effective proce-dure for constructing a simulating CFG for anyRF-MMTAG.)
The ?only if?
direction ()) showsthat, in the sense we have defined, RF-MMTAGis the most powerful such formalism.We can generalize this result using the notionof a meta-level grammar (Dras, 1999).Definition 7 If F1 and F2 are two CFRSs, F2 F1 is the CFRS characterized by the interpretationfunction ~F2F1 = ~F2  ~F1 .F1 is the meta-level formalism, which generatesderivations for F2.
Obviously F1 must be a tree-rewriting system.Proposition 3 For any CFRS F 0, a grammar Gfrom a (possibly different) CFRS is simulable bya grammar in F 0 if and only if it is trivially simu-lable by a grammar in F 0  RF-MMTAG.The ?only if?
direction ()) follows from thefact that the MMTAG constructed in the proof ofProposition 2 generates the same derived trees asthe CFG.
The ?if?
direction (() is a little trickierbecause the constructed CFG inserts and relabelsnodes.4 Multicomponent multifoot TAG4.1 DefinitionsMMTAG resembles a cross between set-localmulticomponent TAG (Joshi, 1987) and rankednode rewriting grammar (Abe, 1988), a variant ofTAG in which auxiliary trees may have multiplefoot nodes.
It also has much in common with d-tree substitution grammar (Rambow et al, 1995).Definition 8 An elementary tree set ~?
is a finiteset of trees (called the components of ~?)
with thefollowing properties:1.
Zero or more frontier nodes are designatedfoot nodes, which lack labels (followingAbe), but are marked with the diacritic ;2.
Zero or more (non-foot) nodes are desig-nated adjunction nodes, which are parti-tioned into one or more disjoint sets calledadjunction sites.
We notate this by assigningan index i to each adjunction site and mark-ing each node of site i with the diacritic i .3.
Each component is associated with a sym-bol called its type.
This is analogous to theleft-hand side of a CFG rule (again, follow-ing Abe).4.
The components of ~?
are connected by d-edges from foot nodes to root nodes (notatedby dotted lines) to form a single tree struc-ture.
A single foot node may have multipled-children, and their order is significant.
(SeeFigure 5 for an example.
)A multicomponent multifoot tree adjoining gram-mar is a tuple h?, P, S i, where:A X 1Y 2 X 1X 1A X 1Y 3 X 1X 1{A AY 3 X 1Y 2 X 1X 1Figure 5: Example of MMTAG adjunction.
Thetypes of the components, not shown in the figure,are all X.1.
?
is a finite alphabet;2.
P is a finite set of tree sets; and3.
S 2 ?
is a distinguished start symbol.Definition 9 A component ?
is adjoinable at anode ?
if ?
is an adjunction node and the type of?
equals the label of ?.The result of adjoining a component ?
at a node?
is the tree set formed by separating ?
from itschildren, replacing ?
with the root of ?, and re-placing the ith foot node of ?
with the ith childof ?.
(Thus adjunction of a one-foot componentis analogous to TAG adjunction, and adjunctionof a zero-foot component is analogous to substi-tution.
)A tree set ~?
is adjoinable at an adjunction site~?
if there is a way to adjoin each component of ~?at a different node of ~?
(with no nodes left over)such that the dominance and precedence relationswithin ~?
are preserved.
(See Figure 5 for an ex-ample.
)We now define a regular form for MMTAG thatis analogous to strict regular form for TAG.
Aspine is the path from the root to a foot of a sin-gle component.
Whenever adjunction takes place,several spines are inserted inside or concatenatedwith other spines.
To ensure that unbounded in-sertion does not take place, we impose an order-ing on spines, by means of functions ?i that mapthe type of a component to the rank of that com-ponent?s ith spine.Definition 10 We say that an adjunction node ?
2~?
is safe in a spine if it is the lowest node (exceptthe foot) in that spine, and if each component un-der that spine consists only of a member of ~?
andzero or more foot nodes.We say that an MMTAGG is in regular form ifthere are functions ?i from ?
into the domain ofsome partial ordering  such that for each com-ponent ?
of type X, for each adjunction node?
2 ?, if the jth child of ?
dominates the ith footnode of ?
(that is, another component?s jth spinewould adjoin into the ith spine), then ?i(X) ?
j(label(?
)), and ?i(X) = ?
j(label(?))
only if ?is safe in the ith spine.Thus the only kinds of adjunction which can oc-cur to unbounded depth are off-spine adjunctionand safe adjunction.
The adjunction shown in Fig-ure 5 is an example of safe adjunction.4.2 Proof of Proposition 2(() First we describe how to construct a simu-lating CFG for any RF-MMTAG; then this direc-tion of the proof follows from the transitivity ofsimulability.When a CFG simulates a regular form TAG,each nonterminal must encapsulate a stack (ofbounded depth) to keep track of adjunctions.
Inthe multicomponent case, these stacks must begeneralized to trees (again, of bounded size).So the nonterminals ofG0 are of the form [?, t],where t is a derivation fragment of G with a dot() at exactly one node ~?, and ?
is a node of ~?.
Let??
be the node in the derived tree where ?
ends up.A fragment t can be put into a normal form asfollows:1.
For every ~?
above the dot, if ??
does not liealong a spine of ~?, delete everything above~?.2.
For every ~?
not above or at the dot, if ??
doesnot lie along a d-edge of ~?, delete ~?
andeverything below and replace it with > if ?
?dominates ~?
; otherwise replace it with ?.3.
If there are two nodes ~?1 and ~?2 along apath which name the same tree set and ??
liesalong the same spine or same d-edge in bothof them, collapse ~?1 and ~?2, deleting every-thing in between.Basically this process removes all unboundedlylong paths, so that the set of normal forms is finite.In the rule schemata below, the terms in the left-hand sides range over normalized terms, and theircorresponding right-hand sides are renormalized.Let up(t) denote the tree that results from movingthe dot in t up one step.The value of a subderivation t0 of G0 under ~sis a tuple of partial derivations of G, one for each> symbol in the root label of t0, in order.
Wherewe do not define a yield function for a productionbelow, the identity function is understood.For every set ~?
with a single, S -type compo-nent rooted by ?, add the ruleS !
[?, ~?
(>, .
.
.
,>)]~?
(x1, .
.
.
, xn)   hx1, .
.
.
, xniFor every non-adjunction, non-foot node ?
withchildren ?1, .
.
.
, ?n (n  0),[?, t]!
[?1, t]    [?n, t]For every component with root ?0 that is adjoin-able at ?,[?, up(t)]!
[?0, t]If ?0 is the root of the whole set ~?0, this rulerewrites a > to several > symbols; the corre-sponding yield function is thenh.
.
.
, ~?0(x1, .
.
.
, xn), .
.
.i    h. .
.
, x1, .
.
.
, xn, .
.
.iFor every component with ith foot ?0i that is ad-joinable at a node with ith child ?i,[?0i , t]!
[?i, up(t)]This last rule skips over deleted parts of thederivation tree, but this is harmless in a regularform MMTAG, because all the skipped adjunc-tions are safe.
()) First we describe how to decompose anygiven derivation t0 of G0 into a set of elementarytree sets.Let t = ~t0s.
(Note the convention that primedvariables always pertain to the simulating gram-mar, unprimed variables to the simulated gram-mar.)
If, during the computation of t, a node ?0creates the node ?, we say that ?0 is productiveand produces ?.
Without loss of generality, let usassume that there is a one-to-one correspondencebetween productive nodes and nodes of t.4To start, let ?
be the root of t, and ?1, .
.
.
, ?n itschildren.Define the domain of ?i as follows: any nodein t0 that produces ?i or any of its descendants isin the domain of ?i, and any non-productive nodewhose parent is in the domain of ?i is also in thedomain of ?i.For each ?i, excise each connected componentof the domain of ?i.
This operation is the reverseof adjunction (see Figure 6): each component gets4If G0 does not have this property, it can be modifiedso that it does.
This may change the derived trees slightly,which makes the proof of Proposition 3 trickier. ? ?1a   d{Q1 :  ?1a  d ?Q1 1 Figure 6: Example derivation (left) of the gram-mar of Figure 4, and first step of decomposition.Non-adjunction nodes are shown with the place-holder  (because the yield functions in the origi-nal grammar were anonymous), the Greek lettersindicating what is produced by each node.
Ad-junction nodes are shown with labels Qi in placeof the (very long) true labels.S : Q1 1Q2 2Q1 : a Q1 1dQ1 : Q2 : b Q2 2 cQ2 : Figure 7: MMTAG converted from CFG of Fig-ure 4 (cf.
the original TAG in Figure 3).
Eachcomponents?
type is written to its left.foot nodes to replace its lost children, and thecomponents are connected by d-edges accordingto their original configuration.Meanwhile an adjunction node is created inplace of each component.
This node is given a la-bel (which also becomes the type of the excisedcomponent) whose job is to make sure the finalgrammar does not overgenerate; we describe howthe label is chosen below.
The adjunction nodesare partitioned such that the ith site contains allthe adjunction nodes created when removing ?i.The tree set that is left behind is the elementarytree set corresponding to ?
(rather, the functionsymbol that labels ?
); this process is repeated re-cursively on the children of ?, if any.Thus any derivation of G0 can be decomposedinto elementary tree sets.
Let ?G be the union ofthe decompositions of all possible derivations ofG0 (see Figure 7 for an example).Labeling adjunction nodes For any node ?0,and any list of nodes h?01, .
.
.
, ?0ni, let the sig-nature of ?0 with respect to h?01, .
.
.
, ?0ni behA, a1, .
.
.
, ami, where A is the left-hand side ofthe GCFG production that generated ?0, and ai =h j, ki if ?0 gets its ith field from the kth field of?0j, or  if ?0 produces a function symbol in its ithfield.So when we excise the domain of ?i, the la-bel of the node left behind by a component ?
ishs, s1, .
.
.
, sni, where s is the signature of the rootof ?
with respect to the foot nodes and s1, .
.
.
, snare the signatures of the foot nodes with respect totheir d-children.
Note that the number of possibleadjunction labels is finite, though large.
?G trivially simulates G. Since each tree of ?Gcorresponds to a function symbol (though notnecessarily one-to-one), it is easy to write a triv-ial simulating interpretation ~ : T ( ?G) !
T (G).To see that ?G does not overgenerate, observe thatthe nonterminal labels inside the signatures en-sure that every derivation of ?G corresponds to avalid derivation ofG0, and therefore G. To see that~ is one-to-one, observe that the adjunction la-bels keep track of how G0 constructed its simu-lated derivations, ensuring that for any derivationt?
of ?G, the decomposition of the derived tree of t?is t?
itself.
Therefore two derivations of ?G cannotcorrespond to the same derivation of G0, nor of G.?G is finite.
Briefly, suppose that the number ofcomponents per tree set is unbounded.
Then it ispossible, by intersecting G0 with a recognizableset, to obtain a grammar whose simulated deriva-tion set is non-recognizable.
The idea is that mul-ticomponent tree sets give rise to dependent pathsin the derivation set, so if there is no bound onthe number of components in a tree set, neither isthere a bound on the length of dependent paths.This contradicts the requirement that a simulatinginterpretation map recognizable sets to recogniz-able sets.Suppose that the number of nodes per compo-nent is unbounded.
If the number of componentsper tree set is bounded, so must the number of ad-junction nodes per component; then it is possible,again by intersecting G0 with a recognizable set,to obtain a grammar which is infinitely ambigu-ous with respect to simulated derivations, whichcontradicts the requirement that simulating inter-pretations be bijective.
?G is in regular form.
A component of ?G corre-sponds to a derivation fragment ofG0 which takesfields from several subderivations and processesthem, combining some into a larger structure andcopying some straight through to the root.
Let?i(X) be the number of fields that a componentof type X copies from its ith foot up to its root.This information is encoded in X, in the signa-ture of the root.
Then ?G satisfies the regular formconstraint, because when adjunction inserts onespine into another spine, the the inserted spinemust copy at least as many fields as the outerone.
Furthermore, if the adjunction site is not safe,then the inserted spine must additionally copy thevalue produced by some lower node.5 DiscussionWe have proposed a more constrained version ofJoshi?s question, ?How much strong generativepower can be squeezed out of a formal systemwithout increasing its weak generative power,?and shown that within these constraints, a vari-ant of TAG called MMTAG characterizes the limitof how much strong generative power can besqueezed out of CFG.
Moreover, using the notionof a meta-level grammar, this result is extended toformalisms beyond CFG.It remains to be seen whether RF-MMTAG,whether used directly or for specifying meta-levelgrammars, provides further practical benefits ontop of existing ?squeezed?
grammar formalismslike tree-local MCTAG, tree insertion grammar,or regular form TAG.This way of approaching Joshi?s question is byno means the only way, but we hope that this workwill contribute to a better understanding of thestrong generative capacity of constrained gram-mar formalisms as well as reveal more powerfulformalisms for linguistic analysis and natural lan-guage processing.AcknowledgmentsThis research is supported in part by NSFgrant SBR-89-20230-15.
Thanks to Mark Dras,William Schuler, Anoop Sarkar, Aravind Joshi,and the anonymous reviewers for their valuablehelp.
S. D. G.ReferencesNaoki Abe.
1988.
Feasible learnability of formalgrammars and the theory of natural language ac-quisition.
In Proceedings of the Twelfth Inter-national Conference on Computational Linguistics(COLING-88), pages 1?6, Budapest.A.
V. Aho and J. D. Ullman.
1969.
Syntax directedtranslations and the pushdown assembler.
J. Comp.Sys.
Sci, 3:37?56.A.
V. Aho and J. D. Ullman.
1971.
Translations ona context free grammar.
Information and Control,19:439?475.Tilman Becker, Owen Rambow, and Michael Niv.1992.
The derivational generative power of formalsystems, or, Scrambling is beyond LCFRS.
Tech-nical Report IRCS-92-38, Institute for Research inCognitive Science, University of Pennsylvania.Noam Chomsky.
1965.
Aspects of the Theory of Syn-tax.
MIT Press, Cambridge, MA.Mark Dras.
1999.
A meta-level grammar: redefiningsynchronous TAG for translation and paraphrase.In Proceedings of the 37th Annual Meeting of theAssocation for Computational Linguistics, pages80?87, College Park, MD.Aravind K. Joshi.
1987.
An introduction to tree ad-joining grammars.
In Alexis Manaster-Ramer, ed-itor, Mathematics of Language.
John Benjamins,Amsterdam.Aravind K. Joshi.
2000.
Relationship between strongand weak generative power of formal systems.
InProceedings of the Fifth International Workshop onTAG and Related Formalisms (TAG+5), pages 107?113.Philip H. Miller.
1999.
Strong Generative Capacity:The Semantics of Linguistic Formalism.
Number103 in CSLI lecture notes.
CSLI Publications, Stan-ford.Owen Rambow, K. Vijay-Shanker, and David Weir.1995.
D-tree grammars.
In Proceedings of the33rd Annual Meeting of the Assocation for Com-putational Linguistics, pages 151?158, Cambridge,MA.James Rogers.
1994.
Capturing CFLs with tree ad-joining grammars.
In Proceedings of the 32nd An-nual Meeting of the Assocation for ComputationalLinguistics, pages 155?162, Las Cruces, NM.Yves Schabes and Richard C. Waters.
1993.
Lexical-ized context-free grammars.
In Proceedings of the31st Annual Meeting of the Association for Com-putational Linguistics, pages 121?129, Columbus,OH.K.
Vijay-Shanker, David Weir, and Aravind Joshi.1987.
Characterizing structural descriptions pro-duced by various grammatical formalisms.
In Pro-ceedings of the 25th AnnualMeeting of the Associa-tion for Computational Linguistics, pages 104?111,Stanford, CA.David J. Weir.
1988.
Characterizing Mildly Context-Sensitive Grammar Formalisms.
Ph.D. thesis, Univ.of Pennsylvania.
