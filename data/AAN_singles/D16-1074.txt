Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 772?783,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsGenerating Coherent Summaries of Scientific ArticlesUsing Coherence PatternsDaraksha Parveen Mohsen MesgarNLP Group and Research Training Group AIPHESHeidelberg Institute for Theoretical Studies gGmbHHeidelberg, Germany{daraksha.parveen|mohsen.mesgar|michael.strube}@h-its.orgMichael StrubeAbstractPrevious work on automatic summarizationdoes not thoroughly consider coherence whilegenerating the summary.
We introduce agraph-based approach to summarize scientificarticles.
We employ coherence patterns to en-sure that the generated summaries are coher-ent.
The novelty of our model is twofold:we mine coherence patterns in a corpus of ab-stracts, and we propose a method to combinecoherence, importance and non-redundancy togenerate the summary.
We optimize these fac-tors simultaneously using Mixed Integer Pro-gramming.
Our approach significantly outper-forms baseline and state-of-the-art systems interms of coherence (summary coherence as-sessment) and relevance (ROUGE scores).1 IntroductionThe growth in the scientific output of many differ-ent fields makes the task of automatic summariza-tion imperative.
Automatic summarizers assist re-searchers to have an informative and coherent gistof long scientific articles.
An automatic summarizerproduces summaries considering three properties:Importance: The summary should contain the im-portant information of the input document.Non-redundancy: The summary should containnon-redundant information.
The information shouldbe diverse in the summary.Coherence: Though the summary should comprisediverse and important information of the input doc-ument, its sentences should be connected to one an-other such that it becomes coherent and easy to read.If we do not ensure that a summary is coher-ent, its sentences may not be properly connected.This results in an obscure summary.
In previouswork coherence has not been thoroughly considered.Parveen and Strube (2015) use single sentence con-nectivity in the input document as a coherence mea-sure.
They measure coherence by calculating theoutdegree of a sentence in a graph representationof an input document.
This has two disadvantages:first, since it is computed only based on one sen-tence, it is not sufficient to generate coherent sum-maries; second, it is obtained based on sentence con-nectivity in the input document rather than in thesummary.In this work, we focus on the coherence aspect ofsummarization.
We use discourse entities as the unitof information that relate sentences.
Here, discourseentities are referred to as head nouns of noun phrases(see Section 2).
The main goal is to extract sentenceswhich refer to those entities which are important andunique, and also to entities which connect the ex-tracted sentences in a coherent manner.
Entities inconnected sentences can be used to create linguis-tically motivated coherence patterns (Danes?, 1974).Recently, Mesgar and Strube (2015) modeled thesecoherence patterns by subgraphs of the graph repre-sentation (nodes represent sentences and edges rep-resent entity connections among sentences) of doc-uments.
They show that the frequency of coherencepatterns can be used as features for coherence.The key idea of this paper is to apply coherencepatterns to long scientific articles to extract (possi-bly) non-adjacent sentences which, however, are al-ready coherent.
Based on the assumption that ab-772c ba (i)S1 Cardiometabolic  diseases  are a growing concern across sub-Saharan Africa (SSA).
S2  According to current estimates, the prevalence of diabetes among adults aged 20?79 y in Africa is 3.8% and       will increase to 4.6% by 2030.
S3 Urban environments and associated lifestyles, including diets high in salt, sugar, and fat, and physical inactivity, have been        widely implicated as leading causes of the rise in cardiometabolic diseases.S4  If and how these changes affect the health of rural residents, however, remains poorly understood.S5  Existing research on lifestyle risk factors for cardiometabolic diseases has almost exclusively focused on exposures       to urban environments.a b(ii)Figure 1: (i) A sample of mined coherence patterns from abstracts; nodes are sentences and edges are entity connections; (ii)Sentences S1, S3 and S5 constitute the pattern in an input document.stracts of scientific articles are similar in style to co-herent summaries, we obtain coherence patterns byanalyzing a corpus of abstracts of articles from bio-medicine (PubMed corpus).
Then we apply the mostfrequent coherence patterns to input documents, i.e.long scientific articles from bio-medicine (PLOSMedicine dataset), extract corresponding sentencesto generate coherent summaries, and evaluate themby comparing with summaries written by a PLOSMedicine editor.
Figure 1 illustrates the extractionof sentences from an input document (Figure 1, (ii))which constitute a coherence pattern (Figure 1, (i)).If we overlay the input document with coherencepatterns and extract the sentences which constitutethose patterns, then the extracted sentences are al-ready coherent.
We also take into account impor-tance and non-redundancy.
We capture all three fac-tors in an objective function maximized by MixedInteger Programming (MIP) (Section 2).We evaluate our method on two different datasets:PLOS Medicine (Parveen and Strube, 2015) andDUC 2002.
We extract frequent coherence patternsfrom all abstracts in the PubMed corpus, and gen-erate summaries of unseen scientific articles of thePLOS Medicine dataset (Section 3.1).
For DUC2002 we extract coherence patterns from the humansummaries of DUC 2005 (Dang, 2005).
We evaluateour model on DUC 2002 to compare with state-of-the-art systems.Our experimental results show that using coher-ence patterns for summarization produces more in-formative (but not redundant) and coherent sum-maries as compared to several baseline methods andstate-of-the-art methods based on ROUGE scoresand human judgements.2 MethodWe solve the task of creating coherent summaries byemploying coherence patterns.
We tightly integratedetermining importance, non-redundancy and co-herence by applying global optimization, i.e., MIP.2.1 Document RepresentationWe use the entity graph (Guinaudeau and Strube,2013) to represent scientific articles.
The entitygraph is a bipartite graph which consists of entitiesand sentences as two disjoint sets of nodes (Figure 2,ii).
Entity nodes are connected only with sentencenodes and not among each other.
An entity node isconnected with a sentence node if and only if the en-tity is present in the sentence.
Entities are the headnouns of noun phrases.We perform a one-mode projection on sentencenodes to create a directed one-mode projectiongraph (Figure 2, iii).
Two sentence nodes in the one-mode projection graph are connected if they share atleast one entity in the entity graph.
Edge directionsencode the sentence order in the input document.2.2 Mining Coherence PatternsWe use one-mode projection graphs of abstracts inthe PubMed corpus (see Section 3.1) to mine coher-ence patterns.
The weight of a coherence pattern,weight(patu), is its frequency in the PubMed cor-pus normalized by the maximum number of its oc-currence in abstracts in the PubMed corpus (Equa-tion 1).weight(patu) =?qk=1 freq(patu, gk)maxqk=1freq(patu, gk), (1)where q is the number of graphs associated with ab-stracts in the corpus, and gk represents the graph ofthe kth abstract in the PubMed corpus.773S1 The overall [rates]e1 of cesarean [delivery]e2 are increasing signifi-cantly in the [world]e3 .S2 In [parts]e4 of [England]e5 in 2010, the [proportion]e6 of total[births]e7 by cesarean [section]e8 was almost 25%, compared withjust 2% in the 1950s.S3 In the United States and Australia rates of greater than 33% have beenreported and in [China]e9 and [parts]e4 of South [America]e10 ,including Brazil and [Paraguay]e11 , cesarean [rates]e1 of between40% and 50% are common.S4 [Concerns]e12 have been expressed regarding the [impact]e13of a cesarean [section]e8 on subsequent [pregnancy]e14[outcome]e15 particularly the [rate]e16 of subsequent[stillbirth]e17 , [miscarriage]e18 , and ectopic pregnancy.S5 Hypothesized biological [mechanisms]e19 include placental[abnormalities]e20 , prior [infection]e21 , and adhesion[formation]e22 due to cesarean [section]e8 .
(i)s1 s2 s3 s4 s5e2 e3 e4 e5 e6 e7 e8e1 e22....(ii)s1 s2s3 s4 s5(iii)Figure 2: (i) A sample text from PLOS Medicine; (ii) entitygraph; (iii) projection graph of the text.The weights of the coherence patterns are not onthe same scale.
We normalize the weights using thestandard score (x???
), where ?
is the mean and ?is the standard deviation.
A sigmoid function scalesweights to the interval [0, 1].2.3 Summary GenerationWe maximize importance, non-redundancy andpattern-based coherence with their respectiveweights ?
to generate coherent summaries.
Theobjective function is:max(?IfI(S) + ?RfR(E) + ?CfC(P )), (2)where S is a set of binary variables for sentences inan article, E is a set of binary variables for entitiesand P is a set of binary variables for coherence pat-terns.Importance (fI(S)): The importance functionquantifies the overall importance of information inthe summary, which is calculated by considering theranks of selected sentences for the summary:fI(S) =n?i=1Rank(senti) ?
si.
(3)In Equation 3, Rank (senti) represents the rank ofsentence senti and si is the binary variable of sen-tence senti.
n is the number of sentences.Kleinberg (1999) develops the Hubs and Author-ities algorithm (HITS) to rank web pages.
He di-vides web pages into two sets: Hubs, pages whichcontain links to informative web pages, and Author-ities, informative web pages.
Here, Hubs are entitiesand Authorities are sentences.
We calculate the rankof sentences using the HITS algorithm (Parveen andStrube, 2015).
Initial ranks for sentences and enti-ties are computed by Equations 4 and 5 in an entitygraph:Rankinit(senti) = 1 + sim(senti, title), (4)Rankinit(entj) = 1.
(5)In Equation 4, sim(senti, title) is the cosine sim-ilarity between the scientific article?s title and sen-tence senti.
In Equation 5, entj refers to the jthentity in the entity graph.
After applying the HITSalgorithm on the entity graph using the above initial-ization, the final rank of a sentence is its importance.Non-redundancy (fR (E)): In the objective func-tion, fR(E) represents the non-redundancy of in-formation in the summary.
Intuitively, if the sum-mary has unique information in every sentence thenthe summary is non-redundant.
We measure non-redundancy as follows:fR(E) =m?j=1ej , (6)where m is the number of entities and ej is a binaryvariable for each entity.
The summary becomes non-redundant if we include only unique entities.On the basis of fI(S) and fR(E) we define thefollowing optimization constraints:n?i=1|Senti| ?
si ?
lmax, (7)?j?Eiej ?
|Ei| ?
si for i = 1, .
.
.
, n, (8)774?si?Sjsi ?
ej for j = 1, .
.
.
,m. (9)The constraint in Equation 7 limits the length of thesummary.
lmax is the maximal length of the sum-mary and |Senti| is the length of sentence senti.In Equation 8, the constraint ensures that if sen-tence senti is selected (si = 1), then all entitiesEi present in sentence senti must also be selected.In Equation 9, Sj represents the set of binary vari-ables of sentences which contain entity entj .
Thisconstraint prescribes that if entity entj is selected(ej = 1), then at least one of the sentences in Sjmust be selected, too.Coherence (fC(P)): We use the mined patternsto extract sentences from the input document ofPLOS Medicine to create a coherent summary.
Weextract sentences, if the connectivity among nodesin their projection graph matches the connectivityamong nodes in a coherence pattern.
In Figure 3 weoverlay the projection graph from Figure 2, ii withthe coherence pattern from Figure 1, i.
This resultsin three instances of this coherence pattern.
How-ever, we select only one since we simultaneously op-timize for importance and non-redundancy.s2s3 s4s2 s5s4s2 s5s3s1 s2s3 s4 s5(i)(ii)Figure 3: (i) A projection graph; (ii) several instances of acoherence pattern in Figure 1, ii.In the objective function, fC(P ) measures the co-herence of the summary based on the weights of thecoherence patterns occurring in it (Section 2.2):fC(P ) =U?u=1weight(patu) ?
pu, (10)where pu is a boolean variable associated with co-herence pattern patu.The optimization considers pattern patu for sum-marizing the input article, if patu is a subgraph ofthe projection graph of the article.
To find the coher-ence pattern in a projection graph we apply a graphmatching algorithm (Lerouge et al, 2015).gpatuxa,s    =12 xa,s    =04xc,s    =02xc,s =14yac,s s    =142 s1 s2s3 s4 s5Figure 4: An illustration of mapping variables to overlay graphg with coherence pattern patu.To model the graph matching problem betweenprojection graph g = (Vg, Eg) and patterns patu =(Vpatu , Epatu), two kinds of mapping binary vari-ables are used: xi,k for the node map, and yij,kl forthe edge map.
xi,k, = 1, if vertices i ?
Vpatu andk ?
Vg match.
yij,kl = 1, if for each pair of edgesij ?
Epatu and kl ?
Eg match (Figure 4).
Con-straints for graph matching are as follows:?
Every node of the pattern matches at most oneunique node of the graph:?k?Vgxi,k ?
1 ?i ?
Vpatu .
(11)?
Every edge of the pattern matches at most oneunique edge of the graph:?kl?Egyij,kl ?
1 ?ij ?
Epatu .
(12)775?
Every node of the graph matches at most onenode of the pattern:?i?Vpatuxi,k ?
1 ?k ?
Vg.
(13)?
A node of pattern patu matches a node of graphg if an edge originating from the node of patumatches an edge originating from the node of g:?kl?Egyij,kl = xi,k ?k ?
Vg, ?ij ?
Epatu .
(14)?
A node of pattern patu matches a node of graphg if an edge targeting the node of patu matchesan edge targeting the node of g:?kl?Egyij,kl = xj,l ?l ?
Vg, ?ij ?
Epatu .
(15)?
We need a constraint to extract induced pat-terns1:?i?Vpatuxi,k +?j?Vpatuxj,l?
?ij?Epatuyij,kl ?
1 ?kl ?
Eg.
(16)The constraints in Equations 11 ?
16 are definedto find pattern patu in projection graph g of the inputarticle.
However these constraints do not ensure thatthe pattern is in the summary.
For this, we defineconstraints in Equations 17 ?
19 to assure that anexisting pattern in an article is selected if there aresome sentences in the summary which constitute thepattern.?
The constraint in Equation 17 ensures that ifsentences sk and sl are selected for the sum-mary then the edge between them is selected(zkl = 1), too:sk ?
sl = zkl ?k, l ?
Vg.
(17)?
Pattern patu is present in the summary (pu = 1)if and only if one of its instances in the projec-tion graph is included in the summary, i.e., some1Pattern patu is an induced subgraph of graph g if patu con-tains all possible edges which appear in g.of the selected sentence nodes must be present inan instance of pattern patu.
|Vpatu | is the num-ber of nodes in pattern patu, and |Epatu | is thenumber of edges in pattern patu.
This constraintis shown below:?i?vpatu?k?vgsk ?
xi,k +?ij?epatu?kl?egzkl ?
yij,kl= pu(|Vpatu |+ |Epatu |).
(18)?
If a sentence is selected then it has to match anode of at least one of the patterns:?patu?P?i?Vpatuxi,k ?
sk ?k ?
Vg.
(19)3 ExperimentsIn this section we discuss the datasets and the experi-mental setup.
We evaluate our model using ROUGEscores and human judgements.3.1 DatasetsPLOS Medicine: This dataset contains 50 scien-tific articles.
In this dataset every scientific articleis accompanied by a summary written by an editorof the month.
This editor?s summary has a broaderperspective than the authors?
abstract.
We use theeditor?s summary as a gold summary for calculat-ing the ROUGE scores.
We use 700 different PLOSMedicine articles from the PubMed2 corpus to minecoherence patterns from their abstracts and to calcu-late patterns?
weights.DUC: The DUC 2002 dataset has been annotatedfor the Document Understanding Conference 2002.It contains 567 news articles for summarization.Every article is accompanied by at least two goldsummaries.
DUC 2002 articles are shorter thanPLOS Medicine articles (25 vs. 154 sentences av-erage length).
We use all (300) DUC 2005 humansummaries to mine coherence patterns and to calcu-late their weights.3.2 Experimental SetupFirst, we extract the text of an article.
We removefigures, tables, references and non-alphabetical char-acters.
Then we use the Stanford parser (Klein and2http://www.ncbi.nlm.nih.gov/pmc/tools/ftp/776Manning, 2003) to determine sentence boundaries.We apply the Brown coherence toolkit (Elsner andCharniak, 2011) to convert the articles into entitygrids (Barzilay and Lapata, 2008) which then aretransformed into entity graphs.
We use gSpan (Yanand Han, 2002) to extract all subgraphs from the pro-jection graphs of the abstracts of the PubMed cor-pus.It is possible that patterns with a large numberof nodes are not at all present in the projectiongraph.
Hence, we use coherence patterns with 3 and4 nodes, referred to as CP3 and CP4, respectively.We use Gurobi (Gurobi Optimization, Inc., 2014) tosolve the MIP problem.
We use a pronoun resolutionsystem (Martschat, 2013) to replace all pronouns inthe summary with their antecedents.We determine the best values for ?I , ?R, and ?con the development sets.
?I = 0.4, ?R = 0.3, and?c = 0.3 are the best weights for the PLOS Medicinedevelopment set.
Weights for the DUC 2002 devel-opment set are ?I = 0.5, ?R = 0.2 and ?c = 0.3.3.3 ResultsWe evaluate our model in two ways.
First, we useROUGE scores to compare our model with othermodels.
Second, we explicitly evaluate the coher-ence of the summaries by human judgements.3.3.1 ROUGE AssessmentThe ROUGE score (Lin, 2004) is a standard evalua-tion score in automatic text summarization.
It calcu-lates the overlap between gold summary and systemsummary.
In automatic text summarization ROUGE1, ROUGE 2 and ROUGE SU4 are usually reported(see Graham (2015) for an assessment of evaluationmetrics for summarization).We compare our system (CP3 andCP4) with fourbaselines: Lead, Random, Maximal Marginal Rel-evance (MMR) and TextRank.
Lead selects adja-cent sentences from the beginning of an input ar-ticle.
Random selects sentences randomly.
MMR(Carbonell and Goldstein, 1998) uses a trade-offbetween relevance and redundancy.
TextRank is agraph-based system using sentences as nodes andedges weighted by cosine similarity between sen-tences (Mihalcea and Tarau, 2004).We compare our system with three state-of-the-artsystems: ECoh (Parveen and Strube, 2015), TCohSystems R-SU4 R-2BaselinesLead 0.067 0.055Random 0.048 0.031MMR 0.069 0.048TextRank 0.068 0.048State-of-the-artECoh 0.131 0.098TCoh 0.129 0.095Mead 0.084 0.068Our ModelCP3 0.135 0.103Table 1: PLOS Medicine, editor?s summaries with 5 sentences.
(Parveen et al, 2015), and Mead (Radev et al,2004).
ECoh uses entity graphs which consists ofentities and sentences, and TCoh uses topical graphswhere entities are replaced by the topics.
Theyboth use the outdegree of sentence nodes in the un-weighted and the weighted projection graph, respec-tively, as the coherence measure of each sentence.Mead employs a linear combination of three fea-tures: centroid score, position score and overlapscore.
The linear combination is used to add sen-tences to the summary up to the required length.
Thecentroid score gives the highest score to the mostcentral sentence in the cluster of sentences, the po-sition score gives a higher score to the sentenceswhich are in the beginning of the document, and theoverlap score computes the similarity between thesentences of a document.
All three features do nottake care of the coherence of a summary as they donot have any notion of the order and the structure ofa summary.To compare with the state-of-the-art systems onPLOS Medicine, ECoh (Parveen and Strube, 2015)and TCoh (Parveen et al, 2015), we limit the lengthof summaries to 5 sentences.
Table 1 reportsROUGE scores of different systems.
Our systemoutperforms baselines and state-of-the-art systems.Since the word length limit of a summary is moremeaningful than the sentence length limit of a sum-mary, we limit the length of a summary to the av-erage length of editor?s summaries in the dataset(750 words).
Table 2 shows the performance ofdifferent systems with 750 words limit for a sum-mary.
In Table 2, we use different versions ofROUGE-SU4 and ROUGE-2 where W/WO stands777PLOS Medicine WOStop WOStop WStop WStop WOStop WOStop WStop WStopEditor?s summaries WStem WOStem WStem WOStem WStem WOStem WStem WOStemROUGE SU4 (*pvalue < 0.05) ROUGE 2 (*pvalue < 0.01)Upper Bound 0.423 0.354 0.519 0.470 0.344 0.304 0.430 0.399BaselinesLead 0.191 0.158 0.246 0.222 0.158 0.140 0.185 0.171Random 0.140 0.113 0.169 0.153 0.102 0.088 0.125 0.116MMR 0.183 0.149 0.240 0.215 0.141 0.125 0.171 0.157TextRank 0.148 0.104 0.161 0.159 0.115 0.084 0.126 0.118State-of-the-artECoh 0.204* 0.167 0.254 0.228 0.160* 0.145 0.187 0.173TCoh 0.195 0.161 0.231 0.206 0.157 0.140 0.169 0.165Mead 0.197 0.165 0.246 0.222 0.156 0.139 0.186 0.172Our ModelCP3 0.215* 0.178 0.268 0.241 0.172* 0.153 0.200 0.184CP4 0.218 0.179 0.270 0.245 0.175 0.156 0.201 0.187Table 2: ROUGE scores on PLOS Medicine with 750 words.for With/Without.
Here, WOStop means withoutconsidering stopwords while calculating ROUGEscores, and WOStem means without applying thePorter Stemmer on summaries while calculatingROUGE scores.
Our models outperform baselineand state-of-the-art systems (Table 2).
We computestatistical significance between ECoh and CP3 onboth scores, ROUGE SU4 is significantly differentby 95%.
ROUGE 2 is significantly different by 99%.Upper Bound in Table 2 represents maximumROUGE scores that can be achieved in extractivesummarization on the PLOS Medicine dataset.
It iscalculated by considering the whole scientific articleas a summary and the corresponding editor?s sum-mary as the gold standard.
The Upper Bound scoresare not very high showing that a significant im-provement in ROUGE scores on the PLOS Medicinedataset is difficult.
Thus, the performance achievedby our systems, CP3 and CP4, is a considerable im-provement on the PLOS Medicine dataset.Furthermore, we apply CP3 on the dataset intro-duced by Liakata et al (2013).
The dataset con-sists of 28 scientific articles from the chemistry do-main.
The state-of-the-art system on this dataset isCoreSC, which is developed by Liakata et al (2013).CoreSC considers discourse information while sum-marizing a scientific article.
The ROUGE-1 scoreof CP3 (0.96) is significantly better than CoreSC(0.75) and Microsoft Office Word 2007 AutoSuma-rize (0.73) (Garc?
?a-Herna?ndez et al, 2009), in re-spect of abstracts.
This shows that our system per-forms well in other domains.We further calculate the average number of sen-tences per summary obtained by Mead andCP3.
Onaverage Mead produces 17.5 sentences per summarywhereasCP3 produces 27.2 sentences per summary.The possibility of longer sentences containing moretopic irrelevant entities is higher than shorter sen-tences (Jin et al, 2010).We calculate the average percentage of sentencesselected from the sections Introduction, Method, Re-sults and Discussion by different systems.
CP3 ex-tracts sentences mainly from Introduction (32.5%)and Method (38.5%), but also a considerable num-ber of sentences from Results (17.67%) and Discus-sion (11.33%).
The distribution is quite similar toTextRank and MMR.
Lead, obviously, extracts onlyfrom Introduction (80.59%) and Method (19.41%).Mead extracts maximum sentences from the begin-ning of the document using its positional feature.The sentences in a summary extracted by CP3 areevenly distributed indicating that they are not biasedto any sections.
This clearly represents that coher-ence patterns not only seeks for nearby sentences butalso for any distant sentences of a scientific article.Table 3 shows the results on DUC 2002 to com-pare the results with state-of-the-art systems.
Thereis no significant difference between the ROUGEscores of using CP3 and CP4 on DUC 2002.
Thus,we only report the results of using CP3 on DUC2002.In Table 3, LREG is a baseline system us-778Systems R-1 R-2 R-SU4BaselinesLead 0.459 0.180 0.201DUC 2002 Best 0.480 0.228TextRank 0.470 0.195 0.217LREG 0.438 0.207State-of-the-artMead 0.445 0.200 0.210ILPphrase 0.454 0.213URANK 0.485 0.215UniformLink (k = 10) 0.471 0.201ECoh 0.485 0.230 0.253TCoh 0.481 0.243 0.242NN-SE 0.474 0.230Our ModelCP3 0.490 0.247 0.258Table 3: ROUGE scores on DUC 2002.ing logistic regression and hand-made features(Cheng and Lapata, 2016).
We compare ourmodel to previously published state-of-the-art sys-tems.
These systems show reasonable performanceon the DUC 2002 summarization task.
ILPphraseis a phrase-based extraction model, which selectsimportant phrases and combines them via inte-ger linear programming (Woodsend and Lapata,2010).
URANK utilizes a unified ranking process forsingle-document and multi-document summariza-tion tasks (Wan, 2010).
UniformLink (k=10), con-siders similar documents for document expansion inthe single-document summarization task (Wan andXiao, 2010).
The more recent system, NN-SE, uti-lizes a neural network hierarchical document en-coder and an attention-based extractor to extract sen-tences from a document for a summary (Cheng andLapata, 2016).
ROUGE scores of our approach onthis dataset are better than baselines and state-of-the-art systems.
This shows that our system performswell even in a different genre (robust) and with con-siderably shorter input documents (scalable).3.3.2 Coherence AssessmentROUGE scores do not evaluate summary coher-ence, since ROUGE only calculates overlapping re-call scores and does not consider the structure of thesummary.
Haghighi and Vanderwende (2009), Ce-likyilmaz and Hakkani-Tu?r (2010) and Christensenet al (2013) evaluate the overall summary qualityby asking human subjects to rank system generatedsummaries.
Parveen and Strube (2015) and Parveenet al (2015) assess the coherence by asking humanassessors to rank system generated summaries andcompare their system with baseline systems.We perform summary coherence assessment byasking one Postdoc, two PhD students and one Mas-ters student from the field of natural language pro-cessing.
We provide them with the output sum-maries of four different systems for ten articles.
Weask them to rank the summaries, i.e., the best sum-mary gets rank 1, the second best gets rank 2, thethird best gets rank 3, and the worst gets rank 4.The four systems assessed are CP3, ECoh, Text-Rank, and Lead.
We apply the Kendall concordancecoefficient (W) (Siegel and Castellan, 1988) to mea-sure whether the human assessors agree in rankingthe four systems.
With W = 0.6725 the correla-tion between the human assessors is high.
Applyingthe ?2 test shows that W is significant at least at the99% level indicating that the ranks provided by thehuman assessors are reliable and informative.
Table4 shows the overall average rank of a system givenby the four human assessors.
The lower the value ofaverage human scores the more coherent the sum-mary.
Unsurprisingly Lead gets the best overall av-PLOS MedicineSystem Average Human ScoreTextRank 3.950ECoh 2.325CP3 1.875Lead 1.625Table 4: The average human scores.erage rank.
Lead extracts adjacent sentences fromthe beginning of the document.
Hence, these sum-maries are as coherent as the author intends themto be, but they are not informative.
However, CP3is very close in coherence to Lead indicating thatour strategy is successful.
It also performs substan-tially better than TextRank and ECoh.
This confirmsthat using coherence patterns for sentence extractionyields more coherent summaries.4 Related WorkSummarizing scientific articles is as difficult asmulti-document summarization because scientificarticles are tend to be long and the important infor-779mation is spread all over the article unlike informa-tion in news articles (Teufel and Moens, 2002).There are various approaches for summarizingscientific articles.
Citations have been used by manyresearchers for summarization in this domain (Elkisset al, 2008; Mohammad et al, 2009; Qazvinian andRadev, 2008; Abu-Jbara and Radev, 2011).
Nanbaand Okumura (2000) develop rules for categoriz-ing citations by analyzing citation sentences.
New-man (2001) analyzes the structure using a citationnetwork.
Similarly, Siddharthan and Teufel (2007)discover scientific attributions using citations.
Dis-course structure (but not necessarily coherence) hasbeen used by Teufel and Moens (2002), Liakata etal.
(2013) and others for summarizing scientific arti-cles.Several state-of-the-art extractive summarizationsystems implement summarization as maximizingan objective function using constraints.
McDonald(2007) interprets text summarization as a global in-ference problem, where he is maximizing the im-portance score of a summary by considering thelength constraint.
Similarly, various approaches forsummarization are based on optimization using ILP(Gillick et al, 2009; Nishikawa et al, 2010; Galaniset al, 2012; Parveen and Strube, 2015).Until now, only few works have considered co-herence while summarizing scientific articles.
Abu-Jbara and Radev (2011) work on citation basedsummarization.
They preprocess the citation sen-tences to filter out irrelevant sentences or sentencefragments, then extract sentences for the summary.Eventually, they refine the summary sentences to im-prove readability.
Jha et al (2015) consider Min-imum Independent Discourse Contexts (MIDC) tosolve the problem of non-coherence in extractivesummarization.
However, none of them deals withthe problem of coherence within the task of sentenceselection.
Sentence selection and ensuring the co-herence of summaries are not tightly integrated intheir techniques.
They model coherence in summa-rization by only considering adjacent sentences.There are few methods (Hirao et al, 2013;Parveen and Strube, 2015; Gorinski and Lapata,2015) which integrate coherence in optimization.These methods do not take into account the overallstructure of the summary.
Unlike earlier methods,we incorporate coherence patterns in optimization.5 ConclusionWe introduce a novel graph-based approach to gen-erate coherent summaries of scientific articles.
Ourapproach takes care of coherence distinctively by co-herence patterns.
We have experimented with PLOSMedicine and DUC 2002.
The results show thatthe approach is robust, works on both scientific andnews documents and with input documents of dif-ferent length.
It considerably outperforms state-of-the-art systems on both datasets.
We collected hu-man assessments to evaluate the coherence of sum-maries.
Our system substantially outperforms base-lines and state-of-the-art systems, i.e., incorporat-ing coherence patterns produces more coherent sum-maries.
The results show that our approach performswell in human summary coherence assessment andrelevance evaluation (ROUGE scores).AcknowledgmentsThis work has been funded by the Klaus TschiraFoundation, Heidelberg, Germany.
The first andsecond authors have been supported by a Heidel-berg Institute for Theoretical Studies Ph.D. schol-arship.
This work has been supported by the Ger-man Research Foundation as part of the ResearchTraining Group ?Adaptive Preparation of Informa-tion from Heterogeneous Sources?
(AIPHES) undergrant No.
GRK 1994/1.
We would like to thank ourcolleagues Alexander Judea, Isabell Wolter, Mark-Christoph Mu?ller and Nafise Moosavi who becamehuman subjects for coherence assessment evalua-tion.ReferencesAmjad Abu-Jbara and Dragomir Radev.
2011.
Co-herent citation-based summarization of scientific pa-pers.
In Proceedings of the 49th Annual Meeting ofthe Association for Computational Linguistics (Vol-ume 1: Long Papers), Portland, Oreg., 19?24 June2011, pages 500?509.Regina Barzilay and Mirella Lapata.
2008.
Modelinglocal coherence: An entity-based approach.
Computa-tional Linguistics, 34(1):1?34.Jaime G. Carbonell and Jade Goldstein.
1998.
Theuse of MMR, diversity-based reranking for reorderingdocuments and producing summaries.
In Proceedingsof the 21st Annual International ACM-SIGIR Confer-ence on Research and Development in Information780Retrieval, Melbourne, Australia, 24?28 August 1998,pages 335?336.Asli Celikyilmaz and Dilek Hakkani-Tu?r.
2010.
A hy-brid hierarchical model for multi-document summa-rization.
In Proceedings of the 48th Annual Meetingof the Association for Computational Linguistics, Up-psala, Sweden, 11?16 July 2010, pages 815?824.Jianpeng Cheng and Mirella Lapata.
2016.
Neural sum-marization by extracting sentences and words.
In Pro-ceedings of the 54th Annual Meeting of the Associa-tion for Computational Linguistics (Volume 1: LongPapers), Berlin, Germany, 7?12 August 2016, pages484?494.Janara Christensen, Mausam, Stephen Soderland, andOren Etzioni.
2013.
Towards coherent multi-document summarization.
In Proceedings of the 2013Conference of the North American Chapter of theAssociation for Computational Linguistics: HumanLanguage Technologies, Atlanta, Georgia, 9?14 June2013, pages 1163?1173.Frantis?ek Danes?, editor.
1974.
Papers on FunctionalSentence Perspective.
Academia, Prague.Hoa Trang Dang.
2005.
Overview of DUC 2005.
In Pro-ceedings of the 2005 Document Understanding Con-ference held at the Human Language Technology Con-ference and Conference on Empirical Methods in Nat-ural Language Processing, Vancouver, B.C., Canada,9?10 October 2005.Aaron Elkiss, Siwei Shen, Anthony Fader, Gu?nes?
Erkan,David States, and Dragomir Radev.
2008.
Blindmen and elephants: What do citation summaries tellus about a research article?
Journal of the Ameri-can Society for Information Science and Technology,59(1):51?62.Micha Elsner and Eugene Charniak.
2011.
Extending theentity grid with entity-specific features.
In Proceed-ings of the 49th Annual Meeting of the Association forComputational Linguistics (Volume 2: Short Papers),Portland, Oreg., 19?24 June 2011, pages 125?129.Dimitrios Galanis, Gerasimos Lampouras, and Ion An-droutsopoulos.
2012.
Extractive multi-documentsummarization with integer linear programming andsupport vector regression.
In Proceedings of the 24thInternational Conference on Computational Linguis-tics, Mumbai, India, 8?15 December 2012, pages 911?926.Rene?
Arnulfo Garc?
?a-Herna?ndez, Yulia Ledeneva,Griselda Mat?
?as Mendoza, A?ngel Herna?ndezDominguez, Jorge Chavez, Alexander Gelbukh, andJose?
Luis Tapia Fabela.
2009.
Comparing commercialtools and state-of-the-art methods for generating textsummaries.
In Proceedings of Advances in ArtificialIntelligence, 8th Mexican International Conferenceon Artificial Intelligence, Guanajuato, Mexico, 9-13November 2009, pages 92?96.Daniel Gillick, Korbinian Riedhammer, Benoit Favre,and Dilek Hakkani-Tu?r.
2009.
A global optimiza-tion framework for meeting summarization.
In Pro-ceedings of the 2009 IEEE International Conferenceon Acoustics, Speech, and Signal Processing, Taipei,Taiwan, 19?24 June 2009, pages 4769?4772.Philip John Gorinski and Mirella Lapata.
2015.
Moviescript summarization as graph-based scene extraction.In Proceedings of the 2015 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies,Denver, Col., 31 May ?
5 June 2015, pages 1066?1076.Yvette Graham.
2015.
Re-evaluating automatic sum-marization with BLEU and 192 shades of ROUGE.In Proceedings of the 2015 Conference on Empiri-cal Methods in Natural Language Processing, Lisbon,Portugal, 17?21 September 2015, pages 128?137.Camille Guinaudeau and Michael Strube.
2013.
Graph-based local coherence modeling.
In Proceedings ofthe 51st Annual Meeting of the Association for Com-putational Linguistics (Volume 1: Long Papers), Sofia,Bulgaria, 4?9 August 2013, pages 93?103.Gurobi Optimization, Inc. 2014.
Gurobi optimizer refer-ence manual.Aria Haghighi and Lucy Vanderwende.
2009.
Exploringcontent models for multi-document summarization.
InProceedings of Human Language Technologies 2009:The Conference of the North American Chapter of theAssociation for Computational Linguistics, Boulder,Col., 31 May ?
5 June 2009, pages 362?370.Tsutomu Hirao, Yasuhisa Yoshida, Masaaki Nishino,Norihito Yasuda, and Masaaki Nagata.
2013.
Single-document summarization as a tree knapsack problem.In Proceedings of the 2013 Conference on Empiri-cal Methods in Natural Language Processing, Seattle,Wash., 18?21 October 2013, pages 1515?1520.Rahul Jha, Reed Coke, and Dragomir Radev.
2015.Surveyor: A system for generating coherent surveyarticles for scientific topics.
In Proceedings of the29th Conference on the Advancement of Artificial In-telligence, Austin, Texas, 25?30 January 2015, pages2167?2173.Feng Jin, Minlie Huang, and Xiaoyan Zhu.
2010.
Acomparative study on ranking and selection strategiesfor multi-document summarization.
In Proceedings ofColing 2010: Poster Volume, Beijing, China, 23?27August 2010, pages 525?533.Dan Klein and Christopher D. Manning.
2003.
Accu-rate unlexicalized parsing.
In Proceedings of the 41stAnnual Meeting of the Association for Computational781Linguistics, Sapporo, Japan, 7?12 July 2003, pages423?430.Jon M. Kleinberg.
1999.
Authoritative sources ina hyperlinked environment.
Journal of the ACM,46(5):604?632.Julien Lerouge, Pierre Le Bodic, Pierre He?roux, andSe?bastien Adam.
2015.
GEM++: A tool for solvingsubstitution-tolerant subgraph isomorphism.
In C.-L.Liu, B. Luo, W.G.
Kropatsch, and J. Cheng, editors,Graph-Based Representations in Pattern Recognition,pages 128?137.
Springer, Heidelberg, Germany.Maria Liakata, Simon Dobnik, Shyamasree Saha, ColinBatchelor, and Dietrich Rebholz-Schuhmann.
2013.A discourse-driven content model for summarisingscientific articles evaluated in a complex question an-swering task.
In Proceedings of the 2013 Conferenceon Empirical Methods in Natural Language Process-ing, Seattle, Wash., 18?21 October 2013, pages 747?757.Chin-Yew Lin.
2004.
ROUGE: A package for automaticevaluation of summaries.
In Proceedings of the TextSummarization Branches Out Workshop at ACL ?04,Barcelona, Spain, 25?26 July 2004, pages 74?81.Sebastian Martschat.
2013.
Multigraph clustering forunsupervised coreference resolution.
In 51st AnnualMeeting of the Association for Computational Linguis-tics: Proceedings of the Student Research Workshop,Sofia, Bulgaria, 5?7 August 2013, pages 81?88.Ryan McDonald.
2007.
A study of global inference al-gorithms in multi-document summarization.
In Pro-ceedings of the European Conference on InformationRetrieval, Rome, Italy, 2-5 April 2007.Mohsen Mesgar and Michael Strube.
2015.
Graph-basedcoherence modeling for assessing readability.
In Pro-ceedings of STARSEM 2015: The Fourth Joint Confer-ence on Lexical and Computational Semantics, Den-ver, Col., 4?5 June 2015, pages 309?318.Rada Mihalcea and Paul Tarau.
2004.
TextRank: Bring-ing order into texts.
In Proceedings of the 2004 Con-ference on Empirical Methods in Natural LanguageProcessing, Barcelona, Spain, 25?26 July 2004, pages404?411.Saif Mohammad, Bonnie Dorr, Melissa Egan, AhmedHassan, Pradeep Muthukrishan, Vahed Qazvinian,Dragomir Radev, and David Zajic.
2009.
Using ci-tations to generate surveys of scientific paradigms.
InProceedings of Human Language Technologies 2009:The Conference of the North American Chapter of theAssociation for Computational Linguistics, Boulder,Col., 31 May ?
5 June 2009, pages 584?592.Hidetsugu Nanba and Manabu Okumura.
2000.
Pro-ducing more readable extracts by revising them.
InProceedings of the 18th International Conference onComputational Linguistics, Saarbru?cken, Germany, 31July ?
4 August 2000, pages 1071?1075.Mark E.J.
Newman.
2001.
Scientific collaboration net-works.
I.
Network construction and fundamental re-sults.
Physical Review E, 64(1):016131.Hitoshi Nishikawa, Takaaki Hasegawa, Yoshihiro Mat-suo, and Genichiro Kikui.
2010.
Opinion summariza-tion with integer linear programming formulation forsentence extraction and ordering.
In Proceedings ofthe 23rd International Conference on ComputationalLinguistics, Beijing, China, 23?27 August 2010, pages910?918.Daraksha Parveen and Michael Strube.
2015.
Integratingimportance, non-redundancy and coherence in graph-based extractive summarization.
In Proceedings of the24th International Joint Conference on Artificial In-telligence, Buenos Aires, Argentina, 25?31 July 2015,pages 1298?1304.Daraksha Parveen, Hans-Martin Ramsl, and MichaelStrube.
2015.
Topical coherence for graph-based ex-tractive summarization.
In Proceedings of the 2015Conference on Empirical Methods in Natural Lan-guage Processing, Lisbon, Portugal, 17?21 September2015, pages 1949?1954.Vahed Qazvinian and Dragomir R. Radev.
2008.
Scien-tific paper summarization using citation summary net-works.
In Proceedings of the 22nd International Con-ference on Computational Linguistics, Manchester,U.K., 18?22 August 2008, pages 689?696.Dragomir Radev, Timothy Allison, Sasha Blair-Goldensohn, John Blitzer, Arda Celibi, StankoDimitrov, Elliott Drabek, Ali Hakim, Wai Lam, DanyuLiu, Jahna Otterbacher, Hong Qi, Horacio Saggion,Simone Teufel, Michael Topper, Adam Winkel, andZhu Zhang.
2004.
MEAD ?
a platform for multidocu-ment multilingual text summarization.
In Proceedingsof the 4th International Conference on LanguageResources and Evaluation, Lisbon, Portugal, 26?28May 2004.Advaith Siddharthan and Simone Teufel.
2007.
Whoseidea was this, and why does it matter?
Attributing sci-entific work to citations.
In Proceedings of HumanLanguage Technologies 2007: The Conference of theNorth American Chapter of the Association for Com-putational Linguistics, Rochester, N.Y., 22?27 April2007, pages 316?223.Sidney Siegel and N. John Castellan.
1988.
Non-parametric Statistics for the Behavioral Sciences.McGraw-Hill, New York, 2nd edition.Simone Teufel and Marc Moens.
2002.
Summariz-ing scientific articles: Experiments with relevanceand rhetorical status.
Computational Linguistics,28(4):409?445.782Xiaojun Wan and Jianguo Xiao.
2010.
Exploiting neigh-borhood knowledge for single document summariza-tion and keyphrase extraction.
ACM Transactions onInformation Systems, 28(2):8 pages.Xiaojun Wan.
2010.
Towards a unified approachto simultaneous single-document and multi-documentsummarizations.
In Proceedings of the 23rd Interna-tional Conference on Computational Linguistics, Bei-jing, China, 23?27 August 2010, pages 1137?1145.Kristian Woodsend and Mirella Lapata.
2010.
Automaticgeneration of story highlights.
In Proceedings of the48th Annual Meeting of the Association for Computa-tional Linguistics, Uppsala, Sweden, 11?16 July 2010,pages 565?574.Xifeng Yan and Jiawei Han.
2002. gSpan: Graph-basedsubstructure pattern mining.
In Proceedings of theInternational Conference on Data Mining, MaebashiCity, Japan, 9?12 December 2002, pages 721?724.783
