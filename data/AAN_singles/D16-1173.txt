Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1670?1679,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsDeep Neural Networks with Massive Learned KnowledgeZhiting Hu, Zichao Yang, Ruslan Salakhutdinov, Eric P. XingSchool of Computer ScienceCarnegie Mellon University{zhitingh,zichaoy,rsalakhu,epxing}@cs.cmu.eduAbstractRegulating deep neural networks (DNNs) withhuman structured knowledge has shown to beof great benefit for improved accuracy and in-terpretability.
We develop a general frame-work that enables learning knowledge and itsconfidence jointly with the DNNs, so that thevast amount of fuzzy knowledge can be incor-porated and automatically optimized with lit-tle manual efforts.
We apply the frameworkto sentence sentiment analysis, augmenting aDNN with massive linguistic constraints ondiscourse and polarity structures.
Our modelsubstantially enhances the performance usingless training data, and shows improved inter-pretability.
The principled framework can alsobe applied to posterior regularization for regu-lating other statistical models.1 IntroductionDeep neural networks (DNNs) have achieved re-markable success in a large variety of applicationdomains (Krizhevsky et al, 2012; Hinton et al,2012; Bahdanau et al, 2014).
However, the power-ful end-to-end learning comes with limitations, in-cluding the requirement on massive amount of la-beled data, uninterpretability of prediction results,and difficulty of incorporating human intentions anddomain knowledge.To alleviate these drawbacks, recent work has fo-cused on training DNNs with extra domain-specificfeatures (Collobert et al, 2011), combining ora-cle similarity constraints (Karaletsos et al, 2016),modeling output correlations (Deng et al, 2014),and others.
Recently, Hu et al (2016) proposed ageneral distillation framework that transfers knowl-edge expressed as first-order logic (FOL) rules intoneural networks, where FOL constraints are inte-grated via posterior regularization (Ganchev et al,2010).
Despite the intuitiveness of FOL rules andthe impressive performance in various tasks, theapproach, as with the previous posterior constraintmethods (Ganchev et al, 2010; Liang et al, 2009;Zhu et al, 2014), has been limited to simple a pri-ori fixed constraints with manually selected weights,lacking the ability of inducing and adapting abstractknowledge from data.
This issue is further exacer-bated in the context of regulating DNNs that mapraw data directly into the label space, leaving a hugesemantic gap in between, and making it unfeasibleto express rich human knowledge built on the inter-mediate abstract concepts.In this paper, we introduce a generalized frame-work which enables a learning procedure for knowl-edge representations and their weights jointly withthe regulated DNN models.
This greatly extends theapplicability to massive structures in diverse forms,such as structured models and soft logic rules, fa-cilitating practitioners to incorporate rich domainexpertise and fuzzy constraints.
Specifically, wepropose a mutual distillation method that iterativelytransfers information between DNN and structuredknowledge, resulting in effective integration of therepresentation learning capacity of DNN and thegeneralization power of structured knowledge.
Ourmethod does not require additional supervision be-yond raw data-labels for knowledge learning.We present an instantiation of our method inthe task of sentence sentiment analysis.
We aug-1670ment a base convolutional network with linguis-tic knowledge that encourages coherent sentimenttransitions across the clauses in terms of discourserelations.
All uncertain modules, such as clauserelation and polarity identification, are automati-cally learned from data, freeing practitioners fromexhaustive specification.
We further improve themodel by integrating thousands of soft word polar-ity and negation rules, with their confidence directlyinduced from the data.Trained with only sentence level supervisions, ourmodel substantially outperforms plain neural net-works learned from both sentence and clause labels.Our method also shows enhanced generalization onlimited data size, and improved interpretability ofpredictions.Our work enjoys general versatility on diversetypes of structured knowledge and neural architec-tures.
The principled knowledge and weight learn-ing approach can also be applied to the posteriorconstraint frameworks (Ganchev et al, 2010; Lianget al, 2009) for regulating other statistical models.2 Related WorkDeep Networks with Structured KnowledgeCombining the powerful deep neural models withstructured knowledge has been of increasing interestto enhance generalization and improve interpretabil-ity (Li et al, 2015; Deng et al, 2014; Johnson et al,2016).
Recently, Hu et al (2016) proposed to trans-fer logical knowledge information into neural net-works with diverse architectures (e.g., convolutionalnetworks and recurrent networks).
They devel-oped an iterative distillation framework that trainsthe neural network to emulate the predictions of a?teacher?
model which is iteratively constructed byimposing posterior constraints on the network.
Theframework has shown to be effective in regulatingdifferent neural models.
However, the method hasrequired fixed constraints and manually specifiedweights, making it unsuitable to incorporate largeamount of fuzzy human intuitions where adaptationto data is necessary to obtain meaningful knowledgerepresentations.The limitation is in fact shared with the general-purpose posterior regularization methods (Ganchevet al, 2010; Liang et al, 2009; Zhu et al, 2014).Though attempts have been made to learn the con-straint weights from additional supervisions (Mei etal., 2014) or for tractability purposes (Steinhardt andLiang, 2015), learning and optimizing knowledgeexpressions jointly with the regulated models fromdata is still unsolved, and critically restricting theapplication scope.Sentiment Analysis Sentence level sentimentclassification is to identify the sentiment polarity(e.g., positive or negative) of a sentence (Pang andLee, 2008).
Recently, a number of neural modelshave been developed and achieved new levels of per-formance (Kim, 2014; Socher et al, 2013; Lei etal., 2015).
Despite the impressive success, most ofthe existing neural network approaches require largeamount of labeled data while encoding very lim-ited linguistic knowledge, making them inefficientto handle sophisticated linguistic phenomena, suchas contrastive transitions and negations (Choi andCardie, 2008; Bhatia et al, 2015).Hu et al (2016) combines a neural network witha logic rule that captures contrastive sense by ob-serving the word ?but?
in a sentence.
However, suchsimple deterministic rules suffer from limited gener-ality and robustness.
This paper develops a new sen-timent neural model that combines a large diverseset of linguistic knowledge through our enhancedframework.
Our method efficiently captures com-plex linguistic patterns from limited data, and yieldshighly interpretable predictions.3 Mutual DistillationThis section introduces the proposed framework thatenables joint learning of knowledge components andtheir weights with the neural network models.
Inparticular, we generalize the one-sided distillationmethod of (Hu et al, 2016) (section 3.1), and pro-pose to mutually transfer information between theneural network and the structured constraints for ef-fective knowledge learning (section 3.2), and opti-mize the weights by considering jointly all compo-nents (section 3.3).We consider input variable x ?
X and targetvariable y ?
Y .
For clarity we focus on classifi-cation where y is a one-hot encoding of the classlabels, though our method also applies to other con-texts.
Let (X,Y ) denote a set of instances of (x,y).1671A neural network defines a conditional probabilityp?
(y|x) parameterized by ?.
We will omit the sub-script ?
when there is no ambiguity.3.1 Network Learning with KnowledgeDistillationWe first review the iterative distillation method(Hu et al, 2016) that transfers structured knowledgeinto neural networks.
Consider constraint functionsfl ?
X ?
Y ?
R, indexed by l, that encode theknowledge and we want to satisfy (i.e., maximizeby optimizing the predictions y) with confidenceweights ?l ?
R. Given the current state of the neuralnetwork parameters ?
at each iteration, a structure-enriched teacher network q is obtained by solvingminq?PKL(q(Y )?p?
(Y |X))?
C?l?lEq[fl(X,Y )], (1)where P denotes the appropriate distribution space;and C is the regularization parameter.
Problem (1)is convex and has a closed-form solutionq?
(Y ) ?
p?
(Y |X) exp{C?l?lfl(X,Y )}, (2)whose normalization term can be calculated ef-ficiently according to how the constraints factor-ize (Hu et al, 2016).
The neural network p?
at it-eration t is then updated with a distillation objec-tive (Hinton et al, 2015) that balances between im-itating soft predictions of teacher q and predictingtrue hard labels:?
(t+1) = arg min???1NN?n=1(1?
pi)`(yn,??
(xn))+ pi`(s(t)n ,??
(xn)),(3)where ` denotes the loss function (e.g., cross en-tropy loss for classification); ??
(x) is the softmaxoutput of p?
on x; s(t)n is the soft prediction vec-tor of q on training point xn at iteration t; N isthe training size; and pi is the imitation parametercalibrating the relative importance of the two objec-tives.
The training procedure iterates between Eq.
(2)and Eq.
(3), resulting in the richly structured teachermodel q and the knowledge distilled student networkp.
While q generally provides better accuracy, p ismore lightweight and applicable to many differentcontexts (Hu et al, 2016; Liang et al, 2008).In (Hu et al, 2016), the constraint fl(X,Y ) hasbeen limited to be of the form rl(X,Y )?
1, whererl is an FOL function yielding truth values in [0, 1],and is required to be fully-specified a priori andfixed throughout the training.
Besides, the constraintweight ?l has to be manually selected.
This severelydeviates from the characters of human knowledgewhich is usually abstract, fuzzy, built on high-levelconcepts (e.g., discourse relations, visual attributes)as opposed to low-level observations (e.g., wordsequences, image pixels), and thus incomplete inthe sense of end-to-end learning that maps raw in-put directly into target space of interest.
This ne-cessitates expressing structured knowledge allowingsome modules unknown and induced automaticallyfrom observations.3.2 Knowledge LearningTo substantially extend the scope of knowledge usedin the framework, we introduce learnable modules?
in the knowledge expression denoted as f?.
Themodule ?
is general, and can be, e.g., free parame-ters of structured metrics, or dependency structuresover semantic units.
We assume f?
can be optimizedin terms of ?
against a given objective (e.g., throughgradient descent for parameter updating).
We aim tolearn the knowledge by determining ?
from data.For clarity we consider one knowledge constraintand omit the index l. We further assume the con-straint factorizes over data instances.
Note thatour method can straightforwardly be applied to thecase of multiple constraints and constraints span-ning multiple instances.
As any meaningful knowl-edge is expected to be consistent with the ob-servations, a straightforward way is then to di-rectly optimize against the training data: ??
=arg max?
1N?n f?
(xn,yn), and insert the result-ing f??
in Eq.
(1) for subsequent steps.
However,such a pipelined method fails to establish interac-tions between the knowledge and network learning,and can lead to a sub-optimal system, as shown inour experiments.To address this, we inspect the posterior regular-ization objective in Eq.
(1), and write it in an anal-ogous form to the variational free energy of somemodel evidence.
Specifically, let log h?
(X,Y ) ,C?f?
(X,Y ), then the objective can be written as?
?Yq(Y ) log p(Y |X)h?
(X,Y )q(Y ) .
(4)1672Intuitively, we can view the output distribution of theneural network p(Y |X) as a prior distribution overthe labels, while considering h?
(X,Y ) as defininga ?likelihood?
metric w.r.t the observations, makingthe objective analogous to a (negative) variationallower bound of the respective ?model?.
This natu-rally inspires an EM-type algorithm (Neal and Hin-ton, 1998) to optimize relevant parameters and im-prove the ?evidence?
: the E-step optimizes over q,yielding Eq.
(2); and the M-step optimizes over ?.Further incorporating the true training labels withbalancing parameter pi?, we obtain the update for ?:?
(t+1) = arg max???1NN?n=1(1?
pi?)h?
(xn,yn)+ pi?Eq(t)(y)[h?
(xn,y)](5)The update rule resembles the distillation objectivefor learning parameters ?
in Eq.(3).
Indeed, the ex-pectation term in Eq.
(5) in effect optimizes h?
onexamples labeled by q(y), i.e., forcing the knowl-edge function to mimic the predictions of the teachermodel and distill encoded information.
Thus, be-sides transferring from structured knowledge to aneural model by Eq.
(3), we now further bridge fromthe neural network to the knowledge constraints forjoint learning and better integrating the best of bothworlds.
We call our framework with the symmet-ric objectives as mutual distillation.
In fact, we canview Eq.
(4) as a single joint objective and we arealternating optimization of ?
and ?, resulting in theupdate rules in Eq.
(3) and Eq.
(5) with the supervisedloss terms included, respectively (and with the lossfunction in Eq.
(3) being cross-entropy loss).Additionally, the resemblance of the two objec-tives indicates that we can readily translate the suc-cessful neural learning method to knowledge learn-ing.
For instance, the expectation term in Eq.
(5),as the second loss term in Eq.
(3), can be evaluatedon rich unlabeled data in addition to labeled exam-ples, enabling semi-supervised learning which hasshown to be useful (Hu et al, 2016).
Empirical stud-ies show superiority of the proposed method overseveral potential alternatives (section 5).3.3 Weight LearningBesides optimizing the knowledge representations,we also aim to automate the selection of constraintweights by learning from data.
This would enableus to incorporate massive amount of noisy knowl-edge, without the need to worry about the confidencewhich is usually unfeasible to set manually.As the constraint weights serve to balance be-tween the different components of the whole frame-work, we learn the weights by optimizing the regu-larized joint model q (see Eq.(2)):?
(t+1) = arg max??01NN?n=1q?
(yn) (6)This is also validated in the view of regularizedBayes (Zhu et al, 2014) where q is a generalizedposterior function by regularizing the standard pos-terior p (see Eq.(1)).
Although here, we omit theBayesian treatment of the weights ?
and insteadoptimize them directly to find the posterior.
It isstraightforward to impose priors over ?
to encodepreferences.
In practice, Eq.
(6) can be carried outthrough gradient descent.The training procedure of the proposed mutualdistillation is summarized in Algorithm 1.Algorithm 1 Mutual DistillationInput: Training data D = {(xn,yn)}Nn=1,Initial knowledge constraints F = {f?,l}Ll=1,Initial neural network p?,Parameters: pi, pi?
?
imitation parametersC ?
regularization parameters1: Initialize neural network parameters ?2: Initialize knowledge parameters ?
and weights ?3: while not converged do4: Sample a minibatch (X,Y ) ?
D5: Build the teacher model q with Eq.
(2) and Eq.
(6)6: Update p?
with distillation objective Eq.
(3)7: Update fl (l = 1, .
.
.
, L) with distillation objec-tive Eq.
(5)8: end whileOutput: Learned network p, knowledge modulesF , andthe joint teacher network q4 Sentiment ClassificationThis section provides a concrete instance of ourgeneral framework in the task of sentence sentimentanalysis.
We augment a base convolutional networkwith a large diverse set of linguistic knowledge, in-cluding 1) sentiment transition structure for coher-ent multi-level prediction, 2) conjunction word rules1673convolutional networkdiscourse relation &sentimenttransitiontransition matrixes discourse relationclause sentimentstudentmodel () predictionteachermodel () predictionshared conv paramsdistillationdistillationFigure 1: Our sentiment classification model.
The left part is the base convolutional network over sentences, and the right part is theknowledge component over clauses.
Blue arrows denote neural feed-forwards; red arrows denote knowledge incorporation steps;and the orange dashed arrows denote the distillation processes.
The convolutional parameters are shared across all the networks.for improving discourse relation identification, and3) word polarity rules for tackling negations.
Theseknowledge structures are fulfilled with neural net-work modules that are learned jointly within ourframework.
The resulting model efficiently capturessophisticated linguistic patterns from limited data,and produces interpretable predictions.Figure 1 shows an overview of our model.
Weassume binary sentiment labels (i.e., positive-1 andnegative-0).
The left part of the figure is the baseneural network for sentence classification.
Since ourframework is agnostic to the neural architecture, wecan use any off-the-shelf neural models such as con-volutional network and recurrent network.
Here wechoose the simple yet effective convolutional net-work proposed in (Kim, 2014).
The network takesas input the word embedding vectors of a given sen-tence, and extracts feature maps with a convolutionallayer followed by max-over-time pooling.
A finalfully-connected layer with softmax activation trans-forms the extracted features into a prediction vector.We next introduce the three types of domainknowledge, which leverage rich fine-grained levelstructures, from clauses to words, to guide sentencelevel prediction.
The clause segmentation of sen-tences is obtained using the public Stanford parser 1.Sentiment transition by discourse relation Dis-course structures characterize how the clauses (i.e.,1http://nlp.stanford.edu/software/openie.htmldiscourse units) of a sentence are connected witheach other and thereby provide clues for coher-ent sentence and clause labeling.
Instead of us-ing standard general-purpose discourse relation sys-tem, we define three types of relations between ad-jacent clauses (denoted as ci and ci+1) specific tosentiment change, namely, consistent (ci and ci+1have the same polarity), contrastive (ci+1 opposesci and is the main part), and concessive (ci+1 op-poses ci and is secondary).
The relations also indi-cate the connections between clauses and the wholesentence.
For instance, a contrastive relation typi-cally indicates ci+1 has the same polarity with thefull sentence (we reasonably assume a sentence hascontrastive sense in at most one position).
To en-code these dependencies we define sentiment tran-sition matrices conditioned on discourse relation rand sentence polarity y, denoted as Mr,y.
For in-stance, given r = contrastive and y = 0, we expectthe sentiment change between two adjacent clausesto followMr=contrastive,y=0 =[0 01 0], (7)i.e., transiting from positive polarity of ci to negativeof ci+1.
We list all transition matrices in supplement.We now design a constraint on sentence predic-tions leveraging the above knowledge.
Using theidentification modules presented shortly, we first getthe discourse relation probabilities pri,i+1 as well as1674the sentiment polarity probabilities pci and pci+1 ofadjacent clauses (ci, ci+1).
For a given sentence la-bel ys, we then compute the expected transition ma-trix at each position by M?i,ys = Epri,i+1 [Mr,ys ].
Thevalue of the constraint function on y = ys is thendefined as the probability of the most likely clausepolarity configuration according to the clause pre-dictions pc?
and the averaged transitions M?
?,ys :fst(x, ys) = maxa?
{0,1}m?ipri,ai ?
M?i,ys,aiai+1 , (8)where a is the polarity configuration and m is thenumber of clauses.
We use the Viterbi algorithm forefficient computation.We need the clause relation and polarity proba-bilities pr and pc, which are unfeasible to identifyfrom raw text with only simple deterministic rules.We apply a convolutional network for each module,with similar network architectures to the base net-work (we describe details in the supplement).
For ef-ficiency, we tie the convolutional parameters acrossall the networks, while leaving the parameters of thefully-connected layers to be learned individually.Conjunction word rules We enhance the dis-course relation neural network with robust cluesfrom explicit discourse connectives (e.g., ?but?,?and?, etc.)
that occur in the sentence.
In particular,we collect a set of conjunction words (listed in thesupplement) and specify a rule constraint for each ofthem.
For instance, the conjunction ?and?
results inthe following constraint function:f rel(ci, ci+1, r) = (1and(ci, ci+1)?
r = consistent) ,where 1and(ci, ci+1) is an indicator function thattakes 1 if the two clauses are connected by ?and?,and 0 otherwise.
Note that these rules are soft, withthe confidence weights learned from data.
We usethe regularized joint model over the base discoursenetwork for predicting the relations.Negation and word polarity rules Negations re-verse the polarity of relevant statements.
Identifyingnegation sense has been a challenging problem foraccurate sentiment prediction.
We address this byincorporating rich lexicon rules at the clause level.That is, if a polarity-carrying word (e.g., ?good?
)occurs in the scope of a negator (e.g., ?not?
), thenthe sentiment prediction of the clause is encouragedto be the opposite polarity.
We specify one separaterule for each polarity-carrying word from public lex-icons (see the supplement), e.g.,f lex(ci, yc) =(1good(ci)?
yc = negative), (9)where 1good(ci) is an indicator function that takes1 if word ?good?
occurs in a negation scope in theclause text, and 0 otherwise.
This results in over3,000 rules, and our automated weight optimizationfrees us from manually selecting the weights ex-haustively.
We define the negation scope to be the 4words following a negator (Choi and Cardie, 2008).Though polarities of single words can be brit-tle features for determining the sentiment of a longstatement due to complex semantic compositions,they are more robust and effective at the level ofclauses which are generally short and simple.
More-over, inaccurate rules will be downplayed throughthe weight learning procedure.We have presented our neural sentiment model.We tackle several long-standing challenges by di-rectly incorporating linguistic knowledge.
Compar-ing to previous work that designs various neural ar-chitectures and relies on substantial annotations forspecific issues (Socher et al, 2013; Bhatia et al,2015), our knowledge framework is more straight-forward, interpretable, and general, while still pre-serving the power of neural methods.Notably, even with several additional compo-nents to be learned for knowledge representation,our method does not require extra supervision sig-nals beyond the raw sentence-labels, making ourframework generally applicable to many differenttasks (Neelakantan et al, 2016).The sentiment transition knowledge is expressedin the form of structured model with features ex-tracted using neural networks.
Though apparentlysimilar to recent deep structured models such asneural-CRFs (Durrett and Klein, 2015; Ammar etal., 2014; Do et al, 2010), ours is different sincewe parsimoniously extract features that are neces-sary for precise and efficient knowledge expression,as opposed to neural-CRFs that learn as rich repre-sentations as possible for final prediction.5 ExperimentsWe evaluate our method on the widely-used sen-timent classification benchmarks.
Our knowledge1675Model Accuracy (%)sentences1 CNN (Kim, 2014) 86.62 CNN+REL q: 87.8; p: 87.13 CNN+REL+LEX q: 88.0; p: 87.2sentences 4 MC-CNN (Kim, 2014) 86.85 Tensor-CNN (Lei et al, 2015) 87.06 CNN+But-q (Hu et al, 2016) 87.1+phrases7 CNN (Kim, 2014) 87.28 Tree-LSTM (Tai et al, 2015) 88.09 MC-CNN (Kim, 2014) 88.110 CNN+But-q (Hu et al, 2016) 89.211 MVCNN (Yin and Schutze, 2015) 89.4Table 1: Classification performance on SST2.
The top andsecond blocks use only sentence-level annotations for training,while the bottom block uses both sentence- and phrases-levelannotations.
We report the accuracy of both the regularizedteacher model q and the student model p after distillation.enriched model significantly outperforms plain neu-ral networks.
We obtain even higher improvementswith limited data sizes.
Comparison with extensiveother potential knowledge learning methods showsthe effectiveness of our framework.
Our model alsoshows improved interpretability.5.1 SetupDatasets Two classification benchmarks are used:1) Stanford Sentiment Treebank-2 (SST2) (Socheret al, 2013) is a binary classification dataset thatconsists of 6920/872/1821 moview review sentencesin the train/dev/test sets, respectively.
Besidessentence-level annotations, the dataset alo providesexhaustive gold-standard labels at fine-grained lev-els, from clauses to phrases.
The resulting full train-ing set includes 76,961 labeled instances.
We trainour model using only the sentence-level annotations,and compare to baselines learned from either train-ing set.
2) Customer Reviews (CR) (Hu and Liu,2004) consists of 3,775 product reviews with pos-itive and negative polarities.
Following previouswork we use 10-fold cross-validation.Model configurations We evaluate two variantsof our model: CNN+REL leverages the knowledgeof sentiment transition and discourse conjunctions,and CNN+REL+LEX additionally incorporates thenegation lexicon rules.Throughout the experiments we set the regulariza-tion parameter to C = 10.
The imitation parameterspi and pi?
decay as pi(t) = pi?
(t) = 0.9t where t istraining size10% 30% 50% 100%accu(%)8082848688  CNN+REL+LEX-qCNNFigure 2: Performance with varying sizes of training examples.the iteration number (Bengio et al, 2015; Hu et al,2016).
For the base neural network, we choose the?non-static?
version from (Kim, 2014) and use thesame configurations.5.2 Classification ResultsTable 1 shows the classification performance on theSST2 dataset.
From rows 1-3 we see that our pro-posed sentiment model that integrates the diverseset of knowledge (section 4) significantly outper-forms the base CNN (Kim, 2014).
The improve-ment of the student network p validates the effec-tiveness of the iterative mutual distillation process.Consistent with the observations in (Hu et al, 2016),the regularized teacher model q provides further per-formance boost, though it imposes additional com-putational overhead for explicit knowledge repre-sentations.
Note that our models are trained withonly sentence-level annotations.
Compared with thebaselines trained in the same setting (rows 4-6), ourmodel with the full knowledge, CNN+REL+LEX,performs the best.
CNN+But-q (row 6) is the baseCNN augmented with a logic rule that identifies con-trastive sense through explicit occurrence of word?but?
(section 3.1) (Hu et al, 2016).
Our enhancedframework enables richer knowledge and achievesmuch better performance.Our method further outperforms the base CNNthat is additionally trained with dense phrase-levelannotations (row 7), showing improved generaliza-tion of the knowledge-enhanced model from limiteddata.
Figure 2 further studies the performance withvarying training sizes.
We can clearly observe thatthe incorporated knowledge tends to offer higher im-provement with less training data.
This property canbe particularly desirable in applications of structuredpredictions where manual annotations are expensivewhile rich human knowledge is available.1676Model Accuracy (%)1 CNN (Kim, 2014) 84.1?0.22 CNN+REL q: 85.0?0.2; p: 84.7?0.23 CNN+REL+LEX q: 85.3?0.3; p: 85.0?0.24 MC-CNN (Kim, 2014) 85.05 Bi-RNN (Lai et al, 2015) 82.66 CRF-PR(Yang and Cardie, 2014) 82.77 AdaSent (Zhao et al, 2015) 86.3Table 2: Classification performance on the CR dataset.
Wereport the average accuracy?one standard deviation with 10-fold CV.
The top block compares the base CNN (row 1) withthe knowledge-enhanced CNNs by our framework.Table 2 shows model performance on the CRdataset.
Our model again surpasses the base net-work and several other competitive neural methodsby a large margin.
Though falling behind AdaSent(row 7) which has a more specialized and complexarchitecture than standard convolutional networks,the proposed framework indeed is general enoughto apply on top of it for further enhancement.To further evaluate the proposed mutual distilla-tion framework for learning knowledge, we compareto an extensive set of other possible knowledge op-timization approaches.
Table 3 shows the results.In row 2, the ?opt-joint?
method optimizes the reg-ularized joint model of Eq.
(2) directly in terms ofboth the neural network and knowledge parameters.Row 3, ?opt-knwl-pipeline?, is an approach that firstoptimizes the standalone knowledge component andthen inserts it into the previous framework of (Hu etal., 2016) as a fixed constraint.
Without interactionbetween the knowledge and neural network learn-ing, the pipelined method yields inferior results.
Fi-nally, rows 4-5 display a method that adapts theknowledge component at each iteration by optimiz-ing the joint model q in terms of the knowledge pa-rameters.
We report the accuracy of both the studentnetwork p (row 4) and the joint teacher network q(row 5), and compare with our method in row 6 and7, respectively.
We can see that both models per-forms poorly, achieving the accuracy of only 68.6%for the knowledge component, similar to the accu-racy achieved by the ?opt-joint?
method.In contrast, our mutual distillation framework of-fers the best performance.
Table 3 shows thatthe knowledge component as a standalone classi-fier does not achieve high accuracy (the numbers inModel Accuracy (%)1 CNN (Kim, 2014) 86.62 opt-joint 86.9 (68.8)3 opt-knwl-pipeline 86.7 (70.4)4 opt-joint-iterative-p 86.95 opt-joint-iterative-q 87.6 (68.6)6 mutual-p 87.27 mutual-q 88.0 (72.5)Table 3: Comparisons between our mutual distillation (rows4-5) and other knowledge optimization methods, on SST2.
Seethe text for details.
The numbers in parentheses are the accuracyof the learned knowledge component (Figure 1, right part) if wetake it as a standalone classifier.
All knowledge is used.it'sallverycute,thoughnotterriblyfunnyifyou're?0.40.60.80.2concessive:0.9Figure 3: An example sentence and the results of the learnedknowledge modules applied on it.
Red denotes positive, andblue denotes negative.
The snippet ?not ... funny?
triggers thenegation rule.enough, good, strong,engaging, greatawful, loses, fakedoubt, badTable 4: The top 5 positive (left) and negative (right) wordswith the largest weights of the negation rules.parentheses).
As discussed in section 4, this is be-cause of the parsimonious formulation for the pre-cise knowledge expression, while leaving the ex-pressive base NN to extract rich representations.
Theenhanced performance of the combination indicatescomplementary effects of the two parts.5.3 Qualitative AnalysisOur model not only provides better classificationperformance, but also shows improved interpretabil-ity due to the learned structured knowledge repre-sentation.
Figure 3 illustrates an example sentencefrom test set.
We see that the clause sentiments aswell as the discourse relation are correctly captured.The negation rule of ?not ... funny?
(Eq.
(9)) alsohelps to identify the right polarity.Table 4 lists the top-5 positive and negative wordsthat are most confident for the negation rules, pro-viding insights into the linguistic norms in the moviereview context.16776 ConclusionIn this paper we have developed a framework thatlearns structured knowledge and its weights for reg-ulating deep neural networks through mutual distil-lation.
We instantiated our framework for the senti-ment classification task.
Using massive learned lin-guistic knowledge, our neural model provides sub-stantial improvements over many of the existing ap-proaches, especially in the limited data setting.
Inthe future work, we plan to apply our framework toother text and vision applications.AcknowledgmentsWe thank the anonymous reviewers for their valu-able comments.
This work is supported by NSFIIS1218282, NSF IIS1447676, Air Force FA8721-05-C-0003.ReferencesWaleed Ammar, Chris Dyer, and Noah A Smith.
2014.Conditional random field autoencoders for unsuper-vised structured prediction.
In Proc.
of NIPS, pages3311?3319.Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-gio.
2014.
Neural machine translation by jointlylearning to align and translate.
arXiv preprintarXiv:1409.0473.Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and NoamShazeer.
2015.
Scheduled sampling for sequence pre-diction with recurrent neural networks.
In Proc.
ofNIPS, pages 1171?1179.Parminder Bhatia, Yangfeng Ji, and Jacob Eisenstein.2015.
Better document-level sentiment analysis fromrst discourse parsing.
In Proc.
of EMNLP.Yejin Choi and Claire Cardie.
2008.
Learning with com-positional semantics as structural inference for subsen-tential sentiment analysis.
In Proc.
of EMNLP, pages793?801.
Association for Computational Linguistics.Ronan Collobert, Jason Weston, Le?on Bottou, MichaelKarlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011.Natural language processing (almost) from scratch.JMLR, 12:2493?2537.Jia Deng, Nan Ding, Yangqing Jia, Andrea Frome, KevinMurphy, Samy Bengio, Yuan Li, Hartmut Neven, andHartwig Adam.
2014.
Large-scale object classifica-tion using label relation graphs.
In ECCV 2014, pages48?64.
Springer.Trinh Do, Thierry Arti, et al 2010.
Neural conditionalrandom fields.
In Proc.
of AISTATS, pages 177?184.Greg Durrett and Dan Klein.
2015.
Neural CRF parsing.Kuzman Ganchev, Joao Grac?a, Jennifer Gillenwater, andBen Taskar.
2010.
Posterior regularization for struc-tured latent variable models.
JMLR, 11:2001?2049.Geoffrey Hinton, Li Deng, Dong Yu, George E Dahl,Abdel-rahman Mohamed, Navdeep Jaitly, Andrew Se-nior, Vincent Vanhoucke, Patrick Nguyen, Tara NSainath, et al 2012.
Deep neural networks for acous-tic modeling in speech recognition: The shared viewsof four research groups.
Signal Processing Magazine,IEEE, 29(6):82?97.Geoffrey Hinton, Oriol Vinyals, and Jeff Dean.
2015.Distilling the knowledge in a neural network.
arXivpreprint arXiv:1503.02531.Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In Proc.
of KDD, pages 168?177.
ACM.Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard Hovy,and Eric Xing.
2016.
Harnessing deep neural net-works with logic rules.
In Proc.
of ACL.Matthew J. Johnson, David K. Duvenaud, Alex B.Wiltschko, Sandeep R. Datta, and Ryan P. Adams.2016.
Composing graphical models with neural net-works for structured representations and fast inference.Arxiv preprint arXiv:1603.06277.Theofanis Karaletsos, Serge Belongie, Cornell Tech, andGunnar Ra?tsch.
2016.
Bayesian representation learn-ing with oracle constraints.
In Proc.
of ICLR.Yoon Kim.
2014.
Convolutional neural networks for sen-tence classification.
Proc.
of EMNLP.Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.2012.
Imagenet classification with deep convolutionalneural networks.
In Proc.
of NIPS, pages 1097?1105.Siwei Lai, Liheng Xu, Kang Liu, and Jun Zhao.
2015.Recurrent convolutional neural networks for text clas-sification.
In AAAI, pages 2267?2273.Tao Lei, Regina Barzilay, and Tommi Jaakkola.
2015.Molding cnns for text: non-linear, non-consecutiveconvolutions.
In Proc.
of EMNLP.Jiwei Li, Dan Jurafsky, and Eudard Hovy.
2015.
Whenare tree structures necessary for deep learning of rep-resentations?Percy Liang, Hal Daume?
III, and Dan Klein.
2008.Structure compilation: trading structure for features.In Proc.
of ICML, pages 592?599.
ACM.Percy Liang, Michael I Jordan, and Dan Klein.
2009.Learning from measurements in exponential families.In Proc.
of ICML, pages 641?648.
ACM.Shike Mei, Jun Zhu, and Jerry Zhu.
2014.
Robust Reg-Bayes: Selectively incorporating first-order logic do-main knowledge into Bayesian models.
In Proc.
ofICML, pages 253?261.1678Radford M Neal and Geoffrey E Hinton.
1998.
A viewof the em algorithm that justifies incremental, sparse,and other variants.
In Learning in graphical models,pages 355?368.
Springer.Arvind Neelakantan, Quoc V Le, and Ilya Sutskever.2016.
Neural programmer: Inducing latent programswith gradient descent.
In Proc.
of ICLR.Bo Pang and Lillian Lee.
2008.
Opinion mining andsentiment analysis.
Foundations and trends in infor-mation retrieval, 2(1-2):1?135.Richard Socher, Alex Perelygin, Jean Y Wu, JasonChuang, Christopher D Manning, Andrew Y Ng, andChristopher Potts.
2013.
Recursive deep models forsemantic compositionality over a sentiment treebank.In Proc.
of EMNLP, volume 1631, page 1642.
Citeseer.Jacob Steinhardt and Percy S Liang.
2015.
Learning withrelaxed supervision.
In Proc.
of NIPS, pages 2809?2817.Kai Sheng Tai, Richard Socher, and Christopher D Man-ning.
2015.
Improved semantic representations fromtree-structured long short-term memory networks.
InProc.
of ACL.Bishan Yang and Claire Cardie.
2014.
Context-awarelearning for sentence-level sentiment analysis withposterior regularization.
In Proc.
of ACL, pages 325?335.Wenpeng Yin and Hinrich Schutze.
2015.
Multichan-nel variable-size convolution for sentence classifica-tion.
Proc.
of CONLL.Han Zhao, Zhengdong Lu, and Pascal Poupart.
2015.Self-adaptive hierarchical sentence model.
arXivpreprint arXiv:1504.05070.Jun Zhu, Ning Chen, and Eric P Xing.
2014.
Bayesianinference with posterior regularization and applica-tions to infinite latent svms.
JMLR, 15(1):1799?1847.1679
