Reducing Lexical Semantic Complexity with Systematic PolysemousClasses and UnderspecificationPaul BuitelaarDFKI Language Technology LabStuhlsatzenhausweg 3,66123 Saarbrticken, Germanypaulb@dfki.deAbstractThis paper presents an algorithm for findingsystematic polysemous classes in WordNetand similar semantic databases, based on adefinition in (Apresjan 1973).
Theintroduction of systematic polysemousclasses can reduce the amount of lexicalsemantic processing, because the number ofdisambiguation decisions can be restrictedmore clearly to those cases that involve realambiguity (homonymy).
In manyapplications, for instance in documentcategorization, information retrieval, andinformation extraction, it may be sufficientto know if a given word belongs to a certainclass (underspecified sense) rather than toknow which of its (related) senses exactly topick.
The approach for finding systematicpolysemous classes is based on that of(Buitelaar 1998a, Buitelaar 1998b), whileaddressing some previous hortcomings.IntroductionThis paper presents an algorithm for findingsystematic polysemous classes in WordNet(Miller et al1990) and GermaNet (Hampand Feldweg 1997) -- a semantic databasefor German similar to WordNet.
Theintroduction of such classes can reduce theamount of lexical semantic processing,because the number of disambiguationdecisions can be restricted more clearly tothose cases that involve real ambiguity(homonymy).
Different than withhomonyms, systematically polysemouswords need not always be disambiguated,because such words have several relatedsenses that are shared in a systematic way bya group of similar words.
In manyapplications then, for instance in documentcategorization and other areas ofinformation retrieval, it may be sufficient oknow if a given word belongs to this grou prather than to know which of its (related)senses exactly to pick.
In other words, it willsuffice to assign a more coarse grained sensethat leaves several related sensesunderspecified, but which can be furtherspecified on demand 1.The approach for finding systematicpolysemous classes is based on that of(Buitelaar 1998a, Buitelaar 1998b), buttakes into account some shortcomings aspointed out in (Krymolowski and Roth1998) (Peters, Peters and Vossen 1998)(Tomuro 1998).
Whereas the originalapproach identified a small set of top-levelsynsets for grouping together lexical items,i As pointed out in (Wilks 99), earlier work in AI on'Polaroid Words' (Hirst 87) and 'Word Experts'(Small 81) advocated a similar, incremental approachto sense representation and interpretation.
In line withthis, the CoreLex approach discussed here provides alarge scale inventory of systematically polysemouslexical items with underspecified r presentations thatcan be incrementally refined.14the new approach compares lexical itemsaccording to all of their synsets on allhierarchy levels.
In addition, the newapproach is both more flexible and preciseby using a clustering algorithm forcomparing meaning distributions betweenlexical items.
Whereas the original approachtook into account only identical distributions(with additional human intervention tofurther group together sufficiently similarclasses), the clustering approach allows forcompletely automatic omparisons, relativeto certain thresholds, that identify partialoverlaps in meaning distributions.1 Acquisition and Application ofSystematic Polysemous ClassesIn lexical semantics, a distinction can bemade between senses that are of acontrastive and those that are of acomplementary nature (Weinreich 1964).Contrastive senses are unrelated to eachother as with the two meanings of "bank".However, such clear-cut (contrastive)meaning distinctions are rather the exceptionthan the rule.
Often, words have a number of(complementary) senses that are somehowrelated to each other in systematic ways(Pustejovsky 1995).
For instance, a wordlike "mouth" has several senses that are allsomehow related (after Cruse 1986):John opened his mouth.This parasite attaches itself to their mouths.The mouth of the cave resembles a bottle.The mouth of the river starts here.2 CoreLexRelated senses are, however, onlysystematic (or regular) if more than oneexample in a language can be found asformulated in (Apresjan 1973):Polysemy of the word A with the meanings aiand aj is called regular if in the givenlanguage, there exists at least one otherword B with the meanings bi bj, which aresemantically distinguished from each otherin exactly the same way as ai and aj and i f  aiand bi, aj and bj are nonsynonymous.With this definition, we can constructclasses of systematically polysemous wordsas shown in the CoreLex approach(Buitelaar 1998a) (Buitelaar 1998b).
Thismethod takes WordNet sense assignmentsand compares their distribution by reducingthem to a set of basic types.
For instance,WordNet assigns to the noun "book" thefollowing senses:1. publication2.
product, production3.
fact4.
dramatic_composition,dramatic_work5.
record6.
section, subdivision7.
journalAt the top of the WordNet hierarchy theseseven senses can be reduced to two basictypes: the content that is beingcommunicated and the medium ofcommunication.
We can arrive atsystematically polysemous classes byinvestigating which other words share thesesame senses and are thus polysemous in thesame way.
For instance, the seven differentsenses that WordNet assigns to "book" canbe reduced to two basic types: artifact andcommunication.
We do this for each nounand then group them into classes accordingto their combination of basic types.
Finally,by human introspection several classes weregrouped together, because their membersseemed sufficiently similar.Among the resulting classes are a number thatare to be expected given the literature onsystematic polysemy.
For instance, the classesanimal / food and plant / natural, product havebeen discussed widely.
Other classes are less15expected, but seem quite intuitive.
The classartifact / attribute / substance for instanceincludes a number of nouns ("chalk, charcoal,daub, fiber, fibre, tincture") that refer to anobject hat is at the same time an artifact madeof some substance and that is also an attribute.3 CoreLex-IIThereby following Apresjan's definition ofsystematic polysemy discussed above.3.2 The AlgorithmThe algorithm worksexample for nouns):as follows (for3.1 A More Flexible ApproachThe CoreLex database has been used and/orevaluated in a number of projects, leading tosome criticisms of the approach in(Krymolowski and Roth 1998) (Peters,Peters and Vossen 1998) (Tomuro 1998) andin personal communication.
Primarily it wasargued that the choice of basic types isarbitrary and on too high a level.
Systematicclass discovery in the original approach isdependent on this set of basic types, whichmeans that classes on lower levels are notcaptured at all.
Further criticism arose on thearbitrariness (and inefficiency) of humanintervention in grouping together esultingclasses into more comprehensive ones basedon the similarity of their members.In response to this, a new approach wasformulated and implemented that addressesboth these points.
Comparison of sensedistributions i now performed over synsetson all levels, not just over a small set on thetop levels.
In addition, similarity on sensedistribution between words need no longerbe complete (100%), as with the formerapproach.
Instead, a threshold on similaritycan be set that constraints a clusteringalgorithm for automatically groupingtogether words into systematic polysemousclasses.
(No human intervention to furthergroup together resulting classes is required.
)This approach took inspiration from thepioneering work by (Dolan 1994), but it isalso fundamentally different, becauseinstead of grouping similar senses together,the CoreLex approach groups togetherwords according to all of their senses.1.
foreach noun2.
get al levell synsets (senses)3. if number of level1 synsets > 1then put noun in list4.
foreaeh level1 synset5.
get al higher level synsets (hypernyms)6. foreaeh nouna in list7.
foreaeh noun2 in list8.
compute similarity nounx and nounz9.
if similarity > thresholdthen put nouns and nounz in matrix10.
foreaeh nounl in matrix11.
if noun1 not assigned to a clusterthen construct a new cluster Ci andassign noun1 to it12.
foreaeh noun2 similar to nounl13.
if nounz not assigned to a clusterthen assign nounz to new cluster CiFor every noun in the WordNet orGermaNet index, get al of its senses (whichare in fact level1 synsets).
If a noun has morethan one sense put it in a separate list thatwill be used for further processing.
Nounswith only one sense are not used in furtherprocessing because we are only interested insystematic distributions of more than onesense over several nouns.
In order tocompare nouns not only on the sense levelbut rather over the whole of the WordNethierarchy, also all higher level synsets(hypernyms) for each sense are stored.Then, for each noun we compare its "sensedistribution" (the complete set of synsetsderived in the previous steps) with eachother noun.
Similarity is computed using theJaccard score, which compares objects16according to the attributes they share andtheir unique attributes.
If the similarity isover a certain threshold, the noun pair isstored in a matrix which is consequentlyused in a final clustering step.Finally, the clustering itself is a simple,single link algorithm that groups togetherobjects uniquely in discrete clusters.3.3 Quantitative and QualitativeAnalysisDepending on the threshold on similarity,the algorithm generates a number of clustersof ambiguous words that share similar sensedistributions, and which can be seen assystematic polysemous classes.
In thefollowing table an overview is given ofresults with different hresholds.
Thenumber of nouns in WordNet that wereprocessed is 46.995, of which 10.772 havemore than one sense.Threshold Number of AmbiguosClusters Nouns in(Systematic ClustersPolysemous (SystematicClasse)s PolysemousNouns)0,70 1.793 4.3910,75 1.341 3.3360,80 1.002 2.5500,90 649 1.449A qualitative analysis of the clusters showsthat best results are obtained with athreshold of 0,75.
Some of the resultingclusters with this threshold are:?
ball/gamebaseball, basketball,handball, volleyballfootball,fish / foodalbacore, blowfish, bluefin, bluefish,bonito, bream, butterfish, crappie,croaker, dolphinfish, flatfish,flounder, grouper, halibut, lingcod,mackerel, mahimahi, mullet,muskellunge, pickerel, pompano,porgy, puffer, rockfish, sailfish, scup,striper, swordfish, tuna, tunny,weakfish?
plant/nutalmond, butternut, candlenut, cashew,chinquapin, chokecherry, cobnut,filbert, hazelnut, pistachio?
plant / berrybilberry, blueberry, checkerberry,cowberry, cranberry, currant, feijoa,gooseberry, huckleberry, juneberry,lingonberry, serviceberry, spiceberry;teaberry, whortleberry?
vessel \] measurebottle, bucket, cask, flask, jug, keg,pail, tub?
cord / fabricchenille, lace, laniard, lanyard,ripcord, whipcord, worsted?
taste_property/sensationacridity, aroma, odor, odour,pungency?
communication / noiseclamor, hiss, howl, roar, roaring,screaming, screech, screeching, shriek,sigh, splutter, sputter, whisper4 ApplicationSystematic polysemous classes that areobtained in this way can be used as filters onsense disambiguation in a variety ofapplications in which a coarse grained senseassignment will suffice in many cases, butwhere an option of further specificationexists.
For instance, in information retrieval17it will not always be necessary to distinguishbetween the two interpretations of "baseball,,,2 basketball, football .
.
.
.
.
Users looking forinformation on a baseball-game may beinterested also in baseball-balls.
On theother hand, a user may be interestedspecifically in buying a new baseball-balland does not wish to be flooded withirrelevant information on baseball-games.
Inthis case, the underspecified ball / gamesense needs to be further specified in the ballsense only.
Similarly, it will not always benecessary to distinguish exactly between thevessel interpretation f "bottle, bucket, cask,..." and the measure interpretation, orbetween the communication i terpretation fa "clamor, hiss, roar, ..." and the noiseinterpretation.Currently, a query expansion module basedon the approach described here is underdevelopment as part of the prototypesystems of two EU funded projects:MIETTA 3 (a cross-lingual search engine inthe tourism domain - Buitelaar et al1998)and OLIVE 4 (a cross-lingual video retrievalsystem).Also in shallow processing applications likesemantic pre-processing for documentcategorization it will be sufficient o use anunderspecified sense instead of needlessdisambiguation between senses that areroughly equal in their relevance to a certaindocument category.
Similarly, in shallowsyntactic processing tasks, like statisticaldisambiguation f PP-attachment, the use ofunderspecified senses may be preferable asshown in experiments by (Krymolowski andRoth 1998).2 Compare (SchUtze 1997) for a similar, but purelystatistical approach to underspecification i lexicalsemantic processing and its use in machine learningand information retrieval.3 http://www.mietta.net/mietta4 http:lltwentyone.tpd.tno.nllolivelIn order to train systems to accuratelyperform syntactic analysis on the basis ofsemantic classes, semantically annotatedcorpora are needed.
This is another area ofapplication of the research described here.CoreLex clusters can be considered byannotators as alternatives to WordNet orGermaNet synsets if they are not able tochoose between the senses given and insteadprefer an underspecified sense.
Thisapproach is currently tested, in cooperationwith the GermaNet group of the Universityof Ttibingen, in a preliminary project onsemantic annotation of German newspapertext.ConclusionWe presented a new algorithm forgenerating systematic polysemous classesfrom existing resources like WordNet andsimilar semantic databases.
Results werediscussed for classes of English nouns asgenerated from WordNet.
With a thresholdof 75% similarity between nouns, 1341classes could be found covering 3336 nouns.Not discussed were similar experiments forverbs and adjectives, both in English andGerman.
The resulting classes can be usedas filters on incremental sensedisambiguation i  various applications inwhich coarse grained (underspecified)senses are preferred, but from which morefine grained senses can be derived ondemand.ReferencesJ.
Apresjan (1973) Regular Polysemy.
Linguistics,142.Paul Buitelaar (1998a) CoreLex: SystematicPolysemy and Underspecification.
PhD Thesis,Brandeis University.Paul Buitelaar (1998b) CoreLex: An Ontology ofSystematic Polysemous Classes.
In: FormalOntology in Information Systems.
IOS Press,Amsterdam.18Paul Buitelaar, Klaus Netter and Feiyu Xu (1998)Integrating Different Strategies In Cross-LanguageInformation Retrieval in the MIETTA Project.
In:Proceedings of TWLT14, Enschede, theNetherlands, December.D.
A. Cruse (1986) Lexical Semantics.
CambridgeUniversity Press.Bill Dolan (1994) Word Sense Ambiguation:Clustering Related Senses.
In: Proceedings ofCOLING-94.
Kyoto, Japan.Birgit Hamp and Helmut Feldweg (1997) GermaNet-a Lexical Semantic Net for German.
In:Proceedings of the ACL Workshop on AutomaticInformation Extraction and Building of LexiealSemantic Resources for NLP Applications.Madrid,.G.
Hirst (1987) Semantic Interpretation and theResolution of Ambiguity.
Cambridge UniversityPress.Yuval Krymolowski and Dan Roth (1998)Incorporating Knowledge in Natural LanguageLearning: A Case Study.
In: Proceedings ACL-98Workshop on the Use of WordNet in NLP.G.
A. Miller and R. Beckwith and Ch.
Fellbaum andD.
Gross and K. Miller (1990) Introduction toWordNet: An On-line Lexical Database.International Journal of Lexicography, 3,4.Wim Peters, Ivonne Peters and Piek Vossen (1998)Automatic Sense Clustering in EuroWordNet.
In:Proceedings of LREC.
Granada.James Pustejovsky (1995) The Generative Lexicon.MIT Press.Hinrich SchiRze (1997) Ambiguity Resolution inLanguage Learning.
Volume 71 of CSLIPublications.
Chicago University Press.S.
Small (1981) Viewing Word Expert Parsing asLinguistic Theory.
In: Proceedings of IJCAI.Noriko Tomuro (1998) Semi-Automatic Induction ofSystematic Polysemy from WordNet.
In:Proceedings ACL-98 Workshop on the Use ofWordNet in NLP.Uriel Weinreich (1964) Webster's Third: A Critiqueof its Semantics.
International Journal of AmericanLinguistics, 405-409, 30.Yorick Wilks (1999) Is Word Sense Disambiguationjust one more NLP task?
Cs.CL/9902030.19
