Proceedings of the EACL 2012 Student Research Workshop, pages 11?21,Avignon, France, 26 April 2012. c?2012 Association for Computational LinguisticsCross-Lingual Genre ClassificationPhilipp PetrenzSchool of Informatics, University of Edinburgh10 Crichton Street, Edinburgh, EH8 9AB, UKp.petrenz@sms.ed.ac.ukAbstractClassifying text genres across languagescan bring the benefits of genre classifi-cation to the target language without thecosts of manual annotation.
This articleintroduces the first approach to this task,which exploits text features that can be con-sidered stable genre predictors across lan-guages.
My experiments show this methodto perform equally well or better thanfull text translation combined with mono-lingual classification, while requiring fewerresources.1 IntroductionAutomated text classification has become stan-dard practice with applications in fields such asinformation retrieval and natural language pro-cessing.
The most common basis for text clas-sification is by topic (Joachims, 1998; Sebas-tiani, 2002), but other classification criteria haveevolved, including sentiment (Pang et al 2002),authorship (de Vel et al 2001; Stamatatos et al2000a), and author personality (Oberlander andNowson, 2006), as well as categories relevant tofilter algorithms (e.g., spam or inappropriate con-tents for minors).Genre is another text characteristic, often de-scribed as orthogonal to topic.
It has been shownby Biber (1988) and others after him, that thegenre of a text affects its formal properties.
It istherefore possible to use cues (e.g., lexical, syn-tactic, structural) from a text as features to pre-dict its genre, which can then feed into informa-tion retrieval applications (Karlgren and Cutting,1994; Kessler et al 1997; Finn and Kushmer-ick, 2006; Freund et al 2006).
This is becauseusers may want documents that serve a particu-lar communicative purpose, as well as being ona particular topic.
For example, a web search onthe topic ?crocodiles?
may return an encyclopediaentry, a biological fact sheet, a news report aboutattacks in Australia, a blog post about a safari ex-perience, a fiction novel set in South Africa, ora poem about wildlife.
A user may reject manyof these, just because of their genre: Blog posts,poems, novels, or news reports may not containthe kind or quality of information she is seeking.Having classified indexed texts by genre would al-low additional selection criteria to reflect this.Genre classification can also benefit LanguageTechnology indirectly, where differences in thecues that correlate with genre may impact sys-tem performance.
For example, Petrenz andWebber (2011) found that within the New YorkTimes corpus (Sandhaus, 2008), the word ?states?has a higher likelihood of being a verb in let-ters (approx.
20%) than in editorials (approx.2%).
Part-of-Speech (PoS) taggers or statisticalmachine translation (MT) systems could benefitfrom knowing such genre-based domain varia-tion.
Kessler et al(1997) mention that parsingand word-sense disambiguation can also benefitfrom genre classification.
Webber (2009) foundthat different genres have a different distributionof discourse relations, and Goldstein et al(2007)showed that knowing the genre of a text can alsoimprove automated summarization algorithms, asgenre conventions dictate the location and struc-ture of important information within a document.All the above work has been done within asingle language.
Here I describe a new ap-proach to genre classification that is cross-lingual.Cross-lingual genre classification (CLGC) differs11from both poly-lingual and language-independentgenre classification.
CLGC entails training agenre classification model on a set of labeled textswritten in a source language LS and using thismodel to predict the genres of texts written in thetarget language LT 6= LS .
In poly-lingual classi-fication, the training set is made up of texts fromtwo or more languages S = {LS1 , .
.
.
, LSN } thatinclude the target language LT ?
S. Language-independent classification approaches are mono-lingual methods that can be applied to any lan-guage.
Unlike CLGC, both poly-lingual andlanguage-independent genre classification requirelabeled training data in the target language.Supervised text classification requires a largeamount of labeled data.
CLGC attempts to lever-age the available annotated data in well-resourcedlanguages like English in order to bring the afore-mentioned advantages to poorly-resourced lan-guages.
This reduces the need for manual annota-tion of text corpora in the target language.
Manualannotation is an expensive and time-consumingtask, which, where possible, should be avoidedor kept to a minimum.
Considering the difficul-ties researchers are encountering in compiling agenre reference corpus for even a single language(Sharoff et al 2010), it is clear that it would be in-feasible to attempt the same for thousands of otherlanguages.2 Prior workWork on automated genre classification was firstcarried out by Karlgren and Cutting (1994).
LikeKessler et al(1997) and Argamon et al(1998)after them, they exploit (partly) hand-crafted setsof features, which are specific to texts in English.These include counts of function words such as?we?
or ?therefore?, selected PoS tag frequen-cies, punctuation cues, and other statistics derivedfrom intuition or text analysis.
Similarly lan-guage specific feature sets were later explored formono-lingual genre classification experiments inGerman (Wolters and Kirsten, 1999) and Russian(Braslavski, 2004).In subsequent research, automatically gener-ated feature sets have become more popular.
Mostof these tend to be language-independent andmight work in mono-lingual genre classificationtasks in languages other than English.
Examplesare the word based approaches suggested by Sta-matatos et al(2000b) and Freund et al(2006),the image features suggested by Kim and Ross(2008), the PoS histogram frequency approach byFeldman et al(2009), and the character n-gramapproaches proposed by Kanaris and Stamatatos(2007) and Sharoff et al(2010).
All of themwere tested exclusively on English texts.
Whilelanguage-independence is a popular argument of-ten claimed by authors, few have shown empir-ically that this is true of their approach.
Oneof the few authors to carry out genre classifica-tion experiments in more than one language wasSharoff (2007).
Using PoS 3-grams and a vari-ation of common word 3-grams as feature sets,Sharoff classified English and Russian documentsinto genre categories.
However, while the PoS 3-gram set yielded respectable prediction accuracyfor English texts, in Russian documents, no im-provement over the baseline of choosing the mostfrequent genre class was observed.While there is virtually no prior work onCLGC, cross-lingual methods have been exploredfor other text classification tasks.
The first toreport such experiments were Bel et al(2003),who predicted text topics in Spanish and En-glish documents, using one language for train-ing and the other for testing.
Their approach in-volves training a classifier on language A, using adocument representation containing only contentwords (nouns, adjectives, and verbs with a highcorpus frequency).
These words are then trans-lated from language B to language A, so that textsin either language are mapped to a common rep-resentation.Thereafter, cross-lingual text classification wastypically regarded as a domain adaptation prob-lem that researchers have tried to solve using largesets of unlabeled data and/or small sets of labeleddata in the target language.
For instance, Rigutiniet al(2005) present an EM algorithm in whichlabeled source language documents are translatedinto the target language and then a classifier istrained to predict labels on a large, unlabeledset in the target language.
These instances arethen used to iteratively retrain the classificationmodel and the predictions are updated until con-vergence occurs.
Using information gain scoresat every iteration to only retain the most predic-tive words and thus reduce noise, Rigutini et al(2005) achieve a considerable improvement overthe baseline accuracy, which is a simple trans-lation of the training instances and subsequent12mono-lingual classification.
They, too, were clas-sifying texts by topics and used a collection ofEnglish and Italian newsgroup messages.
Simi-larly, researchers have used semi-supervised boot-strapping methods like co-training (Wan, 2009)and other domain adaptation methods like struc-tural component learning (Prettenhofer and Stein,2010) to carry out cross-lingual text classification.All of the approaches described above rely onMT, even if some try to keep translation to aminimum.
This has several disadvantages how-ever, as applications become dependent on par-allel corpora, which may not be available forpoorly-resourced languages.
It also introducesproblems due to word ambiguity and morphol-ogy, especially where single words are translatedout of context.
A different method is proposedby Gliozzo and Strapparava (2006), who use la-tent semantic analysis on a combined collectionof texts written in two languages.
The ratio-nale is that named entities such as ?Microsoft?
or?HIV?
are identical in different languages withthe same writing system.
Using term correla-tion, the algorithm can identify semantically sim-ilar words in both languages.
The authors exploitthese mappings in cross-lingual topic classifica-tion, and their results are promising.
However,using bilingual dictionaries as well yields a con-siderable improvement, as Gliozzo and Strappar-ava (2006) also report.While all of the methods above could techni-cally be used in any text classification task, the id-iosyncrasies of genres pose additional challenges.Techniques relying on the automated translationof predictive terms (Bel et al 2003; Prettenhoferand Stein, 2010) are workable in the contexts oftopics and sentiment, as these typically rely oncontent words such as nouns, adjectives, and ad-verbs.
For example, ?hospital?
may indicate atext from the medical domain, while ?excellent?may indicate that a review is positive.
Such termsare relatively easy to translate, even if not alwayswithout uncertainty.
Genres, on the other hand,are often classified using function words (Karl-gren and Cutting, 1994; Stamatatos et al 2000b)like ?of?, ?it?, or ?in?.
It is clear that translatingthese out of context is next to impossible.
This istrue in particular if there are differences in mor-phology, since function words in one languagemay be morphological affixes in another.Although it is theoretically possible to use thebilingual low-dimension approach by Gliozzo andStrapparava (2006) for genre classification, it re-lies on certain words to be identical in two dif-ferent languages.
While this may be the case fortopic-indicating named entities ?
a text contain-ing the words ?Obama?
and ?McCain?
will al-most certainly be about the U.S. elections in 2008,or at least about U.S. politics ?
there is little in-dication of what its genre might be: It could bea news report, an editorial, a letter, an interview,a biography, or a blog entry, just to name a few.Because topics and genres correlate, one wouldprobably reject some genres like instruction man-uals or fiction novels.
However, uncertainty is stilllarge, and Petrenz and Webber (2011) show thatit can be dangerous to rely on such correlations.This is particularly true in the cross-lingual case,as it is not clear whether genres and topics corre-late in similar ways in a different language.3 ApproachThe approach I propose here relies on two strate-gies I explain below in more detail: Stable fea-tures and target language adaptation.
The firstis based on the assumption that certain featuresare indicative of certain genres in more than onelanguage, while the latter is a less restricted wayto boost performance, once the language gap hasbeen bridged.
Figure 1 illustrates this approach,which is a challenging one, as very little priorknowledge is assumed by the system.
On theother hand, in theory it allows any resulting appli-cation to be used for a wide range of languages.3.1 Assumption of prior knowledgeTypically, the aim of cross-lingual techniques is toleverage the knowledge present in one languagein order to help carry a task in another language,for which such knowledge is not available.
In thecase of genre classification, this knowledge com-prises genre labels of the documents used to trainthe classification model.
My approach requires nolabeled data in the target language.
This is impor-tant, as some domain adaptation algorithms relyon a small set of labeled texts in the target do-main.Cross-lingual methods also often rely on MT,but this effectively restricts them to languagesfor which MT is sufficiently developed.
Apartfrom the fact that it would be desirable for across-lingual genre classifier to work for as many13LabelledSet(L S)UnlabelledSet(L T)StandardizedStableFeatureRepresentationStandardizedStableFeatureRepresentationSVMModelPredictionPredictionPredictionTarget Language AdaptationStable FeaturesLabelledSet(L T)PredictionConfidenceValuesLabelledSubset(L T)Bagof WordRepresentation&Feature Selection(Information Gain)SVMModel(Labelsremoved)Figure 1: Outline of the proposed method for CLGC.languages as possible, MT only allows classi-fication in well-resourced languages.
However,such languages are more likely to have genre-annotated corpora, and mono-lingual classifica-tion may yield better results.
In order to bringthe advantages of genre classification to poorly-resourced languages, the availability of MT tech-niques, at least for the time being, must not beassumed.
I only use them to generate baseline re-sults.The same restriction is applied to other types ofprior knowledge, and I do not assume supervisedPoS taggers, syntactic parsers, or other tools areavailable.
In future work however, I may exploreunsupervised methods, such as the PoS inductionmethods of Clark (2003), Goldwater and Griffiths(2007), or Berg-Kirkpatrick et al(2010), as theydo not represent external knowledge.There are a few assumptions that must be madein order to carry out any meaningful experiments.First, some way to detect sentence and paragraphboundaries is expected.
This can be a simple rule-based algorithm, or unsupervised methods, suchas the Punkt boundary detection system by Kissand Strunk (2006).
Also, punctuation symbolsand numerals are assumed to be identifiable assuch, although their exact semantic function is un-known.
For example, a question mark will beidentified as a punctuation symbol, but its func-tion (question cue; end of a sentence) will not.Lastly, a sufficiently large, unlabeled set of textsin the target language is required.3.2 Stable featuresMany types of features have been used in genreclassification.
They all fall into one of threegroups: Language-specific features are cueswhich can only be extracted from texts in one lan-guage.
An example would be the frequency of aparticular word, such as ?yesterday?.
Language-independent features can be extracted in any lan-guage, but they are not necessarily directly com-parable.
Examples would be the frequencies ofthe ten most common words.
While these can beextracted for any language (as long as words canbe identified as such), the function of a word ona certain position in this ranking will likely differfrom one language to another.
Comparable fea-tures, on the other hand, represent the same func-tion, or part of a function, in two or more lan-guages.
An example would be type/token ratios,which, in combination with the document length,represent the lexical richness of a text, indepen-dent of its language.
If such features prove tobe good genre predictors across languages, theymay be considered stable across those languages.Once suitable features are found, CLGC may beconsidered a standard classification problem, asoutlined in the upper part of Figure 1.I propose an approach that makes use of suchstable features, which include mostly structural,rather than lexical cues (cf.
Section 4).
Stablefeatures lend themselves to the classification ofgenres in particular.
As already mentioned, gen-res differ in communicative purpose, rather thanin topic.
Therefore, features involving contentwords are only useful to an extent.
While topicalclassification is hard to imagine without transla-tion or parallel/comparable corpora, genre classi-fication can be done without such resources.
Sta-ble features provide a way to bridge the languagegap even to poorly-resourced languages.This does not necessarily mean that the valuesof these attributes are in the same range acrosslanguages.
For example, the type/token ratio willtypically be higher in morphologically-rich lan-guages.
However, it might still be true that novelshave a richer vocabulary than scientific articles,whether they are written in English or Finnish.
In14order to exploit such features cross-linguistically,their values have to be mapped from one languageto another.
This can be done in an unsupervisedfashion, as long as enough data is present in bothsource and target language (cf.
Section 3.1).
Aneasy and intuitive way is to standardize values sothat each feature in both sets has a mean value ofzero mean and variance of one.
This is achievedby subtracting from each feature value the meanover all documents and dividing it by the standarddeviation.Note that the training and test sets have to bestandardized separately in order for both sets tohave the same mean and variance and thus becomparable.
This is different from classificationtasks where training and test set are assumed tobe sampled from the same distribution.
Althoughstandardization (or another type of scaling) is of-ten performed in such tasks as well, the scalingfactor from the training set would be used to scalethe test set (Hsu et al 2000).3.3 Target language adaptationCross-lingual text classification has often beenconsidered a special case of domain adap-tation.
Semi-supervised methods, such asthe expectation-maximization (EM) algorithm(Dempster et al 1977), have been employed tomake use of both labeled data in the source lan-guage and unlabeled data in the target language.However, adapting to a different language poses agreater challenge than adapting to different gen-res, topics, or sources.
As the vocabularies havelittle (if any) overlap, it is not trivial to initiallybridge the gap between the domains.
Typically,MT would be used to tackle this problem.Instead, my use of stable features shifts the fo-cus of subsequent domain adaptation to exploitingunlabeled data in the target language to improveprediction accuracy.
I refer to this as target lan-guage adaptation (TLA).
The advantage of mak-ing this separation is that a different set of featurescan be used to adapt to the target language.
Thereis no reason to keep the restrictions required forstable features once the language gap has beenbridged.
In fact, any language-independent fea-ture may be used for this task.
The assumption isthat the method described in Section 3.2 providesa good but enhanceable result, that is significantlybelow mono-lingual performance.
The resultingdecent, though imperfect, labeling of target lan-guage texts may be exploited to improve accuracy.A wide range of possible features lend them-selves to TLA.
Language-independent featureshave often been proposed in prior work on genreclassification.
These include bag-of-words, char-acter n-grams, and PoS frequencies or PoS n-grams, although the latter two would have to bebased on the output of unsupervised PoS induc-tion algorithms in this scenario.
Alternatively,PoS tags could be approximated by consideringthe most frequent words as their own tag, as sug-gested by Sharoff (2007).
With appropriate fea-ture sets, iterative algorithms can be used to im-prove the labeling of the set in the target domain.The lower part of Figure 1 illustrates the TLAprocess proposed for CLGC.
In each iteration,confidence values obtained from the previousclassification model are used to select a subset oflabeled texts in the target language.
Intuitively,only texts which can be confidently assigned toa certain genre should be used to train a newmodel.
This is particularly true in the first iter-ation, after the stable feature prediction, as errorrates are expected to be high.
The size of thissubset is increased at each iteration in the processuntil it comprises all the texts in the test set.
Amulti-class Support Vector Machine (SVM) in ak genre problem is a combination of k?
(k?1)2 bi-nary classifiers with voting to determine the over-all prediction.
To compute a confidence value forthis prediction, I use the geometric mean G =(?ni=1 ai)1/n of the distances from the decisionboundary ai for all the n binary classifiers, whichinclude the winning genre (i.e., n = k ?
1).
Thegeometric mean heavily penalizes low values, thatis small distances to the hyperplane separatingtwo genres.
This corresponds to the intuition thatthere should be a high certainty in any pairwisegenre comparison for a high-confidence predic-tion.
Negative distances from the boundary arecounted as zero, which reduces the overall confi-dence to zero.
The acquired subset is then trans-formed to a bag of words representation.
Inspiredby the approach of Rigutini et al(2005), the in-formation gain for each feature is computed, andonly the highest ranked features are used.
A newclassification model is trained and used to re-labelthe target language texts.
This process continuesuntil convergence (i.e., labels in two subsequentiterations are identical) or until a pre-defined iter-ation limit is reached.154 Experiments4.1 BaselinesTo verify the proposed approach, I carried out ex-periments using two publicly available corpora inEnglish and in Chinese.
As there is no prior workon CLGC, I chose as baseline an SVM modeltrained on the source language set using a bag ofwords representation as features.
This had pre-viously been used for this task by Freund et al(2006) and Sharoff et al(2010).1 The texts inthe test set were then translated from the targetinto the source language using Google translate2and the SVM model was used to predict their gen-res.
I also tested a variant in which the training setwas translated into the target language before thefeature extraction step, with the test set remaininguntranslated.
Note that these are somewhat artifi-cial baselines, as MT in reasonable quality is onlyavailable for a few selected languages.
They aretherefore not workable solutions to classify gen-res in poorly-resourced languages.
Thus, even across-lingual performance close to these baselinescan be considered a success, as long as no MTis used.
For reference, I also report the perfor-mances of a random guess approach and a classi-fier labeling each text as the dominant genre class.With all experiments, results are reported forthe test set in the target language.
I infer confi-dence intervals by assuming that the number ofmisclassifications is approximately normally dis-tributed with mean ?
= e ?
n and standard devi-ation ?
=???
(1?
e), where e is the percent-age of misclassified instances and n is the size ofthe test set.
I take two classification results to dif-fer significantly only if their 95% confidence in-tervals (i.e., ??
1.96?
?)
do not overlap.4.2 DataIn line with some of the prior mono-lingual workon genre classification, I used the Brown corpusfor my experiments.
As illustrated in Table 1,the 500 texts in the corpus are sampled from 15genres, which can be categorized more broadlyinto four broad genre categories, and even morebroadly into informative and imaginative texts.The second corpus I used was the Lancaster Cor-pus of Mandarin Chinese (LCMC).
In creating the1Other document representations, including character n-grams, were tested, but found to perform worse in this task.2http://translate.google.comInformativePressPress: Reportage(88 texts)Press: EditorialsPress: ReviewsReligionMisc.
Skills, Trades & Hobbies(176 texts) Popular LoreBiographies & EssaysNon-Fiction Reports & Official Documents(110 texts) Academic ProseImaginativeGeneral FictionMystery & Detective FictionFiction Science Fiction(126 texts) Adventure & Western FictionRomantic FictionHumorTable 1: Genres in the Brown corpus.
Categories areidentical in the LCMC, except Western Fiction is re-placed by Martial Arts Fiction.LCMC, the Brown sampling frame was followedvery closely and genres within these two corporaare comparable, with the exception of WesternFiction, which was replaced by Martial Arts Fic-tion in the LCMC.
Texts in both corpora are tok-enized by word, sentence, and paragraph, and nofurther pre-processing steps were necessary.Following Karlgren and Cutting (1994), Itested my approach on all three levels of granu-larity.
However, as the 15-genre task yields rela-tively poor CLGC results (both for my approachand the baselines), I report and discuss only theresults of the two and four-genre task here.
Im-proving performance on more fine-grained genreswill be subject of future work (cf.
Section 6).4.3 Features and ParametersThe stable features used to bridge the languagegap are listed in Table 2.
Most are simply ex-tractable cues that have been used in mono-lingualgenre classification experiments before: Averagesentence/paragraph lengths and standard devia-tions, type/token ratio and numeral/token ratio.To these, I added a ratio of single lines in a text ?that is, paragraphs containing no more than onesentence, divided by the sentence count.
Theseare typically headlines, datelines, author names,or other structurally interesting parts.
A distribu-tion value indicates how evenly single lines aredistributed throughout a text, with high values in-dicating single lines predominantly occurring atthe beginning and/or end of a text.16Features F N P M Features F N P MAverage Sentence ?0.5 0.6 0.1 0.0 Type/Token 0.0 ?0.9 0.6 0.3Length ?1.0 0.5 0.0 0.3 Ratio 0.0 ?0.9 0.9 0.1Sentence Length ?0.3 0.5 ?0.1 0.0 Numeral/Token ?0.3 0.6 ?0.1 ?0.1Standard Deviation ?0.5 0.4 0.0 0.1 Ratio ?0.7 0.7 0.4 ?0.1Average Paragraph ?0.4 0.3 ?0.1 0.1 Single Lines/ 0.3 0.1 ?0.1 ?0.2Length ?0.4 0.4 ?0.6 0.4 Sentence Ratio 0.0 ?0.3 1.1 ?0.4Paragraph Length ?0.4 0.4 ?0.2 0.1 Single Line ?0.3 0.2 0.0 0.1Standard Deviation ?0.1 0.4 ?0.6 0.1 Distribution 0.1 ?0.1 0.1 0.0Relative tf-idf values of 0.2 0.1 ?0.1 0.0 Topic Average ?0.4 0.8 ?0.3 0.0top 10 weighted words* 0.4 ?0.2 ?0.5 0.1 Precision ?0.4 0.8 ?0.2 ?0.1Table 2: Set of 19 stable features used to bridge the language gap.
The numbers denote the mean values afterstandardization for each broad genre in the LCMC (upper values) and Brown corpus (lower values): Fiction,Non-Fiction, Press, and Miscellaneous.
Negative/Positive numbers denote lower/higher average feature valuesfor this genre when compared to the rest of the corpus.
*Relative tf-idf values are ten separate features.
Thenumbers given are for the highest ranked word only.The remaining features (cf.
last row of Table2) are based on ideas from information retrieval.I used tf-idf weighting and marked the ten high-est weighted words in a text as relevant.
I thentreated this text as a ranked list of relevant andnon-relevant words, where the position of a wordin the text determined its rank.
This allowed me tocompute an average precision (AP) value.
The in-tuition behind this value is that genre conventionsdictate the location of important content wordswithin a text.
A high AP score means that the toptf-idf weighted words are found predominantly inthe beginning of a text.
In addition, for the sameten words, I added the tf-idf value to the featureset, divided by the sum of all ten.
These valuesindicate whether a text is very focused (a sharpdrop between higher and lower ranked words) ormore spread out across topics (relatively flat dis-tribution).For each of these features, Table 2 shows themean values for the four broad genre classes inthe LCMC and Brown corpus, after the sets havebeen standardized to zero mean and unit variance.This is the same preprocessing process used fortraining and testing the SVM model, although thestatistics in Table 2 are not available to the clas-sifier, since they require genre labels.
Each rowgives an idea of how suitable a feature might beto distinguish between these genres in Chinese(upper row) and English (lower row).
Both rowstogether indicate how stable a feature is acrosslanguages for this task.
Some features, such asthe topic AP value, seems to be both a good pre-dictor for genre and stable across languages.
Inboth Chinese and English, for example, the topi-cal words seem to be concentrated around the be-ginning of the text in Non-Fiction, but much lessso in Fiction.
These patterns can be seen in otherfeatures as well.
The type/token ratio is, on av-erage, highest in Press texts, followed by Miscel-laneous texts, Fiction texts, and Non-Fiction textsin both corpora.
While this does not hold for allthe features, many such patterns can be observedin Table 2.Since uncertainty after the initial prediction isvery high, the subset used to re-train the SVMmodel was chosen to be small.
In the first iter-ation, I used up to 60% of texts with the highestconfidence value within each genre.
To avoid animbalanced class distribution, texts were chosenso that the genre distribution in the new trainingset matched the one in the source language.
To il-lustrate this, consider an example with two genreclasses A and B, represented by 80% and 20% oftexts respectively in the source language.
Assum-ing that after the initial prediction both classes areassigned to 100 texts in a test set of size 200, the60 texts with the highest confidence values wouldbe chosen for class A.
To keep the genre distribu-tion of the source language, only the top 15 textswould be chosen for class B.In the second iteration, I simply used the top90% of texts overall.
This number was increasedby 5% in each subsequent iteration, so that the fullset was used from the fourth iteration.
No changeswere made to the genre distribution from the sec-ond iteration.
To train the classification model,I used the 500 features with the highest informa-170.40.50.60.70.80.91.0Rand.
Prior MT Source MT Target SF SF + TLAt: zh 50.0% 74.8% 87.2% 83.2% 79.2% 87.6%t: en 50.0% 74.8% 88.8% 95.8% 76.8% 94.6%Figure 2: Prediction accuracies for the Brown / LCMCtwo genre classification task.
Dark bars denote En-glish as source language and Chinese as target lan-guage (en?zh), light bars denote the reverse (zh?en).Rand.
: Random classifier.
Prior: Classifier always pre-dicting the most dominant class.
The baselines MTSource and MT target use MT to translate texts intothe source and target language, respectively.
SF: Sta-ble Features.
TLA: Target Language Adaptation.tion gain score for the selected training set in eachiteration.
As convergence is not guaranteed theo-retically, I used a maximum limit of 15 iterations.In my experiments however, the algorithm alwaysconverged.5 Results and DiscussionFigure 2 shows the accuracies for the two genretask (informative texts vs. imaginative texts) inboth directions: English as a source language withChinese being the target language (en?zh) andvice versa (zh?en).
As the class distribution isskewed (374 vs. 126 texts), always predictingthe most dominant class yields acceptable perfor-mance.
However, this is simplistic and might failin practice, where the most dominant class willtypically be unknown.Full text translation combined with mono-lingual classification performs well.
Stable fea-tures alone yield a respectable prediction accu-racy, but perform significantly worse than MTSource in both tasks and MT Target in the zh?entask.
However, subsequent TLA significantly im-proves the accuracy on both tasks, eliminating anysignificant difference from baseline performance.Figure 3 shows results for the four genre clas-sification task (Fiction vs. Non-Fiction vs. Pressvs.
Misc.).
Again, MT Source and MT Targetperform well.
However, translating from Chineseinto English yields better results than the reverse.This might be due to the easier identification of0.20.30.40.50.60.70.8Rand.
Prior MT Source MT Target SF SF + TLAt: zh 25.0% 35.2% 64.4% 54.0% 54.2% 69.4%t: en 25.0% 35.2% 51.0% 66.8% 59.2% 70.8%Figure 3: Prediction accuracies for the Brown / LCMCfour genre classification task.
Labels as in Figure 2.words in English and thus a more accurate bagof words representation.
TLA manages to signif-icantly improve the stable feature results.
My ap-proach outperforms both baselines in this experi-ment, although the differences are only significantif texts are translated from English to Chinese.These results are encouraging, as they showthat in CLGC tasks, equal or better performancecan be achieved with fewer resources, when com-pared the baseline of full text translation.
The rea-son why TLA works well in this case can be un-derstood by comparing the confusion matrices be-fore the first iteration and after convergence (Ta-ble 3).
While it is obvious that the stable fea-ture approach works better on some classes thanon others, the distributions of predicted and ac-tual genres are fairly similar.
For Fiction, Non-Fiction, and Press, precision is above 50%, withcorrect predictions outweighing incorrect ones,which is an important basis for subsequent it-erative learning.
However, too many texts arepredicted to belong to the Miscellaneous cate-gory, which reduces recall on the other genres.By using a different feature set and concentrat-ing on the documents with high confidence val-ues, TLA manages to remedy this problem to anextent.
While misclassifications are still present,recalls for the Fiction and Non-Fiction genres areincreased significantly, which explains the higheroverall accuracy.6 Conclusion and future workI have presented the first work on cross-lingualgenre classification (CLGC).
I have shown thatsome text features can be considered stable genrepredictors across languages and that it is possi-ble to achieve good results in CLGC tasks without18Fict.
Non-Fict.
Press Misc.Fiction 65 2 8 51Non-Fiction 4 59 2 45Press 5 8 31 44Miscellaneous 18 28 14 116Precision 0.71 0.61 0.56 0.45Recall 0.52 0.54 0.35 0.66Fict.
Non-Fict.
Press Misc.Fiction 102 0 2 22Non-Fiction 0 83 0 27Press 2 8 27 51Miscellaneous 29 9 3 135Precision 0.77 0.83 0.84 0.57Recall 0.81 0.75 0.31 0.77Table 3: Confusion Matrices for the four genre en?zh task.
Left: After stable feature prediction, but beforeTLA.
Right: After TLA convergence.
Rows 2?5 denote actual numbers of texts, columns denote predictions.resource-intensive MT techniques.
My approachexploits stable features to bridge the language gapand subsequently applies iterative target languageadaptation (TLA) in order to improve accuracy.The approach performed equally well or betterthan full text translation combined with mono-lingual classification.
Considering that Englishand Chinese are very dissimilar linguistically, Iexpect the approach to work at least equally wellfor more closely related language pairs.This work is still in progress.
While my resultsare encouraging, more work is needed to makethe CLGC approach more robust.
At the moment,classification accuracy is low for problems withmany classes.
I plan to remedy this by implement-ing a hierarchical classification framework, wherea text is assigned a broad genre label first and thenclassified further within this category.Since TLA can only work on a sufficientlygood initial labeling of target language texts, sta-ble feature classification results have to be im-proved as well.
To this end, I propose to focusinitially on features involving punctuation.
Thiscould include analyses of the different punctu-ation symbols used in comparison with the restof the document set, their frequencies and devia-tions between sentences, punctuation n-gram pat-terns, as well as the analyses of the positions ofpunctuation symbols within sentences or wholetexts.
Punctuation has frequently been used ingenre classification tasks and it is expected thatsome of the features based on such symbols arevaluable in a cross-lingual setting as well.
As vo-cabulary richness seems to be a useful predictor ofgenres, experiments will also be extended beyondthe simple inclusion of type/token ratios in thefeature set.
For example, hapax legomena statis-tics could be used, as well as the conformance totext laws, such as Zipf, Benford, and Heaps.After this, I will examine text structure a pre-dictor.
While single line statistics and topic APscores already reflect text structure, more sophis-ticated pre-processing methods, such as text seg-mentation and unsupervised PoS induction, mightyield better results.
The experiments using thetf-idf values of terms will be extended.
Result-ing features may include the positions of highlyweighted words in a text, the amount of topicscovered, or identification of summaries.TLA techniques can also be refined.
An obvi-ous choice is to consider different types of fea-tures, as mentioned in Section 3.3.
Different rep-resentations may even be combined to capture thenotion of different communicative purpose, sim-ilar to the multi-dimensional approach by Biber(1995).
An interesting idea to combine differ-ent sets of features was suggested by Chaker andHabib (2007).
Assigning a document to all genreswith different probabilities and repeating this fordifferent sets of features may yield a very flexi-ble classifier.
The impact of the feature sets onthe final prediction could be weighted accordingto different criteria, such as prediction certaintyor overlap with other feature sets.
Improvementsmay also be achieved by choosing a more reliablemethod for finding the most confident genre pre-dictions as a function of the distance to the SVMdecision boundary.
Cross-validation techniqueswill be explored to estimate confidence values.Finally, I will have to test the approach on alarger set of data with texts from more languages.To this end, I am working to compile a referencecorpus for CLGC by combining publicly availablesources.
This would be useful to compare meth-ods and will hopefully encourage further research.AcknowledgmentsI thank Bonnie Webber, Benjamin Rosman, andthree anonymous reviewers for their helpful com-ments on an earlier version of this paper.19ReferencesShlomo Argamon, Moshe Koppel, and Galit Avneri.1998.
Routing documents according to style.
InProceedings of First International Workshop on In-novative Information Systems.Nuria Bel, Cornelis Koster, and Marta Villegas.
2003.Cross-lingual text categorization.
In Traugott Kochand Ingeborg Slvberg, editors, Research and Ad-vanced Technology for Digital Libraries, volume2769 of Lecture Notes in Computer Science, pages126?139.
Springer Berlin / Heidelberg.Taylor Berg-Kirkpatrick, Alexandre Bouchard-Co?te?,John DeNero, and Dan Klein.
2010.
Painlessunsupervised learning with features.
In HumanLanguage Technologies: The 2010 Annual Confer-ence of the North American Chapter of the Associa-tion for Computational Linguistics, HLT ?10, pages582?590, Stroudsburg, PA, USA.
Association forComputational Linguistics.Douglas Biber.
1988.
Variation across Speech andWriting.
Cambridge University Press, Cambridge.Douglas Biber.
1995.
Dimensions of Register Varia-tion.
Cambridge University Press, New York.Pavel Braslavski.
2004.
Document style recognitionusing shallow statistical analysis.
In Proceedings ofthe ESSLLI 2004 Workshop on Combining Shallowand Deep Processing for NLP, pages 1?9.Jebari Chaker and Ounelli Habib.
2007.
Genre cat-egorization of web pages.
In Proceedings of theSeventh IEEE International Conference on DataMining Workshops, ICDMW ?07, pages 455?464,Washington, DC, USA.
IEEE Computer Society.Alexander Clark.
2003.
Combining distributional andmorphological information for part of speech in-duction.
In Proceedings of the tenth conference onEuropean chapter of the Association for Computa-tional Linguistics - Volume 1, EACL ?03, pages 59?66, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.O.
de Vel, A. Anderson, M. Corney, and G. Mohay.2001.
Mining e-mail content for author identifica-tion forensics.
SIGMOD Rec., 30(4):55?64.A.
P. Dempster, N. M. Laird, and D. B. Rubin.
1977.Maximum Likelihood from Incomplete Data via theEM Algorithm.
Journal of the Royal Statistical So-ciety.
Series B (Methodological), 39(1):1?38.S.
Feldman, M. A. Marin, M. Ostendorf, and M. R.Gupta.
2009.
Part-of-speech histograms forgenre classification of text.
In Proceedings of the2009 IEEE International Conference on Acoustics,Speech and Signal Processing, pages 4781?4784,Washington, DC, USA.
IEEE Computer Society.Aidan Finn and Nicholas Kushmerick.
2006.
Learn-ing to classify documents according to genre.
J.Am.
Soc.
Inf.
Sci.
Technol., 57(11):1506?1518.Luanne Freund, Charles L. A. Clarke, and Elaine G.Toms.
2006.
Towards genre classification for IRin the workplace.
In Proceedings of the 1st inter-national conference on Information interaction incontext, pages 30?36, New York, NY, USA.
ACM.Alfio Gliozzo and Carlo Strapparava.
2006.
Exploit-ing comparable corpora and bilingual dictionariesfor cross-language text categorization.
In Proceed-ings of the 21st International Conference on Com-putational Linguistics and the 44th annual meetingof the Association for Computational Linguistics,ACL-44, pages 553?560, Stroudsburg, PA, USA.Association for Computational Linguistics.Jade Goldstein, Gary M. Ciany, and Jaime G. Car-bonell.
2007.
Genre identification and goal-focused summarization.
In Proceedings of the six-teenth ACM conference on Conference on informa-tion and knowledge management, CIKM ?07, pages889?892, New York, NY, USA.
ACM.Sharon Goldwater and Tom Griffiths.
2007.
A fullyBayesian approach to unsupervised part-of-speechtagging.
In Proceedings of the 45th Annual Meet-ing of the Association of Computational Linguistics,pages 744?751, Prague, Czech Republic, June.
As-sociation for Computational Linguistics.Chih-Wei Hsu, Chih-Chung Chang, and Chih-Jen Lin.2000.
A Practical Guide to Support Vector Classifi-cation.Thorsten Joachims.
1998.
Text categorization withsuport vector machines: Learning with many rele-vant features.
In Proceedings of the 10th EuropeanConference on Machine Learning, pages 137?142,London, UK.
Springer-Verlag.Ioannis Kanaris and Efstathios Stamatatos.
2007.Webpage genre identification using variable-lengthcharacter n-grams.
In Proceedings of the 19th IEEEInternational Conference on Tools with AI, pages 3?10, Washington, DC.Jussi Karlgren and Douglass Cutting.
1994.
Recog-nizing text genres with simple metrics using dis-criminant analysis.
In Proceedings of the 15th Con-ference on Computational Linguistics, pages 1071?1075, Morristown, NJ, USA.
Association for Com-putational Linguistics.Brett Kessler, Geoffrey Nunberg, and Hinrich Schu?tze.1997.
Automatic detection of text genre.
In Pro-ceedings of the 35th Annual Meeting of the Associ-ation for Computational Linguistics, pages 32?38,Morristown, NJ, USA.
Association for Computa-tional Linguistics.Yunhyong Kim and Seamus Ross.
2008.
Examiningvariations of prominent features in genre classifica-tion.
In Proceedings of the Proceedings of the 41stAnnual Hawaii International Conference on SystemSciences, HICSS ?08, pages 132?, Washington, DC,USA.
IEEE Computer Society.20Tibor Kiss and Jan Strunk.
2006.
Unsupervised multi-lingual sentence boundary detection.
Comput.
Lin-guist., 32:485?525, December.Jon Oberlander and Scott Nowson.
2006.
Whosethumb is it anyway?
: classifying author person-ality from weblog text.
In Proceedings of theCOLING/ACL on Main conference poster sessions,COLING-ACL ?06, pages 627?634, Morristown,NJ, USA.
Association for Computational Linguis-tics.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
: sentiment classification usingmachine learning techniques.
In Proceedings of theACL-02 conference on Empirical methods in natu-ral language processing - Volume 10, EMNLP ?02,pages 79?86, Morristown, NJ, USA.
Associationfor Computational Linguistics.Philipp Petrenz and Bonnie Webber.
2011.
Stableclassification of text genres.
Comput.
Linguist.,37:385?393.Peter Prettenhofer and Benno Stein.
2010.
Cross-language text classification using structural corre-spondence learning.
In Proceedings of the 48th An-nual Meeting of the Association for ComputationalLinguistics, ACL ?10, pages 1118?1127, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Leonardo Rigutini, Marco Maggini, and Bing Liu.2005.
An em based training algorithm for cross-language text categorization.
In Proceedings of theWeb Intelligence Conference, pages 529?535.Evan Sandhaus.
2008.
New York Times corpus: Cor-pus overview.
LDC catalogue entry LDC2008T19.Fabrizio Sebastiani.
2002.
Machine learning in au-tomated text categorization.
ACM Comput.
Surv.,34:1?47, March.Serge Sharoff, Zhili Wu, and Katja Markert.
2010.The Web Library of Babel: Evaluating genre collec-tions.
In Proceedings of the Seventh conference onInternational Language Resources and Evaluation,pages 3063?3070, Valletta, Malta, may.
EuropeanLanguage Resources Association (ELRA).Serge Sharoff.
2007.
Classifying web corpora intodomain and genre using automatic feature identifi-cation.
In Proceedings of Web as Corpus Workshop.E.
Stamatatos, N. Fakotakis, and G. Kokkinakis.2000a.
Text genre detection using common wordfrequencies.
In Proceedings of the 18th conferenceon Computational linguistics, pages 808?814, Mor-ristown, NJ, USA.
Association for ComputationalLinguistics.Efstathios Stamatatos, George Kokkinakis, and NikosFakotakis.
2000b.
Automatic text categorization interms of genre and author.
Computational Linguis-tics, 26(4):471?495.Xiaojun Wan.
2009.
Co-training for cross-lingual sen-timent classification.
In Proceedings of the JointConference of the 47th Annual Meeting of the ACLand the 4th International Joint Conference on Nat-ural Language Processing of the AFNLP: Volume 1- Volume 1, ACL ?09, pages 235?243, Stroudsburg,PA, USA.
Association for Computational Linguis-tics.Bonnie Webber.
2009.
Genre distinctions for dis-course in the Penn TreeBank.
In Proceedings of theJoint Conference of the 47th Annual Meeting of theACL and the 4th International Joint Conference onNatural Language Processing of the AFNLP, pages674?682.Maria Wolters and Mathias Kirsten.
1999.
Exploringthe use of linguistic features in domain and genreclassification.
In Proceedings of the ninth confer-ence on European chapter of the Association forComputational Linguistics, EACL ?99, pages 142?149, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.21
