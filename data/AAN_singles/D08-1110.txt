Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 1051?1060,Honolulu, October 2008. c?2008 Association for Computational LinguisticsPart-of-Speech Tagging for English-Spanish Code-Switched TextThamar Solorio and Yang LiuHuman Language Technology Research InstituteThe University of Texas at DallasRichardson, TX 75080, USAtsolorio,yangl@hlt.utdallas.eduAbstractCode-switching is an interesting linguisticphenomenon commonly observed in highlybilingual communities.
It consists of mixinglanguages in the same conversational event.This paper presents results on Part-of-Speechtagging Spanish-English code-switched dis-course.
We explore different approaches toexploit existing resources for both languagesthat range from simple heuristics, to languageidentification, to machine learning.
The bestresults are achieved by training a machinelearning algorithm with features that combinethe output of an English and a Spanish Part-of-Speech tagger.1 IntroductionWorldwide the percentage of bilingual speakers isfairly large, and it keeps increasing at a high rate.In the U.S., 18% of the total population speaks alanguage other than English at home, the major-ity of which speaks Spanish (U.S. Census Bureau,2003).
A significant percentage of this Spanish-English bilingual population code-switch betweenthe two languages in what is often referred as Span-glish, the mix of Spanish and English.
Spanishand English are not the only occurrence of languagemixtures.
Examples of other popular combinationsinclude Arabic dialects, French and German, Span-ish and Catalan, Maltese and English, and Englishand French.
Typically when there are linguistic bor-ders, or when the country has more than one officiallanguage, we can find instances of code-switching.Despite the wide use of code-switched discourseamong bilinguals, this linguistic phenomenon hasreceived little attention in the fields of Natural Lan-guage Processing and Computational Linguistics.Part-of-Speech (POS) tagging is a well studied prob-lem in these fields.
For languages such as English,German, Spanish, and Chinese there are several dif-ferent POS taggers that reach high accuracies, espe-cially in news text corpora.
However, to our knowl-edge, there is no previous work on developing a POStagger for text with mixes of languages.In this paper we present results on the problemof POS tagging English-Spanish code-switched dis-course by taking advantage of existing taggers forboth languages.
This rationale follows the evi-dence from studies of code-switching on differentlanguage pairs, which have shown code-switchingto be grammatical according to both languages be-ing switched.
We use different heuristics to combinePOS tag information from existing monolingual tag-gers.
We also explore the use of different languageidentification methods to select POS tags from theappropriate monolingual tagger.
However, the bestresults are achieved by a machine learning approachusing features generated by the monolingual POStaggers.The next section presents the facts about code-switching, including some previous work donemainly in linguistics.
Then in Section 3 we dis-cuss previous work related to the automated pro-cessing of code-switched discourse.
In Section 4we describe the English-Spanish code-switched dataset gathered for the experimental evaluation.
Sec-tion 5 presents the heuristics-based approaches forPOS tagging that we explored.
In Section 6 wedescribe our machine learning approach and show1051results on POS tagging code-switched text.
An indepth analysis of results is presented in Section 7,and we conclude this paper with a summary of thefindings and directions for future work in Section 8.2 Rules of Code-switchingIn the linguistic, sociolinguistic, psychology, andpsycholinguistic literature, bilingualism and the in-herent phenomena it exhibits have been studiedfor nearly a century (Espinosa, 1917; Ervin andOsgood, 1954; Gumperz, 1964; Gumperz andHernandez-Chavez, 1971; Gumperz, 1971; Sankoff,1968; Lipski, 1978).
Despite the numerous previ-ous studies of linguistic characteristics of bilingual-ism, there is no clear consensus on the terminol-ogy related to language alternation patterns in bilin-gual speakers.
The alternation of languages withina sentence is known as code-mixing, but it hasalso been referred as intrasentential code-switching,and intrasentential alternation (Poplack, 1980; Gros-jean, 1982; Ardila, 2005).
Alternation across sen-tence boundaries is known as intersentential code-switching, or just code-switching.
In the rest of thispaper we will refer to the mixing of languages ascode-switching.
When necessary, we will differen-tiate the type of code-switching by referring to al-ternations within sentences as intrasentential code-switching and alternations across sentence bound-aries as intersentential code-switching.Linguistic phenomena in bilingual speakers havebeen analyzed on different language pairs, includ-ing English-French, English-Dutch, Finish-English,Arabic-French, and Spanish-English, to name a few.There is a general agreement that code-switched pat-terns are not generated randomly; according to thesestudies, they follow specific grammatical rules.
Fur-thermore, some studies suggest that, if these rulesare violated, the resulting discourse will sound un-natural (Toribio, 2001b; Toribio, 2001a).
The fol-lowing shows the rules governing code-switchingdiscourse described in several studies (Poplack,1980; Poplack, 1981; Sankoff, 1981; Sankoff,1998a).?
Switches can take place only between full wordboundaries.
This is also known as the free mor-pheme constraint.?
Monolingual constructs within the sentencewill follow the grammatical rules of the mono-lingual fragment.?
Permissible switch points are those that do notviolate the order of adjacent constituents onboth sides of the switch point of either of thelanguages.
This is called the equivalence con-straint.Although these rules are somewhat controversial,and most of the studies on this area have been con-ducted on small samples, we cannot ignore the factthat patterns bearing the above rules have emerged indifferent bilingual communities with different back-grounds.3 Automated Processing of Code-SwitchedDiscourseA previous work related to the processing of code-switched text deals with language identificationon English-Maltese code-switched SMS messages(Rosner and Farrugia, 2007).
In addition to deal-ing with intrasentential code-switching, they haveto deal with text where misspellings and ad hocword contractions abound.
What Rosner and Far-rigua have found to work best for language identi-fication in this noisy domain is a combination of abigram Hidden Markov Model, trained on languagetransitions, and a trigram character Markov Modelfor handling unknown words.
In another relatedwork, Franco and Solorio present preliminary resultson training a language model for Spanish-Englishcode-switched text (Franco and Solorio, 2007).
Toevaluate their language model, they asked a humansubject to judge sentences generated by a PCFG in-duced from training data and the language model.However, they only used one human judge.Regarding the automated POS tagging and pars-ing of code-mixed utterances there is little priorwork.
To the best of our knowledge, there is noparser, nor POS tagger, currently available for thesyntactic analysis of this type of discourse.
Thereare theoretical approaches that propose formalismsto represent the structure of code-switched utter-ances and describe a framework for parsing and gen-erating mixed sentences, for example for Marathiand English (Joshi, 1982), or Hindi and English(Goyal et al, 2003).
Sankoff proposed a productionmodel of bilingual discourse that accounts for the1052equivalence constraint and the unpredictability ofcode-switching (Sankoff, 1998a; Sankoff, 1998b).His real-time production model draws on the alter-nation of fragments from two virtual monolingualsentences.
It also accounts for other types of code-switching such as repetition-translation and inser-tional code-switching.
But no statistical assessmenthas been conducted on real corpora.Our goal is to develop a POS tagger for code-switched utterances, which is the first step of thesyntactic analysis of any language.
Among the chal-lenges we face is the lack of a representative sam-ple of code-mixed discourse.
Most POS taggers arebuilt using large collections, usually at least a mil-lion words, such as the Brown corpus (Kucera andFrancis, 1967), the Wall Street Journal corpus (Pauland Baker, 1992), or the Switchboard corpus (God-frey et al, 1992).
Currently, there is no annotationof code-switched text of comparable size.
But incontrast to the lack of linguistic resources availablefor Spanish-English code-mixed discourse, Englishand Spanish have sufficient resources, especially En-glish.
Thus, rather than starting from scratch, wewill draw on existing taggers for both languages,which will reduce the amount of code-switched dataneeded.
Some examples of POS taggers that per-form reasonably well on monolingual text of eachlanguage can be found in (Brants, 2000; Brill, 1992;Carreras and Padro?, 2002; Charniak, 1993; Ratna-parkhi, 1996; Schmid, 1994).
However, these toolsare designed to work on monolingual text, thereforeif applied as they are to code-switched text, their ac-curacy will decrease by a large margin.
In the fol-lowing sections we will explore different methodsfor combining monolingual taggers.4 Data SetData collections that have instances of Spanish-English code-switching, Spanglish for short, are noteasily found since code-switching is primarily usedin spoken form.
To gather data we recorded a con-versation among three staff members of a southwestuniversity in the U.S.
The three speakers come froma highly bilingual background and code-switch reg-ularly when speaking among themselves, or otherbilingual speakers.This recording session has around 39 minutes ofTable 1: Excerpts taken from the Spanglish data set.Spanglish English Translation(a)Entonces le dio?
elvirus y no se lo atendio?and the virus spreadthrough his body.
(a)Then he got thevirus and he didn?t re-ceive treatment and thevirus spread throughhis body.
(b)Cuando yo lo vi helooked pretty bad.
(b)When I saw him helooked pretty bad.
(c)I think she wastaller than he was.
(c)I think she was tallerthan he was.Y un cara?cter muybonito tambie?n ella.And a very nice char-acter she as well.Very easy going.
Very easy going.continuous speech (922 sentences, about 8k words)and was transcribed and annotated with POS tags bya human annotator.
The annotations were later re-vised by a different annotator but no inter-annotatoragreement was measured.
The POS tag set used inthe annotation is the combination of the tag sets fromthe English and the Spanish Tree Taggers (see Sec-tion 5).
The vocabulary of the transcription has a to-tal of 1,516 different word forms1.
In the conversa-tion a total of 239 switches were identified manually,out of which 129 are intrasentential code-switches,and the rest are intersentential.
English is the pre-dominant language used, with a total of 6,020 tokensand 576 monolingual sentences.
In contrast, thetranscription has close to 2k tokens in Spanish.
Ta-ble 1 shows examples of code-switching taken fromthe recorded conversation; (a) and (b) are instancesof intrasentential code-switching, and (c) shows in-tersentential code-switching.5 Rule-based Methods for ExploitingExisting ResourcesIn this section we present several heuristics-basedmethods for POS tagging code-switched text.
First,we describe the monolingual taggers used in thiswork.
Then we present the different approaches ex-plored and contrast their performance.1This transcription and the audio file are freely available forresearch purposes by contacting the first author.10535.1 Monolingual TaggersWe used the Tree Tagger (Schmid, 1994) for thiswork because of the following considerations:1.
It has both English and Spanish versions.
TheEnglish tagger uses a slightly modified version ofthe Penn Treebank tag set and was trained and eval-uated on different portions of the Penn Treebank,reaching a POS tagging accuracy of 96.36%.
TheSpanish one uses a different tagset with 75 differentPOS tags2 and was trained on the Spanish CRATERcorpus.2.
The transition probabilities are estimated using amodified version of the ID3 decision tree algorithm(Quinlan, 1986), which provides more freedom tolearn contextual cues than n-grams.3.
Both taggers include a special tag for foreignwords, PE for Spanish and FW for English.
We donot expect this tag to identify correctly all foreignwords, but when available this information will beexploited.4.
The Tree tagger generates probability estimateson the tags that can be used as features.5.
Finally, when the tagger fails to lemmatize aword it outputs the special token ?unknown?.
Thisinformation can be used as a hint of words that donot belong to that particular language.5.2 Heuristic-based SystemsFor all heuristics the complete Spanglish data setwas given to both taggers as a single text, then thefinal tag for each word was selected from the outputof the taggers according to the different heuristics.Table 2 shows the tagging accuracies of the differentheuristics we explored, which are explained below.1.
Using the monolingual tagger.
Here we simplygive the Spanglish text to the Spanish and theEnglish tree tagger.
We expect from both taggers aperformance degradation due to the inclusion of for-eign words in code-switching, as compared againsttheir accuracy on monolingual texts.
Anothercomplicating factor to keep in mind is that we aredealing with spoken language.
Hesitations, fillers,disfluencies, and interruption points, such as Umm,Mmmhmm, and Uh-huh, are frequently observed in2The authors were unable to identify the source of the Span-ish tagset.Table 2: Accuracy on POS tagging Spanglish text usingsimple heuristics for combining the output of the Englishand Spanish tagger.Heuristic Accuracy (%)1 Spanish Tree Tagger 25.99English Tree Tagger 54.592 Highest prob tag or English 51.51Highest prob tag or Spanish 49.163 Prob + special tags + lemmas 64.274 Dictionary-based Language Id 86.03Character 5-grams Language Id 81.46Human Language Id 89.72speech and it is well known that they complicatethe POS tagging task.
The tagging accuracy fromusing the individual taggers is rather low, 26% forthe Spanish tagger and 54% for the English one.The large difference between the two taggers can beattributed to the fact that the majority of the wordsin the corpus are in English.2.
Using confidence thresholds.
The Tree Taggercan output probabilities for each tag, showing theconfidence of the tagger on each particular tag.
Touse this information we choose for each word the tagfrom the tagger with the highest confidence.
Whenthere is a tie we use either the English or the Spanishtag.
Table 2 shows the results for the two cases.
The?Highest prob tag or English?
heuristic gives an ac-curacy of 51%, which is almost as accurate as usingonly the English tagger.
The ?Highest prob tag orSpanish?
achieves an accuracy of 49%, which is animprovement over using only the monolingual Span-ish tagger, but it is still below the accuracy of the En-glish monolingual tagger.
This is also possibly dueto the task being easier for the English tagger.3.
Combining confidence thresholds with knowl-edge from special tags and lemmas.
This heuristicuses confidence thresholds combined with decisionsbased on the special tags, described in Section 5.1,and the unknown lemmas found.
Let POSE(wi)and POSS(wi) be the POS tags assigned to wordwi by the English and Spanish tagger respectively;and let ProbE(wi) and ProbS(wi) be the confi-dence scores of POS tags for word wi computed bythe English and Spanish tree taggers, respectively.For each word wi in the text, the final POS tag,1054POSF (wi), will be assigned as follows:1.
If POSE(wi) = FW , then POSF (wi) ?POSS(wi)2.
Else if POSS(wi) = PE, then POSF (wi) ?POSE(wi)3.
Else if POSE(wi) = ?unknown?, thenPOSF (wi)?
POSS(wi)4.
Else if POSS(wi) = ?unknown?, thenPOSF (wi)?
POSE(wi)5.
Else if ProbE(wi) > ProbS(wi), thenPOSF (wi)?
POSE(wi)6.
Else POSF (wi)?
POSS(wi)This heuristic performs better than the other meth-ods explored so far, yielding an accuracy of 64.27%.It seems that knowledge of the taggers can be usedto improve results.
However, POS tagging accuracyis still poor.4.
Selecting POS tags based on automated languageidentification.
We used two different strategies forautomatically identifying the language at the wordlevel.
One is based on dictionary look-up and theother is character-based language models.
For thefirst approach, every word in the text is searched inthe English and Spanish dictionaries.
If a word isfound in the English dictionary, then we identify thatword as belonging to English and the POS tags fromthe English tagger are used for that word and thefollowing ones, until a word is found in the Span-ish dictionary.
Similarly, for a word not found inthe English dictionary, but found in the Spanish dic-tionary, we use the Spanish tags until an Englishword is found.
Note that this simple heuristic willalways label words that belong to both languages asEnglish, which is also the case for words not foundin either dictionary.
This dictionary-based methodhas a language identification accuracy of 94% on theSpanglish corpus.The character language models were trained onthe Agence France Presse (AFP) portions of the Gi-gaword for English and Spanish, respectively.
Foreach of the words in the Spanglish corpus, we firstdecide its language by choosing the one with thelowest perplexity, calculated using character n-gramlanguage models, then we use the correspondingPOS tag.
We experimented with different languagemodel orders, with n ranging from 2 to 6, and foundthat we achieve the highest accuracy, 81.46%, onPOS tagging using a 5-gram language model.
This5-gram method reached a language identification ac-curacy of 85% for the Spanglish corpus.
However,the language identification method using dictionarylook-up achieved the best POS tagging result so far:86.03%.
The Spanglish conversation is dominatedby every-day language that is easily found in dic-tionaries, while the text used to train the charac-ter based n-gram language models includes vocab-ulary that is not commonly used in conversations.This can explain why the simple dictionary look-up approach yielded better results for our corpus.Performing manual identification of the languageand sending to the appropriate tagger just the corre-sponding fragments yields a very high POS taggingaccuracy, 89.72%.
This shows that it is importantto deal with the language switches for boosting ac-curacy.
However relying on human annotated lan-guage tags would be expensive and for some tasksunfeasible.6 Machine Learning for POS TaggingCode-Switched DiscourseFrom Table 2 we can see that, with the exception ofthe language identification heuristic, accuracies arelow for the previous experiments.
However, we be-lieve that we can improve results further by usingMachine Learning (ML) algorithms trained specif-ically for this task.
In this section we describe theML setting and present a comparison of the differ-ent algorithms we tested.6.1 ApproachThe key point is that the features selected for de-scribing the learning instances are the output fromthe English and the Spanish taggers.
This schemeis similar to a stacked classifier approach (Wolpert,1992), where the final classifier takes as input thepredictions made by the different learners on the firstpass and is trained to select the right tag from them,or a different one if the right answer is not available.The gold-standard POS tags are used as theclass label, and instances in this learning task aredescribed by the following attributes:10551.
The word (word)2.
English POS tag (Et)3.
English POS tagger lemma (El)4.
English POS tagger confidence (Ep)5.
Spanish POS tag (St)6.
Spanish POS tagger lemma (Sl)7.
Spanish POS tagger confidence (Sp)Feature 1 is just the lexical word form as it ap-pears in the transcript.
Features 2 to 4 are generatedby the English Tree tagger, while features 5 to 7 aregenerated by the Spanish Tree tagger.
Thus all fea-tures are automatically extracted.6.2 ResultsWe evaluated experimentally the idea of using MLwith different learning algorithms in WEKA (Wit-ten and Frank, 1999).
We selected some of the mostwidely known algorithms, including Support VectorMachines (SVM) with a polynomial kernel of ex-ponent one (Scho?lkopf and Smola, 2002), Weka?smodified version of Quinlan?s C4.5 (J48) (Quinlan,1986), Additive Logistic Regression with DecisionStumps (Logit Boost) (Friedman et al, 1998) andNaive Bayes.
The only parameter we modified wasfor J48 ?we enabled the option for reducing errorpruning.Table 3: POS tagging accuracy of Spanglish text withdifferent Machine Learning algorithms.
Oracle showsthe accuracy achieved when always selecting the rightPOS tag from the output of both Tree Taggers.
LanguageId shows accuracy of identifying the language and thenchoosing the output of the corresponding tagger.ML Algorithms Mean Accuracy (%) VarianceNaive Bayes 88.50 1.9280SVM 93.48 1.2784Logit Boost 93.19 1.4437J48 91.11 2.1527Oracle 90.31 -Language Id 85.80 -Table 3 shows the average accuracy of 10-foldcross-validation for each classifier together with thevariance.
SVM and Logit Boost performed the bestand the difference between the two algorithms is notsignificant according to the paired t-test (P-value =0.1).
For comparison, we show the accuracy of the10 20 30 40 50 60 70 80 9080828486889092949698100Percentage of training data usedAccuracyFigure 1: Effect of different amounts of training data onaccuracylanguage identification approach together with theoracle accuracy.
The oracle is the accuracy achievedwhen always selecting the right POS tag, when itis available, from the output of both Tree Taggers.We did not expect the oracle?s accuracy to be an up-per bound on the accuracy for the ML learning al-gorithm.
Our intuition is that the ML algorithm canbe trained to identify when the taggers have madea mistake and what the right answer should be.
Asthe results show, the ML approach can indeed out-perform the oracle, and the language identificationmethod.In Figure 1 we show the effect of the amountof training data on the accuracy using Logit Boost.We selected Logit Boost for this and the follow-ing experiments since its accuracy is comparable toSVMs but it is computationally less expensive.
Werandomly partitioned the transcription into 10 sub-groups.
Then we used one subgroup as the test setand the rest for training.
Starting with one subgroupin the training set, we incrementally added one sub-group to the training set and evaluate the taggingperformance of the test set.
We repeated this pro-cess several times, choosing randomly a new test seteach time.
The percentages shown are the averageover all the experiments.
With only 10% of the sen-tences for training we are reaching very good accu-racy already, as high as that from the strategy basedon language identification.
The curve flattens after1056Table 4: Accuracy of Logit Boost with different subsetsof attributes.
?X?
marks attributes included.
Et, El, Ep,and St, Sl, and Sp are the POS tag, lemma and confi-dence output by the English and the Spanish POS tagger,respectively.word Et El Ep St Sl Sp AccuracyX X X X ?
?
?
88.80?
X X X ?
?
?
86.22X ?
?
?
X X X 78.59?
?
?
?
X X X 65.28X X X ?
X X ?
92.95X X ?
X X ?
X 92.53X X ?
?
X ?
?
91.22X X X ?
?
X ?
89.76X ?
X X ?
X X 77.08?
?
X ?
?
X ?
74.18X X ?
?
?
?
?
85.76X ?
?
?
?
?
?
71.17?
?
?
X ?
?
X 24.96X X X X X ?
?
92.55X X X X ?
?
X 88.89X ?
X ?
X ?
?
78.74X X X X ?
X ?
89.62?
X ?
?
X X ?
90.76?
?
X X ?
X X 75.94X ?
X ?
X X X 80.24X ?
?
X X X X 79.1360% of the training data is used.
We do not gainmuch by adding more training data after this.Results shown in Table 3 demonstrate that POStagging can be learned effectively based on the at-tributes described in Subsection 6.1, even if we arenot explicitly adding contextual information.
To de-termine the extent to which each attribute is con-tributing to the learning task, we performed anotherset of experiments where we selected different sub-sets of the attributes.
Table 4 shows the results withLogit Boost.
Overall, the attributes taken from theEnglish POS tagger are more valuable for this learn-ing task.
If we only take the word form and the fea-tures from the English Tree tagger (first row in Ta-ble 4) we are reaching an accuracy that outperformsall heuristics.
Still, there is some valuable infor-mation provided by the Spanish POS tagger outputsince the highest accuracy is achieved by includingthe Spanish-based attributes in combination with theEnglish-based ones.
Surprisingly, we can manage tooutperform the oracle by using only three attributes:the lexical word form and the POS tags from theEnglish and Spanish tagger (see row 7 in table), orthe POS tags from the monolingual taggers togetherwith the lemma from the Spanish tagger (see row 4from bottom to top).
We also experimented addingas an attribute the output of the language identifica-tion method, but found no significant changes in theaccuracy.7 DiscussionWe analyzed the different results gathered throughthe experiments and we present here the most rele-vant insights.The first discovery, is that a lot of the errors madeby the oracle, and the other methods as well, are dueto the difficulties inherent in dealing with sponta-neous speech where fillers, interruption points, hes-itations, and the like abound.
About as much as20% of the errors made by the oracle are due tothese features.
Another roughly 20% is due to un-known tokens in the transcription, such as mum-bling, slang words such as ?gonna?
and ?wanna?,or other sounds unintelligible for the human tran-scriber.
For the rest of the analysis we decided toignore these types of mistakes for all methods andfocus only on the remaining mistakes.
In the caseof the oracle we are left with 445 erroneously POStagged words.
From those, about 50%, or 233 tobe exact, are errors in sentences with code-switches.We consider this to be a strong indication of thecomplexity that intrasentential switches add to thetask of POS tagging.
For the taggers, these sentencesare incomplete, or ill-formed, since they have frag-ments with foreign words and thus, they fail to iden-tify them.
The rest of the oracle mistakes can not beattributable to a single cause.
Some are fragmentedsentences, and some are due to errors inherent of thetagger, but nothing is particulary salient about them.The language identification methods share, ofcourse, the same mistakes made by the oracle, plus342 more, for a total of 787 (in the case of thedictionary-based language identification).
The chal-lenge of POS tagging code-switched text is more ev-ident for this method.
Out of the mistakes made bythe language identification method, 540 lie in sen-tences with code-switching, that is, nearly 70% ofthe mistakes.
For 307 of these mistakes the right1057POS tag was available from one of the taggers.Some typical examples of these errors are words thatbelong to both languages, such as ?a?, ?no?, ?me?and ?con?.The ML approach outperformed both the lan-guage identification method and the oracle.
Analyz-ing the predictions made by SVM we verified thatout of the 445 errors made by the oracle, SVM cor-rectly tagged 223, the majority of which are words insentences with code-switching (142 words).
Whencompared against the errors from the method basedon language identification, SVM correctly tagged481 words out of the 787, 374 of which are wordsin sentences with code-switches.
In summary, theML approach is more robust to code-switched sen-tences.
Note that we did find some errors made bythe ML approach that are not shared by the oracleor the language identification method, a total of 105.Some of these mistakes are due to inconsistencieson the human-annotated tags.
For instance, in mostcases slang words such as ?gonna?
and ?wanna?
arelabeled as unknown words, but we found that thesewords were labeled as verbs in a few cases.
Not sur-prisingly this caused the ML algorithm to fail, sincethese class labels were misleading.
The majority ofthe mistakes, however, seem to be due to systematicmistakes by the POS taggers.One last remark is regarding our decision to find amethod for successfully exploiting the existing tag-gers for POS tagging Spanglish text.
Our origi-nal motivation came from the lack of linguistic re-sources to process Spanglish text.
However, we didtrain from scratch a sequential model for POS tag-ging Spanglish, namely Conditional Random Fields(CRFs) (Lafferty et al, 2001).
We used MALLET(McCallum, 2002) for this experiment and the sametraining/testing partitions used in the experiment re-ported in Table 3.
The CRF POS tagger was trainedusing capitalization information and the previous to-ken as context.
The average accuracy of this CRFwas 81%, which is lower than the language identifi-cation heuristic.
We believe that this low accuracy isdue to the lack of a representative sample of anno-tated Spanglish.
It will be interesting to see if whenmore data becomes available the ML algorithms stillyield the best results.8 ConclusionsCode-switching is a fresh and exciting research areathat has received little attention in the language pro-cessing community.
Research on this topic has manyinteresting applications, including automatic speechrecognition, machine translation, and computer as-sisted language learning.
In this paper we presentpreliminary work towards developing a POS taggerfor English-Spanish code-switched text that, to thebest of our knowledge, is the first effort towards thisend.We explored different heuristics for taking advan-tage of existing linguistic resources for English andSpanish with unimpressive results.
A simple word-level language identification strategy outperformedall heuristics tested.
But the best results, even bet-ter than the oracle, were achieved by using machinelearning using the output of monolingual POS tag-gers as input features.In the error analysis we showed that most ofthe mistakes made by the language identificationmethod, and the oracle itself, occur in sentences withintrasentential code-switching, showing the diffi-culty of the task.
In contrast, our machine learningapproach was less sensitive to the complexity of thisalternation pattern.There is still a lot of work to do in this area.
Ourongoing efforts include gathering a larger corpus,with different speakers and conversational styles, aswell as written forms of code-switching from blogsand Internet forums.
In addition, we are exploringthe use of context information.
The features we arecurrently using to represent each word do not takeinto account the context surrounding the word.
Wewant to test if by using contextual features we canfurther improve our results.In this study we focused on code-switching, butborrowing is another complex language alternationpattern that we want the POS tagger to handle.
Weare working on developing a special method foridentification and morphological analysis of borrow-ings.
This method will help increase the accuracy ofthe POS tagger.Spanish-English is not the only popular combi-nation of languages.
An interesting line of futurework would be to explore if the method presentedhere can be adapted to different language combi-1058nations.
Moreover, multilingual communities willcode-switch among more than two codes and thisposes fascinating research challenges as well.AcknowledgementsWe are grateful to Ray Mooney, Melissa Sher-man and the four anonymous reviewers for insight-ful comments and suggestions.
Special thanks toBrenda Medina and Nicolle Whitman for helpingwith some experiments.
This research is supportedby the National Science Foundation under grant0812134.ReferencesArdila, A.
(2005) Spanglish: an anglicized dialect.
His-panic Journal of Behavioral Sciences, 27(1): 60?81.Brants, T. (2000) TnT - a statistical part-of-speech tagger.In Sixth Applied Natural Language Processing Confer-ence ANLP-2000 Seatle, WA.Brill, E. (1990) A simple rule-based part-of-speech tag-ger.
In 3rd Conference on Applied Natural LanguageProcessing, pp.
152?155.
Trento, Italy.Carreras, X. and Padro?, L. (2002) A flexible distributedarchitecture for natural language analyzers.
In ThirdInternational Conference on Language Resources andEvaluation, LREC-02, pp.
1813?1817.
Las Palmas deGran Canaria, Spain.Charniak, E. (1993) Equations for part-of-speech tag-ging.
In 11th National Conference on AI, pp.
784?789.Ervin, S. and Osgood, C. (1954) Second language learn-ing and bilingualism.
Journal of abnormal and socialphsychology, Supplement 49, pp.
139?146.Espinosa, A.
(1917) Speech mixture in New Mexico: theinfluence of English language on New Mexican Span-ish.
In H. Stevens and H. Bolton, (eds.
), The PacificOcean in History, pp.
408?428.Franco, J.C. and Solorio T. (2007) Baby-steps towardsbuilding a Spanglish language model.
In 8th Interna-tional Conference on Computational Linguistics andIntelligent Text Processing, CICLing-2007, pp.
75?84.Mexico City, Mexico.Friedman, J., Hastie, T., and Tibshirani, R. (1998) Addi-tive logistic regression: a statistical view of boosting.Technical Report, Stanford University.Godfrey, J., Holliman, E. and McDaniel, J.
(1992)Switchboard: Telephone speech corpus for researchdevelopment.
In ICASSP, pp.
517?520, San Francisco,CA, USA.Goyal, P., Mital, Manav R., Mukerjee, A., Raina, AchlaM., Sharma, D., Shukla, P. and Vikram, K. (2003) Abilingual parser for Hindi, English and code-switchingstructures.
In Computational Linguistics for SouthAsian Languages ?Expanding Synergies with Europe,EACL-2003 Workshop, Budapest, Hungary.Grosjean, F. (1982) Life with Two Languages: An Intro-duction to Bilingualism.
Harvard University Press.Gumperz, J. J. and Hernandez-Chavez, E. (1971) Cogni-tive aspects of bilingual communication.
Oxford Uni-versity Press, London.Gumperz, J. J.
(1964) Linguistic and social interaction intwo communities.
In John J. Gumperz (ed.
), Languagein social groups, pp.
151?176, Stanford.
Stanford Uni-versity Press.Gumperz, J. J.
(1971) Bilingualism, bidialectism andclassroom interaction.
In Language in social groups,pp.
311?339, Stanford.
Stanford University Press.Joshi, A. K. (1982) Processing of sentences with in-trasentential code-switching.
In Ja?n Horecky?
(ed.
),COLING-82, pp.
145?150, Prague.Kucera, H. and Francis, W. N. (1967) Computationalanalysis of present-day American English.
Brown Uni-versity Press.Lafferty, J. and McCallum, A. and Pereira F. (2001) Con-ditional random fields: Probabilistic models for seg-menting and labeling sequence data.
In 18th ICML,pp.
282?289.
MA, USA.Lipski, J. M. (1978) Code-switching and the problem ofbilingual competence.
In M. Paradis (ed.
), Aspects ofbilingualism, pp.
250?264, Columbia, SC.
Hornbeam.McCallum, A.
(2002) MALLET: A Machine Learningfor Language Toolkit.
Retrieved January 7, 2008 fromhttp://mallet.cs.umass.eduPaul, D. B. and Baker, J. M. (1992) The design of theWall Street Journal-based CSR corpus.
In HLT?91:workshop on speech and Natural Language pp.
357?362, Morristown, NJ, USA.Poplack, S., Sankoff, D. and Miller, C. (1988) The socialcorrelates and linguistic processes of lexical borrowingand assimilation.
Linguistics, 26(1): 47?104.Poplack, S. (1980) Sometimes I?ll start a sentence inSpanish y termino en espan?ol: toward a typology ofcode-switching.
Linguistics, 18(7/8): 581?618.Poplack, S. (1981) Syntactic structure and social functionof code-switching.
In R. Duran (ed.
), Latino discourseand communicative behavior, pp.
169?184, Norwood,NJ.
Ablex.Quinlan, J. R. (1986) Induction of decision trees.
Ma-chine Learning, 1: 81?106.Ratnaparkhi, A.
(1996) A maximum entropy modelfor part-of-speech tagging.
In EMNLP, pp.
133?142,Philadelphia, PA, May.Rosner, M. and Farrugia, P. (2007) A tagging algorithmfor mixed language identification in a noisy domain.1059In INTERSPEECH 2007, pp.
190?193, Antwerp, Bel-gium.Sankoff, D. (1968) Social aspects of multilingualism inNew Guinea.
Ph.D. thesis, McGill University.Sankoff, D. (1981) A formal grammar for codeswitching.Papers in Linguistics: International Journal of Humancommunications, 14(1): 3?46.Sankoff, D. (1998a) A formal production-based explana-tion of the facts of code-switching.
Bilingualism, Lan-guage and Cognition, 1: 39?50.
Cambridge UniversityPress.Sankoff, D. (1998b) The production of code-mixed dis-course.
In 36th ACL, volume I, pp.
8?21, Montreal,Quebec, Canada.Schmid, H. (1994) Probabilistic part-of-speech taggingusing decision trees.
In International Conference onNew Methods in Language Processing, Manchester,UK.Scho?lkopf, B. and Smola, A. J.
(2002) Learning with Ker-nels: Support Vector Machines, Regularization, Opti-mization and Beyond.
MIT Press.Toribio, A. J.
(2001a) Accessing Spanish-English code-switching competence.
International Journal of Bilin-gualism, 5(4):403?436.Toribio, A. J.
(2001b) On the emergence of bilingualcode-switching competence.
Bilingual Language andCognition, 4(3):203?231.U.S.
Census Bureau.
(2003) Language use and En-glish speaking ability: 2000.
Retrieved October 30,2006 from http://www.census.gov/prod/2003pubs/c2kbr-29.pdf.Witten, I. H. and Frank, E. (1999) Data Mining, Practi-cal Machine Learning Tools and Techniques with JavaImplementations.
Morgan Kaufmann.Wolpert, D. H. (1992) Stacked Generalization.
NeuralNetworks, 5(2):241?259.1060
