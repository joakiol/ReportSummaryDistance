Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pp.
1161?1165,Prague, June 2007. c?2007 Association for Computational LinguisticsPro3Gres Parser in the CoNLL Domain Adaptation Shared TaskGerold Schneider and Kaarel Kaljurand and Fabio Rinaldi and Tobias KuhnInstitute of Computational Linguistics, University of ZurichBinzmu?hlestrasse 14CH - 8050 Zurich, Switzerland{gschneid,kalju,rinaldi,tkuhn}@ifi.uzh.chAbstractWe present Pro3Gres, a deep-syntactic, fastdependency parser that combines a hand-written competence grammar with proba-bilistic performance disambiguation and thathas been used in the biomedical domain.
Wediscuss its performance in the domain adap-tation open submission.
We achieve aver-age results, which is partly due to difficultiesin mapping to the dependency representationused for the shared task.1 IntroductionThe Pro3Gres parser is a dependency parser thatcombines a hand-written grammar with probabilis-tic disambiguation.
It is described in detail in(Schneider, 2007).
It uses tagger and chunkerpre-processors ?
parsing proper happens only be-tween heads of chunks ?
and a post-processor graphconverter to capture long-distance dependencies.Pro3Gres is embedded in a flexible XML pipeline.It has been applied to many tasks, such as parsingbiomedical literature (Rinaldi et al, 2006; Rinaldiet al, 2007) and the whole British National Cor-pus, and has been evaluated in several ways.
Wehave achieved average results in the CoNLL do-main adaptation track open submission (Marcus etal., 1993; Johansson and Nugues, 2007; Kulick etal., 2004; MacWhinney, 2000; Brown, 1973).
Theperformance of the parser is seriously affected bymapping problems to the particular dependency rep-resentation used in the shared task.The paper is structured as follows.
We give a briefoverview of the parser and its design policy in sec-tion 2, we describe the domain adaptations that wehave used in section 3, comment on the results ob-tained in section 4 and conclude in section 5.2 Pro3Gres and its Design PolicyThere has been growing interest in exploring thespace between Treebank-trained probabilistic gram-mars (e.g.
(Collins, 1999; Nivre, 2006)) and formalgrammar-based parsers integrating statistics (e.g.
(Miyao et al, 2005; Riezler et al, 2002)).
Wehave developed a parsing system that explores thisspace, in the vein of systems like (Kaplan et al,2004), using a linguistic competence grammar anda probabilistic performance disambiguation allow-ing us to explore interactions between lexicon andgrammar (Sinclair, 1996).
The parser has been ex-plicitly designed to be deep-syntactic like a formalgrammar-based parser, by using a dependency rep-resentation that is close to LFG f-structure, but atthe same time mostly context-free and integratingshallow approaches and aggressive pruning in or-der to keep search-spaces small, without permittingcompromise on performance or linguistic adequacy.
(Abney, 1995) establishes the chunks and dependen-cies model as a well-motivated linguistic theory.
Thenon-local linguistic constraints that a hand-writtengrammar allows us to formulate, e.g.
expressingX-bar principles or barring very marked construc-tions, further reduce parsing time by at least an orderof magnitude.
Since the grammar is on Penn tags(except for few closed classed words, e.g.
allow-ing including to function as preposition) the effortfor writing it manually is manageable.
It has beendeveloped from scratch in about a person month,1161Figure 1: Pro3Gres parser flowchartusing traditional grammar engineering developmentcycles.
It contains about 1000 rules, the number islargely so high due to tag combinatorics: for ex-ample, the various subject attachment rules combin-ing a subject ( NN, NNS, NNP, NNPS) and a verb( VBZ, VBP, VBG, VBN, VBD) are all very simi-lar.The parser is fast enough for large-scale appli-cation to unrestricted texts, and it delivers depen-dency relations which are a suitable base for arange of applications.
We have used it to parse theentire 100 million words British National Corpus(http://www.natcorp.ox.ac.uk) and similar amountsof biomedical texts.
Its parsing speed is about500,000 words per hour.
The flowchart of the parsercan be seen in figure 1.Pro3Gres (PRObabilistic PROlog-implementedRObust Grammatical Role Extraction System) usesa dependency representation that is close to LFGf-structure, in order to give it an established lin-guistic background.
It uses post-processing graphstructure conversions and mild context-sensitivity tocapture long-distance dependencies.
We have ar-gued in (Schneider, 2005) that LFG f-structures canbe parsed for in a completely context-free fashion,except for embedded WH-questions, where a de-vice such as functional uncertainty (Kaplan and Za-enen, 1989) or the equivalent Tree-Adjoining Gram-mar Adjoining operation (Joshi and Vijay-Shanker,1989) is used.
In Dependency Grammar, this deviceis also known as lifting (Kahane et al, 1998; Nivreand Nilsson, 2005).We use a hand-written competence grammar,combined with performance-driven disambiguationobtained from the Penn Treebank (Marcus etal., 1993).
The Maximum-Likelihood Estimation(MLE) probability of generating a dependency re-lation R given lexical heads (a and b) at distance (inchunks) ?
is calculated as follows.p(R, ?|a, b) ?= p(R|a, b) ?
p(?|R) =#(R, a, b)?ni=1#(Ri, a, b)?#(R, ?
)#RThe counts are backed off (Collins, 1999; Merloand Esteve Ferrer, 2006).
The backoff levels includesemantic classes from WordNet (Fellbaum, 1998):we back off to the lexicographer file ID of the mostfrequent word sense.
An example output of theparser is shown in figure 2.3 Domain AdaptationBased on our experience with parsing texts form thebiomedical domain, we have used the following twoadaptations to the domain of chemistry.
(Hindle and Rooth, 1993) exploit the fact that insentence-initial NP PP sequences the PP unambigu-ously attaches to the noun.
We have observed that insentence-initial NP PP PP sequences, also the sec-ond PP frequently attaches to the noun, the nounitself often being a relational noun.
We have thusused such sequences to learn relational nouns fromthe unlabelled domain texts.
Relational nouns areallowed to attach several argument PPs in the gram-mar, all other nouns are not.Multi-word terms, adjective-preposition construc-tions and frequent PP-arguments have strong collo-cational force.
We have thus used the collocationextraction tool XTRACT (Smadja, 2003) to discovercollocations from large domain corpora.
The prob-ability of generating a dependency relation is aug-mented for collocations above a certain threshold.Since the tagging quality of the Chemistry testsetis high, the impact of multi-word term recognitionwas lower than the biomedical domain when using astandard tagger, as we have shown in (Rinaldi et al,2007).For the CHILDES domain, we have not used anyadaptation.
The hand-written grammar fares quitewell on most types of questions, which are very fre-quent in this domain.
In the spirit of the sharedtask, we have not attempted to correct tagging errors,which were frequent in the CHILDES domain.
Wehave restricted the use of external resources to thehand-written, domain-independent grammar, and toWordNet.
Due to serious problems in mapping our1162Figure 2: Example of original parser outputLFG f-structure based dependencies to the CoNLLrepresentation, much less time than expected wasavailable for the domain adaptation.4 Our ResultsWe have achieved average results: Labeled attach-ment score: 3151 / 5001 * 100 = 63.01, unlabeled at-tachment score: 3327 / 5001 * 100 = 66.53, label ac-curacy score: 3832 / 5001 * 100 = 76.62.
These re-sults are about 10 % below what we typically obtainwhen using our own dependency representation orGREVAL (Carroll et al, 2003), a deep-syntactic an-notation scheme that is close to ours.
Detailed eval-uations are reported in (Schneider, 2007).
Our map-ping was quite poor, especially when conjunctionsare involved.
Also punctuation is attached poorly.5.7 % of all dependencies remained unmapped (un-known in the figure).
We give an overview of the therelation-dependent results in figures 1 and 2.Mapping problems include the following exam-ples.
First, headedness is handled very differently:while we assume auxiliaries, prepositions and co-ordinations to be dependents, the CoNNL repre-sentation assumes the opposite, which leads to in-correct mapping under complex interactions.
Sec-ond, the semantics of parentheticals (PRN) partlyremains unclear.
In Quinidine elimination wascapacity limited with apparent Michaelis constant(appKM) of 2.6 microM (about 1.2 mg/L) the goldstandard annotates the second parenthesis as paren-thetical, but the first as nominal modification, al-though both may be said to have appositional char-acter.
Third, we seem to have misinterpreted theroles of ADV and AMOD, as they are often mutu-ally exchanged.
Fourth, the logical subject (LGS)is sometimes marked on the by-PP (... are stronglyinhibited by-LGS carbon monoxide) and sometimeson the participle (... are increased-LGS by pre-deprel gold correct system recall (%) prec.
(%)ADV 366 212 302 57.92 70.20AMOD 87 8 87 9.20 9.20CC 11 0 0 0.00 NaNCOORD 402 233 342 57.96 68.13DEP 9 0 0 0.00 NaNEXP 2 0 0 0.00 NaNGAP 14 0 0 0.00 NaNIOBJ 3 0 0 0.00 NaNLGS 37 0 0 0.00 NaNNMOD 1813 1576 1763 86.93 89.39OBJ 185 146 208 78.92 70.19P 587 524 525 89.27 99.81PMOD 681 533 648 78.27 82.25PRN 34 13 68 38.24 19.12ROOT 195 138 190 70.77 72.63SBJ 279 217 296 77.78 73.31VC 129 116 136 89.92 85.29VMOD 167 116 149 69.46 77.85unknown 0 0 287 NaN 0.00Table 1: Prec.&recall of DEPRELtreatment) in the gold standard.
Relations betweenheads of chunks, which are central for predicate-argument structures which Pro3Gres aims to re-cover, such as SBJ, NMOD, ROOT, perform betterthan those for which Pro3Gres was not originallydesigned, particularly ADV, AMOD, PRN, P. Perfor-mance on COORD was particularly disappointing.Generally, mapping problems between different rep-resentations would be smaller if one used a depen-dency representation that maximally abstracts awayfrom form to function, for example (Carroll et al,2003).We have obtained results slightly above averageon the CHILDES domain, although we did not adaptthe parser to this domain in any way (unlabeled at-tachment score: 3013 / 4999 * 100 = 60.27 %).The hand-written grammar, which includes rules formost types of questions, fares relatively well on thisdomain since questions are rare in the Penn Tree-bank (see (Hermjakob, 2001)).
Pro3Gres has beenemployed for question parsing at a TREC confer-ence (Burger and Bayer, 2005).1163deprel gold correct system recall (%) prec.
(%)ADV 366 161 302 43.99 53.31AMOD 87 5 87 5.75 5.75CC 11 0 0 0.00 NaNCOORD 402 170 342 42.29 49.71DEP 9 0 0 0.00 NaNEXP 2 0 0 0.00 NaNGAP 14 0 0 0.00 NaNIOBJ 3 0 0 0.00 NaNLGS 37 0 0 0.00 NaNNMOD 1813 1392 1763 76.78 78.96OBJ 185 140 208 75.68 67.31P 587 221 525 37.65 42.10PMOD 681 521 648 76.51 80.40PRN 34 12 68 35.29 17.65ROOT 195 138 190 70.77 72.63SBJ 279 190 296 68.10 64.19VC 129 116 136 89.92 85.29VMOD 167 85 149 50.90 57.05unknown 0 0 287 NaN 0.00Table 2: Prec.&recall of DEPREL+ATTACHMENT5 ConclusionWe have described the Pro3Gres parser.
We haveachieved average results in the shared task with rel-atively little adaptation.
Mapping to different repre-sentations is an often underestimated task.
Our per-formance on the CHILDES task, where we did notadapt the parser, indicates that hand-written, care-fully engineered competence grammars may be rel-atively domain-independent while performance dis-ambiguation is more domain-dependent.
We willadapt the parser to further domains and include moreunsupervised learning methods.ReferencesSteven Abney.
1995.
Chunks and dependencies: Bring-ing processing evidence to bear on syntax.
In JenniferCole, Georgia Green, and Jerry Morgan, editors, Com-putational Linguistics and the Foundations of Linguis-tic Theory, pages 145?164.
CSLI.R.
Brown.
1973.
A First Language: The Early Stages.Harvard University Press.John D. Burger and Sam Bayer.
2005.
MITRE?s Qandaat TREC-14.
In E. M. Voorhees and Lori P. Buck-land, editors, The Fourteenth Text REtrieval Confer-ence (TREC 2005) Notebook.John Carroll, Guido Minnen, and Edward Briscoe.
2003.Parser evaluation: using a grammatical relation anno-tation scheme.
In Anne Abeille?, editor, Treebanks:Building and Using Parsed Corpora, pages 299?316.Kluwer, Dordrecht.Michael Collins.
1999.
Head-Driven Statistical Modelsfor Natural Language Parsing.
Ph.D. thesis, Univer-sity of Pennsylvania, Philadelphia, PA.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
MIT Press, Cambridge, MA.Ulf Hermjakob.
2001.
Parsing and question classifica-tion for question answering.
In Proceedings of theACL 2001 Workshop on Open-Domain Question An-swering, Toulouse, France.Donald Hindle and Mats Rooth.
1993.
Structural ambi-guity and lexical relations.
Computational Linguistics,19:103?120.R.
Johansson and P. Nugues.
2007.
Extendedconstituent-to-dependency conversion for English.
InProc.
of the 16th Nordic Conference on ComputationalLinguistics (NODALIDA).Aravind K. Joshi and K. Vijay-Shanker.
1989.
Treat-ment of long-distance dependencies in LFG and TAG:Functional uncertainty in LFG is a corollary in TAG.In Proceedings of ACL ?89.Sylvain Kahane, Alexis Nasr, and Owen Rambow.
1998.Pseudo-projectivity: A polynomially parsable non-projective dependency grammar.
In Proceedings ofCOLINGACL, volume 1, pages 646?652, Montreal.Ronald Kaplan and Annie Zaenen.
1989.
Long-distancedependencies, constituent structure, and functional un-certainty.
In Mark Baltin and Anthony Kroch, editors,Alternative Concepts of Phrase Structrue, pages 17 ?42.
Chicago University Press.Ron Kaplan, Stefan Riezler, Tracy H. King, JohnT.
Maxwell III, Alex Vasserman, and Richard Crouch.2004.
Speed and accuracy in shallow and deepstochastic parsing.
In Proceedings of HLT/NAACL2004, Boston, MA.S.
Kulick, A. Bies, M. Liberman, M. Mandel, R. Mc-Donald, M. Palmer, A. Schein, and L. Ungar.
2004.Integrated annotation for biomedical information ex-traction.
In Proc.
of the Human Language Technol-ogy Conference and the Annual Meeting of the NorthAmerican Chapter of the Association for Computa-tional Linguistics (HLT/NAACL).B.
MacWhinney.
2000.
The CHILDES Project: Toolsfor Analyzing Talk.
Lawrence Erlbaum.M.
Marcus, B. Santorini, and M. Marcinkiewicz.
1993.Building a large annotated corpus of English: the PennTreebank.
Computational Linguistics, 19(2):313?330.Paola Merlo and Eva Esteve Ferrer.
2006.
The notion ofargument in PP attachment.
Computational Linguis-tics, 32(2):341 ?
378.Yusuke Miyao, Takashi Ninomiya, and Jun?ichi Tsujii.2005.
Corpus-oriented grammar development for ac-quiring a Head-driven Phrase Structure Grammar from1164the Penn Treebank.
In Keh-Yih Su, Jun?ichi Tsujii,Jong-Hyeok Lee, and Oi Yee Kwong, editors, NaturalLanguage Processing - IJCNLP 2004, pages 684?693.Springer.Joakim Nivre and Jens Nilsson.
2005.
Pseudo-projectivedependency parsing.
In Proceedings of the 43rdAnnual Meeting of the Association for Computa-tional Linguistics (ACL?05), pages 99?106, Ann Ar-bor, Michigan, June.
Association for ComputationalLinguistics.Joakim Nivre.
2006.
Constraints on non-projective de-pendency parsing.
In Proceedings of the EuropeanChapter of the Association of Computational Linguis-tics (EACL) 2006, pages 73 ?
80, Trento, Italy.
Asso-ciation for Computational Linguistics.Stefan Riezler, Tracy H. King, Ronald M. Kaplan,Richard Crouch, John T. Maxwell, and Mark John-son.
2002.
Parsing the Wall Street Journal using aLexical-Functional Grammar and discriminative esti-mation techniques.
In Proc.
of the 40th Annual Meet-ing of the Association for Computational Linguistics(ACL?02), Philadephia, PA.Fabio Rinaldi, Gerold Schneider, Kaarel Kaljurand,Michael Hess, and Martin Romacker.
2006. .
an en-vironment for relation mining over richly annotatedcorpora: the case of GENIA.
BMC Bioinformatics,7(Suppl 3):S3.Fabio Rinaldi, Gerold Schneider, Kaarel Kaljurand,Michael Hess, Christos Andronis, Ourania Konstanti,and Andreas Persidis.
2007.
Mining of functionalrelations between genes and proteins over biomedicalscientific literature using a deep-linguistic approach.Journal of Artificial Intelligence in Medicine, 39:127?
136.Gerold Schneider.
2005.
A broad-coverage, representa-tionally minimal LFG parser: chunks and F-structuresare sufficient.
In Mriram Butt and Traci HollowayKing, editors, The 10th international LFG Conference(LFG 2005), Bergen, Norway.
CSLI.Gerold Schneider.
2007.
Hybrid Long-Distance Func-tional Dependency Parsing.
Doctoral Thesis, Instituteof Computational Linguistics, University of Zurich.accepted for publication.John Sinclair.
1996.
The empty lexicon.
InternationalJournal of Corpus Linguistics, 1, 1996.Frank Smadja.
2003.
Retrieving collocations from text:Xtract.
Computational Linguistics, 19:1, Special issueon using large corpora:143?177.1165
