DOCUMENT CLASSIFICATION BYMACHINE:Theory and PracticeLou ise  Guthr ieE lber t  Wa lkerNew Mex ico  S ta te  Un ivers i tyLas  Cruces ,  New Mex ico  88001Joe  Guthr ieUn ivers i ty  of ' lb.xas a t  E1 PasoE1 Paso ,  'l>xa~s 79968AbstractIn this note, we present results concerning the the-ory and practice of determining for a given documentwhich of several categories it best fits.
We describe amathematical  model of classification schemes and theone scheme which can be proved optimal among allthose based on word frequencies.
Finally, we reportthe results of an experiment which illustrates the effi-cacy of this classification method.TOPICAL PAPER,Subject Area: TEXT PROCESSING1 In t roduct ionA problem of considerable interest in ComputationalLinguistics is thai; of classifying documents via com-puter processing \[lIayes, 1992; Lewis 1992; Walkerand Amsler, 1986\].
Siml>ly put, it is this: a docu-ment is one of several types, and a machine process-ing of the document is to determine of wbicll type.In this note, we present results concerning the theoryand practice of classification schemes t)ased on wordfrequencies.
The theoretical results are about matlt.ematical models of classification schemes, and apply'to any document classitication problem to tile extentthat the model represents faithfully that problem.
Onemust cimosc a model that not only provides a math-ematical description of the problem at imnd, but onein which the desired calculations can be made.
For ex-ample, in document classificatiou, it would bc nice tobe able to calcnlatc the probability that  a documenton subject i will be classified as on subject i. Further,it would be comforting to know that  there is no bet-ter scheme than the ouc being used.
Our models havethese characteristics.
They are siml)lc, the calculationsof probabilities of correct document classification arestraightforward, and we imve proved that  there are noschemes using tile same information that  have bettersuccess rates.
In an experiment the scheme was u~dto classify two types of documents, and was found towork very well indeed.2 The Descr ip t ion  of a Classifi-cat ion SchemeSuppose that we must classify a document into one of ktypes.
These types arc known.
Here, k is any positiveinteger at least 2, and a typical value might be any-where from 2 to 10.
I)enote these types T1,7~,.
.
.
,  7l'k.The set of words in tile language is broken into m dis-joint subsets W1, W2, .
.
.
,  W,,.
Now from a host ofdoc-umeuts, or a large body of literature, on subject ~/~, tilefrequencies Pij of words in W i are determined.
So withsubject ~ we have associated the vector of frequencies(pil, Pi2, .
.
?
,P im),  and of cour~ p i l+p i2+.
.
.+Pim = 1.Now, given a document on one of the possible k sub-jects, it is classified as follows.
The document has nwords in it, nl  words from I4/1, n2 words from W~,.
.
.
,and nm words from Win.
Based on this information,a calculation is made to determine from which sub-ject the document is most likely to have come, and isso classified.
This calculation is key: there arc manypossible calculations on which a classification can bemade, but some are better titan others.
We will provethat in this situation, there is a best one.We elaborate on a specific case which ~ems tohold promise.
The idea is that the frequencies(Pi l ,  Pi2, ?
.
.
,  pi,,,) will be ditferent enough from i to i todistinguish between types of documents.
From a docu-ment of word length n, let nj  be the number of words inWj.
Titus the vector of word frequencies for that  par-ticular document is (h i /n ,  n2 /n , .
.
.
,  nm/n) .
The wordfrequencies gfrom a document of type i should resem-ble the frequencies (Pi l ,  P lm.
.
.
,P im),  and indeed, theclassification scheme is to declare the documeut o heof type Ti if its freqnencies "most closely resemble" thefrequencies (Pl l ,  Pi2, ?
?
.
,  Pi,,).
Intuitively, if two of tilevectors are (Pil, P i2 , .
.
.
, P im)  very nearly equal, thenit will be difficult to distinguish documents of thosetwo types.
Thus the success of cla.ssification dependscritically on the vectors (p i l ,  p i '~ , .
.
.
,  p im) of frequen-cies.
Equivalently, the sets Wj are critical, and mustbe chosen with great care.
The particular situation wehave in mind is this.
Faeh of the types of documents i1059on a rather special topic, calling for a somewhat spe-cialized vocabulary.
The Language is broken into k + 1disjoint sets W1, Wu, .
.
.
,  Wk+l of words.
For i < k,the words in W/ are "specific" to subject i, and Wk+lconsists of tire remaining words in the language.
Nowfrom a host of documents, or a large body of literature,on the subject T/, we determine the frequencies pij ofwords in W/.
But first, the word sets Wi are needed,and it, is also from such bodies of text that they will bedetermined.
Doing this in a manner that is optimal forour models is a difficult problem, but doing it in sucha way that our models are very effective seems quiteroutine.So with subject Ti we have associated the vectorof frequencies (Pil, P i2, .
.
.
,P im),  the vector being oflength one more than the number of types of docu-ments.
Since the words in Wi are specific to documentsof type 7\], these vectors of frequencies should be quitedissimilar and allow a sharp demarkation between doc-ument ypes.
This particular scheme has the added ad-vantage that m is small, being k+l ,  only one more thanthe number of document ypes.
Further, our schemewill involve only a few hundred words, those that ap-pear in Wl, W2, .
.
.
,  Wk, with the remainder appearingin Wk+l.
This makes is possible to calculate the prob-abilities of correct classification of documents of eachparticular type.
Such calculations are intractable forlarge m, even on fast machines.
There are classificationschemes being used with m in the thousands, makingan exact mathematical  calculation of probabilities ofcorrect classification ext to impossible.
But with kand m small, say no more than 10, such calculationsare possible.3 The Mathemat ica l  Mode lA mathematical  description of the situation justdescribed is this.
We are given k multino-mial populations, with the i-th having frequencies(plr, pi~,.. .
,Pi ,~).
The i-th population may be en-visioned to be an infinite set consisting of m types ofelements, with the proportion of type j being Pij.
Weare given a random sample of size n from one of thepopulations, and are asked to determine from which ofthe populations it came.
If the sample came from pop-ulation i, then the probabil ity that it has nj elementsof type j is given by the formulan m (n!/,,, !
,~!..
.
n.~ !
)(P;~'PT~"" 'P , .
)'This is an elementary probabilistic fact.
If a sample tobe classified has nj elements of type j, we simply makethis calculation for each i, and judge the sample to befrom population i if the largest of the results was forthe i-th population.
Thus, the sample is judged to befrom the i-th population if the probabil ity of gettingthe particular n / 's  that  were gotten is the largest forthat  population.To determine which of(n!/nl!n2!
.
.n  IX\[,~'~,," .
.
.
.
p~,~,) ?
rn  "\]kYil  ~i2is the largest, it is only necessary to determine which ofn l  n~ r'.m the (Plr Pi2 " " "Pin, ) is largest, and that is an easy ma-chine calculation.
All numbers are known beforehandexcept the n i's, which are counted from the sample.Before i l lustrating success rates with some calcula-tions, some comments on our modeling of this docn-meat classification scheme are in order.
The i-th multi-nomial population represents text of type 7~.
This textconsists of m types of things, namely words from eachof the W i.
The frequencies (pit, Pi~,.. .
,pin,) give theproportion of words from the classes W1, W'2,.
.
.
,  Wmin text of type 7~.
A random sample of size n repre-sents a document 'of  word length n. This last repre-sentation is arguable: a document of length n is nota random sample of n words from its type of text.It is a structured sequence of such words?
The va-lidity of the model proposed depends on a documentreflecting the properties of a random sample in the fre-quencies of its words of each type.
Intuitively, longdocuments will do that?
Short ones may not.
Thesuccess of any implementation will hinge on the fre-quencies (Pit, P i2, .
.
.
,P im).
These frequencies mustdiffer enough from document ype to document ypeso that  documents ('an be distinguished on the basis ofthem.4 Some Calcu la t ionsWe now il lustrate with some calculations for a simplecase: there arc two kinds of documents, T1 and 7~, andthree kinds of words.
We have in mind here that Wjconsists of words specific to documents of type Tz, W:2specific to T2, and that  Wa consists of the remainingwords in the language.
So we have the frequencies(pu, pr2, w3) and (m~, m2, m3).
Of course vi.~ = ~-Pll -P i2 .
Now we are given a document hat we knowis either of type 711 or of type 7~, and we nmst discernwhich type it is on the basis of its word frequencies.Suppose it has nj words of type j ,  j = 1,2,3.
Wecalculate the numbersn l  n2  r~3 ti = Pil Pi2 Pi3for i = 1, 2, and declare the document to be of type 7~ ifti is the larger of the two.
Now what is the probabilityof success?
}tere is the calculation.
If a documentof size n is drawn from a trinomial population withparameters (p11, P12, pla), the probabil ity of gettingnl words of type l, n2 words of type 2, and n3 wordsof type 3 isn !
~l In  ll'~ !
n l  ~ na  ( ./ r. 2.
3.
)(PllP12P13).Thus to calculate the probabil ity of classifying sue-cessfidly a document of type 7'1 ms being of that type,we must add these expressions over all those triples(n l ,n2,  n3) for which tl is larger than t2.
This is a1060fairly easy coml)utation, and we have carried it out fora host of different p's and n's.
Table I contains resultsof some of these calculations.Table i gives the probability of classifying a doc-ument of type T1 as of type 7~, and of classifying adocument of type 7~ as of type '/~.
These probabili-ties are labeled Prob(f) and Prob(2), respcctively.
Ofcourse, here we get for free the probabil ity that a docu-ment of type 7'1 will be classified ms of type 7~, namely1- Prob(1).
Similarly, 1~- l'rob(2) is tile probabilitythat a document of type 7.)
will be classified as of type7\].
The Plj are the frequencies of words from Wj fordocuments of type '/~, and n is the muuber of words inthe document.Table 1Ptj .08 .04 .88P2j .03 .06 .91n 50 100 200 400Prob(1) .760 .871 .951 .991Prob(2) .842 .899 .959 .992\[ ~,,.o~(2).10 .03 .87.02 .05 .9350 100 200 400.894 .963 .995 .999.920 .975 .997 .999I Plj .08 .04 .88 p~2 .07 .04 .89I n 50 100 200 400 Prob(1) .575 .553 .595 .638 Prob(2) .533 .598 .617 .658There are several things worth noting in Table 1.The frequencies used in tile table were chosen to il-lustrate the behavior of the scheme, att(l not necessar-ily to reflect document claqsification reality, l\[owevcr,consider the first set of l?equeneies (.08, .
()4, .88) and(.03, .06, .91).
This represents a circnmstan(-c wheredocuments of type T1 have eight percent of their wordsspecific to that subjcct, and four percent specific to theother subject.
Documents of type 7.)
have six percentof their words specific to its subject, and three percentspecific to the other sutlject.
These percentages seemto be easily attainable.
Our scheme correctly classifiesa document of length 200 and of type q'l 95.1 percent ofthe time, and a docmneut of length 400 99.1 percent ofthe time.
The last set of frequencies, (.08, .04, .88) and(.07, .04, .89) arc Mrnost alike, and as the table shows,do not serve to classify documents correctly with highprobability.
In general, the probabilities of success arcremarkably high, even for relatively small n, and in theexperiment reported on in Section 6, it was easy to findword scts with satisfatory frequencies.It is a fact that  the probabil ity of success canbe made as close to 1 as desired by taking n largeenough, assuming that  (Ptt, Pv~, Pro) is not identi-cal to (P'21, P2~, P23).
llowever, since for reasonablefrequencies, tile probabilities of success are high for njust  a few hundred, this snggests that  long documentswould not have to he completely tabulated in ordcr tobe classified correctly with high probability.
One couldjust use.
a random sample of appropriate size from tiledocument.The following table give some success rates for thecase where thcre are three kinds of documents and fourword cla.,~qes.
The rates are surprisingly high.Table 2PU .05 .03 .02 .90P2j .01 .06 .01 .92P~L._  .04 .02 .08 .86n 50 1O0 200 400Prob(1) .703 .871 .966 .997Prob(2) .884 .938 .985 .999Prob(3) .826 .922 .981 .998Plj .05 .03 .02 .90P'zj .01 .05 .0l .93P3j .03 .02 .05 .90n 50 100 200 400l'rob(l) .651 .784 .906 .978l'rob(2) .826 .917 .977 .9981"rob(3) .697 .815 .916 .9785 Theoret i ca l  Resu l tsIn this section, we prove our opti lnality result.
Butfirst we must give it a precise mathematical  formu-lation. '
lb say that there is no better claqsificationschcme than some given one, wc nmst know not onlywhat "better" means, we must kuow precisely whata classitication schenu~ is.
The setup is as in Sec--tion 3.
We have k multinomial populations withfrequencies (Pil,Plu,...,plm), i = 1 ,2 , .
.
.
, k .
We, aregiven a random sample of size n from one of thepopulations and are forced to assert from wMch oneit camc.
Tbe infi)rmation at our disposal, besidesthe set of frequencies (pit,pin,...,pim), is, for eachj, thc number nj of elements of type j ill the sam-pie.
So the inlormation Lfrom the sample is the tu-pie (hi ,  n=,, .
.
.
,n , , ) .
Our scheme for specifying frontwhich population it came is to say that it came?
t \ /  I ' l l  t l :~  * t~m front population i if (n !
/n l  !n~!
..
n.~.
)tpi~ Piu " 'Pi,,, )is max imnm over the i's.
This then, determineswhich (n~, nu .
.
.
.
, n. ,)  re.nits in which cla.~sification.
()ur scheme partit ions the sample space, that is, theset of all the tuples (nl,n2 .
.
.
.
,n. , ) ,  into k pieces,1061the i-th piece being those tuples (n l ,n2 , .
.
.
,nm)for which (n!/nl!nz!."n,,,!
)(p:?l~p .
.
.
.
.
P~r~) is maxi-mum.
For a given sample (or document) size n, thisleads to the definition of a scheme as any partit ion{A1, A~ .
.
.
.
, Ak} of the set of tuples (nl,  n~,.
.
.
,  nm)for which ~i  ni = n into k pieces.
The procedure thenis to classify a sample as coming from the i-th pop-ulation if the tuple (hi ,  n2 , .
.
.
,  am) gotten from thesample is in Ai.
It doesn't matter how this partit ionis arrived at.
Our method is via the probabilitiesrl m qi(nl, nu, .
.
.
,  nm) = (n!
/n l !n2!
."
nm!)(P~?P~?
""Pi,n ).There are many ways we could define optimality.A definition that  has particular charm is to define ascheme to be optimal if no other scheme has an higheroverall probabil ity of correct classification.
But in thissetup, we have no way of knowing the overall rate ofcorrect classification because we do not know what pro-portion of samples come from what populations.
So wecannot use that  definition.
An alternate definition thatmakes sense is to define a scheme to be optimal if noother scheme has, for each population, a higher proba-bility of correct classification of samples from that  pop-ulation.
But our scheme is optimal in a much strongersense.
We define a scheme A1,A2 , .
.
.
,Ak  to be opti-mal if for any other scheme B1, B2, ?
?., B~,~_~ P(AdTi) >_ ~ P(B i IT~) .Proofs of the theorems ill this note will be givenelsewhere, ..Theorem 1 Let T1,T2, .
.
.
,Tk be multinomial popu-lations with the i -  th population having frequencies(Pil ,Pi2 .
.
.
.
.
Pim).
For a random sample of size n fromone of these populations, let nj be the number of ele-ments of type j. Lett l  m qi(nl, n2 .
.
.
.
,nm) = ~:n I/n./1.1n^ l"'z.
n m "\]~vill~('~n~ vi2"~n.
.
.
.
Pim )"Thenspacebythe partition of the sample !
{(n l ,n2 , .
.
.
,n~)  : nj > 0, E jn j  = n} givenAi ~- {(nl, n2 .
.
.
.
.
am): qi(nl,n2 .
.
.
.
.
am)) >qj(nl ,  n2 , .
.
.
,  Urn) for i # j}is an optimal schente for determining from which ofthe populations a sample of size n came.An interesting feature of Table 1 is that for all fre-quencies Prob(1) + Prob(2) is greater for sample size100 than for sample size 50.
This supports our intu-ition that larger sample sizes should yield better re-sults.
This is indeed a fact.Theorem 2 The following inequality holds, withequality only in the trivial case that Pik ~--- Pjk for all i,j, and k,m~x(( ( ,  + 1 ) !
/ ( , , !n~!
?
?
?
n.,!)pT:p~?...
P,"2)  ->n-t-1max((n!/(nl !n~!
.
.
.
- , ,  .
, .
i ,  , ' i s  " " P i , ,  1,nwhere ~n+l  means to sum over those tuples (hi,  n~,?
?
.
, nm) whose sum is n+ 1, and ~n means to sumover those tuples (nl, n2, ?
.
.
, n~) whose sum is n.6 Pract ica l  Resu l tsOur theoretical results assure us that documents canbe classified correctly if we have appropriate sets ofwords.
We have algorithms which compute the proba-bility of classifying document types correctly given thedocument size and the probabil ity of some specializedsets of words appearing in the two document ypes.Tables 1 and 2 show some sample outputs from thatprogram.
Intuitively, we need sets of words whicb ap-pear much more often in one text type than tile other,but the words do not need to appear in either text typevery often.
Below we describe an experiment with twodocument collections that  indicates that  appropriateword sets can be chosen easily.
Moreover, in our sam-ple experiment, the word sets were chosen automati-cally and the classification scheme worked perfectly, aspredicted by our theoretical results.Two appropriate collections of text were availableat the Computing Research Laboratory.
The first wasmade up of 1000 texts on busine~ (joint ventures)/,from the DAR.PA T IPSTER project and the secondcollection consisted of 1100 texts from the MessageUnderstanding Conference (MUC) \[Sundheim, 1991\]describing terrorist incidents in South America.
Thebusiness texts were all newspaper articles, whereas theMUC texts were transmitted by teletype and camefrom various sources, such as excerpts from newspa-per articles, radio reports, or tape rccorded messages.The collections were prepared by human analysts whojudged the relevance of the documents in the collec-tions.
Each collection contained about half a millionwords.We removed any dates, annotations, or header infor-mation from the documents which uniquely identifiedit as being of one text type or another.
We dividedeach collection of texts in half to form two trainingsets and two test sets of documents, yielding four col-lections of about a quarter of a million words each.
Wetreated each of the training sets as one huge text andobtained frequency counts for each of the words in thetext.
Words were not stemmed and no stop list wasused.
Thc result was two lists of words with their cor-responding frequencies, one for the T IPSTER trainingset and one for the MUC training set.Our goal at this point was to choose two sets ofwords, which we call T IP-SET and MUC-SET, thatcould be used to distinguish the documents.
We knewfrom the results of TABLE 1 that if we could identifyone set of words (TIP-SET) that appeared in the TIP-1062STER documents with probability .1 and in the MUCdocuments with low probability (say .03 or less) andanother set (MUC-SET) that appeared with probabil-ity .1 in the MUC documents and a low probability(say .03 or less) in the T IPSTER documents, that wecould achieve perfect or nearly perfect classification.We used a simple heuristic in our initial tests: choosethe TIP-SET by choosing words which were among the300 most frequent in the T IPSTER training set andnot in the 500 most frequent in the MUC training set.We intended to vary the 300 and 500 to see if we couldchoose good sets.
However, this algorithm yielded aset of words that appeared with probability .13 in theT IPSTER training set and with probability .01 in theMUC training set.
Note that even though no stop listwas used when the frequency counts were taken, thisprocedure ffectively creates a stop list automatically.The same algorithm was used to create the MUC-SET:choose words from among the 300 most frequent in theMUC training set if they did not appear in tile 500most frequent in tim TIPSTER~ training set.Our theoretical results implied that we could classifyeach document ype correctly 99.99% or the time if wehad documents with at least 200 words.
Our averagedocument size in the two collections was 500 words.
Wethen tested the classification scheme on the remaininghalf (those not used for training) of each document set.Only one document was classitied ifferently from thetruman classification.When we read the text in question, it was our opin-ion that the original document classification by a hu-man was incorrect.
If we change the classificationof this text, then our document classitication schemeworked perfectly on 700 documents.
It should be notedthat the two document collections that were availableto us were on very different subject matter, so thechoice of the word sets was extremely easy.
We expectthat differentiating texts which are on related subjectareas will be much more difficult and we are developingretinements for this task.\[Walker and Amsler, 1986\] D. Walker and R. Amsler,The Use of Machine-Readable Dictionaries in Sublan-guage Analysis, Analyzing Language in l~eslricled Do-mains, Grishman and Kittredge, eds., Lawrence Erl-baum, I\[illsdale, NJ.7 References\[Hayes, 1992\] Philip Hayes, Intelligent tligh-Volumeq hxt Processing Using Shallow, Domain Specific Tech-niques, 7~xt-Based Intelligent Systems, P. Jacobs, cd.,Lawrence Erlbaum, Ilillsdale, N J, pp.
227- 241.\[Lewis, 1992\] David Lewis, Feature Selection andFeature Extraction for Text Categorization, Proceed-ings Speech and Natural Language Workshop, MorganKaufman, San Mateo, CA, February 1992, pp.
212-217.\[Sundheim, 1991\] Beth Sundheim, editor.
Proceedingsof the Third Message Understanding Evaluation andConference, Morgan Kaufman, Los Altos, CA, May1991.1063
