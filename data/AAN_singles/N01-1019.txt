Information-based Machine TranslationKeiko HORIGUCHISpoken Language Technology, Sony US Research Laboratories3300 Zanker RoadSan Jose, CA 95134keiko@slt.sel.sony.comAbstractThis paper describes an approach to MachineTranslation that places linguistic informationat its foundation.
The difficulty of translationfrom English to Japanese is illustrated withdata that shows the influence of variouslinguistic contextual factors.
Next, a methodfor natural language transfer is presented thatintegrates translation examples (representedas typed feature structures with source-targetindices) with linguistic rules and constraints.The method has been implemented, and theresults of an evaluation are presented.IntroductionHigh-quality automatic translation requires thedisambiguation of common, highly ambiguousverbs, such as to have, to take, or to get.
It alsorequires the correct handling ofnon-compositional, idiomatic expressions withvarying degrees of ?fixedness?.
We viewMachine Translation in terms of linguisticinformation represented as typed featurestructures.
By integrating translation informationrepresented as example pairs with other types oflinguistic information represented as rules, ourapproach extends the capabilities of currentmachine translation methods, and solves anumber of key problems.1.
Linguistic Context for TranslationIn translating different words, phrases, andexpressions, different types and amounts ofinformation from the context need to beconsidered.
(Only the sentential context isconsidered here.)
So far, a systematic solution tothis problem has not been found.
This sectionillustrates the extent of this problem, and theremainder of this paper describes our approach.1.1.
Expressions with to haveWe examined the problem of translating theEnglish main verb to have into Japanese.
Theverb to have was selected because it is quitecommon in colloquial English, yet forms a largevariety of senses, collocations, and idioms.
615different expressions containing the English verbto have were extracted from a 7000-sentencecorpus from the ?international travel?
domain.Each English expression was manually translatedinto Japanese in the most general way possible.1.2.
Target-language DistinctionsThe most general translation for the construction?X have Y?
in this domain was found to be  (X-ni Y-ga aru):The copy shop next door has a fax machine.tonari-no  kopiiya-ni fakkusu-ga arimasu.next-ATT copy shop-LOC fax-NOM  existOther translations are often necessary when thetarget language imposes finer semanticdistinction on the state or on the action that isdescribed.
For example, if the object noun phraserefers to one or more human beings, the Japaneseverb aru is changed into iru.
Similarly, the wordpet or a pet animal as the object noun phrasetriggers the translation of to have as katteiru, aJapanese verb for keeping an animal as a pet :We have two sons.musuko-ga futari  imasu.son-NOM two-CONTR existDo you have pets? !anata-wa petto-wo katte-imasu-kayou-TOP pet-ACC keep-ST-QOther examples of finer target-languagedistinctions include a symptom/disease as theobject of to have.
While many physicalsymptoms and minor diagnoses (e.g.
pain, cavity,fever, allergy) use the default translation (X-gaaru), a serious illness or diagnosis is translatedinto the copula construction.
Many other to haveconstructions with a symptom/disease objectrequire verbs that are specific to the object nounphrase in Japanese:I have diabetes.
"#$%&watashi-wa toonyobyoo desu.I-TOP diabetes  COPMy wife had a stroke last year.
'()*+,&-./tsuma-wa kyonen noosocchu-de taoremashitawife-NOM last year stroke-with fall-PSTMy husband had a heart attack.0123456//otto-ga shinzoohossa-wo okoshi-mashitahusband-NOM heart attack-ACC cause-PST1.3.
Adjuncts in the Source LanguageSome verbal adjuncts can affect the translation ofthe to have construction, not by altering the basicsense of ?existing?, but by adding furtherinformation to specify the way in whichsomething ?exists?.
One example of such anadjunct is a prepositional phrase (PP) whoseobject noun phrase shares its referent with theSUBJ of  have.
For example, the utterance belowexpresses that the map is held or carried by thespeaker, and the Japanese translation uses theverb motte-iru, literally meaning to becarrying/holding.I have the map with me.
"789: watashi-wa sono chizu-wo motte-imasu.TOP the map-ACC hold-STIf the subject noun phrase is inanimate, theJapanese translation uses the verb tsuite-iru,which literally means to be attached.The main dish has a salad with it.meindisshu-ni-wa sarada-ga tsuite-imasu.main dish-LOC-TOP salad-NOM attach-STSimilarly, a construction with an on-PP istranslated into the Japanese constructionnotte-iru, which literally means to bewritten/placed on.
A construction with an in-PPis translated into the Japanese constructionhaitte-iru, which literally means to be placed in:Does the map have subway lines on it.789	8;<= !Sono chizu-ni chikatetsusen-ga notte-imasu-ka.the map-LOC subway line-NOM written-on-QThe closet has extra hangers in it.	 kurozetto-ni yobun-no hangaa-ga  haitte-imasu.closet-LOC extra-ATT hanger-NOM placed-in-STAdjunct adjectival phrases and past participlesalso specify the way something exists.
Forexample, available in the have constructiongenerally changes the translation to aite-iru, to beopen or available:We have one twin room available.>?
@ABCD tsuin-no heya-ga  hitotsu aite-imasutwin-ATT room-NOM one-CONTR open-ST1.4.
Source Language AmbiguitiesIn some cases, the to have construction in Englishcarries more than one sense, and some linguisticcontexts can bring out one of the senses as thepreferred meaning.
For example, the constructionX has a Y taste is ambiguous between to beexercising Y (personal) taste and to taste X.  Thisambiguity is usually resolved by looking at thesemantic properties of the subject noun phrase, asillustrated in the examples below:He has simple tastes.EF@GHIJ/ Kkare-ga shinpuru-na shumi-wo shiteiruhe-NOM simple taste-ACC do-STThis wine has a very clean taste.6L?
@ MNO!JKkono wain-wa totemo sawayaka-na aji-ga  suruthis wine-TOP very refreshing taste-NOM doWhen the object refers to a specific type ofinformation, such as number or address, theconstruction is inherently ambiguous between toknow (the number), to be carrying (the number),and (for the number) to exist.
The constructionusually carries the meaning of to know, but if theconstruction is negated, then the sense of to becarrying becomes more preferred, since thenegative construction is more specific and onlynegates the proposition that the object isaccessible:I don?t have his phone number.
"EPQRS: watashi-ga kare-no denwabangoo-wo motteinaiI-NOM he-GEN phone number-ACC hold-ST-NEGOn the other hand, if the object noun phrase is anindefinite noun phrase, it is more likely to meanto exist :Do you have an extension number?T=RS!naisen bangou-ga  arimasu-kaextension number-NOM exist-QAnother example of the ambiguities of to haveconcerns the two senses to have somethingavailable and to eat, when the object noun phraserefers to an edible entity.
Our corpus analysisshows that some of the linguistic contexts bringout one of the two senses as clearly preferred.For example, the past tense or the perfectiveaspect brings out the to eat sense, whereas thepresent tense without any aspect markerssuppresses this sense:I had raw fish for dinner.UVWXY	YZ/sakana-no sashimi-wo yuushoku-ni tabemashitafish-ATT  raw-ACC    dinner-GOAL eat-PSTI don?t have any American beer on tap.
[\]^_`Habamerika-no  namabiiru-wa  arimasen.America-ATT draft beer-TOP exist-NEG1.5.
Support Verb Constructions and IdiomsIn some of the constructions, to have functions asa support verb.
In the support verb constructionthe object noun phrase constitutes a part of theverbal predicate rather than an argument of theverb.
If the target language does not have anequivalent support verb construction, such anexpression with a support verb construction hasto be translated into the corresponding singleverb construction.Idiomatic expressions in the source and targetlanguages, and their varying degrees of?fixedness?, also play a role.
For example, theword (kentoo), the Japanese translation ofa clue in I don?t have a clue, requires the specialverb(tsuku), to constitute an idiomaticexpression (kentoo-ga tsuku).
Asanother example, the English expression Have agood one does not allow a compositionaltranslation into a Japanese construction with amain verb plus an object.1.6.
DiscussionFrom the data described above, it is clear thatthere are various factors that contribute to thedifferent patterns of translation.
In order tohandle these different translations correctly, it isnecessary to identify the linguistic features of thecontext that trigger different translations, and todetermine how the different features and contextsinteract.
In the case of the English to haveconstruction, the following surface linguisticfeatures are identified that can be interpreted as?triggers?
for translations other than the defaulttranslation:?
past tense?
interrogative or imperative constructions?
negative?
modal auxiliaries?
progressive and/or perfective aspect?
adjectival modifiers for the object  NP(noun phrase)?
prepositional phrase modifiers for theobject NP?
adjectival modifiers for the VP (verbphrase)?
prepositional phrase modifiers for the VP?
adverbial modifiers for the VP?
constructions that carry a pragmatic force(request, suggestion, etc.
)We found that some of the factors have strongerinfluence on the translation than others.
Forexample, consider the following expression:Can I have a look at the room?7Acd.!sono heya-wo mi-raremasu-ka.the  room-ACC look-PTN-QThe source-language expression contains morethan one factor that can trigger a differenttranslation.
The first factor is the constructionthat usually carries the pragmatic force of?request?, Can I have X?, which usually triggersthe X  (X-wo o-negaidekimasu-ka) construction.
At the same time, theobject noun phrase a look means that the verb tohave is used as a support verb.
For this reason, thecombination of the verb have and the object nounphrase a look has to be translated into Japanese asthe verbal predicate  (miru).
This shows thatthe translation preference that is triggered by theroot string of the object noun phrase is strongerand should take preference over the translationpreference that is triggered by the pragmaticforce.2.
Information-based MTWe argue that the sorts of complex translationcorrespondences that were illustrated in theprevious section are best represented astranslation examples, but that the transferprocedure must use qualitative linguisticconstraints in order to choose the correctexamples.
Given the types of linguistic featuresthat influence translation, a highly expressivelinguistic representation for both input andtranslation examples is required.
We employtyped feature structures throughout all stages oftranslation.Since there are complex interactions amongdifferent contextual factors, a single quantitativematching function that calculates a distancebetween the input and the examples is notsufficient.
Multiple steps of matching are needed,each considering a small number of linguisticdimensions, with the steps executed in theappropriate order.
This is best achieved with arule-based linguistic transfer procedure thatcontrols the example matching procedure.2.1.
Transfer Component ArchitectureThe transfer component for information-basedMT consists of two main procedures, thelinguistic transfer procedure and the examplematching procedure.
This is illustrated in Figure1.
The input to this component is thesource-language typed feature structure; this iscreated by an analysis component that is notdescribed further here.
Similarly, the output ofLinguisticTransferProcesureExampleMatchingProcedureBilingualExampleDatabaseThesaurussource-languagefeature structure &a set of conditionssource-languagefeature structure&most appropriate examplepair feature structures&alignment informationsource-languagefeature structuretarget-languagefeature structureCostDatabaseTransferGrammarFigure 1:  Overview of the Transfer Componentthe transfer component is a target-language typedfeature structure, from which the  target-languageexpression is generated by the generationcomponent (also not described further).2.2.
Linguistic TransferThe linguistic transfer procedure is implementedas a rewrite-grammar using the special-purposeGrammar Programming Language (GPL)  (Duan,et al 2000, Franz, et al 2000a).
The general roleof the transfer grammar is to operate on the inputfeature structure in a recursive manner, and toperform source-to-target transfer by invoking theexample matching procedure, and by using thetranslation examples to construct atarget-language feature structure.
The transfergrammar implements the principle  of ?large tosmall?
in covering the input feature structure.When the transfer procedure invokes the examplematching procedure, it implements the principleof ?specific to general?.
Since the linguisticfeatures interact with each other when they arecombined, and since some of the features havemore influence on the translation than others, it isnecessary to specify a number of separateinvocations of the example matching procedure,and to pay particular attention to their order.
Theinvocations of the example matching procedureare arranged so that each call focuses on one ortwo features, making sure that both the input andthe example contain the same feature(s).Different invocations of the matching procedureare ordered so that the system checks theexistence of the most important factors first,gradually progressing to the least importantfactors.2.3.
Example MatchingThe example matching procedure matches theinput feature structure against the examplefeature structures, and it returns the mostappropriate example.
The architecture of thismodule is shown in Figure 2.When the transfer procedure invokes the examplematching procedure, it specifies a set of linguisticconstraints on which examples may beconsidered.
This is used to narrow down thesearch space from all the examples to a muchsmaller set.
The examples that satisfy theseconstraints are matched in detail against the inputfeature structure.
The detailed match is arecursive process operating on the two featurestructures that is based on costs for inserting,deleting, or altering features, and on certainconstraints for particular features.
Lexicalsimilarity is calculated from the thesaurus on thebasis of the information content of the thesaurusnodes.During example matching, the input featurestructure is aligned with the example featurestructure.
The alignment information is used bythe transfer procedure to handle differencesbetween the input and the example.
For example,if the input contains grammatical features,modifiers, adjuncts, or sub-constituents that arenot in the examples, then they are transferred tothe target-language representation.
Similarly, ifthe example feature structure containsinformation that is not present in the input, thenthe transfer procedure deletes the relevantinformation.3.
Example DatabaseThe example database contains a large set oftranslation examples represented as pairs oftyped feature structures in the source and targetlanguages.
Using a Treebanking tool, theexamples are disambiguated, and indices thatshow corresponding constituents are added.
Inaddition to the type and complexity of theexample feature structures, there are threemethods for identifying the degree of linguistic Figure 2:  Architecture of the Example Matching Procedurespecificity of an example: marked examples,example indices, and semantic constraints.
Thisinformation is used by the transfer procedure andthe matching procedure to select the best example,using the mechanism of linguistic matchingconstraints that was described above.3.1.
Marked ExamplesSome of the features that were shown in Section 2to influence the translation have beentraditionally described as ?marked?.
Examplesinclude negation, interrogative, and also thepresence of certain adjuncts.
The transferprocedure regards these examples as morespecific than unmarked examples, and (via thelinguistic constraints passed to the matchingprocedure) only allows such examples whenappropriate.3.2.
Example IndicesExamples can contain two types of indiceslinking a source-language sub-feature-structurewith a target-language sub-feature-structure.
ACORRESPOND-INDEX signals that the twoconstituents correspond to each other, while aREPLACE-INDEX signals that two constituentscorrespond to each other and can be replaced bysimilar constituents.The absence of such indices in a major argumentphrase (such as the subject or object) indicatesthat the example is more specific.
ACORRESPOND-INDEX is more specific than aREPLACE-INDEX, since a CORRESPOND-INDEX indicates that although the head of theconstituent allows modifiers, the constituent cannot be substituted.
For example, the object thebucket in the example for the idiom to kick thebucket does not contain any indices, since theidiom does not allow substitution or modification.On the other hand, a heart attack in to have aheart attack allows modifiers (e.g.
a severe heartattack), so the example for the idiomatictranslation carries a CORRESPOND-INDEX.3.3.
Semantic ConstraintsThe example database also contains certainsemantic constraints on source-languagesub-feature-structures.
When an input featurestructure is matched with such an example, thematching procedure checks whether the inputsatisfies the semantic constraint.
If it does, thenthat example is preferred over other examples,since it is more specific than other examples thatdo not carry a semantic constraint.
On the otherhand, if the input does not match the constraint,then the match is rejected.3.4.
Sample EntryFigure 3 shows the example pair for theexpressions Can I have your name?
(o-namae-wo o-negaidekimasu-ka).
This example has a number ofmarked features.
The mood of the sentence isyes-no question, the modal auxiliary can ispresent, and the subject does not contain an index.These features are used by the transfer procedureto ensure that the example is only used totranslate appropriate input.4.
Implementation and EvaluationA prototype implementation of this translationmethod has been created by the Sony USRLSpeech Translation group (Franz et al 200b).
Theprototype was developed for the ?overseas traveldomain?, which includes utterances andexpressions useful for travel between e.g.
Japanand the USA.4.1.
Lexicon and Example DatabaseThe English-to-Japanese translation systemincludes an English dictionary with 6483 uniqueEnglish root forms, and the English-to-Japaneseexample database contains 14,281 separateexample pairs.
These entries consist ofconstructions of various sizes, ranging from				 !	"#$%!	&'		(&)* 	+	,-		.	+	/0                          *		123   )Figure 3: Excerpt from the example database entry forCan I have your name?conjoined sentences to individual words.
Forsome example pairs, the system automaticallyextracts corresponding parts from the source andtarget expressions, and creates a new examplepair.
As a result, the system has a total of 24,072example database entries available.4.2.
Development SetWe developed, tested, and refined the systemuntil all of the main predicates of the 615development set sentences with to have weretranslated correctly.
For this, the system used 129distinct example pairs with the main verb to have.Many example pairs encode a specifictranslation: 68 out of the 129 entries were used totranslate only one expression from thedevelopment set.
On the other hand, some entriesare very general, and are used to translate a largenumber of expressions.
The most frequentlyused entry is Do you have sushi?  (sushi-ga arimasu-ka), which is usedto translate 113 out of the 615 development setexpressions.4.3.
Linguistic TransferThe transfer grammar contains 153 context-freerules.
Each rule includes a rule-body with GPLstatements, which can include calls to theexample matching procedure, and calls tosub-transfer rules.
To translate the 615expression in the to have development set, thesystem performed an average of 3.4match-and-transfer steps.
(In many cases, morethan one transfer path was pursued.)
Only 26 outof the 615 expressions were translated with onlyone match-and-transfer step.
Examples of suchexpressions include Have a good one!
and Youcan have it.
At the other extreme, the maximumnumber of match-and-transfer steps required totranslate a single input expression was 9.
One ofthe expressions that required 9match-and-transfer steps was The double on thethird floor has a really nice view of the ocean.4.4.
EvaluationThe system was evaluated using a new corpus ofunseen expressions with the verb to have.
Theevaluation data was collected from three differenttravel phrase books published by Barron, Berlitz,and Lonely Planet.
The English expressionscontaining to have as a regular verb (and have gotas a main predicate) were manually extractedfrom the phrase books.
There were 405 uniqueexpressions with have in the resulting evaluationcorpus, with an average of 5.5 words.
Theevaluation corpus was translated by thetranslation system, and each of the outputexpressions was examined and manuallycategorized according to its translation quality.The result is shown in the table below:.Flawless Translations 351 86.7%Incomplete Translationsdue to OOV 48 11.8%Wrong Translations 6 1.5%Total 405 100%The category ?flawless translation?
refers totranslations without any obvious flaws orproblems.
?Incomplete translations due to OOV?refers to translations where the main predicatewas correctly translated, but due to someout-of-vocabulary (OOV) nouns or modifiers,parts of the source-language input words werecarried through to the target language expression.The category ?wrong translation?
refers totranslations where the main predicate isincorrectly translated, with or withoutout-of-vocabulary words.4.5.
DiscussionSome of the wrong translations are due toambiguities in the object noun phrase, such as afall in My child has had a fall, which the systemtranslated as watashi-no kodomo-wa aki-gaarimashita (meaning My child had an autum).There were also a number of expressions thatshould have been translated into differentpredicates in Japanese, but which were notcovered in the example database.
Examples ofthese include the following :Input:    I?ve got a nosebleed.Output: efg g g    hanaji-ga ari-masunosebleed-NOM existAppropriate Translation:efh hanaji-ga dete-imasunosebleed-NOM come out-STThe evaluation shows that the information-basedtranslation method works reliably for translatingshort, single-clause utterances.
In support of thegenerality of this method, we found thattranslation accuracy could be improved byadding more examples, and that the features thatmark specificity of example entries areapplicable to expressions with other commonverbs besides have.4.6.
Future WorkOne difficult problem remains in the treatment ofsupport verb constructions.
When the object hasa modifier, the modifier has to be transferred as averbal modifier in the target language if the targetlanguage requires a single verb construction.
Forexample, to have a close look is translated as tolook closely, and to have another look istranslated as to look again.
There are, however,not enough data in the development set to drawany conclusions about how general thesemodifiers can be treated across different supportverb constructions.One hypothesis is that there are different degreesof proximity between the support verb and theobject noun phrase.
In some cases, there mightbe only one fixed phrase to be interpreted as thesupport verb construction, while other cases mayallow many different modifiers for the objectnoun phrase.
This is suggested by the case of tohave a seat in the development set.
This phraseallows the interpretation of to sit only if theobject noun phrase is exactly a seat.
Theexpression to have another seat cannot betranslated as to sit again, but more like foranother seat to exist.
Further analysis of supportverb construction data, including instances withother verbs besides have, will be necessary todetermine how these constructions can best behandled in the current framework.Another avenue for future work is the use ofMachine Learning techniques to select linguisticfeatures, and statistical methods (such asloglinear models) to model the effect of featurecombinations.ConclusionThe approach described in this paper is based onthe conviction that natural language transfer mustbe driven by qualitative, linguistic information.The analysis of the problem of translating oneconstruction from English to Japanese has shownthat a significant amount of linguisticinformation is necessary for achievinghigh-quality translation of something as simpleas single-clause input.
The transfer method thatthis paper described as one possible solution canintegrate translation examples with linguisticrules and constraints in an effective manner.The linguistic information used in this approachis general and domain-independent;domain-specific translation knowledge isconfined to the example database.
This modularsystem architecture presents significantadvantages for developing, maintaining, andextending a practical machine translation system.AcknowledgementsI would like to thank my advisor Prof. Jun?ichiTsujii, my colleagues at Sony USRL inCalifornia, my colleagues at Sony in Tokyo, andthe anonymous reviewers of this paper.ReferencesDuan, L., A. Franz and K. Horiguchi (2000) ?PracticalSpoken Language Translation Using CompiledFeature Structure Grammars?, in Proceedings ofInternational Conference of Spoken LanguageProcessing (ICSLP-2000), Beijing, China.Franz, A., K. Horiguchi and L. Duan (2000a) ?AnImperative Programming Language for SpokenLanguage Translation?, in Proceedings ofInternational Conference of Spoken LanguageProcessing (ICSLP-2000), Beijing, China.Franz, A., K. Horiguchi, L. Duan, D. Ecker, E. Koontzand K. Uchida (2000b) ?An Integrated Architecturefor Example-based Translation?, in Proceedings ofthe 18th International Conference on ComputationalLinguistics (COLING-2000), Saabrucken,Germany.Furuse, O. and H. Iida (1996)  ?Incrementaltranslation utilizing constituent-boundary patterns?,in Proceedings of COLING-96, pages 412-417.Horiguchi, K. (2000) Integrating LinguisticInformation into Example-based MachineTranslation, Ph.D. thesis, University of ManchesterInstitute of Science and Technology.Maruyama, H. and H. Watanabe (1992) ?Tree coversearch algorithm for example-based translation?, inProceedings of the Fourth International Conferenceon Theoretical and Methodological Issues inMachine Translation (TMI-92), Montreal, pages173-185.Nagao, M. (1984)  ?A framework of a MachineTranslation between Japanese and English byanalogy principle?, in Artificial and HumanIntelligence, A. Elithorn and R. Banerji (eds.
),North Holland, pages 173?180.Sato, S. and M. Nagao (1990)  ?Towardmemory-based translation?, in Proceedings ofCOLING-90, vol.
3, Helsinki, Finland, pages247?252.Sumita, E., O. Furuse, and H. Iida (1993) ?Anexample-based disambiguation of prepositionalphrase attachment?, in Proceedings of the FifthInternational Conference on Theoretical andMethodological Issues in Machine Translation(TMI-93), Kyoto, pages 80-91.Watanabe, H. (1992)  ?A similarity-driven transfersystem?, in Proceedings of COLING-92, Nantes,France, pages 770-776.Watanabe, H. and K. Takeda (1998)  ?A pattern-basedMachine Translation system extended byexample-based processing?, in Proceedings ofACL-COLING-98, pages 1369-1373.
