Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 194?197,Uppsala, Sweden, 15-16 July 2010.c?2010 Association for Computational LinguisticsUvT: The UvT Term Extraction System in the Keyphrase Extraction taskKalliopi ZervanouILK / TiCC - Tilburg centre for Cognition and CommunicationUniversity of Tilburg, P.O.
Box 90153, 5000 LE Tilburg, The NetherlandsK.Zervanou@uvt.nlAbstractThe UvT system is based on a hybrid, lin-guistic and statistical approach, originallyproposed for the recognition of multi-word terminological phrases, the C-valuemethod (Frantzi et al, 2000).
In the UvTimplementation, we use an extended nounphrase rule set and take into considerationorthographic and morphological variation,term abbreviations and acronyms, and ba-sic document structure information.1 IntroductionThe increasing amount of documents in elec-tronic form makes imperative the need for docu-ment content classification and semantic labelling.Keyphrase extraction contributes to this goal bythe identification of important and discriminativeconcepts expressed as keyphrases.
Keyphrasesas reduced document content representations mayfind applications in document retrieval, classifica-tion and summarisation (D?Avanzo and Magnini,2005).
The literature distinguishes between twoprincipal processes: keyphrase extraction andkeyphrase assignment.
In the case of keyphraseassignment, suitable keyphrases from an exist-ing knowledge resource, such as a controlled vo-cabulary, or a thesaurus are assigned to docu-ments based on classification of their content.
Inkeyphrase extraction, the phrases are mined fromthe document itself.
Supervised approaches tothe problem of keyphrase extraction include theNaive Bayes-based KEA algorithms (Gordon etal., 1999) (Medelyan and Witten, 2006), deci-sion tree-based and the genetic algorithm-basedGenEx (Turney, 1999), and the probabilistic KLdivergence-based language model (Tomokiyo andHurst, 2003).
Research in keyphrase extrac-tion proposes the detection of keyphrases basedon various statistics-based, or pattern-based fea-tures.
Statistical measures investigated focus pri-marily on keyphrase frequency measures, whereaspattern-features include noun phrase pattern filter-ing, identification of keyphrase head and respec-tive frequencies (Barker and Cornacchia, 2000),document section position of the keyphrase (e.g.,(Medelyan and Witten, 2006)) and keyphrasecoherence (Turney, 2003).
In this paper, wepresent an unsupervised approach which combinespattern-based morphosyntactic rules with a statis-tical measure, the C-value measure (Frantzi et al,2000) which originates from research in the fieldof automatic term recognition and was initially de-signed for specialised domain terminology acqui-sition.2 System descriptionThe input documents in the Keyphrase Extrac-tion task were scientific articles converted fromtheir originally published form to plain text.Due to this process, some compound hyphen-ated words are erroneously converted into a singleword (e.g., ?resourcemanagement?
vs.
?resource-management?).
Moreover, document sectionssuch as tables, figures, footnotes, headers and foot-ers, often intercept sentence and paragraph text.Finally, due to the particularity of the scientific ar-ticles domain, input documents often contain ir-regular text, such as URLs, inline bibliographicreferences, mathematical formulas and symbols.In our approach, we attempted to address someof these issues by document structuring, treatmentof orthographic variation and filtering of irregulartext.The approach adopted first applies part-of-speech tagging and basic document structuring(sec.
2.1 and 2.2).
Subsequently, keyphrase can-didates conforming to pre-defined morphosyntac-tic rule patterns are identified (sec.
2.3).
Inthe next stage, orthographic, morphological andabbreviation variation phenomena are addressed194(sec.
2.4) and, finally, candidate keyphrases areselected based on C-value statistical measure (sec.2.5).2.1 Linguistic pre-processingFor morphosyntactic analysis, we used the Maxent(Ratnaparkhi, 1996) POS tagger implementationof the openNLP toolsuite1.
In order to improvetagging accuracy, irregular text, such as URLs,inline references, and recurrent patterns indicat-ing footers and mathematical formulas are filteredprior to tagging.2.2 Basic document structuringDocument structuring is based on identified re-current patterns, such as common section titlesand legend indicators (e.g., ?Abstract?, ?Table...?
),section headers numbering and preserved format-ting, such as newline characters.
Thus, the doc-ument sections that the system may recogniseare: Title, Abstract, Introduction, Conclusion,Acknowledgements, References, Header (for anyother section headers and legends) and Main (forany other document section text).2.3 Rule pattern filteringThe UvT system considers as candidatekeyphrases, those multi-word noun phrasesconforming to pre-defined morphosyntactic rulepatterns.
In particular, the patterns considered are:M+NM C M NM+N C NN P M?NN P M?N C NN C N P M?NM C M NM+N C Nwhere M is a modifier, such as an adjective, anoun, a present or past participle, or a proper nounincluding a possessive ending, N is a noun, P apreposition and C a conjunction.
For every sen-tence input, the matching process is exhaustive:after the longest valid match is identified, the rules1http://opennlp.sourceforge.net/are re-applied, so as to identify all possible shortervalid matches for nested noun phrases.
At thisstage, the rules also allow for inclusion of poten-tial abbreviations and acronyms in the identifiednoun phrase of the form:M+(A) NM+N (A)where (A) is a potential acronym appearing as asingle token in uppercase, enclosed by parenthesesand tagged as a proper noun.2.4 Text normalisationIn this processing stage, the objective is therecognition and reduction of variation phenom-ena which, if left untreated, will affect the C-value statistical measures at the keyphrase selec-tion stage.
Variation is a pervasive phenomenonin terminology and is generally defined as the al-teration of the surface form of a terminologicalconcept (Jacquemin, 2001).
In our approach, weattempt to address morphological variation, i.e.,variation due to morphological affixes and ortho-graphic variation, such as hyphenated vs. non-hyphenated compound phrases and abbreviatedphrase forms vs. full noun phrase forms.In order to reduce morphological variation, UvTsystem uses the J.Renie interface2to WordNet lex-icon3to acquire lemmas for the respective can-didate phrases.
Orthographic variation phenom-ena are treated by rule matching techniques.
Inthis process, for every candidate keyphrase match-ing a rule, the respective string alternations aregenerated and added as variant phrases.
For ex-ample, for patterns including acronyms and therespective full form, alternative variant phrasesgenerated may contain either the full form only,or the acronym replacing its respective full form.Similarly, for hyphenated words, non-hyphenatedforms are generated.2.5 C-value measureThe statistical measure used for keyphrase rankingand selection is the C-value measure (Frantzi et al,2000).
C-value was originally proposed for defin-ing potential terminological phrases and is basedon normalising frequency of occurrence measures2http://www.ai.mit.edu/ jrennie/WordNet/3http://wordnet.princeton.edu/195Performance over Reader-Assigned KeywordsSystem top 5 candidates top 10 candidates top 15 candidatesP R F P R F P R FTF?IDF 17.80% 7.39% 10.44% 13.90% 11.54% 12.61% 11.60% 14.45% 12.87%NB & ME 16.80% 6.98% 9.86% 13.30% 11.05% 12.07% 11.40% 14.20% 12.65%UvT 20.40% 8.47% 11.97% 15.60% 12.96% 14.16% 11.93% 14.87% 13.24%UvT - A 23.60% 9.80% 13.85% 16.10% 13.37% 14.61% 12.00% 14.95% 13.31%UvT - I 21.20% 8.80% 12.44% 14.50% 12.04% 13.16% 12.00% 14.95% 13.31%UvT - M 20.40% 8.47% 11.97% 15.10% 12.54% 13.70% 11.40% 14.20% 12.65%UvT - IC 23.20% 9.63% 13.61% 16.00% 13.29% 14.52% 13.07% 16.28% 14.50%Performance over Combined KeywordsSystem top 5 candidates top 10 candidates top 15 candidatesP R F P R F P R FTF?IDF 22.00% 7.50% 11.19% 17.70% 12.07% 14.35% 14.93% 15.28% 15.10%NB & ME 21.40% 7.30% 10.89% 17.30% 11.80% 14.03% 14.53% 14.87% 14.70%UvT 24.80% 8.46% 12.62% 18.60% 12.69% 15.09% 14.60% 14.94% 14.77%UvT - A 28.80% 9.82% 14.65% 19.60% 13.37% 15.90% 14.67% 15.01% 14.84%UvT - I 26.40% 9.00% 13.42% 17.80% 12.14% 14.44% 14.73% 15.08% 14.90%UvT - M 24.80% 8.46% 12.62% 17.90% 12.21% 14.52% 14.07% 14.39% 14.23%UvT - IC 28.60% 9.75% 14.54% 19.70% 13.44% 15.98% 16.13% 16.51% 16.32%Table 1: UvT, UvT variants and baseline systems performance on the Keyphrase Extraction Taskby taking into consideration the candidate multi-word phrase constituent length and terms appear-ing as nested within longer terms.
In particu-lar, depending on whether a candidate multi-wordphrase is nested or not, C-value is defined as:C-value =??
?log2|a|f(a)log2|a|(f(a)?1P (Ta)?b?Taf(b))In the above, the first C-value measurement isfor non-nested terms and the second for nestedterms, where a denotes the word sequence that isproposed as a term, |a| is the length of this termin words, f(a) is the frequency of occurrence ofthis term in the corpus, both as an independentterm and as a nested term within larger terms, andP (Ta) denotes the probability of a term string oc-curring as nested term.In this processing stage of keyphrase selection,we start by measuring frequency of occurrence forall our candidate phrases, taking into considera-tion phrase variants, as identified in the Text nor-malisation stage.
Then, we proceed by calculatingnested phrases frequences and, finally, we estimateC-value.The result of this process is a list of proposedkeyphrases, ranked by decreasing C-value mea-sure, wherefrom the top 15 were selected for theevaluation of the system results.3 ResultsThe overall official results of the UvT system areshown in Table 1, where P , R and F correspondto micro-averaged precision, recall and F-scorefor the respective sets of candidate keyphrases,based on reader-assigned and combined author-and reader-assigned gold standards.
Table 1 alsoillustrates the reported performance of the taskbaseline systems (i.e., TF?IDF, Naive Bayes (NB)and maximum entropy (ME)4) and the UvT sys-tem performance variance based on document sec-tion candidates (-A: Abstract, -I: Introduction, -M:Main, -IC: Introduction and Conclusion combina-tion).
In these system variants, rather than select-ing the top 15 C-value candidates from the sys-tem output, we also apply restrictions based onthe candidate keyphrase document section infor-mation, thus skipping candidates which do not ap-pear in the respective document section.Overall, the UvT system performance is closeto the baseline systems results.
We observe thatthe system exhibits higher performance for its top4The reported performance of both NB and ME for the re-spective gold-standard sets in the Keyphrase Extraction Taskis identical.1965 candidate set and this performance drops rapidlyas we include more terms in the answer set.
Onepossible reason for its average performance couldbe attributed to increased ?noise?
in the results set.In particular, our text filtering method failed to ac-curately remove a large amount of irregular textin form of mathematical formulas and symbolswhich were erroneously tagged as proper nouns.As indicated in Table 1, the improved results ofsystem variants based on document sections, suchas Abstract, Introduction and Conclusion, wherethese symbols and formulas are rather uncommon,could be partly attributed to ?noise?
reduction.Interestingly, the best system performancein these document section results is demon-strated by the Introduction-Conclusion com-bination (UvT-IC).
Other tested combinations(not illustrated in Table 1), such as abstract-intro, abstract-intro-conclusions, abstract-intro-conclusions-references, display similar results onthe reader-assigned set and a performance rang-ing between 15,6-16% for the 15 candidates onthe combined set, while the inclusion of the Mainsection candidates reduces the performance to theoverall system output (i.e., UvT results).
Furtherexperiments are required for refining the criteriafor document section information, when the textfiltering process for ?noise?
is improved.Finally, another reason that contributes to thesystem?s average performance lies in its inherentlimitation for the detection of multi-word phrases,rather than both single and multi-word.
In partic-ular, single word keyphrases account for approx.20% of the correct keyphrases in the gold standardsets.4 ConclusionWe have presented an approach to keyphrase ex-traction mainly based on adaptation and imple-mentation of the C-value method.
This methodwas originally proposed for the detection of ter-minological phrases and although domain termsmay express the principal informational content ofa scientific article document, a method designedfor their exhaustive identification (including bothnested and longer multi-word terms) has not beenproven more effective than baseline methods inthe keyphrase detection task.
Potential improve-ments in performance could be investigated by(1) improving document structure detection, so asto reduce irregular text, (2) refinement of docu-ment section information in keyphrase selection,(3) adaptation of the C-value measure, so as topossibly combine keyphrase frequency with a dis-criminative measure, such as idf .ReferencesKen Barker and Nadia Cornacchia.
2000.
Using nounphrase heads to extract document keyphrases.
InProceedings of the 13th Biennial Conference of theCanadian Society on Computational Studies of In-telligence: Advances in Artificial Intelligence, pages40?52, Montreal, Canada, May.Ernesto D?Avanzo and Bernado Magnini.
2005.
Akeyphrase-based approach to summarization: theLAKE system.
In Proceedings of Document Under-standing Conferences, pages 6?8, Vancouver, BC,Canada, October 9-10.Katerina Frantzi, Sophia Ananiadou, and HidekiMima.
2000.
Automatic recognition of multi-word terms: The C-Value/NC-value Method.
Intern.Journal of Digital Libraries, 3(2):117?132.Ian Witten Gordon, Gordon W. Paynter, Eibe Frank,Carl Gutwin, and Craig G. Nevill-manning.
1999.Kea: Practical automatic keyphrase extraction.
InProceedings of the Fourth ACM conference on Dig-ital Libraries, pages 254?256, Berkeley, CA, USA,August 11-14.
ACM Press.Christian Jacquemin.
2001.
Spotting and DiscoveringTerms through Natural Language Processing.
MITPress, Cambridge, MA, USA.Olena Medelyan and Ian H. Witten.
2006.
Thesaurusbased automatic keyphrase indexing.
In JCDL ?06:Proceedings of the 6th ACM/IEEE-CS joint confer-ence on Digital libraries, pages 296?297, New York,NY, USA.
ACM.Adwait Ratnaparkhi.
1996.
A maximum entropymodel for part-of-speech tagging.
In Eric Brill andKenneth Church, editors, Proceedings of the Empiri-cal Methods in Natural Language Processing, pages133?142.Takashi Tomokiyo and Matthew Hurst.
2003.
A lan-guage model approach to keyphrase extraction.
InProceedings of the ACL 2003 workshop on Mul-tiword expressions, pages 33?40, Morristown, NJ,USA.
Association for Computational Linguistics.Peter Turney.
1999.
Learning to extract keyphrasesfrom text.
Technical Report ERB-1057, NationalResearch Council, Institute for Information Technol-ogy, February 17.Peter Turney.
2003.
Coherent keyphrase extraction viaweb mining.
In IJCAI?03: Proceedings of the 18thinternational joint conference on Artificial intelli-gence, pages 434?439, San Francisco, CA, USA.Morgan Kaufmann Publishers Inc.197
