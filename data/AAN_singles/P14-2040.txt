Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 241?246,Baltimore, Maryland, USA, June 23-25 2014. c?2014 Association for Computational LinguisticsDetection of Topic and its Extrinsic Evaluation Through Multi-DocumentSummarizationYoshimi SuzukiInterdisciplinary Graduate School ofMedicine and EngineeringUniversity of YamanashiKofu, 400-8511, JAPANysuzuki@yamanashi.ac.jpFumiyo FukumotoInterdisciplinary Graduate School ofMedicine and EngineeringUniversity of YamanashiKofu, 400-8511, JAPANfukumoto@yamanashi.ac.jpAbstractThis paper presents a method for detect-ing words related to a topic (we call themtopic words) over time in the stream ofdocuments.
Topic words are widely dis-tributed in the stream of documents, andsometimes they frequently appear in thedocuments, and sometimes not.
We pro-pose a method to reinforce topic wordswith low frequencies by collecting docu-ments from the corpus, and applied LatentDirichlet Allocation (Blei et al, 2003) tothese documents.
For the results of LDA,we identified topic words by using Mov-ing Average Convergence Divergence.
Inorder to evaluate the method, we appliedthe results of topic detection to extractivemulti-document summarization.
The re-sults showed that the method was effectivefor sentence selection in summarization.1 IntroductionAs the volume of online documents has drasticallyincreased, the analysis of topic bursts, topic driftor detection of topic is a practical problem attract-ing more and more attention (Allan et al, 1998;Swan and Allan, 2000; Allan, 2003; Klinken-berg, 2004; Lazarescu et al, 2004; Folino et al,2007).
The earliest known approach is the workof Klinkenberg and Joachims (Klinkenberg andJoachims, 2000).
They have attempted to han-dle concept changes by focusing a window withdocuments sufficiently close to the target concept.Mane et.
al.
proposed a method to generatemaps that support the identification of major re-search topics and trends (Mane and Borner, 2004).The method used Kleinberg?s burst detection al-gorithm, co-occurrences of words, and graph lay-out technique.
Scholz et.
al.
have attempted touse different ensembles obtained by training sev-eral data streams to detect concept drift (Scholz,2007).
However the ensemble method itself re-mains a problem that how to manage several clas-sifiers effectively.
He and Parket attempted to findbursts, periods of elevated occurrence of events asa dynamic phenomenon instead of focusing on ar-rival rates (He and Parker, 2010).
However, thefact that topics are widely distributed in the streamof documents, and sometimes they frequently ap-pear in the documents, and sometimes not oftenhamper such attempts.This paper proposes a method for detectingtopic over time in series of documents.
We rein-forced words related to a topic with low frequen-cies by collecting documents from the corpus, andapplied Latent Dirichlet Allocation (LDA) (Bleiet al, 2003) to these documents in order to ex-tract topic candidates.
For the results of LDA, weapplied Moving Average Convergence Divergence(MACD) to find topic words while He et.
al., ap-plied it to find bursts.
The MACD is a techniqueto analyze stock market trends (Murphy, 1999).
Itshows the relationship between two moving av-erages of prices modeling bursts as intervals oftopic dynamics, i.e., positive acceleration.
Fuku-moto et.
al also applied MACD to find topics.However, they applied it only to the words withhigh frequencies in the documents (Fukumoto etal., 2013).
In contrast, we applied it to the topiccandidates obtained by LDA.We examined our method by extrinsic evalua-tion, i.e., we applied the results of topic detectionto extractive multi-document summarization.
Weassume that a salient sentence includes words re-lated to the target topic, and an event of each doc-uments.
Here, an event is something that occursat a specific place and time associated with somespecific actions(Allan et al, 1998).
We identifiedevent words by using the traditional tf?idf methodapplied to the results of named entities.
Each sen-tence in documents is represented using a vectorof frequency weighted words that can be event241or topic words.
We used Markov Random Walk(MRW) to compute the rank scores for the sen-tences (Page et al, 1998).
Finally, we selected acertain number of sentences according to the rankscore into a summary.2 Topic Detection2.1 Extraction of Topic CandidatesLDA presented by (Blei et al, 2003) modelseach document as a mixture of topics (we callit lda topic to discriminate our topic candidates),and generates a discrete probability distributionover words for each lda topic.
The generative pro-cess for LDA can be described as follows:1.
For each topic k = 1, ?
?
?
, K, generate ?k,multinomial distribution of words specific tothe topic k from a Dirichlet distribution withparameter ?;2.
For each document d = 1, ?
?
?
, D, generate ?d,multinomial distribution of topics specific tothe document d from a Dirichlet distributionwith parameter ?;3.
For each word n = 1, ?
?
?
, Ndin document d;(a) Generate a topic zdnof the nth wordin the document d from the multinomialdistribution ?d(b) Generate a word wdn, the word associ-ated with the nth word in document dfrom multinomial ?zdnLike much previous work on LDA, we used Gibbssampling to estimate ?
and ?.
The sampling prob-ability for topic ziin document d is given by:P (zi| z\i,W ) =(nv\i,j+ ?
)(nd\i,j+ ?
)(n?\i,j+ W?
)(nd\i,?+ T?).
(1)z\irefers to a topic set Z, not including the cur-rent assignment zi.
nv\i,jis the count of word vin topic j that does not include the current assign-ment zi, and n?\i,jindicates a summation over thatdimension.
W refers to a set of documents, and Tdenotes the total number of unique topics.
Aftera sufficient number of sampling iterations, the ap-proximated posterior can be used to estimate ?
and?
by examining the counts of word assignments totopics and topic occurrences in documents.
The..................(i) Lda_topic clusters(ii) Task clusterstopic id0 topic id1clustertask1 task3 task2task2task1task1doc ....doc........task1 task2topic id2topic id1topic id1topic id0topic id0topic id2... .......clusterFigure 1: Lda topic cluster and task clusterapproximated probability of topic k in the docu-ment d, ?
?kd, and the assignments word w to topick,?
?wkare given by:?
?kd=Ndk+ ?Nd+ ?K.
(2)?
?wk=Nkw+ ?Nk+ ?V.
(3)We used documents prepared by summarizationtasks, NTCIR and DUC data as each task consistsof series of documents with the same topic.
Weapplied LDA to the set consisting of all documentsin the summarization tasks and documents fromthe corpus.
We need to estimate the appropriatenumber of lda topic.Let k?
be the number of lda topics and d?
bethe number of topmost d?
documents assigned toeach lda topic.
We note that the result obtainedby LDA can be regarded as the two types of clus-tering result shown in Figure 1: (i) each clustercorresponds to each lda topic (topic id0, topic id1?
?
?
in Figure 1), and each element of the clustersis the document in the summarization tasks (task1,task2, ?
?
?
in Figure 1) or from the corpus (doc inFigure 1), and (ii) each cluster corresponds to thesummarization task and each element of the clus-ters is the document in the summarization tasksor the document from the corpus assigned topicid.
For example, DUC2005 consists of 50 tasks.Therefore the number of different clusters is 50.We call the former lda topic cluster and the lattertask cluster.
We estimated k?
and d?
by using En-tropy measure given by:E = ?1log l?jNjN?iP (Ai, Cj) logP (Ai, Cj).
(4)242l refers to the number of clusters.
P (Ai, Cj) is aprobability that the elements of the cluster Cjas-signed to the correct class Ai.
N denotes the totalnumber of elements and Njshows the total num-ber of elements assigned to the cluster Cj.
Thevalue of E ranges from 0 to 1, and the smallervalue of E indicates better result.
Let EtopicandEtaskare entropy value of lda topic cluster andtask cluster, respectively.
We chose the parame-ters k?
and d?
whose value of the summation ofEtopicand Etaskis smallest.
For each lda topic,we extracted words whose probabilities are largerthan zero, and regarded these as topic candidates.2.2 Topic Detection by MACDThe proposed method does not simply use MACDto find bursts, but instead determines topic wordsin series of documents.
Unlike Dynamic TopicModels (Blei and Lafferty, 2006), it does not as-sume Gaussian distribution so that it is a naturalway to analyze bursts which depend on the data.We applied it to extract topic words in series ofdocuments.
MACD histogram defined by Eq.
(6)shows a difference between the MACD and itsmoving average.
MACD of a variable xtis definedby the difference of n1-day and n2-day movingaverages, MACD(n1,n2) = EMA(n1) - EMA(n2).Here, EMA(ni) refers to ni-day Exponential Mov-ing Average (EMA).
For a variable x = x(t) whichhas a corresponding discrete time series x = {xt| t= 0,1,?
?
?
}, the n-day EMA is defined by Eq.
(5).EMA(n)[x]t= ?xt+ (1?
?)EMA(n?
1)[x]t?1=n?k=0?(1?
?)kxt?k.
(5)?
refers to a smoothing factor and it is often takento be 2(n+1).
MACD histogram shows a differencebetween the MACD and its moving average1.hist(n1, n2, n3) = MACD(n1, n2)?EMA(n3)[MACD(n1, n2)].
(6)The procedure for topic detection with MACDis illustrated in Figure 2.
Let A be a series of doc-uments and w be one of the topic candidates ob-tained by LDA.
Each document in A is sorted inchronological order.
We set A to the documentsfrom the summarization task.
Whether or not aword w is a topic word is judged as follows:1In the experiment, we set n1, n2, and n3to 4, 8 and 5,respectively (He and Parker, 2010).T TTCorrect histogram Bursts histogramHistogram similaritybursts burstsburstsFigure 2: Topic detection with MACD1.
Create document-based MACD histogramwhere X-axis refers to T , i.e., a period of time(numbered from day 1 to 365).
Y-axis is thedocument count in A per day.
Hereafter, re-ferred to as correct histogram.2.
Create term-based MACD histogram whereX-axis refers to T , and Y-axis denotes burstsof word w in A. Hereafter, referred to asbursts histogram.3.
We assume that if a term w is informativefor summarizing a particular documents ina collection, its burstiness approximates theburstiness of documents in the collection.Because w is a representative word of eachdocument in the task.
Based on this assump-tion, we computed similarity between correctand word histograms by using KL-distance2.Let P and Q be a normalized distance ofcorrect histogram, and bursts histogram, re-spectively.
KL-distance is defined by D(P ||Q) =?i=1P (xi) logP (xi)Q(xi)where xirefersbursts in time i.
If the value of D(P || Q)is smaller than a certain threshold value, w isregarded as a topic word.3 Extrinsic Evaluation to Summarization3.1 Event detectionAn event word is something that occurs at a spe-cific place and time associated with some spe-cific actions (Allan, 2003; Allan et al, 1998).
Itrefers to notions of who(person), where(place),2We tested KL-distance, histogram intersection and Bhat-tacharyya distance to obtain similarities.
We reported onlythe result obtained by KL-distance as it was the best resultsamong them.243when(time) including what, why and how in a doc-ument.
Therefore, we can assume that named en-tities(NE) are linguistic features for event detec-tion.
An event word refers to the theme of thedocument itself, and frequently appears in the doc-ument but not frequently appear in other docu-ments.
Therefore, we first applied NE recogni-tion to the target documents to be summarized, andthen calculated tf?idf to the results of NE recogni-tion.
We extracted words whose tf?idf values arelarger than a certain threshold value, and regardedthese as event words.3.2 Sentence extractionWe recall that our hypothesis about key sentencesin multiple documents is that they include topicand event words.
Each sentence in the docu-ments is represented using a vector of frequencyweighted words that can be event or topic words.Like much previous work on extractive sum-marization (Erkan and Radev, 2004; Mihalceaand Tarau, 2005; Wan and Yang, 2008), we usedMarkov Random Walk (MRW) model to computethe rank scores for the sentences.
Given a setof documents to be summarized, G = (S, E) isa graph reflecting the relationships between twosentences.
S is a set of vertices, and each vertexsiin S is a sentence.
E is a set of edges, and eachedge eijin E is associated with an affinity weightf(i ?
j) between sentences siand sj(i 6= j).
Theaffinity weight is computed using cosine measurebetween the two sentences, siand sj.
Two ver-tices are connected if their affinity weight is largerthan 0 and we let f(i ?
i)= 0 to avoid self tran-sition.
The transition probability from sito sjisthen defined as follows:p(i ?
j) =??????
?f(i?j)|S|?k=1f(i?k), if ?f 6= 00 , otherwise.
(7)We used the row-normalized matrix Uij=(Uij)|S|?|S|to describe G with each entry corre-sponding to the transition probability, where Uij=p(i ?
j).
To make U a stochastic matrix, the rowswith all zero elements are replaced by a smoothingvector with all elements set to 1|S|.
The final transi-tion matrix is given by formula (8), and each scoreof the sentence is obtained by the principal eigen-vector of the matrix M .M = ?UT+(1?
?
)| S |~e~eT.
(8)We selected a certain number of sentences accord-ing to rank score into the summary.4 Experiments4.1 Experimental settingsWe applied the results of topic detection to ex-tractive multi-document summarization task, andexamined how the results of topic detection af-fect the overall performance of the salient sen-tence selection.
We used two tasks, Japanese andEnglish summarization tasks, NTCIR-33 SUMMJapanese and DUC4 English data.
The baselinesare (i) MRW model (MRW): The method ap-plies the MRW model only to the sentences con-sisted of noun words, (ii) Event detection (Event):The method applies the MRW model to the resultof event detection, (iii) Topic Detection by LDA(LDA): MRW is applied to the result of topic can-didates detection by LDA and (iv) Topic Detec-tion by LDA and MACD (LDA & MACD): MRWis applied to the result of topic detection by LDAand MACD only, i.e., the method does not includeevent detection.4.2 NTCIR dataThe data used in the NTCIR-3 multi-documentsummarization task is selected from 1998 to 1999of Mainichi Japanese Newspaper documents.
Thegold standard data provided to human judges con-sists of FBFREE DryRun and FormalRun.
Eachdata consists of 30 tasks.
There are two types ofcorrect summary according to the character length,?long?
and ?short?, All series of documents weretagged by CaboCha (Kudo and Matsumoto, 2003).We used person name, organization, place andproper name extracted from NE recognition (Kudoand Matsumoto, 2003) for event detection, andnoun words including named entities for topic de-tection.
FBFREE DryRun data is used to tuningparameters, i.e., the number of extracted words ac-cording to the tf?idf value, and the threshold valueof KL-distance.
The size that optimized the aver-age Rouge-1(R-1) score across 30 tasks was cho-sen. As a result, we set tf?idf and KL-distance to100 and 0.104, respectively.We used FormalRun as a test data, and anotherset consisted of 218,724 documents from 1998 to1999 of Mainichi newspaper as a corpus used in3http://research.nii.ac.jp/ntcir/4http://duc.nist.gov/pubs.html244???????????????????????????????
???
???
???
???
???
???
???????????????
????????????????????????
????????????????????????
????????????????????????
???????????
?Number of documentsEntropyFigure 3: Entropy against the # of topics and doc-umentsMethod Short LongR-1 R-1MRW .369 .454Event .625 .724LDA .525 .712LDA & MACD .630 .742Event & Topic .678 .744Table 1: Sentence Extraction (NTCIR-3 test data)LDA and MACD.
We estimated the number of k?and d?
in LDA, i.e., we searched k?
and d?
in stepsof 100 from 200 to 900.
Figure 3 illustrates en-tropy value against the number of topics k?
anddocuments d?
using 30 tasks of FormalRun data.Each plot shows that at least one of the docu-ments for each summarization task is included inthe cluster.
We can see from Figure 3 that thevalue of entropy depends on the number of doc-uments rather than the number of topics.
Fromthe result shown in Figure 3, the minimum entropyvalue was 0.025 and the number of topics and doc-uments were 400 and 300, respectively.
We usedthem in the experiment.
The summarization re-sults are shown in Table 1.Table 1 shows that our approach, ?Event &Topic?
outperforms other baselines, regardless ofthe summary type (long/short).
Topic candidatesinclude surplus words that are not related to thetopic because the results obtained by ?LDA?
wereworse than those obtained by ?LDA & MACD?,and even worse than ?Event?
in both short andlong summary.
This shows that integration ofLDA and MACD is effective for topic detection.4.3 DUC dataWe used DUC2005 consisted of 50 tasks for train-ing, and 50 tasks of DUC2006 data for testing inorder to estimate parameters.
We set tf?idf andMethod R-1 Method R-1MRW .381 Event .407LDA .402 LDA & MACD .428Event & Topic .438PYTHY .426 HybHSum .456hPAM .412 TTM .447Table 2: Comparative results (DUC2007 test data)KL-distance to 80 and 0.9.
The minimum en-tropy value was 0.050 and the number of topicsand documents were 500 and 600, respectively.45 tasks from DUC2007 were used to evaluatethe performance of the method.
All documentswere tagged by Tree Tagger (Schmid, 1995) andStanford Named Entity Tagger 5 (Finkel et al,2005).
We used person name, organization and lo-cation for event detection, and noun words includ-ing named entities for topic detection.
AQUAINTcorpus6 which consists of 1,033,461 documentsare used as a corpus in LDA and MACD.
Table2 shows Rouge-1 against unigrams.We can see from Table 2 that Rouge-1 obtainedby our approach was also the best compared to thebaselines.
Table 2 also shows the performance ofother research sites reported by (Celikylmaz andHakkani-Tur, 2010).
The top site was ?HybH-Sum?
by (Celikylmaz and Hakkani-Tur, 2010).However, the method is a semi-supervised tech-nique that needs a tagged training data.
Our ap-proach achieves performance approaching the top-performing unsupervised method, ?TTM?
(Ce-likylmaz and Hakkani-Tur, 2011), and is compet-itive to ?PYTHY?
(Toutanoval et al, 2007) and?hPAM?
(Li and McCallum, 2006).
Prior workincluding ?TTM?
has demonstrated the usefulnessof semantic concepts for extracting salient sen-tences.
For future work, we should be able toobtain further advantages in efficacy in our topicdetection and summarization approach by disam-biguating topic senses.5 ConclusionThe research described in this paper explores amethod for detecting topic words over time in se-ries of documents.
The results of extrinsic evalu-ation showed that integration of LDA and MACDis effective for topic detection.5http://nlp.stanford.edu/software/CRF-NER.shtml6http://catalog.ldc.upenn.edu/LDC2002T31245ReferencesJ.
Allan, J. Carbonell, G. Doddington, J. Yamron, andY.
Yang.
1998.
Topic Detection and Tracking PilotStudy Final Report.
In Proc.
of the DARPA Broad-cast News Transcription and Understanding Work-shop.J.
Allan, editor.
2003.
Topic Detection and Tracking.Kluwer Academic Publishers.D.
M. Blei and J. D. Lafferty.
2006.
Dynamic TopicModels.
In Proc.
of the 23rd International Confer-ence on Machine Learning, pages 113?120.D.
M. Blei, A. Y. Ng, and M. I. Jordan.
2003.
La-tent Dirichlet Allocation.
In The Journal of MachineLearning Research, volume 3, pages 993?1022.A.
Celikylmaz and D. Hakkani-Tur.
2010.
A Hy-bird Hierarchical Model for Multi-Document Sum-marization.
In Proc.
of the 48th Annual Meetingof the Association for Computational Linguistics,pages 815?824.A.
Celikylmaz and D. Hakkani-Tur.
2011.
Discoveryof Topically Coherent Sentences for Extractive Sum-marization.
In Proc.
of the 49th Annual Meeting ofthe Association for Computational Linguistics: Hu-man Language Technologies, pages 491?499.G.
Erkan and D. Radev.
2004.
LexPageRank: Prestigein Multi-Document Text Summarization.
In Proc.
ofthe 2004 Conference on Empirical Methods in Nat-ural Language Processing, pages 365?371.J.
R. Finkel, T. Grenager, and C. Manning.
2005.
In-corporating Non-local Information into InformationExtraction Systems by Gibbs Sampling.
In Proc.of the 43rd Annual Meeting of the Association forComputational Linguistics, pages 363?370.G.
Folino, C. Pizzuti, and G. Spezzano.
2007.
AnAdaptive Distributed Ensemble Approach to MineConcept-Drifting Data Streams.
In Proc.
of the 19thIEEE International Conference on Tools with Artifi-cial Intelligence, pages 183?188.F.
Fukumoto, Y. Suzuki, A. Takasu, and S. Matsuyoshi.2013.
Multi-document summarization based onevent and topic detection.
In Proc.
of the 6th Lan-guage and Technology Conference: Human Lan-guage Technologies as a Challenge for ComputerScience and Linguistics, pages 117?121.D.
He and D. S. Parker.
2010.
Topic Dynamics: AnAlternative Model of Bursts in Streams of Topics.In Proc.
of the 16th ACM Special Interest Group onKnowledge Discovery and Data Mining, pages 443?452.R.
Klinkenberg and T. Joachims.
2000.
DetectingConcept Drift with Support Vector Machines.
InProc.
of the 17th International Conference on Ma-chine Learning, pages 487?494.R.
Klinkenberg.
2004.
Learning Drifting Concepts:Example Selection vs.
Example Weighting.
Intel-leginet Data Analysis, 8(3):281?300.T.
Kudo and Y. Matsumoto.
2003.
Fast methods forkernel-based text analysis.
In Proc.
of 41st AnnualMeeting of the Association for Computational Lin-guistics, pages 24?31.M.
M. Lazarescu, S. Venkatesh, and H. H. Bui.
2004.Using Multiple Windows to Track Concept Drift.Intelligent Data Analysis, 8(1):29?59.W.
Li and A. McCallum.
2006.
Pachinko Alloca-tion: Dag-Structure Mixture Model of Topic Cor-relations.
In Proc.
of the 23rd International Confer-ence on Machine Learning, pages 577?584.K.
Mane and K. Borner.
2004.
Mapping Topicsand Topic Bursts in PNAS.
Proc.
of the NationalAcademy of Sciences of the United States of Amer-ica, 101:5287?5290.R.
Mihalcea and P. Tarau.
2005.
Language Indepen-dent Extractive Summarization.
In In Proc.
of the43rd Annual Meeting of the Association for Compu-tational Linguistics, pages 49?52.J.
Murphy.
1999.
Technical Analysis of the FinancialMarkets.
Prentice Hall.L.
Page, S. Brin, R. Motwani, and T. Winograd.
1998.The Pagerank Citation Ranking: Bringing Order tothe Web.
In Technical report, Stanford Digital Li-braries.H.
Schmid.
1995.
Improvements in Part-of-SpeechTagging with an Application to German.
In Proc.
ofthe European chapter of the Association for Compu-tational Linguistics SIGDAT Workshop.M.
Scholz.
2007.
Boosting Classifiers for DriftingConcepts.
Intelligent Data Analysis, 11(1):3?28.R.
Swan and J. Allan.
2000.
Automatic Generationof Overview Timelines.
In Proc.
of the 23rd An-nual International ACM SIGIR Conference on Re-search and Development in Information Retrieval,pages 38?45.K.
Toutanoval, C. Brockett, M. Gammon, J. Jagarla-mudi, H. Suzuki, and L. Vanderwende.
2007.
ThePhthy Summarization System: Microsoft Researchat DUC.
In Proc.
of Document Understanding Con-ference 2007.X.
Wan and J. Yang.
2008.
Multi-Document Summa-rization using Cluster-based Link Analysis.
In Proc.of the 31st Annual International ACM SIGIR Con-ference on Research and Development in Informa-tion Retrieval, pages 299?306.246
