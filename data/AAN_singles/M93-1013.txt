MITRE-Bedford :Description of the Alembic System as Used for MUC-5John Aberdeen, John Burger, Dennis Connolly, Susan Roberts, &Marc VilainThe MITRE Corporation202 Burlington RoadBedford, MA 01730BACKGROUNDThe Alembic text understanding system fielded at MUC-5 by MITRE is an extensive rewrite of the system w epresented at MUC-4.
Alembic' is a research prototype that is still young, and is thus in the process of ongoin gdevelopment .
Our work is part of an internally-funded research initiative aimed at processing open source texts, i .e.
,free natural language texts drawn from broadcast transcripts, news wires, etc.
This initiative explores several majo rresearch areas:?
Error recovery, primarily involving issues of semi-parsing and recovery of plausible attachments .?
Robustness, primarily involving issues of uncertain reasoning and tractable inference .?
Self-extensibility, focusing primarily on machine learning of natural language and user-configurablesemantics .?
System integration, through SGML (the Standard Generalized Markup Language), both at the leve lof meaning analysis and at the overall application level .ARCHITECTUREThe system's underlying architecture, shown in Figure 1 overleaf, follows a by-now familiar task breakdown .Processing occurs in two main phases : preprocessing (in the elementizer module), which covers processes rangin gfrom document destructuring to simple parsing, and natural language analysis per se, including application-specifi coutput generation .
As with several other MUC systems, our use of an explicit pre-processing phase is directl yborrowed from work by Jacobs oral (1991).
One way Alembic differs from other MUC systems, however, is inexploiting SGML (Goldfarb 1990) as the interchange lingua franca between processing phases.
The intention is toallow system modules whose invocation occurs early in the analysis of a document to record processing result sdirectly in the document through SGML markup .
This information then becomes available to subsequent modulesas meta-data .
Further, the elementizer itself is composed of a sequence of processing phases that also exchang epartial results through SGML .As a result of this SGML-based architecture, the system's overall flow of control is governed from an object -oriented document manager built on top of Goldfarb's public domain SGML parser, ARC-SGML .
For MUC-5, thepre-processing elementizer thus takes a source message file and normalizes it in various ways, yielding an inter-mediate SGML document .
The document manager then builds an internal document object by parsing the resultingSGML.
The actual content analysis of the document is performed by invoking the natural language analysi smodules on the internal document object, and the results of these analyses are stored as attributes of the document .Another way in which Alembic differs from a prototypical MUC-class system is in its emphasis on tex tenrichment.
That is, the output of the system is actually a new version of the source document enriched by semanti cmarkup.
The markup consists of a template-based index and simple semantic annotations identifying people ,organizations, places, etc .
For the MUC task, Alembic also provides selective output that consists solely of filledtemplates.
'alembic 1 : an alchemical apparatus used for distillation 2 : something that refines or transmutes as if by distillation .137templates enricheddocumentFigure 1 : System ArchitectureZonerPrepro.Prepar.ParseDefrag .Interp .Ambig .Disc.Tempt .Elementizer 333Scanner 3Parser 33Inference 333Generator 3Table 1 : Correspondence between Alembic and Hobbs' proto-systemINDIVIDUAL PROCESSING MODULE SAs shown in Figure 1, Alembic comprises six main processing modules.
These modules perform all but one o fthe functions described by Hobbs (1993) for his generic information extraction system?we omit the text filterin gphase .
The correspondence from Hobbs' inventory of processing modules to Alembic is summarized in Table 1 .Elementize rThe elementizer (so called because it inserts SGML elements into the text) is built as a cascade of finite-stateLEX-style tokenizers .
The elementizer performs Hobbs' zoning, pre-processing, and pre-parsing functions .
Ourzoning is more sophisticated than that in most like systems because we interpret the markup of MUC-5 messages a sbona fide SGML.
Of Hobbs' several pre-processing tasks, the elementizer performs two : detecting sentence an dparagraph boundaries, and tokenizing certain parts of the lexicon .
The parts in question include some gargantuansub-lexica that we do not want to have to load into our main processor, e.g ., lists of personal names and theinventory of geography terms from the TIPSTER gazetteer .
Also tokenized are contractions and other punctuation -laden lexemes, and assorted closed classes such as corporate designators and currency names .
Finally, theelementizer performs some rudimentary parsing of dates and other constructs whose idiosyncrasies are much easie rto handle in a finite-state framework than in the strictly binary-branching framework of our main parser.138The following elementized sample reproduces parts of the second paragraph of the walkthrough message.
Note,for example, normalization tags such as < N UM > (for numerals) and tokenization tags, including <PT> (forpunctuation), <GEO> (Gazetteer entries), and <LEX> (misc.
closed classes) .<P> THE JOINT VENTURE <PT>,</Pf> BRIDGESTONE SPORTS <GEO co>TAIWAN</GEO> <LEX> CO.</LEX ><PT>,</PT> .
.. A MONTH<Pf>.</PT> <S>THE MONTHLY OUTPUT <NAME>WILL</NAME> BE LATER RAISE DTO <NUM V= "50000">50,000</NUM> UNIT5<PT>,</Pf> BRIDGESTON SPORTS OFFICIALS SAID<PT>.</PT >The elementizer expects its output to be normalized with respect to an SGML document type definition at somelater point, in our case as the elementized source file is read into the document manager .
This allows us to exploit anumber of SGML shortcuts, such as implicit tags, thus simplifying the elementization task significantly .
In thepreceding sample, for example, note how unambiguous </P>, <5> and <IS> tags are not introduced .
They arereconstructed from context by the document manager when the elementized message is read into Alembic .
Moreesoterically, perhaps, we also exploit short forms of attribute names so as to minimize the size of elementize dmessages.
The <GEO co> tag for example is actually short for (roughly)<GEO continent=NIL country=T province=NIL city=NIL airport=NIL port=NIL island=NIL island_group=NlL >Document Manage rThe document manager provides an object-oriented framework for working with SGML documents.
Themanager is entirely CLOS-based, and SGML elements are thus made available as instances of CLOS objects .
Asentence element (corresponding to the string bracketed by matching <5> and <15> tags) is mapped into an instanc eof the 5 class in CLOS, and any S -specific code (e.g ., the linguistic parser) is thus made applicable to the element .As mentioned, the document manager is built around a public domain SGML parser/tokenizer written byGoldfarb, the originator of SGML.
The parser takes care of canonicalizing a document as it is read in by, e .g .
,inserting any tags left implicit by the elementizer, or by filling in the default attribute values of attributes .The parser consists of C language routines made available through the Consortium for Lexical Research .
Onthe Lisp side, the document manager makes available a simple text-processing protocol that is easily specialized fo rcontentful elements, such as <5>, <SO>, and so forth .
We exploit this protocol to structure the entire flow of contro lof the main body ofAlembic, from invoking the scanner all the way through producing template files.ScannerThe scanner performs the remainder of Hobbs' pre-processing phase .
That is, it builds a chart over which theparser will operate, and populates the chart with categories corresponding to either (1) ordinary lexical items in th einput stream, or (2) SGML elements identified by the elementizer (geographic terms, dates, and so forth) .
The latterare handled by specializing the document manager's text processing protocol .
<GEO> elements, for example ,instantiate a prototypical geographical NP category into the chart (our categories are structured attribute valu evectors with variables, i .e., standard unification-style DAGs (Shieber 1986 ; Pareschi &Steedman 1987)) :[[syn :N ][bar-level 2][scm [[head geo-region]]]]Non-SGML items are handled through a three-level lexicon .
Our primary lexicon contains lexical items t owhich is associated fine-grained information .
This may include complex syntactic relationships, as with sententialcomplement verbs, or they may be associated with meaningful semantics, as with domain-specific lexicon entries .The primary lexicon was populated in part by adapting knowledge bases provided to us by Richard Tong of ADS .If a lexical item is not found in the primary lexicon, we obtain its part of speech from a secondary lexicon base don the OAL (Oxford Advanced Learner) word list .
This occurs most often for open-class tokens out of th eimmediate realm of the domain .
Finally, if an item does not even appear in the OAL, we assume it to be an instanc eof a special unknown noun category, UNK-N.
This category is allowed to appear anywhere that is permitted fo rcommon nouns .
In addition, UNK-Ns can participate in many syntactic positions that would otherwise be reserve dto proper nouns, e.g ., as part of personal names and as pre-nominal modifiers to the left of the adjective position .139Linguistic ParserThe original parser in Alembic was strictly based on combinatory categorial grammars (Steedman 1985, 1987) .We originally chose CCGs because their processing is inherently bottom-up and because they are strongly lexicall ygoverned .
One lesson learned in our MUC-4 experience, however, is that strongly categorial frameworks are in -adequate for processing free text, chiefly because they only provide inconvenient treatments of modifier attachment.As a result, one change we brought to our parser in the last year has been to recast it as a hybrid of the categoria land phrase structure frameworks.
Specifically, we rely on structured CCG-style categories to handle argumen tstructure, and on binary-branching phrase structure rules to handle modifier attachment and other general phrasestructure phenomena.
A transitive verb, for example is treated as the V/N category, i.e., as a function that takes anoun phrase argument on the right (the N term) and produces a verb phrase (the V term) .
The noun phrase isattached to the verb through the combinatorial rule of function application, i .e.
,a//3aStrictly speaking, the above is a combinatorial schema, in which a and 13 in this case match V and Nrespectively .
As in standard CCGs, a single combinatorial function application schema is used for attaching allsyntactic arguments to a functor category.
Complex argument attachment phenomena are thus encoded throughcomplex syntactic categories, e .g., V/N/N (for ditransitive verbs such as "give") or V/S/N (for "tell" and simila rsentential complement verbs) .In contrast, modifier attachment is handled by providing rules specific to the particular modificationphenomenon, as in standard phrase structure grammar .
The temporal modifiers of a verb, for example, are handledthrough the following rule (not a schema) .V DATEVThere are a number of advantages to this approach with respect to linguistic modeling .
Beyond handlingmodifiers, Wittenburg (1987) used related strategies to project gapped constituents .
From a computationalperspective, however, the most important is that it makes the grammar entirely unary- or binary-branching .
This i sso because the syntactic phenomena that must traditionally be treated through greater-than-binary rules are typicall ycomplex argument structures?in our framework, these phenomena are handled through "stacked" functorcategories, such as V/N/N .
2 By relying on the binary-branching property of the grammar, we can thus simplifymany aspects of our parser ; we don't need to construct dotted rules, for example .Although there are many further interesting and unconventional aspects of Alembic's parser, they are only ofsecondary interest to an information extraction audience .
For the present purpose, we will thus only allude to som eof the parser's other relevant characteristics .?
The parser organizes rules according to specificity, so that only the most specific variant of a phrasestructure rule is ever used in combining two categories.?
We rely on a number of simple attachment disambiguation heuristics to reduce the number of parse sgenerated for a given sentence.
These heuristics are simple and have so far proved themselve sworkable in practice .
In particular, we prefer argument attachments to modifier attachments, an damong multiple modifier attachments, we prefer those that attach deepest in the parse tree .?
Although the parser often produces spanning parses of even long sentences, we only require it t oproduce semi-parses.
We use a greedy algorithm to segment the chart into maximal chunks and us ethese when a spanning parse is unavailable.2There are admittedly non-binary phenomena besides complex argument structure, for example the grammar of dates .
Wehandle these cases through the finite-state pre-parsing that is performed by the Alembic elementizer .140Semantic interpretationsThe parser produces semantic interpretations in concert with syntactic parses .
The output of the parser is effec-tively a semantic interpretation of the predicate argument structure of the sentence .
We use semantic structuresderived from those in the King Kong NL interface (Bayer d Vilain 1991) ; these are in turn related to the "interpre-tation level" of Alshawi erVan Eijck (1989) .
These are semantic objects that have four primary components :?
Head : that is, a semantic predicate corresponding to the lexical head of a phrase .?
Args : a list of semantic interpretations corresponding to the syntactic arguments of the lexical head.?
Proxy : a semantic individual that instantiates the lexical head .?
Mods : a set of interpretations corresponding to the syntactic modifiers of the phrase .For example, the following is the top level interpretation of "The company last March set up a joint venture.
"[[head create-entity]"set up"[args ( [[head company] .
.
.
]"the company"[[head business-venture] .
.
.]
)]"a joint venture"[proxy c-e-1 ][mods { [[head time-of]"last March"[args ( c-e-1 [[head date] .
.
.]
) ] .
.
.]
} ]]In this case, the head slot of the interpretation corresponds to the main verb of the sentence, and the args slo tholds the arguments of the verb, e .g., the subject and direct object.
The proxy slot denotes a semantic individualwhich serves the role of an event instance in a partially Davidsonian scheme, as in (Hobbs 1985) or (Bayer d-Vilai n1991) .
That is, modifiers of the lexical head (from the mods slot) are made to predicate the proxy individual ., as i nthe example with the date modifier "last March," which predicates a time-of relation of the proxy individual c-e-1 .As with other frameworks with similar interpretation levels, it is worth observing that these representations areambiguous with respect to quantifier scope .
Although quantifier information is saved during parsing (as a fift hquant slot on interpretations), it is ignored except in as much as is needed for determining definiteness of referentia lexpressions.
As noted below, this representational ambiguity is of interest because we perform inference and dataextraction directly upon propositionalized versions of these interpretations, with no need to scope quantifiers .InferenceThe inference module is a completely new addition to Alembic .
It is built on top of a propositional database thatstores propositionalized versions of the semantics of sentences .
The database itself is coupled to a tractable in-ference mechanism (Vilain 1991, 1993) and to an equality reasoner based on congruence closure (McAllester 1989) .With respect to data extraction, the inference module performs two chief functions.
First it provides a uniformframework that seamlessly integrates general-purpose semantic processing and the bulk of data extraction .
Second,it serves as a common substrate upon which Alembic performs various kinds of discourse processing, ranging fromgeneral definite reference resolution to domain-specific event or entity merging .
As we note below, the inferentia lnature of the process allows these two functions to be performed through simple rules, thus avoiding the monolithi cand unwieldy pattern-matching expressions that are typically used for semantic processing and event merging .This material is best illustrated through examplessee below in our discussion of the walkthrough message.Template GenerationAs mentioned, we rely on the inference mechanism to perform the bulk of the work of data extraction.
Thetemplate generator, to a large extent, simply reads the template structure out of the contents of the propositiona ldatabase.
The primary complexity lies in maintaining backpointers from facts in the propositional database to thetext strings required to produce string fills .
Since these fills are typically NPs, this is simply achieved by mappin gsemantic individuals to their originating lexical heads, and mapping these in turn to their maximal projections .In addition, the template generator must handle the innumerable details concerning fill rules for geography ,names, and aliases.
These minutiae are handled through a combination of inference rules and ad hoc code .141SEMANTIC PROCESSING IN THE WALKTHROUGH MESSAG EFrom a data extraction perspective, most of the early stages of processing Alembic performs on this message areonly of partial interest.
Although Alembic has its own distinctive ways of pre-processing, scanning, and parsing th edocument, the heart of the actual extraction process takes place during inference .
As this is also one of thedistinguishing characteristics of Alembic, our description of the walkthrough message thus focuses largely on theinferential process .Mapping parses to proposition sInference begins when the semantic interpretations produced by the parser are added to the propositiona ldatabase.
For example, for the first sentence in the message, the parser produces the following schematic syntacti cattachments (two fully spanning parses are produced for this sentence) .BRIDGESTONE SPORTS CO .SAID FRIDAYIT WILL SET U PA JOINT VENTUR EIN TAIWA NWITHA LOCAL CONCER NAN DA JAPANESE TRADING HOUS ETO PRODUCEGOLF CLUBSTO BE SHIPPED TO JAPA NThe actual semantic interpretations are nested structures that generally mirror this attachment scheme : the toplevel of the interpretation, for example, is provided below.
Note that in the particular case of verbs with sententia lcomplements (e .g ., "Bridgestone Sports Co .
said"), the propositional complement (e .g ., "it will set up") is actuallypulled out to the top level of the interpretation, and the matrix sentence is demoted to a modifier role.
[[head create-entity]"has set up"[args ( [[head pronominal-thing]]"it"[[head business-venture]] )]"a joint venture"[prosy p1][mods { [[head declare]"said Friday"[args ( [[head company]] p1 ) ]] } ]]"Bridgestone Sports Co. "A nested interpretation such as this is then added to the database by flattening and propositionalizing it .
For thefirst sentence of the walkthrough message, the following propositions are added (among others) .
(company ct)"Bridgestone Sports Co."(declare (ct c-e-1))" said Friday"(pronominal-thing t1)" it"(create-entity (t1 b-v-1) c-e-1)"has set up"(business-venture b-v-1)"a joint venture"Note again that this process of propositionalization does not require making any choice of quantifier scoping .General semantic inferenceOnce a sentence has been propositionalized and added to the database, the first set of inferences performed ar etypically of a general semantic nature .
In the case of the first walkthrough sentence, the fast set of rules to derivenew facts are those that identify the participants of the events .
A very general such rule pulls participants out of theconjoined co-agentive phrase "with a local concern and a Japanese trading house ."
To begin with, this co-agentivephrase causes the propositions below to be added in addition to those shown above .142(co-agent (bvl el))"with"(group g1)coordination(group-member (g1 Ic1))"a local concern"(group-member (g1 jthl))"a Japanese trading house"The extraction of participants is performed by the following rule :(event x) & (co-agent (x y)) & (group y) & (group-member (y z)) - (participant (x z) )This rule yields:(participant (bvl Ic1) )(participant (bvl jthl) )An additional rule identifies these participants as venture entities :(business-venture x) & (participant (x y)) ?> (jv-entity (x y)) ,yielding :(jv-entity (bvt Ic1))(jv-entity (bvl jthi) )Together, these two rules identify the existence of two of the joint venture participants (but not their names) .The third participant is identified (modulo reference resolution) by a lexical rule about creating business ventures :(create-entity (x y)) & (business-venture y) -* (participant (x y)) .This rule, along with the immediately preceding one yield:(participant (bvl ptl))i.e., "it" is a participant in the business ventur e(jv-entity (bvl ptl))i.e., "it" is a venture entity of the ventureThese rules typify the kind of inference that goes on in Alembic, wherein domain-specific lexical inference sbuild directly on top of general domain-independent inferences .
This provides an appealing degree of declarativemodularity, and allows significant portions of the semantic infrastructure to be reused across multiple domains .Discourse processin gPerhaps the most appealing aspect of Alembic's propositional database is that it provides a very convenien tsubstrate for discourse processing .
Indeed, Alembic exploits the equality mechanism built into the database to causefacts to become propagated and shared as a result of coreference determinations .
In the version of Alembic used inMUC-5, these co-reference determinations can happen in three different ways .Definite referenceThe definite reference mechanism incorporated into the MUC-5 version of the system is a drastic simplificatio nof the probabilistic mechanism we used in MUC-4 (Aberdeen 6-al 1992).
We restricted the mechanism to consideronly designated classes in our sort hierarchy, namely joint ventures and companies .
Once a definite reference to adesignated class has been identified, it is simply resolved to the most recent instance of that class .
This strategy i serror-prone, and we intend to replace it shortly with a probabilistic reference mechanism more in line with the on ewe used in MUC-4 (but trained on more reliable data!)
.
What is most interesting about our approach, however, i snot the particular reference algorithm we ended up implementing, but the way it exploits the equality mechanism .To see this, consider sentence 2 of the walkthrough message, where we encounter the definite reference "Th ejoint venture, Bridgestone Sports Taiwan Co." This phrase engenders the following propositions in the database :(business-venture bv2)"The joint venture"(has-name (IA2 c2))apposition(company c2)"Bridgestone Sports Taiwan Co."143The definite reference is resolved to the phrase "a joint venture" from sentence 1, which corresponds to th eindividual bv1 .
The individuals bvl and bv2 are then equated, and the following is automatically inferred :(has-name (bvl c2) )Other facts known about le/2 are automatically propagated to bvl as well .Event and entity mergingEvent and entity merging approaches to discourse processing have gained significant visibility recently in ligh tof the success of systems with very fragmentary parsing, e.g ., CIRCUS (Lehnert eb al 1992) or FASTUS (Appelt cral 1993) .
Although we have only had limited experience with this class of techniques, we believe that entity andevent merging can be elegantly handled through Alembic's propositional database.
For instance, consider sentence 4of the walkthrough message, which refers to "The new company, based in Kaohsiung."
The MUC-5 version of oursystem contained the following entity-merging rule, which can be glossed as saying that any new compan ymentioned in the context of a joint venture is in fact that joint venture (or perhaps its joint venture company) :(company x) & (new-thing x) & (jv-in-context (x y)) -f (= (x y)) .As a result of applying this rule, Alembic propagates facts known about the company in sentence four to thejoint venture entity from sentence 1, e .g ., the fact that it is based in Kaohsiung, and so forth .
What is most appealingabout merging events in this way is that it avoids much of the monolithic pattern-matching that is typically requiredfor event merging, especially for copying information from the source events into their combined merger.Stereotypical pronominal referenc eFinally, Alembic exploits the inference mechanism to encode some patterns of pronominal reference that are sostereotypical as to be effectively frozen .
One such pattern appears in the first sentence : "Bridgestone Sports Co .said Friday it will set up a joint venture ."
This pattern is handled by the following simple rule :(declare (x y)) & (event (z) y) & (pronominal-thing z) -a (= (x z) )This rule matches sentences headed by propositional statement verbs (through the declare term).
When theembedded clause (matched through the event term 3 ) has a pronominal subject (the pronominal-thing term), the ruleequates the subject arguments of the two clauses .
As with definite reference, the equality mechanism then propa-gates facts known about the matrix subject to the embedded subject?in this case the fact that it is a company, etc .SYNOPSIS OF EVALUATION MEASURE SWe believe the development effort we undertook in this past year has paid off to a large extent, though not a smuch as we had originally hoped .
We achieved an overall ERR score of 87, corresponding to a P&R score of 22 .Although this is on the low end of scores reported for MUC-5, it represents a significant improvement over ou rMUC-4 performance (P&R of 9 on TST3), especially given the increased difficulty of the MUC-5 task.More important perhaps than these single performance measures is our overall performance profile .
Alembic i sa clean system: we have among the highest precision scores to be presented here (P=58) .
In contrast, ourperformance was hampered by our relatively lower recall (R=14) .
This high-precision profile is also reflected in ourcomparatively better system-by-system ranking in the richness-normalized-error measures (minerr= .89 maxerr=.92 )than in the primary error per response fill measure.
This is due to the fact that Alembic avoids generating spuriousfills, a characteristic that is favored by the richness-normalized error measures .Turning to our recall score, our major problem in obtaining a high recall level was simply an inadequate domai nmodel, especially an insufficient complement of extraction rules for locating joint venture entities .
For example, wefailed to exploit such reliable indicators of these entities as ownership or partnership events .
Since entities3 1n our domain model, event is a generalization that matches any relation, including the create-entity event in the example .144CONDITION F-SCORE (P&R) RECALL PRECISION ERRO RFull System 23,73 14 60 86No OAL 24.27 15 61 85No Reference 23.44 14 60 86Table 2: Ablation experimentscontribute overwhelmingly to the overall complement of fills, we were correspondingly penalized.
In addition, weexperienced in the final run a number of hitherto unobserved bugs in the entity fill normalization code ; these errorscontributed to lowering both our recall and precision scores .Beyond the official final runs, we conducted several ablation experiments in an effort to gain additional insigh tinto the nature of our performance at MUC-5 .
In particular, we created versions of Alembic in which we selectivel ydisabled (1) the secondary lexicon (OAL), or (2) definite reference resolution .
We then compared the performanceof these derivative systems to the baseline performance of the full system on the 86-message section of the dry ru ntest set .
These results are summarized in Table 2, and as can be readily seen, there are no substantial difference sbetween the experimental conditions .
We were somewhat surprised to note a slight performance improvement whenwe disabled the secondary OAL lexicon, which attests to a certain degree to the robustness of our fallback strateg yof mapping unknown lexical items to the UNK-N category .One should refrain, however, from drawing any sweeping conclusions from these experiments .
Indeed, th ebaseline recall level of Alembic on this task is still fairly low, so the effects of these experimental manipulations ar eprobably masked by the lack of sufficient baseline recall .
For example, if Alembic fails to identify a company as ajoint venture participant, it does not matter whether the system later succeeds through reference resolution at deter -mining the company's nationality or location .Finally, we performed an additional experiment in which we hand-tagged all geographical entities, corporations ,and personal names, rather than leaving this task to the elementizer and parser .
The intention here was to provide anoracle for these phrase types, so as to help us determine how much of our recall error might have been due t oinadequacies in the parser or elementizer, especially with respect to parsing the names of joint venture participants.Once again, we found no significant difference between the baseline system and the oracle-driven system .
Thissubstantiates our anecdotal impressions that an inadequate extraction model is the main cause of our recall errors .FUTURE WORKAlembic is still on the early end of its maturation curve .
Our grammar, for example, was undergoing constan tdevelopment up until the fmal runs?unlike many other MUC sites, we did not enter this endeavor with anythin gremotely close to a general grammar of English, or even of the so-called noun and verb groups .
Throughout thi stime period, basic system development was thus responsible for stealing precious time away from domai nengineering.One benefit of all our MUC-5 development, is that Alembic has reached a reasonably stable state .
We now havea flexible framework within which to explore data extraction tasks such as EJV in MUC-5 .
We are especiallyencouraged by our recall/precision profile over the last few weeks of development .
Our daily tests revealed aconsistently high precision level that remained stable even with daily improvements in recall .We are also pleased by our preliminary experiences with the new inference component .
Among MUC-5participants, Alembic is distinguished by its ability to accommodate strategies that place a high premium on fullparsing (the lexical inference rules) alongside strategies more geared towards fragment parsing (the event mergin grules).
We look forward to exploiting this new flexibility as we continue informal self-evaluation on the MUC- 5task, and as we explore future data extraction problems.14 5AcknowledgmentsPrincipal funding for this work was provided by the MITRE Corporation .
We would like to thank LynetteHirschman for her ideas and feedback, and welcome her as the newest contributor to this project .
Finally, we wouldalso like to express our gratitude to Richard Tong and his colleagues at ADS for providing us with their MUC- 4lexicon and taxonomies, parts of which are still in place in our current system .REFERENCESAberdeen, J ., Burger, J., Connolly, D ., Roberts, S ., cr Vilain, M. (1992) .
"MITRE-Bedford : Description of th eAlembic system as used for MUC-4" .
In Sundheim, B ., ed ., Prcdgs.
of the Fourth Message Understandin gConf.
(MUC-4), McLean, VA .Alshawi, H.&Van Eijck, J .
(1989).
"Logical forms in the core language engine" .
In Prcdgs .
of the 27th AnnualMtg.
of the Assoc .
for Computational Linguistics (ACL89), Vancouver, BC .Appelt, D. E., Hobbs, J .
R., Bear, J ., Israel, D ., O. Tyson, M. (1993) .
"FASTUS: A finite-state processor forinformation extraction from real-world text ."
In Prcdgs.
of the 13th Intl.
Joint Conf.
on Arttjficial Intelligenc e(IJCAI93), Chamb6ry, France.Bayer, S .
L .
& Vilain, M .
B .
(1991).
"The relation-based knowledge representation of King Kong" .
Sigart Bulletin2(3), 15-21 .Goldfarb, C. F .
(1990) The SGML Handbook.
Oxford : Clarendon Press .Hobbs, J .
R. (1985).
"Ontological promiscuity" .
In Prcdgs.
of the 23rd Annual Mtg.
of the Assoc.
forComputational Linguistics (ACL85), Chicago, IL .Hobbs, J .
R. (1993) .
"The generic information extraction system ."
In Sundheim, B ., ed ., Prcdgs.
of the FifthMessage Understanding Conf.
(MUC-5), Baltimore, MD .Jacobs, P. S ., Krupka, G., O' Rau, L .
(1991) .
"Lexico-semantic pattern-matching as a companion to parsing" .
InPrcdgs.
of the Fourth DARPA Speech and Natural Language Wkshp .
San Mateo, CA: Morgan Kaufman.Lehnert, W., Cardie, C ., Fisher, D., McCarthy, J ., Riloff, E., d' Soderland, S .
(1992) .
"University of Massachusetts :Description of the CIRCUS system as used for MUC-4 ".
In Sundheim, B ., ed.
Prcdgs .
of the Fourth MessageUnderstanding Conf.
.
(MUC-4), McLean, VA .McAllester, D .
A.
(1989).
Ontic : a knowledge representation system for mathematics .
Cambridge, MA : MIT Press .Pareschi, R .
&Steedman, M. (1987) .
"A lazy way to chart-parse with categorial grammars ."
In Prcdgs .
of the 25thAnnual Mtg.
of the Assoc.
for Computational Linguistics (ACL87), Stanford, CA.Shieber, S .
(1986) An Introduction to Unification-based Approaches to Grammar .
CSLI Lecture Notes N?
4 .Available through the University of Chicago Press .Steedman, M. (1985) "Dependency and coordination in the grammar of Dutch and English," Language 61 .3 .Steedman, M. (1987) .
"Combinatory grammars and parasitic gaps," Natural Language and Linguistic Theory 5 .3 .Vilain, M. (1991) .
"Deduction as parsing : Tractable classification in the KL-ONE framework" .
In Prcdgs .
of theNinth Natl .
Conf on Artificial Intelligence (AAAI91) .
Anaheim, CA .Vilain, M .
(1993) .
Validation of Terminological Inference in an information extraction task .
In Prcdgs .
of the 1993ARPA Human Language Wkshp.
San Mateo, CA: Morgan Kaufman .Wittenhurg, K. (1987) .
"Predictive combinators: A method for efficient processing of combinatory categorial gram -mars," Prcdgs .
of the 25th Annual Mtg.
of the Assoc .
for Computational Linguistics (ACL87), Stanford, CA.146
