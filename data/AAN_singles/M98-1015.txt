1IsoQuest, Inc.:Description of the NetOwl?
Extractor System as Used for MUC-7George R. Krupka Kevin HausmanIsoQuest Inc.3900 Jermantown Ave., Suite 400Fairfax, VA 22030gkrupka@isoquest.comINTRODUCTIONIsoQuest used its commercial software product, NetOwl Extractor, for the MUC-7 Named Entity task.
Theproduct consists of a high-speed C++ engine that analyzes text based on a configuration file containing a pattern rulebase and lexicon.
IsoQuest used the NameTag Configuration to recognize proper names and other key phrases intext, and mapped the product?s extraction tags to the MUC-7 NE tags.
NetOwl Extractor provides access to theextracted information through a flexible API, and IsoQuest used a small application program to process thedocuments and write the SGML output.BACKGROUNDIn 1996, SRA International formed IsoQuest, Inc. around its commercial extraction product calledNameTag.
First released in 1995, NameTag identified proper names and other key phrases and featured a high-speedimplementation and ANSI C API.
The initial target application for NameTag was processing of news stories to addvalue for content providers.
In MUC-6, NameTag excelled in the Named Entity task with an F-Measure of 96.42,achieving the approximate level of human performance.Since that time, IsoQuest has moved beyond proper name recognition and news applications.
The companyhas licensed software to over 30 clients for a variety of applications.
Many applications require topic categorizationor summarization in addition to proper name recognition.
Newspaper organizations require the analysis of classifiedads in order to publish them online.
Financial corporations require software to monitor their email for compliancewith regulations.
Several companies require the analysis of SEC filings in order to provide immediate access forinvestors.
Some applications require the resolution of names across documents or databases.
The variety ofapplications has pushed IsoQuest to increase speed, decrease process size, add additional APIs, and support multiplethreads.
These pressures from customer requirements forced IsoQuest to re-engineer NameTag to extend itsextraction capabilities while improving its software implementation.FasterClassified AdsSEC filingsEmail complianceNameTagTopicsJavaCOMSmallerSummariesNewsFigure 1: NameTag Under Pressure2SYSTEM DESCRIPTIONIsoQuest?s new system is called NetOwl Extractor.
The NetOwl Extractor system has been totallyredesigned to embody a new extraction architecture.
The new architecture clearly separates the run-time processingengine from the declarative configuration data that specifies the type of processing to do.
Although previousversions of NetOwl Extractor consisted of a software engine separate from the data configuration files, the softwareengine contained configuration-specific code and information.The NetOwl Extractor 3.0 architecture maintains a total separation of the extraction engine and API fromthe extraction configuration.
The engine has no configuration-specific code or information, and the API has ageneric framework that applies to any configuration.
The specific processing and data that is required to recognizeproper names and other key phrases is now contained in a configuration file called the NameTag Configuration.However, the same engine and API can perform automotive classified ad extraction based on another separateconfiguration file, for example.NetOwl Extractor 3.0 includes a compiler that creates a configuration file from data source files, illustratedin Figure 2.
At run time, only this configuration file must be loaded, which shortens initialization time and enablesefficient memory usage.
Compilation is fast so there is no impact on development or customization.
(Thecompilation time was 4.6 seconds for the MUC configuration on a Pentium II 300 Mhz.)
Previous versions parsed asignificant number of data source files into memory, causing slow initialization and inefficient memory usage.
Theconfiguration file includes an extensive set of parameters, allowing more customization of performance during runtime.EngineTokenizerDoc structureLexical lookupAttributesFeaturesTemplatesLexiconPattern matchersAction interpreterConfiguration FilePatternsActionsGlobal parametersProcessing classesCompilerData Source FilesFigure 2: NetOwl Extractor Configuration CompilerNetOwl Extractor 3.0 now uses generic facilities called extraction lists to store the extracted information.Each extraction list stores the results of an extraction processing class, and subsequent classes can rely on thecontent of other extraction lists.
Regardless of the type of extraction, application programs now use one genericmethod to retrieve the information.3Multiple ConfigurationsNetOwl Extractor permits a single CPU process to open multiple configuration files.
By having multipleconfigurations open, a single process can perform different types of extraction without having to shutdown and re-initialize the system.
For example, a program using NetOwl Extractor could load three configurations, one for newsstories, one for SEC filings, and one for email.
As it processes documents, it could use the appropriate configurationfor each type of document.NetOwl Extractor also permits processing using more than one CPU thread on those systems that supportin-process threads.
Given that multiple-CPU machines are becoming more common, this ability lets the user takeadvantage of several CPUs while only having to run one process.
Each thread of processing in NetOwl Extractormay have its own configuration, or several threads may share a single configuration, thus lowering memory usage.Figure 3 illustrates multiple-configuration (with a single thread), multiple-thread (with a singleconfiguration), and multiple-thread multiple-configuration (several threads using several configurations) processing.Multi-config, single thread Single-config, multi-thread Multi-config, multi-threadFigure 3: Multi-thread CapabilitiesNameTag ConfigurationAlthough the NetOwl Extractor engine executes the text processing phases, the content of the configurationdetermines the exact characteristics of processing.
The lexicon and pattern rule base define what the enginerecognizes, a template (tag) specification and action definitions define what the engine extracts, and the processingclasses define the distinct processing phases that the engine performs.
Global parameters provide run-time control ofprocessing.The core processing of the NameTag Configuration is proper name recognition.
Proper name recognitionrequires specialized linguistic knowledge about the structure or composition of each type of name.
For example,person names usually have first names and last names, with optional middle names or initials.
Proper namerecognition also requires knowledge about how names appear in free text.
This knowledge consists of contextualclues about how each type of name may appear.
For example, person names may have professional titles ordescriptions preceding or following the name.Proper name recognition also requires a substantial list of proper names in the lexicon in order to identifyhousehold names that do not provide the structural indication of what kind of name it is.
For example, most countrynames, such as ?France?, have no internal composition indicating the name is a country.
Also, many types of textmay not provide proper descriptions or contextual clues about common or assumed proper names.
For example,business news articles may assume that the reader knows what the acronym ?NYSE?
stands for.Proper name recognition also requires the identification of aliases, or shortened variations of the full propername.
For example, many organizational names have acronyms, person names have initials, and corporate names4tend to exclude the official corporate designator, such as ?Corp.?
The NameTag Configuration contains aliasgeneration rules that are applied to recognized names.A major problem with name recognition is the ambiguity of names.
Person, place, and organizationalnames can be composed of the same words.
For example, the word ?Jordan?
can be a first name, a last name, acountry name, or part of an organizational name.
Different types of names can appear in text in similar ways.
Forexample, person, place, and organization names can be the subject of communicative verbs, such as ?said?.The NameTag Configuration addresses this major problem by executing a rule competition phase toselect the most probable interpretation for a name.
The rule competition uses the numeric weight of each rule,factors in the length of each interpretation, and sums these values according to the type of tags.
High rule weightsindicate strong evidence, low rule weights indicate weak evidence, and negative rule weights indicate counter-evidence.
The competition also considers interpretations based on proper name entries in the lexicon, thus allowingdynamic pattern matching results to compete against static name look-up.
The rule competition eliminatesinterpretations with negative sums, and selects the interpretations with the highest sums.Visual ExtractorNetOwl Extractor provides a development graphical user interface (GUI) called Visual Extractor, which isimplemented in Java.
The GUI is totally independent of the configuration, just as the NetOwl Extractor engine is.Visual Extractor provides a project workspace that includes a source file view, a settings view, and a configurationobject view.
The workspace can include multiple configurations and parameter settings to allow greater flexibilitywhile one evaluates the performance of the system.
Visual Extractor can export its settings as a batch parameter fileor as programs in C or Java.
Visual Extractor has an extensible extraction display, allowing many views of theextraction results.
Figure 4 shows a screen shot of Visual Extractor.Figure 4: Visual ExtractorNAMED ENTITY CUSTOM CONFIGURATIONWithout modification, NetOwl Extractor?s NameTag Configuration identifies all of the types of namesand phrases included in the Named Entity task specification.
In fact, the NameTag Configuration identifiessubstantially more expressions and has a richer tagging scheme.
However, the Named Entity tag specification doescontain a few significant differences to the product specification of NameTag, such as tagging numeric and temporal5ranges as one tag where as the NameTag Configuration breaks them into two separate tags.
Also, the NamedEntity task required systems to specially tag the header information in the New York Times documents, such as theSLUG word.
For these reasons, IsoQuest created a Named Entity custom configuration based on the core NameTagConfiguration.The NE configuration contained a small number of custom patterns to handle the document style andtagging differences.
The configuration also included some domain-specific lexical entries for the training set.
Usingthe standard API, users could write a small program to map the extracted tags into the NE tags and generate theSGML format themselves.
Instead, IsoQuest added a small action script to the NE Configuration to perform thismapping, and thus allow the NE tags within Visual Extractor and the direct output of SGML from the standard API.Figure 5 shows the comparison between the NameTag Configuration and the NE configuration in terms of totalsize, lexicon size, and pattern rule base size.0%10%20%30%40%50%60%70%80%90%100%Config Size Lexical Entries PatternsMUC-7NameTagFigure 5: NE vs. NameTag ConfigurationTag MappingOverall, the mapping of NameTag Configuration tags to the Named Entity tags is straight forward.However, due to the complexity of the Named Entity specification (20 pages plus the FAQ), the mapping had toaccount for a substantial number of exceptions and special cases.
Inconsistencies, ambiguities, and unspecified casesin the MUC-7 specification impact the effectiveness of this mapping, and ultimately the final results.
Table 1summarizes the tag mapping.6NameTag NE CommentsNUMERIC NUMEX only PERCENT and MONEYPLACE ENAMEX(LOCATION)except some roadways, ?PERSON ENAMEX(PERSON)Except ?X report?ENTITY ENAMEX(LOCATION)Just airports, camps, forts, ?ENTITY(FACILITY)none Except museums, lodges, ?ENTITY(PUBLICATION)ENAMEX(ORG)Except when referring to the paperENTITY ENAMEX(ORG)Everything else, except ?TIME(TIMEOFDAY)(DATE)TIMEX(TIME)(DATE)Direct mapping.TIME(TEMPORAL)TIMEX(DATE)(TIME)DATE and TIME were assigned based on thetime unit.
Some temporal expressions werefiltered.OTHER none Named events, products, equipment and othernon-entitiesMISC none E-mail addresses, othersTable 1: NE Tag MappingNamed Entity Custom PatternsAs described above, the Named Entity configuration included a few special patterns to account for thespecial document style as well as minor differences in the tagging scheme.
This following list explains the basictypes of custom patterns and provides examples of them.?
Document style patterns ?Seven patterns executed before the name recognition patterns and createdspecial tags around portions of the document.
For example, one pattern identified the SLUG wordinside of the PREAMBLE section so that both occurrences of the SLUG word could be processedidentically.
Another pattern created a DATE tag in the NWORD section when it contained a month/dayexpression.
Other patterns operated on the PREAMBLE and TRAILER sections.?
Publication patterns ?
Five patterns executed after the name recognition patterns and modified theENTITY tags for publications if they appeared in certain contexts indicating the physical paper ratherthan the organization.
For example, the phrase ?edition of X?
indicates that ?X?
is the physical paper,so it should not be tagged.?
Compound tags ?
Ten patterns executed after the name recognition patterns and created a compoundtag for a sequence of individual tags.
For example, these patterns would create a single tag for numericand time expressions of the form ?from X to Y?.
Another pattern created a single PERSON tag forexpressions in the form of ?first name and PERSON?.?
Executive departments ?
Three patterns executed after the name recognition and created ENTITY tagsfor governmental departments appearing as title modifiers.
For example, these patterns create a ENTITYtag for ?transportation?
in the phrase ?transportation secretary?.
The NameTag Configuration doesnot treat these departmental references as true proper name mentions.?
Other ?
Five patterns executed during the name recognition patterns and created additional tags forother miscellaneous cases.
For example, one pattern identified certain names of  the form ?X OrgNounof Place?
and tried to split them into an ENTITY and PLACE tag according to the NE task specifications.Named Entity Application ProgramNetOwl Extractor provides a simple, flexible API that allows users to open configurations, specify run-timeparameters, load and process documents, and extract the results.
The API also includes a built-in SGML writer that7can output the extracted tags in SGML format.
The following listing is the complete application program for the NEtask.
Simple programs such as this provided with the product make it simple for application programmers to quicklybegin their own development.int main(int argc, char ** argv) {NEcfg cfg;NEdoc doc;NEextr extr;NEsgml sgml;int bytes = 0, tokens = 0, dcnt = 0, result, error = 0, docSec;char buf[256];try {if ((result = NEinit()) != E_SUCCESS) throw result;if ((result = NEopenConfiguration(argv[1],&cfg)) != E_SUCCESS) throw result;if ((result = NEcreateDocument(cfg,&doc)) != E_SUCCESS) throw result;if ((result = NEdocLoadParameters(doc,argv[2],1,&docSec,&extr,&sgml)) != E_SUCCESS) throw result;unlink(argv[3]);if ((result = NEdocOpenFile(doc,argv[4])) != E_SUCCESS) throw result;while ((result = NEdocLoadRegion(doc,docSec,&tokens)) == E_SUCCESS && tokens > 0) {dcnt++;bytes += NEdocBytesLoaded(doc);if ((result = NEdocProcess(doc)) != E_SUCCESS) throw result;if ((result = NEsgmlWriteFile(sgml,argv[3],1)) != E_SUCCESS) throw result;NEdocClear(doc);}NEdocClose(doc);NEcloseExtractor(extr);NEcloseSGML(sgml);NEcloseDocument(doc);NEcloseConfiguration(cfg);}catch (int error) {NEgetErrorString(error,buf,256);fprintf(stdout,"Error %d: %s\n",error,buf);}NEshutdown();return error;}TEST RESULTS AND ANALYSISIsoQuest submitted two runs for the formal NE test.
The Official run used the full pattern rule base toperform the maximum analysis, achieving the best results at the slowest speed.
The Optional run used about 20% ofthe rules to perform the minimum analysis, achieving lower performance at the greatest speed.
The performancemeasures and timing information are shown in Table 2.
The time includes initialization and SGML output, and wascomputed on a Pentium II 300 Mhz processor.
As another reference point, a Pentium 133 Mhz laptop performedthese two runs at 140 Meg/hour and 190 Meg/hour.Test Run Recall Precision F-Measure CPU Time(seconds)Speed(Meg/hour)Official 90 93 91.60 3.6 382Optional 74 93 82.61 2.7 513ALLCAPS 78 96 81.96 4.9 279Table 2: NE Test ResultsIsoQuest performed an additional experimental run using the case-insensitive configuration against theupper-case version of the test data.
For the ALLCAPS run, the configuration was optimized for high precision.
Sincethe MUC-7 task specification includes case-sensitive tagging rules, the upper-case version of the test data should bemanually re-tagged.
This would most likely improve the case-insensitive results.The size of the NetOwl Extractor process depends on the size of the configuration, which largely dependson the size of the lexicon.
As an experiment, IsoQuest ran the formal test documents against three configurationscontaining different number of lexical entries.
The results of this experiment are summarized in Table 3.
The size ofthe lexicon has a small effect on the extraction performance since the pattern rule base relies on the content of thelexicon to identify proper names and phrases.8LexiconSizeApproximateEntriesProcess Size(Meg)F-MeasureMaximum 110000 7.0 91.60Medium 25000 4.0 91.45Minimum 9000 3.7 89.13Table 3: Lexicon Size Experimental ResultsError AnalysisThe Official run performed significantly worse than the dry run test in September, approximately 3 pointslower in F-measure.
This drop in performance is almost entirely due to the fact that the domain of the formal testdocuments (satellites) was different from the training and dry run documents (airlines).
Strangely, the Named Entitytask is defined as a domain-independent task, yet the MUC committee selected samples of New York Times articlesthat focused on particular domains.
This selection process greatly influenced the results of the task and substantiallydiminished the value of the formal test.
The formal test failed to achieve its objective of measuring domain-independent name entity identification.
Instead, the formal test measured how well systems perform on a newdomain and how well the airline domain prepared systems for the undisclosed satellite domain.
If the samples wererandomly selected, the formal test would have measured how well systems perform in general and how well systemsimproved from the dry run.The performance measures for the training set and dry run set are shown in comparison to the formal testresults in Table 4.
The formal test results (*) have been adjusted to account for a major inconsistency in the manualtagging of a certain type of temporal expression, which is irrelevant for this analysis.Test Set Recall Precision F-MeasureTraining (9/97) 97 97 97.27Training (3/98) 98 99 98.27Dry run (9/97) 94 97 95.35Dry run (3/98) 94 98 96.28*Formal (3/98) 92 93 92.56Table 4: Training and Test Set ComparisonA drop in performance is typical behavior for the NameTag Configuration when it encounters a documentstyle that has fewer descriptive contextual clues than other rich sources such as the Wall Street Journal.
TheNameTag Configuration does not rely on static lists of proper names although it can accommodate them.
The NewYork Times document style used in MUC-7 had significantly fewer clues especially for organization names.
Table 5shows the effect of the airline-specific lexicon modifications on the dry run set.
The recall of ORGANIZATION tagsincreased 9 points.Test set ORGANIZATION(REC/PRE)PERSON(REC/PRE)LOCATION(REC/PRE)Dry run (unmodified) 85/99 94/98 96/98Dry run (3/98) 94/99 93/98 96/97Formal (3/98) 87/89 94/97 93/95Formal (modified) 93/95 96/99 96/95Table 5: ENAMEX Performance Improvement Due To Lexicon ModificationsConfigurations of NetOwl Extractor are customizable and users are encouraged to make minor adjustmentsto their configuration to optimize their performance.
A quick analysis of the NE formal test documents uncoveredvarious common and problematic names from the satellite industry.
As an experiment, IsoQuest added a smallnumber (42) of custom entries to the Named Entity configuration and re-ran the formal test documents, assummarized in Table 6.
Lexical entries can either be positive or negative indicators of a tag type.
Table 5 shows theeffect of the lexicon modifications on the formal test set.
The recall of ORGANIZATION tags increased 6 points.
Theprecision also increased 6 points due to the elimination of ORGANIZATION tags for some common non-organizations.9NAME TAG POLARITY NAME TAG POLARITYAMSC ENTITY + ARIANE ENTITY +ASIASAT ENTITY + BBN ENTITY -CANALSATELLITE ENTITY - CHINASAT ENTITY +CLIPPERS ENTITY + COLUMBIA OTHER +COSAT ENTITY + DBS ENTITY -DELTA OTHER + DIGITAL TV OTHER +EARTH PLACE + EDDIE BAUER ENTITY +ENDEAVOUR OTHER + EROS PLACE +HUGHES ENTITY + MARS PLACE +MA QIMIN PERSON + MCCLEESE PERSON +MIR OTHER + MISSION CONTROL ENTITY +MOON PLACE + MURDOCH PERSON +NI ENTITY - PANAMSAT ENTITY +PAS ENTITY + PRIMESTAR ENTITY +RADIOSAT ENTITY + RCA ENTITY +REPUBLICANS ENTITY - RINEY ENTITY +ROCKETDYNE ENTITY + ROCKETS ENTITY +SATURN OTHER + SPACE ENTITY -SPACE FLYER UNIT OTHER + SPACE SHUTTLE ENTITY -SPACE STATION ENTITY - STU ENTITY -XICHANG PLACE + X-33 OTHER +Table 6: Custom Lexical EntriesSYSTEM WALKTHROUGHMUC-7 selected document 9602140704 from the Named Entity formal test as the system walkthroughexample.
IsoQuest?s official run achieved an F-measure of 89.15 (85 recall, 94 precision) on this document.
Table 7summarizes the errors made by NetOwl Extractor in this document.
This document typifies the overall performancesince most of the errors are due to household or domain-specific proper names.
Seven of the errors involved thehousehold name ?Murdoch?.
NetOwl Extractor correctly determines that the phrase ?Murdoch?s News Corp.?
is apossessive construct between a person alias and a company name, but it erroneously determined that ?MURDOCHSATELLITE?
was an ORGANIZATION.
Due to this mistake, NetOwl Extractor does not tag three other mentions of?Murdoch?
as a person alias.Tag Error TYPE Key ResponseENAMEX missing PERSON MURDOCHENAMEX missing PERSON MURDOCHENAMEX missing PERSON MURDOCHENAMEX missing LOCATION XichangENAMEX missing ORGANIZATION ViacomENAMEX missing ORGANIZATION Home Box OfficeENAMEX missing ORGANIZATION Turner BroadcastingSystemENAMEX missing PERSON MurdochENAMEX missing PERSON MurdochENAMEX spurious ORGANIZATION MURDOCH-SATELLITEENAMEX spurious ORGANIZATION MURDOCHSATELLITEENAMEX spurious ORGANIZATION CNNTable 7: System Walkthrough ErrorsNetOwl Extractor missed two other household names: ?Viacom?
and ?Home Box Office?.
NetOwlExtractor tagged ?Turner Broadcasting System?
as an OTHER tag and thus filtered it from the NE output.
NetOwlExtractor failed to tag ?Xichang?
as a LOCATION, due to the lack of domain knowledge about launch sites.
Thephrase ?Xichang launch site?
would match an existing NameTag pattern if ?launch site?
was added as a location10noun.
Finally, NetOwl Extractor identified ?CNN?
as an ORGANIZATION but failed to determine that the phrase?beam MTV, CNN and other channels?
indicates that ?CNN?
is a channel and not an organization, according to theNamed Entity task specification.CONCLUSIONIsoQuest successfully used its commercial software product NetOwl Extractor for the Named Entity task inMUC-7.
With minor modifications to the NameTag Configuration, IsoQuest performed the NE task with highperformance, although lower than the intermediate results.
IsoQuest demonstrated that the drop in performance wasmainly due to the document style combined with the change in domain of the formal test documents, and showedhow to improve performance with simple additions to the lexicon.
IsoQuest demonstrated the ease of programmingwith NetOwl Extractor?s API and demonstrated its high speed and low memory.ACKNOWLEDGEMENTSGreg Roberts provided valuable support for IsoQuest?s MUC-7 effort, including analyzing systemperformance and interpreting the Named Entity task specification.IsoQuest, a wholly-owned subsidiary of SRA International Inc., is a leading provider of informationdiscovery products that automatically extract, analyze, index, categorize and summarize text documents.
IsoQuestdevelops, markets and supports the NetOwl Family of Intelligence Discovery Products, including NetOwl Extractor,NetOwl for Electronic Publishing and NetOwl for Classifieds.
NetOwl helps corporations manage electronicinformation and allows end users to know more by reading less.
Headquartered in Fairfax, Virginia, IsoQuest servesa global customer base including IBM, Thomson Corporation, OCLC, EDGAR Online, NewsEdge Corporation andKnight Ridder New Media.
More information about IsoQuest is available at www.isoquest.com.
