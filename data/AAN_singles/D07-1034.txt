Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and ComputationalNatural Language Learning, pp.
325?333, Prague, June 2007. c?2007 Association for Computational LinguisticsExtending a Thesaurus in the Pan-Chinese ContextOi Yee Kwong and Benjamin K. TsouLanguage Information Sciences Research CentreCity University of Hong KongTat Chee Avenue, Kowloon, Hong Kong{rlolivia,rlbtsou}@cityu.edu.hkAbstractIn this paper, we address a unique problemin Chinese language processing and reporton our study on extending a Chinese the-saurus with region-specific words, mostlyfrom the financial domain, from variousChinese speech communities.
With thelarger goal of automatically constructing aPan-Chinese lexical resource, this workaims at taking an existing semantic classi-ficatory structure as leverage and incorpo-rating new words into it.
In particular, it isimportant to see if the classification couldaccommodate new words from heterogene-ous data sources, and whether simple simi-larity measures and clustering methodscould cope with such variation.
We use thecosine function for similarity and test it onautomatically classifying 120 target wordsfrom four regions, using different datasetsfor the extraction of feature vectors.
Theautomatic classification results were evalu-ated against human judgement, and the per-formance was encouraging, with accuracyreaching over 85% in some cases.
Thuswhile human judgement is not straightfor-ward and it is difficult to create a Pan-Chinese lexicon manually, it is observedthat combining simple clustering methodswith the appropriate data sources appearsto be a promising approach toward itsautomatic construction.1 IntroductionLarge-scale semantic lexicons are important re-sources for many natural language processing(NLP) tasks.
For a significant world languagesuch as Chinese, it is especially critical to capturethe substantial regional variation as an importantpart of the lexical knowledge, which will be usefulfor many NLP applications, including natural lan-guage understanding, information retrieval, andmachine translation.
Existing Chinese lexical re-sources, however, are often based on language usein one particular region and thus lack the desiredcomprehensiveness.Toward this end, Tsou and Kwong (2006) pro-posed a comprehensive Pan-Chinese lexical re-source, based on a large and unique synchronousChinese corpus as an authentic source for lexicalacquisition and analysis across various Chinesespeech communities.
To allow maximum versatil-ity and portability, it is expected to document thecore and universal substances of the language onthe one hand, and also the more subtle variationsfound in different communities on the other.
Dif-ferent Chinese speech communities might sharelexical items in the same form but with differentmeanings.
For instance, the word ??
refers togeneral housing in Mainland China but specificallyto housing under the Home Ownership Scheme inHong Kong; and while the word ??
is similar to??
to mean general housing in Mainland China,it is rarely seen in the Hong Kong context.Hence, the current study aims at taking an exist-ing Chinese thesaurus, namely the Tongyici Cilin?????
, as leverage and extending it withlexical items specific to individual Chinese speechcommunities.
In particular, the feasibility dependson the following issues:  (1) Can lexical items fromvarious Chinese speech communities, that is, fromsuch heterogeneous sources, be classified as effec-tively with methods shown to work for clustering325closely related words from presumably the same,or homogenous, source?
(2) Could existing se-mantic classificatory structures accommodate con-cepts and expressions specific to individual Chi-nese speech communities?Measuring similarity will make sense only if thefeature vectors of the two words under comparisonare directly comparable.
There is usually no prob-lem if both words and their contextual features arefrom the same data source.
Since Tongyici Cilin(or simply Cilin hereafter) is based on the vocabu-lary used in Mainland China, it is not clear howoften these words will be found in data from otherplaces, and even if they are found, how well thefeature vectors extracted could reflect the expectedusage or sense.
Our hypothesis is that it will bemore effective to classify new words fromMainland China with respect to Cilin categories,than to do the same on new words from regionsoutside Mainland China.
Furthermore, if this hy-pothesis holds, one would need to consider sepa-rate mechanisms to cluster heterogeneous region-specific words in the Pan-Chinese context.Thus in the current study we sampled 30 targetwords specific to each of Beijing, Hong Kong,Singapore, and Taipei, from the financial domain;and used the cosine similarity function to classifythem into one or more of the semantic categories inCilin.
The automatic classification results werecompared with a simple baseline method, againsthuman judgement as the gold standard.
In general,an accuracy of up to 85% could be reached withthe top 15 candidates considered.
It turns out thatour hypothesis is supported by the Taipei test data,whereas the data heterogeneity effect is less obvi-ous in Hong Kong and Singapore test data, thoughthe effect on individual test items varies.In Section 2, we will briefly review related workand highlight the innovations of the current study.In Sections 3 and 4, we will describe the materialsused and the experimental setup respectively.
Re-sults will be presented and discussed with futuredirections in Section 5, followed by a conclusion inSection 6.2 Related WorkTo build a semantic lexicon, one has to identify therelation between words within a semantichierarchy, and to group similar words together intoa class.
Previous work on automatic methods forbuilding semantic lexicons could be divided intotwo main groups.
One is automatic thesaurusacquisition, that is, to identify synonyms ortopically related words from corpora based onvarious measures of similarity (e.g.
Riloff andShepherd, 1997; Thelen and Riloff, 2002).
Forinstance, Lin (1998) used dependency relation asword features to compute word similarities fromlarge corpora, and compared the thesaurus createdin such a way with WordNet and Roget classes.Caraballo (1999) selected head nouns fromconjunctions and appositives in noun phrases, andused the cosine similarity measure with a bottom-up clustering technique to construct a nounhierarchy from text.
Curran and Moens (2002)explored a new similarity measure for automaticthesaurus extraction which better compromiseswith the speed/performance tradeoff.
You andChen (2006) used a feature clustering method tocreate a thesaurus from a Chinese newspapercorpus.Another line of research, which is more closelyrelated with the current study, is to extend existingthesauri by classifying new words with respect totheir given structures (e.g.
Tokunaga et al, 1997;Pekar, 2004).
An early effort along this line isHearst (1992), who attempted to identify hypo-nyms from large text corpora, based on a set oflexico-syntactic patterns, to augment and critiquethe content of WordNet.
Ciaramita (2002) com-pared several models in classifying nouns with re-spect to a simplified version of WordNet and signi-fied the gain in performance with morphologicalfeatures.
For Chinese, Tseng (2003) proposed amethod based on morphological similarity to as-sign a Cilin category to unknown words from theSinica corpus which were not in the Chinese Elec-tronic Dictionary and Cilin; but somehow the testdata were taken from Cilin, and therefore could notreally demonstrate the effectiveness with unknownwords found in the Sinica corpus.The current work attempts to classify new wordswith an existing thesaural classificatory structure.However, the usual practice in past studies is totest with a portion of data from the thesaurus itselfand evaluate the results against the original classi-fication of those words.
This study is thus differ-ent in the following ways: (1) The test data (i.e.
thetarget words to be classified) were not taken fromthe thesaurus, but extracted from corpora and thesewords were unknown to the thesaurus.
(2) The326target words were not limited to nouns.
(3) Auto-matic classification results were compared with abaseline method and with the manual judgement ofseveral linguistics students constituting the goldstandard.
(4) In view of the heterogeneous natureof the Pan-Chinese context, we experimented withextracting feature vectors from different datasets.3 Materials3.1 The Tongyici CilinThe Tongyici Cilin (?????)
(Mei et al, 1984)is a Chinese synonym dictionary, or more oftenknown as a Chinese thesaurus in the tradition ofthe Roget?s Thesaurus for English.
The Roget?sThesaurus has about 1,000 numbered semanticheads, more generally grouped under higher levelsemantic classes and subclasses, and morespecifically differentiated into paragraphs andsemicolon-separated word groups.
Similarly, some70,000 Chinese lexical items are organized into ahierarchy of broad conceptual categories in Cilin.Its classification consists of 12 top-level semanticclasses, 94 subclasses, 1,428 semantic heads and3,925 paragraphs.
It was first published in the1980s and was based on lexical usages mostly ofpost-1949 Mainland China.
The Appendix showssome example subclasses.
In the followingdiscussion, we will mainly refer to the subclasslevel and semantic head level.3.2 The LIVAC Synchronous CorpusLIVAC (http://www.livac.org) stands for Linguis-tic Variation in Chinese Speech Communities.
It isa synchronous corpus developed and dynamicallymaintained by the Language Information SciencesResearch Centre of the City University of HongKong since 1995 (Tsou and Lai, 2003).
The cor-pus consists of newspaper articles collected regu-larly and synchronously from six Chinese speechcommunities, namely Hong Kong, Beijing, Taipei,Singapore, Shanghai, and Macau.
Texts collectedcover a variety of domains, including front pagenews stories, local news, international news, edito-rials, sports news, entertainment news, and finan-cial news.
Up to December 2006, the corpus hasalready accumulated over 200 million charactertokens which, upon automatic word segmentationand manual verification, amount to over 1.2 mil-lion word types.For the present study, we made use of the sub-corpora collected over the 9-year period 1995-2004from Beijing (BJ), Hong Kong (HK), Singapore(SG), and Taipei (TW).
In particular, we made useof the financial news sections in these subcorpora,from which we extracted feature vectors for com-paring similarity between a given target word and athesaurus class, which is further explained in Sec-tion 4.3.
Table 1 shows the sizes of the subcorpora.3.3 Test DataInstead of using a portion of Cilin as the test data,we extracted unique lexical items from the varioussubcorpora above, and classified them with respectto the Cilin classification.Kwong and Tsou (2006) observed that amongthe unique lexical items found from the individualsubcorpora, only about 30-40% are covered byCilin, but not necessarily in the expected senses.In other words, Cilin could in fact be enriched withover 60% of the unique items from various regions.In the current study, we sampled the most fre-quent 30 words from each of these unique itemlists for testing.
Classification was based on theirsimilarity with each of the Cilin subclasses, com-pared by the cosine measure, as discussed in Sec-tion 4.3.Subcorpus Size of Financial News Sections(rounded to nearest 1K)Word Token Word TypeBJ 232K 20KHK 970K 38KSG 621K 28KTW 254K 22KTable 1  Sizes of Individual Subcorpora4 Experiments4.1 Human JudgementThree undergraduate linguistics students and oneresearch student on computational linguistics fromthe City University of Hong Kong were asked todo the task.
The undergraduate students wereraised in Hong Kong and the research student inMainland China.
They were asked to assign whatthey consider the most appropriate Cilin category(up to the semantic head level, i.e.
third level in the327Cilin structure) to each of the 120 target words.The inter-annotator agreement was measured bythe Kappa statistic (Siegel and Castellan, 1988), atboth the subclass and semantic head levels.
Re-sults on the human judgement are discussed in Sec-tion 5.1.4.2 Creating Gold StandardThe ?gold standard?
was set at both the subclasslevel and semantic head level.
For each level, weformed a ?strict?
standard for which we consideredall categories assigned by at least two judges to aword; and a ?loose?
standard for which we consid-ered all categories assigned by one or more judges.For evaluating the automatic classification in thisstudy, however, we only experimented with theloose standard at the subclass level.4.3 Automatic ClassificationEach target word was automatically classified withrespect to the Cilin subclasses based on the similar-ity between the target word and each subclass.We compute the similarity by the cosine be-tween the two corresponding feature vectors.
Thefeature vector of a given target word contains allits co-occurring content words in the corpus withina window of ?5 words (excluding many generaladjectives and adverbs, and numbers and propernames were all ignored).
The feature vector of aCilin subclass is based on the union of the features(i.e.
co-occurring words in the corpus) from allindividual members in the subclass.The cosine of two feature vectors is computed aswvwvwv vvvvvv ?=),cos(In view of the difference in the feature space of atarget word and a whole class of words, and thusthe potential difference in the number of occur-rence of individual features, we experimented withtwo versions of the cosine measurement, namelybinary vectors and real-valued vectors.In addition, as mentioned in previous sections,we also experimented with the following condi-tions: whether feature vectors for the Cilin sub-classes were extracted from the subcorpus where agiven target word originates, or from the Beijingsubcorpus which is assumed to be representative oflanguage use in Mainland China.
All automaticclassification results were evaluated against thegold standard based on human judgement.4.4 BaselineTo evaluate the effectiveness of the automatic clas-sification, we adopted a simple baseline measureby ranking the 94 subclasses in descending orderof the number of words they cover.
In other words,assuming the bigger the subclass size, the morelikely it covers a new term, thus we compared thetop-ranking subclasses with the classifications ob-tained from the automatic method using the cosinemeasure.5 Results and Discussion5.1 Response from Human JudgesAll human judges reported difficulties in variousdegrees in assigning Cilin categories to the targetwords.
The major problem comes from the re-gional specificity and thus the unfamiliarity of thejudges with the respective lexical items and con-texts.
For instance, students grown up in HongKong were most familiar with the Hong Kong data,and slightly less so with the Beijing data, but moreoften had the least ideas for the Taipei and Singa-pore data.
The research student from MainlandChina had no problem with Beijing data and thelexical items in Cilin, but had a hard time figuringout the meaning for words from Hong Kong,Taipei and Singapore.
For example, all judges re-ported problem with the term ?
?, one of the tar-get words from Singapore referring to ????
(CLOB in the Singaporean stock market), which isreally specific to Singapore.The demand on cross-cultural knowledge thusposes a challenge for building a Pan-Chineselexical resource manually.
Cilin, for instance, isquite biased in language use in Mainland China,and it requires experts with knowledge of a widevariety of Chinese terms to be able to manuallyclassify lexical items specific to other Chinesespeech communities.
It is therefore even moreimportant to devise robust ways for automaticacquisition of such a resource.Notwithstanding the difficulty, the inter-annotator agreement was quite satisfactory.
At thesubclass level, we found K=0.6870.
At the seman-tic head level, we found K=0.5971.
Both figuresare statistically significant.3285.2 Gold StandardAs mentioned, we set up a loose standard and astrict standard at both the subclass and semantichead level.
In general, the judges managed toreach some consensus in all cases, except for twowords from Singapore.
For these two cases, weconsidered all categories assigned by any of thejudges for both standards.The gold standards were verified by the authors.Although in several cases the judges did not reachcomplete agreement with one another, we foundthat their decisions reflected various possible per-spectives to classify a given word with respect tothe Cilin classification; and the judges?
assign-ments, albeit varied, were nevertheless reasonablein one way or another.5.3 Evaluating Automatic ClassificationIn the following discussion, we will refer to thevarious testing conditions for each group of targetwords with labels in the form of Cos-<VectorType>-<Target Words>-<Cilin Feature Source>.Thus the label Cos-Bin-hk-hk means testing onHong Kong target words with binary vectors andextracting features for the Cilin words from theHong Kong subcorpus; and the label Cos-RV-sg-bjmeans testing on Singapore target words with real-valued vectors and extracting features for the Cilinwords from the Beijing subcorpus.
For each targetword, we evaluated the automatic classification(and the baseline ranking) by matching the humandecisions with the top N candidates.
If any of thecategories suggested by the human judges is cov-ered, the automatic classification is considered ac-curate.
The results are shown in Figure 1 for testdata from individual regions.Overall speaking, the results are very encourag-ing, especially in view of the number of categories(over 90) we have at the subclass level.
An accu-racy of 80% or more is obtained in general if thetop 15 candidates were considered, which is muchhigher than the baseline result in all cases.
Table 2shows some examples with appropriate classifica-tion within the Top 3 candidates.
The two-lettercodes in the ?Top 3?
column in Table 2 refer to thesubclass labels, and the code in bold is the onematching human judgement.In terms of the difference between binary vec-tors and real-valued vectors in the similarity meas-urement, the latter almost always gave better re-sults.
This was not surprising as we expected byusing real-valued vectors we could be less affectedby the potential huge difference in the featurespace and the number of occurrence of the featuresfor a Cilin subclass and a target word.As for extracting features for Cilin subclassesfrom the Beijing subcorpus or other subcorpora,the difference is more obvious for the Singaporeand Taipei target words.
We will discuss the re-sults for each group of target words in detail below.5.4  Performance on Individual SourcesTarget words from Beijing were expected to have arelatively higher accuracy because they are ho-mogenous with the Cilin content.
It turned out,however, the accuracy only reached 73% with top15 candidates and 83% with top 20 candidateseven under the Cos-RV-bj-bj condition.
Wordslike ??
(SARS), ??
(save water), ???
(in-dustrialize / industrialization), ???
(passing rate)and ??
(multi-level marketing) could not be suc-cessfully classified.Results were surprisingly good for target wordsfrom the Hong Kong subcorpus.
Under the Cos-RV-hk-hk condition, the accuracy was 87% withtop 15 candidates and even over 95% with top 20candidates considered.
Apart from this high accu-racy, another unexpected observation is the lack ofsignificant difference between Cos-RV-hk-hk andCos-RV-hk-bj.
One possible reason is that therelatively larger size of the Hong Kong subcorpusmight have allowed enough features to be ex-tracted even for the Cilin words.
Nevertheless, thesimilar results from the two conditions might alsosuggest that the context in which Cilin words areused might be relatively similar in the Hong Kongsubcorpus and the Beijing subcorpus, as comparedwith other communities.Similar trends were observed from the Singa-pore target words.
Looking at Cos-RV-sg-sg andCos-RV-sg-bj, it appears that extracting featurevectors for the Cilin words from the Singaporesubcorpus leads to better performance than extract-ing them from the Beijing subcorpus.
It suggeststhat although the Singapore subcorpus shares thosewords in Cilin, the context in which they are usedmight be slightly different from their use inMainland China.
Thus extracting their contextualfeatures from the Singapore subcorpus might betterreflect their usage and makes it more comparable329Classification Accuracy for HK Data01020304050607080901000 5 10 15Top NAcc %Cos-Bin-hk Cos-Bin-bj Cos-RV-hk Cos-RV-bj BaselineClassification Accuracy for BJ Data010203040506070800 5 10 15Top NAcc %Cos-Bin Cos-RV Baseline`Classification Accuracy for SG Data01020304050607080901000 5 10 15Top NAcc %Cos-Bin-sg Cos-Bin-bj Cos-RV-sg Cos-RV-bj BaselineClassification Accuracy for TW Data01020304050607080901000 5 10 15Top NAcc %Cos-Bin-tw Cos-Bin-bj Cos-RV-tw Cos-RV-bj Baselinewith the unique target words from Singapore.Such possible difference in contextual featureswith shared lexical items between different Chi-nese speech communities would require furtherinvestigation, and will form part of our future workas discussed below.
Despite the above observationfrom the accuracy figures, the actual effect, how-ever, seems to vary on individual lexical items.Table 3 shows some examples of target wordswhich received similar (with white cells) and verydifferent (with shaded cells) classification respec-tively under the two conditions.
It appears that theregion-specific but common concepts like ???
(office), ??
(apartment), ??
(private resi-dence), which relate to building or housing, wereaffected most.Taipei data, on the contrary, seems to be moreaffected by the different testing conditions.
Cos-Bin-tw-bj and Cos-RV-tw-bj produced similar re-sults, and both conditions showed better resultsthan Cos-RV-tw-tw.
This supports our hypothesisthat the effect of data heterogeneity is so apparentthat it is much harder to classify target wordsunique to Taipei with respect to the Cilin catego-ries.
In addition, as Kwong and Tsou (2006) ob-served, Beijing and Taipei data share the leastnumber of lexical items, among the four regionsunder investigation.
Hence, words in Cilin mightnot have the appropriate contextual feature vectorsextracted from the Taipei subcorpus.The different results for individual regionsmight be partly due to the endocentric and exocen-tric nature of influence in lexical innovation (e.g.Tsou, 2001) especially with respect to the financialdomain and the history of capitalism in individualregions.
This factor is worth further investigation.Figure 1  Classification Results with Top N Candidates330No.
Region Word Top 31 BJ ????
Di  Gb  Df2 BJ ??
Bq  Ae  Hd3 BJ ??
Bm  Hi  Hd4 BJ ??
Hj  Di  Hd5 BJ ??
Aa  If  Ae6 HK ??
Da  Cb  Bi7 HK ??
Bb  Jc  Hi8 HK ??
Dj  Da  Hi9 HK ??
Bi  Dj  Dn10 HK ???
Bi  Dj  Gb11 SG ??
Ca  Dm  Hi12 SG ??
Ig  He  Dj13 SG ??
Dm  Dj  Hi14 SG ??
Dm  Dj  He15 SG ??
Hi  Hg  Af16 TW ??
Dm  Hd  Hi17 TW ??
Jb  Dn  Dj18 TW ??
Ja  Ca  He19 TW ???
Hf  Dj  Dm20 TW ??
Dj  Ed  CaTable 2  Examples of Correct Classification (Top 3)15.5 General Discussions and Future WorkAs mentioned in a previous section, the test data inthis study were not taken from the thesaurus itself,but were unknown words to the thesaurus.
Theywere extracted from corpora, and were not limitedto nouns.
We found in this study that the simplecosine measure, which used to be applied for clus-tering contextually similar words from homoge-nous sources, performs quite well in general forclassifying these unseen words with respect to theCilin subclasses.
The automatic classification re-sults were compared with the manual judgement ofseveral linguistics students.
In addition to provid-ing a gold standard for evaluating the automaticclassification results in this study, the human1 English gloss: 1-restoring agricultural lands for affore-station, 2-material, 3-coal mine, 4-to seize (an opportu-nity), 5-unemployed, 6-sales performance, 7-broadband,8-red chip, 9-interest rate, 10-property stocks, 11-financial year, 12-sell short, 13-proposal, 14-sell, 15-brigadier general, 16-financial holdings, 17-individualstocks, 18-property market, 19-cash card, 20-stub.judgement on the one hand proves that the Cilinclassificatory structure could accommodate region-specific lexical items; but on the other hand alsosuggests how difficult it would be to construct sucha Pan-Chinese lexicon manually as rich culturaland linguistic knowledge would be required.Moreover, we started with Cilin as the establishedsemantic classification and attempted to classifywords specific to Beijing, Hong Kong, Singapore,and Taipei respectively.
The heterogeneity ofsources did not seem to hamper the similaritymeasure on the whole, provided appropriate data-sets are used for feature extraction, although theactual effect seemed to vary on individual lexicalitems.No.
Source Word Ranking of1st appropriate classCos-RV-hk-hk,etc.Cos-RV-hk-bj,etc.1 HK ??
1 12 HK ??
1 13 HK ??
1 14 HK ??
2 105 HK ??
19 56 HK ???
13 307 SG ???
2 28 SG ??
2 19 SG ???
5 410 SG ??
1 1211 SG ???
1 912 SG ??
8 2613 TW ??
1 114 TW ??
4 315 TW ??
5 116 TW ??
18 417 TW ???
12 518 TW ???
8 2Table 3  Different Impact on Individual Items2Despite the encouraging results with the top 15candidates in the current study, it is desirable toimprove the accuracy for the system to be useful in2 English gloss: 1-sales performance, 2-broadband, 3-red chip, 4-add (supply to market), 5-low level, 6-office,7-financial year, 8-sell short, 9-rights issue, 10-apartment, 11-holding space rate, 12-private residence,13-stub, 14-individual stocks, 15-financial holdings, 16-investment trust, 17-growth rate, 18-cash card.331practice.
Hence our next step is to expand the testdata size and to explore alternative methods suchas using a nearest neighbour approach.
In addition,we plan to further the investigation in the follow-ing directions.
First, we will experiment with theautomatic classification at the Cilin semantic headlevel, which is much more fine-grained than thesubclasses.
The fine-grainedness might make thetask more difficult, but at the same time the morespecialized grouping might pose less ambiguity forclassification.
Second, we will further experimentwith classifying words from other special domainslike sports, as well as the general domain.
Third,we will study the classification in terms of the part-of-speech of the target words, and their respectiverequirements on the kinds of features which givebest classification performance.The current study only dealt with presumablyModern Standard Chinese in different communities,and it could potentially be expanded to handlevarious dialects within a common resource, even-tually benefiting speech lexicons and applicationsat large.6 ConclusionIn this paper, we have reported our study on aunique problem in Chinese language processing,namely extending a Chinese thesaurus with newwords from various Chinese speech communities,including Beijing, Hong Kong, Singapore andTaipei.
The critical issues include whether the ex-isting classificatory structure could accommodateconcepts and expressions specific to various Chi-nese speech communities, and whether the differ-ence in textual sources might pose difficulty in us-ing conventional similarity measures for the auto-matic classification.
Our experiments, using thecosine function to measure similarity and testingwith various sources for extracting contextual vec-tors, suggest that the classification performancemight depend on the compatibility between thewords in the thesaurus and the sources from whichthe target words are drawn.
Evaluated against hu-man judgement, an accuracy of over 85% wasreached in some cases, which were much higherthan the baseline and were very encouraging ingeneral.
While human judgement is not straight-forward and it is difficult to create a Pan-Chineselexicon manually, combining simple classificationmethods with the appropriate data sources seems tobe a promising approach toward its automaticconstruction.AcknowledgementsThe work described in this paper was supported bya grant from the Research Grants Council of theHong Kong Special Administrative Region, China(Project No.
CityU 1317/03H).AppendixThe following table shows some examples of theCilin subclasses:Class SubclassesA ?
(Human) Aa ?
Ae ??
(Occupation)  Af??
(Identity) ?
AnB ?
(Things) Ba ?
Bb ???
(Shape) ?
Bi ??
(Animal)?
Bm ??
(Mate-rial)?Bq ??
(Clothing) ?
BrC ?????
(Time and Space)Ca ??
(Time)  Cb ??
(Space)D ????
(Abstract entities)Da ??
??
(Condition) ?
Df??
(Ideology) ?
Di ??
??
(Society) Dj ??
(Economics) ?Dm ??
(Organization) Dn ????
(Quantity)E ??
(Characteristics)Ea ?
Ed ??
(Property)?
EfF ??
(Action) Fa ?
FdG ????
(Psychologicalactivities)Ga ?
Gb ????
(Psychologi-cal activities)?
GcH ??
(Activities)Ha ?
He ????
(Economicactivities) ?
Hd ??
(Produc-tion) ?
Hf ????
(Transporta-tion) Hg ????
(Scientific re-search)?
Hi ??
(Social contact)Hj ??
(Livelihood)I ?????
(Phenomenon andstate)Ia ?
If ??
(Circumstance)  Ig ??
(Process)?
IhJ ??
(Association)Ja ??
(Liaison)  Jb ??
(Simi-larity and Difference) Jc ??
(Matching) ?
JeK ??
(Auxiliary words)Ka ?
KfL ??
(Respectful ex-pressions)332ReferencesCaraballo, S.A. (1999)  Automatic construction of ahypernym-labeled noun hierarchy from text.
In Pro-ceedings of the 37th Annual Meeting of the Associa-tion for Computational Linguistics (ACL?99), Mary-land, USA, pp.120-126.Ciaramita, M. (2002)  Boosting automatic lexical acqui-sition with morphological information.
In Proceed-ings of the ACL?02 Workshop on Unsupervised Lexi-cal Acquisition, Philadelphia, USA, pp.17-25.Curran, J.R. and Moens, M. (2002)  Improvements inAutomatic Thesaurus Extraction.
In Proceedings ofthe ACL?02 Workshop on Unsupervised Lexical Ac-quisition, Philadelphia, USA, pp.59-66.Hearst, M. (1992)  Automatic Acquisition of Hyponymsfrom Large Text Corpora.
In Proceedings of the 14thInternational Conference on Computational Linguis-tics (COLING-92), Nantes, France, pp.539-545.Kwong, O.Y.
and Tsou, B.K.
(2006)  Feasibility of En-riching a Chinese Synonym Dictionary with a Syn-chronous Chinese Corpus.
In T. Salakoski, F. Ginter,S.
Pyysalo and T. Pahikkala (Eds.
), Advances inNatural Language Processing: Proceedings of Fin-TAL 2006.
Lecture Notes in Artificial Intelligence,Vol.4139, pp.322-332, Springer-Verlag.Lin, D. (1998)  Automatic Retrieval and Clustering ofSimilar Words.
In Proceedings of the 36th AnnualMeeting of the Association for Computational Lin-guistics and 17th International Conference on Com-putational Linguistics (COLING-ACL?98), Montreal,Canada, pp.768-774.Mei et al ???????????????
(1984)???????
(Tongyici Cilin).
?????
(Commerical Press) / ??????
?.Pekar, V. (2004)  Linguistic Preprocessing for Distribu-tional Classification of Words.
In Proceedings of theCOLING2004 Workshop on Enhancing and UsingElectronic Dictionaries, Geneva.Riloff, E. and Shepherd, J.
(1997)  A corpus-based ap-proach for building semantic lexicons.
In Proceed-ings of the Second Conference on Empirical Methodsin Natural Language Processing, Providence, RhodeIsland, pp.117-124.Siegel, S. and Castellan, N.J. (1988)  NonparametricStatistics for the Behavioral Sciences (2nd Ed.
).McGraw-Hill.Thelen, M. and Riloff, E. (2002)  A BootstrappingMethod for Learning Semantic Lexicons using Ex-traction Pattern Contexts.
In Proceedings of the 2002Conference on Empirical Methods in Natural Lan-guage Processing (EMNLP 2002), Philadelphia,USA.Tokunaga, T., Fujii, A., Iwayama, M., Sakurai, N. andTanaka, H. (1997)  Extending a thesaurus by classi-fying words.
In Proceedings of the ACL Workshopon Automatic Information Extraction and Building ofLexical Semantic Resources for NLP Applications,Madrid, pp.16-21.Tseng, H. (2003)  Semantic Classification of ChineseUnknown Words.
In the Proceedings of the ACL-2003 Student Research Workshop, Companion Vol-ume to the Proceedings of the 41st Annual Meeting ofthe Association for Computational Linguistics, Sap-poro, Japan.Tsou, B.K.
(2001)  Language Contact and Lexical Inno-vation.
In M. Lackner, I. Amelung and J.
Kurtz(Eds.
), New Terms for New Ideas: Western Knowl-edge and Lexical Change in Late Imperial China.Berlin: Brill.Tsou, B.K.
and Kwong, O.Y.
(2006)  Toward a Pan-Chinese Thesaurus.
In Proceedings of the Fifth In-ternational Conference on Language Resources andEvaluation (LREC 2006), Genoa, Italy.Tsou, B.K.
and Lai, T.B.Y.
???????
(2003)  ????????????.
In B. Xu, M. Sun and G.Jin ??????????
(Eds.
), ??????????????
(Issues in Chinese LanguageProcessing).
???????
?, pp.147-165You, J-M. and Chen, K-J.
(2006)  Improving ContextVector Models by Feature Clustering for AutomaticThesaurus Construction.
In Proceedings of the FifthSIGHAN Workshop on Chinese Language Processing,COLING-ACL 2006, Sydney, Australia, pp.1-8.333
