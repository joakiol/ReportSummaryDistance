Restricted Parallelism in Object-Oriented Lexical ParsingPeter Neuhaus Udo HahnFreiburg University~} Computational Linguistics LabEuropaplatz 1, D-79085 Freiburg, Germany{neuhaus, hahn}@ coling, uni-freiburg, deAbstractWe present an approach to parallel naturallanguage parsing which is based on a con-current, object-oriented model of computa-tion.
A depth-first, yet incomplete pars-ing algorithm for a dependency grammar isspecified and several restrictions on the de-gree of its parallelization are discussed.1 IntroductionThere are several arguments why computational lin-guists feel attracted by the appeal of parallelism fornatural language understanding (for a survey, cf.
Hahn& Adriaens (1994)): the ubiquitous requirement ofen-hanced efficiency of implementations, itsinherent po-tential for fault tolerance and robustness, and a flavorof cognitive plausibility based on psycholinguistic ev-idences from the architecture of the human languageprocessor.
Among the drawbacks of parallel process-ing one recognizes the danger of greedy resource de-mands and communication overhead for processorsrunning in parallel as well as the immense complexityof control flow making it hard for humans to properlydesign and debug parallel programs.In this paper, we will consider aframework for par-allel natural anguage parsing which summarizes theexperiences we have made during the development ofa concurrent, object-oriented parser.
We started outwith a rather liberal conception which allowed for al-most unconstrained parallelism.
As our work pro-gressed, however, we felt the growing need for restrict-ing its scope as a continuous "domestication process".While still keeping the benefits of parallelism, we havearrived at a point where we argue for a basically se-rial model patched with several parallel phases ratherthan a basically parallel model with few synchroniza-tion checkpoints.
Primarily, this change in perspec-tive was due to large amounts of artificial ambiguitiesthat could be traced to "blind" parallel computationswith excessive r source allocation requirements.
Con-tinuously taming the parallel activities of the parserand, furthermore, sacrificing highly esteemed theoret-ical principles uch as the completeness of the parser,i.e., the guaranteed production of all analyses for agiven input, led us to determine those critical portionsof the parsing process which can reasonably be pur-sued in a parallel manner and thus give real benefits interms of efficiency and effectiveness.2 Design Requirements for the ParserThe application framework for the parsing device un-der consideration is set up by the analysis of real-world expository texts (viz.
information technologyproduct reviews and medical findings reports).
Theparser operates as the NLP component ofa text knowl-edge acquisition and knowledge base synthesis ys-tem.The analysis of texts (as opposed to sentences inisolation) requires the consideration fdiscourse phe-nomena.
This includes the interaction of discourse n-tities (organized in focus spaces and center lists) withstructural descriptions from the parser and conceptualinformation from the domain knowledge base.
Thus,different knowledge sources have to be integrated inthe course of an incremental text understanding pro-cess.Within realistic NLP scenarios the parsing devicewill encounter ungrammatical nd extragrammaticalinput.
In any of these cases, the parser should guar-antee a robust, graceful degradation performance, i.e.,produce fragmentary parses and interpretations corre-sponding to the degree of violation or lack of grammarconstraints.
Depending on the severity of fragmenta-tion, changes in the parsing strategies which drive thetext analysis might also be reasonable.These requirements obviously put a massive bur-den on the control mechanisms ofa text understandingsystem.
In particular, entirely serial control schemataseem inappropriate, since they would introduce arti-ficial serialization constraints into basically parallelprocesses (Waltz & Pollack, 1985).5023 Object-oriented Lexical ParsingIn this section, we introduce the PARSETALK system,whose specification and implementation is based onan object-oriented, inherently concurrent approach tonatural anguage analysis.
We consider constraintswhich introduce increasing restrictions on the paral-lel execution of the parsing task.
This leads us to aparsing algorithm with restricted parallelism, whoseexperimental evaluation isbriefly summarized.3.1 The PARSETALK ModelThe PARSETALK grammar we use (for a survey, cf.BrOker et al (1994)) is based on binary relations be-tween words, e.g., dependency relations between ahead and its modifier, or textual relations between ananaphor and its antecedent.
Restrictions on possiblerelations are attached to the words, e.g., expressed asvalencies in the case of dependency relations, yieldinga strictly lexicalized grammar in the sense of Schabeset al (1988).
The individual behavior of words is gen-eralized in terms of word classes which are primarilymotivated by governability orphrasal distribution; ad-ditional criteria include inflection, anaphoric behavior,and possible modifiers.
A word class specifies mor-phosyntactic features, valencies, and allowed order-ings for its instances.
Further abstraction is achievedby organizing word classes at different levels of speci-ticity in terms of inheritance hierarchies.
The specifi-cation of binary constraints already provides inherentmeans for robust analysis, as grammatical functionsdescribe relations between words rather than well-tormed constituents.
Thus, ill-formed input does oftenstill have an (incomplete) analysis.Tile PARSETALK parser (for a survey, cf.
Neuhaus& Hahn (1996)) generates dependency structures forsentences and coherence relations at the text level ofanalysis.
In order to establish, e.g., a dependency re-lation the syntactic and semantic onstraints relatingto the head and its prospective modifier are checkedin tandem.
Due to this close coupling of grammat-ical and conceptual constraints syntactically possiblethough otherwise disallowed structures are filtered outas early as possible.
Also, the provision of con-ceptual entities which are incrementally generated bythe semantic interpretation process upplies the neces-sary anchoring points for the continuous resolution oftextual anaphora nd ellipses (Strube & Hahn, 1995;Hahn et al, 1996).The lexical distribution of grammatical knowledgeone finds in many lexiealized grammar formalisms(e.g., LTAGS (Schabes et al, 1988) or HPSG (Pollard& Sag, 1994)) is still constrained to declarative no-tions.
Given that the control flow of text understand-ing is globally unpredictable and, also, needs to bepurposefully adapted to critical states of the analysis(e.g., cases of severe extragrammaticality), we drivelexicalization to its limits in that we also incorporateprocedural control knowledge at the lexical gr,'unmarlevel.
The specification of lexiealized communicationprimitives "allows heterogeneous and local lorms of in-teraction among (groups of) lexical items.
We, never-theless, take care not to mix up both levels and providea formally clean specification platform in terms of theactor model of computation (Agha & Hewitt, 1987).In this model each object (actor) constitutes a processon its own.
Actors communicate bysending messages,usually, in an asynchronous mode.
Upon reception ofa message, the receiving actor processes the associ-ated method, a program composed of several gram-matical predicates, e.g., SYNTAXCtIECK, which ac-counts for morphosyntactic or word order constraints,or CONCEPTCItECK, which refers to the terminolog-ical knowledge representatiou layer and accounts fortype and further conceptual dmissibility constraints(number restrictions, etc.
).The grammatical description of single words is or-ganized in a hierarchy of so-called word actors whichnot only inherit he declarative portions of grammati-eal knowledge, but are also supplied with lexicalizedprocedural knowledge that specifies their parsing beohavior in terms of a message protocol.
A specializedactor type, called phrase actor, comprises word actorswhich are connected by dependency relations and en-capsulates inh)rmation about hat phrase.3.2 Parallelism in ParsingIn the following, we discuss three stages of increas-ing restrictions of parallelism at the word level, all ofwhich were considered for the design of the algorithmprovided in Section 3.3.Unbounded Parallelism.
Brute-force parsing mod-els such as the primordial soup algorithm (Janssenet al, 1992), at first sight, exhibit a vast potential forparallel execution, since the central operation of build-ing a structure from two independent parts (in our ap-plication, e.g., the combination of a head and a sin-gle modifier) apparently does not require any centr,'d-ized control.
In such an entirely unconstrained paral-lel model, a word actor is instantiated from the inputstring and sends earch messages to all other word ac-tors in order to establish a dependency relation, even-tually generating a complete parse of the input.Consider, however, the case in which a Noun is pre-ceded by a Determiner and an Adjective.
In order toform the noun phrase \[Det Aclj \[N\]\] two computationsequences will occur in a primordial soup parser: at-taching Det to the N first, then adding Adj, or viceversa.
Hence, the major drawback of unrestrictedparallel algorithms i their non-confluency and, sub-sequently, either the large (exponential, in the worst503case) number of spuriously ambiguous analyses, orthe global operation of subsequent duplicate limina-tion.
This led us to restrain from unbounded paral-lelism and, rather, guarantee contluent behavior by thedesign of the parsing algorithm.Conflueney.
In the first prototype, we enforced con-fluency by an incremental structure-building conditionon the basis of a synchronization schema.
Messageswere forwarded strictly from right to left wanderingthrough the preceding context rather than being broad-casted.
Partial structures were organized such that amessage which could be successfully processed at alarger structure was not forwarded to any of its con-stituent parts.
But still, the number of ambiguities re-mained prohibitively large, often due to unnecessarypartial structures with large discontinuities.
For in-stance, any determiner preceding a noun forms a newstructure, with the Det  modifying the N. Usually, acontiguity restriction would filter out those structuresgiven perfectly well-formed input.
But such a restric-tion is detrimental to requirements set up in a realis-tic text parsing environment, in which the analysis of(possibly large) fractions of un- as well as extragram-matical input must be skipped.
Furthermore, order-ing restrictions on dependency analyses lor Germancan be formulated more transparently, if discontinu-ous structures are allowed.Depth-First Approach.
These experiences led to aredesign of the first prototype.
The parser's forward-ing mechanism for search messages was further e-stricted to circumvent the above mentioned problemof erroneous discontinuous (over)analyses.
In this ap-proach, we let phrases that constituted alternative anal-yses for the same part of the input text be encapsu-lated in a container actor.
Container actors play acentral role in controlling the parsing process, becausethey encapsulate information about he preceding con-tainers that hold the left context and the chronologi-cally previous containers, i.e., a part of the parse his-tory.
Container actors comprising single-word phrasesare called lexical containers.
All phrases in the ac-tive container send a search message to the currentcontext container that forwards them to its encapsu-lated phrases.
The search messages are then asyn-chronously distributed to words within each phrase.
Ifat least one attachment toone of these phrases is pos-sible, no further forwarding to containers which covertext positions preceding the current position will oc-cur.
Thus, the new container composed at this stagewill contain only those phrases that were encapsulatedin the context container and that could be enlarged byattaching a phrase from the active container.This procedure nforces a depth-first style of pro-gression, leaving unconsidered many of the theoreti-eally possible combinations of partial analyses.
Still,some information has to be retained in order to back-track after failures or to employ alternative parsingstrategies.
We encounter a trade-off between robust-ness, efficiency, and completeness in parsing.
If wewere to allow for unrestricted backtracking, we wouldjust trade in run-time complexity for space complex-ity (for a more detailed discussion, cf.
Neuhaus &Hahn (1996)).
Hence, we rather restrict backtrack-ing to those containers in the parse history which holdgoverning phrases, while the containers with modify-ing phrases are immediately deleted after attachment 1 .3.3 Restricted Parallel Parsing AlgorithmThe parsing algorithm of the PARSETALK system iscentered around the head search process of the cur-rently active word actor.
If it fails, a modifier searchprocess is triggered; if it succeeds, a new dependencystructure is constructed combining the partial analy-ses.
In case both of these protocols are not successful,containers may be skipped so that discontinuous anal-yses may occur.
If the skipping process encounters alinguistically valid boundary (in the most trivial case,the punctation mark of the previous entence) it stopsand switches to a backtracking mode leading to a kindof roll-back of the parser invalidating the currentlypursued analysis.
In a companion paper (Neuhaus &Hahn, 1996), we give an integrated escription of thevarious ubprotocols needed for head/modifier search,ambiguity handling, skipping, backtracking, preferen-tial and predictive parsing.In this paper, we concentrate instead on the basicmessage passing patterns for the establishment of de-pendency relations, viz.
the searchHead protocol,and its concurrency aspects.
For illustration purposeswe here introduce the protocol in a diagrammatic form(Figs.
1 to 3).
The figures depict the main steps ofword actor initialization, head search, and phrasal at-tachment.
This format eases communication, whileformal specifications based on a temporal logic frame-work are used when dealing with formal properties ofthe parser (cf., e.g., Schacht (1995) for a partial termi-nation proof of the receipt handler introduced below).The parser is started by an ana lyze :  messagedirected to a ParserActor ,  which is responsiblefor the global administration of the parsing process(cf.
Fig.
1).
It instantiates a Lexkca lCon iza ine~: -Actor  that encapsulates the (potentially)ambiguousreadings of the first word of the text, as accessed fromthe lexicon and corresponding word classes.Upon receiving the analyzeWithContext:message from the ParserActor  (of.
Fig.
2),X Hence, the incompleteness property of our parser stemsfirom the selective storage of analyses (i.e., an "incompletechart" in chart erms), partially compensated byreanalysis.504LexicalCont ainer Actor/~;hraseActor Phra~Actor""~..analyzoFirst ," ,' new ',', /,,new / //~.
fllow ~ ;\]( ,' anal~eWithContext:ParserActor~2> Aeloring .
.
.
.
.
J ~-~k aaynchronous message(~) WordActor -" ~ -'~ synchronous messageFigure I: Protocol for Word Actor Initializationa ReceiptHandler is instantiated by a syn-chronous message, intended to detect he partial ter-mination of the subsequently started search proto-col.
The per fo rmSearchHead message triggers(via per fo rmSearchHead '2o  : messages) asyn-chronous searchHeadFor:  messages to be for-warded by each receiving ph r a s e Ac t o r to its right--most we rdAct  o r. From this origin, the search mes-sage can be distributed to all word actors at the right"rim" of the dependency Irec by simply forwardingit to Ihe respective heads.
After forwarding a, eachsearehHead message vokes the check of syntacticand semantic restrictions by the corresponding meth-ods.
These restrictions nmst be \[net in order to estab-lish a dependency relation between the receiving wordactor and the sender of the n|essage.
Provided thatthese constraints are fnltilled, an a t tach  : messageis sent to the encapsulating PhraseActor .
Beforethe new composite phrase can be built, the address ofthe next container actor must be determined.
Accord-ingly, the getNextConta iner  message ither re-turns this address directly eL if it is not available yet, itwill create the next container actor first (the actual cre-ation protocol is not shown).
The newIn  : messagesubsequently creates a new PhraseActor  that willencapsulate the word actors of the new phrase.
No-rice, that several a t tach  : messages can be receivedby a phrase, because the searcht tead  messages areevaluated in parallel by its word actors.In order to actually build the new phrase aeopyAndAt tach  : message is sent 3.
Fig.
3 depictsthe copying of the governing and modifying phrasesZSince forwarded messages are sent asynchronously theprocessing of the searchHoadFor: message takes place concur-rently at the forwarding sender m~d the respective receivers.3As an alternative to the immediate stablishment of adependency relation, a hoadFound message can be returnedto enable the subsequent selection of preferred attachments(cf.
Neuhaus & Hahn (1996) for such a protocol extension).Par~erActor Recur llamll~ana~yzoW~hCtmtmx?."
~ / ctl~ttBFor:\ \[ ~ ~.~l~dFt~:  (Icttve) {:oi~tllinerActor(r~nlexl) 1\]out Idne rAc/:or ~,.
< ~  ,,, >Cant~nerAdorFigure 2: Protocol for the Search for a Head(active) ContalnerActorF- - -  ??""??
'= " " : C - - -<-"?~'?
"~-~:  ~v/--/' ...... ___ " r  .
.
.
.
.
.
.
.
)pdl~ dFeamr,= ' - Fei~ /~ _  ~q, r ~  ~ ~-ContalnerActorFigure 3: Protocol for Establishing a Dependenciesinto the new PhraseActor by copyHeadFor:and copyModFor  : messages,  respectively - - cot)y-ing enables alternative attachments in the concur-rent system, i.e., no destructive operations are carriedout.
Note that in contrast to the searchHead mes-sage the PhraseActor  lbrwards the copy messageto its root actor from where it is distributed in thetree.
The dependency relation connecting the copiedphrases (indicated by the bold edge in the newly builtPhraseAetor )  is created by the es tab l i sh :message.
Since word actors hold information (suchas features or coverage) locally, updates ,are necessaryto propagate the effects of the cre~ttion of the relation.Alier updating inlormation at relevant word actors inthe resultant tree, successful termination of the scratchmessage is signalled to the Rece ip tHand ler .
Ifnone of the receipts signals success to the handler,the search head protocol will be followed by moditiersearch or backtracking 4 protocols not shown here (cf.4Thus synchronization of protocols enables word-wisescanning, backtracking, etc.
This avoids severe problemsusually encountered in parsers with unrestricted parallelism.505Neuhaus & Hahn (1996)).
In the scenario we have dis-cussed, the Rece ip t  Hand le  r eventually will detectthe success and the termination of the search ead pro-tocol.
Next, the new Conta inerActor  will be sentan ana lyzeWi thContext  : message to continuethe parsing process.3.4 Preliminary Experimental EvaluationThe efficiency gain that results from the parser designintroduced in the previous sections can empiricallybe demonstrated bya comparison of the PARSETALKsystem (abbreviated as "PT" below) with a standardactive chart parser 5 (abbreviated as"CP").
Since thechart parser is implemented in Smalltalk, while thePARSETALK system is implemented in Actalk (Briot,1989) - -  a language which simulates the parallel exe-cution of actors - - ,  a direct comparison of run times isnot reasonable (though even at that level of consider-ation the PARSETALK system outperforms the chartparser).
We therefore compare, at a more abstractcomputation level, the number of method executionsgiven exactly the same dependency grammar 6.
Thecomputationally most expensive methods we considerare SYNTAXCHECK and CONCEPTCHECK (cf.
Sec-tion 3.1).
Especially the latter consumes large compu-tational resources, since for each interpretation vari-ant a knowledge base context has to be built and con-ceptual consistency must be checked.
Therefore, itis only considered when the syntactic riteria are ful-filled.
The number of calls to these methods for a sam-ple of 13 randomly chosen, increasingly complex sen-tences from the information technology domain testlibrary is given by Fig.
4 ("CP.syn" and "PT.syn") andFig.
5 ("CP.con" and "PT.con").
A reduction by a fac-tor of four to five in the (unweighted) average case canbe observed applying the PARSETALK strategy.Furthermore, the PARSETALK parser, by design, isable to cope with discontinuities stemming from un-or extragrammatical input.
The performance of a re-vised version of the chart parser which also handlesthese cases is given as "CP.disc.syn/con" in the fig-ures.
The missing value for sentence 10 results fromthe chart parser crashing on this input because of spacerestrictions of the run-time system (the experimentswere conducted on a SPARCstation 10 with 64 MBof main memory).
The average reduction in compar-5Winograd' s (1983) chartparser was adapted to parsing adependency grammar.
No packing or structure-sharing tech-niques could be used, since semantic interpretation ccursonline, thus requiring continuous referential instantiation fstructural linguistic items (cf.
also Section 4).6This can only serve as a rough estimate, since it does nottake into account the exploitation of PARSETALK'S concur-rency.
Furthermore, the chart parser performs an extremelyresource-intensive subsumption checking method unneces-sary in the PARSETALK system.totoE600050004~03~02~010000.. , , , , , , , , , , , ,"CP.disc.syn" -* - -  /"CP.syn" ~-  / ""PT.syn" ..- .... /~/ , , , / / _. .
.
.
.
.2 3 4 5 6 7 8 9 10 11 12 13sentence180160140120100806040200Figure 4: Calls to SYNTAXCHECK.
.
.
.
.
.
.
A"CP.eon" ~-  / \"PT.con" ..D .... / \/ \.
.
.
.
, , , .
.
.
.
.
.
.
, .
.
.
.
.
.
.
.
.
.
.
.
.
.
, , .
.
.2 3 4 5 6 7 8 9 10 11 12 13sentenceFigure 5: Calls to CONCEPTCIiECKison with the extended version of the chart parser isabout six to nine.4 Related WorkResearch on object-oriented natural language pars-ing actually started with the work of Small & Rieger(1982) on word experts.
Based on a conceptual pars-ing model, this approach took a radical position onfull lexic',dization a d communication based on a strictmessage protocol.
Major drawbacks concerned anoverstatement of he role of lexical idiosyncrasies andthe lack of grammatical bstraction and formalization.Preserving the strengths of this approach (lexicalizedcontrol), but at the sane time reconciling it with cur-rent standards of lexicalized grammar specification,the PARSETALK system can be considered a unifyingapproach which combines procedural and declarativespecifications atthe grammar level in a formally disci-plined way.
This also distinguishes our approach fromanother major stream of object-oriented natural an-guage parsing which is almost entirely concerned withimplementational aspects of object-oriented program-ruing, e.g., Habert (1991), Lin (1993) or Yonezawa &Ohsawa (1994).The reasons why we diverge from conventionalparsing methodologies, e.g., chart parsing based on506Earley- or Tomita-style algorithms, are two-fold.
First,at the syntactic level, any kind of chart parsingalgorithm faces combinatorial problems with non-contiguous grammar specifications (accounting fordiscontinuous language structures) and, in particular,extra- and ungrammatical language input (cf., e.g.,Magerman & Weir (1992) for probabilistic and Leeet al (1995) for symbolic heuristics to cope with thatproblem).
Thus, under ealistic onditions, these tech-niques loose a lot of their theoretical ppeal and com-pete with other approaches merely on the basis of per-formance measurements.
Second, including seman-tic considerations, even if we assume fficient syntac-tic processing for the sake of argument, he questionarises how semantic interpretations can be processedin an incremental, comparably efficient way.
Thoughexperiments have been run with packing feature struc-tures and interleaving syntactic and semantic analyses(Dowding et al, 1994), or with the intentional under-specification of logical forms (leaving scope ambigui-ties of quantifiers and negations underdetermined; cf.,e.g., Hobbs (1983) or Reyle (1995)), no conclusive v-idences have been generated so far in favor of a gen-eral method for efficient, online semantic interpreta-tion.
As we are faced, however, with the problem towork out text interpretations incrementally and withinreasonable resource bounds, we opt for a methodol-ogy that constrains the amount of ambiguous truc-tures right at the source.
Hence, the incompleteness ofthe algorithm trades theoretical purism for feasibilityof realistic NLP.5 Conc lus ionsWe have presented a restricted approach to paral-lelism for object-oriented lexicalized parsing.
Giventhe complex control structure requirements of a real-istic text understanding system (integrated, incremen-tal, robust processing), we argued for a unifying ap-proach in which declarative grammar constraints arelexically encoded and procedural knowledge can bespecified by distinguished lexicalized communicationprimitives (viz.
a message passing protocol).
This ledus to the description of a concurrent parsing algorithmwhich is characterized by a depth-first, robust, yet in-complete analysis of textual input.
We also argued infavor of incompleteness in order to break the text pars-ing complexity barrier.
As a consequence, we do notonly supply an efficient parsing procedure but also onethat is effective in the sense that it guarantees the gen-eration of conceptual representations of the content ofthe text under feasible resource demands.Acknowledgments.
P. Neuhaus is supported by agrant from DFG within the Freiburg University Grad-uate Program on "lluman and Artificial Intelligence".ReferencesAdriaens, G. & U. Hahn (Eds.)
(1994).
Parallel NaturalLanguage Processing.
Norwood, N J: Ablex.Agha, G. & C. Hewitt (1987).
Actors: A conceptual founda-tion for concurrent object-oriented progranmaing.
InB.
Shriver & P. Wegner (Eds.
), Research Directionsin Object-Oriented Programming, pp.
49-74.
Cam-bridge, MA: M1T Press.Briot, J.-P. (1989).
Actalk: A testbed for classifying anddesigning actor languages inthe Smalltalk-80 environ-ment.
In Proc.
of ECOOP-89, pp.
109-129.Br6ker, N., U. Hahn & S. Schacht (1994).
Concurrent lexi-calized dependency parsing: The PARSETALK model.In Proc.
of COLING-94, pp.
379-385.Dowding, J., R. Moore, E Andry & D. Moran (1994).
Inter-leaving syntax and semantics in an efficient bottom-upparser.
In Proc.
of ACL-94, pp.
110-116.Habert, B.
(1991).
Using inheritance inobject-oriented pro-gramming to combine syntactic rules and lexical id-iosyncrasies.
In Proc.
oflWPT-91, pp.
79-88.Hahn, U.
& G. Adriaens (1994).
Parallel natural anguageprocessing: Background and overview.
In (Adriaens &Hahn, 1994), pp.
1-134.Hahn, U., M. Strube & K. Markert (1996).
Bridging textualellipses.
In this volume.Hobbs, J. R. (1983).
An improper t eatment ofquantificationin ordinary English.
In Proc.
of ACL-83, pp.
57-63.Janssen, W., M. Poel, K. Sikkel & J. Zwiers (1992).
Theprimordial soup algorithm.
In Proc.
of COLING-92,pp.
373-379.Lee, K. J. et al (1995).
A robust parser based on syntacticinformation.
In Proc.
of EACL-95, pp.
223-228.Lin, D. (1993).
Principle-based parsing without overgenera-tion.
In Proc.
of ACL-93, pp.
112-120.Magerman, D. M. & C. Weir (1992).
Efficiency, robusmessand accuracy in Picky chart parsing.
In Proc.
of ACL-92, pp.
40-47.Neuhaus, P. & U. Hahn (1996).
Trading off completenessfor efficiency: The PARSETALK performance grammarapproach to real-world text parsing.
In FLAIRS-96.Pollard, C. & I.
A.
Sag (1994).
Head-driven Phrase Struc-ture Grammar.
Chicago: University of Chicago Press.Reyle, U.
(1995).
On reasoning with ambiguities.
In Proc.of EACL-95, pp.
1-8.Schabes, Y., A. Abeille & A. K. Joshi (1988).
Parsingstrategies with 'lexicalized' grammars: Application toTAGs.
In Proc.
of COLING-88, pp.
578-583.Schacht, S. (1995).
Proving properties of actor programs us-ing temporal logic.
In G. Agha & F. De Cindio (Eds.),Proc.
of the Workshop on Object-Or&nted Program-ming and Models of Concurrency.
Torino, IT.Small, S. & C. Rieger (1982).
Parsing and comprehend-hag with word experts (a theory and its realization).
InW.
Lehnert & M. H. Ringle (Eds.
), Strategies for Nat-ural Language Processing, pp.
89-147.
Hillsdale, NJ:L. Erlbaum.Strube, M. & U. Hahn (1995).
PARSETALK about sentence-and text-level anaphora.
In EACL-95, pp.
237-244.Waltz, D. L. & J.
B. Pollack (1985).
Massively parallel pars-ing: A strongly interactive model of natural languageinterpretation.
Cognit&e Sc&nce, 9(1):51-74.Winograd, T. (1983).
Language as a Cognitive Process.
Vol.h Syntax.
Reading, MA: Addison-Wesley.Yonezawa, A.
& I. Ohsawa (1994).
Object-oriented paral-lel parsing for context-free grammars.
In (Adriaens &Hahn, 1994), pp.
188-210.507
