Lean Formalisms~ Linguistic Theory~ and Appl icat ions.Grammar  Deve lopment  in ALEP.Paul Schmidt & Axel Theofilidis& Sibylle RiederIAIMart in -Luther -S t r .
14D-66 111 Saarbr f i cken{pau l ,axe l , s iby l le}  @ia i .uni -sb.deAbstractThis paper describes results achieved in aproject which addresses the issue of how thegap between unification-based grammars as ascientific concept and real world applicationscan be narrowed own 1.
Application-orientedgrammar development has to take into ac-count the following parameters: Efficiency:The project chose a so called 'lean' formalism, a term-encodable language providing effi-cient term unification, ALEP.
Coverage: Theproject adopted a corpus-based approach.Completeness: All modules needed from texthandling to semantics must be there.
Thepaper reports on a text handling compo-nent, Two Level morphology, word structure,phrase structure, semantics and the interfacesbetween these components.
Mainstream ap-proach: The approach claims to be main-stream, very much indebted to HPSG, thusbased on the currently most prominent andrecent linguistic theory.
The relation (andtension) between these parameters are de-scribed in this paper.1 IntroductionApplications on the basis of unification-based gram-mars (UG) so far are rather rare to say the least.Though the advantages of UGs are obvious in thatproperties uch as monotonicity, declarativity, per-spicouity are important for maintaining and easilyextending grammars, their popularity (despite 15years of history) is still restricted to the academia.This paper reports of a project, LS-GRAM, whichtried to make a step further in bringing UGs closerto applications.Application-oriented grammar development has totake into account the following parameters:?
Efficiency: A major problem of UGs is (lack-ing) efficiency.
For the LS-GRAM project this1This project is LS-GRAM, sponsored by the Com-mission of the European Union under LRE 61029.Th ie r ry  Dec le rekIMS,  Un ivers i ty  of  S tut tgar tAzenbergst r .
12D-70174 Stut tgar tth ie r ry@ims.un i - s tu t tgar t .deled to the decision to use a so called 'lean' for-nrMism, ALEP, providing efficient term unifi-cation.
'Leanness' means that computation-ally expensive formal constructs are sacrificedto gain efficiency.
Though this is at the cost ofexpressiveness, it is claimed that by 'leanness''hnguistic felicity' does not suffer.?
Coverage: Most grammar developmentprojects are not based on an investigation ofreal texts, but start from 'the linguists" textbook'.
This is different here in that a corpus-based approach to granlmar development hasbeen adopted which is the implementation ofthe sinlple principle that if a grainnlar is sup-posed to cover reM texts, that the coverage ofthese texts has to be determined first.
Thewas a corpus investigation in the in the begin-ning, in the course of which tools have beenused and developed which allow for automaticand semi-automatic determination of linguisticphenomena.?
Conlpleteness: All modules needed from texthandling to semantics had to ve developed.This is why this paper does not focus on onesingle topic, but tries to represent he ulajorachievements of the whole of the system.
Thepaper reports on a text handling component,Two Level morphology, word structure, phrasestructure, semantics and and very importan{lythe interaction of these components.?
MMnstream approach: None-the-less, the ap-proach we adopted clainls to be mainstream,very much indebted to HPSG, thus based onthe currently most prominent and recent lin-guistic theory.The relation (and tension) between these parame-ters is the topic of this paper.First, we will show, how a corpus-investigationestabfished the basis for the coverage, second,how various phenomena deternlined by corpus-investigation are treated in text handhng (TH),third, how the linguistic modules, Two Level Mor-phology (TLM), word and phrase structure, the lex-icons look hke.
The last section is devoted to the286efficiency and performance of the system.
Figuresare given which prove that the system is not so farfrom real applications 22 Corpus - Invest igat ion  w i th  theMPRO-SystemThe project started with a corpus investigation.
Itconsisted of 150 newspaper articles from the Ger-man 'Die ZEIT'.
They are descriptive texts from thedomain of economy.
They were investigated auto-matically by the (non-statistical) 'MPRO' tagger.
'MPRO' provides the attachment of rich linguis-tic information to the words.
In addition, 'MPRO'provides a built-in facility for resolving categorialambiguities on the basis of homograph reductionsand a facility for handling unknown words whichare written on a file.
Encoding the missing stems(which were very few) ensured complete tagging ofthe corpus.
'MPRO' also provides a facility for searching syn-tactic structures in corpora.
A detailed analysison the internal structure of main clauses, subor-dinate clauses, verbal clusters, clausal topoi (e.g.structure of Vorfeld and Nachfeld), NPs, PPs, APs,CARDPs, coordinate structures, occurrence of ex-pletives, pronominals and negation occurring in thecorpus was made which then guided grammar de-velopment.Another major result of the corpus investigationwas that most sentences coutMn so called 'messydetails', brackets, figures, dates, proper names, ap-positions.
Most sentences contain compounds.In generM, most of the known linguistic phenom-ena occur in all known variations.
Description hasto be done in great &tail (all frames, all syntacticrealizations of frames).
(Long distant) discontinu-ities popular in theoretical linguistics did not playa role.
In order to give a 'general tlavour' of thecorpus-investigation e noteworthy result shouldbe reported: 25% of the number of words occur inNPs of the structure \[ DET (A) (A) N \].
But 'A'and 'N' are of a complex and unexpected nature:?
A: (name) - er: Dortmund-er, Schweiz-er?
(figure) - A: 5-j/?hrig, ffinfj~hrig, 68-prozentig?
N :  Ex-DDR-Monopolisten (Hyphenated com-pounding, including names and abbreviations).The corpus-investigation guided the grantmar de-velopnrent.
A.o.
it showed the necessity to devlopa TH component and separate out specific phenom-ena from the treatment in the grannnar.
(This wasalso necessary from an efficiency point of view).2It should be mentioned that we are referring to theGerman grammar built in the LS-GRAM project.
Forother languages imilar system exist.3 Text  Hand l ingThe ALEP platform provides a TH componentwhich allows "pre-processing" of inputs, it con-verts a number of formats among them 'Latex'.Then the ASCII text first goes through SGML-based tagging: Convertion to an EDIF (EurotraDocument Interchange Format) format, then para-graph recognition, sentence recognition and wordrecognition.
The output of these processes consistsin the tagging of the recognized elements: 'P'  forparagraphs, 'S' for sentences, 'W'  for words (in caseof morphological analysis, the tag 'M' is providedfor morphemes) and 'PT'  for punctuation signs asexelnplified in (1).
(1) <P><S><W>Jolm</W><W>sleeps</W><PT>.</PT></s></P>In the default case, this is the information which isinput to the TH-LS component (Text-Handling toLinguistic Structure) component.
ALEP provides afacility (tsls-rules) which allows the grammar writerto identify information which is to flow from the TtIto the linguistic processes.
We will show how thisfacility can be used for all efficient and consistenttreatnlent of all kinds of 'messy details'.The TH component of the ALEP platform alsoforesees the integration of user-defined tags.
Thetag (USR) is used if the text is tagged by a user-defined tagger.
An example of an integration of auser-defined tagger between the sentence recogni-tion level and the word recognition level of the THtool is given below.The tagger for 'messy details' has been integratedinto the German grammar and has been adaptedfor the following patterns:1 'Quantities' (a cardinal number followed by anamount and a currency name (e.g.
"16,7 Mil-lionen Dollar"))2 Percentages (12%, 12 Prozent, zwSlf Prozent)3 Dates (20.
Januar 1996)4 Acronyms and abbreviations ('Dasa', 'CDU','GmbH', etc.
).5 Prepositional contractions (zum, zur, am etc.)?
Appositions: Prof. Dr. Robin CooperWe will examplify the technique for 'quantities'.Recursive patterns are described in the program-ruing language 'awk'.
(2) defines cardinal numbers(in letters).287(2) two-to-ten = "((\[Zz\]wei) l(\[Dd\]rei)l(\[Vv\]ier) I(\[Ff\] Inf) I( \[Ss\] echs) \] ( \[Ss\] leben) \]( \[Aa\] cht) l ( \[Nn\] ean) I ( \[Zz\] ehn) )"eleven-to-nineteen = .
...t went y-t o-ninetyetc.card = "((\[Ee\]inl"two-to-ten")(und"twenty-to-ninety") ?I " .... )On the basis of these variables other variables canbe defined such as in (3).
(3) range = " ( "number" l "card" ) "amount =" ("Millionen" I"Milliaxden")currency=" ( Mark", "DM", "Dollar")"curmeasure=" ("amount"??
"currency" ?
)"quantity =" ("range .... curmeasure")"The following inputs are automatically recognizedas 'quantities':"Zweiundzwanzig Dollar""Sechsundzwanzig Milliarden""Dreiundvierzig Milliarden DM"This treatment of regular expressions also means asignificant improvement of efficiency because thereis only one string whereas the original input con-sisted of five items ("vierzig bis ffinfzig MilhardenDollar"): "vierzig_bis_fuenfzig_Milliarden_Dollar".
(4) gives an exalnple for information flow from THto linguistic structure:(4) id:{spec => spec:{lu => TYPE},sign => sign:{string => string: {first => \[ STRING I REST\],rest => REST},synsem => synsem:{syn => SYN => syn:{constype => morphol:{lemma => VAL,rain => yes } } } } },'USR',\['TYPE' => TYPE,'VAL' => VAL\], STRING ).The feature 'TYPE '  bears the variable TYPE (inour case: "quantities").
The feature 'VAL' repre-sents the original input (e.g.
: "ffinfzig MilliardenDollar") and the variable STRING represents theoutput string of the tagged input (in this case:"fuenfzig_Milharden_Dollar").
This value is co-shared with the value of the "string" feature of thelexicon entry.
The definition of such generic entriesin the lexicon allows to keep the lexicon smallerbut also to deal with a potentially infinite numberof words.These strategies were extended to the other phe-nomena.
The TH component represents a pre-processing component which covers a substantialpart of what occurs in real texts.4 The Linguistic Modules4.1 Two Level  Morpho logy  (TLM)The TLM component deals with most major mor-phographemic variations occurring in German, suchas umlautung, ss-fl alternation, schwa-instability.We will introduce this component by way of ex-emplification.
(5) represents the treatment o f 'e ' - ' i 'umlautung as occurring in German verbs like 'gebe','gibst', referring to (Trostg0).An ALEP TL rule comes as a four to five placePROLOG term, the first argument being the rulename, the second a TL description, the third (rep-resented by the anonymous variable ) a specifierfeature structure, the fourth a typed feature struc-ture constraining the application of the rule anda fifth allowing for linking variables to predeflnedcharacter sets.
(5) tlm_rule(umlautE_no,\[\] \[el \[\] <=> \[\] \['E'\] \[\],syn:{constype => stem:{phenol => pho:{umlaut => no } } } ).t im_rule(umlautE_i_yes,\[3 \[i\] \[C\] <=> \[\] \['E'\] \[\],syn:{constype => stem:{phenol => pho:{umlaut => (yes,i)} } },\[C in consonants\] ).In order to understand the treatment one has tobear in mind that there exists the lexical entry in(6) to which the TL rules above map to.,6,\[ ,\]\]syn\] cons phenol \[umlaut none&iThe morphologically relevant information is en-coded in 'cons'.
It contains two features, ' lemma'which encodes the abstract nlorpheme with a cap-ital 'E '  (this is the basis for a treatment accordingto ((Trost90)) and the feature 'phenol' which en-codes phonologically relevant information, in thiscase whether ulnlautung is available or not.The values for 'phenol' is a boolean conjunctionfrom two sets: sl ={none, no, yes} and s2 = {e,i\].The treatment consists of mapping a surface 'e' to alexical 'E '  in case the constraint which is expressed288as a feature structure in the fourth argument holds.It says that for the first rule 'e' is nrapped on 'E '  ifthe feature 'umlaut '  has a value which is 'no' .
Thisapplies to (6).
This handles cases such as 'geb-e'.The second rule maps 'i ' 'E '  if 'umlaut '  has thevalue 'yes & i'.
This also holds in cases like 'gib-st'.One would expect according to (Trost90) that onlytwo values 'no' and 'yes' are used.
The change hasbeen done for merely esthetic reasons.
The '2ndpers sing' morpheme 'st '  e.g.
requires an 'umlaut= yes' stenr, if the stem is capable of ulnlautung,at all which is the case for 'gibst' .
In case the stemcannot have umlautung (as for 'kommst ' )  'st '  alsoattaches.
This makes that  uon-unflautung stemshave to be left unspecified for umlautung, as other-wise 'st '  could not attach.
'st '  can now be encodedfox' 'umlaut  = no'.4.2 Lex iconf,exical information is distributed over three lexi-cons:?
A TL  lexicon which contains information rele-vant for seglnentation, cxdusively.?
A syntax lexicon.?
A semantic lexicon.The distribution of information over three lexiconshas a sinrple reason, namely avoiding lexical anrbi-guities at places where they cannot be resolved orwhere they have inrpact on eificiency.
So, e.g.
theverbal suffix 't '  has lots of interpretations: '3rd petssing', 2nd pers pl', preterite and more.
These ambi-guities are NOT introduced in the TLM lexicon asthe only effect would be that a great nunlber of scg-mentat ions would go into syntactic analysis.
Onlythen these ambiguities could be resolved on the ba-sis of morphotact ic  intorlnation.
A similar situa-tion holds on syntactic level.
There is no point innmltiplying syntactic entries by their semantic am-biguities and make all of these entries available foranalysis.
It would result in a desaster ibr efficiency.Semantic reading distinctions thus are put into the(semantic) refinement lexicon.
We would like to in-troduce lexical information for the preposition 'in'by way of i l lustration.TL -Ent ry  for  ' in ' :(7) 'string \[inl_ \],,,od,,,,,,,,ut ,,ojjjjThe nrorphological information is encoded in the'cons' feature.Ana lys l s -Ent r ies  for  ' in ' :Prepositions \]nay occur in 'strongly bound PPswhere they are functional elenrents (semanticallyempty, but syntactically relevant).
This is encodedin (8).
A PP headed by a functor cannot be an ad-junct (rood=none).
The head-dtr chosen by ' in' isan NPacc.
The mother of such a construction alsocomes out as NPacc which is encoded in 'projects' .The major  reason for such a treatment lies in thefact that it allows for a unified t reatment  of allfunctional elements like inflectional affixes, com-plenrentizers, auxiliaries, infinitival zu, functionalprepositions etc..).
(8)I c~t / .
.
\[selects NPacc\[.
\[rood oo etL suDca~ func \[projects NPacc(9) is the entry for ' in' as a head of a PP  subcate-gorizing for an NPacc.
(9)\[ ''y 'c't'Subc tL sub t\[c?'
ps<- cc>\]Semant ic  ent r ies  for  qrlhPrepositions need (semantically) different entriesdepending on whether the.p heads a PP which is aconlplentent or &it adjunct.qn '  as complement :l subj < >The content of a PP is a relational psoa.'
in '  as Ad junct :I-qu o s 11synlcat "" m?d l ' " l c?nt / .
.
\[pso., \[211// V ?-c?n~ Lrest4 z\] \]//L r- lm?a A /Lsubcat Icomp~ < ..
I sem \[cont \[4\] > /"" c?~'t rd-c?=t \[r~str rrex i~ \]'z"< \[,,~gi \[4\]\] t J >r_l)SOa289The preposition puts its content on a restriction list.It composes the restriction list with the restrictionlist of the modified item.
Quants and the psoa arecopied.4.3 Word  St ructure  and  Phrase  St ructure(PS)Both the word structure and the phrase structureconlponent are based on the same snlall set of bi-nary schenlata closely related to HPSG.
In the sys-tenl described here they exist as nlacros and theyare spelt out in category-specific word and phrasestructure rules.
(Efficiency is the major reason, asunderspecified syntax rules are very inefficient).Such a schema is e.g.
the following head-comp-schema.Mother:synsem\[I c t he'?L Jl\]\]syn ,subcat \[compls \[5\]Lsubj\[~\]Lsem \[3\]Head-dtr:ksem \[3\]Comp-dtr:\[synsem \[J\]\]subcat \[compls < \[41115\] >\[subj \[2\]Head information is propagated from head-dtr tomother, so is semantic information.
'subact' infor-marion is structured slightly differently as in HPSGto allow for one innovation wrt HPSG which is ourtreatment of functional elements.Mother:SYN \[\] I CONSTR funct_att \]L /SEM ~ \]Head-dtr:HEAD I BASE ?\[- - .
.
.
.?
oj\]Functor:l F "EAD  IIThe functor macro is highly general.
It shows thefunctor treatment applied in the German gram-mar, namely that the functor selects its head-dtr,combines itself with the head-dtr and projects themother.
More specifically: The functor-dtr, indi-cated by the value 'funct' of the attribute 'subcat'shares the value of the attribute 'selects' with the'synsem' value of the head-dtr and its 'projects'value with the 'syn' attribute of the mother.
The'head' value is shared between head-dtr and mother,the 'base' value in addition between head-dtr andfunctor.
The subcategorization is shared betweenhead-dtr and mother.The difference to the head-comp schema is thathead information comes from the functor, also thesemantics.
'subcat' is inherited from the head-dtr.The powerful mechanism comes in by the subcat-feature of the functor which allows for a very de-tailed specification of the information to be pro-jected.The PS component covers all categories, especiallyall clausal categories (main clauses, subordinateclauses, relatives), NPs, APs, ADVPs, PPs.5 'E f f i c iency '  and  Per fo rmanceIn this section we would like to address the topic ofefficiency.
A number of points contributing specifi-cally to efficiency should be summarized here.?
ALEP is designed to support efficiency as far asthe formalism ('lean' approach) is concerned.Formal constructs known to be computation-ally expensive are not available 3.?
Refinement (mentioned al-ready) is a monotonic appfication of phrasestructure rules and lexical entries to furtherfeaturize (flesh-out with features) a finguis6cstructure, established in analysis.If Q1 is the finguistic output structure of theanalysis, then Q~ is the output structure of 're-finenlent' if Q1 subsumes Q2, i.e.
every localtree in Q= and every lexical entry in Q~ is sub-sumed by a corresponding local tree and a cor-responding lexical entry in Q1.Any non-deterministic backtracking algorithm(depth-first) is badly effected by ambiguitiesas it has to redo repeatedly large amountsof work.
In terms of lingware developmentthis means that lexical ambiguities have to beavoided for analysis.
As on the other hand lexi-calist theories result in an abundance of lexicalambiguities, 'refinement' is a relief.
Optimaldistribution of inforlnation over analysis andrefinement results in a gain of efficiency by sev-eral factors of magnitude.,, Head selections: ALEP allows for user-definedparsing head declarations as "the most appro-3It should have been shown in the precious ectionsthat felicitous descriptions are possible anyway.290priate choice of head relations is grammar de-pendent" (Alshtl),  p.318.
On the basis of theuser-defined head relations the reflexive transi-tive closure over head relations is calculated.
Ithas to be made sure that the derived relationsare as compact as possible.
Optimal choice ofhead relations pays off in a gain in efficiencyby several factors of magnitude.?
Keys: Keys are values of attributes withinlinguistic descriptions defined by path decla-rations.
Keys allow for indexation and effi-cient retrieval of rules and lexical entries.
Thisbeconres extremely relevant for larger-scale re-sources.
A key declaration which the grammardeveloper may do identifies the atomic valuewhich is to serve as a key.
Optimal keys againresult in a substantial gain in efficiency.?
Last not least tuning the grammars with a viewoil efficiency has contributed to tile currentperformance of the system.In the following we would like to give some actualfigures which may illustrate performance.
Thesefigures are not meant to be an exact measurementas exact measurenrents are not available, in or-der to give an indication it may be said that ALLthe phenomena which increase indeterminism ina grammar of German are covered: All forms ofthe articles ('die', 'der') and homomorphous rela-tive pronouns, all readings of verbs ( all frames,all syntactic realizations of complements), seman-tic readings, prepositions and honu)lnorphous pre-fixes, PPs as nominal adjuncts, as preadjectivalcomplements, as adjuncts to adverbs, as VP ad-juncts, valent nouns (with optional complementa-tion), all readings of Gerlnan 'sein', coordination,N -~ N combinations, relatives, Nachfeld.One result of the corpus investigation was that 95%of the sentences in the corpus have between 5 and40 words.
The grammar is able to parse sentenceswith up to 40 words in 120 sees.
The following arecorpus examples containing time-consmning parseproblems.Input: In den Wochen vor Weihnaehten konnte derstolze Vorsitzende der zu Daimler-Benzgehoerenden Deutsche Aerospace AG einJahresergebnis, das alle Erwartungenuebertraf, verkuenden.
(Comment: In the weeks before X-mas the proudhead of the Deutsche Aerospace AG which belongsto Daimler-Benz could announce an annualstatement of accounts which exceeds allexpectations.
)total RWordSeg RLiftAna Refinesol : i 34.
450 0.380 34.070 0.000Input: Dieser Erfolg ueberrascht in zweiHinsichten.
(Comment: This success is surprising in tworespects,)total RWprdSeg RLiftAna Refineso l  : 1 1 .910  0 .130  1 .780  0 .000For industrial purposes this may still be too slow,but we think that the figures show that the systemis not so far away front reality.6 Conc lus ionsThis paper was about the following aspects of ling-ware development:e Linguistic felicity and leanness.?
Leanness and efficiency.?
Methods for large-scale grammar development.?
'Ilolistic' approach.We can summarize briefly:?
ALEP provides all modules and tools from texthandling to discourse processing (the latter notintroduced here).
The lingware created is es:pecially interesting ill that it provides an inte-grated design for all the modules.?
The formalism for lingware development islean, but it provides sufficient means to sup-port mainstream felicitous linguistic descrip-tions.?
Efficiency is goodcompared to other unification-based systems.It is not yet ready for immediate commercialapplications, but it is neither very far away.?
The corpus-based approach to grammar devel-opment is the only realistic way to get closerto a coverage that is interesting from all appli-cation point of view.ALEP is a promising platform for development oflarge-scale application-oriented grammars.ReferencesIliyan Alshawi, Arnold D J, Backofen R, Carter DM, Lindop J, Netter K, Pulman S G, Tsujii J andUszkoreit H, (1991), Eurotra ET6/I: Rule Formal-i,~m and Virtual Machine Design Study (Final Re-port), CEC 1991.H.
Trost: The application of two-level nrorphologyto non-concatenative G rman morphology.
Procecd-ing.s of COLING-90, Helsinki, 1990, vol.2, 371-376.291
