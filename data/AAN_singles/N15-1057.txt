Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 546?555,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsLCCT: A Semi-supervised Model for Sentiment ClassificationMin Yang1Wenting Tu1Ziyu Lu1Wenpeng Yin2Kam-Pui Chow11Department of Computer Science, The University of Hong Kong, Hong Kong{myang,wttu,zylu,chow}@cs.hku.hk2Center for Information and Language Processing, University of Munich, Germanywenpeng@cis.lmu.deAbstractAnalyzing public opinions towards products,services and social events is an important butchallenging task.
An accurate sentiment an-alyzer should take both lexicon-level infor-mation and corpus-level information into ac-count.
It also needs to exploit the domain-specific knowledge and utilize the commonknowledge shared across domains.
In addi-tion, we want the algorithm being able to dealwith missing labels and learning from incom-plete sentiment lexicons.
This paper presentsa LCCT (Lexicon-based and Corpus-based,Co-Training) model for semi-supervised sen-timent classification.
The proposed methodcombines the idea of lexicon-based learningand corpus-based learning in a unified co-training framework.
It is capable of incor-porating both domain-specific and domain-independent knowledge.
Extensive experi-ments show that it achieves very competitiveclassification accuracy, even with a small por-tion of labeled data.
Comparing to state-of-the-art sentiment classification methods, theLCCT approach exhibits significantly betterperformances on a variety of datasets in bothEnglish and Chinese.1 IntroductionDue to the popularity of opinion-rich resources(e.g., online review sites, forums, blogs and the mi-croblogging websites), people express their opinionsall over the Internet.
Motivated by the demand ofgleaning insights from such valuable data, a flurryof research devotes to the task of extracting people?sopinions from online reviews.
Such opinions couldbe expressed on products, services or policies, etc(Pang and Lee, 2008).
Existing sentiment analysisapproaches can be divided into two categories basedon the source of information they use: the lexicon-based approach (Turney, 2002; Dave et al, 2003)and the corpus-based approach (Pang et al, 2002;Blitzer et al, 2007; Wan, 2009).
The lexicon-basedapproach counts positive and negative terms in a re-view based on the sentiment dictionary and classi-fies the document as positive if it contains more pos-itive terms than negative ones.
On the contrary, thecorpus-based approach uses supervised learning al-gorithms to train a sentiment classifier.Further study (Kennedy and Inkpen, 2006;Andreevskaia and Bergler, 2008; Qiu et al,2009) shows that corpus-based and lexicon-basedapproaches have complementary performances.Specifically, the corpus-based approach has highprecision but low recall on positive instances, whilethe lexicon-based approach has high recall but lowprecision on positive instances.
In fact, corpus-based approaches are over conservative in classify-ing instances as positive, because positive reviewsusually contain many neutral statements.
In contrast,the lexicon-based approaches tend to classify nega-tive or neutral instances as positive when there are afew positive words appear in the document.
It mo-tivates us to develop a new approach that achievesgood performance on both precision and recall eval-uations.Besides reviews on products and services, anotherrich source of opinion data are social reviews in fo-rums, blogs and microblogging websites.
Differentfrom product reviews, the social reviews are not as-sociated with numerical ratings, making it difficultto perform supervised classification.
Since man-ual labeling is time consuming and expensive, it is546preferable to label a small portion of social reviewsto perform semi-supervised learning, leveraging in-formation from both labeled and unlabeled data.In this paper, we propose a novel approach tohandle the above two challenges.
We presents theLCCT Model (Lexicon-based and Corpus-based,Co-Training Model), which treats the lexicon-basedinformation and the corpus-based information astwo views, and combine them via co-training (Blumand Mitchell, 1998).
The algorithm naturally in-corporates the framework of semi-supervised learn-ing, as missing labels in each view can be esti-mated by the classifier trained from the other view.The proposed LCCT model exploits the complemen-tary performance associated with the lexicon-basedand the corpus-based approaches, taking the best ofeach side to improve the overall performance.
Wepresent a novel semi-supervised sentiment-awareLDA approach to build the lexicon-based classi-fier, which uses a minimal set of seed words (e.g.,?good?,?happy?
as positive seeds) as well as docu-ment sentiment labels to construct a domain-specificsentiment lexicon.
This model reflects the domain-specific knowledge.
We employ the stacked denois-ing auto-encoder (Vincent et al, 2008; Glorot et al,2011) to build the corpus-based classifier.
As Glorotet al (Glorot et al, 2011) point out, the intermediateabstractions extracted in this way tend to reflect thedomain-independent knowledge, unifying informa-tion across all domains.
Finally, we use a co-trainingalgorithm to combine the corpus-based and lexicon-based classifiers and to combine the domain-specificknowledge and the domain-independent knowledge.The main contributions of our approach are three-folded.
First, we propose a method that exploits bothgeneral domain-independent knowledge and specificdomain-dependent knowledge, behaving like a hu-man being when she analyzes the text.
Second,we complement the lexicon-based approach and thecorpus-based approach to overcome their respectiveclassification biases.
Third, our approach is capa-ble of levering labeled and unlabeled data, unifyingthem into a semi-supervised learning framework.We conduct extensive experiments to verify the ef-fectiveness of the proposed approach on real-worldsocial reviews.
The experiment results show that ourmodel substantially outperforms the state-of-the-artmethods in analyzing sentiments in online reviews.2 Related WorksSentiment analysis of natural language texts is anactive research field.
The papers by Pang and Lee(Pang and Lee, 2008) and Liu (Liu, 2012) describemost of the existing techniques for sentiment anal-ysis and opinion mining.
Sentiment analysis ap-proaches can be categorized into lexicon-based ap-proaches (Turney, 2002; Kennedy and Inkpen, 2006;Andreevskaia and Bergler, 2008) and corpus-basedapproaches (Pang et al, 2002; Blitzer et al, 2007;Wan, 2009).
The lexicon-based approach uses a dic-tionary of opinion words (e.g., ?good?
and ?bad?
)to identify the sentiment of a text.
In contrast, thecorpus-based approach can be seen as a statisticallearning approach (Pang et al, 2002; Whitelaw etal., 2005; Wiebe and Riloff, 2005; Ye et al, 2009).The performance of corpus-based methods often de-generates when the labeled training data is insuffi-cient.As we have discussed earlier, corpus-based algo-rithms are overly conservative on positive reviews,while lexicon-based approaches are overly aggres-sive on positive reviews.
There are several litera-ture integrating both methods (Kennedy and Inkpen,2006; Andreevskaia and Bergler, 2008; Qiu et al,2009; Zhang et al, 2011).
These methods requireeither a complete lexicon or a fully labeled corpusbeing available, which might not be true in practice.The method in this paper, in contrast, uses incom-plete lexicon and partially labeled corpus as trainingexamples.On the other hand, there are semi-supervisedmethods in sentiment analysis which handle incom-plete data (Wan, 2009; Dasgupta and Ng, 2009; Liet al, 2010; Zhou et al, 2010; Biyani et al, 2013).Nevertheless, none of them combines the lexicon-based and corpus-based approaches and thus theydo not solve the bias problem in sentiment classi-fication.3 LCCT ModelIn the LCCT model, we use a novel semi-supervisedsentiment-aware LDA model to build the lexicon-based model.
We use stacked denoising auto-encoder (Vincent et al, 2008; Glorot et al, 2011)to build the corpus-based model.
Finally, a co-training algorithm is employed for semi-supervised547sentiment classification, and the two classifiers fromcorpus-based method and lexicon-based method arecombined.
The overall structure of the model is il-lustrated by Figure 1.3.1 Lexicon-based ApproachFor building the lexicon-based model, the key chal-lenge is that a single word can carry multiple sen-timent meanings in different domains, so that ageneral-purpose sentiment lexicon is less accuratethan domain-specific lexicons.
To solve this prob-lem, we build a domain-specific sentiment lexiconby semi-supervised sentiment-aware LDA (ssLDA).The ssLDA method takes semi-supervised data asinput.3.1.1 Semi-supervised Sentiment-aware LDAIn this section, we describe how each word of thecorpus is generated by the ssLDA model, then il-lustrate its inference method.
Each document hasthree classes of topics: K(p)positive sentiment top-ics, K(n)negative sentiment topics, and K(u)neu-tral sentiment topics.
Each document is a mixtureof the three classes of topics.
Each topic is asso-ciated with a multinomial distribution over words.To prevent conceptual confusion, we use a super-script ?(p)?
and ?(n)?
to indicate variables relatingto positive and negative sentiment topics, and a su-perscript ?(u)?
to indicate variables relating to neu-tral sentiment topics.
In addition, we assume that thevocabulary consists of V distinct words indexed by{1, .
.
.
, V }.For each word w, there is a multinomial dis-tribution determining which class of topics thatw belongs to.
This prior distribution is sam-pled from a Dirichlet distribution Dir(?
), where?
= (?
(p), ?
(n), ?
(u)) is a vector of three scalars.For documents with different sentiment labels, wechoose different values of ?, so that words in thedocument with a positive label has a higher proba-bility belonging to positive topics, and vice versa.In the semi-supervised setting, a document usuallydoesn?t have a sentiment label.
In that case, thevalue of ?
is equal to (13,13,13).Given the class of topics, there is another multino-mial distribution indicating the particular topic thatthe word belongs to.
If it turns out that the wordbelongs to a positive sentiment class, then its topicdistribution is drawn from a biased Dirichlet prior?(p)w?
Dir(?(p)w).
The vector ?(p)w?
RVis con-structed by?
(p)w,k:= ?0(1?
?w) + ?1?wfor k ?
{1, .
.
.
,K}(1)We set ?w= 1 if the word w is a positive seedword, otherwise, we set ?w= 0.
The scalars ?0and ?1are hyperparameters.
Intuitively, the biasedprior enforces a positive seed word more probablydrawn from a positive sentiment topic.
The distri-butions ?(n)w?
Dir(?
(n)w) and ?(u)w?
Dir(?
(u)w) fornegative and neutral sentiment topics are similarlyconstructed.
Once the topic is determined, the wordis generated from a multinomial distribution that as-sociates with the topic.
We summarize the genera-tive process of the ssLDA model as below:1.
For each word w in the vocabulary, drawthe distributions of topics for three sentimentclasses: ?(p)w?
Dir(?
(p)w), ?(n)w?
Dir(?
(n)w)and ?(u)w?
Dir(?(u)w).2.
For each topic k, draw the distribution overwords: ?(p)k?
Dir(?
), ?(n)k?
Dir(?)
and?(u)k?
Dir(?).3.
For each document in the corpus(a) Draw sentiment class distribution p fromeither Dir(?
(p)), Dir(?
(n)) or Dir(?
(u))based on the document?s sentiment label.
(b) For each word in document, Draw sen-timent class indicator c ?
Mult(p),then generate the word?s topic z fromMult(?
(c)w), and generate the wordw fromMult(?
(c)z).Given hyper-parameters ?, ?, and {?
(s), ?
(n), ?
(u)},our goal is to estimate the latent variables in thessLDA model.
We present a collapsed Gibbs-sampling algorithm, which iteratively takes a wordw from the corpus and samples the topic that theword belongs to.
The reader may refer to (Yang etal., 2014) for a detailed derivation of the samplingprocedure.
Let the whole corpus excluding the cur-rent word be denoted by D. Let n(p)i,w(or n(n)j,w, orn(u)k,w) indicate the number of occurrences of posi-tive sentiment topic i(p)(or negative sentiment topicj(n), or neutral sentiment topic k(u)) with word w in548Lexicon-based MethodCorpus-based MethodSVM ClassifierCo-trainingGeneral FeatureExtractionCombined ClassifierLabeled andUnlabeled DataStacked DenoisingAuto-EncoderLexicon-BasedClassifierDomain-specificLexicon ConstructionSemi-supervisedSentiment-aware LDAFigure 1: Algorithm Overviewthe whole corpus.
Let m(p)i(or m(n)j, or m(u)k) indi-cate the number of occurrence of positive sentimenttopic i(p)(or negative sentiment topic j(n), or neu-tral sentiment topic k(u)) in the current document.Then, the posterior probability that the current wordw belongs to a specific topic is presented as followPr(z = i(p)|D)?
(?(p)+K(p)?i=1m(p)i)??+m(p)iK(p)?+?K(p)i?=1m(p)i???
(p)i,w+ n(p)i,w?Vw?=1(?
(p)i,w?+ n(p)i,w?
)(2)Pr(z = j(n)|D)?
(?(p)+K(p)?i=1m(p)i)??+m(n)jK(n)?+?K(n)j?=1m(n)j???
(n)j,w+ n(n)i,w?Vw?=1(?
(n)j,w?+ n(n)j,w?
)(3)Pr(z = k(u)|D)?
(?(p)+K(p)?i=1m(p)i)??+m(u)kK(u)?+?K(u)k?=1m(n)u???
(u)k,w+ n(u)k,w?Vw?=1(?
(u)k,w?+ n(u)k,w?
)(4)By equations (2), (3), and (4), we can sample thetopic z for each word.
In the Gibbs sampling pro-cedure, we only need to maintain the counters n(p),n(n), n(u), m(p), m(n)and m(u), which takes O(1)time to update for each iteration.3.1.2 Lexicon Construction and SentimentClassificationOnce we obtain the topic of each word, we ob-tain the value of hidden variables p(c), ?
(c), ?
(c),where c ?
{p, n, u}.
The goal is to use these val-ues to construct a sentiment lexicon, which assignssentiment scores to each word.
In particular, weneed the probability that each word w appears ina certain sentiment class, i.e.
we want to calculatePr (c ?
{p, n, u}|w) for the sentiment indicator c.We use ?
(p)w, ?
(n)w, ?
(u)wto represent these probabili-ties.
By the ssLDA?s model specification, we define?
(p)w:= Pr (c = p|w) ?
p(p)?K(p)?i=1?(p)i,w?(p)w,i(5)?
(n)w:= Pr (c = n|w) ?
p(n)?K(n)?j=1?(n)i,w?(n)w,j(6)?
(u)w:= Pr (c = u|w) ?
p(u)?K(u)?k=1?(u)i,w?
(u)w,k(7)We construct the sentiment lexicon for each wordw by comparing ?
(p)w, ?
(n)wand ?(u)w.
If ?
(p)wis thegreatest value, then the word w is considered to con-vey positive sentiment, and is added to the positivesentiment lexicon with weight ?(p)w.
If ?
(s)1,wis thegreatest, then the word w is added to the negativesentiment lexicon with weight ??(n)w.
Otherwise,the word w is considered neutral and not includedin the sentiment lexicon.It remains to classify the sentiment for each doc-ument.
We aggregate the weights for each word, sothat the document is classified as ?positive?
if theaccumulated weight is larger than zero; Otherwise,549it is classified as ?negative?.
The proposed modelis a semi-supervised method since it is capable ofprocessing documents without the sentiment label.This property makes the proposed method suitablefor co-training.3.2 Corpus-based MethodThe deep learning approach, especially StackedDenoising Auto-encoders (SDA), has been shownhighly beneficial for extracting domain-independentknowledge (Glorot et al, 2011).
Thus, we use SDAto construct the corpus-based sentiment classifier.The stacked autoencoder method was introduced byRumelhart, Hinton and Williams (Rumelhart et al,1985) and its denoising variant was proposed byVincent et al (Vincent et al, 2010).
Recently, it hasbecome an essential building block in deep learningarchitectures.
A basic denoising autoencoder con-sists of an input layer, a hidden layer and an out-put layer.
The procedure can be interpreted into twophases, i.e., encode and decode.
In the encodingphrase, an encoder function is employed to map in-put data into a feature vector h. For each sample xfrom input dataset {x(1), .
.
.
, x(N)}, we haveh = f(UT(x+ ) + b) (8)where f(x) is sigmoid activation function, U is theweight matrix between input layer and hidden layer,bhis the bias of each input layer neuron and  is arandom Gaussian noise.
In the decoding phrase, adecoder function is deployed to remap the featurevector in the feature space back to the input space,producing a reconstruction x?.
The decoder functiontakes the following formx?
= f(VTh+ b?)
(9)where f(x) is also a sigmoid function, V is theweight matrix between the hidden layer and the out-put layer, and b?
is the bias.
The parameters of theSDA models, namely ?
= {U, V, b, b?
}, are learnedby minimizing the reconstruction error L(x, x?)
overall training instances:J(?)
=?x(t)L(x(t), x?
(t)) (10)where L(?, ?)
is measure of discrepancy.
Popularchoices of L include squared error and Kullback-Liebler divergence.
By iteratively adding autoen-coders on top of a trained denoising autoencoder,we obtain the stacked denoising autoencoder (SDA).Once trained, their parameters can be used to initial-ize a supervised learning algorithm.
In this paper,SDA is learnt in a greedy layer-wise fashion usingstochastic gradient descent.
For the first layer, thedecoder is activated by a sigmoid function, and theKullback-Liebler divergence is used as the recon-struction error.
For the remaining layers, we use thesoftplus function for activation.
After the SDA pa-rameters are trained (on both labeled and unlabeleddata) and the high-level representation of each datainstance is obtained, a SVM classifier is employedusing the resulting representation (of labeled data)to train a sentiment classifier.3.3 Combining two Methods with Co-trainingAlgorithm 1 Co-training with corpus-based and lexicon-based methods?
Inputs: labeled training dataL, unlabeled training dataU?
Create a pool U ?
of examples by choosing u unlabeledexamples at random, then loop for k iterations?
use L and U to train a corpus-based classifier f1,then use f1to label samples from U ?.
Let A1bethe set of p positive and n negative most confidentlylabeled examples.?
use L and U to train a lexicon-based classifier f2,then use f2to label samples from U ?.
Let A2bethe set of p positive and n negative most confidentlylabeled examples.?
Add f1and f2to the set C of classifiers and addthe self-labeled examples A1?
A2to the labeleddataset L. Randomly choose 2p + 2n examplesfrom U to replenish U ??
For testing, run all classifiers inC and output the majorityvote.We employ a variant of co-training algorithm totrain the classifier with a small number of labeleddata and a large number of unlabeled data.
The co-training approach is well known for semi-supervisedapproach (Blum and Mitchell, 1998).
For our prob-lem, the two views of co-training are lexicon-basedmethod (domain-specific knowledge) and corpus-based method (domain-independent knowledge).Initially, both classifiers are trained with the partiallyavailable labels, as described by the above two sub-sections.
Then, we use one of the two classifiers tolabel the unlabeled documents, adding its labels to550the pool of labeled data, re-training the other clas-sifier using the new labeled data.
The procedure isperformed iteratively.
After a sufficient number ofiterations, we obtain a set of classifiers and we com-bine them using a majority-voting scheme to predictthe sentiment label for test data.
The details of thealgorithm are summarized in Algorithm 1.4 ExperimentsIn this section, we compare the proposed LCCTmodel with state-of-the-art methods in sentimentclassification.
The experiment demonstrates the su-perior performance of our approach.4.1 DatasetsWe conduct experiments on English and Chinese re-views from three datasets.
In this subsection, we de-scribe the datasets.Movie Review (MR) dataset in English Themovie reviews are selected if the rating was stars or anumerical score.
In this paper, we use the Movie Re-view dataset containing 1000 positive examples and1000 negative examples (Pang and Lee, 2004).
Posi-tive labels were assigned to reviews that had a ratingabove 3.5 stars and negative labels were assigned tothe rest (Pang and Lee, 2004).SemEval-2013 (SemEval) dataset in EnglishThis dataset is constructed for the Twitter sentimentanalysis task (Task 2) in the Semantic Evaluation ofSystems challenge (SemEval-2013).
All the tweetswere manually annotated by 5 Amazon MechanicalTurk workers with negative, positive and neutral la-bels.
SemEval contains 13,975 tweets with 2,186negative, 6,440 neutrals and 5,349 positives tweets.We collect the 2,186 negative tweets and 5,349 pos-itive tweets as the training data.COAE-2009 (COAE) dataset in Chinese Thisdataset is provided by COAE 20091(Task 4).
Thecorpus consists of 39,976 documents and 50 topics.The topics cover education, entertainment, finance,computer, etc.
In this paper, we select the 2202 neg-ative and 1248 positive documents as our dataset.In all experiments, data preprocessing is per-formed.
For English dataset, the texts are first to-kenized using the natural language toolkit NLTK2.1http://ir-china.org.cn/coae2009.html2http://www.nltk.org5 10 20 30 40 50 60 70 80 90 100Percentage of Labeled Data (%)0.600.650.700.750.800.850.900.95AccuracyMovie Review datasetLCCTNguyen'sDasgupta'sLi'sSelf-learningTSVMSVMLC5 10 20 30 40 50 60 70 80 90 100Percentage of Labeled Data (%)0.550.600.650.700.750.80AccuracySemEval datasetLCCTNguyen'sDasgupta'sLi'sSelf-learningTSVMSVMLC5 10 20 30 40 50 60 70 80 90 100Percentage of Labeled Data (%)0.600.650.700.750.800.85AccuracyCOAE datasetLCCTNguyen'sDasgupta'sLi'sSelf-learningTSVMSVMLCFigure 2: Comparing classification accuracy by varyingthe percentage of labeled data from 5% to 100%.
TheLCCT model is robust to incomplete data.551Then, we remove non-alphabet characters, num-bers, pronoun, punctuation and stop words fromthe text.
Finally, the WordNet stemmer3is appliedto reduce the vocabulary size and settle the issueof data sparseness.
For Chinese dataset, we firstperform Chinese word segmentation with a popu-lar Chinese auto-segmentation system ICTCLAS4.Then, the words about time, numeral words, pro-noun and punctuation are removed as they are un-related to the sentiment analysis task.4.2 Implementation DetailsWe specify the hyper-parameters we use for the ex-periments.
For all datasets, we choose ?
= 0.5,?
(p)= (0.95, 0.25, 0.4), ?
(n)= (0.25, 0.95, 0.4),?
(u)= (0.6, 0.6, 0.4) and (?0, ?1) = (0.25, 0.75).We use cross-validation to set the number of topicson datasets MR, SemEval and COAE as 20, 10 and20, respectively.
The seed words used to constructEnglish and Chinese lexicons are the same as in pre-vious literatures (Xie and Li, 2012) and (Yang et al,2014).
For the corpus-based method, each documentis transformed into binary vectors which encodes thepresence/absence of the terms.
The autoencoder isconstructed with 500 input neurons and 200 hiddenneurons.
Each autoencoder is trained by back prop-agation with 400 iterations.For all datasets, we set the iteration number ofco-training to be k = 50.
Other parameters of co-training are chosen by cross-validation: u is set tobe 10% of all unlabeled data, the sum of p and nare 0.8% of all unlabeled data, while their ratio aredetermined by the ratio of positive and negative sam-ples in labeled training data.4.3 Baseline MethodsIn this paper, we evaluate and compare our approachwith an unsupervised method, two supervised meth-ods and a variety of semi-supervised methods:SVM: 5000 words with greatest information gainare chosen as features.
In our experiment, we usethe LibLinear5implementation of SVM.Lexical Classifier (LC): This method calculatesthe number of positive words and negative wordscontained in the Opinion Lexicon (Hu and Liu,3http://wordnet.princeton.edu/4http://www.ictclas.org5http://www.csie.ntu.edu.tw/~cjlin/liblinear/2004) for English texts or the HowNet6lexicon forChinese texts.
If the positive sentiment words aremore than negative words, then the document is clas-sified as positive, and vice versa.Self-learning: Following the idea of (Zhu, 2006),this method uses the unlabeled data in a bootstrap-ping way.
The SVM classifier is used to select mostconfident unlabeled samples in each iteration.Transductive SVM (TSVM) : Following the ideaof (Joachims, 1999), this method seeks the largestseparation between labeled and unlabeled datathrough regularization.
We implement it with theSVM-light toolkit7.Dasgupta?s method: This is a popular semi-supervised approach to automatic sentiment classi-fication proposed by Dasgupta and Ng (Dasguptaand Ng, 2009).
The unambiguous reviews are firstmined using spectral techniques, then classified bya combination of active learning, transductive learn-ing, and ensemble learning.Li?s method: This method is proposed in (Li etal., 2010).
An unsupervised bootstrapping methodis adopted to automatically split documents into per-sonal and impersonal views.
Then, two views arecombined by an ensemble of individual classifiergenerated by each view.
The co-training algorithmis utilized to incorporate unlabeled data.Nguyen?s method: This method is proposed in(Nguyen et al, 2014), which achieves the state-of-the-art results in supervised sentiment classifica-tion.
We follow all the settings in (Nguyen et al,2014).
For the document with no associated score,we predict a score for the document as the values ofthe rating-based features using a regression modellearned from SRA148dataset.4.4 Experiment ResultsFor each dataset, we use 80% instances as the train-ing data and the remaining are used for testing.
Totest the performance of semi-supervised learning,we randomly select 10% of the training instances aslabeled data and treat the remaining as unlabeled.For fair comparison, the fully supervised SVM andNguyen?s method use the 10% labeled data for train-ing.6http://www.keenage.com/download/sentiment.rar7http://svmlight.joachims.org/8https://sites.google.com/site/nquocdai/resources552Dataset SVM LC Self-learning TSVM Dasgupta?s Li?s Nguyen?s LCCTMR 0.669 0.721 0.677 0.684 0.762 0.731 0.769 0.815SemEval 0.632 0.604 0.675 0.609 0.735 0.702 0.652 0.775COAE 0.625 0.706 0.679 0.649 0.709 0.692 0.642 0.713Table 1: Comparing classification accuracy with 10% labeled data.
The LCCT model performs significantly betterWe summarize the experiment results in Table1.
According to Table 1, the proposed LCCTmethod substantially and consistently outperformsother methods on all the three datasets.
This ver-ifies the effectiveness of the proposed approachand demonstrates its advantage in semi-supervisedsentiment analysis where reviews are from differ-ent domains and different language.
For exam-ple, the overall accuracy of our algorithm is 5.3%higher than Dasgupta?s method and 13.1% higherthan TSVM on Movie Reviews dataset.
On otherdatasets, we observe the similar results.
To verifythat unlabeled data improves the performance, wecompare the SVM and Nguyen?s classifier trained on10% of the labeled data with other semi-supervisedclassifiers.
Table 1 shows that the semi-supervisedlearning methods greatly benefit from using unla-beled data, especially on the Movie Reviews and onthe SemEval dataset.
Surprisingly, on the COAEdataset, lexicon-based method turns out to outper-form SVM, self-learning and TSVM.
The reasonmight be that the topics in the COAE dataset arepretty diverse.
Without sufficient labeled data orprior knowledge such as sentiment lexicon, thecorpus-based classifiers tend to separate the docu-ments into topical sub-clusters as opposed to senti-ment classes.To understand the performance of our algorithmwith respect to different portions of labeled data,we compare our algorithm with baseline methods byvarying the percentage of labeled data from 5% to100%.
Figure 2 shows that our approach is robustand achieves excellent performance on different la-beling percentages.
As expected, having more la-beled data improves the performance.
The LCCTmethod achieves a relative high accuracy with 10%of the reviews labeled, better than SVM, TSVM andSelf-learning with 100% of the reviews labeled.
Onthe other hand, when all the training data are labeled,LCCT is still significantly more accurate than allthe competitors except Nguyen?s method.
Although,the accuracy of Nguyen?s method is slightly betterthan ours on Movie Reviews dataset, it dosen?t per-form well on SemEval and COAE datasets since therating-based features learned from score-associatedproduct reviews cannot significantly benefit the so-cial reviews in forums and blogs, etc.
The mainadvantage of our model comes from its capabil-ity of exploiting the complementary informationfrom the lexicon-based approach and the corpus-based approach.
Another reason for the effective-ness of our approach is the way that we combinethe domain-independent knowledge and the domain-specific knowledge.It is known that both the corpus-based approachand the lexicon-based approach have classificationbiases (Kennedy and Inkpen, 2006; Andreevskaiaand Bergler, 2008; Qiu et al, 2009).
To evalu-ate the effectiveness of our algorithm in reducingthe bias, we compare it with the classifier that onlyuses one view of the LCCT model: either using thecorpus-based view or using the lexicon-based view.The comparison is conducted on the Movie Reviewdataset.
As Table 2 shows, our algorithm achievesgood performance on both precision and recall.
Incontrast, the baseline methods either have high pre-cision but low recall, or have high recall but lowprecision.
The experiment result suggests that com-bining the two views is essential in eliminating theclassification bias.DataCorpus-based Lexicon-based LCCTPrec.
Rec.
Prec.
Rec.
Prec.
Rec.MR pos.
0.92 0.79 0.67 0.86 0.90 0.86MR neg.
0.78 0.90 0.80 0.58 0.88 0.89Table 2: Precision and recall on Movie reviews5535 ConclusionsWe have proposed the LCCT model for semi-supervised sentiment classification, combining theidea of lexicon-based learning and corpus-basedlearning in a unified co-training framework.
Itis capable of incorporating both domain-specificand domain-independent knowledge.
Comparing tostate-of-the-art sentiment classification methods, theLCCT approach exhibits significantly better perfor-mances on a variety of datasets in both English andChinese, even with a small portion of labeled data.ReferencesAlina Andreevskaia and Sabine Bergler.
2008.
Whenspecialists and generalists work together: Overcom-ing domain dependence in sentiment tagging.
In ACL,pages 290?298.Prakhar Biyani, Cornelia Caragea, Prasenjit Mitra,Chong Zhou, John Yen, Greta E Greer, and KennethPortier.
2013.
Co-training over domain-independentand domain-dependent features for sentiment analysisof an online cancer support community.
In the 2013IEEE/ACM International Conference on Advances inSocial Networks Analysis and Mining, pages 413?417.ACM.John Blitzer, Mark Dredze, and Fernando Pereira.
2007.Biographies, bollywood, boom-boxes and blenders:Domain adaptation for sentiment classification.
InACL, volume 7, pages 440?447.Avrim Blum and Tom Mitchell.
1998.
Combining la-beled and unlabeled data with co-training.
In COLT,pages 92?100.
ACM.Sajib Dasgupta and Vincent Ng.
2009.
Mine theeasy, classify the hard: a semi-supervised approachto automatic sentiment classification.
In ACL-IJCNLP:Volume 2, pages 701?709.
Association forComputational Linguistics.Kushal Dave, Steve Lawrence, and David M Pennock.2003.
Mining the peanut gallery: Opinion extrac-tion and semantic classification of product reviews.
InWWW, pages 519?528.
ACM.Xavier Glorot, Antoine Bordes, and Yoshua Bengio.2011.
Domain adaptation for large-scale sentimentclassification: A deep learning approach.
In ICML,pages 513?520.Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In SIGKDD, pages 168?177.ACM.Thorsten Joachims.
1999.
Transductive inference fortext classification using support vector machines.
InICML, volume 99, pages 200?209.Alistair Kennedy and Diana Inkpen.
2006.
Sentimentclassification of movie reviews using contextual va-lence shifters.
Computational Intelligence, 22(2):110?125.Shoushan Li, Chu-Ren Huang, Guodong Zhou, andSophia Yat Mei Lee.
2010.
Employing per-sonal/impersonal views in supervised and semi-supervised sentiment classification.
In ACL, pages414?423.
Association for Computational Linguistics.Bing Liu.
2012.
Sentiment analysis and opinion mining.Synthesis Lectures on Human Language Technologies,5(1):1?167.Dai Quoc Nguyen, Dat Quoc Nguyen, Thanh Vu, andSon Bao Pham.
2014.
Sentiment classification on po-larity reviews: an empirical study using rating-basedfeatures.Bo Pang and Lillian Lee.
2004.
A sentimental education:Sentiment analysis using subjectivity summarizationbased on minimum cuts.
In ACL, page 271.
Associ-ation for Computational Linguistics.Bo Pang and Lillian Lee.
2008.
Opinion mining andsentiment analysis.
Foundations and trends in infor-mation retrieval, 2(1-2):1?135.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
: sentiment classification using ma-chine learning techniques.
In EMNLP: Volume 10,pages 79?86.
Association for Computational Linguis-tics.Likun Qiu, Weishi Zhang, Changjian Hu, and Kai Zhao.2009.
Selc: a self-supervised model for sentimentclassification.
In CIKM, pages 929?936.
ACM.David E Rumelhart, Geoffrey E Hinton, and Ronald JWilliams.
1985.
Learning internal representations byerror propagation.
Technical report, DTIC Document.Peter D Turney.
2002.
Thumbs up or thumbs down?
: se-mantic orientation applied to unsupervised classifica-tion of reviews.
In ACL, pages 417?424.
Associationfor Computational Linguistics.Pascal Vincent, Hugo Larochelle, Yoshua Bengio, andPierre-Antoine Manzagol.
2008.
Extracting and com-posing robust features with denoising autoencoders.
InICML, pages 1096?1103.
ACM.Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, YoshuaBengio, and Pierre-Antoine Manzagol.
2010.
Stackeddenoising autoencoders: Learning useful representa-tions in a deep network with a local denoising cri-terion.
The Journal of Machine Learning Research,9999:3371?3408.Xiaojun Wan.
2009.
Co-training for cross-lingual sen-timent classification.
In ACL-IJCNLP: Volume 1-Volume 1, pages 235?243.
Association for Computa-tional Linguistics.554Casey Whitelaw, Navendu Garg, and Shlomo Argamon.2005.
Using appraisal groups for sentiment analysis.In CIKM, pages 625?631.
ACM.Janyce Wiebe and Ellen Riloff.
2005.
Creating sub-jective and objective sentence classifiers from unan-notated texts.
In Computational Linguistics and Intel-ligent Text Processing, pages 486?497.
Springer.Rui Xie and Chunping Li.
2012.
Lexicon construction:A topic model approach.
In International Confer-ence on Systems and Informatics (ICSAI), pages 2299?2303.
IEEE.Min Yang, Dingju Zhu, Rashed Mustafa, and Kam-PuiChow.
2014.
Learning domain-specific sentiment lex-icon with supervised sentiment-aware lda.
ECAI 2014,pages 927?932.Qiang Ye, Ziqiong Zhang, and Rob Law.
2009.
Senti-ment classification of online reviews to travel destina-tions by supervised machine learning approaches.
Ex-pert Systems with Applications, 36(3):6527?6535.Ley Zhang, Riddhiman Ghosh, Mohamed Dekhil, Me-ichun Hsu, and Bing Liu.
2011.
Combining lexi-conbased and learning-based methods for twitter sen-timent analysis.
HP Laboratories, Technical ReportHPL-2011, 89.Shusen Zhou, Qingcai Chen, and Xiaolong Wang.
2010.Active deep networks for semi-supervised sentimentclassification.
In Coling: Posters, pages 1515?1523.Association for Computational Linguistics.Xiaojin Zhu.
2006.
Semi-supervised learning literaturesurvey.
Computer Science, University of Wisconsin-Madison, 2:3.555
