/ILearn ing  a Lexical ized Grammar  for GermanSandra KfiblerComputational LinguisticsGerhard-Mercator Universi~t Duisburg, Germanys.
kuebl er@uni  - duisburg,  deAbstractIn syntax, the trend nowadays is towards lexiealizedgrammar formalisms.
It is now widely accepted thatdividing words into wordclasses may serve as alabor-saving mechanism - but at the same time, itdiscards all detailed information on the idiosyncraticbehavior of words.
And that is exactly the type ofinformation that may be necessary in order to parsea sentence.
For learning approaches, however,lexicalized grammars represent a challenge for thevery reason that they include so much detailed andspecific information, which is difficult to learn.This paper will present an algorithm for learning a, link grammar of German.
The problem of data spar-seness is tackled by using all the available infor-mation from partial parses as well as from an ex-isting grammar fragment and a tagger.
This is a re-port about work in progress o there are no repre-sentative results available yet.1.
IntroductionWhen looking at the most recent advances in syntaxtheory, one will notice a definite tendency towardslexicalized approaches.
Simple context-free grammarformalisms may be easy to handle but they lack thedescriptive power to model idiosyncrasies in the syn-tactic behavior of  single words.In the natural anguage learning community, prob-abilistic approaches play a dominant role.
Yet prob-abilistie learning has its strength in finding majortrends in the training data.
An idiosyncratic behavioro f  a single word is very likely to go unnoticed forlack o f  data.
This divergence in interest might be thereason why hardly any attempt was made to have alexicalized grammar learned.In this paper, I will describe an approach to learninga link grammar.
Link grammar (Sleator & Temperley199 I) is highly lexicalized, and therefore the problemof  data sparseness will be immense.
As a conse-quence, I have chosen a fuzzy representation.
Thefuzziness in this case models uncertainty rather thanvagueness inherent in the language.
The learningalgorithm tries to extract as much information as pos-sible from a grammar fragment, partial parses pro-vided by this grammar, and wordclass information (forunknown words or to corroborate decision made bythe system).2.
Link GrammarLink grammar (Grinberg, Lafferty & Sleator, 1995;Sleator & Temperley 1991) is a highly lexieal, con-text-free formalism that does not rely on constituentstructure.
Instead, it models connections between wordpairs without building a hierarchical strueture.The link grammar formalism is best explained withan example of a linkage (i.e.
a link grammar parse):Figure 1 shows a linkage for an English sentence.
Alinkage is a graph in which the vertices, representingthe words, are connected by labeled arcs.
These arcsare called links.
For a grammatically correct sentence,the linkage must fulfill the following requirements:the links do not cross (= planarity), the graph is con-nected, and at most one arc connects a pair of  words.I f  there is no linkage for a sequence of words, the sen-tence is not in the language modeled by the grammar.eyog A glr S tMV? "
hFigure 1: A link grammar parseKibler 11 Learning Lexicalised Graramar for GermanSandra Kiibler (1998) Learning a Lexicalised Grammar for German.
In D.M.W.
Powers (ed.)
NeMLaP3/CoNLL98: NewMethods in Language Processing and Computational N tural Language Learning, ACL, pp 11-18.The labels on the arcs denote the syntactic relationsor constituent relationships of the connected words?
Infigure 1, the link labeled S connects the subject nounto the finite verb, D connects determiners to theirnouns, MV connects the verb to the following prepo-sitional phrase, etc.The grammar itself consists of a wordlist in whicheach word is paired up with all potential linking re-quirements.
Each linking requirement models oneusage of the word?
A linking requirement, also calleda disjunct, is a formal specification of the differentconnectors, which link with a matching connector ofanother word, including their direction and order?
It isusually represented as a pair of ordered lists: the leftlist, containing connectors that link to the left of theword, and the right list, containing connectors thatlink to the fight.
For example, the linking require-ment of the word "girl" in figure 1 is characterized bythe formula ((D, A), (S)), for "finished" the formula is((S) (O, MV)), and for "young" (0, (A)).
In a moresophisticated version of the grammar, the labels areannotated by features, e.g.
to ensure agreement be-tween subject and verb.The link grammar formalism is similar toency grammar (Mercuk 1988, Tesrtiere 1959) in thatboth of them model connections between singlewords.
But link grammar connections are purely lexi-cal: they do not intend to model valency or semanticaspects of words.
An additional advantage of linkgrammar is that there exists an efficient parsing algo-rithm (Sleator & Temperley 1991, 1996) whereasthere does not seem to exist one for dependencygrammar.2.1.
Adaptations of the Formalism toCover the German LanguageLink grammar, like many other formalisms, seems tobe especially suited for the English language.
Whentrying to use this formalism for other languages, itseems wise to adapt the formalism to the needs ofthese languages, most of which are caused by a freerword order.
In working with the German language, Ihave found the following changes immensely helpful:~.D Mann ~,~MV_the man laughs oftenMV Doften laughs the manSleator and Temperley (1991) strongly prefer locallinks (i.e.
links connecting words to their immediateneighbors), even if this is not supported by lin-guistics.
As German uses agreement much more ex-tensively than English, it is necessary to link wordsaccording to the agreement requirements rather thanbecause of immediate neighborhood.
This approachresults in considerably more long distance links.In English, the word order is rigidly determined formost parts of the sentence.
Sleator and Temperley(1991) use different labels for links that can occur inmore than one position (e.g.
adverbs) depending onwhether they are left or right links.
In German, how-ever, due to its freer word order, these phenomena arerelatively common.
In order to avoid using too manydifferent labels describing the same kind of link but indifferent order, I have introduced the idea Of control, orrather directionality of links.
Each link is marked aseither controller (8) or controlled (=).
I can thus usethe S-link for subjects preceding or following thefinite verb, as shown in figure 2.The principle of planarity states that links in alinkage must not cross?
Sleator and Temperley (1991,I) comment that most sentences of most languagesadhere to that principle.
Unfortunately, German is oneof the languages in which this principle is violated ina number of cases.
Some of them are caused by thefree word order, some by phenomena like the splittingof the verb:llmen wird vorgeworfen, sie h~ittento them is reproached, they hadsieh in Berlin getroffen .each other in Berlin metThey were reproached for having met in Berlin.Ich babe den Mann gesehen, derI have the man seen, whodas Buch besitztthe book ownsI have seen the man who owns the book?Granlmar:der (0, (=I)))Mann ((?D), (=S)), ((=S, ?D), 0)lacht ((?S), (?MV)), ((?MV), (?S))oft ((=MY), 0), (0, (=MY))Figure 2: Controlled linksKtabler 12 Learning Lexicalised Grammar for German ?mIII!1IIII/II|/In the first example, the dative object "ihnen" linksto "vorgeworfen" and the f'mite verb "wird" to theperiod.
In the second example, "Mann" links to "der",the relative pronoun and the finite verb to the pastparticiple "gesehen".As crossing links are inevitable in German, there isa special marker for such links that may cross.2.2.
What Advantages Does Link Gram-mar Offer for Learning?Link grammar offers at least two characteristics thatwill be of advantage in syntax learning:Instead of relying on a hierarchical constituentstructure, the link grammar formalisms is based onlinks on a single level.
Therefore, they can be learnedindependently; there is no need for a top-down or bot-tom-up structuring.
Thus errors in earlier steps ofbuilding the structure cannot have as disastrous effectsas with constituent s ructures.Another problem of constituent grammars, whichmay cause problems in learning, are long-distancedependencies.
The information about a gap somewherein the structure is usually passed on through severallevels of the constituent tree.
In link grammar, how-ever, these distances are covered by a direct link,which means that these phenomena do not need anyspecial attention during the learning process.2.3.
Former Approaches to LearningLink GrammarThere already exist wo approaches to learning with alink grammar formalism (Delia Pietra et al, 1994;Fong & Wu, 1995).
In both cases, the probabilisticversion of the grammar (Lafferty, Sleator & Tem-perley, 1992) are used and the word pairs plus theirprobabilities are inferred from a corpus by an EM-al-gorithrn.
The probabilistie model of link grammarrestricts disjuncts in that only one left connector andat most two right connectors are allowed.
At least forGerman, this formalism leads to a very unnatural andcounterintuitive d scription.Additionally, to reduce the amount of data to beprocessed, both approaches did not use the link typeinformation but assumed only one type of link.
Thisrestriction may be very helpful concerning computingtime yet thus valuable information is not taken intoconsideration.3.
A Fuzzy Relation for Representingthe Link GrammarEver since Zadeh (1965) has introduced fuzzy sets, theinterest in fuzzy modeling has increased steadily.
Incomputational linguistics, fuzzy methods are mainlyused in semantics to model vague meaning like themeaning of the concept "fast".
A fuzzy set repre-senting this concept would give gradually increasinggrades of membership tothe speed between 0 and 120mph.However, fuzzy methods cannot only be used formodeling vagueness, they are also useful in caseswhere the given information is either inexact or in-complete.
Concerning rammar, and especially learn-ing grammar, the latter case must be assumed.A (complete) link grammar can be represented asa(crisp) relation G among the set W of all words andthe set D of all potential disjunctsG: W ?
L --> {0,1}with its characteristic functiongc(w 'd)={;  /felse <w,d>is  grammaticalwhere an ordered pair <w, d> is assigned the member-ship value 1 if d is a valid linkage for the word w.Now if only a fragment of the grammar is known,the fuzzy relation G* is defined asG* :W x L --~ \[0,1\]where the membership value does not indicate whetherthe ordered pair is in the grammar but whether the pairis known to be in the grammar or to what degree it isassumed to be in the grammar (for the characteristicfunction see section 4.1).
Here the value 1 indicatesthat it is certain that the linkage is valid for the wordin question, 0 indicates that there has never been anyreason to assume that w takes d as a valid linkage.4.
Learning the Link GrammarThe system starts with a grammar f agment extractJ~dfrom a small corpus of 50 annotated sentences.
Thesesentences, as well as the test sentence used below, aretaken from the TAZ, a German newspaper.
At thisstage, the grammar is crisp, i.e.
the only membershipvalues used are 1 for pairs of words and disjunctsfound in the corpus and 0 otherwise.
Then optionalelements are marked, i.e.
if a word is connected totwodisjuncts d and d' of which d is equal to d' except hatd has one ore more connector that are not in d', thenthese connectors are marked as optional.The learning process itself is incremental: once anew sentence is presented to the system, the parsingcomponent takes over.
It attempts to parse the sen-tence with the crisp version of the grammar, i.e.
withall pairs of words and disjuncts for which the relationG* gives the value I.
(At the moment, he parser stillhas to be implemented.
The algorithm is described bySleator and Temperley (1991,1996) yet it must bemodified to account for the changes in the link gram-mar formalism necessary to describe German.)
If thefirst attempt with the crisp grammar does not succeed,the threshold for G* is lowered from 1 to 0.3 and theattempt is repeated.
In this case, less reliable infor-mation is used but if the parse succeeds, the validityof the disjuncts used in the parse is corroborated.Therefore their membership value is increased.If the parser, however, does not succeed in parsingthe sentence, the learning component is called:Kfibler 13 Learning Lexicalised Grammar for German?
As a first step, every word in the sentence istagged.
(The formalism used for tagging will beBrilrs (1993, 1995) transformation-based error-driventagger.)
Unlike other approaches to learning usingconstituent-based grammars, this system does not usethe wordclass information to restrict he roles, a wordcan play in the parse.
Rather it takes this informationas a starting point in the search for potential disjunctsfor unknown words.
And ifa new disjunct is found fora word already in the grammar, its credibility is testedby comparing the word's wordelass to the wordelass ofthe word with which the disjunct has the highestmembership value in the grammar (el.
below).
Inboth cases, the word,lass information is only used tocorroborate d cisions made in advance.?
After the wordelass information is provided, thesystems looks for every potential conjugated verb inthe sentence.
For each of these verbs, a partial inkageis constructed, in which the verb is connected to theperiod by an Xp-link.
This is an important step as theXp-link cannot be crossed by any other link addedlater in the process.?
Then for all words listed in the grammar, the sys-tem retrieves all disjuncts which are connected tothem.
With these disjuncts, all potential partial ink-ages are constructed by linking all words which pos-sess matching connectors.
If word x, for example,possesses a disjunct with a connector =Jd-, it will belinked to word y possessing a disjunct with connector?Jd+.
All these links must fulfill the conditions thatthey must not cross, that the order of connectors inthe disjunct must not be changed, and that no twolinks can connect the same pair of words.?
In the next step, every disjunct in the partialparse which is activated (i.e.
partially f'dled) attemptsto fill the remaining connectors by linking them toneighboring words without violating the restrictionsmentioned above.
Like in the previous teps, all po-tential combinations are stored.?
After that, all words for which linking infor-mation is available but which are not yet connected tothe partial parse are linked in any possible way.?
If the linkage is not connected at this stage, thewords left out are either unknown or the disjunctneeded for this sentence has not been recorded for themyet.
Starting with an initial corpus of only 50 sen-tences, this will be the case for about 90% of the sen-tences.
But even if the grammar fragment is increasedconsiderably, it will be highly probable that mostlinkages are not connected at this stage.
As the dis-juncts needed to complete the linkage, or at least verysimilar ones, may already be included in the grammar,it is necessary to have an efficient relrieval function.In order to reduce the search space, the wordclass in-formation is used to find entries with similar linkingrequirements.
All the disjuncts found in this search arethen given to the unknown word as potential dis-juncts.
They are then used to complete the linkage.?
At this stage in the process, the learner has ag-gregated a number of complete linkages.
The nexttask must then be to evaluate them.
This is done bythe following method: First the membership value foreach word and the disjunct used in the linkage is cal-culated (el.
section 4.1).
This is not as trivial as itmay seem as for many words, the disjuncts actuallyused in the linkage are different form those originallyretrieved from the grammar.
If connector could not befilled, they are dropped, while other connectors whichoriginate from the linking requirements of anotherword are added.
From these membership values of thesingle words, the overall value of the linkage is calcu-lated as the arithmetic mean.
This final figure is usedas a measure of the quality of the linkage.?
The best parse then is given as the preferred parsefor the input sentence, and all new pairs of words anddisjuncts are ad~d to the grammar with their calcu-lated membership values.
For pairs already in thefuzzy grammar, the membership value is increased.?
As a last step, for every new or modified word,optional elements are marked in the disjuncts.4.1.
Calculating the Membership ValueThe following algorithm is used to calculate themembership value lx(w,d) for the pair <w, d>.i f(w ~ G*):if<w, d> ~ G*then ~t(w,d) = ~G.
(w,d)else get the pair <w',d'> with wordclass(w)wordclass(w') and minimal distance(d, d') andmaximal ~.a.
(W ,d' )then~(w,d) =/.re, (w' ,a ' ) -  O.
1 - distance(d,d' )i f(w m G*):if ((d ~ G*) A maximal l .
tc .
(w ' ,d)^(wordclass(w) ~ wordclass(w')))then ~t(w,d)  = Ua.
(w'  ,d)  - 0.1if ((d ~ G*) A maximal btG.
(w' ,d')A(wordelass(w), wordelass(w')))then ~t (w,d)= P 'c* (W'd)2if(d ~G*)then get the pair <w',d'> with (wordclass(w) m_wordelass(w')) and minimal distance(d, ') andmaximal p c. (w' ,  d' ), then~(w, d )  = la c. (w' ,  d' ) - 0.1 - distance(d, ar )KQbler 14 Learning Lexicalised Grammar for GermanlIIIIlIIIlIIIIIIIIIIIIIilIIIIIIIIIIilIIIIIITable 1: The grammar available for the example sentenceaberyoneinerFeh le~k6nnenwirheuteschonspreehen((=E), 0), ((=CO, ?Xk), lied)), (0, (=E))(0~ (?Jd, =MVp)), (0, (?Jd, =Yz, =MVp)), ((=MVp), (?Jdp)), ((=Mp), (?Jd)), ((MVpv), (?Jd))(0., (=Dsfdn)), ((=Ons), (?GEp+))((?MVp), (?Spl, ?In, ?Xk, =Coq)), ((?Sial,), (?In, ?Xk, ?COq)), ((?RSrp3), (~In))((=Sol), 0), (0, (=SpD)(0, (=E))(0, (?EBs)), (0, (=E))((?MVp, ?E, ?MVp), (=In))((=Xp), 0)I 0 if 0.05 ifdistance(d,d')= L ~01 ~.d,~ \] .
if\[0.2 ifException: Nothing is a,~d if the connector c isthe same as the preceding connector and the connectorcan be found in G* at least once marked for multipleoccl l rrence.The reason why the disjunct is punished harder formissing controlled links is that optional connectorsusually are controlling.4.2.
ExampleIn this section, we will look at an example sentence.It will not be possible to give all the potential link-ages but the gist of the argument should becomeclear.The example sentence is:Aber yon einer Fehlemfihnmg kOnnenwirbut of a malnutrition can weheute schon sprechentoday ak-eadyspeakTable 1 gives the information that can be extractedfrom the initial grammar G*.
All the disjuncts listedfor a word have the membership value 1 concerningthis word.
As can be seen in the table, there is onlyone unknown word in the sentence.
However, only forthe words "yon", "einer", "wir", "heute", and .
.
.
.
schon,the needed isjunct is listed.
All words belonging toan open wordclass except "wir" give only partial or noinformation needed for this sentence.1.
step: The only wordclass information eeded inthe further process is that "Fehlemfihrung" is a noun,and "k6nnen" and "sprechen" are potential verbs.2.
step: As we know from step 1, both "kOnnen"and "sprechen" are verbs.
So there are two ways to(c ~d)^(C Ed') place the first link, linking each verb in turn to the, period by an Xp-link.0nly features(d) ~ features(d / 3. step: For the information given in G*, see tablecontr01(d)-- ?'
1.
Three potential linkages are shown in figure 3.
Foreach given linkage, there is another one differing onlycontrol(d)--' =' by linking "schon" instead of"beute" to "sprechen".4. step: There are too many possibilities to link theremaining connectors of activated isjuncts to theirneighbor.
Figure 4 shows three of them, randomlychosen.5.
step: In figure 5, only two potential linkages aregiven at~er the remaining words are connected, theoverall membership value for these linkages is calcu-lated in step 7.6. step: This step is not necessary because the link-age is complete.7.
step: The calculations for the linkages repre-sented in figure 5 are given in table 2 and 3 respec-tively.8.
step: The disjuncts from table 2 for the words"aber", "Fehlem/ihrung", k6nnen", and "sprechen"with their membership values are Mded~ to thegrarrmlar.9.
step: There are two new disjuncts which can bemarked for optional connectors: For the word "aber",the new disjunct is (({=CC}, {=Xk}), (?Cd)), and for"kOnnen" (({=Cd}, ?MVp), (?Spl, ?In, {Xp})).5.
Future WorkThere is still so much work to do that it is hard todecide what should be done first.
The most importantta.sk is certainly the implementation f the algorithmand the parser.
This will hopefully be finished for thepresentation so that at least sample results can begiven.Another important task will be to increase the sizeof the corpus from which the grammar fragment isextracted.
The more information is available to thelearning component, he better the judgment on thebest links will be.
Another way to improve the choiceand evaluation of new disjuncts will be to include co-occurrence information into the calculation of theKObler 15 Learning Lexicalised Graramar for Germanmembership value of a disjunct.
If, for example, theconnector ?Xp+ is accompanied by an S-link in themajority of cases, a new disjunet including both con-neetors hould be valued more confidently than onewhich does not.AberXv ehlemAberAbervon emer Fehlernahrung k6nnen WIT heute schon sprechenvon einer FehlemahrtmgFskOnnen wir heute schon sprechenFigure 3: Potential partial inkages after step 3AberXMV Ij EvAberXMVY ES Ivon einer Fehlemahrung konnen wtr heute schon sprechenKtabler 16 Learning Lexicalised Grammar for GermanIIIII!IIIIIIIIIIIIIIIIII/II/il/IAber~ MV~_......_...~Fs_yon einer Fehlemfihrung k6nnen wir heute schon sprechenFigure 4: Potential partial inkages after step 4?
C .
XMV IJ EA .
.
.
.
.
.CMVJ EAber yon einer Feh le~g k6nnen wit  heute schon sprechenFigure 5: Potential linkages alter step 5Table 2: The evaluation of the disjuncts for the first linkagewordabetyoneinerFehlern~hrungk6nnenwirheutesehonsprechendis itmct(O, (?Cd))value comment0.9 ((), (?Cd)) ~ G*(0, (~Jd, =MVp))(0, (=Dsfdn))((--Jd, ?Dsfdn), 0)((=Cd, ?MVp),(?spl, ?In, ?Xp))((=spD, 0)(0, (-E))(0, (=E))((=In, ?E, ?E), 0)((=Xp), O)arithmetic mean =0.90.751((=Jd~ ?Dsfdn), 0) ~ G*most similar disjunct in G*: ((?MVp), (?Ss3,?.~, ?Xp))110.8 ((-In, ?E), ())~ G*10.93Kfibler 17 Learning Lexicalised Grammar for GermanwordabervoneinerFehlem/ihrungk6nnenwirheuteschonsprechendis, junct0.9 (0, (?Cd))(0, (?Jd, =MVp))(0, (=Dsfdn))((=Jd, ?Dsfdn), 0)(0, (?Spl, ?Xn))((--Spl), 0)(0, (=Z))(0, (=Z))((=Cd, ?MVp, --In,?E, ?E), (?Xp))((=Xp), O)trithmetic mean =value comment110.9(0, (~Cd)) ~ G*Table 3: The evaluation of the disjuncts for the second linkage0.711I0.40.89((=Jd, ?Dsfdn), O) ~ G*most similar disjunct in G*: ((=Cd, ?EF),(?Spl, ?In+))most similar disjunct in G*: ((=Cd, ?MVp),(?Ssl, ?In, ?Xp))6.
Re ferencesBrill, E. (1993).
A Corpus-Based Approach to Lan2guage Learning (Ph.D. thesis).
Philadelphia: Uni-versity of Pennsylvania, Department of Computerand Information Science.Brill, E. (1995).
Transformation-based tagger, version1.14.
ftp://blaze.cs.jhu.edu/pub/brill/Programs/RULE...BA SED TAGGE R_V.
1.14.tar.ZDella Pietra, S. & Della Pietra, V. & Gillett, J.
&Lafferty, J.
& Printz, H. & Ures, L. (1994).
Infer-ence and Estimation of a Long-Range TrigramModel.
In R. Carrasco & J. Oncina (Eds.
), Gram-matical Inference and Applications: Proceedings ofthe Second International Colloquium, 1CG1-94,Alicante, Spain (pp.
78-92).
Berlin: Springer.Fong, E. & Wu, D. (1995).
Learning RestrictedProbabilistic Link Grammars.
1JCA1-95 on NewApproaches toLearning for Nantral Language Proc-essing, Montreal Canada.
(pp.
49-56).Grinberg, D. & Lafferty, J.
& Sleator, D. (1995) Arobust parsing algorithm.for link grammars (Tech.rep.
CMU-CS-95-125).
Pittsburgh, PA: CarnegieMellon University, School of Computer Science.Lafferty, J.
& Sleator, D. & Temperley, D. (1992).Grammatical trigrams: aprobabilistic model of linkgrammar.
Proceedings of the AAAI Conference onProbabilistic Approaches to Natural Language.Cambridge, MA.Mel'cuk, I.
(1988).
Dependency s ntax: theoIT andpractice.
State University of New York.Sleator, D. & Temperley, D. (1991).
Parsing Englishwith a link grammar (Tech.
Rep. CMU-CS-91-196).
Pittsburgh, PA: Carnegie Mellon University,School of Computer Science.Sleator, D. & Temperley, D. (1996).
Link grammarparser, version 2.1. ftp://ftp.cs.cmu.edu/user/sleator/link-grammar/system-2.1 .tar.gzYesniere, L. (I 959).
Elkments de syntaxe structurale.Paris: Klincksieck.Zadeh, L. (1965).
Fuzzy sets.
lnJbrmation ~dControl 8, pp.
338-353.Ktibler 18 Learning Lexicalised Grammar.for GermanIIIIIIiIiInInIIIIII|IIII|IIIIIIII
