Proceedings of the ACL 2010 Conference Short Papers, pages 313?317,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsUsing Speech to Reply to SMS Messages While Driving:An In-Car Simulator User StudyYun-Cheng Ju, Tim PaekMicrosoft ResearchRedmond, WA USA{yuncj|timpaek}@microsoft.comAbstractSpeech recognition affords automobiledrivers a hands-free, eyes-free method ofreplying to Short Message Service (SMS)text messages.
Although a voice searchapproach based on template matching hasbeen shown to be more robust to the chal-lenging acoustic environment of automo-biles than using dictation, users may havedifficulties verifying whether SMS re-sponse templates match their intendedmeaning, especially while driving.
Using ahigh-fidelity driving simulator, we com-pared dictation for SMS replies versusvoice search in increasingly difficult driv-ing conditions.
Although the two ap-proaches did not differ in terms of drivingperformance measures, users made aboutsix times more errors on average usingdictation than voice search.1 IntroductionUsers love Short Message Service (SMS) textmessaging; so much so that 3 trillion SMS mes-sages are expected to have been sent in 2009alone (Stross, 2008).
Because research hasshown that SMS messaging while driving resultsin 35% slower reaction time than being intox-icated (Reed & Robbins, 2008), campaigns havebeen launched by states, governments and evencell phone carriers to discourage and ban SMSmessaging while driving (DOT, 2009).
Yet, au-tomobile manufacturers have started to offer in-fotainment systems, such as the Ford Sync,which feature the ability to listen to incomingSMS messages using text-to-speech (TTS).
Au-tomatic speech recognition (ASR) affords users ahands-free, eyes-free method of replying to SMSmessages.
However, to date, manufacturers havenot established a safe and reliable method of le-veraging ASR, though some researchers havebegun to explore techniques.
In previous re-search (Ju & Paek, 2009), we examined threeASR approaches to replying to SMS messages:dictation using a language model trained on SMSresponses, canned responses using a probabilisticcontext-free grammar (PCFG), and a ?voicesearch?
approach based on template matching.Voice search proceeds in two steps (Natarajan etal., 2002): an utterance is first converted intotext, which is then used as a search query tomatch the most similar items of an index usingIR techniques (Yu et al, 2007).
For SMS replies,we created an index of SMS response templates,with slots for semantic concepts such as time andplace, from a large SMS corpus.
After convolv-ing recorded SMS replies so that the audio wouldexhibit the acoustic characteristics of in-car rec-ognition, they compared how the three approach-es handled the convolved audio with respect tothe top n-best reply candidates.
The voice searchapproach consistently outperformed dictation andcanned responses, achieving as high as 89.7%task completion with respect to the top 5 replycandidates.Even if the voice search approach may bemore robust to in-car noise, this does not guaran-tee that it will be more usable.
Indeed, becausevoice search can only match semantic conceptscontained in the templates (which may or maynot utilize the same wording as the reply), usersmust verify that a retrieved template matches thesemantics of their intended reply.
For example,suppose a user replies to the SMS message ?howabout lunch?
with ?can?t right now running er-rands?.
Voice search may find ?nope, got er-rands to run?
as the closest template match, inwhich case, users will have to decide whetherthis response has the same meaning as their re-ply.
This of course entails cognitive effort, whichis very limited in the context of driving.
On theother hand, a dictation approach to replying toSMS messages may be far worse due to misre-cognitions.
For example, dictation may interpret?can?t right now running errands?
as ?can right313now fun in errands?.
We posited that voicesearch has the advantage because it always gene-rates intelligible SMS replies (since responsetemplates are manually filtered), as opposed todictation, which can sometimes result in unpre-dictable and nonsensical misrecognitions.
How-ever, this advantage has not been empiricallydemonstrated in a user study.
This paper presentsa user study investigating how the two approach-es compare when users are actually driving ?
thatis, when usability matters most.2 Driving Simulator StudyAlthough ASR affords users hands-free, eyes-free interaction, the benefits of leveraging speechcan be forfeit if users are expending cognitiveeffort judging whether the speech interface cor-rectly interpreted their utterances.
Indeed, re-search has shown that the cognitive demands ofdialogue seem to play a more important role indistracting drivers than physically handling cellphones (Nunes & Recarte, 2002; Strayer &Johnston, 2001).
Furthermore, Kun et al (2007)have found that when in-car speech interfacesencounter recognition problems, users tend todrive more dangerously as they attempt to figureout why their utterances are failing.
Hence, anyapproach to replying to SMS messages in auto-mobiles must avoid distracting drivers with er-rors and be highly usable while users are en-gaged in their primary task, driving.2.1 MethodTo assess the usability and performance of boththe voice search approach and dictation, we con-ducted a controlled experiment using the STISIMDrive?
simulator.
Our simulation setup con-sisted of a central console with a steering wheeland two turn signals, surrounded by three 47?
?flat panels placed at a 45?
angle to immerse thedriver.
Figure 1 displays the setup.We recruited 16 participants (9 males, 7 fe-males) through an email sent to employees of ourorganization.
The mean age was 38.8.
All partic-ipants had a driver?s license and were compen-sated for their time.We examined two independent variables: SMSReply Approach, consisting of voice search anddictation, and Driving Condition, consisting ofno driving, easy driving and difficult driving.
Weincluded Driving Condition as a way of increas-ing cognitive demand (see next section).
Overall,we conducted a 2 (SMS Reply Approach) ?
3(Driving Condition) repeated measures, within-subjects design experiment in which the order ofSMS Reply for each Driving Condition was coun-ter-balanced.
Because our primary variable ofinterest was SMS Reply, we had users experienceboth voice search and dictation with no drivingfirst, then easy driving, followed by difficultdriving.
This gave users a chance to adjust them-selves to increasingly difficult road conditions.Driving Task: As the primary task, users wereasked to drive two courses we developed witheasy driving and difficult driving conditionswhile obeying all rules of the road, as they wouldin real driving and not in a videogame.
Withspeed limits ranging from 25 mph to 55 mph,both courses contained five sequential sectionswhich took about 15-20 minutes to complete: aresidential area, a country highway, and a smallcity with a downtown area as well as a busi-ness/industrial park.
Although both courses werealmost identical in the number of turns, curves,stops, and traffic lights, the easy course consistedmostly of simple road segments with relativelyno traffic, whereas the difficult course had fourtimes as many vehicles, cyclists, and pedestrians.The difficult course also included a foggy roadsection, a few busy construction sites, and manyunexpected events, such as a car in front sudden-ly breaking, a parked car merging into traffic,and a pedestrian jaywalking.
In short, the diffi-cult course was designed to fully engage the at-tention and cognitive resources of drivers.SMS Reply Task: As the secondary task, weasked users to listen to an incoming SMS mes-sage together with a formulated reply, such as:(1) Message Received: ?Are you lost??
YourReply: ?No, never with my GPS?The users were asked to repeat the reply back tothe system.
For Example (1) above, users wouldhave to utter ?No, never with my GPS?.
UsersFigure 1.
Driving simulator setup.314could also say ?Repeat?
if they had any difficul-ties understanding the TTS rendering or if theyexperienced lapses in attention.
For each course,users engaged in 10 SMS reply tasks.
SMS mes-sages were cued every 3000 feet, roughly every90 seconds, which provided enough time tocomplete each SMS dialogue.
Once users utteredthe formulated reply, they received a list of 4possible reply candidates (each labeled as ?One?,?Two?, etc.
), from which they were asked to ei-ther pick the correct reply (by stating its numberat any time) or reject them all (by stating ?Allwrong?).
We did not provide any feedback aboutwhether the replies they picked were correct orincorrect in order to avoid priming users to paymore or less attention in subsequent messages.Users did not have to finish listening to the entirelist before making their selection.Stimuli: Because we were interested in examin-ing which was worse, verifying whether SMSresponse templates matched the meaning of anintended reply, or deciphering the sometimesnonsensical misrecognitions of dictation, we de-cided to experimentally control both the SMSreply uttered by the user as well as the 4-best listgenerated by the system.
However, all SMS rep-lies and 4-best lists were derived from the logs ofan actual SMS Reply interface which imple-mented the dictation and the voice search ap-proaches (see Ju & Paek, 2009).
For each course,5 of the SMS replies were short (with 3 or fewerwords) and 5 were long (with 4 to 7 words).
Themean length of the replies was 3.5 words (17.3chars).
The order of the short and long replieswas randomized.We selected 4-best lists where the correct an-swer was in each of four possible positions (1-4)or All Wrong; that is, there were as many 4-bestlists with the first choice correct as there werewith the second choice correct, and so forth.
Wethen randomly ordered the presentation of differ-ent 4-best lists.
Although one might argue thatthe four positions are not equally likely and thatthe top item of a 4-best list is most often the cor-rect answer, we decided to experimentally con-trol the position for two reasons: first, our pre-vious research (Ju & Paek, 2009) had alreadydemonstrated the superiority of the voice searchapproach with respect to the top position (i.e., 1-best), and second, our experimental designsought to identify whether the voice search ap-proach was more usable than the dictation ap-proach even when the ASR accuracy of the twoapproaches was the same.In the dictation condition, the correct answerwas not always an exact copy of the reply in 0-2of the 10 SMS messages.
For instance, a correctdictation answer for Example (1) above was ?noI?m never with my GPS?.
On the other hand, thevoice search condition had more cases (2-4 mes-sages) in which the correct answer was not anexact copy (e.g., ?no I have GPS?)
due to thenature of the template approach.
To some degree,this could be seen as handicapping the voicesearch condition, though the results did not re-flect the disadvantage, as we discuss later.Measures: Performance for both the driving taskand the SMS reply tasks were recorded.
For thedriving task, we measured the numbers of colli-sions, speeding (exceeding 10 mph above thelimit), traffic light and stop sign violations, andmissed or incorrect turns.
For the SMS replytask, we measured duration (i.e., time elapsedbetween the beginning of the 4-best list andwhen users ultimately provided their answer) andthe number of times users correctly identifiedwhich of the 4 reply candidates contained thecorrect answer.Originally, we had an independent rater verifythe position of the correct answer in all 4-bestlists, however, we considered that some partici-pants might be choosing replies that are semanti-cally sufficient, even if they are not exactly cor-rect.
For example, a 4-best list generated by thedictation approach for Example (1) had: ?One:no I?m never want my GPS.
Two: no I?m neverwith my GPS.
Three: no I?m never when myGPS.
Or Four: no no I?m in my GPS.?
Althoughthe rater identified the second reply as being?correct?, a participant might view the first orthird replies as sufficient.
In order to avoid am-biguity about correctness, after the study, weshowed the same 16 participants the SMS mes-sages and replies as well as the 4-best lists theyreceived during the study and asked them to se-lect, for each SMS reply, any 4-best list itemsthey felt sufficiently conveyed the same mean-ing, even if the items were ungrammatical.
Par-ticipants were explicitly told that they could se-lect multiple items from the 4-best list.
We didnot indicate which item they selected during theexperiment and because this selection task oc-curred months after the experiment, it was un-likely that they would remember anyway.
Partic-ipants were compensated with a cafeteria vouch-er.In computing the number of ?correct?
an-swers, for each SMS reply, we counted an an-315swer to be correct if it was included among theparticipants?
set of semantically sufficient 4-bestlist items.
Hence, we calculated the number ofcorrect items in a personalized fashion for everyparticipant.2.2 ResultsWe conducted a series of repeated measuresANOVAs on all driving task and SMS reply taskmeasures.
For the driving task, we did not findany statistically significant differences betweenthe voice search and dictation conditions.
In oth-er words, we could not reject the null hypothesisthat the two approaches were the same in termsof their influence on driving performance.
How-ever, for the SMS reply task, we did find a maineffect for SMS Reply Approach (F1,47 = 81.28, p <.001, ?Dictation = 2.13 (.19), ?VoiceSearch = .38 (.10)).As shown in Figure 2, the average number oferrors per driving course for dictation is roughly6 times that for voice search.
We also found amain effect for total duration (F1,47 = 11.94, p <.01, ?Dictation = 113.75 sec (3.54) or 11.4 sec/reply,?VoiceSearch = 125.32 sec (3.37) or 12.5 sec/reply).We discuss our explanation for the shorter dura-tion below.
For both errors and duration, we didnot find any interaction effects with DrivingConditions.3 DiscussionWe conducted a simulator study in order to ex-amine which was worse while driving: verifyingwhether SMS response templates matched themeaning of an intended reply, or deciphering thesometimes nonsensical misrecognitions of dicta-tion.
Our results suggest that deciphering dicta-tion results under the duress of driving leads tomore errors.
In conducting a post-hoc error anal-ysis, we noticed that participants tended to errwhen the 4-best lists generated by the dictationapproach contained phonetically similar candi-date replies.
Because it is not atypical for the dic-tation approach to have n-best list candidatesdiffering from each other in this way, we rec-ommend not utilizing this approach in speech-only user interfaces, unless the n-best list candi-dates can be made as distinct from each other aspossible, phonetically, syntactically and mostimportantly, semantically.
The voice search ap-proach circumvents this problem in two ways: 1)templates were real responses and manually se-lected and cleaned up during the developmentphase so there were no grammatical mistakes,and 2) semantically redundant templates can befurther discarded to only present the distinct con-cepts at the rendering time using the paraphrasedetection algorithms reported in (Wu et al,2010).Given that users committed more errors in thedictation condition, we initially expected thatdictation would exhibit higher duration thanvoice search since users might be spending moretime figuring out the differences between thesimilar 4-best list candidates generated by thedictation approach.
However, in our error analy-sis we observed that most likely users did notdiscover the misrecognitions, and prematurelyselected a reply candidate, resulting in shorterdurations.
The slightly higher duration for thevoice search approach does not constitute a prob-lem if users are listening to all of their choicesand correctly selecting their intended SMS reply.Note that the duration did not bring about anysignificant driving performance differences.Although we did not find any significant driv-ing performance differences, users experiencedmore difficulties confirming whether the dicta-tion approach correctly interpreted their utter-ances than they did with the voice search ap-proach.
As such, if a user deems it absolutelynecessary to respond to SMS messages whiledriving, our simulator study suggests that themost reliable (i.e., least error-prone) way to re-spond may just well be the voice search ap-proach.ReferencesDistracted Driving Summit.
2009.
Department ofTransportation.
Retrieved Dec. 1:http://www.rita.dot.gov/distracted_driving_summitFigure 2.
Mean number of errors for the dictationand voice search approaches.
Error bars representstandard errors about the mean.316Y.C.
Ju & T. Paek.
2009.
A Voice Search Approachto Replying to SMS Messages in Automobiles.
InProc.
of Interspeech.A.
Kun, T. Paek & Z. Medenica.
2007.
The Effect ofSpeech Interface Accuracy on Driving Perfor-mance, In Proc.
of Interspeech.P.
Natarajan, R. Prasad, R. Schwartz, & J. Makhoul.2002.
A Scalable Architecture for Directory Assis-tance Automation.
In Proc.
of ICASSP, pp.
21-24.L.
Nunes & M. Recarte.
2002.
Cognitive Deamnds ofHands-Free-Phone Conversation While Driving.Transportation Research Part F, 5: 133-144.N.
Reed & R. Robbins.
2008.
The Effect of TextMessaging on Driver Behaviour: A SimulatorStudy.
Transport Research Lab Report, PPR 367.D.
Strayer & W. Johnston.
2001.
Driven to Distrac-tion: Dual-task Studies of Simulated Driving andConversing on a Cellular Phone.
PsychologicalScience, 12: 462-466.R.
Stross.
2008.
?What carriers aren?t eager to tell youabout texting?, New York Times, Dec. 26, 2008:http://www.nytimes.com/2008/12/28/business/28digi.html?_r=3D.
Yu, Y.C.
Ju, Y.-Y.
Wang, G. Zweig, & A. Acero.2007.
Automated Directory Assistance System:From Theory to Practice.
In Proc.
of Interspeech.Wei Wu, Yun-Cheng Ju, Xiao Li, and Ye-Yi Wang,Paraphrase Detection on SMS Messages in Auto-mobiles, in ICASSP, IEEE, March 2010317
