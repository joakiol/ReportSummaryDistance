Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 1783?1792,Beijing, China, July 26-31, 2015. c?2015 Association for Computational LinguisticsCoupled Sequence Labeling on Heterogeneous Annotations: POS Taggingas a Case StudyZhenghua Li, Jiayuan Chao, Min Zhang?, Wenliang Chen(1) Soochow University(2) Collaborative Innovation Center of Novel Software Technology and IndustrializationJiangsu Province, China{zhli13,minzhang,wlchen}@suda.edu.cn; china cjy@163.comAbstractIn order to effectively utilize multipledatasets with heterogeneous annotations,this paper proposes a coupled sequencelabeling model that can directly learn andinfer two heterogeneous annotationssimultaneously, and to facilitatediscussion we use Chinese part-of-speech (POS) tagging as our case study.The key idea is to bundle two sets ofPOS tags together (e.g.
?
[NN, n]?
), andbuild a conditional random field (CRF)based tagging model in the enlargedspace of bundled tags with the help ofambiguous labelings.
To train our modelon two non-overlapping datasets that eachhas only one-side tags, we transform aone-side tag into a set of bundled tagsby considering all possible mappings atthe missing side and derive an objectivefunction based on ambiguous labelings.The key advantage of our coupled modelis to provide us with the flexibility of1) incorporating joint features on thebundled tags to implicitly learn theloose mapping between heterogeneousannotations, and 2) exploring separatefeatures on one-side tags to overcome thedata sparseness problem of using onlybundled tags.
Experiments on benchmarkdatasets show that our coupled modelsignificantly outperforms the state-of-the-art baselines on both one-side POStagging and annotation conversion tasks.The codes and newly annotated data arereleased for non-commercial usage.1?Correspondence author.1http://hlt.suda.edu.cn/?zhli1 IntroductionThe scale of available labeled data significantlyaffects the performance of statistical data-drivenmodels.
As a widely-used structural classificationproblem, sequence labeling is prone to sufferfrom the data sparseness issue.
However, theheavy cost of manual annotation typically limitsone labeled resource in both scale and genre.As a promising research line, semi-supervisedlearning for sequence labeling has been exten-sively studied.
Huang et al (2009) show thatstandard self-training can boost the performanceof a simple hidden Markov model (HMM) basedpart-of-speech (POS) tagger.
S?gaard (2011) ap-ply tri-training to English POS tagging, boost-ing accuracy from 97.27% to 97.50%.
Sun andUszkoreit (2012) derive word clusters from large-scale unlabeled data as extra features for Chi-nese POS tagging.
Recently, the use of naturalannotation has becomes a hot topic in Chineseword segmentation (Jiang et al, 2013; Liu etal., 2014; Yang and Vozila, 2014).
The idea isto derive segmentation boundaries from implicitinformation encoded in web texts, such as anchortexts and punctuation marks, and use them aspartially labeled training data in sequence labelingmodels.The existence of multiple annotated resourcesopens another door for alleviating data sparse-ness.
For example, Penn Chinese Treebank (CTB)contains about 20 thousand sentences annotatedwith word boundaries, POS tags, and syntacticstructures (Xue et al, 2005), which is widely usedfor research on Chinese word segmentation andPOS tagging.
People?s Daily corpus (PD)2 is alarge-scale corpus annotated with word segmentsand POS tags, containing about 300 thousandsentences from the first half of 1998 of People?s2http://icl.pku.edu.cn/icl_groups/corpustagging.asp1783???
? ???
? ??
?China focuses on economic development??
? ??
? ???
? ???
?Our nation strongly develops education[VV,v]  [VE,v][VC,v]  [VA,v]Bundled  tags [NN,n][NN,Ng][NN,vn]??
?Figure 1: An example to illustrate the annotationdifferences between CTB (above) and PD (below),and how to transform a one-side tag into a setof bundled tags.
?NN?
and ?n?
represent nouns;?VV?and ?v?
represent verbs.Daily newspaper (see Table 2).
The two resourceswere independently built for different purposes.CTB was designed to serve syntactic analysis,whereas PD was developed to support informationextraction systems.
However, the key challengeof exploiting the two resources is that they adoptdifferent sets of POS tags which are impossible tobe precisely converted from one to another basedon heuristic rules.
Figure 1 shows two examplesentences from CTB and PD.
Please refer to TableB.3 in Xia (2000) for detailed comparison of thetwo guidelines.Previous work on exploiting heterogeneous data(CTB and PD) mainly focuses on indirect guide-feature based methods.
The basic idea is to useone resource to generate extra guide features onanother resource (Jiang et al, 2009; Sun andWan, 2012), which is similar to stacked learning(Nivre and McDonald, 2008).
First, PD is usedas source data to train a source model TaggerPD.Then, TaggerPD generates automatic POS tagson the target data CTB, called source annota-tions.
Finally, a target model TaggerCTB-guidedis trained on CTB, using source annotations asextra guide features.
Although the guide-featurebased method is effective in boosting performanceof the target model, we argue that it may havetwo potential drawbacks.
First, the target modelTaggerCTB-guided does not directly use PD as train-ing data, and therefore fails to make full use of richlanguage phenomena in PD.
Second, the methodis more complicated in real applications since itneeds to parse a test sentence twice to get the finalresults.This paper proposes a coupled sequence label-ing model that can directly learn and infer twoheterogeneous annotations simultaneously.
Weuse Chinese part-of-speech (POS) tagging as ourcase study.3 The key idea is to bundle two setsof POS tags together (e.g.
?
[NN, n]?
), and builda conditional random field (CRF) based taggingmodel in the enlarged space of bundled tags.
Tomake use of two non-overlapping datasets thateach has only one-side tags, we transform a one-side tag into a set of bundled tags by consideringall possible mappings at the missing side andderive an objective function based on ambiguouslabelings.
During training, the CRF-based cou-pled model is supervised by such ambiguous label-ings.
The advantages of our coupled model are toprovide us the flexibility of 1) incorporating jointfeatures on the bundled tags to implicitly learn theloose mapping between two sets of annotations,and 2) exploring separate features on one-side tagsto overcome the data sparseness problem of usingbundled tags.
In summary, this work makes twomajor contributions:1.
We propose a coupled model which can moreeffectively make use of multiple resourceswith heterogeneous annotations, comparedwith both the baseline and guide-featurebased method.
Experiments show ourapproach can significantly improve POStagging accuracy from 94.10% to 95.00% onCTB.2.
We have manually annotated CTB tags for1, 000 PD sentences, which is the first datasetwith two-side annotations and can be usedfor annotation-conversion evaluation.
Exper-iments on the newly annotated data showthat our coupled model also works effectivelyon the annotation conversion task, improvingconversion accuracy from 90.59% to 93.90%(+3.31%).2 Traditional POS Tagging (TaggerCTB)Given an input sentence of n words, denoted byx = w1...wn, POS tagging aims to find an optimaltag sequence t = t1...tn, where ti?
T (1 ?
i ?n) and T is a predefined tag set.
As a log-linearprobabilistic model (Lafferty et al, 2001), CRF3There are some slight differences in the word segmenta-tion guidelines between CTB and PD, which are ignored inthis work for simplicity.178401: ti?
ti?102: ti?
wi03: ti?
wi?104: ti?
wi+105: ti?
wi?
ci?1,?106: ti?
wi?
ci+1,007: ti?
ci,008: ti?
ci,?109: ti?
ci,k, 0 < k < #ci?
110: ti?
ci,0?
ci,k, 0 < k < #ci?
111: ti?
ci,?1?
ci,k, 0 < k < #ci?
112: if #ci= 1 then ti?
wi?
ci?1,?1?
ci+1,013: if ci,k= ci,k+1then ti?
ci,k?
?consecutive?14: ti?
prefix(wi, k), 1 ?
k ?
4, k ?
#ci15: ti?
suffix(wi, k), 1 ?
k ?
4, k ?
#ciTable 1: POS tagging features f(x, i, ti?1, ti).
?means string concatenation; ci,kdenotes the kthChinese character of wi; ci,0is the first Chinesecharacter; ci,?1is the last Chinese character;#ciis the total number of Chinese characterscontained in wi; prefix/suffix(wi, k) denote the k-Character prefix/suffix of wi.defines the probability of a tag sequence as:P (t|x; ?)
=exp(Score(x, t; ?
))?t?exp(Score(x, t?
; ?
))Score(x, t; ?)
=?1?i?n?
?
f(x, i, ti?1, ti)(1)where f(x, i, ti?1, ti) is the feature vector at theith word and ?
is the weight vector.
We adopt thestate-of-the-art tagging features in Table 1 (Zhangand Clark, 2008).3 Coupled POS Tagging (TaggerCTB&PD)In this section, we introduce our coupled model,which is able to learn and predict two heteroge-neous annotations simultaneously.
The idea is tobundle two sets of POS tags together and let theCRF-based model work in the enlarged tag space.For example, a CTB tag ?NN?
and a PD tag ?n?would be bundled into ?[NN,n]?.
Figure 2 showsthe graphical structure of our model.Different from the traditional model in Eq.
(1),our coupled model defines the score of a bundledtag sequence as follows:Score(x, [ta, tb]; ?)
=?1?i?n?
???
?f(x, i, [tai?1, tbi?1], [tai, tbi])f(x, i, tai?1, tai)f(x, i, tbi?1, tbi)???
(2)where the first item of the enlarged feature vectoris called joint features, which can be obtained byw1 wi-1 wi wn...
...Figure 2: Graphical structure of our coupled CRFmodel.instantiating Table 1 by replacing tiwith bundledtags [tai, tbi]; the second and third items are calledseparate features, which are based on single-sidetags.
The advantages of our coupled model overthe traditional model are to provide us with theflexibility of using both kinds of features, whichsignificantly contributes to the accuracy improve-ment as shown in the following experiments.3.1 Mapping FunctionsThe key challenge of our idea is that both CTB andPD are non-overlapping and each contains onlyone-side POS tags.
Therefore, the problem is howto construct training data for our coupled model.We denote the tag set of CTB as T a, and that ofPD as T b, and the bundled tag set as T a&b.
Sincethe full Cartetian T a ?
T b would lead to a verylarge number of bundled tags, making the modelvery slow, we would like to come up with a muchsmaller T a&b ?
T a ?
T b, based on linguisticinsights of the annotation guidelines of the twodatasets.To obtain a proper T a&b, we introduce a map-ping function between the two sets of tags as m :Ta?
Tb?
{0, 1}, which only allow specific tagpairs to be bundled together.m(ta, tb) ={1 if the two tags can be bundled0 otherwise(3)where one mapping function m corresponds toone T a&b.
When the mapping function becomeslooser, the tag set size |T a&b| becomes larger.Then, based on the mapping function, we canmap a single-side POS tag into a set of bundledtags by considering all possible tags at the missingside, as illustrated in Figure 1.
The word ?
?U4?is tagged as ?NN?
at the CTB side.
Suppose thatthe mapping function m tells that ?NN?
can bemapped into three tags at the PD side, i.e., ?n?,?Ng?, and ?vn?.
Then, we create three bundledtags for the word, i.e., ?
[NN, n]?, ?
[NN, Ng]?,1785?
[NN, vn]?
as its gold-standard references duringtraining.
It is known as ambiguous labelings whena training instance has multiple gold-standard la-bels.
Similarly, we can obtain bundled tags for allother words in sentences of CTB and PD.
Aftersuch transformation, the two datasets are now inthe same tag space.At the beginning of this work, our intuition isthat the coupled model would achieve the bestperformance if we build a tight and linguistical-ly motivated mapping function.
However, ourpreliminary experiments show that our intuitiveassumption is actually incorrect.
Therefore, weexperiment with the following four mapping func-tions to manage to figure out the reasons behindand to better understand our coupled model.?
The tight mapping function produces 145tags, and is constructed by strictly followinglinguistic principles and our careful study ofthe two guidelines and datasets.?
The relaxed mapping function results in 179tags, which is an looser version of the tightmapping function by including extra 34 weakmapping relationships.?
The automatic mapping function generates346 tags.
We use the baseline TaggerCTB toparse PD, and collect all automatic mappingrelationships.?
The complete mapping function obtains1, 254 tags (|T a| ?
|T b| = 33 ?
38).3.2 Training Objective with AmbiguousLabelingsSo far, we have formally defined a coupled modeland prepared both CTB and PD in the samebundled tag space.
The next problem is how tolearn the model parameters ?.
Note that after ourtransformation, a sentence in CTB or PD havemany tag sequences as gold-standard referencesdue to the loose mapping function, known asambiguous labelings.
Here, we derive a trainingobjective based on ambiguous labelings.
Forsimplicity, we illustrate the idea based on thenotations of the baseline CRF model in Eq.
(1).Given a sentence x, we denote a set of ambigu-ous tag sequences as V .
Then, the probability ofV is the sum of probabilities of all tag sequencescontained in V:p(V|x; ?)
=?t?Vp(t|x; ?)
(4)Algorithm 1 SGD training with two labeleddatasets.1: Input: Two labeled datasets: D(1) ={(x(1)i,V(1)i}Ni=1, D(2)= {(x(2)i,V(2)i)}Mi=1;Parameters: I , N ?, M ?, b2: Output: ?3: Initialization: ?0= 0, k = 0;4: for i = 1 to I do {iterations}5: Randomly select N ?
instances from D(1)and M ?
instances from D(2) to compose anew dataset Di, and shuffle it.6: Traverse Di, and use a small batch Dbk?Diat one step.7: ?k+1= ?k+ ?k1b?L(Dbk; ?k)8: k = k + 19: end forSuppose the training data is D = {(xi,Vi)}Ni=1.Then the log likelihood is:L(D; ?)
=N?i=1log p(Vi|xi; ?)
(5)After derivation, the gradient is:?L(D; ?)?
?=N?i=1(Et?Vi[f(xi, t)] ?Et[f(xi, t)])(6)where f(xi, t) is an aggregated feature vector fortagging xias t; Et?Vi[.]
means model expectationof the features in the constrained space of Vi;Et[.]
is model expectation with no constraint.This function can be efficiently solved by theforward-backward algorithm.
Please note that thetraining objective of a traditional CRF model canbe understood as a special case where Vicontainsone sequence.3.3 SGD Training with Two DatasetsWe adopt stochastic gradient descent (SGD) toiteratively learn ?
for our baseline and coupledmodels.
However, we have two separate trainingdata, and CTB may be overwhelmed by PD ifdirectly merging the two datasets into one, sincePD is 15 times larger than CTB (see Table 2),Therefore, we propose a simple corpus-weightingstrategy, as shown in Algorithm 1, where Dbkis asubset of training data used in kth step update; bis the batch size; ?kis a update step.
The idea isto randomly sample instances from each trainingdata in a certain proportion before each iteration.1786The sampled data is then used for one-iterationtraining.
Later experiments will investigate theeffect of the weighting proportion.
In this work,we use b = 30, and follow the implementation inCRFsuite4 to decide ?k.4 Manually Annotating PD Sentenceswith CTB TagsTo evaluate different methods on annotation con-version, we build the first dataset that contains1, 000 sentences with POS tags on both sides ofCTB and PD.
The sentences are randomly sam-pled from PD.
To save annotation effort, we onlyselect 20% most difficult tokens to manually anno-tate.
The difficulty of a word wiis measured basedon marginal probabilities produced by the baselineTaggerCTB.
p(ti|x, wi; ?)
denotes the marginalprobability of tagging wias ti.
The basic assump-tion is that wiis more difficult to annotate if itsmost likely tag candidate (arg maxtp(t|x, wi; ?
))gets lower marginal probability.We build a visualized online annotation systemto facilitate manual labeling.
The annotation taskis designed in such way that at a time an annotatoris provided with a sentence and one focus word,and is required to decide the CTB POS tag of theword.
To further simplify annotation, we providetwo or three most likely tag candidates as well,so that annotators can choose one either amongthe candidates or from a full list.
We employ 8undergraduate students as our annotators.
Anno-tators are trained on simulated tasks from CTBdata for several hours, and and start real annotationonce reaching certain accuracy.
To guaranteeannotation quality, we adopt multiple annotation.Initially, one task is randomly assigned to twoannotators.
Later, if the two annotators submitdifferent results, the system will assign the taskto two more annotators.
To aggregate annotationresults, we only retain annotation tasks that thefirst two annotators agree (91.0%) or three anno-tators among four agree (5.6%), and discard othertasks (3.4%).
Finally, we obtain 5, 769 wordswith both CTB and PD tags, with each annotator?sdetailed submissions, and could be used as anon-synthesized dataset for studying aggregatingsubmissions from non-expert annotators in crowd-sourcing platforms (Qing et al, 2014).
The data isalso fully released for non-commercial usage.4http://www.chokkan.org/software/crfsuite/5 ExperimentsIn this section, we conduct experiments to verifythe effectiveness of our approach.
We adopt CTB(version 5.1) with the standard data split, andrandomly split PD into four sets, among whichone set is 20% partially annotated with CTB tags.The data statistics is shown in Table 2.
The mainconcern of this work is to improve accuracy onCTB by exploring large-scale PD, since CTB isrelatively small, but is widely-used benchmarkdata in the research community.We use the standard token-wise tagging accu-racy as the evaluation metric.
For significancetest, we adopt Dan Bikel?s randomized parsingevaluation comparator (Noreen, 1989).5.The baseline CRF is trained on either CTBtraining data with 33 tags, or PD training datawith 38 tags.
The coupled CRF is trained onboth two separate training datasets with bundledtags (179 tags for the relaxed mapping function).During evaluation, the coupled CRF is not directlyevaluated on bundled tags, since bundled tags areunavailable in either CTB or PD test data.
Instead,the coupled and baseline CRFs are both evaluatedon one-side tags.5.1 Model DevelopmentOur coupled model has two major parameters tobe decided.
The first parameter is to determinethe mapping function between CTB and PD an-notations, and the second parameter is the relativeweights of the two datasets during training (N ?
vs.M?
: number of sentences in each dataset used fortraining at one iteration).Effect of mapping functions (describedin Subsection 3.1) is illustrated in Figure 3.Empirically, we adopt N ?
= 5K vs. M ?
= 20Kto merge the two training datasets at each iteration.Our intuition is that using this proportion, CTBshould not be overwhelmed by PD, and bothtraining data can be used up in relatively similarspeed.
Specifically, all training data of CTB canbe consumed in about 3 iterations, whereas PDcan be consumed in about 14 iterations.
We alsopresent the results of the baseline model trainedusing 5K sentences in one iteration for bettercomparison.Contrary to our intuitive assumption, it actuallyleads to very bad performance when using the5http://www.cis.upenn.edu/?dbikel/software.html1787#sentences #tokens with CTB tags #tokens with PD tagsCTBtrain 16,091 437,991 ?dev 803 20,454 ?test 1,910 50,319 ?PDtrain 273,883 ?
6,488,208dev 1,000 ?
23,427test 2,500 ?
58,301newly labeled 1,000 5,769 27,942Table 2: Data statistics.
Please kindly note that the 1, 000 sentences originally from PD are only partiallyannotated with CTB tags (about 20% most ambiguous tokens).9292.59393.59494.59595.51  11  21  31  41  51  61  71  81  91AccuracyonCTB-dev(%)Iteration NumberCompleteAutomaticRelaxedTightBaseline:CTB(5K)Figure 3: Accuracy on CTB-dev regarding tomapping functions.tight mapping function that is carefully createdbased on linguistic insights, which is even inferiorto the baseline model.
The relaxed mappingfunction outperforms the tight function by largemargin.
The automatic function works slightlybetter than the relaxed one.
The complete functionachieves similar accuracy with the automatic one.In summary, we can conclude that our coupledmodel achieves much better performance whenthe mapping function becomes looser.
In otherwords, this suggests that our coupled model caneffectively learn the implicit mapping betweenheterogeneous annotations, and does not rely ona carefully designed mapping function.Since a looser mapping function leads to alarger number of bundled tags and makes themodel slower, we implement a paralleled trainingprocedure based on Algorithm 1, and run eachexperiment with five threads.
However, it stilltakes about 20 hours for one iteration when usingthe complete mapping function; whereas the otherthree mapping functions need about 6, 2, and 1hours respectively.
Therefore, as a compromise,we adopt the relaxed mapping function in the fol-9292.59393.59494.5951  31  61  91  121  151  181  211  241  271AccuracyonCTB-dev(%)Iteration NumberCTB(5K)+PD(100K)CTB(5K)+PD(20K)CTB(5K)+PD(5K)CTB(5K)+PD(1K)Baseline:CTB(5K)Figure 4: Accuracy on CTB-dev with differentweighting settings.lowing experiments, which achieves slightly loweraccuracy than the complete mapping function, butis much faster.Effect of weighting CTB and PD is investi-gated in Figure 4 and 5.
Since the scale of PDis much larger than CTB, we adopt Algorithm 1to merge the training data in a certain proportion(N ?
CTB sentences and M ?
PD sentences) ateach iteration.
We use N ?
= 5K , and varyM?= 1K/5K/20K/100K .
Figure 4 shows theaccuracy curves on CTB development data.
Wefind that when M ?
= 100K , our coupled modelachieve very low accuracy, which is even worsethan the baseline model.
The reason should be thatthe training instances in CTB are overwhelmed bythose in PD when M ?
is large.
In contrast, whenM?= 1K , the accuracy is also inferior to thecase of M ?
= 5K , which indicates that PD isnot effectively utilized in this setting.
Our modelworks best when M ?
= 5K , which is slightlybetter than the case of M ?
= 1K/20K .Figure 5 shows the accuracy curves on PDdevelopment data.
The baseline model is trainedusing 100K sentences in one iteration.
We find178893.59494.59595.59696.59797.51  31  61  91  121  151  181  211  241  271AccuracyonPD-dev(%)Iteration NumberCTB(5K)+PD(100K)CTB(5K)+PD(20K)CTB(5K)+PD(5K)CTB(5K)+PD(1K)Baseline:PD(100K)Figure 5: Accuracy on PD-dev with differentweighting settings.that when M ?
= 100K , our coupled modelachieves similar accuracy with the baseline model.When M ?
becomes smaller, our coupled modelbecomes inferior to the baseline model.
Particu-larly, when M ?
= 1K , the model converges veryslowly.
However, from the trend of the curves, weexpect that the accuracy gap between our coupledmodel with M ?
= 5K/20K and the baselinemodel should be much smaller when reachingconvergence.
Based on the above observation,we adopt N ?
= 5K and M ?
= 5K in thefollowing experiments.
Moreover, we select thebest iteration on the development data, and use thecorresponding model to parse the test data.5.2 Final ResultsTable 3 shows the final results on the CTB testdata.
We re-implement the guide-feature basedmethod of Jiang et al (2009), referred to as two-stage CRF.
Li et al (2012) jointly models ChinesePOS tagging and dependency parsing, and reportthe best tagging accuracy on CTB.
The resultsshow that our coupled model outperforms thebaseline model by large margin, and also achievesslightly higher accuracy than the guide-featurebased method.5.3 Feature StudyWe conduct more experiments to measure individ-ual contribution of each feature set, namely thejoint features based on bundled tags and separatefeatures based on single-side tags, as defined inEq.
(2).
Table 4 shows the results.
We can see thatwhen only using separate features, our coupledmodel achieves only slightly better accuracy thanthe baseline model.
This is because there isAccuracyBaseline CRF 94.10Two-stage CRF (guide-feature) 94.81 (+0.71) ?Coupled CRF 95.00 (+0.90) ?
?Best result (Li et al, 2012) 94.60Table 3: Final results on CTB test data.
?means the corresponding approach significantlyoutperforms the baseline at confidence level ofp < 10?5; whereas ?
means the accuracydifference between the two-stage CRF and thecoupled CRF is significant at confidence level ofp < 10?2.dev testBaseline CRF 94.28 94.10Coupled CRF (w/ separate feat) 94.36 94.43 (+0.33)Coupled CRF (w/ joint feat) 92.92 92.90 (-1.20)Coupled CRF (full) 95.10 95.00 (+0.90)Table 4: Accuracy on CTB: feature study.little connection and help between the two setsannotations.
When only using joint features,our coupled model becomes largely inferior tothe baseline, which is due to the data sparsenessproblem for the joint features.
However, whenthe two sets of features are combined, the coupledmodel largely outperforms the baseline model.These results indicate that both joint features andseparate features are indispensable componentsand complementary to each other for the successof our coupled model.5.4 Results on Annotation ConversionIn this subsection, we evaluate different methodson the annotation conversion task using our newlyannotated 1, 000 sentences.
The gold-standardPD-to-CTB conversionBaseline CRF 90.59Two-stage CRF (guide-feature) 93.22 (+2.63) ?Coupled CRF 93.90 (+3.31) ?
?Table 5: Conversion accuracy on our annotateddata.
?
means the corresponding approach sig-nificantly outperforms the baseline at confidencelevel of p < 10?5; whereas ?
means the accuracydifference between the two-stage CRF and thecoupled CRF is significant at confidence level ofp < 10?2.1789dev testBaseline CRF 94.28 94.10Coupled CRF 95.10 95.00 (+0.90) ?Baseline CRF + converted PD 95.01 94.81 (+0.71) ?
?Table 6: Accuracy on CTB: using converted PD.?
means the corresponding approach significantlyoutperforms the baseline at confidence level ofp < 10?5; whereas ?
means the accuracydifference between the coupled CRF and thebaseline CRF with converted PD is significant atconfidence level of p < 10?2.PD-side tags are provided, and the goal is to obtainthe CTB-side tags via annotation conversion.
Weevaluate accuracy on the 5, 769 words havingmanually annotated CTB-side tags.Our coupled model can be naturally used forannotation conversion.
The idea is to performconstrained decoding on the test data, using thePD-side tags as hard constraints.
The guide-feature based method can also perform annotationconversion by using the gold-standard PD-sidetags to compose guide features.
Table 5 showsthe results.
The accuracy is much lower thanthose in Table 3, because the 5, 769 words usedfor evaluation are 20% most ambiguous tokens inthe 1, 000 test sentence (partial annotation to saveannotation effort).
From Table 5, we can see thatour coupled model outperforms both the baselineand guide-feature based methods by large margin.5.5 Results of Training with Converted DataOne weakness of our coupled model is the in-efficiency problem due to the large bundled tagset.
In practice, we usually only need resultsfollowing one annotation style.
Therefore, weemploy our coupled model to convert PD into thestyle of CTB, and train our baseline model withtwo training data with homogeneous annotations.Again, Algorithm 1 is used to merge the twodata with N ?
= 5K and M ?
= 5K .
Theresults are shown in the bottom row in Table 6.We can see that with the extra converted data,the baseline model can achieve slightly loweraccuracy with the coupled model and avoid theinefficiency problem at the meantime.6 Related WorkThis work is partially inspired by Qiu et al (2013),who propose a model that performs heterogeneousChinese word segmentation and POS tagging andproduces two sets of results following CTB andPD styles respectively.
Different from our CRF-based coupled model, their approach adopts a lin-ear model, which directly combines two separatesets of features based on single-side tags, withoutconsidering the interacting joint features betweenthe two annotations.
They adopt an approximatedecoding algorithm which tries to find the bestsingle-side tag sequence with reference to tagsat the other side.
In contrast, our approach is adirect extension of traditional CRF, and is moretheoretically simple from the perspective of mod-elling.
The use of both joint and separate featuresis proven to be crucial for the success of ourcoupled model.
In addition, their work indicatesthat their model relies on a hand-crafted loosemapping between annotations, which is oppositeto our findings.
The naming of the ?coupled?CRF is borrowed from the work of Qiu et al(2012), which treats the joint task of Chinese wordsegmentation and POS tagging as two coupledsequence labeling problems.Zhang et al (2014) propose a shift-reduce de-pendency parsing model which can simultaneous-ly learn and produce two heterogeneous parsetrees.
However, their approach assumes the ex-istence of data with annotations at both sides,which is obtained by converting phrase-structuretrees into dependency trees with different heuristicrules.This work is also closely related with multi-task learning, which aims to jointly learn multiplerelated tasks with the benefit of using interac-tive features under a share representation (Ben-David and Schuller, 2003; Ando and Zhang, 2005;Parameswaran and Weinberger, 2010).
However,according to our knowledge, multi-task learningtypically assumes the existence of data with labelsfor multiple tasks at the same time, which isunavailable in our situation.As one reviewer kindly pointed out that ourmodel is a factorial CRF (Sutton et al, 2004), inthe sense that the bundled tags can be factorizedtwo connected latent variables.
Initially, factorialCRFs are designed to jointly model two relat-ed (and typically hierarchical) sequential labelingtasks, such as POS tagging and chunking.
In thiswork, our coupled CRF jointly models two sametasks which have different annotation schemes.Moreover, this work provides a natural way to1790learn from incomplete annotations where one sen-tence only contains one-side labels.
The revieweralso suggests that our objective can be optimizedwith the latent variable structured perceptron ofSun et al (2009), which we leave as future work.Learning with ambiguous labelings are previ-ously explored for classification (Jin and Ghahra-mani, 2002), sequence labeling (Dredze et al,2009), parsing (Riezler et al, 2002; Ta?ckstro?met al, 2013; Li et al, 2014a; Li et al, 2014b).Recently, researchers derive natural annotationsfrom web data, transform them into ambiguouslabelings to supervise Chinese word segmentationmodels (Jiang et al, 2013; Liu et al, 2014; Yangand Vozila, 2014).7 ConclusionsThis paper proposes an effective coupledsequence labeling model for exploiting multiplenon-overlapping datasets with heterogeneousannotations.
Please note that our model can alsobe naturally trained on datasets with both-sideannotations if such data exists.
Experimentalresults demonstrate that our model work betterthan the baseline and guide-feature based methodson both one-side POS tagging and annotationconversion.
Specifically, detailed analysisshows several interesting findings.
First, boththe separate features and joint features areindispensable components for the success of ourcoupled model.
Second, our coupled model doesnot rely on a carefully hand-crafted mappingfunction.
Our linguistically motivated mappingfunction is only used to reduce the size of thebundled tag set for the sake of efficiency.
Finally,using the extra training data converted withour coupled model, the baseline tagging modelachieves similar accuracy improvement.
In thisway, we can avoid the inefficiency problem of ourcoupled model in real application.For future, our immediate plan is to annotatemore data with both CTB and PD tags (a few t-housand sentences), and to investigate our coupledmodel with small amount of such annotation asextra training data.
Meanwhile, Algorithm 1 isempirically effective in merging two training data,but still needs manual tuning of the weightingfactor on held-out data.
Thus, we would liketo find a more principled and theoretically soundmethod to merge multiple training data.AcknowledgmentsThe authors would like to thank the undergraduatestudents Fangli Lu and Xiaojing Wang for buildingour annotation system, and Le Lu, Die Hu, YueZhang, Jian Zhang, Qiuyi Yan, Xinzhou Jiangfor data annotation.
We are also grateful that YuDing kindly shared her earlier codes on which ourannotation system was built.
We also thank thehelpful comments from our anonymous reviewers.This work was supported by National Natural Sci-ence Foundation of China (Grant No.
61432013,61203314) and Jiangsu Planned Projects for Post-doctoral Research Funds (No.
1401075B), andwas also partially supported by Collaborative In-novation Center of Novel Software Technologyand Industrialization of Jiangsu Province.ReferencesRie Kubota Ando and Tong Zhang.
2005.
Aframework for learning predictive structures frommultiple tasks and unlabeled data.
Journal ofMachine Learn Research, 6:1817?1853.Shai Ben-David and Reba Schuller.
2003.
Exploitingtask relatedness for multiple task learning.
In COLT.Mark Dredze, Partha Pratim Talukdar, and KobyCrammer.
2009.
Sequence learning from datawith multiple labels.
In ECML/PKDD Workshop onLearning from Multi-Label Data.Zhongqiang Huang, Vladimir Eidelman, and MaryHarper.
2009.
Improving a simple bigram hmmpart-of-speech tagger by latent annotation and self-training.
In Proceedings of NAACL, pages 213?216.Wenbin Jiang, Liang Huang, and Qun Liu.
2009.
Au-tomatic adaptation of annotation standards: Chineseword segmentation and POS tagging ?
a case study.In Proceedings of ACL, pages 522?530.Wenbin Jiang, Meng Sun, Yajuan Lu?, Yating Yang,and Qun Liu.
2013.
Discriminative learning withnatural annotations: Word segmentation as a casestudy.
In Proceedings of ACL, pages 761?769.Rong Jin and Zoubin Ghahramani.
2002.
Learningwith multiple labels.
In Proceedings of NIPS.John Lafferty, Andrew McCallum, and FernandoPereira.
2001.
Conditional random fields:Probabilistic models for segmenting and labelingsequence data.
In Proceedings of ICML 2001, pages282?289.Zhenghua Li, Min Zhang, Wanxiang Che, and TingLiu.
2012.
A separately passive-aggressive trainingalgorithm for joint POS tagging and dependencyparsing.
In COLING, pages 1681?1698.1791Zhenghua Li, Min Zhang, and Wenliang Chen.2014a.
Ambiguity-aware ensemble training forsemi-supervised dependency parsing.
In ACL, pages457?467.Zhenghua Li, Min Zhang, and Wenliang Chen.
2014b.Soft cross-lingual syntax projection for dependencyparsing.
In COLING, pages 783?793.Yijia Liu, Yue Zhang, Wanxiang Che, Ting Liu, andFan Wu.
2014.
Domain adaptation for CRF-basedChinese word segmentation using free annotations.In Proceedings of EMNLP, pages 864?874.Joakim Nivre and Ryan McDonald.
2008.
Integrat-ing graph-based and transition-based dependencyparsers.
In Proceedings of ACL, pages 950?958.Eric W. Noreen.
1989.
Computer-intensive methodsfor testing hypotheses: An introduction.
John Wiley& Sons, Inc., New York.S.
Parameswaran and K.Q.
Weinberger.
2010.
Largemargin multi-task metric learning.
In J. Lafferty,C.
K. I. Williams, J. Shawe-Taylor, R.S.
Zemel, andA.
Culotta, editors, Advances in Neural InformationProcessing Systems 23, pages 1867?1875.Ciyang Qing, Ulle Endriss, Raquel Fernandez, andJustin Kruger.
2014.
Empirical analysis ofaggregation methods for collective annotation.
InCOLING, pages 1533?1542.Xipeng Qiu, Feng Ji, Jiayi Zhao, and Xuanjing Huang.2012.
Joint segmentation and tagging with coupledsequences labeling.
In Proceedings of COLING2012: Posters, pages 951?964, Mumbai, India.Xipeng Qiu, Jiayi Zhao, and Xuanjing Huang.
2013.Joint Chinese word segmentation and POS taggingon heterogeneous annotated corpora with multipletask learning.
In Proceedings of EMNLP, pages658?668.Stefan Riezler, Tracy H. King, Ronald M. Kaplan,Richard Crouch, John T. III Maxwell, and MarkJohnson.
2002.
Parsing the wall street journal usinga lexical-functional grammar and discriminativeestimation techniques.
In Proceedings of ACL,pages 271?278.Anders S?gaard.
2011.
Semi-supervised condensednearest neighbor for part-of-speech tagging.
InProceedings of ACL, pages 48?52.Weiwei Sun and Hans Uszkoreit.
2012.
Capturingparadigmatic and syntagmatic lexical relations:Towards accurate Chinese part-of-speech tagging.In Proceedings of ACL, pages 242?252.Weiwei Sun and Xiaojun Wan.
2012.
Reducingapproximation and estimation errors for Chineselexical processing with heterogeneous annotations.In Proceedings of ACL, pages 232?241.Xu Sun, Takuya Matsuzaki, Daisuke Okanohara,and Jun?ichi Tsujii.
2009.
Latent variableperceptron algorithm for structured classification.In Proceedings of the 21st International JointConference on Artificial Intelligence (IJCAI 2009),pages 1236?1242.Charles Sutton, Khashayar Rohanimanesh, and An-drew McCallum.
2004.
Dynamic conditionalrandom fields: Factorized probabilistic modelsfor labeling and segmenting sequence data.
InInternational Conference on Machine Learning(ICML).Oscar Ta?ckstro?m, Ryan McDonald, and Joakim Nivre.2013.
Target language adaptation of discriminativetransfer parsers.
In Proceedings of NAACL, pages1061?1071.Fei Xia.
2000.
The part-of-speech tagging guidelinesfor the penn Chinese treebank 3.0.
In TechnicalReport, Linguistic Data Consortium.Nianwen Xue, Fei Xia, Fu-Dong Chiou, and MarthaPalmer.
2005.
The Penn Chinese Treebank: Phrasestructure annotation of a large corpus.
In NaturalLanguage Engineering, volume 11, pages 207?238.Fan Yang and Paul Vozila.
2014.
Semi-supervisedChinese word segmentation using partial-labellearning with conditional random fields.
InProceedings of EMNLP, pages 90?98.Yue Zhang and Stephen Clark.
2008.
Joint wordsegmentation and POS tagging using a singleperceptron.
In Proceedings of ACL-08: HLT, pages888?896.Meishan Zhang, Wanxiang Che, Yanqiu Shao, andTing Liu.
2014.
Jointly or separately: Which isbetter for parsing heterogeneous dependencies?
InProceedings of COLING, pages 530?540.1792
