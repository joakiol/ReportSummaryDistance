Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 271?280,Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational LinguisticsGenerating English Determiners in Phrase-Based Translation withSynthetic Translation OptionsYulia Tsvetkov Chris Dyer Lori Levin Archna BhatiaLanguage Technologies InstituteCarnegie Mellon UniversityPittspurgh, PA, 15213, USA{ytsvetko, cdyer, lsl, archna}@cs.cmu.eduAbstractWe propose a technique for improvingthe quality of phrase-based translationsystems by creating synthetic translationoptions?phrasal translations that are gen-erated by auxiliary translation and post-editing processes?to augment the de-fault phrase inventory learned from par-allel data.
We apply our technique tothe problem of producing English deter-miners when translating from Russian andCzech, languages that lack definitenessmorphemes.
Our approach augments theEnglish side of the phrase table using aclassifier to predict where English arti-cles might plausibly be added or removed,and then we decode as usual.
Doingso, we obtain significant improvements inquality relative to a standard phrase-basedbaseline and to a to post-editing completetranslations with the classifier.1 IntroductionPhrase-based translation works as follows.
A setof candidate translations for an input sentence iscreated by matching contiguous spans of the in-put against an inventory of phrasal translations,reordering them into a target-language appropri-ate order, and choosing the best one according to adiscriminative model that combines features of thephrases used, reordering patterns, and target lan-guage model (Koehn et al 2003).
This relativelysimple approach to translation can be remarkablyeffective, and, since its introduction, it has beenthe basis for further innovations, including devel-oping better models for distinguishing the goodtranslations from bad ones (Chiang, 2012; Gim-pel and Smith, 2012; Cherry and Foster, 2012;Eidelman et al 2013), improving the identifica-tion of phrase pairs in parallel data (DeNero et al2008; DeNero and Klein, 2010), and formal gen-eralizations to gapped rules and rich nonterminaltypes (Chiang, 2007; Galley et al 2006).
Thispaper proposes a different mechanism for improv-ing phrase-based translation: the use of synthetictranslation options to supplement the standardphrasal inventory used in phrase-based translationsystems.In the following, we argue that phrase tables ac-quired in usual way will be expected to have gapsin their coverage in certain language pairs andthat supplementing these with synthetic translationoptions is a priori preferable to alternative tech-niques, such as post processing, for generalizingbeyond the translation pairs observable in trainingdata (?2).
As a case study, we consider the prob-lem of producing English definite/indefinite arti-cles (the, a, and an) when translating from Russianand Czech, two languages that lack overt definite-ness morphemes (?3).
We develop a classifier thatpredicts the presence and absence of English arti-cles (?4).
This classifier is used to generate syn-thetic translation options that are used to augmentphrase tables used the usual way (?5).
We eval-uate their performance relative to post-processingapproach and to a baseline phrase-based system,finding that synthetic translation options reliablyoutperform the other approaches (?6).
We thendiscuss how our approach relates to previous work(?7) and conclude by discussing further applica-tions of our technique (?8).2 Why Synthetic Translation Options?Before turning to the problem of generating En-glish articles, we give arguments for why syn-thetic translation options are a useful extension of271standard phrase-based translation approaches, andwhy this technique might be better than some al-ternative proposals that been made for generaliz-ing beyond translation examples directly observ-able in the training data.In language pairs that are typologically sim-ilar (i.e., when both languages lexicalize thesame kinds of semantic and syntactic informa-tion), words and phrases map relatively directlyfrom source to target languages, and the standardapproach to learning phrase pairs is quite effec-tive.1 However, in language pairs in which in-dividual source language words have many dif-ferent possible translations (e.g., when the targetlanguage word could have many different inflec-tions or could be surrounded by different func-tion words that have no direct correspondence inthe source language), we can expect the standardphrasal inventory to be incomplete, except whenvery large quantities of parallel data are availableor for very frequent words.
There simply will notbe enough examples from which to learn the idealset of translation options.
Therefore, since phrasebased translation can only generate input/outputword pairs that were directly observed in the train-ing corpus, the decoder?s only hope for produc-ing a good output is to find a fluent, meaning-preserving translation using incomplete transla-tion lexicons.
Synthetic translation option genera-tion seeks to fill these gaps using secondary gener-ation processes that produce possible phrase trans-lation alternatives that are not directly extractablefrom the training data.
We hypothesize that byfilling in gaps in the translation options, discrim-inative translation models will be more effective(leading to better translation quality).The creation of synthetic translation options canbe understood as a kind of translation or post-editing of phrasal units/translations.
This raisesa question: if we have the ability to post-edit aphrasal translation or retranslate a source phraseso as to fill in gaps in the phrasal inventory, weshould be able to use the same technique to trans-late the sentence; why not do this?
While the ef-fectiveness of this approach will ultimately be as-sessed empirically, translation option generation isappealing because the translation option synthe-sizer need not produce only single-best guesses?1When translating from a language with a richer lexicalinventory to a simpler one, approximate matching or backingoff to (e.g.)
morphologically simpler forms likewise reliablyproduces good translations.???????????
?saw +1SG +PST cat+ACC1SG+NOMIsawsaw asaw thecatathe catcatsaw the catsaw a catI sawI saw aI saw theFigure 1: Russian-English phrase-based transla-tion example.
Since Russian lacks a definitenessmorpheme the determiners a, the must be part ofa translation option containing ??????
or ????
?in order to be present in the right place in the En-glish output.
Translation options that are in dashedboxes should exist but were not observed in thetraining data.
This work seeks to produce suchmissing translation options synthetically.if multiple possibilities appear to be equally good(say, multiple inflections of a translated lemma),then multiple translation options may be synthe-sized.
Ultimately, of course, the global translationmodel must select one translation for every phraseit uses, but the decoder will have access to globalinformation that it can use to pick better transla-tion options.3 Case Study: English Definite ArticlesWe now turn to a translation problem that we willuse to assess the value of synthetic translation op-tions: generating English in/definite articles whentranslating from Russian.Definiteness is a semantic property of nounphrases that expresses information such as iden-tifiability, specificity, familiarity and unique-ness (Lyons, 1999).
In English, it is expressedthrough the use of article determiners and non-article determiners.
Although languages may ex-press definiteness through such morphemes, manylanguages use alternative mechanisms.
For exam-ple they may use noncanonical word orders (Mo-hanan, 1994)2 or different constructions such asexistentials, differential object marking (Aissen,2003), and the ba (?)
construction in Chinese2See pp.
11?12 for an example in Hindi, a language with-out articles.272(Chen, 2004).
While these languages lack arti-cles, they may use demonstratives and the quan-tifier one to emphasize definiteness and indefinite-ness, respectively.Russian and Czech are examples of languagesthat use non-lexical means to express definiteness.As such, in Russian to English translation systems,we expect that most Russian nouns should have atleast three translation options?the bare noun, thenoun preceded by the, and the noun preceded a/an.Fig.
1 illustrates how the definiteness mismatchbetween Russian and English can result in ?gaps?in the phrasal inventory learned from a relativelylarge parallel corpus.
The Russian input shouldtranslate (depending on context) as either I saw acat or I saw the cat; however, the phrase table welearned is only able to generate the former.34 Predicting English Definite ArticlesAlthough English articles express semantic con-tent, their use is largely predictable in context,both for native English speakers and for automatedsystems (Knight and Chander, 1994).4 In this sec-tion we describe a classifier that uses local contex-tual features to predict whether an article belongsin a particular position in a sequence of words, andif so, whether it is definite or indefinite (the formof the indefinite article is deterministic given thepronunciation of the following word).4.1 ModelThe classifier takes an English word sequence w =?w1, w2, .
.
.
, w|w|?with missing articles and an in-dex i and predicts whether no article, a definite ar-ticle, or an indefinite article should appear beforewi.
We parameterize the classifier as a multiclass3The phrase table for this example was extracted from theWMT 2013 shared task training data consisting of 1.2M sen-tence pairs.4An interesting contribution of this work is a discussionon lower and upper bounds that can be achieved by nativeEnglish speakers in predicting determiners.
67% is a lowerbound, obtained by guessing the for every instance.
The up-per bound was obtained experimentally, and was measured onnoun phrases (NP) without context, in a context of 4 words(2 before and 2 after NP), and given full context.
Humansubjects achieved an accuracy of 94-96% given full context,83-88% for NPs in a context of 4 words, and 79-80% for NPswithout context.
Since in the current state-of-the-art buildingan automated determiners prediction in a full context (repre-senting meaning computationally) is not a feasible task, weview 83-88% accuracy as our goal, and 88% as an upperbound for our method.logistic regression:p(y | w, i) ?
exp?j?jhj(y,w, i),where hj(?)
are feature functions, ?j are the corre-sponding weights, and y ?
{D,I,N} refer, respec-tively, to the outputs: definite article, indefinite ar-ticle, and no article.54.2 FeaturesThe English article system is extremely com-plex (as non-native English speakers will surelyknow!
): in addition to a general placement rulethat articles must precede a noun or its modifiersin an NP, multiple other factors can also affect ar-ticle selection, including countability of the headnoun, syntactic properties of an adjective modi-fying a noun (superlative, ordinal), discourse fac-tors, general knowledge, etc.
In this section, wedefine morphosyntactic features aimed at reflect-ing basic grammatical rules, we define statistical,semantic and shallow lexical features to captureadditional regular and idiosyncratic usages of def-inite and indefinite articles in English.
Below weprovide brief details of the features and their mo-tivation.Lexical.
Because training data can be con-structed inexpensively (from any unannotated En-glish corpus), n-gram indicator features, such as[[wi?1ywiwi+1 = with y lot of]], can be es-timated reliably and capture construction-specificarticle use.Morphosyntactic.
We used part-of-speech(POS) tags produced by the Stanford POS tagger(Toutanova and Manning, 2000) to capture gen-eral article patterns.
These are relevant featuresin the prediction of articles as we observe certainconstraints regarding the use of articles in theneighborhood of certain POS tags.
For example,we do not expect to predict an article following anadjective (JJ).Semantic.
We extract further information indi-cating whether a named entity, as identified by theStanford NE Recognizer (Finkel et al 2005) be-gins at wi.
These features are relevant as there5Realization of the classes D and N as lexical items isstraightforward.
To convert I into a or an, we use theCMU pronouncing dictionary (http://www.speech.cs.cmu.edu/cgi-bin/cmudict) and select an if wistarts with a phonetic vowel.273is, in general, a constraint on the co-occurrenceof articles with named entities which can help uspredict the use of articles in such constructions.For example, proper nouns do not tend to co-occur with articles in English.
Although there aresome proper nouns that have an article included inthem, such as the Netherlands, the United Statesof America, but these are fixed expressions and themodel is easily able to capture such cases with lex-ical features.Statistical.
Statistical features capture probabil-ity of co-occurrences of a sample with each ofthe determiner classes, e.g., for wi?1ywi wecollect probabilities of wi?1Iwi, wi?1Dwi, andwi?1Nwi.64.3 Training and evaluationWe employ the creg regression modeling frame-work to train a ternary logistic regression classi-fier.7 All features were computed for the target-side of the Russian-English TED corpus (Cettoloet al 2012); from 117,527 sentences we removed5K sentences used as tuning and test sets in theMT system.
We extract statistical features frommonolingual English corpora released for WMT-11 (Callison-Burch et al 2011).In the training corpus there are 65,075 I in-stances, 114,571 D instances, and 2,435,287 N in-stances.
To create a balanced training set werandomly sample 65K instances from each set ofcollected instances.8 This training set of featurevectors has 142,604 features and 285,210 param-eters.
To minimize the number of free parame-ters in our model we use `1 regularization.
Weperform 10-fold cross validation experiments withvarious feature combinations, evaluating the clas-sifier accuracy for all classes and for each classindependently.
The performance of the classifieron individual classes and consolidated results forall classes are listed in Table 1.We observe that morphosyntactic and lexicalfeatures are highly significant, reducing the er-ror rate of statistical features by 25%.
A combi-6Although statistical features are de rigeur in NLP, theyare arguably justified for this problem on linguistic groundssince human subjects use frequency-based in addition to theirgrammatical knowledge.
For example, we say He is at schoolrather than He is at the school, but Americans say He is inthe hospital while UK English speakers might prefer He is inhospital.7https://github.com/redpony/creg8Preliminary experiments indicated that the excess of Nlabels resulted in poor performance.Feature combination All I D NStatistical 0.80 0.76 0.79 0.87Lexical 0.82 0.79 0.80 0.87Morphosyntactic 0.75 0.71 0.64 0.86Semantic 0.35 0.99 0.02 0.04Statistical+Lexical 0.85 0.83 0.82 0.89+ Morphosyntactic 0.87 0.86 0.83 0.92+ Semantic 0.87 0.86 0.83 0.92Table 1: 10-fold cross validation accuracy of theclassifier over all and by class.nation of morphosyntactic, lexical, and statisticalfeatures is also helpful, reducing 13% more errors.Semantic features do not contribute to the classi-fier accuracy (we believe, mainly due to the featuresparsity).5 Experimental SetupOur experimental workflow includes the follow-ing steps.
First, we select a phrase table PTsourcefrom which we generate synthetic phrases.
Foreach phrase pair ?f, e?
in PTsource we generate nsynthetic variants of the target side phrase e whichwe then append to PTbaseline.
We annotate boththe original and synthetic phrases with additionaltranslation features in PTbaseline.For this language pair, we have several optionsfor how to construct PTsource.
The most straight-forward way is to extract the phrasal inventory asusual; a second option is to extract phrases fromtraining data from which definite articles havebeen removed (since we will rely on the classifierto reinsert them where they belong).To synthesize phrases, we employ two differ-ent techniques: LM-based and classifier-based.We use a LM for one- or two-word phrases oran auxiliary classifier for longer phrases and cre-ate a new phrase in which we insert, remove orsubstitute an article between each adjacent pair ofwords in the original phrase.
Such distinction be-tween short and longer phrases has clear motiva-tion: phrases without context may allow alterna-tive, equally plausible options for article selection,therefore we can just rely on a LM, trained onlarge monolingual corpora, to identify phrases un-observed in MT training corpus.
Longer contextrestricts determiners usage and statistical modeldecisions are less prone to generating ungrammat-ical synthetic phrases.LM-based method is applied to phrases shorterthan three words.
These phrases are numerous,roughly 20% of a phrase table, and extracted from274many sites in the training data.
For each short (tar-get) phrase we add all possible alternative entriesobserved in the LM and not observed in the orig-inal translation model.
For example, for a shorttarget phrase a cat we extract the cat.We apply an auxiliary classifier to longerphrases, containing three or more words.
Basedon the classifier prediction, we use the maximallyprobable class to insert, remove or substitute anarticle between each adjacent pair of words inthe original phrase.
Synthetic phrases are gener-ated by linguistically-informed features and canintroduce alternative grammatically-correct trans-lations of source phrases by adding or removingexisting articles (since the English article selectionin a local context is often ambiguous and not cat-egorical).
We add a synthetic phrase only if thephrase pair not observed in the original model.We compare two possible applications of a clas-sifier: one-pass and iterative prediction.
Withone-pass prediction we decide on the predictionfor each position independently of other deci-sions.
With iterative update we adopt the bestfirst (greedy) strategy, selecting in each iterationthe update-location in which the classifier obtainshighest confidence score.
In each iteration we in-corporate a prediction in a target phrase, and in thenext iteration the best first decision is made on anupdated phrase.
Iterative prediction stops when noupdates are introduced.Synthetic phrases are added to a phrase tablewith the five standard phrasal translation featuresthat were found in the source phrase, and with sev-eral new features.
First, we add a boolean fea-ture indicating the origin of a phrase: synthetic ororiginal.
Second, we experiment with a posteriorprobability of a classifier averaged over all loca-tions where it could be extracted from the trainingdata.
The next feature is derived from this score:it is a boolean feature indicating a confidence ofthe classifier: the feature value is 1 iff the averageclassifier score is higher than some threshold.Consider again a phrase I saw a cat discussedin Section 1.
Synthetic entry generation from theoriginal phrase table entry is illustrated in Fig-ure 2.6 Translation ResultsWe now review the results of experiments usingsynthetic translation options in a machine trans-lation system.
We use the Moses toolkit (Koehnet al 2007) to train a baseline phrase-based SMTsystem.
Each configuration we compare has a dif-ferent phrase table, with synthetic phrases gen-erated with best-first or iterative strategies, froma phrase table with- or without-determiners, withvariable number of translation features.
To verifythat system improvement is consistent, and is not aresult of optimizer instability (Clark et al 2011),we replicate each experimental setup three times,and then estimate the translation quality of the me-dian MT system using the MultEval toolkit.9The corpus is the same as in Section 4.3:the training part contains 112,527 sentences fromRussian-English TED corpus, randomly sampled3K sentences are used for tuning and a disjoint setof 2K sentences is used for test.
We lowercaseboth sides, and use Stanford CoreNLP10 tools totokenize the corpora.
We employ SRILM toolkit(Stolcke, 2002) to linearly interpolate the targetside of the training corpus with the WMT En-glish corpus, optimizing towards the MT tuningset.
This LM is used in all experiments.The rest of this section is organized as follows.First, we compare two approaches to the deter-miners classifier application.
Then, we providedetailed description of experiments with syntheticphrases.
We evaluate various aspects of syntheticphrases generation and summarize all the resultsin Table 3.
In Table 5 we show examples of im-proved translations.Classifier application: one-pass vs. iterative.First, as an intrinsic evaluation of the predictionstrategy we remove definite and indefinite articlesfrom the reference translations (2K test sentences)and then employ the determiners classifier to re-produce the original sentences.
In Table 2 we re-port on the word error rate (WER) derived fromthe Levenshtein distance between the original sen-tences and the sentences (1) without articles, (2)with articles recovered using one-pass prediction,and (3) articles recovered using iterative predic-tion.
The WER is averaged over all test sentences.Both one-pass and iterative approaches are effec-tive in the task of determiners prediction, reducingthe number of errors by 44%.
The iterative ap-proach yields slightly lower WER, hence we em-ploy the iterative prediction in the future experi-ments with synthetic phrases.9https://github.com/jhclark/multeval10http://nlp.stanford.edu/software/corenlp.shtml275the?
??????
?????
||| i saw the cat ||| f0 f1 f2 f3 f4 exp(1) exp(0) |||<s>      I      saw   a   cat </s>NoneNone?
??????
?????
||| i saw a cat ||| f0 f1 f2 f3 f4 exp(0) exp(0) |||original phrasepost-processingsynthetic phraseis syntheticis no-contextFigure 2: Synthetic entry generation example.
The original parallel phrase has two additional booleanfeatures (set to false) indicating that this is not a synthetic phrase and not a short phrase.
We applyour determiners classifier to predict an article at each location marked with a dashed box.
Based on aclassifier prediction we derive a new phrase I saw the cat.
Since corresponding parallel entry is not inthe original phrase table, we set the synthetic indicator feature to 1.Post-processing WERNone 5.6%One-pass 3.2%Iterative 3.1%Table 2: WER (lower is better) of reference trans-lations without articles and of post-processed ref-erence translations.
Both one-pass and iterativeapproaches are effective in the task of determin-ers prediction.MT output post-processing.
We then evaluatethe post-processing strategy directly on the MToutput.
We experiment with one-pass and itera-tive post-processing of two variants of the base-line system outputs: original output and the out-put without articles (we remove the articles priorto post-processing).
The results are listed in Ta-ble 3.
Interestingly, we do not obtain any improve-ments applying the determiners classifier in a con-ventional way of a MT output post-processing.
Itis the combination of linguistically-motivated fea-tures with synthetic phrases that contribute to thebest performance.LM-based synthetic phrases.
As discussedabove, LM-based (short) phrases are shorter than3 tokens and their synthetic variants contain samewords with articles inserted or deleted betweeneach adjacent pair of words.
The phrase tableof the baseline system contains 2,441,678 phrasepairs.
There are 518,453 original short phrases,and our technique yields 842,252 new syntheticentries which we append to the baseline phrase ta-ble.
Table 3 shows the evaluation of the medianSMT system (derived from three systems) withshort phrases.
In these systems the five phrasaltranslation features are the same as in the base-line systems.
Improvement in the BLEU score(Papineni et al 2002) is statistically significant(p < .05), compared to the baseline systemClassifier-generated synthetic phrases We ap-ply classifier with the iterative prediction directlyon the baseline phrase table entries and synthe-size 944,145 new parallel phrases, increasing thephrase table size by 38%.
The phrasal transla-tion features in each synthetic phrase are the sameas in the phrase it was derived from.
The BLEUscore of the median SMT system with syntheticphrases is 22.9 ?
.1, the improvement is statisti-cally significant (p < .01).
Post-processing of aphrase table created from corpora without articlesand adding synthetic phrases to the baseline phrasetable yielded similar results.Translation features for synthetic phrases Inthe following experiments we aim to establish theoptimal set of translation features that should beused with synthetic phrases.
We train several SMTsystems, each containing synthetic phrases derivedfrom the original phrase table by iterative classifi-cation, and with LM-based short phrases.
Eachsynthetic phrase has five translation features as anoriginal phrase it was derived from.
The additionalfeatures that we evaluate are:1.
Boolean feature for LM-based syntheticphrases276MT System BLEUBaseline 22.6?
.1MT output post-processingone-pass, MT output with articles 20.8one-pass, MT output without articles 19.7iterative, MT output with articles 22.6iterative, MT output without articles 21.8With synthetic phrasesLM-based phrases 22.9?
.1+ classifier-generated phrases 22.9?
.1+ features 1,2 23.0 ?
.1+ features 1,2,3 22.8?
.1+ features 1,2,3,4 22.8?
.1+ feature 5 22.9?
.1Table 3: Summary of experiments with MT out-put post-processing and with synthetic translationoptions in a phrase table.
Post-processing of theMT output do not improve translations.
Best per-forming system with synthetic phrases has fiveoriginal phrase translation features and two addi-tional boolean features indicating if the phrase isLM-based or not, is classifier-generated or not.
Allthe synthetic systems are significantly better thanthe baseline system.2.
Boolean feature for classifier-generated syn-thetic phrases3.
Classifier confidence: posterior probability ofthe classifier averaged over all samples in a tar-get phrase.4.
Boolean feature indicating a confidence of theclassifier: the feature value is 1 iff the Fea-ture 3 scores higher than some threshold.
Thethreshold was set to 0.8, we did not experimentwith other values.5.
Boolean feature for a synthetic phrase of anytype: LM-based or classifier-generatedTable 3 details the change in the BLEU scoreof each experimental setup.
The best perform-ing system has five original phrase translation fea-tures and two additional boolean features indicat-ing if the phrase is LM-based or not, is classifier-generated or not.
Note that all the synthetic sys-tems are significantly better than the baseline.Czech-English.
Our technique was developedusing Russian-English system in the TED domain,so we want to see how our method generalizes to adifferent domain when translating from a differentlanguage.
We therefore applied our most success-ful configuration to a Czech-English news transla-tion task.11 For training, we use the WMT Czech-English parallel corpus CzEng0.7; we tune usingthe WMT2011 test set and test on the WMT2012test set.
The LM is trained on the target side of thetraining corpus.
Determiners classifier, re-trainedon the English side of this corpus, with statistical,lexical, morphosyntactic and dependency featuresobtained an accuracy of 88%.In Table 4, we report the results of evaluat-ing the performance of the Russian-to-Englishand Czech-to-English MT systems with syntheticphrases.
The results of both systems show a statis-tically significant (p < .01) improvement in termsof BLEU score.Russian CzechBaseline 22.6?
.1 16.0?
.05Synthetic 23.0?
.1 16.2?
.03Table 4: BLEU score of Russian-to-Englishand Czech-to-English MT systems with syntheticphrases and features 1 and 2 show a significant im-provement.Qualitative analysis.
Table 5 shows some ex-amples from the output of our Russian-to-Englishsystems.
Although both systems produce compre-hensible translations, the system augmented withdeterminer classifier is more fluent.
The first ex-ample represents a case where a singular countnoun (piece) is present which requires an article.The baseline is not able to identify this require-ment and hence does not insert the article an be-fore the phrase extraordinary engineering piece.Our system, however, correctly identifies the con-struction requiring an article and thus provides anappropriate form of the article (an- Indefinite arti-cle for lexical items beginning with a vowel).
Thuswe see that our system is able to capture the lin-guistic requirement of the singular count nouns toco-occur with an article.
In the second row, thelexical item poor is used as an adjective.
The base-line has inserted an article in front of it, chang-ing it to a noun.
Our system, however, is able tomaintain the status of poor as an adjective sinceit has the option not to insert an article.
Thus wesee that besides fluency, our system also does bet-ter in maintaining the grammatical category of alexical item.
In the third row, the phrase three11Like Russian, Czech is a Slavic language that does nothave definite or indefinite articles.277Source: ??
???
??
?????
, ???
??????????
????????????
???????????
?????????
.Reference: but nonetheless , it ?s an extraordinary piece of engineering .Baseline: but nevertheless , it ?s extraordinary engineering piece of art .Ours: but nevertheless , it ?s an extraordinary piece of engineering art .Source: ?
??
??????
??????????
???
???
??
??????
.Reference: and by many definitions she is no longer poor .Baseline: and in a lot definitions , it ?s not a poor .Ours: and in a lot definitions she ?s not poor .Source: ???
?????
?????????
???
?????????
?????????
???????
.Reference: we must feed three billion people in cities .Baseline: we need to feed the three billion urban hundreds of them .Ours: we need to feed three billion people in the city .Table 5: Examples of translations with improved articles handling.billion people refers to a nonidentifiable referent.The baseline inserts the definite article the.
If ahuman subject reads this translation, it would mis-lead him/her to interpret the object three billionpeople as referring to a specific identifiable set.Our system, on the other hand, correctly selectsthe determiner class N and hence does not insert anarticle.
Thus we see that our system does not justadd fluency but it also captures a semantic distinc-tion, namely identifiability, that a human subjectmakes when producing or interpreting a phrase.7 Related WorkAutomated determiner prediction has been foundbeneficial in a variety of applications, includingpostediting of MT output (Knight and Chander,1994), text generation (Elhadad, 1993; Minnenet al 2000), and more recently identification andcorrection of ESL errors (Han et al 2006; De Fe-lice and Pulman, 2008; Gamon et al 2009; Ro-zovskaya and Roth, 2010).
Our work on determin-ers extends previous studies in several dimensions.While all previous approaches were tested only onNP constructions, we evaluate our classifier on anysequence of tokens.To the best of our knowledge, the only stud-ies that directly address generation of syntheticphrase table entries was conducted by Chen et al(2011) and Koehn and Hoang (2007).
The formerfind semantically similar source phrases and pro-duce ?fabricated?
translations by combining thesesource phrases with a set of their target phrases;however, they do not observe improvements.
Thelater work integrates the synthesis of translationoptions into the decoder.
While related in spirit,their method only supports a limited set of gen-erative processes for producing the candidate set(lacking, for instance, the simple and effectivephrase post-editing process we have used), andtheir implementation has been plagued by compu-tational challenges.Post-processing techniques have been ex-tremely popular.
These can be understood as usinga translation model to generate a translation skele-ton (or k-best skeletons) and then post-editingthese in various ways.
These have been appliedto translation into morphologically rich languages,such as Japanese, German, Turkish, and Finnish(de Gispert et al 2005; Suzuki and Toutanova,2006; Suzuki and Toutanova, 2007; Fraser et al2012; Clifton and Sarkar, 2011; Oflazer and Dur-gar El-Kahlout, 2007).8 Conclusions and future workThe contribution of this work is twofold.
First, wepropose a new supervised method to predict defi-nite and indefinite articles.
Our log-linear modeltrained on a linguistically-motivated set of fea-tures outperforms previously reported results, andobtains an upper bound of an accuracy achievedby human subjects given a context of four words.However, more important result of this work is theexperimentally verified idea of improving phrase-based SMT via synthetic phrases.
While we havefocused on a limited problem in this paper, thereare numerous alternative applications includingtranslation into morphologically rich languages, asa method for incorporating (source) contextual in-formation in making local translation decisions,enriching the target language lexicon using lexicaltranslation resources, and many others.AcknowledgmentsWe are grateful to Shuly Wintner for insightful sugges-tions and support.
This work was supported in part by theU.
S. Army Research Laboratory and the U. S. Army Re-search Office under contract/grant number W911NF-10-1-0533.278ReferencesJ.
Aissen.
2003.
Differential object marking: Iconic-ity vs. economy.
Natural Language and LinguisticTheory, 21(3):435?483.C.
Callison-Burch, P. Koehn, C. Monz, and O. Zaidan.2011.
Findings of the 2011 workshop on statisti-cal machine translation.
In Proceedings of the SixthWorkshop on Statistical Machine Translation, pages22?64, Edinburgh, Scotland, July.
Association forComputational Linguistics.M.
Cettolo, C. Girardi, and M. Federico.
2012.
WIT3:Web inventory of transcribed and translated talks.
InProceedings of the 16th Conference of the EuropeanAssociation for Machine Translation (EAMT), pages261?268, Trento, Italy, May.B.
Chen, R. Kuhn, and G. Foster.
2011.
Semanticsmoothing and fabrication of phrase pairs for SMT.In Proceedings of the International Workshop onSpoken Lanuage Translation (IWSLT-2011).P.
Chen.
2004.
Identifiability and definiteness in chi-nese.
Linguistics, 42(6):1129?1184.C.
Cherry and G. Foster.
2012.
Batch tuning strategiesfor statistical machine translation.
In Proceedings ofHLT-NAACL 2012, volume 12, pages 34?35.D.
Chiang.
2007.
Hierarchical phrase-based transla-tion.
Computational Linguistics, 33(2):201?228.D.
Chiang.
2012.
Hope and fear for discriminativetraining of statistical translation models.
The Jour-nal of Machine Learning Research, 98888:1159?1187.J.
H. Clark, C. Dyer, A. Lavie, and N. A. Smith.2011.
Better hypothesis testing for statistical ma-chine translation: Controlling for optimizer instabil-ity.
In In Proc.
of ACL.A.
Clifton and A. Sarkar.
2011.
Combiningmorpheme-based machine translation with post-processing morpheme prediction.
In Proceedings ofACL.R.
De Felice and S. G. Pulman.
2008.
A classifier-based approach to preposition and determiner errorcorrection in L2 English.
In Proceedings of the22nd International Conference on ComputationalLinguistics-Volume 1, pages 169?176.
Associationfor Computational Linguistics.A.
de Gispert, J.
B. Marin?o, and J. M. Crego.
2005.Improving statistical machine translation by classi-fying and generalizing inflected verb forms.
In Pro-ceedings of InterSpeech.J.
DeNero and D. Klein.
2010.
Discriminative mod-eling of extraction sets for machine translation.
InProceedings of the 48th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 1453?1463.
Association for Computational Linguistics.J.
DeNero, A.
Bouchard-Co?te?, and D. Klein.
2008.Sampling alignment structure under a Bayesiantranslation model.
In Proceedings of the Confer-ence on Empirical Methods in Natural LanguageProcessing, pages 314?323.
Association for Com-putational Linguistics.V.
Eidelman, Y. Marton, and P. Resnik.
2013.
Onlinerelative margin maximization for statistical machinetranslation.
In Proceedings of ACL.M.
Elhadad.
1993.
Generating argumentative judg-ment determiners.
In AAAI, pages 344?349.J.
R. Finkel, T. Grenager, and C. Manning.
2005.
In-corporating non-local information into informationextraction systems by gibbs sampling.
In ACL ?05:Proceedings of the 43rd Annual Meeting on Asso-ciation for Computational Linguistics, pages 363?370, Morristown, NJ, USA.
Association for Compu-tational Linguistics.A.
Fraser, M. Weller, A. Cahill, and F. Cap.
2012.Modeling inflection and word-formation in SMT.
InProceedings of EACL.M.
Galley, J. Graehl, K. Knight, D. Marcu, S. DeNeefe,W.
Wang, and I. Thayer.
2006.
Scalable infer-ence and training of context-rich syntactic transla-tion models.
In ACL-44: Proceedings of the 21st In-ternational Conference on Computational Linguis-tics and the 44th annual meeting of the Associa-tion for Computational Linguistics, pages 961?968,Morristown, NJ, USA.
Association for Computa-tional Linguistics.M.
Gamon, J. Gao, C. Brockett, A. Klementiev, W. B.Dolan, D. Belenko, and L. Vanderwende.
2009.
Us-ing contextual speller techniques and language mod-eling for ESL error correction.
Urbana, 51:61801.K.
Gimpel and N. A. Smith.
2012.
Structured ramploss minimization for machine translation.
In Pro-ceedings of 2012 Conference of the North Ameri-can Chapter of the Association for ComputationalLinguistics: Human Language Technologies HLT-NAACL 2012, Montreal, Canada.N.-R. Han, M. Chodorow, and C. Leacock.
2006.
De-tecting errors in English article usage by non-nativespeakers.K.
Knight and I. Chander.
1994.
Automated poste-diting of documents.
In Proceedings of the Na-tional Conference on Artificial Intelligence, pages779?779, Seattle, WA.P.
Koehn and H. Hoang.
2007.
Factored transla-tion models.
In Proceedings of the 2007 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning (EMNLP-CoNLL), pages 868?876,Prague, Czech Republic, June.
Association for Com-putational Linguistics.279P.
Koehn, F. J. Och, and D. Marcu.
2003.
Statisticalphrase-based translation.
In NAACL ?03: Proceed-ings of the 2003 Conference of the North AmericanChapter of the Association for Computational Lin-guistics on Human Language Technology, pages 48?54.
Association for Computational Linguistics.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: Open source toolkitfor statistical machine translation.
In Proceedings ofthe 45th Annual Meeting of the Association for Com-putational Linguistics Companion Volume Proceed-ings of the Demo and Poster Sessions, pages 177?180, Prague, Czech Republic, June.
Association forComputational Linguistics.C.
Lyons.
1999.
Definiteness.
Cambridge UniversityPress.G.
Minnen, F. Bond, and A. Copestake.
2000.Memory-based learning for article generation.
InProceedings of the 2nd workshop on Learning lan-guage in logic and the 4th conference on Compu-tational natural language learning-Volume 7, pages43?48.
Association for Computational Linguistics.T.
Mohanan.
1994.
Argument Structure in Hindi.CSLI Publications.K.
Oflazer and I. Durgar El-Kahlout.
2007.
Explor-ing different representational units in English-to-Turkish statistical machine translation.
In Proceed-ings of the Second Workshop on Statistical MachineTranslation, pages 25?32, Prague, Czech Republic,June.
Association for Computational Linguistics.K.
Papineni, S. Roukos, T. Ward, and W.-J.
Zhu.
2002.BLEU: a method for automatic evaluation of ma-chine translation.
In ACL ?02: Proceedings of the40th Annual Meeting on Association for Computa-tional Linguistics, pages 311?318, Morristown, NJ,USA.
Association for Computational Linguistics.A.
Rozovskaya and D. Roth.
2010.
Trainingparadigms for correcting errors in grammar and us-age.
Urbana, 51:61801.A.
Stolcke.
2002.
SRILM?an extensible languagemodeling toolkit.
In Procedings of InternationalConference on Spoken Language Processing, pages901?904.H.
Suzuki and K. Toutanova.
2006.
Learning to pre-dict case markers in Japanese.
In Proceedings ofthe 21st International Conference on ComputationalLinguistics and the 44th annual meeting of the Asso-ciation for Computational Linguistics, pages 1049?1056.
Association for Computational Linguistics.H.
Suzuki and K. Toutanova.
2007.
Generating casemarkers in machine translation.
In Proceedings ofHLT-NAACL 2007, pages 49?56.K.
Toutanova and C. D. Manning.
2000.
Enrichingthe knowledge sources used in a maximum entropypart-of-speech tagger.
In Proceedings of the 2000Joint SIGDAT conference on Empirical methods innatural language processing and very large corpora,pages 63?70, Morristown, NJ, USA.
Association forComputational Linguistics.280
