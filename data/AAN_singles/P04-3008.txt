Interactive grammar development with WCDGKilian A. Foth Michael Daum Wolfgang MenzelNatural Language Systems GroupHamburg UniversityD-22527 HamburgGermany{foth,micha,menzel}@nats.informatik.uni-hamburg.deAbstractThe manual design of grammars for accurate natu-ral language analysis is an iterative process; whilemodelling decisions usually determine parser be-haviour, evidence from analysing more or differ-ent input can suggest unforeseen regularities, whichleads to a reformulation of rules, or even to a differ-ent model of previously analysed phenomena.
Wedescribe an implementation of Weighted ConstraintDependency Grammar that supports the grammarwriter by providing display, automatic analysis, anddiagnosis of dependency analyses and allows the di-rect exploration of alternative analyses and their sta-tus under the current grammar.1 IntroductionFor parsing real-life natural language reliably, agrammar is required that covers most syntacticstructures, but can also process input even if itcontains phenomena that the grammar writer hasnot foreseen.
Two fundamentally different waysof reaching this goal have been employed varioustimes.
One is to induce a probability model of thetarget language from a corpus of existing analysesand then compute the most probable structure fornew input, i.e.
the one that under some judiciouslychosen measure is most similar to the previouslyseen structures.
The other way is to gather linguis-tically motivated general rules and write a parsingsystem that can only create structures adhering tothese rules.Where an automatically induced grammar re-quires large amounts of training material and thedevelopment focuses on global changes to the prob-ability model, a handwritten grammar could in prin-ciple be developed without any corpus at all, butconsiderable effort is needed to find and formu-late the individual rules.
If the formalism allowsthe ranking of grammar rules, their relative impor-tance must also be determined.
This work is usu-ally much more cyclical in character; after grammarrules have been changed, intended and unforeseenconsequences of the change must be checked, andfurther changes or entirely new rules are suggestedby the results.We present a tool that allows a grammar writer todevelop and refine rules for natural language, parsenew input, or annotate corpora, all in the same envi-ronment.
Particular support is available for interac-tive grammar development; the effect of individualgrammar rules is directly displayed, and the systemexplicitly explains its parsing decisions in terms ofthe rules written by the developer.2 The WCDG parsing systemThe WCDG formalism (Schro?der, 2002) describesnatural language exclusively as dependency struc-ture, i.e.
ordered, labelled pairs of words in the in-put text.
It performs natural language analysis underthe paradigm of constraint optimization, where theanalysis that best conforms to all rules of the gram-mar is returned.
The rules are explicit descriptionsof well-formed tree structures, allowing a modularand fine-grained description of grammatical knowl-edge.
For instance, rules in a grammar of Englishwould state that subjects normally precede the finiteverb and objects follow it, while temporal NP caneither precede or follow it.In general, these constraints are defeasible, sincemany rules about language are not absolute, butcan be preempted by more important rules.
Thestrength of constraining information is controlled bythe grammar writer: fundamental rules that must al-ways hold, principles of different import that haveto be weighed against each other, and general pref-erences that only take effect when no other disam-biguating knowledge is available can all be formu-lated in a uniform way.
In some cases preferencescan also be used for disambiguation by approximat-ing information that is currently not available to thesystem (e.g.
knowledge on attachment preferences).Even the very weak preferences have an influenceon the parsing process; apart from serving as tie-breakers for structures where little context is avail-able (e.g.
with fragmentary input), they provide anFigure 1: Display of a simplified feature hierarchyinitial direction for the constraint optimization pro-cess even if they are eventually overruled.
As a con-sequence, even the best structure found usually in-curs some minor constraint violations; as long asthe combined evidence of these default expectationfailures is small, the structure can be regarded asperfectly grammatical.The mechanism of constraint optimization si-multaneously achieves robustness against extra-grammatical and ungrammatical input.
There-fore WCDG allows for broad-coverage parsing withhigh accuracy; it is possible to write a grammarthat is guaranteed to allow at least one structure forany kind of input, while still preferring compliantover deviant input wherever possible.
This gracefuldegradation under reduced input quality makes theformalism suitable for applications where deviantinput is to be expected, e.g.
second language learn-ing.
In this case the potential for error diagnosisis also very valuable: if the best analysis that canbe found still violates an important constraint, thisdirectly indicates not only where an error occurred,but also what might be wrong about the input.3 XCDG: A Tool for Parsing andModellingAn implementation of constraint dependency gram-mar exists that has the character of middleware to al-low embedding the parsing functionality into othernatural language applications.
The program XCDGuses this functionality for a graphical tool for gram-mar development.In addition to providing an interface to a rangeof different parsing algorithms, graphical displayof grammar elements and parsing results is possi-ble; for instance, the hierarchical relations betweenpossible attributes of lexicon items can be shown.See Figure 1 for an excerpt of the hierarchy of Ger-man syntactical categories used; the terminals cor-respond to those used the Stuttgart-Tu?bingen Tagsetof German (Schiller et al, 1999).More importantly, mean and end results of pars-ing runs can be displayed graphically.
Dependencystructures are represented as trees, while additionalrelations outside the syntax structure are shown asarcs below the tree (see the referential relationshipREF in Figure 2).
As well as end results, inter-mediate structures found during parsing can be dis-played.
This is often helpful in understanding thebehaviour of the heuristic solution methods em-ployed.Together with the structural analysis, instancesof broken rules are displayed below the depen-dency graph (ordered by decreasing weights), andthe dependencies that trigger the violation are high-lighted on demand (in our case the PP-modificationbetween the preposition in and the infinite formverkaufen).
This allows the grammar writer to eas-ily check whether or not a rule does in fact make thedistinction it is supposed to make.
A unique iden-tifier attached to each rule provides a link into thegrammar source file containing all constraint defi-nitions.
The unary constraint ?mod-Distanz?
inthe example of Figure 2 is a fairly weak constraintwhich penalizes attachments the stronger the moredistant a dependent is placed from its head.
At-taching the preposition to the preceding noun Bundwould be preferred by this constraint, since the dis-tance is shorter.
However, it would lead to a moreserious constraint violation because noun attach-ments are generally dispreferred.To facilitate such experimentation, the parse win-dow doubles as a tree editor that allows structural,lexical and label changes to be made to an analysisby drag and drop.
One important application of theintegrated parsing and editing tool is the creation oflarge-scale dependency treebanks.
With the abilityto save and load parsing results from disk, automat-ically computed analyses can be checked and hand-corrected where necessary and then saved as anno-tations.
With a parser that achieves a high perfor-mance on unseen input, a throughput of over 100 an-notations per hour has been achieved.4 Grammar development with XCDGThe development of a parsing grammar based ondeclarative constraints differs fundamentally fromthat of a derivational grammar, because its rules for-bid structures instead of licensing them: while acontext-free grammar without productions licensesnothing, a constraint grammar without constraintswould allow everything.
A new constraint musttherefore be written whenever two analyses of thesame string are possible under the existing con-straints, but human judgement clearly prefers oneover the other.Figure 2: Xcdg Tree EditorMost often, new constraints are prompted by in-spection of parsing results under the existing gram-mar: if an analysis is computed to be grammati-cal that clearly contradicts intuition, a rule must bemissing from the grammar.
Conversely, if an erroris signalled where human judgement disagrees, therelevant grammar rule must be wrong (or in need ofclarifying exceptions).
In this way, continuous im-provement of an existing grammar is possible.XCDG supports this development style throughthe feature of hypothetical evaluation.
The tree dis-play window does not only show the result returnedby the parser; the structure, labels and lexical selec-tions can be changed manually, forcing the parser topretend that it returned a different analysis.
Recallthat syntactic structures do not have to be specif-ically allowed by grammar rules; therefore, everyconceivable combination of subordinations, labelsand lexical selections is admissible in principle, andcan be processed by XCDG, although its score willbe low if it contradicts many constraints.After each such change to a parse tree, all con-straints are automatically re-evaluated and the up-dated grammar judgement is displayed.
In this wayit can quickly be checked which of two alternativestructures is preferred by the grammar.
This is use-ful in several ways.
First, when analysing pars-ing errors it allows the grammar author to distin-guish search errors from modelling errors: if theintended structure is assigned a better score than theone actually returned by the parser, a search erroroccurred (usually due to limited processing time);but if the computed structure does carry the higherscore, this indicates an error of judgement on thepart of the grammar writer, and the grammar needsto be changed in some way if the phenomenon is tobe modelled adequately.If a modelling error does occur, it must be be-cause a constraint that rules against the intendedanalysis has overruled those that should have se-lected it.
Since the display of broken constraints isordered by severity, it is immediately obvious whichof the grammar rules this is.
The developer canthen decide whether to weaken that rule or extendit so that it makes an exception for the current phe-nomenon.
It is also possible that the intended anal-ysis really does conflict with a particular linguisticprinciple, but in doing so follows a more importantone; in this case, this other rule must be found andstrengthened so that it will overrule the first one.The other rule can likewise be found by re-creatingthe original automatic analysis and see which of itsconstraint violations needs to be given more weight,or, alternatively, which entirely new rule must beadded to the grammar.In the decision whether to add a new rule to a con-straint grammar, it must be discovered under whatconditions a particular phenomenon occurs, so thata generally relevant rule can be written.
The posses-sion of a large amount of analysed text is often use-ful here to verify decisions based on mere introspec-tion.
Working together with an external programto search for specific structures in large treebanks,XCDG can display multiple sentences in stackedwidgets and highlight all instances of the same phe-nomenon to help the grammar writer decide whatthe relevant conditions are.Using this tool, a comprehensive grammar ofmodern German has been constructed (Foth, 2004)that employs 750 handwritten well-formednessrules, and has been used to annotate around 25,000sentences with dependency structure.
It achieves astructural recall of 87.7% on sentences from the NE-GRA corpus (Foth et al, submitted), but can be ap-plied to texts of many other types, where structuralrecall varies between 80?90%.
To our knowledge,no other system has been published that achievesa comparable correctness for open-domain Germantext.
Parsing time is rather high due to the computa-tional effort of multidimensional optimization; pro-cessing time is usually measured in seconds ratherthan milliseconds for each sentence.5 ConclusionsWe demonstrate a tool that lets the user parse, dis-play and manipulate dependency structures accord-ing to a variant of dependency grammar in a graph-ical environment.
We have found such an inte-grated environment invaluable for the developmentof precise and large grammars of natural language.Compared to other approaches, c.f.
(Kaplan andMaxwell, 1996), the built-in WCDG parser pro-vides a much better feedback by pinpointing possi-ble reasons for the current grammar being unable toproduce the desired parsing result.
This additionalinformation can then be immediately used in subse-quent development cycles.A similar tool, called Annotate, has been de-scribed in (Brants and Plaehn, 2000).
This toolfacilitates syntactic corpus annotation in a semi-automatic way by using a part-of-speech tagger anda parser running in the background.
In compari-son, Annotate is primarily used for corpus annota-tion, whereas XCDG supports the development ofthe parser itself also.Due to its ability to always compute the singlebest analysis of a sentence and to highlight possibleshortcomings of the grammar, the XCDG systemprovides a useful framework in which human designdecisions on rules and weights can be effectivelycombined with a corpus-driven evaluation of theirconsequences.
An alternative for a symbiotic coop-eration in grammar development has been devisedby (Hockenmaier and Steedman, 2002), where askeleton of fairly general rule schemata is instan-tiated and weighed by means of a treebank anno-tation.
Although the resulting grammar producedhighly competitive results, it nevertheless requiresa treebank being given in advance, while our ap-proach also supports a simultaneous treebank com-pilation.ReferencesThorsten Brants and Oliver Plaehn.
2000.
Interac-tive corpus annotation.
In Proc.
2nd Int.
Conf.on Language Resources and Engineering, LREC2000, pages 453?459, Athens.Kilian Foth, Michael Daum, and Wolfgang Men-zel.
submitted.
A broad-coverage parser for Ger-man based on defeasible constraints.
In Proc.
7.Konferenz zur Verarbeitung nat?urlicher Sprache,KONVENS-2004, Wien, Austria.Kilian A. Foth.
2004.
Writing weighted constraintsfor large dependency grammars.
In Proc.
RecentAdvances in Dependency Grammars, COLING2004, Geneva, Switzerland.Julia Hockenmaier and Mark Steedman.
2002.Generative models for statistical parsing withcombinatory categorial grammar.
In Proc.
40thAnnual Meeting of the ACL, ACL-2002, Philadel-phia, PA.Ronald M. Kaplan and John T. Maxwell.
1996.LFG grammar writer?s workbench.
Technical re-port, Xerox PARC.Anne Schiller, Simone Teufel, Christine Sto?ckert,and Christine Thielen.
1999.
Guidelines fu?r dasTagging deutscher Textcorpora.
Technical report,Universita?t Stuttgart / Universita?t Tu?bingen.Ingo Schro?der.
2002.
Natural Language Parsingwith Graded Constraints.
Ph.D. thesis, Depart-ment of Informatics, Hamburg University, Ham-burg, Germany.
