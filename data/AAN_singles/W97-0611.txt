Planning Efficient Mixed Initiative DialogueE l i  Hagen*Deutsche Telekom, FZl31PO Box 10 00 0364276 Darmstadt, Germanyemall: hagen@fz.telekom.deBr ig i t te  GroteDept.
of Computer ScienceOtto-von-Guericke Universit~t Magdeburg39106 Magdeburg, Germanyemaih grote@iik.cs.uni-magdeburg.de1 Mot ivat ionA common feature of a number of current spoken di-alogue systems for information retrieval is that lit-tle emphasis is placed on the generation of systemcontributions to the dialogue.
In these systems,utterances have mostly been produced from tem-plates, see for instance (Whittaker and Attwater 1994;Blomberg et al 1993; Oerder and Aust 1993; Menget al 1996).
This is a valid approach in systeminitiative type systems and in systems where utter-ances stand in a one-to-one relation to communica-tive goals.
In mixed initiative systems, however, userand system might both lead the dialogue by provid-ing several pieces of information and pursuing severaldifferent goals within one utterance.
Hence, in thiskind of dialogue we cannot predict what informationthe user chooses to provide, and hence cannot pre-dict the system's response.
We argue that in any sys-tem of reasonable size, the number of templates wouldbe too large to determine a priori.
Instead, in orderto achieve efficient and cooperative dialogue, systemutterances must be generated using natural anguagegeneration (NLG) techniques.NLG has been used by, for instance, (Pan and McKe-own 1996; Sadek et al 1996), but they put emphasison generation of system answers, i.e.
on offering andproviding information.
We are concerned with utter-ances requesting specific information.
(Sadek et al1996) also generate requests, but they are mostly of ageneral nature, and the sample dialogue in their papersuggests that the system's requests for specific infor-mation can only realize one communicative goal at atime.In several recent systems (e.g., (Allen et al 1996;Sadek et al 1996)), confirmation of information thatthe system acquires from the user (variables) is mostlyavoided.
This might be a valid approach as their num-ber of variables is small, but we think that it willlead to frustrating dialogues when several variables areneeded.
Consider the following interaction, where thesystem actually misrecognized all the values providedby the user.
User: "How much is a call from Bonnto Homburg at 8 o'clock?"
Sys: "A call from Berlinto Hamburg at 1800 costs 36 Pfennig per minute."
Itwould be very hard to recover from this situation andthe user would most likely never call again.
*The author is a visiting researcher in the speech pro-cessing group FZ131, Deutsche Telekom.
Authors are inopposite alphabetical order this time.In our domain (calculation of the price of phone calls),the system must acquire several variables--with some-times ambiguous values.
Therefore confirmation anddisambiguation questions are necessary, and hence wehave a larger number of communicative goals to sat-isfy than the afore mentioned systems.
But, if we wereto designate a single utterance for each communica-tive goal, we would quickly end up with inefficient andannoying dialogues like the following:Sample  d ia logue 1A.
Sys: Do you want the rate or the total cost of a call?B.
Usr: How much is a call to Frankfurt, please.C.
Sys: Do you want the rate or the total cost of a call?D.
Usr: The rate of a call to Frankfurt.E.
Sys: Do you want the rate of a call?F.
Usr: Yes, to Frankfurt, please.G.
Sys: What is the destination of your call?H.
Usr: Frankfurt!I.
Sys: Is the destination of your call Frankfurt?J.
Usr: Yess!!K.
Sys: Frankfurt am Main or Frankfurt an der Oder?L.
Usr: Frankfurt am MAAAAIIIN!!
!To avoid such uncooperative dialogues, a system hasto be able to interpret additional information providedby the user, as, for instance, in move D in dialogue 1.Further, system responses must be efficient.
Humansachieve fficiency by pursuing several goals at a timeinstead of dealing with single goals in a strict sequen-tial order.
In our approach, we apply this observationto the design of information systems, hoping that itresults in an interaction as illustrated in dialogue 2.Here, some goals are expressed implicitly (e.g., confir-mation in utterance C), while others are omitted (e.g.,asking for the destination).Sample  d ia logue 2A.
Sys: Do you want the rate or the total cost of a call?B.
Usr: How much is a call to Frankfurt, please.C.
Sys: The rate or the total cost of a call to Frankfurt?D.
Usr: The rate, please.E Sys: Frankfurt am Main or Frankfurt an der Oder?D.
Usr: Am Main.In this paper, we describe an initial realization ofsuch a cooperative and efficient mixed initiative di-alogue system.
In particular, we discuss system utter-ances whose primary goal is to acquire information ofvarious kinds, since these occur frequently in our do-main.
Building on results in (Hagen 1997), we developheuristics for jointly expressing several communicativegoals in one utterance, thus responding to the require-ments of the task at hand and to the user initiativeat the same time.
A prototypical system that answers53I~SADISIPRICE-PER-MINUTEIII /taEol-~eo-datafGE0gRAPHICAL-DATA....... } .......I IDISTANCE ZONEI \%alce=-=ource  takeo-de=tinat?onI ISOURCE DESTINATIONITOTAL-COST/ I/ II~akes-t emporal-dataI I~OEJk l .
-DAT I. .
.
.
.
.
.
\[ .
.
.
.
.
.
.
.I ITIME-POINT TIME-SPAI4I ICALCULATED-TS EXPLICIT-TS/ \ / I tak==-encl-time takel-=?~t-time take=-duratiouI I IEND-TIME START-TIME DURATIONFigure 1: An abridged version of the task descriptionfor the TESADIS telephone rate inquiry system.queries about the cost of telephone calls is currentlybeing implemented.2 Knowledge  sourcesWe assume the existence of three different knowledgesources: A task model describing the tasks a systemcan perform, a model of information seeking dialogue,and a dialogue history.The task descript ion defines the information unitsthat can be negotiated between the participants of adialogue.
As such, it facilitates the choice of a topic forsystem utterances and provides expectations regard-ing potential user responses.
Negotiated topics can beeither alternative ways of solving a task or pieces ofinformation eeded to solve a given task.
Tasks areorganized in hierarchies of concepts and relations be-tween them.
A part of the task model for our applica-tion is given in Figure 1.
CAPITAL LETTERs name con-cepts; unnamed relations denote subconcept relations;named relations represent particular relations holdingbetween concepts (e.g., takes-temporal-data).Subconcept relations imply that there exist differ-ent ways of accomplishing a task, for instance:TESADIS can calculate ither PRICE-PER-MINUTE orTOTAL-COST of a call.
Concepts that participate as therange in a named relation represent obligatory sub-tasks.
For instance, in order to calculate TOTAL-COST,the system needs information on the locational andtemporal setting of the call, indicated by the re-lations takes-geo-data and takes-temporal -databetween TOTAL-COST and GEOGRAPHICAL-DATA andTEMPORAL-DATA.Dialogue model  Our model of information seekingdialogue is speech-act oriented and a simplified ver-sion of the dialogue grammar is presented in Figure 2(see (Sitter and Stein 1992) for a detailed discussion).Each constituent has two parameters--informationseeker and information provider.
The first parame-ter represents he initiator, or speaker, the second thehearer.
During execution, the parameters are instan-tiated to either 'user' or 'system'.
Moves in squarebrackets (\[\]) are optional and X + means one or moreinstances of constituent X.Dialogue history In our system, the dialogue modelis used analytically to build a parse tree of the di-aiogue with respect o the dialogue grammar.
It isDialogue(S,K) -+ (Cycle(S,K)) +Cycle(S,K) -+ Request(S,K),Promise(K,S),lnform(K,S),Evaluate(S,K).Cycle(S,K) ~ Offer(K,S),Accept(S,K),lnform(K,S),Evaluate(S,K).Cycle(S,K) .-+ Offer(K,S),\[Accept(S,K)\],WithdrawOffer(K,S).Cycle(S,K) ~ Offer(K,S),Accept(S,K),WithdrawAccept(S,K).Request(S,K).Request(S,K) -+ request(S,K),\[Dialogue(K,S)\].Request(S,K) ~ request(S,K),\[Assert(S,K)\].Request(S,K) ~ Dialogue(K,S).Request(S,K) ~ Assert(S,K),\[request(S,K)\].Request(S,K) ~ Assert(S,K),\[Dialogue(K,S)\].request(S.K).Inform(K,S) ~ inform(K,S),\[Dialogue(S,K)\].Figure 2: A simplified grammar representation f thedialogue model in pseudo-Prolog syntax.used generatively topredict what can happen ext ina dialogue.
If one of the dialogue partners providesmore than one dialogue act in one turn, the acts arereflected in the parse tree as several partially finishedsub-trees, i.e., there are several open ends from whichthe dialogue might continue.
Figure 3 shows a dia-logue history with three open ends labelled 1-3 (see(Hagen 1997) for further discussion)In addition to the parse tree, we consider the state ofthe task model part of the dialogue history.
Individualnodes (i.e.
concepts) in the task model can be in one ofseveral states: open/dosed nodes are nodes for whichthe system has not/has acquired a confirmed value.Nodes that are still under consideration, i.e., the sys-tem has requested a value or the user has provideda value, are in state topic.
Topic is further dividedinto ambiguous, misrecognition, and confirm, confirmmeans that the system has low confidence in its recog-nition result, ambiguous means that the system hasdiscovered that a value is ambiguous, and misrecogni-tion means that a value has been wrongly understood.Initially, all nodes are open.
During the course of adialogue, transformations to other states take placedepending on the quality of the acquired ata.3 P lann ing  and  In terpreta t ion  o fd ia logue  cont inuat ionsThe dialogue model provides all possible continuationsof a dialogue, while the dialogue history defines thecontext in which to calculate the continuations.
Theparse tree contains everal open ends that might serveas starting points for further dialogue contributions,and the state of the task model defines which of theseare still relevant before the continuations are calcu-lated.
The continuations are represented as partialtrees, and those chosen extends the parse tree at theappropriate open end.
Consider the following dialoguefragment:A. Sys: Where do you want to call?
(request)B. Usr: I want to call Hamburg.
(inform)Part (a) of Figure 3 shows the corresponding parsetree, while tree (b) shows a possible continuation,which could result in the utterance "Did you say Ham-burg?"
if chosen as the continuation ofInform(u,s) andif the recognition rate for Hamburg is low.By choosing a particular continuation of the dia-logue, a dialogue participant is pursuing a certaingoal.
The reasons for performing a dialogue act54a) Dialogue(s) b) Dialogue(s)Cycle(s) 3 Cyde(s)R~s) P(u) l(u) 2 R(s)/ / \  /r(s) i(u) 1 r(s)where?
HamburgF igure  3: A parse tree and a continuation.
Notation:R/r  = R/request, P /p  = P/promise, I/i = I/inform, etc.Parameter values: u = user and s = system.
Thehearer parameter is left out.are fairly straightforward in information-seeking di-alogues, hence we only find a small set of communica-tive goals.
The basic ones are "provide information"and "seek information", which correspond to Hovy's(Hovy 1988) pragmatic goals increase knowledge(of hearer) and access knowledge (of hearer).
Sincewe are concerned with the generation of system re-sponses, we ignore user goals for the time being.
Fur-ther, we focus on the access knowledge kind.
Thisgoal can be further classified with respect o the kindof information under discussion, i.e.
interpreted inthe context of the state of the task model.
We ar-rived at the following set of subgoals for the accessknowledge goal:1. initiate a choice (by hearer)2. acquire specific information (from hearer)3. acquire confirmation (from hearer)4. acquire disambiguation (by hearer)5. clarify misrecognition (by hearer)Obviously, there is no one-to-one mapping betweendialogue continuation and communicative goal, sincea speaker can use the same continuation to achievedifferent goals.
Continuations merely represent theillocutionary aspect of how a dialogue can continue.They must, however, be interpreted in the context ofthe current dialogue history to form a concrete com-municative goal.
Thus, the actual goal depends onthe state of the task concept under consideration a dthe system's beliefs concerning that state.
In our pre-vious example, the system employs the same dialogueact (request) to pursue different goals: With the initialrequest, the system realizes the goal 'acquire specificinformation' with the instantiation 'of source'.
Theuser supplies an answer (inform), which the systembelieves to be Homburg.
Since its confidence in theresult from the speech recognition is low, the contin-uation is interpreted as 'acquire confirmation' (openend 1), which is instantiated to 'acquire confirmationof recognized source=homburg'.In the tables below, we summarize how continuations,states of the nodes in task description, and the sys-tem's beliefs about he state of the nodes are mappedonto specific communicative goals.
If the system con-tinutation ends on a request, we get the following map-pings:State of Xopenconfirmambiguousmisrecog.closedComm.
goalsacquire uval(X)acquire confirm.acq.
disambig.acq.
new sval(X)acquire sval(Y)their domainE inst (X)sv~(X) = u~(X)sval(X) E inst(sval(X))?
inst(X)\{sval(X)}E inst(Y)55If a continutation e ds on an offer, the mappings are:StateofX I Comm.~oals \] their domainopen acquire sval(X) in sub(X)The following notation applies: inst(X) = instantia-tions of a concept X; sub(X) = the subconcepts of aconcept X; sval(X) = what the system believes theuser said; uval(X) = what the user intended, e.g., inthe last example above sval(source) = Homburg anduval(source) = Hamburg.4 P lann ing  an  ut teranceSo far, we have described possible dialogue contin-uations and interpreted them in the context of thedialogue history as pursuing a particular communica-tive goal.
In most current dialogue systems, each ofthese goals would be realized as a separate utterance,i.e.
the surface structure of the dialogue would merelybe a reflection of the underlying dialogue history (seedialogue 1).
Our goal, however, is to generate ut-terances like those in sample dialogue 2.
Hence, weneed to investigate which communicative goals can besatisfied at a time, in other words, which constella-tions of dialogue acts given a certain state of the taskmodel can be jointly expressed in one utterance.
Re-cent work on aggregation i the context of naturallanguage generation (e.g.
(Dalianis and Hovy 1993))states that surface structures are abbreviated wheninformation units that in the domain are representedas separate individuals hare pertinent features, forinstance, syntactical, lexical or semantic features.
Weextended this notion to allow aggregation of commu-nicative goals: Depending on the common feature, wedefined four strategies for condensing dialogue inter-action: abbreviation, abstraction, omission, and dom-inance.Abbreviation.
We call the condensing of informa-tion "abbreviation" when a number of continuationsthat would become adjoining parts of the parse treeand furthermore represent the same communicativegoal are expressed in one utterance.
If the inter-hal structure of adjoining dialogue cycles (siblings,see Figure 4a) is identical, and the concepts/tasksnegotiated in these structures either have the samesuperconcept or are connected to the same conceptby means of a relation, and if the state of the con-cepts under consideration is open, then the resultingutterance is abbreviated.
For instance, abbreviationof several offer constellations that represent the ini-tiate choice as in "Do you want the rate or the to-tal cost of a call?
", where 'acquire uval(TESADIS) ?sub(TESADIS)' = 'acquire uval 0 ?
inst(PRICE-PER-MINUTE) t..J inst(TOTAL-COST)' are abbreviated.Another example would be the abbreviation of actsfor acquiring specific information as in "What are thesource and the destination of your call?
", where 'ac-quire uval(source)' and 'acquire uval(destination)' areaggregated.
Figure 4b, which could be a continuationof the Accept(u) in Figure 4a, illustrates this case.A third example isabbreviation ofseveral acquire con-firmation goals, e.g., "Do you want to call Darmstadtfrom Magdeburg?"
--an bbreviation of 'acquire con-firmation sval(source) = uval(source)' 'acquire confir-(a) Dialogue(u) (b) Dialogue(s)O(s) Ac(u) O(s) RO(u) R(s) R(s)I I I I I Ioffer(s) accept (u) offer(s) to(u) r(s) r(s)pePr~nute "rate" TotalCost source destinationF igure  4: Structures that can be abbreviated.mation sval(destination) = uval(destination)'.Abst ract ion  means that we transform several sim-ilar goals into a new, more abstract goal.
In par-ticular, this applies to the goal 'acquire disambigua-tion' when a large number of alternatives are athand.
Research in cognitive science and ergonomicdesign of dialogue systems have shown that humanbeings can only keep a few alternatives in their shortterm memory, hence instead of presenting the lis-tener with a long list of alternatives, it is more ef-ficient to phrase a question in a way that avoids men-tioning the alternatives.
For instance, the goals 'ac-quire disambiguation sval(name) = maier', 'acquiredisambiguation svai(name) = meyer', etc.
can be ab-stracted into 'acquire disambiguation sval(name) inmaier,meyer,meier,mayer' with the realization "Howdo you spell \[mai:er\]?"
instead of "Is \[mai:er\] speltwith a i, a y, e i, or e y?
"Dominance  and subord inat ion .
It can be efficientto solicit implicit confirmation of previously recog-nized values, hence we allow a goal for acquiring a newvalue and a goal for acquiring confirmation of anothervalue to be realized in one utterance, as in "Whendo you want to call Frankfurt?"
This is a realiza-tion of the dominating oal 'acquire uval(startTime)'and the subordinate goal 'acquire confirmation ofsvai(destination)'.Omiss ion.
Omission means that we leave out agoal altogether, for instance, if the recognition rateof an ambiguous value is high, we take the risk ofasking for disambignation right away, as in the ques-tion "Is your call from Frankfurt am Main or Frank-furt an der Oder?"
Here the goal 'acquire confir-mation sval(source) = uval(source)' is omitted andthe goals 'acquire disambiguation of sval(destination)= Frankfurt am Main' 'acquire disambiguation ofsval(destination)= Frankfurt an der Oder' have beenabstracted as above.When is aggregat ion  not  poss ib le?
Above wediscussed which structures can be successfully aggre-gated into more abstract goals and more compact ut-terances.
However, there are certain limits to perform-ing aggregation.
For instance, one cannot aggregatebetween different levels in the dialogue history if thehigher level has not yet been satisfied as the followingtwo examples illustrate: *"Do you want the rate orthe total cost of a call to where?
or ?
"When do youwant the rate of a call?
".5 Conc lus ionIn naturally occuring dialogue, the structure of thesurface interaction differs from the underlying dia-logue history insofar as certain communicative goals56are jointly expressed in one utterance, others may evenbe omitted.
We modelled this behaviour for mixedinitiative dialogue.
In particular, we focused on thesystem behaviour, and how the system can respond tothe user's cooperation, i.e., to newly introduced goalsfrom the user in an equally cooperative manner.
Wehave shown that in order to achieve this behaviour,one has to define constellations of dialogue acts andgiven a certain state of the task model, which give riseto specific communciative goals.
Several of these canbe realized within a single utterance.The next step will be to take a set of communicativegoals chosen for aggregation and the content selectedby them and pass this to a natural anguage genera-tion system.
For NLG purposes, we will have to in-vestigate how the communicative goals to be realizedwithin one utterance are ranked, how the speech act ofan utterance is determined, how the abstraction stepalters the content o be expressed, and how differentkinds of aggregation rules are realized linguistically.Finally, we will have to build a much more powerfultask model in order to support he disambiguation andabstraction procedures, and the generation process.Re ferencesJ.F.
Allen, B.W.
Miller, E.K.
Ringger, and T. Sikorski.A robust system for natural spoken dialogue.
In Proc.
ofthe Annual Meeting of the ACL, 1996.M.
Blomberg, R. Carlson, K. Elenius, B. GranstrSm,J.
Gustafson, S. Hunnicutt, R. Lindell, and L. Neovius.An experimental dialogue system: WAXHOLM.
In Eu-rospeech'93 (Proc.
European Conf.
on Speech Communi-cation and Technology), pages 1867-1870, 1993.H.
Dalianis and E. Hovy.
Aggregation i natural languagegeneration.
In Proc.
of the European.
Wshp.
on NaturalLanguage Generation, 1993.E.
Hagen.
Mixed initiative in a spoken dialogue system.In Working notes AAAI Spring Symposium Series; Com-putational Models .for Mixed Initiative Interaction (avail-able as technical report from AAAI), 1997.E.H.
Hovy.
Generating Natural Language under Prag-matic Constraints.
Lawrence Erlbaum Associates, Hills-dale, New Jersey, 1988.H.
Meng, S. Busayapongschai, J.
Glass, D. Goddean,L.
Hetherington, E. Hurley, C. Pao, J. Polifroni, S. Sen-eft, and V. Zue.
WHEELS: A conversational system inthe automobile classified domain.
In Proc.
of the 1996Intl.
Conf.
on Spoken Language Processing (ICSLP'96),1996.M.
Oerder and H. Aust.
A realtime prototype of an au-tomatic inquiry system.
In ICSLP'94, pages 703-706,1994.S.
Pan and K. McKeown.
Spoken language generation ia multimedia system.
In ICSLP'96, 1996.M.D.
Sadek, A. Ferrieux, A. Cozannet, P. Bretier,F.
Panaget, and J. Simonin.
Effective human-computercooperative spoken dialogue: AGS demonstrator.
In IC-SLP'96, 1996.S.
Sitter and A. Stein.
Modelling the illocutionary aspectsof information-seeking dialogues.
Information Processingand Management, 8(2):165-180, 1992.S.
Whittaker and D. Attwater.
Advanced speech applica-tions - the integration of speech technology into complexservices.
In Proc.
ESCA Wshp.
on Spoken Dialogue Sys-tems; Theories and Applications, pages 113-116, 1994.
