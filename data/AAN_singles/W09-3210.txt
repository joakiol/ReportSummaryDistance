Proceedings of the 2009 Workshop on Graph-based Methods for Natural Language Processing, ACL-IJCNLP 2009, pages 66?74,Suntec, Singapore, 7 August 2009.c?2009 ACL and AFNLPOpinion Graphs for Polarity and Discourse Classification?Swapna SomasundaranUniv.
of PittsburghPittsburgh, PA 15260swapna@cs.pitt.eduGalileo NamataUniv.
of MarylandCollege Park, MD 20742namatag@cs.umd.eduLise GetoorUniv.
of MarylandCollege Park, MD 20742getoor@cs.umd.eduJanyce WiebeUniv.
of PittsburghPittsburgh, PA 15260wiebe@cs.pitt.eduAbstractThis work shows how to constructdiscourse-level opinion graphs to performa joint interpretation of opinions and dis-course relations.
Specifically, our opiniongraphs enable us to factor in discourse in-formation for polarity classification, andpolarity information for discourse-linkclassification.
This inter-dependent frame-work can be used to augment and im-prove the performance of local polarityand discourse-link classifiers.1 IntroductionMuch research in opinion analysis has focused oninformation from words, phrases and semantic ori-entation lexicons to perform sentiment classifica-tion.
While these are vital for opinion analysis,they do not capture discourse-level associationsthat arise from relations between opinions.
To cap-ture this information, we propose discourse-levelopinion graphs for classifying opinion polarity.In order to build our computational model, wecombine a linguistic scheme opinion frames (So-masundaran et al, 2008) with a collective classifi-cation framework (Bilgic et al, 2007).
Accordingto this scheme, two opinions are related in the dis-course when their targets (what they are about) arerelated.
Further, these pair-wise discourse-levelrelations between opinions are either reinforcingor non-reinforcing frames.
Reinforcing framescapture reinforcing discourse scenarios where theindividual opinions reinforce one another, con-tributing to the same opinion polarity or stance.Non-reinforcing frames, on the other hand, cap-ture discourse scenarios where the individual opin-ions do not support the same stance.
The indi-vidual opinion polarities and the type of relation?This research was supported in part by the Departmentof Homeland Security under grant N000140710152.between their targets determine whether the dis-course frame is reinforcing or non-reinforcing.Our polarity classifier begins with informationfrom opinion lexicons to perform polarity classifi-cation locally at each node.
It then uses discourse-level links, provided by the opinion frames, totransmit the polarity information between nodes.Thus the opinion classification of a node is notjust dependent on its local features, but also on theclass labels of related opinions and the nature ofthese links.
We design two discourse-level linkclassifiers: the target-link classifier, which deter-mines if a given node pair has unrelated targets (nolink), or if their targets have a same or alternativerelation, and the frame-link classifier, which deter-mines if a given node pair has no link, reinforcingor non-reinforcing link relation.
Both these classi-fiers too first start with local classifiers that use lo-cal information.
The opinion graph then providesa means to factor in the related opinion informa-tion into the link classifiers.
Our approach enablesusing the information in the nodes (and links) toestablish or remove links in the graph.
Thus in-formation flows to and fro between all the opinionnodes and discourse-level links to achieve a jointinference.The paper is organized as follows: We first de-scribe opinion graphs, a structure that can capturediscourse-level opinion relationships in Section 2,and then describe our joint interpretation approachto opinion analysis in Section 3.
Next, we describeour algorithm for joint interpretation in Section 4.Our experimental results are reported in Section 5.We discuss related work in Section 6 and concludein Section 7.2 Discourse-Level Opinion GraphsThe pairwise relationships that compose opinionframes can be used to construct a graph over opin-ion expressions in a discourse, which we referto as the discourse-level opinion graph (DLOG).66Figure 1 Opinion Frame Annotations.In this section, we describe these graphs and il-lustrate their applicability to goal-oriented multi-party conversations.The nodes in the DLOG represent opinions, andthere are two kinds of links: target links and framelinks.
Each opinion node has a polarity (positive,negative or neutral) and type (sentiment or argu-ing).
Sentiment opinions are evaluations, feelingsor judgments about the target.
Arguing opinionsargue for or against something.
Target links arelabeled as either same or alternatives.
Same linkshold between targets that refer to the same en-tity or proposition, while alternative links hold be-tween targets that are related by virtue of being op-posing (mutually exclusive) options in the contextof the discourse.
The frame links correspond tothe opinion frame relation between opinions.We illustrate the construction of the opiniongraph with an example (Example 1, from Soma-sundaran et al (2008)) from a multi-party meet-ing corpus where participants discuss and design anew TV remote control.
The opinion expressionsare in bold and their targets are in italics.
Noticehere that speaker D has a positive sentiment to-wards the rubbery material for the TV remote.
(1) D:: ... this kind of rubbery material, it?s a bit morebouncy, like you said they get chucked around a lot.A bit more durable and that can also be ergonomicand it kind of feels a bit different from all the otherremote controls.All the individual opinions in this example areessentially regarding the same thing ?
the rub-bery material.
The speaker?s positive sentiment isapparent from the text spans bit more bouncy,bit more durable, ergonomic and a bit differentfrom all the other remote controls.
The explicittargets of these opinions (it?s, that, and it) and theimplicit target of ?a bit more durable?
are thus alllinked with same relations.Figure 1 illustrates the individual opinion anno-tations, target annotations (shown in italics) andthe relations between the targets (shown in dottedlines).
Note that the target of a bit more durableis a zero span ellipsis that refers back to the rub-bery material.
The opinion frames resulting fromthe individual annotations make pairwise connec-tions between opinion instances, as shown in boldlines in the figure.
For example, the two opinionsbit more bouncy and ergonomic, and the samelink between their targets (it?s and that), make upan opinion frame.
An opinion frame type is de-rived from the details (type and polarity) of theopinions it relates and the target relation involved.Even though the different combinations of opin-ion type (sentiment and arguing), polarity (posi-tive and negative) and target links (same and al-ternative) result in many distinct frames types (32in total), they can be grouped, according to theirdiscourse-level characteristics, into the two cat-egories reinforcing and non-reinforcing.
In thiswork, we only make this category distinction foropinion frames and the corresponding frame links.The next example (Example 2, also from So-masundaran et al (2008)) illustrates an alterna-tive target relation.
In the domain of TV remotecontrols, the set of all shapes are alternatives toone another, since a remote control may have onlyone shape at a time.
In such scenarios, a positiveopinion regarding one choice may imply a nega-tive opinion toward competing choices, and viceversa.
In this passage, speaker C?s positive stancetowards the curved shape is brought out even morestrongly with his negative opinions toward the al-ternative, square-like, shapes.
(2) C:: .
.
.
shapes should be curved, so round shapes.Nothing square-like....C:: .
.
.
So we shouldn?t have too square cornersand that kind of thing.The reinforcing frames characteristically showa reinforcement of an opinion or stance in the dis-course.
Both the examples presented above depicta reinforcing scenario.
In the first example, theopinion towards the rubbery material is reinforcedby repeated positive sentiments towards it, whilein the second example the positive stance towardsthe curved shapes is further reinforced by nega-tive opinions toward the alternative option.
Ex-amples of non-reinforcing scenarios are ambiva-lence between alternative options (for e.g., ?I likethe rubbery material but the plastic will be much67cheaper?)
or mixed opinions about the same tar-get (for e.g., weighing pros and cons ?The rubberymaterial is good but it will be just so expensive?
).3 Interdependent InterpretationOur interdependent interpretation in DLOGs ismotivated by the observation that, when two opin-ions are related, a clear knowledge of the polarityof one of them makes interpreting the other mucheasier.
For instance, suppose an opinion classi-fier wants to find the polarity of all the opinionexpressions in Example 1.
As a first step, it canlook up opinion lexicons to infer that words like?bouncy?, ?durable?
and ?
ergonomic?
are pos-itive.
However, ?a bit different ?
cannot be re-solved via this method, as its polarity can be dif-ferent in different scenarios.Suppose now we relate the targets of opinions.There are clues in the passage that the targets arerelated via the same relation; for instance theyare all third person pronouns occurring in adja-cent clauses and sentences.
Once we relate thetargets, the opinions of the passage are related viatarget links in the discourse opinion graph.
Weare also able to establish frames using the opinioninformation and target link information whereverthey are available, i.e., a reinforcing link betweenbit more bouncy and ergonomic.
For the placeswhere all the information is not available (betweenergonomic and a bit different) there are multiplepossibilities.
Depending on the polarity, either areinforcing frame (if a bit different has positivepolarity) or a non-reinforcing frame (if a bit dif-ferent has negative polarity) can exist.
There areclues in the discourse that this passage representsa reinforcing scenario.
For instance there are rein-forcing frames between the first few opinions, therepeated use of ?and?
indicates a list, conjunctionor expansion relation between clauses (accordingto the Penn Discourse TreeBank (PDTB) (Prasadet al, 2008)), and there is a lack of contrastiveclues that would indicate a change in the opin-ion.
Thus the reinforcing frame link emerges asbeing the most likely candidate.
This in turn dis-ambiguates the polarity of a bit different.
Thus,by establishing target links and frame links be-tween the opinion instances, we are able to per-form a joint interpretation of the opinions.The interdependent framework of this exampleis iterative and dynamic ?
the information in thenodes can be used to change the structure (i.e.,establish new links), and the structure provides aframework to change node polarity.
We build ourclassification framework and feature sets with re-spect to this general framework, where the nodelabels as well as the structure of the graph are pre-dicted in a joint manner.Thus our interdependent interpretation frame-work has three main units: an instance polarityclassifier (IPC), a target-link classifier (TLC), anda frame-link classifier (FLC).
IPC classifies eachnode (instance), which may be a sentence, utter-ance or an other text span, as positive, negativeor neutral.
The TLC determines if a given nodepair has related targets and whether they are linkedby a same or alternative relation.
The FLC deter-mines if a given node pair is related via frames,and whether it is a reinforcing or non-reinforcinglink.
As we saw in the example, there are localclues available for each unit to arrive at its classi-fication.
The discourse augments this informationto aid in further disambiguation.4 Collective Classification FrameworkFor our collective classification framework, weuse a variant of the iterative classification al-gorithm (ICA) proposed by Bilgic et al(2007).It combines several common prediction tasks ingraphs: object classification (predicting the labelof an object) and link prediction (predicting theexistence and class of a link between objects).For our tasks, object classification directly corre-sponds to predicting opinion polarity and the linkprediction corresponds to predicting the existenceof a same or alternative target link or a reinforc-ing or non-reinforcing frame link between opin-ions.
We note that given the nature of our problemformulation and approach, we use the terms linkprediction and link classification interchangeably.In the collective classification framework, thereare two sets of features to use.
The first are localfeatures which can be generated for each object orlink, independent of the links in which they par-ticipate, or the objects they connect.
For example,the opinion instance may contain words that oc-cur in sentiment lexicons.
The local features aredescribed in Section 4.2.
The second set of fea-tures, the relational features, reflect neighborhoodinformation in the graph.
For frame link classifi-cation, for example, there is a feature indicatingwhether the connected nodes are predicted to havethe same polarity.
The relational features are de-68scribed in Section 4.3.4.1 DLOG-ICA AlgorithmOur variant of the ICA algorithm begins by pre-dicting the opinion polarity, and link type usingonly the local features.
We then randomly orderthe set of all opinions and links and, in turn, pre-dict the polarity or class using the local featuresand the values of the currently predicted relationalfeatures based on previous predictions.
We repeatthis until some stopping criterion is met.
For ourexperiments, we use a fixed number of 30 itera-tions which was sufficient, in most of our datasets,for ICA to converge to a solution.
The pseudocodefor the algorithm is shown in Algorithm 4.1.Algorithm 1 DLOG-ICA Algorithmfor each opinion o do {bootstrapping}Compute polarity for o using local attributesend forfor each target link t do {bootstrapping}Compute label for t using local attributesend forfor each frame link f do {bootstrapping}Compute label for f using local attributesend forrepeat {iterative classification}Generate ordering I over all nodes and linksfor each i in I doif i is an opinion instance thenCompute polarity for i using local andrelational attributeselse if i is a target link thenCompute class for i using local and re-lational attributeselse if i is a frame link thenCompute class for i using local and re-lational attributesend ifend foruntil Stopping criterion is metThe algorithm is one very simple way of makingclassifications that are interdependent.
Once thelocal and relational features are defined, a varietyof classifiers can be used.
For our experiments, weuse SVMs.
Additional details are provided in theexperiments section.4.2 Local FeaturesFor the local polarity classifier, we employ opin-ion lexicons, dialog information, and unigram fea-Feature TaskTime difference between the node pair TLC, FLCNumber of intervening instances TLC, FLCContent word overlap between the node pair TLC,FLCFocus space overlap between the node pair TLC, FLCBigram overlap between the node pair * TLC, FLCAre both nodes from same speaker * TLC, FLCBag of words for each node TLC, FLCAnaphoric indicator in the second node TLCAdjacency pair between the node pair FLCDiscourse relation between node pair * FLCTable 1: Features and the classification task it is used for;TLC = target-link classification, FLC = Frame-link classifi-cationtures.
We use lexicons that have been success-fully used in previous work (the polarity lexiconfrom (Wilson et al, 2005) and the arguing lexi-con (Somasundaran et al, 2007)).
Previous workused features based on parse trees, e.g., (Wilson etal., 2005; Kanayama and Nasukawa, 2006), butour data has very different characteristics frommonologic texts ?
the utterances and sentences aremuch shorter, and there are frequent disfluencies,restarts, hedging and repetitions.
Because of this,we cannot rely on parsing features.
On the otherhand, in this data, we have dialog act information1(Dialog Acts), which we can exploit.
Note that theIPC uses only the Dialog Act tags (instance leveltags like Inform, Suggest) and not the dialog struc-ture information.Opinion frame detection between sentences hasbeen previously attempted (Somasundaran et al,2008) by using features that capture discourseand dialog continuity.
Even though our linkclassification tasks are not directly comparable(the previous work performs binary classifica-tion of frame-present/frame-absent between opin-ion bearing sentences, while this work performsthree-way classification: no-link/reinforcing/non-reinforcing between DA pairs), we adapt the fea-tures for the link classification tasks addressedhere.
These features depend on properties of thenodes that the link connects.
We also create somenew features that capture discourse relations andlexical overlap.Table 1 lists the link classification features.New features are indicated with a ?*?.
Continu-ous discourse indicators, like time difference be-tween the node pair and number of interveninginstances are useful for determining if the twonodes can be related.
The content word over-1Manual annotations for Dialog act tags and adjacencypairs are available for the AMI corpus.69lap, and focus space overlap features (the focusspace for an instance is a list of the most recentlyused NP chunks; i.e., NP chunks in that instanceand a few previous instances) capture the overlapin topicality within the node pair; while the bi-gram overlap feature captures the alignment be-tween instances in terms of function words as wellas content words.
The entity-level relations arecaptured by the anaphoric indicator feature thatchecks for the presence of pronouns such as it andthat in the second node in the node pair.
The adja-cency pair and discourse relation are actually fea-ture sets that indicate specific dialog-structure anddiscourse-level relations.
We group the list of dis-course relations from the PDTB into the followingsets: expansion, contingency, alternative, tempo-ral, comparison.
Each discourse relation in PDTBis associated with a list of discourse connectivewords.2Given a node pair, if the first word of thelater instance (or the last word first instance) is adiscourse connective word, then we assume thatthis node is connecting back (or forward) in thediscourse and the feature set to which the connec-tive belongs is set to true (e.g., if a latter instanceis ?because we should ...?, it starts with the con-nective ?because?, and connects backwards via acontingency relation).
The adjacency pair featureindicates the presence of a particular dialog struc-ture (e.g., support, positive-assessment) betweenthe nodes.4.3 Relational FeaturesIn addition to the local features, we introduce re-lational features (Table 2) that incorporate relatedclass information as well as transfer label informa-tion between classifiers.
As we saw in our examplein Figure 1, we need to know not only the polar-ity of the related opinions, but also the type of therelation between them.
For example, if the framerelation between ergonomic and a bit different isnon-reinforcing, then the polarity of a bit differ-ent is likely to be negative.
Thus link labels playan important role in disambiguating the polarity.Accordingly, our relational features transfer infor-mation of class labels from other instances of thesame classifier as well as between different clas-sifiers.
Table 2 lists our relational features.
Eachrow represents a set of features.
Features are gen-erated for all combinations of x, y and z for each2The PDTB provides a list of discourse connectives andthe list of discourse relations each connective signifies.row.
For example, one of the features in the firstrow is Number of neighbors with polarity type pos-itive, that are related via a reinforcing frame link.Thus each feature for the polarity classifier iden-tifies neighbors for a given node via a specific re-lation (z or y) and factors in their polarity values.Similarly, both link classifiers use polarity infor-mation of the node pair, and other link relationsinvolving the nodes of the pair.5 EvaluationWe experimentally test our hypothesis thatdiscourse-level information is useful and non-redundant with local information.
We also wantedto test how the DLOG performs for varyingamounts of available annotations: from full neigh-borhood information to absolutely no neighbor-hood information.Accordingly, for polarity classification, we im-plemented three scenarios: ICA-LinkNeigh, ICA-LinkOnly and ICA-noInfo.
The ICA-LinkNeighscenario measures the performance of the DLOGunder ideal conditions (full neighborhood infor-mation) ?
the structure of the graph (link infor-mation) as well as the neighbors?
class are pro-vided (by an oracle).
Here we do not need theTLC, or the FLC to predict links and the InstancePolarity Classifier (IPC) is not dependent on itspredictions from the previous iteration.
On theother hand, the ICA-noInfo scenario is the otherextreme, and has absolutely no neighborhood in-formation.
Each node does not know which nodesin the network it is connected to apriori, and alsohas no information about the polarity of any othernode in the network.
Here, the structure of thegraph, as well as the node classes, have to be in-ferred via the collective classification frameworkdescribed in Sections 3 and 4.
The ICA-LinkOnlyis an intermediate condition, and is representativeof scenarios where the discourse relationships be-tween nodes is known.
Here we start with the linkinformation (from an oracle) and the IPC uses thecollective classification framework to infer neigh-bor polarity information.Similarly, we vary the amounts of neighbor-hood information for the TLC and FLC classifiers.In the ICA-LinkNeigh condition, TLC and FLChave full neighborhood information.
In the ICA-noInfo condition, TLC and FLC are fully depen-dent on the classifications of the previous rounds.In the ICA-Partial condition, the TLC classifier70FeatureOpinion Polarity ClassificationNumber of neighbors with polarity type x linked via frame link zNumber of neighbors with polarity type x linked via target link yNumber of neighbors with polarity type x and same speaker linked via frame link zNumber of neighbors with polarity type x and same speaker linked via target link yTarget Link ClassificationPolarity of the DA nodesNumber of other target links y involving the given DA nodesNumber of other target links y involving the given DA nodes and other same-speaker nodesPresence of a frame link z between the nodesFrame Link ClassificationPolarity of the DA nodesNumber of other frame links z involving the given DA nodesNumber of other frame links z involving the given DA nodes and other same-speaker nodesPresence of a target link y between the nodesTable 2: Relational features: x ?
{non-neutral (i.e., positive or negative), positive, negative}, y ?
{same, alt}, z ?
{reinforcing, non-reinforcing}uses true frame-links and polarity information,and previous-stage classifications for informationabout neighborhood target links; the FLC classi-fier uses true target-links and polarity information,and previous-stage classifications for informationabout neighborhood frame-links.5.1 DataFor our experiments, we use the opinion frameannotations from previous work (Somasundaranet al, 2008).
These annotations consist of theopinion spans that reveal opinions, their targets,the polarity information for opinions, the labeledlinks between the targets and the frame links be-tween the opinions.
The annotated data consistsof 7 scenario-based, multi-party meetings from theAMI meeting corpus (Carletta et al, 2005).
Themanual Dialog Act (DA) annotations, provided byAMI, segment the meeting transcription into sep-arate dialog acts.
We use these DAs as nodes orinstances in our opinion graph.A DA is assigned the opinion orientation of thewords it contains (for example, if a DA contains apositive opinion expression, then the DA assignedthe positive opinion category).
We filter out verysmall DAs (DAs with fewer than 3 tokens, punctu-ation included) in order to alleviate data skewnessproblem in the link classifiers.
This gives us a to-tal of 4606 DA instances, of which 1935 (42%)have opinions.
Out of these 1935, 61.7% are posi-tive, 30% are negative and the rest are neutral.
TheDAs that do not have opinions are considered neu-tral, and have no links in the DLOG.
We createDA pairs by first ordering the DAs by their starttime, and then pairing a DA with five DAs beforeit, and five DAs after it.
The classes for target-link classification are no-link, same, alt.
The goldstandard target-link class is decided for a DA pairbased on the target link between the targets of theopinions contained in that pair.
Similarly, the la-bels for the frame-link labeling task are no-link,reinforcing, non-reinforcing.
The gold standardframe link class is decided for a DA pair based onthe frame between opinions contained by that pair.In our data, of the 4606 DAs, 1118 (24.27%) par-ticipate in target links with other DAs, and 1056(22.9%) form frame links.
The gold standard datafor links, which has pair-wise information, has atotal of 22,925 DA pairs, of which 1371 (6%) pairshave target links and 1264 (5.5%) pairs have framelinks.We perform 7-fold cross-validation experi-ments, using the 7 meetings.
In each fold, 6 meet-ings are used for training and one meeting is usedfor testing.5.2 ClassifiersOur baseline (Base) classifies the test data basedon the distribution of the classes in the trainingdata.
Note that due to the heavily skewed nature ofour link data, this classifier performs very poorlyfor minority class prediction, even though it mayachieve good overall accuracy.For our local classifiers, we used the classifiersfrom the Weka toolkit (Witten and Frank, 2002).For opinion polarity, we used the Weka?s SVMimplementation.
For the target link and frame linkclasses, the huge class skew caused SVM to learn atrivial model and always predict the majority class.To address this, we used a cost sensitive classifierin Weka where we set the cost of misclassifying aless frequent class, A, to a more frequent class, B,71Base Local ICALinkNeigh LinkOnly noInfoAcc 45.9 68.7 78.8 72.9 68.4Class: neutral (majority class)Prec 61.2 76.3 83.9 78.2 73.5Rec 61.5 83.9 89.6 89.1 86.6F1 61.1 79.6 86.6 83.2 79.3Class: positive polarityPrec 26.3 56.2 70.9 63.3 57.6Rec 26.1 46.6 62.0 47.0 42.8F1 25.8 50.4 65.9 53.5 48.5Class: negative polarityPrec 12.4 52.3 64.6 56.3 55.2Rec 12.2 44.3 60.2 48.2 38.2F1 12.2 46.0 61.9 51.2 43.9Table 3: Performance of Polarity Classifiersas |B|/|A| where |class| is the size of the class inthe training set.
All other misclassification costsare set to 1.For our collective classification, we use theabove classifiers for local features (l) and use sim-ilar, separate classifiers for relational features (r).For example, we learned an SVM for predictingopinion polarity using only the local features andlearned another SVM using only relational fea-tures.
For the ICA-noInfo condition, where weuse TLC and FLC classifiers, we combine thepredictions using a weighted combination whereP (class|l, r) = ?
?
P (class|l) + (1 ?
?)
?P (class|r).
This allows us to vary the influenceeach feature set has to the overall prediction.
Theresults for ICA-noInfo are reported on the best per-forming ?
(0.7).5.3 ResultsOur polarity classification results are presentedin Table 3, specifically accuracy (Acc), precision(Prec), recall (Rec) and F-measure (F1).
As wecan see, the results are mixed.
First, we no-tice that the Local classifier shows substantial im-provement over the baseline classifier.
This showsthat the lexical and dialog features we use are in-formative of opinion polarity in multi-party meet-ings.Next, notice that the ICA-LinkNeigh classifierperforms substantially better than the Local clas-sifier for all metrics and all classes.
The accuracyimproves by 10 percentage points, while the F-measure improves by about 15 percentage pointsfor the minority (positive and negative) classes.This result confirms that our discourse-level opin-ion graphs are useful and discourse-level informa-tion is non-redundant with lexical and dialog-actBase Local ICALinkNeigh Partial noInfoTLCAcc 88.5 85.8 98.1 98.2 86.3P-M 33.3 35.9 76.1 76.1 36.3R-M 33.3 38.1 78.1 78.1 38.1F1-M 33.1 36.0 74.6 74.6 36.5FLCAcc 89.3 86.2 98.9 98.9 87.6P-M 33.3 36.9 81.3 82.8 38.0R-M 33.4 41.2 82.2 84.4 41.7F1-M 33.1 37.2 80.7 82.3 38.1Table 4: Performance of Link Classifiersinformation.The results for ICA-LinkOnly follow the sametrend as for ICA-LinkNeigh, with a 3 to 5 percent-age point improvement.
These results show thateven when the neighbors?
classes are not knowna priori, joint inference using discourse-level rela-tions helps reduce errors from local classification.However, the performance of the ICA-noInfosystem, which is given absolutely no starting in-formation, is comparable to the Local classifier forthe overall accuracy and F-measure metrics for theneutral class.
There is slight improvement in pre-cision for both the positive and negative classes,but there is a drop in their recall.
The reason thisclassifier does no better than the Local classifier isbecause the link classifiers TLC and FLC predict?none?
predominantly due to the heavy class skew.The performance of the link classifiers are re-ported in Table 4, specifically the accuracy (Acc)and macro averages over all classes for preci-sion (P-M), recall (R-M) and F-measure (F1-M).Due to the heavy skew in the data, accuracyof all classifiers is high; however, the macro F-measure, which depends on the F1 of the minor-ity classes, is poor for the ICA-noInfo.
Note,however, that when we provide some (Partial) orfull (LinkNeigh) neighborhood information for theLink classifiers, the performance of these classi-fiers improve considerably.
This overall observedtrend is similar to that observed with the polarityclassifiers.6 Related WorkPrevious work on polarity disambiguation hasused contextual clues and reversal words (Wil-son et al, 2005; Kennedy and Inkpen, 2006;Kanayama and Nasukawa, 2006; Devitt and Ah-mad, 2007; Sadamitsu et al, 2008).
However,these do not capture discourse-level relations.72Polanyi and Zaenen (2006) observe that a cen-tral topic may be divided into subtopics in or-der to perform evaluations.
Similar to Somasun-daran et al (2008), Asher et al (2008) advo-cate a discourse-level analysis in order to get adeeper understanding of contextual polarity andthe strength of opinions.
However, these works donot provide an implementation for their insights.In this work we demonstrate a concrete way thatdiscourse-level interpretation can improve recog-nition of individual opinions and their polarities.Graph-based approaches for joint inference insentiment analysis have been explored previouslyby many researchers.
The biggest difference be-tween this work and theirs is in what the linksrepresent linguistically.
Some of these are notrelated to discourse at all (e.g., lexical similari-ties (Takamura et al, 2007), morphosyntactic sim-ilarities (Popescu and Etzioni, 2005) and wordbased measures like TF-IDF (Goldberg and Zhu,2006)).
Some of these work on sentence cohesion(Pang and Lee, 2004) or agreement/disagreementbetween speakers (Thomas et al, 2006; Bansalet al, 2008).
Our model is not based on sen-tence cohesion or structural adjacency.
The re-lations due to the opinion frames are based onrelationships between targets and discourse-levelfunctions of opinions being mutually reinforcingor non-reinforcing.
Adjacent instances need not berelated via opinion frames, while long distant rela-tions can be present if opinion targets are same oralternatives.
Also, previous efforts in graph-basedjoint inference in opinion analysis has been text-based, while our work is over multi-party conver-sations.McDonald et al (2007) propose a joint modelfor sentiment classification based on relations de-fined by granularity (sentence and document).Snyder and Barzilay (2007) combine an agree-ment model based on contrastive RST relationswith a local aspect (topic) model.
Their aspectswould be related as same and their high contrastrelations would correspond to (a subset of) thenon-reinforcing frames.In the field of product review mining, senti-ments and features (aspects or targets) have beenmined (for example, Yi et al (2003), Popescu andEtzioni (2005), and Hu and Liu (2006)).
More re-cently there has been work on creating joint mod-els of topic and sentiments (Mei et al, 2007; Titovand McDonald, 2008) to improve topic-sentimentsummaries.
We do not model topics; instead wedirectly model the relations between targets.
Thefocus of our work is to jointly model opinion po-larities via target relations.
The task of finding co-referent opinion topics by (Stoyanov and Cardie,2008) is similar to our target link classificationtask, and we use somewhat similar features.
Eventhough their genre is different, we plan to experi-ment with their full feature set for improving ourTLC system.Turning to collective classification, there havebeen various collective classification frameworksproposed (for example, Neville and Jensen (2000),Lu and Getoor (2003), Taskar et al (2004),Richardson and Domingos (2006)).
In this pa-per, we use an approach proposed by (Bilgic etal., 2007) which iteratively predicts class and linkexistence using local classifiers.
Other joint mod-els used in sentiment classification include the spinmodel (Takamura et al, 2007), relaxation labeling(Popescu and Etzioni, 2005), and label propaga-tion (Goldberg and Zhu, 2006).7 ConclusionThis work uses an opinion graph framework,DLOG, to create an interdependent classifica-tion of polarity and discourse relations.
We em-ployed this graph to augment lexicon-based meth-ods to improve polarity classification.
We foundthat polarity classification in multi-party conver-sations benefits from opinion lexicons, unigramand dialog-act information.
We found that theDLOGs are valuable for further improving polar-ity classification, even with partial neighborhoodinformation.
Our experiments showed three tofive percentage points improvement in F-measurewith link information, and 15 percentage pointimprovement with full neighborhood information.These results show that lexical and discourse in-formation are non-redundant for polarity classi-fication, and our DLOG, that employs both, im-proves performance.We discovered that link classification is a dif-ficult problem.
Here again, we found that by us-ing the DLOG framework, and using even partialneighborhood information, improvements can beachieved.ReferencesN.
Asher, F. Benamara, and Y. Mathieu.
2008.
Dis-tilling opinion in discourse: A preliminary study.73COLING-2008.M.
Bansal, C. Cardie, and L. Lee.
2008.
The power ofnegative thinking: Exploiting label disagreement inthe min-cut classification framework.
In COLING-2008.M.
Bilgic, G. M. Namata, and L. Getoor.
2007.
Com-bining collective classification and link prediction.In Workshop on Mining Graphs and Complex Struc-tures at the IEEE International Conference on DataMining.J.
Carletta, S. Ashby, S. Bourban, M. Flynn,M.
Guillemot, T. Hain, J. Kadlec, V. Karaiskos,W.
Kraaij, M. Kronenthal, G. Lathoud, M. Lincoln,A.
Lisowska, I. McCowan, W. Post, D. Reidsma, andP.
Wellner.
2005.
The AMI Meetings Corpus.
InProceedings of the Measuring Behavior Symposiumon ?Annotating and measuring Meeting Behavior?.A.
Devitt and K. Ahmad.
2007.
Sentiment polarityidentification in financial news: A cohesion-basedapproach.
In ACL 2007.A.
B. Goldberg and X. Zhu.
2006.
Seeing starswhen there aren?t many stars: Graph-based semi-supervised learning for sentiment categorization.
InHLT-NAACL 2006 Workshop on Textgraphs: Graph-based Algorithms for Natural Language Processing.M.
Hu and B. Liu.
2006.
Opinion extraction and sum-marization on the Web.
In 21st National Conferenceon Artificial Intelligence (AAAI-2006).H.
Kanayama and T. Nasukawa.
2006.
Fully auto-matic lexicon expansion for domain-oriented sen-timent analysis.
In EMNLP-2006, pages 355?363,Sydney, Australia.A.
Kennedy and D. Inkpen.
2006.
Sentiment classi-fication of movie reviews using contextual valenceshifters.
Computational Intelligence, 22(2):110?125.Q.
Lu and L. Getoor.
2003.
Link-based classification.In Proceedings of the International Conference onMachine Learning (ICML).R.
McDonald, K. Hannan, T. Neylon, M. Wells, andJ.
Reynar.
2007.
Structured models for fine-to-coarse sentiment analysis.
In ACL 2007.Q.
Mei, X. Ling, M. Wondra, H. Su, and C Zhai.
2007.Topic sentiment mixture: modeling facets and opin-ions in weblogs.
In WWW ?07.
ACM.J.
Neville and D. Jensen.
2000.
Iterative classifica-tion in relational data.
In In Proc.
AAAI-2000 Work-shop on Learning Statistical Models from RelationalData, pages 13?20.
AAAI Press.B.
Pang and L. Lee.
2004.
A sentimental education:Sentiment analysis using subjectivity summarizationbased on minimum cuts.
In ACl 2004.L.
Polanyi and A. Zaenen, 2006.
Contextual ValenceShifters.
Computing Attitude and Affect in Text:Theory and Applications.A.-M. Popescu and O. Etzioni.
2005.
Extracting prod-uct features and opinions from reviews.
In HLT-EMNLP 2005.R.
Prasad, A. Lee, N. Dinesh, E. Miltsakaki, G. Cam-pion, A. Joshi, and B. Webber.
2008.
Penn dis-course treebank version 2.0.
Linguistic Data Con-sortium.M.
Richardson and P. Domingos.
2006.
Markov logicnetworks.
Mach.
Learn., 62(1-2):107?136.K.
Sadamitsu, S. Sekine, and M. Yamamoto.
2008.Sentiment analysis based on probabilistic models us-ing inter-sentence information.
In LREC?08.B.
Snyder and R. Barzilay.
2007.
Multiple aspect rank-ing using the good grief algorithm.
In HLT 2007:NAACL.S.
Somasundaran, J. Ruppenhofer, and J. Wiebe.
2007.Detecting arguing and sentiment in meetings.
InSIGdial Workshop on Discourse and Dialogue 2007.S.
Somasundaran, J. Wiebe, and J. Ruppenhofer.
2008.Discourse level opinion interpretation.
In Coling2008.V.
Stoyanov and C. Cardie.
2008.
Topic identificationfor fine-grained opinion analysis.
In Coling 2008.H.
Takamura, T. Inui, and M. Okumura.
2007.
Extract-ing semantic orientations of phrases from dictionary.In HLT-NAACL 2007.B.
Taskar, M. Wong, P. Abbeel, and D. Koller.
2004.Link prediction in relational data.
In Neural Infor-mation Processing Systems.M.
Thomas, B. Pang, and L. Lee.
2006.
Get out thevote: Determining support or opposition from con-gressional floor-debate transcripts.
In EMNLP 2006.I.
Titov and R. McDonald.
2008.
A joint model of textand aspect ratings for sentiment summarization.
InACL 2008.T.
Wilson, J. Wiebe, and P. Hoffmann.
2005.
Recog-nizing contextual polarity in phrase-level sentimentanalysis.
In HLT-EMNLP 2005.I.
H. Witten and E. Frank.
2002.
Data mining: practi-cal machine learning tools and techniques with javaimplementations.
SIGMOD Rec., 31(1):76?77.J.
Yi, T. Nasukawa, R. Bunescu, and W. Niblack.
2003.Sentiment analyzer: Extracting sentiments about agiven topic using natural language processing tech-niques.
In ICDM-2003.74
