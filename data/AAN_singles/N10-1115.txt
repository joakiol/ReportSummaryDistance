Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 742?750,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsAn Efficient Algorithm for Easy-First Non-Directional Dependency ParsingYoav Goldberg?
and Michael ElhadadBen Gurion University of the NegevDepartment of Computer SciencePOB 653 Be?er Sheva, 84105, Israel{yoavg|elhadad}@cs.bgu.ac.ilAbstractWe present a novel deterministic dependency pars-ing algorithm that attempts to create the easiest arcsin the dependency structure first in a non-directionalmanner.
Traditional deterministic parsing algorithmsare based on a shift-reduce framework: they traversethe sentence from left-to-right and, at each step, per-form one of a possible set of actions, until a completetree is built.
A drawback of this approach is thatit is extremely local: while decisions can be basedon complex structures on the left, they can look onlyat a few words to the right.
In contrast, our algo-rithm builds a dependency tree by iteratively select-ing the best pair of neighbours to connect at eachparsing step.
This allows incorporation of featuresfrom already built structures both to the left and to theright of the attachment point.
The parser learns boththe attachment preferences and the order in whichthey should be performed.
The result is a determin-istic, best-first, O(nlogn) parser, which is signifi-cantly more accurate than best-first transition basedparsers, and nears the performance of globally opti-mized parsing models.1 IntroductionDependency parsing has been a topic of active re-search in natural language processing in the last sev-eral years.
An important part of this research effortare the CoNLL 2006 and 2007 shared tasks (Buch-holz and Marsi, 2006; Nivre et al, 2007), which al-lowed for a comparison of many algorithms and ap-proaches for this task on many languages.
?Supported by the Lynn and William Frankel Center forComputer Sciences, Ben Gurion UniversityCurrent dependency parsers can be categorizedinto three families: local-and-greedy transition-based parsers (e.g., MALTPARSER (Nivre et al,2006)), globally optimized graph-based parsers(e.g., MSTPARSER (McDonald et al, 2005)), andhybrid systems (e.g., (Sagae and Lavie, 2006b;Nivre and McDonald, 2008)), which combine theoutput of various parsers into a new and improvedparse, and which are orthogonal to our approach.Transition-based parsers scan the input from leftto right, are fast (O(n)), and can make use of richfeature sets, which are based on all the previouslyderived structures.
However, all of their decisionsare very local, and the strict left-to-right order im-plies that, while the feature set can use rich struc-tural information from the left of the current attach-ment point, it is also very restricted in informationto the right of the attachment point: traditionally,only the next two or three input tokens are avail-able to the parser.
This limited look-ahead windowleads to error propagation and worse performance onroot and long distant dependencies relative to graph-based parsers (McDonald and Nivre, 2007).Graph-based parsers, on the other hand, are glob-ally optimized.
They perform an exhaustive searchover all possible parse trees for a sentence, and findthe highest scoring tree.
In order to make the searchtractable, the feature set needs to be restricted to fea-tures over single edges (first-order models) or edgespairs (higher-order models, e.g.
(McDonald andPereira, 2006; Carreras, 2007)).
There are severalattempts at incorporating arbitrary tree-based fea-tures but these involve either solving an ILP prob-lem (Riedel and Clarke, 2006) or using computa-742(1) ATTACHRIGHT(2)a brown fox jumped with joy-157-27-68403-197-47-152-2432313(2) ATTACHRIGHT(1)a foxbrownjumped with joy-52314-1590-176-14624612(3) ATTACHRIGHT(1)foxa brownjumped with joy-133270-149-15424610(4) ATTACHLEFT(2)jumpedfoxa brownwith joy-161-435186-2(5) ATTACHLEFT(1)jumpedfoxa brownwithjoy430-232(6)jumpedfoxa brownwithjoyFigure 1: Parsing the sentence ?a brown fox jumped with joy?.
Rounded arcs represent possible actions.tionally intensive sampling-based methods (Naka-gawa, 2007).
As a result, these models, while accu-rate, are slow (O(n3) for projective, first-order mod-els, higher polynomials for higher-order models, andworse for richer tree-feature models).We propose a new category of dependency pars-ing algorithms, inspired by (Shen et al, 2007): non-directional easy-first parsing.
This is a greedy, de-terministic parsing approach, which relaxes the left-to-right processing order of transition-based pars-ing algorithms.
By doing so, we allow the ex-plicit incorporation of rich structural features de-rived from both sides of the attachment point, andimplicitly take into account the entire previously de-rived structure of the whole sentence.
This exten-sion allows the incorporation of much richer featuresthan those available to transition- and especially tograph-based parsers, and greatly reduces the local-ity of transition-based algorithm decisions.
On theother hand, it is still a greedy, best-first algorithmleading to an efficient implementation.We present a concrete O(nlogn) parsing algo-rithm, which significantly outperforms state-of-the-art transition-based parsers, while closing the gap tograph-based parsers.2 Easy-first parsingWhen humans comprehend a natural language sen-tence, they arguably do it in an incremental, left-to-right manner.
However, when humans consciouslyannotate a sentence with syntactic structure, theyhardly ever work in fixed left-to-right order.
Rather,they start by building several isolated constituentsby making easy and local attachment decisions andonly then combine these constituents into biggerconstituents, jumping back-and-forth over the sen-tence and proceeding from easy to harder phenom-ena to analyze.
When getting to the harder decisionsa lot of structure is already in place, and this struc-ture can be used in deciding a correct attachment.Our parser follows a similar kind of annotationprocess: starting from easy attachment decisions,and proceeding to harder and harder ones.
Whenmaking later decisions, the parser has access to theentire structure built in earlier stages.
During thetraining process, the parser learns its own notion ofeasy and hard, and learns to defer specific kinds ofdecisions until more structure is available.3 Parsing algorithmOur (projective) parsing algorithm builds the parsetree bottom up, using two kinds of actions: AT-TACHLEFT(i) and ATTACHRIGHT(i) .
Theseactions are applied to a list of partial structuresp1, .
.
.
, pk, called pending, which is initialized withthe n words of the sentence w1, .
.
.
, wn.
Each ac-743tion connects the heads of two neighbouring struc-tures, making one of them the parent of the other,and removing the daughter from the list of partialstructures.
ATTACHLEFT(i) adds a dependencyedge (pi, pi+1) and removes pi+1 from the list.
AT-TACHRIGHT(i) adds a dependency edge (pi+1, pi)and removes pi from the list.
Each action shortensthe list of partial structures by 1, and after n?1 suchactions, the list contains the root of a connected pro-jective tree over the sentence.Figure 1 shows an example of parsing the sen-tence ?a brown fox jumped with joy?.
The pseu-docode of the algorithm is given in Algorithm 1.Algorithm 1: Non-directional ParsingInput: a sentence= w1 .
.
.
wnOutput: a set of dependency arcs over thesentence (Arcs)Acts = {ATTACHLEFT, ATTACHRIGHT}1Arcs?
{}2pending = p1 .
.
.
pn ?
w1 .
.
.
wn3while length(pending) > 1 do4best?
arg maxact?Acts1?i?len(pending)score(act(i))5(parent, child)?
edgeFor(best)6Arcs.add( (parent, child) )7pending.remove(child)8end9return Arcs10edgeFor(act(i)) ={(pi, pi+1) ATTACHLEFT(i)(pi+1, pi) ATTACHRIGHT(i)At each step the algorithm chooses a spe-cific action/location pair using a functionscore(ACTION(i)), which assign scores to ac-tion/location pairs based on the partially builtstructures headed by pi and pi+1, as well as neigh-bouring structures.
The score() function is learnedfrom data.
This scoring function reflects not onlythe correctness of an attachment, but also the orderin which attachments should be made.
For example,consider the attachments (brown,fox) and (joy,with)in Figure (1.1).
While both are correct, the scoringfunction prefers the (adjective,noun) attachmentover the (prep,noun) attachment.
Moreover, theattachment (jumped,with), while correct, receivesa negative score for the bare preposition ?with?(Fig.
(1.1) - (1.4) ), and a high score once the verbhas its subject and the PP ?with joy?
is built (Fig.
(1.5) ).
Ideally, we would like to score easy andreliable attachments higher than harder less likelyattachments, thus performing attachments in orderof confidence.
This strategy allows us both to limitthe extent of error propagation, and to make use ofricher contextual information in the later, harderattachments.
Unfortunately, this kind of orderinginformation is not directly encoded in the data.
Wemust, therefore, learn how to order the decisions.We first describe the learning algorithm (Section4) and a feature representation (Section 5) which en-ables us to learn an effective scoring function.4 Learning AlgorithmWe use a linear model score(x) = ~w ?
?
(x), where?
(x) is a feature representation and ~w is a weightvector.
We write ?act(i) to denote the feature repre-sentation extracted for action act at location i. Themodel is trained using a variant of the structured per-ceptron (Collins, 2002), similar to the algorithm of(Shen et al, 2007; Shen and Joshi, 2008).
As usual,we use parameter averaging to prevent the percep-tron from overfitting.The training algorithm is initialized with a zeroparameter vector ~w.
The algorithm makes severalpasses over the data.
At each pass, we apply thetraining procedure given in Algorithm 2 to everysentence in the training set.At training time, each sentence is parsed using theparsing algorithm and the current ~w.
Whenever aninvalid action is chosen by the parsing algorithm, itis not performed (line 6).
Instead, we update the pa-rameter vector ~w by decreasing the weights of thefeatures associated with the invalid action, and in-creasing the weights for the currently highest scor-ing valid action.1 We then proceed to parse the sen-tence with the updated values.
The process repeatsuntil a valid action is chosen.Note that each single update does not guaranteethat the next chosen action is valid, or even differentthan the previously selected action.
Yet, this is stillan aggressive update procedure: we do not leave asentence until our parameters vector parses it cor-1We considered 3 variants of this scheme: (1) using the high-est scoring valid action, (2) using the leftmost valid action, and(3) using a random valid action.
The 3 variants achieved nearlyidentical accuracy, while (1) converged somewhat faster thanthe other two.744rectly, and we do not proceed from one partial parseto the next until ~w predicts a correct location/actionpair.
However, as the best ordering, and hence thebest attachment point is not known to us, we do notperform a single aggressive update step.
Instead, ouraggressive update is performed incrementally in aseries of smaller steps, each pushing ~w away frominvalid attachments and toward valid ones.
This waywe integrate the search of confident attachments intothe learning process.Algorithm 2: Structured perceptron trainingfor direction-less parser, over one sentence.Input: sentence,gold arcs,current ~w,featurerepresentation ?Output: weight vector ~wArcs?
{}1pending ?
sent2while length(pending) > 1 do3allowed?
{act(i)|isV alid(act(i), Gold,Arcs)}4choice?
arg maxact?Acts1?i?len(pending)~w ?
?act(i)5if choice ?
allowed then6(parent, child)?
edgeFor(choice)7Arcs.add( (parent, child) )8pending.remove(child)9else10good?
arg maxact(j)?allowed~w ?
?act(j)11~w ?
~w + ?good ?
?choice12end13return ~w14Function isValid(action,Gold,Arcs)(p, c)?
edgeFor(action)1if (?c?
: (c, c?)
?
Gold ?
(c, c?)
6?
Arcs)2?
(p, c) 6?
Gold thenreturn false3return true4The function isV alid(act(i), gold, arcs) (line 4)is used to decide if the chosen action/location pairis valid.
It returns True if two conditions apply: (a)(pi, pj) is present in gold, (b) all edges (2, pj) ingold are also in arcs.
In words, the function verifiesthat the proposed edge is indeed present in the goldparse and that the suggested daughter already foundall its own daughters.22This is in line with the Arc-Standard parsing strategy ofshift-reduce dependency parsers (Nivre, 2004).
We are cur-rently experimenting also with an Arc-Eager variant of the non-5 Feature RepresentationThe feature representation for an action can takeinto account the original sentence, as well asthe entire parse history: ?act(i) above is actually?
(act(i), sentence,Arcs, pending).We use binary valued features, and each feature isconjoined with the type of action.When designing the feature representation, wekeep in mind that our features should not only di-rect the parser toward desired actions and away fromundesired actions, but also provide the parser withmeans of choosing between several desired actions.We want the parser to be able to defer some desiredactions until more structure is available and a moreinformed prediction can be made.
This desire is re-flected in our choice of features: some of our fea-tures are designed to signal to the parser the pres-ence of possibly ?incomplete?
structures, such as anincomplete phrase, a coordinator without conjuncts,and so on.When considering an action ACTION(i), we limitourselves to features of partial structures around theattachment point: pi?2, pi?1, pi, pi+1, pi+2, pi+3,that is the two structures which are to be attached bythe action (pi and pi+1), and the two neighbouringstructures on each side3.While these features encode local context, it is lo-cal in terms of syntactic structure, and not purely interms of sentence surface form.
This let us capturesome, though not all, long-distance relations.For a partial structure p, we use wp to refer tothe head word form, tp to the head word POS tag,and lcp and rcp to the POS tags of the left-most andright-most child of p respectively.All our prepositions (IN) and coordinators (CC)are lexicalized: for them, tp is in fact wptp.We define structural, unigram, bigram and pp-attachment features.The structural features are: the length of thestructures (lenp), whether the structure is a word(contains no children: ncp), and the surface distancebetween structure heads (?pipj ).
The unigram andbigram features are adapted from the feature set forleft-to-right Arc-Standard dependency parsing de-directional algorithm.3Our sentences are padded from each side with sentence de-limiter tokens.745Structuralfor p in pi?2, pi?1, pi, pi+1, pi+2, pi+3 lenp , ncpfor p,q in (pi?2, pi?1),(pi?1, pi),(pi, pi+1),(pi+1, pi+ 2),(pi+2, pi+3) ?qp , ?qptptqUnigramfor p in pi?2, pi?1, pi, pi+1, pi+2, pi+3 tp , wp , tplcp , tprcp , tprcplcpBigramfor p,q in (pi, pi+1),(pi, pi+2),(pi?1, pi),(pi?1, pi+2),(pi+1, pi+2) tptq , wpwq , tpwq , wptqtptqlcplcq , tptqrcplcqtptqlcprcq , tptqrcprcqPP-Attachmentif pi is a preposition wpi?1wpircpi , tpi?1wpircwpiif pi+1 is a preposition wpi?1wpi+1rcpi+1 , tpi?1wpi+1rcwpi+1wpiwpi+1rcpi+1 , tpiwpi+1rcwpi+1if pi+2 is a preposition wpi+1wpi+2rcpi+2 , tpi+1wpi+2rcwpi+2wpiwpi+2rcpi+2 , tpiwpi+2rcwpi+2Figure 2: Feature Templatesscribed in (Huang et al, 2009).
We extended thatfeature set to include the structure on both sides ofthe proposed attachment point.In the case of unigram features, we added featuresthat specify the POS of a word and its left-most andright-most children.
These features provide the non-directional model with means to prefer some attach-ment points over others based on the types of struc-tures already built.
In English, the left- and right-most POS-tags are good indicators of constituency.The pp-attachment features are similar to the bi-gram features, but fire only when one of the struc-tures is headed by a preposition (IN).
These featuresare more lexicalized than the regular bigram fea-tures, and include also the word-form of the right-most child of the PP (rcwp).
This should help themodel learn lexicalized attachment preferences suchas (hit, with-bat).Figure 2 enumerate the feature templates we use.6 Computational Complexity and EfficientImplementationThe parsing algorithm (Algorithm 1) begins withn+1 disjoint structures (the words of the sentence +ROOT symbol), and terminates with one connectedstructure.
Each iteration of the main loop connectstwo structures and removes one of them, and so theloop repeats for exactly n times.The argmax in line 5 selects the maximal scoringaction/location pair.
At iteration i, there are n ?
ilocations to choose from, and a naive computation ofthe argmax isO(n), resulting in anO(n2) algorithm.Each performed action changes the partial struc-tures and with it the extracted features and the com-puted scores.
However, these changes are limitedto a fixed local context around the attachment pointof the action.
Thus, we observe that the feature ex-traction and score calculation can be performed oncefor each action/location pair in a given sentence, andreused throughout all the iterations.
After each iter-ation we need to update the extracted features andcalculated scores for only k locations, where k is afixed number depending on the window size used inthe feature extraction, and usually k  n.Using this technique, we perform only (k + 1)nfeature extractions and score calculations for eachsentence, that is O(n) feature-extraction operationsper sentence.Given the scores for each location, the argmax canthen be computed in O(logn) time using a heap,resulting in an O(nlogn) algorithm: n iterations,where the first iteration involves n feature extrac-tion operations and n heap insertions, and each sub-sequent iteration involves k feature extractions andheap updates.We note that the dominating factor in polynomial-time discriminative parsers, is by far the feature-extraction and score calculation.
It makes sense tocompare parser complexity in terms of these opera-tions only.4 Table 1 compares the complexity of our4Indeed, in our implementation we do not use a heap, andopt instead to find the argmax using a simple O(n) max oper-ation.
This O(n2) algorithm is faster in practice than the heapbased one, as both are dominated by the O(n) feature extrac-tion, while the cost of the O(n) max calculationis negligiblecompared to the constants involved in heap maintenance.746parser to other dependency parsing frameworks.Parser Runtime Features / ScoringMALT O(n) O(n)MST O(n3) O(n2)MST2 O(n3) O(n3)BEAM O(n ?
beam) O(n ?
beam)NONDIR (This Work) O(nlogn) O(n)Table 1: Complexity of different parsing frameworks.MST: first order MST parser, MST2: second order MSTparser, MALT: shift-reduce left-to-right parsing.
BEAM:beam search parser, as in (Zhang and Clark, 2008)In terms of feature extraction and score calcula-tion operations, our algorithm has the same cost astraditional shift-reduce (MALT) parsers, and is anorder of magnitude more efficient than graph-based(MST) parsers.
Beam-search decoding for left-to-right parsers (Zhang and Clark, 2008) is also linear,but has an additional linear dependence on the beam-size.
The reported results in (Zhang and Clark,2008) use a beam size of 64, compared to our con-stant of k = 6.Our Python-based implementation5 (the percep-tron is implemented in a C extension module) parsesabout 40 tagged sentences per second on an Intelbased MacBook laptop.7 Experiments and ResultsWe evaluate the parser using the WSJ Treebank.
Thetrees were converted to dependency structures withthe Penn2Malt conversion program,6 using the head-finding rules from (Yamada and Matsumoto, 2003).7We use Sections 2-21 for training, Section 22 fordevelopment, and Section 23 as the final test set.The text is automatically POS tagged using a trigramHMM based POS tagger prior to training and pars-ing.
Each section is tagged after training the taggeron all other sections.
The tagging accuracy of thetagger is 96.5 for the training set and 96.8 for thetest set.
While better taggers exist, we believe thatthe simpler HMM tagger overfits less, and is more5http://www.cs.bgu.ac.il/?yoavg/software/6http://w3.msi.vxu.se/?nivre/research/Penn2Malt.html7While other and better conversions exist (see, e.g., (Johans-son and Nugues, 2007; Sangati and Mazza, 2009)), this con-version heuristic is still the most widely used.
Using the sameconversion facilitates comparison with previous works.representative of the tagging performance on non-WSJ corpus texts.Parsers We evaluate our parser against thetransition-based MALT parser and the graph-basedMST parser.
We use version 1.2 of MALT parser8,with the settings used for parsing English in theCoNLL 2007 shared task.
For the MST parser9,we use the default first-order, projective parser set-tings, which provide state-of-the-art results for En-glish.
All parsers are trained and tested on the samedata.
Our parser is trained for 20 iterations.Evaluation Measures We evaluate the parsers usingthree common measures:(unlabeled) Accuracy: percentage of tokens whichgot assigned their correct parent.Root: The percentage of sentences in which theROOT attachment is correct.Complete: the percentage of sentences in which alltokens were assigned their correct parent.Unlike most previous work on English dependencyparsing, we do not exclude punctuation marks fromthe evaluation.Results are presented in Table 2.
Our non-directional easy-first parser significantly outper-forms the left-to-right greedy MALT parser in termsof accuracy and root prediction, and significantlyoutperforms both parsers in terms of exact match.The globally optimized MST parser is better in root-prediction, and slightly better in terms of accuracy.We evaluated the parsers also on the Englishdataset from the CoNLL 2007 shared task.
Whilethis dataset is also derived from the WSJ Treebank, itdiffers from the previous dataset in two important as-pects: it is much smaller in size, and it is created us-ing a different conversion procedure, which is morelinguistically adequate.
For these experiments, weuse the dataset POS tags, and the same parameters asin the previous set of experiments: we train the non-directional parser for 20 iterations, with the samefeature set.
The CoNLL dataset contains some non-projective constructions.
MALT and MST deal withnon-projectivity.
For the non-directional parser, weprojectivize the training set prior to training usingthe procedure described in (Carreras, 2007).Results are presented in Table 3.8http://maltparser.org/dist/1.2/malt-1.2.tar.gz9http://sourceforge.net/projects/mstparser/747Parser Accuracy Root CompleteMALT 88.36 87.04 34.14MST 90.05 93.95 34.64NONDIR (this work) 89.70 91.50 37.50Table 2: Unlabeled dependency accuracy on PTB Section23, automatic POS-tags, including punctuation.Parser Accuracy Root CompleteMALT 85.82 87.85 24.76MST 89.08 93.45 24.76NONDIR (this work) 88.34 91.12 29.43Table 3: Unlabeled dependency accuracy on CoNLL2007 English test set, including punctuation.While all models suffer from the move to thesmaller dataset and the more challenging annotationscheme, the overall story remains the same: the non-directional parser is better than MALT but not asgood as MST in terms of parent-accuracy and rootprediction, and is better than both MALT and MSTin terms of producing complete correct parses.That the non-directional parser has lower accu-racy but more exact matches than the MST parsercan be explained by it being a deterministic parser,and hence still vulnerable to error propagation: onceit erred once, it is likely to do so again, result-ing in low accuracies for some sentences.
How-ever, due to the easy-first policy, it manages to parsemany sentences without a single error, which leadto higher exact-match scores.
The non-directionalparser avoids error propagation by not making theinitial error.
On average, the non-directional parsermanages to assign correct heads to over 60% of thetokens before making its first error.The MST parser would have ranked 5th in theshared task, and NONDIR would have ranked 7th.The better ranking systems in the shared taskare either higher-order global models, beam-searchbased systems, or ensemble-based systems, all ofwhich are more complex and less efficient than theNONDIR parser.Parse Diversity The parses produced by the non-directional parser are different than the parses pro-duced by the graph-based and left-to-right parsers.To demonstrate this difference, we performed an Or-acle experiment, in which we combine the output ofseveral parsers by choosing, for each sentence, theparse with the highest score.
Results are presentedCombination Accuracy CompletePenn2Malt, Train 2-21, Test 23MALT+MST 92.29 44.03NONDIR+MALT 92.19 45.48NONDIR+MST 92.53 44.41NONDIR+MST+MALT 93.54 49.79CoNLL 2007MALT+MST 91.50 33.64NONDIR+MALT 91.02 34.11NONDIR+MST 91.90 34.11NONDIR+MST+MALT 92.70 38.31Table 4: Parser combination with Oracle, choosing thehighest scoring parse for each sentence of the test-set.in Table 4.A non-oracle blending of MALT+MST+NONDIRusing Sagae and Lavie?s (2006) simplest combina-tion method assigning each component the sameweight, yield an accuracy of 90.8 on the CoNLL2007 English dataset, making it the highest scoringsystem among the participants.7.1 Error Analysis / LimitationsWhen we investigate the POS category of mistakeninstances, we see that for all parsers, nodes withstructures of depth 2 and more which are assignedan incorrect head are predominantly PPs (headedby ?IN?
), followed by NPs (headed by ?NN?).
Allparsers have a hard time dealing with PP attachment,but MST parser is better at it than NONDIR, and bothare better than MALT.Looking further at the mistaken instances, we no-tice a tendency of the PP mistakes of the NONDIRparser to involve, before the PP, an NP embeddedin a relative clause.
This reveals a limitation of ourparser: recall that for an edge to be built, the childmust first acquire all its own children.
This meansthat in case of relative clauses such as ?I saw theboy [who ate the pizza] with my eyes?, the parsermust decide if the PP ?with my eyes?
should be at-tached to ?the pizza?
or not before it is allowed tobuild parts of the outer NP (?the boy who.
.
.
?).
Inthis case, the verb ?saw?
and the noun ?boy?
areboth outside of the sight of the parser when decid-ing on the PP attachment, and it is forced to make adecision in ignorance, which, in many cases, leadsto mistakes.
The globally optimized MST does notsuffer as much from such cases.
We plan to addressthis deficiency in future work.7488 Related WorkDeterministic shift-reduce parsers are restricted by astrict left-to-right processing order.
Such parsers canrely on rich syntactic information on the left, but noton the right, of the decision point.
They are forcedto commit early, and suffer from error propagation.Our non-directional parser addresses these deficien-cies by discarding the strict left-to-right processingorder, and attempting to make easier decisions be-fore harder ones.
Other methods of dealing withthese deficiencies were proposed over the years:Several Passes Yamada and Matsumoto?s (2003)pioneering work introduces a shift-reduce parserwhich makes several left-to-right passes over a sen-tence.
Each pass adds structure, which can then beused in subsequent passes.
Sagae and Lavie (2006b)extend this model to alternate between left-to-rightand right-to-left passes.
This model is similar toours, in that it attempts to defer harder decisions tolater passes over the sentence, and allows late deci-sions to make use of rich syntactic information (builtin earlier passes) on both sides of the decision point.However, the model is not explicitly trained to op-timize attachment ordering, has an O(n2) runtimecomplexity, and produces results which are inferiorto current single-pass shift-reduce parsers.Beam Search Several researchers dealt with theearly-commitment and error propagation of deter-ministic parsers by extending the greedy decisionswith various flavors of beam-search (Sagae andLavie, 2006a; Zhang and Clark, 2008; Titov andHenderson, 2007).
This approach works well andproduces highly competitive results.
Beam searchcan be incorporated into our parser as well.
We leavethis investigation to future work.Strict left-to-right ordering is also prevalent in se-quence tagging.
Indeed, one major influence onour work is Shen et.al.
?s bi-directional POS-taggingalgorithm (Shen et al, 2007), which combines aperceptron learning procedure similar to our ownwith beam search to produce a state-of-the-art POS-tagger, which does not rely on left-to-right process-ing.
Shen and Joshi (2008) extends the bidirectionaltagging algorithm to LTAG parsing, with good re-sults.
We build on top of that work and present aconcrete and efficient greedy non-directional depen-dency parsing algorithm.Structure Restrictions Eisner and Smith (2005)propose to improve the efficiency of a globally op-timized parser by posing hard constraints on thelengths of arcs it can produce.
Such constraintspose an explicit upper bound on parser accuracy.10Our parsing model does not pose such restrictions.Shorter edges are arguably easier to predict, and ourparses builds them early in time.
However, it isalso capable of producing long dependencies at laterstages in the parsing process.
Indeed, the distribu-tion of arc lengths produced by our parser is similarto those produced by the MALT and MST parsers.9 DiscussionWe presented a non-directional deterministic depen-dency parsing algorithm, which is not restricted bythe left-to-right parsing order of other deterministicparsers.
Instead, it works in an easy-first order.
Thisstrategy allows using more context at each decision.The parser learns both what and when to connect.We show that this parsing algorithm significantlyoutperforms a left-to-right deterministic algorithm.While it still lags behind globally optimized pars-ing algorithms in terms of accuracy and root pre-diction, it is much better in terms of exact match,and much faster.
As our parsing framework can eas-ily and efficiently utilize more structural informationthan globally optimized parsers, we believe that withsome enhancements and better features, it can out-perform globally optimized algorithms, especiallywhen more structural information is needed, such asfor morphologically rich languages.Moreover, we show that our parser producesdifferent structures than those produced by bothleft-to-right and globally optimized parsers, mak-ing it a good candidate for inclusion in an ensem-ble system.
Indeed, a simple combination schemeof graph-based, left-to-right and non-directionalparsers yields state-of-the-art results on English de-pendency parsing on the CoNLL 2007 dataset.We hope that further work on this non-directionalparsing framework will pave the way to better under-standing of an interesting cognitive question: whichkinds of parsing decisions are hard to make, andwhich linguistic constructs are hard to analyze?10In (Dreyer et al, 2006), constraints are chosen ?to be theminimum value that will allow recovery of 90% of the left(right) dependencies in the training corpus?.749ReferencesSabine Buchholz and Erwin Marsi.
2006.
CoNLL-Xshared task on multilingual dependency parsing.
InProc.
of CoNLL.Xavier Carreras.
2007.
Experiments with a higher-orderprojective dependency parser.
In Proc.
of CoNLLShared Task, EMNLP-CoNLL.Michael Collins.
2002.
Discriminative training methodsfor hidden markov models: Theory and experimentswith perceptron algorithms.
In Proc of EMNLP.Markus Dreyer, David A. Smith, and Noah A. Smith.2006.
Vine parsing and minimum risk reranking forspeed and precision.
In Proc.
of CoNLL, pages 201?205, Morristown, NJ, USA.
Association for Computa-tional Linguistics.Jason Eisner and Noah A. Smith.
2005. arsing with softand hard constraints on dependency length.
In Proc.of IWPT.Liang Huang, Wenbin Jiang, and Qun Liu.
2009.Bilingually-constrained (monolingual) shift-reduceparsing.
In Proc of EMNLP.Richard Johansson and Pierre Nugues.
2007.
Extendedconstituent-to-dependency conversion for english.
InProc of NODALIDA.Ryan McDonald and Joakim Nivre.
2007.
Characteriz-ing the errors of data-driven dependency parsing mod-els.
In Proc.
of EMNLP.Ryan McDonald and Fernando Pereira.
2006.
On-line learning of approximate dependency parsing al-gorithms.
In Proc of EACL.Ryan McDonald, Koby Crammer, and Fernando Pereira.2005.
Online large-margin training of dependencyparsers.
In Proc of ACL.Tetsuji Nakagawa.
2007.
Multilingual dependency pars-ing using global features.
In Proc.
of EMNLP-CoNLL.Joakim Nivre and Ryan McDonald.
2008.
Integratinggraph-based and transition-based dependency parsers.In Proc.
of ACL, pages 950?958, Columbus, Ohio,June.
Association for Computational Linguistics.Joakim Nivre, Johan Hall, and Jens Nillson.
2006.
Malt-Parser: A data-driven parser-generator for dependencyparsing.
In Proc.
of LREC.Joakim Nivre, Johan Hall, Sandra Ku?bler, Ryan Mcdon-ald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret.2007.
The CoNLL 2007 shared task on dependencyparsing.
In Proc.
of EMNLP-CoNLL.Joakim Nivre.
2004.
Incrementality in deterministic de-pendency parsing.
In Incremental Parsing: BringingEngineering and Cognition Together, ACL-Workshop.Sebastian Riedel and James Clarke.
2006.
Incrementalinteger linear programming for non-projective depen-dency parsing.
In Proc.
of EMNLP 2006, July.Kenji Sagae and Alon Lavie.
2006a.
A best-first proba-bilistic shift-reduce parser.
In Proc of ACL.Kenji Sagae and Alon Lavie.
2006b.
Parser combinationby reparsing.
In Proc of NAACL.Federico Sangati and Chiara Mazza.
2009.
An englishdependency treebank a` la tesnie`re.
In Proc of TLT8.Libin Shen and Aravind K. Joshi.
2008.
Ltag depen-dency parsing with bidirectional incremental construc-tion.
In Proc of EMNLP.Libin Shen, Giorgio Satta, and Aravind K. Joshi.
2007.Guided learning for bidirectional sequence classifica-tion.
In Proc of ACL.Ivan Titov and James Henderson.
2007.
Fast and robustmultilingual dependency parsing with a generative la-tent variable model.
In Proc.
of EMNLP-CoNLL.Yamada and Matsumoto.
2003.
Statistical dependencyanalysis with support vector machines.
In Proc.
ofIWPT.Yue Zhang and Stephen Clark.
2008.
A tale oftwo parsers: investigating and combining graph-basedand transition-based dependency parsing using beam-search.
In Proc of EMNLP.750
