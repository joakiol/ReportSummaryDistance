Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 74?78,Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational LinguisticsThe Effect of Cognitive Load on a Statistical Dialogue SystemM.
Gas?ic?
?, P.
Tsiakoulis?, M.
Henderson?, B.
Thomson?, K.
Yu?, E.
Tzirkel??
and S.
Young?
?Cambridge University Engineering DepartmentTrumpington Street, Cambridge CB2 1PZ, UK{mg436, pt344, mh521, brmt2, ky219, sjy}@eng.cam.ac.uk?
?General Motors Advanced Technical Centre, Israeleli.tzirkel@gm.comAbstractIn recent years statistical dialogue systemshave gained significant attention due to theirpotential to be more robust to speech recogni-tion errors.
However, these systems must alsobe robust to changes in user behaviour causedby cognitive loading.
In this paper, a statisticaldialogue system providing restaurant informa-tion is evaluated in a set-up where the sub-jects used a driving simulator whilst talking tothe system.
The influences of cognitive load-ing were investigated and some clear differ-ences in behaviour were discovered.
In partic-ular, it was found that users chose to respondto different system questions and use differentspeaking styles, which indicate the need for anincremental dialogue approach.1 IntroductionA spoken dialogue system enables a user to obtaininformation while using their hands to perform someother task, which in many cases is the user?s primarytask.
A typical example is an in-car spoken dialoguesystem where the spoken interaction is secondary tothe main task of driving the car (Weng et al, 2004).This domain is particularly challenging since it in-volves dealing with the errors caused by the varyingnoise levels and changes in user behaviour causedby the cognitive load.A statistical approach to dialogue modelling hasbeen proposed as a means of automatically optimis-ing dialogue policies.
In particular, the partially ob-servable Markov decision process (POMDP) modelfor dialogue provides a representation of varyinglevels of uncertainty of the user input, yielding morerobust dialogue policies (Williams and Young, 2007;Thomson and Young, 2010; Young et al, 2010).Another thread of research deals with speechinterfaces for in-car applications, see (Baron andGreen, 2006) for a review.
Past research has inves-tigated the extent to which speaking is cognitivelyless demanding than typing (Gartner et al, 2001;Tsimhoni et al, 2004; Kun et al, 2007).
In addi-tion, considerable research has examined how driv-ing safety is influenced by a dialogue system (Laiet al, 2001; Lee et al, 2001; Nielsen et al, 2008).However, to the best of our knowledge, little workhas been done to investigate the effect of the cog-nitive load when interacting with a real conversa-tional spoken dialogue system.
The work presentedin (Mishra et al, 2004) suggests that the user speechis more disfluent when the user is performing an-other task.
However, this work is based on a Wiz-ard of Oz framework, where a human provides thesystem?s responses.
Also, a push-to-talk button wasused for every utterance which will have affected thenatural flow of the dialogue.
It is important to knowif the change of cognitive load has an effect on thespeaking style and whether the system can alter itsbehaviour to accommodate for this.In this paper we try to answer these questions byexamining dialogues where users drove a car simu-lator and talked to an open-microphone fully auto-mated spoken dialogue system at the same time.The rest of the paper is organised as follows.
Sec-tion 2 provides an overview of the dialogue systemused and section 3 describes the evaluation set-up.The analysis of the results is given in Section 4.
Sec-tion 5 concludes the paper.74Table 1: Example dialogue taskYou are looking for a cheap restaurant and itshould be in the east part of town.
Make sure youget the address of the venue.2 System overviewThe user speaks to the system, and the acoustic sig-nal is converted by the speech recogniser into a setof sentence hypotheses, which represents a proba-bility distribution over all possible things that theuser might have said.
The sentence hypotheses areconverted into an N-best list of dialogue acts by asemantic decoder.
Since the dialogue state cannotbe directly observed it maintains a probability dis-tribution over all states, which is called the beliefstate.
The belief state is updated at every user turnusing Bayesian inference treating the input dialogueacts as evidence.
Based on belief state, the optimalsystem act is selected using a policy and which istrained automatically using reinforcement learning.The abstract system dialogue act is converted to anappropriate utterance by a natural language genera-tor and then converted to speech by an HMM-basedspeech synthesiser.
To enable in-car speech inter-action via mobile phone, a VoIP interface is imple-mented.
The domain is Cambridge restaurant infor-mation with a database of about 150 venues and 7slots that users can query.3 Evaluation set-upOur goal is to understand system performancewhen driving.
However, due to the safety restric-tions, performance was tested using a driving simu-lator.
The following sections explain the set-up.3.1 Car simulatorThe car simulator used in the evaluation was thesame as in (Davies and Robinson, 2011).
It con-sists of a seat, a steering wheel and pedals, whichgive a realistic cab-like environment for the par-ticipants.
There is also a projection screen whichlargely fills the visual field of the driver.
The sim-ulation software is a modified version of RockstarGames?
Grand Theft Auto: San Andreas, with over500 km of roads.
For the purpose of the evaluation,the subjects were asked to drive on the main motor-way, to keep the lane and not to drive over 70mph.3.2 SubjectsFor the study 28 subjects were recruited, 22 wherenative speakers.
Each subject had to complete threescenarios: (1) to drive the car simulator for 10 min-utes, (2) to talk to the system for 7 dialogues and (3)to talk to the system for 7 dialogues while driving.The scenarios were in counter-balanced order.While they were driving, the speed and the roadposition were recorded.
If the scenario involvedtalking to the system, the instructor read out the di-alogue task (see an example in Table 1) and dialledthe phone number.
In addition, the subject had thedialogue task displayed on a small screen next to thedriving wheel.
The subject talked to the system us-ing loud speaker mode on the mobile phone.4 ResultsTo examine the influence of cognitive load, thefollowing examinations were performed.
First, weinvestigate if the subjects felt any change in the cog-nitive load (Section 4.1).
Then, in Section 4.2, weexamine how the driving was influenced by the sub-jects talking to the system.
Finally, we investigatehow successfully the subjects were able to completethe dialogue tasks while driving (Section 4.3).
Thisis followed with an examination of the conversa-tional patterns that occurred when the subjects weredriving whilst talking to the system (Section 4.4).4.1 Cognitive loadAfter each scenario the subjects were asked to an-swer five questions based on the NASA-TLX self-reporting scheme for workload measurement.
Theyanswered by providing a rating from 1 (very easy)to 5 (very hard).
The averaged results are givenin Table 2.
We performed a Kruskal test, followedby pairwise comparisons for every scenario for eachanswer and all differences are statistically signifi-cant (p < 0.03) apart from the differences in thefrustration, the stress and the pace between talkingand talking and driving.
This means that they wereclearly able to feel the change in cognitive load.75Table 2: Subjective evaluation of the cognitive loadDriving Talking Talking&DrivingHow mentally demanding was the scenario?1.61 2.21 2.89How hurried was the pace of the scenario?1.21 1.71 1.89How hard did you have to work?1.5 2.32 2.96How frustrated did you feel during the task?1.29 2.61 2.61How stressed did you feel during the task?1.29 2.0 2.32Table 3: Analysis of driving speed to determine whichmeasures are larger for Talking&Driving than DrivingMeasure Percentage ofusersConfidence in-tervalHigher speed 8% [1%, 25%]Larger std.dev 77% [56%, 91%]Larger entropy 85% [65%, 95%]4.2 Driving performanceFor 26 subjects we recorded position on the roadand the speed.
Since these measurements vary sig-nificantly across the subjects, for each subject wecalculated the average speed, the standard deviationand the entropy and similarly for the average posi-tion in the lane.
For the speed, we computed howmany subjects had a higher average speed when theywere talking and driving versus when they were justtalking and similarly for the standard deviation andthe entropy.
The results are given in Table 3.
Itcan be seen that the user?s speed is lower when theyare driving and talking, however, the increase in thestandard deviation and the entropy suggest that theirdriving is more erratic.
No significant differenceswere observed for the road position.4.3 Dialogue task completionEach participant performed 14 dialogues, 7 for eachscenario.
In total, there were 196 dialogues per sce-nario.
After each dialogue they told the instruc-tor if they thought the dialogue was successful, andthis information was used to compute the subjectiveTable 4: Subjective and Objective Task completion (196Dialogues per scenario)Talking Talking&DrivingSubjective 78.6% 74.0%Objective 68.4% 64.8%Table 5: Percentage of turns that are in line with the pre-defined taskTalking Talking&DrivingPercentage of turnsthat follow the task98.3% 96.79%Number of turns 1354 1388completion rate.
In addition, all dialogues were tran-scribed and analysed to see if the system providedinformation the user asked for and hence calculatean objective completion rate.
The results are givenin Table 4.
These differences are not statistically sig-nificant due to the small sample size.
However, itcan be seen that the trend is that the dialogues wherethe subject was not performing another task at thesame time were more successful.
Also, it is inter-esting that the subjective scores are higher than theobjective ones.
This can be explained by the fact thatthe dialogue tasks were predefined and the subjectsdo not always pay sufficient attention to their taskdescriptions.4.4 Conversational patternsGiven that the subjects felt the change of cognitiveload when they were talking to the system and op-erating the car simulator at the same time, we wereinterested to see if there are any changes in the dia-logues which might suggest this.First, we examine how well they follow the giventask on a turn-to-turn basis.
For example, if the taskis to find a cheap restaurant and if at some pointin the dialogue the user says I?d like an expensiverestaurant that turn is not consistent with the task.The results are given in Table 5 and they are statisti-cally significant (p < 0.01).We then examine the number of contradictions ona turn-to-turn basis.
For example, if the user says I?dlike a cheap restaurant and later on they say I?d like76Table 6: User obedience to system questions1.
system requests or confirms and requestsSamples ObedienceTalking 392 67.6%Talking&Driving 390 63.9%2.
system confirmsSamples ObedienceTalking 91 73.6%Talking&Driving 92 81.5%an expensive restaurant the latter turn is clearly acontradiction.
The percentage of contradicting turnsis less than 1% and the difference between the sce-narios is not statistically significant.
This suggeststhat while users tend to forget the task they are givenwhen they are driving, they still act rationally despitethe increase in the cognitive load.The next analysis concerns the user obedience,i.e.
the extent to which subjects answer the sys-tem questions.
We grouped the system questions intwo classes.
The first class represents the questionswhere the system requests a value for a particularslot, for instance What part of town are you lookingfor?
and the questions where the system confirmsand requests at the same time, for instance You arelooking for a cheap restaurant.
What part of townare you looking for?
The second class correspond tosystem confirmations, for example Did you say youare looking for a cheap restaurant?
The percent-age of the obedient user turns per class is given inTable 6.
Due to the small sample size these resultsare not statistically significant.
Still, it is interest-ing to see that when driving the subjects appear tobe more obedient to the system confirmations thanwhen they are just talking.
When the system makesa confirmation, the user can answer with simple yesor no, whereas when the system requests the valueof a particular slot, the user needs to think more toprovide an answer.The number of barge-ins, the number of fillerwords and the average speech intensity vary con-siderably among the subjects.
Therefore, we aver-age these statistics per user and examine the numberof users for which the particular measure is greaterfor the scenario where they talked to the system anddrove the simulator at the same time.
The resultsTable 7: Analysis of measures related to the speakingstyle which values are larger for Talking&Driving thanTalkingMeasure % of users Conf.
intervalMore barge-ins 87% [69%, 96%]More fillers 73% [54%, 88%]Higher intensity 67% [47%, 83%](Table 7) show that the number of barge-ins and thenumber of fillers is significantly greater for the sce-nario when they are talking and driving and the in-tensity on average tend to be greater.5 Conclusion and Future workThere are several important observations arisingfrom this study.
Firstly, dialogues with cognitivelyloaded users tend to be less successful.
This sug-gests that the system should alter its behaviour tomatch user behaviour and alleviate the cognitiveload in order to maintain the level of performance.This necessitates rapid on-line adaptation of dia-logue policies.The second observation is that cognitively loadedusers tend to respond to some types of system ques-tions more than others.
This indicates that the usermodel within a POMDP dialogue system should beconditioned on a measure of cognitive load.Finally, this study has found that users barge-inand use filler words significantly more often whenthey are cognitively loaded.
This suggests the needfor a much richer turn-taking model which allowsthe system to use back-channels and barge-in whenthe user hesitates.
An obvious candidate is the in-cremental approach (Schlangen and Skantze, 2009;DeVault et al, 2009) which allows the system to pro-cess partial user inputs, back-channels, predict shortterm user input and interrupt the user during hesita-tions.
While incremental dialogue is a growing areaof study, it has not so far been examined in the con-text of dialogue for secondary tasks.
We signpostthis as an important area for future work.AcknowledgmentsWe would like to thank to Peter Robinson and IanDavies for their help with the experiments.77ReferencesA Baron and P Green.
2006.
Safety and Usability ofSpeech Interfaces for In-Vehicle Tasks while Driving:A Brief Literature Review.
Technical Report UMTRI-2006-5.I Davies and P Robinson.
2011.
Emotional investmentin naturalistic data collection.
In International Con-ference on Affective Computing and Intelligent Inter-action.D DeVault, K Sagae, and DR Traum.
2009.
Can I fin-ish?
Learning when to respond to incremental inter-pretation results in interactive dialogue.
In 10th An-nual SIGDIAL meeting on Discourse and Dialogue.U Gartner, W Konig, and T Wittig.
2001.
Evaluation ofManual vs.
Speech Input When Using a Driver Infor-mation System in Real Traffic.
In International Driv-ing Symposium on Human Factors in Driving Assess-ment, Training and Vehicle Design.A Kun, T Paek, and Z?
Medenica.
2007.
The effect ofspeech interface accuracy on driving performance.
InInterspeech.J Lai, K Cheng, P Green, and O Tsimhoni.
2001.
On theRoad and on the Web?
Comprehension of syntheticand human speech while driving.
In SIGCHI.JD Lee, B Caven, S Haake, and TL Brown.
2001.Speech-based Interaction with In-vehicle Computers:The Effect of Speech-based E-mail on Drivers?
Atten-tion to the Roadway.
Human Factors, 43:631?640.R Mishra, E Shriberg, S Upson, J Chen, F Weng, S Pe-ters, L Cavedon, J Niekrasz, H Cheng, and H Bratt.2004.
A wizard of Oz framework for collecting spo-ken human-computer dialogs.
In Interspeech.BS Nielsen, B Harsham, B Raj, and C Forlines.
2008.Speech-Based UI Design for the Automobile.
Hand-book of Research on User Interface Design and Eval-uation for Mobile Technology, pages 237?252.David Schlangen and Gabriel Skantze.
2009.
A general,abstract model of incremental dialogue processing.
InProceedings of the 12th Conference of the EuropeanChapter of the Association for Computational Linguis-tics, EACL ?09, pages 710?718.B Thomson and S Young.
2010.
Bayesian update ofdialogue state: A POMDP framework for spoken di-alogue systems.
Computer Speech and Language,24(4):562?588.O Tsimhoni, D Smith, and P Green.
2004.
Address EntryWhile Driving: Speech Recognition Versus a Touch-Screen Keyboard.
Human Factors, 46:600?610.F Weng, L Cavedon, B Raghunathan, D Mirkovic,H Cheng, H Schmidt, H Bratt, R Mishra, S Peters,L Zhao, S Upson, E Shriberg, and C Bergmann.
2004.Developing a conversational dialogue system for cog-nitively overloaded users.
In Proceedings of the Inter-national Congress on Intelligent Transportation Sys-tems.JD Williams and SJ Young.
2007.
Partially ObservableMarkov Decision Processes for Spoken Dialog Sys-tems.
Computer Speech and Language, 21(2):393?422.SJ Young, M Gas?ic?, S Keizer, F Mairesse, J Schatzmann,B Thomson, and K Yu.
2010.
The Hidden InformationState Model: a practical framework for POMDP-basedspoken dialogue management.
Computer Speech andLanguage, 24(2):150?174.78
