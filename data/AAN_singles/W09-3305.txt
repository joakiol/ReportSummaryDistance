Proceedings of the 2009 Workshop on the People?s Web Meets NLP, ACL-IJCNLP 2009, pages 32?37,Suntec, Singapore, 7 August 2009.c?2009 ACL and AFNLPAutomatic Content-based Categorization of Wikipedia ArticlesZeno GantnerUniversity of HildesheimMachine Learning Labgantner@ismll.deLars Schmidt-ThiemeUniversity of HildesheimMachine Learning Labschmidt-thieme@ismll.deAbstractWikipedia?s article contents and its cate-gory hierarchy are widely used to producesemantic resources which improve perfor-mance on tasks like text classification andkeyword extraction.
The reverse ?
usingtext classification methods for predictingthe categories of Wikipedia articles ?
hasattracted less attention so far.
We proposeto ?return the favor?
and use text classi-fiers to improve Wikipedia.
This couldsupport the emergence of a virtuous circlebetween the wisdom of the crowds and ma-chine learning/NLP methods.We define the categorization of Wikipediaarticles as a multi-label classification task,describe two solutions to the task, and per-form experiments that show that our ap-proach is feasible despite the high numberof labels.1 IntroductionWikipedia?s article contents and its category hi-erarchy are widely used to produce semantic re-sources which improve performance on tasks liketext classification and keyword extraction (Baner-jee, 2007; Gabrilovich and Markovitch, 2007;Minier et al, 2007; Mihalcea and Csomai, 2007;Wang and Domeniconi, 2008; Medelyan et al,2008).
The reverse ?
using text classificationmethods to improve Wikipedia?s article-categorymappings ?
has attracted less attention (Fu et al,2007).A system that automatically suggests categoriesfor Wikipedia articles will help to improve the en-cyclopedia for its users and authors, as well as thesemantic resources created from it.The complexity of Wikipedia?s category sys-tems1and sheer number of categories make it1We use the plural here, as each language version has itshard for ?
possibly inexperienced ?
authors to as-sign categories to new or existing articles.
As ofFebruary 2009, the German Wikipedia has about886,000 articles, which belong to about 64,000categories.
For the English Wikipedia, those num-bers are even higher.2Classical document classification data sets likeReuters RCV1-V2 (Lewis et al, 2004) havearound 100 different categories.
In comparison,the automatic categorization of Wikipedia articlesis a challenging task, as it involves tens to hun-dreds of thousand categories.
For such large-scaleclassification problems, particular attention is nec-essary to deal with both training and predictioncomplexity, as well as imbalanced class distribu-tions.In this article, we present the problem ofcontent-based article categorization in Wikipedia,and suggest an evaluation protocol as well as twocontent-based methods for solving this problem.2 Problem StatementLet X ?
X be the set of all articles and L bethe set of all category labels in one of Wikipedia?slanguage versions.
Each article x ?
X is assigneda set of k(x) category labels {l1, .
.
.
, lk(x)} ?
L.In this context, one can think of several pre-diction problems: Given an article x without cat-egory information, predict all the article?s cate-gories.
This scenario is typical for newly cre-ated articles, thus we call it the new article prob-lem.
Another prediction task would be to predictthe missing categories for an article with existing,but incomplete category information (missing cat-egories problem).
Such a condition can occur e.g.if a new category is created and the creator of thenew category does not include all existing articlesthat should be assigned to that category.
In this pa-own category hierarchy.
The categories may be linked acrosslanguages using so-called interlanguage links.2http://stats.wikimedia.org/32fi(x)1 -1?fi(x)1 tpifpi-1 fnitniTable 1: Confusion matrix for class i.per, we will concentrate on the new article prob-lem.Such a problem is a so-called multi-label, orany-of classification task, as opposed to single-label (one-of ) classification (Manning et al,2008).
Multi-label classification can be expressedas a set of binary classification problems:f(x) = {li|fi(x) = 1}, (1)where fi: X ?
{?1, 1}, 1 ?
i ?
|L| are indica-tor functions for class li, i.e.
fi(x) = 1 iff.
articlex is annotated with the category label li.The associated learning problem is to find a pre-diction model?f that predicts categories for givenarticles as good as possible, according to a givenloss function.We choose micro- and macro-averaged F1asloss functions.
Micro-averaged F1is computedfrom the complete confusion matrix, while macro-averaged F1is the average F1computed fromclass-wise confusion matrices.
Micro-averagedmeasures tend to measure the effectiveness of aclassifier on the large categories, while macro-averaging gives more weight to smaller categories(Manning et al, 2008).Fmacro1:=1|L||L|?i=12 ?
tpi2 ?
tpi+ fpi+ fni, (2)where tpiis the number of true positives, fpithenumber of false positives, and fnithe number offalse negatives for class i (see Table 1).Fmicro1:=2 ?
tp2 ?
tp + fp + fn, (3)where tp =?|L|i=1tpiis the overall number oftrue positives, fp =?|L|i=1fpithe overall numberof false positives, and fn =?|L|i=1fnithe overallnumber of false negatives.F1is widely used in information retrieval andsupervised learning tasks.
While providing a bal-ance between precision and recall, optimizing forF1?forces?
the prediction method and the re-spective learning algorithm to decide which cat-egory labels to predict and which ones not ?just predicting a ranking of labels is not suffi-cient.
This is motivated by the intended use of theprediction method in a category suggestion sys-tem for Wikipedia articles: Such a system can-not present an arbitrarily high number of (possi-bly ranked) suggestions to the user, who would beoverwhelmed by the amount of information.
Onthe other hand, if there is a fixed low number ofsuggestions, there would be the danger of correctcategory labels being left out.3 MethodsThere are many multi-label classification modelsin the literature, which are either adaptions of ex-isting single-label models, or models generatedby transformation of the multi-label problem tosingle-label problems, which are then solved usingagain existing single-label models.
Tsoumakas etal.
(2009) give an overview of multi-label classifi-cation methods.Wikipedia articles are hypertext pages.
Forclassifying hypertext pages, there are two obviouskinds of features: (i), there are content-based fea-tures, like words or n-grams contained in the ar-ticles, and (ii), there are link-based features, suchas in- and outgoing article links, links to externalweb pages, and the (estimated or actually known)categories of the linked articles.
Past research onrelational learning and hypertext classification (Luand Getoor, 2003) has shown that both kinds offeatures are useful, and that the strongest meth-ods combine both.
It makes sense to investigatecontent-based features as well as link-based fea-tures, because improvements in any of the two canlead to overall improvements.
The work presentedhere focuses on content-based features.A naive approach would be to directly takethe binary representation of multi-label classifica-tion (equation 1), and then to train binary classi-fier models like support-vector machines (SVM,Cortes and Vapnik (1995)):?fnaive(x) := {li|?fi(x) = 1} (4)As the training of a traditional binary SVM clas-sifier does not optimize towards the given multi-label loss function, but for accuracy, we do not ex-pect the best results from this method.33If we want better multi-label predictions, chang-ing the threshold of the binary decision functionsis a straightforward solution.
We employed twowell-known thresholding strategies, ranking cut(RCut) and score cut (SCut, Yang (2001)), to pre-dict Wikipedia categories.RCut sorts all labels according to their binaryprediction score?f?i, and selects the t top labels:?frcut(x) := argmaxt1?i?|L|?f?i(x), (5)where argmaxta?Ag(a) refers to the t elements ofA with highest value g(a).
The value of the hyper-parameter threshold t can be chosen empiricallyon a hold-out set.SCut uses an individual decision threshold sifor each label:?fscut(x) := {li|?f?i(x) ?
si} (6)Good threshold values sican be determined dur-ing training.
Algorithm 1 shows a category-wiseoptimization of the threshold values as describedby Yang (2001).
Because it tunes the threshold sifor each category based on the F1measure overthat category, it optimizes for macro-averaged F1.If we are able to find optimal thresholds for eachcategory, then we will achieve optimal macro-F1performance, as the following lemma says.Lemma 1 Letsi:= argmaxs?SF1(X,Yi,?fi), (7)?fi(x) :={1, if?f?i(x) > s?1, otherwise(8)Then(s1, ..., s|L|) = argmax(s?1,...,s?|L|)Fmacro1(X,Y,?f),(9)?f(x) := {li|?f?i(x) > s?i}) (10)i.e., the component-wise binary F1optimizationyields the Fmacro1-optimal multi-label threshold.Proof: The components of the sum in the defi-nition of macro-averaged F1(Equation 2) are ex-actly the class-wise F1values.
The choice of siinfluences only the part of the sum2?tpi2?tpi+fpi+fnibe-longing to i.
Thus each sican be optimized inde-pendently.Representing each category label as binary pre-diction problem, as in the work presented here,requires |L| binary classifiers.
There also existmethods that use |L|2binary classifiers (Menciaand F?urnkranz, 2008), which is not feasible if L islarge.Algorithm 1 Macro-averaged F1optimization forSCutInput: binary classifiers (?f?i),?f?i: X ?
S; train-ing instances X ?
X and labels Y ?
P(L)|X|Output: thresholds (si)1: for i = 1 to |L| do2: Yi?
binary labels for category i generatedfrom Y3: si?
argmaxs?SF1-measure for?f?iwiththreshold s on X,Yi4: end for5: return (si)4 ExperimentsTo demonstrate the general feasibility of the au-tomatic categorization of Wikipedia articles, weconducted experiments on a subset of the GermanWikipedia.
In this section, we describe the ex-tracted data sets, the evaluation protocol, and dis-cuss the results.4.1 Category DataTo generate the data set for the experiment, weused the official database dumps of the GermanWikipedia, generated December 6, 2008.3Wethen extracted all articles belonging to the cate-gory Eishockey (?ice-hockey?)
or to one of its de-scendants, and removed all category labels fromoutside the chosen category sub-graph, and all cat-egory labels of categories containing less than 5articles.
We proceeded identically for the categoryPhilosoph (?philosopher?
).Feature generation was performed as follows:First, we removed all wiki markup from the articlesource code.
Second, we used Mallet (McCallum,2002) to generate bag-of-words representations ofthe articles.
All tokens were converted to lowercase, and tokens occurring in only one article wereremoved.
We conducted no stopword removal, norstemming.
Finally, we normalized the feature vec-tors to sum up to one.Table 2 shows some properties of the data.
|X|is the number of instances, |L| the number of dis-tinct category labels; the fourth column containsthe number of features (words) in the data set.43http://download.wikimedia.org4The data can be downloaded from http://www.domain/path.34top category |X| |L| # featuresPhilosoph 2,445 55 68,541Eishockey 5,037 159 36,473Table 2: Data set properties.4.2 Evaluation ProtocolTrain-Test SplitFor the experiment, we randomly separated thedata sets into 80% of the articles for training, and20% for testing.
To evaluate the new article prob-lem, we removed all category labels from the arti-cles in the test sets.TrainingAs an experimental baseline, we used a static clas-sifier (most-frequent) that always predicts the mostfrequent categories, regardless of the article.We implemented the RCut and SCut strate-gies using linear support-vector machines from theLIBSVM library (Chang and Lin, 2001) for theunderlying binary classification task.
For eachcategory, we used 5-fold cross-validation to finda good value for the hyperparameter C (Hsu etal., 2003).
As SVMs perform only binary deci-sions, but do not yield scores suitable for rankingthe labels, we used LIBSVM?s modified versionof Platt?s method (Platt, 2000) to obtain probabil-ities, which are used as scores for the RCut rank-ings and the SCut decisions.
As SCut?s thresholdsearch goes over an infinite set S = [0, 1] (Al-gorithm 1, line 3), we did an approximate searchover this interval with step size 0.01.
For RCut andmost-frequent, we report results for all thresholds1, .
.
.
, |L|.
In an application setting, we wouldhave to determine a suitable t using a hold-out dataset.4.3 Results and DiscussionThe results can be seen in Table 3 and Figure1 and 2.
Both methods clearly perform betterthan the baseline.
For macro-averaged F1onEishockey, SCut performs better than RCut, whichis not surprising, as this method is optimized to-wards macro-averaged F1.
For Philosoph, RCutwith a rank threshold of t = 3 has a little bit (by0.005) higher macro-averaged F1result, but this islikely not a significant difference.The experiments show that simple models likethe transformation from multi-label to binaryproblems, combined with thresholding strategieslike SCut and RCut, are suitable for the categoriza-tion of Wikipedia articles: The methods achieve agood prediction quality, while the number of un-derlying binary classifiers scales linearly (see Sec-tion 3).5 Conclusion and Future WorkIn this article, we view the categorization ofWikipedia articles as a multi-label classificationproblem and report experiments on a subset of theGerman Wikipedia.
The experiments show thatthere are suitable models for the categorization ofWikipedia articles.We propose to use machine learning algorithmsin order to improve the category assignments ofWikipedia articles.
While data from Wikipediais already widely used to improve text classifica-tion systems, it may be desirable to ?return the fa-vor?
and use text classifiers to improve Wikipedia.This could support the emergence of a virtuous cir-cle between the wisdom of the crowds and ma-chine ?intelligence?, i.e.
machine learning andNLP methods.Wikipedia category data could be used as wellfor generating publicly available, large-scale (hier-archical) multi-label classification benchmark col-lections with different characteristics.
Further-more, it could provide the basis for multilingualdocument classification data sets.To be able to provide category suggestions forlarge Wikipedias like the German, the Spanish orthe English one, we will extend our experiments tolarger subsets, and finally to all of the German andEnglish Wikipedia.
In order to achieve this, wewill also investigate hierarchical multi-label clas-sification methods (Liu et al, 2005; Cai and Hof-mann, 2004; Cesa-Bianchi et al, 2006) and fastertraining algorithms for linear SVMs and logisticregression (Fan et al, 2008; Shalev-Shwartz et al,2007).
Given that we use |L| binary classifiers forour models, this should be feasible, even for largenumbers of categories.
It would also be interest-ing to compare our methods to the work by Fu etal.
(2007), which concentrates on link-based cate-gorization of Wikipedia articles.Other promising research directions are the ex-amination of Wikipedia-specific features, and thesurvey of large-scale multi-label classification al-gorithms that take into account dependencies be-tween labels.35micro-averaged macro-averagedP R F1P R F1method Philosophmost-frequent (t = 1) 0.489 0.315 0.383 0.009 0.019 0.012most-frequent (t = 55) 0.028 1.0 0.055 0.028 1.0 0.049RCut (t = 2) 0.522 0.674 0.589 0.252 0.283 0.244RCut (t = 3) 0.395 0.764 0.520 0.240 0.379 0.266SCut 0.341 0.735 0.466 0.225 0.350 0.261method Eishockeymost-frequent (t = 2) 0.214 0.162 0.185 0.001 0.007 0.003most-frequent (t = 159) 0.008 1.0 0.016 0.008 1.0 0.017RCut (t = 1) 0.829 0.628 0.715 0.499 0.472 0.494RCut (t = 2) 0.526 0.796 0.633 0.406 0.599 0.497SCut 0.646 0.806 0.717 0.461 0.630 0.554Table 3: Results for data sets Philosoph and Eishockey.0 50 100 1500.00.20.40.60.8tmicro?averagedF1lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllMethodsRCutSCutmost frequent0 50 100 1500.00.20.40.60.8tmacro?averagedF1llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllMethodsRCutSCutmost frequentFigure 1: Method comparison for F1on data set Eishockey.
SCut does not depend on t.0 10 20 30 40 500.00.20.40.60.8tmicro?averagedF1llllllllllllllllllllllllllllllllllllllllllllllllllllllllMethodsRCutSCutmost frequent0 10 20 30 40 500.00.20.40.60.8tmacro?averagedF1llllllllllllllllllllllllllllllllllllllllllllllllllllllllMethodsRCutSCutmost frequentFigure 2: Method comparison for F1 on data set Philosoph.
SCut does not depend on t.36AcknowledgmentsThe authors gratefully acknowledge the par-tial co-funding of their work through theEuropean Commission FP7 project MyMedia(www.mymediaproject.org) under the grant agree-ment no.
215006.ReferencesSomnath Banerjee.
2007.
Boosting inductive transferfor text classification using Wikipedia.
In ICMLA?07: Proceedings of the Sixth International Confer-ence on Machine Learning and Applications, Wash-ington, DC, USA.
IEEE Computer Society.Lijuan Cai and Thomas Hofmann.
2004.
Hierarchi-cal document categorization with support vector ma-chines.
In Proceedings of the 13th ACM Interna-tional Conference on Information and KnowledgeManagement (CIKM ?04), November 8-13, 2004,Washington, D.C., USA.
ACM Press, New York, NY,USA.Nicol Cesa-Bianchi, Claudio Gentile, and Luca Zani-boni.
2006.
Incremental algorithms for hierarchi-cal classification.
Journal of Machine Learning Re-search.Chih-Chung Chang and Chih-Jen Lin, 2001.
LIB-SVM: a library for support vector machines.Software available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.Corinna Cortes and Vladimir Vapnik.
1995.
Support?vector networks.
Machine Learning, 20.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin.
2008.
Liblinear: Alibrary for large linear classification.
Journal of Ma-chine Learning Research, 9.Linyun Fu, Haofen Wang, Haiping Zhu, Huajie Zhang,Yang Wang, and Yong Yu.
2007.
Makingmore Wikipedians: Facilitating semantics reuse forwikipedia authoring.
In ISWC/ASWC 2007.Evgeniy Gabrilovich and Shaul Markovitch.
2007.Harnessing the expertise of 70,000 human editors:Knowledge-based feature generation for text catego-rization.
Journal of Machine Learning Research.Chih-Wei Hsu, Chih-Chung Chang, and Chih-Jen Lin.2003.
A practical guide to support vector classifi-cation.
Technical report, Department of ComputerScience, National Taiwan University.David D. Lewis, Yiming Yang, Tony G. Rose, G. Di-etterich, Fan Li, and Fan Li.
2004.
RCV1: Anew benchmark collection for text categorization re-search.
Journal of Machine Learning Research.Tie-Yan Liu, Yiming Yang, Hao Wan, Hua-Jun Zeng,Zheng Chen, and Wei-Ying Ma.
2005.
Support vec-tor machines classification with a very large-scaletaxonomy.
SIGKDD Explorations, (1).Qing Lu and Lise Getoor.
2003.
Link-based classifi-cation using labeled and unlabeled data.
In ICMLWorkshop on ?The Continuum from Labeled to Un-labeled Data in Machine Learning and Data Min-ing?.Christopher D. Manning, Prabhakar Raghavan, andHinrich Sch?utze.
2008.
Introduction to InformationRetrieval.
Cambridge University Press, New York.Andrew Kachites McCallum.
2002.
Mal-let: A machine learning for language toolkit.http://mallet.cs.umass.edu.Olena Medelyan, Ian H. Witten, and David Milne.2008.
Topic indexing with Wikipedia.
In Proceed-ings of the Wikipedia and AI workshop at AAAI-08.AAAI.Eneldo Loza Mencia and Johannes F?urnkranz.
2008.Efficient pairwise multilabel classification for large-scale problems in the legal domain.
In Walter Daele-mans, Bart Goethals, and Katharina Morik, editors,ECML/PKDD (2), volume 5212 of Lecture Notes inComputer Science, pages 50?65.
Springer.Rada Mihalcea and Andras Csomai.
2007.
Wikify!
:linking documents to encyclopedic knowledge.
InCIKM ?07, New York, NY, USA.
ACM.Zsolt Minier, Zalan Bodo, and Lehel Csato.
2007.Wikipedia-based kernels for text categorization.
InSYNASC ?07, Washington, DC, USA.
IEEE Com-puter Society.J.
Platt.
2000.
Probabilistic outputs for support vectormachines and comparison to regularized likelihoodmethods.
In Advances in Large Margin Classifiers.S.
Shalev-Shwartz, Y.
Singer, and N. Srebro.
2007.Pegasos: Primal estimated sub?gradient solver forSVM.
In Proceedings of the International Confer-ence on Machine Learning.G.
Tsoumakas, I. Katakis, and I. Vlahavas.
2009.
Min-ing multi-label data.
unpublished book chapter.Pu Wang and Carlotta Domeniconi.
2008.
Build-ing semantic kernels for text classification usingWikipedia.
In KDD ?08, New York, NY, USA.ACM.Yiming Yang.
2001.
A study on thresholding strategiesfor text categorization.
In W. Bruce Croft, David J.Harper, Donald H. Kraft, and Justin Zobel, editors,SIGIR 2001, pages 137?145.
ACM.37
