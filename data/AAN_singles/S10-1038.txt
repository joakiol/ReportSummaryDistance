Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 178?181,Uppsala, Sweden, 15-16 July 2010.c?2010 Association for Computational LinguisticsUNPMC: Na?
?ve Approach to Extract Keyphrases from Scientific ArticlesJungyeul ParkLINA,Universit?e de NantesNantes, Francejungyeul.park@univ-nantes.frJong Gun LeeLIP6-CNRS,UPMC (Paris 6)Paris, Francejonggun.lee@lip6.frB?eatrice DailleLINA,Universit?e de NantesNantes, Francebeatrice.daille@univ-nantes.frAbstractWe describe our method for extractingkeyphrases from scientific articles whichwe participate in the shared task ofSemEval-2 Evaluation Exercise.
Eventhough general-purpose term extractorsalong with linguistically-motivated analy-sis allow us to extract elaborated morpho-syntactic variation forms of terms, a na?
?vestatistic approach proposed in this paperis very simple and quite efficient for ex-tracting keyphrases especially from well-structured scientific articles.
Based onthe characteristics of keyphrases with sec-tion information, we obtain 18.34% forf-measure using top 15 candidates.
Wealso show further improvement withoutany complications and we discuss this atthe end of the paper.1 Introduction1Key phrases are a set of words to capture the maintopic of the document.
Since key phrases con-tain the substance of the document, they are usedin the large spectrum of areas; from applicationswhich explicitly use key phrases such as automaticindexing, documents classification and search en-gine optimization in information retrieval, to ap-plications which implicitly use key phrases such assummarization and question-answering systems.During the last decade, many previous works havedealt with the various methods for automaticallyextracting key phrases (e.g., Frank et al, 1999;Barker and Corrnacchia, 2000; Turney, 2003;Medelyan and Witten, 2006; Nguyen and Kan,2007; Wan and Xiao, 2008).1UNPMC means the collaborative team from Laboratoired?Informatique de Nantes Atlantique of the Universit?e deNantes and Laboratoire d?Informatique de Paris 6 of the Uni-versit?e Pierre et Marie Curie.The task of extracting key phrases would beconsidered as a subtask of extracting terminologyif key phrases are a kind of terms.
Typical ap-proaches for automatically extracting terms uselinguistic preprocessing which involves morpho-syntactic analysis such as part-of-speech taggingand phrase chunking, and statistical postprocess-ing such as log likelihood which compares theterm frequencies in a document against their ex-pected frequencies derived in a bigger text.
Be-sides, extracting terms prefers syntactically plau-sible noun phrases (NPs) which are mainly multi-words terms.
Kim and Kan (2009) report that mostof key phrases are often simple words than less of-ten compound words2.The task for extracting key phrases tend to in-clude analyzing the document structure.
Espe-cially, extracting key phrases from well-structuredscientific articles should consider cross-section in-formation (Nguyen and Kan, 2007).
This informa-tion has been explored to assess the suitability offeatures during learning in Kim and Kan (2009).Extracting key phrases, however, is more than toextracting terminology or analyzing the documentstructure.
While terms are words which appear inspecific contexts and analyse concept structures indomains of human activity, key phrases are wordsthat capture the key idea of documents.
In addi-tion, while terms usually occur in the given doc-ument more often than we would expect to occur,key phrases do not necessarily occur frequently orkey phrases do not occur at all in the document.Consequently, the task for extracting key phrasesshould not be considered as the subtask of extract-ing terminology and we are not able to directly ap-ply general-purpose term extractors to extract keyphrases.In this paper, we describe our method for ?Au-tomatic Keyphrase Extraction from Scientific Ar-2In training data, only 23.4% of keyphrases, however, aresingle words.178ticles?, the shared task of SemEval-2 Evalua-tion Exercise which we participated in.
Al-though term extractors along with linguistically-motivated analysis allow us to extract even elab-orated morpho-syntactic variation forms of terms,the na?
?ve statistic approach proposed in this pa-per is very simple and quite efficient for extractingkeyphrases especially from well-structured scien-tific articles.
In a nutshell, our method is basedon empirical rules without any linguistically-motivated preprocessing.
Empirical rules are ob-tained from the analysis of the characteristics ofkeyphrases by observing training data.The remaining of this paper is organized as fol-lows: Section 2 explains the characteristics ofkeyphrases in scientific articles.
Section 3 and 4detail our na?
?ve statistic approach and experiment,respectively.
We conclude this paper and discuss afurther improvement in Section 6.2 Characteristics of Keyphrases inScientific ArticlesIn this section, we investigate the characteristics ofkeyphrases in training data.
Table 1 shows statis-tics of training data.
In Table 1, D-author meansthe keyphrases assigned by authors, D-reader thekeyphrases assigned by readers, and D-combinedthe combined keyphrases assigned by both of au-thors and readers.# of papers (p) # of key phrases (k) k / pD-author 144 563 3.91D-reader 144 1,865 12.95D-combined 144 2,265 15.73Table 1: Statistics of training data2.1 Word length of keyphrasesWe measure the distribution of word length of keyphrases in training data and present it in Figure 1.Over half of key phrases are two-word key phrasesin both author- and reader-assigned key phrases.Differently with Kim and Kan (2009) which theyreported that most of key phrases are often sim-ple words than less often compound words, only29.7% and 17.7% of key phrases are one-word keyphrases.
There are also more than four-word keyphrases which hold 4.3% and 7.2% of author andreader assigned key phrases, respectively.2.2 Occurrences of keyphrasesIn which section do keyphrases occur frequently?To answer this question, we count the number oflength=1(29.7%)length=2(51.3%) length=3(14.7%)length=4+(4.3%)(a) D-authorlength=1(17.7%)length=2(53.2%)length=3(21.8%)length=4+(7.2%)(b) D-readerFigure 1: Word length of keyphrases in trainingdataoccurrences of keyphrases of each section.
Dueto the variation of the naming of the section,we divide sections into title and abstract, intro-duction, conclusion, and the rest including refer-ences.
Table 2 and 3 show the number of occur-rences and the accumulative number of unique oc-currences of keyphrases in each section, respec-tively.
We also show the accumulative numberof words in each section in Table 4.
Includingthe rest sections exponentially diminishes the ra-tio of the number of gold keyphrases to the numberof candidate keyphrases.
Note that m words pro-duce?n?1i=0(m ?
i) candidate keyphrases for upto n-word keyphrases by supposing that candidatekeyphrases are simple n-word terms.Note also that both author- and reader-assignedkeyphrases hold only 75.49% and 89.44%, re-spectively.
Even some keyphrases are differentwith surface forms in the document and our na?
?vemethod with no linguistic intervention is not ableto recognize them.
For example, one of reader-assigned keyphrases distributed real-time embed-ded system for C-41 actually appears as distributedreal-time and embedded (DRE) systems.D-author D-readerTitle and Abstract 277 802Introduction 215 491Conclusion 313 982Other 387 1,210Table 2: Number of occurrences of keyphrases ineach sectionD-author D-readerTotal 563 (100.0%) 1,865 (100.0%)Title and Abstract 277 (49.20%) 802 (43.00%)?+?
Introduction 317 (56.30%) 937 (50.24%)?+?
Conclusion 367 (65.19%) 1,311 (70.29%)?+?
Other 425 (75.49%) 1,668 (89.44%)Table 3: Accumulative number of unique occur-rences of keyphrases in each section179# words (W) # gold (G) G/WTitle and Abstract 28435 802 0.0282?+?
Introduction 72729 937 0.0128?+?
Conclusion 178473 1311 0.0073?+?
Other 948007 1668 0.0018Table 4: Number of words in training data andgold data (D-reader)2.3 Coincidence of keyphrasesFigure 2 shows the coincidence of keyphrases3.Almost half of keyphrases (58.44% and 45.74%for author- and reader-assigned keyphrases, re-spectively) occur coincidentally in keysectionsand the rest sections.
Keysections hold 65.19%and 70.29% of keyphrases and the rest sectionsbesides keysections hold 68.74% and 64.88% ofwhole keyphrases.
Note that the rest sections oc-cupy over 70% of the document on the average.
(a) D-author (b) D-readerFigure 2: Coincidence of keyphrases3 MethodologyFrom training data, we observe and decide the fol-lowings:?
More than four-word keyphrases hold only4.3% and 7.2% of whole keyphrases.
Wedecide that our approach limits the wordlength as three for extracting keyphrases.Thus we extract only up to three-wordkeyphrases.
This choice might lead the per-formance degradation of our method becausewe explicitly exclude more than four-wordkeyphrases.?
Keysections hold 65.19% and 70.29% ofkeyphrases.
We decide that our approachlimits keysections from which we extractkeyphrases.
Including the rest sections may3We denote title and abstract as A, introduction as I, con-clusion as C, and the rest sections including references asOther.improve recall, but probably diminish preci-sion since the rest sections occupy over 70%of the document.?
Almost half of keyphrases occur coinciden-tally in keysections and the rest sections.
Wedecide that our approach limits coincidentkeyphrases in both of them.
This decision ismade empirically and improve precision.The following procedure explains and detailsour approach for extracting keyphrases.?
Extract up to three-word terms from keysec-tions as candidate keyphrases.?
Filter them out if they contain one or more ofstop words or non-content-containing words(see Table 5 for non-content-containingwords).?
Count the number of occurrences of extractedterms from each keysection.?
Check the coincidence whether candidatekeyphrases occurs in more than two keysec-tions.
If so, we assign weight.?
Calculate a score for candidate keyphrasesand list them by order of the score.4 Experiment resultsThis section shows the experiment results withtraining and test data.4.1 Training dataTo optimize our results, we use various thresholdsfor the number of n-word keyphrases and weight.We try to find the (i : j : k) pattern whichmeans i one-word, j two-word, and K three-word keyphrases to produce the best results.
Wealso try to find the threshold for weight d to cal-culate the score as follows: if keyphrases ap-pear in more than two keysections, score =d ?
# of total occurences, otherwise score =# of total occurences.
Table 6 shows our bestresults for training data where (i : j : k) = (3 :9 : 3) and d = 2.
Empirically, we found thesethresholds from training data by iterating severalpossibilities4.4.2 Test dataTable 7 shows our test data results published byorganizers of the shared task of SemEval-2 Evalu-ation Exercise.4These thresholds will be more examined in future work.180Type ExamplesNoun section, abstract, introduction, conclusion, reference, future work, figure, paper, result, laboratory, universityVerb present, how, introduce, become, improve, find, help, improve, consider, call, yield, allow, give, assumeAdverb always, formally, necessarily, successfully, previously, usually,mainly, final, essentially, ultinately, commonly,severely, significantly, dramatically, clearly, still, well, who, whose, whom, which, whether, therefore,Other POSs that, this, those, these, many, several, more, over, less, behind, above, below, each, few, different, under,both, within, through, prior, various, better, following, between, possible, via, before,even, such, if, new,show, important, simple, good, tranditional, current, varying, necessary, previous, clearTable 5: Example of (heuristically obtained) non-content-containing termsAUTHOR.STEM.FINAL# Gold: 559 Match Precision Recall F-scoreTop 05 43 5.97% 7.69% 6.72%Top 10 101 7.01% 18.07% 10.10%Top 15 139 6.44% 24.87% 10.23%READER.STEM.FINAL# Gold: 1824 Match Precision Recall F-scoreTop 05 118 16.39% 6.47% 9.28%Top 10 249 17.29% 13.65% 15.26%Top 15 361 16.71% 19.79% 18.12%COMBINED.STEM.FINAL# Gold: 2223 Match Precision Recall F-scoreTop 05 143 19.86% 6.43% 9.71%Top 10 309 21.46% 13.90% 16.87%Top 15 441 20.42% 19.84% 20.13%Table 6: Training data resultsREADER.STEM.FINAL# Gold: 1204 Precision Recall FscoreTop 05 13.80% 5.73% 8.10%Top 10 15.10% 12.54% 13.70%Top 15 14.47% 18.02% 16.05%COMBINED.STEM.FINAL# Gold: 1466 Precision Recall FscoreTop 05 18.00% 6.14% 9.16%Top 10 19.00% 12.96% 15.41%Top 15 18.13% 18.55% 18.34%Table 7: Test data results5 Conclusion and DiscussionIn this paper, we described our simple methodfor extracting keyphrases from scientific arti-cles which we participate in the shared task ofSemEval-2 Evaluation Exercise.
The na?
?ve ap-proach was proposed.
This approach turnedout very simple and quite efficient for extractingkeyphrases from well-structured scientific articles.Based on learning the distribution of keyphraseswith section information, we obtain 18.34% for f-measure using top 15 candidates.Our na?
?ve approach still has much room forimprovement.
For example, we are able to im-prove the result for same test data up to 20.71%and 25.55% for f-measure using top 15 candidatessimply by adding the rest sections and normaliz-ing the number of occurrences of terms from eachsection5.5The result is not improved only by adding the rest sec-tions.Moreover, our n-word terms based extractioncan be benefited by linguistic preprocessing suchas normalizing surface forms.
Handcrafted regu-lar expression rules along with part-of-speech tag-ging and phrase chunking would be also intro-duced to improve candidate selection.
We havenot explored thoroughly feature engineering, nei-ther.
For example, more fine-grained section infor-mation and weight re-assignment might help filterout irrelevant candidates.
We leave these possibil-ities for future work.ReferencesKen Barker and Nadia Cornacchia.
2000.
Using noun phraseheads to extract document keyphrases.
In Proceedingsof the 13th Biennial Conference of the Canadian Soci-ety on Computational Studies of Intelligence: Advancesin Artificial Intelligence, pages 40-52.
May 14-17, 2000.Montr?eal, Quebec, Canada.Eibe Frank , Gordon W. Paynter , Ian H. Witten , Carl Gutwin,and Craig G. Nevill-Manning.
1999.
Domain-SpecificKeyphrase Extraction.
In Proceedings of the 16th Inter-national Joint Conference on Artificial Intelligence, pages668-673.
July 31-August 6, 1999.
Stockholm, Sweden.Su Nam Kim and Min-Yen Kan. 2009.
Re-examining Auto-matic Keyphrase Extraction Approaches in Scientific Ar-ticles.
In Proceedings of the Workshop on Multiword Ex-pressions: Identification, Interpretation, Disambiguationand Applications (MWE 2009), ACL-IJCNLP 2009, pages9-12.
August 6, 2009.
Singapore.Olena Medelyan and Ian H. Witten.
2006.
Thesaurus basedautomatic keyphrase indexing.
In Proceedings of the6th ACM/IEEE-CS joint conference on Digital libraries,pages 296-297.
June 11-15, 2006.
Chapel Hill, NC, USA.Thuy Dung Nguyen and Min-Yen Kan. 2007.
Key phraseExtraction in Scientific Publications.
Asian Digital Li-braries.
Looking Back 10 Years and Forging New Fron-tiers, pages 317-326.
Springer Berlin, Heidelberg.Peter D. Turney.
2003.
Coherent keyphrase extraction viaWeb mining.
In Proceedings of the 18th InternationalJoint Conference on Artificial Intelligence, pages 434-439.
August 9-15, 2003.
Acapulco, Mexico.Xiaojun Wan and Jianguo Xiao.
2008.
CollabRank: towardsa collaborative approach to single-document keyphraseextraction.
In Proceedings of the 22nd InternationalConference on Computational Linguistics (Coling 2008),pages 969-976.
18-22 August, 2008.
Manchester, UK.181
