SENTENTIAL SEMANTICS FOR PROPOSITIONAL ATTITUDESAndrew R. HaasDepartment of Computer ScienceState University of New York at AlbanyAlbany, New York, 12222The sentential theory of propositional attitudes is very attractive to AI workers, but it is difficult to use such atheory to assign semantics to English sentences about attitudes.
The problem is that a compositionalsemantics cannot easily build the logical forms that the theory requires.
We present a new notation for asentential theory, and a unification grammar that builds logical forms in our notation.
The grammar isimplemented using the standard implementation of definite clause grammars in Prolog.1 LOGICAL FORMS FOR PROPOSITIONALATTITUDESThe sentential theory of propositional ttitudes claims thatpropositions are sentences of a thought language.
It has anobvious appeal to AI workers, since their programs oftencontain sentences of an artificial anguage, which are sup-posed to represent the program's beliefs.
These sentencescan be true or false, and the program can make inferencesfrom them, so they have two essential properties of beliefs.It is tempting to conclude that they are the program'sbeliefs, and that human beliefs are also sentences of athought language.
If we extend this to all propositionalattitudes, we have a sentential theory of propositionalattitudes.
In such a theory, an English sentence xpresses aproposition, and this proposition is itself a sentence--although in a different language.
Other theories of atti-tudes hold that a proposition is a set of possible worlds, or asituation--something very different from a sentence.
Mooreand Hendrix (1979), Haas (1986), Perlis (1988), andKonolige (1986) have argued for sentential theories andapplied them to artificial intelligence.Kaplan (1975) proposed an analysis of quantificationinto the scope of attitudes within a sentential theory, andother authors using sentential theories have offered varia-tions of his idea (Haas 1986; Konolige 1986).
Most of thesetheories present serious difficulties for formal semantics.The problem is that they assign two very different logicalforms to a clause: one form when the clause is the object ofan attitude verb, and another when it stands alone.
Thismeans that the logical form of the clause depends on itscontext in a complicated way.
It is difficult to describe thisdependence in a formal grammar.
The present paper aimsto solve this problem--to present a grammar that assignslogical forms that are correct according to Kaplan's ideas.We also describe a parser that builds the logical formsrequired by the grammar.This grammar is a set of definite clauses written in thenotation of Pereira and Warren (1980).
However, it is not adefinite clause grammar for two reasons.
First, our gram-mar cannot be parsed by the top-down left-to-right methodused for definite clause grammar (although it can be modi-fied to allow this).
Second, we do not allow any of thenonlogical operations of Prolog, such as checking whether avariable is bound or free, negation as failure, and the rest.This means that our grammar is a set of ordinary first-ordersentences (in an unusual notation) and its semantics i theordinary semantics of first-order logic.
So the grammar isdeclarative, in the sense that it defines a language andassigns logical forms without reference to any algorithm forparsing or generation.If we stick to the declarative semantics, a neglectedproblem demands our attention.
We must choose the boundvariables that appear in the logical forms generated by thegrammar.
Logic grammars that include semantics nearlyalways ignore this problem, using free variables of themeta-language to represent he bound variables of thelogical form.
This solution directly violates the declarativesemantics of definite clauses, and we therefore reject it.
Wewill see that this problem interacts with the semantics ofNP conjunction and of quantification into attitudes.
Tountangle this knot and handle all three problems in onegrammar is the goal of this paper.Section 1 of this paper will propose logical forms forsentences about propositional attitudes and explain thesemantics of the logical forms in terms of certain relationsthat we take as understood.
Section 2 presents a unificationgrammar for a fragment of English that includes quanti-tiers, NP conjunction, pronouns, and relative clauses.
Thegrammar combines yntax and semantics and assigns oneor more logical forms to each sentence that it generates.Computational Linguistics Volume 16, Number 4, December 1990 213Andrew R. Haas Sentential Semantics for Propositional AttitudesSection 3 extends the grammar to include verbs that de-scribe propositional ttitudes.
Section 4 describes the imple-mentation and summarizes the results.1.1 KAPLAN'S ANALYSIS OF DE RE BELIEFREPORTSNoun phrases in the scope of attitude verbs commonly havean ambiguity between de re and de dicto readings.
Con-sider the example "John believes that Miss America isbald" (Dowty, Wall, and Peters 1981).
Under the de rereading of "Miss America," this sentence says that Johnhas a belief about a woman who in fact is Miss America,but it doesn't imply that John realizes he is Miss America.A sentential theorist might say that the sentence tells usthat John has a belief containing some name that denotesMiss America, but it doesn't ell us what name.
The otherreading, called de dicto, says that John believes that who-ever is Miss America is bald.
The de dicto reading, unlikethe de re, does not imply that anyone actually is MissAmerica--it could be true if the Miss America pageantclosed down years ago, while John falsely supposes thatsomeone still holds that title.Kaplan (1975) considered examples like these.
He saidthat an agent may use many names that denote the sameentity, but there is a subset of those names that representthe entity to the agent (this use of "represent" is differentfrom the common use in AI).
If an agent has a de re beliefabout an entity x, that belief must be a sentence containing,not just any term that denotes x, but a term that representsx to the agent.
Thus if "person0" is a name that representsMiss America to John, and the thought language sentence"bald(person0)" is one of John's beliefs, then the sentence"John thinks Miss America is bald" is true (under the de rereading).Kaplan said that a name represents an entity to an agentif, first, it denotes that entity; second, it is sufficiently vivid;and, finally, there is a causal connection between the entityand the agent's use of the name.
A name N is vivid to anagent if that agent has a collection of beliefs that mentionN and give a good deal of relevant information about thedenotation of N. What is relevant may depend on theagent's interests.Other authors have accepted the idea of a distinguishedsubset of names while offering different proposals abouthow these names are distinguished.
I have argued that thedistinguished names must provide information that theagent needs to achieve his or her current goals (Haas1986).
Konolige (1986) proposed that for each agent andeach entity, the set of distinguished names has exactly onemember.
In this paper, we adopt Kaplan's term "represent"without necessarily adopting his analysis of the notion.
Weassume that representation is a relation between an agent, aname, and the entity that the name denotes.
If an agent hasan attitude toward a thought-language sentence, and thatsentence contains a name that represents a certain entity tothe agent, then the agent has a de re attitude about thatentity.
Our grammar will build logical forms that arecompatible with any sentential theory that includes theseassumptions.One problem about the nature of representation shouldbe mentioned.
This concerns the so-called de se attitudereports.
This term is attributable to Lewis (1979), but theclearest definition is from B6er and Lycan (1986).
De seattitudes are "attitudes whose content would be formulatedby the subject using the equivalent in his or her language ofthe first-person singular pronoun 'I' " (B6er and Lycan1986).
If John thinks that he is wise, and we understandthis a,; a de se attitude, what name represents John tohimself?
One possibility is that it is his selfname.
Anagent's selfname is a thought-language constant hat hestandardly uses to denote himself.
It was postulated inHaa,; (1986) in order to solve certain problems aboutplanning to acquire information.
To expound and defendthis idea would take us far from the problems of composi-tional semantics that concern us here.
We simply mentionit as an example of the kinds of theories that are compatiblewith the logical forms built by our grammar.
See alsoRapal:,ort (1986) for another AI approach to de se atti-tudes.1.2 COMPOSITIONAL SEMANTICS AND LOGICALFORMSConsider the logical form that Kaplan assigns for the de rereading of "John believes that some man loves Mary.
"(1):t (y,man(y) &3 (c~,R(a,y,john) &believe(john,qove(~,mary)q)))The notation is a slight modification of Kaplan's (Kaplan1975).
The predicate letter R denotes representation.
Thesymbol o~ is a special variable ranging over names.
Thesymbols r-and-1 are Quine's quasi-quotes (Quine 1947).
Ifdenotes a name t, then the expression "qove(a,mary) q'' willdenote the sentence "love(t,mary).
"It is hard to see how a compositional semantics can buildthis representation from the English sentence "John be-lieves some man loves Mary."
The difficult part is buildingthe representation for the VP "believes ome man lovesMary."
By definition, a compositional semantics must buildthe representation from the representations of the constitu-ents of the VP: the verb "believe" and the embedded clause.Following Cooper's notion of quantifier storage (Cooper19821), we assume that the representation f the embeddedclause has two parts: the wtT"love(y,mary)" and an existen-tial quantifier that binds the free variable y.
Informally, wecan write the quantifier as "some(y,man(y) & S)," where Sstands for the scope of the quantifier.
Applying thisquanti!fier to the wff "love(y,mary)" gives the sentence"some(y,man(y) & love(y,mary))."
In the present paper,the term "quantifier" will usually refer to this kind ofobject--not to the symbols V and 3 of first-order logic, norto the generalized quantifiers of Barwise and Cooper (1981).214 Comlmtational Linguistics Volume 16, Number 4, December 1990Andrew R. Haas Sentential Semantics for Propositional AttitudesIn Section 2.2 we present a more precise formulation of ourrepresentation f quantifiers.When the clause "some man loves Mary" forms anutterance by itself, the semantics will apply the quantifierto the wff "love(y,mary)" to get the sentence "some(y,man(y) & love(y,mary))."
The problem is that the wit"love(y,mary)" does not appear in Kaplan's representation.In its place is the expression "love(a,mary)," containing avariable that ranges over names, not men.
It might bepossible to build this expression from the wff "love(y,mary),"but this sounds like a messy operation at best.
Similarproblems would arise if we chose another quotation device(such as the one in Haas 1986) or another scoping mecha-nism (as in Pereira and Shieber 1987).Konolige (1986) proposed a very different notation forquantifying in, one that would abolish the difficulty de-scribed here.
His proposal depends on an ingenious non-standard logic.
Unfortunately, Konolige's system has twoimportant limitations.
First, he forbids a belief operator toappear in the scope of another belief operator.
Thus, herules out beliefs about beliefs, which are common in every-day life.
Second, he assumes that each agent assigns toevery known entity a unique "id constant."
When an agenthas a belief about an object x, that belief contains the idconstant for x.
Using Kaplan's terminology, Konolige issaying that for any entity x and agent y, there is a unique asuch that R(cqx,y).
Kaplan never suggests that representa-tion has this property, and as Moore (1988) pointed out,the claim is hard to believe.
Surely an agent can have manynames for an entity, some useful for one purpose and somefor another.
Why should one of them be the unique idconstant?
We will propose a notation that has the advan-tages of Konolige's notation without its limitations.
Section1.3 will present he new notation.
In Section 1.4, we returnto the problem of building logical forms for English sen-tences.1.3 A NEW NOTATION FOR QUANTIFYING INOur logical forms are sentences in a first-order logic aug-mented with a quotation operator.
We call this languagethe target language.
Since the grammar is a set of definiteclauses, our notation is like Prolog's.
The variables of thetarget language are u, v, w, x, y, z, etc.
Constants, functionletters, and atomic wffs are defined in the usual way.
If  pand q are wffs, then not(p), and(p,q), and or(p,q) are wits.I fp  and q are wffs, x a variable, and t a term, the followingare wffs:(2) some(x,p,q)(3) all(x,p,q)(4) unique(x,p,q)(5) let(x,t,p)The first wff is true iffp and q are both true for some valueof x.
The second is true iff q is true for all values of x thatmake p true.
The third is true iff there is exactly one valueofx  that makes p true, and q is true for that value ofx.
Thelast wit is true iff p is true when the value of x is set to thevalue of t. This language should be extended to include theiota operator, forming definite descriptions, ince a definitedescription may often represent an entity to an agent.However, we omit definite descriptions for the time being.Fcr any expression e of the target language, q(e) is aconstant of the target language.
Therefore we have acountable infinity of constants.
The intended models of ourlanguage are all first-order models in which the domain ofdiscourse includes every expression of the language, andeach constant q(e) has the expression e as its denotation.Models of this kind are somewhat unusual, but they areperfectly consistent with standard efinitions of first-orderlogic, which allow the universe of discourse to be anynonempty set (Enderton 1972).
Our language does departfrom standard logic in one way.
We allow a variable toappear inside a constant--for example, since v is a variable,q(v) is a constant hat denotes the variable v. Endertonexplicitly forbids this: "no symbol is a finite sequence ofother symbols" (p. 68).
However, allowing a variable toappear inside a constant is harmless, as long as we arecareful about the definition of a free occurrence of avariable.
We modify Enderton's definition (p. 75) by chang-ing his first clause, which defines free occurrences of avariable in an atomic wff.
We say instead that a variable vappears free in variable w iff v = w; no variable occurs freein any constant; a variable v occurs free in the termf(t 1 .
.
.
tn) iff it occurs free in one of t I .
.
.
tn; and v occursfree in the atomic wff p(t 1 .
.
.
tm) iff it occurs free in one oft I .
.
.
t,,,.
Under this definition x does not occur free in theconstant q(red(x)), although it does occur free in the wffred(x).As usual in a sentential theory of attitudes, we assumethat an agent's beliefs are sentences of thought languagestored in the head, and that knowledge consists of a subsetof those sentences.
Then simple belief is a relation betweenan agent and a sentence of thought language.
To representde re belief reports, we introduce a predicate of threearguments, and we define its extension in terms of simplebelief and the notion of representation.
If  \[p,l,w\] is a triplein the extension of the predicate "believe," then p is theagent who has the belief, l is a list of entities x~.
.
.
xn thatthe belief is about, and w is a wff of the target language.The free variables in w will stand for unspecified terms thatrepresent the entities x I .
.
.
x n to the agent p. These freevariables are called dummy variables.
I f  John believes ofMary that she is a fool, then, using Prolog's notation forlists we write(6) believe(john, \[mary\],q(fool(x))).The constant "mary" is called a de re argument of thepredicate "believe."
The free occurrence of x in fool(x)stands for an unspecified term that represents Mary toJohn.
This means that there is a term t that representsMary to John, and John believes fool(t), x is the dummyvariable for the de re argument "mary."
This notation isinspired by Quine (1975), but we give a semantics quitedifferent from Quine's.
Note that the symbol "believe" isComputational Linguistics Volume 16, Number 4, December 1990 215Andrew R. Haas Sentential Semantics for Propositional Attitudesan ordinary predicate letter, not a special operator?
This is aminor technical advantage of the sentential approach: thequotation operator eliminates the need for a variety ofspecial propositional ttitude operators?To define this notation precisely, we must have some wayof associating dummy variables with the de re arguments?Suppose we have the wff believe(x,\[t 1 .
.
.
t,\],q(p)).
Let v 1?
.
.
v, be a list of the free variables ofp in order of their firstoccurrence.
Then v~ will be the dummy variable for t;.
Inother words, the dummy variable for i-th de re argumentwill be the i-th free variable ofp.
This method of associat-ing dummy variables with de re arguments is somewhatarbitrary--another possibility is to include an explicit listof dummy variables?
Our choice will make the notation alittle more compact.Then the extension of the predicate "believe" is definedas follows?
Let s be an agent, \ [x~.
.
.
x,\] a list of entitiesfrom the domain of discourse, and p a wff of the targetlanguage?
Suppose that p has exactly n free variables, andlet v I .
.
.
v, be the free variables o fp  in order of their firstoccurrence?
Suppose that t~ .
.
.
t n are closed terms such thatt i represents x~ to s, for i from 1 to n. Suppose the simplebelief relation holds between s and the sentence formed bysubstituting t 1 .
.
.
t, for free occurrences v 1. .
.
v, in p. Thenthe extension of the predicate "believe" includes the triplecontaining s,\[x I .
.
.
x,\], and p.As an example, suppose the term "personl" representsMary to John, and John believes "fool(personl)."
Then,since substituting "person l" for "x" in "fool(x)" producesthe sentence "fool(person 1)," it follows that(7) believe(john,\[mary\],q(fool(x)))is true in every intended model where "believe" has theextension defined above?Consider an example with quantifiers: "John believed aprisoner escaped?"
The reading with the quantifier insidethe attitude is easy:(8) believe(john, \[\],q(some(x,prisoner(x),escaped(x)))).In this case the list of de re arguments i empty?
For the"quantifying in" reading we have:(9) some(x,prisoner(x),believe(john, \[x\],q(escaped(y)))).This says that for some prisoner x, John believes ofx that heescaped?
The dummy variable y in the wff escaped(y)stands for an unspecified term that occurs in one of John'sbeliefs and represents he prisoner x to John.Let us consider nested beliefs, as in the sentence "Johnbelieved Bill believed Mary was wise."
Here the de re~dedicto ambiguity give rise to three readings?
One is a straight-forward de dicto reading:(10) believe(john, \[\] q(believe(bill, \[\] q(wise(mary))))).To understand examples involving nested beliefs, it is help-ful to write down the sentence that each agent believes?Since this example does not involve quantifying in, it is easyto write down John's belief~we just take the quotationmark off the last argument of "believe":( 11 ) believe(bill, \[\] ,q(wise(mary))).If this belief of John's is true, then Bill believes(12) wise(mary).In the next reading, the name "Mary" is de dicto for John,but de re for Bill:(13) believe(john, \[\] q(believe(bill, \[mary\] ,q(wise(x))))).Here, John is using the constant "mary" to denote Mary,but ihe does not necessarily think that Bill is using the sameconstant--he only thinks that some term represents Maryto Bill The sentence that John believes is(14) believe(bill, \[mary\],q(wise(x))).If John is right, Bill's belief is formed by substituting forthe :free variable x in "wise(x)" some term that representsMary to Bill.
Suppose this term is "person0," then Bill'sbelief would be(15) wise(person0).Finally, there is a reading in which "Mary" is de re for bothagents:(16) believe(john,\[mary\],q(believe(bill,\[x\],q(wise(y))))).Here there is a name that represents Mary to John, andJohn thinks that there is a name that represents Mary toBill.
Again, John does not necessarily believe that Bill usesthe same name that John uses.
Suppose "person3" is theterm that represents Mary to John, then John's beliefwould, be(17) believe(bill, \[person3\] ,q(wise(y))).If "pe, rson4" is the term that represents Mary to Bill, thenBill's belief would be(18) wise(person4).One might expect a fourth reading, in which "Mary" isde re for John and de dicto for Bill, but our formalismcannot represent such a reading.
To see why, let us try toconstruct a sentence that represents this reading?
In ournotation a nonempty list of de re arguments represents a dere belief, while an empty list of de re arguments representsa de dicto belief.
Therefore the desired sentence shouldhave a nonempty list of de re arguments for John's belief,and a:a empty list for Bill's belief?
This would give(19) believe(john, \[mary\],q(believe(bill, \[\],q(wise(x)))))This sentence does not assert hat John believes Bill has ade dicto belief about Mary.
To see this, consider John'sbelief.
If he uses the constant "personl" to denote Mary,the belief is216 Computational Linguistics Volume 16, Number 4, December 1990Andrew R. Haas Sentential Semantics for Propositional Attitudes(20) believe(bill, \[\],q(wise(x))).In forming John's belief we do not substitute "personl" forthe occurrence of x under the quotation operator--becauseby our definitions this is not a free occurrence of x. ThusJohn's belief says that Bill has a belief containing a freevariable, which our theory forbids.It is not clear to me whether the desired reading exists inEnglish, so I am not certain if this property of the notationis a bug or a feature.
In either case, other notations fordescribing attitudes have similar properties.
For example,in a modal ogic of attitudes we use the scope of quantifiersto represent de re~de dicto distinctions.
If a quantifierappears in the scope of an attitude operator, we have a dedicto reading, and if it appears outside the scope (whilebinding a variable inside the scope) we get a de re reading.In a sentence like "John thinks Bill thinks Mary saw alion," there are three places to put the existential quanti-fier: in the scope of Bill's belief operator, in the scope ofJohn's operator but outside Bill's, or outside both.
Thesegive the same three readings that our formalism allows.
Tomake "a lion" be de re for John and de dicto for Bill, wewould have to put the quantifier outside the scope of John'sbelief operator, but inside the scope of Bill's belief operator.Since Bill's belief operator is in the scope of John's, that isimpossible.The same method applies to other attitudes--for exam-ple, knowledge.
Given a simple knowledge relation, whichexpresses de dicto readings of sentences with "know," onecan define the predicate "know," which expresses both dere and de dicto readings.
"Know" will take three argu-ments just as "believe" does.Next we consider examples like "John knows who likesMary," in which "know" takes a wh noun phrase and asentence containing a gap.
The intuition behind our analy-sis is that John knows who likes Mary if there is a person ssuch that John knows that s likes Mary.
This is of course ade re belief report, and its logical form should be(21) some(x,person(x),know(john, \[x\],q(like(y,mary)))).As an example, suppose the sentence(22) like(bill,mary)is one of John's beliefs, and it belongs to the subsetof beliefs that constitute his knowledge.
If the constant"bill" represents Bill to John, then since substituting"bill" for "y"  in "l ikes(y,mary)" gives the sentence"like(bill,mary)," we have(23) know(john,\[bill\],q(like(y,mary)))and therefore(24) some(x,person(x),know(john, \[x\],q(like(y,mary)))).This proposed analysis of "knowing who" is probably tooweak.
As a counter example, suppose a night watchmancatches a glimpse of a burglar and chases him.
Then thenight watchman has formed a mental description of theburglar--a description that he might express in English as"the man I just saw sneaking around the building."
Theburglar might say to himself, "He knows I'm in here."
Thisis a de re belief report, so it follows that the night watch-man's mental description of the burglar must represent theburglar to the watchman (by our assumption about repre-sentation).
Yet the night watchman surely would not claimthat he knows who is sneaking around the building.
Itseems that even though the watchman's mental descriptionrepresents the burglar, it is not strong enough to supportthe claim that he knows who the burglar is.It would be easy to extend our notation to allow for adifference between "knowing who" and other cases ofquantification i to attitudes.
It would be much harder toanalyze this difference, B/Ser and Lycan (1986) have ar-gued that when we say someone knows who N is, we alwaysmean that someone knows who N is for some purpose.
Thispurpose is not explicitly mentioned, so it must be under-stood from the context of the utterance in which the verb"know" appears.
Then the predicate that represents "know-ing who" must have an extra argument whose value issomehow supplied by context.
These ideas look promising,but to represent this use of context in a grammar is a hardproblem, and outside the scope of this work.Next we consider intensional transitive verbs like "want,"as in "John wants a Porsche."
The intuition behind theanalysis is that this sentence is roughly synonymous with"John wishes that he had a Porsche"--under a reading inwhich "he" refers to John.
Then the logical form would be(25) wish(john,\[\],q(some(x,porsche(x),have(john,x))))for a de dicto reading, and(26) some(x,porsche(x),wish(john, \[x\] q(have(john,y))))for a de re reading.
The predicate letter "wish" need not beidentical to the one that translates the English verb"wish"-- it might only be roughly synonymous.
The predi-cate letter "have" probably is the same one that translatesthe verb "have"---or ather, one of many predicates thatcan translate this highly ambiguous verb.
For the presentpurpose let us assume that the predicate "have" representsa sense of the verb "have" that is roughly synonymous with"possess," as in "John has a Porsche."
Another sense of"have" is relational, as in "John has a son," and "want" hasa corresponding sense, as in "John wants a son."
Thepresent paper will not analyze this relational sense.This grammar will express the meanings of intensionalverbs in terms of propositional ttitudes.
This may not workfor all intensional verbs.
For example, it is not clear that"the Greeks worshipped Zeus" is equivalent to any state-ment about propositional ttitudes.
Montague (1974a) rep-resented intensional verbs more directly, as relations be-tween agents and the intensions of NP's.
A similar analysisis possible in our framework, provided we extend the targetlanguage to include typed lambda calculus.
Suppose theComputational Linguistics Volume 16, Number 4, December 1990 217Andrew R. Haas Sentential Semantics for Propositional Attitudesvariable p ranges over sets of individuals.
Then we couldrepresent the de d icto  reading of"John wants a Porsche" as(27) want(john,q(lambda(p,some(x,porsche(x),x e p)) ).Here the predicate "want" describes a relation between aperson and an expression of thought language, but thatexpression isnot a wff.
Instead it is a closed term denoting aset of sets of individuals.
Certainly this is a natural general-ization of a sentential theory of attitudes.
If agents canhave attitudes toward sentences of thought language, whyshouldn't hey have attitudes toward other expressions ofthe same thought language?1.4 COMPOSITIONAL SEMANTICS AGAINWe now return to the problem of building logical formswith a compositional semantics.
Consider the formula(28) some(x,prisoner(x),believe(john,\[x\],q(escaped(y)))).Following Cooper as before, we assume that the semanticfeatures of the clause "a prisoner escaped" are a wffcontaining a free variable and an existential quantifier thatbinds the same variable.
In formula (28) the existentialquantifier does not bind the variable that appears in the wff"escaped(y)"-- it  binds another variable instead.
Thereforewe have the same problem that arose for Kaplan's represen-ta t ion- i t  is not clear how to build a representation for thebelief sentence from the representations of its constituents.The choice of bound variables is arbitrary, and the choiceof dummy variables is equally arbitrary.
Thus, there is anobvious solution: let the de re arguments and the dummyvariables be the same.
Thus, the wide scope reading for"John believes a prisoner escaped" is not (28), but(29) some(x,prisoner(x),believe(john,\[xl,q(escaped(x)))).Here the variable x serves two purposes--it is a de reargument, and also a dummy variable.
When it occurs as ade re argument, it is bound by the quantifier in the usualway.
When it occurs as a dummy variable, it is definitelynot bound by the quantifier.
In fact the dummy variable is amention of the variable x, not a use, because it occurs undera quotation mark.Formula (29) may be a little confusing, since the samevariable appears twice with very different semantics.
Thisformula has a major advantage over formula (28), how-ever--it contains the wff "escaped(x)" and a quantifierthat binds the free variable of that wff.
Since these areprecisely the semantic features of the clause "a prisonerescaped," it is fairly easy to build the logical form (29)from the sentence "John believed a prisoner escaped.
"We can describe this technique as a convention govern-ing the logical forms that our grammar assigns to Englishphrases.
In any wff of the form believe(x,\[tl ?
?
?
t~\], q(p)),the nth de re argument is equal to its own dummy variable.Then the nth de re argument ~ is equal to the nth freevariable ofp.
In other words, the list \[t I .
.
.
t~\] is just a listof the free variables of p in order of occurrence.
The sameconvention holds for all predicates that represent attitudes.Finally, note that the convention holds only for thelogical forms that the grammar assigns to sentences.
Oncethe grammar has built a logical form, inference procedurescan fi:eely violate the convention.
For example, consider thelogical form of the sentence "Every man believes that Maryloves him":(30) all(x,man(x),believe(x, \[ \],q(love(mary,x)))).From this sentence and the premise man(bill) we can infer(31) believe(bill, \[bill\],q(love(mary,x)))by substituting for a universal variable as usual.
The occur-rence of the variable under the quotation mark is naturallyunaffected, because it is not a free occurrence ofx.1.5 SELF-REFERENCE AND PARADOXOther writers (cited above) have already expounded anddefended sentential theories of attitudes.
This paper takes asentential theory as a starting point, and aims to solvecertain problems about the semantics of attitude reports insuch a theory.
However, one problem about sententialtheories deserves discussion.
The results of Montague(1974b) have been widely interpreted as proof that senten-tial theories of attitudes are inconsistent and thereforeuseless.
Montague did indeed show that certain sententialtheories of knowledge produce self-reference paradoxes,and are therefore inconsistent.
However, he did not showthat these were the only possible sentential theories.
Re-cently des Rivi6res and Levesque (1986) have constructedsentential theories without self-reference and proved themconsiistent.
Thus they showed that while Montague's theo-rem was true, its significance had been misunderstood.Perlis (1988) has shown that if we introduce self-referenceinto a modal theory, it too can become inconsistent.
Inshort, there is no special connection between sententialtheories and paradoxes of self-reference.
A sentential the-ory may or may not include self-reference; a modal theorymay or may not include self-reference; and in either case,self-reference an lead to paradoxes.Kripke (1975) has shown that even the most common-place utterances can create self-reference if they occur inunusual circumstances.
Therefore the problem is not toavoid self-reference, but to understand it.
The problem foradvocates of sentential theories is to find a sentential naly-sis of the self-reference paradoxes that is, if not whollysatisfactory, at least as good as nonsentential nalyses.
Forthe purposes of AI, a successful analysis must avoid para-doxical conclusions, without sacrificing axioms or rules ofinference that have proved useful in AI programs.One idea is that ordinary human intuitions about self-reference are inconsistent.
To most people, it appears thatthe ..sentence "This statement is false" must be both trueand false, yet it cannot be both.
The only error in the formalanalyses is that having derived a contradiction, they allowus to derive any conclusion whatever.
This happens because218 Computational Linguistics Volume 16, Number 4, December 1990Andrew R. Haas Sentential Semantics for Propositional Attitudesstandard logic allows no inconsistent theories except rivialones, containing every sentence of the language.
Thereforewe need a new kind of logic to describe the inconsistentintuitions of the ordinary speaker.
Priest (1989) attemptedthis--he constructed an inconsistent but nontrivial theoryof truth using a paraconsistent logic.
Priest's theory in-cludes the T-scheme, written in our notation as(32) P ~ true(q(P)).P is a meta-variable ranging over sentences of the lan-guage.
Tarski (1936) proposed this scheme as capturing anessential intuition about truth.
Unfortunately, the rule ofmodus ponens is invalid in Priest's system, which meansthat most of the standard AI reasoning methods are invalid.Priest considers various remedies for this problem.Another approach is to look for a consistent theory ofself-reference.
Such a theory will probably disagree withspeakers' intuitions for paradoxical examples like "Thisstatement is false."
Yet these examples are rare in practice,so a natural anguage program using a consistent theory ofself-reference might agree with speakers' intuitions in thevast majority of cases.
Kripke (1975) proposed such atheory, based on a new definition of truth in a model--analternative to Tarski's definition.
Kripke's definition allowstruth-value gaps: some sentences are neither true nor false.Suppose P is a sentence; then the sentence true(q(P)) istrue iff P is true, and false iff P is false.
Therefore if P isneither true nor false, true(q(P)) also has no truth value.
Inother respects, Kripke's definition of truth resembles Tar-ski 's-- it  assigns the same truth values to sentences that donot contain the predicate "true," and it never assigns twodifferent ruth values to one sentence.
Suppose that a modelof this kind contains a sentence that says " I  am not true.
"Formally, suppose the constant c denotes the sentence--7 true(c).
What truth value can such a sentence have underKripke's definition?
Just as in standard logic, m true(c) istrue iff true(c) is false.
True(c) in turn is false iff c is false.Since c is the sentence m true(c), we have shown that c istrue iff c is false.
Since no sentence has two truth values, itfollows that c has no truth value.Once again, problems arise because the system is tooweak.
If P is a sentence with no truth value, then thesentence P V m P has no truth value, even though it is atautology of first-order logic.
One remedy for this appearsin the system of Perlis (1985).
Perlis considers a first-ordermodel M containing a predicate "true," whose extension isthe set of sentences that are true in M by Kripke's defini-tion.
He accepts as theorems all sentences that are Tarski-true in every model of this kind.
Thus Perlis's system usestwo notions of truth: P is a theorem only if P is Tarski-true,but true(q(P)) is a theorem only if P is Kripke-true.Suppose we have P ~ m true(q(P)); then Perlis's systemallows us to prove both P and m true(q(P)).
This certainlyviolates the intuitions of ordinary speakers, but such viola-tions seem to be the inevitable price of a consistent theoryof self-reference.
Perlis devised a proof system for suchmodels, using standard first-order proof and an axiomschema GK for the predicate "true."
Perlis proved that if Lis any consistent set of first-order sentences that does notmention the predicate "true," then the union of L and GKhas a model M in which the extension of "true" is the set ofsentences that are Kripke-true in M. Perlis's system hasone important advantage over Kripke's: since the formal-ism is just a standard first-order theory, we can use all thefamiliar first-order inference rules.
In this respect, Perlis'ssystem is better suited to the needs of AI than eitherKripke's or Priest's.
However, it still excludes ome infer-ences that are standard in everyday reasoning.
For exam-ple, we have true(q(P)) ~ P for every P, but P ~ true(q(P))is not a theorem for certain sentences P-- in particular,sentences that are self-referential nd paradoxical.An adequate account of self-reference must deal not onlywith the Liar, but also with paradoxes arising from proposi-tional attitudes--for example, the Knower Paradox (Mon-tague and Kaplan 1974), and Thomason's paradox aboutbelief (Thomason 1980).
Perlis (1988) has considered thetreatment of attitudes within his system, and Asher andKamp (1986) have treated both paradoxes using ideas akinto Kripke's (their treatment is not sentential, but theyclaim that it could be extended to a sentential treatment).Let us briefly consider the treatment of the Knowerparadox within Perlis's system.
To simplify the treatment,we will assume that knowledge is true belief.
I f  we areworking in Perlis's system, this naturally means that knowl-edge is Kripke-true belief.
We write "the agent knows thatP" as true(q(P)) A believe(q(P)).
The paradox arises froma sentence R that says "The agent knows --hR."
Formally,(33) R ,---, (true(q(mR)) A believe(q(mR))).Since true(q(mR)) ~ mR is a theorem of Perlis's system,(33) implies --hR.
Now suppose that the agent believes (33);then with modest powers of inference the agent can con-clude mR, so we have believe(qmR).
Combining this with(33) gives(34) R ~ true(q(mR)),which at once implies that --nR is not Kripke-true.
It followsthat although mR is a theorem of the system, and the agentbelieves it, the agent does not know it--because it is notKripke-true, and only a sentence that is Kripke-true can beknown.
The Knower paradox arises if we insist that theagent does know mR.
This example brings out a counter-intuitive property of Perlis's system: a sentence may followdirectly from Perlis's axioms, yet he refuses to call it true,or to allow that any agent can know it.
Strange though thisappears, it is a natural consequence of the use of twodefinitions of truth in a single theory.Belief is different from knowledge because it need not betrue.
This makes it surprising that Thomason's paradoxinvolves only the notion of belief, not knowledge or truth.
Infact the paradox arises exactly because Thomason's agentthinks that all his beliefs are true.
This is stated as(35) a(< a(< ?
>) --~ ~ >)Computational Linguistics Volume 16, Number 4, December 1990 219Andrew R. Haas Sententiai Semantics for Propositional Attitudes(Thomason 1980).
The notation is as follows: ~P is a vari-able ranging over all formulas of the language, < ~P > is aconstant denoting (the G6del number of) ~P, and a (< ~P >)means that the agent believes ~P.
This axiom says that forevery formula ~o, the agent believes(36) a (< ~o >) ~ ~p.This sentence says that if the agent believes ~o, ~o must betrue.
Since ~o ranges over all sentences of the language, theagent is claiming that his beliefs are infallible.
This leadsthe agent into a paradox similar to the Knower, and hisbeliefs are therefore inconsistent.
Asher and Kamp showedthat one can avoid this conclusion by denying (35) incertain cases where 4~ is a self-referential sentence.
Anotheralternative is to dismiss (35) completely.
It is doubtful thathuman beings consider their own beliefs infallible, andPerlis (1986) has argued that a rational agent may wellbelieve that some of his or her beliefs are false.We have looked at three sentential analyses of the self-reference paradoxes, and each one sacrifices ome principlethat seems useful for reasoning in an AI program.
Thealternative is an analysis in which propositions are notsentences.
Thomason (1986) considers uch analyses andfinds that they have no clear advantage over the sententialapproaches.
The unpleasant ruth is that paradoxes ofself-reference reate qually serious problems for all knowntheories of attitudes.
It follows that they provide no evi-dence against he sentential theories.2 THE BASIC GRAMMAR2.1 NOTATIONThe rules of our grammar are definite clauses, and we usethe notation of definite clause grammar (Pereira and War-ren 1980).
This notation is now standard among computerscientists who study natural anguage and is explained in atextbook by Pereira and Shieber (1987).
Its advantagesare that it is well defined and easy to learn, because it is anotational variant of standard first-order logic.
Also, it isoften straightforward to parse with grammars written inthis notation (although there can be no general parsingmethod for the notation, since it has Turing machinepower).
DCG notation lacks some useful devices found inlinguistic formalisms like GPSG-- there are no defaultfeature values or general feature agreement principles(Gazdar et al 1985).
On the other hand, the declarativesemantics of the DCG notation is quite clear--unlike thesemantics of GPSG (Fisher 1989).The grammar isa set of meta-language s ntences describ-ing a correspondence b tween English words and sentencesof the target language.
Therefore, we must define a nota-tion for talking about the target language in the meta-language.
Our choice is a notation similar to that of Haas(1986).
I f  f is a symbol of the target language, 'f  is a symbolof the meta-language.
Suppose f is a constant or a variable,taking no arguments.
Then 'f  denotes f. Thus 'john is ameta-language constant that denotes a target-languageconstant, while 'x is a meta-language constant that denotesa target-language variable.
Suppose f is a functor of thetarget language and takes n arguments.
Then ' f  is a meta-language function letter, and it denotes the function thatmaps n expressions of the target language l ?
?
?
en to thetarget-language expression f (e l .
.
,  en).
Thus 'not is a meta-language function letter, and it denotes the function thatmaps a target language wff to its negation.
In the sameway, 'or is a meta-language function letter, and it denotesthe function that maps two target-language wffs to theirdisjunction.Given these denotations, it is easy to see that if p(a,b) isan atomic sentence in the target language, then 'p('a,'b) isa term in the meta-language, and it denotes the wff p(a,b)in the target language.
Suppose that Wffl and Wff2 aremeta-language variables ranging over wffs of the targetlanguage.
Then 'or(Wffl,Wff2) is a meta-language t rm,and since the variables Wffl and Wff2 range over all wffs ofthe target language, the value of 'or(Wffl,Wff2) rangesover all disjunctions in the target language.
These ideasabout the relation between meta-language and target lan-guage are not new or difficult, but it is worth the time toexplain them, because some influential papers about seman-tics in unification grammar have confused the target lan-guage and meta-language (see Section 2.4).
For the sake oflegibility, we omit the quotation marks - - so  whenor(Wffl,Wff2) appears in a rule of the grammar, it is anabbreviation for 'or(Wffl,Wff2).2.2 REPRESENTING QUANTIFIERSNoun phrases in the grammar contribute to logical form intwo ways, and therefore they have two semantic features.The first feature is a variable, which becomes a logicalargument of a verb.
This produces a wiT, in which thevariaN, e appears free.
The second feature is a quantifierthat binds the variable.
By applying the quantifier to thewff, we eliminate free occurrences of that particular vari-able.
After applying all the quantifiers, we have a wffwithout free variables--a sentence.
This is the logical formof an utterance.In Montague's ystem (Montague 1974a), the logicalform of an NP is an expression denoting a quantifier.
Thiskind of analysis is impossible in our system, because thetarget language is first-order.
It contains no expressionsthat denote quantifiers.
Therefore the representation f anNP cannot be an expression of the target language.
Insteadof using Montague's approach, we associate with everyquantifier a function that maps wffs to wffs.
For the NP"every man," we have a function that maps any wff Wffl tothe wff(37) all(V,man(V),Wffl)where V is a variable of the target language.
Notice that ifwe took Montague's representation for the quantified NP,applied it to the lambda expression lambda(V,Wffl),  andthen simplified, we would get an alphabetic variant of (37).220 Computational Linguistics Volume 16, Number 4, December 1990Andrew R. Haas Sentential Semantics for Propositional AttitudesWe will call this function the application function for thequantified NP.To represent application functions in a unification gram-mar, we use a device from Pereira and Warren (1980).
Weassign to each NP an infinite set of readings----one for eachordered pair in the extension of the application function.The first and second elements of the ordered pair aresemantic features of the NP, and the bound variable of thequantifier is a third feature.
For the NP "every man" wehave(38) np(V,Wffl,all(V,man(V),Wffl)) ---- \[every man\].This says that for any variable V and wff Wffl, the string"every man" is an NP, and if it binds the variable V, thenthe pair \[Wffl,all(V,man(V),Wffl)\] is in the extension ofits application function.
It follows that the applicationfunction maps Wffl to the wff all(V,man(V),Wffl).
Whenother rules fix the values of the variables V and Wffl, theresult of the mapping will be fixed as well.
A more complexexample is(39) np(V,Wff l ,and(some(V,man(V),Wff l) ,some(V,woman(V),Wffl))) ~ \[a man and a woman\].Here the application function's output includes two copiesof the input.It is important to consider the declarative semantics ofthese rules.
Each one states that a certain NP has aninfinite set of possible readings, because there are infinitelymany wffs in the target language.
Thus we might say thatthe NP in isolation is infinitely ambiguous.
This "ambiguity"is purely formal, however; in any actual utterance the valueof the variable Wffl will be supplied by other rules, so thatin the context of an utterance the ambiguity is resolved.
Inthe same way, the VP "liked Mary" is ambiguous in personand number--but in the context of the utterance "Johnliked Mary," its person and number are unambiguous.In one respect the declarative semantics of these rules isnot quite right.
The variable V is supposed to range overvariables of the target language, and the variable Wffl issupposed to range over wffs of the target language.
Yet wehave not defined a type system to express these rangerestrictions.
However, such a type system could be added,for example, using the methods of Walther (1987).
In fact,the type hierarchy would be a tree, which allows us to use asimplified version of Walther's methods.
For brevity's akewe will not develop a type system in this paper.
Except forthis omission, the declarative semantics of the above rules isquite clear.Typed variables have mnemonic value even if we do notuse a typed logic.
Therefore we adopt he following conven-tions.
The meta-language variables V, V0, V1 .
.
.
rangeover target language variables.
Wff, Wffl, Wf f2 .
.
.
rangeover target language wffs.
Q, Q1, Q2 .
.
.
range overquantifiers.
QL, QL1, QL2 .
.
.
range over lists of quanti-tiers.
When a wff forms the range restriction of a quantifier,we will sometimes use the variables Range, Range l .
.
.
forthat wiT.2.3 SCOPING AND QUANTIFIER STORAGEGiven a means of describing quantifiers, we must considerthe order of application.
Cooper (1983) has shown how toallow for different orders of application by adding to NPs,VPs, and sentences an extra semantic feature called thequantifier store.
The store is a list of quantifiers that bindthe free variables in the logical form of the phrase.
Thegrammar emoves quantifiers from the store and appliesthem nondeterministically to produce different logical forms,corresponding to different orders of application.
If a sen-tence has a logical form p and a quantifier store 1, thenevery free variable in p must be bound by a quantifier in/--otherwise the final logical form would contain freevariables.Our treatment of quantifier storage is different fromCooper's in two ways.
First, Cooper's grammar mapsphrases to model-theoretic denotations, not logical forms.This sounds like a bigger difference than it is.
The basictechnique is to put quantifiers in a store, and use some kindof marker to link the stored quantifiers to the argumentpositions they must bind.
Whether we work with the logicalforms or with their denotations, much the same problemsarise in applying this technique.A second difference is that in Cooper's grammar, eachNP has two readings---one in which the NP's quantifier isin the store, and one in which it is not.
The first readingleads to wide-scope readings of the sentence, while thesecond leads to narrow-scope readings.
In our grammaronly the first kind of reading for an NP exists--that is, thequantifier of an NP is always in the store.
We generate bothwide- and narrow-scope readings by applying the quanti-tiers from the store in different orders.We represent a quantifier as a pair p(Wffl,Wff2), wherethe application function of the quantifier maps Wffl toWff2.
We represent a quantifier store as a list of such pairs.The predicate apply_quants(QLI,Wffl,QL2,Wff2) meansthat QL1 is a list of quantifiers, Wffl is a wff, Wff2 is theresult of applying some of the quantifiers in QL1 to Wffl,and QL2 contains the remaining quantifiers.
The firstaxiom for the predicate says that if we apply none of thequantifiers, then QL2 = QL1 and Wff2 = Wffl:(40) apply_quants(QL,Wff, QL,Wff).The second axiom uses the predicate choose(L1,X,L2),which means that X is a member of list L1, and L2 isformed by deleting one occurrence ofX from L1.
(41)apply_quants(QLl,Wffl,QL3,Wff3):- choose(QL 1,p(Wffl,Wff2),QL2),apply_quants(QL2,Wff2,QL3,Wff3).Consider the first literal on the right side of this rule.
It saysthat p(Wffl,Wff2) is a member of QL1, and deletingp(Wffl,Wff2) from QL1 leaves QL2.
By definition, if thepair p(Wffl,Wff2) is in the extension of the applicationfunction for a certain quantifier, the application functionComputational Linguistics Volume 16, Number 4, December 1990 221Andrew R. Haas Sentential Semantics for Propositional Attitudesmaps Wffl to Wff2.
The second literal says that applying asubset of the remaining quantifiers QL2 to Wff2 gives anew wff Wff3 and a list QL3 of remaining quantifiers.
Thenapplying a subset of QL1 to Wffl gives Wff3 with remain-ing quantifiers QL3.Suppose that QL1 is(42) \[p(Wffl ,all(V 1 ,man(V 1 ),Wffl)),p(Wff2,some(V2,woman(V2),Wff2) )\].Then solutions for the goal(43) :- apply_quants(QLl,loves(V1,V2),QL3,Wff3)include(44)Wff3 = all(V 1,man(V 1),some(V2,woman(V2),loves(V 1 ,V2)))QL3 = \[\]and also(45)Wff3 = some(V2,woman(V2),all(Vl,man(V1),loves(V1,V2)))QL3 = \[\].There are also solutions in which some quantifiers remainin the store:(46)Wff3 = all(V 1 ,man(V 1 ),loves(V 1 ,V2))QL3 = \[p(Wff2,some(V2,woman(V2),Wff2))\].These solutions will be used to build wide-scope readingsfor propositional ttitude reports.2.4 THE PROBLEM OF ASSIGNING DISTINCTVARIABLES TO QUANTIFIERSThe rules we have given so far do not tell us which targetlanguage variables the quantifiers bind.
These rules containmeta-language variables that range over target languagevariables, rather than meta-language constants that denoteparticular variables of the target language.
In choosing thebound variables it is sometimes crucial to assign distinctvariables to different quantifiers.
The logical form of"Someman loves every woman" can be(47) some(x,man(x),all(y,woman(y),loves(x,y)))but it cannot be(48) some(y,man(y),all(y,woman(y),loves(y,y))).This reading is wrong because the inner quantifier capturesthe variables that are supposed to be bound by the outerquantifier.
To be more precise: the outer quantifier bindsthe variable y, but not all occurrences of y in the scope ofthe outer quantifier are bound by the outer quantifier.Some of them are bound instead by the inner quantifier.
Inthis situation, we say that the inner quantifier shadows theouter one.
We require that no quantifier ever shadowsanother in any logical form built by the grammar.
Thisrequirement will not prevent us from finding logical formsfor English sentences, because any first-order sentence islogically equivalent to a sentence without shadowing.The same problem arises in cases of quantification i tothe ,;cope of attitudes.
Consider the sentence "John thinkssome man loves every woman," and suppose that "someman" has wide scope and "every woman" has narrowscope.
The logical form can be(49)some(x,man(x),thinks(john,\[x\],q(all(y,woman(y),loves(x,y)))))but it cannot be(50)some(y,man(y),thinks(john,\[y\],q(all(y,woman(y),loves(y,y))))).In this formula, the inner quantifier captures a variablethat is supposed to be a dummy variable.
In this case also,we say that the inner quantifier shadows the outer one.Pereira and Warren (1980) prevented shadowing byusing Prolog variables to represent variables of the objectlanguage.
Thus, their translation for "Some man lovesevery woman" is(51) exists(Y) : (man(Y) & all(X) : (woman(X) =~loves(Y,X)))where X and Y are Prolog variables.
This works, but itviolates the declarative semantics of Prolog.
According tothat semantics every variable in an answer is universallyquantified.
Thus if Prolog returns (51) as a description ofthe logical form of a sentence, this means that for all valuesof X and Y the expression (51) denotes a possible logicalform tbr that sentence.
This means that if v is a variable ofthe object language, then(52) exists(v) : (man(v) & all(v) : (woman(v) =~loves(v,v)))is a possible translation, which is clearly false.
Thus, accord-ing to the declarative interpretation, Pereira and Warren'sgrammar does not express the requirement that no quanti-fier can shadow another quantifier.
Pereira and Shieber(198;7) pointed out this problem and said that while for-mally incorrect the technique was "unlikely to causeproblems."
Yet on p. 101 they describe the structures builtby their grammar as "unintuitive" and even "bizarre.
"This confirms the conventional wisdom: violating the declar-ative ,;emantics makes logic programs hard to understand.Therefore, let us look for a solution that is formally correct.Warren (1983) suggested one possible solution.
We canuse a global counter to keep track of all the variables usedin the logical form of a sentence, and assign a new variableto every quantifier.
Then no two quantifiers would bind thesame variable, and certainly no quantifier would shadowanother.
This solution would make it easier to implementour treatment of de re attitude reports, but it would alsocreate, serious problems in the treatment of NP conjunction222 Compultational Linguistics Volume 16, Number 4, December 1990Andrew R. Haas Sentential Semantics for Propositional Attitudesand disjunction (see Section 2.5).
Therefore we consideranother possibility.Let us rewrite the definition of "apply_quants," addingthe requirement that each quantifier binds a variable that isnot bound in the scope of that quantifier.
For each integerN, let v(N) be a variable of the target language.
If N is notequal to M, then v(M) and v(N) are distinct variables.
Werepresent the integers using the constant 0 and the function"s" for "successor" in the usual way.
The predicatehighest_bound_var(Wffl,N) means that N is the largestnumber such that v(N) is bound in Wffl.
To define thispredicate, we need one axiom for each quantifier, connec-tive, and predicate letter of the target language.
Theseaxioms are obvious and are therefore omitted.We also need the predicate binds(Wffl,V), which meansthat the outermost quantifier of Wffl binds the variable V.To define this predicate we need an axiom for each quanti-fier and connective.
Typical axioms are:(53) binds(all(V,Wffl,Wff2),V).
(54) binds(and(Wffl,Wff2),V) :- binds(Wffl,V).The second axiom applies to complex quantifiers arisingfrom conjoined NPs.
In this case there are two branches,but each branch binds the same variable (the rules for NPconjunction ensure that this is so).
Therefore, we recur-sively check the first branch to find the bound variable.Given these predicates, we can rewrite the second axiomfor "apply_quants":(55)apply_quants(QLl,Wffl,QL3,Wff3):- choose(QL 1,p(Wffl ,Wff2),QL2),highest_bound_var(Wffl,N),binds(Wff2,v(s(N))),apply_quants(QL2,Wff2,QL3,Wf3).Wffl is the scope of the quantifier, and v(N) is the highestbound variable of Wffl.
The new quantifier binds thevariable v(s(N)), which is different from every boundvariable in the scope Wffl.
Therefore, the new quantifier isnot shadowed by any lower quantifier.As an example, suppose that QL1 is(56) \[p(Wff2,all(V2,woman(V2),Wff2))\].Then solutions for the goal(57) :- apply_quants(QLl,loves(V1,V2),QL3,Wff3)include(58)Wff3 = all(v( 1 ),woman(v( 1 )),loves(v( 1 ),V2)))QL3 = \[\].
(We have reverted to standard notation for integers.)
Sup-pose that QL1 is(59)  \ [p(Wff l ,some(V 1,man(V 1),Wff l ) ) ,p(Wff2,al l(V2,woman(V2), Wff2) )\].Then solutions for the goal(6O):- apply_quants(QL 1 ,loves(V 1,V2),QL3,Wff3).include(61)Wff 3 = some(v(2),man(v(2),all(v(1),woman(v(1),loves(v(Z),v(1))))QL3 = \[\].The inner quantifier binds the variable v(1), and the outerquantifier binds the variable v(2).
This notation for vari-ables is very hard to read, so in the rest of the paper we willuse the constants x, y, and z to represent variables of thetarget language.2.5 RULES FOR NOUN PHRASESThe following grammar is very similar to the work ofPereira and Shieber (1987, Sections 4.1 and 4.2).
There aretwo major differences, however, First, the treatment ofquantifiers and scoping uses a version of Cooper's quanti-fier storage, instead of the "quantifier tree" of Pereira andShieber.
Second, Pereira and Shieber started with a seman-tics using lambda calculus, which they "encoded" in Pro-log.
In the present grammar, unification semantics tandson its own--it is not a way of encoding some other formal-ism.Formula numbering uses the following conventions.
Therules of the grammar are numbered (R1), (R2), etc.
En-tries in the lexicon are numbered (L 1), (L2), etc.
Formulasbuilt in the course of a derivation get numbers without aprefix.
Groups of related rules are marked by lower caseletters: (Lla), (Llb), and so forth.Every noun phrase has a quantifier store as one of itssemantic features.
If the NP is a gap, the store is empty; ifthe NP is not a gap, the first element of the store is thequantifier generated by the NP (in the present grammar,the quantifier store of an NP has at most one quantifier).We represent the quantifier store as a difference list, usingthe infix operator "-".
Thus if L2 is a tail of L1, L1-L2 isthe list difference of L 1 and L2: the list formed by removingL2 from the end of L1.
Therefore a noun phrase has theform np(V,QL1-QL2,Fx-Fy,VL).
V is the bound variableof the NP.
QL1-QL2 is the quantifier store of the NP.
Wedescribe wh-movement using the standard gap-threadingtechnique (Pereira and Shieber 1987), and Fx-Fy is thefiller list.
Finally, VL is a list of target-language variablesrepresenting NPs that are available for reference by apronoun, which we will call the pronoun reference list.Consider an NP consisting of a determiner and a headnoun: "every man," "no woman," and so forth.
The headnoun supplies the range restriction of the NP's quantifier,and the determiner builds the quantifier given the rangerestriction.
The bound variable of the NP is a feature ofboth the determiner and the head noun.
Then the followingrule generates NPs consisting of a determiner and a headComputational Linguistics Volume 16, Number 4, December 1990 223Andrew R. Haas Sentential Semantics for Propositional Attitudesnoun:(R1)np(V,\[Q\[ QL\]-QL,Fx-Fx,VL)---- det(V,Wffl,Q),n(V,Wffl ).The quantifier list \[Q\[QL\] - QL = \[Q\] contains thequantifier for the NP.
We have the following rules forcommon ouns:(R2a) n(Vl,pizza(V1)) ~ \[pizza\](R2b) n(Vl,man(V1))--* \[man\](R2c) n(Vl,woman(V1))~ \[woman\].Recall that p(Wffl,Wff2) is a quantifier that maps Wffl toWff2.
Then for determiners we have(R3a) det(V2,Range,p(Wffl,some(V2,Range,Wffl))) ---~\[a\](R3b) det(V2,Range,p(Wffl,all(V2,Range,Wffl))) --*\[every\](R3c) det(V2,Range,p(Wffl,unique(V2,Range, Wffl)))\[the\](R3d) det (V2,Range,p(Wffl ,not (some(V2,Range,Wffl))))---- \[no\].Then we get(62) np(V,\[p(Wffl,all(V,man(V),Wffl))\[ QL\]-QL,Fx-Fx,L) ~ \[every man\](63) np(V,\[p(Wffl,not(some(V,woman(V),Wffl)))\[QL\]-QL,Fx-Fx,L) ~ \[no woman\].Thus "every man" is an NP that binds the variable V andmaps Wffl to all(V,man(V),Wffl).Following Moore (1988), we interpret he proper name"John" as equivalent to the definite description "the onenamed "John."
"(R4)np(V,\[p(Wff, unique(V,name(V,C),Wff)) I QL\]-QL,Fx-Fx,VL)\[Terminal\], { proper_noun(Terminal,C) }.The wff proper_noun(X,Y) means that X is a proper nounand Y is its logical form.
Our lexicon includes the axioms(Lla) proper_noun(john,john)(Llb) proper_noun(mary,mary)(L1 c) proper_noun(bill,bill).These axioms use the constant "john" to denote both aterminal symbol of the grammar and a constant of thetarget language--a convenient abuse of notation.
Using(Lla) we get(64) np(V, \[p(Wffl,unique(V,name(V,john),Wffl))\[ QL\]-QL,Fx-Fx,VL)---, \[john\].That is, "john" is an NP that binds the variable V and mapsWffl to the wff unique(V,name(V,john),Wffl).Pronouns use the "let" quantifier.
We have(R5)np(V2, \[p(V2,Wffl , et(VE,V,Wffl ))l QL\]-QL,Fx-Fx,VL)---- \[he\], {member(V,VL)}.If V is a variable chosen from the pronoun reference listVL, then "he" is an NP that binds the variable V2 andmaps Wffl to let(V2,V,Wffl).
Thus, the pronoun refersback to a noun phrase whose bound variable is V. Later, wewi',\] see the rules that put variables into the list VL.
As anexample, we have(65) np(V2,\[p(Wffl,let(V2,Vl,Wffl))\[ QL\]-QL,Fx-Fx,\[V1\]) ~ \[he\].The "let" quantifier in pronouns looks redundant, but itis useful because it makes the semantics of NPs uniform--ew~ry NP (except gaps) has a quantifier.
This is helpful indescribing conjoined NPs.
Suppose that NP1 binds vari-able V and maps Wffl to Wff2.
Suppose NP2 also bindsvariable V and maps the same Wffl to Wff3.
Then theconjunction of NP1 and NP2 binds V and maps Wffl toand(Wff2,Wff3):(R6) np(V,\[p(Wffl,and(Wff2,Wff3))\[ QL1\]-QL3,Fx-Fx,VL)---, np(V,\[p(Wffl,Wff2)l QL1\]-QL2,Fz-Fz,VL),\[and\],np(V,\[p(Wffl,Wff3)\[ QL2\]-QL3,Fy-Fy,VL).As an example we have(66)(6"7)(68)np(V, \[p(Wffl ,all(V,man(V),Wffl ))1QL 1 \] -QL 1,Fx-Fx,L) --, \[every man\]np(V, \[p(Wffl,all(V,woman(V),Wffl))\[ QL2\]-QL2,Fx-Fx,L) --, \[every woman\]np(V,\[p(Wffl,and(all(V,man(V),Wffl),all(V,woman(V),Wffl))) \[ QL1\]-QL1,Fx-Fx,VL)--~\[every man and every woman\].That is, "every man and every woman" is an NP that bindsvariable V and maps Wffl to(6!))
and(all(V,man(V),Wffl),all(V,woman(V),Wffl)).We also have(70) np(V,\[p(Wffl,let(V,V1,Wffl))\[ QL1\]-QL1,Fx-Fx,\[V1\])---- \[he\](71) np(V, \[p(Wffl,unique(V,name(V,john),Wffl))lQL2\]-QL2,Fx-Fx,VL)--, \[john\](72) np(V, \[p(Wffl ,and(let(V,V 1,Wffl),unique(V,name(V,john) ,Wffl )))1 QL 1 \] -QL l,Fx-Fx,\[V1\])\[he and john\].That is, "he and John" is an NP that binds V and mapsWffl to(7:3) and(let(V,V 1,Wffl),unique(V,name(V,john),Wffl)224 Computational Linguistics Volume 16, Number 4, December 1990Andrew R. Haas Sentential Semantics for Propositional Attitudeswhere V1 is chosen from the pronoun reference list.
Thusthe conjunction rule works for pronouns and proper nounsexactly as it does for NPs with determiners.
There is asimilar rule for disjunction of NPs.In conjoining two NPs we combine their quantifiers,which are the first elements of their quantifier stores.
Wemust also collect he remaining elements of both quantifierstores.
The above rule achieves this result by concatenatingdifference lists in the usual way: if QL1-QL2 is the tail ofthe first NP's quantifier list, and QL2-QL3 is the tail of thesecond NP's quantifier list, then QL 1-QL3 is the concatena-tion of the tails.
In the present grammar both tails areempty, because the quantifier store of an NP contains atmost one quantifier, but in a more general grammar thetails might contain quantifiers--for example, quantifiersfrom prepositional phrases modifying the NP.
Thus theMontague-style s mantics for NP conjunction and disjunc-tion requires an extension of standard Cooper storage.When the quantifier store of an NP contains everal quanti-tiers, we must be able to identify the one that represents heNP itself (as opposed to quantifiers that arise from at-tached PPs, for example).
We must then be able to removethis quantifier from the store, build a new quantifier, andput the new quantifier back into the store.Rule (R6) requires that the two NPs being conjoinedshould have quantifiers that bind the same variable.
Sup-pose we had chosen the bound variables in the logical formsby using a global counter to ensure that no two quantifiersever bind the same variable (as suggested in Section 2.4).Then (R6) could never apply.
Thus our treatment of NPconjunction forces us to choose the bound variables afterthe quantifiers from conjoined NPs have been combinedinto a single quantifier, as described in Section 2.4.
Thischoice in turn creates difficulties in implementing ourtreatment of de re attitude reports, as we will see in Section3.1.In this grammar, a conjunction of quantified NPs pro-duces a logical form in which the two quantifiers are inseparate wffs, and these wffs are joined by the connectiveand.
Thus, neither quantifier is in the scope of the other.This gives the desired reading for a sentence such as "Johnhas no house and no car":(74) and(not(some(x,house(x),has(john,x))),not(some(x,car(x), has(john,x)))).However, consider the sentence "John met a farmer and hiswife" and suppose the pronoun "his" refers to "a farmer.
"Under our analysis, the quantifier from "a farmer" cannotbind a variable in the range restriction of the other quanti-tier--because its scope does not include the other quanti-fier.
Thus, the Montagovian analysis of NP conjunction iscertainly correct in some cases, but it cannot be the wholestory.2.6 VERB PHRASE AND SENTENCE RULESOur grammar includes two kinds of transitive verbs: ordi-nary verbs like "eat" and "buy," and propositional ttitudeverbs like "want" and "seek."
Only verbs of the secondkind have de dicto readings.
There is a de dicto reading for"John wants a Ferrari," which does not imply that there isany particular Ferrari he wants.
There is no such readingfor "John bought a Ferrari."
To build a de dicto reading, averb like "want" must have access to the quantifier of itsdirect object.
Verbs like "buy" do not need this access.
Thisleads to a problem that has been well known since Mon-tague.
The two kinds of verbs, although very different intheir semantics, seem to be identical in their syntax.
Wewould like to avoid duplication in our syntax by writing asingle rule for VPs with transitive verbs.
This rule mustallow for both kinds of semantics.Montague's olution was to build a general semanticrepresentation, which handles both cases.
When the verb is"eat" or "buy," one uses a meaning postulate to simplifythe representation.
Our solution is similar: we allow everytransitive verb to have access to the quantifier of its directobject, and then assert hat some verbs don't actually usethe quantifier.
However, our solution improves on Mon-tague and Cooper by avoiding the simplification step.
In-stead, we build a simple representation in the first place.A verb has one feature, the subcategorization frame,which determines what arguments it will accept and whatlogical form it builds.
The rule for verbs says that if aterminal symbol has a subcategorization frame Subcat,then it is a verb:(R7) v (Subcat )~ \[Terminal\], { has_subcat(Terminal,Subcat) }.A subcategorization frame for a transitive verb has theform(75) trans(V 1,V2,QL1,QL2,Wffl).V1 is a variable representing the subject, and V2 is avariable representing the object.
QL1 is the quantifier storeof the object.
QL2 is a list of quantifiers remaining after theverb has built its logical form.
For an ordinary transitiveverb, QL2 equals QL 1.
Wffl is the logical form of the verb.In the case of ordinary transitive verbs, we would like toassert once and for all that QL1 = QL2.
Therefore, wewrite(L2)has_subcat(Terminal,trans(V1,V2,QL1,QLl,WtT)):- ordinary_trans(Terminal,V 1,V2,Wff).This axiom says that for an ordinary transitive verb, thetwo lists of quantifiers are equal, and the values of the otherfeatures are fixed by the predicate "ordinary_trans."
Wehave(L3a) ordinary_trans(saw,V 1 2,saw(V 1,V2))(L3b) ordinary_trans(ate,V 1 , 2,ate(V 1,V2)).From (R7), (L2), and (L3a) we get(76) v(trans(Vl ,V2,QL1,QLl ,saw(Vl ,V2)))~ \[saw\].Computational Linguistics Volume 16, Number 4, December 1990 225Andrew R. Haas Sentential Semantics for Propositional AttitudesThe features of a verb phrase are a variable (representingthe subject), awff (the logical form of the VP), a quantifierstore, a list of fillers, and a pronoun reference list.
The rulefor a verb phrase with a transitive verb is(R8)vp(V1,Wffl,QL2,Fx-Fy,L)--, v(trans(V 1,V2,QL1,QL2,Wffl)),np(V2,QL1,Fx-Fy,L).If the verb is an ordinary transitive verb, then QL1 = QL2,so the quantifier store of the VP is equal to the quantifierstore of the direct object.
From (R1), (R3a), and (R2b) wehave(77) np(V,\[p(Wffl,some(V,man(V),Wffl))l QL\]-QL,Fx-Fx,L) ----, \[a man\].Resolving (76) and (77) against he right side of R8 gives(78)vp(V 1 ,saw(V 1 ,V2), \[p(Wffl  ,some (V2,man (V2),Wffl))l QL\]-QL,Fx-Fx,L)\[saw a man\].The quantifier store contains the quantifier of the NP "aman.
"A sentence has four features: a wff, a quantifier store, alist of fillers, and a pronoun reference list.
The rule for adeclarative sentence is(R9)s(Wff2,QL4,Fx-Fz,L) ---.np(V,QL I-QL2,Fx-Fy,L),vp(V,Wffl,QL2-QL3,Fy-Fz,L),{ apply_quants(QL 1 -QL3,Wffl ,QL4,Wff2) }.The variable V represents the subject, so it becomes thefirst argument of the VP.
QL1-QL3 is the concatenation fthe quantifier stores from the subject and the VP.
"Apply_quants" will apply some of these quantifiers to thelogical form of the VP to produce the logical form Wff2 ofthe sentence.
The list QL4 of remaining quantifiers be-comes the quantifier store of the sentence.
We have(79)np(V 1, \[p(Wff0,all(V 1 ,woman(V 1),Wff0))\] QL 1 \]-QL1,Fx-Fx,L)--~ \[every woman\].From (R9), (79), and (78), we get(8o)s(Wff2,QL4,Fx-Fx,L)\[every woman saw a man\],{apply_quants(\[p(Wff0,all(Vl,woman(V1),Wff0)),p(Wffl,some(V2,man(V2),Wffl))\[ QL3\]-QL3,saw(V1,V2),QL4,Wff2)The., "apply_quants" ubgoal has several solutions.
Choos-ing the one in which "every woman" outscopes "a man," weget(81) s(all(x,woman(x),some(y,man(y),saw(x,y))),QL3-QL3,Fx-Fx,L) ~ \[every woman saw a man\].The; derivation is not yet complete, because "s" is not thestart symbol of our grammar.
Instead we use a specialsymbol "start," which never appears on the right side of arule.
Thus, the start symbol derives only top-level sen-tenees--it cannot derive an embedded sentence.
This isuseful because top-level sentences have a unique semanticproperty: their logical forms must not contain free vari-ables.
It might seem that one can eliminate free variablessimp\]',y by applying all the quantifiers in the store.
Hobbsand Shieber (1987) pointed out that this is not so--it isessential to apply the quantifiers in a proper order.
Con-sider the sentence "every man knows a woman who loveshim," with "him" referring to the subject.
The subjectquantifier binds a variable that occurs free in the rangerestriction of the object quantifier, so one must apply theobject quantifier first in order to eliminate all free vari-ables.Therefore our grammar includes a filter that eliminatesreadings of top-level sentences containing free variables.Let free_vars(Wffl,L) mean that L is a list of the freevariables of Wffl in order of first occurrence.
We omit theeasy definition of this predicate.
The rule for top-levelsentences i :(R 10) start(Wffl) ---, s(Wffl,QL-QL,Fx-Fx,\[\]),{ free_vars(Wffl, \[\]).The goal free_vars(Wffl,\[\]) filters out readings with freevariables.
The above rule allows us to complete the deriva-tion for "every woman saw a man":(82) start(all(x,woman(x),some(y,man(y),saw(x,y))))\[every woman saw a man\].Having treated sentences, we can now consider gaps andrelative clauses.
The rule for gaps follows Pereira andSchieber (1987):(R11) np(V,QL-QL,\[gap(V)I Fx\]-Fx,VL) ~ \[\].This rule removes the marker gap(V) from the filler list,and makes the associated variable V the variable of theempty NP.
The list difference QL-QL is the empty list, sothe quantifier store of the gap is empty.The rule that generates NPs with relative clauses is(R :: 2)np(V,\[QI QL\]-QL,Fx-Fx,L)--~ det(V,and(Range 1 ,Range2),Q),n(V,Rangel),\[that\],s(Range2,QL1-QLl,\[gap(V)\]-\[\],\[\]).226 Comlmtational Linguistics Volume 16, Number 4, December 1990Andrew R. Haas Sententiai Semantics for Propositional AttitudesThe relative clause is a sentence containing a gap, and thelogical form of the gap is the variable V--the same variablethat the quantifier binds.
The logical form of the relativeclause becomes part of the range restriction of the quanti-fier.
We have(83) s(some(x,pizza(x),ate(V,x)),QL-QL,\[gap(V)\[ Fx\]-Fx,\[\]) ~ \[ate a pizza\].The derivation of this sentence is much like the one for"every woman saw a man" above, except hat in place ofthe subject "every woman" we have a gap as a subject.
Therule for gaps above ensures that the variable of the gap is V,the only variable in the filler list, and its quantifier store isempty.
Therefore, V appears as the first argument of thepredicate "ate."
Continuing the derivation we get(84) np(V,\[p(Wffl,some(V,and(man(V),some(x,pizza(x),ate(V,x))),Wffl))\[ QL\]-QL,Fx-Fx,\[\])----\[a man that ate a pizza\].The string "a man that ate a pizza" is an NP that binds Vand maps Wffl to the wff(85) some(V,and(man(V),some(x,pizza(x),ate(V,x))),Wffl).Notice that in the rule for NPs with relative clauses, thequantifier store of the relative clause is empty.
This meansthat no quantifier can be raised out of a relative clause.Thus there is no scope ambiguity in "I saw a man that lovesevery woman."
According to Cooper (1979), this is correct.The restriction is easy to state because in our grammar,quantifier raising is combined with syntax and semantics ina single set of rules.
It would be harder to state the samefacts in a grammar like Pereira and Shieber's (1987),because quantifier aising there operates on a separaterepresentation called a quantifier tree.
This tree leaves outsyntactic information that is needed for determiningscopes--for example, the difference between a relativeclause and a prepositional phrase.3 PROPOSITIONAL ATTITUDES IN THEGRAMMAR3.1 ATTITUDE VERBS TAKING CLAUSESThe following rule introduces verbs such as "believe" and"know," which take clauses as their objects.
(R13)vp(Vl,Wffl,QL1,Fx,L)--~ v(takes_s(V 1 ,Wff2,Wffl )),s(Wff2,QLl,Fx,\[V1 \[L\]).The verb takes the logical form Wff2 of the object clauseand the subject variable V1, and builds the wff Wfflrepresenting the VP.
This rule also adds the subject vari-able to the pronoun reference list of the object clause.
Forthe verb "thought," we have the following subcategoriza-tion frame:(L4)has_subcat(thought,takes_s(V 1,Wffl,thought(Vl,Varsl,q(Wffl)))):- free_vars(Wffl,Varsl).The subject variable becomes the first argument of thepredicate "thought."
The logical form of the object clauseis Wffl, and it appears under a quotation mark as the thirdargument of "thought."
The second argument of "thought"is the de re argument list, and the predicate "free_vars"ensures that the de re argument list is a list of the freevariables in Wffl, as required by our convention.
From therule (R8) for verbs and (L4), we get(86)v(takes_s(Vl,Wff2,thought(V1,Varsl,q(Wff2))))\[thought\], { free_vars(Wff2,Varsl) }.The "free_vars" subgoal has not been solved--it has beenpostponed.
Indeed it must be postponed, because as long asits first argument is a variable, it has an infinite number ofsolutions--one for each wit of our language.Consider the example "John thought Mary ate a pizza.
"We consider two readings.
"A pizza" is understood de dictoin both readings, but "Mary" is de re in one reading and dedicto in the other.
The ambiguity arises from the embeddedsentence, because the predicate "apply_quants" can eitherapply the quantifiers or leave them in the store.
If it appliesthe quantifiers from "Mary" and "a pizza" in their surfaceorder, we get(87)s (un ique(y,name(y,mary) ,some(x,p izza(x) ,ate(y,x)),QL-QL, Fx-Fx,L)---, \[mary ate a pizza\].From (R13), (86), and (87) we get(88)vp(Vl,thought(V1,Varsl,q(unique(y,name(y,mary) ,some(x,pizza(x),ate(y,x))))),QL-QL,Fx-Fx,L)--* \[thought Mary ate a pizza\],{free_vars(unique(y,name(y,mary),some(x,piz-za(x), ate(y,x))),Vars 1 ) }.Since the first argument of "free_vars" is now a groundterm, we can solve the "free_vars" subgoal, gettingVarsl = \[\].
Then we have(89)vp(V1,thought(Vl,\[\],q(unique(y,name(y,mary),some(x,pizza(x),ate(y,x))))),QL-QL,Fx-Fx,L)--~ \[thought Mary ate a pizza\].Computational Linguistics Volume 16, Number 4, December 1990 227Andrew R. Haas Sententiai Semantics for Propositional AttitudesIf we combine this VP with the subject "John" we get asentence whose logical form is(90)unique(z,name(z,john),thought(z, \[\] ,q(unique(y,name(y,mary),some(x,pizza(x),ate(y,x)))))).Now for the reading in which "mary" is de re.
Once again,consider the embedded sentence "Mary ate a pizza."
Sup-pose that the predicate "apply_quants" applies the quanti-fier from "a pizza" and leaves the one from "Mary" in thestore.
We get(91 ) s(some(x,pizza(x),ate(V 1 ,x)),\[p(Wffl,unique(Vl,name(Vl,mary),Wffl))\[QL\]-QL,Fx-Fx,L)--, \[Mary ate a pizza\].Vl is the bound variable of the NP "Mary."
The predicate"apply_quants" will choose a value for Vl when it appliesthe quantifier.
From (R13), (86), and (91), we get(92)vp(V2,thought (V 2,Vars 1 ,q(some(x,pizza (x),ate (V 1,x))))),\[p (W ff 1 ,unique (V 1 ,name (V 1 ,mary),Wff l  ) )1QL\]-QL,Fx-Fx,L)--, \[thought Mary ate a pizza\],{ free_vars(some(x,pizza (x),ate(V 1,x)),Vars 1) }.In this case, the first argument of "free_vars" contains themeta-language variable V1.
Then the "free_vars" subgoalhas an infinity of solutions---one in which V 1 = x and thereare no free variables, and an infinite number in which V1 =y, for some y not equal to x, and the list of free variables is\[y\].
Therefore, it is necessary to postpone the "free_vars"subgoal once more.
The standard technique for parsingDCGs does not allow for this postponing of subgoals, andthis will create a problem for our implementation.This problem would be greatly simplified if we hadchosen to assign a different variable to every quantifier byusing a global counter.
The DCG parser would work fromleft to right and assign a target-language variable to eachNP as soon as it parsed that NP.
In the above example,"Mary" and "a pizza" would both have their variablesassigned by the time we reached the right end of the VP.Then we could handle the "free_vars" subgoals by rewritingthe grammar as follows: remove the "free_vars" subgoalsfrom the lexical entries for the attitude verbs, and place a"free_vars" subgoal at the right end of each VP rule thatintroduces an attitude verb (( R \[ 3), (R 15), and (R8)).
Thiswould ensure that when the parser attempted to solve the"free_vars" subgoal, its first argument would be a groundterm.
However, this solution would make it impossible touse the rule (R6) for NP conjunction (see Section 2.5).
Ifwe pick one solution for the problem of choosing boundvariables, we have problems with NP conjunction; if wepick the other solution we get problems in implementingour analysis of de re attitude reports.
This is the kind ofdifficulty that we cannot even notice, let alne solve, untilwe write formal grammars that cover a reasonable varietyof phenomena.Continuing our derivation, we combine the VP with thesubject "John," apply the quantifier from "Mary," and get(93) s(unique(z,name(z,john),unique(y,name(y,mary),thought(z,Varsl,q(some(x,pizza(x),ate(y,x)))))),QL-QL,Fx-Fx,L)---- \[John thought Mary ate a pizza\],{ free_vars(some(x,pizza(x),ate(y,x)),Vars 1) }.Now the first argument of "free_vars" is a ground term,because applying the quantifier that arose from "Mary"includes choosing the target language variable that thequantifier binds.
The "free_vars" subgoal now has only onesolution, Varsl = \[y\].
Then the logical form of the sen-tence is(94) unique(z,name(z,john),unique(y,name(y,mary),thought(z,\[y\],q(some(x,pizza(x),ate(y,x)))))).This means that there is a term T that represents Mary toJohn, and John believes the sentence(95) some(x,pizza(x),ate(T,x)).For the sentence "John thought he saw Mary," our limitedtreatment of pronouns allows only one reading, in which"he" refers to John.
Using (R9), we get the followingreading for the embedded clause:(96)s(let(y,V 1,unique(x,name(x,mary),saw(y,x)),QL-QL,Fx-Fx,\[V1\])--~ \[he saw Mary\].The pronoun "he" gives rise to a "let" quantifier, whichbinds the variable y to V1, the first member of the pronounreference list.
From (R13), (86), and (96) we get(97)vp(V2,thought (V2,Vars 1 ,q(let (y,V2,unique(x,name(x,mary), saw(y,x)),QL-QL,Fx-Fx,\[\])---* \[thought e saw Mary\],{free_vars(let(y,V2,unique(x,name(x,mary),saw(y,x))),Varsl) }.The VP rule (R13) unifies the subject variable V2 with thefirst element of the pronoun reference list of the embeddedclause, so the "let" quantifier now binds the variable y tothe: subject variable.
Once again, we postpone the "free_vars"228 Computational Linguistics Volume 16, Number 4, December 1990Andrew R. Haas Sentential Semantics for Propositional Attitudesgoal until its first argument is a ground term.
Combiningthis VP with the subject "John" gives(98)s(unique(z,name(z,john),thought(z,Vars 1 ,q(let (y,z,unique(x,name(x,mary),saw(y,x)))))),QL-QL,Fx-Fx,VL)--~ \[John thought he saw Mary\],{free_vars(let(y,z,unique(x,name(x,mary),saw(y~x))),Varsl) }.The first argument of"free_vars" is now a ground term, andsolving the "free_vars" subgoal gives Varsl = \[z\].
Thelogical form of the sentence is(99)unique(z,name(z,john),thought(z,\[z\],q(let(y,z,unique(x,name(x,mary),saw(y,x)))))).The dummy variable z stands for a term T that representsJohn to himself.
Then John's belief looks like this:(100)let(y,T,unique(x,name(x,mary),saw(y,x))).If John simplifies this belief, he will infer(101 ) unique(x,name(x,mary),saw(T,x)).3.2 ATTITUDE VERBS TAKING A CLAUSEWITH A GAPWe proposed the following logical form for "John knowswho Mary likes":(102) some(x,person(x),know(john, \[x\] q(like(mary,x)))).The grammar will generate a similar logical form, exceptfor the translations of the proper nouns.
The existentialquantifier comes from the word "who."
The rules for"who" and "what" are(R14a) wh(V 1, \[p(Wff l ,some(V 1,and(person(V 1),Wffl)))l QL \ ] -QL)~ \[who\](R14b) wh(V 1, \ [p(Wff l ,some(V 1,and(thing(V 1),Wffl)))\] QL\]-QL) ~ \[what\].The semantic features of a wh word are a variable, and alist containing aquantifier that binds that variable.The following rule builds VPs in which the verb takes awh word and a clause as its objects:(R15)vp(VI,Wff3,QL1,Fx-Fx,L)v(takes_wh(V 1,Wffl,Wff2)),wh(V,QL0),s(Wffl,QLl,\[gap(V)\]- \[\],\[V1 I L\]),{ apply_quants(QL0,Wff2,QL-QL,Wff3) }.The embedded S contains a gap, and the variable of thatgap is the one bound by the quantifier from the wh word.The main verb takes the subject variable and the logicalform of the embedded S and builds a wff Wff2.
The rulefinally calls "apply_quants" toapply the quantifier from thewh word to Wff2.
"Apply_quants" can apply any subset ofthe quantifiers in its first argument, but the rule requiresthe output list of quantifiers to be empty, and this guaran-tees that the quantifier from the wh word will actually beapplied.
The resulting wff becomes the logical form of theVP.The rule requires a verb whose subcategorization framehas the form takes_wh(Vl,Wffl,Wff2).
"Know" is such averb:(L5)has_subcat(knows,takes_wh(Vl,Wffl,know(V1,Varsl,q(Wffl)))):- free_vars(Wffl,Varsl).Combining this clause with the rule (R7) for verbs gives(103)v(takes_wh(V1,Wffl,know(V1,Varsl,q(Wffl))))\[knows\], { free_vars(Wffl,Varsl) }.Consider the example "John knows who Mary likes," andsuppose "Mary" is understood e dicto.
The embedded Shas the following reading:(104)s(unique(x,name(x,mary),like(x,V 1)),QL-QL,\[gap(V l) \]Fx\]-Fx,L)--~ \[Mary likes\].The object of "likes" is a gap, so the variable V1 from thefiller list becomes the second argument of the predicate"like."
Resolving (103), (R14a), and (104) against theright side of (R 15) gives(105)vp(V2,Wff3,QL-QL,Fx-Fx,L)\[knows who Mary likes\],{ apply_quants(\[p(Wffl,some(Vl,person(V1),Wffl))I QL\]-QL,know (V2,Vars 1 ,q (unique (x,name(x,mary),like(x,Vl))),QL-QL,Wff3),{free_vars(unique(x,name(x,mary),like(x,V 1)),Vars 1) }.Solving the "apply_quants" ubgoal gives(106)Wff3 ----- some(y,person(y),know(V2,Var s1 ,q (u nique (x,name (x,mary),like (x,y))))).Solving the "free_vars" subgoal gives Varsl = \[y\], and weComputational Linguistics Volume 16, Number 4, December 1990 229Andrew R. Haas Sentential Semantics for Propositional Attitudesthen have(107)Wff3 =some(y,person(y),know(V2, \ [y \ ] ,q (un ique(x ,name(x ,mary) ,like(x,y))))).Therefore(108)vp(V2,some (y,person(y),know(V2,\[y\],q(unique(x,name(x,mary),like(x,y))))),QL- QL,Fx-Fx,L)---- \[knows who Mary likes\].This VP combines with the subject "John" in the usual wayto give a sentence whose logical form is(109)unique(z,name(z,john),some(y,person(y),know(z,\[y\],q(unique(x,name(x,mary),like(x,y)))))).3.3 ATTITUDE VERBS TAKING A NOUN PHRASEFinally, we consider an example with "want."
This verb issemantically very different from most transitive verbs, butsyntactically it is an ordinary transitive verb, introduced bythe rule already given:(R8)vp(V1,Wffl,QL2,Fx-Fy,L)--~ v(trans(V 1,V2,QL 1,QL2,Wffl)),np(V2,QL1,Fx-Fy,L).The difference between "want" and other transitive verbs isin its subcategorization frame:(L6)has_subcat(wants,trans(V 1 ,V2,QL 1 ,QL2,wish (V 1 ,Vars 1 ,q(Wffl)))):- apply_quants(QL 1 ,ha,~e(V 1 ,V2),QL2,Wffl ),free_vars(Wffl,Varsl).Resolving this rule against he verb rule (R7) gives thefollowing rule for the verb "wants":(110)v(trans(V1,V2,QL1,QL2,wish(V1,Varsl,q(Wffl))))---- \[wants\],{ apply_quants(QL 1 ,have(V 1 ,V2),QL2,Wffl ),free_vars(Wffl,Varsl)}.The quantifier list QL1 contains the quantifier from theobject NP.
The predicate "apply_quants" may or may notapply this quantifier to the wff have(VI,V2), and thisnondeterminism gives rise to a de re~de dicto ambiguity.
If"apply_quants" does not apply the object quantifier, thenQL2 = QL1, so the object quantifier is passed up for laterapplication.
Otherwise, QL2 is the empty list.
As usual, thepredicate "free_vars" ensures that the de re arguments obeyour convention.Consider the VP "wants a Porsche."
The object "aPo:rsche" has the following interpretation:(11.1)np(V2,\[p,(Wff0,some(V2,porsche(V2),Wff0))\] QL\]-QL,Fx-Fx,VL)--, \[a porsche\].Resolving (110) and (111) against he left side of (R7)give,;(112)vp(V 1 ,wish(V 1 ,Vars 1 ,q(Wffl ) ),QL2,Fx- Fx,VL)---- \[wants a porsche\],{apply_quants(\[p(Wff0,some(V2,porsche(V2),Wff0))l QL\]-QL,have(V1,V2),QL2,Wffl),free_vars(Wffl,Varsl)I.One solution of the "apply_quants" ubgoal is(113)Wffl = some(x,porsche(x),have(Vl,x))QL2 = QL0-QL0.Given this solution, the logical form of the VP is(1 :t4.)
wish(V1,Varsl,q(some(x,porsche(x),have(V 1,x))))where V1 is the subject variable and the "free_vars" sub-goal has been postponed.
We can combine this VP with thesubject "John" to get a sentence whose logical form is(115)unique(y,name(y,john),wish(y,Varsl  ,q(some(x,porsche(x),have(y,x))))).Solving the "free_vars" subgoal will then give Varsl = \[y\],so tP~e final logical form is(116)unique(y,name(y,john),wish(y,\[y\],q(some(x,porsche(x),have(y,x))))).This means that there is a term T that represents John tohirn,;elf, and the sentence that John wishes to be true is(117) some(x,porsche(x),have(T,x)).This is a de dicto reading--there is not any particularPorsche that John wants.
'Fhe other solution for the "apply_quants" ubgoal is(118)Wffl = have(V1,V2)QL2 = \[p(WffO,some(V2,porsche(V2),WffO))lQL\]-QL.230 Com\]putational Linguistics Volume 16, Number 4, December 1990Andrew R. Haas Sentential Semantics for Propositional AttitudesIn this case, the logical form of the VP is(119) wish(V1,Varsl,q(have(V1,V2)))and its quantifier store is equal to QL2.
Combining this VPwith the subject "John" and applying the quantifiers givesa sentence whose logical form is(120)unique(y,name(y,john),some(x,porsche(x),wish(y,Varsl,q(have(y,x))))).Solving the "free_vars" subgoal gives Varsl = \[y,x\] so thefinal logical form is(121)unique(y,name(y,john),some(x,porsche(x),wish (y,\[y,x\],q(have(y,x))))).This means that there exist terms T1 and T2 such that T1represents John to himself, T2 represents some Porsche toJohn, and the sentence John wishes to be true is(122) have(T1,T2)This is a de re reading, in which John wants some particularPorsche.The rules for verbs that take clauses as complements didnot need to call "apply_quants," because the rules thatbuild the clauses will call "apply_quants" and so create thedesired ambiguity.
In Cooper's grammar, all NPs have theoption of applying their quantifiers, and so there is no needfor verbs like "want" to apply quantifiers--they can rely onthe rule that built the verb's object, just as other intensionalverbs do.
This is a minor advantage of Cooper's grammar.4 IMPLEMENTATION AND CONCLUSIONS4.1 IMPLEMENTATIONThe implementation uses the standard Prolog facility forparsing definite clause grammars.
This facility translatesthe grammar into a top-down, left-to-right parser.
Thisorder of parsing leads to problems with the predicates"apply_quants" and "free_vars."
We cannot run "free_vars"until its first argument is a ground term---otherwise wemight get an infinite number of solutions.
In our exposition,we solved this problem by delaying the execution of"free_vars."
The standard DCG parser has no built-infacility for such delaying.
As usual in such situations, thereare two options: rewrite the predicates so that the existinginterpreter works efficiently, or define a more general inter-preter that allows the desired order of execution.
Thesecond approach is more desirable in the long run, becauseit achieves a central goal of logic programming: to uselogical sentences that express our understanding of theproblem in the clearest way.
However, defining new inter-preters is hard.
The present implementation takes the lowroad--that is, the author ewrote the predicates so that thestandard parser becomes efficient.
In particular, the rulefor top-level clauses calls a Prolog predicate that finds all dere argument lists in the final logical form and calls"free_vars" for each one.There is a similar problem about the predicate"apply_quants" in the rule for "want."
Since the parserworks left to right, the quantifier from the object of "want"is not available when the logical form for the verb is beingconstructed.
This means that the first argument of"apply_quants" is a free variable--so it has an infinitenumber of solutions.
Here the implementation takes advan-tage of Prolog's "call" predicate, which allows us to delaythe solution of a subgoal.
The "apply_quants" ubgoal is anextra feature of the verb "want" (in the case of an ordinarytransitive verb, this feature is set to the empty list of goals).The rule for VPs with transitive verbs uses the "call"predicate to solve the subgoal--after the object of the verbhas been parsed.
At this point the first argument isproperlyinstantiated and the call produces a finite set of solutions.The grammar given above contains the rule NP --, NP\[and\] NP, which is left recursive and cannot be parsed bythe standard DCG parser.
The implementation avoids thisproblem by adding a flag that indicates whether an NP isconjunctive.
This gives the rule(123) NP(+conj)  ~ NP( -con j )  \[and\] NP(Conj),which is not left recursive--it assigns a right-branchingstructure to all conjunctions of NPs.
These are the onlydifferences between the grammar presented here and theProlog code.
The implementation was easy to write andmodify, and it supports the claim that Prolog allows us toturn formal definitions into running programs with a mini-mum of effort.4.2 CONCLUSIONS AND FUTURE WORKThis paper has presented a new notation for a sententialtheory of attitudes, which unlike most existing notationsmakes it possible to give a compositional semantics forattitude reports.
Our notation distinguishes between the dere arguments of an attitude operator and the dummyvariables, which stand for unspecified terms that representthe values of the de re arguments.
The choice of dummyvariables is quite arbitrary--just as the choice of boundvariables in first-order logic is arbitrary.
This allows us toimpose a convention, which says that in fact the dummyvariables are equal to the de re arguments.
Given thisconvention, the logical form of a clause is the same whetherit stands alone or appears as the argument of an attitudeverb.This is a simple proposal, and it would be easy to writeand implement a grammar that applies the proposal to afew examples.
The real question is whether the proposal isrobust--whether it can function in a grammar that covers avariety of phenomena.
We chose definite clauses and afirst-order object language as our semantic formalism.
Wefound a nonobvious interaction between our proposal for dere attitude reports, and two other problems about quantifi-Computational Linguistics Volume 16, Number 4, December 1990 231Andrew R. Haas Sentential Semantics for Propositional Attitudescation: the choice of bound variables in a logical form, andthe conjunction and disjunction of quantified NPs.
Weconsidered two possibilities for choosing the bound vari-ables: assigning a different variable to every NP using aglobal counter, or requiring each quantifier to bind avariable that is not bound by any quantifier within its scope.The first approach makes it impossible to use our rules forNP conjunction and disjunction, while the second createsimplementation problems for the de re argument lists.
Weresolved the dilemma by picking the second approach, andthen rewriting the grammar to solve the implementationproblems.
Thus we have shown that the proposal for de reattitude reports is not just a plausible notion--it can bemade to work in a grammar that is not trivial.The grammar handles three kinds of attitude construc-tions: an attitude verb taking a clause as its object ("Johnthought he saw Mary"),  an attitude verb taking a clausewith a gap ("John knows who Mary likes"), and an attitudeverb taking a noun phrase as its object ("John wants aPorsche").
The grammar includes de re~de dicto ambigu-ities, conjunction of NPs, and a very limited treatment ofpronouns.Another contribution of our work is that it seems to bethe first unification grammar that builds logical forms, andat the same time respects the declarative semantics of thenotation.
We explicitly choose the bound variables of thelogical form, instead of using meta-language variables.
Wealso explain the semantics of our representation for quanti-fied NPs: each NP has an infinite set of readings, one foreach ordered pair in the extension of the application func-tion.
Several authors treat unification grammars with se-mantics as poor relations of Montague grammar.
Pereiraand Shieber (1987) propose to "encode" Montague's ideasin unification grammar, while Moore (1989) fears thatbuilding logical forms with unification grammar is "unprin-cipled feature hacking."
We claim that these problemsarise not from shortcomings of unification grammar, butfrom failure to take unification grammar seriously--whichmeans respecting its declarative semantics.The most obvious line for future work is to extend thegrammar.
It would be fairly easy to include complex whnoun phrases, such as "whose cat" or "how many children"(Cooper's grammar handled these).
A more difficult prob-lem arises when a gap is the object of an intensionalverb---as in "John knows what Mary wants."
The grammarcan generate this sentence, but it assigns only a de rereading:unique(x,name(x,john),some(y,thing(y),know(x,\[y\],q(unique(z,name(z,mary),wish(z,\[z,y\],q(have(z,y)))))))).This is the only reading because the gap has an emptyquantifier store--there is no quantifier available to beapplied to the wff "have(z,y)."
Yet there are examples inwhich such sentences do have de dicto readings.
For exam-ple, consider "What John wants is a Porsche."
Surely thissentence has a de dicto reading--yet the object of"want" isa gap, not a quantified NP.
Cooper discusses this problem,but his grammars could not handle it, and neither can ours.Hirst and Fawcett (1986) have argued that the ambigu-ities in attitude reports are more complex than the familiardistinction between de re and de dicto readings.
They claimthat the sentence "Nadia wants a dog like Ross's" has areading in which Nadia doesn't want a particular dog (sothe qaantifier 3 is inside the scope of the attitude operator),but the description "dog like Ross's" is the speaker's, notNadia's (so the description is outside the scope of theattitude operator).
This reading is certainly different fromthe usual de re and de dicto readings, in which either thewhole logical form of the NP is under the attitude, or noneof it is.
To represent it, we must be able to separate thelogical form of the NP "a dog like Ross's" into two parts(the quantifier 3 and its range restriction), and we must beable to move the range restriction out of the scope of theattitude without moving the quantifier.
This will mean thatwe cannot use the same mechanism for both quantifierscope ambiguities and the ambiguities that arise fromattitudes.
These extensions appear feasible, but they amountto a major change in the formalism.Another possibility for future work is to incorporate theexi,;t!,ng implementation i to a question-answering pro-grant.
This requires finding a way to reason about proposi-tional attitudes efficiently without assuming unique stan-dard designators--which means a substantial generalizationof the work of Konolige.
It also requires us to make muchstronger claims about the properties of 'representation'than we have made in this paper.
I f  these problems can besolved, it should be possible to build a natural languagequestion-answering program that can describe the extent ofits own knowledge--answering questions like "Do youknow the salary of every employee?
"REFERENCESAsher, Nicholas M. and Kamp, John A. W. (1986).
"The knower'sparadox and representational theories of attitudes."
In TheoreticalAspects of Reasoning about Knowledge, dited by Joseph Halpern,1131-147.
Morgan Kaufmann.Barwise, Jon and Cooper, Robin.
(1981).
"Generalized quantifiers andnatural language."
Linguistics and Philosophy, 4: 159-219.Boer, Steven E. and Lycan, William G. (1986).
Knowing Who.
MITPress.Cooper, Robin.
(1983).
Quantification a d Syntactic Theory.
D. Reidel.Coopor, Robin.
(1979).
"Variable binding and relative clauses."
In For-ma,~ Semantics and Pragmatics for Natural Languages, edited by F.Gventhner and S. J. Schmidt, 131-169.
D. Reidel.des Rivieres, J., and Levesque, H. 1986.
"The Consistency of SyntacticalTreatments of Knowledge."
in Joseph Y. Halpern, ed., TheoreticalAspects of Reasoning about Knowledge.
Los Altos, CA, MorganKaufmann: 115-130.Enderton, Herbert.
(1972).
A Mathematical Introduction to Logic.
Aca-demic Press.Fisher, Anthony J.
(1989).
"Practical parsing of GPSG's."
Computa-tional Linguistics, 15:139-148.Gazdar, Gerald; Klein, Ewan; Pullum, Geoffrey; and Sag, Ivan.
(1985).Generalized Phrase Structure Grammar.
Harvard University Press.232 Computational Linguistics Volume 16, Number 4, December 1990Andrew R. Haas Sentential Semantics for Propositional AttitudesHaas, Andrew R. (1986).
"A syntactic theory of belief and action.
"Artificial Intelligence, 28: 245-292.Hobbs, Jerry R. and Shieber, Stuart M. (1987).
"An algorithm forgenerating quantifier scopings."
Computational Linguistics, 13: 47-63.Hirst, Graeme and Fawcett, Brenda.
(1986).
"The detection and represen-tation of ambiguities of intension and description."
In Proceedings ofthe 24th Annual Meeting of the Association for Computational Linguis-tics, 192-199.Kaplan, David.
(1975).
"Quantifying in."
In The Logic of Grammar,edited by Davidson, Donald and Harman, Gilbert, 112-144.
Dickinson.Konolige, Kurt.
(1986).
,4 Deduction Model of Belief.
Pitman.Kripke, Saul.
"Outline of a Theory of Truth."
Journal of Philosophy, 72:690-715.Lewis, David.
(1979).
"Attitudes de dicto and de se."
PhilosophicalReview, 88: 513-543.Montague, Richard.
(1974a).
"The proper treatment of quantification iordinary english."
In Formal Philosophy: Selected Papers of RichardMontague, edited by Thomason, Richmond H., 247-270.
Yale Univer-sity Press.Montague, Richard.
(1974b).
"Syntactical treatments of modality, withcorollaries on reflexion principles and finite axiomatizability."
In For-mal Philosophy: Selected Papers of Richard Montague, edited byThomason, Richmond H., 286-302.
Yale University Press.Montague, Richard and Kaplan, David.
(1974).
"A paradox regained."
InFormal Philosophy: Selected Papers of Richard Montague, edited byThomason, Richmond H., 271-301.
Yale University Press.Moore, Robert C. (1989).
"Unification-based semantic interpretation.
"In Proceedings of the 27th Annual Meeting of the Association forComputational Linguistics, 33-41.Moore, Robert C. (1988).
"Propositional attitudes and russellianpropositions."
Report No.
CSLI-88-119, Center for the Study of Lan-guage and Information, Menlo Park, CA.Moore, Robert C. and Hendrix, Gary.
(1979).
"Computational models ofbelief and semantics of belief sentences."
Technical report 187, SRIInternational, Menlo Park, CA.Moran, Douglas.
(1988).
"Quantifier scoping in the SRI core languageengine."
In Proceedings of the 26th Annual Meeting of the Associationfor Computational Linguistics, 33--40.Pereira, Fernando C. N. and Shieber, Stuart M. (1987).
Prolog andNatural-Language Analysis.
Center for the Study of Language andInformation, Stanford, CA.Pereira, Fernando C. N. and Warren, David H. D. (1980).
"Definiteclause grammars for language analysis--a survey of the formalism anda comparison with augmented transition etworks."
Artificial Intelli-gence, 13: 231-278.Perlis, Donald.
(1988).
"Languages with self reference II: knowledge,belief, and modality."
Artificial Intelligence, 34:179-212.Perlis, Donald.
(1986).
"On the consistency of commonsense r asoning.
"Computational Intelligence, 2: 180-190.Perlis, Donald.
(1985).
"Languages with self-reference I: foundations.
"Artificial Intelligence, 25: 301-322.Rapaport, William J.
(1986).
"Logical Foundations for Belief Represen-tation."
Cognitive Science, 10:371~,2.Quine, Willard van Orman.
(1975).
"Quantifiers and propositionalattitudes."
In The Logic of Grammar, edited by Davidson, Donald andHarman, Gilbert.
Dickinson.Quine, Willard van Orman.
(1947).
Mathematical Logic.
Harvard Uni-versity Press.Tarski, Alfred.
(1936).
"Der Wahrheitsbegriff n den FormalisiertenSprachen.
Studia Philosophia, 1: 261-405.Thomason, Richmond H. (1986).
"Paradoxes and semantic represen-tation."
In Theoretical Aspects of Reasoning about Knowledge, ditedby Joseph Halpern, 225-239.
Morgan Kaufmann.Thomason, Richmond H. (1980).
"A note on syntactical treatments ofmodality."
Synthese, 44(3): 391-395.Walther, Christoph.
(1987).
A Many-Sorted Calculus for Resolution andParamodulation.
Pitman.Warren, David S. (1983).
"Using lambda-calculus to represent meaningsin logic grammars."
In Proceedings of the 21st Annual Meeting of theAssociation for Computational Linguistics, 51-56.Computational Linguistics Volume 16, Number 4, December 1990 233
