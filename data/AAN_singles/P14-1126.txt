Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1337?1348,Baltimore, Maryland, USA, June 23-25 2014. c?2014 Association for Computational LinguisticsUnsupervised Dependency Parsing with TransferringDistribution via Parallel Guidance and Entropy RegularizationXuezhe MaDepartment of LinguisticsUniversity of WashingtonSeattle, WA 98195, USAxzma@uw.eduFei XiaDepartment of LinguisticsUniversity of WashingtonSeattle, WA 98195, USAfxia@uw.eduAbstractWe present a novel approach for induc-ing unsupervised dependency parsers forlanguages that have no labeled trainingdata, but have translated text in a resource-rich language.
We train probabilistic pars-ing models for resource-poor languages bytransferring cross-lingual knowledge fromresource-rich language with entropy reg-ularization.
Our method can be used asa purely monolingual dependency parser,requiring no human translations for thetest data, thus making it applicable to awide range of resource-poor languages.We perform experiments on three Datasets ?
Version 1.0 and version 2.0 ofGoogle Universal Dependency Treebanksand Treebanks from CoNLL shared-tasks,across ten languages.
We obtain state-of-the art performance of all the threedata sets when compared with previouslystudied unsupervised and projected pars-ing systems.1 IntroductionIn recent years, dependency parsing has gaineduniversal interest due to its usefulness in a widerange of applications such as synonym gener-ation (Shinyama et al, 2002), relation extrac-tion (Nguyen et al, 2009) and machine trans-lation (Katz-Brown et al, 2011; Xie et al,2011).
Several supervised dependency parsingalgorithms (Nivre and Scholz, 2004; McDonaldet al, 2005a; McDonald et al, 2005b; McDon-ald and Pereira, 2006; Carreras, 2007; Koo andCollins, 2010; Ma and Zhao, 2012; Zhang et al,2013) have been proposed and achieved high pars-ing accuracies on several treebanks, due in largepart to the availability of dependency treebanks ina number of languages (McDonald et al, 2013).However, the manually annotated treebanks thatthese parsers rely on are highly expensive to cre-ate, in particular when we want to build treebanksfor resource-poor languages.
This led to a vastamount of research on unsupervised grammar in-duction (Carroll and Charniak, 1992; Klein andManning, 2004; Smith and Eisner, 2005; Cohenand Smith, 2009; Spitkovsky et al, 2010; Blun-som and Cohn, 2010; Marec?ek and Straka, 2013;Spitkovsky et al, 2013), which appears to be anatural solution to this problem, as unsupervisedmethods require only unannotated text for trainingparsers.
Unfortunately, the unsupervised gram-mar induction systems?
parsing accuracies oftensignificantly fall behind those of supervised sys-tems (McDonald et al, 2011).
Furthermore, froma practical standpoint, it is rarely the case that weare completely devoid of resources for most lan-guages.In this paper, we consider a practically moti-vated scenario, in which we want to build statisti-cal parsers for resource-poor target languages, us-ing existing resources from a resource-rich sourcelanguage (like English).1 We assume that there areabsolutely no labeled training data for the targetlanguage, but we have access to parallel data witha resource-rich language and a sufficient amountof labeled training data to build an accurate parserfor the resource-rich language.
This scenario ap-pears similar to the setting in bilingual text pars-ing.
However, most bilingual text parsing ap-proaches require bilingual treebanks ?
treebanksthat have manually annotated tree structures onboth sides of source and target languages (Smithand Smith, 2004; Burkett and Klein, 2008), orhave tree structures on the source side and trans-lated sentences in the target languages (Huang et1For the sake of simplicity, we refer to the resource-poorlanguage as the ?target language?, and resource-rich languageas the ?source language?.
In addition, in this study we use En-glish as the source resource-rich language, but our methodol-ogy can be applied to any resource-rich languages.1337al., 2009; Chen et al, 2010).
Obviously, bilingualtreebanks are much more difficult to acquire thanthe resources required in our scenario, since the la-beled training data and the parallel text in our caseare completely separated.
What is more impor-tant is that most studies on bilingual text parsingassumed that the parser is applied only on bilin-gual text.
But our goal is to develop a parser thatcan be used in completely monolingual setting foreach target language of interest.This scenario is applicable to a large set of lan-guages and many research studies (Hwa et al,2005) have been made on it.
Ganchev et al (2009)presented a parser projection approach via paral-lel text using the posterior regularization frame-work (Graca et al, 2007).
McDonald et al (2011)proposed two parser transfer approaches betweentwo different languages ?
one is directly trans-ferred parser from delexicalized parsers, and theother parser is transferred using constraint drivenlearning algorithm where constraints are drawnfrom parallel corpora.
In that work, they demon-strate that even the directly transferred delexi-calized parser produces significantly higher ac-curacies than unsupervised parsers.
Cohen etal.
(2011) proposed an approach for unsuperviseddependency parsing with non-parallel multilingualguidance from one or more helper languages, inwhich parallel data is not used.In this work, we propose a learning frame-work for transferring dependency grammars froma resource-rich language to resource-poor lan-guages via parallel text.
We train probabilisticparsing models for resource-poor languages bymaximizing a combination of likelihood on par-allel data and confidence on unlabeled data.
Ourwork is based on the learning framework used inSmith and Eisner (2007), which is originally de-signed for parser bootstrapping.
We extend thislearning framework so that it can be used to trans-fer cross-lingual knowledge between different lan-guages.Throughout this paper, English is used as thesource language and we evaluate our approach onten target languages ?
Danish (da), Dutch (nl),French (fr), German (de), Greek (el), Italian (it),Korean (ko), Portuguese (pt), Spanish (es) andSwedish (sv).
Our approach achieves significantimprovement over previous state-of-the-art unsu-pervised and projected parsing systems across allthe ten languages, and considerably bridges theEconomic news had little effect on financial marketsRootFigure 1: An example dependency tree.gap to fully supervised dependency parsing per-formance.2 Our ApproachDependency trees represent syntactic relationshipsthrough labeled directed edges between heads andtheir dependents.
For example, Figure 1 shows adependency tree for the sentence, Economic newshad little effect on financial markets, with the sen-tence?s root-symbol as its root.
The focus of thiswork is on building dependency parsers for targetlanguages, assuming that an accurate English de-pendency parser and some parallel text betweenthe two languages are available.
Central to our ap-proach is a maximizing likelihood learning frame-work, in which we use an English parser and par-allel text to estimate the ?transferring distribution?of the target language parsing model (See Section2.2 for more details).
Another advantage of thelearning framework is that it combines both thelikelihood on parallel data and confidence on unla-beled data, so that both parallel text and unlabeleddata can be utilized in our approach.2.1 Edge-Factored Parsing ModelIn this paper, we will use the following notation:x represents a generic input sentence, and y rep-resents a generic dependency tree.
T(x) is usedto denote the set of possible dependency treesfor sentence x.
The probabilistic model for de-pendency parsing defines a family of conditionalprobability p?
(y|x) over all y given sentence x,with a log-linear form:p?
(y|x) =1Z(x)exp{?j?jFj(y,x)}(1)where Fjare feature functions, ?
= (?1, ?2, .
.
.
)are parameters of the model, and Z(x) is a nor-malization factor, which is commonly referred toas the partition function:Z(x) =?y?T(x)exp{?j?jFj(y,x)}(2)1338A common strategy to make this parsing model ef-ficiently computable is to factor dependency treesinto sets of edges:Fj(y,x) =?e?yfj(e,x).
(3)That is, dependency tree y is treated as a setof edges e and each feature function Fj(y,x) isequal to the sum of all the features fj(e,x).We denote the weight function of each edge e asfollows:w(e,x) = exp{?j?jfj(e,x)}(4)and the conditional probability p?
(y|x) has thefollowing form:p?
(y|x) =1Z(x)?e?yw(e,x) (5)2.2 Model TrainingOne of the most common model training meth-ods for supervised dependency parser is Maxi-mum conditional likelihood estimation.
For a su-pervised dependency parser with a set of train-ing data {(xi,yi)}, the logarithm of the likelihood(a.k.a.
the log-likelihood) is given by:L(?)
=?ilog p?
(yi|xi) (6)Maximum likelihood training chooses parameterssuch that the log-likelihood L(?)
is maximized.However, in our scenario we have no labeledtraining data for target languages but we havesome parallel and unlabeled data plus an En-glish dependency parser.
For the purpose oftransferring cross-lingual information from theEnglish parser via parallel text, we explore themodel training method proposed by Smith andEisner (2007), which presented a generalization ofK function (Abney, 2004), and related it to an-other semi-supervised learning technique, entropyregularization (Jiao et al, 2006; Mann and Mc-Callum, 2007).
The objective K function to beminimized is actually the expected negative log-likelihood:K = ??i?yip?
(yi|xi) log p?
(yi|xi)=?iD(p?i||p?,i) +H(p?i) (7)where p?i(?
)def= p?
(?|xi) and p?,i(?
)def= p?(?|xi).p?
(y|x) is the ?transferring distribution?
that re-flects our uncertainty about the true labels, and weare trying to learn a parametric model p?
(y|x) byminimizing the K function.In our scenario, we have a set of aligned par-allel data P = {xsi,xti, ai} where aiis the wordalignment for the pair of source-target sentences(xsi,xti), and a set of unlabeled sentences of thetarget language U = {xti}.
We also have a trainedEnglish parsing model p?E(y|x).
Then the K inequation (7) can be divided into two cases, accord-ing to whether xibelongs to parallel data set P orunlabeled data set U .
For the unlabeled examples{xi?
U}, some previous studies (e.g., (Abney,2004)) simply use a uniform distribution over la-bels (e.g., parses), to reflect that the label is un-known.
We follow the method in Smith and Eis-ner (2007) and take the transferring distributionp?ito be the actual current belief p?,i.
The totalcontribution of the unsupervised examples to Kthen simplifies to KU=?xi?UH(p?,i), which maybe regarded as the entropy item used to constrainthe model?s uncertainty H to be low, as presentedin the work on entropy regularization (Jiao et al,2006; Mann and McCallum, 2007).But how can we define the transferring distri-bution for the parallel examples {xti?
P}?
Wedefine the transferring distribution by defining thetransferring weight utilizing the English parsingmodel p?E(y|x) via parallel data with word align-ments:w?
(et,xti) ={wE(es,xsi), if et algn??
eswE(etdelex,xsi), otherwise(8)where wE(?, ?)
is the weight function of the En-glish parsing model p?E(y|x), and etdelexis thedelexicalized form2 of the edge et.
From thedefinition of the transferring weight, we can seethat, if an edge et of the target language sentencextiis aligned to an edge es of the English sen-tence xsi, we transfer the weight of edge et tothe corresponding weight of edge es in the En-glish parsing model p?E(y|x).
If the edge etis not aligned to any edges of the English sen-tence xsi, we reduce the edge et to the delexical-ized form and calculate the transferring weight inthe English parsing model.
There are two advan-2The delexicalized form of an edge is an edge for whichonly delexicalized features are considered.1339tages for this definition of the transferring weight.First, by transferring the weight function to thecorresponding weight in the well-developed En-glish parsing model, we can project syntactic in-formation across language boundaries.
Second,McDonald et al (2011) demonstrates that parserswith only delexicalized features produce consid-erably high parsing performance.
By reducingunaligned edges to their delexicalized forms, wecan still use those delexicalized features, such aspart-of-speech tags, for those unaligned edges, andcan address problem that automatically generatedword alignments include errors.From the definition of transferring weight inequation (8), the transferring distribution can bedefined in the following way:p?
(y|x) =1?Z(x)?e?yw?
(e,x) (9)where?Z(x) =?y?e?yw?
(e,x) (10)Due to the normalizing factor ?Z(x), the transfer-ring distribution is a valid one.We introduce a multiplier ?
as a trade-off be-tween the two contributions (parallel and unsuper-vised) of the objective function K , and the finalobjective function K ?
has the following form:K?= ??xi?P?yip?
(yi|xi) log p?
(yi|xi)+ ?
?xi?UH(p?,i)= KP+ ?KU(11)KPand KUare the contributions of the paralleland unsupervised data, respectively.
One may re-gard ?
as a Lagrange multiplier that is used toconstrain the parser?s uncertainty H to be low, aspresented in several studies on entropy regulariza-tion (Brand, 1998; Grandvalet and Bengio, 2004;Jiao et al, 2006).2.3 Algorithms and Complexity for ModelTrainingTo train our parsing model, we need to find out theparameters ?
that minimize the objective functionK?
in equation (11).
This optimization problemis typically solved using quasi-Newton numeri-cal methods such as L-BFGS (Nash and Nocedal,1991), which requires efficient calculation of theobjective function and the gradient of the objec-tive function.The first item (KP) of the K ?
function in equa-tion (11) can be rewritten in the following form:KP= ??xi?P[?yip?(yi|xi)?e?yilogw(e,xi)?
logZ(xi)] (12)and according to equation (1) and (3) the gradientof KPcan be written as:?KP??j=?xi?P?p?
(yi|xi) log p?(yi|xi)??j=?xi?P[?yip?(yi|xi)?e?yifj(e,xi)??yip?
(yi|xi)?e?yifj(e,xi)](13)According to equation (9), p?
(y|x) can also befactored into the multiplication of the weight ofeach edge, so both KPand its gradient can becalculated by running the O(n3) inside-outside al-gorithm (Baker, 1979; Paskin, 2001) for projec-tive parsing.
For non-projective parsing, the anal-ogy to the inside algorithm is the O(n3) matrix-tree algorithm based on Kirchhoff?s Matrix-TreeTheorem, which is dominated asymptotically by amatrix determinant (Koo et al, 2007; Smith andSmith, 2007).
The gradient of a determinant maybe computed by matrix inversion, so evaluating thegradient again has the same O(n3) complexity asevaluating the function.The second item (KU) of the K ?
function inequation (11) is the Shannon entropy of the pos-terior distribution over parsing trees, and can bewritten into the following form:KU= ??xi?U[?yip?(yi|xi)?e?yilogw(e,xi)?
logZ(xi)] (14)and the gradient of KUis in the following:?KU??j=?xi?U?p?
(yi|xi) log p?(yi|xi)?
?j= ??yip?
(yi|xi) log p?(yi|xi)Fj(yi,xi)+(?yip?
(yi|xi) log p?(yi|xi))?(?yip?
(yi|xi)Fj(yi,xi))(15)1340#sents/#tokenstraining dev testVersion 1.0de 2,200/30,460 800/12,215 1,000/16,339es 3,345/94,232 370/10,191 300/8,295fr 3,312/74,979 366/8,071 300/6,950ko 5,308/62,378 588/6,545 298/2,917sv 4,447/66,631 493/9,312 1,219/20,376Version 2.0de 14,118/26,4906 800/12,215 1,000/16,339es 14,138/37,5180 1,569/40,950 300/8,295fr 14,511/35,1233 1,611/38,328 300/6,950it 6,389/14,9145 400/9,541 400/9,187ko 5437/60,621 603/6,438 299/2,631pt 9,600/23,9012 1,200/29,873 1,198/29,438sv 4,447/66,631 493/9,312 1,219/20,376Table 1: Data statistics of two versions of GoogleUniversal Treebanks for the target languages.Similar with the calculation of KP, KUcan alsobe computed by running the inside-outside algo-rithm (Baker, 1979; Paskin, 2001) for projectiveparsing.
For the gradient of KU, both the twomultipliers of the second item in equation (15) canbe computed using the same inside-outside algo-rithm.
For the first item in equation (15), an O(n3)dynamic programming algorithm that is closelyrelated to the forward-backward algorithm (Mannand McCallum, 2007) for the entropy regularizedCRF (Jiao et al, 2006) can be used for projectiveparsing.
For non-projective parsing, however, theruntime rises to O(n4).
In this paper, we focus onprojective parsing.2.4 Summary of Our ApproachTo summarize the description in the previous sec-tions, our approach is performed in the followingsteps:1.
Train an English parsing model p?E(y|x),which is used to estimate the transferring dis-tribution p?(y|x).2.
Prepare parallel text by running word align-ment method to obtain word alignments,3 andprepare the unlabeled data.3.
Train a parsing model for the target lan-guage by minimizing the objective K ?
func-tion which is the combination of expectednegative log-likelihood on parallel and unla-beled data.3The word alignment methods do not require additionalresources besides parallel text.# sents500 1000 2000 5000 10000 20000da 12,568 25,225 49,889 126,623 254,565 509,480de 13,548 26,663 53,170 133,596 265,589 527,407el 14,198 28,302 56,744 143,753 286,126 572,777es 15,147 29,214 57,526 144,621 290,517 579,164fr 15,046 29,982 60,569 153,874 306,332 609,541it 15,151 29,786 57,696 145,717 288,337 573,557ko 3,814 7,679 15,337 38,535 77,388 155,051nl 13,234 26,777 54,570 137,277 274,692 551,463pt 14,346 28,109 55,998 143,221 285,590 571,109sv 12,242 24,897 50,047 123,069 246,619 490,086Table 2: The number of tokens in parallel dataused in our experiments.
For all these corpora, theother language is English.3 Data and ToolsIn this section, we illustrate the data sets used inour experiments and the tools for data preparation.3.1 Choosing Target LanguagesOur experiments rely on two kinds of data sets:(i) Monolingual Treebanks with consistent anno-tation schema ?
English treebank is used to trainthe English parsing model, and the Treebanks fortarget languages are used to evaluate the parsingperformance of our approach.
(ii) Large amountsof parallel text with English on one side.
We se-lect target languages based on the availability ofthese resources.
The monolingual treebanks in ourexperiments are from the Google Universal De-pendency Treebanks (McDonald et al, 2013), forthe reason that the treebanks of different languagesin Google Universal Dependency Treebanks haveconsistent syntactic representations.The parallel data come from the Europarl cor-pus version 7 (Koehn, 2005) and Kaist Corpus4.Taking the intersection of languages in the twokinds of resources yields the following seven lan-guages: French, German, Italian, Korean, Por-tuguese, Spanish and Swedish.The treebanks from CoNLL shared-tasks ondependency parsing (Buchholz and Marsi, 2006;Nivre et al, 2007) appear to be another reasonablechoice.
However, previous studies (McDonald etal., 2011; McDonald et al, 2013) have demon-strated that a homogeneous representation is criti-cal for multilingual language technologies that re-quire consistent cross-lingual analysis for down-stream components, and the heterogenous repre-sentations used in CoNLL shared-tasks treebanksweaken any conclusion that can be drawn.4http://semanticweb.kaist.ac.kr/home/index.php/Corpus101341DTP DTP?
PTP?
-U +U ORde 58.50 58.46 69.21 73.72 74.01 78.64es 68.07 68.72 72.57 75.32 75.60 82.56fr 70.14 71.13 74.60 76.65 76.93 83.69ko 42.37 43.57 53.72 59.72 59.94 89.85sv 70.56 70.59 75.87 78.91 79.27 85.59Ave 61.93 62.49 69.19 72.86 73.15 84.67Table 3: UAS for two versions of our approach, to-gether with baseline and oracle systems on GoogleUniversal Treebanks version 1.0.
?Ave?
is themacro-average across the five languages.For comparison with previous studies, never-theless, we also run experiments on CoNLL tree-banks (see Section 4.4 for more details).
We eval-uate our approach on three target languages fromCoNLL shared task treebanks, which do not ap-pear in Google Universal Treebanks.
The threelanguages are Danish, Dutch and Greek.
So totallywe have ten target languages.
The parallel data forthese three languages are also from the Europarlcorpus version 7.3.2 Word AlignmentsIn our approach, word alignments for the paral-lel text are required.
We perform word alignmentswith the open source GIZA++ toolkit5.
The paral-lel corpus was preprocessed in standard ways, se-lecting sentences with the length in the range from3 to 100.
Then we run GIZA++ with the defaultsetting to generate word alignments in both direc-tions.
We then make the intersection of the wordalignments of two directions to generate one-to-one alignments.3.3 Part-of-Speech TaggingSeveral features in our parsing model involve part-of-speech (POS) tags of the input sentences.
Theset of POS tags needs to be consistent across lan-guages and treebanks.
For this reason we usethe universal POS tag set of Petrov et al (2011).This set consists of the following 12 coarse-grained tags: NOUN (nouns), VERB (verbs), ADJ(adjectives), ADV (adverbs), PRON (pronouns),DET (determiners), ADP (prepositions or postpo-sitions), NUM (numerals), CONJ (conjunctions),PRT (particles), PUNC (punctuation marks) andX (a catch-all for other categories such as abbrevi-ations or foreign words).POS tags are not available for parallel data inthe Europarl and Kaist corpus, so we need to pro-5https://code.google.com/p/giza-pp/DTP?
PTP?
-U +U ORde 58.56 69.77 73.92 74.30 81.65es 68.72 73.22 75.21 75.53 83.92fr 71.13 74.75 76.14 76.53 83.51it 70.74 76.08 77.55 77.74 85.47ko 38.55 43.34 59.71 59.89 90.42pt 69.82 74.59 76.30 76.65 85.67sv 70.59 75.87 78.91 79.27 85.59Ave 64.02 69.66 73.96 74.27 85.18Table 4: UAS for two versions of our approach, to-gether with baseline and oracle systems on GoogleUniversal Treebanks version 2.0.
?Ave?
is themacro-average across the seven languages.vide the POS tags for these data.
In our experi-ments, we train a Stanford POS Tagger (Toutanovaet al, 2003) for each language.
The labeled train-ing data for each POS tagger are extracted fromthe training portion of each Treebanks.
The aver-age tagging accuracy is around 95%.Undoubtedly, we are primarily interested in ap-plying our approach to build statistical parsersfor resource-poor target languages without anyknowledge.
For the purpose of evaluation of ourapproach and comparison with previous work, weneed to exploit the gold POS tags to train the POStaggers.
As part-of-speech tags are also a formof syntactic analysis, this assumption weakens theapplicability of our approach.
Fortunately, somerecently proposed POS taggers, such as the POStagger of Das and Petrov (2011), rely only on la-beled training data for English and the same kindof parallel text in our approach.
In practice we canuse this kind of POS taggers to predict POS tags,whose tagging accuracy is around 85%.4 ExperimentsIn this section, we will describe the details of ourexperiments and compare our results with previ-ous methods.4.1 Data SetsAs presented in Section 3.1, we evaluate our pars-ing approach on both version 1.0 and version2.0 of Google Univereal Treebanks for seven lan-guages6.
We use the standard splits of the treebankfor each language as specified in the release of thedata7.
Table 1 presents the statistics of the two ver-sions of Google Universal Treebanks.
We strip all6Japanese and Indonesia are excluded as no practicableparallel data are available.7https://code.google.com/p/uni-dep-tb/1342Google Universal Treebanks V1.0de es fr ko sv# sents PTP?
-U +U PTP?
-U +U PTP?
-U +U PTP?
-U +U PTP?
-U +U500 63.23 70.79 70.93 70.09 72.32 72.64 72.24 74.64 74.90 47.71 56.87 57.22 71.70 75.88 76.131000 65.61 71.71 71.86 70.90 73.44 73.67 72.95 75.07 75.35 47.83 57.65 58.15 72.38 76.55 77.032000 66.52 72.33 72.48 72.01 73.57 73.81 73.69 75.88 76.22 48.37 58.19 58.44 73.65 77.86 78.125000 67.79 73.06 73.31 72.34 74.30 74.79 74.31 76.02 76.29 53.02 58.57 59.04 74.88 78.48 78.7010000 68.44 73.59 73.92 72.48 74.86 75.26 74.43 76.14 76.34 53.61 59.17 59.55 75.34 78.78 79.0820000 69.21 73.72 74.01 72.57 75.32 75.60 74.60 76.55 76.93 53.72 59.72 59.94 75.87 78.91 79.27Google Universal Treebanks V2.0de es fr ko it# sents PTP?
-U +U PTP?
-U +U PTP?
-U +U PTP?
-U +U PTP?
-U +U500 60.10 71.07 71.39 69.52 72.97 73.28 71.10 74.57 74.70 40.09 56.60 57.10 72.80 75.67 75.941000 61.76 72.15 72.39 70.78 73.48 73.79 72.14 75.13 75.43 40.44 57.55 57.93 73.55 76.43 76.672000 65.35 72.73 73.04 71.75 74.10 74.35 73.21 75.78 76.06 40.87 58.11 58.43 74.44 76.99 77.395000 67.86 73.32 73.62 72.43 74.55 74.83 74.14 75.83 76.02 40.90 58.48 58.96 75.07 77.10 77.3410000 68.70 73.71 74.02 72.85 74.80 74.95 74.53 75.97 76.17 41.29 59.13 59.44 75.65 77.50 77.7120000 69.77 73.92 74.30 73.22 75.21 75.53 74.75 76.14 76.53 43.34 59.71 59.89 76.08 77.55 77.74pt# sents PTP?
-U +U500 71.34 74.41 74.681000 71.91 74.48 75.082000 72.93 75.10 75.325000 73.78 75.88 75.9810000 74.40 75.99 76.1520000 74.59 76.30 76.65Table 5: Parsing results of our approach with different amount of parallel data on Google UniversalTreebanks version 1.0 and 2.0.
We omit the results of Swedish for treebanks version 2.0 since the datafor Swedish from version 2.0 are exactly the same with those from version 1.0.the dependency annotations off the training por-tion of each treebank, and use that as the unla-beled data for that target language.
We train ourparsing model with different numbers of parallelsentences to analyze the influence of the amount ofparallel data on the parsing performance of our ap-proach.
The parallel data sets contain 500, 1000,2000, 5000, 10000 and 20000 parallel sentences,respectively.
We randomly extract parallel sen-tences from each corpora, and smaller data sets aresubsets of larger ones.
Table 2 shows the numberof tokens in the parallel data used in the experi-ments.4.2 System performance and comparisonon Google Universal TreebanksFor the comparison of parsing performance, werun experiments on the following systems:DTP: The direct transfer parser (DTP) proposedby McDonald et al (2011), who train a delex-icalized parser on English labeled trainingdata with no lexical features, then apply thisparser to parse target languages directly.
Itis based on the transition-based dependencyparsing paradigm (Nivre, 2008).
We di-rectly cite the results reported in McDon-ald et al (2013).
In addition to their orig-inal results, we also report results by re-implementing the direct transfer parser basedon the first-order projective dependency pars-ing model (McDonald et al, 2005a) (DTP?
).PTP The projected transfer parser (PTP) de-scribed in McDonald et al (2011).
Theresults of the projected transfer parser re-implemented by us is marked as ?PTP?
?.-U: Our approach training on only parallel datawithout unlabeled data for the target lan-guage.
The parallel data set for each languagecontains 20,000 sentences.+U: Our approach training on both parallel andunlabeled data.
The parallel data sets are theones contains 20,000 sentences.OR: the supervised first-order projective depen-dency parsing model (McDonald et al,2005a), trained on the original treebanks withmaximum likelihood estimation (equation 6).One may regard this system as an oracle oftransfer parsing.Parsing accuracy is measured with unlabeled at-tachment score (UAS): the percentage of wordswith the correct head.Table 3 and Table 4 shows the parsing results ofour approach, together with the results of the base-line systems and the oracle, on version 1.0 and ver-sion 2.0 of Google Universal Treebanks, respec-tively.
Our approaches significantly outperform allthe baseline systems across all the seven target lan-guages.
For the results on Google Universal Tree-banks version 1.0, the improvement on averageover the projected transfer paper (PTP?)
is 3.96%1343and up to 6.22% for Korean and 4.80% for Ger-man.
For the other three languages, the improve-ments are remarkable, too ?
2.33% for French,3.03% for Spanish and 3.40% for Swedish.
Byadding entropy regularization from unlabeled data,our full model achieves average improvement of0.29% over the ?-U?
setting.
Moreover, our ap-proach considerably bridges the gap to fully super-vised dependency parsers, whose average UAS is84.67%.
For the results on treebanks version 2.0,we can get similar observation and draw the sameconclusion.4.3 Effect of the Amount of Parallel TextTable 5 illustrates the UAS of our approach trainedon different amounts of parallel data, togetherwith the results of the projected transfer parserre-implemented by us (PTP?).
We run two ver-sions of our approach for each of the parallel datasets, one with unlabeled data (+U) and the otherwithout them (-U).
From table 5 we can get threeobservations.
First, even the parsers trained withonly 500 parallel sentences achieve considerablyhigh parsing accuracies (average 70.10% for ver-sion 1.0 and 71.59% for version 2.0).
This demon-strates that our approach does not rely on a largeamount of parallel data.
Second, when graduallyincreasing the amount of parallel data, the parsingperformance continues improving.
Third, entropyregularization with unlabeled data makes mod-est improvement on parsing performance over theparsers without unlabeled data.
This proves the ef-fectiveness of the entropy regularization from un-labeled data.4.4 Experiments on CoNLL TreebanksTo make a thorough empirical comparison withprevious studies, we also evaluate our systemwithout unlabeled data (-U) on treebanks fromCoNLL shared task on dependency parsing (Buch-holz and Marsi, 2006; Nivre et al, 2007).
To fa-cilitate comparison, we use the same eight Indo-European languages as target languages: Danish,Dutch, German, Greek, Italian, Portuguese, Span-ish and Swedish, and same experimental setup asMcDonald et al (2011).
We report both the resultsof the direct transfer and projected transfer parsersdirectly cited from McDonald et al (2011) (DTPand PTP) and re-implemented by us (DTP?andPTP?
).Table 6 gives the results comparing the modelwithout unlabeled data (-U) presented in this workDMV DTP DTP?
PTP PTP?
-U ORda 33.4 45.9 46.8 48.2 50.0 50.1 87.1de 18.0 47.2 46.0 50.9 52.4 57.3 87.0el 39.9 63.9 62.9 66.8 65.3 67.4 82.3es 28.5 53.3 54.4 55.8 59.9 60.3 83.6it 43.1 57.7 59.9 60.8 63.4 64.0 83.9nl 38.5 60.8 60.7 67.8 66.5 68.2 78.2pt 20.1 69.2 71.1 71.3 74.8 75.1 87.2sv 44.0 58.3 60.3 61.3 62.8 66.7 88.0Ave 33.2 57.0 57.8 60.4 61.9 63.6 84.7Table 6: Parsing results on treebanks from CoNLLshared tasks for eight target languages.
The resultsof unsupervised DMV model are from Table 1 ofMcDonald et al (2011).to those five baseline systems and the oracle (OR).The results of unsupervised DMV model (Kleinand Manning, 2004) are from Table 1 of McDon-ald et al (2011).
Our approach outperforms allthese baseline systems and achieves state-of-the-art performance on all the eight languages.In order to compare with more previous meth-ods, we also report parsing performance on sen-tences of length 10 or less after punctuationhas been removed.
Table 7 shows the resultsof our system and the results of baseline sys-tems.
?USR??
is the weakly supervised system ofNaseem et al (2010).
?PGI?
is the phylogeneticgrammar induction model of Berg-Kirkpatrick andKlein (2010).
Both the results of the two systemsare cited from Table 4 of McDonald et al (2011).We also include the results of the unsuperviseddependency parsing model with non-parallel mul-tilingual guidance (NMG) proposed by Cohen etal.
(2011)8, and ?PR?
which is the posterior reg-ularization approach presented in Gillenwater etal.
(2010).
All the results are shown in Table 7.From Table 7, we can see that among the eighttarget languages, our approach achieves best pars-ing performance on six languages ?
Danish, Ger-man, Greek, Italian, Portuguese and Swedish.
Itshould be noted that the ?NMG?
system utilizesmore than one helper languages.
So it is not di-rectly comparable to our work.4.5 ExtensionsIn this section, we briefly outline a few extensionsto our approach that we want to explore in futurework.8For each language, we use the best result of the four sys-tems in Table 3 of Cohen et al (2011)1344DTP DTP?
PTP PTP?
USR?
PGI PR NMG -Uda 53.2 55.3 57.4 59.8 55.1 41.6 44.0 59.9 60.1de 65.9 57.9 67.0 63.5 60.0 ?
?
?
67.5el 73.9 70.8 73.9 72.3 60.3 ?
?
73.0 74.3es 58.0 62.3 62.3 66.1 68.3 58.4 62.4 76.7 64.6it 65.5 66.9 69.9 71.5 47.9 ?
?
?
73.6nl 67.6 66.0 72.2 72.1 44.0 45.1 37.9 50.7 70.5pt 77.9 79.2 80.6 82.9 70.9 63.0 47.8 79.8 83.3sv 70.4 70.2 71.3 70.4 52.6 58.3 42.2 74.0 75.1Ave 66.6 66.1 69.4 69.8 57.4 ?
?
?
71.1Table 7: UAS on sentences of length 10 or less without punctuation from CoNLL shared task treebanks.?USR??
is the weakly supervised system of Naseem et al (2010).
?PGI?
is the phylogenetic grammarinduction model of Berg-Kirkpatrick and Klein (2010).
Both the ?USR??
and ?PGI?
systems are im-plemented and reported by McDonald et al (2011).
?NMG?
is the unsupervised dependency parsingmodel with non-parallel multilingual guidance (Cohen et al, 2011).
?PR?
is the posterior regularizationapproach presented in Gillenwater et al (2010).
Some systems?
results for certain target languages arenot available as marked by ?.4.5.1 Non-Projective ParsingAs mentioned in section 2.3, the runtime to com-pute KUand its gradient is O(n4).
One reasonablespeedup, as presented in Smith and Eisner (2007),is to replace Shannon entropy with Re?nyi entropy.The Re?nyi entropy is parameterized by ?:R?
(p) =11 ?
?log(?yp(y)?
)(16)With Re?nyi entropy, the computation of KUandits gradient is O(n3), even for non-projective case.4.5.2 Higher-Order Models for ProjectiveParsingOur learning framework can be extended tohigher-order dependency parsing models.
For ex-ample, if we want to make our model capable ofutilizing more contextual information, we can ex-tend our transferring weight to higher-order parts:w?
(pt,xti) ={wE(ps,xsi), if pt align??
pswE(ptdelex,xsi), otherwise(17)where p is a small part of tree y that has limitedinteractions.
For projective parsing, several al-gorithms (McDonald and Pereira, 2006; Carreras,2007; Koo and Collins, 2010; Ma and Zhao, 2012)have been proposed to solve the model trainingproblems (calculation of objective function andgradient) for different factorizations.4.5.3 IGT DataOne possible direction to improve our approachis to replace parallel text with Interlinear GlossedText (IGT) (Lewis and Xia, 2010), which is asemi-structured data type encoding more syntacticinformation than parallel data.
By using IGT Data,not only can we obtain more accurate word align-ments, but also extract useful cross-lingual infor-mation for the resource-poor language.5 ConclusionIn this paper, we propose an unsupervised pro-jective dependency parsing approach for resource-poor languages, using existing resources from aresource-rich source language.
By presenting amodel training framework, our approach can uti-lize parallel text to estimate transferring distribu-tion with the help of a well-developed resource-rich language dependency parser, and use unla-beled data as entropy regularization.
The exper-imental results on three data sets across ten targetlanguages show that our approach achieves signif-icant improvement over previous studies.AcknowledgementsThis material is based upon work supported bythe National Science Foundation under Grant No.BCS-0748919.
Any opinions, findings, and con-clusions or recommendations expressed in thismaterial are those of the authors and do not nec-essarily reflect the views of the National ScienceFoundation.1345ReferencesSteven Abney.
2004.
Understanding the Yarowsky al-gorithm.
Computational Linguistics, 30:2004.James K. Baker.
1979.
Trainable grammars for speechrecognition.
In Proceedings of 97th meeting of theAcoustical Society of America, pages 547?550.Taylor Berg-Kirkpatrick and Dan Klein.
2010.
Phylo-genetic grammar induction.
In Proceedings of ACL-2010, pages 1288?1297, Uppsala, Sweden, July.Phil Blunsom and Trevor Cohn.
2010.
Unsupervisedinduction of tree substitution grammars for depen-dency parsing.
In Proceedings of EMNLP-2010,pages 1204?1213, Cambridge, MA, October.Matthew Brand.
1998.
Structure learning in con-ditional probability models via an entropic priorand parameter extinction.
Neural Computation,11(5):1155?1182.Sabine Buchholz and Erwin Marsi.
2006.
CoNLL-Xshared task on multilingual dependency parsing.
InProceeding of CoNLL-2006, pages 149?164, NewYork, NY.David Burkett and Dan Klein.
2008.
Two languagesare better than one (for syntactic parsing).
In Pro-ceedings of EMNLP-2008, pages 877?886, Hon-olulu, Hawaii, October.Xavier Carreras.
2007.
Experiments with a higher-order projective dependency parser.
In Proceed-ings of the CoNLL Shared Task Session of EMNLP-CONLL, pages 957?961.Glenn Carroll and Eugene Charniak.
1992.
Twoexperiments on learning probabilistic dependencygrammars from corpora.
In Proceedings of Work-ing Notes of the Workshop Statistically-Based NLPTechniques.Wenliang Chen, Jun?ichi Kazama, and Kentaro Tori-sawa.
2010.
Bitext dependency parsing with bilin-gual subtree constraints.
In Proceedings of ACL-2010, pages 21?29, Uppsala, Sweden, July.Shay Cohen and Noah A. Smith.
2009.
Shared lo-gistic normal distributions for soft parameter tyingin unsupervised grammar induction.
In Proceedingsof NAACL/HLT-2009, pages 74?82, Boulder, Col-orado, June.Shay B. Cohen, Dipanjan Das, and Noah A. Smith.2011.
Unsupervised structure prediction with non-parallel multilingual guidance.
In Proceedings ofEMNLP-2011, pages 50?61, Edinburgh, Scotland,UK., July.Dipanjan Das and Slav Petrov.
2011.
Unsuper-vised part-of-speech tagging with bilingual graph-based projections.
In Proceedings of ACL/HLT-2011, pages 600?609, Portland, Oregon, USA, June.Kuzman Ganchev, Jennifer Gillenwater, and BenTaskar.
2009.
Dependency grammar inductionvia bitext projection constraints.
In Proceedings ofACL/AFNLP-2009, pages 369?377, Suntec, Singa-pore, August.Jennifer Gillenwater, Kuzman Ganchev, Joa?o Grac?a,Fernando Pereira, and Ben Taskar.
2010.
Sparsity independency grammar induction.
In Proceedings ofthe ACL 2010 Conference Short Papers, pages 194?199, Uppsala, Sweden, July.Joao V. Graca, Lf Inesc-id, Kuzman Ganchev, and BenTaskar.
2007.
Expectation maximization and pos-terior constraints.
In Advances in NIPS, pages 569?576.Yves Grandvalet and Yoshua Bengio.
2004.
Semi-supervised learning by entropy minimization.
In Ad-vances in Neural Information Processing Systems.Liang Huang, Wenbin Jiang, and Qun Liu.
2009.Bilingually-constrained (monolingual) shift-reduceparsing.
In Proceedings of EMNLP-2009, pages1222?1231, Singapore, August.Rebecca Hwa, Philip Resnik, Amy Weinberg, ClaraCabezas, and Okan Kolak.
2005.
Bootstrappingparsers via syntactic projection across parallel texts.Natural Language Engineering, 11:11?311.Feng Jiao, Shaojun Wang, Chi-Hoon Lee, RussellGreiner, and Dale Schuurmans.
2006.
Semi-supervised conditional random fields for improvedsequence segmentation and labeling.
In Proceed-ings of COLING/ACL-2006, pages 209?216, Syd-ney, Australia, July.Jason Katz-Brown, Slav Petrov, Ryan McDon-ald, Franz Och, David Talbot, Hiroshi Ichikawa,Masakazu Seno, and Hideto Kazawa.
2011.
Train-ing a parser for machine translation reordering.
InProceedings of EMNLP-2011, pages 183?192, Ed-inburgh, Scotland, UK., July.Dan Klein and Christopher Manning.
2004.
Corpus-based induction of syntactic structure: Models of de-pendency and constituency.
In Proceedings of ACL-2004, pages 478?485, Barcelona, Spain, July.Philipp Koehn.
2005.
Europarl: A Parallel Corpusfor Statistical Machine Translation.
In ConferenceProceedings: the tenth Machine Translation Sum-mit, pages 79?86, Phuket, Thailand.
AAMT, AAMT.Terry Koo and Michael Collins.
2010.
Efficient third-order dependency parsers.
In Proceedings of ACL-2010, pages 1?11, Uppsala, Sweden, July.Terry Koo, Amir Globerson, Xavier Carreras, andMichael Collins.
2007.
Structured predicition mod-els via the matrix-tree theorem.
In Proceedingsof EMNLP-CONLL 2007, pages 141?150, Prague,Czech, June.1346William D. Lewis and Fei Xia.
2010.
Developingodin: A multilingual repository of annotated lan-guage data for hundreds of the world?s languages.LLC, 25(3):303?319.Xuezhe Ma and Hai Zhao.
2012.
Fourth-order depen-dency parsing.
In Proceedings of COLING 2012:Posters, pages 785?796, Mumbai, India, December.Gideon S. Mann and Andrew McCallum.
2007.
Ef-ficient computation of entropy gradient for semi-supervised conditional random fields.
In Proceed-ings of NAACL/HLT-2007, pages 109?112, Strouds-burg, PA, USA.David Marec?ek and Milan Straka.
2013.
Stop-probability estimates computed on a large corpusimprove unsupervised dependency parsing.
In Pro-ceedings of ACL-2013, pages 281?290, Sofia, Bul-garia, August.Ryan McDonald and Fernando Pereira.
2006.
Onlinelearning of approximate dependency parsing algo-rithms.
In Proceedings of EACL-2006, pages 81?88,Trento, Italy, April.Ryan McDonald, Koby Crammer, and FernandoPereira.
2005a.
Online large-margin training ofdependency parsers.
In Proceedings of ACL-2005,pages 91?98, Ann Arbor, Michigan, USA, June 25-30.Ryan McDonald, Fernando Pereira, Kiril Ribarov, andJan Hajic.
2005b.
Non-projective dependency pars-ing using spanning tree algorithms.
In Proceedingsof HLT/EMNLP-2005, pages 523?530, Vancouver,Canada, October.Ryan McDonald, Slav Petrov, and Keith Hall.
2011.Multi-source transfer of delexicalized dependencyparsers.
In Proceedings of EMNLP-2011, pages 62?72, Edinburgh, Scotland, UK., July.Ryan McDonald, Joakim Nivre, Yvonne Quirmbach-Brundage, Yoav Goldberg, Dipanjan Das, Kuz-man Ganchev, Keith Hall, Slav Petrov, HaoZhang, Oscar Ta?ckstro?m, Claudia Bedini, Nu?riaBertomeu Castello?, and Jungmee Lee.
2013.
Uni-versal dependency annotation for multilingual pars-ing.
In Proceedings of ACL-2013, pages 92?97,Sofia, Bulgaria, August.Tahira Naseem, Harr Chen, Regina Barzilay, and MarkJohnson.
2010.
Using universal linguistic knowl-edge to guide grammar induction.
In Proceedings ofEMNLP-2010, pages 1234?1244, Cambridge, MA,October.Stephen G. Nash and Jorge Nocedal.
1991.
A numer-ical study of the limited memory bfgs method andtruncated-newton method for large scale optimiza-tion.
SIAM Journal on Optimization, 1(2):358?372.Truc-Vien T. Nguyen, Alessandro Moschitti, andGiuseppe Riccardi.
2009.
Convolution kernels onconstituent, dependency and sequential structuresfor relation extraction.
In Proceedings of EMNLP-2009, pages 1378?1387, Singapore, August.Joakim Nivre and Mario Scholz.
2004.
Deterministicdependency parsing of English text.
In Proceedingsof COLING-2004, pages 64?70, Geneva, Switzer-land, August 23-27.Joakim Nivre, Johan Hall, Sandra Ku?bler, Ryan Mc-donald, Jens Nilsson, Sebastian Riedel, and DenizYuret.
2007.
The conll 2007 shared task on depen-dency parsing.
In Proceeding of EMNLP-CoNLL2007, pages 915?932, Prague, Czech.Joakim Nivre.
2008.
Algorithms for deterministic in-cremental dependency parsing.
Comput.
Linguist.,34(4):513?553, December.Mark A. Paskin.
2001.
Cubic-time parsing andlearning algorithms for grammatical bigram models.Technical Report, UCB/CSD-01-1148.Slav Petrov, Dipanjan Das, and Ryan T. McDonald.2011.
A universal part-of-speech tagset.
CoRR,abs/1104.2086.Yusuke Shinyama, Satoshi Sekine, and Kiyoshi Sudo.2002.
Automatic paraphrase acquisition from newsarticles.
In Proceeding of HLT-2002, pages 313?318.Noah A. Smith and Jason Eisner.
2005.
Contrastiveestimation: Training log-linear models on unlabeleddata.
In Proceedings of ACL-2005, pages 354?362,Ann Arbor, Michigan, June.David A. Smith and Jason Eisner.
2007.
Bootstrappingfeature-rich dependency parsers with entropic pri-ors.
In Proceedings of EMNLP/CoNLL-2007, pages667?677, Prague, Czech Republic, June.David A. Smith and Noah A. Smith.
2004.
Bilin-gual parsing with factored estimation: Using En-glish to parse Korean.
In Proceedings of EMNLP-2004, pages 49?56.David A. Smith and Noah A. Smith.
2007.
Probabilis-tic models of nonporjective dependency trees.
InProceedings of EMNLP-CONLL 2007, pages 132?140, Prague, Czech, June.Valentin I. Spitkovsky, Hiyan Alshawi, and Daniel Ju-rafsky.
2010.
From baby steps to leapfrog: How?less is more?
in unsupervised dependency parsing.In Proceedings of NAACL/HLT-2010, pages 751?759, Los Angeles, California, June.Valentin I. Spitkovsky, Hiyan Alshawi, and Daniel Ju-rafsky.
2013.
Breaking out of local optima withcount transforms and model recombination: A studyin grammar induction.
In Proceedings of EMNLP-2013, pages 1983?1995, Seattle, Washington, USA,October.1347Kristina Toutanova, Dan Klein, Christopher D. Man-ning, and Yoram Singer.
2003.
Feature-rich part-of-speech tagging with a cyclic dependency network.In Proceedings of NAACL/HLT-2003, pages 252?259.Jun Xie, Haitao Mi, and Qun Liu.
2011.
A noveldependency-to-string model for statistical machinetranslation.
In Proceedings of EMNLP-2011, pages216?226, Edinburgh, Scotland, UK., July.Hao Zhang, Liang Huang, Kai Zhao, and Ryan Mc-Donald.
2013.
Online learning for inexact hy-pergraph search.
In Proceedings of EMNLP-2013,pages 908?913, Seattle, Washington, USA, October.1348
