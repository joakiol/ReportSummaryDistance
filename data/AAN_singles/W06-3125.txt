Proceedings of the Workshop on Statistical Machine Translation, pages 162?165,New York City, June 2006. c?2006 Association for Computational LinguisticsN-gram-based SMT System Enhanced with Reordering PatternsJosep M. CregoMarta R. Costa-jussa`Jose?
B. Marin?oAdria` de GispertMaxim KhalilovJose?
A. R. FonollosaDepartment of Signal Theory and CommunicationsTALP Research Center (UPC)Barcelona 08034, Spain{jmcrego,agispert,lambert,mruiz,khalilov,rbanchs,canton,adrian}@gps.tsc.upc.eduPatrik LambertRafael E. BanchsAbstractThis work presents translation results forthe three data sets made available in theshared task ?Exploiting Parallel Texts forStatistical Machine Translation?
of theHLT-NAACL 2006 Workshop on Statisti-cal Machine Translation.
All results pre-sented were generated by using the N-gram-based statistical machine translationsystem which has been enhanced from thelast year?s evaluation with a tagged targetlanguage model (using Part-Of-Speechtags).
For both Spanish-English transla-tion directions and the English-to-Frenchtranslation task, the baseline system al-lows for linguistically motivated source-side reorderings.1 IntroductionThe statistical machine translation approach usedin this work implements a log-linear combinationof feature functions along with a translation modelwhich is based on bilingual n-grams (de Gispert andMarin?o, 2002).This translation model differs from the wellknown phrase-based translation approach (Koehnet al, 2003) in two basic issues: first, training datais monotonously segmented into bilingual units; andsecond, the model considers n-gram probabilities in-stead of relative frequencies.
This translation ap-proach is described in detail in (Marin?o et al, 2005).For those translation tasks with Spanish or En-glish as target language, an additional tagged (us-ing POS information) target language model is used.Additionally a reordering strategy that includes POSinformation is described and evaluated.Translation results for all six translation directionsproposed in the shared task are presented and dis-cussed.
Both translation directions are consideredfor the pairs: English-Spanish, English-French,and English-German.The paper is structured as follows: Section 2briefly outlines the baseline system.
Section 3 de-scribes in detail the implemented POS-based re-ordering strategy.
Section 4 presents and discussesthe shared task results and, finally, section 5 presentssome conclusions and further work.2 Baseline N-gram-based SMT SystemAs already mentioned, the translation model usedhere is based on bilingual n-grams.
It actually con-stitutes a language model of bilingual units, referredto as tuples, which approximates the joint probabil-ity between source and target languages by usingbilingual n-grams (de Gispert and Marin?o, 2002).Tuples are extracted from a word-to-word alignedcorpus according to the following two constraints:first, tuple extraction should produce a monotonicsegmentation of bilingual sentence pairs; and sec-ond, no smaller tuples can be extracted without vi-olating the previous constraint.
See (Crego et al,2004) for further details.For all experiments presented here, the translationmodel consisted of a 4-gram language model of tu-ples.
In addition to this bilingual n-gram translationmodel, the baseline system implements a log linearcombination of five feature functions.162These five additional models are:?
A target language model.
5-gram of the targetside of the bilingual corpus.?
A word bonus.
Based on the number of tar-get words in the partial-translation hypothesis,to compensate the LM preference for short sen-tences.?
A Source-to-target lexicon model.
Based onIBM Model 1 lexical parameters(Brown et al,1993), providing a complementary probabilityfor each tuple in the translation table.
Theseparameters are obtained from source-to-targetalignments.?
A Target-to-source lexicon model.
Analo-gous to the previous feature, but obtained fromtarget-to-source alignments.?
A Tagged (POS) target language model.
Thisfeature implements a 5-gram language modelof target POS-tags.
In this case, each trans-lation unit carried the information of its targetside POS-tags, though this is not used for trans-lation model estimation (only in order to eval-uate the target POS language model at decod-ing time).
Due to the non-availability of POS-taggers for French and German, it was not pos-sible to incorporate this feature in all transla-tion tasks considered, being only used for thosetranslation tasks with Spanish and English astarget languages.The search engine for this translation system isdescribed in (Crego et al, 2005) and implementsa beam-search strategy based on dynamic program-ming, taking into account all feature functions de-scribed above, along with the bilingual n-gram trans-lation model.
Monotone search is performed, in-cluding histogram and threshold pruning and hy-pothesis recombination.An optimization tool, which is based on a down-hill simplex method was developed and used forcomputing log-linear weights for each of the featurefunctions.
This algorithm adjusts the weights so thata non-linear combination of BLEU and NIST scoresis maximized over the development set for each ofthe six translation directions considered.This baseline system is actually very similar tothe system used for last year?s shared task ?Exploit-ing Parallel Texts for Statistical Machine Transla-tion?
of ACL?05 Workshop on Building and Us-ing Parallel Texts: Data-Driven Machine Translationand Beyond (Banchs et al, 2005), whose resultsare available at: http://www.statmt.org/wpt05/mt-shared-task/.
A more detailed description ofthe system can be found in (2005).The tools used for POS-tagging were Freel-ing (Carreras et al, 2004) for Spanish andTnT (Brants, 2000) for English.
All language mod-els were estimated using the SRI language mod-eling toolkit.
Word-to-word alignments were ex-tracted with GIZA++.
Improvements in word-to-word alignments were achieved through verb groupclassification as described in (de Gispert, 2005).3 Reordering FrameworkIn this section we outline the reordering frameworkused for the experiments (Crego and Marin?o, 2006).A highly constrained reordered search is performedby means of a set of reordering patterns (linguisti-cally motivated rewrite patterns) which are used toextend the monotone search graph with additionalarcs.To extract patterns, we use the word-to-wordalignments (the union of both alignment directions)and source-side POS tags.
The main procedure con-sists of identifying all crossings produced in theFigure 1: Reordering patterns are extracted usingword-to-word alignments.
The generalization poweris achieved through the POS tags.
Three instances ofdifferent patterns are extracted using the sentencesin the example.163word-to-word alignments.
Once a crossing has beendetected, its source POS tags and alignments areused to account for a new instance of pattern.
Thetarget side of a pattern (source-side positions afterreordering), is computed using the original orderof the target words to which the source words arealigned.
See figure 1 for a clarifying example ofpattern extraction.The monotone search graph is extended with re-orderings following the patterns found in training.The procedure identifies first the sequences of wordsin the input sentence that match any available pat-tern.
Then, each of the matchings implies the ad-dition of an arc into the search graph (encoding thereordering learnt in the pattern).
However, this ad-dition of a new arc is not performed if a translationunit with the same source-side words already existsin the training.
Figure 2 shows an example of theprocedure.Figure 2: Three additional arcs have been addedto the original monotone graph (bold arcs) giventhe reordering patterns found matching any of thesource POS tags sequence.Once the search graph is built, the decoder tra-verses the graph looking for the best translation.Hence, the winner hypothesis is computed usingall the available information (the whole SMT mod-els).
The reordering strategy is additionally sup-ported by a 5-gram language model of reorderedsource POS-tags.
In training, POS-tags are re-ordered according with the extracted reordering pat-terns and word-to-word links.
The resulting se-quence of source POS-tags are used to train the n-gram LM.Notice that this reordering framework has onlybeen used for some translation tasks (Spanish-to-English, English-to-Spanish and English-to-French).
The reason is double: first, because wedid not have available a French POS-tagger.
Second,because the technique used to learn reorderings (de-tailed below) does not seem to apply for languagepairs like German-English, because the agglutina-tive characteristic of German (words are formed byjoining morphemes together).Table 1: BLEU, NIST and mWER scores (com-puted using two reference translations) obtained forboth translation directions (Spanish-to-English andEnglish-to-Spanish).Conf BLEU NIST mWERSpanish-to-Englishbase 55.23 10.69 34.40+rgraph 55.59 10.70 34.23+pos 56.39 10.75 33.75English-to-Spanishbase 48.03 9.84 41.18+rgraph 48.53 9.81 41.15+pos 48.91 9.91 40.29Table 1 shows the improvement of the originalbaseline system described in section 2 (base), en-hanced using reordering graphs (+rgraph) and pro-vided the tagged-source language model (+pos).The experiments in table 1 were not carried out overthe official corpus of this shared task.
The Spanish-English corpus of the TC-Star 2005 Evaluation wasused.
Due to the high similarities between both cor-pus (this shared task corpus consists of a subset ofthe whole corpus used in the TC-Star 2005 Evalua-tion), it makes sense to think that comparable resultswould be obtained.It is worth mentioning that the official corpus ofthe shared task (HLT-NAACL 2006) was used whenbuilding and tuning the present shared task system.4 Shared Task ResultsThe data provided for this shared task correspondsto a subset of the official transcriptions of the Euro-pean Parliament Plenary Sessions.
The developmentset used to tune the system consists of a subset (500first sentences) of the official development set madeavailable for the Shared Task.164Table 2 presents the BLEU, NIST and mWERscores obtained for the development-test data set.The last column shows whether the target POS lan-guage model feature was used or not.
Computedscores are case sensitive and compare to one refer-ence translation.
Tasks in bold were conducted al-lowing for the reordering framework.
For French-to-English task, block reordering strategy was used,which is described in (Costa-jussa` et al, 2006).
As itcan be seen, for the English-to-German task we didnot use any of the previous enhancements.Table 2: Translation resultsTask BLEU NIST mWER tPOSen ?
es 29.50 7.32 58.95 yeses ?
en 30.29 7.51 57.72 yesen ?
fr 30.23 7.40 59.76 nofr ?
en 30.21 7.61 56.97 yesen ?
de 17.40 5.61 71.18 node ?
en 23.78 6.70 65.83 yesImportant differences can be observed betweenthe German-English and the rest of translation tasks.They result from the greater differences in wordorder present in this language pair (the German-English results are obtained under monotone decod-ing conditions).
Also because the greater vocabularyof words of German, which increases sparseness inany task where German is envolved.
As expected,differences in translation accuracy between Spanish-English and French-English are smaller.5 Conclusions and Further WorkAs it can be concluded from the presented results,although in principle some language pairs (Spanish-English-French) seem to have very little need for re-orderings (due to their similar word order), the useof linguistically-based reorderings proves to be use-ful to improve translation accuracy.Additional work is to be conducted to allow forreorderings when translating from/to German.6 AcknowledgmentsThis work was partly funded by the European Unionunder the integrated project TC-STAR1: Technologyand Corpora for Speech to Speech Translation (IST-2002-FP6-506738) and the European Social Fund.1http://www.tc-star.orgReferencesR.
E. Banchs, J. M. Crego, A. de Gispert, P. Lambert, andJ.
B. Marin?o.
2005.
Statistical machine translation ofeuparl data by using bilingual n-grams.
Proc.
of theACL Workshop on Building and Using Parallel Texts(ACL?05/Wkshp), pages 67?72, June.T.
Brants.
2000.
TnT ?
a statistical part-of-speech tag-ger.
In Proc.
of the Sixth Applied Natural LanguageProcessing (ANLP-2000), Seattle, WA.P.
Brown, S. Della Pietra, V. Della Pietra, and R. Mercer.1993.
The mathematics of statistical machine transla-tion.
Computational Linguistics, 19(2):263?311.X.
Carreras, I. Chao, L.
Padro?, and M. Padro?.
2004.Freeling: An open-source suite of language analyzers.4th Int.
Conf.
on Language Resources and Evaluation,LREC?04, May.M.R.
Costa-jussa`, J.M.
Crego, A. de Gispert, P. Lam-bert, M. Khalilov, R. Banchs, J.B. Marin?o, and J.A.R.Fonollosa.
2006.
Talp phrase-based statistical transla-tion system for european language pairs.
Proc.
of theHLT/NAACL Workshop on Statistical Machine Trans-lation, June.J.
M. Crego and J. Marin?o.
2006.
A reordering frame-work for statistical machine translation.
Internal Re-port.J.
M. Crego, J. Marin?o, and A. de Gispert.
2004.
Finite-state-based and phrase-based statistical machine trans-lation.
Proc.
of the 8th Int.
Conf.
on Spoken LanguageProcessing, ICSLP?04, pages 37?40, October.J.
M. Crego, J. Marin?o, and A. Gispert.
2005.
An ngram-based statistical machine translation decoder.
Proc.
ofthe 9th European Conference on Speech Communica-tion and Technology, Interspeech?05, September.A.
de Gispert and J. Marin?o.
2002.
Using X-gramsfor speech-to-speech translation.
Proc.
of the 7thInt.
Conf.
on Spoken Language Processing, ICSLP?02,September.A.
de Gispert.
2005.
Phrase linguistic classification andgeneralization for improving statistical machine trans-lation.
Proc.
of the ACL Student Research Workshop(ACL?05/SRW), June.P.
Koehn, F.J. Och, and D. Marcu.
2003.
Statisti-cal phrase-based translation.
Proc.
of the HumanLanguage Technology Conference, HLT-NAACL?2003,May.J.B.
Marin?o, R Banchs, J.M.
Crego, A. de Gispert,P.
Lambert, M. R. Costa-jussa`, and J.A.R.
Fonollosa.2005.
Bilingual n?gram statistical machine transla-tion.
Proc.
of the MT Summit X, September.165
