Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 309?314,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsVector spaces for historical linguistics: Using distributional semantics tostudy syntactic productivity in diachronyFlorent PerekPrinceton UniversityPrinceton, NJ, USAfperek@princeton.eduAbstractThis paper describes an application of dis-tributional semantics to the study of syn-tactic productivity in diachrony, i.e., theproperty of grammatical constructions toattract new lexical items over time.
Byproviding an empirical measure of seman-tic similarity between words derived fromlexical co-occurrences, distributional se-mantics not only reliably captures how theverbs in the distribution of a construc-tion are related, but also enables the useof visualization techniques and statisticalmodeling to analyze the semantic develop-ment of a construction over time and iden-tify the semantic determinants of syntacticproductivity in naturally occurring data.1 IntroductionLanguage change does not exclusively consist ofdrastic shifts in ?core?
aspects of grammar, such aschanges in word order.
Variation in usage, whichcan occur in no more than a few decades, is muchmore common, and to many linguists constituteslinguistic change in the making.
Among these as-pects of language use that are subject to diachronicchange, this paper is concerned with the productiv-ity of syntactic constructions, i.e., the range of lex-ical items with which a construction can be used.A given construction might occur with very differ-ent distributions at different points in time, evenwhen the function it conveys remains the same.This is what Israel (1996) finds for the pattern?Verb one?s way Path?, commonly called the way-construction (Goldberg, 1995), exemplified by (1)and (2) below.
(1) They hacked their way through the jungle.
(2) She typed her way to a promotion.As reported by Israel, examples like (1), inwhich the main verb describes the physical meanswhereby motion towards a goal is enabled, are at-tested as early as the 16thcentury, but it was notuntil the 19thcentury that examples like (2) startedto appear, in which the action depicted by the verbprovides a more indirect (and abstract) way of at-taining the agent?s goal.The productivity of a construction may appearpartly arbitrary, but a growing body of evidencesuggests that it is tied to the previous experienceof speakers with that construction (Bar?dal, 2008;Bybee and Eddington, 2006; Suttle and Goldberg,2011).
More specifically, previous research pointsto a strong semantic component, in that the pos-sibility of a novel use depends on how it seman-tically relates to prior usage.
Along these lines,Suttle and Goldberg (2011, 1254) posit a criterionof coverage, defined as ?the degree to which at-tested instances ?cover?
the category determinedjointly by attested instances together with the tar-get coinage?.
Coverage relates to how the seman-tic domain of a construction is populated in thevicinity of a given target coinage, and in particularto the density of the semantic space.The importance of semantics for syntactic pro-ductivity implies that the meaning of lexical itemsmust be appropriately taken into account whenstudying the distribution of constructions, whichcalls for an empirical operationalization of seman-tics.
Most existing studies rely either on the se-mantic intuitions of the analyst, or on semanticnorming studies (Bybee and Eddington, 2006).
Inthis paper, I present a third alternative that takesadvantage of advances in computational linguis-tics and draws on a distributionally-based measureof semantic similarity.
On the basis of a case studyof the construction ?V the hell out of NP?, I showhow distributional semantics can profitably be ap-plied to the study of syntactic productivity.3092 The hell-constructionThe case study presented in this paper considersthe syntactic pattern ?V the hell out of NP?, as ex-emplified by the following sentences from the Cor-pus of Contemporary American English (COCA;Davies, 2008):(3) Snakes just scare the hell out of me.
(4) It surprised the hell out of me when I heardwhat he?s been accused of.
(5) You might kick the hell out of me like youdid that doctor.The construction generally conveys an in-tensifying function (very broadly defined).Thus, scare/surprise the hell out of means?scare/surprise very much?, and kick the hell outof means ?kick very hard?.
The particular aspectthat is intensified may be highly specific to theverb and depend to some extent on the context.Scare and beat are the most typical verbs in thatconstruction (and arguably the two that first cometo mind), but a wide and diverse range of otherverbs can also be found, such that avoid in (6),drive (a car) in (7) and even an intransitive verb(listen) in (8):(6) I [...] avoided the hell out of his presence.
(7) But you drove the hell out of it!
(8) I?ve been listening the hell out of your tape.To examine how the construction evolved overtime, I used diachronic data from the Corpusof Historical American English (COHA; Davies2010), which contains about 20 million wordsof written American English for each decade be-tween 1810 and 2009 roughly balanced for genre(fiction, magazines, newspapers, non-fiction).
In-stances of the hell-construction were filtered outmanually from the results of the query ?
[v*] thehell out of?, mostly ruling out locative construc-tions like get the hell out of here.
The diachronicevolution of the verb slot in terms of token andtype frequency is plotted in Figure 1.
Since thecorpus size varies slightly in each decade, the to-ken frequencies are normalized per million words.The construction is first attested in the corpusin the 1930s.
Since then, it has been steadily in-creasing in token frequency (to the exception ofa sudden decrease in the 1990s).
Also, more andmore different verbs are attested in the construc-tion, as shown by the increase in type frequency.ll ll llll1930 1940 1950 1960 1970 1980 1990 2000 201001234Tokensper millionwordslll llll01020304050TypesToken frequency (per million words)Type frequencyFigure 1: Diachronic development of the hell-construction in terms of normalized token fre-quency and type frequencyThis reflects a general expansion of the productiv-ity of the construction, but it does not show whatthis productivity consists of.
For instance, it doesnot say what kinds of verbs joined the distribu-tion and to what extent the distribution becomessemantically more diverse over time.
To answerthese questions, I will analyze the distribution ofthe construction from a semantic point of viewby using a measure of semantic similarity derivedfrom distributional information.3 Distributional measure of semanticsimilarityDrawing on the observation that words occurringin similar contexts tend to have related mean-ings (Miller and Charles, 1991), distributional ap-proaches to semantics seek to capture the mean-ing of words through their distribution in large textcorpora (Lenci, 2008; Turney and Pantel, 2010;Erk, 2012).
One benefit of the distributional se-mantics approach is that it allows semantic sim-ilarity between words to be quantified by mea-suring the similarity in their distribution.
This isachieved by means of a vector-space model thatassigns an array of numerical values (i.e., a vector)derived from distributional information to eachword.
A wide range of distributional informa-tion can be employed in vector-based models; thepresent study uses the ?bag of words?
approach,which is based on the frequency of co-occurrenceof words within a given context window.
Accord-ing to Sahlgren (2008), this kind of model cap-tures to what extent words can be substituted foreach other, which is a good measure of semanticsimilarity between verbs.
As it turns out, even this310relatively coarse model captures semantic distinc-tions in the distribution of the hell-constructionthat make intuitive sense.All instances of the relevant verbs were ex-tracted from the COCA1with their context of oc-currence.
In order to make sure that enough dis-tributional information is available to reliably as-sess semantic similarity, verbs with less than 2,000occurrences were excluded, which left 92 usableitems (out of 105).
The words in the sentence con-texts extracted from the COCA were lemmatizedand annotated for part-of-speech using TreeTag-ger (Schmid, 1994).
The part-of-speech annotatedlemma of each collocate within a 5-word windowwas extracted from the COCA data to build the co-occurrence matrix recording the frequency of co-occurrence of each verb with its collocates.
Onlythe nouns, verbs, adjectives, and adverbs listedamong the 5,000 most frequent words in the cor-pus were considered (to the exclusion of be, have,and do), thus ignoring function words (articles,prepositions, conjunctions, etc.)
and all words thatdid not make the top 5,000.The co-occurrence matrix was transformed byapplying a Point-wise Mutual Information weight-ing scheme, using the DISSECT toolkit (Dinu etal., 2013), to turn the raw frequencies into weightsthat reflect how distinctive a collocate is for agiven target word with respect to the other tar-get words under consideration.
The resulting ma-trix, which contains the distributional information(in 4,683 columns) for 92 verbs occurring in thehell-construction, constitutes the semantic spaceunder consideration in this case study.
Pairwisedistances between the target verbs were calculatedusing the cosine distance.
The rest of the analysiswas conducted on the basis of this distance matrixin the R environment (R Development Core Team,2013).1The COCA contains 464 million words of American En-glish consisting of the same amount of spoken, fiction, mag-azine, newspaper, and academic prose data for each yearbetween 1990 and 2012.
Admittedly, a more ecologicallyvalid choice would have been to use data from a particulartime frame to build a vector-space model for the same timeframe, but even the twenty-odd million words per decade ofthe COHA did not prove sufficient to achieve that purpose.This is, however, not as problematic as it might sound, sincethe meaning of the verbs under consideration are not likelyto have changed considerably within the time frame of thisstudy.
Besides, using the same data presents the advantagethat the distribution is modeled with the same semantic spacein all time periods, which makes it easier to visualize changes.4 Application of the vector-space model4.1 Semantic plotsOne of the advantages conferred by the quantifi-cation of semantic similarity is that lexical itemscan be precisely considered in relation to eachother, and by aggregating the similarity informa-tion for all items in the distribution, we can pro-duce a visual representation of the structure ofthe semantic domain of the construction in orderto observe how verbs in that domain are relatedto each other, and to immediately identify the re-gions of the semantic space that are densely pop-ulated (with tight clusters of verbs), and those thatare more sparsely populated (fewer and/or morescattered verbs).
Multidimensional scaling (MDS)provides a way both to aggregate similarity infor-mation and to represent it visually.
This techniqueaims to place objects in a space with two (or more)dimensions such that the between-object distancesare preserved as much as possible.The pairwise distances between verbs were sub-mitted to multidimensional scaling into two di-mensions.2To visualize the semantic developmentof the hell-construction over time, the diachronicdata was divided into four successive twenty-yearperiods: 1930-1949, 1950-1969, 1970-1989, and1990-2009.
The semantic plots corresponding tothe distribution of the construction in each periodare presented in Figure 2.
For convenience andease of visualization, the verbs are color-codedaccording to four broad semantic groupings thatwere identified inductively by means of hierarchi-cal clustering (using Ward?s criterion).3By comparing the plots in Figure 2, we canfollow the semantic development of the hell-construction.
The construction is strikingly cen-tered around two kinds of verbs: mental verbs (inred: surprise, please, scare, etc.)
and verbs ofhitting (most verbs in green: smash, kick, whack,etc.
), a group that is orbited by other kinds offorceful actions (such as pinch, push, and tear).These two types of verbs account for most ofthe distribution at the onset, and they continue to2Non-metric MDS was employed (Kruskal, 1964), usingthe function isoMDS from the R package MASS.3Another benefit of combining clustering and MDS stemsfrom the fact that the latter often distorts the data when fittingthe objects into two dimensions, in that some objects mighthave to be slightly misplaced if not all distance relations canbe simultaneously complied with.
Since cluster analysis op-erates with all 4,683 dimensions of the distributional space, itis more reliable than MDS, although it lacks the visual appealof the latter.3111930s ?
1940sxllbeatborebotherchaseeatkickknocklicklovepleasescareshootsmashsurprisetearwantwhipworkworry1950s ?
1960sxlll lllarguebangbeatbombboredepressembarrassflatterfoolfrightenfrustratehateimpressirritatekickkillknockloveneed panpuzzlerelaxscaresellshocksqueezestunsuesurpriseunderstand whackworry1970s ?
1980sxllllllll llactadmireadoreamuseanalyzeannoyavoidbeatbombbotherbribe driveembarrassentertainexploit flyfrighten hanghitimpresskickknocklikeplaypuzzlerackresentrubscarescratchscrubsellshockshootstartlesurprisetearthrash whackwhip1990s ?
2000slllllllllllllllllladoreanalyzeannoybangbeatblastblowbombborebother bugcarecomplicateconfusecutdepressdisappointeatembarrassenjoyexcuseexplainfascinateflatterfrightenfrustrateimpressintimidateirritatekickkillknocklovepinchpoundpushrespectscaresellshockshootsingslamslapslicespoilsqueezesuesurprisetormenttrashtwistwearwhackworkworryFigure 2: Semantic plots of the hell-constructionin four time periods.weigh heavily throughout the history of the con-struction.
These two classes also correspond tothe regions of the semantic domain that attract themost new members, and they constantly do so inall periods.
Outside of these two clusters, the se-mantic space is much more sparsely populated.
Inthe first period (1930-1949), only a few peripheralmembers are found.
They are joined by other dis-tantly related items in later periods, although by nomore than a handful in each.
In other words, theconstruction is markedly less productive in theseouter domains, which never form proper clustersof verbs.In sum, the semantic plots show that denselypopulated regions of the semantic space appear tobe the most likely to attract new members.
Out-side of the two identified domains of predilection,other classes never become important, assumedlybecause they do not receive a ?critical mass?
ofitems, and therefore attract new members moreslowly.4.2 Statistical analysisWith the quantification of semantic similarity pro-vided by the distributional semantic model, it isalso possible to properly test the hypothesis thatproductivity is tied to the structure of the seman-tic space.
On the reasonable assumption that thesemantic contribution of the construction did notchange, and therefore that all verbs ever attestedin it are equally plausible from a semantic pointof view, the fact that some verbs joined the dis-tribution later than others is in want of an expla-nation.
In view of the observations collected onthe semantic plots and in line with previous re-search (especially Suttle and Goldberg?s notion ofcoverage), I suggest that the occurrence of a newitem in the construction in a given period is relatedto the density of the semantic space around thatitem in the previous period.
If the semantic spacearound the novel item is dense, i.e., if there is ahigh number of similar items, the coinage will bevery likely.
The sparser the semantic space arounda given item, the less likely this item can be used.The measure of density used in this study con-siders the set of the N nearest neighbors of a givenitem in the semantic space, and is defined by thefollowing formula:DensityV,N= 1?
?Nn=1d(V, Vn)Nwhere d(V, Vn) is the distance between a verb V312and its nthnearest neighbor.
In plain language,density equals one minus the mean distance to theN nearest neighbors.
The latter value decreaseswith space density (i.e., if there are many closeneighbors), and is therefore technically a measureof sparsity; since cosine distances are between 0and 1, subtracting the mean distance from one re-turns a measure of density within the same bound-aries.This measure of density was used as a factor inlogistic regression to predict the first occurrenceof a verb in the construction, coded as the binaryvariable OCCURRENCE, set to 1 for the first pe-riod in which the verb is attested in the construc-tion, and to 0 for all preceding periods (later pe-riods were discarded).
For each VERB-PERIOD-OCCURRENCE triplet, the density of the semanticspace around the verb in the immediately preced-ing period was calculated.
Six different versionsof the density measure, with the number of neigh-bors under consideration (N) varying between 3and 8, were used to fit six mixed effects regres-sion models with OCCURRENCE as the dependentvariable, DENSITY as a fixed effect, and randomby-verb intercepts and slopes (Bates et al, 2011).The results of these models are summarized in Ta-ble 1.N Effect of DENSITY p-value3 0.7211 0.1954 0.8836 0.1355 1.0487 0.091 (.
)6 1.2367 0.056 (.
)7 1.4219 0.034 (*)8 1.6625 0.017 (*)Table 1: Summary of logistic regression resultsfor different values of N. Model formula: OC-CURRENCE ?
DENSITY + (1 + DENSITY|VERB).Marginally significant effects are marked with aperiod (.
), significant effects with a star (*).For all values of N, we find a positive effect ofDENSITY, i.e., there is a positive relation betweenthe measure of density and the probability of firstoccurrence of a verb in the construction.
However,the effect is only significant for N ?
7; hence, thehypothesis that space density increases the odds ofa coinage occurs in the construction is supportedfor measures of density based on these values ofN.More generally, the p-value decreases as N in-creases, which means that the positive relation be-tween DENSITY and OCCURRENCE is less sys-tematic when DENSITY is measured with fewerneighbors.
This is arguably because a higher Nhelps to better discriminate between dense clusterswhere all items are close together from looser onesthat consist of a few ?core?
items surrounded bymore distant neighbors.
This result illustrates therole of type frequency in syntactic productivity: ameasure of density that is supported by a highernumber of types makes better prediction than ameasure supported by fewer types.
This meansthat productivity not only hinges on how the exist-ing semantic space relates to the novel item, it alsooccurs more reliably when this relation is attestedby more items.
These finding support the viewthat semantic density and type frequency, whilethey both positively influence syntactic productiv-ity, do so in different ways: density defines thenecessary conditions for a new coinage to occur,while type frequency increases the confidence thatthis coinage is indeed possible.5 ConclusionThis paper reports the first attempt at using a dis-tributional measure of semantic similarity derivedfrom a vector-space model for the study of syn-tactic productivity in diachrony.
On the basis ofa case study of the construction ?V the hell outof NP?
from 1930 to 2009, the advantages of thisapproach were demonstrated.
Not only does dis-tributional semantics provide an empirically-basedmeasure of semantic similarity that appropriatelycaptures semantic distinctions, it also enables theuse of methods for which quantification is neces-sary, such as data visualization and statistical anal-ysis.
Using multidimensional scaling and logis-tic regression, it was shown that the occurrenceof new items throughout the history of the con-struction can be predicted by the density of the se-mantic space in the neighborhood of these itemsin prior usage.
In conclusion, this work opens newperspectives for the study of syntactic productivityin line with the growing synergy between compu-tational linguistics and other fields.ReferencesJohana Bar?dal.
2008.
Productivity: Evidence fromCase and Argument Structure in Icelandic.
JohnBenjamins, Amsterdam.313Douglas Bates, Martin Maechler, Ben Bolker andSteven Walker.
2011. lme4: Linear mixed-effects models using S4 classes.
R package.
URL:http://CRAN.R-project.org/package=lme4Joan Bybee.
2010.
Language, Usage and Cognition.Cambridge University Press, Cambridge.Joan Bybee and David Eddington.
2006.
A usage-based approach to Spanish verbs of ?becoming?.Language, 82(2):323?355.Mark Davies.
2008.
The Corpus of ContemporaryAmerican English: 450 million words, 1990-present.Available online at http://corpus.byu.edu/coca/Mark Davies.
2010.
The Corpus of Historical Ameri-can English: 400 million words, 1810-2009.
Avail-able online at http://corpus.byu.edu/coha/Georgiana Dinu, The Nghia Pham and Marco Baroni.2013.
DISSECT: DIStributional SEmantics Compo-sition Toolkit.
In Proceedings of the System Demon-strations of ACL 2013 (51st Annual Meeting of theAssociation for Computational Linguistics).Katrin Erk.
2012.
Vector Space Models of WordMeaning and Phrase Meaning: A Survey.
Languageand Linguistics Compass, 6(10):635?653.Adele Goldberg.
1995.
Constructions: A constructiongrammar approach to argument structure.
Univer-sity of Chicago Press, Chicago.Michael Israel.
1996.
The way constructions grow.
InAdele E. Goldberg (ed.
), Conceptual structure, dis-course and language, pages 217?230.
CSLI Publi-cations, Stanford, CA.Joseph Kruskal.
1964.
Multidimensional scaling byoptimizing goodness of fit to a nonmetric hypothe-sis.
Psychometrika, 29(1):1?27.Alessandro Lenci.
2008.
Distributional semantics inlinguistic and cognitive research.
Rivista di Linguis-tica, 20(1):1?31.George Miller and Walter Charles.
1991.
Contex-tual correlates of semantic similarity.
Language andCognitive Processes, 6(1):1?28.R Development Core Team.
2013.
R: A languageand environment for statistical computing.
R Foun-dation for Statistical Computing, Vienna; URL:http://www.R-project.org/Magnus Sahlgren.
2008.
The distributional hypothe-sis.
Rivista di Linguistica, 20(1):33?53.Helmut Schmid.
1994.
Probabilistic Part-of-SpeechTagging Using Decision Trees.
In Proceedings ofInternational Conference on New Methods in Lan-guage Processing, Manchester, UK.Laura Suttle and Adele Goldberg.
2011.
The partialproductivity of constructions as induction.
Linguis-tics, 49(6):1237?1269.Peter Turney and Patrick Pantel.
2010.
From Fre-quency to Meaning: Vector Space Models of Se-mantics.
Journal of Artificial Intelligence Research,37:141?188.314
