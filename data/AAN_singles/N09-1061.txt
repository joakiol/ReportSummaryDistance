Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 539?547,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsOptimal Reduction of Rule Lengthin Linear Context-Free Rewriting SystemsCarlos Go?mez-Rodr?
?guez1, Marco Kuhlmann2, Giorgio Satta3 and David Weir41 Departamento de Computacio?n, Universidade da Corun?a, Spain (cgomezr@udc.es)2 Department of Linguistics and Philology, Uppsala University, Sweden (marco.kuhlmann@lingfil.uu.se)3 Department of Information Engineering, University of Padua, Italy (satta@dei.unipd.it)4 Department of Informatics, University of Sussex, United Kingdom (davidw@sussex.ac.uk)AbstractLinear Context-free Rewriting Systems(LCFRS) is an expressive grammar formalismwith applications in syntax-based machinetranslation.
The parsing complexity of anLCFRS is exponential in both the rankof a production, defined as the number ofnonterminals on its right-hand side, and ameasure for the discontinuity of a phrase,called fan-out.
In this paper, we presentan algorithm that transforms an LCFRSinto a strongly equivalent form in whichall productions have rank at most 2, andhas minimal fan-out.
Our results generalizeprevious work on Synchronous Context-FreeGrammar, and are particularly relevant formachine translation from or to languages thatrequire syntactic analyses with discontinuousconstituents.1 IntroductionThere is currently considerable interest in syntax-based models for statistical machine translation thatare based on the extraction of a synchronous gram-mar from a corpus of word-aligned parallel texts;see for instance Chiang (2007) and the referencestherein.
One practical problem with this approach,apart from the sheer number of the rules that resultfrom the extraction procedure, is that the parsingcomplexity of all synchronous formalisms that weare aware of is exponential in the rank of a rule,defined as the number of nonterminals on the right-hand side.
Therefore, it is important that the rulesof the extracted grammar are transformed so as tominimise this quantity.
Not only is this beneficial interms of parsing complexity, but smaller rules canalso improve a translation model?s ability to gener-alize to new data (Zhang et al, 2006).Optimal algorithms exist for minimising the sizeof rules in a Synchronous Context-Free Gram-mar (SCFG) (Uno and Yagiura, 2000; Zhang et al,2008).
However, the SCFG formalism is limitedto modelling word-to-word alignments in which asingle continuous phrase in the source language isaligned with a single continuous phrase in the tar-get language; as defined below, this amounts tosaying that SCFG have a fan-out of 2.
This re-striction appears to render SCFG empirically inad-equate.
In particular, Wellington et al (2006) findthat the coverage of a translation model can increasedramatically when one allows a bilingual phrase tostretch out over three rather than two continuoussubstrings.
This observation is in line with empir-ical studies in the context of dependency parsing,where the need for formalisms with higher fan-outhas been observed even in standard, single languagetexts (Kuhlmann and Nivre, 2006).In this paper, we present an algorithm that com-putes optimal decompositions of rules in the for-malism of Linear Context-Free Rewriting Systems(LCFRS) (Vijay-Shanker et al, 1987).
LCFRS wasoriginally introduced as a generalization of sev-eral so-called mildly context-sensitive grammar for-malisms.
In the context of machine translation,LCFRS is an interesting generalization of SCFG be-cause it does not restrict the fan-out to 2, allow-ing productions with arbitrary fan-out (and arbitraryrank).
Given an LCFRS, our algorithm computes astrongly equivalent grammar with rank 2 and min-539imal increase in fan-out.1 In this context, strongequivalence means that the derivations of the orig-inal grammar can be reconstructed using some sim-ple homomorphism (c.f.
Nijholt, 1980).
Our contri-bution is significant because the existing algorithmsfor decomposing SCFG, based on Uno and Yagiura(2000), cannot be applied to LCFRS, as they relyon the crucial property that components of biphrasesare strictly separated in the generated string: Given apair of synchronized nonterminal symbols, the ma-terial derived from the source nonterminal must pre-cede the material derived from the target nontermi-nal, or vice versa.
The problem that we solve hasbeen previously addressed by Melamed et al (2004),but in contrast to our result, their algorithm does notguarantee an optimal (minimal) increase in the fan-out of the resulting grammar.
However, this is essen-tial for the practical applicability of the transformedgrammar, as the parsing complexity of LCFRS is ex-ponential in both the rank and the fan-out.Structure of the paper The remainder of the pa-per is structured as follows.
Section 2 introduces theterminology and notation that we use for LCFRS.In Section 3, we present the technical backgroundof our algorithm; the algorithm itself is discussedin Section 4.
Section 5 concludes the paper by dis-cussing related work and open problems.General notation The set of non-negative integersis denoted by N. For i, j ?
N, we write [i, j] todenote the interval { k ?
N | i ?
k ?
j }, and use[i] as a shorthand for [1, i].
Given an alphabet V , wewrite V ?
for the set of all (finite) strings over V .2 PreliminariesWe briefly summarize the terminology and notationthat we adopt for LCFRS; for detailed definitions,see Vijay-Shanker et al (1987).2.1 Linear, non-erasing functionsLet V be an alphabet.
For natural numbers r ?
0and f, f1, .
.
.
, fr ?
1, a functiong : (V ?
)f1 ?
?
?
?
?
(V ?
)fr ?
(V ?
)f1Rambow and Satta (1999) show that without increasingfan-out it is not always possible to produce even weakly equiv-alent grammars.is called a linear, non-erasing function over V oftype f1 ?
?
?
?
?
fr ?
f , if it can be defined by anequation of the formg(?x1,1, .
.
.
, x1,f1?, .
.
.
, ?xr,1, .
.
.
, xr,fr?)
= ?g ,where ?g = ?
?g,1, .
.
.
, ?g,f ?
is an f -tuple of stringsover the variables on the left-hand side of the equa-tion and symbols in V that contains exactly one oc-currence of each variable.
We call the value r therank of g, the value f its fan-out, and write ?
(g)and ?
(g), respectively, to denote these quantities.Note that, if we assume the variables on the left-hand side of the defining equation of g to be namedaccording to the specific schema given above, then gis uniquely determined by ?g.2.2 Linear context-free rewriting systemsA linear context-free rewriting system (LCFRS)is a construct G = (VN , VT , P, S), where: VN isan alphabet of nonterminal symbols in which eachsymbol A ?
VN is associated with a value ?
(A),called its fan-out; VT is an alphabet of terminalsymbols; S ?
N is a distinguished start symbol with?
(S) = 1; and P is a set of productions of the formp : A?
g(B1, B2, .
.
.
, Br) ,where A,B1, .
.
.
, Br ?
VN , and g is a linear, non-erasing function over the terminal alphabet VT oftype ?
(B1) ?
?
?
?
?
?
(Br) ?
?(A).
In a deriva-tion of an LCFRS, the production p can be used totransform a sequence of r tuples of strings, gener-ated by the nonterminals B1, .
.
.
, Br, into a single?
(A)-tuple of strings, associated with the nonter-minal A.
The values ?
(g) and ?
(g) are called therank and fan-out of p, respectively, and we write?
(p) and ?
(p), respectively, to denote these quan-tities.
The rank and fan-out of G, written ?
(G)and ?
(G), respectively, are the maximum rank andfan-out among all of its productions.
Given that?
(S) = 1, a derivation will associate S with a set ofone-component tuples of strings over VT ; this formsthe string language generated by G.Example 1 The following LCFRS generates thestring language { anbncndn | n ?
N }.
We onlyspecify the set of productions; the remaining com-540ponents of the grammar are obvious from that.S ?
g1(R) g1(?x1,1, x1,2?)
= ?x1,1x1,2?R?
g2(R) g2(?x1,1, x1,2?)
= ?ax1,1b, cx1,2d?R?
g3 g3 = ?
?, ?
?The functions g1 and g2 have rank 1; the function g3has rank 0.
The functions g2 and g3 have fan-out 2;the function g1 has fan-out 1.
23 Technical backgroundThe general idea behind our algorithm is to replaceeach production of an LCFRS with a set of ?shorter?productions that jointly are equivalent to the originalproduction.
Before formalizing this idea, we first in-troduce a specialized representation for the produc-tions of an LCFRS.We distinguish between occurrences of symbolswithin a string by exploiting two different notations.Let ?
= a1a2 ?
?
?
an be a string.
The occurrence aiin ?
can be denoted by means of its position indexi ?
[n], or else by means of its two (left and right)endpoints, i?1 and i; here, the left (right) endpointdenotes a boundary between occurrence ai and theprevious (subsequent) occurrence, or the beginning(end) of the string ?.
Similarly, a substring ai ?
?
?
ajof ?
with i ?
j can be denoted by the positionsi, i+ 1, .
.
.
, j of its occurrences, or else by means ofits left and right endpoints, i?
1 and j.3.1 Production representationFor the remainder of this section, let us fix anLCFRS G = (VN , VT , P, S) and a productionp : A ?
g(B1, .
.
.
, Br) of G, with g defined asin Section 2.1.
We define|p| = ?
(g) +?
(g)?i=1|?g,i|.Let $ be a fresh symbol that does not occur inG.
Wedefine the characteristic string of the production pas?
(p) = ?g,1$ ?
?
?
$?g,?
(g) ,and the variable string of p as the string ?N (p) ob-tained from ?
(p) by removing all the occurrences ofsymbols in VT .Example 2 We will illustrate the concepts intro-duced in this section using the concrete productionp0 : A?
g(B1, B2, B3), where?g = ?x1,1ax2,1x1,2, x3,1bx3,2?
.In this case, we have?
(p0) = x1,1ax2,1x1,2$x3,1bx3,2 , and?N (p0) = x1,1x2,1x1,2$x3,1x3,2 .
2Let I be an index set, I ?
[r].
Consider the set B ofoccurrences Bi in the right-hand side of p such thati ?
I .2 We define the position set of B, denotedby ?B, as the set of all positions 1 ?
j ?
|?N (p)|such that the jth symbol in ?N (p) is a variable of theform xi,h, for i ?
I and some h ?
1.Example 3 Some position sets of p0 are?
{B1} = {1, 3} ,?
{B2} = {2} ,?
{B3} = {5, 6} .2A position set ?B can be uniquely expressed as theunion of f ?
1 intervals [l1 + 1, r1], .
.
.
, [lf + 1, rf ]such that ri?1 < li for every 1 < i ?
f .
Thus wedefine the set of endpoints of ?B as?B = { lj | j ?
[f ] } ?
{ rj | j ?
[f ] } .The quantity f is called the fan-out of ?B, writ-ten ?(?B).
Notice that the fan-out of a position set?
{B} does not necessarily coincide with the fan-outof the non-terminal B in the underlying LCFRS.
Aset with 2f endpoints always corresponds to a posi-tion set of fan-out f .Example 4 For our running example, we have?
{B1} = {0, 1, 2, 3}, ?
{B2} = {1, 2}, ?
{B3} ={4, 6}.
Consequently, the fan-out of ?
{B1} is 2, andthe fan-out of ?
{B2} and ?
{B3} is 1.
Notice that thefan-out of the non-terminal B3 is 2.
2We drop B from ?B and ?B whenever this set isunderstood from the context or it is not relevant.Given a set of endpoints ?
= {i1, .
.
.
, i2f} withi1 < ?
?
?
< i2f , we obtain its corresponding positionset by calculating the closure of ?, defined as[?]
= ?fj=1[i2j?1 + 1, i2j ] .2To avoid clutter in our examples, we abuse the notation bynot making an explicit distinction between nonterminals and oc-currences of nonterminals in productions.5413.2 ReductionsAssume that r > 2.
The reduction of p by the non-terminal occurrencesBr?1, Br is the ordered pair ofproductions (p1, p2) that is defined as follows.
Let?1, .
.
.
, ?n be the maximal substrings of ?
(p) thatcontain only variables xi,j with r ?
1 ?
i ?
r andterminal symbols, and at least one variable.
Thenp1 : A?
g1(B1, .
.
.
, Br?2, X) andp2 : X ?
g2(Br?1, Br) ,where X is a fresh nonterminal symbol, the char-acteristic string ?
(p1) is the string obtained from?
(p) by replacing each substring ?i by the vari-able xr?1,i, and the characteristic string ?
(p2) is thestring ?1$ ?
?
?
$?n.Note that the defining equations of neither g1nor g2 are in the specific form discussed in Sec-tion 2.1; however, they can be brought into this formby a consistent renaming of the variables.
We willsilently assume this renaming to take place.Example 5 The reduction of p0 by the nonterminaloccurrences B2 and B3 has p1 : A ?
g1(B1, X)and p2 : X ?
g2(B2, B3) with?
(p1) = x1,1x2,1x1,2$x2,2?
(p2) = ax2,1$x3,1bx3,2or, after renaming and in standard notation,g1(?x1,1, x1,2?, ?x2,1, x2,2?)
= ?x1,1x2,1x1,2, x2,2?g2(?x1,1?, ?x2,1, x2,2?)
= ?ax1,1, x2,1bx2,2?
.2It is easy to check that a reduction provides us with apair of productions that are equivalent to the originalproduction p, in terms of generative capacity, sinceg1(B1, .
.
.
, Br?2, g2(Br?1, Br)) = g(B1, .
.
.
, Br)for all tuples of strings generated from the nontermi-nalsB1, .
.
.
, Br, respectively.
Note also that the fan-out of production p1 equals the fan-out of p. How-ever, the fan-out of p2 (the value n) may be greaterthan the fan-out of p, depending on the way vari-ables are arranged in ?(p).
Thus, a reduction doesnot necessarily preserve the fan-out of the originalproduction.
In the worst case, the fan-out of p2 canbe as large as ?
(Br?1) + ?
(Br).1: Function NAIVE-BINARIZATION(p)2: result?
?
;3: currentProd?
p;4: while ?
(currentProd) > 2 do5: (p1, p2)?
any reduction of currentProd;6: result?
result ?
p2;7: currentProd?
p1;8: return result ?
currentProd;Figure 1: The naive algorithmWe have defined reductions only for the last twooccurrences of nonterminals in the right-hand side ofa production p. However, it is easy to see that we canalso define the concept for two arbitrary (not neces-sarily adjacent) occurrences of nonterminals, at thecost of making the notation more complicated.4 The algorithmLet G be an LCFRS with ?
(G) = f and ?
(G) = r,and let f ?
?
f be a target fan-out.
We will nowpresent an algorithm that computes an equivalentLCFRS G?
of fan-out at most f ?
whose rank is atmost 2, if such an LCFRS exists in the first place.The algorithm works by exhaustively reducing allproductions in G.4.1 Naive algorithmGiven an LCFRS production p, a naive algorithmto compute an equivalent set of productions whoserank is at most 2 is given in Figure 1.
By ap-plying this algorithm to all the productions in theLCFRSG, we can obtain an equivalent LCFRS withrank 2.
We will call such an LCFRS a binarizationof G.The fan-out of the obtained LCFRS will dependon the nonterminals that we choose for the reduc-tions in line 5.
It is not difficult to see that, in theworst case, the resulting fan-out can be as high asd r2e ?
f .
This occurs when we choose d r2e nonter-minals with fan-out f that have associated variablesin the string ?N (p) that do not occur at consecutivepositions.The algorithm that we develop in Section 4.3 im-proves on the naive algorithm in that it can be ex-ploited to find a sequence of reductions that resultsin a binarization of G that is optimal, i.e., leads to542an LCFRS with minimal fan-out.
The algorithm isbased on a technical concept called adjacency.4.2 AdjacencyLet p be some production in the LCFRS G, and let?1,?2 be sets of endpoints, associated with somesets of nonterminal occurrences in p. We say that?1and ?2 overlap if the intersection of their closuresis nonempty, that is, if [?1]?
[?2] 6= ?.
Overlappingholds if and only if the associated sets of nontermi-nal occurrences are not disjoint.
If ?1 and ?2 donot overlap, we define their merge as?
(?1,?2) = (?1 ?
?2) \ (?1 ?
?2) .It is easy to see that [?
(?1,?2)] = [?1] ?
[?2].We say that ?1 and ?2 are adjacent for a given fan-out f , written ?1 ?f ?2, if ?1 and ?2 do notoverlap, and ?([?
(?1,?2)]) ?
f .Example 6 For the production p0 from Example 2,we have ?(?{B1},?
{B2}) = {0, 3}, showing that?
{B1} ?1 ?{B2}.
Similarly, we have?(?{B1},?
{B3}) = {0, 1, 2, 3, 4, 6} ,showing that ?
{B1} ?3 ?
{B3}, but that neither?
{B1} ?2 ?
{B3} nor ?
{B1} ?1 ?
{B3} holds.
24.3 Bounded binarization algorithmThe adjacency-based binarization algorithm is givenin Figure 2.
It starts with a working set contain-ing the endpoint sets corresponding to each non-terminal occurrence in the input production p. Re-ductions of p are only explored for nonterminal oc-currences whose endpoint sets are adjacent for thetarget fan-out f ?, since reductions not meeting thisconstraint would produce productions with fan-outgreater than f ?.
Each reduction explored by the al-gorithm produces a new endpoint set, associated tothe fresh nonterminal that it introduces, and this newendpoint set is added to the working set and poten-tially used in further reductions.From the definition of the adjacency relation?f ,it follows that at lines 9 and 10 of BOUNDED-BINARIZATION we only pick up reductions for pthat do not exceed the fan-out bound of f ?.
Thisimplies soundness for our algorithm.
Completenessmeans that the algorithm fails only if there exists nobinarization for p of fan-out not greater than f ?.
This1: Function BOUNDED-BINARIZATION(p, f ?
)2: workingSet?
?
;3: agenda?
?
;4: for all i from 1 to ?
(p) do5: workingSet?
workingSet ?
{?
{Bi}};6: agenda?
agenda ?
{?
{Bi}};7: while agenda 6= ?
do8: ??
pop some endpoint set from agenda;9: for all ?1 ?
workingSet with ?1 ?f ?
?
do10: ?2 = ?
(?,?1);11: if ?2 /?
workingSet then12: workingSet?
workingSet ?
{?2};13: agenda?
agenda ?
{?2};14: if ?{B1,B2,...,B?
(p))} ?
workingSet then15: return true;16: else17: return false;Figure 2: Algorithm to compute a bounded binarizationproperty is intuitive if one observes that our algo-rithm is a specialization of standard algorithms forthe computation of the closure of binary relations.A formal proof of this fact is rather long and te-dious, and will not be reported here.
We notice thatthere is a very close similarity between algorithmBOUNDED-BINARIZATION and the deduction pro-cedure proposed by Shieber et al (1995) for parsing.We discuss this more at length in Section 5.Note that we have expressed the algorithm as adecision function that will return true if there existsa binarization of p with fan-out not greater than f ?,and false otherwise.
However, the algorithm caneasily be modified to return a reduction producingsuch a binarization, by adding to each endpoint set?
?
workingSet two pointers to the adjacent end-point sets that were used to obtain it.
If the algorithmis successful, the tree obtained by following thesepointers from the final endpoint set ?{B1,...,B?
(p)} ?workingSet gives us a tree of reductions that willproduce a binarization of p with fan-out not greaterthan f ?, where each node labeled with the set ?
{Bi}corresponds to the nonterminal Bi, and nodes la-beled with other endpoint sets correspond to thefresh nonterminals created by the reductions.5434.4 ImplementationIn order to implement BOUNDED-BINARIZATION,we can represent endpoint sets in a canonical wayas 2f ?-tuples of integer positions in ascending order,and with some special null value used to fill posi-tions for endpoint sets with fan-out strictly smallerthan f ?.
We will assume that the concrete null valueis larger than any other integer.We also need to provide some appropriate repre-sentation for the set workingSet, in order to guar-antee efficient performance for the membership testand the insertion operation.
Both operations can beimplemented in constant time if we represent work-ingSet as an (2?f ?
)-dimensional table with Booleanentries.
Each dimension is indexed by values in[0, n] plus our special null value; here n is the lengthof the string ?N (p), and thus n = O(|p|).
However,this has the disadvantage of using space ?
(n2f ?
),even in case workingSet is sparse, and is affordableonly for quite small values of f ?.
Alternatively, wecan more compactly represent workingSet as a triedata structure.
This representation has size certainlysmaller than 2f ?
?
q, where q is the size of the setworkingSet.
However, both membership and inser-tion operations take now an amount of time O(2f ?
).We now analyse the time complexity of algorithmBOUNDED-BINARIZATION for inputs p and f ?.
Wefirst focus on the while-loop at lines 7 to 13.
Asalready observed, the number of possible endpointsets is bounded by O(n2f ?).
Furthermore, becauseof the test at line 11, no endpoint set is ever insertedinto the agenda variable more than once in a sin-gle run of the algorithm.
We then conclude that ourwhile-loop cycles a number of times O(n2f ?
).We now focus on the choice of the endpoint set?1 in the inner for-loop at lines 9 to 13.
Let us fix ?as in line 8.
It is not difficult to see that any ?1 with?1 ?f ?
?
must satisfy?(?)
+ ?(?1)?
|?
?
?1| ?
f ?.
(1)Let I ?
?, and consider all endpoint sets ?1 with?
?
?1 = I .
Given (1), we also have?
(?1) ?
f ?
+ |I| ?
?(?).
(2)This means that, for each ?
coming out of theagenda, at line 9 we can choose all endpoint sets ?1such that ?1 ?f ?
?
by performing the followingsteps:?
arbitrarily choose a set I ?
?;?
choose endpoints in set ?1\I subject to (2);?
test whether ?1 belongs to workingSet andwhether ?, ?1 do not overlap.We claim that, in the above steps, the numberof involved endpoints does not exceed 3f ?.
Tosee this, we observe that from (2) we can derive|I| ?
?(?)
+ ?
(?1) ?
f ?.
The total numberof (distinct) endpoints in a single iteration step ise = 2?(?)
+ 2?
(?1) ?
|I|.
Combining with theabove inequality we havee ?
2?(?)
+ 2?(?1)?
?(?)?
?
(?1) + f ?= ?(?)
+ ?
(?1) + f ?
?
3f ?
,as claimed.
Since each endpoint takes values inthe set [0, n], we have a total of O(n3f ?)
differentchoices.
For each such choice, we need to clas-sify an endpoint as belonging to either ?\I , ?1\I ,or I .
This amounts to an additional O(33f ?)
dif-ferent choices.
Overall, we have a total number ofO((3n)3f ?)
different choices.
For each such choice,the test for membership in workingSet for ?1 takesconstant time in case we use a multi-dimensional ta-ble, or else O(|p|) in case we use a trie.
The ad-jacency test and the merge operations can easily becarried out in time O(|p|).Putting all of the above observations together, andusing the already observed fact that n = O(|p|),we can conclude that the total amount of time re-quired by the while-loop at lines 7 to 13 is boundedbyO(|p| ?
(3|p|)3f ?
), both under the assumption thatworkingSet is represented as a multi-dimensional ta-ble or as a trie.
This is also a bound on the runningtime of the whole algorithm.4.5 Minimal binarization of a complete LCFRSThe algorithm defined in Section 4.3 can be usedto binarize an LCFRS in such a way that each rulein the resulting binarization has the minimum pos-sible fan-out.
This can be done by applying theBOUNDED-BINARIZATION algorithm to each pro-duction p, until we find the minimum value for the5441: Function MINIMAL-BINARIZATION(G)2: pb = ?
{Set of binarized productions}3: for all production p of G do4: f ?
= fan-out(p);5: while not BOUNDED-BINARIZATION(p, f ?
)do6: f ?
= f ?
+ 1;7: add result of BOUNDED-BINARIZATION(p,f ?)
to pb; {We obtain the tree fromBOUNDED-BINARIZATION as explained inSection 4.3 and use it to binarize p}8: return pb;Figure 3: Minimal binarization by sequential searchbound f ?
for which this algorithm finds a binariza-tion.
For a production with rank r and fan-out f ,we know that this optimal value of f ?
must be inthe interval [f, d r2e ?
f ] because binarizing a pro-duction cannot reduce its fan-out, and the NAIVE-BINARIZATION algorithm seen in Section 4.1 canbinarize any production by increasing fan-out tod r2e ?
f in the worst case.The simplest way of finding out the optimal valueof f ?
for each production is by a sequential searchstarting with ?
(p) and going upwards, as in the algo-rithm in Figure 3.
Note that the upper bound d r2e ?
fthat we have given for f ?
guarantees that the while-loop in this algorithm always terminates.In the worst case, we may need f ?
(d r2e ?
1) + 1executions of the BOUNDED-BINARIZATION algo-rithm to find the optimal binarization of a productionin G. This complexity can be reduced by changingthe strategy to search for the optimal f ?
: for exam-ple, we can perform a binary search within the inter-val [f, d r2e ?
f ], which lets us find the optimal bina-rization in blog(f ?
(d r2e?1)+1)c+1 executions ofBOUNDED-BINARIZATION.
However, this will notresult in a practical improvement, since BOUNDED-BINARIZATION is exponential in the value of f ?
andthe binary search will require us to run it on val-ues of f ?
larger than the optimal in most cases.
Anintermediate strategy between the two is to applyexponential backoff to try the sequence of valuesf?1+2i (for i = 0, 1, 2 .
.
.).
When we find the firsti such that BOUNDED-BINARIZATION does not fail,if i > 0, we apply the same strategy to the interval[f?1+2i?1, f?2+2i], and we repeat this method toshrink the interval until BOUNDED-BINARIZATIONdoes not fail for i = 0, giving us our optimal f ?.With this strategy, the amount of executions of thealgorithm that we need in the worst case is12(dlog(?
)e+ dlog(?
)e2) + 1 ,where ?
= f ?
(d r2e ?
1) + 1, but we avoid usingunnecessarily large values of f ?.5 DiscussionTo conclude this paper, we now discuss a number ofaspects of the results that we have presented, includ-ing various other pieces of research that are particu-larly relevant to this paper.5.1 The tradeoff between rank and fan-outThe algorithm introduced in this paper can be usedto transform an LCFRS into an equivalent formwith rank 2.
This will result into a more effi-ciently parsable LCFRS, since rank exponentiallyaffects parsing complexity.
However, we must takeinto account that parsing complexity is also influ-enced by fan-out.
Our algorithm guarantees a min-imal increase in fan-out.
In practical cases it seemssuch an increase is quite small.
For example, inthe context of dependency parsing, both Go?mez-Rodr?
?guez et al (2009) and Kuhlmann and Satta(2009) show that all the structures in several well-known non-projective dependency treebanks are bi-narizable without any increase in their fan-out.More in general, it has been shown by Seki et al(1991) that parsing of LCFRS can be carried out intime O(n|pM |), where n is the length of the inputstring and pM is the production in the grammar withlargest size.3 Thus, there may be cases in which onehas to find an optimal tradeoff between rank and fan-out, in order to minimize the size of pM .
This re-quires some kind of Viterbi search over the space ofall possible binarizations, constructed as describedat the end of Subsection 4.3, for some appropriatevalue of the fan-out f ?.3The result has been shown for the formalism of multiplecontext-free grammars (MCFG), but it also applies to LCFRS,which are a special case of MCFG.5455.2 Extension to general LCFRSThis paper has focussed on string-based LCFRS.As discussed in Vijay-Shanker et al (1987), LCFRSprovide a more general framework where the pro-ductions are viewed as generating a set of abstractderivation trees.
These trees can be used to specifyhow structures other than tuples of strings are com-posed.
For example, LCFRS derivation trees can beused to specify how the elementary trees of a TreeAdjoining Grammar can be composed to producedderived tree.
However, the results in this paper alsoapply to non-string-based LCFRS, since by limit-ing attention to the terminal string yield of whateverstructures are under consideration, the compositionoperations can be defined using the string-based ver-sion of LCFRS that is discussed here.5.3 Similar algorithmic techniquesThe NAIVE-BINARIZATION algorithm given in Fig-ure 1 is not novel to this paper: it is similar toan algorithm developed in Melamed et al (2004)for generalized multitext grammars, a formalismweakly equivalent to LCFRS that has been intro-duced for syntax-based machine translation.
How-ever, the grammar produced by our algorithm hasoptimal (minimal) fan-out.
This is an important im-provement over the result in (Melamed et al, 2004),as this quantity enters into the parsing complexityof both multitext grammars and LCFRS as an expo-nential factor, and therefore must be kept as low aspossible to ensure practically viable parsing.Rank reduction is also investigated in Nessonet al (2008) for synchronous tree-adjoining gram-mars, a synchronous rewriting formalism based ontree-adjoining grammars Joshi and Schabes (1992).In this case the search space of possible reductionsis strongly restricted by the tree structures specifiedby the formalism, resulting in simplified computa-tion for the reduction algorithms.
This feature is notpresent in the case of LCFRS.There is a close parallel between the techniqueused in the MINIMAL-BINARIZATION algorithmand deductive parsing techniques as proposed byShieber et al (1995), that are usually implementedby means of tabular methods.
The idea of exploit-ing tabular parsing in production factorization wasfirst expressed in Zhang et al (2006).
In fact, theparticular approach presented here has been usedto improve efficiency of parsing algorithms that usediscontinuous syntactic models, in particular, non-projective dependency grammars, as discussed inGo?mez-Rodr?
?guez et al (2009).5.4 Open problemsThe bounded binarization algorithm that we havepresented has exponential run-time in the value ofthe input fan-out bound f ?.
It remains an open ques-tion whether the bounded binarization problem forLCFRS can be solved in deterministic polynomialtime.
Even in the restricted case of f ?
= ?
(p), thatis, when no increase in the fan-out of the input pro-duction is allowed, we do not know whether p can bebinarized using only deterministic polynomial timein the value of p?s fan-out.
However, our boundedbinarization algorithm shows that the latter problemcan be solved in polynomial time when the fan-outof the input LCFRS is bounded by some constant.Whether the bounded binarization problem canbe solved in polynomial time in the value of theinput bound f ?
is also an open problem in the re-stricted case of synchronous context-free grammars,a special case of an LCFRS of fan-out two witha strict separation between the two components ofeach nonterminal in the right-hand side of a produc-tion, as discussed in the introduction.
An interestinganalysis of this restricted problem can be found inGildea and Stefankovic (2007).Acknowledgements The work of Carlos Go?mez-Rodr?
?guez was funded by Ministerio de Educacio?ny Ciencia and FEDER (HUM2007-66607-C04) andXunta de Galicia (PGIDIT07SIN005206PR, IN-CITE08E1R104022ES, INCITE08ENA305025ES,INCITE08PXIB302179PR and Rede Galega deProcesamento da Linguaxe e Recuperacio?n de Infor-macio?n).
The work of Marco Kuhlmann was fundedby the Swedish Research Council.
The work ofGiorgio Satta was supported by MIUR under projectPRIN No.
2007TJNZRE 002.
We are grateful to ananonymous reviewer for a very detailed review witha number of particularly useful suggestions.546ReferencesDavid Chiang.
2007.
Hierarchical phrase-based translation.
Computational Linguistics,33(2):201?228.Daniel Gildea and Daniel Stefankovic.
2007.
Worst-case synchronous grammar rules.
In Human Lan-guage Technologies 2007: The Conference of theNorth American Chapter of the Association forComputational Linguistics; Proceedings of theMain Conference, pages 147?154.
Associationfor Computational Linguistics, Rochester, NewYork.Carlos Go?mez-Rodr?
?guez, David J. Weir, and JohnCarroll.
2009.
Parsing mildly non-projective de-pendency structures.
In Twelfth Conference of theEuropean Chapter of the Association for Compu-tational Linguistics (EACL).
To appear.A.
K. Joshi and Y. Schabes.
1992.
Tree adjoininggrammars and lexicalized grammars.
In M. Nivatand A. Podelsky, editors, Tree Automata and Lan-guages.
Elsevier, Amsterdam, The Netherlands.Marco Kuhlmann and Joakim Nivre.
2006.
Mildlynon-projective dependency structures.
In 21stInternational Conference on Computational Lin-guistics and 44th Annual Meeting of the Asso-ciation for Computational Linguistics (COLING-ACL), Main Conference Poster Sessions, pages507?514.
Sydney, Australia.Marco Kuhlmann and Giorgio Satta.
2009.
Tree-bank grammar techniques for non-projective de-pendency parsing.
In Twelfth Conference of theEuropean Chapter of the Association for Compu-tational Linguistics (EACL).
To appear.I.
Dan Melamed, Benjamin Wellington, and Gior-gio Satta.
2004.
Generalized multitext gram-mars.
In 42nd Annual Meeting of the Associationfor Computational Linguistics (ACL), pages 661?668.
Barcelona, Spain.Rebecca Nesson, Giorgio Satta, and Stuart M.Shieber.
2008.
Optimal k-arization of syn-chronous tree-adjoining grammar.
In Proceedingsof ACL-08: HLT, pages 604?612.
Association forComputational Linguistics, Columbus, Ohio.A.
Nijholt.
1980.
Context-Free Grammars: Cov-ers, Normal Forms, and Parsing, volume 93.Springer-Verlag, Berlin, Germany.Owen Rambow and Giorgio Satta.
1999.
Indepen-dent parallelism in finite copying parallel rewrit-ing systems.
Theoretical Computer Science,223(1?2):87?120.Hiroyuki Seki, Takashi Matsumura, Mamoru Fujii,and Tadao Kasami.
1991.
On Multiple Context-Free Grammars.
Theoretical Computer Science,88(2):191?229.Stuart M. Shieber, Yves Schabes, and FernandoPereira.
1995.
Principles and implementation ofdeductive parsing.
Journal of Logic Program-ming, 24(1?2):3?36.Takeaki Uno and Mutsunori Yagiura.
2000.
Fast al-gorithms to enumerate all common intervals oftwo permutations.
Algorithmica, 26(2):290?309.K.
Vijay-Shanker, David J. Weir, and Aravind K.Joshi.
1987.
Characterizing structural descrip-tions produced by various grammatical for-malisms.
In 25th Annual Meeting of the Associ-ation for Computational Linguistics (ACL), pages104?111.
Stanford, CA, USA.Benjamin Wellington, Sonjia Waxmonsky, andI.
Dan Melamed.
2006.
Empirical lower boundson the complexity of translational equivalence.
In21st International Conference on ComputationalLinguistics and 44th Annual Meeting of the Asso-ciation for Computational Linguistics (COLING-ACL), pages 977?984.
Sydney, Australia.Hao Zhang, Daniel Gildea, and David Chiang.2008.
Extracting synchronous grammar rulesfrom word-level alignments in linear time.
In22nd International Conference on ComputationalLinguistics (Coling), pages 1081?1088.
Manch-ester, England, UK.Hao Zhang, Liang Huang, Daniel Gildea, and KevinKnight.
2006.
Synchronous binarization for ma-chine translation.
In Human Language Technol-ogy Conference of the North American Chapterof the Association for Computational Linguistics,pages 256?263.
New York, USA.547
