USING CLASS IF ICAT ION TO GENERATE TEXTEhud Reiter* and Chris Mellish tDepartment of Artificial IntelligenceUniversity of Edinburgh80 South BridgeEdinburgh EH1 1HNBRITAINABSTRACTThe IDAS natural-language neration systemuses a KL-ONE type classifier to perform contentdetermination, surface realisation, and part of textplanning.
Generation-by-classification ll ws IDASto use a single representation a d reasoning com-ponent for both domain and linguistic knowledge,which is difficult for systems based on unificationor systemic generation techniques.I n t roduct ionClassification is the name for the procedure ofautomatically inserting new classes into the cor-rect position in a KL-ONE type class taxonomy\[Brachman and Schmolze, 1985\].
When combinedwith an attribute inheritance system, classifica-tion provides a general pattern-matching and uni-fication capability that can be used to do muchof the processing needed by NL generation sys-tems, including content-determination, surface-realisation, and portions of text planning.
Classi-fication and inheritance are used in this manner bythe IDAS natural language generation system \[Re-iter et al, 1992\], and their use has allowed IDAS touse a single knowledge representation system forboth linguistic and domain knowledge.IDAS and  I1IDASIDAS is a natural-language generation system thatgenerates on-line documentation and help mes-sages for users of complex equipment.
It supportsuser-tailoring and has a hypertext-like interfacethat allows users to pose follow-up questions.The input to IDAS is a point in questionspace, which specifies a basic question type (e.g.,What-is-it), a component the question is beingasked about (e.g., Computer23),  the user's task(e.g.
Replace-Part), the user's expertise-level*E-mail address is E. ReiterQed.
ac .ukrE-mail address is C.NellishQed.ac.uk265(e.g., Skilled), and the discourse in-focus list.
Thegeneration process in IDAS uses the three stagesdescribed in \[Grosz et al, 1986\]:?
Content Determination: A content-determin-ation rule is chosen based on the inputs; thisrule specifies what information from the KBshould be communicated to the user, andwhat overall format he response should use.?
Text Planning: An expression in the ISISentence Planning Language (SPL) \[Kasper,1989\] is formed from the information speci-fied in the content-determination rule.?
Surface Realisation: The SPL is converted intoa surface form, i.e., actual words interspersedwith text-formatting commands.I1I1 is the knowledge representation system usedin IDAS to represent domain knowledge, grammarrules, lexicons, user tasks, user-expertise models,and content-determination rules.
The I1 systemincludes:?
an automatic classifier;?
a default-inheritance system that inheritsproperties from superclass to subclass, us-ing Touretsky's \[1986\] minimal inferential dis-tance principle to resolve conflicts;?
various support tools, such as a graphicalbrowser and editor.An I1 knowledge base (KB) consists of classes,roles, and user-expertise models.
User-expertisemodels are represented as KB overlays, in a simi-lar fashion to the FN system \[Reiter, 1990\].
Rolesare either definitional or assertional; only defini-tional roles are used in the classification process.Roles can be defined as having one filler or an arbi-trary number of fillers, i.e., as having an inherent'number estriction' of one or infinity.An I1 class definition consists of at least one ex-plicitly specified parent class, primitive?
and in-dividual?
flags, value restrictions for definitionalroles, and value specifications for assertional roles.I1 does not support he more complex definitionalconstructs of KL-ONE, such as structural descrip-tions.
The language for specifying assertional rolevalues is richer than that for specifying definitionalrole value restrictions, and allows, for example:measurements that specify a quantity and a unit;references that specify the value of a role in termsof a KL-ONE type role chain; and templates thatspecify a parametrized class definition as a rolevalue.
The general design goal of I1 is to use a verysimple definitional language, so that classificationis computationally fast, but a rich assertional lan-guage, so that complex things can be stated aboutentities in the knowledge base.An example I1 class definition is:(define-class open-door: parent open: type defined: prop( (ac tor  animate-object)(actee door )(decomposition( (*template*grasp(ac tor  = actor  *se l f * )(ac tee  = (hand le  par t )  ac tee  *se l f * ) )(*template*turn(actor = actor *self*)(actee = (handle part) actee *self*))(*template*pull(actor ffi actor *self*)(ac tee  = (hand le  par t )  ac tee  *se l f * ) )) ) ) )This defines the class Open-door to be adef ined  (non-primitive and non-individual) childof the class Open.
Actor and Actee are defini-tional roles, so the values given for them in theabove definition are treated as definitional valuerestrictions; i.e., an Open-Door entity is anyOpen entity whose Actor role has a filler sub-sumed by Animate-Object ,  and whose Acteerole has a filler subsumed by Door.Decompos i t ion  is an assertional role, whosevalue is a list of three templates.
Each tem-plate defines a class whose ancestor is an action(Grasp, Turn, Pull) that has the same Actor asthe Open-Door action and that has an Acteethat is the filler of the Part role of the Acteeof the Open-Door action which is subsumed byHandle (i.e., (handle part )  is a differentiationof Part onto Handle).For example, if Open-12 was defined as anOpen action with role fillers Actor:Sam andActee:Door-6, then Open-12 would be classifiedbeneath Open-Door by the classifier on the basisof its Actor and Actee values.
If an inquiry wasissued for the value of Decomposition for Open-12, the above definition from Open-Door wouldbe inherited, and, if Door-6 had Handle-6 asone of its fillers for Part, the templates would beexpanded into a list of three actions, (Grasp-12Turn-12 Pull-12), each of which had an Actorof Sam and an Actee of Handle-6.Using Classification inGenerationContent  Determinat ionThe input to IDAS is a point in question space,which specifies a basic question, component, user-task, user-expertise model, and discourse in-focuslist.
The first three members of this tuple areused to pick a content-determination rule, whichspecifies the information the generated responseshould communicate.
This is done by forming arule-instance with fillers that specify the basic-question, component, and user-task; classifyingthis rule-instance into a taxonomy of content-ruleclasses, and reading off inherited values for vari-ous attributive roles.
A (simplified) example of acontent-rule class definition is:(define-class what-operat ions-rule:parent content-rule:type defined: prop( (rule-question .hat)(rule-task operations)(rule-rolegroup(manufacturer model-number colour) )(rule-funct ion' (identify-schema :bullet?
nil))))Rule-question and Rule-Task are definitionalroles that specify which queries a content ruleapplies to; What -Operat ions-Rule  is used for"What" questions i sued under an Operations task(for any component).
Rule-Rolegroup specifiesthe role fillers of the target component that theresponse should communicate o the user; What-Operat lons-Rule specifies that the manufac-turer, model-number, and colour of the targetcomponent should be communicated to the user.Rule-Functlon specifies a Lisp text-planning func-tion that is called with these role fillers in or-der to generate SPL.
Content-rule class defini-tions can also contain attributive roles that spec-ify a human-readable title for the query; followupqueries that will be presented as hypertext click-able buttons in the response window; objects to beadded to the discourse in-focus list; and a testingfunction that determines if a query is answerable.Content-determination in IDAS is therefore doneentirely by classification and feature inheritance;266once the rule-instance has been formed from theinput query, the classifier is used to find the mostspecific content-rule which applies to the rule-instance, and the inheritance mechanism is thenused to obtain a specification for the KB informa~tion that the response should communicate, thetext-planning function to be used, and other rele-vant information.IDAS's content-determination system is primar-ily designed to allow human domain experts to rel-atively easily specify the desired contents of short(paragraph or smaller) responses.
As such, it isquite different from systems that depend on deeperplan-based reasoning (e.g.
\[Wahlster et al, 1991;Moore and Paris, 1989\]).
Authorability is stressedin IDAS because we believe this is the best way toachieve IDAS'S goal of fairly broad, but not neces-sarily deep, domain coverage; short responses arestressed because IDAS's hypertext interface shouldallow users to dynamically choose the paragraphsthey wish to read, i.e., perform their own high-level text-planning \[Reiter et al, 1992\].Text  P lann ingText planning is the only part of the generationprocess that is not entirely done by classificationin IDAS, The job of IDAS'S text-planning systemis to produce an SPL expression that communi-cates the information specified by the content-determination system.
This involves, in partic-ular:?
Determining how many sentences to use, andwhat information each sentence should com-municate (text structuring).?
Generating referring expressions that identifydomain entities to the user.?
Choosing lexical units (words) to express do-main concepts to the user.Classification is currently used only in the lexical-choice portion of the text-planning process, andeven there it only performs part of this task.Text structuring in IDAS is currently done ina fairly trivial way; this could perhaps be im-plemented with classification, but this would notdemonstrate anything interesting about the capa-bilities of classification by generation.
More so-phisticated text-structuring techniques have beendiscussed by, among others, Mann and Moore\[1981\], who used a hill-climbing algorithm basedon an explicit preference function.
We have notto date investigated whether classification couldbe used to implement his or other such text-structuring algorithms.Referring expressions in IDAS are generated bythe algorithm described in \[Reiter and Dale, 1992\].This algorithm is most naturally stated iterativelyin a conventional programming language; theredoes not seem to be much point in attempting tore-express it in terms of classification.Lexical choice in IDAS is based on the ideas pre-sented in \[Reiter, 1991\].
When an entity needs tohe lexicalized, it is classified into the main domaintaxonomy, and all ancestors of the class that havelexical realisations in the current user-expertisemodel are retrieved.
Classes that are too generalto fulfill the system's communicative goal are re-jected, and preference criteria (largely based onlexical preferences recorded in the user-expertisemodel) are then used to choose between the re-maining lexicalizable ancestors.For example, to lexicalize the action (Act ivatewith role fillers Actor :Sam and Actee:Toggle-Switch-23)  under the Skilled user-expertisemodel, the classifier is called to place this actionin the taxonomy.
In the current IDAS knowledgebase, this action would have have two realisableancestors that are sufficiently informative to meetan instructional communicative goal, 1 Act ivate(realisation "activate") and (Act ivate  with rolefiller Actee:Switch)  (realisation "flip").
Prefer-ence criteria would pick the second ancestor, be-cause it is marked as basic-level \[Rosch, 1978\] inthe Skilled user-expertise model.
Hence, if "theswitch" is a valid referring expression for Toggle-Swltch-23,  the entire action will be realised as"Flip the switch".In short, lexical-choice in IDAS use8 classificationto produce a set of possible lexicMizations, butother considerations are used to choose the mostappropriate member of this set.
The lexical-choicesystem could be made entirely classification-basedif it was acceptable to always use the most spe-cific realisable class that subsumed an entity, butignoring communicative goals and the user's pref-erences in this way can cause inappropriate textto be generated \[Reiter, 1991\].In general, it may be the case that an entirelyclassification-based approach is not appropriatefor tasks which require taking into considerationcomplex pragmatic riteria, such as the user's lex-ical preferences or the current discourse context(classification may still be usefully used to per-form part of these tasks, however, as is the casein IVAS's lexical-choice module).
It is not clearto the authors how the user's lexical preferencesor the discourse context could even be encoded ina manner that would make them easily accessi-ble to a classifier-based generation algorithm, al-though perhaps this simply means that more re-search needs to be done on this issue.1The general class Action is an example of an an-cestor class that is too general to meet he communica-tive goal; if the user is simply told "Perform an actionon the switch", he will not know that he is supposedto activate the switch.267Sur face  Rea l i sa t ionSurface realisation is performed entirely by clas-sification in IDAS.
The SPL input to the surfacerealisation system is interpreted as an I1 class def-inition, and is classified beneath an ,pper model\[Bateman et al, 1990\].
The upper model dis-tinguishes, for example, between Relat ional  andNonrelat ional  propositions, and Animate andInan imate  objects.
2 A new class is then createdwhose parent is the desired grammatical unit (typ-ically Complete-Phrase),  and which has the SPLclass as a filler for the definitional Semantics role.This class is classified, and the realisation of thesentence is obtained by requesting the value of itsRealisatlon role (an attributive role).A simplified example of an I1 class that definesa grammatical unit is:(define-class sentence:parent complete-phrase:type defined: prop((semantics predication)(realisation( (*reference*realisation subject ?self?
)(*reference?realisation predicate ?self*)))(number(?reference?
number subject ?self?
))(subject(?template?noun-phrase(semantics = actor semantics ?self*)))(predicate ...)...))Semantics is a definitional role, so the abovedefinition is for children of Complete-Phrasewhose Semantics role is filled by something clas-sifted beneath Predicat ion in the upper model.It states that?
the Realisatlon of the class is formed by con-catenating the realisation of the Subject ofthe class with the realisation of the Predicateof the class;?
the Number of the class is the Number ofthe Subject of the class;?
the Subject of the class is obtained by creat-ing a new class beneath Noun-Phrase whosesemantics i  the Actor of the Semantics ofthe class; this in essence is a recursive call torealise a semantic onstituent.If some specialized types of Sentence need dif-ferent values for Reallsatlon, Number, Subject,2The IDAS upper model is similar to a subset of thePENMAN upper model.268or another attributive role value, this can be spec-ified by creating a child of Sentence that usesII's default inheritance mechanism to selectivelyoverride the relevant role fillers.
For example,(define-class imperative:parent sentence:type defined:prop((semantics command)( rea l i sa t ion( ?
refer ence?real~sation predicate ?self?
))))This defines a new class Imperat ive  that ap-plies to Sentences whose Semantics filler is clas-sifted beneath Command in the upper model(Command is a child of Predication).
Thisclass inherits the values of the Number and Sub-ject fillers from Sentence, but specifies a newfiller for Realisation, which is just the Realisationof the Predicate of the class.
In other words, theabove class informs the generation system of thegrammatical fact that imperative sentences do notcontain surface subjects.
The classification systemplaces classes beneath their most specific parent inthe taxonomy, so to-be-realised classes always in-herit realisation i formation from the most specificgrammatical-unit class that applies to them.The  Ro le  o f  Conf l i c t  Reso lu t ionIn general terms, a classification system can bethought of as supporting a pattern-matching pro-cess, in which the definitional role fillers of a classrepresent the pattern (e.g.
(semantics command)in Imperat ive),  and the attributive roles (e.g.,R.ealisation) specify some sort of action.
In otherwords, a classification system is in essence a wayof encoding pattern-action rules of the form:~1 -'+~1~2 ---~ ~2If several classes subsume an input, then clas-sification systems use the attributive roles speci-fied (or inherited by) the most specific subsumingclass; in production rule terminology, this meansthat if several c~i's match an input, only the ~i as-sociated with the most specific matching crl is trig-gered.
In other words, classification systems usethe conflict resolution principle of always choosingthe most specific matching pattern-action rule.This conflict-resolution principle is used in dif-ferent ways by different parts of \]DAS.
Thecontent-determination system uses it as a prefer-ence mechanism; if several content-determinationrules subsume an input query, any of these rulescan be used to generate a response, but presum-ably the most appropriate r sponse will be gener-ated by the most specific subsuming rule.
Thelexical-choice system, in contrast, effectively ig-nores the 'prefer most specific' principle, and in-stead uses its own preference criteria to chooseamong the lexemes that subsume an entity.
Thesurface-generation system is different yet again, inthat it uses the conflict-resolution mechanism toexclude inapplicable grammar ules.
If a partic-ular term is classified beneath Imperat ive ,  forexample, it also must be subsumed by Sentence,but using the Realisation specified in Sentenceto realise this term would result in text that isincorrect, not just stylistically inferior.The 'use most specific matching rule' conflict-resolution principle is thus just a tool that canhe used by the system designer.
In some cases itcan be used to implement preferences (as in IDAS'scontent-determination system); in some cases itcan be used to exclude incorrect rules which wouldcause an error if they were used (as in IDAS'ssurface-generation system); and in some cases itneeds to be overridden by a more appropriatechoice mechanism (as in IDAS's lexical choice sys-tem).Classif ication vs. OtherApproachesPerhaps the most popular alternative approachesto generation are unification (especially functionalunification) and systemic grammars.
As with clas-sification, the unification and systemic approachescan be applied to all phases of the generation pro-cess \[McKeown et al, 1990; Patten, 1988\].
3 How-ever, most of the published work on unificationand systemic systems deals with surface realisa-tion, so it is easiest to focus on this task whenmaking a comparison with classification systems.Like classification, unification and systemic sys-tems can be thought of as supporting a recursivepattern-matching process.
All three frameworksallow grammar ules to be written declaratively.They also all support unrestricted recursion, i.e.,they all allow a grammar ule to specify that aconstituent of the input should be recursively pro-cessed by the grammar (IDAS does this with I I 'stemplate mechanism).
In particular, this meansthat all three approaches are Turing-equivalent.There are differences in how patterns and actionsare specified in the three formalisms, but it is prob-ably fair to say that all three approaches are suf-ficiently flexible to be able to encode most desir-able grammars.
The choice between them musttherefore be made on the basis of which is easiestto incorporate into a real NL generation system.3Although it is unclear whether unification or sys-temic systems can do any better at the text-planningtasks that are difficult for classification systems, suchas generating referring expressions.We believe that classification has a significant ad-vantage here because many generation systems al-ready include a classifier to support reasoning ona domain knowledge base; hence, using classifi-cation for generation means the same knowledgerepresentation (KR) system can be used to sup-port both domain and linguistic knowledge.
Thus,IDAS uses only one KR system - -  I1 - -  whereassystems uch as COMET (unification) \[McKeownet al, 1990\] and PENMAN (systemic) \[PenmanNatural Language Group, 1989\] use two differentKR systems: a classifier-based system for domainknowledge, and a unification or systemic systemfor grammatical knowledge.Unification SystemsThe most popular unification formalism for gener-ation up to now has probably been functional uni-fication (FUG) \[Kay, 1979\].
FUG systems work bysearching for patterns (alternations) in the gram-mar that unify with the system's input (i.e., uni-fication is used for pattern-matching); inheritingsyntactic (output) feature values from the gram-mar patterns (the actions); and recursively pro-cessing members of the constituent set (the recur-sion).
That is, pattern-action rules of the abovekind are encoded as something like:v v .. .If a unification system is based on a typed featurelogic, then its grammar can include classification-like subsumption tests \[Elhadad, 1990\], and thusbe as expressive in specifying patterns as a classi-fication system.An initial formal comparison of unification withclassification is given in the Appendix.
Perhapsthe most important practical differences are:?
Classification grammars cannot be used bidi-rectionally, while unification grammars can\[Sheiber, 1988\].?
Unification systems produce (at least in prin-ciple) all surface forms that agree (unify) withthe semantic input; classification systems pro-duce a single surface form output.These differences are in a sense a result of the factthat unification grammars represent general map-pings between semantic and surface forms (andhence can be used bidirectionally, and produceall compatible surface forms), while classificationsystems generate a single surface form from a se-mantic input.
In McDonald's \[1983\] terminology,classification-based generation systems determin-istically and indelibly make choices about alter-nate surface-form constructs as the choices arise,with no backtracking; 4 unification-based systems,4McDonald claims, incidentally, that indelibledecision-making is more plausible than backtrackingfrom a psycholinguistic perspective.269in contrast, produce the set of all syntactically cor-rect surface-forms that are compatible with thesemantic input.
5In practice, all generation systems must possessa 'preference filter' of some kind that chooses asingle output surface-form from the set of possi-bilities.
In unification approaches, choosing a par-ticular surface form to output ends to be regarded(at least heoretically) asa separate task from gen-erating the set of syntactically and semanticallycorrect surface forms; in classification approaches,in contrast, he process of making choices betweenpossible surface forms is interwoven with the maingeneration algorithm.Sys temic  approachesSystemic grammars \[Halliday, 1985\] are anotherpopular formalism for generation systems.
Sys-temic systems vary substantially in the input lan-guage they accept; we will here focus on the NIGELsystem \[Mann, 1983\], since it uses the same in-put language (SPL) as IDAS'S surface realisationsystem, s Other systemic systems (e.g., \[Patten,1988\]) tend to use systemic features as their in-put language (i.e., they don't have an equivalentof NIGEL'S chooser mechanism), which makes com-parisons more difficult.NIGEL works by traversing a network of systems,each with an associated chooser.
The choosers de-termine features, by performing tests on the se-mantic input.
Choosers can be arbitrary Lispcode, which means that NIGEL can in principle usemore general 'patterns' in its rules than IDAS can;in practice it is not clear to what extent his ex-tra expressive power is used in NIGEL, since manychoosers eem to be based on subsumption testsbetween semantic omponents and the system'supper model.
In any case, once a set of featureshas been chosen, these features trigger gates andtheir associated realisation rules; these rules as-sert information about the output ext.
From thepattern-matching perspective, choosers and gatesprovide the patterns ai of rules, while realisationrules specify the actions 13i to be performed on theoutput ext.Like classification systems (but unlike unifica-tion systems), systemic generation systems are,in McDonald's terminology, deterministic and in-delible choice-makers; NmEL makes choices about50f course these differences are in a sense moretheoretical than practical, since one can design a uni-fication system to only return a single surface forminstead of a set of surface forms, and one can includebacktracking-like mechanisms in a classification-basedsystem.SStrictly speaking, SPL is an input language to PEN-MAN, not NIGEL; we will here ignore the difference be-tween PENMAN and NIGEL.alternative surface-form constructs as they ariseduring the generation process, and does not back-track.
Systemic generation systems are thus prob-ably closer to classification systems than unifica-tion systems are; indeed, in a sense the biggestdifference between systemic and classification sys-tems is that systemic systems use a notation andinference system that was developed by the lin-guistic community, while classification systems usea notation and inference system that was devel-oped by the AI community.Other  Re la ted  WorkRSsner \[1986\] describes a generation system thatuses object-oriented techniques.
SPL-like inputspecifications are converted into objects, and thenrealised by activating their To-Realise methods.RSsner does not use a declarative grammar; hisgrammar rules are implicitly encoded in his Lispmethods.
He also does not use classification as aninference technique (his taxonomy is hand-built).DATR \[Evans and Gazdar, 1989\] is a system thatdeclaratively represents morphological rules, usinga representation that in some ways is similar to I1.In particular, DATR allows default inheritance andsupports role-chain-like constructs.
DATR does notinclude a classifier, and also has no equivalent ofII 's template mechanism for specifying recursion.PSI-KLONE \[Brachman and Schmolze, 1985,appendix\] is an NL understanding system thatmakes some use of classification, in particular tomap surface cases onto semantic ases.
Syntacticforms are classified into an appropriate taxonomy,and by virtue of their position inherit semanticrules that state which semantic ases (e.g., Actee)correspond to which surface cases (e.g., Object).ConclusionIn summary, classification can be used toperform much of the necessary processing innatural-language neration, including content-determination, surface-realisation, and part oftext-planning.
Classification-based generation al-lows a single knowledge representation system tobe used for both domain and linguistic knowledge;this means that a classification-based generationsystem can have a significantly simpler overall ar-chitecture than a unification or systemic genera-tion system, and thus be easier to build and main-tain.AcknowledgementsThe IDAS project is partially funded by UKSERC grant GR/F/36750 and UK DTI grant IED4/1/1072, and we are grateful to SERC and DTIfor their support of this work.
We would also like270to thank the IDAS industrial collaborators - -  Infer-ence Europe, Ltd.; lgacal Instruments, Ltd.; andRacal Researdh Ltd. - -  for all the help they havegiven us in performing this research.Append ix :  A Compar ison ofClassi f icat ion and Uni f icat ionFUG is only one of a number of grammar for-malisms based on feature logics.
The logic under-lying FUG is relatively simple, but much more ex-pressive logics are now being implemented \[Emeleand Zajac, 1990; D6rre and Seiffert, 1991; D/Srreand Eisele, 1991\].
Here we provide an initial for-mal characterisation of the relation between classi-fication and unification, but abstracting away fromthe differences between the different unificationsystems.Crucial to all approaches in unification-basedgeneration (or parsing) is the idea that at everylevel an input description (i.e.
logical form or sim-ilar) 7 is combined with a set of axioms (type spec-ifications, grammar functional descriptions, rules)and the resulting logical expression is then reducedto a normal form that can be used straightfor-wardly to construct the set of models for the com-bined axioms and description.Classification is an appropriate operation to usein normal form construction when the axioms takethe form oq ~ fit, with ~ interpreted as logicalimplication, and where each ai and/~i s a termin a feature logic.
If the input description is 'com-plete' with respect o the conditions of these ax-ioms (that is, if 7 ^  ai ~ J- exactly when 7 _C ~i,where _ is subsumption), then it follows that forevery model A4:u iffM I= _c u {v}(the relationship is more complex if the gram-mar is reeursive, though the same basic principleholds).
The first step of the computation of themodels of 7 and the axioms then just needs quickaccess to {fli17 _Coti}.
The classification approachis to have the different ai ordered in a subsump-tion taxonomy.
An input description 7 is placedin this taxonomy and the fll corresponding to itsancestors are collected.Input descriptions are 'complete' if every inputdescription is fully specified as regards the condi-tions that will be tested on it.
This implies a rigiddistinction between 'input' and 'output' informa-tion which, in particular, means that classificationwill not be able to implement bidirectional gram-mars.
If all the axioms are of the above form,input descriptions are complete and conjunctive,and the fli's are conjunctive (as is the case in IDAS)then there will always only be a single model.The above assumption about the form of ax-ioms is clearly very restrictive compared to whatis allowed in many modern unification formalisms.In IDAS, the notation is restricted even furtherby requiring the c~i and /~i to be purely con-junctive.
In spite of these restrictions, the sys-tem is still in some respects more expressive thanthe simpler unification formalisms.
In DefiniteClause Grammars (DCGs) \[Pereira nd Warren,1980\], for instance, it is not possible to specifyal --"/~1 and also c~z --*/~, whilst allowing that(al AO?2) ~ (~1A~2)  (unless a land  as are relatedby subsumption) \[Mellish, 19911.The comparison between unification and clas-sification is, unfortunately, made more complexwhen default inheritance is allowed in the classifi-cation system (as it is in IDAS).
Partly, the use ofdefaults may be viewed formally as simply a mech-anism to make it easier to specify 'complete' in-put descriptions.
The extent o which defaults areused in an essential way in IDAS still remains to beinvestigated.
Certainly for the grammar writer theability to specify defaults is very valuable, and thishas been widely acknowledged in grammar f ame-works and implementations.References\[Bateman etal., 1990\] John Bateman, RobertKasper, Johanna Moore, and Richard Whitney.A general organization of knowledge for nat-ural language processing: the Penman uppermodel.
Technical report, Information SciencesInstitute, Marina del Rey, CA 90292, 1990.\[Brachman and Schmolze, 1985\]Ronald Brachman and James Schmolze.
Anoverview of the KL-ONE knowledge representa-tion system.
Cognitive Science, 9:171-216, 1985.\[DSrre and Eisele, 1991\] Jochen D6rre and An-reas Eisele.
A comprehensive unification for-malism, 1991.
Deliverable R3.1.B, DYANA -ESPRIT Basic Research Action BR3175.\[D6rre and Seiffert, 1991\] Jochen D6rre andRoland Seiffert.
Sorted feature terms and re-lational dependencies.
IWBS Report 153, IBMDeutschland, 1991.\[Elhadad, 1990\] Michael Elhadad.
Types in func-tional unification grammars.
In Proceedings ofthe 28th Annual Meeting of the Association forComputational Linguistics (,4 CL-1990), pages157-164, 1990.\[Emele and Zajac, 1990\] Martin Emele and R~miZajac.
Typed unification grammars.
In Pro-ceedings of the 13th International Conferenceon Computational Linguistics (COLING-1990),volume 3, pages 293-298, 1990.271\[Evans and Gazdar, 1989\] Roger Evans and Ger-ald Gazdar.
Inference in DATR.
In Proceedingsof Fourth Meeting of the European Chapter ofthe Association for Computational Linguistics(EACL-1989), pages 66-71, 1989.\[Grosz el al., 1986\] Barbara Grosz, Karen SparckJones, and Bonnie Webber, editors.
Readingsin Natural Language Processing.
Morgan Kauf-mann, Los Altos, California, 1986.\[Halliday, 1985\] M. A. K. Halliday.
An Introduc-tion to Functional Grammar.
Edward Arnold,London, 1985.\[Kasper, 1989\] Robert Kasper.
A flexible interfacefor linking applications to Penman's entencegenerator.
In Proceedings of the 1989 DARPASpeech and Natural Language Workshop, pages153-158, Philadelphia, 1989.\[Kay, 1979\] Martin Kay.
Functional grammar.
InProceedings of the Fifth Meeting of the Berke-ley Linguistics Society, pages 142-158, Berkeley,CA, 17-19 Febuary 1979.\[Mann, 1983\] William Mann.
An overview of theNIGEL text generation grammar.
In Proceed-ings of the ~Ist Annual Meeting of the As-sociation for Computational Linguistics (ACL-1983), pages 79-84, 1983.\[Mann and Moore, 1981\] William Mann andJames Moore.
Computer generation of multi-paragraph English text.
American Journal ofComputational Linguistics, 7:17-29, 1981.\[McDonald, 1983\] David McDonald.
Descriptiondirected control.
Computers and Mathematics,9:111-130, 1983.\[McKeown et ai., 1990\] Kathleen McKeown,Michael Elhadad, Yumiko Fukumoto, JongLim, Christine Lombardi, Jacques Robin, andFrank Smadja.
Natural anguage generation iCOMET.
In Robert Dale, Chris Mellish, andMichael Zock, editors, Current Research in Nat-ural Language Generation, pages 103-139.
Aca~demic Press, London, 1990.\[Mellish, 1991\] Chris Mellish.
Approaches to re-alisation in natural language generation.
InE.
Klein and F. Veltman, editors, Natural Lan-guage and Speech.
Springer-Verlag, 1991.\[Moore and Paris, 1989\] Johanna Moore and Ce-cile Paris.
Planning text for advisory dialogues.In Proceedings of the 27th Annual Meeting ofthe Association for Computational Linguistics(ACL-1989), pages 203-211, 1989.\[Patten, 1988\] Terry Patten.
Systemic Text Gen-eration as Problem Solving.
Cambridge Univer-sity Press, 1988.272\[Penman Natural Language Group, 1989\]Penman Natural Language Group.
The Pen-man user guide.
Technical report, InformationSciences Institute, Marina del Rey, CA 90292,1989.\[Pereira nd Warren, 1980\] Fernando Pereira andDavid Warren.
Definite clause grammarsfor language analysis.
Artificial Intelligence,13:231-278, 1980.\[Reiter, 1990\] Ehud Reiter.
Generating descrip-tions that exploit a user's domain knowledge.
InRobert Dale, Chris Mellish, and Michael Zock,editors, Current Research in Natural LanguageGeneration, pages 257-285.
Academic Press,London, 1990.\[Reiter, 1991\] Ehud Reiter.
A new model oflexicalchoice for nouns.
Computational Intelligence,7(4), 1991.\[Reiter and Dale, 1992\] Ehud Reiter and RobertDale.
A fast algorithm for the generation of re-ferring expressions.
In Proceedings of the Four-teenth International Conference on Computa-tional Linguistics (COLING-199~), 1992.\[Reiter et al, 1992\] Ehud Reiter, Chris Mellish,and John Levine.
Automatic generation ofon-line documentation i  the IDAS project.In Proceedings of the Third Conference onApplied Natural Language Processing (ANLP-1992), pages 64-71, 1992.\[Rosch, 1978\] Eleanor Rosch.
Principles of cat-egorization.
In E. Rosch and B. Lloyd, edi-tors, Cognition and Categorization, pages 27-48.
Lawrence Erlbaum, Hillsdale, N J, 1978.\[RSsner, 1986\] Dietmar RSsner.
FAn System zurGenerierung yon deutschen Texten aus seman-tischen Repr~sentationen.
PhD thesis, Institutfiir Informatik, University of Stuttgart, 1986.\[Sheiber, 1988\] Stuart Sheiber.
A uniform archi-tecture for parsing and generation.
In Pro-ceedings of the 12th International Conferenceon Computational Linguistics (COLING-88),pages 614-619, 1988.\[Touretzky, 1986\] David Touretzky.
The Mathe-matics of Inheritance Systems.
Morgan Kauf-mann, Los Altos, California, 1986.\[Wahlster et al, 1991\] Wolfgang Wahlster, Elis-abeth Andre, Sore Bandyopadhyay, WinfriedGraf, and Thomas Rist.
WIP: The coordinatedgeneration of multimodal presentations from acommon representation.
I  Oliverio Stock, JohnSlack, and Andrew Ortony, editors, Compu-tational Theories of Communication and theirApplications.
Springer-Verlag, 1991.
