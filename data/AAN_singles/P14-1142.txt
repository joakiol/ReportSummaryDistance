Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1512?1523,Baltimore, Maryland, USA, June 23-25 2014. c?2014 Association for Computational LinguisticsA Joint Graph Model for Pinyin-to-Chinese Conversionwith Typo Correction?Zhongye Jia and Hai Zhao?MOE-Microsoft Key Laboratory for Intelligent Computing and Intelligent Systems,Center for Brain-Like Computing and Machine IntelligenceDepartment of Computer Science and Engineering, Shanghai Jiao Tong University800 Dongchuan Road, Shanghai 200240, Chinajia.zhongye@gmail.com, zhaohai@cs.sjtu.edu.cnAbstractIt is very import for Chinese language pro-cessing with the aid of an efficient inputmethod engine (IME), of which pinyin-to-Chinese (PTC) conversion is the corepart.
Meanwhile, though typos are in-evitable during user pinyin inputting, ex-isting IMEs paid little attention to such biginconvenience.
In this paper, motivated bya key equivalence of two decoding algo-rithms, we propose a joint graph model toglobally optimize PTC and typo correctionfor IME.
The evaluation results show thatthe proposed method outperforms both ex-isting academic and commercial IMEs.1 Introduction1.1 Chinese Input MethodThe daily life of Chinese people heavily dependson Chinese input method engine (IME), no matterwhether one is composing an E-mail, writing anarticle, or sending a text message.
However, ev-ery Chinese word inputted into computer or cell-phone cannot be typed through one-to-one map-ping of key-to-letter inputting directly, but has togo through an IME as there are thousands of Chi-nese characters for inputting while only 26 letterkeys are available in the keyboard.
An IME isan essential software interface that maps Chinesecharacters into English letter combinations.
An ef-?This work was partially supported by the National Natu-ral Science Foundation of China (Grant No.60903119, GrantNo.61170114, and Grant No.61272248), the National Ba-sic Research Program of China (Grant No.2013CB329401),the Science and Technology Commission of Shanghai Mu-nicipality (Grant No.13511500200), and the European UnionSeventh Framework Program (Grant No.247619).
?Corresponding authorficient IME will largely improve the user experi-ence of Chinese information processing.Nowadays most of Chinese IMEs are pinyinbased.
Pinyin is originally designed as the pho-netic symbol of a Chinese character (based on thestandard modern Chinese, mandarin) , using Latinletters as its syllable notation.
For example, thepinyin of the Chinese character ???
(love) is ?
?i?.Most characters usually have unique pinyin rep-resentations, while a few Chinese characters maybe pronounced in several different ways, so theymay have multiple pinyin representations.
The ad-vantage of pinyin IME is that it only adopts thepronunciation perspective of Chinese charactersso that it is simple and easy to learn.
But thereare only less than 500 pinyin syllables in stan-dard modern Chinese, compared with over 6,000commonly used Chinese characters, which leadsto serious ambiguities for pinyin-to-charactermap-ping.
Modern pinyin IMEsmostly use a ?sentence-based?
decoding technique (Chen and Lee, 2000)to alleviate the ambiguities.
?Sentence based?means that IME generates a sequence of Chinesecharacters upon a sequence of pinyin inputs withrespect to certain statistical criteria.1.2 Typos and Chinese Spell CheckingWritten in Chinese characters but not alphabets,spell checking for Chinese language is quite dif-ferent from the same task for other languages.Since Chinese characters are entered via IME,those user-made typos do not immediately lead tospelling errors.
When a user types a wrong letter,IME will be very likely to fail to generate the ex-pected Chinese character sequence.
Normally, theuser may immediately notice the inputting errorand then make corrections, which usually meansdoing a bunch of extra operations like cursor1512movement, deletion and re-typing.
Thus there aretwo separated sub-tasks for Chinese spell check-ing: 1. typo checking for user typed pinyin se-quences which should be a built-in module inIME, and 2. spell checking for Chinese texts inits narrow sense, which is typically a module ofword processing applications (Yang et al, 2012b).These two terms are often confused especially inIME related works such as (Chen and Lee, 2000)and (Wu et al, 2009).Pinyin typos have always been a serious prob-lem for Chinese pinyin IMEs.
The user may failto input the completely right pinyin simply be-cause he/she is a dialect speaker and does not knowthe exact pronunciation for the expected character.This may be a very common situation since thereare about seven quite different dialects in Chinese,among which being spoken languages, six are fardifferent from the standard modern Chinese, man-darin.
With the boom of smart-phones, pinyin ty-pos worsen due to the limited size of soft key-board, and the lack of physical feedback on thetouch screen.
However, existing practical IMEsonly provide small patches to deal with typos suchas Fuzzy Pinyin (Wu and Chen, 2004) and otherlanguage specific errors (Zheng et al, 2011b).Typo checking and correction has an importantimpact on IME performance.
When IME fails tocorrect a typo and generate the expected sentence,the user will have to takemuch extra effort to movethe cursor back to the mistyped letter and correct it,which leads to very poor user experience (Jia andZhao, 2013).2 Related WorksThe very first approach for Chinese input withtypo correction was made by (Chen and Lee,2000), which was also the initial attempt of?sentence-based?
IME.
The idea of ?statistical in-put method?
was proposed by modeling PTC con-version as a hidden Markov model (HMM), andusing Viterbi (Viterbi, 1967) algorithm to decodethe sequence.
They solved the typo correctionproblem by decomposing the conditional proba-bility P (H|P ) of Chinese character sequence Hgiven pinyin sequence P into a language modelP (wi|wi?1) and a typing model P (pi|wi).
Thetyping model that was estimated on real user inputdata was for typo correction.
However, real userinput data can be very noisy and not very conve-nient to obtain.
As we will propose a joint modelin this paper, such an individual typing model isnot necessarily built in our approach.
(Zheng et al, 2011a) developed an IME sys-tem with typo correction called CHIME usingnoisy channel error model and language-specificfeatures.
However their model depended on avery strong assumption that input pinyin sequenceshould have been segmented into pinyin words bythe user.
This assumption does not really hold inmodern ?sentence-based?
IMEs.
We release thisassumption since our model solves segmentation,typo correction and PTC conversion jointly.Besides the common HMM approach for PTCconversion, there are also variousmethods such as:support vector machine (Jiang et al, 2007), max-imum entropy (ME) model (Wang et al, 2006),conditional random field (CRF) (Li et al, 2009)and statistical machine translation (SMT) (Yang etal., 2012a; Wang et al, 2013c; Zhang and Zhao,2013), etc.Spell checking or typo checking was first pro-posed for English (Peterson, 1980).
(Mays et al,1991) addressed that spell checking should be donewithin a context, i.e., a sentence or a long phrasewith a certain meaning, instead of only in oneword.
A recent spell correction work is (Li et al,2006), where a distributional similarity was intro-duced for spell correction of web queries.Early attempts for Chinese spelling checkingcould date back to (Chang, 1994) where charac-ter tables for similar shape, pronunciation, mean-ing, and input-method-code characters were pro-posed.
More recently, the 7th SIGHANWorkshopon Chinese Language Processing (Yu et al, 2013)held a shared task on Chinese spell checking.
Var-ious approaches were made for the task includ-ing language model (LM) based methods (Chenet al, 2013), ME model (Han and Chang, 2013),CRF (Wang et al, 2013d; Wang et al, 2013a),SMT (Chiu et al, 2013; Liu et al, 2013), and graphmodel (Jia et al, 2013), etc.3 Pinyin Input Method Model3.1 From English Letter to Chinese SentenceIt is a rather long journey from the first Englishletter typed on the keyboard to finally a completedChinese sentence generated by IME.
We will firsttake an overview of the entire process.The average length of pinyin syllables is about 3letters.
There are about 410 pinyin syllables usedin the current pinyin system.
Each pinyin sylla-1513ble has a bunch of corresponding Chinese char-acters which share the same pronunciation repre-sented by the syllable.
The number of those homo-phones ranges from 1 to over 300.
Chinese char-acters then form words.
But word in Chinese isa rather vague concept.
Without word delimiters,linguists have argued on what a Chinese word re-ally is for a long time and that is why there is al-ways a primary word segmentation treatment inmost Chinese language processing tasks (Zhao etal., 2006; Huang and Zhao, 2007; Zhao and Kit,2008; Zhao et al, 2010; Zhao and Kit, 2011; Zhaoet al, 2013).
A Chinese word may contain from1 to over 10 characters due to different word seg-mentation conventions.
Figure 1 demonstrates therelationship of pinyin andword, from pinyin letters?nihao?
to the word ???
(hello)?.
Typically, anIME takes the pinyin input, segments it into sylla-bles, looks up corresponding words in a dictionaryand generates a sentence with the candidate words.nihao ?
?ni hao ??
Pinyin syllablesChinese charactersPinyin wordChinese wordn i h a o Pinyin charactersFigure 1: Relationship of pinyin and words3.2 Pinyin Segmentation and TypoCorrectionNon-Chinese users may feel confused or evensurprised if they know that when typing pinyinthrough an IME, Chinese IME users will never en-ter delimiters such as ?Space?
key to segment ei-ther pinyin syllables or pinyin words, but just in-put the entire un-segmented pinyin sequence.
Forexample, if one wants to input ?????
(Helloworld)?, he will just type ?nihaoshijie?
instead ofsegmented pinyin sequence ?ni hao shi jie?.
Nev-ertheless, pinyin syllable segmentation is a mucheasier problem compared to Chinese word seg-mentation.
Since pinyin syllables have a very lim-ited vocabulary and follow a set of regularitiesstrictly, it is convenient to perform pinyin sylla-ble segmentation by using rules.
But as the pinyininput is not segmented, it is nearly impossible toadopt previous spell checking methods for Englishto pinyin typo checking, although techniques forEnglish spell checking have been well developed.A bit confusing but interesting, pinyin typo cor-rection and segmentation come as two sides of oneproblem: when a pinyin sequence is mistyped, itis unlikely to be correctly segmented; when it issegmented in an awkward way, it is likely to bemistyped.Inspired by (Yang et al, 2012b) and (Jia et al,2013), we adopt the graph model for Chinese spellchecking for pinyin segmentation and typo correc-tion, which is based on the shortest path word seg-mentation algorithm (Casey and Lecolinet, 1996).The model has two major steps: segmentation andcorrection.3.2.1 Pinyin SegmentationThe shortest path segmentation algorithm is basedon the idea that a reasonable segmentation shouldminimize the number of segmented units.
For apinyin sequence p1p2.
.
.
pL, where piis a letter,first a directed acyclic graph (DAG) GS= (V,E)is built for pinyin segmentation step.
The vertexset V consists of the following parts:?
Virtual start vertex S0and end vertex SE;?
Possible legal syllables fetched from dictio-nary Dpaccording to the input pinyin se-quence:{Si,j|Si,j= pi.
.
.
pj?
Dp};?
The letter itself as a fallback no matter if it isa legal pinyin syllable or not:{Si|Si= pi}.The vertex weights wSare all set to 0.
The edgesare from a syllable to all syllables next to it:E = {E(Si,j?
Sj+1,k)|Si,j, Sj+1,k?
V}.The edge weight the negative logarithm of con-ditional probability P (Sj+1,k|Si,j) that a syllableSi,jis followed by Sj+1,k, which is give by a bi-gram language model of pinyin syllables:WE(Si,j?Sj+1,k)= ?
logP (Sj+1,k|Si,j)The shortest path P ?
on the graph is the path Pwith the least sum of weights:P?= argmin(v,E)?G?
(v,E)?P?vwv+?EWE.1514Computing the shortest path from S0to SEonGSyields the best segmentation.
This is the sin-gle source shortest path (SSSP) problem on DAGwhich has an efficient algorithm by preprocessingthe DAG with topology sort, then traversing ver-tices and edges in topological order.
It has the timecomplexity of O(|V|+ |E|).
For example, one in-tends to input ?????
(Hello world)?
by typ-ing ?nihaoshijie?, but mistyped as ?mihaoshijiw?.The graph for this input is shown in Figure 2.
Theshortest path, i.e., the best segmentation is ?mi haoshi ji w?.
We will continue to use this example inthe rest of this paper.m i h a o s h i j i whahaoaoshij im iFigure 2: Graph model for pinyin segmentation3.2.2 Pinyin Typo CorrectionNext in the correction step, for the segmentedpinyin sequence S1, S2, .
.
.
, SM, a graph Gcisconstructed to perform typo correction.
The ver-tex set V consists of the following parts:?
Virtual start vertex S?0and end vertex S?Ewithvertex weights of 0;?
All possible syllables similar to original syl-lable in Gs.
If the adjacent syllables can bemerged into a legal syllable, the merged syl-lable is also added into V:{S?i,j|S?i,j= S?i.
.
.
S?j?
Dp,S?k?
Sk, k = i ?
j},where the similarity ?
is measured in Lev-enshtein distance (Levenshtein, 1966).
Sylla-bles with Levenshtein distance under a certainthreshold are considered as similar:L(Si, Sj) < T ?
Si?
Sj.The vertex weight is the Levenshtein distancemultiply by a normalization parameter:wS?i,j= ?j?k?iL(S?k, Sk).Similar toGs, the edges are from one syllable to allsyllables next to it and edge weights are the condi-tional probabilities between them.
Computing theshortest path from S?0to S?Eon Gcyields the besttypo correction result.
In addition, the result hasbeen segmented so far.
Considering our runningexample, the graph Gcis shown in Figure 3, andthe typo correction result is ?mi hao shi jie?.whao shi j ij iem itinim ahaihu op aoshusaiz hij ia.
.
.. .
.. .
.. .
.
.
.
.. .
.
.
.
.. .
.ae.
.
.shu aij uFigure 3: Graph model for pinyin typo correctionMerely using the above model, the typo cor-rection result is not satisfying yet, no matter howmuch effort is paid.
The major reason is that thebasic semantic unit of Chinese language is actu-ally word (tough vaguely defined) which is usu-ally composed of several characters.
Thus the con-ditional probability between characters does notmake much sense.
In addition, a pinyin syllableusually maps to dozens or even hundreds of cor-responding homophonic characters, which makesthe conditional probability between syllablesmuchmore noisy.
However, using pinyin words insteadof syllables is not a wise choice because pinyinword segmentation is not so easy a task as syllablesegmentation.
To make typo correction better, weconsider to integrate it with PTC conversion usinga joint model.3.3 Hidden Markov Model forPinyin-to-Chinese ConversionPTC conversion has long been viewed as a decod-ing problem using HMM.
We continue to followthis formalization.
The best Chinese character se-quenceW ?
for a given pinyin syllable sequence Sis the one with the highest conditional probabilityP (W |S) thatW?= argmaxWP (W |S)= argmaxWP (W )P (S|W )P (S)= argmaxWP (W )P (S|W )= argmaxw1,ww,...,wM?wiP (wi|wi?1)?wiP (si|wi)1515In the HMM for pinyin IME, observation states arepinyin syllables, hidden states are Chinese words,emission probability is P (si|wi), and transitionprobability is P (wi|wi?1).
Note the transitionprobability is the conditional probability betweenwords instead of characters.
PTC conversion is todecode the Chinese word sequence from the pinyinsequence.
The Viterbi algorithm (Viterbi, 1967) isused for the decoding.The shortest path algorithm for typo correctionand Viterbi algorithm for PTC conversion are veryclosely related.
It has been strictly proven by (For-ney, 1973) that the sequence decoding problem onHMM is formally identical to finding a shortestpath on a certain graph, which can be constructedin the following manner.Consider a first order HMM with all possi-ble observations O = {o1, o2, .
.
.
, oM}, hiddenstates S = {s1, s2, .
.
.
, sN}, a special start states0, emission probabilities (Esi,ok) = P (ok|si),transition probabilities (Tsi,sj) = P (sj|si), andstart probabilities (Ssi) = P (si|s0).
For anobservation sequence of T time periods Y ={y1, y2, .
.
.
, yT|yt?
O, t = 1, .
.
.
, T}, the de-coding problem is to find the best correspondinghidden state sequence X?
with the highest proba-bility, i.e.,X?= argmaxx1,xt?SSx1Ex1,y1T?t=2Ext,ytTxt?1,xt.
(1)Thenwewill construct a DAGG = (V,E) uponthe HMM.
The vertex set V includes:?
Virtual start vertex v0and end vertex vEwithvertex weight of 0;?
Normal vertices vxt, where t = 1, .
.
.
, T , and?xt?
S. The vertex weight is the negativelogarithm of emission probability:wvxt= ?
log Ext,yt.The edge set E includes:?
Edges from the start vertexE(v0?
vx1)withedge weightWE(v0?vx1)= ?
logSx1,where ?x1?
S;?
Edges to the end vertex E(vxT?
vE) withvertex weights of 0;?
Edges between adjacent time periodsE(vxt?1?
vxt) with edge weightWE(vxt?1?vxt)= ?
log Txt?1,xt,where t = 2, .
.
.
, T , and ?xt, xt?1?
S.The shortest path P ?
from v0to vEis the one withthe least sum of vertex and edge weights, i.e.,P?= argminvxt?VT?t=1(wvxt+ WE(vxt?1?vxt))= argminvx1,vxt?V{?
logSx1?
log Ex1,y1+T?t=2(?
log Ext,yt?
log Txt?1,xt)}= argmaxvx1,vxt?VSx1Ex1,y1T?t=2Ext,ytTxt?1,xt.
(2)The optimization goal of P ?
in Equation (2) isidentical to that of X?
in Equation (1).3.4 Joint Graph Model For Pinyin IMEGiven HMM decoding problem is identical toSSSP problem on DAG, we propose a joint graphmodel for PTC conversion with typo correction.The joint graph model aims to find the global op-timal for both PTC conversion and typo correctionon the entire input pinyin sequence.
The graphG = (V,E) is constructed based on graph Gcfortypo correction in Section 3.2.
The vertex set Vconsists of the following parts:?
Virtual start vertex V0and end vertex VEwithvertex weight of 0;?
Adjacent pinyin syllables in Gcare mergedinto pinyin words.
Corresponding Chinesewords are fetched from a PTC dictionary Dc,which is a dictionary maps pinyin words toChinese words, and added as vertices:{Vi,j|?Vi,j?
Dc[S?i.
.
.
S?j], i ?
j};The vertex weight consists of two parts: 1.the vertex weights of syllables in Gc, and 2.the emission probability:wVi,j=?j?k=iL(S?k, Sk)?
?
logP (S?i.
.
.
S?j|Vi,j);1516If the corresponding pinyin syllables inGchave anedge between them, the vertices in G also have anedge:E = {E(Vi,j?
Vj+1,k)|E(Si,j?
Sj+1,k) ?
Gc}.The edge weights are the negative logarithm of thetransition probabilities:WE(Vi,j?Vj+1,k)= ?
logP (Vj+1,k|Vi,j)Although the model is formulated on first orderHMM, i.e., the LM used for transition probabil-ity is a bigram one, it is easy to extend the modelto take advantage of higher order n-gram LM, bytracking longer history while traversing the graph.Computing the shortest path from V0to VEonGyields the best pinyin-to-Chinese conversion withtypo correction result.
Considering our runningexample, the graph G is shown in Figure 4.ni?haowhao shi j ij iem itinim a haihu op aoshusaiz hij iaaeshu aij um i?hu o?
?...z hi' j ishi' j ie???
...???
...??
...??
...??
...??
...??
?...??
...???
...???
...??
...??
...??
...??
...???
...???
...??...
?
.?..???
...??
...??
...?
?...Figure 4: Joint graph modelThe joint graph is rather huge and density.
Ac-cording to our empirical statistics, when settingthreshold T = 2, for a sentence of M characters,the joint graph will have |V| = M ?
1, 000, and|E| = M ?
1, 000, 000.3.5 K-Shortest PathsTo reduce the scale of graphG, we filter graphGcby searching itsK-shortest paths first to getG?candconstruct G on top of G?c.
Figure 5 shows the 3-shortest paths filtered graphG?cand Figure 6 showsthe correspondingG for our running example.
Thescale of graph may be thus drastically reduced.hao shij ij iem inihu o z hi aFigure 5: K-shortest paths in typo correctionAn efficient heap data structure is required inK-shortest paths algorithm (Eppstein, 1998) forhao shij ij iem inihu o z hi ani?haom i?hu o z hi' j ishi' j ie??
...??...?
.?..??
...???
...??
...??
...???
...??...???
...??
...??...???
...Figure 6: Filtered graph modelbacktracking the best paths to current vertex whiletraversing.
The heap is implemented as a priorityqueue of size K sorted according to path lengththat should support efficient push and pop opera-tions.
Fibonacci heap (Fredman and Tarjan, 1987)is adopted for the heap implementation since it hasa push complexity ofO(1) which is better than theO(K) for other heap structures.Another benefit provided by K-shortest pathsis that it can be used for generating N -best can-didates of PTC conversion, which may be helpfulfor further performance improvement.4 Experiments4.1 Corpora, Tools and Experiment SettingsThe corpus for evaluation is the one providedin (Yang et al, 2012a), which is originally ex-tracted from the People?s Daily corpus and labeledwith pinyin.
The corpus has already been split intotraining T???
?, development D??
and test T??
?sets as shown in Table 1.T????
D??
T??
?#Sentence 1M 2K 100K#character 43,679,593 83,765 4,123,184Table 1: Data set sizeSRILM (Stolcke, 2002) is adopted for lan-guagemodel training andKenLM (Heafield, 2011;Heafield et al, 2013) for language model query.The Chinese part of the corpus is segmented intowords before LM training.
Maximum match-ing word segmentation is used with a large wordvocabulary V extracted from web data providedby (Wang et al, 2013b).
The pinyin part is seg-mented according to the Chinese part.
This vo-cabulary V also serves as the PTC dictionary.
Theoriginal vocabulary is not labeled with pinyin, thuswe use the PTC dictionary of sunpinyin1 which isan open source Chinese pinyin IME, to label the1http://code.google.com/p/sunpinyin/1517vocabulary V with pinyin.
The emission proba-bilities are estimated using the lexical translationmodule of MOSES (Koehn et al, 2007) as ?trans-lation probability?
from pinyin to Chinese.4.2 Evaluation MetricsWewill use conventional sequence labeling evalu-ation metrics such as sequence accuracy and char-acter accuracy2.Chinese characters in a sentence may be sepa-rated by digits, punctuation and alphabets whichare directly inputted without the IME.
We fol-low the so-called term Max Input Unit (MIU), thelongest consecutive Chinese character sequenceproposed by (Jia and Zhao, 2013).
We will mainlyconsider MIU accuracy (MIU-Acc) which is theratio of the number of completely corrected gen-erated MIUs over the number of all MIUs, andcharacter accuracy (Ch-Acc), but the sentence ac-curacy (S-Acc) will also be reported in evaluationresults.We will also report the conversion errorrate (ConvER) proposed by (Zheng et al, 2011a),which is the ratio of the number of mistyped pinyinword that is not converted to the right Chineseword over the total number of mistyped pinyinwords3.4.3 Baseline System without Typo CorrectionFirstly we build a baseline system without typocorrection which is a pipeline of pinyin syllablesegmentation and PTC conversion.
The baselinesystem takes a pinyin input sequence, segments itinto syllables, and then converts it to Chinese char-acter sequence.The pinyin syllable segmentation already hasvery high (over 98%) accuracy with a trigram LMusing improved Kneser-Ney smoothing.
Accord-ing to our empirical observation, emission prob-abilities are mostly 1 since most Chinese wordshave unique pronunciation.
So in this step we set?
= 0.
We consider different LM smoothingmethods including Kneser-Ney (KN), improvedKneser-Ney (IKN), and Witten-Bell (WB).
All ofthe three smoothing methods for bigram and tri-gram LMs are examined both using back-off mod-2We only work on the PTC conversion part of IME, thuswe are unable to use existing evaluation systems (Jia andZhao, 2013) for full Chinese IME functions.3Other evaluation metrics are also proposed by (Zheng etal., 2011a) which is only suitable for their system since oursystem uses a joint modelels and interpolated models.
The number of N -best candidates for PTC conversion is set to 10.The results on D??
are shown in Figure 7 in whichthe ?-i?
suffix indicates using interpolated model.According to the results, we then choose the tri-gram LM using Kneser-Ney smoothing with inter-polation.0.620.640.660.680.70.720.74KN KN-i IKN IKN-i WB WB-i0.9440.9460.9480.950.9520.9540.9560.9580.960.9620.964MIU-Acc Ch-AccMIU-Acc-bigramCh-Acc-bigramMIU-Acc-trigramCh-Acc-trigramFigure 7: MIU-Acc and Ch-Acc with different LMsmoothingThe choice of the number of N -best candidatesfor PTC conversion also has a strong impact on theresults.
Figure 8 shows the results onD?
?with dif-ferentNs, of which theN axis is drawn in logarith-mic scale.
We can observe that MIU-Acc slightlydecreases whileN goes up, but Ch-Acc largely in-creases.
We therefore chooseN = 10 as trade-off.0.72650.7270.72750.7280.72850.7290.72950.730.73050.7310.73150.7321  10  100  10000.9350.940.9450.950.9550.960.9650.970.9750.980.985MIU-Acc Ch-AccMIU-AccCh-AccFigure 8: MIU-Acc and Ch-Acc with differentNsThe parameter ?
determines emission probabil-ity.
Results with different ?
on D??
is shown inFigure 9, of which the ?
axis is drawn in logarith-mic scale.
?
= 0.03 is chosen at last.We compare our baseline system with severalpractical pinyin IMEs including sunpinyin andGoogle Input Tools (Online version)4.
The resultson D??
are shown in Table 2.4http://www.google.com/inputtools/try/15180.450.50.550.60.650.70.750.001  0.01  0.1  10.820.840.860.880.90.920.940.960.98MIU-Acc Ch-AccMIU-AccCh-AccFigure 9: MIU-Acc and Ch-Acc with different ?MIU-Acc Ch-Acc S-AccBaseline 73.39 96.24 38.00sunpinyin 52.37 87.51 13.95Google 74.74 94.81 40.2Yang-ME - 93.3 30.2Yang-MT - 95.5 45.4Table 2: Baseline system compared to otherIMEs (%)4.4 PTC Conversion with Typo CorrectionBased upon the baseline system, we build the jointsystem of PTC conversion with typo correction.We simulate user typos by randomly generatingerrors automatically on the corpus.
The typo rateis set according to previous Human-Computer In-teraction (HCI) studies.
Due to few works havebeen done on modeling Chinese text entry, wehave to refer to those corresponding results onEnglish (Wobbrock and Myers, 2006; MacKen-zie and Soukoreff, 2002; Clarkson et al, 2005),which show that the average typo rate is about 2%.
(Zheng et al, 2011a) performed an experiment that2,000 sentences of 11,968 Chinese words were en-tered by 5 native speakers.
The collected data con-sists of 775 mistyped pinyin words caused by oneedit operation, and 85 caused by two edit opera-tions.
As we observe on T????
that the averagepinyin word length is 5.24, then typo rate in theexperiment of (Zheng et al, 2011a) can be roughlyestimated as:775 + 85?
211968?
5.24= 1.51%,which is similar to the conclusion on English.
Thuswe generate corpora from D??
with typo rate of0% (0-P), 2% (2-P), and 5% (5-P) to evaluate thesystem.According to (Zheng et al, 2011a) mostmistyped pinyin words are caused by one edit op-eration.
Since pinyin syllable is much shorter thanpinyin word, this ratio can be higher for pinyinsyllables.
From our statistics on T???
?, with 2%randomly generated typos, Pr(L(S?, S) < 2) =99.86%.
Thus we set the threshold T for L to 2.We first set K-shortest paths filter to K = 10and tune ?.
Results with different ?
are shownin Figure 10.
With ?
= 3.5, we select K. Re-0.70.7050.710.7150.720.7250.730.7350.740.7452  2.5  3  3.5  4  4.5  50.9540.9560.9580.960.9620.9640.9660.9680.97MIU-Acc Ch-AccMIU-AccCh-Acc(a) 0-P0.6650.670.6750.680.6850.690.6952  2.5  3  3.5  4  4.5  50.9320.9340.9360.9380.940.9420.9440.946MIU-Acc Ch-AccMIU-AccCh-Acc(b) 2-P0.5850.590.5950.60.6050.610.6152  2.5  3  3.5  4  4.5  50.8720.8740.8760.8780.880.8820.8840.8860.888MIU-Acc Ch-AccMIU-AccCh-Acc(c) 5-PFigure 10: MIU-Acc and Ch-Acc with different ?sults with differentK are shown in Figure 11.
Wechoose K = 20 since there is no significant im-provement when K > 20.The selection of K also directly guarantees therunning time of the joint model.
With K = 20,on a normal PC with Intel Pentium Dual-CoreE6700 CPU, the PTC conversion rate is over 2000characters-per-minute (cpm), which is much fasterthan the normal typing rate of 200 cpm.With all parameters optimized, results on T??
?15190.7050.710.7150.720.7250.730.7350.740.7450  10  20  30  40  50  60  70  80  90  100 0.9540.9560.9580.960.9620.9640.9660.968MIU-Acc Ch-AccMIU-AccCh-Acc(a) 0-P0.6550.660.6650.670.6750.680.6850.690.6950.70  10  20  30  40  50  60  70  80  90  100 0.920.9250.930.9350.940.945MIU-Acc Ch-AccMIU-AccCh-Acc(b) 2-P0.550.560.570.580.590.60.610  10  20  30  40  50  60  70  80  90  100 0.850.8550.860.8650.870.8750.880.8850.89MIU-Acc Ch-AccMIU-AccCh-Acc(c) 5-PFigure 11: MIU-Acc and Ch-Acc with differentKusing the proposed joint model are shown in Ta-ble 3 and Table 4.
Our results are compared tothe baseline system without typo correction andGoogle Input Tool.
Since sunpinyin does not havetypo correction module and performs much poorerthan our baseline system, we do not include it inthe comparison.
Though no direct proofs can befound to indicate if Google Input Tool has an in-dependent typo correction component, its outputsshow that such a component is unlikely available.Since Google Input Tool has to be accessedthrough a web interface and the network connec-tion cannot be guaranteed.
we only take a subsetof 10K sentences of T???
to perform the experi-ments, and the results are shown in Table 3.The scores reported in (Zheng et al, 2011a) arenot listed in Table 4 since the data set is differ-ent.
They reported a ConvER of 53.56%, which isgiven here for reference.Additionally, to further inspect the robustness ofourmodel, performance with typo rate ranges from0% to 5% is shown in Figure 12.
Although the per-formance decreases while typo rate goes up, it isstill quite satisfying around typo rate of 2% whichis assumed to be the real world situation.MIU-Acc Ch-Acc S-Acc ConvERBaseline 0-P 79.90 97.47 48.87 -Baseline 2-P 50.47 90.53 11.12 99.95Baseline 5-P 30.26 82.83 3.32 99.99Google 0-P 79.08 95.26 46.83 -Google 2-P 49.47 61.50 11.08 91.70Google 5-P 29.18 36.20 3.29 94.64Joint 0-P 79.90 97.52 49.27 -Joint 2-P 75.55 95.40 40.69 18.45Joint 5-P 67.76 90.17 27.86 24.68Table 3: Test results on 10K sentences from T???
(%)MIU-Acc Ch-Acc S-Acc ConvERBaseline 0-P 74.46 96.42 40.50 -Baseline 2-P 47.25 89.50 9.62 99.95Baseline 5-P 28.28 81.74 2.63 99.98Joint 2-P 74.22 96.39 40.34 -Joint 2-P 69.91 94.14 33.11 21.35Joint 5-P 62.14 88.49 22.62 27.79Table 4: Test results on T???
(%)00.20.40.60.811.20  1  2  3  4  500.20.40.60.811.2MIU-Acc Ch-AccMIU-AccCh-AccFigure 12: MIU-Acc and Ch-Acc with differenttypo rate (%)5 ConclusionIn this paper, we have developed a joint graphmodel for pinyin-to-Chinese conversion with typocorrection.
This model finds a joint global opti-mal for typo correction and PTC conversion on theentire input pinyin sequence.
The evaluation re-sults show that our model outperforms both pre-vious academic systems and existing commercialproducts.
In addition, the joint model is efficientenough for practical use.1520ReferencesRichard G. Casey and Eric Lecolinet.
1996.
A Sur-vey of Methods and Strategies in Character Segmen-tation.
Pattern Analysis and Machine Intelligence,IEEE Transactions on, 18(7):690?706.Chao-Huang Chang.
1994.
A Pilot Study on Auto-matic Chinese Spelling Error Correction.
Journal ofChinese Language and Computing, 4:143?149.Zheng Chen and Kai-Fu Lee.
2000.
A New Statis-tical Approach To Chinese Pinyin Input.
In Pro-ceedings of the 38th Annual Meeting of the Associa-tion for Computational Linguistics, pages 241?247,Hong Kong, October.Kuan-YuChen, Hung-Shin Lee, Chung-HanLee, Hsin-Min Wang, and Hsin-Hsi Chen.
2013.
A Studyof Language Modeling for Chinese Spelling Check.In Proceedings of the Seventh SIGHAN Workshopon Chinese Language Processing, pages 79?83,Nagoya, Japan, October.
Asian Federation of Nat-ural Language Processing.Hsun-wen Chiu, Jian-cheng Wu, and Jason S. Chang.2013.
Chinese Spelling Checker Based on Statis-tical Machine Translation.
In Proceedings of theSeventh SIGHAN Workshop on Chinese LanguageProcessing, pages 49?53, Nagoya, Japan, October.Asian Federation of Natural Language Processing.Edward Clarkson, James Clawson, Kent Lyons, andThad Starner.
2005.
An Empirical Study of Typ-ing Rates onmini-QWERTYKeyboards.
InCHI ?05Extended Abstracts onHuman Factors in ComputingSystems, CHI EA ?05, pages 1288?1291, New York,NY, USA.
ACM.David Eppstein.
1998.
Finding the K Shortest Paths.SIAM Journal on computing, 28(2):652?673.Jr G. David Forney.
1973.
The Viterbi Algorithm.Proceedings of the IEEE, 61(3):268?278.Michael L. Fredman and Robert Endre Tarjan.
1987.Fibonacci Heaps and Their Uses in Improved Net-work Optimization Algorithms.
Journal of the ACM(JACM), 34(3):596?615, July.Dongxu Han and Baobao Chang.
2013.
A Maxi-mum Entropy Approach to Chinese Spelling Check.In Proceedings of the Seventh SIGHAN Workshopon Chinese Language Processing, pages 74?78,Nagoya, Japan, October.
Asian Federation of Nat-ural Language Processing.Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.Clark, and Philipp Koehn.
2013.
Scalable ModifiedKneser-Ney Language Model Estimation.
In Pro-ceedings of the 51st Annual Meeting of the Associa-tion for Computational Linguistics, pages 690?696,Sofia, Bulgaria, August.Kenneth Heafield.
2011.
KenLM: Faster and SmallerLanguage Model Queries.
In Proceedings of theEMNLP 2011 Sixth Workshop on Statistical Ma-chine Translation, pages 187?197, Edinburgh, Scot-land, United Kingdom, July.Changning Huang and Hai Zhao.
2007.
Chinese WordSegmentation: A Decade Review.
Journal of Chi-nese Information Processing, 21(3):8?20.Zhongye Jia and Hai Zhao.
2013.
KySS 1.0: aFramework for Automatic Evaluation of Chinese In-put Method Engines.
In Proceedings of the Sixth In-ternational Joint Conference on Natural LanguageProcessing, pages 1195?1201, Nagoya, Japan, Octo-ber.
Asian Federation of Natural Language Process-ing.Zhongye Jia, Peilu Wang, and Hai Zhao.
2013.
GraphModel for Chinese Spell Checking.
In Proceedingsof the Seventh SIGHAN Workshop on Chinese Lan-guage Processing, pages 88?92, Nagoya, Japan, Oc-tober.
Asian Federation of Natural Language Pro-cessing.Wei Jiang, Yi Guan, Xiaolong Wang, and BingQuanLiu.
2007.
PinYin-to-Character Conversion Modelbased on Support Vector Machines.
Journal of Chi-nese information processing, 21(2):100?105.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-dra Constantin, and Evan Herbst.
2007.
Moses:Open Source Toolkit for Statistical Machine Trans-lation.
In Proceedings of the 45th Annual Meeting ofthe Association for Computational Linguistics Com-panion Volume Proceedings of the Demo and PosterSessions, pages 177?180, Prague, Czech Republic,June.
Association for Computational Linguistics.Vladimir I. Levenshtein.
1966.
Binary Codes Capableof Correcting Deletions, Insertions and Reversals.
InSoviet physics doklady, volume 10, page 707.Mu Li, Muhua Zhu, Yang Zhang, and Ming Zhou.2006.
Exploring Distributional Similarity BasedModels for Query Spelling Correction.
In Proceed-ings of the 21st International Conference on Compu-tational Linguistics and 44th Annual Meeting of theAssociation for Computational Linguistics, pages1025?1032, Sydney, Australia, July.
Association forComputational Linguistics.Lu Li, Xuan Wang, Xiao-Long Wang, and Yan-BingYu.
2009.
A Conditional Random Fields Approachto Chinese Pinyin-to-Character Conversion.
Journalof Communication and Computer, 6(4):25?31.Xiaodong Liu, Kevin Cheng, Yanyan Luo, Kevin Duh,and Yuji Matsumoto.
2013.
A Hybrid ChineseSpelling Correction Using LanguageModel and Sta-tisticalMachine Translation with Reranking.
InPro-ceedings of the Seventh SIGHAN Workshop on Chi-nese Language Processing, pages 54?58, Nagoya,Japan, October.
Asian Federation of Natural Lan-guage Processing.1521I.
Scott MacKenzie and R.William Soukoreff.
2002.
ACharacter-level Error Analysis Technique for Eval-uating Text Entry Methods.
In Proceedings of theSecond Nordic Conference on Human-computer In-teraction, NordiCHI ?02, pages 243?246, NewYork,NY, USA.
ACM.Eric Mays, Fred J Damerau, and Robert L Mercer.1991.
Context Based Spelling Correction.
Informa-tion Processing & Management, 27(5):517?522.James L. Peterson.
1980.
Computer Programs for De-tecting and Correcting Spelling Errors.
Commun.ACM, 23(12):676?687, December.Andreas Stolcke.
2002.
SRILM-An Extensible Lan-guage Modeling Toolkit.
In Proceedings of the in-ternational conference on spoken language process-ing, volume 2, pages 901?904.Andrew J. Viterbi.
1967.
Error Bounds for Con-volutional Codes and an Asymptotically OptimumDecoding Algorithm.
Information Theory, IEEETransactions on, 13(2):260?269.Xuan Wang, Lu Li, Lin Yao, and Waqas Anwar.
2006.A Maximum Entropy Approach to Chinese Pin Yin-To-Character Conversion.
In Systems, Man and Cy-bernetics, 2006.
SMC?06.
IEEE International Con-ference on, volume 4, pages 2956?2959.
IEEE.Chun-Hung Wang, Jason S. Chang, and Jian-ChengWu.
2013a.
Automatic Chinese Confusion WordsExtractionUsing Conditional RandomFields and theWeb.
In Proceedings of the Seventh SIGHANWork-shop on Chinese Language Processing, pages 64?68, Nagoya, Japan, October.
Asian Federation ofNatural Language Processing.Peilu Wang, Ruihua Sun, Hai Zhao, and Kai Yu.2013b.
A New Word Language Model EvaluationMetric for Character Based Languages.
In ChineseComputational Linguistics and Natural LanguageProcessing Based on Naturally Annotated Big Data,pages 315?324.
Springer.Rui Wang, Masao Utiyama, Isao Goto, Eiichro Sumita,Hai Zhao, and Bao-Liang Lu.
2013c.
ConvertingContinuous-Space Language Models into N-GramLanguage Models for Statistical Machine Transla-tion.
In Proceedings of the 2013 Conference on Em-pirical Methods in Natural Language Processing,pages 845?850, Seattle, Washington, USA, October.Association for Computational Linguistics.Yih-Ru Wang, Yuan-Fu Liao, Yeh-Kuang Wu, andLiang-Chun Chang.
2013d.
Conditional RandomField-based Parser and Language Model for Tradi-tional Chinese Spelling Checker.
In Proceedingsof the Seventh SIGHAN Workshop on Chinese Lan-guage Processing, pages 69?73, Nagoya, Japan, Oc-tober.
Asian Federation of Natural Language Pro-cessing.Jacob O.Wobbrock and Brad A.Myers.
2006.
Analyz-ing the Input Stream for Character- Level Errors inUnconstrained Text Entry Evaluations.
ACM Trans.Comput.-Hum.
Interact., 13(4):458?489, December.Jun Wu and Liren Chen.
2004.
Fault-tolerant Roman-ized Input Method for Non-roman Characters, Au-gust 25.
US Patent App.
10/928,131.Jun Wu, Hulcan Zhu, and Hongjun Zhu.
2009.
Sys-tems and Methods for Translating Chinese Pinyinto Chinese Characters, January 13.
US Patent7,478,033.Shaohua Yang, Hai Zhao, and Bao-liang Lu.
2012a.
AMachine Translation Approach for Chinese Whole-Sentence Pinyin-to-Character Conversion.
In Pro-ceedings of the 26th Pacific Asia Conference on Lan-guage, Information, and Computation, pages 333?342, Bali,Indonesia, November.
Faculty of Com-puter Science, Universitas Indonesia.ShaohuaYang, Hai Zhao, XiaolinWang, and Bao-liangLu.
2012b.
Spell Checking for Chinese.
In Interna-tional Conference on Language Resources and Eval-uation, pages 730?736, Istanbul, Turkey, May.Liang-Chih Yu, Yuen-Hsien Tseng, Jingbo Zhu, andFuji Ren, editors.
2013.
Proceedings of the SeventhSIGHAN Workshop on Chinese Language Process-ing.
Asian Federation of Natural Language Process-ing, Nagoya, Japan, October.Jingyi Zhang and Hai Zhao.
2013.
Improving Func-tion Word Alignment with Frequency and Syntac-tic Information.
In Proceedings of the Twenty-Thirdinternational joint conference on Artificial Intelli-gence, pages 2211?2217.
AAAI Press.Hai Zhao and Chunyu Kit.
2008.
Exploiting UnlabeledText with Different Unsupervised Segmentation Cri-teria for Chinese Word Segmentation.
Research inComputing Science, 33:93?104.Hai Zhao and Chunyu Kit.
2011.
Integrating Unsu-pervised and Supervised Word Segmentation: TheRole of Goodness Measures.
Information Sciences,181(1):163?183.Hai Zhao, Chang-Ning Huang, and Mu Li.
2006.
AnImproved Chinese Word Segmentation System withConditional Random Field.
In Proceedings of theFifth SIGHANWorkshop on Chinese Language Pro-cessing, pages 162?165, Sydney, Australia, July.Association for Computational Linguistics.Hai Zhao, Chang-Ning Huang, Mu Li, and Bao-LiangLu.
2010.
A Unified Character-Based TaggingFramework for Chinese Word Segmentation.
ACMTransactions on Asian Language Information Pro-cessing (TALIP), 9(2):5.Hai Zhao, Masao Utiyama, Eiichiro Sumita, and Bao-Liang Lu.
2013.
An Empirical Study on WordSegmentation for Chinese Machine Translation.
InComputational Linguistics and Intelligent Text Pro-cessing, pages 248?263.
Springer.1522Yabin Zheng, Chen Li, and Maosong Sun.
2011a.CHIME: An Efficient Error-tolerant Chinese PinyinInput Method.
In Proceedings of the Twenty-SecondInternational Joint Conference on Artificial Intel-ligence - Volume Volume Three, IJCAI?11, pages2551?2556.
AAAI Press.Yabin Zheng, Lixing Xie, Zhiyuan Liu, Maosong Sun,Yang Zhang, and Liyun Ru.
2011b.
Why PressBackspace?
Understanding User Input Behaviors inChinese Pinyin Input Method.
In Proceedings of the49th Annual Meeting of the Association for Compu-tational Linguistics: Human Language Techologies,pages 485?490, Portland, Oregon, USA, June.
Asso-ciation for Computational Linguistics.1523
