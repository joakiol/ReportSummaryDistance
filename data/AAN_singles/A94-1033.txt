Degraded Text Recognit ion Using Word Collocationand Visual Inter-Word ConstraintsTao Hong and Jonathan  J .
Hu l lCenter  of Excel lence for Document  Analysis and Recognit ionDepar tment  of Computer  ScienceState  Univers i ty  of New York at BuffaloBuffalo, New York 14260taohong@cs.buffalo, edu hull?cs.buffalo, eduAbst ractGiven a noisy text page, a word recognizer can generatea set of candidates for each word image.
A relaxationalgorithm was proposed previously by the authors thatuses word collocation statistics to select the candidatefor each word that has the highest probability of beingthe correct decision.
Because word collocation is a lo-cal constraint and collocation data trained from corporaare usually incomplete, the algorithm cannot select hecorrect candidates for some images.
To overcome thislimitation, contextual information at the image level isnow exploited inside the relaxation algorithm.
If twoword images can match with each other, they shouldhave same symbolic identity.
Visual inter-word rela-tions provide a way to link word images in the text andto interpret them systematically.
By integrating visualinter-word constraints with word collocation data, theperformance of the relaxation algorithm is improved.In t roduct ionWord collocation is one source of information that hasbeen proposed as a useful tool to post-process wordrecognition results(\[1, 4\]).
It can be considered as aconstraint on candidate selection so that the word can-didate selection problem can be formalized as an in-stance of constraint satisfaction.
Relaxation is a typ-ical method for constraint satisfaction problems.
Oneof the advantages of relaxation is that it can achieve aglobal effect by using local constraints.Previously, a probabilistic relaxation algorithmwas proposed for word candidate re-evaluation andselection(\[2\]).
The basic idea of the algorithm is to useword collocation constraints to select the word candi-dates that have a high probability of occurring simulta-neously with word candidates at other nearby locations.The algorithm runs iteratively.
In each iteration, theprobability of each word candidate is upgraded basedon its previous probability, the probabilities of its neigh-bors and word collocation data.
The initial probabilityof each word candidate isprovided by a word recognizer.The relaxation process terminates when the probabil-ity of each word candidate becomes stable.
After relax-ation finishes, for each word image, the word candidatewith highest probabilistic score will be selected as thedecision word.Because the window size of word collocation isusuallysmall, word collocation is a local constraint.
Becauseword collocation data are derived from text corpora, itusually is incomplete and unbalanced.
Those propertieslimit the usefulness of word collocation for candidate se-lection.
By analyzing the performance ofthe algorithm,three sources of errors were identified: (1).
the localcontext cannot provide enough information to distin-guish the competitive candidates; (2).
word collocationdata trained from corpora are not complete so that itdoes not include the statistical data needed to selectthe correct candidate; and (3).
word collocation datatrained from unbalanced corpora re biased so that thewrong candidate is selected.In a normal English text, there are many occurrencesof the same words.
Because the main body of a text isusually prepared in the same font type, different occur-rences of the same word are visually similar even if thetext image is highly degraded.Visual similarity between word images can place use-ful constraints on the process of candidate selection(\[3\]).If two word images can match with each other, theiridentities hould be the same.
For example, if thereare two sentences, "Please fill in the application X "and "This Y is almost the same as that one", where Xand Y are visually similar, and both of them have thecandidate set { farm, form } .
The candidate "form"can be easily selected as the decision for X and Y if weconsider both word collocation and visual inter-wordconstraints, although it is difficult to select a candidatefor Y by only using word collocation.Modif ied Relaxat ion Algor i thmFigure 1 is the description of the new relaxation algo-rithm that integrates word collocation and visuM inter-word constraints for candidate selection.
Given a se-quence of word images from a text page, the first step of186the algorithm is word image clustering.
Then, a wordrecognizer is applied to the prototype for each imagecluster to generate a set of word candidates.
Each wordinside a cluster inherits the candidate set for the cluster.In an iteration of relaxation, the probabilistic scores ofthe candidates for a word image are upgraded basedon word collocation data.
The probabilistic scores ofthe candidates for a cluster are upgraded by summingup the probabilistic scores of the word images insidethe cluster.
Each word image then inherits the candi-date set from the cluster it belongs to.
When there isno further significant change in the confidence scores,the relaxation stops.
The top candidate for each wordimage is selected as the decision.INPUT:  A sequence of word images W/i/, 1 _< i < n;OUTPUT:  W/if.decision, i = 1, 2, ...n/*Word Image Clustering*/ClusterList *-- {};FOR i=l  to n DOFoundMatch 4- FALSE;FOR each cluster C/j/ in ClusterList DOIF( Distance(W/if.image, C\[j\].prototype) < threshold )C\[i\].ImageList *- C\[j\].ImageList t9 W/i/;W\[i\].ClusterIndex *-- j;FoundMatch ,-- TRUE;IF ( FoundMatch =---- FALSE )Create a new cluster C/k/;C\[k\].ImageList *---W/i/;W\[i\].Clusterlndex *--- k;ClusterList ~ ClusterList .I C/k/;/*Isolated Word Recognit ion-Candidate G neration*/FOR each cluster C/j/ in ClusterList DOC\[j\].CandidateList ~ WordRecognition(C\[j\].prototype);Sort candidates in C\[j\].CandidateList in decreasing order;IterationCount ~ 0;REPEATIterationCount *-- IterationCount + 1;/* Generate Word Lattice */FOR each word image W/i/ DOW\[i\].CandidateList *-- C\[W\[i\].ClusterIndex\].CandidateList;/*  Upgrade Confidence Scores For Candidates Of Word Images*/FOR each word image W/i/ DOFOR each word candidate w/m/ in W\[i\].CandidateList DOUpgrade w\[m\].prob by using word collocation;/*  Upgrade Confidence Scores For Candidates Of Clusters*/FOR each cluster C/j/ in ClusterList DOFOR each candidate c/n/ in C\[j\].CandidateList DOc\[n\].prob ,--- 0.0;FOR each word image W/i/ in C\[j\].ImageList DOFOR each word candidate w/m/ in W\[i\].CandidateList DOIF( c\[n\].string == w\[m\].string )c\[n\].prob ~ c\[n\].prob + w\[m\].prob;Sort candidates in C\[j\].CandidateList in decreasing order;UNTIL probabilistic scores of word candidates become stable;/*  Select Best Candidate For Word Image */FOR each word image W/i/ DOW/if.decision ,---C andidateWit hHighest Score( C/W/i/.ClusterIndex\] .CandidateList);ENDFigure 1: Augmented Relaxation AlgorithmExper iments  and  Ana lys i sFive articles from the Brown Corpus, A06, GO2, J42,NO1 and ROT, were randomly selected as testing sam-ples.
There are totally 11,402 words in those testingsamples.
For each word, a topl0 candidate list was gen-erated.
The topl  correct rate is around 55% on highlydegraded text.
Word collocation data was trained fromthe Penn Treebank and the Brown Corpus after remov-ing the testing samples.
We used the frequency of aword pair to measure its collocation strength.
Thereare totally 1,200,000 unique word pairs after training.The result of applying the relaxation algorithm to thenoisy text images is shown in Table 1.
The topl  correctrate of word recognition is as low as 57%.
Relaxationbased on word collocation can improve topl  correct rateto 83%.
After integrating word collocation and visualconstraints, the correct rate of the first choice can befurther improved to 88%.
There is overall 5% improve-ment by introducing visual contextual constraints.top1 top2 top3 top5WordRecognition 57.10% 78.47% 87.51% 92.47%OriginalRe laxat ion  83.19% 92.99% 96.47% 98.61%AugmentedRe laxat ion  88.22% 94.99% 97.37% 98.91%Table 1: Relaxation ResultsConc lus ionsA word-collocation-based r laxation algorithm was pro-posed for candidate selection in degraded text recogni-tion.
Word collocation is a local statistical constraint,which sometimes i not sufficient o distinguish amongthe candidates.
To make candidate selection more accu-rate, visual inter-word constraints are investigated.
Anew relaxation algorithm augmented with visual inter-word constraints was designed.
Experimental resultsshowed that the modified algorithm has better perfor-mance.References\[1\] K. W. Church and P. Hanks, "Word Association Norms, Mu-tual Information, and Lexicography," Computational Linguis-tics, Vol.
16, No.
1, pp.
22-29, 1990.\[2\] T. Hong and J. J.
Hull, "Degraded Text Recognition Using WordCollocation", in Proceedings of the Conference on DocumentRecognition of 1994 ISf~T/SPIE Symposium, San Jose, CA,February 6-10, 1994.\[3\] T. Hong, "Integration Of Visual Inter-Word Constraints And Lin-guistic Knowledge In Degraded Text Recognition", in Proceed-ings of 32nd Annual Meeting of Association for ComputationalLinguistics, pp.
328-330, Los Cruces, New Mexico, 27-30 June,1994(in Student Session).\[4\] T. G. Rose and L. J. Evett, "Text Recognition Using Collocationsand Domain Codes," in Proceedings of the Workshop on VeryLarge Corpora: Academic and Industrial Perspectives, pp.
65-73, Columbus, Ohio, 1993.187
