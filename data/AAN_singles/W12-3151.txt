Proceedings of the 7th Workshop on Statistical Machine Translation, pages 395?400,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsData Issues of the Multilingual Translation MatrixDaniel ZemanCharles University in Prague, Faculty of Mathematics and Physics,Institute of Formal and Applied LinguisticsMalostransk?
n?m?st?
25, CZ-11800 Praha, Czechiazeman@ufal.mff.cuni.czAbstractWe describe our experiments with phrase-based machine translation for the WMT2012 Shared Task.
We trained one sys-tem for 14 translation directions betweenEnglish or Czech on one side and English,Czech, German, Spanish or French on theother side.
We describe a set of resultswith different training data sizes and sub-sets.1 IntroductionWith so many official languages, Europe is aparadise for machine translation research.
Oneof the largest bodies of electronically availableparallel texts is being nowadays generated bythe European Union and its institutions.
At thesame time, the EU also provides motivation andboosts potential market for machine translationoutcomes.Most of the major European languages belongto one of three branches of the Indo-Europeanlanguage family: Germanic, Romance or Slavic.Such relatedness is responsible for many struc-tural similarities in European languages, al-though significant differences still exist.
Withinthe language portfolio selected for the WMTshared task, English, French and Spanish seemto be closer to each other than to the rest.German, despite being genetically related toEnglish, differs in many properties.
Its word or-der rules, shifting verbs from one end of the sen-tence to the other, easily create long-distance de-pendencies.
Long German compound words arenotorious for increasing out-of-vocabulary rate,which has led many researchers to devising unsu-pervised compound-splitting techniques.
Also,uppercase/lowercase distinction is more impor-tant because all German nouns start with anuppercase letter by the rule.Czech is a language with rich morphology(both inflectional and derivational) and rela-tively free word order.
In fact, the predicate-argument structure, often encoded by fixed wordorder in English, is usually captured by inflec-tion (especially the system of 7 grammaticalcases) in Czech.
While the free word order ofCzech is a problem when translating to English(the text should be parsed first in order to de-termine the syntactic functions and the Englishword order), generating correct inflectional af-fixes is indeed a challenge for English-to-Czechsystems.
Furthermore, the multitude of possibleCzech word forms (at least order of magnitudehigher than in English) makes the data sparse-ness problem really severe, hindering both direc-tions.Our goal is to run one system under as similarconditions as possible to all fourteen translationdirections, to compare their translation accura-cies and see why some directions are easier thanothers.
Future work will benefit from knowingwhat are the special processing needs for a givenlanguage pair.
The current version of the systemdoes not include really language-specific tech-niques: we neither split German compounds,nor do we address the peculiarities of Czechmentioned above.3952 The Translation SystemOur translation system is built around Moses1(Koehn et al, 2007).
Two-way word align-ment was computed using GIZA++2 (Och andNey, 2003), and alignment symmetrization us-ing the grow-diag-final-and heuristic (Koehn etal., 2003).
Weights of the system were optimizedusing MERT (Och, 2003).
No lexical reorderingmodel was trained.For language modeling we use the SRILMtoolkit3 (Stolcke, 2002) with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chenand Goodman, 1998).3 Data and Pre-processing PipelineWe applied our system to all the eight offi-cial language pairs.
In addition, we also ex-perimented with translation between Czech onone side and German, Spanish or French onthe other side.
Training data for these addi-tional language pairs were obtained by combin-ing parallel corpora of the officially supportedpairs.
For instance, to create the Czech-Germanparallel corpus, we identified the intersection ofthe English sides of Czech-English and English-German corpora, respectively; then we com-bined the corresponding Czech and German sen-tences.We took part in the constrained task.
Un-less explicitly stated otherwise, the translationmodel in our experiments was trained on thecombined News-Commentary v7 and Europarlv7 corpora.4 Table 1 shows the sizes of the train-ing data.The News Test 2010 data set5 (2489 sentencesin each language) was used as development datafor MERT.
BLEU scores reported in this paperwere computed on the News Test 2012 set (3003sentences each language).
We do not use theNews Tests 2008, 2009 and 2011.1http://www.statmt.org/moses/2http://code.google.com/p/giza-pp/3http://www-speech.sri.com/projects/srilm/4http://www.statmt.org/wmt12/translation-task.html\#download5http://www.statmt.org/wmt12/translation-task.htmlCorpus SentPairs Tokens lng1 Tokens lng2cs-en 782,756 17,997,673 20,964,639de-en 2,079,049 55,143,719 57,741,141es-en 2,123,036 61,784,972 59,217,471fr-en 2,144,820 69,568,241 59,939,548de-cs 652,193 17,422,620 15,383,601es-cs 692,118 20,189,811 16,324,910fr-cs 686,300 22,220,780 16,190,365Table 1: Number of sentence pairs and tokens forevery language pair in the parallel training corpus.Languages are identified by their ISO 639 codes: cs= Czech, de = German, en = English, es = Spanish,fr = French.
Every line corresponds to the respectiveversion of EuroParl + News Commentary.All parallel and monolingual corpora un-derwent the same preprocessing.
They weretokenized and some characters normalized orcleaned.
A set of language-dependent heuris-tics was applied in an attempt to restore andnormalize the directed (opening/closing) quota-tion marks (i.e.
"quoted" ?
?quoted?).
Themotivation is twofold here: First, we hope thatpaired quotation marks could occasionally workas brackets and better denote parallel phrasesfor Moses; second, if Moses learns to output di-rected quotation marks, subsequent detokeniza-tion will be easier.The data are then tagged and lemmatized.We used the Mor?e tagger for Czech and En-glish lemmatization and TreeTagger for Ger-man, Spanish and French lemmatization.
Allthese tools are embedded in the Treex analysisframework (?abokrtsk?
et al, 2008).The lemmas are used later to compute wordalignment.
Besides, they are needed to apply?supervised truecasing?
to the data: we castthe case of the lemma to the form, relying onour morphological analyzers and taggers to iden-tify proper names, all other words are lower-cased.
Note that guessing of the true case isonly needed for the sentence-initial token.
Otherwords can typically be left in their original form,unless they are uppercased as a form of HIGH-LIGHTING.3963.1 Quotation MarksA broad range of characters is used to representquotation marks in the training data: straightASCII quotation mark; Unicode directed quo-tation marks (U+2018 to U+201F); acute andgrave accents; math symbols such as prime anddouble prime (U+2032 to U+2037) etc.
Spacesaround quotes in the original untokenized textought to provide hints as to the direction of thequotes (no space between the opening quote andthe next word, and no space between the clos-ing quote and the previous word) but unfortu-nately there are numerous cases where superflu-ous spaces are inserted or required spaces aremissing.Nested quoting is also possible, such as inAs the Wise Men ?
s Report also says , andI quote : ?
It is elementary ?
common sense ?that the Commission should have supported theParliament ?
s decision - making process .
?We want all possible quotation marks con-verted to one pair of characters.
We do not mindthe distinction between single and double quotesbut we want to keep (or restore) the distinctionbetween opening and closing quotes.
In addi-tion, we want to identify the apostrophe actingas grapheme in some languages, and keep it (ornormalize it, as it could also be mis-typed asacute accent or something else):As the Wise Men ?
s Report also says , andI quote : ?
It is elementary ?
common sense ?that the Commission should have supported theParliament ?
s decision - making process .
?We attempt at solving the problem by a setof rules that consider mutual positions of quota-tion marks, spaces and other punctuation, andalso some language-dependent rules (especiallyon the lexical apostrophe, e.g.
in French d?, l?
).Our rules applied to 1.84 % of Spanish sen-tences, 2.47 % Czech, 2.77 % German, 4.33 %English and 16.9 % French (measured on Eu-roparl data).Our approach is different from the normaliza-tion script provided and applied by the organiz-ers of the shared task, which merely converts allquotes to the undirected ASCII characters.
Webelieve that such MT output is incorrect, so wesubmitted two versions of each system run: theprimary version is intended for human evalua-tion and does not apply the ?official?
normaliza-tion of punctuation.
In contrast, the secondaryversion is normalized, which naturally leads tohigher scores in the automatic evaluation.4 ExperimentsIn the following section we describe several dif-ferent settings and corpora combinations we ex-perimented with.
BLEU scores have been com-puted by our system, comparing truecased tok-enized hypothesis with truecased tokenized ref-erence translation.Such scores must differ from the official evalu-ation?see Section 4.4 for discussion of the finalresults.The confidence interval for most of the scoreslies between ?0.5 and ?0.6 BLEU % points.4.1 Baseline ExperimentsThe set of baseline experiments were trained onthe supervised truecased combination of NewsCommentary and Europarl.
As we had lem-matizers for the languages, word alignment wascomputed on lemmas.
(But our previous ex-periments showed that there was little differ-ence between using lemmas and lowercased 4-character ?stems?.)
A hexagram language modelwas trained on the monolingual version of theNews Commentary + Europarl corpus (typicallya slightly larger superset of the target side of theparallel corpus).4.2 Larger Monolingual DataBesides the monolingual halves of the parallelcorpora, additional monolingual data were pro-vided / permitted:?
The Crawled News corpus from the years2007 to 2011, various sizes for each languageand year.?
The Gigaword corpora published by theLinguistic Data Consortium, available onlyfor English (4th edition), Spanish (3rd) andFrench (3rd).397Due to bugs in the lemmatizers, we were notable to process certain parts of the large corporain time.
Table 2 gives the sizes of the subsetsavailable for our experiments and Table 3 com-pares BLEU scores with large language modelsagainst the baseline.Corpus Segments Tokensnewsc+euro.cs 819,434 18,491,692newsc+euro.de 2,360,811 58,683,607newsc+euro.en 2,430,718 65,934,441newsc+euro.es 2,307,429 66,072,443newsc+euro.fr 2,361,764 74,083,166news.all.cs 14,552,899 244,728,011news.all.de 24,446,319 462,924,303news.all.en 42,161,804 1,039,806,242news.all.es 8,627,438 249,022,213news.all.fr 16,708,622 438,489,352gigaword.en 70,592,779 2,546,581,646gigaword.es 31,304,148 1,064,660,498gigaword.fr 21,674,453 963,571,174Table 2: Number of segments (paragraphs in Giga-word, sentences elsewhere) and tokens of additionalmonolingual training corpora.
?newsc+euro?
are themonolingual versions of the News Commentary andEuroparl parallel corpora.
?news.all?
denotes allyears of the Crawled News corpus for the given lan-guage.The Crawled News corpora, in-domain andlarger than the parallel corpora by an order ofmagnitude, turned out to help significantly im-prove the scores of all language pairs.
On theother hand, and to our surprise, we were notable to achieve any further improvement by us-ing the Gigaword corpora.
Taking into accountthe extra requirements on memory when build-ing such big language models, this makes theusefulness of Gigaword questionable.
We haveno plausible explanation at the moment.4.3 Larger Parallel DataEven stranger behavior was observed whenadding the large UN parallel corpus (over 10million sentence pairs).
When used separately(even for language model) it decreased BLEUsignificantly, which could be explained by dif-ferent domain.
When used together with NewsDirection Baseline news.all gigaworden-cs 0.1196 0.1434en-de 0.1426 0.1629en-es 0.2778 0.3136 0.3136en-fr 0.2599 0.2897 0.2874cs-en 0.1796 0.2031 0.2013de-en 0.1877 0.2136 0.2144es-en 0.2219 0.2428 0.2390fr-en 0.2459 0.2764 0.2756cs-de 0.1365 0.1550cs-es 0.1952 0.2211 0.2184cs-fr 0.1953 0.2167 0.2147de-cs 0.1212 0.1400es-cs 0.1281 0.1489fr-cs 0.1253 0.1442Table 3: BLEU scores of the baseline experiments(left column) on News Test 2012 data, computed bythe system on tokenized data, versus similar setupwith large monolingual corpus (news.all, middle col-umn).
Gigaword never brought significant improve-ment.Commentary and Europarl, and with a languagemodel trained on the Crawled News corpus, itbarely outperformed the same setting withoutthe UN corpus.6 However, the es-en direction isa notable exception where the UN corpus alonegave by far the best score.
See Table 4 for de-tails.We failed to lemmatize the giga French-English corpus in time, so we do not presentany results with that corpus.4.4 Final ResultsTable 5 compares our BLEU scores with thosecomputed at matrix.statmt.org.BLEU (without flag) denotes BLEU scorecomputed by our system, comparing truecasedtokenized hypothesis with truecased tokenizedreference translation.The official evaluation by matrix.statmt.org gives typically lower numbers, reflecting theloss caused by detokenization and new (differ-ent) tokenization.6One of the anonymous reviewers mentioned that thequality of the UN corpus is relatively low.
That couldexplain our observations.398Direction Parallel Mono BLEUen-es news-euro-un news.all 0.3194en-es news-euro news.all 0.3136en-es un un 0.2694en-fr news-euro news.all 0.2897en-fr un un 0.2541es-en un un 0.2688es-en news-euro news.all 0.2428fr-en news-euro news.all 0.2764fr-en un un 0.2392Table 4: BLEU scores with different parallel corpora.4.5 EfficiencyThe baseline experiments were conductedmostly on 64bit AMD Opteron quad-core2.8 GHz CPUs with 32 GB RAM (decodingrun on 15 machines in parallel) and the wholepipeline typically required between a half and awhole day.However, we used machines with up to 500 GBRAM to train the large language models andtranslation models.
Aligning the UN corporawith Giza++ took around 5 days.5 ConclusionWe have described the Moses-based SMT systemwe used for the WMT 2012 shared task.
Wediscussed experiments with large data for manylanguage pairs from the point of view of boththe translation accuracy and efficiency.
We wereunable to process all data that was available;even the experiments where we did use largerdata did not outperform the smaller experimentssignificantly.
Nevertheless, using the CrawledNews monolingual corpus proved essential.AcknowledgementsThe work on this project was supported by thegrant P406/11/1499 of the Czech Science Foun-dation (GA?R).ReferencesStanley F. Chen and Joshua Goodman.
1998.
Anempirical study of smoothing techniques for lan-guage modeling.
In Technical report TR-10-98,Direction BLEU BLEUl BLEUten-cs 0.1434 0.144 0.136en-de 0.1629 0.159 0.154en-es 0.3136 0.316 0.297en-fr 0.2897 0.263 0.251cs-en 0.2031 0.207 0.192de-en 0.2136 0.214 0.200es-en 0.2428 0.253 0.240fr-en 0.2764 0.280 0.266cs-de 0.1550 0.153 0.147cs-es 0.2211 0.224 0.207cs-fr 0.2167 0.197 0.186de-cs 0.1400 0.141 0.134es-cs 0.1489 0.150 0.143fr-cs 0.1442 0.145 0.138Table 5: BLEU scores with the large language mod-els.
BLEU is computed by the system, BLEUl is theofficial lowercased evaluation by matrix.statmt.org.
BLEUt is official truecased evaluation.
Al-though lower official scores are expected, notice thelarger gap in en-fr and cs-fr translation.
There seemsto be a problem in our French detokenization proce-dure.Computer Science Group, Harvard, MA, USA, Au-gust.
Harvard University.Reinhard Kneser and Hermann Ney.
1995.
Im-proved backing-off for m-gram language modeling.In Proceedings of the IEEE International Confer-ence on Acoustics, Speech and Signal Processing,pages 181?184, Los Alamitos, California, USA.IEEE Computer Society Press.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
InNAACL ?03: Proceedings of the 2003 Conferenceof the North American Chapter of the Associationfor Computational Linguistics on Human Lan-guage Technology, pages 48?54, Morristown, NJ,USA.
Association for Computational Linguistics.Philipp Koehn, Hieu Hoang, Alexandra Birch,Chris Callison-Burch, Marcello Federico, NicolaBertoldi, Brooke Cowan, Wade Shen, ChristineMoran, Richard Zens, Chris Dyer, Ond?ej Bojar,Alexandra Constantin, and Evan Herbst.
2007.Moses: Open Source Toolkit for Statistical Ma-chine Translation.
In Proceedings of the 45th An-nual Meeting of the Association for ComputationalLinguistics Companion Volume Proceedings of theDemo and Poster Sessions, pages 177?180, Praha,399Czechia, June.
Association for Computational Lin-guistics.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.Franz Josef Och.
2003.
Minimum error rate train-ing in statistical machine translation.
In ACL?03: Proceedings of the 41st Annual Meeting onAssociation for Computational Linguistics, pages160?167, Morristown, NJ, USA.
Association forComputational Linguistics.Andreas Stolcke.
2002.
Srilm ?
an extensible lan-guage modeling toolkit.
In Proceedings of Interna-tional Conference on Spoken Language Processing,Denver, Colorado, USA.Zden?k ?abokrtsk?, Jan Pt?
?ek, and Petr Pajas.2008.
TectoMT: Highly modular MT system withtectogrammatics used as transfer layer.
In ACL2008 WMT: Proceedings of the Third Workshopon Statistical Machine Translation, pages 167?170,Columbus, OH, USA.
Association for Computa-tional Linguistics.400
