A Finite-Slate Parser for Use in Speech RecognitionKenneth W. ChurchNE43-307Massachusetts Institute of TechnologyCambridge, MA.
02139This paper is divided into two parts.
1 The first section motivatesthe application of finite-state parsing techniques at the phonetic level inorder to exploit certain classes or" contextual constraints.
-In the secondsection, the parsing framework is extended in order to account \['or'feature spreading' (i:.g., agreement and co-articulation) in a naturalway.I.
Parsing at the Phonetic LevelIt is well known that phonemcs have different acoustic/phoneticrealizations depending on the context.
Fur example, the phoneme/ t /is typically realized with a different allophone (phonetic variant) insyllable initial position than in syllable final position.
In syllable initialposition (e.g., Tom),/t/is almost always released (with a strong burst ofenergy) and aspirated (with h-like noise), whereas in syllable finalposition (e.g., cat.
), /t/  is often unreleased and unaspirated_ It iscommon practice in speech research to distinguish acoustic/phoneticproperties that vary a great deal with context (e.g., release andaspiration) from those that are relatively invariant to context (e.g.,place, manner and voicing).
2 In the past, the emphasis has been oninvariants; allophonic variation is traditionally seen as problematic forrecognition.
(I) "In most systems for sentence recognition, such modificationsmust be viewed as a kind of 'noise' that makes it more difficultto hypothesize lexical candidates given an input phonetictranscription.
To see that this must be the case, we note thateach phonological rule \[in an example to be presented below\]l, This research was ~pported (in part) by the National Institutes of I lealth Grant No.
1POt I M 03374-01 and 03374-02 from the National Library of Medicine,2.
Place refers IO the location of the constriction in the vocal tracL Examples include:labial t'at the hpsl/p, b. f, ',.
m/, velar/k, g. r~/, dental (at the teeth)/s, z, t. d, I, n /andpalatal A, ;~, i:,'}/ Manner dislmgu~shes among vowels, liquids and slides (e.g., /1, r, y.w/t.
fricatives le.s.,/s, z, f. v/t, nasals (e.g.,/n.
m. r io  and stops leg , /p ,  t, k, b, d, g/).Voietng (periodie ~,ibration of the vocal fold.s) distingmshes sounds like /b, d. S/ fromsounds like/p, L, k./.results in irreversible ambiguity - the phonological rule doesnot have a unique inverse that cuuld be used to recover theunderlying phonemic representation for a ie,xical item.
l:orexample .... schwa vowels could be the first vowel in a word like'about' or the surface realization of almost any English vowelappearing in a sufficiently destressed word.
The tongue tlap \[Elcould have come from a / t /  or a /d / . "
Klatt (MIT)\[21, pp.
548-5491This view of allophonic variation is representative of much of thespeech recognition literature, especially during the ARPA speechproject.
One can find similar statements by Cole and Jakim~k ICMU)\[5\] and by Jelinek (IBM)\[17\].I prefer to think of variation as usefid.
It is well known that atlo-phonic contrasts can be distinctive, as illustrated by the followingfamous minimal pairs where the crucial distinctions eem to lie in theallophonic realization of the/ t / :(2at a tease / at ease aspirated / flapped(2b) night rate / ni-trate unreteased/retroflexed(2c) great wine / gray twine unreteased/roundedThis evidence suggests that allophonic variation provides a tich sourceof constraints on syllable structure and word stress.
The recognizer tobe discussed here (and partly tmplcmented in Church \[4\]) is designed toexploit allophonic and phonotactic cues by parsing the input utteranceinto syllables and other suprasegmental constituents using phrase-structure parsing techniques.1.1 An Example of Lexical RetrievalIt might be helpful to work out an example it\] order to illustratehow parsing can play a role in l.exica\] retrieval.
Consider the phonetictranscription, mentioned above in the citation from Klatt \[20, p. 1346\]\[2\], pp.
548-549J:91(3) \[dD~hlf_lt) tam\]It is desired to decode (3) into the string ofwords:(4) Did you hit it to Tom?In practice, the lexical retrieval problem is complicated by errors in thefront cad.
However, even with an ideal error-free front-end, it isdifficult to decode (3) because, among other things, there are extensivenile-governed changes affecting the way that words are pronounced indifferent sentence contexts, as Klatt's example illustrates:(5a) Pabtalization o f /d /be fore /y / in  didyou(5b) Reduction of unstressed/u/to schwa in),~u(5c) Flapping of intervocalic / t /  in hit.
it(5d) Reduction of schwa and devoicing o f /u / in  to(5e) Reduc:ion of geminate/t/ in it.toThese allophonic processes often appear to neutralize phonemicdistinctions.
For example, the voicing contrast between/t /  and /d / .which is usually distinctive, is almost completely lost in wr~er/rid_er,where bod~ /t/  and /d /  are realized in American English with a tongue~ap (q.1.2 .\n Ogtimistic "v'icw of NeutralizationFortunately, there are many fewer cases of true neutralizationthan it might seem.
Even in writ.er/ri~.er, the voicing contrast is notcompletely lost.
The vowel in rider tends to be longer than the vowel inw~ter due to a general process that lengthens vowels before voicedconsonants (e.g., /d/ )  and shortens them before unvoiced consonants(e.g.,/t/).A similar lengthening argument can be used to separate In /and/nd l  (at least in some cases).
It tmght be suggested that In / i s  mergedw i th /nd /by  a/d/de let ion rule that applies in words like mena~ wind(noun).
wind (',erbL and find.
(Admittedly there is little if any directacoustic evidence fi)r a /d /segment  in this environment.)
However, \[suspect hat these words can o)~en be distinguished from men, win.)vttte.
and fine mostly on the basis of the duration of the nasal murmurwhich is lengthened in the precedence of a voiced obstruent l ike/d/ .Thus, this /d/-detction process is probably not a true case ofneutralization,Recent studies in acoustic/phonetics seem to indicate that moreand more cases of apparent neutralization can be separated as the fieldprogresses.
For instance, it has been said that/s /merges with f~/ in acontext like ga~ shortage \[12\].
lh)we~cr, a recent experiment 1271suggests that the/s~/sequence can be distinguished from /~,~/ las infisth shortage) on the basis of a spectral tilt: the /s,~/'spectrum is more/s/-like in the beginning and more/~,/-like at the cad, whereas the f~spectrum is relatively constant hroughout.
A similar spectral tiltargument can be used to separate other cases of apparent gemination(e.g../z~'/in ~the).As a final example of apparent ncutra!ization, consider theportion of the spectrogram in Figure !, between 0.85 and 1.1 seconds.This corresponds to the two adjacent / t /s  in Did you hit it to Tom?Klatt analyzed this region with a single geminated/t/ .
However, uponfurther investigation of the spectrum, I believe that there are acousticcues for two segments.
Note especially the total energy, which displaystwo peaks at 0.95 and 1.02 seconds.
On the basis of this evidence, I willreplace Klatt's transcription (6a) with (6b):(6a) \[dl\]ahlf.lu taml(6b) \[dl\]i}hll'I t tlmmlU1.3 Parsing and MatchingEven though 1 might be able to re-interpret many cases ofapparent neutralization, it remains extremely difficult to "undo" theallophonic rules by inverse transformational parsing techniques.
Letme suggest an alternative proposal, l will treat syllable structure as anintermediate l vel of representation between the input segment latticeand ',he output word lattice.
In so doing, I have replaced .
:.he lexicalretrieval problem with two (hopefully simpler) problems: (a) parse thesegment lattice into syllable structure, and (b) match the resultingconstituents a~ainst he lexicon.
I will illustrate the approach withFig.
I.
Did you hit it to Tom?
,-,~.(..~.
)o ,0  P i t  o iZ  .
oi.~ 0 .4  06  o .e  0 .7  O.a 0 .9  l .o  1 .
I  t ,Z 1.3 : .4  l .eas  ,:~o'; Laer?~ - -  t~,6HIm76OH8 .
.
.
.
.
.
.
.
.- ,o~ .
.
.
.
.
- -~-~- , ; - - -~- '~-  ;';' i'L " .
.
.
.
;" ~ ' ~ ' ~ : " ~,,ill , Ig l l , ,  , .
Ird li Wavetom ~ ~ ~IL .
~ ~, .
.I .
_  J .~  L , I ' ,  I .
.
t I , L - t _~!
I - .1  L .
\ ]  I l I IDid you hit it to Tom92Klatt's example (enlu, nced with allophonic diacritics to show aspirationand glottalization):(7) \[drjighlff tht thamlTTrUsing phonotactic and allophonic onstraints on syllable structure suchas: 3(8a) /h / i s  always yllable initial, phonotactic(8b) \[1" I is always yllable final, allophonic(8c) \[?\] is always yllable final, and allophonie(Sd) \[t h\] is always yllable initial, allophonicthe parser can insert he following syllable boundaries:(9) \[di~} # hlf.
# I ?
# tht # tham\]It is now it is relatively easy to decode the utterance with lcxicalmatching routines imilar to those in Smith's Noah program at CMU{241.parsed transcription, decodinldl\]~ -...?
did youhlf= --..* hitl ?
-=+ itth) ---., totham ---, TomIn summary, I believe that the lexical retrieval device will be in asuperior position to hypothesize word candidates if it exploits allo-phonic and phonotactic constraints on syllable structure.1.4 Exploiting Redund:meyIn many cases, atlophonic and phonotacdc onstraints areredundant, Even if the parser should miss a few of the cues for syll~ibiestructure, it will often be able to find the correct structure by takingadvantage of some other edundam cue.
\[:or example, suppose that thefront end failed to notice die glottalized/t./in the word it.
(10) dl\]i9 #h l f _# I #tha  #thamTThe parser could deduce that the input transcription (10) is internallyinconsistent, because of a phonotactic constraint on the lax vowel/ I / .3.
This formulation fthe eonst/'aints is oversimplified forexlx3,sltory convenience; see\[10. lJ.
15\] and references thereto f r discussion fthe more subtle issues.Lax vowels are restricted to closed syllables (sylkdgles ending in aconsonant) \[I\].
However, in this case, /1/ cannot mcct the closedsyllable restriction because the following consonant is aspirated (aridtherefi)re syllable initial).
Thus the transcription is internallyinconsistent.
The parser shotlld probably rejcct tbc transcriot;?,n ~mdhope that the front end can fix dxe problem.
Alternatively, the parsermight attempt to correct he error by hypothesizing a second/t/ .
4There are many other examples like (10) where phonotacticconstraints and allophonic constraints overlap.
Consider the pairsfound in figure 2, where there are multiple arguments for assigning thecrucial syllable boundary.
In de-prive vs. dep-rivalion, for instance, thedifference is revealed by the vowel argument above 5 and by theaspiration rule.
6 In addition, the stress contrast will probably be cor-related with a number of so-called 'suprasegmental' cues, e.g., duration,fundamental frequency, and intensity \[81.In general, there seem to be a large number of multiple low levelcues for syllable strt,cture.
This observation, if correct, could be viewedas a form of a 'constituency hypothesis'.
Just as syntacticians haveargued for the constituent-hood f noun phrases, verb phrases andsentences on the grounds that these constituents seem to capture cruciallinguistic generalizations (e.g., question formation, wh-movement), sotoo, I might argue (along with certain phonologists such as Kahn \[13\])that syllables, onsets, and rhymes are constituents because they alsocapture important generalizations such as aspiration, tensing and laxing.If this constituency hypothesis for phonology is correct (and I believeFig.
2.
Some Structural Contrnstsr !
_wt2 de-privedep-rivationt a-ttributeatt-ributeli de-creasedec-rimentb cele-brationcelcb-rityd a-ddressadd-tessg de-gradedeg-radationdi-plomacydip-lumaticde-cline a-cquiredec-lination acq-uisitiono-bligatoryob-ligation4.
Personally.
1 favor the first alternative: after years of ,.,.smessmg Victor Zue readspectrograms.
I have become most mpressed with the richness oflow level phonetic cues.5.
The syllable de.
is open because the vowel is tense (diphthongizcd): dep" is dosedbecause the vowel is lax6.
lhe /p/ m -prtve is syllable inttml because it ts a.sptrated whereas the /p/ in dep" iss) liable final because it is unaspirated.93that it is) then it seems F~atural to propose a syllabic parser fi)rproccssit~g speech, by analogy with sentence parsers that have bccomestandard practicc in d~e natural laoguagc community for processing.~ext.2.
Parser  Imp lementat ion  and Feature  Spread ingA program has bcen implcmcntcd \[41 which parses a lattice ofphonetic segmcnts into a lattice of syllables and other phonologicalconstituents.
Except for its novcl mechanism for handling features, it isvery much like a standard chart parser (e.g.. Earley's Algorithm lTD.P, ccall that a chart parser takes as input a sentence and a context-freegrammar and produces as output a chart like that below, indicating thestarting point and ending point of each phrase in the input string.lnput~ Sentenc(l: 0 They t are 2 flying 3 planes 4Gram.mar:N "---* they V ---* are N --* tl?ingA -"* flying V ---* flying N --~ planesS --* NP VP VP -..* V NP VP ---.~ V VPNP~ N NP~ APNP NP"-* VP AP - '* A('n,,.rt:oo (}i!1}2!
{}I 2 3 #{Xt',N,they} {S} {S} {S}{ } {VP.V.are) {VP} (VP}{ } \[ } {NP.VP,AP,N.V,A,flying| {NP.VP}( } { } ( } {NP, N.planesl{} {} {} {}bLach entry in the chart represents the possible analyses of the inputwords between a start position (the row index) and a finish position (thecolumn index).
\[-'or example, the entry {NP, VP} in Chart(2,4)represents two alternative analyses of the words between 2 and 4:\[xp fi3ulg pia,esl add \[vp flying planesl..the same parsing methods can be used to find syllable structurefrom an input transcription.lod)u\[ Sentence: O ~" ?
t 2 S 3 l 4 Z 5 (this ~)Grammar:onset~ ~' \ [S IZ  peak---) i t \ [coda --.--) ~' \[ S I Z syl ----) (onset) peak (coda)Chart:0J , Ho{}t{}z{}s t}4{}s ( II 2 3 4 .~ ,{\[.onset.coda} {syl} {syl} { } { }{ } {!,pcak.syl} {syl) { } { }{ } { } {S.onset.codal (syl} {syl}{ } { } { } {l,peak.syl} {syl}{ } { } { } { } {Z, onset.coda){} (} ( I  {} (}This chart shows that the input sentence can be decomposed into twosyllables, one from 0 to 3 (this) and another one from 4 to 5 (is).Alternatively, the input sentence can be decomposed into \[~'t\]\[slzl.
Inthis way.
standard chart parsing techniques can be adopted to processallophonic and phonotactic constraints, if the constraints arereformulated in terms of a grammar.How can allophonic and phonotactic constraints be cast in termsof context-free rules?
In many cases, the constraints can be carried overin a straightforward way.
For example, the following set of rolesexpress the aspiration constraint discussed above.
These rules allowaspiration in syllable initial position (under the onset node), but not insyllable final position (under the coda).
( l la)  uttcrancc ---) syllable*( l ib)  syllable ~ (onset) peak (coda)(II.c) onset --* aspirated-t \[ aspirated-k I aspirated-p I.,.
( l ld)  coda---, unrelcascd-t I unrclcased-k I unrcleased-p I-.-The aspiration constraint (as stated above) is relatively easy to cast interms of context-free rules.
Other allophonic and pho~aotactic processesmay be more difficult.
72..1 The Agreement ProblemIn particular, context-free roles are generally considered to beawkward for expressing agreement facts.
For example, in order toexpress subject-verb agreement in "'pure" context-free rules, it isprobably necessary to expand the rule S ~ NP VP into two cases:(12a) S ---* singular-NP singular-VP singular case(12b) S --) plural-NP plural-YP plural case7.
For example, there may be a problem with constraintS that depend on rule ordering,since rule ordenng is not supported in the context-free formalism.
This topic is discussedat length in I41.94The agreement problem also arises in phonology.
Consider theexample of homorganic nasal clusters (e.g., cam2II2, can't, sank), wherethe nasal agrees with the following obstruent in place of articulation.That is, the labial nasal /m/  is found before the labial stop /p/ ,  thecor9nal nasa l /n /  before the coronal s top / t / ,  and the velar nasal/7//before the velar s top/k / .
This constraint, like subject-verb agreement.poses a problem for pure unaugmented context-free rules; it seems tobe necessary toexpand out each of the three cases:(13a) homorganic-nasal-cluster ~ labial-nasal labial-obstruent(13b) homorganie-nasal-cluster ~ coronal-nasal coronal-obstruent(13c) homorganic-nasal-cluster---* velar-nasal velar-obstruentIn an effort to alleviate this expansion problem, many researchers haveproposed augmentations of various sorts (e.g., ATN registers \[26\], LFGconstraint equations \[16\], GPSG recta-rules til l, local constraints \[18\],bit vectors \[6, 22\]).
My own solution will be suggested after I have hada chance to describe the parser in further detail.2..2 A Parser Based on Matrix OperationsThis scction will show how the grammar can be implemented interms of operations on binary matrices.
Suppose that the chart isdecomposed into a sum of binary matrices:(14) Chart = syl Msy I + onset Monse t + peak Mpeak + .,.where Msy I is a binary matrix 8 describing the location of syllables andMonse t is a binary matrix describing the location of onsets, and so forth.Each of these binary matrices has a I in position (i,j) if there is aconstituent of the appropriate part of speech spanning from the i mposition in the input sentence to the jth position.9 (See figure 3).Ph'rase-structure rules will be implemented with simple oper-ations on these binary matrices.
For example, the homorganic rule (13)could be implemented as:8.
Fhese matnccs will sometimes becalled segmentatton lattices for historical reasons.Techmcally.
these matnc~ need not conform to the restrictions of a lattice, and therefore,the weaker term graph L~ more correcL9 In a probabitisuc framework, one could replace all of the I's and 0's with probabdities.A high prohabdity mloeauon (i. j~ of the s),liable matnx would say that here probably isa ss'llahle from postuon t to position 1:a low probabdity would say that here probablyisn't a syllable between i and 1.
Most of the following apphcs to probabdity matriceswelt as binary ntawices, though the probabdity matnces may be less sparse andconsequently less efficient.Fig.
3.
Msyl, Monse and Mdtyme for: "O '~ I t Z s 3 I 4 z 5"001100 010000 000000001100 000000 001100000011 000100 000000000011 000001 000011000000 000000 000000000000 000000 000000The matrices tend to be very sparse (ahnost entirely full of 0's) becausesyllable grammars are highly constrained.
In principle, there could ben 2 entries.
However, it can be shown that e (the number of l's) islinearly related to n because syllables have finite length.
In Church \[4\],I sharpen this result by arguing that e tends to be bounded by 4n as aconsequence ofa phonotactic principle known as sonority.
Many moreedges will be ruled out by a number of other linguistic constraintsmentioned above: voicing and place assimilation, aspiration, flapping.etc.
In short, these mamces are sparse because allophonic and phono-tactic constraints are useful(15) (setq homorganic-nasal-lattice(M + (M* (phoneme-lattice #/m)labial-lattice)(M* (phoneme-lattice #/n)  coronal-lattice)(M* (phoneme-lattice #/G)  velar-lattice)))illustrating tile use of M + (matrix additit)n) ttt express the uniun ofseveral alternatives and M* (matrix multiplication) to express theconcatenation of subparts.
It is well known that any finite-stategrammar could be implemented in this way with just three matrixoperations: M,,  M+,  and M** (transitive closure).
If context-freepower were required, Valient's algorithm \[25\] could be employed.However, since there doesn't seem to be a need tbr additionalgenerative capacity in speech applications, the system is restricted tohandle only the simpler finite state case.
1?2..3 Feature ManipulationAlthough "pure" unaugmented finite state grammars may beadequate fur speech applications (in the weak generative capacitysense), \[ may, nevertheless, wish to introduce additional mechanism inorder to account for agreement facts in a natural way.
As discussedabove, the formulation of the homorganic rule in (15) is unattractivebecause it splits the rule into three cases, one for each place ofarticulation.
It would be preferable to state the agreement constraintjust once, by defining a homorganic nasal cluster to be a nasal cluster\]0.
I personally hold a much more controversial posution, that inite state grammars aresufficient for most.
if not nil, natural language )-asks \[3\].95subject to phlcc assimilation.
In my language of matrix operations, Ican say just exactly that:(16) (setq homorganic-na~l-cluster-lattice(M& nasal-cluster-latticeplace-assimilation))where M& (element-wise intersection) implements the subject toconstraint.
Nasal-cluster and place-assimilation are defined as:(17a) (setq nasal-cluster-lattice(M. nasal-lattice obstruent-lattice))(17b) (setq place-assimilation-lattice(M + (M** labial-lattice)(M"  dental-lattice)(M ' "  velar-lattice)))In this way.
M& seems to be an attractive solution to the agreementproblem.In addition, M& might also shed some light on co-articulation,another problem of'feature spreading'.
Co-articulation (articulation ofmultiple phonemes at the same time) makes it extremely difficult(perhaps impossible) to segment he speech waveform into phoneme-co-articulation, Fujimura su~csts that place, manner and otherarticulatory features be thought of as asynchronous processes, whichhave a certain amotmt of freedom to overlap in time.
(tSa) "Speech is commonly viewed as the result of concatenatingphonetic segments.
In most discussions of the temporalstructure of speech, a segment in such a model is assumed torepresent a phoneme-sized phonetic unit.
which possesses aninherent \[invariantj target value in terms of articulation oracoustic manifestation.
Any deviation from such aninterpretation of observed phenomena requires specialattention ... \[Biased on some preliminary results of X-raymicrobeam studies \[which associate lip, tongue and jawmovements with phonetic events in the utteranceJ, it will besuggested that understanding articulator'/ processes, which areinherently multi-dimensional \[and (more or less) asynchrouousl,may be essential for a successful description of temporalstructures of speech."
\[9 p. 66\]In light of Fujimura's uggestion, I might re-interpret my parser as ahighly parallel feature-based asynchronous architecture.
For example.the parser can process homorganic nasal clusters by processing placeand manner phrases in parallel, and then synchronizing the results atthe coda node with M&.
That is, (17a) can be computed in parallel with(17b).
mid then the rcsulLs are aligned whcn the coda is computed with(16), as illustrated below for the word tent.
Imagine that the front endproduces the following analysis:(19) t a n tdental: I-I I .
.
.
.
.vowel:  I - .
.
Is top :  I.I I .
.
.
.
.
Inasa l i za t ion :  I .
.
Iwhere many of the ~atures overlap m an asynchronous way.
Theparser will correctly locate the coda by intersecting the nasal clusterlattice (computed with (17a)) with the homorganic lattice (computedwith (17b)).
(20) t a n tnasa l  c lus ter :  I .
.
.
.
.
.
.
JhomonganJc:  I .
.
.
.
.
Icoda:  I .
.
.
.
.
IThis parser is a bold departure from a standard practice in two respects:(1) the input stream is feature-based rather than segmental, and (2) theoutput parse is a heterarchy of overlapping constituents (e.g., place andmanner phrases) as opposed to a list of hierarchical parse-trees.
\[ findthese two modifications most exciting and worthy of furtherinvestigation.In summary, two points have been made.
\[:irst.
I suggested theuse of parsing techniques at the segmental/feature level in speechapplications.
Secondly, I introduced M& as a possible solution to theagreement/co-articulation problem.3.
Ack ,mwledgementsl have received a considerable amount of help and support overthe course of this project.
Let me mention just a few of the people thatI should thank: Jon Allen, Glenn Burke, Francine Chen, Scott Cyphers,Sarah I-ergt,son..,'vlargaret Fleck, Dan Huttenlocher, Jay Kcyser, LoriLameL Ramesh Patil.
Janet Pierrehumbert, Dave Shipman, PeteSzolovits.
Meg Withgott and Victor Zue.Re ferences1.
Bamwell, T., An Algorithm for Segment Durations in aReading Machine Context, unpublished doctoral dis-sertation, department of Electrical Engineering andComputer Science, M1T.
1970.L Chomsky.
N. and Halle, M., The Sound Pattern of~'nglish,Harper & R.ow, 1968.3.
Church, K., On Memoo' Limitations in Natural LanguageProcessing, MS Thesis, MIT, Mr\['/I,CS/TR-245, 1980(also available from Indiana University Linguistics Club).964.
Church, K., Phrase-Structure l'arsing: A Method lbr TakingAdvantage of Allophonic Constraints, unpublisheddoctoral dissertation, department of I-',lectrical Engineeringand Computer Science, MIT, 1983 (also to appear, I.CSand RLE publications, MIT).5.
Cole, R., and Jakimik, J., A Model of Speech Perception, inR.
Cole (ed.).
Perception and l'roduction of Fluent Speech,Lawrence Erlbaum, HiIlsdale, N.J., 1980.6.
Dostert.
B., and Thompson, F., How Features ResolveSyntactic Ambiguity, in Proceedings of the Symposium onInformation Storage and Retrieval, Minker.
J., andRosenfeld, S.
(?d.
), 1971.7.
Farley, J., An Efficient Context-Free Parsing Algorithm,CACM, 13:2, February, 1970.8.
Fry, D., Duration and Intensity as Physical Correlates ofLinguistic Stress, JASA 17:4, 1955, (reprinted in Lehiste(ed.
), Readings in Acoustic l'honetics, MIT Press, 1967.)9.
Fujimura, O., Temporal Organization of Articulatory Move-ments as Multidimensional Phrasal Structure, Phonetica,33: pp.
66-83, 1981.10. l-'ujimura, O., and Lovins.
J., Syllables as ConcatenativePhonetic UralS, Indiana University Linguistics Club, 1982.11.
Gazdar, G., Phrase Structure Grammar, in P. Jacobson andG.
Pullum (eds.
), The Nature of Syntactic Representation,D.
Rcidet, Dordrecht, in press, 1982.12..Heffner, R., General Phonetics, The University ofWisconsin Press, 1960.13.
Kahn, D., Syllable-Based (ieneralizations ht lOtglish Pho-nology,, Indiana University Linguistics Club, 1976.14.
Kiparsky, P., Remarks on the Metrical Structure of the Syl"lable, in W. Dressier (ed.)
Phonologica 1980.
Proceedingsof the Fourth International Phonology Meeting 1981.15.
Kiparsky, P., Metrical Structure, Assignments in Cyclic,Linguistic Inquiry, 10, pp.
421-441, 979.16.
Kaplan, R. and Bresnan, J., LexicabFunctional Grammar:A Formal System for Grammatical Representation, iBresnan (ed.
), The Mental Representation f GrammaticalRelations, MIT Press.
1982.17.
Jetinek, F., course notes, MIT, 1982.18.
Joshi, A., and Levy, L..
Phrase Structure Trees Bear MoreFruit Than You Would Have Thought, AJCL, 8: I, \[982.19.
Klatt, D., Word Verification in a Speech UnderstandingSystem, in P,.
R, eddy (ed.
), Speech Recognition, InvitedPapers Presented at the 1974 \[EEE Symposium, AcademicPress, pp.
321-344, 1974.20.
Klatt, D., Review of the ARPA Speech UnderstandingProject, JASA, 62:6, December 1977.ZI.
Klatt, D., Scriber and Lal's: Two New Approaches toSpeechAnalysis, chapter 25 in W. Lea, Trends in Speech Recog.ration, Prentice-Hall, 1980.22.
Martin, W., Church, K., and Patil, R., Prelhninary Analysisof a Breadth-First Parsing Algorithm: Theoretical ttd Ex"permwntal Results, MI'I'/LCS/'I'R-261, 1981 (also toappear in I..Bolc (ed.
), Natural language ParsingSystems, Macmillan, \[.ondon).23.
Reddv R., Speech Recognition by Machine: A Review,Proceedings ofthe IEEE, pp.
501-531, April 1976,~.
Smith, A., Word flypothesization i  the Ilearsay-ll SpeechSystem, Proc.
IEEE Int, Conf.
ASSP, pp.
549-552, 1976.25.
Valient, l.., General Context Free Recognition i  Less ThanCubic Time, J.
Computer and System Sciences 10, pp.
308-315, 1975.26.
Woods, W., Transition Network Grammars for NaturalLanguage Analysis, CACM, 13:10, 1970.Z7.
Zue, V., and Shattuck-Hufnagel, S. When is a ,/Ts/not a/3V?, ASA, Atlanta, 1980.97
