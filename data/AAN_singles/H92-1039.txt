Session 5b.
In format ion Retr ievalDonna HarmanNat iona l  Ins t i tu te  of S tandards  and  Techno logyGa i thersburg ,  Md.
,  208991.
In t roduct ionAs this is the first time there has been a session on infor-mation retrieval at a DARPA Speech and Natural Lan-guage Workshop, it seems appropriate to provide a moredetailed introduction to this topic than would normallyappear.
The term "information retrieval" refers to a par-ticular application rather than a particular technique,with that application being the location of informationin a (usually) large amount of (relatively) unstructuredtext.
This could be done by constructing a filter to pulluseful information from a continuous stream of text, suchas in building an intelligent router or a library profilingsystem.
Alternatively the text could be archived news-papers, online manuals, or electronic ard catalogs, withthe user constructing an ad-hoc query against his infor-mation.
In both cases there needs to be accurate andcomplete location of information relevant o the ad-hocquery or filter, and efficient techniques capable of pro-cessing often huge amounts of incoming text or very largearchives.The currently-used Boolean retrieval systems grew out ofthe 100 or more year old practice of building cumulativeindices, with early mechanical devices enabling people tojoin two index terms using AND's and OR's.
This mech-anism was adapted to computers and although today'scommercial retrieval systems are much more sophisti-cated, they had not gone beyond the Boolean model.Boolean systems are difficult for naive or intermittentusers to operate, and even skilled searchers find thesesystems limiting.The widespread use of computers in the 1960's, and theavailability of online text made possible some innovativeand extensive research in new information retrieval tech-niques \[5, 3\].
This work has continued, with new mod-els being proposed, many experimental techniques beingtried, and some implementation a d testing of these sys-tems in real-world environments.
For an excellent sum-mary of various models and techniques, ee \[1\], and fora discussion of implementation issues, see \[2\].
The ma-jor archival publications in the area of information re-trieval are 1) Information Processing and Management,Pergamon Press; 2) Journal of the American Society forInformation Science; and 3) the annual proceedings ofthe ACM SIGIR conference, available from ACM Press.text, with the goal being to match a user's query (or afilter) against the text in such a manner as to providea ranked list of titles (or documents), with that rankbased on the probability that a document is relevantto the query or filter.
The use of statistical techniquesrather than natural anguage techniques comes from theneed to handle relatively large amounts of text, and the(supposed) lack-of-need to completely understand textin order to retrieve from it.
For a survey of the use ofnatural anguage procedures in information retrieval, see\[4\].The statistical techniques have proven successful in lab-oratories, and generally retrieve at least some relevantdocuments at high precision levels.
The performancefigure often quoted for these systems is 50% precisionat 50% recall; roughly equivalent o the performanceof Boolean systems used by skilled searchers.
Unfor-tunately this performance has not seen major improve-ment recently, although improvements continue in re-lated parts of information retrieval, such as interfaces,efficiency, etc.
There are two explanations often given forthis lack of improvement.
The first is that the currently-available test collections are too small to allow properperformance of many of the proposed techniques, andsecond, that more sophisticated techniques are needed,including some natural anguage techniques.The DARPA T IPSTER and TREC programs addressboth these issues, with a much larger test collection(4 gigabytes of text) being built, and a range of tech-niques, including sophisticated statistical techniques andefficient natural language techniques, being supported.Results from these projects will be reported in the fu-ture.
The four papers in this session all apply naturallanguage techniques to information retrieval, and illus-trate some of the important ways that natural anguageprocessing can improve information retrieval.2032.
PapersThe first paper, "Information Retrieval using RobustNatural Language Processing" by Tomek Strzalkowskiof New York University, augments a basic statisticalinformation retrieval system with various natural lan-guage components.
One of these components i the re-placement of the standard morphological stemmer witha dictionary-assisted stemmer, improving average preci-sion by 6 to 8%, even in the small test collection beingused.
Additionally a very fast syntactic parser is usedto derive certain types of phrases from the text.
Thesephrases, in addition to the single terms, make for a richerrepresentation f the text, and are also used to expandthe queries.
The query expansion involves finding simi-larity relationships between terms in these phrases, andthen filtering these relationships to carefully select whichterms to add to the query.
This filtering (which addsonly 1.5% of the possible relations) enables a perfor-mance improvement in average precision of over 13%,a significant result for this small test collection.
Thepaper therefore addresses two of the major issues in in-formation retrieval: improving accuracy (precision) us-ing a better stemmer, and improving completeness (re-call), without losing accuracy, by adding carefully se-lected terms to the query.The second paper, "Feature Selection and Feature Ex-traction for Text Categorization" by David D. Lewis ofthe University of Chicago, deals with the problem of textcategorization, or the assigning of texts to predefinedcategories using automated methods based on the textcontents.
Two particular areas are investigated.
Thefirst area involves finding appropriate statistical meth-ods for assigning categories.
Adaptions are made to astatistical model from text retrieval, and methods for de-termining actual category assignments rather than prob-ability estimates are discussed.
The second area of re-search examines various techniques for selecting the textfeatures for use in this statistical method.
Three typesof features are tried: 1) single terms from the text, 2)simple noun phrases found using a stochastic lass tag-ger and a simple noun phrase bracketing program, and3) small clusters of features constructed using severalmethods.
Additionally the effect of using smaller sets ofall three types of features is investigated, and is shownto be more effective than using the full set.
The prob-lem of selecting which features of text to index is im-portant in information retrieval, as often the terms inthe queries are both inaccurate and insufficient for com-plete retrieval.
By improving the indexing of the text,such as by adding selected phrases, clusters, or other fea-tures, these queries can be more successful.
This workwill continue with the larger test collections becomingavailable in the future.The third paper, "Inferencing in Information Retrieval"by Alexa T. McCray of the National Library of Medicine,describes an information retrieval system being designedfor the biomedical domain.
This system takes advan-tage of the complex thesaurii built and maintained bythe National Library of Medicine by making use of ametathesaurus and semantic network based on these the-saurii.
The system uses a syntactic parser against thequeries, related text, the metathesaurus, and an onlinedictionary to construct noun phrases that are groupedinto concepts.
It then attempts to match these conceptsagainst documents that have not only some naturally-occurring text, but also manual indexing terms based onthe thesaurii.
The paper discusses the problems foundin mapping the language of the queries to the languageof the relevant documents, a major difficulty for all in-formation retrieval systems.
In this case, as opposedto the earlier papers, the features of the text that areindexed are fixed, and the issue is how to properly con-struct queries, or properly map natural anguage queries,into structures that will match the text features.The fourth paper, "Classifying Texts using RelevancySignatures" by Ellen Riloff and Wendy Lehnert of theUniversity of Massachusetts, investigates feature selec-tion for text classification, as did the second paper.
Theapplication here, however, is not how to route text intomultiple predefined categories, but how to separate ar-ticles into only two sets: those relevant o a specific butcomplex topic, and those not relevant.
This is used asa filtering or text skimming preprocessor to text extrac-tion.
The paper describes the design of an algorithm thatwill locate linguistic expressions that are reliable cluesto document relevancy.
These expressions are found byparsing the training set as input to the algorithm, andthen automatically selecting the expressions or featuresthat occur in the relevant and non-relevant documents.These features can then be used for later classificationin new collections.
As contrasted to the second paper,the techniques rely on analysis of the training collectionto locate features, rather than on trying to identify moregeneral methods of constructing features from the text.References1.
Belkin N.J. and Croft W.B.
(1987).
Retrieval Tech-niques.
In Williams, M.
(Ed.
), Annual Review of In-formation Science and Technology (pp.
109-145).
NewYork, NY: Elsevier Science Publishers.2.
Harman D. and Candela G. (1990).
Retrieving Recordsfrom a Gigabyte of Text on a Minicomputer using Sta-tistical Ranking, Journal of the American Society forInformation Science, 41(8), 581-589.3.
Salton G. (1971).
The SMART Retrieval System -- Ex-periments in Automatic Document Processing, Prentice-Hall, Englewood Cliffs, N.J.2044.
Smeaton A.F.
(1990).
Natural Language Processing andInformation Retrieval.
Special Edition of InformationProcessing and Management, 26(1).5.
Stevens M.F.
(1965).
Automatic Indexing: A State ofthe Art Report.
Monograph 91, National Bureau of Stan-dards, Washington, D.C., March 1965.205
