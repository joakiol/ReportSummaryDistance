Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1398?1407,Singapore, 6-7 August 2009.c?2009 ACL and AFNLPDetecting Speculations and their Scopes in Scientific TextArzucan?Ozg?urDepartment of EECSUniversity of MichiganAnn Arbor, MI 48109, USAozgur@umich.eduDragomir R. RadevDepartment of EECS andSchool of InformationUniversity of MichiganAnn Arbor, MI 48109, USAradev@umich.eduAbstractDistinguishing speculative statementsfrom factual ones is important for mostbiomedical text mining applications.
Weintroduce an approach which is basedon solving two sub-problems to identifyspeculative sentence fragments.
The firstsub-problem is identifying the speculationkeywords in the sentences and the secondone is resolving their linguistic scopes.We formulate the first sub-problem as asupervised classification task, where weclassify the potential keywords as realspeculation keywords or not by usinga diverse set of linguistic features thatrepresent the contexts of the keywords.After detecting the actual speculationkeywords, we use the syntactic structuresof the sentences to determine their scopes.1 IntroductionSpeculation, also known as hedging, is a fre-quently used language phenomenon in scientificarticles, especially in experimental studies, whichare common in the biomedical domain.
When re-searchers are not completely certain about the in-ferred conclusions, they use speculative languageto convey this uncertainty.
Consider the follow-ing example sentences from abstracts of articles inthe biomedical domain.
The abstracts are availableat the U.S. National Library of Medicine PubMedweb page1.
The PubMed Identifier (PMID) of thecorresponding article is given in parenthesis.1.
We showed that the Roaz protein bound specifically toO/E-1 by using the yeast two-hybrid system.
(PMID:9151733)2.
These data suggest that p56lck is physically associatedwith Fc gamma RIIIA (CD16) and functions to mediate1http://www.ncbi.nlm.nih.gov/pubmed/signaling events related to the control of NK cellularcytotoxicity.
(PMID: 8405050)The first sentence is definite, whereas the sec-ond one contains speculative information, which isconveyed by the use of the word ?suggest?.
Whilespeculative information might still be useful forbiomedical scientists, it is important that it is dis-tinguished from the factual information.Recognizing speculations in scientific text hasgained interest in the recent years.
Previousstudies focus on identifying speculative sentences(Light et al, 2004; Medlock and Briscoe, 2007;Szarvas, 2008; Kilicoglu and Bergler, 2008).However, in many cases, not the entire sentence,but fragments of a sentence are speculative.
Con-sider the following example sentences.1.
The mature mitochondrial forms of the erythroid andhousekeeping ALAS isozymes are predicted to havemolecular weights of 59.5 kd and 64.6 kd, respectively.
(PMID: 2050125)2.
Like RAD9, RAD9B associates with HUS1, RAD1, andRAD17, suggesting that it is a RAD9 paralog thatengages in similar biochemical reactions.
(PMID:14611806)Both sentences are speculative, since they con-tain speculative information, which is signaled bythe use of the word ?predicted?
in the first sen-tence and the word ?suggesting?
in the secondsentence.
The scope of the speculation keyword?predicted?
in the first sentence spans the entiresentence.
Therefore, classifying the sentence asspeculative does not cause information loss.
How-ever, the scope of the speculation keyword ?sug-gesting?
in the second sentence applies only tothe second clause of the sentence.
In other words,only the statement ?RAD9B is a RAD9 paralogthat engages in similar biochemical reactions?
isspeculative.
The statement ?Like RAD9, RAD9Bassociates with HUS1, RAD1, and RAD17?
con-veys factual information.
Therefore, classifying1398the entire sentence as speculative will result in in-formation loss.In this paper, we aim to go beyond recogniz-ing speculative sentences and tackle the problemof identifying speculative fragments of sentences.We propose an approach which is based on solv-ing two sub-problems: (1) detecting the real spec-ulation keywords, (2) resolving their linguisticscopes in the sentences.
As the previous exam-ples demonstrated speculations are signaled withspeculation keywords (e.g.
might, suggest, likely,hypothesize, could, predict, and etc.).
However,these keywords are not always used in a specula-tive context.
In other words, they are not alwaysreal speculation keywords.
Unlike previous ap-proaches which classify sentences as speculativeor not, we formulate the problem as classifying thekeywords as real speculation keywords or not.
Weextract a diverse set of features such as linguisticfeatures that represent the context of the keywordand positional features of the sentence in whichthe keyword occurs.
We use these features withSupport Vector Machines (SVM) to learn modelsto classify whether the occurrence of a keywordis in a speculative context or not.
After detectingthe real speculation keywords, we use the syntacticstructures of the sentences to identify their linguis-tic scopes.2 Related WorkAlthough hedging in scientific articles has beenstudied from a linguistics perspective since the1990s (e.g.
(Hyland, 1998)), it has only gained in-terest from a natural language processing perspec-tive in the recent years.The problem of identifying speculative sen-tences in biomedical articles has been introducedby Light et al (2004).
The authors discussed thepossible application areas of recognizing specu-lative language and investigated whether the no-tion of speculative sentences can be characterizedto enable manual annotation.
The authors devel-oped two automated systems to classify sentencesas speculative or not.
The first method is basedon substring matching.
A sentence is classified asspeculative if it contains one of the 14 predefinedstrings (suggest, potential, likely, may, at least, inpart, possibl, further investigation, unlikely, pu-tative, insights, point toward, promise, propose).The second method is based on using SVM withbag-of-words features.
The substring matchingmethod performed slightly better than the SVMwith bag-of-words features approach.Medlock and Briscoe (2007) extended the workof Light et al (2004) by refining their annota-tion guidelines and creating a publicly availabledata set (FlyBase data set) for speculative sen-tence classification.
They proposed a weakly su-pervised machine learning approach to classifysentences as speculative or not with the aim ofminimizing the need for manually labeled train-ing data.
Their approach achieved 76% preci-sion/recall break-even point (BEP) performanceon the FlyBase data set, compared to the BEPof 60% obtained by Light et al?s (2004) sub-string matching approach on the same data set.Szarvas (2008) extended the weakly supervisedmachine learning methodology of Medlock andBriscoe (2007) by applying feature selection to re-duce the number of candidate keywords, by us-ing limited manual supervision to filter the fea-tures, and by extending the feature representationwith bigrams and trigrams.
In addition, by fol-lowing the annotation guidelines of Medlock andBriscoe (2007), Szarvas (2008) made available theBMC Bioinformatics data set, by annotating fourfull text papers from the open access BMC Bioin-formatics website.
They achieved a BEP perfor-mance of 85.29% and an F-measure of 85.08% onthe FlyBase data set.
The F-measure performanceachieved on the BMC Bioinformatics data set was74.93% when the FlyBase data set was used fortraining.
Kilicoglu and Bergler (2008) compileda list of speculation keywords from the examplesin (Hyland, 1998) and extended this list by us-ing WordNet (Fellbaum, 1998) and UMLS SPE-CIALIST Lexicon (McCray et al, 1994).
Theyused manually crafted syntactic patterns to iden-tify speculative sentences and achieved a BEP andan F-measure of 85% on the FlyBase data set and aBEP and an F-measure of 82% on the BMC Bioin-formatics data set.Unlike pervious studies, which treat the prob-lem of identifying speculative language as a sen-tence classification task, we tackle the more chal-lenging problem of identifying the portions of sen-tences which are speculative.
In other words, weallow a sentence to include both speculative andnon-speculative parts.
We introduce and eval-uate a diverse set of features that represent thecontext of a keyword and use these features ina supervised machine learning setting to classify1399the keywords as real speculation keywords or not.Then, we develop a rule-based method to deter-mine their linguistic scopes by considering thekeyword-specific features and the syntactic struc-tures of the sentences.
To the best of our knowl-edge, the BioScope corpus (Vincze et al, 2008) isthe only available data set that has been annotatedfor speculative sentence fragments and we reportthe first results on this corpus.3 CorpusThe BioScope corpus2has been annotated at thetoken level for speculation keywords and at thesentence level for their linguistic scopes (Vinczeet al, 2008).
The corpus consists of three sub-corpora: medical free texts (radiology reports),biomedical article abstracts, and biomedical fulltext articles.
In this paper we focus on identifyingspeculations in scientific text.
Therefore, we usethe biomedical article abstracts and the biomedi-cal full text articles in our experiments.
The statis-tics (number of documents, number of sentences,and number of occurrences of speculation key-words) for these two sub-corpora are given in Ta-ble 1.
The scientific abstracts in the BioScope cor-Data Set Documents Sentences Hedge KeywordsAbstracts 1273 11871 2694Full Papers 9 2670 682Table 1: Summary of the biomedical scientific articles sub-corpora of the BioScope corpuspus were included from the Genia corpus (Col-lier et al, 1999).
The full text papers consist offive articles from the FlyBase data set and fourarticles from the open access BMC Bioinformat-ics website.
The sentences in the FlyBase andBMC Bioinformatics data sets were annotated asspeculative or not and made available by Med-lock and Briscoe (2007) and Szarvas (2008), re-spectively and have been used by previous stud-ies in identifying speculative sentences (Medlockand Briscoe, 2007; Kilicoglu and Bergler, 2008;Szarvas, 2008).
Vincze et al (2008) annotatedthese full text papers and the Genia abstracts forspeculation keywords and their scopes and in-cluded them to the BioScope corpus.
The key-words were annotated with a minimalist strategy.In other words, the minimal unit that expressesspeculation was annotated as a keyword.
A key-word can be a single word (e.g.
suggest, predict,2Available at: http://www.inf.u-szeged.hu/rgai/bioscopemight) or a phrase (complex keyword), if none ofthe words constituting the phrase expresses a spec-ulation by itself.
For example the phrase ?no ev-idence of??
in the sentence ?Direct sequencing ofthe viral genomes and reinfection kinetics showedno evidence of wild-type reversion even after pro-longed infection with the Tat- virus.?
is an exampleof a complex keyword, since the words formingthe phrase can only express speculation together.In contrast to the minimalist strategy followedwhen annotating the keywords, the annotation ofscopes of the keywords was performed by assign-ing the scope to the largest syntactic unit possibleby including all the elements between the keywordand the target word to the scope (in order to avoidscopes without a keyword) and by including themodifiers of the target word to the scope (Vinczeet al, 2008).
The reader can refer to (Vincze et al,2008) for the details of the corpus and the annota-tion guidelines.The inter-annotator agreement rate was mea-sured as the F-measure of the annotations of thefirst annotator by considering the annotations ofthe second one as the gold standard.
The agree-ment rate for speculation keyword annotation isreported as 92.05% for the abstracts and 90.81%for the full text articles and the agreement rate forspeculation scope resolution is reported as 94.04%for the abstracts and 89.67% for the full text ar-ticles (Vincze et al, 2008).
These rates can beconsidered as the upper bounds for the automatedmethods proposed in this paper.4 Identifying Speculation KeywordsWords and phrases such as ?might?, ?suggest?,?likely?, ?no evidence of?, and ?remains to beelucidated?
that can render statements speculativeare called speculation keywords.
Speculation key-words are not always used in speculative context.For instance, consider the following sentences:1.
Thus, it appears that the T-cell-specific activation ofthe proenkephalin promoter is mediated by NF-kappaB.
(PMID: 91117203)2.
Differentiation assays using water soluble phorbol es-ters reveal that differentiation becomes irreversiblesoon after AP-1 appears.
(PMID: 92088960)The keyword ?appears?
in the first sentence ren-ders it speculative.
However, in the second sen-tence, ?appears?
is not used in a speculative con-text.1400The first sub-problem that we need to solve inorder to identify speculative sentence fragments isidentifying the real speculation keywords in a sen-tence (i.e.
the keywords which convey speculativemeaning in the sentence).
We formulate the prob-lem as a supervised classification task.
We extractthe list of keywords from the training data whichhas been labeled for speculation keywords.
Wematch this list of keywords in the unlabeled (testdata) and train a model to classify each occurrenceof a keyword in the unlabeled test set as a realspeculation keyword or not.
The challenge of thetask can be demonstrated by the following statis-tics from the Genia Abstracts of the BioScope cor-pus.
There are 1273 abstracts in the corpus.
Thereare 138 unique speculation keywords and the to-tal number of their occurrence in the abstracts is6125.
In only 2694 (less than 50%) of their occur-rences they are used in speculative context (i.e.,are real speculation keywords).In this study we focus on identifying the fea-tures that represent the context of a speculationkeyword and use SVM with linear kernel (weused the SVMlightpackage (Joachims, 1999)) asour classification algorithm.
The following sub-section describes the set of features that we pro-pose.4.1 Feature ExtractionWe introduce a set of diverse types of featuresincluding keyword specific features such as thestem and the part-of-speech (POS) of the keyword,and keyword context features such as the wordssurrounding the keyword, the dependency rela-tion types originating at the keyword, the otherkeywords that occur in the same sentence as thekeyword, and positional features such as the sec-tion of the paper in which the keyword occurs.While designing the features, we were inspired bystudies on other natural language processing prob-lems such as Word Sense Disambiguation (WSD)and summarization.
For example, machine learn-ing methods with features based on part-of-speechtags, word stems, surrounding and co-occurringwords, and dependency relationships have beensuccessfully used in WSD (Montoyo et al, 2005;Ng and Lee, 1996; Dligach and Palmer, 2008) andpositional features such as the position of a sen-tence in the document have been used in text sum-marization (e.g.
(Radev et al, 2004)).4.1.1 Keyword FeaturesStatistics from the BioScope corpus suggest thatdifferent keywords have different likelihoods ofbeing used in a speculative context (Vincze et al,2008).
For example, the keyword ?suggest?
hasbeen used in a speculative context in all its oc-currences in the abstracts and in the full papers.On the other hand, ?appear?
is a real specula-tion keyword in 86% of its occurrences in the ab-stracts and in 83% of its occurrences in the fullpapers, whereas ?can?
is a real speculation key-word in 12% of its occurrences in the abstracts andin 16% of its occurrences in the full papers.
POSof a keyword might also play a role in determiningwhether it is a real speculation keyword or not.
Forexample, consider the keyword ?can?.
It is morelikely to have been used in a speculative contextwhen it is a modal verb, than when it is a noun.Based on these observations, we hypothesize thatfeatures specific to a keyword such as the keyworditself, the stem of the keyword, and the POS ofthe keyword might be useful in discriminating thespeculative versus non-speculative use of it.
Weuse Porter?s Stemming Algorithm (Porter, 1980)to obtain the stems of the keywords and StanfordParser (de Marneffe et al, 2006) to get the POS ofthe keywords.
If a keywords consists of multiplewords, we use the concatenation of the POS of thewords constituting the keyword as a feature.
Forexample, the extracted POS feature for the key-words ?no evidence?
and ?no proof?
is ?DT.NN?.4.1.2 Dependency Relation FeaturesBesides the occurrence of a speculation keyword,the syntactic structure of the sentence also playsan important role in characterizing speculations.Kilicoglu and Bergler (2008) showed that man-ually identified syntactic patterns are effective inclassifying sentences as speculative or not.
Theyidentified that, while some keywords do not in-dicate hedging when used alone, they might actas good indicators of hedging when used with aclausal complement or with an infinitival clause.For example, the ?appears?
keyword in the ex-ample sentences, which are given in the beginningof Section 4, is not a real speculation keyword inthe second example ?...soon after AP-1 appears.
?, whereas it is a real speculation keyword in thefirst example, where it is used with a that clausalcomplement ?...it appears that...?.
Similarly, ?ap-pears?
is used in a speculative context in the fol-1401lowing sentence, where it is used with an infini-tival clause: ?Synergistic transactivation of theBMRF1 promoter by the Z/c-myb combination ap-pears to involve direct binding by the Z protein.
?.Another observation is that, some keywordsact as real speculation keywords only when usedwith a negation.
For example, words such as?know?, ?evidence?, and ?proof?
express cer-tainty when used alone, but express a speculationwhen used with a negation (e.g., ?not known?,?no evidence?, ?no proof?
).Auxiliaries in verbal elements might also giveclues for the speculative meaning of the mainverbs.
Consider the example sentence: ?Our find-ings may indicate the presence of a reactivatedvirus hosted in these cells.?.
The modal auxiliary?may?
acts as a clue for the speculative context ofthe main verb ?indicate?.We defined boolean features to represent thesyntactic structures of the contexts of the key-words.
We used the Stanford Dependency Parser(de Marneffe et al, 2006) to parse the sentencesthat contain a candidate speculation keyword andextracted the following features from the depen-dency parse trees.Clausal Complement: A Boolean feature which is set to 1,if the keyword has a child which is connected to it witha clausal complement or infinitival clause dependencytype.Negation: A Boolean feature which is set to 1, if the key-word (1) has a child which is connected to it with anegation dependency type (e.g.
?not known?
: ?not?
isa child of ?known?, and the Stanford Dependency Typeconnecting them is ?neg?)
or (2) the determiner ?no?
isa child of the keyword (e.g., ?no evidence?
: ?no?
is achild of ?evidence?
and the Stanford Dependency Typeconnecting them is ?det?
).Auxiliary: A Boolean feature which is set to 1, if the key-word has a child which is connected to it with an auxil-iary dependency type (e.g.
?may indicate?
: ?may?
is achild of ?indicate?, and the Stanford Dependency Typeconnecting them is ?aux?
).If a keyword consists of multiple-words, we ex-amine the children of the word which is the an-cestor of the other words constituting the key-word.
For example, ?no evidence?
is a multi-wordkeyword, where ?evidence?
is the parent of ?no?.Therefore, we extract the dependency parse treefeatures for the word ?evidence?.4.1.3 Surrounding WordsRecent studies showed that using machine learn-ing with variants of the ?bag-of-words?
featurerepresentation is effective in classifying sentencesas speculative vs. non-speculative (Light et al,2004; Medlock and Briscoe, 2007; Szarvas, 2008).Therefore, we also decided to include bag-of-words features that represent the context of thespeculation keyword.
We extracted the words sur-rounding the keyword and performed experimentsboth with and without stemming, and with win-dow sizes of one, two, and three.
Consider thesentence: ?Our findings may indicate the presenceof a reactivated virus hosted in these cells.?.
Thebag-of-words features for the keyword ?indicate?,when a window size of three and no stemming isused are: ?our?, ?findings?, ?may?, ?indicate?,?the?, ?presence?, ?of?.
In other words, the fea-ture set consists of the keyword, the three words tothe left of the keyword, and the three words to theright of the keyword.4.1.4 Positional FeaturesDifferent parts of a scientific article might havedifferent characteristics in terms of the usage ofspeculative language.
For example, Hyland (1998)analyzed a data set of molecular biology articlesand reported that the distribution of speculationsis similar between abstracts and full text articles,whereas the Results and Discussion sections tendto contain more speculative statements comparedto the other sections (e.g.
Materials and Methodsor Introduction and Background sections).
Theanalysis of Light et al (2004) showed that the lastsentence of an abstract is more likely to be specu-lative than non-speculative.For the scientific abstracts data set, we definedthe following boolean features to represent the po-sition of the sentence the keyword occurs in.
Ourintuition is that titles and the first sentences in theabstract tend to be non-speculative, whereas thelast sentence of the abstract tends to be specula-tive.Title: A Boolean feature which is set to 1, if the keywordoccurs in the title.First Sentence: A Boolean feature which is set to 1, if thekeyword occurs in the first sentence of the abstract.Last Sentence: A Boolean feature which is set to 1, if thekeyword occurs in the last sentence of the abstract.For the scientific full text articles data set, wedefined the following features that represent theposition of the sentence in which the keyword oc-curs.
Our assumption is that the ?Results and Dis-cussion?
and the ?Conclusion?
sections tend to1402contain more speculative statements than the ?Ma-terials and Methods?
and ?Introduction and Back-ground?
sections.
We also assume that figure andtable legends are not likely to contain speculativestatements.Title: A Boolean feature which is set to 1, if the keywordoccurs in the title of the article, or in the title of a sec-tion or sub-section.First Sentence: A Boolean feature which is set to 1, if thekeyword occurs in the first sentence of the abstract.Last Sentence: A Boolean feature which is set to 1, if thekeyword occurs in the last sentence of the abstract.Background: A Boolean feature which is set to 1, if thekeyword occurs in the Background or Introduction sec-tion.Results: A Boolean feature which is set to 1, if the keywordoccurs in the Results or in the Discussion section.Methods: A Boolean feature which is set to 1, if the key-word occurs in the Materials and Methods section.Conclusion: A Boolean feature which is set to 1, if the key-word occurs in the Conclusion section.Legend: A Boolean feature which is set to 1, if the keywordoccurs in a table or figure legend.4.1.5 Co-occurring KeywordsSpeculation keywords usually co-occur in the sen-tences.
Consider the sentence: ?We, therefore,wished to determine whether T3SO4 could mimicthe action of thyroid hormone in vitro.?.
Here,?whether?
and ?could?
are speculation keywordsand their co-occurence might be a clue for theirspeculative context.
Therefore, we decided to in-clude the co-occurring keywords to the feature setof a keyword.5 Resolving the Scope of a SpeculationAfter identifying the real speculation keywords,the next step is determining their scopes in the sen-tences, so that the speculative sentence fragmentscan be detected.
Manual analysis of sample sen-tences from the BioScope corpus and their parsetrees suggests that the scope of a keyword can becharacterized by its part-of-speech and the syntac-tic structure of the sentence in which it occurs.Consider the example sentence whose parse treeis shown in Figure 1.
The sentence contains threespeculation keywords, ?or?
and two occurrencesof ?might?.
The scope of the conjunction ?or?, ex-tends to the ?VP?
whose children it coordinates.In other words, the scope of ?or?
is ?
[might beone of the earliest crucial steps in the lysis of nor-mal and dex-resistant CEM cells, or might serveas a marker for the process]?.
Here, ?or?
con-veys a speculative meaning, since we are not cer-tain which of the two sub-clauses (sub-clause 1:[might be one of the earliest crucial steps in thelysis of normal and dex-resistant CEM cells] orsub-clause 2: [might serve as a marker for the pro-cess]) is correct.
The scope of both occurrencesof the modal verb ?might?
is the parent ?VP?.
Inother words, the scope of the first occurrence of?might?
is ?
[might be one of the earliest crucialsteps in the lysis of normal and dex-resistant CEMcells]?
and the scope of the second occurrence of?might?
is ?
[might serve as a marker for the pro-cess]?.
By examining the keywords, sample sen-tences and their syntactic parse trees we devel-oped the following rule-based approach to resolvethe scopes of speculation keywords.
The exam-ples given in this section are based on the syntacticstructure of the Penn Tree Bank.
But, the rules aregeneric (e.g.
?the scope of a verb followed by aninfinitival clause, extends to the whole sentence?
).The scope of a conjunction or a determiner (e.g.or, and/or, vs) is the syntactic phrase to which itis attached.
For example, the scope of ?or?
inFigure 1 is the ?VP?
immediately dominating the?CC?.The scope of a modal verb (e.g.
may, might,could) is the ?VP?
to which it is attached.
Forexample, the scope of ?might?
in Figure 1 is the?VP?
immediately dominating the ?MD?.The scope of an adjective or an adverb startswith the keyword and ends with the last token ofthe highest level ?NP?
which dominates the ad-jective or the adverb.
Consider the sentence ?Theendocrine events that are rapidly expressed (sec-onds) are due to a [possible interaction with cellu-lar membrane].?
The scope of the speculation key-word ?possible?
is enclosed in rectangular brack-ets.
The sub-tree that this scope maps to is: ?
(NP(NP (DT a) (JJ possible) (NN interaction)) (PP(IN with) (NP (JJ cellular) (NN membrane))))?.If there does not exist a ?NP?
dominating the ad-verb or adjective keyword, the scope extends tothe whole sentence.
For example the scope ofthe speculation adverb ?probably?
in the sentence?
[The remaining portion of the ZFB motif wasprobably lost in TPases of insect Transib trans-posons]?
is the whole sentence.The scope of a verb followed by an infinitival1403Figure 1: The syntactic parse tree of the sentence ?Positive induction of GR mRNA might be one of the earliest crucial stepsin the lysis of normal and dex-resistant CEM cells, or might serve as a marker for the process.
?clause extends to the whole sentence.
For exam-ple, the scope of the verb ?appears?
followed bythe ?to?
infinitival clause is the whole sentence in?
[The block of pupariation appears to involve sig-naling through the adenosine receptor (AdoR)]?.The scope of a verb in passive voice extendsto the whole sentence such as the scope of ?sug-gested?
in ?
[The existence of such an indepen-dent mechanism has also been suggested in mam-mals]?.If none of the above rules apply, the scope of akeyword starts with the keyword and ends at theend of the sentence (or clause).
An example isthe scope of ?suggested?
in ?This [suggested thatthere is insufficient data currently available to de-termine a reliable ratio for human]?.6 EvaluationWe evaluated our approach on two different typesof scientific text from the biomedical domain,namely the scientific abstracts sub-corpus and thefull text articles sub-corpus of the BioScope cor-pus (see Section 3).
We used stratified 10-foldcross-validation to evaluate the performance onthe abstracts.
In each fold, 90% of the abstracts areused for training and 10% are used to test.
To facil-itate comparison with future studies the PubMedIdentifiers of the abstracts that we used as a testset in each fold are provided3.
The full text pa-pers sub-corpus consists of nine articles.
We usedleave-one-out cross-validation to evaluate the per-3http://belobog.si.umich.edu/clair/bioscope/formance on the full text papers.
In each iterationeight articles are used for training and one articleis used to test.
We report the average results overthe runs for each data set.6.1 Evaluation of Identifying SpeculationKeywordsTo classify whether the occurrence of a keyword isin speculative context or not, we built linear SVMmodels by using various combinations of the fea-tures introduced in Section 4.1.
Tables 2 and 3summarize the results obtained for the abstractsand the full text papers, respectively.
BOW N isthe bag-of-words features obtained from the wordssurrounding the keyword (see Section 4.1.3).
N isthe window size.
We experimented both with thestemmed and non-stemmed versions of this fea-ture type.
The non-stemmed versions performedslightly better than the stemmed versions.
The rea-son might be due to the different likelihoods ofbeing used in a speculative context of different in-flected forms of words.
For example, consider thewords ?appears?
and ?appearance?.
They have thesame stems, but ?appearance?
is less likely to be areal speculation keyword than ?appears?.
Anotherobservation is that, decreasing the window sizeled to improvement in performance.
This suggeststhat the words right before and right after the can-didate speculation keyword are more effective indistinguishing its speculative vs. non-speculativecontext compared to a wider local context.
Widerlocal context might create sparse data and degrade1404performance.
Consider the example, ?it appearsthat TP53 interacts with AR?.
The keyword ?ap-pears?, and BOW1 (?it?
and ?that?)
are more rel-evant for the speculative context of the keywordthan ?TP53?, ?interacts?, and ?with?.
Therefore,for the rest of the experiments we used the BOW1 version, i.e., the non-stemmed surrounding bag-of-words with window size of 1.
KW stands forthe keyword specific features, i.e., the keyword, itsstem, and its part-of-speech (discussed in Section4.1.1).
DEP stands for the dependency relationfeatures (discussed in Section 4.1.2).
POS standsfor the positional features (discussed in Section4.1.4) and CO-KW stands for the co-occurringkeywords feature (discussed in Section 4.1.5).Our results are not directly comparable withthe prior studies about identifying speculative sen-tences (see Section 2), since we attempted to solvea different problem, which is identifying specula-tive parts of sentences.
Only the substring match-ing approach that was introduced in (Light et al,2004) could be adapted as a keyword classificationtask, since the substrings are keywords themselvesand we used this approach as a baseline in thekeyword classification sub-problem.
We comparethe performances of our models with two baselinemethods, which are based on the substring match-ing approach.
Light et al (2004) have shown thatthe substring matching method with a predefinedset of 14 strings performs slightly better than anSVM model with bag-of-words features in classi-fying sentences as speculative vs. non-speculative(see Section 2).
In baseline 1, we use the 14 stringsidentified in (Light et al, 2004) and classify all thekeywords in the test set that match any of them asreal speculation keywords.
Baseline 2 is similarto baseline 1, with the difference that rather thanusing the set of strings in (Light et al, 2004), weextract the set of keywords from the training setand classify all the words (or phrases) in the testset that match any of the keywords in the list asreal speculation keywords.Baseline 1 achieves high precision, but low re-call.
Whereas, baseline 2 achieves high recall inthe expense of low precision.
All the SVM mod-els in Tables 2 and 3 achieve more balanced preci-sion and recall values, with F-measure values sig-nificantly higher than the baseline methods.
Westart with a model that uses only the keyword-specific features (KW).
This type of feature aloneachieved a significantly better performance thanthe baseline methods (90.61% F-measure for theabstracts and 80.57% F-measure for the full textpapers), suggesting that the keyword-specific fea-tures are important in determining its specula-tive context.
We extended the feature set by in-cluding the dependency relation (DEP), surround-ing words (BOW 1), positional (POS), and co-occurring keywords (CO-KW) features.
Each newtype of included feature improved the performanceof the model for the abstracts.
The best F-measure(91.69%) is achieved by using all the proposedtypes of features.
This performance is close to theupper bound, which is the human inter-annotatoragreement F-measure of 92.05%.Including the co-occurring keywords to the fea-ture set for full text articles slightly improved pre-cision, but deceased recall, which led to lower F-measure.
The best F-measure (82.82%) for thefull text articles is achieved by using all the fea-ture types except the co-occurring keywords.
Theachieved performance is significantly higher thanthe baseline methods, but lower than the humaninter-annotator agreement F-measure of 90.81%.The lower performance for the full text papersmight be due to the small size of the data set (9full text papers compared to 1273 abstracts).Method Recall Precision F-MeasureBaseline 1 52.84 92.71 67.25Baseline 2 97.54 43.66 60.30BOW 3 - stemmed 81.47 92.36 86.51BOW 2 - stemmed 81.56 93.29 86.97BOW 1 - stemmed 83.08 93.83 88.05BOW 3 82.58 92.04 86.98BOW 2 82.77 92.74 87.41BOW 1 83.27 93.67 88.10KW: kw, kw-stem, kw-pos 88.62 92.77 90.61KW, DEP 88.77 92.67 90.64KW, DEP, BOW 1 88.46 94.71 91.43KW, DEP, BOW 1, POS 88.16 95.21 91.50KW, DEP, BOW 1, POS, CO-KW 88.22 95.56 91.69Table 2: Results for the Scientific AbstractsMethod Recall Precision F-MeasureBaseline 1 33.77 86.75 47.13Baseline 2 88.22 52.57 64.70BOW 3 - stemmed 70.79 83.88 76.58BOW 2 - stemmed 72.31 85.49 78.11BOW 1 - stemmed 73.49 84.35 78.41BOW 3 70.54 82.56 75.88BOW 2 71.52 85.93 77.94BOW 1 73.72 86.27 79.43KW: kw, kw-stem, kw-pos 75.21 87.08 80.57KW, DEP 75.02 89.49 81.53KW, DEP, BOW 1 76.15 89.54 82.27KW, DEP, BOW 1, POS 76.17 90.81 82.82KW, DEP, BOW 1, POS, CO-KW 75.76 90.82 82.58Table 3: Results for the Scientific Full Text Papers14056.2 Evaluation of Resolving the Scope of aSpeculationWe compared the proposed rule-based approachfor scope resolution with two baseline methods.Previous studies classify sentences as speculativeor not, therefore implicitly assigning the scope ofa speculation to the whole sentence (Light et al,2004; Medlock and Briscoe, 2007; Szarvas, 2008;Kilicoglu and Bergler, 2008).
Baseline 1 followsthis approach and assigns the scope of a specu-lation keyword to the whole sentence.
Szarvas(2008) suggest assigning the scope of a keywordfrom its occurrence to the end of the sentence.They state that this approach works accurately forclinical free texts, but no any results are reported(Szarvas, 2008).
Baseline 2 follows the approachproposed in (Szarvas, 2008) and assigns the scopeof a keyword to the fragment of the sentence thatstarts with the keyword and ends at the end of thesentence.
Table 4 summarizes the accuracy resultsobtained for the abstracts and the full text papers.The poor performance of baseline 1, empha-sizes the importance of detecting the portions ofsentences that are speculative, since less than 5%of the sentences that contain speculation keywordsare entirely speculative.
Classifying the entire sen-tences as speculative or not leads to loss in infor-mation for more than 95% of the sentences.
Therule-based method significantly outperformed thetwo baseline methods, indicating that the part-of-speech of the keywords and the syntactic parsesof the sentences are effective in characterizing thespeculation scopes.Method Accuracy-Abstracts Accuracy-Full textBaseline 1 4.82 4.29Baseline 2 67.60 42.82Rule-based method 79.89 61.13Table 4: Scope resolution results7 ConclusionWe presented an approach to identify speculativesentence fragments in scientific articles.
Our ap-proach is based on solving two sub-problems.
Thefirst one is identifying the keywords which areused in speculative context and the second one isdetermining the scopes of these keywords in thesentences.
We evaluated our approach for twotypes of scientific texts, namely abstracts and fulltext papers from the BioScope corpus.We formulated the first sub-problem as a super-vised classification task, where the aim is to learnmodels to classify the candidate speculation key-words as real speculation keywords or not.
We fo-cused on identifying different types of linguisticfeatures that capture the contexts of the keywords.We achieved a performance which is significantlybetter than the baseline methods and comparableto the upper-bound, which is the human inter-annotator agreement F-measure.We hypothesized that the scope of a specula-tion keyword can be characterized by its part-of-speech and the syntactic structure of the sentenceand developed rules to map the scope of a key-word to the nodes in the syntactic parse tree.
Weachieved a significantly better performance com-pared to the baseline methods.
The considerablylower performance of the baseline of assigning thescope of a speculation keyword to the whole sen-tence indicates the importance of detecting specu-lative sentence portions rather than classifying theentire sentences as speculative or not.AcknowledgementsThis work was supported in part by the NIH GrantU54 DA021519 to the National Center for Integra-tive Biomedical Informatics.ReferencesNigel Collier, Hyun S. Park, Norihiro Ogata, YukaTateishi, Chikashi Nobata, Tomoko Ohta, TateshiSekimizu, Hisao Imai, Katsutoshi Ibushi, and Jun I.Tsujii.
1999.
The GENIA project: corpus-basedknowledge acquisition and information extractionfrom genome research papers.
In Proceedings of theninth conference on European chapter of the Asso-ciation for Computational Linguistics, pages 271?272.
Association for Computational Linguistics.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating TypedDependency Parses from Phrase Structure Parses.
InProceedings of LREC-06.Dmitriy Dligach and Martha Palmer.
2008.
Novel Se-mantic Features for Verb Sense Disambiguation.
InProceedings of the 46th Annual Meeting of the Asso-ciation for Computational Linguistics: Human Lan-guage Technologies.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database (Language, Speech, andCommunication).
The MIT Press.Ken Hyland.
1998.
Hedging in Scientific ResearchArticles.
John Benjamins Publishing Co.1406T.
Joachims, 1999.
Advances in Kernel Methods-Support Vector Learning, chapter Making Large-Scale SVM Learning Practical.
MIT-Press.Halil Kilicoglu and Sabine Bergler.
2008.
Recogniz-ing speculative language in biomedical research ar-ticles: a linguistically motivated perspective.
BMCBioinformatics, 9(Suppl 11).Marc Light, Xin Ying Qiu, and Padmini Srinivasan.2004.
The language of bioscience: Facts, spec-ulations, and statements in between.
In LynetteHirschman and James Pustejovsky, editors, HLT-NAACL 2004 Workshop: BioLINK 2004, LinkingBiological Literature, Ontologies and Databases,pages 17?24, Boston, Massachusetts, USA, May 6.Association for Computational Linguistics.A.
T. McCray, S. Srinivasan, and A. C. Browne.
1994.Lexical methods for managing variation in biomed-ical terminologies.
Proc Annu Symp Comput ApplMed Care, pages 235?239.Ben Medlock and Ted Briscoe.
2007.
Weakly super-vised learning for hedge classification in scientificliterature.
In Proceedings of the 45th Annual Meet-ing of the Association of Computational Linguistics,pages 992?999, Prague, Czech Republic, June.
As-sociation for Computational Linguistics.Andres Montoyo, Armando Suarez, German Rigau,and Manuel Palomar.
2005.
Combining knowledge-and corpus-based word-sense-disambiguation meth-ods.
Journal of Artificial Intelligence Research,23:299?330.H.
T. Ng and H. B Lee.
1996.
Integrating multi-ple knowledge sources to disambiguate word senses:An exemplar-based approach.
In Proceedings of the34th Annual Meeting of the Association for Compu-tational Linguistics.M.
F. Porter.
1980.
An algorithm for suffix stripping.Program, 3(14):130?137.Dragomir R. Radev, Timothy Allison, Sasha Blair-Goldensohn, John Blitzer, Arda Celebi, StankoDimitrov, Elliott Drabek, Ali Hakim, Wai Lam,Danyu Liu, Jahna Otterbacher, Hong Qi, HoracioSaggion, Simone Teufel, Adam Winkel, and ZhangZhu.
2004.
Mead - a platform for multidocumentmultilingual text summarization.
In Proceedings ofLREC 2004.Gyorgy Szarvas.
2008.
Hedge classification inbiomedical texts with a weakly supervised selectionof keywords.
In ACL 2008.Veronika Vincze, Gyorgy Szarvas, Richard Farkas, Gy-orgy Mora, and Janos Csirik.
2008.
The BioScopecorpus: biomedical texts annotated for uncertainty,negation and their scopes.
BMC Bioinformatics,9(Suppl 11).1407
