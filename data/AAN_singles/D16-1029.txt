Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 297?306,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsLearning from Explicit and Implicit Supervision JointlyFor Algebra Word ProblemsShyam Upadhyay1 Ming-Wei Chang2 Kai-Wei Chang3 Wen-tau Yih21University of Illinois at Urbana-Champaign, Urbana, IL, USA2Microsoft Research, Redmond, WA, USA3University of Virginia, Charlottesville, VA, USAAbstractAutomatically solving algebra word problemshas raised considerable interest recently.
Ex-isting state-of-the-art approaches mainly relyon learning from human annotated equations.In this paper, we demonstrate that it is pos-sible to efficiently mine algebra problems andtheir numerical solutions with little to no man-ual effort.
To leverage the mined dataset, wepropose a novel structured-output learning al-gorithm that aims to learn from both explicit(e.g., equations) and implicit (e.g., solutions)supervision signals jointly.
Enabled by thisnew algorithm, our model gains 4.6% abso-lute improvement in accuracy on the ALG-514 benchmark compared to the one withoutusing implicit supervision.
The final modelalso outperforms the current state-of-the-artapproach by 3%.1 IntroductionAlgebra word problems express mathematical rela-tionships via narratives set in a real-world scenario,such as the one below:Maria is now four times as old as Kate.Four years ago, Maria was six times asold as Kate.
Find their ages now.The desired output is an equation system which ex-presses the mathematical relationship symbolically:m = 4?
n and m?
4 = 6?
(n?
4) where m andn represent the age of Maria and Kate, respectively.The solution (i.e., m = 40, n = 10) can be found bya mathematical engine given the equation systems.Building efficient automatic algebra word problemsolvers have clear values for online education sce-narios.
The challenge itself also provides a goodtest bed for evaluating an intelligent agent that un-derstands natural languages, a direction advocatedby artificial intelligence researchers (Clark and Et-zioni, 2016).One key challenge of solving algebra word prob-lems is the lack of fully annotated data (i.e., the an-notated equation system associated with each prob-lem).
In contrast to annotating problems with binaryor categorical labels, manually solving algebra wordproblems to provide correct equations is time con-suming.
As a result, existing benchmark datasetsare small, limiting the performance of supervisedlearning approaches.
However, thousands of alge-bra word problems have been posted and discussedin online forums, where the solutions can be easilymined, despite the fact that some of them could beincorrect.
It is thus interesting to ask whether a bet-ter algebra problem solver can be learned by lever-aging these noisy and implicit supervision signals,namely the solutions.In this work, we address the technical difficulty ofleveraging implicit supervision in learning an alge-bra word problem solver.
We argue that the effec-tive strategy is to learn from both explicit and im-plicit supervision signals jointly.
In particular, wedesign a novel online learning algorithm based onstructured-output Perceptron.
By taking both kindsof training signals together as input, the algorithmiteratively improves the model, while at the sametime it uses the intermediate model to find candidateequation systems for problems with only numericalsolutions.297Our contributions are summarized as follows.?
We propose a novel learning algorithm (Sec-tion 3 and 4) that jointly learns from both ex-plicit and implicit supervision.
Under differentsettings, the proposed algorithm outperformsthe existing supervised and weakly supervisedalgorithms (Section 6) for algebra word prob-lems.?
We mine the problem-solution pairs for alge-bra word problems from an online forum andshow that we can effectively obtain the implicitsupervision with little to no manual effort (Sec-tion 5).1?
By leveraging both implicit and explicit su-pervision signals, our final solver outperformsthe state-of-the-art system by 3% on ALG-514, a popular benchmark data set proposed by(Kushman et al, 2014).2 Related WorkAutomatically solving mathematical reasoningproblems expressed in natural language has beena long-studied problem (Bobrow, 1964; Newell etal., 1959; Mukherjee and Garain, 2008).
Recently,Kushman et al (2014) created a template-basesearch procedure to map word problems intoequations.
Then, several following papers studieddifferent aspects of the task: Hosseini et al (2014)focused on improving the generalization ability ofthe solvers by leveraging extra annotations; Royand Roth (2015) focused on how to solve arithmeticproblems without using any pre-defined template.In (Shi et al, 2015), the authors focused on numberword problems and proposed a system that iscreated using semi-automatically generated rules.In Zhou et al (2015), the authors simplified theinference procedure and pushed the state-of-the-artbenchmark accuracy.
The idea of learning fromimplicit supervision is discussed in (Kushman etal., 2014; Zhou et al, 2015; Koncel-Kedziorskiet al, 2015), where the authors train the algebrasolvers using only the solutions with little or noannoated equation systems.
We discuss this in detailin Section 4.1The new resource and the dataset we used for training isavailable soon on https://aka.ms/dataimplicit andhttps://aka.ms/datadrawSolving automatic algebra word problems can beviewed as a semantic parsing task.
In the semanticparsing community, the technique of learning fromimplicit supervision signals has been applied (un-der the name response-driven learning (Clarke et al,2010)) to knowledge base question answering taskssuch as Geoquery (Zelle and Mooney, 1996) andWebQuestions (Berant et al, 2013) or mapping in-structions to actions (Artzi and Zettlemoyer, 2013).In these tasks, researchers have shown that it is pos-sible to train a semantic parser only from question-answer pairs, such as ?What is the largest state bor-dering Texas??
and ?New Mexico?
(Clarke et al,2010; Liang et al, 2013; Yih et al, 2015).One key reason that such implicit supervision iseffective is because the correct semantic parses ofthe questions can often be found using the answersand the knowledge base alone, with the help ofheuristics developed for the specific domain.
Forinstance, when the question is relatively simpleand does not have complex compositional structure,paths in the knowledge graph that connect the an-swers and the entities in the narrative can be inter-preted as legitimate semantic parses.
However, aswe will show in our experiments, learning from im-plicit supervision alone is not a viable strategy foralgebra word problems.
Compared to the knowl-edge base question answering problems, one key dif-ference is that a large number (potentially infinitelymany) of different equation systems could end uphaving the same solutions.
Without a database orspecial rules for combining variables and coeffi-cients, the number of candidate equation systemscannot be trimmed effectively, given only the solu-tions.From the algorithmic point of view, our proposedlearning framework is related to several lines ofwork.
Similar efforts have been made to develop la-tent structured prediction models (Yu and Joachims,2009; Chang et al, 2013; Zettlemoyer and Collins,2007) to find latent semantic structures which bestexplain the answer given the question.
Our algo-rithm is also influenced by the discriminative re-ranking algorithms (Collins, 2000; Ge and Mooney,2006; Charniak and Johnson, 2005) and modelsfor learning from intractable supervision (Steinhardtand Liang, 2015).Recently, Huang et al (2016) collected a large298number of noisily annotated word problems fromonline forums.
While they collected a large-scaledataset, unlike our work, they did not demonstratehow to utilize the newly crawled dataset to improveexisting systems.
It will be interesting to see if ourproposed algorithm can make further improvementsusing their newly collected dataset.23 Problem DefinitionTable 1 lists all the symbols representing the compo-nents in the process.
The input algebra word prob-lem is denoted by x, and the output y = (T,A) iscalled a derivation, which consists of an equationsystem template T and an alignment A.
A templateT is a family of equation systems parameterized bya set of coefficients C(T ) = {ci}ki=1, where each co-efficient ci aligns to a textual number (e.g., four) in aword problem.
Let Q(x) be all the textual numbersin the problem x, and C(T ) be the coefficients to bedetermined in the template T .
An alignment is a setof tuples A = {(q, c) | q ?
Q(x), c ?
C(T ) ?
{}},where the tuple (q, ) indicates that the number q isnot relevant to the final equation system.
By spec-ifying the value of each coefficient, it identifies anequation system belonging to the family representedby template T .
Together, T and A generate a com-plete equation system, and the solution z can be de-rived by the mathematical engine E.Following (Kushman et al, 2014; Zhou et al,2015), our strategy of mapping a word problem toan equation system is to first choose a template thatconsists of variables and coefficients, and then aligneach coefficient to a textual number mentioned inthe problem.
We formulate the mapping betweenan algebra word problem and an equation system asa structured learning problem.
The output space isthe set of all possible derivations using templatesthat are observed in the training data.
Our modelmaps x to y = (T,A) by a linear scoring functionwT?
(x,y), where w is the model parameters and?
is the feature functions.
At test time, our modelscores all the derivation candidates and picks thebest one according to the model score.
We oftenrefer to y as a semantic parse, as it represents thesemantics of the algebra word problem.2The dataset has not been made public at the time of publi-cation....x2y1y2y3y17650y4...z1z2z3z17650z4...x1y1y2y*y17650y4...z1z2z*z17650z4?
z2*InputSematicParsesDerivedSolutionsInputSematicParsesDerivedSolutionsAnnotatedResponseFigure 1: Left: Explicit supervision signals.
Note thatthe solution z can be derived by the semantic parses y.Right: Implicit supervision signals.
In this case, we onlyhave the annotated response z?2.
It is difficult to use z?2to find the correct derivation, as multiple derivations maylead to the same solution.
Therefore, the learning algo-rithm has to explore the output space to guide the modelin order to match the annotated response.Properties of Implicit Supervision Signals Wediscuss some key properties of the implicit supervi-sion signal to explain several design choices of ouralgorithm.
Figure 1 illustrates the main differencesbetween implicit and explicit supervision signals.Algorithms that learn from implicit supervisionsignals face the following challenges.
First, thelearning system usually does not model directly thecorrelations between the input x and the solutionz.
Instead, the mapping is handled by an externalprocedure such as a mathematical engine.
There-fore, E(y) is effectively a one-directional function.As a result, finding semantic parses (derivations)from responses (solutions) E?1(z) can sometimesbe very slow or even intractable.
Second, in manycases, even if we could find a semantic parse fromresponses, multiple combinations of templates andalignments could end up with the same solution set(e.g., the solutions of equations 2 + x = 4 and2 ?
x = 4 are the same).
Therefore, the implicitsupervision signals may be incomplete and noisy,and using the solutions alone to guide the trainingprocedure might not be sufficient.
Finally, since weneed to have a complete derivation before we canobserve the response of the mathematical engine E,we cannot design efficient inference methods suchas dynamic programming algorithms based on par-tial feedback.
As a result, we have to perform explo-ration during learning to search for fully constructedsemantic parses that can generate the correct solu-tion.299Term Symbol ExampleWord Problem x Maria is now four times as old as Kate.
Four years ago, Maria was sixtimes as old as Kate.
Find their ages now.Derivation (Semantic Parse) y = (T,A) ({m?
a?
n = ?1?
a?
b + b,m?
c?
n = 0}, A)Solution z n = 10, m = 40Mathematical Engine E : y?
z After determining the coefficients, the equation system is {m = 4 ?
n,m?
4 = 6?
(n?
4)}.
The solution is thus n = 10, m = 40.Variables v m, nTextual Number3 Q(x) {four, Four, six}Equation System Template T {m?
a?
n = ?1?
a?
b + b,m?
c?
n = 0}Coefficients C(T ) a, b, cAlignment A six?
a, Four?
b, four?
cTable 1: Notation used in this paper to formally describe the problem of mapping algebra word problems to equations.4 Learning from Mixed SupervisionWe assume that we have two sets: De = {(xe,ye)}and Dm = {(xm, zm)}.
De contains the fully an-notated equation system ye for each algebra wordproblem xe, whereas in Dm, we have access to thenumerical solution zm to each problem, but not theequation system (ym = ?).
We refer toDe as the ex-plicit set and Dm as the implicit set.
For the sake ofsimplicity, we explain our approach by modifyingthe training procedure of the structured Perceptronalgorithm (Collins, 2002).4As discussed in Section 3, the key challenge oflearning from implicit supervision is that the map-ping E(y) is one-directional.
Therefore, the correctequation system cannot be easily derived from thenumerical solution.
Intuitively, for data with onlyimplicit supervision, we can explore the structurespace Y and find the best possible derivation y?
?
Yaccording to the current model.
If E(y?)
matches z,then we can update the model based on y?.
Followingthis intuition, we propose MixedSP (Algorithm 1).For each example, we use an approximate searchalgorithm to collect top scoring candidate structures.The algorithm first ranks the top-K templates ac-cording to the model score, and forms a candidateset by expanding all possible derivations that usethe K templates (Line 3).
The final candidate setis ?
= {y1,y2, .
.
.
,yK} ?
Y .When the explicit supervision is available (i.e.,4Our approach can be easily extended to other structuredlearning algorithms such as Structured SVM (Taskar et al,2004; Tsochantaridis et al, 2004).
(xi,yi) ?
De), our algorithm follows the standardstructured prediction update procedure.
We find thebest scoring structure y?
in ?
and then update themodel using the difference of the feature vectors be-tween the gold output structure yi and the best scor-ing structure y?
(Line 6).When only implicit supervision is available (i.e.,(xi, zi) ?
Dm), our algorithm uses the currentmodel to conduct a guided exploration, which it-eratively finds structures that best explain the im-plicit supervision, and use the explanatory structurefor making updates.
As mentioned in Section 3,we have to explore and examine each structure inthe candidate set ?.
This is due the fact that par-tial structure cannot be used for finding the right re-sponse, as getting response E(y) requires completederivations.
In Line 9, we want to find the deriva-tions y where its solution E(y) matches the implicitsupervision zi.
More specifically,y?
= arg miny???
(E(y), zi), (1)where ?
is a loss function to estimate the dis-agreement between E(y) and zi.
In our experi-ments, we simply set ?
(E(y), zi) to be 0 if thesolution partially matches, and 1 otherwise.5 Ifmore than one derivation achieves the minimal valueof ?
(E(y), zi), we break ties by choosing thederivation with higher score wT?(xi,y).
This tie-5The mined solutions are often incomplete for some vari-ables (e.g.
solution y=6 but no value for x could be mined).We allow partial matches so that the model can learn from theincomplete implicit signals as well.300Algorithm 1 Structured Perceptron with Mixed Super-vision.
(MixedSP)Input: De, Dm, L = |De|+ |Dm|, T , K, ?
?
[0, 1)1: for t = 1 .
.
.
N do .
training epochs2: for i = 1 .
.
.
L do3: ?
?
find top-K structures {y} approxi-mately4: if yi 6= ?
then .
explicit supervision5: y??
arg maxy??wT?
(xi,y)6: w?
w + ?
(?(x,yi)?
?
(x, y?
))7: else if t ?
?N then .
implicit supervision8: y??
arg maxy??wT?
(xi,y)9: Pick y?
from ?
by Eq.
(1).
.
exploration10: w?
w + ?
(?
(x, y?)?
?
(x, y?
))11: Return the average of wbreaking strategy is important ?
in practice, severalderivations may lead to the gold numerical solution;however, only few of them are correct.
The tie-breaking strategy relies on the current model andthe structured features ?
(xi,y) to filter out incor-rect derivations during training.
Finally, the modelis updated using y?
in Line 10.Similar to curriculum learning (Bengio et al,2009), it is important to control when the algorithmstarts exploring the output space using weak super-vision.
Exploring too early may mislead the model,as the structured feature weights w may not be ableto help filter out incorrect derivations, while explor-ing too late may lead to under-utilization of the im-plicit supervision.
We use the parameter ?
to controlwhen the model starts to learn from implicit supervi-sion signals.
The parameter ?
denotes the fraction ofthe training time that the model uses purely explicitsupervision.Key Properties of Our Algorithm The idea of us-ing solutions to train algebra word problem solvershas been discussed in (Kushman et al, 2014)and (Zhou et al, 2015).
However, their implicit su-pervision signals are created from clean, fully super-vised data, and the experiments use little to no ex-plicit supervision examples.6 While their algorithmsare interesting, the experimental setting is somewhatunrealistic as the implicit signals are simulated.6Prior work (Kushman et al, 2014) has used only 5 explicitsupervision examples when training with solutions.On the other hand, the goal of our algorithm isto significantly improve a strong solver with a largequantity of unlabeled data.
Moreover, our implicitsupervision signals are noisier given that we crawledthe data automatically, and the clean labeled equa-tion systems are not available to us.
As a result, wehave made several design choices to address issuesof learning from noisy implicit supervision signalsin practice.First, the algorithm is designed to perform up-dates conservatively.
Indeed, in Line 10, the algo-rithm will not perform an update if the model couldnot find any parses matching the implicit signals inLine 9.
That is, if ?
(E(y), zi) = 1 for all y ?
?,y?
= y?
due to the tie-breaking mechanism.
Thisensures that the algorithm drives the learning usingonly those structures which lead to the correct solu-tion, avoiding undesirable effects of noise.Second, the algorithm does not use implicit su-pervision signals in the early stage of model train-ing.
Learning only on clean and explicit supervisionhelps derive a better intermediate model, which laterallows exploring the output space more efficientlyusing the implicit supervision signals.Existing semantic parsing algorithms typicallyuse either implicit or explicit supervision signals ex-clusively (Zettlemoyer and Collins, 2007; Berant etal., 2013; Artzi and Zettlemoyer, 2013).
In contrast,MixedSP makes use of both explicit and implicit su-pervised examples mixed at the training time.5 Mining Implicit Supervision SignalsIn this section, we describe the process of collect-ing SOL-2K, a data set containing question-solutionpairs of algebra word problems from a Web forum7,where students and tutors interact to solve mathproblems.A word problem posted on the forum is often ac-companied by a detailed explanation provided by tu-tors, which includes a list of the relevant equations.However, these posted equations are not suitable fordirect use as labeled data, as they are often impreciseor incomplete.
For instance, tutors often omit manysimplification steps when writing the equations.
Acommonly observed example is that (5-3)x+2ywould be directly written as 2x+2y.
Despite being7http://www.algebra.com301mathematically equivalent, learning from the latterequation is not desirable as the model may learn that5 and 3 appearing the text are irrelevant.
An ex-treme case of this is when tutors directly post the so-lution (such as x=2 and y=5), without writing anyequations.
Another observation is that tutors oftenwrite two-variable equation systems with only onevariable.
For example, instead of writing x+y=10,x-y=2, many tutors pre-compute x=10-y usingthe first equation and substitute it in the second one,which results in 10-y-y=2.
It is also possible thatthe tutor wrote the incorrect equation system, butwhile explaining the steps, made corrections to getthe right answer.
These practical issues make it dif-ficult to use the crawled equations for explicit super-vision directly.On the other hand, it is relatively easy to ob-tain question-solution pairs with simple heuristics.We use a simple strategy to generate the solutionfrom the extracted equations.
We greedily selectequations in a top-down manner, declaring suc-cess as soon as we find an equation system thatcan be solved by a mathematical engine (we usedSymPy (Sympy Development Team, 2016)).
Equa-tions that cause an exception in the solver (due toimproper extraction) are rejected.
Note that the solu-tion thus found may be incorrect (making the minedsupervision noisy), as the equation system used bythe solver may contain an incorrect equation.
To en-sure the quality of the mined supervision, we useseveral simple rules to further filter the problems.For example, we remove questions that have morethan 15 numbers.
We found that usually such ques-tions were not a single word problem, but insteadconcatenations of several problems.Note that our approach relies only on a few rulesand a mathematical engine to generate (noisy) im-plicit supervision from crawled problems, with nohuman involvement.
Once the solutions are gener-ated, we discarded the equation systems used to ob-tain them.
Using this procedure, we collected 2,039question-solution pairs.
For example, the solution tothe following mined problem was ?6?
(The correctsolutions are 6 and 12.
):Roz is twice as old as Grace.
In 5 yearsthe sum of their ages will be 28.
How oldare they now?Settings Explicit sets Implicit sets(De) (Dm)Dataset ALG-514 DRAW-1K SOL-2K# temp.
24 224 Unknown# prob.
514 1,000 2,039Vocab.
1.83k 2.2k 6.8kTable 2: The statistics of the data sets.6 ExperimentsIn this section, we demonstrate the effectiveness ofthe proposed approach and empirically verify the de-sign choices of the algorithm.
We show that our jointlearning approach leverages mined implicit super-vision effectively, improving system performancewithout using additional manual annotations (Sec-tion 6.1).
We also compare our approach to existingmethods under different supervision settings (Sec-tion 6.2).Experimental Settings Table 2 shows the statis-tics of the datasets.
The ALG-514 dataset (Kush-man et al, 2014) consists of 514 algebra word prob-lems, ranging over a variety of narrative scenarios(object counting, simple interest, etc.).
Although itis a popular benchmark for evaluating algebra wordsolvers, ALG-514 has only 24 templates.
To test thegenerality of different approaches, we thus conductexperiments on a newly released data set, DRAW-1K8 (Upadhyay and Chang, 2016), which coversmore than 200 templates and contains 1,000 alge-bra word problems.
The data is split into training,development, and test sets, with 600/200/200 exam-ples, respectively.The SOL-2K dataset contains the word problem-solution pairs we mined from online forum (see Sec-tion 5).
Unlike ALG-514 and DRAW-1K, there areno annotated equation systems in this dataset, andonly the solutions are available.
Also, no prepro-cessing or cleaning is performed, so the problemdescriptions might contain some irrelevant phrasessuch as ?please help me?.
Since all the datasets aregenerated from online forums, we carefully exam-ined and removed problems from SOL-2K that areidentical to problems in ALG-514 and DRAW-1K,to ensure fairness.
We set the number of iterations8https://aka.ms/datadraw302to 15 and the learning rate ?
to be 1.For all experiments, we report solution accuracy(whether the solution was correct).
Following Kush-man et al (2014), we ignore the ordering of answerswhen calculating the solution accuracy.
We reportthe 5-fold cross validation accuracy on ALG-514 inorder to have a fair comparison with previous work.For DRAW-1K, we report the results on the test set.In all the experiments, we only use the templates thatappear in the corresponding explicit supervision.Following (Zhou et al, 2015), we do not modelthe alignments between noun phrases and vari-ables.
We use a similar set of features introducedin (Zhou et al, 2015), except that our solver does notuse rich NLP features from dependency parsing orcoreference-resolution systems.
We follow (Kush-man et al, 2014) and set the beam-size K to 10,unless stated otherwise.6.1 Joint Learning from Mixed SupervisionSupervision Protocols We compare the followingtraining protocols:?
Explicit (D = {(xe,ye)}): the standard set-ting, where fully annotated examples are usedto train the model (we use the structured Per-ceptron algorithm as our training algorithmhere).?
Implicit (D = {(xm, zm))}): the model istrained on SOL-2K dataset only (i.e., only im-plicit supervision).
This setting is similar to theone in (Liang et al, 2013; Clarke et al, 2010).?
Pseudo (D = {(xm, Z?
?1(zm,xm))}): wherewe use Z?
?1(z,x) to denote a pseudo deriva-tion whose solutions match the mined solu-tions.
Similar to the approach in (Yih et al,2015) for question answering, here we attemptsto recover (possibly incorrect) explicit supervi-sion from the implicit supervision by findingparses whose solution matches the mined so-lution.
For each word problem, we generateda pseudo derivation Z?
?1(z,x) by finding theequation systems whose solutions that matchthe mined solutions.
We conduct a brute forcesearch to find Z?
?1(z,x) by enumerating allpossible derivations.
Note that this process canbe very slow for datasets like DRAW-1K be-cause the brute-force search needs to examinemore than 200 templates for each word prob-lem.
Ties are broken by random.?
E+P (D = {(xe,ye)}?
{(xm, Z?
?1(zm,xm))}):a baseline approach that jointly learns by com-bining the dataset generated by Pseudo with theExplicit supervision.?
MixedSP (D = {(xe,ye)}?
{(xm, zm))}): thesetting used by our proposed algorithm.
The al-gorithm trained the word problem solver usingboth explicit and implicit supervision jointly.We set the parameter ?
to 0.5 unless otherwisestated.
In other words, the first half of the train-ing iterations use only explicit supervision.Note that Explicit, E+P, and MixedSP use thesame amount of labeled equations, although E+Pand MixedSP use additional implicit supervised re-sources.Results Table 3 lists the main results.
Withimplicit supervision from mined question-solutionpairs, MixedSP outperforms Explicit by around4.5% on both datasets.
This verifies the claim thatthe joint learning approach can benefit from thenoisy implicit supervision.
Note that with the sameamount of supervision signals, E+P performs poorlyand even under-performs Explicit.
The reason is thatthe derived derivations in SOL-2K can be noisy.
In-deed, we found that about 70% of the problems inthe implicit set have more than one template thatcan produce a derivation which matches the minedsolutions.
Therefore, the pseudo derivation selectedby the system might be wrong, even if they generatethe correct answers.
As a result, E+P can committo the possibly incorrect pseudo derivations beforetraining, and suffer from error propagation.
In con-trast, MixedSP does not commit to a derivation andallows the model to choose the one best explainingthe implicit signals as training progresses.As expected, using only the implicit set Dm per-forms poorly.
The reason is that in both Implicitand Pseudo settings, the algorithm needs to selectone from many derivations that match the labeledsolutions, and use the selected derivation to updatethe model.
When there are no explicit supervision303Dataset De Dm De and DmExpl.
Pseudo Impl.
E+P MixedSPALG-514 78.4 54.1 63.7 73.3 83.0DRAW-1K 55.0 33.5 39.0 48.5 59.5Table 3: The solution accuracies of different protocols onALG-514 and DRAW-1K.signals, the model can use incorrect derivations toupdate the model.
As a result, models on bothImplicit and Pseudo settings perform significantlyworse than the Explicit baseline in both datasets,even if the size of SOL-2K is larger than the fullysupervised data.6.2 Comparisons to Previous WorkWe now compare to previous approaches for solvingalgebra word problems, both in fully supervised andweakly supervised settings.Comparisons of Overall Systems We first com-pare our systems to the systems that use the samelevel of explicit supervision (fully labeled exam-ples).
The comparison between our system and ex-isting systems are in Fig 2a and 2b.
Compared toprevious systems that were trained only on explicitsignals, our Explicit baseline is quite competitive.On ALG-514, the accuracy of our baseline systemis 78.4%, which is 1.3% lower than the best reportedaccuracy achieved by the system ZDC15 (Zhou etal., 2015).
We suspect that this is due to the richerfeature set used by ZDC15, which includes fea-tures based on POS tags, coreference and depen-dency parses, whereas our system only uses fea-tures based on POS tags.
Our system is also thebest system on DRAW-1K, and performs much betterthan the system KAZB14 (Kushman et al, 2014).Note that we could not run the system ZDC15 onDRAW-1K because it can only handle limited typesof equation systems.
Although the Explicit baselineis strong, the MixedSP algorithm is still able to im-prove the solver significantly through noisy implicitsupervision signals without using manual annotationof equation systems.Comparisons of Weakly Supervised AlgorithmsIn the above comparisons, MixedSP benefits fromthe mined implicit supervision as well as using Al-gorithm 1.
Since there are several practical limita-tions for us to run previously proposed weakly su-pervised algorithms in our settings, in the following,we perform a direct comparison between MixedSPand existing algorithms in their corresponding set-tings.
Note that the implicit supervision in weak su-pervision settings proposed in earlier work is noise-free, as it was simulated by hiding equation systemsof a manually annotated dataset.Zhou et al (2015) proposed a weak supervisionsetting where the system was provided with the setof all templates, as well as the solutions of all prob-lems during training.
Under this setting, they re-ported 72.3% accuracy on ALG-514.
Note that suchhigh accuracy can be achieved mainly because thatthe complete and correct templates were supplied.In this setting, running the MixedSP algorithm isequivalent to using the Implicit setting with cleanimplicit supervision signals.
Surprisingly, MixedSPcan obtain 74.3% accuracy, surpassing the weaklysupervised model in (Zhou et al, 2015) on ALG-514.
Compared to the results in Table 3, note thatwhen using noisy implicit signals, it cannot obtainthe same level of results, even though we had moretraining problems (2,000 mined problems instead of514 problems).
This shows that working with real,noisy weak supervision is much more challengingthan working on simulated, noise-free, weak super-vision.Kushman et al (2014) proposed another weak su-pervision setting (5EQ+ANS in the paper), in whichexplicit supervision is provided for only 5 prob-lems in the training data.
For the rest of problems,only their solutions are provided.
The 5 problemsare chosen such that their templates constitute the 5most common templates in the dataset.
This weaksupervision setting is harder than that of (Zhou etal., 2015), as the solver only has the templates for5 problems, instead of the templates for all prob-lems.
Under this setting, our MixedSP algorithmachieves 53.8%, which is better than 46.1% reportedin (Kushman et al, 2014).6.3 AnalysisIn Figure 2c, we investigate the impact of tuning ?in MixedSP on the dataset ALG-514.
Recall that?
controls the fraction of the training time thatthe model uses solely explicit supervision.
At firstglance, it may appear that we should utilize the im-304KAZB14 ZDC15 Explicit MixedSP657075808568.779.7 78.483.0Cross-ValidationAccuracy(a)KAZB14 Explicit MixedSP35404550556037.555.059.5TestAccuracy(b)0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.87678808284AccuracyMixedSP with different ?
Explicit(c)Figure 2: (a) Comparisons between our system to state-of-the-art systems on ALG-514.
ZDC15 is the system pro-posed in (Zhou et al, 2015), and KAZB14 is the system proposed in (Kushman et al, 2014).
(b) Comparisonsbetween our system and other systems on DRAW-1K.
Note that we are not able to run ZDC15 on DRAW-1K becauseit cannot handle some equation systems in the dataset.
(c) Analysis of the impact of ?
in MixedSP.plicit supervision throughout training (set ?
= 0).But setting ?
to 0 hurts overall performance, sug-gesting in this setting that the algorithm uses a weakmodel to guide the exploration for using implicitsupervision.
On the other hand, by delaying ex-ploration (?
> 0.5) for too long, the model couldnot fully utilize the implicit supervision.
We ob-serve similar trend on DRAW-1K as well.
We found?
= 0.5 works well across the experiments.We also analyze the impact of the parameter K,which controls the size of the candidate set ?
inMixedSP.
Specifically, for DRAW-1K, when settingK to 5 and 10, the accuracy of MixedSP is at 59.5%.On setting K to 15, the accuracy of MixedSP im-proves to 61%.
We suspect that enlarging K in-creases the chance to have good structures in thecandidate set that can match the correct responses.7 ConclusionIn this paper, we propose an algorithmic approachfor training a word problem solver based on bothexplicit and implicit supervision signals.
By extract-ing the question answer pairs from a Web-forum,we show that the algebra word problem solver canbe improved significantly using our proposed tech-nique, surpassing the current state-of-the-art.Recent advances in deep learning techniquesdemonstrate that the error rate of machine learningmodels can decrease dramatically when large quan-tities of labeled data are presented (Krizhevsky etal., 2012).
However, labeling natural language datahas been shown to be expensive, and it has becomeone of the major bottleneck for advancing naturallanguage understanding techniques (Clarke et al,2010).
We hope the proposed approach can shedlight on how to leverage data on the web, and even-tually improves other semantic parsing tasks suchas knowledge base question answering and mappingnatural instructions to actions.ReferencesYoav Artzi and Luke Zettlemoyer.
2013.
Weakly su-pervised learning of semantic parsers for mapping in-structions to actions.
In Proc.
of TACL.Yoshua Bengio, Je?ro?me Louradour, Ronan Collobert, andJason Weston.
2009.
Curriculum learning.
In Proc.
ofICML.Jonathan Berant, Andrew Chou, Roy Frostig, and PercyLiang.
2013.
Semantic parsing on Freebase fromquestion-answer pairs.
In Proc.
of EMNLP.Daniel G. Bobrow.
1964.
A question-answering systemfor high school algebra word problems.
In Proceed-ings of the October 27-29, 1964, Fall Joint ComputerConference, Part I.K.-W. Chang, R. Samdani, and D. Roth.
2013.
A con-strained latent variable model for coreference resolu-tion.
In Proc.
of EMNLP.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and maxent discriminative rerank-ing.
In Proc.
of ACL.Peter Clark and Oren Etzioni.
2016.
My computer is anhonor student-but how intelligent is it?
Standardizedtests as a measure of AI.
AI Magazine., 37(1).J.
Clarke, D. Goldwasser, M. Chang, and D. Roth.
2010.Driving semantic parsing from the world?s response.In Proc.
of CoNLL.305M.
Collins.
2000.
Discriminative reranking for naturallanguage parsing.
In Proc.
of ICML.M.
Collins.
2002.
Discriminative training methods forhidden Markov models: Theory and experiments withperceptron algorithms.
In Proc.
of EMNLP.R.
Ge and R. Mooney.
2006.
Discriminative rerankingfor semantic parsing.
In Proc.
of ACL.Javad Mohammad Hosseini, Hannaneh Hajishirzi, OrenEtzioni, and Nate Kushman.
2014.
Learning to solvearithmetic word problems with verb categorization.
InProc.
of EMNLP.Danqing Huang, Shuming Shi, Chin-Yew Lin, Jian Yin,and Wei-Ying Ma.
2016.
How well do computerssolve math word problems?
Large-scale dataset con-struction and evaluation.
In Proc.
of ACL.Rik Koncel-Kedziorski, Hannaneh Hajishirzi, AshishSabharwal, Oren Etzioni, and Siena Dumas Ang.2015.
Parsing algebraic word problems into equations.Proc.
of TACL.Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.2012.
Imagenet classification with deep convolutionalneural networks.
In Proc.
of NIPS.Nate Kushman, Yoav Artzi, Luke Zettlemoyer, andRegina Barzilay.
2014.
Learning to automaticallysolve algebra word problems.
In Proc.
of ACL.Percy Liang, Michael I Jordan, and Dan Klein.
2013.Learning dependency-based compositional semantics.Computational Linguistics.Christopher D. Manning, Mihai Surdeanu, John Bauer,Jenny Finkel, Steven J. Bethard, and David McClosky.2014.
The Stanford CoreNLP natural language pro-cessing toolkit.
In Proc.
of ACL.Anirban Mukherjee and Utpal Garain.
2008.
A re-view of methods for automatic understanding of nat-ural language mathematical problems.
Artif.
Intell.Rev., 29(2):93?122.Allen Newell, John C Shaw, and Herbert A Simon.
1959.Report on a general problem-solving program.
In IFIPCongress, pages 256?264.Subhro Roy and Dan Roth.
2015.
Solving general arith-metic word problems.
In Proc.
of EMNLP.Shuming Shi, Yuehui Wang, Chin-Yew Lin, XiaojiangLiu, and Yong Rui.
2015.
Automatically solving num-ber word problems by semantic parsing and reasoning.In Proc.
of EMNLP.J.
Steinhardt and P. Liang.
2015.
Learning with relaxedsupervision.
In Proc.
of NIPS.Sympy Development Team, 2016.
SymPy: Python li-brary for symbolic mathematics.B.
Taskar, C. Guestrin, and D. Koller.
2004.
Max-marginmarkov networks.
In Proc.
of NIPS.I.
Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun.2004.
Support vector machine learning for interdepen-dent and structured output spaces.
In Proc.
of ICML.Shyam Upadhyay and Ming-Wei Chang.
2016.Annotating derivations: A new evaluation strat-egy and dataset for algebra word problems.
Inhttps://aka.ms/derivationpaper.Wen-tau Yih, Ming-Wei Chang, Xiaodong He, and Jian-feng Gao.
2015.
Semantic parsing via staged querygraph generation: Question answering with knowl-edge base.
In Proc.
of ACL.C.
Yu and T. Joachims.
2009.
Learning structural SVMswith latent variables.
In Proc.
of ICML.J.
M. Zelle and R. J. Mooney.
1996.
Learning to parsedatabase queries using inductive logic proramming.
InProc.
of AAAI.Luke Zettlemoyer and Michael Collins.
2007.
Onlinelearning of relaxed CCG grammars for parsing to log-ical form.
In EMNLP-CoNLL.Lipu Zhou, Shuaixiang Dai, and Liwei Chen.
2015.Learn to solve algebra word problems using quadraticprogramming.
In Proc.
of EMNLP.306
