Proceedings of the Seventeenth Conference on Computational Natural Language Learning, pages 38?46,Sofia, Bulgaria, August 8-9 2013. c?2013 Association for Computational LinguisticsGraph-Based Posterior Regularizationfor Semi-Supervised Structured PredictionLuheng He Jennifer GillenwaterComputer and Information ScienceUniversity of Pennsylvania{luhe,jengi}@cis.upenn.eduBen TaskarComputer Science and EngineeringUniversity of Washingtontaskar@cs.washington.eduAbstractWe present a flexible formulation of semi-supervised learning for structured mod-els, which seamlessly incorporates graph-based and more general supervision by ex-tending the posterior regularization (PR)framework.
Our extension allows for anyregularizer that is a convex, differentiablefunction of the appropriate marginals.
Weshow that surprisingly, non-linearity ofsuch regularization does not increase thecomplexity of learning, provided we usemultiplicative updates of the structured ex-ponentiated gradient algorithm.
We il-lustrate the extended framework by learn-ing conditional random fields (CRFs) withquadratic penalties arising from a graphLaplacian.
On sequential prediction tasksof handwriting recognition and part-of-speech (POS) tagging, our method makessignificant gains over strong baselines.1 IntroductionRecent success of graph-based semi-supervisedlearning builds on access to plentiful unsuperviseddata and accurate similarity measures betweendata examples (Zhu et al 2003; Joachims, 2003;Belkin et al 2005; Zhu and Lafferty, 2005; Al-tun et al 2005; Zhu, 2005; Chapelle et al 2006;Subramanya and Bilmes, 2009; Subramanya etal., 2010; Das and Petrov, 2011).
Many ap-proaches, such as Joachims (2003) and Subra-manya and Bilmes (2009) use graph-based learn-ing in the transductive setting, where unlabeled ex-amples are classified without learning a parametricpredictive model.
While predicted labels can thenbe leveraged to learn such a model (e.g.
a CRF),this pipelined approach misses out on the benefitsof modeling sequential correlations during graphpropagation.
In this work we seek to better inte-grate graph propagation with estimation of a struc-tured, parametric predictive model.To do so, we build on the posterior regulariza-tion (PR) framework of Ganchev et al(2010).
PRis a principled means of providing weak super-vision during structured model estimation.
Moreconcretely, PR introduces a penalty whenever themodel?s posteriors over latent variables contra-dict the specified weak supervision.
Ganchevet al(2010) show how to efficiently optimize alikelihood-plus-posterior-penalty type objective inthe case where the penalty is linear in the model?smarginals.
Yet, there are many forms of supervi-sion that cannot be expressed as a linear functionof marginals.
For example, graph Laplacian regu-larization.
In this work, we extend PR to allow forpenalties expressed as any convex, differentiablefunction of the marginals and derive an efficientoptimization method for such penalties.In our experiments, we explore graph Lapla-cian posterior regularizers for two applications:handwriting recognition and POS tagging.
Themethods of Altun et al(2005), Subramanya et al(2010), and Das and Petrov (2011) are the mostclosely related to this work.
Altun et al(2005)describes coupling a graph regularizer with a max-margin objective for pitch accent prediction andhandwriting recognition tasks.
Their method suf-fers from scalability issues though; it relies on op-timization in the dual, which requires inversion ofa matrix whose dimension grows with graph size.The more recent work of Subramanya et al(2010) tackles the POS tagging task and pro-vides a more scalable method.
Their methodis a multi-step procedure that iterates two mainsteps, graph propagation and likelihood optimiza-tion, until convergence.
Actually computing theoptimum for the graph propagation step would re-quire a matrix inversion similar to that used by Al-tun et al(2005), but they skirt this issue by usingan heuristic update rule.
Unfortunately though, no38guarantees for the quality of this update are es-tablished.
Das and Petrov (2011) proceed verysimilarly, adapting the iterative procedure to in-clude supervision from bi-text data, but applyingthe same heuristic update rule.The work we present here similarly avoids thecomplexity of a large matrix inversion and iter-ates steps related to graph propagation and likeli-hood optimization.
But in contrast to Subramanyaet al(2010) and Das and Petrov (2011) it comeswith guarantees for the optimality of each step andconvergence of the overall procedure.
Further, ourapproach is based on optimizing a joint objective,which affords easier analysis and extensions us-ing other constraints or optimization methods.
Thekey enabling insight is a surprising factorization ofthe non-linear regularizer, which can be exploitedusing multiplicative updates.2 Posterior regularizationWe focus on the semi-supervised setting, showinghow to extend the discriminative, penalty-basedversion of PR for a linear chain CRF.
Our resultsapply more generally though to the unsupervisedsetting, the constraint-based versions of PR, andother graphical models.In the standard semi-supervised setting we aregiven n data instances, {x1, .
.
.
,xn}, and labels{y1, .
.
.
,yl} for the first l  n instances.
Forsimplicity of notation, we?ll assume each xi hasT components.
Modeling this data with a linearchain CRF, the standard conditional log-likelihoodobjective with a Gaussian prior (variance?
?2) is:L(?)
=l?i=1log p?
(yi | xi)?||?||222?2 .
(1)Note that this discriminative objective does not at-tempt to leverage the unlabeled data.
Since p?
de-composes according to the independence assump-tions of a linear chain CRF, it can be expressed as:p?
(y | x) =exp[?Tt=1 ?>f(yt, yt?1,x)]Zp(x)(2)where the Zp(x) is a normalizer:Zp(x) =?y?exp[ T?t=1?>f(y?t, y?t?1,x)](3)and the f are arbitrary feature functions.
We as-sume f(y1, y0,x) receives a special ?start?
markerfor y0.
In what follows, we refer to functionsover the (yt, yt?1,x) as local factors, or p-factors;p?
(y | x) decomposes as a product of p-factors.Given this decomposition, L and its gradientwith respect to ?
can be efficiently computed usingthe forward-backward algorithm for linear chains.This amounts to computing posterior marginalsfor each p-factor (yt, yt?1,x).
Following the gra-dient suffices to find the global optimum of L,since likelihood is concave, and the Gaussian priormakes it strictly concave.Penalty-based posterior regularization (PR)modifies the likelihood objective by adding a?penalty?
term expressing prior knowledge aboutthe posteriors (Ganchev et al 2010).
To allow formore efficient optimization, penalty terms are im-posed on an auxiliary joint distribution q over thelabels instead of directly on p?.
Agreement be-tween q and p?
is encouraged by a KL term:KL(q ?
p?)
=n?i=1KL(q(Y | xi) ?
p?
(Y | xi))where Y is a random variable that can take on anypossible labeling y, and q(Y |xi) is a an arbitrarydistribution over Y for each i1.
The penalty termitself is restricted to be an essentially linear func-tion of the p-factor marginals of q(Y | xi).
Tocompactly express this, we first define some no-tation.
Let mi denote the p-factor marginals ofq(Y | xi).
For first-order linear chain models,if K is the total number of labels a y variablecan take on, then mi contains the marginals fort ?
{1, .
.
.
, T} and all K2 possible (yt, yt?1) la-bel pairs.
That is, mi is a length O(TK2) vectorwith entries:mit,k,j =?y1(yt = k, yt?1 = j)q(y | xi) .
(4)Stacking all these mi, we let m represent theO(nTK2) vector [m1, .
.
.
,mn].
We further de-fine a matrix A of constraint features.
The productAm is then the expectation of these features underq.
Finally we have, with a vector b of limits, thefollowing expression for the penalty term:hlin(m) = ||max (Am?
b,0)||?
(5)where ||?||?
denotes an arbitrary norm.
This ex-pression will be non-zero if the expected value of1We use a notation that is slightly different than, butequivalent to, that of prior work, in order to facilitate our ex-tensions later.39Am is larger than the limit b.
The full posteriorregularizer is then:R(?, q) = KL(q ?
p?)
+ ?hlin(m) , (6)where ?
is a hyperparameter that controls thestrength of the second term.Running example: Consider the task of part-of-speech (POS) tagging, where the y are tagsand the x are words.
To encourage every sen-tence to contain at least one verb, we can pe-nalize if the expected number of verbs underthe q distribution is less than 1.
Specifically,if ?verb?
is represented by tag number v, forsentence i we penalize unless:1 ?T?t=1K?yt?1=1mit,v,yt?1 .
(7)In the notation of Equation (5), these penal-ties correspond to: an n-row A matrix, whererow i has?1?s to select exactly the portion ofm from Equation (7), and a limit b = ?1.We briefly note here that generalized expec-tation (Mann and McCallum, 2007; Mann andMcCallum, 2008) can be used to impose similarpenalties, but without the auxiliary q distribution.Unfortunately though, this means the expectationof the A features is with respect to p?, so comput-ing the gradient requires the covariance betweenthe constraint features in A and the model featuresf , under ?.
For a linear chain CRF, this means therun time of forward-backward is squared, althoughsome optimizations are possible.
PR?s use of theauxiliary q allows us to optimize more efficientlyby splitting the problem into easier blocks.The new objective that combines likelihoodwith the PR penalty is: J (?, q) = L(?)
?R(?, q).
While optimizing L(?)
is easy, findingmax?,q J (?, q) is NP-hard even for the simplestmodels.
To optimize J , Ganchev et al(2010)employ an expectation maximization (EM) basedmethod.
At iteration t + 1, the algorithm updatesq and ?
as follows:E : qt+1 = argminqR(?t, q) (8)M : ?t+1 = argmax?L(?)
+ (9)?n?i=l+1?yqt+1(y | xi) log p?
(y | xi)where ?
here is a hyperparameter that trades offbetween the labeled and unlabeled data.
Thoughnot stated above, note that in the E-step minimiza-tion over q(Y | xi) is constrained to the probabil-ity simplex.
Ganchev et al(2010) show that thisE-step can be efficiently implemented, via pro-jected gradient descent on the dual.
The M-stepis similar to optimizing the original L, but with acontribution from the unlabeled data that furtherencourages q and p?
to agree.
Thus, the M-stepcan be implemented via the same gradient ascentmethods as used for L. As with standard EM,this method monotonically increases J and thusis guaranteed to converge to a local optimum.In this work, we contemplate what other typesof posterior penalty terms besides hlin(m) arepossible.
In the subsequent section, we show thatit is possible to extend the class of efficiently-optimizable PR penalties to encompass all convex,differentiable functions of the marginals.3 Non-linear PRLet h(m) denote an arbitrary convex, differen-tiable function of the marginals of q. ReplacingR?s penalty term with h, we have:R?
(?, q) = KL(q ?
p?)
+ ?h(m) (10)Let J?
represent the full objective with R?.
Weshow that J?
can be efficiently optimized.Running example: Returning to our POStagging example, let?s consider one type ofnon-linear convex penalty that might be use-ful.
Suppose our corpus has N uniquetrigrams, and we construct a graph G =(V,E,W ) where each vertex in V is a trigramand each edge (a, b) ?
E has a weight wabthat indicates the similarity of trigrams a andb.
To use the information from this graph toinform our CRF, we can use the graph Lapla-cian: L = D?W , where D is a diagonal de-gree matrix with daa =?Nj=1waj .
The formof L is such that for every vector v ?
RN :v>Lv = 12N?a=1N?b=1wab(va ?
vb)2 .
(11)The larger the disparity in v values of similarvertices, the larger the value of v>Lv.
Thematrix L is positive semi-definite, so v>Lv is40convex in v. If each entry va is a linear func-tion of the vector of marginals m describedabove, then v(m)>Lv(m) is convex in m.Thus, for any linear v(m), we can use thisLaplacian expression as a PR penalty.For example, we can define v(m) such thath(m) applies a penalty if trigrams that aresimilar according to the graph have differentexpected taggings under the CRF model.
Tostate this more formally, let?s define a map-pingB : ({1, .
.
.
, n}, {1, .
.
.
, T}) 7?
V fromwords in the corpus to vertices in the graph:B(i, t) = a implies word xit maps to vertex a.Then, for a given tag k, we have the followingformula for the value of vertex a:va,k = m?a,k =n?i=1T?t=1B(i,t)=aK?yt?1=1mit,k,yt?1?ni=1?Tt=1 1(B(i, t) = a)There are several issues to overcome in showingthat EM with these more general h(m) can stillbe run efficiently and will still reach a local opti-mum.
First, we have to show that the optimal qfor the E-step minimization can still be compactlyrepresentable as a product of p-factors.3.1 DecompositionTheorem 1.
If h(m) is a convex, differen-tiable function of q?s p-factor marginals, q?
=argminq R?
(?, q) decomposes as a product of p-factors.Proof.
Consider the E-step gradient of R?
(?, q)with respect to q.
Using the shorthand qiy forq(y | xi), the gradient is:?R?
?qiy= log qiy + 1?
log p?
(y | xi) + (12)?
?h(m)?m>?m?qiy.Here, ?m?qiy is just a 0-1 vector indicating which ofthe marginals from m apply to qiy.
For example,for yt = k and yt?1 = j, the marginal mit,k,j isrelevant.
We can more simply write:?h(m)?m>?m?qiy=T?t=1?h(m)?mit,yt,yt?1.
(13)Setting the gradient equal to zero and solving forqiy, we see that it must take the following form:qiy =p?
(y | xi) exp[??T?t=1?h(m)?mit,yt,yt?1]Zq(xi).
(14)From this expression, it is clear that qiy is propor-tional to a product of p-factors.Running example: Recall the graph Lapla-cian penalty, discussed above for a particulartag k. Summing over all tags, the penalty is:h(m) = 12K?k=1N?a=1N?b=1wab(m?a,k ?
m?b,k)2 .The derivative ?h(m)?mit,yt,yt?1 is then:2K?k=1N?a=1wa,B(i,t)(m?B(i,t),k ?
m?a,k) .
(15)In words: for a given k, this gradient is pos-itive if node B(i, t) has larger probability oftaking tag k than its close neighbors.
Movingin the direction opposite the gradient encour-ages similar taggings for similar trigrams.Theorem 1 confirms that the optimal q will de-compose as desired, but does not address whetherwe can efficiently find this q.
Previous PR workoptimized the E-step in the dual.
But while thedual is easy to compute in closed form for normsor linear functions, for arbitrary convex functionsthe dual is often non-trivial.Running example: For the case of agraph Laplacian regularizer, in the primal thepenalty takes the form of a quadratic pro-gram: v>Lv.
Unfortunately, the dual of aquadratic program contains a matrix inverse,L?1 (van de Panne and Whinston, 1964).Taking a matrix inverse is expensive, whichmakes optimization in the dual unattractive.Since moving to the dual would be inefficient,optimizing R?
will require some form of gradientdescent on the qiy.
However, the standard gradientdescent update:qiy ?
qiy ?
??R?
?qiy(16)41where ?
is the step size, does not result in a fea-sible optimization scheme, for several reasons.First, it is possible for the updated q to be outsidethe probability simplex.
To be sure it remains inthe simplex would require a projection step on thefull, exponential-size set of all qiy, for each exam-ple xi.
Second, the updated q may not be propor-tional to a product of p-factors.
To be concrete,suppose the starting point is qiy = p?
(y | xi),which does decompose as a product of p-factors.Then after the first gradient update, we have:qiy = p?
(y | xi)?
?
(1 + ?T?t=1?h(m)?mit,yt,yt?1).Unfortunately, while p?
(y | xi) decomposes as aproduct of p-factors, the other term decomposesas a sum.
Naturally, as we discuss in the followingsection, multiplicative updates are more suitable.3.2 Exponentiated GradientThe exponentiated gradient descent (EGD) algo-rithm was proposed by Kivinen and Warmuth(1995), who illustrate its application to linear pre-diction.
More recently, Collins et al(2005) andCollins et al(2008) extended EGD to exploit fac-torization in structured models.
The most impor-tant aspect of EGD for us is that a variable?s up-date formula takes a multiplicative rather than anadditive form.
Specifically, the update for qiy is:qiy ?
qiy exp[??
?R??qiy].
(17)Lemma 2.
EGD update Equation (17) preservesdecomposition of q into p-factors.Proof.
Applying the multiplicative EGD updateformula to qiy, we see that its new value equals thefollowing product:(qiy)1??p?
(y | xi)?
exp[??
?T?t=1?h(m)?mit,yt,yt?1],up to a normalization constant.
Since qiy andp?
(y | xi) both decompose as a product of p-factors and since the update term is another prod-uct of p-factors, the updated expression is itself aproduct of p-factors (up to normalization).Note that normalization is not an issue withthe EGD updates.
Since q retains its decompo-sition, the normalization can be efficiently com-puted using forward-backward.
Thus, Lemma 2moves us much closer to the goal of running EMefficiently, though there remain several stumblingblocks.
First and foremost, we cannot afford to ac-tually apply EGD to each qiy, as there are an expo-nential number of them.
Thankfully, we can showthese EGD updates are equivalent to following thegradient on a much smaller set of values.
In par-ticular, letting F represent the dimension of m,which for example is O(nTK2) for linear chains,we have the following result.Lemma 3.
Given the gradient vector ?h(m)?m , onestep of EGD on R?
(?, q) can be completed in timeO(F ), where F is the dimension ofm.Proof.
First, we re-express qiy in log-linear form.Applying Lemma 2, we know that qiy is propor-tional to a product of p-factors This means thatthere must exist some factors r such that qiy canbe written:qiy =1Zq(xi)exp[ T?t=1ri,t(yt, yt?1)].
(18)Re-expressing ?R?
?qiy given these r, we have:?R?
?qiy= C +T?t=1[ri,t(yt, yt?1)?
(19)?>f(yt, yt?1,xi) + ?
?h(m)?mit,yt,yt?1],whereC = 1?logZq(xi)+logZp(xi) is constantwith respect to y.
This means that we can justupdate the individual r factors as follows:ri,t(yt, yt?1)?
(1?
?
)ri,t(yt, yt?1) +?
?>f(yt, yt?1,xi)?
???h(m)?mit,yt,yt?1.
(20)Note that if we start from qiy = p?
(y | xi), thenthe initial ri,t(yt, yt?1) are just ?>f(yt, yt?1,xi).To conclude, since the number of r functions isequal to the dimension ofm, the overall update islinear in the number of marginals.At this point, just one small issue remains: howexpensive is computing ?h(m)?m ?
Work analyzingthe reverse mode of automatic differentiation in-dicates that if computing a function h requires coperations, then computing its gradient vector re-quires no more than O(c) operations (Griewank,1988).
Thus, as long as our penalty function is42itself efficiently computable, the gradient vectorwill be too.
We conclude by observing that ourefficient algorithm converges to a local optimum.Theorem 4.
The above EGD-based EM algorithmfor optimizing J?
(?, q) converges to a local opti-mum of this objective.Proof.
The M-step remains unchanged from stan-dard PR EM, and as such is strictly convex in?.
The E-step is strictly convex in q, since KL-divergence is strictly convex and h(m) is convex.Applying EGD, we know that we can efficientlyfind the E-step optimum.
Therefore, the EGD-based EM algorithm efficiently implements coor-dinate ascent on J?
(?, q), with each step monoton-ically increasing J?
:J?
(?t, qt) ?
J?
(?t, qt+1) ?
J?
(?t+1, qt+1) .Hence, we have shown that it is possible toefficiently use an arbitrary convex, differentiablefunction of the marginals, h(m), as a PR penaltyfunction.
In the following section, we apply onesuch function ?
the graph Laplacian quadraticfrom the running example ?
to several tasks.4 ExperimentsWe evaluate the effect of a graph Laplacian PRpenalty on two different sequence prediction tasks:part-of-speech (POS) tagging and handwritingrecognition.
Our experiments are conducted in asemi-supervised setting, where only a small num-ber, l, of labeled sequences are available duringtraining.
Both the l labeled sequences and the re-mainder of the dataset (instances l + 1 through n)are used to construct a graph Laplacian2.
We traina second-order CRF using the methods describedin Section 3 and report results for a test set con-sisting of instances l + 1 through n.4.1 Graph constructionFor each task we define a symmetric similarityfunction on the task?s vertices V , sim : V ?
V 7?R, and build the graph based on its values.
Specif-ically, denoting the k nearest neighbors (NN) ofnode u by Nk(u), we use the following mutual k-NN criterion to decide which edges to include:(u, v) ?
E ??
u ?
Nk(v) ?
v ?
Nk(u) .2While these particular experiments are transductive, ourmethod can easily be applied inductively as well.Entries in the final edge weight matrix are: wuv =1[(u, v) ?
E]sim(u, v).4.2 Part-of-speech taggingWe experiment on ten languages.
Our English(EN) data is from the Penn Treebank (Marcus etal., 1993), Italian (IT) and Greek (EL) are fromCoNLL-2007 (Nivre et al 2007), and the remain-ing languages in Figure 1 (a): German (DE), Span-ish (ES), Portuguese (PT), Danish (DA), Slovene(SL), Swedish (SV), and Dutch (NL) are fromCoNLL-X (Buchholz and Marsi, 2006).
We usea universal tag set (Das et al 2012) throughout.For each language, we first construct a mu-tual 60-NN graph3 on trigram types, excludingtrigrams whose center word is punctuation.
Oursmallest graph (Slovene) contains 25,198 nodeswhile the largest (English) has 611,730.For the similarity function sim(u, v), we followthe method used in (Subramanya et al 2010) and(Das and Petrov, 2011), but with a somewhat mod-ified feature set.
For instance, while (Subramanyaet al 2010) uses suffixes of the trigram?s centerword, we find this type of feature is too easy forunrelated trigrams to match, leading to a noisygraph.
Let a trigram and its left/right context bedenoted by the 5-gram (w0, w1, w2, w3, w4).
Thenthe features we use to build the graph are:?
Trigram features: w12, w13, w23, w2,suffix(w3)w2, suffix(w1)w2?
Context features: w0134, w012, w023, w024,w124, w234, w01, w02, w24, w34where suffix indicates common suffixes collectedfrom Wiktionary data.
For a given feature f andtrigram type t, the value of the feature is deter-mined by pointwise mutual information (PMI):log #(f?t)#(f)#(t) .
Then, for each pair of trigram types,sim(u, v) is given by the cosine similarity of thetrigrams?
feature vectors.For the second-order CRF, we use a fairly stan-dard set of features:?
Emission features: 1(yt = k ?
f(xt?
)),where k can be any POS tag and t?
?
{t, t ?1, t + 1}.
The f(xt?)
takes the form of afunction from the following set: one indica-tor for each word, lowercased word, and suf-3In preliminary experiments we tested graphs with 20, 40,60, 80, and 100 NNs and found that beyond 60 NNs addi-tional performance gains are small.43fix, and also is-capitalized, is-punctuation, is-digit, contains-hyphen, and contains-period.?
Transition features: For any POS tagsk1, k2, k3, we have a feature 1(yt =k1, yt?1 = k2, yt+1 = k3) and its backoffs(indicators for one or two matching tags).4.3 Handwriting recognitionThe handwriting dataset we use was collected byKassel (1995) and filtered to 6,877 words (Taskaret al 2003).
For each word, the first letter is re-moved so that every remaining letter is one of theEnglish language?s 26 lowercase letters.Again, we first build a mutual NN graph.
In thiscase, we use 20-NN, since our graph has fewernodes and a larger set of possible node identi-ties (26 letters instead of 12 tags).
Each nodein this graph is one letter from the dataset, for atotal of 52,152 nodes.
As a first step, we com-pute cosine similarity on the pixels of each pair ofnodes, and then consider only pairs with a similar-ity greater than 0.3.
Next, we apply the Fast EarthMover?s distance E?MD(u, v) (Pele and Werman,2009) with default parameters to compute the dis-similarity of each pair of images.
We convert theseinto similarities via:s(u, v) = exp{?E?MD(u, v)?2EMD}(21)where we set the variance ?EMD = 10.
The fi-nal similarity function sim(u, v) is the weightedcombination of the similarity of the nodes (u, v)and their left neighbors (ul, vl) and right neigh-bors (ur, vr) from their respective words:sim(u, v) = ?s(u, v)+(1??
)(s(ul, vl)+s(ur, vr))where we fix ?
= 0.8.For the second-order CRF, the transition fea-tures are same as for POS tagging, but with tags re-placed by the English alphabet.
The emission fea-tures take a similar form, but with different mean-ings for the f(xt?)
indicator functions.
Specifi-cally, there is one indicator for each pixel loca-tion, with value 1 if the pixel is turned on.
Asthere are many more emission than transition fea-tures, we count the number of fired emission andtransition features, say fe and ft, then discount allemission features, multiplying them by ftfe to bal-ance the amount of supervision.4.4 BaselinesWe compare our posterior regularization (PR) re-sults with three baselines.
We also include resultsfor the first EM iteration of our PR method (PR1),to show there is still significant optimization oc-curring after the first iteration.The first baseline is graph propagation (GP).Specifically, we start from uniform posteriors forall the unlabeled nodes in the graph, then for eachtag/letter k and each node v we apply the gradientupdate:qk,v ?
qk,v ?
?
?u?Nk(v)wkuv(qk,v ?
qk,u) (22)until convergence.
We then select the tag/letterwith the largest probability as the prediction fora node.
If multiple tokens are mapped to a node,then all receive the same prediction.The second baseline incorporates both graphpropagation and sequence information.
As a firststep, we run the GP baseline, then use the decod-ing as additional labeled data to train a second-order CRF (see GP?CRF results).
The third base-line is simply a second-order CRF, trained on the llabeled examples.4.5 Training detailsFor optimizing the CRF, we use L-BFGS (Bert-sekas, 2004) and a Gaussian prior with ?
= 100(chosen by cross-validation on the labeled train-ing examples).
The final predictions are obtainedvia posterior decoding.
For PR, we run EM forat most 20 iterations, which is enough for con-vergence of the combined objective J?
(?, q).
Wecross-validate the constraint strength parameter ?over the following values: {0.1, 0.5, 1.0, 2.0}, ul-timately selecting ?
= 1 for the POS tagging taskand ?
= 0.1 for the handwriting recognition task.4.6 Results and analysisPOS tagging.
For each language, we randomlysample 1000 labeled examples and split them into10 non-overlapping training sets of size l = 100.Figure 1 (a) shows the average error and its stan-dard deviation for these training sets.
If for eachlanguage we take the difference between the aver-age error of PR and that of the best of the threebaselines, the min, average, and max improve-ments are: 2.69%, 4.06%, and 5.35%.
Whenanalyzing the results, we observed that one re-gion where PR makes substantial gains over the44EN DE ES PT DA SL SV EL IT NL Avg0510152025LanguagePOS TaggingErrorGP GP?
CRF CRF PR1 PR(a)0 100 200 300 400 50005101520# of Labeled ExamplesPortuguese Tagging ErrorGP GP?
CRF CRF PR1 PR(b)Figure 1: (a): POS results for 10 languages.
Each bar in each group corresponds to the average POStagging error of one method; the left-to-right order of the methods is the same as in the legend.
Whiskersindicate standard deviations.
The final set of bars is an average across all languages.
See supplement fora table with the exact numbers.
(b): POS results on one language for a range of l.CRF baseline is on unseen words (words that donot occur in the set of l labeled examples).
Ifwe measure performance only on such words, thegain of PR over CRF is 6.7%.
We also test withl = {50, 100, 150, 200, 300, 400, 500} on one lan-guage to illustrate how PR performs with differentamounts of supervision.
Figure 1 (b) shows thateven when l = 500 our PR method is still able toprovide improvement over the best baseline.Handwriting recognition.
For this task, theoverall dataset contains 55 distinct word types.Thus, we set l = 110 and sample 10 trainingsets such that each contains 2 examples of eachof word.
Note that due to the well-balanced train-ing sets, baselines are fairly high here comparedto other similar work with this dataset.
Table 1shows there is an average improvement of 4.93%over the best of the three baselines.GP GP?CRF CRF PR1 PRMean 17.57 15.07 9.82 6.03 4.89StdDev 0.30 0.35 0.48 0.20 0.42Table 1: Handwriting recognition errors.Even in a simpler setting closer to that of POStagging, where we just draw l = 100 samples ran-domly, there are many cases where PR beats thebaselines.
Figure 2 shows predictions from sucha setting and provides general intuition as to whyPR does well on handwriting recognition.
For theword ?Wobble?
(with the first letter removed), theCRF predicts ?obble?
as ?ovely?, because of it re-lies heavily on sequential information; in our smalltraining set, bigrams ?ov?
(2 times) and ?ly?
(12times) are more frequent than ?ob?
(1 time) and?le?
(7 times).
GP correctly predicts these lettersbecause the graph connects them to good neigh-bors.
However, GP mislabels ?l?
as ?i?, since mostof this letter?s neighbors are i?s.
The coupling ofGP and CRF via PR links the neighbor informa-tion with bigram information ?
?bl?
(5 times) ismore frequent than ?bi?
in the training set ?
toyield the correct labeling.l    t    l    l    li    i    i    l    il    l    l    l    lCRF   b    b    b    b    mGP    b    b    b    b    bPR    b    b    b    b    bCRF  o  v  e  l  yGP   o  b  b  i  ePR   o  b  b  l  eFigure 2: Predictions on the word ?Wobble?
andthe 5-NNs of its first ?b?
and ?l?.5 ConclusionWe have presented an efficient extension of theposterior regularization (PR) framework to a moregeneral class of penalty functions.
Encouragingresults using a graph Laplacian penalty suggestpotential applications to a much larger class ofweakly supervised problems.AcknowledgementsJ.
Gillenwater was supported by a National Sci-ence Foundation Graduate Research Fellowship.L.
He and B. Taskar were partially supported byONR Young Investigator Award N000141010746.45References[Altun et al005] Y. Altun, D. McAllester, andM.
Belkin.
2005.
Maximum Margin Semi-Supervised Learning for Structured Variables.
InProc.
NIPS.
[Belkin et al005] M. Belkin, P. Niyogi, and V. Sind-hwani.
2005.
On Manifold Regularization.
In Proc.AISTATS.
[Bertsekas2004] D. Bertsekas.
2004.
Nonlinear Pro-gramming.
[Buchholz and Marsi2006] S. Buchholz and E. Marsi.2006.
CoNLL-X Shared Task on Multilingual De-pendency Parsing.
In Proc.
CoNLL.
[Chapelle et al006] O. Chapelle, B. Scho?lkopf, andA.
Zien, editors.
2006.
Semi-Supervised Learning.
[Collins et al005] M. Collins, P. Bartlett,D.
McAllester, and B. Taskar.
2005.
Expo-nentiated Gradient Algorithms for Large-MarginStructured Classification.
In Proc.
NIPS.
[Collins et al008] M. Collins, A. Globerson, T. Koo,and X. Carreras.
2008.
Exponentiated Gradient Al-gorithms for Conditional Random Fields and Max-Margin Markov Networks.
JMLR.
[Das and Petrov2011] D. Das and S. Petrov.
2011.
Un-supervised Part-of-Speech Tagging with BilingualGraph-Based Projections.
In Proc.
ACL.
[Das et al012] D. Das, S. Petrov, and R. McDonald.2012.
A Universal Part-of-Speech Tagset.
In Proc.LREC.
[Ganchev et al010] K. Ganchev, J. Grac?a, J. Gillen-water, and B. Taskar.
2010.
Posterior Regulariza-tion for Structured Latent Variable Models.
JMLR.
[Griewank1988] A. Griewank.
1988.
On AutomaticDifferentiation.
Technical report, Argonne NationalLaboratory.
[Joachims2003] T. Joachims.
2003.
TransductiveLearning via Spectral Graph Partitioning.
In Proc.ICML.
[Kassel1995] R. Kassel.
1995.
A Comparison of Ap-proaches to On-line Handwritten Character Recog-nition.
Ph.D. thesis, Massachusetts Institute ofTechnology.
[Kivinen and Warmuth1995] J. Kivinen and M. War-muth.
1995.
Additive Versus Exponentiated Gra-dient Updates for Linear Prediction.
In Proc.
STOC.
[Mann and McCallum2007] G. Mann and A. McCal-lum.
2007.
Simple, Robust, Scalable Semi-Supervised Learning via Expectation Regulariza-tion.
In Proc.
ICML.
[Mann and McCallum2008] G. Mann and A. McCal-lum.
2008.
Generalized Expectation Criteria forSemi-Supervised Learning of Conditional RandomFields.
In Proc.
ACL.
[Marcus et al993] M. Marcus, M. Marcinkiewicz, andB.
Santorini.
1993.
Building a Large AnnotatedCorpus of English: Then Penn Treebank.
Compu-tational Linguistics.
[Nivre et al007] J. Nivre, J.
Hall, S. Ku?bler, R. Mc-Donald, J. Nilsson, S. Riedel, and D. Yuret.
2007.The CoNLL 2007 Shared Task on Dependency Pars-ing.
In Proc.
CoNLL.
[Pele and Werman2009] O. Pele and M. Werman.2009.
Fast and Robust Earth Mover?s Distances.
InProc.
ICCV.
[Subramanya and Bilmes2009] A. Subramanya andJ.
Bilmes.
2009.
Entropic Graph Regularization inNon-Parametric Semi-Supervised Classification.
InProc.
NIPS.
[Subramanya et al010] A. Subramanya, S. Petrov, andF.
Pereira.
2010.
Efficient Graph-Based Semi-Supervised Learning of Structured Tagging Models.In Proc.
EMNLP.
[Taskar et al003] B. Taskar, C. Guestrin, andD.
Koller.
2003.
Max Margin Markov Networks.In Proc.
NIPS.
[van de Panne and Whinston1964] C. van de Panne andA.
Whinston.
1964.
The Simplex and the DualMethod for Quadratic Programming.
OperationalResearch Quarterly.
[Zhu and Lafferty2005] X. Zhu and J. Lafferty.
2005.Harmonic Mixtures: Combining Mixture Modelsand Graph-Based Methods for Inductive and Scal-able Semi-Supervised Learning.
In Proc.
ICML.
[Zhu et al003] X. Zhu, Z. Ghahramani, and J. Laf-ferty.
2003.
Semi-Supervised Learning UsingGaussian Fields and Harmonic Functions.
In Proc.ICML.
[Zhu2005] X. Zhu.
2005.
Semi-Supervised LearningLiterature Survey.
Technical report, University ofWisconsin-Madison.46
