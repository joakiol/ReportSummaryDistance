Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 57?64,New York, June 2006. c?2006 Association for Computational LinguisticsAcquiring Inference Rules with Temporal Constraintsby Using Japanese Coordinated Sentences and Noun-Verb Co-occurrencesKentaro TorisawaJapan Advanced Institute of Science and Technology1-1 Asahidai, Nomi-shi, Ishikawa-ken, 923-1211 JAPANtorisawa@jaist.ac.jpAbstractThis paper shows that inference rules withtemporal constraints can be acquired by us-ing verb-verb co-occurrences in Japanesecoordinated sentences and verb-noun co-occurrences.
For example, our unsuper-vised acquisition method could obtain theinference rule ?If someone enforces a law,usually someone enacts the law at the sametime as or before the enforcing of thelaw?
since the verbs ?enact?
and ?enforce?frequently co-occurred in coordinated sen-tences and the verbs also frequently co-occurred with the noun ?law?.
We alsoshow that the accuracy of the acquisitionis improved by using the occurrence fre-quency of a single verb, which we assumeindicates how generic the meaning of theverb is.1 IntroductionOur goal is to develop an unsupervised method foracquiring inference rules that describe logical impli-cations between event occurrences.
As clues to ?ndthe rules, we chose Japanese coordinated sentences,which typically report two events that occur in a cer-tain temporal order.
Of course, not every coordi-nated sentence necessarily expresses implications.
Wefound, though, that reliable rules can be acquired bylooking at co-occurrence frequencies between verbsin coordinated sentences and co-occurrences betweenverbs and nouns.
For example, our method could ob-tain the rule ?If someone enforces a law, usually some-one enacts the law at the same time as or before theenforcing of the law?.
In our experiments, when ourmethod produced 400 rules for 1,000 given nouns,70% of the rules were considered proper by at leastthree of four human judges.Note that the acquired inference rules pose tempo-ral constraints on occurrences of the events describedin the rules.
In the ?enacting-and-enforcing-law?
ex-ample, the constraints were expressed by the phrase?at the same time as or before the event of?.
We thinksuch temporally constrained rules should be bene?cialin various types of NLP applications.
The rules shouldallow Q&A systems to guess or restrict the time atwhich a certain event occurs even if they cannot di-rectly ?nd the time in given documents.
In addition,we found that a large part of the acquired rules can beregarded as paraphrases, and many possible applica-tions of paraphrases should also be target applications.To acquire rules, our method uses a score, which isbasically an approximation of the probability that par-ticular coordinated sentences will be observed.
How-ever, it is weighted by a bias, which embodies our as-sumption that frequently observed verbs are likely toappear as the consequence of a proper inference rule.This is based on our intuition that frequently appear-ing verbs have a generic meaning and tend to describea wide range of situations, and that natural languageexpressions referring to a wide range of situations aremore likely to be a consequence of a proper rule thanspeci?c expressions describing only a narrow range ofevents.
A similar idea relying on word co-occurrencewas proposed by Geffet and Dagan (Geffet and Da-gan, 2005) but our method is simpler and we expect itto be applicable to a wider range of vocabularies.Research on the automatic acquisition of inferencerules, paraphrases and entailments has received muchattention.
Previous attempts have used, for instance,the similarities between case frames (Lin and Pan-57tel, 2001), anchor words (Barzilay and Lee, 2003;Shinyama et al, 2002; Szepektor et al, 2004), and aweb-based method (Szepektor et al, 2004; Geffet andDagan, 2005).
There is also a workshop devoted tothis task (Dagan et al, 2005).
The obtained accuracieshave still been low, however, and we think searchingfor other clues, such as coordinated sentences and thebias we have just mentioned, is necessary.
In addition,research has also been done on the acquisition of thetemporal relations (Fujiki et al, 2003; Chklovski andPantel, 2004) by using coordinated sentences as wedid, but these works did not consider the implicationsbetween events.2 Algorithm with a Simpli?ed ScoreIn the following, we begin by providing an overviewof our algorithm.
We specify the basic steps in the al-gorithm and the form of the rules to be acquired.
Wealso examine the direction of implications and tempo-ral ordering described by the rules.
After that, we de-scribe a simpli?ed version of the scoring function thatour algorithm uses and then discuss a problem relatedto it.
The bias mechanism, which we mentioned in theintroduction, is described in the section after that.2.1 Procedure and Generated Inference RulesOur algorithm is given a noun as its input and pro-duces a set of inference rules.
A produced rule ex-presses an implication relation between two descrip-tions including the noun.
Our basic assumptions forthe acquisition can be stated as follows.?
If verbs v1 and v2 frequently co-occur in coordi-nated sentences, the verbs refer to two events thatactually frequently co-occur in the real world,and a sentence including v1 and another sentenceincluding v2 are good candidates to be descrip-tions that have an implication relation and a par-ticular temporal order between them.?
The above tendency becomes stronger when theverbs frequently co-occur with a given noun n;i.e., if v1 and v2 frequently co-occur in coordi-nated sentences and the verbs also frequently co-occur with a noun n, a sentence including v1 andn and another sentence including v2 and n aregood candidates to be descriptions that have animplication relation between them.Our procedure consists of the following steps.Step 1 Select M verbs that take a given noun n astheir argument most frequently.Step 2 For each possible pair of the selected verbs,compute the value of a scoring function that em-bodies our assumptions, and select the N verbpairs that have the largest score values.
Notethat we exclude the combination of the same verbfrom the pairs to be considered.Step 3 If the score value for a verb pair is higher thana threshold ?
and the verbs take n as their syntac-tic objects, generate an inference rule from theverb pair and the noun.Note that we used 500 as the value of M .
N was setto 4 and ?
was set to various values during our ex-periments.
Another important point is that, in Step 3,the argument positions at which the given noun canappear is restricted to syntactic objects.
This was be-cause we empirically found that the rules generatedfrom such verb-noun pairs were relatively accurate.Assume that a given noun is ?goods?
and the verbpair ?sell?
and ?manufacture?
is selected in Step 3.Then, the following rule is generated.?
If someone sells goods, usually someone manu-factures the goods at the same time as or beforethe event of the selling of the goods.Although the word ?someone?
occurs twice, we donot demand that it refers to the same person in bothinstances.
It just works as a placeholder.
Also notethat the adverb ?usually?1 was inserted to prevent therule from being regarded as invalid by considering sit-uations that are logically possible but unlikely in prac-tice.The above rule is produced when ?manufacture?and ?sell?
frequently co-occur in coordinated sen-tences such as ?The company manufactured goodsand it sold them?.
One might be puzzled because theorder of the occurrences of the verbs in the coordi-nated sentences is reversed in the rule.
The verb ?sell?in the second (embedded) sentence/clause in the coor-dinated sentence appears as a verb in the preconditionof the rule, while ?manufacture?
in the ?rst (embed-ded) sentence/clause is the verb in the consequence.A question then, is why we chose such an order,or such a direction of implication.
There is anotherpossibility, which might seem more straightforward.From the same coordinated sentences, we could pro-duce the rule where the direction is reversed; i.e,., ?Ifsomeone manufactures goods, usually someone sells1We used ?futsuu?
as a Japanese translation.58the goods at the same time as or after the manufactur-ing?.
The difference is that the rules generated by ourprocedure basically infer a past event from anotherevent, while the rules with the opposite direction haveto predict a future event.
In experiments using our de-velopment set, we observed that the rules predictingfuture events were often unacceptable because of theuncertainty that we usually encounter in predicting thefuture or achieving a future goal.
For instance, peo-ple might do something (e.g., manufacturing) with anintention to achieve some other goal (e.g., selling) inthe future.
But they sometimes fail to achieve their fu-ture goal for some reason.
Some manufactured goodsare never sold because, for instance, they are not goodenough.
In our experiments, we found that the preci-sion rates of the rules with the direction we adoptedwere much higher than those of the rules with the op-posite direction.2.2 Simpli?ed Scoring FunctionTo be precise, a rule generated by our method has thefollowing form, where vpre and vcon are verbs and nis a given noun.?
If someone vpre n, usually someone vcon the n atthe same time as or before the vpre-ing of the n.We assume that all three occurrences of noun n in therule refer to the same entity.Now, we de?ne a simpli?ed version of our scoringfunction as follows.BasicS(n, vcon, vpre, arg, arg?)
=Pcoord(vcon, vpre)Parg?
(n|vpre)Parg(n|vcon)/P (n)2Here, Pcoord(vcon, vpre) is the probability that vconand vpre are observed in coordinated sentences in away that the event described by vcon temporally pre-cedes or occurs at the same time as the event de-scribed by vpre.
(More precisely, vcon and vpre mustbe the main verbs of two conjuncts S1 and S2 in aJapanese coordinated sentence that is literally trans-lated to the form ?S1 and S2?.)
This means that inthe coordinated sentences, vcon appears ?rst and vpresecond.
Parg?
(n|vpre) and Parg(n|vcon) are the condi-tional probabilities that n occupies the argument posi-tions arg?
of vpre and arg of vcon, respectively.
At thebeginning, as possible argument positions, we speci-?ed ?ve argument positions, including the syntacticobject and the subject.
Note that when vpre and vconfrequently co-occur in coordinated sentences and noften becomes arguments of vpre and vcon, the scorehas a large value.
This means that the score embodiesour assumptions for acquiring rules.The term Pcoord(vcon, vpre)Parg?
(n|vpre)Parg(n|vcon) inBasicS is actually an approximation of the proba-bility P (vpre, arg?, n, vcon, arg, n) that we will ob-serve the coordinated sentences such that the two sen-tences/clauses in the coordinated sentence are headedby vpre and vcon and n occupies the argument posi-tions arg?
of vpre and arg of vcon.
Another importantpoint is that the score is divided by P (n)2.
This is be-cause the probabilities such as Parg(n|vcon) tend to belarge for a frequently observed noun n. The divisionby P (n)2 is done to cancel such a tendency.
This di-vision does not affect the ranking for the same noun,but, since we give a uniform threshold for selectingthe verb pairs for distinct nouns, such normalizationis desirable, as we con?rmed in experiments using ourdevelopment set.2.3 Paraphrases and Coordinated SentencesThus, we have de?ned our algorithm and a simpli?edscoring function.
Now let us discuss a problem that iscaused by the scoring function.As mentioned in the introduction, a large por-tion of the acquired rules actually consists of para-phrases.
Here, by a paraphrase, we mean a rule con-sisting of two descriptions referring to an identicalevent.
The following example is an English transla-tion of such paraphrases obtained by our method.
Wethink this rule is acceptable.
Note that we invented anew English verb ?clearly-write?
as a translation of aJapanese verb meiki-suruwhile ?write?
is a trans-lation of another Japanese verb kaku.?
If someone clearly-writes a phone number, usu-ally someone writes the phone number at thesame time as or before the clearly-writing of thephone number.Note that ?clearly-write?
and ?write?
have almost thesame meaning but the former is often used in textsrelated to legal matters.
Evidently, in the above rule,?clearly-write?
and ?write?
describe the same event,and it can be seen as a paraphrase.
There are twotypes of coordinated sentence that our method can useas clues to generate the rule.?
He clearly-wrote a phone number and wrote thephone number.?
He clearly-wrote a phone number, and also wrotean address.The ?rst sentence is more similar to the inferencerule than the second in the sense that the two verbs59share the same object.
However, it is ridiculous be-cause it describes the same event twice.
Such a sen-tence is not observed frequently in corpora, and willnot be used as clues to generate rules in practice.On the other hand, we frequently observe sen-tences of the second type in corpora, and our methodgenerates the paraphrases from the verb-verb co-occurrences taken from such sentences.
However,there is a mismatch between the sentence and the ac-quired rule in the sense that the rule describes twoevents related to the same object (i.e., a phone num-ber), while the above sentence describes two eventsthat are related to distinct objects (i.e., a phone num-ber and an address).
Regarding this mismatch, twoquestions need to be addressed.The ?rst question is why our method can acquirethe rule despite the mismatch.
The answer is thatour method obtains the verb-verb co-occurrence prob-abilities (Pcoord(vcon, vpre)) and the verb-noun co-occurrence probabilities (e.g., Parg(n|vcon)) indepen-dently, and that the method does not check whetherthe two verbs share an argument.Then the next question is why our method canacquire accurate paraphrases from such coordinatedsentences.
Though we do not have a de?nite answernow, our hypothesis is related to the strategy that peo-ple adopt in writing coordinated sentences.
When twosimilar but distinct events, which can be described bythe same verb, occur successively or at the same time,people avoid repeating the same verb to describe thetwo events in a single sentence.
Instead they try touse distinct verbs that have similar meanings.
Sup-pose that a person wrote his name and address.
Toreport what she did, she may write ?I clearly-wrotemy name and also wrote my address?
but will seldomwrite ?I clearly-wrote my name and also clearly-wrotemy address?.
Thus, we can expect to be able to ?ndin coordinated sentences a large number of verb pairsconsisting of two verbs with similar meanings.
Notethat our method tends to produce two verbs that fre-quently co-occur with a given noun.
This also helps toproduce the inference rules consisting of two seman-tically similar verbs.3 Bias MechanismWe now describe a bias used in our full scoring func-tion, which signi?cantly improves the precision.
Thefull scoring function is de?ned asScore(n, vcon, vpre, arg, arg?)
=Parg(vcon)BasicS(n, vcon, vpre, arg, arg?
).The bias is denoted as Parg(vcon), which is the prob-ability that we can observe the verb vcon, which is theverb in the consequence of the rule, and its argumentposition arg is occupied by a noun, no matter whichnoun actually occupies the position.An intuitive explanation of the assumption behindthis bias is that as the situation within which the de-scription of the consequence in a rule is valid becomeswider, the rule becomes more likely to be a properone.
Consider the following rules.?
If someone demands a compensation payment,someone orders the compensation payment.?
If someone demands a compensation payment,someone requests the compensation payment.We consider the ?rst rule to be unacceptable while thesecond expresses a proper implication.
The differenceis the situations in which the descriptions in the con-sequences hold.
In our view, the situations describedby ?order?
are more speci?c than those referred to by?request?.
In other words, ?order?
holds in a smallerrange of situations than ?request?.
Requesting some-thing can happen in any situations where there existssomeone who can demand something, but orderingcan occur only in a situations where someone in a par-ticular social position can demand something.
The ba-sic assumption behind our bias is that rules with con-sequences that can be valid in a wider range of situa-tions, such as ?requesting a compensation payment,?are more likely to be proper ones than the rules withconsequences that hold in a smaller range of situa-tions, such as ?ordering a compensation payment?.The bias Parg(vcon) was introduced to capture vari-ations of the situations in which event descriptions arevalid.
We assume that frequently observed verbs formgeneric descriptions that can be valid within a widerange of events, while less frequent verbs tend to de-scribe events that can occur in a narrower range of sit-uations and form more speci?c descriptions than thefrequently observed verbs.
Regarding the ?request-order?
example, (a Japanese translation of) ?request?is observed more frequently than (a Japanese transla-tion of) ?order?
in corpora and this observation is con-sistent with our assumption.
A similar idea by Geffetand Dagan (Geffet and Dagan, 2005) was proposedfor capturing lexical entailment.
The difference is thatthey relied on word co-occurrences rather than thefrequency of words to measure the speci?city of thesemantic contents of lexical descriptions, and neededWeb search to avoid data sparseness in co-occurrence60statistics.
On the other hand, our method needs onlysimple occurrence probabilities of single verbs and weexpect our method to be applicable to wider vocabu-lary than Geffet and Dagan?s method.The following is a more mathematical justi?cationfor the bias.
According to the following discussion,Parg(vcon) can be seen as a metric indicating howeasily we can establish an interpretation of the rule,which is formalized as a mapping between events.
Inour view, if we can establish the mapping easily, therule tends to be acceptable.
The discussion starts froma formalization of an interpretation of an inferencerule.
Consider the rule ?If exp1 occurs, usually exp2occurs at the same time or before the occurrence ofexp1?, where exp1 and exp2 are natural language ex-pressions referring to events.
In the following, we callsuch expressions event descriptions and distinguishthem from an actual event referred to by the expres-sions.
An actual event is called an event instance.A possible interpretation of the rule is that, for anyevent instance e1 that can be described by the eventdescription exp1 in the precondition of the rule, therealways exists an event instance e2 that can be de-scribed by the event description exp2 in the conse-quence and that occurs at the same time as or beforee1 occurs.
Let us write e : exp if event instance ecan be described by event description exp.
The aboveinterpretation can then be represented by the formula?
: ?f(?e1(e1 : exp1 ?
?e2(e2 = f(e1) ?
e2 : exp2)).Here, the mapping f represents a temporal relationbetween events, and the formula e2 = f(e1) expressesthat e2 occurs at the same time as or before e1.The bias Parg(vcon) can be considered (an approx-imation of) a parameter required for computing theprobability that a mapping frandom satis?es the re-quirements for f in ?
when we randomly constructfrandom.
The probability is denoted as P{e2 : exp2 ?e2 = frandom(e1)|e1 : exp1}E1 where E1 denotesthe number of events describable by exp1.
We as-sume that the larger this probability is, the more eas-ily we can establish f .
We can approximate P{e2 :exp2?e2 = frandom(e1)|e1 : exp1} as P (exp2) by 1)observing that the probabilistic variables e1 and e2 areindependent since frandom associates them in a com-pletely random manner and by 2) assuming that theoccurrence probability of the event instances describ-able by exp2 can be approximated by the probabilitythat exp2 is observed in text corpora.
This means thatP (exp2) is one of the metrics indicating how easilywe can establish the mapping f in ?.Then, the next question is what kind of expressionsshould be regarded as the event description exp2.
Aprimary candidate will be the whole sentence appear-ing in the consequence part of the rule to be produced.Since we specify only a verb vcon and its argument nin the consequence in a rule, P (exp2) can be denotedby Parg(n, vcon), which is the probability that we ob-serve the expression such that vcon is a head verb andn occupies an argument position arg of vcon.
By mul-tiplying this probability to BasicS as a bias, we ob-tain the following scoring function.Scorecooc(n, vcon, vpre, arg, arg?)
=Parg(n, vcon)BasicS(n, vcon, vpre, arg, arg?
)In our experiments, though, this score did not workwell.
Since Parg(n, vcon) often has a small value, theproblem of data sparseness seems to arise.
Then, weused Parg(vcon), which denotes the probability of ob-serving sentences that contain vcon and its argumentposition arg, no matter which noun occupies arg, in-stead of Parg(n, vcon).
We multiplied the probabilityto BasicS as a bias and obtained the following score,which is actually the scoring function we propose.Score(n, vcon, vpre, arg, arg?)
=Parg(vcon)BasicS(n, vcon, vpre, arg, arg?
)4 Experiments4.1 SettingsWe parsed 35 years of newspaper articles (Yomiuri87-01, Mainichi 91-99, Nikkei 90-00, 3.24GB in to-tal) and 92.6GB of HTML documents downloadedfrom the WWW using an existing parser (Kanayamaet al, 2000) to obtain the word (co-occurrence) fre-quencies.
All the probabilities used in our methodwere estimated by maximum likelihood estimationfrom these frequencies.
We randomly picked 600nouns as a development set.
We prepared three testsets, namely test sets A, B, and C, which consisted of100 nouns, 250 nouns and 1,000 nouns respectively.Note that all the nouns in the test sets were randomlypicked and did not have any common items with thedevelopment set.
In all the experiments, four humanjudges checked if each produced rule was a proper onewithout knowing how each rule was produced.4.2 Effects of Using Coordinated SentencesIn the ?rst series of experiments, we compared asimpli?ed version of our scoring function BasicSwith some alternative scores.
This was mainlyto check if coordinated sentences can improveaccuracy.
The alternative scores we considered610204060801000  50  100  150  200  250  300  350  400Precision(%)Number of inference rulesBasicSS-VVS-NVMIConditionalRandFigure 1: Comparison with the alternatives (4 judges)0204060801000  50  100  150  200  250  300  350  400Precision(%)Number of inference rulesBasicSS-VVS-NVMIConditionalRandFigure 2: Comparison with the alternatives (3 judges)are presented below.
Note that we did not testour bias mechanism in this series of experiments.S-V V (n, vcon, vpre, arg, arg?)
=Parg(n, vcon)Parg?
(n, vpre)/P (n)2S-NV (n, vcon, vpre) = Pcoord(vcon, vpre)MI(n, vcon, vpre) = Pcoord(vcon, vpre)/(P (vcon)P (vpre))Cond(n, vcon, vpre, arg, arg?
)= Pcoord(vcon, vpre, arg, arg?)Parg(n|vcon)Parg?(n|vpre)/(Parg?
(n, vpre)P (n))Rand(n, vcon, vpre, arg, arg?)
= random numberS-V V was obtained by approximating the proba-bilities of coordinated sentences, as in the case ofBasicS.
However, we assumed the occurrences oftwo verbs were independent.
The difference betweenthe performance of this score and that of BasicSwill indicate the effectiveness of using verb-verbco-occurrences in coordinated sentences.The second alternative, S-NV , simply ignores thenoun-verb co-occurrences in BasicS.
MI is a scorebased on mutual information and roughly correspondsto the score used in a previous attempt to acquire tem-poral relations between events (Chklovski and Pan-tel, 2004).
Cond is an approximation of the proba-bility P (n, vcon|n, vpre); i.e., the conditional proba-0204060801000  20  40  60  80  100  120Precision(%)Number of inference rulesBasicSS-VVS-NVMICondFigure 3: Comparison with the alternatives (3 judges)bility that the coordinated sentences consisting of n,vcon and vpre are observed given the precondition partconsisting of vpre and n. Rand is a random numberand generates rules by combining verbs that co-occurwith the given n randomly.
This was used as a base-line method of our taskThe resulting precisions are shown in Figures 1 and2.
The ?gure captions specify ?
(4 judges)?, as in Fig-ure 1, when the acceptable rules included only thoseregarded as proper by all four judges; the captionsspecify ?
(3 judges)?, as in Figure 2, when the ac-ceptable rules include those considered proper by atleast three of the four judges.
We used test set A (100nouns) and produced the top four rule candidates foreach noun according to each score.
As the ?nal re-sults, all the produced rules for all the nouns weresorted according to each score, and a precision wasobtained for top N rules in the sorted list.
This wasthe same as the precision achieved by setting the scorevalue ofN -th rule in the sorted list as threshold ?.
No-tice that BasicS outperformed all the alternatives2 ,though the difference between S-V V and BasicSwas rather small.
Another important point is that theprecisions obtained with the scores that ignored noun-verb co-occurrences were quite low.
These ?ndingssuggest that 1) coordinated sentences can be usefulclues for obtaining temporally constrained rules and2) noun-verb co-occurrences are also important clues.In the above experiments, we actually allowed nounn to appear as argument types other than the syntac-tic objects of a verb.
When we restricted the argu-2Actually, the experiments concerning Rand were conductedconsiderably after the experiments on the other scores, and onlythe two of the four judges for Rand were included in the judgesfor other scores.
However, we think that the superiority of ourscore BasicS over the baseline method was con?rmed since theprecision of Rand was drastically lower than that of BasicS6220304050607080901000  50  100  150  200  250  300  350Precision(%)Number of inference rulesProposed directionReversedFigure 4: Two directions of implications (3 judges)ment types to syntactic objects, as described in Sec-tion 2, the precision shown in Figure 3 was obtained.In most cases, BasicS outperformed the alternatives.Although the number of produced rules was reducedbecause of this restriction, the precision of all pro-duced rules was improved.
Because of this, we de-cided to restrict the argument type to objects.The kappa statistic for assessing the inter-rateragreement was 0.53, which indicates moderate agree-ment according to Landis and Koch, 1977.
The kappavalue for only the judgments on rules produced byBasicS rose to 0.59.
After we restricted the verb-noun co-occurrences to verb-object co-occurrences,the kappa became 0.49, while that for the rules pro-duced by BasicS was 0.543.4.3 Direction of ImplicationsNext, we examined the directions of implications andthe temporal order between events.
We produced1,000 rules for test set B (250 nouns) using the scoreBasicS, again without restricting the argument typesof given nouns to syntactic objects.
When we re-stricted the argument positions to objects, we obtained347 rules.
Then, from each generated rule, we createda new rule having an opposite direction of implica-tions.
We swapped the precondition and the conse-quence of the rule and reversed its temporal order.
Forinstance, we created ?If someone enacts a law, usuallysomeone enforces the law at the same time as or afterthe enacting of the law?
from ?If someone enforces alaw, usually someone enacts the law at the same timeas or before the enforcing of the law?.Figure 4 shows the results.
?Proposed direction?3These kappa values were calculated for the results except forthe ones obtained by the score Rand, which were assessed bydifferent judges.
The kappa for Rand was 0.33 (fair agreement).4050607080901000  50  100  150  200  250  300  350  400Precision(%)Number of inference rulesScorereranked by Scorereranked by ScoreCoocBasicSreranked by PreBiasFigure 5: Effects of the bias (4 judges)4050607080901000  50  100  150  200  250  300  350  400Precision(%)Number of inference rulesScorereranked by Scorereranked by ScoreCoocBasicSreranked by PreBiasFigure 6: Effects of the bias (3 judges)refers to the precision of the rules generated by ourmethod.
The precision of the rules with the oppositedirection is indicated by ?Reversed.?
The precision of?Reversed?
was much lower than that of our method,and this justi?es our choice of direction.
The kappasvalues for ?BasicS?
and ?Reversed?
were 0.54 and 0.46respectively.
Both indicate moderate agreement.4.4 Effects of the BiasLast, we compared Score and BasicS to see the ef-fect of our bias.
This time, we used test set C (1,000nouns).
The rules were restricted to those in whichthe given nouns are syntactic objects of two verbs.The evaluation was done for only the top 400 rules foreach score.
The results are shown in Figures 5 and 6.?Score?
refers to the precision obtained with Score,while ?BasicS?
indicates the precision with BasicS.For most data points in both graphs, the ?Score?
pre-cision was about 10% higher than the ?BasicS?
preci-sion.
In Figure 6, the precision reached 70% when the400 rules were produced.
These results indicate thedesirable effect of our bias for, at least, the top rules.63rank inference rules/judges4/0 moshi yougi wo hininsuru naraba,yougi wo mitomeru(If someone denies suspicions, usuallysomeone con?rms the suspicions.
)6/4 moshi jikokiroku wo uwamawarunaraba, jikokiroku wo koushinsuru(If someone betters her best record, usuallysomeone breaks her best record.
)21/3 moshi katakuriko wo mabusu naraba,katakuriko wo tsukeru(If someone coats something with potato starch,usually someone covers something with the starch)194/4 moshi sasshi wo haifusuru naraba,sasshi wo sakuseisuru(If someone distributes a booklet, usuallysomeone makes the booklet.
)303/4 moshi netsuzou wo kokuhakusurunaraba, netsuzou wo mitomeru(If someone confesses to a fabrication, usuallysomeone admits the fabrication.
)398/3 moshi ifuku wo kikaeru naraba,ifuku wo nugu(If someone changes clothes, usuallysomeone gets out of the clothes.
)Figure 7: Examples of acquired inference rulesThe 400 rules generated by Score included 175 dis-tinct nouns and 272 distinct verb pairs.
Examples ofthe inference rules acquired by Score are shown inFigure 7 along with the positions in the ranking andthe numbers of judges who judged the rule as beingproper.
(We omitted the phrase ?the same time as orbefore?
in the examples.)
The kappa was 0.57 (mod-erate agreement).In addition, the graphs compare Score with someother alternatives.
This comparison was made tocheck the effectiveness of our bias more carefully.The 400 rules generated by BasicS were re-rankedusing Score and the alternative scores, and the pre-cision for each was computed using the human judg-ments for the rules generated by BasicS.
(We didnot evaluate the rules directly generated by the al-ternatives to reduce the workload of the judges.
)The ?rst alternative was Scorecooc, which was pre-sented in Section 3.
Here, ?reranked by ScoreCooc?refers to the precision obtained by re-ranking with ofScorecooc.
The precision was below that obtained bythe re-ranking with Score, (referred to as ?rerankedby Score)?.
As discussed in Section 3, this indicatesthe bias Parg(vcon) in Score works better than thebias Parg(n, vcon) in Scorecooc.The second alternative was the scoring function ob-tained by replacing the bias Parg(vcon) in Score withParg?
(vpre) , which is roughly the probability that theverb in the precondition will be observed.
The scoreis denoted as PreBias(n, vcon, vpre, arg, arg?)
=Parg?
(vpre)BasicS(n, vcon, vpre, arg, arg?).
Theprecision of this score is indicated by ?reranked byPreBias?
and is much lower than that of ?reranked byScore?, indicating that only probability of the verbsin the consequences should be used as a bias.
This isconsistent with our assumption behind the bias.5 ConclusionWe have presented an unsupervised method for ac-quiring inference rules with temporal constraints,such as ?If someone enforces a law, someone enactsthe law at the same time as or before the enforcing ofthe law?.
We used the probabilities of verb-verb co-occurrences in coordinated sentences and verb-nounco-occurrences.
We have also proposed a bias mecha-nism that can improve the precision of acquired rules.ReferencesR.
Barzilay and L. Lee.
2003.
Learning to paraphrase:anunsupervised approach using multiple-sequence align-ment.
In Proc.
of HLT-NAACL 2003, pages 16?23.T.
Chklovski and P. Pantel.
2004.
Verbocean: Mining theweb for ?ne-grained semantic verb relations.
In Proc.
ofEMNLP-04.I.
Dagan, O. Glickman, and B. Magnini, editors.2005.
Proceedings of the First Challenge Work-shop: Recognizing Textual Entailment.
available fromhttp://www.pascal-network.org/Challenges/RTE/.T.
Fujiki, H. Namba, and M. Okumura.
2003.
Automaticacquisition of script knowledge from text collection.
InProc.
of The Research Note Sessions of EACL?03.M.
Geffet and I. Dagan.
2005.
The distributional inclu-sion hypotheses and lexical entailment.
In Proc.
of ACL2005, pages 107?114.H.
Kanayama, K. Torisawa, Y. Mitsuishi, and J. Tsujii.2000.
A hybrid Japanese parser with hand-crafted gram-mar and statistics.
In Proc.
of COLING 2000.J.
R. Landis and G. G. Koch.
1977.
The measurementof observer agreement for categorial data.
Biometrics,33:159?174.D.
Lin and P. Pantel.
2001.
Discovery of inference rulesfor question answering.
Journal of Natural LanguageEngineering.Y.
Shinyama, S. Sekine, and K. Sudo.
2002.
Automaticparaphrase acquisition from news articles.
In Proc.
ofHLT2002.I.
Szepektor, H. Tanev, I. Dagan, and B. Coppola.
2004.Scaling web-based acquisition of entailment relations.In Proc.
of EMNLP 2004.64
