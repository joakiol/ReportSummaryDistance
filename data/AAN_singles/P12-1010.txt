Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 88?97,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsExtracting Narrative Timelines as Temporal Dependency StructuresOleksandr KolomiyetsKU LeuvenCelestijnenlaan 200AB-3001 Heverlee, BelgiumOleksandr.Kolomiyets@cs.kuleuven.beSteven BethardUniversity of ColoradoCampus Box 594Boulder, CO 80309, USASteven.Bethard@colorado.eduMarie-Francine MoensKU LeuvenCelestijnenlaan 200AB-3001 Heverlee, BelgiumSien.Moens@cs.kuleuven.beAbstractWe propose a new approach to characterizingthe timeline of a text: temporal dependencystructures, where all the events of a narrativeare linked via partial ordering relations like BE-FORE, AFTER, OVERLAP and IDENTITY.
Weannotate a corpus of children?s stories with tem-poral dependency trees, achieving agreement(Krippendorff?s Alpha) of 0.856 on the eventwords, 0.822 on the links between events, andof 0.700 on the ordering relation labels.
Wecompare two parsing models for temporal de-pendency structures, and show that a determin-istic non-projective dependency parser outper-forms a graph-based maximum spanning treeparser, achieving labeled attachment accuracyof 0.647 and labeled tree edit distance of 0.596.Our analysis of the dependency parser errorsgives some insights into future research direc-tions.1 IntroductionThere has been much recent interest in identifyingevents, times and their relations along the timeline,from event and time ordering problems in the Temp-Eval shared tasks (Verhagen et al, 2007; Verhagenet al, 2010), to identifying time arguments of eventstructures in the Automated Content Extraction pro-gram (Linguistic Data Consortium, 2005; Gupta andJi, 2009), to timestamping event intervals in theKnowledge Base Population shared task (Artiles etal., 2011; Amigo?
et al, 2011).However, to date, this research has produced frag-mented document timelines, because only specifictypes of temporal relations in specific contexts havebeen targeted.
For example, the TempEval tasks onlylooked at relations between events in the same or ad-jacent sentences (Verhagen et al, 2007; Verhagen etal., 2010), and the Automated Content Extraction pro-gram only looked at time arguments for specific typesof events, like being born or transferring money.In this article, we propose an approach to temporalinformation extraction that identifies a single con-nected timeline for a text.
The temporal languagein a text often fails to specify a total ordering overall the events, so we annotate the timelines as tem-poral dependency structures, where each event is anode in the dependency tree, and each edge betweennodes represents a temporal ordering relation suchas BEFORE, AFTER, OVERLAP or IDENTITY.
Weconstruct an evaluation corpus by annotating suchtemporal dependency trees over a set of children?sstories.
We then demonstrate how to train a time-line extraction system based on dependency parsingtechniques instead of the pair-wise classification ap-proaches typical of prior work.The main contributions of this article are:?
We propose a new approach to characterizingtemporal structure via dependency trees.?
We produce an annotated corpus of temporaldependency trees in children?s stories.?
We design a non-projective dependency parserfor inferring timelines from text.The following sections first review some relevantprior work, then describe the corpus annotation andthe dependency parsing algorithm, and finally presentour evaluation results.882 Related WorkMuch prior work on the annotation of temporal in-formation has constructed corpora with incompletetimelines.
The TimeBank (Pustejovsky et al, 2003b;Pustejovsky et al, 2003a) provided a corpus anno-tated for all events and times, but temporal relationswere only annotated when the relation was judged tobe salient by the annotator.
In the TempEval compe-titions (Verhagen et al, 2007; Verhagen et al, 2010),annotated texts were provided for a few differentevent and time configurations, for example, an eventand a time in the same sentence, or two main-clauseevents from adjacent sentences.
Bethard et al (2007)proposed to annotate temporal relations one syntacticconstruction at a time, producing an initial corpus ofonly verbal events linked to events in subordinatedclauses.
One notable exception to this pattern ofincomplete timelines is the work of Bramsen et al(2006) where temporal structures were annotated asdirected acyclic graphs.
However they worked on amuch coarser granularity, annotating not the order-ing between individual events, but between multi-sentence segments of text.In part because of the structure of the availabletraining corpora, most existing temporal informa-tion extraction models formulate temporal linkingas a pair-wise classification task, where each pairof events and/or times is examined and classified ashaving a temporal relation or not.
Early work on theTimeBank took this approach (Boguraev and Ando,2005), classifying relations between all events andtimes within 64 tokens of each other.
Most of the top-performing systems in the TempEval competitionsalso took this pair-wise classification approach forboth event-time and event-event temporal relations(Bethard and Martin, 2007; Cheng et al, 2007; UzZa-man and Allen, 2010; Llorens et al, 2010).
Systemshave also tried to take advantage of more global in-formation to ensure that the pair-wise classificationssatisfy temporal logic transitivity constraints, usingframeworks such as integer linear programming andMarkov logic networks (Bramsen et al, 2006; Cham-bers and Jurafsky, 2008; Yoshikawa et al, 2009; Uz-Zaman and Allen, 2010).
Yet the basic approach isstill centered around pair-wise classifications, not thecomplete temporal structure of a document.Our work builds upon this prior research, bothimproving the annotation approach to generate thefully connected timeline of a story, and improvingthe models for timeline extraction using dependencyparsing techniques.
We use the annotation schemeintroduced in more detail in Bethard et.
al.
(2012),which proposes to annotate temporal relations as de-pendency links between head events and dependentevents.
This annotation scheme addresses the issuesof incoherent and incomplete annotations by guaran-teeing that all events in a plot are connected alonga single timeline.
These connected timelines allowus to design new models for timeline extraction inwhich we jointly infer the temporal structure of thetext and the labeled temporal relations.
We employmethods from syntactic dependency parsing, adapt-ing them to our task by including features typical oftemporal relation labeling models.3 Corpus AnnotationThe corpus of stories for children was drawn from thefables collection of (McIntyre and Lapata, 2009)1 andannotated as described in (Bethard et al, 2012).
Inthis section we illustrate the main annotation princi-ples for coherent temporal annotation.
As an examplestory, consider:Two Travellers were on the road together,when a Bear suddenly appeared on thescene.
Before he observed them, one madefor a tree at the side of the road, andclimbed up into the branches and hid there.The other was not so nimble as his compan-ion; and, as he could not escape, he threwhimself on the ground and pretended to bedead.
.
.
[37.txt]Figure 1 shows the temporal dependency structurethat we expect our annotators to identify in this story.The annotators were provided with guidelines bothfor which kinds of words should be identified asevents, and for which kinds of events should belinked by temporal relations.
For identifying eventwords, the standard TimeML guidelines for anno-tating events (Pustejovsky et al, 2003a) were aug-mented with two additional guidelines:1Data available at http://homepages.inf.ed.ac.uk/s0233364/McIntyreLapata09/89Figure 1: Event timeline for the story of the Travellers and the Bear.
Nodes are events and edges are temporal relations.Edges denote temporal relations signaled by linguistic cues in the text.
Temporal relations that can be inferred viatransitivity are not shown.?
Skip negated, modal or hypothetical events (e.g.could not escape, dead in pretended to be dead).?
For phrasal events, select the single word thatbest paraphrases the meaning (e.g.
in used tosnap the event should be snap, in kept perfectlystill the event should be still).For identifying the temporal dependencies (i.e.
theordering relations between event words), the anno-tators were instructed to link each event in the storyto a single nearby event, similar to what has beenobserved in reading comprehension studies (Johnson-Laird, 1980; Brewer and Lichtenstein, 1982).
Whenthere were several reasonable nearby events to choosefrom, the annotators were instructed to choose thetemporal relation that was easiest to infer from thetext (e.g.
preferring relations with explicit cue wordslike before).
A set of six temporal relations was used:BEFORE, AFTER, INCLUDES, IS-INCLUDED, IDEN-TITY or OVERLAP.Two annotators annotated temporal dependencystructures in the first 100 fables of the McIntyre-Lapata collection and measured inter-annotator agree-ment by Krippendorff?s Alpha for nominal data (Krip-pendorff, 2004; Hayes and Krippendorff, 2007).
Forthe resulting annotated corpus annotators achievedAlpha of 0.856 on the event words, 0.822 on the linksbetween events, and of 0.700 on the ordering rela-tion labels.
Thus, we concluded that the temporaldependency annotation paradigm was reliable, andthe resulting corpus of 100 fables2 could be used to2Available from http://www.bethard.info/data/fables-100-temporal-dependency.xmltrain a temporal dependency parsing model.4 Parsing ModelsWe consider two different approaches to learning atemporal dependency parser: a shift-reduce model(Nivre, 2008) and a graph-based model (McDonaldet al, 2005).
Both models take as input a sequenceof event words and produce as output a tree structurewhere the events are linked via temporal relations.Formally, a parsing model is a function (W ?
?
)where W = w1w2 .
.
.
wn is a sequence of eventwords, and pi ?
?
is a dependency tree pi = (V,E)where:?
V = W ?
{Root}, that is, the vertex set of thegraph is the set of words in W plus an artificialroot node.?
E = {(wh, r, wd) : wh ?
V,wd ?
V, r ?
R ={BEFORE, AFTER, INCLUDES, IS INCLUDED,IDENTITY, OVERLAP}}, that is, in the edge setof the graph, each edge is a link between a de-pendent word and its head word, labeled with atemporal relation.?
(wh, r, wd) ?
E =?
wd 6= Root, that is, theartificial root node has no head.?
(wh, r, wd) ?
E =?
((w?h, r?, wd) ?
E =?wh = w?h?
r = r?
), that is, for every node thereis at most one head and one relation label.?
E contains no (non-empty) subset of arcs(wh, ri, wi), (wi, rj , wj), .
.
.
, (wk, rl, wh), thatis, there are no cycles in the graph.90SHIFT Move all of L2 and the head of Q onto L1([a1 .
.
.
ai], [b1 .
.
.
bj ], [wkwk+1 .
.
.
], E) ?
([a1 .
.
.
aib1 .
.
.
bjwk], [], [wk+1 .
.
.
], E)NO-ARC Move the head of L1 to the head of L2([a1 .
.
.
aiai+1], [b1 .
.
.
bj ], Q,E) ?
([a1 .
.
.
ai], [ai+1b1 .
.
.
bj ], Q,E)LEFT-ARC Create a relation where the head of L1 depends on the head of QNot applicable if ai+1 is the root or already has a head, or if there is a path connecting wk and ai+1([a1 .
.
.
aiai+1], [b1 .
.
.
bj ], [wk .
.
.
], E) ?
([a1 .
.
.
ai], [ai+1b1 .
.
.
bj ], [wk .
.
.
], E ?
(wk, r, ai+1)RIGHT-ARC Create a relation where the head of Q depends on the head of L1Not applicable if wk is the root or already has a head, or if there is a path connecting wk and ai+1([a1 .
.
.
aiai+1], [b1 .
.
.
bj ], [wk .
.
.
], E) ?
([a1 .
.
.
ai], [ai+1b1 .
.
.
bj ], [wk .
.
.
], E ?
(ai+1, r, wk)Table 1: Transition system for Covington-style shift-reduce dependency parsers.4.1 Shift-Reduce Parsing ModelShift-reduce dependency parsers start with an inputqueue of unlinked words, and link them into a treeby repeatedly choosing and performing actions likeshifting a node to a stack, or popping two nodes fromthe stack and linking them.
Shift-reduce parsers aretypically defined in terms of configurations and a tran-sition system, where the configurations describe thecurrent internal state of the parser, and the transitionsystem describes how to get from one state to another.Formally, a deterministic shift-reduce dependencyparser is defined as (C, T,CF , INIT, TREE) where:?
C is the set of possible parser configurations ci?
T ?
(C ?
C) is the set of transitions ti fromone configuration cj to another cj+1 allowed bythe parser?
INIT ?
(W ?
C) is a function from the inputwords to an initial parser configuration?
CF ?
C are the set of final parser configura-tions cF where the parser is allowed to terminate?
TREE ?
(CF ?
?)
is a function that extracts adependency tree pi from a final parser state cFGiven this formalism and an oracle o ?
(C ?
T ),which can choose a transition given the current con-figuration of the parser, dependency parsing can beaccomplished by Algorithm 1.
For temporal depen-dency parsing, we adopt the Covington set of transi-tions (Covington, 2001) as it allows for parsing thenon-projective trees, which may also contain ?cross-ing?
edges, that occasionally occur in our annotatedcorpus.
Our parser is therefore defined as:Algorithm 1 Deterministic parsing with an oracle.c?
INIT(W )while c /?
CF dot?
o(c)c?
t(c)end whilereturn TREE(c)?
c = (L1, L2, Q,E) is a parser configuration,where L1 and L2 are lists for temporary storage,Q is the queue of input words, and E is the setof identified edges of the dependency tree.?
T = {SHIFT,NO-ARC,LEFT-ARC,RIGHT-ARC}is the set of transitions described in Table 1.?
INIT(W ) = ([Root], [], [w1, w2, .
.
.
, wn], ?
)puts all input words on the queue and the ar-tificial root on L1.?
CF = {(L1, L2, Q,E) ?
C : L1 = {W ?
{Root}}, L2 = Q = ?}
accepts final stateswhere the input words have been moved off ofthe queue and lists and into the edges in E.?
TREE((L1, L2, Q,E)) = (W ?
{Root}, E) ex-tracts the final dependency tree.The oracle o is typically defined as a machine learn-ing classifier, which characterizes a parser configu-ration c in terms of a set of features.
For temporaldependency parsing, we learn a Support Vector Ma-chine classifier (Yamada and Matsumoto, 2003) usingthe features described in Section 5.4.2 Graph-Based Parsing ModelOne shortcoming of the shift-reduce dependencyparsing approach is that each transition decision91Figure 2: A setting for the graph-based parsing model: an initial dense graph G (left) with edge scores SCORE(e).
Theresulting dependency tree as a spanning tree with the highest score over the edges (right).made by the model is final, and cannot be revisited tosearch for more globally optimal trees.
Graph-basedmodels are an alternative dependency parsing model,which assembles a graph with weighted edges be-tween all pairs of words, and selects the tree-shapedsubset of this graph that gives the highest total score(Fig.
2).
Formally, a graph-based parser followsAlgorithm 2, where:?
W ?
= W ?
{Root}?
SCORE ?
((W ?
?R?W ) ?
<) is a functionfor scoring edges?
SPANNINGTREE is a function for selecting asubset of edges that is a tree that spans over allthe nodes of the graph.Algorithm 2 Graph-based dependency parsingE ?
{(e, SCORE(e)) : e ?
(W ?
?R?W ))}G?
(W ?, E)return SPANNINGTREE(G)The SPANNINGTREE function is usually definedusing one of the efficient search techniques for find-ing a maximum spanning tree.
For temporal depen-dency parsing, we use the Chu-Liu-Edmonds algo-rithm (Chu and Liu, 1965; Edmonds, 1967) whichsolves this problem by iteratively selecting the edgewith the highest weight and removing edges thatwould create cycles.
The result is the globally op-timal maximum spanning tree for the graph (Geor-giadis, 2003).The SCORE function is typically defined as a ma-chine learning model that scores an edge based on aset of features.
For temporal dependency parsing, welearn a model to predict edge scores via the MarginInfused Relaxed Algorithm (MIRA) (Crammer andSinger, 2003; Crammer et al, 2006) using the set offeatures defined in Section 5.5 Feature DesignThe proposed parsing algorithms both rely on ma-chine learning methods.
The shift-reduce parser(SRP) trains a machine learning classifier as the or-acle o ?
(C ?
T ) to predict a transition t from aparser configuration c = (L1, L2, Q,E), using nodefeatures such as the heads of L1, L2 and Q, andedge features from the already predicted temporalrelations in E. The graph-based maximum spanningtree (MST) parser trains a machine learning modelto predict SCORE(e) for an edge e = (wi, rj , wk),using features of the nodes wi and wk.
The full setof features proposed for both parsing models, de-rived from the state-of-the-art systems for temporalrelation labeling, is presented in Table 2.
Note thatboth models share features that look at the nodes,while only the shift-reduce parser has features forpreviously classified edges.6 EvaluationsEvaluations were performed using 10-fold cross-validation on the fables annotated in Section 3.
Thecorpus contains 100 fables, a total of 14,279 tokensand a total of 1136 annotated temporal relations.
As92Feature SRP MSTWord??
??Lemma??
?
?Part of speech (POS) tag??
??Suffixes??
?
?Syntactically governing verb??
?
?Governing verb lemma??
?
?Governing verb POS tag??
?
?Governing verb POS suffixes??
?
?Prepositional phrase occurrence??
?
?Dominated by auxiliary verb???
?
?Dominated by modal verb???
?
?Temporal signal word is nearby???
?
?Head word lemma??
?
?Temporal relation labels of ai and itsleftmost and rightmost dependents?Temporal relation labels of ai?1?sleftmost and rightmost dependents?Temporal relation labels of b1 and itsleftmost and rightmost dependents?Table 2: Features for the shift-reduce parser (SRP) and thegraph-based maximum spanning tree (MST) parser.
The??
features are extracted from the heads of L1, L2 and Qfor SRP and from each node of the edge for MST.only 40 instances of OVERLAP relations were an-notated when neither INCLUDES nor IS INCLUDEDlabel matched, for evaluation purposes all instancesof these relations were merged into the temporallycoarse OVERLAP relation.
Thus, the total number ofOVERLAP relations in the corpus grew from 40 to258 annotations in total.To evaluate the parsing models (SRP and MST)we proposed two baselines.
Both are based on theassumption of linear temporal structures of narrativesas the temporal ordering process that was evidencedby studies in human text rewriting (Hickmann, 2003).The proposed baselines are:?
LinearSeq: A model that assumes all eventsoccur in the order they are written, adding linksbetween each pair of adjacent events, and label-ing all links with the relation BEFORE.?
ClassifySeq: A model that links each pair ofadjacent events, but trains a pair-wise classifierto predict the relation label for each pair.
Theclassifier is a support vector machine trained us-ing the same features as the MST parser.
This isan approximation of prior work, where the pairsof events to classify with a temporal relationwere given as an input to the system.
(Note thatSection 6.2 will show that for our corpus, apply-ing the model only to adjacent pairs of eventsis quite competitive for just getting the basicunlabeled link structure right.
)The Shift-Reduce parser (SRP; Section 4.1) and thegraph-based, maximum spanning tree parser (MST;Section 4.2) are compared to these baselines.6.1 Evaluation Criteria and MetricsModel performance was evaluated using standardevaluation criteria for parser evaluations:Unlabeled Attachment Score (UAS) The fractionof events whose head events were correctly predicted.This measures whether the correct pairs of eventswere linked, but not if they were linked by the correctrelations.Labeled Attachment Score (LAS) The fractionof events whose head events were correctly pre-dicted with the correct relations.
This measures bothwhether the correct pairs of events were linked andwhether their temporal ordering is correct.Tree Edit Distance In addition to the UAS andLAS the tree edit distance score has been recently in-troduced for evaluating dependency structures (Tsar-faty et al, 2011).
The tree edit distance scorefor a tree pi is based on the following operations?
?
?
: ?
= {DELETE, INSERT, RELABEL}:?
?
=DELETE delete a non-root node v in pi withparent u, making the children of v the childrenof u, inserted in the place of v as a subsequencein the left-to-right order of the children of u.?
?
=INSERT insert a node v as a child of u inpi making it the parent of a consecutive subse-quence of the children of u.?
?
=RELABEL change the label of node v in piAny two trees pi1 and pi2 can be turned one into an-other by a sequence of edit operations {?1, ..., ?n}.93UAS LAS UTEDS LTEDSLinearSeq 0.830 0.581 0.689 0.549ClassifySeq 0.830 0.581 0.689 0.549MST 0.837 0.614?
0.710 0.571SRP 0.830 0.647??
0.712 0.596?Table 3: Performance levels of temporal structure pars-ing methods.
A ?
indicates that the model outperformsLinearSeq and ClassifiedSeq at p < 0.01 and a ?
indicatesthat the model outperforms MST at p < 0.05.Taking the shortest such sequence, the tree edit dis-tance is calculated as the sum of the edit operationcosts divided by the size of the tree (i.e.
the numberof words in the sentence).
For temporal dependencytrees, we assume each operation costs 1.0.
The fi-nal score subtracts the edit distance from 1 so thata perfect tree has score 1.0.
The labeled tree editdistance score (LTEDS) calculates sequences overthe tree with all its labeled temporal relations, whilethe unlabeled tree edit distance score (UTEDS) treatsall edges as if they had the same label.6.2 ResultsTable 3 shows the results of the evaluation.
Theunlabeled attachment score for the LinearSeq base-line was 0.830, suggesting that annotators were mostoften linking adjacent events.
At the same time,the labeled attachment score was 0.581, indicatingthat even in fables, the stories are not simply linear,that is, there are many relations other than BEFORE.The ClassifySeq baseline performs identically to theLinearSeq baseline, which shows that the simple pair-wise classifier was unable to learn anything beyondpredicting all relations as BEFORE.In terms of labeled attachment score, both de-pendency parsing models outperformed the base-line models ?
the maximum spanning tree parserachieved 0.614 LAS, and the shift-reduce parserachieved 0.647 LAS.
The shift-reduce parser alsooutperformed the baseline models in terms of labeledtree edit distance, achieving 0.596 LTEDS vs. thebaseline 0.549 LTEDS.
These results indicate that de-pendency parsing models are a good fit to our whole-story timeline extraction task.Finally, in comparing the two different depen-dency parsing models, we observe that the shift-reduce parser outperforms the maximum spanningError Type Num.
%OVERLAP?
BEFORE 24 43.7Attach to further head 18 32.7Attach to nearer head 6 11.0Other types of errors 7 12.6Total 55 100Table 4: Error distribution from the analysis of 55 errorsof the Shift-Reduce parsing model.tree parser in terms of labeled attachment score(0.647 vs. 0.614).
It has been argued that graph-based models like the maximum spanning tree parsershould be able to produce more globally consistentand correct dependency trees, yet we do not observethat here.
A likely explanation for this phenomenonis that the shift-reduce parsing model allows for fea-tures describing previous parse decisions (similar tothe incremental nature of human parse decisions),while the joint nature of the maximum spanning treeparser does not.6.3 Error AnalysisTo better understand the errors our model is still mak-ing, we examined two folds (55 errors in total in20% of the evaluation data) and identified the majorcategories of errors:?
OVERLAP?
BEFORE: The model predicts thecorrect head, but predicts its label as BEFORE,while the correct label is OVERLAP.?
Attach to further head: The model predictsthe wrong head, and predicts as the head anevent that is further away than the true head.?
Attach to nearer head: The model predicts thewrong head, and predicts as the head an eventthat is closer than the true head.Table 4 shows the distribution of the errors over thesecategories.
The two most common types of errors,OVERLAP ?
BEFORE and Attach to further head,account for 76.4% of all the errors.The most common type of error is predictinga BEFORE relation when the correct answer is anOVERLAP relation.
Figure 3 shows an example ofsuch an error, where the model predicts that theSpendthrift stood before he saw, while the anno-tator indicates that the seeing happened during the94Figure 3: An OVERLAP ?
BEFORE parser error.
Truelinks are solid lines; the parser error is the dotted line.Figure 4: Parser errors attaching to further away heads.True links are solid lines; parser errors are dotted lines.time in which he was standing.
An analysis of theseOVERLAP?
BEFORE errors suggests that they occurin scenarios like this one, where the duration of oneevent is significantly longer than the duration of an-other, but there are no direct cues for these durationdifferences.
We also observe these types of errorswhen one event has many sub-events, and thereforethe duration of the main event typically includes thedurations of all the sub-events.
It might be possibleto address these kinds of errors by incorporating auto-matically extracted event duration information (Panet al, 2006; Gusev et al, 2011).The second most common error type of the modelis the prediction of a head event that is further awaythan the head identified by the annotators.
Figure 4gives an example of such an error, where the modelpredicts that the gathering includes the smarting, in-stead of that the gathering includes the stung.
Thesecond error in the figure is also of the same type.In 65% of the cases where this type of error occurs,it occurs after the parser had already made a labelclassification error such as BEFORE ?
OVERLAP.So these errors may be in part due to the sequen-tial nature of shift-reduce parsing, where early errorspropagate and cause later errors.7 Discussion and ConclusionsIn this article, we have presented an approach to tem-poral information extraction that represents the time-line of a story as a temporal dependency tree.
Wehave constructed an evaluation corpus where suchtemporal dependencies have been annotated over aset of 100 children?s stories.
We have introduced twodependency parsing techniques for extracting storytimelines and have shown that both outperform a rule-based baseline and a prior-work-inspired pair-wiseclassification baseline.
Comparing the two depen-dency parsing models, we have found that a shift-reduce parser, which more closely mirrors the incre-mental processing of our human annotators, outper-forms a graph-based maximum spanning tree parser.Our error analysis of the shift-reduce parser revealedthat being able to estimate differences in event dura-tions may play a key role in improving parse quality.We have focused on children?s stories in this study,in part because they typically have simpler temporalstructures (though not so simple that our rule-basedbaseline could parse them accurately).
In most of ourfables, there were only one or two characters with atmost one or two simultaneous sequences of actions.In other domains, the timeline of a text is likely tobe more complex.
For example, in clinical records,descriptions of patients may jump back and forthbetween the patient history, the current examination,and procedures that have not yet happened.In future work, we plan to investigate how to bestapply the dependency structure approach to suchdomains.
One approach might be to first groupevents into their narrative containers (Pustejovskyand Stubbs, 2011), for example, grouping together allevents linked to the time of a patient?s examination.Then within each narrative container, our dependencyparsing approach could be applied.
Another approachmight be to join the individual timeline trees into adocument-wide tree via discourse relations or rela-tions to the document creation time.
Work on howhumans incrementally process such timelines in textmay help to decide which of these approaches holdsthe most promise.AcknowledgementsWe would like to thank the anonymous reviewersfor their constructive comments.
This research waspartially funded by the TERENCE project (EU FP7-257410) and the PARIS project (IWT SBO 110067).95References[Amigo?
et al2011] Enrique Amigo?, Javier Artiles, Qi Li,and Heng Ji.
2011.
An evaluation framework for aggre-gated temporal information extraction.
In SIGIR-2011Workshop on Entity-Oriented Search.
[Artiles et al2011] Javier Artiles, Qi Li, Taylor Cas-sidy, Suzanne Tamang, and Heng Ji.
2011.CUNY BLENDER TAC-KBP2011 temporal slot fill-ing system description.
In Text Analytics Conference(TAC2011).
[Bethard and Martin2007] Steven Bethard and James H.Martin.
2007.
CU-TMP: Temporal relation classifica-tion using syntactic and semantic features.
In Proceed-ings of the Fourth International Workshop on SemanticEvaluations (SemEval-2007), pages 129?132, Prague,Czech Republic, June.
ACL.
[Bethard et al2007] Steven Bethard, James H. Martin, andSara Klingenstein.
2007.
Finding temporal structure intext: Machine learning of syntactic temporal relations.International Journal of Semantic Computing (IJSC),1(4):441?458, 12.
[Bethard et al2012] Steven Bethard, OleksandrKolomiyets, and Marie-Francine Moens.
2012.Annotating narrative timelines as temporal dependencystructures.
In Proceedings of the InternationalConference on Linguistic Resources and Evaluation,Istanbul, Turkey, May.
ELRA.
[Boguraev and Ando2005] Branimir Boguraev andRie Kubota Ando.
2005.
TimeBank-driven TimeMLanalysis.
In Annotating, Extracting and Reasoningabout Time and Events.
Springer.
[Bramsen et al2006] P. Bramsen, P. Deshpande, Y.K.
Lee,and R. Barzilay.
2006.
Inducing temporal graphs.In Proceedings of the 2006 Conference on EmpiricalMethods in Natural Language Processing, pages 189?198.
ACL.
[Brewer and Lichtenstein1982] William F. Brewer and Ed-ward H. Lichtenstein.
1982.
Stories are to entertain: Astructural-affect theory of stories.
Journal of Pragmat-ics, 6(5-6):473 ?
486.
[Chambers and Jurafsky2008] N. Chambers and D. Juraf-sky.
2008.
Jointly combining implicit constraints im-proves temporal ordering.
In Proceedings of the Con-ference on Empirical Methods in Natural LanguageProcessing, pages 698?706.
ACL.
[Cheng et al2007] Yuchang Cheng, Masayuki Asahara,and Yuji Matsumoto.
2007.
NAIST.Japan: Tempo-ral relation identification using dependency parsed tree.In Proceedings of the Fourth International Workshop onSemantic Evaluations (SemEval-2007), pages 245?248,Prague, Czech Republic, June.
ACL.
[Chu and Liu1965] Y. J. Chu and T.H.
Liu.
1965.
Onthe shortest arborescence of a directed graph.
ScienceSinica, pages 1396?1400.
[Covington2001] M.A.
Covington.
2001.
A fundamentalalgorithm for dependency parsing.
In Proceedings ofthe 39th Annual ACM Southeast Conference, pages95?102.
[Crammer and Singer2003] K. Crammer and Y. Singer.2003.
Ultraconservative online algorithms for multi-class problems.
Journal of Machine Learning Research,3:951?991.
[Crammer et al2006] K. Crammer, O. Dekel, J. Keshet,S.
Shalev-Shwartz, and Y.
Singer.
2006.
Onlinepassive-aggressive algorithms.
Journal of MachineLearning Research, 7:551?585.
[Edmonds1967] J. Edmonds.
1967.
Optimum branchings.Journal of Research of the National Bureau of Stan-dards, pages 233?240.
[Georgiadis2003] L. Georgiadis.
2003.
Arborescence op-timization problems solvable by Edmonds?
algorithm.Theoretical Computer Science, 301(1-3):427?437.
[Gupta and Ji2009] Prashant Gupta and Heng Ji.
2009.Predicting unknown time arguments based on cross-event propagation.
In Proceedings of the ACL-IJCNLP2009 Conference Short Papers, ACLShort ?09, pages369?372, Stroudsburg, PA, USA.
ACL.
[Gusev et al2011] Andrey Gusev, Nathanael Chambers,Divye Raj Khilnani, Pranav Khaitan, Steven Bethard,and Dan Jurafsky.
2011.
Using query patterns to learnthe duration of events.
In Proceedings of the Interna-tional Conference on Computational Semantics, pages145?154.
[Hayes and Krippendorff2007] A.F.
Hayes and K. Krip-pendorff.
2007.
Answering the call for a standardreliability measure for coding data.
CommunicationMethods and Measures, 1(1):77?89.
[Hickmann2003] Maya Hickmann.
2003.
Children?s Dis-course: Person, Space and Time Across Languages.Cambridge University Press, Cambridge, UK.
[Johnson-Laird1980] P.N.
Johnson-Laird.
1980.
Men-tal models in cognitive science.
Cognitive Science,4(1):71?115.
[Krippendorff2004] K. Krippendorff.
2004.
Content anal-ysis: An introduction to its methodology.
Sage Publica-tions, Inc.[Linguistic Data Consortium2005] Linguistic Data Con-sortium.
2005.
ACE (Automatic Content Extraction)English annotation guidelines for events version 5.4.32005.07.01.
[Llorens et al2010] Hector Llorens, Estela Saquete, andBorja Navarro.
2010.
TIPSem (English and Spanish):Evaluating CRFs and semantic roles in TempEval-2.
InProceedings of the 5th International Workshop on Se-mantic Evaluation, pages 284?291, Uppsala, Sweden,July.
ACL.96[McDonald et al2005] R. McDonald, F. Pereira, K. Rib-arov, and J. Hajic?.
2005.
Non-projective dependencyparsing using spanning tree algorithms.
In Proceedingsof the Conference on Human Language Technology andEmpirical Methods in Natural Language Processing,pages 523?530.
ACL.
[McIntyre and Lapata2009] N. McIntyre and M. Lapata.2009.
Learning to tell tales: A data-driven approach tostory generation.
In Proceedings of the Joint Confer-ence of the 47th Annual Meeting of the ACL and the 4thInternational Joint Conference on Natural LanguageProcessing of the AFNLP: Volume 1-Volume 1, pages217?225.
ACL.
[Nivre2008] J. Nivre.
2008.
Algorithms for determinis-tic incremental dependency parsing.
ComputationalLinguistics, 34(4):513?553.
[Pan et al2006] Feng Pan, Rutu Mulkar, and Jerry R.Hobbs.
2006.
Learning event durations from eventdescriptions.
In Proceedings of the 21st InternationalConference on Computational Linguistics and 44th An-nual Meeting of the Association for Computational Lin-guistics, pages 393?400, Sydney, Australia, July.
ACL.
[Pustejovsky and Stubbs2011] J. Pustejovsky andA.
Stubbs.
2011.
Increasing informativeness intemporal annotation.
In Proceedings of the 5thLinguistic Annotation Workshop, pages 152?160.
ACL.
[Pustejovsky et al2003a] James Pustejovsky, Jose?Castan?o, Robert Ingria, Roser Saury?, RobertGaizauskas, Andrea Setzer, and Graham Katz.
2003a.TimeML: Robust specification of event and temporalexpressions in text.
In Proceedings of the FifthInternational Workshop on Computational Semantics(IWCS-5), Tilburg.
[Pustejovsky et al2003b] James Pustejovsky, PatrickHanks, Roser Saury?, Andrew See, Robert Gaizauskas,Andrea Setzer, Dragomir Radev, Beth Sundheim,David Day, Lisa Ferro, and Marcia Lazo.
2003b.The TimeBank corpus.
In Proceedings of CorpusLinguistics, pages 647?656.
[Tsarfaty et al2011] R. Tsarfaty, J. Nivre, and E. Ander-sson.
2011.
Evaluating dependency parsing: Robustand heuristics-free cross-annotation evaluation.
In Pro-ceedings of the Conference on Empirical Methods inNatural Language Processing, pages 385?396.
ACL.
[UzZaman and Allen2010] Naushad UzZaman and JamesAllen.
2010.
TRIPS and TRIOS system for TempEval-2: Extracting temporal information from text.
In Pro-ceedings of the 5th International Workshop on Seman-tic Evaluation, pages 276?283, Uppsala, Sweden, July.ACL.
[Verhagen et al2007] Marc Verhagen, Robert Gaizauskas,Frank Schilder, Graham Katz, and James Pustejovsky.2007.
SemEval2007 Task 15: TempEval temporal rela-tion identification.
In SemEval-2007: 4th InternationalWorkshop on Semantic Evaluations.
[Verhagen et al2010] Marc Verhagen, Roser Saur?
?, Tom-maso Caselli, and James Pustejovsky.
2010.
SemEval-2010 Task 13: TempEval-2.
In Proceedings of the 5thInternational Workshop on Semantic Evaluation, Se-mEval ?10, pages 57?62, Stroudsburg, PA, USA.
ACL.
[Yamada and Matsumoto2003] H. Yamada and Y. Mat-sumoto.
2003.
Statistical dependency analysis withsupport vector machines.
In Proceedings of IWPT.
[Yoshikawa et al2009] K. Yoshikawa, S. Riedel, M. Asa-hara, and Y. Matsumoto.
2009.
Jointly identifyingtemporal relations with Markov Logic.
In Proceedingsof the Joint Conference of the 47th Annual Meeting ofthe ACL and the 4th International Joint Conferenceon Natural Language Processing of the AFNLP, pages405?413.
ACL.97
