Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 1302?1310, Dublin, Ireland, August 23-29 2014.Unsupervised Word Sense Induction using Distributional StatisticsKartik GoyalCarnegie Mellon Uniersitykartikgo@cs.cmu.eduEduard HovyCarnegie Mellon Universityhovy@cmu.eduAbstractWord sense induction is an unsupervised task to find and characterize different senses of polyse-mous words.
This work investigates two unsupervised approaches that focus on using distribu-tional word statistics to cluster the contextual information of the target words using two differentalgorithms involving latent dirichlet allocation and spectral clustering.
Using a large corpus forachieving this task, we quantitatively analyze our clusters on the Semeval-2010 dataset and alsoperform a qualitative analysis of our induced senses.
Our results indicate that our methods suc-cessfully characterized the senses of the target words and were also able to find unconventionalsenses for those words.1 IntroductionWord Sense Induction (WSI) involves automatically determining the number of senses of a given wordor a phrase and identifying the features which differentiate those senses.
This task, although similarto the Word Sense Disambiguation (WSD) task, is fundamentally different because it does not involveany supervision or explicit human knowledge about senses of words.
WSI has potential to be extremelyuseful in downstream applications because, apart from the savings on annotation costs, it also mitigatesseveral theoretical conflicts associated with supervised WSD tasks, which generally involve deciding onthe granularity of senses.
Ideally, a WSI algorithm would be able to adapt to different tasks requiringdifferent sense granularities.
WSI algorithms can also be used to model the evolution of the senses ofa word with time and hence can be much easier to maintain than existing fixed sense inventories likeWordNet(Miller, 1995), Ontonotes(Hovy et al., 2006) etc.
Automatic sense identification systems alsohave the potential to generalize well to large amounts of diverse data and hence be useful in variousdifficult domain independent tasks such as machine translation and information retrieval.Several factors make the problem of word sense induction very challenging.
Most importantly, it is notclear what should be the ?true?
senses of a word.
The semantic continuum makes it always possible tobreak a sense into finer grained subsenses.
Thus, the problem is one of finding the optimal granularityfor any given task.
Even in a semi-supervised setting, it is unknown which sense inventories are mostsuited as starting points in a sense bootstrapping procedure.Our unsupervised approach relies heavily on the distributional statistics of words which occur in theproximity of the target words.
Hence, we first obtain the distributional statistics from a very large cor-pus to facilitate generalization and reliable estimation of different possible senses.
Then we use thesestatistics in a novel manner to obtain a representation for the senses of the target word.
In this paper, wediscus the performance of induced senses on the Semeval 2010 WSD/WSI(Manandhar et al., 2010) task.2 Related WorkMuch of the work on word sense induction has been quite recent following the Semeval tasks on WSIin 2007(Agirre and Soroa, 2007) and 2010, but the task was recognized much earlier and various semi-supervised and unsupervised efforts were directed towards the problem.Yarowsky (1995) proposed aThis work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/1302semi-supervised approach, which required humans to specify seed words for every ambiguous word andassumed one sense per discourse for an ambiguous word.
The unsupervised approaches mainly focuson clustering the instances of the target words in a corpus, using first-order vectors, second-order vec-tors (Purandare and Pedersen, 2004)(Sch?utze, 1998) etc.
Pantel and Lin (2002) used various syntacticand surface features for clustering the various occurences of a target word.
Co-occurence graph-basedapproaches(V?eronis, 2004) have also been used, which represent the words co-occuring with the tar-get words as nodes and then identify the highly dense subgraphs or ?hubs?
within this co-occurencegraph.
Brody and Lapata (2009) and Lau et al.
(2012) proposed bayesian WSI systems which clusterthe instances by applying Latent Dirichlet Allocation (LDA)(Blei et al., 2003), Hierarchical DirichletProcesses (HDP)(Teh et al., 2006) etc.
wherein each occurence of a target word is represented as a ?doc-ument?
and its surrounding context as the ?observable content?.
Choe and Charniak (2013) propose a?naive bayes?
model for WSI which assumes one sense per discourse and uses Expectation Maximiza-tion(EM) to estimate model parameters like the probability of generating an instance feature like a wordin the context, given the sense of the target word in a particular instance.
Reisinger and Mooney (2010)and Huang et al.
(2012) have proposed sense dependent multiple prototypes for a word instead of theconventional one vector representation per word and have shown that this sense differentiation improvessemantic similarity measurements between words.3 Basic Motivation: Co-occurence graphsConventionally, each word is represented as a co-occurence vector which may contain frequency, pointwise mutual information or some lower dimensional representation of context and this representationconflates all the senses of a word.
These vectors can be viewed as a graph where words are nodeswhich have an edge between them if a word occurs in the distributional vector of another.
Given a targetambiguous word w, we refer to those words as the ?first order?
words(referred to by ?neighbors?)
whichare directly connected to w. The ?second order?
words are the words directly connected to the first orderwords and so on.
This graph is cyclic and each node might have multiple senses conflated into it.
In thiswork, we only consider the first and second order words, eg.
a target word like ?bank?
will have wordslike ?river?
,?money?
etc in it?s first order and the second order vectors will be the words from the contextof the first order words like ?river?:?flood?,?plains?
etc, ?money?
: ?currency?, ?economy?
etc.
Essentially,these second order words characterize the first order words and hence are very informative for clusteringthe first order words into different senses.
Essentially, we use the second order words as features ofthe first order words and use them to cluster the first order words into different senses.It must be notedthat the first order words themselves might have multiple senses and ideally, those words should also bedisambiguated but in the current work we only focus on disambiguating the ?target?
words.4 MethodologyFor clustering the neighbors of the target words, we implement and compare two methods which differsignificantly in their technical details and employ distribtutional statistics of the neighbors differently,which we describe in the sections below.
For obtaining the distributional statistics on a large scale, weused the 5-gram data of Google N-gram corpus(Michel et al., 2011) which effectively lets us use as 10word window.
No lemmatization or case normalization was performed because the large corpus sizeameliorated the problem of sparseness.
Only nouns, verbs, adjectives and adverbs were employed for thestatistical estimation because our pilot studies suggested that these words were most informative.4.1 Latent Dirichlet AllocationLDA(Blei et al., 2003) is a well known bayesian generative topic model which models every ?document?as a mixture of latent ?topics?
and all its ?words?
as multinomial draws from those latent topics.
In topicmodel parlance, a ?corpus?
consists of various ?documents?.
Each ?document?
has a collection of tokenswhich is treated like a bag of words, where each word is drawn from a latent ?topic?.
The topics areshared across documents thus giving each document a topic proportion based upon the topic assignmentof the tokens in a document.
The priors on topic proportions and the topic multimonial paramers are1303dirichlet parameters.
An important characteristic of LDA is its clustering property which makes themodel inclined to enforce sparseness with small dirichlet priors.It is important to note that we employ LDA in a significantly different manner than the previous ap-proaches which have used LDA or other related topic models for word sense induction.
Other topicmodelling based approaches for WSI represent each instance of the target word as a ?document?
and theimmediate context as the ?bag of words?
for that ?document?.
Unlike these approaches, we represented atarget ambiguous word as the ?corpus?
in the topic modelling parlance.
Then we found out all the ?firstorder?
words co-occuring with the target word within a 10 word window.
Each ?first order?
word/typeis considered a ?document?
in our LDA based approach.
The latent ?topics?
for each ?document?
arethe latent ?senses?
and each first order type comprises of a ?sense distribution?
which is indicative ofits tendency to induce a particular sense in the target word.
The ?second order?
types are all the wordsoccuring in a 10 word window of every ?first order?
word.
These types along with their frequency, formthe ?bag of words?
for the ?first order?
type(LDA document).
Hence, in our model, the latent senses areshared across all the first order neighbors of the target word and the second order tokens play the roleof ?words?
in our LDA based model.
After getting the sense distributions for each first order type, weperform k-means over all the sense distribution vectors such that every first order neighbor gets assigneda cluster.We posit that the distributional statistics of a large corpus helps in improving the coverage of second or-Figure 1: Figure1: s is the latent sense variable.
?
is the sense distribution of a first order neighbor.
w isa second order neighbor of a first order word.
?
is the sense multinomial with a dirichlet prior ?.
?
is adirichlet prior on the sense proportion of a first order type.der words which are essential for reliable clustering of the first order words.
However, the large numberof occurences and a large vocabulary make it intractable to run LDA using the original frequency of thesecond order words.
To overcome this computational hurdle, we posit that with a diverse representationof the second order words, LDA based parameter estimation relies more upon the relative distribution ofthe these words across all the first order words rather than their actual distributions.
Hence, we decided toscale down the actual counts for each word so that we could run LDA with the finite resources available.An important parameter in this model is the number of latent topics/senses to use, which is specified tobe the actual number of senses specified in the Ontonotes sense inventory.
This is an idealized case inwhich the number of senses are known.
The ?
hyperparameter is chosen to be small with respect to theaverage ?document lengths?
we encounter.
This has the effect of pushing most of the probabilistic weightto one topics instead of diluting it among many topics.
We also decided to analyze the effect of part ofspeech tags of the second order words in clustering the first order words.
The various configurations weexperimented with were:?
All: Considered nouns,verbs,adjectives and adverbs in second order bag of words.?
Nouns: Only considered second order words which were nouns to study the effect of Nouns onclustering.?
Verbs: Only considered second order words which were verbs.1304?
Nadj: Considered both nouns and adjectives to study the effect of Noun phrases over clustering.?
Vadv: Considered both verbs and adjectives for second order bag of words.4.2 Spectral ClusteringSpectral Clustering(Ng et al., 2002) is a clustering technique which uses a pairwise similarity matrix,L, to find out clusters such that the seperation between the entities in two seperate clusters is maximumwhile implicitly taking into account the distances between groups of points instead of considering themindividually.
The aim is to find the eigenvectors of D?1L corresponding to smallest eigenvalues tominimize the similarity across two clusters.
Here D is a diagonal matrix with degree of node i on entryDii.
For k clusters, k eigenvectors ordered by their eigenvalues are found out.
These k eigenvectors areused to form a n?
k matrix where n is the number of datapoints.
Each row of this matrix is considereda datapoint with a vector of length k, thus effectively reducing the dimension of the datapoints to k mostprominent dimensions according to the similarity matrix decomposition.
Finally, k-means is performedon the n vectors to assign a cluster to each datapoint.We cluster the first order neighbors for each target word using spectral clustering.
The crux of thisalgorithm lies in using appropriate pairwise distance matrices.
For constructing the pairwise distancematrices of first order types, we used two vectorial representations of the first order words:?
Senna embeddings: The word embeddings trained by a neural network by (Weston et al., 2012)?
Distributional vectors comprised of the frequencies of the second order words.Then we used these vectors to calculate mutual pairwise distance matrices(we experimented with Eu-clidean and Cosine distances), which were converted into similarity matrices by using Gaussian kernels.These matrices were used as input to the spectral clustering algorithm.We chose to ignore very low frequency words for making word vectors.
This cutoff was decided byanalyzing the distributional frequency vs. rank curves of the words, which were heavy tailed.
Again, weuse the same number of clusters as the number of senses in Ontonotes sense inventory, so that we canstudy the correspondence between our clusters and the Ontonotes senses.5 Quantitative AnalysisIn this paper, we discus our systems?
performances on the Semeval-2010 word sense induc-tion/disambiguation dataset, which contains 100 target words: 50 nouns and 50 verbs.
The test datais a part of OntoNotes (Hovy et al., 2006) and contains around 9000 instances of usage of the targetwords.
For annotating a particular test instance, we first filtered the surrounding context to retain onlysalient Nouns, Verbs, Adverbs, and Adjectives.
We report a mixture of senses for each instance, wherethe weight for each sense was proportional to the number of filtered surrounding words belonging to thatsense/cluster.
As mentioned earlier, we experimented with a variety of settings for spectral clusteringand LDA based methods.
The performance with different settings was generally similar and hence, wereport our best results here.
For a better insight into how our models in different settings performed, wealso report the full tables for paired F-score.
The performance trend of various systems is similar forother measures.
We compare our results to three baselines:?
Most Frequent Sense (MFS) baseline: assigns all the test instances to the most frequent sense of thetarget word.?
Brown University?s system results (Choe and Charniak, 2013).?
Lau (LDA) (Lau et al., 2012), who provide only the results for one of the three measures.
Inparticular, we compare our system to their results obtained by a model that was based on LDA andused the gold standard number of senses as the number of topics to be used.1305System V-measure Paired F-score Supervised F-score #clall nouns verbs all nouns verbs all nouns verbsLDA 4.4 5.2 3.2 60.7 53.2 71.7 60.9 55.2 69.2 2.45Spectral 4.5 4.6 4.2 61.5 54.5 71.6 60.7 55.1 68.8 1.87MFS 0.0 0.0 0.0 63.5 57.0 72.7 58.7 53.2 66.6 1.00Brown 18.0 23.7 9.9 52.9 52.5 53.5 65.4 62.6 69.5 3.42Lau - - - - - - 64.0 60.0 69.0 -Table 1: Performance on Paired F-score and supervised F-score.
LDA and Spectral are the two methodsproposed in this paper.
Lau is the baseline in which LDA system of (Lau et al., 2012) is considered.
Itshould be noted that in their paper, (Lau et al., 2012) did not report their performance on Paired F-score.The Semeval-2010 task provides us with 3 evaluation metrics: V-measure, Paired F-score and Super-vised F-score.
It was noticed (Manandhar and Klapaftis, 2009) that V-measure tends to favour systemsthat produce a higher number of clusters than the gold standard and hence is not a reliable estimate ofthe performance of WSI systems.
But, we report our results on V-measure too as it gives useful insightabout the nature of data and the WSI algorithms.It is important to note that all the measures treat Ontonotes sense annotations as the gold standard, whichmakes this task unfit for our evaluation purposes.
As mentioned earlier, our argument is that severaldecisions related to the granularity of senses and definition of senses are a topic of dispute, and hencewe believe that instead of relying upon a pre-annotated sense inventory, it should be more effective toinduce senses automatically in an unsupervised manner using a large and unbiased corpus, and tune thegranularity governing parameters for different downstream tasks which require sense disambiguation.But our performance on these annotations still provides us with valuable information about the agree-ment between Ontonotes senses and our systems?
senses.
In our experiments, we have not tried to tunethe hyperparameters or perform agglomerative clustering to better fit our clusters to the gold standardclusters by using training/development set at all, because we wanted to analyze the performance of ouralgorithms in the most general setting.5.1 V-MeasureThe V-measure defines the quality of a cluster to be the harmonic mean of homogeneity and coverage.These can be viewed as precision and recall of the element-wise assignment to clusters, where homo-geneity measures the ?pureness?
of the clusters and coverage measures the ?cohesiveness?.
It was noticed(Manandhar and Klapaftis, 2009) that V-measure tends to favour systems producing a higher number ofclusters than the gold standard and hence is not a reliable estimate of the performance of WSI systems.In addition, the number of induced clusters in our systems is bounded at the top by the Gold Standardnumber of senses because of our choice of hyperparameters in both spectral clustering and LDA basedapproaches.From the results, we realized that the number of senses induced in the test set by our system is quitelow compared to the baselines and other systems that participated in Semeval-2010.
This hurts our V-measure.
Our systems perform better on nouns than verbs generally according to this measure.
Also,LDA-based approaches with the number of topics equal to the number of gold-standard senses performthe best.
For spectral clustering, euclidean distances seem to perform better.5.2 Paired F-scoreThe paired F-score is the harmonic mean of precision and recall on the task of classifying whether theinstances in a pair belong to the same cluster or not.
This measure also penalizes the systems if thenumber of induced senses is not equal to the number of senses in the gold standard.
It must be noted thatin our approach, the induced number of senses on the test dataset is not equal to the original number ofsenses although we clustered with the number of clusters specified by Ontonotes, because our clustersare different from Ontonotes senses.
MFS has a recall of 100% which makes it a very hard baseline to1306P F-score(%) all nouns verbs #clCD20 60.5 53.1 71.3 2.12CD15 57.9 50.8 68.2 2.26CD10 58.5 50.7 69.7 2.27ED20 61.5 54.5 71.6 1.87ED15 60.6 53.1 71.5 2.12ED10 60.0 52.3 71.3 2.45CS15 59.6 52.9 69.4 2.25CS10 60.1 51.9 72.0 2.07ES15 59.8 52.9 71.3 2.15ES10 60.8 53.5 71.4 2.21MFS 63.5 57.0 72.7 1.00Brown 52.9 52.5 53.5 3.42Table 2: General trend for the various settings: Paired F-Score Evaluation: Spectral Clustering:?C?
:cosine distance, ?E?
: Euclidean Distance, ?D?
: Second order Distributinal counts, ?S?
:Senna em-beddings and the adjacent numbers are the number of nearest neighbors(in 1000s) considered for thedistance matrix.P F-score(%) all nouns verbs #clall 60.7 53.2 71.7 2.47noun 59.6 52.1 70.7 2.32verb 60.0 52.4 71.0 2.25nadj 59.7 52.6 70.1 2.3vadv 59.3 52.27 69.6 2.25MFS 63.5 57.0 72.7 1.00Brown 52.9 52.5 53.5 3.42Table 3: General trend for the various settings: Paired F-Score Evaluation: LDA: ?all?
: All POS tags con-sidered in the first order neighborhood, ?noun?
: Only nouns considere, ?verbs?
: Only verbs considered,?nadj?
: nouns and adjectives considered, ?vadv?
:verbs and adverbs consideredbeat.
Semeval-2010 results show that none of the systems outperform the MFS baseline.
Both of oursystems perform better than other systems on this measure and are comparable to the performance of theMFS baseline.5.3 Supervised F-scoreFor the supervised task, the test data is split into two parts: one for mapping the system senses to the goldstandard senses, and the other for evaluation based upon the mapped senses.
We report our performanceon the 80% mapping and 20% evaluation split.
The mapping is done automatically by the programprovided by the organizers which is based upon representing the gold standard clusters as a mixture ofthe system senses.Our different systems perform similarly on the supervised evaluation.
We outperform the tough MFSbaseline and perform competitively against other systems.
We observe that other systems outperform uson the target nouns whereas our performance on verbs is similar to that of other systems.
This can beattributed to the fact that our methods induce a small number of senses in general over the test set butaccording to the test data based upon Ontonotes, the senses of nouns have a much higher resolution thanverbs.5.4 Discussion on Quantitative ResultsIn general, we found our performance to be competetive with the other systems.
Also, we performsignificantly better than other Semeval-2010 systems on the paired F-score metric.
In our experiments,1307Sense Cluster Words1 Engineers,Presbyterian,Service,Jewish,Police,Ethnicity,Independent,Movements2 membrane,complicated,surgical,hypothalamic,potassium,lymphatic,electron,tumor3 Cynthia,Armstrong,Tracy,Marilyn,Stella,Abbot,Gustavus,Clark,Stewart,Monica4 heels,noses,haze,hand,drooping,galloped,nakedness,pallid,anguish,palms5 night,burdens,gut,assassins,witness,results,celestial,visual,deep,Hell6 lifted,hastily,hovering,guiding,sinner,tendency,developing,sacrificed,condemnedTable 4: Example words in the clusters of ?body.n?we found that for spectral clustering, Euclidean distances tend to perform better than Cosine distances.Also, the distributional counts of the second order words tend to perform better than Senna vectors whichis not surprising because the Senna vectors are trained with the philosophy of a language model, whichresults in words often being clustered according to their POS tags rather than their semantic closeness.Spectral methods, yield slightly better results on two metrics than LDA based clustering which suggeststhat similarity matrices give us a better idea about interactions between groups of words than simpleoccurence frequencies of the words.
But a bigger advantage of spectral clustering techniques is thespeed of computing SVD which is much better than that of slow inference algorithms of LDA basedmodels.For LDA based models, we also note that different settings focusing on different POS tags, performedvery similarly and did not indicate any strong preference for any POS tag for the task of WSI using LDA.Finally, both our methods tend to induce a small number of senses in the test data, which suggests thatthe induced senses are relatively coarse-grained.
Further splitting of coarse clusters using hierarchicalclustering methods might be helpful if a task requires finer-grained senses.6 Qualitative AnalysisIn this section, we present some deductions drawn from the qualitative analysis of clusters generated byour methods which support our hypothesis.
In particular, we discus the nature of clusters generated bythe spectral clustering algorithm using the second order distributional vectors for obtaining the similaritymatrix based on Euclidean distance.A preliminary analysis of cluster sizes revealed that in almost all the cases, one of the clusters was verylarge(about 3 times larger than the second largest cluster) and this largest cluster seemed to conflate alot of senses.
Other clusters were generally similar sized and most of them represented a sense of thetarget word on their own.
The results in general look very promising and many clusters can be easilyinterpreted as different senses of the target word.In Table 4, we show the top few words for the word ?body.n?.
Some senses very clearly representthemselves : 1.
Body as in organization, 2.
Biological terms related to body, 4.
Body in a more informalsense.
Sense 5 seems like a mixture of two senses of body, one related to celestial bodies and other relatedto dead bodies/murder.
Interestingly, sense 3 comprises proper nouns i.e.
people whose bodies have beenmentioned in the corpus.
This is not a conventional sense listed in any of the sense inventories but basedupon the requirements of a task, one might be interested in differentiating between general mentions of?bodies?
and mentions of ?bodies?
which appear when mentioning famous people or celebrities.
This sortof clustering can be incredibly useful in tasks like Machine Translation and Information Retreival whichrequire us to model semantics of rare words such as important proper nouns.7 Discussion and Future WorkWe used a large corpus and its distributional statistics to perform word sense induction for a set of 100target words.
We proposed two algorithms which cluster the salient words surrounding the target wordby using the distributions of surrounding words.
Both LDA based algorithm and the spectral clusteringalgorithm yielded similar clusters.
We believe that these clusters can be employed in downstream tasksand can be further broken into smaller fine grained clusters automatically if needed by the application.1308We also evaluated our clusters arising from the distributional statistics, in the Semeval-2010 tasks with-out any tuning and showed that they perform competetively with other approaches.We argue that treating existing sense inventories as gold standards for WSI tasks is not an appropriatemeasure for WSI systems because these inventories would not be able to measure two very importantcharacteristics of WSI systems which make them more advantageous than supervised WSD systems:a)coverage and b) discovery of new senses.Hence, the Semeval-2010 experiments are not an accurate reflection of the capabilities of WSI systemsbecause they rely on the Ontonotes sense inventory for the Gold Standard judgements, which are admittedeven by the OntoNotes builders to be only 85% reliable on average (Hovy et al., 2006).
Our competetiveperformance on these tasks show that our methods can be compliant with standard word sense disam-biguation tasks but more importantly, our qualitative analysis showed that our techniques can discovernew unconventional senses too, which might not be present in the sense inventories but could be veryuseful in tasks requiring differentiations.
Unfortunately, no metrics exist that can help us quantify thecoverage of senses and their novelty.
An ideal metric to evaluate the WSI systems in a better manner,would be their performance on extrinsic tasks like Machine Translation, Information Retreival, MachineReading etc., which require differentiation of senses at different granular levels.
WSI techniques havea potential of eliminating sense annotation costs hence enabling wider use of sense differentiation in amore generalized setting.Our techniques resulted in coarse-grained senses.
A major challenge in this task is to determine theappropriate number of senses to induce.
To overcome this problem, non-parametric methods could beconceived to identify the ideal number of clusters automatically.
In future, the WSI systems like ours canalso be used to analyze the evolution of senses over a period of time or geographical variation of senses.As mentioned earlier, the co-occurence graph consists of many canonical representation of words whichmust be split according to their different senses.
In our experiments, we considered a small number oftarget words and did not take into account the multiplicity of senses in the representation of ?first?
and?second?
order neighbors.
A more sophisticated iterative approach involving making several passes overa co-occurence graph and refining senses of different words in each pass can ameliorate the problem as-sociated with a single canonical representation of neighboring words.
Finally, designing extrinsic tasksto measure the efficacy of WSI systems will be extremely helpful in development of more robust anduseful WSI systems.AcknowledgmentsThis research was supported in part by DARPA grant FA8750-12-2-0342 funded under the DEFT pro-gram.ReferencesEneko Agirre and Aitor Soroa.
2007.
Semeval-2007 task 02: Evaluating word sense induction and discriminationsystems.
In Proceedings of the 4th International Workshop on Semantic Evaluations, pages 7?12.
Associationfor Computational Linguistics.David M Blei, Andrew Y Ng, and Michael I Jordan.
2003.
Latent dirichlet allocation.
the Journal of machineLearning research, 3:993?1022.Samuel Brody and Mirella Lapata.
2009.
Bayesian word sense induction.
In Proceedings of the 12th Conferenceof the European Chapter of the Association for Computational Linguistics, pages 103?111.
Association forComputational Linguistics.Do Kook Choe and Eugene Charniak.
2013.
Naive bayes word sense induction.
In EMNLP, pages 1433?1437.Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance Ramshaw, and Ralph Weischedel.
2006.
Ontonotes: the90% solution.
In Proceedings of the human language technology conference of the NAACL, Companion Volume:Short Papers, pages 57?60.
Association for Computational Linguistics.1309Eric H Huang, Richard Socher, Christopher D Manning, and Andrew Y Ng.
2012.
Improving word representationsvia global context and multiple word prototypes.
In Proceedings of the 50th Annual Meeting of the Associa-tion for Computational Linguistics: Long Papers-Volume 1, pages 873?882.
Association for ComputationalLinguistics.Jey Han Lau, Paul Cook, Diana McCarthy, David Newman, and Timothy Baldwin.
2012.
Word sense inductionfor novel sense detection.
In Proceedings of the 13th Conference of the European Chapter of the Associationfor Computational Linguistics, pages 591?601.
Association for Computational Linguistics.Suresh Manandhar and Ioannis P Klapaftis.
2009.
Semeval-2010 task 14: evaluation setting for word sense induc-tion & disambiguation systems.
In Proceedings of the Workshop on Semantic Evaluations: Recent Achievementsand Future Directions, pages 117?122.
Association for Computational Linguistics.Suresh Manandhar, Ioannis P Klapaftis, Dmitriy Dligach, and Sameer S Pradhan.
2010.
Semeval-2010 task14: Word sense induction & disambiguation.
In Proceedings of the 5th International Workshop on SemanticEvaluation, pages 63?68.
Association for Computational Linguistics.Jean-Baptiste Michel, Yuan Kui Shen, Aviva Presser Aiden, Adrian Veres, Matthew K Gray, Joseph P Pickett, DaleHoiberg, Dan Clancy, Peter Norvig, Jon Orwant, et al.
2011.
Quantitative analysis of culture using millions ofdigitized books.
science, 331(6014):176?182.George A Miller.
1995.
Wordnet: a lexical database for english.
Communications of the ACM, 38(11):39?41.Andrew Y Ng, Michael I Jordan, Yair Weiss, et al.
2002.
On spectral clustering: Analysis and an algorithm.Advances in neural information processing systems, 2:849?856.Patrick Pantel and Dekang Lin.
2002.
Discovering word senses from text.
In Proceedings of the eighth ACMSIGKDD international conference on Knowledge discovery and data mining, pages 613?619.
ACM.Amruta Purandare and Ted Pedersen.
2004.
Word sense discrimination by clustering contexts in vector andsimilarity spaces.
In Proceedings of the Conference on Computational Natural Language Learning, pages 41?48.
Boston.Joseph Reisinger and Raymond J Mooney.
2010.
Multi-prototype vector-space models of word meaning.
InHuman Language Technologies: The 2010 Annual Conference of the North American Chapter of the Associationfor Computational Linguistics, pages 109?117.
Association for Computational Linguistics.Hinrich Sch?utze.
1998.
Automatic word sense discrimination.
Computational linguistics, 24(1):97?123.Yee Whye Teh, Michael I Jordan, Matthew J Beal, and David M Blei.
2006.
Hierarchical dirichlet processes.Journal of the american statistical association, 101(476).Jean V?eronis.
2004.
Hyperlex: lexical cartography for information retrieval.
Computer Speech & Language,18(3):223?252.Jason Weston, Fr?ed?eric Ratle, Hossein Mobahi, and Ronan Collobert.
2012.
Deep learning via semi-supervisedembedding.
In Neural Networks: Tricks of the Trade, pages 639?655.
Springer.David Yarowsky.
1995.
Unsupervised word sense disambiguation rivaling supervised methods.
In Proceedingsof the 33rd annual meeting on Association for Computational Linguistics, pages 189?196.
Association forComputational Linguistics.1310
