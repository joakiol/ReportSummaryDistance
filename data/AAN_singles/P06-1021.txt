Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 161?168,Sydney, July 2006. c?2006 Association for Computational LinguisticsPCFGs with Syntactic and Prosodic Indicators of Speech RepairsJohn Halea Izhak Shafranb Lisa YungcBonnie Dorrd Mary Harperde Anna Krasnyanskayaf Matthew LeasegYang Liuh Brian Roarki Matthew Snoverd Robin Stewartja Michigan State University; b,c Johns Hopkins University; d University of Maryland, College Park; e Purdue Universityf UCLA; g Brown University; h University of Texas at Dallas; i Oregon Health & Sciences University; j Williams CollegeAbstractA grammatical method of combining twokinds of speech repair cues is presented.One cue, prosodic disjuncture, is detectedby a decision tree-based ensemble clas-sifier that uses acoustic cues to identifywhere normal prosody seems to be inter-rupted (Lickley, 1996).
The other cue,syntactic parallelism, codifies the expec-tation that repairs continue a syntacticcategory that was left unfinished in thereparandum (Levelt, 1983).
The two cuesare combined in a Treebank PCFG whosestates are split using a few simple treetransformations.
Parsing performance onthe Switchboard and Fisher corpora sug-gests that these two cues help to locatespeech repairs in a synergistic way.1 IntroductionSpeech repairs, as in example (1), are one kindof disfluent element that complicates any sortof syntax-sensitive processing of conversationalspeech.
(1) and [ the first kind of invasion of ] the firsttype of privacy seemed invaded to meThe problem is that the bracketed reparan-dum region (following the terminology of Shriberg(1994)) is approximately repeated as the speakerThe authors are very grateful for Eugene Charniak?s helpadapting his parser.
We also thank the Center for Languageand Speech processing at Johns Hopkins for hosting the sum-mer workshop where much of this work was done.
Thismaterial is based upon work supported by the National Sci-ence Foundation (NSF) under Grant No.
0121285.
Any opin-ions, findings and conclusions or recommendations expressedin this material are those of the authors and do not necessarilyreflect the views of the NSF.?repairs?
what he or she has already uttered.This extra material renders the entire utteranceungrammatical?the string would not be gener-ated by a correct grammar of fluent English.
Inparticular, attractive tools for natural languageunderstanding systems, such as Treebank gram-mars for written corpora, naturally lack appropri-ate rules for analyzing these constructions.One possible response to this mismatch be-tween grammatical resources and the brute factsof disfluent speech is to make one look morelike the other, for the purpose of parsing.
Inthis separate-processing approach, reparanda arelocated through a variety of acoustic, lexical orstring-based techniques, then excised before sub-mission to a parser (Stolcke and Shriberg, 1996;Heeman and Allen, 1999; Spilker et al, 2000;Johnson and Charniak, 2004).
The resultingparse tree then has the reparandum re-attached ina standardized way (Charniak and Johnson, 2001).An alternative strategy, adopted in this paper, isto use the same grammar to model fluent speech,disfluent speech, and their interleaving.Such an integrated approach can use syntac-tic properties of the reparandum itself.
For in-stance, in example (1) the reparandum is anunfinished noun phrase, the repair a finishednoun phrase.
This sort of phrasal correspon-dence, while not absolute, is strong in conver-sational speech, and cannot be exploited on theseparate-processing approach.
Section 3 appliesmetarules (Weischedel and Sondheimer, 1983;McKelvie, 1998a; Core and Schubert, 1999) inrecognizing these correspondences using standardcontext-free grammars.At the same time as it defies parsing, con-versational speech offers the possibility of lever-aging prosodic cues to speech repairs.
Sec-161Figure 1: The pause between two or s and the glottalization at the end of the first makes it easy for alistener to identify the repair.tion 2 describes a classifier that learns to labelprosodic breaks suggesting upcoming disfluency.These marks can be propagated up into parsetrees and used in a probabilistic context-free gram-mar (PCFG) whose states are systematically splitto encode the additional information.Section 4 reports results on Switchboard (God-frey et al, 1992) and Fisher EARS RT04F data,suggesting these two features can bring about in-dependent improvements in speech repair detec-tion.
Section 5 suggests underlying linguistic andstatistical reasons for these improvements.
Sec-tion 6 compares the proposed grammatical methodto other related work, including state of the artseparate-processing approaches.
Section 7 con-cludes by indicating a way that string- and tree-based approaches to reparandum identificationcould be combined.2 Prosodic disjunctureEveryday experience as well as acoustic anal-ysis suggests that the syntactic interruption inspeech repairs is typically accompanied by achange in prosody (Nakatani and Hirschberg,1994; Shriberg, 1994).
For instance, the spectro-gram corresponding to example (2), shown in Fig-ure 1,(2) the jehovah?s witness or [ or ] mormons orsomeonereveals a noticeable pause between the occurrenceof the two ors, and an unexpected glottalization atthe end of the first one.
Both kinds of cues havebeen advanced as explanations for human listen-ers?
ability to identify the reparandum even beforethe repair occurs.Retaining only the second explanation, Lickley(1996) proposes that there is no ?edit signal?
per sebut that repair is cued by the absence of smoothformant transitions and lack of normal juncturephenomena.One way to capture this notion in the syntaxis to enhance the input with a special disjunc-ture symbol.
This symbol can then be propa-gated in the grammar, as illustrated in Figure 2.This work uses a suffix ?+ to encode the percep-tion of abnormal prosody after a word, along withphrasal -BRK tags to decorate the path upwards toreparandum constituents labeled EDITED.
SuchNPNP EDITED CC NPNP NNP CC?BRK or NNPSDT NNP POS witnessthe jehovah ?sor~+ mormonsFigure 2: Propagating BRK, the evidence of dis-fluent juncture, from acoustics to syntax.disjuncture symbols are identified in the ToBI la-beling scheme as break indices (Price et al, 1991;Silverman et al, 1992).The availability of a corpus annotated withToBI labels makes it possible to design a breakindex classifier via supervised training.
The cor-pus is a subset of the Switchboard corpus, con-sisting of sixty-four telephone conversations man-ually annotated by an experienced linguist accord-ing to a simplified ToBI labeling scheme (Osten-dorf et al, 2001).
In ToBI, degree of disjunctureis indicated by integer values from 0 to 4, wherea value of 0 corresponds to clitic and 4 to a majorphrase break.
In addition, a suffix p denotes per-ceptually disfluent events reflecting, for example,162hesitation or planning.
In conversational speechthe intermediate levels occur infrequently and thebreak indices can be broadly categorized into threegroups, namely, 1, 4 and p as in Wong et al(2005).A classifier was developed to predict threebreak indices at each word boundary based onvariations in pitch, duration and energy asso-ciated with word, syllable or sub-syllabic con-stituents (Shriberg et al, 2005; Sonmez et al,1998).
To compute these features, phone-leveltime-alignments were obtained from an automaticspeech recognition system.
The duration of thesephonological constituents were derived from theASR alignment, while energy and pitch were com-puted every 10ms with snack, a public-domainsound toolkit (Sjlander, 2001).
The duration, en-ergy, and pitch were post-processed according tostylization procedures outlined in Sonmez et al(1998) and normalized to account for variabilityacross speakers.Since the input vector can have missing val-ues such as the absence of pitch during unvoicedsound, only decision tree based classifiers wereinvestigated.
Decision trees can handle missingfeatures gracefully.
By choosing different com-binations of splitting and stopping criteria, anensemble of decision trees was built using thepublicly-available IND package (Buntine, 1992).These individual classifiers were then combinedinto ensemble-based classifiers.Several classifiers were investigated for detect-ing break indices.
On ten-fold cross-validation,a bagging-based classifier (Breiman, 1996) pre-dicted prosodic breaks with an accuracy of 83.12%while chance was 67.66%.
This compares favor-ably with the performance of the supervised classi-fiers on a similar task in Wong et al (2005).
Ran-dom forests and hidden Markov models providemarginal improvements at considerable computa-tional cost (Harper et al, 2005).For speech repair, the focus is on detecting dis-fluent breaks.
The precision and recall trade-offon its detection can be adjusted using a thresh-old on the posterior probability of predicting ?p?,as shown in Figure 3.In essence, the large number of acoustic andprosodic features related to disfluency are encodedvia the ToBI label ?p?, and provided as additionalobservations to the PCFG.
This is unlike previouswork on incorporating prosodic information (Gre-00.10.20.30.40.50.6 00.10.20.30.40.50.6Probability of MissProbability ofFalseAlarmFigure 3: DET curve for detecting disfluent breaksfrom acoustics.gory et al, 2004; Lease et al, 2005; Kahn et al,2005) as described further in Section 6.3 Syntactic parallelismThe other striking property of speech repairs istheir parallel character: subsequent repair regions?line up?
with preceding reparandum regions.
Thisproperty can be harnessed to better estimate thelength of the reparandum by considering paral-lelism from the perspective of syntax.
For in-stance, in Figure 4(a) the unfinished reparandumnoun phrase is repaired by another noun phrase ?the syntactic categories are parallel.3.1 Levelt?s WFR and ConjunctionThe idea that the reparandum is syntactically par-allel to the repair can be traced back to Levelt(1983).
Examining a corpus of Dutch picture de-scriptions, Levelt proposes a bi-conditional well-formedness rule for repairs (WFR) that relates thestructure of repairs to the structure of conjunc-tions.
The WFR conceptualizes repairs as the con-junction of an unfinished reparandum string (?
)with a properly finished repair (?).
Its originalformulation, repeated here, ignores optional inter-regna like ?er?
or ?I mean.
?Well-formedness rule for repairs (WFR) A re-pair ????
is well-formed if and only if thereis a string ?
such that the string ???
and?
?
?is well-formed, where ?
is a completion ofthe constituent directly dominating the lastelement of ?.
(and is to be deleted if thatlast element is itself a sentence connective)In other words, the string ?
is a prefix of a phrasewhose completion, ?
?if it were present?would163render the whole phrase ??
grammatically con-joinable with the repair ?.
In example (1) ?
is thestring ?the first kind of invasion of?, ?
is ?the firsttype of privacy?
and ?
is probably the single word?privacy.
?This kind of conjoinability typically requiresthe syntactic categories of the conjuncts to be thesame (Chomsky, 1957, 36).
That is, a rule schemasuch as (2) where X is a syntactic category, is pre-ferred over one where X is not constrained to bethe same on either side of the conjunction.X ?
X Conj X (2)If, as schema (2) suggests, conjunction does fa-vor like-categories, and, as Levelt suggests, well-formed repairs are conjoinable with finished ver-sions of their reparanda, then the syntactic cate-gories of repairs ought to match the syntactic cat-egories of (finished versions of) reparanda.3.2 A WFR for grammarsLevelt?s WFR imposes two requirements on agrammar?
distinguishing a separate category of ?unfin-ished?
phrases?
identifying a syntactic category for reparandaBoth requirements can be met by adapting Tree-bank grammars to mirror the analysis of McK-elvie1 (1998a; 1998b).
McKelvie derives phrasestructure rules for speech repairs from fluent rulesby adding a new feature called abort that cantake values true and false.
For a given gram-mar rule of the formA ?
B Ca metarule creates other rules of the formA [abort = Q] ?B [abort = false] C [abort = Q]where Q is a propositional variable.
These rulessay, in effect, that the constituent A is aborted justin case the last daughter C is aborted.
Rules thatdon?t involve a constant value for Q ensure that thesame value appears on parents and children.
The1McKelvie?s metarule approach declaratively expressesHindle?s (1983) Stack Editor and Category Copy Editor rules.This classic work effectively states the WFR as a program forthe Fidditch deterministic parser.WFR is then implemented by rule schemas suchas (3)X ?
X [abort = true] (AFF) X (3)that permit the optional interregnum AFF to con-join an unfinished X-phrase (the reparandum) witha finished X-phrase (the repair) that comes after it.3.3 A WFR for TreebanksMcKelvie?s formulation of Levelt?s WFR can beapplied to Treebanks by systematically recodingthe annotations to indicate which phrases are un-finished and to distinguish matching from non-matching repairs.3.3.1 Unfinished phrasesSome Treebanks already mark unfinishedphrases.
For instance, the Penn Treebank pol-icy (Marcus et al, 1993; Marcus et al, 1994) isto annotate the lowest node that is unfinished withan -UNF tag as in Figure 4(a).It is straightforward to propagate this mark up-wards in the tree from wherever it is annotated tothe nearest enclosing EDITED node, just as -BRKis propagated upwards from disjuncture marks onindividual words.
This percolation simulates theaction of McKelvie?s [abort = true].
The re-sulting PCFG is one in which distributions onphrase structure rules with ?missing?
daughters aresegregated from distributions on ?complete?
rules.3.4 Reparanda categoriesThe other key element of Levelt?s WFR is theidea of conjunction of elements that are in somesense the same.
In the Penn Treebank annota-tion scheme, reparanda always receive the labelEDITED.
This means that the syntactic categoryof the reparandum is hidden from any rule whichcould favor matching it with that of the repair.Adding an additional mark on this EDITED node(a kind of daughter annotation) rectifies the situ-ation, as depicted in Figure 4(b), which adds thenotation -childNP to a tree in which the unfin-ished tags have been propagated upwards.
Thisallows a Treebank PCFG to represent the general-ization that speech repairs tend to respect syntacticcategory.4 ResultsThree kinds of experiments examined the effec-tiveness of syntactic and prosodic indicators of164SCC EDITED NPand NP NPNP PPDT JJ NN IN NPthe first kind of NP PP?UNFNN INinvasion ofDT JJ NNthe first type(a) The lowest unfinished node is given.SCC EDITED?childNP NPand NP?UNF NPNP PP?UNFDT JJ NN IN NP?UNFthe first kind of NP PP?UNFNN INinvasion ofDT JJ NNthe first type(b) -UNF propagated, daughter-annotated Switchboard treeFigure 4: Input (a) and output (b) of tree transformations.speech repairs.
The first two use the CYK algo-rithm to find the most likely parse tree on a gram-mar read-off from example trees annotated as inFigures 2 and 4.
The third experiment measuresthe benefit from syntactic indicators alone in Char-niak?s lexicalized parser (Charniak, 2000).
The ta-bles in subsections 4.1, 4.2, and 4.3 summarizethe accuracy of output parse trees on two mea-sures.
One is the standard Parseval F-measure,which tracks the precision and recall for all labeledconstituents as compared to a gold-standard parse.The other measure, EDIT-finding F, restricts con-sideration to just constituents that are reparanda.
Itmeasures the per-word performance identifying aword as dominated by EDITED or not.
As in pre-vious studies, reference transcripts were used in allcases.
A check (?)
indicates an experiment whereprosodic breaks where automatically inferred bythe classifier described in section 2, whereas in the(?)
rows no prosodic information was used.4.1 CYK on FisherTable 1 summarizes the accuracy of a stan-dard CYK parser on the newly-treebankedFisher corpus (LDC2005E15) of phone conver-sations, collected as part of the DARPA EARSprogram.
The parser was trained on the entireSwitchboard corpus (ca.
107K utterances) thentested on the 5368-utterance ?dev2?
subset of theFisher data.
This test set was tagged using MX-POST (Ratnaparkhi, 1996) which was itself trainedon Switchboard.
Finally, as described in section 2these tags were augmented with a special prosodicbreak symbol if the decision tree rated the proba-bility a ToBI ?p?
symbol higher than the thresholdvalue of 0.75.AnnotationBreakindexParsevalFEDITFnone?
66.54 22.9?66.08 26.1daughter annotation ?
66.41 29.4?
65.81 31.6-UNF propagation ?
67.06 31.5?
66.45 34.8both ?
69.21 40.2?
67.02 40.6Table 1: Improvement on Fisher, MXPOSTed tags.The Fisher results in Table 1 show that syntac-tic and prosodic indicators provide different kindsof benefits that combine in an additive way.
Pre-sumably because of state-splitting, improvementin EDIT-finding comes at the cost of a small decre-ment in overall parsing performance.4.2 CYK on SwitchboardTable 2 presents the results of similar experi-ments on the Switchboard corpus following the165train/dev/test partition of Charniak and Johnson(2001).
In these experiments, the parser was givencorrect part-of-speech tags as input.AnnotationBreakindexParsevalFEDITFnone?
70.92 18.2?69.98 22.5daughter annotation ?
71.13 25.0?
70.06 25.5-UNF propagation ?
71.71 31.1?
70.36 30.0both ?
71.16 41.7?
71.05 36.2Table 2: Improvement on Switchboard, gold tags.The Switchboard results demonstrate independentimprovement from the syntactic annotations.
Theprosodic annotation helps on its own and in com-bination with the daughter annotation that imple-ments Levelt?s WFR.4.3 Lexicalized parserFinally, Table 3 reports the performance of Char-niak?s non-reranking, lexicalized parser on theSwitchboard corpus, using the same test/dev/trainpartition.Annotation Parseval F EDIT Fbaseline 83.86 57.6daughter annotation 80.85 67.2-UNF propagation 81.68 64.7both 80.16 70.0flattened EDITED 82.13 64.4Table 3: Charniak as an improved EDIT-finder.Since Charniak?s parser does its own tagging,this experiment did not examine the utility ofprosodic disjuncture marks.
However, the com-bination of daughter annotation and -UNF prop-agation does lead to a better grammar-basedreparandum-finder than parsers trained on flat-tened EDITED regions.
More broadly, the re-sults suggest that Levelt?s WFR is synergistic withthe kind of head-to-head lexical dependencies thatCharniak?s parser uses.5 DiscussionThe pattern of improvement in tables 1, 2, and3 from none or baseline rows where no syntac-tic parallelism or break index information is used,to subsequent rows where it is used, suggest whythese techniques work.
Unfinished-category an-notation improves performance by preventing thegrammar of unfinished constituents from beingpolluted by the grammar of finished constituents.Such purification is independent of the fact thatrules with daughters labeled EDITED-childXPtend to also mention categories labeled XP fur-ther to the right (or NP and VP, when XP startswith S).
This preference for syntactic parallelismcan be triggered either by externally-suggestedToBI break indices or grammar rules annotatedwith -UNF.
The prediction of a disfluent breakcould be further improved by POS features and N-gram language model scores (Spilker et al, 2001;Liu, 2004).6 Related WorkThere have been relatively few attempts to harnessprosodic cues in parsing.
In a spoken languagesystem for VERBMOBIL task, Batliner and col-leagues (2001) utilize prosodic cues to dramati-cally reduce lexical analyses of disfluencies in aend-to-end real-time system.
They tackle speechrepair by a cascade of two stages ?
identification ofpotential interruption points using prosodic cueswith 90% recall and many false alarms, and thelexical analyses of their neighborhood.
Their ap-proach, however, does not exploit the synergy be-tween prosodic and syntactic features in speech re-pair.
In Gregory et al (2004), over 100 real-valuedacoustic and prosodic features were quantized intoa heuristically selected set of discrete symbols,which were then treated as pseudo-punctuation ina PCFG, assuming that prosodic cues function likepunctuation.
The resulting grammar suffered fromdata sparsity and failed to provide any benefits.Maximum entropy based models have been moresuccessful in utilizing prosodic cues.
For instance,in Lease et al (2005), interruption point probabil-ities, predicted by prosodic classifiers, were quan-tized and introduced as features into a speech re-pair model along with a variety of TAG and PCFGfeatures.
Towards a clearer picture of the inter-action with syntax and prosody, this work usesToBI to capture prosodic cues.
Such a method isanalogous to Kahn et al (2005) but in a genera-tive framework.The TAG-based model of Johnson and Charniak(2004) is a separate-processing approach that rep-166resents the state of the art in reparandum-finding.Johnson and Charniak explicitly model thecrossed dependencies between individual wordsin the reparandum and repair regions, intersect-ing this sequence model with a parser-derived lan-guage model for fluent speech.
This second stepimproves on Stolcke and Shriberg (1996) and Hee-man and Allen (1999) and outperforms the specificgrammar-based reparandum-finders tested in sec-tion 4.
However, because of separate-processingthe TAG channel model?s analyses do not reflectthe syntactic structure of the sentence being ana-lyzed, and thus that particular TAG-based modelcannot make use of properties that depend on thephrase structure of the reparandum region.
Thisincludes the syntactic category parallelism dis-cussed in section 3 but also predicate-argumentstructure.
If edit hypotheses were augmented tomention particular tree nodes where the reparan-dum should be attached, such syntactic paral-lelism constraints could be exploited in the rerank-ing framework of Johnson et al (2004).The approach in section 3 is more closely re-lated to that of Core and Schubert (1999) whoalso use metarules to allow a parser to switch fromspeaker to speaker as users interrupt one another.They describe their metarule facility as a modi-fication of chart parsing that involves copying ofspecific arcs just in case specific conditions arise.That approach uses a combination of longest-firstheuristics and thresholds rather than a completeprobabilistic model such as a PCFG.Section 3?s PCFG approach can also be viewedas a declarative generalization of Roark?s (2004)EDIT-CHILD function.
This function helps anincremental parser decide upon particular tree-drawing actions in syntactically-parallel contextslike speech repairs.
Whereas Roark conditions theexpansion of the first constituent of the repair uponthe corresponding first constituent of the reparan-dum, in the PCFG approach there exists a separaterule (and thus a separate probability) for each al-ternative sequence of reparandum constituents.7 ConclusionConventional PCFGs can improve their detectionof speech repairs by incorporating Lickley?s hy-pothesis about interrupted prosody and by im-plementing Levelt?s well-formedness rule.
Thesebenefits are additive.The strengths of these simple tree-based tech-niques should be combinable with sophisticatedstring-based (Johnson and Charniak, 2004; Liu,2004; Zhang and Weng, 2005) approaches byapplying the methods of Wieling et al (2005)for constraining parses by externally-suggestedbrackets.ReferencesL.
Breiman.
1996.
Bagging predictors.
MachineLearning, 24(2):123?140.W.
Buntine.
1992.
Tree classication software.
In Tech-nology 2002: The Third National Technology Trans-fer Conference and Exposition, Baltimore.E.
Charniak and M. Johnson.
2001.
Edit detectionand parsing for transcribed speech.
In Proceedingsof the 2nd Meeting of the North American Chap-ter of the Association for Computational Linguistics,pages 118?126.E.
Charniak.
2000.
A maximum-entropy-inspiredparser.
In Proceedings of NAACL-00, pages 132?139.N.
Chomsky.
1957.
Syntactic Structures.
Anua Lin-guarum Series Minor 4, Series Volume 4.
Moutonde Gruyter, The Hague.M.
G. Core and L. K. Schubert.
1999.
A syntacticframework for speech repairs and other disruptions.In Proceedings of the 37th Annual Meeting of the As-sociation for Computational Linguistics, pages 413?420.J.
J. Godfrey, E. C. Holliman, and J. McDaniel.
1992.SWITCHBOARD: Telephone speech corpus for re-search and development.
In Proceedings of ICASSP,volume I, pages 517?520, San Francisco.M.
Gregory, M. Johnson, and E. Charniak.
2004.Sentence-internal prosody does not help parsing theway punctuation does.
In Proceedings of NorthAmerican Association for Computational Linguis-tics.M.
Harper, B. Dorr, J. Hale, B. Roark, I. Shafran,M.
Lease, Y. Liu, M. Snover, and L. Yung.
2005.Parsing and spoken structural event detection.
In2005 Johns Hopkins Summer Workshop Final Re-port.P.
A. Heeman and J. F. Allen.
1999.
Speech repairs,intonational phrases and discourse markers: model-ing speakers?
utterances in spoken dialog.
Compu-tational Linguistics, 25(4):527?571.D.
Hindle.
1983.
Deterministic parsing of syntacticnon-fluencies.
In Proceedings of the ACL.M.
Johnson and E. Charniak.
2004.
A TAG-basednoisy channel model of speech repairs.
In Proceed-ings of ACL, pages 33?39.167M.
Johnson, E. Charniak, and M. Lease.
2004.
An im-proved model for recognizing disfluencies in conver-sational speech.
In Proceedings of Rich Transcrip-tion Workshop.J.
G. Kahn, M. Lease, E. Charniak, M. Johnson, andM.
Ostendorf.
2005.
Effective use of prosody inparsing conversational speech.
In Proceedings ofHuman Language Technology Conference and Con-ference on Empirical Methods in Natural LanguageProcessing, pages 233?240.M.
Lease, E. Charniak, and M. Johnson.
2005.
Pars-ing and its applications for conversational speech.
InProceedings of ICASSP.W.
J. M. Levelt.
1983.
Monitoring and self-repair inspeech.
Cognitive Science, 14:41?104.R.
J. Lickley.
1996.
Juncture cues to disfluency.
InProceedings the International Conference on Speechand Language Processing.Y.
Liu.
2004.
Structural Event Detection for RichTranscription of Speech.
Ph.D. thesis, Purdue Uni-versity.M.
Marcus, B. Santorini, and M. A. Marcinkiewicz.1993.
Building a large annotated corpus of En-glish: The Penn Treebank.
Computational Linguis-tics, 19(2):313?330.M.
Marcus, G. Kim, M. A. Marcinkiewicz, R. MacIn-tyre, A. Bies, M. Ferguson, K. Katz, and B. Schas-berger.
1994.
The Penn Treebank: AnnotatingPredicate Argument Structure.
In Proceedings ofthe 1994 ARPA Human Language Technology Work-shop.D.
McKelvie.
1998a.
SDP ?
Spoken Dialog Parser.ESRC project on Robust Parsing and Part-of-speechTagging of Transcribed Speech Corpora, May.D.
McKelvie.
1998b.
The syntax of disfluency in spon-taneous spoken language.
ESRC project on RobustParsing and Part-of-speech Tagging of TranscribedSpeech Corpora, May.C.
Nakatani and J. Hirschberg.
1994.
A corpus-basedstudy of repair cues in spontaneous speech.
Journalof the Acoustical Society of America, 95(3):1603?1616, March.M.
Ostendorf, I. Shafran, S. Shattuck-Hufnagel,L.
Carmichael, and W. Byrne.
2001.
A prosodicallylabelled database of spontaneous speech.
In Proc.ISCA Tutorial and Research Workshop on Prosodyin Speech Recognition and Understanding, pages119?121.P.
Price, M. Ostendorf, S. Shattuck-Hufnagel, andC.
Fong.
1991.
The use of prosody in syntacticdisambiguation.
Journal of the Acoustic Society ofAmerica, 90:2956?2970.A.
Ratnaparkhi.
1996.
A maximum entropy part-of-speech tagger.
In Proceedings of Empirical Methodsin Natural Language Processing Conference, pages133?141.B.
Roark.
2004.
Robust garden path parsing.
NaturalLanguage Engineering, 10(1):1?24.E.
Shriberg, L. Ferrer, S. Kajarekar, A. Venkataraman,and A. Stolcke.
2005.
Modeling prosodic featuresequences for speaker recognition.
Speech Commu-nication, 46(3-4):455?472.E.
Shriberg.
1994.
Preliminaries to a Theory of SpeechDisfluencies.
Ph.D. thesis, UC Berkeley.H.
F. Silverman, M. Beckman, J. Pitrelli, M. Ostendorf,C.
Wightman, P. Price, J. Pierrehumbert, and J. Hir-shberg.
1992.
ToBI: A standard for labeling Englishprosody.
In Proceedings of ICSLP, volume 2, pages867?870.K.
Sjlander, 2001.
The Snack sound visualization mod-ule.
Royal Institute of Technology in Stockholm.http://www.speech.kth.se/SNACK.K.
Sonmez, E. Shriberg, L. Heck, and M. Weintraub.1998.
Modeling dynamic prosodic variation forspeaker verification.
In Proceedings of ICSLP, vol-ume 7, pages 3189?3192.Jo?rg Spilker, Martin Klarner, and Gu?nther Go?rz.
2000.Processing self-corrections in a speech-to-speechsystem.
In Wolfgang Wahlster, editor, Verbmobil:Foundations of speech-to-speech translation, pages131?140.
Springer-Verlag, Berlin.J.
Spilker, A. Batliner, and E. No?th.
2001.
How torepair speech repairs in an end-to-end system.
InR.
Lickley and L. Shriberg, editors, Proc.
of ISCAWorkshop on Disfluency in Spontaneous Speech,pages 73?76.A.
Stolcke and E. Shriberg.
1996.
Statistical languagemodeling for speech disfluencies.
In Proceedingsof the IEEE International Conference on Acoustics,Speech and Signal Processing, pages 405?408, At-lanta, GA.R.
M. Weischedel and N. K. Sondheimer.
1983.Meta-rules as a basis for processing ill-formed in-put.
American Journal of Computational Linguis-tics, 9(3-4):161?177.M.
Wieling, M-J.
Nederhof, and G. van Noord.
2005.Parsing partially bracketed input.
Talk presented atComputational Linguistics in the Netherlands.D.
Wong, M. Ostendorf, and J. G. Kahn.
2005.
Us-ing weakly supervised learning to improve prosodylabeling.
Technical Report UWEETR-2005-0003,University of Washington Electrical EngineeringDept.Q.
Zhang and F. Weng.
2005.
Exploring features foridentifying edited regions in disfluent sentences.
InProceedings of the Nineth International Workshopon Parsing Technologies, pages 179?185.168
