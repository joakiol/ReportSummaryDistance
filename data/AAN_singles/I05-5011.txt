Automatic Paraphrase Discovery based onContext and Keywords between NE PairsSatoshi SekineNew York University715 Broadway, 7th floorNew York, NY 10003 USAsekine@cs.nyu.eduAbstractAutomatic paraphrase discovery is animportant but challenging task.
Wepropose an unsupervised method todiscover paraphrases from a largeuntagged corpus, without requiring anyseed phrase or other cue.
We focus onphrases which connect two Named En-tities (NEs), and proceed in two stages.The first stage identifies a keyword ineach phrase and joins phrases with thesame keyword into sets.
The secondstage links sets which involve the samepairs of individual NEs.
A total of13,976 phrases were grouped.
The ac-curacy of the sets in representing para-phrase ranged from 73% to 99%,depending on the NE categories and setsizes; the accuracy of the links for twoevaluated domains was 73% and 86%.1 IntroductionOne of the difficulties in Natural LanguageProcessing is the fact that there are many waysto express the same thing or event.
If the expres-sion is a word or a short phrase (like ?corpora-tion?
and ?company?
), it is called a ?synonym?.There has been a lot of research on such lexicalrelations, along with the creation of resourcessuch as WordNet.
If the expression is longer orcomplicated (like ?A buys B?
and ?A?s purchaseof B?
), it is called ?paraphrase?, i.e.
a set ofphrases which express the same thing or event.Recently, this topic has been getting more atten-tion, as is evident from the Paraphrase Work-shops in 2003 and 2004, driven by the needs ofvarious NLP applications.
For example, in In-formation Retrieval (IR), we have to match auser?s query to the expressions in the desireddocuments, while in Question Answering (QA),we have to find the answer to the user?s questioneven if the formulation of the answer in thedocument is different from the question.
Also, inInformation Extraction (IE), in which the systemtries to extract elements of some events (e.g.date and company names of a corporate mergerevent), several event instances from differentnews articles have to be aligned even if these areexpressed differently.We realize the importance of paraphrase;however, the major obstacle is the constructionof paraphrase knowledge.
For example, we caneasily imagine that the number of paraphrasesfor ?A buys B?
is enormous and it is not possi-ble to create a comprehensive inventory by hand.Also, we don?t know how many such paraphrasesets are necessary to cover even some everydaythings or events.
Up to now, most IE researchershave been creating paraphrase knowledge (or IEpatterns) by hand and for specific tasks.
So,there is a limitation that IE can only be per-formed for a pre-defined task, like ?corporatemergers?
or ?management succession?.
In orderto create an IE system for a new domain, onehas to spend a long time to create the knowledge.So, it is too costly to make IE technology ?open-domain?
or ?on-demand?
like IR or QA.In this paper, we will propose an unsuper-vised method to discover paraphrases from alarge untagged corpus.
We are focusing onphrases which have two Named Entities (NEs),as those types of phrases are very important forIE applications.
After tagging a large corpuswith an automatic NE tagger, the method tries tofind sets of paraphrases automatically withoutbeing given a seed phrase or any kinds of cue.802 Algorithm2.1 OverviewBefore explaining our method in detail, we pre-sent a brief overview in this subsection.First, from a large corpus, we extract all theNE instance pairs.
Here, an NE instance pair isany pair of NEs separated by at most 4 syntacticchunks; for example, ?IBM plans to acquire Lo-tus?.
For each pair we also record the context,i.e.
the phrase between the two NEs (Step1).Next, for each pair of NE categories, we collectall the contexts and find the keywords which aretopical for that NE category pair.
We use a sim-ple TF/IDF method to measure the topicality ofwords.
Hereafter, each pair of NE categorieswill be called a domain; e.g.
the ?Company ?Company?
domain, which we will call CC-domain (Step 2).
For each domain, phraseswhich contain the same keyword are gathered tobuild a set of phrases (Step 3).
Finally, we findlinks between sets of phrases, based on the NEinstance pair data (for example, different phraseswhich link ?IBM?
and ?Lotus?)
(Step 4).
As weshall see, most of the linked sets are paraphrases.This overview is illustrated in Figure 1.Figure 1.
Overview of the method2.2 Step by Step AlgorithmIn this section, we will explain the algorithmstep by step with examples.
Because of their size,the examples (Figures 2 to 4) appear at the endof the paper.Step 1.
Extract NE instance pairs with contextsFirst, we extract NE pair instances with theircontext from the corpus.
The sentences in thecorpus were tagged by a transformation-basedchunker and an NE tagger.
The NE tagger is arule-based system with 140 NE categories [Se-kine et al 2004].
These 140 NE categories aredesigned by extending MUC?s 7 NE categorieswith finer sub-categories (such as Company,Institute, and Political Party for Organization;and Country, Province, and City for Location)and adding some new types of NE categories(Position Title, Product, Event, and Natural Ob-ject).
All the NE pair instances which co-occurseparated by at most 4 chunks are collectedalong with information about their NE types andthe phrase between the NEs (the ?context?).
Fig-ure 2 shows examples of extracted NE pair in-stances and their contexts.
The data is sortedbased on the frequency of the context (?a unitof?
appeared 314 times in the corpus) and theNE pair instances appearing with that contextare shown with their frequency (e.g.
?NBC?
and?General Electric Co.?
appeared 10 times withthe context ?a unit of?
).Step 2.
Find keywords for each NE pairWhen we look at the contexts for each domain,we noticed that there is one or a few importantwords which indicate the relation between theNEs (for example, the word ?unit?
for the phrase?a unit of?).
Once we figure out the importantword (e.g.
keyword), we believe we can capturethe meaning of the phrase by the keyword.
Weused the TF/ITF metric to identify keywords.CorpusAll the contexts collected for a given domainare gathered in a bag and the TF/ITF scores arecalculated for all the words except stopwords inthe bag.
Here, the term frequency (TF) is thefrequency of a word in the bag and the inverseterm frequency (ITF) is the inverse of the log ofthe frequency in the entire corpus.
Figure 3shows some keywords with their scores.Step 3.
Gather phrases using keywordsNext, we select a keyword for each phrase ?
thetop-ranked word based on the TF/IDF metric.
(If the TF/IDF score of that word is below athreshold, the phrase is discarded.)
We thenNE pair instanceskeywordsSets of phrasesbased on keywordsLinks betweensets of phrasesStep 1Step 2Step 4Step 381gather all phrases with the same keyword.
Fig-ure 4 shows some such phrase sets based onkeywords in the CC-domain.Step 4.
Cluster phrases based on LinksWe now have a set of phrases which share akeyword.
However, there are phrases which ex-press the same meanings even though they donot share the same keyword.
For example, inFigure 3, we can see that the phrases in the?buy?, ?acquire?
and ?purchase?
sets are mostlyparaphrases.
At this step, we will try to linkthose sets, and put them into a single cluster.Our clue is the NE instance pairs.
If the samepair of NE instances is used with differentphrases, these phrases are likely to be para-phrases.
For example, the two NEs ?EasternGroup Plc?
and ?Hanson Plc?
have the follow-ing contexts.
Here, ?EG?
represents ?EasternGroup Plc?.
and ?H?
represents ?Hanson Plc?.xEG, has agreed to be bought by HxEG, now owned by HxH to acquire EGxH?s agreement to buy EGThree of those phrases are actually paraphrases,but sometime there could be some noise; such asthe second phrase above.
So, we set a thresholdthat at least two examples are required to build alink.
More examples are shown in Figure 5.Notice that the CC-domain is a special case.As the two NE categories are the same, we can?tdifferentiate phrases with different orders of par-ticipants ?
whether the buying company or theto-be-bought company comes first.
The linkscan solve the problem.
As can be seen in theexample, the first two phrases have a differentorder of NE names from the last two, so we candetermine that the last two phrases represent areversed relation.
In figure 4, reverse relationsare indicated by `*?
next to the frequency.Now we have sets of phrases which share akeyword and we have links between those sets.3 Experiments3.1 CorporaFor the experiments, we used four newswirecorpora, the Los Angeles Times/WashingtonPost, The New York Times, Reuters and theWall Street Journal, all published in 1995.
Theycontain about 200M words (25M, 110M, 40Mand 19M words, respectively).
All the sentenceshave been analyzed by our chunker and NE tag-ger.
The procedure using the tagged sentences todiscover paraphrases takes about one hour on a2GHz Pentium 4 PC with 1GB of memory.3.2 ResultsIn this subsection, we will report the results ofthe experiment, in terms of the number of words,phrases or clusters.
We will report the evalua-tion results in the next subsection.Step 1.
Extract NE pair instances with contextsFrom the four years of newspaper corpus, weextracted 1.9 million pairs of NE instances.
Themost frequent NE category pairs are ?Person -Person (209,236), followed by ?Country - Coun-try?
(95,123) and ?Person - Country?
(75,509).The frequency of the Company ?
Company do-main ranks 11th with 35,567 examples.As lower frequency examples include noise,we set a threshold that an NE category pairshould appear at least 5 times to be consideredand an NE instance pair should appear at leasttwice to be considered.
This limits the numberof NE category pairs to 2,000 and the number ofNE pair instances to 0.63 million.Step 2.
Find keywords for each NE pairThe keywords are found for each NE categorypair.
For example, in the CC-domain, 96 key-words are found which have TF/ITF scoresabove a threshold; some of them are shown inFigure 3.
It is natural that the larger the data inthe domain, the more keywords are found.
In the?Person ?
Person?
domain, 618 keywords arefound, and in the ?Country ?
Country?
domain,303 keywords are found.
In total, for the 2,000NE category pairs, 5,184 keywords are found.Step 3.
Gather phrases using keywordsNow, the keyword with the top TF/ITF score isselected for each phrase.
If a phrase does notcontain any keywords, the phrase is discarded.For example, out of 905 phrases in the CC-domain, 211 phrases contain keywords found instep 2.
In total, across all domains, we kept13,976 phrases with keywords.82Step 4.
Link phrases based on instance pairsUsing NE instance pairs as a clue, we find linksbetween sets of phrases.
In the CC-domain,there are 32 sets of phrases which contain morethan 2 phrases.
We concentrate on those sets.Among these 32 sets, we found the followingpairs of sets which have two or more links.
Herea set is represented by the keyword and thenumber in parentheses indicates the number ofshared NE pair instances.buy - acquire (5) buy - agree (2)buy - purchase (5) buy - acquisition (7)buy - pay (2)* buy - buyout (3)buy - bid (2) acquire - purchase (2)acquire - acquisition (2)acquire - pay (2)*    purchase - acquisition (4)purchase - stake (2)* acquisition - stake (2)*unit - subsidiary (2) unit - parent (5)It is clear that these links form two clusterswhich are mostly correct.
We will describe theevaluation of such clusters in the next subsection.3.3 Evaluation ResultsWe evaluated the results based on two metrics.One is the accuracy within a set of phraseswhich share the same keyword; the other is theaccuracy of links.
We picked two domains, theCC-domain and the ?Person ?
Company?
do-main (PC-domain), for the evaluation, as theentire system output was too large to evaluate.
Itis not easy to make a clear definition of ?para-phrase?.
Sometimes extracted phrases by them-selves are not meaningful to consider withoutcontext, but we set the following criteria.
If twophrases can be used to express the same rela-tionship within an information extraction appli-cation (?scenario?
), these two phrases areparaphrases.
Although this is not a precise crite-rion, most cases we evaluated were relativelyclear-cut.
In general, different modalities(?planned to buy?, ?agreed to buy?, ?bought?
)were considered to express the same relationshipwithin an extraction setting.
We did have a prob-lem classifying some modified noun phraseswhere the modified phrase does not represent aqualified or restricted form of the head, like?chairman?
and ?vice chairman?, as these areboth represented by the keyword ?chairman?.
Inthis specific case, as these two titles could fillthe same column of an IE table, we regardedthem as paraphrases for the evaluation.Evaluation within a setThe evaluation of paraphrases within a set ofphrases which share a keyword is illustrated inFigure 4.
For each set, the phrases with brack-eted frequencies are considered not paraphrasesin the set.
For example, the phrase ?
's NewYork-based trust unit,?
is not a paraphrase of theother phrases in the ?unit?
set.
As you can see inthe figure, the accuracy for the domain is quitehigh except for the ?agree?
set, which containsvarious expressions representing different rela-tionships for an IE application.
The accuracy iscalculated as the ratio of the number of para-phrases to the total number of phrases in the set.The results, along with the total number ofphrases, are shown in Table 1.Domain # of phrases totalphrases accuracy7 or more 105 87.6%CC 6 or less 106 67.0%7 or more 359 99.2%PC 6 or less 255 65.1%Table 1.
Evaluation results within setsTable 1 shows the evaluation result based onthe number of phrases in a set.
The larger setsare more accurate than the small sets.
We canmake several observations on the cause of errors.One is that smaller sets sometime have meaning-less keywords, like ?strength?
or ?add?
in theCC-domain, or ?compare?
in the PC-domain.Eight out of the thirteen errors in the high fre-quency phrases in the CC-domain are thephrases in ?agree?.
As can be seen in Figure 3,the phrases in the ?agree?
set include completelydifferent relationships, which are not para-phrases.
Other errors include NE tagging errorsand errors due to a phrase which includes otherNEs.
For example, in the phrase ?Company-Alast week purchased rival Marshalls from Com-pany-B?, the purchased company is Marshalls,not Company-B.
Also there are cases where oneof the two NEs belong to a phrase outside of therelation.
For example, from the sentence ?Mr.Smith estimates Lotus will make a profit thisquarter?
?,  our system extracts ?Smith esti-83mates Lotus?
as an instance.
Obviously ?Lotus?is part of the following clause rather than beingthe object of ?estimates?
and the extracted in-stance makes no sense.
We will return to theseissues in the discussion section.Evaluation of linksA link between two sets is considered correct ifthe majority of phrases in both sets have thesame meaning, i.e.
if the link indicates para-phrase.
All the links in the ?CC-domain areshown in Step 4 in subsection 3.2.
Out of those15 links, 4 are errors, namely ?buy - pay?, ?ac-quire - pay?, ?purchase - stake?
?acquisition -stake?.
When a company buys another company,a paying event can occur, but these two phrasesdo not indicate the same event.
The similar ex-planation applies to the link to the ?stake?
set.We checked whether the discovered links arelisted in WordNet.
Only 2 link in the CC-domain (buy-purchase, acquire-acquisition) and2 links (trader-dealer and head-chief) in the PC-domain are found in the same synset of Word-Net 2.1 (http://wordnet.princeton.edu/).
Thisresult suggests the benefit of using the automaticdiscovery method.Domain Link accuracy WN coverageCC 73.3 % 2/11PC 88.9% 2/8Table 2.
Evaluation results for links4 Related WorkThe work reported here is closely related to [Ha-segawa et al 04].
First, we will describe theirmethod and compare it with our method.
Theyfirst collect the NE instance pairs and contexts,just like our method.
However, the next step isclearly different.
They cluster NE instance pairsbased on the words in the contexts using a bag-of-words method.
In order to create good-sizedvectors for similarity calculation, they had to seta high frequency threshold, 30.
Because of thisthreshold, very few NE instance pairs could beused and hence the variety of phrases was alsolimited.
Instead, we focused on phrases and setthe frequency threshold to 2, and so were able toutilize a lot of phrases while minimizing noise.
[Hasegawa et al 04] reported only on relationdiscovery, but one could easily acquire para-phrases from the results.
The number of NE in-stance pairs used in their experiment is less thanhalf of our method.There have been other kinds of efforts to dis-cover paraphrase automatically from corpora.One of such approaches uses comparable docu-ments, which are sets of documents whose con-tent are found/known to be almost the same,such as different newspaper stories about thesame event [Shinyama and Sekine 03] or differ-ent translations of the same story [Barzilay 01].The availability of comparable corpora is lim-ited, which is a significant limitation on the ap-proach.Another approach to finding paraphrases is tofind phrases which take similar subjects and ob-jects in large corpora by using mutual informa-tion of word distribution [Lin and Pantel 01].This approach needs a phrase as an initial seedand thus the possible relationships to be ex-tracted are naturally limited.There has also been work using a bootstrap-ping approach [Brin 98; Agichtein and Gravano00; Ravichandran and Hovy 02].
The basicstrategy is, for a given pair of entity types, tostart with some examples, like several famousbook title and author pairs; and find expressionswhich contains those names; then using thefound expressions, find more author and booktitle pairs.
This can be repeated several times tocollect a list of author / book title pairs and ex-pressions.
However, those methods need initialseeds, so the relation between entities has to beknown in advance.
This limitation is the obsta-cle to making the technology ?open domain?.5 DiscussionKeywords with more than one wordIn the evaluation, we explained that ?chairman?and ?vice chairman?
are considered paraphrases.However, it is desirable if we can separate them.This problem arises because our keywords con-sist of only one word.
Sometime, multiple wordsare needed, like ?vice chairman?, ?prime minis-ter?
or ?pay for?
(?pay?
and ?pay for?
are differ-ent senses in the CC-domain).
One possibility isto use n-grams based on mutual information.
Ifthere is a frequent multi-word sequence in adomain, we could use it as a keyword candidate.84Keyword detection errorEven if a keyword consists of a single word,there are words which are not desirable as key-words for a domain.
As was explained in theresults section, ?strength?
or ?add?
are not de-sirable keywords in the CC-domain.
In our ex-periment, we set the threshold of the TF/ITFscore empirically using a small developmentcorpus; a finer adjustment of the threshold couldreduce the number of such keywords.Also, ?agree?
in the CC-domain is not a de-sirable keyword.
It is a relatively frequent wordin the domain, but it can be used in differentextraction scenarios.
In this domain the majorscenarios involve the things they agreed on,rather than the mere fact that they agreed.?Agree?
is a subject control verb, which domi-nates another verb whose subject is the same asthat of ?agree?
; the latter verb is generally theone of interest for extraction.
We have checkedif there are similar verbs in other major domains,but this was the only one.Using structural informationAs was explained in the results section, we ex-tracted examples like ?Smith estimates Lotus?,from a sentence like ?Mr.
Smith estimates Lotuswill make profit this quarter??.
In order tosolve this problem, a parse tree is needed to un-derstand that ?Lotus?
is not the object of ?esti-mates?.
Chunking is not enough to find suchrelationships.
This remains as future work.LimitationsThere are several limitations in the methods.The phrases have to be the expressions of lengthless than 5 chunks, appear between two NEs.Also, the method of using keywords rules outphrases which don?t contain popular words inthe domain.
We are not claiming that thismethod is almighty.
Rather we believe severalmethods have to be developed using differentheuristics to discover wider variety of para-phrases.ApplicationsThe discovered paraphrases have multiple appli-cations.
One obvious application is informationextraction.
In IE, creating the patterns whichexpress the requested scenario, e.g.
?manage-ment succession?
or ?corporate merger and ac-quisition?
is regarded as the hardest task.
Thediscovered paraphrases can be a big help to re-duce human labor and create a more comprehen-sive pattern set.
Also, expanding on thetechniques for the automatic generation of ex-traction patterns (Riloff 96; Sudo 03) using ourmethod, the extraction patterns which have thesame meaning can be automatically linked, ena-bling us to produce the final table fully auto-matically.
While there are other obstacles tocompleting this idea, we believe automatic para-phrase discovery is an important component forbuilding a fully automatic information extractionsystem.6 ConclusionWe proposed an unsupervised method to dis-cover paraphrases from a large untagged corpus.We are focusing on phrases which have twoNamed Entities (NEs), as those types of phrasesare very important for IE applications.
Aftertagging a large corpus with an automatic NEtagger, the method tries to find sets of para-phrases automatically without being given aseed phrase or any kind of cue.
In total 13,976phrases are assigned to sets of phrases, and theaccuracy on our evaluation data ranges from 65to 99%, depending on the domain and the size ofthe sets.
The accuracies for link were 73% and86% on two evaluated domains.
These resultsare promising and there are several avenues forimproving on these results.7 AcknowledgementsThis research was supported in part by the De-fense Advanced Research Projects Agency aspart of the Translingual Information Detection,Extraction and Summarization (TIDES) pro-gram, under Grant N66001-001-1-8917 from theSpace and Naval Warfare Systems Center, SanDiego, and by the National Science Foundationunder Grant IIS-00325657.
This paper does notnecessarily reflect the position of the U.S. Gov-ernment.We would like to thank Prof. Ralph Grish-man, Mr. Takaaki Hasegawa and Mr. YusukeShinyama for useful comments, discussion andevaluation.85ReferencesAgichtein, Eugene and Gravano, Luis.
2000.
Snow-ball: Extracting reations from large plain-text col-locations.
In Proc.
5th ACM Int?l Conf.
on DigitalLibruaries (ACM DL00) pp 85-94.Barzilay, Regina and McKeown, Kathleen.
2001.Extracting paraphrases from a parallel corpus.
InProc.
39th Annual Meeting  Association for Com-putational Linguistics (ACL-EACL01), pp 50-57.Brin, Sergey.
1998.
Extracting patterns and relationsfrom world wide web.
In Proc.
WebDB Workshopat 6th Int?l Conf.
on Extending Database Technol-ogy (WebDB98), pp172-183.Hasegawa, Takaaki, Sekine, Satoshi and Grishman,Ralph.
2004.
Discovering Relations amongNamed Entities from Large Corpora, In Proc.42nd Annual Meeting  Association for Computa-tional Linguistics (ACL04), pp 415-422Hearst, Marti A.
1992.
Automatic acquisition of hy-ponyms from large text corpora.
In Proc  Four-teenth Int?l Conf.
on Computational Linguistics(COLING92).Lin, Dekang and Pantel, Patrick.
2001.
Dirt ?
discov-ery of inference rules from text.
In Proc.
7th ACMSIGKDD Int?l Conf.
on Knowledge Discovery andData Mining (KDD01), pp323-328Ravichandran, Deepak and Hovy, Eduard.
2002.Learning Surface Text Patterns for a Question An-swering System.
In Proc.
Annual Meeting  Asso-ciation for Computational Linguistics (ACL02)Riloff E. 1996.
Automatically Generating ExtractionPatterns from Untagged Text.
In Proc.
13th Na-tional Conf.
on Artificial Intelligence (AAAI96),1044-1049.Sekine, Satoshi and Nobata , Chikashi.
2004.
Defini-tion, Dictionary and Tagger for Extended NamedEnties.
In Proc.
of the Fourth Int?l Conf.
on Lan-guage Resource and Evaluation (LREC 04)Shinyama, Yusuke and Sekine, Satoshi.
2003.
Para-phrase acquisition for information extraction.
InProc.
2nd Int?l Workshop on Paraphrasing(IWP03)Sudo, Kiyoshi, Sekine, Satoshi and Grishman, Ralph.2003.
An improved extraction pattern representa-tion model for automatic IE pattern acquisition.
InProc.
41st Annual Meeting Association for Com-putational Linguistics (ACL03)# COMPANY COMPANY : 22535@ 314 , a unit of10 NBC   General Electric Co.9  Citibank  Citicorp7  Smith Barney  Travelers Group Inc.6  20th Century Fox the News Corp.5  Salomon Brothers Salomon Inc.5  Fidelity  FMR Corp.5  GTE Mobilnet  GTE Corp4  Smith Barney  Travelers Inc.?
@ 108 , a subsidiary of5  U.S. Ecology Inc. American Ecology Corp.3  Pulte Home Corp. Pulte Corp.?Figure 2.
Extracted NE pair instances and context4846.2 519 44778 buy3682.8 205 261 share3609.1 354 18186 unit2949.2 289 18021 parent2850.6 258 8523 acquire2709.9 275 25541 agree1964.1 163 4020 subsidiary1237.9 119 14959 purchase1036.9 94 8649 acquisition593.7 40 843 sell585.6 55 12000 stake581.3 63 50868 payFigure 3.
High TF/ITF words in ?Com-Com?
(Numbers are TF/ITF score, frequency in the collec-tion (TF), frequency in the corpus (TF) and word)=== buy ===97 agreed to buy84 bought50 said it will buy45 said it agreed to buy25 will buy23 to buy20 plans to buy16 , which bought14 is buying11 said it would buy11 offered to buy10 's agreement to buy9 , which is buying9* agreed to be bought by8 is offering to buy7 said it wants to buy7 was buying6 tried to buy6 said it plans to buy6 said it intends to buy866* was bought by5 is offering to buy the portion of5 is expected to announce plans to buy5 is in talks to buy5 would buy5 succeeds in buying5 , said it 's buying=== unit ===314 , a unit of24 is a unit of6* 's New York-based trust unit ,5 a unit of=== parent ===108 , the parent of81 , parent of56 , the parent company of14 , parent company of10* 's parent ,9* 's parent company ,6* , whose parent company is=== acquire ===70 acquired38 said it will acquire23 agreed to acquire16 will acquire16* agreed to be acquired by14* , has agreed to be acquired by13 to acquire9 said it agreed to acquire8* was acquired by8* , which agreed to be acquired by7 would acquire7 said it would acquire7* is being acquired by6* , which was acquired by6* , which is being acquired by5 , which acquired5 succeeds in acquiring=== agree ===(8) agreed to merge with(8) said it agreed to purchase(8) , agreed to accept any offer by(6) agreed to pay $ 19 billion for(6) has already agreed to make(5) agreed to pay(5) agreed to sell=== subsidiary ===108 , a subsidiary of10 is a subsidiary of(8) 's Brown & Williamson subsidiary ,7 , a wholly owned subsidiary of5 a subsidiary of5* 's U.S. subsidiary ,5 , both subsidiaries of5 will become a subsidiary of=== purchase ===51 's purchase of7 purchased7 an option to purchase6 for a six-year option to purchase(6) purchased Sterling Winthrop from6 recently completed its purchase of6 completes its purchase of6 's purchase of the 37 percent of(6) last week purchased rival Marshalls from(5) 's purchase of S.G. Warburg Group Plc ,5 's $ 5.4 billion purchase of=== acquisition ===41 's acquisition of21 's proposed acquisition of11 's planned acquisition of6 's $ 3.7 billion acquisition of(5) , Dresdner Bank AG 's planned acquisitionof5 's pending acquisition of5 completed the $1 billion stock acquisition ofFigure 4.
Gathered phrases using keywords(* indicates reverse relation, () indicates it is notparaphrase of the other phrases in the set)=== Union Pacific Corp. Southern Pacific Rail Corp.8 - in its takeover by2 + agreed to buy2 + said it will buy=== United Airlines UAL26 - , the parent of5 - , parent of4 - , the holding company for=== Eastern Group Plc Hanson Plc13 + , has agreed to be acquired by8 + , now owned by2 - to acquire2 - 's agreement to buy=== American Airlines AMR18 - , the parent of4 - , the holding company for2 - , the parent company of=== International Business Machines Corp. LotusDevelopment Corp.3 + said it would buy2 + 's bid for2 - agreed to be bought byFigure 5.
Examples of NE instance pairs for links?+?
indicates the same order of NEs,?-?
indicates the reverse order87
