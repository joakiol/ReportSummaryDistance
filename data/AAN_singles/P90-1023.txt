LAZY UNIFICATIONKurt GoddenComputer Science DepartmentGeneral Motors Research LaboratoriesWarren, MI 48090-9055, USACSNet: godden@gmr.comABSTRACTUnification-based NL parsers that copyargument graphs to prevent their destructionsuffer from inefficiency.
Copying is themost expensive operation in such parsers,and several methods to reduce copying havebeen devised with varying degrees ofsuccess.
Lazy Unification is presented hereas a new, conceptually elegant solution thatreduces copying by nearly an order ofmagnitude.
Lazy Unification requires no newslots in the structure of nodes, and onlynominal revisions to the unif icationalgorithm.PROBLEM STATEMENTdegradation in performance.
Thisperformance drain is illustrated in Figure 1,where average parsing statistics are given forthe original implementation of graphunification in the TASLINK natural languagesystem.
TASLINK was built upon the LINKparser in a joint project between GM Researchand the University of Michigan.
LINK is adescendent of the MOPTRANS systemdeveloped by Lytinen (1986).
The statisticsbelow are for ten sentences parsed byTASLINK.
As can be seen, copying consumesmore computation time than unification.20.019 91%Unification is widely used in naturallanguage processing (NLP) as the primaryoperation during parsing.
The datastructures unified are directed acyelicgraphs (DAG's), used to encode grammarrules, lexical entries and intermediateparsing structures.
A crucial pointconcerning unification is that the resultingDAG is constructed irectly from the rawmaterial of its input DAG's, i.e.
unificationis a destructive operation.
This is especiallyimportant when the input DAG's are rules ofthe grammar or lexical items.
If nothingwere done to prevent their destructionduring unification, then the grammar wouldno longer have a correct rule, nor the lexicona valid lexical entry for the DAG's inquestion.
They would have been transformedinto the unified DAG as a side effect.The simplest way to avoid destroyinggrammar rules and lexical entries byunification is to copy each argument DAGprior to calling the unification routine.
Thisis sufficient to avoid the problem ofdestruction, but the copying itself thenbecomes problematic, causing severeb/ .17VoI- Unification ?
Copying \ [ \ ]  Other jFigure 1.
Relative Cost ofOperations during ParsingPAST SOLUTIONSImproving the efficiency of unificationhas been an active area of research inunification-based NLP, where the focus hasbeen on reducing the amount of DAG copying,and several approaches have arisen.Different versions of structure sharing wereemployed by Pereira (1985) as well asKarttunen and Kay (1985).
In Karttunen(1986) structure sharing was abandoned fora technique allowing reversible unification.Wroblewski (1987) presents what he calls anon-destructive unification algorithm thatavoids destruction by incrementally copyingthe DAG nodes as necessary.180All of these approaches to the copyingproblem suffer from difficulties of theirown.
For both Pereira and Wroblewski thereare special cases involving convergent arcs--ares from two or more nodes that point to thesame destination node--that still require fullcopying.
In Karttunen and Kay's version ofstructure sharing, all DAG's are representedas binary branching DAG's, even thoughgrammar rules are more natural lyrepresented as non-binary structures.Reversible unification requires two passesover the input DAG's, one to unify them andanother to copy the result.
Furthermore, inboth successful and unsuccesful unificationthe input DAG's must be restored to theiroriginal forms because reversible unificationallows them to be destructively modified.Wroblewski points out a usefuldistinction between early copying and overcopying.
Early copying refers to the copyingof input DAG's before unification is applied.This can lead to ineff ic iency whenunification fails because only the copying upto the point of failure is necessary.
Overcopying refers to the fact that when the twoinput DAG's are copied they are copied intheir entirety.
Since the resultant unifiedDAG generally has fewer total nodes than thetwo input DAG's, more nodes than necessarywere copied to produce the result.Wroblewski's algorithm eliminates earlycopying entirely, but as noted above it canpartially over copy on DAG's involvingconvergent arcs.
Reversible unification mayalso over copy, as will be shown below.LAZY UNIFICATIONI now present Lazy Unification (LU)as a new approach to the copying problem.
Inthe following section I will present statisticswhich indicate that LU accomplishes nearlyan order of magnitude reduction in copyingcompared to non-lazy, or eager unification(EU).
These results are attained by turningDAG's into active data structures toimplement he lazy evaluation of copying.Lazy evaluation is an optimizationtechnique developed for the interpretation offunctional programming languages (Field and181Harrison, 1988), and has been extended totheorem proving and logic programming inattempts to integrate that paradigm withfunctional programming (Reddy, 1986).The concept underlying lazy evaluationis simple: delay the operation beingoptimized until the value it produces isneeded by the calling program, at whichpoint the delayed operation is forced.
Theseactions may be implemented by high-levelprocedures called delay and force.
Delay isused in place of the original call to theprocedure being optimized, and force isinserted into the program at each locationwhere the results of the delayed procedureare needed.Lazy evaluation is a good technique forthe copying problem in graph unificationprecisely because the overwhelming majorityof copying is unnecessary.
If all copying canbe delayed until a destructive change isabout to occur to a DAO, then both earlycopying and over copying can be completelyel iminated.The delay operat ion is easi lyimplemented by using closures.
A closure isa compound object that is both procedure anddata.
In the context of LU, the data portionof a closure is a DAG node.
The proceduralcode within a closure is a function thatprocesses a variety of messages sent to theclosure.
One may generally think of theencapsulated procedure as being a suspendedcall to the copy function.
Let us refer tothese closures as active nodes as contrastedwith a simple node not combined with aprocedure in a closure.
The delay functionreturns an active node when given a simplenode as its argument.
For now let us assumethat delay behaves as the identity functionwhen applied to an active node.
That is, itreturns an active node unchanged.
As amnemonic we will refer to the delay functionas delay-copy-the-dag.We now redefine DAG's to  allow eithersimple or active nodes wherever simplenodes were previously allowed in a DAG.
Anactive node will be notated in subsequentdiagrams by enclosing the node in anglebrackets.In LU the unification algorithm proceedslargely as it did before, except that at everypoint in the algorithm where a destructivechange is about to be made to an active node,that node is first replaced by a copy of itsencapsulated node.
This replacement ismediated through the force function, whichwe shall call force-delayed-copy.
In the caseof a simple node argument force-delayed-copy acts as the identity function, but whengiven an active node it invokes the suspendedcopy procedure with the encapsulated nodeas argument.
Force-delayed-copy returnsthe DAG that results from this invocation.To avoid copying an entire DAG whenonly its root node is going to be modified byunification, the copying function is alsorewritten.
The new version of copy-the-dagtakes an optional argument to control howmuch of the DAG is to be copied.
The defaultis to copy the entire argument, as one wouldexpect of a function called copy-the-dag.But when copy-the-dag is called from insidean active node (by force-delayed-copyinvoking the procedural portion of the activenode), then the optional argument issupplied with a flag that causes copy-the-dag to copy only the root node of itsargument.
The nodes at the ends of theoutgoing arcs from the new root becomeactive nodes, created by delaying theoriginal nodes in those positions.
Notraversal of the DAG takes place and thedeeper nodes are only present implicitlythrough the active nodes of the resultingDAG.
This is illustrated in Figure 2.v _~gJbecomes<b>a2<><c>"~<d>Figure 2.
Copy-the-dag on 'a' fromInside an Active NodeHere, DAG a was initially encapsulatedin a closure as an active node.
When a isabout to undergo a destructive change bybeing unified with some other DAG, force-delayed-copy activates the suspended call tocopy-the-dag with DAG a as its firstargument and the message de lay -ares  as itsoptional argument.
Copy-the-dag then copiesonly node a, returning a2 with outgoing arcspointing at active nodes that encapsulate theoriginal destination nodes b, e, and d. DAGa2 may then be unified with another DAGwithout destroying DAG a, and theunification algorithm proceeds with theactive nodes <b>, <c>, and <d>.
As thesesubdag's are modified, their nodes arelikewise copied incrementally.
Figure 3illustrates this by showing DAG a2 a f te runifying <b>.
It may be seen that as activenodes are copied one by one, the resultingunified DA(3 is eventually constructed.b2a2~i<c>"~<d>Figure 3.
DAG a2 after Unifying <b>One can see how this scheme reduces theamount of copying if, for example,unification fails at the active node <e>.
Inthis case only nodes a and b will have beencopied and none of the nodes e, d, e, f, g, orh.
Copying is also reduced when unificationsucceeds, this reduction being achieved intwo ways.182First, lazy unification only creates newnodes for the DAG that resu l t s  fromunification.
Generally this DAG has fewertotal nodes than the two input DAG's.
Forexample, if the 8-node DAG a in Figure 2were unified with the 2-node DAG a - -> i ,  thenthe resulting DAG would have only ninenodes, not ten.
The result DAG would havethe arc ' - -> i '  copied onto the 8-node DAG'sroot.
Thus, while EU would copy all tenoriginal nodes, only nine are necessary forthe result.Active nodes that remain in a final DAGrepresent the other savings for successfulunification.
Whereas EU copies all tenoriginal nodes to create the 9-node result,LU would only create five new nodes duringunification, resulting in the DAG of Figure 4.Note that the "missing" nodes e, f, g, and hare implicit in the active nodes and did notrequire copying.
For larger DAG's, this kindof savings in node copying can be significantas several large sub-DAG's may surviveuncopied in the final DAG .<b>a2 ~ <c>Figure 4.
Saving Four Node Copieswith Active NodesA useful comparison with Karttunen'sreversible unification may now be made.Recall that when reversible unification issuccessful the resulting DAG is copied andthe originals restored.
Notice that thiscopying of the entire resulting DAG mayovercopy some of the sub-DAG's.
This isevident because we have just seen in LU thatsome of the sub-DAG's of a resulting DAGremain uncopied inside active nodes.
Thus,LU offers less real copying than reversibleuni f icat ion.Let us look again at DAG a in Figure 2and discuss a potential problem with lazyunification as described thus far.
Let ussuppose that through unification a has beenpartially copied resulting in the DAG shownin Figure 5, with active node <f> about to becopied.b2 02a2 ~< f > ~  h2d>Figure 5.
DAG 'a' Partially CopiedRecall from Figure 2 that node f points ate.
Following the procedure described above,<f> would be copied to f2 which would thenpoint at active node <e>, which could lead toanother node e 3 as shown in Figure 6.
Whatis needed is some form of memory  torecognize that e was already copied once andthat f2 needs to point at e2 not <e>.b2 e2b c<a2 ~ ~t 2 - - - - .
-~~ h2d>Figure 6.
Erroneous Splitting of Nodee into e2 and e3This memory is implemented with a copyenvironment,  which is an association listrelating original nodes to their copies.Before f2 is given an arc pointing at <e>, thisalist is searched to see if e has already beencopied.
Since it has, e2 is returned as thedestination node for the outgoing arc fromf2, thus preserving the topography of theoriginal DAG.183Because there are several DAG's thatmust be preserved during the course ofparsing, the copy environment cannot beglobal but must be associated with each DAGfor which it records the copying history.This is accompl ished by encapsulating aparticular DAG's copy environment in eachof the active nodes of that DAG.
Lookingagain at Figure 2, the active nodes for DAGa2 are all created in the scope of a variablebound to an initially empty association listfor a2 's  copy environment.
Thus, theclosures that implement the active nodes<b>, <c>, and <d> all have access to the samecopy environment.
When <b> invokes thesuspended call to copy- the-dag ,  thisfunction adds the pair (b .
b2) to  the copyenvironment as a side effect before returningits value b2.
When this occurs, <c> and <d>instantly have access to the new pair throughtheir shared access to the same copyenvironment.
Furthermore, when new activenodes are created as traversal of the DAGcontinues during unification, they are alsocreated in the scope of the same copyenvironment.
Thus, this alist is pushedforward deeper into the nodes of the parentDAG as part of the data portion of each activenode.Returning to Figure 5, the pair (e .
e2)was added to the copy environment beingmaintained for DAG a 2 when e was copied toe2.
Active node <f> was created in the scopeof this list and therefore "remembers" at thetime f2 is created that it should point to thepreviously created e2 and not to a new activenode <e>.There is one more mechanism needed tocorrectly implement copy environments.
Wehave already seen how some active nodesremain after unification.
As intermediateDAG's  are  reused  dur ing  thenondeterminist ic  parsing and are unif iedwith other DAG's, it can happen that some ofthese remain ing  act ive nodes becomedescendents of a root different from theiroriginal root node.
As those new root DAG'sare incrementally copied during unification,a situation can arise whereby an activenode's parent node is copied and then an184attempt is made to create an active node outof an active node.For example, let us suppose that the DAGshown in Figure 5 is a sub-DAG of somelarger DAG.
Let us refer to the root of thatlarger DAG as node n. As unification of nproceeds,  we may reach a2  and startincremental ly  copying it.
This couldeventually result in c2 being copied to c3 atwhich point the system will attempt to createan outgoing arc for c3 pointing at a newlycreated active node over the already activenode <f>.
There is no need to try to createsuch a beast as <<f>>.
Rather, what is neededis to assure that active node <f> be givenaccess to the new copy environment for npassed down to <f> from its predecessornodes .
Th is  is accompl i shed  bydestructively merging the new copyenvironment with that previously created fora2 and surviving inside <f>.
It is importantthat this merge be destructive in order togive all active nodes that are descendents ofn access to the same information so that theproblem of node splitt ing i l lustrated inFigure 6 continues to be avoided.It was mentioned previously how calls toforce-delayed-copy must be inserted into theun i f i ca t ion  a lgor i thm to invoke  theincremental copying of nodes.
Anothermodi f icat ion to the a lgor i thm is alsonecessary as a result of this incrementalcopying.
Since active nodes are replaced bynew nodes in the middle of unification, thealgorithm must undergo a revision to effectthis replacement.
For example, in Figure 5in order for <b> to be replaced by b2,  thecorresponding arc from a2 must be replaced.Thus as the unification algorithm traverses aDAG, it also collects such replacements inorder to reconstruct the outgoing arcs of aparent DAG.In addition to the message delay-arcssent to an active node to invoke thesuspended call to copy- the-dag,  othermessages are needed.
In order to compareact ive nodes and merge their  copyenvironments, the active nodes must processmessages that cause the active node to returneither its encapsulated node's label  or theencapsulated copy environment.
40000EFFECTIVENESS OF LAZYUNIF ICAT IONLazy Unification results in an impressivereduction to the amount of copying duringparsing.
This in turn reduces the overallslice of parse time consumed by copying ascan be seen by contrasting Figure 7 withFigure 1.
Keep in mind that these chartsillustrate proportional computations, notspeed.
The pie shown below should beviewed as a smaller pie, representing fasterparse times, than that in Figure 1.
Speed isdiscussed below.45.78%18.67%J l~ Unification ?
Copying \ [ \ ]  Other I "Figure 7.
Relative Cost of Operationswith Lazy UnificationLazy Unification copies less than 7% ofthe nodes copied under eager unification.However, this is not a fair comparison withEU because LU substitutes the creation ofactive nodes for some of the copying.
To get atruer comparison of Lazy vs. EagerUnification, we must add together thenumber of copied nodes and active nodescreated in LU.
Even when active nodes aretaken into account, the results are highlyfavorable toward LU because again less than7% of the nodes copied under EU areaccounted for by active nodes in LU.Combining the active nodes with copies, LUstill accounts for an 87% reduction overeager unification.
Figure 8 graphicallyillustrates this difference for ten sentences.30000Numberof 20000Nodes10000Eager Lazy ActiveCopies Copies NodesFigure 8.
Comparison of Eager vs .Lazy UnificationFrom the time slice of eager copyingshown in Figure 1, we can see that if LU wereto incur no overhead then an 87% reductionof copying would result in a faster parse ofroughly 59%.
The actual speedup is about50%, indicating that the overhead ofimplementing LU is 9%.
However, the 50%speedup does not consider the effects ofgarbage collection or paging since they aresystem dependent.
These effects will bemore pronounced in EU than LU because inthe former paradigm more data structuresare created and referenced.
In practice,therefore, LU performs at better than twicethe speed of EU.There are several sources of overhead inLU, The major cost is incurred indistinguishing between active and simplenodes.
In our Common Lisp implementationsimple DAG nodes are defined as namedstructures and active nodes as closures.Hence, they are distinguished by the Lisppredicates DAG-P and FUNCTIONP.Disassembly on a Symbolics machine showsboth predicates to be rather costly.
(Thefunctions TYPE-OF and TYPEP could alsobe used, but they are also expensive.
)185Another expensive operation occurs whenthe copy environments in active nodes aresearched.
Currently, these environments aresimple association lists which requiresequential searching.
As was discussedabove, the copy environments mustsometimes be merged.
The merge functionpresently uses the UNION function.
While afar less expensive destructive concatenationof copy environments could be employed, theunion operation was chosen initially as asimple way to avoid creation of circular listsduring merging.All of these sources of overhead can andwill be attacked by additional work.
Nodescan be defined as a tagged data structure,allowing an inexpensive tag test todistinguish between active and inactivenodes.
A non-sequential data structurecould allow faster than linear searching ofcopy environments and more eff icientmerging.
These and additional modificationsare expected to eliminate most of theoverhead incurred by the currentimplementation of LU.
In any case, LazyUnification was developed to reduce theamount of copying during unification and wehave seen its dramatic success in achievingthat goal.CONCLUDING REMARKSThere is another optimization possibleregarding certain leaf nodes of a DAG.Depending on the application using graphunification, a subset of the leaf nodes willnever be unified with other DAG's.
In theTASLINK application these are nodesrepresenting such features as third personsingular.
This observation can be exploitedunder both lazy and eager unification toreduce both copying and active nodecreation.
See Godden (1989) for details.It has been my experience that usinglazy evaluation as an optimization techniquefor graph unification, while elegant in theend result, is slow in development time dueto the difficulties it presents for debugging.This property is intrinsic to lazy evaluation,(O'Donnell and Hall, 1988).186The problem is that a DAG is nolonger copied locally because the copyoperation is suspended in the active nodes.When a DAG is eventually copied, thatcopying is performed incrementally andtherefore non-locally in both time andprogram space.
In spite of this distributednature of the optimized process, theprogrammer continues to conceptualize theoperation as occurring locally as it wouldoccur in the non-optimized eager mode.
As aresult of this mismatch between theprogrammer's visualization of the operationand its actual execution, bugs arenotoriously diff icult to trace.
Thedevelopment time for a program employinglazy evaluation is, therefore, much longerthan would be expected.
Hence, thistechnique should only be employed when thepossible efficiency gains are expected to belarge, as they are in the case of graphunification.
O'Donnell and Hall present anexcellent discussion of these and otherproblems and offer insight into how toolsmay be built to alleviate some of them.REFERENCESField, Anthony J. and Peter G. Harrison.1988.
Functional Programming.
Reading,MA: Addison-Wesley.Godden, Kurt.
1989.
"Improving theEfficiency of Graph Unification."
Internaltechnical report GMR-6928.
General MotorsResearch Laboratories.
Warren, MI.Karttunen, Lauri.
1986.
D-PATR: ADevelopment Environment for Unification-Based Grammars.
Report No.
CSLI-86-61.Stanford, CA.Karttunen, Lauri and Martin Kay.
1985.
"Structure-Sharing with Binary Trees.
"Proceedings of the 23 rd Annual Meeting ofthe Association for  ComputationalLinguistics.
Chicago, IL: ACL.
pp.
133-136A.Lytinen, Steven L. 1986.
"DynamicallyCombining Syntax and Semantics in NaturalLanguage Processing."
Proceedings of the5 t h National Conference on ArtificialIntelligence.
Philadelphia, PA- AAAI.
pp.574-578.O'Donnell, John T. and Cordelia V. Hall.1988.
"Debugging in ApplicativeLanguages."
Lisp and Symbolic Computation,1/2.
pp.
113-145.Pereira, Fernando C. N. 1985.
"AStructure-Sharing Representation forUnification-Based Grammar Formalisms.
"Proceedings of the 23 rd Annual Meeting ofthe Association for ComputationalLinguistics.
Chicago, IL: ACL.
pp.
137-144.Reddy, Uday S. 1986.
"On theRelationship between Logic and FunctionalLanguages," in Doug DeGroot and GaryLindstrom, eds.
Logic Programming :Functions, Relations, and Equations.Englewood Cliffs, NJ.
Prentice-Hall.
pp.
3-36.Wroblewski, David A.
1987.
"Nondestructive Graph Unif ication.
"Proceedings of the 6 th National Conferenceon Artificial Intelligence.
Seattle, WA:AAAI.
pp.
582-587.187
