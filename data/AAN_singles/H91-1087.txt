Interactive Multimedia Explanation forEquipment Maintenance and RepairKathteen McKeown and Steven FeinerDepar tment  o f  Computer  Sc ience450 Computer  Sc ience Bu i ld ingCo lumbia  Un ivers i tyNew York ,  N.Y .
10027PROJECT GOALSWe are developing COMET, an interactive system thatgenerates multimedia explanations of how to operate, maintain,and repair equipment.
Our research stresses the dynamic genera-tion of the content and form of all material presented, addressingissues in the generation of text and graphics, and in coordinatingtext and graphics in an integrated presentation.COMET contains a static knowledge base describing objectsand plans for maintenance and repair, and a dynamic knowledgesource for diagnosing failures.
Explanations are produced usinga content planner that determines what information should becommunicated, a media coordinator that determines which infor-marion should be realized in graphics and which in text, andseparate t xt and graphics generators.
The graphics and text for asingle explanation are laid out on the screen by a media layoutcomponent.
A menu interface allows users to request explana-tions of specific procedures or to specify failure symptoms thatwill invoke a diagnostic omponent.
The diagnostic omponentcan ask the user to carry out procedures that COMET will explainif requested.
In contrast o hypermedia systems that presentpreviously authored material, COMET has underlying models ofthe user and context hat allow each aspect of the explanationgenerated tobe based on the current situation.Our focus in the text generation component has been on thedevelopment of the Functional Unification Formalism (FFUF) fornon-syntactic tasks, of a large syntactic grammar in FUF, oflexical choice in FUF using constraints from underlyingknowledge sources and from past discourse, and of models ofconstraints on several classes of word?
choice.
Important resultsin knowledge-based graphics generation include the automateddesign of 3D technical illustrations that contain nested insets,algorithms for and rule-based application of illustrative tech-niques such as cutaway views, a design-grid--based methodology?
for display layout, and development of a testbed for knowledge-based animation.Finally, we have had significant results in the development ofour media coordinator which, unlike other systems, features acommon description language that allows a fine-grained divisionof information between text and graphics.
The media coordinatormaps information to media specific resources, and allows infor-marion expressed in one media to influence realization in theother.
This allows for tight integration and coordination betweendifferent media.RECENT RESULTS?
Incorporated user model constraints on word selection inorder to use words appropriate ouser's vocabulary level.This includes both word substitution and replanning ofsentence content when there is no word that can be sub-stituted for unknown word (e.g., "Check the polarity."
isreplaced by "Make sure the plus lines up with the plus.")?
Completed sentence-picture coordination, allowing longersentences to be broken into shorter ones that canseparately accompany each generated picture when neces-sal T .?
Added all m&r procedures for the radio from the manualto the knowledge base and augmented the lexicon to in-elude new words for the procedures.?
Continued implementation of cross-references betweentext and graphics, including query facilities for thegraphics representation that allow the text generator todetermine where and how an object is displayed, use ofthese facilities along with the underlying knowledge baseto construct cross-references ( .g., "The battery is shownin the cutaway view of the radio.
"), and development of alexicon for such cross-references.?
Extended the graphics generator to support the main-tenanee of visibility constraints through a set of illustra-tive techniques modeled after those used by technicalillustrators.
These involve detecting objects that obscurethose that must remain visible and rendering the obscur-ing objects using transparency, cutaway views, and"ghosting" effects.
The effects are invoked automati-cally as the graphics generator designs its illustrations.?
Developed facilities for dynamic llustrations that are in-erementally redesigned to allow users to explore thegenerated pictures by choosing viewpoints different fromthose selected by the system.PLANS FOR THE COMING YEARWe plan to finish implementation f cross references betweentext and graphics, to increase the ways in which the user modelcan influence lexical choice, and to incorporate all extensions aspart of our demo system.
Following that, we will move to a newcontract, where we will begin work on identifying usage con-straints on a variety of lexical classes through automatic andmanual examination of large text corpora.413
