Proceedings of the 6th EACL Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 101?106,Avignon, France, 24 April 2012. c?2012 Association for Computational LinguisticsAdapting Wikification to Cultural HeritageSamuel Fernando and Mark StevensonDepartment of Computer ScienceRegent Court211 PortobelloSheffield, S1 4DPs.fernando@shef.ac.ukm.stevenson@dcs.shef.ac.ukAbstractLarge numbers of cultural heritage itemsare now archived digitally along with ac-companying metadata and are available toanyone with internet access.
This informa-tion could be enriched by adding links toresources that provide background informa-tion about the items.
Techniques have beendeveloped for automatically adding linksto Wikipedia to text but the methods aregeneral and not designed for use with cul-tural heritage data.
This paper explores arange of methods for adapting a system foradding links to Wikipedia to cultural her-itage items.
The approaches make use ofthe structure of Wikipedia, including thecategory hierarchy.
It is found that an ap-proach that makes use of Wikipedia?s linkstructure can be used to improve the qualityof the Wikipedia links that are added.1 IntroductionCultural heritage (CH) items are now increasinglybeing digitised and stored online where they canbe viewed by anyone with a web browser.
Theseitems are usually annotated with metadata whichgives the title of the item, subject keywords, de-scriptions and so on.
However such metadatacan often be very limited, with some items hav-ing very little metadata at all.
This paper exam-ines methods to enrich such metadata with inlinelinks to Wikipedia.
These links allow users to findinteresting background information on the itemsand related topics, and provides a richer expe-rience especially where the metadata is limited.Additionally the links may also help to categoriseand organise the collections using the Wikipediacategory hierarchy.CH items from Europeana1 are used for theevaluation.
Europeana is a large online aggrega-tion of cultural heritage collections from acrossEurope.
The WikiMiner software (Milne andWitten, 2008) is used to automatically enrichthe Europeana items collections with Wikipedialinks.
Two methods are used to improve thequality of the links.
The first makes use of theWikipedia category hierarchy.
Top-level cate-gories of interest are selected and articles closeto these categories are used as training data forWikiMiner.
The second method uses existinglinks from Wikipedia as evidence to find usefullinks for the CH items.2 BackgroundMihalcea and Csomai (2007) first addressed thetask of automatically adding inline Wikipedialinks into text and coined the term Wikificationfor the process.
Their procedure for wikificationused two stages.
The first stage was detection,which involved identifying the terms and phrasesfrom which links should be made.
The most ac-curate method for this was found to be using linkprobability, defined as the number of Wikipediaarticles that use the term as an anchor, divided bythe number of Wikipedia articles that mention itat all.
The next stage, disambiguation ensure thatthe detected phrases link to the appropriate arti-cle.
For example the term plane usually links toan article about fixed wing aircraft.
However itsometimes points to a page describing the mathe-matical concept of a theoretical surface, or of thetool for flattening wooden surfaces.
To find thecorrect destination a classifier is trained using fea-tures from the context.
Although the quality of re-1http://www.europeana.eu101sults obtained is very good, a large amount of pre-processing is required, since the entire Wikipediaencyclopedia must be parsed.Milne and Witten (2008) build upon this previ-ous work with the WikiMiner program.
The soft-ware is trained on Wikipedia articles, and thuslearns to disambiguate and detect links in thesame way as Wikipedia editors.
Disambiguationof terms within the text is performed first.
Amachine-learning classifier is used with severalfeatures.
The main features used are commonnessand relatedness, as in Medelyan et al (2008).
Thecommonness of a target sense is defined by thenumber of times it is used a destination from someanchor text e.g.
the anchor text ?Tree?
links to thearticle about the plant more often than the math-ematical concept and is thus more common.
Re-latedness gives a measure of the similarity of twoarticles by comparing their incoming and outgo-ing links.
The performance achieved using theirapproach is currently state of the art for this task.The WikiMiner software is freely available2, andhas been used as the basis for the approaches pre-sented here.Recent work on named entity linking and wik-ification makes use of categories and link infor-mation (Bunescu and Pasca, 2006; Dakka andCucerzan, 2008; Kulkarni et al, 2009).
Wikifi-cation has also been applied to the medical do-main (He et al, 2011).
Wikipedia categories andlinks have been used previously to find the sim-ilarity between CH items (Grieser et al, 2011).The category retraining approach presented herediffers in that it only makes use of the top-levelcategories.3 MethodsThree approaches to improving the quality ofWikipedia links added by WikiMiner were devel-oped.
The first two make use of Wikipedia?s cat-egory structure while the third uses the links be-tween Wikipedia articles.3.1 Wikipedia CategoriesAlmost all articles in Wikipedia are manually as-signed to one or more categories.
For example thepage ALBERT EINSTEIN belongs to the categoriesSwiss physicists, German-language philoso-phers and several others.
The category pages thus2http://wikipedia-miner.cms.waikato.ac.nz/group together articles of interest.
Furthermore,each category may itself be a sub-category of oneor more categories.
So for example Swiss physi-cists is a sub-category of the categories Swissscientists, Physicists by nationality etc.The categories give a general indication of thetopic of the article and we assume that articles rel-evant to Cultural Heritage items are likely to beclosely associated with certain categories.3.2 Retraining using CategoriesThe first approach is to retrain WikiMiner us-ing articles associated with particular categories.Three top-level categories manually judged to in-dicate articles that are relevant to cultural her-itage were selected: Culture, Arts and Human-ities.
All articles within 2 links of these selectedcategories were found and used as training datafor WikiMiner.
(We also explored using differ-ent numbers of links but found that fewer than2 links produced a very small number of arti-cles while more than 2 generated very large num-bers which would be prohibitively expensive forretraining.)
The same approach was also testedwith categories which are unlikely to be related tocultural heritage (Computers, Mathematics andScience) in order to test the effect of using dif-ferent categories.3.3 Filtering using CategoriesThis approach uses the category information tofilter articles after WikiMiner has been run.
Eacharticle added by WikiMiner is examined and anywhich are more than a certain distance from a top-level category which has been identified as beingrelevant to cultural heritage is removed.
The as-sumption behind this approach is that relevant ar-ticles are much more likely to be closely associ-ated with these categories than ones which are notrelevant.3.4 Exploiting Wikipedia?s Link StructureThe final method makes use of Wikipedia?s linkstructure rather than the category hierarchy and issimilar to the previous method since it filters thelinks added by WikiMiner to identify those whichare relevant to a particular article.The first stage is to run the item throughWikiMiner to detect suitable links.
This is donewith 2 parameter settings, each returning a set oflinks.
The aim of the first run is to find as many102!"#$%&'(%#)*+,$-./0$-1+/(-#23$++$)&456&+#-(#+7'*%$89&4:;(3"(%<7!"#$%&#'"!"#$%&'()%*+',"+%-./'0$*11*-'2#3%%#/'4*35/'6*3#7'4*3517"3%289:%;#&',"+%-.<%1;3"=#"*+&'>?#%3"*3'@"%A'*B'#7%';.+*=CD0$-1=.#8/#%&>$+#8/&5/#*.-#&?*;3&@-#<<A(""3#+:-$;</B(%"3#9C&,$-./&0$-1+/(-#&!
"!#$#Figure 1: Example illustrating the method, where articles (on the left) which link to the high precision articles(SP ) are used to find good links in the high recall set (SR).potential links in the text as possible, for exampleby using a low confidence threshold.
This give aset of links SR which is high recall (because mostlinks are included), but low precision, since manyincorrect or irrelevant links are also present.
Theaim of the second run is to find a smaller set oflinks which are likely to be of good quality, forexample by setting a high confidence threshold.The resulting set SP is high precision but lowerrecall since good links may be discarded.The result set of links is initialised with the highprecision articles R = SP .
The aim is then to tryto find additional good links within SR.
This isdone by finding a list of articles AP which con-tain links to 1 or more of the articles in SP .
LetO(a) be the set of outlinks from an article a. Eacharticle inAP is then scored on how many links areshared with SP :?a ?
AP : score(a) = |O(a) ?
SP | (1)The N top scoring articles in AP are then usedto find further good links with within SR. Foreach of these articles a:R ?
?= R ?
(O(a) ?
SR) (2)Figure 1 gives an example illustrating how themethod works on an Europeana item about anold Odeon Cinema in York.
The article on PaulGregg links to the articles in the SP set {OdeonCinemas, North Yorkshire}.
Since it also linksto the York article in the SR set, the method takesthis as evidence that Yorkmight also be a good ar-ticle to link to, and so this would be added to theresult set R.4 AnnotationTo evaluate the quality of the Wikipedia links, asample of CH items was manually annotated.
Thesample of 21 items was randomly selected fromEuropeana.
When run through WikiMiner withno probability threshold (i.e.
including all possi-ble links), a total of 366 potential links were iden-tified.
A further 16 links were manually addedwhich the WikiMiner software had missed, givinga total of 381 links.Web surveys were created to allow the annota-tors to judge the links.
For each item in the surveyusers were presented with a picture of the item,the metadata text, and the set of possible links(with the anchor text identified).
The annotatorswere then given a binary choice for each link todecide if it should be included or not.Two separate surveys were taken by three flu-ent English speakers.
The first was to determine ifeach link was correctly disambiguated within thecontext of the item (regardless of whether the linkwas useful or appropriate for that item).
For eachlink the majority decision was used to judge if thelink was indeed correct or not.
Out of the 381links, 70% were judged to be correct and 30% asincorrect.
For 80% of the links the judgement wasunanimous with all 3 annotators agreeing on thecorrectness of the links.
The remaining 20% were2-to-1 judgements.
This gives an overall inter-annotator agreement of 93.4%.The second survey was to determine which ofthe correct links were useful and appropriate for103the corresponding items.
As before each of the21 items was presented to the annotators, but thistime only with the 267 links that had been judgedas correct within the previous survey.
Again,three annotators completed the survey.
Out of the267 correct links, 49.8% were judged to be use-ful/appropriate and 50.2% as not.
For 67.7% ofthe links the judgement was unanimous.
The re-maining 32.2% were 2-1 judgements.
This givesan inter-annotator agreement of 89.3%.
The 133links judged to be correct, useful and appropriatewere then used as the gold standard to evaluate theautomatic methods.As an example, the links and judgements forthe following text are shown in Table 1:Title: Odeon Cinema, Blossom Street, York,North YorkshireSubject: CinemaDescription: Exterior view of the canopy.Link Correct UsefulOdeon Cinemas Yes YesBlossom (TV series) No N/AYork Yes YesNorth Yorkshire Yes NoCinema Yes NoCanopy Yes YesTable 1: Examples of links and judgements5 ExperimentsThe methods from Section 3 were used to identifylinks in the items from Europeana.
The resultswere evaluated against the gold standard manu-ally annotated data that was described in Section4.
For all experiments the standard metrics of pre-cision, recall and F-measure are used to measurethe performance of the methods.Milne and Witten (2008) noted that training us-ing articles with a similar length and link densityto the target documents can improve WikiMiner?sperformance.
The descriptions associated withEuropeana items are relatively short so further ex-periments were carried out in which WikiMinerwas retrained with different sets of articles.
Thebest results were obtained using a set of arti-cles between 100 and 500 words that containeda minimum of five links to other articles.
(Re-sults for experiments comparing other configura-tions are not reported here for brevity.)
Table 2shows results obtained using the default model,when WikiMiner is run ?off the shelf?, and whenit has been retrained.
These results demonstratethat retraining WikiMiner improves performance.Precision improves to over 50% and, althoughthere is a drop in recall, F-measure is also higher.Results using the retrained model are used as abaseline against which alternative approaches arecompared.Model P R FDefault 34.0 91.7 49.6Retrained 56.6 77.4 65.4Table 2: Results obtained using WikiMiner using de-fault model and after retraining5.1 Category retrainingThe category retraining approach (Section 3.2)was applied using all articles within two links ofselected categories as training data forWikiMiner.The results are shown in Table 3 and show thatprecision is improved over the baseline for all cat-egories.
However the results do not fit the hy-pothesis, with Science giving the best F-measureoverall, a statistically significant improvementover the baseline (p < 0.05, t-test).
This may befor various reasons.
Firstly the category hierarchyin Wikipedia is often messy with articles assignedto many different categories, and each categorycan contain a diverse sets of articles which maynot be very useful.
Secondly it may be that thetopics of the articles are not so important for thetraining, but rather factors like the length of thearticles and the link densities.
However it is in-teresting that using articles close to the top levelcategories does appear to improve performance.Method P R FBaseline 56.6 77.4 65.4Culture 65.5 71.4 68.3Arts 69.6 65.4 67.4Humanities 71.9 65.4 68.5Mathematics 72.9 58.6 65.0Science 72.4 69.1 70.8Computers 76.7 59.4 66.9Table 3: Retraining using top level categories.1045.2 Category filteringThe category filtering approach (Section 3.3) wasapplied.
Articles within a distance of 1 to 4 linksfrom selected top level categories are kept andall others are discarded.
The following combina-tions of categories were used: C (Culture), CHA(Culture, Humanities and Arts), and CHAGSE(Culture, Humanities, Arts, Geography, Soci-ety and Education).Results are shown in Table 4 and are surpris-ingly low.
Both precision and recall drop signif-icantly when category filtering is applied.
Thismay be because the articles within categories areoften very diverse and do not capture many ofthe possible topics found within cultural heritageitems.Method Precision Recall FBaseline 56.6 77.4 65.4C 35.1 19.5 25.1CHA 27.4 27.8 27.6CHAGSE 24.5 34.6 28.7Table 4: Filtering using top level categories.5.3 Using Wikipedia linksThe final experiment explores the link filtering ap-proach described in Section 3.4.
The high preci-sion SP set is chosen to be those returned by theretrained WikiMiner model (?Retrained?
in Table2) while the high recall SR set is the default model(?Default?
in Table 2).
Experiments were per-formed varyingN , the number of top scoring arti-cles used (using the score metric defined in Equa-tion 1).No.
of similar articles P R FBaseline 56.6 77.4 65.41 74.0 53.4 62.02 70.7 61.7 65.93 68.5 63.9 66.14 67.4 68.4 67.95 66.9 69.9 68.46 66.2 70.6 68.47 66.2 70.7 68.48 65.5 71.4 68.39 65.1 71.4 68.110 63.9 72.9 68.1Table 5: Filtering using Wikipedia?s link structureThe results are shown in Table 5 and show aclear improvement in precision for N from 1 to 10.The F-measure peaks when 5-7 related articles areused.
The improvement in the F-measure overthe baseline is statistically significant (p < 0.05t-test).6 Conclusions and future workThis paper explores a variety of methods for im-proving the quality of Wikipedia links added bythe WikiMiner software when applied to the cul-tural heritage domain.
Approaches that makeuse of the Wikipedia category hierarchy and linkstructure were compared and evaluated using adata set of manual judgements created for thisstudy.The approaches based on the category hier-archy appeared to be less promising than thosewhich used the link structure.
Improvements wereobtained by retraining WikiMiner using articlesassociated with particular categories.
Howeverthe results were unexpected, with categories suchas Science giving better performance as train-ing data than categories such as Culture or Arts.Although a higher score was obtained using thismethod than the link approach, this may be due tofactors such as document length and link densityrather than the topic of the articles.Results obtained using a novel method basedon existing links within Wikipedia suggest thisapproach is promising.
The method is fully un-supervised so it can be easily applied to domainsother than cultural heritage.Information from both categories and linkscould be combined in a similar way to that sug-gested by Grieser et al (2011).
Enriching culturalheritage data with Wikipedia links should im-prove the experience for users while they browsethe data.
In addition the links themselves may beuseful to categorise, cluster and find similar items.Further work will investigate these possibilities.AcknowledgmentsThe research leading to these results wascarried out as part of the PATHS project(http://paths-project.eu) funded bythe European Community?s Seventh FrameworkProgramme (FP7/2007-2013) under grant agree-ment no.
270082.105ReferencesRazvan Bunescu and Marius Pasca.
2006.
UsingEncyclopedic Knowledge for Named Entity Dis-ambiguation.
In Proceedings of European Chap-ter of the Association of Computational Linguistics(EACL), volume 6, pages 9?16.Wisam Dakka and Silviu Cucerzan.
2008.
Augment-ing Wikipedia with Named Entity Tags.
In Pro-ceedings of The Third International Joint Confer-ence on Natural Language Processing (IJCNLP).Karl Grieser, Timothy Baldwin, Fabian Bohnert, andLiz Sonenberg.
2011.
Using Ontological and Doc-ument Similarity to Estimate Museum Exhibit Re-latedness.
Journal on Computing and Cultural Her-itage (JOCCH), 3(3):10.Jiyin He, Maarten de Rijke, Maarten de Rijke, Robvan Ommering, and Yuechen Qian.
2011.
Generat-ing Links to Background Knowledge: A Case StudyUsing Narrative Radiology Reports.
In 20th ACMConference on Information and Knowledge Man-agement (CIKM), pages 1867?1876, Glasgow.Sayali Kulkarni, Amit Singh, Ganesh Ramakrishnan,and Soumen Chakrabarti.
2009.
Collective An-notation of Wikipedia Entities in Web Text.
InProceedings of the 15th ACM SIGKDD Interna-tional Conference on Knowledge Discovery andData Mining, pages 457?466.Olena Medelyan, Ian H. Witten, and David Milne.2008.
Topic Indexing with Wikipedia.
In Proceed-ings of the Association for the Advancement of Ar-tificial Intelligence (AAAI) WikiAI workshop.Rada Mihalcea and Andras Csomai.
2007.
Wikify!
:Linking Documents to Encyclopedic Knowledge.In ACM Sixteenth Conference on Information andKnowledge Management (CIKM), volume 7, pages233?242.David Milne and Ian H. Witten.
2008.
Learning toLink with Wikipedia.
In Proceeding of the 17thACM conference on Information and KnowledgeManagement, pages 509?518.106
