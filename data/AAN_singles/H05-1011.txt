Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 81?88, Vancouver, October 2005. c?2005 Association for Computational LinguisticsA Discriminative Framework for Bilingual Word AlignmentRobert C. MooreMicrosoft ResearchOne Microsoft WayRedmond, WA 98052bobmoore@microsoft.comAbstractBilingual word alignment forms the foun-dation of most approaches to statisticalmachine translation.
Current word align-ment methods are predominantly basedon generative models.
In this paper,we demonstrate a discriminative approachto training simple word alignment mod-els that are comparable in accuracy tothe more complex generative models nor-mally used.
These models have the theadvantages that they are easy to add fea-tures to and they allow fast optimizationof model parameters using small amountsof annotated data.1 MotivationBilingual word alignment is the first step of mostcurrent approaches to statistical machine translation.Although the best performing systems are ?phrase-based?
(e.g, Och and Ney, 2004), possible phrasetranslations are normally first extracted from word-aligned bilingual text segments.
The standard ap-proach to word alignment makes use of various com-binations of five generative models developed atIBM by Brown et al (1993), sometimes augmentedby an HMM-based model or Och and Ney?s ?Model6?
(Och and Ney, 2003).
The best combinations ofthese models can produce high accuracy alignments,at least when trained on a large corpus of fairly di-rect translations in related languages.These standard models are less than ideal, how-ever, in a number of ways, two of which we addressin this paper.
First, although the standard models cantheoretically be trained without supervision, in prac-tice various parameters are introduced that shouldbe optimized using annotated data.
For, example,Och and Ney (2003) suggest supervised optimiza-tion of a number of parameters, including the prob-ablity of jumping to the empty word in the HMMmodel, as well as smoothing parameters for the dis-tortion probabilities and fertility probabilities of themore complex models.
Since the values of these pa-rameters affect the values of the translation, align-ment, and fertility probabilities trained by EM, thereis no effective way to optimize them other than torun the training procedure with a particular combi-nation of values and evaluate the accuracy of the re-sulting alignments.
Since evaluating each combina-tion of parameter values in this way can take hours todays on a large training corpus, it seems safe to saythat these parameters are rarely if ever truly jointlyoptimized for a particular alignment task.The second problem we address is the difficultyof adding features to the standard generative models.Generative models require a generative ?story?
as tohow the observed data is generated by an interrelatedset of stochastic processes.
For example, the gener-ative story for IBM Models 1 and 2 and the HMMalignment model is that a target language translationof a given source language sentence is generated byfirst choosing a length for the target language sen-tence, then for each target sentence position choos-ing a source sentence word, and then choosing thecorresponding target language word.
When Brownet al (1993) wanted to add a fertility component tocreate Models 3, 4, and 5, however, this generative81story didn?t fit any longer, because it does not in-clude how many target language words to align toeach source language word as a separate decision.To model this explicitly, they had to come up with adifferent generative story.In this paper, we take a different approach toword alignment, based on discriminative training ofa weighted linear combination of a small numberof features.
For a given parallel sentence pair, foreach possible word alignment considered, we sim-ply multiply the values of each of these features by acorresponding weight to give a score for that feature,and sum the features scores to give an overall scorefor the alignment.
The possible alignment havingthe best overall score is selected as the word align-ment for that sentence pair.
Thus, for a sentence pair(e, f) we seek the alignment a?
such thata?
= argmaxan?i=1?ifi(a, e, f)where the fi are features and the ?i are weights.We optimize the model weights using a modifiedversion of averaged perceptron learning as describedby Collins (2002).
This is fast to train, because se-lecting the feature weights is the last step in build-ing the model and the ?online?
nature of perceptronlearning allows the parameter optimization to con-verge quickly.
Furthermore, no generative story hasto be invented to explain how the features generatethe data, so new features can be easily added withouthaving to change the overall structure of the model.In theory, a disadvantage of a discrimintative ap-proach compared to a generative approach is thatit requires annotated data for training.
In practice,however, effective discriminative models for wordalignment require only a few parameters, which canbe optimized on a set of annotated sentence pairscomparable in size to what is needed to tune the freeparameters used in the generative approach.
As wewill show, a simple sequence of two such modelscan achieve alignment accuracy comparable to thatof a combination of more complex standard models.2 Discriminative Alignment ModelsWe develop two word alignment models, incorpo-rating different word association features intendedto indicate how likely two words or groups of wordsare to be mutual translations, plus additional featuresmeasuring how much word reordering is required bythe alignment1, and how many words are left un-linked.
One of the models also includes a featuremeasuring how often one word is linked to severalwords.Each of our feature scores have analogs in theIBM and HMM models.
The association scores cor-responds to word translation probabilities; the re-ordering scores correspond to distortion probabili-ties; the scores for words left unlinked correspondsto probabilities of words being linked to the nullword; and the scores for one-to-many links corre-spond to fertility probabilities.2.1 The Log-Likelihood-Based ModelIn our first model, we use a log-likelihood-ratio(LLR) statistic as our measure of word association.We chose this statistic because it has previously beenfound to be effective for automatically construct-ing translation lexicons (e.g., Melamed, 2000).
Wecompute LLR scores using the following formulapresented by Moore (2004):LLR(f, e) =?f??{f,?f}?e??
{e,?e}C(f?, e?)
log p(f?|e?)p(f?
)In this formula f and e mean that the words whosedegree of association is being measured occur in therespective target and source sentences of an alignedsentence pair, ?f and ?e mean that the correspond-ing words do not occur in the respective sentences,f?
and e?
are variables ranging over these values,and C(f?, e?)
is the observed joint count for the val-ues of f?
and e?.
All the probabilities in the for-mula refer to maximum likelihood estimates.
TheLLR score for a pair of words is high if the wordshave either a strong positive association or a strongnegative association.
Since we expect translationpairs to be positively associated, we discard anynegatively associated word pairs by requiring thatp(f, e) > p(f) ?
p(e).
To reduce the memory re-quirements of our algorithms we discard any wordpairs whose LLR score is less than 1.0.1We will use the term ?alignment?
to mean an overall wordalignment of a sentence pair, and the term ?link?
to mean thealignment of a particular pair of words or small group of words.82In our first model, the value of the word associa-tion feature for an alignment is simply the sum of allthe individual LLR scores for the word pairs linkedby the alignment.
The LLR-based model also in-cludes the following features:nonmonotonicity features It may be observedthat in closely related languages, word alignmentsof sentences that are mutual translations tend to beapproximately monotonic (i.e., corresponding wordstend to be in nearly corresponding sentence posi-tions).
Even for distantly related languages, thenumber of crossing links is far less than chance,since phrases tend to be translated as contiguouschunks.
To model these tendencies, we introducetwo nonmonotonicity features.To find the points of nonmonotonicity of a wordalignment, we arbitrarily designate one of the lan-guages as the source and the other as the target.
Wesort the word pairs in the alignment, first by sourceword position, and then by target word position.
Wethen iterate through the sorted alignment, lookingonly at the target word positions.
The points ofnonmonotonicity in the alignment will be the placeswhere there are backward jumps in this sequenceof target word positions.
For example, suppose wehave the sorted alignment ((1,1)(2,4)(2,5)(3,2)(5,6)).The sequence of target word positions in this sortedalignment is (1,4,5,2,6); hence, there is one point ofnonmonotonicity where target word position 2 fol-lows target word position 5.We still need to decide how to measure the degreeof nonmonotonicity of an alignment.
Two meth-ods immediately suggest themselves.
One is to sumthe magnitudes of the backward jumps in the targetword sequence; the other is to simply count the num-ber of backward jumps.
Rather than choose betweenthem, we use both features.the one-to-many feature It has often been ob-served that word alignment links tend to be one-to-one.
Indeed, word alignment results can often beimproved by restricting more general models to per-mit only one-to-one links.
For example, Och andNey (2003) found that the intersection of the align-ments found training the IBM models in both direc-tions always outperformed either direction alone intheir experiments.
Since the IBM models allow one-to-many links only in one direction, this intersectioncan contain only one-to-one links.To model the tendency for links to be one-to-one,we define a one-to-many feature as the number oflinks connecting two words such that exactly oneof them participates in at least one other link.
Wealso define a many-to-many feature as the number oflinks that connect two words that both participate inother links.
We don?t use this directly in the model,but to cut down on the number of alignments weneed to consider, we discard any alignments havinga non-zero value of the many-to-many feature.the unlinked word feature To control the numberof words that get linked to something, we introducean unlinked word feature that simply counts the totalnumber of unlinked words in both sentences in analigned sentence pair.2.2 The Conditional-Link-Probability-BasedModelIn this model we replace the LLR-based word asso-ciation statistic with the logarithm of the estimatedconditional probability of two words (or combina-tions of words) being linked, given that they co-occur in a pair of aligned sentences.
These estimatesare derived from the best alignments according tosome other, simpler model.
For example, if for-mer occurs 1000 times in English sentences whoseFrench translations contain ancien, and the simpleralignment model links them in 600 of those sentencepairs, we might estimate the conditional link proba-bility (CLP) for this word pair as 0.6.
We find itbetter, however, to adjust these probabilities by sub-tracting a small fixed discount from the link count:LPd(f, e) =links1(f, e)?
dcooc(f, e)LPd(f, e) represents the estimated conditional linkprobability for the words f and e, links1(f, e) isthe number of times they are linked by the simpleralignment model, d is the discount, and cooc(f, e)is the number of times they co-occur.
This adjust-ment prevents assigning high probabilities to linksbetween pairs of words that rarely co-occur.An important difference between the LLR-basedmodel and CLP-based model is that the LLR-basedmodel considers each word-to-word link separately,but allows multiple links per word, as long as they83lead to an alignment consisting only of one-to-oneand one-to-many links (in either direction).
In theCLP-based model, however, we allow conditionalprobabilities for both one-to-one and one-to-manyclusters, but we require all clusters to be disjoint.For example, we estimate the conditional proba-bility of linking not to ne...pas by considering thenumber of sentence pairs in which not occurs in theEnglish sentence and both ne and pas occur in theFrench sentence, compared to the number of timesnot is linked to both ne and pas in pairs of corre-sponding sentences.
However, when we make thisestimate in the CLP-based model, we do not count alink between not and ne...pas if the same instance ofnot, ne, or pas is linked to any other words.The CLP-based model incorporates the same ad-dtional features as the LLR-based model, except thatit omits the one-to-many feature, since we assumethat the one-to-one vs. one-to-many trade-off is al-ready modeled in the conditional link probabilitiesfor particular one-to-one and one-to-many clusters.We have developed two versions of the CLP-based model, using two different estimates for theconditional link probabilities.
One estimate of theconditional link probabilities comes from the LLR-based model described above, optimized on an an-notated development set.
The other estimate comesfrom a heuristic alignment model that we previouslydeveloped (Moore, 2005).2 Space does not permita full description of this heuristic model here, butin brief, it utilizes a series of greedy searches in-spired by Melamed?s competitive linking algorithm(2000), in which constraints limiting alignments tobeing one-to-one and monotonic are applied at dif-ferent thresholds of the LLR score, with a final cut-off of the LLR score below which no alignments aremade.3 Alignment SearchWhile the discriminative models presented aboveare very simple to describe, finding the optimalalignment according to these models is non-trivial.Adding a link for a new pair of words can affect thenonmonotonicity scores, the one-to-many score, andthe unlinked word score differently, depending on2The conditional link probabilities used in the current workare those used in Method 4 of the earlier work.
Full details areprovided in the reference.what other links are present in the alignment.
Never-theless, we have found a beam-search procedure thatseems highly effective in finding good alignmentswhen used with these models.For each sentence pair, we create a list of associa-tion types and their corresponding scores, consistingof the associations for which we have determined ascore and for which the words involved in the asso-ciation type occur in the sentence pair.3 We sort theresulting list of association types from best to worstaccording to their scores.Next, we initialize a list of possible alignmentswith the empty alignment, assigning it a score equalto the number of words in the sentence pair multi-plied by the unlinked word weight.
We then iteratethrough our sorted list of association types from bestto worst, creating new alignments that add links forall instances of the association type currently beingconsidered to existing alignments, potentially keep-ing both the old and new alignments in our set ofpossible alignments.Without pruning, we would soon be overwhelmedby a combinatorial explosion of alignments.
Theset of alignments is therefore pruned in two ways.First, we keep track at all times of the score of thebest alignment we have seen so far, and any newalignment whose overall score is worse than the bestscore so far by more than a fixed difference D is im-mediately discarded.
Second, for each instance of aparticular alignment type, when we have completedcreating modified versions of previous alignments toinclude that instance, we merge the set of new align-ments that we have created into the set of previousalignments.
When we do this merge, the resultingset of alignments is sorted by overall score, and onlythe N best alignments are kept, for a fixed N .Some details of the search differ between theLLR-based model and the CLP-based model.
Onedifference is how we add links to existing align-ments.
In both cases, if there are no existing linksinvolving any of the words involved in the new link,we simply add it (keeping a copy of the originalalignment, subject to pruning).If there are existing links involving word in-stances also involved in the new link, the two mod-3By association type we mean a possible link between a pairof words, or, in the case of the CLP-based models, a possibleone-to-many or many-to-one linkage of words.84els are treated differently.
For the CLP-based model,each association score is for a cluster of words thatmust be disjoint from any other association cluster,so when we add links for a new cluster, we mustremove any other links involving the same word in-stances.
For the LLR-based model, we can add ad-ditional links without removing old ones, but the re-sulting alignment may be worse due to the degra-dation in the one-to-many score.
We therefore addboth an alignment that keeps all previous links, andan additional set of alignments, each of which omitsone of the previous links involving one of the wordinstances involved in the new link.The other difference in how the two models aretreated is an extra pruning heuristic we use in theLLR-based model.
In generating the list of associ-ation types to be used in aligning a given sentencepair, we use only association types which have thebest association score for this sentence pair for oneof the word types involved in the association.
Weinitially explored limiting the number of associa-tions considered for each word type simply as an ef-ficiency heuristic, but we were surprised to discoverthat the most extreme form of such pruning actuallyreduced alignment error rate over any less restrictiveform or not pruning on this basis at all.4 Parameter OptimizationWe optimize the feature weights using a modifiedversion of averaged perceptron learning as describedby Collins (2002).
Starting with an initial set offeature weight values, perceptron learning iteratesthrough the annotated training data multiple times,comparing, for each sentence pair, the best align-ment ahyp according to the current model with thereference alignment aref .
At each sentence pair, theweight for each feature is is incremented by the dif-ference between the value of the feature for the bestalignment according to the model and the value ofthe feature for the reference alignment:?i ?
?i + (fi(aref , e, f)?
fi(ahyp, e, f))The updated feature weights are used to computeahyp for the next sentence pair.Iterating through the data continues until theweights stop changing, because aref = ahyp foreach sentence pair, or until some other stopping con-dition is met.
In the averaged perceptron, the featureweights for the final model are the average of theweight values over all the data rather than simplythe values after the final sentence pair of the finaliteration.We make a few modifications to the procedure asdescribed by Collins.
First, we average the weightvalues over each pass through the data, rather thanover all passes, as we found this led to faster con-vergence.
After each pass of perceptron learningthrough the data, we make another pass through thedata with feature weights fixed to their average val-ues for the previous learning pass, to evaluate cur-rent performance of the model.
We iterate this pro-cedure until a local optimum is found.Next, we used a fixed weight of 1.0 for the word-association feature, which we expect to be most im-portant feature in the model.
Allowing all weights tovary allows many equivalent sets of weights that dif-fer only by a constant scale factor.
Fixing one weighteliminates a spurious apparent degree of freedom.This necessitates, however, employing a version ofperceptron learning that uses a learning rate param-eter.
As described by Collins, the perceptron up-date rule involves incrementing each weight by thedifference in the feature values being compared.
Ifthe feature values are discrete, however, the mini-mum difference may be too large compared to theunweighted association score.
We therefore multi-ply the feature value difference by a learning rate pa-rameter ?
to allow smaller increments when needed:?i ?
?i + ?
(fi(aref , e, f)?
fi(ahyp, e, f))For the CLP-based model, based on the typicalfeature values we expected to see, we guessed that0.01 might be a good value for the learning rate pa-rameter.
That seemed to produce good results, so wedid not attempt to further optimize the learning rateparameter for this model.The situation with the LLR-based model wasmore complicated.
Our previous experience usingLLR scores in statistical NLP applications indicatedthat with large data sets, LLR values can get veryhigh (upwards of 100000 for our 500000 sentencepair corpus), but small difference could be signifi-cant, which led us to believe that the same wouldbe true of the weight values we were trying to learn.That meant that a learning rate small enough to let85us converge on the desired weight values might takea very large number of iterations through the datato reach those values.
We addressed this problem,by using a progression of learning rates, starting at1000, reducing each successive weight by an orderof magnitude, until we ended with a learning rate of1.0.
At each transition between learning rates, we re-initialized the weights to the optimum values foundwith the previous learning rate.We experimented with one other idea for opti-mizing the weight values.
Perceptron learning doesnot directly optimize error rate, but we have onlya small number of parameters that we need to op-timize.
We therefore thought it might be helpfulto apply a general optimization procedure directlyto the error rate, starting from the best parame-ter values found by perceptron learning, using theN -best alignments found with these parameter val-ues.
We experimented with both the downhill sim-plex method (Press et al, 2002, Section 10.4) andPowell?s method (Press et al, 2002, Section 10.5),but we obtained slightly better results with a moreheuristic method designed to look past minor localminima.
We found that using this approach on top ofperceptron learning led to slightly lower error rateson the development set with the CLP-based model,but not with the LLR-base model, so we used it onlywith the former in our final evaluations.5 Data and Methodology for EvaluationWe evaluated our models using data from the bilin-gual word alignment workshop held at HLT-NAACL2003 (Mihalcea and Pedersen, 2003).
We useda subset of the Canadian Hansards bilingual cor-pus supplied for the workshop, comprising 500,000English-French sentences pairs, including 447 man-ually word-aligned sentence pairs designated as testdata.
The test data annotates particular pairs ofwords either as ?sure?
or ?possible?
links.
Auto-matic sentence alignment of the training data wasprovided by Ulrich Germann, and the hand align-ments of the words in the test data were created byFranz Och and Hermann Ney (Och and Ney, 2003).Since our discriminative training approach re-quires a small amount of annotated data for parame-ter optimization, we split the test data set into twovirtually equal subsets, by randomly ordering thetest data pairs, and assigning alternate pairs from therandom order to the two subsets.
We used one ofthese subsets as a development set for parameter op-timization, and held out the other for a final test set.We report the performance of our alignment mod-els in terms of precision, recall, and alignment errorrate (AER) as defined by Och and Ney (2003):recall =|A ?
S||S|precision =|A ?
P ||A|AER = 1?|A ?
P |+ |A ?
S||A|+ |S|In these definitions, S denotes the set of alignmentsannotated as sure, P denotes the set of alignmentsannotated possible or sure, and A denotes the set ofalignments produced by the method under test.
Fol-lowing standard practice in the field, we take AER,which is derived from F-measure, as the primaryevaluation metric that we are attempting to optimize.6 Experimental ResultsWe first trained the LLR-based model by perceptronlearning, using an N -best value of 20 and an un-bounded allowable score difference in the alignmentsearch, using the development set as annotated train-ing data.
We then aligned all the sentences of length100 or less in our 500,000 sentence pair corpus, us-ing an N -best value of 20 and a maximum allowablescore difference of 125000.
We collected link countsand co-occurrence counts from these alignments forestimating conditional link probabilities.
We trainedCLP-based models from these counts for a range ofvalues for the discount used in the conditional linkprobability estimation, finding a value of 0.4 to be aroughly optimal value of the discount parameter forthe development set.
We also trained a CLP-basedmodel using the conditional link probabilities fromthe heuristic alignment model mentioned previously.In training both CLP-based models, we also usedan N -best value of 20 and an unbounded allowablescore difference in the alignment search.We evaluated three models on the final test data:the LLR-based model (LLR) and the two CLP-basedmodels, one with conditional link probabilities from86Alignment Recall Precision AERLLR 0.829 0.848 0.160CLP10.889 0.934 0.086CLP20.898 0.947 0.075Table 1: Discriminative Model Results.Alignment Recall Precision AERE ?
F 0.870 0.890 0.118F ?
E 0.876 0.907 0.106Union 0.929 0.845 0.124Intersection 0.817 0.981 0.097Refined 0.908 0.929 0.079Table 2: IBM Model 4 Results.the LLR-based model (CLP1), and one with condi-tional link probabilities from the heuristic alignmentmodel (CLP2).
All parameters were optimized onthe development set.
Recall, precision, and align-ment error rates on the test set are shown in Table 1.For comparison, we aligned our parallel corpuswith IBM Model 4 using Och?s Giza++ softwarepackage (Och and Ney, 2003).4 We used the de-fault configuration file included with the version ofGiza++ that we used, which resulted in five itera-tions of Model 1, followed by five iterations of theHMMmodel, followed by five iterations of Model 4.We trained the models in both directions, English-to-French and French-to-English, and computed theunion, intersection, and what Och and Ney (2003)call the ?refined?
combination of the two align-ments.
We evaluated the resulting alignments of thefinal test set, with the results shown in Table 2.As these tables show, our discriminatively trainedCLP-based models compare favorably to IBMModel 4 on this data set.
The one with condi-tional link probabilities from the heuristic alignmentmodel, CLP2, performs slightly better than the bestof the Model 4 combinations, and the one withconditional link probabilities from the LLR-basedmodel, CLP1, performs only slightly worse.An interesting question is why CLP2outper-formed CLP1.
CLP1is the more ?principled?
model,so one might have expected it to perform better.
Webelieve the most likely explanation is the fact that4Thanks to Chris Quirk for carrying out this alignment.CLP2received 403,195 link probabilities from theheuristic model, while CLP1received only 144,051link probabilities from the LLR-based model.
HenceCLP2was able to consider more possible links.In light of our claims about the ease of optimiz-ing the models, we should make some commentson the time need to train the parameters.
Our cur-rent implementation of the alignment search is writ-ten in Perl, and is therefore quite slow.
Alignmentof our 500,000 sentence pair corpus with the LLR-based mode took over a day on a 2.8 GHz PentiumIV workstation.
Nevertheless, the parameter opti-mization was still quite fast, since it took only a fewiterations over our 224 sentence pair developmentset.
With either the LLR-based or CLP-based mod-els, one combined learning/evaluation pass of per-ceptron training always took less than two minutes,and it never took more that six passes to reach thelocal optimum we took to indicate convergence.
To-tal training time was greater since we used multipleruns of perceptron learning with different learningrates for the LLR-based model and different condi-tional link probability discounts for CLP1, but totaltraining time for each model was around an hour.7 Related WorkWhen the first version of this paper was submittedfor review, we could honestly state, ?We are notaware of any previous work on discriminative wordalignment models.?
Callison-Burch et al (2004) hadinvestigated the use of small amounts of annotateddata to help train the IBM and HMMmodels, but themodels were still generative and were trained usingmaximum-likelihood methods.Recently, however, three efforts nearly simultane-ous with ours have made use of discriminative meth-ods to train alignment models.
Fraser and Marcu(2005) modify Model 4 to be a log-linear combina-tion of 11 submodels (5 based on standard Model 4parameters, and 6 based on additional features) anddiscriminatively optimize the submodel weights oneach iteration of a Viterbi approximation to EM.Liu et al (2005) also develop a log-linear model,based on IBM Model 3.
They train Model 3 us-ing Giza++, and then use the Model 3 score of apossible alignment as a feature value in a discrim-inatively trained log-linear model, along with fea-87tures incorporating part-of-speech information, andwhether the aligned words are given as translationsin a bilingual dictionary.
The log-linear model istrained by standard maximum-entropy methods.Klein and Taskar (2005), in a tutorial on maxi-mum margin methods for natural-language process-ing, described a weighted linear model incorporat-ing association, position, and orthography features,with its parameters trained by a structured-support-vector-machine method.
This model is in some re-spects very similar to our LLR-based model, us-ing Dice coefficient association scores where we useLLR scores, and absolute position differences wherewe use nonmonotonicity measures.8 ConclusionsThe results of our work and other recent effortson discriminatively trained alignment models showthat results comparable to or better than those ob-tained with the IBM models are possible within aframework that makes it easy to add arbitrary ad-ditional features.
After many years using the samesmall set of alignment models, we now have an easyway to experiment with a wide variety of knowledgesources to improve word-alignment accuracy.ReferencesPeter F. Brown, Stephen A. Della Pietra, Vincent J.Della Pietra, and Robert L. Mercer.
1993.
TheMathematics of Statistical Machine Translation:Parameter Estimation.
Computational Linguis-tics, 19(2):263?311.Chris Callison-Burch, David Talbot, and Miles Os-borne.
2005.
Statistical Marchine Translationwith Word- and Sentences-Aligned Parallel Cor-pora.
In Proceedings of the 42nd Annual Meetingof the ACL, pp.
176?183, Barcelona, Spain.Michael Collins.
2002.
Discriminative TrainingMethods for Hidden Markov Models: Theory andExperiments with Perceptron Algorithms.
In Pro-ceedings of the Conference on Empirical Meth-ods in Natural Language Processing, pp.
1?8,Philadelphia, Pennsylvania.Alexander Fraser and Daniel Marcu.
2005.
ISI?sParticipation in the Romanian-English AlignmentTask.
In Proceedings of the ACL Workshop onBuilding and Using Parallel Texts, pp.
91?94,Ann Arbor, Michigan.Yang Liu, Qun Liu, and Shouxun Lin.
2005.
Log-linear Models for Word Alignment.
In Proceed-ings of the 43rd Annual Meeting of the ACL,pp.
459?466, Ann Arbor, Michigan.Dan Klein and Ben Taskar.
2005.
Max-MarginMethods for NLP: Estimation, Structure, and Ap-plications.
Tutorial presented at ACL 2005, AnnArbor, Michigan.I.
Dan Melamed.
2000.
Models of Transla-tional Equivalence.
Computational Linguistics,26(2):221?249.Rada Mihalcea and Ted Pedersen.
2003.
An Evalu-ation Exercise for Word Alignment.
In Proceed-ings of the HLT-NAACL 2003 Workshop, Buildingand Using Parallel Texts: Data Driven MachineTranslation and Beyond, pp.
1?6, Edmonton, Al-berta, Canada.Robert C. Moore.
2004.
On Log-Likelihood-Ratiosand the Significance of Rare Events.
In Proceed-ings of the 2004 Conference on Empirical Meth-ods in Natural Language Processing, pp.
333?340, Barcelona, Spain.Robert C. Moore.
2005.
Association-Based Bilin-gual Word Alignment.
In Proceedings of the ACLWorkshop on Building and Using Parallel Texts,pp.
1?8, Ann Arbor, Michigan.Franz Joseph Och and Hermann Ney.
2003.A Systematic Comparison of Various StatisticalAlignment Models.
Computational Linguistics,29(1):19?51.Franz Joseph Och and Hermann Ney.
2004.
TheAlignment Template Approach to Statistical Ma-chine Translation.
Computational Linguistics,30(4):417?449.William H. Press, Saul A. Teukolsky, William T.Vetterling, and Brian P. Flannery.
1992.
Numer-ical Recipies in C: The Art of Scientific Comput-ing, Second Edition.
Cambridge University Press,Cambridge, England.88
