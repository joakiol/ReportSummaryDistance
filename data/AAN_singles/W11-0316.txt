Proceedings of the Fifteenth Conference on Computational Natural Language Learning, pages 135?144,Portland, Oregon, USA, 23?24 June 2011. c?2011 Association for Computational LinguisticsAutomatic Keyphrase Extraction by Bridging Vocabulary Gap ?Zhiyuan Liu, Xinxiong Chen, Yabin Zheng, Maosong SunState Key Laboratory of Intelligent Technology and SystemsTsinghua National Laboratory for Information Science and TechnologyDepartment of Computer Science and TechnologyTsinghua University, Beijing 100084, China{lzy.thu, cxx.thu, yabin.zheng}@gmail.com, sms@tsinghua.edu.cnAbstractKeyphrase extraction aims to select a set ofterms from a document as a short summaryof the document.
Most methods extractkeyphrases according to their statistical prop-erties in the given document.
Appropriatekeyphrases, however, are not always statis-tically significant or even do not appear inthe given document.
This makes a largevocabulary gap between a document and itskeyphrases.
In this paper, we consider thata document and its keyphrases both describethe same object but are written in two differentlanguages.
By regarding keyphrase extractionas a problem of translating from the languageof documents to the language of keyphrases,we use word alignment models in statisticalmachine translation to learn translation proba-bilities between the words in documents andthe words in keyphrases.
According to thetranslation model, we suggest keyphrases giv-en a new document.
The suggested keyphrasesare not necessarily statistically frequent in thedocument, which indicates that our methodis more flexible and reliable.
Experimentson news articles demonstrate that our methodoutperforms existing unsupervised methodson precision, recall and F-measure.1 IntroductionInformation on the Web is emerging with thedevelopment of Internet.
It is becoming more andmore important to effectively search and manageinformation.
Keyphrases, as a brief summary of adocument, provide a solution to help organize and?Zhiyuan Liu and Xinxiong Chen have equal contributionto this work.retrieve documents, which have been widely usedin digital libraries and information retrieval (Turney,2000; Nguyen and Kan, 2007).
Due to the explosionof information, it is ineffective for professionalhuman indexers to manually annotate documentswith keyphrases.
How to automatically extractkeyphrases from documents becomes an importantresearch problem, which is usually referred to askeyphrase extraction.Most methods for keyphrase extraction try toextract keyphrases according to their statistical prop-erties.
These methods are susceptible to low perfor-mance because many appropriate keyphrases maynot be statistically frequent or even not appear in thedocument, especially for short documents.
We namethe phenomenon as the vocabulary gap betweendocuments and keyphrases.
For example, a researchpaper talking about ?machine transliteration?
mayless or even not mention the phrase ?machinetranslation?.
However, since ?machine transliter-ation?
is a sub-field of ?machine translation?, thephrase ?machine translation?
is also reasonable tobe suggested as a keyphrase to indicate the topicsof this paper.
Let us take another example: in anews article talking about ?iPad?
and ?iPhone?, theword ?Apple?
may rarely ever come up.
However,it is known that both ?iPad?
and ?iPhone?
are theproducts of ?Apple?, and the word ?Apple?
may thusbe a proper keyphrase of this article.We can see that, the essential challenge ofkeyphrase extraction is the vocabulary gap betweendocuments and keyphrases.
Therefore, the task ofkeyphrase extraction is how to capture the semanticrelations between the words in documents and inkeyphrases so as to bridge the vocabulary gap.In this paper, we provide a new perspective to135documents and their keyphrases: each documentand its keyphrases are descriptions to the sameobject, but the document is written using one lan-guage, while keyphrases are written using anotherlanguage.
Therefore, keyphrase extraction can beregarded as a translation problem from the languageof documents into the language of keyphrases.Based on the idea of translation, we use wordalignment models (WAM) (Brown et al, 1993) instatistical machine translation (SMT) (Koehn, 2010)and propose a unified framework for keyphraseextraction: (1) From a collection of translation pairsof two languages, WAM learns translation probabil-ities between the words in the two languages.
(2)According to the translation model, we are able tobridge the vocabulary gap and succeed in suggestingappropriate keyphrases, which may not necessarilyfrequent in their corresponding documents.As a promising approach to solve the problemof vocabulary gap, SMT has been widely ex-ploited in many applications such as informationretrieval (Berger and Lafferty, 1999; Karimzade-hgan and Zhai, 2010), image and video anno-tation (Duygulu et al, 2002), question answer-ing (Berger et al, 2000; Echihabi and Marcu, 2003;Murdock and Croft, 2004; Soricut and Brill, 2006;Xue et al, 2008), query expansion and rewrit-ing (Riezler et al, 2007; Riezler et al, 2008; Riezlerand Liu, 2010), summarization (Banko et al, 2000),collocation extraction (Liu et al, 2009b; Liu et al,2010b) and paraphrasing (Quirk et al, 2004; Zhaoet al, 2010).
Although SMT is a widely adoptedsolution to vocabulary gap, for various applicationsusing SMT, the crucial and non-trivial problem isto find appropriate and enough translation pairs forSMT.The most straightforward translation pairs forkeyphrase extraction is document-keyphrase pairs.In practice, however, it is time-consuming to anno-tate a large collection of documents with keyphrasesfor sufficient WAM training.
In order to solvethe problem, we use titles and summaries to buildtranslation pairs with documents.
Titles and sum-maries are usually accompanying with the corre-sponding documents.
In some special cases, titlesor summaries may be unavailable.
We are also ableto extract one or more important sentences fromthe corresponding documents to construct sufficienttranslation pairs.2 State of the ArtSome researchers (Frank et al, 1999; Witten et al,1999; Turney, 2000) regarded keyphrase extractionas a binary classification problem (is-keyphrase ornon-keyphrase) and learned models for classifica-tion using training data.
These supervised methodsneed manually annotated training set, which is time-consuming.
In this paper, we focus on unsupervisedmethods for keyphrase extraction.The most simple unsupervised method forkeyphrase extraction is using TFIDF (Salton andBuckley, 1988) to rank the candidate keyphrases andselect the top-ranked ones as keyphrases.
TFIDFranks candidate keyphrases only according to theirstatistical frequencies, which thus fails to suggestkeyphrases with low frequencies.Starting with TextRank (Mihalcea and Tarau,2004), graph-based ranking methods are becomingthe state-of-the-art methods for keyphrase extrac-tion (Liu et al, 2009a; Liu et al, 2010a).
Givena document, TextRank first builds a word graph,in which the links between words indicate theirsemantic relatedness, which are estimated by theword co-occurrences in the document.
By executingPageRank (Page et al, 1998) on the graph, we obtainthe PageRank score for each word to rank candidatekeyphrases.In TextRank, a low-frequency word will benefitfrom its high-frequency neighbor words and thus beranked higher as compared to using TFIDF.
Thisalleviates the problem of vocabulary gap to someextent.
TextRank, however, still tends to extracthigh-frequency words as keyphrases because thesewords have more opportunities to get linked withother words and obtain higher PageRank scores.Moreover, TextRank usually constructs a wordgraph simply according to word co-occurrences asan approximation of the semantic relations betweenwords.
This will introduce much noise because ofconnecting semantically unrelated words and highlyinfluence extraction performance.Some methods have been proposed to improveTextRank, of which ExpandRank (Wan and Xi-ao, 2008b; Wan and Xiao, 2008a) uses a smal-l number, namely k, of neighbor documents to136provide more information of word relatedness forthe construction of word graphs.
Compared toTextRank, ExpandRank performs better when facingthe vocabulary gap by borrowing the information ondocument level.
However, the finding of neighbordocuments are usually arbitrary.
This process mayintroduce much noise and result in topic drift whenthe document and its so-called neighbor documentsare not exactly talking about the same topics.Another potential approach to alleviate vocabu-lary gap is latent topic models (Landauer et al,1998; Hofmann, 1999; Blei et al, 2003), of whichlatent Dirichlet alocation (LDA) (Blei et al, 2003)is most popular.
Latent topic models learn topicsfrom a collection of documents.
Using a topicmodel, we can represent both documents and wordsas the distributions over latent topics.
The semanticrelatedness between a word and a document can becomputed using the cosine similarities of their topicdistributions.
The similarity scores can be used asthe ranking criterion for keyphrase extraction (Hein-rich, 2005; Blei and Lafferty, 2009).
On one hand,latent topic models use topics instead of statisticalproperties of words for ranking, which abates thevocabulary gap problem on topic level.
On the otherhand, the learned topics are usually very coarse, andtopic models tend to suggest general words for agiven document.
Therefore, the method usually failsto capture the specific topics of the document.In contract to the above-mentioned methods, ourmethod addresses vocabulary gap on word level,which prevents from topic drift and works out betterperformance.
In experiments, we will show ourmethod can better solve the problem of vocab-ulary gap by comparing with TFIDF, TextRank,ExpandRank and LDA.3 Keyphrase Extraction by BridgingVocabulary Gap Using WAMFirst, we give a formal definition of keyphraseextraction: given a collection of documents D, foreach document d ?
D, keyphrase extraction aimsto rank candidate keyphrases according to theirlikelihood given the document d, i.e., Pr(p|d) for allp ?
P, where P is the candidate keyphrase set.
Thenwe select top-Md ones as keyphrases, where Md canbe fixed or automatically determined by the system.The document d can be regarded as a sequence ofwords wd = {wi}Nd1 , where Nd is the length of d.In Fig.
1, we demonstrate the framework ofkeyphrase extraction using WAM.
We divide thealgorithm into three steps: preparing translationpairs, training translation models and extractingkeyphrases for a given document.
We will introducethe three steps in details from Section 3.1 toSection 3.3.Input: A large collection of documents D for keyphraseextraction.Step 1: Prepare Translation Pairs.
For each d ?
D, wemay prepare two types of translation pairs:?
Title-based Pairs.
Use the title td of each documentd and prepare translation pairs, denote as ?D,T ?.?
Summary-based Pairs.
Use the summary sd ofeach document d and prepare translation pairs,denote as ?D,S?.Step 2: Train Translation Model.
Given translationpairs, e.g., ?D,T ?, train word-word translation modelPr?D,T ?
(t|w) using WAM, where w is the word in docu-ment language and t is the word in title language.Step 3: Keyphrase Extraction.
For a document d,extract keyphrases according to a trained translationmodel, e.g., Pr?D,T ?(t|w).1.
Measure the importance score Pr(w|d) of each wordw in document d.2.
Compute the ranking score of candidate keyphrasep byPr(p|d) =?t?p?w?d Pr?D,T ?
(t|w)Pr(w|d) (1)3.
Select top-Md ranked candidate keyphrases accord-ing to Pr(p|d) as the keyphrases of document d.Figure 1: WAM for keyphrase extraction.3.1 Preparing Translation PairsTraining dataset for WAM consists of a numberof translation pairs written in two languages.
Inkeyphrase extraction task, we have to constructsufficient translation pairs to capture the semanticrelations between documents and keyphrases.
Herewe propose to construct two types of translationpairs: title-based pairs and summary-based pairs.1373.1.1 Title-based PairsTitle is usually a short summary of the given doc-ument.
In most cases, documents such as researchpapers and news articles have corresponding titles.Therefore, we can use title to construct translationpairs for a document.WAM assumes each translation pair should be ofcomparable length.
However, a document is usuallymuch longer than title.
It will hurt the performanceif we fill the length-unbalanced pairs for WAMtraining.
We propose two methods to address theproblem: sampling method and split method.In sampling method, we perform word samplingfor each document to make it comparable to thelength of its title.
Suppose the lengths of a documentand its title are Nd and Nt , respectively.
Fordocument d, we first build a bag of words bd ={(wi,ei)}Wdi=1, where Wd is the number of uniquewords in d, and ei is the weights of word wi in d.In this paper, we use TFIDF scores as the weightsof words.
Using bd , we sample words for Nttimes with replacement according to the weights ofwords, and finally form a new bag with Nt wordsto represent document d. In the sampling result,we keep the most important words in document d.We can thus construct a document-title pair withbalanced length.In split method, we split each document intosentences which are of comparable length to itstitle.
For each sentence, we compute its semanticsimilarity with the title.
There are various methodsto measure semantic similarities.
In this paper, weuse vector space model to represent sentences andtitles, and use cosine scores to compute similarities.If the similarity is smaller than a threshold ?
, wewill discard the sentence; otherwise, we will regardthe sentence and title as a translation pair.Sampling method and split method have theirown characteristics.
Compared to split method,sampling method loses the order information ofwords in documents.
While split method generatesmuch more translation pairs, which leads to longertraining time of WAM.
In experiment section, wewill investigate the performance of the two methods.3.1.2 Summary-based PairsFor most research articles, authors usually pro-vide abstracts to summarize the articles.
Many newsarticles also have short summaries.
Suppose eachdocument itself has a short summary, we can usethe summary and document to construct translationpairs using either sampling method or split method.Because each summary usually consists of multiplesentences, split method for constructing summary-based pairs has to split both the document andsummary into sentences, and the sentence pairs withsimilarity scores above the threshold are filled intraining dataset for WAM.3.2 Training Translation ModelsWithout loss of generality, we take title-based pairsas the example to introduce the training processof translation models, and suppose documents arewritten in one language and titles are written inanother language.
In this paper, we use IBM Model-1 (Brown et al, 1993) for WAM training.
IBMModel-1 is a widely used word alignment algorithmwhich does not require linguistic knowledge for twolanguages 1.In IBM Model-1, for each translation pair?wd ,wt?, the relationship of the document languagewd = {wi}Ldi=0 and the title language wt = {ti}Lti=0is connected via a hidden variable a = {ai}Ldi=1describing an alignment mapping from words ofdocuments to words of titles,Pr(wd |wt) = ?aPr(wd ,a|wt) (2)For example, a j = i indicates word w j in wd atposition j is aligned to word ti in wt at position i.The alignment a also contains empty-word align-ments a j = 0 which align words of documents toan empty word.
IBM Model-1 can be trained usingExpectation-Maximization (EM) algorithm (Demp-ster et al, 1977) in an unsupervised fashion.
UsingIBM Model-1, we can obtain the translation prob-abilities of two language-vocabularies, i.e., Pr(t|w)and Pr(w|t), where w is a word in documentvocabulary and t is a word in title vocabulary.IBM Model-1 will produce one-to-many align-ments from one language to another language, andthe trained model is thus asymmetric.
Hence, we can1We have also employed more sophisticated WAM al-gorithms such as IBM Model-3 for keyphrase extraction.However, these methods did not achieve better performancethan the simple IBM Model-1.
Therefore, in this paper we onlydemonstrate the experimental results using IBM Model-1.138train two different translation models by assigningtranslation pairs in two directions, i.e., (document?title) and (title ?
document).
We denote the formermodel as Prd2t and the latter as Prt2d.
We definePr?D,T ?
(t|w) in Eq.
(1) as the harmonic mean of thetwo models:Pr?D,T ?
(t|w) ?
(?Prd2t(t|w) +(1??
)Prt2d(t|w))?1(3)where ?
is the harmonic factor to combine the twomodels.
When ?
= 1.0 or ?
= 0.0, it simply usesmodel Prd2t or Prt2d, correspondingly.
Using thetranslation probabilities Pr(t|w) we can bridge thevocabulary gap between documents and keyphrases.3.3 Keyphrase ExtractionGiven a document d, we rank candidate keyphrasesby computing their likelihood Pr(p|d).
Each can-didate keyphrase p may be composed of multiplewords.
As shown in (Hulth, 2003), most keyphrasesare noun phrases.
Following (Mihalcea and Tarau,2004; Wan and Xiao, 2008b), we simply selectnoun phrases from the given document as candidatekeyphrases with the help of POS tags.
For eachword t, we compute its likelihood given d, Pr(t|d) =?w?d Pr(t|w)Pr(w|d), where Pr(w|d) is the weightof the word w in d, which is measured usingnormalized TFIDF scores.
Pr(t|w) is the translationprobabilities obtained from WAM training.Using the scores of all words in candidatekeyphrases, we compute the ranking score of eachcandidate keyphrase by summing up the scoresof each word in the candidate keyphrase, i.e.,Pr(p|d) =?t?pPr(t|d).
In all, the ranking scoresof candidate keyphrases is formalized in Eq.
(1)of Fig.
1.
According to the ranking scores, we cansuggest top-Md ranked candidates as the keyphrases,where Md is the number of suggested keyphrases tothe document d pre-specified by users or systems.We can also consider the number of words in thecandidate keyphrase as a normalization factor to Eq.
(1), which will be our future work.4 ExperimentsTo perform experiments, we crawled a collection of13,702 Chinese news articles 2 from www.163.2The dataset can be obtained from http://nlp.csai.tsinghua.edu.cn/?lzy/datasets/ke_wam.html.com, one of the most popular news websites in Chi-na.
The news articles are composed of various topicsincluding science, technology, politics, sports, arts,society and military.
All news articles are manuallyannotated with keyphrases by website editors, andall these keyphrases come from the correspondingdocuments.
Each news article is also provided witha title and a short summary.In this dataset, there are 72,900 unique words indocuments, and 12,405 unique words in keyphrases.The average lengths of documents, titles and sum-maries are 971.7 words, 11.6 words, and 45.8 words,respectively.
The average number of keyphrasesfor each document is 2.4.
In experiments, weuse the annotated titles and summaries to constructtranslation pairs.In experiments, we select GIZA++ 3 (Och andNey, 2003) to train IBM Model-1 using translationpairs.
GIZA++, widely used in various applicationsof statistical machine translation, implements IBMModels 1-5 and an HMM word alignment model.To evaluate methods, we use the annotatedkeyphrases by www.163.com as the standardkeyphrases.
If one suggested keyphrase exact-ly matches one of the standard keyphrases, itis a correct keyphrase.
We use precision p =ccorrect/cmethod , recall r = ccorrect/cstandard and F-measure f = 2pr/(p + r) for evaluation, whereccorrect is the number of keyphrases correctly sug-gested by the given method, cmethod is the numberof suggested keyphrases, and cstandard is the numberof standard keyphrases.
The following experimentresults are obtained by 5-fold cross validation.4.1 Evaluation on Keyphrase Extraction4.1.1 Performance Comparison and AnalysisWe use four representative unsupervised methodsas baselines for comparison: TFIDF, TextRank (Mi-halcea and Tarau, 2004), ExpandRank (Wan andXiao, 2008b) and LDA (Blei et al, 2003).
Wedenote our method as WAM for short.In Fig.
2, we demonstrate the precision-recallcurves of various methods for keyphrase extractionincluding TFIDF, TextRank, ExpandRank, LDAand WAM with title-based pairs prepared using3The website for GIZA++ package is http://code.google.com/p/giza-pp/.139sampling method (Title-Sa) and split method (Title-Sp), and WAM with summary-based pairs preparedusing sampling method (Summ-Sa) and split method(Summ-Sp).
For WAM, we set the harmonic factor?
= 1.0 and threshold ?
= 0.1, which is the optimalsetting as shown in the later analysis on parameterinfluence.
For TextRank, LDA and ExpandRank, wereport their best results after parameter tuning, e.g.,the number of topics for LDA is set to 400, and thenumber of neighbor documents for ExpandRank isset to 5 .The points on a precision-recall curve representdifferent numbers of suggested keyphrases fromMd = 1 (bottom right) to Md = 10 (upper left),respectively.
The closer the curve is to the upperright, the better the overall performance of themethod is.
In Table 1, we further demonstrate theprecision, recall and F-measure scores of variousmethods when Md = 2 4.
In Table 1, we also showthe statistical variances after ?.
From Fig.
2 andTable 1, we have the following observations:0.10.20.30.40.50.60.70.05  0.1  0.15  0.2  0.25  0.3  0.35  0.4RecallPrecisionTFIDFTextRankLDAExpandRankTitle-SaTitle-SpSumm-SaSumm-SpFigure 2: The precision-recall curves of variousmethods for keyphrase extraction.First, our method outperforms all baselines.
Itindicates that the translation perspective is validfor keyphrase extraction.
When facing vocabu-lary gap, TFIDF and TextRank have no solutions,ExpandRank adopts the external information ondocument level which may introduce noise, andLDA adopts the external information on topic levelwhich may be too coarse.
In contrast to thesebaselines, WAM aims to bridge the vocabulary gapon word level, which avoids topic drift effectively.4We select Md = 2 because WAM gains the best F-measurescore when Md = 2, which is close to the average number ofannotated keyphrases for each document 2.4.Method Precision Recall F-measureTFIDF 0.187 0.256 0.208?0.005TextRank 0.217 0.301 0.243?0.008LDA 0.181 0.253 0.203?0.002ExpandRank 0.228 0.316 0.255?0.007Title-Sa 0.299 0.424 0.337?0.008Title-Sp 0.300 0.425 0.339?0.010Summ-Sa 0.258 0.361 0.289?0.009Summ-Sp 0.273 0.384 0.307?0.008Table 1: Precision, recall and F-measure of variousmethods for keyphrase extraction when Md = 2.Therefore, our method can better solve the problemof vocabulary gap in keyphrase extraction.Second, WAM with title-based pairs performsbetter than summary-based pairs consistently, nomatter prepared using sampling method or splitmethod.
This indicates the titles are closer tothe keyphrase language as compared to summaries.This is also consistent with the intuition that titlesare more important than summaries.
Meanwhile, wecan save training efforts using title-based pairs.Last but not least, split method achieves better orcomparable performance as compared to samplingmethod on both title-based pairs and summary-based pairs.
The reasons are: (1) the split methodgenerates more translation pairs for adequate train-ing than sampling method; and (2) split methodalso keeps the context of words, which helps toobtain better word alignment, unlike bag-of-wordsin sampling method.4.1.2 Influence of ParametersWe also investigate the influence of parametersto WAM with title-based pairs prepared using splitmethod, which achieves the best performance asshown in Fig.
2.
The parameters include: harmonicfactor ?
(described in Eq.
3) and threshold factor?
.
Harmonic factor ?
controls the weights of thetranslation models trained in two directions, i.e.,Prd2t(t|w) and Prt2d(t|w) as shown in Eq.
(3).
Asdescribed in Section 3.1.1, using threshold factor ?we filter out the pairs with similarities lower than ?
.In Fig.
3, we show the precision-recall curvesof WAM for keyphrase extraction when harmonicfactor ?
ranges from 0.0 to 1.0 stepped by 0.2.
Fromthe figure, we observe that the translation modelPrd2t(t|w) (i.e., when ?
= 1.0) performs better than140Prt2d(t|w) (i.e., when ?
= 0.0).
This indicates thatit is sufficient to simply train a translation modelin one direction (i.e., Prd2t(t|w)) for keyphraseextraction.0.250.30.350.40.450.50.550.60.650.70.05  0.1  0.15  0.2  0.25  0.3  0.35  0.4RecallPrecision?
= 0.0?
= 0.2?
= 0.4?
= 0.6?
= 0.8?
= 1.0Figure 3: Precision-recall curves of WAM whenharmonic factor ?
ranges from 0.0 to 1.0.In Fig.
4, we show the precision-recall curvesof WAM for keyphrase extraction when thresholdfactor ?
ranges from 0.01 to 0.90.
In title-based pairs using split method, the total numberof pairs without filtering any pairs (i.e., ?
= 0)is 347,188.
When ?
= 0.01, 0.10 and 0.90, thenumbers of retained translation pairs are 165,023,148,605 and 41,203, respectively.
From Fig.
4,we find that more translation pairs result in betterperformance.
However, more translation pairs alsoindicate more training time of WAM.
Fortunately,we can see that the performance does not drop muchwhen discarding more translation pairs with lowsimilarities.
Even when ?
= 0.9, our method canstill achieve performance with precision p = 0.277,recall r = 0.391 and F-measure f = 0.312 whenMd = 2.
Meanwhile, we reduce the training effortsby about 50% as compared to ?
= 0.01.In all, based on the above analysis on twoparameters, we demonstrate the effectiveness androbustness of our method for keyphrase extraction.4.1.3 When Titles/Summaries Are UnavailableSuppose in some special cases, the titles or sum-maries are unavailable, how can we construct trans-lation pairs?
Inspired by extraction-based documentsummarization (Goldstein et al, 2000; Mihalcea andTarau, 2004), we can extract one or more importantsentences from the given document to constructtranslation pairs.
Unsupervised sentence extraction0.250.30.350.40.450.50.550.60.650.70.05  0.1  0.15  0.2  0.25  0.3  0.35  0.4  0.45RecallPrecision?
= 0.01?
= 0.05?
= 0.10?
= 0.30?
= 0.50?
= 0.70?
= 0.90Figure 4: Precision-recall curves of WAM whenthreshold ?
ranges from 0.01 to 0.90.for document summarization is a well-studied taskin natural language processing.
As shown in Table 2,we only perform two simple sentence extractionmethods to demonstrate the effectiveness: (1) Selectthe first sentence of a document (denoted as ?First?
);and (2) Compute the cosine similarities betweeneach sentence and the whole document representedas two bags-of-words (denoted as ?Importance?
).It is interesting to find that the method of usingthe first sentence performs similar to using titles.This profits from the characteristic of news articleswhich tend to give a good summary for the wholearticle using the first sentence.
Although the secondmethod drops much on performance as compared tousing titles, it still outperforms than other existingmethods.
Moreover, the second method will im-prove much if we use more effective measures toidentify the most important sentence.Method Precision Recall F-measureFirst 0.290 0.410 0.327?0.013Importance 0.260 0.367 0.293?0.010Table 2: Precision, recall and F-measure ofkeyphrase extraction when Md = 2 by extracting onesentence to construct translation pairs.4.2 Beyond Extraction: Keyphrase GenerationIn Section 4.1, we evaluate our method on keyphraseextraction by suggesting keyphrases from docu-ments.
In fact, our method is also able to suggestkeyphrases that have not appeared in the content ofgiven document.
The ability is important especiallywhen the length of each document is short, which141itself may not contain appropriate keyphrases.
Wename the new task keyphrase generation.
Toevaluate these methods on keyphrase generation,we perform keyphrase generation for the titles ofdocuments, which are usually much shorter thantheir corresponding documents.
The experimentsetting is as follows: the training phase is thesame to the previous experiment, but in the testphase we suggest keyphrases only using the titles.LDA and ExpandRank, similar to our method, arealso able to select candidate keyphrases beyond thetitles.
We still use the annotated keyphrases of thecorresponding documents as standard answers.
Inthis case, about 59% standard keyphrases do notappear in titles.In Table 3 we show the evaluation results of vari-ous methods for keyphrase generation when Md = 2.ForWAM, we only show the results using title-basedpairs prepared with split method.
From the table,we have three observations: (1) WAM outperformsother methods on keyphrase generation.
Moreover,there are about 10% correctly suggested keyphrasesby WAM do not appear in titles, which indicates theeffectiveness of WAM for keyphrase generation.
(2)The performance of TFIDF and TextRank is muchlower as compared to Table 1, because the titles areso short that they do not provide enough candidatekeyphrases and even the statistical information torank candidate keyphrases.
(3) LDA, ExpandRankand WAM roughly keep comparable performance asin Table 1 (The performance of ExpandRank dropsa bit).
This indicates the three methods are able toperform keyphrase generation, and verifies again theeffectiveness of our method.Method Precision Recall F-measureTFIDF 0.105 0.141 0.115?0.004TextRank 0.107 0.144 0.118?0.005LDA 0.180 0.256 0.204?0.008ExpandRank 0.194 0.268 0.216?0.012WAM 0.296 0.420 0.334?0.009Table 3: Precision, recall and F-measure of variousmethods for keyphrase generation when Md = 2.To demonstrate the features of our method forkeyphrase generation, in Table 4 we list top-5keyphrases suggested by LDA, ExpandRank andWAM for a news article entitled Israeli MilitaryClaims Iran Can Produce Nuclear Bombs andConsidering Military Action against Iran (We trans-late the original Chinese title and keyphrases intoEnglish for comprehension.).
We have the followingobservations: (1) LDA suggests general words like?negotiation?
and ?sanction?
as keyphrases becausethe coarse-granularity of topics.
(2) ExpandRanksuggests some irrelevant words like ?Lebanon?
askeyphrases, which are introduced by neighbor doc-uments talking about other affairs related to Israel.
(3) Our method can generate appropriate keyphraseswith less topic-drift.
Moreover, our method can findgood keyphrases like ?nuclear weapon?
which evendo not appear in the title.LDA: Iran, U.S.A., negotiation, Israel, sanctionExpandRank: Iran, Israel, Lebanon, U.S.A., IsraeliMilitaryWAM: Iran, military action, Israeli Military, Israel,nuclear weaponTable 4: Top-5 keyphrases suggested by LDA,ExpandRank and WAM.5 Conclusion and Future WorkIn this paper, we provide a new perspective tokeyphrase extraction: regarding a document and itskeyphrases as descriptions to the same object writtenin two languages.
We use IBM Model-1 to bridgethe vocabulary gap between the two languages forkeyphrase generation.
We explore various methodsto construct translation pairs.
Experiments showthat our method can capture the semantic relationsbetween words in documents and keyphrases.
Ourmethod is also language-independent, which can beperformed on documents in any languages.We will explore the following two future work:(1) Explore our method on other types of articlesand on other languages.
(2) Explore more com-plicated methods to extract important sentences forconstructing translation pairs.AcknowledgmentsThis work is supported by the National NaturalScience Foundation of China (NSFC) under GrantNo.
60873174.
The authors would like to thankPeng Li and Xiance Si for their suggestions.142ReferencesM.
Banko, V.O.
Mittal, and M.J. Witbrock.
2000.Headline generation based on statistical translation.
InProceedings of ACL, pages 318?325.A.
Berger and J. Lafferty.
1999.
Information retrieval asstatistical translation.
In Proceedings of SIGIR, pages222?229.A.
Berger, R. Caruana, D. Cohn, D. Freitag, andV.
Mittal.
2000.
Bridging the lexical chasm: statisticalapproaches to answer-finding.
In Proceedings ofSIGIR, pages 192?199.D.M.
Blei and J.D.
Lafferty, 2009.
Text mining:Classification, Clustering, and Applications, chapterTopic models.
Chapman & Hall.D.M.
Blei, A.Y.
Ng, and M.I.
Jordan.
2003.
Latentdirichlet alocation.
Journal of Machine LearningResearch, 3:993?1022, January.P.F.
Brown, V.J.D.
Pietra, S.A.D.
Pietra, and R.L.Mercer.
1993.
The mathematics of statistical machinetranslation: Parameter estimation.
Computationallinguistics, 19(2):263?311.A.P.
Dempster, N.M. Laird, D.B.
Rubin, et al 1977.Maximum likelihood from incomplete data via the emalgorithm.
Journal of the Royal Statistical Society.Series B (Methodological), 39(1):1?38.P.
Duygulu, Kobus Barnard, J. F. G. de Freitas, andDavid A. Forsyth.
2002.
Object recognition asmachine translation: Learning a lexicon for a fixedimage vocabulary.
In Proceedings of ECCV, pages97?112.A.
Echihabi and D. Marcu.
2003.
A noisy-channelapproach to question answering.
In Proceedings ofACL, pages 16?23.E.
Frank, G.W.
Paynter, I.H.
Witten, C. Gutwin, and C.G.Nevill-Manning.
1999.
Domain-specific keyphraseextraction.
In Proceedings of IJCAI, pages 668?673.J.
Goldstein, V. Mittal, J. Carbonell, and M. Kantrowitz.2000.
Multi-document summarization by sentenceextraction.
In Proceedings of NAACL-ANLP 2000Workshop on Automatic summarization, pages 40?48.G.
Heinrich.
2005.
Parameter estimation for text anal-ysis.
Web: http://www.
arbylon.
net/publications/text-est.T.
Hofmann.
1999.
Probabilistic latent semanticindexing.
In Proceedings of SIGIR, pages 50?57.A.
Hulth.
2003.
Improved automatic keyword extractiongiven more linguistic knowledge.
In Proceedings ofEMNLP, pages 216?223.M.
Karimzadehgan and C.X.
Zhai.
2010.
Estimation ofstatistical translation models based on mutual informa-tion for ad hoc information retrieval.
In Proceedingsof SIGIR, pages 323?330.P.
Koehn.
2010.
Statistical Machine Translation.Cambridge University Press.T.K.
Landauer, P.W.
Foltz, and D. Laham.
1998.
Anintroduction to latent semantic analysis.
DiscourseProcesses, 25:259?284.Z.
Liu, P. Li, Y. Zheng, and M. Sun.
2009a.
Clusteringto find exemplar terms for keyphrase extraction.
InProceedings of EMNLP, pages 257?266.Z.
Liu, H. Wang, H. Wu, and S. Li.
2009b.
Collocationextraction using monolingual word alignment method.In Proceedings of EMNLP, pages 487?495.Z.
Liu, W. Huang, Y. Zheng, and M. Sun.
2010a.
Au-tomatic keyphrase extraction via topic decomposition.In Proceedings of EMNLP, pages 366?376.Z.
Liu, H. Wang, H. Wu, and S. Li.
2010b.
Improvingstatistical machine translation with monolingual collo-cation.
In Proceedings of ACL, pages 825?833.R.
Mihalcea and P. Tarau.
2004.
Textrank: Bringingorder into texts.
In Proceedings of EMNLP, pages404?411.V.
Murdock and W.B.
Croft.
2004.
Simple translationmodels for sentence retrieval in factoid question an-swering.
In Proceedings of SIGIR.T.
Nguyen and M.Y.
Kan. 2007.
Keyphrase extractionin scientific publications.
In Proceedings of the 10thInternational Conference on Asian Digital Libraries,pages 317?326.F.J.
Och and H. Ney.
2003.
A systematic comparison ofvarious statistical alignment models.
Computationallinguistics, 29(1):19?51.L.
Page, S. Brin, R. Motwani, and T. Winograd.
1998.The pagerank citation ranking: Bringing order tothe web.
Technical report, Stanford Digital LibraryTechnologies Project, 1998.C.
Quirk, C. Brockett, andW.
Dolan.
2004.
Monolingualmachine translation for paraphrase generation.
InProceedings of EMNLP, volume 149.S.
Riezler and Y. Liu.
2010.
Query rewriting usingmonolingual statistical machine translation.
Compu-tational Linguistics, 36(3):569?582.S.
Riezler, A. Vasserman, I. Tsochantaridis, V. Mittal, andY.
Liu.
2007.
Statistical machine translation for queryexpansion in answer retrieval.
In Proccedings of ACL,pages 464?471.S.
Riezler, Y. Liu, and A. Vasserman.
2008.
Translatingqueries into snippets for improved query expansion.
InProceedings of COLING, pages 737?744.G.
Salton and C. Buckley.
1988.
Term-weightingapproaches in automatic text retrieval.
Informationprocessing and management, 24(5):513?523.R.
Soricut and E. Brill.
2006.
Automatic questionanswering using the web: Beyond the factoid.
Infor-mation Retrieval, 9(2):191?206.143P.D.
Turney.
2000.
Learning algorithms for keyphraseextraction.
Information Retrieval, 2(4):303?336.X.
Wan and J. Xiao.
2008a.
Collabrank: towards acollaborative approach to single-document keyphraseextraction.
In Proceedings of COLING, pages 969?976.X.
Wan and J. Xiao.
2008b.
Single documentkeyphrase extraction using neighborhood knowledge.In Proceedings of AAAI, pages 855?860.I.H.
Witten, G.W.
Paynter, E. Frank, C. Gutwin, andC.G.
Nevill-Manning.
1999.
Kea: Practical automatickeyphrase extraction.
In Proceedings of DL, pages254?255.X.
Xue, J. Jeon, and W.B.
Croft.
2008.
Retrieval modelsfor question and answer archives.
In Proceedings ofSIGIR, pages 475?482.S.
Zhao, H. Wang, and T. Liu.
2010.
Paraphrasing withsearch engine query logs.
In Proceedings of COLING,pages 1317?1325.144
