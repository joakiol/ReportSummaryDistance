Automatic Title Generation for Spoken Broadcast NewsRong JinLanguage Technology InstituteCarnegie Mellon UniversityPittsburgh, PA 15213412-268-7003rong+@cs.cmu.eduAlexander G. HauptmannSchool of Computer ScienceCarnegie Mellon UniversityPittsburgh, PA 15213412-268-1448alex+@cs.cmu.eduABSTRACTIn this paper, we implemented a set of title generation methodsusing training set of 21190 news stories and evaluated them on anindependent test corpus of 1006 broadcast news documents,comparing the results over manual transcription to the results overautomatically recognized speech.
We use both F1 and the averagenumber of correct title words in the correct order as metric.Overall, the results show that title generation for speechrecognized news documents is possible at a level approaching theaccuracy of titles generated for perfect text transcriptions.KeywordsMachine learning, title generation1.
INTRODUCTIONTo create a title for a document is a complex task.
To generate atitle for a spoken document becomes even more challengingbecause we have to deal with word errors generated by speechrecognition.Historically, the title generation task is strongly connected totraditional summarization because it can be thought of extremelyshort summarization.
Traditional summarization has emphasizedthe extractive approach, using selected sentences or paragraphsfrom the document to provide a summary.
The weaknesses of thisapproach are inability of taking advantage of the training corpusand producing summarization with small ratio.
Thus, it will not besuitable for title generation tasks.More recently, some researchers have moved toward ?learningapproaches?
that take advantage of training data.
Witbrock andMittal [1] have used Na?ve Bayesian approach for learning thedocument word and title word correlation.
However they limitedtheir statistics to the case that the document word and the titleword are same surface string.
Hauptmann and Jin [2] extendedthis approach by relaxing the restriction.
Treating title generationproblem as a variant of Machine translation problem, Kennedyand Hauptmann [3] tried the iterative Expectation-Maximizationalgorithm.
To avoid struggling with organizing selected titlewords into human readable sentence, Hauptmann [2] used Knearest neighbour method for generating titles.
In this paper, weput all those methods together and compare their performanceover 1000 speech recognition documents.We decompose the title generation problem into two parts:learning and analysis from the training corpus and generating asequence of title words to form the title.For learning and analysis of training corpus, we present fivedifferent learning methods for comparison: Na?ve Bayesianapproach with limited vocabulary, Na?ve Bayesian approach withfull vocabulary, K nearest neighbors, Iterative Expectation-Maximization approach, Term frequency and inverse documentfrequency method.
More details of each approach will bepresented in Section 2.For the generating part, we decompose the issues involved asfollows: choosing appropriate title words, deciding how many titlewords are appropriate for this document title, and finding thecorrect sequence of title words that forms a readable title?sentence?.The outline of this paper is as follows: Section 1 gave anintroduction to the title generation problem.
The details of theexperiment and analysis of results are presented in Section 2.Section 3 discusses our conclusions drawn from the experimentand suggests possible improvements.2.
THE CONTRASTIVE TITLEGENERATION EXPERIMENTIn this section we describe the experiment and present the results.Section 2.1 describes the data.
Section 2.2 discusses theevaluation method.
Section 2.3 gives a detailed description of allthe methods, which were compared.
Results and analysis arepresented in section 2.4.2.1 Data DescriptionIn our experiment, the training set, consisting of 21190 perfectlytranscribed documents, are obtain from CNN web site during1999.
Included with each training document text was a humanassigned title.
The test set, consisting of 1006 CNN TV newsstory documents for the same year (1999), are randomly selectedfrom the Informedia Digital Video Library.
Each document has aclosed captioned transcript, an alternative transcript generatedwith CMU Sphinx speech recognition system with a 64000-wordbroadcast news language model and a human assigned title.2.2 EvaluationFirst, we evaluate title generation by different approaches usingthe F1 metric.
For an automatically generated title Tauto, F1 ismeasured against corresponding human assigned title Thuman asfollows:F1 = 2?precision?recall / (precision + recall)Here, precision and recall is measured respectively as the numberof identical words in Tauto and Thuman over the number ofwords in Tauto and the number of words in Thuman.
Obviouslythe sequential word order of the generated title words is ignoredby this metric.To measure how well a generated title compared to the originalhuman generated title in terms of word order, we also measuredthe number of correct title words in the hypothesis titles that werein the same order as in the reference titles.We restrict all approaches to generate only 6 title words, which isthe average number of title words in the training corpus.
Stopwords were removed throughout the training and testingdocuments and also removed from the titles.2.3 Description of the Compared TitleGeneration ApproachesThe five different title generation methods are:1.
Na?ve Bayesian approach with limited vocabulary (NBL).It tries to capture the correlation between the words in thedocument and the words in the title.
For each document wordDW, it counts the occurrence of title word same as DW andapply the statistics to the test documents for generating titles.2.
Na?ve Bayesian approach with full vocabulary (NBF).
Itrelaxes the constraint in the previous approach and counts allthe document-word-title-word pairs.
Then this full statisticswill be applied on generating titles for the test documents.3.
Term frequency and inverse document frequencyapproach (TF.IDF).
TF is the frequency of words occurringin the document and IDF is logarithm of the total number ofdocuments divided by the number of documents containingthis word.
The document words with highest TF.IDF werechosen for the title word candidates.4.
K nearest neighbor approach (KNN).
This algorithm issimilar to the KNN algorithm applied to topic classification.It searches the training document set for the closest relateddocument and assign the training document title to the newdocument as title.5.
Iterative Expectation-Maximization approach (EM).
Itviews documents as written in a ?verbal?
language and theirtitles as written a ?concise?
language.
It builds the translationmodel between the ?verbal?
language and the ?concise?language from the documents and titles in the training corpusand ?translate?
each testing document into title.2.4 The sequentializing process for title wordcandidatesTo generate an ordered set of candidates, equivalent to what wewould expect to read from left to right, we built a statisticaltrigram language model using the SLM tool-kit (Clarkson, 1997)and the 40,000 titles in the training set.
This language model wasused to determine the most likely order of the title wordcandidates generated by the NBL, NBF, EM and TF.IDF methods.3.
RESULTS AND OBSERVATIONSThe experiment was conducted both on the closed captiontranscripts and automatic speech recognized transcripts.
The F1results and the average number of correct title word in correctorder are shown in Figure 1 and 2 respectively.KNN works surprisingly well.
KNN generates titles for a newdocument by choosing from the titles in the training corpus.
Thisworks fairly well because both the training set and test set comefrom CNN news of the same year.
Compared to other methods,KNN degrades much less with speech-recognized transcripts.Meanwhile, even though KNN performance not as well as TF.IDFand NBL in terms of F1 metric, it performances best in terms ofthe average number of correct title words in the correct order.
Ifconsideration of human readability matters, we would expectKNN to outperform considerately all the other approaches since itis guaranteed to generate human readable title.Comparison of F10.00%5.00%10.00%15.00%20.00%25.00%30.00%KNNTFIDF NBLNBF EMMethodsF1originaldocumentsspokendocumentsFigure 1: Comparison of Title Generation Approaches on atest corpus of 1006 documents with either perfect transcript orspeech recognized transcripts using the F1 score.NBF performs much worse than NBL.
NBF performances muchworse than NBL in both metrics.
The difference between NBF andNBL is that NBL assumes a document word can only generate atitle word with the same surface string.
Though it appears thatNBL loses information with this very strong assumption, theresults tell us that some information can safely be ignored.
InNBF, nothing distinguishes between important words and trivialwords.
This lets frequent, but unimportant words dominate thedocument-word-title-word correlation.Light learning approach TF.IDF performances considerablywell compared with heavy learning approaches.
Surprisingly,heavy learning approaches, NBL, NBF and EM algorithm didn?tout performance the light learning approach TF.IDF.
We thinklearning the association between document words and title wordsby inspecting directly the document and its title is veryproblematic since many words in the document don?t reflect itscontent.
The better strategy should be distilling the document firstbefore learning the correlation between document words and titlewords.Comparison of # of Correct Words inCorrect Order00.10.20.30.40.50.60.70.8KNNTFIDF NBLNBF EMMethods#ofCorrect WordsintheCorrect OrderoriginaldocumentsspokendocumentsFigure 1: Comparison of Title Generation Approaches on atest corpus of 1006 documents with either perfect transcript orspeech recognized transcripts using the average number ofcorrect words in the correct order.4.
CONCLUSIONFrom the analysis discussed in previous section, we draw thefollowing conclusions:1.
The KNN approach works well for title generation especiallywhen overlap in content between training dataset and testcollection is large.2.
The fact that NBL out performances NBF and TF.IDF outperformance NBL and suggests that we need to distinguishimportant document words from those trivial words.5.
ACKNOWLEDGMENTSThis material is based in part on work supported by NationalScience Foundation under Cooperative Agreement No.
IRI-9817496.
Partial support for this work was provided by theNational Science Foundation?s National Science, Mathematics,Engineering, and Technology Education Digital Library Programunder grant DUE-0085834.
This work was also supported in partby the Advanced Research and Development Activity (ARDA)under contract number MDA908-00-C-0037.
Any opinions,findings, and conclusions or recommendations expressed in thismaterial are those of the authors and do not necessarily reflect theviews of the National Science Foundation or ARDA.6.
REFERENCES[1] Michael Witbrock and Vibhu Mittal.
Ultra-Summarization:A Statistical Approach to Generating Highly CondensedNon-Extractive Summaries.
Proceedings of SIGIR 99,Berkeley, CA, August 1999.
[2] R. Jin and A.G. Hauptmann.
Title Generation for SpokenBroadcast News using a Training Corpus.
Proceedings of 6thInternal Conference on Language Processing (ICSLP 2000),Beijing China.
2000.
[3] P. Kennedy and A.G. Hauptmann.
Automatic TitleGeneration for the Informedia Multimedia Digital Library.ACM Digital Libraries, DL-2000, San Antonio Texas, May2000.
