Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 252?261,Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational LinguisticsOnline Polylingual Topic Models for Fast Document Translation DetectionKriste KrstovskiSchool of Computer ScienceUniversity of Massachusetts AmherstAmherst, MA, 01003kriste@cs.umass.eduDavid A. SmithSchool of Computer ScienceUniversity of Massachusetts AmherstAmherst, MA, 01003dasmith@cs.umass.eduAbstractMany tasks in NLP and IR require ef-ficient document similarity computations.Beyond their common application to ex-ploratory data analysis, latent variabletopic models have been used to representtext in a low-dimensional space, indepen-dent of vocabulary, where documents maybe compared.
This paper focuses on thetask of searching a large multilingual col-lection for pairs of documents that aretranslations of each other.
We present(1) efficient, online inference for repre-senting documents in several languages ina common topic space and (2) fast ap-proximations for finding near neighbors inthe probability simplex.
Empirical evalu-ations show that these methods are as ac-curate as?and significantly faster than?Gibbs sampling and brute-force all-pairssearch.1 IntroductionStatistical topic models, such as latent Dirich-let alcation (LDA) (Blei et al 2003), haveproven to be highly effective at discovering hid-den structure in document collections (Hall et al2008, e.g.).
Often, these models facilitate ex-ploratory data analysis, by revealing which col-locations of terms are favored in different kindsof documents or which terms and topics rise andfall over time (Blei and Lafferty, 2006; Wang andMcCallum, 2006).
One of the greatest advan-tages in using topic models to analyze and processlarge document collections is their ability to rep-resent documents as probability distributions overa small number of topics, thereby mapping doc-uments into a low-dimensional latent space?theT -dimensional probability simplex, where T is thenumber of topics.
A document, represented bysome point in this simplex, is said to have a par-ticular ?topic distribution?.Representing documents as points in a low-dimensional shared latent space abstracts awayfrom the specific words used in each document,thereby facilitating the analysis of relationshipsbetween documents written using different vocab-ularies.
For instance, topic models have been usedto identify scientific communities working on re-lated problems in different disciplines, e.g., workon cancer funded by multiple Institutes within theNIH (Talley et al 2011).
While vocabulary mis-match occurs within the realm of one language,naturally this mismatch occurs across differentlanguages.
Therefore, mapping documents in dif-ferent languages into a common latent topic spacecan be of great benefit when detecting documenttranslation pairs (Mimno et al 2009; Platt et al2010).
Aside from the benefits that it offers in thetask of detecting document translation pairs, topicmodels offer potential benefits to the task of creat-ing translation lexica, aligning passages, etc.The process of discovering relationship be-tween documents using topic models involves: (1)representing documents in the latent space by in-ferring their topic distributions and (2) comparingpairs of topic distributions to find close matches.Many widely used techniques do not scale ef-ficiently, however, as the size of the documentcollection grows.
Posterior inference by Gibbssampling, for instance, may make thousands ofpasses through the data.
For the task of comparingtopic distributions, recent work has also resortedto comparing all pairs of documents (Talley et al2011).This paper presents efficient methods for both252of these steps and performs empirical evaluationson the task of detected translated document pairsembedded in a large multilingual corpus.
Unlikesome more exploratory applications of topic mod-els, translation detection is easy to evaluate.
Theneed for bilingual training data in many languagepairs and domains also makes it attractive to mit-igate the quadratic runtime of brute force transla-tion detection.
We begin in ?2 by extending theonline variational Bayes approach of Hoffman etal.
(2010) to polylingual topic models (Mimno etal., 2009).
Then, in ?3, we build on prior workon efficient approximations to the nearest neighborproblem by presenting theoretical and empiricalevidence for applicability to topic distributions inthe probability simplex and in ?4, we evaluate thecombination of online variational Bayes and ap-proximate nearest neighbor methods on the trans-lation detection task.2 Online Variational Bayes forPolylingual Topic ModelsHierarchical generative Bayesian models, such astopic models, have proven to be very effectivefor modeling document collections and discover-ing underlying latent semantic structures.
Mostcurrent topic models are based on Latent Dirich-let Allocation (LDA) (Blei et al 2003).
In someearly work on the subject, Blei and Jordan (2003)showed the usefulness of LDA on the task of auto-matic annotation of images.
Hall et al(2008) usedLDA to analyze historical trends in the scientificliterature; Wei and Croft (2006) showed improve-ments on an information retrieval task.
More re-cently Eisenstein et al(2010) modeled geographiclinguistic variation using Twitter data.Aside from their widespread use on monolin-gual text, topic models have also been used tomodel multilingual data (Boyd-Graber and Blei,2009; Platt et al 2010; Jagarlamudi and Daume?,2010; Fukumasu et al 2012), to name a few.In this paper, we focus on the Polylingual TopicModel, introduced by Mimno et al(2009).
Givena multilingual set of aligned documents, the PLTMassumes that across an aligned multilingual doc-ument tuple, there exists a single, tuple-specific,distribution across topics.
In addition, PLTM as-sumes that for each language?topic pair, there ex-ists a distribution over words in that language ?l.As such, PLTM assumes that the multilingual cor-pus is created through a generative process whereD TT...DwzN1wzNL...1ELE1KLKFigure 1: Polylingual topic model (PLTM)first a document tuple is generated by drawing atuple-specific distribution over topics ?1 which, asit is the case with LDA, is drawn from a Dirich-let prior ?
?
Dir (?)
.
For each of the languagesl in the tuple and for each of the N words wln inthe document the generative process: first choosesa topic assignment zln ?Multinomial (?)
whichis then followed by choosing a word wln from amultinomial distribution conditioned on the topicassignment and the language specific topics distri-bution over words ?l?Dir (?l).
Both?
and ?1,...,Lare symmetric priors, i.e.
the priors are exchange-able Dirichlet distributions.
Finally, each wordis generated from a language- and topic-specificmultinomial distribution ?lt as selected by the topicassignment variable zln:wln ?
p(wln | zln, ?ln)(1)Figure 1 shows a graphical representation ofthe PLTM using plate notation.
In their originalwork Mimno et al(2009) used the Gibbs sam-pling approach as a posterior inference algorithmto assign topics distributions over their test collec-tion.
While more straightforward to implement,this sampling approach is inherently slow whenapplied to large collections which makes the orig-inal PLTM work practically infeasible to be usedon real-world data sets.In general, performing posterior inference overthe latent variables of a Bayesian model is usu-ally done with two of the three approximate ap-proaches, Gibbs sampling, variational Bayes (VB)and expectation-propagation.
While Gibbs Sam-pling is a variation of Markov Chain Monte Carlomethod (MCMC) which generates a sample fromthe true posterior after converging to a stationary1In the traditional LDA model ?
is used to specify thedocument specific distribution over topics.253distribution; in VB, a set of free variational param-eters characterizes a simpler family of probabil-ity distributions.
These variational parameters arethen optimized by finding the minimum Kullback-Leibler (KL) divergence between the variationaldistribution q (?, z, ?|?, ?, ?)
and the true pos-terior P (?, z, ?|w,?, ?).
From an algorithmicperspective, the variational Bayes approach fol-lows the Expectation-Maximization (EM) proce-dure where for a given document, the E-step up-dates the per document variational parameters ?dand ?d while holding the per words-topic distribu-tion parameter ?
fixed.
It then updates the vari-ational parameter ?
using the sufficient statisticscomputed in the E step.
In order to converge toa stationary point, both approaches require goingover the whole collection multiple times whichmakes their time complexity to grown linearlywith the size of the data collection.
The mere factthat they require continuous access to the wholecollection makes both inference approaches im-practicable to use on very large or streaming col-lections.
To alleviate this problem, several algo-rithms have been proposed that draws from beliefpropagation (Zeng et al 2012), the Gibbs sam-pling approach such as (Canini et al 2009), vari-ational Bayes (Hoffman et al 2010) as well asa combination of the latter two (Hoffman et al2012) to name a few.
In this paper we use Hoff-man et al(2010) approach.
Hoffman et al(2010)proposed a new inference approach called OnlineLDA which relies on the stochastic gradient de-scent to optimize the variational parameters.
Thisapproach can produce good estimates of LDA pos-teriors in a single pass over the whole collection.2.1 Algorithmic ImplementationWe now derive an online variational Bayes algo-rithm for PLTM to infer topic distributions overmultilingual collections.
Figure 2 shows the vari-ational model and free parameters used in our ap-proach.
As in the case of Hoffman et al(2010),our algorithm updates the variational parameters?ld and ?ld on each batch of documents while thevariational parameter ?
is computed as a weightedaverage of the value on the previous batch and itsapproximate version ??.
Averaging is performedusing a decay function whose parameters controlthe rate at which old values of ?l are forgotten.Within the E step of the VB approach, we com-pute the updates over the variational parameter ?lT.
.
.DT zN1zNL.
.
.J 1I LI1E LE1O LOFigure 2: Graphical model representation of thefree variational parameters for the online varia-tional Bayes approximation of the PLTM posteriorfor each language L present in our document tuplewhile the update on the ?
parameter accumulatesthe language specific sufficient statistics:?mk = ?+?l?w?mlwk nmlw (2)We detail these steps in Algorithm 1.2.2 Performance AnalysisTo demonstrate the efficacy of online PLTM, weran topic inference on a subset of the English-Spanish Europarl collection consisting of ?64kparallel speeches and compared the accuracy re-sults vs. the training and inference speed againstthe original PLTM model using topic sets ofT=50,100, 200 and 500.
We explain in detailsthe evaluation task and the performance metricused in ?4.
Shown in Figure 3 are the results ofthese comparisons.
Our speed measurements wereperformed on Xeon quad processors with a clockspeed of 2.66GHz and a total of 16GB of memory.As we increase the number of topics we gain inaccuracy over the evaluation task across both in-ference approaches.
When we increase the num-ber of topics from 50 to 500 the speed improve-ment obtained by Online VB PLTM drops by afactor of 2.9 within the training step and by afactor of 4.45 in the test step.
Our total runningtime for the Online VB PLTM with T=500 ap-proaches the running time of the Gibbs samplingapproach with T=50.
The gradual drop in speedimprovement with the increase of the number top-ics is mostly attributed to the commutation of the254Algorithm 1 Online variational Bayes for PLTMinitialize ?l randomlyobtain the tth mini-batch of tuples Mtfor t = 1 to ?
do?t ?
(1t0+t)?E step:initialize ?t randomlyfor each document tuple in mini-batch tfor m in Mt dorepeatfor l ?
1, .
.
.
,L do?mlwk ?exp {Eq [log ?mk ]} ?exp{Eq[log ?mlkw]}end for?mk = ?+?l?w ?mlwk nmlwuntil convergenceend forM step:for l ?
1, .
.
.
,L do?
?lkw = ?
+D?m ?mlwknmlw?ltkw ?
(1?
?t)?l(t?1)kw + ?t?
?lkwend forend for0 2000 4000 6000 8000 10000 120000102030405060708090100Accuracy[%@Rank 1.
]Running time [sec]Accuracy vs. Running timeGibbs samplingOnline VBT=50T=100T=200 T=500 T=500T=200T=100T=50Figure 3: Speed vs. accuracy comparison betweenOnline VB PLTM and Gibbs Sampling PLTM atT=50,100, 200 and 500.
We used a Python imple-mentation of Online VB and Mallet?s Java imple-mentation of PLTM with in-memory Gibbs Sam-pling using 1000 iterations.0 50 100 250 500 750 1,000020,00040,00060,00080,000100,000120,000140,000160,000180,000200,000Collection size [k]Trainingtime[sec]Collection size vs. training timeGibbs sampling T=50Online VB T=50Gibbs sampling T=500Online VB T=500Figure 4: Collection size vs. training time compar-ison between Online VB PLTM and Gibbs Sam-pling PLTM using multilingual collections of 50k,100k, 250k, 500k, 750k and 1M speech pairs.digamma function (Asuncion et al 2009) whosetime complexity increases linearly with the num-ber of topics.While a multilingual collection of ?64k docu-ment pairs is considered relatively big, our goalof deriving the Online VB PLTM approach was tobe able to utilize PLTM on very large multilingualcollections.
To analyze the potential of using On-line VB PLTM on such collections we ran speedcomparisons within the training step by creatingmultilingual collections of different lengths multi-plying the original English-Spanish Europarl col-lection.
Speed comparisons using collections oflength 50K, 100K, 250K, 500K, 750K and 1M areshown in Figure 4.
Training was performed withthe number of topics T set to T=50 and T=500.As we increase the collection size we observethe real benefit of using Online VB compared toGibbs sampling.
This is mostly attributed to thefact that the Gibbs sampling approach requiresmultiple iterations over the whole collection in or-der to achieve a convergence point.
For collec-tion sizes of 50k and 100k the training time forthe Online VB PLTM with T=500 approaches thetraining time of Gibbs sampling with T=50 and aswe increase the collection size this proximity dis-sipates.In Figure 5 we show a sample set of the alignedtopics extracted using Online VB PLTM withT=400 on the English-Spanish Europarl collec-tion.
For a given topic tuple words are orderedbased on probability of occurrence within thegiven topic.255	 		!	"#"#		$%"	 %	 & 	#&#	#	 	&	 	$$%!				'(	%	)	"%%#		 !	#		!( !		((!&#"#*&"%Figure 5: Sample set of topics extracted from Europarl English-Spanish collection of 64k speeches usingOnline PLTM with T=400 ordered based on their probability of occurrence within the topic.3 Approximate NN Search in theProbability SimplexOne of the most attractive applications for topicmodels has involved using the latent variables asa low-dimensional representation for documentsimilarity computations (Hall et al 2008; Boyd-Graber and Resnik, 2010; Talley et al 2011).
Af-ter computing topic distributions for documents,however, researchers in this line of work have al-most always resorted to brute-force all-pairs simi-larity comparisons between topic distributions.In this section, we present efficient methods forapproximate near neighbor search in the proba-bility simplex in which topic distributions live.Measurements for similarity between two proba-bility distributions are information-theoretic, anddistance metrics, typical for the metric space, arenot appropriate (measurements such as Euclidean,cosine, Jaccard, etc.).
Divergence metrics, such asKullback-Leibler (KL), Jensen-Shannon (JS), andHellinger distance are used instead.
Shown in Fig-ure 6 are the formulas of the divergence metricsalong with the Euclidean distance.
When dealingwith a large data set of N documents, the O(N2)time complexity of all-pairs comparison makes thetask practically infeasible.
With some distancemeasures, however, the time complexity on nearneighbor tasks has been alleviated using approxi-mate methods that reduce the time complexity ofeach query to a sub-linear number of comparisons.For example, Euclidean distance (3) has been effi-ciently used on all-pairs comparison tasks in largedata sets thanks to its approximate based versionsdeveloped using locality sensitive hashing (LSH)(Andoni et al 2005) and k-d search trees (Fried-man et al 1977).
In order to alleviate the all-pairscomputational complexity in the probability sim-plex, we will use a reduction of the Hellinger di-vergence measure (4) to Euclidean distance andtherefore utilize preexisting approximation tech-niques for the Euclidean distance in the probabilitysimplex.This reduction comes from the fact that bothmeasurements have similar algebraic expressions.If we discard the square root used in the Euclideandistance, Hellinger distance (4) becomes equiva-lent to the Euclidean distance metric (3) between?pi and ?qi.
The task of finding nearest neigh-bors for a given point (whether in the metric spaceor the probability simplex) involves ranking allnearest points discovered and as such not com-puting the square root function does not affect theoverall ranking and the nearest neighbor discov-ery.
Moreover, depending on its functional form,the Hellinger distance is often defined as squareroot over the whole summation.
Aside from theHellinger distance, we also approximate Jensen-Shannon divergence which is a symmetric ver-sion of the Kullback-Liebler divergence.
For theJS approximation, we will use a constant factorrelationship between the Jensen-Shannon diver-gence an Hellinger distance previously exploredby (Tops?e, 2000).
More specifically, we will beusing its more concise form (7) also presented by256Eu(p, q) =???
?n?i=1(pi ?
qi)2 (3)He(p, q) =n?i=1(?p(xi)?
?q(xi))2 (4)KL(p, q) =n?i=1p(xi) logp(xi)q(xi)(5)JS(p, q) = 12KL(p, p+ q2)+12KL(q, p+ q2)(6)12He(p, q) ?
JS(p, q) ?
2 ln(2)He(p, q) (7)Figure 6: Distance measures and bounds(Guha et al 2006).
The constant factor relation-ship provides us with the theoretical guaranteesnecessary for this approximation.In practice, we can often do much better thanthis theoretical bound.
Figure 7 shows the empiri-cal relation of JS and Hellinger on a translation-detection task.
As will be described in ?4, wecomputed the JS and Hellinger divergences be-tween topic distributions of English and SpanishEuroparl speeches for a total of 1 million docu-ment pairs.
Each point in the figure representsone Spanish-English document pair that might ormight not be translations of each other.
In thisfigure we emphasize the lower left section of theplot where the nearest neighbors (i.e., likely trans-lations) reside, and the relationship between JSand Hellinger is much tighter than the theoreticalbounds and from pratical perspective as we willshow in the next section.
As a summary for thereader, using the above approaches, we will ap-proximate JS divergence by using the Euclideanbased representation of the Hellinger distance.
Asstated earlier, the Euclidean based representationis computed using well established approximationapproaches and in our case we will use two suchapproaches: the Exact Euclidean LSH (E2LSH)(Andoni et al 2005) and the k-d trees implemen-tation within the Approximate Nearest Neighbor(ANN) library (Mount and Arya, 2010).0 0.02 0.04 0.06 0.08 0.100.020.040.060.080.10.120.140.160.180.2Hellinger DistanceJensen?Shannon DivergenceHellingerUpper boundLower BoundFigure 7: Empirical evidence of the bounds pre-sented in Eq.
7 on 1 million document pairs?zoomed section where nearest neighbors reside.The lower bound is He(p, q) = 12 ln(2)JS(p, q)while the upper bound is He(p, q) = 2JS(p, q).4 Efficient Approximate TranslationDetectionMapping multilingual documents into a common,language-independent vector space for the pur-pose of improving machine translation (MT) andperforming cross-language information retrieval(CLIR) tasks has been explored through vari-ous techniques.
Mimno et al(2009) introducedpolylingual topic models (PLTM), an extension oflatent Dirichlet alcation (LDA), and, more re-cently, Platt et al(2010) proposed extensions ofprincipal component analysis (PCA) and proba-bilistic latent semantic indexing (PLSI).
Both thePLTM and PLSI represent bilingual documents inthe probability simplex, and thus the task of find-ing document translation pairs is formulated asfinding similar probability distributions.
Whilethe nature of both works was exploratory, resultsshown on fairly large collections of bilingual doc-uments (less than 20k documents) offer convinc-ing argument of their potential.
Expanding theseapproaches to much large collections of multilin-gual documents would require utilizing fast NNsearch for computing similarity in the probabil-ity simplex.
While there are many other proposedapproaches to the task of finding document trans-lation pairs that represent documents in metricspace, such as Krstovski and Smith (2011) whichutilizes LSH for cosine distance, there is no evi-dence that they yield good results on documentsof small lengths such as paragraphs and even sen-257tences.In this section, we empirically show how to uti-lize approaches that deal with representing docu-ments in the probability simplex without a signif-icant loss in accuracy while significantly improv-ing the processing time.
We use PLTM represen-tations of bilingual documents.
In addition, weshow how the results as reported by Platt et al(2010) can be obtained using the PLTM represen-tation with a significant speed improvement.As in (Platt et al 2010) and (Mimno et al2009) the task is to find document translation pairsin a multilingual collection of documents by rep-resenting documents in the probability simplexand computing similarity between their probabil-ity distribution representation across all documentpairs.
For this experimental setup, accuracy is de-fined as the number of times (in percentage) thatthe target language document was discovered atrank 1 (i.e.
% @Rank 1.)
across the whole testcollection.4.1 Experimental SetupWe use Mallet?s (McCallum, 2002) implementa-tion of the PLTM to train and infer topics on thesame data set used in Platt et al(2010).
Thatpaper used the Europarl (Koehn, 2005) multilin-gual collection of English and Spanish sessions.Their training collection consists of speeches ex-tracted from all Europarl sessions from the years1996 through 1999 and the year 2002 and a devel-opment set which consists of speeches from ses-sions in 2001.
The test collection consists of Eu-roparl speeches from the year 2000 and the firstnine months of 2003.
While Platt et al(2010) dooffer absolute performance comparison betweentheir JPLSA approach and previous results pub-lished by (Mimno et al 2009), these performancecomparisons are not done on the same training andtest sets?a gap that we fill below.We train PLTM models with number of topics Tset to 50, 100, 200, and 500.
In order to compareexactly the same topic distributions when comput-ing speed vs. accuracy of various approximate andexhaustive all-pairs comparisons we focus only onone inference approach - the Gibbs sampling andignore the online VB approach as it yields sim-ilar performance.
For all four topic models, weuse the same settings for PLTM (hyperparame-ter values and number of Gibbs sampling itera-tions) as in (Mimno et al 2009)2.
Topic distribu-tions were then inferred on the test collection us-ing the trained topics.
We then performed all-pairscomparison using JS divergence, Hellinger dis-tance, and approximate, LSH and kd-trees based,Hellinger distance.
We measured the total timethat it takes to perform exhaustive all-pairs com-parison using JS divergence, the LSH and kd-trees version on a single machine consisting of acore 2 duo quad processors with a clock speed of2.66GHz on each core and a total of 8GB of mem-ory.
Since the time performance of the E2LSH de-pends on the radius R of data set points consideredfor each query point (Indyk and Motwani, 1998),we performed measurements with different valuesof R. For this task, the all-pairs JS code implemen-tation first reads both source and target sets of doc-uments and stores them in hash tables.
We then goover each entry in the source table and compute di-vergence against all target table entries.We refer tothis code implementation as hash map implemen-tation.4.2 Evaluation Task and ResultsPerformance of the four PLTM models and theperformance across the four different similaritymeasurements was evaluated based on the percent-age of document translation pairs (out of the wholetest set) that were discovered at rank one.
Thissame approach was used by (Platt et al 2010) toshow the absolute performance comparison.
As inthe case of the previous two tasks, in order to eval-uate the approximate, LSH based, Hellinger dis-tance we used values of R=0.4, R=0.6 and R=0.8.Since in (Platt et al 2010) numbers were reportedon the test speeches whose word length is greateror equal to 100, we used the same subset (to-tal of 14150 speeches) of the original test col-lection.
Shown in Table 1 are results across thefour different measurements for all four PLTMmodels.
When using regular JS divergence, ourPLTM model with 200 topics performs the bestwith 99.42% of the top one ranked candidate trans-lation documents being true translations.
Whenusing approximate, kd-trees based, Hellinger dis-tance, we outperform regular JS and Hellingerdivergence across all topics and for T=500 weachieve the best overall accuracy of 99.61%.
Webelieve that this is due to the small amount of error2We start off by first replicating the results as in (Mimnoet al 2009) and thus verifying the functionality of our exper-imental setup.258Divergence T=50 100 200 500JS 94.27 98.48 99.42 99.33He 94.30 98.45 99.40 99.31He LSH R=0.4 93.95 97.46 98.27 98.01He LSH R=0.6 94.30 98.46 99.40 99.31He LSH R=0.8 94.30 98.45 99.34 99.31He kd-trees 94.86 98.90 99.50 99.61Table 1: Percentage of document pairs with thecorrect translation discovered at rank 1: compari-son of different divergence measurements and dif-ferent numbers T of PLTM topics.Divergence T=50 100 200 500JS 7.8 4.6 2.4 1.0He LSH R=0.4 511.5 383.6 196.7 69.7He LSH R=0.6 142.1 105.0 59.0 18.6He LSH R=0.8 73.8 44.7 29.5 16.3He kd-trees 196.7 123.7 76.7 38.5Table 2: Relative speed improvement between all-pairs JS divergence and approximate He diver-gence via kd-trees and LSH across different valuesof radius R. The baseline is brute-force all-pairscomparison with Jensen-Shannon and 500 topics.in the search introduced by ANN, due to its ap-proximate nature, which for this task yields pos-itive results.
On the same data set, (Platt et al2010) report accuracy of 98.9% using 50 topics, aslightly different prior distribution, and MAP in-stead of posterior inference.Shown in Table 2 are the relative differences intime between all pairs JS divergence, approximatekd-trees and LSH based Hellinger distance withdifferent value of R. Rather than showing abso-lute speed numbers, which are often influenced bythe processor configuration and available memory,we show relative speed improvements where wetake the slowest running configuration as a refer-ent value.
In our case we assign the referent speedvalue of 1 to the configuration with T=500 and all-pairs JS computation.
Results shown are basedon comparing running time of E2LSH and ANNagainst the all-pairs similarity comparison imple-mentation that uses hash tables to store all docu-ments in the bilingual collection which is signifi-cantly faster than the other code implementation.For the approximate, LSH based, Hellinger dis-tance with T=100 we obtain a speed improve-ment of 24.2 times compared to regular all-pairsJS divergence while maintaining the same per-formance compared to Hellinger distance metricand insignificant loss over all-pairs JS divergence.From Table 2 it is evident that as we increase theradius R we reduce the relative speed of perfor-mance since the range of points that LSH consid-ers for a given query point increases.
Also, as thenumber of topics increases, the speed benefit is re-duced for both the LSH and k-d tree techniques.5 ConclusionHierarchical Bayesian models, such as Polylin-gual Topic Models, have been shown to offergreat potential in analyzing multilingual collec-tions, extracting aligned topics and finding docu-ment translation pairs when trained on sufficientlylarge aligned collections.
Online stochastic opti-mization inference allows us to generate good pa-rameter estimates.
By combining these two ap-proaches we are able to infer topic distributionsacross documents in large multilingual documentcollections in an efficient manner.
Utilizing ap-proximate NN search techniques in the probabilitysimplex, we showed that fast document translationdetection could be achieved with insignificant lossin accuracy.6 AcknowledgmentsThis work was supported in part by the Centerfor Intelligent Information Retrieval and in part byNSF grant #IIS-0910884.
Any opinions, findingsand conclusions or recommendations expressed inthis material are those of the authors and do notnecessarily reflect those of the sponsor.ReferencesAlexandr Andoni, Mayur Datar, Nicole Immorlica, Pi-otr Indyk, and Vahab Mirrokni.
2005.
Locality-sensitive hashing using stable distributions.
InG.
Shakhnarovich, T. Darrell, and P. Indyk, editors,Nearest Neighbor Methods in Learning and Vision:Theory and Practice, pages 61?72.
MIT Press.Arthur Asuncion, Max Welling, Padhraic Smyth, andYee Whye Teh.
2009.
On smoothing and inferencefor topic models.
In Proceedings of the Twenty-FifthConference on Uncertainty in Artificial Intelligence,UAI ?09, pages 27?34, Arlington, Virginia, UnitedStates.
AUAI Press.David M. Blei and Michael I. Jordan.
2003.
Modelingannotated data.
In Proceedings of the 26th annualinternational ACM SIGIR conference on Research259and development in informaion retrieval, SIGIR ?03,pages 127?134, New York, NY, USA.
ACM.David M. Blei and John D. Lafferty.
2006.
Dynamictopic models.
In Proceedings of the 23rd interna-tional conference on Machine learning, ICML ?06,pages 113?120, New York, NY, USA.
ACM.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent dirichlet alcation.
J. Mach.
Learn.Res., 3:993?1022, March.Jordan Boyd-Graber and David M. Blei.
2009.
Multi-lingual topic models for unaligned text.
In Proceed-ings of the Twenty-Fifth Conference on Uncertaintyin Artificial Intelligence, UAI ?09, pages 75?82, Ar-lington, Virginia, United States.
AUAI Press.Jordan Boyd-Graber and Philip Resnik.
2010.
Holis-tic sentiment analysis across languages: multilin-gual supervised latent dirichlet alcation.
In Pro-ceedings of the 2010 Conference on Empirical Meth-ods in Natural Language Processing, EMNLP ?10,pages 45?55, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Kevin R. Canini, Lei Shi, and Thomas L. Griffiths.2009.
Online inference of topics with latent dirichletallocation.
In Proceedings of the 12th InternationalConference on Artificial Intelligence and Statistics(AISTATS).Jacob Eisenstein, Brendan O?Connor, Noah A. Smith,and Eric P. Xing.
2010.
A latent variable modelfor geographic lexical variation.
In Proceedings ofthe 2010 Conference on Empirical Methods in Natu-ral Language Processing, EMNLP ?10, pages 1277?1287, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.J.
H. Friedman, J. L. Bentley, and R. A. Finkel.
1977.An algorithm for finding best matches in logarithmicexpected time.
ACM Transactions on MathematicalSoftware, 3(3):209?226.Kosuke Fukumasu, Koji Eguchi, and Eric Xing.
2012.Symmetric correspondence topic models for multi-lingual text analysis.
In P. Bartlett, F.C.N.
Pereira,C.J.C.
Burges, L. Bottou, and K.Q.
Weinberger, ed-itors, Advances in Neural Information ProcessingSystems 25, pages 1295?1303.Sudipto Guha, Andrew McGregor, and SureshVenkatasubramanian.
2006.
Streaming and sublin-ear approximation of entropy and information dis-tances.
In ACM-SIAM Symposium on Discrete Al-gorithms, pages 733?742.David Hall, Daniel Jurafsky, and Christopher D. Man-ning.
2008.
Studying the history of ideas usingtopic models.
In Proceedings of the Conference onEmpirical Methods in Natural Language Process-ing, EMNLP ?08, pages 363?371, Stroudsburg, PA,USA.
Association for Computational Linguistics.Matthew Hoffman, David Blei, and Francis Bach.2010.
Online learning for latent dirichlet alcation.In J. Lafferty, C. K. I. Williams, J. Shawe-Taylor,R.S.
Zemel, and A. Culotta, editors, Advances inNeural Information Processing Systems 23, pages856?864.Matt Hoffman, David M. Blei, and David M. Mimno.2012.
Sparse stochastic inference for latent dirichletallocation.
In John Langford and Joelle Pineau, ed-itors, Proceedings of the 29th International Confer-ence on Machine Learning (ICML-12), pages 1599?1606, New York, NY, USA.
ACM.Piotr Indyk and Rajeev Motwani.
1998.
Approximatenearest neighbors: towards removing the curse of di-mensionality.
In Proceedings of the thirtieth annualACM symposium on Theory of computing, STOC?98, pages 604?613, New York, NY, USA.
ACM.Jagadeesh Jagarlamudi and Hal Daume?.
2010.
Ex-tracting multilingual topics from unaligned compa-rable corpora.
In Proceedings of the 32nd Euro-pean conference on Advances in Information Re-trieval, ECIR?2010, pages 444?456, Berlin, Heidel-berg.
Springer-Verlag.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In MT Summit, pages79?86.Kriste Krstovski and David A. Smith.
2011.
A mini-mally supervised approach for detecting and rankingdocument translation pairs.
In Proc.
Workshop onStatistical MT, pages 207?216.Andrew Kachites McCallum, 2002.
MALLET: A Ma-chine Learning for Language Toolkit.
http://mallet.cs.umass.edu.David Mimno, Hanna M. Wallach, Jason Naradowsky,David A. Smith, and Andrew McCallum.
2009.Polylingual topic models.
In Proceedings of the2009 Conference on Empirical Methods in Nat-ural Language Processing: Volume 2 - Volume2, EMNLP ?09, pages 880?889, Stroudsburg, PA,USA.
Association for Computational Linguistics.David M. Mount and Sunil Arya, 2010.
ANN: A Li-brary for Approximate Nearest Neighbor Searching.http://www.cs.umd.edu/?mount/ANN/.John C. Platt, Kristina Toutanova, and Wen-tau Yih.2010.
Translingual document representations fromdiscriminative projections.
In Proceedings of the2010 Conference on Empirical Methods in NaturalLanguage Processing, EMNLP ?10, pages 251?261,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Edmund Talley, David Newman, David Mimno, BruceHerr, Hanna Wallach, Gully Burns, Miriam Leen-ders, and Andrew McCallum.
2011.
Database ofNIH grants using machine-learned categories andgraphical clustering.
Nature Methods, 8:443?444.260Flemming Tops?e.
2000.
Some inequalities for in-formation divergence and related measures of dis-crimination.
IEEE Trans.
Information Theory,44(4):1602?1609.Xuerui Wang and Andrew McCallum.
2006.
Top-ics over time: a non-markov continuous-time modelof topical trends.
In Proceedings of the 12th ACMSIGKDD international conference on Knowledgediscovery and data mining, KDD ?06, pages 424?433, New York, NY, USA.
ACM.Xing Wei and W. Bruce Croft.
2006.
Lda-based doc-ument models for ad-hoc retrieval.
In Proceedingsof the 29th annual international ACM SIGIR confer-ence on Research and development in informationretrieval, SIGIR ?06, pages 178?185, New York,NY, USA.
ACM.Jia Zeng, Xiao-Qin Cao, and Zhi-Qiang Liu.
2012.Residual belief propagation for topic modeling.CoRR, abs/1204.6610.261
