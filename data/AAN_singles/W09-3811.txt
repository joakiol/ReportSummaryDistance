Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 73?76,Paris, October 2009. c?2009 Association for Computational LinguisticsAn Improved Oracle for Dependency Parsing with Online ReorderingJoakim Nivre??
Marco Kuhlmann?
Johan Hall?
?Uppsala University, Department of Linguistics and Philology, SE-75126 Uppsala?V?xj?
University, School of Mathematics and Systems Engineering, SE-35195 V?xj?E-mail: FIRSTNAME.LASTNAME@lingfil.uu.seAbstractWe present an improved training strategyfor dependency parsers that use online re-ordering to handle non-projective trees.The new strategy improves both efficiencyand accuracy by reducing the number ofswap operations performed on non-project-ive trees by up to 80%.
We present state-of-the-art results for five languages with thebest ever reported results for Czech.1 IntroductionRecent work on dependency parsing has resulted inconsiderable progress with respect to both accuracyand efficiency, not least in the treatment of discon-tinuous syntactic constructions, usually modeledby non-projective dependency trees.
While non-projective dependency relations tend to be rare inmost languages (Kuhlmann and Nivre, 2006), itis not uncommon that up to 25% of the sentenceshave a structure that involves at least one non-pro-jective relation, a relation that may be crucial foran adequate analysis of predicate-argument struc-ture.
This makes the treatment of non-projectivitycentral for accurate dependency parsing.Unfortunately, parsing with unrestricted non-pro-jective structures is a hard problem, for which exactinference is not possible in polynomial time exceptunder drastic independence assumptions (McDon-ald and Satta, 2007), and most data-driven parserstherefore use approximate methods (Nivre et al,2006; McDonald et al, 2006).
One recently ex-plored approach is to perform online reorderingby swapping adjacent words of the input sentencewhile building the dependency structure.
Using thistechnique, the system of Nivre (2009) processesunrestricted non-projective structures with state-of-the-art accuracy in observed linear time.The normal procedure for training a transition-based parser is to use an oracle that predicts anoptimal transition sequence for every dependencytree in the training set, and then approximate thisoracle by a classifier.
In this paper, we show thatthe oracle used for training by Nivre (2009) is sub-optimal because it eagerly swaps words as earlyas possible and therefore makes a large number ofunnecessary transitions, which potentially affectsboth efficiency and accuracy.
We propose an altern-ative oracle that reduces the number of transitionsby building larger structures before swapping, butstill handles arbitrary non-projective structures.2 BackgroundThe fundamental reason why sentences with non-projective dependency trees are hard to parse is thatthey contain dependencies between non-adjacentsubstructures.
The basic idea in online reorderingis to allow the parser to swap input words so thatall dependency arcs can be constructed betweenadjacent subtrees.
This idea is implemented in thetransition system proposed by Nivre (2009).
Thefirst three transitions of this system (LEFT-ARC,RIGHT-ARC, and SHIFT) are familiar from manysystems for transition-based dependency parsing(Nivre, 2008).
The only novelty is the SWAP trans-ition, which permutes two nodes by moving thesecond-topmost node from the stack back to theinput buffer while leaving the top node on the stack.To understand how we can parse sentences withnon-projective dependency trees, in spite of thefact that dependencies can only be added betweennodes that are adjacent on the stack, note that, forany sentence x with dependency tree G, there isalways some permutation x?
of x such thatG is pro-jective with respect to x?.
There may be more thanone such permutation, but Nivre (2009) defines thecanonical projective order <G for x given G asthe order given by an inorder traversal of G thatrespects the order < between a node and its directdependents.
This is illustrated in Figure 1, wherethe words of a sentence with a non-projective tree73ROOT Who did you send the letter to ?0 6 1 2 3 4 5 7 8ROOTNMODPVGSUBJOBJ2OBJ1DETFigure 1: Dependency tree for an English sentence with projective order annotation.have been annotated with their positions in the pro-jective order; reading the words in this order givesthe permuted string Did you send the letter who to?3 Training OraclesIn order to train classifiers for transition-based pars-ing, we need a training oracle, that is, a functionthat maps every dependency tree T in the trainingset to a transition sequence that derives T .
Whileevery complete transition sequence determines aunique dependency tree, the inverse does not neces-sarily hold.
This also means that it may be possibleto construct different training oracles.
For simplesystems that are restricted to projective dependencytrees, such differences are usually trivial, but fora system that allows online reordering there maybe genuine differences that can affect both the effi-ciency and accuracy of the resulting parsers.3.1 The Old OracleFigure 2 defines the original training oracle ?1 pro-posed by Nivre (2009).
This oracle follows aneager reordering strategy; it predicts SWAP in everyconfiguration where this is possible.
The basic in-sight in this paper is that, by postponing swaps andbuilding as much of the tree structure as possiblebefore swapping, we can significantly decrease thelength of the transition sequence for a given sen-tence and tree.
This may benefit the efficiency ofthe parser trained using the oracle, as each trans-ition takes a certain time to predict and to execute.Longer transition sequences may also be harder tolearn than shorter ones, which potentially affectsthe accuracy of the parser.3.2 A New OracleWhile it is desirable to delay a SWAP transitionfor as long as possible, it is not trivial to find theright time point to actually do the swap.
To seethis, consider the dependency tree in Figure 1.
In aparse of this tree, the first configuration in whichswapping is possible is when who6 and did1 are thetwo top nodes on the stack.
In this configuration wecan delay the swap until did has combined with itssubject you by means of a RIGHT-ARC transition,but if we do not swap in the second configurationwhere this is possible, we eventually end up withthe stack [ROOT0,who6, did1, send3, to7].
Here wecannot attach who to to by means of a LEFT-ARCtransition and get stuck.In order to define the new oracle, we introducean auxiliary concept.
Consider a modification ofthe oracle ?1 from Figure 2 that cannot predictSWAP transitions.
This oracle will be able to pro-duce valid transition sequences only for projectivetarget trees; for non-projective trees, it will fail toreconstruct all dependency arcs.
More specifically,a parse with this oracle will end up in a configur-ation in which the set of constructed dependencyarcs forms a set of projective dependency trees, notnecessarily a single such tree.
We call the elementsof this set the maximal projective components ofthe target tree.
To illustrate the notion, we havedrawn boxes around nodes in the same componentin Figures 1.Based on the concept of maximal projective com-ponents, we define a new training oracle ?2, whichdelays swapping as long as the next node in theinput is in the same maximal projective compon-ent as the top node on the stack.
The definitionof the new oracle ?2 is identical to that of ?1 ex-cept that the third line is replaced by ?SWAP ifc = ([?|i, j], [k|?
], Ac), j <G i, and MPC(j) 6=MPC(k)?, where MPC(i) is the maximal project-ive component of node i.
As a special case, ?2predicts SWAP if j <G i and the buffer B is empty.74?1(c) =????????
?LEFT-ARCl if c = ([?|i, j], B,Ac), (j, l, i)?A and Ai ?
AcRIGHT-ARCl if c = ([?|i, j], B,Ac), (i, l, j)?A and Aj ?
AcSWAP if c = ([?|i, j], B,Ac) and j <G iSHIFT otherwiseFigure 2: Training oracle ?1 for an arbitrary target tree G = (Vx, A), following the notation of Nivre(2009), where c = (?,B,Ac) denotes a configuration c with stack ?, input buffer B and arc set Ac.
Wewrite Ai to denote the subset of A that only contains the outgoing arcs of the node i.
(Note that Ac is thearc set in configuration c, while A is the arc set in the target tree G.)For example, in extracting the transition se-quence for the target tree in Figure 1, the new oraclewill postpone swapping of did when you is the nextnode in the input, but not postpone when the nextnode is send.
We can show that a parser informedby the new training oracle can always proceed toa terminal configuration, and still derive all (evennon-projective) dependency trees.4 ExperimentsWe now test the hypothesis that the new trainingoracle can improve both the accuracy and the ef-ficiency of a transition-based dependency parser.Our experiments are based on the same five datasets as Nivre (2009).
The training sets vary in sizefrom 28,750 tokens (1,534 sentences) for Sloveneto 1,249,408 tokens (72,703 sentences) for Czech,while the test sets all consist of about 5,000 tokens.4.1 Number of TransitionsFor each language, we first parsed the training setwith both the old and the new training oracle.
Thisallowed us to compare the number of SWAP trans-itions needed to parse all sentences with the twooracles, shown in Table 1.
We see that the reductionis very substantial, ranging from 55% (for Czech)to almost 84% (for Arabic).
While this differencedoes not affect the asymptotic complexity of pars-ing, it may reduce the number of calls to the classi-fier, which is where transition-based parsers spendmost of their time.4.2 Parsing AccuracyIn order to assess whether the reduced number ofSWAP transitions also has a positive effect on pars-ing accuracy, we trained two parsers for each ofthe five languages, one for each oracle.
All sys-tems use SVM classifiers with a polynomial kernelwith features and parameters optimized separatelyfor each language and training oracle.
The train-ing data for these classifiers consist only of thesequences derived by the oracles, which means thatthe parser has no explicit notion of projective orderor maximal projective components at parsing time.Table 2 shows the labeled parsing accuracy of theparsers measured by the overall attachment score(AS), as well as labeled precision, recall and (bal-anced) F-score for non-projective dependencies.1For comparison, we also give results for the twobest performing systems in the original CoNLL-Xshared task, Malt (Nivre et al, 2006) and MST (Mc-Donald et al, 2006), as well as the combo systemMSTMalt, (Nivre and McDonald, 2008).Looking first at the overall labeled attachmentscore, we see that the new training oracle consist-ently gives higher accuracy than the old one, withdifferences of up to 0.5 percentage points (for Ar-abic and Slovene), which is substantial given thatthe frequency of non-projective dependencies isonly 0.4?1.9%.
Because the test sets are so small,none of the differences is statistically significant(McNemar?s test, ?
= .05), but the consistent im-provement over all languages nevertheless stronglysuggests that this is a genuine difference.In relation to the state of the art, we note thatthe parsers with online reordering significantly out-perform Malt and MST on Czech and Slovene,and MST on Turkish, and have significantly lowerscores than the combo system MSTMalt only forArabic and Danish.
For Czech, the parser withthe new oracle actually has the highest attachmentscore ever reported, although the difference withrespect to MSTMalt is not statistically significant.Turning to the scores for non-projective depend-encies, we again see that the new oracle consist-ently gives higher scores than the old oracle, with1These metrics are not meaningful for Arabic as the testset only contains 11 non-projective dependencies.75Arabic Czech Danish Slovene TurkishOld (?1) 1416 57011 8296 2191 2828New (?2) 229 26208 1497 690 1253Reduction (%) 83.8 55.0 82.0 68.5 55.7Table 1: Number of SWAP transitions for the old (?1) and new (?2) training oracle.Arabic Czech Danish Slovene TurkishSystem AS AS P R F AS P R F AS P R F AS P R FOld (?1) 67.2 82.5 74.7 72.9 73.8 84.2 30.0 30.0 30.0 75.2 33.3 26.4 29.5 64.7 12.5 11.4 11.9New (?2) 67.5 82.7 79.3 71.0 79.3 84.3 38.2 32.5 35.1 75.7 60.6 27.6 37.9 65.0 14.3 13.2 13.7Malt 66.7 78.4 76.3 57.9 65.8 84.8 45.8 27.5 34.4 70.3 45.9 20.7 25.1 65.7 16.7 9.2 11.9MST 66.9 80.2 60.5 61.7 61.1 84.8 54.0 62.5 57.9 73.4 33.7 26.4 29.6 63.2 ?
11.8 ?MSTMalt 68.6 82.3 63.9 69.2 66.1 86.7 63.0 60.0 61.5 75.9 31.6 27.6 29.5 66.3 11.1 9.2 10.1Table 2: Labeled attachment score (AS) overall; precision (P), recall (R) and balanced F-score (F) fornon-projective dependencies.
Old = ?1; New = ?2; Malt = Nivre et al (2006), MST = McDonald et al(2006), MSTMalt = Nivre and McDonald (2008).the single exception that the old one has marginallyhigher recall for Czech.
Moreover, the reorderingparser with the new oracle has higher F-score thanany other system for all languages except Danish.Especially the result for Czech, with 79.3% preci-sion and 71.0% recall, is remarkably good, makingthe parser almost as accurate for non-projective de-pendencies as it is for projective dependencies.
Itseems likely that the good results for Czech are dueto the fact that Czech has the highest percentage ofnon-projective structures in combination with the(by far) largest training set.5 ConclusionWe have presented a new training oracle for thetransition system originally presented in Nivre(2009).
This oracle postpones swapping as long aspossible but still fulfills the correctness criterion.Our experimental results show that the new trainingoracle can reduce the necessary number of swapsby more than 80%, and that parsers trained in thisway achieve higher precision and recall on non-projective dependency arcs as well as higher at-tachment score overall.
The results are particularlygood for languages with a high percentage of non-projective dependencies, with an all-time best overall metrics for Czech.An interesting theoretical question is whetherthe new oracle defined in this paper is optimal withrespect to minimizing the number of swaps.
The an-swer turns out to be negative, and it is possible to re-duce the number of swaps even further by general-izing the notion of maximal projective componentsto maximal components that may be non-projective.However, the characterization of these generalizedmaximal components is non-trivial, and is thereforean important problem for future research.ReferencesMarco Kuhlmann and Joakim Nivre.
2006.
Mildlynon-projective dependency structures.
In Proceed-ings of the COLING/ACL 2006 Main ConferencePoster Sessions, pages 507?514.Ryan McDonald and Giorgio Satta.
2007.
On thecomplexity of non-projective data-driven depend-ency parsing.
In Proceedings of IWPT, pages 122?131.Ryan McDonald, Kevin Lerman, and Fernando Pereira.2006.
Multilingual dependency analysis with atwo-stage discriminative parser.
In Proceedings ofCoNLL, pages 216?220.Joakim Nivre and Ryan McDonald.
2008.
Integratinggraph-based and transition-based dependency pars-ers.
In Proceedings of ACL, pages 950?958.Joakim Nivre, Johan Hall, Jens Nilsson, G?lsen Ery-ig?it, and Svetoslav Marinov.
2006.
Labeled pseudo-projective dependency parsing with support vectormachines.
In Proceedings of CoNLL, pages 221?225.Joakim Nivre.
2008.
Algorithms for deterministic in-cremental dependency parsing.
Computational Lin-guistics, 34:513?553.Joakim Nivre.
2009.
Non-projective dependency pars-ing in expected linear time.
In Proceedings of ACL-IJCNLP.76
