Proceedings of the ACL 2014 Workshop on Semantic Parsing, pages 71?75,Baltimore, Maryland USA, June 26 2014.c?2014 Association for Computational LinguisticsEfficient Logical Inference for Semantic ProcessingRan Tian?Yusuke Miyao Takuya MatsuzakiNational Institute of Informatics, Japan{tianran,yusuke,takuya-matsuzaki}@nii.ac.jpAbstractDependency-based Compositional Se-mantics (DCS) provides a precise andexpressive way to model semantics ofnatural language queries on relationaldatabases, by simple dependency-liketrees.
Recently abstract denotation is pro-posed to enable generic logical inferenceon DCS.
In this paper, we discuss someother possibilities to equip DCS withlogical inference, and we discuss furtheron how logical inference can help textualentailment recognition, or other semanticprecessing tasks.1 IntroductionDependency-based Compositional Semantics(DCS) was proposed as an interface for queryingrelational databases by natural language.
Itfeatures DCS trees as semantic representation,with a structure similar to dependency trees.
Inits basic version, a node of a DCS tree indicatesa table in the database, and an edge indicates ajoin relation.
Both ends of an edge are labeled bya field of the corresponding table (Liang et al.,2011).
However, when DCS is applied to logicalinference on unrestricted texts, it is unrealistic toassume an explicit database, because we cannotprepare a database for everything in the world.For this reason, DCS trees are detached from anyspecific relational database, in a way that eachnode of a DCS tree indicates a content word in asentence (thus no fixed set of possible word labelsfor a DCS tree node), and each edge indicates?Current affiliation of the first author: Graduate Schoolof Information Sciences, Tohoku University, Japan.
Emailaddress: tianran@ecei.tohoku.ac.jpa semantic relation between two words.
Labelson the two ends of an edge, initially indicatingfields of tables in a database, are consideredas semantic roles of the corresponding words.Abstract denotation is proposed to capture themeaning of this abstract version of DCS tree,and a textual inference system based on abstractdenotation is built (Tian et al., 2014).It is quite natural to apply DCS trees, a simpleand expressive semantic representation, to textualinference; however the use of abstract denotationsto convey logical inference is somehow unusual.There are two seemingly obvious way to equipDCS with logical inference: (i) at the tree level, bydefining a set of logically sound transformationsof DCS trees; or (ii) at the logic level, by convert-ing DCS trees to first order predicate logic (FOL)formulas and then utilizing a theorem prover.
For(i), it may not be easy to enumerate all types oflogically sound transformations, but tree transfor-mations can be seen as an approximation of logicalinference.
For (ii), abstract denotation is more ef-ficient than FOL formula, because abstract deno-tation eliminates quantifiers and meanings of nat-ural language texts can be represented by atomicsentences.To elaborate the above discussion and to pro-vide more topics to the literature, in this paper wediscuss the following four questions: (?2) Howwell can tree transformation approximate logicalinference?
(?3) With rigorous inference on DCStrees, where does logic contribute in the systemof Tian et al.
(2014)?
(?4) Does logical inferencehave further potentials in Recognizing Textual En-tailment (RTE) task?
and (?5) How efficient is ab-stract denotation compared to FOL formula?
Weprovide examples or experimental results to theabove questions.71stormT?
: H?
: ARGblame deathDebbyARG ARGOBJstormARG ARGIOBJtropicalARG MODcause losslifeARGSBJARGMODOBJFigure 1: DCS trees of T: Tropical storm Debby isblamed for death and H: A storm has caused lossof life2 Tree transformation vs. logicalinferenceIn the tree transformation based approach to RTE,it has been realized that some gaps between T andH cannot be filled even by a large number of treetransformation rules extracted from corpus (Bar-Haim et al., 2007a).
For example in Figure 1, itis possible to extract the rule blamed for death?cause loss of life, but not easy to extract tropicalstorm Debby?
storm, because ?Debby?
could bean arbitrary name which may not even appear inthe corpus.This kind of gaps was typically addressed byapproximate matching methods, for example bycounting common sub-graphs of T and H, or bycomputing a cost of tree edits that convert T toH.
In the example of Figure 1, we would expectthat T is ?similar enough?
(i.e.
has many commonsub-graphs) with H, or the cost to convert T into H(e.g.
by deleting the node Debby and then add thenode storm) is low.
As for how similar is enough,or how the cost is evaluated, we will need a statis-tical model to train on RTE development set.It was neglected that some combinations of treeedits are logical (while some are not).
The entail-ment pair in Figure 1 can be easily treated by log-ical inference, as long as the apposition tropicalstorm = Debby is appropriately handled.
In con-trast to graph matching or tree edit models whichtheoretically admit arbitrary tree transformation,logical inference clearly discriminate sound trans-formations from unsound ones.
In this sense, therewould be no need to train on RTE data.When coreference is considered, logicallysound tree transformations can be quite compli-cated.
The following is a modified example fromRTE2-dev:T: Hurricane Isabel, which caused significantdamage, was a tropical storm when she enteredVirginia.stoormblaedbhDypimbtdDdrclrurmblf??bcDfo?rmbydf??
?rocrlrbd?piARGDlfDoDlfDo mbtdD?b?cDdf??T?
: H?
:ARG TIMEARG MOD TIMEARGSBJOBJARGARGMODOBJSBJARG ARGARGARG SBJSBJSBJOBJARGOBJ?rocrlrbFigure 2: DCS trees with coreferenceH: A storm entered Virginia, causing damage.The corresponding DCS trees are shown in Fig-ure 2.
Though the DCS trees of T and H arequite different, H can actually be proven from T.Note the coreference between Hurricane Isabeland she, suggesting us to copy the subtree of Hur-ricane Isabel to she, in a tree edit approach.
Thisis not enough yet, because the head storm in T isnot placed at the subject of cause.
The issue is in-deed very logical: from ?Hurricane Isabel = she?,?Hurricane Isabel = storm?, ?she = subject of en-ter?
and ?Hurricane Isabel = subject of cause?,we can imply that ?storm = subject of enter = sub-ject of cause?.3 Alignment with logical cluesTian et al.
(2014) proposed a way to generate on-the-fly knowledge to fill knowledge gaps: if H isnot proven, compare DCS trees of T and H togenerate path alignments (e.g.
blamed for death?
cause loss of life, as underscored in Figure 1);evaluate the path alignments by a similarity scorefunction; and path alignments with a score greaterthan a threshold (0.4) are accepted and convertedto inference rules.The word vectors Tian et al.
(2014) use tocalculate similarities are reported able to cap-ture semantic compositions by simple additionsand subtractions (Mikolov et al., 2013).
This isalso the case when used as knowledge resourcefor RTE, for example the similarities betweenblamed+death and cause+loss+life, or betweenfound+shot+dead and killed, are computed >0.4.However, generally such kind of similarity isvery noisy.
Tian et al.
(2014) used some logicalclues to filter out irrelevant path alignments, whichhelps to keep a high precision.
To evaluate theeffect of such logical filters, we compare it withsome other alignment strategies, the performanceof which on RTE5-test data is shown in Table 1.Each strategy is described in the following.72Strategy Prec.
Rec.
Acc.LogicClue + Inference 69.9 55.0 65.7LexNoun + Inference 64.2 57.3 62.7LexNoun + Coverage 57.1 75.0 59.3NoFilter + Coverage 54.2 87.7 56.8Table 1: Comparison of different alignment strate-giesLogicClue + Inference This is the system ofTian et al.
(2014)1, which use logical clues to filterout irrelevant path alignments, and apply acceptedpath alignments as inference rules.LexNoun + Inference The same system asabove, except that we only align paths betweenlexically aligned nouns.
Two nouns are alignedif and only if they are synonyms, hyponyms orderivatively related in WordNet.LexNoun + Coverage As above, paths betweenlexically aligned nouns are aligned, and alignedpaths with similarity score > 0.4 are accepted.
Ifall nodes in H can be covered by some acceptedpath alignments, then output ?Y?.
This is verysimilar to the system described in Bar-Haim et al.
(2007b).NoFilter + Coverage Same as above, but allpaths alignments with similarity score > 0.4 areaccepted.4 How can logical inference help RTE?Logical inference is shown to be useful for RTE,as Tian et al.
(2014) demonstrates a system withcompetitive results.
However, despite the expec-tation that all entailment matters can be explainedlogically, our observation is that currently logicalinference only fills very limited short gaps from Tto H. The logical phenomena easily addressed byTian et al.
(2014)?s framework, namely universalquantifiers and negations, seems rare in PASCALRTE data.
Most heavy lifting is done by distribu-tional similarities between phrases, which may failin complicated sentences.
An especially complexexample is:T: Wal-Mart Stores Inc. said Tuesday that a Mas-sachusetts judge had granted its motion to decer-tify a class action lawsuit accusing the world?slargest retailer of denying employees breaks.H: Employee breaks had been denied by a motiongranted by a Massachusetts judge.1http://kmcs.nii.ac.jp/tianran/tifmo/100 1000 10000 100000 1000000123456R?
= 0.24??
?
?
?
??
???
?
?
?
?
?
?????
?????
?Figure 3: Time of forward-chaining (seconds) inour system, plotted on weights of statements (log-arithmic scale).Orig.
3 Sec.
Orig.
5 Min.
Red.
5 Min.Proof found 8 16 82Too many variables 5 24 3Failed to find proof 0 1 3Memory limit 0 2 0Time out 86 57 13Table 2: Proportion (%) of exit status of Prover9The system of Tian et al.
(2014) generated on-the-fly knowledge to join several fragments in Tand wrongly proved H. In examples of such com-plexity, distributional similarity is no longer reli-able.
However, it may be possible to build a pri-ori logical models at the meta level, such as onepistemic, intentional and reportive attitudes.
Themodels then can provide signals for semantic pars-ing to connect the logic to natural language, suchas the words ?grant?, ?decertify?, and ?accuse?
inthe above example.
We hope this approach canbring new progress to RTE and other semantic pro-cessing tasks.5 Efficiency of abstract denotationsTo evaluate the efficiency of logical inference onabstract denotations, we took 110 true entailmentpairs from RTE5 development set, which are alsopairs that can be proven with on-the-fly knowl-edge.
We plot the running time of Tian et al.
(2014)?s inference engine (single-threaded) on a2.27GHz Xeon CPU, with respect to the weightedsum of all statements2, as shown in Figure 3.
Thegraph shows all pairs can be proven in 6 seconds,and proof time scales logarithmically on weight ofstatements.On the other hand, we converted statements onabstract denotations into FOL formulas, and triedto prove the same pairs using Prover9,3a popu-2If a statement is translated to FOL formula, the weight ofthis statement equals to the weighted sum of all predicates inthe FOL formula, where an n-ary predicate is weighted as n.3www.cs.unm.edu/?mccune/prover9/73lar FOL theorem prover.
As the result turns out(Table 2), only 8% of the pairs can be proven in3 seconds (the ?Orig.
3 Sec.?
column), and only16% pairs can be proven in 5 minutes (the ?Orig.5 Min.?
column), showing severe difficulties foran FOL prover to handle textual inferences withmany (usually hundreds of) on-the-fly rules.
Assuch, we use Tian et al.
(2014)?s inference engineto pin down statements that are actually needed forproving H (usually just 2 or 3 statements), and tryto prove H by Prover9 again, using only necessarystatements.
Proven pairs in 5 minutes then jumpto 82% (the ?Red.
5 Min.?
column), showing thata large number of on-the-fly rules may drasticallyincrease computation cost.
Still, nearly 20% pairscannot be proven even in this setting, suggestingthat traditional FOL prover is not suited for tex-tual inference.6 Conclusion and future workWe have discussed the role that logical infer-ence could play in RTE task, and the efficiencyof performing inference on abstract denotations.Though currently logical inference contributes atplaces that are somehow inconspicuous, there isthe possibility that with some meta level logicalmodels and the methodology of semantic parsing,we can build systems that understand natural lan-guage texts deeply: logic implies (in)consistency,which is in turn used as signals to produce moreaccurate semantic interpretation.
And after all, asthere may be many possible variations of seman-tic representations, it is good to have an efficientinference framework that has the potential to con-nect them.
It would be exciting if we can combinedifferent types of structured data with natural lan-guage in semantic processing tasks.
Directions ofour future work are described below.Improvement of similarity score To calculatephrase similarities, Tian et al.
(2014) use the co-sine similarity of sums of word vectors, which ig-nores syntactic information.
We plan to add syn-tactic information to words by some supertags,and learn a vector space embedding for this struc-ture.Integration of FreeBase to RTE It would beexciting if we can utilize the huge amount of Free-Base data in RTE task.
Using the framework ofabstract denotation, meanings of sentences can beexplained as relational database queries; to convertit to FreeBase data queries is like relational to on-tology schema matching.
In order to make effec-tive use of FreeBase data, we also need to recog-nize entities and relations in natural language sen-tences.
Previous research on semantic parsing willbe very helpful for learning such mapping.Winograd Schema Challenge (WSC) As theRTE task, WSC (Levesque et al., 2012) also pro-vides a test bed for textual inference systems.
AWinograd schema is a pair of similar sentences butcontain an ambiguity of pronouns that is resolvedin opposite ways.
A complicated partial exampleis:Michael decided to freeze himself incryo-stasis even though his father wasagainst it, because he hopes to be un-frozen in the future when there is a cureavailable.The logical interplay among decided, hopes,even though, because, and the realization that heis coreferent to Michael (but not his father) is in-triguing.
By working on the task, we hope to gainfurther understanding on how knowledge can begathered and applied in natural language reason-ing.Acknowledgments This research was supportedby the Todai Robot Project at National Institute ofInformatics.ReferencesRoy Bar-Haim, Ido Dagan, Iddo Greental, and EyalShnarch.
2007a.
Semantic inference at the lexical-syntactic level.
In Proceedings of AAAI 2007.Roy Bar-Haim, Ido Dagan, Iddo Greental, Idan Szpek-tor, and Moshe Friedman.
2007b.
Semantic in-ference at the lexical-syntactic level for textual en-tailment recognition.
In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Para-phrasing.Hector Levesque, Ernest Davis, and Leora Morgen-stern.
2012.
The winograd schema challenge.
InKnowledge Representation and Reasoning Confer-ence.Percy Liang, Michael Jordan, and Dan Klein.
2011.Learning dependency-based compositional seman-tics.
In Proceedings of ACL 2011.Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.2013.
Linguistic regularities in continuous spaceword representations.
In Proceedings of NAACL2013.74Ran Tian, Yusuke Miyao, and Matsuzaki Takuya.2014.
Logical inference on dependency-based com-positional semantics.
In Proceedings of ACL 2014.75
