Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 103?108,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsA Java Framework for Multilingual Definition and Hypernym ExtractionStefano Faralli and Roberto NavigliDipartimento di InformaticaSapienza Universita` di Roma{faralli,navigli}@di.uniroma1.itAbstractIn this paper we present a demonstra-tion of a multilingual generalization ofWord-Class Lattices (WCLs), a super-vised lattice-based model used to identifytextual definitions and extract hypernymsfrom them.
Lattices are learned from adataset of automatically-annotated defini-tions from Wikipedia.
We release a JavaAPI for the programmatic use of multilin-gual WCLs in three languages (English,French and Italian), as well as a Web ap-plication for definition and hypernym ex-traction from user-provided sentences.1 IntroductionElectronic dictionaries and domain glossaries aredefinition repositories which prove very useful notonly for lookup purposes, but also for automatictasks such as Question Answering (Cui et al2007; Saggion, 2004), taxonomy learning (Navigliet al 2011; Velardi et al 2013), domain WordSense Disambiguation (Duan and Yates, 2010;Faralli and Navigli, 2012), automatic acquisitionof semantic predicates (Flati and Navigli, 2013),relation extraction (Yap and Baldwin, 2009) and,more in general, knowledge acquisition (Hovy etal., 2013).
Unfortunately, constructing and updat-ing such resources requires the effort of a team ofexperts.
Moreover, they are of no help when deal-ing with new words or usages, or, even worse, newdomains.
Nonetheless, raw text often containsseveral definitional sentences, that is, it provideswithin itself formal explanations for terms of inter-est.
Whilst it is not feasible to search texts manu-ally for definitions in several languages, the task ofextracting definitional information can be autom-atized by means of Machine Learning (ML) andNatural Language Processing (NLP) techniques.Many approaches (Snow et al 2004; Kozarevaand Hovy, 2010, inter alia) build upon lexico-syntactic patterns, inspired by the seminal workof Hearst (1992).
However, these methods suf-fer from two signifiicant drawbacks: on the onehand, low recall (as definitional sentences occur inhighly variable syntactic structures), and, on theother hand, noise (because the most frequent def-initional pattern ?
X is a Y ?
is inherently verynoisy).
A recent approach to definition and hyper-nym extraction, called Word-Class Lattices (Nav-igli and Velardi, 2010, WCLs), overcomes theseissues by addressing the variability of definitionalsentences and providing a flexible way of automat-ically extracting hypernyms from them.
To do so,lattice-based classifiers are learned from a trainingset of textual definitions.
Training sentences areautomatically clustered by similarity and, for eachsuch cluster, a lattice classifier is learned whichmodels the variants of the definition template de-tected.
A lattice is a directed acyclic graph, asubclass of non-deterministic finite state automata.The purpose of the lattice structure is to preserve(in a compact form) the salient differences amongdistinct sequences.In this paper we present a demonstration ofWord-Class Lattices by providing a Java API anda Web application for online usage.
Since multi-linguality is a key need in today?s information so-ciety, and because WCLs have been tested over-whelmingly only with the English language, weprovide experiments for three different languages,namely English, French and Italian.
To do so, incontrast to Navigli and Velardi (2010), who cre-ated a manually annotated training set of defini-tions, we provide a heuristic method for the au-tomatic acquisition of reliable training sets fromWikipedia, and use them to determine the robust-ness and generalization power of WCLs.
We showhigh performance in definition and hypernym ex-traction for our three languages.2 Word-Class LatticesIn this section we briefly summarize Word-ClassLattices, originally introduced by Navigli and Ve-lardi (2010).2.1 Definitional Sentence GeneralizationWCL relies on a formal notion of textual defi-nition.
Specifically, given a definition, e.g.
: ?Incomputer science, a closure is a first-class func-tion with free variables that are bound in the lex-ical environment?, we assume that it contains the103[In geography, a country]DF [is]V F [a political division]GF .
[In finance, a bond]DF [is]V F [a negotiable certificate]GF [that that acknowledges.
.
.
]REST .
[In poetry, a foot]DF [is]V F [a measure]GF [, consisting.
.
.
]REST .Table 1: Example definitions (defined terms are marked in bold face, their hypernyms in italics).IngeographyfinancepoetryNN1 , a ?TARGET?footbondcountryapoliticalnegotiableJJ NN2divisioncertificatemeasureFigure 1: The DF and GF Word-Class Lattices for the sentences in Table 1.following fields (Storrer and Wellinghoff, 2006):definiendum (DF), definitor (VF), definiens (GF)and rest (REST), where DF is the part of thedefinition including the word being defined (e.g.,?In computer science, a closure?
), VF is the verbphrase used to introduce the definition (e.g., ?is?
),GF usually includes the hypernym (e.g., ?a first-class function?, hypernym marked in italics) andRF includes additional clauses (e.g., ?with freevariables that are bound in the lexical environ-ment?
).Consider a set of training sentences T , eachof which is automatically part-of-speech taggedand manually bracketed with the DF, VF, GF andREST fields (examples are shown in Table 1).
Wefirst identify the set of most frequent words F(e.g., the, a, is, of, refer, etc.).
Then we addthe symbol ?TARGET?
to F and replace in T theterms being defined with ?TARGET?.
We then usethe set of frequent words F to generalize words to?word classes?.We define a word class as either a word itselfor its part of speech.
Given a sentence s =w1, w2, .
.
.
, w|s|, where wi is the i-th word of s,we generalize its words wi to word classes ?i asfollows:?i ={wi if wi ?
FPOS(wi) otherwisethat is, a word wi is left unchanged if it occurs fre-quently in the training corpus (i.e., wi ?
F ) or istransformed to its part of speech tag (POS(wi))otherwise.
As a result, we obtain a generalizedsentence s?
= ?1, ?2, .
.
.
, ?|s|.
For instance,given the first sentence in Table 1, we obtain thecorresponding generalized sentence: ?In NN, a?TARGET?
is a JJ NN?, where NN and JJ indicatethe noun and adjective classes, respectively.2.2 LearningThe WCL learning algorithm consists of 3 steps:?
Star patterns: each sentence in the trainingset is preprocessed and generalized to a starpattern by replacing with * all the words wi 6?F , i.e., non-frequent words.
For instance, ?Ingeography, a country is a political division?is transformed to ?In *, a ?TARGET?
is a *?;?
Sentence clustering: the training sentencesare then clustered based on the star patternsthey belong to;?
Word-Class Lattice construction: for eachsentence cluster, a WCL is created separatelyfor each DF, VF and GF field by means of agreedy alignment algorithm.
In Figure 1 weshow the resulting lattices for the DF and GFfields built for the cluster of sentences of Ta-ble 1.
Note that during the construction of thelattice the nodes associated with the hyper-nym words in the learning sentences (i.e., di-vision, certificate and measure) are marked ashypernyms in order to determine the hyper-nym of a test sentence at classification time(see (Navigli and Velardi, 2010) for details).2.3 ClassificationOnce the learning process is over, a set of WCLsis produced for the DF, VF and GF fields.
Givena test sentence s, we consider all possible combi-nations of definiendum, definitor and definiens lat-tices and select the combination of the three WCLsthat best fits the sentence, if such a combinationexists.
In fact, choosing the most appropriatecombination of lattices impacts the performanceof hypernym extraction.
The best combinationof WCLs is selected by maximizing the follow-ing confidence score: score(s, lDF , lV F , lGF ) =coverage ?
log(support+1) where s is the candi-date sentence, lDF , lV F and lGF are three latticesone for each definition field, coverage is the frac-tion of words of the input sentence covered by thethree lattices, and support is the sum of the num-ber of sentences in the star patterns correspondingto the GF lattice.
Finally, when a sentence is clas-sified as a definition, its hypernym is extracted by104# Wikipedia pages # definitions extractedEnglish (EN) 3,904,360 1,552,493French (FR) 1,617,359 447,772Italian (IT) 1,008,044 291,259Table 2: The number of Wikipedia pages and theresulting automatically annotated definitions.selecting the words in the input sentence that aremarked as hypernyms in the WCL selected for GF.3 Multilingual Word-Class LatticesIn order to enable multilinguality, thereby extract-ing definitions and hypernyms in many languages,we provide here a heuristic method for the creationof multilingual training datasets from Wikipedia,that we apply to three languages: English, Frenchand Italian.
As a result, we are able to fully au-tomatize the definition and hypernym extractionby utilizing collaboratively-curated encyclopediacontent.3.1 Automatic Learning of MultilingualWCLsThe method consists of four steps:1. candidate definition extraction: we iteratethrough the collection of Wikipedia pages forthe language of interest.
For each article weextract the first paragraph, which usually, butnot always, contains a definitional sentencefor the concept expressed by the page title.We discard all those pages for which the titlecorresponds to a special page (i.e., title in theform ?List of [.
.
.
]?, ?Index of [.
.
.
]?, ?[.
.
.
](disambiguation)?
etc.).2.
part-of-speech tagging and phrase chunk-ing: for each candidate definition we per-form part-of-speech tagging and chunking,thus automatically identifying noun, verb,and prepositional phrases (we use TreeTag-ger (Schmid, 1997)).3. automatic annotation: we replace all the oc-currences in the candidate definition of thetarget term (i.e., the title of the page) withthe marker ?TARGET?, we then tag as hyper-nym the words associated with the first hy-perlink occurring to the right of ?TARGET?.Then we tag as VF (i.e., definitor field,see Section 2.1) the verb phrase found be-tween ?TARGET?
and the hypernym, if sucha phrase exists.
Next we tag as GF (i.e.,definiens field) the phrase which contains thehypernym and as DF (i.e., definiendum field)the phrase which starts at the beginning ofthe sentence and ends right before the startof the VP tag.
Finally we mark as REST theremaining phrases after the phrase alreadytagged as GF.
For example, given the sen-tence ?Albert Einstein was a German-borntheoretical physicist.
?, we produce the fol-lowing sentence annotation: ?
[Albert Ein-stein]DF [was]V F [a German-born theoreti-cal physicist]GF .?
(target term marked inbold and hypernym in italics).4. filtering: we finally discard all the candidatedefinitions for which not all fields could befound during the previous step (i.e., either the?TARGET?, hypernym or any DF, VF, GF,REST tag is missing).We applied the above four steps to the En-glish, French and Italian dumps of Wikipedia1.The numbers are shown in Table 2: starting with3,904,360 Wikipedia pages for English, 1,617,359for French and 1,008,044 for Italian (first column),we obtained 1,552,493, 447,772, and 291,259 au-tomatically tagged sentences, respectively, for thethree languages (second column in the Table).Since we next had to use these sentences for train-ing our WCLs, we took out a random sampleof 1000 sentences for each language which weused for testing purposes.
We manually annotatedeach of these sentences as definitional or non-definitional2 and, in the case of the former, alsowith the correct hypernym.3.2 EvaluationWe tested the newly acquired training datasetagainst two test datasets.
The first dataset wasour random sampling of 1000 Wikipedia test sen-tences which we had set aside for each language(no intersection with the training set, see previoussection).
The second dataset was the same oneused in Navigli and Velardi (2010), made up ofsentences from the ukWaC Web corpus (Ferraresiet al 2008) and used to estimate the definition andhypernym extraction performance on an open textcorpus.3.3 ResultsTable 3 shows the results obtained on definition(column 2-4) and hypernym extraction (column 5-7) in terms of precision (P), recall (R) and accu-racy (A) on our first dataset.
Note that accuracyalso takes into account candidate definitions inthe test set which were tagged as non-definitional(see Section 3.1).
In the Table we compare theperformance of our English WCL trained fromWikipedia sentences using our automatic proce-dure against the original performance of WCL1We used the 21-09-2012 (EN), 17-09-2012 (FR), 21-09-2012 (IT) dumps.2Note that the first sentence of a Wikipedia page mightseldom be non-definitional, such as ?Basmo fortress is lo-cated in the north-western part .
.
.
?.105Definition Extraction Hypernym ExtractionP R A P R AEN 98.5 78.3 81.0 98.5 77.4 80.0FR 98.7 83.3 84.0 98.6 78.0 79.0IT 98.8 87.3 87.0 98.7 83.2 83.0EN (2010) 100.0 59.0 66.0 100.0 58.3 65.0Table 3: Precision (P), recall (R) and accuracy(A) of definition and hypernym extraction whentesting on our dataset of 1000 randomly sam-pled Wikipedia first-paragraph sentences.
EN(2010) refers to the WCL learned from the origi-nal manually-curated training set from Navigli andVelardi (2010), while EN, FR and IT refer to WCLtrained, respectively, with one of the three trainingsets automatically acquired from Wikipedia.P REN 98.9 57.6EN (2010) 94.8 56.5Table 4: Estimated WCL definition extractionprecision (P) and recall (R), testing a sample ofukWaC sentences.trained on 1,908 manually-selected training sen-tences3.
It can be seen that the automatically ac-quired training set considerably improves the per-formance, as it covers higher variability.
We notethat the recall in both definition and hypernym ex-traction is higher for French and Italian.
We at-tribute this behavior to the higher complexity and,again, variability of English Wikipedia pages, andspecifically first-sentence definitions.
We remarkthat the presented results were obtained withoutany human effort, except for the independent col-laborative editing and hyperlinking of Wikipediapages, and that the overall performances can beimproved by manually checking the automaticallyannotated training datasets.We also replicated the experiment carried outby Navigli and Velardi (2010), testing WCLs witha subset (over 300,000 sentences) of the ukWaCWeb corpus.
As can be seen in Table 4, theestimated precision and recall for WCL defini-tion extraction with the 2010 training set were94.8% and 56.5%, respectively, while with our au-tomatically acquired English training set we ob-tained a higher precision of 98.9% and a recall of57.6%.
This second experiment shows that learn-ing WCLs from hundreds of thousands of defini-tion candidates does not overfit to Wikipedia-styledefinitional sentences.After looking at the automatically acquiredtraining datasets, we noted some erroneous an-notations mainly due to the following factors: i)some Wikipedia pages do not start with defini-3Available from http://lcl.uniroma1.it/wcl1 // select the language of interest2 Language targetLanguage = Language.EN;3 // open the training set4 Dataset ts = new AnnotatedDataset(5 trainingDatasetFile,6 targetLanguage);7 // obtain an instance of the WCL classifier8 WCLClassifier c = new WCLClassifier(targetLanguage);9 c.train(ts);10 // create a sentence to be tested11 Sentence sentence = Sentence.createFromString(12 "WCL",13 "WCL is a kind of classifier.
",14 targetLanguage);15 // test the sentence16 SentenceAnnotation sa = c.test(sentence);17 // print the hypernym18 if (sa.isDefinition())19 System.out.println(sa.getHyper());Figure 2: An example of WCL API usage.tional sentences; ii) they may contain more thanone verbal phrase between the defined term andthe hypernym; iii) the first link after the verbalphrase does not cover, or partially covers, thecorrect hypernym.
The elimination of the abovewrongly acquired definitional patterns can be im-plemented with some language-dependent heuris-tics or can be done by human annotators.
In anycase, given the presence of a high number of cor-rect annotated sentences, these wrong definitionalpatterns have a very low impact on the definitionand hypernym extraction precision as shown in theabove experiments (see Table 3 and Table 4).4 Multilingual WCL APITogether with the training and test sets of theabove experiments, we also release here our im-plementation of Word-Class Lattices, available asa Java API.
As a result the WCL classifier can eas-ily be used programmatically in any Java project.In Figure 2 we show an example of the API usage.After the selection of the target language (line 2),we load the training dataset for the target language(line 4).
Then an instance of WCLClassifier iscreated (line 8) and the training phase is launchedon the input training corpora (line 9).
Now theclassifier is ready to be tested on any given sen-tence in the target language (lines 11-16).
If theclassifier output is positive (line 18) we can printthe extracted hypernym (line 19).
The output ofthe presented code is the string ?classifier?
whichcorresponds to the hypernym extracted by WCLfor the input sentence ?WCL is a kind of classi-fier?.4.1 Web user interfaceWe also release a Web interface to enable onlineusage of our WCLs for the English, French andItalian languages.
In Figure 3 we show a screen-shot of our Web interface.
The user can type the106Figure 3: A screenshot of the WCL Web interface.term of interest, the candidate definition, selectthe language of interest and, after submission, inthe case of positive response from WCL, obtainthe corresponding hypernym and a graphical rep-resentation of the lattices matching the given sen-tence, as shown in the bottom part of the Figure.The graphical representation shows the concate-nation of the learned lattices which match the DF,VF, GF parts of the given sentence (see Section2).
We also allow the user not to provide the termof interest: in this case all the nouns in the sen-tence are considered as candidate defined terms.The Web user interface is part of a client-server ap-plication, created with the JavaServer Pages tech-nology.
The server side produces an HTML page(like the one shown in Figure 3), using the WCLAPI (see Section 4) to process and test the submit-ted definition candidate.5 Related WorkA great deal of work is concerned with the lan-guage independent extraction of definitions.
Muchrecent work uses symbolic methods that dependon lexico-syntactic patterns or features, which aremanually created or semi-automatically learned asrecently done in (Zhang and Jiang, 2009; Wester-hout, 2009).
A fully automated method is, instead,proposed by Borg et al(2009), where higherperformance (around 60-70% F1-measure) is ob-tained only for specific domains and patterns.
Ve-lardi et al(2008), in order to improve precisionwhile keeping pattern generality, prune candidatesusing more refined stylistic patterns and lexical fil-ters.
Cui et al(2007) propose the use of prob-abilistic lexico-semantic patterns, for definitionalquestion answering in the TREC contest4.
How-ever, the TREC evaluation datasets cannot be con-sidered true definitions, but rather text fragmentsproviding some relevant fact about a target term.4Text REtrieval Conferences: http://trec.nist.govHypernym extraction methods vary from simplelexical patterns (Hearst, 1992; Oakes, 2005) to sta-tistical and machine learning techniques (Agirreet al 2000; Caraballo, 1999; Dolan et al 1993;Sanfilippo and Poznanski, 1992; Ritter et al2009).
Extraction heuristics can be adopted inmany languages (De Benedictis et al 2013),where given a definitional sentence the hypernymis identified as the first occuring noun after thedefined term.
One of the highest-coverage meth-ods is proposed by Snow et al(2004).
They firstsearch sentences that contain two terms which areknown to be in a taxonomic relation (term pairs aretaken from WordNet (Miller et al 1990)); thenthey parse the sentences, and automatically ex-tract patterns from the parse trees.
Finally, theytrain a hypernym classifier based on these features.Lexico-syntactic patterns are generated for eachsentence relating a term to its hypernym, and a de-pendency parser is used to represent them.6 ConclusionIn this demonstration we provide three main con-tributions: 1) a general method for obtaining largetraining sets of annotated definitional sentencesfor many languages from Wikipedia, thanks towhich we can release three new training sets forEnglish, French and Italian; 2) an API to program-matically use WCLs in Java projects; 3) a Web ap-plication which enables online use of multilingualWCLs: http://lcl.uniroma1.it/wcl/.AcknowledgmentsThe authors gratefully acknowledgethe support of the ERC StartingGrant MultiJEDI No.
259234.107ReferencesEneko Agirre, Olatz Ansa, Eduard H. Hovy, and DavidMart??nez.
2000.
Enriching very large ontologies using theWWW.
In ECAI Workshop on Ontology Learning, Berlin,Germany.Claudia Borg, Mike Rosner, and Gordon Pace.
2009.
Evo-lutionary algorithms for definition extraction.
In Proceed-ings of the 1st Workshop on Definition Extraction, pages26?32, Borovets, Bulgaria.Sharon A. Caraballo.
1999.
Automatic construction of ahypernym-labeled noun hierarchy from text.
In Proceed-ings of the 37th Annual Meeting of the Association forComputational Linguistics: Proceedings of the Confer-ence, pages 120?126, Maryland, USA.Hang Cui, Min-Yen Kan, and Tat-Seng Chua.
2007.
Soft pat-tern matching models for definitional question answering.ACM Transactions on Information Systems, 25(2):1?30.Flavio De Benedictis, Stefano Faralli, and Roberto Navigli.2013.
GlossBoot: Bootstrapping Multilingual DomainGlossaries from the Web.
In Proceedings of 51st AnnualMeeting of the Association for Computational Linguistics,Sofia, Bulgaria.William Dolan, Lucy Vanderwende, and Stephen D. Richard-son.
1993.
Automatically deriving structured knowledgebases from on-line dictionaries.
In Proceedings of theFirst Conference of the Pacific Association for Computa-tional Linguistics, pages 5?14, Vancouver, Canada.Weisi Duan and Alexander Yates.
2010.
Extracting glossesto disambiguate word senses.
In Proceedings of HumanLanguage Technologies: The 11th Annual Conference ofthe North American Chapter of the Association for Com-putational Linguistics, pages 627?635, Los Angeles, CA,USA.Stefano Faralli and Roberto Navigli.
2012.
A newminimally-supervised framework for Domain Word SenseDisambiguation.
In Proceedings of the 2012 Joint Con-ference on Empirical Methods in Natural Language Pro-cessing and Computational Natural Language Learning,pages 1411?1422, Jeju, Korea.Adriano Ferraresi, Eros Zanchetta, Marco Baroni, and SilviaBernardini.
2008.
Introducing and evaluating ukWaC, avery large web-derived corpus of English.
In Proceedingsof the 4th Web as Corpus Workshop (WAC-4), pages 47?54, Marrakech, Morocco.Tiziano Flati and Roberto Navigli.
2013.
SPred: Large-scaleHarvesting of Semantic Predicates.
In Proceedings of 51stAnnual Meeting of the Association for Computational Lin-guistics, Sofia, Bulgaria.Marti A. Hearst.
1992.
Automatic acquisition of hyponymsfrom large text corpora.
In Proceedings of the 15th Inter-national Conference on Computational Linguistics, pages539?545, Nantes, France.Eduard Hovy, Roberto Navigli, and Simone Paolo Ponzetto.2013.
Collaboratively built semi-structured content andartificial intelligence: The story so far.
Artificial Intelli-gence, 194:2?27.Zornitsa Kozareva and Eduard Hovy.
2010.
Learning argu-ments and supertypes of semantic relations using recur-sive patterns.
In Proceedings of the 48th Annual Meetingof the Association for Computational Linguistics (ACL),Uppsala, Sweden, pages 1482?1491, Uppsala, Sweden.George A. Miller, R.T. Beckwith, Christiane D. Fellbaum,D.
Gross, and K. Miller.
1990.
WordNet: an onlinelexical database.
International Journal of Lexicography,3(4):235?244.Roberto Navigli and Paola Velardi.
2010.
Learning Word-Class Lattices for definition and hypernym extraction.
InProceedings of the 48th Annual Meeting of the Associa-tion for Computational Linguistics, pages 1318?1327, Up-psala, Sweden.Roberto Navigli, Paola Velardi, and Stefano Faralli.
2011.A graph-based algorithm for inducing lexical taxonomiesfrom scratch.
In Proceedings of the 22th InternationalJoint Conference on Artificial Intelligence, pages 1872?1877, Barcelona, Spain.Michael P. Oakes.
2005.
Using Hearst?s rules for the auto-matic acquisition of hyponyms for mining a pharmaceu-tical corpus.
In RANLP Text Mining Workshop?05, pages63?67, Borovets, Bulgaria.Alan Ritter, Stephen Soderland, and Oren Etzioni.
2009.What is this, anyway: Automatic hypernym discovery.In Proceedings of the 2009 AAAI Spring Symposium onLearning by Reading and Learning to Read, pages 88?93,Palo Alto, California.Horacio Saggion.
2004.
Identifying definitions in text col-lections for question answering.
In Proceedings of theFourth International Conference on Language Resourcesand Evaluation, pages 1927?1930, Lisbon, Portugal.Antonio Sanfilippo and Victor Poznanski.
1992.
The ac-quisition of lexical knowledge from combined machine-readable dictionary sources.
In Proceedings of the thirdConference on Applied Natural Language Processing,pages 80?87, Trento, Italy.Helmut Schmid.
1997.
Probabilistic part-of-speech taggingusing decision trees.
In Daniel Jones and Harold Somers,editors, New Methods in Language Processing, Studies inComputational Linguistics, pages 154?164.
UCL Press,London, GB.Rion Snow, Daniel Jurafsky, and Andrew Y. Ng.
2004.Learning syntactic patterns for automatic hypernym dis-covery.
In Lawrence K. Saul, Yair Weiss, and Le?on Bot-tou, editors, Proc.
of NIPS 2004, pages 1297?1304, Cam-bridge, Mass.
MIT Press.Angelika Storrer and Sandra Wellinghoff.
2006.
Automateddetection and annotation of term definitions in Germantext corpora.
In LREC 2006, pages 275?295, Genoa, Italy.Paola Velardi, Roberto Navigli, and Pierluigi D?Amadio.2008.
Mining the Web to create specialized glossaries.IEEE Intelligent Systems, 23(5):18?25.Paola Velardi, Stefano Faralli, and Roberto Navigli.
2013.OntoLearn Reloaded: A graph-based algorithm for taxon-omy induction.
Computational Linguistics, 39(3).Eline Westerhout.
2009.
Definition extraction using linguis-tic and structural features.
In Proceedings of the RANLP2009 Workshop on Definition Extraction, page 61?67,Borovets, Bulgaria.Willy Yap and Timothy Baldwin.
2009.
Experiments onpattern-based relation learning.
In Proceedings of the 18thACM Conference on Information and Knowledge Man-agement (CIKM 2009), pages 1657?1660, Hong Kong,China, 2009.Chunxia Zhang and Peng Jiang.
2009.
Automatic extractionof definitions.
In Proceedings of 2nd IEEE InternationalConference on Computer Science and Information Tech-nology, pages 364?368, Beijing, China.108
