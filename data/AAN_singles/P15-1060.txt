Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 616?625,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsSentiment-Aspect Extraction based on Restricted Boltzmann MachinesLinlin Wang1, Kang Liu2?, Zhu Cao1, Jun Zhao2and Gerard de Melo11Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, China2National Laboratory of Pattern Recognition, Institute of Automation,Chinese Academy of Sciences, Beijing, China{ll-wang13, cao-z13}@mails.tsinghua.edu.cn,{kliu, jzhao}@nlpr.ia.ac.cn, gdm@demelo.orgAbstractAspect extraction and sentiment analysisof reviews are both important tasks inopinion mining.
We propose a novel senti-ment and aspect extraction model based onRestricted Boltzmann Machines to jointlyaddress these two tasks in an unsupervisedsetting.
This model reflects the gener-ation process of reviews by introducinga heterogeneous structure into the hiddenlayer and incorporating informative priors.Experiments show that our model outper-forms previous state-of-the-art methods.1 IntroductionNowadays, it is commonplace for people to ex-press their opinion about various sorts of entities,e.g., products or services, on the Internet, espe-cially in the course of e-commerce activities.
Ana-lyzing online reviews not only helps customers ob-tain useful product information, but also providecompanies with feedback to enhance their prod-ucts or service quality.
Aspect-based opinion min-ing enables people to consider much more fine-grained analyses of vast quantities of online re-views, perhaps from numerous different merchantsites.
Thus, automatic identification of aspects ofentities and relevant sentiment polarities in BigData is a significant and urgent task (Liu, 2012;Pang and Lee, 2008; Popescu and Etzioni, 2005).Identifying aspect and analyzing sentimentwords from reviews has the ultimate goal of dis-cerning people?s opinions, attitudes, emotions, etc.towards entities such as products, services, orga-nizations, individuals, events, etc.
In this con-text, aspect-based opinion mining, also known asfeature-based opinion mining, aims at extractingand summarizing particular salient aspects of enti-ties and determining relevant sentiment polarities?Corresponding Author: Kang Liu (kliu@nlpr.ia.ac.cn)from reviews (Hu and Liu, 2004).
Consider re-views of computers, for example.
A given com-puter?s components (e.g., hard disk, screen) andattributes (e.g., volume, size) are viewed as aspectsto be extracted from the reviews, while sentimentpolarity classification consists in judging whetheran opinionated review expresses an overall posi-tive or negative opinion.Regarding aspect identification, previous meth-ods can be divided into three main categories:rule-based, supervised, and topic model-basedmethods.
For instance, association rule-basedmethods (Hu and Liu, 2004; Liu et al, 1998)tend to focus on extracting product feature wordsand opinion words but neglect connecting productfeatures at the aspect level.
Existing rule-basedmethods typically are not able to group the ex-tracted aspect terms into categories.
Supervised(Jin et al, 2009; Choi and Cardie, 2010) and semi-supervised learning methods (Zagibalov and Car-roll, 2008; Mukherjee and Liu, 2012) were intro-duced to resolve certain aspect identification prob-lems.
However, supervised training requires hand-labeled training data and has trouble coping withdomain adaptation scenarios.Hence, unsupervised methods are often adoptedto avoid this sort of dependency on labeled data.Latent Dirichlet Allocation, or LDA for short,(Blei et al, 2003) performs well in automaticallyextracting aspects and grouping correspondingrepresentative words into categories.
Thus, a num-ber of LDA-based aspect identification approacheshave been proposed in recent years (Brody and El-hadad, 2010; Titov and McDonald, 2008; Zhao etal., 2010).
Still, these methods have several im-portant drawbacks.
First, inaccurate approxima-tions of the distribution over topics may reduce thecomputational accuracy.
Second, mixture modelsare unable to exploit the co-occurrence of topicsto yield high probability predictions for words thatare sharper than the distributions predicted by in-616dividual topics (Hinton and Salakhutdinov, 2009).To overcome the weaknesses of existing meth-ods and pursue the promising direction ofjointly learning aspect and sentiment, we presentthe novel Sentiment-Aspect Extraction RBM(SERBM) model to simultaneously extract as-pects of entities and relevant sentiment-bearingwords.
This two-layer structure model is inspiredby conventional Restricted Boltzmann machines(RBMs).
In previous work, RBMs with sharedparameters (RSMs) have achieved great successin capturing distributed semantic representationsfrom text (Hinton and Salakhutdinov, 2009).Aiming to make the most of their ability tomodel latent topics while also accounting forthe structured nature of aspect opinion mining,we propose replacing the standard hidden lay-ers of RBMs with a novel heterogeneous struc-ture.
Three different types of hidden units areused to represent aspects, sentiments, and back-ground words, respectively.
This modification bet-ter reflects the generative process for reviews, inwhich review words are generated not only fromthe aspect distribution but also affected by senti-ment information.
Furthermore, we blend back-ground knowledge into this model using priors andregularization to help it acquire more accurate fea-ture representations.
After m-step Contrastive Di-vergence for parameter estimation, we can capturethe required data distribution and easily computethe posterior distribution over latent aspects andsentiments from reviews.
In this way, aspects andsentiments are jointly extracted from reviews, withlimited computational effort.
This model is hencea promising alternative to more complex LDA-based models presented previously.
Overall, ourmain contributions are as follows:1.
Compared with previous LDA-based meth-ods, our model avoids inaccurate approxima-tions and captures latent aspects and senti-ment both adequately and efficiently.2.
Our model exploits RBMs?
advantage inproperly modeling distributed semantic rep-resentations from text, but also introducesheterogeneous structure into the hidden layerto reflect the generative process for online re-views.
It also uses a form of regularization toincorporate prior knowledge into the model.Due these modifications, our model is verywell-suited for solving aspect-based opinionmining tasks.3.
The optimal weight matrix of this RBMmodel can exactly reflect individual wordfeatures toward aspects and sentiment, whichis hard to achieve with LDA-based modelsdue to the mixture model sharing mechanism.4.
Last but not the least, this RBM model is ca-pable of jointly modeling aspect and senti-ment information together.2 Related WorkWe summarize prior state-of-the-art models for as-pect extraction.
In their seminal work, Hu andLiu (2004) propose the idea of applying classicalinformation extraction to distinguish different as-pects in online reviews.
Methods following theirapproach exploit frequent noun words and depen-dency relations to extract product features withoutsupervision (Zhuang et al, 2006; Liu et al, 2005;Somasundaran and Wiebe, 2009).
These methodswork well when the aspect is strongly associatedwith a single noun, but obtain less satisfactory re-sults when the aspect emerges from a combinationof low frequency items.
Additionally, rule-basedmethods have a common shortcoming in failing togroup extracted aspect terms into categories.Supervised learning methods (Jin et al, 2009;Choi and Cardie, 2010; Jakob and Gurevych,2010; Kobayashi et al, 2007) such as HiddenMarkov Models, one-class SVMs, and Condi-tional Random Fields have been widely used inaspect information extraction.
These supervisedapproaches for aspect identification are generallybased on standard sequence labeling techniques.The downside of supervised learning is its require-ment of large amounts of hand-labeled trainingdata to provide enough information for aspect andopinion identification.Subsequent studies have proposed unsuper-vised learning methods, especially LDA-basedtopic modeling, to classify aspects of comments.Specific variants include the Multi-Grain LDAmodel (Titov and McDonald, 2008) to capturelocal rateable aspects, the two-step approach todetect aspect-specific opinion words (Brody andElhadad, 2010), the joint sentiment/topic model(JST) by Lin and He (2009), the topic-sentimentmixture model with domain adaption (Mei et al,2007), which treats sentiment as different topics,and MaxEnt-LDA (Zhao et al, 2010), which inte-grates a maximum entropy approach into LDA.617h1v1hFvDviiW1,1W1,F Wi,FWD,FWD,1Wi,1!!!!
hjvhiLatent TopicsW1 W2Figure 1: RBM SchemaHowever, these LDA-based methods can onlyadopt inaccurate approximations for the posteriordistribution over topics rather than exact inference.Additionally, as a mixture model, LDA suffersfrom the drawbacks mentioned in Section 1 thatare common to all mixture models.3 ModelIn order to improve over previous work, we firstintroduce a basic RBM-based model and then de-scribe our modified full model.3.1 Basic RBM-based ModelRestricted Boltzmann Machines can be used fortopic modeling by relying on the structure shownin Figure 1.
As shown on the left side of the fig-ure, this model is a two-layer neural network com-posed of one visible layer and one hidden layer.The visible layer consists of a softmax over dis-crete visible units for words in the text, while thehidden layer captures its topics.
More precisely,the visible layer is represented as a K ?
D ma-trix v, where K is the dictionary size, and D is thedocument length.
Here, if visible unit i in v takesthe k-th value, we set vki= 1.
The hidden layercan be expressed as h ?
{0, 1}F, where F is thenumber of hidden layer nodes, corresponding totopics.
The right side of Figure 1 is another wayof viewing the network, with a single multinomialvisible unit (Hinton and Salakhutdinov, 2009).The energy function of the model can be definedasE(v, h) = ?D?i=1F?j=1K?k=1Wkijhjvki?D?i=1K?k=1vkibki?F?j=1hjaj,(1)where Wkijspecifies the connection weight fromthe i-th visible node of value k to the j-th hiddennode, bkicorresponds to a bias of vki, and ajcorre-sponds to a bias of hj.The probability of the input layer v is defined asP (v) =1Z?hexp(?E(v, h)), (2)where Z is the partition function to normalize theprobability.The conditional probabilities from the hidden tothe visible layer and from the visible to the hiddenone are given in terms of a softmax and logisticfunction, respectively, i.e.P ( vki= 1 | h) =exp(bki+F?j=1hjWkij)K?q=1exp(bqi+F?j=1hjWqij),P ( hj= 1 | v) = ?
(aj+D?i=1K?k=1vkiWkij),(3)where ?
(x) = 1/(1 + exp(?x)) is the logisticfunction.3.2 Our Sentiment-Aspect Extraction modelWhile the basic RBM-based method provides asimple model of latent topics, real online reviewsrequire a more fine-grained model, as they con-sist of opinion aspects and sentiment information.Therefore, aspect identification is a different taskfrom regular topic modeling and the basic RBM-based model may not perform well in aspect ex-traction for reviews.To make the most of the ability of the basicRBM-based model in extracting latent topics, andobtain an effective method that is well-suited tosolve aspect identification tasks, we present ournovel Sentiment-Aspect Extraction RBM model.3.2.1 Generative PerspectiveFrom a generative perspective, product reviewscan be regarded as follows.
Every word in areview text may describe a specific aspect (e.g.?expensive?
for the price aspect), or an opinion(e.g.
?amazing?
for a positive sentiment and ?ter-rible?
for a negative one), or some irrelevant back-ground information (e.g.
?Sunday?).
In a genera-tive model, a word may be generated from a latentaspect variable, a sentiment variable, or a back-ground variable.
Also, there may exist certain re-lations between such latent variables.618v1h1vDhFhjW1,1 W1,FWx,yWD,FWD,1!id1_DT  id2_NN  id3_CC  id4_NNS  id5_NN  id6_JJ id7_VBZ   id8_JJSentencePOS!v1hi hk!!
!h1 hi!!
hj hk FAspect Sentiment Background?2 ?4?1?id_i"#"word count_i Dv1 vD ?W1,F WD,1Joint Learning with ?Prior KnowledgeAspect_i Sentiment_i?3Figure 2: Sentiment-Aspect Extraction Model3.2.2 StructureTo simulate this generative process for reviews,we adapt the standard RBM structure to reflect theaspect-sentiment identification task.Undirected Model.
Our Sentiment-Aspect Ex-traction model structure is illustrated in Figure 2.Compared to standard RBMs, a crucial differ-ence is that hidden units now have a heterogeneousstructure instead of being homogeneous as in thestandard basic RBM model.
In particular, we relyon three types of hidden units, representing aspect,sentiment, and background, respectively.
The firsttwo types are self-explanatory, while the back-ground units are intended to reflect the kind ofwords that do not contribute much to the aspect orsentiment information of review documents.
Sincethe output of the hidden units is a re-encoding ofthe information in the visible layer, we obtain adeeper representation and a more precise expres-sion of information in the input reviews.
Thus, thisapproach enables the model to learn multi-facetedinformation with a simple yet expressive structure.To formalize this, we denote v?k=?Di=1vkiasthe count for the k-th word, where D is the doc-ument length.
The energy function can then bedefined as follows:E(v, h) = ?F?j=1K?k=1Wkjhjv?k?K?k=1v?kbk?F?j=1hjaj,(4)where Wkjdenotes the weight between the k-thvisible unit and the j-th hidden unit.The conditional probability from visible to hid-den unit can be expressed as:P (hj= 1|v) = ?(aj+K?k=1v?kWkj).
(5)In an RBM, every hidden unit can be activatedor restrained by visible units.
Thus, every visibleunit has a potential contribution towards the acti-vation of a given hidden unit.
The probability ofwhether a given visible unit affects a specific hid-den unit is described as follows (cf.
appendix fordetails):P (hj= 1 | v?k) =P (hj= 1 | h?j, v?k)=?(aj+Wkjv?k).
(6)Under this architecture, this equation can be ex-plained as the conditional probability from visibleunit k to hidden unit j (softmax of words to as-pect or sentiment).
According to Eq.
6, the con-ditional probability for the k-th word feature to-wards the j-th aspect or sentiment p(hj= 1 | vk)is a monotone function of Wkj, the (k, j)-th entryof the optimal weight matrix.
Thus, the optimalweight matrix of this RBM model can directly re-flect individual word features toward aspects andsentiment.Informative Priors.
To improve the ability ofthe model to extract aspects and identify senti-ments, we capture priors for words in reviews andincorporate this information into the learning pro-cess of our Sentiment-Aspect Extraction model.We regularize our model based on these priors toconstrain the aspect modeling and improve its ac-curacy.
Figure 3 provides an example of how suchpriors can be applied to a sentence, with ?irepre-senting the prior knowledge.Research has found that most aspect words arenouns (or noun phrases), and sentiment is oftenexpressed with adjectives.
This additional infor-mation has been utilized in previous work on as-pect extraction (Hu and Liu, 2004; Benamara etal., 2007; Pang et al, 2002).
Inspired by this, wefirst rely on Part of Speech (POS) Tagging to iden-tify nouns and adjectives.
For all noun words, wefirst calculate their term frequency (TF) in the re-view corpus, and then compute their inverse doc-ument frequency (IDF) from an external Googlen-gram corpus1.
Finally, we rank their TF?IDF1http://books.google.com/ngrams/datasets619The_DT  delicious_JJ  dishes_NN  in_IN the_DT restaurant_NN  taste_VBZ  great_JJSentencePart of Speech Tagging?2 Aspect?3   ?1Aspect_i Sentiment_i?4 SentimentFigure 3: Prior Feature Extractionvalues and assign them an aspect prior probabilitypA,vk, indicating their general probability of be-ing an aspect word.
This TF-IDF approach is mo-tivated by the following intuitions: the most fre-quently mentioned candidates in reviews have thehighest probability of being an opinion target andfalse target words are non-domain specific and fre-quently appear in a general text corpus (Liu et al,2012; Liu et al, 2013).
For all adjective words, ifthe words are also included in the online sentimentresource SentiWordNet2, we assign prior probabil-ity ps,vkto suggest that these words are generallyrecognized as sentiment words.Apart from these general priors, we obtain asmall amount of fine-grained information as an-other type of prior knowledge.
This fine-grainedprior knowledge serves to indicate the probabil-ity of a known aspect word belonging to a specificaspect, denoted as pAj,vkand an identified senti-ment word bearing positive or negative sentiment,denoted as pSj,vk.
For instance, ?salad?
is alwaysconsidered as a general word that belongs to thespecific aspect food, and ?great?
is generally con-sidered a positive sentiment word.To extract pAj,vk, we apply regular LDA on thereview dataset.
Since the resulting topic clustersare unlabeled, we manually assign top k wordsfrom the topics to the target aspects.
We thusobtain fine-grained prior probabilities to suggestthese words as belonging to specific aspects.
Toobtain pSj,vk, we rely on SentiWordNet and sumup the probabilities of an identified sentimentword being positive or negative sentiment-bearing,respectively.
Then we adopt the correspondingpercentage value as a fine-grained specific senti-ment prior.It is worthwhile to mention that the priors arenot a compulsory component.
However, the pro-cedure for obtaining priors is generic and can eas-2http://sentiwordnet.isti.cnr.itily be applied to any given dataset.
Furthermore,we only obtain such fine-grained prior knowledgefor a small amount of words in review sentencesand rely on the capability of model itself to dealwith the remaining words.3.2.3 Objective FunctionWe now construct an objective function for ourSERBM model that includes regularization basedon the priors defined above in Section 3.2.2.
Sup-pose that the training set is S = v1, v2, .
.
.
, vns,where nsis the number of training objects.
Eachelement has the form vi= (vi1, vi2, .
.
.
, viK)D,where i = 1, 2, .
.
.
, ns, and these data points areassumed to be independent and identically dis-tributed.We define the following novel log-likelihoodfunction lnLS, with four forms of regularizationcorresponding to the four kinds of priors:lnLS= lnns?i=1P (vi)?ns?i=1[?1lnF1?1?j=1?k?R1[P (hj= 1 | v?k)?
pAj,vk]2+ ?2ln?k?R2[F1?j=1P (hj= 1 | v?k)?
pA,vk]2+ ?3lnF2+1?j=F2?k?R3[P (hj= 1 | v?k)?
pSj,vk]2+ ?4ln?k?R4[F2+1?j=F2P (hj= 1 | v?k)?
pS,vk]2](7)Here, P (hj= 1 | v?k) stands for the probability ofa given input word belonging to a specific hiddenunit.
We assume all ?i> 0 for i = 1 .
.
.
4, whileF1and F2are integers for the offsets within thehidden layer.
Units up to index F1capture aspects,with the last one reserved for miscellaneous OtherAspects, while units from F2capture the sentiment(with F1= F2+ 1 < F for convenience).Our goal will be to maximize the log-likelihoodlnLSin order to adequately model the data, in ac-cordance with the regularization.3.2.4 TrainingWe use Stochastic Gradient Descent (SGD) to findsuitable parameters that maximize the objectivefunction.
Given a single training instance v from620the training set S, we obtain?
lnL??=?
lnP (v)???
?1F1?1?j=1?k?R1?
ln[P (hj= 1 | v?k)?
pAj,vk]2???
?2?k?R2?
ln[?F1j=1P (hj= 1 | v?k)?
pA,vk]2???
?3F2+1?j=F2?k?R3?
ln[P (hj= 1 | v?k)?
pSj,vk]2???
?4?k?R4?
ln[?F2+1j=F2P (hj= 1 | v?k)?
pS,vk]2??
(8)where ?
= {W,aj, bi} stands for the parameters.Given N documents {vn}Nn=1, the first term in thelog-likelihood function with respect to W is:1NN?n=1?
lnP (vn)?Wkj= ED1[v?khj]?
ED2[v?khj].
(9)Here, D1[?]
and D2[?]
represent the expectationwith respect to the data distribution and the dis-tribution obtained by this model, respectively.
Weuse Contrastive Divergence (CD) to approximateED2[v?khj] (Hinton and Salakhutdinov, 2009).Due to the m steps of transfer between input andhidden layers in a CD-m run of the algorithm, thetwo types of hidden units, aspect and sentiment,will jointly affect input reviews together with theconnection matrix between the two layers.Finally, we consider the partial derivative of theentire log-likelihood function with respect to theparameter W .
Denoting ln?L?Was ?W , in eachstep we update?Wkjby adding?
[P (hj= 1|v(0))v(0)k?
P (hj= 1|v(cdm))v(cdm)k]?
?1F1?1?j=1?k?R12Gjv?k(1 +Gj)2(11+Gj?
pAj,vk)?
?2?k?R22v?k?F1j=11(1+Gj)?
pA,vkF1?j=1Gj(1 +Gj)2?
?3F2+1?j=F2?k?R32Gjv?k(1 +Gj)2(11+Gj?
pSj,vk)?
?4?k?R42v?k?F2+1j=F21(1+Gj)?
pS,vkF2+1?j=F2Gj(1 +Gj)2,where Gj=e?
(aj+Wkjv?k)for convenience, andv(cdm)is the result from the CD-m steps.4 ExperimentsWe present a series of experiments to evaluate ourmodel?s performance on the aspect identificationand sentiment classification tasks.4.1 DataFor this evaluation, we rely on a restaurant reviewdataset widely adopted by previous work (Ganuet al, 2009; Brody and Elhadad, 2010; Zhao etal., 2010), which contains 1,644,923 tokens and52,574 documents in total.
Documents in thisdataset are annotated with one or more labels froma gold standard label set S = {Food, Staff, Ambi-ence, Price, Anecdote, Miscellaneous}.
Followingthe previous studies, we select reviews with lessthan 50 sentences and remove stop words.
TheStanford POS Tagger3is used to distinguish nounand adjective words from each other.We later also rely on the Polarity dataset v2.04to conduct an additional experiment on senti-ment classification in order to better assess themodel?s overall performance.
This dataset focuseson movie reviews and consists of 1000 positivereview documents and 1000 negative ones.
Ithas also been used in the experiments by Lin &He (2009), among others.4.2 Aspect IdentificationWe first apply our novel model to identify aspectsfrom documents in the restaurant review dataset.4.2.1 Experimental SetupFor the experimental setup, we use ten hiddenunits in our Sentiment-Aspect Extraction RBM(SERBM), where units 0?6 capture aspects, units7?8 capture sentiment information, and unit 9stores background information.
In particular, wefix hidden units 0?6 to represent the target aspectsFood, Staff, Ambience, Price, Ambience, Miscella-neous, and Other Aspects, respectively.
Units 7?8represent positive and negative sentiment, respec-tively.
The remaining hidden unit is intended tocapture irrelevant background information.Note that the structure of our model needs nomodifications for new reviews.
There are twocases for datasets from a new domain.
If the new3http://nlp.stanford.edu/software/tagger.shtml4http://www.cs.cornell.edu/people/pabo/movie-review-data/621Method RBM RSM SERBMPPL 49.73 39.19 21.18Table 1: Results in terms of perplexitydataset has a gold standard label set, then we as-sign one hidden unit to represent each label in thegold standard set.
If not, our model only obtainsthe priors pA,vkand pS,vk, and the aspect set canbe inferred as in the work of Zhao et al (2010).For evaluation, following previous work, the an-notated data is fed into our unsupervised model,without any of the corresponding labels.
Themodel is then evaluated in terms of how well itsprediction matches the true labels.
As for hyperpa-rameter optimization, we use the perplexity scoresas defined in Eq.
10 to find the optimal hyper-parameters.As a baseline, we also re-implement standardRBMs and the RSM model (Hinton and Salakhut-dinov, 2009) to process this same restaurant re-view dataset and identify aspects for every doc-ument in this dataset under the same experimentalconditions.
We recall that RSM is a similar undi-rected graphical model that models topics fromraw text.Last but not the least, we conduct addi-tional comparative experiments, includingwith LocLDA (Brody and Elhadad, 2010),MaxEnt-LDA (Zhao et al, 2010) and the SASmodel (Mukherjee and Liu, 2012) to extractaspects for this restaurant review dataset under thesame experimental conditions.
In the following,we use the abbreviated name MELDA to stand forthe MaxEnt LDA method.4.2.2 EvaluationBrody and Elhadad (2010) and Zhao et al (2010)utilize three aspects to perform a quantitative eval-uation and only use sentences with a single labelfor evaluation to avoid ambiguity.
The three majoraspects chosen from the gold standard labels areS = {Food, Staff, Ambience}.
The evaluation cri-terion essentially is to judge how well the predic-tion matches the true label, resulting in Precision,Recall, and F1scores.
Besides these, we considerperplexity (PPL) as another evaluation metric toanalyze the aspect identification quality.
The aver-age test perplexity PPL over words is defined as:exp(?1NN?n=11DnlogP (vn)),(10)Aspect Method Precision Recall F1RBM 0.753 0.680 0.715RSM 0.718 0.736 0.727food LocLDA 0.898 0.648 0.753MELDA 0.874 0.787 0.828SAS 0.867 0.772 0.817SERBM 0.891 0.854 0.872RBM 0.436 0.567 0.493RSM 0.430 0.310 0.360staff LocLDA 0.804 0.585 0.677MELDA 0.779 0.540 0.638SAS 0.774 0.556 0.647SERBM 0.819 0.582 0.680RBM 0.489 0.439 0.463RSM 0.498 0.441 0.468ambi LocLDA 0.603 0.677 0.638-ence MELDA 0.773 0.588 0.668SAS 0.780 0.542 0.640SERBM 0.805 0.592 0.682Table 2: Aspect identification results in terms ofprecision, recall, and F1scores on the restaurantreviews datasetwhere N is the number of documents, Dnrepre-sents the word number, and vnstands for the word-count of document n.Average perplexity results are reported in Ta-ble 1, while Precision, Recall, and F1evaluationresults for aspect identification are given in Ta-ble 2.
Some LDA-based methods require manualmappings for evaluation, which causes difficultiesin obtaining a fair PPL result, so a few methodsare only considered in Table 2.To illustrate the differences, in Table 3, we listrepresentative words for aspects identified by var-ious models and highlight words without an obvi-ous association or words that are rather unspecificin bold.4.2.3 DiscussionConsidering the results from Table 1 and theRBM, RSM, and SERBM-related results from Ta-ble 2, we find that the RSM performs better thanthe regular RBM model on this aspect identifi-cation task.
However, the average test perplex-ity is greatly reduced even further by the SERBMmethod, resulting in a relative improvement by45.96% over the RSM model.
Thus, despitethe elaborate modification, our SERBM inheritsRBMs?
ability in modeling latent topics, but sig-nificantly outperforms other RBM family models622Aspect RSM RBM Loc-LDA ME-LDA SAS SERBMgreat menu,drink chicken chocolate food,menu salad,cheesedessert food,pizza menu,salad dessert dessert dessertbeef chicken good cream drinks chickenFood drink,BBQ seafood fish ice,cake chicken saucemenu good drinks desserts cheeses rice,pizzadelicious sandwich wine,sauce good beers,salad foodgood soup rice bread delicious dishfish flavor cheese cheese rice sushi,menuservice staff service service staff,slow serviceroom helpful staff,waiter staff,food waitress staff,friendlyslow waiter attentive wait,waiters attentive waitressStaff table friendly busy waiter helpful waitstaffquick good,attentive slow,friendly place service attentivewaitress slow,service table restaurant minutes waitressesfriendly restaurant wait waitress wait,friendly serverswaiter minutes minutes waitstaff waiter minutesatmosphere place great room place atmospheremusic atmosphere atmosphere dining decor atmosphereplace cozy wonderful tables great scenedinner door music bar good placeAmbience romantic cute seating place romantic tablesroom bar experience decor tables outsidecomfortable great relaxed scene bar areatables seating bar space decor ambiancegood experience room area great outdoorambiance romantic outside table music romantic,cozyTable 3: Aspects and representative wordson the aspect identification task.In Table 2, we also observe that SERBMachieves a higher accuracy compared withother state-of-the-art aspect identification meth-ods.
More specifically, it is evident that ourSERBM model outperforms previous methods?
F1scores.
Compared with MELDA, the F1scoresfor the SERBM lead to relative improvements of5.31%, 6.58%, and 2.10%, respectively, for theFood, Staff, and Ambience aspects.
Comparedwith SAS, the F1scores yield relative improve-ments by 6.73%, 5.10%, and 6.56%, respectively,on those same aspects.
As for Precision and Re-call, the SERBM also achieves a competitive per-formance compared with other methods in aspectidentification.Finally, we conclude from Table 3 that theSERBM method has the capability of extractingword with obvious aspect-specific features andmakes less errors compared with other models.4.3 Sentiment ClassificationWe additionally conduct two experiments to eval-uate the model?s performance on sentiment classi-fication.4.3.1 Comparison with SentiWordNetWe assign a sentiment score to every document inthe restaurant review dataset based on the outputof SERBM?s sentiment-type hidden units.
To ana-lyze SERBM?s performance in sentiment classifi-cation, we compare these results with SentiWord-Net5, a well-known sentiment lexicon.
For thisSentiWordNet baseline, we consult the resource toobtain a sentiment label for every word and ag-gregate these to judge the sentiment informationof an entire review document in terms of the sumof word-specific scores.
Table 4 provides a com-parison between SERBM and SentiWordNet, withAccuracy as the evaluation metric.We observe in Table 4 that the sentiment5http://sentiwordnet.isti.cnr.it623Method SentiWordNet SERBMAccuracy 0.703 0.788Table 4: Accuracy for SERBM and SentiWordNetclassification accuracy on the restaurant reviewdataset sees a relative improvement by 12.1% withSERBM over the SentiWordNet baseline.4.3.2 Comparison with JSTWe additionally utilize the Polarity dataset v2.0 toconduct an additional sentiment classification ex-periment in order to assess SERBM?s performancemore thoroughly.
We compare SERBM with theadvanced joint sentiment/topic model (JST) byLin & He (2009).
For the JST and the Trying-JST methods only, we use the filtered subjectiv-ity lexicon (subjective MR) as prior information,containing 374 positive and 675 negative entries,which is the same experimental setting as in Lin& He (2009).
For SERBM, we use the same gen-eral setup as before except for the fact that aspect-specific priors are not used here.Table 5 provides the sentiment classification ac-curacies on both the overall dataset and on the sub-sets for each polarity, where pos.
and neg.
refer tothe positive and negative reviews in the dataset, re-spectively.Method overall pos.
neg.JST(%) 84.6 96.2 73Trying-JST(%) 82 89.2 74.8SERBM(%) 89.1 92.0 86.2Table 5: Accuracy for SERBM and JSTIn Table 5, we observe that SERBM outper-forms JST both in terms of the overall accu-racy and for the positive/negative-specific subsets.SERBM yields a relative improvement in the over-all accuracy by 5.31% over JST and by 8.66% overTrying-JST.5 ConclusionIn this paper, we have proposed the novelSentiment-Aspect Extraction RBM (SERBM)model to jointly extract review aspects and sen-timent polarities in an unsupervised setting.
Ourapproach modifies the standard RBM model byintroducing a heterogeneous structure into the hid-den layer and incorporating informative priors intothe model.
Our experimental results show that thismodel can outperform LDA-based methods.Hence, our work opens up the avenue of uti-lizing RBM-based undirected graphical models tosolve aspect extraction and sentiment classifica-tion tasks as well as other unsupervised tasks withsimilar structure.AppendixThe joint probability distribution is defined asp?
(v, h) =1Z?eE?
(v,h), (11)where Z?is the partition function.
In conjunctionwith Eq.
1, we obtainE?
(v?k, h) = ?biv?k?F?j=1ajhj?F?j=1hjWkjv?k(12)Then, we can obtain the derivation in Eq.
6.P (hj= 1 | v?k)=P (hj= 1 | h?j, v?k)=P (hj= 1, h?j, v?k)P (h?j, v?k)=P (hj= 1, h?j, v?k)P (hj= 1, h?j, v?k) + P (hj= 0, h?j, v?k)=1Ze?E(hj=1,h?j,v?k)1Ze?E(hj=1,h?j,v?k)+1Ze?E(hj=0,h?j,v?k)=e?E(hj=1,h?j,v?k)e?E(hj=1,h?j,v?k)+ e?E(hj=0,h?j,v?k)=11 + e?E(hj=0,h?j,v?k)+E(hj=1,h?j,v?k)=?
(aj+Wkjv?k)(13)AcknowledgmentsThe research at IIIS was supported by China 973Program Grants 2011CBA00300, 2011CBA00301and NSFC Grants 61033001, 61361136003,61450110088.
The research at CASIA was sup-ported by the National Basic Research Programof China Grant No.
2012CB316300 and NSFCGrants 61272332 and 61202329.624ReferencesFarah Benamara, Carmine Cesarano, Antonio Pi-cariello, Diego Reforgiato Recupero, and Venkatra-mana Subrahmanian.
2007.
Sentiment analysis:Adjectives and adverbs are better than adjectivesalone.
In Proceedings of ICWSM 2007.David Blei, Andrew Ng, and Michael Jordan.
2003.Latent dirichlet alocation.
Journal of MachineLearning Research, 3:993?1022.Samuel Brody and Noemie Elhadad.
2010.
An unsu-pervised aspect-sentiment model for online reviews.In Proceedings of NAACL-HLT 2010, pages 804?812.
Association for Computational Linguistics.Yejin Choi and Claire Cardie.
2010.
Hierarchical se-quential learning for extracting opinions and theirattributes.
In Proceedings of ACL 2010, pages 269?274.
Association for Computational Linguistics.Gayatree Ganu, Noemie Elhadad, and Am?elie Marian.2009.
Beyond the stars: Improving rating predic-tions using review text content.
In Proceedings ofWebDB 2009, pages 1?6.Geoffrey Hinton and Ruslan Salakhutdinov.
2009.Replicated softmax: an undirected topic model.
InAdvances in Neural Information Processing Systems(NIPS 2009), pages 1607?1614.Minqing Hu and Bing Liu.
2004.
Mining and sum-marizing customer reviews.
In Proceedings of KDD2004, pages 168?177, New York, NY, USA.
ACM.Niklas Jakob and Iryna Gurevych.
2010.
Extractingopinion targets in a single-and cross-domain settingwith Conditional Random Fields.
In Proceedingsof EMNLP 2010, pages 1035?1045.
Association forComputational Linguistics.Wei Jin, Hung Hay Ho, and Rohini K Srihari.
2009.
Anovel lexicalized HMM-based learning frameworkfor Web opinion mining.
In Proceedings of ICML2009, pages 465?472.Nozomi Kobayashi, Kentaro Inui, and Yuji Matsumoto.2007.
Extracting aspect-evaluation and aspect-ofrelations in opinion mining.
In Proceedings ofEMNLP-CoNLL, pages 1065?1074.Chenghua Lin and Yulan He.
2009.
Joint senti-ment/topic model for sentiment analysis.
In Pro-ceedings of the 18th ACM Conference on Infor-mation and Knowledge Management (CIKM 2009),pages 375?384.
ACM.Bing Liu, Wynne Hsu, and Yiming Ma.
1998.
In-tegrating classification and association rule mining.In Proceedings of KDD 1998, pages 80?86.
AAAIPress.Bing Liu, Minqing Hu, and Junsheng Cheng.
2005.Opinion observer: analyzing and comparing opin-ions on the Web.
In Proceedings of the 14th inter-national conference on World Wide Web, pages 342?351.
ACM.Kang Liu, Liheng Xu, and Jun Zhao.
2012.
Opin-ion target extraction using word-based translationmodel.
In Proceedings of EMNLP-CoNLL 2012,pages 1346?1356.Kang Liu, Liheng Xu, Yang Liu, and Jun Zhao.
2013.Opinion target extraction using partially-supervisedword alignment model.
In Proceedings of the 23rdInternational Joint Conference on Artificial Intelli-gence (IJCAI 2013), pages 2134?2140.
AAAI Press.Bing Liu.
2012.
Sentiment analysis and opinion min-ing.
Synthesis Lectures on Human Language Tech-nologies, 5(1):1?167.Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su,and ChengXiang Zhai.
2007.
Topic sentiment mix-ture: modeling facets and opinions in weblogs.
InProceedings of the 16th international conference onthe World Wide Web (WWW 2007), pages 171?180.ACM.Arjun Mukherjee and Bing Liu.
2012.
Aspect extrac-tion through semi-supervised modeling.
In Proceed-ings of ACL 2012, pages 339?348.Bo Pang and Lillian Lee.
2008.
Opinion mining andsentiment analysis.
Foundations and trends in infor-mation retrieval, 2(1-2):1?135.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
: Sentiment classification us-ing machine learning techniques.
In Proceedings ofEMNLP 2002, pages 79?86.
Association for Com-putational Linguistics.Ana-Maria Popescu and Orena Etzioni.
2005.
Extract-ing product features and opinions from reviews.
InProceedings of HLT/EMNLP 2005.
Springer.Swapna Somasundaran and Janyce Wiebe.
2009.
Rec-ognizing stances in online debates.
In Proceedingsof ACL-IJCNLP 2009, pages 226?234.
Associationfor Computational Linguistics.Ivan Titov and Ryan McDonald.
2008.
Modelingonline reviews with multi-grain topic models.
InProceedings of the 17th international conference onthe World Wide Web (WWW 2008), pages 111?120.ACM.Taras Zagibalov and John Carroll.
2008.
Automaticseed word selection for unsupervised sentiment clas-sification of Chinese text.
In Proceedings of COL-ING 2008, pages 1073?1080.Wayne Xin Zhao, Jing Jiang, Hongfei Yan, and Xiaom-ing Li.
2010.
Jointly modeling aspects and opin-ions with a MaxEnt-LDA hybrid.
In Proceedings ofEMNLP 2010, pages 56?65.
Association for Com-putational Linguistics.Li Zhuang, Feng Jing, and Xiao-Yan Zhu.
2006.Movie review mining and summarization.
In Pro-ceedings of the 15th ACM international Conferenceon Information and Knowledge Management (CIKM2006), pages 43?50.
ACM.625
