Proceedings of the 12th Conference of the European Chapter of the ACL, pages 496?504,Athens, Greece, 30 March ?
3 April 2009. c?2009 Association for Computational LinguisticsLanguage-independent bilingual terminology extraction from amultilingual parallel corpusEls Lefever1,2, Lieve Macken1,2 and Veronique Hoste1,21LT3School of Translation StudiesUniversity College GhentGroot-Brittannie?laan 459000 Gent, Belgium2Department of Applied Mathematicsand Computer ScienceGhent UniversityKrijgslaan281-S99000 Gent, Belgium{Els.Lefever, Lieve.Macken, Veronique.Hoste}@hogent.beAbstractWe present a language-pair independentterminology extraction module that isbased on a sub-sentential alignment sys-tem that links linguistically motivatedphrases in parallel texts.
Statistical filtersare applied on the bilingual list of candi-date terms that is extracted from the align-ment output.We compare the performance of boththe alignment and terminology extrac-tion module for three different languagepairs (French-English, French-Italian andFrench-Dutch) and highlight language-pair specific problems (e.g.
different com-pounding strategy in French and Dutch).Comparisons with standard terminologyextraction programs show an improvementof up to 20% for bilingual terminology ex-traction and competitive results (85% to90% accuracy) for monolingual terminol-ogy extraction, and reveal that the linguis-tically based alignment module is particu-larly well suited for the extraction of com-plex multiword terms.1 IntroductionAutomatic Term Recognition (ATR) systems areusually categorized into two main families.
On theone hand, the linguistically-based or rule-basedapproaches use linguistic information such as PoStags, chunk information, etc.
to filter out stopwords and restrict candidate terms to predefinedsyntactic patterns (Ananiadou, 1994), (Dagan andChurch, 1994).
On the other hand, the statisticalcorpus-based approaches select n-gram sequencesas candidate terms that are filtered by means ofstatistical measures.
More recent ATR systemsuse hybrid approaches that combine both linguis-tic and statistical information (Frantzi and Anani-adou, 1999).Most bilingual terminology extraction systemsfirst identify candidate terms in the source lan-guage based on predefined source patterns, andthen select translation candidates for these termsin the target language (Kupiec, 1993).We present an alternative approach that gen-erates candidate terms directly from the alignedwords and phrases in our parallel corpus.
In a sec-ond step, we use frequency information of a gen-eral purpose corpus and the n-gram frequenciesof the automotive corpus to determine the termspecificity.
Our approach is more flexible in thesense that we do not first generate candidate termsbased on language-dependent predefined PoS pat-terns (e.g.
for French, N N, N Prep N, and NAdj are typical patterns), but immediately link lin-guistically motivated phrases in our parallel cor-pus based on lexical correspondences and syntac-tic similarity.This article reports on the term extraction ex-periments for 3 language pairs, i.e.
French-Dutch,French-English and French-Italian.
The focus wason the extraction of automative lexicons.The remainder of this paper is organized as fol-lows: Section 2 describes the corpus.
In Section 3we present our linguistically-based sub-sententialalignment system and in Section 4 we describehow we generate and filter our list of candidateterms.
We compare the performance of our sys-tem with both bilingual and monolingual state-of-the-art terminology extraction systems.
Section 5concludes this paper.4962 CorpusThe focus of this research project was on the au-tomatic extraction of 20 bilingual automative lex-icons.
All work was carried out in the frameworkof a customer project for a major French automo-tive company.
The final goal of the project is toimprove vocabulary consistency in technical textsacross the 20 languages in the customer?s portfo-lio.
The French database contains about 400,000entries (i.e.
sentences and parts of sentences withan average length of 9 words) and the translationpercentage of the database into 19 languages de-pends on the target market.For the development of the alignment and termi-nology extraction module, we created three paral-lel corpora (Italian, English, Dutch) with Frenchas a central language.
Figures about the size ofeach parallel corpus can be found in table 1.Target Lang.
# Sentence pairs # wordsFrench Italian 364,221 6,408,693French English 363,651 7,305,151French Dutch 364,311 7,100,585Table 1: Number of sentence pairs and total num-ber of words in the three parallel corpora2.1 PreprocessingWe PoS-tagged and lemmatized the French, En-glish and Italian corpora with the freely availableTreeTagger tool (Schmid, 1994) and we used Tad-Pole (Van den Bosch et al, 2007) to annotate theDutch corpus.In a next step, chunk information was addedby a rule-based language-independent chunker(Macken et al, 2008) that contains distituencyrules, which implies that chunk boundaries areadded between two PoS codes that cannot occurin the same constituent.2.2 Test and development corpusAs we presume that sentence length has an impacton the alignment performance, and thus on termextraction, we created three test sets with vary-ing sentence lengths.
We distinguished short sen-tences (2-7 words), medium-length sentences (8-19 words) and long sentences (> 19 words).
Eachtest corpus contains approximately 9,000 words;the number of sentence pairs per test set can befound in table 2.
We also created a developmentcorpus with sentences of varying length to debugthe linguistic processing and the alignment mod-ule as well as to define the thresholds for the sta-tistical filtering of the candidate terms (see 4.1).# Words # Sentence pairsShort (< 8 words) +- 9,000 823Medium (8-19 words) +- 9,000 386Long (> 19 words) +- 9,000 180Development corpus +-5,000 393Table 2: Number of words and sentence pairs inthe test and development corpora3 Sub-sentential alignment moduleAs the basis for our terminology extraction sys-tem, we used the sub-sentential alignment sys-tem of (Macken and Daelemans, 2009) that linkslinguistically motivated phrases in parallel textsbased on lexical correspondences and syntacticsimilarity.
In the first phase of this system, anchorchunks are linked, i.e.
chunks that can be linkedwith a very high precision.
We think these anchorchunks offer a valid and language-independent al-ternative to identify candidate terms based on pre-defined PoS patterns.
As the automotive corpuscontains rather literal translations, we expect that ahigh percentage of anchor chunks can be retrieved.Although the architecture of the sub-sententialalignment system is language-independent, somelanguage-specific resources are used.
First, abilingual lexicon to generate the lexical correspon-dences and second, tools to generate additionallinguistic information (PoS tagger, lemmatizer anda chunker).
The sub-sentential alignment systemtakes as input sentence-aligned texts, together withthe additional linguistic annotations for the sourceand the target texts.The source and target sentences are divided intochunks based on PoS information, and lexical cor-respondences are retrieved from a bilingual dic-tionary.
In order to extract bilingual dictionariesfrom the three parallel corpora, we used the Perlimplementation of IBM Model One that is part ofthe Microsoft Bilingual Sentence Aligner (Moore,2002).In order to link chunks based on lexical cluesand chunk similarity, the following steps are takenfor each sentence pair:1.
Creation of the lexical link matrix2.
Linking chunks based on lexical correspon-dences and chunk similarity4973.
Linking remaining chunks3.1 Lexical Link MatrixFor each source and target word, all translationsfor the word form and the lemma are retrievedfrom the bilingual dictionary.
In the process ofbuilding the lexical link matrix, function words areneglected.
For all content words, a lexical link iscreated if a source word occurs in the set of pos-sible translations of a target word, or if a targetword occurs in the set of possible translations ofthe source words.
Identical strings in source andtarget language are also linked.3.2 Linking Anchor chunksCandidate anchor chunks are selected based on theinformation available in the lexical link matrix.The candidate target chunk is built by concatenat-ing all target chunks from a begin index until anend index.
The begin index points to the first targetchunk with a lexical link to the source chunk un-der consideration.
The end index points to the lasttarget chunk with a lexical link to the source chunkunder consideration.
This way, 1:1 and 1:n candi-date target chunks are built.
The process of select-ing candidate chunks as described above, is per-formed a second time starting from the target sen-tence.
This way, additional n:1 candidates are con-structed.
For each selected candidate pair, a simi-larity test is performed.
Chunks are considered tobe similar if at least a certain percentage of wordsof source and target chunk(s) are either linked bymeans of a lexical link or can be linked on the basisof corresponding part-of-speech codes.
The per-centage of words that have to be linked was em-pirically set at 85%.3.3 Linking Remaining ChunksIn a second step, chunks consisting of one functionword ?
mostly punctuation marks and conjunc-tions ?
are linked based on corresponding part-of-speech codes if their left or right neighbour on thediagonal is an anchor chunk.
Corresponding finalpunctuation marks are also linked.In a final step, additional candidates are con-structed by selecting non-anchor chunks in thesource and target sentence that have correspond-ing left and right anchor chunks as neigbours.
Theanchor chunks of the first step are used as contex-tual information to link n:m chunks or chunks forwhich no lexical link was found in the lexical linkmatrix.In Figure 1, the chunks [Fr: gradient] ?
[En:gradient] and the final punctuation mark have beenretrieved in the first step as anchor chunk.
In thelast step, the n:m chunk [Fr: de remonte?e pe?daled?
embrayage] ?
[En: of rising of the clutch pedal]is selected as candidate anchor chunk because it isenclosed within anchor chunks.Figure 1: n:m candidate chunk: ?A?
stands for an-chor chunks, ?L?
for lexical links, ?P?
for wordslinked on the basis of corresponding PoS codesand ?R?
for words linked by language-dependentrules.As the contextual clues (the left and right neig-bours of the additional candidate chunks are an-chor chunks) provide some extra indication thatthe chunks can be linked, the similarity test forthe final candidates was somewhat relaxed: thepercentage of words that have to be linked waslowered to 0.80 and a more relaxed PoS matchingfunction was used.3.4 EvaluationTo test our alignment module, we manually indi-cated all translational correspondences in the threetest corpora.
We used the evaluation methodologyof Och and Ney (2003) to evaluate the system?sperformance.
They distinguished sure alignments(S) and possible alignments (P) and introduced thefollowing redefined precision and recall measures(where A refers to the set of alignments):precision =|A ?
P ||A|, recall =|A ?
S||S|(1)and the alignment error rate (AER):AER(S, P ;A) = 1?|A ?
P |+ |A ?
S||A|+ |S|(2)498Table 3 shows the alignment results for the threelanguage pairs.
(Macken et al, 2008) showed thatthe results for French-English were competitive tostate-of-the-art alignment systems.SHORT MEDIUM LONGp r e p r e p r eItalian .99 .93 .04 .95 .89 .08 .95 .89 .07English .97 .91 .06 .95 .85 .10 .92 .85 .12Dutch .96 .83 .11 .87 .73 .20 .87 .67 .24Table 3: Precision (p), recall (r) and alignment er-ror rate (e) for our sub-sentential alignment sys-tem evaluated on French-Italian, French-Englishand French-DutchAs expected, the results show that the align-ment quality is closely related to the similarity be-tween languages.
As shown in example (1), Ital-ian and French are syntactically almost identical?
and hence easier to align, English and Frenchare still close but show some differences (e.g dif-ferent compounding strategy and word order) andFrench and Dutch present a very different lan-guage structure (e.g.
in Dutch the different com-pound parts are not separated by spaces, separableverbs, i.e.
verbs with prefixes that are stripped off,occur frequently (losmaken as an infinitive versusmaak los in the conjugated forms) and a differentword order is adopted).
(1) Fr: de?clipper le renvoi de ceinture de se?curite?.
(En: unclip the mounting of the belt of safety)It: sganciare il dispositivo di riavvolgimento dellacintura di sicurezza.
(En: unclip the mounting of the belt of satefy)En: unclip the seat belt mounting.Du: maak de oprolautomaat van de autogordel los.
(En: clip the mounting of the seat-belt un)We tried to improve the low recall for French-Dutch by adding a decompounding module to ouralignment system.
In case the target word doesnot have a lexical correspondence in the sourcesentence, we decompose the Dutch word into itsmeaningful parts and look for translations of thecompound parts.
This implies that, without de-compounding, in example 2 only the correspon-dences doublure ?
binnenpaneel, arc ?
dakverste-viging and arrie`re ?
achter will be found.
By de-composing the compound into its meaningful parts(binnenpaneel = binnen + paneel, dakversteviging= dak + versteviging) and retrieving the lexicallinks for the compound parts, we were able to linkthe missing correspondence: pavillon ?
dakverste-viging.
(2) Fr: doublure arc pavillon arrie`re.
(En: rear roof arch lining)Du: binnenpaneel dakversteviging achter.We experimented with the decompounding mod-ule of (Vandeghinste, 2008), which is based onthe Celex lexical database (Baayen et al, 1993).The module, however, did not adapt well to thehighly technical automotive domain, which is re-flected by its low recall and the low confidencevalues for many technical terms.
In order to adaptthe module to the automotive domain, we imple-mented a domain-dependent extension to the de-compounding module on the basis of the devel-opment corpus.
This was done by first running thedecompounding module on the Dutch sentences toconstruct a list with possible compound heads, be-ing valid compound parts in Dutch.
This list wasupdated by inspecting the decompounding resultson the development corpus.
While decomposing,we go from right to left and strip off the longestvalid part that occurs in our preconstructed listwith compound parts and we repeat this processon the remaining part of the word until we reachthe beginning of the word.Table 4 shows the impact of the decompound-ing module, which is more prominent for shortand medium sentences than for long sentences.
Asuperficial error analysis revealed that long sen-tences combine a lot of other French ?
Dutchalignment difficulties next to the decompoundingproblem (e.g.
different word order and separableverbs).SHORT MEDIUM LONGp r e p r e p r eDutchno dec .95 .76 .16 .88 .67 .24 .88 .64 .26dec .96 .83 .11 .87 .73 .20 .87 .67 .24Table 4: Precision (p), recall (r) and alignment er-ror rate (e) for French-Dutch without and with de-compounding information4 Term extraction moduleAs described in Section 1, we generate candi-date terms from the aligned phrases.
We believethese anchor chunks offer a more flexible approach499because the method is language-pair independentand is not restricted to a predefined set of PoS pat-terns to identify valid candidate terms.
In a secondstep, we use a general-purpose corpus and the n-gram frequency of the automotive corpus to deter-mine the specificity of the candidate terms.The candidate terms are generated in severalsteps, as illustrated below for example (3).
(3) Fr: Tableau de commande de climatisation automa-tiqueEn: Automatic air conditioning control panel1.
Selection of all anchor chunks (minimalchunks that could be linked together) and lex-ical links within the anchor chunks:tableau de commande control panelclimatisation air conditioningcommande controltableau panel2.
combine each NP + PP chunk:commande de climatisa-tion automatiqueautomatic air condition-ing controltableau de commande declimatisation automatiqueautomatic air condition-ing control panel3.
strip off the adjectives from the anchorchunks:commande de climatisa-tionair conditioning controltableau de commande declimatisationair conditioning controlpanel4.1 Filtering candidate termsTo filter our candidate terms, we keep followingcriteria in mind:?
each entry in the extracted lexicon should re-fer to an object or action that is relevant forthe domain (notion of termhood that is usedto express ?the degree to which a linguis-tic unit is related to domain-specific context?
(Kageura and Umino, 1996))?
multiword terms should present a high de-gree of cohesiveness (notion of unithood thatexpresses the ?degree of strength or stabilityof syntagmatic combinations or collocations?
(Kageura and Umino, 1996))?
all term pairs should contain valid translationpairs (translation quality is also taken intoconsideration)To measure the termhood criterion and to fil-ter out general vocabulary words, we appliedLog-Likelihood filters on the French single-wordterms.
In order to filter on low unithood values,we calculated the Mutual Expectation Measure forthe multiword terms in both source and target lan-guage.4.1.1 Log-Likelihood MeasureThe Log-Likehood measure (LL) should allow usto detect single word terms that are distinctiveenough to be kept in our bilingual lexicon (Daille,1995).
This metric considers word frequenciesweighted over two different corpora (in our case atechnical automotive corpus and the more generalpurpose corpus ?Le Monde?1), in order to assignhigh LL-values to words having much higher orlower frequencies than expected.
We implementedthe formula for both the expected values and theLog-Likelihood values as described by (Raysonand Garside, 2000).Manual inspection of the Log-Likelihood fig-ures confirmed our hypothesis that more domain-specific terms in our corpus were assigned highLL-values.
We experimentally defined the thresh-old for Log-Likelihood values corresponding todistinctive terms on our development corpus.
Ex-ample (4) shows some translation pairs which arefiltered out by applying the LL threshold.
(4) Fr: cependant ?
En: however ?
It: tuttavia ?
Du:echterFr: choix ?
En: choice ?
It: scelta ?
Du: keuzeFr: continuer ?
En: continue ?
It: continuare ?
Du:verdergaanFr: cadre ?
En: frame ?
It: cornice ?
Du: frame(erroneous filtering)Fr: alle?gement ?
En: lightening ?
It: alleggerire ?Du: verlichten (erroneous filtering)4.1.2 Mutual Expectation MeasureThe Mutual Expectation measure as described byDias and Kaalep (2003) is used to measure thedegree of cohesiveness between words in a text.This way, candidate multiword terms whose com-ponents do not occur together more often than ex-pected by chance get filtered out.
In a first step,we have calculated all n-gram frequencies (up to8-grams) for our four automotive corpora and thenused these frequencies to derive the Normalised1http://catalog.elra.info/product info.php?products id=438500Expectation (NE) values for all multiword entries,as specified by the formula of Dias and Kaalep:NE =prob(n?
gram)1n?prob(n?
1?
grams)(3)The Normalised Expectation value expresses thecost, in terms of cohesiveness, of the possible lossof one word in an n-gram.
The higher the fre-quency of the n-1-grams, the smaller the NE, andthe smaller the chance that it is a valid multiwordexpression.
The final Mutual Expectation (ME)value is then obtained by multiplying the NE val-ues by the n-gram frequency.
This way, the Mu-tual Expectation between n words in a multiwordexpression is based on the Normalised Expecta-tion and the relative frequency of the n-gram inthe corpus.We calculated Mutual Expectation values for allcandidate multiword term pairs and filtered out in-complete or erroneous terms having ME values be-low an experimentally set threshold (being below0.005 for both source and target multiword or be-low 0.0002 for one of the two multiwords in thetranslation pair).
The following incomplete can-didate terms in example (5) were filtered out byapplying the ME filter:(5) Fr: fermeture embout - En: end closing - It:chiusura terminale - Du: afsluiting deel(should be: Fr: fermeture embout de brancard - En:chassis member end closing panel - It: chiusura ter-minale del longherone - Du: afsluiting voorste deelvan langsbalk)4.2 EvaluationThe terminology extraction module was tested onall sentences from the three test corpora.
The out-put was manually labeled and the annotators wereasked to judge both the translational quality of theentry (both languages should refer to the same ref-erential unit) as well as the relevance of the termin an automotive context.
Three labels were used:OK (valid entry), NOK (not a valid entry) andMAYBE (in case the annotator was not sure aboutthe relevance of the term).First, the impact of the statistical filtering wasmeasured on the bilingual term extraction.
Sec-ondly, we compared the output of our system withthe output of a commercial bilingual terminologyextraction module and with the output of a set ofstandard monolingual term extraction modules.Since the annotators labeled system output, thereported scores all refer to precision scores.
In fu-ture work, we will develop a gold standard corpuswhich will enable us to also calculate recall scores.4.2.1 Impact of filteringTable 5 shows the difference in performance forboth single and multiword terms with and with-out filtering.
Single-word filtering seems to have abigger impact on the results than multiword filter-ing.
This can be explained by the fact that our can-didate multiword terms are generated from anchorchunks (chunks aligned with a very high preci-sion) that already answer to strict syntactical con-straints.
The annotators also mentioned the diffi-culty of judging the relevance of single word termsfor the automotive domain (no clear distinction be-tween technical and common vocabulary).NOT FILTERED FILTEREDOK NOK MAY OK NOK MAYFR-ENSing w 82% 17% 1% 86.5% 12% 1.5%Mult w 81% 16.5% 2.5% 83% 14.5% 2.5%FR-ITSing w 80.5% 19% 0.5% 84.5% 15% 0.5%Mult w 69% 30% 1.0% 72% 27% 1.0%FR-DUSing w 72% 25% 3% 75% 22% 3%Mult w 83% 15% 2% 84% 14% 2%Table 5: Impact of statistical filters on Single andMultiword terminology extraction4.2.2 Comparison with bilingual terminologyextractionWe compared the three filtered bilingual lexi-cons (French versus English-Italian-Dutch) withthe output of a commercial state-of-the-art termi-nology extraction program SDL MultiTerm Ex-tract2.
MultiTerm is a statistically based systemthat first generates a list of candidate terms in thesource language (French in our case) and thenlooks for translations of these terms in the targetlanguage.
We ran MultiTerm with its default set-tings (default noise-silence threshold, default stop-word list, etc.)
on a large portion of our parallelcorpus that also contains all test sentences3.
Weran our system (where term extraction happens ona sentence per sentence basis) on the three testsets.2www.translationzone.com/en/products/sdlmultitermextract370,000 sentences seemed to be the maximum size ofthe corpus that could be easily processed within MultiTermExtract.501Table 6 shows that even after applying statisticalfilters, our term extraction module retains a muchhigher number of candidate terms than MultiTerm.# Extracted terms # Terms after filtering MultiTermFR-EN 4052 3386 1831FR-IT 4381 3601 1704FR-DU 3285 2662 1637Table 6: Number of terms before and after apply-ing Log-Likelihood and ME filtersTable 7 lists the results of both systems andshows the differences in performance for singleand multiword terms.
Following observations canbe made:?
The performance of both systems is compa-rable for the extraction of single word terms,but our system clearly outperforms Multi-Term when it comes to the extraction of morecomplex multiword terms.?
Although the alignment results for French-Italian were very good, we do not achievecomparable results for Italian multiword ex-traction.
This can be due to the fact that thesyntactic structure is very similar in both lan-guages.
As a result, smaller syntactic chunksare linked.
However one can argue that, justbecause of the syntactic resemblance of bothlanguages, the need for complex multiwordterms is less prominent in closely related lan-guages as translators can just paste smallernoun phrases together in the same order inboth languages.
If we take the following ex-ample for instance:de?poser ?
l?
embout ?
de brancardtogliere ?
il terminale ?
del sotto-portawe can recompose the larger compoundl?embout de brancard or il terminale del sot-toporta by translating the smaller parts in thesame order (l?embout ?
il terminale and debrancard ?
del sottoporta?
Despite the worse alignment results forDutch, we achieve good accuracy results onthe multiword term extraction.
Part of thatcan be explained by the fact that French andDutch use a different compounding strategy:whereas French compounds are created byconcatenating prepositional phrases, Dutchusually tends to concatenate noun phrases(even without inserting spaces between thedifferent compound parts).
This way we canextract larger Dutch chunks that correspondto several French chunks, for instance:Fr: feu re?gulateur ?
de pressioncarburant.Du: brandstofdrukregelaar.ANCHOR CHUNK APPROACH MULTITERMOK NOK MAY OK NOK MAYFR-ENSing w 86.5% 12% 1.5% 77% 21% 2%Mult w 83% 14.5% 2.5% 47% 51% 2%Total 84.5% 13.5% 2 % 64% 34% 2%FR-ITSing w 84.5% 15% 0.5% 85% 14% 1%Mult w 72% 27% 1.0% 65% 34% 1%Total 77.5% 22% 1% 76.5% 22.5% 1%FR-DUSing w 75% 22% 3% 64.5% 33% 2.5%Mult w 84% 14% 2% 49.5% 49.5% 1%Total 79.5% 20% 2.5% 58% 40% 2%Table 7: Precision figures for our term extractionsystem and for SDL MultiTerm Extract4.2.3 Comparison with monolingualterminology extractionIn order to have insights in the performance ofour terminology extraction module, without con-sidering the validity of the bilingual terminologypairs, we contrasted our extracted English termswith state-of-the art monolingual terminology sys-tems.
As we want to include both single words andmultiword terms in our technical automotive lex-icon, we only considered ATR systems which ex-tract both categories.
We used the implementationfor these systems from (Zhang et al, 2008) whichis freely available at1.We compared our system against 5 other ATRsystems:1.
Baseline system (Simple Term Frequency)2.
Weirdness algorithm (Ahmad et al, 2007)which compares term frequencies in the tar-get and reference corpora3.
C-value (Frantzi and Ananiadou, 1999)which uses term frequencies as well asunit-hood filters (to measure the collocationstrength of units)1http://www.dcs.shef.ac.uk/?ziqizhang/resources/tools/5024.
Glossex (Kozakov et al, 2004) which usesterm frequency information from both the tar-get and reference corpora and compares termfrequencies with frequencies of the multi-word components5.
TermExtractor (Sclano and Velardi, 2007)which is comparable to Glossex but intro-duces the ?domain consensus?
which ?sim-ulates the consensus that a term must gain ina community before being considered a rele-vant domain term?For all of the above algorithms, the input auto-motive corpus is PoS tagged and linguistic filters(selecting nouns and noun phrases) are applied toextract candidate terms.
In a second step, stop-words are removed and the same set of extractedcandidate terms (1105 single words and 1341 mul-tiwords) is ranked differently by each algorithm.To compare the performance of the ranking algo-rithms, we selected the top terms (300 single andmultiword terms) produced by all algorithms andcompared these with our top candidate terms thatare ranked by descending Log-likelihood (calcu-lated on the BNC corpus) and Mutual Expectationvalues.
Our filtered list of unique English automo-tive terms contains 1279 single words and 1879multiwords in total.
About 10% of the terms donot overlap between the two term lists.
All can-didate terms have been manually labeled by lin-guists.
Table 8 shows the results of this compari-son.SINGLE WORD TERMS MULTIWORD TERMSOK NOK MAY OK NOK MAYBaseline 80% 19.5% 0.5% 84.5% 14.5% 1%Weirdness 95.5% 3.5% 1% 96% 2.5% 1.5%C-value 80% 19.5% 0.5% 94% 5% 1%Glossex 94.5% 4.5% 1% 85.5% 14% 0.5%TermExtr.
85% 15% 0% 79% 20% 1%AC 85.5% 14.5% 0% 90% 8% 2%approachTable 8: Results for monolingual Term Extractionon the English part of the automotive corpusAlthough our term extraction module has been tai-lored towards bilingual term extraction, the resultslook competitive to monolingual state-of-the-artATR systems.
If we compare these results withour bilingual term extraction results, we can ob-serve that we gain more in performance for mul-tiwords than for single words, which might meanthat the filtering and ranking based on the MutualExpectation works better than the Log-Likelihoodranking.An error analysis of the results leads to the fol-lowing insights:?
All systems suffer from partial retrieval ofcomplex multiwords (e.g.
ATR managementecu instead of engine management ecu, ACapproach chassis leg end piece closure in-stead of chassis leg end piece closure panel).?
We manage to extract nice sets of multiwordsthat can be associated with a given concept,which could be nice for automatic ontologypopulation (e.g.
AC approach gearbox cas-ing, gearbox casing earth, gearbox casingearth cable, gearbox control, gearbox controlcables, gearbox cover, gearbox ecu, gearboxecu initialisation procedure, gearbox fixing,gearbox lower fixings, gearbox oil, gearboxoil cooler protective plug).?
Sometimes smaller compounds are not ex-tracted because they belong to the same syn-tactic chunk (E.g we extract passenger com-partment assembly, passenger compartmentsafety, passenger compartment side panel,etc.
but not passenger compartment as such).5 Conclusions and further workWe presented a bilingual terminology extractionmodule that starts from sub-sentential alignmentsin parallel corpora and applied it on three differ-ent parallel corpora that are part of the same auto-motive corpus.
Comparisons with standard termi-nology extraction programs show an improvementof up to 20% for bilingual terminology extractionand competitive results (85% to 90% accuracy) formonolingual terminology extraction.
In the nearfuture we want to experiment with other filteringtechniques, especially to measure the domain dis-tinctiveness of terms and work on a gold standardfor measuring recall next to accuracy.
We willalso investigate our approach on languages whichare more distant from each other (e.g.
French ?Swedish).AcknowledgmentsWe would like to thank PSA Peugeot Citroe?n forfunding this project.503ReferencesK.
Ahmad, L. Gillam, and L. Tostevin.
2007.
Uni-versity of surrey participation in trec8: Weirdnessindexing for logical document extrapolation andrerieval (wilder).
In Proceedings of the Eight TextREtrieval Conference (TREC-8).S.
Ananiadou.
1994.
A methodology for automaticterm recognition.
In Proceedings of the 15th con-ference on computational linguistics, pages 1034?1038.R.H.
Baayen, R. Piepenbrock, and H. van Rijn.
1993.The celex lexical database on cd-rom.I.
Dagan and K. Church.
1994.
Termight: identifyingand translating technical terminology.
In Proceed-ings of Applied Language Processing, pages 34?40.B.
Daille.
1995.
Study and implementation of com-bined techniques for automatic extraction of termi-nology.
In J. Klavans and P. Resnik, editors, TheBalancing Act: Combining Symbolic and StatisticalApproaches to Language, pages 49?66.
MIT Press,Cambridge, Massachusetts; London, England.G.
Dias and H. Kaalep.
2003.
Automatic extractionof multiword units for estonian: Phrasal verbs.
Lan-guages in Development, 41:81?91.K.T.
Frantzi and S. Ananiadou.
1999. the c-value/nc-value domain independent method for multiwordterm extraction.
journal of Natural Language Pro-cessing, 6(3):145?180.K.
Kageura and B. Umino.
1996.
Methods of au-tomatic term recognition: a review.
Terminology,3(2):259?289.L.
Kozakov, Y.
Park, T.-H Fin, Y. Drissi, Y.N.
Do-ganata, and T. Confino.
2004.
Glossary extractionand knowledge in large organisations via semanticweb technologies.
In Proceedings of the 6th Inter-national Semantic Web Conference and he 2nd AsianSemantic Web Conference (Se-mantic Web Chal-lenge Track).J.
Kupiec.
1993.
An algorithm for finding noun phrasecorrespondences in bilingual corpora.
In Proceed-ings of the 31st Annual Meeting of the Associationfor Computational Linguistics.L.
Macken and W. Daelemans.
2009.
Aligning lin-guistically motivated phrases.
In van Halteren H.Verberne, S. and P.-A.
Coppen, editors, Selected Pa-pers from the 18th Computational Linguistics in theNetherlands Meeting, pages 37?52, Nijmegen, TheNetherlands.L.
Macken, E. Lefever, and V. Hoste.
2008.Linguistically-based sub-sentential alignment forterminology extraction from a bilingual automotivecorpus.
In Proceedings of the 22nd InternationalConference on Computational Linguistics (Coling2008), pages 529?536, Manchester, United King-dom.R.
C. Moore.
2002.
Fast and accurate sentence align-ment of bilingual corpora.
In Proceedings of the 5thConference of the Association for Machine Trans-lation in the Americas, Machine Translation: fromresearch to real users, pages 135?244, Tiburon, Cal-ifornia.F.
J. Och and H. Ney.
2003.
A systematic comparisonof various statistical alignment models.
Computa-tional Linguistics, 29(1):19?51.P.
Rayson and R. Garside.
2000.
Comparing cor-pora using frequency profiling.
In Proceedings ofthe workshop on Comparing Corpora, 38th annualmeeting of the Association for Computational Lin-guistics (ACL 2000), pages 1?6.H.
Schmid.
1994.
Probabilistic part-of-speech taggingusing decision trees.
In International Conference onNew Methods in Language Processing, Manchester,UK.F.
Sclano and P. Velardi.
2007.
Termextractor: a webapplication to learn the shared terminology of emer-gent web communities.
In Proceedings of the 3rdInternational Conference on Interoperability for En-terprise Software and Applications (I-ESA 2007).A.
Van den Bosch, G.J.
Busser, W. Daelemans, andS.
Canisius.
2007.
An efficient memory-based mor-phosyntactic tagger and parser for dutch.
In SelectedPapers of the 17th Computational Linguistics in theNetherlands Meeting, pages 99?114, Leuven, Bel-gium.V.
Vandeghinste.
2008.
A Hybrid Modular MachineTranslation System.
LoRe-MT: Low Resources Ma-chine Translation.
Ph.D. thesis, Centre for Compu-tational Linguistics, KULeuven.Z.
Zhang, J. Iria, C. Brewster, and F. Ciravegna.
2008.A comparative evaluation of term recognition algo-rithms.
In Proceedings of the sixth internationalconference of Language Resources and Evaluation(LREC 2008).504
