Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 692?700,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsLarge tagset labeling using Feed Forward Neural Networks.
Casestudy on Romanian LanguageTiberiu Boro Radu Ion Dan TufiResearch Institute for$UWLILFLDO,QWHOOLJHQFH?0LKDLDrJQHVFX?Romanian AcademyResearch Institute for$UWLILFLDO,QWHOOLJHQFH?0LKDLDrJQHVFX?Romanian AcademyResearch Institute for$UWLILFLDO,QWHOOLJHQFH?0LKDLDrJQHVFX?Romanian Academytibi@racai.ro radu@racai.ro tufis@racai.roAbstractStandard methods for part-of-speech taggingsuffer from data sparseness when used onhighly inflectional languages (which requirelarge lexical tagset inventories).
For thisreason, a number of alternative methods havebeen proposed over the years.
One of themost successful methods used for this task,FDOOHG7LHUHG7DJJLQJ7XIL, 1999), exploitsa reduced set of tags derived by removingseveral recoverable features from the lexiconmorpho-syntactic descriptions.
A secondphase is aimed at recovering the full set ofmorpho-syntactic features.
In this paper wepresent an alternative method to TieredTagging, based on local optimizations withNeural Networks and we show how, byproperly encoding the input sequence in ageneral Neural Network architecture, weachieve results similar to the Tiered Taggingmethodology, significantly faster and withoutrequiring extensive linguistic knowledge asimplied by the previously mentioned method.1 IntroductionPart-of-speech tagging is a key process forvarious tasks such as `information extraction,text-to-speech synthesis, word sensedisambiguation and machine translation.
It is alsoknown as lexical ambiguity resolution and itrepresents the process of assigning a uniquelyinterpretable label to every word inside asentence.
The labels are called POS tags and theentire inventory of POS tags is called a tagset.There are several approaches to part-of-speechtagging, such as Hidden Markov Models (HMM)(Brants, 2000), Maximum Entropy Classifiers(Berger et al, 1996; Ratnaparkhi, 1996),Bayesian Networks (Samuelsson, 1993), NeuralNetworks (Marques and Lopes, 1996) andConditional Random Fields (CRF) (Lafferty etal., 2001).
All these methods are primarilyintended for English, which uses a relativelysmall tagset inventory, compared to highlyinflectional languages.
For the later mentionedlanguages, the lexicon tagsets (called morpho-syntactic descriptions (Calzolari and Monachini,1995) or MSDs) may be 10-20 times or evenlarger than the best known tagsets for English.For instance Czech MSD tagset requires morethan 3000 labels (Collins et al, 1999), Slovenemore than 2000 labels (Erjavec and Krek, 2008),and Romanian more than 1100 labels (Tufi,1999).
The standard tagging methods, using suchlarge tagsets, face serious data sparsenessproblems due to lack of statistical evidence,manifested by the non-robustness of the languagemodels.
When tagging new texts that are not inthe same domain as the training data, theaccuracy decreases significantly.
Even taggingin-domain texts may not be satisfactorilyaccurate.One of the most successful methods used forthis taVN FDOOHG 7LHUHG 7DJJLQJ 7XIL, 1999),exploits a reduced set of tags derived byremoving several recoverable features from thelexicon morpho-syntactic descriptions.According to the MULTEXT EAST lexicalspecifications (Erjavec and Monachini, 1997),the Romanian tagset consists of a number of 614MSD tags (by exploiting the case and genderregular syncretism) for wordforms and 10punctuation tags (Tufi et al, 1997), which isstill significantly larger than the tagset ofEnglish.
The MULTEX EAST version 4(Erjavec, 2010) contains specifications for a totalof 16 languages: Bulgarian, Croatian, Czech,Estonian, English, Hungarian, Romanian,692693In the case of out-of-vocabulary (OOV)words, both approaches use suffix analysis todetermine the most probable tags that can beassigned to the current word.To clarify how these two methods work, if wewant to train the network to label the currentword, using a context window of 1 (previous tag,current possible tags, and possible tags for thenext word) and if we have, say 100 tags in thetagset, the input is a real valued vector of 300sub-unit elements and the output is a vectorwhich contains 100 elements, also sub-unit realnumbers.
As mentioned earlier, each value in theoutput vector corresponds to a distinct tag fromtagset and the tag assigned to the current word ischosen to correspond to the maximum valueinside the output vector.The previously proposed methods still sufferfrom the same issue of data sparseness whenapplied to MSD tagging.
However, in ourapproach, we overcome the problem through adifferent encoding of the input data (see section2.1).The power of neural networks results mainlyfrom their ability to attain activation functionsover different patterns via their learningalgorithm.
By properly encoding the inputsequence, the network chooses which inputfeatures contribute in determining the outputfeatures for MSDs (e.g.
patterns composed ofpart of speech, gender, case, type etc.
contributeindependently in selecting the optimal outputsequence).
This way, we removed the need forexplicit MSD to CTAG conversion and MSDrecovery from CTAGs.2.1 The MSD binary encoding schemeA MSD language independently encodes a partof speech (POS) with the associated lexicalattribute values as a string of positional orderedcharacter codes (Erjavec, 2004).
The firstcharacter is an upper case character denoting theSDUWRIVSHHFKHJ?1?
IRUQRXQV?9?IRUYHUEV?$? IRU DGMHFWLYHV HWF DQG WKH IROORZLQJFKDUDFWHUV ORZHU OHWWHUV RU ?-?
specify theinstantiations of the characteristic lexicalattributes of the POS.
For example, the MSD?1FIVUQ? specifies a noun (the first character is?1?
 the type of ZKLFK LV FRPPRQ ?F? WKHsecond character), feminine gender ?I?
VLQJXODUnumber ?V?
 LQQRPLQDWLYHDFFXVDWLYHFDVH?U?
and indefinite form ?Q?
If a specific attribute isnot relevant for a language, or for a givencombination of feature-YDOXHVWKHFKDUDFWHU?-?LVused in the corresponding position.
For alanguage which does not morphologically markthe gender and definiteness features, the earlierH[HPSOLILHG06'ZLOOEHHQFRGHGDV?1F-sr-?In order to derive a binary vector for each ofthe 614 MSDs of Romanian we proceeded to:1.
List and sort all possible POSes ofRomanian (16 POSes) and form a binaryvector with 16 positions in which position kis equal 1 only if the respective MSD hasthe corresponding POS (i.e.
the k-th POS inthe sorted list of POSes);2.
List and sort all possible values of all lexicalattributes GLVUHJDUGLQJWKHZLOGFDUG?-?
forall POSes (94 values) and form anotherbinary vector with 94 positions such that thek-th position of this vector is 1 if therespective MSD has an attribute with thecorresponding value;3.
Concatenate the vectors from steps 1 and 2and obtain the binary codification of a MSDas a 110-position binary vector.2.2 The training and tagging procedureThe tagger automatically assigns four dummytokens (two at the beginning and two at the end)to the target utterance and the neural network istrained to automatically assign a MSD given thecontext (two previously assigned tags and thepossible tags for the current and following twowords) of the current word (see below fordetails).In our framework a training example consistsof the features extracted for a single word insidean utterance as input and it?s MSD within thatutterance as output.
The features are extractedfrom a window of 5 words centered on thecurrent word.
A single word is characterized by avector that encodes either its assigned MSD or itspossible MSDs.
To encode the possible MSDswe use equation 2, where each possible attributea, has a single corresponding position inside theencoded vector.2:=S; L %:S?=;%:S;  (2)Note that we changed the probabilityestimates to account for attributes not tags.To be precise, for every word wk, we obtain itsinput features by concatenating a number of 5vectors.
The first two vectors encode the MSDsassigned to the previous two words (wk-1 and wk-6942).The next three vectors are used to encode thepossible MSDs for the current word (wk) and thefollowing two words (wk+1 and wk+2).During training, we also compute a list ofsuffixes with associated MSDs, which is used atrun-time to build the possible MSDs vector forunknown words.
When such words are foundwithin the test data, we approximate theirpossible MSDs vector using a variation of themethod proposed by Brants (2000).When the tagger is applied to a new utterance,the system iteratively calculates the output MSDfor each individual word.
Once a label has beenassigned to a word, the ZRUG?VDVVRFLDWHGYHFWRUis edited so it will have the value of 1 for eachattribute present in its newly assigned MSD.As a consequence of encoding each individualattribute separately for MSDs, the tagger canassign new tags (that were never associated withthe current word in the training corpus).Although this is a nice behavior for dealing withunknown words it is often the case that it assignsattribute values that are not valid for thewordform.
To overcome these types of errors weuse an additional list of words with their allowedMSDs.
For an OOV word, the list is computed asa union from all MSDs that appeared with thesuffixes that apply to that word.When the tagger has to assign a MSD to agiven word, it selects one from the possiblewordform?V MSDs in its wordform/MSDsassociated list using a simple distance function:???????
K?
F A???
@4(3)2 - The list of all possible MSDs for the given wordJ - The length of the MSDencoding (110 bits)K - The output of the Neural Network for the current wordA - Binary encoding for a MSD in P3 Network hyperparametersIn our experiments, we used a fully connected,feed forward neural network with 3 layers (1input layer, 1 hidden layer and 1 output layer)and a sigmoid activation function (equation 3).While other network architectures such asrecurrent neural networks may prove to be moresuitable for this task, they are extremely hard totrain, thus, we traded the advantages of sucharchitectures for the robustness and simplicity ofthe feed-forward networks.B:P; L ssE A??
(3)B:P; - Neuron outputP -The weighted sum of all theneuron outputs from theprevious layerBased on the size of the vectors used for MSDencoding, the output layer has 110 neurons andthe input layer is composed of 550 (5 x 110)neurons.In order to fully characterize our system, wetook into account the following parameters:accuracy, runtime speed, training speed, hiddenlayer configuration and the number of optimaltraining iterations.
These parameters havecomplex dependencies and relations among eachother.
For example, the accuracy, the optimalnumber of training iterations, the training and theruntime speed are all highly dependent on thehidden layer configuration.
Small hidden layergive high training and runtime speeds, but oftenunder-fit the data.
If the hidden layer is too large,it can easily over-fit the data and also has anegative impact on the training and runtimespeed.
The number of optimal training iterationschanges with the size of the hidden layer (largerlayers usually require more training iterations).To obtain the trade-offs between the abovementioned parameters we devised a series ofexperiments, in all of which we used WKH??MSD annotated corpus, which is composed of118,025 words.
We randomly kept outapproximately 1/10 (11,960 words) of thetraining corpus for building a cross-validationset.
The baseline accuracy on the cross-validationset (i.e.
returning the most probable tag) is93.29%.
We also used an additional inflectionalwordform/MSD lexicon composed ofapproximately 1 million hand-validated entries.695The first experiment was designed todetermine the trade-off between the run-timespeed and the size of the hidden layer.
We madea series of experiments disregarding the taggingaccuracy.Hidden size Time (ms) Words/sec50 1530 781670 1888 633490 2345 5100110 2781 4300130 3518 3399150 5052 2367170 5466 2188190 6734 1776210 7096 1685230 8332 1435250 9576 1248270 10350 1155290 11080 1079310 12364 967Table 1 - Execution time vs. number of neurons onthe hidden layerBecause, for a given number of neurons in thehidden layer, the tagging speed is independent onthe tagging accuracy, we partially trained (usingone iteration and only 1000 training sentences)several network configurations.
The first networkonly had 50 neurons in the hidden layer and forthe next networks, we incremented the hiddenlayer size by 20 neurons until we reached 310neurons.
The total number of tested networks is14.
After this, we measured the time it took totag the 1984 test corpus (11,960 words) for eachindividual network, as an average of 3 taggingruns in order to reduce the impact of theoperating system load on the tagger (Table 1shows the figures).Determining the optimal size of the hiddenlayer is a very delicate subject and there are noperfect solutions, most of them being based ontrial and error: small-sized hidden layers lead tounder-fitting, while large hidden layers usuallycause over-fitting.
Also, because of the trade-offbetween runtime speed and the size of hiddenlayers, and if runtime speed is an importantfactor in a particular NLP application, thenhidden layers with smaller number of neurons arepreferable, as they surely do not over-fit the dataand offer a noticeable speed boost.hiddenlayerTrain setaccuracyCrossvalidationaccuracy50 99.18 97.9570 99.20 98.0290 99.27 98.03110 99.29 98.05130 99.35 98.12150 99.35 98.09170 99.41 98.07190 99.40 98.10210 99.40 98.21Table 2 - Train and test accuracy rates for differenthidden layer configurationsAs shown in Table 1, the runtime speed of oursystem shows a constant decay when we increasethe hidden layer size.
The same decay can beseen in the training speed, only this time by anorder of magnitude larger.
Because training asingle network takes a lot of time, thisexperiment was designed to estimate the size ofthe hidden layer which offers good performancein tagging.
To do this, we individually trained anumber of networks in 30 iterations, usingvarious hidden layer configurations (50, 70, 90,0.970.9750.980.9850.990.99511 5 9 13 17 21 25 29 33 37 41 45 49 53 57 61 65 69 73 77 81 85 89 93 97Test setTrain setNumber of iterrationsAccuracyFigure 2 - 130 hidden layer network test and train set tagging accuracy as a function of the number of iterations696110, 130, 150, 170, 190, and 210 neurons) and 5initial random initializations of the weights.
Foreach configuration, we stored the accuracy ofreproducing the learning data (the tagging of thetraining corpus) and the accuracy on the unseendata (test sets).
The results are shown in Table 2.Although a hidden layer of 210 neurons did notseem to over-fit the data, we stopped theexperiment, as the training time got significantlylonger.The next experiment was designed to see howthe number of training iterations influences thetagging performance of networks with differenthidden layer configurations.
Intuitively, thetraining process must be stopped when thenetwork begins to over-fit the data (i.e.
the trainset accuracy increases, but the test set accuracydrops).
Our experiments indicate that this is notalways the case, as in some situations thecontinuation of the training process leads tobetter results on the cross-validation data (asshown in Figure 2).
So, the problem comes todetermining which is the most stableconfiguration of the neural network (i.e.
whichhidden unit size will be most likely to returngood results on the test set) and establish thenumber of iterations it takes for the system to betrained.
To do this, we ran the training procedurefor 100 iterations and for each training iteration,we computed the accuracy rate of everyindividual network on the cross-validation set(see Table 3 for the averaged values).
As shown,the network configuration using 130 neurons onthe hidden layer is most likely to produce betterresults on the cross-validation set regardless ofthe number of iterations.Although, some other configurations providedbetter figures for the maximum accuracy, theiraverage accuracy is lower than that of the 130hidden unit network.
Other good candidates arethe 90 and 110 hidden unit networks, but not thelarger valued ones, which display a loweraverage accuracy and also significantly slowertagging speeds.The most suitable network configuration for agiven task depends on the language, MSDencoding size, speed and accuracy requirements.In our own daily applications we use the 130hidden unit network.
After observing thebehavior of the various networks on the cross-validation set we determined that a good choiceis to stop the training procedure after 40iterations.Hiddenunits Avg.
acc.
Max.
acc.
St. dev.50 97.94 98.31 0.12700270 98.03 98.31 0.1219750 97.94 98.37 0.13976270 98.03 98.43 0.12499690 98.07 98.39 0.134487110 98.08 98.45 0.127109130 98.14 98.44 0.136072150 98.01 98.36 0.143324170 97.94 98.36 0.122834Table 3 - Average and maximum accuracy for varioushidden layer configuration calculated over 100training iterations on the test setTo obtain the accuracy of the system, in ourlast experiment we used the 130 hidden unitnetwork and we performed the training/testingprocedure on the 1984 corpus, using 10-foldvalidation and 30 random initializations.
Thefinal accuracy was computed as an averagebetween all the accuracy figures measured at theend of the training process (after 40 iterations).The first 1/10 of the 1984 corpus on which wetuned the hyperparameters was not included inthe test data, but was used for training.
The meanaccuracy of the system (98.41%) was measuredas an average of 270 values.4 Comparison to other methods,Q KLV ZRUN &HDXu (2006) presents adifferent approach to MSD tagging using theMaximum Entropy framework.
He presents hisresults on the same corpus we used for trainingand testing (the 1984 corpus) and he compareshis method (98.45% accuracy) with the TieredTagging methodology (97.50%) (Tufi andDragomirescu, 2004).Our Neural Network approach obtainedsimilar (slightly lower) results (98.41%),although it is arguable that our split/trainprocedure is not identical to the one used in hiswork (no details were given as how the 1/10 ofthe training corpus was selected).
Also, our POStagger detected cases where the annotation in theGold Standard was erroneous.
One such exampleLV LQ ?lame de ras? (QJOLVK ?UD]RU EODGHV?
ZKHUH?ODPH?English ?EODGHV?
LVDQRXQ?GH??for?
LVDSUHSRVLWLRQDQG?UDV??VKDYLQJ?)
is asupine verb (with a past participle form) whichwas incorrectly annotated as a noun.6975 Network pattern analysisUsing feed-forward neural networks gives theability to outline what input features contribute tothe selection of various MSD attribute values inthe output layer which might help in reducing thetagset and thus, redesigning the networktopology with beneficial effects both on thespeed and accuracy.To determine what input features contribute tothe selection of certain MSD attribute values, onecan analyze the weights inside the neuralnetwork and extract the input ?
output links thatare formed during training.
We used the networkwith 130 units on the hidden layer, which waspreviously trained for 100 iterations.
Based onthe input encoding, we divided the features into 5groups (one group for each MSD inside the localcontext ?
two previous MSDs, current andfollowing two possible MSDs).
For a targetattribute value (noun, gender feminine, gendermasculine, etc.)
and for each input group, weselected the top 3 input values which support thedecision of assigning the target value to theattribute (features that increase the output value)and the top 3 features which discourage thisdecision (features that decrease the output value).For clarity, we will use the following notationsfor the groups:x G-2: group one ?
the assigned MSD forthe word at position i-2x G-1: group two ?
the assigned MSD forthe word at position i-1x G0: group three ?
the possible MSDs forthe word at position ix G1: group four?
the possible MSDs forthe word at position i+1x G2: group five ?
the possible MSDs forthe word at position i+2where i corresponds to the position of the wordwhich is currently being tagged.
Also, weclassify the attribute values into two categories(C): (P) want to see (support the decision) and(N) GRQ?WZDQWWRVHH (discourage the decision).Table 4 shows partial (G-1 G0 G1) examples oftwo target attribute values (cat=Noun and gender=Feminine) and their corresponding inputfeatures used for discrimination.Targetvalue Group C Attribute valuesNoun G-1 Pmain (of a verb), article,masculine (gender of anoun/adjectiveNparticle, conjunctive particle,auxiliary (of a verb),demonstrative (of a pronoun)G0P noun, common/proper (of anoun)Nadverb, pronoun, numeral,interrogative/relative (of apronoun)G1Pgenitive/dative (of anoun/adjective), particle,punctuationNconjunctive particle, strong (ofa pronoun), non-definite (of anoun/adjective), exclamationmarkFem.G-1Pmain (of a verb), preposition,feminine (of anoun/adjective)N auxiliary (of a verb), particle, demonstrative (of a pronoun)G0Pfeminine (of anoun/adjective),nominative/accusative (of anoun/adjective), past (of averb)Nmasculine (of anoun/adjective), auxiliary (of averb), interrogative/relative (ofa pronoun), adverbG1Pdative/genitive (of anoun/adjective), indicative (ofa verb), feminine (of anoun/adjective)Nconjunctive particle, futureparticle, nominative/accusative(of a noun/adjective)Table 4 ?
P/N features for various attributevalues.For instance, when deciding on whether to give anoun (N) label to current position (G0), we cansee that the neural network has learned someinteresting dependencies: at position G-1 we findan article (which frequently determines a noun)and at the current position it is very important forthe word being tagged to actually be a commonor proper noun (either by lexicon lookup or bysuffix guessing) and not be an adverb, pronounor numeral (POSes that cannot be found in thetypical ambiguity class of a noun).
At the nextposition of the target (G1) we also find a noun ingenitive or dative, corresponding to a frequentconstruction in Romanian, HJ ?PDinaELDWXOXL? EHLQJ D VHTXHQFH RI WZR nouns, thesecond at genitive/dative.If the neural network outputs the femininegender to its current MSD, one may see that it698has actually learned the agreement rules (at leastlocally): the feminine gender is present bothbefore (G-1) the target word as well as after it(G1).6 Conclusions and future workWe presented a new approach for large tagsetpart-of-speech tagging using neural networks.
Anadvantage of using this methodology is that itdoes not require extensive knowledge about thegrammar of the target language.
When building anew MSD tagger for a new language one is onlyrequired to provide the training data and createan appropriate MSD encoding system and asshown, the MSD encoding algorithm is fairlysimple and our proposed version works for anyother MSD compatible encoding, regardless ofthe language.Observing which features do not participate inany decision helps design custom topologies forthe Neural Network, and provides enhancementsin both speed and accuracy.
The configurablenature of our system allows users to provide theirown MSD encodings, which permits them tomask certain features that are not useful for agiven NLP application.If one wants to process a large amount of textand is interested only in assigning grammaticalcategories to words, he can use a MSD encodingin which he strips off all unnecessary features.Thus, the number of necessary neurons woulddecrease, which assures faster training andtagging.
This is of course possible in any othertagging approaches, but our framework supportsthis by masking attributes inside the MSDencoding configuration file, without having tochange anything else in the training corpus.During testing the system only verifies if theMSD encodings are identical and the displayedaccuracy directly reflects the performance of thesystem on the simplified tagging schema.We also proposed a methodology for selectinga network configurations (i.e.
number of hiddenunits), which best suites the applicationrequirements.
In our daily applications we use anetwork with 130 hidden units, as it provides anoptimal speed/accuracy trade-off (approx.
3400words per second with very good averageaccuracy).The tagger is implemented as part of a largerapplication that is primarily intended for text-to-speech (TTS) synthesis.
The system is free fornon-commercial use and we provide both weband desktop user-interfaces.
It is part of theMETASHARE platform and available online 2 .Our primary goal was to keep the systemlanguage independent, thus all our design choicesare based on the necessity to avoid usinglanguage specific knowledge, when possible.
Theapplication supports various NLP related taskssuch as lexical stress prediction, syllabification,letter-to-sound conversion, lemmatization,diacritic restoration, prosody prediction from textand the speech synthesizer uses unit-selection.From the tagging perspective, our future plansinclude testing the system on other highlyinflectional languages such as Czech andSlovene and investigating different methods forautomatically determining a more suitablecustom network topology, such as geneticalgorithms.AcknowledgmentsThe work reported here was funded by theproject METANET4U by the EuropeanCommission under the Grant Agreement No2708932http://ws.racai.ro:9191699ReferencesBerger, A. L., Pietra, V. J. D. and Pietra, S. A. D.1996.
A maximum entropy approach to naturallanguage processing.
Computational linguistics,22(1), 39-71.Brants, T. 2000.
TnT: a statistical part-of-speechtagger.
In Proceedings of the sixth conference onapplied natural language processing (pp.
224-231).Association for Computational Linguistics.Calzolari, N. and Monachini M.
(eds.).
1995.Common Specifications and Notation for LexiconEncoding and Preliminary Proposal for theTagsets.
MULTEXT Report, March.&HDXu, A.
2006.
Maximum entropy tiered tagging.
InProceedings of the 11th ESSLLI Student Session(pp.
173-179).CollinV05DPVKDZ/+DML?-DQG7LOOPDQQ&1999.
A statistical parser for Czech.
In Proceedingsof the 37th annual meeting of the Association forComputational Linguistics on ComputationalLinguistics (pp.
505-512).
Association forComputational Linguistics.Erjavec, T. and Monachini, M.
(Eds.).
1997.Specifications and Notation for Lexicon Encoding.Deliverable D1.1 F. Multext-East Project COP-106.Erjavec, T. 2004.
MULTEXT-East version 3:Multilingual morphosyntactic specifications,lexicons and corpora.
In Fourth InternationalConference on Language Resources andEvaluation, LREC (Vol.
4, pp.
1535-1538).Erjavec, T. and Krek, S. 2008.
The JOSmorphosyntactically tagged corpus of Slovene.
InProceedings of the Sixth International ConferenceRQ/DQJXDJH5HVRXUFHVDQG(YDOXDWLRQ/5(&?Erjavec, T. 2010.
MULTEXT-East Version 4:Multilingual Morphosyntactic Specifications,Lexicons and Corpora.
In Proceedings of theSeventh International Conference on LanguageResources and Evaluation (LREC'10), Valletta,Malta.
European Language Resources Association(ELRA) ISBN 2-9517408-6-7.Lafferty, J., McCallum, A. and Pereira, F. C. 2001.Conditional random fields: Probabilistic modelsfor segmenting and labeling sequence data.Marques, N. C. and Lopes, G. P. 1996.
A neuralnetwork approach to part-of-speech tagging.
InProceedings of the 2nd Meeting for ComputationalProcessing of Spoken and Written Portuguese (pp.21-22).Ratnaparkhi, A.
1996.
A maximum entropy model forpart-of-speech tagging.
In Proceedings of theconference on empirical methods in naturallanguage processing (Vol.
1, pp.
133-142).Samuelsson, C. 1993.
Morphological tagging basedentirely on Bayesian inference.
In 9th NordicConference on Computational Linguistics.Schmid, H. 1994.
Part-of-speech tagging with neuralnetworks.
In Proceedings of the 15th conference onComputational linguistics-Volume 1 (pp.
172-176).Association for Computational Linguistics.Tufi, D., Barbu A.M.,3WUD?FX 9 Rotariu G. andPopescu C. 1997.
Corpora and Corpus-BasedMorpho-Lexical Processing.
In Recent Advancesin Romanian Language Technology, (pp.
35-56).Romanian Academy Publishing House, ISBN 973-27-0626-0.7XIL, D. 1999.
Tiered tagging and combinedlanguage models classifiers.
In Text, Speech andDialogue (pp.
843-843).
SpringerBerlin/Heidelberg.Tufi, D., and Dragomirescu, L. 2004.
Tiered taggingrevisited.
In Proceedings of the 4th LRECConference (pp.
39-42).700
