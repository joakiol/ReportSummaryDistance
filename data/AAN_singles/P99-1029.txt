Using Mutual Information to Resolve Query TranslationAmbiguities and Query Term Weighting1 Myung-Gil Jang, 2 Sung Hyon Myaeng and 1 Se Young Park1 Dept.
of Knowledge Information, Electronicsand Telecommunications Research Institute161 Kajong-Dong, Yusong-Gu,Taejon, Korea 305-350{ mgjang, sypark } @etri.re.kr2 Dept.
of Computer Science,Chungnam National University220 Gung-Dong, Yusong-Gu,Taejon, Korea 305-764shmyaeng@cs.chungnam.ac.krAbstractAn easy way of translating queries in onelanguage to the other for cross-languageinformation retrieval (IR) is to use a simplebilingual dictionary.
Because of the general-purpose nature of such dictionaries, however,this simple method yields a severetranslation ambiguity problem.
This paperdescribes the degree to which this problemarises in Korean-English cross-language IRand suggests a relatively simple yet effectivemethod for disambiguation using mutualinformation statistics obtained only from thetarget document collection.
In this method,mutual information is used not only to selectthe best candidate but also to assign a weightto query terms in the target language.
Ourexperimental results based on the TREC-6collection shows that this method canachieve up to 85% of the monolingualretrieval case and 96% of the manualdisambiguation case.IntroductionCross-language information retrieval (IR)enables a user to retrieve documents written indiverse languages using queries expressed in hisor her own language.
For cross-language IR,either queries or documents are translated toovercome the language differences.
Although itis possible to apply a high-quality machinetranslation system for documents as in Oard &Hackett (1997), query translation has emerged asa more popular method because it is muchsimpler and more economical compared todocument translation.
Query translation can bedone in one or more of the three approaches: adictionary-based approach, a thesaurus-basedapproach, or a corpus-based approach.There are three problems that a cross-languageIR system using a query translation method mustsolve (Grefenstette, 1998).
The first problem isto figure out how a term expressed in onelanguage might be written in another.
Thesecond problem is to determine which of thepossible translations hould be retained.
Thethird problem is to determine how to properlyweight the importance of translation alternativeswhen more than one is retained.For cross-language IR between Korean andEnglish, i.e.
between Korean queries and Englishdocuments, an easy way to handle query, translation is to use a Korean-English machine-readable dictionary (MRD) because suchbilingual MRDs are more widely available thanother resources such as parallel corpora.However, it has been known that with a simpleuse of bilingual dictionaries in other languagepairs, retrieval effectiveness can be only 40%-60% of that with monolingual retrieval(Ballesteros & Croft, 1997).
It is obvious thatother additional resources need to be used forbetter performance.This paper focuses on the last two problems:pruning translations and calculating the weightsfor translation alternatives.
We first describe theoverall query translation process and the extentto which the ambiguity problem arises inKorean-English cross-language IR.
We thenpropose a relatively simple yet effective methodfor resolving translation disambiguation usingmutual information (MI) (Church and Hanks,1990) statistics obtained only from the targetdocument collection.
In this method, mutual223information is used not only to select the bestcandidate but also to assign a weight to queryterms in the target language.1 Overall Query Translation ProcessOur Korean-to-English query translation schemeworks in four stages: keyword selection,dictionary-based query translation, bilingualword sense disambiguation, and query termweighting.
Although none of the commonresources such as dictionaries, thesauri, andcorpora alone is complete enough to producehigh quality English queries, we decided to use abilingual dictionary at the second stage and atarget-language corpus for the third and thefourth stages.
Our strategy was to try not todepend on scarce resources to make theapproach practical.
Figure 1 shows the fourstages of Korean-to-English query translation.KoreanQueryKorean-to-English \[Query TranslationKeywordSelectionEnglishQueryTQuery Term IBilingual Word IDisambiguation\[ Dictionary-Based 1Query TranslationFig.
1.
Four Stages for Korean-to-English QueryTranslation.1.1 Keyword SelectionAt the first stage, Korean keywords to be fedinto the query translation process are extractedfrom a quasi-natural anguage query.
Thiskeyword selection is done with a morphologicalanalyzer and a stochastic part-of-speech (POS)tagger for the Korean language (Shin et al,1996).
The role of the tagger is to help select heexact morpheme sequence from the multiplecandidate sequences generated by themorphological analysis.
This process ofemploying amorphological nalysis and a taggeris crucial for selecting legitimate query wordsfrom the topic statements because Korean is anagglutinative language.
Without the tagger, allthe extraneous candidate keywords generatedfrom the morphological nalyzer will have to beentered into the translation process, which in andof itself will generate xtraneous words, due toone-to-many mapping in the bilingualdictionary.1.2 Dictionary-Based Query TranslationThe second stage does the actual querytranslation based on a dictionary look-up, byapplying both word-by-word translation andphrase-level translation.
For the correctidentification of phrases in a Korean query, itwould help to identify the lexical relations andproduce statistical information on pairs of wordsin a text corpus as in Smadja (1993).
Since thebilingual dictionary lacks some words that areessential for a correct interpretation of theKorean query, it is important to identifyunknown words such as foreign words andtransliterate hem into English strings that needto be matched against an English dictionary(Jeong et al, 1997).1.3 Selection of the Correct TranslationsAt the word disambiguation stage, we filter outthe extraneous words generated blindly from thedictionary lookup process.
In addition to thePOS tagger, we employed a bilingual worddisambiguation technique using the co-occurrence information extracted from thecollection of target documents.
More specifically,The mutual information statistics between pairsof words were used to determine whetherEnglish words from different sets generated bythe translation process are "compatible".
In asense, we make use of mutual disambiguationeffect among query terms.
More details aredescribed in Section 3.1.4 Query Term WeightingFinally, we apply our query term weightingtechnique to produce the final target query.
Theterm weighting scheme basically reflects thedegree of associations between the translatedterms, and we give a high or low term weightingvalue according to the degree of mutualassociation between query terms.
This is anotherarea where we make use of mutual informationobtained from a text corpus.
The result from thefour stages is a set of query terms to be used in a224vector-space r trieval model.2 Analysis of Translation AmbiguityAlthough an easy way to find translations ofquery terms is to use a bilingual dictionary, thismethod alone suffers from problems caused bytranslation ambiguity since there are often one-to-many correspondences in a bilingualdictionary.
For example, in a Korean queryconsisting of three words, ":Z\]-o--~-5~\]- -~7\]_Q_~"(ja-dong-cha gong-gi oh-yum) that meansair pollution caused by automobiles, each wordcan be translated into multiple English wordswhen a Korean-English dictionary is used in astraightforward way.
The first word ":Z\]-o-~-5~\]-"(ja-dong-cha) of the query can be translated intoEnglish words with semantically similar butdifferent words like "motorcar", "automobile",and "car".
The second word "--~-71" (gong-gi), ahomonymous word, can be translated intoEnglish words with different meanings: "air","atmosphere", empty vessel", and "bowl".
Andthe last word "_9--4" (oh-yum) can be translatedinto two English words, "pollution" and"contamination".Retaining multiple candidate words can beuseful in promoting recall in monolingual IRsystem, but previous research indicates thatfailure to disambiguate the meanings of thewords can hurt retrieval effectivenesstremendously.
For instance, it is obvious that aphrase like empty vessel would change themeaning of the query entirely.
Even a word likecontamination, a synonym of pollution, may endup retrieving unrelated documents due to theslight differences in meaning.TitleSho~LongTable 1.
The De~ree of AmbiguitiesI \[W?rds I W?rd Pairs # in S. # in T. Average # in S. # in T. Average Lan.
Lang.
Ambiguity Lan.
Lang.
Ambiguity48 158 I 3.29 \[ 29i 3212 8.83 112 447 3.99 1459 16.03462 1835 3.97 6196 14.65Table 1 shows the extent to which ambiguityoccurs in our query translation when an English-Korean dictionary is used blindly after themorphological analysis and tagging.
The threerows, title, short, and long, indicate threedifferent ways of composing queries from thetopic statements in the TREC collection.
The lefthalf shows the average number of English wordsper Korean word for each query, whereas theright half shows the average number of wordpairs in English that can be formed from a singleword pair in Korean.
The latter indicates that thedisambiguation process will have to select oneout of more than 9 possible pairs on the average,regardless of which part of the topic statementsis used for formal query generation.3 Query Translation and MutualInformationOur strategy for cross-language IR aims atpracticality in that we try not to depend onscarce resources.
Along the same line ofreasoning, we opted for a disambiguationapproach that requires only a collection ofdocuments in the target language, which isalways available in any cross-language IRenvironment.
Since the goal of disambiguation isto select the best pair among many alternativesas described above, the mutual informationstatistic is a natural choice in judging the degreeto which two words co-occur within a certaintext boundary.
It would be reasonable to choosethe pair of words that are most stronglyassociated with each other, thereby eliminatingthose translations that are not likely to be correctones.Mutual information values are calculated basedon word co-occurrence statistics and used as ameasure to calculate correlation between words.The mutual information Ml(x,y) is defined as thefollowing formula (Church and Hanks, 1990).p(x, y) N fw(X, y ) MI(x, y) = log 2 = log z (1)p(x)p(y) f (x ) f (y )Here x and y are words occurring within awindow of w words.The probabilities p(x) and p(y) are estimated bycounting the number of observations of x and yin a corpus, f(x) and fly), and normalizing eachby N, the size of the corpus.
Joint probabilities,p(x,y), are estimated by counting the number oftimes, f,(x,y), that x is followed by y in awindow of w words and normalizing it by N. Inour application of query translation, the joint co-occurrence frequency f,(x,y) has 6-word windowsize which seems to allow semantic relations ofquery as well as fixed expressions (idioms such225as bread and butter).
We ensure that the word xbe followed by the word y within the samesentence only.In our query translation scheme, MI values areused to select most likely translations after eachKorean query word is translated into one ormore English words.
Our use of MI values isbased on the assumption that when two wordsco-occur in the same query, they are likely to co-occur in the same affinity in documents.Conversely, two words that do not co-occur inthe same affinity are not likely to show up in thesame query.
In a sense, we are conjecturingmutual information can reveal some degree ofsemantic association between words.Table 2 gives some examples of MI values forthe alternative word pairs for translated queriesof TREC-6 Cross-Language IR Track.
These MIvalues were extracted from the English textcorpus consisting of 1988 - 1990 AP news,which contains 116,759,540 words.Table 2.
ExamWord x Word yrespiratory ailmentteddy bearfossil fuelair pollutionresearch developmentAIDS spreadivory tradeenvironment protectionbear dollregion countrypoint interestlaw terrorismtreatment resultterrorism governmentopinion newsfood lifecopy pricelabor information)le of Ml(x, Valuesfix) fiy) fix,y) I Ml(x,y)716 1134 74 9.272506679 7932 262 8.644690676 13176 333 8.38142452216 4878 890 6.01121424278 24213 1317 5.56676818575 10199 212 4.8725971885 86608 84 4.0956137771 13139 36 3.7176527932 1394 3 3.45564621093 103833 358 2.94892530419 51917 107 2.06823270182 4762 20 1.94408913432 38055 22 1.6144874762 193977 29 1.2990059124 82220 21 1.18433232222 40625 30 0.9842816803 90594 10 0.63895026571 30245 11 0.468861When Ml(x,y) is large, the word associations arestrong and produce credible results fordisambiguation of translations.
However, ifMl(x,y) < 0, we can predict that the word x andword y are in complementary distribution.4 Disambiguation and WeightCalculationWe can alleviate the translation ambiguity bydiscriminating against hose word pairs with lowMI values.
The word pair with the highest MIvalue is considered to be the correct one amongall the candidates in the two sets.
Since a queryis likely to be targeted at a single concept,regardless of how broad or narrow it is, weconjecture that words describing the concept arelikely to have a high degree of association.Although we use the mutual information statisticto measure the association, others such as thoseused by Ballesteros & Croft (1998) can beconsidered.In the example of Section 2, each Korean wordhas multiple English words due to translationambiguity.
Figure 2 shows the MI valuescalculated for the word pairs comprising thetranslations of the original query.
The wordsunder wl, w2, and w3 are the translations fromthe three query words, respectively.
The linesindicate that mutual information values areavailable for the pairs, and the numbers showsome of the significant MI values for thecorresponding pairs among all the possible pairs.wl w2 w3bowlFig.
2.
An Example of Word Pairs with MIValuesOur bilingual word disambiguation andweighting schemes rely on both relative andabsolute magnitudes of the MI vales.
Thealgorithm first looks for the pair with the highestMI value and selects the best candidates beforeand after the pair by comparing the MI valuesfor the pairs that are connected with the initiallychosen pairs.
This process is applied to thewords immediately before or after the chosenpair in order to limit the effect of the choice thatmay be incorrect.It should be noted that the words not chosen inthis process are not used in the translated queryunless the MI values are greater than a threshold.As described below, we assume that thecandidates not in the first tier may still be usefulif they are strongly associated with the adjacentword selected.226For example, the word pair <air, pollution> thathas the bold line representing the strongestassociation in the column is choisen first.
Thenthe three MI values for the pairs containingair are compared to select the <automobile, air>pair, resulting in <automobile, air, pollution>.
Ifthere were additional columns in the example,the same process would be applied to the rest ofthe network.There are three reasons why query termweighting is of some value in addition to thepruning of conceptually unrelated terms.
First,our word selection method is not guaranteed togive the correct translation.
The method wouldgive a reasonable result only when twoconsecutive query terms are actually usedtogether in many documents, which is ahypothesis yet to be confirmed for its validity.Second, there may be more than one strongassociation whose degrees are different fromeach other by a large magnitude.
Third,seemingly extraneous terms may serve as arecall-enhancing device with a query expansioneffect.The basic idea in our term weighting scheme isto give a large weight to the best candidate anddivide the remaining quantity to assign equalweights to the rest of the candidates.
In otherwords, the weight for the best candidate, W~, iseither 1 if it is greater than a threshold value orexpressed as follows.Wb = f (x )  ?0.5 + 0.5 (2)0+1Here x and 0 are a MI value and a threshold,respectively.
The numerator, f(x), gives thesmallest integer greater than the MI value so thatthe resulting weight is the same for all thecandidates whose MI values are within a certaininterval.
Once the value for W b is calculated, theweight for the rest o f  the candidates arecalculated as follows:Wr _ 1 - W h (3)n -1where n is the number of candidates.
It should benoted that W~ + Z W = 1.Based on our observation of the calculated MIvalues, we chose to use 3.0 as the cut-off valuein choosing the best candidate and assign a fairlyhigh weight.
The cut-off value was determinedpurely based on the data we obtained; it can varybased on the new range of MI values whendifferent corpora are used.In the example of Fig.
2, the word pair candidatebetween wl and w2 are (motorcar, air),(automobile, air), and (car, air).
Here because theweight of the word pairs (automobile, air) is W,= 0.83, the word "automobile" has a relativelyhigher term weight than the other two words"motorcar" and "car".
Finally the optimalEnglish query set with their term weight,<(motocar,0.085), (automobile, 0.83), (car,0.085) >, is generated for the translations of wl.5 ExperimentsWe developed a system for our cross-languageIR techniques and conducted some basicexperiments using the collection from the Cross-Language Track of TREC 6.
The 24 Englishqueries are comprised of three fields: titles,descriptions, and narratives.
These Englishqueries were manually translated into Koreanqueries so that we can pretend as if the Koreanqueries had been generated by human users forcross-language IR.
In order to compare cross-language IR and mono-language IR, we used theSmart 11.0 system developed by CornellUniversity.Our goal was to examine the efficacy of thedisambiguation and term weighting schemes inour query translation.
We ran our system withthree sets of queries, differentiated by the querylengths: 'title' queries with title fields only, 'short'queries with description fields only, and 'long'queries with all the three fields.
The retrievaleffectiveness measured with l 1-point averageprecision was used for comparison against thebaseline of monolingual retrieval using theoriginal English query.Table 3 gives the experimental results fromusing the four types of query set.
The result from"Translated Query I" was generated only withthe keyword selection and dictionary-basedquery translation stages.
The result "TranslatedQuery II" was generated after all the stages ofour word disambiguation and query termweighting were done.
And the result from themanually disambiguated query set was generatedby manually selecting the best candidate termsfrom the Translated Query I.227QuerySetsOriginalQuer)'Tran.Query ITran.Query IIM.Disam.QueryTable 3.
Ex 1 ~erimental ResultsiTitle Short \] Lon~l lpt.
P C/M(~,:) l lpt.
P C/M("~) \[ l lpt.
P C/M(?,~)0.3251 0.3189 0.28210.2290 70.44 0.21443 67.20 0.1587 56.260.2675 82.28 0.2698 84.60 0.2232 79.120.2779 85.48 0.3002 94.14 0.2433 86.25The performance of the Translated query set Iwas about 70%, 67%, and 56% of monolingualretrieval for the three cases, respectively.
Theperformances of the translated query set II wereabout 82%, 85%, and 79% of monolingualretrieval for the three cases, respectively.
Theperformance of the disambiguated queries, 85%,94%, and 86% of monolingual retrieval for thethree cases, respectively, can be treated as theupper limit for the cross-language r trieval.
Thereason why they are not 100% is attributed to theseveral factors.
They are: 1) the inaccuracy ofthe manual translation of the original Englishquery into the Korean queries, 2) the inaccuracyof the Korean morphological analyzer and thetagger in generating query words, and 3) theinaccuracy in generating candidate terms usingthe bilingual dictionary.The difference between Translated Query I andTranslated Query II indicates that the Ml-baseddisambiguation and the term weighting schemesare effective in enhancing the retrievaleffectiveness.
In addition, the results show thatthe use of these query translation schemes ismore effective with long queries than withshorter queries.
This is expected because thelonger the queries are, the more contextualinformation can be used for mutualdisambiguation.ConclusionIt has been known that query translation using asimple bilingual dictionary leads to a more than40% drop in retrieval effectiveness due totranslation ambiguity.
Our query translationmethod uses mutual information extracted fromthe 1988 - 1990 AP corpus in order to solve theproblems of the bilingual word disambiguationand query term weighting.
The experimentsusing test collection of TREC-6 Cross-LanguageTrack show that the method improves retrievaleffectiveness in Korean-to-English cross-language IR.
The performance can be up to 85%of the monolingual retrieval case.
We also foundthat we obtained the largest percent increasewith long queries.While the experimental results are verypromising, there are several issues to beexplored.
First, we need to test how effectivelythe method can be applied.
Second, we intend toexperiment with other co-occurrence metrics,instead of the mutual information statistic, forpossible improvement.
This investigation ismotivated by our observation of some counter-intuitive MI values.
Third, we also plan on usingdifferent algorithms for choosing the terms andcalculating the weights.In addition, we plan to use the pseudo relevancefeedback method that has been proven to beeffective in monolingual retrieval.
Terms insome top-ranked ocuments are thrown into theoriginal query with an assumption that at leastsome, if not all, of the documents are relevant tothe original query and that the terms appearingin the documents are useful in representinguser's information need.
Here we need todetermine a threshold value for the number oftop ranked document for our cross-languageretrieval situation, let alne other phenomenon.ReferencesDouglas W. Oard and Paul Hackett (1997).Document Translation for the Cross-Language TextRetrieval at the University of Maryland, The SixthText Retrieval Conference (TREC-6), NIST.Gregory Grefenstette (1998).
Cross-LanguageInformation Retrieval, Kluwer AcademicPublishers.Lisa BaUesteros and W. Bruce Croft(1997).
PhrasalTranslation and Query Expansion Techniques forCross-lingual Information Retrieval, SIGIR'97.Lisa Ballesteros and W. Bruce Croft(1998).Resolving Ambiguity for Cross-language Retrieval,SIGIR' 98.Kenneth W. Church and Patrick Hanks (1990).
WordAssociation Norms, Mutual Information, andLexicography, Computational Linguistics, Vol.
16,No.
1, pp.
22-29.Joong-Ho Shin, Young-Soek Han, Key-Sun Choi(1996).
A HMM Part of Speech Tagger for Koreanwith Word Phrasal Relations, In Proceedings ofRecent Advances inNatural Language Processing.Frank Samdja (1993) Retrieval Collection from Text:Xtract, Computational Linguistics, Vol.
19, No.
1,pp.143-177.228Jeong, K. S., Kwon,Y.
H. and Myaeng, S. H. (1997).Construction of Equivalence Classes throughAutomatic Extraction and Identification of ForeignWords, In Proceedings of NLPRS'97, Phuket,Tailand.229
