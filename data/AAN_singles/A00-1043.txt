Sentence Reduct ion for Automat ic  Text Summarizat ionHongyan JingDepar tment  of Computer  Sc ienceCo lumbia  Un ivers i tyNew York,  NY  10027, USAhj ing@cs .co lumbia .eduAbstractWe present a novel sentence reduction system forautomatically removing extraneous phrases fromsentences that are extracted from a document forsummarization purpose.
The system uses multiplesources of knowledge to decide which phrases in anextracted sentence can be removed, including syn-tactic knowledge, context information, and statisticscomputed from a corpus which consists of exampleswritten by human professionals.
Reduction can sig-nificantly improve the conciseness of automatic sum-maries.1 MotivationCurrent automatic summarizers usually rely on sen-tence extraction to produce summaries.
Human pro-fessionals also often reuse the input documents togenerate summaries; however, rather than simplyextracting sentences and stringing them together, asmost current summarizers do, humans often "edit"the extracted sentences in some way so that the re-sulting summary is concise and coherent.
We ana-lyzed a set of articles and identified six major opera-tions that can be used for editing the extracted sen-tences, including removing extraneous phrases froman extracted sentence, combining a reduced sentencewith other sentences, yntactic transformation, sub-stituting phrases in an extracted sentence with theirparaphrases, ubstituting phrases with more generalor specific descriptions, and reordering the extractedsentences (Jing and McKeown, 1999; Jing and McK-eown, 2000).We call the operation of removing extraneousphrases from an extracted sentence sentence reduc-tion.
It is one of the most effective operations thatcan be used to edit the extracted sentences.
Reduc-tion can remove material at any granularity: a word,a prepositional phrase, a gerund, a to-infinitive or aclause.
We use the term "phrase" here to refer toany of the above components hat can be removed inreduction.
The following example shows an originalsentence and its reduced form written by a humanprofessional:Original sentence:When it arrives sometime next year in newTV sets, the V-chip will give parents a newand potentially revolutionary device to blockout programs they don't want their childrento see.Reduced sentence by humans:The V-chip will give parents a device to blockout programs they don't want their childrento see.We implemented an automatic sentence reductionsystem.
Input to the reduction system includesextracted sentences, as well as the original docu-ment.
Output of reduction are reduced forms ofthe extracted sentences, which can either be usedto produce summaries directly, or be merged withother sentences.
The reduction system uses multiplesources of knowledge to make reduction decisions,including syntactic knowledge, context, and statis-tics computed from a training corpus.
We evaluatedthe system against he output of human profession-als.
The program achieved a success rate of 81.3%,meaning that 81.3% of reduction decisions made bythe system agreed with those of humans.Sentence reduction improves the conciseness ofau-tomatically generated summaries, making it conciseand on target.
It can also improve the coherence ofgenerated summaries, since extraneous phrases thatcan potentially introduce incoherece are removed.We collected 500 sentences and their correspondingreduced forms written by humans, and found thathumans reduced the length of these 500 sentencesby 44.2% on average.
This indicates that a goodsentence reduction system can improve the concise-ness of generated summaries ignificantly.In the next section, we describe the sentence re-duction algorithm in details.
In Section 3, we intro-duce the evaluation scheme used to access the perfor-mance of the system and present evaluation results.In Section 4, we discuss other applications of sen-tence reduction, the interaction between reductionand other modules in a summarization system, andrelated work on sentence simplication.
Finally, we310conclude with future work.2 Sentence  reduct ion  based  onmul t ip le  sources  o f  knowledgeThe goal of sentence reduction is to "reduce withoutmajor loss"; that is, we want to remove as many ex-traneous phrases as possible from an extracted sen-tence so that it can be concise, but without detract-ing from the main idea the sentence conveys.
Ideally,we want to remove a phrase from an extracted sen-tence only if it is irrelevant to the main topic.
Toachieve this, the system relies on multiple sourcesof knowledge to make reduction decisions.
We firstintroduce the resources in the system and then de-scribe the reduction algorithm.2.1 The  resources(1) The  corpus .
One of the key features ofthe system is that it uses a corpus consisting oforiginal sentences and their corresponding reducedforms written by humans for training and testingpurpose.
This corpus was created using an auto-matic program we have developed to automaticallyanalyze human-written abstracts.
The program,called the decomposition program, matches phrasesin a human-written summary sentence to phrasesin the original document (Jing and McKeown,1999).
The human-written abstracts were collectedfrom the free daily news service "Communications-related headlines", provided by the Benton Founda-tion (http://www.benton.org).
The articles in thecorpus are news reports on telecommunication re-lated issues, but they cover a wide range of topics,such as law, labor, and company mergers.
(2) The  lexicon.
The system also uses a large-scale, reusable lexicon we combined from multipleresources (Jing and McKeown, 1998).
The resourcesthat were combined include COMLEX syntactic dic-tionary (Macleod and Grishman, 1995), EnglishVerb Classes and Alternations (Levin, 1993), theWordNet lexical database (Miller et al, 1990), theBrown Corpus tagged with WordNet senses (Milleret al, 1993).
The lexicon includes subcategoriza-tions for over 5,000 verbs.
This information is usedto identify the obligatory arguments of verb phrases.
(3) The  WordNet  lexical database.
Word-Net (Miller et al, 1990) is the largest lexicaldatabase to date.
It provides lexical relationsbetween words, including synonymy, antonymy,meronymy, entailment (e.g., eat --+ chew), or cau-sation (e.g., kill --4 die).
These lexical links are usedto identify the focus in the local context.
(4) The  syntact ic  parser .
We use the EnglishSlot Grammar(ESG) parser developed at IBM (Mc-Cord, 1990) to analyze the syntactic structure of aninput sentence and produce a sentence parse tree.The ESG parser not only annotates the syntacticcategory of a phrase (e.g., "np" or "vp"), it also an-notates the thematic role of a phrase (e.g., "subject"or "object").2.2 The  a lgor i thmThere are five steps in the reduction program:Step 1: Syntact i c  pars ing.We first parse the input sentence using the ESGparser and produce the sentence parse tree.
The op-erations in all other steps are performed based onthis parse tree.
Each following step annotates eachnode in the parse tree with additional information,such as syntactic or context importance, which areused later to determine which phrases (they are rep-resented as subtrees in a parse tree) can be consid-ered extraneous and thus removed.Step  2: Grammar  check ing .In this step, we determine which components ofa sentence must not be deleted to keep the sentencegrammatical.
To do this, we traverse the parse treeproduced in the first step in top-down order andmark, for each node in the parse tree, which of itschildren are grammatically obligatory.
We use twosources of knowledge for this purpose.
One sourceincludes simple, linguistic-based rules that use thethematic role structure produced by the ESG parser.For instance, for a sentence, the main verb, the sub-ject, and the object(s) are essential if they exist, buta prepositional phrase is not; for a noun phrase, thehead noun is essential, but an adjective modifier ofthe head noun is not.
The other source we rely onis the large-scale lexicon we described earlier.
Theinformation in the lexicon is used to mark the oblig-atory arguments of verb phrases.
For example, forthe verb "convince", the lexicon has the followingentry:conv incesense  I :NP-PP :PVAL ( ' to f ' ' )NP-T0- INF -OCsense  2 :NPThis entry indicates that the verb "convince" canbe followed by a noun phrase and a prepositionalphrase starting with the preposition "of" (e.g., heconvinced me of his innocence).
It can also be fol-lowed by a noun phrase and a to-infinitive phrase(e.g., he convinced me to go to the party).
Thisinformation prevents the system from deleting the"of" prepositional phrase or the to-infinitive that ispart of the verb phrase.At the end of this step, each node in the parse tree- -  including both leaf nodes and intermediate nodes- -  is annotated with a value indicating whether it isgrammatically obligatory.
Note that whether a nodeis obligatory is relative to its parent node only.
For311example, whether a determiner is obligatory is rela-tive to the noun phrase it is in; whether a preposi-tional phrase is obligatory is relative to the sentenceor the phrase it is in.Step 3: Context information.In this step, the system decides which componentsin the sentence are most related to the main topicbeing discussed.
To measure the importance of aphrase in the local context, the system relies on lex-ical links between words.
The hypothesis is thatthe more connected a word is with other words inthe local context, the more likely it is to be thefocus of the local context.
We link the words inthe extracted sentence with words in its local con-text, if they are repetitions, morphologically related,or linked in WordNet through one of the lexical re-lations.
The system then computes an importancescore for each word in the extracted sentence, basedon the number of links it has with other words andthe types of links.
The formula for computing thecontext importance score for a word w is as follows:9ContextWeight(w) = ~-~(Li x NUMi(w))i-----1Here, i represents the different types of lexicalrelations the system considered, including repeti-tion, inflectional relation, derivational relation, andthe lexical relations from WordNet.
We assigned aweight to each type of lexical relation, representedby Li in the formula.
Relations such as repetitionor inflectional relation are considered more impor-tant and are assigned higher weights, while relationssuch as hypernym are considered less important andassigned lower weights.
NUMi(w) in the formularepresents the number of a particular type of lexicallinks the word w has with words in the local context.After an importance score is computed for eachword, each phrase in the "sentence gets a score byadding up the scores of its children nodes in the parsetree.
This score indicates how important the phraseis in the local context.Step 4: Corpus evidence.The program uses a corpus consisting of sen-tences reduced by human professionals and theircorresponding original sentences to compute howlikely humans remove a certain phrase.
The systemfirst parsed the sentences in the corpus using ESGparser.
It then marked which subtrees in these parsetrees (i.e., phrases in the sentences) were removedby humans.
Using this corpus of marked parse trees,we can compute how likely a subtree is removedfrom its parent node.
For example, we can computethe probability that the "when" temporal clause isremoved when the main verb is "give", representedas Prob("when-clause is removed"l"v=give"),or the probability that the to-infinitive modifierof the head noun "device" is removed, represented asProb("to-infinitive modifier is removed"l"n=device").These probabilities are computed using Bayes'srule.
For example, the probability that the "when"temporal clause is removed when the main verb is"give", Prob("when-clause is removed' l"v=give') ,is computed as the product ofProb("v=give"\["when-clause is removed") (i.e.,the probability that the main verb is "give"when the "when" clause is removed) andProb("when-clause is removed") (i.e., the probabil-ity that the "when" clause is removed), divided byProb("v=give") (i.e., the probability that the mainverb is "give").Besides computing the probability that a phrase isremoved, we also compute two other types of proba-bilities: the probability that a phrase is reduced (i.e.,the phrase is not removed as a whole, but some com-ponents in the phrase are removed), and the proba-bility that a phrase is unchanged at all (i.e., neitherremoved nor reduced).These corpus probabilities help us capture hu-man practice.
For example, for sentences like "Theagency reported that ...", "The other source saysthat ...", "The new study suggests that ...', the that-clause following the say-verb (i.e., report, say, andsuggest) in each sentence is very rarely changed atall by professionals.
The system can capture this hu-man practice, since the probability that that-clauseof the verb say or report being unchanged at allwill be relatively high, which will help the systemto avoid removing components in the that-clause.These corpus probabilities are computed before-hand using a training corpus.
They are then storedin a table and loaded at running time.Step 5: Final Decision.The final reduction decisions are based on the re-sults from all the earlier steps.
To decide whichphrases to remove, the system traverses the sentenceparse tree, which now have been annotated with dif-ferent types of information from earlier steps, in thetop-down order and decides which subtrees houldbe removed, reduced or unchanged.
A subtree (i.e.,a phrase) is removed only if it is not grammaticallyobligatory, not the focus of the local context (indi-cated by a low importance score), and has a reason-able probability of being removed by humans.Figure 1 shows sample output of the reductionprogram.
The reduced sentences produced by hu-mans are also provided for comparison.3 Eva luat ion3.1 The  eva luat ion  schemeWe define a measure called success rate to evaluatethe performance of our sentence reduction program.312Example 1:Original sentence : When it arrives sometime next year in new TV sets, the V-chip will giveparents  a new and potentially revolutionary device to block out programs they don'twant  the i r  children to see.Reduction program: The V-chip will give parents a new and potentially revolutionary device toblock out programs they don't want their children to see.Professionals : The V-chip will give parents a device to block out programs they don't wanttheir children to see.Example 2:Original sentence : Som and Hoffman's creation would allow broadcasters to i nser tmultiple ratings into a show, enabling the V-chip to filter out racy or violent material but leaveunexceptional portions of a show alone.Reduction Program: Som and Hoffman's creation would allow broadcasters to insert multiple rat-ings into a show.Professionals : (the same)Figure 1: Sample output of sentence reduction programThe success rate computes the percentage of sys-tem's reduction decisions that agree with those ofhumans.We compute the success rate in the following way.The reduction process can be considered as a seriesof decision-making process along the edges of a sen-tence parse tree.
At each node of the parse tree,both the human and the program make a decisionwhether to remove the node or to keep it.
If a nodeis removed, the subtree with that node as the root isremoved as a whole, thus no decisions are needed forthe descendants of the removed node.
If the node iskept, we consider that node as the root and repeatthis process.DB E G / \  / ' , ,A C F H?ADtB E GC F HReduced: A B D G HFigure 3: Reduced form by a humanDB E GA C F HReduced: B C DInput: A B C D E F G H Figure 4: Reduced form by the programFigure 2: Sample sentence and parse treeSuppose we have an input sentence (ABCDE-FGH), which has a parse tree shown in Figure 2.Suppose a human reduces the sentence to (ABDGH) ,which can be translated to a series of decisions madealong edges in the sentence parse tree as shown inFigure 3.
The symbol "y" along an edge means thenode it points to will be kept, and "n" means thenode will be removed.
Suppose the program reducesthe sentence to (BCD),  which can be translated sim-ilarly to the annotated tree shown in Figure 4.We can see that along five edges (they are D--+B,D--+E, D--+G, B--+A, B-+C), both the human andthe program made decisions.
Two out of the fivedecisions agree (they are D--+B and D--4E), so thesuccess rate is 2/5 (40%).
The success rate is definedas :# of edges along which the hu-man and the program have madesuccess rate = the same decisionthe total # of edges along whichboth the human and the progamhave made decisions313Note that the edges along which only the humanor the program has made a decision (e.g., G--+F andG--+F in Figure 3 and Figure 4) are not consideredin the computation of success rate, since there is noagreement issue in such cases.3.2 Eva luat ion  resu l tIn the evaluation, we used 400 sentences in the cor-pus to compute the probabilities that a phrase isremoved, reduced, or unchanged.
We tested the pro-gram on the rest 100 sentences.Using five-fold validation (i.e., chose different 100sentences for testing each time and repeating the ex-periment five times), The program achieved an aver-age success rate of 81.3%.
If we consider the baselineas removing all the prepositional phrases, clauses,to-infinitives and gerunds, the baseline performanceis 43.2%.We also computed the success rate of program'sdecisions on particular types of phrases.
For the de-cisions on removing or keeping a clause, the systemhas a success rate of 78.1%; for the decisions on re-moving or keeping a to-infinitive, the system has asuccess rate of 85.2%.
We found out that the systemhas a low success rate on removing adjectives of nounphrases or removing adverbs of a sentence or a verbphrase.
One reason for this is that our probabilitymodel can hardly capture the dependencies betweena particular adjective and the head noun since thetraining corpus is not large enough, while the othersources of information, including grammar or con-text information, provide little evidence on whetheran adjective or an adverb should be removed.
Giventhat whether or not an adjective or an adverb isremoved oes not affect the conciseness of the sen-tence significantly and the system lacks of reliabilityin making such decisions, we decide not to removeadjectives and adverbs.On average, the system reduced the length of the500 sentence by 32.7% (based on the number ofwords), while humans reduced it by 41.8%.The probabilities we computed from the trainingcorpus covered 58% of instances in the test corpus.When the corpus probability is absent for a case,the system makes decisions based on the other twosources of knowledge.Some of the errors made by the system result fromthe errors by the syntactic parser.
We randomlychecked 50 sentences, and found that 8% of the er-rors made by the system are due to parsing errors.There are two main reasons responsible for this rela-tive low percentage of errors resulted from mistakesin parsing.
One reason is that we have taken somespecial measures to avoid errors introduced by mis-takes in parsing.
For example, PP attachment is adifficult problem in parsing and it is not rare thata PP is wrongly attached.
Therefore, we take thisinto account when marking the obligatory compo-nents using subcategorization k owledge from thelexicon (step 2) - we not only look at the PPs thatare attached to a verb phrase, but also PPs that arenext to the verb phrase but not attached, in caseit is part of the verb phrase.
We also wrote a pre-processor to deal with particular structures that theparser often has problems with, such as appositions.The other reason is that parsing errors do not alwaysresult in reduction errors.
For example, given a sen-tence "The spokesperson of the University said that... ' ,  although that-clause in the sentence may have acomplicated structure and the parser gets it wrong,the reduction system is not necessarily affected sinceit may decide in this case to keep that-clause as itis, as humans often do, so the parsing errors will notmatter in this example.4 Discussion and related workThe reduction algorithm we present assumes genericsummarization; that is, we want to generate a sum-mary that includes the most important informationin an article.
We can tailor the reduction systemto queries-based summarization.
In that case, thetask of the reduction is not to remove phrases thatare extraneous in terms of the main topic of an arti-cle, but phrases that are not very relevant o users'queries.
We extended our sentence reduction pro-gram to query-based summarization by adding an-other step in the algorithm to measure the relevanceof users' queries to phrases in the sentence.
In thelast step of reduction when the system makes the fi-nal decision, the relevance of a phrase to the query istaken into account, together with syntactic, context,and corpus information.Ideally, the sentence reduction module should in-teract with other modules in a summarization sys-tem.
It should be able to send feedback to the ex-traction module if it finds that a sentence selected bythe extraction module may be inappropriate (for ex-ample, having a very low context importance score).It should also be able to interact with the modulesthat run after it, such as the sentence combinationmodule, so that it can revise reduction decisions ac-cording to the feedback from these modules.Some researchers suggested removing phrases orclauses from sentences for certain applications.
(Grefenstette, 1998) proposed to remove phrases insentences to produce a telegraphic text that canbe used to provide audio scanning service for theblind.
(Corston-Oliver and Dolan, 1999) proposedto remove clauses in sentences before indexing doc-uments for Information Retrieval.
Both studies re-moved phrases based only on their syntactic cate-gories, while the focus of our system is on decidingwhen it is appropriate to remove a phrase.Other researchers worked on the text simplifica-314tion problem, which usually involves in simplifyingtext but not removing any phrases.
For example,(Carroll et al, 1998) discussed simplifying newspa-per text by replacing uncommon words with com-mon words, or replacing complicated syntactic struc-tures with simpler structures to assist people withreading disabilities.
(Chandrasekar et al, 1996) dis-cussed text simplification i general.
The differencebetween these studies on text simplification and oursystem is that a text simplification system usuallydoes not remove anything from an original sentence,although it may change its structure or words, butour system removes extraneous phrases from the ex-tracted sentences.5 Conc lus ions  and  fu ture  workWe present a novel sentence reduction system whichremoves extraneous phrases from sentences thatare extracted from an article in text summariza-tion.
The deleted phrases can be prepositionalphrases, clauses, to-infinitives, or gerunds, and mul-tiple phrases can be removed form a single sen-tence.
The focus of this work is on determining,for a sentence in a particular context, which phrasesin the sentence are less important and can be re-moved.
Our system makes intelligent reduction deci-sions based on multiple sources of knowledge, includ-ing syntactic knowledge, context, and probabilitiescomputed from corpus analysis.
We also created acorpus consisting of 500 sentences and their reducedforms produced by human professionals, and usedthis corpus for training and testing the system.
Theevaluation shows that 81.3% of reduction decisionsmade by the system agreed with those of humans.In the future, we would like to integrate our sen-tence reduction system with extraction-based sum-marization systems other than the one we have de-veloped, improve the performance ofthe system fur-ther by introducing other sources of knowledge nec-essary for reduction, and explore other interestingapplications of the reduction system.AcknowledgmentThis material is based upon work supported by theNational Science Foundation under Grant No.
IRI96-19124 and IRI 96-18797.
Any opinions, findings,and conclusions or recommendations expressed inthis material are those of the authors and do notnecessarily reflect the views of the National ScienceFoundation.Re ferencesJohn Carroll, Guido Minnen, Yvonne Canning,Siobhan Devlin, and John Tait.
1998.
Practi-cal simplification of English newspaper text toassist aphasic readers.
In Proceedings of AAAI-98 Workshop on Integrating Artificial Intelligenceand Assistive Technology, Madison, Wisconsin,July.R.
Chandrasekar, C. Doran, and B. Srinivas.
1996.Motivations and methods for text simplification.In Proceedings of the 16th International Confer-ence on Computational Linguistics (COLING'96),Copenhagen, Denmark, August.Simon H. Corston-Oliver and William B. Dolan.1999.
Less is more: Eliminating index terms fromsubordinate clauses.
In Proceedings of the 37thAnnual Meeting of the Association for Computa-tional Linguistics(ACL'99), pages 349-356, Uni-versity of Maryland, Maryland, June.Gregory Grefenstette.
1998.
Producing intelligenttelegraphic text reduction to provide an audioscanning service for the blind.
In Working Notesof AAAI  1998 Spring Symposium on IntelligentText Summarization, Stanford University, Stand-ford, California, March.Hongyan Jing and Kathleen R. McKeown.
1998.Combining multiple, large-scale resources in areusable lexicon for natural anguage generation.In Proceedings of the 36th Annual Meeting of theAssociation for Computational Linguistics and the17th International Conference on ComputationalLinguistics, volume 1, pages 607-613, Universit~de Montreal, Quebec, Canada, August.Hongyan Jing and Kathleen R. McKeown.
1999.The decomposition of human-written summarysentences.
In Proceedings of the 22nd Interna-tional ACM SIGIR Conference on Research andDevelopment in Information Retrieval, pages 129-136, University of Berkeley, CA, August.Hongyan Jing and Kathleen R. McKeown.
2000.Cut and paste based text summarization.
I  Pro-ceedings of NAACL 2000.Beth Levin.
1993.
English Verb Classes and Alter-nations: A Preliminary Investigation.
Universityof Chicago Press, Chicago, Illinois.Catherine Macleod and Ralph Grishman, 1995.COMLEX Syntax Reference Manual.
ProteusProject, New York University.Michael McCord, 1990.
English Slot Grammar.IBM.George A. Miller, Richard Beckwith, Christiane Fell-baum, Derek Gross, and Katherine J. Miller.1990.
Introduction to WordNet: An on-line lexi-cal database.
International Journal of Lexicogra-phy (special issue), 3(4):235-312.George A. Miller, Claudia Leacock, Randee Tengi,and Ross T. Bunker.
1993.
A semantic oncor-dance.
Cognitive Science Laboratory, PrincetonUniversity.315
