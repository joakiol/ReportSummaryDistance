Referring Expression Generation Using Speaker-based Attribute Selectionand Trainable Realization (ATTR)Giuseppe Di Fabbrizio and Amanda J. Stent and Srinivas BangaloreAT&T Labs - Research, Inc.180 Park AvenueFlorham Park, NJ 07932, USA{pino,stent,srini}@research.att.comAbstractIn the first REG competition, researchersproposed several general-purpose algorithmsfor attribute selection for referring expressiongeneration.
However, most of this work didnot take into account: a) stylistic differencesbetween speakers; or b) trainable surface re-alization approaches that combine semanticand word order information.
In this paper wedescribe and evaluate several end-to-end re-ferring expression generation algorithms thattake into consideration speaker style and usedata-driven surface realization techniques.1 IntroductionThere now exist numerous general-purpose algo-rithms for attribute selection used in referring ex-pression generation (e.g., (Dale and Reiter, 1995;Krahmer et al, 2003; Belz and Gatt, 2007)).
How-ever, these algorithms by-and-large focus on the al-gorithmic aspects of referring expression generationrather than on psycholinguistic factors that influencelanguage production.
For example, we know thathumans exhibit individual style differences duringlanguage production that can be quite pronounced(e.g.
(Belz, 2007)).
We also know that the lan-guage production process is subject to lexical prim-ing, which means that words and concepts that havebeen used recently are likely to appear again (Levelt,1989).In this paper, we first explore the impact of indi-vidual style and priming on attribute selection forreferring expression generation.
To get an ideaof the potential improvement when modeling thesefactors, we implemented a version of full brevitysearch (Dale, 1992) that uses speaker-specific con-straints, and another version that also uses recencyconstraints.
We found that using speaker-specificconstraints led to big performance gains for bothTUNA domains, while the use of recency constraintswas not as effective for TUNA-style tasks.
We thenmodified Dale and Reiter?s classic attribute selectionalgorithm (Dale and Reiter, 1995) to model speaker-specific constraints, and found performance gains inthis more greedy approach as well.Then we looked at surface realization for referringexpression generation.
There are several approachesto surface realization described in the literature (Re-iter and Dale, 2000) ranging from hand-craftedtemplate-based realizers to data-driven syntax-basedrealizers (Langkilde and Knight, 2000; Bangaloreand Rambow, 2000).
Template-based realizationinvolves the insertion of attribute values into pre-determined templates.
Data-driven syntax-basedmethods use syntactic relations between words (in-cluding long-distance relations) for word ordering.Other data-driven techniques exhaustively generatepossible realizations with recourse to syntax in asmuch as it is reflected in local n-grams.
Such tech-niques have the advantage of being robust althoughthey are inadequate to capture long-range depen-dencies.
In this paper, we explore three techniquesfor the task of referring expression generation thatare different hybrids of hand-crafted and data-drivenmethods.The remainder of this paper is organized as fol-lows: In Section 2, we present the algorithms forattribute selection.
The different methods for sur-face realizers are presented in Section 3.
The exper-iments concerning the attribute selection and surfacerealization are presented in Section 4 and Section 5.The final remarks are discussed in Section 6.2 Attribute Selection AlgorithmsFull Brevity (FB) We implemented a version offull brevity search (Dale, 1992).
It does the follow-211ing: first, it constructs AS, the set of attribute setsthat uniquely identify the referent given the distrac-tors.
Then, it selects an attribute set ASu ?
ASbased on a selection criterion.
The minimality (FB-m) criterion selects from among the smallest ele-ments of AS at random.
The frequency (FB-f) cri-terion selects from among the elements of AS theone that occurred most often in the training data.The speaker frequency (FB-sf) criterion selectsfrom among the elements of AS the one used mostoften by this speaker in the training data, backing offto FB-f if necessary.
This criterion models speaker-specific constraints.
Finally, the speaker recency(FB-sr) criterion selects from among the elementsof AS the one used most recently by this speaker inthe training data, backing off to FB-sf if necessary.This criterion models priming and speaker-specificconstraints.Dale and Reiter We implemented two variants ofthe classic Dale & Reiter attribute selection (Daleand Reiter, 1995) algorithm.
For Dale & Reiterbasic (DR-b), we first build the preferred list ofattributes by sorting the most frequently used at-tributes in the training set.
We keep separate listsbased upon the ?+LOC?
and ?-LOC?
conditionsand backoff to a global preferred frequency list incase the attributes are not covered in the current list(merge and sort by frequency).
Next, we iterate overthe list of preferred attributes and select the next onethat rules out at least one entity in the contrast setuntil no distractors are left.
The Dale & Reiterspeaker frequency (DR-sf) uses a speaker-specificpreferred list, backing off to the DR-b preferred listif an attribute is not in the current speaker?s preferredlist.
For this task, we ignored any further attributeknowledge base or taxonomy abstraction.3 Surface Realization ApproachesWe summarize our approaches to surface realizationin this section.
All three surface realizers have thesame four stages: (a) lexical choice of words andphrases for the attribute values; (b) generation of aspace of surface realizations (T ); (c) ranking the setof realizations using a language model (LM ); (d)selecting the best scoring realization.T ?
= BestPath(Rank(T, LM)) (1)Template-Based Realizer To construct ourtemplate-based realizer, we extract the annotatedword string from each trial in the training dataand replace each annotated text segment with theattribute type with which it is annotated.
The keyfor each template is the lexicographically sorted listof attribute types it contains.
Consequently, anyattribute lists not found in the training data cannotbe realized by the template-based realizer; however,if there is a template for an input attribute list it isquite likely to be coherent.At generation time, we find all possible realiza-tions of each attribute in the input attribute set, andfill in each possible template with each combina-tion of the attribute realizations.
We report resultsfor two versions of this realizer: one with speaker-specific lexicon and templates (Template-S), andone without (Template).Dependency-Based Realizer To construct ourdependency-based realizer, we first parse all theword strings from the training data using the depen-dency parser described in (Bangalore et al, 2005;Nasr and Rambow, 2004).
Then, for every pairof words wi, wj that occur in the same referringexpression (RE) in the training data, we compute:freq(i < j), the frequency with which wi pre-cedes wj in any RE; freq(i = j ?
1), the fre-quency with which wi immediately precedes wj inany RE; freq(dep(wi, wj) ?
i < j), the frequencywith which wi depends on and precedes wj in anyRE, and freq(dep(wi, wj) ?
j < i), the frequencywith which wi depends on and follows wj in any RE.At generation time, we find all possible realiza-tions of each attribute in the input attribute set, andfor each combination of attribute realizations, wefind the most likely set of dependencies and prece-dences given the training data.Permute and Rank In this method, the lexicalitems associated with each of the attribute value tobe realized are treated as a disjunctive set of tokens.This disjunctive set is represented as a finite-stateautomaton with two states and transitions betweenthem labeled with the tokens of the set.
The transi-tions are weighted by the negative logarithm of theprobability of the lexical token (w) being associatedwith that attribute value (attr): (?log(P (w|attr))).These sets are treated as unordered bags of tokens;we create permutations of these bags of tokens torepresent the set of possible surface realizations.
Wethen use the language model to rank this set of possi-ble realizations and recover the highest scoring RE.212DICE MASI Acc.
Uniq.
Min.FurnitureFB-m .36 .16 0 1 1FB-f .81 .58 .40 1 0FB-sf .95 .87 .79 1 0FB-sr .93 .81 .71 1 0DR-b .81 .60 .45 1 0DR-sf .86 .64 .45 1 .04PeopleFB-m .26 .12 0 1 1FB-f .58 .37 .28 1 0FB-sf .94 .88 .84 1 .01FB-sr .93 .85 .79 1 .01DR-b .70 .45 .25 1 0DR-sf .78 .55 .35 1 0OverallFB-m .32 .14 0 1 1FB-f .70 .48 .34 1 0FB-sf .95 .87 .81 1 .01FB-sr .93 .83 .75 1 .01DR-b .76 .53 .36 1 0DR-sf .82 .60 .41 1 .02Table 1: Results for attribute selectionUnfortunately, the number of states of the min-imal permutation automaton of even a linear au-tomata (finite-state machine representation of astring) grows exponentially with the number ofwords of the string.
So, instead of creating a fullpermutation automaton, we choose to constrain per-mutations to be within a local window of adjustablesize (also see (Kanthak et al, 2005)).4 Attribute Selection ExperimentsData Preparation The training data were used tobuild the models outlined above.
The developmentdata were then processed one-by-one.
For our finalsubmissions, we use training and development datato build our models.Results Table 1 shows the results for variations offull brevity.
As we would expect, all approachesachieve a perfect score on uniqueness.
For both cor-pora, we see a large performance jump when weuse speaker constraints.
However, when we incor-porate recency constraints as well performance de-clines slightly.
We think this is due to two factors:first, the speakers are not in a conversation, and self-priming may have less impact; and second, we donot always have the most recent prior utterance for agiven speaker in the training data.Table 1 also shows the results for variations ofDale and Reiter?s algorithm.
When we incorpo-String-Edit Dist.
AccuracyFurnitureDEV FB-sf DR-sf DEV FB-sf DR-sfPermute&Rank 4.39 4.60 4.74 0.07 0.04 0.03Dependency 3.90 4.25 5.50 0.14 0.06 0.03Template 4.36 4.33 5.39 0.07 0.05 0.03Template-S 3.52 3.81 5.16 0.28 0.20 0.04PeoplePermute&Rank 6.26 6.46 7.01 0.01 0.01 0.00Dependency 3.96 4.32 7.03 0.06 0.06 0.00Template 5.16 4.62 7.26 0.03 0.06 0.00Template-S 4.25 4.31 7.04 0.18 0.13 0.00OverallPermute&Rank 5.25 5.45 5.78 0.05 0.03 0.01Dependency 3.93 4.28 6.20 0.07 0.06 0.01Template 4.73 4.46 6.25 0.05 0.05 0.01Template-S 3.86 4.04 6.03 0.23 0.17 0.02Table 2: Results for realizationrate speaker constraints, we again see a performancejump, although compared to the best possible case(full brevity) there is still room for improvement.Discussion We have shown that by using speakerand recency constraints in standard algorithms, itis possible to achieve performance gains on the at-tribute selection task.The most relevant previous research is the work of(Gupta and Stent, 2005), who modified Dale and Re-iter?s algorithm to model speaker adaptation in dia-log.
However, this corpus does not involve dialog sothere are no cross-speaker constraints, only within-speaker constraints (style and priming).5 Surface Realization ExperimentsData Preparation We first normalize the trainingdata to correct misspellings and remove punctuationand capitalization.
We then extract a phrasal lexi-con.
For each attribute value we extract the count ofall realizations of that value in the training data.
Wetreat locations as a special case, storing separatelythe realizations of x-y coordinate pairs and singlex- or y-coordinates.
We add a small number of re-alizations to the lexicon by hand to cover possibleattribute values not seen in the training data.Results Table 2 shows the evaluation results forstring-edit distance and string accuracy on the devel-opment set with three different attributes sets: DEV?
attributes selected by the human test; FB-sf ?
at-tributes generated by the full brevity algorithm withspeaker frequency; and DR-sf ?
attributes selected213by the Dale & Reiter algorithm with speaker fre-quency.For the TUNA realization task (DEV attributes),our approaches work better for the furniture domain,where there are fewer attributes, than for the peopledomain.
For the furniture domain, the Template-Sapproach achieves lowest string-edit distance, whilefor the people domain, the Dependency approachachieves lowest string-edit distance.
The lattermethod was submitted for human evaluation.When we consider the ?end-to-end?
referringexpression generation task (FB-sf and DR-sf at-tributes), the best overall performing system is thespeaker-based template generator with full-brevityand speaker frequency attribute selection.
In termsof generated sentence quality, a preliminary andqualitative analysis shows that the combination Per-mute & Rank and DR-sf produces more naturalisticphrases.Discussion Although the Template-S approachachieves the best string edit distance scores over-all, it is not very robust.
If no examples were foundin the training data neither Template approach willproduce no output.
(This happens twice for each ofthe domains on the development data.)
The Depen-dency approach achieves good overall performancewith more robustness.The biggest cause of errors for the Permuteand Reorder approach was missing determiners andmissing modifiers.
The biggest cause of errors forthe Dependency approach was missing determinersand reordered words.
The Template approach some-times had repeated words (e.g.
?middle?, where?middle?
referred to both x- and y-coordinates).6 ConclusionsWhen building computational models of language,knowledge about the factors that influence humanlanguage production can prove very helpful.
Thisknowledge can be incorporated in frequentist andheuristic approaches as constraints or features.
Inthe experiments described in this paper, we useddata-driven, speaker-aware approaches to attributeselection and referring expression realization.
Weshowed that individual speaking style can be use-fully modeled even for quite ?small?
generationtasks, and confirmed that data-driven approaches tosurface realization can work well using a range oflexical, syntactic and semantic information.In addition to individual style and priming, an-other potentially fruitful area for exploration withTUNA-style tasks is human visual search strategies(Rayner, 1998).
We leave this idea for future work.AcknowledgmentsWe thank Anja Belz, Albert Gatt, and Eric Kowfor organizing the REG competition and providingdata, and Gregory Zelinsky for discussions aboutvisually-based constraints.ReferencesS.
Bangalore and O. Rambow.
2000.
Exploiting a prob-abilistic hierarchical model for generation.
In Proc.COLING.S.
Bangalore, A. Emami, and P. Haffner.
2005.
Factor-ing global inference by enriching local representations.Technical report, AT&T Labs-Research.A.
Belz and A. Gatt.
2007.
The attribute selection forGRE challenge: Overview and evaluation results.
InProceedings of UCNLG+MT at MT Summit XI.A.
Belz.
2007.
Probabilistic generation of weather fore-cast texts.
In Proceedings of NAACL/HLT.R.
Dale and E. Reiter.
1995.
Computational interpreta-tions of the Gricean maxims in the generation of refer-ring expressions.
Cognitive Science, 19(2).Robert Dale.
1992.
Generating Referring Expressions:Constructing Descriptions in a Domain of Objects andProcesses.
MIT Press, Cambridge, MA.S.
Gupta and A. Stent.
2005.
Automatic evaluation ofreferring expression generation using corpora.
In Pro-ceedings of UCNLG.S.
Kanthak, D. Vilar, E. Matusov, R. Zens, and H. Ney.2005.
Novel reordering approaches in phrase-basedstatistical machine translation.
In Proc.
ACL Work-shop on Building and Using Parallel Texts.E.
Krahmer, S. van Erk, and A. Verleg.
2003.
Graph-based generation of referring expressions.
Computa-tional Linguistics, 29(1).I.
Langkilde and K. Knight.
2000.
Forest-based statisti-cal sentence generation.
In Proc.
NAACL.W.
Levelt, 1989.
Speaking: From intention to articula-tion, pages 222?226.
MIT Press.A.
Nasr and O. Rambow.
2004.
Supertagging andfull parsing.
In Proc.
7th International Workshopon Tree Adjoining Grammar and Related Formalisms(TAG+7).K.
Rayner.
1998.
Eye movements in reading and infor-mation processing: 20 years of research.
Psychologi-cal Bulletin, 124(3).E.
Reiter and R. Dale.
2000.
Building Natural LanguageGeneration Systems.
Cambridge University Press.214
