INTENTIONS AND INFORMATION IN  D ISCOURSENicho las  AsherIR IT ,  Un ivers i t4  Pau l  Sabat ie r ,118 Route  de Narbonne,31062 Tou louse ,  CEDEX,Franceasher@irit, frAlex  Lascar idesDepar tment  of  L inguis t ics ,S tanford  Un ivers i ty ,S tanford ,Ca  94305-2150,USA,alex~csli, stanford, eduAbstractThis paper is about the flow of inference between com-municative intentions, discourse structure and the do-main during discourse processing.
We augment a the-ory of discourse interpretation with a theory of distinctmental attitudes and reasoning about them, in order toprovide an account of how the attitudes interact withreasoning about discourse structure.INTRODUCTIONThe flow of inference between communicative intentionsand domain information is often essential to discourseprocessing.
It is well reflected in this discourse fromMoore and Pollack (1992):(1)a. George Bush supports big business.b.
He's sure to veto House Bill 1711.There are at least three different interpretations.
Con-sider Context 1: in this context the interpreter I be-lieves that the author A wants to convince him that(lb) is true.
For example, the context is one in whichI has already uttered Bush won't veto any more bills.I reasons that A's linguistic behavior was intentional,and therefore that A believes that by saying (la) hewill convince I that Bush will veto the bill.
Even if Ibelieved nothing about the bill, he now infers it's badfor big business.
So we have witnessed an inferencefrom premises that involve the desires and beliefs of A(Moore and Pollack's "intentional structure"), as wellas his linguistic behavior, to a conclusion about domaininformation (Moore and Pollack's "informational struc-ture").Now consider Context 2: in this context I knows thatA wants to convince him of (la).
As in Context 1, Imay infer that the bill is bad for big business.
But now,(lb) is used to support (la).Finally, consider Context 3: in this context I knowsthat House Bill 1711 is bad for big business, but doesn'tknow A's communicative desires prior to witnessinghis linguistic behaviour.
From his beliefs about tiledomain, he infers that supporting big business wouldcause Bush to veto this bill.
So, A must.
have uttered(la) to support (lb).
Hence I realises that A wan~edhim to believe (lb).
So in contrast o Contexts 1 and 2,we have a flow of inference from informational structureto intentional structure.This story makes two main points.
First, we agreewith Moore and Pollack that we must represent boththe intentional import and the informational importof a discourse.
As they show, this is a problem forcurrent formulations of Rhetorical Structure Theory(RST) (Thompson and Mann, 1987).
Second, we gofurther than Moore and Pollack, and argue that rea-soning about beliefs and desires exploits different rulesand axioms from those used to infer rhetorical relations.Thus, we should represent intentional structure and dis-course structure separately.
But we postulate rhetoricalrelations that express the discourse function of the con-stituents in the communicative plan of the author, andwe permit interaction between reasoning about rhetor-ical relations and reasoning about beliefs and desires.This paper provides the first steps towards a formalanalysis of the interaction between intentional struc-ture and informational structure.
Our framework fordiscourse structure analysis is SDRT (Asher 1993).
Thebasic representational structures of that theory may beused to characterise cognitive states.
We will extend thelogical engine used to infer rhetorical relations--DiCE(Lascarides and Asher 1991, 1993a, 1993b, Lascaridesand Oberlander 1993)--to model inferences about in-tentional structure and its interaction with informa-tional structure.BUSH'S REQUIREMENTSWe must represent both the intentional import andthe informational import of a discourse simultaneously.So we need a theory of discourse structure where dis-course relations central to intentional import and toinformational import can hold simultaneously betweenthe same constituents.
A logical framework in which allthose plausible relations between constituents that areconsistent with each other are inferred, such as a non-monotonic logic like that in DICE (Lascarides and Asher,1993a), would achieve this.
So conceivably, a similarnonmonotonic logic for RST might solve the problemof keeping track of the intentional and informational34structure simultaneously.But this would work only if the various discourse rela-tions about intentions and information could simultane-ously hold in a consistent knowledge base (KB).
Mooreand Pollack (1992) show via discourse (2) that the cur-rent commitment to the nucleus-satellite distinction inRST precludes this.(2)a.
Let's go home by 5.b.
Then we can get to the hardware storebefore it closes.c.
That way we can finish the bookshelves tonight.From an intentional perspective, (2b) is a satellite to(2a) via Motivation.
From an informational perspec-tive, (2a) is a satellite to (2b) via Condition.
Thesetwo structures are incompatible.
So augmenting rtsTwith a nonmonotonic logic for inferring rhetorical rela-tions would not yield a representation of (2) on multiplelevels in which both intentional and informational re-lations are represented.
In SDRT, on the other hand,not all discourse relations induce subordination, andso there is more scope for different discourse relationsholding simultaneously in a consistent KB.Grosz and Sidner's (1986) model of discourse inter-pretation is one where the same discourse lements arerelated simultaneously on the informational and inten-tional levels.
But using their framework to model (1) isnot straightforward.
As Grosz and Sidner (1990) pointout: "any model (or theory) of the communication sit-uation must distinguish among beliefs and intentionsof different agents," but theirs does not.
They repre-sent intentional structure as a stack of propositions, anddifferent attitudes aren't distinguished.
The informalanalysis of (1) above demands uch distinctions, how-ever.
For example, analysing (1) under Context 3 re-quires a representation f the following statement: sinceA has provided a reason why (lb) is true, he must wantI to believe that ( lb) is true.
It 's unclear how Groszand Sidner would represent this.
SDRT (hsher, 1993) isin a good position to be integrated with a theory of cog-nitive states, because it uses the same basic structures(discourse representation structures or DRSs) that havebeen used in Discourse Representation Theory (DRT)to represent different attitudes like beliefs and desires(Kamp 1981, Asher 1986, 1987, Kamp 1991, Asher andSingh, 1993).A BR IEF  INTRODUCTION TOSDRT AND DICEIn SDRT (Asher, 1993), an NL text is represented by asegmented DRS (SDRS), which is a pair of sets contain-ing: the DRSS or SDRSs representing respectively sen-tences and text segments, and discourse relations be-tween them.
Discourse relations, modelled after thoseproposed by Hobbs (1985), Polanyi (1985) and Thomp-son and Mann (1987), link together the constituents ofan SDRS.
We will mention three: Narration, Result andEvidence.?
SDRSS have a hierarchical configuration, and SDRTpredicts points of attachment in a discourse structurefor new information.
Using DICE we infer from thereader's knowledge resources which discourse relationshould be used to do attachment.Lascarides and Asher (1991) introduce default rulesrepresenting the role of Gricean pragmatic maxims anddomain knowledge in calculating the value of the up-date function (r, a, fl), which means "the representationfl of the current sentence is to be attached to a with adiscourse relation, where a is an open node in the repre-sentation r of the text so far".
Defaults are representedby a condit ional--?
> ?
means 'if ?, then normally ?.For example, Narration says that by default Narrationrelates elements in a text.?
Narrat ion:  (v, c~,/3) > garration(c~,/3)Associated axioms show how Narration affects the tem-poral order of the events described: Narration and thecorresponding temporal axioms on Narration predictthat normally the textual order of events matches theirtemporal order.The logic on which DICE rests is Asher and Mor-reau's (1991) Commonsense Entailment (CE).
Two pat-terns of nonmonotonic inference are particularly rele-vant here.
The first is Defeasible Modus PontEs: if onedefault rule has its antecedent verified, then the con-sequent is nonmonotonically inferred.
The second isthe Penguin Principle: if there are conflicting defaultrules that apply, and their antecedents are in logicalentailment relations, then the consequent of the rulewith the most specific antecedent is inferred.
Lascaridesand Asher (1991) use DICE to yield the discourse struc-tures and temporal structures for simple discourses.But the theory has so far ignored how A's intentionalstructure--or more accurately, I 's  model of A's inten-tional structure--influences I ' inferences about the do-main and the discourse structure.ADDING INTENTIONSTo discuss intentional structure, we develop a languagewhich can express beliefs, intentions and desires.
Foblowing Bratman (forthcoming) and Asher and Singh(1993), we think of the objects of attitudes either asplans or as propositions.
For example, the colloquialintention to do something--l ike wash the dishes--willbe expressed as an intention toward a plan, whereasthe intention that Sue be happy is an intention towarda proposition.
Plans will just consist of sequences of ba-sic actions al; a2; .
.
.
;an.
Two operators--7~ for aboutto do or doing, and 7:) for having done--will convert ac-tions into propositions.
The attitudes we assume in ourmodel are believes (BA?
means 'A believes ?
'), wants(WA?
means 'A wants ?
'), and intends (ZA?
means'A intends ?').
All of this takes place in a modal, dy-namic logic, where the propositional attitudes are sup-plied with a modal semantics.
To this we add the modalconditional operator >, upon Which the logic of DICE is35based.Let's take a closer look at (1) in Context 1.
Let thelogical forms of the sentences ( la) and (lb) be respec-tively a and/3.
In Context 1, I believes that A wantsto convince him of/3 and thinks that he doesn't believealready.
Following the DRT analysis of attitudes, weassume I 's  cognitive state has embedded in it a modelof A's cognitive state, which in turn has a represen-tation of I 's  cognitive state.
So )'VABI/3 and BA~BI/3hold in I 's  KB.
Furthermore, (v, (~,/3) A Info(c~,/3) holdsin I 's  KB, where Info(a,/3) is a gloss for the seman-tic content of a and /~ that I knows about )  I mustnow reason about what A intended by his particulardiscourse action.
I is thus presented with a classicalreasoning problem about attitudes: how to derive whata person believes, from a knowledge of what he wantsand an observation of his behaviour.
The classic meansof constructing such a derivation uses the practical syl-logism, a form of reasoning about action familiar sinceAristotle.
It expresses the following maxim: Act so asto realize your goals ceteris paribus.The practical syllogism is a rule of defeasible reason-ing, expressible in CE by means of the nonmonotonicconsequence r lation ~.
The consequence r lation 0~?can be stated directly in the object language of CE bya formula which we abbreviate as ~?,  ?)
(Asher 1993).We use 2_(?, ?)
to state the practical syllogism.
First,we define the notion that the KS and ?, but not the KBalone, nonmonotonically yield ?
:* Definition:?)
I(KB A ?, ?)
^  I(KB, ?
)The Practical Syllogism says that if (a) A wants ?
butbelieves it's not true, and (b) he knows that if g, wereadded to his KB it would by default make ?
true even-tually, then by default A intends ?.
* The Practical Syllogism:(a) (WA(?)
A(b) BA(3Cb(?, evenfually(?))))
>(c)The Practical Syllogism enables.I to reason about A'scognitive state.
In Context 1, when substituting in thePractical Syllogism BI/3 for ?, and (r, c~,/3) A Info(oq j3)for ?, we find that clause (a) of the antecedent to thePractical Syllogism is verified.
The conclusion (c) isalso verified, because I assumes that A's discourse actwas intentional.
This assumption could be expressedexplicitly as a >-rule, but we will not do so here.Now, abduction (i.e., explanatory reasoning) as wellas nonmonotonic deduction is permitted on the Prac-tical Syllogism.
So from knowing (a) and (c), I canconclude the premise (b).
We can state in cE an 'ab-ductive' rule based on the Practical Syllogism:* The hbductive Practical Syl logism I (APSl)(}/~\]A(?)
A ~A(~?)
A ~'A(?))
>BA (:1?b(?, evenLually(?
)))1This doesn't necessarily include that House Bill 1711 isbad for big business.hPsl  allows us to conclude (b) when (a) and (c) ofthe Practical Syllogism hold.
So, the intended action?
must be one that A believes will eventually make ?true.When we make the same substitutions for ?
and!/' in APSl as before, I will infer the conclusion ofAPS1 via Defeasible Modus Ponens: BA(J.kb((r, 0~,/3) ^Info(cq/3), eventually(B1~3))).
That is, I infers that Abelieves that, by uttering what he did, I will come tobelieve/3.In general, there may be a variety of alternatives thatwe could use to substitute for ?
and ?
in APSl, in agiven situation.
For usually, there are choices on whatcan be abduced.
The problem of choice is one thatHobbs e~ hi.
(1990) address by a complex weightingmechanism.
We could adopt this approach ere.The Practical Syllogism and APS 1 differ in two impor-tant ways from the DICE axioms concerning discourserelations.
First, APS1 is motivated by an abductiveline of reasoning on a pattern of defeasible reasoninginvolving cognitive states.
The DICE axioms are not.Secondly, both the Practical Syllogism and hPsl  don'tinclude the discourse update function (r, c~,/3) togetherwith some information about the semantic ontent of aand/3 in the antecedent, while this is a standard featureof the DICE axioms for inferring discourse structure.These two differences distinguish reasoning about in-tentional structures and discourse structures.
But dis-course structure is linked to intentional structure in thefollowing way.
The above reasoning with A's cognitivestate has led I to conclusions about the discourse func-tion of ~.
Intuitively, a was uttered to support /3, ora 'intentionally supports' /3.
This idea of intentionalsupport is defined in DICE as follows:* Intends to  Support:Isupport(c~, fl) ~-* (WA(B,~3) A BA(-~13,~) ABA (~bh((r ,  ~,/3)hInfo(~,/3), even*ually( B1/3) ) )In words, a intentionally supports \]3 if and only if Awants I to believe /3 and doesn't think he does so al-ready, and he also believes that by uttering a and /3together, so that I is forced to reason about how theyshould be attached with a rhetorical relation, I willcome to believe/3.Isupport(a,/3) defines a relationship between a and/3at the discourse structural level, in terms of I 's  and A'scognitive states.
With it we infer further informationabout the particular discourse relation that I shoulduse to attach /3 to c~.
Isupport(ot,/3) provides the linkbetween reasoning about cognitive states and reasoningabout discourse structure.Let us now return to the interpretation of (1) underContext 1.
I concludes Isupport(o~,/3), because the righthand side of the *-*-condition in Intends to Support issatisfied.
So I passes from a problem of reasoning aboutA's intentional structure to one of reasoning about dis-course structure.
Now, I should check to see whethero" actually does lead him to believe/3.
This is a checkon the coherence of discourse; in order for an SDRS r to36be coherent, the discourse relations predicated of theconstituents must be satisfiable.
2 Here, this amountsto justifying A's belief that given the discourse contextand I 's  background beliefs of which A is aware, I willarrive at the desired conclusion--that he believes ft. So,I must be able to infer a particular discourse relation Rbetween a and fl that has what we will call the BeliefProperty: (Bin A R(a, fl)) > /~1fl.
That is, R must bea relation that would indeed license I 's  concluding flfrom a.We concentrate here for illustrative purposes ontwo discourse relations with the Belief Property:Result(a, fl) and Evidence(a, fl); or in other words, aresults in fl, or a is evidence for ft.* Re la t ions  with the Be l ie f  P roper ty :(B,c~ A Evidence(a, fl)) > ~.~I~(t31a ^  Result(a, fl)) > &flThe following axiom of Cooperation captures theabove reasoning on I 's  part: if a Isupports fl, then itmust be possible to infer from the semantic content,that either Result(a, fl) or Evidence(a, fl) hold:?
Cooperat ion  :(:l&.b((r, a, fl) A \[nfo(a, fl), Resull(a, fl))V~b((r ,  a, fl) A Info(a, fl), Evidence(a, fl)))The intentional structure of A that I has inferred hasrestricted the candidate set of discourse relations thatI can use to attach fl to a: he must use Result or Evi-dence, or both.
If I can't accommodate A's intentionsby doing this, then the discourse will be incoherent.We'll shortly show how Cooperation contributes to theexplanation of why (3) is incoherent.(3)a.
George Bush is a weak-willed president.b.
?He's sure to veto House Bill 1711.FROM INTENTIONS TOINFORMATION:CONTEXTS 1 AND 2The axioms above allow I to use his knowledge of A'scognitive state, and the behaviour of A that he observes,to (a) infer information about A's communicative inten-tions, and (b) consequently to restrict the set of candi-date discourse relations that are permitted between theconstituents.
According to Cooperation, I must inferthat one of the permitted discourse relations does in-deed hold.
When clue words are lacking, the semanticcontent of the constituents must be exploited.
In cer-tain cases, it's also necessary to infer further informa-tion that wasn't explicitly mentioned in the discourse,2Asher (1993) discusses this point in relation to Con-trast: the discourse marker butis used coherently only if thesemantic ontent of the constituents it connects do indeedform a contrast: compare Mary's hair is black but her eyesare blue, with ?Mary's hair is black but John's hair i.~ black.in order to sanction the discourse relation.
For exam-ple, in (1) in Contexts 1 and 2, I infers the bill is badfor big business.Consider again discourse (1) in Context 1.
Intu-itively, the reason we can infer Result(a, fl) in the anal-ysis of (1) is because (i) a entails a generic (Bush vetoesbills that are bad for big business), and (ii) this genericmakes fl true, as long as we assume that House Bill1711 is bad for big business.To define the Result Rule below that captures thisreasoning for discourse attachment, we first define thisgeneric-instance r lationship: instance(e, ?)
holds justin case ?
is (Vx)(A(x) > B(x)) and ?
is A\[x/a~AB\[x/a~.For example, bird(tweety) Afly(tweety) (Tweety is a birdand Tweety flies) is an instance of Vx(bird(x) > fly(x))(Birds fly).The Result Rule says that if (a) fl is to be attached toa, and a was intended to support fl, and (b) a entails ageneric, of which fl and 6 form an instance, and (c) 6 isconsistent with what A and I believe, 3 then normally,6 and Result(a, fl) are inferred.?
The  Resu l t  Ru le :(a) ((r, a, fl) A Isupport(a, fl)A(b) ~b^T(a, ?
)^ ~b^~^~(fl, ?)
^  instance(e, ?
)^(c) co,sistent(KBi U ~BA U 6))> (Res.tt(a, fl) ^  6)The Result Rule does two things.
First, it allows us toinfer one discourse relation (Result) from those permit-ted by Cooperation.
Second, it allows us to infer a newpiece of information 6, in virtue of which Result(a, fl)is true.We might want further constraints on 6 than that in(c); we might add that 6 shouldn't violate expectationsgenerated by the text.
But note that the Result Ruledoesn't choose between different tfs that verify clauses(b) and (c).
As we've mentioned, the theory needs tobe extended to deal with the problem of choice, andit may be necessary to adopt strategies for choosingamong alternatives, which take factors other than logi-cal structure into account.We have a similar rule for inferring Evidence(fl, a)("fl is evidence for a") .
The Evidence rule resemblesthe Result Rule, except that the textual order of thediscourse constituents, and the direction of intentionalsupport changes:* The  Ev idence  Ru le :(a) (if, a, fl) ^ Isuppo~t(fl, a)^(b) ~,b^,(a, ?
)^ ~b^~^~(~, ~) ^  instance(e, ~)^(c) consistent(Ks~ UKSA U6))> (E, idence(Z, a) ^  6)We have seen that clause (a) of the Result Rule is sat-isfied in the analysis of (1) in Context 1.
Now, let 6 bethe proposition that the House Bill 1711 is bad for big3Or, more accurately, ~i must be consistent with what Ihimself believes, and what he believes that A believes.
Inother words, KBA is I'$ model of A's KB.37business (written as bad(1711)).
This is consistent withKBI U KBA, and so clause (c) is satisfied.
Clause (b)is also satisfied, because (i) a entails Bush vetoes billsthat are bad for big business--i.e., : l~B^r(a,  ?)
holds,where ?
is Vx((bill(x) A bad(z)) > veto(bush, x)); (it)fl ^/ i  is bill(1711) A veto(bush, 1711) A bad(1711); andso (iii) instance(?,fl A/i) and IKB^T^~(fl, fl A 6) bothhold.So, when interpreting (1) in Context 1, two rules ap-ply: Narration and the Result Rule.
But the consequentof Narration already conflicts with what is known; thatthe discourse relation between a and fl must satisfy theBelief Property.
So the consequent of the Result Rule isinferred: /i (i.e., House Bill 1711 is bad for big business)and Result(a, fl) .4These  rules show how (1) can make the knowledgethat the house bill is bad for big business moot.
; onedoes not need to know that the house bill is bad forbig business prior to attempting discourse attachment.One can infer it at the time when discourse attachmentis attempted.Now suppose that we start from different premises, asprovided by Context 2: BABIfl, BA~BI a and )/VABIa.That is, I thinks A believes that I believes Bush willveto the bill, and I also thinks that A wants to con-vince him that Bush supports big business.
Thenthe 'intentional' line of reasoning yields different re-sults from the same observed behaviour--A's  utter-ance of (1).
Using APSl again, but substituting B iafor ?
instead of B1fl, I concludes BA(I-kb((r,a,fl) AI fo(a, fl), eve t any(B a)).
So Is vVo t (fl, a) holds.Now the antecedent to Cooperation is verified, and soin the monotonic omponent of cE, we infer that a andfl must be connected by a discourse relation R' suchthat (B1fl A R'(a, fl)) > Bla.
As before, tiffs restrictsthe set of permitted discourse relations for attaching/?
to a.
But unlike before, the textual order of a andfl, and their direction of intentional support mismatch.The rule that applies this time is the Evidence Rule.Consequently, a different discourse relation is inferred,although the same information/ i - - that  House Bill 1711is bad for big business--supports the discourse relation,and is also be inferred.In contrast, the antecedents of the Result and Evi-dence Rules aren't verified in (3).
Assuming I knowsabout the legislative process, he knows that if GeorgeBush is a weak willed president, then normally, he won'tveto bills.
Consequently, there is no /i that is consis-tent with his KB, and sanctions the Evidence or Resullrelation.
Since I cannot infer which of the permitteddiscourse relations holds, and so by contraposing theaxiom Cooperation, a doesn't Isupport ft. And so I hasfailed to conclude what A intended by his discourse ac-tion.
It can no longer be a belief that it will eventually4We could have a similar rule to the Result Rule forinferring Evidence(a, fl) in this discourse context oo.SGiven the new KB, the antecedent of APSl would nolonger be verified if we substituted ?
with Blfl.lead to I believing fl, because otherwise Isupport(a, fl)would be true via the rule Intends To Support.
Conse-quently, I cannot infer what discourse relation to use inattachment, yielding incoherence.FROM INFORMATION TOINTENTIONS:CONTEXT 3Consider the interpretation of (1) in Context 3: I hasno knowledge of A's communicative intentions prior towitnessing his linguistic behaviour, but he does knowthat the House Bill 1711 is bad for big business.
I hassufficient information about the semantic ontent of aand fl to infer Result(a, fl), via a rule given in Lascaridesand Asher (1991):?
Result(if, a, fl) ^ fl)) > ResetS(a, fl)Resull(a, fl) has the Belief Property, and I reasons thatfrom believing a, he will now come to believe ft. Havingused the information structure to infer discourse struc-ture, I must now come to some conclusions about A'scognitive state.Now suppose that BABIa is in I ' s  KS.
Then thefollowing principle of Charity allows I to assume that Awas aware that I would come to believe fl too, throughdoing the discourse attachment he did:?
Charity: BI?
> BABI?This is because I has inferred Result(a, fl), and sinceResult has the belief property, I will come to believe flthrough believing a; so substituting fl for ?
in Charity,BAI3Ifl will become part of I 's  KB via Defeasible ModusPonens.
So, the following is now part of I 's  KB:BA( \[-kb((V, a, fl) ^ Info(a, fl)), eventually(Blfl)).
Fur-thermore, the assumption that A's discourse behaviourwas intentional again yields the following as part ofI's Km 7A((V, a, fl) A Info(a, fl)).
So, substituting BIfland (r, a, fl) A Info(a, fl) respectively for ?
and ?
intothe Practical Syllogism, we find that clause (b) of thepremises, and the conclusion are verified.
Explanatoryreasoning on the Practical Syllogism this time permitsus to infer clause (a): A's communicative goals were toconvince I of fl, as required.The inferential mechanisms going from discoursestructure to intentional structure are much less wellunderstood.
One needs to be able to make some sup-positions about the beliefs of A before one can inferanything about his desires to communicate, and thisrequires a general theory of commonsense belief attri-bution on tile basis of beliefs that one has.IMPERATIVES ANDPLAN UPDATESThe revision of intentional structures exploits modes ofspeech other than the assertoric.
For instance, consideranother discourse from Moore and Pollack (1992):38(2)a.
Let's go home by 5.b.
Then we can get to the hardware storebefore it closes.c.
That way we can finish the bookshelves tonight.Here, one exploits how the imperative mode affectsreasoning about intentions.
Sincere Ordering capturesthe intuition that i fA orders a, then normally he wantsa to be true; and Wanting and Doing captures the in-tuition that if A wants a to be true, and doesn't hinkthat it's impossible to bring a about, then by defaulthe intends to ensure that c~ is brought about, either bydoing it himself, or getting someone lse to do it (cf.Cohen and Levesque, 1990a).
* Sincere Ordering:>?
Wanting and Doing:(~VA~ A ~BA~eventually(7~)) > ZA(~)These rules about A's intentional structure help usanalyse (2).
Let the logical forms of (2a-c) be respec-tively or, /3 and 7- Suppose that we have inferred bythe linguistic clues that Result(o~,13) holds.
That is,the action a (i.e., going home by 5pro), results in /3(i.e., the ability to go to the hardware store before itcloses).
Since (~ is an imperative, Defeasible Modus Po-nens on Sincere Ordering yields the inference that )/VA c~is true.
Now let us assume that the interpreter I be-lieves that the author A doesn't believe that c~'s beingbrought about is impossible.
Then we may use Defea-sible Modus Ponens again on Wanting and Doing, toinfer ZA(Tia).
Just how the interpreter comes to thebelief, that the author believes c~ is possible, is a com-plex matter.
More than likely, we would have to encodewithin the extension of DiCE we have made, principlesthat are familiar from autoepistemic reasoning.
We willpostpone this exercise, however, for another time.Now, to connect intentions and plans with discoursestructure, we propose a rule that takes an author's useof a particular discourse structure to be prima facieevidence that the author has a particular intention.
Therule Plan Apprehension below, states that if ~ is a planthat A intends to do, or get someone lse to do, andhe states that 6 is possible as a Result of this action c~,then the interpreter may normally take the author A toimply that he intends 6 as well.?
Plan Apprehension:(nesult(~, t3) A ZA(~)  A/3 = can(6)) > ZA(r-(~; 6))We call this rule Plan Apprehension, to make clear thatit furnishes one way for the interpreter of a verbal mes-sage, to form an idea of the author's intentions, on thebasis of that message's discourse structure.Plan Apprehension uses discourse structure to at-tribute complex plans to A.
And when attaching/3 to~, having inferred Result(a, 13), this rule's antecedent isverified, and so we infer that 6--which in this case is togo to the hardware store before it closes--as part of A'splan, which he intends to bring about, either himself,or by getting another agent to do it.Now, we process 7- That way in 3' invokes ananaphoric reference to a complex plan.
By the acces-sibility constraints in SDRT, its antecedent must \[a; 6\],because this is the only plan in the accessible discoursecontext.
So 7 must be the DKS below: as a result of do-ing this plan, finishing the bookshelves (which we havelabelled e) is possible:(7)Result(\[a;Now, substituting \[c~; ~\] and e for a and fl into thePlan Apprehension Rule, we find that the antecedent tothis rule is verified again, and so its consequent is non-monotonically inferred: Za(T~(a; 6; e)).
Again, I hasused discourse structure to attribute plans to A.Moore and Pollack (1992) also discuss one of I 's  pos-sible responses to (2):(4)We don't need to go to the hardware store.I borrowed a saw from Jane.Why does I respond with (4)?
I has inferred the ex-istence of the plan \[~r; 6; el via Plan Apprehension; so hetakes the overall goal of A to be e (to finish the book-shelves this evening).
Intuitively, he fills in A's planwith the reason why going to the hardware store is asubgoal: I needs a saw.
So A's plan is augmented withanother subgoal ~, where ~ is to buy a saw, as follows:Za(7~.\[c~;6;~;e\]).
But since ~ holds, he says this andassumes that this means that A does not have to do c~and 6 to achieve ~.
To think about this formally, weneed to not only reason about intentions but also howagents update their intentions or revise them when pre-sented with new information.
Asher and Koons (1993)argue that the following schema captures part of thelogic which underlies updating intentions:?
VpdateZa(n\[al;... ; Z ) (a l ; .
.
.
; aS)In other words, if you're updating your intentions todo actions al  to ~, ,  and a l  to c U are already done,then the new intentions are to do otj+t to an, and youno longer intend to do a l  to aj .The question is now: how does this interact with dis-course structure?
I is attempting to be helpful to A;he is trying to help realize A's goal.
We need axioms tomodel this.
Some key tools for doing this have been de-veloped in the past couple of decades--belief revision,intention and plan revision--and the long term aimwould be to enable formM theories of discourse struc-ture to interact with these formal theories of attitudesand attitude revision.
But since a clear understand-ing of how intentions are revised is yet to emerge, anyspeculation on the revision of intentions in a particulardiscourse context seems premature.39CONCLUSIONS ANDFURTHER WORKWe have argued that it is important to separate reason-ing about mental states from reasoning about discoursestructure, and we have suggested how to integrate aformal theory of discourse attachment with common-sense reasoning about the discourse participants' cog-nitive states and actions.We exploited a classic principle of commonsense rea-soning about action, the Practical Syllogism, to modelI's inferences about A's cognitive state during discourseprocessing.
We also showed how axioms could be de-fined, so as to enable information to mediate betweenthe domain, discourse structure and communicative in-tentions.Reasoning about intentional structure took a differ-ent form from reasoning about discourse attachment,in that explanatory reasoning or abduction was per-mitted for the former but not the latter (but cf.
Hobbset al 1990).
This, we argued, was a principled reasonfor maintaining separate representations of intentionalstructure and discourse structure, but preserving closelinks between them via axioms like Cooperation.
Coop-eration enabled I to use A's communicative intentionsto reason about discourse relations.This paper provides an analysis of only very simplediscourses, and we realise that although we have in-troduced distinctions among the attitudes, which wehave exploited uring discourse processing, this is onlya small part of the story.Though DICE has used domain specific informationto infer discourse relations, the rules relate domainstructure to discourse structure in at best an indirectway.
Implicitly, the use of the discourse update fimction(v, c~, ~) in the DICE rules reflects the intuitively obviousfact that domain information is filtered through the cog-nitive state of A.
To make this explicit, the discoursecommunity should integrate work on speech acts andattitudes (Perrault 1990, Cohen and Levesque 1990a,1990b) with theories of discourse structure.
In futurework, we will investigate discourses where other axiomslinking the different attitudes and discourse structureare important.REFERENCESAsher, Nicholas (1986) Belief in Discourse Representa-tion Theory, Journal of Philosophical Logic, 15, 127-189.Asher, Nicholas (1987) A Typology for AttitudeVerbs, Linguistics and Philosophy, 10, pp125-197.Asher, Nicholas (1993) Reference to Abstract Objectsin Discourse, Kluwer Academic Publishers, Dordrecht,Holland.Asher, Nicholas and Koons, Robert (1993) The Revi-sion of Beliefs and Intentions in a Changing World, inPrecedings of the hal Spring Symposium Series: Rea-soning about Mental States: Formal Theories and Ap-plications.Asher, Nicholas and Morreau, Michael (1991) Com-mon Sense Entailment: A Modal Theory of Nonmono-tonic Reasoning, in Proceedings to the 12th Interna-tional Joint Conference on Artificial Intelligence, Syd-ney Australia, August 1991.Asher, Nicholas and Singh, Munindar (1993) ALogic of Intentions and Beliefs, Journal of PhilosophicalLogic, 22 5, pp513-544.Bratman, Michael (forthcoming) Intentions, Plansand Practical Reason, Harvard University Press, Cam-bridge, Mass.Cohen, Phillip R. and Levesque, Hector J.
(1990a)Persistence, Intention, and Commitment, In Philip R.Cohen, Jerry Morgan and Martha E. Pollack (editors)Intentions in Communication, pp33-69.
Cambridge,Massachusetts: Bradford/MIT Press.Cohen, Phillip R. and Levesque, Hector J.
(1990b)Rational Interaction and the Basis for Communica-tion, In Philip R. Cohen, Jerry Morgan and Martha E.Pollack (editors) Intentions in Communication, pp221-256.
Cambridge, Massachusetts: Bradford/MIT Press.Grosz, Barbara J. and Sidner, Candice L. (1986)Attention, Intentions and the Structure of Discourse.Computational Linguistics, 12, 175-204.Grosz, Barbara J. and Sidner, Candice L. (1990)Plans for Discourse.
In Philip R. Cohen, Jerry Morganand Martha E. Pollack (editors) Intentions in Com-munication, pp417-444.
Cambridge, Massachusetts:Bradford/MIT Press.Hobbs, Jerry R. (1985) On the Coherence and Struc-ture of Discourse.
Report No: CSLI-85-37, Center forthe Study of Language and Information, October 1985.Kamp, tlans (1981) A Theory of Truth and SemanticRepresentation, i  Groenendijk, J.
A. G., Janssen, T.M.
V., and Stokhof, M. B. J.
(eds.)
Formal Methods inthe Study of Language, 277-332.Kamp, Hans (1991) Procedural and Cognitive As-pects of Propositional Attitude Contexts, Lecture Notesfrom the Third European Summer School in Language,Logic and Information, Saarbriicken, Germany.Lascarides, Alex and Asher, Nicholas (1991) Dis-course Relations and Defeasible Knowledge, in Proceed-ings of the ?o9th Annual Meeting of Computational Lin-guistics, 55-63, Berkeley California, USA, June 1991.Lascarides, Alex and Asher, Nicholas (1993a) Tempo-ral Interpretation, Discourse Relations and Common-sense Entailment, in Linguistics and Philosophy, 16,pp437-493.Lascarides, Alex and Asher, Nicholas (1993b) A Se-mantics and Pragmatics for the Pluperfect, in Pro-ceedings of the European Chapter of the Associationfor Computational Linguistics (EACL93), pp250-259,Utrecht, The Netherlands.Lascarides, Alex, Asher, Nicholas and Oberlander,Jon (1992) Inferring Discourse Relations in Context, inProceedings of the 30th Annual Meeting of the Asso-40ciation of Computational Linguistics, ppl-8, DelawareUSA, June 1992.Lascarides, Alex and Oberlander, Jon (1993) Tempo-ral Connectives in a Discourse Context, in Proceedingsof the European Chapter of the Association for Com-putational Linguistics (EACL93), pp260-268, Utrecht,The Netherlands.Moore, Johanna and Pollack, Martha (1992) A Prob-lem for RST: The Need for Multi-Level Discourse Anal-ysis Computational Linguistics, 18 4, pp537-544.Perrault, C. Ray (1990) An Application of DefaultLogic to Speech Act Theory, in Philip R. Cohen,Jerry Morgan and Martha E. Pollack (editors) h~ten-tions in Communication, pp161-185.
Cambridge, Mas-sachusetts: Bradford/MIT Press.Polanyi, Livia (1985) A Theory of Discourse Struc-ture and Discourse Coherence, in Eilfor, W.
It., Kroe-bet, P. D., and Peterson, K. L., (eds), Papers from theGeneral Session a the Twenty-First Regional Meeting ofthe Chicago Linguistics Society, Chicago, April 25-27,1985.Thompson, Sandra and Mann, William (1987)Rhetorical Structure Theory: A Framework for theAnalysis of Texts.
In IPRA Papers in Pragrnatics, 1,79-105.41
