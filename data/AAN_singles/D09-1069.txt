Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 658?667,Singapore, 6-7 August 2009. c?2009 ACL and AFNLPCan Chinese Phonemes Improve Machine Transliteration?
:A Comparative Study of English-to-Chinese Transliteration ModelsJong-Hoon Oh, Kiyotaka Uchimoto, and Kentaro TorisawaLanguage Infrastructure Group, MASTAR Project,National Institute of Information and Communications Technology (NICT)3-5 Hikaridai Seika-cho, Soraku-gun, Kyoto 619-0289 Japan{rovellia,uchimoto,torisawa}@nict.go.jpAbstractInspired by the success of Englishgrapheme-to-phoneme research in speechsynthesis, many researchers have pro-posed phoneme-based English-to-Chinesetransliteration models.
However, such ap-proaches have severely suffered from theerrors in Chinese phoneme-to-graphemeconversion.
To address this issue,we propose a new English-to-Chinesetransliteration model and make system-atic comparisons with the conventionalmodels.
Our proposed model relies onthe joint use of Chinese phonemes andtheir corresponding English graphemesand phonemes.
Experiments showed thatChinese phonemes in our proposed modelcan contribute to the performance im-provement in English-to-Chinese translit-eration.1 Introduction1.1 MotivationTransliteration, i.e., phonetic translation, is com-monly used to translate proper names and techni-cal terms across languages.
A variety of English-to-Chinese machine transliteration models hasbeen proposed in the last decade (Meng et al,2001; Gao et al, 2004; Jiang et al, 2007; Leeand Chang, 2003; Li et al, 2004; Li et al, 2007;Wan and Verspoor, 1998; Virga and Khudanpur,2003).
They can be categorized into those basedon Chinese phonemes (Meng et al, 2001; Gaoet al, 2004; Jiang et al, 2007; Lee and Chang,2003; Wan and Verspoor, 1998; Virga and Khu-danpur, 2003) and those that don?t rely on Chinesephonemes (Li et al, 2004; Li et al, 2007).Inspired by the success of English grapheme-to-phoneme research in speech synthesis, many re-searchers have proposed phoneme-based English-to-Chinese transliteration models.
In these ap-proaches, Chinese phonemes are generated fromEnglish graphemes or phonemes, and then theChinese phonemes are converted into Chinesegraphemes (or characters), where Chinese Pinyinstrings1 are used for representing a syllable-levelChinese phoneme sequence.
Despite its high ac-curacy in generating Chinese phonemes from En-glish, this approach has severely suffered from er-rors in Chinese phoneme-to-grapheme conversion,mainly caused by Chinese homophone confusion?
one Chinese Pinyin string can correspond to sev-eral Chinese characters (Li et al, 2004).
For ex-ample, the Pinyin string ?LI?
corresponds to suchdifferent Chinese characters as,, and.
Forthis reason, it has been reported that English-to-Chinese transliteration without Chinese phonemesoutperforms that with Chinese phonemes (Li et al,2004).Then ?Can Chinese phonemes improveEnglish-to-Chinese transliteration, if we can re-duce the errors in Chinese phoneme-to-graphemeconversion??
Our research starts from thisquestion.1.2 Our ApproachPrevious approaches using Chinese phonemeshave relied only on Chinese phonemes in Chi-nese phoneme-to-grapheme conversion.
However,the simple use of Chinese phonemes doesn?t al-ways provide a good clue to reduce the ambi-guity in Chinese phoneme-to-grapheme conver-sion.
Let us explain with an example, the Chinesetransliteration of Greeley in Table 1, where Chi-nese phonemes are represented in terms of Chi-nese Pinyin strings and English phonemes are rep-resented by ARPAbet symbols2.In Table 1, Chinese Pinyin string ?LI?
corre-sponds to two different Chinese characters, and1Pinyin, the most commonly used Romanization sys-tem for Chinese characters, faithfully represents Chinese658Table 1: Chinese Pinyin string ?LI?
and its corre-sponding Chinese characters in Chinese transliter-ation of GreeleyEnglish grapheme g ree leyEnglish phoneme G R IY L IYChinese Pinyin GE LI LIChinese character   .
It seems difficult to find evidence for select-ing the correct Chinese character corresponding toeach Chinese Pinyin string ?LI?
by just lookingat the sequence of Chinese Pinyin strings ?GE LILI.?
However, English graphemes (ree and ley) orphonemes (?R IY?
and ?L IY?)
corresponding toChinese Pinyin string ?LI?, especially their conso-nant parts (r and l in the English graphemes and?R?
and ?L?
in the English phonemes), providestrong evidence to resolve the ambiguity.
Thus,we can easily find rules for the conversion fromChinese Pinyin string ?LI?
to and as follows:?
?
?R IY?, LI ?
??
?
?L IY?, LI ?
?Based on the observation, we propose anEnglish-to-Chinese transliteration model based onthe joint use of Chinese phonemes and their corre-sponding English graphemes and phonemes.
Wedefine a set of English-to-Chinese transliterationmodels and categorize them into the followingthree classes:?
MI: Models Independent of Chinesephonemes?
MS: Models based on Simple use of Chinesephonemes?
MJ: Models based on Joint use of Chi-nese phonemes and English graphemes andphonemes that correspond to our proposedmodel.Our comparison among the three types of translit-eration models can be summarized as follows.?
The MImodels relying on either Englishgraphemes or phonemes could not outper-form those based on both English graphemesand phonemes.phonemes and syllables (Yin and Felley, 1990).2http://www.cs.cmu.edu/?laura/pages/arpabet.ps?
The MSmodels always showed the worstperformance due to the severe error rate inChinese phoneme-to-grapheme conversion.?
The MJmodels significantly reduced er-rors in Chinese phoneme-to-grapheme con-version; thus they achieved the best perfor-mance.The rest of this paper is organized as follows.Section 2 introduces the notations used through-out this paper.
Section 3 describes the translitera-tion models we compared.
Section 4 describes ourtests and results.
Section 5 concludes the paperwith a summary.2 PreliminariesLet EGbe an English word composed of n Englishgraphemes, and let EPbe a sequence of Englishphonemes that represents the pronunciation of EG.Let CGbe a sequence of Chinese graphemes cor-responding to the Chinese transliteration of EG,and let CPbe a sequence of Chinese phonemesthat represents the pronunciation of CG.CPcorresponds to a sequence of the ChinesePinyin strings of CG.
Because a Chinese Pinyinstring represents the pronunciation of a sylla-ble consisting of consonants and vowels, we di-vide a Chinese Pinyin string into consonant andvowel parts like ?L+I?, ?L+I+N?, and ?SH+A.
?In this paper, we define a Chinese phonemeas the vowel and consonant parts in a ChinesePinyin string (e.g., ?L?, ?SH?, and ?I?).
A Chi-nese character usually corresponds to multipleEnglish graphemes, English phonemes, and Chi-nese phonemes (i.e.,  corresponds to Englishgraphemes ree, English phonemes ?R IY?, andChinese phonemes ?L I?
in Table 1).
To repre-sent these many-to-one correspondences, we usethe well-known BIO labeling scheme to representa Chinese character, where B and I represent thebeginning and inside/end of the Chinese charac-ters, respectively, and O is not used.
Each Chi-nese phoneme corresponds to a Chinese characterwith B and I labels.
For example, Chinese charac-ter ??
in Table 1 can be represented as ?:B?and ?:I?, where ?:B?
and ?:I?
correspondto Chinese phonemes ?L?
and ?I?, respectively.
Inthis paper, we define a Chinese grapheme as a Chi-nese character represented with a BIO label, e.g.,?:B?
and ?:I.?659Table 2: egiand its corresponding epi, cpi, and cgiin Greeley and its corresponding Chinese translit-eration ??i 1 2 3 4 5 6 7EGg r e e l e yEPG R IY ?
L IY ?CPGE L I ?
L I ?GE LI ?
LI ?CG:B :B :I ?
:B :I ?  ?
 ?Then EP, CP, and CGcan be segmented into aseries of sub-strings, each of which corresponds toan English grapheme in EG.
We can thus write?
EG= eg1, ?
?
?
, egn= egn1?
EP= ep1, ?
?
?
, epn= epn1?
CP= cp1, ?
?
?
, cpn= cpn1?
CG= cg1, ?
?
?
, cgn= cgn1where egi, epi, cpi, and cgirepresent the ithEnglish grapheme, English phonemes, Chinesephonemes, and Chinese graphemes correspondingto egi, respectively.Based on the definition, we model English-to-Chinese transliteration so that each Englishgrapheme is tagged with its corresponding En-glish phonemes, Chinese phonemes, and Chinesegraphemes.
Table 2 illustrates egi, epi, cpi, andcgiwith the same example listed in Table 1 (En-glish word Greeley and its corresponding Chinesetransliteration ??
)3, where ?
represents anempty string.3 Transliteration ModelWe defined eighteen transliteration models to becompared.
These transliteration models are clas-sified into three classes, MI, MS, andMJas de-scribed in Section 1.2; each class has three basictransliteration models and three hybrid ones.
Inthis section, we first describe the basic translit-eration models in each class by focusing on themain difference among the three classes and thendescribe the hybrid transliteration models.3We performed alignment between EGand EPand be-tween EPand CPin a similar manner presented in Li et al(2004).
Then the two alignment results were merged usingEPas a pivot.
Finally, we made a correspondence relationamong egi, epi, cpi, and cgiusing the merged alignment re-sult and the Pinyin table.3.1 Basic Transliteration ModelsThe basic transliteration models in each class aredenoted as M(x, y).?
(x, y) ?
X ?
Y?
x ?
X = {EG, EP, EGP}?
y ?
Y = {?, CP, JCP}x is an English-side parameter representing En-glish grapheme (EG), English phoneme (EP), andthe joint use of English grapheme and phoneme(EGP= ?EG, EP?)
that contributes to generat-ing Chinese phonemes or Chinese graphemes ina transliteration model.
y is a Chinese-phonemeparameter that represents a way of using Chinesephonemes to generate Chinese graphemes in atransliteration model.
Since M(x, ?)
representsa transliteration model that does not rely on Chi-nese phonemes, it falls intoMI, while M(x, CP)corresponds to a transliteration model in MSthatonly uses Chinese phonemes in Chinese phoneme-to-grapheme conversion.
M(x, JCP) is a translit-eration model in theMJclass that generates Chi-nese transliterations based on joint use of x andChinese phoneme CP, where x ?
X .
Thus,M(x, JCP) can be rewritten as M(x, ?x, CP?
),where the joint representation of x and CP,?x, CP?, is used in Chinese phoneme-to-graphemeconversion.
The three basic models inMJcan beinterpreted as follows:?
M(EG, JCP) = M(EG, ?EG, CP?)?
M(EP, JCP) = M(EP, ?EP, CP?)?
M(EGP, JCP) = M(EGP, ?EGP, CP?
)M(EG, JCP) directly converts Englishgraphemes into Chinese phonemes withoutthe help of English phonemes and then gener-ates Chinese transliterations based on the jointrepresentation of English graphemes and Chi-nese phonemes.
The main difference betweenM(EP, JCP) and M(EGP, JCP) lies in theuse of English graphemes to generate Chinesephonemes and graphemes.
English graphemesare only used in English grapheme-to-phonemeconversion, and English phonemes play a crucialrole for generating Chinese transliteration inM(EP, JCP).
Chinese phoneme-to-graphemeconversion that relies on the joint use of Englishgraphemes, English phonemes, and Chinese660PM(EG,JCP)(CG|EG) =?
?CPP (CP|EG)?
P (CG|EG, CP) (1)PM(EP,JCP)(CG|EG) =??CP?
?EPP (EP|EG)?
P (CP|EP)?
P (CG|EP, CP) (2)PM(EGP,JCP)(CG|EG) =??CP?
?EPP (EP|EG)?
P (CP|EG, EP)?
P (CG|EG, EP, CP) (3)PM(EG,CP)(CG|EG) =?
?CPP (CP|EG)?
P (CG|CP) (4)PM(EP,CP)(CG|EG) =??CP?
?EPP (EP|EG)?
P (CP|EP)?
P (CG|CP) (5)PM(EGP,CP)(CG|EG) =??CP?
?EPP (EP|EG)?
P (CP|EG, EP)?
P (CG|CP) (6)phonemes is the key feature of M(EGP, JCP).Because M(x, JCP) can be interpreted asM(x, ?x, CP?
), English-side parameter x de-termines the English graphemes and phonemes,or both jointly used with Chinese phonemes inChinese phoneme-to-grapheme conversion.
Thenwe can represent the three basic transliterationmodels as in Eqs.
(1)?
(3), where P (CG|EG, CP),P (CG|EP, CP), and P (CG|EG, EP, CP) are thekey points in our proposed models,MJ.The three basic transliteration models in MS?
M(EG, CP), M(EP, CP), and M(EGP, CP) ?are formulated as Eqs.
(4)?(6).
Chinese phoneme-based transliteration models in the literature fallinto either M(EG, CP) or M(EP, CP) (Meng etal., 2001; Gao et al, 2004; Jiang et al, 2007; Leeand Chang, 2003; Wan and Verspoor, 1998; Virgaand Khudanpur, 2003).
The three basic transliter-ation models inMSare identical as those inMJ,except for the Chinese phoneme-to-grapheme con-version method.
They only depend on Chinesephonemes in Chinese phoneme-to-grapheme con-version represented as P (CG|CP) in Eqs.
(4)?(6).PM(EG,?
)(CG|EG) = P (CG|EG) (7)PM(EP,?
)(CG|EG) (8)=?
?EPP (EP|EG)?
P (CG|EP)PM(EGP,?
)(CG|EG) (9)=?
?EPP (EP|EG)?
P (CG|EG, EP)The three basic transliteration models in MIarerepresented in Eqs.
(7)?(9).
Because theMImod-els are independent of Chinese phonemes, they arethe same as the transliteration models in the lit-erature used for machine transliteration from En-glish to other languages without relying on target-language phonemes (Karimi et al, 2007; Malik,2006; Oh et al, 2006; Sherif and Kondrak, 2007;Yoon et al, 2007).
Note that M(EG, ?)
is thesame transliteration model as the one proposed byLi et al (2004).3.2 Hybrid Transliteration ModelsThe hybrid transliteration models in each classare defined by discrete mixture between the prob-ability distribution of the two basic transliter-ation models, as in Eq.
(10) (Al-Onaizan andKnight, 2002; Oh et al, 2006), where 0 < ?
<1.
We denote a hybrid transliteration model be-tween two basic transliteration models M(x1, y)and M(x2, y) as M(x1+ x2, y, ?
), where y ?Y = {?, CP, JCP}, x16= x2, and x1, x2?X = {EG, EP, EGP}.
In this paper, we definethree types of hybrid transliteration models in eachclass: M(EG+ EP, y, ?
), M(EG+ EGP, y, ?
),and M(EP+ EGP, y, ?).PM(x1+x2,y,?
)(CG|EG) (10)= ?
?
PM(x1,y)(CG|EG)+ (1?
?)
?
PM(x2,y)(CG|EG)3.3 Probability EstimationBecause Eqs.
(1)?
(9) can be estimated in a similarway, we limit our focus to Eq.
(3) in this section.Assuming that P (EP|EG), P (CP|EG, EP), andP (CG|EG, EP, CP) in Eq.
(3) depend on the sizeof the context window, k (k = 3 in this paper),661Table 3: Feature functions for P (cgi|cgi?1i?k, ?eg, ep, cp?i+ki?k) with an example in Table 2, where i = 2f1gram3(egi) egi+2i= ?ree?
cgi= ?:B?f2pair11(cpi?1, cgi?1) cpi?1= ?G?, cgi?1= ?:B?
cgi= ?:B?f3pair12(cgi?1, cpi?1) cpii?1= ?GE L?, cgi?1= ?:B?
cgi= ?:B?f4pair22(cpi?1, cgi?2) egii?1= ?gr?, epii?1= ?G R?
cgi= ?:B?f5triple1(egi, cpi, cgi?1) egi= ?r?, cpi?1= ?GE?, cgi?1= ?:B?
cgi= ?:B?f6triple2(egi?1, cgi?1, cpi?1) egi?1= ?g?, cpii?1= ?GE L?, cgi?1= ?:B?
cgi= ?:B?they can be simplified into a series of products inEqs.
(11)?
(13).The maximum entropy model is used to esti-mate the probabilities in Eqs.
(11)?
(13) (Bergeret al, 1996).
Generally, a conditional maxi-mum entropy model is an exponential model thatgives the conditional probability, as described inEq.
(14), where ?iis the parameter to be estimatedand fi(a, b) is a feature function corresponding to?i(Berger et al, 1996; Ratnaparkhi, 1997):P (EP|EG) ?
?iP (epi|epi?1i?k, egi+ki?k) (11)P (CP|EG, EP) (12)?
?iP (cpi|cpi?1i?k, ?eg, ep?i+ki?k)P (CG|EG, EP, CP) (13)?
?iP (cgi|cgi?1i?k, ?eg, ep, cp?i+ki?k)P (b|a) =exp(?i?ifi(a, b))?b?exp(?i?ifi(a, b?
))(14)fi(a, b) is a binary function returning TRUEor FALSE based on context a and output b.If fi(a, b)=1, its corresponding model parame-ter ?icontributes toward conditional probabilityP (b|a) (Berger et al, 1996; Ratnaparkhi, 1997).The feature functions used here are defined interms of context predicates ?
a function return-ing TRUE or FALSE that depends on the presenceof the information in the current context (Ratna-parkhi, 1997).
Context predicates and their de-scriptions used are given in Table 4.N-GRAM includes gram1(uj), gram2(uj), andgram3(uj) corresponding to a unigram, a bigram,and a trigram, respectively.
PAIR includes a pair ofunigrams (pair11), unigram and bigram (pair12),and bigrams (pair22).
TRIPLE includes a triple ofthree unigrams (triple1) and a triple of two uni-grams and one bigram (triple2).
Note that if dif-ferent context predicates represent the same con-text, we accept one of them and ignore the othersTable 4: Context predicates and their descriptionsCategory Context predicates DescriptionN-GRAM gram1(uj) ujgram2(uj) uj+1jgram3(uj) uj+2jPAIR pair11(uj, vk) uj, vkpair12(uj, vk) uj, vk+1kpair22(uj, vk) uj+1j, vk+1kTRIPLE triple1(uj, vk, wl) uj, vk, wltriple2(uj, vk, wl) uj, vk, wl+1l(e.g., pair12(uj, uj+1) = trigram(uj) = uj+2j).Table 3 represents the examples of feature func-tions for P (cgi|cgi?1i?k, ?eg, ep, cp?i+ki?k).We used the ?Maximum Entropy ModelingToolkit?4 to estimate the probabilities and theLBFGS algorithm to find ?iin Eq.
(14).
Foreach transliteration model, we produced n-besttransliterations using a stack decoder (Schwartzand Chow, 1990).3.4 SummaryIn this paper, we defined eighteen transliterationmodels to be compared.
There are six translitera-tion models, three basic and three hybrid ones, ineach class, MI, MS, and MJ.
We compared thetransliteration models from the viewpoint of Chi-nese phonemes or the class of transliteration mod-els in our experiments.4 Testing and ResultsWe used the same test set used in Li et al (2004)for our testing5.
It contains 37,694 pairs of Englishwords and their official Chinese transliterations4Available at http://homepages.inf.ed.ac.uk/s0450736/maxent_toolkit.html5This test set was also used in ?NEWS09 machine translit-eration shared task?
for English-to-Chinese transliteration (Liet al, 2009)662extracted from the ?Chinese Transliteration of For-eign Personal Names?
(Xinhua News Agency,1992), which includes names in English, French,German, and many other foreign languages (Li etal., 2004).
We used the same test data as in Li etal.
(2004).
But we randomly selected 90% of thetraining data used in Li et al (2004) as our trainingdata and the remainder as the development data, asshown in Table 5.Table 5: Number of English-Chinese translitera-tion pairs in each data setOurs Li et al (2004)Training data 31,299 34,777Development data 3,478 N/ABlind test data 2,896 2,896We used the training data for training thetransliteration models.
For each model, we tunedthe parameters including the number of iterationsfor training the maximum entropy model and aGaussian prior for smoothing the maximum en-tropy model using the development data.
Further,the development data was used to select param-eter ?
of the hybrid transliteration models.
Wevaried parameter ?
from 0 to 1 in 0.1 intervals(i.e., ?=0, 0.1, 0.2, ?
?
?
,1) and tested the perfor-mance of the hybrid models with the developmentdata.
Then we chose ?
that showed the best per-formance in each hybrid model.
The blind testdata was used for evaluating the performance ofeach transliteration model.
The CMU Pronounc-ing Dictionary6, which contains about 120,000English words and their pronunciations, was usedfor estimating P (EP|EG).We conducted two experiments.
First, we com-pared the overall performance of the translitera-tion models.
Second, we investigated the effectof training data size on the performance of eachtransliteration model.The evaluation was done for word accuracyin top-1 (ACC), Chinese pronunciation accuracy(CPA) and a mean reciprocal rank (MRR) met-ric (Kantor and Voorhees, 2000; Li et al, 2009;Chang et al, 2009).
ACC measures how manycorrect transliterations appeared in the top-1 re-sult of each system.
CPA measures the Chinesepronunciation accuracy in the top-1 of the n-bestChinese pronunciation.
We used CPA for com-6Available at http://www.speech.cs.cmu.edu/cgi-bin/cmudictparing the performance between systems based onChinese phonemes.
MRR, mean reciprocal ranksof n-best results of each system over the test en-tries, is an evaluation measure for n-best translit-erations.
If a transliteration generated by a systemmatches a reference transliteration7 at the rth posi-tion of the n-best results, its reciprocal rank equals1/r; otherwise its reciprocal rank equals 0, where1 ?
r ?
n. We produced 10-best Chinese translit-erations for each English word in our experiments.4.1 Comparison of the Overall PerformanceTable 6 represents the overall performance of onesystem in a previous work (Li et al, 2004) andeighteen systems based on the transliteration mod-els defined in this paper.
ACC, MRR, and CPArepresent the evaluation results for each modeltrained by our training data.
To test transliterationmodels without the errors introduced by incorrectChinese phonemes, we carried out the experimentswith the correct Chinese pronunciation (or thecorrect Chinese phoneme sequence) in Chinesephoneme-to-grapheme conversion.
In the exper-iment, we put the correct Chinese pronunciationinto the top-1 of the n-best Chinese pronunciationwith the highest probability, say P (CP|EG)=1;thus CPA was assumed to be 100%.
The ACCof the transliteration models under this conditionis denoted as ACC?
in Table 6.
TRAIN representsthe evaluation results of the transliteration mod-els trained by our training data.
To compare Liet al (2004) and transliteration models defined inthis paper under the same condition, we also car-ried out experiments with the same training datain Li et al (2004).
Since the training data usedin Li et al (2004) is identical as the union ofour training and development data, we denoted itas TRAIN+DEV in Table 6.
In both TRAIN andTRAIN+DEV, we used the same parameter settingthat was obtained by using the development data.LI04 represents a system in Li et al (2004),and its ACC?
in TRAIN+DEV is taken from theliterature.
The systems based on the translitera-tion models defined in our paper are representedfrom the second row in Table 6.
The phoneme-based transliteration models in the literature cor-respond to either M(EG, CP) (Wan and Verspoor,1998; Lee and Chang, 2003; Jiang et al, 2007) orM(EP, CP) (Meng et al, 2001; Gao et al, 2004;7In our test set, an English word corresponds to one refer-ence Chinese transliteration.663Table 6: Comparison of the overall performanceClass Model TRAIN TRAIN+DEVACC MRR CPA ACC?
ACC MRR CPA ACC?LI04 N/A N/A N/A N/A 70.1 N/A N/A N/AM(EG, JCP) 71.9 80.4 72.3 88.2 72.3 80.7 73.1 88.9M(EP, JCP) 61.1 70.3 62.4 82.8 61.1 70.6 63.1 83.8MJM(EGP, JCP) 72.3 80.9 73.2 89.6 73.5 81.5 73.9 90.4M(EG+EP, JCP, 0.7) 72.8 80.7 73.8 89.7 73.2 81.0 74.7 90.5M(EG+EGP, JCP, 0.6) 73.5 81.7 74.2 90.6 73.7 81.8 74.8 91.2M(EP+EGP, JCP, 0.1) 71.6 80.3 73.3 89.8 72.5 80.8 73.8 90.1M(EG, ?)
70.0 78.5 N/A N/A 70.6 79.0 N/A N/AM(EP, ?)
58.5 69.3 N/A N/A 59.4 70.1 N/A N/AMIM(EGP, ?)
71.2 79.9 N/A N/A 72.3 80.7 N/A N/AM(EG+EP, ?, 0.7) 70.7 79.1 N/A N/A 72.0 80.0 N/A N/AM(EG+EGP, ?, 0.4) 72.0 80.3 N/A N/A 72.8 80.9 N/A N/AM(EP+EGP, ?, 0.1) 71.0 79.6 N/A N/A 72.0 80.4 N/A N/AM(EG, CP) 58.9 70.2 72.3 78.4 59.1 70.4 73.1 78.4M(EP, CP) 50.2 62.3 62.4 78.4 50.4 62.6 63.1 78.5MSM(EGP, CP) 59.1 70.4 73.2 78.4 59.3 70.5 73.9 78.5M(EG+EP, CP, 0.8) 59.7 71.3 73.8 79.0 60.3 71.7 74.7 79.0M(EG+EGP, CP, 0.6) 59.8 71.7 74.2 78.9 60.6 72.1 74.8 78.9M(EP+EGP, CP, 0.1) 58.8 70.4 73.3 78.9 59.4 70.7 73.8 78.8Virga and Khudanpur, 2003).A comparison between the basic and hybridtransliteration models showed that the hybridones usually performed better (the exception wasM(EP+EGP, y, ?)
but the performance still com-parable to the basic ones in each class).
Es-pecially, the hybrid ones based on the best twobasic transliteration models, M(EG+EGP, y, ?
),showed the best performance.A comparison among the MI, MS, andMJmodels showed that Chinese phonemes didcontribute to the performance improvement ofEnglish-to-Chinese transliteration when Chinesephonemes were used together with their corre-sponding English graphemes and phonemes inChinese phoneme-to-grapheme conversion.
Aone-tail paired t-test between the MIand MJmodels showed that the results of the MJmod-els were always significantly better than thoseof the MImodels if the MIand MJmodelsshared the same English-side parameter, x ?
{EG, EP, EGP} (level of significance = 0.001).In the results obtained by the MSand MJmod-els, the figures in CPA are the same when theMSand our MJmodels share the same English-sideparameter.
Moreover, the difference between thefigures in ACC and CPA can be interpreted asthe error rate of Chinese phoneme-to-graphemeconversion.
Our proposed MJmodels gener-ated Chinese transliterations with a very low er-ror rate in Chinese phoneme-to-grapheme conver-sion, while theMSmodels suffered from a signif-icant error rate in Chinese phoneme-to-graphemeconversion.
ACC?
showed that the MJmodelsstill outperformed the MSmodels even withouterrors in generating Chinese pronunciation fromthe English words.
These results indicate that thejoint use of Chinese phonemes and their corre-sponding English graphemes and phonemes sig-nificantly improved the performance in Chinesephoneme-to-grapheme conversion and English-to-Chinese transliteration.Table 7 shows the Chinese transliterations gen-erated by M(EG, ?
), M(EGP, ?
), M(EG, JCP),and M(EGP, JCP) where English or Chinesephonemes contributed to the correct translitera-tion.
In this table, the first column show theEnglish words and their English phonemes, andthe second and third columns represent the Chi-nese transliterations and their phonemes.
Notethat the Chinese phonemes in the second and thirdcolumns of theMImodels are not used in translit-eration.
They are shown in the table to indicatethe difference in the Chinese phonemes of Chinese664Table 7: Top-1 results of M(EG, ?
), M(EGP, ?
),M(EG, JCP), and M(EGP, JCP), where * rep-resents incorrect transliterationsM(EGP,JCP)M(EG,JCP)MJ models????
*(LAI YIN HA TE)????
*(LAI YIN HA TE)Reinhardt(R AI N HH AA R T)??
(AI WEI)??
*(YI WEI)Ivy(AY V IY)???
*(AI MI LI)???
*(AI MI LI)Emily(EH M IH L IY)???
?LAI YIN HA TE???
?LAI YIN HA TEReinhardt(R AI N HH AA R T)?
?AI WEI??
*YI WEIIvy(AY V IY)??
?AI MI LI??
?AI MI LIEmily(EH M IH L IY)M(EGP,?)M(EG,?
)MI modelstransliterations between theMIandMJmodels.For Emily and Reinhardt, the MJmodels gen-erated correct Chinese transliterations, but theMImodels did not.
Figure 1 shows the probabil-ity distribution when a transliteration model gen-erates the first Chinese character in the Chinesetransliteration of Reinhardt with and without Chi-nese phonemes.
Two Chinese characters,  and, were strong candidates and  is the correctone in this case.
Without Chinese phonemes,M(EG, ?
), which is based on P(cg|Reinhardt)in Figure 1(a) preferring  to , generated theincorrect transliteration as shown in Table 7.
How-ever, Figure 1(b) shows that  can be selectedif the correct Chinese phoneme sequence ?LAIYIN ...?
is given.
Three Chinese phoneme se-quences starting with ?LAI YIN ...?, ?LAI NA...?, and ?LAI NEI ...?
were generated from Rein-hardt, where ?LAI YIN ...?
was the best Chinesephoneme sequence based on the probability distri-bution in Figure 1(c).
As a result, M(EG, JCP),which jointly used Chinese phonemes with En-glish graphemes, generated the correct Chinesetransliteration of Reinhardt based on two probabil-ity distribution in Figures 1(b) and 1(c).
In the caseof Ivy, English phonemes contributed to generat-ing the correct transliteration in the M(EGP, ?
)and M(EGP, JCP) models.Chinese transliterations sometimes reflect theEnglish word?s pronunciation as well as the Chi-nese character?s meaning (Li et al, 2007).
Li00.20.40.60.8P(?|Reinhardt) P(?|Reinhardt)(a) Probability distribution when Chi-nese phonemes are not given00.20.40.60.81?
?P(cg|Reinhardt, "LAI YIN ..") P(cg|Reinhardt, "LAI NA ..")P(cg|Reinhardt, "LAI NEI ..")(b) Probability distribution when Chinese phonemes aregiven00.20.40.60.81P("LAI YIN .."|Reinhardt) P(?
"LAI YIN .."|Reinhardt)(c) Probability distribution for Chinese phoneme se-quence ?LAI YIN ...?
and othersFigure 1: Probability distribution for the first Chi-nese character in the Chinese transliteration ofReinhardt: M(EG, ?)
vs. M(EG, JCP)et al (2007) defined such a Chinese transliter-ation as a phonetic-semantic transliteration (se-mantic transliteration) to distinguish it from ausual phonetic transliteration.
One fact thataffects semantic transliteration is gender asso-ciation (Li et al, 2007).
For example, (meaining jasmine) is frequently used in Chi-nese transliterations of female names but sel-dom in common person names.
Because Emilyis often used in female names, the results ob-tained by the M(EG, JCP) and M(EGP, JCP)models are acceptable.
This indicates that Chi-nese phonemes coupled with English graphemesor those coupled with English graphemes andphonemes could provide evidence required for se-mantic transliteration as well as phonetic translit-eration.
As a result, M(EGP, ?
), M(EG, JCP),665and M(EGP, JCP), which used phonemes cou-pled with English graphemes, achieved higher per-formance than M(EG, ?
), which relied only onEnglish graphemes.4.2 Effect of Training Data Size8070605040302080 60 40 20MRRTraining Data Size (%)M(EG,?)M(EP,?)M(EGP,?
)M(EG,CP)M(EP,CP)M(EGP,CP)M(EG,JCP)M(EP,JCP)M(EGP,JCP)(a) Basic transliteration models80706050403080 60 40 20MRRTraining Data Size (%)M(EG+EP,?,0.7)M(EG+EGP,?,0.4)M(EP+EGP,?,0.1)M(EG+EP,CP,0.8)M(EG+EGP,CP,0.6)M(EP+EGP,CP,0.1)M(EG+EP,JCP,0.7)M(EG+EGP,JCP,0.6)M(EP+EGP,JCP,0.1)(b) Hybrid transliteration modelsFigure 2: Performance of each system with differ-ent training data sizeWe investigated the effect of training data sizeon the performance of each transliteration model.We randomly selected training data with ratiosfrom 10 to 90% and compared the performanceof each system trained by different sizes of train-ing data.
The results for the basic translitera-tion models in Figure 2(a) can be categorized intothree groups.
M(EGP, ?)
and M(EGP, JCP)fall into the best group, where they showed thebest performance regardless of training data size.M(EG, ?)
and M(EG, JCP) belong to the mid-dle group, where they showed lower performancethan the best group if the training data size issmall, but their performance is comparable to thebest group if the size of the training data is largeenough.
The others always showed lower perfor-mance than both the best and middle groups.
Fig-ure 2(b) shows that hybrid transliteration models,on average, were less sensitive to the training datasize than the basic ones, because the two differ-ent basic transliteration models used in the hybridones boosted transliteration performance by com-plementing each other?s weak points.5 ConclusionWe proposed a new English-to-Chinese transliter-ation model based on Chinese phonemes and theircorresponding English graphemes and phonemes.We defined eighteen English-to-Chinese translit-eration models including our proposed model andclassified them into three classes based on the roleof Chinese phonemes in the transliteration mod-els.
Experiments showed that Chinese phonemesin our proposed model can contribute to theperformance improvement in English-to-Chinesetransliteration.Now we can answer Yes to this paper?s key ques-tion, ?Can Chinese phonemes improve machinetransliteration??
Actually, this is the second timethe same question has been answered.
The pre-vious answer, which was unfortunately reportedas No by Li et al (2004), has been accepted astrue for the last five years; the research issue hasbeen considered closed.
In this paper, we founda new answer that contradicts the previous an-swer.
We hope that our answer promotes researchon phoneme-based English-to-Chinese translitera-tion.Appendix: Illustration of BasicTransliteration Models inMJandMSEGCPEG EPEG EPCGCPCPCGCG:)JC,?(?
PG:)JC,?(?PP:)JC,?
(?PGP(a) MJmodelsEGCPEG EPEG EPCGCPCPCGCG:)C,?(?PGP:)C,?(?PP:)C,?
(?PG(b) MSmodels666ReferencesY.
Al-Onaizan and Kevin Knight.
2002.
Translatingnamed entities using monolingual and bilingual re-sources.
In Proc.
of ACL ?02, pages 400?408.A.
L. Berger, S. D. Pietra, and V. J. D. Pietra.
1996.
Amaximum entropy approach to natural language pro-cessing.
Computational Linguistics, 22(1):39?71.M.
Chang, D. Goldwasser, D. Roth, and Y. Tu.
2009.Unsupervised constraint driven learning for translit-eration discovery.
In Proceedings of NAACL HLT?09.Wei Gao, Kam-Fai Wong, and Wai Lam.
2004.Phoneme-based transliteration of foreign names forOOV problem.
In Proc.
of IJCNLP 2004, pages110?119.Long Jiang, Ming Zhou, Lee-Feng Chien, and ChengNiu.
2007.
Named entity translation with web min-ing and transliteration.
In Proc.
of IJCAI ?07, pages1629?1634.Paul B. Kantor and Ellen M. Voorhees.
2000.
The trec-5 confusion track: Comparing retrieval methods forscanned text.
Information Retrieval, 2:165?176.Sarvnaz Karimi, Falk Scholer, and Andrew Turpin.2007.
Collapsed consonant and vowel models: Newapproaches for English-Persian transliteration andback-transliteration.
In Proceedings of ACL ?07,pages 648?655.Chun-Jen Lee and Jason S. Chang.
2003.
Acqui-sition of English-Chinese transliterated word pairsfrom parallel-aligned texts using a statistical ma-chine transliteration model.
In Proc.
of HLT-NAACL2003 Workshop on Building and Using ParallelTexts, pages 96?103.Haizhou Li, Min Zhang, and Su Jian.
2004.
A jointsource-channel model for machine transliteration.In Proceedings of the 42th Annual Meeting of the As-sociation of Computational Linguistics, pages 160?167.Haizhou Li, Khe Chai Sim, Jin-Shea Kuo, and MinghuiDong.
2007.
Semantic transliteration of personalnames.
In Proceedings of the 45th Annual Meetingof the Association of Computational Linguistics.Haizhou Li, A Kumaran, Min Zhang, and VladimirPervouchine.
2009.
Whitepaper of NEWS 2009machine transliteration shared task.
In Proc.
ofACL-IJCNLP 2009 Named Entities Workshop.M.G.
Abbas Malik.
2006.
Punjabi machine translit-eration.
In Proceedings of the COLING/ACL 2006,pages 1137?1144.H.M.
Meng, Wai-Kit Lo, Berlin Chen, and K. Tang.2001.
Generating phonetic cognates to handlenamed entities in English-Chinese cross-languagespoken document retrieval.
In Proc.
of Auto-matic Speech Recognition and Understanding, 2001.ASRU ?01, pages 311?314.Jong-Hoon Oh, Key-Sun Choi, and Hitoshi Isahara.2006.
A comparison of different machine transliter-ation models.
Journal of Artificial Intelligence Re-search (JAIR), 27:119?151.Adwait Ratnaparkhi.
1997.
A linear observed time sta-tistical parser based on maximal entropy models.
InProceedings of the Second Conference on EmpiricalMethods in Natural Language Processing, pages 1?10.Richard Schwartz and Yen-Lu Chow.
1990.
The N-Best algorithm: an efficient procedure for findingtop N sentence hypotheses.
In Proc.
of ICASSP ?90,pages 81?84.Tarek Sherif and Grzegorz Kondrak.
2007.
Substring-based transliteration.
In Proceedings of ACL ?07,pages 944?951.Paola Virga and Sanjeev Khudanpur.
2003.
Translit-eration of proper names in cross-lingual informationretrieval.
In Proc.
of ACL 2003 Workshop on Multi-lingual and Mixed-language Named Entity Recogni-tion, pages 57?64.Stephen Wan and Cornelia Maria Verspoor.
1998.
Au-tomatic English-Chinese name transliteration for de-velopment of multilingual resources.
In Proc.
ofCOLING ?98, pages 1352?1356.Xinhua News Agency.
1992.
Chinese transliterationof foreign personal names.
The Commercial Press.Binyong Yin and Mary Felley.
1990.
Chinese Roman-ization: Pronunciation and Orthography.
Sinolin-gua.Su-Youn Yoon, Kyoung-Young Kim, and RichardSproat.
2007.
Multilingual transliteration usingfeature based phonetic method.
In Proceedings ofACL?07, pages 112?119.667
