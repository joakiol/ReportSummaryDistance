Combining Lexical and Formatting Cues for Named EntityAcquisition from the WebChr i s t ian  Jacquera in  1 and Caro l ine  Bush  1'21CNRS-LIMSI, BP 133, F-91403 ORSAY Cedex, FRANCE2UMIST, Dept of Language Engineering, PO Box 88, Manchester M60 1QD, UK{j acquemin, caroline}@lims?, frAbst ractBecause of their constant renewal, it is nec-essary to acquire fresh named entities (NEs)from recent ext sources.
We present a toolfor the acquisition and the typing of NEs fromthe Web that associates a harvester and threeparallel shallow parsers dedicated to specificstructures (lists, enumerations, and anchors).The parsers combine lexical indices such asdiscourse markers with formatting instruc-tions (HTML tags) for analyzing enumera-tions and associated initializers.1 Overv iewLexical acquisition from large corpora haslong been considered as a means for enrich-ing vocabularies (Boguraev and Pustejovsky,1996).
Depending on the studies, different is-sues are considered: the acquisition of terms(Daille, 1996), the acquisition of subcatego-rization frames (Basili et al, 1993), the acqui-sition of semantic links (Grefenstette, 1994),etc.
While traditional electronic orpora suchas journal articles or corpus resources (BNC,SUSANNE, Brown corpus) are satisfactory forclassical lexical acquisition, Web corpora areanother source of knowledge (Crimmins et al,1999) that can be used to acquire NEs becauseof the constant updating of online data.The purpose of our work is to propose atechnique for the extraction of NEs from theWeb through the combination of a harvesterand shallow parsers.
Our study also belongsto corpus-based acquisition of semantic re-lationships through the analysis of specificlexico-syntactic contexts (Hearst, 1998) be-cause hypernym relationships are acquired to-gether with NEs.
The unique contributionof our technique is to offer an integrated ap-proach to the analysis of HTML documentsthat associates lexical cues with formattinginstructions in a single and cohesive frame-work.
The combination of structural informa-tion and linguistic patterns is also found inwrapper induction, an emerging topic of re-search in artificial intelligence and machinelearning (Kushmerick et al, 1997).Our work differs from the MUC-related NEtagging task and its possible extension toname indexing of web pages (Aone et al,1997) for the following reasons:?
The purpose of our task is to build lists ofNEs, not to tag corpora.
For this reason,we only collect non-ambiguous context-independent NEs; partial or incompleteoccurrences such as anaphora re consid-ered as incorrect.?
The types of NEs collected here are muchmore accurate than the four basic typesdefined in MUC.
The proposed tech-nique could be extended to the collec-tion of any non-MUC names which canbe grouped under a common hypernym:botanic names, mechanical parts, booktitles, events...?
We emphasize the role of document s ruc-ture in web-based collection.2 Focus ing  on Def in i to ry  ContextsTwo issues are addressed in this paper:1.
While traditional electronic orpora canbe accessed irectly and entirely throughlarge-scale filters such as shallow parsers,access to Web pages is restricted tothe narrow and specialized medium of asearch engine.
In order to spot and re-trieve relevant ext chunks, we must fo-cus on linguistic ues that can be used toaccess pages containing typed NEs withhigh precision.2.
While Web pages are full of NEs, only asmall proportion of them are relevant forthe acquisition of public, fresh and well-known NEs (the name of someone's cat181is not relevant o our purpose).
So thatautomatically acquired NEs can be usedin a NE recognition task, they are asso-ciated with types such as actor (PER-SON), lake (LOCATION), or university(ORGANIZATION).The need for selective linguistic ues (wrt tothe current facilities offered by search engines)and for informative and typifying contexts hasled us to focus on collections, a specific type ofdefinitory contexts (Pdry-Woodley, 1998).
Be-cause they contain specific linguistic triggerssuch as following or such as, definitory con-texts can be accessed through phrase queriesto a search engine.
In addition, these contextsuse the classical scheme genus/differentia todefine NEs, and thus provide, through thegenus, a hypernym of the NEs they define.Our study extends (Hearst, 1998) to Web-based and spatially formatted corpora.3 Arch i tec ture  and  Pr inc ip lesTo acquire NEs from the Web, we have devel-oped a system that consists of three sequentialmodules (see Figure 1):1.
A harvester that downloads the pages re-trieved by a search engine from the fourfollowing query strings(1.a) following (NE) (1.c) (NE) such as(1.b) list of (NE) (1.d) such (NE) asin which (NE) stands for a typifyinghypernym of NEs such as Universities,politicians, or car makers (see list in 4).. Three parallel shallow parsers Pc, P1 andPa which extract candidate NEs respec-tively from enumerations, lists and ta-bles, and anchors.. A post-filtering module that cleans up thecandidate NEs from leading determinersor trailing unrelated words and splits co-ordinated NEs into unitary items.Corpus HarvestingThe four strings (1.a-d) given above are usedto query a search engine.
They consist of anhypernym and a discourse marker.
They areexpected to be followed by a collection of NEs.Figure 2 shows five prototypical examplesof collections encountered in HTML pages re-Queries WWWI1  arch Eogioe IH'I'ML corpus.
.
.
.
.
\[ - ~ ;  - ~ L .
z ~ " ~ < z - 1 2 .
- ~ i  - - -~2r ; J2' 1 1  " I I -!Enumeration ~ List and tables II Anchor I. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
t t  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Candidate NEs Initializers and Candtdateate~ Index pagesI Filter ITyped NEsFigure 1: Architecturetrieved through one of the strings (1.a-d)3The first collection is an enumerat ion  andconsists of a coordination of three NEs.
Thesecond collection is a list organized into twosublists.
Each sublist is introduced by a hy-pernym.
The third structure is a list markedby bullets.
Such lists can be constructedthrough an HTML table (this example), orby using enumeration marks (<ul> or <ol>).The fourth example is also a list built by us-ing a table structure but displays a more com-plex spatial organization and does not em-ploy graphical bullets.
The fifth example isan anchor  to a collection ot provided to thereader within the document, but which can bereached by following an hyperlink instead.The corpus of HTML pages is collectedthrough two search engines with different ca-pabilities: AltaVista (AV) and Northern Light(NL).2 AV offers the facility of double-quotingthe query strings in order to search for exactstrings (also called phrases in IR).
NL doesnot support phrase search.
However, in AV,the number of retrievable documents i  limitedto the 200 highest ranked documents while itis potentially unlimited in NL.
For NL, the1 (NE) is international organzzations, here.
The ty-pographical mark-up of the query string in the figureis ours.
The hypernym is in bold italics and the dis-course marker is in bold.2The harvester that retrieves Web pages through asearch engine is a combination of wget available fromftp://sunsite, auc.
dk/pub/infosystems/wget/ andPerl scripts.182It's development is due to the support gwen by the Ministry of Pubhc Health, aided byinternational organizations uch as the Pan American Health Organization (PAHO), theUnited Nations Development program, and the Caribbean and Latin American Medical ScienceInformation Center.7.
The session was also attended by observers from the following international organizations:(a) United Nations organsInternational Bank for Reconstruction a d Development (World Bank)(b) lntergovernmental organizationsAsian-African Legal Consultative Committee (AALCC)Inter-American Development BankInternauonal Institute for the Umficauon of Private Law (UNIDROIT)International OrganizationsThe following international organizations are collaborating on the Project:lp International Commission on Non-Ionizing Radiation Protection (ICNIRP)1~ International Agency for Research on Cancer (IARC)United Nations Environment Programme (UNEP)Below is the list of international organizations that we distribute:EU (European Union)Books, documentation, periodicals on European legislation,economy, agriculture, industry, educatmn, norms, ocialpohtics, law.
For more information publicauons, COMdocuments and to subscribe tothe Officml Journal pleasecontact Dunya Infotel.UN (United Nations)Peace and security, economics, statistics, energy, naturalresources, nvironment, i ernational law, human rights,polmcal ffairs and disarmament, social questions.
1997periodicals include: Development Business, East-WestInvestment News, Transnattonal Corporations, MonthlyBulletin of Stat~stms, etc.An agency may detail or transfer an employee to any orgamzaUon which the Office ofPersonnel Management has designated asan international organization (see list of internationalorganizations).Figure 2: Five different ypes of formatting used for enumerating NEs.number of retrieved ocuments was howeverrestricted to 2000 in order to limit process-ing times.
The choice of these two search en-gines is intended to evaluate whether a poorerquery mode (bags of words in NL instead ofstrings in AV) can be palliated by accessingmore documents (2000 max.
for NL insteadof 200 max.
for AV).The corpus collected by the two searchengines and the four f~.milies of queries is2,958Mb large (details are given in Section 4).Acquis i t ion of  Candidate  NEsThree parallel shallow parsers Pc, P\].
and Paare used to extract NEs from the corpora col-lected by the harvester.
The parsers rely onthe query string to detect he sentence intro-ducing the collection of NEs (the initializer in(P~ry-Woodley, 1998)).
The text and HTMLmarks after the initializer are parsed jointlyin order to retrieve one of the following threespatio-syntactic structures:1. a textual enumeration (parser Pc, top-183most example in Figure 2),2. a list or a table (parser Pl, the next threeexamples in Figure 2),3. an anchor toward a page containing a list(parser Pa, bottom example in Figure 2).In brief, these parsers combine stringmatching (the initial lexical cue), syntacticanalysis (enumerations in Pe), analysis of for-matting instructions (lists and tables in Pl),and access to linked documents through an-chors detected by Pa.
The results presented inthis paper only concern the first two parsers.Since anchors raise specific problems in lin-guistic analysis (Amitay, 1999), they will beanalyzed in another pubhcation.
The result-ing candidate NEs are cleaned up and filteredby a post-filtering module that splits associa-tions of NEs, suppresses initial determiners ortrailing modifiers and punctuations, and re-jects incorrect NEs.The  Enumerat ion  Parser  PeThe enumerations are expected to occur in-side the sentences containing the query string.Pe uses a traditional approach to parsingthrough conjunction splitting in which a NEpattern NE is given by (3) and an enumera-tion by (4).
3NE = (\[A-Z \ &\]\[a-zA-Z \-\'\]* )+ (3)Enum = (NE, )*WE(, ?)
(andlor) WE (4)The List Parser  P1The lists are expected to occur no further thanfour lines after the sentence containing thequery string.
The lists are extracted throughone of the following three patterns.
They cor-respond to three alternatives commonly usedby HTML authors in order to build a spa-tial construction of aligned items (lists, linebreaks, or tables).
They are expressed bycase-insensitive r gular expressions in whichthe selected string is the shortest  acceptableunderlined pattern:<li> ?
(</ti> I<ti> I</ot> I</~t>?5)<~> ?
</~> (6)(<td> I<th>) ._" (<td> \[<th> I</td> (7)I</th> I</table> )3The patterns are slightly more complicated in or-der to accept diacriticized letters, and possible abbre-viations composed of a single letter followed by a dot.In addition, after the removal of the HTMLmark-up tags, only the longest subpart of thestring accepted by (3) is produced as outputto the final filter.
These patterns do not coverall the situations in which a formatted text de-notes a list.
Some specific ases of lists such aspre-formatted text in a verbatim environment(<we>), or items marked by a paragraph tag(<p>) are not considered here.
They wouldproduce too inaccurate results because theyare not typical enough of lists.Postf i l ter lngThe pre-candidate NEs produced by the shal-low parsers are processed by filters before be-ing proposed as candidate NEs.
The roles ofthe filters are (in this order):?
removal of trailing lower-case words,?
deletion of the determiner the and the co-ordinating conjunctions and and or andthe words which follow them,?
rejection of pre-candidates that containthe characters @, {, # , ", $, !
or ?.?
suppression of item marks such as 1., - - ,?
or a),?
suppression of HTML markups,?
suppression of leading coordinating con-junctions,?
suppression of appositive sequences aftera comma or a hyphen,?
transformation f upper-case words intoinitial upper-case in non-organizationcandidate NEs because only organizationnames are expected to contain acronyms,?
rejection of NEs containing words in astop list such as Next, Top, Web, or Click.Postfiltering is completed by discardingsingle-word candidates, that are described ascommon words in the CELEX 4 database, andmulti-word candidates that contain more than5 words.4 Exper iments  and  Eva luat ionsData  Co l lec t ionThe acquisition of NEs is performed on 34types of NEs chosen arbitrarily among threesubtypes of the MUC typology:4The CELEX database for the English language isavailable from the Consortium for Lexical Resources at~.
Idc.
upenn, edu/readme_files/celex, readme, html.184ORGANIZATION (American companies,international organizations, universities, po-litical organizations, international agencies,car makers, terrorist groups, financial insti-tutions, museums, international companies,holdings, sects, and realtors),PERSON (politicians, VIPs, actors, man-agers, celebrities, actresses, athletes, authors,film directors, top models, musicians, singers,and journalists), andLOCATION (countries, regions, states,lakes, cities, rivers, mountains, and islands).Each of these 34 types (a (NE) string)is combined with the four discourse mark-ers given in (1.a-d), yielding 136 queries forthe two search engines.
Each of the 272 cor-pora collected through the harvester is madeof the 200 documents downloadable throughAV for the phrase search (or less if less areretrieved) and 2,000 documents though NL.Each of these corpora is parsed by the enu-meration and the list parsers.Two aspects of the data are evaluated.First, the size of the yield is measured in orderto compare the productivity of the 272 queriesaccording to the type of query (type of NEand type of discourse marker) and the type.of search engine (rich versus plain queries andlow versus high number of downloaded ocu-ments).
Second, the quality of the candidateNEs is measured through uman inspection ofaccessible Web pages containing each NE.Corpus SizeThe 272 corpora are 2,958 Mb large: 368Mb for the corpora collected through AV and2,590 Mb for those obtained through NL.
De-tailed sizes of corpora are shown in Table 1.The corpora collected through NL for the pat-tern list o/ (NE / represent more than a halfof the NL collection (1,307 Mb).
The mostproductive pattern for AV is (NE) such asthrough which 41% of the AV collection isdownloaded (150 Mb).The sizes of the corpora also depends onthe type of NEs.
For each search engine, thetotal sizes are reported for each pattern (1.a-d).
In addition, the largest corpus for eachof the three types of NEs is indicated in thelast three lines.
The variety of sizes and dis-tribution among the types of NEs shows thatusing search engines with different capabili-ties yields different figures for the collectionsof pages.
Therefore, the subsequent process ofNE acquisition heavily depends on the meansused to collect the basic textual data fromwhich knowledge is acquired.Quantitative Evaluation of AcquisitionTable 2 presents, for each pattern and eachsearch engine, the number of candidates, theproductivity, the ratios of the number of enu-merations to lists, and the rate of redundancy.In all, 17,176 candidates are producedthrough AV and 34,978 through NL.
The low-est accuracy of the NL query mode is well pal-liated by a larger collection of pages.P roduct iv i ty .
The productivity is the ra-tio of the number of candidates to the sizeof the collection.
Using a unit of number ofcandidates per Mb, the productivity of AV is46.7 while it is 3.5 times lower for NL (13.5).Thus, collecting NEs from a coarser search en-gine, such as NL, requires downloading 3.5times larger corpora for the same yield.
Afiner search engine with phrase query facili-ties, such as AV, is more economical with re-spect to knowledge acquisition based on dis-course markers.As was the case for the size of the col-lection, the productivity of the corpora alsodepends on the types of NEs.
Universi-ties (28.1), celebrities (53.0) and countries(36.5) are the most productive NEs in theircategories while international agencies (4.0),film directors (4.4) and states (8.7) are theless productive ones.
These discrepanciescertainly depend on the number of existingnames in these categories.
For instance, thereare many more names of celebrities than .filmdirectors.
In fact, the productivity of NL issignificantly lower than the productivity of AVonly for the pattern list of NE.
Since this pat-tern corresponds to the largest corpus (see Ta-ble 1), its poor performance in acquisition hasa strong impact on the overall productivityof NL.
Avoiding this pattern would make NLmore suitable for acquisition with a produc-tivity of 23.2 (only 2 times lower than AV).Rat ios  enumerat ions / l i s t s .
The ratiosin the third lines of the tables correspond tothe quotient of the number of candidates ac-quired by analyzing enumerations (Pe parser)to the number of candidates obtained fromthe analysis of lists (P1 parser).
FollowingNE mainly yields NEs through the analysisof lists, probably because numerations u ingcoordinations are better introduced by suchas.
The outcome is more balanced for listof NE.
It could be expected that this pat-185Table h Size of the corpora of HTML pages (in Mb) collected on the four patterns (1.a-d)through AltaVista (AV) and Northern Light (NL).AV engine following NE (AV) list of NE (AV) NE such as (AV) such NE as (AV)Largest corpus 6.1 6.4 11.3 5.8ORGANIZATIONS int.
organizations universities int.
organizations int.
organizationsLargest corpus 5.8 4.3 7.3 2.8PERSON managers journalists pohticians musiciansLargest corpus 6.8 4.9 13.6 7.3LOCATION countries countries states statesTotal size 85.9 64.9 150.4 66.3NL engine following NE (NL) list of NE (NL) NE such as (NL) such NE as (NL)Largest corpus 10.0 75.1 58.5 19.5ORGANIZATIONS museums int.
agencies holdings universitiesLargest corpus 10.2 60.0 44.1 48.6PERSON actors pohticians actors authorsLargest corpus 23.0 61.2 34.4 118.3LOCATION rivers islands rivers statesTotal size 172.8 1,306.9 652.7 458.1Table 2: Size of the number of candidate NEs acquired from the web-based corpora describedin Table 1.AV engine bZlowing NE (AV) list of NE (AV) NE such as (AV) such NE as (AV)# candidates 4,747 3,112 5,738 3,579Productivity 55.2 48.0 38.2 53.9Ratio enum./list 0.28 0.83 12.5 43.74Redundancy 2.12 2.15 1.77 1.69NL engine following NE (NL) list of NE (NL) NE such as (NL) such NE as (NL)# candidates 5,667 5,176 14,800 9,335Productivity 32.8 4.0 22.7 20.4Ratio enura./list 0.31 0.49 10.41 14.72Redundancy 2.12 2.34 2.13 2.20AV & NL following NE list of NE NE such as such NE as Total# candidates 8,673 7,380 18,005 10,566 44,624Overlap 16.7% 11.0% 12.3% 18.2% 15 .0~186tern tends to introduce only lists, but thereare only 1.66 times more NEs obtained fromlists than from enumerations through list offNE.
The large number of NEs produced fromenumerations after this pattern certainly re-lies on the combination of linguistics and for-matting cues in the construction of meaning.The writer avoids using (the word) list whenthe text is followed by a (physical) list.
Lastly,in all, 11 times more NEs are obtained fromenumerations than from lists after the patternNE such as, and 18 times more after such NEas.
This shows that the linguistic pattern suchas preferably introduces textual enumerationsthrough coordinations (Hearst, 1998).Redundancy .
There are two main causesof redundancy in acquisition.
A first cause isthat the same NE can be acquired from sev-eral collections in the same corpus.
Redun-dancy in the fourth lines of the tables is theratio of duplicates among the yield of can-didate NEs for each search engine and eachquery.
This value is relatively stable what-ever the search engine or the query pattern.On average, redundancy is 2.09: each candi-date is acquired slightly more than two times.Acquisition through NL is slightly more re-.~:dundant (2.18) than through AV (1.92).
Thisdifference is not significant since the numberof NEs acquired through NL is twice as largeas the number of NEs acquired through AV.Over lap.
Another cause of multiple acqui-sition is due to the concurrent exploitation oftwo search engines.
If these engines were usingsimilar techniques to retrieve documents, theoverlap would be large.
Since we have chosentwo radically different modes of query (phrasevs.
bag-of-word technique), the overlap---theratio of the number common candidates tothe number of total candidates--is low (15%).The two search engines seem to be comple-mentary rather than competitive because theyretrieve different sets of documents.P rec i s ion  of Acqu is i t ionIn all, 31,759 candidates are produced bypostfiltering the acquisition from the corporaretrieved by the two search engines.
A set of504 candidates i randomly chosen for the pur-pose of evaluation.
For each candidate, AV isqueried with a phrase containing the string ofthe NE.
The topmost 20 pages retrieved byAV are downloaded and then used for manualinspection in case of doubt about the actualstatus of the candidate.
We assume that ifa candidate is correct, an unambiguous refer-ence with the expected type should be foundat least in one of the topmost 20 pages.Two levels of precision are measured:1.
A NE is correct if its full name is re-trieved and if its fine-grained type (the 34types given at the beginning of this sec-tion) is correct.
The manual inspectionof the 504 candidates indicates a preci-sion of 62.8%.2.
A NE is correct if its full name is retrievedand if its MUC type (ORGANIZATION,PERSON, or LOCATION) is correct.
Inthis case, the precision is 73.6%.The errors can be classified into the follow-ing categories:Wrong type  Many errors in NE typing aredue to an incorrect connection between aquery pattern and a collection in a doc-ument.
For instance, Ashley Judd is in-correctly reported as an athlete (she is anactress) from the occurrenceHis clientele includes stars andathletes uch as Ashley Judd(below) and Mats Sundin.The error is due to a partial analysis ofthe initializer (underlined above).
Onlyathletes is seen as the hypernym whilestars is also part of it.
A correct anal-ysis of the occurrence would have led toa type ambiguity.
In this context, there isno clue for deciding whether Ashley Juddis a star or an athlete.Other wrong types are due to poly-semy.
For instance, HorseFlySwarm isextracted from a list of actors in a pagedescribing the commands and proceduresfor programming a video game.
Here ac-tors has the meaning of a virtual actor,a procedure in a programming environ-ment, and not a movie star.Incomplete  Partial extraction of candidatesis mainly due to parsing errors or to col-lections containing partial names of enti-ties.As an illustration of the second case, theauthor's name Goffman is drawn fromthe occurrenceReadings are drawnf rom thework o\] such authors as Laing,187Szasz, Goffman, Sartre, Bate-son, and Freud.Since this enumeration ,does not containthe first names of the authors, it is notappropriate for an acquisition of unam-biguous author's names.Other names such as Lucero are ambigu-ous even though they are completely ex-tracted because they correspond to a firstname or to a name that is part of sev-eral other ones.
They are also countedas errors since they will be responsible ofspurious identifications in a name taggingtask.Over -complete  Excessive extractions aredue to parsing errors or to collections thatcontain words accompanying names thatare incorrectly collected together withthe name.
For instance, Director LewisBurke FFrumkes is extracted as an au-thor's name from a list in which the ac-tual name Lewis Burke Frumkes is pre-ceded by the title Director.Misce l laneous  Other types of errors do notshow clear connection between the ex-tracted sequence and a NE.
They aremainly due to errors in the analysis ofthe web page.These types of errors are distributed as fol-lows: wrong type 25%, incomplete 24%, over-complete 8% and miscellaneous 43%.5 Ref inement  o f  the  Types  o f  NEsSo far, the type of the candidate NEs is pro-vided by the NE hypernym given in (1.a-d).However, the initializer preceding the collec-tion of NEs to be extracted can contain moreinformation on the type of the following NEs.In fact the initializer fulfills four distinct func-tions:1. introduces the presence and the proxim-ity of the collection, e.g.
Here is2.
describes the structure of the collection,e.g.
a list of3.
gives the type of each item of the collec-tion, e.g.
universities4.
specifies the particular characteristics ofeach item.
e.g.
universities in VietnamThe cues used by the harvester are elementswhich either introduce the collection (e.g.
the.following) or describe the structure (e.g.
alist of).
In initializers in general, these first2 functions need not be expressed explicitlyby lexical means, as the layout itself indi-cates the presence and type of the collection.Readers exploit the visual properties of writ-ten text to aid the construction of meaning(P6ry-Woodley, 1998).However it is necessary to be explicit whendefining the items of the collection as thisinformation is not available to the readervia structural properties.
Initializers gener-ally contain additional characteristics of theitems which provide the differentia (under-lined here):This is a list off American companieswith business interests in Latvia.This example is the most explicit form an ini-tializer can take as it contains a lexical ele-ment which corresponds to each of the fourfunctions outlined above.
It is fairly simple toextract the details of the items from initializ-ers with this basic form, as the modificationof the hypernym takes the form of a relativeclause, a prepositional phrase or an adjectivalphrase.
A detailed grammar of this form ofinitializer is as shown in Figure 3.
5InitializerThe following is NP(det) (adj) Ns PPP NP\] (adj) l~/pl (PP \ [~.
)list of universities in Indonesia:Figure 3: The structure of a basic initializerWe tag the collection by part of speech us-ing the TreeTagger (Schmid, 1999).
The el-ements which express the differentia are ex-tracted by means of pattern matching: theyare always the modifiers of the plural noun inthe string, which is the hypernym of the itemsof the collection.5pp = prepositional phrase, Ns = noun (singular),Npl = noun (plural), Vp = verb in present tense, rel.cl.= relative clause.188Initializers containing the search string suchas behave somewhat differently.
They aresyntactically incomplete, and the missing con-stituent is provided by each item of the col-lection (Virbel, 1985).
These phrases varyconsiderably in structure and can require rela-tively complex syntactic rearrangement to ex-tract the properties of the hypernym.
We willnot discuss these in more detail here.One type of error in this system occurswhen a paragraph containing the search stringis followed by an unrelated list.
For examplethe harvester recognizesAsk the long list of American com-panies who have unsuccessfully mar-keted products in Japan.as an initializer when in fact it is not related toany collection.
If it happened to be followedon the page by an collection of any kind thesystem would mistakenly collect the items asNEs of the type specified by the search string.The cue list of is commonly used in dis-cursive texts, so some filtering is required toidentify collections which are not employed asinitializers and to reduce the collection of er-roneous items.
Analyzing the syntactic formsh:has allowed us to construct a set of regularexpressions which are used to eliminate non-initializers and disregard any items collectedfollowing them.We have extracted 1813 potential initial-izers from the corpus of HTML pages col-lected via AV & NL for the query string listof NE.
Using lexico-syntactic patterns in or-der to identify correct initializers, we have de-signed a shallow parser for filtering and ana-lyzing the strings.
This parser consists of 14modules, 4 of which carry out pre-filtering toprepare and tag the corpus, and 10 of whichcarry out a fine-grained syntactic analysis, re-moving collections that do not function as ini-tializers.
After filtering, the corpus contains520 collections.
The process has a precisionof 78% and a recall of 90%.6 Conc lus ionThis study is another application that demon-strates the usability of the WWW as a re-source for NLP (see, for instance, (Grefen-stette, 1999) for an application of usingWWW frequencies in selecting translations).It also confirms the interest of non-textual lin-guistic features, such as formatting markups,inNLP for structured ocuments such as Webpages.
Further work on Web-based NE acqui-sition could take advantage of machine learn-ing techniques as used for wrapper induction(Kushmerick et al, 1997).Re ferencesE.
Amitay.
1999.
Anchors in context: A corpusanalysis of web pages authoring conventions.
InL.
Pemberton and S. Shurville, editors, Wordson the Web - Computer Mediated Communica-tion, page 192.
Intellect Books, UK.C.
Aone, N. Charocopos, and J. Gorlinski.1997.
An intelligent multilingual informationbrowsing and retrieval system using Informa-tion Extraction.
In Proceedings, Fifth Confer-ence on Applied Natural Language Processing(ANLP'97), pages 332-39, Washington, DC.R.
Basili, M.T.
Pazienza, and P. Velardi.
1993.Acquisition of selectional patterns in sublan-guages.
Machine Translation, 8:175-201.B.
Boguraev and J. Pustejovsky, editors.
1996.Corpus Processing for Lexical Acquisition.
MITPress, Cambridge, MA.F.
Crimmins, A.F.
Smeaton, T. Dkaki, andJ Mothe.
1999.
T@trafusion: Information dis-covery on the internet.
IEEE Intelligent Sys-tems and Their Applications, 14(4):55-62.B.
Daille.
1996.
Study and implementation ofcombined techniques for automatic extractionof terminology.
In J.L.
Klavans and P. Resnik,editors, The Balancing Act, pages 49-66.
MITPress, Cambridge, MA.G.
Grefenstette.
1994.
Explorations in AutomaticThesaurus Discovery.
Kluwer Academic Pub-lisher, Boston, MA.G.
Grefenstette.
1999.
The WWW as a resourcefor example-based MT tasks.
In Proc., ASLIBTranslating and the Computer 21 Conference,London.M.A.
Hearst.
1998.
Automated discovery ofWordNet relations.
In C. Fellbaum, editor,WordNet: An Electronic Lexical Database.
MITPress, Cambridge, MA.N.
Kushmerick, D.S.
Weld, and R. Doorenbos.1997.
Wrapper induction for information ex-traction.
In Proc., IJCAI'97, pages 729-735,Nagoya.M.-P. P@ry-Woodley.
1998.
Signalling in writtentext: a corpus based approach.
In Workshop onDiscourse Relations and Discourse Markers at .COLING-ALC'98, pages 79-85.H.
Schmid.
1999.
Improvements in part-of-speech tagging with an application to german.In S. Armstrong, K.W.
Church, P. Isabelle,S.
Manzi, E. Tzoukermann, and D. Yarowski,editors, Natural Language Processing UsingVery Large Corpora.
Kluwer, Dordrecht.J.
Virbel.
1985.
Mise en forme des documents.Cahiers de Grammaire, 17.
- -189
