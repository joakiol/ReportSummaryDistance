Disti l l ing dialogues - A method using natural dialoguedialogue systems developmentArne  JSnsson  and  N i l s  Dah lb~ickDepar tment  of Computer  and  In format ion  Sc ienceL inkSp ing  Un ivers i tyS-581 83, L INKOPINGSWEDENnilda@ida.liu.se, arnjo@ida.liu.secorpora forAbst ractWe report on a method for utilising corpora col-lected in natural settings.
It is based on distilling(re-writing) natural dialogues to elicit the type ofdialogue that would occur if one the dialogue par-ticipants was a computer instead of a human.
Themethod is a complement toother means uch as Wiz-ard of Oz-studies and un-distilled natural dialogues.We present he distilling method and guidelines fordistillation.
We also illustrate how the method af-fects a corpus of dialogues and discuss the pros andcons of three approaches in different phases of dia-logue systems development.1 In t roduct ionIt has been known for quite some time now, thatthe language used when interacting with a comput-er is different from the one used in dialogues betweenpeople, (c.f.
JSnsson and Dahlb~ick (1988)).
Giventhat we know that the language will be different,but not how it will be different, we need to baseour development of natural language dialogue sys-tems on a relevant set of dialogue corpora.
It is ourbelief that we need to clarify a number of differentissues regarding the collection and use of corpora inthe development of speech-only and multimodal dia-logue systems.
Exchanging experiences and develop-ing guidelines in this area are as important as, and insome sense a necessary pre-requisite to, the develop-ment of computational models of speech, language,and dialogue/discourse.
It is interesting to note thedifference in the state of art in the field of natu-ral language dialogue systems with that of corpuslinguistics, where issues of the usefulness of differentsamples, the necessary sampling size, representative-ness in corpus design and other have been discussedfor quite some time (e.g.
(Garside t al., 1997; Atkinset al, 1992; Crowdy, 1993; Biber, 1993)).
Also theneighboring area of evaluation of NLP systems (foran overview, see Sparck Jones and Galliers (1996))seems to have advanced further.Some work have been done in the area of natu-ral language dialogue systems, e.g.
on the designof Wizard of Oz-studies (Dahlb~ck et al, 1998),on measures for inter-rater eliability (Carletta,1996), on frameworks for evaluating spoken dialogueagents (Walker et al, 1998) and on the use of differ-ent corpora in the development of a particular sys-tem (The Carnegie-Mellon Communicator, Eskenaziet al (1999)).The question we are addressing in this paper ishow to collect and analyse relevant corpora.
We be-gin by describing what we consider to be the mainadvantages and disadvantages of the two currentlyused methods; studies of human dialogues and Wiz-ard of Oz-dialogues, especially focusing on the eco-logical validity of the methods.
We then describe amethod called 'distilling dialogues', which can serveas a supplement to the other two.2 Natural and Wizard ofOz-DialoguesThe advantage of using real dialogues between peo-ple is that they will illustrate which tasks and needsthat people actually bring to a particular serviceprovider.
Thus, on the level of the users' generalgoals, such dialogues have a high validity.
But thereare two drawbacks here.
First; it is not self-evidentthat users will have the same task expectations froma computer system as they have with a person.
Sec-ond, the language used will differ from the languageused when interacting with a computer.These two disadvantages have been the majorforce behind the development of Wizard of Oz-methods.
The advantage here is that the setting willbe human-computer interaction.
But there are im-portant disadvantages, too.
First, on the practicalside, the task of setting up a high quality simulationenvironment and training the operators ('wizards')to use this is a resource consuming task (Dahlb~ck etal., 1998).
Second, and probably even more impor-tant, is that we cannot hen observe real users usinga system for real life tasks, where they bring theirown needs, motivations, resources, and constraintsto bear.
To some extent this problem can be over-come using well-designed so called 'scenarios'.
Aspointed out in Dahlb~ck (1991), on many levels ofanalysis the artificiality of the situation will not af-44fect the language used.
An example of this is thepattern of pronoun-antecedent relations.
But sincethe tasks given to the users are often pre-describedby the researchers, this means that this is not a goodway of finding out which tasks the users actuallywant to perform.
Nor does it provide a clear enoughpicture on how the users will act to find somethingthat satisfies their requirements.
If e.g.
the task isone of finding a charter holiday trip or buying a TV-set within a specified set of constraints (economicaland other), it is conceivable that people will staywith the first item that matches the specification,whereas in real life they would probably look foralternatives.
In our experience, this is primarily aconcern if the focus is on the users' goals and plans,but is less a problem when the interest is on lower-level aspects, such as, syntax or patterns of pronoun-antecedent relationship (c.f.
Dahlb~ick (1991)).To summarize; real life dialogues will provide areasonably correct picture of the way users' ap-proach their tasks, and what tasks they bring tothe service provider, but the language used will notgive a good approximation of what the system un-der construction will need to handle.
Wizard of Oz-dialogues, on the other hand, will give a reasonableapproximation of some aspects of the language used,but in an artificial context.The usual approach has been to work in threesteps.
First analyse real human dialogues, and basedon these, in the second phase, design one or moreWizard of Oz-studies.
The final step is to fine-tunethe system's performance on real users.
A good ex-ample of this method is presented in Eskenazi et al(1999).
But there are also possible problems withthis approach (though we are not claiming that thiswas the case in their particular project).
Eskenazi etal.
(1999) asked a human operator to act 'computer-like' in their Wizard of Oz-phase.
The advantageis of course that the human operator will be ableto perform all the tasks that is usually provided bythis service.
The disadvantage is that it puts a heavyburden on the human operator to act as a comput-er.
Since we know that lay-persons' ideas of whatcomputers can and cannot do are in many respectsfar removed from what is actually the case, we riskintroducing some systematic distortion here.
Andsince it is difficult to perform consistently in similarsituations, we also risk introducing non-systematicdistortion here, even in those cases when the 'wiz-ard' is an NLP-professional.Our suggestion is therefore to supplement heabove mentioned methods, and bridge the gap be-tween them, by post-processing human dialogues togive them a computer-like quality.
The advantage,compared to having people do the simulation on thefly, is both that it can be done with more consis-tency, and also that it can be done by researchersthat actually know what human-computer naturallanguage dialogues can look like.
A possible dis-advantage with using both Wizard of Oz-and realcomputer dialogues, is that users will quickly adaptto what the system can provide them with, and willtherefore not try to use it for tasks they know itcannot perform.
Consequently, we will not get a fullpicture of the different services they would like thesystem to provide.A disadvantage with this method is, of course,that post-processing takes some time compared tousing the natural dialogues as they are.
There is al-so a concern on the ecological validity of the results,as discussed later.3 Distilling dialoguesDistilling dialogues, i.e.
re-writing human interac-tions in order to have them reflect what a human-computer interaction could look like involves a num-ber of considerations.
The main issue is that in cor-pora of natural dialogues one of the interlocutors inot a dialogue system.
The system's task is insteadperformed by a human and the problem is how toanticipate the behaviour of a system that does notexist based on the performance of an agent with dif-ferent performance characteristics.
One importantaspect is how to deal with human features that arenot part of what the system is supposed to be ableto handle, for instance if the user talks about thingsoutside of the domain, such as discussing an episodeof a recent TV show.
It also involves issues on howto handle situations where one of the interlocutersdiscusses with someone lse on a different opic, e.g.discussing the up-coming Friday party with a friendin the middle of an information providing dialoguewith a customer.It is important for the distilling process to have atleast an outline of the dialogue system that is underdevelopment: Will it for instance have the capacityto recognise users' goals, even if not explicitly stat-ed?
Will it be able to reason about the discoursedomain?
What services will it provide, and whatwill be outside its capacity to handle?In our case, we assume that the planned dialoguesystem has the ability to reason on various aspectsof dialogue and properties of the application.
In ourcurrent work, and in the examples used for illustra-tion in this paper, we assume a dialogue model thatcan handle any relevant dialogue phenomenon andalso an interpreter and speech recogniser being ableto understand any user input that is relevant o thetask.
There is is also a powerful domain reason-ing module allowing for more or less any knowledgereasoning on issues that can be accomplished with-in the domain (Flycht-Eriksson, 1999).
Our currentsystem does, however, not have an explicit user taskmodel, as opposed to a system task model (Dahlb~ick45and JSnsson, 1999), which is included, and thus, wecan not assume that the 'system' remembers utter-ances where the user explains its task.
Furthermore,as our aim is system development we will not con-sider interaction outside the systems capabilities asrelevant o include in the distilled dialogues.The context of our work is the development amulti-modal dialogue system.
However, in our cur-rent work with distilling dialogues, the abilities ofa multi-modal system were not fully accounted for.The reason for this is that the dialogues would besignificantly affected, e.g.
a telephone conversationwhere the user always likes to have the next con-nection, please will result in a table if multi-modaloutput is possible and hence a fair amount of the di-alogne is removed.
We have therefore in this paperanalysed the corpus assuming a speech-only system,since this is closer to the original telephone conversa-tions, and hence needs fewer assumptions on systemperformance when distilling the dialogues.4 Dis t i l l a t ion  gu ide l inesDistilling dialogues requires guidelines for how tohandle various types of utterances.
In this sectionwe will present our guidelines for distilling a corpusof telephone conversations between a human infor-mation provider on local buses 1to be used for devel-oping a multimodal dialogue system (Qvarfordt andJSnsson, 1998; Flycht-Eriksson and JSnsson, 1998;Dahlb~ick et al, 1999; Qvarfordt, 1998).
Similarguidelines are used within another project on devel-oping Swedish Dialogue Systems where the domainis travel bureau information.We can distinguish three types of contributors:'System' (i.e.
a future systems) utterances, User ut-terances, and other types, such as moves by otherspeakers, and noise.4.1 Modifying system utterancesThe problem of modifying 'system' utterances canbe divided into two parts: how to change and whento change.
They are in some respects intertwined,but as the how-part affects the when-part more wewill take this as a starting point.?
The 'system' provides as much relevant infor-mation as possible at once.
This depends onthe capabilities of the systems output modal-ities.
If we have a screen or similar outputdevice we present as much as possible whichnormally is all relevant information.
If we, onthe other hand, only have spoken output theamount of information that the hearer can inter-pret in one utterance must be considered when1The bus time table dialogues are collected atLinkSping University and are available (in Swedish) onhttp://www.ida.l iu.se/~arnjo/kfb/dialoger.htmldistilling.
The system might in such cases pro-vide less information.
The principle of provid-ing all relevant information is based on the as-sumption that a computer system often has ac-cess to all relevant information when queryingthe background system and can also present itmore conveniently, especially in a multimodalsystem (Ahrenberg et al, 1996).
A typical ex-ample is the dialogue fragment in figure 1.
Inthis fragment he system provides informationon what train to take and how to change to abus.
The result of distilling this fragment pro-vides the revised fragment of figure 2.
As seen inthe fragment of figure 2 we also remove a num-ber of utterances typical for human interaction,as discussed below.
* System utterances are made more computer-l ikeand do not include irrelevant information.
Thelatter is seen in $9 in the dialogue in figure 3where the provided information is not relevant.It could also be possible to remove $5 and re-spond with $7 at once.
This, however, dependson if the information grounded in $5-U6 is need-ed for the 'system' in order to know the arrivaltime or if that could be concluded from U4.This in turn depends on the system's capabili-ties.
If we assume that the dialogue system hasa model of user tasks, the information in $5-U6could have been concluded from that.
We will,in this case, retain $5-U6 as we do not assume auser task model (Dahlb/ick and JSnsson, 1999)and in order to stay as close to the original di-alogue as possible.The next problem concerns the case when 'system'utterances are changed or removed.?
Dialogue contributions provided by something orsomeone other than the user or the 'system' areremoved.
These are regarded as not being partof the interaction.
This means that if some-one interrupts the current interaction, say thatthe telephone rings during a face-to-face inter-action, the interrupting interaction is normallyremoved from the corpus.Furthermore, 'system' interruptions are re-moved.
A human can very well interrupt anoth-er human interlocuter, but a computer systemwill not do that.However, this guideline could lead to problems,for instance, when users follow up such interrup-tions.
If no information is provided or the in-terrupted sequence does not affect the dialogue,we have no problems removing the interruption.The problem is what to do when informationfrom the 'system' is used in the continuing dia-logue.
For such cases we have no fixed strategy,46U4:$5:U6:$7:U8:$9:U10:$11:U12:S13:U14:$15:yes I wonder if you have any mm buses or (.)
like express buses leaving from LinkSpingto Vadstena (.)
on sundayja ville undra om ni hade ndgra 5h bussar eUer (.)
typ expressbussar sore dkte frdn LinkSpingtill Vadstena (.)
pd sSndano the bus does not run on sundaysnej bussen g~r inte pd sSndagarhow can you (.)
can you take the train and then change some way (.)
because (.
)to MjSlby 'n' sohur kan man (.)
kan man ta tdg d sen byta p~ ndtt sStt (.)
fSr de (.
)till mjSlby ~ sdthat you can do too yesde kan du gSra ocksd jahow (.)
do you have any such suggestionshut (.)
har du n~ra n~gra s~na fSrslagyes let's see (4s) a moment (15s) now let us see here (.)
was it on the sunday you should travelja ska se h~ir (4s) eft 5gonblick (15s) nu ska vise hSr (.)
va de p~ sSndagen du skulle dka pdyes right afternoon preferablyja just de eftermidda ggirnaafternoon preferable (.)
you have train from LinkSping fourteen twenty nineeftermidda gSrna (.)
du hat t~g frdn LinkSping fjorton d tjugoniemmmmand then you will change from MjSlby station six hundred sixtysd byter du frdn MjSlby station sexhundrasextisixhundred sixtysexhundrasextififteen and tenfemton ~ tieFigure 1: Dialogue fragment from a real interaction on bus time-table informationU4: I wonder if you have any buses or (.)
like express buses going from LinkSpingto Vadstena (.)
on sundayS5: no the bus does not run on sundaysU6: how can you (.)
can you take the train and then change some way (.)
because (.
)to MjSlby and so$7: you can take the train from LinkSping fourteen and twenty nine and then you willchange at MjSlby station to bus six hundred sixty at fifteen and tenFigure 2: A distilled version of the dialogue in figure 1the dialogue needs to be rearranged ependingon how the information is to be used (c.f.
thediscussion in the final section of this paper).?
'System' utterances which are no longer validare removed.
Typical examples of this are theutterances $7, $9, $11 and $13 in the dialoguefragment of figure 1.
* Remove sequences of utterances where the 'sys-tem' behaves in a way a computer would not do.For instance jokes, irony, humor, commentingon the other dialogue participant, or droppingthe telephone (or whatever is going on in $7in figure 4).
A common case of this is whenthe 'system' is talking while looking for infor-mation, $5 in the dialogue fragment of figure 4is an example of this.
Related to this is whenthe system provides its own comments.
If wecan assume that it has such capabilities theyare included, otherwise we remove them.The system does not repeat information that hasalready been provided unless explicitly asked todo so.
In human interaction it is not uncommonto repeat what has been uttered for purposesother than to provide grounding information orfeedback.
This is for instance common during47U4: 'n' I must be at Resecentrum before fourteen and thirty five (.)
'cause we will going to theinterstate busesja ska va p~ rececentrum innan \]jorton ~ trettifem (.)
f5 vi ska tilll~ngf~irdsbussarna$5: aha (.)
'n' then you must be there around twenty past two something thenjaha (.)
~ dd behhver du va here strax e~ter tjuge 5vet tvd n~nting d~U6: yes around thatja ungefgir$7: let's see here ( l ls)  two hundred and fourteen Ryd end station leaves forty six (.)
thirteen 'n'forty six then you will be down fourteen oh seven (.
)d~ ska vise hSr (11s) tv~hundrafjorton Ryd 5ndh~llplatsen gdr ~5rtisex (.)
tretton d\]Srtisex d~ dr du nere ~jorton noll sju 5)U8: ahajaha$9: 'n' (.)
the next one takes you there (.)
fourteen thirty seven (.)
but that is too late(.)
ndsta dr du nere 5) ~jorton d trettisju (.)
men de 5 ju ~Sr sentFigure 3: Dialogue fragment from a real interaction on bus time-table informationU2: Well, hi (.)
I am going to Ugglegatan eighthja hej (.)
ja ska till Ugglegatan dtta$3: YesjaU4: and (.)
I wonder (.)
it is somewhere in Tanneforsoch (.)
jag undrar (.)
det ligger ndnstans i Tannefors$5: Yes (.)
I will see here one one I will look exactly where it is one moment pleaseja (.)
jag ska se hhr eft eft jag ska titta exakt vat det ligger eft 6gonblick barnU6: Oh Yeahjar~$7: (operator disconnects) (25s) mm (.)
okey (hs) what the hell (2s)(operator connects again) hello yes((Telefonisten kopplar ur sig)) (25s) iihh (.)
okey (hs) de va sore \]aan (2s)((Telefonisten kopplar in sig igen)) halld jaU8: Yes helloja hej$9: It is bus two hundred ten which runs on old tannefors road that you have to take and get off atthe bus stop at that bus stop named vetegatandet ~i buss tv~hundratio sore g~r gamla tanne~orsvSgen som du ~r  ~ka ~ g~ av ridden hdllplatsen rid den hdllplatsen sore heter vetegatan.Figure 4: Dialogue fragment from a natural bus timetable interactionsearch procedures as discussed above.?
The system does not ask for information it hasalready achieved.
For instance asking again if itis on Sunday as in $9 in figure 1.
This is not un-common in human interaction and such utter-ances from the user are not removed.
However,we can assume that the dialogue system doesnot forget what has been talked about before.4.2 Mod i fy ing  user  u t te rancesThe general rule is to change user utterances as lit-tle as possible.
The reason for this is that we do notwant to develop systems where the user needs torestrict his/her behaviour to the capabilities of thedialogue system.
However, there are certain changesmade to user utterances, in most cases as a conse-quence of changes of system utterances.Utterances that are no longer valid are removed.The most common cases are utterances whoserequest has already been answered, as seen inthe distilled dialogue in figure 2 of the dialoguein figure 1.48Sl1: sixteen fifty fivesexton \]emti/emU12: sixteen fifty five (.)
ahasexton femti/em (.)
jahaS13: bus line four hundred thirty fivelinje \]yrahundra tretti/emFigure 5: Dialogue fragment from a natural bustimetable interaction?
Utterances are removed where the user discuss-es things that are in the environment.
Forinstance commenting the 'systems' clothes orhair.
This also includes other types of commu-nicative signals such as laughter based on thingsoutside the interaction, for instance, in the en-vironment of the interlocuters.?
User utterances can also be added in order tomake the dialogue continue.
In the dialogue infigure 5 there is nothing in the dialogue xplain-ing why the system utters S13.
In such caseswe need to add a user utterance, e.g.
Whichbus is that?.
However, it might turn out thatthere are cues, such as intonation, found whenlistening to the tapes.
If  such detailed analysesare carried out, we will, of course, not need toadd utterances.
Furthermore, it is sometimesthe case that the telephone operator deliberate-ly splits the information into chunks that canbe comprehended by the user, which then mustbe considered in the distillation.5 App ly ing  the  methodTo illustrate the method we will in this section try tocharacterise the results from our distillations.
Theillustration is based on 39 distilled dialogues fromthe previously mentioned corpus collected with atelephone operator having information on local bustime-tables and persons calling the information ser-vice.The distillation took about three hours for all 39dialogues, i.e.
it is reasonably fast.
The distilleddialogues are on the average 27% shorter.
However,this varies between the dialogues, at most 73% wasremoved but there were also seven dialogues thatwere not changed at all.At the most 34 utterances where removed fromone single dialogue and that was from a dialoguewith discussions on where to find a parking lot, i.e.discussions outside the capabilities of the applica-tion.
There was one more dialogue where more than30 utterances were removed and that dialogue is atypical example of dialogues where distillation actu-ally is very useful and also indicates what is normal-ly removed from the dialogues.
This particular dia-logue begins with the user asking for the telephonenumber to 'the Lost property office' for a specific busoperator.
However, the operator starts a discussionon what bus the traveller traveled on before provid-ing the requested telephone number.
The reason forthis discussion is probably that the operator knowsthat different bus companies are utilised and wouldlike to make sure that the user really understandshis/her request.
The interaction that follows can,thus, in that respect be relevant, but for our pur-pose of developing systems based on an overall goalof providing information, not to understand humaninteraction, our dialogue system will not able to han-dle such phenomenon (JSnsson, 1996).The dialogues can roughly be divided into five dif-ferent categories based on the users task.
The dis-cussion in twenty five dialogues were on bus timesbetween various places, often one departure and onearrival but five dialogues involved more places.
Infive dialogues the discussion was one price and var-ious types of discounts.
Five users wanted to knowthe telephone number to 'the Lost property office',two discussed only bus stops and two discussed howthey could utilise their season ticket to travel out-side the trafficking area of the bus company.
It isinteresting to note that there is no correspondencebetween the task being performed uring the inter-action and the amount of changes made to the dia-logue.
Thus, if we can assume that the amount ofdistillation indicates omething about a user's inter-action style, other factors than the task are impor-tant when characterising user behaviour.Looking at what is altered we find that the mostimportant distilling principle is that the 'system'provides all relevant information at once, c.f.
fig-ures 1 and 2.
This in turn removes utterances pro-vided by both 'system' and user.Most added utterances, both from the user andthe 'system', provide explicit requests for informa-tion that is later provided in the dialogue, e.g.
ut-terance $3 in figure 6.
We have added ten utterancesin all 39 dialogues, five 'system' utterances and fiveuser utterances.
Note, however, that we utilised thetranscribed ialogues, without information on into-nation.
We would probably not have needed to addthis many utterances if we had utilised the tapes.Our reason for not using information on intonationis that we do not assume that our system's peechrecogniser can recognise intonation.Finally, as discussed above, we did not utilise thefull potential of multi-modality when distilling thedialogues.
For instance, some dialogues could befurther distilled if we had assumed that the systemhad presented a time-table.
One reason for this isthat we wanted to capture as many interesting as-pects intact as possible.
The advantage is, thus, thatwe have a better corpus for understanding human-49U2: Yees hi Anna Nilsson is my name and I would like to take the bus from Ryd center to Resecentrumin LinkSpingjaa hej Anna Nilsson heter jag och jag rill ~ka buss ~r~n Ryds centrum till resecentrumi LinkSping.$3: mm When do you  want  to  leave?mm N~ir r i l l  du  ?ka?U4: 'n' I must be at Resecentrum before fourteen and thirty five (.)
'cause we will going to theinterstate busesja ska va p~ rececentrum innan fjorton d trettifem (.)
f5 vi ska tilll~ngfiirdsbussarnaFigure 6: Distilled dialogue fragment with added utterancecomputer interaction and can from that corpus doa second distillation where we focus more on multi-modal interaction.6 Discuss ionWe have been presenting a method for distilling hu-man dialogues to make them resemble human com-puter interaction, in order to utilise such dialoguesas a knowledge source when developing dialogue sys-tems.
Our own main purpose has been to use themfor developing multimodal systems, however, as dis-cussed above, we have in this paper rather assumeda speech-only system.
But we believe that the basicapproach can be used also for multi-modal systemsand other kinds of natural language dialogue sys-tems.It is important o be aware of the limitations ofthe method, and how 'realistic' the produced resultwill be, compared to a dialogue with the final sys-tem.
Since we are changing the dialogue moves, byfor instance providing all required information in onemove, or never asking to be reminded of what the us-er has previously requested, it is obvious that whatfollows after the changed sequence would probablybe affected one way or another.
A consequence ofthis is that the resulting dialogue is less accurate asa model of the entire dialogue.
It is therefore not anideal candidate for trying out the systems over-allperformance during system development.
But forthe smaller sub-segments or sub-dialogues, we be-lieve that it creates a good approximation of whatwill take place once the system is up and running.Furthermore, we believe distilled dialogues in somerespects to be more realistic than Wizard of Oz-dialogues collected with a wizard acting as a com-puter.Another issue, that has been discussed previouslyin the description of the method, is that the distillingis made based on a particular view of what a dialoguewith a computer will look like.
While not necessari-ly being a detailed and specific model, it is at leastan instance of a class of computer dialogue models.One example of this is whether the system is meantto acquire information on the user's underlying mo-tivations or goals or not.
In the examples presented,we have not assumed such capabilities, but this as-sumption is not an absolute necessity.
We believe,however, that the distilling process should be basedon one such model, not the least to ensure a con-sistent treatment of similar recurring phenomena tdifferent places in the corpora.The validity of the results based on analysing dis-tilled dialogues depends part ly on how the distilla-tion has been carried out.
Even when using naturaldialogues we can have situations where the interac-tion is somewhat mysterious, for instance, if some ofthe dialogue participants behaves irrational such asnot providing feedback or being too elliptical.
How-ever, if careful considerations have been made to stayas close to the original dialogues as possible, we be-lieve that distilled dialogues will reflect what a hu-man would consider to be a natural interaction.AcknowledgmentsThis work results from a number of projects on de-velopment of natural language interfaces upportedby The Swedish Transport & Communications Re-search Board (KFB) and the joint Research Programfor Language Technology (HSFR/NUTEK) .
We areindebted to the participants of the Swedish DialogueSystems project, especially to Staffan Larsson, LenaSantamarta, and Annika Flycht-Eriksson for inter-esting discussions on this topic.Re ferencesLars Ahrenberg, Nils Dahlb~ck, Arne JSnsson,and /~ke Thur~e.
1996.
Customizing interac-tion for natural language interfaces.
LinkSpin9Electronic articles in Computer and Informa-tion Science, also in Notes from Workshop onPragmatics in Dialogue, The XIV:th Scandi-navian Conference of Linguistics and the VI-II:th Conference of Nordic and General Linguis-50tics, GSteborg, Sweden, 1993, 1(1), October, 1.http :/ / www.ep.liu.se / ea /cis /1996 / O01/.Sue Atkins, Jeremy Clear, and Nicholas Ostler.1992.
Corpus design criteria.
Literary and Lin-guistic Computing, 7(1):1-16.Douglas Biber.
1993.
Representativeness in cor-pus design.
Literary and Linguistic Computing,8(4):244-257.Jean Carletta.
1996.
Assessing agreement on classi-fication tasks: The kappa statistic.
Computation-al Linguistics, 22(2):249-254.Steve Crowdy.
1993.
Spoken corpus design.
Literaryand Linguistic Computing, 8(4):259-265.Nils Dahlb/ick and Arne JSnsson.
1999.
Knowledgesources in spoken dialogue systems.
In Proceed-ings of Eurospeech'99, Budapest, Hungary.Nils Dahlb/ick, Arne JSnsson, and Lars Ahrenberg.1998.
Wizard of oz studies - why and how.In Mark Maybury & Wolfgang Wahlster, editor,Readings in Intelligent User Interfaces.
MorganKaufmann.Ntis Dahlb/ick, Annika Flycht-Eriksson, ArneJSnsson, and Pernilla Qvarfordt.
1999.
An ar-chitecture for multi-modal natural dialogue sys-tems.
In Proceedings of ESCA Tutorial and Re-search Workshop (ETRW) on Interactive Dialoguein Multi-Modal Systems, Germany.Nils Dahlb/ick.
1991.
Representations ofDiscourse,Cognitive and Computational Aspects.
Ph.D. the-sis, LinkSping University.Maxine Eskenazi, Alexander Rudnicki, Karin Grego-ry, Paul Constantinides, Robert Brennan, Christi-na Bennett, and Jwan Allen.
1999.
Data collec-tion and processing in the carnegie mellon com-municator.
In Proceedings of Eurospeech'99, Bu-dapest, Hungary.Annika Flycht-Eriksson and Arne JSnsson.
1998.
Aspoken dialogue system utilizing spatial informa-tion.
In Proceedings of ICSLP'98, Sydney, Aus-tralia.Annika Flycht-Eriksson.
1999.
A survey of knowl-edge sources in dialogue systems.
In Proceedingsof lJCAI-99 Workshop on Knowledge and Reason-ing in Practical Dialogue Systems, August, Stock-holm.Roger Garside, Geoffrey Leech, and AnthonyMeEnery.
1997.
Corpus Annotation.
Longman.Arne JSnsson and Nils Dahlb/ick.
1988.
Talking to acomputer is not like talking to your best friend.
InProceedings of the First Scandinavian Conferenceon Artificial InterUigence, Tvoms?.Arne JSnsson.
1996.
Natural language generationwithout intentions.
In Proceedings of ECAI'96Workshop Gaps and Bridges: New Directionsin Planning and Natural Language Generation,pages 102-104.Pernilla Qvarfordt and Arne JSnsson.
1998.
Effectsof using speech in timetable information systemsfor www.
In Proceedings of ICSLP'98, Sydney,Australia.Pernilla Qvarfordt.
1998.
Usability of multimodaltimetables: Effects of different levels of do-main knowledge on usability.
Master's thesis,LinkSping University.Karen Sparck Jones and Julia R. Galliers.
1996.Evaluating Natural Language Processing Systems.Springer Verlag.Marilyn A. Walker, Diane J. Litman, Candace A.Kamm, and Alicia Abella.
1998.
Paradise: Aframework for evaluating spoken dialogue agents.In Mark Maybury & Wolfgang Wahlster, editor,Readings in Intelligent User Interfaces.
MorganKaufmann.51
