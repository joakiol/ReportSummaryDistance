Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 501?507, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsSSA-UO: Unsupervised Twitter Sentiment AnalysisReynier Ortega, Adrian FonsecaCERPAMID, University of OrienteAve Patricio Lumumba S/NSantiago de Cuba, CubaYoan Gutie?rrezDI, University of MatanzasAutopista a Varadero Km 312Matanzas, CubaAndre?s MontoyoDLSI, University of AlicanteCarretera de San Vicente S/NAlicante,SpainAbstractThis paper describes the specifications and re-sults of SSA-UO, unsupervised system, pre-sented in SemEval 2013 for Sentiment Analy-sis in Twitter (Task 2) (Wilson et al 2013).The proposal system includes three phases:data preprocessing, contextual word polaritydetection and message classification.
Thepreprocessing phase comprises treatment ofemoticon, slang terms, lemmatization andPOS-tagging.
Word polarity detection is car-ried out taking into account the sentiment as-sociated with the context in which it appears.For this, we use a new contextual sentimentclassification method based on coarse-grainedword sense disambiguation, using WordNet(Miller, 1995) and a coarse-grained sense in-ventory (sentiment inventory) built up fromSentiWordNet (Baccianella et al 2010).
Fi-nally, the overall sentiment is determined us-ing a rule-based classifier.
As it may be ob-served, the results obtained for Twitter andSMS sentiment classification are good consid-ering that our proposal is unsupervised.1 IntroductionThe explosion of Web 2.0 has marked a new agefor the human society.
The huge use of Social Me-dia such as Facebook1 , MySpace2 , LinkedIn3 andTwitter4 , offers a place for people to share informa-tion in real time.
Twitter is one of the most popular1https://www.facebook.com2http://www.myspace.com/3http://www.linkedin.com4https://www.twitter.com/social network websites and has been growing at avery fast pace.
The number of active users exceeds500 million and the number of tweets posted by dayexceeds 500 million (as of May 2012)5.
Through thetwitter applications, users shared opinions about per-sonalities, politicians, products, companies, events,etc.
This has been attracting the attention of dif-ferent research communities interested in analyz-ing its content and motivated many natural languagetasks, such as sentiment analysis, emotions detec-tion, opinions retrieval, product recommendation oropinion summarization.One of the most popular sentiment analysis tasksis polarity classification.
This task is a new fieldthat classifies opinion texts as positive, negative orneutral (Pang et al 2002; Turney, 2002; Esuli andSebastiani, 2006; Wilson et al 2006; Wiegand etal., 2010).
Determining polarity might seem an easytask, as many words have some polarity by them-selves.
However, words do not always express thesame sentiment, and in most cases the polarity of aword depends on the context in which the word isused.
So, terms that clearly denote negative feel-ings can be neutral, or even positive, dependingon their context.
Hence, sentiment analysis sys-tems should include semantic-level analysis in orderto solve word ambiguity and correctly capture themeaning of each word according to its context.
Also,complex linguistic processing is needed to deal withproblems such as the effect of negations and infor-mal language.
Moreover, understanding the senti-mental meaning of the different textual units is im-portant to accurately determine the overall polarity5http://www.statisticbrain.com/twitter-statistics/501of a text.In this paper, we present a system that has as mainobjective to analyze the sentiments of tweets andclassify these as positive, negative or neutral.
Theproposal system includes three phases: data prepro-cessing, contextual word polarity detection and mes-sage classification.
The preprocessing phase com-prises treatment of emoticons, spell-errors, slangterms, lemmatization and POS-tagging.
Word po-larity detection is carried out taking into account thesentiment associated with the context within whichit appears.
For this, we use a new contextual senti-ment classification method based on coarse-grainedword sense disambiguation, using WordNet (Miller,1995) and a coarse-grained sense inventory (senti-ment inventory) built up from SentiWordNet (Bac-cianella et al 2010).
Finally, the polarity is deter-mined using a rule-based classifier.
The paper isorganized as follows.
Section 2 describes of SSA-UO system.
In Section 3 we evaluate our proposaland discuss the results obtained in the SemEval 2013Task No.
2.
Finally, section 4 provides concludingremarks.2 SSA-UO SystemWe use an unsupervised strategy consisting in acoarse-grained clustering-based word sense disam-biguation (WSD) method that differentiates positive,negative, highly positive, highly negative and objec-tive uses of every word on context which it occurs.The proposal method uses WordNet and a coarse-grained sense inventory (sentiment inventory) builtup from SentiWordNet.
The overall architecture ofour sentiment classifier is shown in Figure 1.Firstly, data preprocessing is done to eliminate in-complete, noisy or inconsistent information.
A Sen-timent Word Sense Disambiguation method (Section2.3) is then applied to content words (nouns, adjec-tives, verbs and adverbs).
Once all content wordsare disambiguated, we apply a rule-based classifier(Section 2.4) to decide whether the tweet is positive,negative or neutral.Unsupervised word sense disambiguation methodproposed by (Anaya-Sa?nchez et al 2006) wasadapted for sentiment word sense disambiguation.Unlike the authors, who aim to obtain the correctsense of a word, we use the method to determineFigure 1: Overall architecture of Sentiment Classifierwhen a word is used with highly positive (HP), posi-tive (P), highly negative (HN), negative (N) or objec-tive (O) meaning based on a sentiment sense inven-tory.
We make sentiment sense inventory based onsense-level annotation in SentiWordNet.
Finally, weapply a rule-based classifier to determine the overallsentiment in tweet.2.1 Data PreprocessingThe tweets differ from the text in articles, books, oreven spoken language.
It is limited to 140 charac-ters, also includes many idiosyncratic uses, such asemoticons, slang terms, misspellings, URLs, ?RT?for re-tweet, ?@?
for user mentions, ?#?
for hash-tags, and character repetitions.
Therefore it is nec-essary to preprocess the text, in order to reduce thenoise information.
The preprocessing step involvethe following task.
The text is tokenized and URL,re-tweets and author mentions are removed.
Hash-tag tokens frequently contain relevant informationrelated to the topic of the tweet, this is included aspart of the text but without the ?#?
character.
Wereplace emoticon tokens by emotion words usingan emoticons dictionary, obtained from Wikipedia5026.
Each emoticon was manually annotated with anemotion word and polarity value.
Emoticons thatsuggest positive emotions - ?
:-)?, ?
:)?, ?X-D?
- areannotated with the emotion word ?happy?
and neg-ative emoticons - ?
:-(?, ?
:-c?, ?:,(?
- are annotatedwith the emotion word ?sad?.
The presence of ab-breviations within a tweet is noted, therefore abbre-viations are replaced by their meaning (e.g., LOL ?laughing out loud) using a dictionary7.
Finally thetext is POS-tagged and lemmatized using TreeTag-ger (Schmid, 1994) and stopwords are discarded.2.2 Sentiment Sense InventoryWe considered SentiWordNet for building senti-ment coarse-grained sense inventory.
SentiWordNetcontain positive, negative and objective scores be-tween 0 and 1 for all senses in WordNet.
Basedon this sense level annotation, we define a newrule (SentiS) for classifying senses in five sentimentclass.
The senses are classified in the following man-ner (Alexandra et al 2009): senses whose positivescore is greater than or equal to 0.75 are consid-ered to be highly positive (HP), senses with posi-tive score greater than or equal to 0.5 and lower than0.75 are considered positive (P), senses with nega-tive score greater than or equal 0.75 are consideredhighly negative (HN), whereas those whose negativescore is lower than 0.75 and greater than or equal to0.5 are considered to be negative (N).
In the remain-ing cases, the senses are considered to be objective(O) (see equation(1)).sentiS(s)=??????????????
?HP i f ScoreP(s)?
0.75HN i f ScoreN(s)?
0.75P i f ScoreP(s) < 0.75 and ScoreP(s)?
0.5N i f ScoreN(s) < 0.75 and ScoreN(s)?
0.5O in other case(1)Table 1 summarizes the distribution of the fivesentiment classes once classified all senses of Sen-tiWordNet.A notable unbalance can be observed between thenumber of highly positive, highly negative, positive,negative and objective senses.6http://en.wikipedia.org/wiki/List of emoticons7http://www.noslang.com/dictionary/Once all senses were classified in a five sentimentsense class, we create a coarse sense inventory basedon this classification.
This inventory is defined in thefollowing manner: For each word in SentiWordNetwe grouped its senses with the same sentiment classin a single sense (coarse-sense), in case of objectivesenses these are kept separated.2.3 Contextual Word Polarity DetectionMuch work on sentiment analysis have been di-rected to determine the polarity of opinion usinganotated lexicons with prior polarity (Hatzivas-siloglou and McKeown, 1997; Kamps and Marx,2002; Turney, 2002).
However a word can mod-ify your prior polarity in relation to the contextwithin which it is invoked.
For example the word?earthquake?
is used with negative meaning in thesentence :?Selling the company caused an earthquake amountthe employees?.Whereas it is used in an neutral meaning in thesentence:?An earthquake is the result of a sudden release ofenergy in the Earth?s crust that creates seismic waves?.For this reason, our system uses a coarse-grainedWSD method for obtaining the contextual polarityof all words in tweets.
The selected disambigua-tion method (Anaya-Sa?nchez et al 2006) was de-veloped for the traditional WSD task.
In this WSDmethod, the senses are represented as topic signa-tures (Lin and Hovy, 2000) built from the repositoryof concepts of WordNet.
The disambiguation pro-cess starts from a clustering distribution of all pos-sible senses of the ambiguous words by applyingthe Extended Star clustering algorithm (Gil-Garc?
?aet al 2003).
Such a clustering tries to identify co-hesive groups of word senses, which are assumedto represent different meanings for the set of words.Resource HP HN P N OSWN 310 938 2242 2899 109035Table 1: Senses highly positive, highly negative, positive,negative and objective distributions.503Then, clusters that match the best with the contextare selected.
If the selected clusters disambiguateall words, the process stops and the senses belong-ing to the selected clusters are interpreted as the dis-ambiguating ones.
Otherwise, the clustering is per-formed again (regarding the remaining senses) untila complete disambiguation is achieved.
It does notdistinguish between highly positive, positive, nega-tive, highly negative or objective meaning of a word.In this paper, we propose a strategy to built a coarse-grained sense representation.
Firstly, a topic signa-tures for all senses into WordNet is built and thetopic signatures for coarse-grained senses is the sumof the topic signatures of the corresponding fine-grained senses that was grouped.We explain coarse-grained sense representationusing the following example:Let us consider the adjective ?sad?.
This adjec-tive has three word senses into WordNet 2.0sad#a#1 ?
experiencing or showing sorrow or unhappinesssad#a#2 ?
of things that make you feel sadsad#a#3 ?
bad; unfortunateFirstly the topic signature are built for each wordsense:vector1 = topicSignature(sad#a#1)vector2 = topicSignature(sad#a#2)vector3 = topicSignature(sad#a#3)The senses are classified using equation (1)(inSection 2.2), sense 1 and 3 were considered ashighly negative, whereas the sense 2 is objective.The topic signature associated to highly negativecoarse-grained sense is computed as:topicSignature(sad#a#HN) = sum(vector1+ vector3)and objective coarse-grained sense is kept asvector2topicSignature(sad#a#O) = vector22.4 Rule-based Sentiment ClassifierWe use a rule-based classifier to classify tweets intopositive, negative or neutral.
A polarity value is as-signed to each word, based on equation 2, after thesewere disambiguated.
It is necessary to clarify thatemotion words that replaced emoticons in the pre-processing phase, are not disambiguated.
Instead,we give a prior polarity value equal to 4 if emotionword is ?happy?
and -4 in case that emotion word is?sad?.
It is important to mention that the polarity ofa word is forced into the opposite class if it is pre-ceded by a valence shifter (obtained from the Negatecategory in GI (Stone et al 1966)).polarity(w) =??????????????
?4?42?20i f w is disambiguated as HPi f w is disambiguated as HNi f w is disambiguated as Pi f w is disambiguated as Ni f w is disambiguated as O(2)The polarity of the tweet is determined from thescores of positive and negative words it contains.
Tosum up, for each tweet the overall positive (PosS(t))value and overall negative value (NegS(t)) , are com-puted as:PosS(t) = ?wi?WPpolarity(wi) (3)WP: Words disambiguated as highly positive orpositive in tweet tNegS(t) = ?wi?WNpolarity(wi) (4)WN : Words disambiguated as highly negative ornegative in tweet tIf PosS(t) is greater than NegS(t) then the tweetis considered as positive.
On the contrary, if PosS(t)is less than NegS(t) the tweet is negative.
Finally, ifPosS(t) is equal to NegS(t) the tweet is consideredas neutral.2.5 A Tweet Sentiment Classification ExampleThe general operation of the algorithm is illustratedin the following example:Let us consider the following tweet:@JoeyMarchant: I really love Jennifer Aniston :-)#loving, she is very cooooollll and sexy.
I?m married toher... LOL, http://t.co/2RShsRNSDW504After applying the preprocessing phase, weobtain the following normalized text:I really love Jennifer Aniston ?happy?
loving, sheis very cooll and sexy.
I?m married to her... lots of laughs.When the text is lemmatized and stopwords areremoved, we obtain the following bag of words (foreach word we show: lemma and part-of-speech n-noun, v-verb, a-adjective, r-adverb and u-unknown):really#r love#v jennifer#a aniston#n ?happy?#aloving#a cooll#a sexy#a marry#v lot#n laugh#n.After contextual word polarity detection, weobtain the following result (for each word weshown lemma, part-of-speech and sentiment sense,HP-highly positive, HN-highly negative, P-positive,N-negative and O-objective).really#r#P love#v#P jennifer#a#O aniston#n#O?happy?#a loving#a#HP cooll#a#O sexy#a#Pmarry#v#O lot#n#O laugh#n#POnce that all words were disambiguated weobtained their polarities using the equation 2 intro-duced in section 2.4.
We show the polarities valuesassigned to each word, in Table 2.Word POS Sentiment Polarityreally r P 2love v P 2jennifer a O 0aniston n O 0?happy?
a - 4loving a HP 4cooll a O 0sexy a P 2marry a O 0lot n O 0laugh n P 2Table 2: Polarity assigned to each wordNote that the word ?happy?
has not been dis-ambiguated, its polarity is assigned accordingto the emoticon associated in the original tweet.Afterward we compute overall positive and negativepolarity value:NegS(t) = 0PosS(t) = 2+2+4+4+2+2 = 16Therefore, the tweet t is classified as positive.3 ResultsThis section presents the evaluation of our system inthe context of SemEval 2013 Task No.2 Subtask B(Sentiment Analysis in Twitter).
For evaluating theparticipant?s systems two unlabeled datasets wereprovided, one composed of Twitter messages andanother of SMS messages.
For each dataset tworuns can be submitted, the first (constrained), thesystem can only be used the provided training dataand other resources such as lexicons.
In the second(unconstrained), the system can use additional datafor training.
Our runs are considered as constrainedbecause SSA-UO only use lexical resources for sen-timent classification.Runs Dataset F1 all runs Ranktwitter-1 Twitter 50.17 33(48)sms-1 SMS 44.39 33 (42)Table 3: SSA-UO results in polarity classification, allruns summitedRuns Dataset F1 constrained runs Ranktwitter-1 Twitter 50.17 25 (35)sms-1 SMS 44.39 22 (28)Table 4: SSA-UO results in polarity classification, con-strained runs summitedIn Table 3 we summarize the results obtained bySSA-UO system.
As may be observed average F1measure for Twitter dataset is the 50.17 and 44.39for the SMS dataset.
A total of 48 runs were sub-mitted by all systems participant?s in Twitter and 42for SMS dataset.
Our runs were ranked 33th for bothdatasets.In Table 4 we compare our results with those runsthat can be considered as constrained.
A total of 35runs for Twitter and 28 for SMS were submitted ,505ours runs were ranked in 25th and 22th respectively.It?s worth mentioning that, the results obtained canbe considered satisfactory, considering the complex-ity of the task and that our system is unsupervised.4 ConclusionIn this paper, we have described the SSA-UO systemfor Twitter Sentiment Analysis Task at SemEval-2013.
This knowledge driven system relies on unsu-pervised coarse-grained WSD to obtain the contex-tual word polarity.
We used a rule-based classifierfor determining the polarity of a tweet.
The experi-mental results show that our proposal is accurate forTwitter sentiment analysis considering that our sys-tem does not use any corpus for training.AcknowledgmentsThis research work has been partially funded bythe Spanish Government through the project TEXT-MESS 2.0 (TIN2009-13391-C04), ?Ana?lisis de Ten-dencias Mediante Te?cnicas de Opinio?n Sema?ntica?
(TIN2012-38536-C03-03) and ?Te?cnicas de Decon-struccio?n en la Tecnolog?
?as del Lenguaje Humano?
(TIN2012-31224); and by the Valencian Govern-ment through the project PROMETEO (PROME-TEO/2009/199).ReferencesBalahur Alexandra, Steinberger Ralf, Goot Erik van der,Pouliquen Bruno, and Kabadjov Mijail.
2009.
Opin-ion mining on newspaper quotations.
In Proceed-ings of the 2009 IEEE/WIC/ACM International JointConference on Web Intelligence and Intelligent AgentTechnology - Volume 03, WI-IAT ?09, pages 523?526,Washington, DC, USA.
IEEE Computer Society.Henry Anaya-Sa?nchez, Aurora Pons-Porrata, and RafaelBerlanga-Llavori.
2006.
Word sense disambiguationbased on word sense clustering.
In Proceedings ofthe 2nd international joint conference, and Proceed-ings of the 10th Ibero-American Conference on AI 18thBrazilian conference on Advances in Artificial Intelli-gence, IBERAMIA-SBIA?06, pages 472?481, Berlin,Heidelberg.
Springer-Verlag.Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-tiani.
2010.
Sentiwordnet 3.0: An enhanced lexi-cal resource for sentiment analysis and opinion min-ing.
In Nicoletta Calzolari (Conference Chair), KhalidChoukri, Bente Maegaard, Joseph Mariani, Jan Odijk,Stelios Piperidis, Mike Rosner, and Daniel Tapias, edi-tors, Proceedings of the Seventh International Confer-ence on Language Resources and Evaluation (LREC?10), Valletta, Malta, may.
European Language Re-sources Association (ELRA).Andrea Esuli and Fabrizio Sebastiani.
2006.
Sentiword-net: A publicly available lexical resource for opinionmining.
In In Proceedings of the 5th Conference onLanguage Resources and Evaluation (LREC?06, pages417?422.R.
Gil-Garc?
?a, J. M.
Bad?
?a-Contelles, and A. Pons-Porrata.
2003.
Extended Star Clustering Algorithm.In CIARP 2003, LNCS, vol.
2905, pages 480?487.Vasileios Hatzivassiloglou and Kathleen R. McKeown.1997.
Predicting the semantic orientation of adjec-tives.
In Proceedings of the eighth conference on Eu-ropean chapter of the Association for ComputationalLinguistics, EACL ?97, pages 174?181, Stroudsburg,PA, USA.
Association for Computational Linguistics.Jaap Kamps and Maarten Marx.
2002.
Words with atti-tude.
In First International WordNet conference.Chin-Yew Lin and Eduard Hovy.
2000.
The automatedacquisition of topic signatures for text summarization.In Proceedings of the 18th conference on Computa-tional linguistics - Volume 1, COLING ?00, pages 495?501, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.George A. Miller.
1995.
Wordnet: A lexical database forenglish.
Communications of the ACM, 38:39?41.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
sentiment classification using ma-chine learning techniques.
In Proceeding of EmpiricalMethods in Natural Language Processing, pages 79?86.Helmut Schmid.
1994.
Probabilistic part-of-speech tag-ging using decision trees.Philip J.
Stone, Dexter C. Dunphy, Marshall S. Smith,and Daniel M. Ogilvie.
1966.
The General Inquirer:A Computer Approach to Content Analysis.
MITPress, Cambridge, MA.Peter Turney.
2002.
Thumbs up or thumbs down?
se-mantic orientation applied to unsupervised classifica-tion of reviews.
pages 417?424.Michael Wiegand, Alexandra Balahur, Benjamin Roth,Dietrich Klakow, and Andre?s Montoyo.
2010.
A sur-vey on the role of negation in sentiment analysis.
InProceedings of the Workshop on Negation and Spec-ulation in Natural Language Processing, NeSp-NLP?10, pages 60?68, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Theresa Wilson, Janyce Wiebe, and Rebecca Hwa.
2006.Recognizing strong and weak opinion clauses.
Com-putational Intelligence, 22:73?99.506Theresa Wilson, Zornitsa Kozareva, Preslav Nakov, SaraRosenthal, Veselin Stoyanov, and Alan Ritter.
2013.SemEval-2013 task 2: Sentiment analysis in twitter.In Proceedings of the International Workshop on Se-mantic Evaluation, SemEval ?13, June.507
