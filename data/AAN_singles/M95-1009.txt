LOCKHEED MARTIN :LOUELLA PARSING ,AN NLTOOLSET SYSTEM FOR MUC- 6byLois Childs, Deb Brady, Louise Guthrie, Jose Franco ,Dan Valdes-Dapena, Bill Reid, John Kielty, Glen nDierkes and Ira SiderLockheed MartinBuilding 10, Room 1527P.O.
Box 8048Philadelphia Pa. 1910 1BACKGROUNDDuring the 1980s, General Electric Corporate Research and Development began the designand implementation of a set of text-processing tools known as the NLToolset .
This suite of tool sdeveloped, over time, in cooperation with a subgroup of the Management and Data Systems Op-erations component of General Electric Aerospace.
Through corporate mergers, this subgrou phas become the Language Exploitation Technologies group of the Lockheed Martin Managementand Data Systems division .
Over the years, the toolset has evolved into a robust set of aids for tex tanalysis .
It has been used to build a variety of applications, and the knowledge gained from eachapplication has been utilized to improve the toolset .
The LOUELLA PARSING system was de -signed with the latest version of the NLToolset .The Lockheed Martin group's LOUELLA PARSING system participated in three of the fou rMUC-6 evaluations :1)The evaluation of systems that mark named entities (NE) in a text .
In particular, systems wererequired to mark locations, dates, times, organizations, people, and currency phrases in a text .2) The evaluation of systems that extract template elements (TE) corresponding to people an dorganizations from the text .
These templates can be thought of as index cards containing in -formation about people and organizations mentioned in a text .3) The evaluation of systems that extract information about corporate management successionsfrom a text .
This task is called the "scenario template" (ST), and requires a deeper anlysis of th etext than the other tasks .This paper will give an overview of our systems, describe our performance on each of the task sand the walkthrough article, and discuss areas where our systems need to be improved .LOUELLA's NE system was developed using the "spotters" from the NLToolset .
The TE and STsystems were developed using a range of tools for reference resolution, for information extraction ,for simple discourse processing, and for template generation, as well as a variety of spotters forspotting entities .
Below we describe the processing stages that are used in LOUELLA's NE, TE an dST systems .
The first three stages are used in the NE task .PROCESSING STAGE SThe NLToolset contains a core knowledge base, a large sense-disambiguated lexicon, and avariety of text-processing tools for extracting information, organizing information, and generatingoutput.
Typically, these tools are sequentially applied to text .97Text Tokenization and Segmentatio nLOUELLA uses sequential processing which simplifies the text with each phase .
The first text-processing module used is NLlex, a lexical-analyzer-development package which handles thecharacter string to word translation and tokenizes the text.
Next, the text segmenter interprets theSGML markers and common punctuation, and stores the text in a structure that holds the origina lversion of the text as a whole ; it also stores each section of the text, such as paragraph, sentence ,headline, dateline, etc.
Throughout processing, the structure holds an original and a "latest "version of each sentence ; the "latest" version is updated with each processing phase .Lexical Look-upAt this point, the text is stored in tokenized form, and any unambiguous names and phrase sthat are stored in the lexicon are identified .
Named entities, such as organizations and people, ar estored on an active token list to allow the system to link occurrences of the same entity, based o nname variations.
Next, each word is analyzed morphologically and tagged with its possible parts o fspeech, which are found in the lexicon.
The following is an example of the first check against th elexicon.
Here the phrasal "less than" and the company "Coke" are identified and marked as multi-tokens (MT):"I would be [MT{LESS-THAN} : less than ] honest to say I'm not disappointed not to be able to clai mcreative leadership for [MT{COCA-COLA} : Coke]," Mr. Dooner says .Text ReductionLOUELLA uses a non-deterministic, lexico-semantic, finite-state pattern matcher .
By thisdefinition, we refer to the pattern matcher as a finite-state machine which matches against bot hsyntactic and semantic features of text .
The pattern matcher uses a knowledge base of pattern -action rules, grouped in rule packages .
These rule packages are applied to the text in successiv epasses to mark primitive text elements such as time, money, locations, person, and compan ynames.
These marked phrases are then reduced into single tokens .LOUELLA uses eight rule-packages to reduce elements ranging from the most primitive tim eexpressions and organization noun phrases to the more complex IN_AND_OUT objects .
Thisphase of text processing extends from the Named Entity system through to the Template Element ,and includes the Scenario Template phase .
Here are several examples :Matches: (TIME-RULE-0 TIME-RULE-36 TIME-RULE-38 )[TIME-ABSOLUTE{36} : Yesterday ], McCann made official what had been widely anticipated : Mr.James, 57 years old, is stepping down as chief executive officer on [DATE{4} : July 1 ] and will retireas chairman [TIME-RELATIVE{38} : at the end of the year ] .Matches: (PNAME-RULE-2)Yesterday, McCann made official what had been widely anticipated : [PNAME{2} : Mr. James ], 57years old, is stepping down as chief executive officer on July 1 and will retire as chairman at the end o fthe year .Matches: (OTHERNP-RULE-3)[PPNOUN{3} : He ] will be succeeded by Dooner, 45 .Matches: (ORGNP-RULE-3)But the bragging rights to Coke's ubiquitous advertising belongs to Creative Artists Agency ,[ORGNP{3} : the big Hollywood talent agency ] .Matches: (ORGANIZATION-RULE-7 PERSON-RULE )Now, [PERSON{0} : James] is preparing to sail into the sunset, and [PERSON{0} : Dooner] is poisedto rev up the engines to guide [ORGANIZATION{7} : Interpublic Group ] 's [ORGANIZATION{7} :McCann-Erickson ] into the 21st century.Matches: (IN_AND_OUT-RULE-O IN_AND_OUT-RULE-1 )Yesterday, McCann made official what had been widely anticipated : [IN_AND_OUT{O} : James] , 5798years old, is stepping down as [OFFICERTOK{1} : chief executive officer] on July 1 and will retire as[OFFICERTOK{1} : chairman ] at the end of the year.Reference ResolutionReference resolution is ongoing throughout processing .
As soon as a named entity is recog-nized, it is stored?along with its variations?on an active token list so that variations of the nam ecan be recognized and linked to the original occurrence .
When organization names are recog-nized, they can often be directly linked to their appositives or prenominal phrases .
In addition ,noun-phrase recognition prompts a backward search through a stack of named entities in orde rto identify its referent.
This search uses several tactics to find the correct referent .
If the noun-phrase is semantically rich, a content filter is constructed and compared against content filters forknown, named entities .
If this is not successful, various heuristics are used based on entity typ eand position in text .Information ExtractionLOUELLA uses the same pattern matcher for information extraction that it uses for text reduc -tion; however, there is a difference in the way the pattern matcher is used .
While extracting, thepattern matcher is allowed to overlap patterns because it is not changing the text found ; it ismerely extracting information of interest and sending it to the text organizer.
The text organize rtries to assemble the extracted information into a lucid account of events .
It performs this assem-bly by using a model of the domain as delineated in the task specification .
For example, it is per-missible to have more than one IN_AND_OUT object participating in a SUCCESSION_EVENT, bu tthere must be one SUCCESSION_ORG involved .PostprocessingPostprocessing is the final review of the extracted information before the templates are gener -ated.
It is LOUELLA's chance to apply any heuristics which may seem helpful to an accurate re -porting of information.
This part of the system is entirely dependent on the domain and can b ecustomized at will by the developer .Template GeneratingLOUELLA has a template generator which uses an object-oriented mapping script for generat -ing the final template.
The script is based on the task specification and contains the path whic hthe template generator should follow through the objects .
The script also contains pointers to thefunctions which print each slot fill .SYSTEM MODULE SFor MUC-6, LOUELLA is comprised of three system modules, one for each of the MUC-6 tasksaddressed: Named Entity (NE), Template Element (TE), and Scenario Template (ST) .
Below, wegive a brief description of each of these systems .The NE SystemLOUELLA's Named Entity system is a multi-pass process which builds upon entities whic hare found in previous passes.
In addition to the segmentation and lexical look-up stages of ou rsystem, early passes of the reduction phase identify time, date, money, and percent components .The system then searches for locations, knowing that the entities found previously will not be par tof the location phrase .
The person and company-name passes also use the previous informatio nto identify contexts which indicate the presence of a company name, such as : "ABC stock rose*percentage*" .
The NE system generates all possible variations for each person and companyname it finds; another pass tries to find these variations .99LOUELLA's NE system uses a variety of matching methods.
Entities such as dates are foundby combining structure format with a list of valid items, i .e .
a valid month followed by a number .Mr.
<ENAMEX TYPE="PERSON">James</ENAMEX>, 57 years old, is stepping down as chief executiv eofficer on <TIMEX TYPE="DATE">July 1</TIMEX> and will retire as chairman at the end of the year.In cases where none of the entity parts are in a list of known things, we use surrounding con -text to identify the name .One of the many differences between <ENAMEX TYPE="PERSON">Robert L. James</ENAMEX>,chairman and chief executive officer of <ENAMEX TYPE="ORGANIZATION">McCann-Erick-son</ENAMEX>In the above example, LOUELLA does not know what McCann-Erickson is, however, she doesknow that people are "chairman and chief executive officer of' an organization .
Other widelyknown companies such as "Coca-Cola" are identified through a list of known organizations .
Thislist also helps identify "Coke" as referring to the "Coca-Cola" company .LOUELLA's NE system makes a basic assumption that any organizations that appear in th eheadline are the same as, or variations of, the organizations found in the text .
Therefore, the sys-tem does not examine the headline for organizations until it processes the body of the text .
In theprevious example, the reference to "McCann-Erickson" in the headline of the walkthrough text i sfound only after the body of the text is processed during the variation matching phase .Each variation of a person or organization found is linked to the original name .
This link isused in the TE system to identify aliases found in the text for that entity .
Only people and namedcompanies found by the NE system will be processed by the TE system .One additional NE system feature used by the TE system is a "company rename function ."
Ifan organization changed?or plans to change?its name, the old or future name is linked to thecurrent name, and the system symbol for the current name is used by all references to eithe rname.
The TE system then uses the current name to find all references to the current and old o rfuture names .The TE SystemThe TE system builds an object for each organization and person name that contains all of th erelated information it can find in the article .An organization object consists of :1) the organization's name2) all aliases for that name found in the text3) one descriptor phrase,4) the organization type ,5) the organization's locale an d6) country.A person object consists of :1) the person's nam e2) any aliases for that name in the article, an d3) any titles for that individual which appear in the text .Much of the information related to the entity name is found during the initial phases of the NEmodule in the context surrounding the entity name .
Appositives, for example, are often gooddescriptor phrases .
The system also links other descriptive phrases and pronouns to the namedentity, and these additional descriptions are used to assist the ST system in its information-ex-traction task .
Later, these links will allow for the replacing of noun phrases with, for example ,normalized organization template elements .Once an organization noun-phrase or personal pronoun is identified, the reference resolutionmodule seeks to find its referent .
For persons, LOUELLA uses the simple heuristic of assigning the100last person mentioned as the referent, keeping in mind gender constraints .
For organizations, th eprocess involves several steps.
First, the phrase is checked to make sure it hasn't already beenrecognized and linked by the NE system .
If no match is recognized, a content filter for the phrase i srun against a content filtered version of each known organization name ; if there is a match, thelink is made .Content Filters :"the jewelry chain" => ( jewelry jewel chain )"Smith Jewelers" => ( smith jewelers jeweler jewel )For example, if the organization noun phrase "the jewelry chain" is identified, its content filte rwould be applied to the list of known company names .
When it reaches "Smith Jewelers," it wil lcompare the filter against a filtered version of the name .
The best match is considered the referent .If there is a tie, file position is considered as a factor, and the closest name is the most likely refer -ent.
For generic phrases like "the company," reference is currently determined solely by file posi-tion and type .When a descriptor is linked to an organization name, the syntactic relationship of the descrip -tor to the organization name is also stored with the phrase .
For example, appositives and prenom -inal phrases recognized by the NE system are tagged with " :APP" and " :PRENOM", respectively .Likewise, references resolved by the reference resolution module are appropriately tagged .
Thetemplate generator uses a heuristic to choose the descriptor which is most likely correct .
Thechoice is based on a hierarchy which begins with appositives, prenominals, and predicate nomi-natives, and ends with references resolved by the reference resolution module .Once an organization or person has been linked to all its variations in the article, the TE sys -tem chooses the best name for the element and relegates the rest of the names to the alias catego -ry.
Assigning the same symbol name to each instance of a template element greatly simplifies th ework of the subsequent ST system.The ST SystemThe ST system extracts information about complex events that involve template elements lik eorganizations and people .
LOUELLA's scenario is about changes in corporate management .The top-level template of interest is the SUCCESSION_EVENT, which is comprised of:SUCCESSION_ORG :an organization template element ,POST:a string fill ,IN_AND_OUT:a relational object about each person involve d(may be more than one) ,VACANCY REASON :a set fill .LOUELLA's strategy is to repeatedly simplify the text before information extraction take splace.
This approach allows the most basic elements of the scenario to be identified first.
The TEsystem identifies the primitive template elements (person and organization) involved in a particu -lar scenario.
In addition, NE-style methods are applied, at this point, to recognize and tag man-agement-position titles within the text .The next level of complexity is to find the relational object, IN_AND_OUT.
This object is filledby: a pointer to a person template element, the IO_PERSON ; a set-fill indicating whether the per -son is in or out, the NEW_STATUS ; a set fill indicating whether the person is currently on the job ,the ON THE JOB; a pointer to an organization template element representing another corporat eentity involved in the change, the OTHER_ORG, (if known) ; and a set-fill indicating the relation -ship of the other organization, the REL_OTHER_ORG .It makes sense to first convert all person template elements into potential IN_AND_OUT ob-jects.
In most cases, the sentence clues which will tell the system whether a person is in or out of aposition and whether the person is still on the job are also the clues for the succession event itself .10 1It is preferable, then, to instantiate an empty IN_AND_OUT object around each person element ,and then to fill in the rest of the information if an event is extracted .LOUELLA's ST application consists of three rule packages: ingress.k, which holds all rules forentering corporate posts ; egress .k, which holds all rules for leaving corporate posts ; and activa-tions.k, which holds all macros for the ingress and egress rule packages .The Lockheed Martin approach to information extraction is to build sets of floating phrases ,i .e.
rules, which can glide over each sentence, binding to the right configuration of information .This information is then extracted and reorganized into a lucid account of the events .
This ap-proach is similar to the model-based segmentation method used in image-understanding sys-tems.
Portions of images are recognized easily, and their configuration is ultimately used to iden -tify the complete image .By examining a training set of articles for the sentences which report the events of interest ,rules are developed .
As training progresses, the rules are generalized to cover more and more pos -sible constructs .
A typical ingress rule, made up of macros, might look something like this :$subjphr $conjphr ?IN=$appointvb { $postorg } => c-reassigning-templateThe binding macros are $subjphr, $appointvb, and an optional $postorg.
$conjphr is a buffer macroallowing the pattern matcher to skip over irrelevant material .
This rule contains a variable ?I Nwhich is bound when the rule is matched .
This binding is then conveyed to the IN_AND_OUT ob-ject as its NEW_STATUS .
Other variables are also present within the macro definitions.
Thesevariables, when bound, will convey information about VACANCY_REASON, ON THE JOB, an dthe OTHER_ORG to the objects involved in the event.
For example, if the ?ACTING, ?IN, and ?FU-TURE variables are all bound in a match, then the IN_AND_OUT's NEW_STATUS is IN an dON THE JOB is NO, because the text is reporting that the person will be acting in a position .A difficulty occurs with this method when a sentence identifies a person as leaving one posi-tion and entering another.
For example, "Judy Jones, president of Exxon, has been hired as CE Oof GE."
In this case, the person element will have two different NEW_STATUS values, dependin gon the position being discussed .
When this happens, the person element must be re-instantiate das an additional IN_AND_OUT object in order to collect the correct value .Once an article's information has been extracted, it is then organized into a sensible accountbased on a model of the domain .
This model, along with the final template model (which guides th esystem's template generator), is constructed at the beginning of training .
Both models are base don the scenario specifications .In the postprocessing stage, we apply any heuristics learned during the course of system de-velopment.
For this application, the OTHER_ORG portion of the IN_AND_OUT object was filled-in here, based on the information gathered about that person .
For example, if at this pointLOUELLA knows that a person is leaving one organization and joining another, she can conclud ethat each organization can be the OTHER_ORG in the IN_AND_OUT object for the other organiza-tion's SUCCESSION_EVENT; in effect, the system swaps SUCCESSION_ORGs between succes-sion events to supply their respective IN_AND_OUT objects with OTHER_ORG fillers .WALKTHROUGH PERFORMANC EScenario TemplateWARNING: this message does not represent LOUELLA's typical performance.
Its F-measure isless than half of LOUELLA's average performance .
In fact, this was her next-to-worst score of al lthe messages .
Nonetheless, the system produced the following template for the walkthrough mes-sage.
The template represents recall of only 15, with precision of 80.102<TEMPLATE-9402240133-1> : =DOC_NR :CONTENT:<SUCCESSION_EV ENT-9402240133-1> :=POST:IN_AND_OUTVACANCY REASON :<IN_AND_OUT-9402240133-1> : _10_PERSON :NEW_STATUS :ON THE JOB :<PERSON-9402240133-1> :=PER_NAME :PER_ALIAS:PER TITLE :'9402240133 "<SUCCESSIONEVENT-9402240133-1 >"chief executive officer "<I N_A N D_O U T-9402240133-1 >REASSIGNMENT<P E R SO N-9402240133-1 >OUTUNCLEA R"Robert L. James""James ""Mr. "Performance on this message reveals two areas in which our system can be improved .
First ,our method of generalizing had not reached fruition by the time of the evaluation .
This messagewas improved by expanding the definition for one of the floating phrases, i .e .
macros, which makeup all ingress and egress patterns, and by inserting a buffer phrase into one of the egress patterns .Adding a buffer phrase allows the pattern matcher to jump over part of the conjunctive phrasein the following sentence :James, 57 years old, is stepping down as chief executive officer on July 1 and will retire as chairman a tthe end of the year .The following sections show the extraction process taking place .
The italicized words represen tthe rule which is being matched and the variables which are being bound.
The buffer additionallows two rules to overlap the sentence, extracting both succession events .EVALUATION EXTRACTION:[C-REASSIGNING-TEMPLATE{0} ?IN AND OUT=James, 57 years old, is ?OUT=< ?UN-CLEAR=?VACANCY REASON=stepping ?HEAD=down >=?OUT as ?POST=chief executive offi-cer {OJ] on July 1 and will retire as chairman at the end of the year.POST-EVALUATION - WITH BUFFER ADDITION :[C-REASSIGNING-TEMPLATE{1,0} ?IN AND OUT=James, 57 years old, is ?OUT=< ?UN-CLEAR=?VACANCY REASON=stepping ?HEAD=down >=?OUT as ?POST=chief executive offi-cer {0}] on July 1 and ?FUTURE=will ?VACANCY REASON=?OUT=?HEAD=refire as?POST-chairman {0}] at the end of the year.The secondary factors that hurt LOUELLA's performance were unsatisfactory post-processin gdecisions .
During development, generic patterns were instantiated to extract organization swhich would likely be involved in a succession event .
These companies are usually in the act ofannouncing some event.
Then, if succession events are extracted without an organization bein gdirectly involved in the event statement, the announcing organization can be tied to the organiza-tion-less events .
This heuristic worked well ; however, no allowance had been made for the case inwhich a SUCCESSION_ EVENT was extracted in the absence of any SUCCESSION_ORG .
This wasremedied, post-evaluation, by allowing the system to collect all organizations, and to choose a norganization during postprocessing to act as a default SUCCESSION_ORG for all organization -less events .
Even though post-processing chose the wrong organization for the walk-throug hmessage, it still got two extra points for having an organization .The most striking effect of a deficient post-processing heuristic was the decision to eliminat eany succession events which contained only an IN_AND_OUT object, with no other information .103Removal of this heuristic alone, with no other pattern modifications, increased the recall on thewalk-through message from 15R/80P to 44R/61P!
This is due to the fact that LOUELLA was no wproducing four succession events, instead of one, each with its own IN_AND_OUT object .
Thisincreased the number of correct slots from 8 to 23, even though the additional succession event shad no post and no succession organization .Changes in post-processing, while prompted by performance on the walk-through message ,affect system performance as a whole .
Consequently, the entire evaluation set was rerun with thechanges made to improve the walk-through message .
Performance increased from 43R/64P witha 51 .63 F-measure to 49R/60P with a 54 .04 F-measure .Of course, the best performance occurs when LOUELLA recognizes all of the organization spresent .
When improvements were made to the Named Entity task for the walk-through message ,the Scenario Template task scores were improved to 65R/56P on that message, for an F-measur eof 60 .1 .Template ElementLOUELLA produced the following set of template elements for the walk-through message .<ORGANIZATION-9402240133-12> :=ORG_NAME :ORG TYPE :<ORGANIZATION-9402240133-11> : =ORG_NAME :ORG_TYPE :ORG_LOCALE :ORG_COUNTRY:<ORGANIZATION-9402240133-10> :_ORG_NAME :ORG TYPE :<ORGANIZATION-9402240133-9> : =ORG_NAME :ORG_ALIAS :ORG TYPE :<ORGANIZATION-9402240133-8> : _ORG_NAME :ORG TYPE :<ORGANIZATION-9402240133-7> : _ORG_NAME :ORG_ALIAS :ORG_DESCRIPTOR :ORG TYPE :<ORGANIZATION-9402240133-6> : =ORG_NAME :ORG TYPE :<ORGANIZATION-9402240133-5> : _ORG_DESCRIPTOR :ORG TYPE :<ORGANIZATION-9402240133-4> : _ORG_NAME :ORG_DESCRIPTOR :ORG TYPE :"Interpublic Group"COMPANY"McCann"GOVERNMEN TMcCann CITYUnited States"PaineWebber"COMPANY"Coca-Cola""Coke"COMPANY"Coke"COMPANY"Creative Artists Agency""CAA""the big Hollywood talent agency"GOVERNMEN T"WPP Group"COMPANY"a hot agency "COMPANY"Ammirati & Puris""a quality operation"COMPANY104<ORGANIZATION-9402240133-3> :-ORG_DESCRIPTOR :ORG TYPE :<ORGANIZATION-9402240133-2> : =ORG_NAME :ORG TYPE :<ORGANIZATION-9402240133-1> : =ORG_NAME :ORG_DESCRIPTOR :ORG TYPE :<PERSON-9402240133-6> : =PER_NAME :PER_ALIAS :<PERSON-9402240133-5> :=PER_NAME :<PERSON-9402240133-4> :=PER_NAME :<PERSON-9402240133-3> :=PER_NAME :<PERSON-9402240133-2> :=PER_NAME :PER_ALIAS :PER TITLE :<PERSON-9402240133-1> :_PER_NAME :"one of the largest world-wide agencies "COMPANY"New York Yacht Club "COMPANY"McCann-Erickson ""guide Interpublic group"COMPANY"Even Alan Gottesman""Even""Peter Kim""J. Walter Thompson""Martin Puris ""Robert L. James ""James""Mr.""Kevin Goldman "The score for this document is as follows :- -----------------------------------------------------------------------------SLOTPOS ACTT COR PAR INC' MIS SPU NONIREC PRE UND OVG ERR SUB- ---------------------------------------------------------------------------- -organization 10 121 10 0 01 0 2 01100 83 0 17 17 0name 10 101 6 0 21 2 2 0160 60 20 20 50 2 5alias 3 21 2 0 01 1 0 7167 100 33 0 33 0descriptor 3 51 3 0 01 0 2 61100 60 0 40 40 0type 10 121 9 0 11 0 2 0190 75 0 17 25 1 0locale 2 11 0 0 01 2 1 810 0 100 100 100 0country 2 11 0 0 01 2 1 810 0 100 100 100 0person 6 71 5 0 11 0 1 0183 71 0 14 29 1 7name 6 71 5 0 11 0 1 0183 71 0 14 29 1 7alias 3 31 2 0 01 1 1 3167 67 33 33 50 0title 2 21 2 0 01 0 0 41100 100 0 0 0 0- ---------------------------------------------------------------------------- -TOTAL4143129041810361 71 67 20 23 43 1 2----------------------------------------------------------------------------- -Notice that all of the person objects have actually been extracted .
The discrepancy in the scorefor the person object is due to the incorrect string-fill for the name of Alan Gottesman .
LOUELLAincorrectly added the word "Even .
"The main improvement to LOUELLA for this walk-through message was the recognition o f"McCann" as an alias for "McCann-Erickson," instead of as a location .
This allowed the mapping'10 5of the two McCann-Erickson organization objects, which improved our score to 76R/79P fro m71R/67P.Named EntityOur official NE scores for the walk-through document were 91R/88P.
We found two systemproblems that drastically reduced this score .
One problem was the variation for McCann-Erick-son, "McCann."
LOUELLA threw out the variation because it was known in the gazetteer as a cityname.
By testing that the variation is part of a hyphenated name, we could then allow the varia-tion to be valid.
This one change raised this particular document's score to 96R/93P.Additionally, LOUELLA found "Even Alan Gottesman" as a person, as well as the variatio n"Even" later in the document .
By forcing LOUELLA to accept the match that starts with a knownfirst name, instead of another part of speech, we threw out this match and raised the documen ttotal score to 97R/94P.With the addition of these two modifications, our total NE F-measure rose to : 94.08 .This document also contains an example of the difficulty in recognizing when a company nam eis being used as a modifier to a product .. .
.
the agency still is dogged by the loss of the key creative assignment for the prestigious <ENAME XTYPE="ORGANIZATION">Coca-Cola</ENAMEX> Classic account .We are currently looking into expanding the NE module to include a products package.
Thispackage will use knowledge about the use of products in text, i .e., how they are referred to andwhen they include the company name as a premodifier.
This type of information may be useful t othe analyst who notices a particular person frequently associated with the purchase of certai nproducts, such as Winchester Rifles .Another interesting ambiguous phrase, which our system did not handle correctly, is :Mr. <ENAMEX TYPE="PERSON">Dooner</ENAMEX>, who recently lost <NUMEXTYPE="MONEY">60 pounds</NUMEX> over three?and?a?half months, says now that he has "rein -vented" himself, he wants to do the same for the agency .Since it is conceivable that Mr .
Dooner could have lost 60 pounds of currency, this makes fo ran interesting discussion of how smart our systems should be at the named entity level .
By possi -bly making the reference between "reinventing himself' and "lost 60 pounds," the system coul dthrow out the money tag.
Another argument could be made that since McCann-Erickson is re-ferred to as "world-wide" in many places, it is even more possible that Mr .
Dooner could lose 6 0pounds of money.
Another possibility is to give our systems the notion of money value vs .
weightvalue; that is, is 60 pounds of currency significant enough to outweigh 60 pounds of weight loss ?AN ANALYSIS OF SYSTEM PERFORMANC ELOUELLA experienced two bugs during the evaluation which caused at least one documen tnot to be scored in each task .
Therefore, we will report two sets of results : the official scores for theincomplete responses, and the unofficial scores for the complete responses which were generatedafter the bugs were fixed .
We consider our true performance to be the complete responses .Overall, LOUELLA's performance was near the top in all tasks, with F-measures within si xpercentage points of the top F-measures in Named Entity, within four in Template Element, an dwithin five in Scenario Template .Named EntityThe Named Entity performance was severely effected by a bug which virtually eliminated oneentire response out of the set of thirty ; accordingly, the difference in scores between official an d106unofficial is most dramatic here.
The bottom line scot es for Named Entity performance follow ,along with the Task Subcategorization Scores for the complete response .OFFICIAL NE - incomplete (29 texts )------------------------------------------------------------------------------SLOTPOS ACTT COR PAR INCA SPU MISNONIREC PRE UND OVG ERR SU B------------------------------------------------------------------------------ALL OBJECTS 2258 22641 20540681 142 13601 91 9166 143------------------------------------------------------------------------------F-MEASURESP&R2P&RP&2 R90 .8490 .7790 .9 2UNOFFICIAL NE - complete (30 texts )------------------------------------------------------------------------------SLOTPOS ACTT COR PAR INC' SPU MISNONIREC PRE UND OVG ERR SUB----------------------------------------------------------------------------- -ALL OBJECTS 2276 22961 2128 0 741 94 74 01 93 93 3 4 10 3----------------------------------------------------------------------------- -F-MEASURESP&R2P&RP&2R93 .0992 .8493 .3 3* * * UNOFFICIAL TASK SUBCATEGORIZATION SCORES * * *=SLOTPOS ACTT COR PAR INC' SPU MIS NONE REC PRE UND OVG ERR SUB- ---------------------------------------------------------------------------- -Enamex :organization 449 4401 403 0 271 10 19 01 90 92 4 2 126person 373 3781 362 0 41 12 7 01 97 96 2 3 61location 110 1221 100 0 31 19 7 01 91 82 6 16 223------------------------------------------------------------------------------Timex :date1131121 109001 3401 96 974360------------------------------------------------------------------------------Numex :money76791 76001 3001 100 960440percent17171 17001 0001 100 1000000----------------------------------------------------------------------------- -Note that LOUELLA has achieved near-perfection in four of the six subcategories .
It is expectedthat performance would be even greater over a larger corpus .
Since the NE component is a reus-able module, it is expected to increase?over time?in recall and precision as it is exercised over alarger corpus .TemplateElementOfficial performance on the Template Element task was degraded by two bugs which causedLOUELLA to lose two articles from the set of 100 .
Official bottom-line and unofficial total slo tscores are :107OFFICIAL TE ?
incomplete (98 texts )------------------------------------------------------------------------------SLOTPOS ACTT COR PAR INCA MIS SPU NONIREC PRE UND OVG ERR SU B------------------------------------------------------------------------------ALL OBJECTS2622 25821 19850 2071 430 390 17291 76 77 16 15 349------------------------------------------------------------------------------F?MEASURESP&R2P&RP&2R76 .2976 .6475 .94UNOFFICIAL TE ?
complete (100 texts )------------------------------------------------------------------------------SLOT POS ACTT COR PAR INC' MIS SPU NONIREC PRE UND OVG ERR SUB------------------------------------------------------------------------------organization 589 6631 540 0 241 25 99 01 92 81 4 15 22 4name 539 5471 419 0 701 50 58 321 78 77 9 11 30 14alias 171 1581 115 0 11 55 42 3641 67 73 32 27 46 1descriptor 225 2391 89 0 521 84 98 2891 40 37 37 41 72 37type 589 6631 525 0 391 25 99 01 89 79 4 15 24 7locale 115 1061 67 0 101 38 29 2781 58 63 33 27 53 1 3country 116 1031 75 0 21 39 26 2801 65 73 34 25 47 3person 495 5211 465 0 121 18 44 01 94 89 4 8 14 3name 495 5211 453 0 241 18 44 01 92 87 4 8 16 5alias 170 1651 154 0 11 15 10 2671 91 93 9 6 14 1title 166 1651 158 0 11 7 6 2731 95 96 4 4 8 1------------------------------------------------------------------------------ALL OBJECTS 2586 26671 2055 0 2001 331 412 17831 79 77 13 15 31 9------------------------------------------------------------------------------F?MEASURESP&R2P&RP&2R78 .2477 .5278 .9 750 .037 .525 .012 .5listbrahms bizetverdi dvorak wagner mahler chopin .n Puccini chopin .b grieg borodinFigure 1 : Descriptor F-measure sLOUELLA had very high recall in the Template Element task .
She also had very high F-mea-sure for the locale and country slots, and for the descriptor slot.
Figures 1 and 2 illustrate F-mea-108sure rankings in the descriptor and locale/country slots, respectively.
Since location informationis often found in the descriptor phrase, these three slots are somewhat related .
High performanc eon these slots may be due to the attention given to reference resolution during the development ofLOUELLA for MUC-6 .liszt brahms verdi dvorak bizet borodin puccinichopin .nwagnerchopin .bmahler grieg grieg*Figure 2 : Locale/Country F-measuresA difficulty with the descriptor slot is its mixed role .
One function of the slot is to contain anydescriptor phrase which is related to an organization's name.
This is a true reference resolutiontask.
In addition, however, the slot may also contain a phrase describing an un-named organiza-tion.
This then requires LOUELLA to differentiate between the two types of phrases and may lea dher to overgenerate un-named organization objects, thereby suppressing precision .Scenario TemplateOfficial performance on the Scenario Template task was degraded by two bugs which cause dus to lose two articles from the set of 100 .
Fortunately, only one of these articles was relevant tothe task.
Official bottom-line and unofficial total slot scores are :OFFICIAL ST ?
incomplete (98 texts )- ---------------------------------------------------------------------------- -SLOTPOS ACTS COR PAR INCA MIS SPU NONIREC PRE UND OVG ERR SUB----------------------------------------------------------------------------- -ALL OBJECTS2913 19951 12670 33711309 391 1911 43 64 45 20 62 2 1----------------------------------------------------------------------------- -TEXT FILTER 53 551 48 0 01 5 7 401 91 87 9 13 20 0----------------------------------------------------------------------------- -70656055500F?MEASURESP&R2P&RP&2R51 .6358 .1646 .4 2109UNOFFICIAL ST - complete (100 texts )----------------------------------------------------------------------------- -SLOTPOS ACTT COR PAR INCA MIS SPU NONIREC PRE UND OVG ERR SUB----------------------------------------------------------------------------- -template 53 561 49 0 01 4 7 401 92 88 8 13 18 0content 196 131 118 0 11 77 12 01 60 90 39 9 43 1succession_e 196 1421 118 0 11 77 23 01 60 83 39 16 46 1success_or 196 1381 87 0 301 79 21 01 44 63 40 15 60 26post 196 1421 75 0 441 77 23 01 38 53 39 16 66 37in_and_out 262 2121 115 0 301 117 67 01 44 54 45 32 65 2 1vac_reason 196 1421 76 0 431 77 23 01 39 54 39 16 65 3 6in_and_out 266 2121 170 0 11 95 41 01 64 80 36 19 45 1io_person 266 2121 139 0 321 95 41 01 52 66 36 19 55 1 9new_status 266 2121 145 0 261 95 41 01 55 68 36 19 53 1 5on_the_job 266 2121 105 0 661 95 41 01 39 50 36 19 66 3 9other_org 189 811 42 0 191 128 20 441 22 52 68 25 80 3 1rel_other_org 189 811 30 0 311 128 20 441 16 37 68 25 86 5 1organization 115 841 72 0 01 43 12 01 63 86 37 14 43 0name 112 771 52 0 131 47 12 01 46 68 42 16 58 2 0alias 68 561 38 0 11 29 17 161 56 68 43 30 55 3descriptor 67 311 9 0 101 48 12 151 13 29 72 39 89 5 3type 115 841 72 0 01 43 12 01 63 86 37 14 43 0locale 43 161 13 0 21 28 ?1 201 30 81 65 6 70 13country 43 161 14 0 11 28 1 201 33 88 65 6 68 7person 133 1221 98 0 31 32 21 01 74 80 24 17 36 3name 133 1221 93 0 81 32 21 01 70 76 24 17 40 8alias 85 671 62 0 21 21 3 251 73 93 25 4 30 3title 81 701 64 0 01 17 6 241 79 91 21 9 26 0------------------------------------------------------------------------------ALL OBJECTS2969 21021 13490 35911261 394 2081 45 64 42 19 60 2 1------------------------------------------------------------------------------TEXT FILTER535614900147401 92 888 13 180------------------------------------------------------------------------------P&R2P&RP&2 RF-MEASURES53 .2059 .2948 .25LOUELLA recognized 60% of the succession events after one person-month of development .In fact, she had an F-measure of 69 .65 for that slot .
This performance shows the system's adapt -ability.
This fact is even more remarkable because of the necessity to write specialized code tohandle the peculiarities of this task.
Unlike previous extraction tasks in which the event templateis built from lower-level relational and primitive elements, this specific task requires that informa -tion, such as IN or OUT status, be recognized at the event level but instantiated in the lower leve lrelational element, the IN_AND_OUT object .TRAINING LOUELLAMethodologyTen percent of the 100 development messages were set aside as a blind set for the developmen tphase.
This ten percent was chosen based on the size of their keys, so as to accurately represen tthe complexity of the development set .
Over four weeks, the Scenario Template task was able toachieve F-measure of 70.16 on the development set and 52 .05 on the blind set.
This measure i squite close to our evaluation F-measure of 51 .63 .During training, the system is run over both the blind set and the development set of message sovernight, several times a week.
Developers can then check the scores at the start of the day and11 0determine which area of the system is most in need of improvement at that time .
This methodallows us to check our progress frequently, and to backtrack quickly if a regression is noticed .EffortThe NE and TE modules of LOUELLA were developed over the Spring and Summer of 1995 b ytwo experienced system developers, one focusing on the NE task and the other on the TE task, wit han emphasis on reference resolution .
When the evaluation period started, the NE person shifte dattention to the TE task, while the TE person shifted to the ST task .
Two inexperienced developerswere then assigned to the NE task for the evaluation period .The bulk of the NE effort was directed toward perfecting the rules for recognition .
The TE taskwas more code-intensive because of its reference resolution component, i .e .
that task requires anassembling of information gathered up from throughout the article for each organization and per -son object .
The ST effort runs the gamut from domain-specific application design through rul econstruction and specialized coding ; however, the Lockheed Martin NLToolset system provides abasic framework for building an information-extraction application which greatly reduces th eamount of effort required .
The NE and TE modules themselves are now available for any informa-tion-extraction task, and the object-oriented template generator allows the system to easily pro -duce any new template based on the task specifications .DIRECTIONThe reference resolution strategies used for MUC-6 will be expanded to provide more accuracyin identifying related and unrelated organization descriptors, as well as pronoun references .
In-clusion of linguistic theory, in addition to other techniques that have been successful for the coref -erence participants, is a possibility .
Research into this area is currently underway .The procedure for building an extraction system is currently too labor-intensive and haphaz -ard a process, dependent to a great extent on the abilities of the developer.
The first step towardremedying this procedure is to build a rigorous syntactic framework which can be used as a tem -plate for rule variations.
A further step is to investigate the possibility of building a self-trainin gsystem.
Since, at the point of extraction, the system knows a great deal about the components o feach sentence, it may be possible to have the system itself generate a set of interesting patterns fora particular domain .A preliminary effort at linking sub-parts of succession events was attempted for MUC-6 .
Thisentailed extracting generic events which were disposable if not linked to task-relevant events .Expansion in this area will include layering of events, as well as an incorporation of time elements ,and will ultimately improve the system understanding of the texts being processed .111
