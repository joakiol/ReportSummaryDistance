Experiences with the GTU grammar development environmentMart in VolkUniversity of ZurichDepartment of Computer ScienceComputational LinguisticsWinterthurerstr.
190CH-8057 Zurichvolk?if i. unizh, chDirk RicharzUniversity of Koblenz-LandauInstitute of Computational LinguisticsRheinau 1D-56075 Koblenzricharz?informatik, uni-koblenz, deAbstractIn this paper we describe our experi-ences with a tool for the developmentand testing of natural language gram-mars called GTU (German: Grammatik-Testumgebumg; grammar test environ-ment).
GTU supports four grammar for-malisms under a window-oriented user in-terface.
Additionally, it contains a setof German test sentences covering varioussyntactic phenomena as well as three typesof German lexicons that can be attached toa grammar via an integrated lexicon inter-face.
What follows is a description of theexperiences we gained when we used GTUas a tutoring tool for students and as an ex-perimental tool for CL researchers.
Fromthese we will derive the features necessaryfor a future grammar workbench.1 IntroductionGTU (German: Grammatik-Testumgebung; gram-mar test environment) was developed as a flexibleand user-friendly tool for the development and test-ing of grammars in various formats.
Throughoutthe last 7 years it has been successfully used as atutoring tool to supplement syntax courses in com-putational linguistics at the Universities of Koblenzand Zurich.GTU has been implemented in Arity Prolog underDOS and OS/2, and in SICStus Prolog under UNIX.In this paper we will concentrate on the UNIX ver-sion.
GTU in this version is a stand-alone systemof about 4.5 MB compiled Prolog code (not count-ing the lexicons) 1.
GTU interacts with 3 Germanlexicons:lAccording to rearrangements of the operating sys-tem the actual memory requirements total about 7 MBfor both SUN OS 4.x and SUN OS 5.x.1.
a small hand-coded stem-lexicon whose vocabu-lary has been tailored towards the test sentences(This lexicon also contains selectional restric-tions for all its nouns and adjectives.),2.
GerTWOL (Oy, 1994), a fast morphology anal-ysis program, and3.
PLOD, a full-form lexicon that has been derivedfrom the CELEX lexical database (Baayen,Piepenbrock, and van Rijn, 1995).GTU supports grammars under four formalisms:1.
Definite Clause Grammar (DCG, (Pereira andShieber, 1987)) augmented with feature struc-tures,2.
Immediate Dominance / Linear PrecedenceGrammar (ID/LP; a subset of GPSG),3.
Generalized Phrase Structure Grammar(GPSG, (Gazdar et al, 1985)),4.
Lexical Functional Grammar (LFG, (Kaplanand Bresnan, 1982)).Additionally, GTU provides a first step towardssemantic processing of LFG f-structures.
Thus agrammar developer may specify the way the seman-tic module computes logical expressions for an f-structure using semantic rules.
In another modulethe selectional restrictions of the hand-coded lexi-con can be used to compute if (a reading of) a sen-tence is semantically anomalous.
This module canbe switched on and off when parsing a sentence.GTU's features have been published before (see(Jung, l%icharz, and Volk, 1994) or (Volk, Jung, andFticharz, 1995)).
In this paper we concentrate onevaluating GTU's features, comparing them to someother workbenches that we have access to (mostlyGATE (Gaizauskas et al, 1996) and the Xerox LFGworkbench (Kaplan and Maxwell, 1996)).
Fromthis we derive recommendations for future grammarworkbenches.1072 GTU - i t s  mer i t s  and  i t s  l im i tsGrammar  ru le  notat ionOne of the primary goals in the GTU project was tosupport a grammar ule notation that is as close aspossible to the one used in the linguistics literature.This has been a general guideline fi)r every formal-ism added to the GTU system.
Let us give someexamples.
Typical ID-rules in GTU are:(1) S -> NP\[X\],VP\[X\] \[ X = \[kas=nom\].
(2) NP\[kas=K\] -> Det\[kas=K, hUm=N\],(AdjP\[kas=K, num=N\] ),N\[kas=K, num=N\] .Rule (I) says, that a constituent of type S con-sists of constituents of type NP and VP.
The featurestructures are given in square brackets.
A capitalletter in a feature structure represents a variable.Identical variables within a rule stand for shared val-ues.
Hence, the feature structures for NP and VP inrule (1) are declared to be identical.
In addition thefeature structure equation behind the vertical bar\[ specifies that X must be unified with the featurestructure \[kaa=nom\].
Rule (2) says that an NP con-sists of a Det, an optional AdjP and an N. It also saysthat the features kas and arm are set to be identi-cal across constituents while only the feature kas ispassed on to the NP-node.There are further means for terminal symbolswithin a grammar and a reserved word representingan empty constituent.In our experience the grammar rule notation helpsthe students in getting acquainted with the system.But students till need some time in understandingthe syntax.
In particular they are sometimes misledby the apparent similarity of GTU's ID-rules to Pro-log DCG-rules.
While in Prolog constituent symbolsare atoms and are usually written with lower caseletters, GTU requires upper case letters as is custom-ary in the linguistic literature.
In addition studentsneed a good understanding of feature structure uni-fication to be able to manipulate the grammaticalfeatures within the grammar ules.For writing grammar rules GTU has an inte-grated editor that facilitates loading the grammarinto GTU's  database.
A grammar thus becomesimmediately available for testing.
Loading a gram-mar involves the translation of a grammar ule intoProlog.
This is done by various grammar proces-sors (one for each formalism).
The grammar pro-cessors are SLR parsers generated from metagram-mars.
There is one metagrammar for each gram-mar formalism describing the format of all admissi-ble grammar ules and lexicon interface rules underthis formalism.Writing large grammars with GTU has sometimeslead to problems in navigation through the grammarfiles.
A grammar browser could be used to alliviatethese problems.
The Xerox LFG-WB contains sucha browser.
It consists of a clickable index of all ruleheads (i.e.
all defined constituent symbols).
Via thisindex the grammar developer can comfortably accessthe rule definitions for a given constituent.Stat i c  g rammar  checksFor the different formalisms in GTU, different ypesof parsers are produced.
GPSG grammars are pro-cessed by a bottom-up chart parser, DCG and LFGgrammars are processed by top-down depth-firstparsers.
All parsers have specific problems withsome structural properties of a grammar,  e.g.
top-down depth-first parsers may run into infinite loopsif the grammar contains (direct or indirect) left re-cursive rules.Therefore GTU provides a static check for detect-ing left recursions.
This is done by building up agraph structure.
After processing all grammar ulesand inserting all possible edges into the graph, thegrammar contains a possible left recursion if thisgraph contains at least one cycle.
In a similar man-ner we can detect cycles within transitive LP rulesor within alias definitions.These checks have shown to be very helpful in un-covering structural problems once a grammar hasgrown to more than two dozen rules.
The staticchecks in GTU have to be explicitly called by thegrammar developer.
It would be better to performthese checks automatically any time a grammar isloaded into the system.A model for the employment of grammar checksis the workbench for affix grammars introduced by(Nederhof et al, 1992), which uses grammar checksin order to report on inconsistencies (conflicts withwell-formedness conditions uch as that every non-terminal should have a definition), properties (suchas LL(1)), and information on the overall grammarstructure (such as the is-cMled-by relation).Output  in d i f ferent  granu lar i t iesOne of GTU's  main features is the graphics displayof parsing results.
All constituent structures can bedisplayed as parse trees.
For LFG-grammars GTUadditionally outputs the f-structure.
For DCG andGPSG the parse tree is also displayed in an indentedfashion with all features used during the parsing pro-cess.
Output can be directed into one or multiplewindows.
The multiple window option facilitates the108comparison of the tree structures on screen.
Pars-ing results can also be saved into files in order touse them in documentations or for other evaluationpurposes.The automatic graphic display of parsing resultsis an important feature for using GTU as a tutoringtool.
For students this is the most striking advantageover coding the grammar directly in a programminglanguage.
The GTU display works with structuresof arbitrary size.
But a structure that does not fiton the screen requires extensive scrolling.
A zoomoption could remedy this problem.Zooming into output structures is nicely inte-grated into the Xerox LFG-WB.
Every node in theparse tree output can be enlarged by a mouse clickto its complete feature structure.
Every label on achart edge output can be displayed with its internaltree structure and with its feature structure.Automat ic  compar i son  of  output  s t ruc turesWhen developing a grammar it often happens thatthe parser finds multiple parses for a given sentence.Sometimes these parses differ only by a single featurewhich may be hard to detect by a human.
Automaticcomparison of the parses is needed.
This can also beused to compare the parses of a given sentence beforeand after a grammar modification.It is difficult to assess the effects of a grammarmodification.
Often it is necessary to rerun longseries of tests.
In these tests one wants to savethe parse structure(s) for a given test sentence ifa certain level of coverage and correctness has beenreached.
Should a modification of the grammar be-come necessary, the newly computed parse structurecan be automatically compared to the saved struc-ture.
We have included such a tool in GTU.The comparison tool works through three subse-quent levels.
First, it checks whether the branchingstructures of two parse trees are identical, then itcompares the node names (the constituent symbols),and finally it detects differences in the feature struc-tures.
The procedure stops when it finds a differenceand reports this to the user.Implementing such a comparison tool is not toodifficult, but integrating it into the testing moduleof a grammar workbench is a major task, if this mod-ule supports different ypes of tests (single sentencetests and series of tests; manual input and selectionsfrom the test suite).
At the same time one needsto ensure that the module's functionality is trans-parent and its handling is easy.
For example, whatshould happen if a sentence had two readings beforea grammar modification and has three readings now?We decided to compare the first two new structureswith the saved structures and to inform the user thatthere now is an additional reading.
In our compari-son tool series of comparisons for multiple sentencescan be run in the background.
Their results are dis-played in a table which informs about the numbersof readings for every sentence.This comparison tool is considered very helpful,once the user understands how to use it.
It shouldbe complemented with the option to compare theoutput structures of two readings of the same inputsentence.T rac ing  the  pars ing  processWithin GTU the parsing of natural language inputcan be traced on various levels.
It can be traced?
during the lexicon lookup process displaying themorpho-syntactical information for every word,?
during the evaluation of the lexicon interfacerules displaying the generated lexical rules for agiven word,?
during the application of the grammar or se-mantic rules.For GPSG grammars GTU presents every edgeproduced by the bottom-up chart parser.
For DCGand LFG grammars GTU shows ENTRY, EXIT,FAIL and REDO ports for a predicate, as in a Pro-log development environment.
But GTU does notprovide options for selectively skipping the trace fora particular category or for setting special interruptpoints that allow more goal-oriented tracing.
Fur-thermore, the parser cannot be interrupted by anabort option in trace mode.
These problems lead toa reluctance in using the trace options since most ofthe time too much information is presented on thescreen.
Only elaborate trace options are helpful inwriting sizable grammars.Lex icon in ter faceThe flexible lexicon interface is another of GTU'score elements.
With special lexicon interface rulesthat are part of every grammar formalism the gram-mar developer can specify which lexicon informationthe grammar needs and how this information shouldbe structured and named.For each word a lexicon provides informationabout the possible part of speech and morpho-syntactical information.
Lexicon interface rules de-termine how this information is passed to the gram-mar.A lexicon interface rule contains a test criterionand a specification and has the following format:109if_in_lex ( test  cr i ter ion) then_in_gram(specif ication) .The test criterion is a list of feature-value pairsto be checked against a word's lexical information.Additionally, constraints are allowed that check ifsome feature has a value for the given word.
Forexample, the test(pos=verb, !tense, "reflexive)will only succeed for irrefiexive finite verbs 2.While it is necessary that the test contains onlyfeatures available in the lexicon, the specificationpart may add new information to the informationfound in the lexicon.
For example, the specificationcase = #kasus, number =#numerus ,  person = 3assigns the value of the feature kasus found in thelexicon (which is indicated by #) to a feature namedcase (and the like for number).
Additionally, a newfeature person is added with the value 3.
In this wayevery noun may get a specification for the personfeature.The specification part defines how lexicon infor-mation shall be mapped to a syntactic ategory incase the test criterion is met.
While the format ofthe test criterion is the same for all formalisms, theformat of the specification has been adjusted to theformat of every grammar formalism.
In this way thedefinition of lexical entries can be adapted to a gram-mar formalism while reusing the lexical resources.Writing lexicon interface rules requires a good un-derstanding of the underlying lexicon.
And some-times it is difficult to see if a problem with lexicalfeatures tems from the lexicon or is introduced bythe interface rules.
But overall this lexicon inter-face has been successful.
With its simple format ofrules with conditions and constraints it can serve asa model for interfacing other modules to a grammarworkbench.Test  su i te  admin is t ra t ionGTU contains a test suite with about 300 sentencesannotated with their syntactic properties.
We haveexperimented with two representations of the testsuite (Volk, 1995).
One representation had everysentence assigned to a phenomenon class and everyclass in a separate file.
Each sentence class can beloaded into GTU and can be separately tested.
In asecond representation the sentences were organizedas leaves of a hierarchical tree of syntactic phenom-ena.
That is, a phenomenon like 'verb group syn-2, !feature' means that the feature must have somevalue, while ',-,feature' prohibits any value on thefeature.tax' was subdivided into 'simple verb groups', 'com-plex verb groups', and 'verb groups with separatedprefixes'.
The sentences were attached to the phe-nomena they represented.
In this representation thegrammar developer can select a phenomenon result-ing in the display of the set of subsumed sentences.If multiple phenomena re selected the intersectionof the sets is displayed.It turned out that the latter representation washardly used by our students.
It seems that gram-mar writing itself is such a complex process that auser does not want to bother with the complexitiesof navigating through a phenomena tree.
The other,simple representation of sentence classes in files isoften used and much appreciated.
It is more trans-parent, easier to select from, and easier to modify(i.e.
it is easier to add new test sentences).Few other grammar workbenches include an elab-orate test module and only PAGE (Oepen, 1997)comprises a test suite which is integrated similarlyto GTU.
PAGE's test suite, however, is more com-prehensive than GTU's since it is based on theTSNLP (Test Suites for Natural Language Process-ing) database.
TSNLP provides more than 4000 testitems for English, French and German each.
We arenot aware of any reports of this test suite's usabilityand acceptability in PAGE.Output  of  recogn ized  f ragments  in case ofungrammat ica l i tyIn case a parser cannot process the complete naturallanguage input, it is mandatory that the grammardeveloper gets feedback about the processed frag-ments.
GTU presents the largest recognized frag-ments.
That is, starting from the beginning of thesentence it takes the longest fragment, from the endof this fragment it again takes the longest fragmentand so on.
If there is more than one fragment ofthe same length, only the last one parsed is shown.The fragments are retrieved from the chart (GPSG)or from a well-formed substring table (DCG, LFG).Obviously, such a display is sometimes misleadingsince the selection is not based on linguistic criteria.As an alternative we have experimented with dis-playing the shortest paths through the chart (i.e.the paths from the beginning to the end of the in-put with the least number of edges).
In many casessuch a path is a candidate close to a parsing solution.In general, it fares better than the longest fragmentsbut again it suffers from a lack of linguistic insight.Yet another way is to pick certain combinationsof constituents according to predefined patterns.
Itis conceivable that the grammar developer specifiesan expected structure for a given sentence and that110the system reports on the parts it has found.
Or thedisplay system may use the grammar ules for se-lecting the most promising chart entries.
Displayingthe complete chart, as done in the Xerox LFG-WB,will help only for small grammars.
For any sizablegrammar this kind of display will overwhelm the userwith hundreds of edges.Selecting and displaying chart fragments is aninteresting field where more research is urgentlyneeded, especially with respect to treating the re-sults of parsing incomplete or ill-formed input.Lex icon extens ion  modu leWhen writing grammars for real natural languagesentences, every developer will soon encounter wordsthat are not in the lexicon, whatever size it has.Since GTU was meant as a tutoring tool it containsonly static lexicons.
In fact, its first lexicon was tai-lored towards the vocabulary of the test suite.
GTUdoes not provide an extension module for any of theattached lexical resources.
The grammar developerhas to use the information as is.
Adding new featurescan only be done by inserting them in lexicon inter-face rules or grammar rules.
Words can be added asterminal symbols in the grammar.This is not a satisfactory solution.
It is not onlythat one wants to add new words to the lexiconbut also that lexicon entries need to be correctedand that new readings of a word need to be en-tered.
In that respect using GerTWOL is a draw-back, since it is a closed system which cannot bemodified.
(Though its developers are planning onextending it with a module to allow adding words.
3)The other lexicons within GTU could in principlebe modified, and they urgently need a user inter-face to support his.
This is especially important forthe PLOD-lexicon derived from the CELEX lexicaldatabase, which contains many errors and omissions.Models for lexicon extension modules can befound in the latest generation of commercial machinetranslation systems uch as IBM's Personal Trans-lator or Langenscheidts T1.
Lexicon extension inthese systems is made easy by menus asking onlyfor part of speech and little inflectional information.The entry word is then classified and all inflectionalforms are made available.Of course in a multi-user system these modifica-tions need to be organized with access restrictions.Every developer should be able to have his own sub-lexicon where lexicon definitions of any basic lexi-con can be superseded.
But only a designated user3Personal communication with Ari Majorin of Ling-soft, Helsinki, in December 1996.should be allowed to modify the basic lexicon ac-cording to suggestions sent to him by the grammardevelopers.Combinat ion  of  lexical  resourcesGTU currently does not support the combinationof lexical resources.
Every lexical item is takenfrom the one lexicon selected by the user.
Miss-ing features cannot be complemented by combininglexicons.
This is a critical aspect because none ofthe lexicons contains every information necessary.While GerTWOL analyzes a surprising variety ofwords and returns morphological information withhigh precision, it does not provide any syntactical in-formation.
In particular it does not provide a verb'ssubcategorization.
This information can be found inthe PLOD/CELEX lexicon to some degree.
For ex-ample, the grammar developer can find out whethera verb requires a prepositional object, but he cannotfind out which preposition the phrase has to startwith .4C lear  modular i za t ionThe development of a large grammar - like a largesoftware system - makes it necessary to split thework into modules.
GTU supports such modular-isation into files that can be loaded and tested inde-pendently.
But GTU only recommends to divide agrammar into modules, it does not enforce modular-isation.
For a consistent development of large gram-mars, especially if distributed over a group of people,we believe that a grammar workbench should sup-port more engineering aspects we know from soft-ware development environments such as a moduleconcept with clear information hiding, visualisationo f  call graphs on various levels, or summarisation ofselected rule properties.Genera l  remarks  on GTUGTU focuses on grammar writing.
It does not in-clude any means to influence parsing efficiency.
Butparsing efficiency is another important aspect oflearning to deal with grammars and to write NLPsystems.
It would therefore be desirable to have asystem with parameterizable parsers.
On the otherhand this might result in an unmanageable degreeof complexity for the user and - like with the alter-native test suite - we will end up with a nice featurethat nobody wants to use.The GTU system has been implemented withgreat care.
Over time more than a dozen program-4The next version of CELEX will contain such prepo-sitional requirements.
(Personal communication withCELEX manager Richard Piepenbrock in April 1997)I l lmers have contributed modules to the overall sys-tem.
The robust integration of these modules waspossible since the core programmers did not change.They had documented their code in an exemplaryway.
Still, the problem of interfacing new moduleshas worsened.
A more modular approach seems de-sirable for building large workbenches.3 D i f fe rent  g rammar  dewelopmentenv i ronmentsIn order to position GTU within the context of gram-mar development environments, let us classify themaccording to their purpose.Tutor ing  env i ronments  are designed for learningto write grammars.
They must be robust andeasy to use (including an intuitive format forgrammar ules and an intuitive user interface).The grammar developer should be able to fo-cus on grammar writing.
Lexicon and test suiteshould be hidden.
Tutoring environments there-fore should contain a sizable lexicon and a testsuite with a clear organisation.
They shouldprovide for easy access to and intuitive displayof intermediate and final parsing results.
Theyneed not bother with efficiency considerationsof processing a natural anguage input.
GTU isan example of such a system.Exper imentat ion  env i ronments  aredesigned for professional experimentation a ddemonstration.
They must also be robust butthey may require advanced engineering and lin-guistic skills.
They should provide for check-ing the parsing results.
They must supportthe grammars and parsers to be used outsidethe development system.
We think that Alvey-GDE (Carroll, Briscoe, and Grover, 1991) andPleuk (Calder and Humphreys, 1993) are goodexamples of such environments.
They allow thetuning of the parser (Alvey) and even redefin-ing the grammar formalism (Pleuk).
The XeroxLFG-WB is partly a tutoring environment (es-peciMly with its grammar index and zoom-indisplays) and partly an experimentation e vi-ronment since it lacks a test suite and a lexicon.Note that the systems also differ in the num-ber of grammar formalisms they support.
TheAlvey-GDE (for GPSG) and the Xerox LFG-WB work only for one designated formalism.GTU has built-in processors for three for-malisms, and Pleuk supports whatever formal-ism one defines.NLP  env i ronments  are designed as platforms forthe development of multi-module NLP systems.Rather than being a closed system they providea shell for combining multiple linguistic mod-ules such as tokenizers, taggers, morphology an-alyzers, parsers (with grammars) and so on.
Agrammar workbench is a tool to develop sucha module.
All the modules can be tailored andtuned to the specific needs of the overall sys-tem.
We consider ALEP (Simpkins, 1994) andGATE (Gaizauskas et al, 1996) to be examplesof such environments.
Although it seems logi-cal and desirable that NLP environments shouldprovide for the delivery of stand-alone systemsthis aspect has been neglected so far.
In par-ticular we suspect hat the interface format, asrequired e.g.
between GATE modules, will havenegative ffects on the processing efficiency ofthe complete system.
5GTU was designed as a tutorial system for gram-mar development.
Over time it has grown into asystem that supports most functions of experimenta-tion environments.
Its main limitations are its closedarchitecture and the inability to use the grammarsoutside the system.
Many of its modules can be em-ployed by an NLP environment.
GTU's most suc-cessful modules are its flexible lexicon interface, thetight integration of the test suite and the module forcomparison of output structures.An NLP environment should be an open platformrather than a closed workbench, as is the core con-cept of ALEP and GATE.
This is needed to allowspecial treatment for special inguistic problems.
Forinstance, the treatment of separable prefix verbs inGerman is so specific that it could be tackled bya preprocessor before parsing starts.
Only after theseparated prefix and the main verb have been recom-pounded the verb's subcategorization can be deter-mined.Another specific problem of German is the reso-lution of elliptical coordinated compounds (e.g.
In-und Ausland standing for Inland und Ausland).
Ifsuch ellipses are filled in before parsing starts sucha coordination does not need special grammar ules.Other peculiarities such as date, time, currency, dis-tance expressions will also need special modules.
Inthis way only the processing of the core syntacticphenomena is left to the parser.An NLP environment should allow parametrisa-tion of parsers or multiple parsers of different pro-5GATE requires modules to communicate via a socalled CREOLE interface, which is a layer wrappedaround an existing module.112cessing strategies (e.g.
a combination of symbolicand statistic parsing) and processing depths (e.g.shallow parsing if no complete parse can be found).4 Conc lus ionsTools like GTU are well suited for learning to de-velop grammars, for experimenting with grammarformalisms, and for demonstrating the work of com-putational linguistics.
The use of GTU as an ed-ucational tool in computational linguistics courseshas been very successful.
In a recent project GTU'sflexibility is being challenged in a joint project withthe Institute of Germanic Language at the Univer-sity of Koblenz.
In this project we examine the useof GTU for the benefit of courses in German as aforeign language.For the development of large grammars in combi-nation with large linguistic resources and for pro-cessing them efficiently, GTU is less suited.
Weare now convinced that we need an open platformthat provides a framework for combining modulesfor such a task.
For this it is necessary to develop in-terface standards for different types of modules (tag-gets, grammars, lexicons, test suites etc.
).Finally, we should keep in mind that a com-putational environment for grammar developmentoffers help in engineering NLP modules for well-understood phenomena.
The real hard problems inNLP (most importantly the resolution of ambigu-ity) need to be solved by bringing to bear the rightinformation at the right time.
But this is of yet acomplex area with many questions that have not re-ceived a theoretical nswer let alne an engineeringsolution.5 AcknowledgementsWe would like to thank Diego Mollh Aliod andGerold Schneider for providing background informa-tion on some grammar workbenches.Re ferencesBaayen, R. H., R. Piepenbrock, and H. van Rijn.1995.
The CELEX lexical database (CD-ROM).Linguistic Data Consortium, University of Penn-sylvania.Calder, J. and K. Humphreys.
1993.
Pleukoverview.
Technical report, University of Edin-burgh.
Centre for Cognitive Science.Carroll, John, Ted Briscoe, and Claire Grover.
1991.A development environment for large natural lan-guage grammars.
Technical report, University ofCambridge Computer Laboratory.Gaizauskas, R., H. Cunningham, Y. Wilks,P.
Rodgers, and K. Humphreys.
1996.
GATE:an environment to support research and develop-ment in natural anguage ngineering.
In Proc.
ofthe 8th IEEE Conf.
on tools with AI (ICTAI-96}.Gazdar, Gerald, Ewan Klein, Geoffrey Pullum,and Ivan Sag.
1985.
Generalized phrase struc.ture grammar.
Harvard University Press, Cam-bridge,MA.Jung, Michael, Dirk Richarz, and Martin Volk.1994.
GTU - Eine Grammatik-Testumgebung.In Proceedings of KONVENS-94, pages 427-430,Wien.Kaplan, R.M.
and J.T.
Maxwell III, 1996.
LFGGrammar Writer's Workbench (Version 3.1).
Xe-rox Corporation.Kaplan, Ronald and Joan Bresnan.
1982.
Lexical-functional grammar.
A formal system for gram-matical representation.
In Joan Bresnan, editor,The Mental Representation f Grammatical Rela-tions.
MIT Press, Cambridge,MA.Nederhof, M.J., C.H.A.
Koster, C. Dekkers, andA.
van Zwol.
1992.
The grammar workbench: Afirst step towards lingware ngineering.
In W. terStal, A. Nijholt, and R. op den Akker, editors,Proceedings of Second Twente Workshop on Lan-guage Technology, pages 103-115, Twente, NL.Oepen, Stephan.
1997.
PAGE.
Platform forAdvanced Grammar Engineering.
WWW page(http://cl-www.dfki.uni-sb.de/cl/systems/page),April.Oy, Lingsoft.
1994.
Gertwol.
Questionnaire for Mor-pholympics 1994.
LD V-Forum, 11 (1): 17-29.Pereira, Fernando C.N.
and Stuart M. Shieber.1987.
Prolog and Natural-Language Analysis, vol-ume 10 of CSLI Lecture Notes.
University ofChicago Press, Stanford.Simpkins, N.K.
1994.
An open architecture for lan-guage ngineering.
The Advanced Language Engi-neering Platform (ALEP).
In Proceedings of Lan-guage Engineering Convention, Paris.
EuropeanNetwork in Language and Speech, Centre for Cog-nitive Science, Edinburgh, pages 129-136.Volk, M., M. Jung, and D. Richarz.
1995.
GTU -A workbench for the development of natural an-guage grammars.
In Proc.
of the Conference onPractical Applications of Prolog, pages 637-660,Paris.Volk, Martin.
1995.
Einsatz einer Testsatzsamm-lung im Grammar Engineering, volume 30 ofSprache und Information.
Niemeyer Verlag,Tiibingen.113
