Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 37?46,The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational LinguisticsProbabilistic Ontology Trees for Belief Tracking in Dialog SystemsNeville MehtaOregon State Universitymehtane@eecs.oregonstate.eduRakesh GuptaHonda Research Institutergupta@hra.comAntoine RauxHonda Research Institutearaux@hra.comDeepak RamachandranHonda Research Institutedramachandran@hra.comStefan KrawczykStanford Universitystefank@cs.stanford.eduAbstractWe introduce a novel approach for robustbelief tracking of user intention withina spoken dialog system.
The space ofuser intentions is modeled by a proba-bilistic extension of the underlying do-main ontology called a probabilistic on-tology tree (POT).
POTs embody a prin-cipled approach to leverage the dependen-cies among domain concepts and incorpo-rate corroborating or conflicting dialog ob-servations in the form of interpreted userutterances across dialog turns.
We tailorstandard inference algorithms to the POTframework to efficiently compute the userintentions in terms of m-best most proba-ble explanations.
We empirically validatethe efficacy of our POT and compare it toa hierarchical frame-based approach in ex-periments with users of a tourism informa-tion system.1 IntroductionA central function of a spoken dialog system(SDS) is to estimate the user?s intention based onthe utterances.
The information gathered acrossmultiple turns needs to be combined and under-stood in context after automatic speech recogni-tion (ASR).
Traditionally, this has been addressedby dialog models and data structures such as forms(Goddeau et al, 1996) and hierarchical task de-composition (Rich and Sidner, 1998).
To formal-ize knowledge representation within the SDS andenable the development of reusable software andresources, researchers have investigated the or-ganization of domain concepts using IS-A/HAS-Aontologies (van Zanten, 1998; Noh et al, 2003).Because the SDS only has access to noisy ob-servations of what the user really uttered due tospeech recognition and understanding errors, be-lief tracking in speech understanding has receivedparticular attention from proponents of probabilis-tic approaches to dialog management (Bohus andRudnicky, 2006; Williams, 2006).
The mecha-nism for belief tracking often employs a Bayesiannetwork (BN) that represents the joint probabil-ity space of concepts while leveraging conditionalindependences among them (Paek and Horvitz,2000).
Designing a domain-specific BN requiressignificant effort and expert knowledge that is notalways readily available.
Additionally, real-worldsystems typically yield large networks on whichinference is intractable without major assumptionsand approximations.
A common workaround tomitigate the intensive computation of the joint dis-tribution over user intentions is to assume full con-ditional independence between concepts which vi-olates the ground truth in most domains (Bohusand Rudnicky, 2006; Williams, 2006).We propose a novel approach to belief track-ing for an SDS that solves both the design andtractability issues while making more realisticconditional independence assumptions.
We repre-sent the space of user intentions via a probabilisticontology tree (POT) which is a tree-structured BNwhose structure is directly derived from the hier-archical concept structure of the domain specifiedvia an IS-A/HAS-A ontology.
The specialization(IS-A) and composition (HAS-A) relationships be-tween the domain concepts are intuitive and pro-vide a systematic way of representing ontologicalknowledge for a wide range of domains.The remainder of the paper is structured as fol-lows.
We begin by describing the construction ofthe POT given a domain ontology.
We show howa POT employs null semantics to represent con-sistent user intentions based on the specializationand composition constraints of the domain.
Wethen show how standard inference algorithms canbe tailored to exploit the characteristics of the POTto efficiently infer the m-best list of probable ex-planations of user intentions given the observa-37tions.
The POT and the associated inference al-gorithm empower a dialog manager (DM) to ac-count for uncertainty while avoiding the designcomplexity, intractability issues, and other restric-tive assumptions that characterize state-of-the-artsystems.
The section on empirical evaluation de-scribes experiments in a tourist information do-main that compare the performance of the POTsystem to a frame-based baseline system.
The pa-per concludes with a discussion of related work.2 Problem FormulationLet {X1, X2, .
.
.
, XN} be a set of N concepts.Every conceptXi takes its value from its finite dis-crete domain D(Xi) which includes a special nullelement for the cases where Xi is irrelevant.
Theuser intention space is defined as U = D(X1) ?D(X2) ?
?
?
?
?
D(XN ).
At each dialog turn t,the system makes a noisy observation ot aboutthe true user intention u ?
U .
ot consists ofa set of slots.
A slot is a tuple ?v, d, c?
wherev ?
{X1, .
.
.
, XN}, d ?
D(v) is a value of v,and c ?
R is the confidence score assigned to thatconcept-value combination by the speech under-standing (SU) system.The goal of belief tracking is to maintainPr(X1, .
.
.
, XN |o1, .
.
.
, ot), a distribution overthe N -dimensional space U conditioned on all theobservations made up to turn t. At each turn, thebelief is updated based on the new observations toestimate the true, unobserved, user intention.3 Probabilistic Ontology TreesWe model the space of the user intentions via aPOT.
A POT is a tree-structured BN that extendsa domain ontology by specifying probability dis-tributions over its possible instantiations based onspecializations and compositions.3.1 Domain OntologyTo ensure that the corresponding POTs are tree-structured, we consider a restricted class of do-main ontologies over concepts.Definition 1.
A domain ontology is a labeled di-rected acyclic graph.
The set of vertices (corre-sponding to the domain concepts) is partitionedinto {V0}, VS , and VC , where V0 is the only rootnode, VS is the set of specialization nodes (re-lated via IS-A to their parents), and VC is the setof composition nodes (related via HAS-A to theirparents).
The set of edges satisfy the constraintsABDCEHFIGJKIJKFigure 1: The ontology for a sample domain whereB IS-A A, C IS-A A, D IS-A A, E IS-A B, F IS-A B,C HAS-A G (essential), D HAS-A G (nonessential),H IS-A D, E HAS-A I (essential), J IS-A G, andK IS-A G. Specialization nodes are drawn single-lined, composition nodes are drawn double-lined,and the root node is drawn triple-lined.
Special-ization subtrees are marked by dashed ovals.that a specialization node has exactly one parentand a composition node may only have more thanone parent if they are all specialization nodes witha common parent.Specialization nodes represent refinements oftheir parent concepts.
Specializations of a con-cept are disjoint, that is, for any particular instanceof the parent exactly one specialization is applica-ble and the rest are inapplicable.
For example, ifDog IS-A Animal and Cat IS-A Animal, then Catis inapplicable when Dog is applicable, and viceversa.
Composition nodes represent attributes oftheir parents and may be essential or nonessential,e.g., Dog HAS-A Color (essential), Dog HAS-ATail (nonessential).
These definitions correspondwith the standard semantics in the knowledge rep-resentation community (Noh et al, 2003).
An ex-ample ontology is shown in Figure 1.Definition 2.
A specialization subtree (spec-tree)in the ontology is a subtree consisting of a nodewith its specialization children (if any).3.2 POT ConstructionWe now describe how a POT may be constructedfrom a domain ontology.
The purpose of the POTis to maintain a distribution of possible instanti-ations of the ontology such that the ontologicalstructure is respected.38Given an ontology G, the corresponding POT isa tree-structured BN defined as follows:Variables.
Let T be a spec-tree in G with rootR.
Unless R is a (non-root) specialization nodewith no specialization children, T is representedin the POT by a variable X with the domainD(X) =?????
{exists, null}, if ChildrenT (R) = ?ChildrenT (R), if R = V0ChildrenT (R) ?
{null}, otherwise.Edges.
Let POT variables X and Y correspondto distinct spec-trees TX and TY in G. There is adirected edge from X to Y if and only if either?
A leaf of TX is the root of TY .?
There is an edge from a leaf in TX to the non-specialization root of TY .?
There is an edge from the non-specializationroot of TX to that of TY .Conditional Probability Tables (CPTs).
If X(corresponding to spec-tree TX ) is the parent of Y(corresponding to spec-tree TY ) in the POT, thenY ?s CPT is conditioned as follows:?
If TY is rooted at one of the leaves of TX ,thenPr(Y = null|X = Y) = 0Pr(Y = null|X 6= Y) = 1where Y is the domain value of X corre-sponding to child Y .?
If R is the root of TX , and TY has a compo-sition root node that is attached only to nodesin S ?
ChildrenTX (R), thenPr(Y = null|X = V) = 1for any domain value V of X correspondingto a node V ?
ChildrenTX (R)?
S.?
If the root of TY is an essential compositionnode attached to a leaf V of TX , thenPr(Y = null|X = V) = 0where V is the domain value of X corre-sponding to the leaf V .We label a POT variable with that of the root ofthe corresponding spec-tree for convenience.
Thedomain of a POT variable representing a spec-treecomprises the specialization children (node namesin sanserif font) and the special value null; the nullABCD0.40.350.25BDEFnullB0.60.40C001D001HnullB01C01D10existsnullE10F01null01JKnullB001C0.80.20D0.70.10.2IGFigure 2: The POT for the example domain.
If anode represents a spec-tree in the ontology, then itis labeled by the root of the spec-tree; otherwise,it is labeled with the name of the correspondingontology node.
D(A) = {B, C, D}, D(B) = {E, F,null}, D(D) = {H, null}, and Pr(A), Pr(B|A) andPr(D|A) represent some distributions over the re-spective specializations.
D(I) = {exists, null} andD(G) = {J, K, null}.
Note that a composition node(G) can be shared between multiple specializa-tions (C and D) in the ontology while the resultingPOT remains tree-structured.value allows us to render any node (except theroot) inapplicable.
Spec-trees comprising singlenodes have the domain value exists to switch be-tween being applicable and inapplicable.
The CPTentries determine the joint probabilities over pos-sible valid instantiations of the ontology and couldbe based on expert knowledge or learned fromdata.
The conditions we impose on them (null se-mantics) ensure that inconsistent instantiations ofthe ontology have probability 0 in the POT.
Whilethe ontology might have undirected cycles involv-ing the children of spec-trees, the correspondingPOT is a tree because spec-trees in the ontologycollapse into single POT nodes.
The POT for theexample domain is shown in Figure 2.3.3 Tourist Information POTFor the empirical analysis, we designed a POT fora tourist information system that informs the userabout places to shop, eat, get service, and displaysrelevant information such as the distance to an in-tended location.
The user can also provide con-versational commands such as stop, reset, undo,etc.
The full ontology for the tourist informationdomain is shown in Figure 3 and the POT is inFigure 4.
In the POT, Action is the root node, withD(Action) = {Venue, Command}, and D(Venue)39ActionVenueCommandStartCancelRestaurantStoreServiceAreaDisplayMilesAmbienceCuisineHoursServiceTypeStreetRatingStoreTypePriceRangeFigure 3: The ontology for the tourist information domain.
All the composition nodes have specializa-tions of their own (such as Japanese and Greek for Cuisine), but have not been shown for the sake ofcompactness.= {Restaurant, Store, Service, null}.
All the com-position (or attribute) nodes such as Hours andRating are made children of Venue by construc-tion.
Since a Command is inapplicable when theAction is a Venue, we have Pr(Command = null| Action = Venue) = 1.
The composition nodes(Cuisine, Street, etc.)
have specializations of theirown ({Japanese, Greek, .
.
.
}, {Castro, Elm, .
.
.
},etc.
), but are not shown for the sake of clarity.Since Cuisine is an essential attribute of Restau-rant, Pr(Cuisine = null | Venue = Restaurant) = 0;moreover, Pr(Cuisine = null | Venue = Service) =1 because Cuisine is not relevant for Service.4 Inferring User IntentionWe have seen how the POT provides the proba-bilistic machinery to represent domain knowledge.We now discuss how the POT structure can beleveraged to infer user intention based on the slotsprovided by the SU.4.1 Soft EvidenceEvery slot retrieved from the SU needs to be incor-porated as observed evidence in the POT.
We canset the associated node within the POT directly toits domain value as hard evidence when we knowthese values with certainty.
Instead, we employprobabilistic observations to soften the evidenceentered into the POT.
We assume that the confi-dence score c ?
[0, 100] of a slot corresponds tothe degree of certainty in the observation.
For anobserved slot variableX , we create an observationnode X?
on the fly with the same domain as X andmake it a child of X .
If x is the observed value forslot X , then the CPT of X?
is constructed from theslot?s confidence score as follows:Pr(X?|X = x) ={c(|D(X)|?1)/100+1|D(X)| , X?
= x1?c/100|D(X)| , X?
6= xThe probability values are generated by lin-early interpolating between the uniform probabil-ity value and 1 based on the confidence score.
Forthe remaining values,Pr(X?|X 6= x) ={1?
?
(|D(X)| ?
1), X?
= X?, X?
6= Xwhere ?
> 0.1 Since the confidence score gives anindication of the probability for the observed valueof a slot but says nothing about the remaining val-ues, the diagonal elements for the remaining val-ues are near 1.
We cannot make them exactly 1because the observation node needs to coexist withpossibly conflicting observations in the POT.If the user confirms the current POT hypothesis,then observations corresponding to the current hy-pothesis (with CPTs proportional to the score ofthe confirmation) are added to the POT to enforcethe belief.
If the user denies the current hypothe-sis, then all observations corresponding to the cur-rent hypothesis are removed from the POT.1In our experiments, we use ?
= 10?10.40ActionVenueCommandAmbienceCuisineDisplayHoursServiceTypeMilesRatingStoreTypeAreaStreetPriceRangeCuisineStreetCastroElmnullCastro0.80.10.1JapaneseGreeknullJapanese0.60.20.2CuisineStreetElm?1?2??null?
?1?2?p Greek?1?2??null?
?1?2?Figure 4: The POT for the tourist information domain.
Assuming that D(Cuisine) = {Japanese, Greek,null} and D(Street) = {Castro, Elm, null}, the shaded observation nodes represent the soft evidence forinput slots ?Cuisine, Japanese, 40?
and ?Street, Castro, 70?.The POT for the tourist information domain af-ter getting two slots as input is shown in Figure 4.The attached nodes are set to the observed slot val-ues and the evidence propagates through the POTas explained in the next section.4.2 POT InferenceA probable explanation (PE) or hypothesis is anassignment of values to the variables in the POT,and the most probable explanation (MPE) withinthe POT is the explanation that maximizes thejoint probability conditioned on the observed vari-ables.
The top m estimates of the user?s intentionscorrespond to them-best MPEs.
The design of thePOT ensures that the m-best MPEs are all con-sistent across specializations, that is, exactly onespecialization is applicable per node in any PE; allinconsistent explanations have a probability of 0.The m-best MPEs could be found naively us-ing the Join-Tree algorithm to compute the jointdistribution over all variables and then use that tofind the top m explanations.
The space required tostore the joint distribution alone is O(nN ), whereN is the number of nodes and n the number ofvalues per node.
Because the run time complex-ity is at least as much as this, it is impractical forany reasonably sized tree.
However, we can geta significant speedup for a fixed m by using theproperties of the POT.Algorithm 1 uses a message-passing protocol,similar to many in the graphical models litera-ture (Koller and Friedman, 2009), to simulate aAlgorithm 1 COMPUTE-PEInput: POT T with rootX0, number of MPEsm, evidence EOutput: m MPEs for T1: for X ?
T in reverse topological order do2: Collect messages ?Yi from all children Yi of X3: ?X = COMPUTE-MPE-MESSAGE(X,m, {?Yi})4: end for5: return top m elements of Pr(X0|E)?X0(?)
without EAlgorithm 2 COMPUTE-MPE-MESSAGEInput: POT node X , number of MPEs m, messages fromchildren ?YiOutput: Message ?X(?
)1: if X is a leaf node then2: ?X(x)?
1,?x ?
D(X)3: return ?X4: end if5: for x ?
D(X) do6: for ~z = ((y1, ~z1), .
.
.
, (yk, ~zk)) ?
{D(?Y1)?
.
.
.
?D(?Yk ) : Pr (Yi = null|X = x,E) < 1} do7: ?
?X(x, ~z)?
?i[Pr(Yi = yi|X = x,E)?Yi (yi, ~zi)]8: end for9: ?X(x)?
top m elements of ?
?X(x).10: end for11: return ?Xdynamic programming procedure across the lev-els of the tree (see Figure 5).
In Algorithm 2, anMPE message is computed at each node X usingmessages from the children, and sent to the par-ent.
The message from X is the function (or ta-ble) ?X(x,~z) that represents the probabilities ofthe top m explanations, ~z, of the subtree rooted atX for a particular value of X = x.
At the rootnode X0 we try all values of x0 to find the top mMPEs for the entire tree.
Note that in step 7, we41A?
D?
B BD?
D?
B??
GIG?
I(a)A =B?
D?
B BD?
D?
B??
GIG?
I(b)A =C?
D?
B BD?
D?
B??
GIG?
I(c)A =D?
D?
B BD??
G?
D?
B IG?
I(d)Figure 5: COMPUTE-MPE applied to the exam-ple POT.
(a) Inference starts with the messages be-ing passed up from the leaves to the root A. Everymessage ?X is an m ?
n table that contains theprobabilities for the m-best MPEs of the subtreerooted at X for all the n domain values of X .
(b)At the root, A is set to its first element B, and itsmarginal Pr(A = B) is combined with the mes-sage ?B .
The semantics of the POT ensures thatthe other messages can be safely ignored becausethose subtrees are known to be null with probabil-ity 1.
(c) A is set to C and only the essential at-tribute G is non-null.
(d) A is set to its final el-ement D, and consequently both the node D andthe nonessential attribute G are non-null and theirmessages are mutually independent.need the marginal P (Y |X,E) which can be ef-ficiently computed by a parallel message-passingmethod.
Evidence nodes can only appear as leavesbecause of our soft evidence representation, andare encompassed by the base case.
The algorithmleverages the fact that the joint of any entire sub-tree rooted at a node that is null with probability 1can be safely assumed to be null with probability1.
The validity of Algorithm 1 is proven in Ap-pendix A.4.3 Complexity AnalysisAt a POT node with at most n values and branch-ing factor k, we do nmaximizations over the prod-uct space of k nm-sized lists.
Thus, the timecomplexity of Algorithm 1 on a POT with Nnodes is O(N(nm)k) and the space complexity isO(Nnmk).
(Insertion sort maintains a sorted listtruncated at m elements to keep track of the topm elements at any time.)
However, the algorithmis significantly faster on specialization nodes be-cause only one child is applicable and needs to beconsidered in the maximization (step 7).
In the ex-treme case of a specialization-only POT, the timeand space complexities both drop to O(Nmn).A similar algorithm for incrementally findingm-best MPEs in a general BN is given in Srinivasand Nayak (1996).
However, our approach has theability to leverage the null semantics in POTs re-sulting in significant speedup as described above.This is crucial because the run-time complexity ofenumerating MPEs is known to be PPP -Completefor a general BN (Kwisthout, 2008).5 Empirical EvaluationTo test the effectiveness of our POT approach, wecompare it to a frame-based baseline system forinferring user intentions.The baseline system uses a hierarchical frame-based approach.
Each frame maps to a par-ticular user intention, and the frames are filledconcurrently from the dialog observations.
Theslots from a turn overwrite matching slots re-ceived in previous turns.
The baseline system usesthe same ontology as the POT to insure that itonly produces consistent hypotheses, e.g., it neverproduces ?Venue=Service, Cuisine=Japanese?
be-cause Service does not have a Cuisine attribute.When several hypotheses compete, the system se-lects the one with the maximum allocated slots.We implemented the POT engine based on theProbabilistic Network Library (Intel, 2005).
Ittakes a POT specification as input, receives theASR slots, and returns its m-best MPEs.Using a tourism information spoken dialog sys-tem, we collected a corpus of 375 dialogs from15 users with a total of 720 turns (details inAppendix B).
Evaluation is performed by run-ning these collected dialogs in batch and pro-viding the ASR slots of each turn to both thebaseline and POT belief-tracking systems.2 Af-ter each turn, both systems return their best hy-pothesis of the overall user intention in the formof a set of concept-value pairs.
These hypothe-2Speech recognition and understanding was performedusing the Nuance Speech Recognition System v8.5 runningmanual and statistical grammars with robust interpretation.42System Precision Recall F1Top hypothesis 0.84 0.81 0.83Top 2 hypotheses 0.87 0.84 0.85POT Top 3 hypotheses 0.89 0.85 0.87Top 4 hypotheses 0.91 0.86 0.89Top 5 hypotheses 0.92 0.86 0.89Baseline 0.84 0.79 0.81Table 1: Precision/recall results comparing thebaseline system against the POT-based system onthe 25-scenario experiment.
Results are averagedover all 15 users.
?1 ?0.8 ?0.6 ?0.4 ?0.2 00.20.30.40.50.60.70.80.91Log?likelihood of top POT hypothesisF1Figure 6: F1 score as a function of the log-likelihood of the top hypothesis for the user?s goal.ses are compared to the true user intention ex-pressed so far in the dialog (e.g., if the user wantsa cheap restaurant but has not mentioned it yet,PriceRange=Cheap is not considered part of theground truth).
This offline approach allows us tocompare both versions on the same input.Table 1 shows the precision/recall results for theexperiment based on comparing the set of true userintention concepts to the inferred hypotheses ofthe POT and baseline systems.
The average worderror rate for all users is 29.6%.
The POT sys-tem shows a 2% improvement in recall and F1over the baseline.
Additionally, leveraging the m-best hypotheses beyond just the top one could helpenhance performance or guide useful clarificationquestions as shown by the improved performancewhen using the top 2?5 hypotheses; we assumean oracle for selecting the hypothesis with highestF1 among the top m hypotheses.
All of the CPTsin the POT (besides the structural constraints) areuniformly distributed.
Thus, the performance ofthe POT could be further improved by training theCPTs on real data.To assess the quality of likelihood returned bythe POT as a belief confidence measure, we binneddialog turns according to the log-likelihood of thetop hypothesis and then computed the F1 score ofeach bin.
Figure 6 shows that belief log-likelihoodis indeed a good predictor of the F1 score.
Thisinformation could be very useful to a dialog man-ager to trigger confirmation or clarification ques-tions for example.6 DiscussionThe definition and construction of POTs provide aprincipled and systematic way to construct proba-bilistic models for an SDS.
While any BN can beused to model the space of user intentions, design-ing an effective network is not an easy task for sys-tem designers not well versed in graphical mod-els.
In previous belief tracking work, researchersdescribe their networks with little indication onhow they arrived at the specific structure (Paek andHorvitz, 2000; Thomson and Young, 2009).
Priorwork on ontologies for SDSs (van Zanten, 1998;Noh et al, 2003) as well as the prominence ofconcept hierarchies in other areas such as object-oriented programming and knowledge engineer-ing make them a natural and intuitive way of repre-senting SDS domains.
The development of POTsbuilds on past research on constructing BNs basedon ontological knowledge (Helsper and van derGaag, 2002; Pfeffer et al, 1999).While most approaches to belief tracking in thedialog systems community make a strict indepen-dence assumption between concepts (Bohus andRudnicky, 2006; Williams, 2006), POTs modelthe dependencies between concepts connected byspecialization and composition relationships whileremaining significantly more tractable than gen-eral BNs and being very straightforward to de-sign.
The null semantics allow a POT to capturedisjoint values and the applicability of attributeswhich are common aspects of concept ontologies.Obviously, a POT cannot capture all types of con-cept relationships since each concept can haveonly one parent.
However, this restriction allowsus to perform efficient exact computation of them-best MPEs which is a significant advantage.Statistical Relational Learning approaches such asMarkov Logic Networks (Richardson and Domin-gos, 2006) have been developed for more generalrelational models than strict ontologies, but theylack the parsimony and efficiency of POTs.43Thomson and Young (2009) describe an ap-proach to dialog management based on a partiallyobservable Markov decision process (POMDP)whose policy depends only on individual con-cepts?
marginal distributions rather than on theoverall user intention.
Because their system per-forms belief tracking with a dynamic Bayesiannetwork (DBN) rather than a static BN, the ex-act marginal computation is intractable and the au-thors use loopy belief propagation to compute themarginals.
Even then, they indicate that the depen-dencies of the subgoals must be limited to enabletractability.
In practice, all concepts are made in-dependent except for the binary validity nodes thatdeterministically govern the dependence betweennodes (similar to the null semantics of a POT).Williams (2007) also represents the user goal asa DBN for a POMDP-based DM.
They performbelief updating using particle filtering and approx-imate the joint probability over the user intentionwith the product of the concept marginals.
Thiscould lead to inaccurate estimation for condition-ally dependent concepts.Among authors who have used m-best lists ofdialog states for dialog management, Higashinakaet al (2003) have shown empirically that main-taining multiple state hypotheses facilitates shorterdialogs.
Their system scores each dialog stateusing a linear combination of linguistic and dis-course features, and this score is used by a hand-crafted dialog policy.
While illustrating the advan-tages of m-best lists, this scoring approach lackstheoretical justification and ability to include priorknowledge that POTs inherit from BNs.7 ConclusionWe have presented the POT framework for belieftracking in an SDS.
We have shown how a POTcan be constructed from the domain ontology andprovided an exact algorithm to infer the user?s in-tention in real-time.
POTs strike a balance be-tween representing rich concept dependencies andfacilitating efficient tracking of them-best user in-tentions based on exact joint probabilities ratherthan approximations such as concept marginals.ReferencesD.
Bohus and A. Rudnicky.
2006.
A K Hypotheses+ Other Belief Updating Model.
In AAAI Workshopon Statistical and Empirical Approaches to SpokenDialogue Systems.D.
Goddeau, H. Meng, J. Polifroni, S. Seneff, andS.
Busayapongchai.
1996.
A Form-Based DialogueManager for Spoken Language Applications.
In IC-SLP.E.
Helsper and L. van der Gaag.
2002.
BuildingBayesian Networks through Ontologies.
In Euro-pean Conference on Artificial Intelligence.R.
Higashinaka, M. Nakano, and K. Aikawa.
2003.Corpus based Discourse Understanding on SpokenDialog Systems.
In Annual Meeting on Associationfor Computational Linguistics.Intel.
2005.
Probabilistic Network Library.
http://sourceforge.net/projects/openpnl/.D.
Koller and N. Friedman.
2009.
ProbabilisticGraphical Models: Principles and Techniques.
MITPress.J.
Kwisthout.
2008.
Complexity Results for Enumerat-ing MPE and Partial MAP.
In European Workshopon Probabilistic Graphical Models.H.
Noh, C. Lee, and G. Lee.
2003.
Ontology-basedInference for Information-seeking in Natural Lan-guage Dialog Systems.
In IEEE International Con-ference on Industrial Informatics.T.
Paek and E. Horvitz.
2000.
Conversation as Ac-tion under Uncertainty.
In Uncertainty in ArtificialIntelligence.A.
Pfeffer, D. Koller, B. Milch, and K. T. Takusagawa.1999.
Spook: A system for probabilistic object-oriented knowledge representation.
In Uncertaintyin Artifical Intelligence.C.
Rich and C. Sidner.
1998.
COLLAGEN: a Col-laboration Manager for Software Interface Agents.An International Journal: User Modeling and UserAdapted Interaction, 8.M.
Richardson and P. Domingos.
2006.
Markov LogicNetworks.
Machine Learning, 62:107?136.S.
Srinivas and P. Nayak.
1996.
Efficient Enumerationof Instantiations in Bayesian Networks.
In UAI.B.
Thomson and S. Young.
2009.
Bayesian Updateof Dialogue State: A POMDP Framework for Spo-ken Dialogue Systems.
Computer Speech and Lan-guage.G.
van Zanten.
1998.
Adaptive Mixed-Initiative Dia-logue Management.
In IEEE Workshop on Interac-tive Voice Technology for Telecommunications Ap-plications.J.
Williams.
2006.
Partially Observable Markov Deci-sion Processes for Dialog Management.J.
Williams.
2007.
Using Particle Filters to TrackDialogue State.
In IEEE Workshop on AutomaticSpeech Recognition & Understanding.44A Analysis of the Inference AlgorithmTheorem 1.
Algorithm 1 returns the top m MPEsof the POT along with their joint probabilities.Proof.
We first prove this for the special case ofm = 1 to simplify notation.
For the base caseof a node with no children, Algorithm 2 sim-ply returns a message with all probabilities at1 for all values of that node.
Now, consider anode X with children Y1, .
.
.
, Yk.
Let Desc(Y )be the descendants of node Y .
Since Algo-rithm 2 given node X returns exactly one expla-nation, z for each x ?
D(X), we will define?X(x) = ?X(x, z).
Now, to show that ?X(x) =maxDesc(X) Pr(Desc(X)|X = x,E), that is, Al-gorithm 2 returns the top explanation of the entiresubtree rooted at X for every value in D(X), weuse structural induction on the tree.maxDesc(X)Pr(Desc(X)|X = x,E)= maxY1:k,Desc(Y1:k)Pr(Y1:k,Desc(Y1:k)|X = x,E)= maxY1:k,Desc(Y1:k)?iPr(Yi|X = x,E) Pr(Desc(Yi)|Yi, E)=?imaxYi,Desc(Yi)[Pr(Yi|X = x,E) Pr(Desc(Yi)|Yi, E)]=?imaxYi[Pr(Yi|X = x,E) maxDesc(Yi)Pr(Desc(Yi)|Yi, E)]=?imaxYi[Pr(Yi|X = x,E)?Yi(yi)]{Inductive step}= ?X(x).The proof for m > 1, where every maximizationreturns a list of the top m elements, is similar.B Dialogs in the Tourist InformationDomainEach user conducted 25 dialogs according to pre-scribed scenarios for the tourist information do-main.
The order of scenarios was randomized foreach user.
Sample scenarios:1.
Find a good and cheap Mexican restaurant inMountain View.2.
There is a medical emergency and you needto get to the hospital.
Find a route.3.
You need to find your favorite coffee fran-chise.
You have 10 minutes to get coffee.4.
Find a place to buy some fruits and vegeta-bles.5.
Find a Chinese restaurant in Santa Clara withgood ambiance, and display travel distance.6.
Find an ATM on Castro Street in MountainView.Figure 7 shows a typical interaction with thesystem for the first scenario along with a possi-ble hypothesis inferred by the system at every turnof the dialog.
Figure 8 shows an example wherethe POT system is able to discard an incorrect ob-servation about a restaurant based on the accumu-lated belief about bookstores over multiple turns.Figure 9 shows how the POT is able to leverage theontological structure to pick out higher-level con-cepts with lower confidence scores over spuriouslow-level concepts with higher confidence scores.45User Find a Mexican restaurant in Mountain View.Hypothesis [venue restaurant] [area mountain view] [cuisine italian]{Note: Mexican is misrecognized as Italian.
}User No, Mexican.Hypothesis [venue restaurant] [area mountain view] [cuisine mexican]User Show me ones with at least four star rating.Hypothesis [venue restaurant] [area mountain view] [cuisine mexican] [rating four star]User I want a cheap place.Hypothesis [venue restaurant] [area mountain view] [cuisine mexican] [rating four star] [price cheap]User Is there anything on Castro?Hypothesis [venue restaurant] [area mountain view] [street castro] [cuisine mexican] [rating four star] [price cheap]Figure 7: A sample dialog in the tourism information domain showing the inferred hypothesis of theuser?s intention at every turn.
The information response from the system?s back-end is based on itscurrent hypothesis.User utterance Where is the bookstore?ASR where is the bookstoreTrue hypothesis [action venue] [venue store] [sell book]Baseline hypothesis [action venue] [venue store] [sell book]POT hypothesis [action venue] [venue store] [sell book]User utterance Store on Market Street.ASR store on market streetTrue hypothesis [action venue] [venue store] [sell book] [street market]Baseline hypothesis [action venue] [venue store] [sell book] [street market]POT hypothesis [action venue] [venue store] [sell book] [street market]User utterance In downtown.ASR dennysTrue hypothesis [action venue] [venue store] [sell book] [street market] [area downtown]Baseline hypothesis [action venue] [venue restaurant] [brand dennys]POT hypothesis [action venue] [venue store] [sell book] [street market]Figure 8: A dialog showing the ASR input for the user?s utterance, and the corresponding true, baseline,and POT hypotheses.
The POT is able to correctly discard the inconsistent observation in the third turnwith the observations in previous turns.User utterance Where should I go to buy Lego for my kid?SU slots ?Venue Store 38?
?ServiceType GolfCourse 60?True hypothesis [action venue] [venue store] [storetype toy]Baseline hypothesis [action venue] [venue service] [servicetype golf course]POT hypothesis [action venue] [venue store]Figure 9: A single dialog turn showing the SU slots for the user?s utterance, and the correspondingbaseline, POT, and true hypotheses.
Any system that looks at the individual confidence scores will baseits hypothesis on the ?ServiceType GolfCourse 60?
slot.
Instead, the POT hypothesis is influenced by?Venue Store 38?
because its score in combination with the concept?s location in the POT makes it morelikely than the other slot.46
