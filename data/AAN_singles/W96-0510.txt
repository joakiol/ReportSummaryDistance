Summarization: an Application for NL GenerationBeryl HoffmanCentre for Cognitive ScienceUniversity of Edinburgh2 Buccleuch PlaceEdinburgh EH8 9LW, U.K.hof fman~cogsc?,  ed.
ac.
uk1 IntroductionIn this paper, I will be exploring techniques forautomatically summarising texts, concentrat-ing on selecting the content of the summaryfrom a parsed (semantic) representation f theoriginal text.
Summarization is a particularlynice application for natural language genera-tion because the original text can serve as theknowledge base for generating the summary.In addition, we only need to develop a lexiconlimited to the words and senses in the origi-nal text (as long as we use the same words inthe same context as the original text).
Thissimplifies the generation task somewhat.However, summarization is not a trivialtask.
We must first analyze the original textusing a robust grammar that can produce a re-liable semantic interpretation of the text.
Tosimplify this investigation, I will not tackle themany problems of NL analysis, but will use al-ready parsed texts from the TAG Tree Bank(UPenn, 1995).
I use a perl script to convertthe syntactic structures in this parsed corpusinto a list of logical forms that roughly indi-cate the predicate-argument structure of eachclause in the text.
1 We can generate a sum-mary by choosing a subset of this list of LFs.However, choosing the right subset is not easy.The problem is how to judge which clausesare important: Sophisticated iscourse analy-sis is needed in order to interpret he inten-tional and rhetorical structure of the originaltext and then prune it in the appropriate ways.1A parser which directly produces the pred-argstructure is probably preferable to this method.
Notethat the parser probably would not have to resolve allsyntactic ambiguities in the the summarization task,because we can preserve the same ambiguities in thesummary, or delete some of the problem phrases uchas PPs in the summary anyway.However, discourse analysis is a hard task thatrequires an immense amount of world knowl-edge (Sparck-Jones, 1993).
I investigate waysto generate a summary without full interpreta-tion of the original text.
I use Centering The-ory to roughly segment he text, as describedin the next section.
Then, as described in sec-tion 3, a set of pruning rules based on centersand discourse relations are used to select thecontent of the summary.
First, those segmentsthat are about the most frequent centers of at-tention are selected, and then these segmentsare pruned by recognizing non-critical elabora-tions among the propositions.
Another heuris-tic used is to select restatements among thepropositions for the summary, since restate-ment is a good indicator of important informa-tion.
The proposed summarization heuristicsare tested out on a sample text in section 4;an implementation to test out these heuristicsis in progress.2 D iscourse  Segmentat ionCentering Theory (Grosz, Joshi, and Wein-stein, 1995) is a computational model of localdiscourse coherence which relates each utter-ance to the previous and the following utter-ances by keeping track of the center of atten-tion.
The most salient entity, the center ofattention, at a particular utterance is calledthe backward looking center (Cb).
The Cb isdefined as the highest hematically ranked el-ement in the previous utterance that also oc-curs in the current utterance.
If there is apronoun in the sentence, it is preferred to beCb.Centering Theory can be used to segmenta discourse by noting whether the same cen-ter of attention, Cb, is preserved from one ut-37terance to another.
Basically, we can eitherCONTINUE to talk about the same entity orSHIFT to a new center.
A SHIFT indicatesthe start of a new discourse segment.
2In the method that I am proposing, the orig-inal text is first divided into segments accord-ing to Centering Theory.
Then, as describedin the following sections, the segments whichaxe about the most frequent Cb(s) in the textare selected for the summary, and then thediscourse relations of elaboration and restate-ment are used to further prune and select in-formation for the summary.3 Content  Se lec t ion3.1 F requent  CentersAfter the text has been segmented, we needto decide which of the discourse segments areimportant for the summary.
The most preva-lent discourse topic will play a big role in thesummary.
Thus, the most frequent Cb can beused to select the important segments in thetext.
I propose the following heuristic:Heur i s t i c  1: Select those segmentsthat are about the most frequent Cbin the text 3 for the summary.Picking the most frequent Cb gives bet-ter results than simply picking the most fre-quent words or references as the most im-portant topics in the text.
For example,in the sample text (see Section 4) about anew electronic surveillance method being triedon prisoners that will allow them to be un-der house-arrest, "wristband" occurs just asfrequently as "surveillance/supervision', how-ever "surveillance/supervision" is a more fre-quent Cb than "wristband", and this reflectsthe fact that it is a more central topic in thetext.3.2 Pruning Elaborat ionsWhile doing the centering analysis of mysample texts, I noticed that it is the seg-ment boundaries, the SHIFTs, that are impor-tant for summarization i the discourse anal-2There are other  cues to discourse segmentat ion(not yet included in this study) such as tense and as-pect cont inuity and the use of cue words such as "and".3More than  one frequent Cb can be picked if thereare no clear winners.ysis of the original text.
In fact, the CON-TINUE transitions in Centering often corre-spond to Elaboration relations in RST (Mannand Thompson, 1987).
A restricted type of theelaboration relation between sentences can berestated in Centering terms:Elaborat ion on the  same topic:the subject of the clause is a pronounthat refers to the subject of the pre-vious clause - a CONTINUE in cen-tering.Thus, I propose the following heuristic forpruning the segments in the summary:Heur i s t i c  2: Delete elaborations onthe same topic (as defined above) inthe summary.For example, the second sentence below canbe left out of the summary because it is anelaboration on the same topic.
(1) a.
Most county jail inmates  did notcommit violent crimes.
(Cb = inmates, SHIFT)b.
They ' re  in jail for such things as badchecks or stealing.
(Cb = they = inmates, CONTINUE)3.3 RestatementAnother RST relation that is very importantfor summarization is Restatement, because re-statements are a good indicator of importantinformation.
Good authors often restate thethesis, often at the beginning and at the endof the text, to ensure that the point of the textgets across.
The heuristic used is:Heur i s t i c  3:Select repeated or semantically syn-onymous LFs (i.e.
predicate-argument relations) in the originaltext for the summary.One way to find restatements in the text isto simply search for repeated phrases.
How-ever, most good authors restate phrases rathersimply repeating them.
That is why I pro-pose we search for repeated LFs rather thanrepeated words or phrases.
Since LFs capturethe primary relations in a whole clause, theirfrequency captures dependencies that tradi-tional statistical approaches uch as bigrams38and trigrams would miss.
However, some in-ference would be necessary in order to inferwhether LFs are.
semantically synonymous.For example, the following two sentencesfrom the sample text are very similar.Their semantic representations contain thepropositions call(computer, prisoner) and plug-in(prisoner), after anaphora resolution and in-ferences uch as that call(computer, prisoner)is equivalent to make(a computerized call, to aformer prisoner's home).
Notice that a simpletrigram would not recognize "that person an-swers by plugging in" in (2)b as a restatementof the "prisoner plugs in".
We need to con-sider the predicate-argument relations insteadof simple word collocations.
(2) a.
Whenever a computer andomly callsthem from jail, the former prisonerplugs in to let corrections officialsknow they're in the right place at theright time.b.
When a computerized call is made toa former prisoner's home, that personanswers by plugging in the device.Searching for similar LFs captures impor-tant information that is restated many timesin the text.
4 This method is similar to aggrega-tion methods used in NL generation.
Summa-rization can be seen as a massive applicationof aggregation algorithms.
We need to lookfor shared elements, agents, propositions, etc.in the semantic representation f the originaltext in order to aggregate similar elements aswell as to recognize important elements thatthe author restates many times.4 An  Example  TextThe following is a sample text from the PennTreebank.
The A and alternating normal anditalicized script mark segment breaks in thetext as determined by Centering Theory.
Em-bedded subsegments are shown with brackets.The Cbs are shown in bold.TEXT:AComputer i zed  phone  calls \[which do ev-erything from selling magazine subscriptionsto reminding people about meetings\] have be-come the telephone quivalent of junk mail,4Many restatements  in the texts involve the mostfrequent Cb which may serve as an addit ional  heuristic.but a new application of the techno logy  isabout to be tried out in Massachusetts \[to easecrowded jail conditions\].
AA Next week somei nmates  IT released early .from the HamptonCounty jail\] in Springfield will be wearing awristband \[that T hooks up with a special jackon their home phones\].
\[Whenever a computerrandomly calls them .from jail\], the  fo rmerpr isoner  plugs in \[\[to let corrections officialsknow\] they're in the right place at the righttime\]\].
A The device is attached to a plasticwristband.
It  looks like a watch.
It  func-tions like an electronic probation officer.
A\[When a computerized call is made to a formerprisoner's home phone\], that person answersby plugging in the device.
A The wristbandcan be removed only by breaking its clasp and\[if that's done\] the inmate immediately is re-turned to jail.
A The description conjuresup images of big brother watching, A but JayAsh, \[deputy superintendent of the HamptonCounty jail in Springfield\], says \[the surveil-lance system is not that sinister\].
Such su-pervis ion,  \[according to Ash\], is a sensiblecost effective alternative to incarceration \[thatT should not alarm civil libertarians\].
A Dr.Norman Rosenb la t t ,  \[dean of the college ofcriminal justice at Northeastern University\],agrees.
Rosenb la t t  expects electronic surveil-lance in parole situations to become more widespread, and he thinks \[eventually people willget used to the idea\].
A Springfield jail deputysuperintendent Ash says \[\[although it will al-low some prisoners to be released a few monthsbefore their sentences are up\], concerns thatmay raise about public safety are not wellfounded\].
AA Most  county  jail inmatesdid not commit violent crimes.
They ' re  injail for such things as bad checks or stealing.Those  on ear ly release must check in withcorrections officials fifty times a week accord-ing to Ash \[who says about half the contacts fora select group will now be made by the comput-erized phone calls\].
A Initially the programwill involve only a handful of inmates.
Ashsays the ultimate goal is to use it \[to get aboutforty out of jail early\].
A The Springfield jailIT built for 270 people\] now houses more than500.
AThe content of the summary is selected bypicking the two segments with the most fre-39quent Cb, the inmate(s)/prisoner.
These aremarked with two AAs at the beginning ofthe segments above.
Then, elaborations (i.e.CONTINUEs) in these segments are deleted.Essentially, this leaves the first sentence ofeach segment with the Cb the inmates.
In ad-dition, we search for restatements in the text.As a result, the following sentences from thetext are selected for the summary.
The firstand third sentences are the first sentences inthe segments about the most frequent Cb, theinmates; the second sentence as well as partof the first sentence is given by recognizing re-statements in the text.Summary :ANext week some inmates released early fromthe Hampton County jail in Springfield willbe wearing a wristband that hooks up with aspecial jack on their home phones.
A When acomputerized call is made to a former pris-oner's home phone, that person answers byplugging in the device.
A Most county jailinmates did not commit violent crimes.
AThe summary above just shows the relevantportions of the original text (in the original or-der) selected for the summary.
The heuristicsfor content selection actually operate on LFs;the selected LFs will then be sent to a genera-tor which can plan a more coherent summarythan what is produced above.
55 Conc lus ionsIn this paper, I have outlined the followingmethod for content selection in the summa-rization task.
The content of the summary isselected from a parsed (semantic) representa-tion of the original text.
Centering Theoryis used to segment he text.
Segments thatare about the most frequent centers and LFsthat are restated in the text are selected as im-portant information for the summary.
Thesesegments are then pruned by recognizing elab-orations.1.
Parse the original text into a list of logicalforms.2.
Divide the original text into segmentsaccording to Centering Theory and doanaphora resolution.5The selected LFs for each sentence should also besimplified by pruning unnecessary adjuncts and em-bedded clauses.3.
Select the segments that are about themost frequent Cb(s) in the text.4.
Delete elaborations (i.e.
CONTINUEs inCentering terms) in these selected seg-ments, and substitute antecedents for allanaphora in the LFs for these segments.5.
Simplify the LFs in these selected seg-ments by pruning unnecessary adjunctsand embedded clauses.6.
Find restated propositions in the seman-tic representation f the original text bysearching for repeated or semanticallysynonymous LFs.7.
Generate the summary from the LFs pro-duced by the last two steps.I believe that the method proposed aboveshows promise in selecting important informa-tion from the original text for the summary.However, a rigorous evaluation of the sum-maries produced by the method is now needed.I have assumed that in the summarization taskthe computer does not have to fully under-stand the original text if it can reuse the samewords, phrases, and predicate-argument rela-tions.
However, the summary will improveas we undertake deeper (rhetorical and inten-tional) analysis of the original text and as wemove from simply selecting information fromthe text to inferencing and generalizing fromthe information in the text.Re ferencesBarbara Grosz, Aravind K. Joshi, and Scott Wein-stein.
1995.
Centering: A framework for mod-elling the local coherence ofdiscourse.
Compu-tational Linguistics.Karen Sparck Jones.
1993.
What might be in asummary?
In Knorz, Krause, and Womser-Hackr, editors, Information Retrieval 93: Vonder ModeUierung zur Anwendung, pages 9-26.William Mann and Sandra Thompson.
1987.Rhetorical structure theory: A framework forthe analysis of texts.
Technical Report RS-87-185, ISI.Penn TreeBank.
1995.
University of Pennsylvania.copyrighted.40
