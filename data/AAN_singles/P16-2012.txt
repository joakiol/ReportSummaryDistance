Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 72?76,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsImproved Parsing for Argument-Clusters CoordinationJessica FiclerComputer Science DepartmentBar-Ilan UniversityIsraeljessica.ficler@gmail.comYoav GoldbergComputer Science DepartmentBar-Ilan UniversityIsraelyoav.goldbreg@gmail.comAbstractSyntactic parsers perform poorly in pre-diction of Argument-Cluster Coordination(ACC).
We change the PTB representationof ACC to be more suitable for learningby a statistical PCFG parser, affecting 125trees in the training set.
Training on themodified trees yields a slight improvementin EVALB scores on sections 22 and 23.The main evaluation is on a corpus of 4thgrade science exams, in which ACC struc-tures are prevalent.
On this corpus, we ob-tain an impressive ?2.7 improvement inrecovering ACC structures compared to aparser trained on the original PTB trees.1 IntroductionMany natural language processing systems makeuse of syntactic representations of sentences.These representations are produced by parsers,which often produce incorrect analyses.
Many ofthe mistakes are in coordination structures, andstructures involving non-constituent coordination,such as Argument Cluster Coordination, RightNode-Raising and Gapping (Dowty, 1988), are es-pecially hard.Coordination is a common syntactic phenomenaand work has been done to improve coordinationstructures predication in the general case (Hogan,2007; Hara et al, 2009; Shimbo and Hara, 2007;Okuma et al, 2009).
In this work we focus on oneparticular coordination structure: Argument Clus-ter Coordination (ACC).
While ACC are not com-mon in the Penn TreeBank (Marcus et al, 1993),they commonly appear in other corpora.
For ex-ample, in a dataset of questions from the Regents4th grade science exam (the Aristo Challenge),14% of the sentences include ACC.ACC is characterized by non-constituent se-quences that are parallel in structure.
For instance,in ?I bought John a microphone on Monday andRichie a guitar on Saturday?, the conjunction isbetween ?John a microphone on Monday?
and?Richie a guitar on Saturday?
which are both non-constituents and include parallel arguments: theNPs ?John?
and ?Richie?
; the NPs ?a micro-phone?
and ?a guitar?
; and the PPs ?on Monday?and ?on Saturday?.Previous NLP research on the Argument Clus-ters Coordination (Mouret, 2006) as well as thePenn TreeBank annotation guidelines (Marcus etal., 1993; Bies et al, 1995) focused mainly onproviding representation schemes capable of ex-pressing the linguistic nuances that may appear insuch coordinations.
The resulting representationsare relatively complex, and are not easily learn-able by current day parsers, including parsers thatrefine the grammar by learning latent annotations(Petrov et al, 2006), which are thought to be moreagnostic to the annotations scheme of the trees.
Inthis work, we suggest an alternative, simpler rep-resentation scheme which is capable of represent-ing most of the Argument Cluster coordinationcases in the Penn Treebank, and is better suitedfor training a parser.
We show that by changingthe annotation of 125 trees, we get a parser whichis substantially better at handling ACC structures,and is also marginally better at parsing generalsentences.2 Arguments Cluster Coordination inthe Penn Tree BankArgument Cluster Coordinations are representedin the PTB with two or more conjoined VPs,where the first VP contains a verb and indexed ar-guments, and the rest of the VPs lack a verb andinclude arguments with indices corresponding to72those of the first conjoined VP.
For example, con-sider the PTB representation of ?The Q ratio wasonly 65% in 1987 and 68.9% in 1988?
:VPVPVBDwasNP-1only 65 %PP-2in 1987CCandVPNP=168.9 %PP=2in 1988The main VP includes two conjoined VPs.
Thefirst VP includes the verb was and two indexed ar-guments: ?only 65%?
(1) and ?in 1987?
(2).
Thesecond VP does not include a verb, but only twoarguments, that are co-indexed with the parallel ar-gument at the first conjoined VP.ACC structures in the PTB may include modi-fiers that are annotated under the main VP, and theconjoined VPs may includes arguments that arenot part of the cluster.
These are annotated withno index, i.e.
?insurance costs?
in [1a].ACC structures are not common in the PTB.The training set includes only 141 ACC structuresof which are conjoined by and or or.
Some ofthem are complex but most (78%) have the follow-ing pattern (NT is used to denote non-terminals):VPVPVerb NT-1 NT-2CCand/orVPNT=1 NT=2These structures can be characterized as follows:(1) the first token of the first conjoined VP is averb; (2) the indexed arguments are direct chil-dren of the conjoined VPs; (3) the number of theindexed arguments is the same for each conjoinedVP.Almost all of these cases (98%) are symmetric:each of the conjoined VPs has the same types ofindexed arguments.
Non-symmetric clusters (e.g.
?He made [these gestures]1NP[to the red group]2PPand [for us]2PP[nothing]1NP?)
exist but are lesscommon.We argue that while the PTB representation forACC gives a clear structure and covers all the ACCforms, it is not a good representation for learn-ing PCFG parsers from.
The arguments in theclusters are linked via co-indexation, breaking thecontext-free assumptions that PCFG parsers relyon.
PCFG parsers ignore the indexes, essentiallylosing all the information about the ACC con-struction.
Moreover, ignoring the indexes resultin ?weird?
CFG rules such as VP?
NP PP.
Notonly that the RHS of these rules do not include averbal component, it is also a very common struc-ture for NPs.
This makes the parser very likely toeither mis-analyze the argument cluster as a noun-phrase, or to analyze some NPs as (supposedlyACC) VPs.
The parallel nature of the constructionis also lost.
To improve the parser performance forACC structures prediction, we suggest an alterna-tive constituency representation for ACC phraseswhich is easier to learn.3 Alternative Representation for ACCOur proposed representation for ACC respects thecontext-free nature of the parser.
In order to avoidincorrect syntactic derivations and derivations thatallows conjoining of clusters with other phrases,as well as to express the symmetry that occur inmany ACC phrases, we change the PTB represen-tation for ACC as follows: (1) we move the verband non-indexed elements out of the first argu-ment cluster to under the main VP; (2) each ar-gument cluster is treated as a phrase, with newnon-terminal symbols specific to argument clus-ters; (3) the conjunction of clusters also receives adedicated phrase level.
For example see compari-son between the original and new representations:[1]VPVPVBNdrivenPRTupNPinsurancecostsNP-120%PP-2in MarylandCCandVPNP=130%PP=2in California(a) PTB representationVPVBNdriven PRTupNPinsurancecostsACCPHNPACCNP?PPNP-120%PP-2inMarylandCCand ACCNP?PPNP=130%PP=2inCalifornia(b) Our modified treeThe main verb driven as well as the particle upand the non-indexed argument insurance costs aremoved to the external VP.
The two argument clus-ters (formerly VPs) receive dedicated phrase la-bels ACCX, where X reflects the syntactic types73of the indexed elements (e.g.
ACCNP?PPfor thefirst cluster in [1b] above).
The most commoncases are ACCNP?PPwhich appears in 41.6%of the clusters, ACCADJP?PPwith 21.2% of theclusters and ACCPP?PPwith 5.3% of the clus-ters.Finally, we introduce a new phrase type(ACCPHX) for the coordination of the two clus-ters.
Here X denotes the main element in the clus-ters, determined heuristically by taking the first ofthe following types that appear in any of the clus-ters: NP, PP, ADJP, SBAR.
Cases where the clus-ters contains an ADVP element are usually special(e.g.
the following structure is missing ?people?
inthe second cluster: ((NP 8000 people) (in Spain))and ((NP 2000) (ADVP abroad))).
For such cases,we add ?ADVP?
to the ACCPH level label.
Ta-ble 1 lists theACCPH level labels and their num-ber of the appearances in the 125 modified trees.1The representation is capable of representingcommon cases of ACC where the cluster elementsare siblings.
We similarly handle also some of themore complex cases, in which an extra layer ap-pears between an indexed argument and the con-joined VP to host an empty element, such as inthe following case with an extra S layer abovesingle-B-3:VPVPVBNratedSNP-NONE-ADJP-1single-B-3PP-2by...CCandVPADJP=1single-B-plusPP=2by...in which we remove the empty NP as well as theextra S layer:VPVBNratedACCPHPPACCADJP?PPADJPsingle-B-3PPby...CCandACCADJP?PPADJPsingle-B-plusPPby...1Parsers that apply latent annotations to the grammar,such as the Berkeley Parser (Petrov et al, 2006) we use inour experiments, can potentially learn some of our proposedrefinements on their own.
However, as we show in the ex-periments section, the performance of the Berkeley Parseron ACC structures significantly improve when applying ourtransformations prior to training.Label # Label #ACCPHNP69 ACCPHNP?ADV P6ACCPHPP36 ACCPHPP?ADV P11ACCPHADJP2 ACCPHSBAR?ADV P1Table 1: The labels for the new level in the ACCtrees.
#: number of occurrences.Limitations Our representation is similar to therepresentation that was suggested for ACC byHuddleston et al (2002) in their comprehen-sive linguistic description of the English gram-mar.
However, while it is capable of repre-senting the common cases of ACC, it does notcover some complex and rare cases encounteredin the PTB: (1) Argument-Cluster structures thatinclude errors such as missing indexed argumentand a wrong POS tag for the main verb; (2) ACCconstructions where the main verb is betweenthe indexed arguments such as the following:?
([About half]1invested [in government bonds]2)and ([about 10%]1[in cash]2)?
; (3) Argument-Cluster structures that include an indexed phrasewhich is not a direct child of the cluster headand has non-empty siblings, such as in the follow-ing case that includes an indexed argument (8%)which is not directly under the conjoined VP andhas non-empty sibling (of ): ?see a raise [[of][8%]NP?1]PPin the first year] and [7%]NP=1in each of the following two years?.Our changes are local and appear in small num-ber of trees (0.003% of the PTB train set).
We alsoignore more complex cases of ACC.
Yet, trainingthe parser with the modified trees significantly im-proves the parser results on ACC structures.4 ExperimentsWe converted 125 trees with ACC structures inthe training sets (sections 2-21) of the PTB tothe new representation, and trained the Berkeleyparser (Petrov et al, 2006) with its default settings.As the PTB test and dev sets have only 12 ACCstructures that are coordinated by and or or, weevaluate the parser on Regents, a dataset in whichACC structures are prevalent (details below).
AsRegents does not include syntactic structures, wefocus on the ACC phenomena and evaluate theparsers?
ability to correctly identify the spans ofthe clusters and the arguments in them.To verify that the new representation does notharm general parsing performance, we also eval-74Dataset R P F1DevPTB Trees 90.88 90.89 90.88Modified Trees 90.97 91.21 91.09TestPTB Trees 90.36 90.79 90.57Modified Trees 90.62 91.06 90.84Table 2: Parsing results (EVALB) on PTB Sec-tions 22 (DEV) and 23 (TEST).PTB Trees Modified TreesACCPTB13.0 -ACCOUR24.1 64.8Table 3: The parser Recall score in recover-ing ACC conjunct spans on the Regents dataset.ACCPTB: the set is annotated with the verb in-side the first cluster.
ACCOUR: the set is anno-tated following our approach.uate the parer on the traditional development andtest sets (sections 22 and 23).
As can be seen inTable 2, the parser results are slightly better whentrained with the modified trees.24.1 Regents data-setRegents ?
a dataset of questions from the Regents4th grade science exam (the Aristo Challenge),3includes 281 sentences with coordination phrases,where 54 of them include Argument Cluster co-ordination.
We manually annotated the sentencesby marking the conjuncts spans for the constituentcoordination phrases, e.g.
:Wendy (ran 19 miles) and (walked 9 miles)as well as the spans of each component of theargument-cluster coordinations, including the in-ner span of each argument:Mary paid ([$11.08] [for berries]) , ([$14.33] [forapples]) , and ([$9.31] [for peaches])The bracketing in this set follow our proposedACC bracketing, and we refer to it as ACCOUR.We also created a version in which the bracket-ing follow the PTB scheme, with the verb includedin span of the first cluster, e.g.
:Mary ([paid] [$11.08] [for berries]) , ([$14.33][for apples]) , and ([$9.31] [for peaches])We refer to this dataset as ACCPTB.2The same trend holds also if we exclude the 12 modifiedtrees from the evaluation sets.3http://allenai.org/content/data/Regents.zipWe evaluate the parsers?
ability to correctly re-cover the components of the coordination struc-tures by computing the percentage of gold anno-tated phrases where the number of predicted con-junct is correct and all conjuncts spans (roundbrackets) are predicted correctly (Recall).
Forexample, consider the following gold annotatedphrase:A restaurant served (9 pizzas during lunch) and (6during dinner) todayA prediction of (?9 pizzas during lunch?, ?6during dinner today?)
is considered as incorrectbecause the second conjunct boundaries are notmatched to the gold annotation.We compare the Recall score that the parserachieves when it is trained on the modified treesto the score when the parser is trained on the PTBtrees.When evaluated on all coordination cases in theRegents dataset (both ACC and other cases of con-stituent coordination), the parser trained on themodified trees was successful in recovering 54.3%of the spans, compared to only 47% when trainedon the original PTB trees.We now focus on specifically on the ACCcases (Table 3).
When evaluating the PTB-trainedparser on ACCPTB, it correctly recovers only13% of the ACC boundaries.
Somewhat sur-prisingly, the PTB-trained parser performs betterwhen evaluated against ACCOUR, correctly re-covering 24.1% of the structures.
This highlightshow unnatural the original ACC representation isfor the parser: it predicts the alternative represen-tation more often than it predicts the one it wastrained on.
When the parser is trained on the mod-ified trees, results on ACCOURjump to 64.8%,correctly recovering ?2.7 more structures.The previous results were on recovering thespans of the coordinated elements (the roundbrackets in the examples above).
When mea-suring the Recall in recovering any of the argu-ments themselves (the elements surrounded bysquare brackets), the parser trained on the mod-ified trees recovers 72.46% of the arguments inclusters, compared to only 58.29% recovery bythe PTB-trained parser.
We also measure in whatpercentage of the cases in which both the clusterboundaries (round brackets) were recovered cor-rectly, all the internal structure (square brackets)was recovered correctly as well.
The score is 80%when the parser trained on the modified trees com-75pared to 61.5% when it is trained on the PTB-trees.Overall, the parser trained on the modified treessignificantly outperforms the one trained on theoriginal trees in all the evaluation scenarios.Another interesting evaluation is the ability ofthe parser that is trained on the modified trees todetermine whether a coordination is of ArgumentClusters type (that is, whether the predicted co-ordination spans are marked with the ACCPH la-bel).4The results are a Recall of 57.4% and Pre-cision of 83.78%.
When we further require thatboth the head be marked as ACCPH and the in-ternal structure be correct, the results are 48.14%Recall and 70.27% Precision.5 ConclusionsBy focusing on the details of a single and rela-tively rare syntactic construction, argument clus-ters coordination, we have been able to signifi-cantly improve parsing results for this construc-tion, while also slightly improving general parsingresults.
More broadly, while most current researchefforts in natural language processing and in syn-tactic parsing in particular is devoted to the de-sign of general-purpose, data-agnostic techniques,such methods work on the common phenomenawhile often neglecting the very long tail of impor-tant constructions.
This work shows that there aregains to be had also from focusing on the detailsof particular linguistic phenomena, and changingthe data such that it is easier for a ?data agnostic?system to learn.AcknowledgmentsThis work was supported by The Allen Insti-tute for Artificial Intelligence as well as the Ger-man Research Foundation via the German-IsraeliProject Cooperation (DIP, grant DA 1600/1-1).ReferencesAnn Bies, Mark Ferguson, Karen Katz, Robert Mac-Intyre, Victoria Tredinnick, Grace Kim, Mary AnnMarcinkiewicz, and Britta Schasberger.
1995.Bracketing guidelines for treebank ii style penn tree-bank project.
University of Pennsylvania, 97:100.David Dowty.
1988.
Type raising, functional com-position, and non-constituent conjunction.
In Cat-4This measurement is relevant only when parsing basedon our proposed annotation, and cannot be measured forparse trees based the original PTB annotation.egorial grammars and natural language structures,pages 153?197.
Springer.Kazuo Hara, Masashi Shimbo, Hideharu Okuma, andYuji Matsumoto.
2009.
Coordinate structure analy-sis with global structural constraints and alignment-based local features.
In Proceedings of the JointConference of the 47th Annual Meeting of the ACLand the 4th International Joint Conference on Natu-ral Language Processing of the AFNLP: Volume 2-Volume 2, pages 967?975.
Association for Compu-tational Linguistics.Deirdre Hogan.
2007.
Coordinate noun phrase disam-biguation in a generative parsing model.
Associa-tion for Computational Linguistics.Rodney Huddleston, Geoffrey K Pullum, et al 2002.The cambridge grammar of english.
Language.Cambridge: Cambridge University Press, pages1273?1362.Mitchell P Marcus, Mary Ann Marcinkiewicz, andBeatrice Santorini.
1993.
Building a large anno-tated corpus of english: The penn treebank.
Compu-tational linguistics, 19(2):313?330.Franc?ois Mouret.
2006.
A phrase structure approachto argument cluster coordination.
In Proceedings ofthe HPSG06 Conference, pages 247?267.
CSLI on-line Publications.Hideharu Okuma, Kazuo Hara, Masashi Shimbo, andYuji Matsumoto.
2009.
Bypassed alignment graphfor learning coordination in japanese sentences.
InProceedings of the ACL-IJCNLP 2009 ConferenceShort Papers, pages 5?8.
Association for Computa-tional Linguistics.Slav Petrov, Leon Barrett, Romain Thibaux, and DanKlein.
2006.
Learning accurate, compact, andinterpretable tree annotation.
In Proceedings ofthe 21st International Conference on ComputationalLinguistics and the 44th annual meeting of the Asso-ciation for Computational Linguistics, pages 433?440.
Association for Computational Linguistics.Masashi Shimbo and Kazuo Hara.
2007.
A discrim-inative learning model for coordinate conjunctions.In EMNLP-CoNLL, pages 610?619.76
