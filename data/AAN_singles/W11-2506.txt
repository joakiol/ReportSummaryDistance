Proceedings of the GEMS 2011 Workshop on Geometrical Models of Natural Language Semantics, EMNLP 2011, pages 52?61,Edinburgh, Scotland, UK, July 31, 2011. c?2011 Association for Computational LinguisticsAssessing Interpretable, Attribute-related Meaning Representations forAdjective-Noun Phrases in a Similarity Prediction TaskMatthias Hartung and Anette FrankComputational Linguistics DepartmentHeidelberg University{hartung,frank}@cl.uni-heidelberg.deAbstractWe present a distributional vector space modelthat incorporates Latent Dirichlet Allocationin order to capture the semantic relation hold-ing between adjectives and nouns along inter-pretable dimensions of meaning: The meaningof adjective-noun phrases is characterized interms of ontological attributes that are promi-nent in their compositional semantics.
Themodel is evaluated in a similarity predictiontask based on paired adjective-noun phrasesfrom the Mitchell and Lapata (2010) bench-mark data.
Comparing our model against ahigh-dimensional latent word space, we ob-serve qualitative differences that shed lighton different aspects of similarity conveyedby both models and suggest integrating theircomplementary strengths.1 IntroductionThis paper offers a comparative evaluation of twotypes of accounts to the compositional meaning ofadjective-noun phrases.
This comparison is embed-ded in a similarity judgement task that determinesthe semantic similarity of pairs of adjective-nounphrases.
All models we consider establish the sim-ilarity of adjective-noun pairs by measuring simi-larity between vectors representing the meaning ofthe individual adjective-noun phrases.
However, themodels we investigate differ in the type of interpreta-tion they assign to adjectives, nouns and the phrasescomposed from them.One type of approach is represented by the clas-sical vector space model (VSM) of Mitchell and La-pata (2010; henceforth: M&L).
It represents the se-mantics of adjective-noun phrases in latent seman-tic space, based on dimensions defined by bags ofcontext words.
This classical model will be com-pared against a compositional analysis of adjective-noun phrases that represents adjectives and nounsalong interpretable dimensions of meaning, i.e.
dis-crete ontological attributes such as SIZE, COLOR,SPEED, WEIGHT.
Here, lexical vectors for adjec-tives and nouns define possible attribute meanings ascomponent values; vector composition is intendedto elicit those attributes that are prominent in themeaning of the whole phrase.
For instance, a com-posed vector representation of the phrase hot pep-per is expected to yield high component values onthe dimensions TASTE and SMELL, rather than TEM-PERATURE.
The underlying relations between ad-jectives and nouns, respectively, and the attributesthey denote is captured by way of latent semantic in-formation obtained from Latent Dirichlet Allocation(LDA; Blei et al (2003)).
Thus, we treat attributesas an abstract meaning layer that generalizes overlatent topics inferred by LDA and utilize this inter-pretable layer as the dimensions of our VSM.This approach has been shown to be effectivein an attribute selection task (Hartung and Frank,2011), where the goal is to predict the most promi-nent attribute(s) ?hidden?
in the compositional se-mantics of adjective-noun phrases.
In this paper,our main interest is to assess the potential of mod-eling adjective semantics in terms of discrete, inter-pretable attribute meanings in a similarity judgementtask, as opposed to a representation in latent seman-tic space that is usually applied to tasks of this kind.52For this purpose, we rely on the evaluation dataset of M&L which serves as a shared benchmark inthe GEMS 2011 workshop.
Their similarity judge-ment task, being tailored to measuring latent simi-larity, represents a true challenge for an analysis fo-cused on discrete ontological attributes.Our results show that the latent semantic modelof M&L cannot be beaten by an interpreted anal-ysis based on LDA topic models.
However, weshow substantial performance improvements of theinterpreted analysis in specific settings with adaptedtraining and test sets that enable focused compar-ison.
An interesting outcome of our investiga-tions is that ?
using an interpreted LDA analysis ofadjective-noun phrases ?
we uncover divergences inthe notions of similarity underlying the judgementtask that go virtually unnoticed in a latent semanticVSM, while they need to be clearly distinguished inmodels focused on interpretable representations.The paper is structured as follows: After a briefsummarization of related work, Section 3 introducesControled LDA, a weakly supervised extension tostandard LDA, and explains how it can be utilized toinject interpretable meaning dimensions into VSMs.In Section 4, we describe the parameters and exper-imental settings for comparing our model to M&L?sword-based latent VSM in a similarity predictiontask.
Section 5 presents the results of this experi-ment, followed by a thorough qualitative analysis ofthe specific strengths and weaknesses of both mod-els in Section 6.
Section 7 concludes.2 Related WorkRecent work in distributional semantics has engen-dered different perspectives on how to character-ize the semantics of adjectives and adjective-nounphrases.Almuhareb (2006) aims at capturing the seman-tics of adjectives in terms of attributes they denoteusing lexico-syntactic patterns.
His approach suf-fers from severe sparsity problems and does not ac-count for the compositional nature of adjective-nounphrases, as it disregards the meaning contributed bythe noun.
It is therefore unable to perform disam-biguation of adjectives in the context of a noun.Baroni and Zamparelli (2010) and Guevara(2010) focus on how best to represent composition-ality in adjective-noun phrases considering differ-ent types of composition operators.
These worksadhere to a fully latent representation of mean-ing, whereas Hartung and Frank (2010) assign sym-bolic attribute meanings to adjectives, nouns andcomposed phrases by incorporating attributes as di-mensions in a compositional VSM.
By holding theattribute meaning of adjectives and nouns in dis-tinct vector representations and combining themthrough vector composition, their approach im-proves on both weaknesses of Almuhareb?s work.However, their account is still closely tied to Al-muhareb?s pattern-based approach in that counts ofco-occurrence patterns linking adjectives and nounsto attributes are used to populate the vector represen-tations.
These, however, are inherently sparse.
Theresulting model therefore still suffers from sparsityof co-occurrence data.Finally, Latent Dirichlet Allocation, originally de-signed for tasks such as text classification and doc-ument modeling (Blei et al, 2003), found its wayinto lexical semantics.
Ritter et al (2010) and?O Se?aghdha (2010), e.g., model selectional restric-tions of verb arguments by inducing topic distribu-tions that characterize mixtures of topics observed inverb argument positions.
Mitchell and Lapata (2009,2010) were the first to use LDA-inferred topics asdimensions in VSMs.Hartung and Frank (2011) adopt a similar ap-proach, by embedding LDA into a VSM foradjective-noun meaning composition, with LDAtopics providing latent variables for attribute mean-ings.
That is, contrary to M&L, LDA is used toconvey information about interpretable semantic at-tributes rather than latent topics.
In fact, Hartungand Frank (2011) are able to show that ?injecting?topic distributions inferred from LDA into a VSMalleviates sparsity problems that persisted with thepattern-based VSM of Hartung and Frank (2010).Baroni et al (2010) highlight two strengths ofVSMs that incorporate interpretable dimensions ofmeaning: cognitive plausibility and effectiveness inconcept categorization tasks.
In their model, con-cepts are characterized in terms of salient proper-ties and relations (e.g., children have parents, grassis green).
However, their approach concentrates onnouns.
Open questions are (i) whether it can be ex-tended to further word classes, and (ii) whether the53interpreted meaning layers are interoperable acrossword classes, to cope with compositionality.
Thepresent paper extends their work by offering a testcase for an interpretable, compositional VSM, ap-plied to adjective-noun composition with attributesas a shared meaning layer.
Moreover, to our knowl-edge, we are the first to expose such a model to apairwise similarity judgement task.3 Attribute Modeling based on LDA3.1 Controled LDAThis section introduces Controled LDA (C-LDA), aweakly supervised variant of LDA.
We use C-LDAto model attribute information that pertains to ad-jectives and nouns individually.
This information is?injected?
into a vector-space framework as a ba-sis for computing the attributes that are prominentin compositional adjective-noun phrases.In its original statement, LDA is a fully unsu-pervised process that estimates topic distributionsover documents ?d and word-topic distributions ?twith topics represented as hidden variables.
Esti-mating these parameters on a document collectionyields topic proportions P (t|d) and topic distribu-tions P (w|t) that can be used to compute a smoothdistribution P (w|d) as in (1), where t denotes a la-tent topic, w a word and d a document in the corpus.P (w|d) =?tP (w|t)P (t|d) (1)While the generative story underlying both mod-els is identical, C-LDA extends standard LDA by?implicitly?
taking supervised category informationinto account.
This allows for linking latent topics tointerpretable semantic attributes.
The idea is to col-lect pseudo-documents in a controlled way such thateach document conveys semantic information aboutone specific attribute.
The pseudo-documents areselected along syntactic dependency paths linkingthe respective attribute noun to meaningful contextwords (adjectives and nouns).
A corpus consistingof the two sentences in (2), e.g., yields a pseudo-document for the attribute noun SPEED containingcar and fast.
(2) What is the speed of this car?
The machineruns at a very fast speed.Note that, though we are ultimately interestedin triples between attributes, adjectives and nounsthat are conveyed by the compositional semanticsof adjective-noun phrases, C-LDA is only exposedto binary tuples between attributes and adjectives ornouns, respectively.
This is in line with the findingsof Hartung and Frank (2010), who obtained sub-stantial performance improvements by splitting thetriples into separate binary relations.3.2 Embedding C-LDA into a VSMThe main difference of C-LDA compared to stan-dard LDA is that the estimated topic proportionsP (t|d) of the former will be highly attribute-specific, and similarly so for the topic distributionsP (w|t).
We experiment with two variants of VSMsthat differ in the way they integrate attribute infor-mation inferred from C-LDA, denoted as C-LDA-Aand C-LDA-T.In C-LDA-A, the dimensions of the space are in-terpretable attributes.
The vector components re-lating a target word w to an attribute a are set toP (w|a).
This probability is obtained from C-LDAby constructing the pseudo-documents as distribu-tional fingerprints of the respective attribute, as de-scribed in Section 3.1 above:P (w|a) ?
P (w|d) =?tP (w|t)P (t|d) (3)C-LDA-T capitalizes on latent topics as dimen-sions; the vector components are set to the topic pro-portions P (w|t) as directly obtained from C-LDA.14 Parameters and Experimental SettingsData.
Our experiments are based on the adjective-noun section of M&L?s 2010 evaluation data set2.
Itconsists of 108 pairs of adjective-noun phrases thatwere rated for similarity by human judges.1The ?topics as dimensions?
approach has also been usedby Mitchell and Lapata (2010) for dimensionality reduction.
Intheir word space model, however, this setting leads to a decreasein performance on adjective-noun phrases.
Therefore, we donot compare ourselves to this instantiation of their model in thispaper.2Available from: http://homepages.inf.ed.ac.uk/s0453356/share54Models.
We contrast the two LDA-based models(i, ii) C-LDA-A and C-LDA-T with two standardVSMs: (iii) a re-implementation of the latent VSMof M&L and (iv) a dependency-based VSM (De-pVSM) which relies on dependency paths that con-nect the target elements and attribute nouns in localcontexts.
The paths are identical to the ones usedfor constructing pseudo-documents in (i) and (ii).Thus, DepVSM relies on the same information asC-LDA-A and C-LDA-T, without capitalizing on thesmoothing power provided by LDA.In the C-LDA models, we experiment with severaltopic number settings.
Depending on the number ofattributes |A| contained in the training material (seebelow), we train one model instance for each topicnumber in the range from 0.5 ?
|A| to 2 ?
|A|.
For ourLDA implementations, we use MALLET (McCal-lum, 2002).
We run 1000 iterations of Gibbs sam-pling with hyperparameters set to the default values.Training data.
For C-LDA-A, C-LDA-T and De-pVSM we apply two different training scenarios:In the first setting, we collect pseudo-documentsinstantiating 262 attribute nouns that are linked toadjectives by an attribute relation in WordNet(Fellbaum, 1998).
The topic distributions inducedfrom this data cover the broadest space of attributemeanings we could produce from WordNet3.
In asecond setting, we assume the presence of an ?or-acle?
that confines the training data to a subset of33 attribute nouns that are linked to those adjectivesthat actually occur in the M&L test set, to allow fora focused evaluation.
In both C-LDA variants, alladjectives and nouns occurring at least five times inthe pseudo-documents become target elements in theVSM.
The pseudo-documents are collected alongdependency paths extracted from section 2 of thepukWaC corpus (Baroni et al, 2009).
The same set-tings are used for training the DepVSM model.As the M&L model is not intended to reflect at-tribute meaning, the training data for this model re-mains constant.
Like M&L, we set the target el-ements of this model to all types contained in thecomplete evaluation data set (including nouns, ad-3Note that in Hartung and Frank (2011) only a subset ofthese attributes, mainly those characterized as properties inWordNet, could be successfully modeled, at overall moderateperformance levels.jectives and verbs) and select the 2000 context wordsthat co-occur most frequently with these targets inpukWaC 2 as the dimensions of the space.Filters on test set.
Given the different types of?semantic gist?
of the models described above, weexpect that the LDA models perform best on thosetest pairs that involve attributes known to the model.To test this expectation, we compile a restricted testset containing 43 pairs (adj1 n1, adj2 n2) whereboth adj1 and adj2 bear an attribute meaning accord-ing to WordNet.Composition operators.
In our experiments, weuse a subset of the operators proposed by Mitchelland Lapata (2010) to obtain a compositional repre-sentation of adjective-noun phrases from individualvectors: vector multiplication (?
; best operator inM&L?s experiments on adjective-noun phrases) andvector addition (+).
Besides, in order to assess thecontribution of individual vectors in the composi-tion process, we experiment with two ?compositionsurrogates?
by taking the individual adjective (ADJ-only) or noun vector (N-only) as the result of thecomposition process.Evaluating the models.
The models describedabove are evaluated against the human similarityjudgements data provided by Mitchell and Lapata(2010) as follows: We compute the cosine similar-ity between the composed vectors representing theadjective-noun phrases in each test pair.
Next, wemeasure the correlation between the model scoresand the human judgements in terms of Spearman?s?, where each human rating is treated as an indi-vidual data point.
The correlation coefficient finallyreported is the average over all instances4 of onemodel.
For completeness, we also report the corre-lation score of the best model instance and the stan-dard deviation over all model instances.5 Discussion of ResultsResults on complete test set.
Table 1 displays theresults achieved by the VSMs based on C-LDA and4In fact, only those model instances resulting in a significantcorrelation with the human judgements (p < 0.05) are takeninto account.
This way, we eliminate both inefficient and overlyoptimistic model instances.55+ ?
ADJ-only N-onlyavg best ?
avg best ?
avg best ?
avg best ?262attrs C-LDA-A 0.19 0.25 0.05 0.15 0.20 0.04 0.17 0.23 0.04 0.11 0.23 0.06C-LDA-T 0.19 0.24 0.02 0.28 0.31 0.02 0.20 0.24 0.02 0.18 0.24 0.03M&L 0.21 0.34 0.19 0.27DepVSM -0.09 -0.09 -0.14 -0.0833attrs C-LDA-A 0.23 0.27 0.02 0.21 0.24 0.01 0.27 0.29 0.01 0.17 0.22 0.02C-LDA-T 0.21 0.28 0.03 0.14 0.23 0.04 0.22 0.27 0.03 0.10 0.21 0.06M&L 0.21 0.34 0.19 0.27DepVSM 0.21 0.20 0.27 0.19Table 1: Correlation coefficients (Spearman?s ?)
for different training sets, complete test set+ ?
ADJ-only N-onlyavg best ?
avg best ?
avg best ?
avg best ?262attrs(filtered) C-LDA-A 0.22 0.31 0.07 0.12 0.30 0.11 0.18 0.30 0.08 0.17 0.28 0.07C-LDA-T 0.25 0.30 0.03 0.26 0.35 0.04 0.24 0.29 0.04 0.19 0.23 0.04M&L 0.38 0.40 0.24 0.43DepVSM 0.08 -0.09 0.06 -0.0733attrs(filtered) C-LDA-A 0.29 0.32 0.02 0.31 0.36 0.02 0.34 0.38 0.02 0.09 0.18 0.04C-LDA-T 0.26 0.36 0.05 0.14 0.30 0.09 0.28 0.38 0.07 0.03 0.18 0.08M&L 0.38 0.40 0.24 0.43DepVSM 0.34 0.32 0.35 0.19Table 2: Correlation coefficients (Spearman?s ?)
for different training sets and filtered test setsthe M&L word space model on the full adjective-noun test set.
The table is split into an upper and alower part containing the different results obtainedfrom training on 262 and 33 attributes, respectively.Each multicolumn shows the performance achievedby one of the different composition operators pre-sented in Section 4, as well as results obtained frompredicting similarity on the basis of raw adjective(ADJ-only) and noun (N-only) vectors.First and foremost, we observe best overall per-formance for the M&L model when combined withmultiplicative vector composition (?
= 0.34), eventhough the best results for this setting reported inM&L (2010) (?
= 0.46) cannot be reproduced.Nevertheless, the C-LDA models show a consid-erable performance improvement when the trainingmaterial is constrained to appropriate attributes byan oracle (cf.
Sect.
4).
Another interesting obser-vation is that the individual adjective and noun vec-tors produced by M&L and the C-LDA models, re-spectively, show diametrically opposed performance(cf.
3rd and 4th multicolumn in Table 1).More in detail, C-LDA-A achieves relative im-provements across all composition operators whencomparing the 33-ATTR to the 262-ATTR setting.Contrasting C-LDA-A and C-LDA-T, the latter isclearly more effective on the larger training set, es-pecially in combination with the ?
operator (?
=0.28).
This might be due to the intersective characterof multiplication, which requires densely populatedcomponents in both the adjective and the noun vec-tor.
This requirement meets best with the C-LDA-Tmodel as long as the number of topics provided islarge.
The + operator, on the other hand, combinesbetter with C-LDA-A.
In the 33-ATTR setting, thiscombination even outperforms vector addition un-der the M&L model.
Generally, C-LDA-A performsbetter on the smaller training set, where it leaves C-LDA-T behind in every configuration.
This high-lights that an interpretable, attribute-related meaninglayer generalizing over latent topics can be effectiveif a small, discriminative set of attributes is availablefor training.
Otherwise, C-LDA-T seems to be morepowerful for the present similarity judgement task.Analyzing the performance of the compositionsurrogates ADJ-only and N-only in the restricted 33-ATTR setting reveals an interesting twist in the qual-ity of adjective vs. noun vectors: While M&L gen-56erally yields better results on noun vectors alone (ascompared to adjective vectors), C-LDA-A clearlyoutperforms M&L in predicting similarity based onadjective meanings in isolation.
In this configura-tion, M&L is also outperformed by the (very strong)dependency baseline which is, in turn, only slightlybeaten by C-LDA-A in its best configuration.
Infact, it is the ADJ-only surrogate under the C-LDA-A model in its best setting (?
= 0.29) that comesclosest to the overall best-performing M&L model.This indicates that modeling attributes in the latentsemantics of adjectives can be informative for thepresent similarity prediction task.
The poor qualityof the noun vectors, however, limits the overall per-formance of the C-LDA models considerably.Results on filtered test set.
As can be seen fromTable 2, our expectation that C-LDA-A and C-LDA-T should benefit from limiting the test set toinstances related to attribute meanings is largelymet.
We observe overall improvement of correla-tion scores; also the characteristics of the individualmodels observed in Table 1 remain unchanged.However, M&L benefits from filtering as well,and in some configurations, e.g.
under vector addi-tion, the relative improvement is even bigger for thelatent word space models.
This shows that M&Land our C-LDA models are not fully complemen-tary, i.e.
some aspects of attribute similarity are alsocovered by latent models.Neverthelesss, the adjective/noun twist observedfor individual vector performance is corroborated:C-LDA-A?s adjective vectors outperform those ofM&L by ten points (33 attributes, filtered setting;compared to six points on the complete test set),whereas the performance of the noun vectors dropseven further.
Again, the DepVSM baseline performsvery strong on the adjective vectors in isolation,which clearly underlines that our dependency-basedcontext selection procedure is effective.
On the otherhand, the individual noun vectors produced by M&Leven yield the best overall result on the filtered testdata, thus outperforming both composition methods.Differences in adjective and noun vectors.
In or-der to highlight qualitative differences of the indi-vidual adjective and noun vectors across the variousmodels, we analyzed their informativeness in termsof entropy.
The intuition is as follows: The lower the262 attrs 33 attrsavg ?
avg ?C-LDA-A (JJ) 1.20 0.48 0.83 0.27C-LDA-A (NN) 1.66 0.72 1.23 0.46C-LDA-T (JJ) 0.92 0.04 0.50 0.04C-LDA-T (NN) 1.10 0.06 0.60 0.02M&L (JJ) 2.74 0.91 2.74 0.91M&L (NN) 2.96 0.33 2.96 0.33DepVSM (JJ) 0.48 0.61 0.65 0.32DepVSM (NN) 0.38 0.67 0.96 0.21Table 3: Average entropy of individual adjective andnoun vectors across different modelsentropy exhibited by a vector, the more pronouncedare its most prominent components.
On the contrary,high entropy indicates a rather broad, less accen-tuated distribution of the probability mass over thevector components (cf.
Hartung and Frank (2010)).The results of this analysis are displayed in Ta-ble 3.
With regard to the C-LDA models, we observelower entropy in adjective vectors compared to nounvectors across both training settings, which corre-sponds to their relative performance in the similar-ity prediction task.
This indicates that C-LDA cap-tures the relation between adjectives and attributesin a very pronounced way, and that this informationproves valuable for similarity prediction.The DepVSM model shows inconsistent resultswith regard to the different training sets.
While thepattern observed for the C-LDA models is confirmedon the limited training set, training on the full set of262 attributes results in more accentuated noun vec-tors.
Given the huge standard deviations, however,we suppose that these figures are not very reliable.5The correspondence between lower entropy andbetter performance we could observe for C-LDA-A and C-LDA-T is, however, not confirmed by theM&L word space model, as their adjective vectorsexhibit lower entropy on average6, while they per-sistently underperform relative to the noun vectors5In fact, unlike the C-LDA models and M&L, DepVSMfaces severe sparsity problems on the large training set, as be-comes evident from the average total frequency mass per vector:Noun vectors accumulate 704 cooccurrence counts over 262 di-mensions on average, while adjective vectors are populated with1555 counts on average (652 vs. 1052 counts over 33 dimen-sions on the small training set).6The entropy values of M&L are not directly comparable tothose of the C-LDA models and DepVSM; M&L entropies aregenerally higher due to the higher dimensionality of the model.57(cf.
Tables 1 and 2).
Note, however, that the en-tropy values of individual adjective vectors dispersewidely around the mean (?=0.91).
This suggeststhat a considerable proportion of M&L?s adjectivevectors is rather evenly distributed.Analyzing the individual performance of nounvectors in terms of entropy is less conclusive.
Whilethe noun vectors consistently exhibit relatively highentropy, their varying performance across the dif-ferent models cannot be explained.
We hypothesizethat the characteristics of the different models mightbe more decisive instead: Apparently, attributes asan abstract meaning layer are appropriate for mod-eling the contribution of adjectives to phrase simi-larity, whereas the contribution of nouns seems tobe captured more effectively by M&L-like distribu-tions along bags of context words.6 Error AnalysisIn order to gain deeper insight into the strengthsand weaknesses of C-LDA-A and M&L, weextracted the ten most similar/dissimilar pairs(+Sim/?SimC-LDA-A/M&L; cf.
Table 4) accordingto system predictions, as well as the ten pairson which system and human raters show high-est/lowest agreement in terms of similarity scores(+Agr/?AgrC-LDA-A/M&L; cf.
Table 5), for the best-performing model instance of C-LDA-A and M&Lin the unfiltered 33-ATTR setting, respectively.All pairs in +SimC-LDA-A and +SimM&L exhibitmatching attributes.
+SimC-LDA-A contains two pairsinvolving contrastive attribute values (vs. four in+SimM&L): long period ?
short time, hot weather?
cold air.
Obviously, C-LDA-A is not prepared torecognize this type of dissimilarity, as it does notmodel the semantics and orientation of attribute val-ues, and so assigns overly optimistic similarity rates.While this deficiency is explained for C-LDA, it isunexpected for M&L, where in +SimM&L we findpairs such as old person ?
elderly lady with similar-ity ratings that are almost identical to antonymouspairs discussed above, such as high price ?
low cost.We further observe a striking difference regardingoverall similarity ratings in both systems: We findhigh scores of 0.88 on average within +SimC-LDA-A,as opposed to 0.52 in +SimM&L.
The differenceis less marked regarding ?Sim.
Similarly, wefind overall low average similarity rates (0.2) in+AgrM&L, whereas +AgrC-LDA-A achieves somewhathigher rates (0.27).
While all examples point to-wards dissimilarity, C-LDA-A shows more discrim-inative power, as exemplified by hot weather ?
el-derly lady (lowest rating) vs. central authority ?
lo-cal office (highest rating).
This suggests that, over-all, C-LDA-A disposes of a more discriminative se-mantic representation to judge similarity ?
which ofcourse can also go astray.The disagreement set ?AgrC-LDA-A contains theantonymous adjectives with high similarity ratingsfrom +SimC-LDA-A, of course.
We also note a highproportion (5/10) of pairs involving adjectives withvague and highly ambiguous attribute meanings,such as good, new, certain, general.
These are dif-ficult to capture, especially in combination with ab-stract noun concepts such as information, effect orcircumstance.An interesting type of similarity is represented byearly evening ?
previous day.
In this case, we ob-serve a contrast in the semantics of the nouns in-volved, while the pair exhibits strong similarity onthe attribute level, which is reflected in the system?ssimilarity score.
This type of similarity is reminis-cent of relational analogies investigated in Turney(2008).
A related example is rural community ?
fed-eral assembly.
Unlike the human judges, C-LDApredicts high similarity for both pairs.The examples given in ?AgrM&L, by contrast,clearly point to a lack in capturing adjective seman-tics, with misjudgements such as effective way ?
effi-cient use, large number ?
vast amount or large quan-tity ?
great majority.Turning to ?AgrC-LDA-A again, we find 9/10 itemsexhibit values greater than 0.67 (average: 0.78).This means the model yields a high number offalse positives in rating similarity (with explanationsand some reservations just discussed).
All items in?AgrM&L, by contrast, have values below 0.36 (av-erage: 0.16).
That is, we again observe that thismodel assigns lower similarity scores.
This is con-firmed by a comparative analysis of average sim-ilarity scores on the entire test set: C-LDA-A;+yields an average similarity of 0.48 (?=0.05) overall instances, while M&L;?
yields 0.16 on average(?=0.16).
The human ratings (after normalizationto the scale from 0 to 1) amount to 0.39 (?=0.26).58SIMILARITYC-LDA-A; + M&L; ?+Simlong period ?
short time 0.95 important part ?
significant role 0.66hot weather ?
cold air 0.95 certain circumstance ?
particular case 0.60different kind ?
various form 0.91 right hand ?
left arm 0.56better job ?
good place 0.89 long period ?
short time 0.55different part ?
various form 0.88 old person ?
elderly lady 0.54social event ?
special circumstance 0.88 high price ?
low cost 0.54better job ?
good effect 0.88 black hair ?
dark eye 0.48similar result ?
good effect 0.85 general principle ?
basic rule 0.44social activity ?
political action 0.82 special circumstance ?
particular case 0.43early evening ?
previous day 0.80 hot weather ?
cold air 0.43?Simearly stage ?
long period 0.11 old person ?
right hand 0.03northern region ?
early age 0.11 new information ?
further evidence 0.03earlier work ?
early evening 0.11 early stage ?
dark eye 0.01elderly woman ?
black hair 0.10 practical difficulty ?
cold air 0.01practical difficulty ?
cold air 0.08 left arm ?
elderly woman 0.01small house ?
old person 0.07 hot weather ?
elderly lady 0.00left arm ?
elderly woman 0.06 national government ?
cold air 0.00hot weather ?
further evidence 0.06 black hair ?
right hand 0.00dark eye ?
left arm 0.05 hot weather ?
further evidence 0.00national government ?
cold air 0.03 better job ?
economic problem 0.00Table 4: Similarity scores predicted by optimal C-LDA-A and M&L model instances; 33-ATTR settingAGREEMENTC-LDA-A; + M&L; ?+Agrmajor issue ?
american country 0.29 similar result ?
good effect 0.29efficient use ?
little room 0.29 small house ?
important part 0.14economic condition ?
american country 0.29 national government ?
new information 0.12public building ?
central authority 0.29 major issue ?
social event 0.26northern region ?
industrial area 0.28 new body ?
significant role 0.11new life ?
economic development 0.42 social event ?
special circumstance 0.25new body ?
significant role 0.13 economic development ?
rural community 0.32hot weather ?
elderly lady 0.13 new technology ?
public building 0.18social event ?
low cost 0.13 high price ?
short time 0.10central authority ?
local office 0.44 new body ?
whole system 0.24?Agrearly evening ?
previous day 0.80 effective way ?
efficient use 0.29rural community ?
federal assembly 0.67 federal assembly ?
national government 0.24new information ?
general level 0.68 vast amount ?
high price 0.10similar result ?
good effect 0.85 different kind ?
various form 0.24better job ?
good effect 0.88 vast amount ?
large quantity 0.36social event ?
special circumstance 0.88 large number ?
vast amount 0.31better job ?
good place 0.89 older man ?
elderly woman 0.00certain circumstance ?
particular case 0.22 earlier work ?
early stage 0.00hot weather ?
cold air 0.95 large number ?
great majority 0.09long period ?
short time 0.95 large quantity ?
great majority 0.04Table 5: Test pairs showing high and low agreement between systems and human raters, together with system similarityscores as obtained from optimal model instances; 33-ATTR setting59While these means are not fully comparable as theyare the result of different composition operations,the standard deviations suggest that M&L?s similar-ity predictions are dispersed over a larger range ofthe scale, while the C-LDA scores show only smallvariation.
This missing spread might be one of thereasons for C-LDA?s lower performance.In summary, we note one obvious shortcoming inthe C-LDA-A model, in that it does not capture dis-similarity due to distinct contrastive meanings of at-tribute values in cases of similarity on the noun andattribute levels.
With its focus on attribute seman-tics, however, C-LDA-A is able to capture similar-ity due to relational analogies, as in early evening?
previous day (0.8), whereas the latent model ofM&L is clearly noun-oriented, and thus predicts alow similarity of 0.2 for this pair.We conclude that the proposed attribute analysisof adjective-noun pairs implements an inherently re-lational form of similarity.
Noun semantics is cap-tured only indirectly, through the range of attributesfound relevant for the noun.
The current model alsofully neglects the meaning of scalar attribute values.Whether a more comprehensive analysis of inter-preted adjective-noun meanings is able to succeedin a paired similarity prediction task is an open issueto be explored in future work.7 ConclusionIn this paper, we presented a distributional VSMthat incorporates latent semantic information char-acterizing ontological attributes in the meaning ofadjective-noun phrases, as obtained from C-LDA, aweakly supervised variant of LDA.
Originally de-signed for an attribute selection task (Hartung andFrank, 2011), this model faces a true challenge whenevaluated in a pairwise similarity judgement taskagainst a high-dimensional word space model, suchas M&L?s VSM.
In fact, our model is unable to com-pete with M&L even in its best configurations.Thorough analysis reveals, however, that the qual-ity of individual adjective and noun vectors is dia-metric across the two models: C-LDA, capitalizingon interpretable ontological dimensions, produceseffective adjective vectors, whereas its noun repre-sentations lag behind.
The inverse situation is ob-served for the word-based latent VSM of M&L.One qualification is in order, though: In its cur-rent state, the C-LDA model relies on an ?oracle?that pre-selects the attributes involved in the test setfor the model to be trained on.
Although one couldargue that tailoring the context words to the targetwords has a similar effect in our re-implementationof M&L, interferences of this kind are not desirablein principle.
Future work will need to explore inmore detail possible attribute ranges with regard totheir usefulness for different tasks and data sets.Our comparative investigaton of the specificstrengths and weaknesses of the models indicatesthat they focus on different aspects of similarity:M&L, possibly due to its higher and more discrim-inative dimensionality, tends to produce more ef-ficient noun vectors.
Overall, this model accordsbetter with human similarity judgements across di-verse aspects of similarity than the more focusedattribute-oriented LDA models.
The C-LDA mod-els focus on a specific, interpretable meaning di-mension shared by adjectives and nouns, with a ten-dency for stronger modeling capacity for adjectives.They are currently not prepared to capture dissimi-larity in cases of contrastive attribute values, whileon the positive side, they effectively cope with re-lational analogies, both with similar and dissimilarnoun meanings.Our findings suggest that adding more discrimina-tive power to the noun representations and scalar in-formation about attribute values to the adjective vec-tors might be beneficial.
Further research is neededto investigate how to combine interpretable seman-tic representations tailored to specific relations, ascaptured by C-LDA, with M&L-like bag-of-wordsrepresentations in a single distributional model.Applying interpreted models to the present simi-larity rating task will still remain a challenge, as itinvolves mapping diverse mixtures of aspects andgrades of similarity to human judgements.
How-ever, if the performance of an integrated model cancompete with a purely latent semantic analysis, thisoffers a clear advantage for more general tasks thatrequire linking phrase meaning to symbolic knowl-edge bases such as (multilingual) ontologies, or forapplication scenarios that involve discrete seman-tic labels, such as text classification based on topicmodeling (Blei et al, 2003) or fine-grained namedentity classification (Ekbal et al, 2010).60ReferencesAbdulrahman Almuhareb.
2006.
Attributes in LexicalAcquisition.
Ph.D. Dissertation, Department of Com-puter Science, University of Essex.Marco Baroni and Roberto Zamparelli.
2010.
Nounsare vectors, adjectives are matrices: Representingadjective-noun constructions in semantic space.
InProceedings of the 2010 Conference on Empiri-cal Methods in Natural Language Processing, EastStroudsburg, PA, pages 1183?1193.Marco Baroni, Silvia Bernardini, Adriano Ferraresi, andEros Zanchetta.
2009.
The WaCky Wide Web: A Col-lection of Very Large Linguistically Processed Web-crawled Corpora.
Journal of Language Resources andEvaluation, 43(3):209?226.Marco Baroni, Brian Murphy, Eduard Barbu, and Mas-simo Poesio.
2010.
Strudel.
A Corpus-based Seman-tic Model based on Properties and Types.
CognitiveScience, 34:222?254.David M. Blei, Andrew Ng, and Michael Jordan.
2003.Latent Dirichlet Allocation.
JMLR, 3:993?1022.Asif Ekbal, Eva Sourjikova, Anette Frank, and SimonePonzetto.
2010.
Assessing the Challenge of Fine-grained Named Entity Recognition and Classification.In Proceedings of the ACL 2010 Named Entity Work-shop (NEWS), Uppsala, Sweden.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
MIT Press, Cambridge,Mass.Emiliano Guevara.
2010.
A regression model ofadjective-noun compositionality in distributional se-mantics.
In Proceedings of the 2010 Workshop onGEometrical Models of Natural Language Semantics,Stroudsburg, PA. Association for Computational Lin-guistics.Matthias Hartung and Anette Frank.
2010.
A StructuredVector Space Model for Hidden Attribute Meaning inAdjective-Noun Phrases.
In Proceedings of the 23rdInternational Conference on Computational Linguis-tics (COLING), Beijing, China, August.Matthias Hartung and Anette Frank.
2011.
ExploringSupervised LDA Models for Assigning Attributes toAdjective-Noun Phrases.
In Proceedings of the 2011Conference on Empirical Methods in Natural Lan-guage Processing, Edinburgh, UK.Andrew Kachites McCallum.
2002.
MAL-LET: A machine learning for language toolkit.http://mallet.cs.umass.edu.Jeff Mitchell and Mirella Lapata.
2008.
Vector-basedModels of Semantic Composition.
In Proceedings ofACL-08: HLT, pages 236?244, Columbus, Ohio, June.Jeff Mitchell and Mirella Lapata.
2009.
Language Mod-els Based on Semantic Composition.
In Proceedingsof the 2009 Conference on Empirical Methods in Nat-ural Language Processing, Singapore, August 2009,pages 430?439, Singapore, August.Jeff Mitchell and Mirella Lapata.
2010.
Compositionin Distributional Models of Semantics.
Cognitive Sci-ence, 34:1388?1429.Diarmuid ?O Se?aghdha.
2010.
Latent variable modelsof selectional preference.
In Proceedings of the 48thAnnual Meeting of the Association for ComputationalLinguistics, pages 435?444, Uppsala, Sweden, July.Association for Computational Linguistics.Alan Ritter, Mausam, and Oren Etzioni.
2010.
A latentdirichlet alocation method for selectional preferences.In Proceedings of the 48th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 424?434,Uppsala, Sweden, July.
Association for ComputationalLinguistics.Peter D. Turney.
2008.
A uniform approach to analogies,synonyms, antonyms, and associations.
In Proceed-ings of the 22nd International Conference on Com-putational Linguistics (Coling 2008), pages 905?912,Manchester, UK.61
