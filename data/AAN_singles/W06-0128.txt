Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 166?168,Sydney, July 2006. c?2006 Association for Computational LinguisticsChinese Word Segmentation using Various DictionariesGuo-Wei BianDepartment of Information ManagementHuafan University, Taiwan, R.O.C.gwbian@cc.hfu.edu.twAbstractMost of the Chinese word segmentationsystems utilizes monolingual dictionaryand are used for monolingual processing.For the tasks of machine translation (MT)and cross-language information retrieval(CLIR), another translation dictionarymay be used to transfer the words ofdocuments from the source languages totarget languages.
The inconsistencies re-sulting from the two types of dictionaries(segmentation dictionary and transferdictionary) may produce some problemsfor MT and CLIR.
This paper shows theeffectiveness of the external resources(bilingual dictionary and word list) forChinese word segmentations.1 IntroductionMost of the Chinese word segmentations areused for monolingual processing.
In general, theword segmentation program utilizes the wordentries, part-of-speech (POS) information (Chenand Liu, 1992) in a monolingual dictionary,segmentation rules (Palmer, 1997), and somestatistical information (Sproat, et al, 1994).
Forthe tasks of machine translation (MT) (Bian andChen, 1998) and cross-language information re-trieval (CLIR) (Bian and Chen, 2000), anothertranslation dictionary may be used to transfer thewords of documents from the source languagesto target languages.
Because of the inconsisten-cies resulting from the two types of dictionaries(segmentation dictionary and transfer dictionary),this approach has the problems that some seg-mented words cannot be found in the transferdictionary.In this paper, we focus on the effectiveness ofthe Chinese word segmentation using differentdictionaries.
Four different dictionaries (or wordlists) and two different testing collections (testingdata) are used to evaluate the results of the Chi-nese word segmentation.2 Chinese Word Segmentation SystemThe segmentation system used only the vari-ous dictionaries in this design.
In this paper, theother possible resources (POS, segmentationrules, word segmentation guide, and statisticalinformation) are ignored to test the average per-formance between different testing collectionsspecially followed the different segmentedguidelines.The longest-matching method is adopted inthis Chinese segmentation system.
The segmen-tation processing searches for a dictionary entrycorresponding to the longest sequence of Chinesecharacters from left to right.
The system pro-vided the approximate matching to search a sub-string of the input with the entry in the dictionaryif no total matching is found.
For example, thesystem will segment the input ???????????????
as ???
??
??
??
??
?
???
which matched the term with theentry ?????
in dictionary if no entry ???
?found.2.1 Various DictionariesThe word segmentation are evaluated usingdifferent dictionaries (or word lists) and differenttesting collections (testing data).
There are fourdictionaries are used: the first one is convertedfrom an English-Chinese bilingual dictionary,and the other three are extracted from the train-ing corpora.The original English-Chinese dictionary (Bianand Chen, 1998), which containing about 67,000English word entries, is converted to a new Chi-nese-English dictionary (called CEDIC later).There are 125,719 Chinese word entries in thisCEDIC.The terms in the various training corpora (theSinica Corpus and the City University Corpus)are extracted to build the different word lists asthe segmentation dictionaries (called CKIP andCityU later).
The tokens starting with the special166characters or punctuation marks are ignored.The following shows some examples:?, ???
?, ??
?, ?, ?, ?, ?, , ?,???
?, ???
?, ?, ??
?, ?, ?, ????????
?, ?, ,?, ?, .com,Table 1 lists the number of tokens (#tokens),the number of ignored tokens (#ignored), thenumber of words (#words), and the unique words(#unique) for each dictionaries.
There are140,971 unique words are extracted from thetraining collection of Sinica Corpus, and 75,433respected to the training set of the CityUniversity Corpus.
These two dictionaries arecombined to another dictionary which containing174,398 unique words.#Tokens #Ignored #Words #UniqueCKIP (CK) 5,468,793 894,686 4,574,107 140,971CityU (CT) 1,643,421 257,032 1,386,389 75,433CKIP+CityU(CK + CT)7,112,214 1,151,718 5,960,496 174,398Table 1.
Statistical Information of the ExtractedDictionaries3 Experimental ResultsTo evaluate the results of Chinese word seg-mentations, we implement 8 experiments (runs)using the 4 different dictionaries (CEDIC, CK,CT, and CK+CT) mentioned in previous section.Two test collections (the Sinica Corpus and theCity University Corpus) are used to measure theprecision, recall, and an evenly-weighted F-measure for the Chinese words segmentations.Table 2 shows the F-measure of theexperimental results, and the Figure 1 illustratesthe comparisons of the segmentation perform-ances.
The symbol (*) indicates that the run is aclosed test, which only uses the training materialfrom the training data for the particular corpus.We can find that the larger dictionary (CK+CT)produces better segmentation results even theword lists are combined from the different re-sources (corpora) and followed the differentguidelines of word segmentations.CEDIC CK + CT CK CTCKIP 0.710 0.695 0.692* 0.611CityU 0.481 0.589 0.547 0.513*Table 2.
The F-measure results of segmentation per-formances using various dictionaries (*: closed test)00.10.20.30.40.50.60.70.8CEDIC CK+CT CK CTCKIPCityUFigure 1.
The comparison of segmentation perform-ances using various dictionaries (*: close test)3.1 Error Analysis3.1.1 Format Error of Result FileThe results file for word segmentation is re-quired to appear with one line for each sen-tence/line in the test file with words and punctua-tion separated by whitespace.
Our system makessome mistakes to produce no whitespace beforeEnglish terms and Arabic numbers, and produceno whitespace after Chinese punctuation marks.This formatting problem has made many adja-cent segmented words to be evaluated as errors.A sentence with such errors is listed below(Our Answer)?
????
??
???
?
??
??
??
???
???
???
???
???
???
???
??
?
???
9?
??
???
??
?????
???
??
?
?9+2 ?
?
?(Standard)?
????
??
?
??
?
??
??
??
???
?
??
?
??
?
??
?
??
?
??
?
??
?
??
?
??
9 ?
??
?
??
??
?
??
??
???
?
??
?
9+2 ?
?
?The standard answer of the testing collection(CityU) of the City University Corpus has 7,512sentences and 220,147 words.
The total numberof English terms, Arabic numbers, and Chinesepunctuation marks is 37,644.
Such formattingproblem makes the error rate of about 30% forthe City University Corpus.3.1.2 Different Viewpoints of SegmentationsIn our experiments, there are different wordlists extracted from the different training corpora.Some errors are produced because of the differ-167ent results of word segmentations in the trainingcorpora according to the different guidelines.Table 3 shows some different results.
The firstcolumn (CKIP) is the standard answer of the test-ing collection of Sinica Corpus, and the secondcolumn (HFUIM) is our answer.
The third andfourth columns are the words with their frequen-cies appeared in the training collections of SinicaCorpus and City University Corpus.
For exam-ple, our system produces the word ???
?, butthe standard answer of Sinica Corpus is ???
and???.
However, the word ????
appear 61times in the training collection of City UniversityCorpus.CKIP HFUIM CKIP-Training CityU-Training??
?
?
??
(0)?
?
??
?
(1839)?
(366)??
(2)?
?
??
???
(4)???
(20)?
?
??
?
(2551)?
(16694)??
(61)?
?
??
?
(32409)?
(39558)??
(714)?
?
??
?
(984)?
(7967)??
(18)?
?
??
?
(9012)?
(963)??
(35)Table 3.
The Different Segmentation Results3.1.3 Inconsistency of Word SegmentationSome errors of word segmentations are re-ported because of the inconsistency of wordsegmentations.
The following shows such aproblem.
For example, the word ????
appears317 times in the training data, but it has beentreated as two terms (???
and ???)
19 times inthe golden standard of the testing data.
(Training data)z ??
???
??
?
??
?
??
??
??
??
(Golden Standard)z ??
?
?
??
??
??
??
??
?
?z ???
??
??
?
?
?
?
??
?
?z ?
?
??
???
?
??
??
?
????
?
??
?
?
??
??
???
??
?
?4 ConclusionIn this paper, we discuss the effectiveness ofthe Chinese word segmentation using variousdictionaries.
In the experimental results, we canfind that the larger dictionary will produce bettersegmentation results even the word lists arecombined from the different resources (corpora)and followed the different guidelines of wordsegmentations.
Some results show that the ex-ternal resource (e.g., the bilingual dictionary) canperform the task of Chinese word segmentationbetter than the monolingual dictionary whichextracted from the training corpus.ReferenceBian, G.W.
and Chen, H.H.
(2000).
"Cross LanguageInformation Access to Multilingual Collections onthe Internet."
Journal of American Society for In-formation Science & Technology (JASIST), SpecialIssue on Digital Libraries, 51(3), 2000, 281-296.Bian, G.W.
and Chen, H.H.
(1998).
"IntegratingQuery Translation and Document Translation in aCross-Language Information Retrieval System.
"Machine Translation and the Information Soap(AMTA ?98), D. Farwell, L Gerber, and E.
Hovy(Eds.
), Lecture Notes in Computer Science, Vol.1529, Springer-Verlag, pp.
250-265, 1998Chen, K.J and Liu, S.H (1992), ?word identificationfor Mandarin Chinese sentences?
Proceedings ofthe 14th conference on Computational linguistics,pp.
101-107, France, 1992Palmer, D. (1997), ?A trainable rule-based algorithmfor word segmentation?, Proceeding of ACL'97,321-328, 1997.Sproat, R., et al (1994) ?A Stochastic Finite-StateWord-Segmentation Algorithm for Chinese?, Pro-ceeding of 32nd Annual Meeting of ACL, New Mex-ico, pp.
66-73.168
