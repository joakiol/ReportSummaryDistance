Probabilistic named entity verificationYi-Chung Lin and Peng-Hsiang HungAdvanced Technology Center, Computer and Communications Laboratories,Industrial Technology Research Institute, Taiwan{lyc,phhung}@itri.org.twAbstractNamed entity (NE) recognition is an impor-tant task for many natural language applica-tions, such as Internet search engines,document indexing, information extractionand machine translation.
Moreover, in ori-ental languages (such as Chinese, Japaneseand Korean), NE recognition is even moreimportant because it significantly affects theperformance of word segmentation, the mostfundamental task for understanding the textsin oriental languages.
In this paper, a prob-abilistic verification model is designed forverifying the correctness of a named entitycandidate.
This model assesses the confi-dence level of a candidate not only accord-ing to the candidate?s structure but also ac-cording to its context.
In our design, theclues for confidence measurement are col-lected from both positive and negative ex-amples in the training data in a statisticalmanner.
Experimental results show that theproposed method significantly improves theF-measure of Chinese personal name recog-nition from 86.5% to 94.4%.IntroductionNamed entity (NE) recognition (or proper namerecognition) is a task to find the entities of per-son, location, organization, date, time, percent-age and monetary value in text documents.
It isan important task for many natural languageapplications, such as Internet search engines,document indexing, information extraction andmachine translation.
Moreover, in oriental lan-guages (such as Chinese, Japanese and Korean),NE recognition is even more important becauseit significantly affects the performance of wordsegmentation, the most fundamental task forunderstanding the texts in oriental languages.Therefore, a high-accuracy NE recognitionmethod is highly demanded for most naturallanguage applications in various languages.There are two major approaches to NErecognition: the handcrafted approach (Grish-man, 1995) and the statistical approach (Bikel,1997; Chen, 1998; Yu, 1998).
In the first ap-proach, a system usually relies on a large num-ber of handcrafted rules.
This kind of systemscan be rapid prototyped but are hard to scale up.In fact, there will be numerous exceptions formost handcrafted rules.
It is generally expensiveand impossible to code for every exception wecan imagine, not to mention those exceptions weare not able to think of.
Another serious problemwith the handcrafted approach is that systemsare hard to be ported across different domainsand different languages.
Porting a handcraftedsystem usually means rewriting all its rules.Therefore, the statistical approach is becomingmore and more popular because of its cost-effectiveness in scaling up and porting systems.In general, the statistical approach to NErecognition can be viewed as a two-stage proc-ess.
First, according to dictionaries and/or pat-tern matching rules, the input text is tokenizedinto tokens.
Each token may be a word or an NEcandidate which can consist of more than oneword.
Then, the most likely token sequence isselected according to a statistical model, such asMarkov model (Bikel, 1997; Yu, 1998) ormaximum entropy model (Borthwick, 1999).Although, the statistical NE recognition is muchmore scalable and portable, its performance isstill not satisfactory.
The insufficient cover-age/precision of pattern matching rules andunknown words are the major sources of errors.Furthermore, the role of the statistical model isto assess the relative possibilities of all possibletoken sequences and select the most probableone.
The scores obtained from the statisticalmodel can be used for a comparison of compet-ing token sequences, but not for an assessmentof the probability that a spotted named entity iscorrect.To reduce the recognition errors, we pro-pose a probabilistic verification model to verifythe correctness of a named entity.
This modelassesses the confidence level of a named entitycandidate not only according to the candidate?sstructure but also according to its contexts.
Inour design, the clues for confidence measure-ment are collected from both positive and nega-tive examples in the training data.
Therefore, theconfidence measure has strong discriminantpower for judging the correctness of a namedentity.
In the experiments of Chinese personalname recognition, the proposed verificationmodel increases the F-measure from 86.5% to94.4%, which corresponds to 58.5% error re-duction rate, where ?error rate?
is defined as?100% F-measure?
?.1.
Named Entity VerificationAs mentioned before, there are several kinds ofnamed entities, including person, location, or-ganization, date, time, percentage and monetaryvalue.
In the following description, we use thetask of verifying Chinese personal name as anexample.
However, our proposed method is alsoapplicable on verifying other kinds of namedentities in different languages.Before introducing our approach, we firstdescribe the notations that will be used.
In thisproposal, a random variable is written with aboldface italic letter.
An outcome of a randomvariable is written with the same italic letter butin normal face.
For example, an outcome of therandom variable o is denoted as o .
If there isno confusion, we usually use ( )P o to denotethe probability ( )P o=o .
A symbol sequence?
1, , nx x" ?
is denoted as ?
1nx ?.
Likewise, ?
,,1Y nYx ?denotes the sequence ?,1 ,, ,Y Y nx x" ?.The task of verifying a named entity can-didate is viewed as making an acceptance orrejection decision according to the text segmentconsisting of the candidate and its context.Without loss of generality, a text segment isconsidered as an outcome of the random vector, , ,,1 ,1 ,1[ , , ]L x C y R zL C R=O o o o .
The outcome of each ran-dom variable in O is one basic element of text.In Chinese, the basic elements of text are Chine-se characters.
However, in English, the basicelements are English words.
Figure 1 shows anexample of a text segment in which the size ofthe candidate to be verified is 3 (i.e., consists ofthree Chinese characters) and the sizes of its leftcontext and right context are set to 2 (i.e., twoChinese characters).Figure 2 depicts the flowchart of our veri-fication approach.
First, the candidate in theinput text segment is parsed by a predefinedgrammar.
If the candidate is ill-formed (i.e., failFigure 1: Example of a text segment.CandidateParsingConfidenceMeasurementIll-formed?
Yes RejectNocm ?< Yes RejectNoAcceptTextSegmentFigure 2: Flowchart of the verificationmethod.shi,1Lozhangmayingjiubiaoshi,2Lo ,1Co ,2Co ,3Co ,1Ro ,2RoLeft Context Right ContextCandidateto be parsed), it will be rejected immediately.Otherwise, the text segment is passed to theconfidence measurement module to assess theconfidence level that the candidate in the textsegment is to be a named entity.
If the confi-dence measure is less than a predefined thresh-old, the candidate will be rejected.
Otherwise, itwill be accepted.2.
Confidence MeasurementThe basic idea of our approach is to formulatethe confidence measurement problem as theproblem of hypothesis testing.
The null hypothe-sis 0H in which the candidate is a name istested against the alternative hypothesis 1H inwhich the candidate is not a name.
According toNeyman-Pearson Lemma, an optimal hypothesistest involves the evaluation of the following loglikelihood ratio:, , ,,1 ,1 ,1, , ,,1 ,1 ,1 0, , ,,1 ,1 ,1 1, , ,,1 ,1 ,1 0, , ,,1 ,1 ,1 1( , , )( , , | )log ( , , | )log ( , , | )log ( , , | )L x C y R zL C RL x C y R zL C RL x C y R zL C RL x C y R zL C RL x C y R zL C RLLR o o oP o o o HP o o o HP o o o HP o o o H==?
(1)where , , ,,1 ,1 ,1 0( , , | )L x C y R zL C RP o o o H is the likelihood ofthe candidate and its left and right contextsgiven the hypothesis that the candidate is a nameand , , ,,1 ,1 ,1 1( , , | )L x C y R zL C RP o o o H is the likelihood ofthe candidate and its left and right contextsgiven the hypothesis that the candidate is not aname.
The hypothesis test is performed by com-paring the log likelihood ratio, , ,,1 ,1 ,1( , , )L x C y R zL C RLLR o o o to a predefined criticalthreshold ?
.
If , , ,,1 ,1 ,1( , , )L x C y R zL C RLLR o o o ??
, thenull hypothesis will be accepted.
Otherwise, itwill be rejected.In our design, as shown in Figure 3, theconfidence measurement module consists of twomodels, named NE model and anti-NE model.The NE model is used to assess the value of, , ,,1 ,1 ,1 0log ( , , | )L x C y R zL C RP o o o H and the anti-NE modelis used to assess the value of, , ,,1 ,1 ,1 1log ( , , | )L x C y R zL C RP o o o H .2.1.
NE ModelThe purpose of the NE model is to evaluate thevalue of , , ,,1 ,1 ,1 0log ( , , | )L x C y R zL C RP o o o H , the log like-lihood of the candidate and its left and rightcontexts given the hypothesis that the candidateis a name.
Since it is infeasible to directly esti-mate the probability , , ,,1 ,1 ,1 0( , , | )L x C y R zL C RP o o o H , it isapproximated as follows:, , , , , ,,1 ,1 ,1 0 0 ,1 ,1 ,1, , ,0 ,1 0 ,1 0 ,1( , , | ) ( , , )( ) ( ) ( )L x C y R z L x C y R zL C R L C RL x C y R zL C RP o o o H P o o oP o P o P o??
(2)where the subscript of 0( )P ?
indicates the prob-ability is evaluated given that the null hypothesisis true.
The probability ,0 ,1( )L xLP o is further ap-proximated according to the bigram model asfollows:,0 ,1 0 , , 11( ) ( | )xL xL L i L iiP o P o o?=?
?
(3)where 0 ,1 ,0 0 ,1( | ) ( )L L LP o o P o?
.
One should noticethat we do not assume that the random sequence,,1L xLo is time invariant.
For example, the prob-ability, , 1( | )L i L iP x y?= =o o is not assumed tobe equal to,2 ,1( | )L LP x y= =o o for 3i ?
.Likewise, the probability ,0 ,1( )R zRP o is also fur-ther approximated as follows:,0 ,1 0 , , 11( ) ( | )zR zR R i R iiP o P o o?=?
?
(4)where 0 ,1 ,0 0 ,1( | ) ( )R R RP o o P o?
.The probability corresponding to the can-didate is evaluated by applying the SCFG (Sto-NE ( )S ?cmNE Modelanti-NE ( )S ?Anti-NE ModelTextSegmentFigure 3: Block diagram of the confi-dence measurement module.chastic Context-free Grammar) model (Fujisaki,1989) as follows:,0 ,1 00 0( ) ( )max ( ) max ( | )C yCTT T A TP o P TP T P A???
?=?
=??
(5)where T stands for one possible parse tree thatderive the candidate, A ??
indicates a rule inthe parse tree T , A stands for the left-hand-side symbol of the rule and ?
stands for thesequence of right-hand-side symbols of the rule.Figure 4 shows an example of a parse tree of theChinese personal name candidate ?(maying jiu)?, where ?(ma)?
is the surname and?(ying jiu)?
is the given name.
In this figure,the symbol ?S?
denotes the start symbol, thesymbol ?SNG?
denotes the nonterminal derivingsurname characters and the symbol ?GNC?denotes the nonterminal deriving given namecharacters.
As a result, according to equations (2)-(5), the scoring function in the NE model isdefined as equation (6) to assess the log likeli-hood of the text segment ?
, , ,,1 ,1 ,1, ,L x C y R zL C Ro o o ?
giventhe null hypothesis that ?
,,1C yCo ?
is a name., , ,NE ,1 ,1 ,10 , , 1 0 , , 11 10( , , )log ( | ) log ( | )max log ( | )L x C y R zL C Rx zL i L i R i R ii iT A TS o o oP o o P o oP A???
?= =?
?= ++?
??
(6)where T is one possible parse tree that derivethe candidate ?
,,1C yCo ?.2.2.
Anti-NE ModelThe purpose of the anti-NE model is to evaluatethe value of , , ,,1 ,1 ,1 1log ( , , | )L x C y R zL C RP o o o H , the loglikelihood of the candidate and its left and rightcontexts given the hypothesis that the candidateis not a name.
Since it is infeasible to directlyestimate the probability , , ,,1 ,1 ,1 1( , , | )L x C y R zL C RP o o o H , itis approximated as follows:, , , , , ,,1 ,1 ,1 1 1 ,1 ,1 ,11 , , 1 1 , , 11 11 , , 11( , , | ) ( , , )( | ) ( | )( | )L x C y R z L x C y R zL C R L C RyxL i L i C i C ii izR i R iiP o o o H P o o oP o o P o oP o o?
?= =?==?
???
??
(7)where,0 ,R C yo o?
, ,0 ,C L xo o?
, and 1 ,1 ,0( | )L LP o o1 ,1( )LP o?
.
Therefore, the following scoringfunction is used in the anti-NE model to assessthe log likelihood of the text segment?, , ,,1 ,1 ,1, ,L x C y R zL C Ro o o ?
given the alternative hypothesisthat ?
,,1C yCo ?
is not a name., , ,anti-NE ,1 ,1 ,11 , , 1 1 , , 11 11 , , 11( , , )log ( | ) log ( | )log ( | )L x C y R zL C RyxL i L i C i C ii izR i R iiS o o oP o o P o oP o o?
?= =?== ++?
??(8)3.
Experiment SetupThe proposed named entity verification methodis used to recognize Chinese personal namesfrom news.
In Chinese, most of the personalnames consist of three Chinese characters.
Thefirst character is a surname.
The last two char-acters are a given name.
Therefore, our prelimi-nary experiments are focused on recognizing thepersonal names of three Chinese characters.In our experiments, the training corpusconsists of about 14,339,000 Chinese characterscollected from economy and industry news.
Thiscorpus should be annotated to estimate the prob-abilistic parameters of the scoring functionsNE ( )S ?
and anti-NE ( )S ?
.
However, labeling suchlarge amount of data is too costly or prohibitedeven if it is possible.
Therefore, labeling(ma)(ying)(jiu)SNC GNC GNCSFigure 4: A parse tree of the Chinese per-sonal name ?(ma ying jiu)?.methods that can be bootstrapped from a littleseed data or a few seed rules (Collins, 1999;Cucerzan, 1999) are highly demanded to auto-matically annotate the training data.
In the fol-lowing section, we propose an EM-style boot-strapping procedure (Cucerzan, 1999) for anno-tating the training data automatically.3.1.
EM-Style BootstrappingThe Expectation-Maximization (EM) algorithm(Moon, 1996) has been widely used to estimatemodel parameters from incomplete data in manydifferent applications.
In this section, an EM-style bootstrapping procedure is proposed toautomatically annotate the named entities in thetraining corpus.
It iteratively uses the proposedverification model to label the training corpus(expectation step), and then uses the labeledtraining corpus to re-estimate the parameters ofthe verification model (maximization step).Figure 5 shows the flowchart of the bootstrap-ping procedure.
First, we collect the names of541 famous people, including government offi-cers and CEOs of big companies.
These namesare used as seed names of the name corpus.Then, the news is automatically annotated ac-cording to the name corpus.
The annotated cor-pus is used to estimate the probabilisticparameters of the scoring functions.
Afterward,the proposed verification procedure is used toverify every possible name candidate in thenews.
The candidates whose confidence meas-ures are larger than a predefined threshold aredetermined to be names.
Currently, if the confi-dence measures of two overlapped candidates(such as ?ma ying jiu?
and ?ying jiu biao?
inFigure 1) pass the threshold, both of them aredetermined as names.
Although this strategy isinadequate, it does not make too much troublebecause the chance to get overlapped names isvery small in our experiments.
Finally, theseguessed names are added to the name corpuswhich will be used to annotate the news in nextiteration.In our case, after four iterations, the sizeof name corpus is enlarged from 541 to 6,296, asshown in Table 1.
The total occurrence frequen-cy of these 6,296 names in the training corpus is40,345.3.2.
Baseline ModelIn the past, many researchers have studied theproblem of Chinese personal name recognition.Chang (1994) used the 0-order Markov model tosegment a text into words, including Chinesepersonal names.
In his approach, a name prob-ability model is proposed to estimate the prob-abilities of Chinese personal names.
Sproat(1994) proposed to recognize Chinese personalnames with the stochastic finite-state word seg-mentation algorithm.
His approach is similar toChang?s, except that the name probability modelis slightly different.
In addition to name prob-ability, Chen (1998) also add extra scores to aname candidate according to context clues (suchas position, title, speech-act verbs).
In the re-searches mentioned above, the reported F-measure performances on recognizing Chinesepersonal names are somewhere between 70%and 86%.
Since these performances are meas-NewsNameCorpus NameVerificationGuessedNamesSeedNamesNewsAnnotationParameterEstimationFigure 5: EM-style bootstrapping.Iteration Nunber ofdistinct namesTotal frequencyof names0 541 183101 3389 311572 5327 374233 6055 399774 6296 40345Table 1: Number of distinct names inthe name corpus and total frequencyof names in the annotated news dur-ing the bootstrapping iteration.ured based on different data, higher reportedperformance does not imply better.
In fact, thename probability models used in these re-searches are very similar.
Their performancesshould be comparable to each other.
Therefore,in this paper, Chang?s approach, whose reportedF-measure is 86%, is chosen as the baselinemodel.The baseline model is additionallyequipped with a dictionary of 72,333 Chinesewords.
The prior probabilities of words are esti-mated from Academia Sinica Balanced Corpus,which contains about 2 million Chinese words.4.
Experimental Results and DiscussionsBoth the baseline model and the proposed nameentity verification model (named NEV model)are tested on the same testing corpus.
The testingcorpus, also collected from economy and indus-try news, consists of about 737,000 characters.This corpus is annotated manually and containstotally 2,545 Chinese personal names.The F-measure of the baseline model is86.5% (as indicated by the dashed line in Figure6).
The precision and recall rates of the baselinemodel are 79.1% and 95.5% respectively.
Alt-hough the recall rate of the baseline model ishigh, the precision rate is pretty low.
Over 20%of the name candidates proposed by the baselinemodel are incorrect.In our experiments, the sizes of the left-and right-context windows of the NEV modelare set to 2.
In Figure 6, the solid line with trian-gle markers depicts the F-measure of the NEVmodel versus the iteration number of bootstrap-ping.
The F-measure saturates after 3 iterations.After 4 iterations, the F-measure of the NEVmodel reaches 94.4%.
The corresponding preci-sion and recall rates are 96.4% and 92.5% re-spectively.
Compared with the baseline model,the precision rate is greatly improved from79.1% to 96.4% with a little sacrifice in recallrate.
The F-measure is improved from 86.5% to94.4%, which corresponds to 58.5% error re-duction rate, where ?error rate?
is defined as?100% F-measure?
?.Table 2 lists three examples of the mis-recognized names made by the baseline model.These examples clearly show that the baselinemodel tends to incorrectly group consecutivesingle characters, either from unknown words orsingle-character words, into names.
In the firsttwo examples, the single characters come fromthe unknown location name ?(ga luolai na; Carolina) and the unknown companyname ?(luo ji; Logitech)?.
The single char-acters in the last example are single-characterwords ?
(gi; quarter)?, ?
(quan; all)?
and ?
(mei; USA)?.Without the inadequate strong tendency ofgrouping single characters, the NEV model isable to avoid the misrecognition errors made bythe baseline model.
The NEV model assesses theconfidence measure of each name candidateaccording to the context around the candidate.
InTable 2, the name candidates in the shadedboxes are rejected by the NEV model because0 1 2 3 40.850.900.951.00IterationF?measureNEVBaselineFigure 6: The performances of baselineand name entity verification (NEV).dachangluojizaiqunian ...(In last year, the big company Logitech ...)dongdiyijiquanmeilaozhe ...(In the first quarter, the workers in all USA ...)beigaluolainazhouweiliyi(take North Carolina State as an example)Table 2: Examples of the incorrect Chi-nese personal names (in the shaded boxes)produced by the baseline model.their confidence measures are too low.To sum up, the experimental results de-monstrate that the contextual information, eitherfrom positive examples or from negative exam-ples, is very helpful for named entity verification.Besides, the superiority of the NEV model alsoshows that the proposed probabilistic scorefunctions NE ( )S ?
and anti-NE ( )S ?
are effective inproviding the scores to produce a reliable confi-dence measure.
Especially, the proposed namedentity verification approach does not require anydictionary in advance.ConclusionNamed entity (NE) recognition is an importanttask for many natural language applications,such as Internet search engines, document in-dexing, information extraction and machinetranslation.
Moreover, in oriental languages(such as Chinese, Japanese and Korean), NErecognition is even more important because itsignificantly affects the performance of wordsegmentation, the most fundamental task forunderstanding the texts in oriental languages.In this paper, a probabilistic verificationmodel is proposed to verify the correctness of anamed entity.
This model assesses the confi-dence level of a name candidate not only ac-cording to the candidate?s structure but alsoaccording to its contexts.
The clues for confi-dence measurement are collected from bothpositive and negative examples in the trainingdata.
Therefore, the confidence measure hasstrong discriminant power for judging the cor-rectness of a named entity.
In the experiments ofChinese personal name recognition, the pro-posed verification model greatly increases theprecision rate from 79.1% to 96.4% with a littlesacrifice in recall rate.
The F-measure is im-proved from 86.5% to 94.4%, which corre-sponds to 58.5% error reduction rate, where?error rate?
is defined as ?100% F-measure?
?.AcknowledgementsThis paper is a partial result of ProjectA311XS1211 conducted by ITRI under sponsor-ship of the Ministry of Economic Affairs, R.O.C.Especially thanks to the CKIP group of Acade-mia Sinica for providing the Academia SinicaBalanced Corpus.ReferencesBikel, D., Miller S., Schwartz R., and Weischedel R.(1997) Nymble: A High-performance LearningName Finder.
In Proceedings of the Fifth Confer-ence on Applied Natural Language Processing, pp.194?201.Borthwick, A.
(1999) A Maximum Entropy Approachto Named Entity Recognition.
Ph.D. Thesis, NewYork University.Chang J., Chen S., Ker S., Chen Y. and Liu J.
(1994)A Multiple-Corpus Approach to Recognition ofProper Names in Chinese Texts.
Computer Proc-essing of Chinese and Oriental Languages, Vol.
8,No.
1, pp.
75-85.Chen, H., Ding Y., Tsai S. and Bian G. (1998) De-scription of the NTU System used for MET2.
inProceedings of the 7th Message UnderstandingConference (MUC-7)Collins, M. and Singer, Y.
(1999) UnsupervisedModels for Named Entity Classification.
In Pro-ceedings of the Joint SIGDAT Conference on Em-pirical Methods in Natural Language Processingand Very Large Corpora, pp.
100-110.Cucerzan S. and Yarowsky D. (1999) Languageindependent named entity recognition combiningmorphological and contextual evidence.
In Pro-ceedings of the Joint SIGDAT Conference on Em-pirical Methods in Natural Language Processingand Very Large Corpora, pp.
90-99.Fujisaki, T., Jelinek F., Cocke J., Black E. and Nishi-no T. (1989), A Probabilistic Parsing Method forSentence Disambiguation.
In Proceedings of theInternational Workshop on Parsing Technologies,pp.
85-94.Grishman, R. (1995) The NYU system for MUC-6 orwhere's the syntax?
In Proceedings of the 6th Mes-sage Understanding Conference (MUC-6), pp.
167-175.Moon, T. K. (1996) The Expectation-MaximizationAlgorithm, IEEE Signal Processing Magazine, No-vember, 1996, pp.
47-60.Sproat R. and Chang N. (1994) A Stochastic Finite-State Word-Segmentation Algorithm for Chinese.In Proceeding of 32nd Annual Meeting of the As-sociation for Computational Linguistics, pp.
66-73.Yu, S., Bai S. and Wu P. (1998) Description of theKent Ridge Digital Labs System Used for MUC-7.In Proceedings of the 7th Message UnderstandingConference (MUC-7)
