On Learn ing  more  Appropr ia te  Se lec t iona l  Rest r i c t ionsFrancesc Ribas*Departament de Llenguatges i Sistemes InformkticsUniversitat Polit~cnica de CatalunyaPau Gargallo, 508028 BarcelonaSpainr ibas?isi,  upc.
esAbstractWe present some variations affecting theassociation measure and thresholding ona technique for learning Selectional Re-strictions from on-line corpora.
It usesa wide-coverage noun taxonomy and astatistical measure to generalize the ap-propriate semantic classes.
Evaluationmeasures for the Selectional Restrictionslearning task are discussed.
Finally, anexperimental evaluation of these varia-tions is reported.Sub jec t  Areas:  corpus-based languagemodeling, computational lexicography1 IntroductionIn recent years there has been a common agree-ment in the NLP research community on the im-portance of having an extensive coverage of selec-tional restrictions (SRs) tuned to the domain towork with.
SRs can be seen as semantic type con-straints that a word sense imposes on the wordswith which it combines in the process of seman-tic interpretation.
SRs may have different ap-plications in NLP, specifically, they may help aparser with Word Sense Selection (WSS, as in(Hirst, 1987)), with preferring certain structuresout of several grammatical ones (Whittemore tal., 1990) and finally with deciding the semanticrole played by a syntactic complement (Basili etal., 1992).
Lexicography is also interested in theacquisition of SRs (both defining in context ap-proach and lexical semantics work (Levin, 1992)).The aim of our work is to explore the feasibil-ity of using an statistical method for extractingSRs from on-line corpora.
Resnik (1992) devel-oped a method for automatically extracting class-based SRs from on-line corpora.
Ribas (1994a)*This research as been made in the framework ofthe Acquilex-II Esprit Project (7315), and has beensupported by a grant of Departament d'Ensenyament,Generalitat de Catalunya, 91-DOGC-1491.performed some experiments using this basic tech-nique and drew up some limitations from the cor-responding results.In this paper we will describe some substantialmodifications to the basic technique and will re-port the corresponding experimental evaluation.The outline of the paper is as follows: in section2 we summarize the basic methodology used in(Ribas, 1994a), analyzing its limitations; in sec-tion 3 we explore some alternative statistical mea-sures for ranking the hypothesized SRs; in sec-tion 4 we propose some evaluation measures onthe SRs-learning problem, and use them to testthe experimental results obtained by the differenttechniques; finally, in section 5 we draw up thefinal conclusions and establish future lines of re-search.2 The basic technique for learningSRs2.1 Descr ip t ionThe technique functionality can be summarizedas :I nput  The training set, i.e.
a list ofcomplement co-occurrence triples, (verb-lemma, syntactic-relationship, noun-lemma)extracted from the corpus.P rev ious  knowledge  used  A semantic hierar-chy (WordNet 1) where words are clustered insemantic lasses, and semantic lasses are or-ganized hierarchically.
Polysemous words arerepresented as instances of different classes.Output  A set of syntac-tic SRs, (verb-lemma, syntactic-relationship,semantic-class, weight).
The final SRs mustbe mutually disjoint.
SRs are weighted ac-cording to the statistical evidence found inthe corpus.Learn ing  process  3 stages:1.
Creation of the space of candidateclasses.1WordNet is a broad-coverage lexieal database, see(Miller et al, 1991))112Acquired SR Type Assoc< suit, suing > Senses 0.41< suit_of_clothes > Senses 0.41< suit > Senses 0.40< group > l~Abs 0.35< legal_action > Ok 0.28<person, individual> Ok 0.23< radical> Senses 0.16<city> Senses 0.15< admin._district > Senses 0.14< social_cont rol > Senses 0.11< status > Senses 0.087< activity > Senses -0.01< cognition > Senses -0.04Examples of nouns in Treebanksuitsuitsuitadministration, agency, bank, ...suitadvocate, buyer,carrier, client, ...groupproper_nameproper_nameadministration ,governmentgovernment, leadershipadministration, leadership, provisionconcern, leadership, provision, scienceTable 1: SRs acquired for the subject of seek2.
Evaluation of the appropriateness of thecandidates by means of a statistical mea-sure.3.
Selection of the most appropriate subsetin the candidate space to convey the SRs.The appropriateness of a class for expressingSRs (stage 2) is quantified from tile strength ofco-occurrence of verbs and classes of nouns in the.corpus (Resnik, 1992).
Given the verb v, thesyntactic-relationship s and the candidate class c,the Association Score, Assoc, between v and c ins is defined:Assoc(v,s,c) = p(clv, s)I(v;cls )= p(clv, s)log p( lv, s._____))p(cls)The two terms of Assoc try to capture differentproperties:1.
Mutual information ratio, l(v; cls), measuresthe strength of the statistical association be-tween the given verb v and the candidateclass c in the given syntactic position s. Itcompares the prior distribution, p(cls), withthe posterior distribution, p(clv, s).2. p(elv, s) scales up the strength of the associ-ation by the frequency of the relationship.Probabilities are estimated by Maximum Likeli-hood Estimation (MLE), i.e.
counting the relativefrequency of the considered events in the corpuQ.However, it is not obvious how to calculate classfrequencies when the training corpus is not seman-tically tagged as is the case.
Nevertheless, we takea simplistic approach and calculate them in thefollowing manner:f req(v,s ,c)  = ~f req(v ,s ,n )  ?
w (1)r tEc2The utility of introducing smoothing techniqueson class-based istributions is dubious, see (Resnik,1993).Where w is a constant factor used to normalizethe probabilities 3W .~~vEV ~sqS ~nqAf freq( v, S, n)lsenses(n)l(2)When creating the space of candidate classes(learning process, stage 1), we use a threshold.ing technique to ignore as much as possible thenoise introduced in the training set.
Specifically,we consider only those classes that have a highernumber of occurrences than the threshold.
Theselection of the most appropriate classes (stage 3)is based on a global search through the candidates,in such a way that the final classes are mutuallydisjoint (not related by hyperonymy).2.2 Eva luat ionRibas (1994a) reported experimental results ob-tained from the application of the above techniqueto learn SRs.
He performed an evaluation of theSRs obtained from a training set of 870,000 wordsof the Wall Street Journal.
In this section we sum-marize the results and conclusions reached in thatpaper.For instance, table 1 shows the SRs acquiredfor the subject position of the verb seek.
Type indi-cates a manual diagnosis about the class appropri-ateness (Ok: correct; ~Abs: over-generalization;Senses: due to erroneous senses).
Assoc cor-responds to the association score (higher valuesappear first).
Most of the induced classes aredue to incorrect senses.
Thus, although suit wasused in the WSJ articles only in the sense of< legal_action >, the algorithm not only consid-ered the other senses as well (< suit, suing >,<aResnik (1992) and Ribas (1994a) used equation1 without introducing normalization.
Therefore, theestimated function didn't accomplish probability ax-ioms.
Nevertheless, their results should be equivalent(for our purposes) to those introducing normalizationbecause it shouldn't affect the relative ordering of As-soc among rival candidate classes for the same (v, s).113suit_of_clothes >, < sugt >) , but the Assoc scoreranked them higher than the appropriate sense.We can also notice that the l~Abs class, < group >,seems too general for the example nouns, whileone of its daughters, < people > seems to fit thedata much better.Analyzing the results obtained from differentexperimental evaluation methods, Ribas (1994a)drew up some conclusions:a.
The technique achieves a good coverage.b.
Most of the classes acquired result from theaccumulation of incorrect senses.c.
No clear co-relation between Assoc and themanual diagnosis is found.d.
A slight tendency to over-generalization existsdue to incorrect senses.Although the performance of the presentedtechnique seems to be quite good, we think thatsome of the detected flaws could possibly be ad-dressed.
Noise due to polysemy of the nouns in-volved seems to be the main obstacle for the prac-ticality of the technique.
It makes the associationscore prefer incorrect classes and jump on over-generalizations.
In this paper we are interestedin exploring various ways to make the techniquemore robust to noise, namely, (a) to experimentwith variations of the association score, (b) to ex-periment with thresholding.3 Var ia t ions  on  the  assoc ia t ions ta t i s t i ca l  measureIn this section we consider different variations onthe association score in order to make it more ro-bust.
The different techniques are experimentallyevaluated in section 4.2.3.1 Var ia t ions  on the  pr io r  p robab i l i tyWhen considering the prior probability, the moreindependent of the context it is the better to mea-sure actual associations.
A sensible modificationof the measure would be to consider p(c) as theprior distribution:Assoc'(v,s,c) =p(c,v,s) logP(;'(;; s)Using the chain rule on mutual information(Cover and Thomas, 1991, p. 22) we can mathe-matically relate the different versions of Assoc,mssoc'(v, s c) = p(clv, s)log ~+Assoc(v ,  s, c)The first advantage of Assoc' would come fromthis (information theoretical) relationship.
Specif-ically, the AssoF takes into account the prefer-ence (selection) of syntactic positions for partic-ular classes.
In intuitive terms, typical subjects(e.g.
<person, individual, ...>) would be preferred(to atypical subjects as <suit_of_clothes>) as SRson the subject in contrast o Assoc.
The secondadvantage is that as long as the prior probabili-ties, p(c), involve simpler events than those usedin Assoc, p(cls), the estimation is easier and moreaccurate (ameliorating data sparseness).A subsequent modification would be to estimatethe prior, p(c), from the counts of all the nouns ap-pearing in the corpus independently of their syn-tactic positions (not restricted to be heads of ver-bal complements).
In this way, the estimation ofp(c) would be easier and more accurate.3.2 Es t imat ing  class probab i l i t i es  f romnoun f requenc iesIn the global weighting technique presented inequation 2 very polysemous nouns provide thesame amount of evidence to every sense as non-ambiguous nouns do -while less ambiguous nounscould be more informative about the correctclasses as long as they do not carry ambiguity.The weight introduced in (1) could alternativelybe found in a local manner, in such a way thatmore polysemous nouns would give less evidenceto each one of their senses than less ambiguousones.
Local weight could be obtained using p(cJn).Nevertheless, a good estimation of this probabil-ity seems quite problematic because of the lack oftagged training material.
In absence of a betterestimator we use a rather poor one as the uniformdistribution,c) =  (cln) = e elIs ,,ses(,,)lResnik (1993) also uses a local normalizationtechnique but he normalizes by the total numberof classes in the hierarchy.
This scheme seemsto present two problematic features (see (Ribas,1994b) for more details).
First, it doesn't takedependency relationships introduced by hyper-onymy into account.
Second, nouns categorized inlower levels in the taxonomy provide less weightto each class than higher nouns.3.3 Other  s ta t i s t i ca l  measures  to  scoreSRsIn this section we propose the application of othermeasures apart from Assoc for learning SRs: log-likelihood ratio (Dunning, 1993), relative entropy(Cover and Thomas, 1991), mutual informationratio (Church and Hanks, 1990), ?2 (Gale andChurch, 1991).
In section (4) their experimentalevaluation is presented.The statistical measures used to detect associ-ations on the distribution defined by two randomvariables X and Y work by measuring the devia-tion of the conditional distribution, P(XJY), fromthe expected distribution if both variables wereconsidered independent, i.e.
the marginal distri-bution, P(X).
If P(X) is a good approximation114ev_s p(clv-s)~v_s p( cl-.v_s )p(c)"~Cp(-~clv~)p(-,cl-,v-s)p(-~c)Table 2: Conditional and marginal distributionsof P(X IY) ,  association measures hould be low(near zero), otherwise deviating significantly fromzero .Table 2 shows the cross-table formed by the con-ditional and marginal distributions in the case ofX = {e, ~e} and Y = {v_s,-,v_s}.
Different asso-ciation measures use the information provided inthe cross-table to different extents.
Thus, Assocand mutual information ratio consider only thedeviation of the conditional probability p(c\[v,s)from the corresponding marginal, p(c).On the other hand, log-likelihood ratio and ?2measure the association between v_s and c con-sidering the deviation of the four conditional cellsin table 2 from the corresponding marginals.
It isplausible that the deviation of the cells not takeninto account by Assoc can help on extracting use-ful Sits.Finally, it would be interesting to only use theinformation related to the selectional behavior ofv_s, i.e.
comparing the conditional probabilitiesof c and -~c given v_s with the correspondingmarginals.
Relative entropy, D(P(XIv_s) I IP(X))  ,could do this job.4 Eva luat ion4.1 Eva luat ion  methods  of  SRsEvaluation on NLP has been crucial to fosteringresearch in particular areas.
Evaluation of the SRlearning task would provide grounds to comparedifferent echniques that try to abstract SRs fromcorpus using WordNet (e.g, section 4.2).
It wouldalso permit measuring the utility of the SRs ob-tained using WordNet in comparison with otherframeworks using other kinds of knowledge.
Fi-nally it would be a powerful tool for detectingflaws of a particular technique (e.g, (Ribas, 1994a)analysis).However, a related and crucial issue is whichlinguistic tasks are used as a reference.
SRs areuseful for both lexicography and NLP.
On the onehand, from the point of view of lexicography, thegoal of evaluation would be to measure the qualityof the SRs induced, (i.e., how well the resultingclasses correspond to the nouns as they were usedin the corpus).
On the other hand, from the pointof view of NLP, StLs should be evaluated on theirutility (i.e., how much they help on performingthe reference task).4.1.1 Lex icography-or iented  va luat ionAs far as lexicography (quality) is concerned,we think the main criteria SRs acquired from cor -pora  should meet are: (a) correct categorization-inferred classes hould correspond to the correctsenses of the words that are being generalized-,(b) appropriate generalization level and (c) goodcoverage -the majority of the noun occurrences inthe corpus should be successfully generalized bythe induced SRs.Some of the methods we could use for assessingexperimentally the accomplishment of these crite-ria would be:?
In t rospect ion  A lexicographer checks if theSRs accomplish the criteria (a) and (b) above(e.g., the manual diagnosis in table 1).
Be-sides the intrinsic difficulties of this approach,it does not seem appropriate when comparingacross different techniques for learning SRs,because of its qualitative flavor.?
Quant i f i ca t ion  of  genera l i za t ion  levelappropr ia teness  A possible measure wouldbe the percentage of sense occurrences in-cluded in the induced SRs which are effec-tively correct (from now on called AbstractionRatio).
Hopefully, a technique with a higherabstraction ratio learns classes that fit the setof examples better.
A manual assessment ofthe ratio confirmed this behavior, as testingsets With a lower ratio seemed to be inducingless ~Abs cases.?
Quant i f i ca t ion  of  coverage It could bemeasured as the proportion of triples whosecorrect sense belongs to one of the SRs.4.1.2 NLP  eva luat ion  tasksThe NLP tasks where SRs utility could be eval-uated are diverse.
Some of them have alreadybeen introduced in section 1.
In the recent lit-erature ((Grishman and Sterling, 1992), (Resnik,1993), ...) several task oriented schemes to testSelectional Restrictions (mainly on syntactic am-biguity resolution) have been proposed.
However,we have tested SRs on a WSS task, using thefollowing scheme.
For every triple in the testingset the algorithm selects as most appropriate thatnoun-sense that has as hyperonym the SR classwith highest association score.
When more thanone sense belongs to the highest SR, a randomselection is performed.
When no SR has been ac-quired, the algorithm remains undecided.
The re-sults of this WSS procedure are checked against atesting-sample manually analyzed, and precisionand recall ratios are calculated.
Precision is cal-culated as the ratio of manual-automatic matches/ number of noun occurrences disambiguated bythe procedure.
Recall is computed as the ratioof manual-automatic matches / total number ofnoun occurrences.115TechniqueAssoc & All nounsAssoc & P(cls)Assoc& Head-nounsDlog - likelihoodAssoc& Normalizing?21Coverage (%)95.795.595.393.792.992.788.274.1Table 3: Coverage Ratio4.2 Exper imenta l  resu l tsIn order to evaluate the different variants on theassociation score and the impact of thresholdingwe performed several experiments.
In this sectionwe analyze the results.
As training set we usedthe 870,000 words of WSJ material provided inthe ACL/DCI version of the Penn Treebank.
Thetesting set consisted of 2,658 triples correspondingto four average common verbs in the Treebank:rise, report, seek and present.
We only consideredthose triples that had been correctly extractedfrom the Treebank and whose noun had the cor-rect sense included in WordNet (2,165 triples outof the 2,658, from now on, called the testing-sample).As evaluation measures we used coverage, ab-straction ratio, and recall and precision ratios onthe WSS task (section 4.1).
In addition we per-formed some evaluation by hand comparing theSRs acquired by the different echniques.4.2.1 Compar ing  d i f ferent  techn iquesCoverage for the different echniques is shownin table 3.
The higher the coverage, the better thetechnique succeeds in correctly generalizing moreof the input examples.
The labels used for re-ferring to the different echniques are as follows:"Assoc & p(cls)" corresponds to the basic associ-ation measure (section 2), "Assoc & Head-nouns"and "Assoc & All nouns" to the techniques intro-duced in section 3.1, "Assoe & Normalizing" tothe local normalization (section 3.2), and finally,log-likelihood, D (relative entropy) and I (mutualinformation ratio) to the techniques discussed insection 3.3.The abstraction ratio for the different tech-niques is shown in table 4.
In principle, the higherabstraction ratio, the better the technique suc-ceeds in filtering out incorrect senses (less tAbs).The precision and recall ratios on the noun WSStask for the different echniques are shown in ta-ble 5.
In principle, the higher the precision andrecall ratios the better the technique succeeds ininducing appropriate SRs for the disambiguationtask.As far as the evaluation measures try to accountfor different phenomena the goodness of a partic-ular technique should be quantified as a trade-off.TechniqueIlog - likelihood ?2Assoc & All nounsAssoc & Head-nounsAssoc & p(cls)DAssoc & NormalizingAbs Ratio (%)66.664.664.464.363.96362.358.5Table 4: Abstraction RatioTechniqueAssoc & All nounsAssoc & p(cls)Assoc & Head-nounslog - likelihoodDAssoc & NormalizingIGuessing HeuristicPrec.
(%)80.379.978.577.275.975.967.850.462.7Rec.
(%)78.577.976.774.474.173.36345.762.7Table 5: Precision and Recall on the WSS taskMost of the results are very similar (differencesare not statistically significative).
Therefore weshould be cautious when extrapolating the results.Some of the conclusions from the tables above are:1.
4) 2 and I get sensibly worse results thanother measures (although abstraction is quitegood).2.
The local normalizing technique using theuniform distribution does not help.
It seemsthat by using the local weighting we mis-inform the algorithm.
The problem is thereduced weight, that polysemous nouns get,while they seem to be the most informative 4.However, a better informed kind of localweight (section 5) should improve the tech-nique significantly.3.
All versions of Assoc (except the local nor-malization) get good results.
Specially thetwo techniques that exploit a simpler priordistribution, which seem to improve the ba-sic technique.4.
log-likelihood and D seem to get slightly worseresults than Assoc techniques, although theresults are very similar.4.2.2 Thresho ld lngWe were also interested in measuring the impactof thresholding on the SRs acquired.
In figure 1we can see the different evaluation measures ofthe basic technique when varying the threshold.Precision and recall coincide when no candidate4In some way, it conforms to Zipf-law (Zipf, 1945):noun frequency and polysemy are correlated.116%1009590858075706560I I IPrecision ~'Recall + 'Coverage oAbstraction Ratio -?--Z_x ~(54.x ?<.xI K'X  *X.
)j( ~ 'X  k 'X  ~ 'X  ~.v  ~70 5 10 15 20ThresholdFigure 1: Assoc: Evaluation ratios vs. Thresholdclasses are refused (threshold = 1).
However, asit might be expected, as the threshold increases(i.e.
some cases are not classified) the two ratiosslightly diverge (precision increases and recall di-minishes).Figure 1 also shows the impact of thresholdingon coverage and abstraction ratios.
Both decrease"when threshold increases, probably because whenthe rejecting threshold is low, small classes thatfit the data well can be induced, learning over-general or incomplete SRs otherwise.Finally, it seems that precision and abstrac-tion ratios are in inverse co-relation (as precisiongrows, abstraction decreases).
In terms of WSS,general classes may be performing better thanclasses that fit the data better.
Nevertheless, thisrelationship should be further explored in futurework.5 Conc lus ions  and  fu ture  workIn this paper we have presented some variationsaffecting the association measure and thresholdingon tile basic technique for learning SRs fi'om on-line corpora.
We proposed some evaluation mea-sures for the SRs learning task.
Finally, experi-mental results on these variations were reported.We can conclude that some of these variationsseem to improve the results obtained using thebasic technique.
However, although the techniquestill seems far from practical application to NLPtasks, it may be most useful for providing exper-imental insight to lexicographers.
Future lines ofresearch will mainly concentrate on improving thelocal normalization technique by solving the nounsense ambiguity.
We have foreseen the applicationof the following techniques:?
Simple techniques to decide the best sensec given the target noun n using estimatesof the n-grams: P(e), f(eln), P(clv, s) andP(cJv, s,n), obtained from supervised andun-supervised corpora.?
Combining the different n-grams by means ofsmoothing techniques.?
Calculating P(elv ,s,n) combining P(nle )and P(clv ,s), and applying the EM Algo-rithm (Dempster et al, 1977) to improve themodel.?
Using the WordNet hierarchy as a source ofbacking-off knowledge, in such a way that ifn-grams composed by c aren't enough to de-cide the best sense (are equal to zero), thetri-grams of ancestor classes could be usedinstead.ReferencesR.
Basili, M.T.
Pazienza, and P. Velardi.
1992.Computational lexicons: the neat examples andthe odd exemplars.
In Procs 3rd ANLP, Trento,Italy, April.K.W.
Church and P. Hanks.
1990.
Word associa-tion norms, mutual information and lexicogra-phy.
Computational Linguistics, 16(1).T.M.
Cover and J.A.
Thomas, editors.
1991.
El-ements of Iuformation Theory.
John Wiley.A.
P. Dempster, N. M. Laird, and D. B. Ru-bin.
1977.
Maximum likelihood from incom-plete data via the em algorithm.
Journal of theRoyal Statistical Society, 39(B):1-38.T.
Dunning.
1993.
Accurate methods for thestatistics of surprise and coincidence.
Compu-tational Linguistics, 19(1):61-74.W.
Gale and K. W. Church.
1991.
Identify-ing word correspondences in parallel texts.
InDARPA Speech and Natural Language Work-shop, Pacific Grove, California, February.R.
Grishman and J.
Sterling.
1992.
Acquisitionof selectional patterns.
In COLING, Nantes,France, march.G.
Hirst.
1987.
Semantic interpretation and theresolution of ambiguity.
Cambridge UniversityPress.B.
Levin.
1992.
Towards a lexical organization ofEnglish verbs.
University of Chicago Press.G.
Miller, R. Beckwith, C. Fellbaum, D. Gross,and K. Miller.
1991.
Five papers on wordnet.International Journal of Lexicography.P.
S. Resnik.
1992.
Wordnet and distributionalanalysis: A class-based approach to lexieal dis-covery.
In AAAI Symposium on ProbabilisticApproaches to NL, San Jose, CA.P.
S. Resnik.
1993.
Selection and Information: AClass-Based Approach to lexical relationships.Ph.D.
thesis, Computer and Information Sci-ence Department, University of Pennsylvania.F.
Ribas.
1994a.
An experiment on learning ap-propriate selectional restrictions from a parsedcorpus.
In COLING, Kyoto, Japan, August.F.
Ribas.
1994b.
Learning more appropriateselectional restrictions.
Technical report, ES-PRIT BRA-7315 ACQUILEX-II WP,G.
Whittemore, K. Ferrara, and H. Brunner.1990.
Empirical study of predictive powersof simple attachment schemes for post-modifierprepositional phrases.
In Procs.
ACL, Pennsyl-vania.G.
K. Zipf.
1945.
The meaning-frequency rela-tionship of words.
The Journal of General Psy-chology, 33:251-256.
(Aequilex-II Working Papers can be obtainedby sending a request o cide~cup.cam.uk)' 440%1009590858075706560I I I !PrecisionRecall + -Coverage \[\]Abstraction Ratio "?
'"_ .
.
.
.-?
~(*X.?~'?
~('?
~'?
~'?
~'?
4"?
~.v ~..0 5 10 15 20ThresholdFigure 1: Assoc: Evaluation ratios vs. Thresholdclasses are refused (threshold = 1).
However, asit might be expected, as the threshold increases(i.e.
some cases are not classified) the two ratiosslightly diverge (precision increases and recall di-minishes).Figure 1 also shows the impact of thresholdingon coverage and abstraction ratios.
Both decrease"when threshold increases, probably because whenthe rejecting threshold is low, small classes thatfit the data well can be induced, learning over-general or incomplete SRs otherwise.Finally, it seems that precision and abstrac-tion ratios are in inverse co-relation (as precisiongrows, abstraction decreases).
In terms of WSS,general classes may be performing better thanclasses that fit the data better.
Nevertheless, thisrelationship should be further explored in futurework.5 Conc lus ions  and  fu ture  workIn this paper we have presented some variationsaffecting the association measure and thresholdingon the basic technique for learning SRs from on-line corpora.
We proposed some evaluation mea-sures for the SRs learning task.
Finally, experi-mental results on these variations were reported.We can conclude that some of these variationsseem to improve the results obtained using thebasic technique.
However, although the techniquestill seems far from practical application to NLPtasks, it may be most useful for providing exper-imental insight to lexicographers.
Future lines ofresearch will mainly concentrate on improving thelocal normalization teclmique by solving the nounsense ambiguity.
We have foreseen the applicationof the following techniques:?
Simple techniques to decide the best sensec given the target noun n using estimatesof the n-grams: P(e), P(e\[n), P(e\[v,s) andP(c\[v, s,n), obtained from supervised andun-supervised corpora.?
Combining the different n-grams by means ofsmoothing techniques.?
Calculating P(clv, s,n ) combining P(nlc)and P(e\[v,s), and applying the EM Algo-rithm (Dempster et al, 1977) to improve themodel.?
Using the WordNet hierarchy as a source ofbacking-off knowledge, in such a way that ifn-grams composed by c aren't enough to de-cide the best sense (are equal to zero), thetri-grams of ancestor classes could be usedinstead.ReferencesR.
Basili, M.T.
Pazienza, and P. Velardi.
1992.Computational lexicons: the neat examples andthe odd exemplars.
In Procs 3rd ANLP, Trento,Italy, April.K.W.
Church and P. Hanks.
1990.
Word associa-tion norms, mutual information and lexicogra-phy.
Computational Linguistics, 16(1).T.M.
Cover and J.A.
Thomas, editors.
1991.
El-ements of Information Theory.
John Wiley.A.
P. Dempster, N. M. Laird, and D. B. Ru-bin.
1977.
Maximum likelihood from incom-plete data via the em algorithm.
Journal of theRoyal Statistical Society, 39(B):1-38.T.
Dunning.
1993.
Accurate methods for thestatistics of surprise and coincidence.
Compu-tational Linguistics, 19(1):61-74.W.
Gale and K. W. Church.
1991.
Identify-ing word correspondences in parallel texts.
InDARPA Speech and Natural Language Work-shop, Pacific Grove, California, February.R.
Grishman and J.
Sterling.
1992.
Acquisitionof selectional patterns.
In COLING, Nantes,France, march.G.
Hirst.
1987.
Semantic interpretation and theresolution of ambiguity.
Cambridge UniversityPress.B.
Levin.
1992.
Towards a lexical organization ofEnglish verbs.
University of Chicago Press.G.
Miller, R. Beckwith, C. Fellbaum, D. Gross,and K. Miller.
1991.
Five papers on wordnet.International Journal of Lexicography.P.
S. Resnik.
1992.
Wordnet and distributionalanalysis: A class-based approach to lexical dis-covery.
In AAAI  Symposium on ProbabilisticApproaches to NL, San Jose, CA.P.
S. Resnik.
1993.
Selection and Information: AClass-Based Approach to lexical relationships.Ph.D.
thesis, Computer and Information Sci-ence Department, University of Pennsylvania.117F.
Ribas.
1994a.
An experiment on learning ap-propriate selectional restrictions from a parsedcorpus.
In COLING, Kyoto, Japan, August.F.
Ribas.
1994b.
Learning more appropriateselectional restrictions.
Technical report, ES-PRIT BRA-7315 ACQUILEX-II WP.G.
Whittemore, K. Ferrara, and H. Brunner.1990.
Empirical study of predictive powersof simple attachment schemes for post-modifierprepositional phrases.
In Proes.
ACL, Pennsyl-vania.G.
K. Zipf.
1945.
The meaning-frequency rela-tionship of words.
The Journal of General Psy-chology, 33:251-256.
(Acquilex-II Working Papers can be obtainedby sending a request o cide?cup, caaa.uk)118
