Theory and practice of ambiguity labelling with a view tointeractive disambiguation in text and speech MTChristian BoitetGETA, CLIPS, IMAG (UJF & CNRS),150 rue de la Chimie, BP 5338041 Grenoble Cedex 9, FranceChristian.
BoitetOimag.
frAbstractIn many contexts, automatic analyzers cannotfully disambiguate a sentence or an utterancereliably, but can produce ambiguous resultscontaining the correct interpretation.
It is usefulto study vatious properties of these ambiguitiesin the view of subsequent total or partial inter-active disambiguation.
We have proposed atechnique for labelling ambiguities in texts andin dialogue transcriptions, and experimented iton multilingual data.
It has been first necessaryto define formally the very notion of ambiguityrelative to a representation system, as well asassociated concepts uch as ambiguity kernel,ambiguity scope, ambiguity occurrence.Keywords: interactive disambiguation, ambiguitylabelling, ambiguity occurrence, ambiguity kernelIntroductionWe are interested in improving the quality of MTsystems for monolinguals, where the input can be textor speech, no revision is possible, and the controlledlanguage approach is not usable.
In such contexts, theautomatic analyzer cannot fully and reliably disambi-guate a sentence or an utterance, and the best availableheuristics don't select he correct results often enough.Complete or partial interactive disambiguation, folio-wing a best possible automatic disambiguation, is anattractive way to raise quality and reliability.To develop good strategies for interactive disambi-guation, it is useful to study vatious properties of theambiguities unsolvable by state of the art analyzers.To conduct such studies, it is necessary to gatherdata, that is, to perform "ambiguity labelling" on textsand transcriptions of spoken dialogues.
Our motiva-tions and goals are explained in more detail in the firstpart.
As the usual notion of ambiguity is too vaguefor our purpose, it is necessary to refine it.
This isdone in the second part, where we define formally thenotion of ambiguity relative to a representation sys-tem, as well as associated concepts uch as kernel,scope, occurrence and type of ambiguity.
In the thirdpart, we propose a format for ambiguity labelling, andillustrate it examples from a transcribed dialogue.
Thisformat is independent of the exact kind of outputproduced by any implemented analyzer, essentiallybecause ambiguities are described with a view togenerate human-oriented questions.We have experimented our technique on various kindsof dialogues and on some texts in several languages.
Insome cases, analysis results produced by automaticMutsuko TomokiyoATR Interpreting Telecommunications Research Labs2-2 Hikari-dai, Seika-cho, Soraku-gunKyoto 619-02, Japantomokiyo@itl, atr.
co. jpanalyzers were available, in others not.
It is interestingto compare the intuition of the human labeller withresults actually produced: most of the time, differencesmay be attributed to the fact that available analyzersdon't yet match our expectations for "state of the art"analyzers, because they produce spurious, "parasite"ambiguities, and don't yet implement all types of surelinguistic constraints.1 Motivations and GoalsInteractive disambiguation technology must be deve-loped in the context of research towards practicalInterpreting Telecommunications systems as well ashigh-quality multitarget text translation systems.
Inthe case of speech translation, this is because the stateof the art is such that a black box approach to spokenlanguage analysis (speech recognition plus linguisticparsing) is likely to give a correct output for no morethan 50 to 60% of the utterances ("Viterbi consisten-cy" \[2\]) l, while users would presumably require anoverall success rate of at least 90% to be able to usesuch systems at all.
However, the same spoken lan-guage analyzers may be able to produce sets of outputscontaining the correct analysis in about 90% of thecases ("structural consistency" \[2\]) 2 .
In the remainingcases, the system would be unable to analyze theinput, or no output would be correct.Further extralinguistic and sure disambiguation maybe performed (1) by an expert system, if the task isconstrained enough; (2) by the users (author orspeakers), through interactive disambiguation; and (3)by a (human) expert ranslator or interpreter, accessiblethrough the network.
For example, an expert inter-preter "monitoring" several bilingual conversationscould solve some ambiguities from his workstation,either because the system decides to ask him first, or1 According to a study by Cohen & Oviatt, the combinedsuccess rate (SR) is bigger than the product of the indivi-dual success rates by about 10% in the middle range.Taking $2 = SI*S1 + (1-S1)*A with A=20%, we get:SR of 1 component (S1) 40% 45% 50% 55% 60%SRofcombination(S2) 28% 31% 35% 39% 44%S1 65% 70% 75% 80% 85% 90% 95% 100%$2 49% 55% 61% 68% 75% 83% 91% 100%50~60% overall Viterbi constitency corresponds then to65~75% individual success rate, which is optimistic.2 According to the preceding table, this corresponds to astructural consistency of 95% for each component, whichseems impossible to achieve by strictly automatic meansin practical applications involving general users.119because he sees it on his screen and steps in.
In caseswhere users could not achieve satisfactory results byusing (and helping) the system, the human expertwould take charge of (part ot) the translation.We suppose an architecture flexible enough to allowthe above three extralinguistic processes to be optio-nal, and, in the case of interactive disambiguation, toallow users to control the amount of questions askedby the system.
Hence, some ambiguities may remainafter extralinguistic disambiguation.
They should besolved by the system heuristically and "unsurely", byusing preferences, cores or defaults.
In that case, it isimportant that the questions asked from the users arethe most crucial ones, so that failure of the last step toselect the correct interpretation does not result in toodamaging translation errors.The questions we want to study on "ambiguity label-led" dialogues and texts are the following:?
what kinds of ambiguities (unsolvable by state-of-the-art speech and text analyzers) are there in realdata to be handled by the envisaged systems??
what are the possible methods of interactivedisambiguation, for each ambiguity type ??
how can a system determine whether it is importantor not for the overall communication goal todisambiguate a given ambiguity ??
what kind of  knowledge is necessary to solve agiven ambiguity, or, in other words, whom shouldthe system ask: the user, the interpreter, or theexpert system, if any??
in a given dialogue or document, how far dosolutions to ambiguities carry over."
to the end ofthe piece, to a limited distance, or not at all?Ambiguity labelling should not be performed withreference to any particular analyzer, even if a good oneis available.
It should be done at a less specific level,suitable for generating disambiguation dialogues under-standable by non-specialists.
For example, attachmentambiguities are represented differently in the outputs ofvarious analyzers, but it is always possible torecognize such an ambiguity, and to explain it byusing a "skeleton" flat bracketing.
Ambiguity label-ling may also be considered as part of the specificationof present and future state of the art analyzers, whichmeans that:it should be compatible with the representationsystems used by the actual or intended analyzers.it should be clear and simple enough for linguists todo the labelling in a reliable way and in a reasonableamount of time.Finally, our labelling should only be concerned withthe final result of analysis, not in any intermediatestage, because we want to retain only ambiguitieswhich would remain unsolved after the completeautomatic analysis process has been performed.2 Representations, Ambiguities andAssociated NotionsEven if we want to label ambiguities independentlyof any specific analyzer, we must have in mind acertain class of possible representation systems foranalysis results, and to be clear about what an "ambi-guous representation" is and about what counts as anambiguity, etc.What is an "ambiguous representation"?
This ques-tion is not as trivial as it seems, because it is oftennot clear what we exactly mean by "the" representationof an utterance.
In the case of a classical context-freegrammar G, shall we say that a representation f U isany tree T associated to U via G, or that it is the set ofall such trees?
Usually, linguists say that U hasseveral representations with reference to G.But if we use f-structures with disjunctions, U willalways have one (or zero!)
associated structure S.Then, we would like to say that S is ambiguous if itcontains at least one disjunction.
Returning to G, wemight then say that "the" representation f U is thedisjunction of all trees T associated to U via G.In practice, however, developers prefer to use hybriddata structures to represent utterances.
Trees decoratedwith various types of structures are very popular.
Forspeech and language processing, lattices bearing suchtrees are also used, which means at least 3 levels atwhich a representation may be ambiguous.Which class of representation systems do we considerin our labelling?
First, they must be fine-grainedenough to allow the intended operations.
For instance,text-to-speech requires less detail than translation.
Onthe other hand, it is counter-productive to make toomany distinctions.
For example, what is the use ofdefining a system of 1000 semantic features if nosystem and no lexicographers may assign them toterms in an efficient and reliable way?
Second, there isa matter of taste and consensus: although differentrepresentation systems may be formally equivalent,researchers and developers have their preferences.
Third,the representations should be amenable to efficientcomputer processing.
Let us make this point moreprecise.A "computable" representation system is a representa-tion system for which a "reasonable" parser can bedeveloped.A "reasonable" parser is a parser such as:?
its size and time complexity are tractable over theclass of intended utterances;?
assumptions about its ultimate capabilities,especially about its disambiguation capabilities,are realistic given the state of the art.A representation will be said to be ambiguous if it ismultiple or u nderspec~fied.In all known representation systems, it is possible todefine "proper representations", extracted from theusual representations, and ambiguity-free.
For exam-ple, if we represent "we read  books" by the uniquedecorated dependency free:\[ \["We" ( (lex "I-Pro") (cat pronoun)(person i) (number plur)...) \]"read" ( (lex "read-V") (cat verb)(person i) (number plur)(tense {pres past\])...)\["books" ( (lex "book-N") (cat noun)...) \] \]there would be 2 proper representations, one with( tense pres ) , and the other with ( tense past).120For defining the proper representations of a represemtation system, it is necessary to specify whichdisjunctions are exclusive, and which are inclusive.A representation i  a formal representation system isproper if it contains no exclusive disjunction.The set of proper representations a sociated to a repre-sentation R, is obtained by expanding all exclusivedisjunctions of R (and eliminating duplicates).
It isdenotexl hem by_ProA)er(_R ~ .
.
.
.
.R is multiple if IProper(R)l>l.
R is multiple if (andon lz i~n~m_per .
_ _ _ _A proper epresentation P is undersT)ecified if it is un-defined with respect o some necessaryinformation.There are two cases: the intbrmation is specified, butits value is unknown, or it is nfissing altogether.The first case often happens in the case of anaphoras:( re f  ?)
, or in the case where some information hasnot been exactly computed, e.g.
( taskdomain  ? )
,\ [decade of  month ?)
, but is necessary for transla-ting in at least one of tile target languages.
It is quitenatural to consider this as ambiguous.
For example, ananaphoric reference should be said to be ambiguous?
if several possible referents appear in therepresentation (several proper epresentations),?
and also if the referent is simply marked asunknown, which causes no disjunction.The second case nmy never occur in representationswhere all attributes are present in each decoration.
But,in a standard f-structure, one cannot force tile presenceof an attribute, so that a necessary attribute may bemissing: ( re f  .9) means the absence of attribute re f .1"or any \[brmal representation system, then, we mustspecify what the "necessary information" is.
Contraryto what is needed for defining Proper(R), this may wirywith the intended application.Our final definition is now simple to state.A representation R is ambiguous if it is multiple or~f \]eper(R ) contains an underspecified P.We distinguish three levels of granularity.a dialogue (resp.
a text) can be segmented in atleast two different ways into turns (resp.paragraphs), ora turn (rcsp.
a paragraph) can be segmented in atleast two different ways into utterances, oran utterance can be analyzed in at least twodifferent ways, whereby the analysis is performedin view of translation into one or several_ l%ngugges inthe context o~i a certifin generic task.Ambiguities of segmentation i to paragraphs mayoccur in written texts, if, for example, there is aseparation by a <new line> character only, without<line feed> or <paragraph>.
They are much morefrequent and problematic in dialogues.
We found manyexamples of such ambiguities in ATR's transcriptionsof Wizard of Oz interpretations dialogues \[101.Ambiguities of segmentation i to utterances are fre-quent, and most annoying, as analyzers generally workutterance by utterance, even if they can access analysisresults of the preceding context.
For example: "r  ightI?
now I ?
turn left..." or (\[10\], p. 50): ~OI< I ?
sogo back and is this number  three I ?
r ightthere I?
shall I wait here for the bus?
".As far as utteranceqevel ambiguities are concerned,let us stress again that we consider only those whichshould be produced by a state-of-the-art analyzerconstrained by the task.
For instance, "P lease  s ta teyour  phone number" shoukl not be deemed ambi-guous, as no complete analysis should allow "state" tobe a noun, or "phone" to be a verb.
That could bedifferent in a context where "state" could be construedas a proper noun ("State"), for example in a dialogueinvolving the State Department.There is a fmther point.
Consider the utterance:(i) Do you know where the internationaltelephone services are located?
"File underlilmd fragment has an ambiguity ot'attachment, because it has two different "skeleton" 12\]representations:\[international telephone\] services/ international \[telephone services\]As a title, this sequence presents the same ambiguity.However, it is not enough to consider it in isolation.Take for example:(2) The international telephone servicesmany countries.The ambiguity has disappeared!
It is indeed frequentthat an ambiguity relative to a fragment appears,disappears and reappears as one broadens its context.For example, in(3) The international telephone servicesmany countries have established arevery reliable.the ambiguity has reappeared.
Hence, inorder to define properly what an ambiguity is, we mustconsider the fragment within an utterance, and chuifythe idea that the fragment is the smallest (within theutterance) where the ambiguity can be observed.Although utterance-level ambiguities must be consi-dered in tile context of whole utterances, a sequencelike " in ternat iona l  te lephone serv ices"  isambiguous in the same way in utterances (l) and (3)above.
We call this an "ambiguity kernel", as opposedto "ambiguity occurrence", or "ambiguity" for short.it also clear that another sequence, such as "importanthusiness addresses", presents the same sort of ambigui-ty, or "ambiguity type" in analogous contexts (here,"ambiguity of attachment", or "structural ambiguity").Other types concern the acceptions (word senses), thefunctions (syntactic or semantic), etc.
"Ambiguitypatterns" are more specific kinds of ambiguity types,usable to trigger actions, such as tim production ofdisambiguating dialogues.We take it for granted that, for each consideredrepresentation system, we know how to define, R~reach fragment V of an utterance U having a properrepresentation P, tile part of P which represents V.For example, given a context-free grammar and anassociated tree structure P for U, the part of Prepresenting a substring V of U is the smallest sub-tree Q containing all leaves corresponding to V. Q is121not necessarily the whole subtree of P rooted at theroot of Q. Conversely, for each part Q of P, wesuppose that we know how to define the fragment V ofU represented byQ.Let P be a proper epresentation f U. Q is a minimalunderspecifiedpart of P if it does not contain anystrictly smaller underspecified part Q'.-Let P be a proper epresentation f U and Q be aminimal underspecified part of P. The scope of theambiguity of underspecification exhibited by Q is thefragment V represented byQ.In the case of an anaphoric element, Q willpresumably correspond to one word or term V. In thecase of an indeterminacy of semantic relation (deepcase), e.g.
on some argument of a predicate, Q wouldcorrespond to a whole phrase V.I A fragment V presents an ambiguity of multiplicity n (n>2) in an utterance U if it has n different proper representations which are part of n or more properrepresentations of U.V is an ambiguity scope of an ambiguity if it isminimal relative to that ambiguity.
This means thatany strictly smaller fragment W of U has strictly lessthan n associated sub-representations r, equivalently,that at least two of the representations of V are be\] equal with respect to W.In example (1) above, then, the fragment "the interna-tional telephone services", together with the two skele-ton representationsthe \[international telephone\] services/ the international \[telephone services\]is not minimal, because it and its two representationscan be reduced to the subfragment "internationaltelephone services" and its two representations (whichare minimal).This leads us to consider that, in syntactic trees, therepresentation of a fragment is not necessarily a"horizontally complete" subtree.
In the case above, forexample, we might have the configurations given inthe figure below.NP NPthe international telephone services the international telephone sQrviceservicesinternationalservicest h e ~internationalIn the first pair (constituent s ructures), "internationaltelephone services" is represented by a completesubtree.
In the second pair (dependency structures), therepresenting subtrees are not complete subtrees of thewhole tree.I An ambiguity occurrence, or simply ambiguity, A, of multiplicity n (n>2) relative to a representation system R, may be formally defined as: A = (U, V, <P1, P2...Pm>, <Pl, P2...Pn>), where m>n and:U is a complete utterance, called the context of theambiguity.V is a fragment of U, usually, but not necessarilyconnex, the scope of the ambiguity.P1, P2...Pm are all proper epresentations of U inR, and Pl, P2...Pn are the parts of them whichrepresent V.For any fragment W of U strictly contained in V,if ql, q2...qn are the parts of Pl, P2.--Pncorresponding to W, there is at least one pair_ qi, qj (i~j) such that qi = qj.This may be illustrated by the following diagram,A P2 'p3_where we take the representations to be tree structuresrepresented by triangles.
Here, P2 and P3 have thesame part P2 representing V, so that m>n.I The an ambiguity kernel ofA = (U, V, <PI, P2...Pm>, <Pl, P2...pn>) is thescope of A and its (proper) representations:K(A) = (V, <Pl, P2...Pn>) ?In a data base, it suffices to store only the kernels,and references tothe kernels from the utterances.The of A is the in which the differ, and type way Pimust be defined relative to each particular R.If the representations are complex, the differencebetween two representations is defined recursively.
Forexample, two decorated trees may differ in theirgeometry or not.
If not, at least two correspondingnodes must differ in their decorations.Further efinements can be made only with respect tothe intended interpretation of the representations.
Forexample, anaphoric references and syntactic functionsmay be coded by the same kind of attribute-value pairs,but are usually considered as different ambiguity types.When we define ambiguity types, the linguisticintuition should be the main factor to consider,because it is the basis for any disambiguation method.For example, syntactic dependencies may be codedgeometrically in one representation system, and withfeatures in another, but disambiguating questionsshould be the same.
Finally,An ambiguity pattern is a schem~i wfth variableswhich can be instantiated toa (usually unbounded) setof ambiguity kernels.Here is an ambiguity pattern of multiplicity 2 corres-ponding to the example above (constituent s ructures ) .NP\ [x l  NP \ [x2  x3\] \] , NP \ [NP \ [x I  x2\] x3\] .We don't elaborate, as ambiguity patterns are specificto particular representation systems and analyzers, sothat they should not appear in our labelling.1223 Principles of Ambiguity LabellingFor lack of space, we cannot give here the context-free grammar which defines our labelling formally, andillustrate the underlying principles by way of examplesfrom a dialogue transcription taken from \[1 \].The labelling begins by listing the text or thetranscription of the dialogue, thereby indicatingsegmentation problems with the mark " \[ I ?
".
Bracke-ted numbers are optional and correspond to the turns orparagraphs as presented in the original.LABELLED DIALOGUE: "EMMI l Oa"\[1\] A: Good morning conference office I1?how can I help you\[2\] AA: \[ah\] yes good morning could youtell me please how to get from Kyotostation to your conference center\[7\] A: / Is/  OK, you're at Kyoto stationright now II7\[8\] AA: {yes}\[9\] A: {/breath/} and to get to theInternational Conference Center you caneither travel by taxi bus or subway howwould you like to go\[10\] AA: I think subway sounds like thebest way to meThe labelling continues with the next level of granu-larity, paragraphs or turns.
The difference is that a turnbegins with a speaker's code.
For each paragraph orturn, we then label the ambiguities of each possibleutterance.
If there is an ambiguity of segmentation iparagraphs or turns, there may be more labelledparagraphs or turns than in the source.
For example, AI1?
B I1?
C may give rise to A-BIIC and AIIB-C, and notto A-B-C and AIIBIIC.
Which combinations arepossible should be determined by the person doing thelabelling.
An interruption such as \[8\] may also create adiscontinuous turn (\[7, 9\] here).In the case of utterances, the same remarks apply.However, discontinuities should not appear.
There areoften less possible utterances than all possiblecombinations.
Take the example given in I1.3 above:OK l?
so go back and is this number threeI?
right there I?
shall I wait here forthe bus?This is an A I?
B I?
C I?
D pattern, giving rise to 10possible combinations.
If the labeller considers onlythe 4 possibilities AIBIC-D, AIBICID, AIB-CID, and A-B-CID, the following 7 utterances will be labelled:A OKA-B-C OK so go back and is this numberthree right thereB so go back and is this number threeB-C so go back and is this number threeright thereC right thereC-D right there shall I wait here for thebus ?D shall I wait here for the bus?The mark TUm~ (or PARAG for a text) must be used ifthere is more than one utterance.
/TURN is optional andshould be inserted to close the list of utterances, that isif the next paragraph contains only one utterance anddoes not begin with PARAG.
A format still closer to theTEl guidelines may be proposed in the future.LABELLED TURNS OF DIALOGUE "EMMI 10a"TURN\[1\] AA: Good morning, conference office,I?
How can I help you?UTTERANCES\[1.1\] AA: Good morning, conferenceoffice(1 )(ambiguity EMMI10a-l-2.2.8.3 ((scope "conference office")(status expert_system)(type address (*speaker *hearer))(importance not-important)(multimodal facial-expression)(desambiguation_scope definitive)))\[1.2\] AA: How can I help you?...
ambiguities\[1.1, 2\] AA: Good morning, conferenceoffice, how can I help you?...
ambiguitiesTURN\[2\] AA: \[ah\] yes, good morning, I Couldyou tell me please how to get fromKyoto station to your conference center?...
ambiguitiesThe labeller indicates here a sure segmentation.UTTERANCES\[2.1\] AA: \[ah\] yes(2), good morning.\[2.2\] AA: Could you tell me please how toget from Kyoto station to yourconference center(3)?The idea is to label all ambiguity occurrences, butonly the ambiguity kernels not already labelled.
Theend of the scope of each ambiguity occurrence isindicated in the text by a bracketed number whichidentifies its ambiguity kernel.Each ambiguity kernel begins with its header.
Thencome its obligatory labels (scope, then status, impor-tance, and type, in any order), and its other labels.
Forexample, the kernel header "ambigui ty  ~ I10a-2  ' -5 .1  " identifies kernel #2' in dialogue EMMI 10a,noted here EMMI10a.
"5.1" is the coding of \[11\].The status (expert_system, interpreter, user)expresses the kind of supplementary knowledge neededto reliably solve the considered ambiguity.
If"expert_system" is given, and if a disambiguationstrategy decides to solve this ambiguity interactively,it may ask: the expert system, if any; the interpreter, ifany; or the user (speaker).
If "interpreter" is given, itmeans that an expert system of the generic task at handcould not be expected to solve the ambiguity.The importance (crucial, important, not-important,negligible) expresses the impact of solving the ambi-guity in the context of the intended task.
Then comes123the ambiguity type (structure, comm_act, class,meaning, target language, reference, address, situation,mode) and its value(s).
The linguists may define moretypes and complete the list of values if necessary.Other labels are optional.
Their list will be completedin the future as more ambiguity labelling is performed.As for now, they comprise the disambiguation scope(how far does the solution of the ambiguity kernelcarry over in the subsequent u terances), and the multi-modality (what kind of cues could be used to helpsolve the ambiguity in a multimodal setting).For lack of space, we can present only a few of theinteresting examples from the same dialogue.\[4\] AA: yes I am to(5) attend thi \[uh\]Second International Symposium {on}Interpreting Telecommunications(ambiguity EMMIlOa-5-3.1.2 ((scope "am to")(status user)(type Japanese ("tal$'/aZdta:~""~_ & I~_f~: ~-~7~ .
.
.
.
I~t ~YYcS"))(importance important)))The interpretation of "1 am to" (obligationor future) is solvable reliably only by the speaker.The following example is like the famous one: "Timeflies like an arrow"/"Linguist's examples" are oftenderided, but they really appear in texts and dialogues.However, as soon as they are taken out of context,they look again as artificial as "linguist's examples"/\[10\] AA: I think subway sounds(10)like(11) the best way to me(ambiguity EMMI10a-10-3.1.1 ((scope "sounds")(status interpreter)(type cat (verb noun))(importance crucial)(multimodal (prosody pause)))(ambiguity EMMIlOa-11-3.1.1 ((scope "like")(status interpreter)(type cat (verb preposition))(importance crucial)(multimodal (prosody pause)))Here is an example of communication-act mbiguity,which is crucial for translating into Japanese.\[11\] A: OK, \[ah\] you wanna go by subwayand you're at the station right now(12).
(ambiguity EMMI10a-12-5.1 ((scope "you wanna go by subway and you'reat the station right now")(status expert-system)(type CA (yn-question inform))(importance crucial)(multimodal prosody)))Conc lus ionAlthough many studies on ambiguities have beenpublished, the specific goal of studying ambiguities inthe context of interactive disambiguation i text andspeech translation has led us to explore new groundand to propose the concept of "ambiguity labelling".About 80 pages of dialogues gathered at ATR havebeen labelled: monolingual dialogues in Japanese andEnglish, and bilingual WOZ dialogues \[ 10\].
Attemptshave also been made on French texts and dialogues,and on monolingual telephone dialogues for whichanalysis results produced by automatic analyzers wereavailable.
Part of these collected ambiguities have beenused for experiments on interactive disambiguation.AcknowledgmentsOur thanks go to Dr. Y. Yamazaki, president ofATR-ITL, Mr. T. Morimoto, head of Department 4,and Dr. K.-H. Loken-Kim, for their constant supportto this project, and to its funders, CNRS and ATR.References\[1\] ATR-ITL (1994) Transcriptions of English OralDialogues Collected by ATR-ITL using EMMI.
TR-IT-0029, ATR-ITL, January 1994, 33 p.\[2\] Black E., Garside R. & Leech G. (1993)Statistically-Driven Grammars ofEnglish: theIBM/Lancaster Approach.
J. Aarts & W. Mejs, cd.,Language and Computers: Studies in Practical Linguistics,Rodopi, Amsterdam, 248 p.\[311 Blanchon H. (1994) Perspectives of DBMT formonolingual uthors on the basis of LIDIA-I, animplemented mockup.
Proc.
15th InternationalConference on Computational Linguistics, COLING-94,Kyoto, Japan, 5-9 Aug. 1994, vol.
I/2, pp.
115--119.\[411 Boitet C. (1993) Practical Speech TranslationSystems will integrate human expertise, multimodalcommunication, and interactive disambiguation.
Proc.MTS-IV, Kobe, 18-22 July 1993, pp.
173-176.\[5\] Boitet C. & Blanehon H. (1994)Multilingual Dialogue-Based MT for MonolingualAuthors: the LIDIA Project and a First Mockup.
MachineTranslation, 9/2, pp.
99--132.\[6\] Boitet C. & Loken-Kim K.-H. (1993)Human-Machine-Human Interactions in InterpretingTelecommunications.
Proc.
International Symposium onSpoken Dialogue, Tokyo, 10-12 November 1993,Waseda University, 4 p.117\] Maruyama H., Watanabe H. & Ogino S.(1990) An Interactive Japanese Parser for MachineTranslation.
Proc.
COLING-90, Helsinki, 20-25/8/90, 11.Karlgren, ed., ACL, vol.
2/3, pp.
257-262.\[8\] Park Y.-D. & Loken-Kim K.-H. (1994) TextDatabase of the Telephone and Multimedia Multimodalhzterpretation Experiment.
Technical Report, ATR-|TL,Dec.
94, 161 p.\[9\] Park Y.-D., Loken-Kim K.-H. & Fais L.(1994) An Experiment for telephone versus multimediamultimodal Interpretation: Methods and Subject'sBehavior.
Technical Report, ATR-ITL, Dec. 94, 15 p.\[10\] Park Y.-D., Loken.Kim K.-H., MizunashiS.
& Fais L. (1995) Transcription of the CollectedDialogue in a Telephone and Multbnedia/Multimodal WOZExperiment.
Technical Report, ATR-ITL, Feb. 95, 123 p.\[11\] Tnmokiyo M. (1994) AmbiguityClassification and Representation.
Proc.
NaturalLanguage Understanding and Models of Communication,Oct.
94.124
