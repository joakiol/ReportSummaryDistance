Proceedings of NAACL HLT 2007, Companion Volume, pages 141?144,Rochester, NY, April 2007. c?2007 Association for Computational LinguisticsStating with Certainty or Stating with Doubt:Intercoder Reliability Results forManual Annotation of Epistemically Modalized StatementsVictoria L. RubinFaculty of Information and Media StudiesUniversity of Western OntarioLondon, Ontario, Canada N6A 5B7vrubin@uwo.caAbstractTexts exhibit subtle yet identifiable mo-dality about writers?
estimation of howtrue each statement is (e.g., definitely trueor somewhat true).
This study is an analy-sis of such explicit certainty and doubtmarkers in epistemically modalizedstatements for a written news discourse.The study systematically accounts for fivelevels of writer?s certainty (ABSOLUTE,HIGH, MODERATE, LOW CERTAINTY andUNCERTAINTY) in three news pragmaticcontexts: perspective, focus, and time.The study concludes that independentcoders?
perceptions of the boundaries be-tween shades of certainty in epistemicallymodalized statements are highly subjec-tive and present difficulties for manualannotation and consequent automation foropinion extraction and sentiment analysis.While stricter annotation instructions andlonger coder training can improve inter-coder agreement results, it is not entirelyclear that a five-level distinction of cer-tainty is preferable to a simplistic distinc-tion between statements with certaintyand statements with doubt.1 Introduction1.1 Epistemic Modality, or CertaintyText conveys more than just a writer?s proposi-tional context of assertions (Coates, 1987), e.g., Xis true.
Text can also transfer the writers?
attitudesto the propositions, assessments of possibilities,and the writer?s certainty, or lack thereof, in thevalidity of the truth of the statements, e.g., X mustbe true, Y thinks that X is true, or perhaps X istrue.
A statement is qualified in such a way (be-yond its mere referential function) is modal, orepistemically modalized (Coates, 1987; Westney,1986).CERTAINTY, or EPISTEMIC MODALITY, concernsa linguistic expression of an estimation of the like-lihood that a certain state of affairs is, has been, orwill be true (Nuyts, 2001).
Pragmatic and dis-course literatures are abundant in discussions ofepistemic modality (Coates, 1987; Nuyts, 2001);mood (Palmer, 1986); evidentiality and evidentials(Mushin, 2001); expressions of doubt and certainty(Holmes, 1982; Hoye, 1997) and hedging(Lackoff, 1972) and hedging in news writing(Hyland, 1999; Zuck & Zuck, 1986).
Little at-tempt, however, has been made in natural languagecomputing literature to manually annotate and con-sequently automate identification of statementswith an explicitly expressed certainty or doubt, orshades of epistemic qualifications in between.
Thislack is possibly due to the complexity of comput-ing epistemic interpretations in different pragmaticcontexts; and due to unreliability of variety of lin-guistic expressions in English that could explicitlyqualify a statement.
Another complication is a lackof agreed-upon and easily identifiable discretecategories on the continuum from certainty todoubt.
Several annotation projects have success-fully addressed closely related subjective issuessuch as private states in news writing (Wiebe, Wil-son, & Cardie, 2005) and hedging in scientificwriting (Light, Qiu, & Srinivasan, 2004; Mercer,DiMarco, & Kroon, 2004).
Having access to theopinion holder?s evaluation of how true a state-ment is valuable in predicting reliability of argu-ments and claims, and stands to benefit the tasks of141opinion and sentiment analysis and extraction innatural language computing.1.2 Certainty Level ScalesWhile there is an on-going discussion in pragmaticliterature on whether epistemic modality markersshould be arranged on a continuum or in discretecategories, there seems to be an agreement thatthere are at least three articulated points on a pre-sumed continuum from certainty to doubt.
Hoye(1997) suggested an epistemic trichotomy of CER-TAINTY, PROBABILITY, and POSSIBILITY, consistentwith Holmes?
(1982) scale of certainty of asser-tions and negations where the writer asserts WITHCERTAINTY that a proposition is true or not true; orthat the proposition is PROBABLY or POSSIBLY trueor not true.
In attitude and affect computationalanalysis literature, the context of extracting opin-ions from news article corpora, Rubin and col-leagues (2004; 2005) extended Hoye-Holmesmodels by adding two extremes on the epistemiccontinuum scales: ABSOLUTE CERTAINTY (definedas a stated unambiguous indisputable conviction orreassurance) and UNCERTAINTY (defined as hesi-tancy or stated lack of clarity or knowledge), andre-defined the middle categories as HIGH CER-TAINTY (i.e., high probability or firm knowledge),MODERATE CERTAINTY (i.e., estimation of an aver-age likelihood or reasonable chances), and LOWCERTAINTY (i.e., distant possibility, see Fig.
1).Figure 1.
Revised Explicit Certainty CategorizationModel (redrawn from Rubin, 2006).While Rubin?s (2006) model is primarily con-cerned with identification of certainty levels en-coded in explicit certainty markers in propositions,it also takes into account three contextual dimen-sions relevant to news discourse.
Perspective at-tributes explicit certainty either to the writer or twotypes of reported sources ?
direct participants andexperts in a field.
Focus separates certainty in factsand opinions.
Time is an organizing principle ofnews production and presentation, and if relevant,is separated into past, present, or future.2 MethodologyThis study uses the above-described conceptualcertainty categorization model to annotate a newsdataset, and produce a typology of syntactic, se-mantic and lexical classes of certainty markers thatmap statements into 5 levels of certainty rangingfrom absolutely certain to uncertain.The dataset consisted of 80 randomly selectedarticles (from the AQUAINT Corpus of EnglishTexts, distributed by The New York Times Ser-vices in 2000).
It constituted a total of 2,243 sen-tences, with 866 sentences in the editorials and1377 sentence in the news reports (Rubin, 2006).
Asubset of 10 articles (272 sentences, about 12% ofthe full dataset) was analyzed by 4 independentlytrained annotators (excluding the author).
Theagreement results were evaluated in 2 consecutiveintercoder reliability experiments.2.1 Annotation ProcessThe manual annotation scheme was defined in thecodebook instructions that specified the proceduresfor determining certainty-qualified statements, theorder of assigning categories, and exemplified eachcertainty category (Rubin, 2006).
In Experiment 1,three coders received individual one-hour trainingregarding the use of the annotation scheme, andwere instructed to use the original codebook writ-ten in a general suggestive tone.
In Experiment 2,the fourth annotator went through a more thoroughfive-hour training and used a revised, more rigidly-specified codebook with an alphabetized key-wordindex mapped certainty markers into 5 levels.Each statement in a news article (be it a sentenceor its constituent part such as a clause) was a po-tential locus of explicit certainty.
In both experi-ments coders were asked to decide if a sentencehad an explicit indication of a certainty level.
If so,they then looked for explicit certainty markers thatcontributed to that indication.
If a sentence con-tained a certainty marker, the annotators were in-142structed to consider such a sentence certainty-qualified.
The statement was assigned a certaintylevel and placed in its pragmatic context (i.e., intoone of the categories) within the perspective, fo-cus, and time dimensions (see D2 ?
D4, Fig.
1)relevant to the news discourse.
Each marker wasonly assigned one category from each dimension.2.2 Intercoder Agreement Measures.Each pair of coders were evaluated on whetherthey agreed regarding 1) the sentences that contai-ned explicit certainty markers; 2) the specific cer-tainty markers within agreed upon certainty-qualified sentences; and 3) classification of theagreed upon markers into one of the categorieswithin each dimension (i.e., level, perspective, fo-cus and time).
The sentence and marker agreementmeasures were calculated with percent agreement.Partial word string matches were considered amarker match but were weight-adjusted.
Theagreed-upon marker category assignments wereassessed in each pair of independent coders withCohen?s kappa statistic (Cohen, 1960), averaged,and compared to the author?s annotation.3 Results and Discussion3.1 Typology of Certainty MarkersThe content analysis of the dataset generated agroup of 1,330 explicitly certainty-qualified sen-tences with 1,727 occurrences of markers.
Themarkers were grouped into a typology of 43 syn-tactico-lexical classes; each class is likely to occurwithin one of the 5 levels of certainty.
The typol-ogy will become a basis for an automated certaintyidentification algorithm.
Among the most fre-quently used certainty markers are central modalauxiliary verbs (e.g., must, could), gradable adjec-tives in their superlative degree, and adverbial in-tensifiers (e.g., much and so), while adjectivaldowntoners (e.g., feeble + NP) and adverbialvalue disjuncts (e.g., annoyingly, rightly) arerarely used to express explicit certainty.3.2 Intercoder Reliability Test ResultsIn Experiment 1, 1) three coders agreed on whethera sentences was modalized by an explicit certaintymarker or not 71% of the time with 0.33 Cohen?skappa, on average.
2) Within agreed-upon cer-tainly-qualified sentences, three coders agreed onactual certainty markers 54% of the time, on aver-age, based on a combined count of the full andweight-adjusted partial matches.
3) In the categori-zation task for the agreed-upon markers, the threecoders, on average, were able to reach a slightagreement in the level and focus dimensions (0.15and 0.13 kappa statistics, respectively), and a fairagreement in perspective and time dimensions(0.44 and 0.41 kappa) according to the Landis andKoch (1977) agreement interpretation scale.The subsequent Experiment 2 showed promisingresults in agreement on explicit certainty markers(67%) and overall ability to distinguish certainty-qualified statements from unmarked statements(0.51 kappa), and in the relatively intuitive catego-rization of the perspective dimension (0.65 kappa).Although stricter instructions may have imposeda more orderly way of looking at the epistemiccontinuum, the 5 level certainty boundaries are stillsubject to individual perceptions (0.41 kappa) andmay present difficulties in automation.
In spite ofits large inventory of certainty markers, Englishmay not be precise enough to reliably distinguishmultiple epistemic shades between certainty anddoubt.
Alternatively, people might be using sameexpressions but underlying categorization systemsfor different individuals do not overlap accurately.Recent pragmatic, discourse, and philosophy oflanguage studies in mood and modality call formore comprehensive and truer to natural languagedescription of epistemic modality in English refer-ence grammar materials (Hoye, 2005).
The latestmodality scholarship will undoubtedly contributeto natural language applications such as opinionextraction and sentiment analysis.Time categorization in the context of certaintyremained a challenge in spite of more vigoroustraining in Experiment 2 (0.31 kappa).
The inter-pretation of the reference point of ?the present?
inthe reported speech and nested events can be am-biguous in the certainty identification task.
Distin-guishing facts versus opinions in combination withcertainty identification also presented a particularlypuzzling cognitive task (0.16 kappa), possibly dueto necessity to evaluate closely related facets of astatement: whether the statement is purely factual,and how sure the author is about the proposition.The possibility of epistemically modalized facts isparticularly intriguing.1434 Conclusions and ApplicationsThis study reported the results of the manual an-notation of texts in written news discourse, andidentified the most prominent patterns and regu-larities in explicitly stated markers occurrences inmodalized statements.
The linguistic means of ex-pressing varying levels of certainty are docu-mented and arranged into the typology ofsyntactico-semantic classes.
This study implies thatboundaries between shades of certainty in epis-temically modalized statements (such as probabil-ity and possibility) are highly subjective andpresent difficulties in manual annotation.
This con-clusion may warrant a simplification of the exist-ing 5 certainty levels to a basic binary distinctionbetween certainty and doubt.
A baseline for futureattempts to improve the calibration of levels andtheir boundaries was established.
These modestintercoder reliability results attest to the complex-ity of the automation of the epistemically modal-ized statements ranging from certainty to doubt.In the future studies, I intend to revise the num-ber of the discrete categories on the epistemic con-tinuum and further re-define certainty levelsconceptually.
I plan to further validate the collec-tion of agreed-upon certainty markers on a muchlarger dataset and by using the typology as inputdata to machine learning algorithms for certaintyidentification and extraction.ReferencesCoates, J.
(1987).
Epistemic Modality and Spoken Dis-course.
Transactions of the Philological Soci-ety, 110-131.Cohen, J.
(1960).
A coefficient of agreement for nomi-nal scales.
Educational and PsychologicalMeasurement, 20, 37-46.Holmes, J.
(1982).
Expressing Certainty and Doubt inEnglish.
RELC Journal, 13(2), 9-29.Hoye, L. (1997).
Adverbs and Modality in English.London, New York: Longman.Hoye, L. (2005).
"You may think that; I couldn't possi-bly comment!"
Modality Studies: Contempo-rary Research and Future Directions.
Part II.Journal of Pragmatics, 37, 1481-1506.Hyland, K. (1999).
Academic attribution: Citation andthe construction of disciplinary knowledge.Applied Linguistics, 20(3), 341-367.Lackoff, G. (1972).
Hedges: a study of meaning criteriaand the logic of fuzzy concepts.
Paper pre-sented at the Chicago Linguistic Society Pa-pers.Landis, J., & Koch, G. G. (1977).
The measurement ofobserver agreement for categorical data.
Bio-metrics, 33, 159-174.Light, M., Qiu, X. Y., & Srinivasan, P. (2004).
TheLanguage of Bioscience: Facts, Speculations,and Statements in Between.
Paper presented atthe BioLINK 2004: Linking Biological Litera-ture, Ontologies, and Databases.Mercer, R. E., DiMarco, C., & Kroon, F. W. (2004).The Frequency of Hedging Cues in CitationContexts in Scientific Writing.
Paper presentedat the Proceedings of the 17th Conference ofthe CSCSI/SCEIO (AI'2004).Mushin, I.
(2001).
Evidentiality and EpistemologicalStance: Narrative Retelling (Vol.
87).
Amster-dam, Philadelphia: John Benjamins PublishingCompany.Nuyts, J.
(2001).
Epistemic Modality, Language, andConceptualization: A cognitive-pragmatic pre-spective (Vol.
5).
Amsterdam, Philadelphia:John Benjamin Publishing Company.Palmer, F. R. (1986).
Mood and Modality.
Cambridge:Cambridge University Press.Rubin, V. L. (2006).
Identifying Certainty in Texts.
Un-published Doctoral Thesis, Syracuse Univer-sity, Syracuse, NY.Rubin, V. L., Kando, N., & Liddy, E. D. (2004).
Cer-tainty Categorization Model.
Paper presentedat the AAAI Spring Symposium: Exploring At-titude and Affect in Text: Theories and Appli-cations, Stanford, CA.Rubin, V. L., Liddy, E. D., & Kando, N. (2005).
Cer-tainty Identification in Texts: CategorizationModel and Manual Tagging Results.
In J.Wiebe (Ed.
), Computing Attitude and Affect inText: Theory and Applications (The Informa-tion Retrieval Series): Springer-Verlag NewYork, Inc.Westney, P. (1986).
How to Be More-or-Less Certain inEnglish - Scalarity in Epistemic Modality.IRAL: International Review of Applied Lin-guistics in Language Teaching, 24(4), 311-320.Wiebe, J., Wilson, T., & Cardie, C. (2005).
AnnotatingExpressions of Opinions and Emotions in Lan-guage.
Netherlands: Kluwer Academic Pub-lishers.Zuck, J. G., & Zuck, L. V. (1986).
Hedging in News-writing.
beads or braclets?
How do we ap-proach LSP?
Paper presented at the FifthEuropean Symposium on LSP.144
