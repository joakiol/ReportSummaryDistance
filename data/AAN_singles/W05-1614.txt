Computational Mechanisms for Pun GenerationGraeme RitchieDepartment of Computing ScienceUniversity of AberdeenAberdeen AB24 3UEScotlandgritchie@csd.abdn.ac.ukAbstractComputer pun-generators have so far relied on arbi-trary semantic content, not linked to the immediatecontext.
The mechanisms used, although tractable,may be of limited applicability.
Integrating punsinto normal text may involve complex search.1 IntroductionRecently, there has been a growing interest in computationalhumour, as indicated by two international workshops [Hul-stijn and Nijholt, 1996; Stock et al, 2002].
A number of com-puter programs (mostly quite small) have been constructedwhich generated very short humorous texts (see Section 4 be-low).
All but one of these programs generate some form ofpun, where we take a pun, informally and pre-theoretically,to be a supposedly humorous written or spoken text whichrelies crucially on phonetic similarity for its humorous effect.There is no accepted strict definition of a pun, even amongsthumour scholars, but the computer-generated examples arealmost certainly puns by any reasonable definition; whetherthey are funny or not is a separate question.The purpose of this paper is to consider the task of pungeneration from the wider perspective of NLG, particularlyapplied NLG, and to discuss the following:?
how the mechanisms used in pun generation systemscompare with conventional NLG;?
two classes of pun, with different potential roles in NLG;?
the computations that might achieve such puns;?
possible limitations of these computations.We shall start with the claims made for the usefulness ofcomputer-generated jokes, give a very brief summary of pastwork and then present some observations and arguments.2 MotivationIt could be argued that computer modelling of humour isworthwhile because it might shed light on human use of hu-mour, and hence could contribute to a cognitive model of hu-mour.
Here we shall leave that aside, and consider a casewhich has been more explicitly argued: that certain practicalcomputer systems will be more effective, or more pleasant touse, if they display humour.It has been claimed for some time that humour enhancescommunication in various ways.
In one study, subjectswere persuaded more effectively by material including hu-mour [Lyttle, 2001].
In another, human subjects gave morefavourable reports of working with computer systems whichemployed humour (albeit pre-coded, rather than computer-generated) [Morkes et al, 1999].Binsted [1995] argues that a user-interface which used hu-mour would be more congenial to interact with.
Stock [Stock,2002; 2003] suggests that computerised humour will haveeven wider applicability, in advertising, entertainment andeducation.
Nijholt [2002] points out that if virtual agentsare to show rich ?personalities?
in their interactions with hu-mans, some form of humour is essential.
McKay [2002] sug-gests the use of automated humour in a system for second-language learning, and O?Mara and Waller [2003] proposethat machine-assisted communication by those with languagedisabilities (particularly children) could be helped by somesoftware support for humour.So far, no computer system for humour-generation has yetbeen shown to have these benefits.
Nevertheless, for thepurposes of this paper we shall assume, from the writingscited above, that a case can be made for the desirability ofcomputer-generated humour in practical applications.These authors have argued generally for the practical useof humour, not merely puns.
However, the type of humour-generation that is likely to be available in the near future ispun-generation.
In the following sections, therefore, we shallfocus solely on puns, considering the ways in which theymight be generated within a broader NLG system.3 Two classes of punsThere are various ways in which puns, or jokes in general,could be classified, depending on the aspects which are of in-terest.
For the discussion here, we wish to make a distinctionbetween two loose groupings (not usually distinguished in theliterature):Self-contained puns: These are pieces of text which can beused as humorous items in a wide variety of circum-stances.
Any semantic links which they might have tothe context are not directly part of the joke structure, andtheir only preconditions for use are general knowledge(of the surrounding culture, etc.)
and a social situationin which joke-making is acceptable.
Example (1) (from[Binsted, 1996]) is a self-contained pun, as are all of thepuns ((5) ?
(13)) shown in Section 4.1 below.
(1) What do you get when you cross a murderer with abreakfast food?
A cereal killer.Contextually integrated puns: This type of pun occurswithin some broader discourse, with the use of a textwhich, in addition to conveying some information oremotion, has further linguistic properties which make ita pun (and may thereby augment the effects of the text,either emotionally, persuasively or otherwise).
Also, thestatus of the text as a pun may depend on contextual(possibly non-linguistic) factors.
Ritchie [2004, p.115]offers (2) and (3) as puns; both of these, when first de-livered, were contextually integrated puns.
(2) A shopper is walking along, and a leek falls fromhis shopping bag to the ground, unnoticed.
Anothershopper calls out, ?Hey!
Your bag?s leaking!?
(3) A minor football team known informally as ?CaleyThistle?
(where Caley rhymes with alley) soundlydefeats Celtic (then the top team in the country) ina major competition.
The next day, a newspaperheadline reads: ?Super Caley Go Ballistic, CelticAre Atrocious?.
(The Sun, 9 February 2000)In (2), the pun status depends upon the substring leak be-ing phonetically similar (identical) to the word leek, andthe latter word being directly related to the surroundingcontext.
In (3) the whole headline has some phoneticsimilarity to the song-title Supercalifragilisticexpialido-cious.
In both cases, the utterance conveys contextuallyappropriate information.For both these types of puns, the text?s status as a pun is inaddition to a full set of normal linguistic properties: the pun-ning texts are usually syntactically well formed texts whichhave an internally consistent semantics.The difference between the two classes can be viewed asfollows: in self-contained puns the semantic content is arbi-trary, and of secondary importance to the features that makethe text a pun, whereas in contextually integrated puns the se-mantic message is non-arbitrary, and the pun features have tobe compatible with it.There are some puns which might seem to be borderlineexamples.
In everyday social situations, someone may makea remark simply in order to make a pun, which might seemtherefore to count as a self-contained pun, but such an utter-ance is very rarely completely unconnected to the context,even if its sole purpose is humour.
For example, someonewho moves their position in a room to avoid cold air from anopen window might make the remark in (4), punning on theUSA expression draft-dodger, ?someone who avoids militaryconscription?.
(4) I?m just a draught-dodger.Although this remark may communicate little useful infor-mation, and is made solely as an attempt at humour, it is still acontextually integrated pun, in the sense that what it conveysrelates to the context, and it would not be a pun without thisconnection ?
if the speaker had not moved to avoid cold air,it would not be felicitous, and if someone later recounted theremark alone, with no account of the context, that would notcount as a joke.4 Previous work: self-contained puns4.1 The programsSince 1992, there have been a small number of programswhich created puns (cf.
[Ritchie, 2004, Ch 10]).
(Jokes de-pend on cultural knowledge, and puns rely heavily on linguis-tic knowledge, so some of these examples may be puzzling toreaders from other cultural or linguistic backgrounds.
)Lessard and Levison [1992] devised a program which cre-ated a type of pun, the Tom Swifty, exemplified by (5).
(5) ?Turn up the heat,?
said Tom coldly.The form consists of a quoted utterance, and an adverbiallymodified attribution of this remark to Tom.
The meaning ofthe utterance, or some subpart of it, is semantically linked tothe adverb.
The generation is based on finding a configurationof a root word (e.g.
cold) which can be made into an adverb(coldly) and a sentence somehow linked to the root word.The JAPE program [Binsted, 1996; Binsted and Ritchie,1997] generated punning riddles of certain types, illustratedby (1), (6), (7), (8) (cf.
[Lessard and Levison, 1993]).
(6) How is a nice girl like a sugary bird?Each is a sweet chick.
(7) What is the difference between leaves and a car?One you brush and rake, the other you rush and brake(8) What do you call a strange market?A bizarre bazaar.This was achieved by various rules which specified allow-able combinations of lexical entries and surface words; moredetails are given in Section 4.2 below.The HCPP [Venour, 1999] could create two-utterance texts,where the second part was always a short noun phrase, as in(9) (punning on doc/dock) and (10) (carrel/carol).
(9) The surgeon digs a garden.
A doc yard.
(10) Joan hears wailing in the booth.
Carrel singing.Venour describes his method in terms which borrow bothfrom Binsted and from Lessard and Levison.The puns produced by the WISCRAIC program [McKay,2002] came in three forms, exemplified by (11), (12), (13).
(11) Who broke the woman?s hart?The cruel deer-keeper.
(12) The performing lumberjack took a bough.
(13) Your mate Johnny is a hard-up deer-keeper.
He reallyneeds doe!Like the earlier programs, WISCRAIC operated by findingsets of items (e.g.
take a bow, bough, lumberjack, perform-ing) which were related in specific ways, then slotting theminto stock textual forms.The output of all these programs consists of self-containedpuns in the sense given in Section 3 above.4.2 An architecture for self-contained punsSome of the pun-generators (Lessard and Levison, Venour)reviewed above were implemented using the Vinci languagegenerator [Levison and Lessard, 1992], others (Binsted,McKay) using various Prolog facilities, including definiteclause grammars [Pereira and Warren, 1980].
However, thegeneral flow of processing in these systems is broadly thesame, and can be described using the model used by [Bin-sted, 1996] (see also [Ritchie, 2003]).
We will look at it inmore detail, partly to make more concrete some aspects ofthese puns, and partly to show how these mechanisms relateto more conventional NLG.The JAPE processing falls into three stages: content selec-tion, constituent building, surface string construction, eachof which is controlled by particular types of symbolic rule.
(Binsted calls the constituent-building stage SAD generation,where ?SAD?
stands for small adequate description, becausein JAPE it leads to short descriptive noun phrases.
)We shall describe each of these stages in turn.Content selectionIn this phase, a small number of items are selected from thelexicon as the core of the pun.
The generator has rules aboutsuitable combinations of lexical items and/or surface words,and uses these to search for a cluster of workable items.Binsted calls the content selection rules schemas.
A pun-generator program would have a number of schemas (JAPE-3 had 15), each corresponding to some subclass of pun.
Aschema contains two rather different types of information:Precondition.
A schema has a condition which a sequenceof lexical entries or surface strings (intuitively, the parame-ters for the schema) must meet in order for this type of pun tobe generated.
The precondition consists of a conjunction ofterms, where each term is a predicate (e.g.
homophone) ap-plied to variable arguments, and all variables are existentiallyquantified.
(None of the programs appear to need constantvalues as arguments to predicates.)
For example, one schema(from [Ritchie, 2003]) has the precondition:noun_phrase(NPLex),component_lexemes(NPLex, LexA, LexB),written_form([LexA], WordA),homophone(WordA, HomWord),written_form([HomLex], HomWord)where some of the variables (NPLex, LexA, LexB, HomLex)are to be matched against lexemes (abstract identifiers forlexical entries) and others (WordA,HomWord) are matchedagainst surface strings.
One possible set of bindings is NPLex= serial killer, LexA = serial, LexB = killer, WordA= ?serial?, HomWord = ?cereal?, HomLex = cereal.Although many examples can be produced using predi-cates which are computable using standard lexical informa-tion (e.g.
homophone), some of the puns (particularly thosein McKay?s system) need semantic relationships which, whilenot seriously problematic, might not be standard lexical rela-tions; for example an action ?
take a bow ?
which is ?typical?of an entity with a particular property ?
performing.
Coveringthese might need a more encyclopaedic knowledge base.Interface to later stages.
This part of a schema specifieswhat is to be done with (some or all of) the values which sat-isfy the preconditions.
It contains a formula indicating howfurther processing of the items is to be carried out, specifi-cally what sorts of constituents they are to be built into.For example, the JAPE schema illustrated immediatelyabove has the output specification (taking some liberties withnotation to save space):<same, sad(share_properties, [HomLex, NPLex]),sad(make_phrase, [HomLex, LexB]) >This (rather obscurely) indicates that the values HomLex,NPLex are to be used to create a phrase which, semantically,has some mix of their properties (e.g.
a murderer with fi-bre), and that HomLex, LexB, are to be made directly intoa phrase (hence cereal killer).
Also, the final text should con-vey that the abstract relation same holds between these twoconstituents.
That is, the output specification of a schema pro-vides a recipe for producing a structure which, while not ac-tually a text, is much closer to the eventual surface form.
Thevarious building procedures (e.g.
share properties) havea certain amount of non-deterministic freedom (see below),so that there may be more than one way in which the linguis-tic form of the phrase can be constructed, without affectingthe basic joke; for example, share properties might cre-ate a crunchy murderer.Constituent buildingGiven the items found in content selection, it may be nec-essary to form constituents (noun phrases, verb phrases, sen-tences) which either contain these items or bear some system-atic relationship to them.
In this stage, linguistic representa-tions of these chunks are constructed, following the outputspecification of the schema.The constituent building stage is a relatively arbitrary map-ping from the formulae provided by the schema to somethingwhich is more of a surface semantic structure.
This is doneby pattern-action rules which match against the various ?out-put specifications?
that can be come from the schema handler,and produces something either in surface linguistic form (e.g.a string of words) or some skeletal linguistic item whose ex-act details (e.g.
person, number) are left to the final (surfacestring) stage.
Thus some variation is possible in the linguisticform of phrases, within the limits set by the initial schemamatch.
That is why Binsted introduced this middle stage (notpresent in an earlier version of JAPE): to allow some linguis-tic variety where this does not alter the underlying joke.
Forexample, (14) requires the same schema (and surface tem-plate) as (8), but uses a different constituent for the question;this difference would occur in the constituent-building phase.
(14) What do you call an odd mall?A bizarre bazaar.Surface string constructionIn the third and final stage, a complete surface text is builtby transforming the semantic constituents into surface stringsand concatenating them, in some order, with various fixedstrings of words.
Minor adjustments such as number agree-ment, or choosing between a and an, are carried out.
All thisis driven by templates, which are like DCG rules with somepre-conditions attached.4.3 Discussion of the mechanismsThe mechanisms summarised here were designed solely toproduce puns, but the notions of ?schema?
and ?template?are not radically (or interestingly) different from those estab-lished within mainstream NLG (e.g.
[McKeown, 1985], [Ku-kich, 1983]).
However, the way that this whole architectureis deployed is unusual.
Normally in NLG, we can reason-ably make a distinction between some background knowledgebase (e.g.
linguistic rules, lexicon, general facts about the do-main) and some message which is to be conveyed.
A typ-ical schema-based system then matches its schemas againstthe message to determine applicability, with the backgroundknowledge being called upon only as needed in the match.In contrast, the pun generators have only a knowledge base,and do not start from a message to be conveyed: they arerandom generators of arbitrary puns.
Hence the schemasare tested against the whole lexical knowledge base, to seeif any sequence of items will meet the stated preconditions.Rather than asking, as in informative NLG, ?is the messageof this general shape?
?, the pun generator asks ?are there anyitems which can be put together in this way??.
Thus con-tent selection (which, conventionally, would precede schema-matching) is inherent in this search for matching items.Also, the remits passed from the schema-instantiator to theconstituent builder may be extremely vague, and not directlyrelated to any communicative goals.
For example, generating?Tom Swifties?
requires, for the utterance part of the text, aconstituent to be constructed which is, roughly speaking, ?anysentence which uses this specific word?.These processing characteristics follow naturally from thefact that the pun generators produce self-contained puns, andhence have no communicative goals: any text will do, regard-less of content, providing it constitutes a pun.Hence, although schemas and templates are standard NLGnotions, the freedom allowed to the processing model is lessnormal.
Is this model of wider use?
One possible applica-tion where this arrangement (arbitrary content but constrainedform) might be of use is a language-teaching tool in which theillustrative examples are not all pre-programmed by hand butare machine-generated (either in advance or in response tothe interaction with the human learner).
It is conceivable thata such a system might need to create phrases or sentenceswhich are not embedded in any real context, and for whichthe information conveyed is not critical, but whose linguisticstructure must manifest some particular property (e.g.
usingsome specific word, or being in passive voice).
In that case,the unusual priorities embodied in the JAPE-style architecture(linguistic form over content) might be relevant.The three-stage pun generation architecture allows quiteefficient processing, but the initial lexicon search could becostly if done crudely.
However, given the well-defined na-ture of that search, it can be optimised in various ways;preliminary unpublished results on the STANDUP project[Waller et al, 2005] suggest that fast schema-instantiationfrom a realistically large lexical database is quite feasible.4.4 Usefulness of self-contained punsAlthough a self-contained pun is of use only where it wouldbe helpful to interject a joke for its own sake, it could havea limited degree of contextual connection, in the followingway.
The status of the text as a pun is not context-dependent(otherwise it would be a contextually integrated pun), but itcould mention topics which are currently salient.
For exam-ple, Loehr [1996] describes a very small prototype system inwhich the user interface occasionally tells the user a (JAPE-generated) joke.
Loehr explores limited contextual linking,based on keywords (for example, using a joke involving theword aid when help was needed).Such loose subject matter links do not require computerjoke-generation, but could be achieved from an database ofjokes which had been thoroughly cross-indexed.
This mightbe a viable way to add humour to a user-interface.
Someinvestigation would be needed of what types of semanticlinks give rise to the most appropriate jokes, and the cross-indexing, to be automated, would have to depend on well-defined mechanisable relations (e.g.
from a lexical database).The main weakness of using self-contained puns in practi-cal applications (such as those suggested by writers cited inSection 2) is the lack of a subtle connection to what is go-ing on at the moment of delivery.
Nevertheless, isolated orrandom jokes could still play a role in some applications:Virtual agents: If a life-like image is to have a facetious?personality?, then producing the occasional joke (evena bad one) might be fitting (as in Loehr?s system).Teaching language: An interactive system for assisting lan-guage learners might use jokes as subject matter to bestudied or played with (as proposed by McKay, or by[Manurung et al, 2004]).
In such cases, the jokes mightnot need to be tightly related to context.Again, both these applications could meet the joking re-quirements using a database of jokes, although proponents ofthe educational application might argue that the effect willbe enhanced if the learner can experiment with joke-buildingusing an interactive system; cf.
[Waller et al, 2005].Notice that even a witty advertising slogan, although typ-ically used in an isolated, context-independent fashion, ismore sophisticated than the types of self-contained pun thathave so far been computer generated, in that the content of aslogan is not arbitrary: it has to convey a particular message.In contrast, the systems reviewed in Section 4.1 above giveno regard to the communicative content of the output text.5 A general definitionFrom (2), (3) and other examples, Ritchie [2004] argues thatthere is a relatively well-defined, but large, subclass of punswhich can be summarised thus:(i) part of the utterance is phonetically similar (perhapsidentical) to some other string not present in the utter-ance;(ii) either the utterance, or the utterance with that otherstring substituted in, is contextually appropriate;(iii) if the two substrings are identical, then they should belexically analysable in different ways, and the lexicalanalysis of the one not in the utterance should eitherbe linked semantically to the context, or should involvegrouping together words which are separate within theutterance;(iv) if the two substrings are merely similar, then the un-spoken one should form a complete and recognisablelinguistic unit (e.g.
a complete word or an establishedphrase).
[Ritchie, 2004, pp.125-126]This is probably the best available formal definition of thiskind of pun (see [Davies, 2004]), but it has some limitations(which Ritchie documents) and some weaknesses:(i) This covers only paradigmatic puns, where the com-parison is between two strings, only one of which ac-tually appears in the text.
There are also syntagmaticpuns where both the similar/identical strings appear inthe text; (7) and (8) are very simple examples.
(ii) Where a sequence of words is involved in the pun, eventhe unspoken sequence must ?make sense?
in some way;that is, a pun is not formed when a contextually appropri-ate remark has a portion which is phonetically identicalto some random sequence of words (unless the individ-ual words qualify as puns separately).
We shall assumethis further condition in our discussions.
(iii) In the case where the two strings are merely similar(but not identical) the definition puts no restriction onwhich should appear in the actual text (providing thenon-present text forms a well-known phrase).
However,consider an example like (3), above.
The headline wouldnot have worked as a pun had it simply read ?Super-califragilisticexpialidocious?, as this would not have al-lowed recovery of the contextually-appropriate message(even though it would still conform to Ritchie?s defini-tion).
The correct condition may be better stated in termsof the ease with which the absent string can be sum-moned up or reconstructed, although this is not an un-problematic notion [Hempelmann, 2003].
It may be thatthere is a trade-off between the degree of phonetic simi-larity and the extent to which the string outside the textis a well-known phrase.
Ritchie also cites the headline(15), but this may work because un-bolivia-ble is not avalid word, which may draw attention to the possibilitythat another word or phrase should be considered.
(15) Some South American stamps are un-bolivia-bleThe word unbelievable is not a well-known item in thesense of being famous, but it is cohesive as a morpho-logically complex word.
(iv) The previous point suggests that the condition stipulat-ing that either one of the two similar strings should forma contextually appropriate part of the utterance may, insome cases, be too loose.
(v) Ritchie adopts the widespread assumption that puns aredefined on phonetic strings, as this allows a natural de-scription of the central relationship (phonetic similarity).However, many puns are conveyed in written text, andmost NLG systems produce textual rather than spokenoutput.
When a pun involves two phonetically identicalstrings, the question of which string appears in the ac-tual utterance is moot when all the representations arephonetic; when the text is orthographically represented,the choice of string may affect whether the pun is notice-able to the reader.
It is arguable that (2) would be moreobviously a pun if the final sentence were Your bag?sleeking!
That is, it may improve the effectiveness of thepun to use the textual form which is not completely lin-guistically appropriate (here, there is no verb to leek).Ritchie [2004, p. 199] gives a more formal version of hisdefinition, which makes it clearer what primitive concepts itdepends upon.
These are:Phonetic similarity.
Study of an extensive range of puns(e.g.
[Sobkowiak, 1991]) shows that the degree (and na-ture) of similarity required for punning is not obvious.Contextually appropriate.
Puns are part of a text which?makes sense in context?.
Although this is not unprob-lematic, it is a condition which an NLG system shouldaim for, even if no punning is intended; that is, it is nota further condition imposed by the aim of punning.Linked to the context.
This is a looser notion than ?contex-tually appropriate?.
The linking just means that someconcepts which are salient in the context are some-how related to the concept(s) mentioned in the word orphrase; e.g.
in a situation where cooking is being dis-cussed, words like grill or baste would be linked to thecontext.Forming a recognisable word/phrase.
Puns can depend ona sequence of words being matched against a singleword, or a well-known idiom, motto or quotation.
Itis not clear when a phrase is sufficiently established toqualify.The above definition covers contextually integrated punsrelatively naturally ?
see (2), (4) and the examples in [Ritchie,2004, Ch 9] ?
and is therefore directly relevant to the possiblegeneration of such puns.
Less obviously, the definition couldbe seen as covering self-contained puns (and hence the punsin Section 4), as follows.
The early part of the text (e.g.
thequestion in a riddle) can be treated as the ?context?, and thelatter part (e.g.
the answer to a riddle) as forming the punutterance proper.
That is, self-contained puns can be seen aspuns with their own ?context?
built in, rather than linking tosome context outside the text.6 Computing contextually integrated puns6.1 The usefulness of contextually integrated punsMany of the advocates of useful computational humour seemto have in mind some form of ?wit?
by the computer system,rather than the mere spouting of jokes.
The hypothetical il-lustrations given by Binsted[1995], for example, involve drollobservations by the computer about what is happening at themoment.
Such goals take us in the direction of contextuallyintegrated puns.
More concretely, if puns delivered within aquasi-natural dialogue are not contextually appropriate in anon-trivial way, there is little point in wasting time with com-puter generation; as noted earlier, a large and well-indexeddatabase of jokes would be much more straightforward.Let us consider what would be needed for a system to pro-duce a text which met al the pun conditions given in Sec-tion 5.
We assume that the NLG system will already bestriving for a text which makes sense (in context), so weneed only consider how the further pun conditions might beachieved.
All of these requirements are decidable in princi-ple, although (as noted above) there are non-trivial problemsin defining what should count as sufficient phonetic similar-ity, what counts as an established phrase, and what counts aslinkage to a context.6.2 Detecting punsSuppose some communicative system is to enhance its verbaloutput with puns.
It seems reasonable to propose that sucha system (particularly in cases where this behaviour is to bepart of a life-like ?personality?)
should be ?aware?
of havingmade a pun.
That is, if the system makes a pun, it should havesome record of that having happened, so that it can respondappropriately to, or even anticipate, the user?s reaction.
Ide-ally, the system should also be able to avoid humour whenthis would be socially inappropriate.This suggests that the most minimal form of pun-computation would be checking textual output to see if itcontains accidental puns.
The system would then be in theposition to make sense of any reaction by the user to the pun(or to eliminate any accidental but undesirable humour).
Thiswould not involve any special-purpose text construction ?
thesystem would merely check the output it had designed to meetits current (non-punning) goals.
If unwanted humour is to beeliminated, this is more difficult, as it would require someform of revision component, which is not trivial.Such a scheme could be seen as a special case of a moregeneral post-checking approach, which tests for other desir-able or undesirable properties, such as accidental ambiguity.
(General ambiguity might even constitute a form of fortuitoushumour, but that goes beyond the basic punning we are cur-rently considering.
)As we shall discuss below, the full pun definition mightlead to complex computations.
A simplification which shouldbe more tractable (but might miss more complex puns) wouldbe merely to check each lexical item in the text to determinewhether it had a homophone which was linked to the context.In order to ensure that the user was aware of the pun, thehomophone might have to be substituted into the text (as inour method below, Substitution with identity).Notice that incomplete coverage is something of a flaw ina checking mechanism like this, as the aim is for the systemto spot every occasion on which it makes a pun; if it missessome, then the user might respond to a pun in a way which thesystem cannot easily interpret (or an unwanted joke might slipthrough).
On the other hand, a pun-production mechanism,like those discussed below, need not be comprehensive, aslong as it can produce some puns (and does not cause the textto become faulty in other respects).6.3 The search problemOur working definition (Section 5) involves a combinationof conditions, some of which result in considerable search:finding some substring of the utterance, finding some stringnot in the utterance (a very large set!
), finding some lexicalanalysis of the non-utterance string which meets certain con-ditions, finding some well-known word or phrase which issimilar.
The definition also has a few disjunctions, to furtherincrease the search.
Hence, even a non-constructive check(Section 6.2) would involve a significant amount of search-ing, particularly if na?
?vely implemented.Some of the simpler cases considered below (e.g.
substi-tuting a contextually-linked homophone) might fit naturallyinto a NLG system based on constraint-satisfaction (CS) (cf.
[Power, 2000]).
However, CS methods would not completelyremove the complexity problems involved in implementingthe entire definition from Section 5.
CS reduces process-ing in cases where the possible values of the variables arewell-defined and easily enumerable, and evaluating individ-ual constraints is relatively cheap; i.e.
where the main com-putational load is in testing compatibility among chains ofvalues.
Here, the main work is elsewhere.
Conditions such astesting whether some substring of some possible output stringis similar to some well-known phrase would require compu-tationally expensive enumeration of the basic values (possiblesubstrings of possible output texts), and non-trivial conditions(phonetic similarity) involving very large sets (all words andwell-known phrases).
CS might be slightly better than a na?
?vesearch, but it would not be a panacea.One complicating factor is that the pun criteria are largelysurface constraints which apply to what, in a conventionalpipeline NLG architecture [Reiter and Dale, 2000], would bethe final output of the generator.
Hence, it may be difficultfor high-level (early) stages of a pipeline generator to makesyntactic or lexical decisions which will result in puns, noris it simple to effect ?revisions?
to a surface text which hasbeen the outcome of much high-level processing.
There isnot space here to explore the large issue of surface-level con-straints and their consequences for NLG architecture, but see[Reiter, 2000] for some discussion.Puns are not the only forms in which surface constraints arecentral: poetry generation [Manurung et al, 2000; Gerva?s,2002] makes comparably awkward demands.6.4 Some possible devicesWe can consider some possible ways in which an NLG sys-tem might include contextually integrated puns.Substitution with identity.
The crudest approach to actualpun-generation would be to attach a punning module as a finalstage.
This module would review the entire text as generatedand see whether it could be edited to form a pun, while mak-ing as few revisions as possible ?
preferably none ?
to pre-vious higher-level decisions.
The simplest tactic here wouldbe the substitution of a phonetically similar (and internallycoherent) string for some subpart of the message, where thesubstituted string does not represent the same lexical itemsas those in the original message, and either the content ofthe substituted string is somehow linked to the context or thesubstituted version should represent a finer segmentation ofthe material into words.
Even for this very basic method, thesearch is considerable.
A simplified version could be limitedto looking for homophones of words in the message, and sub-stituting these providing they were contextually linked; thisis probably the most tractable option.Substitution with similarity.
A slight extension of the pre-vious method would be to relax the condition from phoneticidentity to phonetic similarity.
However, some care wouldbe needed in deciding under what conditions this should bepermitted, in view of the point raised earlier about the ?re-coverability?
of the contextually appropriate string.
(This ex-tension worsens the search problem.
)Minor rephrasing.
It is conceivable that a surface-basedediting component could detect that a minor re-wordingwould fulfil the pun conditions.
However, such changesshould not impair the overall message of the text, whichmeans that this is not an easy solution.Lexical preference.
Rather than using a post-editing stage,we could build the pun facilities into a higher level ofthe NLG system.
One possibility would be some form ofamended lexical choice, within the NLG process (i.e.
notpost-editing as in the above mechanisms).
The system could,when choosing a lexical item, give preference (if it would notdistort the intended message) to a word which has a homo-phone which is in some way linked to the context.
It mightalso be helpful to use that homophone in the text, to make thepun obvious to the reader, as noted previously.
An extensionwould be to have the lexical choice system seek a phoneti-cally similar item (not a strict homophone) which is associ-ated with the context.
In this case, inserting that other wordin the text (in place of the more directly correct one) wouldbe not just helpful but necessary.Rephrasing for lexical preference.
The previous devicecould perhaps be generalised, depending on how the genera-tor organises lexical choice, to giving preference to a phrasing(not just the choice of a single word in isolation) which con-tains a word with a homophone/similar word which meets thepun conditions.
This increases the amount of searching thatthe NLG system would require.Matching against phrases.
A further generalisation wouldbe for the system to seek not an identical/similar word, buta phrase (similar/identical to a valid wording of the intendedmessage) which met the pun conditions (perhaps, as in exam-ple (3), matching one word against several).
These conditions(Section 5) for a phrase are slightly different from those for aword.
To consider matching all possible well-known phrases(assuming such a database were available) when constructinga sentence would lead to high search costs.Some of these processes could be quite open-ended, aspuns (human-constructed) sometimes involve quite global re-phrasing in order to achieve the punning effect.
The subeditorwho created (3) must have planned the entire headline withthe word Supercalifragilisticexpialidocious in mind.The later tactics (Rephrasing for lexical preference, Match-ing against phrases) would be more easily incorporated intoa generator which was opportunistic about what material toinclude.
For example, the ILEX text generator [Oberlander etal., 1998] has a content selection stage in which the knowl-edge base is traversed to gather facts to be expressed.
Thisis not as free as the process in Section 4.2 above, as ILEXstarts from a particular knowledge base object which is to bedescribed, and the search is for facts relevant to that object.The STREAK system [Robin, 1994] can produce variants ofa text in which different amounts of supporting information(for the central proposition) are included.
The choice of thisadditional information could allow more freedom to a pun-devising algorithm (although still with significant search).Even if any of these pun-creating schemes were imple-mented, it is quite likely that in many cases no suitable matchwould be found, and text realisation would have to proceed asnormal.
That is, the pun-condition checking might be wastedeffort, just adding to the generation time for the text.7 ConclusionsWe have seen that existing pun generators assume a relativelysimple rule-based generation architecture, but the way thatthis architecture has been used is not typical of NLG tasks.These generators produce self-contained puns, but such jokeswould be of potential use only in certain applications (wherebald joke-telling is acceptable, or where language is to bestudied rather than used in natural communication).
The casefor using contextually integrated puns to enhance computersystems is more plausible, but in the most general case thiscould lead to computational complexity.
Nevertheless, theremay be some tractable ?tricks?
which an NLG system coulduse to produce very simple contextually-integrated puns.Acknowledgements: This paper benefitted from commentsfrom the Aberdeen NLG group, and from Ruli Manurung.References[Binsted and Ritchie, 1997] Kim Binsted and GraemeRitchie.
Computational rules for generating punning rid-dles.
Humor: International Journal of Humor Research,10(1):25?76, 1997.
[Binsted, 1995] Kim Binsted.
Using humour to make naturallanguage interfaces more friendly.
In Hiroaki Kitano, ed-itor, Proceedings of the International Joint Conference onArtificial Intelligence Workshop on AI and Entertainment,pages 55?57, Montreal, 1995.
[Binsted, 1996] Kim Binsted.
Machine humour: An imple-mented model of puns.
PhD thesis, University of Edin-burgh, Edinburgh, Scotland, October 1996.
[Davies, 2004] Christie Davies.
Review of ?The linguis-tic analysis of jokes?.
Journal of Literary Semantics,33(2):196?197, 2004.
[Gerva?s, 2002] Pablo Gerva?s.
Exploring quantitative evalua-tions of the creativity of automatic poets.
In Carlos Bento,Amilcar Cardoso, and Geraint Wiggins, editors, 2nd Work-shop on Creative Systems, Approaches to Creativity inArtificial Intelligence and Cognitive Science, ECAI 2002,Lyon, France, 2002.
[Hempelmann, 2003] Christian Hempelmann.
ParonomasicPuns: Target Recoverability Towards Automatic Genera-tion.
PhD thesis, Purdue University, 2003.
[Hulstijn and Nijholt, 1996] Joris Hulstijn and Anton Ni-jholt, editors.
Proceedings of the International Workshopon Computational Humor, number 12 in Twente Work-shops on Language Technology, Enschede, Netherlands,September 1996.
University of Twente.
[Kukich, 1983] Karen Kukich.
Design of a knowledge-based report generator.
In Proceedings of the 21st AnnualMeeting of the Association for Computational Linguistics,pages 145?150.
ACL, 1983.
[Lessard and Levison, 1992] Greg Lessard and Michael Lev-ison.
Computational modelling of linguistic humour: TomSwifties.
In ALLC/ACH Joint Annual Conference, Oxford,pages 175?178, 1992.
[Lessard and Levison, 1993] Greg Lessard and Michael Lev-ison.
Computational modelling of riddle strategies.
InALLC/ACH Joint Annual Conference, Georgetown Uni-versity, Washington, DC, pages 120?122, 1993.
[Levison and Lessard, 1992] Michael Levison and GregLessard.
A system for natural language generation.
Com-puters and the Humanities, 26:43?58, 1992.
[Loehr, 1996] Dan Loehr.
An integration of a pun genera-tor with a natural language robot.
In Hulstijn and Nijholt[1996], pages 161?172.
[Lyttle, 2001] Jim Lyttle.
The effectiveness of humor in per-suasion: The case of business ethics training.
Journal ofGeneral Psychology, 128(3):206?216, April 2001.
[Manurung et al, 2000] Hisar Maruli Manurung, GraemeRitchie, and Henry Thompson.
A flexible integratedarchitecture for generating poetic texts.
In Proc ofthe Fourth Symposium on Natural Language Processing(SNLP 2000), pages 7?22, Chiang Mai, Thailand, 2000.
[Manurung et al, 2004] Ruli Manurung, Alistair Low, Lu-cia Trujillo-Dennis, David O?Mara, Helen Pain, GraemeRitchie, and Annalu Waller.
Interactive computer genera-tion of jokes for language skill development.
Talk at An-nual Conference of the International Society for HumorStudies, June 2004.
Dijon, France.
[McKay, 2002] Justin McKay.
Generation of idiom-basedwitticisms to aid second language learning.
In Stock et al[2002], pages 77?87.
[McKeown, 1985] Kathleen McKeown.
Text Generation.Studies in Natural Language Processing.
Cambridge Uni-versity Press, Cambridge, UK, 1985.
[Morkes et al, 1999] John Morkes, Hadyn K. Kernal, andClifford Nass.
Effects of humor in task-oriented human-computer interaction and computer-mediated communica-tion: A direct test of srct theory.
Human-Computer Inter-action, 14(4):395?435, 1999.
[Nijholt, 2002] Anton Nijholt.
Embodied agents: A new im-petus to humor research.
In Stock et al [2002], pages 101?111.
[Oberlander et al, 1998] Jon Oberlander, Mick O?Donnell,Alistair Knott, and Chris Mellish.
Conversation in the mu-seum: experiments in dynamic hypermedia with the intel-ligent labelling explorer.
New Review of Hypermedia andMultimedia, pages 11?32, 1998.
[O?Mara and Waller, 2003] Dave A. O?Mara and AnnaluWaller.
What do you get when you cross a communica-tion aid with a riddle?
The Psychologist, 16(2):78?80,2003.
[Pereira and Warren, 1980] F. Pereira and D. H. D. Warren.Definite clause grammars for language analysis ?
a surveyof the formalism and a comparison with augmented tran-sition networks.
Artificial Intelligence, 13:231?278, 1980.
[Power, 2000] Richard Power.
Planning texts by constraintsatisfaction.
In Proceedings of the 18th International Con-ference on Computational Linguistics (COLING-2000),pages 642?648, Saarbru?cken, Germany, 2000.
[Reiter and Dale, 2000] Ehud Reiter and Robert Dale.
Build-ing Natural Language Generation Systems.
CambridgeUniversity Press, Cambridge, UK, 2000.
[Reiter, 2000] Ehud Reiter.
Pipelines and size constraints.Computational Linguistics, 26(2):251?259, June 2000.
[Ritchie, 2003] Graeme Ritchie.
The JAPE riddle genera-tor: technical specification.
Informatics Research ReportEDI-INF-RR-0158, School of Informatics, University ofEdinburgh, Edinburgh, February 2003.
[Ritchie, 2004] Graeme Ritchie.
The Linguistic Analysis ofJokes.
Routledge, London, 2004.
[Robin, 1994] Jacques Robin.
Revision-Based Generation ofNatural Language Summaries Providing Historical Back-grouns: Corpus-Based Analysis, Design, Implementationand Evaluation.
PhD thesis, Columbia University, 1994.
[Sobkowiak, 1991] Wlodzimierz Sobkowiak.
Metaphonol-ogy of English Paronomasic Puns, volume 26 of Univer-sity of Bamberg Studies in English Linguistics.
Peter Lang,Frankfurt, 1991.
[Stock et al, 2002] Oliviero Stock, Carlo Strapparava, andAnton Nijholt, editors.
Proceedings of the April Fools?Day Workshop on Computational Humor, number 20 inTwente Workshops on Language Technology, Enschede,Netherlands, April 2002.
University of Twente.
[Stock, 2002] Oliviero Stock.
Computational humor.
In Ste-fano A. Cerri, Guy Gouarde`res, and Fa?bio Paraguac?u, ed-itors, Intelligent Tutoring Systems: Proceedings of the 6thInternational Conference, Lecture Notes in Computer Sci-ence, pages 2?3, Berlin, 2002.
Springer.
Invited talk.
[Stock, 2003] Oliviero Stock.
?Password Swordfish?
: Verbalhumor in the interface.
Humor: International Journal ofHumour Research, pages 281?295, 2003.
[Venour, 1999] Chris Venour.
The computational generationof a class of puns.
Master?s thesis, Queen?s University,Kingston, Ontario, 1999.
[Waller et al, 2005] Annalu Waller, Dave O?Mara, Ruli Ma-nurung, Helen Pain, and Graeme Ritchie.
Facilitating userfeedback in the design of a novel joke generation systemfor people with severe communication impairment.
InProceedings of 11th International Conference on Human-Computer Interaction, Las Vegas, July 2005.
