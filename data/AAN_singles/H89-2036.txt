Automatic New Word Acquisition:Spelling from AcousticsFil Alleva and Kai-Fu LeeSchool of Computer ScienceCarnegie Mellon UniversityPittsburgh, PAAbstractThe problem of extending the lexicon of words in an automatic speech recognition system is com-monly referred to as the the new word problem.
When encountered in the context of an embedded speechrecognition system this problem can be be divided into the following sub-problems.
First, identify thepresence of a new word.
Second, acquire a phonetic transcription of the new word.
Third, acquire theorthographic transcription (spelling) of the new word.
In this paper we present the results of a preliminarystudy that employs a novel approach to the problem of acquiring the orthographic transcription throughthe use of an n-gram language model of english spelling and a quad-letter labeling of acoustic models thatwhen taken together potentially produce an acoustic to spelling transcription of any spoken input.IntroductionThis paper focuses on t_he problem of acquiring the orthographic transcription of new words andexplicitly ignores the problems of identifying the presence of a new word and generating the phoneticbase-form of the new word.
The approach that we employ here is to map directly from the acousticevidence to an orthographic transcription.
In other words we model the acoustics of our training set basedon the readily available orthographic transcription of the sentence instead of a phonetic transcription.
Thelanguage model that we employ is the familiar n-gram model.
Our model consists of a five gram with 27tokens, A through Z plus blank.
One may reasonably ask what led us to think that a reasonable vel ofperformance would be possible.
A question is the answer in this case.
Ask yourself how many guessesyou might require to get the fifth letter correct in a five letter sequence if you had been given the previous4 letters?
We guessed that a perplexity of english spelling might be somewhere between two and five fora five gram language model.
A more detailed analysis of the perplexity of english spelling can be foundin \[Shannon 51\].
Given such a low perplexity we believed it would be possible to overcome much of theinherent ambiguity in english spelling.Acoustic ModelsSignal ProcessingThe signal processing front-end used in this work is identical to the Sphinx front-end \[Lee 89\].
Wecomputed power and 12 bilinear-transformed LPC cepstral coefficients, which are then quantized intothree different codebooks: (1) 12 stationary coefficients, (2) 12 differential coefficients, and (3) powerand differenced power.
Each codebook has 256 entries, thereby reducing each centisecond of speech intothree bytes.266HMM InventoryIn most speech recognition systems, subword units are based on phonemes, which we believe to bemost appropriate for this task as well.
However, deriving orthography from phonemic units requires aprobabilistic phoneme-to-spelling component, as well as a complex search algorithm that satisfies or-thographic as well as phonemic ontext constraints.
This was considerably more effort than warranted fora preliminary study such as this one.
Therefore, we compromised some accuracy by using letters of thealphabet and blank as our speech unit.
In other words, a hidden Markov model represents each letter ofthe alphabet.One serious problem with letter models is that letters are highly context-dependent -- much more sothan phonemes.
For example, the "h" in "sh", "ch", "th", "eh", are extremely different.
In order to dealwith this problem, we modeled the letters in a context-dependent fashion.
Since there are only 28 units(26 letters, blank, and silence), we could afford to train very detailed units that model each letter in thecontext of its two left letters and one right letter.
We shall refer to this model as the quad-lener model.For example, the letter "h" in the word "school" is aware that its two left neighbors are "s" and "c", andthat its right neighbor is "o".
From this information, the proper pronunciation of each letter can beinferred, and context can be modeled in the same spirit as triphones \[Schwartz 85\].
Since not all quad-letters occur frequently enough, we model only those that occur often enough.
The less frequent oneswould be merged into tri-letter (one left and one right context) or bi-letter (right context only) models.This resulted in a total of 1427 quad-letter models.Another problem is that letters do not always have acoustic realizations.
For example, the letters"g" and "h" are silent in night.
In order to deal with this problem, we used a hidden Markov model thatallowed the entire model to be skipped.
Our model is shown in Figure 1.
Since this skip probability iscontext-dependent, silent letters will have very high probabilities of being skipped.B M E\ _./Figure h The Quad-Letter HMM267HMM TrainingWe used a total of 15,000 training sentences to train the quad-letter models.
The training dataincluded Resource Management, TIMIT, as well as locally-recorded Harvard sentences and GeneralEnglish database.
These databases are described in \[Hon 89\].First, an inventory of 1427 models was detemined by examining the frequencies of the quad-lettersin the training set.
These models are trained on sentences of connected speech, using an initializationfrom the context-independent l t er models.
During the quad-letter t aining, for each sentence, the cor-responding quad-letters of each word are concatenated.
Two words are connected by a blank, and silencemodels are used in the beginning and the end of the sentence.
Thus, the blank model could correspond tosilence, glottal stop, or nothing.
Therefore, we model blank in a context-dependent fashion, in the samemanner as quad-letters.
A single silence model is used, but silence is used as a letter-context for quad-letters.Two iterations of the forward-backward algorithm were run, and the resulting quad-letter models aresmoothed by deleted interpolation \[Jelinek 80\] with contextlindependent l tter models.Language ModelsThe language model used here is a five gram model where we determine P(14/11121315) based on atraining set.
It is possible to train this five gram model because the size of the lexicon is only 27, ie.
theletters A through Z plus blank.
So there are potentially 275 (14,348,907) probabilities to determine.
Totrain this model we chose a suitably large data base in the digital version of the Academic AmericanEncyclopedia.
The encyclopedia was preprocessed to remove tokens that were not part of the the 27token lexicon as well as tokens that were likely to add noise to the language model.
Examples of such'noise' tokens would be those tokens that appeared between delimiters uch as 0 and \[\] and those tokensthat appeared in sentences that were fewer than ten tokens in length.
After preprocessing 45 milliontokens remained from which two language models were developed.
The first language model included theblank token and modeled spelling across word boundaries.
The second model did not contain the blanktoken and modeled the spelling of words in an unspecified context.
Finally, in each of these languagemodels, the five grams where interpolated with their four grams and the four grams with their three gramsetc.
when the number of observations was below a specified threshold.
For the sake of simplicity in therecognizer five grams that were not observed are assumed to have a probability of zero.
We note here thatall of the five grams in our test happened to be modeled in the training set even though the two data setswere disjoint.Recognition SystemThe recognition system used is a version of the one used in Sphinx \[Lee 89\] with the followingadditions.
First we adapted it to compute the additional null transition in the acoustic models and secondwe adapted it to be able to manipulate our simplified five gram language model.268Results for continuous peechTwo experiments were perfomaed.
The first experiment was performed on a set of 25 generalenglish sentences from 5 different speakers.
For this experiment the language model that included blankwas used.
The results were a letter accuracy of 59.3% and an error rate of 54.3%.
The spelling perplexityof this test set was 2.09.
One problem we observed was that the system was unable to reliably fred correctword boundaries and that this was a source of many errors.
Below we present he two most accuratelytranscribed sentences from this experiment.SENTENCE 1 (ge4214)Cor rect  = 77.1%, Er rors  = 43.8%REF:he  was a l so  NOUr* IsH** inG A h*atRed**  OF***  in te l lec tu*a lsHYP:he  was  a l so  MARRY sTRA in*  **hEat*ed  A UNDED in te l lec tuRa lsSENTENCE 23 (ge4262)Cor rect  = 79.4%, Er rors  = 33.3%REF:Hof fe r  EAr*nED h is  l i v ing  asA  d ish*wash**e**RHYP:Cof fe r  *Pr In*G h is  l i v ing  as**d ish  wash IReD AREF : Lumber** jackAND migrantHYP :NumberG jack*IM*migrantResults for end point detected embedded wordsThe second experiment perhaps is more indicative of the conditions an acoustic to spellingtranscriber will be expected to operate in.
In this experiment we identified 30 ship and place names fromthe 1987 Resource Management test set.
Using the begin and end times identified by the Sphinx recog-nizer we analyzed this portion of the utterance with the second language model (the one that does notcontain blank).
The results were a letter accuracy of 72.7% and an error rate of 39.3% and a stringaccuracy of 21.1%.
The spelling perplexity of the test set words was 4.04.
It is not surprising that thisperplexity is twice as large as the General English test set since the spelling for names is not as wellconstrained as the rest of english spelling.
Despite this higher perplexity, the accuracy is much improvedover the previous experiment though it remains to be seen if the end points of unknown words can bedetermined as accurately as the end points determined by Sphinx when it knew the word in question.SummaryThe performance is still too low to suggest that this approach be employed to address the new wordproblem.
In future work we will address the use of phonetic units for acoustic modeling with an inter-mediate mapping from phonetic units to english spelling or perhaps to the syllable level and then toenglish spelling.
Also the problems of identifying the presence of a new word and of creating the base-form for the new word must be addressed before we can fully integrate the new word into a speechrecognizer.269\[Hon 89\]\[Jelinek 80\]\[Lee 89\]\[Schwartz 85\]\[Shannon 51 \]ReferencesHon, H.W., Lee, K.F., Weide, R.Towards Speech Recognition Without Vocabulary-Specific Training.Submitted to Eurospeech '89.1989Jelinek, F., Mercer, R.L.Interpolated Estimation of Markov Source Parameters from Sparse Data.In E.S.
Gelsema nd L.N.
Kanal (editor), Pattern Recognition i  Practice, pages381-397.
North-Holland Publishing Company, Amsterdam, the Netherlands, 1980.Lee.
K.F., Hon, H.W., Hwang, M.Y., Mahajan, S., Reddy, R.The SPHINX Speech Recognition System.In IEEE International Conference on Acoustics, Speech, and Signal Processing.
April,1989.Schwartz, R., Chow, Y., Kimball, O., Roucos, S., Krasner, M., Makhoul, J.Context-Dependent Modeling for Acoustic-Phonetic Recognition of ContinuousSpeech.In IEEE International Conference on Acoustics, Speech, and Signal Processing.
April,1985.Shannon.Prediction and Entropy of Printed English.Bell Systems Technical Journal 30:50-64, 1951.270
