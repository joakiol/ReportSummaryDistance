FEATURE LOGIC  WITH WEAK SUBSUMPTIONCONSTRAINTSJochen DbereIBM Deutschland OmbHScience Center - IKBSP.O.
Box 80 08 80D-7000 Stuttgart 80, GermanyABSTRACTIn the general framework of a constraint-basedgrammar formalism often some sort of featurelogic serves as the constraint language to de-scribe linguistic objects.
We investigate the ex-tension of basic feature logic with subsumption(or matching) constraints, based on a weak no-tion of subsumption.
This mechanism of one-way information flow is generally deemed to benecessary to give linguistically satisfactory de-scriptions of coordination phenomena in suchformalisms.
We show that the problem whethera set of constraints i satisfiable in this logic isdecidable in polynomial time and give a solutionalgorithm.1 IntroductionMany of the current constralnt-based grammarformalisms, as e.g.
FUG \[Kay 79, Kay 85\], LFG\[Kaplan/Bresnan 82\], HPSG \[Pollard/Sag 87\],PATR-II \[Shieber et al 83\] and its derivates,model linguistic knowledge in recursive fea-ture structures.
Feature (or functional) equa-tions, as in LFG, or feature terms, as in FUGor STUF \[Bouma et al 88\], are used as con-straints to describe declaratively what proper-ties should be assigned to a linguistic entity.In the last few years, the study of the for-real semantics and formal properties of logicsinvolving such constraints has made substan-tial progress \[Kasper/Rounds 86, Johnson 87,Smolka 88, Smolka 89\], e.g., by making precisewhich sublanguages of predicate logic it corre-sponds to.
This paves the way not only for reli-able implementations of these formalisms, butalso for extensions of the basic logic with aprecisely defined meaning.
The extension wepresent here, weak subsumption constraints, isa mechanism of one-way information flow, oftenproposed for a logical treatment of coordinationin a feature-based unification grammar.
1 It canI Another application would be type inference in agrammar formalism (or programming language) thatbe informally described as a device, which en-ables us to require that one part of a (solution)feature structure has to be subsumed (be an in-stance of) another part.Consider the following example of a coordina-tion with "and", taken from \[Shieber 89\].
(1) Pat hired \[tcP a Republican\] and\[NP a banker\].
(2) *Pat hired \[NP a Republican\] andlAP proud of it\].Clearly (2) is ungrammatical since the verb"hire" requires a noun phrase as object com-plement and this requirement has to be ful-filled by both coordinated complements.
Thissubcategorization requirement is modeled ina unification-based grammar generaUy usingequations which cause the features of a comple-ment (or parts thereof encoding the type) to getunified with features encoding the requirementsof the respective position in the subcategoriza-tion frame of the verb.
Thus we could assumethat for a coordination the type-encoding fea-tures of each element have to be "unified into"the respective position in the subcategorisationframe.
This entails that the coordinated ele-ments are taken to be of one single type, whichthen can be viewed as the type of the wholecoordination.
This approach works fine for theverb "hire", but certain verbs, used very fre-quently, do not require this strict identity.
(3) Pat has become \[NP a banker\] and\[AP very conservative\].
(4) Pat is lAP healthy\] and \[pp ofsound mind\].The verb "become" may have either noun-phrase or adjective-phrase complements, "tobe" Mlows prepositional and verb phrases inaddition, and these may appear intermixed ina coordination.
In order to allow for such"polymorphic" type requirements, we want tol~e~ a-type discipline with polymorphic types.256state, that (the types of) coordinated argumentseach should be an instance of the respective re-quirement from the verb.
Expressed in a gen-eral rule for (constituent) coordination, we wantthe structures of coordinated phrases to be in-stances of the structure of the coordination.
Us-ing subsumption constraints the rule basicallylooks like this:E ~ C and  DE~CE~DWith an encoding of the types like the one pro-posed in HPSG we can model the subcatego-risation requirements fo r " to  be" and "to be-come" as generalizations ofall allowed types (cf.Fig.
1).i n: \] \] NP= v :  - AP= v:  +bar :  2 bar :  2VPffi v: + PP= v: -bar :  2 bar :  2'to be' requires: 'to become' requires:Figure 1: Encoding of syntactic typeA similar treatment of constituent coordina-tion has been proposed in \[Kaplan/Maxwell 88\],where the coordinated elements are required tobe in a set of feature structures and where thefeature structure of the whole set is defined asthe generalisation (greatest lower bound w.r.t.subsumption) of its elements.
This entailsthe requirement stated above, namely that thestructure of the coordination subsumes those ofits elements.
In fact, it seems that especially inthe context of set-valued feature structures (cf.\[Rounds 88\]) we need some method of inheri-tance of constraints, since if we want to stategeneral combination rules which apply to theset-valued objects as well, we would like con-straints imposed on them to affect also theirmembers in a principled way.Now, recently it turned out that a feature logicinvolving subsumption constraints, which arebased on the generally adopted notion of sub-sumption for feature graphs is undecidable (cf.\[D rre/Rounds 90\]).
In the present paper wetherefore investigate a weaker notion of sub-sumption, which we can roughly characterize as257relaxing the constraint hat an instance of a fea-ture graph contains all of its path equivalencies.Observe, that path equivalencies play no role inthe subcategorisation requirements in our ex-amples above .
.
.
.
.
.
~2 Feature  A lgebrasIn this section we define the basic structureswhich are possible interpretations of feature de-scriptions, the expressions of our feature logic.Instead of restricting ourselves to a specific in-terpretation, like in \[Kasper/Rounds 86\] wherefeature structures are defined as a special kindof finite automata, we employ an open-world se-mantics as in predicate logic.
We adopt mostof the basic definitions from \[Smolka 89\].
Themathematical structures which serve us as in-terpretations are called feature algebras.We begin by assuming the pairwise disjoint setsof symbols L, A and V, called the sets of fea-tures (or labels), atoms (or constants) and vari-ables, respectively.
Generally we use the letters/ ,g,  h for features, a, b, c for atoms, and z, ~, zfor variables.
The letters s and t always denotevariables or atoms.
We assume that there areinfinitely many variables.A feature algebra .A is a pair (D ~4, ..4) consistingof a nonempty set D ~t (the domain of.4) and aninterpretation .~ defined on L and A such that* a ~4 E D "4 for a E A.
(atoms are constants)?
I fa  ~ b then a "4 ~ b ~4.
(unique name as-sumption)?
If f is a feature then/~4 is a unary partialfunction on D ~4.
(features are functional)?
No feature is defined on an atom.Notat ion .
We write function symbols on theright following the notation for record fields incomputer languages, so that f(d) is written dr.If f is defined at d, we write d.f ~, and other-wise d/ T. We use p ,q , r  to denote strings offeatures, called paths.
The interpretation func-tion .Jr is straightforwardly extended to paths:for the empty path e, ~.4 is the identity on D~4;for a path p = fl  .
.
.
f - ,  p~4 is the unary partialfunction which is the composition of the filnc-tions fi"4.., f.4, where .fl "4 is applied first.A feature algebra of special interest is the Fea-tu re  Graph A lgebra  yr  since it is canonicalin the sense that whenever there exists a solu-tion for a formula in basic feature logic in somefeature algebra then there is also one in the Fea-ture Graph Algebra.
The same holds if we ex-tend our logic to subsumption constraints (see~DSrre/Rounds 90\]).
A feature graph is a rootedand connected directed graph.
The nodes areeither variables or atoms, where atoms may ap-pear only as terminal nodes.
The edges are la-beled with features and for every node no twooutgoing edges may be labeled with the samefeature.We formalize feature graphs as pairs (s0, E)where So E VUA is the root and E C V xL x (V U A) is a set of triples, the edges.
Thefollowing conditions hold:1.
If s0EA,  thenE=0.2.
If (z, f, s) and (z, f, t) are in E, then s : t.3.
If (z, f, 8) is in E, then E contains edgesleading from the root s0 to the node z.Let G - (z0, E) be a feature graph containingan edge (z0, f,  s).
The subgraph under f of G(written G/ f )  is the maximal graph (s, E') suchthat E t C E.Now it is clear how the Feature Graph Algebra~" is to be defined.
D ~r is the set of all featuregraphs.
The interpretation of an atom a ~r is thefeature graph (a, ~), and for a feature f we letG.f 7~ = G/.f, if this is defined.
It is easy toverify that ~r is a feature algebra.Feature graphs are normally seen as data ob-jects containing information.
From this view-point there exists a natural preorder, called sub-sumptlon preorder, that orders feature graphsaccording to their informational content herebyabstracting away from variable names.
We donot introduce subsumption on feature graphshere directly, but instead we define a subsump-tion order on feature algebras in general.Let .A and B be feature algebras.
A s imulat ionbetween .A and B is a relation A C D ~4 ?
D vsatisfying the following conditions:1. if (a ~4, d) E A then d = a B, for each atoma, and2.
for any d E D~,e  E D B and f E L: ifdf A ~ and (d,e) E A, then ef  B ~ and(dr ~4, ef B) E A.Notice that the union of two simulations andthe transitive closure of a simulation are alsosimulations.A partial homomorph lsm "y between .A andB is a simulation between the two which is apartial function.
If.A = B we also call T a partialendomorphism.Def in i t ion.
Let .A be a feature algebra.
The(s t rong)  subsumpt ion  preorder  ff_A and258the weak subsumpt ion  preorder  ~4 of ~4are defined as follows:* d (strongly) subsumes e (written d E ~4 e)iff there is an endomorphism "ysuch that= e .
* d wealcly subsumes e (written d ~4 e) iffthere is a simulation A such that dAe.It can be shown (see \[Smolka 89\]) that thesubsumption preorder of the feature graphalgebra coincides with the subsumption or-der usually defined on feature graphs, e.g.
in\[Kasper/Rounds 86\].Example: Consider the feature algebra de-picted in Fig.
2, which consists of the elements{1, 2, 3, 4, 5, a, b) where a and b shall be (the pic-tures of) atoms and f, g, i and j shall be featureswhose interpretations are as indicated.i i simulation Af g 1A32A42A5aAabAba a bFigure 2: Example of Weak SubsumptionNow, element 1 does not strongly subsume 3,since for 3 it does not hold, that its f-valueequals its g-value.
However, the simulation Ademonstrates that they stand in the weak sub-sumption relation: 1 ~ 3.3 Const ra in tsTo describe feature algebras we use a relationallanguage similar to the language of feature de-scriptions in LFG or path equations in PATR-II.
Our syntax of constraints hall allow for theformszp "-- ~q, zp "-- a, zp ~ ~qwhere p and q are paths (possibly empty), a EA, and z and ~/are variables.
A feature  c lauseis a finite set of constraints of the above forms.As usual we interpret constraints with respectto a variable assignment, in order to make surethat variables are interpreted uniformly in thewhole set.
An ass ignment  is a mapping ~ ofvariables to the elements of some feature alge-bra.
A constraint ~ is satisfied in .,4 under as-signment a, written (A, a) ~ ~, as follows:(.,4, a) ~ zp - vq iff a(z)p A = a(v)q A(.4, a) ~ zp -- a aft a(z)p Aif  (v)qA.The so lut ions  of a clause C in a feature alge-bra .4 are those assignments which satisfy eachconstraint in C. Two clauses C1 and C2 areequiva lent  iff they have the same set of solu-tions in every feature algebra .A.The problem we want to consider is the follow-ing:Given a clause C with symbols fromV, L and A, does C have a solution insome feature algebra?We call this problem the weak semiunificationproblem in feature algebras)4 An A lgor i thm4.1 P reso lved  FormWe give a solution algorithm for feature clausesbased on normalization, i.e.
the goal is to de-fine a normal form which exhibits unsatisfiabil-ity and rewrite rules which transform each fea-ture clause into normal form.
The normal formwe present here actually is only half the way toa solution, but we show below that with the useof a standard algorithm solutions can be gener-ated from it.First we introduce the restricted syntax of thenormal form.
Clauses containing only con-straints of the following forms are called sim-ple:z f  - -y ,  z - - s ,  z ~ ywhere s is either a variable or an atom.
Eachfeature clause can be restated in linear time asan equisatisfiable simple feature clause whosesolutions are extensions of the solutions of theoriginal clause, through the introduction of aux-iliary variables.
This step is trivial.A feature clause C is called preso lved  iff it issimple and satisfies the following conditions.~The anMogous problem for (strong) subsumptionconstraints i undecidable, ven if we restrict ourselvesto finite feature algebras.
Actually, this problem couldbe shown to be equivalent to the semiunification prob-lem for rational trees, i.e.
first-order terms which maycontain cycles.
The interested reader is referred to\[D~rre/Rounds 90\].C1.
If z - ~/is in C, then z occurs exactly oncein C.C2.
I f z f -yandz f -zare inC ,  theny=z.C3.
I f z~vandy~zare inC ,  thenz~z isin C (transitive closure).C4.
I f z  ~V and z f - -  z t and Vf -- V t are inC, then z' ~ V' is in C (downward propa-gation closure).In the first step our algorithm attempts to trans-form feature clauses to presolved form, therebysolving the equational part.
In the simplifica-tion rules (cf.
Fig.
3) we have adapted someof Smolka's rules for feature clauses includingcomplements \[Smolka 89\].
In the rules \[z/s\]Cdenotes the clause C where every occurrence ofz has been replaced with s, and ~ & C denotesthe feature clause {~} U C provided ~b ~ C.Theorem 1 Let C be a simple feature clause.ThenI.
if C can be rewritten to 19 using one ofthe rules, then 1) i8 a simple feature clauseequivalent to C,f.
for every non-normal simple feature clauseone of the rewrite rules applies,3.
there is no infinite chain C --* U1 --* C2 --,ProoL  3 The first part can be verified straight-forwardly by inspecting the rules.
The sameholds for the second part.
To show the termina-tion claim first observe that the application ofthe last two rules can safely be postponed untilno one of the others can apply any more, sincethey only introduce subsumption constraints,which cannot feed the other rules.
Now, calla variable z isolated in a clause C, if C containsan equation z - 7/and z occurs exactly once inC.
The first rule strictly increases the numberof isolated variables and no rule ever decreasesit.
Application of the second and third rule de-crease the number of equational constraints orthe number of features appearing in C, whichno other rule increase.
Finally, the last tworules strictly increase the number of subsump-tion constraints for a constant set of variables.Hence, no infinite chain of rewriting steps maybe produced.
\[\]We will show now, that the presolved form canbe seen as a nondeterministic finite automaton~Part of this proof has been directly adapted from\[S molka 89\].259z -y&Cz -z&Cz f  -1/  gr z f  - z & Cz g ~ z t z C--4 z - - l /  & \[z/1/\]C, if z occurs in C and z~l /--, C--+ z~y&zf  "--z'gryf "--yt&zt~y'&Cif z t ~ ~ ~ C(1)(2)(3)(4)Ca)Figure 3: Rewriting to presolved formwith e-moves and that we can read off solutionsfrom its deterministic equivalent, if that is ofa special, trivially verifiable, form, called clash-bee.4.2 The  Trans i t ion  Re la t ion  6c of  aP reso lved  C lause  CThe intuition behind this construction is, thatsubsumption constraints basically enfoice thatinformation about one variable (and the spaceteachable hom it) has to be inherited by (copiedto) another variable.
For example the con-straints z H y and zp - a entail that alsolip - a has to hold.
4 Now, if we have a con-straint z ~ T/, we could think of actually copyingthe information found under z to y, e.g.
z f  - z ~would be copied to 1/f - 1/t, where 1/I is a newvariable, and z I would be linked to yl by z p ~ ?/.However, this treatment is hard to control in thepresence of cycles, which always can occur.
In-stead of actually copying we also can regard aconstraint z g 7/as a pointer ?rom ~ back to zleading us to the information which is needed toconstruct he local solution of ~.
To extend thisview we regard the whole p~esolved chase C asa finite automaton: take variables and atomsas nodes, a feature constraint as an arc labeledwith the feature, constraints z - s and 1/~ zas e-moves horn z to s or ~/.
We can show thenthat C is unsatisfiable iff there is some z homwhich we reach atom a via path p such that wecan also reach b(~ a) via p or there is a pathstarting from z whose proper prefix is p.Formally, let NFA Arc of presolved clause C be~F~rora this point of view the difference between weakand strong subsumpt ion can be captured in the typeof information they enforce to be inherited.
Strongsubsumpt ion requires path equivalences to be inherited(x ~ y and ~p -" zq implies yp - yq), whereas weaksubsumpt ion does not.260defined as follows.
Its states are the variablesoccurring in C (Vc) plus the atoms plus thestates qF and the initial state q0.
The set offinal states is Vc U {qp}.
The alphabet of Arc isvcu z, u A u {e}.
5The transition relation is defined as follows: s6c := vc}o {(a,a,q~)la~ A}u I ?
g c}u f, I -" c}v ?
c}As usual, let ~c be the extension of 6c to paths.Notice that zpa E L(Afc) iff (z ,p ,a)  E ~c.The language accepted by this automaton con-tains strings of the forms zp or zpa, where astring zp indicates that in a solution a the ob-ject ol(z)p ~t should be defined and zpa tells usfurther that this object should be a A.A set of strings of (V x L*) U (V x L* x A) iscalled c lash- f ree iff it does not contain a stringzpa together with zpb (where a ~ b) or togetherwith zpf.
It is clear that the property of a reg-ular language L of being dash-free with respectto L and A can be read off immediately froma DFA D for it: if D contains a state q with5(q, a) E F and either 6(q, b) E F (where a ~ b)or 6(q, f )  E F, then it is not clash-free, other-wise it is.We now present our centrM theorem.Theorem 2 Let Co be a feature clause, C itspresolved form and Arc the NFA as constructedsir  L or A are infinite we restrict ourselves to the setsof symbols actual ly occurring in C.6Notice that  if x - s E C, then either s is an atom oroccurs only once.
Thus it is pointless to have an arcfr,)m s to ~, since we either have already the max imumof information for s or ~ will not provide any new arcs.above.
Then the following conditions are equiv-alent:i. L(Are) is cZash- ,eeYL There exists a finite feature algebra .A andan assignment c~ such that (.A,c~) ~ Co,provided the set of atoms is finite.3.
There exists a feature algebra .4 and an as-8ignraent ol such that (.A, c~) ~ Co.Proof .
see Appendix A.Now the algorithm consists of the following sim-ple or well-understood steps:1: (a) Solve the equationai constraints of C,which can be done using standard uni-fication methods, exemplified by rules1) to 3).
(b) Make the set of weak subsumptionconstraints transitively and "down-ward" closed (rules 4) and 5)).2: The result interpreted as an NFA is madedeterministic using standard methods andtested of being clash-free.4.3 Determining Clash-Freeness Di-rectlyFor the purpose of proving the algorithm cor-rect it was easiest o assume that clash-freenessis determined after transforming the NFA of thepresolved form into a deterministic automaton.However, this translation step has a time com-plexity which is exponential with the numberof states in the worst case.
In this section\[A weconsider a technique to determine clash-freenessdirectly from the NFA representation f the pre-solved form in polynomial time.
We do not gointo implementational details, though.
Insteadwe are concerned to describe the different stepsmore from a logical point of view.
It can beassumed that there is still room left for opti-mizations which improve ef\[iciency.In a first step we eliminate all the e-transitionsfrom the NFA Arc- We will call the resultstill Arc.
For every pair of a variable nodez and an atom node a let Arc\[z,a\] be the(sub-)automaton f all states of Arc reachablehorn z, but with the atom a being the only finalstate.
Thus, Afc\[z,g\] accepts exactly the lan-guage of all strings p for which zpg E L(Arc).Likewise, let Afc\[z,~\] be the (sub-)automatonof all states o la f  C reachable from z, but whereevery atom node besides a is in the set of fi-nal states as well as every node with an outgo-ing feature arc.
The set accepted by this ma-chine contains every string p such that zpb EL(ArC), (b ~ a) or zpf  E L(Arc).
If and only ifthe intersection of these two machines is emptyfor every z and a, L(Arc) is clash-free.4.4 ComplexityLet us now examine the complexity of the dif-ferent steps of the algorithm.We know that Part la) can be done (usingthe efficient union/find technique to maintainequivalence classes of variables and vectors offeatures for each representative) in nearly lin-ear time, the result being smaller or of equalsize than Co. Part lb) may blow up the clauseto a size at most quadratic with the numberof different variables n, since we cannot havemore subsumption constraints than this.
Forevery new subsumption constraint, rying to ap-ply ruh 4) might involve at most 2n membershiptest to check whether we are actually adding anew constraint, whereas for rule 5) this numberonly depends on the size of L. Hence, we staywithin cubic time until here.Determining whether the presolved form isdash-free from the NPA representation is donein three steps.
The e-free representation f Arcdoes not increase the number of states.
If n ,aand l are the numbers of variables, atoms andfeatures resp.
in the initial clause, then thenumber of edges is in any case smaller than(n + a) ~ ?
l, since there are only n + a states.This computation can be performed in time ofan order less than o((~z + a)3).Second, we have to build the intersections forArc\[z,a\] and Arc\[z,g\] for every z and a. Inter-section of two NFAs is done by building a cross-product machine, requiring maximally o((~z +a) 4 ?
l) time and space.
?
The test for emptinessof these intersection machines is again trivialand can be performed in constant ime.Hence, we estimate a total time and space com-plexity of order n-  a.
(Tz + a) 4 ?
I.7This is an estimate for the number of edges, since thenmuber of states is below (n + a) 2.
As usual, we assumeappropriate data structures where we can neglect theorder of access times.
Probably the space (and time)complexity can be reduced hrther, since we actually donot need the representations of the intersection machinesbesides for testing, whether they can accept anything.2615 ConclusionWe proposed an extension to the basic featurelogic of variables, features, atoms, and equa-tional constraints.
This extension provides ameans for one-way information passing.
Wehave given a simple, but nevertheless completelyformal semantics for the logic and have shownthat the satisfiability (or unification) problemin the logic involving weak subsumption con-straints is decidable in polynomial time.
Fur-thermote, the first part of the algorithm is a sur-prisingly simple extension of a standard unifica-tion algorithm for feature logic.
We have formu-lated the second part of the problem as a simpleproperty of the regular language which the out-come of the first part defines.
Hence, we couldmake use of standard techniques from automatatheory to solve this part of the problem.
Thealgorithm has been proved to be correct, com-plete, and guaranteed to terminate.
There areno problems with cycles or with infinite chainsof subsumption relations as generated by a con-straint like z ~ z f .
sThe basic algorithmic requirements o solve theproblem being understood, the challenge now isto find ways how solutions can be found in amore incremental way, if we already have solu-tions for subsets of a clause.
To achieve this weplan to amalgamate more closely the two partsalgorithms, for instance, through implementingthe check for clash-freeness also with the helpof (a new form of) constraints.
It would be in-teresting also from a theoretical point of viewto find out how much of the complexity of thesecond part is really necessary.AcknowledgmentI am indebted to Bill Romtds for reading a first draftof this paper and pointing out to me a way to testdash-freeness in polynomial time.
Of course, anyremaining errors are those of the author.
I wouldalso llke to thank Gert Smolka for giving valuablecomments on the first draft.References\[Bouma et at.
88\] Gosse Bouma, Esther K~nig andHans Uszkoreit.
A flexible graph-lmification for-realism and its application to natural-languageprocessing.
In: IBM Journal of Research and De-velopment, 1988.SSee \[$hieber 89\] for a discussion of this problem.\[D~rre/Rounds 90\] Jochen D~rre and Willimn C.Rounds.
On Subsuraption and Seminnification iFeature Algebras.
In Proceedings of the 5th An-nual Symposium on Logic in Computer Science,pages 300-310, Philadelphia, PA., 1990.
Also ap-pears in: Journal of Symbolic Computation.\[Johnson 87\] Mark Jolmson.
Attribute-Value Logicand the Theory of Grammar.
CSLI Lecture Notes16, CSLI, Stanford University, 1987.\[Kaphm/Bresnan 82\] Ronald M. Kaplan and JoanBresnan.
Lexleal Functional Granunar: A For-real System for Grammatical Representation.
I :J. Bresnan (ed.
), The Mental Representation o\]Grammatical Relations.
MIT Press, Cambridge,Massachusetts, 1982.\[Kaplan/Maxwell 88\] Ronald M. Kaplan and JohnT.
Maxwell HI.
Constituent Coordination inLexieal-Functional Grammar.
In: Proc.
o\] COL.ING'88, pp.303-305, Budapest, Hmtgary, 1988.\[Kasper/Rounds 86\] Robert T. Kasper and WilliantC.
Rounds.
A Logical Semantics for FeatureStructures.
In: Proceedings o\] the ~th  AnnualMeeting o\] the A CL.
Columbia University, NewYork, NY, 1986.\[Kay 79\] Martin Kay.
Functional Grmnmar.
In: C.Chiarello et al (eds.)
Proceedings o\] the 5th An-nual Meeting o\] the Berkeley Linguistic Society.1979.\[Kay 85\] Martin Kay.
Parsing in Functional Unifi-cation Grammar.
In: D. Dowry, L. Karttunen,and A. Zwieky (eds.)
Natural Language Parsing,Cambridge, England, 1985\[Pollard/Sag 87\] Carl Pollard and Ivan A. Sag.In\]ormation-Based Syntax and Semantics, Voi.1.
CSLI Lecture Notes 13, CSLI, Stanford Uni-versity, 1987.\[Rounds 88\] William C. Rounds.
Set Values forUnification-Based Grammar Formalisms andLogic Programming.
CSLI-Report 88-129, CSLI,Stanford University, 1988.\[Shieber et al 83\] Stuart M. Shiebcr, Hans Uszko-reit, Fernando C.N.
Perelra, J.J. Robinson, M.Tyson.
The formalism and implementation ofPATR-II.
In: J. Bresnan (ed.
), Research on In-teractive Acquisition and Use o\] Knowledge, SRIInternational, Menlo Park, CA, 1983.\[Shieber 89\] Stuart M. Shieber.
Parsing and TypeInference for Nahtral and Computer Languages.Technical Note 460, SRI International, MeldoPark, CA, March 1989.\[Smolka 88\] Gert Smolka.
A Feature Logic with 5ub-sorts.
LILOG-Report 33, IWBS, IBM Deutsch-land, W. Germany, May 1988.
To appear in theJournal of Automated Reasoning.\[SmoUm 89\] Gert Smollm.
Feature Constraint Log-ics \]or Unification Grammars.
I"WBS Report 93,IWBS, IBM Deutschland, W. Germany, Nov.1989.
To appear in the Proceedings of the Work-shop on Unification Formalisms--Syntax, Se-mantics and Implementation, Titisee, The MITPress, 1990.262Appendix  A: P roo f  of Theorem 2From Theorem I we know that C is equivalent to Co,i.e.
it suffices to show the theorem for the existenceof solutions of C in 2) and 3).
Since 2) =~ 3) isobvious, it remains to show 1) =~ 2) and 3 7 ::~ 1).1) ~ 2): We construct a finite model (?4, a) whosedomain contains partial functions from paths toatoms (D A C L*-+ A).
Interpretation and variableassignment are given as follows:?
a "~ = {(e,a)} for every atom a (the functionmapping only the empty string to a)?
for every \] ?
L ,X ?
L*--M: X\] "4 ={(p, a)I (Yp, a) ?
x}?
a(w) = {(p,a) l zpa ?L(Afc)},  which is apar-tial function, due to 1 ).Now let the elements of the dommn be, besides in-terpretations of atoms, just those objects (partialfunctions) which can be reached by application ofsome features to some a(z).?
DA = {a(z)q  "41 =eVe, q?L'} u {.-~ IaeA}.To see that D ~t is finite, we first observethat the domain of each a(z)  is a regular set({Pl zpaEA/'v, aEA}) and the range is finite.
Now,for a regular set R call {p \[ qp?R} the suffix languageof R with respect o string q.
It is clear, that thereare only finitely many suit-ix languages, since eachcorresponds to one state in the minimal finite au-tomaton for R. But then also the number of partialfunctions "reachable" from an a(z)  is finite, sincethe domain of a(z)q "4 is a suffix language of the do-main of a(=).We now show that given 17 the model (.A~ c~) satisfiesall constraints in C.?
I fm "-- a ?
C: za e Z~(Afc) ~ ( , ,a) e o,(z).Now we know from I) that no other pair is ina(=), i.e.
a(z)  = a "a.?
If m - y ?
C: Since = occurs only once inC, the only transition from z is (z, e, y), thus(=,p,a) ?
~c m (V,p,a) ?
~ .
We concludethat (p, a t ?
0t(=) itf (p, a) ?
a(V ).?
I f  my "- y ?
C: Let (p,a) ?
a(m)/"4.
Then(z, \]p,a) ?
5c.
This implies that there is astate z' reachable with n e-moves (n > 0) fromm such that z ' f  - V' ?
C and (y' ,p,a) ?
5c,i.e.
z' is the last state before f is consumedon a path consuming .fpa.
But now, since e-moves on such a chain correspond to subsump-tion constraints (none of the variables in thecltain is isolated) and since C is transitivelyclosed for subsumption constraints, C has tocontain a constraint z' ~ z.
But the last con-dition for normal form now tells us, that alsoy' ~ y is in C, implying (y,e,V') ?
5c.
Hence,(~, p, ~) ?
~c and (p, .)
?
~(v).Conversely, let (p, a) ?
(z(y).
Then (11,P, a) ?6c.
Front the construction also (z , / ,  V) ?
6c,hence (Iv,,,) ?
,~(=) and (p, a) ?
~,(~.)f~.263?
If x ~ V ?
C: The simulation witnessinga(z)  ~a  a(V) is simply the subset relation.Suppose (p, a) ?
a(m).
We conclude (z,p, a) ?~c, but ~o (v, e, =) ?
~c.
Hence, (V,P, a) ?
i cand (p, a t E a(y).In order to show the other direction let us first showa property needed in the proof.Lemma 1 /f  (.A, a) is a model/or presol~ed elaasec ,,.,t (=,p, s) e ,~c, the.
o,(s) ~a ,.(,~)pa.
(z!s = a let ez(a) = a A /or  this p~trpose.
)Proof .
We show by induction over the defmltionof 5c that, given the condition above, there exists asimulation a in .,4 such that a(s)Aa(z)p'4..1. p=eandz=v:  A=ID.2.
p = e and l t~z  ?
C: since ot is asolution,there exists a simulation A with cr(y)Aot(z) \[=~(~)~l.3.
p = f and z f  - y ?
C: A =ID, since~(=) /a  = ~(v).4. p= e and=-  s 6 C: A =ID, s incea(z)  =~(s).5. p = qr ,~d (=,q, , )  ?
;c and (V,,',s) ?
~c:by induction hypothesis there exist Al and A=such that ~,(V),',,,,(=)q "4 and ,.(s)~,.(y),-. '
.Let A = (At O A=)* (the transitive clo-sure of their union), then a(y)Aa(z)q  "4 anda(s)Aa(y)r  "a.
But now, since oz(y)r "4 I andA is a simulation, also cr(y)rAAot(z)qAr "~.H~ce, ~,(s)a~,(=)(q,') "~.
olet us proof 3) ~ 1) of the main theorem by Nowcontradiction.s) ~ 1):Suppose t) does not hold, but (.,4, c,) ~ C.there is a string zpa ?
L(A/'c) such thatCase 1: =pb ?
L(JV*c) where a # b.Thenknow with lemma 1 that a "4 ~A a(m)p.a andbA ~.4 ~x(z)p.4.
But this Contradicts condition1) for a simulation: oz(z)f  t = a "t # b "4 =~,(=)p,4.Case 2: zp\] 6 L(A/c).As in case 1) we have ~(z)pjt __ aA.
Ffonlwhich entails that \].4 has to be defined for~(z)p.4, a contradiction.This completes the proof.
\[\]
