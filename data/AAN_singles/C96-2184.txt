Segmentation Standard for Chinese Natural Language ProcessingChu-Ren Huang*, Keh-j iann Chen #' and Li-Li Chang #Instatute of History and Philology, and #Institute of Information ScienceAcademia Sinica, Nankang, Taipei, Taiwan 115hschuren@ccvax.sinica.edu.tw, kchen@iis.sinica.edu.tw, lili@iis.sinica.edu.twAbstractThis paper proposes a segmentation stan-dard for Chinese natural language processing.The standard is proposed to achieve linguis-tic felicity, computational feasibility, anddata uniformity.
Linguistic felicity is main-tained by defining a segmentation unit to beequivalent to the theoretical definition ofword, and by providing a set of segmentationprinciples that are equivalent o a functionaldefinition of a word.
Computational feasi-bility is ensured by the fact that the abovefunctional definitions are procedural in na-ture and can be converted to segmentationalgorithms, as well as by the implementableheuristic guidelines which deal with specificlinguistic categories.
Data uniformity isachieved by stratification of the standarditself and by defining a standard lexicon aspart of the segmentation standard.I.
IntroductionOne important feature of Chinese texts isthat they are character-based, not word-based.
Each Chinese character stands for onephonological syllable and in most cases rep-resents a morpheme.
The fact that Chinesewriting does not mark word boundaries posesthe unique question of word segmentation iChinese computational linguistics (e.g.
Sproatand Shih 1990, and Chert and Liu 1992).Since words are the linguistically significantbasic elements that are entered in the lexiconand manipulated by grammar rules, no lan-guage processing can be done unless wordsare identified.
In theoretical terms, the pri-macy of the concept of word can be morefirmly established if its existence can be em-pirically supported in a language that doesnot mark it conventionally in texts (e.g.
Bateset al 1993, Huang et al 1993).
In computa-tional terms, no serious Chinese languageprocessing can be done without segmenta-tion.
No efficient sharing of electronic re-sources or computational tools is possibleunless segmentation can be standardized.Evaluation, and thus comparisons and im-provements, are also impossible in Chinesecomputational linguistics without standard-ized segmentation.Since the proposed segmentation standardis intended for Chinese natural languageprocessing, it is very important that it re-flects linguistic reality as well as computa-tional applicability.
Hence we stipulate thatthe proposed standard must be linguisticallyfelicitous, computationally feasible, and mustensure data uniformity.1.1.Components of the Sezmentation StandardOur proposed segmentation standard con-sists of two major components to meet thegoals discussed above.
The modularization ofthe components will facilitate revisions andmaintenance in the future.
The two majorcomponents of the segmentation standardsare the segmentation criteria and the (stan-dard) lexicon.
The tripartite segmentationcriteria consist of a definition of the segmen-tation unit, two segmentation principles, anda set of heuristic guidelines.
The segmenta-tion lexicon contains a list of Mandarin Chi-nese words and other linguistic units that theheuristic guidelines must refer to.II.Segmentation Standard Part I:Segmentation CriteriaII.1.
A Definition of the Segmentation UnitGiven Bloomfield's (1933) definition ofwords as 'the smallest units of speech thatcan meaningfully stand by their own,' theyare natural units for segmentation in lan-guage processing.
However, as Chao (1968)observes, sociological words and linguisticwords very often do not match up.
In Eng-lish, a sociological word can be defined bythe delimitation of blanks in writing.
It isnevertheless possible for a linguistic wordsuch as a compound to be composed of morethan one sociological words, such as 'theWhite House.'
Since these cases representonly a relatively small portion of English1045texts, sociological words are taken as thedefault standard for segmentation units aswell as a reasonable approximation to lin-guistic words in English language processing.Chinese, on the other hand, defines itssociological words in terms of characters, inspite of the fact that grammatical words maybe made up of one or more characters.
Infact, one-character words represent slightlyless than 10% of all lexical entries, whiletwo-character words take up more than 65%.Similarly, one-character words are estimatedto take up only 50% of all texts in Chinese(Chen et al, 1993).
Since the notion of theone-word-per-character sociological word isnot a good working hypothesis for linguisticwords, and since there is no fixed length forwords, a crucial issue is whether the notionof linguistic words can be directly used asthe standard for segmentation unit.Computational inguistic works suggestthat linguistic words are not the perfect unitsfor natural language processing.
For instance,the necessity for lemmatization attests to thefact that some linguistically dependent unitsmay have independent grammatical functionand meaning and need to be treated as basicunits in language processing (e.g.
Sproat1992).
We follow the above findings anddefine the standard segmentation unit as aclose approximation of linguistic words withemphasis on functional rather than phono-logical or morphological independency.1) Segmentation Unitde f is the smalleststring of character(s) that has both anindependent meaning and a fixed gra-mmatical category.There are two points worth remarkinginvolving the above definition.
First, non-technical terms are deliberately chosen suchthat even developers in information indus-tries with little or no linguistic backgroundcould follow this standard.
Second, it followsfrom this definition that many of the so-called particles, which show various levels oflinguistic dependencies but represent invari-ant grammatical functions, will be treated assegmentation units.
They include le 'perfec-tive marker', and de 'relative clause marker'.II, 2, Segmentatign PrinciplesWe propose two segmentation principlesto define the two basic concepts underliningthe definition: independent meaning andfixed grammatical category.
The principlesalso provide a functional/procedural go-rithm for identifying segmentation units.2) Segmentation Principlesa) A string whose meaning cannot be de-rived by the sum of its componentsshould be treated as a segmentation unit.b) A string whose structural compositionis not determined by the grammatical re-quirements of its components, or a stringwhich has a grammatical category otherthan the one predicted by its structuralcomposition should be treated as a seg-mentation unit.Take note that characters are the basic pro-cessing units when segmentation is involved.Thus the two principles address the questionof which strings of characters can be furthercombined to form a segmentation unit.
Prin-ciples 2a) and b) elaborate on the semantic(independent meaning) and syntactic (fixedcategory) components of the definition ofsegmentation unit.Because of the procedural nature of thetwo principles, they provide the basis forsegmentation algorithm.
Since a charactercould be a lexical or sub-lexical element, thebasic decision in segmentation is whether therelation between two characters are morpho-lexical or syntactic.
For instance, with a VOsequence such as lai-dian come-electricity'to strike a chord with, to mutually attract',principle 2b) applies to predict that the stringis a segmentation unit since lai is an intransi-tive verb and do not take an object.II.3.Segmentation GuidelinesEven though the above principled defini-tion provides a broad direction for standard-ized segmentation, it lacks the nuance forguiding actual segmentation.
The definitionof segmentation units and the segmentationprinciples are essentially language indepen-dent formalizations of information units (i.e.words).
Thus they will not vary with linguis-tic change, and need not be revised for spe-cific applications.
However, this universalnature also prevents them from referring tospecific details.
Hence we propose that a setof Segmentation Guidelines be included inour segmentation standard to reflect heuristicknowledge that is dependent on actual lin-1046guistic data.
These guidelines can be added,deleted, or altered as necessitated by the lin-guistic data we are dealing with.
Since allessential inguistic knowledge is encoded inthe lexicon, it follows that the guidelines willhave to refer to a Mandarin lexicon.
In con-trast, the broad linguistic concepts in thedefinition and principles do not refer to spe-cific lexical information.
Last, we also envi-sion that the guidelines are quantifiable.They are quantifiable because more guide-lines a string satisfies, the more likely it is tobe a segmentation u it.3) Segmentation Guidelinesa) Bound morphemes hould be attachedto neighboring words to form a seg-mentation unit when possible.b) A string of characters that has a highfrequency in the language or high co-occurrence frequency among the com-ponents hould be treated as a segmen-tation unit when possible.c) Strings separated by overt segmenta-tion markers hould be segmented.d) Strings with complex internal struc-tures should be seglnented when possible.IlI.
Segmentation Standard Part II:The Standard LexiconWe propose that a standard lexicon be in-cluded as part of the segmentation standard.This lexicon will list words as well as pro-ductive morpho-lexical affixes.
It will alsocontain the list of mandatory segmentationmarkers, such as the end of sentence marker('), (o) etc.
All derived words can be coveredsimply by firing all derivational rules gov-erning the list of bound morphemes.
How-ever, non-derived words are trickier sincethey cannot be predicted with generativerules.
The only way to verify that they aresegmentation units is to consult a lexical list,which is finite and incomplete by nature.The incompleteness of the lexical listunderlines the importance of conforming tothe segmentation criteria while compiling thestandard lexicon.
An entry is entered in thelexicon only when it qualifies as a segmenta-tion unit.
The segmentation guidelines 3a)-3c) are the same heuristic guidelines for se-lecting lexical entries.
However, since alllanguage lexicons are constantly changing, anentry in the lexicon is determined by its fre-quency and usage of the time.
The standardlexicon will be updated and maintained reg-ularly to keep up with the evolution of thelanguage.
In addition, application of the seg-mentation standard in any specific domainmay require a new special domain lexicon.IN.
Three Levels of Segmentation Stm!d=ardA central concern in proposing any stan-dard is whether this standard can be success-fully and consistently followed.
We took intoconsideration of the state of art of automaticsegmentation i Chinese NLP as well as thetechnology level of information industriesdealing with Chinese natural languages andproposed the following stratification of threelevels of instantiations for the SegmentationStandard.
It is hoped that this stratificationwill ensure successful standardization as wellas lead to eventual identification of segmen-tation units with linguistics words.5) Levels of Segmentation Standarda) Faithful\[xin41: All segmentationunits listed in the standard lexiconshould be successfully segmented.b) Truthful\[da2\]: All segmentationunits identified at the Faithful level aswell as all segmentation units derivableby morphological rules should be suc-cessfully segmented.c) Graceful\[ya31: All linguistic wordsare successfully identified as segmenta-tion units.The goal of the Faithful level is to definea segmentation standard such that uniformityof electronic texts can be achieved evenwhen they are prepared with the lowest pos-sible computational sophistication.
In otherwords, the standard must be as easy to followas the convention of inserting blanks atwordbreaks in English text processing.
Atthis level, unless it matches a lexical entry, astring will simply be segmented into individ-ual characters.
Notice that this is NOT atrivial level since possible ambiguous seg-ments take up as high as 25% of Chinesetexts (Chen and Liu 1992).
Various autonmticsegmentation programs reported over 99%precision rate when unknown words are nottaken into account (e.g., Chiang et al 1992).This will be the default segmentation levelfor the exchange of electronic texts.The goal of the Truthful level is to de-1047fine a segmentation standard for most com-putational inguistic applications.
The cover-age of the Faithful level is too low for mostNLP applications.
For instance, unknownwords can be left unidentified for data ex-change but not for machine translation.
Wanget al (1995) classified unknown words intothree types.
The first type are the words thatare generated by morphological rules.
Theyare productive and cannot be exhaustivelylisted in the lexicon.
The second type are thewords whose derivation is either context-dependent or cannot be captured by familiarmorphological rules.
A good example is thesuoxie abbreviation where a character fromeach compound or phrase component is se-lected to form a new word (Huang et al1993), such as deriving hua2hang2 fromzhonglhua2 hang2kongl 'China Airlines.
'The third type are the unknown words whichare not derived by any rules, such as propernames(Chert et al 1994).
Only the first typeof unknown words can be comfortably dealtwith by current Chinese NLP technology.Thus, at the Truthful level of segmentation,we stipulate that all lexical entries as well asall morphologically derivable unknown wordsshould be properly segmented.
This level willoffer a wide enough coverage for most NLPapplications and yet a reasonably high con-sistency can still be achieved with currentautomatic segmentation technology.
Since afinite state machine implementing the mor-phological rules on top of a finite lexiconlisting can generate all the segmentationunits, the only technical challenge would beto resolve ambiguities among the above units.Lastly, the Graceful level of segmenta-tion standard will have to deal with the tworemaining types of unknown words.
It maynot be too long before reasonable consistencycan be achieved at this level of standard forfully automated language understanding.V.
Concluding RemarksIn this paper, we propose a SegmentationStandard for Chinese language processingcomposed of two distinct parts: a) the lan-guage and lexicon-independent definitionand principles, and b) the lexicon-dependentguidelines.
The definition and principlesoffer the conceptual basis of segmentationand are the unifying idea behind resolutionof heuristic conflicts.
The lexicon-dependentguidelines, as well as the data-dependentlexicon, allows the standard to be easily ad-aptable to linguistic and sub-languagechanges.BibliographyBates, E., S. Chert, P. Li, M. Opie, O. Tzeng.1993.
Where is the Boundary betweenCompounds and Phrases in Chinese?
Brainand Language.
45:94-107.Bloomfield, L. 1933.
Language.
New York:Holt, Rinehart, and Winston.Chao, Y. R. 1968.
A Grammar of SpokenChinese.
Berkeley: U. of California Press.Chen, C., S. Tseng, C.-R. Huang and K.-J.Chen.
1993.
Some Distributional Propertiesof Mandarin Chinese-A Study Based on theAcademia Sinica Corpus.
Proc.
of the 1stPACFoCoL.
81-95.
Taipei.Chen, H. and C. Li.
1994.
Recognition ofText-based Organization Names in Chi-nese.
\[in Chinese\] Communications ofCOLIPS.
4.2.131-142.Chert, K.-J.
and S.-H. Liu.
1992.
Word Iden-tification for Mandarin Chinese Sentences.COLING-92.
101- 105.
Nantes, France.Chiang, T.-H., J.-S. Chang, M.-Y.
Lin, andK.Y.
Su.
1992.
Statistical Models for WordSegmentation and Unknown Word Resolu-tion.
Proc.
of ROCLING V. 121-146.Huang, C.-R., K. Ahrens, and K.-J.
Chen.1993.
A Data-driven Approach to Psycho-logical Reality of the Mental Lexicon: TwoStudies in Chinese Corpus Linguistics.Proc.
of the International Conference onthe Biological Basis of Language.
53-68.Chiayi: Center of Cognitive Science, Na-tional Chung Cheng U.Sproat, R. 1992.
Morphology and Computa-tion.
Cambridge: MIT Press.and C. Shih.
1990.
A Statistical Methodfor Finding Word Boundaries in ChineseText.
Computer Processing of Chinese andOriental Languages.
4.4:336-351.Wang, M.-C., C.-R. Huang, and K.-J.
Chen.1995.
The Identification and Classificationof Unknown Words in Chinese: A N-gram-Based Approach.
In A. Ishikawa and Y,Nitta Eds.
Proc.
of the 1994 Kyoto Confer-ence.
A Festschrift for Professor Akiralkeya.
113-123.
Tokyo: The Logico-Lin-guistics Society of" Japan.1048
