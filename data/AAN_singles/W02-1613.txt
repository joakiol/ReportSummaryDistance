Automatic Information Transfer Between English And ChineseJianmin Yao, Hao Yu, Tiejun ZhaoSchool of Computer Science and TechnologyHarbin Institute of TechnologyHarbin, China, 150001james@mtlab.hit.edu.cnXiaohong LiDepartment of Foreign StudiesHarbin Institute of TechnologyHarbin, China, 150001goodtreeyale@yahoo.com.cnAbstractThe translation choice and transfer modulesin an English Chinese machine translationsystem are introduced.
The translationchoice is realized on basis of a grammar treeand takes the context as a word bag, with thelexicon and POS tag information as contextfeatures.
The Bayes minimal errorprobability is taken as the evaluationfunction of the candidate translation.
Therule-based transfer and generation moduletakes the parsing tree as the input andoperates on the information of POS tag,semantics or even the lexicon.IntroductionMachine translation is urgently needed to getaway with the language barrier betweendifferent nations.
The task of machinetranslation is to realize mapping from onelanguage to another.
At present there are threemain methods for machine translation systems[Zhao 2000]: 1) pattern/rule based systems:production rules compose the main body of theknowledge base.
The rules or patterns are oftenmanually written or automatically acquired fromtraining corpus; 2) example based method.
Theknowledge base is a bilingual corpus of sourceslices S?
and their translations T?
Given a sourceslice of input S, match S with the source slicesand choose the most similar as the translation orget the translation from it.
3) Statistics basedmethod: it is a method based on monolinguallanguage model and bilingual language model.The probabilities are acquired from large-scale(bilingual) corpora.Machine translation is more than amanipulation of one natural language (e.g.Chinese).
Not only the grammatical andsemantic characteristics of the source languagemust be considered, but also those of the targetlanguage.
To sum up, the characteristics ofbilingual translation is the essence of a machinetranslation system.A machine translation system usuallyincludes 3 sub-systems [Zhao 1999] ?
(1)Analysis: to analyse the source languagesentence and generate a syntactic tree withsyntactic functional tags; (2) Transfer: map asource parsing tree into a target language parsingtree; (3) Generation: generate the targetlanguage sentence according to the targetlanguage syntactic tree.The MTS2000 system developed in HarbinInstitute of Technology is a bi-directionalmachine translation system based on acombination of stochastic and rule-basedmethods.
Figure 1 shows the flow of the system.Input English SentenceMorphology AnalysisSyntactic AnalysisWord Translation ChoiceTransfer and GenerationOutput Chinese SentenceFigure 1 Flowchart of MTS2000 SystemAnalysis and transfer are separated in thearchitecture of the MTS2000 system.
Thismodularisation is helpful to the integration ofstochastic method and the rule based method.New techniques are easier to be integrated intothe modularised system.
Two modulesimplement the transfer step and the generationstep after analysis of the source sentence.
Thespecific task of transfer and generation is toproduce a target language sentence given thesource language syntactic tree.
In details, givenan English syntactic tree (e.g.
S[PP[ In/INBNP[our/PRP$ workshop/NN]] BNP[ there/EX]VP[ is/VBZ NP[ no/DT NP[ NN[ machine/NNtool/NN] SBAR[ but/CC VP[ is/VBZmade/VBN PP[ in/IN BNP[ China/NNP ]]]]]]]]),using knowledge sources such as grammaticalfeatures, simple semantic features, construct aChinese syntactic tree, whose terminal nodescompromise in sequence the Chinese translation.The input sentence are analysed using themorphology analyser, part-of-speech tagger, andsyntactic analyser.
After these steps, a syntacticparsing tree is obtained which has multiplelevels with functional tags [Meng 2000].Followed is the parser flow:Figure 2.
Parser based on Hybrid MethodsAt present, our English parser is able togenerate syntactic tree bleway.
The English parsininformation about relatioin the source sentenceinformation of the nodesof transfer and generatiothe nodes is the startinggeneration.
After syntacttransfer and generation inchoice of ambiguousadjustment and insertifunctional words.
Transimplemented using twoword translation choice,transfer and translation m1 Parsing Based TranFirst we will give a ftranslation choice in[Manning 1999]: Suppose the source sentence tobe translated to be ES.
In the sentence theambiguous word EW has M target translationsCW1, CW2, ... CWM.
And the translationsoccurs in a specific context C with probabilitiesP(CW1 | C)?P(CW2 | C), ... P(CWM|C)?Fromthe Bayes minimum error probability formula,we get:CW = argmax[P(CWk|C)]= argmax[logP(CWk) + logP(C|CWk) ] (1)Generally when the condition fulfillsP(CW1|C)>P(CW2|C)>...>P(CWM|C), we maychoose CW1 as the translation for EW.
From theNa?ve Bayes formula?P(C|CWk) = P({vj | vj in C}|CWk)= ?Vj in C P(vj|sk)              (2)So formula (1) can be rewritten as:CW = argmax[P(CWk|C)]Input Sentence Statistics Knowledge = argmax[logP(CWk)+?Vj in ClogP(vj|CWk)] (3)Where P(CWk) denotes the probability thatCWk occurs in the corpus; P (vj| CWk) denotesthe probability that the context feature vjco-occurs with translation CWk?A general algorithm of supervised wordsense disambiguation is as follows:1. comment: Training2.
for all senses sk of w do3.
for all words vj in the vocabulary do4.
P(vj|sk) = C(vj, sk)/C(vj)5.    end6.
end7.
for all senses sk of w do8.
P(sk) = C(sk)/C(w)9. endPOS Tagger Manual RuleBasePPA ResolutionLayered Parsing eein comparative usagnsh, a, isn.piccluwonfermtheodslaormmParsing Trtree, with the basicip among the nodeslso with semanticinput to the moduleThe information ofoint of transfer andparsing, the task ofdes word translationords, word order/deletion of someand generation areodules: one is forother for structureification.tion Choiceal description forachine translation10.
comment: Disambiguation11.
for all sense sk of w do12.
Score(sk) = logP(sk)13.    for all words vj in the context window c do14.
score(sk) = score(sk) + logP(vj|sk)15.    end16.
end17.
choose s?
= argmaxskscore(sk)Figure 5.
Bayesian disambiguationFrom the above formal description we cansee that the key to the stochastic wordtranslation is to select proper context and contextfeatures Vj.
Present methods often define a wordwindow of some size, i.e.
to suppose only wordswithin the window contributes to the translationchoice of the ambiguous word.
For example,[Huang 1997] uses a word window of length 6words for word sense disambiguation; [Xun1998] define a moveable window of length 4words; [Ng 1997] uses a word window withoffset ?2.
But two problems exist for thismethod: (1) some words that are informative tosense disambiguation may not be covered by thewindow; (2) some words that are covered by theword window really contribute nothing to thesense choice, but only bring noise information.After a broad investigation for large-scaleambiguous words, we choose the contextaccording to the correlation of the context wordswith the ambiguous word, but not only thedistance from the word.From the above analysis, we choose thetranslation choice method based on syntacticanalysis.
Place the module of translation choicebetween the parser and the generator; acquire acontext set for the ambiguous word.
Whenchoosing the translation, we may take thecontext set as a word bag, i.e.
the grammaticalcontext as word bag.
No single word isconsidered but only that lexical andpart-of-speech information are taken as contextfeatures.
Bayes minimum error probability istaken as evaluation function for word translationchoice.In this paper, grammatical context isconsidered for word translation choice.
Thestructure related features of the ambiguouswords are taken into account for fully use of theparsing result.
It has the characteristics below: (1)The window size is not defined by human but onbasis of the grammatical structure of thesentence, so we can acquire more efficiently theuseful context features; (2) The unrelatedcontext features in sentence structure are filteredout for translation choice; (3) The features arebased on the structure relationship, but not 100%right parsing result.
From the abovecharacteristics, we can see the method is reallypractical.2 Rule Based Transfer & GenerationFor MTS2000, structural transfer is to start fromthe syntactic parsing tree and construct theChinese syntactic tree.
While the generation ofChinese is to generate a word link from theChinese tree and build the translation sentence[Yao 2001].
This module has adopted therule-based knowledge representation method.The design of the rule system is highly related tothe performance of the machine translationsystem.The rule description language of themachine translation system is in the form ofproduction rules, i.e.
a rule composed of aconditional part and an operational part.
Theconditional part is a scan window of variablelength, which uses the context constraintconditions such as phrases or some linguisticfeatures.
The operational part generates thecorresponding translation or some correspondinggeneration features in the operational part.
If theconditions are met, the operations will beperformed.
The representation of the rule systemhas shown a characteristic of the system, that isthe integration of transfer and generation.
Therule description language is similar to naturallanguage and consistent with human habits.Multiple description methods are implemented.The conditional part of the rules iscomposed of node numbers and ?+?
symbolsthat is used to link the nodes.
The operation partconsists of corresponding conditional parts andtranslations and also, if necessary, some actionfunctions.For example, the rule to combine anadjective and a noun to generate a noun phrase isas follows:0:Cate=A + 1:Cate=N->0:* + 1:* + _NodeUf(N?0?1)in which, ?*?
stands for correspondingtranslation of the nodes, _NodeUf() is a functionthat combines the nodes to generate a new node.The new translation is generated at the sametime with the combination of nodes.In general, the English Chinese machinetranslation system has the following features inthe transfer and generation phase:1) The grammatical and semantic features aredescribed by a string composed of framename and values linked with ?=?
;2) The conditions may be operated by ?and?,?or?
and ?not?
;3) Nodes in the same level of the sentence maybe scanned and tested arbitrarily;4) The action functions and test functions cangenerate corresponding features for featuretransmission and test.The rules are organized into various levels.All the rules are put in the knowledge base withpart-of-speech as the entry feature.
The ruleshave different priorities, which decide theirsequence in rule matching.
In general, the morespecific the rule, the higher is its priority.
Themore general the rule, the lower is its priority.The levels of the rules help resolve rulecollision.ConclusionThe system prototype has been implemented andlarge-scale development and refinement areunder progress.
From our knowledge of thesystem, knowledge acquisition and rule baseorganization is the bottleneck for MTS2000system and similar natural language processingsystems.
The knowledge acquisition for wordtranslation choice needs large-scale wordaligned bilingual corpus.
We are makingresearch on new word translation methods onbasis of our 60,000-sentence aligned bilingualcorpus.
The transfer and generation knowledgebase are facing much knowledge collision andredundancy problem.
The organizationtechnique of knowledge base is also animportant issue in the project.ReferencesTie-Jun Zhao, En-Dong Xun, Bin Chen, Xiao-HuLiu,Sheng Li, Research on Word SenseDisambiguation based on Target LanguageStatistics, Applied Fundamental and EngineeringJournal, 1999?7?1?
?101-110Meng Yao, Zhao Tiejun, Yu Hao, Li Sheng, ADecision Tree Based Corpus Approach to EnglishBase Noun Phrase Identification, ProceedingsInternational conference on East-Asian LanguageProcessing and Internet Information Technology,Shenyang, 2000: 5-10Christopher D. Manning, Hinrich Sch ?
tze,Foundation of Statistical Natural LanguageProcessing.
The MIT Press.
pp229-262.
1999.Chang-Ning Huang, Juan-Zi Li, A language modelfor word sense disambiguation, 10th anniversaryfor Chinese Linguistic Society, October, 1997,FuzhouEn-Dong Xun, Sheng Li, Tie-Jun Zhao, Bi-gramco-occurrence based stochastic method for wordsense disambiguation, High Technologies, 1998,10(8): 21-25Hwee Tou Ng.
Exemplar-Based Word SenseDisambiguation: Some Recent Improvements.
InProceedings of the Second Conference onEmpirical Methods in Natural LanguageProcessing (EMNLP-2), August 1997Tie-Jun Zhao etc, Principle of Machine Translation,Press of Harbin Institute of Technology, 2000.Jian-Min Yao, Jing Zhang, Hao Yu, Tie-JunZhao,Sheng Li, Transfer from an English parsingtree to a Chinese syntactic tree, Joint Conference ofthe Society of Computational Linguistics, 2001,Taiyuan.-138.
