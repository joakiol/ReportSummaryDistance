BRIDJE over a Language Barrier:Cross-Language Information Accessby Integrating Translation and RetrievalTetsuya Sakai Makoto Koyama Masaru Suzuki Akira Kumano Toshihiko ManabeToshiba Corporate R&D Center Knowledge Media Laboratory,1 Komukai-Toshiba-cho, Saiwai-ku, Kawasaki 212-8582, JAPANtetsuya.sakai@toshiba.co.jpAbstractThis paper describes two new features ofthe BRIDJE system for cross-languageinformation access.
The first feature isthe partial disambiguation function ofthe Bi-directional Retriever, which canbe used for search request translation incross-language IR.
Its advantage over a?black-box?
machine translation approachis consistent across five test collectionsand across two language permutations:English-Japanese and Japanese-English.The second new feature is the InformationDistiller, which performs interactivesummarisation of retrieved documentsbased on Semantic Role Analysis.
Ourexamples illustrate the usefulness ofthis feature, and our evaluation resultsshow that the precision of Semantic RoleAnalysis is very high.1 IntroductionCross-Language Information Retrieval(CLIR) (Grefenstette, 1998) has received a lotof attention recently.
TREC currently studiesEnglish-Arabic IR, CLEF studies CLIR acrossEuropean languages, and NTCIR studies CLIRacross Asian languages (Chen et al, 2003; Kando,2001).
As with monolingual IR, CLIR evaluationsusually rely on the use of static test collections: Thesystem accepts a source language search request andoutputs a ranked list of target language documents,and this list is evaluated using metrics such asAverage Precision.
However, CLIR solves only partof the Language Barrier Problem: if the user cannotexpress his information need in target language,then he probably cannot make much use of theretrieved documents written in the same language.
(If the source and target languages are reasonablysimilar, then the user may find such plain CLIRuseful.
However, this is certainly not the case forpairs of disparate languages such as English andJapanese.)
Thus, what deserves more attention isCross-Language Information Access (CLIA), whichsubsumes CLIR and provides useful information tothe user in source language (e.g.
(Frederking et al,1997)).This paper describes two new features of theBRIDJE (Bi-directional Retriever/Information Dis-tiller for Japanese and English) system (Sakai et al,2002a; Sakai et al, 2002b; Sakai et al, 2003) whichintegrates machine translation (MT) with informa-tion retrieval (IR) to support both English-Japanese(E-J) and Japanese-English (J-E) CLIA.
The first fea-ture is the partial disambiguation function of the Bi-directional Retriever part of BRIDJE for enhancingretrieval performance in the traditional sense.
Whilemost of the traditional MT-based CLIR systems useMT as a ?black box?, partial disambiguation accessesthe internal data structures of a commercial MT sys-tem for search request translation so that multipletranslation candidates can be used as search terms.We present positive results that are consistent acrossfive test collections (or six topic sets), and acrosstwo language permutations: English-Japanese andJapanese-English.
To our knowledge, BRIDJE isthe first system that truly integrates MT with IR andperforms well in terms of standard measures.
Thesecond new feature is the entire Information Dis-tiller part of BRIDJE, which can provide genericor query-specific summaries of the retrieved docu-ments, as well as their translations in source lan-guage.
Based on Semantic Role Analysis (SRA)originally designed for enhancing retrieval perfor-mance (Sakai et al, 2002a; Suzuki et al, 2001),the Information Distiller extracts important text frag-ments from a retrieved document on the fly.
Prelim-inary evaluations suggest that SRA can classify textfragments with very high precision, and that it isuseful for efficient information access.
We regardour Information Distiller feature as one step towardsCross-Language Question Answering.BRIDJE is an enhanced, fully bilingual versionof the KIDS Japanese retrieval system that recentlyachieved the highest performances in the English-Japanese and Japanese monolingual IR tasks atNTCIR-3 (Chen et al, 2003; Sakai et al, 2003).The remainder of this paper is organised as fol-lows: Section 2 compares some of the previous workon CLIR/CLIA with our present study.
Section 3provides an overview of the BRIDJE system.
Sec-tion 4 describes an extensive set of retrieval experi-ments that compares partial disambiguation with theblack-box MT approach.
Section 5 provides exam-ples to illustrate the advantages of the InformationDistiller for efficient information access, as well assome evaluation results of SRA.
Finally, Section 6provides conclusions.2 Previous WorkThis section reviews some previous work onCLIR/CLIA, focussing primarily on those that dealwith English and Japanese or those that use MT insome way or other.The early J-E CLIR systems (Susaki et al, 1996;Yamabana et al, 1998) employed dictionary-basedsearch request translation, with corpus-based dis-ambiguation.
However, it is not clear how effectivethese systems are in terms of retrieval performance.In contrast, for both J-E and E-J CLIR, MT-basedsearch request translation has been combined suc-cessfully with Pseudo-Relevance Feedback (Sakai etal., 1999a; Sakai, 2001).
The recent CLIR resultsat NTCIR-3 also showed that this approach, whichBRIDJE also employs, is very promising (Chen etal., 2003; Sakai et al, 2003).In our partial disambiguation experiments, wego beyond the use of MT as a black box by ac-cessing the internal data structures of a commer-cial MT system in order to use multiple transla-tion candidates as search terms.
Jones et al (Joneset al, 1999) have explored this approach to someextent, but they observed performance degradationwhen compared to full disambiguation (i.e.
black-box MT), as they treated the multiple candidates asdistinct search terms.
In contrast, BRIDJE treatsthese candidates as a group of synonyms, which isnow known to be effective in CLIR (Pirkola, 1998).Thus, while dictionary-based approaches start fromthe maximum ambiguity state and performs vigorousdisambiguation, we start from the minimum ambi-guity state reached through full MT and take a stepbackward for obtaining alternative translations.
TheSYSTRAN NLP browser (Gachot et al, 1998) alsointegrates MT with IR at a deep level, but this wasdesigned for retrieving sentences that match specificgrammatical features, and its effectiveness as a doc-ument retrieval system is not clear.Regarding CLIA (as opposed to CLIR), Frederk-ing et al (Frederking et al, 1997) proposed a frame-work in which retrieved documents could be sum-marised and translated by multiple MT engines inparallel.
MULINEX (Capstick et al, 2000), whichis a dictionary-based CLIR system for French, En-glish and German, uses the LOGOS MT system fordocument/summary presentation.
Oard and Ren-sik (Oard and Resnik, 1999) have used word-by-wordJ-E translations in their study on interactive docu-ment selection.
PRIME (Higuchi et al, 2001), yetanother J-E/E-J CLIR system based on dictionariesand corpora, translates retrieved patent documentsphrase-by-phrase.
Compared to these CLIA sys-tems, the Information Distiller part of BRIDJE isunique in that it performs SRA for interactive docu-ment summarisation/presentation.3 The BRIDJE SystemThis section describes the general features of theBRIDJE system.
Sections 3.1 and 3.2 describethe request translation and indexing/retrieval compo-nents of the Bi-directional Retriever.
Section 3.3 in-troduces the Information Distiller that provides sum-maries and translations of retrieved documents.3.1 Request TranslationThe default search request translation strategy ofBRIDJE is full disambiguation: a source languagerequest is fed to a commercial MT system (Amano etal., 1989), and the output is treated as a monolingualrequest written in target language.
BRIDJE is alsocapable of performing transliteration for treatingwords that are outside of the MT dictionary (Sakai etal., 2002b), but this feature is not used in the presentstudy.In order to describe partial disambiguation, wefirst illustrate the disambiguation process of MT withan example.
Suppose that a search request containsthe word ?play?
in the context of E-J CLIR.
Firstly,by dictionary lookup, we recognise that ?play?
caneither be a noun or a verb, and obtain all possi-ble Japanese translations accordingly.
Secondly, wedetermine its part-of-speech through syntactic anal-ysis.
Here, suppose that ?play?
was used as a verb,and that all Japanese translations for the noun ?play?have been filtered out.
Thirdly, we perform semanticanalysis using transfer rules.
These rules containknowledge such as ?IF the object of the verb ?play?is a sport, THEN it should be translated as ?suru?.
IFthe object is a musical instrument, THEN it shouldbe translated as ?hiku?
or ?enso?-suru?.
Here, sup-pose that the object was ?violin?, and therefore that?hiku?
and ?enso?-suru?
have been selected as transla-tion candidates.
Then, at the final output stage, onlyone translation is selected for each source languageword.
For the word ?play?
in the above example,?hiku?
is selected as the final translation since thisis the first entry in the aforementioned transfer rule.
(The above explanation is a simplified version ofwhat really goes on inside our MT system.
)Partial disambiguation takes all candidate trans-lations that are left just after the semantic analysisstage (?hiku?
and ?enso?-suru?
in the above example),and treats them as a set of synonyms in retrieval.
Asit is well known, disambiguation in MT is far fromperfect, and the synonym groups thus produced oftencontain some inappropriate terms.
Despite this, ourexperiments described in Section 4 show that partialdisambiguation is effective.3.2 Indexing and RetrievalOur default retrieval strategy is Okapi/BM25 withPseudo-Relevance Feedback (PRF) (Robertson andSparck Jones, 1997; Sakai, 2001).
The term selec-tion criterion used in all of our experiments involvingPRF is ow , which incorporates the initial documentscores into the traditional offer weight (Sakai et al,2003).BRIDJE employs word-based indexing, prior towhich synonyms and phrases can be defined.
Syn-onym groups can also be defined at query time, whichis useful for partial disambiguation and translitera-tion (Sakai et al, 2002b): the term frequency (tf )and the document frequency (df ) are counted as if allthe members of a synonym group are one identicalterm.Optionally, BRIDJE can perform indexing and re-trieval based on SRA (Sakai et al, 2002a; Suzukiet al, 2001), which was originally designed for go-ing beyond the ?bag-of-words?
approach to IR.
Al-though the present study uses SRA for interactivedocument summarisation/presentation and not for re-trieval, it works as follows: During document index-ing and search request processing, BRIDJE can ex-amine the output of the parser (morphological anal-yser for Japanese; part-of-speech tagger/stemmer forEnglish), based on a set of hand-written SRA ruleswhich specify the following: How to break up the text into fragments, basedon regular expression pattern matching.
A frag-ment can be a sentence, a paragraph, a prepo-sitional phrase, and so on.
For example, anEnglish sentence of the form ?A for B with C?can be broken into ?A?, ?for B?
and ?with C?
ifprepositions are used as fragment boundaries. How to assign Semantic Roles (SRs) to eachfragment, again based on regular expressionpattern matching.
Using prepositions as SRAtriggers in the above example, it is possibleto tag the fragment ?for B?
with ?PURPOSE?,the fragment ?with C?
with ?MEANS?, and thefragment ?A?
with ?UNDETERMINED?
(whichmeans that no SRA rule matched). The SR correlation weights for document scorecalculation in retrieval (not used for documentpresentation).
For example, if a term occurs ina PURPOSE context in the request and occursin a PURPOSE context in the document as well,its BM25 term weight can be upweighted.The above simple example of using PURPOSEand MEANS as SRs has been shown to be effec-tive for retrieving highly relevant documents fromthe NTCIR-2 English test collection (Sakai et al,2002a).
However, we have also found that it is dif-ficult to devise SRA rules that work across differentrelevance levels or across different document types.This lead us to explore an alternative way of utilisingSRA, i.e.
for document summarisation/presentation.3.3 Information DistillerThe Information Distiller can interactively gener-ate generic or query-specific summaries of a re-trieved document by extracting fragments (usuallysentences) that meet specified criteria.
The uniquefeature of BRIDJE as a CLIA system is that itsupports interactive selection of fragments basedon SRA: For example, the user can select frag-ments whose SRs are TOPIC/AIM, BACKGROUND,RESULT/CONCLUSION, OPINION, and so on.
Inaddition, the Information Distiller can generate leadand tf -idf -based extracts, and these criteria can becombined with SRA requirements.
The summariesthus produced (or the original document text) can betranslated back into source language using MT.4 Evaluation of Partial DisambiguationThis section compares partial disambiguation withtraditional full disambiguation for search requesttranslation in CLIR.4.1 Experimental SettingWe used three English-Japanese test collections:NTCIR-3 E-J (Chen et al, 2003), NTCIR-2 E-J (Kando, 2001) and BMIR-J2 E-J (Sakai et al,1999a; Sakai et al, 1999b) 1.
As BMIR-J2 E-Jhas two English topic sets X and Y translated froma single Japanese topic set (Sakai et al, 1999a), we1Data in BMIR-J2 is taken from the Mainichi Shimbun CD-ROM 1994 data collection.
BMIR-J2 was constructed by theSIG Database Systems of the Information Processing Society ofJapan, in collaboration with the Real World Computing Partner-ship.performed four sets of E-J CLIR experiments in total.On the other hand, we used two Japanese-Englishtest collections: NTCIR-3 J-E (Chen et al, 2003)and NTCIR-2 J-E (Kando, 2001).
Table 1 sum-marises the features of these five test collections.As they provide multiple relevance levels, the num-ber of relevant documents summed across topics areshown for each relevance level: S-relevant (highlyrelevant), A-relevant (relevant), and B-relevant (par-tially relevant).
There are no S-relevant documentsfor BMIR-J2.Following the practice at NTCIR, we computedMean Average Precision (MAP) based on ?relaxed?relevance (which treats S,A and B-relevant docu-ments as relevant) and on ?rigid?
relevance (whichtreats S and A-relevant documents as relevant) (Chenet al, 2003; Kando, 2001).
In addition, for unifiedevaluation with multiple relevance levels, we usedAverage Gain Ratio (AGR) (Sakai et al, 2003; Sakai,2003).
For testing statistical significance, we usedthe sign test.For each test collection, full disambiguation andpartial disambiguation queries were generated us-ing the topic descriptions.
Although our MT systemhas several domain-specific dictionaries, we used thegeneral dictionary only.
For the NTCIR-3 E-J exper-iment, the BM25 and PRF parameters were tunedusing the dryrun topics (Sakai et al, 2003).
For allother experiments, Okapi/BM25 defaults were used,and the number of pseudo-relevant documents andthat of expansion terms were fixed to 10 and 30,respectively (Sakai, 2001).4.2 ResultsTable 2 summarises the results of our CLIR exper-iments.
Full disambiguation runs with and withoutPRF are denoted by FD+PRF and FD, while the cor-responding partial disambiguation runs are denotedby PD+PRF and PD, respectively.
The monolin-gual performances with and without PRF, denotedby ML+PRF and ML, are also shown.
Columns (i),(ii) and (iii) show performances in MAP with relaxedrelevance, MAP with rigid relevance, and MeanAGR (MAGR), respectively.
Runs that significantlyoutperform FD are indicated by ??s, while thosethat significantly outperform PD are indicated by?y?s.
For example, Table 2A Column (i) includethe following information in terms of relaxed MAP:Table 1: Test Collectionsname #topics #S/A/B-rel docs #docs document typeEnglish-Japanese test collectionsNTCIR-3 E-J 42 330/1324/884 236,664 Mainichi newspaper 1998-1999NTCIR-2 E-J 49 465/2815/1813 736,158 conference paper abstracts+ grant-in-aid research report abstractsBMIR-J2 E-J 50(X) 0/624/1057 5,080 Part of Mainichi newspaper 199450(Y )Japanese-English test collectionsNTCIR-3 J-E 32 116/328/297 22,927 Mainichi Daily News 1998-1999+ Taiwan News / ChinatimesEnglish News 1998-1999NTCIR-2 J-E 49 214/1196/726 322,058 conference paper abstracts+ grant-in-aid research report abstracts(a) PD+PRF is 8% better than FD+PRF, and signifi-cantly better than FD (  ) and PD (  );(b) FD+PRF is not significantly better than FD andPD (hence the lack of ??s and ?y?s); and (c) PD is6% better than FD, but this difference is not statisti-cally significant (hence the lack of ??s).The following are general observations made fromTable 2: PD outperforms FD for all test collections interms of all three evaluation measures.
Theimprovements are 1-11%.
The differences arestatistically significant in Table 2C Columns (i)and (iii), for Topic Set Y (  ). PD+PRF outperforms FD+PRF for all test col-lections in terms of all three evaluation mea-sures.
The improvements are 1-8%.
Althoughthese differences are not statistically significantby direct comparison, the ??s and ?y?s, whichindicate superiority over FD and PD, suggestthat PD+PRF is superior to FD+PRF in gen-eral.
(Table 2B is an exception: here, thereis no statistical evidence which suggests thatPD+PRF is superior to FD+PRF.
However,note that PD+PRF outperforms FD+PRF onaverage even for this test collection.
) In general, PRF preserves the positive effect ofpartial disambiguation.
For example, Table 2AColumn (ii) shows that PD is 8% better thanFD, and that PD+PRF is also 8% better thanFD+PRF.
(Table 2C is an exception: For ex-ample, in Column (ii), PD+PRF(Y ) is only 2%better than FD+PRF(Y ) even though PD(Y ) is11% better than FD(Y ).
)Thus, the small advantage of partial disambiguationover full disambiguation is consistent across the fivetest collections (six topic sets) and across the twolanguage permutations.Table 3(a) compares FD and PD for each test col-lection in terms of average number of query termsper topic.
For the E-J topics, the PD queries areapproximately three times longer than the FD ones.Compared to this, the FD and PD queries for the J-Etopics are relatively similar in length.
That is, seman-tic analysis in J-E MT generally yields fewer transla-tion candidates than that in E-J MT does.
However,the relationship between the number of alternativetranslations and the success of partial disambigua-tion is not straightforward: While the E-J results aremore successful than the J-E results for NTCIR-3(Table 2A vs D), suggesting that ?adding more termsis better?, this is not true for NTCIR-2 (Table 2Bvs E).
This is probably because the quality of thealternative translations vary widely, as we shall seelater.Table 3(b) shows the total number of out-of-vocabulary words for each topic set.
Neither FDnor PD could translate these words as our generalMT dictionary was not tuned in any way for our ex-periments.
The NTCIR-3 E-J topic set containedthree out-of-vocabulary words, including ?Tomi-ich?
which is a misspelling of ?Tomiichi (Mu-rayama, a former Japanese prime minister)?, whilethe NTCIR-3 J-E topic set contains five, including?konpyuta??
which is a misspelling of ?konpyu?ta??
or?konpyu?ta?.
Meanwhile, almost all of the out-of-vocabulary words in the NTCIR-2 E-J and J-E topicsets were technical terms.
However, there was notopic that contained more than one out-of-vocabularyTable 2: Partial disambiguation vs full disambiguation.
(i) relaxed MAP (ii) rigid MAP (iii) MAGRA.
NTCIR-3 E-JML+PRF 0.4308 0.3715 0.6130ML 0.3953 0.3368 0.5854PD+PRF 0.3846(+8%)   y 0.3365(+8%)   yy 0.5835(+5%)   yyFD+PRF 0.3575 0.3121 0.5561 PD 0.3351(+6%) 0.2874(+8%) 0.5400(+3%)FD 0.3158 0.2672 0.5250B.
NTCIR-2 E-JML+PRF 0.2903 0.3039 0.4076ML 0.2462 0.2650 0.3478PD+PRF 0.2461(+3%) y 0.2769(+3%)   y 0.3562(+1%)  y yFD+PRF 0.2391   yy 0.2691   yy 0.3536   yyPD 0.1898(+3%) 0.2229(+3%) 0.2839(+1%)FD 0.1845 0.2157 0.2810C.
BMIR-J2 E-JML+PRF 0.4653 0.4135 0.6736ML 0.4345 0.3792 0.5485PD+PRF(X) 0.3816(+4%)   yy 0.3532(+3%)   yy 0.5870(+2%)  y yFD+PRF(X) 0.3658  0.3434   yy 0.5751PD(X) 0.3380(+6%) 0.3009(+2%) 0.4192(+6%)FD(X) 0.3196 0.2936 0.3939PD+PRF(Y ) 0.3522(+6%)   yy 0.2949(+2%)  0.5660(+4%) FD+PRF(Y ) 0.3333  0.2879  0.5423 PD(Y ) 0.2965(+7%)  0.2538(+11%) 0.4307(+11%) FD(Y ) 0.2772 0.2291 0.3888D.
NTCIR-3 J-EML+PRF 0.4620 0.4141 0.6698ML 0.4237 0.3809 0.6322PD+PRF 0.4103(+3%)  0.3735(+3%)  0.6112(+1%) yFD+PRF 0.3973 0.3617 0.6038 yPD 0.3676(+3%) 0.3396(+2%) 0.5603(+2%)FD 0.3584 0.3329 0.5497E.
NTCIR-2 J-EML+PRF 0.2644 0.3075 0.4496ML 0.2279 0.2729 0.3811PD+PRF 0.2202(+4%)   yy 0.2440(+4%)   yy 0.3984(+3%)   yyFD+PRF 0.2112  0.2344 y 0.3861   yyPD 0.1870(+5%) 0.2212(+4%) 0.3352(+1%)FD 0.1780 0.2120 0.3297Runs that significantly outperform FD are indicated by ??
(  ) and ??
(  ).Those that significantly outperform PD are indicated by ?y?
(  ) and ?yy?
(  ).The percentages in the PD+PRF rows represent the gain over FD+PRF, while those in the PD rows represent the gain over FD.Table 3: (a)#terms per topic / (b)#out-of-vocabulary words.
(a) (b)FD PDNTCIR-3 E-J 8.6 26.9 3NTCIR-2 E-J 6.5 18.1 4BMIR-J2 E-J (X) 3.1 11.9 1BMIR-J2 E-J (Y ) 3.5 12.3 0NTCIR-3 J-E 11.0 20.1 5NTCIR-2 J-E 13.5 16.0 8word (with one exception), and it appears that out-of-vocabulary words did not directly affect our experi-ments: partial disambiguation managed to improvefive of the eight NTCIR-2 J-E topics that containedan out-of-vocabulary word.Given that the effect of out-of-vocabulary wordsis negligible, one may hypothesize that the advan-tage of partial disambiguation over full disambigua-tion may be smaller with technical papers than withnewspapers, as technical papers contain more tech-nical terms and full disambiguation may be sufficientfor translating them.
By comparing the E-J results(Table 2A-C), it can be observed that partial dis-ambiguation was indeed a little less successful forNTCIR-2 E-J (technical papers) than for NTCIR-3 E-J and BMIR-J2 E-J (newspapers).
However,as our J-E results (Table 2D-E) show comparableperformances for both document types, the abovehypothesis is not fully supported.4.3 Per-topic AnalysesWhile partial disambiguation improves retrieval per-formance on average for all test collections, per-topicanalyses show that it hurts performance for some top-ics, and that there is room for improvement.
Table 4provides some per-topic comparisons of the Aver-age Precision values of FD and PD.
Two examplesare given for NTCIR-3 E-J and for J-E, respectively,where the Japanese descriptions for the latter areshown here in English.
Words that are mentioned inthe discussion below are underlined.As Table 4 shows, PD was hugely successful forE-J Topic 017: The only word that FD translated cor-rectly was ?Kitano?
: ?Director?
was mistranslated as?kanrisha?
(manager), ?Takeshi?
was transliteratedinto katakana (which is not appropriate in this case),and ?films?
was transliterated into ?firumu?
(whichmeans ?camera films?, not ?movies?).
In contrast,PD successfully recaptured the correct translations?kantoku?
(director) and ?eiga?
(films).
However,some inappropriate translations such as ?shikisha?
(orchestra director) and ?torishimariyaku?
(manag-ing director) were added as well, as semantic anal-ysis is not perfect.
Moreover, PD did not help intranslating ?Takeshi?
: although it obtained two kanjispellings for it, they were incorrect for this particularTakeshi Kitano.
(There are more than 40 possiblekanji spellings for ?Takeshi?!)
Nevertheless, the useof synonym operators seems to have absorbed thenegative effect of such inappropriate translations forthis topic.
On the other hand, PD was not success-ful for E-J Topic 004: while FD obtained the cor-rect translations ?denshisho?torihiki?
(E-commerce)and ?naiyo??
(contents), PD added the acronym of?E-commerce?, which happened to hit many nonrel-evant documents that mention ?European Commu-nity?.
(The roman alphabet is often used in Japanesetexts for representing foreign acronyms.)
Moreover,PD added inappropriate translations for ?contents?such as ?mokuji?
(table of contents) and ?yo?ryo??
(ca-pacity).PD was also successful for J-E Topic 031: FDobtained ?optimal?
instead of ?best?, and ?place?instead of ?spot?.
In contrast, PD successfully re-captured ?best?
and ?spot?, even though it also addedsome possibly harmful terms such as ?position?
and?space?.
On the other hand, PD was not success-ful for J-E Topic 050: FD obtained ?dress?
insteadof ?clothing?, to which PD added ?appearance?,?clothes?, ?costume?
and ?garment?.
Meanwhile,FD obtained ?hairstyle?
instead of ?hair styles?, towhich PD added ?hairdo?
and ?coiffure?.
FD ob-tained ?makeup?
instead of ?cosmetics?, to whichPD added ?dressing?
and ?toilet?.As mentioned earlier, while semantic analysis in J-E MT generally yields fewer translations than that inE-J MT does, this difference is not clearly reflected interms of retrieval performance.
One possible causeof this is that the partial disambiguation terms in theJ-E case are more polysemous, e.g.
?space?
and?toilet?, though fewer in number.The above examples suggest that partial disam-biguation may be improved by adopting a more se-lective strategy.
Although we have conducted addi-tional experiments by limiting the number of termsadded by partial disambiguation, this did not im-prove performance as the candidate terms obtainedafter semantic analysis have no priority informationin our MT system.
One possible solution to this isto utilise the corpus statistics such as the documentfrequency so that polysemous words can be filteredout, but this is beyond the scope of this paper.Finally, by looking across the columns of Table 2,it can be observed that the results in terms of MAGRare generally consistent with those in terms of re-laxed/rigid MAP.
This suggests that MAGR is a goodTable 4: Per-topic comparison of Average Precision: FD vs.PD.NTCIR-3 E-JTopicID DESCRIPTION FD PD017 Articles relating [related] to Director Takeshi Kitano?s films.
0.038  0.278004 Find [out] what E-Commerce is and its contents.
0.368  0.283NTCIR-3 J-ETopicID Official English translation of DESCRIPTION FD PD031 Where are the best spots in Kyoto for viewing of 0.504  0.607Japanese maples in their fall color?050 To retrieve documents describing teenagers?
fashion trends 0.330  0.306in clothing, hair styles, cosmetics.Japan-Nepal Health Scientific Expedition -Comparative Epidemiological Studies on theGenesis of Hypertension- (UNDETERMINED)S1: It is generally thought that the increase in blood pressure with age may be avoided by the extremely low sodium intake.
(BACKGROUND)S2: we, however, have noticed that blood pressure hardly increased with age in some communities briefly studied in Nepal since1978, even though the inhabitants take salty foods and beverages.
(TOPIC/AIM)S3: Our purpose was to ascertain this and to clarify the factor(s) influencing no increase in blood pressure with age in terms ofextensive epidemiological standpoint.
(TOPIC/AIM)S9: RESULTS : blood pressure for both sexes was statistically significantly higher in villagers in Bhadrakali than in Kotyang.
(RESULT/CONCLUSION)S16: CONCLUSION : In spite of consuming more than 10g per day of salt in both Kotyang and Bhadrakali, the blood pressurehardly increased with age only in the former, suggesting that the blood pressure may be influenced by physical activity, fat freemass and nutrient consumption rather than salt intake in these villages in Nepal.
(RESULT/CONCLUSION)Figure 1: A summary for NTCIR-2 J-E Topic 0103 (official English translation: ?Correlations between theonset of hypertension and diet, such as salt intake, based on epidemiological surveys in countries other thanJapan?
)substitute for MAP in evaluations using multiple rel-evance levels.5 Information DistillerThis section provides some example summaries andtranslations to illustrate the usefulness of the Infor-mation Ditiller for efficient information access, aswell as some preliminary evaluation results of SRA.5.1 Example Summaries and TranslationsAs this paper is intended primarily for the Englishspeaking community, we provide one example sum-mary in the context of J-E CLIR before they aretranslated by MT into Japanese, and two in the con-text of E-J CLIR after they have been translated byMT into English.
The summaries shown here are allquery-specific, and are based on full disambiguationqueries.Figure 1 shows a sample summary of an Englishtechnical paper abstract that is S-relevant to NTCIR-2 J-E Topic 0132, which is about ?correlations be-tween hypertension and diet.?
Of the 16 sentences inthe original document (excluding the title, shown atthe top of this summary), those which do not containany of the English query terms and those whose SRswere UNDETERMINED have been filtered out, leav-ing only five sentences.
The words that matched thequery terms are shown in boldface, and the Englishexpressions which acted as SRA triggers are under-lined.
For example, Sentence 1 (S1) was tagged withBACKGROUND because the string ?It is generallythought?
matched a regular expression in one of theSRA rules.
If the user desires an indicative summary,BRIDJE can present S2 and S3, which are taggedwith TOPIC/AIM.
Subsequently, if he desires an in-formative summary, BRIDJE can present S9 and S16,which are tagged with RESULT/CONCLUSION.
Ofcourse, the user can specify multiple SRs, choose toread UNDETERMINED sentences, or combine suchusage with tf -idf -based sentence filtering.
Real-time response is easy because SRA for the documentsare done at index time.
Finally, the summary can betranslated into Japanese by MT for the Japanese user.In the above example, only one SR was assignedThe Cannes International Film Festival is challenged shortly.
?
Director Takeshi Kitano and"chrysanthemum Jiro?s summer" are sent.
(TITLE)S1: The [Paris 22-day cooperation] Director Takeshi Kitano who won Golden Lion (Grand Prix) at the Venice Film Festival in1997 will send new work "chrysanthemum Jiro?s summer" into a world?s largest film festival and the competition section of theCannes International Film Festival.
(TOPIC,DATE,TITLE)S4: It is Director Kitano 8 Motome?s work in "the summer of chrysanthemum Jiro."
(TITLE)Figure 2: A translated summary for NTCIR-3 E-J Topic 017: ?Articles relating [related] to Director TakeshiKitano?s films.
?The Emperor and Empress?
 is decided.
(UNDETERMINED)S1: The schedule on which the Emperor and Empress visit Britain and Denmark as a guest of the nation was reported to thecabinet meeting on the 17th, and outlines, such as a welcome event, solidified.
(DATE)S3: Periods are 13 nights and 14 days of May 23 start and June 5 homecoming.
(DATE)S4: After dropping in at Portugal, it will arrive in Britain for 25 days, and from the next day, starting with Queen Elizabeth?swelcome ceremony, a Japanese company besides a start, 3 times of dinner meetings, and 2 times of luncheons visits Wales towhich it has advanced mostly by day?s trip, or a formal event has a friendly talk [ scientists / of a royal association ].
(DATE)S5: Arriving in Denmark is on the afternoon of the 31st.
(DATE)S6: Although there is no formal event, events, such as a welcome ceremony, start the royal palace of lodgings on a visit andfollowing the 2nd, and Queen Margrethe inspects the Copenhagen university, the National Museums, a welfare institution for theaged, etc., and she will go back Denmark earnestly on the afternoon of the 5th on the night of the 4th on the next day.
(DATE)Figure 3: A translated summary for NTCIR-3 E-J Topic 030: ?When, if ever, has the Japanese Emperorbeen to Denmark?
?to each fragment (i.e.
sentence) for simplicity.
How-ever, SRs can be used as orthogonal features, asshown in the next example.Figure 2 shows a sample translated summary (i.e.an MT output) of a Japanese newspaper article thatis S-relevant to NTCIR-3 E-J Topic 017: ?Articlesrelating [related] to Director Takeshi Kitano?s films.
?Words that match those from the source language re-quest are indicated in boldface, and words that corre-spond to the Japanese SRA triggers are underlined.As the search request ends with the word ?films?, it ispossible for BRIDJE to guess that movie titles may beuseful to the user.
Thus, BRIDJE can show S1 and S4to the user by default, as they have been tagged withTITLE based on SRA triggers such as ?kantoku?
(director), ?sakuhin?
(work) and Japanese brackets.Note also that S1 has two more SRs, TOPIC andDATE.
Unfortunately, the correct English translationof the movie title is ?Kikujiro?s summer?
: Kikujirois a very unusual Japanese name, while Jiro is a com-mon first name.
Besides, kiku does mean chrysan-themum the flower!
Nevertheless, we view this ex-ample as one step towards cross-language questionanswering, which deals with questions such as ?Listup Takeshi Kitano?s Japanese films - give me roughtranslations in English.
?Similarly, Figure 3 shows a translated summaryof a Japanese newspaper article that is S-relevant toNTCIR-3 E-J Topic 030: ?When, if ever, has theJapanese Emperor been to Denmark??.
By perform-ing SRA on this ?when?
question, it is possible forBRIDJE to guess that the user is looking for DATE-type information, as in question answering.
In such acase, BRIDJE can present a list of sentences contain-ing dates as shown.
Even though the translations arefar from perfect, the English speaking user can prob-ably guess, by reading S3, S5, and S6 that the answerto the question is ?from May 31st to June 4th or 5th?.Combining this with the meta-data of this document,a sophisticated cross-language question answeringsystem would output the year ?1998?
as well.
Un-fortunately, the document title in Figure 3 containsa kanji word which MT failed to translate: ?ho?o?bi?
(dates for visiting Europe), shown as ??
inthis paper to avoid Japanese fonts.The above three examples illustrate the usefulnessof SRA for efficient access to the desired informa-tion within an English or a Japanese document, andfor allowing different views for summarising a doc-ument.
Moreover, we have argued that current MTtechnology can be useful for CLIA despite its limitedquality.
By performing SRA-based sentence filter-ing, the amount of MT output that the user has to gothrough can be kept to a minimum.Table 5: SRA precision for NTCIR-2.Semantic Role #fragments PrecisionA.
NTCIR-2 English documentsTOPIC/AIM 72 (12%) 100%RESULT/ 58 (10%) 98%CONCLUSION (57/58)BACKGROUND 8 (1%) 100%OPINION 0 (0%) -SubTotal 138 (23%) 99%(137/138)UNDETERMINED 454 (77%) -Total 592 (100%) -B. NTCIR-2 Japanese documentsTOPIC/AIM 82 (15%) 96%(79/82)RESULT/ 42 (8%) 100%CONCLUSIONBACKGROUND 27 (5%) 93%(25/27)OPINION 7 (1%) 100%SubTotal 158 (31%) 97%(153/158)UNDETERMINED 355 (69%) -Total 513 (100%) -5.2 Precision of SRAAs the Information Distiller is an interactive sub-system, user-oriented, overall usefulness evaluationsshould be performed.
As a first step, however, weevaluate the precision of the SRA rule sets that wereactually used to generate the aforementioned exam-ples.
The results reported here are only indicative asthe rule sets are experimental versions.By using S-relevant documents as training data,one SRA rule set was devised for each of the fourdocument collections: NTCIR-2 English/Japanese(technical papers) and NTCIR-3 English/Japanese(newspapers).
Then, for each collection, we pre-pared a test set of documents A as follows: Let Sand A be the set of unique S-relevant and A-relevantdocuments, respectively.
Take 100 A-relevant doc-uments at random from the set A  S and let thisset be A.
This ensures that the test sets consist ofunknown documents only, even if a document that isA-relevant for a certain topic is S-relevant for anothertopic.SRA was performed on all fragments (i.e.
sen-tences) from A for each collection.
Then, thefirst author examined each fragment and judgedwhether the assigned SR was ?acceptable?
or not.Here, ?unacceptable?
SRs are those that wouldTable 6: SRA precision for NTCIR-3.Semantic Role #fragments PrecisionC.
NTCIR-3 English documentsTOPIC 157 (6%) 98%(154/157)OPINION 24 (1%) 100%MONEY 43 (2%) 100%YEAR 62 (2%) 100%PERCENTAGE 29 (1%) 100%SubTotal 315 (13%) 99%(312/315)UNDETERMINED 2201 (87%) -Total 2516 (100%) -D. NTCIR-3 Japanese documentsTOPIC 123 (6%) 98%(121/123)COMMENT 171 (8%) 89%(153/171)TITLE 5 (0%) 100%DATE 81 (4%) 98%(79/81)MONEY 27 (1%) 100%PERCENTAGE 22 (1%) 100%SubTotal of 401 (18%) 95%unique fragments (379/401)UNDETERMINED 1772 (82%) -Total 2173 (100%) -probably mislead the user: For example, if afragment from a technical paper is tagged withRESULT/CONCLUSION even though the fragmentin fact provides a BACKGROUND information, thismay cause a misunderstanding and is therefore un-acceptable.
Note also that this evaluation concernsgeneric summary fragments, as they subsume query-focused ones.We define SRA precision as the number of frag-ments with acceptable SRs divided by the total num-ber of fragments.
We do not consider its recall coun-terpart here, because the Information Distiller is sup-posed to filter out many sentences and present ?typi-cal?
sentences only.
Although our current SRA rulesets assign SRs to only a small fraction of given frag-ments, the user can choose to read UNDETERMINEDsentences or select multiple SRs at any time, as dis-cussed earlier.
Thus, the aim of this lenient eval-uation is to ensure that the output of InformationDistiller will ?look okay?
to the user.Tables 5 and 6 summarise our SRA precision re-sults.
Table 5A corresponds to the NTCIR-2 En-glish SRA rule set (which was used to generate thesummary in Figure 1), and 5B corresponds to theTable 7: Unacceptable vs desirable SRs.Assigned SR Desirable SR #fragsA.
NTCIR-2 English docsRESULT/ BACKGROUND 1CONCLUSIONB.
NTCIR-2 Japanese docsTOPIC/AIM BACKGROUND 2TOPIC/AIM RESULT/ 1CONCLUSIONBACKGROUND TOPIC/AIM 1BACKGROUND RESULT/ 1CONCLUSIONC.
NTCIR-3 English docsTOPIC OPINION 2TOPIC MONEY 1D.
NTCIR-3 Japanese docsTOPIC UNDETERMINED 2COMMENT UNDETERMINED 13COMMENT TITLE 5DATE UNDETERMINED 2NTCIR-2 Japanese SRA rule set.
Table 6C cor-responds to the NTCIR-3 English SRA rule set,and 6D corresponds to the NTCIR-3 Japanese SRArule set (which was used to generate the originalJapanese summaries for Figures 2 and 3).
Forexample, Table 5A includes information such as:(a) Of the 592 fragments extracted from the testset A, only 138 (23%) were tagged with an SR;(b) Of the above 138 fragments, 58 were taggedwith RESULT/CONCLUSION, but one of them wasjudged as unacceptable.
Hence the Precision forthis SR is 57/58=98%; (c) As the abovementionedfragment was the only unacceptable one, the overallprecision is 137/138=99%.The one unacceptable fragment tagged withRESULT/CONCLUSION was: ?As Kipps?s recog-nition algorithm does not give us a way to extractany parsing result, his algorithm is not consideredas a practical parsing algorithm.?
which acciden-tally matched an SRA rule that included ?result?
as atrigger.
As shown in Table 7A, this fragment shouldprobably be tagged with BACKGROUND, since it dis-cusses previous work rather than the author?s presentwork.Similarly, Tables 5B and 7B show the results forthe NTCIR-2 Japanese SRA rule set which is verysimilar to its English counterpart.
As there were fiveunacceptable cases, its overall precision is 97%.Tables 6C and 7C show the results for the NTCIR-3 English SRA rule set.
Three fragments tagged withTOPIC were judged as unacceptable, one of whichwas: ?But I?ve always said that I won?t compromisewhen it comes to demanding that the facts surround-ing the incident come out in the open.?
This fragmentaccidentally matched an SRA trigger ?said that?, de-signed to match fragments such as ?The prime min-ister said that.
.
.
?Tables 6D and 7D show the results for the NTCIR-3 Japanese SRA rule set.
Unlike the other SRA rulesets, the SRs in this rule set were defined as or-thogonal features, which allowed multiple SRs perfragment as in Figure 2.
(Hence the SubTotal rowprovides information on distinct fragments.)
Asmany as 18 fragments were incorrectly tagged withCOMMENT, due to our reliance on Japanese brack-ets as SRA triggers: words surrounded by bracketsare often technical terms or movie/book titles, ratherthan quoted comments.
Moreover, two fragmentswere incorrectly tagged withDATE as they containedthe word ?ichinichi?
(one day), whose spelling is thesame as ?tsuitachi?
(first [of January]).To summarise our preliminary results: Our ex-perimental SRA rule sets can assign SRs to 13-31%of completely unknown English/Japanese sentences(but from known document genres), with precisionof 95-99%.
Moreover, SRA precision would be evenhigher for query-focused summaries.
Thus, the SRspresented by the Information Distiller would proba-bly look satisfactory to the user.6 ConclusionsThis paper introduced two new features of theBRIDJE system, namely, partial disambiguationfor effective CLIR and document summarisa-tion/presentation based on Semantic Role Analysis.We showed that the advantage of partial disambigua-tion over full disambiguation is consistent across fivetest collections, with four English-Japanese and twoJapanese-English topic sets.
As for document pre-sentation using the Information Distiller, we haveprovided examples as well as preliminary evalua-tions to show that it can be useful for efficient andinteractive cross-language information access.
Top-ics of our future work include: Improving partial disambiguation by beingmore selective; Extensive and user-oriented evaluations of theInformation Distiller; User-oriented query expansion using the Infor-mation Distiller; Expanding our language scope, for example, toChinese; and Building a true cross-language question answer-ing system.ReferencesAmano, S., et al: The Toshiba Machine Translation Sys-tem, Future Computing Systems, Vol.
2, No.
3 (1989).Capstick, J. et al: A System for Supporting Cross-Lingual Information Retrieval, Information Processingand Management, Vol.
36, No.
2, pp.
275?289 (2000).Chen, K.-H. et al: Overview of CLIR Task at the ThirdNTCIR Workshop, NTCIR-3 Proceedings (2003).Frederking, R. et al: Translingual Information Access,AAAI Spring Symposium Cross-Language Text andSpeech Retrieval.Gachot, D. A., Lange, E. and Yang, J.: The SYSTRANNLP Browser: An Application of Machine TranslationTechnology in Cross-Language Information Retrieval,In (Grefenstette, 1998).Grefenstette, G.
(ed.
): Cross-Language Information Re-trieval, Kluwer Academic Publishers (1998).Higuchi, S. et al: PRIME: A System for Multi-lingualPatent Retrieval, MT Summit VIII, pp.
163?167 (2001).Jones, G. J. F. et al: A Comparison of Query Trans-lation Methods for English-Japanese Cross-LanguageInformation Retrieval, ACM SIGIR ?99 Proceedings,pp.
269?270 (1999).Kando, N.: Overview of Japanese and English Infor-mation Retrieval Tasks (JEIR) at the Second NTCIRWorkshop, NTCIR-2 Proceedings, pp.
73?96 (2001).Oard, D. W. and Resnik, P.: Support for InteractiveDocument Selection in Cross-Language InformationRetrieval, Information Processing and Management,Vol.
35, No.
3, pp.
363?379 (1999).Pirkola, A: The Effects of Query Structure and DictionarySetups in Dictionary-Based Cross-Language Informa-tion Retrieval, ACM SIGIR ?98 Proceedings, pp.
55?63(1998).Robertson, S. E. and Sparck Jones, K: Simple,Proven Approaches to Text Retrieval, ComputerLaboratory, University of Cambridge (1997).http://www.ftp.cl.cam.ac.uk/ftp/papers/reports/#TR356Sakai, T. et al: A Study on English-to-Japanese /Japanese-to-English Cross-Language Information Re-trieval using Machine Translation (in Japanese), IPSJJournal, Vol.
40, No.
11, pp.
4075?4086 (1999).Sakai, T. et al: BMIR-J2: A Test Collectionfor Evaluation of Japanese Information RetrievalSystems, ACM SIGIR Forum, Vol.
33, No.
1(1999).http://www.acm.org/sigir/forum/F99/tetsuya.sakai.pdfSakai, T.: Japanese-English Cross-Language Informa-tion Retrieval Using Machine Translation and Pseudo-Relevance Feedback, IJCPOL, Vol.
14, No.
2, pp.
83?107 (2001).Sakai, T. et al: Retrieval of Highly Relevant Documentsbased on Semantic Role Analysis (in Japanese), Forumon Information Technology 2002 Information Technol-ogy Letters, pp.
67?68 (2002).Sakai, T. et al: Generating Transliteration Rules forCross-Language Information Retrieval from MachineTranslation Dictionaries, IEEE SMC 2002 (2002).Sakai, T. et al: Toshiba KIDS at NTCIR-3, NTCIR-3 Proceedings (2003).
http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings3/NTCIR3-CLIR-SakaiTSakai, T.: Average Gain Ratio: A Simple Retrieval Per-formance Measure for Evaluation with Multiple Rele-vance Levels,ACM SIGIR 2003 Proceedings, to appear(2003).Susaki, S., Hayashi, Y. and Kikui, G: Navigation Inter-face in Cross-Lingual WWW Search Engine, TITAN,AUUG ?96 & Asia Pacific World Wide Web, http://www.csu.edu.au/special/auugwww96/proceedings/susaki/susaki.html (1996).Suzuki, M. et al: Customer Support Operation witha Knowledge Sharing System KIDS: An Approachbased on Information Extraction and Text Structuriza-tion, IIIS SCI 2001 Proceedings, pp.
89?94 (2001).World Multiconference on Systemics, Cybernetics andInformatics, International Institute of Informatics andSystemicsYamabana, K. et al: A Language Conversion Front-Endfor Cross-Language Information Retrieval, In (Grefen-stette, 1998).
