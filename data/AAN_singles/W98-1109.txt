Refining the Automatic Identification of Conceptual Relations inLarge..scale CorporaAlex Collier, Mike Pacey and Antoinette RenoufResearch and Development Unit for English StudiesUniversity of LiverpoolAbstractIn the ACRONYM Project, we have taken theFirthian view (e.g.
Firth 1957) that context is partof the meaning of the word, and measuredsimilarity of meaning between words throughsecond-order collocation.
Using large-scale, freetext corpora of UK journalism, we have generatedcollocational data for all words except for high-frequency grammatical words, and have foundthat semantically related word pairings can beidentified, whilst syntactic relations aredisfavoured.
We have then moved on to refinethis system, to deal with multi-word terms andidentify changing conceptual relationships acrosstime.
The system, conceived in the late 80's anddeveloped in 1994-97, differs from others of the90's in purpose, scope, methodology and results,and comparisons will be drawn in the course ofthe paper.IntroductionThe team at Liverpool has created over the yearsa series of automated systems for handling andextracting information from large textual corpora.These systems consist of software and knowledgebases derived from those same textual resources.Most recently, the system known as ACRONYM(Automated Collocational Retrieval of 'Nyms')has involved the identification of conceptuallyrelated items.
These are referred to as 'nyms', byanalogy with 'synonyms' and other sense relateditems, as a reflection of the fact that it isconceptual similarity that is being discoveredthrough collocation.Like its predecessors, the ACRONYMsystem has a dual purpose.
On the one hand, it isintended to generate pairs or clusters of itemswhich can function as alternative search terms ina diachronic text retrieval environment.
On theother, it is intended to support a description of thethesaurus in text.
In the latter application, theprecise nature of the nyms generated by a giventarget word is important.The basic system for identifyingconceptual relationsThe starting point for the nyrnic identificationsystem is the raw text from which thesauralrelations are to be derived.
This corpus currentlycontains over 300 million words from TheIndependent ewspaper from 1988 to 1997.
Aswith similar work (e.g.
Brown et al1992), the sizeof the corpus makes preprocessing such aslemmatization, POS tagging or partial parsing, toocostly.
The sole preprocessing performed on thecorpus is thus the relabelling of numeric tokensinto general categories.During this preprocessing stage, thecorpus is also integerised and indexed.
Thisincreases efficiency during later processingstages, in particular the creation of the collocate?
database.
Within the system, collocates are bydefault defined as the four words to the left andright of every word.
The only exceptions to thisrule are that collocates are not recorded for a setof 253 stopwords (high frequency terms;grammatical words, numeric labels and someverbs), and these are also not recorded ascollocates of any other word.
The raw frequenciesof left and right span collocates for a given word-pair are merged, and their significance measured,using a Z-score statistic.
Statistically significantcollocates are then stored as a sparse matrix in thecollocate database.
A corpus of 3 x 108 words and1.5 X 10 6 word types produces just over 4.8 x 10 6statistically significant collocates (using a liberalthreshold for significance).We refer to the set of statisticallysignificant collocates for a given word as a'collocational profile'.
Similarity between any76two given words is ~then measured throughcomparison of their pr?
files; the measure itself isbased on the size of tae profiles of both wordsand the number of collocates they share (i.e.,second order collocarion), and also on thecollocation between those two words (first ordercolloc~ation).The definition of'what constitutes first-- order collocation differs f,.~r different researchers.For example, the corpus described inGrefensttette (1992) is comparatively small,allowing for extensive preprocessing, includingPOS tagging and partial parsing.
Only modifiersand their modified nouns are recorded ascollocating pairs, allowing for a more fine-grained analysis, of just a subset of word classes.In contrast, SchiJtze and Pedersen (1995) treat theset of collocates for a word as a vector containingthe frequencies of collocation with other wordsoccurring within a 40-word window.
Futrelle andGauch (1993) use a similar approach but preservepositional information (i.e., the number of wordsto the left and right of the target word).
Positionalinformation is also retained by Brown et ai(1992), who store collocation information asword n-grams.For very large corpora, a lot ofcollocational information will be generated,making any form of collocational similaritymeasurement computationally expensive.
Again,researchers have adopted iffering approaches tothis problem.
Schtitze and Pedersen (1995) buildtheir collocate vectors using a bootstrap methodinvolving increasingly larger sets of the lexicon,finally constructing a low (20) dimensional wordvector space by Singular Value Decomposition.
Asimpler method is employed bl?
Futrelle andGauch (1993), whereby collocate vectors arerecorded for all word forms, but for each wordform, only its frequency of co-occurrence with thetop 150 most frequent word forms is recorded.The researchers use a 2-word window to the leftand right of the target word, but they alsopreserve the positional information of thecollocates, resulting in a 600-dimension word-vector of mutual information measurements.While there are many different ways torecord collocates, the primary difference betweenthe ACRONYM collocate database and thosedetailed above is the omission both of collocationinvolving grammatical function words, and ofpositional information.
By omitting these twoelements, the resulting collocate database focusesless on the syntagmatic similarity between wordsand more on their paradigmatic relations.Generating conceptually-relatedword pairsThe definition and purpose of word similaritymeasures in the above systems also differ.
Vector-based models define similarity as the cosinemeasure between two words, and the purpose ofSchiitze and Brown's vector-based work is tocluster grammatical word classes automatically.Mutual information-based approaches, such asthose of Brown et ai (1992) and Futrelle andGauch (1993), measure word similarity in thecontext of a set of words to be clustered, typicallywith the aim of clustering for general similarity.The Jaccard coefficient measurement offered byGrefenstette (1992) is the nearest o our own,defining similarity simply in terms of the numberof shared 'attributes' between two words againstthe number of attributes of both.While Schiitze and Pedersen (1993),Brown et al(1992) and Futrelle and Gauch (1993)all demonstrate the ability of their systems toidentify word similarity using clustering on themost frequently occurring words in their corpus,only Grefenstette (1992) demonstrates his systemby generating word similarities with respect o aset of target words.
His purpose is to allow a userto specify a target word, and have the systemreturn an ordered list of related words.
To thisextent, the purpose of the basic ACRONYMsystem is echoed in Grefenstette's work.Given the liberal thresholds currentlyused in the ACRONYM system, such a list ofconceptually related words may contain severaltens of thousands of entries.
As the size of thelexicon renders it computationally infeasible tocalculate all word-pair similarities in advance, thesystem generates word similarity measures for agiven word on the fly, using the collocatedatabase described above.Examples of conceptually-related, ornymic, output are given in Table !
for the nodewords key.
medicine, pretty and testing.77NodekeymedicineprettytestingTable 1:Symsfactor ole element issues areas issueelements figure players componentcomplementary alternative food herbalpreventive genito-urinary modernconventional clinical sciencegood sight looks look awful girl sillyboring looked stupidnuclear random positive curriculum DNAdrug genetic HIV psychometric testsTen top nyms for nodes key, pretty,medicine, testingModification to software to increasesemantic nature of nymic outputThe nymic output in Table !
contains collocatesand other related items, which are relevant inprinciple for IT purposes, but which for linguisticpurposes may be usefully separated out.
This isachieved by using only second order collocation,which boosts semantically (and morphologically)related nymic output, as can be seen in Table 2.Node Nymskey crucial important vital significant essentialmain fundamental major strategic specificmedicine medical medicines sciences mathematicsbiology science chemistry psychologyphysics clinicalpretty fairly quite incredibly extremely terriblyreally nice extraordinarily lovely sexytesting tests test ested assessment monitoringscreening research rigorous clinicalcurriculumTable 2: Nyms for nodes key, pretty, medicine,testing suppressing first order collocatesThe Deese AntonymsThe focussing effect achieved by suppressing firstorder collocational information may be furtherdemonstrated with reference to the work of Deese(1964), cited in Grefenstette (1992), andspecifically to a set of conceptuaily-relatedantonymic pairs which Deese had identified by aseries of psycholinguistic tests.
Grefenstettehypothesised that any system identifying sharedcollocation between words would pick up theDeese antonyms as being strongly related; heexperimented by feeding the 'primer' word foreach of those antonym; into his SEXTANTsystem, and listing the 19 most closely relatedwords produced.The same 'primer' words were fed intothe refined ACRONYM System, i.e.
with first-order collocates uppressed, and the results aredisplayed in Table 3 orn the next page.
(Deeseantonyms, where they o=cur, are capitalised).A basic comparison reveals that theACRONYM system yiel.ls a similar level of results -to Grefenstette's system.
15133 of the Deeseantonyms occur in SEXTANT output as first orsecond most-related word, compared with 13generated by ACRONYM; whilst 16 of the Deeseantonyms appear within the top 10 most relatedwords of SEXTANT output, compared with 18 inoutput from ACRONYM.
Similarly, as withGrefenstette's findings, there are cases whereACRONYM yields a non-Deese antonym which isnevertheless close: see for instance: big-small;dark-pale; deep-surface; happy-unhappy; new-existing; old-modern.
A scrutiny of the actualcontents of each ACRONYM list further revealsthat, like Futrelle and Gauch, ACRONYM whenusing the particular non collocate upweighting ?method iscovers "... (entire) graded fields, ratherthan just pairs of opposites".
Of particularinterest in this respect are the results for big, easy,fast and strong.For some words in Table 3, failure torelate closely to their Deese antonym can in partbe explained by textual domain.
For example, inthe listing for empty, the strongest nyms reflectthe sense of an empty building or structure,suggesting that such a context predominatesthroughout the corpus.
Likewise, with the wordpretty, we see that intensifiers predominate asnyms, with the synonym lovely appearing only in9th place.
Analysis of a random sample of thecorpus reveals that pretty is indeed predominantlyadverbial, and only rarely adjectival.Multi-Word NymsAs described, the basic ACRONYM systemgenerates information on both first and secondorder collocates within its single-word nymicoutput.
First order collocation can be suppressedto enrich the semantic information, as78Primel-activealivebackbadbigblackbottomcleancolddarkdeepdryeasyemptyfasthappyhardheavyhighlargeleftlongnarrownewoldprettyrichrightroughshortsourstrongthinNymsactively organisations groups involved activities effective activity developing vigorousencourageDEAD loved dying die mum frightened loves buried forever lovingdown away ball straight FRONT again foot around yards feetGOOD worse dreadful awful poor terrible nasty stupid silly appallingbigger huge large biggest major larger smaller small massive normousWHITE red brown blue wearing pink yellow green grey leatherTOP relegated side relegation feet foot floor inches table straightwash cool dry cleaning smooth kitchen warm water washing shinyHOT warm dry cool boiling wet salt boiled cooked am pgrey pale brown green bright white blue red thick purpledeeper profound ark intense sand depth surface feelings thick mixturedried hot warm soft brown creamy crisp salt lemon coldeasier difficult impossible harder HARD simple able quick enough unabledeserted filled crowded erelict crammed windows floor surrounded cramped nearbyfaster bowler pace speed bowlers bowling SLOW slowly slower quickpleased unhappy mum nice happily enjoy relaxed OK loving cheerfulharder difficult impossible EASY easier unable trying able enough toughartillery thick huge massive metal large high rain vehicles lowLOW higher lower levels rising highest level increased increase fallingSMALL huge larger vast smaller big tiny substantial mainly plasticleaving ball leave yards corner back injured pulled minutes hotSHORT longer hair dark slow white wearing black down widesteep WIDE broad stretch paths hill lined tiny path brickexisting technology proposed latest development plans current commercial systems designancient Victorian traditional white houses buildings around man black modernfairly quite incredibly extremely terribly really nice extraordinarily ovely looksspicy delicious flavours wealthy sweet fruit flavour ipe soft texturewrong LEFT want freedom rights able back necessary wanted lawmuddy sand wet dirt grass tricky dusty mud trees dampLONG length brief straight ight balls wide wicket quick ballSWEET salty soured spiced delicious tomato soy creamy chilli pungentstronger strongest powerful WEAK strength sharp steady solid underlying stronglyTHICK brown strips pale slices orange fat white creamy softTable 3: Deese antonyms indemonstrated in Tables 1 and 2.
Often, however,these collocates are really part of multi-wordunits, combining with other words to formhyponyms.
They often combine with the targetword itself, thereby forming hyponyms of thetype "ordinate plus modifier'.
These items are ofprime importance in linguistic description, sincethey represent hitherto undocumented differencesbetween the textual thesaurus and the mentallexicon.Another refinement to the basicACRONYM system is therefore achieved when thenyms of the single-word nymic output are re-combined into multi-word units which betterrepresent he target concept.
This procedure iscarried out in two stages.
First, the list of nyms isACRONYM nymic outputprocessed by a software module which attemptsto identify the most likely word pairs that couldbe created by combining the individual nyms,making use of a variety of measures includingcollocational as well as contextual clues from thecorpus database.
The resulting list of wordcombinations, which need not necessarily beadjacent, is passed to a second-stage module,which checks which of these candidate word pairshave collocational environments similar to theoriginal node word.
The benefits of this approachare that no a priori word-pair list needs to beestablished, this being decided by the contents ofthe nym list and by the corpus, and that nocollocational profiles need to be stored for wordpairs.79Tables 4 and 5 display multi-word nymsfor therapy and weapons.gene therapyshock therapyreplacement therapygroup therapyspeech therapyoccupational therapytherapy sessionshormone replacementcancer drugdrug tamoxifensex therapistdrug grouphormone treatmentdrug AZTgroup sexcounselling sessionsintensive treatmentshock treatmentmedical treatmentdrugs groupdrug treatmentcancer patientsTable 4: Multi-word nymic output for therapynuclear weaponschemical weaponsbiological weaponsnuclear armsanti-tank weaponsnuclear warheadsnuclear arsenalweapons capabilitynuclear arsenalsland-based nuclearland-based missileschemical armsair-launched nuclearnuclear capabilitynuclear non-proliferationarms cachesub-machine gunsshort-range nuclearshort-range missileschemical warheadsnuclear missilessemi-automatic weaponsanti-tank missilesballistic missileballistic missilesmissile launchersTable 5: Multi-word nymic output for weaponsIn Tables 4 and 5, a series of multi-wordhyponyms have emerged, several consisting ofadjectives or nouns modifying the node orsynonyms of it.Multi-word nodes are a further refinementof the system.
As with multi-word nymic output,the collocate profiles for multi-word nodes aregenerated on the fly.
Table 6 presents an exampleof the multi-word nymic output for the multi-word node Soviet Union.Soviet Unioneastern EuropeSoviet republicsSoviet republicSoviet forcesEastern blocSoviet nuclearCommunist leadersCommunist governmentSoviet blocAlgirdas BrazauskasCommunist countriesSoviet leadersEast GermanyNato leadersPact countriesformer Easternpolitical independenceTable 6: Multi-word nymic output for SovietUnionSemantic ClusteringAs well as generating flat lists of semanticallyrelated words, the ACRONYM system can performclustering upon a set of nyms, in order to revealtheir semantic inter-relationships.
In ACRONYM,the set of words to be clustered is usually one ofthe flat lists of nyms of the kind displayed above.This is in contrast o work by researchers such asSchiitze and Pedersen (1992), Brown et al(1992)and Futrelle and Gauch (1995), where it is oftenthe most frequent words in the lexicon which areclustered, predominantly with the purpose ofdetermining their grammatical classes.ACRONYM uses two publicly availableclustering tools, PAM and AGNES, described inKaufman and Rousseeuw (1990).
The first, PAM(Partitioning Around Medoids), is a k-medoidpartitioning method, while AGNES is a variant onagglomerative nesting.
Both algorithms allowobject-relations to be represented by a similaritymeasure, which we take as the collocationalprofile similarity measure described earlier.
Anexample of PAM output is shown in Table 7.=== Cluster !
===electricity 0.21privatised 0.15sewerage 0.09supply 0.08mains 0.08companies 0.07newly-privatised 0.06=== Cluster 2 ===hot 0.09aquifers 0.05cavern 0.05=== Cluster 3 ===bottled 0.19ice-cold 0.07carbonated 0.05=== Cluster 4 ===oz 0.30tablespoons 0.17ml 0.16tablespoon 0.14fl 0.09=== Cluster 5 ===litres 0.64gallons 0.48pints 0.38=== Cluster 6 ===pan 0.27heavy-based 0.20heavy-bottomed 0.20lidded 0.I 1=== Cluster 7 ===salt 0.14Dissolve 0.10Soak 0.06=== Cluster 8 ===Add 0.08winched 0.06=== Cluster 9 ===pollution 0.19sediments 0.08fast-flowing 0.07polluted 0.07Table 7: PAM Clustering for waterThe PAM-generated clusters in Table 7are created from the top nyms for water, andreflect several different meanings (senses, uses orreferences) that are associated with the node80word, namely: (1) 'water utility', (2) 'body ofwater', (3) 'type of drinking water', (4) 'fluidmeasurement', (5) 'unit of water', (6) 'liquid usedin cooking', (7) 'medium for certain domesticprocesses', and (9) 'water in various more or lesspure states'.
Some of these senses are fairlyconventional, others are more contextuallydetermined.
Not every cluster is adequate; here,Cluster 8 is weak and uninterpretable.
Takenoverall, it seems that this type of clustering doessharpen the picture for the user of the system.While previous researchers have usedagglomerative n sting clustering (e.g.
Brown et al(1992), Futrelle and Gauch (1993)), comparisonswith our work are difficult to draw, due to theiruse of the 1,000 commonest words from theirrespective corpora.In Brown et al(1992), the authors providesome sample subtrees resulting from such a1,000-word clustering.
The sets of words fromeach subtree have been fed into the ACRONYMclustering system, and the results from AGNESare shown below.
This is not strictly a faircomparison, as the clustering of a superset ofthese words would doubtless create a differentstructure.
Nevertheless, it appears thatACRONYM organises these subsets into a moresatisfactory taxonomy, in contrast with a tendencyin Brown et als system to produce right-heavytaxonomies.In Fig.
I, the last example highlights adistinction between syntax and semantics.
WhileBrown et als system splits the four words alongthe singular/plural divide (i.e., rep-representativeand reps-representatives), ACRONYM splits themsemantically; the abbreviated versions refer tosales-people or those representing travelcompanies, whilst the full versions are used in apolitical context,Identifying Change in ConceptualRelationsThe ACRONYM database has also been designedin such a way that it can be accesseddiachronically.
This facility was incorporated inorder to ensure that the system remains up to datein its application to text retrieval and linguisticdescription, and it has already enabled the Unit toestablish a new words service within its web site(http://www.rdues.liv.ac.uk/newwds.html).The team first explored the way in whichlanguage changes over time in the AVIATORProject (Renouf 1993, Collier 1993, Blackwell1993), where they investigated the dynamicaspects not only of single words, but also of thecollocational behaviour of those words, with thegoal of identifying new collocations or changes inmeaning.
In ACRONYM (Renouf 1996, Collier &Pacey 1996), the collocational and diachronicconcepts have been developed considerably,taking advantage Of improvements in technologyand the greater availability of electronic text.
Theresult is an integrated system of databases andindexes which can be accessed as one virtualentity or divided into any desired configuration ofits constituent parts.
In the current database, thesmallest accessible component, which we refer toas a se~,ment, consists of three months' of textfrom national UK newspapers, containing onaverage ight million running words (tokens).Each segment is composed of anintegerised corpus database?
providing all theusual corpus- and text-retrieval facilities fromsimple frequency information for a single word tothe full KWIC, sentence or article context forboolean (multi-word) searches.
The frequencydata is readily extractable?
allowing a word orphrase to be 'tracked' over time.
In addition, eachsegment has one or more collocate databaseswhich store profiles for each word in the corpus.By comparing the output from two collocatedatabases, the change in coilocational behaviourof any node can be identified in a similar fashionto a change in frequency-of-occurrence.
Asestablished in the AVIATOR Project?
an alterationin a word's profile signals a change in itsmeaning, with a consequent change in the set ofwords which can be regarded as its semanticequivalents.
If we require time scales longer thanthree months, the software needs to perform acomparison across several collocate databasesrather than just two.
In order to accelerate thisprocess, we have added a facility for creatingmerged atabases, for example combining all fourdatabases for 1994 into one.
By using this inconjunction with a similarly merged atabase81\\\\\\charge\ \--- case\--- quest ionletter\ \ \ .... statement\ \--- memo\ - - -  requestdraft\--- p lan\ \ \\ \\ \\\- ana lys isassessment\--- eva luat ionunders tand ing\--- op in ionconversat ion\--- d i scuss ion\ \ \ .
.
.
.
.\ \\ \ - - -\.
.
.
.
.yearmonthhalfquarterweekday.
\ .
.
.
.
.\ \\ - - - -\peop leind iv idualsstudentsaccountscustomersemployeesrepresentat ive\--- representat ivesreps\--- repFigure 1: AGNES clusterings of selected subtreesbased on other individual segments, the collocatecomparison process can be carried out moreefficiently.When identifying nymic change, wegenerally increase the time period to a whole year,to avoid recording any seasonal fluctuations inreal world events.
The usual procedure is to createtwo merged collocate databases, one for the yearin question (the target corpus) and another of allsegment databases prior to that year (the baselinecorpus).
These two databases are then comparedand any significant change in collocate profiles isrecorded.
This may be done for individual wordsor all the words in the corpus.
In looking at thechanged profiles, the collocates are categorisedinto four sets:'up' collocatesthose which have increased in significancein the target corpus;'down' collocatesthose which have decreased insignificance in the target corpus;'new' collocatesthose which have appeared for the firsttime in the target corpus;'gone' collocatesthose which appeared in the baselinecorpus but which are no longer present inthe target corpus.The normal process of nym identification,as explained earlier, finds candidates which haveas many collocates as possible in common withthe target word.
In monitoring the change innymic relationships, however, only thosecollocates which are considered to have changedare involved in this process.
The semanticproximity of the target word to the candidatenyms is therefore measured in terms of thenumber of changed collocates the two words havein common.
If the task is to identify new nyms,then only 'up' and 'new' collocates are used;conversely, 'down' and 'gone' collocates areemployed in finding nyms which have decreasedin significance.
This is exemplified in Table 8,82%which presents the 1997 'up' andfor the node word crisis.threehitSouthOperaoperaEast,Mi~mmcialhighercurrencyBusinessKong~.,~ Hong recruitment ?
.. AsiaAsianPacific: illustratededucationdisciplineBlairanalysts'new' collocatescoal IMFNI-IS Outlookfunding hospitalsprison injuryovercrowding MontserratFar LUCYspread .
Beefenvironmental ThaiStill Coal'suniversity escalatingCHRIS Thailand's1apan's strikerThailand mid-lifedeepened pesoKorean millenniumSouth-east MATTHEWlurched WARDSouth-East BSEGuinea blabChris VINESwinterAsia'sTable 8:1997 'up'/'new' collocates of crisisIt can be seen that the collocates in Table8 refer to a number of crises topical in 1997.
Thenext stage involves the identification of wordswhich share these collocates with the originalnode word crisis in the 1997 collocate database.The output from this is given in Table 9.financial Korea problemscrisis economy investmentAsian Hong South-eastcurrency market fearsfunding Far officialsEast Japan authoritiesSouth Kong stockAsia Letter healtheconomic tiger Bangkokmarkets turbulence IMFyesterday turmoil economiesBusiness educationTable 9:1997 'up' nyms of crisisThe nyms in Table 9, presented indescending order of strength of association, focusmore clearly on the financial crisis rooming inSouth East Asia.Since one of the chief goals of thismethodology is to provide up-to-date informationon thesaural equivalents, it can also be used tofind nyms which have declined in significance.The output is harder to interpret, since thedifference in size between the baseline and targetdatabases results in many more down/gonecollocates than up/new ones.
For crisis, as anexample, there were 3,187 down/gone collocatesbut only 68 new/up ones.
Nevertheless, the nymswhich are generated by using the down/gonecollocates can be useful and interesting.
Tables10a and 10b show nyms for war, using 1993 asthe target corpus and all previous data (1988-1992) as the baseline;civil siege ethnicgenocide warring fightingcrimes fighters enclavewar Karadzic besiegedMuslim-led commanders offensivestronghold embargo UNGorazde Yugoslavia warscleansing Muslims convoysBosnian atrocities IzetbegovicBosnia factions Belgradeaggression Bosnia'sshelling VanceTable 10a: 'up' nyms of war  (1993)In Table 10a, the 'up" nyms are presentedand it can be seen that these all relate to the civilwar in the former Yugoslavia.
In Table 10b, incontrast, those nyms are listed which in 1993?
became less closely associated with war.Gulf Shias militarywar HAERI EgyptiansIran-Iraq MANAGUA ADELIRAQI Iraq ScudsJordanians al-Arab CAIRONICOSIA SAFA DhahranUS-led KABUL al-AssadKhafji emirate starveTEHRAN ISLAMABAD oilfieldswaterway Barco UAEinvading DARWISH SaddamTable 10b: 'down' nyms of war  (1993)The main reference reflected in the 'downnyms' of Table 10b is to the Gulf War, whichfollowed Iraq's invasion of Kuwait.
Theimplication of this evidence is that by 1993, theGulf War had ceased to figure so prominently in83our corpus data and so had become less stronglyassociated with the concept of war.Concluding RemarksThis paper has described the basic ACRONYMsystem, a set of tools which has relevance both totext retrieval applications and to linguisticdescription.
The focus here has been on outliningthe recent modifications which have been carriedout to refine the nymic output to facilitate thelinguistic task of describing the textual thesaurus.Several of them, in particular semantic lustering,are also intended to improve performance indocument retrieval.
The nymic output fromACRONYM intuitively appears to have thepotential to increase both recall and precision, andinitial tests of its effectiveness in this regard havebeen carried out, by using nymic output o extractarticle headlines.
The next stage of the researchwill focus more closely on the evaluation andoptimisation of the system as a text retrievalfacility.BibliographyBlackweli, S. (1993) 'From dirty data to cleanlanguage' in English Language Corpora:Design, Analysis and Exploitation, Papersfrom the 13th International Conference onEnglish Language Research on ComputerizedCorpora, Nijmegen 1992, Aarts, J., P. de Haanand N. Oostdijk (eds) Rodopi, Amsterdam, pp.97-106.Brown, P. F., P. V. de Souza, R. L. Mercer, V. JDella Pietra and J. C. Lai (1992), 'Class-Basedn-gram Models of Natural Language' inComputational Linguistics, volume 18, number4, ACL, MIT Press, pp.
467-479.Collier, A.
(1993) 'Issues of large-scalecollocational nalysis' in English LanguageCorpora: Design, Analysis and Exploitation,Papers from the 13th International Conferenceon English Language Research onComputerized Corpora, Nijmegen 1992, Aarts,J.,P.
de Haan and N. Oostdijk (eds) Rodopi,Amsterdam, pp.
289-298.Collier, A. and M. Pacey (1997), 'A Large ScaleCorpus System For Identifying ThesauralRelations', in Corpus-based Studies in English- Papers from thle seventeenth InternationalConference on ~'nglish Lang,age Research onComputerized Corpora (ICAME 17), Ljung,M.
(ed) pp.
87-100.Deese, J., (1964), "The associative structure ofsome common English adjectives', in Journalof Verbal Learning and Verbal Behaviour 3,pp.
347-357?Firth, JR (1957), Papers in Linguistics, 1934-195I.
London: Oxford University Press.Futrelle, R. P and S. Gauch (1993), 'Experiments?
.
f in Syntactic and Semantic Classification'andDisambiguation Using Bootstrapping', inAcquisition of Lexical Knowledge from Text.1993, pp.
i 17-127.
Columbus, OH.
Assoc.Computational Linguistics?Grefenstette, G (1992), 'Finding SemanticSimilarity in Raw Text: the Deese Antonyms',in AAAI Fall Symposium Series: ProbabilisticApproaches to Natural Language (WorkingNotes), pp.
54-60?
Cambridge MA.Kaufman, L. and Peter J. Rousseeuw (1990),Finding Groups in Data: An hltroduction toCluster Analysis, John Wiley and Sons, NY.Renouf, A.
(1993) 'A word in time: First findingsfrom the investigation of dynamic text' inEnglish Language Corpora: Design, Analysisand Exploitation, Papers from the 13thInternational Conference on English LanguageResearch on Computerized Corpora, Nijmegen1992, Aarts, J., P. de Haan and N.Oostdijk(eds) Rodopi, Amsterdam, pp.
279-288.Renouf, A.
(1996), 'The ACRONYM Project:Discovering the textual thesaurus', inSynchronic orpus linguistics - Papers fromthe 16th International Conference on EnglishLanguage Research on Computerised Corpora(ICAME 16), Percy, C. E, C. F Meyer and lanLancashire (eds).
pp.
17 I- !
88.Schiitze, H. and J. Pedersen (1993) 'A vectormodel for syntagmatic and paradigmaticrelatedness' in Proceedings of the 9th AnnualConference of the UW Centre for the NewOED and Text Research, pp.
104-113, Oxford,England.Schiitze, H. and J. O. Pedersen ( 1995),'Information Retrieval Based on WordSenses', in Fourth Annual Symposium onDocument Analysis and Information Retrieval,pp.
i 6 i - !
75, Las Vegas NV.\84
