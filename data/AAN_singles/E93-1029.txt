Mathematical  Aspects of Command RelationsMarcus  KrachtII.
Mathemat isches Inst i tutArnimaUee 3D - 1000 Berlin 33GERMANYemail: k racht~ath ,  fu -ber l in ,  deAbst rac tIn GB, the importance of phrase-structurerules has dwindled in favour of nearnessconditions.
Today, nearness conditions playa major role in defining the correct linguis-tic representations.
They are expressed interms of special binary relations on treescalled command relations.
Yet, while theformal theory of phrase-structure gram-mars is quite advanced, no formal investi-gation into the properties of command re-lations has been done.
We will try to closethis gap.
In particular, we will study the in-trinsic properties of command relations asrelations on trees as well as the possibil-ity to reduce nearness conditions expressedby command relations to phrase-structurerules.1 In t roduct ion1.1 Historic OriginEarly transformational grammar consisted of arather complex generative component and an equallycomplex and equally imperspicuous transformationalcomponent.
But since the aim always has been tounderstand languages rather than describing them,there has been a need for a reduction of these rulesystems into preferably few and simple principles.The analysis of transformations a  series of move-ments - an analysis made possible by the introduc-tion of empty categories - was one step.
This in-deed drastically simplified the transformational com-ponent.
A second step consisted in simplifying thegenerative component by reducing the rules in favourof well-formedness conditions, o-called filters.
Whilethis turned transformational grammar into a realtheory now known as GB, the relationship of GB withother syntactic formalisms such as GPSG, LFG, cate-gorial grammar etc.
became less and less clear.
Thisin addition to Noam Chomsky's often repeated scep-ticism with respect o formalizations has led to thecommon attitude that GB is simply gibberish, unfor-malizable or hopelessly untractable at best.
How-ever, since it is possible to evaluate predictions oftheories of GB and have constructive debates overthem these theories are if not formal then at leastrigorous.
Hence, it must be possible to formalizethem.
Formalizations of GB have been offered, e. g.in \[Stabler, 1989\] hut in a manner that makes 6Beven less comprehensible.
So if formalization meansproviding as complete as possible intellectual ccessto the formal consequences of an otherwise rigor-ously defined theory the project has failed if everbegun.
More or less the same criticism applies to\[Gazdar et al, 1985\].
Even if 6PsG is rigorously de-fined the formalism as laid out in this book does notlead to an understanding of it's properties.
More orless the same applies to categorial grammar whichmight have the advantage that it's formal proper-ties are well-studied but which suffers from the sameill-suitedness to the human intellect.
The situationcan be compared with computer science.
While it isperfectly possible to reduce programs in PASCAL toprograms in machine language, hardly is anyone in-terested in doing so.
Even if machine language suitsthe machine, we need to provide a higher languageand a translation to make computers eally useful forpractical tasks.
However, as long as we do not knowin linguistics what the 'machine language' of the hu-man mind is, the best we can do at the moment isto provide means to translate in between all thesesyntactical formalisms.
So, even if from the point of240view of universal grammar this gets us no closer tothe language faculty of the human mind, the need tounderstand the formal properties of Gs and the re-lationship between all these approaches remains andmust be satisfied in order to achieve real progress.The theory of command relations forms part of aninvestigation that should ultimately lead to such anunderstanding.
The present paper will sketch thetheory of command relation and is a distilled versionof \[Kracht, 1993\].1.2 Re levance  o f  Command Re lat ionsThe idea to study the formal properties of commandrelations is due to \[Barker and Pullum, 1990\].
Therewe find a definition of command relations as well asmany illustrations of command relations from lin-guistic theory.
In that paper the origins of the no-tions are also discussed.
I guess it is fair to attributeto \[l~inhart, 1981\] the beginning of the study of do-mains.
Moreover, \[Koster, 1986\] presents a impres-sive and thorough study of the role of domains ingrammar.
Yet al this work is either too specificor too vague to lead to a proper understanding ofnearness conditions in grammar.
In \[Kracht, 1992\] Itook the case of \[Barker and Pullum, 1990\] furtherand proved some more results concerning these rela-tions especially the structure of the heyting algebraof command relations.
The latter proved to be oflittle significance in the light of the questions raisedin ?
1.1.
Instead, it emerged that it is more fruitfulto study the properties of command relations underintersection, union and relational composition.
Theyform an algebraic structure called a distributoid.
Thestructure of this distributoid can be determined.
Ifthe grammar is enriched with enough labels, this dis-tributoid contains enough command relations to ex-press all known nearness conditions.
This being so,it becomes an immediate question whether the ef-fect of a nearness condition expressed via commandrelations can be incorporated into the syntax.
Thisis discussed at length in \[Kracht, 1993\].
The resultis that indeed all such conditions are implementable,but this often requires a lot more basic features.
Theexplosion of the size grammars when translating fromGB to GPSG can be explained namely by the neces-sity to add auxiliary features that secure that thegrammar obeys certain nearness restrictions.
A typ-ical example is the SLASH-feature which has beeninvented to guarantee a gap for a displaced filler.With such proof that implementations of nearnessconditions into cfg's can always be given (maybe oncertain other harmless conditions) one is in principledispensed from writing GVSG-type grammars in or-der to make available the rich theory of context-freegrammars.
Now it is possible to transfer this the-ory to grammars which consist both of a generativecontext-free component and a set of well-formednessconditions based on command relations.
In particu-lar, it is perfectly decidable whether two such gram-mars generate the same bracketed strings and henceeffective comparison between two different heoriesof natural language - if given in that format - ispossible.2 Grammat ica l  Re la t ions  on  Trees2.1 Def in i t ionsA t ree  is an object T = iT, <, r) with r the root  and< a tree ordering.
We write x -4 y if z is immediatelydominated by y; in mathematical jargon y is said tocover  z.
A leaf  is an element which does not cover; zis in ter io r  if it is neither a leaf nor the root.
int(T) isthe set of interior nodes ofT.
We put ~ x = {YlY < x}and \]" z = {YlY >-- Z}.
~ X is called the lower and T zthe upper  cone of z.
If R C_ 7 '2 is a binary relationwe write Rx = {ylxRy} and call Rz the R -domalnof z.
A function f : T ~ T is called monotone  ifz < y implies f (x)  < f(y),  i nc reas ing  if  z <_ f(x)for all x, and s t r i c t ly  increas ing  if z < f (z )  for allx<r .Def in i t ion  1 A binary relation R C T 2 is called acommand re la t ion  (CR for short) iff there ex-ists a function fR : T ~ T such that (1), (~) and (8)hold; R is called monotone  if in addition it sat-isfies (4) and t ight  if it satisfies (5) in addition to(1) - (3).
fR is called the assoc ia ted  funct ionof R.(1) Rr = ~fR(x)(2) z < fR(z) for all z < r(3) fRO ' )  = ,"(4) z < y implies fR(z) < fR(Y)(5) x < fR(y) impZies fR(x) <_ fR(y).
(1) expresses that fR(z)  represents R; (2) and (3) ex-press that fR must be strictly increasing.
If (4) holds,fR is monotone.
A tight relation is monotone; for ifz _< y and y < r then y < fR(Y) and so z < fR(Y);whence fR(z) _< fR(Y) by (5).
For some reason\[Barker and Pullum, 1990\] do not count monotonic-ity as a defining property of CRs even though thereis no known command relation that fails to be mono-tone.Given a set P _C T we can define a function gp by(t) gp(z) = min{yly ?
P, y > z}We put minO = r; thus gp(r) = r. Let zPy iffy < gp(z), gp is the associated function of P, arelation commonly referred to as P -command.
Wecall P the basic set of gp as well as P.Here are some examples.
With  P the set of branch-ing nodes P is c-command, with P = T we have thatP is IDC-command.
When we take P to be the set ofmaximal projections we obtain that P is M-command,and, finally, with P the set of bounding nodes, e. g.{NP, S}, the relation P defined becomes identical toLasnik's KOMMAND.
Lasnik's KOMMAND i8 identicalto 1-node subjacency under the typical definition ofsubjacency.241Relations that are of the form P for some P arecalled fair.Theorem 2 R is fair iff it is tight.
There are2 ~I"'(T) distinct tight CRs on T.Proof .
(=~) Assume x < gp(y) = min{z E Plz >y}.
Then gp(z) = min{z E P\]z > z} <_ gp(y)since gp(y) E P.
(?
:) Put P = {fR(z)\]z E T}.We have to show (t)- By (5), however, f it(z) =min{fit(z)\]fit(z) > z}.
For the second claim observefirst that if P, Q differ only in exterior nodes thenP = Q.
If, however, z E P - Q is interior then y -< zfor some y and gp(y) = z but go(Y) > z.
?Tight relations have an important property; evenwhen the structure of the tree is lost and we knowonly P we can recover gp and < to some extent.
No-tice namely that if Px ?
T then gp(z) is the uniquey such that y E Px but the P-domain of y is largerthan the P-domain of z.
We can then exactly saywhich elements are dominated by y: exactly the el-ements of the P-domain of z.
By consequence, ifwe are given T, the root r and we know the IDC-command omains, < can be recovered completely.This is of relevance to syntax because often the treestructures are not given directly but are recoveredusing domains.2.2 Lat t i ce  S t ructureLet f,  g be increasing functions; then define( f  LIg)(z)  "- maz{f(z),g(z)}( f  ng) (z )  = min{f(z),g(z)}( fog)(z)  = f (g(z))Since f (z ) ,g (z )  >_ z, that is, f ( z ) ,g (z )  E ~z andsince T z is linear, the maximum and minimum arealways defined.
Clearly, with f and g increasing, f LIg, f\[qg and fog are also increasing.
Furthermore, if fand g are strictly increasing, the composite functionsare strictly increasing as well.Lemma 3 fRus = fit U fs.
fitns = fit R fs.Proof .
z <_ fitus(X) iff z (R U S)z iff either zRzor zSz iff either z <_ fR(z) or z < fs(z) iff z <maz{fR(z), fs(z)}.
Analogously for intersection, iTheorem 4 For any given tree T the command re-lations over T form a distributive lattice Er(T) =(Cr(T), N, U) which contains the lattice 93Ion(T) ofmonotone CRs as a sublattice.Proof .
By the above lemma, the CRs over T areclosed under intersection and union.
Distributivityautomatically follows since lattices isomorphic to lat-tices of sets with intersection and union as opera-tions are always distributive.
The second claim fol-lows from the fact that if fR, fs are both monotone,so is fit I I fs  and fit n fs.
We prove one of theseclaims.
Assume z < y.
Then f it(z) _< fa(Y) andfs (z)  _< fs(Y), hence f it(z) _< max{fR(y),fs(y)}as well as fs(=) <_ maz{fit(u), fs(u)}.
Somax{fit(=), fs(=)} _< max{fn(y), fs(y)} and ther -fore fRus(z) < fRus(y), by definition.
?P ropos i t ion  5 gPuq = gP \[7 go.
Hence tight rela-tions over a tree are closed under intersection.
Theyare generally not closed under closed union.Proof.
Let P, Q c_ T be two sets upon which therelations P and Q are basedl Then the intersection ofthe relations, P N Q, is derived from the union P U Qof the basic sets.
Namely, gpuq(Z) = min{yly E PUQ,y > z} = min{min{yly E P ,y  > z}, min{yly EQ,y > z}} = min{gp(z) ,go(z)}  = (gp r\] go) (x ) .To see that tight relations are not necessarily closedunder union take the union of N P-command and S-command.
If it were tight, the nodes of the form g(z)for some z define the set on which this relation mustbe based.
But this set is exactly the set of boundingnodes, which defines Lasnik's kommand.
The latter,however, is the intersection, not the union of theserelations.
?The consequences of this theorem are the follow-ing.
The tight relations form a sub-semilattice of thelattice of command relations; this semi-lattice is iso-morphic to (2 int(T), U).
Although the natural join oftight relations is not necessarily tight, it is possibleto define a join in the semi-lattice.
This operationis completely determined by the meet-semilatticestructure, because this structure determines the par-tial order of the elements which in turn defines thejoin.
In order to distinguish this join from the or-dinary one we write it as P ?
Q.
The correspondingbasic set from which this relation is generated is theset PNQ; this is the only choice, beacuse the semilat-mr(T) t ice/2' , U) allows only one extension to a lattice,namely (2 int(T), U, N).
The notation for associatedfunctions is the same as for the relations.
If gp andgq are associated functions, then gp ?
go = gPnqdenotes the associated function of the (tight) join.2.3 Compos i t ionFor monotone relations there is more structure.
Con-sider the definition of the relationM productR o S = {(z, z) l(3y)(znyaz)}Then fitos = fs o fR (with converse ordering!).
Fora proof consider the largest z such that x(R o S)z.Then there exists a g such that zRySz.
Now lettj be the largest g such that zRy.
Then not onlyzR~ but also tgSz, since S is monotone.
By choiceof ~, ~ = fn(z) .
By choice of z, z = fs(~t), sincefs(~t) > z would contradict he maximality of z. Intotal, z = (fs o f i t)(z) and that had to be proved.From the theory of binary relations it is knownthat o distributes over U, that is, that we have R o(S U T) = (R o S) U (R o T) as well as (S U T) o R =(S o R) U (T o R).
But in this special setting o alsodistributes over N.P ropos i t ion  6 Let R, S, T be monotone CRs.
ThenRo(SNT)  = (RoS)  N(RoT) , (SNT)o  R= (SoR) N (T o R).Proof .
Let z(R o (S N T))z, that is, zRy(S N T)z,that is, zRySz and zRyTz for some y.
Then, by242definition, x(R o S)z and x(R o T)z and so x((R oS) fq (R o T))z. Conversely, if the latter is true thenx(R o S)z and x(R o T)z and so there are Yl, Y2 withxRylSz and xRy2Tz.
With y - max{yl,y2} wehave xRy(S M T)z since S, T are monotone.
Thusx(R o (s  n T))z.
Now for the second claim.
Assumez((S N T) o R)z, that is, x(S fq T)yRz for some y.Then xSy, xTy and yRz, which means x(SoR)z andx(T  o R)z and so x((S o R) M (T o R))z. Conversely,if the latter holds then x(S o R)z and x(T o R)z andso there exist Yl, Y2 with xSylRz and xTy2Rz.
Puty = rain{y1, Y2}.
Then xSy, xTy, hence x(S M T)y.Moreover, yRz, from which x( ( S N T) o R)z.
?Def in i t ion  7 A d i s t r ibuto id  is a structure fO =(D, N, U, o) such thai (1) (D, n, u) is a distributivelattice, (2) o an associative operation and (3) o dis-tributes both over M and U.Theorem 8 The monotone CRs over a given treeform a distributoid enoted by ~Diz(T).
?2.4 Normal  FormsThe fact that distributoids have so many distributivelaws means that for composite CRs there are quitesimple normal forms.
Namely, if 9t is a CR com-posed from the CRs R1,.
?., Rn by means of M, U ando, then we can reproduce 91 in the following simpleform.
Call ~ a cha in  if it is composed from the Riusing only o.
Then 91 is identical to an intersectionof unions of chains, and it is identical to a union ofintersections of chains.
Namely, by (3), both M andU can be moved outside the scope of o.
Moreover, flcan be moved outside the scope of U and U can bemoved outside the scope of N.Theorem 9 (Normal  Forms)For every 91 = 91(R1, .
.
.
,Rn)  there exist chains?
{ = ?
{(R1, .
.
,n , )  a.d = suchthat 91 = Ui with = Ni and 91 = with= N, ?From the linguistic point of view, tight relations playa key role because they are defined as a kind of topo-logical closure of nodes with respect o the topologyinduced by the various categories.
(However, thisanalogy is not perfect because the topological clo-sure is an idempotent operation while the domainclosure yields larger and larger sets, eventually beingthe whole tree.)
It is therefore reasonable to assumethat all kinds of linguistic CRs be defined using tightrelations as primitives.
Indeed, \[Koster, 1986\] arguesfor quite specific choices of fundamental relations,which will be discussed below.
It is worthwile to askhow much can be defined from tight relations.
Thisproves to yield quite unexpected answers.
Namely,it turns out that union can be eliminated in presenceof intersection and composition.
We prove this firstfor the most simple case.Lemma 10 Let gp, go be the associated functions oftight relations.
Thengp u go = (gP o go) n (go o gp) n (gp ?
go)Proof .
First of all, since gP,gO <- gP o go,go ogP,gP ?gO we have gp I Igo  < (gP?gq)  \ [q (go?gP) 1-\] (gP ?
go).
The converse inequation needs tobe established.
There are three cases for a nodez.
(i) gp(z) = go(x).
Then (gp U go)(z) =gpnq(X) = (gp ?
go)(x), because the next P-nodeabove z is identical to the next Q-node above zand so is identical to the next P N Q-node abovez.
(it) gp(x) < go(z).
Then with y = gp(x)we also have gQ(y) = go(z), by tightness.
Hence(gp U go)(x)  = (go o gp)(z) .
(iii) gp(x) >g0(z ) .Then as in (it) (gp LI gq)(x)  = (gp o go)(z).The next case is the union of two chains of tightrelations.
Let g = grn ogm_ l .
.
.ogz  and 0 =h,  o ha-  1 -.
?
o hi be two associated functions of suchchains.
Then define a spl ice of g and ~ to be anychain t = kt o k t -1 .
.
.o  kl such that ?
= m+ n andki = gj or ki = hj for some j and each gi and hjoccurs exactly once and the order of the gi as well asthe order of the hi in the splice is as in their originalchain.
So, the situation is comparable with shufflingtwo decks of cards into each other.
A weak  spl iceis obtained from a splice by replacing some numberof gi o hj and hj o gi by gi * hi, least tight relationcontaining both gi and hi.
In a weak splice, theshuffling is not perfect in the sense that some pairsof cards may be glued to each other.
I f  g = g2 o gland 0 = h2 o hi then the following are all splices of gand 0: g2?gl ?h2?hl ,  g2?h2?gl ?hl, g2?h2?hl ?gz ?The following are weak splices (in addition to thesplices, which are also weak splices): g2 091 ?
h2 0 hi,g2 ?
h2 0 gl ?
hi.
A non-splice is gl 0 h2 0 g2 0 hi, andg2 ?
gl 0 h2 0 hi is not a weak splice.Lemma 11 Let g, ~ be two chains of tight relations(or their associated functions).
Let wk(g, O) be theset of weak splices of g and b. Thenu b = R @Is wk@, b))Proof .
As before, it is not difficult to show thato < n( l. wk(g ,  because g, 0 _< s foreach weak splice.
So it is enough to show that theleft hand side is equal to one of the weak splices inany tree for any given node.
Consider therefore atree T and a node z E T. We define a weak splices such that s(z) = maz{g(z), b(z)}.
To this endwe define the following nodes, z0 = z, y0 = z,Z1 = gl(xo),hl(YO),...,xi+l = gi+l(Zi),Yi+l --hi+l(yl),....
The zi and the yi each form an in-creasing sequence.
We can also assume that bothsequences are strictly increasing because otherwisethere would be an i such that zi = r or Yi = r. Then(@ U D)(z) = r and so for any weak splice z(z) = ras well.
So, all the xi can be assumed distinct and243all the yi as well.
Now we define zi as follows.zo = x, Zl = min{xz , .
.
.
, zm,yt , .
.
.
, y ,} , .
.
.
, z i+t  =min({zz , .
.
.
,  zm, yz , .
.
.
,  Y,~} - {Zl , .
.
.
,  zl}).
Thus,the sequence of the zi is obtained by fusing the twosequences along the order given by the upper seg-ment T z.
Finally, the weak splice can be defined.We begin with st.
I f z t  = yl, $1 = g l?h l ,  i f z t  < Yz,sz = 91 and if zz > yl then sz = hi.
Generally, forzi+z there are three cases.
First, zi+z = zj = Yk forsome j, k. Then si+t = gj ?
hk.
Else zi+z = zj forsome j,  but Zi+l ?
y~ for all k. Then si+t = gj.
Orelse zi+t = yk for some k but zi+z ?
zj for all j;then si+t = hk.
It is straightforward to show thatz as just defined is a weak splice, that zi+z = si(zi)and hence that z(z) = maz{0(z), t)(z)}.
?The tight relations generate a subdistributoidSot(T) in :Di~(T) members of which we call tightgenerab le .Theorem 12 Each light generable command rela-tion is an intersection of chains of light relations.3 In t roduc ing  Boo lean  Labe ls3.1 Boo lean  GrAmmarsWe are now providing means to define CRs uniformlyover trees.
The trees are assumed to be labelled.For mathematical convenience the labels are drawnfrom a boolean algebra ?
= (L, 0, 1, - ,  n, U).
A la-be l l ing  is a function ?
: T ~ L. ?
is called ful lif ~(z) is an atom of ?
or 0 for every z.
If either~(z) = a = 0or  0 < ?
(x) < a we say that z i so fca tegory  a. Labelled trees are generated by booleangrammars.
Since syntax is abstracting away fromactual words to word classes named each by its ownsyntactical label we may forget to discriminate be-tween the terminal labels with impunity.
This allowsto give all of them the unique value 0, which is nowthe only terminal, the non-terminals being all ele-ments of L - {0}.
A boo lean  grammar  is definedas a triple 6 = (~, ~, R) where R is a finite subsetof (L - {0}) x L + and ~ ?
L - {0}.
G generatesT = (T,?)
- in symbols G >> T - ,  if (r) r is ofcategory ~, (t) x is of category 0 iff x is a leaf and(nt) if x immediately dominates Y l , .
.
.
,  Y- then withan appropriate order of the indices there is a rulea --* b t , .
.
.
,  b, in R such that x is of category a andYl is of category bl for all i. Boolean grammars are amild step away from context free grammars.
Namely,if a --* bz .
.
.
bn is a boolean rule, we may consider itas an abbreviation of the set of rules a* --* b~ .
.
.
b~where a* is an atom of ?
below a and b~ is an atomof ?
below bi for each i.
Likewise, the start symbolabbreviates a set of start symbols ~*, which by fa-miliar tricks can be replaced by a single one denotedby R, which is added artificially.
In this way we cantranslate G into a cfg O* over the set of atoms of ?plus 0 and the new start symbol R, which generatesthe same fully labelled trees - ignoring the deviantstart symbol.
It is known that there is an effectiveprocedure to eliminate from a cfg labels that neveroccur in a finite tree generated by the grammar (seee.
g. \[Harrison, 1978\]).
This procedure can easily beadapted to boolean grammars.
A boolean grammarwithout such superfluous ymbols is called normal .3.2 Domain  SpecificationEach boolean label a defines the relation of a-command on a fully labelled tree via the set ofnodes of category a.
This is the classical scenario;the label S defines S-command, the label NPU CP de-fines Lasnik's Kommand.
And so forth.
We denotethe particular relation induced on (T,?)
by 6T(a).~,From this basic set of tight CRs we allow to definemore complex CRs using the operations.
To do thiswe first define a constructor language that containsa constant a for each a E L and the binary sym-bols A, V and o.
(Although we also use e, we willtreat it as an abbreviation; also, this operation is de-fined only for tight relations.)
Since we assume theequations of distributoids, the symbols a generate adistributoid with A, V, o, namely the so-called f reed i s t r ibuto id .
The map ~T can be extended to ahomomorphism from this distributoid into :Diz(T).Simply putT(VVe) = 6T( )O6T(e)o e) = o  T(e)By definition, the image of ~ under ~T is tight gen-erable.
Hence ~v maps all nearness terms into tightgenerable relations.
With N P U C P being 1-node sub-jaceny (for English) we find that (NPUCP)o(NPUCP)is 2-node subjacency.
Using a more complex defini-tion it is possible to define 0- and 1-subjacency inthe barriers system on the condition that there areno double segments of a category.
If  we considerthe power of subsystems of this language, e. g. rela-tions definable using only A etc.
the following pictureemerges.
{o,^}/{o} {v,^}{^}This follows mainly from Theorem 12 because themap ~ is by definition into the distributoid ",for(T)of tight generated CRs.
Moreover, A alone does notcreate new CRs, because of Prop.
5.
Each of theinclusions is proper as is not hard to see.
So V doesnot add definitional strength in presence of o and A;244although things may be more perspicuously phrasedusing V it is in principle eliminable.
By requiringCRs to be intersections of chains we would thereforenot express a real restriction at all.3.3 The  Equat iona l  TheoryGiven a boolean grammar G, a tree T and two do-mains D, e constructed from the labels of G we writeT ~ ~ = e if 6T(e) = 6T(e).
The setEq(O) - {B = I(VT << O)(T F= = ,)}is called the equat iona l  theory  of (3.
To deter-mine the equational theory of a grammar we pro-ceed through a series of reductions.
(3 admits thesame finite trees as does is normal reduct G n. So,we might as well assume from start that (3 is nor-mal.
Second, domains are insensitive to the branch-ing nature of rules.
We can replace with impunityany rule p = a --, b l .
.
.b ,  by the set of rulespU = {a --* bili <_ n}.
We can do this for all rules ofthe grammar.
The grammar G ~ = (I3, 2, R ~) whereR" = {p"\[p E R} is called the unary  reduct  o fG.
It  has the same equational theory as G since thetrees it generates are exactly the branches of treegenerated by G. Next we reduce the unary grammarto an ordinary cfg G ~* in the way described above,with an artificially added start symbol R. This gram-mar is completely isomorphic to a transition etworkalias directed graph with single source R and singlesink 0.
This network is realized over the set of atomsof ?
plus R and 0.
There are only finitely manysuch networks over given E - to be exact, at most2 ("+!
)~ (!)
where n is the number of atoms of 2.Finally, it does not harm if we add some transitionsfrom R and transitions to 0.
First, if we do so, theequational theory must be included in the theory ofG since we allow more structures to be generated.But it cannot be really smaller; we are anyway inter-ested in all substructures T z for nodes z, so addingtransitions to 0 is of no effect.
Moreover, addingtransitions from R can only give more equations be-cause the generated trees of this new transition sys-tem are branches where some lower and some uppercone is cut off.
Thus, rather than taking the gram-mar G u* we can take a grammar with some morerules, namely all transitions R --+ A, A --* 0 for anatom A plus R ---, 0.
In all, the role of source and sinkare completely emptied, and we might as well forgetabout them.
What we keep to distinguish grammarsis the directed graph on the atoms of ~ induced bythe unary reduct of G. Let us denote this graphby Gpb(G).
We have seen that if two grammarsG, H have the same graph, their equational theoryis the same.
The converse also holds.
To see this,take an atom A and let As ?
be the disjunction ofall atoms B such that B --, A is a transition in thegraph (or, equivalently, in the unary reduct) of G.Then A o A e = A o J_ E Eq(G).
However, if C ~ A ethen A o C = A o _1_ ~ Eq(G).
If O and H have dif-ferent graphs, then there must be an A such thatA~ ?
A~, that is, either A~ ~ A~ or A~ ~ A 8.Consequently, either A o A O - A o .L ~ Eq(H) orAoA~ -- Ao.L ?
EKG ).Theorem 13 EKe,) = EKH) i ff =?pb(H).
Hence it is decidable for any pair G, H o\].boolean grammars over the same labels whether ornot Eq(G) = Eq(H).
mThe question is now how we can decide whether agiven domain equation holds in a grammar.
Weknow by the reductions that we can assume thisgrammar to be unary.
Now take an equation B -e. Suppose this equation is not in the theory andwe have a countermodel.
This countermodel is anon-branching labelled tree T a node z such that6T(~)): ~ 6T(?)~.
Let Sf(~) denote the set of sub-formulas of ~ and Sf(e) the set of subformulas of ?.Put S = {f~(x)l 0 E Sf(~) U Sf(e)}.
S is certainlyfinite and its cardinality is bounded by the sum ofthe cardinalities of Sf(~) and Sf(?).
Now let y, z betwo points from S such that y < z and for all usuch that y< u<z  u~S.
Let ul andu2 be twopoints such that y < ul < us < z and such thatul and us have the same label.
We construct a newlabelled tree U by dropping all nodes from ul up un-til the node immediately below us.
The followingholds of the new model.
(i) It is a tree generated byG and (ii) 6u(0)x ~ 6u(e)x. Namely, if w -< ul then?
(ul) ---, ?
(w) is a transition of G, hence ?
(u2) --, t(w)is a transition of G as well because l (u l )  - ?
(u2); andso (i) is proved.
For (ii) it is enough to prove thatfor all ~ E Sf(D) 0 Sf(?)
the value f~(z) in the newmodel is the same as the value fs(z)  in the old model.
(Identification is possible, because these points havenot been dropped.)
This is done by reduction onthe structure of g. Suppose then that 0 = IJ Aand f~(z) -- fb(z) as well as f~(z) = fe(z); thenf~(x) = min{f~(z), f~(z)} = min{fb(z),fe(z)} =fg(z).
And similarly for g = b V ~.
By the normalform theorem we can assume 0 to be a disjunction ofconjunctions of chains, so by the previous reductionsit remains to treat the case where g is a chain.
Hencelet i~ = dot .
We assume f ; (z)  -- re(x)----: y. Letz := f~(z).
Then if y < r, y < z and else y = z. Byconstruction, z is the first node above y to be of cat-egory a and z E S, by which z is not dropped.
In thereduced model, z is again the first node of categorya above y, and so f~(z) -- f~(y) = z, which had tobe shown.Assume now that we have a tree of minimal sizegenerated by G in which/~ = e does not hold.
Theni fy,  z E S such that y < z but for no u E S y < u <z, then in between y and z all nodes have differentlabels.
Thus, in between y and z sit no more pointsthan there are atoms in ?.
Let this number be n;then our model has size < n ?
S. Now if we want todecide whether or not ~ = ?
is in Eq(G), all we haveto do is to first generate all possible branches of trees245of length at most n x (~Sf(O)+ ~Sf(c))+ 2 and checkthe equation on them.
If it holds everywhere, thenindeed 0 = e is valid in all trees because otherwisewe would have found a countermodel of at most thissize.Theorem 14 It is decidable whether or not ~ - ?
EEq(O).
?These theorems tell us that there is nothing dan-gerous in using domains in grammar as concerns thequestion whether the predictions made by this theorycan effectively be computed; that is, as!ong as onesticks to the given format of domain constructions,it is decidable whether or not a given grammaticaltheory makes a certain prediction about domains.4 Implementations4.1 P rob lems of  Imp lementat ionsThe aim set by our theory is to reduce all possi-ble nearness conditions of grammar to some restric-tions involving command relations.
Thus we treatnot only binding theory or case theory but also re-strictions on movement.
Even though \[Barker andPullum, 1990\] did not think of movement and subja-cency as providing cases for command relations, thefact that nearness conditions are involved clearly in-dicates that the theory should have something to sayabout them.
However, there are various obstacles toa direct implementation.The theory of command relations is not directlycompatible with standard nearness relations in G8.A command relation as defined here depends in itssize only of the isomorphism type of the linear struc-ture above the node z.
So, typical definitions uchas those involving the notions of being governed, be-ing bound, having an accessible subject fail to be ofthe kind proposed here because they involve a nodethat stands in relation of c-command rather thandomination.
Nevertheless, if 6B would be spelt outfully into a boolean grammar, far more labels haveto be used than appear usually on trees displayedin GB books.
The reason is that while context-freegrammars by definition allow no context o rule thestructure of a local tree, in GB the whole tree is im-plicitly treated as a context.
But if it is true thatthe context for a node reduces to nodes that are c-commanding, it is enough to add for certain prim-itive labels X another label QX which translates asone of my daughters is X.
Here, QX is not necessar-ily understood to be a new label but a specific labelthat guarantees one of the daughters to be of cate-gory X.
However, 'modals' such as Q are somewhatwhimsical creatures.
Sometimes, QX is an alreadyexisting category, for example Q|P can (with the ex-ception of exceptional case marking constructions)he equated with C'.
On other occasions, however, weneed to incorporate them into our grammar; promi-nent modals are SLASH : X, which has the meaningsomewhere below me is a gap of category X and AGR: X which says this sentence has a subject of cate-gory X.
If a context-free rendering of phrase struc-ture is done properly (as for example in \[Gazdar etaL, 1985\]) a single entry such as V must be split intoa vast number of different symbols so we can rea-sonably assume that our grammar is rich enough tohave all the QX for the X we need; otherwise theymust be added artificially.
In that case many of thestandard nearness relations can be directly encodedusing command relations.A second problem concerns the role of adjunctionin the definition of subjacency.
If the domain ofmovement for a node (that is, the domain withinwhich the antecedent has to be found) is tight, thenno iteration of movement leads to escaping the orig-inal domain.
So, the domain for movement mustbe large.
But it cannot be too large either be-cause we loose the necessity of free escape hatches(spec of comp, for example).
The typical defini-tions of subjacency lead to domains that are justabout right in size.
However, the dilemma must besolved that after moving to spec of comp, an elementcan move higher than it could from its original po-sition.
Different solutions have been offered.
Themost simple is standard 2-node subjacency which isKOMMAND o KOMMAND.
This domain indeed allowsthis type of cyclical movement; cyclic movement fromspec of comp to spec of comp is possible - but onlyto the next spec of comp.
However, due to it's short-comings, this notion has been criticised; moreover, ithas been felt that 1-node subjacacency should be su-perior, largely because of the slogan 'grammar doesnot count'.
Yet, tight domains don't do the jobs andso tricks have been invented.
\[Chomsky, 1986\] for-mulated rather small domains but included a mecha-nism to escape them by creating 'grey zones' in whichelements are neither properly dominated by a nodenor in fact properly non-dominated.
This idea hascaught on (for example in \[Sternefeld, 1991\]) but hasto be treated cautiously as even the simplest notionssuch as category, node etc.
receive new interpreta-tions because nodes are not necessarily identical withoccurrences of categories as before.
A reduction tostandard notions hould certainly be possible and de-sired - without necessarily banning adjunction.4.2 The  Koster  Mat r ixAs \[Koster, 1986\] observed, grammatical relationsare typically relations between a dependent elementand an antecedent or:I IR\[Koster, 1986\] notes four conditions on such configu-rations.a.
obligatoriness246b.
uniqueness of the antecedentc.
c-command of the antecedentd.
localityIf these conditions are met then this relation has theeffectshare propertyThis has to be understood as follows.
(a.)
and (b.
)express nothing but that 6 needs one and only oneantecedent.
This antecedent, a must c-command 6.Finally, (d.) states that a must be found in some lo-cal domain of 6.
Of course, this domain is languagespecific as well as specific to the syntactic onstruc-tion, i. e. the category of 6 and c~.
Likewise, theproperty to be shared depends on the category of aand 6.The locality restriction expresses that a is foundwithin the R-domain of 6.
This relation R is in theunmarked case defined as follows.Def in i t ion  15 a is l oca l ly  access ib le  I to 6 ifc~ <_ 1~, where fl is the least maximal projection con-taining 6 and a governor of 6.\[Koster, 1986\] assumes that greater domains areformed by licensed extensions.
These extensions aremarked constructions; while all languages agree onthe local accessibility 1 as the minimal domain withinwhich antecedents must be found, larger domainsmay also exist but their size is language and con-struction specific.
Nevertheless, the variation is lim-ited.
There are only three basic types, namely locallyaccessible i for i = 1, 2, 3.Def in i t ion 16 a is loca l ly  access ib le  2 to 6 ifot <_ ~, where 1~ is the least maximal projection con-taining 6, a governor for 6 and some opacity elementw.
a is loca l ly  access ib le  z to & if there is a se-quence ~i, 1 < n, such that \[31 is locally accessible 2from & and ~i+1 is locally accessible 2 from ~i.The opacity elements are drawn from a rather lim-ited list.
Such elements are tense, mood etc.
Awell-known example are Icelandic reflexives whosedomain is the smallest indicative sentence.4.3 The  Command Re lat ions  o f  Koster ' sMat r ixThe local accessibility relations certainly are com-mand relations in our sense.
The real problem iswhether they are definable using primitive labels ofthe grammar.
In particular the recursiveness of thethird accessibility makes it unlikely that we can finda definition in terms of A, V, o.
Yet, if it were re-ally an arbitrary iteration of the second accessibil-ity relation it would be completely trivial, becauseany iteration of a command relation over a tree isthe total relation over the tree.
Hence, there mustbe something non-trivial about this domain; indeed,the iteration is stopped if the outer/~ is ungoverned.This is the key to a non-iterative definition of thethird accessibility relation.Let us assume for simplicity that there is a singletype of governors denoted by GOV and that thereis a single type of opacity element denoted by OP.Y,The first hurdle is the clarification of government.Normally, government requires a governing element,i.e.
an element of category GOV that is close in somesense.
How close, is not clarified in \[Koster, 1986\].Clearly, by penalty of providing circular definitions,closeness cannot be accessibility1; really, it must bean even smaller domain.
Let us assume for simplicitythat it is sisterhood.
If then we introduce the modaltX to denote one of my sisters is of category X, beinggoverned is equal to being of category tGOV.
Like-wise we will assume that the opacity element mustbe in c-command relation to 6.
We are now readyto define the three accessibility relations, which wedenote by LA 1, LA 2 and LA 3.LA 1 = ?GOV* BAR:2AQGOV o BAR:2LA z = ?GOV* ?OPY?
BAR:2A?GOV ?
QOPY o BAR:2A?GOV o QOPY ?
BAR:2A?GOV o QOPY o BAR:2LA s = ?GOV ?
QOPY ?
BAR:2 ?-IIGOVA(~GOV ?
(~OPY o BAR:2 ?
-tGOVA?GOV o ~OPY ?
BAR:2 ?
-tGOVA?GOV o ?OPY o BAR:2 ?
-tlGOV(Observe that ?
binds stronger than o.)
For a proofconsider a point z of a labelled tree T. Let g denotethe smallest node dominating both x and its governorand let m be the smallest maximal projection of 9.Then x < g _< m. So two cases arise, namely g = mand g < rn.
In each cases LA 1 picks the right node.Likewise, if o denotes the smallest element containingx and a opacity element hat c-commands z, thenx < o.
Three cases are conceivable, o < g, o = g ando > g. However, if government can take place onlyunder sisterhood, o < g cannot occur.
So x < g _<o < m. For each of the four cases LA 2 picks the rightnode.
Finally, for LA s there is an extra condition onm that it be ungoverned.Notice that our translation is faithful to Koster'sdefinitions only if the domains defined in \[Koster,1986\] are monotone.
This is by no means triv-ial.
Namely, it is conceivable that a node has anungoverned element y locally accessible 2, while thehighest locally accessible 2 node, z, is governed.
Inthat case (ignoring the opacity element for a mo-ment) the domain of local accessibility 3 of y is z whilethe domain of z is strictly larger.
We find no answerto this puzzle in the book because the domains aredefined only for governed elements.
But it seems cer-tain that the monotone definition given here is theintended one.It should be stressed that GOV and OPY are notspecific labels but variables.
Their value may changefrom situation to situation.
Consequently, the localaccessibility relations are parametrized with respectto the choice of particular governors and particular247opacity elements.
As an example, recall the Icelandiccase again, where certain anaphors whose domain ofaccessibility 2 (typically the clause) can be extendedin case the opacity element is subjunctive.
Followingour reduction, the domain of local accessibility 3 isdefined by the first maximal projection that is notsubjunctive, hence indicative.
We take a primitivelabel IND to stand for is indicative.
So, for Icelandicwe have the following special domainLA 3 = (~GOV, ~)IND, BAR:2 ,-tGOVAQGOV ?
QIND o BAR:2 ?-~GOVA~)GOV o QIND ?
BAR:2 ?
-I:IGOVAQGOV o QIND o BAR:2 ?-bGOVWe notice in passing that recent results have putthis analysis into doubt (see \[Koster and Reuland,1991\]) but this is a problem of Koster's original def-initions, not of this translation.
What is a problem,however, is the standard opacity factor of an acces-sible subject.
While subject (or even SUBJEC~ canbe easily handled with a boolean label, the acces-sibility condition presents real difficulties.
First ofall it involves indexing and indexes potentially de-stroy the finiteness of the labelling system; secondly,it is not clear how the accessibility condition (namely,the reqirement that the i/i-Filter is respected afterconindexation) can be handled at all in this calculus.This issue is too complex to be tackled here, so weleave it for another occasion.4.4 Trans la t ing  Koster ' s  Mat r ix  into  RulesIn a final step we show how the nearness conditionsof the Koster Matrix can be rewritten into rules of acontext-free grammar.
To be more precise, we showhow they can be implemented into any given booleancfg.
The booleanness, of course, is not essential butis here for convenience.
We noticed earlier that thedomains in cB really are for the purpose of introduc-ing some limited forms of context-sensitivity.
If twonodes relate via some dependency relation R thenKoster assumes that a certain property is shared.But context-free grammars do in principle not allowsuch a sharing except between mother and daughtersand between sister nodes.
Nevertheless, as we do notrequire all properties to be shared but only some itis possible to enrich the grammar in such a way thatnodes receive relevant information about parts of thestructure that normally cannot be accessed.
We willshow how.First, we will assume that share property is to beunderstood as a dependency in the labellings be-tween two elements.
We simplify this by assum-ing that there are special features PRPi, i < n, ofunspecified nature whose instantiation at the twonodes, 6 and a, is somehow correlated.
Since thedependent element is structurally lower than the an-tecedent, and since generation in cfg's is top to bot-tom, we assume that it is the dependent element thathas to set the PRPI according to the way they areset at the antecedent.
The best way to implementthis is by a function f that for every assignment prpof the primitive labels at the antecedents gives thelabelling f(prp) which the dependent element mustsatisfy.
In order to be able to achieve this correla-tion in a context-free grammar, the dependent ele-ment needs to know in which way the atoms PRPihave been set at a.
Thus the problem reduces to atransfer of information from ct to 6.
If we generateonly fully labelled trees the problem is precisely totransfer n bits of information from tr to 6.
The con-tent of this information is of course irrelevant for theformalization.To begin with, we need to be able to recognizeantecedent and dependent element by their category.We do this here by taking two labels ANT and DEPwith obvious meaning.
Furthermore, one of our tasksis to ensure that the labels X and IX are correctlydistributed.
Notice, by the way, that it is only forspecial choices of X that we need these compositeelements, so there is nothing recursive or infinite inthis procedure.
For the sake of simplicity we assumethe grammar to be in Chomsky Normal Form; thatis, we only have rules ot type X ---* YZ, X --~ Y, X ---* 0for X, Y and Z atoms or = R (see \[Harrison, 1978\]).For any rule p = A ---, BC and any X we distributethe new labels QX and tX as follows.
If B _< X butC ~ X then we replace p byAnoxB n-~n ~xHowever, if C < X but B :~ X then we use this ruleAnexB n '~n 4xIt is clear what we do if both B, C < X.
If neitheris the case, however, we have this ruleAn-OXBLikewise the unary rules are expanded.
Here, wehave either B _< X (left) or B ~ X (right).AA?X AA-?Xol x248After having inserted enough ~X and ~X we canproceed to the domains of accessibility.
The generalproblem is as said above, the transfer of informationfrom a to &.
The problem is attacked by introduc-ing more modal elements.
Namely, for certain g andcertain labels X we introduce the new label (g)X. Itsinterpretation is an element of label X is in my g-domain and neither do I dominate it nor am I dom-inated by it.
If we succeed in distributing these newlabels according to their intended interpretation wecan code the Koster Matrix into the grammar.
Weshow the encoding for (F)V. It is then more or lessevident how (9)X is encoded for a chain g because(b o F)X = (b)(F)X, just as in modal logic.
Now for(F)Y there are two cases.
(i) The mother node is ofcategory (F)Yn-F. Then the information (F)Y mustbe passed on to all daughters.
(ii) The mother isof category -(F)Y U F. Then a daughter is (F)Y ifand only if it has a sister of category Y.
Thus at alldaughters we simply instantiate (F)Y ~ ~Y.It should be quite clear that by a suitable choiceof (g)X to be added a dependent element 6 will haveaccess to the information that it has an antecedent inits domain of local accessibility i.
If it needs to knowwhat category this antecedent has, this informationhas to be supplied in tandem with the mere prop-erty that needs to be shared.
One snag remains;namely, it may happen that there are more thanone antecedent of required type.
In that case weneed to manipulate the rules of the grammar as fol-lows.
As long as we have an element of categoryANT we suppress any other antecedents of categoryANT within the same domain.
This might be notentirely straightforward, but to keep matters implehere we assume that the grammar takes care of that.We show now how the translation is completed.
Foraccessibility z we add the following boolean axiom tothe grammar (that is, we 'kill' all rules that do notcomply with this axiom):(BAR:2)(ANT f'1 prp) 13 I;IGOV lq DEP.
--* .f(prp)By choice of the interpretation, this axiom declaresthat a node which is governed and dependent and hasan anetecdent within the next maximal projectionmust be of category f(prp) if its (unique) antecedentis of category prp.
The uniqueness i assumed hereto be guaranteed by the grammar into which we en-code.
Furthermore, note that the assumption thatgovernment takes place under sisterhood results ina significant simplification.
Limitations of space for-bid us to treat the more general case, however.
Foraccessibility 2 this axiom is added insteadCOPY o BAR:2 A OPY ?
BAR:2)(ANT n prp)n~GOV n DEP.
--~ .f(prp)Finally, for accessibility 3, we have to replace BAR:2by BAR:217-hGOV.More details can be found in \[Kracht, 1993\].
Theupshot of this is the following.
Suppose that a gram-mar of some language consists of a basic generativecomponent in form of a cfg 13 and a number of KosterMatrices as additional constraints on the structures.If the number of matrices is finite, then finitely manyadditional labels suffice to create a cfg G + from theoriginal grammar that guarantess that it's outputtrees satisfy the local conditions of 13 as well as thenearness conditions imposed by the Koster Matri-ces.
Upper bounds on the number of labels of G +(depending both on (3 and the additional matrices)can be computed as well.AcknowledgementsI wish to thank A. and J. for their moral support andF.
Wolter for helpful discussions.References\[Barker and Pullum, 1990\] Chris Barker and Geof-frey Pullum.
A theory of command relations.
Lin-guistics and Philosophy, 13:1-34, 1990.\[Chomsky, 1986\] Noam Chomsky.
Barriers.
MITPress, Cambrigde (Mass.
), 1986.\[Gazdar et al, 1985\] Gerald Gazdar, Ewan Klein,Geoffrey Pullum, and Ivan Sag.
GeneralizedPhrase Structure Grammar.
Blackwell, Oxford,1985.\[Harrison, 1978\] Michael A. Harrison.
Introductionto Formal Language Theory.
Addison-Wesley,Reading (Mass.
), 1978.\[Koster and Reuland, 1991\] Jan Koster and EricReuland, editors.
Long-Distance Anaphora.
Cam-bridge University Press, Cambridge, 1991.\[Koster, 1986\] Jan Koster.
Domains and Dynasties:the Radical Autonomy of Syntaz.
Foris, Dordrecht,1986.\[Kracht, 1992\] Marcus Kracht.
The theory of syn-tactic domains.
Technical report, Dept.
of Philos-ophy, Rijksuniversiteit Utrecht, 1992.
Logic GroupPreprint Series No.
75.\[Kracht, 1993\] Marcus Kracht.
Nearness and syntac-tic influence spheres.
Manuscript, 1993.\[Reinhart, 1981\] Tanya Reinhart.
Definite np-anaphora nd c-command omains.
Linguistic In-quiry, 12:605-635, 1981.\[Stabler, 1989\] Edward Jr. Stabler.
A logical ap-proach to syntax: Foundation, specification andimplementation of theories of government andbinding.
Manuscript, 1989.\[Sternefeld, 1991\] Wolfgang Sternefeld.
Syntaldis-che Grenzen.
Chomsky's Barrierentheorie ndihre Weiterentwicklungen.
Westdeutscher Verlag,Opladen, 1991.249
