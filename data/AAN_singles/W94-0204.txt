EDEFAULT F IN ITE  STATE MACHINESAND F IN ITE  STATE PHONOLOGYGerald PennComputational Linguistics ProgramCarnegie Mellon UniversityPittsburgh, PA 15213Internet: penn@lcl.cmu.eduRichmond ThomasonIntelligent Systems ProgramUniversity of PittsburghPittsburgh, PA 15260Internet: thomason~isp.pitt.eduAbstractWe propose DFSM's as an extension of finite statemachines, explore some of their properties, and in-dicate how they can be used to formalize naturallyoccurring linguistic systems.
We feel that this im-plementation of two-level rules may be more lin-guistically natural and easier to work with eom-putationally.
We provide complexity results thatshed light on the computational situation.INTRODUCTIONTwo-level phonology combines the computationaladvantages of finite state technology with a for-malism that permits phenomena to be describedwith familiar-looking rules.
The problem withsuch a scheme is that, in practice, the finite statemachines (FSM's) can grow too large to be man-ageable; one wants to describe them and to runthem without having to deal with them directly.The KIMMO approachlseeks to achieve this by(I) decomposing the computational process intoa battery of parallel finite state machines and(2) compiling rules (which notationally resemblefamiliar phonological rules, but which axe inter-preted declaxatively) into these parallel finite stateimplementations.
But the KIMMO formalism un-fortunately gains no tractability in the processof compilation.
Moreover, the compiler is com-plex enough to create software engineering prob-lems, and this has led to practical difficulties,which in turn have made the KIMMO technol-ogy less generally available than one might wish.IIere, we describe a different finite-state founda-tion for two-level rules, involving generalizationsof FSM's which we call Default Finite State Ma-chines (DFSM's).
Whether or not this approachremains intractable after compilation is an openquestion; but even without compilation, we be-lieve that it has some conceptual advantages aswell.1See the discussion and references in (Sprout,1992).DFSM's extend FSM's (specifically, finite-state transducers) so that transitions can becontext-sensitive, and enforce a preference for themaximally specific transitions.
The first changeallows phonological rules to appear as labels oftransition arcs in transducers; the second changeincorporates the elsewhere condition into the com-putational model.
2 DFSM's can be implementeddirectly, although there may be a method to com-pile them into a more efficient machine.
We be-lieve that either approach will be feasible for re-alistic linguistic applications (though, of course,not in the theoretically worst case).
In paxticu-lax, the direct implementation of DFSM's is verystraightforward; no rule compiler is needed, sincerules are labels on the arcs of the machines them-selves.
This implementation may not provide anoptimal allocation of space and time usage at runtime, but we believe that it will be adequate fortesting and research purposes.This presentation of DFSM's is confined todefining the basic ideas, presenting some exam-pies of linguistic description, and providing a par-tial complexity analysis.
In later work, we hopeto explore descriptive and implementational issuesfurther.NOTATIONAL PRELIMINARIESWe assume an alphabet L, with a reserved symbol0 ~ ?
for insertions and deletions.
A replacementover ?
is a pair of the form I = (1,1') where (1)!
E ?
and (2) I I E ?
or i I = 0; Replacements?is the set of replacements over ?.
US-strings?
isthe set of strings over the set ?2 U \[?
x {0}\] ofreplacements.2The elsewhere condition is built into an implemen-tation (due to Karttnnen) of the TWOL rule compiler;see (Dalrymple t al., 1993), pp.
28-32.
But on this'approach, default reasoning and the elsewhere condi-tion are not employed at a level of computation that istheoretically modeled; this reasoning is simply a con-venient feature of the code that translates rules intofinite state automata.33We use roman letters to denote themselves:for instance, T denotes the letter I. Boldface let-ters denote constant replacements: for instance, Iis the pair (l,l).
Moreover, ?
is the empty stringover L~, and ~ is the empty string over the ?
re-placements.
When the name of a subset of/2 (e.g.C) is written in boldface, (e.g.
C), the set of iden-tity pairings is intended (e.g., C = {l:l/l E C}).We use ordinary italics as variables over let-~rs, and boldface italics as variables over replace-ments and strings of replacements.
Ordinarily, wewill use I for replacements and z, 7t for strings ofreplacements.
Finally, we use ' I:I" for the pair(l,l').Where z E US-strings?, U-String(a,.)
is theunderlying projection of z, and S-String(z) is itssurface projection.
That is, if z = (z,z ') ,  thenU-String(z) = z and S-String(z) = x'.RULE NOTATION ANDEXAMPLESThe rules with which we are concerned are likethe rewrite rules of generative phonology; they aregeneral, context-conditioned replacements.
Thatis, a rule allows a replacement if (1) the replace-ment belongs to a certain type, and (2) the sur-rounding context meets certain constraints.If we represent the contextual constraints ex-tensionally, as sets of strings, a rule will consist ofthree things: a replacement type, and two sets ofUS-Strings.
Thus, we can think of a rule as a triple(X, Y, F), where X and Y are sets of US-strings.Imagine that we are given a replacement instance lin a context (z, y), where z and y are US-strings.This contextualized replacement (~, l, y) satisfiesthe rule i f zEX ,  yE  Y, and IEF .For linguistic and computational purposes,the sets that figure in rules must somehow befinitely represented.
The K IMMO tradition usesregular sets, which can of course be' representedby regular expressions, for this purpose.
We havenot been able to convince ourselves that regularsets are needed in phonological applications, a In-aThe issue here is whether there are any linguis-tically plausible or well-motivated applications of theKleene star in stating phonological rules.
For instance,take the English rule that replaces "e by 0 after amorpheme boundary preceded by one or more con-sonants preceded by a vowel."
You could representthe context in question with the regular expressionVC*C; but you could equally well use VC I VCC \]VCCC \] VCCCC.The only way to distinguish the tworule formulations is by considering strings that vio-late the phonotactic constraints of English; but as faras we can see, there are no intuitions about the re-sults of applying English rules to underlying stringslike typppppe+ed.
We do not question the usefulnessstead, we make the stronger assumption that con-texts can be encoded by finite sets of strings.
Astring satisfies such a context when its left (orits right) matches one of the strings in this set.
(Note that satisfaction is not the same as mem-bership; infinitely many strings can satisfy a finiteset of strings.)
Assuming a finite alphabet, all re-placement types will be finite sets.
With theseassumptions, a rule can be finitely encoded as apair {(X, Y~, F), where the sets X and Y are fi-nite, and F is s replacement type.Rule encodings, rule applicability and satis-faction are illustrated by the rule examples givenbelow.
The ideas are further formalized in thenext section.Language:Let ?
= {a ,b , .
.
.
, z ,+ ,#, ' ,  i}Declare the following subsets of ?
:C = {b ,c ,d , f ,g ,h , j , k , l ,m,n ,p ,q , r , s , t ,v ,w ,x,y,z}Csib = {s, x, z}Example  rules:Example  1Rule encoding: {d), {(+,0)})Rule notation: + --~ 0 \[Rule description: Delete +.Example 2Rule encoding: ({C, {(+, 0)}), {(y, i)})Rule notation: y --~ i / C_  + :0Rule description: Replace y by i before a mor-pheme boundary and after a constant US-consonant, i.e.
after (l,i), where !
E C.Example 3Rule encoding: (({sh}, {i ^ (#, O) / I E Csib}),{(+,e)})Rule notation: + --~ e / sh_Cs ib  #:0Rule description: Keplace + with e after sh andbefore a suffix in Csib.Example  ru le  app l i ca t ions :1.
The rule encoded in Example 1 is satisfied by(+,0) in the context (cat ,  s) because (1) forsome , cat = z^e, (2) for some y, s = c ^y,and (3) (+,0) e {{+,0)}.of regular expressions in many computational pplica-tions, but are not convinced that they are needed ina linguistic setting.
We would be interested to see awell motivated case in which the Kleene star is linguis-tically indispensable in formulating a two-level phono-logical rule.
Such a case would create problems for theapproach that we adopt here.342.
The rule encoded in Example 2 is not satisfiedby (y,i) in the context (spot + :t ,  +:0 hess)because there is no s such that spot + :t = ~e ~l,where I E C.3.
The rule encoded in Example 3 is not satis-fied by (+, 0) in the context (ash, s #:0).
Infact, the context is satisfied: (1) sh = m-shfor some :e and (2) s #:0 E Csib ~y for someIt.
(3.1) Moreover, the underlying symbol ofthe replacement (namely, +) matches the ar-gument of the ~ule's replacement function.
Un-der these circumstances, we will say that therule is applicable.
But the rule is not satis-fied, because (3.2) the surface symbol of the re-placement (namely, 0) does not match the valueof the rule's replacement function (namely, e):thus, (+,0) ~\[ {(+,e)}.INDEXED STRINGS AND RULESWe now restate the above ideas in the form offormal definitions.Definit ion 1.
Context ype.A context ype is a pair C = (X, Y), where Xand Y are sets of US-Strings.Definit ion 2.
Indexed US-strings.An indexed US-String over ?
is a triple(as, l,y), where a,y E US.stringsr and I EReplacementsr.An indexed US-string is a presentation of anonempty US-string that divides the string intothree components: (1) a replacement occurring inthe string, (2) the material to the left of that re-placement, and (3) the material to the right of it.Where (as, I, y) is an indexed string, we call as theleft context of the string, I / the right context ofthe string, and I the designated replacement of thestring.A rule licenses certain sorts of replacementsin designated sorts of environments, or contexttypes.
For instance, we may be interested in theenvironment after a consonant and before a mor-pheme boundary.
Here, the phrase "after a con-sonant" amounts to saying that the string beforethe replacement must end in a consonant, and thephrase "before a morpheme boundary" says thatthe string after the replacement must begin in amorpheme bound'ary.
Thus, we can think of acontext ype as a pair of constraints, one on theUS-string to the left of the replacement, and theother on the US-string to its right.
If we identifysuch constraints with the set of strings that satisfythem, a context ype is then a pair of sets of US-strings; and an indexed string satisfies a contexttype in case its left and right context belong to thecorresponding types.35Definit ion 3.
Replacement types.A replacement type over ?
is a partial functionF from ?
U {0} to ?
U {0}.
(Thus, a replacementtype is a certain set of replacements.)
Dora(F)is the domain of F.Definit ion 4.
Rules.A rule is a pair 7~ = (C, F), where C is a contexttype and/ '  is a replacement type.Definit ion 5.
Rule applicability.A rule ((X, Y), F)  is applicable to an indexedstring (se, (i,l'), y) if and only if as E X, y ~ Y,and F(l) is defined, i.e., i E Dom(F).Definit ion 6.
Rule satisfaction.An indexed string (as, i, y) satisfies a rule (C, F)if and only if as E X, y E Y, and F (l) = l ?.The above definitions do not assume that thecontexts are finitely encodable.
But, as we said, weaxe assuming as a working hypotheses that phono-logical contexts are finitely encodable; this ideawas incorporated in the method of rule encodingthat we presented above.
We now make this ideaexplicit by defining the notion of a finitely encod-able rule.Definit ion 7.
LeftExp( X ), RightExp( X )LeftExp(X) = {z^, / ,  E X}Right~xp(X) = {?^z/  ?
~ X}Definit ion 8.
Finite encodabilityA subset X of US-strings j: is left-encoded by aset U in case X = LeftExp(U), and is right-encoded by 17 in case X = RightExp(V).
(It iseasy to get confused about the usage of "left"and "right" here; in left encoding, the left ofthe encoded string is arbitrary, and the rightmust match the encoding set.
We have chosenour terminology so that a left context ype willbe left-encoded and a right context ype will beright-encoded.
)A context ype C = (X, Y) is encoded by a pair(U, V) of sets in case U left-encodes X and Vright-encodes Y.A rule ~ = (C, F)  is finitely encoded by a ruleencoding structure ((U, V),g) in case (U,V)encodes C, g = F, and ff and V are finite.In the following material, we will not only con-fine our attention to finitely encodable rules, butwill refer to rules by their encodings; when thenotation ((X, Y), F~ appears below, it should beread as a rule encoding, not as a rule.
Thus, forinstance, the indexed string (cat, +:0, s I satisfiesthe rule (encoded by) (({~}, {~}), {(+, 0)}), eventhough cat ?
{e}.SPECIF IC ITY  OF  CONTEXTTYPES AND RULESWe have a good intuitive grasp of when one con-text type is more specific than another.
For in-stance, the context ype preceded by a back vowelis more specific than the type preceded by a vowel;the context type followed by an obstruent is nei-ther more nor less specific than the type followedby a voiced consonant; the context type precededby a vowel is neither more nor less specific thanthe type followed by a vowel.Since we have identified context types withpairs of sets of strings, we have a very natural wayof defining specificity relations uch as "more spe-cific than", "equivalent", and "more specific thanor equivalent": we simply use the subset relation.Def in i t ion 9.
C < C'.Let C = (X1, Y1) and C' = (X2, Y2} be contexttypes.
C < C' if and only if X~ C_ X~ and Yt C_Y~.Def in i t ion 10.
C _= C ~.C =_ C' if and only if C < C' and C' _< C.Def in i t ion 11.
C < C ~.C < C' if and only if C < C' and C I ~ C.It is not in general true that if LeflEzp(X) CLeflEzp(JO, then X C Y; for instance,LeftExp({aa, ba}) C_ ?eflExp({a}), but {aa, ba}{a}.
However, we can easily determine the speci-ficity relations of two contexts from their finiteencodings:Lemma 1.
LeflExp(X) C_ LeflEzp(Y) iff for allz E X there is a y E Y such that for some z, ffi =z Ay.
Similarly, RightExp(X) C RightExp(Y) ifffor all z E X there is a y E Y such that for someProof of the lemma is immediate from the def-initions.
It follows from the lemma that there is atractable algorithm for testing specificity relationson finitely encodable contexts:Lemma 2.
Let C be finitely encoded by {X1, X2)and C' be finitely encoded by {YI, Y2).
Thenthere is an algorithm for testing whether C < C ~that is no more complex than O(m ?
n x k), wherem = max(I Xxl, \[.X21), n = max(I Yll, I Y zl), and kis the length of the longest string in Y1 U Y2.Proof.
Test whether for each zl E X1 thereis a Yl E Yl that matches the end of zl.
Thenperform a similar test on X2 and Y~.DFSM'SA DFSM's transitions are labelled with finitely en-codable rules rather than with pairs of symbols.Moreover, nondeterminism is restricted so that incase of conflicting transitions, a maximally spe-cific transition must be selected.
The critical def-inition is that of minimal satisfaction of an arcby an indezed path, where an indexed path repre-sents a DFSM derivation, by recording the statetransitions and replacements hat are traversed inprocessing a US-String.Def in i t ion 12.
Arcs.An arc over a set S of states and alphabet ?
isa triple A = (s, s l ,~),  where s,s I E S and 7~ isa rule over/:.Def in i t ion 13.
DFSMs.A DFSM on ~: is a structure .hd = {S,i,T,.A},where S is a finite set of states, i E S is theinitial state, T C S is the set of terminal states,and .,4 is a set of arcs over S on ?.Def in i t ion 14.
Paths.A path ~" or ~r(s0, an) over .M from state so tostate sn is a string s011stl l .
.
.
lnsn, where forall m, 0 _< m _< n, sm is a state of .h4 andlm E US-strings~c.Remark I: n >_ 0, so that the simplest possiblepath has the form s, where s is a state.
Remark &we use the notations ~r and ~r(s, s ~) alternativelyfor the same path; the second notation provides away of referring to the beginning and end statesof the path.Def in i t ion 15.
Recovery of strings from paths.Let lr = solzszl l .
.
.
lnsn.
Then String(~') =11 .
.
.1.
.Def in i t ion 16.
Indezed paths.An indexed path over .Ad is a triple (%1, 7r')where 7r, 7c' are paths, and l,n E US-strings?.
(Tr, 1, or') is an indexing of path a if and only ifo" --" ?r ~l ~lr I.Def in i t ion 17.
Applicability of an arc to an in-dezed path.An are (u,u',7~) is applicable to an indexedpath {lr(s, t), 1, ~'~(s ~,t')} if and only if t = u andthe rule 7~ is applicable to the indexed string(String0r), 1, String(~')).Def in i t ion 18.
Satisfaction of an arc by an in.dezed path.
(~'(s, t), 1, r~(s ~, t~)) satisfies an are {u, u ~, ~)  ifand only if t -- u, s ~ = u ~, and the indexedstring {String(~r), 1  String(~'~)) satisfies the rule36Definit ion 19.
Minimal satisfaction of an arc byan indezed path.Ca',l, z") minimally satisfies an arc A = (s, s', 7~)of.M i f  and only if (a', 1, lr') satisfies A and thereis no state s" and arc A' = i s, s", ~')  of Ad suchthat A' = (s, s ' , 'g ' )  is applicable to (a',l, a")and ~ '  < g .As we said, the above definition is the cru-cial component of the definition of DFSM's.
Ac-cording to this definition, to see whether a DFSMderivation is correct, you must check that eachstate transition represents a maximally specificrule application.
This means that at each stage theDFSM does not provide another arc with a com-peting replacement and a more specific context.
("Competing" means that the underlying symbolsof the replacement match; a replacement competeseven if the surface symbols does not match the let-ter in the US-String being tested.)
4Def in i t ion  20.
Indezed path acceptance by aDFSM.M = (8, i,T,.A) accepts an indexed path(Tr, l,z "~) if and only if there is an arc A I =(s, s I, g~) of .M that is minimally satisfied by(,~, I, 7r').Definit ion 21.
Path acceptance by a DFSM.= (8, i, T, ,4) accepts a path a'(s, s ~) if andonly if .Ad accepts every indexing of ~', s = i,and s' G T.Definit ion 22.
US-String acceptance by a DFSM..Ad accepts z E US-stringsr if and only if thereis a path ~r such that ,Ad accepts ~r, where z =String(Jr).Definit ion 23.
Generation of SF from UF by aDFSM..A4 generates a surface form z '  from an underly-ing form z (where z and z' are strings over ?
)if and only if there is a a E US-strings?
suchthat .Ad accepts z, where U.String(v) = z andS-Str ing(v)  = z' .EXAMPLE:  SPELL ING RULESFOR ENGLISH STEM+SUFF IXCOMBINAT IONSThe following is an adaptation of the treatment inAntworth (1990) of English spelling rules, which4This use of competition builds some directionalbias into the definition of DFSM's, i.e., some prefer-ence for their use in generation.
Even if we are usingDFSM's for recognition, we will need to verify thatthe recognized string is generated from an underlyingform by a derivatio~ that does not allow more specificcompeting derivations.in turn is taken from Karttunen and Wittenburg(1983).?
.M = (S, i, T, A), where S = {i, s, t}.
T = {t}.- Task of i: Begin and process left word bound-ary.- Task of s: Process stem and suffixes.- Task o f t :  Quit, having processed right wordboundary.?
Remark: the small number of states is deceptive,since contexts are allowed on the arcs.
An equiv-alent finite-state transducer would have manyhundreds of states at least.?
Remark: the relatively small number of arcsenumerated below is also deceptive, since twoof these "arcs," are 3 and arc 13, are actuallyschemes.
In the following discussion we willspeak loosely and refer to these schemes as arcs;this will simplify the discussion and should cre-ate no confusion.?
Declare the foUowing subsets of ?
:Lt r= {a, b, c, d, e, f, g, h,i, j, k, 1, m, n, o, p, q, rS, t~ U, V, W, X, y, Z)C = {b,c, d, f, g, h,j, k, l, m, n, p, q, r, s, t,v,w,x,y,z}Csib = {s, x, z}Opal = {c, g}V = {a, e, i, o, u}Vbk = (a, o, u};Where s,s' E 8, let A,,,, = {A/A  G A andfor some 7?,A = (s, s', 'g)}.
We present arcsby listing the rules associated with the arcs, foreach appropriate pair (s, s') of states.
We willgive each arc a numerical label, and give a briefexplanation of the purpose of the arc.?
Arcs in .Ai,, :1.
#~0/_Delete left word boundary.?
Arcs in .A,,,:2.
+ ---~ 0 /__Delete morpheme boundary.3.
I - -~1/__  : lGLt rAny underlying letter is normally unchanged.4.
'~ ' / __Apostrophe is normally unchanged.Stress is normally unchanged.6.
+ ~e/ \ [Cs ib lch \ [sh  \[ y:i\]--s \[+:0 I #:0\]Epenthesis before -s suffix.377.
y--~ i / C__ + :0Spell y as i after consonant and before suffix.8.
y -~ y / C_  + :0\[i:i I ':'\]Exception to Rule 7; cf.
"trying", "fly's".9. s ~ 0 / \[+:0 I +:e\]s +:0 ' -Delete possessive's after plural suffix.10.
e --~ 0 / VCC +_  + :0 VElision.
~11.
e --~ e / VC+Cpa l_  +:0VbkException to Rule 10.12. i --~ y / _e :0  +:0iSpell i as y before elided e before i-initial suf-fix.13.
+~i / ' :OC+Vi : l _ \ [V ly \ ]  :1 E {b, d, g, l, m, n, p, r, t}Gemination.?
Arcs in Ae,t:14.
#- .o / _Delete right word boundary.?
I l l us t ra t ionsI.
The derivation that relates #k iss+s# to0kisses0 proceeds as follows.1.
Begin in state i looking at #:0.2.
Follow arc 2 to s, recognizing k:k. (This isthe only applicable arc.)3.
Follow arc 3 to s, recognizing i:i.
(This is theonly applicable arc.)4.
Follow arc 3 to s, recognizing s:s. (This is theonly applicable arc.)5.
Follow arc 3 to s, recognizing s:s. (This is theonly applicable arc.)6.
Follow arc 6 to s, recognizing +:e. (Arc 2 isalso applicable here; but see the next illustra-tion.)7.
Follow arc 3 to s, recognizing s:s. (This is theonly applicable arc.)8.
Follow arc 14 to f ,  recognizing #:0.
(This isthe only applicable arc.)II.
No derivation relates #kiss+s# to 0kiss0s0.Any such derivation would have to proceed likethe above derivation through Step 5.
At thenext step, the conditions for two arcs are met:arc 2 (replacing + with 0) and arc 6 (replac-ing + with e).
Since the context of the latter~llere, C + can be any string of no more than fourconsonants.arc is more specific, it must apply; there is noderivation from this point using arc 2.III.
The derivation that relates #try+ing# to0try0ing0 proceeds as follows.1.
Begin in state i looking at #:0.2.
Follow arc 2 to s, recognizing t:t. (This is theonly applicable arc.)3.
Follow arc 3 to s, recognizing r:r. (This is theonly applicable arc.)4.
Follow arc 8 to s, recognizing y:y.
(There arethree applicable arcs at this point: arc 3, arc7, and arc 8.
However, arcs 3 and 7 are illegalhere, since their contexts are both less specificthan arc 8's.)5.
Follow are 2 to s, recognizing +:0.
(This isthe only applicable arc.)6.
Follow arc 3 to s, recognizing i:i.
(This is theonly applicable arc.)7.
Follow arc 3 to s, recognizing n:n. (This isthe only applicable arc.)8.
Follow arc 3 to s, recognizing :g. (This is theonly applicable arc.)9.
Follow arc 14 to f ,  recognizing #:0.
(This isthe only applicable arc.)IV.
No derivation relates #t ry+ing# to0tri0ing0.
Any such derivation would have toproceed like the above derivation through Step3.
At the next step, arc 7 cannot be traversed,since arc 8 is also applicable and its context ismore specific.
Therefore, no arc is minimallysatisfied and the derivation halts at this point.COMPUTATIONALCOMPLEXITYWe now consider the complexity of using DFSM'sto create one side of a US-string, given the otherside as input.
There are basically two tasks to beanalyzed:?
DFSM GENERATION:  Given a DFSM, D,over an alphabet, ?, and an underlying form, u,does D generate a surface form, s, from u??
DFSM RECOGNIT ION:  Given a DFSM, D,over an alphabet, ?, and a surface form, s, doesD generate an underlying form, u, from s?These two tasks are related to the tasks of KIMMOGENERATION and KIMMO RECOGNITION, thevarious versions of which Barton et al (1987)proved to be NP-complete or worse.Re la t ionsh ip  to  K immoThe DFSM is not a generalization of KIMMO; itis an alternative architecture for two-level rules.38KIMMO takes a programming approach; it pro-vides a declarative rule formalism, which can berelated to a very large FS automaton or to a sys-tem of parallel FSI automata.
The automata rein general too unwieldy to be pictured or manageddirectly; they are manipulated using the rules.
Byintegrating rules into the automata, the DFSMapproach provides .a procedural formalism that iscompact enough to be diagrammed and manipu-lated directly.DFSM rules are procedural; their meaning de-pends on the role that they play in an algorithm.In a DFSM with many states, the effect achievedby a rule (where a rule is a context-dependent re-placement type) will in general depend on how therule is attached to states.
In practice, however, theproceduralism of the DFSM approach can be lim-ited by allowing only a few states, which have anatural morphonemic nterpretation.
The Englishspelling example that we presented in the previ-ous section illustrates the idea.
There are only fourstates.
Of these, two of them delimit word process-ing; one of them begins processing by traversing aleft word boundary, the other terminates process-ing after traversing a final word boundary.
Of theremaining two states, one processes the word; allof the rules concerning possible replacements areattached to arcs that loop from this state to it-self.
The other is a nonterminal state with no arcsleading from it.
In the  example, the only purposeof this state is to render certain insertions or dele-tions obligatory, by "trapping" all US-strings inwhich the operation is not performed in the re-quired context.In cases of this kind, where the ways in whichrules can be attached to arcs are very restricted,tile proceduralism of the DFSM formalism is lim-ited.
The uses of rules in such cases correspondroughly to two traditional types of phonologicalconstructs: rules that allow certain replacementsto occur, and constraints that make certain re-placements obligatory.Although DFSM's are less declarative thanKIMMO, we believe that it may be possible tointerpret at least some DFSM's (those in whichthe roles that can~ be played by states are lim-ited) using a nonmonotonic formalism that pro-vides for prioritization of defaults, such as prior-itized default logic; see (Brewka, 1993).
In thisway, DFSM's could be equated to declarative, ax-iomatic theories with a nonmonotonic consequencerelation.
But we have not carried out the detailsof this idea.Though it is desirable to constrain the num-ber of states in a DFSM, there may be appli-cations in which we may want more states thanin the English example.
For instance, one natu-ral way to process vowel harmony would multiplystates by creating a word-processing state for eachvowel quality.
Multiple modes of word-processingcould also be used to handle cases (as in manyAthabaskan languages) where different morpho-phonemic processes occur in different parts of theword.If  they are desired, local translations of thefour varieties of KIMMO rules ?
into DFSM's areavailable, by using only one state plus a sink state.
?The following correspondences provide transla-tions, in polynomial time, to one or more DFSMarcs :Exclusion, u : s /  ~ LC__RC:  an arc us / LC- -RC from the state to a sink state .
.
.
.
.
.
.
.
.Context Restriction, u : s ~ LC_ -RC:  a loopu --~ s / LC__RC,  and an arc u --~ s / _ to asink state.Surface Coercion, u : s ~ LC__RC:  a loop us / LC- -RC,  and for each surface character s t E?, an arc u --~ s t / LC .
- -RC to a sink state.Composite, u : s ?~ LC ._RC:  all of the arcsmentioned in Context Restriction or Surface Co-ercion.
:Ex tended DFSM'sThe differences between KIMMO and DFSM's pro-hibit the complexity analysis for the correspond-ing two KIMMO problems from naturally extend-ing to an analysis of DFSM generation and recog-nition.
In fact, we can define an extended DFSM(EDFSM) ,  which drops the finite encodability re-quirement hat KIMMO lacks, for which we havethe following result:Theorem 1.
EDFSM GENERATION is PSPACE-hardProof  by reduction of REGULAR EXPRES-SION NON-UNIVERSALITY (see Figure 1).
Givenan alphabet E, and a regular expression, a ?
~b,over E, we define an EDFSM over the alphabet,U {$}, where $ ~ E. We choose one non-emptystring ceEL(a) of length n. The EDFSM first rec-ognizes each character in a, completing the taskat state n0:al  a l  I (?
:?
)* - - (?
:?
)*  7From no, there are two arcs, which map to differentstates:eSproat (1992), p. 145.7Unlike with normal DFSM's, we will use reg,larexpressions for the contexts themselves in EDFSM's,not their encodings, since they may be infinite anyway.392 ~ 2 / E*.._,~*2 -~ 2 / (a + 2)__(a + 2)where the latter rule traverses to some state 81,with a being the expression which replaces eachatom, b, in a by its constant replacement, b:b,and likewise for ~.From Sl, the EDFSM then recognizes o~ again,terminating at the only final state.
We providethis EDFSM, along with the input ot2o~ to EDFSMGENERATION.
This EDFSM can accept c~$ot ifand only if, at state so, the context (~3", ~*) is notmore specific than the context ((a + $), (a + 2)).So, we have:(~', ~') ?
((.
+ 2), (~ + 2))(~',  ~')  ~ ((~ + $),(a+ 2))or (z ' ,  ~*) =_ ((a + 2), (~ + $))~.
~" ~ L(a + 2)or Z* = L(a+ $)~* ~ L (a+ 2), since $ ~ ~,~* ~ L(a) U {$}E* ~ L(a), since $ ~ ~,~" ?
L(.)?}
L(a) # E* (we know L(a) C_ E*)The translation function is linear in the size of theinput.~Owrite ccu, 10i ~  ~" write ~:c~(a+$) _ (a+$)$ -> ~ z*k..J / x*_Figure 1.
EDFSM constructed in Theorem 1.The  Complex i ty  o f  DFSM GENERATIONFinite encodability foils the above proof tech-nique, since one can no longer express arbitraryregular expressions over pairs in the contexts ofrules.
In fact, as we demonstrated above, thereis a polynomial-time algorithm for comparing thespecificities of finitely-encodable contexts.
Finiteencodability does not, however, restrict the com-plexity of DFSM's enough to make DFSM GEN-ERATION polynomial time:Theoren l  2.
I)I"SM GENERATION is NI Lcomplete.Proof DFSM GENERATION is obviously inNP.
The proof of NP-hardness is a reduction of3-SAT.
Given an input formula, w, we constructa DFSM consisting of one state over an alphabetconsisting of 0, 1, ~,  one symbol, u~, for each vari-able in w, and one symbol, ej, for each conjunctin w. Let m be the number of variables in w, andn, the number of conjuncts.
For each variable, ui,we add four loops:u, ~ 1 / #:# u1:?
.
.
.
u~-1:?-- ,u~ ~ 0 / #:# u1:?
.
.
.
u~-1:?-- ,ui -~ 1 / u/:l ui+l:?
.. .
um:?
?:?u1:?
.. .
u l -x:?-- ,u~ ~ 0 / u~:0 u i+ l :?
.
.
.
u,~:?
?:?u1:?
.. .
u~-x:?--The first two choose an assignment for a variable,and the second two enforce that assignment's con-sistency.
For each conjunct, Ijl V 1/2 V ljs, wherethe l's are literals, we also add three loops, onefor each literal.
The loops enforce a value of 1on the symbol uj~ if lj~ is a positive literal, or 0,if it is negative.
For example, for the conjunctul V qua V u4, we add the following three rules:cj -+ cj / ul : l  u~:?
.
.
.
um:?--c~ ~ c~ / us:0 u4:?
.
.
.
u, , :?__Cj --~ Cj / u4:l u5:?
.
.
.
um:?- -Thus, the input to DFSM GENERATION isthe above DFSM plus an input string cre-ated by iterating the substring u l .
.
.umc jfor each conjunct.
The input string corre-sponding to the formula, ('~ul V u2 V u4) A(~u~ V us V'~u4) A (ul V u2 V us), would be~ulu2usu4clulu2uau4e2ulu2uau4cs.
The DFSMaccepts this input string if and only if the inputformula is satisfiable; and this translation is linearinm+n.
DCompi la t ionOf course, we should consider whether the com-plexity of DFSM GENERATION can be compiledout, leaving a polynomial-time machine which ac-cepts input strings.
This can be formalized as theseparate problem:?
F IXED-DFSM-GENERATION:  For someDFSM, D, over alphabet, ?, given an underly-ing form, u, does D generate a surface form, s,from u?Whether or not FIXED DFSM GENERATIONbelongs to P remains an open problem.
It is, ofcourse, no more difficult than the general DFSMGENERATION problem, and thus no more difficultthan NP-complete.
The method used in tile proofgiven above, however, does not naturally extendto the case of FIXED DFSM GENERATION, sincewe cannot, with a fixed DFSM, know in advance40.
.
.
.
.
.
,.,.
:how many variables to expect in a given input for-mula, without which we cannot use the same trickwith the left context o preserve the consistencyof variable assignment.Even more interestingly, the technique used inthe proof of PSPACFE-hardnees of EDFSM GEN-ERATION does not naturally extend to fixedEDFSM's either; thus, whether or not FIXEDDFSM GENERATION belongs to P is an openquestion as well s. Dropping finite encodability, ofcourse, affects the compilation time of the problemimmensely.Nu l l sThe two proofs we have given remain validif we switch alll of the underlying forms withtheir surface counterparts.
Thus, without nulls,EDFSM RECOGNITION is PSPACE-hard, DFSMRECOGNTION is NP-complete, and, if FIXEDDFSM GENERATION is in P, then we can presum-ably use the same compilation trick with the rolesof underlying and surface strings reversed to showthat FIXED DFSM RECOGNITION is in P as well.If nulls are permitted in surface realizations,however, DFSM RECOGNTION becomes muchmore difficult, even with finite encodability en-forced:Theorem 3.
DFSM RECOGNTION with nulls isPSPACE-hard.Proof by reduction of CONTEXT-SENSITIVELANGUAGE MEMBERSHIP (see Figure 2).
Givena context-sensitive grammar and an input stringof length m, we let the input surface form to theDFSM RECOGNTION problem be the same as theinput string.
We then design a DFSM with analphabet equal to E U {$,!
}, where ~ is the theset of non-terminals plus the set of terminals.
TheDFSM first copies each surface input symbol tothe corresponding position in the underlying form,and then adds the pair $:0, completing the taskin a state So.Having copied the string onto the underlyingside of the pair, the remainder of the recognizedunderlying form will consist of rewritings of thestring for each rule application, and will be pairedwith surface nulls at the end of the input string.Each rewriting will be separated by a $ symbol,and, as the string length changes, it will be paddedby !
symbols.
For each rule a ~ #, we add a cycleto the DFSM, emanating from state so, which firstsit is quite unlikely, however, since the reduc-tion can probably be made with a different PSPACE-complete problem, from which the NP-completenessof FIXED EDFSM GENERATION would follow as acorollary.writes j copies of the !
symbol to the underlyingform, where j = b - a, b = Ifll, and a = la l :!
-*  0 / ~:?(?:?
.
.
.~  ?:?)
-- :.j >_ 0 since the rules are context-sensitive.copy string + $:0to underly~gg$:0 / !
:L ...
!
:L write J l:O,sji=~ a S:L $:L_( r l )OOL a->'_:r2)recognize \[3, write al~,.,L,~' ( r l )OFigure 2.
DFSM constructed in Theorem 3.The cycle then copies part of the most recentS-bounded string of symbols with a family of loopsof the form:o" --+ 0 / o':?
(?
: ...m+j ?
:?  )
-- (r l)for each o" E ~.
It then recognizes ~, and : writesa, with:~1 ~ 0 / (& :?
...b & :?
)( ?:?
.
.
.
, ,+ j+ l -b  ?:? )
--,followed by:or2 - -  0 / - - ,o<, --+ 0 / -I t  then copies the rest of the most recent g-bounded string, using copy of the family of loopsin (rl), and then adds a new $ with a rule thatalso ensures that this second loop has iterated theappropriate number of times by checking that thelength has been preserved:$ -~ 0 / $:?
(?:L.
.
.m L:L ) "  (r2)The DFSM also has a loop emanating from sowhich adds more !
symbols:!
-..+ 0 / h?
( ?:?
...m ?:? )
-All of the rule-cycles will use this to copypreviously-added !
symbols, as the string shrinksin size.
The proper application of this loop is alsoensured by the length-checking of (r2).Finally, we add one arc to the DFSM from Soto the only final .state which checks that the finalcopy of the string contains only the distinguishedsymbol, S:$ -* 0 / ( h?
.
.
.~- I  h?)
S:?
$:?__L , .41 'Thus, the DFSM recognises the surface formif and only if there is a series of rewritings from theinput string to S using the rules of the grammar,and the translation is linear in the size of the inputstring times the number of rules.
OSince there exist fixed context-sensitive gram-mars for which the acceptance problem is NP-hard 9, the NP-hardness of FIXED DFSM RECOG-NITION with nulls follows as a corollary.CONCLUSIONWe claimed that DFSM's  provide an approach torules that is likely to seem more natural and in-tuitive to phonologists.
Bridging the gap betweenlinguistically adequate formalisms and computa-tionally useful formalisms is a long-term, commu-nity effort, and we feel that it would be prematureto make claims about the linguistic adequacy ofthe approach; this depends on whether two-levelapproaches can be developed and deployed in away that will satisfy the theoretical and explana-tory needs of linguists.
A specific claim on whichour formalism depends is that all natural two-levelphonologies can be reproduced using DFSM's  withfinitely encodable rules.
We feel that this claim isplausible, but it needs to be tested in practice.Computationally, our complexity work so faron DFSM's  does not preclude the possibility thatcompilers for generation and recognition (with-out nulls) exist which will allow for polynomial-time behavior at run-time.
Although this ques-tion must eventually be resolved, we feel that anyimplementation is likely to be simpler than thatrequired for KIMMO, and that even a direct imple-mentation of DFSM's  can prove adequate in manycircumstances.
We have not constructed an imple-mentation as yet.Like other two-level approaches, we have aproblem with surface nulls.
It is possible inmost realistic recognition applications to boundthe number of nulls by some function on the lengthof the overt input; and it remains to be seenwhether a reasonable bound could sufficiently im-prove complexity in these cases.We have dealt with the problem of underlyingnulls by simply ruling them out.
This simplifiesthe formal situation considerably, but we do notbelieve that it is acceptable as a general solution;for instance, we can't expect all cases ofepenthesesto occur at morpheme boundaries.
If underlyingnulls are allowed, though, we will somehow need tolimit the places where underlying nulls can occur;this is another good reason to pay attention to aphonotactic level of analysis.9Garey and Johnson, (1979), p. 271.ACKNOWLEDGEMENTSThis material is based upon work supported undera National Science Foundation Graduate ResearchFellowship.
This work was funded by NationalScience Foundation grant IRI-9003165.
We thankthe anonymous referees for helpful comments.REFERENCESEvan Antworth.
1990.
Pc-KIMMO: a two-level processor for morphological nalysis.
Dallas,Texas: Summer Institute of Linguistics.Edward Barton, Robert Berwick, and EricRistad.
19877.
Computational Complezity andNatural Language.
Cambridge, Massachusetts:MIT Press.Gerhard Brewka.
1993.
Adding priorities andspecificity to default logic.
DMG Technical Re-port.
Sankt Augustin, Germany: Gesellschaft drMathematik und Datenverarbeitung.Mary Dalrymple, Ronald Kaplan, Lanri Kart-tunen, K immo Koskenniemi, Sami Shalo, andMichael Wescoat.
1987.
Tools for MorphologicalAnalysis.
Stanford, California, 1987: CSLI Tech-nical Report CSLI-87-108.Michael Garey and David Johnson.
1979.Computers and Intractability: A Guide to theTheory of NP-completeness.
New York, NewYork: Freeman and Co.Lanri Karttunen.
1991.
"Finite-state con-straints."
International conference on currentissues in computational inguistics.
Penang,Malaysia.Lauri Karttunen and Kent Wittenburg.
1983.
"A two-level morphological nalysis of English.
"Tezas Linguistic Forum ~ pp.
217-228.Graeme Ritchie, Graham Russell, Alan Blackand Stephen Pulman.
1992.
Computational mor-phology.
Cambridge, Massachusetts: MIT Press.Richard Sproat.
1992.
Morphology and com-putation.
Cambridge, Massachusetts: MIT Press.42
