Document  retr ieval  and text  retr ievalKaren Sparck JonesComputer  Laboratory,  University of CambridgeNew Museums Site, Pembroke Street, Cambridge CB2 3QG, UK1.
Essent ia l s  o f  document  re t r ieva lDocument retrieval (DR) is for the user who wants tofind out about something by reading about it.DR systems illustrate very variety of indexing language,request and document description, and search mecha-nism.
Controlled languages (CLs) have been commonlyused, across the range from only slightly restricted nat-ural language (NL) to a carefully designed artificial lan-guage.
With CLs professional indexing is required andprofessional searching is the norm.
However automaticDR systems have also encouraged the use of NL throughsearching on titles and abstracts.
This naturally makesend-user searching practicable, though not necessarilyeasy; and end-users often lack the experience to searcheffectively when strict word matching fails to identifyappropriate documents.
The essential requirement in re-trieval is that a match between request and document de-scriptions hould reflect he underlying relation betweenuser need and document content.Indexing, providing for matches, thus aims to promoteprecision and/or recall.
It often has to do this underthe external constraints of large files with small rele-vance sets.
It always has to do it under the internalconstraints on indexing itself.
These are, for both re-quests and documents, variability of language, whetherthis stems from ambiguity or differences of perspective;for requests, underspecification, whether through vague-ness or incompleteness; and for documents, informationreduction, whether through generalisation r selection.Reduction isessential for DR, for both efficiency in scan-ning and effectiveness in concentrating onkey content.The implications of these constraints for index languagedesign and use are conflicting, and suggest many alterna-tive possibilities within the CL/NL space for the treat-ment of terms and term relations, of implicit and ex-plicit relations, and of syntagmatic and paradigmatic re-lations.
Mixes and tradeoffs are possible, and the neces-sary flexibility is achieved, because descriptions are ma-nipulated in searching.However though the conventional preference is for CLs,extensive tests have shown that very competitive perfor-mance can be obtained through cheap and simple index-ing using coordinated single NL terms along with sta-tistical selection and weighting, ranked output, and rel-evance feedback.
The gains from this approach comefrom allowing for late binding and redundancy, alongwith derivation from source documents, in topic char-acterisation.
The findings have been supported by manytests investigating different DR system factors, and theapproach as been implemented commercially.
But thetest evidence is not always strong, and the tests havebeen on a limited scale; further, the strategy depends onrequest quality and probably also on working with docu-ment surrogates, like abstracts, which concentrate infor-mation.
Even so, the puzzle is that linguistic sophisti-cation, even with human LP, does not provide clear per-formance gains, and routine performance typically fallswithin an undistinguished 30-60% R-P tradeoff area.2.
Text  re t r ieva lHowever a new situation has arisen with the availabilityof machine-readable full text.
For text retrieval (TR),NLP to provide more sophisticated indexing may beneeded because more discrimination within large files oflong texts is required, or may be desired because more fo-cusing is possible.
This suggests the more NLP the bet-ter, but whether for better-motivated simple indexing orfor more complex representation has to be determined.Given past experience, and the need for flexibility in theface of uncertainty, a sound approach appears to be tomaintain overall simplicity but to allow for more complexindexing descriptors than single terms, derived throughNLP and NL-flavoured, e.g.
simple phrases or predi-cations.
These would be just coordinated for descrip-tions but, more importantly, statistically selected andweighted.
To obtain the reduced escriptions still neededto emphasise important text content, text-locational orstatistical information could be exploited.
To supportindexing, and, more critically, searching a terminologi-cal apparatus again of a simple NL-oriented kind provid-ing term substitutes orcollocates, and again statisticallycontrolled, could be valuable.
Searching should allow347the substitution or relaxation of elements and relationsin complex terms, again with weighting, especially viafeedback.
This whole approach would emphasise the NLof the texts while recognising the statistical propertiesof large files and long documents.
The crux is thus todemonstrate hat linguistically-constrained terms are su-perior to e.g.
co-locational ones.Heavy testing is needed to establish performance for thesuggested approach, given the many factors affecting re-trieval systems, both environment variables e.g.
doc-ument type, subject domain, user category, and systemparameters e.g.
description exhaustivity, language speci-ficity, weighting formula.
There are also different eval-uation criteria, performance measures, and applicationmethods to consider.
Proper testing is hard (and costly)since it requires large collections, of requests as much asdocuments, with relevance assessments, and implies fine-grained comparisons within a grid of system contexts anddesign options.Various approaches along the lines suggested, as well assimpler DR-derived ones, are being investigated withinARPA TREC.
The TREC experiments are important asthe largest retrieval tests to date, with an earnest eval-uation design, as well as being TR tests on the grandscale.
But any conclusions drawn from them must betreated with caution since the TREC queries are highlyhoned, and are for standing interests (matching a docu-ment against many requests not vice versa), with tightlyspecified response needs.
TREC is not typical of manyretrieval situations, notably the 'wants to read about'one, so any results obtained, especially good ones relyingon collection tailoring, may not be generally applicableand other tests are mandatory.3.
HLT  i ssuesIn the present state of TR research, and the HLT con-text, the issues are as follows:1.
With respect o the objects manipulated in retrieval,i.e.
index descriptions, given that indexing is mak-ing predictions for future searching:What kind of sophistication is in order: what con-cepts should be selected and how should they berepresented?
How should linguistic and statisticalfacts be related?
For example, how should weightsfor compounds be derived, by wholes or from con-stituents, and how should matching, by wholes orconstituents, be handled?2.
Wrt the process of retrieval, given that searching isfundamentally interactive:What way of developing requests is best: shouldthe system be proactive or reactive?
How can theuser be involved?
For example, how can the usercope with CLs that are incomprehensible (throughnotation) or misleading (through pseudo-English);or with statistical numbers?3.
Wrt the implementation f retrieval systems, giventheir asymmetry with requests demanding noticebut many documents never wanted:What distribution of effort is rational: should effortbe at file time or search time?
How can flexibility bemaintained?
For instance, when should compoundsbe formed, or their weights computed?4.
Wrt the model adopted to underpin systems, giventhe lumpiness inherent in system operation in themass and average but user interest in the individualand distinctive:What strength of assumptions i rational: shouldthe system work with the vector, or probabilistic,or some other model?
How can an abstract formalmodel supply specific instructions for action?
Forinstance, can the model say precisely how matchesshould be scored?5.
Wrt retrieval using full text, given that with moredetail there is also more noise:What functions should TR serve: should it helpto refine indexing or offer passage retrieval?
Howmight indexing and searching on two levels operate?For instance, how can a dispersed concept, spreadover text, be identified?6.
Wrt system testing, given the enormous variety ofenvironment factors and system possibilities:What degree of reality and representativeness is re-quired for validity: can collections be picked up ormust they be designed?
How can control be im-posed to isolate factor effects?
For instance, howshould non-repeatable user search data be treated?These issues reflect the conflict between the fact of in-terdependencies within systems and the aim of decom-position for understanding and design.
Thus the keypoints for DR and TR as potential NLP tasks, as op-posed to e.g.
database query or translation, is that scalephenomena count; thus the value of index descriptions iin file discrimination, not document definition; and re-trieval output is contingent on the lifetime file, not thelocal situation.
At the same time, information retrievalexperience has shown that any approach can seem plau-sible, as also that whatever one does comes out grey inthe wash.348
