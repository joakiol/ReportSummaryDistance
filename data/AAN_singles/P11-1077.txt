Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 763?772,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsAge Prediction in Blogs: A Study of Style, Content, and OnlineBehavior in Pre- and Post-Social Media GenerationsSara RosenthalDepartment of Computer ScienceColumbia UniversityNew York, NY 10027, USAsara@cs.columbia.eduKathleen McKeownDepartment of Computer ScienceColumbia UniversityNew York, NY 10027, USAkathy@cs.columbia.eduAbstractWe investigate whether wording, stylisticchoices, and online behavior can be usedto predict the age category of blog authors.Our hypothesis is that significant changesin writing style distinguish pre-social me-dia bloggers from post-social media blog-gers.
Through experimentation with arange of years, we found that the birthdates of students in college at the timewhen social media such as AIM, SMS textmessaging, MySpace and Facebook firstbecame popular, enable accurate age pre-diction.
We also show that internet writingcharacteristics are important features forage prediction, but that lexical content isalso needed to produce significantly moreaccurate results.
Our best results allow for81.57% accuracy.1 IntroductionThe evolution of the internet has changed theway that people communicate.
The introductionof instant messaging, forums, social networkingand blogs has made it possible for people of ev-ery age to become authors.
The users of thesesocial media platforms have created their ownform of unstructured writing that is best char-acterized as informal.
Even how people com-municate has dramatically changed, with multi-tasking increasing and responses generated im-mediately.
We should be able to exploit thosedifferences to automatically determine from blogposts whether an author is part of a pre- or post-social media generation.
This problem is calledage prediction and raises two main questions:?
Is there a point in time that proves to bea significantly better dividing line betweenpre and post-social media generations??
What features of communication most di-rectly reveal the generation in which a blog-ger was born?We hypothesize that the dividing line(s) oc-cur when people in generation Y1, or the millen-nial generation, (born anywhere from the mid-1970s to the early 2000s) were typical college-aged students (18-22).
We focus on this gen-eration due to the rise of popular social mediatechnologies such as messaging and online socialnetworks sites that occurred during that time.Therefore, we experimented with binary clas-sification into age groups using all birth datesfrom 1975 through 1988, thus including studentsfrom generation Y who were in college duringthe emergence of social media technologies.
Wefind five years where binary classification is sig-nificantly more accurate than other years: 1977,1979, and 1982-1984.
The appearance of socialmedia technologies such as AOL Instant Messen-ger (AIM), weblogs, SMS text messaging, Face-book and MySpace occurred when people withthese birth dates were in college.We explore two of these years in more detail,1979 and 1984, and examine a wide variety of1http://en.wikipedia.org/wiki/Generation Y763features that differ between the pre-social me-dia and post-social media bloggers.
We examinelexical-content features such as collocations andpart-of-speech collocations, lexical-stylistic fea-tures such as internet slang and capitalization,and features representing online behavior suchas time of post and number of friends.
We findthat both stylistic and content features have asignificant impact on age prediction and showthat, for unseen blogs, we are able to classifyauthors as born before or after 1979 with 80%accuracy and born before or after 1984 with 82%accuracy.In the remainder of this paper, we first dis-cuss work to date on age prediction for blogsand then present the features that we extracted,which is a larger set than previously explored.We then turn separately to three experiments.In the first, we implement a prior approach toshow that we can produce a similar outcome.
Inthe second, we show how the accuracy of ageprediction changes over time and pinpoint whenmajor changes occur.
In the last experiment, wedescribe our age prediction experiments in moredetail for the most significant years.2 Related WorkIn previous work, Mackinnon (2006) , used Live-Journal data to identify a blogger?s age by ex-amining the mean age of his peer group usinghis social network and not just his immediatefriends.
They were able to predict the correctage within +/-5 years at 98% accuracy.
This ap-proach, however, is very different from ours as itrequires access to the age of each of the blogger?sfriends.
Our approach uses only a body of textwritten by a person along with his blogging be-havior to determine which age group he is moreclosely identified with.Initial research on predicting age without us-ing the ages of friends focuses on identifying im-portant candidate features, including bloggingcharacteristics (e.g., time of post), text features(e.g., length of post), and profile information(e.g., interests) (Burger and Henderson, 2006).They aimed at binary prediction of age, classify-ing LiveJournal bloggers as either over or under18, but were unable to automatically predict agewith more accuracy than a baseline model thatalways chose the majority class.
In our study ondetermining the ideal age split we did not find18 (bloggers born in 1986 in their dataset) to besignificant.Prior work by Schler et al (2006) has ex-amined metadata such as gender and age inblogger.com bloggers.
In contrast to our work,they examine bloggers based on their age at thetime of the experiment, whether in the 10?s, 20?sor 30?s age bracket.
They identify interestingchanges in content and style features across cat-egories, in which they include blogging words(e.g., ?LOL?
), all defined by the Linguistic In-quiry and Word Count (LIWC) (Pennebaker etal., 2007).
They did not use characteristics ofonline behavior (e.g., friends).
They can distin-guish between bloggers in the 10?s and in the 30?swith relatively high accuracy (above 96%) butmany 30s are misclassified as 20s, which resultsin a overall accuracy of 76.2%.
We re-implementSchler et al?s work in section 5.1 with similarfindings.
Their work shows that ease of classi-fication is dependent in part on what divisionis made between age groups and in turn moti-vates our decision to study whether the creationof social media technologies can be used to findthe dividing line(s).
Neither Schler et al, norwe, attempt to determine how a person?s writ-ing changes over his lifespan (Pennebaker andStone, 2003; Robins et al, 2002).
Goswami etal.
(2009) add to Schler et al?s approach usingthe same data and have a 4% increase in accu-racy.
However, the paper is lacking details andit is entirely unclear how they were able to dothis with fewer features than Schler et alIn other work, Tam and Martell (2009) at-tempt to detect age in the NPS chat corpus be-tween teens and other ages.
They use an SVMclassifier with only n-grams as features.
Theyachieve > 90% accuracy when classifying teensvs 30s, 40s, 50s, and all adults and achieve atbest 76% when using 3 character gram featuresin classifying teens vs 20s.
This work shows thatn-grams are useful features for detecting age andit is difficult to detect differences between con-secutive groups such as teens and 20s, and this764Figure 1: Number of bloggers in 2010 by year of birthfrom 1950-1996.
A minimal amount of data occurredin years not shown.provides evidence for the need to find a goodclassification split.Other researchers have investigated weblogsfor differences in writing style depending on gen-der identification (Herring and Paolillo, 2006;Yan and Yan, 2006; Nowson and Oberlander,2006).
Herring et al(2006) found that the typi-cal gender related features were based on genreand independent of author gender.
Yan et al(2006) used text categorization and stylistic webfeatures, such as emoticons, to identify genderand achieved 60% F-measure.
Nowson et al(2006) employed dictionary and n-gram basedcontent analysis and achieved 91.5% accuracyusing an SVM classifier.
We also use a super-vised machine learning approach, but classifica-tion by gender is naturally a binary classificationtask, while our work requires determining a nat-ural dividing point.3 Data CollectionOur corpus consists of blogs downloaded fromthe virtual community LiveJournal.
We choseto use LiveJournal blogs for our corpus becausethe website provides an easy-to-use format inXML for downloading and crawling their site.In addition, LiveJournal gives bloggers the op-portunity to post their age on their profile.
Wetake advantage of this feature by downloadingblogs where the user chooses to publicly providethis metadata.We downloaded approximately 24,500 Live-Journal blogs containing age.
We represent ageas the year a person was born and not his ageat the time of the experiment.
Since technol-ogy has different effects in different countries,we only analyze the blogs of people who havelisted US as their country.
It is possible thattext written in a language other than Englishis included in our corpus.
However, in a man-ual check of a small portion of text from 500blogs, we only found English words.
Each blogwas written by a unique individual and includesa user profile and up to 25 recent posts writtenbetween 2000-2010 with the most recent post be-ing written in 2009-2010.
The birth dates of thebloggers range in years from 1940 to 2000 andthus, their age ranges from 10 to 70 in 2010.
Fig-ure 1 shows the number of bloggers per age inour group with birth dates from 1950 to 1996.The majority of bloggers on LiveJournal wereborn between 1978-1989.4 MethodsWe pre-processed the data to add Part-of-Speech tags (POS) and dependencies (de Marn-effe et al, 2006) between words using the Stan-ford Parser (Klein and Manning, 2003a; Kleinand Manning, 2003b).
The POS and syntacticdependencies were only found for approximatelythe first 90 words in each sentence.
Our classifi-cation method investigates 17 different featuresthat fall into three categories: online behavior,lexical-stylistic and lexical-content.
All of thefeatures we used are explained in Table 1 alongwith their trend as age decreases where applica-ble.
Any feature that increased, decreased, orfluctuated should have some positive impact onthe accuracy of predicting age.4.1 Online Behavior and InterestsOnline behavior features are blog specific, suchas number of comments and friends as describedin Table 1.1.
The first feature, interests, is ouronly feature that is specific to LiveJournal.
In-terests appear in the LiveJournal user profile,but are not found on all blog sites.
All otheronline behavior features are typically availablein any blog.765Feature Explanation Example Trend as AgeDecreases1 Interests Top3 interests provided on the profile page2 disney N/A2# of Friends Number of friends the blogger has 45 fluctuates# of Posts Number of downloadable posts (0-25) 23 decrease# of Lifetime Posts Number of posts written in total 821 decreaseTime Mode hour (00-23) and day the blogger posts 11/Monday no changeComments Average number of comments per post 2.64 increase3Emoticons number of emoticons1 :) increaseAcronyms number of internet acronyms1 lol increaseSlang number of words that are not found in the dictionary1 wazzup increasePunctuation number of stand-alone punctuation1 ... increaseCapitalization number of words (with length > 1) that are all CAPS1 YOU increaseSentence Length average sentence length 40 decreaseLinks/Images number of url and image links1 www.site.com fluctuates4Collocations Top3 Collocations in the age group.
to [] the N/ASyntax Collocations Top3 Syntax Collocations in the age group.
best friends N/APOS Collocations Top3 Part-of-Speech Collocations in the age group.
this [] [] VB N/AWords Top3 words in the age group his N/ATable 1: List of all features used during classification divided into three categories (1,2) online behavior andinterests, (3) lexical - content, and (4) lexical - stylistic 1 normalized per sentence per entry, 2 available inLiveJournal only, 3 pruned from top 200 features to include those that do not occur within +/- 10 positionin any other age groupWe extracted the top 200 interests based onoccurrence in the profile page from 1500 randomblogs in three age groups.
These age groups areused solely to illustrate the differences that oc-cur at different ages and are not used in ourclassification experiments.
We then pruned thelist of interests by excluding any interest thatoccurred within a +/-10 window (based on itsposition in the list) in multiple age groups.
Weshow the top interests in each age group in Ta-ble 2.
For example, ?disney?
is the most popu-lar unique interest in the 18-22 age group withonly 39 other non-unique interests in that agegroup occurring more frequently.
?Fanfiction?is a popular interest in all age groups, but itis significantly more popular in the 18-22 agegroup than in other age groups.Amongst the other online behavior features,the number of friends tends to fluctuate butseems to be higher for older bloggers.
The num-ber of lifetime posts (Figure 2(d)), and posts de-creases as bloggers get younger which is as onewould expect unless younger people were ordersof magnitude more prolific than older people.The mode time (Figure 2(b)), refers to the most18-22 28-32 38-42disney 39 tori amos 49 polyamory 40yaoi 40 hiking 55 sca 67johnny depp 42 women 61 babylon 5 84rent 44 gaming 62 leather 94house 45 comic books 67 farscape 103fanfiction 11 fanfiction 58 fanfiction 138drawing 10 drawing 25 drawing 65sci-fi 199 sci-fi 37 sci-fi 21Table 2: Top interests for three different age groups.The top half refers to the top 5 interests that areunique to each age group.
The value refers to theposition of the interest in its listcommon hour of posting from 00-24 based onGMT time.
We didn?t compute time based onthe time zone because city/state is often not in-cluded.
We found time to not be a useful featurein this manner and it is difficult to come to anyconclusions from its change as year of birth de-creases.4.2 Lexical - StylisticThe Lexical-Stylistic features in Table 1.2, suchas slang and sentence length, are computed us-766Figure 2: Examples of change to features over time (a) Average number of emoticons in a sentence increasesas age decreases (b) The most common time fluctuates until 1982, where it is consistent (c) The numberof links/images in a sentence fluctuates (d) The average number of lifetime posts per year decreases as agedecreasesing the text from all of the posts written by theblogger.
Other than sentence length, they werenormalized by sentence and post to keep thenumbers consistent between bloggers regardlessof whether the user wrote one or many posts inhis/her blog.
The number of emoticons (Figure2(a)), acronyms, and capital words increased asbloggers got younger.
Slang and punctuation,which excludes the emoticons and acronymscounted in the other features, increased as well,but not as significantly.
The length of sentencesdecreased as bloggers got younger and the num-ber of links/images varied across all years asshown in Figure 2(c).4.3 Lexical - ContentThe last category of features described in Ta-ble 1.3 consists of collocations and words, whichare content based lexical terms.
The top wordsare produced using a typical ?bag-of-words?
ap-proach.
The top collocations are computed us-ing a system called Xtract (Smadja, 1993).We use Xtract to obtain important lexical col-locations, syntactic collocations, and POS col-locations as features from our text.
Syntac-tic collocations refer to significant word pairsthat have specific syntactic dependencies suchas subject/verb and verb/object.
Due to thelength of time it takes to run this program, weran Xtract on 1500 random blogs from each agegroup and examined the first 1000 words perblog.
We looked at 1.5 million words in totaland found approximately 2500-2700 words thatwere repeated more than 50 times.We extracted the top 200 words and colloca-tions sorted by post frequency (pf), which is thenumber of posts the term occurred in.
Then,similarly to interests, we pruned each list toinclude the features that did not occur within+/-10 window (based on its position in the list)within each age group.
Prior to settling on thesemetrics, we also experimented with other met-rics such as the number of times the collocation76718-22 28-32 38-42ldquot (?)
101 great 166 may 164t 152 find 167 old 183school 172 many 177 house 191x 173 years 179 world 192anything 175 week 181 please 198maybe 179 post 190 - -because 68 because 80 because 93him 59 him 85 him 73Table 3: Top words for three age groups.
The tophalf refers to the top 5 words that are unique to eachage group.
The value refers to the position of theinterest in its listoccurred in total, defined as collocation or termfrequency (tf), the number of blogs the colloca-tion occurred in, defined as blog frequency (bf),and variations of TF*IDF (Salton and Buck-ley, 1988) where we tried using inverse blog fre-quency and inverse post frequency as the valuefor IDF.
In addition, we also experimented withlooking at a different number of important wordsand collocations ranging from the top 100-300terms and experimented without pruning.
Noneof these variations improved accuracy in ourexperiments, however, and thus, were droppedfrom further experimentation.Table 3 shows the top words for each agegroup; older people tend to use words such as?house?
and ?old?
frequently and younger peo-ple talk about ?school?.In our analysis of the top collocations, wefound that younger people tend to use first per-son singular (I,me) in subject position whileolder people tend to use first person plural (we)in subject position, both with a variety of verbs.5 Experiments and ResultsWe ran three separate experiments to determinehow well we can predict age: 1. classifying intothree distinct age groups (Schler et al (2006)experiment), 2. binary classification with thesplit at each birth year from 1975-1988 and 3.Detailed classification on two significant splitsfrom the second experiment.We ran all of our experiments in Weka (Hall etal., 2009) using logistic regression over 10 runsof 10-fold cross-validation.
All values shown areblogger.com livejournal.comdownloadyear2004 2010# of Blogs 19320 11521# of Posts1 1.4 million 256,000# of words1 295 million 50 millionage 13?17 23?27 33?37 18?22 28?32 38?42size 8240 8086 2994 3518 5549 2454majoritybaseline43.8% (13-17) 48.2% (22-32)Table 4: Statistics for Schler et al?s data (blog-ger.com) vs our data (livejournal.com) 1 is approxi-mate amount.the averages of the accuracies from the 10 cross-validation runs and all results were comparedfor statistical significance using the t-test whereapplicable.We use logistic regression as our classifier be-cause it has been shown that logistic regressiontypically has lower asymptotic error than naiveBayes for multiple classification tasks as well asfor text classification (Ng and Jordan, 2002).We experimented with an SVM classifier andfound logistic regression to do slightly better.5.1 Age GroupsThe first experiment implements a variation ofthe experiment done by Schler et al (2006).The differences between the two datasets areshown in Tables 4.
The experiment looks atthree age groups containing a 5-year gap be-tween each group.
Intermediate years were notincluded to provide clear differentiation betweenthe groups because many of the blogs have beenactive for several years and this will make it lesscommon for a blogger to have posts that fall intotwo age groups (Schler et al, 2006).We did not use the same age groups as Schleret al because very few blogs on LiveJournal, in2010, are in the 13-17 age group.
Many early de-mographic studies (Perseus Development, 2004;Herring et al, 2004) show teens as the dom-inant age group in all blogs.
However, morerecent studies (Nowson and Oberlander, 2006;Lenhart et al, 2010) show that less teens blog.Furthermore, an early study on the LiveJournal768Figure 3: Style vs Content: Accuracy from 1975-1988 for Style (Online-Behavior+Lexical-Stylistic)vs Content (BOW)demographic (Kumar et al, 2004) reported that28.6% of blogs are written by bloggers betweenthe ages 13-18 whereas based on the current de-mographic statistics, in 20102, only 6.96% ofblogs are written by that age group and thenumber of bloggers in the 31-36 age group in-creased from 3.9% to 12.08%.
We chose the laterage groups because this study is based on blogsupdated in 2009-10 which is 5-6 years later andthus, the 13-17 age group is now 18-22 and soon.We use style-based (lexical-stylistic) andcontent-based features (BOW, interests) tomimic Schler et al?s experiment as closely aspossible and also experimented with addingonline-behavior features.
Our experiment withstyle-based and content-based features had anaccuracy of 57%.
However, when we addedonline-behavior, we increased our accuracy to67%.
A more detailed look at the better resultsshow that our accuracies are consistently 7%lower than the original work but we have similarfindings; 18-22s are distinguishable from 38-42swith accuracy of 94.5%, and 18-22s are distin-guishable from 28-32s with accuracy of 80.5%.However, many 38-42s are misclassified as 28-32s with an accuracy of 72.1%, yielding overallaccuracy of 67%.
Due to our findings, we believethat adding online-behavior features to Schler etal.
?s dataset would improve their results as well.2http://www.livejournal.com/stats.bml5.2 Social Media and Generation YIn the first experiment we used the current ageof a blogger based on when he wrote his lastpost.
However, the age of a person changes;someone who was in one age group now will bein a different age group in 5 years.
Furthermore,a blogger?s posts can fall into two categories de-pending on his age at the time.
Therefore, oursecond experiment looks at year of birth insteadof age, as that never changes.
In contrast toSchler et al?s experiment, our division does notintroduce a gap between age groups, we do bi-nary classification, and we use significantly lessdata.We approach age prediction as attempting toidentify a shift in writing style over a 14 yeartime span from birth years 1975-1988:For each year X = 1975-1988:?
get 1500 blogs (?33,000 posts) balanced acrossyears BEFORE X?
get 1500 blogs (?33,000 posts) balanced acrossyears IN/AFTER X?
Perform binary classification between blogs BE-FORE X and IN/AFTER XThe experiment focuses on the range of birthyears of bloggers from 1975-1888 to identify atwhat point in time, if any, shift(s) in writingstyle occurred amongst college-aged students ingeneration Y.
We were motivated to examinethese years due to the emergence of social me-dia technologies during that time.
Furthermore,research by Pew Internet (Zickuhr, 2010) hasfound that this generation (defined as 1977-1992 in their research) uses social networking,blogs, and instant messaging more than theirelders.
The experiment is balanced to ensurethat each birth year is evenly represented.
Webalance the data by choosing a blogger consec-utively from each birth year in the category, re-peating these sweeps through the category untilwe have obtained 1500 blogs.
We chose to use1500 blogs from each group because of process-ing power, time constraints, and the amount ofblogs needed to reasonably sample the age groupat each split.
Due to the extensive running time,we only examined variations of a combination of769Figure 4: Style and Content: Accuracy from 1975-1988 using BOW, Online Behavior, and Lexical-Stylistic featuresonline-behavior, lexical-stylistic, and BOW fea-tures.We found accuracy to increase as year of birthincreases in various feature experiments which isconsistent with the trends we found while exam-ining the distribution of features such as emoti-cons and lifetime posts in Figure 2.
We ex-perimented with style and content features andfound that both help improve accuracy.
Figure 3shows that content helps more than style, butstyle helps more as age decreases.
However, asshown in Figure 4, style and content combinedprovided the best results.
We found 5 years tohave significant improvement over all prior yearsfor p ?
.0005: 1977, 1979, and 1982-1984.Generation Y is considered the social me-dia generation, so we decided to examine howthe creation and/or popularity of social mediatechnologies compared to the years that had achange in writing style.
We looked at many pop-ular social media technologies such as weblogs,messaging, and social networking sites.
Figure 5compares the significant years 1977,1979, and1982-1984 against when each technology wascreated or became popular amongst college agedstudents.
We find that all the technologies hadan effect on one or more of those years.
AIM andweblogs coincide with the earlier shifts at 1977and 1979, SMS messaging coincide with boththe earlier and later shifts at 1979 and 1982,and the social networking sites, MySpace andFacebook coincide with the later shifts of 1982-Figure 5: The impact of social media technologies:The arrows correspond to the years that generationYers were college aged students.
The highlightedyears represent the significant years.
1Year it be-came popular (Urmann, 2009)1984.
On the other hand, web forums and Twit-ter each coincide with only one outlying yearwhich suggests that either they had less of animpact on writing style or, in the case of Twit-ter, the change has not yet been transferred toother writing forms.5.3 A Closer Look: 1979 and 1984Our final experiment provides a more detailedexplanation of the results using various featurecombinations when splitting pre- and post- so-cial media bloggers by year of birth at two ofthe significant years found in the previous sec-tion; 1979 and 1984.
The results for all of theexperiments described are shown in Table 5.We experimented against two baselines, on-line behavior and interests.
We chose these twofeatures as baselines because they are both easyto generate and not lexical in nature.
We foundthat we were able to exceed the baselines sig-nificantly using a simple bag-of-words (BOW)approach.
This means the BOW does a betterjob of picking topics than interests.
We foundthat including all 17 features did not do well, butwe were able to get good results using a subsetof the lexical features.
We found the best re-sults to have an accuracy of 79.96% and 81.57%for 1979 and 1984 respectively using BOW, in-terests, online behavior, and all lexical-stylisticfeatures.In addition, we show accuracy without in-terests since they are not always available.770Experiment 1979 1984Online-Behavior 59.66 61.61Interests 70.22 74.61Lexical-Stylistic 65.382 67.282Slang+Emoticons+Acronyms 60.572 62.102Online-Behavior + Lexical-Stylistic67.162 71.312Collocations + Syntax Colloca-tions53.471 73.452POS-Collocations + POS-Syntax Collocations55.541 74.002BOW 75.26 77.76BOW+Online-Behavior 76.39 79.22BOW + Online-Behavior +Lexical-Stylistic77.45 80.88BOW + Online-Behavior +Lexical-Stylistic + Syntax Collo-cations74.8 80.36BOW + Online-Behavior+ Lexical-Stylistic + POS-Collocations + POS SyntaxCollocations74.73 80.54Online-Behavior + Interests +Lexical-Stylistic74.39 77.20BOW + Online-Behavior + In-terests + Lexical-Stylistic79.96 81.57All Features 71.26 74.072Table 5: Feature Accuracy.
The top portion refers tothe baselines.
The best accuracies are shown in bold.Unless otherwise marked, all accuracies are statisti-cally significant at p<=.0005 for both baselines.
1not statistically significant over Online-Behavior andInterests.
2 not statistically significant over Interests.BOW, online-behavior, and lexical-stylistic fea-tures combined did best achieving accuracy of77.45% and 80.88% in 1979 and 1984 respec-tively.
This indicates that our classificationmethod could work well on blogs from any web-site.
It is interesting to note that colloca-tions and POS-collocations were useful, but onlywhen we use 1984 as the split which implies thatbloggers born in 1984 and later are more homo-geneous.6 Conclusion and Future WorkWe have shown that it is possible to predict theage group of a person based on style, content,and online behavior features with good accu-racy; these are all features that are availablein any blog.
While features representing writ-ing practices that emerged with social media(e.g., capitalized words, abbreviations, slang)do not significantly impact age prediction ontheir own, these features have a clear change ofvalue across time, with post-social media blog-gers using them more often.
We found thatthe birth years that had a significant changein writing style corresponded to the birth datesof college-aged students at the time of the cre-ation/popularity of social media technologies,AIM, SMS text messaging, weblogs, Facebookand MySpace.In the future we plan on using age and othermetadata to improve results in larger tasks suchas identifying opinion, persuasion and powerby targeting our approach in those tasks tothe identified age of the person.
Another ap-proach that we will experiment with is the useof ranking, regression, and/or clustering to cre-ate meaningful age groups.7 AcknowledgementsThis research was funded by the Office of theDirector of National Intelligence (ODNI), In-telligence Advanced Research Projects Activity(IARPA), through the U.S. Army Research Lab.All statements of fact, opinion or conclusionscontained herein are those of the authors andshould not be construed as representing the of-ficial views or policies of IARPA, the ODNI orthe U.S. Government.ReferencesShlomo Argamon, Moshe Koppel, Jonathan Fine,and Anat Rachel Shimoni.
2003.
Gender, genre,and writing style in formal written texts.
TEXT,23:321?346.John D. Burger and John C. Henderson.
2006.
Anexploration of observable features related to blog-ger age.
In AAAI Spring Symposia.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating typeddependency parses from phrase structure parses.In In LREC 2006.Sumit Goswami, Sudeshna Sarkar, and MayurRustagi.
2009.
Stylometric analysis of bloggers?771age and gender.
In International AAAI Confer-ence on Weblogs and Social Media.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H. Witten.2009.
The weka data mining software: An update.Susan C. Herring and John C. Paolillo.
2006.
Gen-der and genre variation in weblogs.
Journal ofSociolinguistics, 10(4):439?459.Susan C. Herring, L.A. Scheidt, S. Bonus, andE.
Wright.
2004.
Bridging the gap: A genre anal-ysis of weblogs.
In Proceedings of the 37th HawaiiInternational Conference on System Sciences.Dan Klein and Christopher D. Manning.
2003a.
Ac-curate unlexicalized parsing.
In Proceedings of the41st Annual Meeting of the Association for Com-putational Linguistics, pages 423?430.Dan Klein and Christopher D. Manning.
2003b.
Fastexact inference with a factored model for naturallanguage parsing.
In Advances in Neural Informa-tion Processing Systems, volume 15.
MIT Press.Ravi Kumar, Jasmine Novak, Prabhakar Raghavan,and Andrew Tomkins.
2004.
Structure and evolu-tion of blogspace.
Commun.
ACM, 47:35?39, De-cember.Amanda Lenhart, Kristen Purcell, Aaron Smith, andKathryn Zickuhr.
2010.
Social media and youngadults.Ian Mackinnon.
2006.
Age and geographic inferencesof the livejournal social network.
In In StatisticalNetwork Analysis Workshop.Andrew Y Ng and Michael I Jordan.
2002.
On dis-criminative vs. generative classifiers: A compari-son of logistic regression and naive bayes.
NeuralInformation Processing Systems, 2:841?848.Scott Nowson and Jon Oberlander.
2006.
The iden-tity of bloggers: Openness and gender in personalweblogs.James W Pennebaker and Lori D Stone.
2003.Words of wisdom: language use over the life span.J Pers Soc Psychol, 85(2):291?301.J.W.
Pennebaker, R.E.
Booth, and M.E.
Fran-cis.
2007.
Linguistic inquiry and word count:Liwc2007 ?
operator?s manual.
Technical report,LIWC, Austin, TX.Perseus Development.
2004.
The blogging iceberg:Of 4.12 million hosted weblogs, most little seenand quickly abandoned.
Technical report, PerseusDevelopment.R.W.
Robins, K. H. Trzesniewski, J.L.
Tracy, S.DGosling, and J Potter.
2002.
Global self-esteemacross the lifespan.
Psychology and Aging, 17:423?434.Gerard Salton and Christopher Buckley.
1988.Term-weighting approaches in automatic text re-trieval.
In Information Processing and Manage-ment, pages 513?523.J.
Schler, M. Koppel, S. Argamon, and J. Pen-nebaker.
2006.
Effects of age and gender on blog-ging.
In AAAI Spring Symposium on Computa-tional Approaches for Analyzing Weblogs.Frank Smadja.
1993.
Retrieving collocations fromtext: Xtract.
Computational Linguistics, 19:143?177.Jenny Tam and Craig H. Martell.
2009.
Age detec-tion in chat.
In Proceedings of the 2009 IEEE In-ternational Conference on Semantic Computing,ICSC ?09, pages 33?39, Washington, DC, USA.IEEE Computer Society.David H. Urmann.
2009.
The history of text mes-saging.Xiang Yan and Ling Yan.
2006.
Gender classificationof weblog authors.
In AAAI Spring SymposiumSeries on Computation Approaches to AnalyzingWeblogs, pages 228?230.Kathryn Zickuhr.
2010.
Generations 2010.772
