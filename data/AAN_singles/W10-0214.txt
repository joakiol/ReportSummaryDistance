Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 116?124,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsRecognizing Stances in Ideological On-Line DebatesSwapna SomasundaranDept.
of Computer ScienceUniversity of PittsburghPittsburgh, PA 15260swapna@cs.pitt.eduJanyce WiebeDept.
of Computer Science andThe Intelligent Systems ProgramUniversity of PittsburghPittsburgh, PA 15260wiebe@cs.pitt.eduAbstractThis work explores the utility of sentiment andarguing opinions for classifying stances in ide-ological debates.
In order to capture arguingopinions in ideological stance taking, we con-struct an arguing lexicon automatically froma manually annotated corpus.
We build su-pervised systems employing sentiment and ar-guing opinions and their targets as features.Our systems perform substantially better thana distribution-based baseline.
Additionally,by employing both types of opinion features,we are able to perform better than a unigram-based system.1 IntroductionIn this work, we explore if and how ideologi-cal stances can be recognized using opinion analy-sis.
Following (Somasundaran and Wiebe, 2009),stance, as used in this work, refers to an overall po-sition held by a person toward an object, idea orproposition.
For example, in a debate ?Do you be-lieve in the existence of God?,?
a person may take afor-existence of God stance or an against existenceof God stance.
Similarly, being pro-choice, believ-ing in creationism, and supporting universal health-care are all examples of ideological stances.Online web forums discussing ideological and po-litical hot-topics are popular.1 In this work, we are1http://www.opposingviews.com,http://wiki.idebate.org, http://www.createdebate.com andhttp://www.forandagainst.com are examples of such debatingwebsites.interested in dual-sided debates (there are two pos-sible polarizing sides that the participants can take).For example, in a healthcare debate, participants cantake a for-healthcare stance or an against-healthcarestance.
Participants generally pick a side (the web-sites provide a way for users to tag their stance)and post an argument/justification supporting theirstance.Personal opinions are clearly important in ideo-logical stance taking, and debate posts provide out-lets for expressing them.
For instance, let us con-sider the following snippet from a universal health-care debate.
Here the writer is expressing a nega-tive sentiment2 regarding the government (the opin-ion spans are highlighted in bold and their targets,what the opinions are about, are highlighted in ital-ics).
(1) Government is a disease pretending to be itsown cure.
[side: against healthcare]The writer?s negative sentiment is directed towardthe government, the initiator of universal healthcare.This negative opinion reveals his against-healthcarestance.We observed that arguing, a less well exploredtype of subjectivity, is prominently manifested inideological debates.
As used in this work, arguing isa type of linguistic subjectivity, where a person is ar-guing for or against something or expressing a beliefabout what is true, should be true or should be done2As used in this work, sentiment is a type of linguistic sub-jectivity, specifically positive and negative expressions of emo-tions, judgments, and evaluations (Wilson and Wiebe, 2005;Wilson, 2007; Somasundaran et al, 2008).116in his or her view of the world (Wilson and Wiebe,2005; Wilson, 2007; Somasundaran et al, 2008).For instance, let us consider the following snippetfrom a post supporting an against-existence of Godstance.
(2) Obviously that hasn?t happened, and to becompletely objective (as all scientists shouldbe) we must lean on the side of greatest evi-dence which at the present time is for evolu-tion.
[side: against the existence of God]In supporting their side, people not only expresstheir sentiments, but they also argue about what istrue (e.g., this is prominent in the existence of Goddebate) and about what should or should not be done(e.g., this is prominent in the healthcare debate).In this work, we investigate whether sentimentand arguing expressions of opinion are useful forideological stance classification.
For this, we ex-plore ways to capture relevant opinion informationas machine learning features into a supervised stanceclassifier.
While there is a large body of resourcesfor sentiment analysis (e.g., the sentiment lexiconfrom (Wilson et al, 2005)), arguing analysis doesnot seem to have a well established lexical resource.In order to remedy this, using a simple automatic ap-proach and a manually annotated corpus,3 we con-struct an arguing lexicon.
We create features calledopinion-target pairs, which encode not just the opin-ion information, but also what the opinion is about,its target.
Systems employing sentiment-based andarguing-based features alone, or both in combina-tion, are analyzed.
We also take a qualitative lookat features used by the learners to get insights aboutthe information captured by them.We perform experiments on four different ideo-logical domains.
Our results show that systems us-ing both sentiment and arguing features can performsubstantially better than a distribution-based base-line and marginally better than a unigram-based sys-tem.
Our qualitative analysis suggests that opinionfeatures capture more insightful information thanusing words alone.The rest of this paper is organized as follows: Wefirst describe our ideological debate data in Section2.
We explain the construction of our arguing lexi-con in Section 3 and our different systems in Section3MPQA corpus available at http://www.cs.pitt.edu/mpqa.4.
Experiments, results and analyses are presented inSection 5.
Related work is in Section 6 and conclu-sions are in Section 7.2 Ideological DebatesPolitical and ideological debates on hot issues arepopular on the web.
In this work, we analyze the fol-lowing domains: Existence of God, Healthcare, GunRights, Gay Rights, Abortion and Creationism.
Ofthese, we use the first two for development and theremaining four for experiments and analyses.
Eachdomain is a political/ideological issue and has twopolarizing stances: for and against.Table 2 lists the domains, examples of debate top-ics within each domain, the specific sides for eachdebate topic, and the domain-level stances that cor-respond to these sides.
For example, consider theExistence of God domain in Table 2.
The twostances in this domain are for-existence of God andagainst-existence of God.
?Do you believe in God?,a specific debate topic within this domain, has twosides: ?Yes!!?
and ?No!!?.
The former correspondsto the for-existence of God stance and the latter mapsto the against-existence of God stance.
The situa-tion is different for the debate ?God Does Not Ex-ist?.
Here, side ?against?
corresponds to the for-existence of God stance, and side ?for?
correspondsto the against-existence of God stance.In general, we see in Table 2 that, while specificdebate topics may vary, in each case the two sidesfor the topic correspond to the domain-level stances.We download several debates for each domain andmanually map debate-level stances to the stancesfor the domain.
Table 2 also reports the numberof debates, and the total number of posts for eachdomain.
For instance, we collect 16 different de-bates in the healthcare domain which gives us a totalof 336 posts.
All debate posts have user-reporteddebate-level stance tags.2.1 ObservationsPreliminary inspection of development data gave usinsights which shaped our approach.
We discusssome of our observations in this section.Arguing OpinionWe found that arguing opinions are prominentwhen people defend their ideological stances.
We117Domain/Topics stance1 stance2Healthcare (16 debates, 336 posts) for againstShould the US have universal health-careYes NoDebate: Public insurance option inUS health carePro ConExistence of God (7 debates, 486posts)for againstDo you believe in God Yes!!
No!
!God Does Not Exist against forGun Rights (18 debates, 566 posts) for againstShould Guns Be Illegal against forDebate: Right to bear arms in the US Yes NoGay Rights (15 debates, 1186 posts) for againstAre people born gay Yes NoIs homosexuality a sin No YesAbortion (13 debates, 618 posts) for againstShould abortion be legal Yes NoShould south Dakota pass the abor-tion banNo YesCreationism (15 debates, 729 posts) for againstEvolution Is A False Idea for againstHas evolution been scientificallyprovedIt hasnotIt hasTable 1: Examples of debate topics and their stancessaw an instance of this in Example 2, where the par-ticipant argues against the existence of God.
He ar-gues for what (he believes) is right (should be), andis imperative (we must).
He employs ?Obviously?to draw emphasis and then uses a superlative con-struct (greatest) to argue for evolution.Example 3 below illustrates arguing in a health-care debate.
The spans most certainly believe andhas or must do reveal arguing (ESSENTIAL, IM-PORTANT are sentiments).
(3) ...
I most certainly believe that there aresome ESSENTIAL, IMPORTANT thingsthat the government has or must do [side: forhealthcare]Observe that the text spans revealing arguing canbe a single word or multiple words.
This is differ-ent from sentiment expressions that are more oftensingle words.Opinion TargetsAs mentioned previously, a target is what anopinion is about.
Targets are vital for determiningstances.
Opinions by themselves may not be as in-formative as the combination of opinions and tar-gets.
For instance, in Example 1 the writer supportsan against-healthcare stance using a negative senti-ment.
There is a negative sentiment in the examplebelow (Example 4) too.
However, in this case thewriter supports a for-healthcare stance.
It is by un-derstanding what the opinion is about, that we canrecognize the stance.
(4) Oh, the answer is GREEDY insurance com-panies that buy your Rep & Senator.
[side: forhealthcare]We also observed that targets, or in general itemsthat participants from either side choose to speakabout, by themselves may not be as informative asopinions in conjunction with the targets.
For in-stance, Examples 1 and 3 both speak about the gov-ernment but belong to opposing sides.
Understand-ing that the former example is negative toward thegovernment and the latter has a positive arguingabout the government helps us to understand the cor-responding stances.Examples 1, 3 and 4 also illustrate that thereare a variety of ways in which people supporttheir stances.
The writers express opinions aboutgovernment, the initiator of healthcare and insur-ance companies, and the parties hurt by governmentrun healthcare.
Participants group government andhealthcare as essentially the same concept, whilethey consider healthcare and insurance companiesas alternative concepts.
By expressing opinions re-garding a variety of items that are same or alternativeto main topic (healthcare, in these examples), theyare, in effect, revealing their stance (Somasundaranet al, 2008).3 Constructing an Arguing LexiconArguing is a relatively less explored category in sub-jectivity.
Due to this, there are no available lexiconswith arguing terms (clues).
However, the MPQAcorpus (Version 2) is annotated with arguing sub-jectivity (Wilson and Wiebe, 2005; Wilson, 2007).There are two arguing categories: positive arguingand negative arguing.
We use this corpus to gener-ate a ngram (up to trigram) arguing lexicon.The examples below illustrate MPQA arguing an-notations.
Examples 5 and 7 illustrate positive argu-118ing annotations and Example 6 illustrates negativearguing.
(5) Iran insists its nuclear program is purelyfor peaceful purposes.
(6) Officials in Panama denied that Mr. Chavezor any of his family members had asked forasylum.
(7) Putin remarked that the events in Chechnia?could be interpreted only in the contextof the struggle against international terror-ism.
?Inspection of these text spans reveal that arguing an-notations can be considered to be comprised of twopieces of information.
The first piece of informationis what we call the arguing trigger expression.
Thetrigger is an indicator that an arguing is taking place,and is the primary component that anchors the argu-ing annotation.
The second component is the ex-pression that reveals more about the argument, andcan be considered to be secondary for the purposesof detecting arguing.
In Example 5, ?insists?, by it-self, conveys enough information to indicate that thespeaker is arguing.
It is quite likely that a sentenceof the form ?X insists Y?
is going to be an arguingsentence.
Thus, ?insists?
is an arguing trigger.Similarly, in Example 6, we see two arguing trig-gers: ?denied?
and ?denied that?.
Each of these canindependently act as arguing triggers (For example,in the constructs ?X denied that Y?
and ?X deniedY?).
Finally, in Example 7, the arguing annotationhas the following independent trigger expressions?could be * only?, ?could be?
and ?could?.
The wildcard in the first trigger expression indicates that therecould be zero or more words in its place.Note that MPQA annotations do not provide thisprimary/secondary distinction.
We make this dis-tinction to create general arguing clues such as ?in-sist?.
Table 3 lists examples of arguing annotationsfrom the MPQA corpus and what we consider astheir arguing trigger expressions.Notice that trigger words are generally at the be-ginning of the annotations.
Most of these are uni-grams, bigrams or trigrams (though it is possible forthese to be longer, as seen in Example 7).
Thus, wecan create a lexicon of arguing trigger expressionsPositive arguing annotations Trigger Expr.actually reflects Israel?s determination ... actuallyam convinced that improving ... am convincedbear witness that Mohamed is his ... bear witnesscan only rise to meet it by making ... can onlyhas always seen usama bin ladin?s ... has alwaysNegative Arguing Annotations Trigger Expr.certainly not a foregone conclusion certainly nothas never been any clearer has nevernot too cool for kids not toorather than issuing a letter of ... rather thanthere is no explanation for there is noTable 2: Arguing annotations from the MPQA corpus andtheir corresponding trigger expressionsby extracting the starting n-grams from the MPQAannotations.
The process of creating the lexicon isas follows:1.
Generate a candidate Set from the annotationsin the corpus.
Three candidates are extractedfrom the stemmed version of each annotation:the first word, the bigram starting at the firstword, and the trigram starting at the first word.For example, if the annotation is ?can only riseto meet it by making some radical changes?,the following candidates are extracted from it:?can?, ?can only?
and ?can only rise?.2.
Remove the candidates that are present in thesentiment lexicon from (Wilson et al, 2005) (asthese are already accounted for in previous re-search).
For example, ?actually?, which is atrigger word in Table 3, is a neutral subjectivityclue in the lexicon.3.
For each candidate in the candidate Set,find the likelihood that it is a reliable indi-cator of positive or negative arguing in theMPQA corpus.
These are likelihoods of theform: P (positive arguing|candidate) =#candidate is in a positive arguing span#candidate is in the corpusand P (negative arguing|candidate) =#candidate is in a negative arguing span#candidate is in the corpus4.
Make a lexicon entry for each candidate con-sisting of the stemmed text and the two proba-bilities described above.This process results in an arguing lexiconwith 3762 entries, where 3094 entries have119P (positive arguing|candidate) > 0; and 668entries have P (negative arguing|candidate) > 0.Table 3 lists select interesting expressions from thearguing lexicon.Entries indicative of Positive Arguingbe important to, would be better, would need to, be just the, bethe true, my opinion, the contrast, show the, prove to be, onlyif, on the verge, ought to, be most, youve get to, render, man-ifestation, ironically, once and for, no surprise, overwhelmingevidence, its clear, its clear that, it be evident, it be extremely,it be quite, it would thereforeEntries indicative of Negative Arguingbe not simply, simply a, but have not, can not imagine, we dontneed, we can not do, threat against, ought not, nor will, neveragain, far from be, would never, not completely, nothing will,inaccurate and, inaccurate and, find no, no time, deny thatTable 3: Examples of positive argu-ing (P (positive arguing|candidate) >P (negative arguing|candidate)) and negativearguing (P (negative arguing|candidate) >P (positive arguing|candidate))from the arguinglexicon4 Features for Stance ClassificationWe construct opinion target pair features, which areunits that capture the combined information aboutopinions and targets.
These are encoded as binaryfeatures into a standard machine learning algorithm.4.1 Arguing-based FeaturesWe create arguing features primarily from our ar-guing lexicon.
We construct additional arguing fea-tures using modal verbs and syntactic rules.
The lat-ter are motivated by the fact that modal verbs suchas ?must?, ?should?
and ?ought?
are clear cases ofarguing, and are often involved in simple syntacticpatterns with clear targets.4.1.1 Arguing-lexicon FeaturesThe process for creating features for a post usingthe arguing lexicon is simple.
For each sentence inthe post, we first determine if it contains a positive ornegative arguing expression by looking for trigram,bigram and unigram matches (in that order) with thearguing lexicon.
We prevent the same text span frommatching twice ?
once a trigram match is found, asubstring bigram (or unigram) match with the sametext span is avoided.
If there are multiple arguing ex-pression matches found within a sentence, we deter-mine the most prominent arguing polarity by addingup the positive arguing probabilities and negative ar-guing probabilities (provided in the lexicon) of allthe individual expressions.Once the prominent arguing polarity is deter-mined for a sentence, the prefix ap (arguing positive)or an (arguing negative) is attached to all the contentwords in that sentence to construct opinion-targetfeatures.
In essence, all content words (nouns, verbs,adjectives and adverbs) in the sentence are assumedto be the target.
Arguing features are denoted as ap-target (positive arguing toward target) and an-target(negative arguing toward target).4.1.2 Modal Verb Features for ArguingModals words such as ?must?
and ?should?
areusually good indicators of arguing.
This is a smallclosed set.
Also, the target (what the arguing isabout) is syntactically associated with the modalword, which means it can be relatively accuratelyextracted by using a small set of syntactic rules.For every modal detected, three features are cre-ated by combining the modal word with its subjectand object.
Note that all the different modals arereplaced by ?should?
while creating features.
Thishelps to create more general features.
For exam-ple, given a sentence ?They must be available toall people?, the method creates three features ?theyshould?, ?should available?
and ?they should avail-able?.
These patterns are created independently ofthe arguing lexicon matches, and added to the fea-ture set for the post.4.2 Sentiment-based FeaturesSentiment-based features are created independent ofarguing features.
In order to detect sentiment opin-ions, we use a sentiment lexicon (Wilson et al,2005).
In addition to positive (+) and negative (?
)words, this lexicon also contains subjective wordsthat are themselves neutral (=) with respect to po-larity.
Examples of neutral entries are ?absolutely?,?amplify?, ?believe?, and ?think?.We find the sentiment polarity of the entire sen-tence and assign this polarity to each content word inthe sentence (denoted, for example, as target+).
Inorder to detect the sentence polarity, we use the Vote120and Flip algorithm from Choi and Cardie (2009).This algorithm essentially counts the number of pos-itive, negative and neutral lexicon hits in a given ex-pression and accounts for negator words.
The algo-rithm is used as is, except for the default polarityassignment (as we do not know the most prominentpolarity in the corpus).
Note that the Vote and Flipalgorithm has been developed for expressions but weemploy it on sentences.
Once the polarity of a sen-tence is determined, we create sentiment features forthe sentence.
This is done for all sentences in thepost.5 ExperimentsExperiments are carried out on debate posts from thefollowing four domains: Gun Rights, Gay Rights,Abortion, and Creationism.
For each domain, a cor-pus with equal class distribution is created as fol-lows: we merge all debates and sample instances(posts) from the majority class to obtain equal num-bers of instances for each stance.
This gives us atotal of 2232 posts in the corpus: 306 posts for theGun Rights domain, 846 posts for the Gay Rightsdomain, 550 posts for the Abortion domain and 530posts for the Creationism domain.Our first baseline is a distribution-based baseline,which has an accuracy of 50%.
We also constructUnigram, a system based on unigram content infor-mation, but no explicit opinion information.
Un-igrams are reliable for stance classification in po-litical domains (as seen in (Lin et al, 2006; Kimand Hovy, 2007)).
Intuitively, evoking a particulartopic can be indicative of a stance.
For example,a participant who chooses to speak about ?child?and ?life?
in an abortion debate is more likely froman against-abortion side, while someone speakingabout ?woman?, ?rape?
and ?choice?
is more likelyfrom a for-abortion stance.We construct three systems that use opinion in-formation: The Sentiment system that uses only thesentiment features described in Section 4.2, the Ar-guing system that uses only arguing features con-structed in Section 4.1, and the Arg+Sent systemthat uses both sentiment and arguing features.All systems are implemented using a standard im-plementation of SVM in the Weka toolkit (Hall etal., 2009).
We measure performance using the accu-racy metric.5.1 ResultsTable 4 shows the accuracy averaged over 10 foldcross-validation experiments for each domain.
Thefirst row (Overall) reports the accuracy calculatedover all 2232 posts in the data.Overall, we notice that all the supervised systemsperform better than the distribution-based baseline.Observe that Unigram has a better performance thanSentiment.
The good performance of Unigram indi-cates that what participants choose to speak about isa good indicator of ideological stance taking.
Thisresult confirms previous researchers?
intuition that,in general, political orientation is a function of ?au-thors?
attitudes over multiple issues rather than pos-itive or negative sentiment with respect to a sin-gle issue?
(Pang and Lee, 2008).
Nevertheless, theArg+Sent system that uses both arguing and senti-ment features outperforms Unigram.We performed McNemar?s test to measure the dif-ference in system behaviors.
The test was performedon all pairs of supervised systems using all 2232posts.
The results show that there is a significant dif-ference between the classification behavior of Uni-gram and Arg+Sent systems (p < 0.05).
The dif-ference between classifications of Unigram and Ar-guing approaches significance (p < 0.1).
There isno significant difference in the behaviors of all othersystem pairs.Moving on to detailed performance in each do-main, we see that Unigram outperforms Sentimentfor all domains.
Arguing and Arg+Sent outperformUnigram for three domains (Guns, Gay Rights andAbortion), while the situation is reversed for one do-main (Creationism).
We carried out separate t-testsfor each domain, using the results from each test foldas a data point.
Our results indicate that the perfor-mance of Sentiment is significantly different fromall other systems for all domains.
However there isno significant difference between the performance ofthe remaining systems.5.2 AnalysisOn manual inspection of the top features used bythe classifiers for discriminating the stances, wefound that there is an overlap between the contentwords used by Unigram, Arg+Sent and Arguing.
For121Domain (#posts) Distribution Unigram Sentiment Arguing Arg+SentOverall (2232) 50 62.50 55.02 62.59 63.93Guns Rights (306) 50 66.67 58.82 69.28 70.59Gay Rights (846) 50 61.70 52.84 62.05 63.71Abortion (550) 50 59.1 54.73 59.46 60.55Creationism (530) 50 64.91 56.60 62.83 63.96Table 4: Accuracy of the different systemsexample, in the Gay Rights domain, ?understand?and ?equal?
are amongst the top features in Uni-gram, while ?ap-understand?
(positive arguing for?understand?)
and ?ap-equal?
are top features forArg+Sent.However, we believe that Arg+Sent makes finerand more insightful distinctions based on polarity ofopinions toward the same set of words.
Table 5 listssome interesting features in the Gay Rights domainfor Unigram and Arg+Sent.
Depending on whetherpositive or negative attribute weights were assignedby the SVM learner, the features are either indicativeof for-gay rights or against-gay rights.
Even thoughthe features for Unigram are intuitive, it is not ev-ident if a word is evoked as, for example, a pitch,concern, or denial.
Also, we do not see a clear sep-aration of the terms (for e.g., ?bible?
is an indicatorfor against-gay rights while ?christianity?
is an indi-cator for for-gay rights)The arguing features from Arg+Sent seem tobe relatively more informative ?
positive arguingabout ?christianity?, ?corinthians?, ?mormonism?and ?bible?
are all indicative of against-gay rightsstance.
These are indeed beliefs and concerns thatshape an against-gay rights stance.
On the otherhand, negative arguings with these same words de-note a for-gay rights stance.
Presumably, these oc-cur in refutations of the concerns influencing the op-posite side.
Likewise, the appeal for equal rightsfor gays is captured positive arguing about ?liberty?,?independence?, ?pursuit?
and ?suffrage?.Interestingly, we found that our features also cap-ture the ideas of opinion variety and same and alter-native targets as defined in previous research (So-masundaran et al, 2008) ?
in Table 5, items thatare similar (e.g., ?christianity?
and ?corinthians?
)have similar opinions toward them for a given stance(for e.g., ap-christianity and ap-corinthians belongto against-gay rights stance while an-christianity andan-corinthians belong to for-gay rights stance).
Ad-ditionally, items that are alternatives (e.g.
?gay?
and?heterosexuality?)
have opposite polarities associ-ated with them for a given stance, that is, positivearguing for ?heterosexuality?
and negative arguingfor ?gay?
reveal the the same stance.In general, unigram features associate the choiceof topics with the stances, while the arguing featurescan capture the concerns, defenses, appeals or de-nials that signify each side (though we do not ex-plicitly encode these fine-grained distinctions in thiswork).
Interestingly, we found that sentiment fea-tures in Arg+Sent are not as informative as the argu-ing features discussed above.6 Related WorkGenerally, research in identifying political view-points has employed information from words in thedocument (Malouf and Mullen, 2008; Mullen andMalouf, 2006; Grefenstette et al, 2004; Laver et al,2003; Martin and Vanberg, 2008; Lin et al, 2006;Lin, 2006).
Specifically, Lin et al observe that peo-ple from opposing perspectives seem to use wordsin differing frequencies.
On similar lines, Kim andHovy (2007) use unigrams, bigrams and trigrams forelection prediction from forum posts.
In contrast,our work specifically employs sentiment-based andarguing-based features to perform stance classifica-tion in political debates.
Our experiments are fo-cused on determining how different opinion expres-sions reinforce an overall political stance.
Our re-sults indicate that while unigram information is re-liable, further improvements can be achieved in cer-tain domains using our opinion-based approach.
Ourwork is also complementary to that by Greene andResnik (2009), which focuses on syntactic packag-ing for recognizing perspectives.122For Gay Rights Against Gay RightsUnigram Featuresconstitution, fundamental, rights, suffrage, pursuit, discrimina-tion, government, happiness, shame, wed, gay, heterosexual-ity, chromosome, evolution, genetic, christianity, mormonism,corinthians, procreate, adoptpervert, hormone, liberty, fidelity, naval, retarded, orientation, pri-vate, partner, kingdom, bible, sin, bigotArguing Features from Arg+Sentap-constitution, ap-fundamental, ap-rights, ap-hormone,ap-liberty, ap-independence, ap-suffrage, ap-pursuit, ap-discrimination, an-government, ap-fidelity, ap-happiness,an-pervert, an-naval, an-retarded, an-orientation, an-shame,ap-private, ap-wed, ap-gay, an-heterosexuality, ap-partner,ap-chromosome, ap-evolution, ap-genetic, an-kingdom, an-christianity, an-mormonism, an-corinthians, an-bible, an-sin,an-bigot, an-procreate, ap-adopt,an-constitution, an-fundamental, an-rights, an-hormone,an-liberty, an-independence, an-suffrage, an-pursuit, an-discrimination, ap-government, an-fidelity, an-happiness,ap-pervert, ap-naval, ap-retarded, ap-orientation, ap-shame,an-private, an-wed, an-gay, ap-heterosexuality, an-partner,an-chromosome, an-evolution, an-genetic, ap-kingdom, ap-christianity, ap-mormonism, ap-corinthians, ap-bible, ap-sin,ap-bigot, ap-procreate, an-adoptTable 5: Examples of features associated with the stances in Gay Rights domainDiscourse-level participant relation, that is,whether participants agree/disagree has been founduseful for determining political side-taking (Thomaset al, 2006; Bansal et al, 2008; Agrawal etal., 2003; Malouf and Mullen, 2008).
Agree-ment/disagreement relations are not the main focusof our work.
Other work in the area of polarizing po-litical discourse analyze co-citations (Efron, 2004)and linking patterns (Adamic and Glance, 2005).
Incontrast, our focus is on document content and opin-ion expressions.Somasundaran et al (2007b) have noted the use-fulness of the arguing category for opinion QA.
Ourtasks are different; they use arguing to retrieve rele-vant answers, but not distinguish stances.
Our workis also different from related work in the domain ofproduct debates (Somasundaran and Wiebe, 2009)in terms of the methodology.Wilson (2007) manually adds positive/negativearguing information to entries in a sentiment lexi-con from (Wilson et al, 2005) and uses these as ar-guing features.
Our arguing trigger expressions areseparate from the sentiment lexicon entries and arederived from a corpus.
Our n-gram trigger expres-sions are also different from manually created regu-lar expression-based arguing lexicon for speech data(Somasundaran et al, 2007a).7 ConclusionsIn this paper, we explore recognizing stances in ide-ological on-line debates.
We created an arguing lex-icon from the MPQA annotations in order to recog-nize arguing, a prominent type of linguistic subjec-tivity in ideological stance taking.
We observed thatopinions or targets in isolation are not as informativeas their combination.
Thus, we constructed opiniontarget pair features to capture this information.We performed supervised learning experimentson four different domains.
Our results show thatboth unigram-based and opinion-based systems per-form better than baseline methods.
We found that,even though our sentiment-based system is able toperform better than the distribution-based baseline,it does not perform at par with the unigram system.However, overall, our arguing-based system does aswell as the unigram-based system, and our systemthat uses both arguing and sentiment features obtainsfurther improvement.
Our feature analysis suggeststhat arguing features are more insightful than uni-gram features, as they make finer distinctions thatreveal the underlying ideologies.ReferencesLada A. Adamic and Natalie Glance.
2005.
The politicalblogosphere and the 2004 u.s. election: Divided theyblog.
In LinkKDD.Rakesh Agrawal, Sridhar Rajagopalan, RamakrishnanSrikant, and Yirong Xu.
2003.
Mining newsgroupsusing networks arising from social behavior.
In WWW.Mohit Bansal, Claire Cardie, and Lillian Lee.
2008.The power of negative thinking: Exploiting label dis-agreement in the min-cut classification framework.
In123Proceedings of the 22nd International Conference onComputational Linguistics (COLING-2008).Yejin Choi and Claire Cardie.
2009.
Adapting a polaritylexicon using integer linear programming for domain-specific sentiment classification.
In Proceedings ofthe 2009 Conference on Empirical Methods in Natu-ral Language Processing, pages 590?598, Singapore,August.
Association for Computational Linguistics.Miles Efron.
2004.
Cultural orientation: Classifyingsubjective documents by cocitation analysis.
In AAAIFall Symposium on Style and Meaning in Language,Art, and Music.Stephan Greene and Philip Resnik.
2009.
More thanwords: Syntactic packaging and implicit sentiment.
InProceedings of Human Language Technologies: The2009 Annual Conference of the North American Chap-ter of the Association for Computational Linguistics,pages 503?511, Boulder, Colorado, June.
Associationfor Computational Linguistics.Gregory Grefenstette, Yan Qu, James G. Shanahan, andDavid A. Evans.
2004.
Coupling niche browsers andaffect analysis for an opinion mining application.
InProceeding of RIAO-04, Avignon, FR.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H. Witten.2009.
The weka data mining software: An update.
InSIGKDD Explorations, Volume 11, Issue 1.Soo-Min Kim and Eduard Hovy.
2007.
Crystal: Ana-lyzing predictive opinions on the web.
In Proceedingsof the 2007 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning (EMNLP-CoNLL), pages1056?1064.Michael Laver, Kenneth Benoit, and John Garry.
2003.Extracting policy positions from political texts usingwords as data.
American Political Science Review,97(2):311?331.Wei-Hao Lin, Theresa Wilson, Janyce Wiebe, andAlexander Hauptmann.
2006.
Which side are youon?
Identifying perspectives at the document and sen-tence levels.
In Proceedings of the 10th Conference onComputational Natural Language Learning (CoNLL-2006), pages 109?116, New York, New York.Wei-Hao Lin.
2006.
Identifying perspectives at the doc-ument and sentence levels using statistical models.
InProceedings of the Human Language Technology Con-ference of the NAACL, Companion Volume: DoctoralConsortium, pages 227?230, New York City, USA,June.
Association for Computational Linguistics.Robert Malouf and Tony Mullen.
2008.
Taking sides:Graph-based user classification for informal online po-litical discourse.
Internet Research, 18(2).Lanny W. Martin and Georg Vanberg.
2008.
A ro-bust transformation procedure for interpreting politicaltext.
Political Analysis, 16(1):93?100.Tony Mullen and Robert Malouf.
2006.
A preliminaryinvestigation into sentiment analysis of informal po-litical discourse.
In AAAI 2006 Spring Symposiumon Computational Approaches to Analysing Weblogs(AAAI-CAAW 2006).Bo Pang and Lillian Lee.
2008.
Opinion mining andsentiment analysis.
Foundations and Trends in Infor-mation Retrieval, Vol.
2(1-2):pp.
1?135.Swapna Somasundaran and Janyce Wiebe.
2009.
Rec-ognizing stances in online debates.
In Proceedingsof the Joint Conference of the 47th Annual Meetingof the ACL and the 4th International Joint Conferenceon Natural Language Processing of the AFNLP, pages226?234, Suntec, Singapore, August.
Association forComputational Linguistics.Swapna Somasundaran, Josef Ruppenhofer, and JanyceWiebe.
2007a.
Detecting arguing and sentiment inmeetings.
In SIGdial Workshop on Discourse and Di-alogue, Antwerp, Belgium, September.Swapna Somasundaran, Theresa Wilson, Janyce Wiebe,and Veselin Stoyanov.
2007b.
Qa with attitude: Ex-ploiting opinion type analysis for improving questionanswering in on-line discussions and the news.
In In-ternational Conference on Weblogs and Social Media,Boulder, CO.Swapna Somasundaran, Janyce Wiebe, and Josef Rup-penhofer.
2008.
Discourse level opinion interpreta-tion.
In Proceedings of the 22nd International Con-ference on Computational Linguistics (Coling 2008),pages 801?808, Manchester, UK, August.Matt Thomas, Bo Pang, and Lillian Lee.
2006.
Get outthe vote: Determining support or opposition from con-gressional floor-debate transcripts.
In Proceedings ofthe 2006 Conference on Empirical Methods in NaturalLanguage Processing, pages 327?335, Sydney, Aus-tralia, July.
Association for Computational Linguistics.Theresa Wilson and Janyce Wiebe.
2005.
Annotatingattributions and private states.
In Proceedings of ACLWorkshop on Frontiers in Corpus Annotation II: Pie inthe Sky.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity in phrase-levelsentiment analysis.
In hltemnlp2005, pages 347?354,Vancouver, Canada.Theresa Wilson.
2007.
Fine-grained Subjectivity andSentiment Analysis: Recognizing the Intensity, Polar-ity, and Attitudes of private states.
Ph.D. thesis, Intel-ligent Systems Program, University of Pittsburgh.124
