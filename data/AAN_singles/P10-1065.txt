Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 631?639,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsOn Jointly Recognizing and Aligning Bilingual Named EntitiesYufeng Chen, Chengqing ZongInstitute of Automation, Chinese Academy of SciencesBeijing, China{chenyf,cqzong}@nlpr.ia.ac.cnKeh-Yih SuBehavior Design CorporationHsinchu, Taiwan, R.O.C.bdc.kysu@gmail.comAbstractWe observe that (1) how a given named en-tity (NE) is translated (i.e., either semanti-cally or phonetically) depends greatly on itsassociated entity type, and (2) entities withinan aligned pair should share the same type.Also, (3) those initially detected NEs are an-chors, whose information should be used togive certainty scores when selecting candi-dates.
From this basis, an integrated model isthus proposed in this paper to jointly identifyand align bilingual named entities betweenChinese and English.
It adopts a new map-ping type ratio feature (which is the propor-tion of NE internal tokens that are semanti-cally translated), enforces an entity type con-sistency constraint, and utilizes additionalmonolingual candidate certainty factors(based on those NE anchors).
The experi-ments show that this novel approach has sub-stantially raised the type-sensitive F-score ofidentified NE-pairs from 68.4% to 81.7%(42.1% F-score imperfection reduction) inour Chinese-English NE alignment task.1 IntroductionIn trans-lingual language processing tasks, suchas machine translation and cross-lingual informa-tion retrieval, named entity (NE) translation isessential.
Bilingual NE alignment, which linkssource NEs and target NEs, is the first step totrain the NE translation model.Since NE alignment can only be conducted af-ter its associated NEs have first been identified,the including-rate of the first recognition stagesignificantly limits the final alignment perform-ance.
To alleviate the above error accumulationproblem, two strategies have been proposed inthe literature.
The first strategy (Al-Onaizan andKnight, 2002; Moore, 2003; Feng et al, 2004;Lee et al, 2006) identifies NEs only on thesource side and then finds their correspondingNEs on the target side.
In this way, it avoids theNE recognition errors which would otherwise bebrought into the alignment stage from the targetside; however, the NE errors from the sourceside still remain.To further reduce the errors from the sourceside, the second strategy (Huang et al, 2003)expands the NE candidate-sets in both languagesbefore conducting the alignment, which is doneby treating the original results as anchors, andthen re-generating further candidates by enlarg-ing or shrinking those anchors' boundaries.
Ofcourse, this strategy will be in vain if the NE an-chor is missed in the initial detection stage.
Inour data-set, this strategy significantly raises theNE-pair type-insensitive including-rate 1  from83.9% to 96.1%, and is thus adopted in this paper.Although the above expansion strategy hassubstantially alleviated the error accumulationproblem, the final alignment accuracy is still notgood (type-sensitive F-score only 68.4%, as indi-cated in Table 2 in Section 4.2).
After havingexamined the data, we found that: (1) How agiven NE is translated, either semantically(called translation) or phonetically (called trans-literation), depends greatly on its associated en-tity type2.
The mapping type ratio, which is thepercentage of NE internal tokens which aretranslated semantically, can help with the recog-nition of the associated NE type; (2) Entitieswithin an aligned pair should share the same type,and this restriction should be integrated into NEalignment as a constraint; (3) Those initiallyidentified monolingual NEs can act as anchors togive monolingual candidate certainty scores1 Which is the percentage of desired NE-pairs that are in-cluded in the expanded set, and is the upper bound on NEalignment performance (regardless of NE types).2 The proportions of semantic translation, which denote theratios of semantically translated words among all the asso-ciated NE words, for person names (PER), location names(LOC), and organization names (ORG) approximates 0%,28.6%, and 74.8% respectively in Chinese-English nameentity list (2005T34) released by the Linguistic Data Con-sortium (LDC).
Since the title, such as ?sir?
and ?chairman?,is not considered as a part of person names in this corpus,PERs are all transliterated there.631(preference weightings) for the re-generated can-didates.Based on the above observation, a new jointmodel which adopts the mapping type ratio, en-forces the entity type consistency constraint, andalso utilizes the monolingual candidate certaintyfactors is proposed in this paper to jointly iden-tify and align bilingual NEs under an integratedframework.
This framework is decomposed intothree subtasks: Initial Detection, Expansion, andAlignment&Re-identification.
The Initial Detec-tion subtask first locates the initial NEs and theirassociated NE types inside both the Chinese andEnglish sides.
Afterwards, the Expansion subtaskre-generates the candidate-sets in both languagesto recover those initial NE recognition errors.Finally, the Alignment&Re-identification subtaskjointly recognizes and aligns bilingual NEs viathe proposed joint model presented in Section 3.With this new approach, 41.8% imperfection re-duction in type-sensitive F-score, from 68.4% to81.6%, has been observed in our Chinese-English NE alignment task.2 MotivationThe problem of NE recognition requires bothboundary identification and type classification.However, the complexity of these tasks varieswith different languages.
For example, ChineseNE boundaries are especially difficult to identifybecause Chinese is not a tokenized language.
Incontrast, English NE boundaries are easier toidentify due to capitalization clues.
On the otherhand, classification of English NE types can bemore challenging (Ji et al, 2006).
Since align-ment would force the linked NE pair to share thesame semantic meaning, the NE that is more re-liably identified in one language can be used toensure its counterpart in another language.
Thisbenefits both the NE boundary identification andtype classification processes, and it hints thatalignment can help to re-identify those initiallyrecognized NEs which had been less reliable.As shown in the following example, althoughthe desired NE ?????????
is recognizedpartially as ??????
in the initial recognitionstage, it would be more preferred if its Englishcounterpart ?North Korean's Central NewsAgency?
is given.
The reason for this is that?News Agency?
would prefer to be linked to ????
?, rather than to be deleted (which wouldhappen if ??????
is chosen as the corre-sponding Chinese NE).
(I) The initial NE detection in a Chinese sentence:???
<ORG>???
?</ORG> ???????...
(II) The initial NE detection of its English counterpart:Official <ORG>North Korean's Central News Agency</ORG> quoted the navy's statement?
(III) The word alignment between two NEs:(VI) The re-identified Chinese NE boundary after alignment:???
<ORG>??????
?</ORG> ?????
?...As another example, the word ?lake?
in theEnglish NE is linked to the Chinese character???
as illustrated below, and this mapping isfound to be a translation and not a transliteration.Since translation rarely occurs for personalnames (Chen et al, 2003), the desired NE type?LOC?
would be preferred to be shared betweenthe English NE ?Lake Constance?
and its corre-sponding Chinese NE ???????.
As a result,the original incorrect type ?PER?
of the givenEnglish NE is fixed, and the necessity of usingmapping type ratio and NE type consistency con-straint becomes evident.
(I) The initial NE detection result in a Chinese sentence:?
<LOC>????
?</LOC> ??????????
(II) The initial NE detection of its English counterpart:The captain of a ferry boat who works on <PER>Lake Con-stance </PER>?
(III) The word alignment between two NEs:(VI) The re-identified English NE type after alignment:The captain of a ferry boat who works on <LOC>LakeConstance</LOC>?3 The Proposed ModelAs mentioned in the introduction section, given aChinese-English sentence-pair ( , , with itsinitially recognized Chinese NEs)CS ES1, ,Si i iCNE CType S?
1?
?
?1[ , ] ,Tj j jENE EType T?
?and English NEs(  and 1 ieCTyp jEtyiCNEpeENareoriginal NE types assigned to  and ,respectively), we will first re-generate two NEcandidate-sets from them by enlarging andshrinking the boundaries of those initially recog-nized NEs.
LetjE1 CKR  and CNE 1 EKRENECdenotethese two re-generated candidate sets for Chi-nese and English NEs respectively ( K  and EKare their set-sizes), and ?
?min ,K S T?
, then atotal K  pairs of final Chinese and English NEswill be picked up from the Cartesian product of6321 CKRCNE  and 1 EKRENE( ,RCNE R?
?
[ ]kRENERType?
REiCNE, according to their associ-ated linking score, which is defined as follows.Let  denote the asso-ciated linking score for a given candidate-pairand , where  and  arethe associated indexes of the re-generated Chi-nese and English NE candidates, respectively.Furthermore, let  be the NE type to be re-assigned and shared by RCNE  and(as they possess the same meaning).
Assumethat  and  are derived from ini-tially recognized  and , respectively,and[ ]kre ENEkk?
[ ]kNEENScokRCNE?
?RCNE)kk?
?k?
?jE[ ]kRENE[ ]kICM  denotes their internal component map-ping, to be defined in Section 3.1, thenis  defined as follows: [ ]( ,k RENE?
?
[ ], ,k kIC ki iRENEM RTypeNE CType)kNEScore RC,maxIC kM RTypeScore RCNP?
[ ]( , ),     , , ,[ , ],k kj jERCNE RENEC CS ENE EType ES?
??
?????
?
?| ????
(1)Here, the ?max?
operator varies over eachpossible internal component mapping ICM  andre-assigned type (PER, LOC, and ORG).
Forbrevity, we will drop those associated subscriptsfrom now on, if there is no confusion.The associated probability factors in the abovelinking score can be further derived as follows.?
???
?, , ,, ,    [ , ],, ,, ,, ,ICICCNE CType CSP M RType ENE EType ESP M RTyp ENEP RCNE CS RTypeP RENE E ES RTypeP RType Type EType?
?
?
?????????
?,, ,| ,| ,| ,RCNE RENEe RCNE RCNE CTypeNE ETypeCNE ENE C??
(2)In the above equation,?
?, ,e RCNE?
| , ,ENE C| ,CType| ,NE ETypeICP M RTyp RENE?andare the Bilin-gual Alignment Factor and the Bilingual TypeRe-assignment Factor respectively, to representthe bilingual related scores (Section 3.1).
Also,andare Monolin-gual Candidate Certainty Factors (Section 3.2)used to assign preference to each selectedand , based on the initially recognizedNEs (which act as anchors).,P RType CNE Type EType?
?, ,P RCNE CNE CS RType?
?, ,P RENE E ES RTypeRENERCNE3.1 Bilingual Related FactorsThe bilingual alignment factor mainly representsthe likelihood value of a specific internal com-ponent mapping ICM , given a pair of possibleNE configurations RCNE  and  and theirassociated .
Since Chinese word segmen-tation is problematic, especially for transliteratedwords, the bilingual alignment factorRENERType?
?, ,CNE REICP M RType R NE  in Eq (2) is derivedto be conditioned on RE  (i.e., starting fromthe English part).NEWe define the internal component mappingICM  to be [ ] 1[ , , ] ,NIC n n n nM cpn ew Mtype ??
?
???
?
[ ][ , , ]n n new Mtypencpn,where  denotes a linked pairconsisting of a Chinese componentcpn?
??
?
[ ]new RCNE(which might contain several Chinese characters)and an English word  within  andrespectively, with their internal mappingtypeRENEnMtypeTLN2[ ,n ewto be either translation (abbreviatedas TS) or transliteration (abbreviated as TL).
Intotal, there are N  component mappings, withtranslation mappingsand  transliteration mappingsTSNcpn1 1[ ][ , , TSNn ncpn ew TS?
?2 2[ ] 1, ] TLNn nTL1 1]n ??
?
?
TS TLN N N?
?, so that .Moreover, since the mapping type distribu-tions of various NE types deviate greatly fromone another, as illustrated in the second footnote,the associated mapping type ratio ?
?/TSN N?
?
isthus an important feature, and is included in theinternal component mapping configuration speci-fied above.
For example, the ICM  between ???????
and ?Constance Lake?
is [???
?,Constance, TL] and [?, Lake, TS], so its asso-ciated mapping type ratio will be ?0.5?
(i.e., 1/2).Therefore, the internal mappingis further deduced by in-troducing the internal mapping type( | ,ICP M RType RENE)nMtype  andthe mapping type ratio ?
as follows:[ ] 1[ ]1 [ ]( | , )([ , , ] , | , )( | , , )( | , )( | )ICNn n n nN n n nn n nP M RType RENEP cpn ew Mtype RType RENEP cpn Mtype ew RTypeP Mtype ew RTypeP RType???
?
??
????
??
?
???
??
???
(3)In the above equation, the mappings betweeninternal components are trained from the sylla-ble/word alignment of NE pairs of different NEtypes.
In more detail?
for transliteration, themodel adopted in (Huang et al, 2003), whichfirst Romanizes Chinese characters and thentransliterates them into English characters, is633used for .
For transla-tion, conditional probability is directly used for.
[ ]( | , ,n n nP cpn TL ew RType?
?
[ ]( | , , )n n nTS ew RType)?P cpn?
?Lastly, the bilingual type re-assignment factorproposed inEq (2) is derived as follows:?
| , , ,P RType CNE ENE CType EType?
??
?| , , ,| ,P RType RCNE RENE CType ETypeP RType CType EType?
(4)As Eq (4) shows, both the Chinese initial NEtype and English initial NE type are adopted tojointly identify their shared NE type RType .3.2 Monolingual Candidate Certainty FactorsOn the other hand, the monolingual candidatecertainty factors in Eq (2) indicate the likelihoodthat a re-generated NE candidate is the true NEgiven its originally detected NE.
For Chinese, itis derived as follows:?11( , , , ), , [ ] , ,( , , )( , , )( | , )CCCMm mmP RCNE CNE CType CS RTypeP LeftD RightD Str RCNE Len CType RTypeP LeftD Len CType RTypeP RightD Len CType RTypeP cc cc RType???????||||?
(5)Where, the subscript C  denotes Chinese, andis the length of the originally recognizedChinese NE CN .
and  denote theleft and right distance (which are the numbers ofChinese characters) that R  shrinks/enlargesfrom the left and right boundary of its anchor, respectively.
As in the above example,assume that CN  and  are ?????
?and ????????
respectively, Le  andwill be ?-1?
and ?+3?.
Also,stands for the associated Chinese string of ,denotes the m-th Chinese character withinthat string, andCLenCNERightDmccEELeftDRRightDCNECNEftDStr RR[ ]CNECNEM denotes the total number ofChinese characters within .
RCNEOn the English side, following Eq (5),?
?| , , ,P RENE ENE EType ES RTypeftDE RENELeftD RightDmcccan be derivedsimilarly, except that Le  and  will bemeasured in number of English words.
For in-stance, with   EN  and  as  ?Lake Con-stance?
and ?on Lake Constance?
respectively,and  will be ?+1?
and ?0?.
Also,the bigram unit  of the Chinese NE string isreplaced by the English word unit .RightDnewAll the bilingual and monolingual factorsmentioned above, which are derived from Eq (1),are weighted differently according to their con-tributions.
The corresponding weighting coeffi-cients are obtained using the well-known Mini-mum Error Rate Training (Och, 2003; com-monly abbreviated as MERT) algorithm byminimizing the number of associated errors inthe development set.3.3 Framework for the Proposed ModelThe above model is implemented with a three-stage framework: (A) Initial NE Recognition; (B)NE-Candidate-Set Expansion; and (C) NEAlignment&Re-identification.
The FollowingDiagram gives the details of this framework:For each given bilingual sentence-pair:(A) Initial NE Recognition: generates the ini-tial NE anchors with off-the-self packages.
(B) NE-Candidate-Set Expansion: For eachinitially detected NE, several NE candi-dates will be re-generated from the origi-nal NE by allowing its boundaries to beshrunk or enlarged within a pre-specifiedrange.
(B.1) Create both RCNE and RENEcandidate-sets, which are ex-panded from those initial NEsidentified in the previous stage.
(B.2) Construct an NE-pair candidate-set (named NE-Pair-Candidate-Set), which is the Cartesianproduct of the RCNE and RENEcandidate-sets created above.
(C) NE Alignment&Re-identification: Rankeach candidate in the NE-Pair-Candidate-Set constructed above with the linkingscore specified in Eq (1).
Afterwards, con-duct a beam search process to select thetop K non-overlapping NE-pairs from thisset.Diagram 1.
Steps to Generate the Final NE-PairsIt is our observation that, four Chinese charac-ters for both shrinking and enlarging, two Eng-lish words for shrinking and three for enlargingare enough in most cases.
Under these conditions,the including-rates for NEs with correct bounda-ries are raised to 95.8% for Chinese and 97.4%for English; and even the NE-pair including rateis raised to 95.3%.
Since the above range limita-tion setting has an including-rate only 0.8%lower than that can be obtained without anyrange limitation (which is 96.1%), it is adoptedin this paper to greatly reduce the number of NE-pair-candidates.6344 ExperimentsTo evaluate the proposed joint approach, a priorwork (Huang et al, 2003) is re-implemented inour environment as the baseline, in which thetranslation cost, transliteration cost and taggingcost are used.
This model is selected for com-parison because it not only adopts the same can-didate-set expansion strategy as mentioned above,but also utilizes the monolingual informationwhen selecting NE-pairs (however, only a simplebi-gram model is used as the tagging cost in theirpaper).
Note that it enforces the same NE typeonly when the tagging cost is evaluated:1111min [ log( ( | , ))log( ( | , ))]RTypeMtag m mmNn nnC P cc cc RTypeP ew ew RType?????
????
.To give a fairer comparison, the same train-ing-set and testing-set are adopted.
The training-set includes two parts.
The first part consists of90,412 aligned sentence-pairs newswire datafrom the Foreign Broadcast Information Service(FBIS), which is denoted as Training-Set-I.
Thesecond Part of the training set is theLDC2005T34 bilingual NE dictionary3, which isdenoted as Training-Set-II.
The required featureinformation is then manually labeled throughoutthe two training sets.In our experiments, for the baseline system,the translation cost and the transliteration costare trained on Training-Set-II, while the taggingcost is trained on Training-Set-I.
For the pro-posed approach, the monolingual candidate cer-tainty factors are trained on Training-Set-I, andTraining-Set-II is used to train the parametersrelating to bilingual alignment factors.For the testing-set, 300 sentence pairs are ran-domly selected from the LDC Chinese-EnglishNews Text (LDC2005T06).
The average lengthof the Chinese sentences is 59.4 characters, whilethe average length of the English sentences is24.8 words.
Afterwards, the answer keys for NErecognition and alignment were annotated manu-ally, and used as the gold standard to calculatemetrics of precision (P), recall (R), and F-score(F) for both NE recognition (NER) and NEalignment (NEA).
In Total 765 Chinese NEs and747 English NEs were manually labeled in thetesting-set, within which there are only 718 NEpairs, including 214 PER, 371 LOC and 133ORG NE-pairs.
The number of NE pairs is less3 The LDC2005T34 data-set consists of proofread bilingualentries: 73,352 person names, 76,460 location names and68,960 organization names.than that of NEs, because not all those recog-nized NEs can be aligned.Besides, the development-set for MERTweight training is composed of 200 sentencepairs selected from the LDC2005T06 corpus,which includes 482 manually tagged NE pairs.There is no overlap between the training-sets, thedevelopment-set and the testing-set.4.1 Baseline SystemBoth the baseline and the proposed models sharethe same initial detection subtask, which adoptsthe Chinese NE recognizer reported by Wu et al(2005), which is a hybrid statistical model incor-porating multi-knowledge sources, and the Eng-lish NE recognizer included in the publiclyavailable Mallet toolkit4 to generate initial NEs.Initial Chinese NEs and English NEs are recog-nized by these two available packages respec-tively.NE-type P (%): C/E R (%): C/E F (%): C/EPER 80.2 / 79.2 87.7 / 85.3 83.8 / 82.1LOC 89.8 / 85.9 87.3 / 81.5 88.5/ 83.6ORG 78.6 / 82.9 82.8 / 79.6 80.6 / 81.2ALL 83.4 / 82.1 86.0 / 82.6 84.7 / 82.3Table 1.
Initial Chinese/English NERTable 1 shows the initial NE recognition per-formances for both Chinese and English (thelargest entry in each column is highlighted forvisibility).
From Table 1, it is observed that theF-score of ORG type is the lowest among all NEtypes for both English and Chinese.
This is be-cause many organization names are partially rec-ognized or missed.
Besides, not shown in thetable, the location names or abbreviated organi-zation names tend to be incorrectly recognized asperson names.
In general, the initial ChineseNER outperforms the initial English NER, as theNE type classification turns out to be a more dif-ficult problem for this English NER system.When those initially identified NEs are di-rectly used for baseline alignment, only 64.1% Fscore (regard of their name types) is obtained.Such a low performance is mainly due to thoseNE recognition errors which have been broughtinto the alignment stage.To diminish the effect of errors accumulating,which stems from the recognition stage, the base-line system also adopts the same expansion strat-egy described in Section 3.3 to enlarge the possi-4 http://mallet.cs.umass.edu/index.php/Main_Page635ble NE candidate set.
However, only a slight im-provement (68.4% type-sensitive F-score) is ob-tained, as shown in Table 2.
Therefore, it is con-jectured that the baseline alignment model is un-able to achieve good performance if those fea-tures/factors proposed in this paper are notadopted.4.2 The Recognition and Alignment JointModelTo show the individual effect of each factor inthe joint model, a series of experiments, fromExp0 to Exp11, are conducted.
Exp0 is the basicsystem, which ignores monolingual candidatecertainty scores, and also disregards mappingtype and NE type consistency constraint by ig-noring  and [ ]( | ,n nP Mtype ew RType) ( | )P RType?
,and also replacing Pwith  in Eq (3).
[ ], ,n n new RType( |cpn?
?
[ ]( | )n nP cpn ew?
?
)))))nMtypeTo show the effect of enforcing NE type con-sistency constraint on internal component map-ping, Exp1 (named Exp0+RType) replacesin Exp0 with; On the other hand, Exp2(named Exp0+MappingType) shows the effect ofintroducing the component mapping type to Eq(3) by replacing  in Exp0 by; ThenExp3 (named Exp2+MappingTypeRatio) furtheradds[ ]( |n nP cpn ew?
?
[ ]( |n nP cpn ew?
?
( |n nP cpn Mtype?
?
( |P RTy, RTypeP c[ ],ew)pe[ ]( |n npn ew?
?)
(n P Mtype e?
[ ]|n w?
to Exp2, to manifest the con-tribution from the mapping type ratio.
In addition,Exp4 (named Exp0+RTypeReassignment) addsthe NE type reassignment score, Eq (4), to Exp0to show the effect of enforcing NE-type consis-tency.
Furthermore, Exp5 (named All-BiFactors)shows the full power of the set of proposed bi-lingual factors by turning on all the options men-tioned above.
As the bilingual alignment factorswould favor the candidates with shorter lengths,[ ] 1([ , , ] , | , ),Nn n n nP cpn ew Mtype RType RENE??
?
?
Eq (3),is further normalized into the following form:1[ ]1[ ]( | , , ) ( | ),( | , )N Nn n nnn nP cpn Mtype ew RType P RTypeP Mtype ew RType??
???
??
?
??
??
???
?
?and is shown by Exp6 (named All-N-BiFactors).To show the influence of additional informa-tion carried by those initially recognized NEs,Exp7 (named Exp6+LeftD/RightD) adds left andright distance information into Exp6, as thatspecified in Eq (5).
To study the monolingual bi-gram capability, Exp8 (named Exp6+Bigram)adds the NEtype dependant bigram model ofeach language to Exp6.
We use SRI LanguageModeling Toolkit5 (SRILM) (Stolcke, 2002) totrain various character/word based bi-gram mod-els with different NE types.
Similar to what wehave done on the bilingual alignment factorabove, Exp9 (named Exp6+N-Bigram) adds thenormalized NEtype dependant bigram to Exp6for removing the bias induced by having differ-ent NE lengths.
The normalized Chinese NEtypedependant bigram score is defined as111[ ( | , )M ]Mm mm P cc cc RType???
.
A Similar trans-formation is also applied to the English side.Lastly, Exp10 (named Fully-JointModel)shows the full power of the proposed Recogni-tion and Alignment Joint Model by adopting allthe normalized factors mentioned above.
Theresult of a MERT weighted version is furthershown by Exp11 (named Weighted-JointModel).Model P (%) R (%) F (%)Baseline 77.1  (67.1)79.7(69.8)78.4(68.4)Exp0(Basic System)67.9(62.4)70.3(64.8)69.1(63.6)Exp1(Exp0 + Rtype)69.6(65.7)71.9(68.0)70.8(66.8)Exp2(Exp0 + MappingType)70.5(65.3)73.0(67.5)71.7(66.4)Exp3(Exp2 + MappingTypeRatio)72.0(68.3)74.5(70.8)73.2(69.5)Exp4(Exp0 + RTypeReassignment)70.2(66.7)72.7(69.2)71.4(67.9)Exp5(All-BiFactors)76.2(72.3)78.5(74.6)77.3(73.4)Exp6(All-N-BiFactors)77.7(73.5)79.9(75.7)78.8(74.6)Exp7(Exp6 + LeftD/RightD)83.5(77.7)85.8(80.1)84.6(78.9)Exp8(Exp6 + Bigram)80.4(75.5)82.7(77.9)81.5(76.7)Exp9(Exp6 + N-Bigram)82.7(77.1)85.1(79.6)83.9(78.3)Exp10(Fully-JointModel)83.7(78.1)86.2(80.7)84.9(79.4)Exp11(Weighted-Joint Model)85.9(80.5)88.4(83.0)87.1(81.7)Table 2.
NEA Type-Insensitive (Type-Sensitive)PerformanceSince most papers in the literature are evalu-ated only based on the boundaries of NEs, twokinds of performance are thus given here.
Thefirst one (named type-insensitive) only checksthe scope of each NE without taking its associ-ated NE type into consideration, and is reported5   http://www.speech.sri.com/projects/srilm/636as the main data at Table 2.
The second one(named type-sensitive) would also evaluate theassociated NE type of each NE, and is givenwithin parentheses in Table 2.
A large degrada-tion is observed when NE type is also taken intoaccount.
The highlighted entries are those thatare statistically better6 than that of the baselinesystem.4.3 ME Approach with Primitive FeaturesAlthough the proposed model has been derivedabove in a principled way, since all these pro-posed features can also be directly integratedwith the well-known maximum entropy (ME)(Berger et al, 1996) framework without makingany assumptions, one might wonder if it is stillworth to deriving a model after all the relatedfeatures have been proposed.
To show that notonly the features but also the adopted model con-tribute to the performance improvement, an MEapproach is tested as follows for comparison.
Itdirectly adopts all those primitive features men-tioned above as its inputs (including internalcomponent mapping, initial and final NE type,NE bigram-based string, and left/right distance),without involving any related probability factorsderived within the proposed model.This ME method is implemented with a publicpackage YASMET7, and is tested under varioustraining-set sizes (400, 4,000, 40,000, and 90,412sentence-pairs).
All those training-sets are ex-tracted from the Training-Set-I mentioned above(a total of 298,302 NE pairs included are manu-ally labeled).
Since the ME approach is unable toutilize the bilingual NE dictionary (Training-Set-II), for fair comparison, this dictionary was alsonot used to train our models here.
Table 3 showsthe performance (F-score) using the same test-ing-set.
The data within parentheses are relativeimprovements.Model 400 4,000 40,000 90,412ME framework 36.5 (0%)50.4(0%)62.6(0%)67.9(0%)Un-weighted-JointModel+4.6(+12.6%)+4.5(+8.9%)+4.3(+6.9%)+4.1(+6.0%)Weighted-JointModel+5.0(+13.7%)+4.7(+9.3%)+4.6(+7.3%)+4.5(+6.6%)Table 3.
Comparison between ME Frameworkand Derived Model on the Testing-Set6 Statistical significance test is measured on 95% confidencelevel on 1,000 re-sampling batches (Zhang et al, 2004)7 http://www.fjoch.com/YASMET.htmlThe improvement indicated in Table 3 clearlyillustrates the benefit of deriving the modelshown in Eq (2).
Since a reasonably derivedmodel not only shares the same training-set withthe primitive ME version above, but also enjoysthe additional knowledge introduced by the hu-man (i.e., the assumptions/constraints implied bythe model), it is not surprising to find out that agood model does help, and that it also becomesmore noticeable as the training-set gets smaller.5 Error Analysis and DiscussionAlthough the proposed model has substantiallyimproved the performance of both NE alignmentand recognition, some errors still remain.
Havingexamined those type-insensitive errors, we foundthat they can be classified into four categories:(A) Original NEs or their components are al-ready not one-to-one mapped (23%).
(B) NEcomponents are one-to-one linked, but the asso-ciated NE anchors generated from the initial rec-ognition stage are either missing or spurious(24%).
Although increasing the number of outputcandidates generated from the initial recognitionstage might cover the missing problem, possibleside effects might also be expected (as the com-plexity of the alignment task would also be in-creased).
(C) Mapping types are not assumed bythe model (27%).
For example, one NE is abbre-viated while its counterpart is not; or some loan-words or out-of-vocabulary terms are translatedneither semantically nor phonetically.
(D) WrongNE scopes are selected (26%).
Errors of this typeare uneasy to resolve, and their possible solutionsare beyond the scope of this paper.Examples of above category (C) are interest-ing and are further illustrated as follows.
As aninstance of abbreviation errors, a Chinese NE???????
(GlaxoSmithKline Factory)?
istagged as ????
/PRR ???
/n?, while itscounterpart in the English side is simply abbrevi-ated as ?GSK?
(or  replaced by a pronoun ?it?sometimes).
Linking ?????
to ?GSK?
(or tothe pronoun ?it?)
is thus out of reach of ourmodel.
It seems an abbreviation table (or evenanaphora analysis) is required to recover thesekind of errors.As an example of errors resulting from loan-words; Japanese kanji ????
(the name of aJapanese emperor) is linked to the English word?Akihito?.
Here the Japanese kanji ????
is di-rectly adopted as the corresponding Chinesecharacters (as those characters were originallyborrowed from Chinese), which would be pro-637nounced as ?Mingren?
in Chinese and thus devi-ates greatly from the English pronunciation of?Akihito?.
Therefore, it is translated neither se-mantically nor phonetically.
Further extendingthe model to cover this new conversion typeseems necessary; however, such a kind of exten-sion is very likely to be language pair dependent.6 Capability of the Proposed ModelIn addition to improving NE alignment, the pro-posed joint model can also boost the perform-ance of NE recognition in both languages.
Thecorresponding differences in performance (of theweighted version) when compared with the ini-tial NER ( ,   and P?
R?
F? )
are shown in Table 4.Again, those marked entries indicate that they arestatistically better than that of the original NER.NEtype P?
(%): C/E R?
(%): C/E F?
(%): C/EPER +5.4 / +6.4 +2.2 / +2.6 +3.9 / +4.6LOC +4.0 / +3.4 -0.2 / +2.7 +1.8 / +3.0ORG +7.0 / +3.9 +5.6 / +9.1 +6.2 / +6.4ALL +5.3 /+5.2 +2.4 / +4.0 +3.9 / +4.6Table 4.
Improvement in Chinese/English NERThe result shows that the proposed joint modelhas a clear win over the initial NER for eitherChinese or English NER.
In particular, ORGseems to have yielded the greatest gain amongstNE types, which matches our previous observa-tions that the boundaries of Chinese ORG aredifficult to identify with the information onlycoming from the Chinese sentence, while thetype of English ORG is uneasy to classify withthe information only coming from the Englishsentence.Though not shown in the tables, it is also ob-served that the proposed approach achieves a28.9% reduction on the spurious (false positive)and partial tags over the initial Chinese NER, aswell as 16.1% relative error reduction comparedwith the initial English NER.
In addition, total27.2% wrong Chinese NEs and 40.7% wrongEnglish NEs are corrected into right NE types.However, if the mapping type ratio is omitted,only 21.1% wrong Chinese NE types and 34.8%wrong English NE types can be corrected.
Thisclearly indicates that the ratio is essential foridentifying NE types.With the benefits shown above, the alignmentmodel could thus be used to train the monolin-gual NE recognition model via semi-supervisedlearning.
This advantage is important for updat-ing the NER model from time to time, as variousdomains frequently have different sets of NEsand new NEs also emerge with time.Since the Chinese NE recognizer we use is notan open source toolkit, it cannot be used to carryout semi-supervised learning.
Therefore, only theEnglish NE recognizer and the alignment modelare updated during training iterations.
In our ex-periments, 50,412 sentence pairs are first ex-tracted from Training-Set-I as unlabeled data.Various labeled data-sets are then extracted fromthe remaining data as different seed corpora (100,400, 4,000 and 40,000 sentence-pairs).
Table 5shows the results of semi-supervised learningafter convergence for adopting only the EnglishNER model (NER-Only), the baseline alignmentmodel (NER+Baseline), and our un-weightedjoint model (NER+JointModel) respectively.
TheInitial-NER row indicates the initial performanceof the NER model re-trained from different seedcorpora.
The data within parentheses are relativeimprovement over Initial-NER.
Note that thetesting set is still the same as before.As Table 5 shows, with the NER model alone,the performance may even deteriorate after con-vergence.
This is due to the fact that maximizinglikelihood does not imply minimizing the errorrate.
However, with additional mapping con-straints from the aligned sentence of another lan-guage, the alignment module could guide thesearching process to converge to a more desir-able point in the parameter space; and these addi-tional constraints become more effective as theseed-corpus gets smaller.Model 100 400 4,000 40,000Initial-NER 36.7 (0%)58.6(0%)71.4(0%)79.1(0%)NER-Only -2.3 (-6.3%)-0.5(-0.8%)-0.3(-0.4%)-0.1(-0.1%)NER+Baseline +4.9 (+13.4%)+3.4(5.8%)+1.7(2.4%)+0.7(0.9%)NER+JointModel+10.7(+29.2%)+8.7(+14.8%)+4.8(+6.7%)+2.3(+2.9%)Table 5.
Testing-Set Performance for Semi-Supervised Learning of English NE Recognition7 ConclusionIn summary, our experiments show that the newmonolingual candidate certainty factors are moreeffective than the tagging cost (only bigrammodel) adopted in the baseline system.
Moreover,both the mapping type ratio and the entity typeconsistency constraint are very helpful in identi-fying the associated NE boundaries and types.After having adopted the features and enforced638the constraint mentioned above, the proposedframework, which jointly recognizes and alignsbilingual named entities, achieves a remarkable42.1% imperfection reduction on type-sensitiveF-score (from 68.4% to 81.7%) in our Chinese-English NE alignment task.Although the experiments are conducted onthe Chinese-English language pair, it is expectedthat the proposed approach can also be applied toother language pairs, as no language dependentlinguistic feature (or knowledge) is adopted inthe model/algorithm used.AcknowledgmentsThe research work has been partially supportedby the National Natural Science Foundation ofChina under Grants No.
60975053, 90820303,and 60736014, the National Key TechnologyR&D Program under Grant No.
2006BAH03B02,and also the Hi-Tech Research and DevelopmentProgram (?863?
Program) of China under GrantNo.
2006AA010108-4.ReferencesAl-Onaizan, Yaser, and Kevin Knight.
2002.
Translat-ing Named Entities Using Monolingual and Bilin-gual resources.
In Proceedings of the 40th AnnualMeeting of the Association for Computational Lin-guistics (ACL), pages 400-408.Berger, Adam L., Stephen A. Della Pietra and Vin-cent J. Della Pietra.
1996.
A Maximum EntropyApproach to Natural Language Processing.
Com-putational Linguistics, 22(1):39-72, March.Chen, Hsin-His, Changhua Yang and Ying Lin.
2003.Learning Formulation and Transformation Rulesfor Multilingual Named Entities.
In Proceedings ofthe ACL 2003 Workshop on Multilingual andMixed-language Named Entity Recognition, pages1-8.Feng, Donghui, Yajuan Lv and Ming Zhou.
2004.
ANew Approach for English-Chinese Named EntityAlignment.
In Proceedings of the Conference onEmpirical Methods in Natural Language Process-ing (EMNLP 2004), pages 372-379.Huang, Fei, Stephan Vogel and Alex Waibel.
2003.Automatic Extraction of Named Entity Translin-gual Equivalence Based on Multi-Feature CostMinimization.
In Proceedings of ACL?03, Work-shop on Multilingual and Mixed-language NamedEntity Recognition.
Sappora, Japan.Ji, Heng and Ralph Grishman.
2006.
Analysis andRepair of Name Tagger Errors.
In Proceedings ofCOLING/ACL 06, Sydney, Australia.Lee, Chun-Jen, Jason S. Chang and Jyh-Shing R. Jang.2006.
Alignment of Bilingual Named Entities inParallel Corpora Using Statistical Models and Mul-tiple Knowledge Sources.
ACM Transactions onAsian Language Information Processing (TALIP),5(2): 121-145.Moore, R. C.. 2003.
Learning Translations of Named-Entity Phrases from Parallel Corpora.
In Proceed-ings of 10th Conference of the European Chapterof ACL, Budapest, Hungary.Och, Franz Josef.
2003.
Minimum Error Rate Train-ing in Statistical Machine Translation.
In Proceed-ings of the 41st Annual Conference of the Associa-tion for Computational Linguistics (ACL).
July 8-10, 2003.
Sapporo, Japan.
Pages: 160-167.Stolcke, A.
2002.
SRILM -- An Extensible LanguageModeling Toolkit.
Proc.
Intl.
Conf.
on SpokenLanguage Processing, vol.
2, pp.
901-904, Denver.Wu, Youzheng, Jun Zhao and Bo Xu.
2005.
ChineseNamed Entity Recognition Model Based on Multi-ple Features.
In Proceedings of HLT/EMNLP 2005,pages 427-434.Zhang, Ying, Stephan Vogel, and Alex Waibel, 2004.Interpreting BLEU/NIST Scores: How Much Im-provement Do We Need to Have a Better System?In Proceedings of the 4th International Conferenceon Language Resources and Evaluation, pages2051--2054.639
