Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 804?809,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsAutomatic Term Ambiguity DetectionTyler Baldwin Yunyao Li Bogdan Alexe Ioana R. StanoiIBM Research - Almaden650 Harry Road, San Jose, CA 95120, USA{tbaldwi,yunyaoli,balexe,irs}@us.ibm.comAbstractWhile the resolution of term ambiguity isimportant for information extraction (IE)systems, the cost of resolving each in-stance of an entity can be prohibitivelyexpensive on large datasets.
To combatthis, this work looks at ambiguity detec-tion at the term, rather than the instance,level.
By making a judgment about thegeneral ambiguity of a term, a system isable to handle ambiguous and unambigu-ous cases differently, improving through-put and quality.
To address the termambiguity detection problem, we employa model that combines data from lan-guage models, ontologies, and topic mod-eling.
Results over a dataset of entitiesfrom four product domains show that theproposed approach achieves significantlyabove baseline F-measure of 0.96.1 IntroductionMany words, phrases, and referring expressionsare semantically ambiguous.
This phenomenon,commonly referred to as polysemy, represents aproblem for NLP applications, many of which in-herently assume a single sense.
It can be particu-larly problematic for information extraction (IE),as IE systems often wish to extract informationabout only one sense of polysemous terms.
Ifnothing is done to account for this polysemy, fre-quent mentions of unrelated senses can drasticallyharm performance.Several NLP tasks, such as word sense disam-biguation, word sense induction, and named en-tity disambiguation, address this ambiguity prob-lem to varying degrees.
While the goals and initialdata assumptions vary between these tasks, all ofthem attempt to map an instance of a term seenin context to an individual sense.
While makinga judgment for every instance may be appropri-ate for small or medium sized data sets, the costof applying these ambiguity resolution proceduresbecomes prohibitively expensive on large data setsof tens to hundreds of million items.
To combatthis, this work zooms out to examine the ambigu-ity problem at a more general level.To do so, we define an IE-centered ambiguitydetection problem, which ties the notion of am-biguity to a given topical domain.
For instance,given that the terms Call of Juarez and A NewBeginning can both reference video games, wewould like to discover that only the latter case islikely to appear frequently in non-video game con-texts.
The goal is to make a binary decision asto whether, given a term and a domain, we canexpect every instance of that term to reference anentity in that domain.
By doing so, we segregateambiguous terms from their unambiguous coun-terparts.
Using this segregation allows ambiguousand unambiguous instances to be treated differ-ently while saving the processing time that mightnormally be spent attempting to disambiguate in-dividual instances of unambiguous terms.Previous approaches to handling word ambigu-ity employ a variety of disparate methods, vari-ously relying on structured ontologies, gleaminginsight from general word usage patterns via lan-guage models, or clustering the contexts in whichwords appear.
This work employs an ambiguitydetection pipeline that draws inspiration from allof these methods to achieve high performance.2 Term Ambiguity Detection (TAD)A term can be ambiguous in many ways.
It mayhave non-referential senses in which it shares aname with a common word or phrase, such as inthe films Brave and 2012.
A term may have refer-ential senses across topical domains, such as TheGirl with the Dragon Tattoo, which may referenceeither the book or the film adaptation.
Terms may804also be ambiguous within a topical domain.
Forinstance, the term Final Fantasy may refer to thevideo game franchise or one of several individualgames within the franchise.
In this work we con-cern ourselves with the first two types of ambigu-ity, as within topical domain ambiguity tends topose a less severe problem for IE systems.IE systems are often asked to perform extrac-tion over a dictionary of terms centered arounda single topic.
For example, in brand manage-ment, customers may give a list of product namesand ask for sentiment about each product.
Withthis use case in mind, we define the term ambigu-ity detection (TAD) problem as follows: Given aterm and a corresponding topic domain, determinewhether the term uniquely references a memberof that topic domain.
That is, given a term suchas Brave and a category such as film, the task ismake a binary decision as to whether all instancesof Brave reference a film by that name.2.1 FrameworkOur TAD framework is a hybrid approach consist-ing of three modules (Figure 1).
The first moduleis primarily designed to detect non-referential am-biguity.
This module examines n-gram data froma large text collection.
Data from The Corpus ofContemporary American English (Davies, 2008 )was used to build our n-grams.The rationale behind the n-gram module isbased on the understanding that terms appearingin non-named entity contexts are likely to be non-referential, and terms that can be non-referentialare ambiguous.
Therefore, detecting terms thathave non-referential usages can also be used todetect ambiguity.
Since we wish for the ambigu-ity detection determination to be fast, we developour method to make this judgment solely on then-gram probability, without the need to examineeach individual usage context.
To do so, we as-sume that an all lowercased version of the term isa reasonable proxy for non-named entity usages informal text.
After removing stopwords from theterm, we calculate the n-gram probability of thelower-cased form of the remaining words.
If theprobability is above a certain threshold, the termis labeled as ambiguous.
If the term is below thethreshold, it is tentatively labeled as unambiguousand passed to the next module.
To avoid makingjudgments of ambiguity based on very infrequentuses, the ambiguous-unambiguous determinationthreshold is empirically determined by minimiz-ing error over held out data.The second module employs ontologies to de-tect across domain ambiguity.
Two ontologieswere examined.
To further handle the commonphrase case, Wiktionary1 was used as a dictionary.Terms that have multiple senses in Wiktionarywere labeled as ambiguous.
The second ontologyused was Wikipedia disambiguation pages.
Allterms that had a disambiguation page were markedas ambiguous.The final module attempts to detect both non-referential and across domain ambiguity by clus-tering the contexts in which words appear.
To doso, we utilized the popular Latent Dirichlet Allo-cation (LDA (Blei et al 2003)) topic modelingmethod.
LDA represents a document as a distri-bution of topics, and each topic as a distributionof words.
As our domain of interest is Twitter,we performed clustering over a large collection oftweets.
For a given term, all tweets that containedthe term were used as a document collection.
Fol-lowing standard procedure, stopwords and infre-quent words were removed before topic modelingwas performed.
Since the clustering mechanismwas designed to make predictions over the alreadyfiltered data of the other modules, it adopts a con-servative approach to predicting ambiguity.
If thecategory term (e.g., film) or a synonym from theWordNet synset does not appear in the 10 mostheavily weighted words for any cluster, the term ismarked as ambiguous.A term is labeled as ambiguous if any one ofthe three modules predicts that it is ambiguous,but only labeled as unambiguous if all three mod-ules make this prediction.
This design allows eachmodule to be relatively conservative in predictingambiguity, keeping precision of ambiguity predic-tion high, under the assumption that other moduleswill compensate for the corresponding drop in re-call.3 Experimental Evaluation3.1 Data SetInitial Term Sets We collected a data set of termsfrom four topical domains: books, films, videogames, and cameras.
Terms for the first three do-mains are lists of books, films, and video gamesrespectively from the years 2000-2011 from db-pedia (Auer et al 2007), while the initial terms1http://www.wiktionary.org/805Tweet Term Category JudgmentWoke up from a nap to find a beautiful mind on.
#win A Beautiful Mind film yesI Love Tyler Perry ; He Has A Beautiful Mind.
A Beautiful Mind film noI might put it in the top 1.
RT @CourtesyFlushMo Splice.
Top 5 worst movies ever Splice film yesSplice is a great, free replacement to iMove for your iPhone, Splice film noTable 1: Example tweet annotations.Figure 1: Overview of the ambiguity detectionframework.for cameras includes all the cameras from the sixmost popular brands on flickr2.Gold Standard A set of 100 terms per domainwere chosen at random from the initial term sets.Rather than annotating each term directly, am-biguity was determined by examining actual us-age.
Specifically, for each term, usage exampleswere extracted from large amounts of Twitter data.Tweets for the video game and film categories wereextracted from the TREC Twitter corpus.3 Theless common book and camera cases were ex-tracted from a subset of all tweets from September1st-9th, 2012.For each term, two annotators were given theterm, the corresponding topic domain, and 10 ran-domly selected tweets containing the term.
Theywere then asked to make a binary judgment as towhether the usage of the term in the tweet referredto an instance of the given category.
The degreeof ambiguity is then determined by calculating thepercentage of tweets that did not reference a mem-ber of the topic domain.
Some example judgmentsare given in Table 1.
If all individual tweet judg-ments for a term were marked as referring to a2http://www.flickr.com/cameras/3http://trec.nist.gov/data/tweets/Configuration Precision Recall F-measureBaseline 0.675 1.0 0.806NG 0.979 0.848 0.909ON 0.979 0.704 0.819CL 0.946 0.848 0.895NG + ON 0.980 0.919 0.948NG + CL 0.942 0.963 0.952ON + CL 0.945 0.956 0.950NG + ON + CL 0.943 0.978 0.960Table 2: Performance of various framework con-figurations on the test data.member of the topic domain, the term was markedas fully unambiguous within the data examined.All other cases were considered ambiguous.4Inter-annotator agreement was high, with rawagreement of 94% (?
= 0.81).
Most disagree-ments on individual tweet judgments had little ef-fect on the final judgment of a term as ambiguousor unambiguous, and those that did were resolvedinternally.3.2 Evaluation and ResultsEffectiveness To understand the contribution ofthe n-gram (NG), ontology (ON), and clustering(CL) based modules, we ran each separately, aswell as every possible combination.
Results areshown in Table 2, where they are compared to amajority class (ambiguous) baseline.As shown, all configurations outperform thebaseline.
Of the three individual modules, the n-gram and clustering methods achieve F-measureof around 0.9, while the ontology-based moduleperforms only modestly above baseline.
Unsur-prisingly, the ontology method is affected heav-ily by its coverage, so its poor performance is pri-marily attributable to low recall.
As noted, manyIE tasks may involve sets of entities that are notfound in common ontologies, limiting the abilityof the ontology-based method alone.
Additionally,ontologies may be apt to list cases of strict ambi-guity, rather than practical ambiguity.
That is, anontology may list a term as ambiguous if there are4The annotated data is available at http://researcher.watson.ibm.com/researcher/view_person_subpage.php?id=4757.806several potential named entities it could refer to,even if the vast majority of references were to onlya single entity.Combining any two methods produced substan-tial performance increases over any of the individ-ual runs.
The final system that employed all mod-ules produced an F-measure of 0.960, a significant(p < 0.01) absolute increase of 15.4% over thebaseline.Usefulness To establish that term ambiguity de-tection is actually helpful for IE, we conducteda preliminary study by integrating our pipelineinto a commercially available rule-based IE sys-tem (Chiticariu et al 2010; Alexe et al 2012).The system takes a list of product names as inputand outputs tweets associated with each product.It utilizes rules that employ more conservative ex-traction for ambiguous entities.Experiments were conducted over several mil-lion tweets using the terms from the video gameand camera domains.
When no ambiguity detec-tion was performed, all terms were treated as un-ambiguous.
The system produced very poor pre-cision of 0.16 when no ambiguity detection wasused, due to the extraction of irrelevant instancesof ambiguous objects.
In contrast, the system pro-duced precision of 0.96 when ambiguity detectionwas employed.
However, the inclusion of disam-biguation did reduce the overall recall; the systemthat employed disambiguation returned only about57% of the true positives returned by the systemthat did not employ disambiguation.
Althoughthis reduction in recall is significant, the overallimpact of disambiguation is clearly positive, dueto the stark difference in precision.
Nonetheless,this limited study suggests that there is substantialroom for improvement in the extraction system, al-though this is out of the scope of the current work.4 Related WorkPolysemy is a known problem for many NLP-related applications.
Machine translation systemscan suffer, as ambiguity in the source languagemay lead to incorrect translations, and unambigu-ous sentences in one language may become am-biguous in another (Carpuat and Wu, 2007; Chanet al 2007).
Ambiguity in queries can also hin-der the performance of information retrieval sys-tems (Wang and Agichtein, 2010; Zhong and Ng,2012).The ambiguity detection problem is similar tothe well studied problems of named entity dis-ambiguation (NED) and word sense disambigua-tion (WSD).
However, these tasks assume thatthe number of senses a word has is given, essen-tially assuming that the ambiguity detection prob-lem has already been solved.
This makes thesetasks inapplicable in many IE instances where theamount of ambiguity is not known ahead of time.Both named entity and word sense disambigua-tion are extensively studied, and surveys on eachare available (Nadeau and Sekine, 2007; Navigli,2009).Another task that shares similarities with TADis word sense induction (WSI).
Like NED andWSD, WSI frames the ambiguity problem as oneof determining the sense of each individual in-stance, rather than the term as a whole.
Unlikethose approaches, the word sense induction taskattempts to both figure out the number of senses aword has, and what they are.
WSI is unsupervised,relying solely on the information that surroundsword mentions in the text.Many different clustering-based WSI methodshave been examined.
Pantel and Lin (2002) em-ploy a clustering by committee method that itera-tively adds words to clusters based on their sim-ilarities.
Topic model-based methods have beenattempted using variations of Latent Dirichlet Al-location (Brody and Lapata, 2009) and Hierarchi-cal Dirichlet Processes (Lau et al 2012).
Sev-eral graph-based methods have also been exam-ined (Klapaftis and Manandhar, 2010; Navigli andCrisafulli, 2010).
Although the words that sur-round the target word are the primary source ofcontextual information in most cases, additionalfeature sources such as syntax (Van de Cruys,2008) and semantic relations (Chen and Palmer,2004) have also been explored.5 ConclusionThis paper introduced the term ambiguity detec-tion task, which detects whether a term is am-biguous relative to a topical domain.
Unlike otherambiguity resolution tasks, the ambiguity detec-tion problem makes general ambiguity judgmentsabout terms, rather than resolving individual in-stances.
By doing so, it eliminates the need forambiguity resolution on unambiguous objects, al-lowing for increased throughput of IE systems onlarge data sets.Our solution for the term ambiguity detection807task is based on a combined model with three dis-tinct modules based on n-grams, ontologies, andclustering.
Our initial study suggests that the com-bination of different modules designed for differ-ent types of ambiguity used in our solution is ef-fective in determining whether a term is ambigu-ous for a given domain.
Additionally, an exami-nation of a typical use case confirms that the pro-posed solution is likely to be useful in improvingthe performance of an IE system that does not em-ploy any disambiguation.Although the task as presented here was mo-tivated with information extraction in mind, it ispossible that term ambiguity detection could beuseful for other tasks.
For instance, TAD couldbe used to aid word sense induction more gener-ally, or could be applied as part of other tasks suchas coreference resolution.
We leave this avenue ofexamination to future work.AcknowledgmentsWe would like to thank the anonymous review-ers of ACL for helpful comments and suggestions.We also thank Howard Ho and Rajasekar Krishna-murthy for help with data annotation and Shivaku-mar Vaithyanathan for his comments on a prelim-inary version of this work.ReferencesBogdan Alexe, Mauricio A. Herna?ndez, Kirsten Hil-drum, Rajasekar Krishnamurthy, Georgia Koutrika,Meenakshi Nagarajan, Haggai Roitman, MichalShmueli-Scheuer, Ioana Roxana Stanoi, ChitraVenkatramani, and Rohit Wagle.
2012.
Surfacingtime-critical insights from social media.
In SIG-MOD Conference, pages 657?660.So?ren Auer, Christian Bizer, Georgi Kobilarov, JensLehmann, Richard Cyganiak, and Zachary Ives.2007.
Dbpedia: a nucleus for a web of open data.In Proceedings of the 6th international The seman-tic web and 2nd Asian conference on Asian semanticweb conference, ISWC?07/ASWC?07, pages 722?735, Berlin, Heidelberg.
Springer-Verlag.David Blei, Andrew Ng, and Micheal I. Jordan.
2003.Latent dirichlet alcation.
Journal of MachineLearning Research, 3:993?1022, January.Samuel Brody and Mirella Lapata.
2009.
Bayesianword sense induction.
In Proceedings of the 12thConference of the European Chapter of the Asso-ciation for Computational Linguistics, EACL ?09,pages 103?111, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Marine Carpuat and Dekai Wu.
2007.
Improving sta-tistical machine translation using word sense disam-biguation.
In Proceedings of the 2007 Joint Con-ference on Empirical Methods in Natural LanguageProcessing and Computational Natural LanguageLearning (EMNLP-CoNLL), pages 61?72.Yee Seng Chan, Hwee Tou Ng, and David Chiang.2007.
Word sense disambiguation improves statisti-cal machine translation.
In Proceedings of the 45thAnnual Meeting of the Association of ComputationalLinguistics, pages 33?40, Prague, Czech Republic,June.
Association for Computational Linguistics.Jinying Chen and Martha Palmer.
2004.
Chinese verbsense discrimination using an em clustering modelwith rich linguistic features.
In Proceedings of the42nd Annual Meeting on Association for Computa-tional Linguistics, ACL ?04, Stroudsburg, PA, USA.Association for Computational Linguistics.Laura Chiticariu, Rajasekar Krishnamurthy, YunyaoLi, Sriram Raghavan, Frederick Reiss, and Shivaku-mar Vaithyanathan.
2010.
SystemT: An algebraicapproach to declarative information extraction.
InACL, pages 128?137.Mark Davies.
2008-.
The corpus of contempo-rary american english: 450 million words, 1990-present.
Avialable online at: http://corpus.byu.edu/coca/.Ioannis P. Klapaftis and Suresh Manandhar.
2010.Word sense induction & disambiguation using hi-erarchical random graphs.
In Proceedings of the2010 Conference on Empirical Methods in NaturalLanguage Processing, EMNLP ?10, pages 745?755,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Jey Han Lau, Paul Cook, Diana McCarthy, David New-man, and Timothy Baldwin.
2012.
Word sense in-duction for novel sense detection.
In Proceedings ofthe 13th Conference of the European Chapter of theAssociation for Computational Linguistics, EACL?12, pages 591?601, Stroudsburg, PA, USA.
Asso-ciation for Computational Linguistics.David Nadeau and Satoshi Sekine.
2007.
A surveyof named entity recognition and classification.
Lin-guisticae Investigationes, 30(1):3?26.Roberto Navigli and Giuseppe Crisafulli.
2010.
Induc-ing word senses to improve web search result clus-tering.
In Proceedings of the 2010 Conference onEmpirical Methods in Natural Language Process-ing, EMNLP ?10, pages 116?126, Stroudsburg, PA,USA.
Association for Computational Linguistics.Roberto Navigli.
2009.
Word sense disambiguation:A survey.
ACM Comput.
Surv., 41(2):10:1?10:69,February.Patrick Pantel and Dekang Lin.
2002.
Discoveringword senses from text.
In Proceedings of the eighth808ACM SIGKDD international conference on Knowl-edge discovery and data mining, KDD ?02, pages613?619, New York, NY, USA.
ACM.Tim Van de Cruys.
2008.
Using three way data forword sense discrimination.
In Proceedings of the22nd International Conference on ComputationalLinguistics - Volume 1, COLING ?08, pages 929?936, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.Yu Wang and Eugene Agichtein.
2010.
Query ambigu-ity revisited: Clickthrough measures for distinguish-ing informational and ambiguous queries.
In HumanLanguage Technologies: The 2010 Annual Confer-ence of the North American Chapter of the Associa-tion for Computational Linguistics, pages 361?364,Los Angeles, California, June.
Association for Com-putational Linguistics.Zhi Zhong and Hwee Tou Ng.
2012.
Word sensedisambiguation improves information retrieval.
InProceedings of the 50th Annual Meeting of the As-sociation for Computational Linguistics (Volume 1:Long Papers), pages 273?282, Jeju Island, Korea,July.
Association for Computational Linguistics.809
