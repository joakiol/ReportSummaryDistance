Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 73?80,Sydney, July 2006. c?2006 Association for Computational LinguisticsNamed Entity Transliteration with Comparable CorporaRichard Sproat, Tao Tao, ChengXiang ZhaiUniversity of Illinois at Urbana-Champaign, Urbana, IL, 61801rws@uiuc.edu, {taotao,czhai}@cs.uiuc.eduAbstractIn this paper we investigate Chinese-English name transliteration using compa-rable corpora, corpora where texts in thetwo languages deal in some of the sametopics ?
and therefore share referencesto named entities ?
but are not transla-tions of each other.
We present two dis-tinct methods for transliteration, one ap-proach using phonetic transliteration, andthe second using the temporal distribu-tion of candidate pairs.
Each of these ap-proaches works quite well, but by com-bining the approaches one can achieveeven better results.
We then propose anovel score propagation method that uti-lizes the co-occurrence of transliterationpairs within document pairs.
This prop-agation method achieves further improve-ment over the best results from the previ-ous step.1 IntroductionAs part of a more general project on multilin-gual named entity identification, we are interestedin the problem of name transliteration across lan-guages that use different scripts.
One particular is-sue is the discovery of named entities in ?compara-ble?
texts in multiple languages, where by compa-rable we mean texts that are about the same topic,but are not in general translations of each other.For example, if one were to go through an English,Chinese and Arabic newspaper on the same day,it is likely that the more important internationalevents in various topics such as politics, business,science and sports, would each be covered in eachof the newspapers.
Names of the same persons,locations and so forth ?
which are often translit-erated rather than translated ?
would be found incomparable stories across the three papers.1 Wewish to use this expectation to leverage translit-eration, and thus the identification of named enti-ties across languages.
Our idea is that the occur-rence of a cluster of names in, say, an English text,should be useful if we find a cluster of what lookslike the same names in a Chinese or Arabic text.An example of what we are referring to can befound in Figure 1.
These are fragments of twostories from the June 8, 2001 Xinhua English andChinese newswires, each covering an internationalwomen?s badminton championship.
Though thesetwo stories are from the same newswire source,and cover the same event, they are not translationsof each other.
Still, not surprisingly, a lot of thenames that occur in one, also occur in the other.Thus (Camilla) Martin shows up in the Chineseversion as ???
ma-er-ting; Judith Meulendijksis ???????
yu mo-lun-di-ke-si; and MetteSorensen is ????
?mai su-lun-sen. Severalother correspondences also occur.
While some ofthe transliterations are ?standard?
?
thus Martinis conventionally transliterated as ???
ma-er-ting ?
many of them were clearly more novel,though all of them follow the standard Chineseconventions for transliterating foreign names.These sample documents illustrate an importantpoint: if a document in language L1 has a set ofnames, and one finds a document in L2 containinga set of names that look as if they could be translit-erations of the names in the L1 document, thenthis should boost one?s confidence that the two setsof names are indeed transliterations of each other.We will demonstrate that this intuition is correct.1Many names, particularly of organizations, may be trans-lated rather than transliterated; the transliteration method wediscuss here obviously will not account for such cases, thoughthe time correlation and propagation methods we discuss willstill be useful.73Dai Yun Nips World No.
1 Martin to Shake off OlympicShadow .
.
.
In the day?s other matches, second seed Zhou Mioverwhelmed Ling Wan Ting of Hong Kong, China 11-4, 11-4, Zhang Ning defeat Judith Meulendijks of Netherlands 11-2, 11-9 and third seed Gong Ruina took 21 minutes to elimi-nate Tine Rasmussen of Denmark 11-1, 11-1, enabling Chinato claim five quarterfinal places in the women?s singles.?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?.
.
.
??????,????????4?
??,??
.
.
.?
?
?
?
?
?
?
?
?
?
?
?
11:1?
?
?
?
?
???
????,??????11:2?11:9?????
????????,??????11:4?11:1?
??
??????
?Figure 1: Sample from two stories about an inter-national women?s badminton championship.2 Previous WorkIn previous work on Chinese named-entitytransliteration ?
e.g.
(Meng et al, 2001; Gaoet al, 2004), the problem has been cast as theproblem of producing, for a given Chinese name,an English equivalent such as one might need ina machine translation system.
For example, forthe name ?????
?wei wei-lian-mu-si, onewould like to arrive at the English name V(enus)Williams.
Common approaches include source-channel methods, following (Knight and Graehl,1998) or maximum-entropy models.Comparable corpora have been studied exten-sively in the literature (e.g.,(Fung, 1995; Rapp,1995; Tanaka and Iwasaki, 1996; Franz et al,1998; Ballesteros and Croft, 1998; Masuichi et al,2000; Sadat et al, 2003)), but transliteration in thecontext of comparable corpora has not been welladdressed.The general idea of exploiting frequency corre-lations to acquire word translations from compara-ble corpora has been explored in several previousstudies (e.g., (Fung, 1995; Rapp, 1995; Tanakaand Iwasaki, 1996)).Recently, a method based onPearson correlation was proposed to mine wordpairs from comparable corpora (Tao and Zhai,2005), an idea similar to the method used in (Kayand Roscheisen, 1993) for sentence alignment.
Inour work, we adopt the method proposed in (Taoand Zhai, 2005) and apply it to the problem oftransliteration.
We also study several variations ofthe similarity measures.Mining transliterations from multilingual webpages was studied in (Zhang and Vines, 2004);Our work differs from this work in that we usecomparable corpora (in particular, news data) andleverage the time correlation information naturallyavailable in comparable corpora.3 Chinese Transliteration withComparable CorporaWe assume that we have comparable corpora, con-sisting of newspaper articles in English and Chi-nese from the same day, or almost the same day.
Inour experiments we use data from the English andChinese stories from the Xinhua News agency forabout 6 months of 2001.2 We assume that we haveidentified names for persons and locations?twotypes that have a strong tendency to be translit-erated wholly or mostly phonetically?in the En-glish text; in this work we use the named-entityrecognizer described in (Li et al, 2004), whichis based on the SNoW machine learning toolkit(Carlson et al, 1999).To perform the transliteration task, we proposethe following general three-step approach:1.
Given an English name, identify candi-date Chinese character n-grams as possibletransliterations.2.
Score each candidate based on how likely thecandidate is to be a transliteration of the En-glish name.
We propose two different scoringmethods.
The first involves phonetic scoring,and the second uses the frequency profile ofthe candidate pair over time.
We will showthat each of these approaches works quitewell, but by combining the approaches onecan achieve even better results.3.
Propagate scores of all the candidate translit-eration pairs globally based on their co-occurrences in document pairs in the compa-rable corpora.The intuition behind the third step is the following.Suppose several high-confidence name transliter-ation pairs occur in a pair of English and Chi-nese documents.
Intuitively, this would increaseour confidence in the other plausible translitera-tion pairs in the same document pair.
We thus pro-pose a score propagation method to allow thesehigh-confidence pairs to propagate some of their2Available from the LDC via the English Gigaword(LDC2003T05) and Chinese Gigaword (LDC2003T09) cor-pora.74scores to other co-occurring transliteration pairs.As we will show later, such a propagation strat-egy can generally further improve the translitera-tion accuracy; in particular, it can further improvethe already high performance from combining thetwo scoring methods.3.1 Candidate SelectionThe English named entity candidate selection pro-cess was already described above.
Candidate Chi-nese transliterations are generated by consultinga list of characters that are frequently used fortransliterating foreign names.
As discussed else-where (Sproat et al, 1996), a subset of a few hun-dred characters (out of several thousand) tends tobe used overwhelmingly for transliterating foreignnames into Chinese.
We use a list of 495 suchcharacters, derived from various online dictionar-ies.
A sequence of three or more characters fromthe list is taken as a possible name.
If the character???
occurs, which is frequently used to representthe space between parts of an English name, thenat least one character to the left and right of thischaracter will be collected, even if the character inquestion is not in the list of ?foreign?
characters.Armed with the English and Chinese candidatelists, we then consider the pairing of every En-glish candidate with every Chinese candidate.
Ob-viously it would be impractical to do this for all ofthe candidates generated for, say, an entire year:we consider as plausible pairings those candidatesthat occur within a day of each other in the twocorpora.3.2 Candidate scoring based onpronunciationWe adopt a source-channel model for scoringEnglish-Chinese transliteration pairs.
In general,we seek to estimate P (e|c), where e is a word inRoman script, and c is a word in Chinese script.Since Chinese transliteration is mostly based onpronunciation, we estimate P (e?|c?
), where e?
isthe pronunciation of e and c?
is the pronunciationof c. Again following standard practice, we de-compose the estimate of P (e?|c?)
as P (e?|c?)
=?i P (e?i|c?i).
Here, e?i is the ith subsequence ofthe English phone string, and c?i is the ith subse-quence of the Chinese phone string.
Since Chi-nese transliteration attempts to match the syllable-sized characters to equivalent sounding spans ofthe English language, we fix the c?i to be syllables,and let the e?i range over all possible subsequencesof the English phone string.
For training data wehave a small list of 721 names in Roman script andtheir Chinese equivalent.3 Pronunciations for En-glish words are obtained using the Festival text-to-speech system (Taylor et al, 1998); for Chinese,we use the standard pinyin transliteration of thecharacters.
English-Chinese pairs in our trainingdictionary were aligned using the alignment algo-rithm from (Kruskal, 1999), and a hand-derivedset of 21 rules-of-thumb: for example, we haverules that encode the fact that Chinese /l/ can cor-respond to English /r/, /n/ or /er/; and that Chinese/w/ may be used to represent /v/.
Given that thereare over 400 syllables in Mandarin (not count-ing tone) and each of these syllables can matcha large number of potential English phone spans,this is clearly not enough training data to cover allthe parameters, and so we use Good-Turing esti-mation to estimate probabilities for unseen corre-spondences.
Since we would like to filter implau-sible transliteration pairs we are less lenient thanstandard estimation techniques in that we are will-ing to assign zero probability to some correspon-dences.
Thus we set a hard rule that for an En-glish phone span to correspond to a Chinese sylla-ble, the initial phone of the English span must havebeen seen in the training data as corresponding tothe initial of the Chinese syllable some minimumnumber of times.
For consonant-initial syllableswe set the minimum to 4.
We omit further detailsof our estimation technique for lack of space.
Thisphonetic correspondence model can then be usedto score putative transliteration pairs.3.3 Candidate Scoring based on FrequencyCorrelationNames of the same entity that occur in differentlanguages often have correlated frequency patternsdue to common triggers such as a major event.Thus if we have comparable news articles over asufficiently long time period, it is possible to ex-ploit such correlations to learn the associations ofnames in different languages.
The idea of exploit-ing frequency correlation has been well studied.
(See the previous work section.)
We adopt themethod proposed in (Tao and Zhai, 2005), which3The LDC provides a much larger list of transliteratedChinese-English names, but we did not use this here for tworeasons.
First, we have found it it be quite noisy.
Secondly,we were interested in seeing how well one could do with alimited resource of just a few hundred names, which is a morerealistic scenario for languages that have fewer resources thanEnglish and Chinese.75works as follows: We pool all documents in a sin-gle day to form a large pseudo-document.
Then,for each transliteration candidate (both Chineseand English), we compute its frequency in eachof those pseudo-documents and obtain a raw fre-quency vector.
We further normalize the raw fre-quency vector so that it becomes a frequency dis-tribution over all the time points (days).
In orderto compute the similarity between two distributionvectors, The Pearson correlation coefficient wasused in (Tao and Zhai, 2005); here we also consid-ered two other commonly used measures ?
cosine(Salton and McGill, 1983), and Jensen-Shannondivergence (Lin, 1991), though our results showthat Pearson correlation coefficient performs bet-ter than these two other methods.3.4 Score PropagationIn both scoring methods described above, scoringof each candidate transliteration pair is indepen-dent of the other.
As we have noted, documentpairs that contain lots of plausible transliterationpairs should be viewed as more plausible docu-ment pairs; at the same time, in such a situation weshould also trust the putative transliteration pairsmore.
Thus these document pairs and translitera-tion pairs mutually ?reinforce?
each other, and thiscan be exploited to further optimize our translit-eration scores by allowing transliteration pairs topropagate their scores to each other according totheir co-occurrence strengths.Formally, suppose the current generation oftransliteration scores are (ei, ci, wi) i = 1, ..., n,where (ei, ci) is a distinct pair of English and Chi-nese names.
Note that although for any i 6= j, wehave (ei, ci) 6= (ej , cj), it is possible that ei = ejor ci = cj for some i 6= j. wi is the transliterationscore of (ei, ci).These pairs along with their co-occurrence re-lation computed based on our comparable cor-pora can be formally represented by a graph asshown in Figure 2.
In such a graph, a node repre-sents (ei, ci, wi).
An edge between (ei, ci, wi) and(ej , cj , wj) is constructed iff (ei, ci) and (ej , cj)co-occur in a certain document pair (Et, Ct), i.e.there exists a document pair (Et, Ct), such thatei, ej ?
Et and ci, cj ?
Ct.
Given a node(ei, ci, wi), we refer to all its directly-connectednodes as its ?neighbors?.
The documents do notappear explicitly in the graph, but they implicitlyaffect the graph?s topology and the weight of eachedge.
Our idea of score propagation can now beformulated as the following recursive equation forw1w4w2w3w5w6w7(e4, c4)(e3, c3)(e5, c5)(e5, c5)(e2, c2)(e7, c7)(e6, c6)Figure 2: Graph representing transliteration pairsand cooccurence relations.updating the scores of all the transliteration pairs.w(k)i = ??
w(k?1)i + (1 ?
?)
?n?j 6=i,j=1(w(k?1)j ?
P (j|i)),where w(k)i is the new score of the pair (ei, ci)after an iteration, while w(k?1)i is its old scorebefore updating; ?
?
[0, 1] is a parameter tocontrol the overall amount of propagation (when?
= 1, no propagation occurs); P (j|i) is the con-ditional probability of propagating a score fromnode (ej , cj , wj) to node (ei, ci, wi).We estimate P (j|i) in two different ways: 1)The number of cooccurrences in the whole collec-tion (Denote as CO).
P (j|i) = C(i,j)?j?
C(i,j?
), whereC(i, j) is the cooccurrence count of (ei, ci) and(ej , cj); 2) A mutual information-based method(Denote as MI).
P (j|i) = MI(i,j)?j?
MI(i,j?
), whereMI(i, j) is the mutual information of (ei, ci) and(ej , cj).
As we will show, the CO method worksbetter.
Note that the transition probabilities be-tween indirect neighbors are always 0.
Thus prop-agation only happens between direct neighbors.This formulation is very similar to PageRank,a link-based ranking algorithm for Web retrieval(Brin and Page, 1998).
However, our motivationis propagating scores to exploit cooccurrences, sowe do not necessarily want the equation to con-verge.
Indeed, our results show that although theinitial iterations always help improve accuracy, toomany iterations actually would decrease the per-formance.4 EvaluationWe use a comparable English-Chinese corpus toevaluate our methods for Chinese transliteration.We take one day?s worth of comparable news arti-cles (234 Chinese stories and 322 English stories),generate about 600 English names with the entityrecognizer (Li et al, 2004) as described above, and76find potential Chinese transliterations also as pre-viously described.
We generated 627 Chinese can-didates.
In principle, all these 600 ?
627 pairs arepotential transliterations.
We then apply the pho-netic and time correlation methods to score andrank all the candidate Chinese-English correspon-dences.To evaluate the proposed transliteration meth-ods quantitatively, we measure the accuracy of theranked list by Mean Reciprocal Rank (MRR), ameasure commonly used in information retrievalwhen there is precisely one correct answer (Kan-tor and Voorhees, 2000).
The reciprocal rank isthe reciprocal of the rank of the correct answer.For example, if the correct answer is ranked as thefirst, the reciprocal rank would be 1.0, whereas ifit is ranked the second, it would be 0.5, and soforth.
To evaluate the results for a set of Englishnames, we take the mean of the reciprocal rank ofeach English name.We attempted to create a complete set of an-swers for all the English names in our test set,but a small number of English names do not seemto have any standard transliteration according tothe resources that we consulted.
We ended upwith a list of about 490 out of the 600 Englishnames judged.
We further notice that some an-swers (about 20%) are not in our Chinese candi-date set.
This could be due to two reasons: (1) Theanswer does not occur in the Chinese news articleswe look at.
(2) The answer is there, but our candi-date generation method has missed it.
In order tosee more clearly how accurate each method is forranking the candidates, we also compute the MRRfor the subset of English names whose transliter-ation answers are in our candidate list.
We dis-tinguish the MRRs computed on these two sets ofEnglish names as ?AllMRR?
and ?CoreMRR?.Below we first discuss the results of each of thetwo methods.
We then compare the two methodsand discuss results from combining the two meth-ods.4.1 Phonetic CorrespondenceWe show sample results for the phonetic scoringmethod in Table 1.
This table shows the 10 high-est scoring transliterations for each Chinese char-acter sequence based on all texts in the Chineseand English Xinhua newswire for the 13th of Au-gust, 2001.
8 out of these 10 are correct.
For allthe English names the MRR is 0.3, and for the?paris ???
pei-lei-si 3.51iraq ???
yi-la-ke 3.74staub ???
si-ta-bo 4.45canada ?
?
jia-na-da 4.85belfast ?????
bei-er-fa-si-te 4.90fischer ???
fei-she-er 4.91philippine ???
fei-lu?-bin 4.97lesotho ??
lai-suo-two 5.12?tirana ???
tye-lu-na 5.15freeman ???
fu-li-man 5.26Table 1: Ten highest-scoring matches for the Xin-hua corpus for 8/13/01.
The final column is the?log P estimate for the transliteration.
Starredentries are incorrect.core names it is 0.89.
Thus on average, the cor-rect answer, if it is included in our candidate list,is ranked mostly as the first one.4.2 Frequency correlationSimilarity AllMRR CoreMRRPearson 0.1360 0.3643Cosine 0.1141 0.3015JS-div 0.0785 0.2016Table 2: MRRs of the frequency correlation meth-ods.We proposed three similarity measures for thefrequency correlation method, i.e., the Cosine,Pearson coefficient, and Jensen-Shannon diver-gence.
In Table 2, we show their MRRs.
Giventhat the only resource the method needs is compa-rable text documents over a sufficiently long pe-riod, these results are quite encouraging.
For ex-ample, with Pearson correlation, when the Chinesetransliteration of an English name is included inour candidate list, the correct answer is, on aver-age, ranked at the 3rd place or better.
The resultsthus show that the idea of exploiting frequencycorrelation does work.
We also see that amongthe three similarity measures, Pearson correlationperforms the best; it performs better than Cosine,which is better than JS-divergence.Compared with the phonetic correspondencemethod, the performance of the frequency correla-tion method is in general much worse, which is notsurprising, given the fact that terms may be corre-lated merely because they are topically related.774.3 Combination of phonetic correspondenceand frequency correlationMethod AllMRR CoreMRRPhonetic 0.2999 0.8895Freq 0.1360 0.3643Freq+PhoneticFilter 0.3062 0.9083Freq+PhoneticScore 0.3194 0.9474Table 3: Effectiveness of combining the two scor-ing methods.Since the two methods exploit complementaryresources, it is natural to see if we can improveperformance by combining the two methods.
In-deed, intuitively the best candidate is the one thathas a good pronunciation alignment as well as acorrelated frequency distribution with the Englishname.
We evaluated two strategies for combiningthe two methods.
The first strategy is to use thephonetic model to filter out (clearly impossible)candidates and then use the frequency correlationmethod to rank the candidates.
The second is tocombine the scores of these two methods.
Sincethe correlation coefficient has a maximum valueof 1, we normalize the phonetic correspondencescore by dividing all scores by the maximum scoreso that the maximum normalized value is also 1.We then take the average of the two scores andrank the candidates based on their average scores.Note that the second strategy implies the applica-tion of the first strategy.The results of these two combination strategiesare shown in Table 3 along with the results of thetwo individual methods.
We see that both com-bination strategies are effective and the MRRs ofthe combined results are all better than those of thetwo individual methods.
It is interesting to see thatthe benefit of applying the phonetic correspon-dence model as a filter is quite significant.
Indeed,although the performance of the frequency corre-lation method alone is much worse than that of thephonetic correspondence method, when workingon the subset of candidates passing the phoneticfilter (i.e., those candidates that have a reasonablephonetic alignment with the English name), it canoutperform the phonetic correspondence method.This once again indicates that exploiting the fre-quency correlation can be effective.
When com-bining the scores of these two methods, we notonly (implicitly) apply the phonetic filter, but alsoexploit the discriminative power provided by thephonetic correspondence scores and this is shownto bring in additional benefit, giving the best per-formance among all the methods.4.4 Error AnalysisFrom the results above, we see that the MRRs forthe core English names are substantially higherthan those for all the English names.
This meansthat our methods perform very well whenever wehave the answer in our candidate list, but we havealso missed the answers for many English names.The missing of an answer in the candidate list isthus a major source of errors.
To further under-stand the upper bound of our method, we manu-ally add the missing correct answers to our can-didate set and apply all the methods to rank thisaugmented set of candidates.
The performance isreported in Table 4 with the corresponding perfor-mance on the original candidate set.
We see that,Method ALLMRROriginal AugmentedPhonetic 0.2999 0.7157Freq 0.1360 0.3455Freq+PhoneticFilter 0.3062 0.6232Freq+PhoneticScore 0.3194 0.7338Table 4: MRRs on the augmented candidate list.as expected, the performance on the augmentedcandidate list, which can be interpreted as an up-per bound of our method, is indeed much better,suggesting that if we can somehow improve thecandidate generation method to include the an-swers in the list, we can expect to significantly im-prove the performance for all the methods.
Thisis clearly an interesting topic for further research.The relative performance of different methods onthis augmented candidate list is roughly the sameas on the original candidate list, except that the?Freq+PhoneticFilter?
is slightly worse than thatof the phonetic method alone, though it is stillmuch better than the performance of the frequencycorrelation alone.
One possible explanation maybe that since these names do not necessarily oc-cur in our comparable corpora, we may not havesufficient frequency observations for some of thenames.78Method AllMRR CoreMRRinit.
CO MI init.
CO MIFreq+PhoneticFilter 0.3171 0.3255 0.3255 0.9058 0.9372 0.9372Freq+PhoneticScore 0.3290 0.3373 0.3392 0.9422 0.9659 0.9573Table 5: Effectiveness of score propagation.4.5 Experiments on score propagationTo demonstrate that score propagation can furtherhelp transliteration, we use the combination scoresin Table 3 as the initial scores, and apply our prop-agation algorithm to iteratively update them.
Weremove the entries when they do not co-occur withothers.
There are 25 such English name candi-dates.
Thus, the initial scores are actually slightlydifferent from the values in Table 3.
We showthe new scores and the best propagation scores inTable 5.
In the table, ?init.?
refers to the initialscores.
and ?CO?
and ?MI?
stand for best scoresobtained using either the co-occurrence or mutualinformation method.
While both methods resultin gains, CO very slightly outperforms the MI ap-proach.
In the score propagation process, we in-troduce two additional parameters: the interpola-tion parameter ?
and the number of iterations k.Figure 3 and Figure 4 show the effects of theseparameters.
Intuitively, we want to preserve theinitial score of a pair, but add a slight boost fromits neighbors.
Thus, we set ?
very close to 1 (0.9and 0.95), and allow the system to perform 20 it-erations.
In both figures, the first few iterationscertainly leverage the transliteration, demonstrat-ing that the propagation method works.
However,we observe that the performance drops when moreiterations are used, presumably due to noise intro-duced from more distantly connected nodes.
Thus,a relatively conservative approach is to choose ahigh ?
value, and run only a few iterations.
Note,finally, that the CO method seems to be more sta-ble than the MI method.5 Conclusions and Future WorkIn this paper we have discussed the problem ofChinese-English name transliteration as one com-ponent of a system to find matching names in com-parable corpora.
We have proposed two methodsfor transliteration, one that is more traditional andbased on phonetic correspondences, and one thatis based on word distributions and adopts meth-ods from information retrieval.
We have shown0.760.780.80.820.840.860.880.90.920.940.960.980  2  4  6  8  10  12  14  16  18  20MRRvaluesnumber of iterationsalpha=0.9, MIalpha=0.9, COalpha=0.95, MIalpha=0.95, COFigure 3: Propagation: Core itemsthat both methods yield good results, and that evenbetter results can be achieved by combining themethods.
We have further showed that one canimprove upon the combined model by using rein-forcement via score propagation when translitera-tion pairs cluster together in document pairs.The work we report is ongoing.
We are inves-tigating transliterations among several languagepairs, and are extending these methods to Ko-rean, Arabic, Russian and Hindi ?
see (Tao et al,2006).6 AcknowledgmentsThis work was funded by Dept.
of the Interior con-tract NBCHC040176 (REFLEX).
We also thankthree anonymous reviewers for ACL06.ReferencesLisa Ballesteros and W. Bruce Croft.
1998.
Resolv-ing ambiguity for cross-language retrieval.
In Re-search and Development in Information Retrieval,pages 64?71.Sergey Brin and Lawrence Page.
1998.
The anatomyof a large-scale hypertextual Web search engine.Computer Networks and ISDN Systems, 30:107?117.790.280.290.30.310.320.330.340  2  4  6  8  10  12  14  16  18  20MRRvaluesnumber of iterationsalpha=0.9, MIalpha=0.9, COalpha=0.95, MIalpha=0.95, COFigure 4: Propagation: All itemsA.
Carlson, C. Cumby, J. Rosen, and D. Roth.
1999.The SNoW learning architecture.
Technical ReportUIUCDCS-R-99-2101, UIUC CS Dept.Martin Franz, J. Scott McCarley, and Salim Roukos.1998.
Ad hoc and multilingual information retrievalat IBM.
In Text REtrieval Conference, pages 104?115.Pascale Fung.
1995.
A pattern matching methodfor finding noun and proper noun translations fromnoisy parallel corpora.
In Proceedings of ACL 1995,pages 236?243.W.
Gao, K.-F. Wong, and W. Lam.
2004.
Phoneme-based transliteration of foreign names for OOVproblem.
In IJCNLP, pages 374?381, Sanya,Hainan.P.
Kantor and E. Voorhees.
2000.
The TREC-5 confu-sion track: Comparing retrieval methods for scannedtext.
Information Retrieval, 2:165?176.M.
Kay and M. Roscheisen.
1993.
Text translationalignment.
Computational Linguistics, 19(1):75?102.K.
Knight and J. Graehl.
1998.
Machine translitera-tion.
CL, 24(4).J.
Kruskal.
1999.
An overview of sequence compar-ison.
In D. Sankoff and J. Kruskal, editors, TimeWarps, String Edits, and Macromolecules, chapter 1,pages 1?44.
CSLI, 2nd edition.X.
Li, P. Morie, and D. Roth.
2004.
Robust reading:Identification and tracing of ambiguous names.
InNAACL-2004.J.
Lin.
1991.
Divergence measures based on the shan-non entropy.
IEEE Transactions on InformationTheory, 37(1):145?151.H.
Masuichi, R. Flournoy, S. Kaufmann, and S. Peters.2000.
A bootstrapping method for extracting bilin-gual text pairs.H.M.
Meng, W.K Lo, B. Chen, and K. Tang.
2001.Generating phonetic cognates to handle named enti-ties in English-Chinese cross-languge spoken doc-ument retrieval.
In Proceedings of the AutomaticSpeech Recognition and Understanding Workshop.R.
Rapp.
1995.
Identifying word translations in non-parallel texts.
In Proceedings of ACL 1995, pages320?322.Fatiha Sadat, Masatoshi Yoshikawa, and Shunsuke Ue-mura.
2003.
Bilingual terminology acquisition fromcomparable corpora and phrasal translation to cross-language information retrieval.
In ACL ?03, pages141?144.G.
Salton and M. McGill.
1983.
Introduction to Mod-ern Information Retrieval.
McGraw-Hill.R.
Sproat, C. Shih, W. Gale, and N. Chang.
1996.
Astochastic finite-state word-segmentation algorithmfor Chinese.
CL, 22(3).K.
Tanaka and H. Iwasaki.
1996.
Extraction of lexicaltranslation from non-aligned corpora.
In Proceed-ings of COLING 1996.Tao Tao and ChengXiang Zhai.
2005.
Mining compa-rable bilingual text corpora for cross-language infor-mation integration.
In KDD?05, pages 691?696.Tao Tao, Su-Youn Yoon, Andrew Fister, RichardSproat, and ChengXiang Zhai.
2006.
Unsupervisednamed entity transliteration using temporal and pho-netic correlation.
In EMNLP 2006, Sydney, July.P.
Taylor, A.
Black, and R. Caley.
1998.
The archi-tecture of the Festival speech synthesis system.
InProceedings of the Third ESCA Workshop on SpeechSynthesis, pages 147?151, Jenolan Caves, Australia.Ying Zhang and Phil Vines.
2004.
Using the web forautomated translation extraction in cross-languageinformation retrieval.
In SIGIR ?04, pages 162?169.80
