Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 1054?1063,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsCo-training for Semi-supervised Sentiment Classification Based onDual-view Bags-of-words RepresentationRui Xia1,2, Cheng Wang1, Xinyu Dai2, and Tao Li3,41School of Computer Science, Nanjing University of Science & Technology, China2State Key Laboratory for Novel Software Technology, Nanjing University, China3School of Computer Science, Florida International University, USA4School of Computer Science, Nanjing University of Posts & Telecommunications, Chinarxia@njust.edu.cn, wangcheng1022@gmail.com,daixinyu@nju.edu.cn, taoli@cs.fiu.eduAbstractA review text is normally represented asa bag-of-words (BOW) in sentiment clas-sification.
Such a simplified BOW modelhas fundamental deficiencies in modelingsome complex linguistic phenomena suchas negation.
In this work, we propose adual-view co-training algorithm based ondual-view BOW representation for semi-supervised sentiment classification.
Indual-view BOW, we automatically con-struct antonymous reviews and model areview text by a pair of bags-of-wordswith opposite views.
We make use of theoriginal and antonymous views in pairs,in the training, bootstrapping and test-ing process, all based on a joint observa-tion of two views.
The experimental re-sults demonstrate the advantages of our ap-proach, in meeting the two co-training re-quirements, addressing the negation prob-lem, and enhancing the semi-supervisedsentiment classification efficiency.1 IntroductionIn the past decade, there has been an explosionof user-generated subjective texts on the Internetin forms of online reviews, blogs and microblogs.With the need of automatically identifying senti-ments and opinions from those online texts, senti-ment classification has attracted much attention inthe field of natural language processing.Lots of previous research focused on the taskof supervised sentiment classification.
However,in some domains, it is hard to obtain a sufficientamount of labeled training data.
Manual annota-tion is also very expensive and time-consuming.To address this problem, semi-supervised learningapproaches were employed in sentiment classifica-tion, to reduce the need for labeled reviews by tak-ing advantage of unlabeled reviews.The dominating text representation method inboth supervised and semi-supervised sentimentclassification is known as the bag-of-words (BOW)model, which is difficult to meet the requirementsfor understanding the review text and dealing withcomplex linguistic structures such as negation.
Forexample, the BOW representations of two oppositereviews ?It works well?
and ?It doesn?t work well?are considered to be very similar by most statisticallearning algorithms.In supervised sentiment classification, many ap-proaches have been proposed in addressing thenegation problem (Pang et al, 2002; Na et al,2004; Polanyi and Zaenen , 2004; Kennedy andInkpen, 2006; Ikeda et al, 2008; Li et al, 2010b;Orimaye et al, 2012; Xia et al, 2013).
Nev-ertheless, in semi-supervised sentiment classifica-tion, most of the current approaches directly ap-ply standard semi-supervised learning algorithms,without paying attention to appropriate representa-tion for review texts.
For example, Aue and Ga-mon (2005) applied the na?
?ve Bayes EM algorithm(Nigam et al, 2000).
Goldberg and Zhu (2006) ap-plied a graph-based semi-supervised learning algo-rithm by (Zhu et al, 2003).
Wan (2009) employeda co-training approach for cross-language senti-ment classification.
Li et al (2010a) employed co-training with personal and impersonal views.
Renet al (2011) explored the use of label propagation(Zhu and Ghahramani, 2002).As pointed by (Goldberg and Zhu, 2006): it isnecessary to investigate better review text represen-tations and similarity measures based on linguis-tic knowledge, as well as reviews?
sentiment pat-terns.
However, to the best knowledge, such inves-tigations are very scarce in the research of semi-1054supervised sentiment classification.In (Xia et al, 2013), we have developed adual sentiment analysis approach, which createsantonymous reviews and makes use of original andantonymous reviews together for supervised sen-timent classification.
In this work, we proposea dual-view co-training approach based on dual-view BOW representation for semi-supervised sen-timent classification.
Specifically, we model boththe original and antonymous reviews by a pair ofbags-of-words with opposite views.
Based on sucha dual-view representation, we design a dual-viewco-training approach.
The training, bootstrappingand testing processes are all performed by observ-ing two opposite sides of one review.
That is, weconsider not only how positive/negative the orig-inal review is, but also how negative/positive theantonymous review is.In comparison with traditional methods, ourdual-view co-training approach has the followingadvantages:?
Effectively address the negation problem;?
Automatically learn the associations amongantonyms;?
Better meet the two co-training requirementsin (Blum and Mitchell, 1998).2 Related WorkThe mainstream of the research in sentiment clas-sification focused on supervised and unsupervisedlearning tasks.
In comparison, semi-supervisedsentiment classification has much less related stud-ies.
In this section, we focus on reviewing the workof semi-supervised sentiment classification.Aue and Gamon (2005) combined a smallamount of labeled data with a large amount ofunlabeled data in target domain for cross-domainsentiment classification based on the EM algo-rithm.
Goldberg and Zhu (2006) presented a graph-based semi-supervised learning algorithm (Zhu etal., 2003) for the sentiment analysis task of rat-ing inference.
Dasgupta and Ng (2009) proposeda semi-supervised approach to mine the unambigu-ous reviews at first and then exploiting them toclassify the ambiguous reviews, via a combinationof active learning, transductive learning and en-semble learning.
Ren et al (2011) explored theuse of label propagation (LP) (Zhu and Ghahra-mani, 2002) in building a semi-supervised senti-ment classifier, and compared their results withTransductive SVMs(T-SVM).
LP and T-SVM aretransductive learning methods where the test datashould participate in the training process.Zhou et al (2010) proposed a deep learningapproach called active deep networks to addresssemi-supervised sentiment classification with ac-tive learning.
Socher et al (2012) introduced adeep learning framework called semi-supervisedrecursive autoencoders for predicting sentence-level sentiment distributions.
The limitation ofdeep learning approaches might be their depen-dence on a considerable amount of unlabeled datato learn the representations and the inability to ex-plicitly model the negation problem.One line of semi-supervised learning researchis to bootstrap class labels using techniques likeself-training, co-training and their variations.
Wan(2009) proposed a co-training approach to addressthe cross-lingual sentiment classification problem.They made use of the machine translation serviceto produce two views (a English view and a Chi-nese view) for co-training a Chinese review senti-ment classifier, based on English corpus and unla-beled Chinese corpus.
Li et al (2010a) proposedan unsupervised method at first to automaticallyseparate the review text into a personal view and animpersonal view, based on which the standard co-training algorithm is then applied to build a semi-supervised sentiment classifier.
Li et al (2011)further studied semi-supervised learning for imbal-anced sentiment classification by using a dynamicco-training approach.
Su et al (2012) proposeda multi-view learning approach to semi-supervisedsentiment classification with both feature partitionand language translation strategies (Wan , 2009).Following (Li et al, 2010a), Li (2013) proposeda co-training approach which exploits subjectiveand objective views for semi-supervised sentimentclassification.
Our approach can also be viewed asa variation of co-training.
The innovation of ourapproach is the dual-view construction techniqueby incorporating antonymous reviews and the boot-strapping mechanism by observing two oppositesides of one review.3 The Proposed Approach3.1 Dual-view BOW Representation forReview TextsEvery coin has two sizes.
In this work, we are mo-tivated to automatically construct the antonymousreviews, consider the original and antonymous re-views as two opposite sides of one review, and rep-10551111111011011011appphonedidn'tworkwelldisappointingrecommendsatisfactoryFeatureSpaceOriginalViewAntonymousViewFigure 1: An illustration of the dual-view BOWrepresentation.
The feature vector with black fontcolor and grey background denotes the originalview; while the one with white font color andblack background denotes the reversed antony-mous view.resent them in pairs by a dual-view BOW model.Look at the following example:Original Review: ?The app doesn?twork well on my phone.
Disappointing.Don?t recommend it.
?Antonymous Review: ?The app workswell on my phone.
Satisfactory.
Recom-mend it.
?Given an original review, its antonymous reviewis automatically created as follows1: 1) We first de-tect the negations in each subsentence of the reviewtext; 2) If there is a negation, we remove negatorsin that subsentence; 3) Otherwise, we reverse allthe sentiment words in the subsentence into theirantonyms, according to a pre-defined antonym dic-tionary2.We subsequently use a dual-view BOW model torepresent such a pair of reviews, as shown in Fig-ure 1.
The original and antonymous reviews willbe used in pairs in our dual-view semi-supervisedlearning approach.
As we determine the sentimentof one review, we could observe not only the orig-inal view, but also the antonymous view.1It is worth noting that our emphasis here is not to generatenatural-language-like review texts.
Since either the original orthe created antonymous review will be represented as a vectorof independent words in the BOW model, the grammaticalrequirement is not as strict as that in human languages.2In our experiments, we extract the antonym dic-tionary from the WordNet lexicon http://wordnet.princeton.edu/.Antonymous Viewt s iOriginal ViewAntonymousSentimentC lassif ierOriginalSentimentC lassif ierL ab eledOriginalR ev iewsL ab eledAntonymousR ev iewsU nlab eledOriginalR ev iewsU nlab eledAntonymousR ev iewsR ev iewR ev ersionB ootstrappingR ev iewR ev ersionDual-viewSentimentConsensusD ualSentimentC lassif ierFigure 2: The process of dual-view co-training.Again, the white font color and black backgroundare used to denote the antonymous view.It is important to notice that the antony-mous view removes all negations and incorporatesantonymous features.
On this basis, we design adual-view co-training approach.
We will introduceour approach in detail in Section 3.2, and analyzeits potential advantages in Section 3.3.3.2 The Dual-view Co-training ApproachSince the original and antonymous views form twodifferent views of one review text, it is natural toemploy the co-training algorithm, which requirestwo views for semi-supervised classification.Co-training is a typical bootstrapping algorithmthat first learns a separate classifier for each viewusing the labeled data.
The most confident predic-tions of each classifier on the unlabeled data arethen used to construct additional labeled trainingdata iteratively.
Co-training has been extensivelyused in NLP, including statistical parsing (Sarkar ,2001), reference resolution (Ng and Cardie, 2003),part-of-speech tagging (Clark et al, 2003), wordsense disambiguation (Mihalcea, 2004), and senti-ment classification (Wan , 2009; Li et al, 2010a).But it should be noted that the dual views inour approach are different from traditional views.One important property of our approach is thattwo views are opposite and therefore associatedwith opposite class labels.
Figure 2 illustrates theprocess of dual-view co-training.1056(1) Dual-view trainingFor each instance in the initial labeled set, we con-struct the dual-view representations.
Let xloandxladenote the bags of words in the original viewand the antonymous view, respectively.
Note thatthe class labels in two views are kept opposite:yla= 1 ?
ylo(y ?
{0, 1}).
That is, we reversethe class label in the original view (i.e., positive tonegative, or vice versa), as the class label of thecreated antonymous view.Suppose L is the labeled set, with Loand Ladenoting the original-view and antonymous-viewlabeled sets, respectively.
We train two distinctclassifiers: the original-view classifier hoand theantonymous-view classifier ha, based on LoandLa, respectively.
We further train a joint classifierby using Loand Latogether as the training data,and refer to it as hd.
(2) Dual-view bootstrappingIn standard co-training, we allow each classifier toexamine the unlabeled set U and select the mostconfidently predicted examples in each category.The selected examples are then added into L ,along with the predicted class labels.In this work, we design a dual-view co-trainingalgorithm to bootstrap the class labels by a joint ob-servation of two sides of one review.
Specifically,we propose a new bootstrapping mechanism, basedon a principle called dual-view sentiment consen-sus.
Given an unlabeled instance {xuo, xua}, dualview sentiment consensus requires that, the orig-inal prediction yuoand the antonymous predictionshould be opposite: yua= 1?
yuo.
In other words,we only select the instances of which the originalprediction is positive/negative, and the same timethe antonymous prediction is negative/positive.
Toincrease the degree of sentiment consensus, we fur-ther require that the predition yudof hdshould bethe same as yuo.We sort all unlabeled instances according to thedual-view predictions in each class, filter the listaccording to the dual-view sentiment consensusprinciple, and add the top-ranked s instances ineach class to the labeled set.
For each selected un-labeled instance, its original view xuois added intoLowith class label yuo; and the antonymous viewxuais added into La, with an opposite class labelyua= 1?
yuo.
When Loand Lareceive the supple-mental labeled instances, we update hoand ha.Our bootstrapping mechanism differs from thetraditional methods in two major aspects: First, intraditional co-training, given the same instance,the class labels in two views are the same.
But inour approach, the class labels in two views needto be opposite.
Second, in traditional co-training,the most confidently predicted examples in eachview are selected to extend the amount of labeleddata.
It is dangerous to believe the confident butincorrect predictions.
While in our approach, thecandidates are further filtered by the principle ofdual-view sentiment consensus.
In this way, thelabeling accuracy and learning efficiency can beimproved.
(3) Dual-view testingFinally, in the testing stage, standard co-traininguses a joint set of features in two views to train theclassifier.
In dual-view testing, we use hoand hato predict the test example in two views, and makethe final prediction by considering both sizes of thereview.Given a test example xtewith its original viewdenoted by xteoand antonymous view denotedby xtea, let po(?|xteo) be the posterior probabilitypredicted by the original-view classifier ho, andpa(?|xtea) be the posterior probability predicted byha.
The dual-view testing process can be formu-lated as follows:p(+|xte) = p(+|xteo, xtea) =po(+|xteo) + pa(?|xtea)2;p(?|xte) = p(?|xteo, xtea) =po(?|xteo) + pa(+|xtea)2.That is, the final positive score is assigned bymeasuring not only how positive the original re-view is, but also how negative the antonymous oneis; the negative score is assigned by measuring notonly how positive the original review is, but alsohow negative the antonymous one is.3.3 Advantages of Dual-view Co-trainingOur proposed dual-view co-training approach hasthe following three advantages.
(1) Effectively address the negation issueWe use the antonymous review as a view to effec-tively address the negation issue.
Let us revisit theexample in Section 3.1 and assume that the orig-inal review (i.e., ?The app doesn?t work well onmy phone.
Disappointing.
Do not recommend it.?
)is an unlabeled sample.
Because the traditional1057BOW model cannot well represent negative struc-tures, the review is likely to be incorrectly labeledas positive and then added into the labeled set.In our proposed approach, the antonymous re-view (i.e., ?The app works well on my phone.
Sat-isfactory.
Recommend it.?)
removed all the neg-ative structures, and is thus more suited for theBOW representation.
In this example, the antony-mous review is also likely to be marked as positive.Hence, in this case, both the original review andits antonymous review will be labeled as positive,which violates the principle of dual-view sentimentconsensus as mentioned in Section 3.2.
As a result,the unlabeled instance will not be added into thelabeled set.Therefore, our approach can overcome the limi-tations of the conventional methods in addressingthe negation issue and reduce the labeling errorrate (caused by the negative structures) during thebootstrapping process.
(2) Automatically learn the associations amongantonymsIn semi-supervised sentiment classification, onlylimited association information between the wordsand categories can be obtained from a small num-ber of initial labeled data.For instance, in the above example ?disappoint-ing?
and ?satisfactory?
are a pair of antonyms.From the initial labeled data, we may only learnthat ?disappointing?
is derogatory, but we cannotinfer that ?satisfactory?
is commendatory.During the bootstrapping process in ourapproach, when constructing the dual view rep-resentation, the original view and its antonymousview are required to have opposite class labels.Hence we can automatically infer the relationshipbetween ?satisfactory?
and ?disappointing?
(e.g.,one is positive and one is negative), therebyimproving the learning efficiency of the system.
(3) Better meet two co-training requirementsCompared with traditional methods, our dual-viewco-training can better meet the two co-training re-quirements: 1) sufficient condition (i.e., each viewis sufficient for classification); 2) complementarycondition (i.e., the two views are conditionally in-dependent).First, for the sufficient condition, we use a dif-ferent view construction method.
Most traditionalmethods construct the two views by feature parti-tioning (i.e., dividing the original feature set intotwo subsets), while we use data expansion by gen-erating antonymous reviews.
We will demonstratein the experimental section (Section 4.6), that ourdata expansion method can construct better viewsthan the feature partition method in terms of pre-dicting the class labels from individual views.Second, as we know, every coin has two sidesand the two sides are often complementary.
Inour proposed approach, the original review and itsantonymous review (i.e., two sides of one review)are used as two views for co-training and they canbetter meet the complementary condition.
We willillustrate this point in Section 4.6 by calculating theKL divergence between the two views.4 Experimental Study4.1 Datasets and Experimental SettingsWe conduct the experiments on the multi-domainsentiment datasets, which were introduced in(Blitzer et al, 2007) and have been widely used insentiment classification.
It consists of four domains(Book, DVD, Electronics, and Kitchen) of reviewsextracted from Amazon.com.
Each of the fourdatasets contains 1,000 positive and 1,000 negativereviews.
Following the experimental settings usedin (Li et al, 2010a), we randomly separate all thereviews in each class into a labeled data set, a un-labeled data set, and a test set, with a proportion of10%, 70% and 20%, respectively.
We report the av-eraged results of 10-fold cross-validation in termsof classification accuracy.Note that our approach is a general frameworkthat allows different classification algorithms.
Dueto the space limitation, we only report the results byusing logistic regression3.
Note the similar conclu-sions can be obtained by using the other algorithmssuch as SVMs and na?
?ve Bayes.
The LibLineartoolkit4is utilized, with a dual L2-regularized fac-tor, and a default tradeoff parameter c. Similar to(Wan , 2009; Li et al, 2010a), we carry out the ex-periments with the unigram features without fea-ture selection.
Presence is used as the term weight-ing scheme as it was reported in (Pang et al, 2002)that it performed better than TF and TF-IDF.
Fi-nally, the paired t-test (Yang and Liu , 1999) is per-formed to test the significance of the difference be-3Logistic regression is quite similar to Maximum Entropy,and has been proved to be more efficient in sentiment clas-sification than some other classification algorithms includingna?
?ve Bayes and SVMs (Pang et al, 2002).4http://www.csie.ntu.edu.tw/?cjlin/liblinear/1058BOOK DVD ELEC KITC Avg.Baseline 0.680 0.691 0.726 0.740 0.709LP 0.681 0.676 0.697 0.722 0.694T-SVM 0.671 0.677 0.716 0.729 0.698EM 0.702 0.706 0.758 0.744 0.728Self-Training 0.689 0.705 0.736 0.751 0.720Self-Reserved 0.690 0.708 0.735 0.754 0.722Co-Static 0.696 0.714 0.745 0.762 0.729Co-Dynamic 0.701 0.725 0.756 0.767 0.737Co-PI 0.702 0.716 0.746 0.769 0.733Our approach 0.721 0.738 0.769 0.780 0.752Table 1: The semi-supervised classification accu-racy of ten systems.tween two systems, with a default significant levelof 0.05.4.2 Compared SystemsWe implement the following nine systems andcompare them with our approach:?
Baseline, the supervised baseline trained withthe initial labeled data only;?
Expectation Maximization (EM), with thena?
?ve Bayes model proposed by Nigam et al(2000);?
Label Propagation (LP), a graph-basedsemi-supervised learning method proposed byZhu and Ghahramani (2002);?
Transductive SVM (T-SVM), an extensionof SVM so that it can exploit unlabeled data insemi-supervised learning ( Joachims, 1999);?
Self-Training, a bootstrapping model thatfirst trains a classifier, uses it to classify theunlabeled data, and adds the most confidentdata to the labeled set;?
Self-Reserved, a variation of self-trainingproposed in (Liu et al, 2013),with a reservedprocedure to incorporate some less confidentexamples;?
Co-Static, the co-training algorithm by usingtwo static partitions of feature set as two views(Blum and Mitchell, 1998);?
Co-Dynamic, a variation of co-training thatuses dynamic feature space in each loop.
Itwas reported in (Li et al, 2011) that the Co-Dynamic significantly outperforms Co-Staticsignificantly;?
Co-PI, another variation of co-training pro-posed by (Li et al, 2010a), by using personal0 100 200 300 400 500 600 700 800 900Number of new labeled data bootstrapped from unlabeled set0.690.700.710.720.730.740.75AccuracyPerformance across four datasetsSelf-trainingCo-staticCo-PICo-dynamicOur approachFigure 3: Comparsion of different boostrappingmethods.and impersonal views for co-training.4.3 Performance ComparisonIn table 1, we report the semi-supervised classifica-tion accuracy of ten evaluated systems.
We reportthe results with 200 labeled, 1400 unlabeled and400 test reviews.
Note that the similar conclusionscan be obtained when the size of the initial labeleddata changes.
We will discuss its influence later.As can be seen, trained with only 200 labeleddata, the supervised baseline yields an average ac-curacy of 0.709.
Self-training gains an improve-ment of 1.1%.
Self-reserved does not show sig-nificant priority against Self-training.
Three co-training systems (Co-static, Co-dynamic and Co-PI) get significant improvements.
They increasethe supervised baseline by 2.0%, 2.8% and 2.4%,respectively.It is somehow surprising that T-SVM and LP donot outperform the supervised baseline, probablybecause the supervised baseline is obtained by lo-gistic regression, which was reported to be more ef-fective than SVMs in sentiment classification (thesupervised result of SVMs is 0.695).Our proposed approach significantly outper-forms all the other methods.
It gains the improve-ment over the supervised baseline, Self-training,Co-static, Co-dynamic and Co-PI by 4.3%, 3.2%,2.3%, 1.5% and 1.9%, respectively.
All of the im-provements are significant according to the pairedt-test.4.4 Comparison of Bootstrapping MethodsIn Figure 3, we further compare five bootstrap-ping methods by drawing the accuracy curve dur-10590.550.60.650.70.750.820 50 100 150 200 300 400Supervised Co-Dynamic Co-PI Our ApproachFigure 4: Influence of the size of initial labeleddata.ing the bootstrapping process.
The x-axis denotesthe number of new labeled data bootstrapped fromthe unlabeled data.We can roughly rank five bootstrapping methodsas follows: Our approach  Co-dynamic > Co-PI > Co-static Self-training.
Self-training givesthe worst performance.
Co-static works better butthe effect is limited.
Co-PI and Co-dynamic aresignificantly better.
Our proposed approach outper-forms the other systems robustly, along with the in-creased number of the new labeled data.
It suggeststhat our approach is very efficient in bootstrappingthe class labels from the unlabeled data.4.5 Influence of the Size of the Initial LabeledSetThe above results are obtained with 200 labeled,1400 unlabeled and 400 test reviews.
We now tunethe size of the initial labeled set (from 20 to 400),and report its influence in Figure 4.
For all the set-tings, we fix the size of test set as 400.
The x-axisdenotes the number of initial labeled set.
For ex-ample, ?20?
denotes the setting of 20 labeled and1580 unlabeled data.We can observe that our all methods improve asthe initial size increases.
But the improvements be-come limited when the size becomes larger.
Whenthe initial size is 400, the semi-supervised perfor-mance is close to the golden result obtained by thesupervised classifier trained with all 1600 labeleddata.Our approach performs consistently the bestacross different sizes of the initial sizes.
Thesmaller the initial size is, the more improvementsour approach can gain, in comparison with theother methods.
This confirms our analysis in Sec-tion 3.3 that the technique of dual-view construc-tion is very effective to boost the semi-supervised0 200 400 600 800 1000Number of new labeled data bootstrapped from unlabeled set0.600.620.640.660.680.700.720.74AccuracyDVDCo-PI-view1Co-PI-view2Co-PIOriginal viewAntonymous viewDual-view testing0 200 400 600 800 1000Number of new labeled data bootstrapped from unlabeled set0.640.660.680.700.720.740.760.78AccuracyELECCo-PI-view1Co-PI-view2Co-PIOriginal viewAntonymous viewDual-view testingFigure 5: Comparison of different views on theDVD and Electronics datasets.classification performance, especially when thesize of the initial labeled set is small.4.6 Discussion on the Two Co-trainingRequirementsIdeally, co-training requires that each view issufficient for classification (sufficient condition)and two views provide complementary informa-tion of the instance,(complementary condition).Inthis section, we answer the following questionempirically: whether our approach could meet thetwo requirements?
(1) Sufficient conditionIn Figure 5, we report the classification perfor-mance obtained by the classifiers trained with dis-tinct views and compared them with the two viewsin Co-PI, on the DVD and Electronics datasets.The observation in Book is similar to that in Elec-tronics; the observation in DVD is similar to that inKitchen.Seen from Figure 5, the classification perfor-mance of both the original-view and antonymous-view classifiers are satisfactory.
It shows that in1060our approach, each individual view is sufficient topredict the sentiment.
In comparison with the twoviews in Co-PI (i.e., the personal and impersonalviews), two views in our approach perform signifi-cantly better.As has been mentioned in Section 3.3, in tradi-tional methods, such as Co-PI and Co-dynamic,two views are created by data partition (or featurepartition).
In comparison, the two views in ourapproach are constructed in a manner of data ex-pansion.
By creating a new antonymous view, ourapproach can provide more sufficient informationof the reviews than traditional methods.
(2) Complementary conditionSince we have not found a direct measure of thecomplementarity of two views, we instead calcu-late the Kullback-Leibler (KL) divergence betweenthem, based on an assumption that two views withhigher KL divergence can provide more comple-mentary information of the instance.KL divergence is a widely used metric of statis-tical distance.
We assume that distribution of thereview text is multinomial, and calculate the K-Ldivergence between two views as follows:DKL(p||q) =V?i=1pilog(piqi)where piand qiare the probabilities of word ap-pearing in two views, respectively.
In our ex-periments, we use information gain (IG) to selecta set of discriminative words with the dimensionV = 2000.In Table 2, we report the results of three differ-ent methods: 1) dataset random partition; 2) per-sonal and impersonal views in Co-PI; 3) originaland antonymous views in our approach.
We canobserve from Table 2 that, random partition hasthe lowest KL divergence.
It shows that the dis-tributional distance between two randomly parti-tioned views is very small.
Co-PI is a higher value,but it still does not have significant difference intwo views.
By contrast, the KL divergence be-tween the original view and the antonymous viewis much higher than both random partition and Co-PI.
It demonstrates that the distributions of twoviews in our approach are significantly different.We thereby infer that the two views constructed inour approach can provide more complementary in-formation than traditional methods.
It is reason-able since the antonymous view incorporates theKL divergenceRandom Partition 2.43Co-PI 4.59Our approach 12.33Table 2: The average KL divergence between twoviews across four datasets.antonyms that might have not appeared in the origi-nal view (e.g., ?satisfactory?
in the example in Sec-tion 3.2).
These features might provide new infor-mation about the instance.4.7 The Effect of Dual-view TestingIn Figure 5, we can further observe the effect ofdual-view testing.
On the Electronics dataset, theantonymous view performs better than the orig-inal view.
This suggests the advantage of theantonymous view, as it removes the negations andthus is more suitable for the BOW representa-tion.
On the DVD dataset, the original view isslightly better.
This is also reasonablel, because theantonymous review is automatically created and itsquality might be limited in some cases.
By tak-ing two opposite views into a joint consideration,our dual-view testing technique guarantees a satis-factory classification performance across differentdatasets.Note that in the current version, the original-view and antonymous-view classifiers have thesame predicting weight.
We believe that by learn-ing the tradeoff between two views in different set-tings may further improve our approach?s perfor-mance.
For example, if the original view on theElectronics dataset gets a relatively larger weight,dual-view testing might gain more improvements.5 ConclusionsIn this work, a review text is represented by apair of bags-of-words with opposite views (i.e., theoriginal and antonymous views).
By making useof two views in pairs, a dual-view co-training al-gorithm is proposed for semi-supervised sentimentclassification.
The dual-view representation is in agood accordance with the two co-training require-ments (i.e., sufficient condition and complemen-tary condition).
The experimental results demon-strate the effect of our approach, in addressing thenegation problem and enhancing the bootstrappingefficiency for semi-supervised sentiment classifica-tion.1061AcknowledgementThe work is supported by the Natural ScienceFoundation of China (61305090), and the JiangsuProvincial Natural Science Foundation of China(BK2012396).ReferencesA.
Aue and M. Gamon.
2005.
Customizing SentimentClassifiers to New Domains: A Case Study.
In Pro-ceedings of Recent Advances in Natural LanguageProcessing.J.
Blitzer, M. Dredze, and F. Pereira.
2007.
Biogra-phies, Bollywood, Boom-boxes and Blenders: Do-main Adaptation for Sentiment Classification.
InProceedings of ACL .A.
Blum and T. Mitchell.
1998.
Combining labeledand unlabeled data with co-training.
In Proceedingsof COLT.S.
Clark, J. R. Curran, and M. Osborne.
2003.
Boot-strapping POS taggers using unlabelled data.
In Pro-ceedings of CoNLL.S.
Dasgupta and V. Ng.
2009.
Mine the Easy and Clas-sify the Hard: Experiments with Automatic Senti-ment Classification.
In Proceedings of ACL-IJCNLP.A.
Goldberg and X. Zhu.
2006.
Seeing stars whenthere aren?t many stars: graph-based semi-supervisedlearning for sentiment categorization.
In Proceed-ings of the Workshop on TextGraphs at HLT-NAACL.M.
Hu and B. Liu.
2004.
Mining opinion features incustomer reviews.
In Proceedings of the NationalConference on Artificial Intelligence (AAAI).D.
Ikeda, H. Takamura, L. Ratinov, and M. Okumura.2008.
Learning to Shift the Polarity of Words forSentiment Classification.
In Proceedings of IJCNLP.T.
Joachims.
1999.
Transductive Inference for TextClassification using Support Vector Machines.
InProceedings of ICML.A.
Kennedy and D. Inkpen.
2006.
Sentiment classi-fication of movie reviews using contextual valenceshifters.
Computational Intelligence, 22:110?125.LaTeX Error: File ?url.sty?
not found.
V. Ng and C.Cardie.
2003.
Weakly supervised natural languagelearning without redundant views.
In Proceedings ofHLT-NAACL.K.
Nigam, A. McCallum, S. Thrun, and T. Mitchell.2000.
Text classification from labeled and unlabeleddocuments using EM.
Machine Learning, 39(2/3):103?134.S.
Li, C. Huang, G. Zhou, and S. Y. M. Lee.
2010a.Employing personal/impersonal views in supervisedand semi-supervised sentiment classification.
In Pro-ceedings of the Annual Meeting of the Association forComputational Linguistics (ACL) .S.
Li, S. Lee, Y. Chen, C. Huang, and G. Zhou.
2010b.Sentiment Classification and Polarity Shifting.
InProceeding of the International Conference on Com-putational Linguistics (COLING).S.
Li, Z. Wang, G. Zhou, and S. Lee.
2011.
Semi-Supervised Learning for Imbalanced Sentiment Clas-sification.
In Proceedings of IJCAI.S.
Li.
2013.
Sentiment classification using subjectiveand objective views.
International Journal of Com-puter Applications, 80(7): 30?34.Z.
Liu, X. Dong, Y. Guan, and J. Yang.
2013.
ReservedSelf-training: A Semi-supervised Sentiment Classifi-cation Method for Chinese Microblogs.
In Proceed-ings of IJCNLP.R.
Mihalcea.
2004.
Co-training and self-trainingfor word sense disambiguation.
In Proceedings ofCoNLL.J.
Na, H. Sui, C. Khoo, S. Chan, and Y. Zhou.
2004.Effectiveness of simple linguistic processing in au-tomatic sentiment classification of product reviews.In Proceeding of the Conference of the InternationalSociety for Knowledge Organization.S.
Orimaye, S. Alhashmi, and E. Siew.
2012.
Buy it -don?t buy it: sentiment classification on Amazon re-views using sentence polarity shift.
In Proceedingsof the Pacific Rim International Conferences on Arti-ficial Intelligence (PRICAI).B.
Pang, L. Lee, and S. Vaithyanathan.
2002.
Thumbsup?
: sentiment classification using machine learningtechniques.
In Proceedings of EMNLP.L.
Polanyi and A. Zaenen.
2004.
Contextual lexicalvalence shifters.
In Proceedings of the AAAI SpringSymposium on Exploring Attitude and Affect in Text.Y.
Ren, N. Kaji, N. Yoshinaga, M. Toyoda, and M.Kitsuregawa.
2011.
Sentiment Classification inResource-Scarce Languages by using Label Prop-agation.
In Proceedings of the Pacific Asia Con-ference on Language, Information and Computation(PACLIC).A.
Sarkar.
2001.
Applying cotraining methods to sta-tistical parsing.
In Proceedings of NAACL.R.
Socher, J. Pennington, E. H. Huang, and A. Y.
2012.Semi-Supervised Recursive Autoencoders for Pre-dicting Sentiment Distributions.
In Proceedings ofEMNLP.Y.
Su, S. Li, S. Ju, G. Zhou and J. Li.
2012.
2012.Multi-view Learning for Semi-supervised SentimentClassification.
In Proceedings of the InternationalConference on Asian Language Processing.1062X.
Wan.
2009.
Co-Training for Cross-Lingual Senti-ment Classification.
In Proceedings of ACL-IJCNLP.R.
Xia, T. Wang, X. Hu, S. Li, and C. Zong.
2013.
DualTraining and Dual Prediction for Polarity Classifica-tion.
In Proceedings of ACL.Y.
Yang and X. Liu.
1999.
A re-examination of textcategorization methods.
In Proceedings SIGIR.S.
Zhou, Q. Chen, and X. Wang.
2010.
Active DeepNetworks for Semi-Supervised Sentiment Classifica-tion.
In Proceedings of COLING.X.
Zhu and Z. Ghahramani.
2002.
Learningfrom labeled and unlabeled data with label prop-agation.
Technical Report CMU-CALD-02-107,Carnegie Mellon University.X.
Zhu, Z. Ghahramani, and J. Lafferty.
2003.
Semi-supervised learning using Gaussian fields and har-monic functions.
In Proceddings of the InternationalConference on Machine Learning (ICML).1063
