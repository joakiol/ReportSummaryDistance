Proceedings of the TextGraphs-8 Workshop, pages 29?38,Seattle, Washington, USA, 18 October 2013. c?2013 Association for Computational LinguisticsGraph-Based Unsupervised Learning of Word Similarities UsingHeterogeneous Feature TypesAvneesh Saluja?Carnegie Mellon Universityavneesh@cmu.eduJir???
Navra?tilIBM Researchjiri@us.ibm.comAbstractIn this work, we propose a graph-basedapproach to computing similarities betweenwords in an unsupervised manner, and take ad-vantage of heterogeneous feature types in theprocess.
The approach is based on the creationof two separate graphs, one for words andone for features of different types (alignment-based, orthographic, etc.).
The graphs are con-nected through edges that link nodes in thefeature graph to nodes in the word graph, theedge weights representing the importance of aparticular feature for a particular word.
Highquality graphs are learned during training, andthe proposed method outperforms experimen-tal baselines.1 IntroductionData-driven approaches in natural language process-ing (NLP) have resulted in a marked improvementin a variety of NLP tasks, from machine translationto part-of-speech tagging.
Such methods however,are generally only as good as the quality of the dataitself.
This issue becomes highlighted when thereis a mismatch in domain between training and testdata, in that the number of out-of-vocabulary (OOV)words increases, resulting in problems for languagemodeling, machine translation, and other tasks.
Anapproach that specifically replaces OOV words withtheir synonyms from a restricted vocabulary (i.e., thewords already contained in the training data) couldalleviate this OOV word problem.
?This work was done during the first author?s internship atthe IBM T.J. Watson Research Center, Yorktown Heights, NYin 2012.Vast ontologies that capture semantic similaritiesbetween words, also known as WordNets, have beencarefully created and compiled by linguists for dif-ferent languages.
A WordNet-based solution couldbe implemented to fill the gaps when an OOV wordis encountered, but this approach is not scalable inthat it requires significant human effort for a num-ber of languages in which the WordNet is limitedor does not exist.
Thus, a practical solution to thisproblem should ideally require as little human su-pervision and involvement as possible.Additionally, words can be similar to each otherdue to a variety of reasons.
For example, the similar-ity between the words optimize and optimal can becaptured via the high orthographical similarity be-tween the words.
However, relying too much on asingle feature type may result in false positives, e.g.,suggestions of antonyms instead of synonyms.
Valu-able information can be gleaned from a variety offeature types, both monolingual and bilingual.
Thus,any potential solution to an unsupervised or mildlysupervised word similarity algorithm should be ableto take into account heterogeneous feature types andcombine them in a globally effective manner whenyielding the final solution.In this work, we present a graph-based approachto impute word similarities in an unsupervised man-ner and takes into account heterogeneous features.The key idea is to maintain two graphs, one forwords and one for the all the features of differenttypes, and attempt to promote concurrence betweenthe two graphs in an effort to find a final solution.The similarity graphs learned during training aregenerally of high quality, and the testing approachproposed outperforms the chosen baselines.292 ApproachThe eventual goal is to compute the most similarword to a given OOV word from a restricted, pre-existing vocabulary.
We propose a graph-based so-lution for this problem, relying on undirected graphsto represent words and features as well as the simi-larities between them.
The solution can be broadlydivided into two distinct sub-problems, the trainingand testing components.2.1 Learning the GraphThe intuition of our approach is best expressedthrough a small example problem.
Figure 1 showsan example graph of words (shaded) and features(unshaded).
For exposition, let v1 = optimize, v2 =optimal, and v3 = ideal, while f1 = orth |opti, i.e.,an orthographic feature corresponding to the sub-string ?opti?
at the beginning of a word, and f5 =align ide?al, i.e., a bilingual feature corresponding tothe alignment of the word ?optimal?
to the Frenchword ?ide?al?
in the training data1.v1v3v2v4v5f1f2f5f3f4Zv1,f1Wf1,f5Wv1,v2Figure 1: An example graph for explanatory purposes.
Thenodes in red constitute the word graph, and the nodes in whitethe feature graph.There are three types of edges in this scenario.Edges between word nodes (e.g., Wv1,v2) representword similarities, and edges between features (e.g.,Wf1,f5) represent feature similarities.
Edges be-tween words and features (e.g., Zv1,f1 , the dashedlines) represent pertinent or active features for agiven word when computing its similarity with otherwords, with the edge weight reflecting the degree ofimportance.We restrict the values of all similarities to be be-tween 0 and 1, as negative-valued edges in undi-1such word alignments can be extracted through standardword alignment algorithms applied to a parallel corpus in twodifferent languages.rected graphs are significantly more complicatedand would make subsequent computations more in-tricate.
In an ideal situation, the similarity matricesthat represent the word and feature graphs should bepositive semi-definite, which provides a nice prob-abilistic interpretation due to connections to covari-ance matrices of multivariate distributions, but thisconstraint is not enforced here.
Future work willfocus on improved optimization techniques that re-spect the positive semi-definiteness constraint.2.1.1 Objective FunctionTo learn the graph, the following objective func-tion is minimized:?
(WV ,WF ,Z) = ?0?fp,fq?F(Wfp,fq ?W ?fp,fq )2 (1)+ ?1?vi?V?fp?F(Zvi,fp ?
Z?vi,fp)2 (2)+ ?2?vi,vj?V?fp,fq?FZvi,fpZvj ,fq (Wvi,vj ?Wfp,fq )2(3)+ ?3?vi,vj?V?fp,fq?FWvi,vjWfp,fq (Zvi,fp ?
Zvj ,fq )2(4)where Wfp,fq is the current similarity between fea-ture fp and feature fq (with corresponding initialvalue W ?fp,fq ), Wvi,vj is the current similarity be-tween word vi and word vj , Zvi,fp is the currentimportance weight of feature fp for word vi (withcorresponding initial value Z?vi,fp), and ?0 to ?3 areparameters (that sum to 1) which represent the im-portance of a given term in the objective function.The intuition of the objective function is straight-forward.
The first two terms correspond to minimiz-ing the `2-norm between the initial and current val-ues of Wfp,fq and Zvi,fp (for further details on ini-tialization, see Section 2.1.2).
The intuition behindthe third term is to minimize the difference betweenthe word similarity of words vi and vj and the fea-ture similarity of features fp and fq in proportion tohow important those features are for words vi and vjrespectively.
If two features have high importanceweights for two words, and those features are verysimilar to each other, then the corresponding wordsshould also be similar.
The fourth term has a simi-lar rationale, in that it minimizes the difference be-tween importance weights in proportion to the sim-ilarities.
In other words, we attempt to promote pa-rameter concurrence between the word and feature30graphs, which in turn ensures smoothness over thetwo graphs.The basic idea of minimizing two quantities of thegraph in proportion to their link strength has beenused before, for example (but not limited to) graph-based semi-supervised learning and label propaga-tion (Zhu et al 2003) where the concept is appliedto node labels (as opposed to edge weights as pre-sented in this work).
In such methods, the idea isto ensure that the function varies smoothly over thegraph (Zhou et al 2004), i.e., to promote parame-ter concurrence within a graph, whereas we promoteparameter concurrence across two graphs.
In thatsense, the ?
parameters as control the trade-off be-tween respecting initial values vs. achieving consis-tency between the two graphs.While not necessary, we decided to tie the param-eters together, such that ?0 and ?2 (representing fea-ture similarity preference for initial values vs. pref-erence for consistency) sum to 0.5, and ?1 and ?3sum to 0.5 as well, implicitly giving equal weight tofeature similarities and importance weights.
In thefuture, a more appropriate method of learning these?
parameters will be explored.2.1.2 InitializationIn many unsupervised algorithms, e.g., EM, theinitialization of parameters is of paramount impor-tance, as these initial values guide the algorithm inits attempt to minimize a proposed objective func-tion.
In our problem, initial estimates for word simi-larities do not exist (otherwise the problem would beconsiderably easier!).
Instead, word similarities areseeded from the initial feature similarities and initialimportance weights, and all three quantities are theniteratively refined.The initial importance weight values are com-puted from the co-occurrence statistics betweenwords and features, by taking the geometric meanof the conditional probabilities (feature given wordand word given feature) in both directions: Z?vi,fp =?P(vi|fp)P(fp|vi).
For the initial feature similar-ity values, the pointwise mutual information (PMI)vector for each feature is first computed, by takingthe log ratio of the joint probability with each wordto the marginal probabilities of the feature and theword (also done through the co-occurrence statis-tics).
Subsequently, the initial similarity is thencomputed as the normalized dot product betweenfeature vectors:PMIfp ?PMIfq?PMIfp?
?PMIfq?.After computing the initial feature similarityand weights matrices, we remove features that aredensely connected in the feature similarity graph bytrimming high entropy features (normalizing edgeweights and treating the resulting values as a prob-ability distribution).
This pruning was done in or-der to speed up the optimization procedure, and wefound that results were not affected by pruning awaythe top one percentile of features sorted by entropy.2.1.3 OptimizationThe objective function (Equations 1 to 4) is con-vex and differentiable with respect to the individ-ual variables Wvi,vj ,Wfp,fq , and Zvi,fp .
Hence, oneway to minimize it is to evaluate the derivatives ofthe objective function with respect to these variables,set to 0 and solve.
The final update equations areprovided in the Appendix.The entire training pipeline is captured in Figure2.
We first compute the word similarities from theinitial feature similarities and importance weights,and then update those values in turn, based onthe alternating minimization method (Csisza?r andTusna?dy, 1984).
The process is repeated till con-vergence.PreprocessingFeature ExtractionInitializationUpdate Word SimCorpusUpdate Feature SimRepeat for N iterationsUpdate WeightsFigure 2: Flowchart for the training pipeline described in Sec-tion 2.1.3.
The number of iterations N is determined before-hand.312.2 Link PredictionGiven a learned word similarity graph (along witha learned feature similarity graph and the edges be-tween the two graphs) and an OOV word with as-sociated features, the proposed solution should alsogenerate a list of synonyms.
In a graph-based set-ting, this is analogous to the link prediction prob-lem: given a graph and a new node that needs to beembedded in the graph, which links, or edges, do weadd between the new node and all the existing ones?We experimented with two different approachesfor link prediction.
The first computes word sim-ilarities in the same manner as in training, as perEquation 5.
However, since the learned importanceweights Zvi,fp (or Zvj ,fq ) are specific to a givenword, importance weights for the OOV word are ini-tialized in the same manner as in Section 2.1.2 forthe words in the training data.
Thus, for a givenOOV word, we obtain word similarities with allwords in the vocabulary through Equation 5, andoutput the most similar words by this metric.The second method is based on a random walkapproach, similar to (Kok and Brockett, 2010),wherein a probabilistic interpretation is imposed onthe graphs by row-normalizing all of the matricesinvolved (word similarity, feature similarity, and im-portance weights), implying that the transition prob-ability, say from node vi to vj , is proportional tothe similarity between the two nodes.
For this ap-proach, only the active features for a given OOVword, i.e., the features that have at least one non-zero Z edge between the feature and a word, areused (see Section 2.3 for more details on active andinactive features).
First, M random walks are ini-tialized from each active feature node, each walk ofmaximum length T .
For every walk, the number ofsteps needed to hit a word node in the word simi-larity graph for the first time is recorded.
After av-eraging across the M runs, we need to average thehitting times across all of the active features, whichis done by weighting the hitting times of each ac-tive feature f?
by?viZvi,f?
, i.e., the sum across allrows of a given feature (represented by a column) inthe importance weights matrix.The random walk-based approach introducesthree new parameters: M , the number of randomwalks per active feature, T , the maximum lengthof each random walk, and ?, a parameter that con-trols how often a random walk should take a Zedge (thereby transitioning from one graph to theother) or a W edge (thereby staying within the samegraph).
If a node has both Z and W edges, then ?is the parameter for a simple Bernoulli distributionthat samples whether to take one type of edge or theother; if the node has only one type of edge, then thewalk traverses only that type.2.3 SparsificationThere is a crucial point regarding Equations 1 to4, namely that restricting the inputted values to be-tween 0 and 1 does not guarantee that the resultingsimilarity or weight value will also be between 0 and1, due to the difference in terms in the numeratorof the equations.
In order to bypass this problem,a projection step is employed subsequent to an up-date, wherein the value obtained is projected into thecorrect part of the n-dimensional Euclidean space,namely the positive orthant.
Although slightly moreinvolved in the multidimensional case, i.e., wheren > 1, since the partial derivatives as computedin Equations 5 to 7 are with respect to a single ele-ment, orthant projection in the unidimensional caseamounts to nothing more than setting the value to 0if it is less than 0.
This effectively sparsifies the re-sulting matrix, and is similar to the soft-thresholdingeffect that comes about due to `1-norm regulariza-tion.
Further exploration of this link is left to futurework.However, the sparsification of the graphs/matricesis problematic for the random walk-based approach,in that an OOV word may consist of features that areall inactive, i.e., none of the features have a non-zeroZ edge to the word similarity graph.
In this case,we cannot compute which words in our vocabularyare similar to the OOV word.
One method to allevi-ate this drawback is to add back Z edges that wereremoved during training with their initial weights.Yet, we found that adding back all of the featuresfor a test word was worse than filtering out the fea-tures with the highest entropy (i.e., with the mostedges to other features) out of the features to addback.
The latter approach was thus adopted and isthe setup used in Section 3.5.3 Experiments & ResultsIn our experiments, we looked at both the quality ofthe similarity graphs learned from the data, as wellas the performance of the link prediction techniques.32Corpus Sentences WordsEuroParl+ NewsComm (Train) 1.64 million+ 40.6 million+WMT2010 (Test) 2034 44,671Table 1: Corpus statistics for the datasets used in evaluation.3.1 DatasetTable 1 summarizes the statistics of the training andtest sets used.
We used the standard WMT 2010evaluation dataset, and the training data consists of acombination of European Parliament and news com-mentary bitext, while the test set is from the newsdomain.
Note that a parallel corpus is not needed asonly the English side is used.
While the current ex-periment is restricted to English, any language canbe used in principle.3.2 FeaturesDuring the feature extraction phase, we first filteredthe 30 most common words from the corpus and donot extract features for those words.
However, thesecommon words are still used when extracting distri-butional features.
The following features are used:?
Orthographic: all substrings of length 3, 4, and5 for a given word are extracted.
For exam-ple, the feature ?orth |opt?, corresponding tothe substring ?opt?
at the beginning of a word,would be extracted from the word ?optimal?.?
Distributional (a.k.a., contextual): for a givenword, we extract the word immediately preced-ing and succeeding it as well as words withina window of 5.
These features are extractedfrom a corpus without the 30 most commonwords filtered.
An example of such a featureis ?LR the+cost?, representing an instance of apreceding and succeeding word for ?optimal?,extracted from the phrase ?the optimal cost?.Lastly, all distributional features that occur lessthan 5 times are removed.?
Part-of-Speech (POS): for example, ?pos JJ?
isa POS feature extracted for the word ?optimal?.?
Alignment (a.k.a., bilingual): alignment fea-tures are extracted from alignment matricesacross languages.
For every word, we filterall words in the target language (treating En-glish, our working language, as the source)that have a lexical probability less than half themaximum lexical probability, and use the re-sulting aligned words as features.
For exam-ple, ?align ide?al?
would be a feature for theword ?optimal?, since the French word ?ide?al?is aligned (with high probability) to the word?optimal?.
Note that the assumption during testtime is that alignment features are not availablefor OOV words; if they were, then the wordwould not be OOV.
Nonetheless, alignment in-formation can be utilized indirectly in the linkprediction stage from random walk traversalsof in-vocabulary nodes.Statistics on the number of features broken down bytype are presented in Table 2, for 3 different vocab-ulary sizes.
In the experiments, we concentrated onthe 10,000 and 50,000 size vocabularies.3.3 BaselinesWhen selecting the baselines, we had two goals inmind.
Firstly, we wanted to compare the proposedapproach against simpler alternatives for generatingword similarities.
The baselines were also chosenso as to correspond in some way to the various fea-ture types, since a main advantage of our approachis that it effectively combines various feature typesto yield global word similarity scores.
This choiceof baselines also provides insight into the impact ofthe various feature types chosen; the idea is that abaseline corresponding to a particular feature typewould be indicative of word similarity performanceusing just that type.
Three baselines were initiallyselected:?
Distributional: a PMI vector is computed foreach word over the various distributional fea-tures.
The inner product of two PMI vectorsis computed to evaluate the similarity of twowords.
We found that this baseline performedpoorly relative to the other ones, and thus de-cided not to include it in the final evaluation.?
Orthographic: based on a simple edit distance-based approach, where all words within an editdistance of 25% of the length of the test wordare retrieved.?
Alignment: we compose the alignment matri-ces in both directions to generate an Englishto English matrix (using German as the pivotlanguage), from which the three most similar33Vocabulary Words Features Alignment Distributional Orthographic POSFull 93,011 780,357 325,940 206,253 248,114 5050k-vocab 50,000 569,890 222,701 204,266 142,873 5010k-vocab 10,000 301,555 61,792 199,256 40,457 50Table 2: Statistics on the number of features extracted based on the number of words, broken down by feature type.
Note that thedistributional features are only those with count 5 and above.words (as per the lexical probabilities in thematrices) are extracted.3.4 EvaluationAutomatic evaluation of an algorithm that computessimilarities between words is tricky.
The judgmenton whether two words are synonyms is still donebest by a human, requiring significant manual effort.Therefore, during the experimentation and parame-ter selection process we developed an intermediateform of evaluation wherein a human annotator as-sisted in creating a pseudo ?ground truth?.
Prior tocreating the ground truth, all OOV words in the testset were identified (i.e., no match in our vocabulary),resulting in 978 OOV words.
Named entities werethen manually filtered, resulting in a final test set of312 words for evaluation purposes.To create the ground truth, we generated for eachtest OOV word a set of possible synonyms using thealignment and orthographic baselines, as per Section3.3.
Naturally, many of the words generated werenot legitimate synonyms; human evaluators thus re-moved all words that were not synonyms or nearsynonyms, ignoring mild grammatical inconsisten-cies, like singular vs. plural.
Generally, a synonymwas considered valid if substituting the word withthe synonym preserved meaning in a sentence.The final evaluation was performed by a humanevaluator.
The two baselines and the proposed ap-proach generated the top three synonym candidatesfor a given OOV test word and both 1-best and 3-best results were evaluated (as in Table 3).
Finalperformance was evaluated using precision and re-call.
Recall is defined as the percentage of wordsfor which at least one synonym was generated, andprecision evaluates the number of correct synonymsfrom the ones generated.3.5 ResultsFigure 3 looks at the neighborhood of words aroundthe word ?guardian?.
Note that while only two dif-ferent ?
parameter configurations are compared inTest Word Synonym 1 Synonym 2 Synonym 3pubescent puberty adolescence nanotubessportswoman sportswomen athlete draftswomanbriny salty saline salinityTable 3: Example of the annotation task.
The suggested syn-onyms are real output from our algorithm.the figure, we investigated a variety of settings andfound that ?0 = 0.3, ?1 = 0.4, ?2 = 0.2, ?3 = 0.1worked best from a final evaluation perspective.The first point to note is that the graph in Fig-ure 3b is generally more dense than that of Figureguardiancustodianangelguardianstutor0.130.220.080.07guardguardiastickler0.170.130.12custodianstrainerstutors0.200.050.43michelangeloangelic0.090.04teachers0.060.330.100.11(a) ?0 = 0.3, ?1 = 0.4, ?2 = 0.2, ?3 = 0.1guardiancustodianangelguardianstutor0.070.190.060.09stewardstickler0.090.07custodianskeeperstutors0.150.040.24michelangeloangelic0.030.04teachers0.030.060.190.06rod0.030.004(b) ?0 = 0.4, ?1 = 0.4, ?2 = 0.1, ?3 = 0.1Figure 3: A snapshot of a portion of the learned graph for twodifferent parameter settings.
The graph in 3b is more dense.341 2 3 4 5012345678910 x 105Number of ElementsIteration10k Word SimilarityHHLLHLLHLHHLNHNL(a) Word similarity matrix sparsity0 1 2 3 4 5051015 x 105Number of ElementsIteration10k WeightsHHLLHLLHLHHLNHNL(b) Weights matrix sparsityFigure 4: Word similarity and weights matrices sparsities for10,000-word vocabulary.3a.
For example, Figure 3b contains an edge be-tween ?custodian?
and ?custodians?, whereas Figure3a does not.
In the latter graph, there is a higher pref-erence for smoothness over the graph and thus theidea is that ?custodian?
and ?custodians?
are linkedvia the smooth transition ?custodian??
?guardian??
?guardians??
?custodians?, whereas in the for-mer, there is a higher preference to respect the ini-tial values, which generates this additional edge.
Wealso observed weak edges between words like ?cus-todian?
and ?tutor?
in Figure 3b but not in Figure3a.
The effect of the parameters on the sparsity ofthe graph is definitely apparent, but generally thelearned graphs are of high quality.
A further anal-ysis reveals that for many of the words in the cor-pus, the highest weighted features are usually align-ment features; their heavy use allows the algorithmto produce interesting synonym candidates, and em-phasizes the importance of bilingual features.To underscore the point regarding impact of pa-rameters on graph sparsity, Figures 4 and 5 presentthe number of elements in the resulting word sim-ilarity and weights matrices (graphs) vs. iterationfor vocabulary sizes of 10,000 and 50,000 respec-Configuration ?0 ?1 ?2 ?3HHLL 0.4 0.4 0.1 0.1NHNL 0.3 0.4 0.2 0.1HLLH 0.4 0.1 0.1 0.4LHHL 0.1 0.4 0.4 0.1Table 4: Legend for the charts in Figures 4 and 5.
H corre-sponds to ?high?, L to ?low?, and N to ?neutral?.1 2 3 4 5051015 x 105Number of ElementsIteration50k Word SimilarityHHLLNHNL(a) Word similarity matrix sparsity0 1 2 3 4 500.511.522.5 x 106Number of ElementsIteration50k WeightsHHLLNHNL(b) Weights matrix sparsityFigure 5: Word similarity and weights matrices sparsities for50,000-word vocabulary.tively, with Table 4 providing a legend to the curvesin those figures.
Higher ?
weights for terms 1 and2 in the objective function result in less sparse solu-tions.
The density of the matrices also drops drasti-cally after a few iterations and stabilizes thereafter.Lastly, Tables 5 and 6 present the final results ofthe evaluation, as assessed by a human evaluator, onthe 312 OOV words in the test set.
While the re-sults on the 1-best front are marginally better thanthe edit distance-based baseline, 3-best the perfor-mance of our approach is comfortably better than thebaselines.
Testing was done with the word similarityupdate method.The performance of the random walk-based link35Method Precision Recall F-1?
matrix 31.1% 67.0% 42.5%orthographic 37.5% 92.3% 53.3%50k-nhnl 37.2% 100% 54.2%Table 5: 1-best evaluation results on WMT 2010 OOV wordstrained on a 50,000-word vocabulary.
Our best approach (?50k-nhnl?)
is boldedMethod Precision Recall F-1?
matrix 96.7% 67.0% 79.1%orthographic 89.9% 92.3% 91.1%50k-nhnl 92.6% 100% 96.2%Table 6: 3-best evaluation results on WMT 2010 OOV wordstrained on a 50,000-word vocabulary.
Our best approach (?50k-nhnl?)
is boldedprediction approach was sub-optimal for several rea-sons.
Firstly, it was difficult to use the learned im-portance weights as is, since the resulting weightsmatrix was so sparse that many test words simplydid not have active features.
This issue resultedin the vanilla variant of the random walk approachto have very low recall.
Therefore, we adopted a?mixed weights?
strategy, where we selectively in-troduced a number of features previously inactivefor a test word, not including the features that hadhigh entropy.
Yet in this case, the random walks getstuck traversing certain edges, and a good samplingof similar words was not properly achievable.A general issue that arose during link predictionis that the orthographic features tend to dominatethe candidate synonyms list since alignment featuresare not utilized.
If instead we assume that align-ment features are accessible during testing, then therandom walk-based approaches do marginally betterthan the word similarity update method, but furtherinvestigation is warranted before drawing any defini-tive conclusions.4 Related WorkWe used the objective function and basic formula-tion of (Muthukrishnan et al 2011), but correctedtheir derivation of the optimization and introducedmethods to handle the resulting complications.
Inaddition, (Muthukrishnan et al 2011) implementedtheir approach on just one feature type and with farfewer nodes, since their word similarity graph wasactually over documents and their feature similar-ity graph was over words.
Recently, an alterna-tive graph-based approach for the same problem waspresented in (Minkov and Cohen, 2012).
However,in addition to requiring a dependency parse of thecorpus, the emphasis of that work is more on thetesting side.
Indeed, we can incorporate some of theideas presented in that work to improve our link pre-diction during query time.
The label propagation-based approaches of (Tamura et al 2012; Razmaraet al 2013), wherein ?seed distributions?
are ex-tracted from bilingual corpora and are propagatedaround a similarity graph, can also be easily inte-grated into our approach as a downstream methodspecific to machine translation.Another approach to handle OOVs, particularlyin the translation domain, is (Zhang et al 2005),wherein the authors leveraged the web as an ex-panded corpus for OOV mining.
If web access is un-available however, then this method would not work.The general problem of combining multiple viewsof similarity (i.e., across different feature types)can also be tackled through multiple kernel learn-ing (MKL) (Bach et al 2004).
However, most ofthe work in this field has been on supervised MKL,whereas we required an unsupervised approach.An area that has seen a recent resurgence in popu-larity is deep learning, especially in its applicationsto continuous embeddings.
Embeddings of worddistributions have been explored in (Mnih and Hin-ton, 2007; Turian et al 2010; Weston et al 2008).Lastly, while not directly relevant to our work, theidea of using a graph-based framework to combineboth monolingual and bilingual features was alsopresented in (Das and Petrov, 2011).5 Conclusion & Future WorkIn this work, we presented a graph-based approachto computing word similarities, based on dual wordand feature similarity graphs, and the edges thatgo between the graphs, representing importanceweights.
We introduced an objective function thatpromotes parameter concurrence between the twographs, and minimized this function with a simplealternating minimization-based approach.
The re-sulting optimization recovers high quality word sim-ilarity graphs, primarily due to the bilingual features,and improves over the baselines during the link pre-diction stage.In the future, on the training side we would liketo optimize the proposed objective function in abetter manner, while enforcing the positive semi-36definiteness constraints.
Other link prediction tech-niques should be explored, as the current techniqueshave pitfalls.
Richer features that model more re-fined aspects can be introduced.
In particular, fea-tures from a dependency parse of the data would bevery useful in this situation.ReferencesFrancis R. Bach, Gert R. G. Lanckriet, and Michael I.Jordan.
2004.
Multiple kernel learning, conic duality,and the smo algorithm.
In Proceedings of the twenty-first international conference on Machine learning,ICML ?04.I.
Csisza?r and G. Tusna?dy.
1984.
Information geome-try and alternating minimization procedures.
Statisticsand Decisions, Supplement Issue 1:205?237.Dipanjan Das and Slav Petrov.
2011.
Unsupervised part-of-speech tagging with bilingual graph-based projec-tions.
In Proceedings of the 49th Annual Meeting ofthe Association for Computational Linguistics: Hu-man Language Technologies - Volume 1, HLT ?11,pages 600?609.Stanley Kok and Chris Brockett.
2010.
Hitting the rightparaphrases in good time.
In Human Language Tech-nologies: The 2010 Annual Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics, HLT ?10, pages 145?153.Einat Minkov and William W. Cohen.
2012.
Graphbased similarity measures for synonym extractionfrom parsed text.
In TextGraphs-7: Graph-basedMethods for Natural Language Processing.Andriy Mnih and Geoffrey Hinton.
2007.
Three newgraphical models for statistical language modelling.
InProceedings of the 24th international conference onMachine learning, ICML ?07, pages 641?648.Pradeep Muthukrishnan, Dragomir R. Radev, andQiaozhu Mei.
2011.
Simultaneous similarity learningand feature-weight learning for document clustering.In TextGraphs-6: Graph-based Methods for NaturalLanguage Processing, pages 42?50.Majid Razmara, Maryam Siahbani, Gholamreza Haffari,and Anoop Sarkar.
2013.
Graph propagation for para-phrasing out-of-vocabulary words in statistical ma-chine translation.
In Proceedings of the 51st AnnualMeeting of the Association for Computational Linguis-tics, ACL ?13.Akihiro Tamura, Taro Watanabe, and Eiichiro Sumita.2012.
Bilingual lexicon extraction from comparablecorpora using label propagation.
In Proceedings of the2012 Joint Conference on Empirical Methods in Natu-ral Language Processing and Computational NaturalLanguage Learning, EMNLP-CoNLL ?12, pages 24?36, Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Joseph Turian, Lev Ratinov, and Yoshua Bengio.
2010.Word representations: a simple and general method forsemi-supervised learning.
In Proceedings of the 48thAnnual Meeting of the Association for ComputationalLinguistics, ACL ?10, pages 384?394.Jason Weston, Fre?de?ric Ratle, and Ronan Collobert.2008.
Deep learning via semi-supervised embedding.In ICML, pages 1168?1175.Ying Zhang, Fei Huang, and Stephan Vogel.
2005.
Min-ing translations of oov terms from the web throughcross-lingual query expansion.
In Proceedings of the28th annual international ACM SIGIR conference onResearch and development in information retrieval,SIGIR ?05, pages 669?670.Dengyong Zhou, Olivier Bousquet, Thomas Navin Lal,Jason Weston, and Bernhard Scho?lkopf.
2004.
Learn-ing with local and global consistency.
In SebastianThrun, Lawrence Saul, and Bernhard Scho?lkopf, edi-tors, Advances in Neural Information Processing Sys-tems 16.
MIT Press, Cambridge, MA.Xiaojin Zhu, Z. Ghahramani, and John Lafferty.
2003.Semi-supervised learning using gaussian fields andharmonic functions.
In Proceedings of the Twenti-eth International Conference on Machine Learning(ICML-2003), volume 20, page 912.A Final Equations for Parameter UpdatesWvi,vj =1C1??
?fp,fq?F?2Zvi,fpZvj ,fqWfp,fq?
?32Wfp,fq(Zvi,fp ?
Zvj ,fq)2)(5)Wfp,fq =1C2??
?vi,vj?V(?2Zvi,fpZvj ,fqWvi,vj?
?32Wvi,vj (Zvi,fp ?
Zvj ,fq)2)+ ?0W ?fp,fq)(6)Zvi,fp =1C3??
?vi?V?fp?F(?3Zvj ,fqWvi,vjWfp,fq?
?22Zvj ,fq(Wvi,vj ?Wfp,fq)2)+ ?1Z?vi,fp)(7)37whereC1 = ?2?fp,fq?FZvi,fpZvj ,fqC2 = ?0 + ?2?vi,vj?VZvi,fpZvj ,fqC3 = ?1 + ?3?vi?V?fp?FWvi,vjWfp,fq38
