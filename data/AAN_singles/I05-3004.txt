Chinese Classifier Assignment Using SVMsHui Guo and Huayan ZhongDepartment of Computer ScienceStony Brook UniversityStony Brook, NY 11794-4400, USA{huguo, huayan}@cs.sunysb.eduAbstractIn Chinese, nouns need numeral clas-sifiers to express quantity.
In this pa-per, we explore the relationship be-tween classifiers and nouns.
We ex-tract a set of lexical, syntactic and onto-logical features and the correspondingnoun-classifier pairs from a corpus andthen train SVMs to assign classifers tonouns.
We analyse which features aremost important for this task.1 IntroductionIn English, numbers directly modify count nouns,as in ?two apples?
and ?five computers?.
Num-bers cannot directly modify mass nouns; instead,an embedded noun phrase must be formed, e.g.
?five slices of bread?.
However, in Chinese allnouns need numeral classifiers to express quan-tity1.
When translating from English to Chinese,we may need to choose Chinese classifiers to formnoun phrases.
We can see the difference betweenthe two languages in the following two examples:?
[liang] ?[ge]?
*[pingguo] (Chinese)two apples (English)and?[wu]?[pian]??
[mianbao] (Chinese)five slices of bread (English)Noun classifer combinations appear with highfrequency in Chinese.
There are more than 500classifiers although fewer than 200 of them arefrequently used.
Each classifier can only be1Proper nouns and bare noun phrases do not need classi-fiers.used with certain classes of noun.
Nouns in aclass usually have similar properties.
For exam-ple, nouns that can be used with the classifier??[gen]?
are: ?uz?
(straw), ?M?(chopstick),?
?
(pipe), etc.
All these objects are long andthin.
However, sometimes nouns with similarproperties are in different classes.
For example,?:?
(cow), ?j?
(horse) and ???
(lamb) are all live-stock, but they associate with different classifiers.This means that classifier assignment is not totallyrule-based but partly idiomatic.In this paper, we explore the relationship be-tween classifiers and nouns.
We extract a set offeatures and the corresponding noun-classifier at-tachments from a corpus and then train SVMs toassign classifers to nouns.
In Section 4 we de-scribe our data set.
In Section 5 we describe ourexperiments.
In Section 6 we present our results.2 Related WorkMany Asian languages (e.g.
Chinese, Korean,Japanese and Thai) have numeral classifier sys-tems.
Previous work on noun-classifier match-ing has been done in these languages.
(Sorn-lertlamvanich et al, 1994) present an algorithmfor selecting an appropriate classifier for a nounin Thai.
The general idea is to extract noun-classifier collocations from a corpus, and output alist of noun-classifier pairs with frequency infor-mation.
During noun phrase generation, the mostfrequently co-occurring classifier for a given nounis selected.
However, no evaluation is reported forthis algorithm.The algorithm described in (Paik and Bond,2001) generates Japanese and Korean numeral25classifiers using semantic classes from an ontol-ogy.
The authors assigned classifiers to eachof the 2,710 semantic classes in the ontologyby hand.
During generation, nouns in each se-mantic class are assigned the associated classi-fier.
The classifier assignment accuracy is 81%for Japanese classifiers and 62% for Korean clas-sifiers.
However, the evaluation set contains only90 noun phrases, which is pretty small.
Further-more, it is hard work to attach classifiers to an on-tology by hand, and with this approach it is hardto deal with cases like the cattle example men-tioned earlier.
(Paul et al, 2002) present a method for ex-tracting classifier information from a bilingual(Japanese-English) corpus based on phrasal cor-respondences in the sentential context.
Bilin-gual sentence pairs are compared to find noun-classifier collocations.
The evaluation was doneby a human.
The precision is high (84.2%) butthe recall is only about 40% because the algorithmdoes not give output for half of the nouns.In contrast to these algorithms, our approach: isbased on a large data set; uses machine learning;and does not require the attachment of classifiersto an ontology by hand.3 Support Vector MachinesSupport Vector Machines (SVMs) are a type ofclassifier first introduced in (Boser et al, 1992).In the last few years SVMs have become an im-portant and active field in machine learning re-search.
The SVM algorithm detects and exploitscomplex patterns in data.A binary SVM is a maximum margin classifier.Given a set of training data {x1, x2, ..., xk}, withcorresponding labels y1, y2, ..., yk ?
{+1,?1}, abinary SVM divides the input space into two re-gions at a decision boundary, which is a separat-ing hyperplane ?w, x?
+ b = 0 (Figure 1).
Thedecision boundary should classify all points cor-rectly, that is:yi(?w, xi?
+ b) > 0,?iAlso, the decision boundary should have themaximum separating margin with respect to thetwo classes.
If we rescale w and b to makethe closest point(s) to the hyperplane satisfybwxxxxxxxx<w, x> + b = 0Figure 1: The input space and hyperplane|?w, xi?
+ b| = 1, then the margin equals 1/||w||and the problem can be formulated as:minimize 12 ||w||2subject to yi(?w, xi?
+ b) ?
1,?iThe generalized Lagrange Function is:L(w, b, ?)
= 12?w,w?
?l?i=1?i[yi(?w, xi?+b)?1]So we can transform the problem to its dual:maximizeW (?)
=n?i=1?i ?12n?i=1,j=1?i?jyiyj?xi, xj?subject to ?i ?
0,n?i=1?iyi = 0This is a quadratic programming (QP) problemand we can always find the global maximum of?i.
We can recover w and b for the hyperplaneby:w =n?i=1?iyixib = ?maxyi=?1(?w, xi?)
+ minyi=+1(?w, xi?
)2If the points in the input space are not linearlyseparable, we allow ?slack variables?
?i in theclassification.
We need to find a soft margin hy-perplane, e.g.
:minimize 12 ||w||2 + Cn?i=1?i26subject to yi(?w, xi?
+ b) ?
1 ?
?i,?iOnce again, a QP solver can be used to find thesolution.For our task we need multi-class SVMs.
To getmulti-class SVMs, we can construct and combineseveral binary SVMs (one-against-one), or we candirectly consider all data in one optimization for-mula (one-against-all).Many SVM implementations are available onthe web.
We chose LIBSVM (Chang and Lin,2001), which is an efficient multi-class imple-mentation.
LIBSVM uses the ?one-against-one?approach in which k(k?
1)/2 classifiers are con-structed and each one trains on data from two dif-ferent classes (Hsu and Lin, 2002).4 Data and ResourcesWe use the Penn Chinese Treebank (Xue et al,2002) as our corpus and the ontology/lexiconHowNet (Dong and Dong, 2000) to get ontologi-cal features for nouns.
We train SVMs on differ-ent feature sets to see which set(s) of features areimportant for noun-classifier matching.4.1 Penn Chinese TreebankThe Penn Chinese Treebank is a 500,000 wordChinese corpus annotated with both part-of-speech (POS) tags and syntactic brackets.We automatically extract noun phrases thatcontain classifiers from the corpus.
An examplenoun phrase (translation: ?a major commercialwaterway?)
is:(IP....(NP (QP (CD) (CLP (M)))(NP (NNy?))
(ADJP (JJL))(NP (NN?s)))...)The word in (CLP (M[tiao])) is the classifierand the head noun of the noun phrase is (NN ?s).
In Section 5.3 we describe a set of featureswe obtain from each noun phrase and the sentencein which it is embedded.In our corpus, there are 61587 noun occur-rences (12225 unique nouns) and 3940 classifier-noun co-occurrences (212 unique classifiers).However, there is a trival rule determiningwhether a noun needs a classifier.
If a noun ispreceded by a quantifier or a determiner, then aclassifier is needed, otherwise it is not.
Hence,we only focus on noun-classifier pairs.
The mostfrequently occurring classifier in this corpus is??
[ge]?, which occurs with 497 unique nouns.
Inthis corpus, 87 classifiers occur in only one noun-classifier pair.4.2 HowNetWe get ontological features of nouns fromHowNet.
HowNet is a bilingual Chinese-Englishlexicon and ontology.
Each word sense is as-signed to a concept containing ontological fea-tures.
HowNet uses basic meaning units namedsememes to construct concepts.Table 1 shows an example entry in HowNet.The entry in Table 1 is for the word ?*?(writer).
The sememe at the first position, ?hu-man(|)?, is the categorical attribute, which de-scribes the general category of the concept.
Thesememes following the first sememe are addi-tional attributes, which give additional specificfeatures.
There are two types of pointer, ?#?
and?
*?, in the definition.
?#?
means ?related?, so?#occupation?
shows that the concept has a re-lationship with ?occupation?.
?*?
means ?agent?,so ?*compile?
shows that ?writer?
is the agent of?compile?.
The sememes ?#readings?
and ?litera-ture?
show that the job of ?writer?
is to compile?readings?
about ?literature?.We use HowNet 2000, which contains 120,496entries for about 65,000 Chinese words definedwith a set of 1503 sememes.
It is big enough forour task and we can get ontological features for94.71% of the nouns from the Penn Chinese Tree-bank.
For the nouns that are not in HowNet, wejust leave the ontological features blank.5 ExperimentsWe use six different feature sets to assign classi-fiers to nouns.
To evaluate each feature set, weperform 10-fold cross validation.
We report ourresults in Section 6.5.1 Baseline AlgorithmIn the training data, we count the number of timeseach classifier appears with a given noun.
We as-sign to each noun in the testing data its most fre-27No.
: 114303W C (word in Chinese): *E C (example in Chinese):G C (POS tag in Chinese): NW E (word in English): writerE E (example in English):G E (POS tag in English): NDEF (concept definition): human(|),#occupation(??
),*compile(?),#readings(??),literature(?
)Table 1: An entry in HowNetLexical Features Syntactic Featuresnoun POS of nounfirst premod POS of first premodsecond premod POS of second premodmain verb POS of main verbtotal number of premodifiers sentTypeembedded in vp or ppquoted or notTable 2: Features extracted from training dataquently co-occurring classifier (c.f.
(Sornlertlam-vanich et al, 1994)).
If a noun does not appear inthe training data, we assign the classifier ??
[ge]?,the classifier which appears most frequently over-all in the corpus.5.2 Noun FeaturesSince classifiers are assigned mostly based on thenoun, the most important features for classifierprediction should be features of the nouns.
Weran four different experiments for noun features:?
(1) The feature set includes only the noun it-self.?
(2) The feature set includes ontological fea-tures of the noun only.
If classifiers are as-sociated with semantic categories (c.f.
(Paikand Bond, 2001)), we should be able to as-sign classifiers based on the ontological fea-tures of nouns.?
(3) The feature set includes the noun and on-tological features.?
(4) Two SVMs are trained: one on the nounonly, and one on ontological features only.During testing, nouns in the training setare assigned classifiers using the first SVM;other nouns are assigned classifiers using thesecond SVM.5.3 Context FeaturesIn this set of experiments, we used features fromboth the noun and the context.
The features weused can be categorized into two groups: lexicalfeatures and syntactic features.
They are shownin Table 2.We ran two experiments using this set of fea-tures:?
(5) The feature set includes the noun, lexicaland syntactic features only.?
(6) The feature set includes the noun, lexical,syntactic and ontological features.6 Results and DiscussionWe built SVMs using all the feature sets describedin Section 5 and tested using 10-fold cross valida-tion.
We tried the four types of kernel function inLIBSVM: linear, polynomial, radial basis func-tion (RBF) and sigmoid, then selected the RBFkernal K(x, y) = e?
?||x?y||2 , which gives the28Algorithm All nouns Nouns occuring 2+ timesBaseline 50.76% 50.69%(1) noun only 57.81% (c = 4, ?
= 0.5) 59.34% (c = 16, ?
= 0.125)(2) ontology only 58.69% (c = 4, ?
= 0.5) 60.68% (c = 256, ?
= 0.125)(3) noun and ontology 57.81% (c = 16, ?
= 0.5) 59.46% (c = 16, ?
= 0.125)(4) noun or ontology 58.71% 60.55%(5) noun, syntactic andlexical features 52.14% (c = 1024, ?
= 0.5) 53.51% (c = 16, ?
= 0.5)(6) all features 52.06% (c = 1024, ?
= 0.075) 53.55% (c = 16, ?
= 0.5)Table 3: Accuracy of different algorithmsMost commonnoun?
[wei] '[ci] ?
[ge] ?
[ming] ?
[jie] 1[xiang]?
[wei] ?
(official) 24.1 (57.1) 14.7 (34.7)'[ci] L?
(conven-tion)22.3 (53.3) 1.1 (2.6) 7.6 (18.2)?
[ge] 1?
(project) 1.0 (7.0) 0.7 (5.2) 0.2 (1.7) 3.3 (24.4)?
[ming] |?
(person) 31.7 (55.2) 23.8 (41.4)?
[jie] ???
(sportstournament)1.9 (2.1) 29.6 (34.0) 31.5 (36.2)1[xiang] ?
* (achieve-ment)6.6 (11.3) 35.2 (60.4) 1.1 (1.9)Table 4: Most commonly misclassified classifiers; Cell shows percentage of total occurrences of rowvalue misclassified as column value and (percentage of total misclassifications of row value misclassi-fied as column value)highest accuracy.
For each feature set, we sys-tematically varied the values for the parameters C(range from 2?5 to 215) and ?
(range from 23 to2?15); we report the best results with correspond-ing values for C and ?.
Finally, for each featureset, we ran once on all nouns and once only onnouns occurring twice or more in the corpus.Classifier assignment accuracy is reported inTable 3.
The performance of all the SVMs is sig-nificantly better than baseline (paired t-test, p <0.005).
There is no significant difference betweenthe performance with the 1st, 2nd, 3rd and 4thfeature sets.
But the performance of the SVMs us-ing lexical and syntactic features (experiments 5and 6) is significantly worse than the performanceon feature sets 1-4 (df = 17.426, p < 0.05).These results show that lexical and syntacticcontextual features do not have a positive effecton the assignment of classifiers.
They confirm theintuition that the noun is the single most importantpredictor of the classifier; however, the semanticclass of the noun works as well as the noun itself.In addition, a combination approach that uses se-mantic class information when the noun is previ-ously unseen does not perform better.We also computed the confusion matrix for themost commonly misclassified classifiers.
The re-sults are reported in Table 4.For these experiments we used automatic eval-uation (cf.
(Paul et al, 2002)).
A classifier is onlyjudged to be correct if it is exactly the same as thatin the original test set.
For some noun phrases,there are multiple valid classifiers.
For example,we can say?[yi]L[kuai]?][jinpai]?or?[yi]?[mei]?][jinpai]?
(a golden medal).We did a subjective evaluation on part of ourdata to evaluate how many automatically gener-ated classifiers are acceptable to human readers.We randomly selected 241 noun-classifier pairsfrom our data.
We presented the sentence con-taining each pair to a human judge who is a na-tive speaker of Mandarin Chinese.
We asked thejudge to rate all the classifiers generated by our29Algorithm Number rated 1or higherPercent rated 1 orhigherAverage ratingBaseline 209 86.7% 1.59(1) noun only 224 92.9% 1.76(2) ontology only 226 93.8% 1.78(3) noun and ontology 226 93.8% 1.77(4) noun or ontology 227 94.2% 1.80(5) noun, syntactic andlexical features 218 90.5% 1.67(6) all features 218 90.5% 1.67Original 241 100% 1.95Table 5: Human evaluation: Ratings of classifiersalgorithms as well as the original classifier by in-dicating whether each is good (2), acceptable (1)or bad (0) in that sentence context.
The classifierswere presented in random order; the judge wasblind to the source of the classifiers.The results for our human evaluation are re-ported in Table 5.
Although our automatic eval-uation indicates relatively poor accuracy, 94.2%of generated classifiers using feature set 4) arerated acceptable or good in our subjective evalua-tion.
Also, the performance of SVMs with the 1st,2nd, 3rd and 4th feature sets is significantly bet-ter than baseline (paired t-test, p < 0.005).
Thereis no significant difference between the perfor-mance with the 1st, 2nd, 3rd and 4th feature sets.But the performance of the SVMs using lexicaland syntactic features (experiments 5 and 6) issignificantly worse than those without (p < 0.05).The ratings of the classifiers generated by all ouralgorithms are significantly worse than the origi-nal classifiers in the corpus.
In future work, weplan to extend this evaluation using more judges.Which classifier to select also depends on theemotional background of the discourse (Fang,2003).
For example, we can use different class-fiers to express different affect for the same noun(e.g.
if a government official is in favor or dis-grace).
However, we cannot get this kind of in-formation from our corpus.7 Conclusions and Future WorkOur machine learning approach to classifier as-signment in Chinese performs better than previ-ously published rule-based approaches and worksfor bigger data sets.
The noun is clearly the mostimportant feature (experiment 1).
However, westill think ontological features may be useful inclassifier assignment, for example for previouslyunseen nouns, and our experimental results showa trend in this direction, although not a statisti-cally significant one (experiments 2 and 4).We used the Chinese Treebank for these ex-periments because it is the only available corpusof parsed Chinese text.
Now that we have iso-lated the relevant features for this task, we plan toconduct further experiments using larger corpora,such as the Chinese Gigaword (Graf and Chen,2003).Our use of ontological features could be im-proved in several ways.
First, the ontological fea-tures we get from HowNet do not fit our pur-pose well.
For example, the definitions of ???
(cat) and ?:?
(cow) are both ?livestock?
; how-ever, they should use different classifiers.
In or-der to improve the performance of our approach,we need an ontology that correctly groups nounsinto classes according to their semantic properties(e.g.
type, shape, color, size).For another knowledge-rich approach, wecould use a complex ontology plus a Chineseclassifier dictionary that describes the propertiesof the objects each classifier can modify.
Bycomparing noun properties and classifier char-acteristics, classifier assignment could be im-proved as long as the nouns are in the ontol-ogy.
However, there are many idiomatic noun-classifier matchings that can not be categorisedby dictionaries.
Therefore, a combination of rule-30based and machine-learning approaches seemsmost promising.Third, we can classify Chinese classifers intogroups and focus on those that modify single ob-jects.
Certain Chinese classifiers can be usedbefore all plural nouns.
Some classifiers spec-ify the container of the objects, for example,?[yi] {[lanzi] ?*[pingguo]?
(a basket ofapples).
The classifier changes when the con-tainer changes.
These can be treated differentlyfrom sortal and anaphoric classifiers.AcknowledgementsWe thank the anonymous reviewers for their help-ful feedback, HowNet for giving us permission todownload their knowledge base, and Chih-ChungChang and Chih-Jen Lin for the implementationof LIBSVM.This material is based upon work supported bythe Defense Advanced Research Projects Agency(DARPA), through the Department of the Interior,NBC, Acquisition Services Division, under Con-tract No.
NBCHD030010.ReferencesB.
Boser, I. Guyon, and V. Vapnik.
1992.
A trainingalgorithm for optimal margin classifiers.
In Pro-ceedings of the Fifth Annual ACM Conference onComputational Learning Theory (COLT 1992).Chih-Chung Chang and Chih-Jen Lin,2001.
LIBSVM: a library for supportvector machines.
Software available athttp://www.csie.ntu.edu.tw/ cjlin/libsvm.Z.
Dong and Q. Dong.
2000.
Introductionto HowNet - Chinese message structure base.http://www.keenage.com.L.
Fang.
2003.
Research of Chinese lexicon teaching- quantities.
Journal of Secondary Education.D.
Graf and K. Chen.
2003.
Chinese gigaword.
LDCCatalog Number LDC2003T09.C.
Hsu and C. Lin.
2002.
A comparison of methodsfor multi-class support vector machines.
In IEEETransactions on Neural Networks.K.
Paik and F. Bond.
2001.
Multilingual generationof numeral classifiers using a common ontology.
InProceedings of the 19th International Conferenceon Computer Processing of Oriental Languages.M.
Paul, E. Sumita, and S. Yamamoto.
2002.
Corpus-based generation of numeral classifier using phrasealignment.
In Proceedings of the 19th InternationalConference on Computational Linguistics.V.
Sornlertlamvanich, W. Pantachat, and S. Meknavin.1994.
Classifier assignment by corpus-based ap-proach.
In Proceedings of the 15th Conference onComputational Linguistics.N.
Xue, F. Chiou, and M. Palmer.
2002.
Building alarge-scale annotated Chinese corpus.
In Proceed-ings of the 19th International Conference on Com-putational Linguistics.31
