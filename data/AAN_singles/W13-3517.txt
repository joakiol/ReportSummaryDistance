Proceedings of the Seventeenth Conference on Computational Natural Language Learning, pages 153?162,Sofia, Bulgaria, August 8-9 2013. c?2013 Association for Computational LinguisticsDynamic Knowledge-Base Alignment for Coreference ResolutionJiaping Zheng Luke Vilnis Sameer Singh Jinho D. Choi Andrew McCallumSchool of Computer ScienceUniversity of MassachusettsAmherst MA 01003{jzheng,luke,sameer,jdchoi,mccallum}@cs.umass.eduAbstractCoreference resolution systems can benefitgreatly from inclusion of global context,and a number of recent approaches havedemonstrated improvements when precom-puting an alignment to external knowledgesources.
However, since alignment itselfis a challenging task and is often noisy, ex-isting systems either align conservatively,resulting in very few links, or combine theattributes of multiple candidates, leadingto a conflation of entities.
Our approachinstead performs joint inference betweenwithin-document coreference and entitylinking, maintaining ranked lists of candi-date entities that are dynamically mergedand reranked during inference.
Further, weincorporate a large set of surface string vari-ations for each entity by using anchor textsfrom the web that link to the entity.
Theseforms of global context enables our systemto improve classifier-based coreference by1.09 B3 F1 points, and improve over theprevious state-of-art by 0.41 points, thusintroducing a new state-of-art result on theACE 2004 data.1 IntroductionCoreference resolution is the task of identifyingsets of noun phrase mentions from a documentthat refer to the same real-world entities.
For ex-ample, in the following excerpt: ?The Chicagosuburb of Arlington Heights is the first stop for?George W. Bush?1 today.
?The Texas governor?2stops in ?Gore?s home state?3 of ?Tennessee?4 thisafternoon.
.
.
?, (m1,m2) and (m3,m4) define thecoreferent pairs.
Coreference resolution forms animportant component for natural language process-ing and information extraction pipelines due to itsutility in relation extraction, cross-document coref-erence, text summarization, and question answer-ing.
The task of coreference is challenging forautomated systems as the local information con-tained in the document is often not enough to accu-rately disambiguate mentions, for example, corefer-encing (m1,m2) requires identifying that GeorgeW.
Bush (m1) is the governor of Texas (m2), andsimilarly for (m3,m4).
External knowledge-basessuch as FrameNet (Baker et al 1998), Wikipedia,Yago (Suchanek et al 2007), and Freebase (Bol-lacker et al 2008), can be used to provide globalcontext, and there is a strong need for coreferenceresolution systems to accurately use such sourcesfor disambiguation.Incorporating external knowledge bases intocoreference has been the subject of active recentresearch.
Ponzetto and Strube (2006) and Ratinovand Roth (2012) precompute a fixed alignment ofthe mentions to the knowledge base entities.
Theattributes of these entities are used during corefer-ence by incorporating them in the mention features.Since alignment of mentions to the external enti-ties is itself a difficult task, these systems favorhigh-precision linking.
Unfortunately, this resultsin fewer alignments, and improvements are onlyshown on mentions that are easier to align and core-fer (such as the non-transcript documents in Rati-nov and Roth (2012)).
Alternatively, Rahman andNg (2011) link each mention to multiple entities inthe knowledge base, improving recall at the costof lower precision; the attributes of all the linkedentities are aggregated as features.
Although thisapproach is more robust to noise in the documents,the features of a mention merge the different as-pects of the entities, for example a ?Michael Jordan?mention will contain features for both the scientistand basketball personas.Instead of fixing the alignment of the mentions tothe knowledge base, our proposed approach main-tains a ranked list of candidate entities for eachmention.
To expand the set of surface strings that153may be used to refer to each entity, the attributesof each candidate contain anchor texts (the visibletext) of the links on the web that refer to that entitycandidate.
When mentions are compared duringinference, we use the features computed from thetop ranked entity candidate of the antecedent men-tion.
As mentions are merged, the ranked lists ofcandidate entities are also merged and reranked, of-ten changing the top-ranked entity candidate usedin subsequent comparisons.
The large set of sur-face string variations and constant reranking of theentity candidates during inference allows our ap-proach to correct mistakes in alignment and makesexternal information applicable to a wider varietyof mentions.Our paper provides the following contributions:(1) an approach that jointly reasons about bothwithin-doc entities and their alignment to KB-entities by dynamically adjusting a ranked list ofcandidate alignments, during coreference, (2) Uti-lization of a larger set of surface string variationsfor each entity candidate by using links that appearall over the web (Spitkovsky and Chang, 2012), (3)A combination of these approaches that improvesupon a competitive baseline without a knowledgebase by 1.09 B3 F1 points on the ACE 2004 data,and outperforms the state-of-the-art coreferencesystem (Stoyanov and Eisner, 2012) by 0.41 B3F1 points, and (4) Accurate predictions on docu-ments that are difficult for coreference, such as thetranscript documents that were omitted from theevaluation in Ratinov and Roth (2012), and docu-ments that contain a large number of mentions.2 Baseline Pairwise SystemIn this section we describe a variant of a commonly-used coreference resolution system that does notutilize external knowledge sources.
This widelyadopted model casts the problem as a series ofbinary classifications (Soon et al 2001; Ng andCardie, 2002; Ponzetto and Strube, 2006; Bengstonand Roth, 2008; Stoyanov et al 2010).
Givena document with its mentions, the system itera-tively checks each mention mj for coreference withpreceding mentions using a classifier.
A corefer-ence link may be created between mj and one ofthese preceding mentions using one of the follow-ing strategies.
The CLOSESTLINK (Soon et al2001) method picks the closest mention to mj thatis positively classified, while the BESTLINK (Ngand Cardie, 2002) method links mj to the preced-Types FeaturesString-Similaritymention string match, head string match,head substring match, head word pair, men-tion substring match, acronymSyntax number match, gender match, apposition,relative pronoun, mention type, modifiermatch, head word POS tagsSemantic synonym, antonym, hypernym, modifier re-lations, both mentions are surrounded by averb meaning ?to say?, demonym matchOther predicted entity type, predicted entity typematch, both mentions in same sentence, sen-tence/token distance, capitalizationTable 1: Features of the baseline model.
Extensionsto Bengston and Roth (2008) are italicized.ing mention that was scored the highest.
If noneof the preceding mentions are classified as positive(for CLOSESTLINK), or are above a threshold (forBESTLINK), then mj is left unlinked.
After all thementions have been processed, the links are usedto generate a transitive closure that corresponds tothe recognized entities in the document.2.1 Pairwise Mention FeaturesThe features used to train our classifier are similarto those in Bengston and Roth (2008), includinglexical, syntactical, semantic, predicted NER types,etc., with the exclusion of their ?learned features?that require additional classifiers.
Further, we in-clude features that compare the mention strings, thedistance between the two mentions in terms of thenumber of sentences and tokens, and the POS tagsof the head words.
We also use the conjunctions ofthese features as in Bengston and Roth (2008), aswell as the BESTLINK approach.
The complete setof features are listed in Table 1.The training for our system is similarto Bengston and Roth (2008).
The positive train-ing examples are generated from mentions andtheir immediate preceding antecedent.
The neg-ative examples are generated from mentions andall their preceding non-coreferent mentions.
If themention is not a pronoun, preceding pronouns arenot used to create training examples, and they arealso excluded during inference.
In contrast to aver-aged perceptron used in Bengston and Roth (2008),our baseline system is trained using hinge-loss, `2-regularized SVM.2.2 Merging Pairwise FeaturesWhen a mention mj is compared against a preced-ing mention mi, information from other mentions154that are already coreferent with mi may be helpfulin disambiguating mj as they may contain infor-mation that is not available from mi.
Let M bethe mentions between mi and mj that are coref-erent with mi.
Let mq ?
M be the mention thatis closest to mj .
All the features from the pair(mq,mj), except those that characterize one men-tion (for example, mention type of mj), are addedto the features between (mi,mj).
This extends asimilar approach by Lee et al(2011) that mergesonly the attributes of mentions (such as gender, butnot all pairwise features).2.3 Pruning Comparisons During TrainingA potential drawback of including all the negativeexamples as in Bengston and Roth (2008) is thatthe negative instances far outnumber the positiveones, which is challenging for training a classifier.In their system, the positive training examples onlyconstitute 1.6% of the total training instances.
Bycontrast, Soon et al(2001) reduce the number ofnegative instances by using only mentions betweenthe mention and its closest coreferent pair as neg-ative examples.
Instead of just using the closestcoreferent mention, we extend this approach touse the k closest of coreferent preceding mentions,where k is tuned using the development data.3 Dynamic Linking to Knowledge-BaseIn this section, we describe our approach to coref-erence resolution that incorporates external knowl-edge sources.
The approach is an extension of thepairwise model described earlier, with the inclusionof a ranked list of entities, and using a larger set ofsurface string variations.3.1 AlgorithmWe describe our overall approach in Algorithm 1.The system assumes that the data is annotated withtrue mention boundaries and mention types.
Weadditionally tokenize the document text and tag thetokens with their parts of speech for use as features.First, an empty entity candidate list is created foreach mention in the document.
For each propernoun mention, we query a knowledge base for anordered list of Wikipedia articles that may referto it, and add these to the mention?s candidate list.Other mentions?
candidates lists are left empty.After this pre-processing, each mention miis compared against its preceding mentionsm1 .
.
.mi?1 and their top-ranked entity candi-Algorithm 1 Dynamic Linking to Wikipedia1: Input: Mentions {mj}2: Initialize blank entity lists {Em} .
Section 3.23: for m ?
Proper Noun Mentions do4: LINKWIKIPEDIA(m, Em) .
Section 3.25: POPULATEENTITYATTRS(Em) .
Section 3.36: end for7: for mi ?Mentions do8: Antecedents?
{m1...mi?1}9: for m?
?
Antecedents do10: t?
TOPRANKEDATTRS(Em?)
.
Section 3.411: s?
SCORE(m?, mi, t) .
Section 3.412: Scoresm??
s13: end for14: m?
?
argmaxm?
Scoresm?15: if Scoresm?
> threshold then16: MARKCOREFERENT(m?, mi)17: MERGEENTITYLISTS(Em?
, Emi ) .
Section 3.418: end if19: end for20: return Coreferent mention clustersdate using a classifier.
Amongst antecedentsm1 .
.
.mi?1 that score above a threshold, thehighest-scoring one mj is marked as coreferentwith mi and the two candidate lists that correspondto mi and mj are merged.
Merging two mentionsresults in the merging and reranking of their respec-tive entity candidate lists, described below.
If noantecedents score above a threshold, we leave themention in its singleton cluster.3.2 Linking to WikipediaTo create the initial entity candidate lists forproper noun mentions, we query a knowledge basesearcher (Dalton and Dietz, 2013) with the textof these mentions.
These queries return scored,ranked lists of entity candidates (Wikipedia arti-cles), which we associate with each proper nounmention, leaving the rest of the candidate listsempty.
Linking is often noisy, so only selecting thehigh-precision links as in Ratinov and Roth (2012)results in too few matches, while picking an aggre-gation of all links results in more noise due to lowerprecision (Rahman and Ng, 2011).
Additionally,since linking is often performed in pre-processing,two mentions that are determined coreferent dur-ing inference could still be linked to different KBentities.
To avoid these problems, we keep a list ofcandidate links for each mention, merging the listswhen two mentions are determined coreferent, andrerank this list during inference.3.3 Populating Entity AttributesAfter linking to Wikipedia, we have a list of can-didate KB entities for each mention.
Each entity155has access to external information keyed on theWikipedia article, but this information could moregenerally come from any knowledge base.
Giventhese entities, there are many possible features thatmay be used for disambiguation of the mentions,such as gender and fine-grained Wikipedia cate-gories as used by Ratinov and Roth (2012), how-ever most of these features may not be relevant tothe task of within-document coreference.
Instead,an important resource for linking non-proper men-tions of an entity is to identify the possible namevariations of the entity.
For example, it would beuseful to know that Massachusetts is also referredto as ?The 6th State?, however this information isnot readily available from Wikipedia.1We instead use the corpus describedin Spitkovsky and Chang (2012) that con-sists of anchor texts of links to Wikipedia thatappear on web pages.
This collection of anchortexts is sufficiently extensive to cover manycommon misspellings of entity names, as well asmany name variations missing from Wikipedia.For example, for the entity ?Massachusetts?, ouranchor texts include misspellings like ?Massachus-setts?
and ?Messuchusetts?, and the (debatably)affectionate nickname of ?Taxachusetts?
?none ofwhich are found in Wikipedia.
Using these anchortexts, each entity candidate provides a rich set ofname variations that we use for disambiguation, asdescribed in the next section.3.4 Inference with Dynamic LinkingThe input to our inference algorithm consists of anumber of mentions, a list of ranked entity candi-dates for the proper noun mentions that are presentin the KB, and a list of attributes (in this case, namevariations) for each entity candidate.Scoring: Our underlying model is a pairwiseclassification approach as described in Section 2.Similar to existing coreference systems such asBengston and Roth (2008) and Rahman and Ng(2011), we perform coreference resolution usinggreedy left-to-right pairwise mention classification,clustering each mention with its highest-scoringantecedent (or leaving it as a singleton temporarilyif no score is above a threshold).
We add the sameadditional features and perform feature mergingoperation (Section 2.2) as in our baseline system.1Some of this information is available as redirects andfrom links within Wikipedia, however these do not accuratelyreflect all the variations of the name.The top-ranked entity candidate of the an-tecedent mention is used during coreference toprovide additional features for the pairwise classi-fier.
Only using the top-ranked entity candidate al-lows the system to maintain a consistent one entityper cluster hypothesis, reducing the noise resultingfrom conflated entities.
The attributes for this top-ranked entity consist of name variations.
We add abinary feature, and conjunctions of this with otherfeatures, if the text of the right mention matchesone of these name variations.Entity List Merging: Once a mention pair isscored as coreferent, their corresponding entity can-didates are merged.
Merging is performed by sim-ply combining the two lists of candidates.
Note thatthere is only one candidate list for a given group ofcoreferent mentions at any point in inference: if m1and m2 have been previously marked as coreferent,and m3 is marked as coreferent with m2, m1?s en-tity candidates will then contain those from m3 forfuture classification decisions.Re-Ranking: After the two entity candidate listsare merged, we rerank the candidates to identifythe top-ranked one.
We sort the new list of candi-date entities by the number of times each candidateoccurs in the list, breaking ties by their originalrelevance from the KB.
For example, if two men-tions disagree on the top-ranked KB search result,but agree on the second one, after being clusteredthey will both use the second search result whencreating feature vectors for future coreference de-cisions.
Even though other candidates besides thetop-ranked one are ignored for a single classifica-tion decision, they may become top-ranked aftermerging with later candidate sets.This approach allows our system to use the inter-mediate results of coreference resolution to re-linkmentions to KB entities, reducing the noise andcontradictory features from incorrect links.
Addi-tionally, features from the KB are added to non-proper noun mentions once those mentions arelinked with a populated entity, allowing the resultsof coreference to enrich non-proper noun mentionswith KB-based features.
The initial proper nounqueries effectively seed the linking process, andKB data is then dynamically spread to the othermentions through coreference.3.5 ExampleWe describe a run of our approach on an exam-ple in Figure 1.
Consider three mentions, each156?about navigation charts that he hadordered from a company based in thestate of Washington.
He assumed ?
?opened one of them to discover theabsentee ballot of Steven H. Forresterof Bellevue, Wash?....were not meaningful becausecounting in Washington State hasbeen completed...(a) Example Excerpts with MentionsWashington, DCWashington State...Car WashThe Wash...Washington StateWashington State...WashingtonWashWashingtonState(b) Initial Alignment (top-ranked in bold)Washington StateWashington, DCCar WashThe Wash...Washington State...WashingtonWashWashingtonState(c) Merged and Reranked AlignmentFigure 1: Example of Dynamic Alignmentpaired with a top-ranked KB candidate: ?Washing-ton?, ?Wash?, and ?Washington State?.
For thefirst two mentions, clearly the top entity candidateis incorrect; hence approaches that rely on a fixedalignment will perform poorly.
In particular, since?Washington State?
mention is not compatible withthe top-ranked entities of the first two mentions(Washington, D.C. and Car Wash respectively), ap-proaches that do not modify the ranking duringinference may not resolve them.
However, the cor-rect candidate Washington State does appear in thecandidate entities of the first two mentions, albeitwith a lower rank.
In our approach, clusteringthe first two mentions causes the shared candidateWashington State to move to the top of the list.
Thecoreference system is now able to easily identifythat the ?Washington State?
mention is compati-ble with the Washington State entity formed by theprevious two mentions, providing evidence that thefinal mention should be clustered with either ofthem in subsequent comparisons.4 Experiments4.1 SetupWe evaluate our system on the ACE 2004 anno-tated dataset (Doddington et al 2004).
Followingthe setup in Bengston and Roth (2008), we splitthe corpus into training, development, and test sets,resulting in 268 documents in the train set, 107documents in the test set, and 68 documents in thedevelopment set.
The data is processed using stan-dard open source tools to segment the sentencesand tokenize the corpus, and using the OpenNLP2tagger to obtain the POS tags.
The hyperparame-ters of our system, such as regularization, initialnumber of candidates, and the number of compar-2http://opennlp.apache.org/isons during training (k in Section 2.3) are tunedon the development data when trained on the trainset.
The models we use to evaluate on the test dataset are trained on the training and development sets,following the standard evaluation for coreferencefirst used by Culotta et al(2007).To provide the initial ranked list of entity candi-dates from Wikipedia, we query the KB Bridge sys-tem (Dalton and Dietz, 2013) with the proper namementions.
KB Bridge is an information-retrieval-based entity linking system that connects the querymentions to Wikipedia entities using a sequentialdependence model.
This system has been shown tomatch or outperform the top performing systems inthe 2012 TAC KBP entity linking task.4.2 MethodsOur experiments investigate a number of baselinesthat are similar or identical to existing approaches.Wikipedia Linking: As a simple baseline, wedirectly evaluate the quality of the alignment forcoreference by merging all pairs of proper nounmentions that share at least one common candi-date, as per KB bridge.
Further, the non-pronounmentions are linked to these proper nouns if themention string matches any of the entity titles oranchor texts.Bengston and Roth (2008): A pairwise corefer-ence model containing a rich set of features, as de-scribed and evaluated in Bengston and Roth (2008).Baseline: Our implementation of a pairwisemodel that is similar to the approach in Bengstonand Roth (2008) with the differences described inSection 2.
This is our baseline system that performscoreference without the use of external knowledge.Incidentally, it outperforms Bengston and Roth(2008).Dynamic linking: This is our complete system as157described in Section 3, in which the list of candi-dates associated with each mention is reranked andmodified during inference.Static linking: Identical to dynamic linking ex-cept that entity candidate lists are not merged dur-ing inference (i.e., Algorithm 1 without line 17).This approach is comparable to the fixed alignmentmodel, as in the approaches of Ponzetto and Strube(2006) and Ratinov and Roth (2012).4.3 ResultsAs in Bengston and Roth (2008), we evaluate oursystem primarily using the B3 metric (Bagga andBaldwin, 1998), but also include pairwise, MUCand CEAF(m) metrics.
The performance of oursystems on the test data set is shown in Table 2.These results use true mentions provided in thedataset, since, as suggested by Ng (2010), corefer-ence resolvers that use different mention detectors(extraction from parse tree, detector trained fromgold boundaries, etc.)
should not be compared.Our baseline system outperforms Bengston andRoth (2008) by 0.32 B3 F1 points on this data set.Incorporating Wikipedia and anchor text informa-tion from the web with a fixed alignment (staticlinking) further improves our performance by 0.54B3 F1 points.
Using dynamic linking, which im-proves the alignment during inference, achievesanother 0.55 F1 point improvement, which is 1.09F1 above our baseline, 1.41 F1 above the currentbest pairwise classification system (correspondingto an error reduction of 7.4%), and 0.4 F1 above thecurrent state-of-art on this dataset (Stoyanov andEisner, 2012).
The improvement of the dynamiclinking approach over our baselines is consistentacross the various evaluation metrics.5 DiscussionWe also explore our system?s performance on sub-sets of the ACE dataset, and on the OntoNotesdataset.5.1 Document LengthCoreference becomes more difficult as the numberof mentions is increased since the number of pair-wise comparisons increases quadratically with thenumber of mentions.
We observe this phenomenonin our dataset: the performance on the smallestthird of the documents (when sorted according tonumber of mentions) is 8.5-10% higher than on thelargest third of the documents, as per the B3 metric.55   10 15 20 25 30 35 40 45 500.60.811.21.41.61.8Top X% of Docs by Number of MentionsImprovement overBaselineDynamic LinkingStatic LinkingFigure 2: Improvements on the top X% of docu-ments ranked by the number of mentions.Method Non-Transcripts TranscriptsBaseline 82.50 79.77RR 2012 83.03 -Static Linking 83.06 80.25Dynamic Linking 83.32 81.13Table 3: B3 F1 accuracy on transcripts and non-transcripts from the ACE test data.
RR 2012 onlyevaluate on non-transcripts.However, we expect dynamic linking of entities tobe more beneficial on these larger documents asour system can use the information from a largernumber of mentions to improve the alignment dur-ing inference.
Static linking, on the other hand, isunlikely to obtain higher improvements with thelarger number of mentions in the document as thealignment is fixed.We perform the following experiment to analyzethe performance with varying numbers of mentions.We sort all the documents in the test set accordingto their number of mentions, and evaluate on the topX% of this list (where X is 10, 33, 40, 50).
As theresults demonstrate in Figure 2, the improvementof the static linking approach stays fairly even asX is varied.
Even though the experiments suggestthat the larger documents are tougher to corefer-ence,3 dynamic linking provides higher improve-ments when the documents contain a larger numberof mentions.5.2 Performance on TranscriptsThe quality of alignment and the coreference pre-dictions for a document is influenced by the qualityof the mentions in the document.
In particular,3i.e., the absolute values are lower for these splits.
Thebaseline system obtains 83.08, 79.29, 79.64, and 79.77 respec-tively for X = 10, 33, 40, 50.158Method Pairwise MUC CEAF B3P / R F1 P / R F1 P / R F1 P / R F1Culotta et al(2007) - - - - - - 86.7 73.2 79.3Raghunathan et al(2010) 71.6 46.2 56.1 80.4 71.8 75.8 - - 86.3 75.4 80.4Stoyanov and Eisner (2012) - - - 80.1 - - - 81.8Wiki-linking 64.15 14.99 24.30 74.41 28.39 41.10 58.54 58.4 58.47 92.89 57.21 70.81Bengston and Roth (2008) - - 82.7 69.9 75.8 - - 88.3 74.5 80.8Baseline 66.56 47.07 55.14 82.84 72.02 77.05 75.58 75.40 75.49 87.02 75.97 81.12Static Linking 82.53 40.80 54.61 88.39 66.93 76.18 75.33 75.35 75.44 93.10 72.72 81.66Dynamic Linking 72.20 47.40 57.23 85.07 72.02 78.01 76.55 76.37 76.46 89.37 76.12 82.21Table 2: Evaluation on the ACE test data, with the system trained on the train and development sets.00.20.40.60.811.21.4Improvement overBaselinenon-transnon-transtranscriptsStatic Linking Dynamic LinkingtransFigure 3: Comparison on the transcripts data.ACE contains a large number of broadcast newsdocuments, many of which consist of transcribeddata containing noise in the form of incompletesentences and disfluencies.
Since these transcriptsprovide an additional challenge for alignment andcoreference, Ratinov and Roth (2012) only use theset of non-transcripts for their evaluation.Using dynamic linking and a large set of surfacestring variations, our approach may be able to pro-vide an improvement even on the transcripts.
Toidentify the transcripts in the test set, we use theapproximation from Ratinov and Roth (2012) thatconsiders a document to be non-transcribed if itcontains proper noun mentions and at least a thirdof those start with a capital letter.
The performanceis shown in Table 3, while the improvement overour baseline is shown in Figure 3.Our static linking matches the performance ofRatinov and Roth (2012) on the non-transcripts.Further, the improvement of static linking on thetranscripts over the baseline is lower than that onthe non-transcript data, suggesting that noisy men-tions and text result in poor quality alignment.
Dy-namic linking, on the other hand, not only outper-forms all other systems, but also shows a higher im-provement over the baseline on the transcripts thanon non-transcripts.
This indicates that dynamiclinking approach is robust to noise, and its widervariety of surface strings and flexible alignmentsare especially useful for transcripts.5.3 OntoNotesWe also run our systems on the OntoNotes dataset,which was used for evaluation in CoNLL 2011Shared Task (Pradhan et al 2011).
The datasetconsists of 2083 documents from a much larger va-riety of genres, such as conversations, magazines,web text, etc.
Further, the dataset al consists ofmentions that refer to events, most of which do notappear as Wikipedia pages.
Since only the non-singleton mentions are annotated in the training set,we also include additional noun phrase mentionsduring training.
We obtain B3 F1 of 65.3, 67.6, and67.7 for our baseline, static linking, and dynamiclinking respectively.4 When compared to the par-ticipants of the closed task, the dynamic linkingsystem outperforms all but two on this metric, sug-gesting that dynamic alignment is beneficial evenwhen the features have not been engineered forevents or for different genres.6 Related WorkWithin-document coreference has been well-studied for a number of years.
A variety of ap-proaches incorporate linguistic knowledge as rulesiteratively applied to identify the chains, suchas Haghighi and Klein (2009), Raghunathan etal.
(2010), Stoyanov et al(2010).
Alternatively(and similar to our approach), others represent thisknowledge as features in a machine learning model.Early applications of such models include Soon etal.
(2001), Ng and Cardie (2002) and (Bengstonand Roth, 2008).
There are also a number of tech-niques that represent entities explicitly (Culotta et4with MUC 46.1, 49.9 & 50.1, and CEAF(m) 47.9, 49.6 &49.8, respectively for baseline, static and dynamic linking.159al., 2007; Wick et al 2009; Haghighi and Klein,2010; Stoyanov and Eisner, 2012).This work is an extension of recent approachesthat incorporate external knowledge sources to im-prove within-document coreference.
Ponzetto andStrube (2006) identify Wikipedia candidates foreach mention as a preprocessing step, and incor-porate them as features in a pairwise model.
Ourmethod differs in that we draw such features fromentity candidates during inference, and also main-tain and update a set of candidate entity linksinstead of selecting only one.
Rahman and Ng(2011) introduce similar features from a more ex-tensive set of knowledge sources (such as YAGOand FrameNet) into a cluster-based model whosefeatures change as inference proceeds.
However,the features for each cluster come from a combina-tion of all entities aligned to the cluster mentions.We improve upon this approach by maintaining alist of the candidate entities for each mention clus-ter, modifying this list during the course of infer-ence, and using features from only the top-rankedcandidate at any time.
Further, they do not providea comparison on a standard dataset.Ratinov and Roth (2012) extend the multi-sievecoreference model (Raghunathan et al 2010) byidentifying at most a single candidate for each men-tion, and incorporating high-precision attributesextracted from Wikipedia.
The high-precisionmention-candidate pairings are precomputed andfixed; additionally, the features for an entity arebased on the predictions of the previous sieves, thusfixed while a sieve is applied.
With these restric-tions, they show improvements over the state-of-the-art on a subset of ACE mentions that are moreeasily aligned to Wikipedia, while our approachdemonstrates improvements on the complete set ofmentions including the tougher to link mentionsfrom the transcripts.There are a number of approaches that providean alignment from mentions in a document toWikipedia.
Wikifier (Ratinov et al 2011) analyzesthe context around the mentions and the entitiesjointly, and was used to align mentions for corefer-ence in Ratinov and Roth (2012).
Dalton and Dietz(2013) introduce an approximation to the above ap-proach, but incorporate retrieval-based supervisedreranking that provides multiple candidates andscores; this approach performed competitively onprevious TAC-KBP entity linking benchmarks (Di-etz and Dalton, 2012).
Alignment to an externalknowledge-base has improved performance for anumber of NLP and information extraction tasks,such as named-entity recognition (Cucerzan, 2007;Han and Zhao, 2009), cross-document corefer-ence (Finin et al 2009; Singh et al 2010), andrelation-extraction (Riedel et al 2010; Hoffmannet al 2011).7 ConclusionsIn this paper, we incorporate external knowledge toimprove within-document coreference.
Instead offixing the alignment a priori, our approach main-tains a ranked list of candidate entities for eachmention, and merges and reranks the list duringinference.
Further, we consider a large set of sur-face string variations for each entity by using an-chor texts from the web.
These external sourcesallow our system to achieve a new state-of-the-arton the ACE data.
We also demonstrate improve-ments on documents that are difficult for alignmentand coreference, such as transcripts and documentscontaining a large number of mentions.A number of possible avenues for future studyare apparent.
First, our alignment to a knowledge-base can benefit from more document-aware link-ing to entities, such as the Wikifier (Ratinov et al2011).
Second, we would like to augment mentionfeatures with additional information available fromthe knowledge base, such as Wikipedia categoriza-tion and gender attributes.
We also want to investi-gate a cluster ranking model, as used in (Rahmanand Ng, 2011; Stoyanov and Eisner, 2012), to ag-gregate the features of all the coreferent mentionsas inference progresses.AcknowledgmentsThis work was supported in part by the Centerfor Intelligent Information Retrieval, in part byDARPA under agreement number FA8750-13-2-0020, in part by NSF medium IIS-0803847 andin part by an award from Google.
The U.S. Gov-ernment is authorized to reproduce and distributereprint for Governmental purposes notwithstandingany copyright annotation thereon.
Any opinions,findings and conclusions or recommendations ex-pressed in this material are the authors?
and neces-sarily those of the sponsor.160ReferencesAmit Bagga and Breck Baldwin.
1998.
Algorithmsfor scoring coreference chains.
In InternationalConference on Language Resources and Evaluation(LREC) Workshop on Linguistics Coreference, pages563?566.Collin F. Baker, Charles J. Fillmore, and John B. Lowe.1998.
The berkeley framenet project.
In Proceed-ings of the 36th Annual Meeting of the Associa-tion for Computational Linguistics and 17th Inter-national Conference on Computational Linguistics -Volume 1, ACL ?98, pages 86?90, Stroudsburg, PA,USA.
Association for Computational Linguistics.Eric Bengston and Dan Roth.
2008.
Understandingthe value of features for coreference resolution.
InEmpirical Methods in Natural Language Processing(EMNLP).Kurt Bollacker, Colin Evans, Praveen Paritosh, TimSturge, and Jamie Taylor.
2008.
Freebase: a collab-oratively created graph database for structuring hu-man knowledge.
In Proceedings of the 2008 ACMSIGMOD international conference on Managementof data, SIGMOD ?08, pages 1247?1250, New York,NY, USA.
ACM.Silviu Cucerzan.
2007.
Large-scale named entity dis-ambiguation based on Wikipedia data.
In EmpiricalMethods in Natural Language Processing (EMNLP),pages 708?716.Aron Culotta, Michael Wick, and Andrew McCallum.2007.
First-order probabilistic models for corefer-ence resolution.
In North American Chapter of theAssociation for Computational Linguistics - HumanLanguage Technologies (NAACL HLT).Jeffrey Dalton and Laura Dietz.
2013.
A neighbor-hood relevance model for entity linking.
In OpenResearch Areas in Information Retrieval (OAIR).Laura Dietz and Jeffrey Dalton.
2012.
Across-document neighborhood expansion: UMass at TACKBP 2012 entity linking.
In Text Analysis Confer-ence (TAC).G.
Doddington, A. Mitchell, M. Przybocki,L.
Ramshaw, S. Strassel, and R. Weischedel.2004.
The Automatic Content Extraction (ACE)program?tasks, data, and evaluation.
In Pro-ceedings of LREC, volume 4, pages 837?840.Citeseer.Tim Finin, Zareen Syed, James Mayfield, Paul Mc-Namee, and Christine Piatko.
2009.
Using Wiki-tology for cross-document entity coreference resolu-tion.
In AAAI Spring Symposium on Learning byReading and Learning to Read.Aria Haghighi and Dan Klein.
2009.
Simple corefer-ence resolution with rich syntactic and semantic fea-tures.
In Empirical Methods in Natural LanguageProcessing (EMNLP), pages 1152?1161.Aria Haghighi and Dan Klein.
2010.
Coreference reso-lution in a modular, entity-centered model.
In NorthAmerican Chapter of the Association for Computa-tional Linguistics - Human Language Technologies(NAACL HLT), pages 385?393.Xianpei Han and Jun Zhao.
2009.
Named entity disam-biguation by leveraging Wikipedia semantic knowl-edge.
In Conference on Information and KnowledgeManagement (CIKM), pages 215?224.Raphael Hoffmann, Congle Zhang, Xiao Ling,Luke Zettlemoyer, and Daniel S. Weld.
2011.Knowledge-based weak supervision for informationextraction of overlapping relations.
In Annual Meet-ing of the Association for Computational Linguis-tics (ACL), pages 541?550, Portland, Oregon, USA,June.
Association for Computational Linguistics.Heeyoung Lee, Yves Peirsman, Angel Chang,Nathanael Chambers, Mihai Surdeanu, and DanJurafsky.
2011.
Stanford?s multi-pass sievecoreference resolution system at the CoNLL-2011shared task.
In Conference on ComputationalNatural Language Learning (CoNLL), pages 28?34.Association for Computational Linguistics.Vincent Ng and Claire Cardie.
2002.
Improving ma-chine learning approaches to coreference resolution.In Annual Meeting of the Association for Computa-tional Linguistics (ACL), pages 104?111.Vincent Ng.
2010.
Supervised noun phrase corefer-ence research: the first fifteen years.
In Proceedingsof the 48th Annual Meeting of the Association forComputational Linguistics, ACL ?10, pages 1396?1411, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.Simone Paolo Ponzetto and Michael Strube.
2006.Exploiting semantic role labeling, WordNet andWikipedia for coreference resolution.
In NorthAmerican Chapter of the Association for Computa-tional Linguistics - Human Language Technologies(NAACL HLT), pages 192?199.Sameer Pradhan, Lance Ramshaw, Mitchell Marcus,Martha Palmer, Ralph Weischedel, and NianwenXue.
2011.
CoNLL-2011 shared task: Modelingunrestricted coreference in ontonotes.
In Confer-ence on Computational Natural Language Learning(CoNLL), pages 1?27.Karthik Raghunathan, Heeyoung Lee, Sudarshan Ran-garajan, Nathanael Chambers, Mihai Surdeanu, DanJurafsky, and Christopher Manning.
2010.
A multi-pass sieve for coreference resolution.
In EmpiricalMethods in Natural Language Processing (EMNLP),pages 492?501.
Association for Computational Lin-guistics.Altaf Rahman and Vincent Ng.
2011.
Coreferenceresolution with world knowledge.
In Annual Meet-ing of the Association for Computational Linguis-tics (ACL), pages 814?824, Portland, Oregon, USA,June.161L.
Ratinov and D. Roth.
2012.
Learning-based multi-sieve co-reference resolution with knowledge.
InEmpirical Methods in Natural Language Processing(EMNLP).L.
Ratinov, D. Roth, D. Downey, and M. Anderson.2011.
Local and global algorithms for disambigua-tion to wikipedia.
In Annual Meeting of the Associa-tion for Computational Linguistics (ACL).Sebastian Riedel, Limin Yao, and Andrew McCallum.2010.
Collective cross-document relation extractionwithout labelled data.
In Empirical Methods in Nat-ural Language Processing (EMNLP).Sameer Singh, Michael L. Wick, and Andrew McCal-lum.
2010.
Distantly labeling data for large scalecross-document coreference.
Computing ResearchRepository (CoRR), abs/1005.4298.Wee Meng Soon, Hwee Tou Ng, and DanielChung Yong Lim.
2001.
A machine learning ap-proach to coreference resolution of noun phrases.Computational Linguistics, 27(4):521?544, Dec.Valentin I. Spitkovsky and Angel X. Chang.
2012.
Across-lingual dictionary for english wikipedia con-cepts.
In International Conference on Language Re-sources and Evaluation (LREC).Veselin Stoyanov and Jason Eisner.
2012.
Easy-firstcoreference resolution.
In Computational Linguis-tics (COLING).Veselin Stoyanov, Claire Cardie, Nathan Gilbert, EllenRiloff, David Buttler, and David Hysom.
2010.Coreference resolution with reconcile.
In AnnualMeeting of the Association for Computational Lin-guistics (ACL), pages 156?161, Stroudsburg, PA,USA.
Association for Computational Linguistics.Fabian M. Suchanek, Gjergji Kasneci, and GerhardWeikum.
2007.
Yago: a core of semantic knowl-edge.
In Proceedings of the 16th international con-ference on World Wide Web, WWW ?07, pages 697?706, New York, NY, USA.
ACM.Michael Wick, Aron Culotta, Khashayar Rohani-manesh, and Andrew McCallum.
2009.
An entity-based model for coreference resolution.
In SIAM In-ternational Conference on Data Mining (SDM).162
