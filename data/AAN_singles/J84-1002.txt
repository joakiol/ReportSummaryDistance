A Formal Basis for Performance Evaluationof Natural Language Understanding SystemsGiovann i  Gu ida  1 and G iancar lo  Maur i  2Istituto di Matemat ica ,  Informatica e Sistemist icaUniversit~ di UdineUdine, ItalyThe task of evaluating the performance of a natural language understanding system,despite its largely recognized relevance, is still poorly defined.
It mostly relies on intuitivereasoning and lacks a sound theoretical foundation.
This paper sets a formal and quantita-tive proposal for this task.
In particular, a measure of performance that allows the basicinput-output characteristics of a system to be evaluated is introduced first at an abstractlevel.
The definition of concrete measures is then obtained by assigning actual values tothe functional parameters of the abstract definition; some particular cases are shown anddiscussed in detail.
Finally, the task of measuring performance in practice is considered,and a model for experimental performance evaluation is presented.
Comparison withrelated works is also briefly discussed; open problems and promising directions for futureresearch are outlined.
A limited case study experimentation with the model proposed ispresented in the appendix.1.
IntroductionResearch on natural language processing has recentlybeen featured by the design and implementation of anumber of experimental systems.
Recent survey re-ports (Waltz 1977, Kaplan 1982) mention more thanone hundred items among the most successful andrelevant systems in the classical application fields ofdata base inquiry, machine translation, question an-swering, and man-machine interfacing.This trend is not surprising in the context of re-search whose specific aim is that of providing automat-ed tools for the understanding or translating of naturallanguages; but it is also evident even in natural lan-guage research with a more theoretical flavour.
Thesuccessful construction of a good performing system is1 Address:Prof. Giovanni GuidaDipartimento di ElettronicaPolitecnico di MilanoP.zza Leonardo da Vinci, 32i-20133 MILANO, ItalyAlso with Milan Polytechnic Artificial Intelligence Project, Milano,Italy.2 Also with lstituto di Cibernetica, Universita di Milano, Mila-no, Italy.in fact often considered as the most evident proof ofthe validity of a theory, and, therefore, designing run-ning systems is routine, and even sometimes the spe-cific goal of several researchers.The task of evaluating the performance of a givensystem and that of comparing the behaviour of differ-ent systems appears, therefore, to be a fundamentalissue.
Despite its large recognized relevance (Woods1977, Tennant 1980), measuring the performance of asystem for natural language processing is still poorlydefined.
It mostly relies on intuitive reasoning andlacks a sound theoretical foundation.
As Tennantclearly points out (1980), there is a nearly completeabsence of meaningful evaluation in current naturallanguage processing research.
This leaves several cru-cial questions unanswered:?
What is the relevance and value of obtained results??
How general are the proposed solutions??
How do they compare with other proposals??
What problems are still open??
What directions have to be followed??
What issues are to be faced in the progress of theresearch?Copyright 1984 by the Association for Computational  Linguistics.
Permission to copy without fee all or part of this material is grantedprovided that the copies are not made for direct commercial advantage and the CL reference and this copyright notice are included on thefirst page.
To copy otherwise, or to republish, requires a fee and/or  specific permission.0362-613X/84/030015- -16503.00Computational Linguistics, Volume 10, Number 1, January-March 1984 15Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUSThe lack of evaluation constitutes a serious obsta-cle to the development of a sound technology in natu-ral language processing.The purpose of this paper is to provide a formaland quantitative model for the performance valuationtask.
In particular, we give a formal definition of"understanding power",  and we propose some techni-ques for measuring this feature in practice.
Our pro-posal is based on several assumptions we discuss be-low.First, we assume as object of our attention onlythat module of a natural language system that is devot-ed to understanding natural language, that is, to map-ping input expressions into formal internal representa-tions.
This can clearly include several kinds of proc-essing activities, such as linguistic analysis, reasoning,inferencing, etc.
; but must have as ultimate goal theconstruction of a correct internal representation, otthe production of any type of service to the end userof the natural language system.
Thus, for example, aquestion answering system (Tennant 1979) does notbelong to the class of natural language understandingsystems that concern us; instead, it is the natural lan-guage interface it contains that meets exactly our re-quirements.Second, we assume the following naive notion ofperformance: the extent to which a system is able tocorrectly understand natural language expressions in agiven application domain.
The resources needed bythe system to accomplish its task are irrelevant in thiscase.
In other words, we want to capture and measurethe "power"  of the system, in terms of how much andhow well it is capable of understanding, not its"eff iciency", that is, how much does it cost (for exam-ple, in terms of time and memory requirements) tounderstand what it is capable of understanding.Third, we want to define a measure of performancethat allows the evaluation of the input-output charac-teristics of a particular system in a given domain.
Thiskind of measure is clearly inappropriate to reveal andtest features, such as the power of a model as opposedto that of a particular implementation of it, the appli-cability of the model to other domains, its extensibili-ty, etc., which are more closely related to the internalstructure and mode of operation of a system, ratherthan to its input-output behaviour.
The goal of evalu-ating such more general properties, worked on by Ten-nant (1980) through the method of abstract analysis(mainly based on taxonomies of conceptual, linguistic,and implementational issues), is not considered in thiswork.This paper is organized in the following way.
Insection 2 we discuss in an intuitive, yet precise, waythe basic concepts involved in the performance valua-tion problem, in order to have a sufficiently clearspecification of what we want to formalize.
Then, insection 3, we give an abstract definition of the formalmodel, and in section 4 we discuss some actual casesof particular interest.
Section 5 presents some techni-ques that could be used to measure in practice theperformance of a natural language understanding sys-tem.
In section 6 we discuss some concluding re-marks, and present open problems and promising top-ics for future research.
A limited case study experi-mentation with the model proposed is presented in theappendix.2.
Basic Definit ions and Statement  of theProblemLet us introduce some background definitions neededto clearly state the problem of performance valuation,as discussed in this work.
The model of natural lan-guage understanding we are going to define is so con-ceived as to include only those very few features thatare relevant for the purpose of performance valuationand is strictly tailored to this particular goal.Let an expression of a natural language be any fi-nite sequence of legal words and punctuation marksfrom the given language.
Let A be the set of all ex-pressions of a natural language.Note that the above definition is very loose anddoes not take into account the structure of the expres-sions.
So an expression can be a sentence, a dialogue,a meaningless sequence of words, the whole content ofa book, or just a single word.
Introducing a moredefinite notion of expression is not necessary at thispoint for our purpose of stating the problem of per-formance evaluation.Although the above definition includes expressionsof arbitrarily (finite) length, so that A contains infi-nitely many expressions, in a more pragmatic approachthe length of existing expressions of a natural languageat a given moment of its history has an upper bound.Therefore, it makes sense to restrict our attention to afinite subset E of A, containing all expressions oflength less than or equal to an appropriately fixedinteger n.Let L be the set of all meaningful expressions of anatural language, that is, of all expressions to whichhumans attach a meaning.
Note that L is defined on apurely semantic basis, so that expressions of L do nothave to be syntactically correct with respect to anyfixed syntax, and that, generally, more than one mean-16 Computational Linguistics, Volume 10, Number 1, January-March 1984Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUSing may be attached to the same expression, that is,expressions are not required to be univocal.Let S be the set of all possible meanings that canbe attached to expressions of E.We do not face here the problems of what S actual-ly contains or of how S could be represented explicitly(which mostly pertain to cognitive psychology); let usassume S merely as that basic datum, shared by allhumans speaking a given language, which allows effec-tive interpersonal communication.We call the semantics of a natural language thetotal function f: E~2 s (into 2S), which associates toeach expression of E the set of all its possible mean-ings.Clearly the function f can be computed by anyperson who can understand perfectly the natural lan-guage to which the expressions of E belong (theoreti-cal problems concerning subjective interpretation anddisagreement between different people are not consid-ered here).Moreover,  f(e) = ~ denotes that no meaning isassociated to the expression e, and hence eeLiff f(e) ~ .Each expression eeE such that I f (e) l_<l is calledan univocal expression.Let now D be a nonempty subset of S that containsmeanings all related to a unique subject ("what we arespeaking of", "the topic of the discourse", "the con-ceptual competence of a natural language understand-ing system"); we call D a domain.Let fD be the restriction of f to D defined as:fo(e)  = f(e)fl D, for any eeE.Let L D = E- - fDI (~)  be the restriction of L to D.It is obvious that LD_qL_qE.Let us now try to formalize the concept of naturallanguage understanding system.The main problem is that of giving a formal repre-sentation to the informally defined domain D. To thispurpose, we take a finite set of symbols B, calledalphabet, and then we construct a set R of sequencesof arbitrary finite length over B (that is, R -B* ) ,  insuch a way that to every element deD an element ofR, r = laD(d), is associated by a bi-univocal functionh o.
The sequence r = hD(d) is called therepresentation f d, while the set R is called a represen-tation language for D.Obviously, the map la Dl is a total functionhD~:R-~D, which associates to every sequence of R itsinformal meaning in D. Both h D and laD 1 are knownto man, in the sense that he is able to compute them.We are now able to formalize the naive notion ofnatural language understanding system in the followingway.Let D-S  be a domain and R a representation lan-guage for D. A natural language understanding systemUR/D in R on D is an algorithm that computes a totalu R function gR/D:E---2 U {_L} (into 2Ru {?
}), where ?
isU called the undefined symbol, gR/D(e) = ?
denotes thatU is unable to assign a meaning to the expression e,that is, that it fails in computing gR/D(e) (not that ehas no meaning in the domain D!
).Note that in the above definition we have assumedthat a system UR/D should accept as input not onlyexpression of L D but, generally, all expressions of E.The reason for this choice is that a basic feature ofnatural language understanding is also to recognizethat some expressions are meaningless (they belong toE -L )  or are in no way related to a given domain D(they are in L -LD) .
Clearly, this feature is often lessimportant han the capability of correctly understand-ing expressions of LD, but this can be appropriatelytaken into account when defining a measure of per-formance.Measuring the performance of a natural languageunderstanding system UR/D may now be defined asevaluating how well UR/D is capable of explicitly rep-resenting in R the meaning of expressions of E.To define such a notion in quantitative terms wecan first extend the bi-univocal function hD:D--,-R tothe function (bi-univocal if ?
is not considered)hD:2D~ 2Ru {?
},defined by:hD(X) = U {hD(d)},dexfor xe2 D.Figure 1 illustrates the definitions of the functionsuf, fD' hD' hD' and gR/D presented above.Considering now the three functions fD, hD, and ugR/D defined above, if we denote hDOfD-----gD' theperformance of UR/D can then be expressed as the udegree of precision to which gR/D approaches gD overE.This task raises, however, some difficult problems.Two basic questions are: u(i) how to define the "di f ference" between gR/D andgD over E in such a way to match the intuitivenotion of performance;(ii) how to measure such a "di f ference" in practice,that is, through an effective experimental proce-dure.Computational Linguistics, Volume 10, Number 1, January-March 1984 17Giovanni Guida and Giancarlo Mauri  A Formal Basis for Performance Evaluation of NLUS2 s / 2 DfOs f OELLD~rgUR/D2 ~ u f?lU Figure 1.
Relationships between the functions f, fD, hD, hD' and gR/D"18 Computat iona l  Linguistics, Vo lume 10, Number 1, January-March 1984Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUSBoth of these problems are discussed in the follow-ing sections (the former in sections 3 and 4, and thelatter in section 5).3.
A Theoret ica l  F rameworkBefore tackling the core topic of this section in a for-mal way, let us examine from an intuitive point ofview the basic requirements for a measure of perform-ance ~r to be reasonably acceptable.
The primary goalis that it should allow consistent comparison amongdifferent systems, in the sense that if ~r(U 1) = qr(U 2)the behaviour of the two systems U 1 and U 2 should besufficiently similar, and that if ~r(Ul)>~r(U2), U 1should perform better than U 2.Furthermore, this comparison should be as fine andprecise as possible, in such a way to capture all theessential features of the behaviour of a system U in agiven domain.Finally, comparison might be between two differentsystems, between two versions of the same system,between a system and a given set of issues, or betweena system and an independent scale (Tennant 1980).To capture the intuitive notion of performanceaccording to the above requirements, at least twopoints of view seem worth considering.
First, a meas-ure of performance should give a numerical value foruthe "distance" between the two functions gR/D andgD' that is, the measure should allow us to formalizeuhow near gR/D(e) approaches ~D(e) for any eeE, or,more explicitly, how well each expression e?E is un-derstood by the system U.
Second, it should weightthis notion of "distance" in such a way as to take intoaccount the fact that, generally, it is not equally im-portant to understand well any expression in E; forexample, it could be reasonable to suppose that correctunderstanding of expressions in L D is far more rele-vant than in E--LD, or that correct understanding ismore important for frequently used expressions thanfor unusual and rare ones.According to the above remarks, an appropriatenotion of performance qr will depend on two basic pa-rameters:(i) the shifting #ubetween gR/D(e) and ~D(e) for any eEE(ii) the importance pfor any expression eeE to be correctly under-stood.Different choices of /z and p clearly provide differ-ent notions of performance, ~r\[/~,0\], that fit differentneeds for capturing particular classes of features in anatural language understanding system.Let us now go further in defining an appropriateformal framework embedding the above ideas.
In the ufollowing, we shall omit in fD, gR/D, and gD the super-script U and the subscripts R /D  and D, whenever thiswill not cause ambiguities.Let R be a representation language for a domainDc-S a shifting function ~t on R is a function/z:(2 R U {.t .
})x2R~\[0,1\] ,such that:- for each pair (r ,r ' ) ,  /z(r,r') = 0 iff r = r ' ;- there exists a pair (r,r t) such that/z(r,r  w) = 1.From an intuitive point of view, /~(g(e),~(e)) repre-sents the "di f ference" between the (set of) meaning(s)of e computed by a natural language understandingsystem U, which is expressed by g(e), and its correct(set of) meaning(s) ~(e).
Hence, the valuetz(g(e),g(e)) = 0 denotes perfect understanding of e,while t~(g(e),g(e)) = 1 denotes the worst case of mis-understanding of e.Given the set E of all expressions of a natural lan-guage of length less or equal than an appropriatelyfixed integer n, an importance function O on E is afunctionp:E-* \[0,1\].Intuitively, p(e) represents the importance that themeaning of e is correctly understood by the system U.The value p(e) = 0 denotes that it is not at all impor-tant that e be understood correctly or incorrectly;values of p(e) greater than 0 denote the greater impor-tance for e to be understood correctly.
Given a shift-ing function # on R and an importance function p onE, a performance measure cr for natural language un-derstanding systems OR/D is the function'/7"\[/x,p\] : {OR/D} ~ \[0,1 \],defined by:#(gR/D(e),gD(e)) o(e)?r\[/~,p\](UR/D) = e~Ep(e)eEEClearly, ~r ranges from the value 0, in the casewhere all expressions of E are correctly understood, tothe value 1, in the case where all expressions are com-pletely (that is, in the worst manner) misunderstood,Computational Linguistics, Volume 10, Number 1, January-March 1984 19Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUSindependently of the choice of 0 (of course, o -O isnot allowed, being meaningless).~r\[/~,O\] provides a very synthetic representation ofthe performance of U that can be useful in severalcases of evaluation and comparison.
A richer andmore informed picture of the performance of a systemU fully coherent with the above definitions can beobtained in the following way, for the cases where theranges of tt and 0 are finite.
For given shifting tz andimportance 0, let range(t~) = {61 ..... 8 n} and range(o)= {?01,...,60m}.
Then we pose:Ei, j = {e I tz(g(e),~(e)) = 8iandp(e) = a~j},for iE{1 ..... n} and jE{1 ..... n}.Clearly, UEi, j = E and all El, j are pairwise disjoint.Therefore, {Ei,j} is a partitioning of E.Now let:I E~,j IPi,j = I EI  'for iE{1 ..... n} and jE{1 ..... m}.
(We remember that Ehas been assumed to be finite, and hence so is Ei,j_-qE ).The n xm matrix \[Pi,j\] is called the ~-o-profile ofU and and provides a far more informed representa-tion of the performance of U than the value ~r\[/~,0\].
Infact, \[Pi,j\] allows one to discover and analyse thespecific features of the system, going beyond the glob-al value ~r\[/~,O\].The relation between \[Pi,j\] and ~r\[/~,O\] is straight-forward:n m IE I~r\[#'P\] = X Z Pi,j ?
8i ?
wj ?
?i=l j=l Z 0(e)ecENote that \[Pi,j\] depends on /z and p only through thepartitioning {El,j} they induce on E, but it is inde-pendent of the actual values of 8 i and ~oj.Different choices of /~ and p clearly provide differ-ent measures of performance that can be compared, ingeneral, only on a qualitative and intuitive basis.Therefore, evaluating the performance of a system Urequires first the definition of t~ and 0, and then thecomputation of rr\[/z,p\].
Clearly, the most critical ofthese two steps is, from a conceptual point of view,the first as it completely determines the "goodness" ofthe measure and its actual matching with desired intui-tive requirements.
The second is only difficult fromthe computational point of view since E is usually verylarge and, hence, it is not possible to evaluate the sumin the definition of ~r\[/~,p\] in a direct, exhaustive way.In the next section we discuss in detail the problemof appropriately defining t~ and p, while section 5 isdevoted to the topic of actually computing ~r\[/~,p\].4.
Some S ign i f i cant  Choices of Sh i f t ing  andImpor tance  ParametersHaving discussed in the previous section an abstracttheory of performance valuation, we now deal withsome implementations of it that may be of practicalinterest.
Clearly, an implementation is obtained byassigning actual functions as values for the(functional) parameters /~ and p in the definition of ~r.Different choices of/z and p will yield different modelsfor performance valuation and will allow one to ana-lyse different features of the systems to be evaluated.Since ~ and p are fully independent parameters, weshall deal with each separately.Let us begin with the shifting function t~; in orderthat only the effect of /~ be relevant to 7r, we shallsuppose throughout the following discussion that 0 hasthe constant value 0 (e )= l  for any eEE.The simplest case is that where /z may assume onlytwo (boolean) values 0 and 1, denoting a correct and awrong understanding, respectively.
Such a booleanshifting function is denoted by /~1 and formally de-fined by:{~ if r' =r"/ l l ( r " r " )  = if r '#r"for any pair ( r ' , r ' )e (2Ru {?
})x2  R.The intuitive meaning of /~1, when used to evalu-ate a natural language understanding system U, isstraightforward: ~r\[tzl,1\](U ) = x denotes the percent-age of expressions of E that U is unable to understandcorrectly (clearly, 1 -x  is the percentage of expres-sions correctly understood by U).The above definition of ~t is very crude; in fact,systems with the same qr\[/ll,1 \] can show a very dif-ferent behaviour, and, furthermore, qr\[#l,1\](Ul) 2>~r\[tzl,1\](U 2) does not generally ensure that U 1 per-forms better than U 2.A slight improvement can be obtained by splittingthe case r1#r '' into two subcases that cover, whenevaluating U, the following situations:(i) U is unable to assign a meaning to an expressione (that is, it fails); hence, g(e) = r' = ?
# r" =~(e)(ii) U assigns to an expression e a meaning that is notthe correct one; hence, g(e) = r' # r" = ~(e),with g(e) # ?.20 Computational Linguistics, Volume 10, Number 1, January-March 1984Giovann i  Guida and Giancarlo Mauri A Formal  Basis for Performance Evaluation of NLUSIt seems quite reasonable that generally case (i) isless serious than case (ii), so that we can propose anew definition of shifting ~t2:l 0 if r '  =r"  /~2(r',r") = 8 if r '  = ?
1 if r '#?
and r '#r"where 3E(0,1).Clearly, the choice of 8 strongly affects the valuesof ~r\[/~,l\](U) and will depend on how much we want todistinguish between cases (i) and (ii) mentionedabove.Going further to propose more fitting definitions of#, we may want to analyze in more detail the caser '~?
and r '#r" .
Recalling that r '  and r" are sets ofstrings in R, we can distinguish the following cases:(i) U assigns to an expression e the value 4~ (that is,no meaning), while it has a well-defined mean-ing;(ii) U assigns to an expression e a proper nonemptysubset of its meanings;(iii) U assigns to an expression e all its correctmeanings and, in addition, other incorrect ones;(iv) U assigns to an expression e a proper nonemptysubset of its meanings and, in addition, otherincorrect ones;(v) U assigns to an expression e a nonempty set ofmeanings that is fully different from the correctone.that covers Formally, we can define the shifting It 3all such situations by:/~3 (r ' , r " )0 i f  r w - r "d 1 i f r '=  ?8 2 i f r '=~andr"#~8 3 if r '#~ and r ' c r "= 8 4 if r '  ~r" and r"#q,3 5 if r 'Nr"#q~ and r ' - r "#~and r " - r '  #q~1 if r'#4~ and r 'N r" = ~where 6i?
(0,1), for i = 1, 2, 3, 4, 5.It could be reasonably assumed 61 < 8 2 < 6 3 < 6 4< 6 5, since the situations to which they are attachedare generally considered as denoting increasing degreesof misunderstanding (note that #3 deals in great detailwith the case of ambiguous understanding, where atleast one of r '  or r" is not a singleton).Along the line of reasoning shown in the abovedefinitions, several other improvements are possible.For example, we can further refine the above case (v),r'#4~ and r 'N r" = ~, by taking into account the actu-al structure of the elements of r '  and r".
R being awell-defined formal language, we can first define anappropriate notion of "distance" /~ between elementsof R, and then extend it to nonempty disjoint elementsof 2 R.This kind of ref inement is particularly significantwhen both r '  and r" are singletons, that is, under-standing is not ambiguous, as is often the case.
Also,it generally allows far more meaningful definitions ofshifting, thus further approaching the intuitive notionof "distance" as "degree of understanding".Let us turn our attehtion now to the importancefunction 0.Also for this function, a first simple proposal canbe a boolean definition: no importance at all is as-signed to expressions in E -L  D and the same (notnull) importance to every expression in L D. So wecan define Pl as:p l (e)  = /~ i fe~LDif eeL Dfor each eeE.A refinement of p\] can be obtained by analyzingthe case eeL D and taking into account the frequencyof use of expressions in L o.
This will give more im-portance to the correct understanding of more fre-quently used expressions and less importance to thatof rare or unusual ones.
From the human point ofview, it is obvious that texts with a greater frequencyare used, and hence understood, by a larger number ofpeople.Therefore, it seems meaningful to consider a systemthat can understand quite well the relatively smallnumber of the most common texts and fails on themost unusual ones, to be better than a system thatunderstands a lot of very rare texts but often fails inunderstanding the most common ones.Formally, we can define the frequency of expres-sions of e as a map z : E- - \ [0,1\] ,  with the constraintthat E z(e) = 1.
Then, we can define a new impor-eEEtance function P2 such that:z(e) if eeL o02(e) = 0 otherwiseThe frequency function z(e) can be effectively deter-mined by collecting, through an appropriate experi-mental activity, a meaningful bag of texts T, in whicheach eeE appears with a given integer multiplicitym(e), and then by computingComputational Linguistics, Volume 10, Number 1, January-March 1984 21Giovanni Guida and Giancarlo Mauri  A Formal Basis for Per formance Evaluation of NLUSm(e)z(e) = - -E m(e) "eEEA totally different criterion that could be used to re-fine the definition of importance functions is structuralcomplexity of the expressions of E (or of LD).A very crude notion of structural complexity issimply given by the length of an expression e. In thiscase, given a chain 0 = ~O<~l<.. .</~m_ 1 of m non-negative integers, we can partition E into m classes:E l = {elg0< lel <e l}Ez = {e lg l< le l  _<~2 }E m = {e ~m_l < I el \].Then, a new importance function P3 is defined by:P3(e) = t0 i iff e~Ei,where ?0iE\[0,1\], for i = 1 .... ,m.It is worth noting that the length of a text is not inde-pendent of its frequency of use; we feel that in severalapplication domains (such as, for example, man-machine interaction) short texts are much more fre-quent than long ones and that texts exceeding a givenlength are not used at all.A more refined notion of structural complexity ofan expression may be given by taking into account itssyntactic structure, defined on the basis of an appro-priate set of characteristic features - see, for example,the classification proposed in Tennant (1980).
E canbe partit ioned into different and disjoint classes E i,according to the set of syntactical features they match,and an importance function P4 can  be defined asabove:P4(e) = ,0 i iff eEEi,where ~0iE\[0,1\], for i = 1 ..... m.Let us note that, contrary to the above illustratedrelation between the length of a text and its frequency,it seems reasonable to consider syntactical complexityas fully independent of frequency; in fact, quite com-plex syntactical features (such as ellipsis, anaphora,broken text, etc.)
are frequently found in several ap-plication domains.Finally, a couple of other possible choices for as-signing the importance function p are worth mention-ing: one based on the notions of " informationcontent" or "structural complexity" according to Kol-mogorov (1965, 1968), and the other based on theconcept of "semant ic  complexity"  of an expression,which could be formally defined, for example, in therepresented omain R. However,  some more theoreti-cal work on these notions is necessary before we canuse them for our needs; hence we will not further de-velop these notions here.5.
Measuring Performance in .PracticeIn the preceding sections, some theoretical tools formeasuring the performance of a natural language un-derstanding system have been illustrated.
At thispoint we have to put them to work: that is, we mustdiscuss how the performance of a system can be actu-ally evaluated and how the comparison between twodifferent systems can be carried out.We distinguish two steps in the process of perform-ance evaluation:(i) to assign the functions/~ and p;(ii) to compute ~r\[#,p\].Let us examine in detail each of the two points.The choice 'of the shifting function /~ depends onlyon the degree to which we want to refine the notion oferror in understanding and on the varying importancewe want to assign to each type of error.
Hence it isoften only a matter of subjective feeling choosing ap-propriate values for /~ in order to analyse particularfeatures of the system to be evaluated.
Also, the defi-nition of # is strongly dependent on the representationlanguage R for the domain D: the richer and morestructured R is, the more refined and subtle are thepossible definitions of/~.On the contrary, however, the choice of the impor-tance function p can generally be based on more ob-jective arguments, once an appropriate ranking amongthe desired understanding capabilities of the system tobe evaluated has been defined.
For example, in thecase where the frequency of texts is taken into ac-count, an appropriate xperimental  activity can pro-vide reliable statistical estimations for the frequencyz(e) of each expression eEE, thus allowing the effec-tive computation of p(e).
(Problems connected withthe choice of a meaningful sample to estimate z(e) -which could freely include millions of millions of ex-pressions - are not dealt with here, since they aremore related to statistics than to computat ional  lin-guistics.
)Clearly, the choice of t~ and p fully determines thenumerical value of ~r\[/~,p\] (or of the matrix \[Pi,j\]) incorrespondence to a given system U.
How a change in/~ or p can affect qr\[/~,p\] is generally impossible to pre-22 Computat ional  Linguistics, Volume 10, Number 1, January-March 1984Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUSdict, since this strongly depends on the particular fea-tures of U.
Therefore, evaluating a system with differ-ent choices of p or p can indeed provide a clearer im-age of its performance.
Although the comparisonbetween different values of 7r obtained with differentpairs (#,O) is often only a matter of intuitive reason-ing, an interesting particular case that can be conven-iently dealt with formally is briefly sketched below.A shifting function /~' is a refinement of a shiftingfunction # (/~'_2/,) iff:- range(/,) = {61 ..... 6 n} with 61<62<.
.
.<6 n ;- range(/ , ' )  = {6' l .... ,6'n,}, with 6 '1< 6 '2<.
.
.<6t n, and n v >n ;- the partitioning {El} of E induced by/z t is a re-f inement of the partitioning {El} of E induced by/~;- for each class E i = U E '  t, , whereteTT= {t I ..... ti } _c {1 ..... n '},  w i th t l<  t2<.
.
.<  ti:6 i_1<6' t l<6t t2<.
.
.<6; t i  = 6 i.In an analogous way we can define the refinementp, of an importance function p (pv___p).A pair (~tV,p v) is a refinement of a pair (/~,p) (wewrite (p ' ,p ' )  _3 (/~,p)) iff/~' _3 /z and p'  _3 p.It is straightforward to prove that:For any system U and any two pairs (/z,p) and(p ' ,p ' ) ,  (/L',p') _3 (/~,p) implies ~r\[tt' ,p'\](U ) <~\[~,p\](U).For example, the shifting function /z 3 in section 4refines /~2, which in turn refines /Zl, that is,/~1 --- #3" For the importance function p, on the otherhand, not one of the functions Ol, P2,  P3 ,  P4 ,  insection 4 is a refinement of any other one.It is worth noting that, when defining appropriatepairs (it,p) to evaluate a system, there are basicallytwo ways of reasoning for comparing different choices:the first one is to Start from a first basic proposal andto proceed through successive ref inements until thedesired degree of precision and detail is reached; thesecond one consists in proposing functions correspond-ing to several different points of view and then inte-grating them together in a well-balanced synthesis.Generally, the first approach is appropriate for thedefinition of /x, while the second one can be utilizedfor the choice of o.Let us turn now to the problem of computing~r\[/~,O\], once/~ and P have been assigned.Obviously, it is unrealistic to compute the exactvalue of qr by considering the behaviour of the systemwith respect to every expression ecE.
Hence, a se-quence of test cases has to be considered (Gold 1967).Figure 2 shows a model for experimental perform-ance evaluation.
A GENERATOR provides at eachtime instant i ( i=1,2 .... ) an expression eiEE.
Then,the system U to be evaluated computes the meaningg(ei), which is compared by/z with the correct mean-ing g(ei) supplied by an EVALUATOR (a man suppos-ed to be able to compute ~, that is, both f and ~).Finally, the value p(ei) is computed, and the currentvalue ofiE /~(g(ej),g(ej)) ?
p(ej)j= l,/7" i =ip(ei)j= lis determined.The major problem with the computation of ~r isthe design of the GENERATOR, that is, the choice ofthe sample of E to be used for the evaluation of thesystem U.The mathematically simplest case is the one wherea subset B _ E is randomly generated on the basis of agiven probabil ity distribution in E (for example, equi-probability); then,qr B =~\] ~(g(e),~(e)) ?
p(e)ecBp(e)eeBis a random variable such that E(qrB) = 7r for reason-able distributions, where E0rB) denotes the expecta-tion of qr B.
The value of E(qrB) may be estimated bymeans of statistical techniques such as, for example,the maximum likelihood function.
Here, we will notgive a detailed account of such techniques.
They canbe easily found in classical works of statistics and sam-pling theory (Kobayashi  1978; Cox, Hinkley 1977;Mood, Graybill 1980), when needed.A different technique would be that of fixing aconfidence interval, and then establishing the numbern of tests to be generated in order to obtain the valueof qr(/z,p) within the given confidence level, by means,for example, of X 2 techniques.In addition to these elementary statistical methods,more sophisticated sampling techniques can be used.This requires us first to choose a partitioning of E intomeaningful classes, and then to define a sample strati-fied according to the considered partitioning.
In thisComputational Linguistics, Volume 10, Number 1, January-March 1984 23Giovanni Guida and Giancarlo Mauri  A Formal Basis for Per formance Evaluation of NLUSGENERATOR Iei_1 system U- It0 be evatuated-~  EVALUATORI g(ei) ~ i ) )i\] t\] (ei) j=Z1 IJ (g(eil'c\](eJ))'P(ei)i,_ j=lFigure 2.
A model for experimental performance evaluation.TElILcase, the GENERATOR might not work on a purelyrandom basis.All the above-mentioned techniques are independ-ent of the choice of p, and do not take into accountspecific goals that could be assigned to performanceevaluation (for example, syntactic capabilities, linguis-tic or conceptual competence, etc.).
Such generalpurpose methods can sometimes provide a too muchglobal and too less meaningful evaluation.
Moreover,the sample to be used for the computation of ~r is gen-erally very large and hard to collect.Special purpose evaluation, centered on the analysisof some specific features of U, can often be moreinteresting and easier to implement.
In this case, thespecific goal of the measurement should be carefullytaken into account in the definition of P, and both thegoal and p should direct the choice of the appropriatesample of E to be used for the experimental computa-tion of ~r.
More precisely, an experimental (specialpurpose) evaluation session could be organized asfollows:1. precisely individuating the system U, the domainD, and the representation language R;2. defining the goals of the evaluations;3. deciding which samples of E to collect and how tocollect them;4. defining/~;5. defining p (and how to compute it for the chosensamples);6. computing ~r (and/or  \[Pi,j\])-Note that several tx and p could be generally consid-ered for a careful experimentation.
Moreover, steps 3,4, and 5 might require, in critical cases, specific pre-experimentation a d some refinement loops for appro-priate tuning.In the appendix, a limited case study experimenta-tion is briefly discussed.6.
Discussion and Future Research DirectionsIn this paper we have presented a model for perform-ance evaluation of natural language understandingsystems.
The main task of this model is that of pro-viding a basis for a quantitative measure of how well asystem can understand natural language, thus allowingan objective and experimental comparison of the per-formance of different systems.Before discussing some open problems and illustrat-ing the main lines of future research, let us brieflydiscuss some further features of our approach by com-paring it to the classical work by Tennant (1979,1980) and by Finin, Goodman, and Tennant (1979).Tennant's proposal is based on the three main con-cepts of habitability, completeness, and abstract analy-sis.
This last point is not considered here, as ex-plained in section 1 (see further in this section for its24 Computational Linguistics, Volume 10, Number 1, January-March 1984Giovanni  Guida and Giancar lo  Maur i  A Formal  Basis for  Per fo rmance  Evaluat ion of  NLUSpossible relevance to future work); we therefore focuson the first two.
From a naive point of view, habita-bility is used to test whether or not the system doeswhat it was designed to do; completeness i  introducedto test whether or not the system meets users' require-ments.
More precisely, Tennant introduces the twonotions of coverage and completeness to denote, respec-tively, the capabilities (both conceptual and linguistic)that the designer has put within a system, and(similarly to Woods, Kaplan, Nash-Webber 1972though differing from Woods 1977) the degree towhich the capabilities expected by a set of users canactually be found in the system coverage.
Further-more, habitability denotes (quite differently from Watt1968) the degree to which a system can actually ex-hibit the capabilities that it was designed to have.Our approach is based on a slightly different modeland provides in some sense a refinement of the aboveconcepts.We denote by the term competence the capabilitiesthat a system is actually able to show, while by theterm coverage we refer, according to Tennant, to thetheoretical capabilities that a system should have as aconsequence of its design specifications.More precisely, the conceptual coverage of a sys-tem UR/D is formalized in our model by the domainD, which represents, in fact, the range of concepts thatare within the domain of discourse of a given applica-tion.The linguistic coverage clearly includes L D but,generally, is not limited to L D since understanding alanguage in a given domain also implies the capabilityof recognizing that some expressions are not meaning-ful in that domain.In general, for a given importance function p, wecan assume that the linguistic coverage is defined by:LW D = {e l ecE and 0(e)>A},where A(0<A<I )  is a fixed bound.The linguistic competence can then be defined as:L '  D = {e I eeL '  D and g(e) = ~(e)},and the conceptual competence as:D = U fD(e).eeLrD(without distinction between conceptual and linguisticaspects) approaches its coverage.
This measure isquite similar to, and provides a ref inement of, theconcept of habitability, involving also to some extentthe notion of completeness.
In fact, both the choiceof D as an adequate domain and the definition of o asa suitable importance function (and, therefore, ofLWD) implicitly refer to a set of users and then tocompleteness.It is apparent hat the proposal introduced in thispaper demands further work, both theoretical andexperimental, in order to have fully adequate tools forperformance valuation.First of all, some of the concepts presented herehave to be further discussed and expanded.
For exam-ple, in the definition of ~r, we have normalized it withrespect o O by setting:E / t .pA different choice could be:E/?pqT"  - -  mIEIwhere tt and p are given the same importance (in thiscase the value ~r=l would be reached only when allexpressions of E are fully misunderstood, that is,t~=_l, and when it is important at the highest degreethat each of them is correctly understood, that is,0 -1 ) .
While we have preferred here the first defini-tion, arguments could be given in favour of the sec-ond.A second critical point is the definition of the/~-p-profile \[Pi,j\]" This could be further extended soas to provide a picture of several dimensions (features,for example: frequency, syntactic complexity, informa-tion content, etc.).
Third, it is worthwhile consideringand improving the notion of refinement: in fact, thepresent definition is not stable with respect to thechoice of ~t and O.
That is, it could be that, given twosystems U and UI:~\[u,p\](u) < ~\[u,pl(U')and, for some refinement (tL',p') of (/~,p):~r\[~',o'\](U) > ~r\[tz',p'\](U'),The above concepts are summarized in Figure 3.Our definition of performance ~r\[/~,p\] tries to give aglobal idea of how well the competence of a systemso that the refinement of the evaluation criteria maygive an inversion of the first evaluation.
A formaldevelopment of the three points mentioned above willComputational Linguistics, Volume 10, Number 1, January-March 1984 25Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUSsystemdesignlevelsystemperformancelevelDconceptualcoverageconceptualcompetencecapabi l i t ies expected bythe users//I / COMPLETENESSI / %JW#L D \l ingu is t icHABITABILITYcompetenceNATURAL LANGUAGEUNDERSTANDINGSYSTEMUFigure 3.
Coverage and competence of a natural anguage understanding system.26 Computational Linguistics, Volume 10, Number 1, January-March 1984Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUSbe part of a future paper.For what concerns the main directions in the devel-opment of the current research activity, we mention:?
experimentation with the model proposed in theevaluation of large systems;?
development of appropriate sampling techniques forthe experimental evaluation of 7r;?
experimentation with several different choices of /~and p;?
design of techniques for special purpose evaluation(choice of the goal, definition of/~ and p, sampling,etc.);?
analysis of the adequacy of the notion of/~-p-profilefor representing all interesting details of the per-formance of a system.Beyond these issues we also point out two moreambitious and promising problems; they will be facedin future work.
The approach to performance valua-tion presented in this paper has two major limitations:first, it is only concerned with input-output behaviourand does not take into account the internal model onwhich a system is based; second, it does not deal withthe efficiency of the natural language understandingprocess.
As far as the former topic is concerned, it isclear that, except in the case where commercial appli-cations are considered, one is primarily interested inmodels rather than in particular implementations.
It isfar more significant hat a model, a knowledge repre-sentation method, and a parsing algorithm have beendesigned to build natural language understanding sys-tems rather than that a specific system has been con-structed in a particular domain for a particular use.Tennant (1980) (see also Woods 1977) proposes amethod, called abstract analysis, to organize in an in-formal but disciplined way the evaluation, throughtaxonomies of conceptual, linguistic, and implementa-tional issues, of the internal behaviour of a naturallanguage system (including analysis of failure causes,domain dependent features, knowledge base complete-ness and closure, algorithm deficiencies, extensibility,etc.).
A very demanding research issue that couldsubstantially contribute to the development of theresearch on natural language processing is the defini-tion of more formal methods that, starting from theabove proposal, allow a "deep" evaluation and com-parison of systems on the basis of their internal struc-ture and mode of operation, opposed to the "surface"measure of their input-output behaviour, as consideredin the present paper.Concerning the latter topic, efficiency, two aspectsseem worth considering: the experimental measure ofthe efficiency of a specific system in understandingnatural language that could appropriately complete theconcept of performance defined in the present work;and the theoretical evaluation of the complexity of thegeneral model underlying the construction of a particu-lar system, which could possibly complete the notionof "deep" evaluation mentioned above.AcknowledgementsWe are grateful to the anonymous referees for theiruseful criticism and suggestions.We would also like to acknowledge the appreciatedsupport provided by CSELT Laboratories (Torino,Italy) with the experimentation of the PARNAX sys-tem.ReferencesComino, R.; Gemello, R.; Guida, G.; Rullent, C.; Sisto, L.; andSomalvico, M. 1983 Understanding Natural LanguageThrough Parallel Processing of Syntactic and Semantic Knowl-edge: An Application to Data Base Query.
In Proc.
8th Int.Joint Conference on Artificial Intelligence.
Karlsruhe, West Ger-many: 663-667.Cox, D.R.
and Hinkley, D.V.
1974 Theoretical Statistics.
Chapmanand Hall, London.Finin, T.; Goodman, B.; and Tennant, H. 1979 JETS: AchievingCompleteness Through Coverage and Closure.
In Proc.
6th Int.Joint Conference on Artificial Intelligence.
Tokyo, Japan: 275-281.Gold, E.M. 1967 Language Identification i  the Limit.
Informa-tion and Control 10: 447-474.Kaplan, J.
1982 Special Section: Natural Language Processing.ACM S IGART Newsletter 79:27-109 and 80: 59-61.Kolmogorov, A.N.
1965 Three Approaches to the Concept of"'The Amount of Information".
Probl.
o f  InformationTransmission 1 (1): 3-11.Mood, R.S.
and Graybill, H.J.
1980 Introduction to Statistics.McGraw-Hill, Englewood Cliffs, New Jersey;Tennant, H. 1979 Experience with the Evaluation of NaturalLanguage Question Answerers.
in Proc.
6th Int.
Joint Confer-ence on Artificial Intelligence.
Tokyo, Japan: 874-876.Tennant, H. 1980 Evaluation of Natural Language Processes.Report T-103.
Coordinated Science Laboratory, University ofIllinois, Urbana, lllinois.Waltz, D. 1977 Natural Language Interfaces.
ACM S1GARTNewsletter 61 : 16-64.Watt, W.C. 1968 Habitability.
American Documentation 338-351.Woods, W.A.
1977 A Personal View of Natural Language Under-standing.
ACM S IGART Newsletter 61: 17-20.Woods, W.A.
; Kaplan, R.M.
; and Nash-Webber, B.
1972 TheLunar Sciences Natural Language Information System: FinalReport.
Report 2378.
Bolt Beranek and Newman, Cambridge,Massachusetts.Computational Linguistics, Volume 10, Number 1, January-March 1984 27Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUSAppend ixIn this appendix we present a limited case study ex-perimentation with the model proposed, which shouldhelp in concretely conveying the ideas on how an eval-uation session could be carried out in practice.
Widerexperiments will be the subject of a future paper.For this limited experimentat ion we have chosenthe PARNAX system (Comino et al 1983): a naturallanguage interface for querying in Italian ADABASdata bases.
The toy data base utilized concerns theemployees of a company, and contains just theEMPLOYEE file with the following record structure:(ii) eliminating all queries differing only for the val-ues of the attributes (for example, "Tell me thebirth-date of John"  and "Tell me the birth-dateof  Robert") ,  except one.Note that this preprocessing constitutes a kind of verynaive stratif ication, consisting in the choice of onlysome elements as representative for a class of cases.A v contains about 800 queries.The shifting function /z has been chosen to be theboolean function:{0 if g (e )=g(e)/~(g(e),g(e)) = if g (e )#g(e)NAMEDATE-OF-BIRTHPLACE-OF-BIRTHPLACE-OF-RESIDENCEHIRING-DATEDEPARTMENTJOB-LEVELDEGREEThe PARNAX system, that is, the natural languageunderstanding system U to be evaluated, maps naturallanguage queries (more generally, query dialogues)into expressions of the formal query language used toaccess the ADABAS data base, namely the NATURALlanguage.Owing to the very simple data base chosen, thedomain D is reasonably limited, and so are L D (theset of all possible queries in Italian to the EMPLOYEEfile) and R (the set of all possible NATURAL queries).We consider two goals for this experiment: namely,evaluating some aspects of the conceptual competenceand of the linguistic competence.According to these goals, two samples of querieshave been collected from LtD-ZL D (recall that thelinguistic coverage L wD-E should generally be largerthan L D - see section 6):A: A sample of casual queries to the data base.
Ninehundred fifty queries have been collected from 90people chosen from several different classes ofpossible users of the data base.B: A sample of linguistic variations for expressing aspecific request.
The sentence to be rephrasedhas been chosen of medium-level complexity withrespect to the sample data base so as to allowmeaningful linguistic variations to be formed.The query utilized is: "Tell me the birth-date ofall employees who have a master degree inmathematics".
Five hundred queries have beencollected from 35 people.The sample A was then slightly preprocessed beforebeing used for the evaluation.
A new sample A t wasobtained from A through the following operations:(i) eliminating all queries expressing the same request(not having the same answer!
), except one;I 1 =12 =13 =The following importance function P3defined:\[ 0.70 i feE I  10.25 if ecI  2P3(e) = I .0.05 if eEI 3(see section 4, /~l) for the analysis both of A w and B.Several different choices have been taken for theimportance function p. For what concerns the sampleA t , two functions have been considered:- p l= l-- 02(e) = if eeL D(see section 4, 02).For the sample B the most natural choice for 0seemed to be the frequency of queries.
Unfortunately,only very few (30 queries in sample B turned out tobe repeated (one repetition for two queries, two repe-titions for another query; note that this result is highlysurprising even if the set from which B has been ex-tracted is enormously large).
Therefore, frequencywas abandoned.
Two other criteria were considered:namely length and structural features.For what concerns the former, the length (numberof words) of each sentence was computed first andTable 1 obtained.
The length interval \[5,26\] was thenpartit ioned into three parts:\[12,16\], into which about 70% of the sentencesof  B fall;\[7,111U\[17,18\], includes about 25% of the ex-pressions of B;\[5,61U\[19,26\], to which less than 5% of thesentences of B belong.has beenHere, the importance of recognizing an expressionis assumed to be proport ional to the "weight"(cardinality) of the length class to which it belongs.For what concerns the latter criterion, we first defineda taxonomy of linguistic elements suitable for analys-ing the structural features of the sentences of SampleB.
The following attributes were considered (Tennant1980):28 Computational Linguistics, Volume 10, Number 1, January-March 1984Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUSD declarative structureG interrogative structureE imperative structureT telegraphic sentencesV cleft and discontinuous sentences, parentheticclauses, inversionsM multiple sentencesR relative clausesI interrogative clausesN non-finite clauses (-ing, -ed participle)P prepositional phrasesQ quantifiers, predeterminersS possessive and demonstrat ive clauses, personalpronounsThe sentences of B were then classified according tothe above taxonomy by assigning to each of them allthe relevant attributes.
F i f ty-two classes were ob-tained:44 containing 1 to 12 sentences (total 315)5 containing 13 to 24 sentences (total 92)3 containing 25 to 36 sentences (total 93)NUMBER OFLENGTH SENTENCES5 26 77 118 179 1310 2511 4012 5313 13014  6215 4516 5017 2418 1219 520 221 126 1Table 1.This result suggested restricting the analysis to asmaller number of classes to be obtained through aless refined taxonomy of linguistic elements.
The fol-lowing attributes, which characterize the most crudefeatures of the sentence structure, were chosen: D, G,E, T, V, M. Ten classes have now been obtained asshown in Table 2 (each class is denoted by the stringof attributes that characterizes the structure of thesentences belonging to it).NUMBER OFSTRUCTURE SENTENCEST 22D 91DV 6DM 27G 79GM 5E 174EV 44EM 33EVM 19Table 2.The importance function P4 has therefore beendefined to be exactly the frequency of the class towhich every expression belongs, that is:.044 if ecT.182 if eeD.012 i feeDV.054 if ecDM.158 if eeGp4(e) = .010 i feEGM.348 if eeE.088 if ecEV.066 if eEEM.038 if eeEVMUsing the samples A w and B and the # and p functionsdefined above, the performance of the PARNAX sys-tem was evaluated.
The following results were ob-tained:Computational Linguistics, Volume 10, Number 1, January-March 1984 29Giovanni Guida and Giancarlo Mauri A Formal Basis for  Per fo rmance  Evaluat ion of  NLUSCase 1: sample A t with # and 01472 \[0.41 \]~r 1 - = 0.59 \[Pi,j\] = 800 I_0.59Case 2: sample A 1 with/~ and 02371 \[0.00 0.41\]7r 2 - -  = 0.53 \[Pi,j\] = 701 10.12 0.47_1Case 3: sample B with/~ and P381,4 = 0.30 \[Pi,j\] = \ [0.49 0.19 0.01\]~r3 = 274,------~ 1_0.19 0.09 0.03Case 4: sample B with/z and P421.778 =0.22  \[Pi,j\] = \[0.03 0.15 0.00 0.01 0.11 0.00 0.29 0.07 0.02 0.01\]qr4 = 98.91-------6 1-0.01 0.04 0.01 0.04 0.05 0.01 0.06 0.02 0.04 0.03_!A few comments on the above results can be add-ed.
A global analysis of qr shows that the linguisticcapabilities of PARNAX are generally higher than theconceptual ones (qr\],~r 2 >> ~'3,~'4).
In particular, thevalue of qr 4, which relies on a fine analysis of syntac-tic features, seems very good.Examining further the t~-o-profiles obtained (exceptcase 1, which is not meaningful), several interestingdetails of the system performance may be pointed out.Cases 2 and 3 show that the system performs better incorrespondence to sentences with higher importance,and, hence, it is reasonably well tailored.
On the con-trary, it generally lacks robustness.
Finally, case 4(especially when the analysis with 52 classes, not re-ported here, is considered) provides to the systemdesigner a lot of useful suggestions for corrections andimprovements.30 Computational Linguistics, Volume 10, Number 1, January-March 1984
