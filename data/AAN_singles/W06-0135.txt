Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 193?196,Sydney, July 2006. c?2006 Association for Computational LinguisticsNetEase Automatic Chinese Word SegmentationLi xin                                                                       Dai shuaixiangNETEASE INFORMATION TECHNOLOGY (BEIJING) CO., LTD.SP Tower D, 26th Floor, Tsinghua Science Park Building 8, No.1 Zhongguancun East Road,Haidian District Beijing, 100084, PRC.lxin@corp.netease.com                                          ddai@corp.netease.comAbstractThis document analyses the bakeoff re-sults from NetEase Co. in the SIGHAN5Word Segmentation Task and Named En-tity Recognition Task.
The NetEase WSsystem is designed to facilitate researchin natural language processing and in-formation retrieval.
It supports Chineseand English word segmentation, Chinesenamed entity recognition, Chinese part ofspeech tagging and phrase conglutination.Evaluation result shows our WS systemhas a passable precision in word segmen-tation except for the unknown words rec-ognition.1 IntroductionAutomatic Chinese Word Segmentation (WS) isthe fundamental task of Chinese informationprocessing [Liu, 2000].Since there are lots ofworks depending on the automatic segmentationof Chinese words, different Chinese NLP-enabled applications may have different re-quirements that call for different granularities ofword segmentation.
The key to accurate auto-matic word identification in Chinese lies in thesuccessful resolution of those ambiguities and aproper way to handle out-of-vocabulary (OOV)words (such as person names, place names andorganization name etc.
).We have applied corpus-based method to ex-tracting various language phenomena from realtexts; and have combined statistical model withrules in Chinese word segmentation, which hasincreased the precision of segmentation by im-proving ambiguous phrase segmentation and out-of-vocabulary word recognition.In the second section of this paper, we de-scribe a Chinese word segmentation system de-veloped by NetEase.
And we present our strate-gies on solving the problems of ambiguousphrase segmentation and identification of Chi-nese people names and place names.
The thirdsection is analysis of evaluation result.2 Modern Chinese Automatic Segmen-tation System2.1 System StructureThe WS system of NETEASE CO. supports Chi-nese and English word segmentation, Chinesenamed entity recognition, Chinese part of speechtagging and phrase conglutination.
In ordering toprocessing mass data, it is designed as an effi-cient system.
The whole system includes someprocessing steps: pre-processing, num-ber/date/time recognition, unknown words rec-ognition, segmenting, POS tagging and post-processing, as Fig 1 shows.The Prehandler module performs the pre-processing, splits the text into sentences accord-ing to the punctuations.Number/Data/Time recognition processes thenumber, date, time string and English words.Unknown word recognition includes personalname recognition and place name recognition.Segmenter component performs word-segmenting task, matches all the candidate wordsand processes ambiguous lexical.POSTagger module performs part of speechtagging task and decides the optimal word seg-mentation using hierarchical hidden Markovmodel (HHMM) [Zhang, 2003].Posthandler retrieves phrases with multi-granularities from segmentation result and de-tects new words automatically etc.2.2 Ambiguous phrase segmentationAssume that ?AJB?
are character strings and thatW is a word list.
In the field ?AJB?, if ?AJ?
?W,193and ?JB?
?W, then ?AJB?
is called ambiguousphrase of overlap type.
For example, in the string"???
", both "??"
and "??"
are words , so"???"
is an ambiguous phrase of overlap type;and there is one ambiguous string.In the string ?AB?, if ?AB?
?W(word), ?A?
?W, and ?B?
?W, then the string ?AB?
is calledambiguous phrase of combination type.
For ex-ample, in the string "??
", since "??
", "?
"and "?
"are all words, so the string "??"
is anambiguous phrase of combination type.We have built an ambiguous phrase lib ofoverlap and combination type from tagged cor-pus, which contains 200,000 phrases from 1-gram to 4-gram.
For example: ?
?/d ?/v ??/v,?
?/vn ?/v ??
vn?
If one ambiguous phrasefound in raw text, the potential segmentation re-sult will be found in the lib and submit to nextmodule.
If not found, POS tagger module willdisambiguate it.2.3 Chinese Personal Name RecognitionAt present we only consider the recognition ofnormal people name with both a family nameand a first name.
We got the statistical CharacterSet of Family Name and First Name data fromcorpus.
And also consider the ability of  charac-ter of constructing word.
Some characters itselfcannot be regarded as a word or composes aword with other characters, such as "?,?,?
";Some  name characters which can compose wordwith other characters only, e.g.
??????
?can construct words "??????????
";Some name characters  are also a commonwords themselves, e.g.
????
?.The recognition procedure is as follows:1) Find the potential Chinese personal names:Family name is the trigger.
Whenever a familyname is found in a text, its following word istaken as a first name word, or its following twocharacters as the head character and the tail char-acter of a first name.
Then the family name andits following make a potential people name, theprobable largest length of which is 4 when it iscomposed of a double-character family name anda double-character first name.2) Based on the constructing word rules andthe protective rules, sift the potential peoplenames for the first time.
For example, when rawtext is ????,???
?, then the ??,??
werenot family name.
Because the ??,??
is number.3) Compute the probabilities of the potentialname and the threshold values of correspondingfamily names, then sift the people names againbased on the personal name probability functionand description rules.4) According to the left-boundary rules andthe right-boundary rules which base on title, forFig 1 Structure and Components of WS194example, ???
,??
?, and name frequent ofcontext, determine the boundaries of peoplenames.5) Negate conflicting potential people names.6) Output the result: The output contains everysentence in the processed text and the start andthe end positions and the reliability values of allpeople names in it.2.4 Chinese Place Name RecognitionBy collecting a large scale of place names, Forexample, (1) The names of administrative re-gions superior to county; (2) The names of in-habitation areas; (3) The names of geographicentities, such as mountain, river, lake, sea, islandetc.
; (4) Other place names, e.g.
monument, ruins,bridge and power station etc.
building the placename dictionary.Collecting words that can symbolize a place,e.g.
???
?, ???
?, ???
etc.Base on these knowledge we applied positivededuction mechanism.
Its essence is that withreference to certain control strategies, a rule isselected; then examining whether the factmatches the condition of the rule, if it does, therule will be triggered.In addition, Those words that often concurrentwith a place name are collected , including:??
?, ????
etc.
And which often concurrentwith a people name, such as ???
?, ???
andso on,  are also considered in NER.WS system identifies all potential place namesin texts by using place name base and gatherstheir context information; and through deduction,it utilizes rule set and knowledge base to confirmor negate a potential place name; hereupon, theremainders are recognized place name.2.5 Multi-granularities of word segmenta-tionWhenever we deploy the segmenter for any ap-plication, we need to customize the output of thesegmenter according to an application specificstandard, which is not always explicitly defined.However, it is often implicitly defined in a givenamount of application data (for example, Searchengines log, Tagged corpus) from which the spe-cific standard can be partially learned.Most variability in word segmentation acrossdifferent standards comes from those words thatare not typically stored in the basic dictionary.To meet the applications of different levels, inour system, the standard adaptation is conductedby a post-processor which performs an orderedlist of transformations on the output.
For exam-ple: When input is ???????????
?,the output will be:1.
????/?
?/ ?
?/ ???
?2.
????/???
?/ ????3.
????/???????
?Result 1 is normal segmentation, also is mini-mum granularity of word.
Result 2 and 3 is big-ger granularity.
Every application can select ap-propriate segmentation result according to itspurpose.3 Test resultsThe speed of NetEase WS system is about1500KB/s--300KB/s in different algorithm andp4-2.8/512M computer.
In SigHan5, the F-MEASURE of our word segmentation is 0.924,the IN Recall is 0.959, but OOV Recall Rate isonly 0.656.
This indicates that our unknownwords recognition is poor; it makes a bad impacton the segmented result.
It also shows our sys-tem should be improved largely in unknownwords recognition.
For example:1.
Name Entity Recognize: ????
?, ???
?, ????
were falsely segment to ??/??/?
), ?
?/?/?, ?/?/??.2.
Name Entity Ambiguous: ?
?/ ?
?/LOC?are falsely recognized ????/PER?.3.
Abbreviations of phrase: ???
(???
)?was segment to  ??/??.4.
New Word: ???
?, ?
?, ???5.
Standard of Word: we think ??????
?and ??????
is one word, but criterion is ???/?/??
?, ???/???
etc.In evaluation, our system?s TOTAL INSER-TIONS is 5292 and TOTAL DELETIONS is2460.
The result show: our WS usually segmentout ?shorter word?, for example,  ??????
?,and ??????
is segmented to ???/??/?
?, ???/???
.
But not every string is oneword.Much work needs to be done to evaluate thisWS system more thoroughly.
Refined pre-processing or post-processing steps could alsohelp improve segmentation accuracy.For example, pre-processing will split ASCIIstring and Chinese character, so  "DD6112H6?,ic?, ???"
will falsely segment "DD6112H6/?, ic/?, ??/?
"; In post-processing, by usingconsecutive single characters ?
?/?, ?/??
to195detect the valid out-of-vocabulary words ???,???
also is good idea.ReferencesKaiying Liu.
Automatic Chinese Word Segmentationand POS Tagging.
Business Publishing House.Beijing.
2000.Hua-Ping Zhang etc.
Chinese Lexical Analysis UsingHierarchical Hidden Markov Model.
SecondSIGHAN workshop affiliated with 41th ACL, Sap-poro Japan, July, 2003, pp.
63-70196
