Early Results forNamed Entity Recognition with Conditional Random Fields,Feature Induction and Web-Enhanced LexiconsAndrew McCallum and Wei LiDepartment of Computer ScienceUniversity of Massachusetts AmherstAmherst, MA 01003{mccallum,weili}@cs.umass.edu1 IntroductionModels for many natural language tasks benefit from theflexibility to use overlapping, non-independent features.For example, the need for labeled data can be drasticallyreduced by taking advantage of domain knowledge inthe form of word lists, part-of-speech tags, character n-grams, and capitalization patterns.
While it is difficult tocapture such inter-dependent features with a generativeprobabilistic model, conditionally-trained models, suchas conditional maximum entropy models, handle themwell.
There has been significant work with such mod-els for greedy sequence modeling in NLP (Ratnaparkhi,1996; Borthwick et al, 1998).Conditional Random Fields (CRFs) (Lafferty et al,2001) are undirected graphical models, a special case ofwhich correspond to conditionally-trained finite state ma-chines.
While based on the same exponential form asmaximum entropy models, they have efficient proceduresfor complete, non-greedy finite-state inference and train-ing.
CRFs have shown empirical successes recently inPOS tagging (Lafferty et al, 2001), noun phrase segmen-tation (Sha and Pereira, 2003) and Chinese word segmen-tation (McCallum and Feng, 2003).Given these models?
great flexibility to include a widearray of features, an important question that remains iswhat features should be used?
For example, in somecases capturing a word tri-gram is important, however,there is not sufficient memory or computation to includeall word tri-grams.
As the number of overlapping atomicfeatures increases, the difficulty and importance of con-structing only certain feature combinations grows.This paper presents a feature induction method forCRFs.
Founded on the principle of constructing onlythose feature conjunctions that significantly increase log-likelihood, the approach builds on that of Della Pietra etal (1997), but is altered to work with conditional ratherthan joint probabilities, and with a mean-field approxi-mation and other additional modifications that improveefficiency specifically for a sequence model.
In compari-son with traditional approaches, automated feature induc-tion offers both improved accuracy and significant reduc-tion in feature count; it enables the use of richer, higher-order Markov models, and offers more freedom to liber-ally guess about which atomic features may be relevantto a task.Feature induction methods still require the user to cre-ate the building-block atomic features.
Lexicon member-ship tests are particularly powerful features in natural lan-guage tasks.
The question is where to get lexicons that arerelevant for the particular task at hand?This paper describes WebListing, a method that obtainsseeds for the lexicons from the labeled data, then uses theWeb, HTML formatting regularities and a search engineservice to significantly augment those lexicons.
For ex-ample, based on the appearance of Arnold Palmer in thelabeled data, we gather from the Web a large list of othergolf players, including Tiger Woods (a phrase that is dif-ficult to detect as a name without a good lexicon).We present results on the CoNLL-2003 named entityrecognition (NER) shared task, consisting of news arti-cles with tagged entities PERSON, LOCATION, ORGANI-ZATION and MISC.
The data is quite complex; for exam-ple the English data includes foreign person names (suchas Yayuk Basuki and Innocent Butare), a wide diversity oflocations (including sports venues such as The Oval, andrare location names such as Nirmal Hriday), many typesof organizations (from company names such as 3M, toacronyms for political parties such as KDP, to locationnames used to refer to sports teams such as Cleveland),and a wide variety of miscellaneous named entities (fromsoftware such as Java, to nationalities such as Basque, tosporting competitions such as 1,000 Lakes Rally).On this, our first attempt at a NER task, with just a fewperson-weeks of effort and little work on development-set error analysis, our method currently obtains overallEnglish F1 of 84.04% on the test set by using CRFs, fea-ture induction and Web-augmented lexicons.
German F1using very limited lexicons is 68.11%.2 Conditional Random FieldsConditional Random Fields (CRFs) (Lafferty et al, 2001)are undirected graphical models used to calculate the con-ditional probability of values on designated output nodesgiven values assigned to other designated input nodes.In the special case in which the output nodes of thegraphical model are linked by edges in a linear chain,CRFs make a first-order Markov independence assump-tion, and thus can be understood as conditionally-trainedfinite state machines (FSMs).
In the remainder of thissection we introduce the likelihood model, inference andestimation procedures for CRFs.Let o = ?o1, o2, ...oT ?
be some observed input datasequence, such as a sequence of words in text in a doc-ument, (the values on n input nodes of the graphicalmodel).
Let S be a set of FSM states, each of whichis associated with a label, l ?
L, (such as ORG).
Lets = ?s1, s2, ...sT ?
be some sequence of states, (the val-ues on T output nodes).
By the Hammersley-Clifford the-orem, CRFs define the conditional probability of a statesequence given an input sequence to beP?
(s|o) =1Zoexp(T?t=1?k?kfk(st?1, st,o, t)),where Zo is a normalization factor over all state se-quences, fk(st?1, st,o, t) is an arbitrary feature func-tion over its arguments, and ?k is a learned weight foreach feature function.
A feature function may, for exam-ple, be defined to have value 0 in most cases, and havevalue 1 if and only if st?1 is state #1 (which may havelabel OTHER), and st is state #2 (which may have la-bel LOCATION), and the observation at position t in ois a word appearing in a list of country names.
Higher ?weights make their corresponding FSM transitions morelikely, so the weight ?k in this example should be pos-itive.
More generally, feature functions can ask pow-erfully arbitrary questions about the input sequence, in-cluding queries about previous words, next words, andconjunctions of all these, and fk(?)
can range ??...
?.CRFs define the conditional probability of a labelsequence based on total probability over the state se-quences, P?
(l|o) =?s:l(s)=l P?
(s|o), where l(s) isthe sequence of labels corresponding to the labels of thestates in sequence s.Note that the normalization factor, Zo, is the sumof the ?scores?
of all possible state sequences, Zo =?s?ST exp(?Tt=1?k ?kfk(st?1, st,o, t)), and thatthe number of state sequences is exponential in the in-put sequence length, T .
In arbitrarily-structured CRFs,calculating the normalization factor in closed form isintractable, but in linear-chain-structured CRFs, as inforward-backward for hidden Markov models (HMMs),the probability that a particular transition was taken be-tween two CRF states at a particular position in the inputsequence can be calculated efficiently by dynamic pro-gramming.
We define slightly modified forward values,?t(si), to be the ?unnormalized probability?
of arrivingin state si given the observations ?o1, ...ot?.
We set ?0(s)equal to the probability of starting in each state s, andrecurse:?t+1(s) =?s??t(s?)
exp(?k?kfk(s?, s,o, t)).The backward procedure and the remaining details ofBaum-Welch are defined similarly.
Zo is then?s ?T (s).The Viterbi algorithm for finding the most likely statesequence given the observation sequence can be corre-spondingly modified from its HMM form.2.1 Training CRFsThe weights of a CRF, ?={?, ...}, are set to maximize theconditional log-likelihood of labeled sequences in sometraining set, D = {?o, l?
(1), ...?o, l?
(j), ...?o, l?(N)}:L?
=N?j=1log(P?(l(j)|o(j)))?
?k?2k2?2,where the second sum is a Gaussian prior over parameters(with variance ?)
that provides smoothing to help copewith sparsity in the training data.When the training labels make the state sequence un-ambiguous (as they often do in practice), the likelihoodfunction in exponential models such as CRFs is con-vex, so there are no local maxima, and thus finding theglobal optimum is guaranteed.
It has recently been shownthat quasi-Newton methods, such as L-BFGS, are signifi-cantly more efficient than traditional iterative scaling andeven conjugate gradient (Malouf, 2002; Sha and Pereira,2003).
This method approximates the second-derivativeof the likelihood by keeping a running, finite-sized win-dow of previous first-derivatives.L-BFGS can simply be treated as a black-box opti-mization procedure, requiring only that one provide thefirst-derivative of the function to be optimized.
Assum-ing that the training labels on instance j make its statepath unambiguous, let s(j) denote that path, and then thefirst-derivative of the log-likelihood is?L??k=??N?j=1Ck(s(j),o(j))?????N?j=1?sP?(s|o(j))Ck(s,o(j))???
?k?2where Ck(s,o) is the ?count?
for feature k given sand o, equal to?Tt=1 fk(st?1, st,o, t), the sum offk(st?1, st,o, t) values for all positions, t, in the se-quence s. The first two terms correspond to the differ-ence between the empirical expected value of feature fkand the model?s expected value: (E?[fk]?E?
[fk])N .
Thelast term is the derivative of the Gaussian prior.3 Efficient Feature Induction for CRFsTypically the features, fk, are based on some number ofhand-crafted atomic observational tests (such as word iscapitalized or word is ?said?, or word appears in lexi-con of country names), and a large collection of featuresis formed by making conjunctions of the atomic tests incertain user-defined patterns; (for example, the conjunc-tions consisting of all tests at the current sequence po-sition conjoined with all tests at the position one stepahead?specifically, for instance, current word is capi-talized and next word is ?Inc?).
There can easily beover 100,000 atomic tests (mostly based on tests for theidentity of words in the vocabulary), and ten or moreshifted-conjunction patterns?resulting in several millionfeatures (Sha and Pereira, 2003).
This large number offeatures can be prohibitively expensive in memory andcomputation; furthermore many of these features are ir-relevant, and others that are relevant are excluded.In response, we wish to use just those time-shiftedconjunctions that will significantly improve performance.We start with no features, and over several rounds of fea-ture induction: (1) consider a set of proposed new fea-tures, (2) select for inclusion those candidate features thatwill most increase the log-likelihood of the correct statepath s(j), and (3) train weights for all features.
The pro-posed new features are based on the hand-crafted obser-vational tests?consisting of singleton tests, and binaryconjunctions of tests with each other and with featurescurrently in the model.
The later allows arbitrary-lengthconjunctions to be built.
The fact that not all singletontests are included in the model gives the designer greatfreedom to use a very large variety of observational tests,and a large window of time shifts.To consider the effect of adding a new feature, definethe new sequence model with additional feature, g, hav-ing weight ?, to beP?+g,?
(s|o) =P?
(s|o) exp(?Tt=1 ?
g(st?1, st,o, t))Zo(?, g, ?
);Zo(?, g, ?)def=?s?
P?
(s?|o) exp(?Tt=1 ?
g(s?t?1, s?t,o, t))in the denominator is simply the additional portion ofnormalization required to make the new function sum to1 over all state sequences.Following (Della Pietra et al, 1997), we efficiently as-sess many candidate features in parallel by assuming thatthe ?
parameters on all included features remain fixedwhile estimating the gain, G(g), of a candidate feature, g,based on the improvement in log-likelihood it provides,G?
(g) = max?G?
(g, ?)
= max?L?+g?
?
L?.where L?+g?
includes ?
?2/2?2.In addition, we make this approach tractable for CRFswith two further reasonable and mutually-supporting ap-proximations specific to CRFs.
(1) We avoid dynamicprogramming for inference in the gain calculation witha mean-field approximation, removing the dependenceamong states.
(Thus we transform the gain from a se-quence problem to a token classification problem.
How-ever, the original posterior distribution over states giveneach token, P?
(s|o) = ?t(s|o)?t+1(s|o)/Zo, is stillcalculated by dynamic programming without approxima-tion.)
Furthermore, we can calculate the gain of aggre-gate features irrespective of transition source, g(st,o, t),and expand them after they are selected.
(2) In manysequence problems, the great majority of the tokens arecorrectly labeled even in the early stages of training.
Wesignificantly gain efficiency by including in the gain cal-culation only those tokens that are mislabeled by the cur-rent model.
Let {o(i) : i = 1...M} be those tokens, ando(i) be the input sequence in which the ith error tokenoccurs at position t(i).
Then algebraic simplification us-ing these approximations and previous definitions givesG?
(g, ?)
=M?i=1log(exp(?
g(st(i),o(i), t(i)))Zo(i)(?, g, ?))?
?22?2= M?E?
[g] ?M?i=1log(E?[exp(?
g)|o(i)] ?
?22?2,where Zo(i)(?, g, ?)
(with non-bold o) is simply?s P?
(s|o(i)) exp(?g(s,o(i), t(i))).
The optimal val-ues of the ?
?s cannot be solved in closed form, but New-ton?s method finds them all in about 12 quick iterations.There are two additional important modeling choices:(1) Because we expect our models to still require sev-eral thousands of features, we save time by adding manyof the features with highest gain each round of inductionrather than just one; (including a few redundant featuresis not harmful).
(2) Because even models with a small se-lect number of features can still severely overfit, we trainthe model with just a few BFGS iterations (not to con-vergence) before performing the next round of feature in-duction.
Details are in (McCallum, 2003).4 Web-augmented LexiconsSome general-purpose lexicons, such a surnames and lo-cation names, are widely available, however, many nat-ural language tasks will benefit from more task-specificlexicons, such as lists of soccer teams, political parties,NGOs and English counties.
Creating new lexicons en-tirely by hand is tedious and time consuming.Using a technique we call WebListing, we build lexi-cons automatically from HTML data on the Web.
Previ-ous work has built lexicons from fixed corpora by deter-mining linguistic patterns for the context in which rele-vant words appear (Collins and Singer, 1999; Jones et al,1999).
Rather than mining a small corpus, we gather datafrom nearly the entire Web; rather than relying on fragilelinguistic context patterns, we leverage robust formattingregularities on the Web.
WebListing finds co-occurrencesof seed terms that appear in an identical HTML format-ting pattern, and augments a lexicon with other terms onthe page that share the same formatting.
Our current im-plementation uses GoogleSets, which we understand tobe a simple implementation of this approach based on us-ing HTML list items as the formatting regularity.
We arecurrently building a more sophisticated replacement.5 ResultsTo perform named entity extraction on the news articlesin the CoNLL-2003 English shared task, several familiesof features are used, all time-shifted by -2, -1, 0, 1, 2: (a)the word itself, (b) 16 character-level regular expressions,mostly concerning capitalization and digit patterns, suchas A, A+, Aa+, Aa+Aa*, A., D+, where A, a and D indi-cate the regular expressions [A-Z], [a-z] and [0-9],(c) 8 lexicons entered by hand, such as honorifics, daysand months, (d) 15 lexicons obtained from specific websites, such as countries, publicly-traded companies, sur-names, stopwords, and universities, (e) 25 lexicons ob-tained by WebListing (including people names, organi-zations, NGOs and nationalities), (f) all the above testswith prefix firstmention from any previous duplicate ofthe current word, (if capitalized).
A small amount ofhand-filtering was performed on some of the WebList-ing lexicons.
Since GoogleSets?
support for non-Englishis severely limited, only 5 small lexicons were used forGerman; but character bi- and tri-grams were added.A Java-implemented, first-order CRF was trained forabout 12 hours on a 1GHz Pentium with a Gaussian priorvariance of 0.5, inducing 1000 or fewer features (downto a gain threshold of 5.0) each round of 10 iterations ofL-BFGS.
Candidate conjunctions are limited to the 1000atomic and existing features with highest gain.
Perfor-mance results for each of the entity classes can be foundin Figure 1.
The model achieved an overall F1 of 84.04%on the English test set using 6423 features.
(Using a setof fixed conjunction patterns instead of feature inductionresults in F1 73.34%, with about 1 million features; trial-and-error tuning the fixed patterns would likely improvethis.)
Accuracy gains are expected from experimentationwith the induction parameters and improved WebListing.AcknowledgmentsWe thank John Lafferty, Fernando Pereira, Andres Corrada-Emmanuel, Drew Bagnell and Guy Lebanon, for helpfulinput.
This work was supported in part by the Centerfor Intelligent Information Retrieval, SPAWARSYSCEN-SDgrant numbers N66001-99-1-8912 and N66001-02-1-8903, Ad-vanced Research and Development Activity under contractnumber MDA904-01-C-0984, and DARPA contract F30602-01-2-0566.ReferencesA.
Borthwick, J.
Sterling, E. Agichtein, and R. Grishman.
1998.Exploiting diverse knowledge sources via maximum entropyin named entity recognition.
In Proceedings of the SixthWorkshop on Very Large Corpora, Association for Compu-tational Linguistics.M.
Collins and Y.
Singer.
1999.
Unsupervised models fornamed entity classification.
In Proceedings of the Joint SIG-DAT Conference on Empirical Methods in Natural LanguageProcessing and Very Large Corpora.Stephen Della Pietra, Vincent J. Della Pietra, and John D. Laf-ferty.
1997.
Inducing Features of Random Fields.
IEEEEnglish devel.
Precision Recall F?=1LOC 93.82% 91.78% 92.79MISC 83.99% 78.52% 81.17ORG 84.23% 82.03% 83.11PER 92.64% 93.65% 93.14Overall 89.84% 88.10% 88.96English test Precision Recall F?=1LOC 87.23% 87.65% 87.44MISC 74.44% 71.37% 72.87ORG 79.52% 78.33% 78.92PER 91.05% 89.98% 90.51Overall 84.52% 83.55% 84.04German devel.
Precision Recall F?=1LOC 68.55% 68.84% 68.69MISC 72.66% 45.25% 55.77ORG 70.64% 54.88% 61.77PER 82.21% 64.31% 72.17Overall 73.60% 59.01% 65.50German test Precision Recall F?=1LOC 71.92% 69.28% 70.57MISC 69.59% 42.69% 52.91ORG 63.85% 48.90% 55.38PER 90.04% 74.14% 81.32Overall 75.97% 61.72% 68.11Table 1: English and German named entity extraction.Transactions on Pattern Analysis and Machine Intelligence,19(4):380?393.Rosie Jones, Andrew McCallum, Kamal Nigam, and EllenRiloff.
1999.
Bootstrapping for Text Learning Tasks.
InIJCAI-99 Workshop on Text Mining: Foundations, Tech-niques and Applications.John Lafferty, Andrew McCallum, and Fernando Pereira.
2001.Conditional Random Fields: Probabilistic Models for Seg-menting and Labeling Sequence Data.
In Proc.
ICML.Robert Malouf.
2002.
A comparison of algorithms for max-imum entropy parameter estimation.
In Sixth Workshop onComputational Language Learning (CoNLL-2002).Andrew McCallum and Fang-Fang Feng.
2003.
ChineseWord Segmentation with Conditional Random Fields and In-tegrated Domain Knowledge.
In Unpublished Manuscript.Andrew McCallum.
2003.
Efficiently Inducing Features ofConditional Random Fields.
In Nineteenth Conference onUncertainty in Artificial Intelligence (UAI03).
(Submitted).Adwait Ratnaparkhi.
1996.
A Maximum Entropy Model forPart-of-Speech Tagging.
In Eric Brill and Kenneth Church,editors, Proceedings of the Conference on Empirical Meth-ods in Natural Language Processing, pages 133?142.
Asso-ciation for Computational Linguistics.Fei Sha and Fernando Pereira.
2003.
Shallow Parsing withConditional Random Fields.
In Proceedings of Human Lan-guage Technology, NAACL.
