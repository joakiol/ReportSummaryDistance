Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 185?193,Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational LinguisticsTopics as Contextual Indicators for Word Choice in SMS ConversationsUte Winter1, Roni Ben-Aharon, Daniel Chernobrov, Ron M Hecht11GM Advanced Technical Center, HaManofim Street 11, Herzeliya 46725, Israelute.winter@gm.com, r.ben.aharon@gmail.com,daniel-cher@hotmail.com, ron.hecht@gm.comAbstractSMS dictation by voice is becoming a viable al-ternative providing a convenient method fortexting in a variety of environments.
Contextualknowledge should be used to improve perfor-mance.
We propose to add topic knowledge aspart of the contextual awareness of both textingpartners during SMS conversations.
Topics canbe used for speech applications, if the relationbetween the conversed topics and the choice ofwords in SMS dialogs is measurable.
In thisstudy, we collected an SMS corpus, developeda topic annotation scheme, and built a topic hie-rarchy in a tree structure.
We validated our top-ic assignments and tree structure by theAgglomerative Information Bottleneck method,which also proved the measurability of the in-terrelation between topics and wording.
Toquantify this relation we propose a na?ve classi-fication method based on the calculation of top-ic distinctive word lists and compare theclassifiers?
topic recognition capabilities forSMS dialogs with unigram language models.The results demonstrate that the relation be-tween topic and wording is significant and canbe integrated into SMS dictation.1 IntroductionOne of the largest growth areas in communicationis the Short Message Service (SMS) or text mes-saging, as it is more popularly known.
SMS grewout of what was initially a by-product of the mo-bile phone industry (Agar, 2003; Goggin, 2006).
Infact, by 2009 text messaging has become the mostfrequently used communication means amongteens in the US, supported by the mobile phoneindustry offering unlimited texting plans (Lenhartet.
al., 2010).For many reasons, voice enabled texting has be-come a desirable alternative in a variety of mobilescenarios.
The number of speech applications formobile phones including texting by voice is con-stantly growing.
However, the challenges for SMSdictation by voice are multifold, from particularnoise conditions, to the use of vocabulary and do-main specific language, the dialogical nature oftext messaging (Thurlow and Poff, 2009), and toerror correction of imperfect recognition results.Achieving a high and robust performance is cru-cial for the success of the application.
For this pur-pose additional contextual factors can be integratedinto the recognition process.
One possible factor,the conversed topic, has influence on the speaker?schoice of words.
Hence, it is an important contex-tual factor for the prediction of the speaker?s word-ing, since it originates in the speaker?s mentalconcepts during a dialog situation, which is thenature of texting.To date, research on text messaging has primari-ly examined socio-linguistic phenomena (e.g.,Thurlow, 2003).
With respect to language andcommunication, text messaging is still an under-examined research area.
Thurlow and Poff (2009)provide a comprehensive overview of existing lite-rature about SMS in linguistics.
Moreover, thereexists noteworthy work on SMS text normalization(Aw et.
al., 2006; Fairon and Paumier, 2006; Cookand Stevenson, 2009; Kobus et.
al., 2008; Pennelland Liu, 2010), for instance for the purpose of Ma-chine Translation, Text-to-Speech engines or spellchecking, work on SMS based question answering185services (Kothari, 2009), and work on predefinedSMS replies in automobiles (Wu et.
al., 2010).However, conversed topics in the context of SMSdiscourse have not been examined in the literature,neither in linguistics nor for any Natural LanguageProcessing applications.Hence, in this paper we have developed a newapproach to make topics useful as context know-ledge for SMS dictation by voice.
We describe top-ic annotation of a novel SMS corpus and study theinfluence which SMS dialog topics may have onthe choice of words.
Based on the results, we areable to estimate and initially quantify its impact.This research can serve as the basis for developingalgorithms that use topic knowledge for SMS dic-tation in speech applications.2 Topic Annotation for SMS2.1 SMS Corpus in US EnglishSMS data was collected from 250 participants whoconversed with another 900.
Participants were dis-tributed almost evenly across gender, two agegroups, and four US regions.
Participants under 30years comprised 48% of the dataset, and partici-pants over 30 years comprised 52% of the dataset.Within each of these two age groups, there wereequal number of men and women.
The demograph-ic spread contained datasets from participants fromthe various regions in the USA: east coast 19%,west coast 24%, central 29%, and south 28%.The corpus dataset contains a total number ofmore than 51,000 messages, chosen randomly froma significantly larger set of data, for which partici-pants provided authentic SMS conversations fromtheir mobile phones to online SMS backup servic-es.
Besides demographic constraints, all text mes-sages are part of SMS conversations, eachcomposed at least by one message and a textualresponse, to preserve a contextual authentic situa-tion.
A conversation is considered to be ended if atime frame of 4 hours elapses without a response.The average length of SMS conversations in thecorpus is between 8-9 messages, distributed over anotably higher number of shorter conversions thanlonger dialogs.
Altogether the corpus containsmore than 5800 conversations.Personal information of the SMS conversationswas removed.
Nonetheless the corpus itself is cur-rently not published, because identifying informa-tion can be indirectly present in SMS dialogs.The SMS corpus is semi-automatically norma-lized following a general guideline to transformeach texted message into one which could be dic-tated by the user.
For all following research thenormalized rather than the raw SMS textual utter-ances are used.Table 1 shows representative examples for textnormalization.Raw NormalizedYea b workin forhospiceyeah be working forhospiceI am at vetran@at@8 amI am at Veteran ateight ei-emLets go 2 eat Let?s go to eatYou wanna go to dab walk or sumthin?You wanna go to thebee walk or some-thing?Table 1: Text messages in raw and normalized format.2.2 Topic Annotation MethodA key point for usefulness of an annotated corpusis the abstraction which maps SMS conversationspresent in the corpus to an abstract model servingthe research goals (Wallis and Nelson, 2001; McEnery et.
al., 2006).
In our research, the corpusshall be used to explore to what extent the know-ledge of one or more discussed topics, for whichboth SMS dialog partners try to make progress, cancontribute to the performance of a speech recogni-tion engine, where we expect the engine to bebased on Statistical Language Models (SLM).Consequently, the annotation needs to enable us totrace a path from discussed topics to the choice ofwords and phrases in SMS conversations.
This ab-straction leads to our definition of the term topicand to guidelines for the annotation which areidentified to be essential, when incorporating top-ics into speech recognition.Other than an agreement on ?what is beingtalked about?, the definition of topic in linguisticsis a matter of viewpoint and dispute (Levinson,1983; Li and Thompson, 1976; Chafe, 1976;Moln?r, 1993; Stutterheim, 1997).
Moreover, aliterature review has not revealed existing topicannotations which can be used for our purpose (McEnery et.
al., 2006; Meyer, 2002).
Since the inten-186tion is to build a task driven, problem oriented an-notation scheme we further specify a discoursetopic as observable content or story line which dis-course partners follow up in an SMS conversation.Hence, we understand a topic foremost as anattribute of an SMS dialog rather than of a singleSMS, or of a phrase within the dialog.
We assign atleast one topic to each dialog.
Since dialogs can infact contain several distinct topics, we assign allexplicitly mentioned topics to a conversation andmark separately all SMS which belong doubtlesslyto each topic in the context of the conversation,Topics describe the content only, not any otherlevel of discourse.
The example in figure 1 shows aconversation with the topic ?meeting arrangement?.Figure 1: Example of SMS dialog about ?meetingarrangement?.2.3 Topic Annotation ProcedureDiscourse topics are highly domain dependent intheir nature and may differ from the SMS domainto other domains, even to computer mediatedcommunication services, like e-mail, Twitter, orInstant Messaging.
Because of that, the list of SMSrelevant topics evolves from the data itself.
Addi-tionally the list of possible topics always remainsan open tag list, although one can expect recurringtopics after a while with sparse extension of anexisting topic list.
Hence, the approach for annotat-ing the SMS corpus must be manual.
For this pur-pose a team of four annotators marked theconversations with the help of an annotation tooldeveloped specifically for the topic annotation.
Toensure annotator agreement a linguist verified andconfirmed the growing topic list and all topic as-signments in several iterations.
Further annotationof a larger corpus may be semi-automated based onthe achieved topic list.Assigning topics to a dialog remains intuitive toa certain extent, because any mutual understandingof the dialog?s content and pragmatic meaning issupported by social cues, situation awareness andworld knowledge of dialog partners (Levinson,1983; Lambert and Carberry, 1992).
These know-ledge dimensions need to be reconstituted duringthe annotation process, when assigning a new top-ic.
One criterion is to ask if the topic is distinctfrom other topics with regard to describing piecesof our world knowledge dimensions, e.g.
scriptsand events that people repeatedly experience, orsubjects, they are recurrently dealing with.Furthermore, a task driven approach demands todetermine the level of specialization and detail fortopics.
Even if broad topics, such as ?food?
or ?ap-pointment?, may prove themselves to be distinctand meaningful enough for speech recognition, theannotation is done to one degree more detailed.Each topic is composed by a term and one restric-tive attribute which divides a major topic into moredistinctive topics.
Thus ?appointment?
appears inthe corpus divided into ?cancel appointment?, ?at-tending an appointment?, ?meeting arrangements?,and other.
The advantage of the annotation proce-dure is twofold; it leads to a list of topics, whichcan be depicted in a tree structure with several le-vels of specialization, and, even though the annota-tion is targeted to a special problem, there issufficient information to make the corpus usefulfor a broader range of research.3 Corpus Analysis for Topic Usage3.1 Properties of TopicsSMS conversations may follow up on one or moretopics.
Multiple topic conversations may makeprogress on topics even in parallel, either switchingtopics or addressing both within the same SMS.
Ingeneral, we avoid topics which are suspected todescribe the intention or strategy for the conversa-tion rather than the content.
There are a few excep-tions, where the topic is implicitly or explicitlypresent in the dialog not only on content level butalso as driving force for texting, e.g.
?maintainfriendship/relationship?
or ?small talk?
(see exam-ple (2) in figure 2).
The border cannot be clearlydrawn in these cases.Two topic assignments require explanation.
?Small talk?
is used for a group of short SMS di-Hey how is every-thing going?Good.
Wanna goto the lax house?Maybe, when are uplanning on going?In a little bitI'm still at the li-brary?
maybe i'llmeet u ther Ok sounds good.187alogs, for which one cannot identify a topic.
One isable to understand the dialog as a short form offriendship maintenance though, where both partiesachieve mutual positive feedback about their cur-rent situation, e.g.
via salutation.
Therefore ?smalltalk?
is expected to be of interest regarding wordusage contrary to ?undefined topic?.
The latter isassigned to all conversations, where we do notshare enough knowledge about the background andsituation of the texters to understand and identifythe topic of the dialog (example (3) in figure 2).Figure 2: SMS dialogs with (1) multiple topics, (2)small talk, and (3) undefined topic.All in all, the corpus contains 42.1% of dialogswith one annotated topic and 46.6% with multipletopics.
The remaining 11.3% of dialogs are taggedas ?undefined?.3.2 Building a Topic TreeThe identification of similar or related topics in ourcorpus allow for grouping them together in specifictopic clusters, such as ?human relations?, ?tech-nology?, and ?transportation?, and represent themin a tree structure hierarchy.
The assignment to atopic cluster for each topic is determined by therelation between topics, which humans definebased on their world knowledge and based on thesemantic meaning of the topic.The topic tree hierarchy consists of four levels.The nodes in the first two levels build the treestructure and represent the topic clusters.
Thereforethey have not been used during the annotationprocess.
Only from level three and above the topicnames are assigned to the corpus and may beleaves of the tree.
A forth level is used, when thirdlevel topics are frequently used in SMS dialogs andcan further be divided into meaningful sub topics.Figure 3: Topic tree branch related to ?shopping?.Figure 4: Topic tree branch for ?positive emotion?.3.3 Topic Distribution in SMS Corpus87.1% of all text messages are categorized in ninepreferably conversed topic clusters (see figure 5),the remaining messages belong either to SMS di-alogs, where the topic is labeled as undefined, or tomiscellaneous, rarely conversed topics, e.g.?weather?
or ?religious belief?.More than 55% of all text messages are moti-vated by interpersonal and emotional matters.About 45% of all text messages deal with ?humanrelations?, mainly including sub topics regardingrelation maintenance (36% of ?human relations?,e.g.
?make promise?, ?make apology?, ?healthcondition?, ?small talk?, a.
o.
), regarding relationswith friends (14%), concerning relationship issuesactivities & eventstravel    recreation    special occasions ?sport activities    going shopping    going out ?buy clothes   buy gift   buy item   going to storeemotionnegative            positiveexpress joy   express love   feeling better ?Missed phone call, planned scheduleTexter 1: Hi, sorry I missed your call.
I'mactually at an appointment right now.Texter 1: I will call you about 12:45pm.Please answer, so we can finally connect, ifnot I will call after 17:00.Texter 2: O.K no problem, call me whenyou're free :)Texter 1: The appointment is over, I triedcalling you but you didn't answer, will talkwhen I'm on my way homeTexter 2: Thankyou.Small talkTexter 1: What?s up?Texter 2: I?m good, u?Texter 1: I?m fine, talk to you laterTexter 2: Sure :)Topic undefinedTexter 1: dfTexter 2: what?Texter 1: don?t forgetTexter 2: Lol :-) I won't123188with a partner (11%).
The latter 10% converseabout negative or positive emotions, nearly 50% ofthese dialogs expressing love.
SMS dialogs from?human relations?
contain 9.3 messages per dialogin the average, which is significantly more than theaverage of 4-6 messages in all other topic clusters.The second most discussed topic is ?activities &events?
(14% of all messages), such as ?going out?
(32% of ?activities & events?
labeled messages),or ?going shopping?
(15%).
Interestingly, the topicof ?appointment & scheduling?
is only the thirdmost popular, consisting of less than 13% of alltext messages.Figure 5 shows the topic distribution in the cor-pus with respect to the topic tree?s first hierarchy.Figure 5: Topic distribution on first tree level.Thurlow (2003) has presented a study about thecommunicative intent of US English text messag-es, describing their functional orientation ratherthan the content.
Thurlow?s findings concur in thatthe amount of SMS with relational and intimateorientation vs. transactional orientation is similarto the amount of SMS with interpersonal and emo-tional content vs. all other topic clusters.Finally, we examine if distribution differencesdepend on the demographic data of the users re-garding gender, age groups (18-23, 24-28, 29-35,36-42) and regions.
Users older than 42 years arenot taken into account because of the limited num-ber of text messages in the corpus.Generally, males and females talk about thesame topics in SMS conversations through all agegroups and regions.
However, there are still somedifferences between those groups worth mention-ing and shown in figure 6.While interpersonal and emotional text messag-es together are present in fairly equal quantity forboth gender groups, females tend to express their?emotion?
via text messages much more frequentlythan males (12.5% compared to 8.5%); likely onthe expense of non-emotional ?human relations?messages (46.8% for males compared to 41.9%).Furthermore, males and females have contradictingtrends in ?emotion?
talk over ages.
Females tend toexpress emotions more with age progression, whilemales have the opposite tendency.
In both genders,the corpus suggests a tradeoff between the topics?human relations?
and ?emotion?, i.e.
age maychange the portion of one topic on the expense ofthe other one.4 Relation between Topic and Wording4.1 Automated Validation of Topic TreeA human annotation process is highly effectivedue to people?s ability to exploit their mentalknowledge base and mind concepts, and thus abroad range of information sources.
However, evenFigure 6: Topic distribution by gender (males left, females right) and age groups189in a most rigorous procedure errors may occur,especially regarding annotation and tree consisten-cy.
Therefore we need to verify the quality of theannotation.
Additionally, we want to ensure thatrelevant algorithms can trace the interrelation be-tween topics and the choice of words in SMS.In order to verify both requirements, we performan automatic validation by applying a nuance(Hecht et al, 2009) of the Agglomerative Informa-tion Bottleneck (AIB) method (Tishby et al, 1999;Slonim and Tishby, 2000).
This derivative of theAIB is a hierarchical clustering algorithm, and assuch, it produces a hierarchical topic tree.The clustering starts with each lower level topicas a singleton.
In an iterative process, the two clos-est topics are merged to form a larger topic, wherethe two closest topics are defined as the ones thatminimize the AIB functional (Eq.
1).
The processends when all topics are merged into a single topic.?
??
?
?
?
?
?XYIXXIxxpL ?;?;?
???
(1)X , Y and X?
are the set of topics, set of wordsand clustered set of topics respectively.
?
?BAI ;isthe mutual information between A  and B .Figure 7: Tree branch of the hierarchical clustering oftopics into groups.Intuitively, the function tries to achieve twogoals simultaneously.
It minimizes ?
?XXI ?
; whichcan be interpreted as finding the most compact top-ic representation and at the same time it maximizes?
?XYI ?
;which can be interpreted as finding themost indicative subset of topics.
These two goalscontradict one another.
Therefore a tradeoff para-meter ?
is added.Presenting the entire AIB tree is not feasible inthis paper.
In order to provide some intuition, a subtree is shown in figure 7.
Briefly, each AIB treebranch shows a distribution of topics that is mostlyin line with the hand crafted topic tree.
Even sen-timents are clustered (negative sentiment for alllower level topics in figure 7), a superior achieve-ment to the manual topic tree, where this is doneonly for ?emotion?.
Moreover, it becomes evidentthat the interrelation between topics and wordingin SMS can likely be captured automatically.4.2 Method for Relation DiscoveryBeing confident regarding automatic computation,we can strive for more and aim to discover the in-terrelation between topics and wording in detail.Any vocabulary used in SMS dialogs can intuitive-ly be viewed as containing information whichpoints to one or a limited group of conversed top-ics, or as being general vocabulary with respect totopic distinctiveness.
Such a view point entailsquestions.
How can we extract a list of distinctivewords per topic; words which are dominant in acertain topic but subordinate in others respective-ly?
To what extent are topic distinctive words stillambiguous and are assigned to more than one top-ic?
And ultimately, can we use topic distinctivevocabulary to recognize a list of conversed topicsfor each SMS dialog based on its choice of words?Our method evolves from the questions as fol-lows: First, we categorize the SMS vocabulary intotopic distinctive vs. general vocabulary by intro-ducing an algorithm which uses topic informationas qualitative measurement to extract a list of dis-tinctive words operating as classifiers for topics.
Ina second step we evaluate for each topic to whatextent topic distinctive word list classifiers canrecognize topics in SMS dialogs.
Finally we com-pare the classifiers?
topic recognition capabilitieswith unigram language models.
We use only thenine first level topic clusters to guarantee that theamount of available dialogs per topic is sufficient.1904.3 Topic Distinctive VocabularyTo categorize the vocabulary we calculate for eachword wi with at least 4 occurrences in the corpusand topic tj the ratio between word frequency in thetopic and general word frequency in the corpus(known as Term Frequency/Collection FrequencyMeasure) normalized by the topic size (Eq.
2):?
??
?l mjmlijijicorpusitjjitwcounttwcounttwcounttsizewfreqwfreqtwCfTf),(*),(),()(1*)()(),(?
(2)After scores are calculated for all words, we sortthe words for each topic from their highest to low-est score.
Then we assign a topic dependent thre-shold for each topic determined by a ReceiverOperating Characteristic (ROC) analysis as de-scribed in 4.4.
All words above the threshold be-long to the distinctive word set (DWS) per topic.
Inadditionally conducted experiments with the cor-pus this method has proven to outperform otheralternatives, such as TF*IDF or Term Discrimina-tion Models (Salton et.
al., 1975).Table 2: Examples of topic distinctive words.Table 2 illustrates examples of high-scored re-trieved distinctive words from several topics.
Itbecomes evident that words with high scores arerelated to a topic in our intuition or mental con-cepts.
However, frequently used general words,such as pronouns, prepositions, and commonnouns, do not receive high scores, because of theirvast number of occurrences in other topics, e.g.
?never?, ?flat?, ?boy?, ?you?, or ?from?.
Topicsthat are more descriptive or transactional in theirorientation, such as ?transportation?
or ?finance?,generate better content distinctive word sets thanthe ones with relational intent, such as ?emotion?.4.4 Topic Recognition by Word SetsIn order to determine optimal thresholds (see 4.3)and to analyze the coverage and distinctiveness ofthe word set , we divide the corpus into a trainingbatch (90% of all messages) and a test batch(10%).
The training batch is used for the calcula-tion of word scores as described in 4.3.
By itera-tively increasing the score threshold which definesa word set, we calculate per iteration the amount ofdialogs from the test batch containing at least oneword of the set, for dialogs annotated with the affi-liated topic as well as for dialogs tagged different-ly.
Consequently, ROC curves are created for alltopics.
This process is performed in a cross valida-tion manner (10-fold).Figure 8 shows the ROC curves for the topics?human relations?, ?activities & events?, ?finance& property?, and ?food & drinks?, averaged overthe 10-fold iterations.Figure 8: ROC curves for selected topics including bestand worst performing topics with x axes for false posi-tive rate (FPR) and y axes for true positive rate (TPR).These results show that once appropriate thre-sholds are chosen, relatively small DWS, mostlyranging between 60-120 words per set, have thecapability of achieving a true positive rate (TPR,transporta-tionfinance &propertyemotionlane loan lossboarding payments xoxtires printing beyondflight sander childishwheel cheque lovelicense paypal bitchingroads discount mentallybattery invoice sooplane price stressedexit dollars nerves191also known as recall) of 80.3% for topic dialogswith an average false positive rate (FPR, alsoknown as fall-out) of 26.8%, even with a relativelyna?ve classification method.
Table 3 provides de-tailed results of TPR and FPR.
Topic DWS formore descriptive or transactional topics (e.g.
?transportation?, ?food & drinks?)
manage to dis-tinguish better than relational targeted topics, suchas ?emotion?
and ?human relations?, since wordslike ?love?, ?babe?, or ?thank?
are highly related tothe ?emotion?
topic, but also appear in many othertopics.
Hence, these words are increasing the FPR.Eventually, the word sets chosen by optimalthresholds allow us to quantify topic recognition ofdialogs.
We automatically assign topics to eachdialog in the corpus according to the described al-gorithm.
Then we compare these topics to the ma-nually annotated topics and measure recall andprecision per dialog, denoted (Eq.
3):topicsmatchedtopicsmatchedcorrectprectopicsannotatedtopicsmatchedcorrectrecall_#__#_#__#??
(3)The average recall and precision rates over alldialogs are 73.5% and 44.3%, respectively.
Takinginto account the complexity of the recognition taskdue to the possibility of multiple topic assignmentfor each dialog, the results strengthen the hypothe-sis of the positively measureable interrelation be-tween topics and wording.4.5 Comparison to Full Vocabulary ModelsFinally, we wish to better understand the impact ofDWS, in comparison to the general language de-rived from the topic text, which is motivated by thefact that speech applications rely on SLMs.
To thisend, we construct a unigram language model bi-nary classifier for each topic as baseline and per-form a 10-fold cross validation classification task,to identify whether a given dialog is related to thetopic or not, using the following formula (Eq.
4),where Di is the ith dialog and Mt is the languagemodel of topic t:?????
?iDwttopictopicttitopictopictiMwpMDDtopic))|((maxarg)|(maxarg)(,,*(4)Table 3 summarizes the results of TPR and FPRof the two approaches.
As expected, the DWS ap-proach suffers from a higher FPR, due to a lack ofweights and relative comparisons to other classes.Since the differences in FPR between the two me-thods are not immense, we conclude that our cho-sen word sets are indeed distinctive, and withproper tuning have the potential of achieving betterresults.
On the other hand, the DWS approachmanages to outperform language models in termsof TPR.
Hence, most of the information needed forthe identification of dialog topics is provided bydistinctive words to a significant higher extent asby the rest of the vocabulary.Table 3: True and false positive rates for all topics usingDWS classification and language models.5 ConclusionThe primary motivation of this study has been toestimate and facilitate the potential integration ofcontextual knowledge, in particular topics, intoSMS dictation by voice.
We have identified theinterrelation between conversed topics and thechoice of words in SMS dialogs as a key property,which needs to be quantified.
After creating anannotated corpus and developing a classificationmethod based on topic distinctive word lists, wehave presented initial, promising results, whichencourage further research.Our study exposes also some challenges, whichmay not be easy to address.
It would be useful tohave a larger annotated corpus.
Fully automatedannotation of topics seems hardly achievable inview of our results.
We may therefore rely onsemi-supervised or unsupervised learning algo-rithms.
Moreover, the study explores the relationof topics to single words.
It needs to be enhancedTopic DWS LanguagemodelsTPR FPR TPR FPRActivities & events 81.9 34.7 64.1 22.8Appoint.
& schedule 69.5 31.0 82.6 21.4Transportation 78.7 17.3 68.8 9.8Finance & property 77.9 17.0 76.5 9.6Food & drinks 88.4 11.7 74.1 10.6School & work 80.9 22.4 54.3 14.0Technology 92.4 28.7 75.5 12.6Emotion 80.7 34.4 71.3 12.7Human relation 72.2 34.7 69.8 20.880.3 26.8 70.7 14.9192to phrases, because SMS dictation by voice relieson higher order n-gram SLMs.In summary, when taking the next step andmoving towards speech applications, we expectperformance improvement after making topicknowledge useful for SMS dictation.ReferencesAgar, Jon (2003).
Constant touch: A global history ofthe mobile phone.
Cambridge, UK: Icon Books.Aw, AiTi, Zhang, Min, Xiao, Juan & Su, Jian (2006).
Aphrase-based statistical model for SMS text normali-zation.
In Proceedings of COLING/ACL, Sidney,AU.Chafe, Wallace (1976).
Givenness, contrastiveness, de-finiteness, subjects, topics, and point of view.
In Li,Charles N.
(Ed.
), Subject and Topic (pp.
25-55).
NewYork: Academic Press.Cook, Paul & Stevenson, Suzanne (2009).
An unsuper-vised model for text message normalization.
In Pro-ceedings of the NAACL HLT, Boulder, CO.Fairon, C?drick & Paumier, S?bastien (2006).
A trans-lated corpus of 30,000 French SMS.
In Proceedingsof LREC, GenovaGoggin, Gerard (2006).
Cell phone culture: Mobiletechnology in everyday life.
New York: Routledge.Hecht, Ron M., et.
al.
(2009).
Information Bottleneckbased age verification.
In Proceedings of Interspeech,Brighton, UK.Kobus, Catherine, Yvon, Francois & Damnati, Geral-dine (2008).
Normalizing SMS: are two metaphorsbetter than one?
In Proceedings of COLING, Man-chester, UK.Kothari, Govind, Negi, Sumit & Faruquie, Tanveer A.(2009).
SMS based interface for FAQ retrieval.
InProceedings of ACL, Singapore.Lambert, Lynn & Carberry, Sandra (1992).
Using lin-guistic, world, and contextual knowledge in a planrecognition model of dialogue.
In Proceedings of the14th International Conference on ComputationalLinguistics.Lenhart, Amanda, et.
al.
(2010).
Teens and mobilephones.
From Pew Research Centerhttp://pewinternet.org/Reports/2010/Teens-and-Mobile-Phones.aspxLevinson, Stephen C. (1983).
Pragmatics.
Cambridge:Cambridge University Press.Li, Charles N. & Thompson, Sandra A.
(1976).
Subjectand topic.
A new typology of languages.
In Li,Charles N.
(Ed.
), Subject and Topic (pp.
457-490).New York: Academic Press.McEnery, Tony, Xiao, Richard & Tono, Yukio (2006).Corpus-based language studies.
An advanced re-source book.
London, New York: Routledge.Meyer, Charles F. (2002).
English corpus linguistics.An introduction.
Cambridge: Cambridge UniversityPress.Moln?r, Valer?a (1993).
Zur Pragmatik und Grammatikdes Topik-Begriffes.
In Reis, Marga (Ed.
),Wortstellung und Informationsstruktur (pp.
155-202).T?bingen: Niemeyer.Pennell, Deana L. & Liu, Yang (2010).
Normalizationof text messages for text-to-speech.
In Proceedings ofICASSP, Dallas, TX.Salton, Gerard, Wong, Anita & Yang, Chung-Shu(1975).
A Vector Space Model for automatic index-ing.
In Proceedings of Communications of the ACM,18(11), 613?620.Slonim, Noam & Tishby, Naftali (2000).
AgglomerativeInformation Bottleneck.
In Proceedings of NIPS 12.Stutterheim, Christiane von (1997).
Einige Prinzipiendes Textaufbaus.
Empirische Untersuchungen zurProduktion m?ndlicher Texte.
T?bingen: Niemeyer.Thurlow, Crispin (2003).
Generation txt?
The sociolin-guistics of young people's text-messaging.
From Dis-course Analysis Onlinehttp://extra.shu.ac.uk/daol/articles/v1/n1/a3/thurlow2002003-01.htmlThurlow, Crispin & Poff, Michele (2009).
The languageof text messaging.
In Herring, Susan C., Stein, Dieter& Virtanen, Tuija (Eds.
), Handbook of the Pragmat-ics of CMC.
Berlin and New York: Mouton de Gruy-ter.Tishby, Naftali, Pereira, Fernando C. & Bialek, William(1999).
The Information Bottleneck method.
In Pro-ceedings of 37th annual Allerton conference oncommunication, control and computing, Monticello,IL.Wallis, Sean & Nelson, Gerald (2001).
Knowledge dis-covery in grammatically analysed corpora.
Data Min-ing and Knowledge Discovery, 5(4), 305-335.Wu, Wei, Ju, Yun-Cheng, Li, Xiao & Wang, Ye-Yi(2010).
Paraphrase detection on SMS messages inautomobiles.
In Proceedings of ICASSP, Dallas, TX.193
