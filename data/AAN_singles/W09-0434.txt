Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 197?205,Athens, Greece, 30 March ?
31 March 2009. c?2009 Association for Computational LinguisticsA Quantitative Analysis of Reordering PhenomenaAlexandra Birch Phil Blunsom Miles Osbornea.c.birch-mayne@sms.ed.ac.uk pblunsom@inf.ed.ac.uk miles@inf.ed.ac.ukUniversity of Edinburgh10 Crichton StreetEdinburgh, EH8 9AB, UKAbstractReordering is a serious challenge in sta-tistical machine translation.
We proposea method for analysing syntactic reorder-ing in parallel corpora and apply it to un-derstanding the differences in the perfor-mance of SMT systems.
Results at recentlarge-scale evaluation campaigns showthat synchronous grammar-based statisti-cal machine translation models producesuperior results for language pairs such asChinese to English.
However, for languagepairs such as Arabic to English, phrase-based approaches continue to be competi-tive.
Until now, our understanding of theseresults has been limited to differences inBLEU scores.
Our analysis shows that cur-rent state-of-the-art systems fail to capturethe majority of reorderings found in realdata.1 IntroductionReordering is a major challenge in statistical ma-chine translation.
Reordering involves permutingthe relative word order from source sentence totranslation in order to account for systematic dif-ferences between languages.
Correct word order isimportant not only for the fluency of output, it alsoaffects word choice and the overall quality of thetranslations.In this paper we present an automatic methodfor characterising syntactic reordering found in aparallel corpus.
This approach allows us to analysereorderings quantitatively, based on their numberand span, and qualitatively, based on their relation-ship to the parse tree of one sentence.
The methodswe introduce are generally applicable, only requir-ing an aligned parallel corpus with a parse over thesource or the target side, and can be extended toallow for more than one reference sentence andderivations on both source and target sentences.Using this method, we are able to compare the re-ordering capabilities of two important translationsystems: a phrase-based model and a hierarchicalmodel.Phrase-based models (Och and Ney, 2004;Koehn et al, 2003) have been a major paradigmin statistical machine translation in the last fewyears, showing state-of-the-art performance formany language pairs.
They search all possible re-orderings within a restricted window, and theiroutput is guided by the language model and alexicalised reordering model (Och et al, 2004),both of which are local in scope.
However, thelack of structure in phrase-based models makes itvery difficult to model long distance movement ofwords between languages.Synchronous grammar models can encodestructural mappings between languages which al-low complex, long distance reordering.
Somegrammar-based models such as the hierarchicalmodel (Chiang, 2005) and the syntactified targetlanguage phrases model (Marcu et al, 2006) haveshown better performance than phrase-based mod-els on certain language pairs.To date our understanding of the variation in re-ordering performance between phrase-based andsynchronous grammar models has been limited torelative BLEU scores.
However, Callison-Burch etal.
(2006) showed that BLEU score alone is insuffi-cient for comparing reordering as it only measuresa partial ordering on n-grams.
There has been littledirect research on empirically evaluating reorder-ing.We evaluate the reordering characteristics ofthese two paradigms on Chinese-English andArabic-English translation.
Our main findings areas follows: (1) Chinese-English parallel sentencesexhibit many medium and long-range reorderings,but less short range ones than Arabic-English, (2)phrase-based models account for short-range re-orderings better than hierarchical models do, (3)197by contrast, hierarchical models clearly outper-form phrase-based models when there is signif-icant medium-range reordering, and (4) none ofthese systems adequately deal with longer rangereordering.Our analysis provides a deeper understand-ing of why hierarchical models demonstrate bet-ter performance for Chinese-English translation,and also why phrase-based approaches do well atArabic-English.We begin by reviewing related work in Sec-tion 2.
Section 3 describes our method for ex-tracting and measuring reorderings in aligned andparsed parallel corpora.
We apply our techniquesto human aligned parallel treebank sentences inSection 4, and to machine translation outputs inSection 5.We summarise our findings in Section 6.2 Related WorkThere are few empirical studies of reordering be-haviour in the statistical machine translation lit-erature.
Fox (2002) showed that many commonreorderings fall outside the scope of synchronousgrammars that only allow the reordering of childnodes.
This study was performed manually anddid not compare different language pairs or trans-lation paradigms.
There are some comparativestudies of the reordering restrictions that can beimposed on the phrase-based or grammar-basedmodels (Zens and Ney, 2003; Wellington et al,2006), however these do not look at the reorderingperformance of the systems.
Chiang et al (2005)proposed a more fine-grained method of compar-ing the output of two translation systems by us-ing the frequency of POS sequences in the output.This method is a first step towards a better under-standing of comparative reordering performance,but neglects the question of what kind of reorder-ing is occurring in corpora and in translation out-put.Zollmann et al (2008) performed an empiri-cal comparison of the BLEU score performanceof hierarchical models with phrase-based models.They tried to ascertain which is the stronger modelunder different reordering scenarios by varyingdistortion limits the strength of language models.They show that the hierarchical models do slightlybetter for Chinese-English systems, but worse forArabic-English.
However, there was no analysis ofthe reorderings existing in their parallel corpora,or on what kinds of reorderings were produced intheir output.
We perform a focused evaluation ofthese issues.Birch et al (2008) proposed a method for ex-tracting reorderings from aligned parallel sen-tences.We extend this method in order to constrainthe reorderings to a derivation over the source sen-tence where possible.3 Measuring ReorderingReordering is largely driven by syntactic differ-ences between languages and can involve complexrearrangements between nodes in synchronoustrees.
Modeling reordering exactly would besparse and heterogeneous and thus we make animportant simplifying assumption in order for thedetection and extraction of reordering data to betractable and useful.
We assume that reorderingis a binary process occurring between two blocksthat are adjacent in the source.
We extend themethods proposed by Birch et al (2008) to iden-tify and measure reordering.
Modeling reorderingas the inversion in order of two adjacent blocks issimilar to the approach taken by the Inverse Trans-duction Model (ITG) (Wu, 1997), except that herewe are not limited to a binary tree.
We also detectand include non-syntactic reorderings as they con-stitute a significant proportion of the reorderings.Birch et al (2008) defined the extraction pro-cess for a sentence pair that has been word aligned.This method is simple, efficient and applicable toall aligned sentence pairs.
However, if we have ac-cess to the syntax tree, we can more accuratelydetermine the groupings of embedded reorder-ings, and we can also access interesting informa-tion about the reordering such as the type of con-stituents that get reordered.
Figure 1 shows theadvantage of using syntax to guide the extractionprocess.
Embedded reorderings that are extractedwithout syntax assume a right branching structure.Reorderings that are extracted using the syntac-tic extraction algorithm reflect the correct sentencestructure.
We thus extend the algorithm to extract-ing syntactic reorderings.
We require that syntac-tic reorderings consist of blocks of whole siblingnodes in a syntactic tree over the source sentence.In Figure 2 we can see a sentence pair with analignment and a parse tree over the source.
We per-form a depth first recursion through the tree, ex-tracting the reorderings that occur between wholesibling nodes.
Initially a reordering is detected be-tween the leaf nodes P and NN.
The block growingalgorithm described in Birch et al (2008) is thenused to grow block A to include NT and NN, andblock B to include P and NR.
The source and tar-get spans of these nodes do not overlap the spans198Figure 1.
An aligned sentence pair which shows twodifferent sets of reorderings for the case without andwith a syntax tree.of any other nodes, and so the reordering is ac-cepted.
The same happens for the higher level re-ordering where block A covers NP-TMP and PP-DIR, and block B covers the VP.
In cases wherethe spans do overlap spans of nodes that are notsiblings, these reorderings are then extracted us-ing the algorithm described in Birch et al (2008)without constraining them to the parse tree.
Thesenon-syntactic reorderings constitute about 10% ofthe total reorderings and they are a particular chal-lenge to models which can only handle isomorphicstructures.RQuantityThe reordering extraction technique allows us toanalyse reorderings in corpora according to thedistribution of reordering widths and syntactictypes.
In order to facilitate the comparison of dif-ferent corpora, we combine statistics about in-dividual reorderings into a sentence level metricwhich is then averaged over a corpus.
This met-ric is defined using reordering widths over the tar-get side to allow experiments with multiple lan-guage pairs to be comparable when the commonlanguage is the target.We use the average RQuantity (Birch et al,2008) as our measure of the amount of reorderingin a parallel corpus.
It is defined as follows:RQuantity =?r?R |rAt | + |rBt |Iwhere R is the set of reorderings for a sentence,I is the target sentence length, A and B are thetwo blocks involved in the reordering, and |rAs |is the size or span of block A on the target side.RQuantity is thus the sum of the spans of all thereordering blocks on the target side, normalised$ %$%Figure 2.
A sentence pair from the test corpus, with itsalignment and parse tree.
Two reorderings are shownwith two different dash styles.by the length of the target sentence.
The minimumRQuantity for a sentence would be 0.
The max-imum RQuantity occurs where the order of thesentence is completely inverted and the RQuantityis?Ii=2 i.
See, for example, Figure 1 where theRQuantity is 94 .4 Analysis of Reordering in ParallelCorporaCharacterising the reordering present in differenthuman generated parallel corpora is crucial to un-derstanding the kinds of reordering wemust modelin our translations.
We first need to extract reorder-ings for which we need alignments and deriva-tions.
We could use automatically generated an-notations, however these contain errors and couldbe biased towards the models which created them.The GALE project has provided gold standardword alignments for Arabic-English (AR-EN) andChinese-English (CH-EN) sentences.1 A subset ofthese sentences come from the Arabic and Chi-nese treebanks, which provide gold standard parsetrees.
The subsets of parallel data for which wehave both alignments and parse trees consist of1see LDC corpus LDC2006E93 version GALE-Y1Q4199lll ll ll l lll0.00.20.40.60.81.0Sentence Length BinRQuantity0?9 20?29 40?49 60?69 80?89 >=100l CH.EN.RQuantityAR.EN.RQuantityFigure 3.
Sentence level measures of RQuantity for theCH-EN and AR-EN corpora for different English sen-tence lengths.l lllllllll05001000150020002500Reordering WidthNumberof Reorderings2 3 4 5 6 7?8 9?10 16?20l CH?ENAR?ENFigure 4.
Comparison of reorderings of different widthsfor the CH-EN and AR-EN corpora.3,380 CH-EN sentences and 4,337 AR-EN sen-tences.Figure 3 shows that the different corpora havevery different reordering characteristics.
The CH-EN corpus displays about three times the amountof reordering (RQuantity) than the AR-EN cor-pus.
For CH-EN, the RQuantity increases withsentence length and for AR-EN, it remains con-stant.
This seems to indicate that for longer CH-EN sentences there are larger reorderings, but thisis not the case for AR-EN.
RQuantity is low forvery short sentences, which indicates that thesesentences are not representative of the reorderingcharacteristics of a corpus.
The measures seemto stabilise for sentences with lengths of over 20words.The average amount of reordering is interesting,but it is also important to look at the distributionof reorderings involved.
Figure 4 shows the re-orderings in the CH-EN and AR-EN corpora bro-llllllllll051015202530Widths of Reorderings% Number of Reorderingsfor Width2 3 4 5 6 7?8 9?10 16?20l NPDNPCPNP.PNFigure 5.
The four most common syntactic types beingreordered forward in target plotted as % of total syntac-tic reorderings against reordering width (CH-EN).ken down by the total width of the source spanof the reorderings.
The figure clearly shows howdifferent the two language pairs are in terms ofreordering widths.
Compared to the CH-EN lan-guage pair, the distribution of reorderings in AR-EN has many more reorderings over short dis-tances, but many fewer medium or long distancereorderings.
We define short, medium or long dis-tance reorderings to mean that they have a reorder-ing of width of between 2 to 4 words, 5 to 8 andmore than 8 words respectively.Syntactic reorderings can reveal very richlanguage-specific reordering behaviour.
Figure 5is an example of the kinds of data that can be usedto improve reordering models.
In this graph we se-lected the four syntactic types that were involvedin the largest number of reorderings.
They cov-ered the block that was moved forward in the tar-get (block A).
We can see that different syntactictypes display quite different behaviour at differentreordering widths and this could be important tomodel.Having now characterised the space of reorder-ing actually found in parallel data, we now turnto the question of how well our translation modelsaccount for them.
As both the translation modelsinvestigated in this work do not use syntax, in thefollowing sections we focus on non-syntactic anal-ysis.5 Evaluating Reordering in TranslationWe are interested in knowing how current trans-lation models perform specifically with regard toreordering.
To evaluate this, we compare the re-orderings in the parallel corpora with the reorder-ings that exist in the translated sentences.
We com-200None Low Medium HighAverage RQuantityCH-EN 0 0.39 0.82 1.51AR-EN 0 0.10 0.25 0.57Number of SentencesCH-EN 105 367 367 367AR-EN 293 379 379 379Table 1.
The RQuantity and the number of sentencesfor each reordering test set.pare two state-of-the-art models: the phrase-basedsystem Moses (Koehn et al, 2007) (with lexi-calised reordering), and the hierarchical model Hi-ero (Chiang, 2007).
We use default settings forboth models: a distortion limit of seven for Moses,and a maximum source span limit of 10 words forHiero.
We trained both models on subsets of theNIST 2008 data sets, consisting mainly of newsdata, totalling 547,420 CH-EN and 1,069,658 AR-EN sentence pairs.
We used a trigram languagemodel on the entire English side (211M words)of the NIST 2008 Chinese-English training cor-pus.
Minimum error rate training was performedon the 2002 NIST test for CH-EN, and the 2004NIST test set for AR-EN.5.1 Reordering Test CorpusIn order to determine what effect reordering hason translation, we extract a test corpus with spe-cific reordering characteristics from the manuallyaligned and parsed sentences described in Sec-tion 4.
To minimise the impact of sentence length,we select sentences with target lengths from 20 to39 words inclusive.
In this range RQuantity is sta-ble.
From these sentences we first remove thosewith no detected reorderings, and we then divideup the remaining sentences into three sets of equalsizes based on the RQuantity of each sentence.
Welabel these test sets: ?none?, ?low?, ?medium?
and?high?.All test sentences have only one reference En-glish sentence.
MT evaluations using one refer-ence cannot make strong claims about any partic-ular test sentence, but are still valid when used tocompare large numbers of hypotheses.Table 1 and Figure 6 show the reordering char-acteristics of the test sets.
As expected, we seemore reordering for Chinese-English than for Ara-bic to English.It is important to note that although we mightname a set ?low?
or ?high?, this is only relativeto the other groups for the same language pair.The ?high?
AR-EN set, has a lower RQuantitythan the ?medium?
CH-EN set.
Figure 6 shows050100150200250Widths of ReorderingsNumberof Reorderings2 3 4 5 6 7?8 9?10 16?20LowMediumHighFigure 6.
Number of reorderings in the CH-EN test setplotted against the total width of the reorderings.none low med high allMOSESHIERO1416182022Figure 7.
BLEU scores for the different CH-EN reorder-ing test sets and the combination of all the groups forthe two translation models.The 95% confidence levelsas measured by bootstrap resampling are shown foreach bar.that the CH-EN reorderings in the higher RQuan-tity groups have more and longer reorderings.
TheAR-EN sets show similar differences in reorderingbehaviour.5.2 Performance on Test SetsIn this section we compare the translation outputfor the phrase-based and the hierarchical systemfor different reordering scenarios.
We use the testsets created in Section 5.1 to explicitly isolate theeffect reordering has on the performance of twotranslation systems.Figure 7 and Figure 8 show the BLEU scoreresults of the phrase-based model and the hierar-chical model on the different reordering test sets.The 95% confidence intervals as calculated bybootstrap resampling (Koehn, 2004) are shown foreach of the results.
We can see that the modelsshow quite different behaviour for the differenttest sets and for the different language pairs.
Thisdemonstrates that reordering greatly influences the201none low med high allMOSESHIERO161820222426Figure 8.
BLEU scores for the different AR-EN reorder-ing test sets and the combination of all the groups forthe two translation models.
The 95% confidence lev-els as measured by bootstrap resampling are shown foreach bar.BLEU score performance of the systems.In Figure 7 we see that the hierarchical modelperforms considerably better than Moses on the?medium?
CH-EN set, although the confidenceinterval for these results overlap somewhat.
Thissupports the claim that Hiero is better able to cap-ture longer distance reorderings than Moses.Hiero performs significantly worse than Moseson the ?none?
and ?low?
sets for CH-EN, andfor all the AR-EN sets, other than ?none?.
Allthese sets have a relatively low amount of reorder-ing, and in particular a low number of mediumand long distance reorderings.
The phrase-basedmodel could be performing better because itsearches all possible permutations within a certainwindow whereas the hierarchical model will onlypermit reorderings for which there is lexical evi-dence in the training corpus.
Within a small win-dow, this exhaustive search could discover the bestreorderings, but within a bigger window, the moreconstrained search of the hierarchical model pro-duces better results.
It is interesting that Hiero isnot always the best choice for translation perfor-mance, and depending on the amount of reorder-ing and the distribution of reorderings, the simplerphrase-based approach is better.The fact that both models show equally poorperformance on the ?high?
RQuantity test set sug-gests that the hierarchical model has no advantageover the phrase-based model when the reorder-ings are long enough and frequent enough.
Nei-ther Moses nor Hiero can perform long distancereorderings, due to the local constraints placed ontheir search which allows performance to be lin-ear with respect to sentence length.
Increasing thewindow in which these models are able to performreorderings does not necessarily improve perfor-ll ll ll l l020406080100120140Widths of ReorderingsNumberof Reorderings2 3 4 5 6 7 8 >8l NoneLowMediumHighFigure 9.
Reorderings in the CH-EN MOSES transla-tion of the reordering test set, plotted against the totalwidth of the reorderings.mance, due to the number of hypotheses the mod-els must discriminate amongst.The performance of both systems on the ?high?test set could be much worse than the BLEU scorewould suggest.
A long distance reordering that hasbeen missed, would only be penalised by BLEUonce at the join of the two blocks, even though itmight have a serious impact on the comprehensionof the translation.
This flaw seriously limits theconclusions that we can draw from BLEU score,and motivates analysing translations specificallyfor reordering as we do in this paper.Reorderings in TranslationAt best, BLEU can only partially reflect the re-ordering performance of the systems.
We thereforeperform an analysis of the distribution of reorder-ings that are present in the systems?
outputs, in or-der to compare them with each other and with thesource-reference distribution.For each hypothesis translation, we recordwhich source words and phrase pairs or rules wereused to produce which target words.
From this wecreate an alignment matrix from which reorder-ings are extracted in the same manner as previ-ously done for the manually aligned corpora.Figure 9 shows the distribution of reorderingsthat occur between the source sentence and thetranslations from the phrase-based model.
Thisgraph is interesting when compared with Figure 6,which shows the reorderings that exist in the orig-inal reference sentence pair.
The two distribu-tions are quite different.
Firstly, as the models usephrases which are treated as blocks, reorderingswhich occur within a phrase are not recorded.
Thisreduces the number of shorter distance reorder-ings in the distribution in Figure 6, as mainly short202lll llll l01020304050Widths of ReorderingsNumberof Reorderings2 3 4 5 6 7 8 >8l NoneLowMediumHighFigure 10.
Reorderings in the CH-EN Hiero translationof the reordering test set, plotted against the total widthof the reorderings.phrases pairs are used in the hypothesis.
However,even taking reorderings within phrase pairs intoaccount, there are many fewer reorderings in thetranslations than in the references, and there areno long distance reorderings.It is interesting that the phrase-based model isable to capture the fact that reordering increaseswith the RQuantity of the test set.
Looking at theequivalent data for the AR-EN language pair, asimilar pattern emerges: there are many fewer re-orderings in the translations than in the references.Figure 10 shows the reorderings from the outputof the hierarchical model.
The results are very dif-ferent to both the phrase-based model output (Fig-ure 9) and to the original reference reordering dis-tribution (Figure 6).
There are fewer reorderingshere than even in the phrase-based output.
How-ever, the Hiero output has a slightly higher BLEUscore than the Moses output.
The number of re-orderings is clearly not the whole story.
Part of thereason why the output seems to have few reorder-ings and yet scores well, is that the output of hier-archical models does not lend itself to the analysisthat we have performed successfully on the ref-erence or phrase-based translation sentence pairs.This is because the output has a large number ofnon-contiguous phrases which prevent the extrac-tion of reorderings from within their span.
Only4.6% of phrase-based words were blocked off dueto non-contiguous phrases but 47.5% of the hier-archical words were.
This problem can be amelio-rated with the detection and unaligning of wordswhich are obviously dependent on other words inthe non-contiguous phrase.Even taking blocked off phrases into account,however, the number of reorderings in the hierar-l llllllll0100200300400500600Reordering WidthNumberof Reorderings2 3 4 5 6 7?8 9?10 16?20l Test.SetPhrase.BasedHierarchicalFigure 11.
Number of reorderings in the original CH-EN test set, compared to the reorderings retained bythe phrase-based and hierarchical models.
The data isshown relative to the length of the total source width ofthe reordering.chical output is still low, especially for the mediumand long distance reorderings, as compared to thereference sentences.
The hierarchical model?s re-ordering behaviour is very different to human re-ordering.
Even if human translations are freer andcontain more reordering than is strictly necessary,many important reorderings are surely being lost.Targeted Automatic EvaluationComparing distributions of reorderings is inter-esting, but it cannot approach the question of howmany reorderings the system performed correctly.In this section we identify individual reorderingsin the source and reference sentences and detectwhether or not they have been reproduced in thetranslation.Each reordering in the original test set is ex-tracted.
Then the source-translation alignment isinspected to determine whether the blocks in-volved in the original reorderings are in the reverseorder in the translation.
If so, we say that these re-orderings have been retained from the reference tothe translation.If a reordering has been translated by one phrasepair, we assume that the reordering has been re-tained, because the reordering could exist insidethe phrase.
If the segmentation is slightly differ-ent, but a reordering of the correct size occurred atthe right place, it is also considered to be retained.Figure 11 shows that the hierarchical modelretains more reorderings of all widths than thephrase-based system.
Both systems retain few re-orderings, with the phrase-based model missingalmost all the medium distance reorderings, andboth models failing on all the long distance re-203Correct Incorrect NARetained 61 4 10Not Retained 32 31 12Table 2.
Correlation between retaining reordering and itbeing correct - for humans and for systemorderings.
This is possibly the most direct evi-dence of reordering performance so far, and againshows how Hiero has a slight advantage over thephrase-based systemwith regard to reordering per-formance.Targeted Manual AnalysisThe relationship between targeted evaluationand the correct reordering of the translation stillneeds to be established.
The translation system cancompensate for not retaining a reordering by us-ing different lexical items.
To judge the relevanceof the targeted evaluation we need to perform amanual evaluation.
We present evaluators with thereference and the translation sentences.
We markthe target ranges of the blocks that are involvedin the particular reordering we are analysing, andask the evaluator if the reordering in the translationis correct, incorrect or not applicable.
The not ap-plicable case is chosen when the translated wordsare so different from the reference that their order-ing is irrelevant.
There were three evaluators whoeach judged 25 CH-EN reorderings which were re-tained and 25 CH-EN reorderings which were notretained by the Moses translation model.The results in Table 2 show that the retainedreorderings are generally judged to be correct.
Ifthe reordering is not retained, then the evaluatorsdivided their judgements evenly between the re-ordering being correct or incorrect.
It seems thatthe fact that a reordering is not retained does in-dicate that its ordering is more likely to be incor-rect.
We used Fleiss?
Kappa to measure the cor-relation between annotators.
It expresses the ex-tent to which the amount of agreement betweenraters is greater than what would be expected ifall raters made their judgements randomly.
In thiscase Fleiss?
kappa is 0.357 which is considered tobe a fair correlation.6 ConclusionIn this paper we have introduced a general andextensible automatic method for the quantitativeanalyse of syntactic reordering phenomena in par-allel corpora.We have applied our method to a systematicanalysis of reordering both in the training corpus,and in the output, of two state-of-the-art transla-tion models.
We show that the hierarchical modelperforms better than the phrase-based model in sit-uations where there are many medium distance re-orderings.
In addition, we find that the choice oftranslation model must be guided by the type of re-orderings in the language pair, as the phrase-basedmodel outperforms the hierarchical model whenthere is a predominance of short distance reorder-ings.
However, neither model is able to capture thereordering behaviour of the reference corpora ad-equately.
These result indicate that there is stillmuch research to be done if statistical machinetranslation systems are to capture the full range ofreordering phenomena present in translation.ReferencesAlexandra Birch, Miles Osborne, and Philipp Koehn.
2008.Predicting success in machine translation.
In Proceedingsof the Empirical Methods in Natural Language Process-ing.Chris Callison-Burch, Miles Osborne, and Philipp Koehn.2006.
Re-evaluating the role of Bleu in machine trans-lation research.
In Proceedings of the European Chapterof the Association for Computational Linguistics, Trento,Italy.David Chiang, Adam Lopez, Nitin Madnani, Christof Monz,Philip Resnik, and Michael Subotin.
2005.
The Hieromachine translation system: Extensions, evaluation, andanalysis.
In Proceedings of the Human Language Tech-nology Conference and Conference on Empirical Methodsin Natural Language Processing, pages 779?786, Vancou-ver, Canada.David Chiang.
2005.
A hierarchical phrase-based model forstatistical machine translation.
In Proceedings of the As-sociation for Computational Linguistics, pages 263?270,Ann Arbor, Michigan.David Chiang.
2007.
Hierarchical phrase-based translation.Computational Linguistics (to appear), 33(2).Heidi J.
Fox.
2002.
Phrasal cohesion and statistical machinetranslation.
In Proceedings of the Conference on Empiri-cal Methods in Natural Language Processing, pages 304?311, Philadelphia, USA.Philipp Koehn, Franz Och, and Daniel Marcu.
2003.
Sta-tistical phrase-based translation.
In Proceedings of theHuman Language Technology and North American Asso-ciation for Computational Linguistics Conference, pages127?133, Edmonton, Canada.
Association for Computa-tional Linguistics.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Constantin,and Evan Herbst.
2007.
Moses: Open source toolkitfor statistical machine translation.
In Proceedings ofthe Association for Computational Linguistics CompanionDemo and Poster Sessions, pages 177?180, Prague, CzechRepublic.
Association for Computational Linguistics.204Philipp Koehn.
2004.
Statistical significance tests for ma-chine translation evaluation.
In Dekang Lin and DekaiWu, editors, Proceedings of EMNLP 2004, pages 388?395, Barcelona, Spain, July.
Association for Computa-tional Linguistics.Daniel Marcu, Wei Wang, Abdessamad Echihabi, and KevinKnight.
2006.
SPMT: Statistical machine translation withsyntactified target language phrases.
In Proceedings of theConference on Empirical Methods in Natural LanguageProcessing, pages 44?52, Sydney, Australia.Franz Josef Och and Hermann Ney.
2004.
The alignmenttemplate approach to statistical machine translation.
Com-putational Linguistics, 30(4):417?450.Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur, AnoopSarkar, Kenji Yamada, Alex Fraser, Shankar Kumar, Li-bin Shen, David Smith, Katherine Eng, Viren Jain, ZhenJin, and Dragomir Radev.
2004.
A smorgasbord of fea-tures for statistical machine translation.
In Proceedings ofHuman Language Technology Conference and Conferenceon Empirical Methods in Natural Language Processing,pages 161?168, Boston, USA.
Association for Computa-tional Linguistics.Benjamin Wellington, Sonjia Waxmonsky, and I. DanMelamed.
2006.
Empirical lower bounds on the complex-ity of translational equivalence.
In Proceedings of the In-ternational Conference on Computational Linguistics andof the Association for Computational Linguistics, pages977?984, Sydney, Australia.Dekai Wu.
1997.
Stochastic inversion transduction gram-mars and bilingual parsing of parallel corpora.
Computa-tional Linguistics, 23(3):377?403.Richard Zens and Hermann Ney.
2003.
A comparative studyon reordering constraints in statistical machine translation.In Proceedings of the Association for Computational Lin-guistics, pages 144?151, Sapporo, Japan.Andreas Zollmann, Ashish Venugopal, Franz Och, and JayPonte.
2008.
A systematic comparison of phrase-based,hierarchical and syntax-augmented statistical mt.
In Pro-ceedings of International Conference On ComputationalLinguistics.205
