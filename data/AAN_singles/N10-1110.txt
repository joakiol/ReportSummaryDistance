Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 725?728,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsInvestigations into the Crandem Approach to Word RecognitionRohit Prabhavalkar, Preethi Jyothi, William Hartmann, Jeremy Morris, and Eric Fosler-LussierDepartment of Computer Science and EngineeringThe Ohio State University, Columbus, OH{prabhava,jyothi,hartmanw,morrijer,fosler}@cse.ohio-state.eduAbstractWe suggest improvements to a previously pro-posed framework for integrating ConditionalRandom Fields and Hidden Markov Models,dubbed a Crandem system (2009).
The pre-vious authors?
work suggested that local la-bel posteriors derived from the CRF were toolow-entropy for use in word-level automaticspeech recognition.
As an alternative to thelog posterior representation used in their sys-tem, we explore frame-level representationsderived from the CRF feature functions.
Wealso describe a weight normalization transfor-mation that leads to increased entropy of theCRF posteriors.
We report significant gainsover the previous Crandem system on the WallStreet Journal word recognition task.1 IntroductionConditional Random Fields (CRFs) (Lafferty etal., 2001) have recently emerged as a promisingnew paradigm in the domain of Automatic SpeechRecognition (ASR).
Unlike Hidden Markov Mod-els (HMMs), CRFs are direct discriminative models:they predict the probability of a label sequence con-ditioned on the input.
As a result, CRFs can capturelong-range dependencies in the data and avoid theneed for restrictive independence assumptions.
Vari-ants of CRFs have been successfully used in phonerecognition tasks (Gunawardana et al, 2005; Morrisand Fosler-Lussier, 2008; Hifny and Renals, 2009).While the improvements in the phone recognitiontask are encouraging, recent efforts have been di-rected towards extending the CRF paradigm to theword recognition level (Zweig and Nguyen, 2009;Morris and Fosler-Lussier, 2009).
The Crandemsystem (Morris and Fosler-Lussier, 2009) is one ofthe promising approaches in this regard.
The Cran-dem system is directly inspired by the techniquesof the Tandem system (Hermansky et al, 2000),where phone-label posterior estimates produced bya Multi-Layer Perceptron (MLP) are transformedinto a suitable acoustic representation for a standardHMM.
In both systems, the frame-based log poste-rior vector of P (phone|acoustics) over all phones isdecorrelated using the Karhunen-Loeve (KL) trans-form; unlike MLPs, CRFs take into account the en-tire label sequence when computing local posteriors.However, posterior estimates from the CRF tend tobe overconfident compared to MLP posteriors (Mor-ris and Fosler-Lussier, 2009).In this paper, we analyze the interplay betweenthe various steps involved in the Crandem process.Is the local posterior representation from the CRFthe best representation?
Given that the CRF poste-rior estimates can be overconfident, what transfor-mations to the posteriors are appropriate?In Section 2 we briefly describe CRFs and theCrandem framework.
We suggest techniques for im-proving Crandem word recognition performance inSection 3.
Details of experiments and our results arediscussed in Sections 4 and 5 respectively.
We con-clude with a discussion of future work in Section 6.2 CRFs and the Crandem SystemConditional random fields (Lafferty et al, 2001) ex-press the probability of a label sequence Q condi-tioned on the input data X as a log-linear sum of725weighted feature functions,p(Q|X) =expPtPj ?jsj(qt, X) +Pj ?jfj(qt?1, qt, X)Z(X)(1)where sj(?)
and fj(?)
are known as state featurefunctions and transition feature functions respec-tively, and ?j and ?j are the associated weights.Z(X) is a normalization term that ensures a validprobability distribution.
Given a set of labeled ex-amples, the CRF is trained to maximize the con-ditional log-likelihood of the training set.
Thelog-likelihood is concave over the entire parameterspace, and can be maximized using standard convexoptimization techniques (Lafferty et al, 2001; Shaand Pereira, 2003).
The local posterior probabilityof a particular label can be computed via a forward-backward style algorithm.
Mathematically,p(qt = q|X) =?t(q|X)?t(q|X)Z(X)(2)where ?t(q|X) and ?t(q|X) accumulate contribu-tions associated with possible assignments of la-bels before and after the current time-step t. TheCrandem system utilizes these local posterior val-ues from the CRF analogously to the way in whichMLP-posteriors are treated in the Tandem frame-work (Hermansky et al, 2000), by applying a logtransformation to the posteriors.
These transformedoutputs are then decorrelated using a KL-transformand then dimensionality-reduced to be used as a re-placement for MFCCs in a HMM system.
Whilethe MLP is usually reduced to 39 dimensions, thestandard CRF benefits from a higher dimensionalityreduction (to 19 dimensions).
The decorrelated out-puts are then used as an input representation for aconventional HMM system.3 Improving Crandem RecognitionResultsMorris and Fosler-Lussier (2009) indicate that thelocal posterior outputs from the CRF model pro-duces features that are more heavily skewed to thedominant phone class than the MLP system, leadingto an increase in word recognition errors.
In orderto correct for this, we perform a non-linear trans-formation on the local CRF posterior representa-tion before applying a KL-transform and subsequentstages.
Specifically, we normalize all of the weights?j and ?j in Equation 1 by a fixed positive constantn to obtain normalized weights ?
?j and ?
?j .
We notethat the probability of a label sequence computed us-ing the transformed weights, p?
(Q|X), is equivalentto taking the nth-root of the CRF probability com-puted using the unnormalized weights, with a newnormalization term Z ?(X)p?
(Q|X) =p(Q|X)1/nZ ?
(X)(3)where, p(Q|X) is as defined in Equation 1.
Alsoobserve that the monotonicity of the nth-root func-tion ensures that if p(Q1|X) > p(Q2|X) thenp?
(Q1|X) > p?(Q2|X).
In other words, the rankorder of the n-best phone recognition results are notimpacted by this change.
The transformation does,however, increase the entropy between the domi-nant class from the CRF and its competitors, sincep?
(Q|X) < p(Q|X).
As we shall discuss in Section5, this transformation helps improve word recogni-tion performance in the Crandem framework.Our second set of experiments are based on thefollowing observation regarding the CRF posteriors.As can be seen from Equation 2, the CRF posteri-ors involve a global normalization over the entire ut-terance as opposed to the local normalization of theMLP posteriors in the output softmax layer.
Thismotivates the use of representations derived fromthe CRF that are ?local?
in some sense.
We there-fore propose two alternative representations that aremodeled along the lines of the linear outputs from anMLP.
The first uses the sum of the state feature func-tions, to obtain a vector f state(X, t) for each timestep t and input utterance X of length |Q| dimen-sions, where Q is the set of possible phone labelsf state(X, t) =???j?jsj(q,X)?
?T?q ?
Q(4)where q is a particular phone label.
Note that thelack of an exponential term in this representation en-sures that the representation is less ?spiky?
than theCRF posteriors.
Additionally, the decoupling of therepresentation from the transition feature functionscould potentially allow the system to represent rel-726ative ambiguity between multiple phones hypothe-sized for a given frame.The second ?local?
representation that we experi-mented with incorporates the CRF transition featurefunctions as follows.
For each utterance X we per-form a Viterbi decoding of the most likely state se-quence Qbest = argmaxQ{p(Q|X)} hypothesizedfor the utterance X .
We then augmented the statefeature representation with the sum of the transitionfeatures corresponding to the phone label hypothe-sized for the previous frame (qbestt?1) to obtain a vectorf trans(X, t) of length |Q|,f trans(X, t) ="Xj?jsj(q,X) +Xj?jfj(qbestt?1 , q,X)#T(5)As a final note, following (Morris and Fosler-Lussier, 2009), our CRF systems are trained usingthe linear outputs of MLPs as its state feature func-tions and transition biases as the transition featurefunctions.
Hence, f state is a linear transformation ofthe MLP linear outputs down to |Q| dimensions.1Both f state and f trans can thus be viewed as an im-plicit mapping performed by the CRF of the in-put feature function dimensions down to |Q| dimen-sions.
Note that the CRF implicitly uses informa-tion concerning the underlying phone labels unlikedimensionality reduction using KL-transform.4 Experimental SetupTo evaluate our proposed techniques, we carriedout word recognition experiments on the speaker-independent portion of the Wall Street Journal 5Kclosed vocabulary task (WSJ0).
Since the corpus isnot phonetically transcribed, we first trained a stan-dard HMM recognition system using PLP featuresand produced phonetic transcriptions by force align-ing the training data.
These were used to train anMLP phone classifier with a softmax output layer,using a 9-frame window of PLPs with 4000 hiddenlayer units to predict one of the 41 phone labels (in-cluding silence and short pause).
The linear outputsof the MLP were used to train a baseline Tandemsystem.
We then trained a CRF using the MLP lin-ear outputs as its state feature functions.
We extract1We note that our system uses an additional state bias featurethat has a fixed value of 1.
However, since this is a constantterm, it has no role to play in the derived representation.System Accuracy (%)Crandem-baseline 89.4%Tandem-baseline 91.8%Crandem-NormMax 91.4%Crandem-Norm5 92.1%Crandem-state 91.7%Crandem-trans 91.0%Table 1: Word recognition results on the WSJ0 tasklocal posteriors as well as the two ?local?
representa-tions described in Section 3.
These input represen-tations were then normalized at the utterance level,before applying a KL-transformation to decorrelatethem and reduce dimensionality to 39 dimensions.Finally, each of these representations was used totrain a HMM system with intra-word triphones and16 Gaussians per mixture using the Hidden MarkovModel Toolkit (Young et al, 2002).5 ResultsResults for each of the experiments described inSection 4 are reported in Table 1 on the 330-sentence standard 5K non-verbalized test set.
TheCrandem-baseline represents the system of (Mor-ris and Fosler-Lussier, 2009).
Normalizing theCRF weights of the system by either the weightwith largest absolute value (CRF-NormMax) or by5 (tuned on the development set) leads to signif-icant improvements (p ?
0.005) over the Cran-dem baseline.
Similarly, using either the state fea-ture sum (Crandem-state) or the representation aug-mented with the transition features (Crandem-trans)leads to significant improvements (p ?
0.005) overthe Crandem baseline.
Note that the performance ofthese systems is comparable to the Tandem baseline.To further analyze the results obtained using thestate feature sum representations and the Tandembaseline, we compute the mean distance for eachphone HMM from every other phone HMM ob-tained at the end of the GMM-HMM training phase.The distance between two HMMs is computed as auniformly weighted sum of the average distances be-tween the GMMs of a one-to-one alignment of statescorresponding to the two HMMs.
GMM distancesare computed using a 0.5-weighted sum of inter-dispersions normalized by self-dispersions (Wang et727Figure 1: Normalized mean distances for each of the phone models from every other phone model trained using theTandem MLP baseline and the state feature sum representation.al., 2004).
Distances between monomodal Gaus-sian distributions were computed using the Bhat-tacharyya distance measure.
The phone HMM dis-tances are normalized using the maximum phonedistance for each system.
As can be seen in Figure1, the mean distances obtained from the state featuresum representation are consistently greater than thecorresponding distances in the Tandem-MLP sys-tem, indicating larger separability of the phones inthe feature space.
Similar trends were seen with thetransition feature sum representation.6 Conclusions and Future WorkIn this paper, we report significant improvementsover the Crandem baseline.
The weight normaliza-tion experiments confirmed the hypothesis that in-creasing the entropy of the CRF posteriors leads tobetter word-level recognition.
Our experiments withdirectly extracting frame-level representations fromthe CRF reinforce this conclusion.
Although our ex-periments with the systems using the state featuresum and transition feature augmented representationdid not lead to improvements over the Tandem base-line, the increased separability of the phone modelstrained using these representations is encouraging.In the future, we intend to examine techniques bywhich these representations could be used to furtherimprove word recognition results.Acknowledgement: The authors gratefully ac-knowledge support by NSF grants IIS-0643901 andIIS-0905420 for this work.ReferencesA.
Gunawardana, M. Mahajan, A. Acero, and J. Platt.2005.
Hidden conditional random fields for phoneclassification.
Interspeech.H.
Hermansky, D. Ellis, and S. Sharma.
2000.
Tan-dem connectionist feature stream extraction for con-ventional hmm systems.
ICASSP.Y.
Hifny and S. Renals.
2009.
Speech recognition usingaugmented conditional random fields.
IEEE Trans-actions on Audio, Speech, and Language Processing,17(2):354?365.J.
Lafferty, A. McCallum, and F. Pereira.
2001.
Con-ditional random fields: Probabilistic models for seg-menting and labeling sequence data.
ICML.J.
Morris and E. Fosler-Lussier.
2008.
Conditional ran-dom fields for integrating local discriminative classi-fiers.
IEEE Transactions on Acoustics, Speech, andLanguage Processing, 16(3):617?628.J.
Morris and E. Fosler-Lussier.
2009.
Crandem: Con-ditional random fields for word recognition.
Inter-speech.F.
Sha and F. Pereira.
2003.
Shallow parsing with condi-tional random fields.
NAACL.Xu Wang, Peng Xuan, and Wang Bingxi.
2004.
A gmm-based telephone channel classification for mandarinspeech recognition.
ICSP.S.
Young, G. Evermann, T. Hain, D. Kershaw, G. Moore,J.
Odell, D. Ollason, D. Povey, V. Valtchev, andP.
Woodland.
2002.
The HTK Book.
Cambridge Uni-versity Press.G.
Zweig and P. Nguyen.
2009.
A segmental crf ap-proach to large vocabulary continuous speech recogni-tion.
ASRU.728
