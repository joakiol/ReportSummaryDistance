Transformat iona l  Dec~npos?t~on zA Simple Descr ip t ion  of anAlgor i thm for  Transformat iona l  'Ana lys i s  of Engl ish  Sentences~Danuta Hi~Arav lndK.
Josh l?
Un ivers i ty  of PennsylvanlaABSTRACTIn this paper, we will present a ra~her simplified description o?
analgorithm for transformationalanalysls (decomposition) of Englishsentences, our purpose here is not to discuss the transformationaltheoryj the full details of the theoretical formulations of the algo-rlthmj or of the gran~ar.
Ratherj we will present a set of examplesof the decomposition and some discussion of them with the hope thatit will give enough insight into the capability of the algorlthm andindicate to some extent the power of transformational analysis.
?This work was carried out in the Transformations and Discourse AnalysisProjectj University of Pennsylvania, sponsored by the National ScienceFoundation.1.0 Here, we will present a rather simplified description of an algo-rithm for transformational analysis (decomposition) of English sentences.Our purpose here is not to discuss the transformational theory 3 the fulldetai ls  of the theoretical formulations of the algorlthm 3 or o f thegrammar W. Rather, we will present a set of examples of the decompositionand some discussion of them with the hope that it will give enough in-sight into the capability of the algorithm and indicate to some extentthe power of transformational analysis?I.i Transformations are certain relations among sets of sentences andin particular, it is possible to relate a given sentence to a set ofelementary sentences (kernel sentences) by means of transformations.The kernel sentence forms (for English) are defined as the string ofclass marks N ~ ~ followed by one of the kernel Object strings: ~, N,~ ,  ~P__~, __~, e~, D, A (m Noun; ~: ~ense/aux; ~: verb; ~: preposi-tion; D: adverb; ~: adjective; ~ : zero).
Thus John bou~h't'a book;Nar~ will come etc.
are kernel sentences.
Each transformation ischaracterized by certain permutations, deletions or additions of spe-cific class marks or constants.
In the resultant of a transformationone may look for s ubsequenceswhich remain~xg~n~ even when the re-sultant is subjected to further transformations.
The 5asic features ofthe algorithm area) stating the various invarlant sequences andb) formulating I) a grammar of such Invarlant sequences, 2) a corre~spondlng recognition procedure, and 3) a systematic procedure for com-puting the kernel sentences as well as other kernel-like sentences andthe corresponding transformational history.It should be emphasized tha t i t is not assumed and also not im-pl~ed in the algorithm that any kind of prior analysis (either strlnganalysis or constituent analysis) is requlred as a prere~uisltelforthe present algorithm.~Such a detailed description will appear later elsewhere.++,+ ,..+ ++...,/i/+\~1.2 Trans format ions  are  in i t ia l l y  de f ined  on kerne l  sentence  forms.Howeverj they work on cer ta in  other  sentence forms which are  not  kerne lsentence forms.
Thus a transformation is completely defined by firstdeflnlng it on a suitable kernel sentence form(s) and then extendlng?
the ~omaln  of the transformation to other "sentence forms.
This exte~.-slon which contains infinitely many sentence forms can be representedby+ first listing a finite number of sentence forms in the extension andall the remaining sentence forms in the extension are obtained by cer-tain recurslve rules (see the i-llsts in 1.3).1.3 A unan~.z, transformation transforms one sentence form into anothersentence form and a bi~nary transformation transforms a pair of sentenceforms into another sentence form.
Each unary transformation defined ona sentence form may be represented by a sequence of class marks consti-tuting another sentence form.
Most binary transformations can be de-fined as interruptions of certain unary transformation sequences atstated positions by certain other sequences of class marks.
These In-terruptlng sequences are not sentence forms but are deformatlons_-o~ sen-" - - - - - - - " - - ' se  ~ o~ <+tence  forms cor respond ing  to  the ~ sentence  form of the b ins ry  t rans -fo rmat ion .
For example,  John was deta ined  by the old woman decom~sesin to  woman deta ined  John and woman t be o ld w i th  a pass ive  t rans forma-t ion  on the f i r s t  kerne l  and a b inary  t rans format ion  on the sentenceJohn was deta ined  by the woman and the kerne l  sentence woman t be o ld .
~The sentence  form cor respond ing  to  the pass ive  t rans format ion ,N t be en V by  N i s  then  in ter rupted  by the sequence AN before  the las tAN i s  a de format ion  of the kerne l  sentence form N t be A symbo l .
- -which  i s  the second sentence  form of the b inary  t rans format ion .
Theresulting sentence form is thus N t be en V by A B,.
In the resultingsentence form the shared symbol N appears only once.
Such a symbolwhich two t rans format ion  sequences ?
hare (o r  on which t_hey over lap)be  ignore  here  the ar t i c le  th.._~e for  s imp l i c i ty .a.
2 --wlll be called a residue of one.sequence with respect to another.
2 Inaddition to the transformation sequences which are sentence forms, andthe interrupting sequences (deformed sentence forms) which correspond tomost binary transformations, there is yet another type of interruptingsequences (again deformed sentence forms) which correspond tonominal-izatlons.
For example consider: the book was written by Brown andJohn's travel to Italy was descrlbed by Mar~.
In the second sentencejthe kernel sentence John travelled to Italy is mappedonto the objectof Mary described before the resultant undergoes the same passive whichacted on Brown wrote the book giving the first sentence.
N's nV P N(John's travel to Italy) is a nominalizati0n which appears in many dlf-ferent transformations and carries in them the associated kernel intoone of the positions which could be occupied by a noun.
For eachtransformation sequence in each intersymbol position we llst all in-terrupting sequences (including both the second and the third kind ofsequences as dlscussedabove).
Of course, the interrupting sequenceshave their own interrupting sequences, etc.
These Intersymbol inter-rupting lists will be called i-lists.2.
A sketch of the algorithm2.0 As stated in i, in order to define the set of all transforms weneed a set Of sequences of class marks (or class mark-llke symbols)which has 3 subsets.1.
Sequences each of which corresponds to a sentence form (e.g.
thepassive sequence N t be en V by N);2.
Sequences each of which represents a deformed kernel-form and Isnot a sentence form, but when inserted between specified neigh-boring symbols of a sequence of the first set~ preserves thecharacter of the sentence form (e.g.
_~j en V N);3.
Sequences each of which represents a deformed kernel-form and is~he concept of the residue can be extended to shared sequences as wellas sequences which replace a given symbol in another sequence.
Theterm carrier is used in this context.
This device has been extensive-ly used in this algorithm.-3 -not a sentence form, but, when substituted for a symbol in a se-quence (of ~et I or 2 or 3), preserves the character of that se-quence (e.g.
er V or/L , n A of N).There are also rules for inserting sequences from the second setinto other sequences or into sequences of the third set, withoutchanging the character of e i ther .All insertion or replacement rules are stated in the interruption listsappearing between every pair of adjacent symbols of each sequence.Most of the sequences in the first set represent unary transforma-tions of kernel forms.
Many are extended (often by permitting thereplacement of certain symbols with selected sequences from the thirdset) to include analogous unary transforms of kernel-llke forms.The  second set of sequencesj together with the rules of their in-sertion in the sequences for unary transformations, account for mostof the binary transformations.
Other binary transformations are rep-resented by replacement in pairs of class marks in unary transformationsequences by members of the third sets most of which consist of nomln-a l i za t ions .An arb i t ra r i l y  long Eng l i sh  sentence  form can be seen as  composedo f  a f in i te  number o f  such sequences recurs tve ly  embedded in  oneanother .2 .1  Cor respond ing  to  the  above three  subsets  o f  sequences and the i rmutua l  embedding ru les ,  we recogn ize  three  sets  of  s t r ings .
Eachs t r ing  i s  a program for  compar ing one o f  the sequences w i th  a por t iono f  the  ana lyzed  sentence  form of  the data .
The program i s  equippedto  permi t  in ter rupt ion  by o ther  such programs accord ing  to  the  i - l i s t so f  the  sequence.
Each s t r ing ,  when ent i re ly  matched by a segment Ofdata ,  rep laces  that  segment with  the  car r ie r  o f  the s t r ing .
The car -r ie r  is sometimes null.
In strings from the second set it is usuallythe residue of the binary insert (e.g.
the center symbol of a nounphrase: N of AN, o f~,etc . )
.
In strings from the  third setthe carrier is a class-mark-llke symbol which, by replaclng a class-mark in a formderlved from a kernel form I extends it to one simi-- -4  --l a r ly  derived from a kerne l - l l ke  form.
Let the car r ie r  be~\[nV~\] for  anoun phrase bu i l t  around an nV.
The extended passive form:N\ [or~\ [nV\ ] \ ]  t be en V by N represents  the form of the sentence John 'st rave l  to I ta ly  was descr ibed by Haryas  soon as the car r ie r  of thestr~ng replaces in the data the nomlr~ !
segment John's travel to Italy.The carrier from all strings in the first set is s, a symbol of a well-formed sentence.The program'of eachl string, whose sequence is a deformed (Or trans-forme~) kernel or kernel-like form, reconstructs that form for decom-position and attaches ?o it a labe___~l descrlptive of the deformation (ortransformation).
The result of a decomposition is a set of kernel orkernel-llke sentences with labels.
Some of the kernel sentences are /incomplete and have blanks in them because a t ransformat ion may de t ~ .
.
.
.
.
.
.elements.
Some kerne l - l l ke  sentences may contain,  instead of  a wo/rd)a c lass -mark- l lke  symbol (e .g ,~)  with a re fe rence .
to  aprev lous  com-)ponent of the decomposit ion.
I f  that  previous component is  a kernelsentence (with or without b lanks) ,  then the label  (descr ib l r~ the de-formation) with the kernel-llke form (containing the reference) withits label, together constitute a description of the transformation un-dergone by the component kernel sentence.
If the previous componentitself is a kernel-llke sentence with a reference in turn to anothercomponent, both'kernel-llke sentences and all three labeis constitutethe description of the transformatlonundergone by the c~,nponent ker-nel sentence ultimately referred to s e tc .If the symbol x appears, instead of a word, in a kernel or ker'nel-llke sentence, it replaces a regular noun there.
It is intro-duced in the sentence as a carrier from a nominallzation such as ateacher of Latln, .the driving instructor, etc.
The same x must ap-pear in two or more sentences of the decomposition ?
(onewhere thenominal stands for a noun, and one in the sentence of whlch the nom-inallzatlon is a deformation, e.g.
x - teach Latin).
Which x's re-quire identical substitutions is discoverable, because each x has ina sharp bracket (< >) the names of every prevlous llne in which thesame x appeared, often no actual substltutionls posslble and the xserves only to identlfy ~ with each other, two or more blanks in differ-ent components.
The substitution of the noun replacing N for x in linesaj bj .
.
.
d is implied when one kernel-llke component has the formI t be  x ~/a~ b .
.
.
d> .2.2 The three  sets  of s t r ings  (programs) const i tu te  the major por t ionof  granmmtlcal mater ia l  in the a lgor i thm.
Another body o?
such mater ia li s  the d lc t lonar~.
?The d ic t ionary  assoc ia tes  to  each Engl ish word a symbol represent ingthe wordts grannnatlcal c lass~ together  with markers of cer ta in  add i t ion -a l  character i s t i cs  the word may revea l  by res t r i c t ing  i t s  environment inthe sentence.
Some words may occur in more than one ro le  and have there -fo re  severa l  equ lva lents  in thed ic t lonary .
(e .g .
the word labor  shouldbe g iven four d i f fe rent  c lass  marks: p resent  tense Vs V(untensed verb) j(nomlna l l zat lon  des lgnat lngthe  act iv i ty  of labor ing)~ er 'V  (nominal-Izatlon designating the actor(s), possibly laborers in aggregate)).
:alThe d ic t ionary  fo r  Transformation^Crannnar must car ry  fa r  more de-ta i l s  than i s  needed for  the Str ing Analys is  a lone.
Thus for  examplethe t rans format iona l  ana lys i s  must be able to  d iscover  in Johnts s leepnot  only a nouh phrase~ but a l so  the incomplete kernel  sentence John-s leep ~ which under l ies  each t rans format ion  contain ing such a nounphrase .
Hence?
the c lass  marks: nV (s leep) j  ~ (shar ing)  vA (brav-e y), (teacher), eeV (e loyee), (brotherho L aV (helpful)and severa l  o thers .~:AV-entrY in the St r ing  Analys is  d ic t ionary  contains in format ion/about: the L~nd of ob jec ts  requi red by the verb V. An nV may requ i reob jec ts  d i f fe r /~t  from i t s  V and th i s  must be ind icated (e .g .
th~at tacked  the enemy vs .
they  made an a t tack  " on the enemy).Noun phrases l i ke  n V, IngV, etc .
can occur in p lace o?
a sen-tence ob ject  or a sub ject  of a sentence but  only when it i s  organized' ,  \ .around a verb requ i r ing  such sub jec ts  or ob Jec ts j  and such, verbs aremarked accord ing ly  in the d ic t ionary .The sub ject  and ob ject  res t r i c t ions  for  a verb or a verb - re la ted-6 -wordare recorded in pairs~because they are not mutually independent.
(0-" is the label for a subject (Z) requirement; _.~_~for an object (~)requirement of a tensed or untensed verb and some in_~ occurrences;t~nV labels an object requirement of nV-nominallzatlonj ~ ingV thoseof an i~  V-nomlnalizatlonl etc.
When needed j~ I is distinguishedfrom ~ 2 (which usually is the same as the corresponding ~-~) to markthe form assumed by the object when it precedes the verb or verb re-lated word (compare for instance house construction with constructionof house where c~ nVl (the same as o~ ) is N, while ~ nV2 (the sameas nV ) I sP  \[of\] N).
)The analysis is preceded by a replacement of the Words in thesentence by corresponding entries in the dictionary.2.3 The process of analyzing a sentence begins in postulatlng (inturn) all those strings in the grammar which may occur at the beg lnn lngP- -q~o/ /~of a sentence (and whose initial symbol is the s~me as the first symbolin the data).
(See i I of #30).
Each verified postulate forces other?
postulates as its consequences I until the termlnal period of the sen-tence is found which is consistent with a hypothesis.
It is qultel ike ly  that an analysis will produce more than one correct reading ofa sentencej because structural ambiguity is even more frequent intransformational grammar than it is in the mere s~ring analysis.-7 -3.
Examples of decompositionFour examples of decomposition obtained by the algorithm follow.These examples are intended to exhibit the power of the algorithm.It is posslble I without changing the algorithm I to increase thepower and depth of the analysis by incorporating more details abouttransformations as they become available by adding either new trans-formation sequences or adding new classes and new co-occurencerestrlc-tlons in the dictionary or both.Among the various issues which are nowrecelvlng further atten-tlon, some are as follows: a) a better characterization of nF-nounsand the underlylng kernel sentences in terms of which the modifierscan  he explained (e.g.
school prlnclpa~ (example 3), French teacher;~ueen~ etc); b) the relation of classifier nouns to each otherand their kernel positions with respect to'thelr modifiers (e.g.
organ~~e~?erI c  chemistryj helpful t r ip,  friendly ~e~j etc.)
;  ?)
precise relatlonof constants (e.g.
hi__ss~ both in example h) or classifier nouns witha definite artlcle to other nouns or phrases for which they are a re -placement.Examples: The first column lists the kernel sentences or kernel-llkesentences (or intermediate resultants).
The second column glvestherest of the transformational history.
Here the names as stated arepartial in the sense that the corresponding strings do not alwayscorrespond to complete transformatlal sequences as discussed previously.IDText: ?
The fact that John is aT N that N pres.be\[3\] T whis 1lie here unbearable.R'B nV D aV?
stranger makesN present V\[3\] I.~I indicates here 3rd person.l o2.3.Decomposition:Kernel or Kernel- transformationllke sentences ~(partlal .
@mes) carrierJohn pres.be stranger (a) container 2 noun: N w that  S Nw.
~/l>He-  l ive here; N~'-nomlnaliztion; g's n~ "1 "N <'2>- cannot bear~(2> ad Ject lv lzat lon  : aV ~ ~3>N < l>pres, make 'N< 2>AC3> container: N V NA Sw w-2.Text: Our algebra teacherRls  N erVwas requested by the schoolpast be \[3\] enV by T Nprlnclpal to interviewnF Co VDecomposition:Kernel or Kernel-llke sentencesa woman candidate from Swarthmore.T N N P Ntransformations(partial .names) carrierfirst reading:1. x - teach algebra2.
We- have x~l>3.
x - heads 3 school~.
woman-'V P candidate (a) app app-a(V pp= be; Papp = ~)5. candldate-be from Swarthmore noun, right modified: ?candidate"i P Na6.
x <1,27  - interview .
.-'~ passive of container: Scand ldate<~,5)~ N t VwN infinitive7- x (3~pas~ request x \[ <1,2  (6> - )x-nomlnallzation: GerV x ~i>?
left modified noun: N's N x <1.,2>x-nominallzation: NnF x 43> ,.,compound noun: NIN 2 candldate<~2k%oughly,  container forms are sentence forms In which 1) there is averb (Vw) requir ing a sentent la l  subject or a sentent la l  object orboth or 2) there is  a noun (N w) or fidJectlve (Aw) requir ing sen-tent la l  complements.~eads  is a V for nF pr inc ipa l  as found in d ic t ionary .
- -  appropriate-9  - :!Kernel or Kernel-llke sentencessecond reading:I.2.3.transformations.
(par t ia l  names)x - teach us algebrax - head schoolwoman - V P candidate (a) compound ?
noun: app app4.
candidate-be from Swarthmore noun I right mod'ifled: NIPN 2~.
x~J> - interview candidate ~passlve ofcon-  talner:)Jlnfinitlve6.
x<2>past  request  x <1%2< ,?
?Text:x-nomlnallzation: f l e rvx-nominalization: NnF5N2Accident insurance of an employee byN nV P T eeV Pprotects  both.present, V :  \[3\] QDecomposition:Kernel or Kernel-~llke sentencesfirst reading:I.
- - employ x2.
x - employ him3.
x <2>-  insure x < l>(an)P accident .app~.
N ~3~ present protect bothhis  employerR's erVsecond reading:1.
- - employ x2.
x - .employ -3.  he  - ~ve  x /~2>h .
x <2> - insure x <OCin)P accident app~.
N ~h> present protect bothNote:heText:carrierx <l>x ~2>cand idate<3>candidate z3, >Stransformation(part la lnames) carrierx-nomlnallzation: eeV x ~I>x-nomlnalizati0n: erV .
.x <2>~-nomlnallzatlon: nV N\ [nV+~?
?z\] <3)container: N t V N W S Wx-nomlnallzatlon: eeVx-nomlnalizatlon: erVleft modified noun:?
N'sN 2~-nominallzatlon: nVcontainer: N t V NW.
<l>x <2>X<2,3 >N\[nV+ ~?z\] <3>sThe analysis would reach even deeper if the words ~hls and ~b?thwere treated as reference words leading to a substltutlonj e.g.of x <I.__.~> for he, x ~ I> and x <2> for both.Crop sharing between the tenant and the land ownerN Ing V P T N and T N errQ may rep lace N.-10 -Ispresent be \[3\] Torganized labor.enV erVDecomposition:Kernel or Kernel-like sentencesan economic arrangement unsatisfactory toaN nV aV PI.
X - own land2.
tenant (the) and x ~l>(the)-share crop3- - - arrange -; P economy apph.
x - labor - x-nominallzatlon: erV~.
- - organize x ~h> left modified noun:enVN6.
~<3> -not satlsfy x <~,5> q right modlfled:~aV7- N<2> present be'N- ~3,6~ (an) container: N'~t be'Ntransformations~(partlal names) carrierx-nomlnallzatlon: erV ..x ~ I>"~-nomlnallzatlon: Ingv N\[ingVd-?
~~2>N"~-- nomlna llzat ion: nV N\[nv\]~3>x< ~,5>I Sk.
Anil lustratiQn of the procedureExample 5 John is a good story tellerTh is  example illustrates the process of analysis in some detail.Because of space limitations for this paper a rather simple structurehad to be chosen for this purpose.
A short dictionary of the words inthe sentence has been prepared and also a small set of grammar stringsin provided for this illustration.
Both were greatly simplified sothat rich grammatical material will not obscure the demonstratl6n ofthe choice of hypotheses, their verification or rejection, the use ofthe carrler~ changes of levels in analysis and the exploration of al-ternative readings.The analysis always begins with the strlng ~30 postulated.
Adecomposition ends I when the program associated with thls~trlng isfinished.
All possible sentence beginnings are included in i I of ~30.--After- t-hee-nd of--~30-aiternatfve-decompositlons are sought.When a new string is postulated on the basis of an i-llst of.
another strlngj the verification of thenew string takes place in thenext level of a push-down memory~ so that the state of computation ofthe suspended string is not affected.Whenever two or more alternative paths open up for the analy~s~i~sjeach must be pursuedto a successful completion or until failure occurs.
(The analysis must produce every possible decomposition of a structur-ally ambiguous sentence).
In our analyslsj different paths are pursued ~- 11  -serially.
Every time an inspection of i-lists allows more than onehypothesls~ .one is chosen~ while a list of the remaining ones to-gether with all relevant positions of the.memory goes on top ofanother push-down storage.
The contents of that ?storage is examined .after the end of the chosen path.
The analysis ends'after all pos-slble paths have been explored and thlsstorage is empty.
~n theexample of analysis given herej we markbypassed open branches byasterisks on the left margin and their resumption by slmilar aster~Isks encirc led.
~Dict ionary used in Example ~.John - N \[proper, hu~anj singular\] .Is present be \[3~; ~r-: N\[or x\];?~= N{A/PN/D.o-: S\[nV/inO\]; to.
~ ,  ~,  ~\[nV/ingv\] etc.\]a - T\[a\]good - A \[A-ly =well\]story - Ntel ler-  erV \ [&  : human, count; ~J=~erVl :  N/N\[nV\]/~;~JerV2;PN\[or x or N: nV .~Grammar Str ings used in example 5-Nominal str ings (each gives a noun-l ike carr ier) :I?
T\[ the/a/an\]  l l  i N\[or x; o r~:  nV/ingV/nA/nl~\] 2-Dame=kerne l :car r ie r :  N\[the ar t i c le \ ]  (as matched)2.
~x i .
\ [o rx \ ]i I 2,~,5 ,  "i 2 -name: .
l e f t  modified noun: ANkernel :  N - be Acarrier: N< address of kerne l>~eslgnatesth l rd person,- ZZ~..eI 0 -I i -N\[ object \]i I -.~  -?
i t .
# x \ ] i2  A N\[nV/ingV; ori 1 .3,, i 2 -name: left modified nominal: A N \[or x\]addition to kernel of'N : ; A-ly (Alas matched)car r ie r :  ~ ~as matched from data)i Ierri I -name: x-nomlnallzatlonkernel: x-V- ?carrier: x \[subclasses required from subject of V\]~addressof kernel>i I i 2erVname: x-nominal izat ionkernel: x- V N '(N,V as matchedfromdata),carrier: x \[subclasses required from subject .of V\] ~addressof.
kernel>i 1 , i 2nV?
nvi 1 -?
t 2 -name:  N-nomlnallzatlon: nV\[+~ \]kerne I: f/n "car r ie r :  ~n; \ ]  v <a~dress of kernel~)Object Str ings:.\[or x\] i:I I - ?name- objectcontr ibut ion to kernel in car r ie rcarrier: ~\[N\]il N\[or x\] Pi I -i 2 1,2,~,9i s -(as matched from data)(N  as matched in data)i 2 i 3N\[or x\]w 13 -name - objectcontribution to kernel in carriercarrier:?
~\[N P N\]=.
(N P N as matched in data)Sentence Strings20 - N t V gi I -i 2 -i 3 - 10,11,1,~,3,~,~,6% -21-DaJme:kernel:carrier: S < address of kernel>11 12 13 ~- i~N t be  Nt 1 -i 2 -- 1,3,6name: ~containing "be" : N is Nkernel: N t be Ncarrier: S 4 address of kernel>identity of kernel form: N t VN t V ~ (as found in data)(as matched from data)Monitor Stringi I i 2 i B30 - " S "i I 1,2,3,~,~,6,20,21i 2 -i 3 -Zllustratlon of the process of analysis:Data:.
N\[John\] pres.V\[3,be\] T\[a\] A\[good\] N\[story\] erV\[teller\].~30:= .?
S .
(levell)S # Ni I of 30 allows the following strilgs beginning with N to interupt 30here: ~,20.
Try 20, mark ~ for the branch opening with 9 on level 2.W Data: N\[John\] pres V\[3,be\] Tie\] A\[good\] N\[story\] er V\[teller\]~20 : N tV ~ (level 2)N=N\[John\]t =presentV=V b_e accepts Joh____nn as subject.
For a human subject, the ob-Ject cannot be~ 6(in this simplified grammar).
The verb b~e- 14  -rejects object form of ~Ii.R ~ T Among the remaining strings of i 3only 1 starts by T.Data: T\[a\] A\[good\] N\[story\]~i  : T NT~TN~Af I of i has 2,3 beginning wlthA.bypassed 3.of 2o (1,2,3,a,%10)erV\ [ te l le r \ ] .
( level  3)Try 2, mark ~.__~ fo rData: A\[goodJ N\[story\] er V\[teller\].
(level ~).A---A~/  N=N note:i I of 2 has string 5 beginning withN.Mark ~-~ for the bypassed branch,end 2. kernel I: story-be good.
Resume I.Data: ~\[story\] ~l> erV\[tener\].
(level 3)continue ~I$ /~ N=N note:i I of I has string ~ beginning with N. Markopen branch ~-~.
end 1.
Resume 20.Data: N\[story\] < 1 > (a) er y\[teller\].
(level 2)contfnue~20of the str ings from i 3 allowed by object requirement of theverb b ej ~ and I0 begin wfth N. Try 10j mark ___ ~ for by-passed ~.D ta:  \[story\] (a) err\[teller\].
(level 3)#IO: NN= Nend i0.
Resume 20.Data: ~ \[N\[Story\]< I> (a) J erV\[teUer\].
(level 2)contlnue~20.~=~ \[N\[storyL<l> (a)\]End 20.
Ke~del 2: John pres.
be story < I> (a) .
Resume 30.D.ta= s crY\[teller> ( evel l)continue ~3oS =S-~erThere is no string in f 2 of 30 which begins with er.
Resume the near-est open branch: #~ at level 3- Erase mark ~ (kernel 2 is alsoerased)~ Data: N\[story\] ~ I> (a) erV\[teller\].
(level 3)~5 : N erVN=Ner ?
erV = V story ls a proper object f~r teller- 15 -End ~.
Ker~e~ 2: x - te l l  story <I> (a).
Resume 20./Data: x < 2> .
(level 2)contlnue~20The only string beglnning with x among those of i 3 allowed asobject of be is I0Data:  x < 27 .
( leve l  3)~I0: N\[or x\]?
N ~xend of I0.
Resume ~20.Data: ~\[x <2>\ ]cont lnue~0.= ~ \[x\[humanj ct., slngular\] < 2>\].
Howeverj the verb be witha count-noun subject requires from a noun object an ar-ticle or an artlcle-replacer.
This lackingj the currentbranch fails, the branch marked ~ is reopened with #9onlevel  ~.
(Kernel 2 of the fai-~ng branch is erased.
)Erase ~+~-~.Data: N\[story\] erV\[teller\].
(level h)~ : N erVN = Ner  = erV= V story is appropriate object for teller.End ~.
Kernel 2: x - tell story < I~'.
Resume I.Data: x < 2 >.
(levei 3)continue ~iN=xend 1.
Resume 20.Data:continue ~30S=SEnd 30Prin t output:Data: xcontinue~xonly  oneData:~I0  :< 2>(a) .
(level 2)20string beginn ing by x can interrupt here; i t  is I0.CLevel 3)~\[or x\]N~ Xend IO.
Resume 20Data: fi\[x < 2> (a)\] .
(level 2)contlnue~20fl = fiend 20.
Kernel 3: John pres.
be x ~ 2> (a).S .--=-- (level I)Resume 30.1.  s tory  - be good ( le f t  modi f ied noun)2.  x - te l l  s to ry  < 1 > \ (x -nomfna l f za t fon :  flerV)3.
John present be x < 2> (a) (identity of extended NtVN)"- 16  -Are there any branches open?Erase ~ek.Yes ,  ~-~ at level ~.
#~ will be tried.- Data: N\[story\] erV\[teller\].
(level 5)?
~5 : N erVN=Ner = erV = V ~ i s  appropr ia te  ob ject  of te l le rend ~.
.Kernel la :  x - te l l  s to ry .
Resume 2.Data: xX l>.
(level~)continue -~N-xEnd 2.
Kernel 2a: x ~ I~-  be good.
Resume I.Data:continue ~i#N----xend I.
Resume 20.
(level 3)Data: x (1 ,2> (a).
(l.~el 2)cont inueThe on!y s t r ing  al lowed to in ter rupt  here i s  10.Data: x ~1,2~ (a).
( leve l  3)~Io: N\[orx\]N=xEnd 10.
Resume 20.End 20.
Kernel 3a: John pres.
be X ~I t2~Data: s ~3>.
(level l)cont inue 30S~Se- -  ?end 30.(a).
Resume 30.print output: I. x - tell story (x-nomfnallzation: ~erV)2. x ~ i> - be good (left modifier noun)3.
John pres.
be x ~1,2> (a) (identity of extendedAre there  any branches open?
Yes, ~ l~ at  level ~.
(To abbreviate, we will,just say t~-t--this branch will be very much llkethe last one, except that, due to the difference between strings 2 and3~ i t  will give the output:- 17  -1. x- tell story; well (x-nominalication: ~erV;left modified nominal)2.
John pres.
be x < I> (a) (identity of extendedNtVN)The last open branch, marked ~ fails immediately.).2.
!References3oshij A. K., Hi~1D.j "String representation of transformationsand a decomposition procedure"~ Part I and Part IIj Transforma-tions and Discourse Analysis Project PaperIUnlverslty ofPennsylvania; Dec. 1965.3oshi s A. K.~ "Transformational analysis by computer with some:iappllcation~'j Presented at the National Institute of HealthSeminar on Computational Linguistics, Bethesda, Oct. 1966~:(To be published).
