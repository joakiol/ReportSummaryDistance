Acquiring Synonyms from MonolingualComparable TextsMitsuo Shimohata1 and Eiichiro Sumita21 Oki Electric Industry Co., Ltd.,2-5-7, Honmachi, Chuo-ku, Osaka City, Japanshimohata363@oki.com2 ATR Spoken Language Translation Research Laboratories,2-2-2 Hikaridai, Keihanna Science City, Kyoto, Japaneiichiro.sumita@atr.jpAbstract.
This paper presents a method for acquiring synonyms frommonolingual comparable text (MCT).
MCT denotes a set of monolin-gual texts whose contents are similar and can be obtained automatically.Our acquisition method takes advantage of a characteristic of MCT thatincluded words and their relations are confined.
Our method uses con-textual information of surrounding one word on each side of the targetwords.
To improve acquisition precision, prevention of outside appear-ance is used.
This method has advantages in that it requires only part-of-speech information and it can acquire infrequent synonyms.
We evaluatedour method with two kinds of news article data: sentence-aligned par-allel texts and document-aligned comparable texts.
When applying theformer data, our method acquires synonym pairs with 70.0% precision.Re-evaluation of incorrect word pairs with source texts indicates thatthe method captures the appropriate parts of source texts with 89.5%precision.
When applying the latter data, acquisition precision reaches76.0% in English and 76.3% in Japanese.1 IntroductionThere is a great number of synonyms, which denote a set of words sharing thesame meaning, in any natural language.
This variety among synonyms causesdifficulty in natural language processing applications, such as information re-trieval and automatic summarization, because it reduces the coverage of lexicalknowledge.
Although many manually constructed synonym resources, such asWordNet [4] and Roget?s Thesaurus [12], are available, it is widely recognizedthat these knowledge resources provide only a small coverage of technical termsand cannot keep up with newly coined words.We propose a method to acquire synonyms from monolingual comparabletext (MCT).
MCT denotes sets of different texts1 that share similar contents.MCT are appropriate for synonym acquisition because they share not only many1 In this paper, ?text?
can denote various text chunks, such as documents, articles,and sentences.R.
Dale et al (Eds.
): IJCNLP 2005, LNAI 3651, pp.
233?244, 2005.c?
Springer-Verlag Berlin Heidelberg 2005234 M. Shimohata and E. Sumitasynonymous words but also the relations between the words in a each text.Automatic MCT construction can be performed in practice through state-of-the-art clustering techniques [2].
News articles are especially favorable for textclustering since they have both titles and date of publication.Synonym acquisition is based on a distributional hypothesis that words withsimilar meanings tend to appear in similar contexts [5].
In this work, we adoptloose contextual information that considers only the surrounding one word fromeach side of the target words.
This narrow condition enables extraction fromsource texts2 that have different structures.
In addition, we use another con-straint, prevention of outside appearance, which reduces improper extraction bylooking over outside places of other texts.
This constraint eliminates many non-synonyms having the same surrounding words by chance.
Since our method doesnot cut off acquired synonyms by frequency, synonyms that appear only oncecan be captured.In this paper, we describe related work in Sect.
2.
Then, we present our acqui-sition method in Sect.
3 and describe its evaluation in Sect.
4.
In the experiment,we provide a detailed analysis of our method using monolingual parallel texts.Following that, we explain an experiment on automatically constructed MCTdata of news articles, and conclude in Sect.
52 Related WorkWord Clustering from Non-comparable TextThere have been many studies on computing similarities between words basedon their distributional similarity [6,11,7].
The basic idea of the technique is thatwords sharing a similar characteristic with other entities form a single cluster[9,7].
A characteristic can be determined from relations with other entities, suchas document frequency, co-occurrence with other words, and adjectives depend-ing on target nouns.However, this approach has shortcomings in obtaining synonyms.
First, wordsclustered by this approach involve not only synonyms but also many near-synonyms, hypernyms, and antonyms.
It is difficult to distinguish synonymsfrom other related words [8].
Second, words to be clustered need to have highfrequencies to determine similarity, therefore, words appearing only a few timesare outside the scope of this approach.
These shortcomings are greatly reducedwith synonym acquisition from MCT owing to its characteristics.Lexical Paraphrase Extraction from MCTHere, we draw comparisons with works sharing the same conditions for acquiringsynonyms (lexical paraphrases) from MCT.
Barzilay et al [1] shared the sameconditions in that their extraction relies on local context.
The difference is that2 We call texts that yield synonyms as ?source texts.
?Acquiring Synonyms from Monolingual Comparable Texts 235their method introduces a refinement of contextual conditions for additionalimprovement, while our method introduces two non-contextual conditions.Pang et al [10] built word lattices from MCT, where different word pathsthat share the same start nodes and end nodes represent paraphrases.
Latticesare formed by top-down merging based on structural information.
Their methodhas a remarkable advantage in that synonyms do not need to be surroundedwith the same words.
On the other hand, their method is not applicable tostructurally different MCTs.Shimohata et al [13] extracted lexical paraphrases based on the substitutionoperation of edit operations.
Text pairs having more than three edit distancesare excluded from extraction.
Therefore, their method considers sentential wordordering.
Our findings, however, suggest that local contextual information isreliable enough for extracting synonyms.3 Synonym AcquisitionSynonym extraction relies on word pairs that satisfy the following three con-straints: (1) agreement of context words; (2) prevention of outside appearance;and (3) POS agreement.
Details of these constraints are described in the follow-ing sections.
Then, we describe refinement of the extracted noun synonyms inSect.
3.4.3.1 Agreement of Context WordsSynonyms in MCTs are considered to have the same context since they generallyshare the same role.
Therefore, agreement of surrounding context is a key featurefor synonym extraction.
We define contextual information as surrounding oneword on each side of the target words.
This minimum contextual constraintpermits extraction from MCT having different sentence structures.Figure 1 shows two texts that have different structures.
From this textpair, we can obtain the following two word pairs WP-1 and WP-2 with con-text words (synonym parts are written in bold).
These two word pairs placedin different parts would be missed if we used a broader range for contextualinformation.Sentence 1 The    severely    wounded    man    was    later    rescued    by    an    armored    personnel    carrier.Troops    arived    in    an    armored    troop    carrier    and    saved    the    seriously    wounded    man.Sentence 2Fig.
1.
Extracting Synonyms with Context Words236 M. Shimohata and E. SumitaWP-1 ?the severely wounded?
?
?the seriously wounded?WP-2 ?armored personnel carrier?
?
?armored troop carrier?Words are dealt with based on their appearance, namely, by preserving theircapitalization and inflection.
Special symbols representing ?Start-of-Sentence?and ?End-of-Sentence?
are attached to sentences.
Any contextual words are ac-cepted, but cases in which the surrounding words are both punctuation marksand parentheses/brackets are disregarded.3.2 Prevention of Outside AppearancePrevention of outside appearance is a constraint based on characteristics of MCT.It filters incorrect word pairs by looking into outside of synonym words andcontext words in the other text (we call this outside region the ?outside part.?
).This constraint is based on the assumption that an identical context word ?either a noun, verb, adjective, or adverb ?
appears only once in a text.
Actually,our investigation of English texts in the Multiple-Translation Chinese Corpusdata (MTCC data described in Sect.
4.1) proves that 95.2% of either nouns,verbs, adjectives, or adverbs follow this assumption.This constraint eliminates word pairs that have a word satisfying the follow-ing two constraints.C1 The word appears in the outside part of the other text.C2 The word does not appear in the synonym part of the other text.The constraint C1 means that the word in the outside part of the other textis considered as a correspondent word, and a captured word is unlikely to becorresponding.
In other words, appearance of the word itself is more reliablethan local context coincidence.
The constraint C2 means that if the word isincluded in the synonym part of the other text, this word pair is considered tocapture a corresponding word independent of the outside part.Figure 2 illustrates an example of outside appearance.
From S1 and S2, theword pair ?Monetary Union?
and ?Finance Minister Engoran?
can be extracted.However, the word ?Monetary?
in S1 does appear in the synonym part of S2 butdoes appear in another part of S2.
This word pair is eliminated due to outsideappearance.
However, if the word appears in the synonym part of S2, it remainsindependent of the outside part.This constraint is a strong filtering tool for reducing incorrect extraction, al-though it inevitably involves elimination of appropriate word pairs.
When apply-ing this constraint to the MTCC data (described in Sect.
4.1), this filtering reducesacquired noun pairs from 9,668 to 2,942 (reduced to 30.4% of non-filtered pairs).3.3 POS AgreementWord pairs to be extracted should have the same POS.
This is a natural con-straint since synonyms described in ordinary dictionaries share the same POS.In addition, we focus our target synonym on content words such as nouns, verbs,adjectives, and adverbs.
A definition of each POS is given below.Acquiring Synonyms from Monolingual Comparable Texts 237Outside  Appearance... the member countries of Economic  and   Monetary Union   of  Western Africa ...Economy  and   Finance Minister Engoran   of  Cote d?Ivoiresaid that the member of countries of the West Afcican Economic and Monetary UnionWord PairS1S2Fig.
2.
Text Pair Having Outside AppearanceNouns Consist of a noun sequence.
Length of sequences is not limited.Verbs Consist of one verb.Adjectives Consist of one adjective.Adverbs Consist of one adverb.The word pair WP-1 satisfies the constraint for adverbs, and WP-2 satisfiesthat for nouns.
The MCT in Fig.
1 can produce the word pair ?the severelywounded man?
and ?the seriously wounded man.?
This word pair is elimi-nated because the synonym part consists of an adverb and an adjective and doesnot satisfy the constraint.3.4 Refinement of Noun Synonym PairsAcquired noun pairs require two refinement processes, incorporating contextwords and eliminating synonyms that are subsets of others, since nouns areallowed to contain more than one word.After the extraction process, we can obtain noun pairs with their surroundingcontext words.
If these context words are considered to be a part of compoundnouns, they are incorporated into the synonym part.
A context word attached tothe front of the synonym part is incorporated if it is either a noun or an adjective.One attached to the back of the synonym part is incorporated if it is a noun.Thus, when the noun pair ?air strike operation?
= ?air attack operation?
isextracted, both context words remain since they are nouns.Next, a noun pair included in another noun pair is deleted since the shorternoun pair is considered a part of the longer noun pair.
If the following noun pairsNoun-1 and Noun-2 are extracted3, Noun-1 is deleted by this process.Noun-1 ?British High?
?
?British Supreme?Noun-2 ?British High Court?
?
?British Supreme Court?3 All words in these expressions belong to ?proper noun, singular?
(represented asNNP in the Penn Treebank manner).238 M. Shimohata and E. Sumita4 ExperimentWe used two types of MCT data: sentence-aligned parallel texts (MTCC) anddocument-aligned comparable texts (Google News).
Both data are based on newsarticles, and their volumes are relatively small.
The former data are used fordetailed analysis and the latter data are employed to show practical performance.The Google News data consists of both English and Japanese versions.
Table 1shows the statistics of the experimental data, with the major difference betweenMTCC and Google News data being ?Words per Text.?
The text length ofGoogle News data is much longer than MTCC data since texts in Google Newsdata denote a whole article whereas those in MTCC data denote a sentence.These two English data and the one Japanese data originally contained plaintext data.
We applied the Charniak parser [3] to the English data and Chasen4to the Japanese data to obtain POS information.
It should be noted that we donot use any information except that of POS from parsed results.Table 1.
Statistics of Three Experimental DataMTCC Google News (E) Google News (J)Text Clusters 993 61 88Texts 10,655 394 417Words 302,474 176,482 127,482Texts per Cluster (Mean) 10.7 6.5 4.7Words per Text (Mean) 28.4 447.9 305.7(Variance) 364.5 64591.3 55495.7MTCC: Multiple-reference Data from LDC4.1 Multiple-Translation Chinese CorpusThe Linguistic Data Consortium (LDC) releases several multiple-translation cor-pora to support the development of automatic means for evaluating translationquality.
The Multiple-Translation Chinese Corpus5 (MTCC) is one of those, andit contains 105 news stories and 993 sentences selected from three sources ofjournalistic Mandarin Chinese text.
Each Chinese sentence was independentlytranslated into 11 English sentences by translation teams.
We applied the Char-niak parser to these 10,923 translations and obtained 10,655 parsed results.
Thisdata comprises high-quality comparable texts, namely parallel texts.We applied our method to the data and obtained 2,952 noun pairs, 887 verbpairs, 311 adjective pairs, and 92 adverb pairs.
Samples of acquired synonymsare shown in Appendix A.
Roughly speaking, the number of acquired word pairsfor each POS is proportional to the frequency of occurrence for that POS in theMTCC data.4 http://chasen.naist.jp/hiki/ChaSen/5 Linguistic Data Consortium (LDC) Catalog Number LDC2002T01.Acquiring Synonyms from Monolingual Comparable Texts 239Extracted word pairs were manually evaluated by two methods: evaluationwith source texts and without source texts.
First, an evaluator judged whetherextracted word pairs were synonyms or not without source texts.
If two wordscould be considered synonyms in many cases, they were marked ?yes,?
otherwise?no.?
The criterion for judgment conformed to that of ordinary dictionaries, i.e.,the evaluator judges whether given a word pair would be described as a synonymby an ordinary dictionary.
Therefore, word pairs heavily influenced by the sourcetexts are judged as ?no,?
since these word pairs are not synonymous in generalsituations.
Morphological difference (e.g.
singular/plural in nouns) is not takeninto consideration.Next, word pairs evaluated as non-synonyms were re-evaluated with theirsource texts.
This evaluation is commonly used in paraphrase evaluation [1,10].When word pairs could be considered to have the same meaning for the givensentence pair, the evaluator marked ?yes,?
otherwise ?no.?
This evaluation clar-ifies the ratio of the these two causes of incorrect acquisition.1.
The method captures proper places in sentences from source texts, but thesemantic difference between words in this place pair exceeds the range ofsynonyms.2.
The method captures improper places in sentences from source texts thathave the same local context by chance.An example of evaluation with source texts and without source texts is shownin Fig.
3.
Samples of this evaluation are also shown in Appendix A.The precision, the ratio of ?yes?
to the total, on MTCC data by each POS isshown in Fig.
4, where the All POS precision with source texts reaches 89.5%.This result suggests that our method could capture proper places of MCT pairswith this level of precision.
However, this precision falls to 70.0% without sourcetexts that represents synonym acquisition precision.
This is because some of theextracted word pairs have a hypernymous relationship or have great influenceon context in source texts.Acquired word pairs include those occurring only once since our method doesnot cut off according to word frequency.
The amount of those occurring only onceaccounts for 88.8% of the total.
This feature is advantageous for acquiring propernouns; acquired word pairs including proper nouns account for 63.9% of the totalnoun pairs.Word pair judged as non-synonymSynonym-1 Muslim robeSynonym-2 sarongSource Text PairSentence-1 A resident named Daxiyate wears a turban and Muslim robe.Sentence-2 A citizen named Daciat wore a Moslem hat and sarong.Fig.
3.
Example of Evaluation with Source Texts240 M. Shimohata and E. Sumita0 20 40 60 80 100  (%)NounsVerbsAdjectivesAdverbsAll POS...
Precision w/o Src.
(%)...
Precision w/   Src.
(%)... Error Ratio (%)Fig.
4.
Precisions for MTCC DataHere, we discuss our method?s coverage of all the synonyms in the trainingdata.
Since it is very difficult to list all synonyms appearing in the training data,we substitute identical word pairs for synonym pairs to estimate coverage.
Wecounted identical word pairs from all MCT pairs (Total) and those that have thesame context words (Same Context).
The ratio of ?Same Context?
to ?Total?denotes coverage of our method and it was found to be 27.7%.
If the tendencyof local context for identical word pairs is equal to that of synonym word pairs,our method can capture 27.7% of the embedded synonyms in the training data.We looked up acquired word pairs in WordNet6, a well-known publicly avail-able thesaurus, to see how much general synonym knowledge is included in theacquired synonyms.
We could obtain 1,001 different word pairs of verbs, adjec-tives, and adverbs after unifying conjugation7.
WordNet knows, i.e., both wordsare registered as entries, 951 word pairs (95.0%) among the 1,001 acquired pairs.The thesaurus covers, i.e., both words are registered as synonyms, 205 word pairs(21.6%) among 951 known pairs.
This result shows that our method can actuallycapture general synonym information.
The remaining acquired word pairs arestill valuable since they include either general knowledge not covered by WordNetor knowledge specific to news articles.
For example, extracted synonym pairs,?express?=?say,?
?present?=?report,?
and ?decrease?=?drop?
are found fromthe data and are not registered as synonyms in WordNet.4.2 Google News DataWe applied our method to Google News data acquired from ?Google News, 8?provided by Google, Inc.
This site provides clustered news articles that describethe same events from among approximately 4,500 news sources worldwide.6 http://www.cogsci.princeton.edu/?wn/7 Acquired nouns are excluded from the consulting since many proper names areacquired but are not covered in WordNet.8 English version: http://news.google.com/Japanese version: http://news.google.com/nwshp?ned=jpAcquiring Synonyms from Monolingual Comparable Texts 241From the Google News site, we gathered articles with manual layout-levelchecking.
This layout-level checking eliminates unrelated text such as menusand advertisements.
Our brief investigation found that clustered articles oftenhave a small overlap in described facts since each news site has its own interestand viewpoint in spite of covering the same topic.We use entire articles as ?texts?
and do not employ an automatic sentencesegmentation and alignment tool.
This is because the results derived from au-tomatic sentence segmentation and alignment on the Google News data wouldprobably be unreliable, since the articles greatly differ in format, style, and con-tent.
Since our method considers only one-word-length context in each direction,it can be applied to this rough condition.
On the other hand, this condition en-ables us to acquire synonyms placed at distant places in articles.The next issue for the experimental conditions is the range for outside-appearance checking.
Following the condition of MTCC data, the outside-ap-pearance checking range covers entire texts, i.e., outside appearance should bechecked throughout an article.
However, this condition is too expensive to followsince text length is much longer than that of MTCC data.
We tested variousranges of 0 (no outside-appearance checking), 10, 20, 40, 70, 100, 200, and un-limited words.
Figure 5 illustrates the range of outside-appearance checking.We limit the words to be tested to nouns since the acquired amounts of otherPOS types are not sufficient.
Acquired noun pairs are evaluated without source-20 words +20 wordsArticleSynonym+40 words+ unlimited-40 words- unlimitedFig.
5.
Range for Outside-Appearance Checking0204060801000 10 20 40 70 100 200 Unlimited101001000Acquired PairsPrecisionPrecision (%) # of Acquired PairsRangeFig.
6.
Precisions of Google (E) by Outside-Appearance Checking Range242 M. Shimohata and E. Sumita0204060801000 10 20 40 70 100 200 Unlimited101001000Precision (%) # of Acquired PairsRangeAcquired Pairs PrecisionFig.
7.
Precisions of Google (J) by Outside-Appearance Checking Rangetexts.
Appendix B shows examples.
Figures 6 and 7 display the amount andprecision for acquired nouns in each range of English data and Japanese data,respectively.The tendencies of these two data are similar, as the range expands, precisionincreases and the amount of acquired pairs decreases at an exponential rate.When the range is close to unlimited, precision levels off.
The average preci-sion at this stable range is 76.0% in English data and 76.3% in Japanese.
Theprecision improvement (from 13.8% to 76.0% in English data and from 9.5% to76.3% in Japanese data) shows the great effectiveness of prevention of outsideappearance.5 ConclusionsWe proposed a method to acquire synonyms from monolingual comparable texts.MCT data are advantageous for synonym acquisition and can be obtained auto-matically by a document clustering technique.
Our method relies on agreementof local context, i.e., the surrounding one word on each side of the target words,and prevention of outside appearance.The experiment on monolingual parallel texts demonstrated that the methodacquires synonyms with a precision of 70.0%, including infrequent words.
Oursimple method captures the proper place of MCT text pairs with a precision of89.5%.
The experiment on comparable news data demonstrated the robustnessof our method by attaining a precision of 76.0% for English data and 76.3%for Japanese data.
In particular, prevention of outside-appearance played animportant role by improving the precision greatly.The combination of our acquisition method, an automatic document cluster-ing technique, and daily updated Web texts enables automatic and continuoussynonym acquisition.
We believe that the combination will bring great practicalbenefits to NLP applications.Acquiring Synonyms from Monolingual Comparable Texts 243AcknowledgmentThe research reported here was supported in part by a contract with the NationalInstitute of Information and Communications Technology entitled ?A study ofspeech dialogue translation technology based on a large corpus?.References1.
R. Barzilay and K. McKeown.
Extracting paraphrases from a parallel corpus.
InProc.
of ACL-01, pages 50?57, 2001.2.
M.W.
Berry, editor.
Survey of Text Mining Clustering, Classification, and Re-trieval.
Springer, 2004.3.
E. Charniak.
A maximum-entropy-inspired parser.
In Proc.
of the 1st Conferenceof the North American Chapter of the Association for Computational Linguistics,2000.4.
C. Fellbaum.
WordNet: An Electronic Lexical Database.
MIT Press, 1998.5.
Z. Harris.
Mathematical Structures of Language.
Interscience Publishers, 1968.6.
D. Hindle.
Noun classification from predicate-argument structures.
In Proc.
ofACL-90, pages 268?275, 1990.7.
D. Lin.
Automatic retrieval and clustering of similar words.
In Proc.
of COLING-ACL 98, pages 768?774, 1998.8.
D. Lin, S. Zhao, L. Qin, and M. Zhou.
Identifying synonyms among distributionallysimilar words.
In Proc.
of the 18th International Joint Conference on ArtificialIntelligence (IJCAI), pages 1492?1493, 2003.9.
C.D.
Manning and H. Schu?tze, editors.
Foundations of Statistical Natural LanguageProcessing, pages 265?314.
MIT Press, 1999.10.
B. Pang, K. Knight, and D. Marcu.
Syntax-based alignment of multiple trans-lations: Extracting paraphrases and generating new sentences.
In Proc.
of HLT-NAACL 2003, pages 181-188, 2003.11.
F. Pereira, N. Tishby, and L. Lee.
Distributional clustering of English words.
InProc.
of ACL-93, pages 183?190, 1993.12.
P.M. Roget.
Roget?s International Thesaurus.
Thomas Y. Crowell, 1946.13.
M. Shimohata and E. Sumita.
Identifying synonymous expressions from a bilin-gual corpus for example-based machine translation.
In Proc.
of the 19th COLINGWorkshop on Machine Translation in Asia, pages 20?25, 2002.AppendixA Samples of Acquired Words from MTCC and TheirEvaluationSynonym-1 Synonym-2 Evaluationpress conference news conference Yesforeign funds foreign capital YesNouns complete finish Yesdisclose reveal Yesmilitary officials military officers NoSunday radio program Sunday TV program No244 M. Shimohata and E. Sumitaindicate show Yesbelieve think YesVerbs cease stop Yesconsider study Nobelieve trust Nobasic essential Yesnotable significant YesAdjectives massive substantial Yesactive good Nodirect strong Nocurrently now Yescertainly definitely YesAdverbs extremely very Yesnow officially Noabsolutely entirely NoB Samples of Acquired Nouns from Google News (E)and Their EvaluationSynonym-1 Synonym-2 EvaluationKarzai President Karzai YesAbu Omar Abu Umar YesNouns relief effort relief mission YesMuslim community Muslim minority NoWorld Food Program World Health Organization No
