Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 1113?1120Manchester, August 2008A Hybrid Generative/Discriminative Framework to Train a SemanticParser from an Un-annotated CorpusDeyu Zhou and Yulan HeInformation Research CentreThe University of ReadingReading, RG6 6BX, UKd.zhou@rdg.ac.uk, y.he@rdg.ac.ukAbstractWe propose a hybrid genera-tive/discriminative framework for se-mantic parsing which combines the hiddenvector state (HVS) model and the hiddenMarkov support vector machines (HM-SVMs).
The HVS model is an extension ofthe basic discrete Markov model in whichcontext is encoded as a stack-orientedstate vector.
The HM-SVMs combine theadvantages of the hidden Markov modelsand the support vector machines.
Byemploying a modified K-means clusteringmethod, a small set of most representativesentences can be automatically selectedfrom an un-annotated corpus.
Thesesentences together with their abstract an-notations are used to train an HVS modelwhich could be subsequently applied onthe whole corpus to generate semanticparsing results.
The most confidentsemantic parsing results are selected togenerate a fully-annotated corpus which isused to train the HM-SVMs.
The proposedframework has been tested on the DARPACommunicator Data.
Experimental resultsshow that an improvement over the base-line HVS parser has been observed usingthe hybrid framework.
When comparedwith the HM-SVMs trained from the fully-annotated corpus, the hybrid frameworkgave a comparable performance with onlya small set of lightly annotated sentences.c?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.1 IntroductionSemantic parsing maps the natural language sen-tences to complete formal meaning representa-tions.
Traditionally, research in the field of se-mantic parsing can be divided into two categories:rule-based approaches and statistical approaches.Based on hand-crafted semantic grammar rules,rule-based approaches fill slots in semantic framesusing word pattern and semantic tokens (Dowdinget al, 1994; Ward and Issar, 1994).
Such rule-based approaches are typically domain-specificand often fragile.
Statistical approaches are gen-erally based on stochastic models.
They can befurther categorized into three types: generativeapproaches, discriminative approaches and a hy-brid of the two.
Generative approaches learn thejoint probability model, P (W,C), of input sen-tence W and its semantic tag sequence C, com-pute P (C|W ) using the Bayes rule, and then takethe most probable tag sequence C. The hiddenMorkov model (HMM), being a generative model,has been predominantly used in statistical seman-tic parsing.
It models sequential dependencies bytreating a semantic parse sequence as a Markovchain, which leads to an efficient dynamic pro-gramming formulation for inference and learning.The hidden vector state (HVS) model (He andYoung, 2005) is a discrete HMM model in whicheach HMM state represents the state of a push-down automaton with a finite stack size.
Statetransitions are factored into separate stack popand push operations constrained to give a tractablesearch space.
The result is a model which iscomplex enough to capture hierarchical structurebut which can be trained automatically from onlylightly annotated data.
Discriminative approachesdirectly model posterior probability P (C|W ) and1113learn mappings from W to C. One representa-tive example is support vector machines (SVMs)(Vapnik, 1995).
More recently, the hidden Markovsupport vector machines (HM-SVMs) (Altun et al,2003) have been proposed which combine the flex-ibility of kernel methods with the idea of HMMs topredict a label sequence given an input sequence.However, HM-SVMs require full annotated cor-pora for training which are difficult to obtain inpractical applications.
On the other hand, the HVSmodel can be easily trained from only lightly an-notated corpora.
It is thus interesting to explore thefeasibility to combine the advantages of the HVSmodel and the HM-SVMs.We propose a hybrid generative/discriminativeframework here where a modified K-means clus-tering method is first applied to select a smallset of the most representative sentences automat-ically from an un-annotated corpus.
These sen-tences together with their abstract annotations areused to train an HVS model which could be sub-sequently applied on the whole corpus to generatesemantic parsing results.
The most confident se-mantic parsing results are selected to generate afully-annotated corpus which is used to train theHM-SVMs.
Experimental results show that an im-provement over the baseline HVS parser has beenachieved using the hybrid framework.
When com-pared with the HM-SVMs trained from the fully-annotated corpus, the hybrid framework gave acomparable performance with only a small set oflighted annotated sentences.The rest of this paper is organized as follows.Section 2 reviews other proposed hybrid gener-ative/discriminative frameworks in recent years.Section 3 briefly describes the HVS model andthe HM-SVMs followed by the presentation of theproposed hybrid framework.
In Section 4, exper-imental setup and results are discussed.
Finally,Section 5 concludes the paper.2 Related WorkCombination of generative and discriminativemodels for data classification has recently attractedmuch interests in the machine learning community.It has been shown theoretically and experimentallyin (Jaakkola and Haussler, 1998; Ng and Jordan,2002; Bouchard and Triggs, 2004) that the hy-brid model combines the complementary powersof the both models.
The first extensive study on hy-brid models were discussed in (Jaakkola and Haus-sler, 1998) where discriminative features were ex-tracted using generative models and were laterused in discriminative models.
More recently, theHM-SVMs (Altun et al, 2003) have been proposedwhich incorporate kernel methods into HMMs topredict a label sequence given an input sequence.There have also been several studies on explor-ing the hybrid generative/discriminative frame-works which combine the generative and discrim-inative models in a pipelined way.
One exam-ple is the hybrid framework proposed in (Abou-Moustafa et al, 2004) for sequential data classi-fication.
The framework employs HMMs to mapthe variable length sequential data into a fixed sizeP -dimensional vector that can be classified us-ing any discriminative model.
Experiments wereconducted on the NIST database for handwrittendigits and results showed a better recognition ratethan that of standard HMMs.
Another example isthe hybrid generative/discriminative approach pro-posed in (Holub et al, 2008) for detecting andclassifying object categories in the machine ver-sion domain.
In this approach, ?Fisher Kernels?were used to retain most of the desirable prop-erties of generative methods and a discriminativesetting was used to increase the classification per-formance.
Experimental results showed signifi-cant performance improvement over the generativecounterpart.3 MethodologiesThis section first introduces the hidden vectorstate (HVS) model and the hidden Markov sup-port vector machines (HM-SVMs) followed bythe presentation of the proposed hybrid genera-tive/discriminative framework.3.1 Hidden Vector State ModelGiven a model and an observed word sequenceW = (w1?
?
?wT), semantic parsing can beviewed as a pattern recognition problem and themost likely semantic representation can be foundthrough statistical decoding.
If assuming that thehidden data take the form of a semantic parse treeC then the model should be a push-down automatawhich can generate the pair ?W,C?
through somecanonical sequence of moves D = (d1?
?
?
dT).That is,P (W,C) =T?t=1P (dt|dt?1?
?
?
d1) (1)1114For the general case of an unconstrained hierarchi-cal model, D will consist of three types of proba-bilistic move:1. popping semantic category labels off thestack;2. pushing one or more non-terminal semanticcategory label onto the stack;3. generating the next word.When considering a constrained form of au-tomata where the stack is finite depth and ?W,C?is built by repeatedly popping 0 to n labels offthe stack, pushing exactly one new label onto thestack and then generating the next word, it definesthe Hidden Vector State (HVS) model in whichconventional grammar rules are replaced by threeprobability tables.Given a word sequence W , concept vector se-quence C and a sequence of stack pop operationsN , the joint probability of P (W,C,N) can be de-composed asP (W,C,N) =T?t=1P (nt|ct?1)P (ct[1]|ct[2 ?
?
?Dt])P (wt|ct) (2)where ct, the vector state at word position t, is avector of Dtsemantic concept labels (tags), i.e.ct= [ct[1], ct[2], ..ct[Dt]] where ct[1] is the preter-minal concept label and ct[Dt] is the root conceptlabel, ntis the vector stack shift operation at wordposition t and take values in the range 0, .
.
.
, Dt?1and ct[1] = cwtis the new preterminal semantictag assigned to word wtat word position t.3.2 Hidden Markov Support VectorMachinesTo learn a function that assigns to a sequence ofwords W = (w1?
?
?wT), wi?
W, i = 1, .
.
.
T asequence of semantic tags C = c1c2.
.
.
cT, ci?C, i = 1, .
.
.
T , a common approach is to deter-mine a discriminant function F : W?C ?
R thatassigns a score to every input W ?
W := W?andevery semantic tag sequence C ?
C := C?, whereW?denotes the Kleene closure of W. In order toobtain a prediction f(W ) ?
C, the function is max-imized with respect to f(W ) = argmaxC?CF (W,C).In particular, the function F (W,C) is assumedto be linear in some combined feature represen-tation of W and C in HM-SVMs (Altun et al,2003), F (W,C) := ?w,?(W,C)?.
Given a setof training data (Wi, Ci), i = 1, .
.
.
N , the param-eters w are adjusted so that the true semantic tagsequence Ciscores higher than all other tag se-quences C ?
Ci:= C\Ciwith a large margin.
Toachieve the goal, the following optimization prob-lem is solved instead.min?i?R,w?FCons?i?i+12?w?2(3)s.t.
?w,?(W,Ci)?
?
?w,?(W,C)?
?
1?
?i,?i = 1, .
.
.
N and C ?
C\Ciwhere ?iis non-negative slack variables allowingone to increase the global margin by paying a lo-cal penalty on some outlying examples, and Consdictates the desired trade off between margin sizeand outliers.
To solve the equation 3, the dual ofthe equation is solved instead.
The solution w?canbe written asw?=N?i=1?C?C?i(C)?
(Wi, C), (4)where ?i(C) is the Lagrange multiplier of the con-straint associated with example i and Ci.3.3 A Hybrid Generative/DiscriminativeFramework for Semantic ParsingThe framework of combining the HVS model andthe HM-SVMs is illustrated in Figure 1.
It consistsof three main stages, Representative Sentences Se-lection, Fully Annotated Corpus Generation, andHM-SVM Training and Testing.
Each of them isdiscussed in details below.?
Representative Sentences Selection.
Given anun-annotated corpus, the modified K-meansclustering algorithm is first employed to se-lect the most representative sentences for an-notation.
This is to avoid annotating thewhole corpus and hopefully the model trainedfrom the subset of the original corpus wouldstill give a similar performance when com-pared with the model trained from the fullcorpus.
The modified K-means clustering al-gorithm is described in Figure 3.3.Initially, k different sentences are randomlyselected as the initial centroids.
Then, eachsentence siin the training data is assigned toone of the k clusters based on the similaritymeasurement which will be discussed later.1115HM-SVMTraining and TestingFully Annotated Corpus GenerationRepresentative Sentence SelectionUn-annotatedcorpusTest Data(Sentences)HVSmodelParsing results filteringHVS trainingHVS parsingClusteringAnnotatingHM-SVMTrainingClassificationResultsSentences andtheir annotationsFully annotatedcorpusSentences and theirparsing sequencesRepresentativesentencesHM-SVMClassifierFigure 1: The hybrid generative/discriminative framework for semantic parsing.After that, the centroids of the k clusters arerecalculated.
The above process repeats untilthere are no further changes in the centroids.The similarity between two sentences is cal-culated based on sequence alignment.
Sup-pose a = a1a2?
?
?
anand b = b1b2?
?
?
bmarethe two word sequences of length of n and m,Sim(i, j) is defined as the score of the op-timal alignment between the initial segmentfrom a1to aiof a and the initial segment fromb1to bjof b, where Sim(i, j) is recursivelycalculated as follows:Sim(i, 0) = 0, i = 1, 2, ...nSim(0, j) = 0, j = 1, 2, ...mSim(i, j) = max???????????0,Sim(i?
1, j ?
1) + s(ai, bj),Sim(i?
1, j) + s(ai,???
),Sim(i, j ?
1) + s(??
?, bj)Here s(ai, bj) is the score of aligning aiwithbjand is defined as:s(ai, bj) = log[p(ai, bj)p(ai)?
p(bj)](5)where, p(ai) denotes the occurrence probabil-ity of the word aiand p(ai, bj) denotes theprobability that aiand bjappear at the sameposition in two aligned sequences.To ensure that content words containing keyinformation are weighted more heavily thanthe less relevant words such as functionwords, a score matrix can then be built anddynamic programming is used to find thelargest score between two sequences.
Thedistance between the two sentences is de-fined as the negation of the similarity betweenthem.After generating k clusters, the centroid ineach of the clusters is selected as the represen-tative sentence for annotation.
This results inan exactly k sentences being selected.
Thereare however two ways to construct the anno-tated corpus depending on the neighborhoodthreshold value d. When d = 1, the anno-tated corpus only contains k sentences.
Whend < 1, both the centroid and some of its near-est neighboring sentences in each cluster willreceive the same abstract annotation.
Thus,the annotated corpus will contain more thank sentences.
It has to be noted that in bothcases, only k sentences (centroids) need to beannotated.?
Fully Annotated Corpus Generation.
AnHVS model is trained from the annotated cor-pus constructed in the previous stage whichis then applied to the original un-annotatedcorpus to generate a semantic tag sequencefor each sentence.
The generated semantictag sequences essentially define the explicitword/tag alignments which could serve as thefull annotation required by HM-SVMs train-ing.
However, the HVS model does not guar-antee to parse the sentences with 100% accu-racy.
Based on a user-defined parse probabil-1116Input: A set of sentences S = {si, i = 1, .
.
.
, N}, a distance threshold ?, a neighborhood threshold dOutput: A set of representative sentences R = {rj, j = 1, .
.
.
,M}, and a set of the centroids of thegenerated clusters CentAlgorithm:1.
For each si?
S, set Flagi= 1.
Initialize R and Cent to be empty sets.2.
Select sentences from S with Flag equal to 1 , then reconstruct?S = {sj|Flagj= 1, j =1, .
.
.
,?N},?N is the number of sentences with Flag equal to 1 in S.3.
Randomly select k different sentences ckfrom?S, the default value of k is 1000.
Construct kclusters C = {cl}, l = 1, .
.
.
, k. Set NumOfFlag = ??S?4.
Loop for each sentences si?
?SLoop for each cluster clCalculate the distance between siand the centroid of cl.
Distil= Distance(si, cl).If Distil< ?, then cl= cl?si, set Flagi= 0, ExitLoop.EndLoopIf Flagi6= 0, then find the cluster l?= argminl{Distil, l = 1, .
.
.
, k}, cl?= cl?
?siEndLoopIf ?{si|si?
?S, F lagi= 1}?
<NumOfFlag, then set NumOfFlag = ?{si|si?
?S, F lagi= 1}?,go to Step 4.Cent = Cent?Centl, l = 1, .
.
.
, k, ?cl?
6= 0.5.
If NumOfFlag > 0 then Go to step 2.ElseR = R?Cent.Construct ?Cent?
clusters?C = {cl}, l = 1, .
.
.
, ?Cent?.Loop for each sentences si?
SFind the cluster l?= argminl{Distil, l = 1, .
.
.
, ?Cent?
}, c?l= c?l?siIf Distil?< d, then R = R?siEndLoopEndIfFigure 2: A modified K-means clustering method.ity threshold, the most confident parse resultsare selected for the construction of the fullyannotated corpus.?
HM-SVMs Training and Testing.
Given thefully annotated corpus generated in the previ-ous stage, the HM-SVMs can then be trainedwhich could later be used to derive the seman-tic tag sequences for the test data.4 ExperimentExperiments have been conducted on the DARPACommunicator data (CUData, 2004) which areavailable to the public as open source download.The data contain utterance transcriptions and thesemantic parse results from the rule-based Phoenixparser1.
The DARPA Communicator data werecollected in 461 days.
From these, 46 days wererandomly selected for use as test set data and theremainder were used for training.
After cleaningup the data, the training set consist of 12702 utter-ances while the test set contains 1178 utterances.1http://communicator.colorado.edu/phoenixThe abstract annotation used for training and thereference annotation needed for testing were de-rived by hand correcting the Phoenix parse results.For example, for the sentence ?Show me flightsfrom Boston to New York?, the abstract annota-tion would beFLIGHT(FROMLOC(CITY) TOLOC(CITY)).Such an annotation need only list a set of valid se-mantic concepts and the dominance relationshipsbetween them without considering the actual real-ized concept sequence or attempting to identify ex-plicit word/concept pairs.
Thus, it avoids the needfor expensive tree-bank style annotations.To evaluate the performance of the model, a ref-erence frame structure was derived for every testset sentence consisting of slot/value pairs.
An ex-ample of a reference frame is:Show me flights from Boston to New York.Frame: FLIGHTSlots: FROMLOC.CITY = BostonTOLOC.CITY = New YorkPerformance was then measured in terms ofF -measure on slot/value pairs, which combines1117Table 1: Feature templates used in HM-SVMs.
wiis the current word, and w1, .
.
.
, wnis the entiresentence.Current word wiPrevious word wi?1Word two back wi?2Next word wi+1Word two ahead wi+2Bigram features wi?2, wi?1wi?1, wiwi, wi+1wi+1, wi+2Table 2: The number of representative sentencesvs the different settings of ?
and d.HHHHHHd?0.5 0.6 0.7 0.8 0.91 350 663 1068 1743 27630.6 6878 7596 9810 9640 11872the precision (P) and recall (R) values with equalweight and is defined as F = (P +R)/2PR.In all the subsequent experiments, the opensource SVMhmm(Tsochantaridis et al, 2005)2has been used to train and test the HM-SVMs.
Thefeatures used in the HM-SVMs are listed in Ta-ble 1.4.1 Comparison between HVS andHM-SVMsIn the modified K-means clustering algorithm de-scribed in Figure 3.3, the number of representativesentences depends on both the distance threshold ?and the neighborhood threshold d. Table 2 showsthe number of representative sentences obtained byvarying ?
and d.First, a set of experiments were conducted tocompare the performance of the HVS model withthe HM-SVMs only without incorporating the hy-brid framework.
Based on the different values ofd and ?, we constructed different sets of the anno-tated corpus.
For example, when ?
= 0.5, thereare 350 clusters generated from a total of 12702sentences in the un-annotated corpus.
The centroidfrom each of the cluster is then selected for annota-tion.
These 350 sentences were annotated with ab-stract annotation for the HVS model training.
Andthey were also fully annotated by providing word-level annotations for HM-SVMs training.2http://www.cs.cornell.edu/People/tj/svm light/svm hmm.html0.5 0.6 0.7 0.8 0.90.50.550.60.650.70.750.80.850.90.951?F?measureHM?SVMHVS (d = 1)HVS (d = 0.6)Figure 3: Comparisons of the performance of HVSand HM-SVMs on different ?.Since only abstract annotations need to be pro-vided for the HVS model training, it is possible toautomatically enlarge the annotated corpus by in-cluding some of the neighboring sentences if thesame annotation of the centroid can be assigned tothem.
This is controlled by varying the neighbor-hood threshold d. If d = 1, then the annotatedcorpus only contains 350 sentences with their ab-stract annotations.
If varying d to 0.6, then for eachcluster, some of the neighboring sentences also re-ceive the same abstract annotation as that of thecentroid, thus the annotated corpus is enlarged tocontain 6878 sentences.The performance comparison of the HVS andthe HM-SVMs is shown in Figure 3.
It can beobserved that in general, HM-SVMs outperformsHVS.
This is not surprising as HM-SVMs wastrained from the fully annotated corpus.
The HVSmodel based on d = 0.6 achieved better perfor-mance over the one based on d = 1 since the en-larged annotated corpus was used for training.
Thebest performance given by HM-SVMs is 92.5%of F-measure when ?
= 0.9 and 2793 annotatedsentences were used for training, while the HVSmodel gave an F-measure of 86.9%.Though HM-SVMs outperforms HVS by 5.5%,it should be noted that the time consumed forpreparing the fully annotated corpus for HM-SVMs is far more than the time spent for abstractannotation for HVS as shown in Figure 4.
When?
= 0.5, annotating 350 sentences with the ex-plicit word/semantic tag mappings took about 17.5hours while abstract annotation only took about 3hours.
When ?
= 0.9, the time spent on fully an-notating 2763 sentences is almost six times that ofabstract annotation.111802040608010012014012345alphahoursAbstract AnnotationWord level AnnotationFigure 4: Comparison of time Consuming inpreparing training data for the HVS model and theHM-SVMs.4.2 Comparison between HVS and theHybrid Framework with ClusteringFigure 5 shows the performance comparison be-tween the HVS model and the hybrid frameworkby varying ?.
It can be observed that when the sizeof the annotated corpus is small, the HVS modeloutperforms the hybrid framework.
However, withincreased number of annotated sentences, the hy-brid framework achieves the better performance.For both the HVS model and the hybrid frame-work, improved performance is observed by train-ing the model/framework from the augmented an-notated corpus with the neighboring sentences au-tomatically added in (cf.
Figure 5(a) and (b)).We notice from Figure 5(a) that when the num-ber of annotated sentences increases from 1743 to2763, the performances of both the HVS modeland the hybrid framework decrease.
By analyz-ing the clustering results generated from the mod-ified K-means algorithm, we found that some ofthe clusters formed actually contain those rare sen-tences and they represent the outliers of the orig-inal training set.
This therefore leads to the de-creased performance of the HVS model and thehybrid framework.With only 2763 annotated sentences, the hybridframework trained under d = 0.6 achieves 88.5%in F-measure which results in a relative error re-duction of 12% when compared with the HVSmodel where the F-measure value of 87.0% wasobtained.4.3 Comparison between HVS and theHybrid Framework without ClusteringExperiments have also been conducted to comparethe performance of the HVS model and the hy-0.5 0.6 0.7 0.8 0.90.750.760.770.780.790.80.810.820.830.840.850.860.870.880.890.9?F?measureHVSHybrid framework(a) d = 1.0.5 0.6 0.7 0.8 0.90.780.790.80.810.820.830.840.850.860.870.880.890.9?F?measureHVSHybrid framework(b) d = 0.6.Figure 5: Comparison of the performance of theHVS model and the hybrid frameworkbrid framework without employing the modifiedK-means clustering algorithm to automatically se-lect the most representative sentences for annota-tion.
That is, the whole corpus of 12702 sentenceswere provided with abstract annotations.
Boththe HVS model and the hybrid framework weretrained from the training set which was formed byrandomly selecting the annotated sentences fromthe original corpus.
Figure 6 illustrates the perfor-mance of the HVS model and the hybrid frame-work versus the varying sizes of the training data.Here 10-fold cross validation was performed andthe F-measure value at each point of the curve inFigure 6 was calculated by averaging the perfor-mance of the 10 experiments each time with dif-ferent training set of the same size.It can be observed that the performance of boththe HVS model and the proposed hybrid frame-work increases with the increased size of the train-ing data.
The hybrid framework outperforms theHVS model when the size of the training data isbeyond 6000.
The improvement is more substan-tial by incorporating more training data.The best performance achieved by the HVSmodel and the proposed hybrid framework is listed11191 2 3 4 5 6 7 8 9 10 11 120.780.790.80.810.820.830.840.850.860.870.880.890.90.91Number of Sentences in the Training data (*1000)F?measureHVSHybrid frameworkFigure 6: Performance of the HVS model and thehybrid framework vs the size of the training data.in Table 3.
It can be observed that the hybridframework gives the relative error reduction of22% when compared with the performance of theHVS model where only 87.97% was achieved.Table 3: Performance comparison between HVSand the hybrid framework.Measurement HVS Hybrid FrameworkRecall 87.81% 90.99 %Precision 88.13% 90.25%F-measure 87.97% 90.62%It should also be noted that the best performanceof 87.97% in F-measure was obtained when theHVS model was trained on the whole annotatedcorpus of 12702 sentences.
By employing the clus-tering method to select the most representative sen-tences, the hybrid framework trained with less thanone fourth of the original training data (2763 an-notated sentences) achieves 88.53% in F-measure,which is better than that of the HVS model.5 ConclusionsThis paper presented a hybrid framework by com-bining the HVS model and the HM-SVMs for se-mantic parsing.
Experimental results show that22% relative error reduction in F-measure was ob-tained using the hybrid framework on the DARPACommunicator Data when compared with the per-formance of the HVS model.
Furthermore, em-ploying the modified K-means clustering algo-rithm to automatically select the most representa-tive sentences for annotation greatly reduces thehuman effort for annotation.
With only 2763annotated sentences, the hybrid framework givesthe better performance compared with the HVSmodel trained on the full 12702 annotated sen-tences.
Also, the hybrid framework gives the com-parable performance with that of the HM-SVMsbut without the use of the expensive word-level an-notations.ReferencesAbou-Moustafa, K.T., C.Y.
Suen, and M. Cheriet.2004.
A generative-discriminative hybrid for se-quential data classification.
In Acoustics, Speech,and Signal Processing, 2004 (ICASSP ?04), vol-ume 5, pages 805?808.Altun, Y., I. Tsochantaridis, and T. Hofmann.
2003.Hidden markov support vector machines.
In Inter-national Conference in Machine Learning, pages 3?10.Bouchard, Guillaume and Bill Triggs.
2004.
The trade-off between generative and discriminative classifiers.In Proc.
of COMPSTAT 2004, pages 721?728.CUData.
2004.
Darpa communicator travel data.university of colorado at boulder.
Avaiable fromhttp://communicator.colorado.edu/phoenix.Dowding, J., R. Moore, F. Andry, and D. Moran.
1994.Interleaving syntax and semantics in an efficientbottom-up parser.
In Proc.
of the 32th Annual Meet-ing of the Association for Computational Linguistics,pages 110?116, Las Cruces, New Mexico, USA.He, Yulan and Steve Young.
2005.
Semantic process-ing using the hidden vector state model.
ComputerSpeech and Language, 19(1):85?106.Holub, Alex D., Max Welling, and Pietro Perona1.2008.
Hybrid generative-discriminative visual cat-egorization.
International Journal of Computer Vi-sion, 77:239?258.Jaakkola, T. and D. Haussler.
1998.
Exploiting genera-tive models in discriminative classifiers.
In Proc.
ofAdvances in Neural Information Processing 11.Ng, A. and M. Jordan.
2002.
On generative vs. dis-criminative classifiers: A comparison of logistic re-gression and naive bayes.
In Proc.
of Advances inNeural Information Processing 15, pages 841?848.Tsochantaridis, Ioannis, Thorsten Joachims, ThomasHofmann, and Yasemin Altun.
2005.
Large mar-gin methods for structured and interdependent outputvariables.
J. Mach.
Learn.
Res., 6:1453?1484.Vapnik, Vladimir N. 1995.
The nature of statisticallearning theory.
Springer-Verlag New York, Inc.,New York, NY, USA.Ward, W. and S. Issar.
1994.
Recent improvements inthe cmu spoken language understanding system.
InProc.
of the workshop on Human Language Technol-ogy, pages 213?216, Plainsboro, New Jerey, USA.1120
