Proceedings of the 8th Workshop on Asian Language Resources, pages 47?55,Beijing, China, 21-22 August 2010. c?2010 Asian Federation for Natural Language ProcessingLabeling Emotion in Bengali Blog Corpus ?
A Fine GrainedTagging at Sentence LevelDipankar DasDepartment of Computer Science& Engineering,Jadavpur Universitydipankar.dipnil2005@gmail.comSivaji BandyopadhyayDepartment of Computer Science& Engineering,Jadavpur Universitysivaji_cse_ju@yahoo.comAbstractEmotion, the private state of a humanentity, is becoming an important topicin Natural Language Processing (NLP)with increasing use of search engines.The present task aims to manually an-notate the sentences in a web basedBengali blog corpus with the emotionalcomponents such as emotional expres-sion (word/phrase), intensity, associ-ated holder and topic(s).
Ekman?s sixemotion classes (anger, disgust, fear,happy, sad and surprise) along withthree types of intensities (high, generaland low) are considered for the sen-tence level annotation.
Presence of dis-course markers, punctuation marks,negations, conjuncts, reduplication,rhetoric knowledge and especiallyemoticons play the contributory rolesin the annotation process.
Differenttypes of fixed and relaxed strategieshave been employed to measure theagreement of the sentential emotions,intensities, emotional holders and top-ics respectively.
Experimental resultsfor each emotion class at word level ona small set of the whole corpus havebeen found satisfactory.1 IntroductionHuman emotion described in texts is an impor-tant cue for our daily communication but theidentification of emotional state from texts isnot an easy task as emotion is not open to anyobjective observation or verification (Quirk etal., 1985).
Emails, weblogs, chat rooms, onlineforums and even twitter are considered as theaffective communication substrates to analyzethe reaction of emotional catalysts.
Amongthese media, blog is one of the communicativeand informative repository of text based emo-tional contents in the Web 2.0 (Lin et al,2007).Rapidly growing web users from multilin-gual communities focus the attention to im-prove the multilingual search engines on thebasis of sentiment or emotion.
Major studieson Opinion Mining and Sentiment Analyseshave been attempted with more focused per-spectives rather than fine-grained emotions.The analyses of emotion or sentiment requiresome basic resource.
An emotion-annotatedcorpus is one of the primary ones to start with.The proposed annotation task has been car-ried out at sentence level.
Three annotatorshave manually annotated the Bengali blog sen-tences retrieved from a web blog archive1 withEkman?s six basic emotion tags (anger (A),disgust (D), fear (F), happy (H), sad (Sa) andsurprise (Su)).
The emotional sentences aretagged with three types of intensities such ashigh, general and low.
The sentences of non-emotional (neutral) and multiple (mixed) cate-gories are also identified.
The identification ofemotional words or phrases and fixing thescope of emotional expressions in the sen-tences are carried out in the present task.
Eachof the emoticons is also considered as individ-ual emotional expressions.
The emotion holderand relevant topics associated with the emo-tional expressions are annotated consideringthe punctuation marks, conjuncts, rhetoricalstructures and other discourse information.
Theknowledge of rhetorical structure helps in re-moving the subjective discrepancies from the1 www.amarblog.com47writer?s point of view.
The annotation schemeis used to annotate 123 blog posts containing4,740 emotional sentences having single emo-tion tag and 322 emotional sentences for mixedemotion tagss along with 7087 neutral sen-tences in Bengali.
Three types of standardagreement measures such as Cohen?s kappa() (Cohen, 1960; Carletta, 1996), Measure ofAgreement on Set-valued Items (MASI) (Pas-sonneau, 2004) and agr (Wiebe et al, 2005)metrics are employed for annotating the emo-tion related components.
The relaxed agree-ment schemes like MASI and agr are speciallyconsidered for fixing the boundaries of emo-tional expressions and topic spans in the emo-tional sentences.
The inter annotator agreementof some emotional components such as senten-tial emotions, holders, topics show satisfactoryperformance but the sentences of mixed emo-tion and intensities of general and low showthe disagreement.
A preliminary experimentfor word level emotion classification on asmall set of the whole corpus yielded satisfac-tory results.The rest of the paper is organized as fol-lows.
Section 2 describes the related work.
Theannotation of emotional expressions, sententialemotion and intensities are described in Sec-tion 3.
In Section 4, the annotation scheme foremotion holder is described.
The issues ofemotional topic annotation are discussed inSection 5.
Section 6 describes the preliminaryexperiments carried out on the annotated cor-pus.
Finally, Section 7 concludes the paper.2 Related WorkOne of the most well known tasks of annotat-ing the private states in texts is carried out by(Wiebe et al, 2005).
They manually annotatedthe private states including emotions, opinions,and sentiment in a 10,000-sentence corpus (theMPQA corpus) of news articles.
The opinionholder information is also annotated in theMPQA corpus but the topic annotation task hasbeen initiated later by (Stoyanov and Cardie,2008a).
In contrast, the present annotationstrategy includes the fine-grained emotionclasses and specially handles the emoticonspresent in the blog posts.
(Alm et al, 2005) have considered eightemotion categories (angry, disgusted, fearful,happy, sad, positively surprised, negativelysurprised) to accomplish the emotion annota-tion task at sentence level.
They have manuallyannotated 1580 sentences extracted from 22Grimms?
tales.
The present approach discussesthe issues of annotating unstructured blog textconsidering rhetoric knowledge along with theattributes, e.g.
negation, conjunct, reduplica-tion etc.Mishne (2005) experimented with moodclassification in a blog corpus of 815,494 postsfrom Livejournal(http://www.livejournal.com), a free weblogservice with a large community.
(Mihalcea andLiu, 2006) have used the same data source forclassifying the blog posts into two particularemotions ?
happiness and sadness.
The blogposts are self-annotated by the blog writerswith happy and sad mood labels.
In contrast,the present approach includes Ekman?s sixemotions, emotion holders and topics to ac-complish the whole annotation task.
(Neviarouskaya et al, 2007) collected 160sentences labeled with one of the nine emo-tions categories (anger, disgust, fear, guilt, in-terest, joy, sadness, shame, and surprise) and acorresponding intensity value from a corpus ofonline diary-like blog posts.
On the other hand,(Aman and Szpakowicz, 2007) prepare anemotion-annotated corpus with a rich set ofemotion information such as category, inten-sity and word or phrase based expressions.
Thepresent task considers all the above emotioninformation during annotation.
But, the presentannotation task additionally includes the com-ponents like emotion holder, single or multipletopic spans.The emotion corpora for Japanese were builtfor recognizing emotions (Tokuhisa et al,2008).
An available emotion corpus in Chineseis Yahoo!
?s Chinese news(http://tw.news.yahoo.com), which is used forChinese emotion classification of news readers(Lin, et al, 2007).
The manual annotation ofeight emotional categories (expect, joy, love,surprise, anxiety, sorrow, angry and hate)along with intensity, holder, word/phrase, de-gree word, negative word, conjunction, rheto-ric, punctuation and other linguistic expres-sions are carried out at sentence, paragraph aswell as document level on 1,487 Chinese blogdocuments (Quan and Ren, 2009).
In addition48to the above emotion entities, the present ap-proach also includes the annotation of single ormultiple emotion topics in a target span.Recent study shows that non-native Englishspeakers support the growing use of the Inter-net 2.
This raises the demand of linguistic re-sources for languages other than English.
Ben-gali is the fifth popular language in the World,second in India and the national language inBangladesh but it is less computerized com-pared to English.
To the best of our knowl-edge, at present, there is no such available cor-pus that is annotated with detailed linguisticexpressions for emotion in Bengali or even forother Indian languages.
Thus we believe thatthis corpus would help the development andevaluation of emotion analysis systems inBengali.3 Emotion AnnotationRandom collection of 123 blog posts contain-ing a total of 12,149 sentences are retrievedfrom Bengali web blog archive 3  (especiallyfrom comics, politics, sports and short stories)to prepare the corpus.
No prior training wasprovided to the annotators but they were in-structed to annotate each sentence of the blogcorpus based on some illustrated samples ofthe annotated sentences.
Specially for annotat-ing the emotional expressions and topic(s) inemotional sentences, the annotators are free inselecting the texts spans.
This annotationscheme is termed as relaxed scheme.
For otheremotional components, the annotators aregiven items with fixed text spans and in-structed to annotation the items with definitetags.3.1 Identifying Emotional Expressions forSentential Emotion and IntensityThe identification of emotion or affect affixedin the text segments is a puzzle.
But, the puzzlecan be solved partially using some lexicalclues (e.g.
discourse markers, punctuationmarks (sym), negations (NEG), conjuncts(CONJ), reduplication (Redup)), structuralclues (e.g.
rhetoric and syntactic knowledge)and especially some direct affective clues (e.g.2 http://www.internetworldstats.com/stats.htm3 www.amarblog.comemoticons (emo_icon)).
The identification ofstructural clues indeed requires the identifica-tion of lexical clues.Rhetorical Structure Theory (RST) de-scribes the various parts of a text, how theycan be arranged and connected to form a wholetext (Azar, 1999).
The theory maintains thatconsecutive discourse elements, termed textspans, which can be in the form of clauses,sentences, or units larger than sentences, arerelated by a relatively small set (20?25) of rhe-torical relations (Mann and Thompson, 1988).RST distinguishes between the part of a textthat realizes the primary goal of the writer,termed as nucleus, and the part that providessupplementary material, termed satellite.
Theseparation of nucleus from satellite is donebased on punctuation marks (, !
@?
), emoti-cons, discourse markers (  jehetu [as], jemon [e.g.
],karon [because], 	 mane[means]), conjuncts (e ebong [and], nkintu [but], a athoba [or]), causal verbs( ghotay [caused]) if they are explicitlyspecified in the sentences.Use of emotion-related words is not the solemeans of expressing emotion.
Often asentence, which otherwise may not have anemotional word, may become emotion bearingdepending on the context or underlyingsemantic meaning (Aman and Szpakowicz,2007).
An empirical analysis of the blog textsshows two types of emotional expressions.
Thefirst category contains explicitly statedemotion word (EW) or phrases (EP) mentionedin the nucleus or in the satellite.
Anothercategory contains the implicit emotional cluesthat are identified based on the context or fromthe metaphoric knowledge of the expressions.Sometimes, the emotional expressions containdirect emotion words (EW) (koutuk[joke], 	 ananda [happy], ashcharjyo [surprise]), reduplication (Redup)(   sanda sanda [doubt with fear],question words (EW_Q) (ki [what], kobe[when]), colloquial words (k kshyama[perdon]) and foreign words ( thanku[thanks],  gossya [anger]).
On the otherhand, the emotional expressions containindirect emotion words e.g.
proverbs, idioms(  taser ghar [weakly built],  grri-hadaho [family disturbance]) and emoticons(,).49A large number of emoticons (emo_icon)present in the Bengali blog texts vary accord-ing to their emotional categories and slant.Each of the emoticons is treated as individualemotional expression and its correspondingintensity is set based on the image denoted bythe emoticon.
The labeling of the emoticonswith Ekman?s six emotion classes is verifiedthrough the inter-annotator agreement that isconsidered for emotion expressions.The intensifiers (! khub [too much/very],aanek [huge/large], "#$bhishon[heavy/too much]) associated with the emo-tional phrases are also acknowledged in anno-tating sentential intensities.
As the intensifiersdepend solely on the context, their identifica-tion along with the effects of negation and con-juncts play a role in annotating the intensity.Negations (	 na [no], 	 noy [not]) and con-juncts freely occur in the sentence and changethe emotion of the sentence.
For that very rea-son, a crucial analysis of negation and con-juncts is carried out both at intra and interphrase level to obtain the sentential emotionsand intensities.
An example set of the anno-tated blog corpus is shown in Figure 1.<ES_S%><hold&r>'':</hold&r> "i(<sym>!</sym> <EW_D>*</EW_D>i+	?</ES_S%><ES_A><ES_Su>	 <EW_Su><EW_Q></EW_Q></EW_Su> ,-<EW_Su><EW_Q> </EW_Q></EW_Su>*	<EW_Su>!</EW_Su> <R&-dup><EW_A></EW_A></R&dup> "'- -	 <EW_F>0 </EW_F>'	 1<NEG>	</NEG> </ES_Su></ES_A><ES_H>1	 <top2c></top2c> 13e ei <EW_H>4</EW_H> 13+- </ES_H>?Figure 1.
Annotated sample of the corpus?3.2 Agreement of Sentential Emotion andIntensityThree annotators identified as A1, A2 and A3have used an open source graphical tool tocarry out the annotation 4 .
As the Ekman?semotion classes and intensity types belong tosome definite categories, the annotation4 http://gate.ac.uk/gate/doc/releases.htmlagreement for emotion and intensities aremeasured using standard Cohen's kappa coef-ficient () (Cohen, 1960).
The annotationagreement for emoticons is also measured us-ing the kappa metric.
It is a statistical measureof inter-rater agreement for qualitative (cate-gorical) items.
It measures the agreement be-tween two raters who separately classify itemsinto some mutually exclusive categories.The agreement of classifying sentential in-tensities into three classes (high, general andlow) is also measured using kappa ().
Theintensities of mixed emotional sentences arealso considered.
Agreement results of emo-tional, non-emotional and mixed sentences,emoticons, along with results for each emotionclass, intensity types are shown in Table 1.Sentential emotions with happy, sad or sur-prise classes produce comparatively higherkappa coefficient than the other emotionclasses as the emotional expressions of thesetypes were explicitly specified in the blogtexts.
It has been observed that the emotionpairs such as ?sad-anger?
and ?anger-disgust?often cause the trouble in distinguishing theemotion at sentence level.
Mixed emotioncategory, general and low intensity types givepoor agreement results as expected.
Instead ofspecifying agreement results of emoticons foreach emotion class, the average results for thethree annotation sets are shown in Table 1.3.3 Agreement of Emotional ExpressionsEmotional expressions are words or strings ofwords that are selected by the annotators.
Theagreement is carried out between the sets oftext spans selected by the two annotators foreach of the emotional expressions.
As there isno fixed category in this case, we have em-ployed two different strategies instead ofkappa () to calculate the agreement betweenannotators.
Firstly, we chose the measure ofagreement on set-valued items (MASI) (Pas-sonneau, 2006) that was used for measuringagreement on co reference annotation (Passon-neau, 2004) and in the semantic and pragmaticannotation (Passonneau, 2006).
MASI is a dis-tance between sets whose value is 1 for identi-cal sets, and 0 for disjoint sets.
For sets A andB it is defined as: MASI = J * M, where theJaccard metric is:50J = | | / | |A B A B Monotonicity (M) is defined as,1,2 / 3,1/ 3, , ,0,ifA BifA BorB AifA B A B andB AifA B       Secondly, the annotators will annotate dif-ferent emotional expressions by identifying theresponsible text anchors and the agreement ismeasured using agr metric (Wiebe et al,2005).
If A and B are the sets of anchors anno-tated by annotators a and b, respectively, agr isa directional measure of agreement that meas-ures what proportion of a was also marked byb.
Specifically, we compute the agreement of bto a as:( || )agr a b | || |AmatchingBAThe agr (a|| b) metric corresponds to the re-call if a is the gold standard and b the system,and to precision, if b is the gold standard and ais the system.
The results of two agreementstrategies for each emotion class are shown inTable 1.
The annotation agreement ofemotional expressions produces slightly lessvalues for both kappa and agr.
It leads to thefact that the relaxed annotation scheme that isprovided for fixing the boundaries of theexpressions causes the disagreements.4 Identifying Emotion HolderThe source or holder of an emotional expres-sion is the speaker or writer or experiencer.The main criteria considered for annotatingemotion holders are based on the nested sourcehypothesis as described in (Wiebe et al,2005).
The structure of Bengali blog corpus (asshown in Figure 2) helps in the holder annota-tion process.
Sometimes, the comments of oneblogger are annotated by other bloggers in theblog posts.
Thus the holder annotation task inuser comments sections was less cumbersomethan annotating the holders inscribed in thetopic section.Classes(# Sentencesor Instances)Agreement (pair of annota-tors)A1-A2  A2-A3  A1-A3  Avg.Emotion /Non-Emotion(5,234/7,087)0.88  0.83 0.86 0.85Happy   (804)  0.79  0.72  0.83 0.78Sad        (826)  0.82 0.75 0.72 0.76Anger    (765)  0.75 0.71  0.69  0.71Disgust  (766) 0.76  0.69 0.77 0.74Fear       (757) 0.65  0.61 0.65 0.63Surprise (822)  0.84 0.82 0.85 0.83Mixed (322) 0.42 0.21 0.53 0.38High  (2,330) 0.66 0.72 0.68 0.68General(1,765)0.42 0.46 0.48 0.45Low (1345) 0.21 0.34 0.26 0.27Emoticonsw.r.t six Emo-tion Classes(678)0.85 0.73 0.84 0.80Emoticonsw.r.t three In-tensities0.72 0.66 0.63 0.67Emotional Ex-pressions(7,588)[MASI]0.64 0.61 0.66 0.63Emotional Ex-pressions(7,588)  [agr]0.67 0.63 0.68 0.66Table 1: Inter-Annotator Agreements for sen-tence level Emotions, Intensities, Emoticonsand Emotional Expressions-<DOC docid = xyz>-<Topic>?.
</Topic>-<User Comments>-<U uid=1>?
</U>-<U uid=2>?
</U>-<U uid=3>?.-<U uid=1>?
</U> ?</U>?</User Comments></DOC>?Figure.
2.
General structure of a blog docu-ment?Prior work in identification of opinion hold-ers has sometimes identified only a singleopinion per sentence (Bethard et al, 2004),51and sometimes several (Choi et al, 2005).
Asthe blog corpus has sentence level emotionannotations, the former category is adopted.But, it is observed that the long sentences con-tain more than one emotional expression andhence associated with multiple emotion hold-ers (EH).
All probable emotion holders of asentence are stored in an anchoring vector suc-cessively according to their order of occur-rence.The annotation of emotion holder at sen-tence level requires the knowledge of two ba-sic constraints (implicit and explicit) sepa-rately.
The explicit constraints qualify singleprominent emotion holder that is directly in-volved with the emotional expression whereasthe implicit constraints qualify all direct andindirect nested sources as emotion holders.
Forexample, in the following Bengali sentences,the pattern shown in bold face denotes theemotion holder.
In the second example, theappositive case (e.g.
 !
(Ram?s pleasure))is also identified and placed in the vector byremoving the inflectional suffix (-e  in thiscase).
Example 2 and Example 3 contain theemotion holders  (Ram) and 		 -(Nasrin Sultana) based on implicit constraints.Example 1.
EH_Vector: < >"#$	        a	"(Sayan)     (bhishon)     (anondo)      (anubhob)+-(korechilo)Sayan felt very happy.Example 2.
EH_Vector: < 5,  >5      a	"+-        (Rashed) (anubhob) (korechilo) (je)   (Ramer)!
a6#(sukh) (antohin)Rashed   felt that Ram?s pleasure is endless.Example 3.
EH_Vector: < '', 		 -> ''         - :     		  -(GeduChaCha) (bole) (ami) (Nasrin Sultanar)8!      9       ;-(dookher) (kathate)    (kende)   (feli)Gedu Chacha says: No my sister, I fall into cryon the sad speech of Nasrin Sultana4.1 Agreement of Emotion HolderAnnotationThe emotion holders containing multi wordNamed Entities (NEs) are assumed as singleemotion holders.
As there is no agreement dis-crepancy in selecting the boundary of the sin-gle or multiple emotion holders, we have usedthe standard metric, Cohen?s kappa () formeasuring the inter-annotator agreement.
Eachof the elementary emotion holders in an an-choring vector is treated as a separate emotionholder and the agreement between two annota-tors is carried out on each separate entity.
It isto be mentioned that the anchoring vectorsprovided by the two annotators may be dis-joint.To emphasize the fact, a different techniqueis employed to measure the annotation agree-ment.
If X is a set of emotion holders selectedby the first annotator and Y is a set of emotionholders selected by the second annotator for anemotional sentence containing multiple emo-tion holders, inter-annotator agreement IAAfor that sentence is equal to quotient of numberof emotion holders in X and Y intersectiondivided by number of emotion holders in Xand Y union:IAA = X  Y / X U YTwo types of agreement results per emotionclass for annotating emotion holders (EH) areshown in Table 2.
Both types of agreementshave been found satisfactory and the differencebetween the two agreement types is signifi-cantly less.
The small difference indicates theminimal error involved in the annotation proc-ess.
It is found that the agreement is highlymoderate in case of single emotion holder, butis less in case of multiple holders.
The dis-agreement occurs mostly in the case of satisfy-ing the implicit constrains but some issues areresolved by mutual understanding.5 Topic Annotation and AgreementTopic is the real world object, event, or ab-stract entity that is the primary subject of theopinion as intended by the opinion holder(Stoyanov and Cardie, 2008).
They mentionthat the topic identification is difficult withinthe single target span of the opinion as thereare multiple potential topics, each identified52with its own topic span and the topic of anopinion depends on the context in which itsassociated opinion expression occurs.
Hence,the actual challenge lies on identification of thetopics spans from the emotional sentences.
Thewriter?s emotional intentions in a sentence arereflected in the target span by mentioning oneor more topics that are related to the emotionalexpressions.
Topics are generally distributed indifferent text spans of writer?s text and can bedistinguished by capturing the rhetorical struc-ture of the text.EmotionClasses[# Sen-tences,# Holders]Agreement between pair of anno-tators () [IAA]A1-A2   A2-A3    A1-A3     Avg.Happy[804, 918](0.87)[0.88](0.79)[0.81](0.76)[0.77](0.80)[0.82]Sad[826, 872](0.82)[0.81](0.85)[0.83](0.78)[0.80](0.81)[0.81]Anger[765,780](0.80)[0.79](0.75)[0.73](0.74)[0.71](0.76)[0.74]Disgust[766, 770](0.70)[0.68](0.72)[0.69](0.83)[0.84](0.75)[0.73]Fear[757, 764](0.85)[0.82](0.78)[0.77](0.79)[0.81](0.80)[0.80]Surprise[822, 851](0.78)[0.80](0.81)[0.79](0.85)[0.83](0.81)[0.80]Table 2: Inter-Annotator Agreement for Emo-tion Holder AnnotationIn blog texts, it is observed that an emotiontopic can occur in nucleus as well as in satel-lite.
Thus, the whole sentence is assumed asthe scope for the potential emotion topics.
Thetext spans containing emotional expression andemotion holder can also be responsible for be-ing the candidate seeds of target span.
In Ex-ample 3 of Section 4, the target span (	-	 8! ?sad speech of Nasrin Sul-tana?)
contains emotion holder (		 -?Nasrin Sultana?)
as well as the emotional ex-pression (8! ?sad speech?)
For thatreason, the annotators are instructed to con-sider the whole sentence as their target spanand to identify one or more topics related tothe emotional expressions in that sentence.As the topics are multi word components orstring of words, the scope of the individualtopics inside a target span is hard to identify.To accomplish the goal, we have not used thestandard metrics Cohen?s kappa ().
We em-ployed MASI and agr metric (as mentioned inSection 3) for measuring the agreement oftopic spans annotation.
The emotional sen-tences containing single emotion topic hasshown less disagreement than the sentencesthat contain multiple topics.
It is observed thatthe agreement for annotating target span is (0.9).
It means that the annotation is almost sat-isfactory.
But, the disagreement occurs in an-notating the boundaries of topic spans.
Theinter-annotator agreement for each emotionclass is shown in Table 3.
The selection ofemotion topic from other relevant topicscauses the disagreement.EmotionClasses[# Sen-tences,# topics]Agreement  between Pair of annota-tors (MASI) [agr]A1-A2    A2-A3    A1-A3       AvgHappy[804, 848](0.83)[0.85](0.81)[0.83](0.79)[0.82](0.81)[0.83]Sad[826, 862](0.84)[0.86](0.77)[0.79](0.81)[0.83](0.80)[0.82]Anger[765,723](0.80)[0.78](0.81)[0.78](0.86)[0.84](0.82)[0.80]Disgust[766, 750](0.77)[0.76](0.78)[0.74](0.72)[0.70](0.75)[0.73]Fear[757, 784](0.78)[0.79](0.77)[0.80](0.79)[0.81](0.78)[0.80Surprise[822, 810](0.90)[0.86](0.85)[0.82](0.82)[0.80](0.85)[0.82]Table 3: Inter-Annotator Agreement for TopicAnnotation6 Experiments on Emotion Classifica-tionA preliminary experiment (Das and Bandyop-adhyay, 2009b) was carried out on a small setof 1200 sentences of the annotated blog corpususing Conditional Random Field (CRF)(McCallum et al, 2001).
We have employedthe same corpus and similar features (e.g.
POS,punctuation symbols, sentiment words etc.)
forclassifying the emotion words using SupportVector Machine (SVM) (Joachims, 1999).
Theresults on 200 test sentences are shown in Ta-ble 4.
The results of the automatic emotionclassification at word level show that SVMoutperforms CRF significantly.
It is observed53that both classifiers fail to identify the emotionwords that are enriched by morphological in-flections.
Although SVM outperforms CRF butboth CRF and SVM suffer from sequence la-beling and label bias problem with other non-emotional words of a sentence.
(For erroranalysis and detail experiments, see Das andBandyopadhyay, 2009b).Test Set EmotionClasses (# Words) CRF SVMHappy (106) 67.67 80.55Sad (143) 63.12       78.34Anger (70) 51.00 66.15Disgust (65) 49.75 53.35Fear (37) 52.46 64.78Surprise (204) 68.23 79.37Table 4: Word level Emotion tagging Accura-cies (in %) using CRF and SVMAnother experiment (Das and Bandyop-adhyay, 2009a) was carried out on a small setof 1300 sentences of the annotated blog cor-pus.
They assign any of the Ekman?s (1993)six basic emotion tags to the Bengali blog sen-tences.
Conditional Random Field (CRF)based word level emotion classifier classifiesthe emotion words not only in emotion or non-emotion classes but also the emotion wordsinto Ekman?s six emotion classes.
Corpusbased and sense based tag weights that are cal-culated for each of the six emotion tags areused to identify sentence level emotion tag.Sentence level accuracies for each emotionclass were also satisfactory.Knowledge resources can be leveraged inidentifying emotion-related words in text andthe lexical coverage of these resources may belimited, given the informal nature of onlinediscourse (Aman and Szpakowicz, 2007).
Theidentification of direct emotion wordsincorporates the lexicon lookup approach.
Arecently developed Bengali WordNet Affectlists (Das and Bandyopadhyay, 2010) havebeen used in determining the directly statedemotion words.
But, the affect lists covers only52.79% of the directly stated emotion words.The fact leads not only to the problem ofmorphological enrichment but also to refer theproblem of identifying emoticons, proverbs,idioms and colloquial or foreign words.
But, inour experiments, the case of typographical er-rors and orthographic features (for e.g.
i?disgusting?, b ?surprising?)
that express oremphasize emotion in text are not considered.7 ConclusionThe present task addresses the issues of identi-fying emotional expressions in Bengali blogtexts along with the annotation of sentenceswith emotional components such as intensity,holders and topics.
Nested sources are consid-ered for annotating the emotion holder infor-mation.
The major contribution in the task isthe identification and fixing the text spans de-noted for emotional expressions and multipletopics in a sentence.
Although the preliminaryexperiments carried out on the small sets of thecorpus show satisfactory performance, but thefuture task is to adopt a corpus-driven ap-proach for building a lexicon of emotion wordsand phrases and extend the emotion analysistasks in Bengali.ReferencesAman Saima and Stan Szpakowicz.
2007.
Identify-ing Expressions of Emotion in Text.
V. Ma-tou?ek and P. Mautner (Eds.
): TSD 2007, LNAI,vol.
4629, pp.196-205.Azar, M. 1999.
Argumentative Text as RhetoricalStructure: An Application of Rhetorical Struc-ture Theory.
Argumentation, vol 13, pp.
97?114.Bethard Steven, Yu H., Thornton A., Hatzivassi-loglou V., and Jurafsky, D. 2004.
Automatic Ex-traction of Opinion Propositions and their Hold-ers.
In AAAI Spring Symposium on ExploringAttitude and Affect in Text: Theories and Appli-cations.Carletta Jean.
1996.
Assessing Agreement on Clas-sification Tasks: The Kappa Statistic.
Computa-tional Linguistics, vol.
22(2), pp.249-254.Choi, Y., Cardie, C., Riloff, E., and Patwardhan, S.2005.
Identifying Sources of Opinions withConditional Random Fields and Extraction Pat-terns.
Human Language Technology / EmpiricalMethod in Natural Language Processing.Alm, Cecilia Ovesdotter, Dan Roth, and RichardSproat.
2005.
Emotions from text: Machinelearning for text-based emotion prediction.
Hu-man Language Technology - Empirical Methodin Natural Language Processing, pp.
579-586.54Cohen, J.
1960.
A coefficient of agreement fornominal scales.
Educational and PsychologicalMeasurement, vol.
20, pp.
37?46.Das Dipankar and Sivaji Bandyopadhyay.
2009a.Word to Sentence Level Emotion Tagging forBengali Blogs.
Association for ComputationalLinguistics ?International Joint Conference ofNatural Language Processing-2009, pp.
149-152.
Suntec, Singapore.Das Dipankar and Sivaji Bandyopadhyay.
2009b.Emotion Tagging ?
A Comparative Study onBengali and English Blogs.
7th InternationalConference On Natural Language Processing-09, pp.177-184, India.Das Dipankar and Sivaji Bandyopadhyay.
2010.Developing Bengali WordNet Affect for Analyz-ing Emotion.
International Conference on theComputer Processing of Oriental Languages-International Conference on Software Engineer-ing and Knowledge Engineering-2010, USA.Ekman, P. 1992.
An Argument for Basic Emotions.Cognition and Emotion.
vol.
6, pp.169?200.Joachims, Thorsten.
1998.
Text Categorization withSupport Machines: Learning with Many Rele-vant Features.
In European Conference on Ma-chine Learning (ECML),137-142Lin K.
H.-Y., C. Yang and H.-H. Chen.
2007.
WhatEmotions News Articles Trigger in Their Read-ers?.
Proceedings of SIGIR, pp.
733-734.Mann, W. C. and S. A. Thompson.
1988.
RhetoricalStructure Theory: Toward a Functional Theoryof Text Organization, TEXT 8, pp.
243?281.McCallum Andrew, Fernando Pereira and JohnLafferty.
2001.
Conditional Random Fields:Probabilistic Models for Segmenting and label-ing Sequence Data.
ISBN, 282 ?
289.Mihalcea Rada and Hugo Liu.
2006.
A corpus-based approach to finding happiness.
Associationfor the Advancement of Artificial Intelligence,pp.
139-144.Mishne Gilad.
2005.
Emotions from text: Machinelearning for text-based emotion prediction.SIGIR?05, pp.
15-19.Neviarouskaya Alena, Helmut Prendinger, and Mi-tsuru Ishizuka.
2007.
Textual Affect Sensing forSocial and Expressive Online Communication.2nd international conference on Affective Com-puting and Intelligent Interaction, pp.
218-229.Passonneau, R. 2004.
Computing reliability forcoreference annotation.
Language Resources andEvaluation, Lisbon.Passonneau, R.J. 2006.
Measuring agreement onset-valued items (MASI) for semantic and prag-matic annotation.
Language Resources andEvaluation.Quan Changqin and Fuji Ren.
2009.
Constructionof a Blog Emotion Corpus for Chinese Emo-tional Expression Analysis.
Empirical Method inNatural Language Processing- Association forComputational Linguistics, pp.
1446-1454, Sin-gaporeQuirk, R., Greenbaum, S., Leech, G., Svartvik, J.1985.
A Comprehensive Grammar of the EnglishLanguage.
Longman, New York.Stoyanov, V., and C. Cardie.
2008.
Annotating top-ics of opinions.
Language Resources andEvaluation.Tokuhisa Ryoko, Kentaro Inui, and Yuji.
Matsu-moto.
2008.
Emotion Classification Using Mas-sive Examples Extracted from the Web.
COL-ING 2008, pp.
881-888.Wiebe Janyce, Theresa Wilson, and Claire Cardie.2005.
Annotating expressions of opinions andemotions in language.
Language Resources andEvaluation, vol.
39, pp.164?210.Yang C., K. H.-Y.
Lin, and H.-H. Chen.
2007.Building Emotion Lexicon from Weblog Cor-pora.
Association for Computational Linguis-tics, pp.
133-136.55
