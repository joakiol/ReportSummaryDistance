Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 736?747,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsModelling Discourse Relations for ArabicAmal AlsaifUniversity of LeedsLeeds, UKLS2 9JTamalalsaif@yahoo.co.ukKatja MarkertUniversity of LeedsLeeds, UKLS2 9JTmarkert@comp.leeds.ac.ukAbstractWe present the first algorithms to automat-ically identify explicit discourse connectivesand the relations they signal for Arabic text.First we show that, for Arabic news, mostadjacent sentences are connected via explicitconnectives in contrast to English, making thetreatment of explicit discourse connectives forArabic highly important.
We also show thatexplicit Arabic discourse connectives are farmore ambiguous than English ones, makingtheir treatment challenging.
In the secondpart of the paper, we present supervised al-gorithms to address automatic discourse con-nective identification and discourse relationrecognition.
Our connective identifier basedon gold standard syntactic features achievesalmost human performance.
In addition, anidentifier based solely on simple lexical andautomatically derived morphological and POSfeatures performs with high reliability, essen-tial for languages that do not have high-qualityparsers yet.
Our algorithm for recognizing dis-course relations performs significantly betterthan a baseline based on the connective sur-face string alone and therefore reduces the am-biguity in explicit connective interpretation.1 IntroductionThe automatic detection of discourse relations, suchas causal, contrast or temporal relations, is useful formany applications such as automatic summarization(Marcu, 2000), question answering (Girju, 2003),sentiment analysis (Somasundaran et al, 2008) andreadability assessment (Pitler and Nenkova, 2008).This task has recently seen renewed interest due tothe growing availability of large-scale corpora anno-tated for discourse relations, such as the Penn Dis-course Treebank (Prasad et al, 2008a).In the Penn Discourse Treebank (PDTB), lo-cal discourse relations (also called senses) such asCAUSAL or CONTRAST are annotated.
They holdbetween two text segments (so-called arguments)that express abstract entities such as events, facts andpropositions.
Annotated discourse relations can besignalled explicitly by so-called discourse connec-tives (Marcu, 2000; Webber et al, 1999; Prasad etal., 2008a) or hold implicitly between adjacent sen-tences in the same paragraph, i.e.
are not signalledby a specific surface string.
In Ex.
1, the connec-tive while indicates an explicit CONTRAST betweenthe attitudes of John and Richard.
In Ex.
2, the con-nective while indicates an explicit TEMPORAL rela-tion.
In Ex.
3, an implicit CAUSAL relation betweenthe first and second sentence holds.
We indicate dis-course connectives and the two arguments they re-late via annotated square brackets.
(1) [John liked adventure,]Arg2 [ while]DC[Richardwas cautious]Arg2(2) [The children were cryingloudly]Arg1[while]DC,[their mother wascooking]Arg2(3) [I cannot eat any dessert.
]Arg1 [I have eaten fartoo much already.
]Arg2Although similar corpora for other languages arebeing developed such as for Hindi (Prasad et al,2008b), Turkish (Zeyrek and Webber, 2008), Chi-nese (Xue, 2005) and, by ourselves, for Arabic (Al-736Saif and Markert, 2010), efforts in the automatedrecognition of discourse connectives, arguments andrelations have so far almost exclusively centered onEnglish.In contrast we present the first models for dis-course relations for Arabic, focusing on explicit con-nectives.
This focus is partially justified by the factthat this first study for a new language should cen-ter on the superficially more straightforward caseand that no annotations for implicit relations are yetavailable for Arabic.
More importantly, however,we make two essential claims (Section 4).
Firstly,Arabic discourse connectives are more ambiguousthan their English counterparts, i.e cases such aswhile which can signal different relations dependenton context (see Example 1 and 2) are far more fre-quent.
This makes their treatment more challenging.Secondly, discourse relations between adjacent sen-tences in Arabic tend to be expressed via an explicitconnective, at least for the news genre, i.e.
casessuch as Example 3 are rarer.
This makes the treat-ment of explicit connectives essential.We tackle two tasks for explicit Arabic connec-tives in this paper, which are further discussed inSection 2.
Discourse connective recognition needsto distinguish between discourse usage of potentialconnectives and non-discourse usage (such as theuse of while as a noun).
We show in Section 5 thatwe can distinguish discourse- and non-discourse us-age for potential connectives in Arabic with veryhigh reliability, even without parsed data, a fact thatis important for languages with fewer high qualityNLP tools available.
We then present an algorithmfor relation identification in Section 6 that showssmall but significant gains over assigning the mostfrequent relation for each connective.
We discussfuture work and conclude in Section 7.2 The TasksThe handling of explicit connectives can be split intothree tasks (Pitler and Nenkova, 2009).
The first taskof discourse connective recognition distinguishesbetween the discourse usage and non-discourse us-age of potential connectives.
Whereas some poten-tial connectives such as the Arabic connective 	??
?/lkn/but almost always have discourse usage, this isnot true for all potential connectives.1 Thus, the dis-course usage of Arabic ?J.
?P /rg?bh/desire needs tobe distinguished from its use as a noun.
Conjunc-tions such as ?
/w/and,?
@ /a?w/or can have discourseusage or just conjoin two non-abstract entities as in?PA?
?
Q??
/?mr w sa?rh/Omar and Sarah.The second task is discourse connective interpre-tation where a discourse connective in context is as-signed a discourse relation.
Again, some connec-tives are largely unambiguous in this respect.
Forexample, 	???
/lkn/but signals almost always a CON-TRAST relation.
However, there are connectiveswhere this is not the case, such as 	Y 	J?
/mnd?/sincewhich has a CAUSAL and a TEMPORAL sense.The third task is argument identification whichidentifies the arguments?
position and extent.
In thispaper we tackle Task 1 and Task 2 for Arabic in asupervised machine learning framework.3 Related workAnnotated Discourse Corpora and LinguisticBackground.
Discourse relations are widely stud-ied in theoretical linguistics (Halliday and Hasan,1976; Hobbs, 1985), where also different relationtaxonomies have been derived (Hobbs, 1985; Knottand Sanders, 1998; Mann and Thompson, 1988;Marcu, 2000).
Different inventories have been usedin English corpora annotated for discourse relations(Hobbs, 1985; Prasad et al, 2008a; Carlson et al,2002) which also differ in other respects (such aswhether they prescribe a tree structure for discourseannotation).
However, the annotation level of ex-isting Arabic corpora has not yet included the dis-course layer, making our work the first to addressthis problem for Arabic on a larger scale.Automatic discourse parsing: explicit relations.There is no work on discourse connective recog-nition, interpretation and argument assignment forArabic, so that we break entirely new ground here.However, the two tasks we explore (discourse con-nective recognition and discourse connective disam-biguation) have been tackled for English.2 (Pitler1Arabic examples contain in order: the Arabic right-to-leftscript, the transliteration (standards ISO/R 233 and DIN 31635)and the English translation (if possible).2There is also substantial work on argument identification(Wellner and Pustejovski, 2007; Elwell and Baldridge, 2008)737and Nenkova, 2009) use gold standard syntactic fea-tures as well as the connective surface string in asupervised model for discourse connective recogni-tion.
They achieve very high results with this ap-proach.
We will (i) show that similar features workwell for Arabic (ii) take into account Arabic-specificmorphological properties that improve results fur-ther and (iii) present a robust version of this ap-proach that does not rely on full parsing or gold stan-dard syntactic annotations.With regard to discourse connective interpreta-tion, (Miltsakaki et al, 2005) concentrate on disam-biguating the three connectives since, while, whenonly, using a very small set of features indicatingtense and temporal markers in arguments.
Theyachieve good improvements over a ?most frequentrelation per connective?
baseline.
A more compre-hensive study on all discourse connectives in thePDTB (Pitler et al, 2008; Pitler and Nenkova, 2009)reveals that most connectives are not ambiguous inEnglish.
Using syntactic features of the connec-tive, they achieve only a very small improvementover a ?most frequent relation per connective base-line?
for which significance tests are not given.
Wewill show that for Arabic, discourse connectives aremore highly ambiguous with regard to the relationsthey convey.
We will present a supervised learningmodel that uses a wider feature set and that achievessmall but significant improvements over the mostfrequent relation per connective baseline.Automatic discourse parsing: implicit relations.Implicit relations have excited substantial interestfor English.
This includes work in the frame-work of RST (Soricut and Marcu, 2003; duVerleand Prendinger, 2009; Marcu and Echihabi, 2002),SDRT (Baldridge and Lascarides, 2005), Graph-Bank (Wellner et al, 2006), the PDTB (Blair-Goldensohn et al, 2007; Pitler et al, 2009; Linet al, 2009; Wang et al, 2010; Zhou et al,2010; Louis and Nenkova, 2010) or framework-independent (Sporleder and Lascarides, 2008).3 Thetask is challenging as implicits behave substantiallydifferently from explicits (Sporleder and Lascarides,but we do not discuss this work in depth here.3Some work does not make the distinction between implicitand explicit and/or treats them in a joint framework (Soricut andMarcu, 2003; Wellner et al, 2006; Wang et al, 2010).2008) and often need world knowledge (Lin etal., 2009).
However, features/approaches that haveshown improvement over a baseline are word pairs(Sporleder and Lascarides, 2008), production rulesand syntactic trees (Wang et al, 2010; Lin et al,2009) as well as language modelling (Zhou et al,2010).
As we only deal with explicit connectivesthis work is not directly comparable to ours, al-though we do explore some of the suggested featuresfor improving explicit connective disambiguation.4 An Arabic Discourse CorpusWe annotate news articles from the Arabic PennTreebank (Part 1 v2.0) (Maamouri and Bies, 2004)for explicitly marked discourse relations.
This is thefirst discourse-annotated corpus for Arabic, whoseinitial development stages we have described in (Al-Saif and Markert, 2010).
We summarize this previ-ous work and extend it by including agreement stud-ies for arguments in Sections 4.1 and 4.2.
In Sec-tions 4.3, 4.4 and 4.5. we then present a corpus studyon the corpus which shows our major claim as to theimportance and high levels of ambiguity of Arabicdiscourse connectives.4.1 Annotation PrinciplesWe overall follow the annotation principles in thePenn Discourse Treebank for explicit connectives(for example, arguments can occur at any distancefrom the connectives).
The relation set we use isa more coarse-grained version of the PDTB rela-tions with two relations added ?
BACKGROUNDand SIMILARITY ?
that we found in our Arabicnews texts.
The final, hierarchically organized, re-lation set of 17 discourse relations is shown in Fig 1.Further adaptations necessary for Arabic are theinclusion of clitics as connectives such as ?
/l/for, H./b/by,with and 	?
/f/then .
In addition, differently toEnglish, prepositions were included as connectivesas these are frequently used to express discourse re-lations in Arabic.
In these cases, normally argument2 is the so-called Al-Masdar.4 Typical examples are????
/ws.
wl/arrival from the verb ???
/ws.
/to ar-rive and ???Am?
/mh.
a?wlh/attempt from the verb ?
?Ag4The medieval Arabic grammar schools, the Basra and Kufa,debated whether the noun (almasdar) or the verb is the mostbasic element of language (Ryding, 2005).738Figure 1: Discourse relations for Arabic/h.
a?wl/to try.
Al-Masdar is formed using morpho-logical patterns well-known in the Arabic grammat-ical tradition: major Arabic grammars list around 60patterns although some other references also claimthat the patterns are many more as well as more un-predictable (Abdl al latif et al, 1997; Wright, 2008;Ryding, 2005).
Al-Masdar forms do not fit into onegrammatical or morphological category in English:they might correspond to a gerund, a nominalizationor a noun which is not a nominalization.
Some ex-amples are listed in Table 1.Table 1: A list of Al-MaSdar patterns, examples and theirEnglish correspondenceRoot Pattern MaSdar TranslationiJ.?
/sbh.
??A?
?
/f?alh ?kAJ.?
/sbah.
h swimmingY?K /nfd?
?J?
?K /tf?yl 	YJ?
JK /tnfyd?
execution?
?X /df?
?A?
?
/f?
?al ?A 	?X /dfa??
defence?P 	P /zr?
??A?
?
/f?
?alh ??
@P 	P /zra?
?h agricultureH.
Qk /h.
rb ??
?
/f?l H. Qk /h.
rb warAn example of Al-MaSdar as argument of a dis-course relation is Ex.
4, where 	?J?J.
K/tblyg?/informingis the Al-MaSdar form of 	??K.
/blg?/inform.
(4) 	?@Y?
?
??
?J?J.
J?]DC[?]
Arg1[??Q???
@ 	Q?Q?
??
@ AJJ.?X]Arg2[?J???Q?
@??Q???
@?KAK?[d?hbna?
?la?
mrkz al-s?rt.t.]Arg1[l]DC[ltblyg?
?n fqda?nwt?a?
?iq als?rkh alrsmyh]Arg2[We went to the police station]Arg1 [for]DC [in-forming about the loss of the company?s officialdocuments.
]Arg24.2 Agreement StudiesThe occurrences of a precompiled list of 107 po-tential discourse connectives were annotated inde-pendently by 2 native Arabic speakers on 537 newstexts.
Agreement was measured for the distinctionof discourse vs. non-discourse usage, relation as-signment and argument assignment.Agreement for the classification tasks of dis-course connective recognition and relation assign-ment was measured using kappa (Siegel and Castel-lan, 1956).
Argument agreement was measured byagr, a directional measure (Wiebe et al, 2005).
Itmeasures the word overlap between the text spansof two judges (ann1 and ann2).
agr(ann1||ann2)measures the proportion of words ann1 annotatedthat were also annotated by ann2.agr(ann1||ann2) = |ann1 matching ann2||ann1|Discourse connective recognition proved to behighly reliable with percentage agreement of 0.95and a kappa of 0.88 on the 23,331 occurrences ofthe 107 potential discourse connectives.
5586 of thepotential connectives were agreed on by both anno-tators to have discourse usage and agreement for re-lations and argument assignment was measured onthese.
As shown in Table 2, kappa on all 17 relationswas low with 0.57 ?
it turned out that this was dueto the frequent, almost rhetorical use of the connec-tive ?
/w/and at the beginning of paragraphs, whichis a genre convention for Arabic news that normallydoes not convey a specific discourse relation.
Disre-garding such occurrences of ?
/w/and, kappa rises togood agreement: 0.69 for fine-grained relations and0.75 when measuring agreement between the 4 ma-jor relations EXPANSION, CONTINGENCY, COM-PARISON and TEMPORAL.Argument agreement on the 5586 agreed connec-tives is shown in Table 3.
We report high word over-lap via agr (over 90%) for Arg2, which is the ar-gument syntactically attached to the connective, andlesser but still substantial agreement for Arg1.739Table 2: Inter-annotator reliability for discourse relationassignmentAll connectives (5586)Observed agreement 0.66Kappa 0.57Class levelObserved agreement 0.8Kappa 0.67Connectives excluding ?
/w/and at BOP (3500)Observed agreement 0.74Kappa 0.69Class levelObserved agreement 0.71Kappa 0.75Agreed disc.
conn 5586Arg1 Arg2a) exact matchexact match =1 2361 (42%) 3803 (68%)exact match =0 699 (13%) 18 (0.3%)partial match 2526 (45%) 1765 (32%)b) agr metricagr(ann1||ann2) 78% 93%agr(ann2||ann1) 74% 93%Avr (agr) 76% 93%Table 3: Inter-annotator reliability for arguments Arg1and Arg2, using two different measurements (a) exactmatch (b) agr4.3 Gold standardWe produced a unified gold standard.
First, we auto-matically corrected easily made annotator mistakes.With regard to argument extent, we automaticallycorrected mistakes such as the erroneous inclusionof punctuation marks at the end of clauses/sentencesor not including all obligatory complements in averb phrase argument.
The latter relied on the syn-tactic annotation in the ATB.
Second, with regard todiscourse relation assignment, we automatically as-signed EXPANSION.CONJUNCTION to all disagreedinstances of ?
/w/and at BOP.5 A further disam-biguation study is necessary for ?
/w/and at BOP,which is beyond the scope of this paper.Finally, an adjudicator not initially involved in an-notation reconciled the remaining disagreements at5Other instances of ?
/w/and are not treated this way.all levels and included annotations for 5 new po-tential discourse connective types not in our initialconnective list but commented on by the annotatorsduring annotation.
3 news files were removed fromthe corpus ?
they contained no actual news reportsbut just a list of headlines.The final discourse treebank we use has 6328 an-notated explicit connectives in 534 files.
68 connec-tive types were found, rising to 80 connective typesif we include all modified forms of a connective asdistinct types such as 	??
?
?Q?AK.
/ba?lrg?m mn, 	?
@ ?
?P/rg?m a?n as modified forms of ?
?P /rg?m/although.Most discourse connectives were only annotatedwith a single relation but 5% were annotated withtwo or more relations (as also allowed in the PDTB).These statistics are summarised in Table 4.Files 534Total tagged tokens 126,046(125KB)Sentences 3607Paragraphs 3312Discourse connectives (tokens) 6328Distinct connective (types) 68including modifed form con-nectives80Clitic discourse connectives (to-kens)4779(76%)Non-clitic discourse connec-tives (tokens)1549(24%)Relations types (17 single, 38combined)55Single relations (tokens) 6039(95%)Combined relations (tokens) 289 (5%)Table 4: Statistics of the final gold standard corpus4.4 Importance of explicitly signalled relationsWe compared the number of relations between 2adjacent sentences that were explicitly signalled inEnglish vs. the ones that were explicitly signalledin Arabic, using the PDTB and our corpus (bothcontaining texts of the news genre).
Out of a total44,470 adjacent sentence pairs in the PDTB, 5355740(12%) were linked by an explicit connective.6 Incontrast, out of the 3073 adjacent sentence pairs inour corpus, 2140 (70%) were linked by an explicitconnective, 948 (30%) were linked via non-wa con-nectives.
Thus, for our corpus, modeling of explicitconnectives is primary: intrasentential relations tendto be marked by connectives anyway in both Englishand Arabic, and our corpus shows that this is true formost local intersentential relations as well.4.5 Ambiguity for Arabic discourse connectivesWe investigate the ambiguity of Arabic connectiveswith regard to their sense at class level (4 relations)as well as the more fine-grained level (all 17 rela-tions).
We restrict our investigation to the connec-tive occurrences that were annotated with a singlerelation (6039 tokens) and also exclude ?
/w/and atthe beginning of paragraph, leaving 3813 tokens.7Of 80 connective types, 52 were unambiguous at theclass level and 47 at the fine-grained level.
However,many of the most frequent connectives are highlyambiguous.
If we just assign the most frequent read-ing to each of the 3813 connectives, we achieve anaccuracy of 82.7% at the class-level and 74.3% atthe more fine-grained level for relation assignment,leaving a substantial error margin.
This contrastswith the English PDTB, where at the class-level 92%can be achieved with this simple method and 85% atthe second-level.85 Discourse Connective RecognitionWe distinguished discourse vs. non-discourse usagefor all potential connectives in the 534 gold stan-dard files.
As headers and footers in the news filesnever contained true discourse connectives, we dis-regarded these, leaving 20,312 potential discourseconnectives of which 6328 are actual connectives.6Connections between subclauses or phrases in different,adjacent sentences were included in the count.7We automatically assigned CONJUNCTION to many occur-rences of ?
/w/and at BOP (Section 4.3) so that it is not sensibleto include these occurrences in a study of human-assigned am-biguity.8The second level in the PDTB with its 16 relations corre-sponds approximately to our fine-grained inventory.
This com-parison can only be appropriate due to slight differences in thelower-grained relation inventory.5.1 FeaturesApart from the surface string of the potential con-nective Conn, we use the following features.
Fea-tures are either extracted from raw files tokenizedby white space only (M2) or from raw files tok-enized by white space and tagged by the Stanfordtagger9 (Models M3, M4) or from the Arabic Tree-bank (ATB) gold standard part-of-speech and parseannotation (models M5-M9).
The syntactic features(Syn) are inspired by (Pitler and Nenkova, 2009).Lexical/POS patterns of surrounding words, cliticfeatures and Al-Masdar are novel.Surface Features (SConn).
These include the po-sition of the potential connective (sentence-initial,medial or final).
The type of the potential connectiveis Simple when the potential connective is a singletoken not attached to other tokens, PotClitic whenit is attached.
Potential connectives containing morethan one token have MoreThanToken type.Models where we use ATB or automated tagging(M3-M9) distinguish further between potential cli-tics that are assigned a POS and ones that are not.Models that use ATB annotation also distinguishbetween potential connectives that correspond to aphrase in the ATB (MorethanToken Phrase) andthe ones that do not (MorethanToken NonPhrase).Lexical features of surrounding words (Lex).We encode the surface strings of the three wordsbefore and after the connective, recording posi-tion.
These features are especially useful for lan-guages where no accurate parser or tagger is avail-able as lexical patterns can capture discourse andnon-discourse usage.
For instance, if a potentialconnective is followed by 	?
@ /a?n/ it most likely hasa discourse function (see Ex.
5).
(5) DC[ ? ]
Arg1[ ?A?PBAK.
@?K.
A??
@] 	????
?A 	?
?B@ 	?@@??AJK??
@X @??@PY?
@ ?Cg Arg2[?A?
J?AK.
@?Q?
??@]@YJk.
[ a?n a?la?t.fa?l ymkn [a?n ys.
a?bwa?
ba?la?rha?-q]Arg1[w]DC[a?n ys??rwa?
ba?ln?
?as]Arg2 h?la?l a?ldra?sha?d?a?
lm yna?mwa?
g?yda?
[Children might be tired]Arg1 [and]DC [feelsleepy]Arg2 during school time if they did not sleepwell9http://nlp.stanford.edu/software/tagger.shtml741Part of Speech features (POS).
We includethe pos tag of the potential connective via theATB/Stanford Tagger.
For potential connectives thatconsist of more than one token, we combined itsordered POS tags.
Thus, the potential connective?Ag ??
/fy h. a?l/in case with its tags (fy PREP)(HalNOUN)) will receive the pos PREP#NOUN.
If a po-tential connective does not receive a separate POStag in the ATB/tagger, the value ?NONE?
is as-signed.
This allows to distinguish clitics from let-ters at the start of a word.
We also record thePOS of the three words before/after the connective(ATB/Stanford Tagger).
Similar to lexical patterns,these can capture discourse and non-discourse us-age.
For instance, if a potential connective is soonfollowed by a modal, it is more likely to have a dis-course function.Syntactic category of related phrases (Syn).
Werecord the syntactic category of the parent of the po-tential connective in ATB.
For example, it is rarethat cases where the parent of the potential connec-tive is an adjective phrase, correspond to discourse-usage.
A typical example of a non-discourse usageof ?
/w/and ( ??J?g.
?
?QJ.?
??PY??
@ /a?lmdrsh kbyrh wg?mylh/ the school is very large and beautiful) illus-trates this.
Unlike English, parents in Arabic oftenare noun phrases as nominalisations are frequent ar-guments of prepositional connectives.
We also en-code the Left sibling category and right sibling cat-egory of the connective.
For discourse connectives,the right sibling is normally S, SBAR, VP or an NP(if the connective is a preposition).Al-Masdar feature.
Potential connectives fol-lowed by Al-Masdar are more likely to have dis-course usage (see Section 4.1).
Especially preposi-tions with discourse usage are normally attached toAl-masdar such as in ?KXAj??
/lmh.
a?dt?h/for contactingor Z @Qk.
AK.
/ba?g?ra?
?/by processing.
Al-Masdar informa-tion is not included in the ATB so we constructed abinary Al-Masdar feature from (tagged) text by ex-amining the first noun after the potential connective.We developed an algorithm to judge such a noun asAl-Masdar or not.
This algorithm uses a stemmerfor Arabic and then determines whether the stem isal-Masdar by a combination of surface-based rulesto check whether the stem corresponds to one of theknown Al-Masdar patterns.5.2 Results and DiscussionWe used the implementation JRip of the rule-based classifier Ripper in the machine learning toolWEKA with its default settings.
We used 10-foldcross-validation throughout.
Significance tests arereported using the McNemar test at the significancelevel of 1%.
A most frequent category baselinewould assign all potential connectives as not connec-tive, achieving an accuracy of 68.9% as only 6328 ofour potential 20,312 connectives actually have dis-course usage.
We built several models using differ-ent features.
The results are shown in Table 5.A simple model M1 that only uses the connectivestring improves significantly over the baseline with75.7% accuracy but a kappa of only 0.48, showingthat this is not a reliable strategy.
Models M2-M4do not rely on gold standard annotation or parsing(in contrast to the models for English in (Pitler andNenkova, 2009)).
Using only surface and lexicalfeatures that can be extracted from white-space to-kenized raw files in addition to the connective string(M2), gains a substantial improvement over usingthe connective string alone.
This is further improvedby using POS tags of connectives and surroundingwords with an automatic tagger (M3) and by includ-ing the Al-Masdar feature (M4), thus making gooduse of the morphological properties of Arabic.
Alldifferences are statistically significant (M1 < M2 <M3 < M4).
The final model is reliable (kappa 0.70),an encouraging result given the absence of parsingand important for resource-scarce languages.With ATB gold standard tokenisation, tagging andparsing, our models (not surprisingly) improve fur-ther showing the same pattern of (M1 < M5 < M6 <M7) with all differences being significant.
The finalbest model achieves highly reliable results (accuracy92.4%, kappa 0.82).
We also conclude that syntac-tic features are more useful than lexical patterns asmodel M8 (syntax with no lexical patterns) achievesequally good results as M6.
Our models also man-age to generalise well over individual connectives.If we leave out the connective string (M9), we stillachieve a highly reliable result.6 Discourse Relation RecognitionWhen disambiguating the relation that discourseconnectives signal, we assume that the arguments of742Features Acurr KBaseline (not conn) 68.9 0M1 Conn only 75.7 0.48Tokenization by white space + auto taggerM2 Conn+ SConn+Lex 85.6 0.62M3 Conn+ SConn+Lex+POS 87.6 0.69M4 Conn+SConn+Lex+POS+Masdar 88.5 0.70ATB-based featuresM5 Conn+SConn+Lex 86.2 0.65M6 Conn+SConn+Lex+Syn/POS 91.2 0.79M7 Conn+SConn+Lex+Syn/POS+Masdar 92.4 0.82M8 Conn+SConn+Syn 91.2 0.79M9 SConn+Lex+Syn+Masdar 91.2 0.79Table 5: Performance of different models for identifying discourse connectives.the connective are known.
This is well-establishedfor PDTB relation recognition (Wang et al, 2010;Lin et al, 2009; Miltsakaki et al, 2005).
Our mod-els predict single relations on two datasets: (i) allinstances of connectives signalling single relations(Set All, 6039 instances) (2) all instances apart fromthe connective ?
/w/and at beginning of paragraphas they are affected by the auto-correction process(Set no-wa-atBOP, 3813 instances).
We use 10-foldcross-validation and JRip as well as a McNemar testat the 5% level for significance tests.6.1 FeaturesWhereas some of the features we use have been usedfor English implicit relation recognition (Lin et al,2009; Wang et al, 2010; Pitler et al, 2009) , theyare new for Arabic and not widely used for explicitconnectives.
All features are extracted from the ATBgold standard parses.Connective features.
This includes the connec-tive string Conn.
In addition, we also use the sur-face connective features and POS of connective de-scribed in Section 5.
We also use the syntactic pathto the connective as a novel feature.Words and POS of arguments.
The words andpos tags of the first three words in Arg1 andArg2 are used to catch patterns in arguments.For example, when the first word of Arg2 isY?
/qd/might/may or 	?A?
/ka?n/had, the relation islikely to be EXPANSION.BACKGROUND or EXPAN-SION.CONJUNCTION.
We also measure word over-lap between the arguments, hoping to catch relationssuch as COMPARISON.SIMILARITY.Masdar.
This feature states whether the first orsecond word in Arg 2 is an Al-Masdar.
Many prepo-sitional connectives followed by an Al-Masdar indi-cate a CONTINGENCY.CAUSE relation (see Ex.
4)Tense and Negation.
Each argument is assignedits tense as one of perfect, imperfect, future or none.We also indicate whether the tense of Arg1 or 2 arethe same and whether a negation is part of Arg 1or 2.
Inspired by (Miltsakaki et al, 2005), we stip-ulate that tense is useful for recognizing temporaland causal relations.
For example, the arguments ofthe relation TEMPORAL.SYNCHRONOUS are likelyto have the same tense.
In contrast, arg1 tense ismore likely to be prior to arg2 tense for TEMPO-RAL.ASYNCHRONOUS and CAUSE relations.Length, Distance and Order Features.
We usethe length of arguments (in words), word distancebetween a connective and its arguments (-1; for ar-guments in order Arg1 Conn Arg2 Arg1), tree dis-tance of connective and arguments (0 if connectiveand an argument are in the same tree) and a bi-nary feature of whether Arg1 and Arg2 are in dif-ferent sentences.
A nominal feature encodes one ofthe three orders Arg1 Conn Arg2, Conn Arg2 Arg1and Arg1 Conn Arg2 Arg1, the latter being fre-quent in Arabic for TEMPORAL.ASYNCHRONOUSrelations.Argument Parent.
We record the syntactic par-ent of each Argument.
However, not every argu-743ment corresponds to a complete tree in the ATB ?in these cases we extract the category of the parentshared by the first and last word in the argument.Production Rules.
We use all non-lexical produc-tion rules that occur more than 10 times in the argu-ments as binary features.
This was inspired by (Linet al, 2009) who use production rules to good effectfor implicit relations in English.6.2 ResultsTable 6 shows the results for fine-grained (17 rela-tions) classification.
The baseline of assigning themost frequent relation EXPANSION.CONJUNCTIONto every connective performs with an accuracy of52.5% on Set All and 35% on set no-wa-atBOP.
Ifwe use a model that relies on the discourse connec-tive alone (M1) we achieve results of 77.2%/74.3%,respectively.
As noted in Section 4.5 this is substan-tially lower than what the same model can achievefor English.
Including connective and argument fea-tures (apart from production rules) in M2, leads to asmall but significant improvement.10 Further incor-poration of production rules does not improve theresults (M3).
In Table 7, we show the results at theclass-level (4 relations).
Here using additional fea-tures over the connective string does not lead to sig-nificant improvements.6.3 Discussion and Error AnalysisWe concentrate our discussion on fine-grained clas-sification excluding wa at BOP.Our improvements in M2 over the connective-only classifier (M1) are in two main areas.
First, ourmodel performs generalisation, i.e.
outputs somerules that do not use the connective string at all.These achieve a somewhat surprising improvementof M2 over M1 for unambiguous connectives whichare too rare to classify via the connective string.
Inthose cases, they either (i) have not been seen in thetraining data before and are therefore not classifiablewhen seen first time in the test set or (ii) have been10Our corpus includes some texts on similar topics wheresome sentences are (almost) repeated in different texts.
Toinvestigate whether our improvements are due to this repeti-tion, we also performed an experiment excluding all repeatedinstances of feature vectors from the corpus.
The results arealmost the same and, most importantly, M2 again improves sig-nificantly over M1.Ref Features Acc KAll connectives (6039)Baseline (CONJUNCTION) 52.5 0M1 Conn only (1) 77.2 0.60M2 Conn+Conn f+ Arg f (37) 78.8 0.66M3 Conn+Conn f+ Arg f+ Pro-duction rules (1237)78.3 0.65excluding wa at BOP (3813)Baseline (CONJUNCTION) 35 0M1 Conn only (1) 74.3 0.65M2 Conn+Conn f+ Arg f (37) 77 0.69M3 Conn+Conn f+ Arg f+ Pro-duction rules (1237)76.7 0.69Table 6: Performance of different models for identifyingfine-grained discourse relations on two datasets.Ref Features Acc KAll connectives (6039)Baseline (EXPANSION) 62.4 0M1 Conn only (1) 88.7 0.78M2 Conn+Conn f+ Arg f (37) 88.7 0.78excluding wa at BOP (3813)Baseline (EXPANSION) 41.8 0M1 Conn only (1) 82.7 0.74M2 Conn+Conn f+ Arg f (37) 83.5 0.75Table 7: Performance of different models for identifyingclass-level discourse relations on two datasets.seen in the training data too rarely for the rule-basedclassifier to develop a rule judged to be more re-liable than the default EXPANSION.CONJUNCTIONclassification.
Our data includes 47 unambiguousconnective types, accounting for 574 of the 3813tokens.
30 of these 47 types are so rare that wefound mistakes in the connective-only classification,including B@ /a?la?/except (2), I.
??
/?qb(2), A??
A?
/t.a?-lma?
(2), ?
?QK.
/brg?m(1).
For 14 of these 30 connec-tives, model M2 was able to use generalised rulesto improve relation assignment.11 These rules in-volve mainly connective surface and POS features.Thus, sentence-start adverbials consisting of morethan one token such as 	?
@ YJK.
/byd a?n(6) and 	?
@ Q?/g?yr a?n(6) were correctly classified as CONTRAST.11For the other 16 connectives neither of the models was ableto classify them correctly.744This advantage of our model over the connective-only model might disappear if in a larger corpusmore instances of those connectives are foundand are still unambiguous.
Therefore, we aremore interested in how our classifier does ontruly ambiguous connectives (33 connective typesaccounting for 3239 tokens of 3813 overall to-kens).
We conducted a separate significance teston ambiguous connectives only and found thatM2 improves over M1 classification significantlyat the 1% level.
How well we do on individualconnectives depends on their frequency and on theirlevel of ambiguity.
If connectives are ambiguousand of low frequency (??
/lw, A?
?
@ /a?nma?, ?Ag /h.
a?l/)both M1 and M2 do perform badly on them.
Ifconnectives are frequent (10 or more occurrences)and have relatively low ambiguity (majority readingaccounts for more than 70% of instances), theoverall performance of M1 and M2 with regard toaccuracy is also similar, often both using just theconnective string.
On the other hand, if connectivesare frequent and have high ambiguity (i.e.
no suchclear majority reading), then M2 normally improves(often substantially) on M1.
Examples of suchconnectives are A??
/kma?, A?J?
/fyma?and QK@ /a?t?r.Most of the successful rules use tense in some form,either via part of speech of verbs or via comparingthe tense in the two arguments.
This, for example,led to a successful recognition of all 9 instances ofSimilarity in the connective kmA (whose major-ity relation is Expansion.Conjunction in 40 outof 65 occurrences).
The connective 	?
/f/then is dis-tinguished into EXPANSION.EXEMPLIFICATION,CONTINGENCY.CAUSE.RESULT and CONTIN-GENCY.CAUSE.REASON readings, depending onthe lexemes around it, the parents of its arguments,and whether its argument 2 is tensed or not.
Thus,nontensed arguments are most often nominalisationsleading to a reason reading, whereas a verb phraseas argument 2 and a sentence as argument 1 often isa result reading.
However, it is worth reporting thatin cases of very high ambiguity, M2 is still far fromperfect such as for connectives f 	?
/fand QK@ /a?t?r.Some improvements again come from gener-alised rules: there are some very high-coverageand high precision generalised rules that reducedependency on the connective string.
For example,clitic prepositions (such as ?
/l/for) can withoutany further information be clearly classified asContingency.Cause.Reason.NonPragmaticcovering 494 occurrences with only 26 mistakes.These are cases where the following argument isnormally Al-Masdar.Our analysis leads us to the following strategyfor follow-on work.
First of all, a larger corpus isnecessary to get more examples for low frequencyconnectives.
Secondly, experiments with differentclassifiers are worthwhile to conduct to see how ourimprovements generalise.
Third, the most mileageis in further improvements on frequent, ambiguousconnectives such as 	?
/f, 	Y 	J?
/mnd?and ?
@ /a?w.
Thiscan be achieved with, on the one hand, trainingconnective-specific classifiers on larger data sets butwill, on the other hand, also need a wider featurebase.
From our corpus study, we think that lexico-semantic features such as word pairs and seman-tic classes of verbal/nominalised arguments are themost promising.7 Conclusions and Future WorkWe have presented the first study on the automaticdetection and disambiguation of Arabic discourseconnectives.
A corpus study showed that theseare highly frequent and more ambiguous than theirEnglish counterparts.
Our automatic algorithmsachieve very good results on discourse connectiveidentification, using Arabic morphological proper-ties to good effect.
It is particular promising that wedo not need parsed data to identify discourse usageof potential connectives reliably.
Our algorithm fordiscourse connective interpretation beats the chal-lenging baseline of assigning the most frequent re-lation per connective.
In future, we will explore fur-ther features for connective disambiguation as wellas connective-specific classification, combined withsemi-supervised algorithms to alleviate data sparse-ness.
We will also develop algorithms for argumentidentification.AcknowledgmentsAmal Al-Saif is supported by a PhD scholarship fromthe Imam Muhammad Ibn Saud University, Saudi Arabia.We thank the British Academy for additional funding forthe annotation study via Grant SG51944.
Also thank youto the 3 anonymous reviewers for their comments.745ReferencesM.
Abdl al latif, A. Umar, and M. Zahran.
1997.
AlnhwAlAsAsi.
Dar Alfker Al-Arabi, Cairo, Egypt.A.
AlSaif and K. Markert.
2010.
The leeds arabic dis-course treebank: Annotating discourse connectives forarabic.
In Language Resources and Evaluation Con-ference (LREC).J.
Baldridge and A. Lascarides.
2005.
Probabilistic head-driven parsing for discourse structure.
In Proc.
OfConll 2005.S.
Blair-Goldensohn, K McKeown, and O. Rambow.2007.
Building and refining rhetorical-semantic rela-tion models.
In Proc.
of HLT-NAACL 2007.L.
Carlson, D. Marcu, and M. Okurewski.
2002.
Rstdiscourse treebank.
Linguistic Data Consortium.D.
duVerle and H. Prendinger.
2009.
A novel discourseparser based on support vector machine classification.In Proc.
of ACL 2009.R.
Elwell and J. Baldridge.
2008.
Discourse connec-tive argument identification with connective specificrankers.
In Proc.
of the International Conference onSemantic Computing.R.
Girju.
2003.
Automatic detection of causal relationsfor questions answering.
In Proc.
of the ACL 2003Workshop on Multilingual Summarisation and Ques-tion Answering, pages 76?83.M.A.K.
Halliday and R. Hasan.
1976.
Cohesion in En-glish.
Longman London.J.R.
Hobbs.
1985.
On the coherence and structure ofdiscourse.
Center for the Study of Language and In-formation, Stanford, Calif.A.
Knott and T. Sanders.
1998.
The classification ofcoherence relations and their linguistic markers: Anexploration of two languages.
Journal of Pragmatics,30(2):135?175.Z.
Lin, M. Kan, and H.T.
Ng.
2009.
Recognizing implicitdiscourse relations in the penn discourse treebank.
InProc.
of EMNLP 2009, pages 343?351.A.
Louis and A. Nenkova.
2010.
Creating local coher-ence: An empirical assessment.
In Proc.
of NAACL2010.M.
Maamouri and A. Bies.
2004.
Developing an Ara-bic treebank: Methods, guidelines, procedures, andtools.
In Proceedings of the Workshop on Computa-tional Approaches to Arabic Script-based Languages(COLING), Geneva.W.C.
Mann and S.A. Thompson.
1988.
Rhetorical struc-ture theory: Toward a functional theory of text organi-zation.
Text, 8(3):243?281.D.
Marcu and A. Echihabi.
2002.
An unsupervised ap-proach to recognizing discourse relations.
In Proc.
ofACL 2002.D.
Marcu.
2000.
The theory and practice of discourseparsing and summarization.
MIT Press.E.
Miltsakaki, N. Dinesh, R. Prasad, A. Joshi, andB.
Webber.
2005.
Experiments on sense annotationand sense disambiguation of discourse connectives.
InProc.
of the Workshop on Treebanks and LinguisticTheories.E.
Pitler and A. Nenkova.
2008.
Revisiting readabil-ity: A unified framework for predicting text quality.
InProc.
of EMNLP 2008, pages 186?195.E.
Pitler and A. Nenkova.
2009.
Using syntax to dis-ambiguate explicit discourse connectives.
In Proc ofACL-IJCNLP 2009 (Short Papers), pages 13?16.E.
Pitler, M. Raghupathy, H. Mehta, A. Nenkova, A. Lee,and A. Joshi.
2008.
Easily identifiable discourserelations.
In Proceedings of the 22nd InternationalConference on Computational Linguistics (COLING2008), Manchester, UK, August.E.
Pitler, A. Louis, and A. Nenkova.
2009.
Automaticsense prediction for implicit discourse relations in text.In Proc.
of ACL-IJCNLP 2009, pages 683?691.R.
Prasad, N. Dinesh, A. Lee, E. Miltsakaki, L. Robaldo,A.
Joshi, and B. Webber.
2008a.
The Penn discoursetreebank 2.0.
In Proceedings of the 6th InternationalConference on Language Resources and Evaluation(LREC 2008).R.
Prasad, S. Husain, D.M.
Sharma, and A. Joshi.
2008b.Towards an Annotated Corpus of Discourse Relationsin Hindi.
In The Third International Joint Conferenceon Natural Language Processing, pages 7?12.
Cite-seer.K.C.
Ryding.
2005.
A reference grammar of modernstandard Arabic.
Cambridge Univ Pr.S.
Siegel and N.J. Castellan.
1956.
Nonparametricstatistics for the behavioral sciences.
McGraw-HillNew York.S.
Somasundaran, J. Wiebe, and J. Ruppenhofer.
2008.Discourse-level opinion interpretation.
In Proc.
ofColing 2008.R.
Soricut and D. Marcu.
2003.
Sentence level dis-course parsing using syntactic and lexical information.In Proc of HLT-NAACL 2003.C.
Sporleder and A. Lascarides.
2008.
Using auto-matically labelled examples to classify rhetorical rela-tions: An assessment.
Natural Language Engineering,14:369?416.W.
Wang, J. Su, and C. Tan.
2010.
Kernel-based dis-course relation recognition with temporal ordering in-formation.
In Proc.
of ACL 2010, pages 710?719.B.
Webber, A. Knott, M. Stone, and A. Joshi.
1999.Discourse relations: A structural and presuppositionalaccount using lexicalised TAG.
In Proceedings of746the 37th annual meeting of the Association for Com-putational Linguistics on Computational Linguistics,page 48.
Association for Computational Linguistics.B.
Wellner and J. Pustejovski.
2007.
Automaticallyidentifying the arguments of discourse connectives.
InProc.
of EMNLP 2007, pages 92?101.B.
Wellner, J. Pustejovski, A. Havasi, A. Rumshisky, andR.
Suair.
2006.
Classification of discourse coherencerelations: An exploratory study using multiple knowl-edge sources.
In Proc.
of SIGDIAL2006.Janyce Wiebe, Theresa Wilson, and Claire Cardie.
2005.Annotating expressions of opinions and emotions inlanguage.
Language Resources and Evaluation.W.
Wright.
2008.
A grammar of the Arabic language.Bibliobazaar.Nianwen Xue.
2005.
Annotating discourse connectivesin the chinese treebank.
In CorpusAnno ?05: Proceed-ings of the Workshop on Frontiers in Corpus Annota-tions II, pages 84?91, Morristown, NJ, USA.
Associa-tion for Computational Linguistics.D.
Zeyrek and B. Webber.
2008.
A discourse resourcefor turkish: Annotating discourse connectives in themetu corpus.
Proceedings of IJCNLP-2008.
Hyder-abad, India.Z.
Zhou, Y. Xu, Z. Niu, M. Lan, .
Su, and Tan.
C. 2010.Predicting discourse connectives for implicit discourserelation recognition.
In Proc.
of Coling 2010, pages1507?1514.747
