Proceedings of the ACL-HLT 2011 System Demonstrations, pages 103?108,Portland, Oregon, USA, 21 June 2011. c?2011 Association for Computational LinguisticsAn Efficient Indexer for Large N-Gram CorporaHakan CeylanDepartment of Computer ScienceUniversity of North TexasDenton, TX 76203hakan@unt.eduRada MihalceaDepartment of Computer ScienceUniversity of North TexasDenton, TX 76203rada@cs.unt.eduAbstractWe introduce a new publicly available toolthat implements efficient indexing and re-trieval of large N-gram datasets, such as theWeb1T 5-gram corpus.
Our tool indexes theentire Web1T dataset with an index size ofonly 100 MB and performs a retrieval of anyN-gram with a single disk access.
With anincreased index size of 420 MB and dupli-cate data, it also allows users to issue wildcard queries provided that the wild cards in thequery are contiguous.
Furthermore, we alsoimplement some of the smoothing algorithmsthat are designed specifically for large datasetsand are shown to yield better language mod-els than the traditional ones on the Web1T 5-gram corpus (Yuret, 2008).
We demonstratethe effectiveness of our tool and the smooth-ing algorithms on the English Lexical Substi-tution task by a simple implementation thatgives considerable improvement over a basiclanguage model.1 IntroductionThe goal of statistical language modeling is to cap-ture the properties of a language through a proba-bility distribution so that the probabilities of wordsequences can be estimated.
Since the probabilitydistribution is built from a corpus of the languageby computing the frequencies of the N-grams foundin the corpus, the data sparsity is always an issuewith the language models.
Hence, as it is the casewith many statistical models used in Natural Lan-guage Processing (NLP), the models give a muchbetter performance with larger data sets.However the large data sets, such as the Web1T5-Gram corpus of (Brants and Franz, 2006), presenta major challenge.
The language models built fromthese sets cannot fit in memory, hence efficient ac-cessing of the N-gram frequencies becomes an is-sue.
Trivial methods such as linear or binary searchover the entire dataset in order to access a singleN-gram prove inefficient, as even a binary searchover a single file of 10,000,000 records, which isthe case of the Web1T corpus, requires in the worstcase dlog2(10, 000, 000)e = 24 accesses to the diskdrive.Since the access to N-grams is costly for theselarge data sets, the implementation of further im-provements such as smoothing algorithms becomesimpractical.
In this paper, we overcome this problemby implementing a novel, publicly available tool1that employs an indexing strategy that reduces theaccess time to any N-gram in the Web1T corpus to asingle disk access.
We also make a second contribu-tion by implementing some of the smoothing modelsthat take into account the size of the dataset, and areshown to yield up to 31% perplexity reduction on theBrown corpus (Yuret, 2008).
Our implementation isspace efficient, and provides a fast access to both theN-gram frequencies, as well as their smoothed prob-abilities.2 Related WorkLanguage modeling toolkits are used extensively forspeech processing, machine translation, and manyother NLP applications.
The two of the most pop-ular toolkits that are also freely available are theCMU Statistical Language Modeling (SLM) Toolkit(Clarkson and Rosenfeld, 1997), and the SRI Lan-guage Modeling Toolkit (Stolcke, 2002).
However,1Our tool can be freely downloaded from the download sec-tion under http://lit.csci.unt.edu103even though these tools represent a great resourcefor building language models and applying them tovarious problems, they are not designed for verylarge corpora, such as the Web1T 5-gram corpus(Brants and Franz, 2006), hence they do not provideefficient implementations to access these data sets.Furthermore, (Yuret, 2008) has recently shownthat the widely popular smoothing algorithms forlanguage models such as Kneser-Ney (Kneser andNey, 1995), Witten-Bell (Witten and Bell, 1991), orAbsolute Discounting do not realize the full poten-tials of very large corpora, which often come withmissing counts.
The reason for the missing countsis due to the omission of low frequency N-grams inthe corpus.
(Yuret, 2008) shows that with a modifiedversion of Kneser-Ney smoothing algorithm, namedas the Dirichlet-Kneser-Ney, a 31% reduction in per-plexity can be obtained on the Brown corpus.A tool similar to ours that uses a hashing tech-nique in order to provide a fast access to the Web1Tcorpus is presented in detail in (Hawker et al, 2007).The tool provides access to queries with wild cardsymbols, and the performance of the tool on 106queries on a 2.66 GHz processor with 1.5 GBytesof memory is given approximately as one hour.
An-other tool, Web1T5-Easy, described in (Evert, 2010),provides indexing of the Web1T corpus via rela-tional database tables implemented in an SQLite en-gine.
It allows interactive searches on the corpus aswell as collocation discovery.
The indexing time ofthis tool is reported to be two weeks, while the non-cached retrieval time is given to be in order of a fewseconds.
Other tools that implement a binary searchalgorithm as a simpler, yet less efficient method arealso given in (Giuliano et al, 2007; Yuret, 2007).3 The Web1T 5-gram CorpusThe Web1T 5-gram corpus (Brants and Franz, 2006)consists of sequences of words (N-grams) and theirassociated counts extracted from a Web corpus ofapproximately one trillion words.
The length of eachsequence, N , ranges from 1 to 5, and the size of theentire corpus is approximately 88GB (25GB in com-pressed form).
The unigrams form the vocabularyof the corpus and are stored in a single file whichincludes around 13 million tokens and their associ-ated counts.
The remaining N-grams are stored sep-arately across multiple files in lexicographic order.For example, there are 977,069,902 distinct trigramsin the dataset, and they are stored consecutively in98 files in lexicographic order.
Furthermore, eachN-gram file contains 10,000,000 N-grams except thelast one, which contains less.
It is also important tonote that N-grams with counts less than 40 are ex-cluded from the dataset for N = 2, 3, 4, 5, and thetokens with less than 200 are excluded from the un-igrams.4 The Indexer4.1 B+-treesWe used a B+-tree structure for indexing.
A B+-tree is essentially a balanced search tree where eachnode has several children.
Indexing large files us-ing B+ trees is a popular technique implementedby most database systems today as the underlyingstructure for efficient range queries.
Although manyvariations of B+-trees exist, we use the definition forprimary indexing given in (Salzberg, 1988).
There-fore we assume that the data, which is composed ofrecords, is only stored in the leaves of the tree andthe internal nodes store only the keys.The data in the leaves of a B+-tree is groupedinto buckets, where the size of a bucket is deter-mined by a bucket factor parameter, bkfr.
Thereforeat any given time, each bucket can hold a number ofrecords in the range [1, bkfr].
Similarly, the num-ber of keys that each internal node can hold is deter-mined by the order parameter, v. By definition, eachinternal node except the root can have any number ofkeys in the range [v, 2v], and the root must have atleast one key.
Finally, an internal node with k keyshas k + 1 children.4.2 Mapping Unigrams to Integer KeysA key in a B+-tree is a lookup value for a record,and a record in our case is an N-gram together withits count.
Therefore each line of an N-gram file inthe Web1T dataset makes up a record.
Since eachN-gram is distinct, it is possible to use the N-gramitself as a key.
However in order to reduce the stor-age requirements and make the comparisons fasterduring a lookup, we map each unigram to an inte-ger, and form the keys of the records using the inte-ger values instead of the tokens themselves.2To map unigrams to integers, we use the unigramssorted in lexicographic order and assign an integervalue to each unigram starting from 1.
In otherwords, if we let the m-tuple U = (t1, t2, ..., tm) rep-resent all the unigrams sorted in lexicographic order,2This method does not give optimal storage, for which oneshould implement a compression Huffman coding scheme.104then for a unigram ti, i gives its key value.
The keyof trigram ?ti tj tk?
is simply given as ?i j k.?
Thus,the comparison of two keys can be done in a similarfashion to the comparison of two N-grams; we firstcompare the first integer of each key, and in case ofequality, we compare the second integers, and so on.We stop the comparison as soon as an inequality isfound.
If all the comparisons result in equality thenthe two keys (N-grams) are equal.4.3 Searching for a RecordWe construct a B+-tree for each N-gram file in thedataset for N = 2, 3, 4, 5, and keep the key of thefirst N-gram for each file in memory.
When a queryq is issued, we first find the file that contains q bycomparing the key of q to the keys in memory.
Sincethis is an in-memory operation, it can be simplydone by performing a binary search.
Once the cor-rect file is found, we then search the B+-tree con-structed for that file for the N-gram q by using itskey.As is the case with any binary search tree, a searchin a B+-tree starts at the root level and ends in theleaves.
If we let ri and pj represent a key and apointer to the child of an internal node respectively,for i = 1, 2, ..., k and j = 1, 2, ..., k + 1, then tosearch an internal node, including the root, for a keyq, we first find the key rm that satisfies one of thefollowing:?
(q < rm) ?
(m = 1)?
(rm?1 ?
q) ?
(rm > q) for 1 < m ?
k?
(q > rm) ?
(m = k)If one of the first two cases is satisfied, the searchcontinues on the child node found by following pm,whereas if the last condition is satisfied, the pointerpm+1 is followed.
Since the keys in an internal nodeare sorted, a binary search can be performed to findrm.
Finally, when a leaf node is reached, the entirebucket is read into memory first, then a record witha key value of q is searched.4.4 Constructing a B+-treeThe construction of a B+-tree is performed throughsuccessive record insertions.3 Given a record, we3Note that this may cause efficiency issues for very largefiles as memory might become full during the construction pro-cess, hence in practice, the file is usually sorted prior to index-ing.first compute its key, find the leaf node it is supposedto be in, and insert it if the bucket is not full.
Other-wise, the leaf node is split into two nodes, each con-taining dbkfr/2e, and bbkfr/2c+1 records, and thefirst key of the node containing the larger key valuesis placed into the parent internal node together withthe node?s pointer.
The insertion of a key to an in-ternal node is similar, only this time both split nodescontain v values, and the middle key value is sent upto the parent node.Note that not all the internal nodes of a B+-treehave to be kept on the disk, and read from there eachtime we do a search.
In practice, all but the last twolevels of a B+-tree are placed in memory.
The rea-son for this is the high branching factor of the B+-trees together with their effective storage utilization.It has been shown in (Yao, 1978) that the nodes of ahigh-order B+-tree are ln2 ?
69% full on average.However, note that the tree will be fixed in ourcase, i.e., once it is constructed we will not be in-serting any other N-gram records.
Therefore we donot need to worry about the 69% space utilization,but instead try to make each bucket, and each in-ternal node full.
Thus, with a bkfr = 1250, andv = 100, an N-gram file with 10,000,000 recordswould have 8,000 leaf nodes on level 3, 40 inter-nal nodes on level 2, and the root node on level 1.Furthermore, let us assume that integers, disk andmemory pointers all hold 8 bytes of space.
There-fore a 5-gram key would require 40 bytes, and a fullinternal node in level 2 would require (200x40) +(201x8) = 9, 608 bytes.
Thus the level 2 would re-quire 9, 608x40 ?
384 Kbytes, and level 1 wouldrequire (40?40)+(41?8) = 1, 928 bytes.
Hence, aWeb1T 5-gram file, which has an average size of 286MB can be indexed with approximately 386 Kbytes.There are 118 5-gram files in the Web1T dataset, sowe would need 386x118 ?
46 MBytes of memoryspace in order to index all of them.
A similar calcu-lation for 4-grams, trigrams, and bigrams for whichthe bucket factor values are selected as 1600, 2000,and 2500 respectively, shows that the entire Web1Tcorpus, except unigrams, can be indexed with ap-proximately 100 MBytes, all of which can be keptin memory, thereby reducing the disk access to onlyone.
As a final note, in order to compute a keyfor a given N-gram quickly, we keep the unigramsin memory, and use a hashing scheme for mappingtokens to integers, which additionally require 178Mbytes of memory space.The choice of the bucket factor and the inter-105nal node order parameters depend on the hard-diskspeed, and the available memory.4.
Recall that evento fetch a single N-gram record from the disk, the en-tire bucket needs to be read.
Therefore as the bucketfactor parameter is reduced, the size of the index willgrow, but the access time would be faster as long asthe index could be entirely fit in memory.
On theother hand, with a too large bucket factor, althoughthe index can be made smaller, thereby reducing thememory requirements, the access time may be un-acceptable for the application.
Note that a randomreading of a bucket of records from the hard-diskrequires the disk head to first go to the location ofthe first record, and then do a sequential read.5 As-suming a hard-disk having an average transfer rateof 100 MBytes, once the disk head finds the correctlocation, a 40 bytes N-gram record can be read in4x10?7 seconds.
Thus, assuming a seek time around8-10 ms, even with a bucket factor of 1,000, it can beseen that the seek time is still the dominating factor.Therefore, as the bucket size gets smaller than 1,000,even though the index size will grow, there would bealmost no speed up in the access time, which justi-fies our parameter choices.4.5 Handling Wild Card QueriesHaving described the indexing scheme, and how tosearch for a single N-gram record, we now turn ourattention to queries including one or more wild cardsymbols, which in our case is the underscore char-acter ?
?, as it does not exist among the unigramtokens of the Web1T dataset.
We manually add thewild card symbol to our mapping of tokens to inte-gers, and map it to the integer 0, so that a search for aquery with a wild card symbol would be unsuccess-ful but would point to the first record in the file thatreplaces the wild card symbol with a real token asthe key for the wild card symbol is guaranteed to bethe smallest.
Having found the first record we per-form a sequential read until the last read record doesnot match the query.
The reason this strategy worksis because the N-grams are sorted in lexicographicorder in the data set, and also when we map unigramtokens to integers, we preserve their order, i.e., thefirst token in the lexicographically sorted unigramlist is assigned the value 1, the second is assigned4We used a 7200 RPM disk-drive with an average read seektime of 8.5 ms, write seek time of 10.0 ms, and a data transfertime up to 3 GBytes per second.5A rotational latency should also be taken into account be-fore the sequential reading can be done.2, and so forth.
For example, for a given query OurHonorable , the record that would be pointed at theend of search in the trigram file 3gm-0041 is the N-gram Our Honorable Court 186, which is the firstN-gram in the data set that starts with the bigramOur Honorable.Note however that the methodology that is de-scribed to handle the queries with wild card sym-bols will only work if the wild card symbols arethe last tokens of the query and they are contigu-ous.
For example a query such as Our Court willnot work as N-grams satisfying this query are notstored contiguously in the data set.
Therefore in or-der to handle such queries, we need to store addi-tional copies of the N-grams sorted in different or-ders.
When the last occurrence of the contiguouswild card symbols is in position p of a query N-gramfor p = 0, 1, ..., N ?
1, then the N-grams sorted lex-icographically starting from position (p + 1)modNneeds to be searched.
A lexicographical sort for aposition p, for 0 ?
p ?
(N ?
1) is performed bymoving all the tokens in positions 0...(p ?
1) to theend for each N-gram in the data set.
Thus, for allthe bigrams in the data set, we need one extra copysorted in position 1, for all the trigrams, we needtwo extra copies; one sorted in position 1, and an-other sorted in position 2, and so forth.
Hence, inorder to handle the contiguous wild card queries inany position, in addition to the 88 GBytes of origi-nal Web1T data, we need an extra disk space of 265GBytes.
Furthermore, the indexing cost of the du-plicate data is an additional 320 MBytes.
Thus, thetotal disk cost of the system will be approximately353 GBytes plus the index size of 420 MBytes, andsince we keep the entire index in memory, the finalmemory cost of the system will be 420 MBytes +178 MBytes = 598 MBytes.4.6 PerformanceGiven that today?s commodity hardware comes withat least 4 GBytes of memory and 1 TBytes of hard-disk space, the requirements of our tool are rea-sonable.
Furthermore, our tool is implemented ina client-server architecture, and it allows multipleclients to submit multiple queries to the server overa network.
The server can be queried with an N-gram query either for its count in the corpus, orits smoothed probability with a given smoothingmethod.
The queries with wild cards can ask forthe retrieval of all the N-grams satisfying a query, oronly for the total count so the network overhead can106be avoided depending on the application needs.Our program requires about one day of offlineprocessing due to resorting the entire data a fewtimes.
Note that some of the files in the corpusneed to be sorted as many as four times.
For thesorting process, the files are first individually sorted,and then a k-way merge is performed.
In our im-plementation, we used a min heap structure for thispurpose, and k is always chosen as the number offiles for a given N. The index construction howeveris relatively fast.
It takes about an hour to constructthe index for the 5-grams.
Once the offline process-ing is done, it only takes a few minutes to start theserver, and from that point the online performanceof our tool is very fast.
It takes about 1-2 seconds toprocess 1000 randomly picked 5-gram queries (withno wild card symbols), which may or may not existin the corpus.
For the queries asking for the fre-quencies only, our tool implements a small cachingmechanism that takes the temporal locality into ac-count.
The mechanism is very useful for wild cardqueries involving stop words, such as ?the ?, and?of the ?
which occur frequently, and take a longtime to process due to the sequential read of a largenumber of records from the data set.5 Lexical SubstitutionIn this section we demonstrate the effectiveness ofour tool by using it on the the English Lexical Sub-stitution task, which was first introduced in SemEval2007 (McCarthy and Navigli, 2007).
The task re-quires both the human annotators and the participat-ing systems to replace a target word in a given sen-tence with the most appropriate alternatives.
The de-scription of the tasks, the data sets, the performanceof the participating systems as well as a post analy-sis of the results is given in (McCarthy and Navigli,2009).Although the task includes three subtasks, in thisevaluation we are only concerned with one of them,namely the best subtask.
The best subtask asks thesystems and the annotators to provide only one sub-stitute for the target words ?
the most appropriateone.
Two separate datasets were provided with thistask: a trial dataset was first provided in order forthe participants to get familiar with the task and traintheir systems.
The trial data used a lexical sample of30 words with 10 instances each.
The systems werethen tested on a larger test data, which used a lexicalsample of 171 words each again having 10 instances.Our methodology for this task is very simple; weModel Precision Mod PrecisionNo Smoothing 10.13 14.78Absolute Discounting 11.05 16.75KN with Missing Counts 11.19 16.75Dirichlet KN 10.98 15.76Table 1: Results on the trial dataModel Precision Mod PrecisionNo Smoothing 9.01 14.15Absolute Discounting 11.64 18.62KN with Missing Counts 11.61 18.54Dirichlet KN 11.03 17.48Best Baseline 9.95 15.28Best SEMEVAL System 12.90 20.65Table 2: Results on the test datareplace the target word with an alternative from a listof candidates, and find the probability of the contextwith the new word using a language model.
The can-didate that gives the highest probability is providedas the system?s best guess.
The list of candidates isobtained from two different lexical sources, Word-Net (Fellbaum, 1998) and Roget?s Thesaurus (The-saurus.com, 2007).
We retrieve all the synonymsfor all the different senses of the word from both re-sources and combine them.
We did not consider anylexical relations other than synonymy, and similarlywe did not consider any words at a further semanticdistance.We start with a simple language model that cal-culates the probability of the context of a word,and then continue with three smoothing algorithmsdiscussed in (Yuret, 2008), namely Absolute Dis-counting, Kneser-Ney with Missing Counts, and theDirichlet-Kneser-Ney Discounting.
Note that allthree are interpolated models, i.e., they do not justback-off to a lower order probability when an N-gram is not found, but rather use the higher andlower order probabilities all the time in a weightedfashion.The results on the trial dataset are shown in Ta-ble 1, and the results on the test dataset are shownin Table 2.
In all the experiments we use the trigrammodels, i.e., we keep N fixed to 3.
Since our sys-tem makes a guess for all the target words in the set,our precision and recall scores, as well as the modprecision and the mod recall scores are the same,so only one from each is shown in the table.
Notethat the highest achievable score for this task is not100%, but is restricted by the frequency of the bestsubstitute, and it is given as 46.15%.
The highestscoring participating system achieved 12.9%, which107gave a 2.95% improvement over the baseline (Yuret,2008; McCarthy and Navigli, 2009); the scores ob-tained by the best SEMEVAL system as well as thebest baseline calculated using the synonyms for thefirst synset in WordNet are also shown in Table 2.On both the trial and the test data, we see that theinterpolated smoothing algorithms consistently im-prove over the naive language modeling, which isan encouraging result.
Perhaps a surprising resultfor us was the performance of the Dirichlet-Kneser-Ney Smoothing Algorithm, which is shown to giveminimum perplexity on the Brown corpus out of thegiven models.
This might suggest that the parame-ters of the smoothing algorithms need adjustmentsfor each task.It is important to note that this evaluation is meantas a simple proof of concept to demonstrate the use-fulness of our indexing tool.
We thus used a verysimple approach for lexical substitution, and did notattempt to integrate several lexical resources andmore sophisticated algorithms, as some of the bestscoring systems did.
Despite this, the performanceof our system exceeds the best baseline, and is betterthan five out of the eight participating systems (see(McCarthy and Navigli, 2007)).6 ConclusionsIn this paper we described a new publicly avail-able tool that provides fast access to large N-gramdatasets with modest hardware requirements.
Inaddition to providing access to individual N-gramrecords, our tool also handles queries with wild cardsymbols, provided that the wild cards in the queryare contiguous.
Furthermore, the tool also imple-ments smoothing algorithms that try to overcomethe missing counts that are typical to N-gram cor-pora due to the omission of low frequencies.
Wetested our tool on the English Lexical Substitutiontask, and showed that the smoothing algorithms givean improvement over simple language modeling.AcknowledgmentsThis material is based in part upon work sup-ported by the National Science Foundation CA-REER award #0747340 and IIS awards #0917170and #1018613.
Any opinions, findings, and conclu-sions or recommendations expressed in this materialare those of the authors and do not necessarily reflectthe views of the National Science Foundation.ReferencesT.
Brants and A. Franz.
2006.
Web 1T 5-gram corpusversion 1.
Linguistic Data Consortium.P.
Clarkson and R. Rosenfeld.
1997.
Statistical languagemodeling using the cmu-cambridge toolkit.
In Pro-ceedings of ESCA Eurospeech, pages 2707?2710.S.
Evert.
2010.
Google web 1t 5-grams made easy (butnot for the computer).
In Proceedings of the NAACLHLT 2010 Sixth Web as Corpus Workshop, WAC-6 ?10,pages 32?40.C.
Fellbaum, editor.
1998.
WordNet: An Electronic Lex-ical Database.
MIT Press, Cambridge, MA.C.
Giuliano, A. Gliozzo, and C. Strapparava.
2007.
Fbk-irst: lexical substitution task exploiting domain andsyntagmatic coherence.
In SemEval ?07: Proceedingsof the 4th International Workshop on Semantic Evalu-ations, pages 145?148.T.
Hawker, M. Gardiner, and A. Bennetts.
2007.
Practi-cal queries of a massive n-gram database.
In Proceed-ings of the Australasian Language Technology Work-shop 2007, pages 40?48, Melbourne, Australia.R.
Kneser and H. Ney.
1995.
Improved backing-off forn-gram language modeling.
In Acoustics, Speech, andSignal Processing, 1995.
ICASSP-95., 1995 Interna-tional Conference on, volume 1, pages 181?184 vol.1.D.
McCarthy and R. Navigli.
2007.
Semeval-2007 task10: English lexical substitution task.
In SemEval ?07:Proceedings of the 4th International Workshop on Se-mantic Evaluations, pages 48?53.D.
McCarthy and R. Navigli.
2009.
The english lexicalsubstitution task.
Language Resources and Evalua-tion, 43:139?159.B.
Salzberg.
1988.
File structures: an analytic ap-proach.
Prentice-Hall, Inc., Upper Saddle River, NJ,USA.A.
Stolcke.
2002.
SRILM ?
an extensible language mod-eling toolkit.
In Proceedings of ICSLP, volume 2,pages 901?904, Denver, USA.Thesaurus.com.
2007.
Rogets new millennium the-saurus, first edition (v1.3.1).I.
H. Witten and T. C. Bell.
1991.
The zero-frequencyproblem: Estimating the probabilities of novel eventsin adaptive text compression.
IEEE Transactions onInformation Theory, 37(4):1085?1094.A.
Chi-Chih Yao.
1978.
On random 2-3 trees.
Acta Inf.,9:159?170.D.
Yuret.
2007.
Ku: word sense disambiguation by sub-stitution.
In SemEval ?07: Proceedings of the 4th In-ternational Workshop on Semantic Evaluations, pages207?213.D.
Yuret.
2008.
Smoothing a tera-word language model.In HLT ?08: Proceedings of the 46th Annual Meet-ing of the Association for Computational Linguisticson Human Language Technologies, pages 141?144.108
