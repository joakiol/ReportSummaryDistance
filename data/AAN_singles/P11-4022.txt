Proceedings of the ACL-HLT 2011 System Demonstrations, pages 127?132,Portland, Oregon, USA, 21 June 2011. c?2011 Association for Computational LinguisticsC-Feel-It: A Sentiment Analyzer for Micro-blogsAditya Joshi1 Balamurali A R2 Pushpak Bhattacharyya1 Rajat Mohanty 31Dept.
of Computer Science and Engineering, IIT Bombay, Mumbai2 IITB-Monash Research Academy, IIT Bombay, Mumbai3 AOL India (R&D), BangaloreIndia{adityaj,balamurali,pb}@cse.iitb.ac.in r.mohanty@teamaol.comAbstractSocial networking and micro-blogging sitesare stores of opinion-bearing content createdby human users.
We describe C-Feel-It, a sys-tem which can tap opinion content in posts(called tweets) from the micro-blogging web-site, Twitter.
This web-based system catego-rizes tweets pertaining to a search string aspositive, negative or objective and gives an ag-gregate sentiment score that represents a senti-ment snapshot for a search string.
We presenta qualitative evaluation of this system basedon a human-annotated tweet corpus.1 IntroductionA major contribution of Web 2.0 is the explosive riseof user-generated content.
The content has been aby-product of a class of Internet-based applicationsthat allow users to interact with each other on theweb.
These applications which are highly accessibleand scalable represent a class of media called socialmedia.
Some of the currently popular social mediasites are Facebook (www.facebook.com), Myspace(www.myspace.com), Twitter (www.Twitter.com)etc.
User-generated content on the social media rep-resents the views of the users and hence, may beopinion-bearing.
Sales and marketing arms of busi-ness organizations can leverage on this informationto know more about their customer base.
In addi-tion, prospective customers of a product/service canget to know what other users have to say about theproduct/service and make an informed decision.C-Feel-It is a web-based system whichpredicts sentiment in micro-blogs onTwitter (called tweets).
(Screencast at:http://www.youtube.com/user/cfeelit/ ) C-Feel-It uses a rule-based system to classify tweets aspositive, negative or objective using inputs fromfour sentiment-based knowledge repositories.
Aweighted-majority voting principle is used to predictsentiment of a tweet.
An overall sentiment score forthe search string is assigned based on the results ofpredictions for the tweets fetched.
This score whichis represented as a percentage value gives a livesnapshot of the sentiment of users about the topic.The rest of the paper is organized as follows: Sec-tion 2 gives background study of Twitter and relatedwork in the context of sentiment analysis for Twitter.The system architecture is explained in section 3.
Aqualitative evaluation of our system based on anno-tated data is described in section 4.
Section 5 sum-marizes the paper and points to future work.2 Background studyTwitter is a micro-blogging website and ranks sec-ond among the present social media websites (Prelo-vac, 2010).
A micro-blog allows users to exchangesmall elements of content such as short sentences,individual pages, or video links (Kaplan and Haen-lein, 2010).
More about Twitter can be found here 1.In Twitter, a micro-blogging post is called atweet which can be upto 140 characters in length.Since the length is constrained, the language used intweets is highly unstructured.
Misspellings, slangs,contractions and abbreviations are commonly usedin tweets.
The following example highlights theseproblems in a typical tweet:?Big brother doing sian massey no favours.Let her ref.
She?s good at it you know#lifesapitch?We choose Twitter as the data source becauseof the sheer quantity of data generated and its fastreachability across masses.
Additionally, Twitter al-lows information to flow freely and instantaneouslyunlike FaceBook or MySpace.
These aspects of1http://support.twitter.com/groups/31-twitter-basics127Twitter makes it a source for getting a live snapshotof the things happenings on the web.In the context of sentiment classification of tweetsAlec et al (2009a) describes a distant supervision-based approach for sentiment classification.
Thetraining data for this purpose is created following asemi-supervised approach that exploits emoticons intweets.
In their successive work, Alec et al (2009b)additionally use hashtags in tweets to create train-ing data.
Topic-dependent clustering is performedon this data and classifiers corresponding to each aremodeled.
This approach is found to perform betterthan a single classifier alone.We believe that the models trained on data cre-ated using semi-supervised approaches cannot clas-sify all variants of tweets.
Hence, we follow a rule-based approach for predicting sentiment of a tweet.An approach like ours provides a generic way ofsolving sentiment classification problems in micro-blogs.3 Architecturekeyword (s)Tweet fetcherTweet SentimentPredictorC-Feel-ItSentiment scoreTweet SentimentCollaboratorscoreFigure 1: Overall ArchitectureThe overall architecture of C-Feel-It is shown inFigure 1.
C-Feel-It is divided into three parts: TweetFetcher, Tweet Sentiment Predictor and TweetSentiment Collaborator.
All predictions are pos-itive, negative or objective/neutral.
C-Feel-It offerstwo implementations of a rule-based sentiment pre-diction system.
We refer to them as version 1 and2.
The two versions differ in the Tweet SentimentPredictor module.
This section describes differentmodules of C-Feel-It and is organized as follows.
Insubsections 3.1, 3.2 & 3.3, we describe the threefunctional blocks of C-FeeL-It.
In subsection 3.4,we explain how four lexical resources are mappedto the desired output labels.
Finally, subsection 3.5gives implementation details of C-Feel-It.Input to C-Feel-It is a search string and a versionnumber.
The versions are described in detail in sub-section 3.2.Output given by C-Feel-It is two-level: tweet-wiseprediction and overall prediction.
For tweet-wiseprediction, sentiment prediction by each of the re-sources is returned.
On the other hand, overall pre-diction combines sentiment from all tweets to returnthe percentage of positive, negative and objectivecontent retrieved for the search string.3.1 Tweet FetcherTweet fetcher obtains tweets pertaining to a searchstring entered by a user.
To do so, we use live feedsfrom Twitter using an API 2.
The parameters passedto the API ensure that system receives the latest 50tweets about the keyword in English.
This API re-turns results in XML format which we parse using aJava SAX parser.3.2 Tweet Sentiment PredictorTweet sentiment predictor predicts sentiment fora single tweet.
The architecture of Tweet Senti-ment Predictor is shown in Figure 2 and can be di-vided into three fundamental blocks: Preprocessor,Emoticon-based Sentiment Predictor, Lexicon-basedSentiment Predictor (refer Figure 3 & 4).
The firsttwo blocks are same for both the versions of C-Feel-It.
The two versions differ in the working of theLexicon-based Sentiment Predictor.PreprocessorThe noisy nature of tweets is a classical challengethat any system working on tweets needs to en-counter.
Preprocessor deals with obtaining cleantweets.
We do not deploy any spelling correctionmodule.
However, the preprocessor handles exten-sions and contractions found in tweets as follows.Handling extensions: Extensions like ?besssssst?are common in tweets.
However, to look up re-sources, it is essential that these words are normal-ized to their dictionary equivalent.
We replace con-secutive occurrences of the same letter (if more than2http://search.Twitter.com/search.atom128Lexicon-based sentimentpredictorWord extensionhandlerTweetif no emoticonSentimentpredictionChat lingonormalizationEmoticon-basedsentimentpredictorTweet PreprocessingSentimentpredictionFigure 2: Tweet Sentiment Predictor: Version 1 and 2three occurrences of the same letter) with a singleletter and replace the word.An important issue here is that extensions are in factstrong indicators of sentiment.
Hence, we replace anextended word by two occurences of the contractedword.
This gives a higher weight to the extendedword and retains its contribution to the sentiment ofthe tweet.Chat lingo normalization: Words used inchat/Internet language that are common in tweets arenot present in the lexical resources.
We use a dictio-nary downloaded from http://chat.reichards.net/ .
Achat word is replaced by its dictionary equivalent.Emoticon-based Sentiment PredictorEmoticons are visual representations of emo-tions frequently used in the user-generated con-tent on the Internet.
We observe that in mostcases, emoticons pinpoint the sentiment of atweet.
We use an emoticon mapping fromhttp://chat.reichards.net/smiley.shtml.
An emoticonis mapped to an output label: positive or negative.
Atweet containing one of these emoticons that can bemapped to the desired output labels directly.
Whilewe understand that this heuristic does not work incase of sarcastic tweets, it does provide a benefit inmost cases.Lexicon-based Sentiment PredictorFor a tweet, the Lexicon-based Sentiment Predic-tor gives a prediction each for four resources.
Inaddition, it returns one prediction which combinesthe four predictions by weighting them on the ba-TweetLexical ResourceGetsentiment predictionFor all words Returnoutputlabelcorrespondingtomajority of wordsSentimentPredictionFigure 3: Lexicon-based Sentiment Predictor: C-Feel-ItVersion 1sis of their accuracies.
We remove stop words 3from the tweet and stem the words using Lovinsstemmer (Lovins, 1968).
Negation in tweets is han-dled by inverting sentiment of words after a negat-ing word.
The words ?no?, ?never?, ?not?
are consid-ered negating words and a context window of threewords after a negative words is considered for in-version.
The two versions of C-Feel-It vary in theirLexicon-based Sentiment Predictor.
Figure 3 showsthe Lexicon-based Sentiment Predictor for version1.
For each word in the tweet, it gets the predic-tion from a lexical resource.
We use the intuitionthat a positive tweet has positive words outnumber-ing other words, a negative tweet has negative wordsoutnumbering other words and an objective tweethas objective words outnumbering other words.Figure 4 shows the Lexicon-based Sentiment Predic-tor for version 2.
As opposed to the earlier version,version 2 gets prediction from the lexical resourcefor some words in the tweet.
This is because certainparts-of-speech have been found to be better indi-cators of sentiment (Pang and Lee, 2004).
A tweetis annotated with parts-of-speech tags and the POSbi-tags (i.e.
a pattern of two consecutive POS) aremarked.
The words corresponding to a set of opti-mal POS bi-tags are retained and only these wordsused for lookup.
The prediction for a tweet usesmajority vote-based approach as for version 1.
Theoptimal POS bi-tags have been derived experimen-tally by using top 10% features on information gain-based-pruning classifier on polarity dataset by (Pangand Lee, 2005).
We used Stanford POS tagger(Tou,3http://www.ranks.nl/resources/stopwords.html1292000) for tagging the tweets.Note: The dataset we use to find optimal POSbi-tags consists of movie reviews.
We understandthat POS bi-tags hence derived may not be universalacross domains.TweetLexical ResourceGet sentimentpredictionFor all wordsPOS tagthe tweetRetain words correspondReturnoutput label corresponding to majority of wordsSentimentPredictioncorresponding to select POSbi-tagsFigure 4: Lexicon-based Sentiment Predictor: C-Feel-ItVersion 23.3 Tweet Sentiment CollaboratorBased on predictions of individual tweets, the TweetSentiment Collaborator gives overall predictionwith respect to a keyword in form of percentageof positive, negative and objective content.
Thisis on the basis of predictions by each resource byweighting them according to their accuracies.
Theseweights have been assigned to each resource basedon experimental results.
For each resource, thefollowing scores are determined.posscore[r] =m?i=1piwpinegscore[r] =m?i=1niwniobjscore[r] =m?i=1oiwoiwhereposscore[r] = Positive score for search string rnegscore[r] = Negative score for search string robjscore[r] = Objective score for search string rm = Number of resources used for predictionpi, ni, oi = Positive,negative & objective count of tweetpredicted respectively using resource iwpi, wni, ooi = Weights for respective classes derivedfor each resource iWe normalize these scores to get the final positive, neg-ative and objective pertaining to search string r. Thesescores are represented in form of percentage.3.4 ResourcesSentiment-based lexical resources annotatewords/concepts with polarity.
The completenessof these resources individually remains a question.To achieve greater coverage, we use four differentsentiment-based lexical resources for C-Feel-It.
They aredescribed as follows.1.
SentiWordNet (Esuli and Sebastiani, 2006) assignsthree scores to synsets of WordNet: positive score,negative score and objective score.
When a word islooked up, the label corresponding to maximum ofthe three scores is returned.
For multiple synsets ofa word, the output label returned by majority of thesynsets becomes the prediction of the resource.2.
Subjectivity lexicon (Wiebe et al, 2004) is a re-source that annotates words with tags like parts-of-speech, prior polarity, magnitude of prior polarity(weak/strong), etc.
The prior polarity can be posi-tive, negative or neutral.
For prediction using thisresource, we use this prior polarity.3.
Inquirer (Stone et al, 1966) is a list of wordsmarked as positive, negative and neutral.
We usethese labels to use Inquirer resource for our predic-tion.4.
Taboada (Taboada and Grieve, 2004) is a word-listthat gives a count of collocations with positive andnegative seed words.
A word closer to a positiveseed word is predicted to be positive and vice versa.3.5 Implementation DetailsThe system is implemented in JSP (JDK 1.6) using Net-Beans IDE 6.9.1.
For the purpose of tweet annotation,an internal interface was written in PHP 5 with MySQL5.0.51a-3ubuntu5.7 for storage.4 System Analysis4.1 Evaluation DataFor the purpose of evaluation, a total of 7000 tweetswere downloaded by using popular trending topics of20 domains (like books, movies, electronic gadget, etc.
)as keywords for searching tweets.
In order to downloadthe tweets, we used the API provided by Twitter 4 thatcrawls latest tweets pertaining to keywords.Human annotators assigned to a tweet one out of 4classes: positive, negative, objective and objective-spam.4http://search.twitter.com/search.atom?130A tweet is assigned to objective-spam category if it con-tains promotional links or incoherent text which was pos-sibly not created by a human user.
Apart from these nom-inal class labels, we also assigned the positive/negativetweets scores ranging from +2 to -2 with +2 being themost positive and -2 being the most negative score re-spectively.
If the tweet belongs to the objective category,a value of zero is assigned as the score.The spam category has been included in the annotationas a future goal of modeling a spam detection layer priorto the sentiment detection.
However, the current versionof C-Feel-It does not have a spam detection module andhence for evaluation purpose, we use only the data be-longing to classes other than objective-spam.4.2 Qualitative AnalysisIn this section, we perform a qualitative evaluation of ac-tual results returned by C-Feel-It.
The errors describedin this section are in addition to the errors due to mis-spellings and informal language.
These erroneous resultshave been obtained from both version 1 and 2.
Theyhave been classified into eleven categories and explainedhenceforth.4.2.1 Sarcastic TweetsTweet: Hoge, Jaws, and Palantonio are brilliant to-gether talking X?s and O?s on ESPN right now.Label by C-Feel-It: PositiveLabel by human annotator: NegativeThe sarcasm in the above tweet lies in the use of a pos-itive word ?brilliant?
followed by a rather trivial action of?talking Xs and Os?.
The positive word leads to the pre-diction by C-Feel-It where in fact, it is a negative tweetfor the human annotator.4.2.2 Lack of Sense UnderstandingTweet: If your tooth hurts drink some pain killers andplace a warm/hot tea bag like chamomile on your toothand hold it.
it will relieve the painLabel by C-Feel-It: NegativeThis tweet is objective in nature.
The words ?pain?,?killers?, etc.
in the tweet give an indication to C-Feel-Itthat the tweet is negative.
This misguided implication isbecause of multiple senses of these words (for example,?pain?
can also be used in the sentence ?symptoms of thedisease are body pain and irritation in the throat?
whereit is non-sentiment-bearing).
The lack of understandingof word senses and being unable to distinguish betweenthem leads to this error.4.2.3 Lack of Entity SpecificityTweet: Casablanca and a lunch comprising of riceand fish: a good sundayKeyword: CasablancaLabel by C-Feel-It: PositiveLabel by human annotator: ObjectiveIn the above tweet, the human annotator understoodthat though the tweet contains the keyword ?Casablanca?,it is not Casablanca about which sentiment is expressed.The system finds a positive word ?good?
and marks thetweet as positive.
This error arises because the systemcannot find out which sentence/parts of sentence is ex-pressing opinion about the target entity.4.2.4 Coverage of ResourcesTweet: I?m done with this bullshit.
You?re the psychonot me.Label by SentiWordNet: NegativeLabel by Taboada/Inquirer: ObjectiveLabel by human annotator: NegativeOn manual verification, it was observed that an entryfor the emotion-bearing word ?bullshit?
is present in Sen-tiWordNet while Inquirer and Taboada resource do nothave them.
This shows that the coverage of the lexicalresource affects the performance of a system and may in-troduce errors.4.2.5 Absence of Named Entity RecognitionTweet: @user I don?t think I need to guess, but ok,close encounters of the third kind?
LolEntity: Close encounters of the third kindLabel by C-Feel-It: PositiveThe words comprising the name of the film ?Close en-counters of the third kind?
are also looked up.
Inability toidentify the named entity leads the system into this trap.4.2.6 Requirement of World KnowledgeTweet: The soccer world cup boasts an audience twicethat of the Summer Olympics.Label by C-Feel-It: NegativeTo judge the opinion of this tweet, one requires an un-derstanding of the fact that larger the audience, more fa-vorable it is for a sports tournament.
This world knowl-edge is important for a system that aims to handle tweetslike these.4.2.7 Mixed Emotion TweetsTweet: oh but that last kiss tells me it?s goodbye, justlike nothing happened last night.
but if i had one chance,i?d do it all over againLabel by C-Feel-It: PositiveThe tweet contains emotions of positive as well as neg-ative variety and it would in fact be difficult for a humanas well to identify the polarity.
The mixed nature of thetweet leads to this error by the system.4.2.8 Lack of ContextTweet: I?ll have to say it?s a tie between Little Womenor To kill a Mockingbird131Label by C-Feel-It: NegativeLabel by human user: PositiveThe tweet has a sentiment which will possibly be clearin the context of the conversation.
Going by the tweetalone, while one understands that an comparative opinionis being expressed, it is not possible to tag it as positiveor negative.4.2.9 Concatenated WordsTweet: To Kill a Mockingbird is a #goodbook.Label by C-Feel-It: NegativeThe tweet has a hashtag containing concatenatedwords ?goodbook?
which get overlooked as out-of-dictionary words and hence, are not used for sentimentprediction.
The sentiment of ?good?
is not detected.4.2.10 InterjectionsTweet: Oooh.
Apocalypse Now is on bluray now.Label by C-Feel-It: ObjectiveLabel by human user: PositiveThe extended interjection ?Oooh?
is an indicator ofsentiment.
Since it does not have a direct prior polar-ity, it is not present in any of the resources.
However, thisinterjection is an important carrier of sentiment.4.2.11 ComparativesTweet: The more years I spend at Colbert Heights..themore disgusted I get by the people there.
I?m soooo readyto graduate.Label by C-Feel-It: PositiveLabel by human user: NegativeThe comparatives in the sentence expressed by ?..moredisgusted I get..?
have to be handled as a special casebecause ?more?
is an intensification of the negative senti-ment expressed by the word ?disgusted?.5 Summary & Future WorkIn this paper, we described a system which categorizeslive tweets related to a keyword as positive, negativeand objective based on the predictions of four sentiment-based resources.
We also presented a qualitative evalua-tion of our system pointing out the areas of improvementfor the current system.A sentiment analyzer of this kind can be tuned to take in-puts from different sources on the internet (for example,wall posts on facebook).
In order to improve the qual-ity of sentiment prediction, we propose two additions.Firstly, while we use simple heuristics to handle exten-sions of words in tweets, a deeper study is required todecipher the pragmatics involved.
Secondly, a spam de-tection module that eliminates promotional tweets beforeperforming sentiment detection may be added to the cur-rent system.
Our goal with respect to this system is to de-ploy it for predicting share market values of firms basedon sentiment on social networks with respect to relatedentitites.AcknowledgementWe thank Akshat Malu and Subhabrata Mukherjee, IITBombay for their assistance during generation of evalua-tion data.ReferencesGo Alec, Huang Lei, and Bhayani Richa.
2009a.
Twit-ter sentiment classification using distant supervision.Technical report, Standford University.Go Alec, Bhayani Richa, Raghunathan Karthik, andHuang Lei.
2009b.
May.Andrea Esuli and Fabrizio Sebastiani.
2006.
SentiWord-Net: A publicly available lexical resource for opinionmining.
In Proceedings of LREC-06, Genova, Italy.Andreas M. Kaplan and Michael Haenlein.
2010.
Theearly bird catches the news: Nine things you shouldknow about micro-blogging.
Business Horizons,54(2):05 ?
113.Julie B. Lovins.
1968.
Development of a Stemming Al-gorithm.
June.Bo Pang and Lillian Lee.
2004.
A sentimental edu-cation: sentiment analysis using subjectivity summa-rization based on minimum cuts.
In Proceedings ofthe 42nd Annual Meeting on Association for Compu-tational Linguistics, ACL ?04, Stroudsburg, PA, USA.Association for Computational Linguistics.Bo Pang and Lillian Lee.
2005.
Seeing stars: Exploitingclass relationships for sentiment categorization withrespect to rating scales.
In Proceedings of ACL-05.Vladimir Prelovac.
2010.
Top social media sites.
Web,May.Philip J.
Stone, Dexter C. Dunphy, Marshall S. Smith,and Daniel M. Ogilvie.
1966.
The General Inquirer:A Computer Approach to Content Analysis.
MITPress.Maite Taboada and Jack Grieve.
2004.
Analyzing Ap-praisal Automatically.
In Proceedings of the AAAISpring Symposium on Exploring Attitude and Affect inText: Theories and Applications, pages 158?161, Stan-ford, US.2000.
Enriching the knowledge sources used in a maxi-mum entropy part-of-speech tagger, Stroudsburg, PA,USA.
Association for Computational Linguistics.Janyce Wiebe, Theresa Wilson, Rebecca Bruce, MatthewBell, and Melanie Martin.
2004.
Learning subjec-tive language.
Computional Linguistics, 30:277?308,September.132
