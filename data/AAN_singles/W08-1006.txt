Proceedings of the ACL-08: HLT Workshop on Parsing German (PaGe-08), pages 40?46,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsParsing Three German Treebanks: Lexicalized and Unlexicalized BaselinesAnna N. Rafferty and Christopher D. ManningComputer Science DepartmentStanford UniversityStanford, CA 94305{rafferty,manning}@stanford.eduAbstractPrevious work on German parsing has pro-vided confusing and conflicting results con-cerning the difficulty of the task and whethertechniques that are useful for English, suchas lexicalization, are effective for German.This paper aims to provide some understand-ing and solid baseline numbers for the task.We examine the performance of three tech-niques on three treebanks (Negra, Tiger, andTu?Ba-D/Z): (i) Markovization, (ii) lexicaliza-tion, and (iii) state splitting.
We additionallyexplore parsing with the inclusion of gram-matical function information.
Explicit gram-matical functions are important to Germanlanguage understanding, but they are numer-ous, and na?
?vely incorporating them into aparser which assumes a small phrasal categoryinventory causes large performance reductionsdue to increasing sparsity.1 IntroductionRecent papers provide mixed evidence as to whethertechniques that increase statistical parsing perfor-mance for English also improve German parsingperformance (Dubey and Keller, 2003; Ku?bler et al,2006).
We provide a systematic exploration of thistopic to shed light on what techniques might bene-fit German parsing and show general trends in therelative performance increases for each technique.While these results vary across treebanks, due todifferences in annotation schemes as discussed byKu?bler (2005), we also find similarities and provideexplanations for the trend differences based on theannotation schemes.We address three parsing techniques:(i) Markovization, (ii) lexicalization, and (iii) statesplitting (i.e., subcategorization).
These techniquesare not independent, and we thus examine howlexicalization and Markovization interact, sincelexicalization for German has been the mostcontentious area in the literature.
Many of thesetechniques have been investigated in other work(Schiehlen, 2004; Dubey, 2004; Dubey, 2005),but, we hope that by consolidating, replicating,improving, and clarifying previous results we cancontribute to the re-evaluation of German proba-bilistic parsing after a somewhat confusing start toinitial literature in this area.One feature of German that differs markedly fromEnglish is substantial free word order.
This requiresthe marking of grammatical functions on phrases toindicate their syntactic function in sentences (sub-ject, object, etc.
), whereas for English these func-tions can be derived from configurations (Chomsky,1965; de Marneffe et al, 2006).
While some simi-lar functions are present in English treebanks, theyare used more frequently in German treebanks andmany more unique functions and category-functionpairings exist.
Because of the relatively free wordordering in German, the usefulness of parses is sub-stantially increased by generating them with this in-formation.
We demonstrate the difficulties intro-duced by na?
?vely concatenating these functions tocategories and how this treatment interacts with theother parsing techniques.
There are several avenuesfor improving this situation in future work.
The ver-sions of the treebanks we use here do not includecase information in part-of-speech tags and we do40Treebank Train Dev ?
40 Test ?
40Tiger 20894 2611 2535 2611 2525Tu?Ba-D/Z 20894 2611 2611 2611 2611Negra v2 18602 1000 975 1000 968Table 1: Size in sentences of treebanks used in this paper.?Tiger?
and ?Tu?Ba-D/Z?
refer to the corpora prepared forthe ACL-08 workshop shared task; the full Tiger corpusis much larger.
Our Negra results are on the test set.not use any morphological analyzer; this should berectified in future work.
A new parsing model couldbe written to treat separate grammatical functionsfor nodes as first class objects, rather than just con-catenating phrasal categories and functions.
Finally,assignment of grammatical functions could be leftto a separate post-processing phase, which could ex-ploit not only case information inside noun phrasesbut joint information across the subcategorizationframes of predicates.2 MethodologyWe use the Stanford Parser (Klein and Manning,2003b) for all experiments.
An advantage of thisparser for baseline experiments is that it providesclean, simple implementations of component mod-els, with many configuration options.
We show re-sults in most instances for evaluations both with andwithout grammatical functions and with and withoutgold tags.
When training and parsing with the inclu-sion of grammatical functions, we treat each pair-ing of basic category and grammatical function asone new category.
Rules are learned for each suchcategory with a separate orthographic form, withno attempt to learn general rules for nodes with thesame basic category but different functions.
Clearly,more sophisticated methods of handling grammat-ical functions exist, but our focus is on providingbaseline results that are easily replicable by others.We focus primarily on the Tu?Ba-D/Z and Tigercorpora, training on the training sets for the ACL2008 Workshop on Parsing German shared task andproviding ablation results based on development setperformance.
Additionally, we show a limited num-ber of results on the Negra corpus, using the standardtraining/development/test splits, defined in (Dubeyand Keller, 2003).
The sizes of these data sets areshown in table 1.3 MarkovizationPrevious work has shown that adding verticalMarkovization ((grand-)parent annotation) and us-ing horizontal Markovization can greatly improveEnglish parsing performance (Klein and Manning,2003a).
Several papers have already reported par-tially corresponding results on German: Schiehlen(2004) and Dubey (2004) reported gains of severalpercent for unlexicalized parsing on Negra; Ku?bleret al (2006) agreed with these results for Negra, butsuggests that they do not hold for Tu?Ba-D/Z.
We ex-tend these results by examining a variety of com-binations of Markovization parameters for all threecorpora (Tu?Ba-D/Z, Tiger, and Negra) in table 2.
Noresults presented here do include grammatical func-tions; we present results on the interaction betweenthese functions and Markovization in section 4.For Tu?Ba-D/Z, we see that adding verticalMarkovization provides a substantial performancegain of about 2% (vertical Markovization = 2) forall levels of horizontal Markovization; increasingvertical Markovization improves performance onlyslightly further.
Decreasing horizontal Markoviza-tion from the default of infinity for a standardPCFG also provides marginal gains, and decreasesthe number of rules learned by the parser, cre-ating a more compact grammar.
The results ofMarkovization on the Tiger and Negra corpora il-lustrate the problems of a large grammar.
While amodest improvement is found by using parent anno-tation (vertical Markovization = 2) when horizontalMarkovization is small, increasing either horizontalor vertical Markovization past this point decreasesperformance due to sparsity.
Thus, while the gen-eral results concerning Markovization from Englishhold, the size of performance increase is affected ap-preciably by the annotation strategy.In table 3, we show a subset of the results of var-ious Markovization parameters when gold part-of-speech tags are used, focusing on models that per-formed well without gold tags and that produce rel-atively compact grammars.
Gold tags provide 2?3%absolute improvement in F1 over tagging while pars-ing; slightly greater improvements are seen when thePCFG model is used individually (3?4% absoluteimprovement), and absolute improvement does notvary greatly between treebanks.
These results are41Tu?Ba-D/Z Tiger NegraHoriz.
Vertical Markov Order Vertical Markov Order Vertical Markov OrderOrder 1 2 3 1 2 3 1 2 31 86.50 88.60 88.71 76.69 77.40 76.46 76.63 77.20 75.91(+2.76) (+1.21) (+0.89) (+3.54) (+3.57) (+3.27) (+2.39) (+2.06) (+2.08)2 86.55 88.61 88.84 75.91 75.30 74.20 76.39 75.39 73.77(+2.63) (+1.22) (+0.90) (+3.22) (+3.09) (+3.10) (+3.40) (+2.20) (+2.16)3 86.47 88.56 88.74 75.27 74.08 72.88 75.30 74.22 72.53(+2.63) (+1.18) (+0.90) (+3.36) (+3.41) (+2.85) (+3.74) (+2.12) (+2.60)?
86.04 88.41 88.67 74.44 73.26 71.96 74.48 73.50 71.84(+2.17) (+1.07) (+0.91) (+3.10) (+3.02) (+2.51) (+3.31) (+1.97) (+3.02)Table 2: Factored parsing results for Tu?Ba-D/Z, Tiger, and Negra when tagging is done by the parser.
Numbers initalics show difference between factored parser and PCFG, where improvements over the PCFG are positive.comparable to Maier (2006), which found 3?6% im-provement using an unlexicalized PCFG; these ab-solute improvements hold despite the fact that theMaier (2006) parser has results with 2?4% absolutelower F1 than those in this paper.4 Inclusion of Grammatical FunctionsIn this section we examine how the addition of gram-matical functions for training and evaluation affectsperformance.
As noted previously, we add gram-matical functions simply by concatenating them tothe dependent phrasal categories and calling eachunique symbol a PCFG nonterminal; this is an ob-vious way to adapt an existing PCFG parser, but nota sophisticated model of grammatical functions.
Wealso present our shared task results (table 6).4.1 Effects on EvaluationAs shown in table 4, the inclusion of grammati-cal functions decreases performance by 10?15% forboth treebanks.
This is partially due to the increasein grammar size, creating less supporting evidencefor each rule, and the fact that the parser must nowdiscriminate amongst more categories.
The largergrammar is particularly problematic for Tiger due toits flat annotation style.
Adding gold tags (table 5)increases performace by 2?3%, a similar gain to thatfor the parsers without grammatical functions.
Wealso see that lexicalization provides smaller gainswhen grammatical functions are included; we dis-cuss this further in section 5.
Finally, especially forthe Tiger corpus, vertical Markovization diminishesTu?Ba-D/Z Vertical Markov OrderHorizontal Order 1 21 89.66 91.69(+1.82) (+0.54)2 89.72 91.71(+1.56) (+0.43)?
89.34 91.43(+1.39) (+0.29)Tiger Vertical Markov OrderHorizontal Order 1 21 79.39 79.67(+2.83) (+2.53)2 78.60 77.40(+2.74) (+2.22)?
76.65 75.29(+2.50) (+1.94)Negra Vertical Markov OrderHorizontal Order 1 21 78.80 79.51(+2.39) (+1.55)2 77.92 77.43(+2.15) (+1.81)?
74.44 73.26(+3.10) (+3.02)Table 3: Factored parsing results for Tu?Ba-D/Z, Tiger,and Negra when gold tags are provided as input to theparser.
Numbers in italics show difference between fac-tored parser and PCFG, where improvements over thePCFG are positive.42TueBa-D/Z TigerHoriz.
Vertical VerticalOrder 1 2 1 21 75.97 77.21 60.48 58.00(+2.69) (+1.49) (+2.69) (+2.24)2 76.96 53.68(+1.44) (+2.22)?
75.24 76.66 55.36 50.94(+2.18) (+1.22) (+2.50) (+1.94)Table 4: Results for Tu?Ba-D/Z and Tiger when gram-matical functions are included and tagging is done bythe parser.
Numbers in italics show difference betweenfactored parser and PCFG, where improvements over thePCFG are positive.Tu?Ba-D/Z TigerHoriz.
Vertical VerticalOrder 1 2 1 21 78.91 80.64 67.72 64.93(+1.60) (+0.81) (+1.16) (+0.77)2 80.32 59.60(+0.69) (+0.67)?
78.38 80.01 60.36 56.77(+1.33) (+0.59) (+0.89) (+0.18)Table 5: Results for Tu?Ba-D/Z and Tiger when gram-matical functions are included and gold tags (includinggrammatical functions) are given to the parser.Tu?Ba-D/Z TigerPetrov & Klein 83.97 69.81Rafferty & Manning 79.24 59.44Hall 75.37 65.18Rafferty & Manning -gf 73.36 49.03Table 6: Shared task results (F1) for Tu?Ba-D/Z and Tigerwhen grammatical functions are included and gold tagsare given to the parser.
Gold tags include grammaticalfunctions except in the case of ?Rafferty & Manning -gf?.performance.
Sparsity becomes too great of an is-sue for increased vertical annotations to be effective:the grammar grows from 11,170 rules with horizon-tal Markovization = 1, vertical Markovization = 1to 39,435 rules with horizontal Markovization = ?,vertical Markovization = 2.Tu?Ba-D/Z Fact.
PCFGConfiguration F1 ?
F1 ?H = 1, V = 1 87.63 +1.63 85.32 +1.58H = 1, V = 2 88.47 ?0.13 87.31 ?0.08H = 2, V = 2 88.30 ?0.31 87.13 ?0.26H = ?, V = 1 87.23 +1.17 85.27 +1.40H = ?, V = 2 88.18 ?0.23 87.09 ?0.25Tiger Fact.
PCFGConfiguration F1 ?
F1 ?H = 1, V = 1 72.09 ?4.60 69.09 ?4.06H = 1, V = 2 69.25 ?8.15 67.24 ?6.59H = 2, V = 2 66.08 ?9.22 64.42 ?7.79H = ?, V = 1 67.58 ?9.07 64.85 ?6.49H = ?, V = 2 63.54 ?11.75 62.21 ?8.03Table 7: Effect of adding grammatical functions infor-mation to the training data only.
The difference (?)
isfrom a parser with same Markovization parameters butnot trained with grammatical functions.4.2 Effects on Training OnlyWhile training and testing with grammatical func-tions significantly reduces our performance, thisdoes not necessarily mean that we cannot benefitfrom grammatical functions.
We explored whethertraining with grammatical functions could improvethe parser?s test time performance on syntactic cat-egories (ignoring grammatical functions), hypothe-sizing that the functions could provide additional in-formation for disambiguating which rule should beapplied.
This test also provides evidence of whetherdecreased performance with grammatical functionsis due to sparseness caused by the large grammaror simply that more categorization needs to be donewhen grammatical functions are included.We found, as shown in table 7, that grammaticalfunctions provide limited gains for basic categoriesbut have no extra utility once vertical Markoviza-tion is added.
These results suggest that addinggrammatical functions is not only problematic due toincreased categorization but because of sparseness(this task has the same categorization demands asparsing without grammatical functions consideredin section 3).
The Stanford Parser was initially de-signed under the assumption of a small phrasal cat-egory set, and makes no attempts to smooth gram-mar rule probabilities (smoothing only probabilities43of words having a certain tag and probabilities of de-pendencies).
While this approach is in general notoptimal when many category splits are used insidethe parser ?
smoothing helps, cf.
Petrov et al (2006)?
it becomes untenable as the category set growslarge, multi-faceted, and sparse.
This is particularlyevident given the results in table 7 that show the pre-cipitous decline in F1 on the Tiger corpus, wherethe general problems are exacerbated by the flatterannotation style of Tiger.5 LexicalizationIn the tables in section 3, we showed the utilityof lexicalization for German parsing when gram-matical functions are not required.
This contrastsstrongly with the results of (Dubey and Keller, 2003;Dubey, 2004) where no performance increases (in-deed, performance decreases) are reported from lex-icalization.
Lexicalization shows fairly consistent2?3% gains on the Negra and Tiger treebanks.
Asthe number of tags increases, however, such as whengrammatical functions are included, gains from lex-icalization are limited due to sparseness.
While use-ful category splits lessen the need for lexicaliza-tion, we think the diminishing gain is primarily dueto problems resulting from the unsmoothed PCFGmodel.
As the grammar becomes sparser, there arelimited opportunities for the lexical dependenciesto correct the output of the PCFG grammar underthe factored parsing model of Klein and Manning(2003b).
Indeed, as shown in table 8, the grammarbecomes sufficiently sparse that for many sentencesthere is no tree on which the PCFG and dependencygrammar can agree, and the parser falls back to sim-ply returning the best PCFG parse.
This falloff, inaddition to overall issues of sparsity, helps explainthe drop in performance with the addition of gram-matical functions: our possible gain from lexicalizedparsing is decreased by the increasing rate of fail-ure for the factored parser.
Thus, for future Germanwork to gain from lexicalization, it may be necessaryto explore smoothing the grammar or working witha diminished tagset without grammatical functions.Lexicalized parsing focuses on identifying depen-dencies.
As recognized by Collins (2003), identi-fying dependencies between words allows for bet-ter evaluation of attachment accuracy, diminishingTotal ParseableDataset Sent.
w.o.
GFs with GFsTu?Ba-D/Z 2611 2610 2197Tiger 2535 2534 1592Table 8: Number of sentences parseable by the factoredlexicalized parser.
If the factored model fails to returna parse, the parser returns the best PCFG parse, so theparser maintains 100% coverage.Tu?Ba-D/Z TigerGold Tags 91.00 90.21Auto.
Tags 86.90 83.39Gold Tags -gf 89.89 88.97Auto.
Tags -gf 86.89 85.86Table 9: Performance (F1) on identifying dependenciesin Tu?Ba-D/Z and Tiger.
Tags were either provided (?GoldTags?)
or generated during parsing (?Auto.
Tags?
); gram-matical functions were used for the first two results andomitted for the final two (?-gf?
).spurious effects on labeled bracketing F1 of differ-ent annotation schemes.
In particular, Rehbein andvan Genabith (2007) correctly emphasize how F1scores are very dependent on the amount of branch-ing structure in a treebank, and are hence not validlycomparable across annotation styles.
We evaluateperformance on identifying unlabeled dependenciesbetween heads and modifiers, extracting dependen-cies automatically from the parse trees.
Most headsin the Tu?Ba-D/Z and Tiger treebanks are marked,and we use marked heads when possible for train-ing and evaluation.
When heads were not marked,we used heuristic rules to identify the likely head.Broadly consistent with the results of Rehbein andvan Genabith (2007), Table 9 shows that the dis-parity in performance between Tu?Ba-D/Z and Tigeris much smaller when measuring dependency accu-racy rather than labeled bracketing F1, especiallywhen using gold tags.
These results also reverse thetrend in our other results that adding grammaticalfunctions greatly reduces F1.
While F1 decreasesor remains constant when grammatical functions areused with automatic tags, probably reflecting a de-crease in accuracy on tags when using grammaticalfunctions, they increase F1 given gold tags.
Theseresults suggest both that useful information may begained from grammatical functions and that the dif-44ferences between the annotation schemes of Tu?Ba-D/Z and Tiger may not cause as large a fundamen-tal difference in parser performance as suggested inKu?bler et al (2006).6 Feature SplitsAnother technique shown to improve accuracy inEnglish parsing is state splits (Klein and Manning,2003a).
We experimented with such splits in anattempt to show similar utility for German.
How-ever, despite trying a number of splits that leveragedobservations of useful splits for English as well asinformation from grammatical functions, we wereunable to find any splits that caused significant im-provement for German parsing performance.
Some-what more positive results are reported by Schiehlen(2004) ?
in particular, his relative clause markingadds significantly to performance ?
although manyof the other features he explores also yield little.7 Errors by CategoryIn this section, we examine which categories havethe most parsing errors and possible reasons forthese biases.
Two types of error patterns are con-sidered: errors on particularly salient grammaticalfunctions and overall category errors.7.1 Grammatical Function ErrorsA subset of grammatical functions was recognizedby Ku?bler et al (2006) as particularly important forusing parsing results, so we investigated trainingand testing with the inclusion of these grammaticalfunctions but without any others.
These functionswere the subject, dative object, and accusative objectfunctions.
We found that the three categories haddistinctively different patterns of errors, although weunfortunately still do not achieve particularly highF1 for any of the individual pairings of node labeland grammatical function.
Note that this analysisdiffers from that of Ku?bler et al (2006) due to ouranalysis of the accuracy of node labels and gram-matical functions, rather than only performance onidentifying these three grammatical functions (with-out regards to the correctness of the original nodelabel).
Overall, dative objects occur much less fre-quently than either of the other two types, and ac-cusative objects occur less frequently than subjects.Consistent with sparsity causing degradations in per-formance, for both Tiger and Tu?Ba-D/Z, we showthe best performance on subjects, followed by ac-cusative objects and then dative objects.
For all cat-egories, we find that these functions occur most fre-quently with noun phrases, and we achieve higherperformance when pairing tthem with a noun phrasethan with any other basic category.
While Ku?bleret al (2006) suggests these functions are particu-larly important for parsing, our low performance ondative objects (F1 between 0.00 and 0.06) may notmatter a great deal given that dative objects consistof only 0.42% of development set nodes in Tu?Ba-D/Z and 0.76% of such nodes in Tiger.7.2 Overall ErrorsOne limiting factor for overall parsing accuracy isroughly defined by the number of local (one-level)trees in the test set that are present in the training set.While changes such as Markovization may allowrules to be learned that do not correspond directly tosuch local trees, it is unlikely that many such ruleswill be created.
Thus, if a local tree in the test setis not represented in the training set, it is unlikelywe will be able to correctly parse this sentence.
Thenumber of such local trees and the amount of test setcoverage they provide varies widely between Tu?Ba-D/Z and Tiger.
Without grammatical functions, thetraining set for Tu?Ba-D/Z contains 4,532 unique lo-cal trees, whereas the training set for Tiger con-tains 20,957; both have 20,894 complete trees.
Lo-cal trees from the training set represent 79.6% ofthe unique local trees in the development set forTu?Ba-D/Z, whereas they represent 61.8% of uniquelocal trees in Tiger?s development set.
This trans-lates to 99.3% of total local trees in the develop-ment set represented in the training set for Tu?Ba-D/Z versus 92.3% for Tiger.
With grammatical func-tions, the number of unique local trees increases forboth Tu?Ba-D/Z and Tiger (10,464 and 32,614 treesin training, respectively), and total coverage in thedevelopment sets drop to 98.6% (Tu?Ba-D/Z) and87.7% (Tiger).
Part of the reason for this decreasein coverage with the addition of grammatical func-tions, and the disparity between corpora, is a largeincrease in the number of possible categories foreach node: from 26 to 139 categories for Tu?Ba-D/Zand from 24 to 192 categories for Tiger.45ReferencesNoam Chomsky.
1965.
Aspects of the Theory of Syntax.MIT Press, Cambridge, MA.Michael Collins.
2003.
Head-driven statistical modelsfor natural language parsing.
In Computational Lin-guistics, pages 589?638.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating typed de-pendency parses from phrase structure parses.
In 5thInternational Conference on Language Resources andEvaluation (LREC 2006), pages 449?454.Amit Dubey and Frank Keller.
2003.
Probabilistic pars-ing for German using sister-head dependencies.
InACL 41, pages 96?103.Amit Dubey.
2004.
Statistical Parsing for German:Modeling Syntactic Properties and Annotation Differ-ences.
Ph.D. thesis, Universitaet des Saarlandes.Amit Dubey.
2005.
What to do when lexicalization fails:parsing German with suffix analysis and smoothing.In ACL 43, pages 314?21.Dan Klein and Christopher D. Manning.
2003a.
Accu-rate unlexicalized parsing.
In ACL 41, pages 423?430.Dan Klein and Christopher D. Manning.
2003b.
Fastexact inference with a factored model for natural lan-guage parsing.
Advances in Neural Information Pro-cessing Systems, 15:3?10.Sandra Ku?bler, Erward W. Hinrichs, and WolfgangMaier?
2006.
Is it really that difficult to parse German?In Proceedings of the 2006 Conference on EmpiricalMethods in Natural Language Processing.Sandra Ku?bler.
2005.
How do treebank annotationschemes influence parsing results?
Or how not to com-pare apples and oranges.
In Proceedings of RANLP2005.Wolfgang Maier.
2006.
Annotation schemes and their in-uence on parsing results.
In Proceedings of the COL-ING/ACL 2006 Student Research Workshop, pages 19?24.Slav Petrov, Leon Barrett, Romain Thibaux, and DanKlein.
2006.
Learning accurate, compact, and inter-pretable tree annotation.
In ACL 44, pages 433?440.Ines Rehbein and Josef van Genabith.
2007.
Treebankannotation schemes and parser evaluation for German.In Proceedings of the 2007 Joint Conference on Em-pirical Methods in Natural Language Processing andComputational Natural Language Learning (EMNLP-CoNLL), pages 630?639.Michael Schiehlen.
2004.
Annotation strategies forprobabilistic parsing in German.
In Proceedings of the20th International Conference on Computational Lin-guistics, pages 390?96.46
