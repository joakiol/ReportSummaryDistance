Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 65?72,Sydney, July 2006. c?2006 Association for Computational LinguisticsA Pipeline Framework for Dependency ParsingMing-Wei Chang Quang Do Dan RothDepartment of Computer ScienceUniversity of Illinois at Urbana-ChampaignUrbana, IL 61801{mchang21, quangdo2, danr}@uiuc.eduAbstractPipeline computation, in which a task isdecomposed into several stages that aresolved sequentially, is a common compu-tational strategy in natural language pro-cessing.
The key problem of this modelis that it results in error accumulation andsuffers from its inability to correct mis-takes in previous stages.
We developa framework for decisions made via inpipeline models, which addresses thesedifficulties, and presents and evaluates itin the context of bottom up dependencyparsing for English.
We show improve-ments in the accuracy of the inferred treesrelative to existing models.
Interestingly,the proposed algorithm shines especiallywhen evaluated globally, at a sentencelevel, where our results are significantlybetter than those of existing approaches.1 IntroductionA pipeline process over the decisions of learnedclassifiers is a common computational strategy innatural language processing.
In this model a taskis decomposed into several stages that are solvedsequentially, where the computation in the ithstage typically depends on the outcome of com-putations done in previous stages.
For example,a semantic role labeling program (Punyakanok etal., 2005) may start by using a part-of-speech tag-ger, then apply a shallow parser to chunk the sen-tence into phrases, identify predicates and argu-ments and then classify them to types.
In fact,any left to right processing of an English sentencemay be viewed as a pipeline computation as it pro-cesses a token and, potentially, makes use of thisresult when processing the token to the right.The pipeline model is a standard model ofcomputation in natural language processing forgood reasons.
It is based on the assumption thatsome decisions might be easier or more reliablethan others, and their outcomes, therefore, can becounted on when making further decisions.
Nev-ertheless, it is clear that it results in error accu-mulation and suffers from its inability to correctmistakes in previous stages.
Researchers have re-cently started to address some of the disadvantagesof this model.
E.g., (Roth and Yih, 2004) suggestsa model in which global constraints are taken intoaccount in a later stage to fix mistakes due to thepipeline.
(Punyakanok et al, 2005; Marciniakand Strube, 2005) also address some aspects ofthis problem.
However, these solutions rely on thefact that all decisions are made with respect to thesame input; specifically, all classifiers considereduse the same examples as their input.
In addition,the pipelines they study are shallow.This paper develops a general framework fordecisions in pipeline models which addressesthese difficulties.
Specifically, we are interestedin deep pipelines ?
a large number of predictionsthat are being chained.A pipeline process is one in which decisionsmade in the ith stage (1) depend on earlier deci-sions and (2) feed on input that depends on earlierdecisions.
The latter issue is especially importantat evaluation time since, at training time, a goldstandard data set might be used to avoid this issue.We develop and study the framework in the con-text of a bottom up approach to dependency pars-ing.
We suggest that two principles to guide thepipeline algorithm development:(i) Make local decisions as reliable as possible.
(ii) Reduce the number of decisions made.Using these as guidelines we devise an algo-65rithm for dependency parsing, prove that it satis-fies these principles, and show experimentally thatthis improves the accuracy of the resulting tree.Specifically, our approach is based on a shift-reduced parsing as in (Yamada and Matsumoto,2003).
Our general framework provides insightsthat allow us to improve their algorithm, and toprincipally justify some of the algorithmic deci-sions.
Specifically, the first principle suggests toimprove the reliability of the local predictions,which we do by improving the set of actions takenby the parsing algorithm, and by using a look-ahead search.
The second principle is used to jus-tify the control policy of the parsing algorithm ?which edges to consider at any point of time.
Weprove that our control policy is optimal in somesense, and that the decisions we made, guided bythese, principles lead to a significant improvementin the accuracy of the resulting parse tree.1.1 Dependency Parsing and Pipeline ModelsDependency trees provide a syntactic reresenta-tion that encodes functional relationships betweenwords; it is relatively independent of the grammartheory and can be used to represent the structureof sentences in different languages.
Dependencystructures are more efficient to parse (Eisner,1996) and are believed to be easier to learn, yetthey still capture much of the predicate-argumentinformation needed in applications (Haghighi etal., 2005), which is one reason for the recent in-terest in learning these structures (Eisner, 1996;McDonald et al, 2005; Yamada and Matsumoto,2003; Nivre and Scholz, 2004).Eisner?s work ?
O(n3) parsing time generativealgorithm ?
embarked the interest in this area.His model, however, seems to be limited whendealing with complex and long sentences.
(Mc-Donald et al, 2005) build on this work, and usea global discriminative training approach to im-prove the edges?
scores, along with Eisner?s algo-rithm, to yield the expected improvement.
A dif-ferent approach was studied by (Yamada and Mat-sumoto, 2003), that develop a bottom-up approachand learn the parsing decisions between consecu-tive words in the sentence.
Local actions are usedto generate a dependency tree using a shift-reduceparsing approach (Aho et al, 1986).
This is atrue pipeline approach, as was done in other suc-cessful parsers, e.g.
(Ratnaparkhi, 1997), in thatthe classifiers are trained on individual decisionsrather than on the overall quality of the parser, andchained to yield the global structure.
Clearly, itsuffers from the limitations of pipeline process-ing, such as accumulation of errors, but neverthe-less, yields very competitive parsing results.
Asomewhat similar approach was used in (Nivre andScholz, 2004) to develop a hybrid bottom-up/top-down approach; there, the edges are also labeledwith semantic types, yielding lower accuracy thanthe works mentioned above.The overall goal of dependency parsing (DP)learning is to infer a tree structure.
A commonway to do that is to predict with respect to eachpotential edge (i, j) in the tree, and then choose aglobal structure that (1) is a tree and that (2) max-imizes some score.
In the context of DPs, this?edge based factorization method?
was proposedby (Eisner, 1996).
In other contexts, this is similarto the approach of (Roth and Yih, 2004) in thatscoring each edge depends only on the raw dataobserved and not on the classifications of otheredges, and that global considerations can be usedto overwrite the local (edge-based) decisions.On the other hand, the key in a pipeline modelis that making a decision with respect to the edge(i, j) may gain from taking into account deci-sions already made with respect to neighboringedges.
However, given that these decisions arenoisy, there is a need to devise policies for reduc-ing the number of predictions in order to make theparser more robust.
This is exemplified in (Ya-mada and Matsumoto, 2003) ?
a bottom-up ap-proach, that is most related to the work presentedhere.
Their model is a ?traditional?
pipeline model?
a classifier suggests a decision that, once taken,determines the next action to be taken (as well asthe input the next action observes).In the rest of this paper, we propose and jus-tify a framework for improving pipeline process-ing based on the principles mentioned above: (i)make local decisions as reliably as possible, and(ii) reduce the number of decisions made.
Weuse the proposed principles to examine the (Ya-mada and Matsumoto, 2003) parsing algorithmand show that this results in modifying some ofthe decisions made there and, consequently, betteroverall dependency trees.2 Efficient Dependency ParsingThis section describes our DP algorithm and jus-tifies its advantages as a pipeline model.
We pro-66pose an improved pipeline framework based on thementioned principles.For many languages such as English, Chineseand Japanese (with a few exceptions), projectivedependency trees (that is, DPs without edge cross-ings) are sufficient to analyze most sentences.
Ourwork is therefore concerned only with projectivetrees, which we define below.For words x, y in the sentence T we introducethe following notations:x ?
y: x is the direct parent of y.x ??
y: x is an ancestor of y;x ?
y: x ?
y or y ?
x.x < y: x is to the left of y in T .Definition 1 (Projective Language) (Nivre,2003) ?a, b, c ?
T, a ?
b and a < c < b implythat a ??
c or b ??
c.2.1 A Pipeline DP AlgorithmOur parsing algorithm is a modified shift-reduceparser that makes use of the actions described be-low and applies them in a left to right manneron consecutive pairs of words (a, b) (a < b) inthe sentence.
This is a bottom-up approach thatuses machine learning algorithms to learn the pars-ing decisions (actions) between consecutive wordsin the sentences.
The basic actions used in thismodel, as in (Yamada and Matsumoto, 2003), are:Shift: there is no relation between a and b, orthe action is deferred because the relationship be-tween a and b cannot be determined at this point.Right: b is the parent of a,Left: a is the parent of b.This is a true pipeline approach in that the clas-sifiers are trained on individual decisions ratherthan on the overall quality of the parsing, andchained to yield the global structure.
And, clearly,decisions make with respect to a pair of words af-fect what is considered next by the algorithm.In order to complete the description of the algo-rithm we need to describe which edge to consideronce an action is taken.
We describe it via the no-tion of the focus point: when the algorithm con-siders the pair (a, b), a < b, we call the word a thecurrent focus point.Next we describe several policies for determin-ing the focus point of the algorithm following anaction.
We note that, with a few exceptions, de-termining the focus point does not affect the cor-rectness of the algorithm.
It is easy to show thatfor (almost) any focus point chosen, if the correctaction is selected for the corresponding edge, thealgorithm will eventually yield the correct tree (butmay require multiple cycles through the sentence).In practice, the actions selected are noisy, and awasteful focus point policy will result in a largenumber of actions, and thus in error accumulation.To minimize the number of actions taken, we wantto find a good focus point placement policy.After S, the focus point always moves one wordto the right.
After L or R there are there naturalplacement policies to consider:Start Over: Move focus to the first word in T .Stay: Move focus to the next word to the right.That is, for T = (a, b, c), and focus being a, anL action will result is the focus being a, while Raction results in the focus being b.Step Back: The focus moves to the previous word(on the left).
That is, for T = (a, b, c), and focusbeing b, in both cases, a will be the focus point.In practice, different placement policies have asignificant effect on the number of pairs consid-ered by the algorithm and, therefore, on the fi-nal accuracy1.
The following analysis justifies theStep Back policy.
We claim that if Step Backis used, the algorithm will not waste any action.Thus, it achieves the goal of minimizing the num-ber of actions in pipeline algorithms.
Notice thatusing this policy, when L is taken, the pair (a, b) isreconsidered, but with new information, since nowit is known that c is the child of b.
Although thisseems wasteful, we will show this is a necessarymovement to reduce the number of actions.As mentioned above, each of these policiesyields the correct tree.
Table 1 compares the threepolicies in terms of the number of actions requiredto build a tree.Policy #Shift #Left #RightStart over 156545 26351 27918Stay 117819 26351 27918Step back 43374 26351 27918Table 1: The number of actions required to buildall the trees for the sentences in section 23 of PennTreebank (Marcus et al, 1993) as a function ofthe focus point placement policy.
The statistics aretaken with the correct (gold-standard) actions.It is clear from Table 1 that the policies result1Note that (Yamada and Matsumoto, 2003) mention thatthey move the focus point back after R, but do not state whatthey do after executing L actions, and why.
(Yamada, 2006)indicates that they also move focus point back after L.67Algorithm 2 Pseudo Code of the dependencyparsing algorithm.
getFeatures extracts the fea-tures describing the word pair currently consid-ered; getAction determines the appropriate actionfor the pair; assignParent assigns a parent for thechild word based on the action; and deleteWorddeletes the child word in T at the focus once theaction is taken.Let t represents for a word tokenFor sentence T = {t1, t2, .
.
.
, tn}focus= 1while focus< |T | do~v = getFeatures(tfocus, tfocus+1)?
= getAction(tfocus, tfocus+1, ~v)if ?
= L or ?
= R thenassignParent(tfocus, tfocus+1, ?
)deleteWord(T, focus, ?
)// performing Step Back herefocus = focus ?
1elsefocus = focus + 1end ifend whilein very different number of actions and that StepBack is the best choice.
Note that, since the ac-tions are the gold-standard actions, the policy af-fects only the number of S actions used, and notthe L and R actions, which are a direct functionof the correct tree.
The number of required ac-tions in the testing stage shows the same trend andthe Step Back also gives the best dependency ac-curacy.
Algorithm 2 depicts the parsing algorithm.2.2 Correctness and Pipeline PropertiesWe can prove two properties of our algorithm.First we show that the algorithm builds the de-pendency tree in only one pass over the sentence.Then, we show that the algorithm does not wasteactions in the sense that it never considers a wordpair twice in the same situation.
Consequently,this shows that under the assumption of a perfectaction predictor, our algorithm makes the smallestpossible number of actions, among all algorithmsthat build a tree sequentially in one pass.Note that this may not be true if the action clas-sifier is not perfect, and one can contrive examplesin which an algorithm that makes several passes ona sentence can actually make fewer actions than asingle pass algorithm.
In practice, however, as ourexperimental data shows, this is unlikely.Lemma 1 A dependency parsing algorithm thatuses the Step Back policy completes the tree whenit reaches the end of the sentence for the rst time.In order to prove the algorithm we need the fol-lowing definition.
We call a pair of words (a, b) afree pair if and only if there is a relation betweena and b and the algorithm can perform L or R ac-tions on that pair when it is considered.
Formally,Definition 2 (free pair) A pair (a, b) consideredby the algorithm is a free pair, if it satises thefollowing conditions:1. a ?
b2.
a, b are consecutive in T (not necessary inthe original sentence).3.
No other word in T is the child of a or b.
(aand b are now part of a complete subtree.)Proof.
: It is easy to see that there is at least onefree pair in T , with |T | > 1.
The reason is thatif no such pair exists, there must be three words{a, b, c} s.t.
a ?
b, a < c < b and ?
(a ?
c ?b ?
c).
However, this violates the properties of aprojective language.Assume {a, b, d} are three consecutive words inT .
Now, we claim that when using Step Back, thefocus point is always to the left of all free pairs inT .
This is clearly true when the algorithm starts.Assume that (a, b) is the first free pair in T and letc be just to the left of a and b.
Then, the algorithmwill not make a L or R action before the focuspoint meets (a, b), and will make one of these ac-tions then.
It?s possible that (c, a ?
b) becomes afree pair after removing a or b in T so we needto move the focus point back.
However, we alsoknow that there is no free pair to the left of c.Therefore, during the algorithm, the focus pointwill always remain to the left of all free pairs.
So,when we reach the end of the sentence, every freepair in the sentence has been taken care of, and thesentence has been completely parsed.
2Lemma 2 All actions made by a dependencyparsing algorithm that uses the Step Back policyare necessary.Proof.
: We will show that a pair (a, b) will neverbe considered again given the same situation, thatis, when there is no additional information aboutrelations a or b participate in.
Note that if R or68L is taken, either a or b will become a child wordand be eliminate from further consideration by thealgorithm.
Therefore, if the action taken on (a, b)is R or L, it will never be considered again.Assume that the action taken is S, and, w.l.o.g.that this is the rightmost S action taken before anon-S action happens.
Note that it is possible thatthere is a relation between a and b, but we can-not perform R or L now.
Therefore, we shouldconsider (a, b) again only if a child of a or b haschanged.
When Step Back is used, we will con-sider (a, b) again only if the next action is L. (Ifnext action is R, b will be eliminated.)
This is truebecause the focus point will move back after per-forming L, which implies that b has a new childso we are indeed in a new situation.
Since, fromLemma 1, the algorithm only requires one round.we therefore consider (a, b) again only if the situ-ation has changed.
22.3 Improving the Parsing Action SetIn order to improve the accuracy of the action pre-dictors, we suggest a new (hierarchical) set of ac-tions: Shift, Left, Right, WaitLeft, WaitRight.
Webelieve that predicting these is easier due to finergranularity ?
the S action is broken to sub-actionsin a natural way.WaitLeft: a < b. a is the parent of b, but it?spossible that b is a parent of other nodes.
Action isdeferred.
If we perform Left instead, the child of bcan not find its parents later.WaitRight: a < b. b is the parent of a, but it?spossible that a is a parent of other nodes.
Similarto WL, action is deferred.Thus, we also change the algorithm to performS only if there is no relationship between a and b2.The new set of actions is shown to better supportour parsing algorithm, when tested on differentplacement policies.
When WaitLeft or WaitRightis performed, the focus will move to the next word.It is very interesting to notice that WaitRight isnot needed in projective languages if Step Backis used.
This give us another strong reason to useStep Back, since the classification becomes moreaccurate ?
a more natural class of actions, with asmaller number of candidate actions.Once the parsing algorithm, along with the fo-cus point policy, is determined, we can train the2Interestingly, (Yamada and Matsumoto, 2003) mentionthe possibility of an additional single Wait action, but do notadd it to the model.action classifiers.
Given an annotated corpus, theparsing algorithm is used to determine the actiontaken for each consecutive pair; this is used to traina classifier to predict one of the five actions.
Thedetails of the classifier and the feature used aregiven in Section 4.When the learned model is evaluated on newdata, the sentence is processed left to right and theparsing algorithm, along with the action classifier,are used to produce the dependency tree.
The eval-uation process is somewhat more involved, sincethe action classifier is not used as is, but rather viaa look ahead inference step described next.3 A Pipeline Model with Look AheadThe advantage of a pipeline model is that it can usemore information, based on the outcomes of previ-ous predictions.
As discussed earlier, this may re-sult in accumulating error.
The importance of hav-ing a reliable action predictor in a pipeline modelmotivates the following approach.
We devise alook ahead algorithm and use it as a look aheadpolicy, when determining the predicted action.This approach can be used in any pipelinemodel but we illustrate it below in the context ofour dependency parser.The following example illustrates a situation inwhich an early mistake in predicting an actioncauses a chain reaction and results in further mis-takes.
This stresses the importance of correct earlydecisions, and motivates our look ahead policy.Let (w, x, y, z) be a sentence of four words, andassume that the correct dependency relations areas shown in the top part of Figure 1.
If the systemmistakenly predicts that x is a child of w before yand z becomes x?s children, we can only considerthe relationship between w and y in the next stage.Consequently, we will never find the correct parentfor y and z.
The previous prediction error propa-gates and impacts future predictions.
On the otherhand, if the algorithm makes a correct prediction,in the next stage, we do not need to consider w andy.
As shown, getting useful rather than misleadinginformation in a pipeline model, requires correctearly predictions.
Therefore, it is necessary to uti-lize some inference framework to that may helpresolving the error accumulation problem.In order to improve the accuracy of the actionprediction, we might want to examine all possiblecombinations of action sequences and choose theone that maximizes some score.
It is clearly in-69X YW ZXYW ZFigure 1: Top figure: the correct dependency rela-tions between w, x, y and z.
Bottom figure: if thealgorithm mistakenly decides that x is a child of wbefore deciding that y and z are x?s children, wecannot find the correct parent for y and z.tractable to find the global optimal prediction se-quences in a pipeline model of the depth we con-sider.
Therefore, we use a look ahead strategy,implemented via a local search framework, whichuses additional information but is still tractable.The local search algorithm is presented in Algo-rithm 3.
The algorithm accepts three parameters,model, depth and State.
We assume a classifierthat can give a confidence in its prediction.
This isrepresented here by model.As our learning algorithm we use a regularizedvariation of the perceptron update rule, as incorpo-rated in SNoW (Roth, 1998; Carlson et al, 1999),a multi-class classifier that is tailored for largescale learning tasks and has been used successfullyin a large number of NLP tasks (e.g., (Punyakanoket al, 2005)).
SNoW uses softmax over the rawactivation values as its confidence measure, whichcan be shown to produce a reliable approximationof the labels?
conditional probabilities.The parameter depth is to determine the depthof the search procedure.
State encodes the config-uration of the environment (in the context of thedependency parsing this includes the sentence, thefocus point and the current parent and children foreach word).
Note that State changes when a pre-diction is made and that the features extracted forthe action classifier also depend on State.The search algorithm will perform a search oflength depth.
Additive scoring is used to scorethe sequence, and the first action in this sequenceis selected and performed.
Then, the State is up-dated, the new features for the action classifiers arecomputed and search is called again.One interesting property of this framework isthat it allows that use of future information in ad-dition to past information.
The pipeline model nat-urally allows access to all the past information.Algorithm 3 Pseudo code for the look ahead algo-rithm.
y represents a action sequence.
The func-tion search considers all possible action sequenceswith |depth| actions and returns the sequence withthe highest score.Algo predictAction(model, depth, State)x = getNextFeature(State)y = search(x, depth, model, State)lab = y[1]State = update(State, lab)return labAlgo search(x, depth, model, State)maxScore = ?
?F = {y | ?y?
= depth}for y in F dos = 0, TmpState = Statefor i = 1 .
.
.
depth dox = getNextFeature(TmpState)s = s+ score(y[i], x, model)TmpState = update(TmpState, y[i])end forif s > maxScore theny?
= ymaxScore = send ifend forreturn y?Since the algorithm uses a look ahead policy, italso uses future predictions.
The significance ofthis becomes clear in Section 4.There are several parameters, in addition todepth that can be used to improve the efficiency ofthe framework.
For example, given that the actionpredictor is a multi-class classifier, we do not needto consider all future possibilities in order to de-cide the current action.
For example, in our exper-iments, we only consider two actions with highestscore at each level (which was shown to producealmost the same accuracy as considering all fouractions).4 Experiments and ResultsWe use the standard corpus for this task, the PennTreebank (Marcus et al, 1993).
The training setconsists of sections 02 to 21 and the testing set issection 23.
The POS tags for the evaluation datasets were provided by the tagger of (Toutanova etal., 2003) (which has an accuracy of 97.2% section7023 of the Penn Treebank).4.1 Features for Action ClassificationFor each word pair (w1, w2) we use the words,their POS tags and also these features of the chil-dren of w1 and w2.
We also include the lexiconand POS tags of 2 words before w1 and 4 wordsafter w2 (as in (Yamada and Matsumoto, 2003)).The key additional feature we use, relative to (Ya-mada and Matsumoto, 2003), is that we includethe previous predicted action as a feature.
Wealso add conjunctions of above features to ensureexpressiveness of the model.
(Yamada and Mat-sumoto, 2003) makes use of polynomial kernelsof degree 2 which is equivalent to using even moreconjunctive features.
Overall, the average numberof active features in an example is about 50.4.2 EvaluationWe use the same evaluation metrics as in (McDon-ald et al, 2005).
Dependency accuracy (DA) is theproportion of non-root words that are assigned thecorrect head.
Complete accuracy (CA) indicatesthe fraction of sentences that have a complete cor-rect analysis.
We also measure that root accuracy(RA) and leaf accuracy (LA), as in (Yamada andMatsumoto, 2003).
When evaluating the result,we exclude the punctuation marks, as done in (Mc-Donald et al, 2005) and (Yamada and Matsumoto,2003).4.3 ResultsWe present the results of several of the experi-ments that were intended to help us analyze andunderstand several of the design decisions in ourpipeline algorithm.To see the effect of the additional action, wepresent in Table 2 a comparison between a systemthat does not have the WaitLeft action (similarto the (Yamada and Matsumoto, 2003) approach)with one that does.
In both cases, we do not use thelook ahead procedure.
Note that, as stated above,the action WaitRight is never needed for our pars-ing algorithm.
It is clear that adding WaitLeft in-creases the accuracy significantly.Table 3 investigates the effect of the look ahead,and presents results with different depth param-eters (depth= 1 means ?no search?
), showing aconsistent trend of improvement.Table 4 breaks down the results as a functionof the sentence length; it is especially noticeablethat the system also performs very well for longmethod DA RA CA LAw/o WaitLeft 90.27 90.73 39.28 93.87w WaitLeft 90.53 90.76 39.74 93.94Table 2: The significant of the action WaitLeft .method DA RA CA LAdepth=1 90.53 90.76 39.74 93.94depth=2 90.67 91.51 40.23 93.96depth=3 90.69 92.05 40.52 93.94depth=4 90.79 92.26 40.68 93.95Table 3: The effect of different depth settings.sentences, another indication for its global perfor-mance robustness.Table 5 shows the results with three settings ofthe POS tagger.
The best result is, naturally, whenwe use the gold standard also in testing.
How-ever, it is worthwhile noticing that it is better totrain with the same POS tagger available in test-ing, even if its performance is somewhat lower.Table 6 compares the performances of severalof the state of the art dependency parsing systemswith ours.
When comparing with other depen-dency parsing systems it is especially worth notic-ing that our system gives significantly better accu-racy on completely parsed sentences.Interestingly, in the experiments, we allow theparsing algorithm to run many rounds to parse asentece in the testing stage.
However, we foundthat over 99% sentences can be parsed in a singleround.
This supports for our justification about thecorrectness of our model.5 Further Work and ConclusionWe have addressed the problem of using learnedclassifiers in a pipeline fashion, where a task is de-composed into several stages and stage classifiersare used sequentially, where each stage may usethe outcome of previous stages as its input.
Thisis a common computational strategy in natural lan-guage processing and is known to suffer from erroraccumulation and an inability to correct mistakesin previous stages.Sent.
Len.
DA RA CA LA<11 93.4 96.7 85.2 94.611-20 92.4 93.7 56.1 94.721-30 90.4 91.8 32.5 93.431-40 90.4 89.8 16.8 94.0>40 89.7 87.9 8.7 93.3Table 4: The effect of sentences length.
The ex-periment is done with depth = 4.71Train-Test DA RA CA LAgold?pos 90.7 92.0 40.8 93.8pos?pos 90.8 92.3 40.7 94.0gold?gold 92.0 93.9 43.6 95.0Table 5: Comparing different sources of POS tag-ging in a pipeline model.
We set depth= 4 in allthe experiments of this table.System DA RA CA LAY&M03 90.3 91.6 38.4 93.5N&S04 87.3 84.3 30.4 N/AM&C&P05 90.9 94.2 37.5 N/ACurrent Work 90.8 92.3 40.7 94.0Table 6: The comparison between the currentwork with other dependency parsing systems.We abstracted two natural principles, one whichcalls for making the local classifiers used in thecomputation more reliable and a second, whichsuggests to devise the pipeline algorithm in sucha way that minimizes the number of decisions (ac-tions) made.We study this framework in the context of de-signing a bottom up dependency parsing.
Not onlywe manage to use this framework to justify severaldesign decisions, but we also show experimentallythat following these results in improving the accu-racy of the inferred trees relative to existing mod-els.
Interestingly, we can show that the trees pro-duced by our algorithm are relatively good evenfor long sentences, and that our algorithm is do-ing especially well when evaluated globally, at asentence level, where our results are significantlybetter than those of existing approaches ?
perhapsshowing that the design goals were achieved.Our future work includes trying to generalizethis work to non-projective dependency parsing,as well as attempting to incorporate additionalsources of information (e.g., shallow parsing in-formation) into the pipeline process.6 AcknowledgementsWe thank Ryan McDonald for providing the anno-tated data set and to Vasin Punyakanok for usefulcomments and suggestions.This research is supported by the AdvancedResearch and Development Activity (ARDA)?sAdvanced Question Answering for Intelligence(AQUAINT) Program and a DOI grant under theReflex program.ReferencesA.
V. Aho, R. Sethi, and J. D. Ullman.
1986.
Compilers:Principles, techniques, and tools.
In Addison-Wesley Pub-lishing Company, Reading, MA.A.
Carlson, C. Cumby, J. Rosen, and D. Roth.
1999.The SNoW learning architecture.
Technical ReportUIUCDCS-R-99-2101, UIUC Computer Science Depart-ment, May.J.
Eisner.
1996.
Three new probabilistic models for de-pendency parsing: An exploration.
In Proc.
the Inter-national Conference on Computational Linguistics (COL-ING), pages 340?345, Copenhagen, August.A.
Haghighi, A. Ng, and C. Manning.
2005.
Robust textualinference via graph matching.
In Proceedings of HumanLanguage Technology Conference and Conference on Em-pirical Methods in Natural Language Processing, pages387?394, Vancouver, British Columbia, Canada, October.Association for Computational Linguistics.T.
Marciniak and M. Strube.
2005.
Beyond the pipeline: Dis-crete optimization in NLP.
In Proceedings of the NinthConference on Computational Natural Language Learn-ing (CoNLL-2005), pages 136?143, Ann Arbor, Michigan,June.
Association for Computational Linguistics.M.
P. Marcus, B. Santorini, and M. Marcinkiewicz.
1993.Building a large annotated corpus of English: The PennTreebank.
Computational Linguistics, 19(2):313?330,June.R.
McDonald, K. Crammer, and F. Pereira.
2005.
Onlinelarge-margin training of dependency parsers.
In Proc.
ofthe Annual Meeting of the ACL, pages 91?98, Ann Arbor,Michigan.J.
Nivre and M. Scholz.
2004.
Deterministic dependencyparsing of english text.
In COLING2004, pages 64?70.Joakim Nivre.
2003.
An efficient algorithm for projectivedependency parsing.
In IWPT, Nancy, France.V.
Punyakanok, D. Roth, and W. Yih.
2005.
The necessityof syntactic parsing for semantic role labeling.
In Proc.of the International Joint Conference on Artificial Intelli-gence (IJCAI), pages 1117?1123.A.
Ratnaparkhi.
1997.
A linear observed time statisticalparser based on maximum entropy models.
In EMNLP-97, The Second Conference on Empirical Methods in Nat-ural Language Processing, pages 1?10.D.
Roth and W. Yih.
2004.
A linear programming for-mulation for global inference in natural language tasks.In Hwee Tou Ng and Ellen Riloff, editors, Proc.
of theAnnual Conference on Computational Natural LanguageLearning (CoNLL), pages 1?8.
Association for Computa-tional Linguistics.D.
Roth.
1998.
Learning to resolve natural language ambi-guities: A unified approach.
In Proc.
National Conferenceon Artificial Intelligence, pages 806?813.K.
Toutanova, D. Klein, and C. Manning.
?2003?.
Feature-rich part-of-speech tagging with a cyclic dependency net-work.
In Proceedings of HLT-NAACL 03.H.
Yamada and Y. Matsumoto.
2003.
Statistical dependencyanalysis with support vector machines.
In IWPT2003.H.
Yamada.
2006.
Private communication.72
