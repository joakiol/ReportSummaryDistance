Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 636?646,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsIdentifying Phrasal Verbs Using Many Bilingual CorporaKarl Pichotta?Department of Computer ScienceUniversity of Texas at Austinpichotta@cs.utexas.eduJohn DeNeroGoogle, Inc.denero@google.comAbstractWe address the problem of identifying mul-tiword expressions in a language, focus-ing on English phrasal verbs.
Our poly-glot ranking approach integrates frequencystatistics from translated corpora in 50 dif-ferent languages.
Our experimental eval-uation demonstrates that combining statisti-cal evidence from many parallel corpora us-ing a novel ranking-oriented boosting algo-rithm produces a comprehensive set of Englishphrasal verbs, achieving performance compa-rable to a human-curated set.1 IntroductionA multiword expression (MWE), or noncomposi-tional compound, is a sequence of words whosemeaning cannot be composed directly from themeanings of its constituent words.
These idiosyn-cratic phrases are prevalent in the lexicon of a lan-guage; Jackendoff (1993) estimates that their num-ber is on the same order of magnitude as that of sin-gle words, and Sag et al(2002) suggest that theyare much more common, though quantifying themis challenging (Church, 2011).
The task of identify-ing MWEs is relevant not only to lexical semanticsapplications, but also machine translation (Koehn etal., 2003; Ren et al 2009; Pal et al 2010), informa-tion retrieval (Xu et al 2010; Acosta et al 2011),and syntactic parsing (Sag et al 2002).
Awarenessof MWEs has empirically proven useful in a num-ber of domains: Finlayson and Kulkarni (2011), forexample, use MWEs to attain a significant perfor-mance improvement in word sense disambiguation;Venkatapathy and Joshi (2006) use features associ-ated with MWEs to improve word alignment.
?Research conducted during an internship at Google.We focus on a particular subset of MWEs, Englishphrasal verbs.
A phrasal verb consists of a headverb followed by one or more particles, such thatthe meaning of the phrase cannot be determined bycombining the simplex meanings of its constituentwords (Baldwin and Villavicencio, 2002; Dixon,1982; Bannard et al 2003).1 Examples of phrasalverbs include count on [rely], look after [tend], ortake off [remove], the meanings of which do not in-volve counting, looking, or taking.
In contrast, thereare verbs followed by particles that are not phrasalverbs, because their meaning is compositional, suchas walk towards, sit behind, or paint on.We identify phrasal verbs by using frequencystatistics calculated from parallel corpora, consist-ing of bilingual pairs of documents such that oneis a translation of the other, with one document inEnglish.
We leverage the observation that a verbwill translate in an atypical way when occurring asthe head of a phrasal verb.
For example, the wordlook in the context of look after will tend to trans-late differently from how look translates generally.In order to characterize this difference, we calculatea frequency distribution over translations of look,then compare it to the distribution of translations oflook when followed by the word after.
We expectthat idiomatic phrasal verbs will tend to have unex-pected translation of their head verbs, measured bythe Kullback-Leibler divergence between those dis-tributions.Our polyglot ranking approach is motivated by thehypothesis that using many parallel corpora of dif-ferent languages will help determine the degree ofsemantic idiomaticity of a phrase.
In order to com-1Nomenclature varies: the term verb-particle constructionis also used to denote what we call phrasal verbs; further, theterm phrasal verb is sometimes used to denote a broader classof constructions.636bine evidence from multiple languages, we developa novel boosting algorithm tailored to the task ofranking multiword expressions by their degree of id-iomaticity.
We train and evaluate on disjoint subsetsof the phrasal verbs in English Wiktionary2.
In ourexperiments, the set of phrasal verbs identified au-tomatically by our method achieves held-out recallthat nears the performance of the phrasal verbs inWordNet 3.0, a human-curated set.
Our approachstrongly outperforms a monolingual system, andcontinues to improve when incrementally addingtranslation statistics for 50 different languages.2 Identifying Phrasal VerbsThe task of identifying phrasal verbs using corpusinformation raises several issues of experimental de-sign.
We consider four central issues below in moti-vating our approach.Types vs. Tokens.
When a phrase is used in con-text, it takes a particular meaning among its pos-sible senses.
Many phrasal verbs admit composi-tional senses in addition to idiomatic ones?contrastidiomatic ?look down on him for his politics?
withcompositional ?look down on him from the balcony.
?In this paper, we focus on the task of determiningwhether a phrase type is a phrasal verb, meaning thatit frequently expresses an idiomatic meaning acrossits many token usages in a corpus.
We do not at-tempt to distinguish which individual phrase tokensin the corpus have idiomatic senses.Ranking vs.
Classification.
Identifying phrasalverbs involves relative, rather than categorical, judg-ments: some phrasal verbs are more compositionalthan others, but retain a degree of noncomposition-ality (McCarthy et al 2003).
Moreover, a poly-semous phrasal verb may express an idiosyncraticsense more or less often than a compositional sensein a particular corpus.
Therefore, we should expecta corpus-driven system not to classify phrases asstrictly idiomatic or compositional, but instead as-sign a ranking or relative scoring to a set of candi-dates.Candidate Phrases.
We distinguish between thetask of identifying candidate multiword expressions2http://en.wiktionary.orgFeature Description?L (?50) KL Divergence for each language L?1 frequency of phrase given verb?2 PMI of verb and particles?3 ?1 with interposed pronounsTable 1: Features used by the polyglot ranking system.and the task of ranking those candidates by their se-mantic idiosyncracy.
With English phrasal verbs, itis straightforward to enumerate all desired verbs fol-lowed by one or more particles, and rank the entireset.Using Parallel Corpora.
There have been a num-ber of approaches proposed for the use of multilin-gual resources for MWE identification (Melamed,1997; Villada Moiro?n and Tiedemann, 2006; Caseliet al 2010; Tsvetkov and Wintner, 2012; Salehiand Cook, 2013).
Our approach differs from pre-vious work in that we identify MWEs using transla-tion distributions of verbs, as opposed to 1?1, 1?m,or m?n word alignments, most-likely translations,bilingual dictionaries, or distributional entropy.
Tothe best of our knowledge, ours is the first approachto use translational distributions to leverage the ob-servation that a verb typically translates differentlywhen it heads a phrasal verb.3 The Polyglot Ranking ApproachOur approach uses bilingual and monolingual statis-tics as features, computed over unlabeled corpora.Each statistic characterizes the degree of idiosyn-crasy of a candidate phrasal verb, using a singlemonolingual or bilingual corpus.
We combine fea-tures for many language pairs using a boosting algo-rithm that optimizes a ranking objective using a su-pervised training set of English phrasal verbs.
Eachof these aspects of our approach is described in de-tail below; for reference, Table 1 provides a list ofthe features used.3.1 Bilingual StatisticsOne of the intuitive properties of an MWE is thatits individual words likely do not translate literallywhen the whole expression is translated into anotherlanguage (Melamed, 1997).
We capture this effect637by measuring the divergence between how a verbtranslates generally and how it translates when head-ing a candidate phrasal verb.A parallel corpus is a collection of documentpairs ?DE , DF ?, where DE is in English, DF is inanother language, one document is a translation ofthe other, and all documents DF are in the samelanguage.
A phrase-aligned parallel corpus alignsthose documents at a sentence, phrase, and wordlevel.
A phrase e aligns to another phrase f if someword in e aligns to some word in f and no word ine or f aligns outside of f or e, respectively.
As aresult of this definition, the words within an alignedphrase pair are themselves connected by word-levelalignments.Given an English phrase e, define F (e) to be theset of all foreign phrases observed aligned to e in aparallel corpus.
For any f ?
F (e), let P (f |e) be theconditional probability of the phrase e translating tothe phrase f .
This probability is estimated as therelative frequency of observing f and e as an alignedphrase pair, conditioned on observing e aligned toany phrase in the corpus:P (f |e) = N(e, f)?f ?
N(e, f ?
)with N(e, f) the number of times e and f are ob-served occurring as an aligned phrase pair.Next, we assign statistics to individual verbswithin phrases.
The first word of a candidate phrasalverb e is a verb.
For a candidate phrasal verb e anda foreign phrase f , let pi1(e, f) be the subphrase off that is most commonly word-aligned to the firstword of e. As an example, consider the phrase paire = talk down to and f = hablar con menosprecio.Suppose that when e is aligned to f , the word talk ismost frequently aligned to hablar.
Then pi1(e, f) =hablar.For a phrase e and its set F (e) of aligned trans-lations, we define the constituent translation proba-bility of a foreign subphrase x as:Pe(x) =?f?F (e)P (f |e) ?
?
(pi1(e, f), x) (1)where ?
is the Kronecker delta function, taking value1 if its arguments are equal and 0 otherwise.
Intu-itively, Pe assigns the probability mass for every fto its subphrase most commonly aligned to the verbin e. It expresses how this verb is translated in thecontext of a phrasal verb construction.3 Equation (1)defines a distribution over all phrases x of a foreignlanguage.We also assign statistics to verbs as they are trans-lated outside of the context of a phrase.
Let v(e)be the verb of a phrasal verb candidate e, whichis always its first word.
For a single-word verbphrase v(e), we can compute the constituent transla-tion probability Pv(e)(x), again using Equation (1).The difference between Pe(x) and Pv(e)(x) is thatthe latter sums over all translations of the verb v(e),regardless of whether it appears in the context of e:Pv(e)(x) =?f?F (v(e))P (f |v(e)) ?
?
(pi1(v(e), f), x)For a one-word phrase such as v(e), pi1(v(e), f)is the subphrase of f that most commonly directlyword-aligns to the one word of v(e).Finally, for a phrase e and its verb v(e), we calcu-late the Kullback-Leibler (KL) divergence betweenthe translation distribution of v(e) and e:DKL(Pv(e)?Pe)=?xPv(e)(x) lnPv(e)(x)Pe(x)(2)where the sum ranges over all x such that Pv(e)(x) >0.
This quantifies the difference between the trans-lations of e?s verb when it occurs in e, and when itoccurs in general.
Figure 1 illustrates this computa-tion on a toy corpus.Smoothing.
Equation (2) is defined only if, for ev-ery x such that Pv(e)(x) > 0, it is also the casethat Pe(x) > 0.
In order to ensure that this con-dition holds, we smooth the translation distributionstoward uniform.
Let D be the set of phrases withnon-zero probability under either distribution:D = {x : Pv(e)(x) > 0 or Pe(x) > 0}Then, let UD be the uniform distribution over D:UD(x) ={1/|D| if x ?
D0 if x /?
D3To extend this statistic to other types of multiword expres-sions, one could compute a similar distribution for other contentwords in the phrase.6380%10%20%30%40%50%0 5 10 15 20 25 30 35 40 45 50Testsetrecall-at-1220Number of languages (k)Combined with AdaBoostIndividual Bilingual Statisticslooking forward tomirando adelante alooking forward todeseandolookingmirandolookingbuscando  a3153Aligned Phrase PairN(e, f) ?1(e, f)mirandodeseandomirandobuscando\begin{tabular}{rrrr}&\textit{mirando}   &\textit{deseando} &\textit{buscando} \\ [2ex]$P_{v(e)}(x)$ &$\frac{5}{8}=0.625 $  &$0$       &$\frac{3}{8}=0.375 $ \\ [1ex]\hline \\ [-1ex]$P'_{v(e)}(x)$&$0.610     $         &$0.02$     &$0.373$ \\ [1ex]\hline \\ [-1ex]$P_e(x)$ &$\frac{3}{4}=0.75 $  &$\frac{1}{4}=0.25 $ &$0$ \\ [1.5ex]\hline \\ [-1ex]$P'_e(x)$&$0.729     $         &$0.254    $     &$0.02$ \\ [1ex]\hline \\ [-1ex]\end{tabular}DKL(P 0v(ei)kP 0ei) =  0.109 + 0.045 + 1.159 = 1.005D_{KL} (P'_{v(e_i)} \| P'_{e_i}) = -0.109 + -0.045 + 1.159 = 1.005mirando deseando buscandoPv(e)(x) 58 = 0.625 0 38 = 0.375P 0v(e)(x) 0.610 0.02 0.373Pe(x) 34 = 0.75 14 = 0.25 0P 0e(x) 0.729 0.254 0.02Figure 1: The computation of DKL(P ?v(ei)?P?ei) using atoy corpus, for e = looking forward to.
Note that the sec-ond aligned phrase pair contains the third, so the second?scount of 3 must be included in the third?s count of 5.When computing divergence in Equation (2), we usethe smoothed distributions P ?e and P ?v(e):P ?e(x) = ?Pe(x) + (1?
?
)UD(x)P ?v(e)(x) = ?Pv(e)(x) + (1?
?
)UD(x).We use ?
= 0.95, which distributes 5% of the totalprobability mass evenly among all events in D.Morphology.
We calculate statistics for morpho-logical variants of an English phrase.
For a candi-date English phrasal verb e (for example, look up),letE denote the set of inflections of that phrasal verb(for look up, this will be [look|looks|looked|looking]up).
We extract the variants in E from the verb en-tries in English Wiktionary.
The final score com-puted from a phrase-aligned parallel corpus translat-ing English sentences into a language L is the aver-age KL divergence of smoothed constituent transla-tion distributions for any inflected form ei ?
E:?L(e) =1|E|?ei?EDKL(P ?v(ei)?P?ei)3.2 Monolingual StatisticsWe also collect a number of monolingual statisticsfor each phrasal verb candidate, motivated by theconsiderable body of previous work on the topic(Church and Hanks, 1990; Lin, 1999; McCarthy etal., 2003).
The monolingual statistics are designedto identify frequent collocations in a language.
Thisset of monolingual features is not comprehensive, aswe focus our attention primarily on bilingual fea-tures in this paper.As above, define E to be the set of morpholog-ically inflected variants of a candidate e, and letV be the set of inflected variants of the head verbv(e) of e. We define three statistics calculated fromthe phrase counts of a monolingual English corpus.First, we define ?1(e) to be the relative frequency ofthe candidate e, given e?s head verb, summed overmorphological variants:?1(e) = lnP (E|V )= ln?ei?EN(ei)?vi?VN(vi)where N(x) is the number of times phrase x wasobserved in the monolingual corpus.Second, define ?2(e) to be the pointwise mutualinformation (PMI) between V (the event that one ofthe inflections of the verb in e is observed) and R,the event of observing the rest of the phrase:?2(e)= PMI(V,R)= lgP (V,R)?
lg (P (V )P (R))= lgP (E)?
lg (P (V )P (R))= lg?ei?EN(ei)?lg?vi?VN(vi)?lgN(r)+lgNwhere N is the total number of tokens in the corpus,and logarithms are base-2.
This statistic character-izes the degree of association between a verb andits phrasal extension.
We only calculate ?2 for two-word phrases, as it did not prove helpful for longerphrases.639Finally, define ?3(e) to be the relative frequencyof the phrasal verb e augmented by an accusativepronoun, conditioned on the verb.
Let A be theset of phrases in E with an accusative pronoun (it,them, him, her, me, you) optionally inserted either atthe end of the phrase or directly after the verb.
Fore = look up, A = {look up, look X up, look up X,looks up, looks X up, looks up X, .
.
.
}, with X anaccusative pronoun.
The ?3 statistic is similar to ?1,but allows for an intervening or following pronoun:?3(e) = lnP (A|V )= ln?ei?AN(ei)?vi?VN(vi).This statistic is designed to exploit the intuition thatphrasal verbs frequently have accusative pronounseither inserted into the middle (e.g.
look it up) or atthe end (e.g.
look down on him).3.3 Ranking Phrasal Verb CandidatesOur goal is to assign a single real-valued score toeach candidate e, by which we can rank candidatesaccording to semantic idiosyncrasy.
For each lan-guage L for which we have a parallel corpus, wedefined, in section 3.1, a function ?L(e) assigningreal values to candidate phrasal verbs e, which wehypothesize is higher on average for more idiomaticcompounds.
Further, in section 3.2, we defined real-valued monolingual functions ?1, ?2, and ?3 forwhich we hypothesize the same trend holds.
Be-cause each score individually ranks all candidates,it is natural to view each ?L and ?i as a weak rank-ing function that we can combine with a supervisedboosting objective.
We use a modified version ofAdaBoost (Freund and Schapire, 1995) that opti-mizes for recall.For each ?L and ?i, we compute a ranked listof candidate phrasal verbs, ordered from highest tolowest value.
To simplify learning, we consider onlythe top 5000 candidate phrasal verbs according to?1, ?2, and ?3.
This pruning procedure excludescandidates that do not appear in our monolingualcorpus.We optimize the ranker using an unranked, in-complete training set of phrasal verbs.
We can eval-uate the quality of the ranker by outputting the topN ranked candidates and measuring recall relativeAlgorithm 1 Recall-Oriented Ranking AdaBoost1: for i = 1 : |X| do2: w[i]?
1/|X|3: end for4: for t = 1 : T do5: for all h ?
H do6: h ?
07: for i = 1 : |X| do8: if xi 6?
h then9: h ?
h + w[i]10: end if11: end for12: end for13: ht ?
argmaxh?H |B ?
h|14: ?t ?
ln(B/ht)15: for i = 1 : |X| do16: if xi ?
ht then17: w[i]?
1Zw[i] exp (?
?t)18: else19: w[i]?
1Zw[i] exp (?t)20: end if21: end for22: end forto this gold-standard training set.
We choose thisrecall-at-N metric so as to not directly penalize pre-cision errors, as our training set is incomplete.DefineH to be the set of N -element sets contain-ing the top proposals for each weak ranker (we useN = 2000).
That is, each element ofH is a set con-taining the 2000 highest values for some ?L or ?i.We define the baseline error B to be 1?E[R], withR the recall-at-N of a ranker ordering the candidatephrases in the set ?H at random.
The value E[R] isestimated by averaging the recall-at-N of 1000 ran-dom orderings of ?H.Algorithm 1 gives the formulation of the Ada-Boost training algorithm that we use to combineweak rankers.
The algorithm maintains a weightvector w (summing to 1) which contains a positivereal number for each gold standard phrasal verb inthe training set X .
Initially, w is uniformly set to1/|X|.
At each iteration of the algorithm, w is mod-ified to take higher values for recently misclassi-fied examples.
We repeatedly choose weak rankersht ?
H (and corresponding real-valued coefficients?t) that correctly rank examples with high w values.640Lines 5?12 of Algorithm 1 calculate the weightederror values h for every weak ranker set h ?
H.The error h will be 1 if h contains none of X and 0if h contains all of X , as w always sums to 1.
Line13 picks the ranker ht ?
H whose weighted error isas far as possible from the random baseline error B .Line 14 calculates a coefficient ?t for ht, which willbe positive if ht < B and negative if ht > B .Intuitively, ?t encodes the importance of ht?it willbe high if ht performs well, and low if it performspoorly.
The Z in lines 17 and 19 is the normalizingconstant ensuring the vector w sums to 1.After termination of Algorithm 1, we haveweights ?1, .
.
.
, ?T and lists h1, .
.
.
, hT .
Define ftas the function that generated the list ht (each ft willbe some ?L or ?i).
Now, we define a final combinedfunction ?, taking a phrase e and returning a realnumber:?
(e) =T?t=1?tft(e).We standardize the scores of individual weakrankers to have mean 0 and variance 1, so that theirscores are comparable.The final learned ranker outputs a real value, in-stead of the class labels frequently found in Ada-Boost.
This follows previous work using boostingfor learning to rank (Freund et al 2003; Xu and Li,2007).
Our algorithm differs from previous methodsbecause we are seeking to optimize for Recall-at-N ,rather than a ranking loss.4 Experimental Evaluation4.1 Training and Test SetIn order to train and evaluate our system, we con-struct a gold-standard list of phrasal verbs fromthe freely available English Wiktionary.
We gatherphrasal verbs from three sources within Wiktionary:1.
Entries labeled as English phrasal verbs4,2.
Entries labeled as English idioms5, and3.
The derived terms6 of English verb entries.4http://en.wiktionary.org/wiki/Category:English_phrasal_verbs5http://en.wiktionary.org/wiki/Category:English_idioms6For example, see http://en.wiktionary.org/wiki/take#Derived_termsabout across after against alongamong around at before behindbetween beyond by down forfrom in into like offon onto outside over pastround through to towards underup upon with within withoutTable 2: Particles and prepositions allowed in phrasalverbs gathered from Wiktionary.Many of the idioms and derived terms are notphrasal verbs (e.g.
kick the bucket, make-or-break).We filter out any phrases not of the form V P+, withV a verb, and P+ denoting one or more occurrencesof particles and prepositions from the list in Table 2.We omit prepositions that do not productively formEnglish phrasal verbs, such as amid and as.
Thisprocess also omits some compounds that are some-times called phrasal verbs, such as light verb con-structions, e.g.
have a go (Butt, 2003), and noncom-positional verb-adverb collocations, e.g.
look for-ward.There are a number of extant phrasal verb cor-pora.
For example, McCarthy et al(2003) presentgraded human compositionality judgments for 116phrasal verbs, and Baldwin (2008) presents a largeset of candidates produced by an automated system,with false positives manually removed.
We use Wik-tionary instead, in an attempt to construct a maxi-mally comprehensive data set that is free from anypossible biases introduced by automatic extractionprocesses.4.2 Filtering and Data PartitionThe merged list of phrasal verbs extracted from Wik-tionary included some common collocations thathave compositional semantics (e.g.
know about), aswell as some very rare constructions (e.g.
cheesedown).
We removed these spurious results system-atically by filtering out very frequent and very infre-quent entries.
First, we calculated the log probabilityof each phrase, according to a language model builtfrom a large monolingual corpus of news documentsand web documents, smoothed with stupid back-off (Brants et al 2007).
We sorted all Wiktionaryphrasal verbs according to this value.
Then, we se-lected the contiguous 75% of the sorted phrases thatminimize the variance of this statistic.
This method641Recall-at-1220Dev TestFrequent Candidates 17.0 19.3BaselineWordNet 3.0 Frequent 41.6 43.7WordNet 3.0 Filtered 49.4 48.8Monolingual Only 30.1 30.2BoostedBilingual Only 47.1 43.9Monolingual+Bilingual 50.8 47.9Table 3: Our boosted ranker combining monolingualand bilingual features (bottom) compared to three base-lines (top) gives comparable performance to the human-curated upper bound.removed a few very frequent phrases and a largenumber of rare phrases.
The remaining phrases weresplit randomly into a development set of 694 itemsand a held-out test set of 695 items.4.3 CorporaOur monolingual English corpus consists of news ar-ticles and documents collected from the web.
Ourparallel corpora from English to each of 50 lan-guages also consist of documents collected fromthe web via distributed data mining of parallel doc-uments based on the text content of web pages(Uszkoreit et al 2010).The parallel corpora were segmented into alignedsentence pairs and word-aligned using two iterationsof IBM Model 1 (Brown et al 1993) and two iter-ations of the HMM-based alignment model (Vogelet al 1996) with posterior symmetrization (Liang etal., 2006).
This training recipe is common in large-scale machine translation systems.4.4 Generating CandidatesTo generate the set of candidate phrasal verbs con-sidered during evaluation, we exhaustively enumer-ated the Cartesian product of all verbs present in thepreviously described Wiktionary set (V), all parti-cles in Table 2 (P) and a small set of second parti-cles T = {with, to, on, }, with  the empty string.The set of candidate phrasal verbs we consider dur-ing evaluation is the product V ?P ?T , which con-tains 96,880 items.4.5 ResultsWe optimize a ranker using the boosting algorithmdescribed in section 3.3, using the features from Ta-ble 1, optimizing performance on the Wiktionary de-velopment set described in section 4.2.
Monolingualand bilingual statistics are calculated using the cor-pora described in section 4.3, with candidate phrasalverbs being drawn from the set described in section4.4.We evaluate our method of identifying phrasalverbs by computing recall-at-N .
This statistic is thefraction of the Wiktionary test set that appears in thetop N proposed phrasal verbs by the method, whereN is an arbitrary number of top-ranked candidatesheld constant when comparing different approaches(we use N = 1220).
We do not compute precision,because the test set to which we compare is not anexhaustive list of phrasal verbs, due to the develop-ment/test split, frequency filtering, and omissions inthe original lexical resource.
Proposing a phrasalverb not in the test set is not necessarily an error, butidentifying many phrasal verbs from the test set is anindication of an effective method.
Recall-at-N is anatural way to evaluate a ranking system where thegold-standard data is an incomplete, unranked set.Table 3 compares our approach to three baselinesusing the Recall-at-1220 metric evaluated on boththe development and test sets.
As a lower bound, weevaluated the 1220 most frequent candidates in ourMonolingual corpus (Frequent Candidates).As a competitive baseline, we evaluated the set ofphrasal verbs in WordNet 3.0 (Fellbaum, 1998).
Weselected the most frequent 1220 out of 1781 verb-particle constructions in WordNet (WordNet 3.0 Fre-quent).
A stronger baseline resulted from apply-ing the same filtering procedure to WordNet thatwe did to Wiktionary: sorting all verb-particle en-tries by their language model score and retaining the1220 consecutive entries that minimized languagemodel variance (WordNet 3.0 Filtered).
WordNetis a human-curated resource, and yet its recall-at-Ncompared to our Wiktionary test set is only 48.8%,indicating substantial divergence between the tworesources.
Such divergence is typical: lexical re-sources often disagree about what multiword expres-sions to include (Lin, 1999).The three final lines in Table 3 evaluate our6420%10%20%30%40%50%0 5 10 15 20 25 30 35 40 45 50Testsetrecall-at-1220Number of languages (k)Combined with AdaBoostIndividual Bilingual StatisticsFigure 2: The solid line shows recall-at-1220 when com-bining the k best-performing bilingual statistics and threemonolingual statistics.
The dotted line shows the indi-vidual performance of the kth best-performing bilingualstatistic, when applied in isolation to rank candidates.boosted ranker.
Automatically detecting phrasalverbs using monolingual features alone strongly out-performed the frequency-based lower bound, but un-derperformed the WordNet baseline.
Bilingual fea-tures, using features from 50 languages, proved sub-stantially more effective.
The combination of bothtypes of features yielded the best performance, out-performing the human-curated WordNet baseline onthe development set (on which our ranker was opti-mized) and approaching its performance on the held-out test set.4.6 Feature AnalysisThe solid line in Figure 2 shows the recall-at-1220for a boosted ranker using all monolingual statisticsand k bilingual statistics, for increasing k. Bilin-gual statistics are added according to their individualrecall, from best-performing to worst.
That is, thepoint at k = 0 uses only ?1, ?2, and ?3, the point atk = 1 adds the best individually-performing bilin-gual statistic (Spanish) as a weak ranker, the nextpoint adds the second-best bilingual statistic (Ger-man), etc.
Boosting maximizes performance on thedevelopment set, and evaluation is performed on thetest set.
We use T = 53 (equal to the total numberof weak rankers).Recall-at-1220Dev TestBilingual only 47.1 43.9Bilingual+?1 48.1 46.9Bilingual+?2 50.1 48.3Bilingual+?3 48.4 46.3Bilingual+?1 + ?2 50.2 47.9Bilingual+?1 + ?3 49.0 47.4Bilingual+?2 + ?3 50.4 49.4Bilingual+?1 + ?2 + ?3 50.8 47.9Table 4: An ablation of monolingual statistics shows thatthey are useful in addition to the 50 bilingual statisticscombined, and no single statistic provides maximal per-formance.The dotted line in Figure 2 shows that individualbilingual statistics have recall-at-1220 ranging from34.4% to 5.0%.
This difference reflects the differ-ent sizes of parallel corpora and usefulness of dif-ferent languages in identifying English semantic id-iosyncrasy.
Combining together the signal of mul-tiple languages is clearly beneficial, and includingmany low-performing languages still offers overallimprovements.Table 4 shows the effect of adding different sub-sets of the monolingual statistics to the set of all50 bilingual statistics.
Monolingual statistics givea performance improvement of up to 5.5% recallon the test set, but the comparative behavior of thevarious combinations of the ?i is somewhat unpre-dictable when training on the development set andevaluating on the test set.
The pointwise mutual in-formation of a verb and its particles (?2) appears tobe the most useful feature.
In fact, the test set per-formance of using ?2 alone outperforms the combi-nation of all three.
The best combination even out-performs the WordNet 3.0 baseline on the test set,though optimizing on the development set would notselect this model.4.7 Error AnalysisTable 5 shows the 100 highest ranked phrasal verbcandidates by our system that do not appear in eitherthe development or test sets.
Most of these candi-dates are in fact English phrasal verbs that happenedto be missing from Wiktionary; some are presentin Wiktionary but were removed from the reference643pick up pat on tap into fit for charge with suit againstcatch up burst into muck up haul up give up get offget through get up get in tack on buzz about do likeplump for haul in keep up with strap on catch up with suck intoget round chop off slap on pitch into get into inquire intodrop behind get on catch up on pass on cue from carry aroundget around get over shoot at pick over shoot by shoot inmake up to get past cast down set up with rule off hand roundpiss on hit by break down move for lead off pluck offflip through edge over strike off plug into keep up go pastset off pull round see about stay on put up sidle up tobuzz around take off set up slap in head towards shoot pastinquire for tuck up lie with well before go on with reel fromdrive along snap off barge into whip on put down instance throughbar from cut down on let in tune in to move off suit inlean against well beyond get down to go across sail into lie overhit with chow down on look after catch atTable 5: The highest ranked phrasal verb candidates from our full system that do not appear in either Wiktionary set.Candidates are presented in decreasing rank; ?pat on?
is the second highest ranked candidate.sets during filtering, and the remainder are in factnot phrasal verbs (true precision errors).These errors fall largely into two categories.Some candidates are compositional, but contain pol-ysemous verbs, such as hit by, drive along, and headtowards.
In these cases, prepositions disambiguatethe verb, which naturally affects translation distri-butions.
Other candidates are not phrasal verbs, butinstead phrases that tend to have a different syntac-tic role, such as suit against, instance through, fitfor, and lie over (conjugated as lay over).
A care-ful treatment of part-of-speech tags when computingcorpus statistics might address this issue.5 Related WorkThe idea of using word-aligned parallel corporato identify idiomatic expressions has been pur-sued in a number of different ways.
Melamed(1997) tests candidate MWEs by collapsing theminto single tokens, training a new translation modelwith these tokens, and using the performance ofthe new model to judge candidates?
noncomposi-tionality.
Villada Moiro?n and Tiedemann (2006)use word-aligned parallel corpora to identify DutchMWEs, testing the assumption that the distributionsof alignments of MWEs will generally have higherentropies than those of fully compositional com-pounds.
Caseli et al(2010) generate candidate mul-tiword expressions by picking out sufficiently com-mon phrases that align to single target-side tokens.Tsvetkov and Wintner (2012) generate candidateMWEs by finding one-to-one alignments in paral-lel corpora which are not in a bilingual dictionary,and ranking them based on monolingual statistics.The system of Salehi and Cook (2013) is perhapsthe closest to the current work, judging noncompo-sitionality using string edit distance between a can-didate phrase?s automatic translation and its com-ponents?
individual translations.
Unlike the currentwork, their method does not use distributions overtranslations or combine individual bilingual valueswith boosting; however, they find, as we do, that in-corporating many languages is beneficial to MWEidentification.A large body of work has investigated the identifi-cation of noncompositional compounds from mono-lingual sources (Lin, 1999; Schone and Jurafsky,2001; Fazly and Stevenson, 2006; McCarthy etal., 2003; Baldwin et al 2003; Villavicencio,2003).
Many of these monolingual statistics couldbe viewed as weak rankers and fruitfully incorpo-rated into our framework.There has also been a substantial amount of workaddressing the problem of differentiating betweenliteral and idiomatic instances of phrases in con-text (Katz and Giesbrecht, 2006; Li et al 2010;644Sporleder and Li, 2009; Birke and Sarkar, 2006;Diab and Bhutada, 2009).
We do not attempt thistask; however, techniques for token identificationcould be used to improve type identification (Bald-win, 2005).6 ConclusionWe have presented the polyglot ranking approachto phrasal verb identification, using parallel corporafrom many languages to identify phrasal verbs.
Weproposed an evaluation metric that acknowledges theinherent incompleteness of reference sets, but dis-tinguishes among competing systems in a manneraligned to the goals of the task.
We developed arecall-oriented learning method that integrates mul-tiple weak ranking signals, and demonstrated exper-imentally that combining statistical evidence from alarge number of bilingual corpora, as well as frommonolingual corpora, produces the most effectivesystem overall.
We look forward to generalizingour approach to other types of noncompositionalphrases.AcknowledgmentsSpecial thanks to Ivan Sag, who argued for theimportance of handling multi-word expressions innatural language processing applications, and whotaught the authors about natural language syntaxonce upon a time.
We would also like to thank theanonymous reviewers for their helpful suggestions.ReferencesOtavio Acosta, Aline Villavicencio, and Viviane Moreira.2011.
Identification and treatment of multiword ex-pressions applied to information retrieval.
In Proceed-ings of the ACL Workshop on Multiword Expressions.Timothy Baldwin and Aline Villavicencio.
2002.
Ex-tracting the unextractable: A case study on verb-particles.
In Proceedings of the Sixth Conference onNatural Language Learning.Timothy Baldwin, Colin Bannard, Takaaki Tanaka, andDominic Widdows.
2003.
An empirical model ofmultiword expression decomposability.
In Proceed-ings of the ACL Workshop on Multiword Expressions.Timothy Baldwin.
2005.
Deep lexical acquisition ofverb-particle constructions.
Computer Speech & Lan-guage, Special Issue on Multiword Expressions.Timothy Baldwin.
2008.
A resource for evaluating thedeep lexical acquisition of english verb-particle con-structions.
In Proceedings of the LREC Workshop To-wards a Shared Task for Multiword Expressions.Colin Bannard, Timothy Baldwin, and Alex Lascarides.2003.
A statistical approach to the semantics of verb-particles.
In Proceedings of the ACL Workshop onMultiword Expressions.Julia Birke and Anoop Sarkar.
2006.
A clustering ap-proach for the nearly unsupervised recognition of non-literal language.
In Proceedings of European Chapterof the Association for Computational Linguistics.Thorsten Brants, Ashok C. Popat, Peng Xu, Franz J.Och, and Jeffrey Dean.
2007.
Large language mod-els in machine translation.
In Proceedings of the JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning.Peter F. Brown, Stephen A. Della Pietra, Vincent J. DellaPietra, and Robert L. Mercer.
1993.
The mathematicsof statistical machine translation: Parameter estima-tion.
Computational Linguistics.Miriam Butt.
2003.
The light verb jungle.
In Proceed-ings of the Workshop on Multi-Verb Constructions.Helena de Medeiros Caseli, Carlos Ramisch, Maria dasGrac?as Volpe Nunes, and Aline Villavicencio.
2010.Alignment-based extraction of multiword expressions.Language Resources and Evaluation.Kenneth Ward Church and Patrick Hanks.
1990.
Wordassociation norms, mutual information, and lexicogra-phy.
Computational Linguistics, 16(1).Kenneth Church.
2011.
How many multiword expres-sions do people know?
In Proceedings of the ACLWorkshop on Multiword Expressions.Mona T. Diab and Pravin Bhutada.
2009.
Verb nounconstruction MWE token supervised classification.
InProceedings of the ACL Workshop on Multiword Ex-pressions.Robert Dixon.
1982.
The grammar of english phrasalverbs.
Australian Journal of Linguistics.Afsaneh Fazly and Suzanne Stevenson.
2006.
Automat-ically constructing a lexicon of verb phrase idiomaticcombinations.
In Proceedings of the European Chap-ter of the Association for Computational Linguistics.Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
The MIT Press.Mark Finlayson and Nidhi Kulkarni.
2011.
Detectingmultiword expressions improves word sense disam-biguation.
In Proceedings of the ACL Workshop onMultiword Expressions.Yoav Freund and Robert E. Schapire.
1995.
A decision-theoretic generalization of on-line learning and an ap-plication to boosting.
In Proceedings of the Confer-ence on Computational Learning Theory.645Yoav Freund, Raj Iyer, Robert E Schapire, and YoramSinger.
2003.
An efficient boosting algorithm forcombining preferences.
The Journal of MachineLearning Research.Ray Jackendoff.
1993.
The Architecture of the LanguageFaculty.
MIT Press.Graham Katz and Eugenie Giesbrecht.
2006.
Auto-matic identification of non-compositional multi-wordexpressions using latent semantic analysis.
In Pro-ceedings of the ACL Workshop on Multiword Expres-sions.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Proceed-ings of the North American Chapter of the Associationfor Computational Linguistics.Linlin Li, Benjamin Roth, and Caroline Sporleder.
2010.Topic models for word sense disambiguation andtoken-based idiom detection.
In Proceedings of theAssociation for Computational Linguistics.Percy Liang, Ben Taskar, and Dan Klein.
2006.
Align-ment by agreement.
In Proceedings of the NorthAmerican Chapter of the Association for Computa-tional Linguistics.Dekang Lin.
1999.
Automatic identification of non-compositional phrases.
In Proceedings of the Asso-ciation for Computational Linguistics.Diana McCarthy, Bill Keller, and John Carroll.
2003.Detecting a continuum of compositionality in phrasalverbs.
In Proceedings of the ACL Workshop on Multi-word Expressions.I.
Dan Melamed.
1997.
Automatic discovery of non-compositional compounds in parallel data.
In Pro-ceedings of the Conference on Empirical Methods inNatural Language Processing.Santanu Pal, Sudip Kumar Naskar, Pavel Pecina, SivajiBandyopadhyay, and Andy Way.
2010.
Handlingnamed entities and compound verbs in phrase-basedstatistical machine translation.
In Proceedings of theCOLING 2010 Workshop on Multiword Expressions.Zhixiang Ren, Yajuan Lu, Jie Cao, Qun Liu, and YunHuang.
2009.
Improving statistical machine transla-tion using domain bilingual multiword expressions.
InProceedings of the ACL Workshop on Multiword Ex-pressions.Ivan A.
Sag, Timothy Baldwin, Francis Bond, Ann A.Copestake, and Dan Flickinger.
2002.
Multiword ex-pressions: A pain in the neck for NLP.
In Proceedingsof the CICLING Conference on Intelligent Text Pro-cessing and Computational Linguistics.Bahar Salehi and Paul Cook.
2013.
Predicting the com-positionality of multiword expressions using transla-tions in multiple languages.
In Second Joint Confer-ence on Lexical and Computational Semantics.Patrick Schone and Daniel Jurafsky.
2001.
Isknowledge-free induction of multiword unit dictionaryheadwords a solved problem?
In Proceedings ofthe Conference on Empirical Methods in Natural Lan-guage Processing.Caroline Sporleder and Linlin Li.
2009.
Unsupervisedrecognition of literal and non-literal use of idiomaticexpressions.
In Proceedings of the European Chapterof the Association for Computational Linguistics.Yulia Tsvetkov and Shuly Wintner.
2012.
Extractionof multi-word expressions from small parallel corpora.In Natural Language Engineering.Jakob Uszkoreit, Jay Ponte, Ashok Popat, and Moshe Du-biner.
2010.
Large scale parallel document mining formachine translation.
In Proceedings of the Conferenceon Computational Linguistics.Sriram Venkatapathy and Aravind K Joshi.
2006.
Us-ing information about multi-word expressions for theword-alignment task.
In Proceedings of the ACLWorkshop on Multiword Expressions.Begon?a Villada Moiro?n and Jo?rg Tiedemann.
2006.Identifying idiomatic expressions using automaticword-alignment.
In Proceedings of the EACL Work-shop on Multiword Expressions in a Multilingual Con-text.Aline Villavicencio.
2003.
Verb-particle constructionsand lexical resources.
In Proceedings of the ACLworkshop on Multiword expressions.Stephan Vogel, Hermann Ney, and Christoph Tillmann.1996.
HMM-based word alignment in statistical trans-lation.
In Proceedings of the Conference on Computa-tional linguistics.Jun Xu and Hang Li.
2007.
AdaRank: a boosting al-gorithm for information retrieval.
In Proceedings ofthe SIGIR Conference on Research and Developmentin Information Retrieval.Ying Xu, Randy Goebel, Christoph Ringlstetter, andGrzegorz Kondrak.
2010.
Application of the tightnesscontinuum measure to chinese information retrieval.In Proceedings of the COLING Workshop on Multi-word Expressions.646
