Bidirectional Contextual ResolutionStephen G. Pu lman*Centre for Linguistics and Philology,Oxford UniversityThis paper describes a formalism and implementation for the interpretation and generation ofsentences containing con text-dependent constructs like determiners, pronouns,focus, and ellipsis.A variant of quasi-logical form is used as an underspecified meaning representation, related toresolved logical forms via conditional equivalences.
These quivalences define the interpretationof contextually dependent constructs with respect to a given context.
Higher-order unificationand abduction are used in relating expressions tocontexts.
The conditional equivalences can beused unchanged in both the interpretation and the generation direction.1.
IntroductionThis paper has several aims.
Firstly, it outlines a formalism within which quasi-logicalform-based theories of contextual interpretation of sentences can be stated in a waywhich is completely reversible; that is to say, theories expressed within the formalismcan be used to provide interpretations for (utterances of) sentences containing con-textually dependent constructs, given a context; and, given an interpretation and acontext, to generate a sentence which has that interpretation i that context.
Process-ing in both directions is done using exactly the same grammar, and the same set ofcontextual interpretation rules.To give an extremely simplified example, the aim is to have a way of interpretingthe sentences in the left-hand column below as expressing the logical forms in themiddle column, given that they are encountered in that order in an otherwise neutralcontext: and the reverse--given a sequence of logical forms as in the middle column, tobe able to generate (among others) the sequence of sentences in the left-hand column,rather than the unnatural although literally correct version given in the right-handcolumn.Joe sneezed, sneeze(joe) Joe sneezed.He laughed, laugh(joe) Joe laughed.Bill laughed too.
laugh(bill) Bill laughed.We will assume that if the context is loosely specified enough to permit alternativerealizations of the same content, then different versions of the same text could begenerated or analysed:(1) Joe sneezed and laughed.
Bill laughed too.Joe sneezed.
Joe and Bill laughed.Joe sneezed.
He laughed.
So did Bill.Somerville College, Oxford OX2 6HD.
E-mail: stephenpulman@linguistics-phil?l?gy'?xac'ukQ 2001 Association for Computational LinguisticsComputational Linguistics Volume 26, Number 4Secondly, we illustrate the formalism and the general approach by developing anaccount of contextual interpretation based on a kind of quasi-logical form and givingan account of a fragment (in the sense of Montague \[1974a\]) that treats several corephenomena of English contextual dependence.We also have some theoretical objectives: the particular approach illustrated here,like most computational pproaches to contextual interpretation, uses an intermediatequasi-logical form representation level.
Using such a level of representation incurs anobligation to say what it means ("no notation without denotation").
We try to showhow the theory presented here leads to a natural semantics for these quasi-logicalforms, and indeed leads to a truth theory for contextually dependent interpretationthat supports a natural consequence r lation, and one appropriate for cases whereinterpretations are not fully specified.
We relate this approach both to the classicaltradition of formal linguistic semantics exemplified by Davidson (1972) and Mon-tague (1974b) and more recent literature on the use of underspecification in seman-tics.The structure of the paper is as follows: In the next section we give an outline ofthe formalism and illustrate with the small fragment of English that has been imple-mented within this framework.
We present analyses of the contextual interpretation ofpronouns, definites, ellipsis, focus, and quantifier scope.
There is far more to say abouteach of these phenomena, of course, and the analyses here are by no means claimed tobe definitive.
The aim is merely to show that we can, to a first approximation, providea reasonably fully worked out description of these phenomena in a truly bidirectionalway.We then go on to compare the current approach with that of some other theorieswith similar aims: the "standard" version of quasi-logical form implemented in theCore Language Engine, as rationally reconstructed by Alshawi and Crouch (1992) andCrouch and Pulman (1994); underspecified Discourse Representation Theory (Reyle1993); and the "glue language" approach of Dalrymple et al (1996).Finally, we discuss ome of the semantic and logical issues raised by the approachdescribed here, in particular the extent o which the theory meets the desiderata foraccounts of underspecification utlined by van Eijck and Jaspars (1996), and the extentto which the theory supplies a methodologically satisfactory account of truth andinterpretation for sentences involving contextually dependent constructs.2.
Contextual InterpretationThe major components and assumptions of the approach to contextual interpretationhere are as follows:.
We assume that the output of grammatical processing of a sentence is aquasi-logical form, henceforth QLF.
Of course, for anything other than atrivial grammar, a given sentence will typically yield many QLFs.
Wewill assume that syntactic and lexical disambiguation have taken placeand that the only things still needed for a complete interpretation are theresolution of constructs like pronouns, definites, ellipsis, and so on.
Wereturn later to issues concerning robustness of linguistic coverage and tothe interleaving of contextual disambiguation with syntactic andsemantic processing.For concreteness, we are assuming here that QLFs are built using asimple unification grammar formalism of the type described in Pulman(1996), and that a chart parser and semantic head-driven generator are498Pulman Bidirectional Contextual Resolution..used for the analysis of sentences to QLFs and vice versa.
But little ofthis detail is essential to our main aims: a wide range of grammaticalformalisms and interpreters would be compatible with the basicassumptions of the contextual interpretation mechanism, assuming onlythat the same grammatical description is used in both the analysis andgeneration direction.What is required is that QLFs are, as here, expressed in a typedhigher-order logic, augmented with constructs representing theinterpretation f context-dependent lements (pronouns, ellipsis, focus,etc.).
These constructs correspond as directly as possible to properties ofthe linguistic structure that express them and are, to as small an extentas possible, dependent on the requirements of contextual resolution(unlike, say, the metavariables of standard QLFs \[Alshawi and Crouch1992\], or the labels of UDRS \[Reyle 1996\], which are motivated entirelyby the mechanisms that operate on them after grammatical processing).Syntactic properties relevant for binding constraints, parallelism, scopeconstraints, and so on, are not directly represented atQLF (again unlikestandard QLFs) but are assumed to be available as components of thelinguistic ontext.
~The context-independent meanings of sentences, which we refer to asresolved logical forms (RLFs), are expressed in the "ordinary" subset ofthe QLF language.
A fully resolved RLF can be directly evaluated fortruth: it contains no QLF constructs.
Since it is just an expression of"ordinary" logic, it could serve as a knowledge representation a dreasoning language, and thus the output of some information systemproducing such representations could in principle feed directly intogeneration (modulo well-known "equivalence of logical form" problems).
"Contexts" are here modeled by sets of sentences in the RLF subset ofthis language, with some kind of salience ordering on them (recency, inthe implementation), about which we say nothing more.
These sentencesmay, but need not, arise from prior linguistic processing.
Contextscontain information about the form as well as the content of previousutterances, as mentioned earlier.
Context sentences may also reflectfeatures of the nonlinguistic context gained by direct observation orinference.This is a very minimal theory of context.
We need to be able to reasonabout context, hence we need it represented in a logic.
We need to beable to refer to properties of the form of linguistic utterances as well astheir content, hence context must contain this information too.
Weobviously need some nonlinguistic nformation.
We also need somestructure to reflect he fact that not all components of the context arerelevant to everything, hence salience.
This is all we need for the timebeing, although there is clearly much more to be said.1 This is probably too strong a position to take.
There are good arguments for allowing some syntacticdistinctions to be represented more directly.499Computational Linguistics Volume 26, Number 4.
QLFs are interpreted by conditional equivalences (Rayner and Alshawi1992; Rayner 1993) of the form:QLF ~:~ RLFifConditionl,, .
.
vConditionn.These state a contextual equivalence between an expression containingone or more QLF constructs (the left-hand side) and an expressioncontaining at least one fewer QLF constructs (the right-hand side).
QLFand RLF are therefore sometimes used to signify partially as well as fully(un)resolved LFs.
An equivalence can be paraphrased as: "In a contextwhere these conditions hold, this QLF can be interpreted as this RLF," or"In a context where these conditions hold, this RLF can be expressed asthis QLF."
Conditional equivalences, if @ is interpreted as materialequivalence, can be unpacked to a conjunction of implications:(Conditions & QLF ~ RLF)&(Conditions & RLF --~ QLF)...Conditions are treated as goals to be satisfied with respect o the currentcontext, in a way familiar from the theorem proving and logicprogramming tradition.
Variables in goals may or may not beinstantiated, and satisfying a goal can instantiate variablesnondeterministically.
The scope of a variable is within the wholeequivalence.
The interpretation f variables is as for Prolog.Later, we extend the notion of inference involved in checking conditionsbeyond that provided by Prolog and the like to allow conditions to be"abduced" and added to the context if they cannot be proved directly,always provided that adding them to the context does not cause acontradiction.
We assume some "cost" mechanism constrains thisprocess.Equivalences describe QLF or RLF patterns, typically containingvariables.
Determining whether an equivalence applies to a QLF or anRLF is done by higher-order unification (henceforth, HOU) (Huet 1975;Miller and Nadathur 1986; Pulman 1991; Dalrymple, Shieber, and Pereira1991; Gawron 1992) of the logical form with the relevant pattern.
Manyof the contextual conditions require a higher-order equation to be solved.The interpretation f a QLF is given via the RLFs it can be equivalent towith respect o given contexts.
Given a fixed, fully-specified context, aQLF will generally be equivalent to a single RLF (unless theequivalences allow for several synonymous interpretations).
In caseswhere the context does not resolve an ambiguity, the QLF willcorrespond to different RLFs depending on which assumptions areadded to the context.
Likewise, given a partially specified context and anRLF, there may be several QLFs that can express the content of the RLF.Notice that the equivalence holds/f  the conditions hold, not iff.500Pulman Bidirectional Contextual ResolutionThe overall architecture of the system can be pictured very simply as describedbelow.parser  equ iva lencesSentence < .
.
.
.
.
> QLF  < .
.
.
.
.
.
.
.
.
.
.
> RLFgenerator  + context3.
An Illustrative Fragment3.1 PronounsIt is easiest o see how all this is supposed to work out by giving some examples.Consider the simple discourse:(2) Smith owned NLPCom.
He disappeared.The QLF we will assign to the first sentence will be:existsl(Ae.pos(past(own (e,smith,nlpcom))))We actually interpret sentences as predicates on eventualities (type ev), and interprettense and aspect markers as QLF operators, subject o contextual interpretation of acomplex kind (see Pulman \[1997a\] and Thomas and Pulman \[1999\] for an account ofreversible tense and aspect interpretation within this framework).
But for the purposesof this paper, we will simply assume that tense and aspect processing consists of quan-tifying over the event variable, and further simplify by assuming that this happens inthe grammar rather than in resolution.
In the logical form, pos is the opposite of negand is motivated as an explicit element of QLF by the fact that the positive polarityof a sentence can be focused, as in Smith DID disappear.The quantifier existslc~>~>~ is so called to distinguish it from the generalized quan-tifier exists~o>t~ce>~>t used later.
2This QLF/RLF, given our simplifying assumptions, needs no resolution and willform the context for the interpretation f the QLF for the subsequent sentence:existsl(Af.po%>~(past~>~(disappear ...... fo~,h%))Note that the interpretation f the pronoun is represented by the QLF construct hee,which adequately summarizes the properties of singularity and masculinity requiredof an antecedent.
(For computational economy, we might want to generalize this rep-resentation i an implementation to something like pron(X), where X is he, she, etc., toenable a single equivalence tocover all the cases, but there is no linguistic motivationfor including any more information than we have.
)Next we try to resolve the QLF construct he.
We have, we will assume, an equiv-alence of the form:Pron-hePred(he) ~ Pred(Ref)ifsalientContext(pronoun,Context),possibleAntecedent(Context,he, Ref),binding_conditions_hold...which is one of several that might be applicable.
(We follow Prolog-like notationalconventions: query variables begin with upper case; variables beginning with under-score "_ "  are those whose instantiation we are not interested in; constants begin with2 Type subscripts will be omitted where they are easy to infer,501Computational Linguistics Volume 26, Number 4lower case, and "," between expressions i  interpreted as conjunction.
Lambda-boundvariables of type ev (eventuality) are e, f. g .
.
.
.
and those of type e (individual) are x,y, z ...).
Applicability is determined in two steps: first, equivalences are indexed byany QLF constructs that they involve (like he), and secondly, higher-order unificationis tried between the QLF and the left-hand side of an equivalence retrieved by theindexing.
The indexing step is necessary both for completeness and for efficiency: ifwe just used HOU, then, since it is not decidable, equivalences that did not matchthe QLF could lead to nontermination, or at best, to spurious matches that would befiltered out expensively when checking the conditions.
(To see how this could be so,consider that trying to higher order unify Pred(he) with any formula F of the appro-priate type will succeed with Pred = Ax.F, where x does not occur in F.) Other thanthis, application of equivalences is entirely free and nondeterministic.
Of course, if inthe analysis direction we require full resolution, then we will have to continue untilall QLF constructs have been resolved.
But in the generation direction, application ofsome constructs will be optional (such as this pronoun one), and some will be in effectobligatory (like the quantifier scoping equivalences described later) because failureto apply will not result in a QLF that the grammar can generate from.
Equivalencescurrently apply to an entire QLF, although in reality this is an oversimplification a dsome more dynamic and incremental control regime should be used.
We return to thisissue later.Note also that here and throughout the paper, there may be alternative solutionsto equations in equivalences, ome corresponding to alternative interpretations, andsome that will hopefully be filtered out by the relevant conditions.
We assume that itis possible to represent structural constraints like binding and scoping principles asconditions in an equivalence.
To keep the presentation manageable, we abstract awayfrom these issues, and also avoid questions of how the correct interpretation is actuallychosen, where there is a choice.The conditions in this pronoun equivalence are stated in terms of several predi-cates that recur in the treatment of different phenomena.
The predicatesalientContext(Construct.Context) finds a logical form that is a salient one for the currentconstruct in the context.
Having the construct as a parameter enables earch to bereduced: pronouns and ellipsis typically find their antecedents in either an earlier por-tion of the current sentence, or the preceding sentence (Hobbs 1979), whereas definitesfrequently refer back over several previous entences.
We parameterize this predicateso that these preferences can be respected.The predicate possibleAntecedent(Context,Proform,Candidate) does most of the work.
Thesimplest clause in its definition is:possibleAntecedent(Contextt,he,Refe)ifContext = _OtherPred(Ref),isOfType(he, Ref).where = means that the equation is solved by HOU, and the predicate isOfType carriesout the obvious number and gender checks.
More complete definitions of possibleAn-tecedent would include checks for the type of restriction often expressed as bindingconstraints, and for the type of preference obtained by centering theory.
We ignorethese details here since they are not our main focus.The sequence of unifications now is that the QLFexists1(.~f.pos(past(disappear(f, he))))will HOU with the expression Pred(he) to givePred=Xx.existsl(.Xf.pos(past(disa ppear(f,x))))502Pulman Bidirectional Contextual ResolutionSalientContext will return existsl(Ae.pos(past(own(e.smith.nlpcom)))) as the value of Context,and when we attempt to solve the goal possibleAntecedent, we will have two nonvacuoussolutions for the equation in its definition:Context = _OtherPred(Ref)with Ref-smith, or nlpcorn.
Of these, only the first will pass the isOfType test, and so theRLF side of the equivalence will be instantiated to:\[Ax.existsl(Af.pos(past(disappear(f,x))))\](smith)which after beta-reduction will be the intended interpretation.Consider now what would happen if we were operating in the other direction;that is to say, we have the same sequence of resolved logical forms and we wish togenerate sentences expressing them.
The first logical form:existsl(Ae.pos(past(own (e,smith,nlpcom))))has no relevant context (for our purposes) and thus leads directly to the sentence Smithowned NLPCom.
For the second logical form, one outcome is that it is also treated in acontext-independent way and the sentence Smith disappeared is generated.
(We shouldhave some way of ranking this as dispreferred, but we will postpone that issue fornow.)
The other possible outcome is that we apply the pronoun equivalence in the gen-eration direction.
Conditions for applicability are a little more difficult here, because weoften have no QLF constructs to index equivalences from.
Instead we currently have torely on coarser indexing heuristics.
Assuming that, we then use HOU to check the con-ditions for applicability: we will unify Pred(Ref) with exists(Af.pos(past(disappear(f.smith))))and the conditions will locate the prior reference to Smith as constituting a sufficientcondition for realizing this occurrence of Smith by the pronoun he.In fact, as the equivalence is stated, we will be able to also generate the sentence hedisappeared if the current RLF was existsl(Af.pos(past(disappear(f.jones))), which is clearlyincorrect.
The reason for this is that the HOU in the possibleAntecedent condition mightalso succeed with a vacuous solution, namely:_OtherPred = Ax.existsl(Af.pos(past(disappear(f, smith)))and the remainder of the conditions will also succeed.
We must therefore restrictsolutions to this equation to nonvacuous ones: in fact, we will not lose anything bymaking this a general restriction on admissible solutions, as we have already beendoing implicitly)Of course, this analysis of pronoun reference will cover only the simplest possiblecases of intersentential naphora.
Before going on to more complex cases, we will alsoshow how to deal with intrasentential naphora, including reflexives, and binding ofa pronoun by a quantifier.
The relevant equivalence is:Pron-he-intraRest(~=~)=>~(Ay.Pred(y, he)) ~ Rest(~)=~(Ay.Pred(y,y))ifbinding_conditions_hold .
.
.
.This equivalence is doing essentially the same job as Pereira's pronoun abstractionschema in Pereira (1990).
It will identify a pronoun with any term of type e elsewherein the QLF, relying on the binding conditions to prevent impossible associations.3 For this case, and for many other types of restrictions currently handled by conditions, more elegantsolutions are available using the "sorted" and "colored" versions of higher-order unification developedby Michael Kohlhase and colleagues (Gardent and Kohlhase 1996b, 1997; Gardent Kohlhase, and vanLeusen 1996; Gardent, Kohlhase, and Konrad 1999).503Computational Linguistics Volume 26, Number 4We illustrate this equivalence with the relevant instantiations for the followingcases (in fact, the reflexive case is done with a separate quivalence differing only inthat it mentions he-self instead of he, with associated ifferences in binding conditions):(3) Smith admires himself.QLF=exists1(Ae.pos(pres(like(e,smith, he-self))))Rest= AQ.Q(smith)Pred=.Xx.Ay.exists1(Ae.pos(pres(like,e,x,y)))RLF=exists1(Ae.pos(pres(like(e,smith,smith))))(4) Smith likes his computer.QLF=existsl(Ae.pos(pres(like(e,smith,of(he,com purer)))))Rest= AQ.Q(smith)Pred=Ax.Ay.existsl(Ae.pos(pres(like,e,x,of(y, c mputer))))RLF=existsl(Ae.pos(pres(like(e,smith,of(smith,computer)))))(5) Every manager likes his computer.QLF (partially resolved) = forall(manager,Ax.existsl(Ae.pos(pres(like,e,x,of(he,computer)))))Rest=~,Q.forall(ma nager,Q)Pred=Aa..kb.existsl(.ke.pos(pres(like,e,a,of(b,com puter))))RLF = forall(manager,Ax.existsl(Ae.pos(pres(like,e,x,of(x,computer)))))Note that here we have assumed that the quantifier has already been scoped.We return later to issues of the interaction of scoping with ellipsis and anaphora.In the meantime, we simply point out that bound variable uses of pronouns need noextra mechanisms than those required for simple intrasentential pronouns.
4It is easy to extend to far more complex cases of intersentential naphora byextending the definition of possibleAntecedent to allow for reference to different ypesof antecedent.
For example, if we adopt a theory like Webber's (Webber 1983), wecan construct discourse referents from the representation f quantified NP meanings.Recall that in Webber's approach, a logical form representing the meaning of a sentenceprocessed in a discourse will trigger the application of rewrite rules, which will addnew entities to the context.
For example, given a logical form that in our notationwould be:exists(cat,~,X.saw(I,X)))a discourse ntity like:iota(AX.cat(X) & saw(I,X) & evoke(sl,X))will be produced, where iota is a term-forming operator interpreted roughly like adefinite description.
(The evoke predicate serves as a unique identifier for the referent,tagging it with a label for its source sentence.
)Webber's rules lend themselves very naturally to a higher-order formulation, al-though when systems based on her theory have been implemented on a realistic scale,they have been implemented either as code or as Lisp pattern-matching rules (Ayuso4 A referee queries whether generating back out from the resolved form of (5) might not leave adangling variable when the quantifier scoping is undone.
This is not so, for the simple reason that novalid application of HOU could result in a previously lambda-bound variable becoming free.
We needno free variable constraints given this mechanism.504Pulman Bidirectional Contextual Resolution1989).
Using HOU we can formulate an axiom to infer the existence of an entity of theappropriate type:Pred~(exists(~)~(e~t)~t(Restriction,Body))existsl(o~)~(Ax.x=iota(Ay.Restriction(y) & Body(y)))The operator iota(~)~ means here 'the (unique) thing satisfying (the intersection of)restriction and body'.
An additional clause in the definition of possibleAntecedent essen-tially encodes this inference:possibleAntecedent(Context,he, D E)ifContext = Pred~(exists(Restriction,Body)),isOfType(he,iota(Ax.Restriction(x) & Body(x))),defined(DE,iota(Ax.Restriction(x) & Body(x))).The predicate defined will succeed if there is already a discourse referent defined interms of this iota description.
If there is not, it will create one (essentially a newSkolem constant) and identify it with the iota term, asserting the definition.
It is thusnot a strictly logical predicate, but is necessary for thoroughly familiar easons.This inference rule will handle well-known Netherlandish examples like:(6) A man walked in a park.
He whistled.or:(7) Smith owned a computer.
It disappeared.with the antecedent sentence in the latter being resolved as:exists(computer,exists1(~e.Ax.pos(past(own(e,smith,x))))(We will turn below to the resolution of quantified noun phrases, but for now willjust assume the appropriate resolved forms.)
The pronoun it here will be interpretedas (say) il, equivalent to:iota(Ax.computer(x) & exists1(Ae.pos(past(own(e,smith,x)))giving an RLF existsl(Af.pos(past(disappear(f, il))).
Thus it, in this context, is interpreted,roughly, as 'the computer that figures in the eventuality ofbeing owned by Smith'.
(Inthe simple cases covered here, uniqueness ofthe eventuality and thus of the denotationof the iota term are not actually guaranteed: in a fuller treatment of tense and aspect,the eventuality described by the sentence will be uniquely identified and thus thisproblem will not arise.
)The quantifier exists~o~t~o~t~ is here the translation of the indefinite article, althoughas is well known this is not the only alternative.
We could encode DRT-like analysesdirectly via an equivalence creating anew discourse referent for an indefinite.
On suchan analysis, the earlier pronoun equivalence would apply to this discourse referent justas for a proper name, provided the appropriate number and gender information wasavailable.By extending the definition of possibleAntecedent, we can combine with Webber'sapproach aspects of the DRT theory of plurals (Kamp and Reyle 1993) to account forexamples like:(8) Every manager liked Smith.
They admired him.505Computational Linguistics Volume 26, Number 4possibleAntecedent(Context,they, DE)ifContext = Pred(forall(Restriction,Body)),isOfType(they, sigma(~xRestriction(x) & Body(x))),define(DE,sigma(.Xx.Restriction(x) & Body(x))).The antecedent sentence w i l l  be resolved to:forall(manager, Ax.exists1(Ae.pos(past(like(e,x,smith)))))Here they will be interpreted as i2, equivalent to:sigma(Ax.manager(x) & existsl(Ae.pos(past(like(e,x,srnith)))))where sigmace~t~ o is an operator meaning 'the maximal set of things satisfying bothrestriction and body'.
To get the details completely right, we would need to add someextra machinery to our existing logic to model the distinction between singular andplural, but there is no problem of principle in doing so, nor of extending to caseswhere universals cope over existentials: 5possibleAntecedent(Context,they, DE)ifContext = Pred(forall(Rl,Xx._(exists(R2,Body))),isOfType(they, sigma(Xx.R2(x) & exists(R1,Body)),define(DE,sigma(Ax.R2(x) & exists(R1,Body)).
(9) Every manager owns a computer.
NLPcom supplied them.The antecedent sentence is resolved, on the relevant scoping, to:forall(ma nager,Xx.
(exists(com puter,Ay.existsl(Ae.pos(pres(own(e,x,y)))))))The pronoun is resolved, on the relevant interpretation:them = i3 = sigma(.Xx.computer(x) & exists(manager,~y.existsl(Ae.own(e,y,x))))Using HOU, we can easily formulate many more inferences that create new dis-course entities.
For example, plurals can be created by assembling terms from indi-viduals mentioned in the context.
Define "+" as a functor creating plural individualsfrom its arguments:possibleAntecedent(Context,they, DE)ifContext = Pred ....... (X,Y),isOfType(heSheOrlt,X),isOfType(heSheOrlt,Y),define(DE,X+Y).Now we can interpret sequences like:(10) Smith sells the machines to NLPCom.
They have a contract.On one interpretation, they will be interpreted as the complex individual smith+nlpcom.Depending on the approach taken towards phenomena like collective versus distribu-tive predication, this construct may be taken as the QLF or the RLF corresponding toNP conjunction.
In the former case, it may need further contextual resolution: again,5 Just as with the original analysis, we will need to write different equivalences for the case where twoor more universals are involved, which is a little clumsy.506Pulman Bidirectional Contextual Resolutionthis depends on whether these distinctions are matters of resolution or inference froma resolved logical form.Note that all of the equivalences are reversible: in the generation direction thosewhich assume quantified NP antecedents presuppose that the RLF contains a discourseentity (or, with minimal change, a sigma or iota term).It is also possible to give a plausible analysis within this framework of moredifficult phenomena such as "donkey" sentences and dependent plurals, but the detailswould take us too far afield.3.2 Definite DescriptionsWe can implement a simple Russellian theory of definite descriptions by means of thefollowing equivalence:ThePrede=~t(the(oo~)?~e(Restr)) ~ Pred(Refe)ifsalientContext(definite,Context)possibleAntecedent(Context,the,Ref).u n iq ue(Ref, Restr)where unique(Ref, Restr) is defined so as to be true if Ref is the only thing in the localcontext hat satisfies Restr.Clearly, possibleAntecedent will be largely the same for definites as for pronouns,although there will have to be provision for inferred antecedents (a car.., the steeringwheel).
In particular, we need to be able to create discourse entities for quantifiedantecedents, plurals, etc.
that are analogous to those we have been discussing forpronouns.
(11) Smith bought a computer.
The computer disappeared.Smith hired Jones.
The managers wrote a report.Every manager uses a computer.
The managers .
.
.
/The computers.. .If we allow the expressions created by possibleAatecedent identifying discourse refer-ents with iota terms to figure as elements of the context (sentences of the form de-fined(DiscRef.lotaTerm)), then an initially surprising but rather natural consequence ofthis formulation of the definite equivalence merges.
The resolved logical form for asentence containing a definite will have either a normal constant (a name) or a dis-course referent as the equivalent of the definite description.
When we try to generateback out from the resolved logical form, name constants will be expressed either asnames or pronouns.
Discourse referents will not give rise to sentences with names,since the discourse referents are not entries in our lexicon.
But since the expressionsthat equate them with iota or other terms will be possible contexts, the equivalenceabove will generate both the original definite description and a fuller one that re-states the whole content of the iota term.
We can illustrate this informally with thesequence:(12) Smith bought a computer.
The computer disappeared.In processing the definite description, we will use our version of Webber's rule em-bodied in possibleAntecedent to create a discourse referent, say il, from the existentialquantifier arising from the indefinite description a computer in the RLF acting as the507Computational Linguistics Volume 26, Number 4context.
If the condition unique(il,computer) succeeds, which it will, then a side effectof resolving the definite will be to add to the context he definition:defined(il,iota(~x.computer(x) & existsl(~e.pos(past(buy(e,smith,x)))))The RLF for the sentence will be:existsl(Ae.pos(past(disa ppe r(e,il)))In trying to generate a paraphrase of this resolved logical form several equiva-lences can apply.
We can realize il as a pronoun by the pronoun equivalence earlier.We can also realize il as a definite the computer by using the definite description equiv-alence with the same variable instantiations a  were just used in the interpretationdirection.
One QLF produced by the equivalence with the definition above as thevalue of the Context variable will have as the QLF for the subject of disappeared theterm the(Ax.computer(x) & existsl(Ae.pos(past(buy(e,smith.x)))), because il and this lambdaexpression will be one of the solutions to the condition unique(Ref, Pred) in the equiva-lence.
It so happens that in the current grammar this QLF can be realized as an NPwith a tensed relative clause, so another paraphrase of the resolved logical form willbe:(13) The computer that Smith bought disappeared.In fact, similar effects can be obtained for pronouns if some small tweaks to therelevant conditions are made: this turns out to be more than a neat trick, and is veryuseful in providing informative f edback on what resolutions have been chosen, whendeveloping the system, or in the context of an application.3.3 EllipsisNot surprisingly, we can adapt a version of the HOU approach to ellipsis resolution(Dalrymple, Shieber, and Pereira 1991; Pulman 1991; Gawron 1992, 1995) very easilywithin this framework.
On the DSP approach to VP ellipsis, an elliptical sentence like:(14) John likes fish and Mary does too.will be analyzed as follows.
Firstly (ignoring tense, too, etc.)
we represent the meaningof the elliptical conjunct with a free variable applied to the subject:Ellipsis(mary)Secondly we locate an element in the antecedent like(john,fish) that is parallel to mary,namely john.
Next we construct a HOU equation:Ellipsis(john) = like(john,fish)the relevant solution to which instantiates the ELLipsis variable to .Xx.like(x,fish), whichwhen substituted in the elliptical phrase yields the correct result.Our analysis is similar in spirit.
However, at QLF we represent the semantics ofthe elliptical sentence not with a free variable but by using the construct vpEIlipsis .......The interpretation f this construct is given by the relevant equivalence:vp-ellipsisXt>t(existsl(.Xe.(PolarityTenseEtct~(vpEllipsis(e,Subject)))))X~(exists1(Ae.
(PolarityTenseEtq~t (Predicate(e,Su bject)))))ifsalientConte?t(vpEllipsis,Context),Context -- Y(exists1(Xf.
(CPolarityTenseEtc(Predicate(f, CSubject))))),parallel(Su bject,CSubject)508Pulman Bidirectional Contextual ResolutionThe predicate parallel implements he use of parallelism in this analysis.
Note that theequation in the second line of the equivalence uses HOU to simultaneously suggestcandidates for parallel elements and the value of the Predicate that corresponds to theEllipsis variable in the description of DSP above.Some sortal conditions within both the equivalence and the predicate parallel arenecessary to make sure that the variables PolarityTenseEtc are appropriately instanti-ated, since there are many possibilities consistent with their type requirements.
But noextralogical mechanisms are needed, apart from the definition of "parallel," which isintended to correspond to the notion discussed in Dalrymple, Shieber, and Pereira(1991), Prfist (1992), Hobbs and Kehler (1997), and Gardent and Kohlhase (1997),among others.
Parallelism may involve syntactic, semantic, pragmatic, and discoursecomponents, depending on the construction i volved.
VP deletion, for example, re-quires the parallel element to be the subject of the preceding conjunct as well as beingin the same domain of quantification asthe remnant; whereas phrasal ellipsis like ...and John merely requires the antecedent tobe in the same domain of quantification.Now given a sequence like:(15) Smith liked Sandy.
Jones didn't.where the antecedent logical form and the QLF to be resolved are respectively:existsl(Ae, pos(past(like(e,smith,sandy)))neg(existsl(Af.past(vpell(f,jones)))the variables in the vp-ellipsis equivalence will be instantiated thus:vp-ellipsisXt~t(existsl(Ae.
(PolarityTenseEtq~(vpEllipsis(e,Su bject)))))X~(exists1(.Xe.
(PolarityTenseEtct~t(Predicate(e,Su bject)))))ifsalientContext(vpEllipsis,Context),% Context = exists1(.Xe.pos(past(like(e,smith,sandy)))% X = identity function of type t>tContext = Y(exists1(Af.
(CPolarityCTenseEtc(Predicate(f, CSubject))))),% PolarityTenseEtc -- .Xx.pos(past(x))% Y--neg, CPolarityCTenseEtc -- Ax.past(x)% Predicate = Ag.As.like(g,s,sandy)% SubJect, CSubject = jones, smith respectivelyparallel(Subject,CSu bjectC)When the Predicate is applied to the event and subject arguments on the right-handside of the equivalence, the correct interpretation is obtained.Again, this is completely reversible.
If we were instead generating from the se-quence of logical forms:exists1()~e.pos(past(like(e,smith,sandy)))neg(exists1(Af.past(like(f,jones,sandy)))the equivalence, and the associated conditions, can apply in the same way to licencea QLF w i th  the vpEllipsis construct in it, causing an ell iptical sentence to be generatedfrom that QLF.3.4 FocusLet us turn now to examples involving focus-sensitive adverbs.
(A more elaboratetreatment of a wider range of focus phenomena within the current framework canbe found in Pulman \[1997b\].
An extension of some of these analyses can be found in509Computational Linguistics Volume 26, Number 4Gardent and Kohlhase \[1996a\]).
We will illustrate with the adverb too, as in:(16) a. Smith likes Sandy.
Jones likes Sandy too.b.
Smith likes Sandy.
Jones does too.To a first approximation, use of too is appropriate if the sentence asserts thatsomething similar but not identical to a previous event or state occurred.
The twosentences must share some information, or they must contain parallel information,and must differ on at least one point: the different components are focused, in thesense that the main stress when the sentence is spoken will fall on those constituents:Jones in the example).
We encode this analysis by treating too as a QLF constructthat takes as arguments the meaning of the focused constituent and the meaning ofthe sentence itself (without too).
The information structure requirements on too are(partly) captured in the conditions on the following equivalence that interprets thisQLF construct: the instantiation of the Shared variable will contain what is similarbut the Focus variable states what is different.
However, as for ellipsis, the focusedconstituent must be parallel to the corresponding item in the antecedent expression.Too-focusRestlt~>~(existsl Ae.Restto>t(too(Focus,Pred(e,Focus))))Restl~o>t(existsl Ae.
Restt=>~(Pred(e,Focus))))ifsalientContext(too-focus,Context),Context = _X(existsl(Af.Shared(f,Ant%pe),parallel(Shared,Pred),parallel(Ante~e, Focus~pe),not(Ante=Focus)Since focus can fall on almost any constituent in a sentence, the type of the Focusvariable, and consequently that of too are not completely fixed.
(Note that this poly-morphism means that in the case where the type of a term cannot be inferred beforeHOU, some preprocessing to instantiate the type variable with likely candidates maybe required, since the HOU algorithm requires the inputs to be fully typed.
)In processing the second sentence of (16a), variables will be instantiated asfollows:QLF:existsl(Ae.too(jones,pos(pres(like(e,jones,sa ndy)))))Too-focusRestl~:>~(existsl Ae.Rest~o>t(too(Focus,Pred(e,Focus))))Restlt:>~(existsl Ae.Restto>~(Pred (e,Focus))))ifsalient Context(too-focus,Context),% Context = existsl(Af.pos(pres(like(f,smith,sandy))))% Restl,Rest = identityContext = _X(exists1(Af.Shared(f, AnteTypo),% Shared = Ag.~x.pos(pres(like(g,x,sandy)))% Pred = Ah..~y.pos(pres(like(h,y, sandy)))% Ante = smith, Focus = jonesparallel(Shared,Pred),parallel(AnteTyp~,FocusTypo),not(Ante=Focus)RLF:existsl(Ah.pos(pres(like(h,jones,sandy))))On our analysis, too adds nothing to the truth conditions of an utterance, butmerely serves to compare and contrast with the context.510Pulman Bidirectional Contextual ResolutionNotice that Too-focus will also apply in (16b) along with VPEllipsis.
The order ofapplication of equivalences is in general not significant, except hat one order may becomputationally more efficient han another.
In this case, both orders of applicationresult in the same interpretation.
The exception to this is that the equivalences forinterpreting unscoped quantified NPs, described below, may apply several times in asentence containing more than one quantifier and different orders of application willcorrespond to different scopings, if these are permitted by the contextual conditions.Now consider an example in which we will assume that the focused elementcannot be determined from the linguistic form, and is thus represented at QLF by afree variable.
It is of course important for computational purposes not to be committedto an analysis of focus that requires it to be overtly marked in a sentence, for essentiallythe same reason that it is important not to require quantifier scopes to be explicitlyrepresented: combinatorial explosion.
Narrow focus can be marked virtually anywherein a sentence and to treat a sentence with no apparent focus marking as ambiguousbetween all possible focus markings would be computationally disastrous (as well asnot very plausible psychologically).Assume that we are analyzing the same sequence as before (16a), but that thefocus is not marked intonationally.
The QLF will be:existsl(Ae.pos(pres(too(Focus,like(e,jones,sa ndy))))Applying the Too-focus equivalence will instantiate the variables in it as before,except hat since Focus is not instantiated there would, in the absence of any constraintsfrom context, be multiple solutions for it (and hence for Pred), in which Focus is in-stantiated to any constituent of the sentence.
However, if the contextual conditions inthe equivalence are to be satisfied, then only the solution on which Focus=jones will befound, for on all the others it will be impossible to find values for Shared and Ante thatmeet the various requirements of parallelism and nonidentity.
This corresponds withthe observation that if focus is explicitly marked in the too sentence, it must fall onJones, for no other choice is coherent (in that context).
(17) a. Smith likes Sandy.
?
?Jones likes SANDY too.b.
Smith likes Sandy.
?
?Jones LIKES Sandy too.To conclude the focus examples, we illustrate the way that higher-order unification andabduction can work together to add something to the context, in those cases wherethere is a context, but where it does not at first sight support he appropriate useof a focusing device.
Consider the following sequence in a context where the hearerhappens not to know that an iMac is a computer:(18) a. Jones bought an iMac.b.
Smith has a new computer too.We will simplify the QLF to:existsl(~e.pos(pres(too(smith, have(e,smith,a-new-computer))))In attempting to satisfy the conditions for the Too-focus equivalence, we will notbe able, let us assume, to find a suitable Context o serve as an expression providingan antecedent, nor be able to solve the equation Conte?t=_X(existsl(Af.Shared(f, AnteT~e)).However, we do know the values of Pred=Ag.Ax.oos(pres(have(g,x,a-new-comouter))) andFocus=smith.511Computational Linguistics Volume 26, Number 4Recall that we are assuming that the various conditions in equivalences are goalsto be proved in the manner of Prolog or similar inference methods.
Thus a predicatelike parallel can be called with or without arguments instantiated.
Defining such apredicate in the general case is not trivial, but it is clear that one clause in its definitionshould be parallel(A,A).
Other clauses should search in the context for entities of similartype and sortal status to any instantiated arguments.
Thus if we call parallel(A,smith)or parallel(B,Pred) we will get back as solutions (among others, perhaps) that A=jonesand that B=Pred=&g.&x.pos(pres(have(g,x,a-new-computer))).
These instantiations will alsoinstantiate the Context variable via the equations in the equivalence, to:existsl(,~e.pos(pres(have(e,jones,a-new-computer))))By an abductive step, we can add this to the context as an implicature or "accom-modat ion" that is needed to make sense of the focus structure of the sequence (18).The relation between utterance, focus, and context is such that either of the lat-ter two relata can be incompletely specified without preventing interpretation of theformer.
Any analysis of focus should be able to capture this phenomenon.
The vi-tal ingredient of the analysis here is the nondirectionality of inference provided byhigher-order unification, supplemented by abduction.3.5 Quantifier ScopeWe can implement a deductive theory of quantifier scope using the conditional equiv-alence mechanism.
The version proposed here combines a basic insight from Lewin(1990) with higher-order unification to give an analysis that has a strong resem-blance to that proposed in Pereira (1990, 1991), with some differences that are com-mented on below.
Like Pereira's approach, it avoids the need for a free variable con-straint, nor does it need the explicit recursion on the quantifier estriction imposed byLewin.We analyze quantified NPs at the QLF level as il lustrated in the QLF for:(19) Every manager uses a computer.existsl(&e.pos(pres(use(e,every(.>t,>~(manager),ac.,t),.
(com puter))))We assume that every determiner has its own equivalence, which resolves it as aquantifier: sometimes this can be quite a complicated matter, as with any (Alshawi1990), which will resolve in different ways depending on its linguistic context, buthere we avoid this complexity.
66 Separate quivalences might also make it easier to encode determiner-specific preferences, such as thatof each for wide scope.
A referee points out that the lack of any explicit ordering of application ofequivalences makes one natural way of doing this unavailable.
But I am not convinced that this wouldhave been the right way in any case.
These preferences are just that, not hard and fast rules, so weneed to be able to permit all permutations where the context, or the structure, prefers the less frequentinterpretation, asin examples like the following (from the LOB corpus), where the most salient readingis that in which a bird outscopes each:(i) Out of a total of 100 marks which are to be allocated, 15 are awarded for these attributes, and it hasto be remembered that a bird has to earn each one of them when on the judging bench.512Pulman Bidirectional Contextual ResolutionThe equivalence for every is:EveryRestt~(Predo~t(every(Nom~)))~ 4=  Rest~(forall(Nome~,Pred~))~ifsalientContext(quant,Context),scopelsLicensed...The final condition is a placeholder to allow for the encoding of whatever struc-tural constraints and preferences on quantifier scopes are thought o be necessary.Applying the equivalence to the QLF above gives us this solution:Rest,>t(Prede>,(every(Nome>,)))t ~ Rest,>,(forall(Nome,,,Predo~,)),if% Rest = identity% Pred = ~x.existsi(Ae.pos(pres(own,e,x,a(computer))))% Nora = managersalientContext(qua nt,Context),scopelsLicensed...The RLF is:forall(manager,Ax.existsl(Ae.pos(pres(own(e,x,a(com puter))))))This still contains the QLF construct a and so the analogous equivalence for a (whichwe will continue to treat as a quantifier here for illustration) can apply:ARestt,~(Prede~t(a(Nom~,~)))t  Res t,t(exists(Nomo~t,Pred~,~))~if% Rest = identity% Pred = Ay.forall(manager,.kx.existsi(.Xe.pos(pres(own(e,x,y)))))% Nom = computersalientContext(quant,Context),scopelsLicensed...The final RLF is then:exists(corn puter,Ay.forall(ma nager,Ax.existsl(.Xe.pos(pres(own (e,x,y))))))provided that the scoping constraints and the context permit this interpretation.The ordering of equivalences i  not fixed: they simply apply nondeterministicallyas permitted by the relevant contextual conditions.
We could have applied the twoquantifier equivalences in a different order, leading to the alternative partial and thenfull scoping:exists(computer,Ay.existsl(Ae.pos(pres(own(e,every(ma nager),y)))))forall(ma nager,Ax.exists(computer,Ay.existsl(.~e.pos(pres(use(e,x,y)))))This is a somewhat incomplete treatment of the relationship between events andquantifier scope, of course.Because of the particular logical syntax we are using, we need to add anotherversion of the quantifier equivalences to allow for application inside the restriction ofthe body of an already scoped quantifier:Every2Rest?~,~,(Ax.
Pred ..... (x,every(Nom)))Restc.~,(Ax.forall(Nom, Xy.
Pred ..... (x,y)))ifsalientContext(q ua nt,Context),scopelsLicensed...513Computational Linguistics , Volume 26, Number 4We could avoid this inelegance by using polymorphism in the equivalences, orsome "syntactic sugar" in the logical forms to produce amore uniform representation.As will be seen below, we need in any case something like the pair quantifier notationof Dalrymple, Shieber, and Pereira (1991), which would also solve this problem.
Withthis addition we are able to produce both scopings for examples like:(20) Every manager in some company disappeared.This is a rather oversimplified treatment of quantifier scope, which we will refinea little shortly, but even as it stands the treatment has several advantages:?
in classic examples like:(21) Every representative in a company saw most samples.only the available five relative scopings of the quantifiers are produced(Hobbs and Shieber 1987, 47), but without he need for a free variableconstraint--the HOU algorithm will not produce any solutions in whicha previously bound variable becomes free;?
the equivalences are reversible, and thus the above sentences can begenerated from scoped logical forms;?
partial scopings are permitted (see Reyle \[1996\])?
scoping can be freely interleaved with other types of reference resolution;?
unscoped or partially scoped forms are available for inference or forgeneration at every stage.3.6 Comparison with Deductive InterpretationIt is interesting to compare this analysis with that described in Dalrymple, Shieber,and Pereira (1991) and Pereira (1990, 1991).
Recall that in their treatment, quantifiednoun phrases are treated in two stages: firstly, what they call a "free variable" oftype e is introduced in the NP position, with an associated "quantifier assumption,"which is added as a kind of premise.
At a later stage the quantifier assumption is"discharged," capturing all occurrences of the free variable.
Thus their analysis ofsomething like every manager disappeared would proceed as follows:every managerdisappearedevery manager disappeared- discharge the assumption:= every(x,manager(x))  I- x= disappear= every(x,manager(x))  I- disappear(x)= every(x,ma nager(x),disa ppear(x))In the final logical form, I am using an informal representation f their "pair" no-tation for generalized quantifiers, which uses the same variable in both the restrictionand the body, unlike the one we have been using.
If we make a comparison betweenthe way phenomena such as antecedent contained eletion are treated in our twoframeworks, we can see that we also need such a notational change.DSP's analysis of the relevant antecedent contained eletion cases goes like this:(22) a. John greeted every person when Bill did.b.
John greeted every person that Bill did.514Pulman Bidirectional Contextual ResolutionIn (22a), the context for the ellipsis is the first conjunct, analyzed as:every x person(x) I- greet(john,x) when P(bill)The equation is P(john)=greet(john,x), with P=.~z.greet(z,x).
The interpretation for thewhole sentence is now:every x person(x) t- greet(john,x) when greet(bill,x)When the quantifier is discharged, both occurrences of the variable x are bound:every(x,person(x), greet(john,x) when greet(bill,x))If the quantifier is discharged first, then the context for the ellipsis is:every(x,person(x),greet(joh n,x))and the equation is:every(x,person(x),greet(john,x)) = P(john)with P= &z.every(x,person(x),greet(z,x))Now the interpretation for the whole sentence is:every(x,person(x),greet(john,x)) when every(x,person(x),greet(bill,x))For (22b), the QLF isevery x person(x) & P(bill) I- greet(john,x)The equation is: P(john)=greet(john,x),with P=Az.greet(z,x), immediately giving the rightresult.
If the quantifier is discharged first, then the QLF isevery(x,person(x) & P(bill),greet(john,x))But now the equation will beP(john) = I- every(x,person(x) & P(bill),greet(john,x))which is invalid because P is on both sides, leading to an "occurs check" violation.Note that there is a somewhat uneasy mixture of logic and metalogic involved inthe DSP analysis, caused by merging the deductive, assumption-based reasoning, andstraight higher-order unification.
When the quantifier is undischarged, the associatedso-called free variable is not treated as such when solving the HOU equations.
It hasto be treated as a (unique) constant in order to get the right result.
When the quantifierhas been discharged, all occurrences of this constant are treated as bound variables.We have to assume that the HOU algorithm has to be told what status particularoccurrences of the variable actually have, because their analysis involves applicationsof HOU under both guises.
7In our system we run into some of the same problems as DSP, but from a slightlydifferent perspective.
The analogous QLF, represented in a simplified form akin to thatin DSP for ease of comparison, for (22a) is:when(greet(john,every(person)), VPELL(bilI))If we use the first, unscoped, conjunct as context for the ellipsis, then we get the rightresult:VPELL(john) = greet(john,every(person)), VPELL= ,~y.greet(y, every(person))when(greet(john ,every(person))),greet(bill,every(person)))After scoping the two conjuncts we will get the reading on which the greetings areindependent.
If we had scoped the QLF first we would get:forall(person,Ax.when(greet(john,x),VPELL(bill)))7 Pereira cknowledges this elsewhere: (Pereira 1991, footnote 3): "Xhe direct replacement of ellipsisequation solutions into derivations and subsequent normalisation f the result involve some abuse ofthe formalism..."515Computational Linguistics Volume 26, Number 4The equation we need is VPELL(john) = greet(john.x), which also requires us to treatthe x as a constant.
However, it is plausible to assume that for sentence-internal ellipsis,we will need a different control regime for application of equivalences.
Sofar we havebeen assuming that each equivalence applies to an entire QLF, but for cases wheresome earlier portion of the sentence is acting as the context hen this will not bepossible.
Assuming instead that a recursive traversal of the QLF is involved, then thisparticular unification equation will be formed and solved entirely within the scope ofthe lambda binding x.
In terms of Huet's algorithm, then, x will count as a "rigid"variable, that is, it will be semantically ike a constant.For (22b), our QLF isgreet(john,every(~x.person(x) & VPELL(BilI)))With the every unscoped, there is no choice of context which contains aparallel ele-ment o bill that does not also contain the VPELL functor, leading to an infinite regress,analogous to the "occurs check" failure in DSP.
Thus we correctly cannot produce theunavailable reading.
However, if we try to resolve the ellipsis after scoping, we have:forall(.Xx.person(x) & VPEkL(bill),~y.greet(john,y))This will not succeed either, because the choice of context will have to be greet(john.y),but in this expression, y really is free and so we do not have a valid equation.
Wewould have to adopt Pereira's pair notation for our quantifiers in order to make surethat the equation was valid:forall(.Xx.
(person(x) & VPELL(bill),greet(john,x)))Now everything is taking place within the scope of the lambda, as above.
Note thatthis chain of reasoning is, mutatis mutandis, exactly the same motivation for DSP'suse of the pair notation.Given our different control regime for the application of equivalences, and the pairquantifier notation, we appear to avoid the need for the sleight of hand involved inthe dual nature of DSP's assumption variables.
However, what is arguably the sameproblem in a different guise occurs when we examine the interaction of our scopingequivalence and that for sentence-internal pronoun reference given earlier.
Recall thatthis equivalence will identify a pronoun with any term of type e elsewhere in theQLF provided the usual binding and agreement conditions are met.
Unfortunately,in our analysis, quantified NPs are also of type e and thus we will produce invalidinterpretations in cases where the equivalence applies before the quantifier has beenscoped.
Thus, as well as the correct bound variable interpretation for a sentence likeevery manager likes his secretary, we will also produce the structure corresponding toevery manager likes every manager's ecretary.
What we need is some way of capturingthe fact that NPs like every manager, although of type e, have to be treated ifferentlythan NPs like Smith.
A simple way of doing this would be to introduce subtypes ofe, so that both types of NP would still be of type e but they could be distinguishedwhere necessary.
The Pron-intra equivalences would then be restricted to apply onlyto names or variables.
This has the advantage that we still stay within the same logicalframework (Kohlhase and Pfenning \[1993\] show how to extend HOU to accommodatesubtypes), although of course we are really using subtypes here to record a syntacticdistinction that has been erased in the course of constructing the QLF.4.
An ImplementationA small implementation which (with the exception of the examples just discussed,and those needing abduction) covers all of the phenomena described so far has beendeveloped.
It uses a simple unification grammar (based on the formalism described in516Pulman Bidirectional Contextual Resolution(Pulman, 1996)) to produce QLFs.
The same grammar is used in generation to producesentences from QLFs.Equivalences are interpreted using a Prolog implementation of Huet's algorithmfor higher order unification, with some additional heuristics to bound search in thecase where terms of high order are encountered.
The implementation is aimed at clarityrather than efficiency but is still not disastrously inefficient (rather to my surprise, Imight add).
The whole process of parsing, resolving, and generating a paraphrase ofthe resolved LF for the following little text takes about 30 seconds on a 300 MHzlaptop PC.
(X^^Body is the notation for Ax.Body.
Upper case in the input (or output)corresponds to narrow focus intonation).Smith hired Sandy.They wrote a report.Jones read it.He liked the report.He is a manager.Sandy likes him.Smith doesn't.HE likes Roberts.SANDY does too.Working through the examples we show the input sentence; the (first) QLF foundfor it; the (first) RLF found for the QLF given the context (usually just the precedingRLF); and as full as possible a paraphrase of the RLF which we get by reversingthe equivalences and applying them in a null context to obtain a QLF which wethen generate from.
Note that in this implementation the existentially quantified eventvariable has been Skolemised.> Input: Smith hired Sandy.QLF:pos(past(hire(eO,smith,sandy)))RLF:pos(past(hire(eO,smith,sandy)))Resolved as: smith hired sandy.No resolution is needed in this example, since there is no preceding context.> Input: They wrote a report .QLF :pos(past (wr i te (e l , they ,a ( repor t ) ) ) )RLF:exists(report,A~^pos(past(write(el,npand(smith,sandy),A))))Resolved as: smith and sandy wrote a report.npand is the '+' operator described in the text.
It corresponds to one QLF construct forNP conjunction, hence the informative paraphrase.
If we ask for more paraphraseswith the previous entence serving as a context we get:he and sandy wrote a report.he and sandy wrote some report.he and she wrote a report.he and she wrote some report.smith and sandy wrote some report.smith and she wrote a report.smith and she wrote some report.
('Some' is treated as synonymous with 'a', which is not quite correct).> Input: Jones read it.517Computational Linguistics Volume 26, Number 4QLF:pos(past(read(e2,jones,it)))RLF:pos(past(read(e2,jones,i3)))Kesolved as: jones read the report that smith and sandy wrote.In this version we have incorporated the tweaks to allow for informative paraphrasesof pronouns described earlier.
'i3' is a Webber-style discourse referent correspondingto 'a report'.
It is identified with an iota term which supports the use of the definitein paraphrasing the resolved LF.
Further paraphrases reveal the well-known problemthat generated sentences may be ambiguous in a potentially confusing way:jones read the report that he and sandy wrote.jones read the report that he and she wrote.jones read the report that smith and she wrote.> Input: He liked the report.~LF:pos(past(like(e4,he,the(report))))RLF:pos(past(like(e4,jones,i3)))Resolved as: jones liked the report that smith and sandy wrote.The same paraphrasing behavior happens more or less automatically for definites.Alternative paraphrases for the RLF should include 'Jones liked it', and 'Jones likedthe report'.> Input: He is a manager.QLF:pos(pres(be(e5,he,a(manager))))RLF:exists(manager,A'^pos(pres(be(e5,jones,A))))Resolved as: jones is a manager.> Input: Sandy likes him.QLF:pos(pres(like(e6,sandy,he)))RLF:pos(pres(like(e6,sandy,jones))Resolved as: sandy likes jones.> Input: Smith doesn't.QLF:neg(pres(vpell(eT,smith)))RLF:neg(pres(like(eT,smith,jones))Resolved as: smith doesn't like jones.This is an example of simple VP ellipsis.
Alternative contextualized paraphrases are:smith doesn't.smith doesn't like him.Now we have set up a context in which contrastive focus is appropriate:> Input: HE likes Roberts.QLF:focus(he,pos(pres(like(e8,he,roberts))))RLF:focus(smith,pos(pres(like(e8,smith,roberts))))Resolved as: SMITH likes roberts.This example shows a QLF construct (from (Pulman, 1997b)) not discussed earlier,and for which no equivalence has been written yet.
Thus the input is only partlyresolved and focus is retained in the paraphrase.> Input: SANDY does too.QLF:pos(pres(too(sandy,vpell(e9,sandy))))RLF:pos(pres(like(e9,sandy,roberts)))Resolved as: sandy likes roberts.518Pulman Bidirectional Contextual ResolutionA combination of VP ellipsis and too-focus as described earlier.
Contextualized alter-natives are:SANDY likes him too.SANDY likes roberts too.sandy does.sandy likes him.This reveals a bug somewhere, as we do not get out the sentence we put in, whichshould always be one of the options.Here is the Hobbs-Shieber scope example, from a slightly differently configuredversion of the system in which the event variable is explicitly quantified rather thanSkolemised.I ?- ana ( \[every, manager, in, some, company, owns, a, car\], RLF, null : t),display_in_readable_f orm (RLF, LF) ?every, some, aLF = forall(A^'exists(company,B"and(manager(A), in(A,B))) ,CA^exists(car,D'^exists1(E^Apos(pres(own(E,C,D))))))some, every, aLF = exists(company,A-^forall(B^Aand(manager(B),in(B,A)),CA^exists(car,D^-existsl(E'^pos(pres(own(E,C,D)))))))a, every, someLF = exists(car,A^^forall(BAAexists(company,C^Aand(manager(B),in(B,C))),DA-existsl(E^^pos(pres(own(E,D,A))))))some, a, everyLF = exists(company,AA^exists(car,BAAforall(C^~and(manager(C),in(C,A)),D^Aexistsl(EA'pos(pres(own(E,D,B)))))))a, some, everyLF = exists(car,A^'exists(company,BA'forall(C'^and(manager(C),in(C,B)),D~^exists1(E^Apos(pres(own(E,D,A))))))),noThe missing combination which is correctly excluded is every - a - some.Clearly, these are small beginnings.
But this small scale implementation demon-strates that the approach is computationally viable in principle.
Issues to do with howto scale up to wider coverage are addressed later.5.
Comparison with Alternative Approaches5.1 Core Language Engine Quasi-Logical FormThe starting point for the approach followed here was a dissatisfaction with certainaspects of the theory of quasi-logical form as described in Alshawi (1990, 1992), andimplemented in SRI's Core Language Engine (CLE).
In the CLE-QLF approach, as ra-519Computational Linguistics Volume 26, Number 4tionally reconstructed by Alshawi and Crouch (1992) and Crouch and Pulman (1994),the context-independent meaning of a sentence is given by one or more QLFs thatare built directly from syntactic and semantic rules.
Just as here, these QLFs repre-sent the basic predicate argument structure of the sentence, and contain constructswhich represent those aspects of the meaning of the sentence that are dependent oncontext.The effects of contextual resolution are uniformly represented via the instantiationof metavariables.
This instantiation is brought about by the operation of resolutionrules, which are essentially user-defined Prolog predicates finding appropriate instan-tiations for metavariables from the current context.
Contextual resolution is thereforea process of adding information to an underspecified meaning representation u til itis sufficiently specified for the task at hand.
(In translation, for example, it need notbe fully specified.
For tasks like database query, it usually will have to be).
This pro-cess is completely monotonic and therefore fulfils a necessary (though not a sufficient)condition for reversibility.Some simplified examples will give the flavor of this theory.
A pronoun is rep-resented at QLF by a term containing essentially a syntactic category, an index, arestriction predicate, and a metavariable; schematically:term(pro, <idx>, <restriction>, <met avrble>)Thus a sentence like he sneezed will, ignoring tense and aspect, be represented asfollows at the QLF level; and, when the metavariable has been instantiated to thecontextually preferred candidate referent, at the resolved quasi-logical form (RQLF)level:QLF = sneeze(term(pro,+l,masc,Referent))KQLF = sneeze (term (pro, +I, masc, john) )Scoping of quantifiers is also a matter of instantiating metavariables.
QLF  formulascontaining quantifiers are prefixed by a scoping metavariable which scoping resolutionrules instantiate to a list of the indices associated with quantifiers, in an order thatindicates the preferred scoping:QLF =Scope : like (term(q, every, +i ,philosopher),term (q, some, +2, book) )RQLF =\[+i, +2\] : like (term (q, every, + i, philosopher),term (q, some, +2, book) )% every .... some ...\[+2, +I\] : like (term (q, every, +i, philosopher),term(q, some, +2 ,book) )% some ... every ...The denotational semantics of RQLF  structures involving instantiated scope andreferent metavariables is given in terms of simple interpretation rules that have the ef-fect of interpreting the quantifiers as having the scopes indicated by the lists of indices,and the pronouns as having the interpretation of the instantiation of the metavariable(in these cases at least).Alshawi and Crouch 0992) present an illustrative first-order fragment along theselines and are able to supply a coherent formal semantics for the CLE-QLFs themselves,using a technique essentially equivalent to supervaluations: a QLF  is true iff all itspossible RQLFs are, false iff they are all false, and undefined otherwise.There are many good things about this approach.
It has proved itself amenableto a large-scale implementation of impressive coverage, generality, and relative effi-ciency (Alshawi 1992).
It has the theoretically desirable property of monotonicity and,520Pulman Bidirectional Contextual Resolutionin practice, a large degree of reversibility.
In the implementation, generation can takeplace from the QLF level, or from resolved QLF.
(Which is the appropriate level de-pends partly on the application: generation from QLF is all that is needed for manytypes of translation, for example.
Generation from resolved QLF is chiefly used forchecking with a user that resolution has accurately resolved contextually dependentconstructs.)
Furthermore, QLF has, in principle at least, a coherent formal semantics viathe supervaluation technique--these are not uninterpreted representations (althoughthe supervaluation semantics does not lead to an appropriate consequence r lation, aswe shall see below).Nevertheless, there are several aspects of the theory that are not completely satis-factory.
Firstly, the QLFs themselves, although they are built by technically composi-tional semantic rules from syntactic structures, contain many constructs that are solelymotivated by the requirements of the resolution process.
QLFs contain, to take themost obvious example, indices and metavariables: constructs for which there is noapparent motivation in the syntax and morphology of English.Secondly, the semantic relation between underspecified QLFs and their furtherspecified RQLF representations is given entirely in terms of subsumption: a QLF sub-sumes all its possible RQLFs.
They differ syntactically only via the instantiation ofmetavariables, giving a particularly simple way of determining subsumption.
But thisnotion of subsumption does not model the intuitive relationship between contextuallydependent sentences and (relatively) contextually independent paraphrases that onemight expect: the QLF for he sneezed, for example, does not subsume the RQLF of Johnsneezed even in a context where he can only be interpreted as John.
In fact, when theCLE generates the sentence John sneezed as a check that he sneezed has been interpretedcorrectly, it does not do so from the resolved QLF corresponding to the latter.
ThisRQLF has the form:sneeze(term (pro,+23,masc,john)).But the QLF corresponding to John sneezed is:sneeze( term( name, + 32,A Y.name( Y,john ), Referent ) )Some inference has to take place to relate the RQLF for the interpreted sentenceto a QLF that unambiguously expresses its contextualized meaning.
This makes thetask of expressing the output of some application system in a context-dependent wayquite difficult: rather than being related to an RQLF, this output has to be related toa QLF that is sufficiently instantiated for a contextually unambiguous sentence to begenerated from it.
The resolution mechanism is not intended to be reversible, althoughby redefining resolution rules, reversibility is achievable to some extent within thelimitations just discussed (Hurst 1994).A third problem arises with the approach to the semantics of QLFs that this notionof the relationship between QLF and RQLF encourages one to adopt: it is that taken byAlshawi and Crouch (1992).
This describes the semantics of QLFs via a supervaluationover the semantics of the RQLFs that they subsume.
Although the problem does notarise for the simple fragment hey illustrate there, if their approach were extended tocover a wider range of constructions, it would be found that many QLFs subsumedRQLFs that are not actually permitted by the resolution rules: for example, those thatcan only arise via a violation of scoping or binding constraints.
The role of resolu-tion rules (for perfectly good presentational reasons) is completely ignored by theirtreatment.
However, it is really the case that in giving the semantics of a QLF, one isinterested only in the set of RQLFs that are obtainable from it under closure of theresolution rules.
Ideally, therefore, we would like a formal reconstruction of resolution521Computational Linguistics Volume 26, Number 4rules as well.
This is so, not just for reasons of formal hygiene in trying to make logicalsense out of underspecified representations, but also because resolution rules and theknowledge they express are an important object of study in their own right.
Anyonewho has built a wide-coverage system knows that the range of context-dependentphenomena encountered in real life is a lot wider than the preoccupations of manylinguists might suggest.
In the CLE, for example, contextual resolution forms a largerpart of the system than do syntactic and semantic processing.
Unfortunately, in theCLE there is no formal theory of resolution rules, and thus no prospect of capturingtheir role in assigning a semantics to QLFs.A further problem, that the supervaluation semantics does not yield the rightconsequence r lation, is discussed below.The QLF-based theory illustrated in the approach advocated here does not sufferfrom these problems:QLFs contain only information for which there is a direct syntactic ormorphological reflex.
In particular, there are no indices or metavariables.the relation between QLF and RLF is directly reversible.the semantics of QLFs is completely given by the conditionalequivalences that relate them to RLFs, thus avoiding the problem of thesubsumption-based treatment and the associated supervaluationsemantics.
(More detail on precisely how this semantic account works isgiven below.
)conditional equivalences are a formal language for resolution rules, thusbringing them within the scope of the theory.5.2 Glue LanguageWithin the LFG framework, Dalrymple and her colleagues have been working on alinear logic glue language approach to semantic assembly and underspecification (Dal-rymple et al 1996).
LFG distinguishes two different levels of syntactic representation:constituent structure and functional structure (f-structure) at which the basic syntacticrelations are distinguished (subject, object, etc.).
Semantic interpretation is also at twolevels: a o--projection maps an f-structure to a or-structure.
Although o--structures aredescribed as semantic structures, they are not themselves meanings.
Rather they areconnected to meanings or logical forms via "--J, which the authors describe as anotherwise uninterpreted binary predicate symbol.
Given a c~-structure and the mean-ing constructors associated with the lexical items in the f-structure from which it wasprojected, the initial semantic level is a (linear logic) conjunction of the meaningsassociated with the lexical items.
This is approximately the equivalent of our ownQLF level of representation, although there are enough different assumptions that thisequivalence is not very meaningful.From the initial level, inferences can be drawn via linear logic derivations.
Theseinferences correspond roughly to our RLFs, in that they are logical forms that can beevaluated irectly for truth (I assume: this is not stated explicitly).To illustrate, we show the derivation of the two different scopings of our earlierexample:(44) Every manager uses a computer.522Pulman Bidirectional Contextual ResolutionThis sentence will receive the following f-structure.
:"PREDSUBJOBJuseSPEC every \]g: LPRED managerjh: I SPEC aLPRED computerThe a-projections for g introduces initially empty VAR and RESTR attributes.
Thelexical entry for every isVG,R,S.(Vx.(T?
VAR) -,a x -o (G RESTR) ~ R(x))?
(gx.T?---~ x -o G ~ S(x))-o G ~ every(R,S)which can be paraphrased:Ifif the variable of the NP a-projection this is part of is arbitrary xthen the noun restriction of the NP ~r-projection is interpreted as R(x)andif the a-projection of the whole NP is arbitrary xthen the scope is interpreted as S(x)then the scope can be (re)interpreted asthe quantification: every(R,S)The semantic lexical entry for manager will be:VX.
(T,~ VAR) --~ X -o (T?
RESTR) --~ manager(X)When these lexical entries are unified with the f-structure the T?
will be instantiatedto g?.
In the result, the entry for manager unifies with the nested implication in theantecedent of the entry for every, allowing the deduction (by modus  ponens, withsubstitutions {(X,x>,(R, manager>}) to the conclusion:VG,S.
(Vx.
g~ ~ x -o G ~ S(x))-o G ~ every(manager, S)The meaning of a computer is constructed analogously:VH, Q.
(Vy.
he ~ y -o  H ,-~ Q(x))-o H ~ a(computer, Q)The meaning for a transitive verb like use is of the form:VX,Y.(T?
SUBJ) --~ X ?
(T?
OBJ) ~ Y -o To ~ use(X,Y)523Computational Linguistics Volume 26, Number 4i.e., 'if the subject means X and the object means Y then the sentence means use(X,Y)'.The meaning of a sentence is obtained from the conjunction of this expression withthe meanings of the subject and object.
With nonquantified arguments, the meaningsof the subject and object simply satisfy the antecedent of the implication allowing theconsequent to be deduced, with X and Y instantiated to the subject and object mean-ings.
In the case of quantified arguments this inference will not go through directly.Instead, the verb meaning is rewritten to one of two logically equivalent forms, whereg?
and he are the subject and object meanings:usel: VX.
g?
-,~ X -o (VY.
he --~ Y -o f?
~ use(X,Y))use2: VY.
he ~ Y -o (VX.
g?
~ X -o f,~ ~ use(X,Y))(The theoretical status of these rewriting operations i not clear: it is presumably some-thing that happens in the lexicon, but whether it counts as a spurious ambiguity ofverb meaning as in some similar categorial grammar treatments of quantifier scope isnot specified).
From the meaning of use1 and the meaning of a computer we can de-duce the following formula, corresponding tothe choice of narrow scope for a computer(linear implication -o is like ~ in that {q,p ~ (q ~ r) ~ p ~ r}).VX.g?
~ X -o ff?
~ a(manager, Av.use(X,v))The variable substitutions are { <H,f?
>,<Y,y>,<Q,Av.use(X,v)> }.
We can now combine thiswith every manager to give:fo --~ every(manager, Au.a(manager, Av.use(u,v)))with substitution {<G,g?>,<X,x>,<S, Au.a(manager, Av.use(u,v)>}.To get the alternative scoping we combine every manager with use2 to get:VY.h?
,-~ Y -o ff?
,-~ every(manager, Au.use(u,Y))which then combines with a computer to give:fo --~ a(computer, Av.every(manager, Au.use(u,v)))There are several points of contact between this glue language analysis and ourown:.
Both share the somewhat inelegant feature that a quantified noun phrasehas to have a denotation of type e at some level, because it is anargument of a verb.
In our case, this is achieved by resolving adeterminer like every of type <<e,t>,e> as a quantifier like all, where thescope is supplied by higher-order unification, which in effect abstractsover this argument position.
This means that we do not have a veryplausible story to tell about the independent denotation of QLF levelevery--it just denotes ome function from noun meanings to individuals.In the glue language version, the same is true: the antecedent of therelevant implication says 'if we can assign an arbitrary meaning x oftype e to the f-structure of the whole NP, ... ' .524Pulman Bidirectional Contextual Resolution.
both use higher-order unification: in order to assemble the correct valuesfor the variables R, S, and Q above, a higher-order unification isnecessary.However, I would maintain that the QLF treatment has several distinct advantages:,2..it uses only HOU: we do not need to allow verb rewriting, in particular.it is reversible: nothing further is required to be able to generatesentences from scoped logical forms.
The glue language treatment is notobviously reversible, at least in its present form.it is sensitive to context: the conditional equivalences require the contextto be an appropriate one for the scoping derived.
The form of theimplication in the interpretation direction is 'QLF & Context t- RLF'.
Bycontrast, if I have understood correctly, the glue language deductions aspresented require only the linguistic forms to be present: thus allinterpretations of an ambiguous form will be derivable, whatever thecontext.
Some further specification of how context acts to eliminateimpossible readings is required.
85.3 Underspecified Discourse Representation StructuresIn a series of papers, Reyle (1993, 1995, 1996) has elaborated a version of DRT thatis able to represent quantifier scope and other ambiguities in a single underspecifiedrepresentation.
(In other respects like pronoun or definite description interpretation,standard DRT is already an underspecification-based theory.)
UDRT differs from stan-dard DRT in that the familiar "boxes" are partly replaced by a set of labels for theconditions in the boxes and the relations between them, and partial relations of in-clusion between (the components indexed by) these labels.
When sentences are fullyscoped, the representations are like standard DRT with extra labels.
Thus a sentencelike(45) Every manager owns a computer.would be represented in its different scopings by:11: 12: x13:manager(x) =-kI y 14: 15:computer(y)16:owns(x,y)8 The glue language approach makes much of the "resource sensitivity" of linear logic.
But in thespecific instances of the analysis of quantifier scope and pronouns discussed in Dalrymple et al (1996),the linearity and resource sensitivity of the logic assumed is, as far as I can see, subverted by thedevice of "reinterpreting" constructs like the "scope" variable (see example 28) or the "reintroduction"of pronoun meanings (see example 39).525Computational Linguistics Volume 26, Number 4and:11: 12\[ 13:manager(x) 15:computer(y) 14: 16:owns(x,y)But a representation which does not specify the scoping in ambiguous cases canbe given by listing the component elements, along with the inclusion ordering thatdetermines the scoping.
The components are:( 11: ,12: /L13: manager(x) 1 15: computer(y) 1 16: owns(x,y) \] )and the two orderings are:14\[{12 -~ 11, 13 -~ 12, 14 -~ 11, 15 -~ 14, 16 -~ 14}{12 ~ 11, 13 -~ 12, 14 ~ 11, 15 -~ 11, 16 -~ 14}We now represent the unspecified scoping by (roughly) the intersection of these inclu-sion constraints, which gives the following partial order, here determined just on thebasis of the syntactic structure of the sentence.
This representation leaves it unresolvedas to whether the indefinite has wide or narrow scope:/ 11: 12: x13:manager(x) 14: I 16:owns(x,y)15: Ycomputer(y)Resolution of scoping consists of adding further inclusion constraints.
Other than thosewhich are the result of general principles (e.g., binding constraints), it is not part ofthe theory to say where these constraints come from.
Just as for pronoun resolution,(U)DRT provides a representation that allows for the monotonic addition of infor-mation to do the resolution, but has nothing to say about the mechanisms that dothis.Reyle sketches various methodological requirements that should be met by a the-ory of meaning underspecification (Reyle 1996, 241ff.).
Firstly, it should be possibleto represent partial orders of scoping relations.
Secondly, it should be able in effectto emulate the DRT treatment of donkey sentences (p. 243) (a somewhat parochialrequirement, given that the case is not yet closed on whether this treatment is correct:see Elworthy \[1995\], among others).
Thirdly, the theory should not need anything likethe free variable constraint.526Pulman Bidirectional Contextual ResolutionClearly, UDRS meets these requirements, asdoes our own QLF-based approach.There are some similarities between the UDRS and the glue language approaches, asdetailed in Crouch and van Genabith (1997).
There are also some differences: unlikeour approach, or the glue language approach, UDRS does not have the problem ofhow to represent the meaning of quantified NPs as things of different ype at dif-ferent levels.
However, it achieves this at the cost of not representing the meaningsof quantified NPs as independent units at all: determiner and restriction are separatecomponents hat have no close connection to each other until the inclusion constraintsare imposed.
It remains to be seen whether this unconstrained approach to semanticassembly can be implemented on a large scale, given that it is prima facie not verycompositional.Early versions of UDRS (Reyle 1993) treated ambiguity as disjunction, which as weshall see, is not correct.
The more recent version (Reyle 1996) remedies this.
UDRS alsomakes a serious attempt at developing a calculus for reasoning directly with under-specified DRSs, a necessary move: the whole point of working on underspecificationis to be able to work with underspecified representations directly, rather than relyingon their fully specified resolutions.
This is a deficit in our own account (and the gluelanguage account) that we shall begin to remedy below.While there are many points of contact between the two approaches, there are atleast wo dimensions along which I would maintain the QLF approach to be preferable:..it is reversible.
It may be possible to do reversible resolution withinUDRT, but since the theory does not specify how to do resolution, wecannot really say one way or the other.the representations postulated are motivated only by overt linguisticelements.
UDRS shares with the CLE-QLF approach a proliferation ofmetaconstructs (labels, indices, ordering constraints, etc.)
that aremotivated only by the resolution process, not by the linguistic forms ofsentences.
It might be argued that this is an aesthetic preference ratherthan a substantive one, but it is likely to have consequences for bothmethodology and implementation: semantic assembly is surely going tobe a very unconstrained and noncompositional process in thisframework.6.
The Semantics of QLF6.1 The Meaning ofAs was pointed out earlier, conditional equivalences of the form:QLF 4:~ RLFifConditionl,' ' .
tCondition..are logically equivalent to the conjunction:(Conditionsl .... & QLF --~ RLF)&(Conditionsl .... & RLF --~ QLF)527Computational Linguistics Volume 26, Number 4if the symbol v-z is interpreted as material or logical equivalence.
9 We would like topreserve this interpretation, because by doing so we can claim that our conditionalequivalences collectively provide a truth definition for expressions of our QLF lan-guage.In, say, first-order logic, truth is defined directly via clauses like:3x.P(x) is true iff some value of x makes P(x) true.P & Q is true iff P is true and Q is true.etc.But for QLFs, truth is defined derivatively, via the truth conditions for the RLFs withwhich a QLF is associated via the equivalences:QLF ~ RLFifC1... C,The RLFs themselves are assigned truth conditions directly via the usual interpretationfunction for a typed higher-order logic of the kind we are assuming.
An actual QLFmay require a sequence of equivalences in order to arrive at a fully truth evaluableRLF, of course.
But we can simplify by assuming that this sequence is represented asa single equivalence, because:(Q1 ~ Q2 if Ci ) & (Q2 ~ Q3 if C2) & ...  (Q, ~ R if C,)is equivalent to:QI ~ R if Cl & C2 & .. ?
Cnwhich has the same form as a single equivalence.
(We ignore the possibility of abduc-tion in this section and assume that all conditions are fully evaluable.
)So for a particular resolved QLF, the truth definition induced by the equivalenceswill be an instance of a schema like:if C l .
.
.
Cn, then P(he) is true iff P(john)if C i .
.
.
C,, then P(every(R)) is true iff forall(R,P)etc.Truth will be relative to a particular known context.For an unresolved QLF, the truth definition will have to take into account all thepossible contexts in which it could be resolved, and all the ways within each contextthat it could be resolved (there may be equally plausible choices of pronoun antecedent,for example).
In the general case, there could be an infinite number of these.
Thenumber of different sequences of equivalence involved in resolutions will hopefullybe bounded by the number of QLF constructs appearing in the initial QLF, and thenumber of valid solutions to attempts to match equivalences to them.
(Unfortunately,nothing in the formal mechanism itself guarantees this.
It would be perfectly possibleto write equivalences that generated cycles.
I am assuming--or rather, hoping--that9 I am grateful to Stanley Peters for helpful discussion of the issues in this section.528Pulman Bidirectional Contextual Resolutionno such analysis would be linguistically plausible).
Because many of the contextualconditions are just variables over contextually available propositions, there will be nofixed upper limit on the number of valid contexts that could be considered.
So theform of a truth definition for an unresolved QLF will be:Ci --~ (Q is true iffR1) & C2 --~ (Q is trueif fR2) & .
.
.&  Cn --~ (Q is true iffThis seems like an intuitively sound reconstruction of our basic intuitions about themeaning of constructs like pronouns or ellipses.
It doesn't make much sense (unlesstalking theory) to ask "what does he mean?"
in the abstract.
But if we did, then ananswer like "Well, in this utterance context he means John, and in this utterance contexthe means Bill, etc .
.
. "
is a perfectly satisfactory answer.
That is essentially the formof answer that the current heory proposes.
It does not assign a full meaning to QLFconstructs like he or every in isolation, but only in a context.However, the coherence of such an approach is dependent on how fine-grainedour notion of context is made to be.
For if our truth definition is defining meaningsas above:C1 ~ (Q ~ R1)&C2 --~ (Q 4=~ R2)then it will follow that if, for a QLF Q in a given situation both C1 and C2 are satisfied,R1 and R2 must be equivalent.
It is clear that for the case of quantifier scope (at least)there will be many examples where the same QLF appears to be capable of beingresolved to two nonequivalent or even incompatible logical forms.neg(leave(e,every(boy)))(every boy didn't leave) can be resolved toneg(every(boy,&x.leave(e,x)))or:every(boy,&x.neg(leave(e,x)))which are not equivalent.
If we are to maintain that ~ is interpreted as logical equiv-alence, then we must argue that such a situation cannot happen.
Either the QLFs forthese cases will be different, or there will be something in the context hat means thatonly one interpretation can be derived.
(Michael Kohlhase has pointed out to me thatthis is equivalent to a requirement that a set of equivalences are "confluent" if viewedas a rewriting system.
)In the quantifier scope example above it might be, for example, that there is stress-marked focus on every (and falling intonation on the VP) leading to the wide-scopeevery interpretation.
An appropriate context for this would be where what is beingdenied is the proposition that some(boys,~x.neg(leave(e,x))).
The other interpretation ismost naturally associated with stress on didn't, forcing the negation to have widescope.
An appropriate context for this would be one in which what is being denied isthe proposition every(boy,~,x.leave(e,x)).If the focus is overtly marked, then the two QLFs will be different in that respectand so only one interpretation will be obtained.
But if the focus is underspecified, thenthe two contexts are still incompatible with each other, and only one interpretationwill be derived, as is required by our interpretation of the equivalences.529Computational Linguistics Volume 26, Number 4My assumption is that this is always the case: if the equivalences are capable ofresolving the same QLF to two logically distinct RLFs, then there is no (full) contextthat will simultaneously support both resolutions.
What this amounts to is the questionof whether an utterance--an utterance, not a sentence--is ever genuinely ambiguous.There are of course cases of deliberate ambiguity for poetic or humorous effect (seePoesio \[1996\]), but I think it is legitimate to regard these as metalinguistic or parasiticon the normal case (I read Barwise and Perry \[1983, 40-41\] as also taking this view).
Inmost cases the purpose of the ambiguity is precisely to cause the audience to becomeaware of the two different contexts that are associated with the different interpretations.It is not the case that the real circumstances of the utterance support both of thesecontexts.To summarize, on our theory, if we interpret ~ as logical equivalence, then we arecon~nitted to the claim that no utterance (where the context is fully specified) is trulyambiguous.
(This does not entail that particular speakers must be able to fully resolveall utterances.)
That is to say, there must be some feature of the form and content ofthe utterance, or the context in which it is produced, that exclude all but one of thepossible interpretations.6.2 Truth and ConsequenceIn van Deemter (1996), van Eijck and Jaspars (1996), and Jaspars (1997), criteria for anotion of ambiguous consequence are outlined.
In the following, R1 and R2 are (all)the resolutions of Q, and ~a is an ambiguous consequence r lation.We can smnmarize these requirements as follows:1.
Q D~ R1 or R22.
R1 and R2 D~ Q3.
-~Q ~a -~R1 or mR 24.
-~R1 and -~R2 ~a -~Q5.
Q ,~ R1 and R26.
R1 or R2 ~ka Q7.
-7 Q ~ ~R1 and ~R28.
~R1 or ~R2 ~ -~QIf an ambiguous expression is true then at least one of its readings is true (1).
Butthe stronger version, that all readings are true, is not plausible (5).
This would meanthat any expression with mutually contradictory eadings would lead to inconsistency.
(The CLE-QLF supervaluation semantics falls prey to this problem.)
On the other hand,if we know both readings are true, then we can safely assert he ambiguous expression(2).
If only one reading is true, we cannot assert he ambiguous expression safely (6).
Todo so would be to identify ambiguity with disjunction (given 1), and as van Deemter(1996) points out, this is to confuse the level at which the disjunction holds: When anexpression is ambiguous, then either it means P, or it means Q.
This is not the sameas saying that it means either P or Q.If we know that an ambiguous expression is false, then at least one of its inter-pretations must be false (3).
Again, we cannot strengthen this to the conclusion thatall readings are false (7) because that would lead us again to be regarding ambiguityas equivalent to disjunction: -~(P v Q) = -~P & -~Q.
However, if we know that bothreadings are false, we can assert that the ambiguous expression is false (4), but justas before, we cannot do this on the basis of knowing that just one of the readings isfalse (8).530Pulman Bidirectional Contextual ResolutionIs our account of truth for QLFs consistent with (1) to (8)?
Consider (1).
In the casethat R1 and R2 are the only disambiguations, then the truth definition tells us that:(T) C1--~ (Q~ R1)& C2--~ (Q~ R2)If we know that Q is true, then, because Q can only be equivalent to one of R1 orR2, for T to hold it must be the case that either C1 holds and so Q is equivalent to R1(and the other conjunct is vacuously true) or ditto for C2 and R2.
So one of R1 or R2will be true.
Since T will hold here if only one of R1 or R2 is true, this shows that (5)is valid also.Consider (2).
If both possible resolutions are true, for example, in a situation inwhich there are two tall men, John and Bill, and thus both John is tall and Bill is tall aretrue, a QLF corresponding to he is tall will count as true even if we do not know whichcontext holds.
For T to hold where both R1 and R2 are true, either the equivalence(Q iff R1) and the corresponding context, C1, must both fail, or the equivalence (Q iffR2) with context C2 must both fail.
But Q will still be true by virtue of the remainingequivalence.
However, if only one of R1 and R2 is true, then there is a model whereQ is false, namely where R1 is true and C1 is false, and C2 is true but R2 is false, orvice versa.
This shows that (6) is valid.Consider (3).
If Q is false, then for T to hold either R1 is false and C1 holds, or R2is false and C2 holds.
In either case the other conjunct is vacuously true.
However, ifwe try to strengthen this to the case where both R1 and R2 are false, T will only holdif both C1 and C2 hold: this cannot be so on our account, showing that (7) is also true.Consider finally (4).
If R1 and R2 are both false, then if Q is true, for T to holdC1 and C2 must both be false, which is impossible.
If either of them is true, Q mustbe false.
If only one of R1 and R2 is false, then it is possible for T to hold and for Qto be true, namely where R1 and C1 are false and R2 and C2 are true, or vice versa.This shows that (8) also holds for us.So our truth definition appears to support he kind of consequence r lation that isappropriate for reasoning with ambiguous entences.
Notice that several other prop-erties that are desirable will also fall out of our truth definition.
For example, we wantit to be the case that9.
Q, ~R1 ~ R2which says that if there is a true, two-ways ambiguous entence and one of the in-terpretations i  not true, the other one must be: perhaps the most basic kind of dis-ambiguation strategy.
It is in fact not completely trivial to arrive at such a conclusionwithout reducing ambiguity to disjunction: the logic of ambiguity in van Eijck andJaspars (1996), for example, does not have this property (Jaspars 1997).
But a ver-sion of (9) follows directly from T, with the additional conclusion that C2 must alsohold.6.3 Reasoning with QLFsWhy would we want to be sure that we have a coherent semantics for QLFs and asensible consequence r lation?
There are several reasons for doing so.
Firstly, there areoverwhelming arguments that some level like QLF is essential as part of a theory ofutterance interpretation, both for linguistic and computational reasons.
The practicalarguments for this position are well known and have been implicit in computationalpractice since at least Woods (1968, 1978).
It is simply not feasible to interleave theprocesses of quantifier scope or reference and ellipsis resolution, for example, with theotherwise compositional process of meaning assembly.
The space of possible interpre-531Computational Linguistics Volume 26, Number 4tations becomes unmanageably large.
However, postulating such a level of represen-tation incurs an obligation to say what it means: logical and computational hygienerequire us to supply a semantic account of it.Secondly, since the processes of contextual interpretation involve a certain amountof inference to be successfully achieved, and since some of the ingredients in thatinference are components of meaning of the sentence itself (such as the fact that apronoun is masculine, or that a determiner like any is in the scope of a negative) weneed to be sure that our partly specified representations have enough of a semanticsthat we can carry out this reasoning in a logically respectable way.In fact some types of linguistic processing presuppose that meanings are not fullyresolved.
Consider the following exchange:(46) A: She's here!B: Who is?The VP ellipsis in B's response has to be resolved with respect o an antecedentsentence that cannot be fully resolved: indeed, B's question would be pointless if itwas.
Observations like these compel the conclusion that partially resolved LFs need tohave enough of a semantics to support his kind of inference, while still being subjectto further linguistic processing.Thirdly, there are many practical natural anguage processing applications thatcan be carried out without needing (or being able) to produce a fully contextual-ized interpretation f a sentence.
Translation is an obvious example: while there willalways be some cases for which full interpretation is required for a correct ransla-tion to be possible, in general, translation on the basis of purely linguistic proper-ties can often be perfectly adequate.
A less obvious example is information extrac-tion: since it is not possible at the current state of the art to find complete gram-matical analyses for every sentence, let alne full contextual interpretations, infor-mation extraction proceeds by reasoning from partial or underspecified representa-tions that are in most logical respects the same kind of animal as the unresolvedQLFs we have been talking about.
Information extraction systems typically carryout such reasoning in a way that is, in Jerry Hobbs' phrase, unhindered by the-ory.Developing a calculus for reasoning with QLFs is too large a task to be under-taken here.
But the general outlines are reasonably clear, and we can adapt some ofthe UDRS (Reyle 1995) work to our own framework.
Reyle points out that many ofthe inferences involving underspecified representations that we would like to capturerely on the assumption that whatever context disambiguates the premise also disam-biguates the conclusion, even if we do not know what that context or disambiguationis.
His example is:If the students get ?10 then they buy books.The students get ?10.They buy books.Our treatment of the interpretation of QLFs makes it a tautology that if one re-solved form implies another, then the corresponding QLFs also do, given a fixedcontext.The other common patterns of inference that we want to capture are those in whichsome (unambiguous) conclusion will follow from an unresolved form, whichever res-532Pulman Bidirectional Contextual Resolutionolution of the unresolved form is correct.
Examples of these are things like:Every student went to a lecture.Mary is a student.Mary went to a lecture.Two hundred companies lost more than $2 million last year.Two hundred companies lost money last year.A teacher who gave a low mark to every student was dismissed.A teacher was dismissed.The first argument is valid whichever scoping of the first premise is taken, and itis possible that most people would accept he argument as valid without even noticingthe ambiguity.
The second argument is valid whether the premise is construed in acollective or a distributive way.
The third argument is valid whichever scoping of therelative clause is correct.We can begin to capture such inferences by using proof rules for QLFs (partlymodeled after those for UDRS in Reyle \[1995\]) such as these:CONJ: (where R is resolved, and Q may contain some unresolved constructs)R&QRQUANT: (where Q is a downward monotone determiner, and P does not containa negative)Pe~,t(Q~eo,t~,o(Roo,t))exists(R,P)CONJ and QUANT need considerable r finement in order to cover more than thesimplest cases, but they will give the correct results for the latter two examples.
Forthe first example something more is needed, perhaps along the lines suggested byMuskens (1998).7.
Conclusions and Further WorkWe have presented what is probably the first fully bidirectional formalism for theinterpretation a d generation of quasi-logical form representations and illustrated itsapplication with a fragment of English grammar that contains (admittedly simple)instances of some of the most important types of context-dependent construct.
Thisfragment has been fully implemented and works as advertised.We have tried to show that the interpretation f QLFs implicit in our treatment isa logically coherent one, supplying akind of contextual truth definition for unresolvedQLF constructs.
We have also argued that this truth definition supports a notion oflogical consequence that meets all the obvious desiderata for such a relation and havesketched how a calculus for reasoning directly with wholly or partially unresolvedQLFs could be developed, again in a logically coherent way.We conclude with a brief discussion of a series of issues that arise in thinking howto extend and apply the system described here.Robustness.
The work described here is an instance of what might be called "classical"NLP: a (hopefully) neat bit of theory, a nice clean logical formulation, and a small-scale implementation.
This kind of thing is currently desperately unfashionable on the533Computational Linguistics Volume 26, Number 4grounds that such methods cannot scale up to real-world applications.
(If you wantto get ahead, get a corpus.)
This is not the place to argue over whether this view isthe correct one, but it is worth pointing out that the current heory is, at least in onedirection, consistent with the kind of large-scale statistical processing that is viewed asthe appropriate alternative.
It was stated earlier that the grammatical formalism usedwas not an essential component of the theory.
Thus any alternative robust parsingsystem could be plugged in instead.What is required is that QLFs be stated in a typed higher-order logic.
The QLFswe have been dealing with correspond to complete and correct grammatical nalysesof sentences: in the real world, as we know, such things are not usually available.But in fact for the current approach, they are not needed: a partial or fragmentaryanalysis can be represented in QLF either by introducing a quantifier over a relationthat is assumed to hold between the components (thus presupposing that there wasa coherent message xpressed by the partially analyzed sentence) or by introducingSkolem-like predicate constants to achieve the same effect.
(See Pinkal \[1995\] for asimilar suggestion.)
The conditional equivalences will apply to such representationsdirectly, leaving the quantified relation or the Skolem constants in the resolved form.Of course, the resulting system will not be fully reversible, but it would be capable inprinciple of carrying out contextual disambiguation as part of a robust ext-processingsystem.Disambiguation.
We have been assuming that the "correct" QLF has been chosen beforeapplying our conditional equivalences.
However, this is an unrealistic assumption inthe fully general case, because it is quite conceivable that lexical disambiguation couldrequire some contextual disambiguation first.
Likewise, many PP attachment decisionshave to be made on contextual grounds.There are several stategies that might be pursued.
One is to adopt Pinkal's "radi-cal underspecification" approach (Pinkal 1995) and use underspecified representationsfor all types of ambiguity, even syntactic ambiguity.
The more conservative approachis to try to integrate xisting statistical disambiguation schemes for QLFs, either in-dividually or in a "packed" structure (Alshawi and Carter 1994), with the resolutionprocess as described here.
Alternatively, I believe it is worth exploring the approach todisambiguation described in Pulman (2000), which would mesh nicely with the theorypresented here.Efficiency.
Extending coverage of linguistic constructs, and trying to achieve robust-ness or integrate with disambiguation schemes each pose the further problem of theefficiency of the HOU-based resolution process itself.
While efficiency is acceptable forthe short, simple sentences illustrated earlier, the computational properties of HOUmean that processing times increase in a highly nonlinear way when larger QLFs areencountered.There are several avenues worth exploring to solve this problem.
While the equiv-alences are stated in a direction-neutral manner, there is scope in an implementationfor compiling them in different ways for the analysis and synthesis directions (recallthat the equivalences decompose to a conjunction of higher-order Horn clauses).
Onceyou know which direction you are going in, most of the unifications actually reduceto matchings (since one side of the equation is fully instantiated), which may allowfor various optimizations to the unification algorithm itself.
Prehofer (1994) describessome tractable subcases of higher-order unification.Another strategy is to change the control regime by which the equivalences apply.The regime assumed here, and that implemented, is entirely nondeterministic.
Equiv-534Pulman Bidirectional Contextual Resolutionalences apply to whole QLFs, in any order, whenever they can.
This means that manyequivalences are tried which are later filtered out because their associated conditionscannot be met.
This is both expensive and an unrealistic model of language processing.The other strategy is to make the resolution process incremental, rather than op-erating on whole QLFs at a time.
To some extent, the linguistic facts force this optionon us anyway, of course, because for many types of elliptical or anaphoric devicesthe appropriate context is an earlier part of the same sentence.
It ought to be a rela-tively straightforward matter to devise a control strategy to resolve QLFs essentially acomponent at a time, perhaps guided by the original syntactic structure.
This wouldbound the scope of higher order unify and keep it manageable, as well as having anintuitively satisfactory "dynamic" aspect o the resolution process.
(The strategy usedabove is incremental nd dynamic in that only one construct at a time is resolved, andeach resolution changes the context, but this does not necessarily always correspondto a left-to-right traversal of the original sentence).
There are some interesting inter-actions with the incremental interpretation scheme proposed in Pulman (1986) to beexplored here.Contextual Resolution Primitives.
Currently the content of the conditions in conditionalequivalences i rather unconstrained: any Prolog-definable predicate could be used.My hope is that in developing descriptions of a wider range of context-dependentphenomena, a set of conditions that recur (such as "parallel") can be isolated anddefined in a way that covers their use in resolving different ypes of contextual de-pendency.
Eventually one might hope that all the equivalences necessary would callon just a restricted range of such contextual predicates.
These predicates would thenin effect constitute the primitives of the linguistic theory of contextual resolution, fac-toring out all of the inferential processes that are not specifically linguistic.
In movingtowards such a theory, the requirement of reversibility is a hard one, but I believe itplaces a useful and productive methodological constraint on us, as well as yielding asignificant practical payoff.AcknowledgmentsThis paper is a descendant of Pulman(1994).
Versions of it have been given atBilkent University, Ankara, IMS Stuttgart,Cambridge, Edinburgh, ITRI Brighton,Sheffield, Oxford, and at workshops in BadTeinach and SaarbrOcken.
I thank theaudiences on these occasions: I canremember (at least) Varol Akman, NickAsher, Robin Cooper, Dick Crouch, Keesvan Deemter, Jan van Eijck, Tim Fernando,Josef van Genabith, Jan Jaspars, HansKamp, Ron Kaplan, Stanley Peters, ManfredPinkal, and Massimo Poesio makingsuggestions that changed the content of thepaper in one way or another.
The usualabsolutions apply.
Apologies to those who Ihave forgotten.
Thanks are also due to threeanonymous Computational Linguisticsreferees for insightful comments andcriticisms, to Fernando Pereira foranswering various questions, and toMichael Kohlhase for his detailed commentsand helpful discussion of the prefinal draft.ReferencesAlshawi, Hiyan.
1990.
Resolving quasilogical forms.
Computational Linguistics,16(3):133-144.Alshawi, Hiyan.
1992.
The Core LanguageEngine.
MIT Press.Alshawi, Hiyan and David M. Carter.
1994.Training and scaling preference functionsfor disambiguation.
ComputationalLinguistics, 20(4):635-648.Alshawi, Hiyan and Richard Crouch.
1992.Monotonic semantic interpretation.
IProceedings ofthe 30th Annual Meeting,pages 33-39.
Association forComputational Linguistics.Ayuso, Damaris M. 1989.
Discourse ntitiesin Janus.
In Proceedings ofthe 27th AnnualMeeting, pages 243-250, Vancouver.Association for ComputationalLinguistics.Barwise, John and John Perry.
1983.Situations and Attitudes.
MIT Press.Crouch, Richard and Josef van Genabith.1997.
On interpreting f-structures as535Computational Linguistics Volume 26, Number 4UDRSs.
In Proceedings ofthe 35th AnnualMeeting of the ACL and the 8th Conference ofthe European Chapter of the ACL,pages 402-409.
Association forComputational Linguistics.Crouch, Richard S. and Stephen G. Pulman.1994.
Monotonic semantics.
In R. Cooper,R.
Crouch, J. van Eijck, C. Fox, J. vanGenabith, J. Jaspars, H. Kamp, M. Pinkal,M.
Poesio, S. G. Pulman, and E. Vestre,editors, Describing the Approaches:Deliverable D8 of the FraCaS Project.Cognitive Science, University ofEdinburgh, pages 184-218.
Available fromftp.cogsci.ed.ac.uk/pub/FRACAS.Dalrymple, Mary, J. Lamping, FernandoC.
N. Pereira, and Vijay Saraswat.
1996.Quantifiers, anaphora, and intensionality.Journal of Logic, Language, and Information,6(3):219-273.Dalrymple, Mary, Stuart M. Shieber, andFernando C. N. Pereira.
1991.
Ellipsis andhigher-order unification.
Linguistics andPhilosophy, 14(4):399-452.Davidson, Donald.
1972.
Semantics fornatural anguages.
In D. Davidson andG.
Harman, editors, Semantics of NaturalLanguage.
Reidel.
Also in Davidson, 1984,Inquiries into Truth and Interpretation,Oxford, pages 55-64.Elworthy, David A. H. 1995.
A theory ofanaphoric information.
Linguistics andPhilosophy, 18(3):297-332.Gardent, Claire and Michael Kohlhase.1996a.
Focus and higher-orderunification.
In Proceedings ofthe 16thInternational Conference on ComputationalLinguistics, pages 430-435, Copenhagen.Gardent, Claire and Michael Kohlhase.1996b.
Higher-order colored unificationand natural anguage semantics.
InProceedings ofthe 34th Annual Meeting,pages 1-9.
Association for ComputationalLinguistics.Gardent, Claire and Michael Kohlhase.
1997.Computing parallelism in discourse.
InProceedings oflJCAI '97, pages 1016-1021,Tokyo.Gardent, Claire, Michael Kohlhase, andKarsten Konrad.
1999.
Higher-ordercolored unification: A linguisticapplication.
Tdchnique et SciencesInformatiques, Special Issue forJFPLC-UNIF'97, 18(2):181-209.Gardent, Claire, Michael Kohlhase, andNoor van Leusen.
1996. Corrections andhigher-order unification.
In Proceedings ofKONVENS'96, pages 268-279, Bielefeld,Germany.
De Gruyter.Gawron, Jean M. 1992.
Focus and ellipsisin comparatives and superlatives: A casestudy.
In C. Barker and D. Dowty, editors,Proceedings ofthe Second Conference on Se-mantics and Linguistic Theory, Working Papersin Linguistics No.
40, Ohio State University,pages 79-98.
Ohio University Press.Gawron, Jean M. 1995.
Comparatives,superlatives, and resolution.
Linguisticsand Philosophy, 18:333-380.Hobbs, Jerry R. 1979.
Coherence andcoreference.
Cognitive Science, 3(1):67-90.Hobbs, Jerry R. and Andrew Kehler.
1997.
Atheory of parallelism and the case ofvp-ellipsis.
In Proceedings ofthe 35thAnnual Meeting of the ACL, and the 8thConference ofthe European Chapter of theACL, pages 394-401.
Association forComputational Linguistics.Hobbs, Jerry R. and Stuart M. Shieber.
1987.An algorithm for generating quantifierscopings.
Computational Linguistics,13(1-2):47-63.Huet, Gerard.
1975.
A unification algorithmfor typed h-calculus.
Theoretical ComputerScience, 1:27-57.Hurst, Matthew.
1994.
Reversible resolutionwith an application to paraphrasing.
InProceedings ofthe 15th InternationalConference on Computational Linguistics,pages 551-555, Kyoto.Jaspars, Jan. 1997.
Minimal logics forreasoning with ambiguous expressions.Technical Report available fromwww.turing.wins.uva.nl / ,-~jaspars.Kamp, Hans and Uwe Reyle.
1993.
FromDiscourse to Logic: Introduction to ModelTheoretic Semantics of Natural Language,Formal Logic and Discourse RepresentationTheory.
Kluwer.Kohlhase, Michael and Frank Pfenning.1993.
Unification in a lambda calculuswith intersection types.
In Dale Miller,editor, Logic Programming: Proceedings ofthe1993 International Symposium,pages 488-505, Vancouver.
MIT Press.Lewin, Ian.
1990.
A quantifier scopingalgorithm without a free variableconstraint.
In Proceedings of the 13thInternational Conference on ComputationalLinguistics, Volume 3, pages 190-194,Helsinki, Finland.Miller, Dale and Gopalan Nadathur.
1986.Some uses of higher order unification incomputational linguistics.
In Proceedings ofthe 24th Annual Meeting, pages 247-255.Association for ComputationalLinguistics.Montague, Richard.
1974a.
The propertreatment of quantification i English.
InR.
Thomason, editor, Formal Philosophy.Yale University Press, New York,pages 222-246.536Pulman Bidirectional Contextual ResolutionMontague, Richard.
1974b.
Universalgrammar.
In R. Thomason, editor, FormalPhilosophy.
Yale University Press, NewYork.Muskens, Reinhard.
1998.
Logic, reasoningand underspecification f linguisticstructure.
Presented at a workshop in BadTeinach, Germany, May.Pereira, Fernando C. N. 1990.
Categorialsemantics and scoping.
ComputationalLinguistics, 16:1-9.Pereira, Fernando C. N. 1991.
Deductiveinterpretation.
In E. Klein and F. Veltman,editors, Natural Language and Speech.Springer Verlag, pages 116-133.Pinkal, Manfred.
1995.
Radicalunderspecification.
I  Proceedings ofthel Oth Amsterdam Colloquium on FormalSemantics, pages 587-606.Poesio, Massimo.
1996.
Semantic ambiguityand perceived ambiguity.
In S. Peters andK.
van Deemter, editors, SemanticAmbiguity and Underspecification.
CSLI,pages 159-202.Prehofer, Christian.
1994.
Decidablehigher-order unification problems.
InAutomated Deduction CADE-12, 12thInternational Conference on AutomatedDeduction.
Springer, pages 635-649.Prfist, Hub.
1992.
On Discourse Structure, VPAnaphora, and Gapping.
Ph.D. thesis,University of Amsterdam.Pulman, Stephen G. 1986.
Grammars,parsers and memory limitations.
Languageand Cognitive Processes, 1(3):197-225.Pulman, Stephen G. 1991.
Comparatives andellipsis.
In Proceedings ofthe 5th EuropeanMeeting of the Association for ComputationalLinguistics, pages 1-6.
Berlin: ACL.Pulman, Stephen G. 1994.
A computationaltheory of context dependence.
In H. Bunt,R.
Muskens, and G. Rentier, editors,Proceedings: International Workshop onComputational Semantics, pages 161-170.Institute for Language Technology,Tilburg University, The Netherlands.Pulman, Stephen G. 1996.
Unificationencodings of grammatical notations.Computational Linguistics, 22(3):295-328.Pulman, Stephen G. 1997a.
Aspectual shiftas type coercion.
Transactions ofthePhilological Society, 95(2):279-317.Pulman, Stephen G. 1997b.
Higher orderunification and the interpretation offocus.
Linguistics and Philosophy, 20:73-115.Pulman, Stephen G. 2000.
Statistical andlogical reasoning in disambiguation.Philosophical Transactions ofthe RoyalSociety, Series A, 358(1,769):1,267-1,280.Rayner, Manny.
1993.
Abductive EquivalentialTranslation and its application to NaturalLanguage Database Infferencing.
Ph.D. thesis,Stockholm University.
Also available athttp://www.cam.sri.com/tr.Rayner, Manny and Hiyan Alshawi.
1992.Deriving database queries from logicalforms by abductive definition expansion.In Proceedings ofthe 3rd InternationalConference on Applied Natural LanguageProcessing, pages 1-8, Trento, Italy.Association for ComputationalLinguistics.Reyle, Uwe.
1993.
Dealing with ambiguitiesby underspecification.
Journal of Semantics,10:123-179.Reyle, Uwe.
1995.
On reasoning withambiguities.
In Proceedings ofEACL 95,pages 1-8.
Association for ComputationalLinguistics.Reyle, Uwe.
1996.
Co-indexing labelledDRSS to represent and reason withambiguities.
In S. Peters and K. vanDeemter, editors, Semantic Ambiguity andUnderspecification, pages 239-268.
CSLI.Thomas, James and Stephen G. Pulman.1999.
Bidirectional interpretation of tenseand aspect.
In H. Bunt et al, editors,Proceedings ofthe Third InternationalWorkshop on Computational Semantics,pages 247-263.van Deemter, Kees.
1996.
Towards a logic ofambiguous expressions.
In S. Peters andK.
van Deemter, editors, SemanticAmbiguity and Underspecification.
CSLI,pages 203-238.van Eijck, Jan and Jan Jaspars.
1996.Ambiguity and reasoning.
CWI TechnicalReport CS-R9616.Webber, Bonnie L. 1983.
So what can wetalk about now?
In M. Brady andR.
Berwick, editors, Computational Modelsof Discourse.
MIT Press, pages 331-371.Woods, William.
1968.
Procedural semanticsfor a question-answering machine.
InProceedings ofthe Fall Joint ComputerConference, New York, pages 457-471, NewYork.Woods, William.
1978.
Semantics andquantification i natural anguagequestion answering.
In Yovits, editor,Advances in Computers.
Academic Press,New York, pages 2-64.537
