Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 581?589,Beijing, August 2010Improving the Quality of Text Understanding by Delaying AmbiguityResolutionDoo Soon KimDept.
of Computer ScienceUniversity of Texasonue5@cs.utexas.eduKen BarkerDept.
of Computer ScienceUniversity of Texaskbarker@cs.utexas.eduBruce PorterDept.
of Computer ScienceUniversity of Texasporter@cs.utexas.eduAbstractText Understanding systems often committo a single best interpretation of a sen-tence before analyzing subsequent text.This interpretation is chosen by resolv-ing ambiguous alternatives to the one withthe highest confidence, given the contextavailable at the time of commitment.
Sub-sequent text, however, may contain infor-mation that changes the confidence of al-ternatives.
This may especially be thecase with multiple redundant texts on thesame topic.
Ideally, systems would de-lay choosing among ambiguous alterna-tives until more text has been read.One solution is to maintain multiple can-didate interpretations of each sentence un-til the system acquires disambiguating ev-idence.
Unfortunately, the number of al-ternatives explodes quickly.
In this pa-per, we propose a packed graphical (PG)representation that can efficiently repre-sent a large number of alternative interpre-tations along with dependencies amongthem.
We also present an algorithm forcombining multiple PG representations tohelp resolve ambiguity and prune alterna-tives when the time comes to commit to asingle interpretation.Our controlled experiments show that bydelaying ambiguity resolution until multi-ple texts have been read, our prototype?saccuracy is higher than when committingto interpretations sentence-by-sentence.1 IntroductionA typical text understanding system confronts am-biguity while parsing, mapping words to conceptsand formal relations, resolving co-references, andintegrating knowledge derived from separate sen-tences or texts.
The system discards many candi-date interpretations to avoid combinatorial explo-sion.
Commonly, after reading each sentence, asystem will commit to its top ranked interpreta-tion of the sentence before reading the next.If a text understanding system could postponecommitting to an interpretation without beingswamped by a combinatorial explosion of alterna-tives, its accuracy would almost surely improve.This intuition follows from the observation thattext is redundant in at least two ways.
First, withina single coherent text (about the same entitiesand events), each sentence informs the interpre-tation of its neighbors.
Second, within a corpus oftexts on the same topic, the same information isexpressed in different surface forms, ambiguousin different ways.
Related fields, such as Infor-mation Extraction, exploit textual redundancy togood effect, and perhaps text understanding canas well.One approach is for the text understanding sys-tem to maintain multiple complete candidate in-terpretations.
After reading each sentence, for ex-ample, the system would retain a beam of the n-best interpretations of the sentence.
While thisapproach avoids a combinatorial explosion (forreasonable values of n), several problems remain.First, because the beam width is limited, the sys-tem may still discard correct interpretations beforebenefiting from the extra context from related text.Second, enumeration of the candidate interpreta-581tions does not represent the dependencies amongthem.
For example, there may be multiple candi-date word senses and semantic roles for a givensentence, but sense alternatives might be depen-dent on role selection (and vice-versa).
The setof reasonable interpretations may be a subset ofall combinations.
Finally, maintaining distinct in-terpretations does not contribute to addressing theproblem of combining evidence to narrow downalternatives and ultimately select a single best in-terpretation of a text.This paper addresses these three problems.
Wepropose an approach that postpones committing toan interpretation of a text by representing ambi-guities and the dependencies among them.
Theremay still be combinatorial growth in the set of al-ternative interpretations, but they are representedonly intensionally, using a packed representation,which maintains alternatives while avoiding enu-merating them.
We also propose an algorithm forupdating and pruning the packed representation asmore sentences and texts are read.We evaluate our approach by comparing tworeading systems: a baseline system that commitsto its best interpretation after each sentence, andour prototype system that uses a packed represen-tation to maintain all interpretations until furtherreading enables it to prune.
For this initial proof ofconcept, we use a small corpus of redundant texts.The results indicate that our approach improvesthe quality of text interpretation by preventing ag-gressive pruning while avoiding combinatorial ex-plosion.In the following sections, we first describe ourtarget semantic representation of the interpreta-tion of sentences.
We then present the detailsof our packed graphical representation (PG rep-resentation) and our algorithm to resolve ambi-guities in the PG representations as disambiguat-ing evidence from subsequent text accrues.
Wedescribe the architecture of a prototype that pro-duces PG representations for text and implementsthe disambiguating algorithm.
Finally, we presentthe results from controlled experiments designedto compare the accuracy of the prototype to abaseline system that prunes more aggressively.Figure 1: The target semantic graph representa-tion for S12 Target semantic representationOur target representation is a semantic graph inwhich nodes are words and the ontological typesto which they map.
Edges are semantic relationscorresponding either to function words or syntac-tic relations in the sentence?s parse.Fig.
1 shows the target semantic representationfor the following simple sentence:S1: An engine ignites gasoline with its spark plug.3 PG representationAlternative semantic interpretations for a sentencecan be captured with a single PG representationwith ambiguities represented as local alternatives.Because candidate representations are often struc-turally similar, a PG representation can signifi-cantly compress the representation of alternatives.Fig.
2 shows the PG representation of alternateinterpretations of S1 (PG1).
The different types ofambiguity captured by the PG representation areas follows.3.1 Word-Type ambiguityIn PG1, the node engine-2a corresponds to theword ?engine?
in S1.
Its annotation [LIVING-ENTITY .3 | DEVICE .7] captures the map-ping to either LIVING-ENTITY (probability 0.3)or DEVICE (probability 0.7).
The PG repre-sentation does not presume a particular uncer-Figure 2: The PG representation for S1 (PG1)582tainty formalism.
Any formalism, (Dempster-Shafer theory (Pearl, 1988), Markov Logic Net-works (Richardson and Domingos, 2006), etc.
)could be used.3.2 Semantic Relation ambiguityIn PG1, the edge label <agent .6 | location .4>from ignite-3a to engine-2a says that the engine iseither agent or location of the ignition.3.3 Structural ambiguityIn PG1, edges D and E are alternatives corre-sponding to the different prepositional phrase at-tachments for ?with its spark plug?
(to ignite-3aor gasoline-4a).
The annotation {D .3 | E .7} saysthat the choices are mutually exclusive with prob-abilities of 0.3 and 0.7.3.4 Co-reference ambiguityCo-reference of nodes in a PG representation iscaptured using a ?co-reference?
edge.
In PG1, theedge labeled <coref .7> represents the probabil-ity that engine-2a and its-7a are co-referent.In addition to storing ambiguities explicitly,the PG representation also captures dependenciesamong alternatives.3.5 Simple dependencyThe existence of one element in the graph de-pends on the existence of another element.
Ifsubsequent evidence suggests that an element isincorrect, its dependents should be pruned.
Forexample, the dependency A ?
C, means that ifLIVING-ENTITY is ultimately rejected as the typefor engine-2a, the agent relation should be pruned.3.6 Mutual dependencyElements of a mutual dependency set are mutuallyconfirming.
Evidence confirming or rejecting anelement also confirms or rejects other elements inthe set.
In the example, the box labeled B says that(engine-2a type DEVICE) and (ignite-3a locationengine-2a) should both be confirmed or prunedwhen either of them is confirmed or pruned.Formally, the PG representation is a structureconsisting of (a) semantic triples ?
e.g., (ignite-3a type BURN), (b) macros ?
e.g., the symbol Arefers to (ignite-3a agent engine-2a), and (c) con-straints ?
e.g., A depends on C.4 Combining PG representationsMaintaining ambiguity within a PG representationallows us to delay commitment to an interpreta-tion until disambiguating evidence appears.
Forany text fragment that results in a PG represen-tation (PGa) containing ambiguity, there may ex-ist other text fragments that are partly redundant,but result in a less ambiguous (or differently am-biguous) representation (PGb).
PGb can be usedto adjust confidences in PGa.
Enough such evi-dence allows us to prune unlikely interpretations,ultimately disambiguating the original representa-tion.For example, sentence S3 does not have suffi-cient context to disambiguate between the MO-TOR sense of ?engine?
and the VEHICLE sense (asin locomotive).S3: General Electric announced plans this weekfor their much anticipated new engine.The PG3 representation for S3 (PG3) wouldmaintain the ambiguous representation (with con-fidences for each sense based on prior probabil-ities, for example).
On subsequently encounter-ing sentence S4, a Lesk-based word sense disam-biguation module (as in our prototype) would pro-duce a PG4 with a strong preference for the loco-motive sense of ?engine?, given the more specificcontext of S4.S4: The announcement comes to the relief of manyin the railway industry looking to replace the en-gines in their aging locomotive fleets.To use PG4 to help disambiguate PG3, we needto align PG3 and PG4 semantically and mergetheir conflict sets.
(In the simple example, theconflict sets for the word ?engine?
might be [MO-TOR .5 | VEHICLE .5] in PG3 and [MOTOR .2 |VEHICLE .8] in PG4).Algorithm 1 describes how two PG representa-tions can be combined to help resolve their ambi-guities.
The algorithm identifies their isomorphicsubgraphs (redundant portions of the interpreta-tions) and uses the information to disambiguatetheir ambiguities.
For illustration, we will stepthrough Algorithm 1, merging PG1 (Fig.
2) with583Algorithm 1 Disambiguating PG representationsInput : PG1, PG2Output: new PG representation1.
Identify semantically aligned parts betweenPG1 and PG2.
Use graph matching to identifyalignments (redundant portions) between PG1and PG2: align nodes with the same base wordor with taxonomically related types; from thenode alignments, align identical types as typealignments; align relations if the relations arethe same and their head and tail nodes havebeen aligned.2.
Use alignments to disambiguate PG1 andPG2.
With the available information (the con-fidence scores and the constraints in PG1 andPG2 and the alignments between them), usejoint inference to calculate the confidence scoreof each candidate interpretation.
If the con-fidence score of one interpretation becomesmuch higher than competing ones, the interpre-tation is chosen while the others are discarded.3.
Combine the disambiguated PG1 and PG2into one PG representation using the align-ments identified in the first step.Figure 3: PG representation for S2, ?The engine?sspark plug combusts gasoline.
?PG2 (Fig.
3).1.
The graph matcher identifies alignmentsbetween PG1 and PG2.
Type alignments include(engine-2a[DEVICE], Engine-1b[DEVICE]),(spark-plug-8a[LIVING-ENTITY], spark-plug-3b[LIVING-ENTITY]).
Relation alignmentsinclude ((combust-5b instrument spark-plug-3b),(ignite-3 instrument spark-plug-8)), ((ignite-3ainstrument spark-plug-8a) (combust-5b instru-ment spark-plug-3b)).2.
In this example, when two interpreta-tions are aligned, we simply add their confi-dence scores.
(We are currently incorporatingAlchemy (Richardson and Domingos, 2006) in theprototype system to do the joint inference).
Forexample, aligning engine-2a with Engine-1b re-sults in a score of 1.7 for DEVICE (1 + .7).
Theconfidence score of LIVING-ENTITY in engine-2a is unchanged at .3.
Since the resulting scorefor DEVICE is much higher than 1 the score forLIVING-ENTITY, LIVING-ENTITY is discarded.Deleting LIVING-ENTITY causes deletion of theagent edge between ignite-3a and engine-2a dueto the dependency constraint A ?
C.3.
The disambiguated PG1 and PG2 are mergedinto a single PG representation (PG1+2) based onthe alignments.
Any remaining ambiguity persistsin PG1+2, possibly to be resolved with anothersentence.5 Prototype system5.1 ParserOur prototype system uses the StanfordParser (Klein and Manning, 2003).
To cap-ture structural ambiguity for our experiments,we manually edited the parser output by addingcorrections as alternatives wherever the parsetree was incorrect.
This gave a syntactic PGrepresentation with both incorrect and correctalternatives.
We gave the original, incorrectalternatives high confidence scores and the added,correct alternatives low scores, simulating aparser pruning correct interpretations in favorof incorrect ones with higher confidence scores.The syntactic PG for S1 is shown in Fig.
4.
Wehave recently designed a modification to theStanford Parser to make it produce syntactic PGrepresentations natively, based on the completechart built during parsing.5.2 Semantic InterpreterThe semantic interpreter assigns types to nodes inthe syntactic PG representation and semantic rela-tions to the edges.Type ambiguity.
Types and confidence scoresare assigned to words using SenseRelate (Pat-wardhan et al, 2005), WSD software based on the1In our prototype, we set the pruning threshold at 13?thescore of the top-scored interpretation.584Lesk Algorithm (Lesk, 1986).
Assigned sensesare then mapped to our Component Library ontol-ogy (Barker et al, 2001) using its built-in Word-Net mappings.Relational ambiguity.
Semantic relations areassigned to the dependency relations in the syn-tactic PG representation according to semantic in-terpretation rules.
Most rules consider the headand tail types as well as the dependency relation,but do not produce confidence scores.
Our proto-type scores candidates equally.
We plan to incor-porate a more sophisticated scoring method suchas (Punyakanok et al, 2005).Structural ambiguity.
Parse ambiguities (suchas PA vs. PB in Fig.
4) are converted directly tostructural ambiguity representations (D vs. E inFig.
2) in the semantic PG representation.Simple Dependency.
A dependency is in-stalled between a type t for word w and a semanticrelation r when (1) r is produced by a rule basedon t and (2) r is dependent on no other candidatetype for w. In Fig.
2, a dependency relation is in-stalled from A to C, because (1) LIVING-ENTITYin engine-2a was used in the rule assigning agentbetween ignite-3a and engine-2a and (2) the as-signment of agent is not dependent on DEVICE,the other candidate type of engine-2a.Mutual dependency.
If multiple interpreta-tions depend on one another, a mutual dependencyset is created to include them.5.3 PG MergerThe PG Merger implements Algorithm 1 to com-bine PG representations.
The PG representationFigure 4: Syntactic PG representation for S1, cap-turing the PP-attachment ambiguity of ?with itsspark plug?.Original Text Hearts pump blood through the body.Blood carries oxygen to organs throughout the body.Blood leaves the heart, then goes to the lungs whereit is oxygenated.
The oxygen given to the blood by thelungs is then burned by organs throughout the body.Eventually the blood returns to the heart, depleted ofoxygen.Paraphrase The heart begins to pump blood into thebody.
The blood first travels to the lungs, where itpicks up oxygen.
The blood will then be depositedinto the organs, which burn the oxygen.
The bloodwill then return to the heart, where it will be lackingoxygen, and start over again.Figure 5: The original text and a paraphrasefor each sentence is merged with the cumulativePG from previous sentences.
The global PG repre-sentation integrates sentence-level PG representa-tions to the extent that they align semantically.
Inthe worst case (completely unrelated sentences),the global PG representation would simply be theunion of individual PG representations.
The ex-tent to which the global PG is more coherent re-flects redundancy and semantic overlap in the sen-tences.6 Experiment 1We first wanted to evaluate our hypothesis thatAlgorithm 1 can improve interpretation accuracyover multiple redundant texts.
We manuallygenerated ten redundant texts by having volun-teers rewrite a short, tutorial text, using AmazonTurk (http://mturk.com) 2 The volunteers had noknowledge of the purpose of the task, and wereasked to rewrite the text using ?different?
lan-guage.
Fig.
5 shows the original text and one vol-unteer?s rewrite.
The total number of sentencesover the ten texts was 37.
Average sentence lengthwas 14.5 words.6.1 Evaluation ProcedureWe ran two systems over the ten texts.
The base-line system commits to the highest scoring consis-tent interpretation after each sentence.
The pro-totype system produces an ambiguity-preserving2We ultimately envision a system whose task is to developa model of a particular topic by interpreting multiple texts.Such a system might be given a cluster of documents or useits own information retrieval to find similar documents givena tutorial text.5850 10 20 30 400.650.70.750.80.850.9number of sentencescorrectness(%)type triples0 10 20 30 400.650.70.750.80.850.9content triples0 10 20 30 400.650.70.750.80.850.9all triplesprototypebaselineFigure 6: Correctness scores for the prototype vs. baseline system on (a) type triples (word sense assignment), (b) contenttriples (semantic relations) and (c) all triples (with standard deviation).PG representation.
For each sentence, the proto-type?s PG Merger merges the PG of the sentencewith the merged PG of the previous sentences.
Af-ter N sentences (varying N from 1..37), the systemis forced to commit to the highest scoring con-sistent interpretation in the merged PG.
For N=1(commit after the first sentence), both the base-line and prototype produce the same result.
ForN=2, the baseline produces the union of the high-est scoring interpretations for each of the first twosentences.
The prototype produces a merged PGfor the first two sentences and then prunes to thehighest scoring alternatives.At each value of N, we measured the cor-rectness of the interpretations (the percentageof correct semantic triples) for each system bycomparing the committed triples against human-generated gold standard triples.We repeated the experiment ten times with dif-ferent random orderings of the 37 sentences, aver-aging the results.6.2 Evaluation resultFig.
6 shows that both type assignment and se-mantic relation assignment by the prototype im-prove as the system reads more sentences.
Thisresult confirms our hypothesis that delaying com-mitment to an interpretation resolves ambiguitiesbetter by avoiding overly aggressive pruning.To determine an upper bound of correctness forthe prototype, we inspected the PG representa-tions to see how many alternative sets containedthe correct interpretation even if not the highestscoring alternative.
This number is different fromthe correctness score in Fig.
6, which is the per-baseline prototypenodes w/ the correct type 76 91edges w/ the correct relation 74 88Table 1: Percentage of nodes and edges containing the cor-rect types and semantic relations in the baseline and the pro-totype for all 37 sentences.centage of gold standard triples that are the high-est scoring alternatives in the merged PG.Table.
1 shows that 91% of the nodes in the PGcontain the correct type (though not necessarilythe highest scoring).
88% of the edges contain thecorrect semantic relations among the alternatives.In contrast, the baseline has pruned away 24% ofthe correct types and 26% of the correct semanticrelations.7 Experiment 2Our second experiment aims to evaluate the claimthat the prototype can efficiently manage a largenumber of alternative interpretations.
The top linein Fig.
7 shows the number of triples in the PGrepresentations input to the prototype.
This is thetotal number of triples (including ambiguous al-ternatives) in the PG for each sentence prior to in-voking Algorithm 1.
The middle line is the num-ber of triples remaining after merging and pruningby Algorithm 1.
The bottom line is the number oftriples after pruning all but the highest scoring al-ternatives (the baseline system).
The results showthat Algorithm 1 achieves significant compressionover unmerged PG representations.
The result-ing size of the merged PG representations moreclosely tracks the size of the aggressively pruned5860 5 10 15 20 25 30 35 40020040060080010001200bar: standard deviation5 times repeatedsentencesnumber of triplestriples in input PG representationstriples in the PG representation after mergingtriples in the baseline systemFigure 7: Total number of triples in individual sentence PGrepresentations (top); total number of triples in the PG rep-resentation after merging in the prototype system (middle);total number of triples after pruning to the highest scoringalternative (bottom).representations.8 Experiment 3Finally, we wanted to measure the sensitivity ofour approach to the quality of the natural languageinterpretation.
In this experiment, we artificiallyvaried the confidence scores for the correct inter-pretations in the PG representations input to theprototype and baseline systems by a fixed per-centage.
For example, consider a node heart-1with multiple candidate types, including the cor-rect sense for its context: INTERNAL-ORGANwith confidence 0.8.
We reran Experiment 1 vary-ing the confidence in INTERNAL-ORGAN in in-crements of +/-10%, while scaling the confidencesin the incorrect types equally.
As the confidencein correct interpretations is increased, all correctinterpretations become the highest scoring, so ag-gressive pruning is justified and the baseline per-formance approaches the prototype performance.As the confidences in correct interpretations aredecreased, they are more likely to be pruned byboth systems.Fig.
8 shows that Algorithm 1 is able to recoverat least some correct interpretations even whentheir original scores (relative to incorrect alterna-tives) is quite low.9 Discussion and Future WorkOur controlled experiments suggest that it is bothdesirable and feasible to delay ambiguity resolu-bar: standard deviation5 times repeated0.4 0.5 0.6 0.7 0.8 0.90.40.50.60.70.80.9the quality of the triples in the baseline system(%)thequalityof thetriplesintheprototypesystem(%)prototypebaselineFigure 8: Sensitivity of the prototype and baseline systemsto the quality of the NL system output.
The quality of in-put triples is perturbed affecting performance accuracy of thetwo systems.
For example, when the quality of input triplesis such that the baseline system performs at 70% accuracy,the prototype system performs at 80%.
The arrow indicatesunperturbed language interpreter performance.tion beyond sentence and text boundaries.
Im-provements in the correctness of semantic inter-pretation of sentences is possible without an ex-plosion in size when maintaining multiple inter-pretations.Nevertheless, these experiments are proofs ofconcept.
The results confirm that it is worthwhileto subject our prototype to a more real-world,practical application.
To do so, we need to addressseveral issues.First, we manually simulated structural (parse)ambiguities.
We will complete modifications tothe Stanford Parser to produce PG representationsnatively.
This change will result in a significantincrease in the number of alternatives stored inthe PG representation over the current prototype.Our initial investigations suggest that there is stillenough structural overlap among the candidateparse trees to allow the PG representation to con-trol explosion, but this is an empirical questionthat will need to be confirmed.We are modifying our semantic interpreter toadmit induced semantic interpretation rules whichwill allow us to train the system in new domains.The current prototype uses a naive heuristic foridentifying co-reference candidates.
We are inves-tigating the use of off-the-shelf co-reference sys-tems.Finally, we are incorporating theAlchemy (Richardson and Domingos, 2006)587probabilistic inference engine to calculate theprobability that a candidate interpretation iscorrect given the PG constraints and alignments,in order to inform confirmation or pruning ofinterpretations.Once these updates are complete, we will per-form more wide-scale evaluations.
We will inves-tigate the automatic construction of a test corpususing text clustering to find redundant texts, andwe will conduct experiments in multiple domains.10 Related WorkSuccinctly representing multiple interpretationshas been explored by several researchers.
Thepacked representation (Maxwell III and Kaplan,1981; Crouch, 2005) uses logical formulae to de-note alternative interpretations and treats the dis-ambiguation task as the propositional satisfiabil-ity problem.
Core Language Engine (Alshawi,1992) introduces two types of packing mecha-nism.
First, a quasi logical form allows the under-specification of several types of information, suchas anaphoric references, ellipsis and semantic re-lations (Alshawi and Crouch, 1992).
Second, apacked quasi logical form (Alshawi, 1992) com-pactly represents the derivations of alternativequasi logical forms.
In contrast, the PG repre-sentation is (1) based on a graphical representa-tion, (2) explicitly represents constraints and (3)includes confidence scores.These representations and the PG represen-tation have one feature in common: they rep-resent a set of complete alternative interpreta-tions of a text.
Another class of compact repre-sentations, called ?underspecification?, has beenstudied as a formal representation of ambigu-ous sentences.
These representations includeHole Semantics (Bos, 2004), Underspecified Dis-course Representation Semantics (Reyle, 1995),Minimal Recursion Semantics (Copestake et al,2005) and Dominance Constraints (Egg et al,2001).
These representations, rather than packingfully-represented candidate interpretations, spec-ify fragments of interpretations which are un-ambiguously interpreted, along with constraintson their combination (corresponding to differentinterpretations).
They generally focus on spe-cific ambiguities such as scope ambiguity (Bos,2004) (Egg et al, 2001) (Copestake et al, 2005)or discourse relations (Schilder, 1998) (Regneri etal., 2008).Disambiguating compact representations hasreceived relatively less attention.
(Riezler et al,2002; Geman and Johnson, 2002) use a packedrepresentation to train parsers on a corpus anduses the learned statistics to disambiguate packedrepresentations.
(Clark and Harrison, 2010) usesparaphrase databases and a hand-built knowledgebase to resolve underspecified representations.Different architectures have been proposed toimprove the pipeline architecture.
(Sutton andMcCallum, 2005; Wellner et al, 2004) maintaina beam of n best interpretations in the pipelinearchitecture.
Their pipeline, however, consists ofonly two components.
(Finkel et al, 2006) usessampling over the distribution of alternative inter-pretations at each stage of the pipeline and thenpasses the sampled data to the next component.The packed representation (Crouch, 2005) andCLE (Alshawi, 1992) use packed representation inthe pipeline, though both, at some stages, unpackthem and re-pack the processed result.
(Crouchand King, 2006) later proposes a new method thatdoes not require unpacking and then repacking.11 ConclusionWe have begun to address the challenge of effi-ciently managing multiple alternative interpreta-tions of text.
We have presented (1) a packedgraphical representation that succinctly repre-sents multiple alternative interpretations as well asthe constraints among them, and (2) an algorithmfor combining multiple PG representations to re-inforce correct interpretations and discount im-plausible interpretations.
Controlled experimentsshow that it is possible to improve the correctnessof semantic interpretations of text by delaying dis-ambiguation, without incurring the cost of an ex-ponentially expanding representation.12 AcknowledgementSupport for this research was provided in part byAir Force Contract FA8750-09-C-0172 under theDARPA Machine Reading Program588ReferencesAlshawi, Hiyan and Richard S. Crouch.
1992.
Mono-tonic semantic interpretation.
In ACL, pages 32?39.Alshawi, Hiyan, editor.
1992.
The Core LanguageEngine.
MIT Press, Cambridge, Massachusetts.Barker, Ken, Bruce Porter, and Peter Clark.
2001.
Alibrary of generic concepts for composing knowl-edge bases.
In Proceedings of the international con-ference on Knowledge capture, pages 14?21.Bos, Johan.
2004.
Computational semantics in dis-course: Underspecification, resolution, and infer-ence.
Journal of Logic, Language, and Information,13(2):139?157.Clark, Peter and Phil Harrison.
2010.
Exploiting para-phrases and deferred sense commitment to interpretquestions more reliably.
In To appear in Proceed-ings of CoLing 2010.Copestake, Ann, Dan Flickinger, Carl Pollard, andIvan Sag.
2005.
Minimal recursion semantics: anintroduction.
Research on Language and Computa-tion, 3:281?332.Crouch, Richard S. and Tracy Holloway King.
2006.Semantics via f-struecture rewriting.
In Proceed-ings of LFG06 Conference.Crouch, Dick.
2005.
Packed rewriting for mapping se-mantics to kr.
In In Proceedings Sixth InternationalWorkshop on Computational Semantics.Egg, Markus, Alexander Koller, and Joachim Niehren.2001.
The constraint language for lambda struc-tures.
Journal of Logic, Language, and InformationVol 10 (4), 2001, pp.457-485, 10:457?485.Finkel, Jenny Rose, Christopher D. Manning, and An-drew Y. Ng.
2006.
Solving the problem of cas-cading errors: approximate bayesian inference forlinguistic annotation pipelines.
In EMNLP, pages618?626, Morristown, NJ, USA.Geman, Stuart and Mark Johnson.
2002.
Dynamicprogramming for parsing and estimation of stochas-tic unification-based grammars.
In ACL, pages 279?286.Klein, Dan and Christopher D. Manning.
2003.
Accu-rate unlexicalized parsing.
In ACL, pages 423?430,Morristown, NJ, USA.Lesk, Michael.
1986.
Automatic sense disambigua-tion using machine readable dictionaries: how totell a pine cone from an ice cream cone.
In SIG-DOC ?86: Proceedings of the 5th annual interna-tional conference on Systems documentation, pages24?26, New York, NY, USA.Maxwell III, John T. and Ronald M. Kaplan.
1981.A method for disjunctive constraint satisfaction.
InTomita, Masaru, editor, Current Issues in Pars-ing Technology, pages 173?190.
Kluwer AcademicPublishers, Dordrecht.Patwardhan, Siddharth, Satanjeev Banerjee, and TedPedersen.
2005.
Senserelate:: Targetword-A gen-eralized framework for word sense disambiguation.In ACL.Pearl, Judea.
1988.
Probabilistic Reasoning in In-telligent Systems: Networks of Plausible Inference.Morgan-Kaufmann.Punyakanok, Vasin, Dan Roth, and Wen tau Yih.
2005.The necessity of syntactic parsing for semantic rolelabeling.
In Kaelbling, Leslie Pack and AlessandroSaffiotti, editors, IJCAI, pages 1117?1123.
Profes-sional Book Center.Regneri, Michaela, Markus Egg, and AlexanderKoller.
2008.
Efficient processing of underspecifieddiscourse representations.
In HLT, pages 245?248,Morristown, NJ, USA.Reyle, Uwe.
1995.
Underspecified discourse repre-sentation structures and their logic.
Logic Journalof the IGPL, 3(2-3):473?488.Richardson, Matthew and Pedro Domingos.
2006.Markov logic networks.
Kluwer Academic Publish-ers.Riezler, Stefan, Tracy H. King, Ronald M. Kaplan,Richard S. Crouch, John T. Maxwell III, and MarkJohnson.
2002.
Parsing the wall street journal us-ing a lexical-functional grammar and discriminativeestimation techniques.
In ACL, pages 271?278.Schilder, Frank.
1998.
An underspecified seg-mented discourse representation theory (USDRT).In COLING-ACL, pages 1188?1192.Sutton, Charles and Andrew McCallum.
2005.
Jointparsing and semantic role labeling.
In CONLL,pages 225?228, Morristown, NJ, USA.Wellner, Ben, Andrew McCallum, Fuchun Peng, andMichael Hay.
2004.
An integrated, conditionalmodel of information extraction and coreferencewith application to citation matching.
In UAI, pages593?601, Arlington, Virginia, United States.589
