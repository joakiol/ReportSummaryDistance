Lexica\] Selection in the Process of Language Generation3ames  Puste jovskyDepartment of Computer ScienceBrandeis UniversityWaltham, MA 02254617-736-2709j amespQ brandeis.caner -relaySerge i  N i renburgComputer Science DepartmentCarnegie-Mellon UniversityPittsburgh, PA. 15213412-268-3823sergeiQcad.cs.cmu.eduAbstractIn this paper we argue that lexical selection plays a moreimportant role in the generation process than has com-monly been assumed.
To stress the importance of lexical-semantic input to generation, we explore the distinctionand treatment of generating open and closed cla~s lexicalitems, and suggest an additional classification of the lat-ter into discourse-oriented and proposition-oriented items.Finally, we discuss how lexical selection is influenced bythematic (\[oc~) information in the input.I .
In t roduct ionThere is a consensus among computational linguiststhat a comprehensive analyzer for natural language musthave the capability for robust lexical d isambiguat ion,i.e., its central task is to select appropriate meanings oflexical items in the input and come up with a non contra-dictory, unambiguous representation f both the proposi-tional and the non-propositional meaning of the input text.The task of a natural anguage generator is, in some sense,the opposite task of rendering an unambiguous meaningin a natural language.
The main task here is to to per-form principled selection of a) lexical items and b) thesyntactic structure for input constituents, based on lexicalsemantic, pragmatic and discourse clues available in theinput.
In this paper we will discuss the problem of lexlcalselection.The problem of selecting lexical items in the pro-cess of natural language generation has not received asmuch attention as the problems associated with express-ing explicit grammatical knowledge and control.
In mostof the generation systems, lexical selection could not bea primary concern due to the overwhelming complexityof the generation problem itself.
Thus, MUMBLE con-centrates on gr:~mmar-intensive control decisions (McDon-ald and Pustejovsky, 1985a) and some stylistic considera-tions (McDonald and Pustejovsk'y, 1985b); TEXT (McKe-own, 1985) stresses the strategical level of control decisionsabout the overall textual shape of the generation output.~KAMP (Appelt, 1985) emphasizes the role that dynamicplanning plays in controlling the process of generation,and specifically, of referring expressions; N IGEL  (Mannand Matthiessen, 1983) derives its control structures fromthe choice systems of systemic grammar, concentrating ongrammatical knowledge without fully realizing the 'deli-cate' choices between elements of what systemicists callleto's (e.g., HaLiiday, 1961).
Thus, the survey in Cummlng(1986) deals predominantly with the grammatical spectsof the lexicon.We discuss here the problem of lexical selection andexplore the types of control knowledge that are neces-sary for it.
In particular, we propose different controlstrategies and epistemological foundations for the selec-tion of members of a) open-class and b) closed-class lex-ical items.
One of the most important aspects of controlknowledge our generator employs for lexical selection is thenon-propositional information (including knowledge aboutfocus and discourse cohesion markers).
Our generationsystem incorporates the discourse and textual knowledgeprovided by TEXT as well as the power of MUMBLE'sgrammatical constraints and adds principled lexical selec-tion (based on a large semantic knowledge base) and acontrol structure capitalizing on the inherent flexibility ofdistributed architectures.
2 The specific innovations dis-cussed in this paper are:I Derr and McKeown, 1984 and McKeown, 1985, however,discuss thematic information, i e. focus, as a basis for the selec-tion of anaphoric pronouns.
This is a fruitful direction, and weattempt to extend it for treatment of additional discourse-basedphenomena.2 Rubinoff (1986) is one attempt st integrating the tex-tual component ofTEXT with the grammar of MUMBLE.
Thisinteresting idea leads to a significant improvement in the perfor-mance of sentence production.
Our approach differs from thiseffort in two important repsects.
First, in Rubinoff's ystem theoutput of TEXT serves as the input to MUMBLE, resulting ina cascaded process.
We propose a distributed control where theseparate knowledge sources contribute to the control when theycan, opportunistically.
Secondly, we view the generation processas the product of many more components han the number pro-posed in current generators.
For a detailed discussion of thesesee Nirenburg and Pu~tejovslry, in preparation.201I.
We attach importance to the question of what the inputto a generator should be, both as regards its content andits form; thus, we maintain that discourse and pragmaticinformation is absolutely essentiM in order for the genera-tor to be able to handle a large class of lexicM phenomena;we distinguish two sources of knowledge for lexicM selec-tion, one discourse and pragznatics-based, the other lexicMsemantic.2.
We argue that lexicM selection k not just a side ei~ect ofgrammatical decisions but rather ~ts to flexibly constrainconcurrent and later generation decisions of either lexicMor ~at icM type.For comparison, MUMBLE lexical selections are per-formed after some grammatical constraints have been usedto determine the surface syntactic structure; this type ofcontrol of the generation process does not seem optimalor su~icient for all generation tasks, although it may beappropriate for on-line generation models; ; we argue thatthe decision process is greatly enhanced by making lexicMchoices early on in the process.
Note that the above doesnot presuppose that the control structure for generation lsto be like cascaded transducers; in fact, the actual systemthat we are building based on these principles, features adistributed architecture that supports non-rigid decisionmaking (it follows that the lexical and grammatical deci-sions are not explicitly ordered with respect to each other).This architecture is discussed in detail in Nirenburg ~ndPustejovsky, in preparation.3.
We introduce an important distinction between open-class and closed-class lexical items in the way they are rep-resented as well as the way they are processed by our gen-erator; our computational, processing-oriented paradigmhas led us to develop a finer classification of the closed-class items than that tr~litionMly acknowledged in thepsycholinguistic literature; thus, we distinguish betweendiscourse oriented closed-class (DOCC) items and propo-sition oriented ones (POCC);4.
We upgrade the importance of knowledge about focusin the sentence to be generated so that it becomes one ofthe prime heuristics for controlling the entire generationprocess, including both lexical selection and grammaticalphrasing.5.
We suggest a comprehensive design for the concept lex-icon component used by the generator, which is perceivedas a combination of a gener'M-purpose semantic knowl-edge base describing a subject domain (a subworld) anda generation-specific lexicon (indexed by concepts in thisknowledge base) that consists of a large set of discrimi-nation nets with semantic and pragmatic tests on theirnodes.These discrimination nets are distinct from the choo-sers in NIGEL's choice systems, where grammatical knowl-edge is not systematically separated from the lexical se-mantic knowledge (for a discussion of problems inherentin this approach see McDonald, Vaughau and Pustejovsky,1986); the pragmatic nature of some of the tests, as wellms the fine level of detail of knowledge representation iswhat distinguishes our approach from previous conceptualgenerators, notably PHRED (Jscobs, 1985)).2.
Input  to  Generat ionAs in McKeown (1985,1986) the input to the pro-cess of generation i cludes information about the discoursewithin which the proposition is to be generated.
In our sys-tem the following static knowledge sources constitute theinput to generation:1.
A representation f the meaning of the text to be gener-ated, chunked into proposition-size modules, each of whichcarries its own set of contextual values; (cf.
TRANSLA-TOR, Nirenburg et al, 1986, 1987);2. the semantic knowledge base (concept lexicon) thatcontains information about the types of concepts (objects(mental, physical and perceptuM) and processes (statesand actions)) in the subject domain, represented with thehelp of the description module (DRL) of the TRANSLA-TOR knowledge representation language.
The organiza-tiona~ basis for the semantic knowledge base is an empir-ically derived set of inheritance networks (isa, m~ie-of,belongs-to, has-as-part, etc.).3.
The specific lexicon for generation, which takes the formof a set of discrimination ets, whose leaves are markedwith lex/cal units or lexicM gaps and whose non-leaf nodescontain discrimination criteria that for open-class items arederived from selectional restrictions, in the sense of Katzand Fodor (1963) or Chomsk'y (1965), as modified by theideas of preference semantics (Wilks, 1975, 1978).
Notethat most closed.class items have a special status in thisgeneration lexicon: the discrimination ets for them axeindexed not by concepts in the concept lexicon, but ratherby the types of values in certain (mostly, nonpropc~itional)slots in input frames;4.
The history of processing, structured Mong the lines ofthe episodic memory oWaa~zat~on suggested by Kolodner(1984) and including the feedback of the results of actuallexic~l choices during the generation of previous sentencesin a text.2023.
Lex ica l  C lassesThe distinction between the open- and closed-classlexical unite has proved an important one in psychologyand psycholinguistics.
The manner in which retrieval of el-ements from these two classes operates is taken as evidencefor a particular mental lexicon structure.
A recent pro-posal (Morrow, 1986) goes even further to explain some ofour discourse processing capabilities in term~ of the prop-erties of some closed-da~ lexicM items.
It is interestingthat for this end Morrow assumes, quite uncritically, thestandard division between closed- and open-cla~ lexicalcategories: 'Open-class categories include content words,such as nouns, verbs and adjectives... Closed-class cate-gories include function words, such as articles and prepo-sitions...' (op.
cir., p. 423).
We do not elaborate on thedefinition of the open-class lexical items.
We have, how-ever, found it useful to actually define a particular subsetof dosed-class items as being discourse-oriented, distinctfrom those closed-class items whose processing does notdepend on discourse knowledge.A more complete list of closed-class lexical itemswill include the following:?
determiners and demonstratives (a, the, thiJ, tl~t);?
quantifiers (most, e~ery, each, all o/);?
pronouns (he, her, its);?
deictic terms and indexicats (here, now, I, there);?
prepositions (on, during, against);.
paxentheticals and attitudinal~ (az a matter off act,o~ the contrary);?
conjunctions, including discontinuous ones (and, be.r .~e,  neither...nor);primary verbs (do, have, be);?
modal verbs (shall, might, aurar to);?
wh-words (toho, why, how);?
expletives (no, yes, maybe).We have concluded that the above is not a homoge-neous list; its members can be characterized on the basis ofwhat knowledge sources axe used to evaluate them in thegeneration process.
We have established two such distinctknowledge sources: purely propositional information andcontextual and discourse knowledge.
Those closed-classitems that are assigned a denotation only in the contextof an utterance will be termed discourse-oriented closedclass (DOCC) items; this includes determiners, pronouns,indexicals, and temporal prepositions.
Those contributingto the propositional content of the utterance will be calledproposition-oriented closed-class (POCC) items.
These in-clude modals, locative and function prepositions, and pri-mary verbs.According to this classification, the ~definiteneeseffect" (that is, whether a definite or an intefinite nounphrase is selected for generation) is distinct from generalquantification, which appears to be decided on the basisof propositional factors.
Note that prepositions no longerform a natural class of simple closed-class items.
For ex-ample, in (I) the preposition before unites two entities con-nected through a discourse marker.
In (2) the choice of thepreposition on is determined by information contained inthe propositional content of the sentence.
(I) John ate breakfast bet'ore leaving for work.
(2) John sat on the bed.We will now suggest a set of processing heuristics forthe lexical selection of a member from each lexical class.This classification entails that the lexicon for generationwill contain only open-cla~ lexical items, because the restof the lexical items do not have an independent epistemo-logical status, outside the context of an utterance.
Theselection of closed-class items, therefore, comes as a resultof the use of the various control heuristics that guide theprocess of generation.
In other words, they axe incorpo-rated in the procedural knowledge rather than the staticknowledge.4.0  Lex ica l  Se lec t ion4.1 Selection of Open-Class ItemsA significant problem in lexical selection of open-class items is how well the concept to be generated matchesthe desired lexical output.
In other words, the input togenerate in English the concept 'son's wife's mother' willfind no single lexical item covering the entire expression.
InRussian, however, this meaning is covered by a single word'swatja.'
This illustrates the general problem of lexlcalgaps and bears on the question of how strongly the con-ceptual representation is influenced by the native tongue ofthe knowledge-engineer.
The representation must be com-prehensive yet flexible enough to accommodate this kindof problem.
The processor, on the other hand, must beconstructed so that it can accommodate lexical gaps bybeing able to build the most appropriate phrase to insertin the slot for which no single lexical unit can be selected(perhaps, along the lines of McDonald and Pustejovsky,1985a).To illustrate the knowledge that bears upon thechoice of an open-class lexicM item, let us trace the processof lexicai selection of one of the words from the list: desk,table, dining table, coffee table, utility table.
Suppose, dur-ing a run of our generator we have already generated thefollowing p~.-tial sentence:(3) John bought a ......and the pending input is as partially shown in Figures 1-3.Figure I contains the instance of a concept to be generated.203(stol$4(instance-of 8tel)(coXor black)(size 8m~l)(height average)(:as.
auerafe)(a,~e-of ateel)(location-of #~t))F|~Lre I(stol( i .
,  furniture)(color black brown yellow white)(size amaJl average)(height lOW averGgs high)(was.
les~-than-avsmqe averaqe)(aade-of t~ood plastic steel)(Iocatlon-of e~t write sew work)(has-as-pert ( leg leg leg (leg) top)(topolol7 O| (top loS)))Figure 2Figure 2 contains the representation of the correspondingtype in the semantic knowledge base.
Figure 3 contains anexcerpt from the English generation lexicon, which is thediscrimination et for the concept in Figure 2.cuo location-of ofeat: cuo height oflow: co~ree tableavnrqe  : dining table~.te :  demksev: sewing tablesaw: workbenchotherwise: tableFigure 3In order to select the appropriate l xicalization thegenerator has to traverse the discrimination et, havingfirst found the answers to tests on its nodes in the repre-sentation of the concept oken (in Figure 1).
In addition,the latter representation is compared with the represen-tation of the concept type and if non-default values arefound in some slots, then the result of the generation willbe a noun phrase with the above noun as its he~l and anumber of ~ljectival modifiers.
Thus, in our example, thegenerator will produce 'bla~.k steel dining table'.4.2 Selection of  POCC I temsNow let us discuss the process of generating a propo-sition oriented lexical item.
The example we will use hereis that of the function preposition to.
The observ'4tionhere is that if to is a POCC item, the information requiredfor generating it should be contained within the proposi-tional content of the input representation; o contextualinformation should be necessary for the lexical decision.A~ume that we wish to generate sentence (1) where weaxe focussing on the selection of to.
(1) John walked to the store.If the input to the gener~tor is(walk(Actor John)(Location "hers')(Source U)(Goal stars23)(TL~o past2)( in tent ion  U)(Direction otare~3) )then the only information ecessary to generate the prepo-sition is the case role for the goal, 8tore.
Notice that achange in the lexicalization of this attribute would onlyarise with a different input to the generator.
Thus, if thegoal were unspecified, we might generate (2) instead of (1);but here the propositional content is different.
(2) John walked towards the store.In the complete paper we will discuss the generation of twoother DOCC items; namely, quantifiers and primary verbs,such as do and have.4.2 Selection of  DOCC I tems:?
Generat ing  a discourse anaphorSuppose we wish to generate an anaphoric pronounfor an NP in a discourse where its antecedent was men-tioned in a previous entence.
We illustrate this in Figure2.
Unlike open-cl~s items, pronominals axe not going tobe directly a~ociated with concepts in the semantic kn-woledge b~se.
Rather, they are generated as a result ofdecisions involving contextual knowledge, the beliefs of thespeaker and hearer, and previous utterances.
Suppose, wehave alre~ly generated (4) and the next sentence to begenerated a.l~o refers to the same individual and informsus that John was at his father's for two days.
(1) John, visited his father.
(2) He~ stayed for two days.Immediate/ocuz information, in the sense of Grosz (1979)interacts with a history of the previous sentence struc-tures to determine a strategy for selecting the appropriateanaphor.
Thus, selecting the appropriate pronoun is anattached procedure.
The heuristic for discourse-directedpronomin~ization is as follows:204IF: (I) the input for the generation of a sentenceincludes an instance of an object present in a recentinput; and(2) the the previous instance of this object (the po-tential antecedent} is in the topic position; and(3) there are few intervening potential antecedents;and(4} there is no focus shift in the space between theoccurrence of the antecedent and the current objectinstanceTHEN: realize the current instance of that object as a pro-noun; consult the grammatical knowledge source forthe proper gender, number and case form of the pro-noun.In McDonald and Pustejovsky (1985b) a heursiticwas given for deciding when to generate a full NP  andwhen a pronoun.
This decision was fully integrated intothe grammatical decisions made by MUMBLE in terms ofrealization-classes, and was no different from the decisionto make a sentence active or passive.
Here, we are separat.ing discourse information from linguistic knowledge.
Oursystem is closer to McKeown's (1985, 1986) TEXT system,where discourse information acts to constrain the controlregimen for Linguistic generation.
We extend McKeown'sidea, however, in that we view the process of lexical selec-tion as a constraining factor i~ geruera/.
In the completepaper, we illustrate how this works with other discourseoriented dosed-class items.5.
The  Ro le  o f  Focus  in  Lex ica l  Se lec t ionAs witnessed in the previous section, focus is an im-portant factor in the generation of discourse anaphors.
Inthis section we demonstrate that focus plays an importantrole in selecting non-discourse items as well.
Suppose yourgenerator has to describe a financial transaction as a resultof which(I) Bill is the owner of a car that previously belongedto John, and(2) John is richer by $2,000.Assuming your generator is capable of representing the~at ica l  structure of the resulting-English sentence,it still faces an important decision of how to express lexi-cally the actual transaction relation.
Its choice is to eitheruse buy or 8ell as the main predicate, leading to either (I)or (2), or to use a non-perspective phrasing where neitherverb is used.
(1) Bill bought a car from John for $2,000.
(2) John sold a car to Bill for $2,000.We distinguish the following major contributing factors forselecting one verb over the other;, (I) the intended perspec-tive of the situation, (2) the emphasis of one activity ratherthan another, (3) the focus being on a particular individ-ual, and (4) previous lexicalizations of the concept.These observations are captured by allowing/ocu8to operate over several expression including event-typessuch as tra~/sr.
Thus, the variables at pIw for focus in-dude:?
end-of-transfer,?
beginning-of-transfer,?
activity-of- transfer,?
goal-of-object,?
source-of-object,?
goal-of-money,?
source-of-money.That is, lexical/zation depends on which expressions are infocus.
For example, if John is the immediate focus (as inMcKeown (1985)) and beginning-of-transfer is the current-focus, the generator will lexicalize from the perspective ofthe sell/ng, namely (2).
Given a different focus configura-tion in the input to the generator, the selection would bedifferent and another verb would be generated.6.
Conc lus ionIn this paper we have argued that lexJcal selectionis an important contributing factor to the process of gen-eration, and not just a side effect of grammatical deci-s/ons.
Furthermore, we claim that open-class items arenot only conceptually different from closed-class items, butare processed ifferently as well.
Closed class items haveno epistemological status other than procedural attach-ments to conceptual and discourse information.
Related tothis, we discovered an interesting distinction between twotypes of closed-class items, distinguished by the knowledgesources necessary to generate them; discourse oriented andproposition-oriented.
Finally, we extend the importance offocus information for directing the generation process.205References\[1\] Appelt, Dougla~ Planning Enqlish Sentences, Cam.bridge U. Press.\[2\] Chomsky, Noam A~pec~ on tM.
Theo~ o!
$ynt~MIT Press.\[3\] Cumming, Susanna, "A Guide to Lexical Acquisi-tion in the JANUS System" ISI Research ReportISI/RR-85-162, Information Sciences Institute, Ma-rina del Rey, California~ 1986a.\[4\] Cvmming, Stumana, "The Distribution of I.,exic.MInformation i Text Generation', presented for Work-shop on Automating the Lexicon, Pisa~ 1986b.\[5\] Den', K. and K. McKeown "Focus in Generation,COLING 1984\[6\] Dowty, David R., Word Meaning and MontagueGrammar, D. Reidel, Dordrecht, Holland, 1979.\[7\] Hall/day, M.A.K.
~Options and functions in the En-gl~h clause m. Brno Studies in Enfli~h 8, 82-88.\[8\] Jacobs, Paul S., "PHRED: A Generator for Nat-ural Language Interface', Computational Linguis-tics, Volume 11, Number 4, 1085.\[9\] Katz, Jerrold and Jerry A. Fodor, "The Structure ofa Semantic Theory', Language Vol 39, pp.170-210,1963.\[10\] Mann, William and Matthiessen, "NIGEL: a Sys-temic Grammar for Text Generation', in Freddle(ed.
), Systemic Perspectives on Discoerae, Ablex.\[11\] McDonald, David and James Pustejovsky, "Descrip-tion directed Natural Language Generation" Pro-ceedings of IJCAI-85.
Kaufmann.\[12\] McDonald, David and James Pustejovsky, "A Com-putational Theory of Prose Style for Natural Lan-guage Generation, Proceedings ofthe European ACL,University of Geneva, 1985.\[13\] McKeown, Kathy Tez~ Generatio,~ Cambridge Uni-versity Press.\[14\] McKeown, Kathy, "Stratagies and Constraints forGenerating Natural Language Text ~, in Bolc andMcDonald, 1087.\[151 Morrow "The Processing of Closed Class LexicalItems', in Cognitive Science 10.4, 1986.\[161 Nirenburg, Sergei, Victor Raskin, and Allen Tucker,"The Structure of Interlingua in TRANSLATOR",in Nirenburg (ed.)
Machine Translation: Theoret-ical ~nd Afeth~dolofical ls~ttes, Cambridge Univer-sity Pres~.
1987.\[17\] Wilks, Yorick "Preference Semantics, ~ Artificial In-telligence, 1975.206
