Pseudo Relevance Feedback Method Based on Taylor Expansion of Re-trieval Function in NTCIR-3 Patent Retrieval TaskKazuaki KISHIDAFaculty of Cultural Information ResourcesSurugadai University698 Azu, Hanno, Saitama 357-8555 JAPANkishida@surugadai.ac.jpAbstractPseudo relevance feedback is empiricallyknown as a useful method for enhancingretrieval performance.
For example, wecan apply the Rocchio method, which iswell-known relevance feedback method,to the results of an initial search by as-suming that the top-ranked documents arerelevant.
In this paper, for searching theNTCIR-3 patent test collection throughpseudo feedback, we employ two rele-vance feedback mechanism; (1) the Roc-chio method, and (2) a new method that isbased on Taylor formula of linear searchfunctions.
The test collection consists ofnear 700,000 records including full text ofJapanese patent materials.
Unfortunately,effectiveness of our pseudo feedbackmethods was not empirically observed atall in the experiment.1 IntroductionRelevance feedback is widely recognized as aneffective method for improving retrieval effective-ness in the context of interactive IR.
As oftenpointed out, it is difficult for users to representtheir own information needs into a well-defined setof search terms or statements.
The resulting shortor poor queries would bring them unsatisfactoryresults.
However, if a few relevant documents hap-pen to be found by the search, we could automati-cally or manually extract some useful terms fromthe documents, and add them to the initial searchexpression.
It is obviously expected that searcheffectiveness of the second search using the ex-tended query will be improved significantly.
Thisis a basic idea of relevance feedback.Inevitably, for executing automatic relevancefeedback, the system has to obtain relevance in-formation, i.e., relevant or irrelevant documents,from the users interactively.
However, some re-searchers have tried to employ relevance feedbacktechniques with no relevance information.
The ob-jective is to enhance search performance of re-trieval models such as vector space model,probabilistic model and so on, without interactionon relevance information between system and us-ers.
The technique is usually called pseudo rele-vance feedback, in which a standard feedbackmethod (e.g., the Rocchio method) is applied byassuming that top-ranked documents searched bythe initial search are relevant.The purpose of this paper is to report results ofretrieval experiments for examining effectivenessof pseudo relevance feedback in the case of search-ing a patent collection.
In particular, we attempt tocompare search performance of the traditionalRocchio method with that of an alternative method,which is based on Taylor approximation of re-trieval function proposed by Kishida[1].
This re-port is based on two experiments using theNTCIR-1 test collection and the NTCIR-3 patenttest collection, respectively.
As to the latter, theresults were obtained at the time of NTCIR-3Workshop held in October 2002 [2].The rest of this paper is organized as follows.
InSection 2, the Rocchio method and an alternativemethod proposed by Kishida[1] will be introduced.In Section 3 a preliminary experiment for confirm-ing how well the alternative method works in anormal relevance feedback situation will be de-scribed.
The NTCIR-1 test collection with rele-vance judgment information is used for thepreliminary experiment.
In Section 4, results of anexperiment on pseudo relevance feedback methodusing the NTCIR-3 patent test collection will beshown.22.1Relevance Feedback MethodsRocchio MethodThe most typical approach to relevance feedbackwould be so-called the Rocchio method [3].
A ba-sic idea of the method is to add an average weightof each term within a set of relevant documents tothe original query vector, and to subtract an aver-age weight within a set of irrelevant ones from thevector.We denote a document vector and a query vec-tor by d  and q , whereis a weight of a term within a document andis a weight of a term within the query (i i iMTw w= ( ,..., )1 = ( ,..., )w wq qM T1wij wqjM  is thetotal number of distinct terms in the database, andT  indicates transposition).A modified query vector is obtained by a for-mula,????
?+=DdiiDdiiii DD ::~ ddqq ???
,                           (1)where D  is the set of relevant documents, D  is theset of irrelevant documents, and ?
?
?
?and ?are constants.It has been empirically shown that the perform-ance of the Rocchio method is very good [4], andin recent, many researchers have examined themethod directly or indirectly [5-8].
Also, due to itseffectiveness and simplicity, the Rocchio methodhas been widely applied in other research areas, forexample, image retrieval [0] or text categorization[10].2.2 Feedback Method Using Taylor Formulaof Retrieval FunctionKishida[1] has proposed an alternative relevancefeedback method, which is suitable for the situa-tion that the degree of relevance is given as a nu-merical value, not dichotomous value (i.e.,relevance or not), from actual users.
In this section,according to Kishida[1], the method will be ex-plained.In vector space model [10], typical formulas fordetermining term weights are as follows:w xij ij= +log .10                                                 (2)( )w x Nqj qj j= +(log . )
log10 n                              (3)wherexij : frequency of a term  in a document , t j dixqj : frequency of a term t  in the query, jn j  : the number of documents including t , jN  : the total number of documents in the data-base.For calculating the degree of similarity betweena document vector d  and the query vector q , acosine formula is normally used:is w w wi ij qjjMij qjjMjM= = =?
?1 2 11 w=?
2                      (4)where  is a numerical score indicating similarityof the document given a query vector.siOn the other hand, a well-known formula basedon probabilistic model derived from an assumptionof two-Poisson distribution [12] is?
= ???
?++=Mjijiiji xllxs1 )5.15.0(0.3????++??
?5.05.0logjjqj nnNx(5)wherel xi ijM= =?
1 j , and l N , liiN= ?
=?1 1i.e., the former is a document length, and the latteris an average of the length over documents withinthe database.
The formula (5) is a version of so-called Okapi weighting [12] under a particular set-ting of its parameters.We can represent concisely the two importantretrieval models as a linear function of vector,s b Ab= =f ( ) ,                                               (6)where  is a s N  dimensional vector of documentscores, s ,  is a linear function of vec-tor ( ), and= ( , )sN T1M N?...,sR?1f1f R: ?
A  is a N M?
matrix ofwhich each element is?
= ++= Mj ijijij xxa 1 2)0.1(log)0.1(log ,           (7)in the case of vector space model (see (2) and (4)),orijiijij xllxa ++= )5.15.0(0.3                                     (8)in the case of the Okapi formula (see (5)).Also,  is a b M  dimensional vector of whicheach element is defined asb w wj qj qjM= =?
21 j                                          (9)where (w x Nqj qj j= +(log . )
log10 )n  in the case ofvector space model (see (3)), orAn approach to estimating ~b  is to pay our at-tention to a difference between initial scoreand secondary scoref X ( )bf X (~)b , and to apply so-calledTaylor approximation for obtaining a vector func-tion f X (~)b , i.e.,b xN nnj qjjj= ?
++log..0 50 5(10)in the case of the Okapi formula (see (5)).The most important thing is that both of twowell-known formulas for estimating scores to rankdocuments are able to be represented by a simpleform (6).
f ff KX X X T(~) ( ) ( ) (~ )b b bbb b= + ?
+?
?,               (13)For making ranked output, documents have tobe sorted in the decreasing order of scores, s( iiN= 1,..., ).
This means that each score is assumedto indicate the degree of relevance.
In other words,the score is expected to be an estimate of ?true?degree of relevance .
riwhere K  is a residual term (see [13]).
If we em-ploy (11) and assume thatrX  = , )~(bXfaccording to a target condition (12), we can obtainthat~ (b b A r s= + ?
?X X X1 ) ,                                     (14)Let be a vector representing ?true?relevance degrees.
By using this notation, we candescribe operationally a purpose of retrieval sys-tem as ?to estimate a vector s  that is the closest tovector r  when a search request is given.
?r = ( ,..., )r rN T1 (see Appendix for detail calculation).
It should benoted that 0=K  due to the linearity of Equation(11).
This means (14) is not an approximation butan exact relation.The Equation (14) contains an abnormal inversematrix , which is an A X?1 M n?
matrix andwhere  is aA AX X?
=1 I M I M M M?
matrix of whichall diagonal elements are 1 and others are 0.
Usingsingular value decomposition (SVD), transposematrix of  can be represented as A XOf course, r  is unknown in real situations, butit is possible to obtain information on a part of rthrough the process of relevance feedback.
For ex-ample, if a user replies a set of scores indicatingthe degrees of relevance for top-ranked n  docu-ments searched by the initial query, the scores al-low us to estimate the part of r  corresponding tothe n  documentsA U VXT T= ?
,whereU : an M n?
orthogonal matrix, We denote a set of the top-ranked n  documentsby X  and the part of r  corresponding to the set Xby , which is actually n  dimensional vector re-constructed by extracting n  elements of the docu-ments from the original vector r .
According to (6),we can write thatrX?
: an n n?
diagonal matrix, andV : an n n?
orthogonal matrix.By employing the decomposition, we can finallyrepresent (14) such as~ (b b U V r s= + ???
1 T X X )33.1(15)(see Appendix for details).
This is a final formulaof our relevance feedback algorithm.
For conven-ience, we call the algorithm ?the Taylor formulabased method?
in this paper.s b AX X Xf= =( ) b ,                                       (11)whereA X : an n M?
matrix,s X : an n  dimensional vector,  andf R RXM n: ?
?
?1 1 .
Preliminary Experiment with RelevanceInformation Both of the matrix and the vector are constructedby the same way with .
rXIf we establish a distance measure ?
betweenand s , the objective of relevance feedback canbe formally described as follows: the relevancefeedback aims at estimating a modified query vec-tor such thatrX XPurpose and Test DataBefore applying pseudo relevance feedbackbased on the Equation (15) to the patent test collec-tion, we try checking retrieval performance of theTaylor formula based method by using other testcollection with relevance judgment information.To do this, we employ a well-known Japanese TestCollection NTCIR-1 (NII/NACSIS Test Collection~ arg min ( , )b rb= ?
X Xs = arg min ( , ( ))br b?
X Xf .
(12)Then we can use ~b  for the secondary search.for Information Retrieval - 1)1, which consists ofabout 330,000 bibliographic records of proceed-ings at conferences held in Japan.
It should benoted that, in the preliminary experiment, rele-vance judgment information was used (i.e., notpseudo feedback).- In the case of runs based on the Taylorformula, TYLVEC and TYLPRB, thelinear function (6) was used for matchingoperation.Fifty-three topics of NTCIR-1 were employedfor the experiment (from No.31 to No.83).
Theformat of these topics is also very similar with thatof TREC, i.e., a record of each topic consists offields of <title>, <description>, <narrative> and soon.
For realistic situation in which feedback meth-ods are used, it would be more reasonable to as-sume that original search statements are short.Thus we employed only <title> and <description>fields for representing each topic.
This means thata kind of ?short query?
was used for the experiment.3.2 Procedure and type of runsProcedure of the preliminary experiment is as fol-lows:(a) Initial search: two initial search runs were car-ried out, i.e., the first is based on vector spacemodel from (2) to (4) and the second isprobabilistic model (5).
We denote the initialsearch runs as ORGVEC and ORGPRB, re-spectively.
(b) Query modification through relevance feed-back: initial queries were modified by usingrelevance judgment information on top-rankeddocuments of each initial run.
In this paper,we set 10 and 20 as the value of n ,n- In the case of vector space model, we canattempt two modification methods, i.e.,the Rocchio method (1) (where ?
= 8 ,?
= 16 and?
= 4 ) and the Taylor formulabased method (7), (9) and (15).
The runusing the Rocchio method is denoted asROCCHI, and the run by the Taylor for-mula based method as TYLVEC.- In the case of probabilistic model, onlythe Taylor formula based method wasapplied using (8), (10) and (15).
We de-note this run as TYLPRB.
(c) Secondary search: each modified query wasused for second run- In the case of ROCCHI, modified querieswere matched with document vectors bycosine formula (4).3.3 Conversion of binary judgment into con-tinuous valueOne of the advantages of the Taylor formula basedmethod (15) is to allow us for making use of con-tinuous values representing the degree to whicheach document is relevant.
Unfortunately, in theexperiment, such values were not available be-cause only results of binary judgments are offi-cially provided as relevance information.Therefore, in order to testify the Taylor formulabased method, we need to develop a special algo-rithm for converting each binary judgment to acontinuous score.
An easy way for converting avalue of binary judgment into a continuous degreeof relevance is to predict the degree from a docu-ment score in initial search by using a simpleregression, r As Bi i= + .It would be straightforward that the constants Aand B  are determined based on maximum andminimum values of s  and  for relevant and ir-relevant documents independently.
That is, we usea set of eight values for parameter estimation asfollows.i ri- s  and s : maximum and minimum values offor ?relevant?
documents in top-ranked ndocuments,max1si1min- s  and s : maximum and minimum values offor ?irrelevant?
documents in top-ranked ndocuments,max0simin0- r  and r : maximum and minimum values offor ?relevant?
documents in top-ranked ndocuments,max1rimin1-  r  and r : maximum and minimum valuesof  for ?irrelevant?
documents in top-rankeddocuments.max0rinmin0For the set of relevant documents, we can ob-tain estimates of A  and B  by solving equations,r Asr Asmax maxmin min1 11 1= += +??
?BB)It is easy to show thatA r r s s= ?
?
( ) / (max min max min1 1 1 1  andB s r r s s s= ?
?
( ) (max min max min max min1 1 1 1 1 1 ) .1 http://research.nii.ac.jp/ntcir/Similarly, for the set of irrelevant documents,we obtain thatA r r s s= ?
?
( ) / (max min max min0 0 0 0 )  andB s r r s s s= ?
?
( ) (max min max min max min0 0 0 0 0 0 )3.43.544.1.Furthermore, we have to determine a priori val-ues of r , r , r  and r , max1 min1 max0 min0(a) For vector space model, it is reasonablethat r  is assumed to be 1.0 and r  is0.0 according to cosine function (4).
Asfor  and , it is necessary to set amargin between them, i.e., amount ofdifference from minimum value for rele-vant documents to maximum value forirrelevant ones.
If we take the margin as2.0, it is automatically determined thatand r .
As a result, targetvalues  for relevant and irrelevantdocuments are distributed from 0.6 to1.0, and from 0.0 and 0.4, respectively.max1rmin1.6 0=min0rmax0ma0rmin1rx .4 0=i(b) For probabilistic model, we set arbitrar-ily that r , andas a trial in the experiment.This means that range of documentscores is enlarged doubly, and each rfor relevant documents is to be distrib-uted in the range from s  to 2 .
Onthe other hand, maximum value of r  forirrelevant documents is  complicated alittle, i.e.,1max1max 2s= r smin max1 1=max1smaxrmin .0 0 0=i1i),min( 0min1min0max ssr =2/)],min(),[max( 0min1min0max1max ssss ?+ ,since there is no guarantee that s  is al-ways greater than s , and s  is alwayssmaller than smax1max0min0min1Segmentation of Japanese textThe test collection NTCIR-1 basically consists ofdocuments written in Japanese (as well as theNTCIR-3 patent test collection).
We need to seg-ment each text into a set of terms automatically forindexing the Japanese documents and queries, ofwhich text has no explicit boundary between termsunlike English.In the experiment, each term was identified bymatching with entries in a machine-readable dic-tionary.
We used a dictionary of the ChaSen[14],which is a well-known morphological analyzer forJapanese text, and selected each longest entrymatched with a portion of text as a index term.Also, an ?unknown?
string was decomposed ac-cording to change of kinds of character, Hiragana,Katakana, Kanji and so on (Hiragana strings werenot taken as index terms).Also, for identifying compound words as con-tent-bearing terms, we employed a heuristic rulethat an adjacent pair of index terms identified bydictionary matching is automatically combinedinto a compound word.ResultsThe NTCIR-1 collection includes 332,918 records,and average document length, i.e., average of thetotal number of terms appearing in each document,was 118.0.
Table 1 shows values of mean averageprecision of each run.As shown in Table 1, the Taylor formula basedmethod outperforms the Rocchio method slightly,but clearly there is no statistically significant dif-ference between ROCCHI and TYLVEC (.376and .378 at top 10, and .434 and .459 at top 20).The rate of improvement by feedback in vectorspace model is greater than that in probabilisticmodel.
The run showing best performance in Table1 is the Taylor formula based method in the vectorspace model (TYLVEC) using top-ranked 20documents, which increases mean average preci-sion at 101.6% from ORGVEC (from .228 to .459).Experiment on Pseudo Relevance Feed-back using NTCIR-3 Patent Test Col-lectionProcedureIn the previous section, the Taylor formula basedmethod has proven to work well at the experimentusing the NTCIR-1 test collection with relevanceinformation.
Next, we attempt to examine the ef-fectiveness of pseudo relevance feedback methodusing the Taylor formula based feedback in thecase of searching the NTCIR-3 patent test collec-tion (with no relevance information).The method and procedure are almost samewith those in the previous section.
However, in theRocchio method, D  is assumed to be empty (?
is0 in the Equation (1)).Table 1.
Mean average precision (using theNTCIR-1 collection with relevance information)model Vector space  Probabilis-ticinitial search(baseline)ORGVEC.228ORGPRB.268feedback ROCCHI TYLVEC TYLPRBtop 10 docu-ments.376(+65.2%).378(+66.3%).396(+48.0%)top 20 docu-ments.434(+90.4%).459(+101.6%).450(+68.1%)In the experiment, only six runs were executedas shown in Table 2 (at the time of the NTCIR-3Workshop, only the six runs were submitted).
Wediscern two kinds of run according to query (topic)fields used for run; (I) <ARTICLE> and <SUP-PLEMENT> fields and (II) <DESCRIPTION> and<NARRATIVE> fields.
The <ARTICLE> fieldincludes a news article, i.e., in the NTCIR-3 PatentTask, the participants were asked to search thedocument collection for a news article related tothe information needs of users.
The number of top-ics is 32.Table 2.
Runs in the experiment using patent testcollectionTopic fields Initial runfeedback<A><S>* <D><N>**OKAPI TAYLOR Run1 Run2VECTOR ROCCHIO Run3 Run4OKAPI none Run5 Run6*<A>:<ARTICLE>, <S>:<SUPPLEMENT>**<D>:<DESCRIPTION>,<N>:<NARRATIVE4.2 ResultsIn the indexing phase, 697,262 records were proc-essed and average length of documents is 393.32.Table 3 shows search performance of each run.Unfortunately, pseudo relevance feedback usingrelevance feedback techniques has no effect on theperformance.
It seems that there are no statisticallysignificant differences between any pairs of runs.However,00.10.20.30.40.50.60.70.80.90 0.1 0.2 0.3 0.4 0.5 0.6 0.7OKAPI-none (baseline)TAYLORandROCCHIOROCCHIOTAYLORFigure 1.
Topic-by-topic Analysis (in the case ofusing <DESCRIPTION> and <NARRATIVE>)Figure 1 is a plot of values of average precisionby topic.
We can compare the Taylor formulabased method (OKAPI-TAYLOR) and the Roc-chio method (VECTOR-ROCCHIO) with normalOkapi formula (OKAPI-none), in level of eachtopic.
It should be noted that, in Figure 1, squareindicates ROCCHIO and circle TAYLOR.Figure 1 shows that for most of topics, normalOkapi formula outperforms the Rocchio methodand Taylor formula based method although theRocchio method and Taylor formula based methodare superior in some topics.Table 3.
Average Precision and R-precision (Using NTCIR-3 Patent Test Collection)Topic Fields Initial run feedback Average precision R-precisionOKAPI TAYLOR 0.1152 0.1421VECTOR ROCCHIO 0.1281 0.1565<ARTICLE><SUPPLEMENT>OKAPI none 0.1282 0.1565OKAPI TAYLOR 0.1370 0.1820VECTOR ROCCHIO 0.1581 0.1896<DESCRIPTION><NARRATIVE>OKAPI none 0.1583 0.18135 DiscussionAlthough the Rocchio method and Taylor formulabased method have shown good performance in thepreliminary experiment using the NTCIR-1 testcollection with relevance judgment with relevancejudgment information, unfortunately the pseudorelevance feedback was not able to show im-provement of search effectiveness.
A main reasonfor the failure may be that term selection processwas omitted.
In standard pseudo relevance feed-back methods, better terms are usually selectedfrom the set of top-ranked documents according tothe term weights.
We can expect that if the termselection process is applied, the performance isimproved in the case of the Rocchio method.
How-ever, how can we select better terms in the case ofthe Taylor formula based method?The behavior of the Taylor formula basedmethod in the process of term re-weighting is alittle complicated.
For example, we assume thatthere are only 6 distinct terms (from term1 toterm6) in a database, and thatb = ( .
, .
, .
, .
, .
, .
)05 05 05 05 05 05 T ,which means that all term weights in the initialquery vector are equal.
The matrix of weights ofterms in top-ranked 4 documents (from doc1 todoc4) is supposed to be that??????????????=111200112100110021110012XA.
(16)A row of the matrix represents each document vec-tor, e.g.,d  )1,1,0,0,1,2(1 =TFurthermore, it is assumed that a set of numeri-cal values indicating degree of relevance for eachdocument was given by a user, and difference frominitial document scores was calculates such thatr sX XT?
= ?
?
( .
, .
, .
, .
)01 0 2 01 0 2 .
(17)Under these assumptions, relevance feedback bythe Taylor formula based method is as follows.First, by the SVD algorithm, the transpose matrixof the A  can be decomposed as UX V?
T , and aftersimple calculation, we can finally obtain thatU V r s??
?
= ?1 0 0 01 01 0 0 0 0 0 0T X X T( ) ( .
, .
, .
, .
, .
, . )
.
(18)This example represents well characteristics ofthe Taylor formula based method.
From (17) weunderstand that scores of doc1 and doc2 have to beincreased and those of doc3 and doc4 decreased.Intuitively, it seems that weights of both term1 andterm2 should be augmented because they are onlyappearing in doc1 and doc2, neither doc3 nor doc4at all.
However, a solution by (18) indicates thatthe weight of term1 is unchanged (only to that ofterm2, 0.1 is added).
This is a result so as to keepthe condition (17), which means that scores ofdoc1 and doc2 have to be increased by 0.1 and 0.2,respectively, for reaching at an ideal situation.
Ac-tually, we can calculate from (16) such that2 0 0 1 01 01?
+ ?
=.
.1 0 0 2 01 0.  for doc1 and that2?
+ ?
=.
.
.
for doc2.
The results indicatethat the condition (17) is completely satisfied.
Asshown in the simple calculation, the Taylor for-mula based method takes the difference r sX X?into consideration for re-weighting of search terms.On the other hand, in the case of the Rocchiomethod, re-weighting of search terms is done bylooking into only A  regardless of .
We sup-pose that doc1 and doc2 were judged as relevantdocuments, and doc3 and doc4 irrelevant.
In thecondition, the Rocchio method adds simply(1+2)/2=1.5 to weights of both of term1 and term2,not considering document scores in an initialsearch.X s XAs shown in above example, in the case of theTaylor formula based method, term re-weighting isdependent on the values of r .
Therefore, wecan not use simply the vector (18) for selectingbetter terms.
We have to consider carefully how touse the Equation (18) for term selection.
Furtherinvestigation will be needed for executing termselection for pseudo relevance feedback in the caseof the Taylor formula based method.sX ?
X6 Concluding RemarksIn this paper, results of two experiments on rele-vance feedback have been reported.
The purpose offirst experiment is to check performance of a newfeedback method proposed by Kishida[1] (the Tay-lor formula based method) in a normal situationwith relevance information.
The result has shownthat the Taylor formula based method works well.The second experiment aims at examining effec-tiveness of pseudo relevance feedback using theTaylor formula based method for searching a pat-ent collection.
Unfortunately, the pseudo relevancefeedback did not show good performance.
We needto devise a technique for selecting better terms[10] M. F. Moens and J. Dumortier.
2000.
Textcategorization: the assignment of subject de-scriptors to magazine articles.
InformationProcessing and Management, 36: 841-861.from top-ranked documents in the case of applyingthe new feedback method.References[1] K. Kishida.
2001.
Feedback method for docu-ment retrieval using numerical values on rele-vance given by users.
IPSJ SIG NotesFundamental Infology, 61: 189-196.
(in Japa-nese)[11] C. Buckley, J. Allan, and G. Salton.
1994.Automatic routing and ad-hoc retrieval usingSMART: TREC2.
in D.K.
Harman ed., TheSecond Text Retrieval Conference (TREC2).National Institute of Standards and Technology,Gaithersburg MD, 45-55.
[2] K. Kishida.
2003.
Experiment on Pseudo Rele-vance Feedback Method Using Taylor Formulaat NTCIR-3 Patent Retrieval Task.
Proceed-ings of the Third NTCIR Workshop on Re-search in Information Retrieval, AutomaticText Summarization and Question Answering,NII, Tokyo.
http://research.nii.ac.jp/ntcir/[12] S. E. Robertson, et al 1995.
Okapi at TERC-3.in D.K.
Harman ed.
Overview of the ThirdText Retrieval Conference (TREC-3).
NationalInstitute of Standards and Technology,Gaithersburg MD, 109-126.
[13] D. A. Harville.
1997.
Matrix Algebra from aStatistician?s Perspective.
Springer, New York.
[3] J. J. Rocchio, Jr. 1971.
Relevance feedback ininformation retrieval.
in G. Salton ed., TheSMART Retrieval System: Experiments inAutomatic Document Processing, Prentice-Hall, Englewood Cliffs, NJ, 313-323.
[14] Yuji Matsumoto, Akira Kitauchi, TatsuoYamashita, Yoshitaka Hirano, Hiroshi Matsuda,Kazuma Takaoka and Masayuki Asahara.
2000.Morphological Analysis System ChaSen version2.2.1 Manual.
http://chasen.aist-nara.ac.jp/[4] G. Salton and C. Buckley.
1990.
Improvingretrieval performance by relevance feedback.Journal of the American Society for Informa-tion Science, 41: 288-297.
Appendix.
Detail of Calculation[5] P. Sarinivasan.
1996.
Query expansion andMEDLINE.
Information Processing andManagement, 32: 431-4If we assume a linear function (11),???
?f XTXT X( ) ( )bbA bbA= = , 43.which is a well-known result in the field of linearalgebra [13].
Therefore (13) becomes that[6] J. H. Lee.
1998.
Combining the evidence ofdifferent relevance feedback methods for in-formation retrieval.
Information Processingand Management, 34: 681-691.f fX X X(~) ( ) (~ )b b A b= + ?
b(it should be noted that K = 0 ).By following our assumption that r  is equal to Xf X (~)b  and noting that , we obtain that f X ( )b s=[7] R. Mandala, T. Tokunaga and H. Tanaka.
2000.Query expansion using heterogeneous thesauri.Information Processing and Management, 36:361-378.XXA b b r sX X(~ )?
= ?
.
(A.1)The (14) is easily derived from (A.1).
[8] M. Iwayama.
2000.
Relevance feedback with asmall number of relevance judgments: incre-mental relevance feedback vs.
Document clus-tering.
in Proceedings of the 23rd AnnualInternational ACM SIGIR Conference on Re-search and Development in Information Re-trieval, ACM Press, 10-16.By using singular value decomposition we canobtain that .
The transposition is that A U VXT = ?
T( ) ( )A A U V V UX XT T T T T= = =?
?
,                (A.2)because  and U V  are orthogonal matrixes and ?
isa diagonal matrix.
Substituting (A.2) into (A.1), wefinally obtain thatV U b b r s?
T X X(~ )?
= ?
.~[9] G. Ciocca.
and R. Schettini.1999.
A relevancefeedback mechanism for content-based imageretrieval.
Information Processing and Man-agement, 35: 605-632.
)(1 XXT srVUbb ??+=?
?
.
